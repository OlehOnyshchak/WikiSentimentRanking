{
  "pages": [
    {
      "title": "Boris Galerkin",
      "url": "https://en.wikipedia.org/wiki/Boris_Galerkin",
      "text": "'''Boris Grigoryevich Galerkin''' ({{lang-ru|Бори́с Григо́рьевич Галёркин}}, surname more accurately [[Romanization|romanized]] as '''Galyorkin'''; {{OldStyleDate|4 March|1871|20 February}}&nbsp;– 12 July 1945), born in [[Polotsk]], [[Vitebsk Governorate]], [[Russian Empire]], was a [[USSR|Soviet]] [[mathematician]] and an [[engineer]].\n\n==Biography==\n\n===Early days===\nGalerkin was born on {{OldStyleDate|March 4|1871|February 20, 1871}} in [[Polotsk]], [[Vitebsk Governorate]], [[Russian Empire]], now part of [[Belarus]], to Jewish<ref>{{Citation|first=Karl-Eugen|last=Kurrer|title=The History of the Theory of Structures|page=1999|url=https://books.google.com/books?id=BcbxRXYUFc0C&pg=PA1999&lpg=PA1999&dq=boris+galerkin+jewish&source=bl&ots=NhWi4-z1ly&sig=ChFb7Rk1trmPz-OVv99rsNopszs&hl=en&sa=X&ved=0ahUKEwj1-4Gd5P_WAhXn5YMKHaOiB1sQ6AEIXDAJ#v=onepage&q=boris%20galerkin%20jewish&f=false|accessdate=2017-10-20}}</ref><ref>{{citation|title=Jewish Encyclopedia of Russia Surnames starting with the letter G|url=https://www.jewishgen.org/Belarus/misc/JewishEncycRussia/g/index.html|accessdate=2017-10-20}} by way of the [[Jewish Encyclopedia|Jewish Encyclopedia of Russia]]</ref><ref>http://www.jinfo.org/Mathematics.html and http://www.jinfo.org/Mathematics_Comp.html</ref> parents, Girsh-Shleym (Hirsh-Shleym) Galerkin and Perla Basia Galerkina. His parents owned a house in the town, but the homecraft they made did not bring enough money, so at the age of 12, Boris started working as [[calligrapher]] in the court. He had finished school in Polotsk, but still needed the exams from an additional year which granted him the right to continue education at a higher level. He passed those  in [[Minsk]] in 1893, as an external student. The same year he was enrolled at the [[St. Petersburg Technological Institute]], at the mechanics department. Due to the lack of funds Boris Grigoryevich had to combine studying at the institute with working as a draftsman and giving private lessons. In some point of his life, he married Revekka Treivas, a second niece. They did not have any children.\n[[File:Boris Galerkin 01.jpg|thumb|200px|right|Boris Galerkin]]\n\n===Political activities and imprisonment===\nLike many other students and technologists, he was involved in political activities, and joined the social-democratic group. In 1899, the year of graduating from the institute, he became a member of the [[Russian Social-Democratic Party]] (which would become the [[Communist Party of the Soviet Union]]). This provides a plausible explanation for his frequent job changes. The first three years after graduation Boris Grigoryevich was an engineer at the Russian Mechanical and Steam-locomotive Union factory in [[Kharkov]], while simultaneously teaching workers at special courses. From the end of 1903 he was an engineer on the construction of the [[China Far East Railway]], half a year later he became the technical head at the 'North mechanical and boiler factory' . He participated in organizing the Union of Engineers in St. Petersburg and, in 1905 he was arrested for organizing a strike among the engineers. In 1906, Boris Grigoryevich became a member of the Social-Democratic Party's St. Petersburg Committee and did not work anywhere else.\n\nIn prison, known as \"Kresty\", Boris Grigoryevich lost interest to revolutionary activities and devoted himself to science and engineering, activities which prisoners of that time could pursue. And what is more, in his work-book it is written that Boris Grigoryevich worked as an engineer at designing and constructing the boiler power plant from 1907. This fact was not explained, and Boris Grigoryevich did not like to remind others about his revolutionary youth. Later, in Soviet questionnaires he would not give clear answers on the persistent questions about membership in different parties. Of course, he was familiar with the fate of old Party members, but the main reason for it was that he had been elected to the Committee from the [[Mensheviks]] (a Party group with non-radical views, whose members were later accused of contra-revolutionary activities and repressed). Galerkin's life could become the price if this fact became known to the public.\n\n===Academic===\nSame year his first scientific work was published by the institutes \"Transactions\". The article was titled \"A theory of longitudinal curving and an experience of longitudinal curving theory application to many-storied frames, frames with rigid junctions and frame systems\". The length of the title was indicative of the length of the work itself, 130 pages. It was written in the \"Kresty\" prison. In the summer of 1909 Boris Grigoryevich had a trip abroad to see constructions and buildings which interested him. During the next four years, i.e., before World War I, he and many other institute staff visited Europe to stimulate their scientific interests. Galerkin visited [[Germany]], [[Austria]], [[Switzerland]], [[Belgium]] and [[Sweden]].\n\nGalerkin taught students at the mechanical department structural mechanics, i.e., conducted exercises and designing. The lecturer was professor [[V.L.Kirpichov]] - a famous scientist in the field of mechanics and per se the head of the [[Petersburg mechanical scientific school]]. However, most members also worked in the [[Saint Petersburg Polytechnical University|Polytechnical Institute]], for example: [[Ivan Bubnov]], [[A.N. Krylov]], [[I.V. Meshcherskiy]] and [[S.P. Timoshenko]].\n\nFrom autumn 1911, Galerkin also worked at the Women's Polytechnical Institute. In 1913 he worked with the design of the metallic frame for a boiler power plant in [[St. Petersburg]] - the first building with metallic frame under big loads in Russia. Later it was considered to be one of the unique European engineering objects. Galerkin regularly published his works in the institutes \"Transactions\", and since 1915 - also in [[Engineering News-Record#History|Engineering News]]. Before 1915 pivot systems were at the center of his scientific interest, later he started researching plates.\n\nIn 1915 Galerkin published an article in which he put forward an idea of an approximate method for [[differential equation]]s, in particular [[boundary value problem]]s. He had applied his method to a big number of pivot and [[Plate theory|plate]] analysis problems. Some time before I.G.Bubnov developed a similar approach for the [[Calculus of variations|variational problem]] solution, which he interpreted as a variant of [[Ritz method]] [[algorithm]]. The distinguishing features of Galerkin's method were the following: he did not associate the method, developed by him, with any variational problem direct solution, but considered it to be common for solving differential equations. He interpreted it, using the probable displacements principle. These ideas showed to be very productive, not only in [[structural mechanics]], but for [[mathematical physics]] at large.\n\nThe [[Galerkin method]] (or Bubnov-Galerkin method) with Galerkin's (or \"[[weak formulation|weak]]\") differential equations problem statement form are known all over the world. Nowadays they provide a foundation for algorithms in the fields of [[mechanics]], [[thermodynamics]], [[electromagnetism]], [[hydrodynamics]] and many others.\n\nIn January 1919, Galerkin became a professor in the 2nd (formerly Women's) Polytechnical Institute, remaining a teacher of structural mechanics in the 1st Polytechnical Institute (at that time the Polytechnical Institute was named so) mechanical department. In March 1920, a professor chair in structural mechanics was established at the department, and Boris Grigoryevich won it in a competition. In Summer 1921, [[S.P. Belzetskiy]], a famous scientist in the field of structural mechanics and theory of elasticity, who was holding a similar chair at the [[civil engineering]] faculty, emigrated to [[Poland]]. Galerkin took part in a competition for his chair and in the beginning of 1922 he left the mechanical faculty for the civil engineering faculty, which was nearer to him in his scientific and engineering activities.\n\nHowever his talent at that time was not wanted by anyone and he could concentrate his attention towards scientific problems. Before, in 1917-1919 Galerkin published a series of works on rectangular and triangular plates curving in scientific periodicals, mentioned above, and in the \"Russian Academy of Sciences Transactions\". Later he had a break in publications, and only in 1922 he began publishing again, but only in foreign magazines (in the [[Soviet Union]] there was not enough paper for scientific literature).\n\nIn December 1923 Galerkin was elected [[dean (education)|dean]] of the Polytechnical Institutes civil engineering faculty. It happened during a very important period of the institute's history, when a group of deans resigned from their posts, protesting from unceremonious intervention of so-called \"student' representatives\", controlled by the trade-unions and the Communist party committees, into the educational process. Galerkin showed to be a talented leader of the faculty. He managed to neutralize too active \"assistants\", who were appointed against his will, and he did not hurry to fulfill the orders of incompetent leaders, who were conducting infinite experiments in the higher school at that time. In 1924 - 1929 Galerkin was also a professor in the [[Railway Engineers Institute]] and in the St. Petersburg University. In 1924 he made his last trip abroad&nbsp;– he participated in the Congress on applied mechanics in the [[Netherlands]].\n\nIn spring 1926 Galerkin learned that [[Narkompros]] (Ministry of education) had adopted a decision to close the road-making section at his faculty. This decision was prepared and adopted secretly from the dean by the institute Communist party committee in the connection with the company on elimination of parallel specialities. Meanwhile, there were no other faculties in the country, training specialists in the construction of electrified railways, urban railways and subways (the faculty had worked on this since 1907). Galerkin managed to cancel this rash decision by [[Moscow]]. During the period of Galerkin at the dean post, the first laboratory at the faculty was created. He also managed to receive governmental approval of the idea to build some other big laboratories for the faculty (the [[Hydrotechnical Research Institute]] was later established on their base).\n\nIn January 1928 Galerkin was appointed as a corresponding member-elected at the [[USSR Academy of sciences]]. His candidature was nominated by academicians  A.F. Yoffe ([[Abram Ioffe]]), [[A.N. Krylov]], [[P.P. Lazarev]]. In October 1929 he left the dean's post. After this the civil engineering faculty was divided into two parts: the [[Hydromechanics|hydrotechnical]] and [[irrigation]] sections became the [[water industry]] faculty, and the rest that became a part of the civil engineering faculty. was soon left out of the Polytechnical Institute and became the [[Civil and Industrial Engineering Institute]], which however does not exist anymore. The [[water industry]] faculty soon became the Hydrotechnical institute. Galerkin was a professor at both institutes.\n\nBy the 1920s, Galerkin was already a world-famous scientist. He had had become an authority among engineers-designers. He was often recruited as a consultant to the designing and construction of serious industrial objects in the north-west Russia (heat power plants, [[Volkhov hydro power plant]], [[Kondopoga]] [[Pulp Mill|pulp]] and [[paper mill]] and others). He was a member of the technical Councils of the designing institutes Gipromez and Giprotsvetmet, a member of the [[academic council]]s in the research institutes: [[Irrigation Institute]] (later&nbsp;– Hydrotechnical Research Institute), [[Institute of Structures]]. After the end of the [[Dnieper Hydroelectric Station]] construction Boris Grigoryevich also became a member of the governmental commission.\n\nIn 1934, Galerkin got two [[doctoral degree]]s in [[Engineering|technics]] and [[mathematics]] and the Honoured Worker in Science and Engineering title. In the beginning of 1936 he was elected a member of the USSR Academy of sciences. He also became a member of the highest Certifying Commission in the State Committee on higher technical education, a chairman of the technical mechanics group in the [[USSR Academy of sciences technical section]], the headmaster of the USSR Academy of sciences Institute of Mechanics, the chairman of the [[Civil engineers scientific society]] and its [[Saint Petersburg|Leningrad]] section. In April 1936 according to a governmental order Galerkin was appointed chairman of the Governmental Commission for the examination of the Moscow [[Palace of Soviets]] steel frame walls and overlappings initial project.\n\nThough having so many titles, Galerkin remained a professor of the structural mechanics and theory of elasticity department at the hydrotechnical faculty (the Hydrotechnical Institute was returned to the [[Institute of technology|Polytechnical]] (at that time&nbsp;– Industrial) Institute as a faculty in 1934). Mostly he taught the course of the theory of elasticity, which was very difficult for the students of that time, who had a very weak training in mathematics. Students were visiting his lectures to look at the \"real academician\", but he disappointed them. He was short, puny, had a weak voice. His image did not correspond to the status of serious scientist with big authority, received from the government. At one time the academician was even pulled out of a tram by other well-grown passengers, and after this \"accident\" the institute administration applied to the authorities for a car.\n\n===War times and death===\nGalerkin drew in [[general]]s uniform in 1939, when the [[Military engineering-technical university|VITU of Navy]] (previously known as the Nikolaevsky Engineering Academy, now [[Military engineering-technical university]], Russian: [[:ru:Военный инженерно-технический университет|Военный инженерно-технический университет]]), was revival on the base of [[Civil and Industrial Engineering Institute]], as the head of its structural mechanics department and the academician became a [[lieutenant general]]. Boris Grigoryevich had never been in the army before, but had to wear the generals uniform. He was shy and when someone [[salute]]d to him he usually got frightened and waved his hands.\n\nIn the summer of 1941 after the beginning of the war the [[Commission on the defensive installations construction]] was created by the city government. Some academicians and prominent scientists became members (almost everyone was from the Polytechnical Institute), but only Boris Grigoryevich was involved with construction engineering. Practically he became the supervisor of the work for the Commission. Simultaneously Boris Grigoryevich was the city engineering defence department experts group head.\n\nLater he was evacuated to Moscow, where he joined the military engineering commission of the Academy of Sciences of the USSR. Hard non-stop work was undermining the scientist's health. Not long after the [[Victory in Europe Day|Great Victory]], on July 12, 1945 Galerkin died in Moscow.\n\n==Mathematical contributions==\nGalerkins name is forever attached to the [[finite element method]], which is a way to [[numerical analysis|numerically]] solve [[partial differential equations]]\n\n''Galerkin'' methods include:\n*The [[Galerkin method]] - A method for approximating the solution to a problem in [[weak formulation|weak form]]. Most well known in the [[finite element method]].\n*The [[Petrov–Galerkin method]]\n*The [[streamline upwind Petrov–Galerkin method]] (SUPG)\n*The [[Discontinuous Galerkin method]]\n\n==References==\n{{reflist}}\n* [https://web.archive.org/web/20060517215854/http://smitu.cef.spbstu.ru/galerkin_en.htm  Saint-Petersburg State Polytechnical Universitys Galerkin biography]\n\n==External links==\n* {{MacTutor Biography|id=Galerkin}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Galerkin, Boris Grigoryevich}}\n[[Category:1871 births]]\n[[Category:1945 deaths]]\n[[Category:People from Polotsk]]\n[[Category:People from Vitebsk Governorate]]\n[[Category:Belarusian Jews]]\n[[Category:Belarusian mathematicians]]\n[[Category:Soviet mathematicians]]\n[[Category:Military Engineering-Technical University faculty]]\n[[Category:People associated with the finite element method]]\n[[Category:Saint Petersburg State Institute of Technology alumni]]\n[[Category:Full Members of the USSR Academy of Sciences]]\n[[Category:Stalin Prize winners]]\n[[Category:Recipients of the Order of Lenin]]"
    },
    {
      "title": "Alexander Hrennikoff",
      "url": "https://en.wikipedia.org/wiki/Alexander_Hrennikoff",
      "text": "{{Infobox scientist\n| name              = Alexander Hrennikoff\n| image             = Alexander_Hrennikoff.jpg\n| image_size        = \n| caption           = Russian-Canadian engineer Alexander Hrennikoff\n| birth_date        = \n| birth_place       = [[Russian Empire|Russia]], 1896\n| death_date        = {{Death date |1984|12|31|df=y}}\n| death_place       = \n| nationality       =  \n| citizenship       = \n| field             = [[Engineering]] \n| alma_mater        = [[Moscow State University of Railway Engineering|Institute of Railway Engineering]] <br> [[University of British Columbia]]<br>[[Massachusetts Institute of Technology]]  \n| doctoral_advisor =  \n|academic_advisors = \n|doctoral_students = \n|notable_students  = \n| known_for         = Structural Engineering\n|author_abbrev_bot = \n|author_abbrev_zoo = \n|influences        = \n|influenced        = \n| awards            = \n|religion          = \n| signature         =  \n|footnotes         = \n}}\n'''Alexander Pavlovich Hrennikoff''' ({{lang-ru|Александр Павлович Хренников}}; 11 November 1896 — 31 December 1984) was a [[Russia]]n-[[Canadians|Canadian]] [[Structural Engineer]], a founder of the [[Finite Element Method]].\n\n==Biography==\nAlexander was born in [[Russian Empire|Russia]], graduated from the [[Moscow State University of Railway Engineering|Institute of Railway Engineering]] in [[Moscow]], received M.A.Sc. degree from the [[University of British Columbia]] (1933), and [[D.Sc]] degree from the [[Massachusetts Institute of Technology]] (1941). From 1933 until his death in 1984 he worked as a professor of Civil Engineering at the [[University of British Columbia]].<ref>[http://www.library.ubc.ca/archives/pdfs/chronicle/AL_CHRON_1985_1.pdf The Alumni UBC Chronicle]</ref><ref>[http://www.library.ubc.ca/archives/pdfs/calendars2/UBC_Calendar_1953_54.pdf The University of British Columbia - Calendar]</ref>\n\n==Work==\nDuring his work at the [[Massachusetts Institute of Technology]] he developed the '''lattice analogy''' which models membrane and [[Plate (metal)|plate]] bending of structures as a [[latticework|lattice]] framework. While this work received little attention at the time because of the lack of computational power, it is often considered as the turning point in the [[Structural analysis#Timeline|Time-Line of the Structural Analysis]] leading to development of the [[Finite Element Method]]. He later extended the lattice models to plate and shell buckling problems, and made important contributions to the plastic design theory of metal structures.\n\n==References==\n{{reflist}}\n*A. Hrennikoff, ''Solution of Problems of Elasticity by the Frame-Work Method'' (1941). ASME J. Appl. Mech. '''8''', A619–A715.\n*C. A. Felippa, ''The Amusing History of Shear Flexible Beam Elements'', 2005, available online as [http://titan.colorado.edu/Felippa.d/FelippaHome.d/Publications.d/Report.CU.CAS-05-01.pdf]{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}\n*J. T. Oden, ''Historical Comments on Finite Elements'', available online as [http://delivery.acm.org/10.1145/50000/41592/p125-oden.pdf?key1=41592&key2=9248702511&coll=ACM&dl=GUIDE&CFID=15151515&CFTOKEN=6184618]{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}\n\n==External links==\n*[http://digitalcollections.library.ubc.ca/cdm/singleitem/collection/arphotos/id/2753 Photograph of Alexander Hrennikoff]\n\n{{authority control}}\n\n{{DEFAULTSORT:Hrennikoff, Alexander}}\n[[Category:1896 births]]\n[[Category:1983 deaths]]\n[[Category:Russian inventors]]\n[[Category:Canadian inventors]]\n[[Category:Canadian civil engineers]]\n[[Category:Structural engineers]]\n[[Category:Russian engineers]]\n[[Category:Imperial Russian emigrants to Canada]]\n[[Category:University of British Columbia faculty]]\n[[Category:People associated with the finite element method]]\n[[Category:20th-century inventors]]\n\n\n{{Canada-scientist-stub|Hrennikoff}}\n{{Russia-scientist-stub}}"
    },
    {
      "title": "Thomas J.R. Hughes",
      "url": "https://en.wikipedia.org/wiki/Thomas_J.R._Hughes",
      "text": "{{multiple issues|\n{{advert|date=September 2016}}\n{{third-party|date=September 2016}}\n{{BLP sources|date=January 2010}}\n}}\n{{Infobox scientist\n| name = Thomas Joseph Robert Hughes\n| image = Thomas Hughes 15202836874 888f90762b o.jpg|\n| caption = Thomas J.R. Hughes 2014\n| birth_date = 1943\n| birth_place = \n| death_date = \n| death_place = \n| residence = [[Austin, Texas]]\n| nationality = [[United States|American]]\n| field = [[Computational mechanics]]<br/> [[Finite element method]]\n| work_institution = [[The University of Texas at Austin]]\n| alma_mater = [[Pratt Institute]]<br/> [[University of California, Berkeley]]\n| doctoral_advisor =\n| doctoral_students = \n| known_for = [[Computational mechanics]]<br/> [[Finite element method]]\n| prizes = [[Timoshenko Medal]] {{small|(2007)}}<br>[[Theodore von Karman Medal]] {{small|(2009)}}\n| religion = \n| footnotes =\n}}\n\n'''Thomas Joseph Robert Hughes''' (born 1943) is a Professor of Aerospace Engineering and Engineering Mechanics and currently holds the Computational and Applied Mathematics Chair III at the Oden Institute at [[The University of Texas at Austin]].<ref name=facultyreview>{{cite web |url=http://users.oden.utexas.edu/~hughes/ |title=Thomas J.R. Hughes - Professor of Aerospace Engineering and Engineering Mechanics |publisher=University of Texas at Austin |archivedate=December 6, 2014 |deadurl=no |archiveurl=https://web.archive.org/web/20141206051546/http://users.oden.utexas.edu/~hughes/ |accessdate=June 24, 2017 |df= }}</ref><ref name=department&phd>{{cite web |url=http://www.ae.utexas.edu/faculty/faculty-directory/hughes |title=Department of Aerospace Engineering and Engineering Mechanics |publisher=University of Texas at Austin |archivedate=December 23, 2014 |deadurl=no |archiveurl=https://web.archive.org/web/20141223214845/http://www.ae.utexas.edu/faculty/faculty-directory/hughes |accessdate=June 24, 2017 |df= }}</ref>\nHughes has been listed as an ISI Highly Cited Author in Engineering by the [[ISI Web of Knowledge]], Thomson Scientific Company.<ref>[http://hcr3.isiknowledge.com/author.cgi?&link1=Browse&link2=Results&id=505 ISI Highly Cited Author - T. J. R. Hughes]</ref>\n\nA leading expert in [[computational mechanics]], Hughes has received numerous academic distinctions and awards for his work. He is a research fellow of the [[United States National Academy of Sciences|National Academy of Sciences]], [[National Academy of Engineering]], [[American Academy of Arts & Sciences]], the American Academy of Mechanics, the American Society of Mechanical Engineers (ASME), the U.S. Association for Computational Mechanics (USACM), the International Association for Computational Mechanics (IACM), the [[American Association for the Advancement of Science]], and has been elected as a foreign member of [[The Royal Society]]. He is a founder and past President of USACM and IACM, and past Chairman of the Applied Mechanics Division of ASME.\n\n==Career==\nHughes began his career as a mechanical design engineer at [[Grumman|Grumman Aerospace]], subsequently joining [[General Dynamics]] as a research and development engineer. After receiving his Ph.D. from [[University of California, Berkeley]],<ref name= department&phd/><ref name= phd_ucb>{{cite web|url=https://www.ices.utexas.edu/people/339/|title= Thomas J.R. Hughes,Ph.D. - UC Berkeley|publisher=''Institute for Computational Engineering and Sciences'', [[Institute for Computational Engineering and Sciences|ICES]] |deadurl=no |archivedate=November 5, 2011 |archiveurl=https://web.archive.org/web/20111105053922/https://www.ices.utexas.edu/people/339/ |accessdate=June 24, 2017}}</ref> he joined the [[University of California, Berkeley|Berkeley]] faculty, eventually moving to [[California Institute of Technology]]. He then moved to [[Stanford University]] before joining The University of Texas at Austin. At Stanford, he served as Chairman of the Division of Applied Mechanics, Chairman of the Department of Mechanical Engineering, and Chairman of the Division of Mechanics and Computation, and occupied the Mary and Gordon Crary Chair of Engineering. While at Stanford he served as a member of International Advisory Committee, [[ICTACEM]] (2001).<ref name=Internationalcommittee>{{cite web|url=http://www.jeo.org/ictacem/acommittee.html|title=T. Hughes - International Advisory Committee|publisher='' International Conference on Theoretical, Applied, Computational and Experimental Mechanics'', [[ICTACEM]]|archivedate=September 2, 2000|deadurl=no|archiveurl=https://web.archive.org/web/20000902155159/http://www.jeo.org/ictacem/acommittee.html|df=}}</ref>\n\nHughes has developed computational methods for understanding solid, structural and fluid mechanics. He recently has applied this expertise to develop customized models of blood flow for patients using their individual imaging records such as [[X-ray computed tomography|CT]] scans and [[MRI]]s.\n\n==Books==\n\n* Thomas J. R. Hughes and [[Jerrold E. Marsden]], A Short Course in Fluid Mechanics, Mathematics lecture series, v. 6, Boston: Publish or Perish, 1976.\n* Thomas J. R. Hughes, D. Gartling, Robert L. Spilker, Applied Mechanics Division, Vol. 44: New Concepts in Finite Element Analysis, [[ASME]], 1981.\n* Thomas J. R. Hughes, A. Pifko, A. Jay, Applied Mechanics Division, Vol. 48: Nonlinear Finite Element Analysis of Plates and Shells, [[ASME]], 1981.\n* Thomas J. R. Hughes, Stress-point algorithm for a pressure-sensitive multiple-yield-surface plasticity theory, Unknown Binding, Available from National Technical Information Service, 1982.\n* Computational methods for transient analysis, edited by Ted Belytschko and Thomas J.R. Hughes, Computational methods in mechanics, Volume 1: Mechanics and mathematical methods, New York: Elsevier Science Pub. Co., 1983.\n* Thomas J. R. Hughes and Englewood Cliffs, The finite element method: linear static and dynamic finite element analysis, NJ: Prentice-Hall, (1987), 1985.\n* Thomas J. R. Hughes, [[Ernest Hinton]]. Finite Element Methods for Plate and Shell Structures, Volume 1: Element Technology, Pineridge Press Ltd, 1986.\n* Thomas J. R. Hughes, Ernest Hinton. Finite Element Methods for Plate and Shell Structures, Volume 2: Formulation and Algorithms, Pineridge Press Ltd, 1986.\n* Jerrold E. Marsden and Thomas J. R. Hughes, Mathematical Foundations of Elasticity, Dover Publications, 1994.\n* J.C. Simo and T.J.R. Hughes, Interdisciplinary applied mathematics, Volume 7: Computational inelasticity, New York: Springer, 1998.\n* Thomas J. R. Hughes, [https://books.google.com/books?hl=en&lr=&id=cHH2n_qBK0IC&oi=fnd&pg=PP1&dq=analysis+&ots=vssosad2WR&sig=3vLGNWRHqNXaEdJJk7MGcCPRWH0#v=onepage&q=analysis&f=false The Finite Element Method: Linear Static and Dynamic Finite Element Analysis], Dover Publications, 2000.\n* Erwin Stein, René de Borst, Thomas J.R. Hughes, Encyclopedia of Computational Mechanics, Volume 1: Fundamentals, Wiley, 2004.\n* Erwin Stein, René de Borst, Thomas J.R. Hughes, Encyclopedia of Computational Mechanics, Volume 2: Solids and Structures, Wiley, 2004.\n* Erwin Stein, René de Borst, Thomas J.R. Hughes, Encyclopedia of Computational Mechanics, Volume 3: Fluids, Wiley, 2004.\n* J. Austin Cottrell, Thomas J. R. Hughes, Yuri Bazilevs, Isogeometric Analysis: Toward Integration of CAD and FEA, Wiley, 2009.\n\n==Awards and honors==\n*Hughes has received several awards, including the Walter L. Huber Civil Engineering Research Prize from ASCE, the Melville Medal from ASME, the Computational Mechanics Award from the Japan Society of Mechanical Engineers, the von Neumann Medal from USACM, the Gauss-Newton Medal from IACM, and the Worcester Reed Warner Medal from ASME. He is also a recipient of [[Timoshenko Medal]] in 2007.<ref name=\"timo_medal\">''[http://www.asme.org/Governance/Honors/SocietyAwards/Timoshenko_Medal.cfm \"ASME Timoshenko Medal\"]'' asme.org. Retrieved 9 January 2010.</ref>\n*Honorary degree, [[University of Pavia]], 2007.\n*In 2009 he was awarded an [[Honorary degree|honorary doctorate]] by the [[Norwegian University of Science and Technology|Norwegian University of Science and Technology (NTNU)]].<ref>{{Cite web|url=https://www.ntnu.edu/phd/honorary-doctors|title=Honorary Doctors|last=|first=|date=|website=www.ntnu.edu|language=en|archive-url=|archive-date=|dead-url=|access-date=2018-08-30}}</ref>\n*In 2011 he was elected a [[Foreign Member of the Royal Society]].<ref>{{cite web | url = http://royalsociety.org/about-us/fellowship/foreign-members/| title = Foreign Members|publisher= Royal Society|accessdate= 2012-03-20}}</ref>\n*On June 21, 2013, Professor T.J.R. Hughes has named Doctor Honoris Causa from Escuela Técnica Superior Engenieros de Caminos, Canales y Puertos (E.T.S.I.C.C.P), at University of A Coruña (U.D.C) - Spain, into the ambit of Civil Engineering for his contributions in computational mechanics.\n\n==Videos==\n* Together with the [[Texas Advanced Computing Center]], he developed the video [https://www.youtube.com/watch?v=wHQY0o8RdS4 \"Simulating Patient-specific Nanoparticulate Drug Delivery for the Treatment of Vulnerable Plaques\"].\n\n==References==\n{{reflist}}\n\n==External links==\n*[http://users.ices.utexas.edu/~hughes/ T.J.R. Hughes webpage]\n*[http://www.ae.utexas.edu/faculty/faculty-directory/hughes/ T.J.R. Hughes Faculty, Directory Page, The University of Texas at Austin]\n\n{{FRS 2011}}\n{{Authority control}}\n\n{{DEFAULTSORT:Hughes, Thomas J.R.}}\n[[Category:21st-century American engineers]]\n[[Category:Fellows of the American Academy of Arts and Sciences]]\n[[Category:ISI highly cited researchers]]\n[[Category:Living people]]\n[[Category:People associated with the finite element method]]\n[[Category:University of California, Berkeley College of Engineering alumni]]\n[[Category:University of Texas at Austin faculty]]\n[[Category:1943 births]]\n[[Category:Fellows of the Society for Industrial and Applied Mathematics]]\n[[Category:University of California, Berkeley faculty]]\n[[Category:California Institute of Technology faculty]]\n[[Category:Stanford University School of Engineering faculty]]\n[[Category:Members of the United States National Academy of Engineering]]\n[[Category:Members of the United States National Academy of Sciences]]\n[[Category:Fellows of the American Society of Mechanical Engineers]]\n[[Category:Fellows of the American Institute of Aeronautics and Astronautics]]\n[[Category:Foreign Members of the Royal Society]]"
    },
    {
      "title": "Bruce Irons (engineer)",
      "url": "https://en.wikipedia.org/wiki/Bruce_Irons_%28engineer%29",
      "text": "{{More citations needed|date=December 2012}}\n{{Infobox scientist\n| name              = Bruce M. Irons\n| image             = File:Bruce_Irons.jpg\n| image_size        = \n| caption           = \n| birth_date        = 1924\n| birth_place       = [[Southampton]], England\n| death_date        = {{Death date |1983|12|5|df=y}}\n| death_place       = [[Calgary]], [[Alberta]], Canada\n| nationality       = English, Canadian \n|citizenship       = \n| field             = [[Engineering]] \n| alma_mater        = [[University College, Southampton]] <br> [[University of Wales Swansea]] (D.Sc.)\n| doctoral_advisor  = \n|academic_advisors = \n|doctoral_students = \n|notable_students  = \n| known_for         = [[Finite element method]]\n|author_abbrev_bot = \n|author_abbrev_zoo = \n|influences        = \n|influenced        = \n| awards            = [[Von Karman]] Award 1974 <br> Bruce M. Irons Memorial Scholarship Univ Calgary\n|religion          = \n| signature         =  \n|footnotes         = \n}}\n\n'''Bruce Moncur Irons''' (6 October 1924 – 5 December 1983) was an engineer and mathematician, known for his fundamental contribution to the [[finite element method]], including the [[Patch test (finite elements)|patch test]], the [[frontal solver]] and, along with [[Ian C. Taig]], the [[isoparametric element]] concept.\n<ref>{{Citation\n | last =  OCZ IC\n | first = \n | title = Obituary: Professor Bruce Irons\n | journal = International Journal for Numerical Methods in Engineering\n | volume = 20\n | pages = 1167–1168\n | date = June 1984\n \n | doi = 10.1002/nme.1620200615\n}}</ref>\n<ref>{{cite book\n | last1 = Irons \n | first1 = Bruce\n | last2 = Sohrab\n | first2 = Ahmad\n | title = Techniques of Finite Elements\n | location = Chichester, West Sussex, England\n | publisher = Ellis Horwood Limited\n | year= 1980\n | page = 529\n | month = \n | isbn = }}</ref>\n\nHe developed [[multiple sclerosis]]; finding it difficult to accept anticipated relapses, he committed suicide on 5 December 1983, and his wife followed suit.<ref>{{Citation\n | last =  Cormeau\n | first = Ivan\n | title = Bruce Irons: A non-conforming engineering scientist to be remembered and rediscovered\n | journal = International Journal for Numerical Methods in Engineering\n | volume = 22\n | pages = 1–10\n | date = 22 Jun 2005\n  \n | doi = 10.1002/nme.1620220102\n}}</ref>\n\n==References==\n{{Reflist|30em}}\n\n==External links==\n* [https://web.archive.org/web/20140810204739/https://iac01.ucalgary.ca/FGSA/Public/SpecificAward.aspx?AwardID=2792 Bruce M. Irons Memorial Scholarship]\n\n{{Authority control}}\n\n{{DEFAULTSORT:Irons, Bruce}}\n[[Category:People associated with the finite element method]]\n[[Category:1983 deaths]]\n[[Category:1924 births]]\n[[Category:20th-century mathematicians]]\n\n\n{{Canada-engineer-stub}}\n{{mathematician-stub}}"
    },
    {
      "title": "Andrew Ronald Mitchell",
      "url": "https://en.wikipedia.org/wiki/Andrew_Ronald_Mitchell",
      "text": "{{Use dmy dates|date=February 2018}}\n{{Use British English|date=February 2018}}\n'''Andrew Ronald Mitchell''' (22 June 1921 – 22 November 2007), popularly known as '''Ron Mitchell''', was a [[British people|British]] [[applied mathematics|applied mathematician]] and [[numerical analysis|numerical analyst]].<ref name=\"siam\">{{cite web|url=http://www.siam.org/news/news.php?id=1291|title=Obituaries: A.R. Mitchell|date=6 January 2008|publisher=[[Society for Industrial and Applied Mathematics|SIAM]]|accessdate=13 March 2010|archive-url=https://web.archive.org/web/20110615084457/http://www.siam.org/news/news.php?id=1291|archive-date=15 June 2011|dead-url=yes}}</ref> He was a professor of mathematics at the [[University of St Andrews]], [[Dundee]], Scotland. He was known for his contributions to the field of [[numerical analysis]] of [[partial differential equation]]s in general and [[finite difference method]] and [[finite element method]] in particular.<ref name=\"MacTutor\">{{MacTutor Biography|id=WhoAreYou}}</ref> Mitchell has authored several influential books on numerical solution of partial differential equations, including \"The Finite Element Analysis in Partial Differential Equations\" with Richard Wait and \"The Finite Difference Method in Partial Differential Equations\" with David F. Griffiths.<ref name=\"birthday_volume\">{{cite book|last=Griffiths|first=D. F. |author2=G. A. Watson|title=Numerical analysis: A.R. Mitchell 75th birthday volume|publisher=World Scientific|year=1996|url=https://books.google.com/?id=zBinOrlPJqsC&printsec=frontcover&dq=AR+mitchell#v=onepage&q=&f=false|accessdate=13 March 2010 | isbn=978-981-02-2719-7}}</ref>\n\n==Early life and education==\nMitchell was born in [[Dundee]], Scotland, on 22 June 1921. His father was a blacksmith.<ref name=\"MacTutor\" /> Mitchell went to school at [[Morgan Academy]], Dundee. He played [[Association football|football]] at school and was invited to sign for North End Junior Football Club in Dundee. He left Morgan Academy in 1938 after receiving a scholarships through the school to do a mathematics degree in the University College, Dundee. He graduated with First Class Honours in 1942, and was called up and sent to the wartime Ministry of Aircraft Production in [[London]], where he remained until after the end of the [[World War II|war]]. While he was in London, he continued to play football during the war, turning out a few times for [[Chelsea F.C.|Chelsea]].<ref name=\"birthday_volume\" /> After the war he played for a number of Scottish clubs including [[St Johnstone F.C.|St Johnstone]], [[East Fife F.C.|East Fife]], [[Brechin City F.C.|Brechin City]]  before ending his playing career at [[Berwick Rangers F.C.|Berwick Rangers]] in 1955.\n\n== References ==\n{{Reflist}}\n\n==External links==\n*{{MathGenealogy|id=50758}}\n*{{NeilBrownPlayers|player4/ronmitchell}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Mitchell, Ron}}\n[[Category:1921 births]]\n[[Category:2007 deaths]]\n[[Category:20th-century mathematicians|Mitchell, Andrew Ronald]]\n[[Category:Alumni of the University of Dundee]]\n[[Category:Scottish mathematicians|Mitchell, Andrew Ronald]]\n[[Category:People associated with the finite element method|Mitchell, Andrew Ronald]]\n[[Category:People from Dundee|Mitchell, Andrew Ronald]]\n[[Category:Sportspeople from Dundee]]\n[[Category:Berwick Rangers F.C. players]]\n[[Category:Brechin City F.C. players]]\n[[Category:Chelsea F.C. wartime guest players]]\n[[Category:East Fife F.C. players]]\n[[Category:St Johnstone F.C. players]]\n[[Category:Scottish Football League players]]\n[[Category:Association football wing halves]]\n[[Category:Scottish footballers]]\n\n\n{{UK-mathematician-stub}}"
    },
    {
      "title": "Andreas Öchsner",
      "url": "https://en.wikipedia.org/wiki/Andreas_%C3%96chsner",
      "text": "{{Orphan|date=September 2018}}\n\n{{Infobox scientist\n| honorific_prefix =\n| name        = Andreas Öchsner\n| honorific_suffix =\n| native_name = \n| native_name_lang = Andreas Öchsner\n| image       = http://www.utm.my/imeditec2017/files/2017/02/advisory-08.png\n| image_size  = \n| alt         = \n| caption     = \n| birth_date  = 1970|10|19\n| birth_place = [[Blieskastel]], [[Germany]]\n| death_date  =        \n| death_place = \n| death_cause = \n| resting_place = \n| resting_place_coordinates =  <!--{{coord|LAT|LONG|type:landmark|display=inline,title}}-->\n| other_names = Andreas Oechsner\n| residence   = \n| citizenship = \n| nationality = [[File:Flag of Germany.svg|20px]] [[Germany|German]]\n| fields      = [[Computational mechanics]], [[Experimental Mechanics]], [[Finite Element Method]], [[Plasticity (physics)|Plasticity]], [[Thin Interphases]], Advanced [[Structured Materials]]<ref>{{cite web|title=Google Scholar|url=https://scholar.google.com.au/citations?user=-jQHnjUAAAAJ}}</ref>\n| workplaces  = [[University of Erlangen-Nuremberg]], [[University of Aveiro]], [[University of Technology, Malaysia]], [[University of Newcastle (Australia)]], [[Griffith University]]\n| patrons     = \n| education   = \n| alma_mater  = [[University of Stuttgart]], [[University of Erlangen]], [[University of Newcastle (Australia)]]\n| thesis_title =        <!--(or  | thesis1_title =  and  | thesis2_title = )-->\n| thesis_url  =         <!--(or  | thesis1_url  =   and  | thesis2_url  =  )-->\n| thesis_year =         <!--(or  | thesis1_year =   and  | thesis2_year =  )-->\n| doctoral_advisor =    <!--(or  | doctoral_advisors = )-->\n| academic_advisors = \n| doctoral_students = \n| notable_students = \n| known_for   = [[Finite Element Method]], [[Computational Statics and Dynamics]]\n| influences  = \n| influenced  = \n| awards      = \n| author_abbrev_bot = \n| author_abbrev_zoo = \n| spouse      =         <!--(or | spouses = )-->\n| partner     =         <!--(or | partners = )-->\n| children    = \n| signature   =         <!--(filename only)-->\n| signature_alt = \n| website     =  https://www.griffith.edu.au/engineering-information-technology/griffith-school-engineering/staff/professor-andreas-Ochsner\n| footnotes   = \n}}\n\n'''Andreas Öchsner''' (born 19 October 1970) is a professor, head of discipline, in mechanical engineering at [[Griffith University]], [[Queensland, Australia]].<ref>{{cite web|title=Griffith University Staff Profiles|url=https://www.griffith.edu.au/engineering-information-technology/griffith-school-engineering/staff/professor-andreas-Ochsner|access-date=2016-10-03|archive-url=https://web.archive.org/web/20161116181436/https://www.griffith.edu.au/engineering-information-technology/griffith-school-engineering/staff/professor-andreas-Ochsner|archive-date=2016-11-16|dead-url=yes|df=}}</ref> He is a conjoint Professor of the Centre for Mass and Thermal Transport in Engineering Materials at the [[University of Newcastle (Australia)]].<ref>{{cite web|title=Webpage of The University of Newcastle (Australia)|url=https://www.newcastle.edu.au/research-and-innovation/centre/cmttem/people|date=2014-02-06}}</ref>\nHe is the author and co-author of over 150 refereed journal papers, over 70 conference papers and 15 book-chapters in the area of [[advanced materials]] and [[structures]]. Furthermore, he is the author and co-author of five books and 13 research monographs.\n\n==Education==\n* D.Sc. - [[University of Newcastle (Australia)]], 2010\n* Ph.D. - [[University of Erlangen-Nuremberg]], [[Germany]], 2003\n* M.Sc. - [[University of Stuttgart]], [[Germany]], 1997\n\n==Research Interests==\n*Mechanics of Cellular Materials (Metals and Ceramics) \n*Experimental and Computational Mechanics\n*Thin Structures and Interphases\n*Diffusion Simulation in Metals\n*Adhesive Technology\n*Damage Mechanics\n\n==Summary of Publications==\n*Books (63)\n**Author (15)\n**Monographs (13)\n**Proceedings (14)\n**Chapters (21)\n*Journals (281)\n**International (197)\n**National (19)\n**Guest editor (65)\n*Conference Proceedings (77)\n\n==Books==\n# A. Öchsner: Experimentelle und numerische Untersuchung des elasto-plastischen Verhaltens zellularer Modellwerkstoffe [Experimental and Numerical Investigations of the Elastic Plastic Properties of Model Cellular Materials] (140 pages). Düsseldorf: VDI Verlag 2003.\n# M. Merkel, A. Öchsner: [https://www.springer.com/la/book/9783642544811 Eindimensionale Finite Elemente – Ein Einstieg in die Methode] [One-Dimensional Finite Elements: An Introduction into the Method] (422 pages). Berlin: Springer Verlag 2010.\n# M. Gromada, G. Mishuris, A. Öchsner: [https://www.springer.com/us/book/9783642221330 Correction Formulae for the Stress Distribution in Round Tensile Specimens at Neck Presence] (89 pages). SpringerBriefs in Applied Sciences and Technology (Computational Mechanics). Berlin: Springer Verlag 2011.\n# A. Öchsner, M. Merkel: [https://www.springer.com/gp/book/9783642317965 One-Dimensional Finite Elements – An Introduction to the FE Method] (398 pages). Berlin: Springer Verlag 2013.\n# A. Öchsner: [https://www.springer.com/us/book/9783642386459 Introduction to Scientific Publishing – Backgrounds, Concepts, Strategies] (96 pages). SpringerBriefs in Applied Sciences and Technology. Heidelberg: Springer Verlag 2013.\n# A. Öchsner: [https://www.springer.com/gp/book/9783662442241 Elasto-Plasticity of Frame Structure Elements – Modeling and Simulation of Rods and Beams] (596 pages). Berlin: Springer Verlag 2014. \n# S.I. Yengejeh, S.A. Kazemi, A. Öchsner: [https://www.springer.com/gp/book/9783662442241 A Primer on the Geometry of Carbon Nanotubes and their Modifications] (70 pages). Cham: Springer Verlag 2015.\n# H.R. Rezaie, L. Bakhtiari, A. Öchsner: [https://www.springer.com/gp/book/9783319178455 Biomaterials and Their Applications] (49 pages). Cham: Springer Verlag 2015.\n# M. Merkel, A. Öchsner: [https://www.springer.com/de/book/9783642049927 Eindimensionale Finite Elemente – Ein Einstieg in die Methode] [One-Dimensional Finite Elements: An Introduction into the Method], 2nd edition (428 pages). Berlin: Springer Vieweg Verlag 2015.\n# M. Öchsner, A. Öchsner: [https://www.springer.com/de/book/9783658095024 Das Textverarbeitungssystem LaTeX: Eine praktische Einführung in die Erstellung wissenschaftlicher Dokumente] [The text processing system LaTeX: A practical introduction into the preparation of scientific documents]. Wiesbaden: Springer Vieweg 2015.\n# F.A. Nasruddin, M.N. Harun, A. Syahrom, M.R.A. Kadir, A.H. Omar, A. Öchsner: [https://www.springer.com/gp/book/9783319217345 Finite Element Analysis on Badminton Racket Design Parameters] (47 pages). SpringerBriefs in Applied Sciences and Technology (Computational Mechanics). Cham: Springer 2016.\n# A. Öchsner: [https://www.springer.com/gp/book/9789812878632 Continuum Damage and Fracture Mechanics] (163 pages). Singapore: Springer 2016.\n# A. Öchsner: [https://www.springer.com/us/book/9789811007323 Computational Statics and Dynamics – An Introduction Based on the Finite Element Method] (485 pages). Singapore: Springer 2016.\n# A. Öchsner, M. Öchsner: [https://www.springer.com/it/book/9789811008207 The Finite Element Analysis Program MSC Marc/Mentat] (136 pages). Singapore: Springer 2016.\n# A. Öchsner: [https://www.springer.com/de/book/9783658146375 Theorie der Balkenbiegung: Einführung und Modellierung der statischen Verformung und Beanspruchung] [Theory of Beam Bending: Introduction and Modeling of the #Static Deformation and Loading] (44 pages). Wiesbaden: Springer Vieweg 2016.\n\n==Monographs==\n# A. Öchsner, G.E. Murch, M.J.S. de Lemos (Eds.): [http://au.wiley.com/WileyCDA/WileyTitle/productCd-3527319387.html Cellular and Porous Materials - Thermal Properties Simulation and Prediction] (422 pages). Weinheim, Germany: Wiley-VCH 2008.\n# W. Ahmed, N. Ali, A. Öchsner (Eds.): [http://www.ttp.net/978-0-87849-480-4.html Biomaterials and Biomedical Engineering] (555 pages). Stafa-Zurich, Switzerland: Trans Tech Publications Ltd, 2008.\n# L.F.M. da Silva, A. Öchsner (Eds.): [https://link.springer.com/book/10.1007%2F978-3-540-79056-3 Modeling of Adhesively Bonded Joints] (335 pages). Berlin, Germany: Springer 2008.\n# A. Öchsner, W. Ahmed and N. Ali (Eds.): [http://www.ttp.net/978-0-87849-346-3.html Nanocomposite Coatings and Nanocomposite Materials] (402 pages). Stafa-Zurich, Switzerland: Trans Tech Publications Ltd, 2009.\n# A. Öchsner, C. Augustin (Eds.): [https://link.springer.com/book/10.1007%2F978-3-642-00491-9 Multifunctional Metallic Hollow Sphere Structures] (258 pages). Berlin, Germany: Springer 2009.\n# N. Ali, A. Öchsner, W. Ahmed (Eds.): Carbon Based Nanomaterials (322 pages). Stafa-Zurich, Switzerland: Trans Tech Publications Ltd, 2010.\n# H. Altenbach, A. Öchsner (Eds.): [https://link.springer.com/book/10.1007%2F978-3-7091-0297-8 Cellular and Porous Materials in Structures and Processes], CISM Courses and Lectures Vol. 521 (334 pages). Wien, Austria: Springer 2010.\n# A. Öchsner, W. Ahmed (Eds.): [http://au.wiley.com/WileyCDA/WileyTitle/productCd-3527324313.html Biomechanics of Hard Tissues] (306 pages). Weinheim, Germany: Wiley-VCH 2010.\n# L.F.M. da Silva, A. Pirondi, A. Öchsner (Eds.): [https://www.springer.com/la/book/9783642166228 Hybrid Adhesive Joints] (309 pages). Berlin, Germany: Springer 2011.\n# L.F.M. da Silva, A. Öchsner, R.D. Adams (Eds.): [https://link.springer.com/referencework/10.1007%2F978-3-642-01169-6 Handbook of Adhesion Technology] (1548 pages in two volumes). Berlin, Germany: Springer 2011.\n# A. Öchsner, G.E. Murch (Eds.): [https://link.springer.com/book/10.1007%2F978-3-642-04403-8 Heat Transfer in Multi-Phase Materials] (460 pages). Berlin, Germany: Springer 2011.\n# A. Öchsner, A. Shokuhfar (Eds.): [https://www.springer.com/la/book/9783642146961 New Frontiers of Nanoparticles and Nanocomposite Materials] (371 pages). Berlin, Germany: Springer 2013.\n# H. Altenbach, A.Öchsner (Eds.): [https://www.springer.com/us/book/9783642409448 Plasticity of Pressure-Sensitive Materials] (376 pages). Berlin, Germany: Springer 2014\n\n==Conferences==\n# Chair of International Conference on Advanced Computational Engineering and Experimenting, ACE-X (since 2006)<ref>{{cite web|url=http://www.acex-conference.com/|title=ACEX Conference Webpage}}</ref>\n# Chair of International Conference on Diffusion in Solids and Liquids - DSL (since 2004)<ref>{{cite web|url=http://www.dsl-conference.com/|title=DSL Conference Webpage}}</ref>\n\n==References==\n{{reflist|30em}}\n{{authority control}}\n\n{{DEFAULTSORT:Öchsner, Andreas}}\n[[Category:Griffith University faculty]]\n[[Category:People associated with the finite element method]]\n[[Category:ISI highly cited researchers]]\n[[Category:1970 births]]\n[[Category:Living people]]"
    },
    {
      "title": "J. Tinsley Oden",
      "url": "https://en.wikipedia.org/wiki/J._Tinsley_Oden",
      "text": "{{Use mdy dates|date=October 2011}}\n{{Infobox scientist\n| name = John Tinsley Oden\n| image =\n| caption =\n| birth_date =  {{birth date and age|1936|12|25}}\n| birth_place =\n| death_date =\n| death_place =\n| residence =\n| nationality = [[Image:Flag of the United States.svg|20px|]] American\n| field = [[Computational mechanics]]\n| work_institution =  [[Oklahoma State University]]<br> [[The University of Alabama in Huntsville]]<br> [[The University of Texas at Austin]]\n| alma_mater = [[Louisiana State University]]<br> [[Oklahoma State University]]\n| doctoral_advisor =\n| doctoral_students = [[J. N. Reddy]]\n| known_for  = [[Finite Element Method]]\n| prizes = [[Eringen Medal]] {{small|(1989)}}<br> [[Theodore von Karman Medal|Theodore von Kármán Medal]] {{small|(1992)}}<br>  [[Timoshenko Medal]] {{small|(1996)}}<br>  [[Honda Prize]] {{small|(2013)}}\n\n| religion =\n| footnotes =\n}}\n\n'''J. Tinsley Oden''' (born December 25, 1936 in [[Alexandria, Louisiana]]) is the Associate Vice President for Research, the Cockrell Family Regents' Chair in Engineering #2, the [[Peter O'Donnell (Texas)|Peter O'Donnell, Jr.]] Centennial Chair in Computing Systems, a Professor of Aerospace Engineering and Engineering Mechanics, a Professor of Mathematics, and a Professor of Computer Science at [[University of Texas at Austin|The University of Texas at Austin]]. Oden has been listed as an ISI Highly Cited Author in Engineering by the [[ISI Web of Knowledge]], Thomson Scientific Company.<ref>[http://hcr3.isiknowledge.com/author.cgi?&link1=Browse&link2=Results&id=530 ISI Highly Cited Author – J. Tinsley Oden]</ref>\n\nDr. Oden is the founding Director of the [[Institute for Computational Engineering and Sciences]] (ICES), which was started in January 2003 as an expansion of the Texas Institute for Computational and Applied Mathematics (TICAM), also directed by Oden for over a decade.<ref name=\"UTexas\">{{Cite web |url=https://www.ices.utexas.edu/people/85/ |title=J. Tinsley Oden |publisher=utexas.edu |accessdate=December 11, 2016}}</ref>\n\nHe earned a B.S. degree in civil engineering from LSU in 1959. Dr. Oden earned a PhD in engineering mechanics from [[Oklahoma State University–Stillwater|Oklahoma State University]] in 1962. He taught at OSU and [[University of Alabama in Huntsville|The University of Alabama in Huntsville]], where he was the head of the Department of Engineering Mechanics prior to going to Texas in 1973. He has held visiting professor positions at other universities in the United States, England, and Brazil.<ref name=\"UTexas\"/>\n\nAn author of over 500 scientific publications: books, book chapters, conference papers, and monographs, he is an editor of the series, Finite Elements in Flow Problems and of Computational Methods in Nonlinear Mechanics. He has published extensively in this field and in related areas over the last three decades.<ref name=\"UTexas\"/><ref>{{Cite web |url=http://catalog.utexas.edu/undergraduate/natural-sciences/faculty/ |title=Faculty |publisher=utexas.edu |accessdate=December 11, 2016}}</ref>\n\n==Honors and awards==\n\nDr. Oden is an Honorary Member of the [[American Society of Mechanical Engineers]] and is a Fellow of six international scientific/technical societies: IACM, AAM, ASME, ASCE, SES, and BMIA. He is a Fellow, founding member, and first President of the U.S. Association for Computational Mechanics and the International Association for Computational Mechanics. He is a Fellow and past President of both the American Academy of Mechanics and the Society of Engineering Science. Oden was awarded the [[A. Cemal Eringen]] [[Eringen Medal|Medal]] in 1989, the [[Worcester Reed Warner Medal]], the Lohmann Medal, the [[Theodore von Karman Medal]], the John von Neumann medal, the Newton/Gauss Congress Medal, and the [[Timoshenko Medal|Stephan P. Timoshenko Medal]]. He was also knighted as “Chevalier des Palmes Academiques” by the French government and he holds four honorary doctorates, honoris causa, from universities in Portugal (Technical University of Lisbon), Belgium (Faculte Polytechnique), Poland (Cracow University of Technology), and the United States (Presidential Citation, The University of Texas at Austin). Oden is also a member of the [[National Academy of Engineering|U.S. National Academy of Engineering]].<ref name=\"UTexas\"/>\n\n==Books==\n*''Finite Elements of Nonlinear Continua'', Dover Publications, 2006.\n*''An Introduction to the Mathematical Theory of Finite Elements'', with [[J. N. Reddy]], John Wiley & Sons Inc., 1976.\n*''Applied Functional Analysis'', Prentice Hall, 1979.\n*''Mechanics of Elastic Structures'', 2nd ed., with E. A. Ripperger, McGraw-Hill Inc., 1981.\n*''Finite Elements an Introduction'', volume 1, with E. B. Becker and G. F. Carey, 1981.\n*''Finite Elements in Fluids'', volume 2, with [[Olgierd Zienkiewicz|O. C. Zienkiewicz]], R. H. Gallagher, and C. Taylor, John Wiley & Sons, New York, 1976.\n*''Finite Elements in Fluids'', volume 4 with R. H. Gallagher, D. N. Norrie, and O. C. Zienkiewicz, Wiley, Chichester, 1982.\n*''Finite Elements in Fluids'', volume 6, with R. H. Gallagher, G. F. Carey, and O.C. Zienkiewicz, Wiley, Chichester, 1985.\n*''State of the Art Survey in Computational Fluid Mechanics'', with A. K. Noor, ASME, 1988.\n*''Computational Methods in Nonlinear Mechanics'', North-Holland, Amsterdam, 1980.\n\n{{Portalbar|Biography|Louisiana|Alabama|Oklahoma|Texas|Engineering|Mathematics|Education}}\n\n==References==\n{{reflist|30em}}\n\n==External links==\n{{MathGenealogy|id=45789}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Oden, J. Tinsley}}\n[[Category:1936 births]]\n[[Category:Living people]]\n[[Category:People from Alexandria, Louisiana]]\n[[Category:21st-century American engineers]]\n[[Category:Members of the United States National Academy of Engineering]]\n[[Category:University of Texas at Austin faculty]]\n[[Category:Oklahoma State University faculty]]\n[[Category:People associated with the finite element method]]\n[[Category:ISI highly cited researchers]]\n[[Category:University of Alabama in Huntsville faculty]]\n[[Category:Oklahoma State University alumni]]\n[[Category:Louisiana State University alumni]]\n[[Category:Fellows of the Society for Industrial and Applied Mathematics]]\n[[Category:Fellows of the American Society of Mechanical Engineers]]"
    },
    {
      "title": "Eugenio Oñate Ibañez de Navarra",
      "url": "https://en.wikipedia.org/wiki/Eugenio_O%C3%B1ate_Iba%C3%B1ez_de_Navarra",
      "text": "{{no footnotes|date=November 2010}}\n\n{{Infobox scientist\n| name = Eugenio Oñate\n| image =\n| caption =\n| birth_date = {{b-da|28 March 1953}}\n| birth_place = [[Valencia, Spain]]\n| death_date =\n| death_place =\n| residence =\n| nationality = [[Image:Flag of Spain.svg|20px]] [[Spain|Spanish]]\n| field = [[Structural mechanics]]<br/>[[Computational mechanics]]<br/>[[Finite element method]]\n| work_institution = School of Civil Engineering, [[Technical University of Catalonia]]<br/>International Center for Numerical Methods in Engineering \n| alma_mater = [[Polytechnic University of Valencia]]<br/>[[University College of Swansea]]\n| doctoral_advisor = [[Olgierd Zienkiewicz]]\n| doctoral_students =\n| known_for = [[Finite element method]]<br/>[[Particle finite element method]]\n| prizes =\n| religion =\n| footnotes =\n}}\n\n'''Eugenio Oñate Ibañez de Navarra''' ([[Valencia, Spain|Valencia]], 28 March 1953), often referred as '''Eugenio Onãte''', is a [[Spain|Spanish]] [[engineer]] who works in [[computational mechanics]].\n\n==Books==\n* Oñate E., Kröplin B., Textile Composites and Inflatable Structures (Computational Methods in Applied Sciences), Springer 2005.\n* Oñate E., Owen R., Computational Methods in Applied Sciences, Volume 7: Computational Plasticity, Springer 2007.\n* Oñate E., Structural Analysis with the Finite Element Method. Linear Statics, Volume 1: Basis and Solids (Lecture Notes on Numerical Methods in Engineering and Sciences), Springer 2009.\n* Oñate E., Structural Analysis with the Finite Element Method. Linear Statics, Volume 2: Beams, Plates and Shells (Lecture Notes on Numerical Methods in Engineering and Sciences), Springer 2010.\n\n==External links==\n* {{Official website|http://www.cimne.upc.es/eo/}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Onate Ibanez De Navarra, Eugenio}}\n[[Category:1953 births]]\n[[Category:Polytechnic University of Catalonia]]\n[[Category:Polytechnic University of Valencia alumni]]\n[[Category:Alumni of Swansea University]]\n[[Category:People associated with the finite element method]]\n[[Category:ISI highly cited researchers]]\n[[Category:Living people]]\n\n\n{{europe-mathematician-stub}}\n{{Spain-scientist-stub}}"
    },
    {
      "title": "J. N. Reddy",
      "url": "https://en.wikipedia.org/wiki/J._N._Reddy",
      "text": "{{multiple issues|\n{{BLP sources|date=October 2017}}\n{{peacock|date=October 2017}}\n{{third-party|date=October 2017}}\n}}\n{{Use dmy dates|date=October 2011}}\n{{Infobox scientist\n| name = J. N. Reddy\n| image = JN Reddy.png\n| caption = \n| birth_date = {{b-da|12 August 1945}}\n| birth_place = [[Warangal]], [[Telangana]] (then [[Andhra Pradesh]]), India\n| death_date = \n| death_place = \n| residence = \n| nationality = [[File:Flag of India.svg|20px]] [[India]]n<br> [[File:Flag of the United States.svg|20px]] American\n| alma_mater = [[Osmania University]], [[Oklahoma State University]], [[University of Alabama in Huntsville]]\n| doctoral_advisor = [[Tinsley Oden]]\n| doctoral_students = \n| known_for = [[Finite Element Method]], [[Plate and Shell Theories]], Composites, [[Applied Mathematics]]\n| footnotes = He is a Distinguished Professor, Regents' Professor &\ninaugural holder of the Oscar S. Wyatt Endowed Chair in Mechanical Engineering at [[Texas A&M University]], [[College Station, Texas]], USA\n| field = [[Theoretical and Computational mechanics]]\n| work_institution = [[University of Oklahoma]], [[Virginia Polytechnic Institute and State University]], [[Texas A&M University]]\n| prizes = [[ASME Medal]]{{small|(2016)}}\n| religion = \n}}\n\n'''Junuthula N. Reddy''' (born 12 August 1945) is a Distinguished Professor, Regents' Professor and inaugural holder of the [[Oscar Wyatt|Oscar S. Wyatt]] Endowed Chair in Mechanical Engineering at [[Texas A&M University]], [[College Station, Texas]], USA.<ref>[https://www.tamu.edu/faculty/jnreddy/acml/About.html] at Texas A&M University</ref> He is one of the researchers responsible for the development of the [[Finite Element Method]] (FEM). He is an authoritative figure in the broad area of mechanics. He has made significant seminal contributions in the specific areas of [[finite element method]], plate theory, [[solid mechanics]], [[Calculus of variations|variational methods]], mechanics of [[Composite material|composites]], functionally graded materials, fracture mechanics, plasticity, biomechanics, classical and non-Newtonian fluid mechanics, and applied [[functional analysis]]. Reddy has over 620 journal papers, 20 books (with several second and third editions), and has given numerous (over 150) national and international talks. He has served as a member of International Advisory Committee at [[ICTACEM]], 2001 and keynote addressing in 2014.<ref name= InternationalA_committee>{{cite web|url=http://www.jeo.org/ictacem/acommittee.html|title=J.N. Reddy - International Advisory Committee|publisher=''International Conference on Theoretical, Applied, Computational and Experimental Mechanics'', [[ICTACEM]], 2001 |accessdate=25 December 2014 |archivedate=2 September 2000 |deadurl=no |archiveurl=https://web.archive.org/web/20000902155159/http://www.jeo.org/ictacem/acommittee.html}}</ref><ref name= keynote_addressing>{{cite web|url=http://www.ictacem2014.in/index.php/conf14/index/pages/view/pspeaker|title=Keynote Addressing|publisher=''International Conference on Theoretical, Applied, Computational and Experimental Mechanics'', [[ICTACEM]], 2014 |accessdate=3 November 2016 |archivedate=8 August 2014 |deadurl=yes |archiveurl=https://web.archive.org/web/20140808072915/http://www.ictacem2014.in/index.php/conf14/index/pages/view/pspeaker}}</ref>\n\nHe has advised around 36 postdoctoral fellows, 65 Ph.D. students, and 46 M.S students over 40 years. Many of his (former) PhD and postdoctoral students are currently faculty members in major universities throughout the world. He has been listed as an ISI Highly Cited Author in Engineering by the [[ISI Web of Knowledge]], Thomson Scientific Company.<ref>[http://hcr3.isiknowledge.com/author.cgi?&link1=Browse&link2=Results&id=6 ISI Highly Cited Author – J. N. Reddy]</ref> Reddy is one of the original top 100 ISI Highly Cited Researchers in Engineering around world, with h-index of over 66 as per Web of Science; the number of citations is over 54,000 with h-index of 94 and i10-index of 438 (i.e., 438 papers are cited at least 10 times) as per Google Scholar.\n\nHe is also renowned as an educator. He has won many teaching awards, and his books are widely used as textbooks in many courses at various universities across the world. His books are known for explaining very difficult theories in lucid manner.\n\n==Education==\n* Post Doctoral Fellow, Texas Institute for Computational Mechanics, University of Texas at Austin, 1973-1974.\n* PhD. - Engineering Mechanics (Advisor: Dr. [[J. Tinsley Oden]]), [[University of Alabama in Huntsville]], Alabama, 1973.\n* M.S. - Mechanical Engineering, [[Oklahoma State University]], Stillwater, Oklahoma, 1970.\n* B.E. - Mechanical Engineering, [[Osmania University]], Hyderabad, Andhra Pradesh, India, 1968.\n\n==International Awards==\n*[[ASME Medal]], American Society of Mechanical Engineers, 2016 <ref>{{cite web|url=https://www.asme.org/about-asme/news/asme-news/jn-reddy-james-duderstadt-receive-prestigious|title=J.N. Reddy and James Duderstadt to Receive Prestigious ASME Honors|publisher= ASME|accessdate= 10 March 2017}}</ref>\n*Prager Medal, Society of Engineering Science (medal to be presented at 53rd Annual Technical Meeting at University of Maryland, 4–6 October 2016).\n*Simpson Distinguished Visiting Professor, Department of Mechanical Engineering, Northwestern University, April–May, 2016.\n*Inductee, The Hall of Fame of the College of Engineering, Architecture and Technology, Oklahoma State University, Stillwater, 17 October 2015.\n*Foreign Fellow, the Indian National Academy of Engineering, September 2015.\n*Special Sessions organized in honor of Professor JN Reddy at the Eighth International Conference on Advances in Steel Structures (ICASS) and IJSSD Symposium on Progress in Structural Stability and Dynamics, held in Lisbon, Portugal, 22–24 July 2015, Technical University of Lisbon, Portugal (a special issue of the International Journal of Structural Stability and Dynamics in honor of JN Reddy is published).\n*Special Sessions organized in honor of Professor JN Reddy at the 18th International Conference on Composite Structures, held in Lisbon, Portugal, 15–18 June 2015, Lisbon, Portugal (a special issue of the Composite Structures journal in honor of JN Reddy is planned).\n*The IACM O.C. Zienkiewicz Award from the International Association for Computational Mechanics, 2014.\n*Raymond D. Mindlin Medal from the American Society of Civil Engineers, 2014.\n*Finland Distinguished Professor (FiDiPro), Aalto University and National Technology Agency of Finland (Tekes), 2014–2018.\n*Visiting Professor of the Science without Borders Program of Brazil (University of São Paulo), 2014–2016.\n*Chair of Excellence, Universidad Carlos III de Madrid, Spain, 2014–2015.Elected to prestigious NAE (Class of 2015) for contributions to composite structures and to engineering education and practice.\n*Distinguished Visiting Fellowship, The Royal Academy of Engineering, London, UK, 2013.\n*Satish Dhawan Visiting Professor, Department of Aerospace Engineering, Indian Institute of Science, Bangalore, 2012–2013.\n*Computational Mechanics Award, the Japanese Society of Mechanical Engineers (JSME), October 2012.\n*Top 100 Scientists, International Biographical Centre, Cambridge, England, 2012.\n*Honorary Doctorate Degree, Odlar Yurdu University, Baku, Azerbaijan, 2011.\n*Life Fellow, American Society of Mechanical Engineers (ASME), June 2011.\n*Regents' Professor, Texas A&M University, College Station, Texas, 2010.\n*Honorary degree (Honoris Causa) from the Technical University of Lisbon, Portugal, 2009.\n*Fellow of American Institute of Aeronautical and Astronautics, 2005.\n*Distinguished Research Award of the American Society for Composites, 2004.\n*Computational Solids Mechanics award for the US Association for Computational Mechanics, 2003.\n*Outstanding Man of the 21st century, 2000.\n*The Nathan M. Newmark medal from the American Society of Civil Engineering, 1998.\n*Fellow of the International Association of Computational Mechanics, 1998.\n*Charles Russ Richards Memorial Award, the American Society of Mechanical Engineers, 1995.\n*Men of Achievement, 1994.\n\n==Books==\n*J. T. Oden and J. N. Reddy, ''A Mathematical Theory of Finite Elements'', Wiley-Interscience (1976)\n*J. T. Oden and J. N. Reddy, ''Variational Methods in Theoretical Mechanics'', 2nd ed., Springer-Verlag (1982)\n*J. N. Reddy and M. L. Rasmussen, ''Advanced Engineering Analysis'', John Wiley (1982) reprinted by Krieger, Melbourne, FL, 1990\n*J. N. Reddy, ''Applied Functional Analysis and Variational Methods in Engineering'', McGraw-Hill (1986); reprinted by Krieger, Melbourne (1991)\n*O. O. Ochoa and J. N. Reddy, ''Finite Element Analysis of Composite Laminates'', 2nd ed., Kluwer Academic Publishers, The Netherlands (1992) {{ISBN|0-7923-1125-6}}\n*J. N. Reddy and A. Miravete, ''Practical Analysis of Laminated Composite Structures'', 3rd ed., CRC Press, FL, 1995. {{ISBN|0-8493-9401-5}}\n*C. M. Wang, J. N. Reddy and K.H. Lee, ''Shear Deformation Theories of Beams and Plates Dynamics Relationships with Classical Solution'', Elsevier, U.K., 2000. {{ISBN|0-08-043784-2}}\n*J. N. Reddy, ''Energy Principles and Variational Methods in Applied Mechanics'', 2nd ed., John Wiley (2002) {{ISBN|0-471-17985-X}}, 3rd edition to appear in 2017.\n*J. N. Reddy, ''An Introduction to Nonlinear Finite Element Analysis'', Oxford University Press, USA (2004). {{ISBN|0-19-852529-X}}\n*J. N. Reddy, ''Mechanics of Laminated Composite Plates and Shells: Theory and Analysis'', 2nd ed., CRC Press (2004). {{ISBN|0-8493-1592-1}}\n*J. N. Reddy, ''An Introduction to the Finite Element Method'', 3rd ed., McGraw-Hill Education (2005). {{ISBN|0-07-124473-5}}\n*J. N. Reddy and D. K. Gartling, ''The Finite Element Method in Heat Transfer and Fluid Dynamics'', 3rd ed., CRC Press, FL, 2010. {{ISBN|1-4200-8598-0}}\n*J. N. Reddy, ''Theory and Analysis of Elastic Plates and Shells'', 2nd ed., Taylor & Francis (2007) {{ISBN|0-8493-8415-X}}\n*C. M. Wang, C. Y. Wang, and J. N. Reddy, ''Exact Solutions for Buckling of Structural Members'', CRC Press (2005) {{ISBN|0-8493-2222-7}}\n*J. N. Reddy, ''Principles of Continuum Mechanics. A Study of Conservation Principles with Applications'', Cambridge University Press (2010) {{ISBN|0-521-51369-3}}\n*R. T. Fenner and J. N. Reddy, ''Mechanics of Solids and Structures'', 2nd ed., CRC Press (2012) {{ISBN|0-632-02018-0}}\n*J. N. Reddy, ''An Introduction to Continuum Mechanics with Applications'', 2nd ed., Cambridge University Press (2013) {{ISBN|978-0-521-87044-3}}\n*J. N. Reddy, ''An Introduction to Nonlinear Finite Element Analysis'', 2nd ed., Oxford University Press (2015) {{ISBN|0-19-852529-X}}\n*Ashwin Rao, A.R. Srinivasa and J. N. Reddy, ''Design of Shape Memory Alloy (SMA) Actuators'', Springer (2015) {{ISBN|978-3-319-03187-3}} (Print) and {{ISBN|978-3-319-03188-0}} (Online)\n*K.S. Surana and J.N. Reddy, ''The Finite Element Method for Boundary Value Problems, Mathematics and Computations,'' CRC Press, to appear (2017)\n\n==References==\n{{reflist|30em}}\n\n{{Authority control}}\n{{ASME Medal|state=collapsed}}\n\n{{DEFAULTSORT:Reddy, J. N.}}\n[[Category:1945 births]]\n[[Category:Living people]]\n[[Category:Texas A&M University faculty]]\n[[Category:Oklahoma State University alumni]]\n[[Category:Osmania University alumni]]\n[[Category:University of Alabama alumni]]\n[[Category:Indian emigrants to the United States]]\n[[Category:People associated with the finite element method]]\n[[Category:ISI highly cited researchers]]\n[[Category:Fellows of the American Institute of Aeronautics and Astronautics]]\n[[Category:American male scientists of Indian descent]]\n[[Category:People from Warangal district]]\n[[Category:American academics of Indian descent]]\n[[Category:ASME Medal recipients]]"
    },
    {
      "title": "Peter P. Silvester",
      "url": "https://en.wikipedia.org/wiki/Peter_P._Silvester",
      "text": "{{Infobox scientist\n| name = Peter Peet Silvester\n| image = \n| caption = \n| birth_date = January 25, 1935\n| birth_place = Tallinn, Estonia\n| death_date = {{d-da|October 11, 1996|January 25, 1935}}\n| death_place = Victoria, British Columbia, Canada\n| residence = \n| nationality = \n| field = [[Computational electromagnetics]]<br/> [[Finite element method]]\n| work_institution = [[McGill University]] (Montreal)\n| alma_mater = \n| doctoral_advisor =\n| doctoral_students = \n| known_for = [[Computational electromagnetics]]<br/> [[Finite element method]]\n| prizes = \n| religion = \n| footnotes =\n}}\n\n'''Peter Peet Silvester''' (January 25, 1935 – October 11, 1996) was an [[electrical engineer]] who contributed to understanding of numerical analysis of [[electromagnetic fields]] and authored a standard textbook on the subject.\n\nSilvester was born in [[Tallinn]], [[Estonia]]. He graduated from the Camegie Institute of Technology (now [[Carnegie-Mellon University]]) in Pittsburgh, Pennsylvania, in 1956. After a period of industrial practice, he continued his studies at the [[University of Toronto]], obtaining the MASc in 1958, and then at [[McGill University]] ([[Montreal]]), where he was awarded the PhD in [[Electrical Engineering]], in 1964. He initially joined the Department of Electrical Engineering at McGill as Lecturer, then as Assistant Professor, Associate Professor, and Full Professor. In 1996, he was honored with the titles of [[emeritus professor]]<ref name=McGill>{{cite web|title=Emeritus professors|author=[[McGill University]]|url=http://reporter-archive.mcgill.ca/Rep/r2917/emeriti.html|accessdate=2010-03-03}}</ref> at McGill University, and Honorary Professor at the [[University of British Columbia]].\n\nSilvester devoted a large part of his career to the numerical analysis of electromagnetic field], with applications to [[magnetics]], [[microwaves]], [[geomagnetics]], [[antennas]], and [[bioelectricity]]. His main research focused on the [[finite element method]], as applied to electromagnetics, where he was a pioneer.<ref name=R.Ferrari>{{cite journal|title=The Finite-Element Method, Part 2: P. P. Silvester, an Innovator in Electromagnetic Numerical Modeling|author=[[Ronald L. Ferrari]]|year=2007|doi=10.1109/MAP.2007.4293978}}</ref> His paper, ''Finite-Element Solution of Homogeneous-Waveguide Problems'', presented at the 1968 [[URSI]] Symposium on Electromagnetic Waves, and later on, published in the Italian technical journal, ''Alta Frequenza'', was definitely the first FEM application to electronic engineering.\n\nIn this field, his contributions were valuable, both from the theoretical and the applications side. He studied topics which ranged from potential and scalar-wave problems, in the first years, to applications to microwave devices, antennas, electric machines, as well as new kinds of elements and formulations, open-boundary problems, and parallel computing. His book, Finite Elements for Electrical Engineering, written with Ron Ferrari, has been the only textbook on this specific topic for many years, and it has been translated into many languages, among which are [[Russian language|Russian]], [[Chinese language|Chinese]], [[Japanese language|Japanese]], and [[Spanish language|Spanish]].\n\nHe founded the Computational Analysis and Design Laboratory (CAD-Lab) at the Electrical Engineering Department of McGill University, in 1978, which has now become probably the largest research organization of its kind in Canada, and one of the largest in the world. Peter Silvester also was a founder of [http://www.infolytica.com/ Infolytica Corporation] (Montreal), a consulting and [[Computer-aided engineering|engineering simulation software]] (computer-aided engineering, or CAE) company.\n\nSilvester maintained strong research ties with colleagues of several other institutions, notably the [[University of Cambridge]] and the [[University of Florence]], creatively sharing his knowledge. He also acted as a consultant to a number of major corporations and government agencies.\n\nHe was a member of major professional organizations in his field, a member of steering committees and boards of various scientific and professional conferences, and was elected a Fellow of the [[IEEE]] for \"...contributions to the art of finite-element analysis.\" He was also a Fellow of the [[Institution of Electrical Engineers|IEE]], and of the [[Royal Society of Canada]]. His archives are held at the [[McGill University Archives]].<ref>{{Cite web|url=https://archivalcollections.library.mcgill.ca/index.php/peter-p-silvester-fonds|title=Peter P. Silvester fonds|last=|first=|date=|website=McGill Archival Collections Catalogue|archive-url=|archive-date=|dead-url=|access-date=2018-11-12}}</ref>\n\n==Books==\n* Peter P. Silvester, M. V. K. Chari, ''Finite Elements in Electrical and Magnetic Field Problems'', John Wiley & Sons Inc, 1980. {{ISBN|0-471-27578-6}}\n* Peter P. Silvester, [[Ronald L. Ferrari]], ''Finite Elements for Electrical Engineers, 1ed'', Cambridge University Press, 1983.\n* Peter P. Silvester, [[D. A. Lowther]] ''Computer-Aided Design in Magnetics'', Berlin, Springer-Verlag, 1986\n* Peter P. Silvester, Ronald L. Ferrari, ''Finite Elements for Electrical Engineers, 2ed'', Cambridge University Press, 1990.\n* Peter P. Silvester, [[Giuseppe Pelosi]], ''Finite Elements for Wave Electromagnetics'', IEEE Press, New York, 1994, {{ISBN|0-7803-1040-3}}\n* Peter P. Silvester, [[Tatsuo Itoh]], Giuseppe Pelosi, ''Finite Element Software for Microwave Engineering'', Wiley-Interscience, 1996, {{ISBN|0-471-12636-5}}\n* Peter P. Silvester, [[Institution of Electrical Engineers]] (Corporate Author), [[University of Florence]] (Corporate Author), ''Software for Electrical Engineering Analysis and Design III'', Computational Mechanics, 1996, {{ISBN|1-85312-395-1}}\n* Peter P. Silvester, Ronald L. Ferrari, ''Finite Elements for Electrical Engineers, 3ed'', Cambridge University Press, 1996.\n\n==References==\n{{Reflist}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Silvester, Peter P.}}\n[[Category:Carnegie Mellon University alumni]]\n[[Category:McGill University faculty]]\n[[Category:People associated with the finite element method]]\n[[Category:1935 births]]\n[[Category:1996 deaths]]"
    },
    {
      "title": "Gilbert Strang",
      "url": "https://en.wikipedia.org/wiki/Gilbert_Strang",
      "text": "{{BLP sources|date=February 2013}}\n{{Infobox scientist\n| name              = W. Gilbert Strang\n| image             = \n| image_size        = 200px\n| alt               = \n| caption           = \n| birth_date        = {{Birth date and age|1934|11|27}}\n| birth_place       = [[Chicago, Illinois]]\n| death_date        = <!-- {{Death date and age|YYYY|MM|DD|YYYY|MM|DD}} (death date then birth date) -->\n| death_place       = \n| resting_place     = \n| resting_place_coordinates = <!-- {{Coord|LAT|LONG|type:landmark|display=inline,title}} -->\n| residence         =\n| citizenship       = \n| nationality       = [[United States]]\n| fields            = [[Mathematics]]\n| workplaces        = [[Massachusetts Institute of Technology]]\n| alma_mater        = [[Massachusetts Institute of Technology|MIT]] <small>([[Bachelor of Science|S.B.]])</small><br>[[Balliol College, Oxford|Balliol College]], [[University of Oxford|Oxford]] <small>([[Master of Arts|M.A.]])</small><br>[[University of California, Los Angeles|UCLA]] <small>([[Doctor of Philosophy|Ph.D.]])</small>\n| thesis_title      = Difference Methods for Mixed Boundary Value Problems\n| thesis_url        = \n| thesis_year       = 1959\n| doctoral_advisor  = [[Peter K. Henrici]]\n| academic_advisors = \n| doctoral_students = [[Hermann Flaschka]]\n| notable_students  = \n| known_for         = \n| author_abbrev_bot = \n| author_abbrev_zoo = \n| influences        = \n| influenced        = \n| awards            = [[Chauvenet Prize]] (1977)\n| signature         = <!--(filename only)-->\n| signature_alt     = \n| website           = <!-- {{URL|www.example.com}} -->\n| footnotes         = \n| spouse            = \n}}\n\n'''William Gilbert Strang''' (born November 27, 1934<ref name=\"Roselle\" />), usually known as simply '''Gilbert Strang''' or '''Gil Strang''', is an [[Americans|American]] [[mathematician]], with contributions to [[Finite elements|finite element theory]], the [[calculus of variations]], [[wavelet analysis]] and [[linear algebra]]. He has made many contributions to [[mathematics]] education, including publishing seven mathematics textbooks and one [[monograph]]. Strang is the [[MathWorks]] Professor of Mathematics at the [[Massachusetts Institute of Technology]].<ref name=\"MathWorks\" />  He teaches Introduction to [[Linear Algebra]] and Computational Science and Engineering and his lectures are freely available through [[MIT OpenCourseWare]].\n\n==Education==\n* [[Bachelor of Science|S.B.]], 1955, [[MIT]]\n* B. A., M. A., 1957, [[Rhodes Scholar]], [[Balliol College, Oxford|Balliol College]], [[University of Oxford|Oxford]]\n* Ph. D., [[National Science Foundation]] Fellow, 1959, [[University of California, Los Angeles]]. Dissertation: \"Difference Methods for [[Boundary value problem|Mixed Boundary Value Problems]]\"\n\n==University positions==\n* Professor of Mathematics, MIT (1962–)\n* Honorary Fellow, [[Balliol College]], [[University of Oxford|Oxford]]\n\n==Awards and honors==\n* [[Rhodes Scholar]] (1955)\n* [[Sloan Fellows|Alfred P. Sloan Fellow]] (1966–1967)\n* [[Chauvenet Prize]], [[Mathematical Association of America]] (1976)\n* Honorary Professor, [[Xian Jiaotong University]], China (1980)\n* American Academy of Arts and Sciences (1985)\n* Honorary Fellow, Balliol College, Oxford University (1999)\n* Honorary Member, Irish Mathematical Society (2002)\n* Award for Distinguished Service to the Profession, [[Society for Industrial and Applied Mathematics]] (2003)\n* [[Lester R. Ford Award]] (2005)<ref>{{cite journal|author=Edelman, Alan|author2=Strang, Gilbert|title=Pascal matrices|journal=Amer. Math. Monthly|year=2004|pages=189–197|doi=10.2307/4145127|url=http://www.maa.org/programs/maa-awards/writing-awards/pascal-matrices}}</ref>\n* Von Neumann Medal, US Association for Computational Mechanics (2005)\n* Haimo Prize, Mathematical Association of America (2007)<ref>{{cite web | title = Deborah and Franklin Tepper Haimo Award | url = http://www.maa.org/programs/maa-awards/teaching-awards/haimo-award-distinguished-teaching}}</ref>\n* Su Buchin Prize, International Congress (ICIAM, 2007)\n* Henrici Prize (2007)\n* [[United States National Academy of Sciences|National Academy of Sciences]] (2009)\n* Fellow of the [[Society for Industrial and Applied Mathematics]] (2009) <ref>{{cite web | title = SIAM Fellows | url = http://fellows.siam.org/index.php?sort=last }}</ref>\n* Doctor Honoris Causa, University of Toulouse (2010)\n* Fellow of the [[American Mathematical Society]] (2012)<ref>[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-08-05.</ref>\n* Doctor Honoris Causa, Aalborg University (2013)\n\n==Service==\n* President, [[Society for Industrial and Applied Mathematics]] (1999, 2000)<ref>{{cite web | title = SIAM Presidents | url = http://www.siam.org/about/more/presidents.php }}</ref>\n* Chair, U.S. National Committee on Mathematics (2003–2004)\n* Chair, [[National Science Foundation]] (NSF) Advisory Panel on Mathematics\n* Board Member, [[International Council for Industrial and Applied Mathematics]] (ICIAM)\n*[[Abel Prize]] Committee (2003–2005)\n\n==Publications==\n\n===Books and monographs===\n#''Linear Algebra and Learning from Data'' (2019)<ref>http://math.mit.edu/~gs/learningfromdata/</ref>\n#''Calculus'' (2017)\n#''Introduction to Linear Algebra'' (2016)\n#''Differential Equations and Linear Algebra'' (2014) http://math.mit.edu/dela/\n#''Essays in Linear Algebra'' (2012)\n#''Algorithms for Global Positioning'', with Kai Borre (2012)\n#''An Analysis of the Finite Element Method'', with [[George Fix]] (2008)\n#''Computational Science and Engineering'' (2007)\n#''Linear Algebra and Its Applications'' (2005)\n#''Linear Algebra, Geodesy, and GPS'', with Kai Borre (1997)\n#''Wavelets and Filter Banks'', with Truong Nguyen (1996)\n# {{cite book|<!-- last=Strang|first=Gilbert|authorlink=Gilbert Strang -->|title=Introduction to Applied Mathematics|publisher=Wellesley-Cambridge Press |location=Wellesley, MA|year=1986|pages=xii+758|mr=870634|ref=harv}}\n<!-- ===Journals (selected)=== -->\n\n==See also==\n\n* The [[Joint spectral radius]], introduced by Strang in the early 60s.\n* The Strang–Fix condition for accuracy of approximation.\n* [[Strang splitting]]\n\n== References ==\n{{reflist|refs=\n<ref name=\"Roselle\">{{cite journal\n| last        = Roselle |first = D. P. |authorlink = David Roselle\n| title       = Award of the 1977 Chauvenet Prize to Professor Gilbert Strang\n| journal     = The American Mathematical Monthly|year = 1977|volume = 84|issue = 6\n|accessdate=<!-- July 17, 2012 --> |page = 417\n| citeseerx = 10.1.1.119.4043 |jstor=2321898}}</ref>\n<ref name=\"MathWorks\">{{cite web \n| title      = MIT announces Professor Gilbert Strang as the first MathWorks Professor of Mathematics \n| url        = http://web.mit.edu/newsoffice/2011/mathworks-chair-strang.html \n| publisher  = MIT News \n| location   = Cambridge, MA \n| accessdate = September 26, 2011 \n}}</ref>\n}}\n\n==External links==\n* Gilbert Strang's [http://www-math.mit.edu/~gs/ Home Page at MIT]\n* International Council for Industrial and Applied Mathematics: [http://www.iciam.org ICIAM]\n* Society for Industrial and Applied Mathematics: [http://www.siam.org SIAM]\n* [https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/ Linear Algebra video lectures by Gilbert Strang, recorded in Fall of 1999]\n* [https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/video-lectures/ Matrix Methods in Data Analysis by Gilbert Strang on OCW, recorded in Spring of 2018] and [https://video.odl.mit.edu/collections/affe50ec8e5f46e1b57cfe1449348684/ the unedited Spring 2019 version]\n* [https://ocw.mit.edu/resources/res-18-005-highlights-of-calculus-spring-2010/ Highlights of Calculus video lectures by Gilbert Strang on OCW]\n* [https://www.youtube.com/view_play_list?p=BE9407EA64E2C318 Highlights of Calculus video lectures by Gilbert Strang on YouTube]\n* [https://dspace.mit.edu/bitstream/handle/1721.1/45136/18-085Fall-2005/OcwWeb/Mathematics/18-085Fall-2005/VideoLectures/index.htm Mathematical Methods for Engineers I video lectures by Gilbert Strang]\n* [https://ocw.mit.edu/courses/mathematics/18-086-mathematical-methods-for-engineers-ii-spring-2006/video-lectures/ Mathematical Methods for Engineers II video lectures by Gilbert Strang]\n* {{MathGenealogy |id=13383}}\n\n{{Chauvenet Prize recipients}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Strang, Gilbert}}\n[[Category:1934 births]]\n[[Category:Living people]]\n[[Category:20th-century American mathematicians]]\n[[Category:21st-century mathematicians]]\n[[Category:Massachusetts Institute of Technology faculty]]\n[[Category:Mathematics educators]]\n[[Category:People associated with the finite element method]]\n[[Category:ISI highly cited researchers]]\n[[Category:Fellows of the Society for Industrial and Applied Mathematics]]\n[[Category:American Rhodes Scholars]]\n[[Category:Massachusetts Institute of Technology alumni]]\n[[Category:University of California, Los Angeles alumni]]\n[[Category:People from Chicago]]\n[[Category:Members of the United States National Academy of Sciences]]\n[[Category:Fellows of the American Mathematical Society]]\n[[Category:Presidents of the Society for Industrial and Applied Mathematics]]\n[[Category:Sloan Research Fellows]]\n[[Category:Mathematicians from Illinois]]"
    },
    {
      "title": "Edward L. Wilson",
      "url": "https://en.wikipedia.org/wiki/Edward_L._Wilson",
      "text": "{{Use mdy dates|date=May 2015}}\n'''Edward L. Wilson''' (born September 5, 1931 in [[Ferndale, California]]) is an [[United States|American]] [[civil engineer]] and academic who is known for his contributions to the development of [[finite element method]]. He was the T.Y. and Margaret Lin Professor in Engineering at the [[University of California, Berkeley]]. He is currently the Professor Emeritus at the civil and environmental engineering, [[University of California, Berkeley|UC Berkeley]].<ref>[http://www.ce.berkeley.edu/faculty/faculty.php?name=Wilson Edward L. Wilson] at the [[University of California, Berkeley]]</ref> Wilson is a member of the [[National Academy of Engineering]]<ref>{{cite web | url = http://www.ce.berkeley.edu/faculty/faculty_awards.php?name=Wilson | title = CEE Faculty - Selected Awards | publisher = [[UC Berkeley]] | accessdate = 2009-09-02}}</ref> and is a recipient of the [[John von Neumann Award]].<ref>{{cite web | url = http://www.usacm.org/hon_awards.htm | title = Award Recipients | publisher = United States Association for Computational Mechanics | accessdate = 2009-09-02}}</ref>\n\nWilson is considered to be one of the early pioneers in the field of finite element analysis and its applications.<ref>{{cite book | title = Giants of Engineering Science | url = https://books.google.com/books?id=S2OiZVmf1ccC&pg=PA68&dq=Klaus-Jurgen+Bathe | author = Anwar Bég, O. | edition =  | publisher = Troubador Publishing Ltd | year = 2003 | isbn = 9781899293520 | accessdate = 2010-11-20}}</ref> He is credited with having written the first widely accepted computer package for structural analysis (SAP)<ref>{{cite book | title = Application of the Finite Element Method in Implant Dentistry |editor1=Jianping Geng |editor2=Weiqi Yan |editor3=Wei Xu | publisher = Springer | year = 2008 | url = https://books.google.com/books?id=NzGdLDVsgQMC&pg=PA4&lpg=PA4&dq=%22E.+L.+Wilson%22+finite+element#v=onepage&q=%22E.%20L.%20Wilson%22%20finite%20element&f=false | accessdate = 2009-09-02 | isbn = 978-7-308-05510-9}}</ref> and has co-authored the widely cited book in [[finite element method|FEM]], \"Numerical Methods in Finite Element Analysis\", with [[Klaus-Jurgen Bathe]].<ref>{{cite web | url = http://www.slac.stanford.edu/spires/find/books?irn=67741 | title = SLAC Library Catalog | publisher = SLAC National Accelerator Laboratory | accessdate = 2009-09-02}}</ref>\n\n==Education==\nBorn in [[Ferndale, California|Ferndale]], [[California]], Wilson received his B.S., M.S., and D.Eng. degrees from the [[University of California, Berkeley]] in 1955, 1959, and 1963 respectively. He earned the master's and a doctoral degree under [[Ray W. Clough]].<ref name=\"me_design\">{{cite web | url = http://www.memagazine.org/supparch/medesign/mesh/mesh.html | title = Early Masters of the Mesh | last = Carrabine | first = Laura | publisher = ASME International | accessdate = 2009-09-03 | deadurl = yes | archiveurl = https://web.archive.org/web/20080918055346/http://www.memagazine.org/supparch/medesign/mesh/mesh.html | archivedate = September 18, 2008 | df = mdy-all }}</ref>\n\n==References==\n{{reflist}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Wilson, Edward L.}}\n[[Category:University of California, Berkeley alumni]]\n[[Category:University of California, Berkeley faculty]]\n[[Category:People associated with the finite element method]]\n[[Category:Living people]]\n[[Category:Members of the United States National Academy of Engineering]]\n[[Category:1931 births]]\n[[Category:People from Ferndale, California]]\n[[Category:Engineers from California]]\n\n\n{{US-engineer-stub}}\n{{US-academic-stub}}"
    },
    {
      "title": "Numerical methods for ordinary differential equations",
      "url": "https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations",
      "text": "{{more footnotes|date=April 2010}}\n[[File:Numerical integration illustration, step=1.svg|right|180px|thumb|Illustration of numerical integration for the differential equation <math>y'=y, y(0)=1.</math> Blue: the [[Euler method]], green: the [[midpoint method]], red: the exact solution, <math>y=e^t.</math> The step size is <math>h=1.0.</math>]]\n[[File:Numerical integration illustration step=0.25.svg|right|180px|thumb|The same illustration for <math>h=0.25.</math> It is seen that the midpoint method converges faster than the Euler method.]]\n\n'''Numerical methods for ordinary differential equations''' are methods used to find [[Numerical analysis|numerical]] approximations to the solutions of [[ordinary differential equation]]s (ODEs). Their use is also known as \"[[numerical integration]]\", although this term is sometimes taken to mean the computation of [[integral]]s.\n\nMany differential equations cannot be solved using [[symbolic computation]] (\"analysis\"). For practical purposes, however&nbsp;– such as in engineering&nbsp;– a numeric approximation to the solution is often sufficient. The [[algorithm]]s studied here can be used to compute such an approximation. An alternative method is to use techniques from [[calculus]] to obtain a [[series expansion]] of the solution.\n\nOrdinary differential equations occur in many scientific disciplines, for instance in [[physics]], [[chemistry]], [[biology]], and [[economics]]. In addition, some methods in [[numerical partial differential equations]] convert the [[partial differential equation]] into an ordinary differential equation, which must then be solved.\n\n== The problem ==\n\nA first-order differential equation is an [[Initial value problem]] (IVP) of the form,<ref>{{harvtxt|Bradie|2006|pp=533–655}}</ref>\n:<math>y'(t) = f(t,y(t)), \\qquad y(t_0)=y_0, \\qquad\\qquad (1)</math>\nwhere ''f'' is a function that maps [''t''<sub>0</sub>,∞)&nbsp;×&nbsp;'''R'''<sup>d</sup> to '''R'''<sup>d</sup>, and the initial condition ''y''<sub>0</sub>&nbsp;∈&nbsp;'''R'''<sup>d</sup> is a given vector.  ''First-order'' means that only the first derivative of ''y'' appears in the equation, and higher derivatives are absent.\n\nWithout loss of generality to higher-order systems, we restrict ourselves to ''first-order'' differential equations, because a higher-order ODE can be converted into a larger system of first-order equations by introducing extra variables.  For example, the second-order equation \n''y''<nowiki>''</nowiki>&nbsp;=&nbsp;−''y'' \ncan be rewritten as two first-order equations: ''y''<nowiki>'</nowiki>&nbsp;=&nbsp;''z'' and ''z''<nowiki>'</nowiki>&nbsp;=&nbsp;−''y''.\n\nIn this section, we describe numerical methods for IVPs, and remark that ''[[boundary value problem]]s'' (BVPs) require a different set of tools.  In a BVP, one defines values, or components of the solution ''y'' at more than one point.  Because of this, different methods need to be used to solve BVPs.  For example, the [[shooting method]] (and its variants) or global methods like [[finite difference]]s, [[Galerkin method]]s, or [[collocation method]]s are appropriate for that class of problems.\n\nThe [[Picard&ndash;Lindelöf theorem]] states that there is a unique solution, provided ''f'' is [[Lipschitz continuity|Lipschitz-continuous]].\n\n== Methods ==\n\nNumerical methods for solving first-order IVPs often fall into one of two large categories: [[linear multistep method]]s, or [[Runge–Kutta methods]]. A further division can be realized by dividing methods into those that are explicit and those that are implicit. For example,  implicit [[linear multistep method]]s include [[Linear multistep method#Adams–Moulton methods|Adams-Moulton methods]], and [[Backward differentiation formula|backward differentiation methods]] (BDF), whereas [[implicit Runge–Kutta methods]]<ref>{{harvtxt|Hairer|Nørsett|Wanner|1993|pages=204–215}}</ref> include [[diagonally implicit Runge–Kutta]] (DIRK), [[singly diagonally implicit Runge–Kutta]] (SDIRK), and [[Gauss–Radau]] (based on [[Gaussian quadrature]]) numerical methods. Explicit examples from the [[Linear multistep method|linear multistep family]] include the [[Adams–Bashforth methods]], and any Runge–Kutta method with a lower diagonal [[Butcher tableau]] is [[explicit Runge–Kutta methods|explicit]]. A loose rule of thumb dictates that [[stiff equation|stiff]] differential equations require the use of implicit schemes, whereas non-stiff problems can be solved more efficiently with explicit schemes.\n\nThe so-called [[general linear methods]] (GLMs) are a generalization of the above two large classes of methods.\n\n===Euler method===\n<!--Linked from [[Trigonometric tables]]-->\n{{details|Euler method}}\nFrom any point on a curve, you can find an approximation of a nearby point on the curve by moving a short distance along a line [[tangent]] to the curve.\n\nStarting with the differential equation (1), we replace the derivative ''y''<nowiki>'</nowiki> by the [[finite difference]] approximation\n:<math> y'(t) \\approx \\frac{y(t+h) - y(t)}{h}, \\qquad\\qquad (2) </math>\nwhich when re-arranged yields the following formula\n:<math> y(t+h) \\approx y(t) + hy'(t) \\qquad\\qquad </math>\nand using (1) gives:\n:<math> y(t+h) \\approx y(t) + hf(t,y(t)). \\qquad\\qquad (3) </math>\nThis formula is usually applied in the following way. We choose a step size ''h'', and we construct the sequence ''t''<sub>0</sub>, ''t''<sub>1</sub>&nbsp;=&nbsp;''t''<sub>0</sub>&nbsp;+&nbsp;''h'', ''t''<sub>2</sub>&nbsp;=&nbsp;''t''<sub>0</sub>&nbsp;+&nbsp;2''h'', … We denote by ''y''<sub>''n''</sub> a numerical estimate of the exact solution ''y''(''t''<sub>''n''</sub>). Motivated by (3), we compute these estimates by the following [[recursion|recursive]] scheme \n:<math> y_{n+1} = y_n + hf(t_n,y_n). \\qquad\\qquad (4) </math>\nThis is the ''[[Euler method]]'' (or ''[[forward Euler method]]'', in contrast with the ''backward Euler method'', to be described below). The method is named after [[Leonhard Euler]] who described it in 1768.\n\nThe Euler method is an example of an [[explicit and implicit methods|''explicit'']] method. This means that the new value ''y''<sub>''n+1''</sub> is defined in terms of things that are already known, like ''y''<sub>''n''</sub>.\n\n===Backward Euler method===\n{{details|Backward Euler method}}\nIf, instead of (2), we use the approximation\n:<math> y'(t) \\approx \\frac{y(t) - y(t-h)}{h}, \\qquad\\qquad (5)</math>\nwe get the ''backward Euler method'':\n:<math> y_{n+1} = y_n + hf(t_{n+1},y_{n+1}). \\qquad\\qquad (6)</math>\nThe backward Euler method is an [[explicit and implicit methods|''implicit'']] method, meaning that we have to solve an equation to find ''y''<sub>''n''+1</sub>. One often uses [[fixed-point iteration]] or (some modification of) the [[Newton's method|Newton–Raphson method]] to achieve this.\n\nIt costs more time to solve this equation than explicit methods; this cost must be taken into consideration when one selects the method to use. The advantage of implicit methods such as (6) is that they are usually more stable for solving a [[stiff equation]], meaning that a larger step size ''h'' can be used.\n\n===First-order exponential integrator method===\n{{details|Exponential integrator}}\nExponential integrators describe a large class of integrators that have recently seen a lot of development.<ref name=\"Exponential integrators\">{{harvtxt|Hochbruck|2010|pp=209–286}} This is a modern and extensive review paper for exponential integrators</ref>  They date back to at least the 1960s.\n\nIn place of (1), we assume the differential equation is either of the form\n:<math>y'(t) = -A\\, y+ \\mathcal{N}(y), \\qquad\\qquad\\qquad (7)</math>\nor it has been locally linearized about a background state to produce a linear term <math>-Ay</math> and a nonlinear term <math>\\mathcal{N}(y)</math>.\n\nExponential integrators are constructed by multiplying (7) by <math>e^{A t}</math>, and exactly integrating the result over\na time interval <math>[t_n, t_{n+1} = t_n + h]</math>:\n:<math> y_{n+1} = e^{-A h } y_n + \\int_{0}^{h} e^{ -(h-\\tau) A } \\mathcal{N}\\left( y\\left( t_n+\\tau \\right) \\right)\\, d\\tau. </math>\nThis integral equation is exact, but it doesn't define the integral.\n\nThe first-order exponential integrator can be realized by holding <math>\\mathcal{N}( y( t_n+\\tau ) )</math> constant over the full interval:\n:<math>y_{n+1} = e^{-Ah}y_n + A^{-1}(1-e^{-Ah}) \\mathcal{N}( y( t_n ) )\\ . \\qquad\\qquad (8)</math>\n\n===Generalizations===\nThe Euler method is often not accurate enough. In more precise terms, it only has order one (the concept of ''order'' is explained below). This caused mathematicians to look for higher-order methods.\n\nOne possibility is to use not only the previously computed value ''y''<sub>''n''</sub> to determine ''y''<sub>''n''+1</sub>, but to make the solution depend on more past values. This yields a so-called ''multistep method''. Perhaps the simplest is the [[leapfrog method]] which is second order and (roughly speaking) relies on two time values.\n\nAlmost all practical multistep methods fall within the family of [[linear multistep method]]s, which have the form\n:<math> \\alpha_k y_{n+k} + \\alpha_{k-1} y_{n+k-1} + \\cdots \n+ \\alpha_0 y_n</math>\n::<math> = h \\left[ \\beta_k f(t_{n+k},y_{n+k}) + \\beta_{k-1}\nf(t_{n+k-1},y_{n+k-1}) + \\cdots + \\beta_0 f(t_n,y_n) \\right]. </math>\n\nAnother possibility is to use more points in the interval [''t''<sub>''n''</sub>,''t''<sub>''n''+1</sub>]. This leads to the family of [[Runge–Kutta methods]], named after [[Carl David Tolmé Runge|Carl Runge]] and [[Martin Kutta]]. One of their fourth-order methods is especially popular.\n\n===Advanced features===\nA good implementation of one of these methods for solving an ODE entails more than the time-stepping formula.\n\nIt is often inefficient to use the same step size all the time, so ''variable step-size methods'' have been developed. Usually, the step size is chosen such that the (local) error per step is below some tolerance level. This means that the methods must also compute an ''error indicator'', an estimate of the local error.\n\nAn extension of this idea is to choose dynamically between different methods of different orders (this is called a ''variable order method''). Methods based on [[Richardson extrapolation]], such as the [[Bulirsch–Stoer algorithm]], are often used to construct various methods of different orders.\n\nOther desirable features include: \n* ''dense output'': cheap numerical approximations for the whole integration interval, and not only at the points ''t''<sub>0</sub>, ''t''<sub>1</sub>, ''t''<sub>2</sub>, ...\n* ''event location'': finding the times where, say, a particular function vanishes. This typically requires the use of a [[root-finding algorithm]].\n* support for [[parallel computing]].\n* when used for integrating with respect to time, time reversibility\n\n===Alternative methods===\nMany methods do not fall within the framework discussed here. Some classes of alternative methods are:\n* ''multiderivative methods'', which use not only the function ''f'' but also its derivatives. This class includes ''Hermite–Obreschkoff methods'' and ''[[Runge–Kutta–Fehlberg method|Fehlberg methods]]'', as well as methods like the [[Parker–Sochacki method]] or [[Bychkov–Scherbakov method]], which compute the coefficients of the [[Taylor series]] of the solution ''y'' recursively.\n* ''methods for second order ODEs''. We said that all higher-order ODEs can be transformed to first-order ODEs of the form&nbsp;(1). While this is certainly true, it may not be the best way to proceed. In particular, ''[[Nyström method]]s'' work directly with second-order equations.\n* ''[[geometric integrator|geometric integration methods]]'' are especially designed for special classes of ODEs (e.g., [[symplectic integrator]]s for the solution of [[Hamiltonian mechanics|Hamiltonian equations]]). They take care that the numerical solution respects the underlying structure or geometry of these classes.\n* ''[[Quantized state systems methods]]'' are a family of ODE integration methods based on the idea of state quantization. They are efficient when simulating sparse systems with frequent discontinuities.\n\n===Parallel-in-time methods===\nFor applications that require [[parallel computing]] on [[supercomputer]]s, the degree of concurrency offered by a numerical method becomes relevant. \nIn view of the challenges from [[exascale computing|exascale]] computing systems, numerical methods for [[initial value problem]]s which can provide concurrency in temporal direction are being studied.<ref>{{cite conference\n | last = Gander\n | first = Martin J.\n | authorlink =\n | title = 50 years of Time Parallel Time Integration\n | publisher = Springer International Publishing\n | series = Contributions in Mathematical and Computational Sciences\n | volume = 9\n | edition = 1\n | date = \n | location =\n | pages =\n | language =\n | url =\n | doi = 10.1007/978-3-319-23321-5\n | id =\n | isbn = 978-3-319-23321-5\n | mr =\n | zbl =\n | jfm = }}</ref>\n[[Parareal]] is a relatively well known example of such a ''parallel-in-time'' integration method, but early ideas go back into the 1960s.<ref>\n{{cite journal\n| last       = Nievergelt\n| first      = Jürg\n| date       = 1964\n| title      = Parallel methods for integrating ordinary differential equations\n| journal    = Communications of the ACM\n| volume     = 7\n| issue      =  12\n| pages      =  731–733\n| bibcode    = \n| doi        = 10.1145/355588.365137\n}}</ref>\n\n== Analysis ==\n\n[[Numerical analysis]] is not only the design of numerical methods, but also their analysis. Three central concepts in this analysis are:\n* ''convergence'': whether the method approximates the solution,\n* ''order'': how well it approximates the solution, and\n* [[numerical stability|''stability'']]: whether errors are damped out.\n\n===Convergence===\n{{main|Sequence|Limit (mathematics)|Limit of a sequence}}\nA numerical method is said to be ''convergent'' if the numerical solution approaches the exact solution as the step size ''h'' goes to 0. More precisely, we require that for every ODE (1) with a [[Lipschitz continuous|Lipschitz]] function ''f'' and every ''t''<sup>*</sup>&nbsp;>&nbsp;0,\n\n:<math> \\lim_{h\\to0+} \\max_{n=0,1,\\dots,\\lfloor t^*/h\\rfloor} \\| y_{n,h} - y(t_n) \\| = 0. </math>\n\nAll the methods mentioned above are convergent.\n\n===Consistency and order===\n{{details|Truncation error (numerical integration)}}\nSuppose the numerical method is\n\n:<math> y_{n+k} = \\Psi(t_{n+k}; y_n, y_{n+1}, \\dots, y_{n+k-1}; h). \\, </math>\n\nThe ''local (truncation) error'' of the method is the error committed by one step of the method. That is, it is the difference between the result given by the method, assuming that no error was made in earlier steps, and the exact solution:\n\n:<math> \\delta^h_{n+k} = \\Psi \\left( t_{n+k}; y(t_n), y(t_{n+1}), \\dots, y(t_{n+k-1}); h \\right) - y(t_{n+k}). </math>\n\nThe method is said to be ''consistent'' if \n:<math> \\lim_{h\\to 0} \\frac{\\delta^h_{n+k}}{h} = 0. </math>\nThe method has ''order'' <math>p</math> if\n:<math> \\delta^h_{n+k} = O(h^{p+1}) \\quad\\mbox{as } h\\to0. </math>\nHence a method is consistent if it has an order greater than 0. The (forward) Euler method (4) and the backward Euler method (6) introduced above both have order 1, so they are consistent. Most methods being used in practice attain higher order. Consistency is a necessary condition for convergence, but not sufficient; for a method to be convergent, it must be both consistent and [[zero-stable]].\n\nA related concept is the ''global (truncation) error'', the error sustained in all the steps one needs to reach a fixed time ''t''. Explicitly, the global error at time ''t'' is ''y''<sub>''N''</sub>&nbsp;&minus;&nbsp;''y''(''t'') where ''N''&nbsp;=&nbsp;(''t''&minus;''t''<sub>0</sub>)/''h''. The global error of a ''p''th order one-step method is O(''h''<sup>''p''</sup>); in particular, such a method is convergent.  This statement is not necessarily true for multi-step methods.\n\n===Stability and stiffness===\n{{details|Stiff equation}}\nFor some differential equations, application of standard methods—such as the Euler method, explicit [[Runge–Kutta methods]], or [[multistep method]]s (e.g., Adams–Bashforth methods)—exhibit instability in the solutions, though other methods may produce stable solutions. This \"difficult behaviour\" in the equation (which may not necessarily be complex itself) is described as ''stiffness'', and is often caused by the presence of different time scales in the underlying problem. For example, a collision in a mechanical system like in an [[impact oscillator]] typically occurs at much smaller time scale than the time for the motion of objects; this discrepancy makes for very \"sharp turns\" in the curves of the state parameters.\n\nStiff problems are ubiquitous in [[chemical kinetics]], [[control theory]], [[solid mechanics]], [[weather forecasting]], [[biology]], [[plasma physics]], and [[electronics]]. One way to overcome stiffness is to extend the notion of differential equation to that of [[differential inclusion]], which allows for and models non-smoothness.<ref name=\"Fiedler2001\">{{cite book|editor=Bernold Fiedler|title=Ergodic Theory, Analysis, and Efficient Simulation of Dynamical Systems|year=2001|publisher=Springer Science & Business Media|isbn=978-3-540-41290-8|page=431|chapter=Non-smooth Dynamical Systems: An Overview|authors=Markus Kunze and Tassilo Kupper}}</ref><ref name=\"ZanderSchieferdecker2011\">{{cite book|editor=Justyna Zander, Ina Schieferdecker and Pieter J. Mosterman|title=Model-Based Testing for Embedded Systems|year=2011|publisher=CRC Press|isbn=978-1-4398-1845-9|page=411|author=Thao Dang|chapter=Model-Based Testing of Hybrid Systems}}</ref>\n\n== History ==\n\nBelow is a [[Chronology|timeline]] of some important developments in this field.\n\n* 1768 - [[Leonhard Euler]] publishes his method.\n* 1824 - [[Augustin Louis Cauchy]] proves convergence of the Euler method. In this proof, Cauchy uses the implicit Euler method.\n* 1855 - First mention of the [[multistep method]]s of [[John Couch Adams]] in a letter written by [[F. Bashforth]].\n* 1895 - [[Carl David Tolmé Runge|Carl Runge]] publishes the first [[Runge–Kutta method]].\n* 1901 - [[Martin Kutta]] describes the popular fourth-order [[Runge–Kutta method]].\n* 1910 - [[Lewis Fry Richardson]] announces his [[extrapolation method]], [[Richardson extrapolation]].\n* 1952 - [[Charles F. Curtiss]] and [[Joseph Oakland Hirschfelder]] coin the term ''[[stiff equation]]s''.\n* 1963 - [[Germund Dahlquist]] introduces ''[[Stiff equation#A-stability|A-stability]]'' of integration methods.\n\n== Numerical solutions to second-order one-dimensional boundary value problems ==\n\nBoundary value problems (BVPs) are usually solved numerically by solving an approximately equivalent matrix problem obtained by discretizing the original BVP. The most commonly used method for numerically solving BVPs in one dimension is called the [[Finite Difference Method]].  This method takes advantage of linear combinations of point values to construct [[finite difference coefficient]]s that describe derivatives of the function. For example, the second-order [[central difference]] approximation to the first derivative is given by:\n\n: <math> \\frac{u_{i+1}-u_{i-1}}{2h} = u'(x_i) + \\mathcal{O}(h^2), </math>\n\nand the second-order [[central difference]] for the second derivative is given by:\n\n: <math> \\frac{u_{i+1}- 2 u_i + u_{i-1}}{h^2} = u''(x_i) + \\mathcal{O}(h^2). </math>\n\nIn both of these formulae, <math> h=x_i-x_{i-1}</math> is the distance between neighbouring ''x'' values on the discretized domain. One then constructs a linear system that can then be solved by standard [[numerical linear algebra|matrix methods]]. For instance, suppose the equation to be solved is:\n\n: <math> \\frac{d^2 u}{dx^2} -u =0, </math>\n\n: <math> u(0)=0, </math>\n\n: <math> u(1)=1. </math>\n\nThe next step would be to discretize the problem and use linear derivative approximations such as\n\n: <math> u''_i =\\frac{u_{i+1}-2u_{i}+u_{i-1}}{h^2} </math>\n\nand solve the resulting system of linear equations. This would lead to equations such as:\n\n: <math> \\frac{u_{i+1}-2u_{i}+u_{i-1}}{h^2}-u_i = 0, \\quad \\forall i={1,2,3,...,n-1}.</math>\n\nOn first viewing, this system of equations appears to have difficulty associated with the fact that the equation involves no terms that are not multiplied by variables, but in fact this is false. At ''i'' = 1 and ''n'' &minus; 1 there is a term involving the boundary values <math>u(0)=u_0 </math> and <math> u(1)=u_n  </math> and since these two values are known, one can simply substitute them into this equation and as a result have a non-homogeneous linear system of equations that has non-trivial solutions.\n\n== See also ==\n* [[Courant–Friedrichs–Lewy condition]]\n* [[Energy drift]]\n* [[General linear methods]]\n* [[List of numerical analysis topics#Numerical methods for ordinary differential equations]]\n* [[Reversible reference system propagation algorithm]]\n*[[Modelica]] Language and [[OpenModelica]] software\n\n== Notes ==\n{{reflist|2}}\n\n== References ==\n*{{cite book|last=Bradie|first=Brian|title=A Friendly Introduction to Numerical Analysis|year=2006|publisher=Pearson Prentice Hall|location=Upper Saddle River, New Jersey|isbn=978-0-13-013054-9}}\n*[[John C. Butcher|J. C. Butcher]], ''Numerical methods for ordinary differential equations'', {{isbn|0-471-96758-0}}\n*Ernst Hairer, Syvert Paul Nørsett and Gerhard Wanner, ''Solving ordinary differential equations I: Nonstiff problems,'' second edition, Springer Verlag, Berlin, 1993. {{isbn|3-540-56670-8}}.\n*Ernst Hairer and Gerhard Wanner, ''Solving ordinary differential equations II: Stiff and differential-algebraic problems,'' second edition, Springer Verlag, Berlin, 1996. {{isbn|3-540-60452-9}}. <br> ''(This two-volume monograph systematically covers all aspects of the field.)''\n*{{cite journal|last=Hochbruck|first=Marlis|author1-link=Marlis Hochbruck|author2=Ostermann, Alexander |title=Exponential integrators|journal=Acta Numerica|volume=19|date=May 2010|pages=209–286|doi=10.1017/S0962492910000048|url=http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=7701740|bibcode=2010AcNum..19..209H|citeseerx=10.1.1.187.6794}}\n*Arieh Iserles, ''A First Course in the Numerical Analysis of Differential Equations,'' Cambridge University Press, 1996. {{isbn|0-521-55376-8}} (hardback), {{isbn|0-521-55655-4}} (paperback). <br> ''(Textbook, targeting advanced undergraduate and postgraduate students in mathematics, which also discusses [[numerical partial differential equations]].)''\n*John Denholm Lambert, ''Numerical Methods for Ordinary Differential Systems,'' John Wiley & Sons, Chichester, 1991. {{isbn|0-471-92990-5}}. <br> ''(Textbook, slightly more demanding than the book by Iserles.)''\n\n== External links ==\n* Joseph W. Rudmin, ''[http://csma31.csm.jmu.edu/physics/rudmin/ps.pdf Application of the Parker–Sochacki Method to Celestial Mechanics]'', 1998.\n* Dominique Tournès, ''[http://www.reunion.iufm.fr/dep/mathematiques/calculsavant/Equipe/tournes.html L'intégration approchée des équations différentielles ordinaires (1671-1914)]'', thèse de doctorat de l'université Paris 7 - Denis Diderot, juin 1996. Réimp. Villeneuve d'Ascq : Presses universitaires du Septentrion, 1997, 468 p. (Extensive online material on ODE numerical analysis history, for English-language material on the history of ODE numerical analysis, see e.g. the paper books by Chabert and Goldstine quoted by him.)\n\n{{Numerical integrators}}\n\n{{DEFAULTSORT:Numerical Ordinary Differential Equations}}\n[[Category:Numerical differential equations| ]]\n[[Category:Ordinary differential equations]]"
    },
    {
      "title": "Numerical partial differential equations",
      "url": "https://en.wikipedia.org/wiki/Numerical_partial_differential_equations",
      "text": "'''Numerical partial differential equations''' is the branch of [[numerical analysis]] that studies the numerical solution of [[partial differential equations]] (PDEs).\n\n==Numerical  techniques for solving PDEs==\n\n===Finite difference method===\n{{Main|Finite difference method}}\nIn this method, functions are represented by their values at certain grid points and derivatives are approximated through differences in these values.\n\n===Method of lines===\n{{Main|Method of lines}}\nThe '''method of lines''' (MOL, NMOL, NUMOL<ref name=Schiesser1991>{{cite book|last=Schiesser|first=W. E. |year=1991|title=The Numerical Method of Lines|publisher=Academic Press|isbn=0-12-624130-9}}</ref><ref name=Hamdi2007>Hamdi, S., W. E. Schiesser and G. W. Griffiths (2007), [http://www.scholarpedia.org/article/Method_of_Lines  Method of lines], ''Scholarpedia'', 2(7):2859.</ref><ref name=Schiesser2009>{{cite book|last=Schiesser|first=W. E. |first2=G. W. |last2=Griffiths|year=2009|title=A Compendium of Partial Differential Equation Models:  Method of Lines Analysis with Matlab|publisher=Cambridge University Press|isbn=978-0-521-51986-1}}</ref>) is a technique for solving [[partial differential equations]] (PDEs) in which all but one dimension is discretized.  MOL allows standard, general-purpose methods and software, developed for the numerical integration of [[ordinary differential equation]]s (ODEs) and [[differential algebraic equation]]s (DAEs), to be used. A large number of integration routines have been developed over the years in many different programming languages, and some have been published as [[open source]] resources.<ref name=Lee2004>{{cite book|last=Lee |first=H. J. |first2=W. E. |last2=Schiesser |year=2004|title=Ordinary and Partial Differential Equation Routines in C, C++, Fortran, Java, Maple and Matlab|publisher=CRC Press|isbn=1-58488-423-1}}</ref>\n\nThe method of lines most often refers to the construction or analysis of numerical methods for partial differential equations that proceeds by first discretizing the spatial derivatives only and leaving the time variable continuous.  This leads to a system of ordinary differential equations to which a numerical method for initial value ordinary equations can be applied.  The method of lines in this context dates back to at least the early 1960s.<ref name=Sarmin1962>E. N. Sarmin, L. A. Chudov (1963), On the stability of the numerical integration of systems of ordinary differential equations arising in the use of the straight line method, ''USSR Computational Mathematics and Mathematical Physics'', '''3'''(6), (1537–1543).</ref>\n\n===Finite element method===\n{{Main|Finite element method}}\nThe '''finite element method (FEM)''' is a [[numerical analysis|numerical technique]] for finding approximate solutions to [[boundary value problem]]s for [[differential equations]]. It uses [[variational methods]] (the [[calculus of variations]]) to minimize an error function and produce a stable solution. Analogous to the idea that connecting many tiny straight lines can approximate a larger circle, FEM encompasses all the methods for connecting many simple element equations over many small subdomains, named finite elements, to approximate a more complex equation over a larger [[domain of a function|domain]].\n\n===Gradient discretization method===\n{{Main|Gradient discretization method}}\nThe '''gradient discretization method (GDM)''' is a [[numerical analysis|numerical technique]] that encompasses a few standard or recent methods. It is based on the separate approximation of a function and of its gradient. Core properties allow the convergence of the method for a series of linear and nonlinear problems, and therefore all the methods that enter the GDM framework (conforming and nonconforming finite element, mixed finite element, mimetic finite difference...) inherit these convergence properties.\n\n===Finite volume method===\n{{Main|Finite volume method}}\nThe '''finite-volume method''' is a method for representing and evaluating [[partial differential equation]]s in the form of algebraic equations [LeVeque, 2002; Toro, 1999].  \nSimilar to the [[finite difference method]] or [[finite element method]], values are calculated at discrete places on a meshed geometry. \"Finite volume\" refers to the small volume surrounding each node point on a mesh. In the finite volume method, volume integrals in a partial differential equation that contain a [[divergence]] term are converted to [[surface integral]]s, using the [[divergence theorem]]. These terms are then evaluated as fluxes at the surfaces of each finite volume. Because the flux entering a given volume is identical to that leaving the adjacent volume, these methods are [[Conservation law (physics)|conservative]]. Another advantage of the finite volume method is that it is easily formulated to allow for unstructured meshes. The method is used in many [[computational fluid dynamics]] packages.\n\n===Spectral method===\n{{Main|Spectral method}}\n'''Spectral methods''' are techniques used in [[applied mathematics]] and [[scientific computing]] to numerically solve certain [[differential equation]]s, often involving the use of the [[Fast Fourier Transform]]. The idea is to write the solution of the differential equation as a sum of certain \"basis functions\" (for example, as a [[Fourier series]], which is a sum of [[Sine wave|sinusoid]]s) and then to choose the coefficients in the sum that best satisfy the differential equation.\n\nSpectral methods and [[finite element method]]s are closely related and built on the same ideas; the main difference between them is that spectral methods use basis functions that are nonzero over the whole domain, while finite element methods use basis functions that are nonzero only on small subdomains. In other words, spectral methods take on a ''global approach'' while finite element methods use a ''local approach''. Partially for this reason, spectral methods have excellent error properties, with the so-called \"exponential convergence\" being the fastest possible, when the solution is [[Smooth function|smooth]]. However, there are no known three-dimensional single domain spectral [[shock capturing]] results.<ref name=\"CHQZ\">[https://books.google.com/books?id=7COgEw5_EBQC pp 235, Spectral Methods]: evolution to complex geometries and applications to fluid dynamics, By Canuto, Hussaini, Quarteroni and Zang, Springer, 2007.</ref> In the finite element community, a method where the degree of the elements is very high or increases as the grid parameter ''h'' decreases to zero is sometimes called a [[spectral element method]].\n\n===Meshfree methods===\n{{Main|Meshfree methods}}\n'''Meshfree methods''' do not require a mesh connecting the data points of the simulation domain. Meshfree methods enable the simulation of some otherwise difficult types of problems, at the cost of extra computing time and programming effort.\n\n===Domain decomposition methods===\n{{Main|Domain decomposition method}}\n'''Domain decomposition methods''' solve a [[boundary value problem]] by splitting it into smaller boundary value problems on subdomains and iterating to coordinate the solution between adjacent subdomains. A [[coarse problem]] with one or few unknowns per subdomain is used to further coordinate the solution between the subdomains globally. The problems on the subdomains are independent, which makes domain decomposition methods suitable for [[parallel computing]]. Domain decomposition methods are typically used as [[preconditioner]]s for [[Krylov space]] [[iterative method]]s, such as the [[conjugate gradient method]] or [[GMRES]].\n\nIn overlapping domain decomposition methods, the subdomains overlap by more than the interface. Overlapping domain decomposition methods include the [[Schwarz alternating method]] and the [[additive Schwarz method]]. Many domain decomposition methods can be written and analyzed as a special case of the [[abstract additive Schwarz method]].\n\nIn non-overlapping methods, the subdomains intersect only on their interface. In primal methods, such as [[Balancing domain decomposition]] and [[BDDC]], the continuity of the solution across subdomain interface is enforced by representing the value of the solution on all neighboring subdomains by the same unknown. In dual methods, such as [[FETI]], the continuity of the solution across the subdomain interface is enforced by [[Lagrange multiplier]]s. The [[FETI-DP]] method is hybrid between a dual and a primal method.\n\nNon-overlapping domain decomposition methods are also called '''iterative substructuring methods'''.\n\n[[Mortar method]]s are discretization methods for partial differential equations, which use separate discretization on nonoverlapping subdomains. The meshes on the subdomains do not match on the interface, and the equality of the solution is enforced by Lagrange multipliers, judiciously chosen to preserve the accuracy of the solution. In the engineering practice in the finite element method, continuity of solutions between non-matching subdomains is implemented by [[multiple-point constraint]]s.\n\nFinite element simulations of moderate size models require solving linear systems with millions of unknowns. Several hours per time step is an average sequential run time, therefore, parallel computing is a necessity. Domain decomposition methods embody large potential for a parallelization of the finite element methods, and serve a basis for distributed, parallel computations.\n\n===Multigrid methods===\n{{Main|Multigrid method}}\n'''Multigrid (MG) methods''' in [[numerical analysis]] are a group of [[algorithm]]s for solving [[differential equations]] using a [[hierarchy]] of [[discretization]]s. They are an example of a class of techniques called [[Multiresolution analysis|multiresolution methods]], very useful in (but not limited to) problems exhibiting [[Multiscale modeling|multiple scales]] of behavior. For example, many basic [[relaxation method]]s exhibit different rates of convergence for short- and long-wavelength components, suggesting these different scales be treated differently, as in a [[Fourier analysis]] approach to multigrid.<ref>{{cite book |title=Practical Fourier analysis for multigrid methods |author1=Roman Wienands |author2=Wolfgang Joppich |page=17 |url=https://books.google.com/books?id=IOSux5GxacsC&pg=PA17 |isbn=1-58488-492-4 |publisher=CRC Press |year=2005}}</ref> MG methods can be used as solvers as well as [[preconditioner]]s.\n\nThe main idea of multigrid is to accelerate the convergence of a basic iterative method by ''global'' correction from time to time, accomplished by solving a [[coarse problem]]. This principle is similar to [[interpolation]] between coarser and finer grids. The typical application for multigrid is in the numerical solution of [[elliptic partial differential equation]]s in two or more dimensions.<ref>{{cite book |title=Multigrid |author1=U. Trottenberg |author2=C. W. Oosterlee |author3=A. Schüller |publisher=Academic Press |year=2001 |isbn=0-12-701070-X |url=https://books.google.com/books?id=-og1wD-Nx_wC&printsec=frontcover&dq=isbn:012701070X#v=onepage&q=elliptic&f=false}}</ref>\n\nMultigrid methods can be applied in combination with any of the common discretization techniques. For example, the [[finite element method]] may be recast as a multigrid method.<ref>{{cite book |title=Multigrid finite element methods for electromagnetic field modeling |author1=Yu Zhu |author2=Andreas C. Cangellaris |url=https://books.google.com/books?id=amq9j71_nqAC&pg=PA132 |page=132 ''ff'' |isbn=0-471-74110-8 |year=2006 |publisher=Wiley}}</ref> In these cases, multigrid methods are among the fastest solution techniques known today. In contrast to other methods, multigrid methods are general in that they can treat arbitrary regions and [[boundary condition]]s. They do not depend on the [[Separable partial differential equation|separability of the equations]] or other special properties of the equation.  They have also been widely used for more-complicated non-symmetric and nonlinear systems of equations, like the [[Lamé system]] of [[Elasticity (physics)|elasticity]] or the [[Navier-Stokes equations]].<ref>{{cite thesis |last=Shah |first=Tasneem Mohammad |title=Analysis of the multigrid method |bibcode=1989STIN...9123418S |publisher=Oxford University |year=1989 }}</ref>\n\n==Comparison of methods==\nThe finite difference method is often regarded as the simplest method to learn and use. \nThe finite element and finite volume methods are widely used in [[engineering]] and in [[computational fluid dynamics]], and are well suited to problems in complicated geometries.\nSpectral methods are generally the most accurate, provided that the solutions are sufficiently smooth.\n\n== See also ==\n* [[List of numerical analysis topics#Numerical methods for partial differential equations]]\n* [[Numerical ordinary differential equations]]\n\n==References==\n{{reflist}}\n*LeVeque, Randall (1990), ''Numerical Methods for Conservation Laws'', ETH Lectures in Mathematics Series, Birkhauser-Verlag.\n*Tannehill, John C., et al., (1997), ''Computational Fluid mechanics and Heat Transfer'', 2nd Ed., Taylor and Francis.\n\n== External links ==\n*[http://ocw.mit.edu/courses/aeronautics-and-astronautics/16-920j-numerical-methods-for-partial-differential-equations-sma-5212-spring-2003/ Numerical Methods for Partial Differential Equations] course at [[MIT OpenCourseWare]].\n*[https://web.archive.org/web/20060118052359/http://www.imtek.uni-freiburg.de/simulation/mathematica/IMSweb/ IMS], the Open Source IMTEK Mathematica Supplement (IMS)\n*[http://www3.nd.edu/~dbalsara/Numerical-PDE-Course/ Numerical PDE Techniques for Scientists and Engineers], open access Lectures and Codes for Numerical PDEs\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Numerical Partial Differential Equations}}\n[[Category:Numerical differential equations| ]]\n[[Category:Partial differential equations]]"
    },
    {
      "title": "Adaptive mesh refinement",
      "url": "https://en.wikipedia.org/wiki/Adaptive_mesh_refinement",
      "text": "{{about|the use of adaptive meshing in [[numerical analysis]]|the use of adaptive techniques in [[computer graphics]] modelling|Subdivision surface}}\n\nIn [[numerical analysis]], '''adaptive mesh refinement''' ('''AMR''') is a method of adapting the accuracy of a solution within certain sensitive or turbulent regions of simulation, dynamically and during the time the solution is being calculated. When solutions are calculated numerically, they are often limited to pre-determined quantified grids as in the Cartesian plane which constitute the computational grid, or 'mesh'. Many problems in numerical analysis, however, do not require a uniform precision in the numerical grids used for graph plotting or computational simulation, and would be better suited if specific areas of graphs which needed precision could be refined in quantification only in the regions requiring the added precision. Adaptive mesh refinement provides such a dynamic programming environment for adapting the precision of the numerical computation based on the requirements of a computation problem in specific areas of multi-dimensional graphs which need precision while leaving the other regions of the multi-dimensional graphs at lower levels of precision and resolution.\n\nThis dynamic technique of adapting computation precision to specific requirements has been accredited to [[Marsha Berger]], Joseph Oliger, and [[Phillip Colella]] who developed an [[algorithm]] for dynamic gridding called ''local adaptive mesh refinement''. The use of AMR has since then proved of broad use and has been used in studying turbulence problems in hydrodynamics as well as in the study of large scale structures in astrophysics as in the [[Bolshoi Cosmological Simulation]].\n \n==Development of adaptive mesh refinement==\n[[File:amrgridimg.jpg|framed|The image above shows the grid structure of an AMR calculation of a shock impacting an inclined slope. Each of the boxes is a grid; the more boxes it is nested within, the higher the level of refinements. As the image shows, the algorithm uses high resolution grids only at the physical locations and times where they are required.]]\n\nIn a series of [[scientific paper|papers]], [[Marsha Berger]], Joseph Oliger, and [[Phillip Colella]] developed an [[algorithm]] for dynamic gridding called ''local adaptive mesh refinement''. The algorithm begins with the entire computational [[domain (mathematics)|domain]] covered with a coarsely resolved base-level regular [[Cartesian coordinate system|Cartesian grid]]. As the calculation progresses, individual grid cells are tagged for refinement, using a criterion that can either be user-supplied (for example [[mass]] per cell remains constant, hence higher [[density]] regions are more highly resolved) or based on [[Richardson extrapolation]].\n\nAll tagged cells are then refined, meaning that a finer grid is overlaid on the coarse one. After refinement, individual grid patches on a single fixed level of refinement are passed off to an [[integrator]] which advances those cells in [[time]]. Finally, a correction procedure is implemented to correct the transfer along coarse-fine grid interfaces, to ensure that the amount of any conserved quantity leaving one cell exactly balances the amount entering the bordering cell. If at some point the level of refinement in a cell is greater than required, the high resolution grid may be removed and replaced with a coarser grid.\n\nThis allows the user to solve problems that are completely intractable on a [[regular grid|uniform grid]]; for example, [[astrophysics|astrophysicists]] have used AMR to model  a collapsing [[giant molecular cloud]] core down to an effective resolution of 131,072 cells per initial cloud [[radius]], corresponding to a resolution of 10<sup>15</sup> cells on a uniform grid.<ref>{{cite journal |last1=Klein |first1=Richard |year=1999 |title=Star formation with 3-D adaptive mesh refinement: the collapse and fragmentation of molecular clouds |journal=Journal of Computational and Applied Mathematics |volume=109 |issue=1-2 |pages=123–152 |doi=10.1016/S0377-0427(99)00156-9 |url=http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6TYH-3Y0R65K-V&_user=483702&_coverDate=09/30/1999&_rdoc=1&_fmt=high&_orig=search&_origin=search&_sort=d&_docanchor=&view=c&_searchStrId=1643511112&_rerunOrigin=scholar.google&_acct=C000022720&_version=1&_urlVersion=0&_userid=483702&md5=577df4203e5f672ac4b9e8acad8db5db&searchtype=a |archive-url=https://archive.today/20120912231840/http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6TYH-3Y0R65K-V&_user=483702&_coverDate=09/30/1999&_rdoc=1&_fmt=high&_orig=search&_origin=search&_sort=d&_docanchor=&view=c&_searchStrId=1643511112&_rerunOrigin=scholar.google&_acct=C000022720&_version=1&_urlVersion=0&_userid=483702&md5=577df4203e5f672ac4b9e8acad8db5db&searchtype=a |dead-url=yes |archive-date=September 12, 2012 |accessdate= February 16, 2011}}</ref>\n\nAdvanced mesh refinement has been introduced via functionals.<ref>{{cite book |last1=Huang| first1=Weizhang| last2=Russell|first2=Robert D.| title=\"Adaptive Moving Mesh Methods\"}}</ref> Functionals allow the ability to generate grids and provide mesh adaptation. Some advanced functionals include the Winslow and modified Liao functionals.<ref>{{cite arxiv| last1=Khattri| first1=Sanjay Kumar |title=\"Grid Generation and Adaptation by Functionals\" | arxiv=math/0607388}}</ref>\n\n==Applications of adaptive mesh refinement==\nWhen calculating a solution to the [[shallow water equations]], the solution (water height) might only be calculated for points every few feet apart—and one would assume that in between those points the height varies smoothly.  The limiting factor to the resolution of the solution is thus the grid spacing: there will be no features of the numerical solution on scales smaller than the grid-spacing.  Adaptive mesh refinement (AMR) changes the spacing of grid points, to change how accurately the solution is known in that region.  In the shallow water example, the grid might in general be spaced every few feet—but it could be adaptively refined to have grid points every few inches in places where there are large waves.\n\nIf the region in which higher resolution is desired remains localized over the course of the computation, then ''static mesh refinement'' can be used - in which the grid is more finely spaced in some regions than others, but maintains its shape over time.\n\nThe advantages of a dynamic gridding scheme are:\n\n#Increased computational savings over a static grid approach.\n#Increased storage savings over a static grid approach.\n#Complete control of grid resolution, compared to the fixed resolution of a static grid approach, or the Lagrangian-based adaptivity of [[smoothed particle hydrodynamics]].\n#Compared to pre-tuned static meshes, the adaptive approach requires less detailed a priori knowledge on the evolution of the solution.\n#The computational costs inherit properties of the physical system <ref>Stéphane Popinet, A quadtree-adaptive multigrid solver for the Serre–Green–Naghdi equations, Journal of Computational Physics, Volume 302, 2015,</ref>. \n\n==References==\n* Berger, M. J.; Colella, P. (1989). \"Local adaptive mesh refinement for shock hydrodynamics\". J. Comput. Phys. (Elsevier) 82: 64–84.\n{{reflist}}\n \n==See also==\n\n*[[Adaptive stepsize]]\n*[[Cactus Framework]]\n*[[Multigrid method]]\n*[[Silo (library)]]\n\n{{DEFAULTSORT:Adaptive Mesh Refinement}}\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Alternating direction implicit method",
      "url": "https://en.wikipedia.org/wiki/Alternating_direction_implicit_method",
      "text": "In [[numerical linear algebra]], the '''Alternating Direction Implicit (ADI) method''' is an iterative method used to solve [[Sylvester equation|Sylvester]] matrix equations. It is a popular method for solving the large matrix equations that arise in [[systems theory]] and [[Control theory|control]],<ref name=\":1\">{{Cite journal|last=Simoncini|first=V.|date=2016|title=Computational Methods for Linear Matrix Equations|url=https://doi.org/10.1137/130912839|journal=SIAM Review|language=en|volume=58|issue=3|pages=377–441|doi=10.1137/130912839|issn=0036-1445|via=}}</ref> and can be formulated to construct solutions in a memory-efficient, factored form.<ref name=\":2\">{{Cite journal|last=Li|first=Jing-Rebecca|last2=White|first2=Jacob|date=2002|title=Low Rank Solution of Lyapunov Equations|url=https://doi.org/10.1137/S0895479801384937|journal=SIAM Journal on Matrix Analysis and Applications|language=en|volume=24|issue=1|pages=260–280|doi=10.1137/s0895479801384937|issn=0895-4798|via=}}</ref><ref name=\":3\">{{Cite journal|last=Benner|first=Peter|last2=Li|first2=Ren-Cang|last3=Truhar|first3=Ninoslav|date=2009|title=On the ADI method for Sylvester equations|url=https://doi.org/10.1016/j.cam.2009.08.108|journal=Journal of Computational and Applied Mathematics|volume=233|issue=4|pages=1035–1045|doi=10.1016/j.cam.2009.08.108|issn=0377-0427|via=|bibcode=2009JCoAM.233.1035B}}</ref>  It is also used to numerically solve [[Parabolic partial differential equation|parabolic]] and [[Elliptic partial differential equation|elliptic]] partial differential equations, and is a classic method used for modeling [[heat conduction]] and solving the [[diffusion equation]] in two or more dimensions.<ref name=\":0\">{{Citation|title=The numerical solution of parabolic and elliptic differential equations|year=1955|last1=Peaceman|last2=Rachford Jr.|first1=D. W.|first2=H. H.|journal=Journal of the Society for Industrial and Applied Mathematics|volume=3|issue=1|pages=28–41|doi=10.1137/0103003|mr=0071874}}.</ref> It is an example of an [[operator splitting]] method.<ref>*{{Cite book | last1=Press | first1=WH | last2=Teukolsky | first2=SA | last3=Vetterling | first3=WT | last4=Flannery | first4=BP | year=2007 | title=Numerical Recipes: The Art of Scientific Computing | edition=3rd | publisher=Cambridge University Press |  publication-place=New York | isbn=978-0-521-88068-8 | chapter=Section 20.3.3. Operator Splitting Methods Generally | chapter-url=http://apps.nrbook.com/empanel/index.html#pg=1052}}\n</ref>\n\n== ADI for matrix equations ==\n\n=== The method ===\nThe ADI method is a two step iteration process that alternately updates the column and row spaces of an approximate solution to <math>AX - XB = C</math>. One ADI iteration consists of the following steps:<ref>{{Cite journal|last=Wachspress|first=Eugene L.|date=2008|title=Trail to a Lyapunov equation solver|url=https://doi.org/10.1016/j.camwa.2007.04.048|journal=Computers & Mathematics with Applications|volume=55|issue=8|pages=1653–1659|doi=10.1016/j.camwa.2007.04.048|issn=0898-1221|via=}}</ref><blockquote>1. Solve for <math>X^{(j + 1/2)}</math>, where <math>\\left( A - \\beta_{j +1} I\\right) X^{(j+1/2)} = X^{(j)}\\left( B - \\beta_{j + 1} I \\right) + C.</math> </blockquote><blockquote>2. Solve for <math> X^{(j + 1)}</math>, where  <math> X^{(j+1)}\\left( B - \\alpha_{j + 1} I \\right) = \\left( A - \\alpha_{j+1} I\\right) X^{(j+1/2)} - C</math>.</blockquote>\nThe numbers <math>(\\alpha_{j+1}, \\beta_{j+1})</math> are called shift parameters, and convergence  depends strongly on the choice of these parameters.<ref name=\":4\">{{Cite journal|last=Lu|first=An|last2=Wachspress|first2=E.L.|date=1991|title=Solution of Lyapunov equations by alternating direction implicit iteration|url=https://doi.org/10.1016/0898-1221(91)90124-M|journal=Computers & Mathematics with Applications|volume=21|issue=9|pages=43–58|doi=10.1016/0898-1221(91)90124-m|issn=0898-1221|via=}}</ref><ref name=\":5\">{{Cite journal|last=Beckermann|first=Bernhard|last2=Townsend|first2=Alex|date=2017|title=On the Singular Values of Matrices with Displacement Structure|url=https://doi.org/10.1137/16M1096426|journal=SIAM Journal on Matrix Analysis and Applications|language=en|volume=38|issue=4|pages=1227–1248|doi=10.1137/16m1096426|issn=0895-4798|via=|arxiv=1609.09494}}</ref> To perform <math>K</math> iterations of ADI, an initial guess <math>X^{(0)}</math> is required, as well as <math>K</math> shift parameters, <math>\\{ (\\alpha_{j}, \\beta_{j})\\}_{j = 1}^{K}</math>.\n\n=== When to use ADI ===\nIf <math>A \\in \\mathbb{C}^{m \\times m}</math> and  <math>B \\in \\mathbb{C}^{n \\times n}</math>,  then <math> AX - XB = C</math> can be solved directly in <math> \\mathcal{O}(m^3 + n^3)</math> using the Bartels-Stewart method.<ref>{{Cite book|url=https://www.worldcat.org/oclc/824733531|title=Matrix computations|last=Golub, G.|publisher=Johns Hopkins University|others=Van Loan, C|year=1989|isbn=1421407949|edition=Fourth |location=Baltimore|pages=|oclc=824733531}}</ref> It is therefore only beneficial to use ADI when matrix-vector multiplication and linear solves involving <math>A</math> and <math>B</math> can be applied cheaply.\n\nThe equation <math> AX-XB=C</math> has a unique solution if and only if <math> \\sigma(A) \\cap \\sigma(B) = \\emptyset</math>, where <math> \\sigma(M) </math> is the [[Spectrum of a matrix|spectrum]] of <math>M</math>.<ref name=\":1\" /> However, the ADI method performs especially well when <math>\\sigma(A)</math> and <math>\\sigma(B)</math> are well-separated, and <math>A</math> and <math>B</math> are [[Normal matrix|normal matrices]]. These assumptions are met, for example, by the Lyapunov equation <math>AX + XA^* = C</math> when <math>A</math> is [[Positive-definite matrix|positive definite]].  Under these assumptions, near-optimal shift parameters are known for several choices of <math>A</math> and <math>B</math>.<ref name=\":4\" /><ref name=\":5\" /> Additionally, a priori error bounds can be computed, thereby eliminating the need to monitor the residual error in implementation.\n\nThe ADI method can still be applied when the above assumptions are not met. The use of suboptimal shift parameters may adversely affect convergence,<ref name=\":1\" /> and convergence is also affected by the non-normality of <math>A</math> or <math>B</math> (sometimes advantageously).<ref name=\":6\">{{Cite journal|last=Sabino|first=J|date=2007|title=Solution of large-scale Lyapunov equations via the block modified Smith method|url=https://scholarship.rice.edu/handle/1911/20641|journal=PhD diss., Rice Univ.|volume=|pages=|via=}}</ref> [[Krylov subspace]] methods, such as the Rational Krylov Subspace Method,<ref>{{Cite journal|last=Druskin|first=V.|last2=Simoncini|first2=V.|date=2011|title=Adaptive rational Krylov subspaces for large-scale dynamical systems|url=https://doi.org/10.1016/j.sysconle.2011.04.013|journal=Systems & Control Letters|volume=60|issue=8|pages=546–560|doi=10.1016/j.sysconle.2011.04.013|issn=0167-6911|via=}}</ref> are observed to typically converge more rapidly than ADI in this setting,<ref name=\":1\" /><ref name=\":3\" /> and this has led to the development of hybrid ADI-projection methods.<ref name=\":3\" />\n\n=== Shift Parameter Selection and the ADI error equation ===\nThe problem of finding good shift parameters is nontrivial. This problem can be understood by examining the ADI error equation.  After <math>K</math> iterations, the error is given by\n\n<math>  X - X^{(K)}   = \\prod_{j = 1}^K \\frac{(A - \\alpha_j I)}{(A - \\beta_j I)} \\left ( X - X^{(0)} \\right ) \\prod_{j = 1}^K \\frac{(B - \\beta_j I)}{(B - \\alpha_j I)}.</math>\n\nChoosing <math>X^{(0)} = 0</math> results in the following bound on the relative error:\n\n<math> \\frac{\\left \\|X - X^{(K)} \\right \\|_2}{\\|X\\|_2} \\leq \\| r_K(A) \\|_2 \\| r_K(B)^{-1}\\|_2, \\quad r_K(M) =  \\prod_{j = 1}^K \\frac{(M - \\alpha_j I)}{(M - \\beta_j I)}.  </math>\n\nwhere <math>\\| \\cdot \\|_2</math> is the [[Matrix norm|operator norm]]. The ideal set of shift parameters <math> \\{ (\\alpha_j, \\beta_j)\\}_{j = 1}^K  </math> defines a [[rational function]] <math> r_K  </math> that minimizes the quantity <math> \\| r_K(A) \\|_2 \\| r_K(B)^{-1}\\|_2  </math>. If <math>A</math> and <math>B</math> are [[Normal matrix|normal matrices]] and have [[Eigendecomposition of a matrix|eigendecompositions]] <math>A = V_A\\Lambda_AV_A^*</math> and <math>B = V_B\\Lambda_BV_B^*</math>, then\n\n<math> \\| r_K(A) \\|_2 \\| r_K(B)^{-1}\\|_2  = \\| r_K(\\Lambda_A) \\|_2 \\| r_K(\\Lambda_B)^{-1}\\|_2 </math>.\n\n==== Near-optimal shift parameters ====\nNear-optimal shift parameters are known in certain cases, such as when <math>\\Lambda_A \\subset [a, b]</math> and <math>\\Lambda_B \\subset [c, d]</math>, where <math>[a, b]</math> and <math>[c, d]</math> are disjoint intervals on the real line.<ref name=\":4\" /><ref name=\":5\" /> The [[Lyapunov equation]] <math>AX + XA^* = C</math>, for example, satisfies these assumptions when <math>A</math> is [[Positive-definite matrix|positive definite]]. In this case, the shift parameters can be expressed in closed form using [[elliptic integral]]s, and can easily be computed numerically.\n\nMore generally, if closed, disjoint sets <math>E</math> and <math>F</math>, where  <math>\\Lambda_A \\subset E</math> and <math>\\Lambda_B \\subset F</math>, are known, the optimal shift parameter selection problem is approximately solved by finding an extremal rational function that attains the value\n\n<math>\nZ_K(E, F) : = \\inf_{r} \\frac{ \\sup_{z \\in E} |r(z)| }{ \\inf_{z \\in F} |r(z)| },\n</math>\n\nwhere the infimum is taken over all rational functions of degree <math>(K, K)</math>.<ref name=\":5\" /> This approximation problem is related to several results in [[potential theory]],<ref>{{Cite book|url=https://www.worldcat.org/oclc/883382758|title=Logarithmic potentials with external fields|last=1944-|first=Saff, E. B.,|others=Totik, V.|isbn=9783662033296|location=Berlin|oclc=883382758}}</ref><ref>{{Cite journal|last=Gonchar|first=A.A.|date=1969|title=Zolotarev problems connected with rational functions|url=|journal=Mat. Sb. (N.S.)|volume=78 (120):4|pages=640–654|via=}}</ref> and was solved by [[Yegor Ivanovich Zolotarev|Zolotarev]] in 1877 for <math>E</math> = [a, b] and  <math> F=-E.</math><ref>{{Cite journal|last=Zolotarev|first=D.I.|date=1877|title=Application of elliptic functions to questions of functions deviating least and most from zero|url=|journal=Zap. Imp. Akad. Nauk.  St. Petersburg|volume=30|pages=1–59|via=}}</ref> The solution is also known when <math> E</math> and <math> F</math> are disjoint disks in the complex plane.<ref>{{Cite journal|last=Starke|first=Gerhard|date=July 1992|title=Near-circularity for the rational Zolotarev problem in the complex plane|url=https://doi.org/10.1016/0021-9045(92)90059-W|journal=Journal of Approximation Theory|volume=70|issue=1|pages=115–130|doi=10.1016/0021-9045(92)90059-w|issn=0021-9045}}</ref>\n\n==== Heuristic shift parameter strategies ====\nWhen less is known about <math>\\sigma(A)</math> and <math>\\sigma(B)</math>, or when <math>A</math> or <math>B</math> are non-normal matrices, it may not be possible to find near-optimal shift parameters. In this setting, a variety of strategies for generating good shift parameters can be used.  These include strategies based on asymptotic results in potential theory,<ref>{{Cite journal|last=Starke|first=Gerhard|date=June 1993|title=Fejér-Walsh points for rational functions and their use in the ADI iterative method|url=https://doi.org/10.1016/0377-0427(93)90291-I|journal=Journal of Computational and Applied Mathematics|volume=46|issue=1-2|pages=129–141|doi=10.1016/0377-0427(93)90291-i|issn=0377-0427}}</ref> using the Ritz values of the matrices <math>A</math>, <math>A^{-1}</math>, <math>B</math>, and <math>B^{-1}</math> to formulate a greedy approach,<ref name=\":7\">{{Cite journal|last=Penzl|first=Thilo|date=January 1999|title=A Cyclic Low-Rank Smith Method for Large Sparse Lyapunov Equations|url=https://doi.org/10.1137/S1064827598347666|journal=SIAM Journal on Scientific Computing|language=en|volume=21|issue=4|pages=1401–1418|doi=10.1137/s1064827598347666|issn=1064-8275}}</ref> and cyclic methods, where the same small collection of shift parameters are reused until a convergence tolerance is met.<ref name=\":7\" /><ref name=\":6\" /> When the same shift parameter is used at every iteration, ADI is equivalent to an algorithm called Smith's method.<ref>{{Cite journal|last=Smith|first=R. A.|date=January 1968|title=Matrix Equation XA + BX = C|url=https://doi.org/10.1137/0116017|journal=SIAM Journal on Applied Mathematics|language=en|volume=16|issue=1|pages=198–201|doi=10.1137/0116017|issn=0036-1399|via=}}</ref>\n\n=== Factored ADI ===\nIn many applications, <math>A</math> and <math>B</math> are very large, sparse matrices, and <math>C</math> can be factored as <math>C = C_1C_2^*</math>, where <math>C_1 \\in \\mathbb{C}^{m \\times r}, C_2 \\in \\mathbb{C}^{n \\times r}</math>, with <math>r = 1, 2</math>.<ref name=\":1\" />  In such a setting, it may not be feasible to store the potentially dense matrix <math>X</math> explicitly. A variant of ADI, called factored ADI,<ref name=\":3\" /><ref name=\":2\" /> can be used to compute <math>ZY^*</math>, where <math>X \\approx ZY^*</math>.  The effectiveness of factored ADI depends on whether <math>X</math> is well-approximated by a low rank matrix. This is known to be true under various assumptions about <math>A</math> and <math>B</math>.<ref name=\":6\" /><ref name=\":5\" />\n\n== ADI for parabolic equations ==\nHistorically, the ADI method was developed to solve the 2D diffusion equation on a square domain using finite differences.<ref name=\":0\" /> Unlike ADI for matrix equations, ADI for parabolic equations does not require the selection of shift parameters, since the shift appearing in each iteration is determined by parameters such as the timestep, diffusion coefficient, and grid spacing. The connection to ADI on matrix equations can be observed when one considers the action of the ADI iteration on the system at steady state.\n\n=== Example: 2D diffusion equation ===\n[[File:ADI-stencil.svg|thumb|Stencil figure for the alternating direction implicit method in finite difference equations]]\n\nThe traditional method for solving the heat conduction equation numerically is the [[Crank–Nicolson method]]. This method results in a very complicated set of equations in multiple dimensions, which are costly to solve. The advantage of the ADI method is that the equations that have to be solved in each step have a simpler structure and can be solved efficiently with the [[tridiagonal matrix algorithm]].\n\nConsider the linear diffusion equation in two dimensions,\n\n: <math>{\\partial u\\over \\partial t} =\n \\left({\\partial^2 u\\over \\partial x^2 } +\n{\\partial^2 u\\over \\partial y^2 }\n\\right)\n =  ( u_{xx} + u_{yy} )\n</math>\n\nThe implicit Crank–Nicolson method produces the following finite difference equation:\n\n: <math>{u_{ij}^{n+1}-u_{ij}^n\\over \\Delta t} =\n{1 \\over 2(\\Delta x)^2}\\left(\\delta_x^2+\\delta_y^2\\right)\n\\left(u_{ij}^{n+1}+u_{ij}^n\\right)</math>\n\nwhere:\n\n: <math>\\Delta x = \\Delta y</math>\n\nand <math>\\delta_p^2</math> is the central second difference operator for the ''p''-th coordinate\n: <math>\\delta_p^2 u_{ij}=u_{ij+e_p}-2u_{ij}+u_{ij-e_p}</math>\nwith <math>e_p=10</math> or <math>01</math> for <math>p=x</math> or <math>y</math> respectively (and <math>ij</math> a shorthand for lattice points <math>(i,j)</math>).\n\nAfter performing a [[Von Neumann stability analysis|stability analysis]], it can be shown that this method will be stable for any <math>\\Delta t</math>.\n\nA disadvantage of the Crank–Nicolson method is that the matrix in the above equation is [[band matrix|banded]] with a band width that is generally quite large. This makes direct solution of the [[system of linear equations]] quite costly (although efficient approximate solutions exist, for example use of the [[conjugate gradient method]] preconditioned with [[incomplete Cholesky factorization]]).\n\nThe idea behind the ADI method is to split the finite difference equations into two, one with the ''x''-derivative taken implicitly and the next with the ''y''-derivative taken implicitly,\n\n: <math>{u_{ij}^{n+1/2}-u_{ij}^n\\over \\Delta t/2} =\n{\\left(\\delta_x^2 u_{ij}^{n+1/2}+\\delta_y^2 u_{ij}^{n}\\right)\\over \\Delta x^2}</math>\n\n: <math>{u_{ij}^{n+1}-u_{ij}^{n+1/2}\\over \\Delta t/2} =\n{\\left(\\delta_x^2 u_{ij}^{n+1/2}+\\delta_y^2 u_{ij}^{n+1}\\right)\\over \\Delta y^2}</math>\n\nThe system of equations involved is [[symmetric matrix|symmetric]] and tridiagonal (banded with bandwidth 3), and is typically solved using [[tridiagonal matrix algorithm]].\n\nIt can be shown that this method is unconditionally stable and second order in time and space.<ref>{{Citation | last1=Douglas, Jr. | first1=J.  | title=On the numerical integration of u<sub>xx</sub>+ u<sub>yy</sub>= u<sub>t</sub> by implicit methods | mr=0071875 | year=1955 |  journal=Journal of the Society for Industrial and Applied Mathematics | volume=3 | pages=42–65}}.\n</ref>  There are more refined ADI methods such as the methods of Douglas,<ref>{{Citation | last1=Douglas Jr. | first1=Jim | title=Alternating direction methods for three space variables | doi=10.1007/BF01386295 | year=1962 | journal=Numerische Mathematik | issn=0029-599X | volume=4 | issue=1 | pages=41–63}}.</ref> or the f-factor method<ref>{{Citation | last1=Chang | first1=M. J. | last2=Chow | first2=L. C. | last3=Chang | first3=W. S. | title=Improved alternating-direction implicit method for solving transient three-dimensional heat diffusion problems | doi=10.1080/10407799108944957 | year=1991 | journal=Numerical Heat Transfer, Part B: Fundamentals | issn=1040-7790 | volume=19 | issue=1 | pages=69–84}}.</ref> which can be used for three or more dimensions.\n\n=== Generalizations ===\nThe usage of the ADI method as an operator splitting scheme can be generalized. That is, we may consider general evolution equations\n: <math> \\dot u = F_1 u + F_2 u, </math>\nwhere <math> F_1 </math> and <math> F_2 </math> are (possibly nonlinear) operators defined on a Banach space.<ref>{{cite book|last2=Verwer|first2=Jan|first1=Willem|last1=Hundsdorfer|title=Numerical Solution of Time-Dependent Advection-Diffusion-Reaction Equations|date=2003|publisher=Springer Berlin Heidelberg|location=Berlin, Heidelberg|isbn=978-3-662-09017-6}}</ref><ref>{{cite journal|last1=Lions|first1=P. L.|last2=Mercier|first2=B.|title=Splitting Algorithms for the Sum of Two Nonlinear Operators|journal=SIAM Journal on Numerical Analysis|date=December 1979|volume=16|issue=6|pages=964–979|doi=10.1137/0716071}}</ref> In the diffusion example above we have <math> F_1 = {\\partial^2 \\over \\partial x^2} </math> and <math> F_2 = {\\partial^2 \\over \\partial y^2} </math>.\n\n== References ==\n{{Reflist}}\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Alternating Direction Implicit Method}}\n[[Category:Partial differential equations]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Analytic element method",
      "url": "https://en.wikipedia.org/wiki/Analytic_element_method",
      "text": "The '''analytic element method''' ('''AEM''') is a [[numerical analysis|numerical]] method used for the solution of [[partial differential equation]]s. It was initially developed by O.D.L. Strack at the [[University of Minnesota]]. It is similar in nature to the [[boundary element method]] (BEM), as it does not rely upon discretization of volumes or areas in the modeled system; only internal and external boundaries are discretized. One of the primary distinctions between AEM and BEMs is that the boundary integrals are calculated analytically. \n\nThe analytic element method has been applied to problems of [[Groundwater flow equation|groundwater flow]] governed by a variety of linear partial differential equations including the [[Laplace equation|Laplace]], the [[Poisson equation]], the modified Helmholtz equation, the [[heat equation]], and the [[Biharmonic equation|biharmonic]] equations. \n\nThe basic premise of the analytic element method is that, for [[linear differential equation]]s, elementary solutions may be superimposed to obtain more complex solutions. A suite of 2D and 3D analytic solutions (\"elements\") are available for different governing equations. These elements typically correspond to a discontinuity in the dependent variable or its gradient along a geometric boundary (e.g., point, line, ellipse, circle, sphere, etc.). This discontinuity has a specific functional form (usually a polynomial in 2D) and may be manipulated to satisfy Dirichlet, Neumann, or Robin (mixed) boundary conditions. Each analytic solution is infinite in space and/or time. In addition, each analytic solution contains degrees of freedom (coefficients) that may be calculated to meet prescribed boundary conditions along the element's border. To obtain a global solution (i.e., the correct element coefficients), a system of equations is solved such that the boundary conditions are satisfied along all of the elements (using [[collocation method|collocation]], [[least squares|least-squares minimization]], or a similar approach). Notably, the global solution provides a spatially continuous description of the dependent variable everywhere in the infinite domain, and the governing equation is satisfied everywhere exactly except along the border of the element, where the governing equation is not strictly applicable due to the discontinuity.\n\nThe ability to superpose numerous elements in a single solution means that analytical solutions can be realized for arbitrarily complex boundary conditions.  That is, models that have complex geometries, straight or curved boundaries, multiple boundaries, transient boundary conditions, multiple aquifer layers, piecewise varying properties and continuously varying properties can be solved.  Elements can be implemented using far-field expansions such that model containing many thousands of elements can be solved efficiently to high precision.\n\nA contemporary student of Strack's who is a proponent of the Analytic Element Method (AEM) in groundwater modeling applications is Dr. David Steward of Kansas State University.\n\n==See also==\n* [[Boundary element method]]\n\n==References==\n*{{cite book |last=Haitjema |first=H. M. |date=1995 |title=Analytic element modeling of groundwater flow |url=http://www.haitjema.com/howtoorder.html |publisher=Academic Press |location=San Diego, CA |isbn=978-0-12-316550-3}}\n*{{cite book |last=Strack |first=O. D. L. |date=1989 |title=Groundwater Mechanics |publisher=Prentice Hall |location=Englewood Cliffs, NJ}}\n*{{cite book |last=Fitts |first=C. R. |date=2012 |title=Groundwater Science |edition=2nd |url=http://booksite.elsevier.com/9780123847058/ |location=San Diego, CA |publisher=Elsevier/Academic Press |isbn=9780123847058}}\n\n==External links==\n* [http://www.analyticelements.org/mw/index.php/Main_Page Analytic elements community wiki]\n* [http://www.fittsgeosolutions.com/ Fitts Geolsolutions, AnAqSim (analytic aquifer simulator) and AnAqSimEDU (free) web site]\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Analytic Element Method}}\n[[Category:Numerical differential equations]]\n[[Category:Hydrology models]]\n\n\n{{analysis-stub}}\n{{comp-sci-stub}}"
    },
    {
      "title": "AUSM",
      "url": "https://en.wikipedia.org/wiki/AUSM",
      "text": "{{for|the New Zealand students' union|AuSM}}\n\n'''AUSM''' stands for ''Advection Upstream Splitting Method''. It is developed as a numerical [[inviscid]] [[flux]] function for solving a general system of [[conservation equation]]s. It is based on the upwind concept and was motivated to provide an alternative approach to other upwind methods, such as the [[Godunov method]], flux difference splitting methods by Roe, and Solomon and Osher, flux vector splitting methods by Van Leer, and Steger and Warming. The AUSM first recognizes that the inviscid flux consist of two physically distinct parts, i.e., convective and pressure fluxes. The former is associated with the flow ([[advection]]) speed, while the latter with the acoustic speed; or respectively classified as the linear and nonlinear fields. Currently, the convective and pressure fluxes are formulated using the [[eigenvalue]]s of the flux [[Jacobian matrix|Jacobian matrices]]. The method was originally proposed by Liou and Steffen <ref>Liou, M.-S. and Steffen, C., “A New Flux Splitting Scheme,” J. Comput. Phys., Vol. 107, 23-39, 1993.</ref> for the typical compressible aerodynamic flows, and later substantially improved in <ref name=\"firstName\">Liou, M.-S., “A Sequel to AUSM: AUSM+” J. Comput. Phys., Vol. 129, 364-382, 1996.</ref><ref>Wada, Y. and Liou, M.-S., “An Accurate and Robust Flux Splitting Scheme for Shock and Contact Discontinuities,” SIAM J. Scientific Computing, Vol. 18, 633-657, 1997.</ref> to yield a more accurate and robust version. To extend its capabilities, it has been further developed in <ref name=\"secondName\">Liou, M.-S., “A Sequel to AUSM, Part II: AUSM+-up” J. Comput. Phys., Vol. 214, 137- 170, 2006.\n</ref><ref>Edwards, J. R., Franklin, R., and Liou, M.-S., “Low-Diffusion Flux-Splitting Methods for Real Fluid Flows with Phase Transitions,” AIAA J., Vol. 38, 1624-1633, 2000.</ref><ref>Chang, C.-H. and Liou, M.-S., “A New Approach to the Simulation of Compressible Multifluid Flows with AUSM+ Scheme,” AIAA Paper 2003-4107, 16th AIAA CFD Conference, Orlando, FL, June 23–26, 2003.</ref> for all speed-regimes and [[multiphase flow]]. Its variants have also been proposed.<ref>Edwards, J. R. and Liou, M.-S., “Low-Diffusion Flux-Splitting Methods for Flows at All Speeds,” AIAA J., Vol. 36, 1610-1617, 1998.</ref><ref>Kim, K. H., Kim, C., and Rho, O., “Methods for the Accurate Computations of Hypersonic Flows I. AUSMPW+ Scheme,” J. Comput. Phys., Vol. 174, 38-80, 2001.</ref>\n\n==Features==\nThe Advection Upstream Splitting Method has many features. The main features are:\n*accurate capturing of [[Shocks and discontinuities (magnetohydrodynamics)|shock and contact discontinuities]]\n*[[entropy]]-satisfying solution\n*positivity-preserving solution\n*algorithmic simplicity (not requiring explicit eigen-structure of the flux Jacobian matrices) and straightforward extension to additional conservation laws\n*free of “carbuncle” phenomena\n*uniform accuracy and convergence rate for all [[Mach number]]s.\nSince the method does not specifically require [[eigenvector]]s, it is especially attractive for the system whose eigen-structure is not known explicitly, as the case of two-fluid equations for multiphase flow.\n\n==Applications==\nThe AUSM has been employed to solve a wide range of problems, low-Mach to [[hypersonic]] [[aerodynamics]], [[large eddy simulation]] and [[aero-acoustics]],<ref>Mary, I. and Sagaut, P., “Large Eddy Simulation of Flow Around an Airfoil Near Stall,” AIAA J., Vol. 40, 1139-1145, 2002.</ref><ref>Manoha, E., Redonnet, S., Terracol, M., and Guenanff, G., “Numerical Simulation of Aerodynamics Noise,” ECCOMAS 24–28 July 2004.</ref> direct numerical simulation,<ref>Billet, G. and Louedin, O., “Adaptive Limiters for Improving the Accuracy of the MUSCL Approach for Unsteady Flows,” J. Comput. Phys., Vol. 170, 161-183, 2001.</ref> multiphase flow,<ref>[http://www.crss.ucsb.edu/ Center for Risk Studies and Safety] {{webarchive |url=https://web.archive.org/web/20060424060610/http://www.crss.ucsb.edu/ |date=April 24, 2006 }}, University of California (Santa Barbara)</ref> galactic relativistic flow<ref>Wada, K. and Koda, J., “Instabilities of Spiral Shock – I. Onset of Wiggle Instability and its Mechanism,” [[Monthly Notices of the Royal Astronomical Society]], Vol. 349, 270-280 (11), 2004.</ref> etc.\n\n==See also==\n*[[Euler equations]]\n*[[Finite volume method]]\n*[[Flux limiter]]\n*[[Godunov's theorem]]\n*[[High resolution scheme]]\n*[[Numerical method of lines]]\n*[[Sergei K. Godunov]]\n*[[Total variation diminishing]]\n\n==References==\n<references/>\n\n{{DEFAULTSORT:Ausm}}\n[[Category:Computational fluid dynamics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Backward differentiation formula",
      "url": "https://en.wikipedia.org/wiki/Backward_differentiation_formula",
      "text": "The '''backward differentiation formula''' (BDF) is a family of implicit methods for the [[Numerical ordinary differential equations|numerical integration of ordinary differential equations]]. They are [[linear multistep method]]s that, for a given function and time, approximate the derivative of that function using information from already computed times, thereby increasing the accuracy of the approximation. These methods are especially used for the solution of [[Stiff equation|stiff differential equations]]. The method were first introduced by [[:de:Charles Francis Curtiss|Charles F. Curtiss]] and [[Joseph O. Hirschfelder]] in 1952.<ref>Curtiss, C. F., & Hirschfelder, J. O. (1952). Integration of stiff equations. Proceedings of the National Academy of Sciences, 38(3), 235-243.</ref>\n\n== General formula ==\n\nA BDF is used to solve the [[initial value problem]]\n\n: <math> y' = f(t,y), \\quad y(t_0) = y_0. </math>\n\nThe general formula for a BDF can be written as <ref name=ascher1998>{{harvnb|Ascher|Petzold|1998|loc = §5.1.2, p. 129}}</ref>\n\n: <math> \\sum_{k=0}^s a_k y_{n+k} = h \\beta f(t_{n+s}, y_{n+s}), </math>\n\nwhere <math> h </math> denotes the step size and <math> t_n = t_0 + nh </math>. Since <math>f</math> is evaluated for the unknown <math>y_{n+s}</math>, BDF methods are [[explicit and implicit methods|implicit]] and possibly require the solution of nonlinear equations at each step. The coefficients <math> a_k </math> and <math> \\beta </math> are chosen so that the method achieves order <math> s </math>, which is the maximum possible.\n\n=== Derivation of the coefficients ===\nStarting from the formula <math display=\"inline\">y'(t_{n+s}) = f(t_{n+s}, y(t_{n+s}))</math> one approximates <math>y(t_{n+s}) \\approx y_{n+s}</math> and <math>y'(t_{n+s}) \\approx p_{n, s}'(t_{n+s})</math>, where <math>p_{n, s}(t)</math> is the [[Lagrange polynomial|Lagrange interpolation polynomial]] for the points <math>(t_n, y_n), \\ldots, (t_{n+s}, y_{n+s})</math>. Using that <math> t_n = t_0 + nh </math> and multiplying by <math>h</math> one arrives at the BDF method of order <math>s</math>.\n\n== Specific formulas ==\n\nThe ''s''-step BDFs with ''s'' < 7 are:<ref>{{harvnb|Iserles|1996|p=27}} (for ''s'' = 1, 2, 3); {{harvnb|Süli|Mayers|2003|p=349}} (for all ''s'')</ref>\n* BDF1: <math> y_{n+1} - y_n = h f(t_{n+1}, y_{n+1}) </math> (this is the [[backward Euler method]])\n* BDF2: <math> y_{n+2} - \\tfrac43 y_{n+1} + \\tfrac13 y_n = \\tfrac23 h f(t_{n+2}, y_{n+2}) </math>\n* BDF3: <math> y_{n+3} - \\tfrac{18}{11} y_{n+2} + \\tfrac9{11} y_{n+1} - \\tfrac2{11} y_n = \\tfrac6{11} h f(t_{n+3}, y_{n+3}) </math>\n* BDF4: <math> y_{n+4} - \\tfrac{48}{25} y_{n+3} + \\tfrac{36}{25} y_{n+2} - \\tfrac{16}{25} y_{n+1} + \\tfrac{3}{25} y_n = \\tfrac{12}{25} h f(t_{n+4}, y_{n+4}) </math>\n* BDF5: <math> y_{n+5} - \\tfrac{300}{137} y_{n+4} + \\tfrac{300}{137} y_{n+3} - \\tfrac{200}{137} y_{n+2} + \\tfrac{75}{137} y_{n+1} - \\tfrac{12}{137} y_n = \\tfrac{60}{137} h f(t_{n+5}, y_{n+5}) </math>\n* BDF6: <math> y_{n+6} - \\tfrac{360}{147} y_{n+5} + \\tfrac{450}{147} y_{n+4} - \\tfrac{400}{147} y_{n+3} + \\tfrac{225}{147} y_{n+2} - \\tfrac{72}{147} y_{n+1} + \\tfrac{10}{147} y_n = \\tfrac{60}{147} h f(t_{n+6}, y_{n+6}) </math>\nMethods with ''s'' > 6 are not [[zero-stability|zero-stable]] so they cannot be used.<ref name=suli2003p349>{{harvnb|Süli|Mayers|2003|p=349}}</ref>\n\n==Stability==\n\nThe stability of numerical methods for solving [[stiff equation]]s is indicated by their region of absolute stability. For the BDF methods, these regions are shown in the plots below.\n\nIdeally, the region contains the left half of the complex plane, in which case the method is said to be A-stable. However, [[linear multistep method]]s with an order greater than 2 cannot be [[stiff equation|A-stable]]. The stability region of the higher-order BDF methods contain a large part of the left half-plane and in particular the whole of the negative real axis. The BDF methods are the most efficient linear multistep methods of this kind.<ref name=suli2003p349 />\n\n{{Gallery\n|title=The pink region shows the stability region of the BDF methods\n|width=220\n|align=center\n|perrow=3\n|File:Stability region for BDF1.svg|BDF1\n|File:Stability region for BDF2.svg|BDF2\n|File:Stability region for BDF3.svg|BDF3\n|File:Stability region for BDF4.svg|BDF4\n|File:Stability region for BDF5.svg|BDF5\n|File:Stability region for BDF6.svg|BDF6}}\n\n==References==\n\n===Citations===\n\n{{reflist}}\n\n=== Referred works ===\n\n* {{Citation | last1=Ascher | first1=U. M. | last2=Petzold | first2=L. R. | author2-link = Linda Petzold| title=Computer Methods for Ordinary Differential Equations and Differential-Algebraic Equations | publisher=SIAM, Philadelphia | year=1998|isbn=0-89871-412-5}}.\n* {{Citation | first1 = Arieh | last1 = Iserles | year = 1996 | title = A First Course in the Numerical Analysis of Differential Equations | publisher = Cambridge University Press | isbn = 978-0-521-55655-2 }}.\n* {{Citation | last1=Süli | first1=Endre | last2=Mayers | first2=David | title=An Introduction to Numerical Analysis | publisher=[[Cambridge University Press]] | isbn=0-521-00794-1 | year=2003}}.\n\n== Further reading ==\n* [http://sundials.wikidot.com/bdf-method BDF Methods] at the SUNDIALS wiki (SUNDIALS is a library implementing BDF methods and similar algorithms).\n\n{{Numerical integrators}}\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Backward Euler method",
      "url": "https://en.wikipedia.org/wiki/Backward_Euler_method",
      "text": "In [[numerical analysis]] and [[scientific computing]], the '''backward Euler method''' (or '''implicit Euler method''') is one of the most basic [[numerical methods for ordinary differential equations|numerical methods for the solution of ordinary differential equations]]. It is similar to the (standard) [[Euler method]], but differs in that it is an [[explicit and implicit methods|implicit method]]. The backward Euler method has error of order one in time.\n\n== Description ==\n\nConsider the [[ordinary differential equation]] \n:<math> \\frac{\\mathrm{d} y}{\\mathrm{d} t} = f(t,y) </math> \nwith initial value <math> y(t_0) = y_0. </math> Here the function <math>f</math> and the initial data <math>t_0</math> and <math>y_0</math> are known; the function <math>y</math> depends on the real variable <math>t</math> and is unknown. A numerical method produces a sequence <math> y_0, y_1, y_2, \\ldots </math> such that <math> y_k </math> approximates <math> y(t_0+kh) </math>, where <math> h </math> is called the step size.\n\nThe backward Euler method computes the approximations using\n:<math> y_{k+1} = y_k + h f(t_{k+1}, y_{k+1}). </math> <ref>{{harvnb|Butcher|2003|p=57}}</ref>\nThis differs from the (forward) Euler method in that the latter uses <math> f(t_k, y_k) </math> in place of <math>f(t_{k+1}, y_{k+1})</math>.\n\nThe backward Euler method is an implicit method: the new approximation <math> y_{k+1} </math> appears on both sides of the equation, and thus the method needs to solve an algebraic equation for the unknown <math> y_{k+1} </math>. For non-[[Stiff equation|stiff]] problems, this can be done with [[fixed-point iteration]]:\n:<math> y_{k+1}^{[0]} = y_k, \\quad y_{k+1}^{[i+1]} = y_k + h f(t_{k+1}, y_{k+1}^{[i]}). </math>\nIf this sequence converges (within a given tolerance), then the method takes its limit as the new approximation\n<math> y_{k+1} </math>.<ref>{{harvnb|Butcher|2003|p=57}}</ref>\n\nAlternatively, one can use (some modification of) the [[Newton's method|Newton–Raphson method]] to solve the algebraic equation.\n\n== Derivation ==\n\nIntegrating the differential equation <math> \\frac{\\mathrm{d} y}{\\mathrm{d} t} = f(t,y) </math> from <math> t_n </math> to <math> t_{n+1} = t_n + h </math> yields\n: <math> y(t_{n+1}) - y(t_n) = \\int_{t_n}^{t_{n+1}} f(t, y(t)) \\,\\mathrm{d}t. </math>\nNow approximate the integral on the right by the right-hand [[rectangle method]] (with one rectangle):\n: <math> y(t_{n+1}) - y(t_n) \\approx h f(t_{n+1}, y(t_{n+1})). </math>\nFinally, use that <math> y_n </math> is supposed to approximate <math> y(t_n) </math> and the formula for the backward Euler method follows.<ref>{{harvnb|Butcher|2003|p=57}}</ref>\n\nThe same reasoning leads to the (standard) Euler method if the left-hand rectangle rule is used instead of the right-hand one.\n\n== Analysis ==\n\n[[File:Stability region for BDF1.svg|thumb|The pink region outside the disk shows the stability region of the backward Euler method.]]\nThe backward Euler method has order one. This means that the [[local truncation error]] (defined as the error made in one step) is <math> O(h^2) </math>, using the [[big O notation]]. The error at a specific time <math> t </math> is <math> O(h) </math>.\n\nThe [[Stiff_equation#Runge%E2%80%93Kutta_methods|region of absolute stability]] for the backward Euler method is the complement in the complex plane of the disk with radius 1 centered at 1, depicted in the figure.<ref>{{harvnb|Butcher|2003|p=70}}</ref> This includes the whole left half of the complex plane, making it suitable for the solution of [[stiff equation]]s.<ref>{{harvnb|Butcher|2003|p=71}}</ref> In fact, the backward Euler method is even [[L-stability|L-stable]].\n\nThe region for a discrete '''stable''' system by Backward Euler Method is a circle with radius 0.5 which is located at (0.5, 0) in the z-plane.<ref>[http://b-ok.xyz/book/600092/2d1ce9], Wai-Kai Chen, Ed., Analog and VLSI Circuits The Circuits and Filters Handbook, 3rd ed. Chicago, USA: CRC Press, 2009.</ref>.\n\n== Extensions and modifications ==\n\nThe backward Euler method is a variant of the (forward) [[Euler method]]. Other variants are the [[semi-implicit Euler method]] and the [[exponential Euler method]].\n\nThe backward Euler method can be seen as a [[Runge–Kutta method]] with one stage, described by the Butcher tableau:\n:<math>\n\\begin{array}{c|c}\n1 & 1 \\\\\n\\hline\n  & 1 \\\\\n\\end{array}\n</math>\n\nThe backward Euler method can also be seen as a [[linear multistep method]] with one step. It is the first method of the family of [[Adams–Moulton method]]s, and also of the family of [[backward differentiation formula]]s.\n\n==See also==\n*[[Crank–Nicolson method]]\n\n== Notes ==\n{{reflist}}\n\n== References ==\n* {{Citation | last1=Butcher | first1=John C. | author1-link=John C. Butcher | title=Numerical Methods for Ordinary Differential Equations | publisher=[[John Wiley & Sons]] | location=New York | isbn=978-0-471-96758-3 | year=2003}}.\n\n{{Numerical integrators}}\n\n[[Category:Numerical differential equations]]\n[[Category:Runge–Kutta methods]]"
    },
    {
      "title": "Beeman's algorithm",
      "url": "https://en.wikipedia.org/wiki/Beeman%27s_algorithm",
      "text": "'''Beeman's algorithm''' is a method for [[numerical quadrature|numerically integrating]] [[ordinary differential equation]]s of order 2, more specifically Newton's equations of motion <math>\\ddot x=A(x)</math>. It was designed to allow high numbers of particles in simulations of molecular dynamics. There is a direct or explicit and an implicit variant of the method. The direct variant was published by Schofield in 1973<ref name=\"schofield73\" /> as a personal communication from Beeman.  This is what is commonly known as '''Beeman's method'''. It is a variant of the [[Verlet integration]] method.  It produces identical positions, but uses a different formula for the velocities. Beeman in 1976 published<ref name=\"beeman76\" /> a class of implicit (predictor–corrector) multi-step methods, where '''Beeman's method''' is the direct variant of the third-order method in this class.\n\n== Equation ==\nThe formula used to compute the positions at time <math>t + \\Delta t</math> in the full predictor-corrector<ref name=\"beeman76\" /> scheme is:\n\n* Predict <math>x(t+\\Delta t)</math> from data at times <math>t\\text{ and }t - \\Delta t</math>\n::<math>\nx(t+\\Delta t)\n= x(t) + v(t) \\Delta t\n  + \\frac{1}{6}\\Bigl( 4 a(t) - a(t - \\Delta t)\\Bigr)\\Delta t^2\n  + O( \\Delta t^4)\n</math>.\n\n* Correct position and velocities at time <math>t + \\Delta t</math> from data at times <math>t\\text{ and }t+\\Delta t</math> by repeated evaluation of the differential equation to get the acceleration <math>a(t+\\Delta t)</math> and of the equations of the implicit system\n::<math>\\begin{align}\nx(t+\\Delta t)\n&= x(t) + v(t) \\Delta t\n   + \\frac{1}{6}\\Bigl(a(t+\\Delta t) + 2a(t)\\Bigr)\\Delta t^2 \n   + O(\\Delta t^4);\\\\\nv(t+\\Delta t)\\Delta t\n&=x(t+\\Delta t)-x(t)\n   + \\frac16 \\Bigl(2a(t+\\Delta t) + a(t)\\Bigr)\\Delta t^2\n   + O(\\Delta t^4);\n\\end{align}</math>\n:In tests it was found that this corrector step needs to be repeated at most twice. The values on the right are the old values of the last iterations, resulting in the new values on the left.\n\nUsing only the predictor formula and the corrector for the velocities one obtains a direct or explicit method<ref name=\"schofield73\" /> which is a variant of the Verlet integration method:<ref name=\"levitt83\" />\n:<math>\\begin{align}\nx(t+\\Delta t)\n&= x(t) + v(t) \\Delta t\n  + \\frac{1}{6}\\Bigl( 4 a(t) - a(t - \\Delta t)\\Bigr)\\Delta t^2\n  + O( \\Delta t^4) \\\\\nv(t+\\Delta t)\n&=v(t)\n   + \\frac16 \\Bigl(2a(t+\\Delta t) + 5a(t)-a(t-\\Delta t)\\Bigr)\\Delta t\n   + O(\\Delta t^3);\n\\end{align}</math>\n\nThis is the variant that is usually understood as ''Beeman's method''.\n\nBeeman<ref name=\"beeman76\" /> also proposed to alternatively replace the velocity update in the last equation by the second order [[Linear multistep method#Adams–Moulton methods|Adams–Moulton method]]:\n\n:<math>\nv(t + \\Delta t)\n  = v(t)\n    + \\frac{1}{12}\\Bigl(5a(t + \\Delta t)  + 8a(t)  - a(t - \\Delta t)\\Bigr)\\Delta t\n    + O(\\Delta t^3)\n</math>\n\nwhere\n\n*<math>t</math> is present time (i.e.: independent variable)\n*<math>\\Delta t</math> is the time step size\n*<math>x(t)</math> is the position at time t\n*<math>v(t)</math> is the velocity at time t\n*<math>a(t)</math> is the acceleration at time t, computed as a function of <math>x(t)</math>\n*the last term is the error term, using the [[big O notation]]\n\n== Predictor–corrector modifications ==\n\nIn systems where the forces are a function of velocity in addition to position, the above equations need to be modified into a predictor–corrector form whereby the velocities at time <math>t + \\Delta t</math> are predicted and the forces calculated, before producing a corrected form of the velocities.\n\nAn example is:\n\n:<math>x(t+\\Delta t) = x(t) + v(t) \\Delta t + \\frac{2}{3}a(t) \\Delta t^2 - \\frac{1}{6} a(t - \\Delta t) \\Delta t^2 + O( \\Delta t^4).</math>\n\nThe velocities at time <math>t = t + \\Delta t</math> are then calculated from the positions.\n\n:<math>v(t + \\Delta t)~\\text{(predicted)} = v(t) + \\frac{3}{2}a(t) \\Delta t - \\frac{1}{2}a(t - \\Delta t) \\Delta t + O(\\Delta t^3).</math>\n\nThe accelerations at time <math>t = t + \\Delta t</math> are then calculated from the positions and predicted velocities.\n\n:<math>v(t + \\Delta t)~\\text{(corrected)} = v(t) + \\frac{5}{12}a(t + \\Delta t) \\Delta t + \\frac{2}{3}a(t) \\Delta t - \\frac{1}{12}a(t - \\Delta t) \\Delta t + O(\\Delta t^3).</math>\n\n== Error term ==\nAs shown above, the local error term is <math>O(\\Delta t^4)</math> for position and <math>O(\\Delta t^3)</math> velocity, resulting in a global error of <math>O(\\Delta t^3)</math>.  In comparison, Verlet is <math>O(\\Delta t^2)</math> for position and velocity. In exchange for greater accuracy, Beeman's algorithm is moderately computationally more expensive.\n\n== Memory requirements ==\nThe simulation must keep track of position, velocity, acceleration and previous acceleration vectors per particle (though some clever workarounds for storing the previous acceleration vector are possible), keeping its memory requirements on par with velocity Verlet and slightly more expensive than the original Verlet method.\n\n== References ==\n<references>\n<ref name=\"beeman76\">\n{{Citation | last = Beeman | first = David\n| title=Some multistep methods for use in molecular dynamics calculations\n| periodical=Journal of Computational Physics\n| volume=20 | issue=2 | pages=130–139 | year=1976\n| doi=10.1016/0021-9991(76)90059-0}}\n</ref>\n\n<ref name=\"schofield73\">\n{{Citation | last = Schofield | first = P.\n| title = Computer simulation studies of the liquid state\n| journal = Computer Physics Communications\n| volume = 5 |issue = 1| pages = 17–23| year = 1973\n| doi = 10.1016/0010-4655(73)90004-0\n}}\n</ref>\n<ref name=\"levitt83\">\n{{Citation | first1 = Michael| last1 = Levitt\n| first2 = Hagai |last2 = Meirovitch\n| first3 = R. | last3 = Huber\n| title = Integrating the equations of motion\n| journal = Journal of Molecular Biology\n| volume = 168 | issue = 3 | pages = 617–620| year = 1983\n| doi = 10.1016/S0022-2836(83)80305-2 | pmid=6193281\n}}\n</ref>\n</references>\n\n* {{Citation|last=Sadus|first=Richard J.|year=2002|title=Molecular Theory of Fluids: Theory, Algorithms and Object-Orientation|publisher=Elsevier|isbn=0-444-51082-6|page=231}}\n\n{{Numerical integrators}}\n\n{{DEFAULTSORT:Beeman's Algorithm}}\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Boundary element method",
      "url": "https://en.wikipedia.org/wiki/Boundary_element_method",
      "text": "{{Use American English|date=January 2019}}\n{{Short description|Method of solving linear partial differential equations}}\nThe '''boundary element method''' ('''BEM''') is a numerical computational method of solving linear [[partial differential equations]] which have been formulated as [[integral equation]]s (i.e. in ''boundary integral'' form).   including [[fluid mechanics]], [[acoustics]], [[electromagnetics]] ('''Method of Moments'''),<ref> In electromagnetics, the more traditional term \"method of moments\" is often used, though not always, as a synonymous of \"boundary element method\": see {{harv|Walton|2008}} for further information on the subject.</ref> [[fracture mechanics]],<ref>The boundary element method is well suited for analyzing cracks in solids. There are several boundary element approaches for crack problems. One such approach is to formulate the conditions on the cracks in terms of hypersingular boundary integral equations, see {{harv|Ang|2013}}.</ref> and [[contact mechanics]].<ref>{{Cite journal|last=Pohrt|first=R.|last2=Li|first2=Q.|date=2014-10-01|title=Complete boundary element formulation for normal and tangential contact problems|journal=Physical Mesomechanics|language=en|volume=17|issue=4|pages=334–340|doi=10.1134/S1029959914040109|issn=1029-9599}}</ref><ref>{{Cite web|url=http://www.tribonet.org/contact-pressure-for-rough-surfaces-a-tutorial/|title=BEM Based Contact Pressure Calculation Tutorial|last=|first=|date=|website=www.tribonet.org|access-date=}}</ref>\n\n==Mathematical basis==\nThe integral equation may be regarded as an exact solution of the governing partial differential equation. The boundary element method attempts to use the given [[boundary condition]]s to fit boundary values into the integral equation, rather than values throughout the space defined by a partial differential equation. Once this is done, in the post-processing stage, the integral equation can then be used again to calculate numerically the solution directly at any desired point in the interior of the solution domain.\n\nBEM is applicable to problems for which [[Green's function]]s can be calculated.  These usually involve fields in [[linear]] [[Homogeneity (physics)|homogeneous]] media.  This places considerable restrictions on the range and generality of problems to which  boundary elements can usefully be applied.  Nonlinearities can be included in the formulation, although they will generally introduce volume integrals which then require the volume to be [[discretize|discretise]]d before solution can be attempted, removing one of the most often cited advantages of BEM{{Citation needed|date=May 2016}}. A useful technique for treating the volume integral without discretising the volume is the [[dual-reciprocity method]]. The technique approximates part of the integrand using [[radial basis function]]s (local interpolating functions) and converts the volume integral into boundary integral after collocating at selected points distributed throughout the volume domain (including the boundary). In the dual-reciprocity BEM, although there is no need to discretize the volume into meshes, unknowns at chosen points inside the solution domain are involved in the linear algebraic equations approximating the problem being considered.\n\nThe Green's function elements connecting pairs of source and field patches defined by the mesh form a matrix, which is solved numerically.  Unless the Green's function is well behaved, at least for pairs of patches near each other, the Green's function must be integrated over either or both the source patch and the field patch.  The form of the method in which the integrals over the source and field patches are the same is called \"[[Galerkin's method]]\".  Galerkin's method is the obvious approach for problems which are symmetrical with respect to exchanging the source and field points.  In frequency domain electromagnetics, this is assured by [[reciprocity (electromagnetism)|electromagnetic reciprocity]].  The cost of computation involved in naive Galerkin implementations is typically quite severe. One must loop over elements twice (so we get n<sup>2</sup> passes through) and for each pair of elements we loop through [[Gauss quadrature|Gauss point]]s in the elements producing a multiplicative factor proportional to the number of Gauss-points squared.  Also, the function evaluations required are typically quite expensive, involving trigonometric/hyperbolic function calls.  Nonetheless, the principal source of the computational cost is this double-loop over elements producing a fully populated matrix.\n\nThe [[Green's function|Green's functions]], or [[Fundamental solution|fundamental solutions]], are often problematic to integrate as they are based on a solution of the system equations subject to a singularity load (e.g. the electrical field arising from a point charge).  Integrating such singular fields is not easy.  For simple element geometries (e.g. planar triangles) analytical integration can be used.  For more general elements, it is possible to design purely numerical schemes that adapt to the singularity, but at great computational cost.  Of course, when source point and target element (where the integration is done) are far-apart, the local gradient surrounding the point need not be quantified exactly and it becomes possible to integrate easily due to the smooth decay of the fundamental solution.  It is this feature that is typically employed in schemes designed to accelerate boundary element problem calculations.\n\n==Comparison to other methods==\nThe boundary element method is often more efficient than other methods, including finite elements, in terms of computational resources for problems where there is a small surface/volume ratio.<ref>See {{harv|Katsikadelis|2002}}.</ref> Conceptually, it works by constructing a \"[[mesh]]\" over the modelled surface.  However, for many problems boundary element methods are significantly less efficient than volume-discretisation methods ([[finite element method]], [[finite difference method]], [[finite volume method]]). A good example of application of the boundary element method is efficient calculation of [[natural frequencies]] of [[Slosh dynamics|liquid sloshing]] in tanks.<ref>{{Cite journal|last=Kolaei|first=Amir|last2=Rakheja|first2=Subhash|last3=Richard|first3=Marc J.|date=2015-09-01|title=Three-dimensional dynamic liquid slosh in partially-filled horizontal tanks subject to simultaneous longitudinal and lateral excitations|url=http://www.sciencedirect.com/science/article/pii/S0997754615000746|journal=European Journal of Mechanics B|volume=53|pages=251–263|doi=10.1016/j.euromechflu.2015.06.001|bibcode = 2015EJMF...53..251K }}</ref><ref>{{Cite journal|last=Kolaei|first=Amir|last2=Rakheja|first2=Subhash|last3=Richard|first3=Marc J.|date=2015-01-31|title=A coupled multimodal and boundary-element method for analysis of anti-slosh effectiveness of partial baffles in a partly-filled container|url=http://www.sciencedirect.com/science/article/pii/S0045793014004186|journal=Computers & Fluids|volume=107|pages=43–58|doi=10.1016/j.compfluid.2014.10.013}}</ref><ref>{{Cite book|last=Kolaei|first=Amir|last2=Rakheja|first2=Subhash|last3=Richard|first3=Marc J.|date=2014-11-14|pages=V04AT04A067|doi=10.1115/IMECE2014-37271|title=Volume 4A: Dynamics, Vibration, and Control|isbn=978-0-7918-4647-6}}</ref> Boundary element method is one of the most effective methods for numerical simulation of contact problems,<ref>{{Cite book|url=https://www.springer.com/us/book/9783662530801|title=Contact Mechanics and Friction - Physical Principles and (Chapter 19)|last=Popov|first=Valentin|publisher=Springer|year=2017|isbn=9783662530801|location=|pages=337–341|language=en}}</ref> in particular for simulation of adhesive contacts.<ref>{{Cite journal|last=Pohrt|first=Roman|last2=Popov|first2=Valentin L.|date=2015-04-09|title=Adhesive contact simulation of elastic solids using local mesh-dependent detachment criterion in boundary elements method|url=http://casopisi.junis.ni.ac.rs/index.php/FUMechEng/article/view/764|journal=Facta Universitatis, Series: Mechanical Engineering|language=en|volume=13|issue=1|pages=3–10|issn=|via=}}</ref>\n\nBoundary element formulations typically give rise to fully populated matrices.  This means that the storage requirements and computational time will tend to grow according to the square of the problem size.  By contrast, finite element matrices are typically banded (elements are only locally connected) and the storage requirements for the system matrices typically grow quite linearly with the problem size.  Compression techniques (e.g. multipole expansions or adaptive cross approximation/[[hierarchical matrix|hierarchical matrices]]) can be used to ameliorate these problems, though at the cost of added complexity and with a success-rate that depends heavily on the nature of the problem being solved and the geometry involved.\n\n==See also==\n* [[Analytic element method]]\n* [[CN-MoM|Combined Node Method of Moments]]\n* [[Computational electromagnetics]]\n* [[Electromagnetic modeling]]\n* [[Meshfree methods]]\n* [[Immersed boundary method]]\n* [[Stretched grid method]]\n\n== References ==\n{{Reflist}}\n\n==Bibliography==\n*{{Citation\n | last =Ang\n | first =Whye-Teong\n | author-link =\n | title =A Beginner's Course in Boundary Element Methods\n | place =Boca Raton, Fl\n | publisher =[[Universal Publishers (United States)|Universal Publishers]]\n | series =\n | volume =\n | year =2007\n | month=\n | edition =\n | chapter =\n | url =\n | page =\n | pages =\n | language =\n | doi =\n | id =\n | isbn =978-1-58112-974-8\n | mr =\n | zbl =\n}}.\n*{{Citation\n | last =Ang\n | first =Whye-Teong\n | author-link =\n | title =Hypersingular Integral Equations in Fracture Analysis\n | place =Oxford\n | publisher =[[Woodhead Publishing]]\n | year =2013\n | pages =\n | language =\n | url =https://books.google.com/books?id=rDGTlAEACAAJ\n | doi =\n | id =\n | isbn =978-0-85709-479-7\n | mr =\n | zbl =\n}}.\n*{{Citation\n | last =Banerjee\n | first =Prasanta Kumar\n | author-link =\n | title =The Boundary Element Methods in Engineering\n | place = London, etc.\n | publisher =[[McGraw-Hill]]\n | series =\n | volume =\n | year =1994\n | edition =2nd\n | pages =\n | language =\n | url =\n | doi =\n | id =\n | isbn =978-0-07-707769-3\n | mr =\n | zbl =\n}}.\n*{{Citation\n | last = Beer\n | first =Gernot\n | author-link =\n | last2 = Smith\n | first2 =Ian\n | author2-link =\n | last3 = Duenser\n | first3 = Christian\n | author3-link =\n | title =The Boundary Element Method with Programming: For Engineers and Scientists\n | place =Berlin – Heidelberg – New York\n | publisher =[[Springer-Verlag]]\n | pages =XIV+494\n | url =\n | doi =\n | id =\n | isbn =978-3-211-71574-1\n | mr =\n | zbl =\n}}\n*{{Citation\n  | last = Cheng\n  | first = Alexander H.-D.\n  | author-link =\n  | last2 = Cheng\n  | first2 = Daisy T.\n  | author2-link =\n  | title = Heritage and early history of the boundary element method\n  | journal = Engineering Analysis with Boundary Elements\n  | volume = 29\n  | issue = 3\n  | pages = 268–302\n  | year = 2005\n  | doi = 10.1016/j.enganabound.2004.12.001\n  | zbl = 1182.65005\n}}, available also [http://www.boundaryelements.com/images/stories/HistoryofBEM%20ChengandCheng.pdf here].\n*{{Citation\n | last =Gibson\n | first = Walton C\n | author-link =\n | title =The Method of Moments in Electromagnetics\n | place =Boca Raton, Florida\n | publisher =[[Chapman & Hall]]/[[CRC Press]]\n | year =2008\n | pages =xv+272\n | url =\n | isbn =978-1-4200-6145-1\n | mr =2503144\n | zbl =1175.78002\n}}.\n*{{Citation\n | last =Katsikadelis\n | first =John T.\n | author-link =\n | title =Boundary Elements Theory and Applications\n | place =Amsterdam\n | publisher =[[Elsevier]]\n | year =2002\n | pages =XIV+336\n | language =\n | url =\n | doi =\n | id =\n | isbn =978-0-080-44107-8\n | mr =\n | zbl =\n}}.\n*{{Citation\n | last =Wrobel\n | first =L. C.\n | author-link =\n | last2 =Aliabadi\n | first2 =M. H.\n | author2-link =\n | title =The Boundary Element Method\n | place =New York\n | publisher =[[John Wiley & Sons]]\n | year =2002\n | pages =1066\n | url =\n | doi =\n | id =\n | isbn =978-0-470-84139-6\n | mr =\n | zbl =\n}} (in two volumes).\n\n==Further reading==\n* {{cite book|author1=Constanda, Christian|author2=Doty, Dale|author3=Hamill, William|year=2016|title=Boundary Integral Equation Methods and Numerical Solutions: Thin Plates on an Elastic Foundation\n|location=New York|publisher=Springer|isbn=978-3-319-26307-6}}\n\n==External links==\n*[http://www.boundaryelements.com/index.php An Online Resource for Boundary Elements]\n*[http://george-and-bem.cege.umn.edu What lies beneath the surface? A guide to the Boundary Element Method and Green's functions for the students and professionals]\n*[http://www.ntu.edu.sg/home/mwtang/bem2011.html An introductory BEM course (with a chapter on Green's functions)]\n*[http://www.ntu.edu.sg/home/mwtang/anghyperbook.html Boundary elements for plane crack problems]\n*[http://www.cvel.clemson.edu/modeling/ Electromagnetic Modeling web site at Clemson University] (includes list of currently available software)\n*[http://www.conceptanalyst.com Concept Analyst Boundary Element Analysis software]\n*[https://archive.is/20030314193630/http://www.integratedsoft.com/papers/research/hybrid/ Klimpke, Bruce ''A Hybrid Magnetic Field Solver Using a Combined Finite Element/Boundary Element Field Solver'', U.K. Magnetics Society Conference, 2003] which compares FEM and BEM methods as well as hybrid approaches\n\n===Free software===\n*[http://www.bembel.eu Bembel] A 3D, isogeometric, higher-order, open-source BEM for Laplace, Helmholtz and Maxwell problems utilizing a fast multipole method for compression and reduction of computational complexity\n*[http://www.boundary-element-method.com boundary-element-method.com] An open-source BEM software for solving acoustics / Helmholtz and Laplace problems\n*[http://sourceforge.net/projects/puma-em/ Puma-EM] An open-source and high-performance Method of Moments / Multilevel Fast Multipole Method parallel program\n*[http://acousto.sourceforge.net/ AcouSTO] Acoustics Simulation TOol, a free and open-source parallel BEM solver for the Kirchhoff-Helmholtz Integral Equation (KHIE)\n*[http://www.yijunliu.com/Software/ FastBEM] Free fast multipole boundary element programs for solving 2D/3D potential, elasticity, Stokes flow and acoustic problems\n*[http://www.parafem.org.uk/ ParaFEM] Includes the free and open-source parallel BEM solver for elasticity problems described in Gernot Beer, Ian Smith, Christian Duenser, ''The Boundary Element Method with Programming: For Engineers and Scientists'', Springer, {{ISBN|978-3-211-71574-1}} (2008)\n*[http://www.sam.math.ethz.ch/betl Boundary Element Template Library (BETL)] A general purpose C++ software library for the discretisation of boundary integral operators\n*[http://lheea.ec-nantes.fr/doku.php/emo/nemoh/start?&#nemoh Nemoh] An open source hydrodynamics BEM software dedicated to the computation of first-order wave loads on offshore structures (added mass, radiation damping, diffraction forces)\n*[http://www.bempp.org BEM++], An open-source BEM software for 3D Laplace, Helmholtz and Maxwell problems\n*[http://physik.uni-graz.at/mnpbem/ MNPBEM], An open-source Matlab toolbox to solve Maxwell's equations for arbitrarily shaped nanostructures\n*[http://www.tribonet.org/cmdownloads/tribology-simulator/ Contact Mechanics and Tribology Simulator], Free, BEM based software\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Boundary Element Method}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]\n[[Category:Computational electromagnetics]]"
    },
    {
      "title": "Cash–Karp method",
      "url": "https://en.wikipedia.org/wiki/Cash%E2%80%93Karp_method",
      "text": "In [[numerical analysis]], the '''Cash–Karp method''' is a method for solving [[ordinary differential equations]] (ODEs). It was proposed by Professor Jeff R. Cash <ref>[http://www3.imperial.ac.uk/people/j.cash Jeff R. Cash, Professor of Numerical Analysis, Imperial College London]</ref> from [[Imperial College London]] and Alan H. Karp from [[IBM]] Scientific Center. The method is a member of the [[Runge–Kutta]] family of ODE solvers. More specifically, it uses six function evaluations to calculate fourth- and fifth-order accurate solutions. The difference between these solutions is then taken to be the error of the (fourth order) solution. This error estimate is very convenient for [[adaptive stepsize]] integration algorithms. Other similar integration methods are [[Fehlberg]] (RKF) and [[Dormand–Prince]] (RKDP).\n\nThe [[Butcher tableau]] is:\n{| cellpadding=3px cellspacing=0px\n|width=\"20px\"| || style=\"border-right:1px solid;\" | 0\n|-\n||| style=\"border-right:1px solid;\" | 1/5 || 1/5\n|-\n||| style=\"border-right:1px solid;\" | 3/10 || 3/40 || 9/40\n|-\n||| style=\"border-right:1px solid;\" | 3/5 || 3/10 || −9/10 || 6/5\n|-\n||| style=\"border-right:1px solid;\" | 1 || −11/54 || 5/2 || −70/27 || 35/27\n|-\n||| style=\"border-right:1px solid; border-bottom:1px solid;\" | 7/8 || style=\"border-bottom:1px solid;\" | 1631/55296 || style=\"border-bottom:1px solid;\" | 175/512 || style=\"border-bottom:1px solid;\" | 575/13824 || style=\"border-bottom:1px solid;\" | 44275/110592 || style=\"border-bottom:1px solid;\" | 253/4096 || style=\"border-bottom:1px solid;\" |\n|-\n||| style=\"border-right:1px solid;\" | || 37/378 || 0 || 250/621 || 125/594 || 0 || 512/1771\n|-\n||| style=\"border-right:1px solid;\" | || 2825/27648 || 0 || 18575/48384 || 13525/55296 || 277/14336 || 1/4\n|}\n\nThe first row of ''b'' coefficients gives the fifth-order accurate solution, and the second row gives the fourth order solution.\n\n== See also ==\n* [[Runge–Kutta methods#Adaptive Runge–Kutta methods|Adaptive Runge-Kutta methods]]\n* [[List of Runge-Kutta methods]]\n\n== Notes ==\n\n{{Reflist}}\n\n==References ==\n* J. R. Cash, A. H. Karp. \"[http://www.elegio.it/mc2/rk/doc/p201-cash-karp.pdf A variable order Runge-Kutta method for initial value problems with rapidly varying right-hand sides]\", ''ACM Transactions on Mathematical Software'' '''16''': 201-222, 1990. {{doi|10.1145/79505.79507}}.\n\n{{DEFAULTSORT:Cash-Karp Method}}\n[[Category:Numerical differential equations]]\n[[Category:Runge–Kutta methods]]"
    },
    {
      "title": "Cell lists",
      "url": "https://en.wikipedia.org/wiki/Cell_lists",
      "text": "'''Cell lists''' (also sometimes referred to as '''cell linked-lists''') are a tool for finding all atom pairs within a given cut-off distance of each other in [[molecular dynamics]] simulations. These pairs are needed to compute the short-range non-bonded interactions in a system, such as [[Van der Waals force]]s or the short-range part of the electrostatic interaction when using [[Ewald summation]].\n\n==Algorithm==\n[[Image:CellLists.png|thumb|right|200px|The pairwise interactions for a single particle can be computed by a) computing the interaction to all other particles or b) by dividing the domain into ''cells'' with an edge length of at least the cut-off radius of the interaction potential and computing the interaction between the particle and all particles in the same (red) and in the adjacent (green) cells.]]\nCell lists work by subdividing the simulation domain into cells with an edge length greater than or equal to the cut-off radius of the interaction to be computed. The particles are sorted into these cells and the interactions are computed between particles in the same or neighbouring cells.\n\nIn its most basic form, the non-bonded interactions for a cut-off distance <math>r_c</math> are computed as follows:\n\n:'''for all''' neighbouring cell pairs <math>(C_\\alpha, C_\\beta)</math> '''do'''\n::'''for all''' <math>p_\\alpha \\in C_\\alpha</math> '''do'''\n:::'''for all''' <math>p_\\beta \\in C_\\beta</math> '''do'''\n::::<math>r^2 = \\| \\mathbf x[p_\\alpha] - \\mathbf x[p_\\beta] \\|_2^2</math>\n::::'''if''' <math>r^2 \\le r_c^2</math> '''then'''\n:::::Compute the interaction between <math>p_\\alpha</math> and <math>p_\\beta</math>.\n::::'''end if'''\n:::'''end for'''\n::'''end for'''\n:'''end for'''\n\nSince the cell length is at least <math>r_c</math> in all dimensions, no particles within <math>r_c</math> of each other can be missed.\n\nGiven a simulation with <math>N</math> particles with a homogeneous particle density, the number of cells <math>m</math> is proportional to <math>N</math> and inversely proportional to the cut-off radius (i.e. if <math>N</math> increases, so does the number of cells). The average number of particles per cell <math>\\overline{c} = N/m</math> therefore does not depend on the total number of particles. The cost of interacting two cells is in <math>\\mathcal O(\\overline{c}^2)</math>. The number of cell pairs is proportional to the number of cells which is again proportional to the number of particles <math>N</math>. The total cost of finding all pairwise distances within a given cut-off is in <math>\\mathcal O(Nc) \\in \\mathcal O(N)</math>, which is significantly better than computing the <math>\\mathcal O(N^2)</math> pairwise distances naively.\n\n==Periodic boundary conditions==\nIn most simulations, [[periodic boundary conditions]] are used to avoid imposing artificial boundary conditions. Using cell lists, these boundaries can be implemented in two ways.\n\n===Ghost cells===\n[[Image:CellLists Ghosts.png|thumb|right|250px|Periodic boundary conditions can be simulated by wrapping the simulation box in an additional layer of cells (shaded orange) containing periodic copies of the boundary cells (blue particles).]]\nIn the ghost cells approach, the simulation box is wrapped in an additional layer of cells. These cells contain periodically wrapped copies of the corresponding simulation cells inside the domain.\n\nAlthough the data—and usually also the computational cost—is doubled for interactions over the periodic boundary, this approach has the advantage of being straightforward to implement and very easy to parallelize, since cells will only interact with their geographical neighbours.\n\n===Periodic wrapping===\nInstead of creating ghost cells, cell pairs that interact over a periodic boundary can also use a periodic correction vector <math>\\mathbf q_{\\alpha\\beta}</math>. This vector, which can be stored or computed for every cell pair <math>(C_\\alpha,C_\\beta)</math>, contains the correction which needs to be applied to \"wrap\" one cell around the domain to neighbour the other. The pairwise distance between two particles <math>p_\\alpha \\in C_\\alpha</math> and <math>p_\\beta \\in C_\\beta</math> is then computed as\n\n:<math>r^2 = \\| \\mathbf x[p_\\alpha] - \\mathbf x[p_\\beta] - \\mathbf q_{\\alpha\\beta} \\|^2_2</math>.\n\nThis approach, although more efficient than using ghost cells, is less straightforward to implement (the cell pairs need to be identified over the periodic boundaries and the vector <math>\\mathbf q_{\\alpha\\beta}</math> needs to be computed/stored).\n\n==Improvements==\nDespite reducing the computational cost of finding all pairs within a given cut-off distance from <math>\\mathcal O(N^2)</math> to <math>\\mathcal O(N)</math>, the cell list algorithm listed above still has some inefficiencies.\n\nConsider a computational cell in three dimensions with edge length equal to the cut-off radius <math>r_c</math>. The pairwise distance between all particles in the cell and in one of the neighbouring cells is computed. The cell has 26 neighbours: 6 sharing a common face, 12 sharing a common edge and 8 sharing a common corner. Of all the pairwise distances computed, only about 16% will actually be less than or equal to <math>r_c</math>. In other words, 84% of all pairwise distance computations are spurious.\n\nOne way of overcoming this inefficiency is to partition the domain into cells of edge length smaller than <math>r_c</math>. The pairwise interactions are then not just computed between neighboring cells, but between all cells within <math>r_c</math> of each other (first suggested in <ref>{{cite book| first=M. P. | last=Allen |author2=D. J. Tildesley | title=Computer Simulation of Liquids | publisher=Clarendon Press | location=Oxford | year=1987}}</ref> and implemented and analysed in <ref>{{cite journal | last=Mattson | first=W. |author2=B. M. Rice | title=Near-neighbor calculations using a modified cell-linked list method | journal=Computer Physics Communications | year=1999 | volume=119 | issue=2-3 | pages=135 | doi=10.1016/S0010-4655(98)00203-3 |bibcode = 1999CoPhC.119..135M }}</ref><ref>{{cite journal | last=Yao | first=Z. |author2=Wang, J.-S. |author3=Liu, G.-R. |author4= Cheng, M  | title=Improved neighbor list algorithm in molecular simulations using cell decomposition and data sorting method | journal=Computer Physics Communications | year=2004 | volume=161 | pages=27 | doi=10.1016/j.cpc.2004.04.004 |arxiv = physics/0311055 |bibcode = 2004CoPhC.161...27Y }}</ref> and <ref>{{cite journal| last=Heinz | first=T. N. |author2=Hünenberger, P. H. | title=A fast pairlist-construction algorithm for molecular simulations under periodic boundary conditions | journal=Journal of Computational Chemistry | year=2004 | volume=25 | pages=1474–86 | doi=10.1002/jcc.20071| pmid=15224391| issue=12}}</ref>). This approach can be taken to the limit wherein each cell holds at most one single particle, therefore reducing the number of spurious pairwise distance evaluations to zero. This gain in efficiency, however, is quickly offset by the number of cells <math>C_\\beta</math> that need to be inspected for every interaction with a cell <math>C_\\alpha</math>, which, for example in three dimensions, grows cubically with the inverse of the cell edge length. Setting the edge length to <math>r_c/2</math>, however, already reduces the number of spurious distance evaluations to 63%.\n\nAnother approach is outlined and tested in Gonnet,<ref>{{cite journal| first=Pedro | last=Gonnet | title=A Simple Algorithm to Accelerate the Computation of Non-Bonded Interactions in Cell-Based Molecular Dynamics Simulations | journal=Journal of Computational Chemistry | volume=28 | issue=2 | pages=570–573 | doi=10.1002/jcc.20563 | year=2007| pmid=17183605 }}</ref> in which the particles are first sorted along the axis connecting the cell centers. This approach generates only about 40% spurious pairwise distance computations, yet carries an additional cost due to sorting the particles.\n\n==See also==\n* [[Verlet list]]\n\n==References==\n<references />\n\n[[Category:Molecular dynamics]]\n[[Category:Computational chemistry]]\n[[Category:Molecular physics]]\n[[Category:Computational physics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Characteristic mode analysis",
      "url": "https://en.wikipedia.org/wiki/Characteristic_mode_analysis",
      "text": "'''Characteristic modes (CM)''' form a set of functions which, under specific boundary conditions, diagonalizes operator relating [[Electric field|field]] and induced [[Electric current|sources]]. Under certain conditions, the set of the CM is unique and complete (at least theoretically) and thereby capable of describing the behavior of a studied object in full.\n\nThis article deals with characteristic mode decomposition in [[electromagnetics]], a domain in which the CM theory has originally been proposed.\n\n== Background ==\n\nCM decomposition was originally introduced as set of modes diagonalizing a scattering matrix. <ref name=\"Garbacz1\" /><ref name=\"Garbacz2\" /> The theory has, subsequently, been generalized by Harrington and Mautz for antennas.<ref name=\"HarringtonMautz1\" /><ref name=\"HarringtonMautz2\" /> Harrington, Mautz and their students also successively developed several other extensions of the theory.<ref name=\"ChangHarrington1\" /><ref name=\"HarringtonMautz3\" /><ref name=\"HarringtonMautzEtAl1\" /><ref name=\"Hajj1\" /> Even though some precursors<ref name=\"Montgomery1\" /> were published back in the late 1940s, the full potential of CM has remained unrecognized for an additional 40 years. The capabilities of CM were revisited<ref name=\"CabedoEtAl1\" /> in 2007 and, since then, interest in CM has dramatically increased. The subsequent boom of CM theory is reflected by the number of prominent publications and applications.\n\n== Definition ==\n\nFor the simplicity, only the original form of the CM — formulated for [[Perfect Electric Conductor|perfectly electrically conducting]] (PEC) bodies in [[Vacuum|free space]] — will be treated in this article. The electromagnetic quantities will solely be represented as Fourier's images in [[frequency domain]]. [[Lorenz gauge|Lorenz's gauge]] is used.\n[[File:CMoriginalStructure.png|300px|thumb|right|Example of a scatterer <math>\\Omega</math> composed of a perfect electric conductor.]]\n\nThe scattering of an [[electromagnetic wave]] on a PEC body is represented via a boundary condition on the PEC body, namely\n\n:<math> \\boldsymbol{\\hat{n}} \\times \\boldsymbol{E}^\\mathrm{i} = -\\boldsymbol{\\hat{n}} \\times \\boldsymbol{E}^\\mathrm{s}, </math>\n\nwith <math>\\boldsymbol{\\hat{n}}</math> representing [[Normal vector|unitary normal]] to the PEC surface, <math>\\boldsymbol{E}^\\mathrm{i}</math> representing incident electric field intensity, and <math>\\boldsymbol{E}^\\mathrm{s}</math> representing scattered [[electric field intensity]] defined as\n\n:<math>\\boldsymbol{E}^\\mathrm{s} = -\\mathrm{j}\\omega\\boldsymbol{A} - \\nabla\\varphi, </math>\n\nwith <math>\\mathrm{j}</math> being [[imaginary unit]], <math>\\omega</math> being [[angular frequency]], <math>\\boldsymbol{A}</math> being [[vector potential]]\n\n:<math> \\boldsymbol{A} \\left(\\boldsymbol{r}\\right) = \\mu_0 \\int\\limits_\\Omega \\boldsymbol{J} \\left(\\boldsymbol{r}'\\right) G \\left(\\boldsymbol{r}, \\boldsymbol{r}'\\right) \\, \\mathrm{d}S, </math>\n\n<math>\\mu_0</math> being [[vacuum permeability]], <math>\\varphi</math> being [[scalar potential]]\n\n:<math> \\varphi \\left(\\boldsymbol{r}\\right) = - \\frac{1}{\\mathrm{j}\\omega\\epsilon_0} \\int\\limits_\\Omega \\nabla\\cdot\\boldsymbol{J} \\left(\\boldsymbol{r}'\\right) G \\left(\\boldsymbol{r}, \\boldsymbol{r}'\\right) \\, \\mathrm{d}S, </math>\n\n<math>\\epsilon_0</math> being [[vacuum permittivity]], <math>G \\left(\\boldsymbol{r},\\boldsymbol{r}'\\right)</math> being scalar [[Green's function]]\n\n:<math> G \\left(\\boldsymbol{r},\\boldsymbol{r}'\\right) = \\frac{\\mathrm{e}^{-\\mathrm{j}k\\left|\\boldsymbol{r} - \\boldsymbol{r}'\\right|}}{4\\pi \\left|\\boldsymbol{r} - \\boldsymbol{r}'\\right|} </math>\n\nand <math>k</math> being [[wavenumber]]. The integro-differential operator <math>\\boldsymbol{\\hat{n}} \\times \\boldsymbol{E}^\\mathrm{s} \\left(\\boldsymbol{J} \\right)</math> is the one to be diagonalized via characteristic modes.\n\nThe governing equation of the CM decomposition is\n:<math> \\mathcal{X} \\left(\\boldsymbol{J}_n\\right) = \\lambda_n \\mathcal{R} \\left(\\boldsymbol{J}_n\\right) \\qquad\\mathrm{(1)} </math>\n\nwith <math>\\mathcal{R}</math> and <math>\\mathcal{X}</math> being real and imaginary parts of impedance operator <math>\\mathcal{Z}</math>, respectively, defined as\n\n:<math> \\mathcal{Z} \\left(\\boldsymbol{J}\\right) = \\mathcal{R} \\left(\\boldsymbol{J}\\right) + \\mathrm{j} \\mathcal{X} \\left(\\boldsymbol{J}\\right) = \\boldsymbol{\\hat{n}} \\times \\boldsymbol{\\hat{n}} \\times \\boldsymbol{E}^\\mathrm{s} \\left(\\boldsymbol{J}\\right). \\qquad\\mathrm{(2)} </math>\n\nThe outcome of (1) is a set of characteristic modes <math>\\left\\{\\boldsymbol{J}_n\\right\\}</math>, <math>n\\in \\left\\{1,2,\\dots\\right\\}</math>, accompanied by associated characteristic numbers <math>\\left\\{\\lambda_n\\right\\}</math>. Clearly, (1) is a [[generalized eigenvalue problem]], which, however, cannot be analytically solved (except for a few canonical bodies<ref name=\"CapekEtAl1\" />). Therefore, the numerical solution described in the following paragraph is commonly employed.\n\n== Matrix formulation ==\n\nDiscretization <math>\\mathcal{D}</math> of the body of the scatterer <math>\\Omega</math> into <math>M</math> subdomains as <math>\\Omega^M = \\mathcal{D}\\left(\\Omega\\right)</math> and using a set of linearly independent piece-wise continuous functions <math>\\left\\{\\boldsymbol{\\psi}_n\\right\\}</math>, <math>n\\in\\left\\{1,\\dots,N\\right\\}</math>, allows current density <math>\\boldsymbol{J}</math> to be represented as\n[[File:CMdiscretizedStructure.png|300px|thumb|right|Example of a scatterer's triangular (Delaunay) discretization <math>\\Omega^M</math>.]]\n\n:<math> \\boldsymbol{J} \\left(\\boldsymbol{r}\\right) \\approx \\sum\\limits_{n=1}^N I_n \\boldsymbol{\\psi}_n \\left(\\boldsymbol{r}\\right) </math>\n\nand by applying the [[Galerkin method]], the impedance operator (2)\n\n:<math> \\mathbf{Z} = \\mathbf{R} + \\mathrm{j} \\mathbf{X} = \\left[Z_{uv}\\right] = \\left[\\,\\int\\limits_\\Omega \\boldsymbol{\\psi}_u^\\ast \\cdot \\mathcal{Z} \\left(\\boldsymbol{\\psi}_v\\right) \\, \\mathrm{d}S\\right]. </math>\n\nThe eigenvalue problem (1) is then recast into its matrix form\n\n:<math> \\mathbf{X} \\mathbf{I}_n = \\lambda_n \\mathbf{R}\\mathbf{I}_n, </math>\n\nwhich can easily be solved using, e.g., the [[generalized Schur decomposition]] or the [[Arnoldi iteration|implicitly restarted Arnoldi method]] yielding a finite set of expansion coefficients <math>\\left\\{\\mathbf{I}_n\\right\\}</math> and associated characteristic numbers <math>\\left\\{\\lambda_n\\right\\}</math>. The properties of the CM decomposition are investigated below.\n\n[[File:CMmode1.png|thumb|right|300px|The first (dominant) characteristic mode of a shape <math>\\Omega^M</math>.]]\n[[File:CMmode2.png|thumb|right|300px|The second characteristic mode of a shape <math>\\Omega^M</math>.]]\n\n== Properties ==\n\nThe properties of CM decomposition are demonstrated in its matrix form.\n\nFirst, recall that the [[Bilinear form|bilinear forms]] \n\n:<math> P_\\mathrm{r} \\approx \\frac{1}{2} \\mathbf{I}^\\mathrm{H} \\mathbf{R} \\mathbf{I} \\geq 0 </math>\n\nand\n\n:<math> 2\\omega\\left(W_\\mathrm{m} - W_\\mathrm{e}\\right) \\approx \\frac{1}{2} \\mathbf{I}^\\mathrm{H} \\mathbf{X} \\mathbf{I}, </math>\n\nwhere superscript <math>^\\mathrm{H}</math> denotes the [[Hermitian transpose]] and where <math>\\mathbf{I}</math> represents an arbitrary surface current distribution, correspond to the radiated power and the reactive net power,<ref name=\"Harrington1\" /> respectively. The following properties can then be easily distilled:\n* The weighting matrix <math>\\mathbf{R}</math> is theoretically positive definite and <math>\\mathbf{X}</math> is indefinite. The [[Rayleigh quotient]]\n:<math>\t\\lambda_n \\approx \\frac{\\mathbf{I}_n^\\mathrm{H}\\mathbf{X}\\mathbf{I}_n}{\\mathbf{I}_n^\\mathrm{H}\\mathbf{R}\\mathbf{I}_n} </math>\n\nthen spans the [[Numerical range|range]] of <math>-\\infty \\leq \\lambda_n \\leq \\infty</math> and indicates whether the characteristic mode is capacitive (<math>\\lambda_n < 0</math>), inductive (<math>\\lambda_n > 0</math>), or in resonance (<math>\\lambda_n = 0</math>). In reality, the Rayleigh quotient is limited by the numerical dynamics of the [[machine precision]] used and the number of correctly found modes is limited.\n* The characteristic numbers evolve with frequency, i.e., <math>\\lambda_n = \\lambda_n \\left(\\omega\\right)</math>, they can cross each other, or they can be the same (in case of degeneracies <ref name=\"SchabBernhard1\" />). For this reason, the tracking of modes is often applied in order to get smooth curves <math>\\lambda_n \\left(\\omega\\right)</math>.<ref name=\"CapekEtAl2\" /><ref name=\"RainesRojas1\" /><ref name=\"LudicsEtAl1\" /><ref name=\"MiersLau1\" /><ref name=\"SafinManteuffel1\" /> Unfortunately, this process is partly heuristic and the tracking algorithms are still far from perfection.<ref name=\"CapekEtAl1\" />\n* The characteristic modes can be chosen as real-valued functions, <math>\\mathbf{I}_n \\in \\mathbb{R}^{N\\times 1}</math>. In other words, characteristic modes form a set of equiphase currents.\n* The CM decomposition is invariant with respect to the amplitude of the characteristic modes. This fact is used to normalize the current so that they radiate unitary radiated power\n:<math>\t\\frac{1}{2} \\mathbf{I}_m^\\mathrm{H} \\mathbf{Z} \\mathbf{I}_n \\approx \\left(1 + \\mathrm{j} \\lambda_n\\right) \\delta_{mn}. </math>\n\nThis last relation presents the ability of characteristic modes to diagonalize the impedance operator (2) and demonstrates far field [[orthogonality]], i.e.,\n\n:<math>\t\\frac{1}{2} \\sqrt{\\frac{\\varepsilon_0}{\\mu_0}} \\int\\limits_0^{2\\pi} \\int\\limits_0^\\pi \\boldsymbol{F}_m^\\ast \\cdot \\boldsymbol{F}_n \\sin \\vartheta \\, \\mathrm{d} \\vartheta \\, \\mathrm{d} \\varphi = \\delta_{mn}. </math>\n\n== Modal quantities ==\n\nThe modal currents can be used to evaluate antenna parameters in their modal form, for example:\n* modal far-field <math>\\boldsymbol{F}_n \\left(\\boldsymbol{\\hat{e}}, \\boldsymbol{\\hat{r}}\\right)</math> (<math>\\boldsymbol{\\hat{e}}</math> — [[Polarization (waves)|polarization]], <math>\\boldsymbol{\\hat{r}}</math> — direction), <ref name=\"HarringtonMautz1\" />,\n* modal [[directivity]] <math>\\boldsymbol{D}_n \\left(\\boldsymbol{\\hat{e}}, \\boldsymbol{\\hat{r}}\\right)</math>,\n* modal radiation efficiency <math>\\eta_n</math> <ref name=\"CapekEtAl3\" />,\n* modal quality factor <math>Q_n</math> <ref name=\"CapekEtAl4\" />,\n* modal impedance <math>Z_n</math>.\n\nThese quantities can be utilized for analysis, feeding synthesis, radiator's shape optimization, or antenna characterization.\n\n== Applications and further development ==\n\nThe number of potential applications is enormous and still growing:\n* antenna analysis and synthesis,<ref name=\"WuSu1\" /><ref name=\"VogelEtAl1\" /><ref name=\"YangAdams1\" />\n* design of [[MIMO]] antennas,<ref name=\"LiEtAl1\" /><ref name=\"DengEtAl1\" /><ref name=\"YangAdams2\" /><ref name=\"EichlerEtAl1\" />\n* compact antenna design ([[RFID]], [[Wifi]]),<ref name=\"RezaiesarlakManteghi1\" /><ref name=\"BohannonBernhard1\" />\n* [[UAV]] antennas,<ref name=\"ChenEtAl1\" />\n* selective excitation of chassis and platforms,<ref name=\"AustinEtAl1\" />\n* model order reduction,<ref name=\"GustafssonEtAl1\" />\n* bandwidth enhancement,<ref name=\"AdamsEtAl1\" /><ref name=\"SafinManteuffel2\" />\n* nanotubes<ref name=\"HassanEtAl1\" /> and metamaterials,<ref name=\"RabahEtAl1\" /><ref name=\"RabahEtAl2\" />\n* validation of computational electromagnetics codes.<ref name=\"CapekEtAl1\" />\n\nThe prospective topics include\n* electrically large structures calculated using MLFMA,<ref name=\"DaiEtAl1\" />\n* dielectrics,<ref name=\"HarringtonMautzEtAl1\" /><ref name=\"GuoEtAl1\" />\n* utilization of Combined Field Integral Equation,<ref name=\"DaiEtAl2\" />\n* periodic structures,\n* formulation for arrays.<ref name=\"TzanidisEtAl1\" />\n\n== Software ==\n\nCM decomposition has recently been implemented in major electromagnetic simulators, namely in FEKO<ref name=\"FEKO\" />, CST-MWS<ref name=\"CST-MWS\" />, and WIPL-D<ref name=\"WIPLD\" />. Other packages are about to support it soon, for example HFSS<ref name=\"HFSS\" /> and CEM One<ref name=\"CEMOne\" />. In addition, there is a plethora of in-house and academic packages which are capable of evaluating CM and many associated parameters.\n\n== Alternative bases ==\n\nCM are useful to understand radiator's operation better. They have been used with great success for many practical purposes. However, it is important to stress that they are not perfect and it is often better to use other formulations such as energy modes<ref name=\"SchabBernhard2\" />, radiation modes<ref name=\"SchabBernhard2\" />, stored energy modes<ref name=\"GustafssonEtAl1\" /> or radiation efficiency modes<ref name=\"JelinekCapek1\" />.\n\n== References ==\n\n{{Reflist|refs=\n<ref name=Garbacz1>{{cite journal | last=Garbacz | first=R.J. | title=Modal expansions for resonance scattering phenomena | journal=Proceedings of the IEEE | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=53 | issue=8 | year=1965 | issn=0018-9219 | doi=10.1109/proc.1965.4064 | pages=856–864}}</ref>\n<ref name=Garbacz2>Garbacz, R. J., \"A Generalized Expansion for Radiated and Scattered Fields,\" Ph.D. thesis, Department of Electrical Engineering, The Ohio State Univ., 1968.</ref>\n<ref name=HarringtonMautz1>{{cite journal | last=Harrington | first=R. | last2=Mautz | first2=J. | title=Theory of characteristic modes for conducting bodies | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=19 | issue=5 | year=1971 | issn=0096-1973 | doi=10.1109/tap.1971.1139999 | pages=622–628}}</ref>\n<ref name=HarringtonMautz2>{{cite journal | last=Harrington | first=R. | last2=Mautz | first2=J. | title=Computation of characteristic modes for conducting bodies | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=19 | issue=5 | year=1971 | issn=0096-1973 | doi=10.1109/tap.1971.1139990 | pages=629–639}}</ref>\n<ref name=ChangHarrington1>{{cite journal | last=Chang | first=Y. | last2=Harrington | first2=R. | title=A surface formulation for characteristic modes of material bodies | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=25 | issue=6 | year=1977 | issn=0096-1973 | doi=10.1109/tap.1977.1141685 | pages=789–795}}</ref>\n<ref name=HarringtonMautz3>{{cite journal | last=Harrington | first=R.F. | last2=Mautz | first2=J.R. | title=Characteristic Modes for Aperture Problems | journal=IEEE Transactions on Microwave Theory and Techniques | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=33 | issue=6 | year=1985 | issn=0018-9480 | doi=10.1109/tmtt.1985.1133105 | pages=500–505}}</ref>\n<ref name=HarringtonMautzEtAl1>{{cite journal|last=Harrington |first= R. F.|last2=Mautz|first2=J.R.|last3= Chang|first3= Y.|title=Characteristic modes for dielectric and magnetic bodies|journal=IEEE Transactions on Antennas and Propagation|volume=20|issue=2|pages=194–198|date=March 1972|doi=10.1109/TAP.1972.1140154}}</ref>\n<ref name=Hajj1>{{cite journal | last=El-Hajj | first=A. | last2=Kabalan | first2=K.Y. | last3=Harrington | first3=R.F. | title=Characteristic mode analysis off electromagnetic coupling through multiple slots in a conducting plane | journal=IEE Proceedings H Microwaves, Antennas and Propagation | publisher=Institution of Engineering and Technology (IET) | volume=140 | issue=6 | year=1993 | issn=0950-107X | doi=10.1049/ip-h-2.1993.0069 | page=421}}</ref>\n<ref name=Montgomery1> Montgomery, C. G.; Dicke, R.H.; Purcell, E. M., Principles of Microwave Circuits, Section 9.24, New York, United States: McGraw-Hill, 1948.</ref>\n<ref name=CabedoEtAl1>{{cite journal | last=Cabedo-Fabres | first=Marta | last2=Antonino-Daviu | first2=Eva | last3=Valero-Nogueira | first3=Alejandro | last4=Bataller | first4=Miguel | title=The Theory of Characteristic Modes Revisited: A Contribution to the Design of Antennas for Modern Applications | journal=IEEE Antennas and Propagation Magazine | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=49 | issue=5 | year=2007 | issn=1045-9243 | doi=10.1109/map.2007.4395295 | pages=52–68}}</ref>\n<ref name=CapekEtAl1>{{cite journal | last=Capek | first=Miloslav | last2=Losenicky | first2=Vit | last3=Jelinek | first3=Lukas | last4=Gustafsson | first4=Mats | title=Validating the Characteristic Modes Solvers | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=65 | issue=8 | year=2017 | issn=0018-926X | doi=10.1109/tap.2017.2708094 | pages=4134–4145}}</ref>\n<ref name=Harrington1> Harrington, R. F., Field Computation by Moment Methods, Wiley -- IEEE Press, 1993.</ref>\n<ref name=SchabBernhard1>{{cite journal | last=Schab | first=K. R. | last2=Bernhard | first2=J. T. | title=A Group Theory Rule for Predicting Eigenvalue Crossings in Characteristic Mode Analyses | journal=IEEE Antennas and Wireless Propagation Letters | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=16 | year=2017 | issn=1536-1225 | doi=10.1109/lawp.2016.2615041 | pages=944–947}}</ref>\n<ref name=CapekEtAl2>{{cite journal | last=Capek | first=Miloslav | last2=Hazdra | first2=Pavel | last3=Hamouz | first3=Pavel | last4=Eichler | first4=Jan | title=A method for tracking characteristic numbers and vectors | journal=Progress In Electromagnetics Research B | publisher=EMW Publishing | volume=33 | year=2011 | issn=1937-6472 | doi=10.2528/pierb11060209 | pages=115–134}}</ref>\n<ref name=RainesRojas1>{{cite journal | last=Raines | first=Bryan D. | last2=Rojas | first2=Roberto G. | title=Wideband Characteristic Mode Tracking | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=60 | issue=7 | year=2012 | issn=0018-926X | doi=10.1109/tap.2012.2196914 | pages=3537–3541}}</ref>\n<ref name=LudicsEtAl1>{{cite conference | last=Ludick | first=D.J. | last2=Jakobus | first2=U. | last3=Vogel | first3=M. | title=A tracking algorithm for the eigenvectors calculated with characteristic mode analysis | publisher=IEEE | year=2014 | isbn=978-88-907018-4-9 | doi=10.1109/eucap.2014.6901820 | page=569-572|conference=Proceedings of the 8th European Conference on Antennas and Propagation}}</ref>\n<ref name=MiersLau1>{{cite journal | last=Miers | first=Zachary | last2=Lau | first2=Buon Kiong | title=Wideband Characteristic Mode Tracking Utilizing Far-Field Patterns | journal=IEEE Antennas and Wireless Propagation Letters | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=14 | year=2015 | issn=1536-1225 | doi=10.1109/lawp.2015.2417351 | pages=1658–1661}}</ref>\n<ref name=SafinManteuffel1>{{cite journal | last=Safin | first=Eugen | last2=Manteuffel | first2=Dirk | title=Advanced Eigenvalue Tracking of Characteristic Modes | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=64 | issue=7 | year=2016 | issn=0018-926X | doi=10.1109/tap.2016.2556698 | pages=2628–2636}}</ref>\n<ref name=CapekEtAl3>{{cite journal | last=Capek | first=Miloslav | last2=Hazdra | first2=Pavel | last3=Eichler | first3=Jan | title=Evaluating radiation efficiency from characteristic currents | journal=IET Microwaves, Antennas & Propagation | publisher=Institution of Engineering and Technology (IET) | volume=9 | issue=1 | date=9 January 2015 | issn=1751-8725 | doi=10.1049/iet-map.2013.0473 | pages=10–15}}</ref>\n<ref name=CapekEtAl4>{{cite journal | last=Capek | first=Miloslav | last2=Hazdra | first2=Pavel | last3=Eichler | first3=Jan | title=A Method for the Evaluation of Radiation Q Based on Modal Approach | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=60 | issue=10 | year=2012 | issn=0018-926X | doi=10.1109/tap.2012.2207329 | pages=4556–4567}}</ref>\n<ref name=WuSu1>{{cite journal | last=Wu | first=Qi | last2=Su | first2=Donglin | title=A Broadband Model of the Characteristic Currents for Rectangular Plates | journal=IEEE Transactions on Electromagnetic Compatibility | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=55 | issue=4 | year=2013 | issn=0018-9375 | doi=10.1109/temc.2012.2221718 | pages=725–732}}</ref>\n<ref name=VogelEtAl1>{{cite journal | last=Vogel | first=Martin | last2=Gampala | first2=Gopinath | last3=Ludick | first3=Danie | last4=Reddy | first4=C.J. | title=Characteristic Mode Analysis: Putting Physics back into Simulation | journal=IEEE Antennas and Propagation Magazine | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=57 | issue=2 | year=2015 | issn=1045-9243 | doi=10.1109/map.2015.2414670 | pages=307–317}}</ref>\n<ref name=YangAdams1>{{cite journal | last=Yang | first=Binbin | last2=Adams | first2=Jacob J. | title=Computing and Visualizing the Input Parameters of Arbitrary Planar Antennas via Eigenfunctions | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=64 | issue=7 | year=2016 | issn=0018-926X | doi=10.1109/tap.2016.2554604 | pages=2707–2718}}</ref>\n<ref name=LiEtAl1>{{cite journal | last=Li | first=Hui | last2=Miers | first2=Zachary Thomas | last3=Lau | first3=Buon Kiong | title=Design of Orthogonal MIMO Handset Antennas Based on Characteristic Mode Manipulation at Frequency Bands Below 1 GHz | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=62 | issue=5 | year=2014 | issn=0018-926X | doi=10.1109/tap.2014.2308530 | pages=2756–2766}}</ref>\n<ref name=DengEtAl1>{{cite journal | last=Deng | first=Changjiang | last2=Feng | first2=Zhenghe | last3=Hum | first3=Sean Victor | title=MIMO Mobile Handset Antenna Merging Characteristic Modes for Increased Bandwidth | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=64 | issue=7 | year=2016 | issn=0018-926X | doi=10.1109/tap.2016.2537358 | pages=2660–2667}}</ref>\n<ref name=YangAdams2>{{cite journal | last=Yang | first=Binbin | last2=Adams | first2=Jacob J. | title=Systematic Shape Optimization of Symmetric MIMO Antennas Using Characteristic Modes | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=64 | issue=7 | year=2016 | issn=0018-926X | doi=10.1109/tap.2015.2473703 | pages=2668–2678}}</ref>\n<ref name=EichlerEtAl1>{{cite journal | last=Eichler | first=J. | last2=Hazdra | first2=P. | last3=Capek | first3=M. | last4=Korinek | first4=T. | last5=Hamouz | first5=P. | title=Design of a Dual-Band Orthogonally Polarized L-Probe-Fed Fractal Patch Antenna Using Modal Methods | journal=IEEE Antennas and Wireless Propagation Letters | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=10 | year=2011 | issn=1536-1225 | doi=10.1109/lawp.2011.2178811 | pages=1389–1392}}</ref>\n<ref name=RezaiesarlakManteghi1>{{cite journal | last=Rezaiesarlak | first=Reza | last2=Manteghi | first2=Majid | title=Design of Chipless RFID Tags Based on Characteristic Mode Theory (CMT) | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=63 | issue=2 | year=2015 | issn=0018-926X | doi=10.1109/tap.2014.2382640 | pages=711–718}}</ref>\n<ref name=BohannonBernhard1>{{cite journal | last=Bohannon | first=Nicole L. | last2=Bernhard | first2=Jennifer T. | title=Design Guidelines Using Characteristic Mode Theory for Improving the Bandwidth of PIFAs | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=63 | issue=2 | year=2015 | issn=0018-926X | doi=10.1109/tap.2014.2374213 | pages=459–465}}</ref>\n<ref name=ChenEtAl1>{{cite journal | last=Chen | first=Yikai | last2=Wang | first2=Chao-Fu | title=Electrically Small UAV Antenna Design Using Characteristic Modes | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=62 | issue=2 | year=2014 | issn=0018-926X | doi=10.1109/tap.2013.2289999 | pages=535–545}}</ref>\n<ref name=AustinEtAl1>{{cite journal | last=Austin | first=B.A. | last2=Murray | first2=K.P. | title=The application of characteristic-mode techniques to vehicle-mounted NVIS antennas | journal=IEEE Antennas and Propagation Magazine | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=40 | issue=1 | year=1998 | issn=1045-9243 | doi=10.1109/74.667319 | pages=7–21}}</ref>\n<ref name=GustafssonEtAl1>{{cite journal|last=Gustafsson|first=M.|last2= Tayli|first2= D.|last3= Ehrenborg|first3=C.|last4=Cismasu|first4=M.|last5=Norbedo|first5=S.|title=Antenna current optimization using MATLAB and CVX|journal=FERMAT|volume=15|pages=1–29|date=May–June 2016|url=https://www.e-fermat.org/articles/gustafsson-art-2016-vol15-may-jun-005/}}</ref>\n<ref name=AdamsEtAl1>{{cite journal | last=Adams | first=Jacob J. | last2=Bernhard | first2=Jennifer T. | title=Broadband Equivalent Circuit Models for Antenna Impedances and Fields Using Characteristic Modes | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=61 | issue=8 | year=2013 | issn=0018-926X | doi=10.1109/tap.2013.2261852 | pages=3985–3994}}</ref>\n<ref name=SafinManteuffel2>{{cite journal | last=Safin | first=Eugen | last2=Manteuffel | first2=Dirk | title=Manipulation of Characteristic Wave Modes by Impedance Loading | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=63 | issue=4 | year=2015 | issn=0018-926X | doi=10.1109/tap.2015.2401586 | pages=1756–1764}}</ref>\n<ref name=HassanEtAl1>{{cite journal | last=Hassan | first=Ahmed M. | last2=Vargas-Lara | first2=Fernando | last3=Douglas | first3=Jack F. | last4=Garboczi | first4=Edward J. | title=Electromagnetic Resonances of Individual Single-Walled Carbon Nanotubes With Realistic Shapes: A Characteristic Modes Approach | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=64 | issue=7 | year=2016 | issn=0018-926X | doi=10.1109/tap.2016.2526046 | pages=2743–2757}}</ref>\n<ref name=RabahEtAl1>{{cite journal | last=Rabah | first=M. Hassanein | last2=Seetharamdoo | first2=Divitha | last3=Berbineau | first3=Marion | title=Analysis of Miniature Metamaterial and Magnetodielectric Arbitrary-Shaped Patch Antennas Using Characteristic Modes: Evaluation of the $Q$ Factor | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=64 | issue=7 | year=2016 | issn=0018-926X | doi=10.1109/tap.2016.2571723 | pages=2719–2731}}</ref>\n<ref name=RabahEtAl2>{{cite journal | last=Rabah | first=M. Hassanein | last2=Seetharamdoo | first2=Divitha | last3=Berbineau | first3=Marion | last4=De Lustrac | first4=Andre | title=New Metrics for Artificial Magnetism From Metal-Dielectric Metamaterial Based on the Theory of Characteristic Modes | journal=IEEE Antennas and Wireless Propagation Letters | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=15 | year=2016 | issn=1536-1225 | doi=10.1109/lawp.2015.2452269 | pages=460–463}}</ref>\n<ref name=DaiEtAl1>{{cite journal | last=Dai | first=Qi I. | last2=Wu | first2=Junwei | last3=Gan | first3=Hui | last4=Liu | first4=Qin S. | last5=Chew | first5=Weng Cho | last6=Sha | first6=Wei E. I. | title=Large-Scale Characteristic Mode Analysis With Fast Multipole Algorithms | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=64 | issue=7 | year=2016 | issn=0018-926X | doi=10.1109/tap.2016.2526083 | pages=2608–2616}}</ref>\n<ref name=GuoEtAl1>{{cite journal | last=Guo | first=Liwen | last2=Chen | first2=Yikai | last3=Yang | first3=Shiwen | title=Characteristic Mode Formulation for Dielectric Coated Conducting Bodies | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=65 | issue=3 | year=2017 | issn=0018-926X | doi=10.1109/tap.2016.2647687 | pages=1248–1258}}</ref>\n<ref name=DaiEtAl2>{{cite journal | last=Dai | first=Qi I. | last2=Liu | first2=Qin S. | last3=Gan | first3=Hui U. I. | last4=Chew | first4=Weng Cho | title=Combined Field Integral Equation-Based Theory of Characteristic Mode | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=63 | issue=9 | year=2015 | issn=0018-926X | doi=10.1109/tap.2015.2452938 | pages=3973–3981}}</ref>\n<ref name=TzanidisEtAl1>{{cite journal | last=Tzanidis | first=Ioannis | last2=Sertel | first2=Kubilay | last3=Volakis | first3=John L. | title=Characteristic Excitation Taper for Ultrawideband Tightly Coupled Antenna Arrays | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=60 | issue=4 | year=2012 | issn=0018-926X | doi=10.1109/tap.2012.2186269 | pages=1777–1784}}</ref>\n<ref name=FEKO> Altair, [Online: [https://www.feko.info/ FEKO]], 2017.</ref>\n<ref name=CST-MWS> Dassault Systemes, CST Computer Simulation Technology, [Online: [https://www.cst.com/ CST-MWS]], 2017.</ref>\n<ref name=WIPLD> WIPL-D d.o.o., [Online: [https://www.wipl-d.com/ WIPL-D]], 2017.</ref>\n<ref name=HFSS> ANSYS, [Online: [http://www.ansys.com/products/electronics/ansys-hfss HFSS]], 2017.</ref>\n<ref name=CEMOne> ESI Group, [Online: [https://www.esi-group.com/software-solutions/virtual-environment/electromagnetics/cem-one-solution CEM One]], 2017.</ref>\n<ref name=SchabBernhard2>{{cite journal | last=Schab | first=Kurt R. | last2=Bernhard | first2=Jennifer T. | title=Radiation and Energy Storage Current Modes on Conducting Structures | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=63 | issue=12 | year=2015 | issn=0018-926X | doi=10.1109/tap.2015.2490664 | pages=5601–5611}}</ref>\n<ref name=JelinekCapek1>{{cite journal | last=Jelinek | first=Lukas | last2=Capek | first2=Miloslav | title=Optimal Currents on Arbitrarily Shaped Surfaces | journal=IEEE Transactions on Antennas and Propagation | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=65 | issue=1 | year=2017 | issn=0018-926X | doi=10.1109/tap.2016.2624735 | pages=329–341}}</ref>\n}}\n\n[[Category:Electromagnetism]]\n[[Category:Electrodynamics]]\n[[Category:Antennas (radio)]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Collocation method",
      "url": "https://en.wikipedia.org/wiki/Collocation_method",
      "text": "In mathematics, a '''collocation method''' is a method for the [[numerical analysis|numerical]] solution of [[ordinary differential equation]]s, [[partial differential equation]]s and [[integral equation]]s. The idea is to choose a finite-dimensional space of candidate solutions (usually [[polynomial]]s up to a certain degree) and a number of points in the domain (called ''collocation points''), and to select that solution which satisfies the given equation at the collocation points.\n\n== Ordinary differential equations ==\n\nSuppose that the [[ordinary differential equation]]\n:<math> y'(t) = f(t,y(t)), \\quad y(t_0)=y_0, </math>\nis to be solved over the interval <math> [t_0,t_0+c_k h]</math>. Choose <math>c_k</math> from 0 ≤ ''c''<sub>1</sub>< ''c''<sub>2</sub>< &hellip; < ''c''<sub>''n''</sub> ≤ 1.\n\nThe corresponding (polynomial) collocation method approximates the solution ''y'' by the polynomial ''p'' of degree ''n'' which satisfies the initial condition <math>p(t_0) = y_0</math>, and the differential equation <math>p'(t_k) = f(t_k,p(t_k)) </math>\n\nat all ''collocation points'' <math>t_k = t_0 + c_k h</math> for <math>k = 1, \\ldots, n</math>. This gives ''n''&nbsp;+&nbsp;1 conditions, which matches the ''n''&nbsp;+&nbsp;1 parameters needed to specify a polynomial of degree ''n''.\n\nAll these collocation methods are in fact implicit [[Runge–Kutta methods]]. The coefficients ''c''<sub>''k''</sub> in the Butcher tableau of a Runge–Kutta method are the collocation points. However, not all implicit Runge–Kutta methods are collocation methods.\n<ref>{{harvnb|Ascher|Petzold|1998}}; {{harvnb|Iserles|1996|pp=43–44}}</ref>\n\n=== Example: The trapezoidal rule ===\nPick, as an example, the two collocation points ''c''<sub>1</sub> = 0 and ''c''<sub>2</sub> = 1 (so ''n'' = 2). The collocation conditions are\n\n:<math> p(t_0) = y_0, \\, </math>\n:<math> p'(t_0) = f(t_0, p(t_0)), \\, </math>\n:<math> p'(t_0+h) = f(t_0+h, p(t_0+h)). \\, </math>\n\nThere are three conditions, so ''p'' should be a polynomial of degree 2. Write ''p'' in the form\n\n:<math> p(t) = \\alpha (t-t_0)^2 + \\beta (t-t_0) + \\gamma \\, </math>\n\nto simplify the computations. Then the collocation conditions can be solved to give the coefficients\n\n:<math> \n   \\begin{align}\n   \\alpha &= \\frac{1}{2h} \\Big( f(t_0+h, p(t_0+h)) - f(t_0, p(t_0)) \\Big), \\\\\n   \\beta &= f(t_0, p(t_0)), \\\\\n   \\gamma &= y_0. \n   \\end{align} \n</math>\n\nThe collocation method is now given (implicitly) by\n\n:<math> y_1 = p(t_0 + h) = y_0 + \\frac12h \\Big (f(t_0+h, y_1) + f(t_0,y_0) \\Big), \\, </math>\n\nwhere ''y''<sub>1</sub> = ''p''(''t''<sub>0</sub>&nbsp;+&nbsp;''h'') is the approximate solution at ''t'' = ''t''<sub>0</sub>&nbsp;+&nbsp;''h''.\n\nThis method is known as the \"[[trapezoidal rule (differential equations)|trapezoidal rule]]\" for differential equations. Indeed, this method can also be derived by rewriting the differential equation as\n\n:<math> y(t) = y(t_0) + \\int_{t_0}^t f(\\tau, y(\\tau)) \\,\\textrm{d}\\tau, \\, </math>\n\nand approximating the integral on the right-hand side by the [[trapezoidal rule]] for integrals.\n\n=== Other examples ===\n\nThe [[Gauss–Legendre method]]s use the points of [[Gauss–Legendre quadrature]] as collocation points. The Gauss–Legendre method based on ''s'' points has order 2''s''.<ref>{{harvnb|Iserles|1996|pp=47}}</ref> All Gauss–Legendre methods are [[A-stability|A-stable]].<ref>{{harvnb|Iserles|1996|pp=63}}</ref>\n\nIn fact, one can show that the order of a collocation method corresponds to the order of the quadrature rule that one would get using the collocation points as weights.\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n* {{Citation | last1=Ascher | first1=Uri M. | last2=Petzold | first2=Linda R. |author2-link=Linda Petzold| title=Computer Methods for Ordinary Differential Equations and Differential-Algebraic Equations | publisher=[[Society for Industrial and Applied Mathematics]] | location=Philadelphia | isbn=978-0-89871-412-8 | year=1998}}.\n* {{Citation | last1=Hairer | first1=Ernst | last2=Nørsett | first2=Syvert Paul | last3=Wanner | first3=Gerhard | title=Solving ordinary differential equations I: Nonstiff problems | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-56670-0 | year=1993}}.\n* {{Citation | last1=Iserles | first1=Arieh | author1-link=Arieh Iserles | title=A First Course in the Numerical Analysis of Differential Equations | publisher=[[Cambridge University Press]] | isbn=978-0-521-55655-2 | year=1996}}.\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Collocation Method}}\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Compact stencil",
      "url": "https://en.wikipedia.org/wiki/Compact_stencil",
      "text": "[[Image:CompactStencil.svg|right|thumb|150px|A 2D compact stencil using all 8 adjacent nodes, plus the center node (in red).]]\n\nIn [[mathematics]], especially in the areas of [[numerical analysis]] called [[numerical partial differential equations]], a '''compact stencil''' is a type of [[stencil (numerical analysis)|stencil]] that uses only nine nodes for its [[discretization]] method in two dimensions.  It uses only the center node and the [[Adjacent (graph theory)|adjacent]] nodes. For any [[structured grid]] utilizing a compact stencil in 1, 2, or 3 [[dimension]]s the maximum number of [[Node (graph theory)|nodes]] is 3, 9, or 27 respectively. Compact stencils may be compared to [[non-compact stencil|non-compact stencils]]. Compact stencils are currently implemented in many [[partial differential equation]] solvers, including several in the topics of CFD, FEA, and other mathematical solvers relating to PDE's.<ref>W. F. Spotz. High-Order Compact Finite Difference Schemes for Computational Mechanics. PhD thesis, University of Texas at Austin, Austin, TX, 1995.</ref><ref>Communications in Numerical Methods in Engineering, Copyright © 2008 John Wiley & Sons, Ltd.</ref>\n\n==Two Point Stencil Example==\nThe two point stencil for the ''first derivative'' of a function is given by:\n\n<math>\nf'(x_0)=\\frac{f\\left(x_0 + h\\right) - f\\left(x_0 - h\\right)}{2h} + O\\left(h^2\\right)\n</math>.\n\n\nThis is obtained from the [[Taylor series]] expansion of the first derivative of the function given by:\n\n<math>\\begin{array} {l}\nf'(x_0)=\\frac{f\\left(x_0 + h\\right) - f(x_0)}{h} -\\frac{f^{(2)}(x_0)}{2!}h - \\frac{f^{(3)}(x_0)}{3!}h^2 - \\frac{f^{(4)}(x_0)}{4!}h^3 + \\cdots\n\\end{array}</math>.\n\n\nReplacing <math>h</math> with <math>-h</math>, we have:\n\n<math>\\begin{array} {l}\nf'(x_0)=-\\frac{f\\left(x_0 - h\\right) - f(x_0)}{h} + \\frac{f^{(2)}(x_0)}{2!}h - \\frac{f^{(3)}(x_0)}{3!}h^2 + \\frac{f^{(4)}(x_0)}{4!}h^3 + \\cdots \n\\end{array}</math>.\n\n\nAddition of the above two equations together results in the cancellation of the terms in odd powers of <math>h</math>:\n\n<math>\\begin{array} {l}\n2f'(x_0)=\n\\frac{f\\left(x_0 + h\\right) - f(x_0)}{h}\n-\\frac{f\\left(x_0 - h\\right) - f(x_0)}{h}\n-2\\frac{f^{(3)}(x_0)}{3!}h^2 + \\cdots\n\\end{array}</math>.\n\n<math>\\begin{array} {l}\nf'(x_0)=\n\\frac{f\\left(x_0 + h\\right) - f\\left(x_0 - h\\right)}{2h} - \\frac{f^{(3)}(x_0)}{3!}h^2 + \\cdots\n\\end{array}</math>.\n\n<math>\\begin{array} {l}\nf'(x_0)=\n\\frac{f\\left(x_0 + h\\right) - f\\left(x_0 - h\\right)}{2h} + O\\left(h^2\\right)\n\\end{array}</math>.\n\n\n==Three Point Stencil Example==\nFor example, the three point stencil for the ''second derivative'' of a function is given by:\n\n<math>\\begin{array} {l}\nf^{(2)}(x_0)=\n\\frac{f\\left(x_0 + h\\right) + f\\left(x_0 - h\\right) - 2f(x_0)}{h^2} + O\\left(h^2\\right)\n\\end{array}</math>.\n\n\nThis is obtained from the [[Taylor series]] expansion of the first derivative of the function given by:\n\n<math>\\begin{array} {l}\nf'(x_0)=\\frac{f\\left(x_0 + h\\right) - f(x_0)}{h} -\\frac{f^{(2)}(x_0)}{2!}h - \\frac{f^{(3)}(x_0)}{3!}h^2 - \\frac{f^{(4)}(x_0)}{4!}h^3 + \\cdots\n\\end{array}</math>.\n\n\nReplacing <math>h</math> with <math>-h</math>, we have:\n\n<math>\\begin{array} {l}\nf'(x_0)=-\\frac{f\\left(x_0 - h\\right) - f(x_0)}{h} + \\frac{f^{(2)}(x_0)}{2!}h - \\frac{f^{(3)}(x_0)}{3!}h^2 + \\frac{f^{(4)}(x_0)}{4!}h^3 + \\cdots \n\\end{array}</math>.\n\n\nSubtraction of the above two equations results in the cancellation of the terms in even powers of <math>h</math>:\n<math>\\begin{array} {l}\n0=\n\\frac{f\\left(x_0 + h\\right) - f(x_0)}{h}\n+\\frac{f\\left(x_0 - h\\right) - f(x_0)}{h}\n- 2\\frac{f^{(2)}(x_0)}{2!}h - 2\\frac{f^{(4)}(x_0)}{4!}h^3 + \\cdots\n\\end{array}</math>.\n\n<math>\\begin{array} {l}\nf^{(2)}(x_0)=\n\\frac{f\\left(x_0 + h\\right) + f\\left(x_0 - h\\right) - 2f(x_0)}{h^2} - 2\\frac{f^{(4)}(x_0)}{4!}h^2 + \\cdots\n\\end{array}</math>.\n\n<math>\\begin{array} {l}\nf^{(2)}(x_0)=\n\\frac{f\\left(x_0 + h\\right) + f\\left(x_0 - h\\right) - 2f(x_0)}{h^2} + O\\left(h^2\\right)\n\\end{array}</math>.\n\n\n==See also==\n*[[Stencil (numerical analysis)]]\n*[[Non-compact stencil]]\n*[[Five-point stencil]]\n\n== References ==\n{{refimprove|date=July 2008}}\n{{reflist}}\n\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Constraint (computational chemistry)",
      "url": "https://en.wikipedia.org/wiki/Constraint_%28computational_chemistry%29",
      "text": "In [[computational chemistry]], a '''constraint algorithm''' is a method for satisfying the  Newtonian motion of a rigid body which consists of mass points. A restraint algorithm is used to ensure that the distance between mass points is maintained. The general steps involved are; (i) choose novel unconstrained coordinates (internal coordinates), (ii) introduce explicit constraint forces, (iii) minimize constraint forces implicitly by the technique of [[Lagrange multipliers]] or projection methods.\n\nConstraint algorithms are often applied to [[molecular dynamics]] simulations. Although such simulations are sometimes performed using internal coordinates that automatically satisfy the bond-length, bond-angle and torsion-angle constraints, simulations may also be performed using explicit or implicit constraint forces for these three constraints. However, explicit constraint forces give rise to inefficiency; more computational power is required to get a trajectory of a given length. Therefore, internal coordinates and implicit-force constraint solvers are generally preferred.\n\nConstraint algorithms achieve computational efficiency by neglecting motion along some degrees of freedom. For instance, in atomistic molecular dynamics, typically the length of covalent bonds to hydrogen are constrained; however, constraint algorithms should not be used if vibrations along these degrees of freedom are important for the phenomenon being studied.\n\n==Mathematical background==\n\nThe motion of a set of ''N'' particles can be described by a set of second-order ordinary differential equations, Newton's second law, which can be written in matrix form\n\n: <math>\n\\mathbf{M} \\cdot \\frac{d^{2}\\mathbf{q}}{dt^{2}} = \\mathbf{f} = -\\frac{\\partial V}{\\partial \\mathbf{q}}\n</math>\n\nwhere '''M''' is a ''mass matrix'' and '''q''' is the [[Vector (geometric)|vector]] of [[generalized coordinate]]s that describe the particles' positions.  For example, the vector '''q''' may be a ''3N'' Cartesian coordinates of the particle positions '''r'''<sub>''k''</sub>, where ''k'' runs from 1 to ''N''; in the absence of constraints, '''M''' would be the ''3N''x''3N'' diagonal square matrix of the particle masses.  The vector '''f''' represents the generalized forces and the scalar ''V''('''q''') represents the potential energy, both of which are functions of the generalized coordinates '''q'''.\n\nIf ''M'' constraints are present, the coordinates must also satisfy ''M'' time-independent algebraic equations\n\n:<math>\ng_{j}(\\mathbf{q}) = 0 \n</math>\n\nwhere the index ''j'' runs from 1 to ''M''.  For brevity, these functions ''g''<sub>''i''</sub> are grouped into an ''M''-dimensional vector '''g'''  below.  The task is to solve the combined set of differential-algebraic (DAE) equations, instead of just the ordinary differential equations (ODE) of Newton's second law.\n\nThis problem was studied in detail by [[Joseph Louis Lagrange]], who laid out most of the methods for solving it.<ref name=\"lagrange_1788\" >{{cite book | last = Lagrange | first = GL| authorlink = Lagrange| year = 1788 | title = Mécanique analytique}}</ref>  The simplest approach is to define new generalized coordinates that are unconstrained; this approach eliminates the algebraic equations and reduces the problem once again to solving an ordinary differential equation.  Such an approach is used, for example, in describing the motion of a rigid body; the position and orientation of a rigid body can be described by six independent, unconstrained coordinates, rather than describing the positions of the particles that make it up and the constraints among them that maintain their relative distances.  The drawback of this approach is that the equations may become unwieldy and complex; for example, the mass matrix '''M''' may become non-diagonal and depend on the generalized coordinates.\n\nA second approach is to introduce explicit forces that work to maintain the constraint; for example, one could introduce strong spring forces that enforce the distances among mass points within a \"rigid\" body.  The two difficulties of this approach are that the constraints are not satisfied exactly, and the strong forces may require very short time-steps, making simulations inefficient computationally.\n\nA third approach is to use a method such as [[Lagrange multipliers]] or projection to the constraint manifold to determine the coordinate adjustments necessary to satisfy the constraints.  Finally, there are various hybrid approaches in which different sets of constraints are satisfied by different methods, e.g., internal coordinates, explicit forces and implicit-force solutions.\n\n==Internal coordinate methods==\n\nThe simplest approach to satisfying constraints in energy minimization and molecular dynamics is to represent the mechanical system in so-called ''internal coordinates'' corresponding to unconstrained independent degrees of freedom of the system.  For example, the dihedral angles of a protein are an independent set of coordinates that specify the positions of all the atoms without requiring any constraints.  The difficulty of such internal-coordinate approaches is twofold: the Newtonian equations of motion become much more complex and the internal coordinates may be difficult to define for cyclic systems of constraints, e.g., in ring puckering or when a protein has a disulfide bond.\n\nThe original methods for efficient recursive energy minimization in internal coordinates were developed by Gō and coworkers.<ref name=\"noguti_1983\" >{{cite journal | last = Noguti T |author2=Gō N | year = 1983 | title = A Method of Rapid Calculation of a 2nd Derivative Matrix of Conformational Energy for Large Molecules | journal = Journal of the Physical Society of Japan | volume = 52 | issue = 10 | pages = 3685–3690 | doi = 10.1143/JPSJ.52.3685 | first1 = Toshiyuki|bibcode = 1983JPSJ...52.3685N }}</ref><ref name=\"Abe_1984\" >{{cite journal | last = Abe | first = H |author2=Braun W|author3=Noguti T|author4=Gō N | year = 1984 | title =  Rapid Calculation of 1st and 2nd Derivatives of Conformational Energy with respect to Dihedral Angles for Proteins: General Recurrent Equations | journal = Computers and Chemistry | volume = 8 | issue = 4 | pages = 239–247 | doi =  10.1016/0097-8485(84)85015-9}}</ref>\n\nEfficient recursive, internal-coordinate constraint solvers were extended to molecular dynamics.<ref name=\"Bae_Haug_1988a\" >{{cite journal | last = Bae | first = D-S |author2=Haug EJ | year = 1988 | title = A Recursive Formulation for Constrained Mechanical System Dynamics: Part I. Open Loop Systems | journal = Mechanics of Structures and Machines | volume = 15 | issue = 3 | pages = 359–382| doi = 10.1080/08905458708905124 }}</ref><ref name=\"jain_1993\" >{{cite journal | last = Jain | first = A |author2=Vaidehi N|author3=Rodriguez G | year = 1993 | title = A Fast Recursive Algorithm for Molecular Dynamics Simulation | journal = Journal of Computational Physics | volume = 106 | issue = 2 | pages = 258–268 | doi = 10.1006/jcph.1993.1106 | bibcode = 1993JCoPh.106..258J}}</ref>  Analogous methods were applied later to other systems.<ref name=\"rice_1994\" >{{cite journal | last = Rice | first = LM |author2=Brünger AT | year = 1994 | title = Torsion Angle Dynamics: Reduced Variable Conformational Sampling Enhances Crystallographic Structure Refinement | journal = Proteins: Structure, Function, and Genetics | volume = 19 | pages = 277–290 | doi = 10.1002/prot.340190403 | pmid = 7984624 | issue = 4}}</ref><ref>{{cite journal | last = Mathiowetz | first = AM |author2=Jain A |author3=Karasawa N |author4=Goddard III, WA | year = 1994 | title = Protein Simulations Using Techniques Suitable for Very Large Systems: The Cell Multipole Method for Nonbond Interactions and the Newton-Euler Inverse Mass Operator Method for Internal Coordinate Dynamics | journal = Proteins: Structure, Function, and Genetics | volume = 20 | pages = 227–247 | doi = 10.1002/prot.340200304 | pmid = 7892172 | issue = 3}}</ref><ref name=\"mazur_1997\" >{{cite journal | last = Mazur | first = AK | year = 1997 | title = Quasi-Hamiltonian Equations of Motion for Internal Coordinate Molecular Dynamics of Polymers | journal = Journal of Computational Chemistry | volume = 18 | issue = 11 | pages = 1354–1364 | doi = 10.1002/(SICI)1096-987X(199708)18:11<1354::AID-JCC3>3.0.CO;2-K| arxiv = physics/9703019 }}</ref>\n\n==Lagrange multiplier-based methods==\n[[File:SHAKE.png|thumb|200px|right|Resolving the constraints of a rigid water molecule using [[Lagrange multipliers]]: a) the unconstrained positions are obtained after a simulation time-step, b) the [[gradients]] of each constraint over each particle are computed and c) the Lagrange multipliers are computed for each gradient such that the constraints are satisfied.]]\n\nIn most of [[molecular dynamics]] simulations that use constraint algorithms, constraints are enforced using the method of [[Lagrange multipliers]]. Given a set of ''n'' linear ([[Holonomic constraints|holonomic]]) constraints at the time ''t'',\n\n:<math>\\sigma_k(t) := \\| \\mathbf x_{k\\alpha}(t) - \\mathbf x_{k\\beta}(t) \\|^2 - d_k^2 = 0, \\quad k=1 \\ldots n</math>\n\nwhere <math>\\scriptstyle \\mathbf x_{k\\alpha}(t)</math> and <math>\\scriptstyle\\mathbf x_{k\\beta}(t)</math> are the positions of the two particles involved in the ''k''th constraint at the time ''t'' and <math>d_k</math> is the prescribed inter-particle distance.\n\nThe forces due to these constraints are added in the equations of motion, resulting in, for each of the ''N'' particles in the system\n\n:<math>\\frac{\\partial^2 \\mathbf x_i(t)}{\\partial t^2} m_i = -\\frac{\\partial}{\\partial \\mathbf x_i} \\left[ V(\\mathbf x_i(t)) + \\sum_{k=1}^n \\lambda_k \\sigma_k(t) \\right], \\quad i=1 \\ldots N.</math>\n\nAdding the constraint forces does not change the total energy, as the net work done by the constraint forces (taken over the set of particles that the constraints act on) is zero.\n\nFrom integrating both sides of the equation with respect to the time, the constrainted coordinates of particles at the time, <math>t + \\Delta t</math>, are given,\n\n:<math>\\mathbf x_i(t + \\Delta t) = \\hat{\\mathbf x}_i(t + \\Delta t) + \\sum_{k=1}^n \\lambda_k \\frac{\\partial\\sigma_k(t)}{\\partial \\mathbf x_i}\\left(\\Delta t\\right)^2m_i^{-1}, \\quad i=1 \\ldots N</math>\n\nwhere <math>\\hat{\\mathbf x}_i(t + \\Delta t)</math> is the unconstrained (or uncorrected) position of the ''i''th particle after integrating the unconstrained equations of motion.\n\nTo satisfy the constraints <math>\\sigma_k(t + \\Delta t)</math> in the next timestep, the [[Lagrange multipliers]] should be determined as the following equation,\n\n:<math>\\sigma_k(t + \\Delta t) := \\left\\| \\mathbf x_{k\\alpha}(t+\\Delta t) - \\mathbf x_{k\\beta}(t+\\Delta t)\\right\\|^2 - d_k^2 = 0.</math>\n\nThis implies solving a system of <math>n</math> non-linear equations\n\n:<math>\\sigma_j(t + \\Delta t) := \\left\\| \\hat{\\mathbf x}_{j\\alpha}(t+\\Delta t) - \\hat{\\mathbf x}_{j\\beta}(t+\\Delta t) +    \\sum_{k=1}^n \\lambda_k \\left(\\Delta t\\right)^2 \\left[ \\frac{\\partial\\sigma_k(t)}{\\partial \\mathbf x_{j\\alpha}}m_{j\\alpha}^{-1} -  \\frac{\\partial\\sigma_k(t)}{\\partial \\mathbf x_{j\\beta}}m_{j\\beta}^{-1}\\right] \\right\\|^2 - d_j^2 = 0, \\quad j = 1 \\ldots n</math>\n\nsimultaneously for the <math>n</math> unknown Lagrange multipliers <math>\\lambda_k</math>.\n\nThis system of <math>n</math> non-linear equations in <math>n</math> unknowns is commonly solved using [[Newton's method|Newton–Raphson method]] where the solution vector <math>\\underline{\\lambda}</math> is updated using\n\n:<math>\\underline{\\lambda}^{(l+1)} \\leftarrow \\underline{\\lambda}^{(l)} - \\mathbf J_\\sigma^{-1} \\underline{\\sigma}(t+\\Delta t)</math>\n\nwhere <math>\\mathbf J_\\sigma</math> is the [[Jacobian matrix and determinant|Jacobian]] of the equations σ<sub>''k''</sub>:\n\n:<math>\\mathbf J = \\left( \\begin{array}{cccc}\n    \\frac{\\partial\\sigma_1}{\\partial\\lambda_1} & \\frac{\\partial\\sigma_1}{\\partial\\lambda_2} & \\cdots & \\frac{\\partial\\sigma_1}{\\partial\\lambda_n} \\\\[5pt]\n    \\frac{\\partial\\sigma_2}{\\partial\\lambda_1} & \\frac{\\partial\\sigma_2}{\\partial\\lambda_2} & \\cdots & \\frac{\\partial\\sigma_2}{\\partial\\lambda_n} \\\\[5pt]\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\[5pt]\n    \\frac{\\partial\\sigma_n}{\\partial\\lambda_1} & \\frac{\\partial\\sigma_n}{\\partial\\lambda_2} & \\cdots & \\frac{\\partial\\sigma_n}{\\partial\\lambda_n} \\end{array}\\right).</math>\n\nSince not all particles contribute to all of constraints, <math>\\mathbf J_\\sigma</math> is a [[block matrix]] and can be solved individually to block-unit of the matrix. In other words, <math>\\mathbf J_\\sigma</math> can be solved individually for each molecule.\n\nInstead of constantly updating the vector <math>\\underline{\\lambda}</math>, the iteration can be started with <math>\\underline{\\lambda}^{(0)} = \\mathbf 0</math>, resulting in simpler expressions for <math>\\sigma_k(t)</math> and <math>\\frac{\\partial \\sigma_k(t)}{\\partial \\lambda_j}</math>. In this case\n\n: <math> J_{ij} = \\left.\\frac{\\partial\\sigma_j}{\\partial\\lambda_i}\\right|_{\\mathbf \\lambda=0} =  2\\left[\\hat{x}_{j\\alpha} - \\hat{x}_{j\\beta}\\right]\\left[\\frac{\\partial \\sigma_i}{\\partial x_{j\\alpha}} m_{j\\alpha}^{-1} - \\frac{\\partial \\sigma_i}{\\partial x_{j\\beta}} m_{j\\beta}^{-1} \\right]. </math>\n\nthen <math>\\lambda</math> is updated to\n:<math> \\mathbf \\lambda_j = - \\mathbf J^{-1}\\left[ \\left\\| \\hat{\\mathbf x}_{j\\alpha}(t+\\Delta t) - \\hat{\\mathbf x}_{j\\beta}(t+\\Delta t)\\right\\|^2 - d_j^2\\right].</math>\n\nAfter each iteration, the unconstrained particle positions are updated using\n\n:<math>\\hat{\\mathbf x}_i(t+\\Delta t) \\leftarrow \\hat{\\mathbf x}_i(t+\\Delta t) + \\sum_{k=1}^n \\lambda_k\\frac{\\partial \\sigma_k}{\\partial \\mathbf x_i}.</math>\n\nThe vector is then reset to\n\n:<math>\\underline{\\lambda} = \\mathbf 0.</math>\n\nThe above procedure is repeated until the solution of constraint equations, <math>\\sigma_k(t+\\Delta t)</math>, converges to a prescribed tolerance of a numerical error.\n\nAlthough there are a number of algorithms to compute the Lagrange multipliers, these difference is rely only on the methods to solve the system of equations. For this methods, [[quasi-Newton method]]s are commonly used.\n\n===The SETTLE algorithm===\nThe SETTLE algorithm<ref>{{cite journal | last = Miyamoto | first = S |author2=Kollman PA | year = 1992 | title = SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithm for Rigid Water Models | journal = Journal of Computational Chemistry | volume = 13 | issue = 8 | pages = 952–962 | doi = 10.1002/jcc.540130805}}</ref> solves the system of non-linear equations analytically for <math>n=3</math> constraints in constant time. Although it does not scale to larger numbers of constraints, it is very often used to constrain rigid water molecules, which are present in almost all biological simulations and are usually modelled using three constraints (e.g. SPC/E and [[TIP3P]] [[water model]]s).\n\n=== The SHAKE algorithm ===\nThe SHAKE algorithm was first developed for satisfying a bond geometry constraint during [[molecular dynamics]] simulations.<ref name=\"ryckaert_1977\" >{{cite journal | last = Ryckaert | first = J-P |author2=Ciccotti G|author3=Berendsen HJC | year = 1977 | title = Numerical Integration of the Cartesian Equations of Motion of a System with Constraints: Molecular Dynamics of ''n''-Alkanes | journal = Journal of Computational Physics | volume = 23 | issue = 3 | pages = 327–341 | doi = 10.1016/0021-9991(77)90098-5 | bibcode=1977JCoPh..23..327R| citeseerx = 10.1.1.399.6868 }}</ref>\n\nIn SHAKE algorithm, the system of non-linear constraint equations is solved using the [[Gauss–Seidel method]] which approximates the solution of the linear system of equations using the [[Newton iteration|Newton–Raphson method]];\n\n:<math>\\underline{\\lambda} = -\\mathbf J_\\sigma^{-1} \\underline{\\sigma}.</math>\n\nThis amounts to assuming that <math>\\mathbf J_\\sigma</math> is diagonally dominant and solving the <math>k</math>th equation only for the <math>k</math> unknown. In practice, we compute\n\n: <math>\n\\begin{align}\n\\lambda_k & \\leftarrow \\frac{\\sigma_k(t)}{\\partial \\sigma_k(t)/\\partial \\lambda_k}, \\\\[5pt]\n\\mathbf x_{k\\alpha} & \\leftarrow \\mathbf x_{k\\alpha} + \\lambda_k \\frac{\\partial \\sigma_k(t)}{\\partial \\mathbf x_{k\\alpha}}, \\\\[5pt]\n\\mathbf x_{k\\beta} & \\leftarrow \\mathbf x_{k\\beta} + \\lambda_k \\frac{\\partial \\sigma_k(t)}{\\partial \\mathbf x_{k\\beta}},\n\\end{align}\n</math>\n\nfor all <math>k=1\\ldots n</math> iteratively until the constraint equations <math>\\sigma_k(t+\\Delta t)</math> are solved to a given tolerance.\n\nThe calculation cost of each iteration is <math>\\mathcal O(n)</math>, and the iterations themselves converge linearly.\n\nA non[[iterative]] form of SHAKE was developed later on.<ref>{{cite journal | last = Yoneya | first = M |author2=Berendsen HJC|author3=Hirasawa K | title = A Noniterative Matrix Method for Constraint Molecular-Dynamics Simulations | journal = Molecular Simulations | volume = 13 | issue = 6 | pages = 395–405 | doi = 10.1080/08927029408022001 | year = 1994 }}</ref>\n\nSeveral variants of the SHAKE algorithm exist. Although they differ in how they compute or apply the constraints themselves, the constraints are still modelled using [[Lagrange multipliers]] which are computed using the [[Gauss–Seidel method]].\n\nThe original SHAKE algorithm is limited to mechanical systems with a [[tree structure]] (i.e., no closed loops of constraints), while a later extension of the method, QSHAKE ([[Quaternion]] SHAKE) was developed to amend the former method.<ref name=\"forester_1998\" >{{cite journal | last = Forester | first = TR |author2=Smith W | year = 1998 | title = SHAKE, Rattle, and Roll: Efficient Constraint Algorithms for Linked Rigid Bodies | journal = Journal of Computational Chemistry | volume = 19 | pages = 102–111 | doi = 10.1002/(SICI)1096-987X(19980115)19:1<102::AID-JCC9>3.0.CO;2-T }}</ref>  It works satisfactorily for ''rigid'' loops such as [[aromatic ring]] systems but fails for flexible loops, such as when a [[protein]] that has a disulfide bond.<ref>{{cite journal | last = McBride | first = C |author2=Wilson MR|author3=Howard JAK | year = 1998 | title = Molecular dynamics simulations of liquid crystal phases using atomistic potentials | journal = Molecular Physics | volume = 93 | issue = 6 | pages = 955–964 | doi = 10.1080/002689798168655| bibcode = 1998MolPh..93..955C }}</ref>\n\nFurther extensions include RATTLE,<ref name=rattle>{{cite journal | first=Hans C.| last=Andersen | title=RATTLE: A \"Velocity\" Version of the SHAKE Algorithm for Molecular Dynamics Calculations | journal=Journal of Computational Physics | year=1983 | volume=52 | issue=1 | pages=24–34 | doi=10.1016/0021-9991(83)90014-1 |bibcode = 1983JCoPh..52...24A | citeseerx=10.1.1.459.5668 }}</ref> WIGGLE,<ref name=wiggle>{{cite journal| first=Sang-Ho | last=Lee |author2=Kim Palmo |author3=Samuel Krimm  | title=WIGGLE: A new constrained molecular dynamics algorithm in Cartesian coordinates | journal=Journal of Computational Physics | volume=210 | issue=1 | year=2005 | pages=171–182 | doi=10.1016/j.jcp.2005.04.006 |bibcode = 2005JCoPh.210..171L }}</ref> and MSHAKE.<ref name=mshake>{{cite journal| first=S. G. | last=Lambrakos |author2=J. P. Boris |author3=E. S. Oran |author4=I. Chandrasekhar |author5=M. Nagumo  | title=A Modified SHAKE algorithm for Maintaining Rigid Bonds in Molecular Dynamics Simulations of Large Molecules | journal=Journal of Computational Physics | volume=85 | year=1989| issue=2 | pages=473–486 | doi= 10.1016/0021-9991(89)90160-5 |bibcode = 1989JCoPh..85..473L }}</ref>\n\nWhile RATTLE works the same way as SHAKE,<ref name=shake-symp>{{cite journal| first=Benedict | last=Leimkuhler |author2=Robert Skeel | title=Symplectic numerical integrators in constrained Hamiltonian systems | journal=Journal of Computational Physics | volume=112 | issue=1 | year=1994 | pages=117–125 | doi=10.1006/jcph.1994.1085 |bibcode = 1994JCoPh.112..117L }}</ref> yet using the [[Velocity Verlet]] time integration scheme, WIGGLE extends SHAKE and RATTLE by using an initial estimate for the [[Lagrange multipliers]] <math>\\lambda_k</math> based on the particle velocities. It is worth mentioning that MSHAKE computes corrections on the constraint ''forces'', achieving better convergence.\n\nA final modificatio to the SHAKE algorithm is the P-SHAKE algorithm<ref name=p-shake>{{cite journal| first=Pedro | last=Gonnet | title=P-SHAKE: A quadratically convergent SHAKE in <math>\\mathcal O(n^2)</math> | journal=Journal of Computational Physics | volume=220 | year=2007| issue=2 | pages=740–750 | doi=10.1016/j.jcp.2006.05.032 |bibcode = 2007JCoPh.220..740G }}</ref> that is applied to very rigid or semi-rigid [[molecule]]s. P-SHAKE computes and updates a pre-conditioner which is applied to the constraint gradients before the SHAKE iteration, causing the Jacobian <math>\\mathbf J_\\sigma</math> to become diagonal or strongly diagonally dominant. The thus de-coupled constraints converge much faster (quadratically as opposed to linearly) at a cost of <math>\\mathcal O(n^2)</math>.\n\n===The M-SHAKE algorithm===\nThe M-SHAKE algorithm<ref name=kraeutler_2001>{{cite journal|last=Kräutler|first=Vincent|author2=W. F. van Gunsteren |author3=P. H. Hünenberger |title=A Fast SHAKE Algorithm to Solve Distance Constraint Equations for Small Molecules in Molecular Dynamics Simulations|journal=Journal of Computational Chemistry|volume=22|issue=5|pages=501–508|year=2001|doi=10.1002/1096-987X(20010415)22:5<501::AID-JCC1021>3.0.CO;2-V}}</ref> solves the non-linear system of equations using [[Newton's method]] directly. In each iteration, the linear system of equations\n\n:<math>\\underline{\\lambda} = -\\mathbf J_\\sigma^{-1} \\underline{\\sigma}</math>\n\nis solved exactly using an [[LU decomposition]]. Each iteration costs <math>\\mathcal O(n^3)</math> operations, yet the solution converges [[Quadratic convergence|quadratically]], requiring fewer iterations than SHAKE.\n\nThis solution was first proposed in 1986 by [[Giovanni Ciccotti|Ciccotti]] and Ryckaert<ref name=ciccotti_1986>{{cite journal|last=Ciccotti|first=G.|author2=J. P. Ryckaert|title=Molecular Dynamics Simulation of Rigid Molecules|journal=Computer Physics Reports|volume=4|year=1986|issue=6|pages=345–392|doi=10.1016/0167-7977(86)90022-5|bibcode = 1986CoPhR...4..346C }}</ref> under the title \"the matrix method\", yet differed in the solution of the linear system of equations. Ciccotti and Ryckaert suggest inverting the matrix <math>\\mathbf J_\\sigma</math> directly, yet doing so only once, in the first iteration. The first iteration then costs <math>\\mathcal O(n^3)</math> operations, whereas the following iterations cost only <math>\\mathcal O(n^2)</math> operations (for the matrix-vector multiplication). This improvement comes at a cost though, since the Jacobian is no longer updated, convergence is only [[Linear convergence|linear]], albeit at a much faster rate than for the SHAKE algorithm.\n\nSeveral variants of this approach based on sparse matrix techniques were studied by Barth ''et al.''.<ref name=barthkuczeraetal>{{cite journal|last=Barth|first=Eric|author2=K. Kuczera |author3=B. Leimkuhler |author4=R. Skeel |title=Algorithms for constrained molecular dynamics |journal=Journal of Computational Chemistry|volume=16|issue=10|pages=1192–1209|year=1995|doi=10.1002/jcc.540161003}}</ref>\n\n===The SHAPE algorithm===\n\nThe SHAPE algorithm<ref name=Tao_2012>{{cite journal|last=Tao|first=Peng|author2=Xiongwu Wu |author3=Bernard R. Brooks |title= Maintain rigid structures in Verlet based Cartesian molecular dynamics simulations|journal= The Journal of Chemical Physics|volume=137|issue=13|pages= 134110|year=2012|doi= 10.1063/1.4756796|pmid=23039588|bibcode = 2012JChPh.137m4110T |pmc=3477181}}</ref> is a multicenter analog of SHAKE for constraining rigid bodies of three or more centers. Like SHAKE, an unconstrained step is taken and then corrected by directly calculating and applying the rigid body rotation matrix that satisfies:\n\n: <math> L^\\text{rigid} \\left( t + \\frac{\\Delta t} 2 \\right) = L^\\text{nonrigid} \\left( t + \\frac{\\Delta t} 2 \\right)</math>\n\nThis approach involves a single 3x3 matrix diagonalization followed by three or four rapid Newton iterations to determine the rotation matrix.  SHAPE provides the identical trajectory that is provided with fully converged iterative SHAKE, yet it is found to be more efficient and more accurate than SHAKE when applied to systems involving three or more centers. It extends the ability of SHAKE like constraints to linear systems with three or more atoms, planar systems with four or more atoms, and to significantly larger rigid structures where SHAKE is intractable. It also allows rigid bodies to be linked with one or two common centers (e.g. peptide planes) by solving rigid body constraints iteratively in the same basic manner that SHAKE is used for atoms involving more than one SHAKE constraint.\n\n===The LINCS algorithm===\n\nAn alternative constraint method, LINCS (Linear Constraint Solver) was developed in 1997 by Hess, Bekker, Berendsen and Fraaije,<ref name=\"hess_1997\" >{{cite journal | last = Hess | first = B |author2=Bekker H |author3=Berendsen HJC |author4=Fraaije JGEM  | year = 1997 | title = LINCS: A Linear Constraint Solver for Molecular Simulations | journal = Journal of Computational Chemistry | volume = 18 | issue = 12 | pages = 1463–1472 | doi = 10.1002/(SICI)1096-987X(199709)18:12<1463::AID-JCC4>3.0.CO;2-H| citeseerx = 10.1.1.48.2727 }}</ref> and was based on the 1986 method of Edberg, Evans and Morriss (EEM),<ref>{{cite journal | last = Edberg | first = R |author2=Evans DJ|author3=Morriss GP | year = 1986 | title = Constrained Molecular-Dynamics Simulations of Liquid Alkanes with a New Algorithm | journal = Journal of Chemical Physics | volume = 84 | issue = 12 | pages = 6933–6939 | doi = 10.1063/1.450613|bibcode = 1986JChPh..84.6933E }}</ref> and a modification thereof by Baranyai and Evans (BE).<ref>{{cite journal | last = Baranyai | first = A |author2=Evans DJ | year = 1990 | title = New Algorithm for Constrained Molecular-Dynamics Simulation of Liquid Benzene and Naphthalene | journal = Molecular Physics | volume = 70 | issue = 1 | pages = 53–63 | doi = 10.1080/00268979000100841|bibcode = 1990MolPh..70...53B }}</ref>\n\nLINCS applies [[Lagrange multipliers]] to the constraint forces and solves for the multipliers by using a series expansion to approximate the inverse of the Jacobian <math>\\mathbf J_\\sigma</math>:\n\n:<math>(\\mathbf I - \\mathbf J_\\sigma)^{-1} = \\mathbf I + \\mathbf J_\\sigma + \\mathbf J_\\sigma^2 + \\mathbf J_\\sigma^3 + \\cdots</math>\n\nin each step of the Newton iteration. This approximation only works for matrices with [[Eigenvalues]] smaller than 1, making the LINCS algorithm suitable only for molecules with low connectivity.\n\nLINCS has been reported to be 3-4 times faster than SHAKE.<ref name=\"hess_1997\" />\n\n==Hybrid methods==\n\nHybrid methods have also been introduced in which the constraints are divided into two groups; the constraints of the first group are solved using internal coordinates whereas those of the second group are solved using constraint forces, e.g., by a Lagrange multiplier or projection method.<ref name=\"mazur_1999\" >{{cite journal | last = Mazur | first = AK | year = 1999 | title = Symplectic integration of closed chain rigid body dynamics with internal coordinate equations of motion | journal = Journal of Chemical Physics | volume = 111 | issue = 4 | pages = 1407–1414 | doi = 10.1063/1.479399|bibcode = 1999JChPh.111.1407M }}</ref><ref>{{cite journal | last = Bae | first = D-S |author2=Haug EJ | year = 1988 | title = A Recursive Formulation for Constrained Mechanical System Dynamics: Part II. Closed Loop Systems | journal = Mechanics of Structures and Machines | volume = 15 | issue = 4 | pages = 481–506| doi = 10.1080/08905458708905130 }}</ref><ref>{{cite journal | last = Rodriguez | first = G |author2=Jain A|author3=Kreutz-Delgado K | year = 1991 | title = A Spatial Operator Algebra for Manipulator Modeling and Control | journal = The International Journal of Robotics Research | volume = 10 | issue = 4 | pages = 371–381 | doi = 10.1177/027836499101000406}}</ref>  This approach was pioneered by [[Joseph Louis Lagrange|Lagrange]],<ref name=\"lagrange_1788\" /> and result in ''Lagrange equations of the mixed type''.<ref>{{cite book | last = Sommerfeld | first = Arnold | authorlink = Arnold Sommerfeld | year = 1952 | title = Lectures on Theoretical Physics, Vol. I: Mechanics | publisher = Academic Press | location = New York | isbn = 978-0-12-654670-5}}</ref>\n\n==See also==\n\n* [[Molecular dynamics]]\n* [[List of software for molecular mechanics modeling|Software for molecular mechanics modeling]]\n\n==References and footnotes==\n{{Reflist}}\n\n{{DEFAULTSORT:Constraint Algorithm}}\n[[Category:Molecular dynamics]]\n[[Category:Computational chemistry]]\n[[Category:Molecular physics]]\n[[Category:Computational physics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Coupled mode theory",
      "url": "https://en.wikipedia.org/wiki/Coupled_mode_theory",
      "text": "'''Coupled mode theory''' ('''CMT''') is a perturbational approach for analyzing the coupling of [[vibration]]al systems (mechanical, optical, electrical, etc.) in space or in time. Coupled mode theory allows a wide range of devices and systems to be modeled as one or more coupled resonators. In optics, such systems include laser cavities, [[photonic crystal]] slabs, [[metamaterials]], and [[Optical ring resonators|ring resonators]].\n\n== History ==\n\nCoupled mode theory first arose in the 1950s in the works of Miller on microwave [[transmission lines]],<ref name=Miller54>S.E.Miller,\"Coupled wave theory and waveguide applications.\", ''Bell System Technical Journal'', 1954</ref> Pierce on [[electron beam]]s,<ref>J. R. Pierce, \"Coupling of modes of propagations\", ''Journal of Applied Physics'', 25, 1954</ref> and Gould on [[backward wave oscillator]]s.<ref name=Gould1>R.W. Gould, \"A coupled mode description of the backward-wave oscillator and the Kompfner dip condition\" ''I.R.E. Trans. Electron Devices'', vol. PGED-2, pp. 37–42, 1955.</ref> This put in place the mathematical foundations for the modern formulation expressed by [[H. A. Haus]] ''et al.'' for optical waveguides.<ref>Haus, H., et al. \"Coupled-mode theory of optical waveguides.\" Journal of Lightwave Technology 5.1 (1987): 16-23.</ref><ref name=Haus1>H. A. Haus, W. P. Huang. \"Coupled Mode Theory.\"Proceedings of the IEEE, Vol 19, No 10, October 1991.</ref>\n\nIn the late 1990s and early 2000s, the field of [[nanophotonics]] has revitalized interest in coupled mode theory. Coupled mode theory has been used to account for the [[Fano resonance]]s in photonic crystal slabs<ref name=Fan1>S. Fan, W. Suh, J. Joannopoulos, \"Temporal coupled-mode theory for the Fano resonance in optical resonators,\" JOSA A, vol. 20, no. 3, pp. 569–572, 2003.</ref> and has also been modified to account for optical resonators with non-orthogonal modes.<ref name=Suh1>W. Suh, Z. Wang, and S. Fan, \"Temporal coupled-mode theory and the presence of non-orthogonal modes in lossless multimode cavities,\" ''Quantum Electronics, IEEE Journal of'', vol. 40, no. 10, pp. 1511–1518, 2004</ref>\n\n== Overview ==\nThe oscillatory systems to which coupled mode theory applies are described by second order partial differential equations (e.g. a mass on a spring, an RLC circuit).  CMT allows the second order differential equation to be expressed as one or more uncoupled first order differential equations. The following assumptions are generally made with CMT:\n\n* Linearity\n* Time-reversal symmetry\n* Time-invariance\n* Weak mode coupling (small perturbation of uncoupled modes)\n* Energy conservation\n\n== Formulation ==\nThe formulation of the coupled mode theory is based on the development of the solution to an electromagnetic problem into modes. Most of the time it is eigenmodes which are taken in order to form a complete base. The choice of the base and the adoption of certain hypothesis like parabolic approximation differs from formulation to formulation.\nThe classification proposed by <ref name=Bar2002>Barybin and Dmitriev,\"Modern Electrodynamics and Coupled-mode theory\",2002</ref> of the different formulation is as follows:\n#The choice of starting differential equation. some of the coupled mode theories are derived directly from the Maxwell differential equations <ref name=Hardy54>Hardy and Streifer, \"Coupled mode theory of parallel waveguides\", Journal of Lightwave Technology,1985</ref><ref name=snyder83>A. W. Snyder and [[J. D. Love]], \"Optical waveguide Theory\",Chapman and Hall, 1983</ref> ([[Maxwell's equations|here]]) although others use simplifications in order to obtain a [[Helmholtz equation]].\n#The choice of principle to derive the equations of the CMT. Either the reciprocity theorem <ref name=Hardy54/><ref name=snyder83/> or the [[variational principle]] have been used.\n#The choice of orthogonality product used to establish the eigenmode base. Some references use the unconjugated form <ref name=Hardy54/> and others the complex-conjugated form.<ref name=snyder83/>\n#Finally, the choice of the form of the equation, either vectorial <ref name=Hardy54/><ref name=snyder83/> or scalar.\n\nWhen n modes of an [[electromagnetic]] wave propagate through a media in the direction ''z'' without loss the power transported by each mode is described by a modal power Pm. At a given frequency&nbsp;''ω''.\n\n: <math> P^\\omega(z) = \\sum_m^n P^\\omega_m(z) = \\frac 1 4 \\sum_m^n N^\\omega_m \\left| a^\\omega_m(z) \\right|^2 \\,\\!</math>\n\nwhere ''N''<sub>''m''</sub> is the norm of the ''m''th mode and ''a''<sub>''m''</sub> is the modal amplitude.\n\n==References==\n{{reflist}}\n\n== External links ==\n* [http://wmm.computational-photonics.eu/cmt.html WMM mode solver manual on couple mode theory]\n* [https://web.archive.org/web/20140304074633/http://emlab.utep.edu/ee5390em21.htm Coupled-Mode Theory and Devices (see and listen to Lectures 5 and 6)]\n\n{{DEFAULTSORT:Coupled Mode Theory}}\n[[Category:Electrodynamics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Courant–Friedrichs–Lewy condition",
      "url": "https://en.wikipedia.org/wiki/Courant%E2%80%93Friedrichs%E2%80%93Lewy_condition",
      "text": "In [[mathematics]], the '''Courant–Friedrichs–Lewy (CFL) condition''' is a necessary condition for convergence while solving certain [[partial differential equation]]s (usually [[Hyperbolic partial differential equation|hyperbolic PDE]]s) numerically. It arises in the [[numerical analysis]] of [[temporal discretisation|explicit time integration]] schemes, when these are used for the numerical solution. As a consequence, the time step must be less than a certain time in many [[explicit method|explicit]] time-marching [[computer simulation]]s, otherwise the simulation produces incorrect results. The condition is named after [[Richard Courant]], [[Kurt Friedrichs]], and [[Hans Lewy]] who described it in their 1928 paper.<ref>See reference {{harvnb|Courant|Friedrichs|Lewy|1928}}. There exists also an [[English language|English]] [[translation]] of the 1928 [[German language|German]] original: see references {{harvnb|Courant|Friedrichs|Lewy|1956}} and {{harvnb|Courant|Friedrichs|Lewy|1967}}.</ref>\n\n==Heuristic description==\nThe principle behind the condition is that, for example, if a wave is moving across a discrete spatial grid and we want to compute its [[amplitude]] at discrete time steps of equal duration,<ref>This situation commonly occurs when a [[hyperbolic partial differential equation|hyperbolic partial differential operator]] has been [[approximation theory|approximated]] by a [[Finite difference|finite difference equation]], which is then solved by [[numerical linear algebra]] methods.</ref> then this duration must be less than the time for the wave to travel to adjacent grid points. As a corollary, when the grid point separation is reduced, the upper limit for the time step also decreases. In essence, the numerical domain of dependence of any point in space and time (as determined by initial conditions and the parameters of the approximation scheme) must include the analytical domain of dependence (wherein the initial conditions have an effect on the exact value of the solution at that point) to assure that the scheme can access the information required to form the solution.\n\n==The CFL condition==\nTo make a reasonably formally precise statement of the condition, it is necessary to define the following quantities:\n*''Spatial coordinate'': one of the [[coordinate]]s of the [[physical space]] in which the problem is posed\n*''Spatial dimension of the problem'': the number <math>n</math> of [[Dimension (mathematics)|spatial dimensions]], i.e., the number of spatial [[coordinate]]s of the [[physical space]] where the problem is posed. Typical values are <math>n=1</math>, <math>n=2</math> and <math>n=3</math>.\n*''Time'': the [[coordinate]], acting as a [[parameter]], which describes the evolution of the system, distinct from the spatial coordinates\nThe spatial coordinates and the time are discrete-valued independent [[Variable (mathematics)|variables]], which are placed at regular distances called the ''interval length''<ref>This quantity is not necessarily the same for each spatial variable, as it is shown in \"[[Courant–Friedrichs–Lewy condition#The two and general ''n''–dimensional case|The two and general ''n''–dimensional case]]\" section of this entry: it can be selected to somewhat relax the condition.</ref>  and the ''time step'', respectively. Using these names, the CFL condition relates the length of the time step to a function of the interval lengths of each spatial coordinate and of the maximum speed that information can travel in the physical space.\n\nOperatively, the CFL condition is commonly prescribed for those terms of the [[finite-difference approximation]] of general [[partial differential equation]]s that model the [[advection]] phenomenon.<ref>Precisely, this is the hyperbolic part of the PDE under analysis.</ref>\n\n===The one-dimensional case===\nFor one-dimensional case, the CFL has the following form:\n\n: <math>C = \\frac {u\\,\\Delta t} {\\Delta x} \\leq C_\\max </math>\n\nwhere the [[dimensionless number]] <math>C</math> is called the '''Courant number''',\n\n*<math>u</math> is the [[Magnitude (mathematics)|magnitude]] of the velocity (whose [[Dimensional analysis#Definition|dimension]] is length/time)\n*<math>\\Delta t</math> is the time step (whose [[Dimensional analysis#Definition|dimension]] is time)\n*<math>\\Delta x</math> is the length interval (whose [[Dimensional analysis#Definition|dimension]] is length).\n\nThe value of <math>C_\\max</math> changes with the method used to solve the discretised equation, especially depending on whether the method is [[Explicit and implicit methods|explicit or implicit]]. If an explicit (time-marching) solver is used then typically <math>C_\\max = 1</math>. Implicit (matrix) solvers are usually less sensitive to numerical instability and so larger values of <math>C_\\max</math> may be tolerated.\n\n===The two and general ''n''-dimensional case===\nIn the [[Dimension (mathematics)|two-dimensional]] case, the CFL condition becomes\n\n:<math>C = \\frac {u_ x\\,\\Delta t}{\\Delta x} + \\frac {u_ y\\,\\Delta t}{\\Delta y} \\leq C_\\max </math>\n\nwith obvious meaning of the symbols involved. By analogy with the two-dimensional case, the general CFL condition for the <math>n</math>-dimensional case is the following one:\n\n:<math>C = \\Delta t \\left( \\sum_{i=1}^n\\frac{u_{x_i}}{\\Delta x_i} \\right) \\leq C_\\max. </math>\n\nThe interval length is not required to be the same for each spatial variable <math>\\Delta x_i, i = 1, \\ldots , n</math>. This \"[[Degrees of freedom (physics and chemistry)|degree of freedom]]\" can be used to somewhat optimize the value of the time step for a particular problem, by varying the values of the different interval to keep it not too small.\n\n== Notes ==\n{{reflist|30em}}\n\n== References ==\n*{{Citation\n  | last = Courant\n  | first = R.\n  | author-link = Richard Courant\n  | last2 = Friedrichs\n  | first2 = K.\n  | author2-link = Kurt Otto Friedrichs\n  | last3 = Lewy\n  | first3 = H.\n  | author3-link = Hans Lewy\n  | title = Über die partiellen Differenzengleichungen der mathematischen Physik\n  | journal = [[Mathematische Annalen]]\n  | volume = 100\n  | issue = 1\n  | pages = 32–74\n  | year = 1928\n  | month =\n  | language = German\n  | url = http://resolver.sub.uni-goettingen.de/purl?GDZPPN002272636\n  | doi = 10.1007/BF01448839\n  | jfm = 54.0486.01\n  | mr = 1512478\n |bibcode = 1928MatAn.100...32C }}.\n*{{Citation\n  | last = Courant\n  | first = R.\n  | author-link = Richard Courant\n  | last2 = Friedrichs\n  | first2 = K.\n  | author2-link = Kurt Otto Friedrichs\n  | last3 = Lewy\n  | first3 = H.\n  | author3-link = Hans Lewy\n  | title = On the partial difference equations of mathematical physics\n  | place = New York\n  | publisher = AEC Computing and Applied Mathematics Centre – [[Courant Institute of Mathematical Sciences]]\n  | series = AEC Research and Development Report\n  | volume = NYO-7689\n  | origyear = 1928\n  |date=September 1956\n  | edition = \n  | pages = V + 76\n  | url = https://archive.org/details/onpartialdiffere00cour\n  | archiveurl = https://archive.org/stream/onpartialdiffere00cour#page/n0/mode/2up\n  | archivedate = October 23, 2008\n  | doi = \n  | id = \n  | isbn = \n}}.: translated from the [[German language|German]] by Phyllis Fox. This is an earlier version of the paper {{harvnb|Courant|Friedrichs|Lewy|1967}}, circulated as a research report.\n*{{Citation\n  | last = Courant\n  | first = R.\n  | author-link = Richard Courant\n  | last2 = Friedrichs\n  | first2 = K.\n  | author2-link = Kurt Otto Friedrichs\n  | last3 = Lewy\n  | first3 = H.\n  | author3-link = Hans Lewy\n  | title = On the partial difference equations of mathematical physics\n  | journal = [[IBM Journal of Research and Development]]\n  | volume = 11\n  | issue = 2\n  | pages = 215–234\n  | origyear = 1928\n  |date=March 1967\n  | url = http://domino.research.ibm.com/tchjr/journalindex.nsf/a3807c5b4823c53f85256561006324be/769774a3c9f3685f85256bfa00683f8a!OpenDocument\n  | mr = 0213764\n  | zbl = 0145.40402\n|bibcode = 1967IBMJ...11..215C |doi = 10.1147/rd.112.0215 }}. A freely downloadable copy can be found [http://www.stanford.edu/class/cme324/classics/courant-friedrichs-lewy.pdf here].\n\n== External links ==\n*{{springer\n | title=Courant–Friedrichs–Lewy condition\n | id= C/c026760\n | last= Bakhvalov\n | first= N. S.\n | author-link= Nikolai Sergeevich Bakhvalov\n}}\n*{{MathWorld |title=Courant-Friedrichs-Lewy Condition |id=Courant-Friedrichs-LewyCondition}}\n\n{{DEFAULTSORT:Courant-Friedrichs-Lewy condition}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Cyclic reduction",
      "url": "https://en.wikipedia.org/wiki/Cyclic_reduction",
      "text": "'''Cyclic reduction''' is a [[numerical method]] for solving large linear systems by repeatedly splitting the problem.  Each step eliminates even or odd rows and columns of a matrix and remains in a similar form.  The elimination step is relatively expensive but splitting the problem allows parallel computation.\n\n==Applicability==\nThe method only applies to matrices that can be represented as a (block) [[Toeplitz matrix]], such problems often arise in implicit solutions for partial differential equations on a lattice.  For example fast solvers for [[Poisson's equation]] express the problem as solving a tridiagonal matrix, discretising the solution on a regular grid.\n\n==Accuracy==\nSystems which have good numerical stability initially tend to get better with each step to a point where a good approximate solution can be given,<ref>Walter Gander and Gene H. Golub, [http://www.inf.ethz.ch/personal/gander/papers/cyclic.pdf Cyclic Reduction – History and Applications], Proceedings of the Workshop on Scientific Computing 10–12 March 1997</ref> but because the special matrix form must be preserved pivoting cannot be performed to improve numerical accuracy.\n\n==Comparison to multigrid==\nThe method is not iterative, it seeks an exact solution to the linear problem consistent with the given boundary values, contrast that with the similar but computationally cheaper [[multigrid method]] which propagates error-correction estimates down and allows for different relaxation parameters at different scales, the iterative aspect allowing better incorporation of non-linear features.\n\n==Combination with [[fast Fourier transform]] FFT==\nTransforming from the spatial domain and restating the PDE is called a [[spectral method]], Fourier analysis and cyclic reduction are combined in the FACR algorithm<ref>P. N. Swarztrauber, The method of cyclic reduction, Fourier analysis and the FACR algorithm for the discrete solution of Poisson's equation on a rectangle, Society for Industrial and Applied Mathematics' SIAM Review 19 pp.&nbsp;490–501 1977</ref> which is explained in Numerical Recipes – see 19.4 Fourier and Cyclic Reduction Methods for Boundary Value Problems.<ref>W. H. Press, S. A. Teukolsky, W. T. Vetterling, B. P. Flannery [http://www2.units.it/ipl/students_area/imm2/files/Numerical_Recipes.pdf Numerical Recipes In 'C': The Art Of Scientific Computing] p 885 {{ISBN|0-521-43108-5}} Cambridge University Press 1988–1992</ref>\n\n==Notes and references==\n\n{{Reflist}}\n\n{{Numerical PDE}}\n\n[[Category:Numerical differential equations]]\n\n\n{{Mathanalysis-stub}}"
    },
    {
      "title": "Diffuse element method",
      "url": "https://en.wikipedia.org/wiki/Diffuse_element_method",
      "text": "In [[numerical analysis]] the '''diffuse element method''' ('''DEM''') or simply '''diffuse approximation''' is a [[meshfree methods|meshfree method]].\n\nThe diffuse element method was developed by B. Nayroles, G. Touzot and Pierre Villon at the Universite de Technologie de Compiegne, in 1992.\nIt is in concept rather similar to the much older [[smoothed particle hydrodynamics]]. In the paper they describe a \"diffuse approximation method\", a method for [[function approximation]] from a given set of points.\nIn fact the method boils down to the well-known [[moving least squares]] for the particular case of a global approximation (using all available data points). Using this function approximation method, [[partial differential equation]]s and thus [[fluid dynamic]] problems can be solved. For this, they coined the term diffuse element method (DEM).\nAdvantages over [[finite element method]]s are that DEM doesn't rely on a grid, and is more precise in the evaluation of the derivatives of the reconstructed functions.\n\n== See also ==\n* [[Computational fluid dynamics]]\n\n== References ==\n* [http://www.springerlink.com/content/v7164702238848p1/ Generalizing the finite element method: diffuse approximation and diffuse elements], B Nayroles, G Touzot. Pierre Villon, P, Computational Mechanics Volume 10, pp 307-318, 1992\n\n{{fluiddynamics-stub}}\n\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Direct multiple shooting method",
      "url": "https://en.wikipedia.org/wiki/Direct_multiple_shooting_method",
      "text": "In the area of [[mathematics]] known as [[numerical ordinary differential equations]], the '''direct multiple shooting method''' is a [[numerical method]] for the solution of [[boundary value problem]]s. The method divides the interval over which a solution is sought into several smaller intervals, solves an initial value problem in each of the smaller intervals, and imposes additional matching conditions to form a solution on the whole interval. The method constitutes a significant improvement in distribution of nonlinearity and [[numerical stability]] over single [[shooting method]]s.\n\n== Single shooting methods ==\n\nShooting methods can be used to solve boundary value problems (BVP) like\n:<math> y''(t) = f(t, y(t), y'(t)), \\quad y(t_a) = y_a, \\quad y(t_b) = y_b, </math>\nin which the time points ''t''<sub>a</sub> and ''t''<sub>b</sub> are known and we seek \n:<math>y(t),\\quad t \\in (t_a,t_b).</math>\n\nSingle shooting methods proceed as follows. Let ''y''(''t''; ''t''<sub>0</sub>, ''y''<sub>0</sub>) denote the solution of the initial value problem (IVP)\n:<math> y''(t) = f(t, y(t), y'(t)), \\quad y(t_0) = y_0, \\quad y'(t_0) = p </math>\nDefine the function ''F''(''p'') as the difference between ''y''(''t''<sub>''b''</sub>; ''p'') and the specified boundary value ''y''<sub>''b''</sub>: ''F''(''p'') = ''y''(''t''<sub>''b''</sub>; ''p'') − ''y''<sub>''b''</sub>. Then for every solution (''y''<sub>a</sub>, ''y''<sub>b</sub>) of the boundary value problem we have ''y''<sub>a</sub>=''y''<sub>0</sub> while ''y''<sub>b</sub> corresponds to a [[root of a function|root]] of ''F''. This root can be solved by any [[root-finding method]] given that certain method-dependent prerequisites are satisfied. This often will require initial guesses to ''y''<sub>a</sub> and ''y''<sub>b</sub>. Typically, analytic root finding is impossible and iterative methods such as [[Newton's method]] are used for this task.\n\nThe application of single shooting for the numerical solution of boundary value problems suffers from several drawbacks.\n\n* For a given initial value ''y''<sub>0</sub> the solution of the IVP obviously must exist on the interval [''t''<sub>a</sub>,''t''<sub>b</sub>] so that we can evaluate the function ''F'' whose root is sought.\nFor highly nonlinear or unstable ODEs, this requires the initial guess ''y''<sub>0</sub> to be extremely close to an actual but unknown solution ''y''<sub>a</sub>. Initial values that are chosen slightly off the true solution may lead to singularities or breakdown of the ODE solver method. Choosing such solutions is inevitable in an iterative root-finding method, however.\n*  Finite precision numerics may make it impossible at all to find initial values that allow for the solution of the ODE on the whole time interval.\n*  The nonlinearity of the ODE effectively becomes a nonlinearity of ''F'', and requires a root-finding technique capable of solving nonlinear systems. Such methods typically converge slower as nonlinearities become more severe. The boundary value problem solver's performance suffers from this.\n*  Even stable and well-conditioned ODEs may make for unstable and ill-conditioned BVPs. A slight alteration of the initial value guess ''y''<sub>0</sub> may generate an extremely large step in the ODEs solution ''y''(''t''<sub>b</sub>; ''t''<sub>a</sub>, ''y''<sub>0</sub>) and thus in the values of the function ''F'' whose root is sought. Non-analytic root-finding methods can seldom cope with this behaviour.\n\n== Multiple shooting ==\n\nA direct multiple shooting method partitions the interval [''t<sub>a</sub>'', ''t<sub>b</sub>''] by introducing additional grid points\n:<math> t_a = t_0 < t_1 < \\cdots < t_N = t_b </math>.\nThe method starts by guessing somehow the values of ''y'' at all grid points ''t<sub>k</sub>'' with 0 ≤ ''k'' ≤ ''N'' &minus; 1. Denote these guesses by ''y<sub>k</sub>''. Let ''y''(''t''; ''t<sub>k</sub>'', ''y<sub>k</sub>'') denote the solution emanating from the ''k''th grid point, that is, the solution of the initial value problem\n:<math> y'(t) = f(t, y(t)), \\quad y(t_k) = y_k. </math>\nAll these solutions can be pieced together to form a continuous trajectory if the values ''y'' match at the grid points. Thus, solutions of the boundary value problem correspond to solutions of the following system of ''N'' equations:\n:<math> \\begin{align}\n& y(t_1; t_0, y_0) = y_1 \\\\\n& \\qquad\\qquad\\vdots \\\\\n& y(t_{N-1}; t_{N-2}, y_{N-2}) = y_{N-1} \\\\\n& y(t_N; t_{N-1}, y_{N-1}) = y_b.\n\\end{align}\n</math>\nThe central ''N''&minus;2 equations are the matching conditions, and the first and last equations are the conditions ''y''(''t''<sub>a</sub>) = ''y''<sub>a</sub> and ''y''(''t''<sub>b</sub>) = ''y''<sub>b</sub> from the boundary value problem. The multiple shooting method solves the boundary value problem by solving this system of equations. Typically, a modification of the [[Newton's method]] is used for the latter task.\n\n=== Multiple shooting and parallel-in-time methods ===\nMultiple shooting has been adopted to derive [[Parallel computing|parallel]] solvers for [[initial value problem]]s.<ref>{{cite journal\n| last       = Kiehl\n| first      =  Martin\n| date       = 1994\n| title      = Parallel multiple shooting for the solution of initial value problems\n| journal    = Parallel Computing\n| volume     = 20\n| issue      = 3\n| pages      =  275–295\n| bibcode    = \n| doi        = 10.1016/S0167-8191(06)80013-X\n}}</ref>\nFor example, the [[Parareal]] parallel-in-time integration method can be derived as a multiple shooting algorithm with a special approximation of the [[Jacobian matrix and determinant|Jacobian]].<ref name=\"gander2007\">{{cite journal\n| last       = Gander\n| first      =  Martin J.\n| last2      = Vandewalle\n| first2     = Stefan\n| date       = 2007\n| title      = Analysis of the Parareal Time‐Parallel Time‐Integration Method\n| journal    = SIAM Journal on Scientific Computing\n| volume     = 29\n| issue      = 2\n| pages      = 556–578\n| bibcode    = \n| doi        = 10.1137/05064607X\n| citeseerx= 10.1.1.92.9922\n}}</ref>\n\n== References ==\n{{Reflist}}\n* {{Citation | last1=Stoer | first1=Josef | last2=Bulirsch | first2=Roland | title=Introduction to Numerical Analysis | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=3rd | isbn=978-0-387-95452-3 | year=2002}}. See Sections 7.3.5 and further.\n* {{Citation | last1=Bock | first1=Hans Georg | last2=Plitt | first2=Karl J. | title=Proceedings of the 9th IFAC World Congress | contribution= A multiple shooting algorithm for direct solution of optimal control problems | location=Budapest | year=1984 | url=http://www.iwr.uni-heidelberg.de/groups/agbock/FILES/Bock1984.pdf }}\n* {{Citation | last1=Morrison| first1=David D. | last2=Riley | first2=James D. | last3=Zancanaro | first3=John F. | title=Multiple shooting method for two-point boundary value problems |date=December 1962 | volume=5 | number=12  | pages=613–614 | journal=Commun. ACM | doi=10.1145/355580.369128}}\n\n{{DEFAULTSORT:Direct Multiple Shooting Method}}\n[[Category:Numerical differential equations]]\n[[Category:Boundary value problems]]"
    },
    {
      "title": "Direct stiffness method",
      "url": "https://en.wikipedia.org/wiki/Direct_stiffness_method",
      "text": "As one of the methods of [[structural analysis]], the '''direct stiffness method''', also known as the '''matrix stiffness method''', is particularly suited for computer-automated analysis of complex structures including the [[statically indeterminate]] type. It is a ''matrix'' method that makes use of the members' stiffness relations for computing member forces and displacements in structures. The direct stiffness method is the most common implementation of the [[finite element method]] (FEM).  In applying the method, the system must be modeled as a set of simpler, idealized elements interconnected at the nodes.  The material stiffness properties of these elements are then, through [[Matrix (mathematics)|matrix mathematics]], compiled into a single matrix equation which governs the behaviour of the entire idealized structure.  The structure’s unknown displacements and forces can then be determined by solving this equation.  The direct stiffness method forms the basis for most commercial and free source finite element software.\n\nThe direct stiffness method originated in the field of [[aerospace]].  Researchers looked at various approaches for analysis of complex airplane frames.  These included [[elasticity theory]], [[energy principles in structural mechanics]], [[flexibility method]] and [[matrix stiffness method]].  It was through analysis of these methods that the direct stiffness method emerged as an efficient method ideally suited for computer implementation.\n\n==History==\nBetween 1934 and 1938 [[Arthur Roderick Collar|A. R. Collar]] and [[W. J. Duncan]] published the first papers with the representation and terminology for matrix systems that are used today. Aeroelastic research continued through [[World War II]] but publication restrictions from 1938 to 1947 make this work difficult to trace. The second major breakthrough in matrix structural analysis occurred through 1954 and 1955 when professor [[John H. Argyris]] systemized the concept of assembling elemental components of a structure into a system of equations. Finally, on Nov. 6 1959, [[M. J. Turner]], head of [[Boeing]]’s Structural Dynamics Unit, published a paper outlining the direct stiffness method as an efficient model for computer implementation {{harv|Felippa|2001}}.\n\n==Member stiffness relations==\n\nA typical member stiffness relation has the following general form:\n\n:<math>\\mathbf{Q}^m = \\mathbf{k}^m \\mathbf{q}^m + \\mathbf{Q}^{om} \\qquad \\qquad \\qquad \\mathrm{(1)}</math>\nwhere\n:''m'' = member number ''m''.\n:<math>\\mathbf{Q}^m </math> = vector of member's characteristic forces, which are unknown internal forces.\n:<math>\\mathbf{k}^m </math> = member stiffness matrix which characterizes the member's resistance against deformations.\n:<math>\\mathbf{q}^m </math> = vector of member's characteristic displacements or deformations.\n:<math>\\mathbf{Q}^{om} </math> = vector of member's characteristic forces caused by external effects (such as known forces and temperature changes) applied to the member while <math>\\mathbf{q}^m = 0 </math>.\n\nIf <math>\\mathbf{q}^m </math> are member deformations rather than absolute displacements, then <math>\\mathbf{Q}^m </math> are independent member forces, and in such case (1) can be inverted to yield the so-called ''member flexibility matrix'', which is used in the [[flexibility method]].\n\n==System stiffness relation==\n{{See also|Stiffness matrix}}\n\nFor a system with many members interconnected at points called nodes, the members' stiffness relations such as Eq.(1) can be integrated by making use of the following observations:\n* The member deformations <math>\\mathbf{q}^m </math> can be expressed in terms of system nodal displacements '''r''' in order to ensure compatibility between members. This implies that '''r''' will be the primary unknowns.\n* The member forces <math>\\mathbf{Q}^m </math> help to the keep the nodes in equilibrium under the nodal forces '''R'''. This implies that the right-hand-side of (1) will be integrated into the right-hand-side of the following nodal equilibrium equations for the entire system:\n\n:<math>\\mathbf{R} = \\mathbf{Kr} + \\mathbf{R}^o \\qquad \\qquad \\qquad \\mathrm{(2)}</math>\nwhere\n:<math>\\mathbf{R} </math> = vector of nodal forces, representing external forces applied to the system's nodes.\n:<math>\\mathbf{K} </math> = system stiffness matrix, which is established by ''assembling'' the members' stiffness matrices <math>\\mathbf{k}^m </math>.\n:<math>\\mathbf{r} </math> = vector of system's nodal displacements that can define all possible deformed configurations of the system subject to arbitrary nodal forces '''R'''.\n:<math>\\mathbf{R}^o </math> = vector of equivalent nodal forces, representing all external effects other than the nodal forces which are already included in the preceding nodal force vector '''R'''. This vector is established by assembling the members' <math>\\mathbf{Q}^{om} </math>.\n\n==Solution==\n\nThe system stiffness matrix '''K''' is square since the vectors '''R''' and '''r''' have the same size. In addition, it is symmetric because <math>\\mathbf{k}^m </math> is symmetric. Once the supports' constraints are accounted for in (2), the nodal displacements are found by solving the [[system of linear equations]] (2), symbolically:\n:<math>\\mathbf{r} = \\mathbf{K}^{-1} (\\mathbf{R}-\\mathbf{R}^o ) \\qquad \\qquad \\qquad \\mathrm{(3)}</math>\n\nSubsequently, the members' characteristic forces may be found from Eq.(1) where <math>\\mathbf{q}^m </math> can be found from '''r''' by compatibility consideration.\n\n==The direct stiffness method==\nIt is common to have Eq.(1) in a form where <math>\\mathbf{q}^m </math> and <math>\\mathbf{Q}^{om} </math> are, respectively, the member-end displacements and forces matching in direction with '''r''' and '''R'''. In such case, <math>\\mathbf{K} </math> and <math>\\mathbf{R}^o </math> can be obtained by direct summation of the members' matrices <math>\\mathbf{k}^m </math> and <math>\\mathbf{Q}^{om} </math>. The method is then known as the direct stiffness method.\n\nThe advantages and disadvantages of the matrix stiffness method are compared and discussed in the [[flexibility method]] article.\n\n==Example==\n\n===Breakdown===\nThe first step when using the direct stiffness method is to identify the individual elements which make up the structure.\n\n[[Image:DSMImage1.png]]\n \nOnce the elements are identified, the structure is disconnected at the nodes, the points which connect the different elements together.\n\n[[Image:DSMImage2.png]]\n\nEach element is then analyzed individually to develop member stiffness equations.  The forces and displacements are related through the element stiffness matrix which depends on the geometry and properties of the element.\n\nA truss element can only transmit forces in compression or tension.  This means that in two dimensions, each node has two [[degrees of freedom (physics and engineering)|degrees of freedom]] (DOF): horizontal and vertical displacement.  The resulting equation contains a four by four stiffness matrix.\n\n<math>\n\\begin{bmatrix}\nf_{x1} \\\\\nf_{y1} \\\\\nf_{x2} \\\\\nf_{y2} \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nk_{11} & k_{12} & k_{13} & k_{14} \\\\\nk_{21} & k_{22} & k_{23} & k_{24} \\\\\nk_{31} & k_{32} & k_{33} & k_{34} \\\\\nk_{41} & k_{42} & k_{43} & k_{44} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nu_{x1} \\\\\nu_{y1} \\\\\nu_{x2} \\\\\nu_{y2} \\\\\n\\end{bmatrix}\n</math>\n\nA frame element is able to withstand bending moments in addition to compression and tension.  This results in three degrees of freedom: horizontal displacement, vertical displacement and in-plane rotation.  The stiffness matrix in this case is six by six.\n\n<math>\n\\begin{bmatrix}\nf_{x1} \\\\\nf_{y1} \\\\\nm_{z1} \\\\\nf_{x2} \\\\\nf_{y2} \\\\\nm_{z2} \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nk_{11} & k_{12} & k_{13} & k_{14} & k_{15} & k_{16} \\\\\nk_{21} & k_{22} & k_{23} & k_{24} & k_{25} & k_{26} \\\\\nk_{31} & k_{32} & k_{33} & k_{34} & k_{35} & k_{36} \\\\\nk_{41} & k_{42} & k_{43} & k_{44} & k_{45} & k_{46} \\\\\nk_{51} & k_{52} & k_{53} & k_{54} & k_{55} & k_{56} \\\\\nk_{61} & k_{62} & k_{63} & k_{64} & k_{65} & k_{66} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nu_{x1} \\\\\nu_{y1} \\\\\n\\theta_{z1} \\\\\nu_{x2} \\\\\nu_{y2} \\\\\n\\theta_{z2} \\\\\n\\end{bmatrix}\n</math>\n\nOther elements such as plates and shells can also be incorporated into the direct stiffness method and similar equations must be developed.\n\n===Assembly===\nOnce the individual element stiffness relations have been developed they must be assembled into the original structure.  The first step in this process is to convert the stiffness relations for the individual elements into a global system for the entire structure.  In the case of a truss element, the global form of the stiffness method depends on the angle of the element with respect to the global coordinate system (This system is usually the traditional [[Cartesian coordinate system]]).\n\n<math>\n\\begin{bmatrix}\nf_{x1} \\\\\nf_{y1} \\\\\nf_{x2} \\\\\nf_{y2} \\\\\n\\end{bmatrix}\n=\n\\frac{EA}{L}\n\\begin{bmatrix}\nc^2 & sc & -c^2 & -sc \\\\\nsc & s^2 & -sc & -s^2 \\\\\n-c^2 & -sc & c^2 & sc \\\\\n-sc & -s^2 & sc & s^2 \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nu_{x1} \\\\\nu_{y1} \\\\\nu_{x2} \\\\\nu_{y2} \\\\\n\\end{bmatrix}\n\n\\begin{array}{ r }\ns = \\sin\\beta \\\\\nc = \\cos\\beta \\\\\n\\end{array}\n</math>\n'' (for a truss element at angle β)''\nEquivalently,\n<math>\n\\left[\n\\begin{array}{c}\n f_{x1} \\\\\n f_{y1} \\\\ \n\\hline\n f_{x2} \\\\\n f_{y2} \\\\\n\\end{array}\n\\right]\n=\\frac{EA}{L}\n\\left[\n\\begin{array}{c c|c c}\n c_x c_x & c_x c_y & -c_x c_x & -c_x c_y\\\\\n c_y c_x & c_y c_y & -c_y c_x & -c_y c_y\\\\\n\\hline\n -c_x c_x & -c_x c_y & c_x c_x & c_x c_y \\\\\n -c_y c_x & -c_y c_y & c_y c_x & c_y c_y\\\\\n\\end{array}\n\\right]\n\\left[\n\\begin{array}{c}\n u_{x1} \\\\\n u_{y1} \\\\ \n\\hline\n u_{x2} \\\\\n u_{y2} \\\\\n\\end{array}\n\\right]\n</math>\n\nwhere <math>c_x</math> and <math>c_y</math> are the direction cosines of the truss element (i.e., they are components of a unit vector aligned with the member). This form reveals how to generalize the element stiffness to 3-D space trusses by simply extending the pattern that is evident in this formulation.\n \nAfter developing the element stiffness matrix in the global coordinate system, they must be merged into a single “master” or “global” stiffness matrix.  When merging these matrices together there are two rules that must be followed: compatibility of displacements and force equilibrium at each node.  These rules are upheld by relating the element nodal displacements to the global nodal displacements.\n\n[[Image:DSMImage3.png]]\n\nThe global displacement and force vectors each contain one entry for each degree of freedom in the structure.  The element stiffness matrices are merged by augmenting or expanding each matrix in conformation to the global displacement and load vectors.\n\n<math>\nk^{(1)}\n=\n\\frac{EA}{L}\n\\begin{bmatrix}\n1 & 0 & -1 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n-1 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n\\end{bmatrix}\n\\rightarrow\nK^{(1)}\n=\n\\frac{EA}{L}\n\\begin{bmatrix}\n1 & 0 & -1 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n-1 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\end{bmatrix}\n</math>\n''(for element (1) of the above structure)''\n\nFinally, the global stiffness matrix is constructed by adding the individual expanded element matrices together.\n\n===Solution===\nOnce the global stiffness matrix, displacement vector, and force vector have been constructed, the system can be expressed as a single matrix equation.\n\n[[Image:DSMImage4.png]]\n\nFor each degree of freedom in the structure, either the displacement or the force is known.\n\n[[Image:DSMImage5.png]]\n\nAfter inserting the known value for each degree of freedom, the master stiffness equation is complete and ready to be evaluated.  There are several different methods available for evaluating a matrix equation including but not limited to [[Cholesky decomposition]] and the brute force evaluation of systems of equations.  If a structure isn’t properly restrained, the application of a force will cause it to move rigidly and additional support conditions must be added.\n\nThe method described in this section is meant as an overview of the direct stiffness method.  Additional sources should be consulted for more details on the process as well as the assumptions about material properties inherent in the process.\n\n==Applications==\nThe direct '''stiffness method''' was developed specifically to effectively and easily implement into computer software to evaluate complicated structures that contain a large number of elements.  Today, nearly every finite element solver available is based on the direct stiffness method.  While each program utilizes the same process, many have been streamlined to reduce computation time and reduce the required memory.  In order to achieve this, shortcuts have been developed.\n\nOne of the largest areas to utilize the direct stiffness method is the field of structural analysis where this method has been incorporated into modeling software.  The software allows users to model a structure and, after the user defines the material properties of the elements, the program automatically generates element and global stiffness relationships.  When various loading conditions are applied the software evaluates the structure and generates the deflections for the user.\n\n==See also==\n*[[Finite element method]]\n*[[Finite element method in structural mechanics]]\n*[[Structural analysis]]\n*[[Flexibility method]]\n*[[List of finite element software packages]]\n\n==External links==\n* [http://faculty.washington.edu/eberhard/CEE%20379/1D_Spring_Systems.pdf Application of direct stiffness method to a 1-D Spring System]\n* [http://www.duke.edu/~hpgavin/cee421/ Matrix Structural Analysis]\n* [https://web.archive.org/web/20070821072021/http://www.nenastran.com/newnoran/animations Animations of Stiffness Analysis Simulations]\n\n==References==\n* {{Citation | last1=Felippa | first1=Carlos A. | author1-link=Carlos A. Felippa | title=A historical outline of matrix structural analysis: a play in three acts | url=http://www.colorado.edu/engineering/CAS/Felippa.d/FelippaHome.d/Publications.d/Report.CU-CAS-00-13.pdf | doi=10.1016/S0045-7949(01)00025-6 | year=2001 | journal=Computers & Structures | issn=0045-7949 | volume=79 | issue=14 | pages=1313–1324}}\n* [[Felippa, Carlos A.]] Introduction to Finite Element Method. Fall 2001. University of Colorado. 18 Sept. 2005\n* Robinson, John. Structural Matrix Analysis for the Engineer.  New York: John Wiley & Sons, 1966\n* Rubinstein, Moshe F. Matrix Computer Analysis of Structures.  New Jersey: Prentice-Hall, 1966\n* McGuire, W., Gallagher, R. H., and Ziemian, R. D. Matrix Structural Analysis, 2nd Ed. New York: John Wiley & Sons, 2000.\n\n[[Category:Structural analysis]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Discontinuous Galerkin method",
      "url": "https://en.wikipedia.org/wiki/Discontinuous_Galerkin_method",
      "text": "In applied mathematics, '''discontinuous Galerkin methods (DG methods)''' form a class of [[numerical analysis|numerical]] methods for solving [[differential equation]]s. They combine features of the [[finite element method|finite element]] and the [[finite volume method|finite volume]] framework and have been successfully applied to [[Hyperbolic partial differential equation|hyperbolic]], [[Elliptic partial differential equation|elliptic]], [[Parabolic partial differential equation|parabolic]] and mixed form problems arising from a wide range of applications. DG methods have in particular received considerable interest for problems with a dominant first-order part, e.g. in [[electrodynamics]], [[fluid mechanics]] and [[plasma physics]].\n\nDiscontinuous Galerkin methods were first proposed and analyzed in the early 1970s as a technique to numerically solve partial differential equations. In 1973 Reed and Hill introduced a DG method to solve the hyperbolic neutron transport equation.\n\nThe origin of the DG method for elliptic problems cannot be traced back to a single publication as features such as jump penalization in the modern sense were developed gradually. However, among the early influential contributors were [[Ivo Babuška|Babuška]], [[Jacques-Louis Lions|J.-L. Lions]], Joachim Nitsche and Miloš Zlámal. DG methods for elliptic problems were already developed in a paper by Garth Baker in the setting of 4th order equations in 1977. A more complete account of the historical development and an introduction to DG methods for elliptic problems is given in a publication by Arnold, Brezzi, Cockburn and Marini. A number of research directions and challenges on DG methods are collected in the proceedings volume edited by Cockburn, Karniadakis and Shu.\n\n==Overview==\nMuch like the [[Galerkin method|continuous Galerkin (CG) method]], the discontinuous Galerkin (DG) method is a [[finite element method]] formulated relative to a [[weak formulation]] of a particular model system.  Unlike traditional CG methods that are [[finite element method|conforming]], the DG method works over a trial space of functions that are only [[piecewise continuous]], and thus often comprise more inclusive [[function spaces]] than the finite-dimensional inner product subspaces utilized in conforming methods.\n\nAs an example, consider the [[continuity equation]] for a scalar unknown <math>\\rho</math> in a spatial domain <math>\\Omega</math> without \"sources\" or \"sinks\" :\n\n:<math> \\frac{\\partial \\rho} {\\partial t} + \\nabla \\cdot \\mathbf{J} = 0,</math> \nwhere <math>\\mathbf{J}</math> is the flux of <math>\\rho</math>.\n\nNow consider the finite-dimensional space of discontinuous piecewise polynomial functions over the spatial domain <math>\\Omega</math> restricted to a discrete [[Triangulation (geometry)|triangulation]] <math>\\Omega_{h}</math>, written as\n\n:<math> S_{h}^{p}(\\Omega_{h})=\\{v_{|\\Omega_{e_{i}}}\\in P^{p}(\\Omega_{e_{i}}), \\ \\ \\forall\\Omega_{e_{i}}\\in \\Omega_{h}\\}</math>\n\nfor <math>P^{p}(\\Omega_{e_{i}})</math> the space of polynomials with degrees less than or equal to <math> p</math> over element <math>\\Omega_{e_{i}}</math> indexed by <math>i</math>.  Then for finite element shape functions <math>N_{j}\\in P^{p}</math> the solution is represented by\n\n:<math>\\rho_{h} = \\sum_{j=1}^{\\text{dofs}}\\rho_{j}^{i}(t)N_{j}^{i}(\\boldsymbol{x}), \\quad \\forall\\boldsymbol{x}\\in\\Omega_{e_{i}}.</math>\n\nThen similarly choosing a test function\n\n:<math>\\phi_{h}(\\boldsymbol{x})=\\sum_{j=1}^{\\text{dofs}}\\phi_{j}^{i}N_{j}^{i}(\\boldsymbol{x}), \\quad \\forall \\boldsymbol{x}\\in\\Omega_{e_{i}},</math>\n\nmultiplying the continuity equation by <math>\\phi_h</math> and [[integration by parts|integrating by parts in space]], the semidiscrete DG formulation becomes:\n\n:<math> \\frac{d}{dt}\\int_{\\Omega_{e_{i}}}\\rho_{h}\\phi_{h}d\\boldsymbol{x} + \\int_{\\partial\\Omega_{e_{i}}} \\phi_{h}\\mathbf{J}_{h}\\cdot\\boldsymbol{n} d\\boldsymbol{x} = \\int_{\\Omega_{e_{i}}}\\mathbf{J}_{h}\\cdot\\nabla\\phi_{h}d\\boldsymbol{x}.</math>\n\n== Scalar hyperbolic conservation law ==\nA scalar [[Hyperbolic_partial_differential_equation#Hyperbolic_system_and_conservation_laws|hyperbolic conservation law]] is of the form\n:<math>\n\\begin{align}\n  \\partial_t u + \\partial_x f(u) &= 0\n    \\quad \\text{for} \\quad\n    t>0,\\, x\\in \\R\n    \\\\\n  u(0,x) &= u_0(x)\\,,\n\\end{align}\n</math>\nwhere one tries to solve for the unknown scalar function <math> u \\equiv u(t,x) </math>, and the functions <math> f,u_0 </math> are typically given.\n\n=== Space discretization ===\nThe <math> x </math>-space will be discretized as\n:<math>\n  \\R = \\bigcup_k I_k\n    \\,, \\quad\n    I_k := \\left( x_k, x_{k+1} \\right)\n    \\quad \\text{for} \\quad\n    x_k<x_{k+1}\\,.\n</math>\nFurthermore, we need the following definitions\n:<math>\n  h_k := | I_k | \\,, \\quad\n    h := \\sup_k h_k \\,, \\quad\n    \\hat{x}_k := x_k + \\frac{h_k}{2}\\,.\n</math>\n\n=== Basis for function space ===\nWe derive the basis representation for the function space of our solution <math> u </math>.\nThe function space is defined as\n:<math>\n  S_h^p := \n    \\left\\lbrace \n      v \\in L^2(\\R)\n      \\; \\colon \\;\n      {v|}_{I_k} \\in \\Pi_p\n    \\right\\rbrace \n    \\quad \\text{for} \\quad\n    p \\in \\N_0 \\,,\n</math>\nwhere <math> {v|}_{I_k} </math> denotes the [[Restriction_(mathematics)|restriction]] of <math> v </math> onto the interval <math> I_k </math>, and <math> \\Pi_p </math> denotes the space of polynomials of maximal [[Degree_of_a_polynomial|degree]] <math> p </math>.\nThe index <math> h </math> should show the relation to an underlying discretization given by <math> \\left(x_k\\right)_k </math>.\nNote here that <math> v </math> is not uniquely defined at the intersection points <math> \\left(x_k\\right)_k </math>.\n\nAt first we make use of a specific polynomial basis on the interval <math> [-1,1] </math>, the [[Legendre polynomials]] <math> \\left(P_n\\right)_{n\\in\\N_0} </math>, i.e.,\n:<math>\n  P_0(x) = 1\n    \\,,\\quad\n    P_1(x)=x\n    \\,,\\quad\n    P_2(x) = \\frac{1}{2}\\left( 3x^2-1 \\right)\n    \\,, \\dots\n</math>\nNote especially the orthogonality relations \n:<math>\n  \\left\\langle P_i,P_j \\right\\rangle_{L^2([-1,1])} = \\frac{2}{2i+1} \\delta_{ij}\n    \\quad \\forall \\, i,j \\in \\N_0 \\,.\n</math>\nTransformation onto the interval <math> [0,1] </math>, and normalization is achieved by functions <math> \\left(\\phi_i\\right)_i </math>\n:<math>\n  \\phi_i (x) := \\sqrt{2i+1} P_i(2x-1)\n    \\quad \\text{for} \\quad x\\in [0,1]\\,,\n</math>\nwhich fulfill the orthonormality relation\n:<math>\n  \\left\\langle \\phi_i,\\phi_j \\right\\rangle_{L^2([0,1])} = \\delta_{ij}\n    \\quad \\forall \\, i,j \\in \\N_0 \\,.\n</math>\nTransformation onto an interval <math> I_k </math> is given by <math> \\left( \\bar{\\varphi}_{ki}\\right)_i </math>\n:<math>\n  \\bar{\\varphi}_{ki} := \\frac{1}{\\sqrt{h_k}} \\phi_i \\left( \\frac{x-x_k}{h_k} \\right)\n    \\quad \\text{for} \\quad x\\in I_k\\,,\n</math>\nwhich fulfill\n:<math>\n  \\left\\langle \\bar{\\varphi}_{ki},\\bar{\\varphi}_{kj} \\right\\rangle_{L^2(I_k)} = \\delta_{ij}\n    \\quad \\forall \\, i,j \\in \\N_0 \\forall \\, k \\,.\n</math>\nFor <math> L^\\infty </math>-normalization we define <math> \\varphi_{ki}:= \\sqrt{h_k} \\bar{\\varphi}_{ki} </math>, and for <math> L^1 </math>-normalization we define <math> \\tilde{\\varphi}_{ki}:= \\frac{1}{\\sqrt{h_k}} \\bar{\\varphi}_{ki} </math>, s.t.\n:<math>\n  \\| \\varphi_{ki} \\|_{L^\\infty (I_k) }\n    = \\| \\phi_i \\|_{L^\\infty ([0,1]) }\n    =: c_{i,\\infty}\n    \\quad \\text{and} \\quad\n    \\| \\tilde{\\varphi}_{ki} \\|_{L^1 (I_k) }\n    = \\| \\phi_i \\|_{L^1 ([0,1]) }\n    =: c_{i,1}\n    \\,.\n</math>\n\nFinally, we can define the basis representation of our solutions <math> u_h </math>\n:<math>\n\\begin{align}\n  u_h(t,x) :=& \n    \\sum_{i=0}^p u_{ki}(t) \\varphi_{ki} (x)\n    \\quad \\text{for} \\quad\n    x \\in (x_k,x_{k+1})\n    \\\\\n  u_{ki} (t) =& \n    \\left\\langle u_h(t, \\cdot ),\\tilde{\\varphi}_{ki} \\right\\rangle_{L^2(I_k)} \\,.\n\\end{align}\n</math>\nNote here, that <math> u_h </math> is not defined at the interface positions.\n\nBesides, prism bases are employed for planar-like structures, and are capable for 2-D/3-D hybridation.\n\n=== DG-Scheme ===\nThe conservation law is transformed into its weak form by multiplying with test functions, and integration over test intervals\n:<math>\n\\begin{align}\n  \\partial_t u + \\partial_x f(u) &= 0\n    \\\\\n  \\Rightarrow \\quad \n    \\left\\langle \\partial_t u , v \\right\\rangle_{L^2(I_k)}\n    + \\left\\langle \\partial_x f(u) , v \\right\\rangle_{L^2(I_k)}\n    &= 0\n    \\quad \\text{for} \\quad\n    \\forall \\, v \\in S_h^p\n    \\\\\n  \\Leftrightarrow \\quad\n    \\left\\langle \\partial_t u , \\tilde{\\varphi}_{ki} \\right\\rangle_{L^2(I_k)}\n    + \\left\\langle \\partial_x f(u) , \\tilde{\\varphi}_{ki} \\right\\rangle_{L^2(I_k)}\n    &= 0\n    \\quad \\text{for} \\quad\n    \\forall \\, k \\; \\forall\\, i \\leq p    \n    \\,.\n\\end{align}\n</math>\nBy using partial integration one is left with\n:<math>\n\\begin{align}\n  \\frac{\\mathrm d}{\\mathrm d t} u_{ki}(t)\n    + f(u(t, x_{k+1} )) \\tilde{\\varphi}_{ki}(x_{k+1}) \n    - f(u(t, x_k )) \\tilde{\\varphi}_{ki}(x_k) \n    - \\left\\langle f(u(t,\\,\\cdot\\,)) , \\tilde{\\varphi}_{ki}' \\right\\rangle_{L^2(I_k)}\n    =0\n    \\quad \\text{for} \\quad\n    \\forall \\, k \\; \\forall\\, i \\leq p    \n    \\,.\n\\end{align}\n</math>\nThe fluxes at the interfaces are approximated by numerical fluxes <math>g</math> with\n:<math>\ng_k := g(u_k^-,u_k^+) \n  \\,, \\quad\n  u_k^{\\pm} := u(t,x_k^{\\pm}) \\,,\n</math>\nwhere <math>u_k^{\\pm}</math> denotes the left- and right-hand sided limits.\nFinally, the ''DG-Scheme'' can be written as\n:<math>\n\\begin{align}\n  \\frac{\\mathrm d}{\\mathrm d t} u_{ki}(t)\n    + g_{k+1} \\tilde{\\varphi}_{ki}(x_{k+1}) \n    - g_k \\tilde{\\varphi}_{ki}(x_k) \n    - \\left\\langle f(u(t,\\,\\cdot\\,)) , \\tilde{\\varphi}_{ki}' \\right\\rangle_{L^2(I_k)}\n    =0\n    \\quad \\text{for} \\quad\n    \\forall \\, k \\; \\forall\\, i \\leq p    \n    \\,.\n\\end{align}\n</math>\n\n== Scalar elliptic equation ==\nA scalar elliptic equation is of the form\n\n:<math>\n\\begin{align}\n  -\\partial_{xx} u &= f(x)\n    \\quad \\text{for} \\quad\n    x\\in (a,b)\n    \\\\\n  u(x) &= g(x)\\,\\quad\\text{for}\\,\\quad x=a,b\n\\end{align}\n</math>\n\nThis equation is the steady-state heat equation, where <math>\nu </math> is the temperature. Space discretization is the same as above. We recall that the interval\n<math>(a,b)</math> is partitioned into <math>N+1</math> intervals of length <math>h</math>.\n\nWe introduce jump <math>[\\cdot]</math> and average <math>\\{\\cdot\\}</math> of functions at the node <math> x_k</math>:\n:<math>\n [v]|_{x_k} = v(x_k^+)-v(x_k^-), \\quad \\{v\\}|_{x_k} = 0.5 (v(x_k^+)+v(x_k^-))\n</math>\n\nThe interior penalty discontinuous Galerkin (IPDG) method is: find <math>u_h</math> satisfying\n\n:<math>\nA(u_h,v_h) + A_{\\partial}(u_h,v_h) = \\ell(v_h) + \\ell_\\partial(v_h)\n</math>\nwhere the bilinear forms <math>A</math> and <math>A_\\partial</math> are\n:<math>\nA(u_h,v_h) = \\sum_{k=1}^{N+1} \\int_{x_{k-1}}^{x_k}\\partial_x u_h \\partial_x v_h\n-\\sum_{k=1}^N \\{ \\partial_x u_h\\}_{x_k} [v_h]_{x_k}\n+\\epsilon\\sum_{k=1}^N \\{ \\partial_x v_h\\}_{x_k} [u_h]_{x_k}\n+\\frac{\\sigma}{h} \\sum_{k=1}^N [u_h]_{x_k} [v_h]_{x_k}\n</math>\nand\n:<math>\nA_\\partial(u_h,v_h) = \\partial_x u_h(a) v_h(a) -\\partial_x u_h(b) v_h(b)\n-\\epsilon \\partial_x v_h(a) u_h(a) + \\epsilon\\partial_x v_h(b) u_h(b)\n+\\frac{\\sigma}{h} \\big(u_h(a) v_h(a) + u_h(b) v_h(b)\\big)\n</math>\nThe linear forms <math>\\ell</math> and <math>\\ell_\\partial</math> are\n:<math>\n\\ell(v_h) = \\int_a^b f v_h\n</math>\nand\n:<math>\n\\ell_\\partial(v_h) = -\\epsilon \\partial_x v_h(a) g(a) + \\epsilon\\partial_x v_h(b) g(b)\n+\\frac{\\sigma}{h} \\big( g(a) v_h(a) + g(b) v_h(b) \\big)\n</math>\n\nThe penalty parameter <math>\\sigma</math> is a positive constant. Increasing its value will reduce the jumps in the discontinuous solution.  The term <math>\\epsilon</math> is chosen to be equal to <math>-1</math> for the symmetric interior penalty Galerkin method; it is equal to <math>+1</math> for the non-symmetric interior penalty Galerkin method. \n\n==See also==\n\n*[[Galerkin method]]\n\n==References==\n* D.N. Arnold, F. Brezzi, B. Cockburn and L.D. Marini, ''Unified analysis of discontinuous Galerkin methods for elliptic problems'', SIAM J. Numer. Anal. 39(5):1749–1779, 2002.\n* G. Baker, ''Finite element methods for elliptic equations using nonconforming elements'', Math. Comp. 31 (1977), no. 137, 45–59.\n* A. Cangiani, Z. Dong, E.H. Georgoulis, and P. Houston, ''hp-Version Discontinuous Galerkin Methods on Polygonal and Polyhedral Meshes'', SpringerBriefs in Mathematics, (December 2017).\n* W. Mai, J. Hu, P. Li, and H. Zhao, “[https://ieeexplore.ieee.org/document/7898872/ An efficient and stable 2-D/3-D hybrid discontinuous Galerkin time-domain analysis with adaptive criterion for arbitrarily shaped antipads in dispersive parallel-plate pair],” ''IEEE Trans. Microw. Theory Techn.'', vol. 65, no. 10, pp. 3671–3681, Oct. 2017.\n* W. Mai ''et al.'', “[https://ieeexplore.ieee.org/document/8299439/?arnumber=8299439&source=authoralert A straightforward updating criterion for 2-D/3-D hybrid discontinuous Galerkin time-domain method controlling comparative error],” ''IEEE Trans. Microw. Theory Techn.'', vol. 66, no. 4, pp. 1713–1722, Apr. 2018.\n* B. Cockburn, G. E. Karniadakis and C.-W. Shu (eds.), ''Discontinuous Galerkin methods. Theory, computation and applications'', Lecture Notes in Computational Science and Engineering, 11. Springer-Verlag, Berlin, 2000.\n* P. Lesaint, and P. A. Raviart. \"On a finite element method for solving the neutron transport equation.\" Mathematical aspects of finite elements in partial differential equations 33 (1974): 89-123.\n* D.A. Di Pietro and A. Ern, [https://www.springer.com/mathematics/computational+science+%26+engineering/book/978-3-642-22979-4 ''Mathematical Aspects of Discontinuous Galerkin Methods'']. Mathématiques et Applications, Vol. 69, Springer-Verlag, Berlin, 2011.\n* J.S. Hesthaven and T. Warburton, [https://www.springer.com/mathematics/computational+science+%26+engineering/book/978-0-387-72065-4 ''Nodal Discontinuous Galerkin Methods: Algorithms, Analysis, and Applications'']. Springer Texts in Applied Mathematics 54. Springer Verlag, New York, 2008.\n* B. Rivière, [https://dx.doi.org/10.1137/1.9780898717440 ''Discontinuous Galerkin Methods for Solving Elliptic and Parabolic Equations: Theory and Implementation'']. SIAM Frontiers in Applied Mathematics, 2008.\n* CFD Wiki http://www.cfd-online.com/Wiki/Discontinuous_Galerkin\n* W.H. Reed and T.R. Hill, ''Triangular mesh methods for the neutron transport equation'', Tech. Report LA-UR-73-479, Los Alamos Scientific Laboratory, 1973.\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Discontinuous Galerkin Method}}\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n[[Category:Finite element method]]"
    },
    {
      "title": "Discrete element method",
      "url": "https://en.wikipedia.org/wiki/Discrete_element_method",
      "text": "{{distinguish|finite element method}}\n\nA '''discrete element method''' ('''DEM'''), also called a '''distinct element method''', is any of a family of [[numerical analysis|numerical]] methods for computing the motion and effect of a large number of small particles. Though DEM is very closely related to [[molecular dynamics]], the method is generally distinguished by its inclusion of rotational degrees-of-freedom as well as stateful contact and often complicated geometries (including polyhedra). With advances in computing power and numerical algorithms for nearest neighbor sorting, it has become possible to numerically simulate millions of particles on a single processor. Today DEM is becoming widely accepted as an effective method of addressing engineering problems in granular and discontinuous materials, especially in granular flows, powder mechanics, and rock mechanics. Recently, the method was expanded into the [[Extended Discrete Element Method]] taking [[thermodynamics]] and coupling to [[Computational fluid dynamics|CFD]] and [[Finite element method|FEM]] into account.\n\nDiscrete element methods are relatively computationally intensive, which limits either the length of a simulation or the number of particles. Several DEM codes, as do molecular dynamics codes, take advantage of parallel processing capabilities (shared or distributed systems) to scale up the number of particles or length of the simulation. An alternative to treating all particles separately is to average the physics across many particles and thereby treat the material as a [[Continuum mechanics|continuum]].  In the case of [[solid]]-like granular behavior as in [[soil mechanics]], the continuum approach usually treats the material as [[Elasticity (physics)|elastic]] or [[Plasticity (physics)|elasto-plastic]] and models it with the [[finite element method]] or a [[Meshfree methods|mesh free method]].  In the case of liquid-like or gas-like granular flow, the continuum approach may treat the material as a [[fluid]] and use [[computational fluid dynamics]]. Drawbacks to [[Homogenization (chemistry)|homogenization]] of the granular scale physics, however, are well-documented and should be considered carefully before attempting to use a continuum approach.\n\n==The DEM family==\nThe various branches of the DEM family are the [[distinct element method]] proposed by [[Peter A. Cundall]] in 1971, the [[generalized discrete element method]] {{harv|Williams|Hocking|Mustoe|1985}}, the [[Discontinuous Deformation Analysis|discontinuous deformation analysis]] (DDA) {{harv|Shi|1992}} and the finite-discrete element method concurrently developed by several groups (e.g., [[Ante Munjiza|Munjiza]] and [[Roger Owen (mathematician)|Owen]]). The general method was originally developed by Cundall in 1971 to problems in rock mechanics. The theoretical basis of the method was established by Sir Isaac Newton in 1697<!-- 1967 is INCORRECT! --Aclariont Sept 25, 2009 (assumed a typo for now)-->. {{harvtxt|Williams|Hocking|Mustoe|1985}} showed that DEM could be viewed as a generalized finite element method. Its application to geomechanics problems is described in the book ''Numerical Methods in Rock Mechanics'' {{harv|Williams|Pande|Beer|1990}}. The 1st, 2nd and 3rd International Conferences on Discrete Element Methods have been a common point for researchers to publish advances in the method and its applications. Journal articles reviewing the state of the art have been published by Williams, [[Nenad Bicanic|Bicanic]], and [[Antonio Bobet|Bobet]] et al. (see below).  A comprehensive treatment of the combined Finite Element-Discrete Element Method is contained in the book ''The Combined Finite-Discrete Element Method''.<ref name=\"Munjiza 2004\">{{cite book |last1=Munjiza |first1=Ante |title=The Combined Finite-Discrete Element Method |date=2004 |publisher=Wiley |location=Chichester |isbn=978-0-470-84199-0}}</ref>\n\n[[File:Cundall DEM.gif|thumb|upright=1|Discrete-element simulation with particles arranged after a photo of Peter A. Cundall. As proposed in Cundall and Strack (1979), grains interact with linear-elastic forces and Coulomb friction. Grain kinematics evolve through time by temporal integration of their force and torque balance. The collective behavior is self-organizing with discrete shear zones and angles of repose, as characteristic to cohesionless granular materials.]]\n\n==Applications==\nThe fundamental assumption of the method is that the material consists of separate, discrete particles. These particles may have different shapes and properties. Some examples are:\n* liquids and solutions, for instance of sugar or proteins;\n* bulk materials in storage silos, like cereal;\n* granular matter, like sand;\n* powders, like toner.\n* Blocky or jointed rock masses\n\nTypical industries using DEM are:\n* Agriculture and food handling\n* Chemical\n* Civil Engineering\n* Oil and gas\n* Mining\n* Mineral processing\n* Pharmaceutical\n* Powder metallurgy\n\n==Outline of the method==\n\nA DEM-simulation is started by first generating a model, which results in spatially orienting all particles and assigning an initial [[velocity]]. The forces which act on each particle are computed from the initial data and the relevant physical laws and contact models. Generally, a simulation consists of three parts: the initialization, explicit time-stepping, and post-processing. The time-stepping usually requires a nearest neighbor sorting step to reduce the number of possible contact pairs and decrease the computational requirements; this is often only performed periodically.\n\nThe following forces may have to be considered in macroscopic simulations:\n* [[friction]], when two particles touch each other;\n* [[contact plasticity]], or recoil, when two particles collide;\n* [[gravity]], the force of attraction between particles due to their mass, which is only relevant in astronomical simulations.\n* attractive potentials, such as [[Cohesion (chemistry)|cohesion]], [[adhesion]], [[liquid bridging]], [[electrostatic attraction]]. Note that, because of the overhead from determining nearest neighbor pairs, exact resolution of long-range, compared with particle size, forces can increase computational cost or require specialized algorithms to resolve these interactions.\n\nOn a molecular level, we may consider:\n* the [[Coulomb force]], the [[electrostatic]] attraction or repulsion of particles carrying [[electric charge]];\n* [[Pauli exclusion principle|Pauli repulsion]], when two atoms approach each other closely;\n* [[van der Waals force]].\n\nAll these forces are added up to find the total force acting on each particle. An [[numerical ordinary differential equations|integration method]] is employed to compute the change in the position and the velocity of each particle during a certain time step from [[Newton's laws of motion]]. Then, the new positions are used to compute the forces during the next step, and this [[program loop|loop]] is repeated until the simulation ends.\n\nTypical integration methods used in a discrete element method are:\n* the [[Verlet integration|Verlet algorithm]],\n* [[velocity Verlet]],\n* [[symplectic integrator]]s,\n* the [[leapfrog method]].\n\n==Long-range forces==\n\nWhen long-range forces (typically gravity or the Coulomb force) are taken into account, then the interaction between each pair of particles needs to be computed. Both the number of interactions and cost of computation [[quadratic growth|increase quadratically]] with the number of particles. This is not acceptable for simulations with large number of particles. A possible way to avoid this problem is to combine some particles, which are far away from the particle under consideration, into one pseudoparticle. Consider as an example the interaction between a star and a distant [[galaxy]]: The error arising from combining all the stars in the distant galaxy into one point mass is negligible. So-called tree algorithms are used to decide which particles can be combined into one pseudoparticle. These algorithms arrange all particles in a tree, a [[quadtree]] in the two-dimensional case and an [[octree]] in the three-dimensional case.\n\nHowever, simulations in molecular dynamics divide the space in which the simulation take place into cells. Particles leaving through one side of a cell are simply inserted at the other side (periodic [[boundary condition]]s); the same goes for the forces. The force is no longer taken into account after the so-called cut-off distance (usually half the length of a cell), so that a particle is not influenced by the mirror image of the same particle in the other side of the cell. One can now increase the number of particles by simply copying the cells.\n\nAlgorithms to deal with long-range force include:\n* [[Barnes–Hut simulation]],\n* the [[fast multipole method]].\n\n==Combined finite-discrete element method==\n\nFollowing the work by Munjiza and Owen, the combined finite-discrete element method has been further developed to various irregular and deformable particles in many applications including pharmaceutical tableting,<ref>{{Cite journal |last1=Lewis |first1=R. W. |last2=Gethin |first2=D. T. |last3=Yang |first3=X. S. |last4=Rowe |first4=R. C. |title=A combined finite-discrete element method for simulating pharmaceutical powder tableting |doi=10.1002/nme.1287 |journal=International Journal for Numerical Methods in Engineering |volume=62 |issue=7 |pages=853 |year=2005|bibcode = 2005IJNME..62..853L |arxiv=0706.4406 }}</ref> packaging and flow simulations,<ref>{{Cite journal |last1=Gethin |first1=D. T. |last2=Yang |first2=X. S. |last3=Lewis |first3=R. W. |doi=10.1016/j.cma.2005.10.025 |title=A two dimensional combined discrete and finite element scheme for simulating the flow and compaction of systems comprising irregular particulates |journal=Computer Methods in Applied Mechanics and Engineering |volume=195 |issue=41–43 |pages=5552 |year=2006 |pmid= |pmc=|bibcode = 2006CMAME.195.5552G }}</ref> and impact analysis.<ref>{{Cite journal |last1=Chen |first1=Y. |last2=May |first2=I. M. |doi=10.1680/stbu.2009.162.1.45 |title=Reinforced concrete members under drop-weight impacts |journal=Proceedings of the ICE - Structures and Buildings |volume=162 |pages=45–56 |year=2009 |pmid= |pmc=}}</ref>\n\n==Advantages and limitations==\nAdvantages\n* DEM can be used to simulate a wide variety of granular flow and rock mechanics situations. Several research groups have independently developed simulation software that agrees well with experimental findings in a wide range of engineering applications, including adhesive powders, granular flow, and jointed rock masses.\n* DEM allows a more detailed study of the micro-dynamics of powder flows than is often possible using physical experiments. For example, the force networks formed in a granular media can be visualized using DEM. Such measurements are nearly impossible in experiments with small and many particles.\n\nDisadvantages\n* The maximum number of particles, and duration of a virtual simulation is limited by computational power. Typical flows contain billions of particles, but contemporary DEM simulations on large cluster computing resources have only recently been able to approach this scale for sufficiently long time (simulated time, not actual program execution time). \n* DEM is computationally demanding, which is the reason why it has not been so readily and widely adopted as continuum approaches in computational engineering sciences and industry. However, the actual program execution times can be reduced significantly when graphical processing units (GPUs) are utilized to conduct DEM simulations,<ref>{{Cite journal |last1=Xu |first1=J. |last2=Qi |first2=H. |last3=Fang |first3=X.|last4=Lu |first4=L.|last5=Ge |first5=W. |last6=Wang |first6=X.|last7=Xu |first7=M. |last8=Chen |first8=F. |last9=He |first9=X. |last10=Li |first10=J.|doi=10.1016/j.partic.2011.01.003 |title=Quasi-real-time simulation of rotating drum using discrete element method with parallel GPU computing |journal=Particuology |volume=9 |issue=4 |pages=446–450 |year=2011 |pmid= |pmc=}}</ref><ref>{{Cite journal |last1=Govender |first1=N. |last2=Wilke |first2=D. N. |last3=Kok |first3=S.|doi=10.1016/j.softx.2016.04.004 |title=Blaze-DEMGPU: Modular high performance DEM framework for the GPU architecture |journal=SoftwareX |volume=5 |pages=62–66 |year=2016 |pmid= |pmc=|bibcode=2016SoftX...5...62G }}</ref> due to the large number of computing cores on typical GPUs. In addition GPUs tend to be significantly more energy efficient than conventional computing clusters when conducting DEM simulations i.e. a DEM simulation solved on GPUs requires less energy than when it is solved on a conventional computing cluster.\n\n== Software ==\n\nOpen-source and non-commercial software packages:\n* BALL & TRUBAL (1979–1980) distinct element method (FORTRAN code), originally written by P.Cundall and currently maintained by [http://www.iem.bham.ac.uk/computation/granular/colthor.htm C.Thornton].\n* [http://www.mercurydpm.org/ Mercury-DPM] Developed by Mercury LAB, [[University of Twente]].\n* [http://yade-dem.org/ YADE] Yet Another Dynamic Engine, second incarnation of SDEC written from ground-up, GPL license.\n* [https://github.com/CFDEMproject/LIGGGHTS-PUBLIC/ LIGGGHTS]: [[LAMMPS]] improved for general granular and granular heat transfer simulations, developed by [https://www.dcs-computing.com/ DCS Computing GmbH]\n* [https://mfix.netl.doe.gov/ MFIX-DEM] Developed by National Energy Technology Laboratory ([https://www.netl.doe.gov/ NETL-USA])\n*[http://mechsys.nongnu.org/ MechSys] Developed by few people and currently maintained by [https://www.liverpool.ac.uk/engineering/staff/sergio-andres-torres/ S. A. Galindo-Torres] at The University of Liverpool.\n\nCommercial software:\n* [https://www.itascacg.com/software/ UDEC и 3DEC (Distinct Element Code in 2 Dimensions and 3 Dimensions)]\n* [http://www.chutemaven.com Chute Maven (Hustrulid Technologies Inc.)]\n* [https://www.itascacg.com/software/pfc PFC2D и PFC3D (Particle Flow Code in 2 Dimensions; Particle Flow Code in 3 Dimensions)]\n* [https://www.edemsimulation.com/ EDEM (DEM Solutions Ltd.)]\n* [http://www.igc.ethz.ch/gromos/ GROMOS 96]\n* [http://www.rockfieldglobal.com/software/geomechanical/ ELFEN]\n* [http://www.technalysis.com/engineering_software.aspx PASSAGE®/DEM]\n* [http://www.applieddem.com/software/ Bulk Flow Analyst]\n* [http://www.rocky-dem.com/ Rocky DEM - Discrete Element Modeling and Particle Simulation Software that quickly and accurately simulates the flow behavior]\n\n== See also ==\n*[[Movable Cellular Automata]]\n\n==References==\n{{Reflist}}\n\n==Bibliography==\n\n'''Book'''\n\n* {{cite encyclopedia |last=Bicanic |first=Ninad |title=Discrete Element Methods |editor1-last=Stein |editor1-first=Erwin |editor2-last=De Borst |editor3-last=Hughes |editor3-first=Thomas J.R. |encyclopedia=Encyclopedia of Computational Mechanics |volume=1 |publisher=Wiley |date=2004 |isbn=978-0-470-84699-5}}\n* {{cite book|last1=Griebel|first1=Michael|title=Numerische Simulation in der Moleküldynamik |date=2003 |publisher=Springer |location=Berlin |isbn=978-3-540-41856-6|display-authors=etal}}\n* {{cite journal |last1=Williams |first1=J. R. |last2=Hocking |first2=G. |last3=Mustoe |first3=G. G. W. |title=The Theoretical Basis of the Discrete Element Method |journal=NUMETA 1985, Numerical Methods of Engineering, Theory and Applications |publisher=A.A. Balkema |location=Rotterdam |date=January 1985 |ref=harv}}\n* {{cite book |last1=Williams |first1=G.N. |last2=Pande |first2=G. |last3=Beer |first3=J.R. |title=Numerical Methods in Rock Mechanics |date=1990 |publisher=Wiley |location=Chichester |isbn=978-0471920212 |ref=harv}}\n* {{cite book |editor1-last=Radjai |editor1-first=Farang |editor2-last=Dubois |editor2-first=Frédéric |title=Discrete-element modeling of granular materials |date=2011 |publisher=Wiley-ISTE |location=London |isbn=978-1-84821-260-2 |url=http://www.iste.co.uk/index.php?f=x&ACTION=View&id=384,}}\n* {{cite book |last1=Pöschel |first1=Thorsten |last2=Schwager |first2=Thoms |title=Computational Granular Dynamics: Models and Algorithms |date=2005 |publisher=Springer |location=Berlin |isbn=978-3-540-21485-4}}\n\n'''Periodical'''\n\n* {{cite journal |last1=Bobet |first1=A. |last2=Fakhimi |first2=A. |last3=Johnson |first3=S. |last4=Morris |first4=J. |last5=Tonon |first5=F. |last6=Yeung |first6=M. Ronald |title=Numerical Models in Discontinuous Media: Review of Advances for Rock Mechanics Applications |journal=Journal of Geotechnical and Geoenvironmental Engineering |date=November 2009 |volume=135 |issue=11 |pages=1547–1561 |doi=10.1061/(ASCE)GT.1943-5606.0000133}}\n* {{cite journal |last1=Cundall |first1=P. A. |last2=Strack |first2=O. D. L. |title=A discrete numerical model for granular assemblies |journal=Géotechnique |date=March 1979 |volume=29 |issue=1 |pages=47–65 |doi=10.1680/geot.1979.29.1.47}}\n* {{cite journal |last1=Kawaguchi |first1=T. |last2=Tanaka |first2=T. |last3=Tsuji |first3=Y. |title=Numerical simulation of two-dimensional fluidized beds using the discrete element method (comparison between the two- and three-dimensional models) |journal=Powder Technology |date=May 1998 |volume=96 |issue=2 |pages=129–138|doi=10.1016/S0032-5910(97)03366-4 |url=http://www-mupf.mech.eng.osaka-u.ac.jp/paper_pdf/PT98,v96,129}}\n* {{cite journal |last1=Williams |first1=J. R. |last2=O'Connor |first2=R. |title=Discrete element simulation and the contact problem |journal=Archives of Computational Methods in Engineering |date=December 1999 |volume=6 |issue=4 |pages=279–304 |doi=10.1007/BF02818917|citeseerx=10.1.1.49.9391 }}\n* {{cite journal |last1=Zhu |first1=H.P. |last2=Zhou |first2=Z.Y. |last3=Yang |first3=R.Y. |last4=Yu |first4=A.B. |title=Discrete particle simulation of particulate systems: Theoretical developments |journal=Chemical Engineering Science |date=July 2007 |volume=62 |issue=13 |pages=3378–3396 |doi=10.1016/j.ces.2006.12.089}}\n* {{cite journal |last1=Zhu |first1=HP |last2=Zhou |first2=ZY |last3=Yang |first3=RY |last4=Yu |first4=AB |title=Discrete particle simulation of particulate systems: A review of major applications and findings |journal=Chemical Engineering Science |date=2008 |volume=63 |issue=23 |pages=5728–5770 |url=http://www.dem-solutions.com/papers/discrete-particle-simulation-of-particulate-systems-a-review-of-major-applications-and-findings/ |doi=10.1016/j.ces.2008.08.006}}\n\n'''Proceedings'''\n* {{cite journal |last1=Shi |first1=Gen‐Hua |title=Discontinuous Deformation Analysis: A New Numerical Model For The Statics And Dynamics of Deformable Block Structures |journal=Engineering Computations |date=February 1992 |volume=9 |issue=2 |pages=157–168 |doi=10.1108/eb023855 |ref=harv}}\n* {{cite journal|last1=Williams|first1=John R.|last2=Pentland|first2=Alex P.|title=Superquadrics and Modal Dynamics For Discrete Elements in Interactive Design|journal=Engineering Computations|date=February 1992|volume=9|issue=2|pages=115–127|doi=10.1108/eb023852}}\n* {{cite book |editor1-last=Williams |editor1-first=John R. |editor2-last=Mustoe |editor2-first=Graham G. W. |title=Proceedings of the 2nd International Conference on Discrete Element Methods (DEM) |date=1993 |publisher=IESL Publications |location=Cambridge, MA |isbn=978-0-918062-88-8 |edition=2nd}}\n\n{{DEFAULTSORT:Discrete Element Method}}\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Dormand–Prince method",
      "url": "https://en.wikipedia.org/wiki/Dormand%E2%80%93Prince_method",
      "text": "In [[numerical analysis]], the '''Dormand–Prince''' ('''RKDP''') '''method''' or '''DOPRI method''', is an explicit method for solving [[ordinary differential equations]] {{harv|Dormand|Prince|1980}}. The method is a member of the [[Runge–Kutta]] family of ODE solvers. More specifically, it uses six function evaluations to calculate fourth- and fifth-order accurate solutions. The difference between these solutions is then taken to be the error of the (fourth-order) solution. This error estimate is very convenient for adaptive stepsize integration algorithms. Other similar integration methods are [[Runge–Kutta–Fehlberg method|Fehlberg]] (RKF) and [[Cash–Karp]] (RKCK).\n\nThe Dormand–Prince method has seven stages, but it uses only six function evaluations per step because it has the FSAL (First Same As Last) property: the last stage is evaluated at the same point as the first stage of the next step. Dormand and Prince chose the coefficients of their method to minimize the error of the fifth-order solution. This is the main difference with the Fehlberg method, which was constructed so that the fourth-order solution has a small error. For this reason, the Dormand–Prince method is more suitable when the higher-order solution is used to continue the integration, a practice known as local extrapolation ({{harvnb|Shampine|1986}}; {{harvnb|Hairer|Nørsett|Wanner|2008|pages=178–179}}).\n\nDormand–Prince is currently the default method in the <code>ode45</code> solver for [[MATLAB]] and [[GNU Octave]] and is the default choice for the [[Simulink]]'s model explorer solver. A [[Fortran]] [[free software]] implementation of the algorithm called {{mono|DOPRI5}} is also available.<ref>See http://www.unige.ch/~hairer/prog/nonstiff/dopri5.f</ref>\n\nThe [[Butcher tableau]] is:\n{| cellpadding=3px cellspacing=0px\n|width=\"20px\"| || style=\"border-right:1px solid;\" | 0\n|- \n||| style=\"border-right:1px solid;\" | 1/5 || 1/5\n|- \n||| style=\"border-right:1px solid;\" | 3/10 || 3/40 || 9/40\n|- \n||| style=\"border-right:1px solid;\" | 4/5  || 44/45 || −56/15 || 32/9\n|- \n||| style=\"border-right:1px solid;\" | 8/9  || 19372/6561 || −25360/2187 || 64448/6561 || −212/729\n|- \n||| style=\"border-right:1px solid;\" | 1 || 9017/3168 || −355/33 || 46732/5247 || 49/176 || −5103/18656\n|-\n||| style=\"border-right:1px solid; border-bottom:1px solid;\" | 1 || style=\"border-bottom:1px solid;\" | 35/384 || style=\"border-bottom:1px solid;\" | 0 || style=\"border-bottom:1px solid;\" | 500/1113 || style=\"border-bottom:1px solid;\" | 125/192 || style=\"border-bottom:1px solid;\" | −2187/6784 || style=\"border-bottom:1px solid;\" | 11/84 || style=\"border-bottom:1px solid;\" |\n|- \n||| style=\"border-right:1px solid;\" | || 35/384 || 0 || 500/1113 || 125/192 || −2187/6784 || 11/84 || 0\n|-\n||| style=\"border-right:1px solid;\" | || 5179/57600 || 0 || 7571/16695 || 393/640 || −92097/339200 || 187/2100 || 1/40 \n|}\n\nThe first row of ''b'' coefficients gives the fifth-order accurate solution, and the second row gives an alternative solution which, when subtracted from the first solution, yields the error estimate.\n\n== Notes==\n<references/>\n\n== References ==\n* Software implementation in [[MATLAB]]: https://www.mathworks.com/help/matlab/ref/ode45.html\n* Implementation in [[GNU Octave]]: https://octave.org/doc/interpreter/Matlab_002dcompatible-solvers.html#Matlab_002dcompatible-solvers\n* Implementation in [[Python (programming language)]] : https://web.archive.org/web/20150907215914/http://adorio-research.org/wordpress/?p=6565\n* {{Citation | last1=Dormand | first1=J. R. | last2=Prince | first2=P. J. | title=A family of embedded Runge-Kutta formulae | doi=10.1016/0771-050X(80)90013-3 | year=1980 | journal=Journal of Computational and Applied Mathematics | volume=6 | issue=1 | pages=19–26}}.\n* {{Citation | last1=Dormand | first1=John R. | title=Numerical Methods for Differential Equations: A Computational Approach | year=1996 | publisher=CRC Press| location=Boca Raton| isbn=0-8493-9433-3| pages=82–84}}.\n* {{Citation | last1=Hairer | first1=Ernst | last2=Nørsett | first2=Syvert Paul | last3=Wanner | first3=Gerhard | title=Solving ordinary differential equations I: Nonstiff problems | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-56670-0 | year=2008}}.\n* {{Citation | last1=Shampine | first1=Lawrence F. | title=Some Practical Runge-Kutta Formulas | year=1986 | journal=[[Mathematics of Computation]] | volume=46 | issue=173 | pages=135–150 | doi=10.2307/2008219 | jstor=2008219 | publisher=American Mathematical Society}}.\n\n{{DEFAULTSORT:Dormand-Prince method}}\n[[Category:Numerical differential equations]]\n[[Category:Runge–Kutta methods]]"
    },
    {
      "title": "Energy drift",
      "url": "https://en.wikipedia.org/wiki/Energy_drift",
      "text": "In [[computer simulation]]s of mechanical systems, '''energy drift''' is the gradual change in the total energy of a closed system over time.  According to the laws of mechanics, the energy should be a [[constant of motion]] and should not change. However, in simulations the energy might fluctuate on a short time scale and increase or decrease on a very long time scale due to [[numerical ordinary differential equations|numerical integration]] artifacts that arise with the use of a finite time step ''Δt''.  This is somewhat similar to the [[flying ice cube]] problem, whereby numerical errors in handling equipartition of energy can change vibrational energy into translational energy.\n\nMore specifically, the energy tends to increase exponentially; its increase can be understood intuitively because each step introduces a small perturbation δ'''v''' to the true velocity '''v<sub>true</sub>''', which (if uncorrelated with '''v''', which will be true for simple integration methods) results in a second-order increase in the energy\n\n:<math>\nE = \\sum m \\mathbf{v}^{2} = \\sum m \\mathbf{v}_{true}^{2} + \\sum m \\ \\delta \\mathbf{v}^{2}\n</math>\n\n(The cross term in '''v''' · δ'''v''' is zero because of no correlation.)\n\nEnergy drift - usually damping - is substantial for numerical integration schemes that are not [[symplectic integrator|symplectic]], such as the [[Runge-Kutta]] family. Symplectic integrators usually used in molecular dynamics, such as the [[Verlet integration|Verlet integrator]] family, exhibit increases in energy over very long time scales, though the error remains roughly constant. These integrators do not in fact reproduce the actual [[Hamiltonian mechanics]] of the system; instead, they reproduce a closely related \"shadow\" Hamiltonian whose value they conserve many orders of magnitude more closely. The accuracy of the energy conservation for the true Hamiltonian is dependent on the time step.<ref name=\"Gans\">Gans J, Shalloway D. (2000). Shadow mass and the relationship between velocity and momentum in symplectic numerical integration. ''Phys. Rev. E'' 61(4):4587–4592.</ref><ref name=\"Engle\">Engle RD, Skeel RD, Drees M. (2005). Monitoring energy drift with shadow Hamiltonians. ''J Comput Phys'' 206:432–452</ref> The energy computed from the modified Hamiltonian of a symplectic integrator is <math>\\mathcal{O}\\left(\\Delta t^{p}\\right)</math> from the true Hamiltonian.\n\nEnergy drift is similar to [[parametric oscillator#Parametric resonance|parametric resonance]] in that a finite, discrete timestepping scheme will result in nonphysical, limited sampling of motions with [[frequency|frequencies]] close to the frequency of velocity updates. Thus the restriction on the maximum step size that will be stable for a given system is proportional to the period of the fastest [[fundamental mode]]s of the system's motion. For a motion with a natural frequency ω, artificial resonances are introduced when the frequency of velocity updates, <math>\\frac{2\\pi}{\\Delta t}</math> is related to ω as \n:<math>\n\\frac{n}{m}\\omega = \\frac{2\\pi}{\\Delta t}\n</math>\nwhere ''n'' and ''m'' are integers describing the resonance order. For Verlet integration, resonances up to the fourth order <math>\\left(\\frac{n}{m} = 4\\right)</math> frequently lead to numerical instability, leading to a restriction on the timestep size of \n:<math>\n\\Delta t < \\frac{\\sqrt{2}}{\\omega} \\approx 0.225p\n</math>\nwhere ω is the frequency of the fastest motion in the system and ''p'' is its period.<ref name=\"Schlick\">Schlick T. (2002). ''Molecular Modeling and Simulation: An Interdisciplinary Guide''. Interdisciplinary Applied Mathematics series, vol. 21. Springer: New York, NY, USA. {{ISBN|0-387-95404-X}}. See pp420-430 for complete derivation.</ref> The fastest motions in most biomolecular systems involve the motions of [[hydrogen]] atoms; it is thus common to use [[constraint algorithm]]s to restrict hydrogen motion and thus increase the maximum stable time step that can be used in the simulation. However, because the time scales of heavy-atom motions are not widely divergent from those of hydrogen motions, in practice this allows only about a twofold increase in time step. Common practice in all-atom biomolecular simulation is to use a time step of 1 [[femtosecond]] (fs) for unconstrained simulations and 2 fs for constrained simulations, although larger time steps may be possible for certain systems or choices of parameters.\n\nEnergy drift can also result from imperfections in evaluating the [[function (mathematics)|energy function]], usually due to simulation parameters that sacrifice accuracy for computational speed. For example, cutoff schemes for evaluating the [[electrostatic]] forces introduce systematic errors in the energy with each time step as particles move back and forth across the cutoff radius if sufficient smoothing is not used. [[Particle mesh Ewald]] summation is one solution for this effect, but introduces artifacts of its own. Errors in the system being simulated can also induce energy drifts characterized as \"explosive\" that are not artifacts, but are reflective of the instability of the initial conditions; this may occur when the system has not been subjected to sufficient structural minimization before beginning production dynamics. In practice, energy drift may be measured as a percent increase over time, or as a time needed to add a given amount of energy to the system. The practical effects of energy drift depend on the simulation conditions, the [[thermodynamic ensemble]] being simulated, and the intended use of the simulation under study; for example, energy drift has much more severe consequences for simulations of the [[microcanonical ensemble]] than the [[canonical ensemble]] where the temperature is held constant. Energy drift is often used as a measure of the quality of the simulation, and has been proposed as one quality metric to be routinely reported in a mass repository of molecular dynamics trajectory data analogous to the [[Protein Data Bank]].<ref name=\"Sansom\">Murdock SE, Tai K, Ng MH, Johnston S, Wu B, Fangohr H, Laughton CA, Essex JW, Sansom MSP. (2006). Quality assurance for biomolecular simulations. ''J Chem Theory Comput'' 2(6): 1477&ndash;1481.</ref>\n\n==References==\n<references />\n\n===Further reading===\n* Sanz-Serna JM, Calvo MP. (1994). ''Numerical Hamiltonian Problems''. Chapman & Hall, London, England.\n\n[[Category:Molecular dynamics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "ENO methods",
      "url": "https://en.wikipedia.org/wiki/ENO_methods",
      "text": "{{short description|Class of high-resolution schemes in numerical solutions of differential equations}}{{one source\n| date = January 2019\n}}'''ENO (essentially non-oscillatory) methods''' are classes of [[high-resolution scheme]]s in numerical solution of [[differential equations]]. \n\n== History ==\nThe first ENO scheme was developed by [[Ami Harten|Harten]], [[Björn Engquist|Engquist]], [[Stanley Osher|Osher]] and Chakravarthy in 1987. In 1994, the first [[WENO methods|weighted version]] of ENO was developed.<ref>{{cite journal |doi=10.1006/jcph.1994.1187 |title=Weighted Essentially Non-oscillatory Schemes |journal=Journal of Computational Physics |volume=115 |pages=200–212 |year=1994 |last1=Liu |first1=Xu-Dong |last2=Osher |first2=Stanley |last3=Chan |first3=Tony |citeseerx=10.1.1.24.8744 }}</ref>\n\n==See also==\n*[[High-resolution scheme]]\n*[[WENO methods]]\n*[[Shock-capturing method]]\n\n==References==\n{{reflist}}\n\n{{Numerical PDE}}\n\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]\n\n\n{{applied-math-stub}}"
    },
    {
      "title": "Euler–Maruyama method",
      "url": "https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method",
      "text": "{{dablink|This article is about numerical methods in stochastic models ([[stochastic differential equation]]s). For the same issue, but in deterministic realm, see [[Euler method]] and [[Ordinary differential equation]].}}\n\nIn [[Itô calculus]], the '''Euler–Maruyama method''' (also called the '''Euler method''') is a method for the approximate [[numerical analysis|numerical solution]] of a [[stochastic differential equation]] (SDE). It is a simple generalization of the [[Euler method]] for [[ordinary differential equation]]s to stochastic differential equations. It is named after [[Leonhard Euler]] and [[Gisiro Maruyama]]. Unfortunately, the same generalization cannot be done for any arbitrary deterministic method <ref>{{cite book |author1=Kloeden, P.E. |author2= Platen, E. |last-author-amp=yes | title=Numerical Solution of Stochastic Differential Equations | publisher=Springer, Berlin | year=1992 | isbn=3-540-54062-8 }}</ref>.\n\nConsider the stochastic differential equation (see [[Itô calculus]])\n\n:<math>\\mathrm{d} X_t = a(X_t) \\, \\mathrm{d} t + b(X_t) \\, \\mathrm{d} W_t,</math>\n\nwith [[initial condition]] ''X''<sub>0</sub>&nbsp;=&nbsp;''x''<sub>0</sub>, where ''W''<sub>''t''</sub> stands for the [[Wiener process]], and suppose that we wish to solve this SDE on some interval of time [0,&nbsp;''T'']. Then the '''Euler–Maruyama approximation''' to the true solution ''X'' is the [[Markov chain]] ''Y'' defined as follows:\n\n* partition the interval [0,&nbsp;''T''] into ''N'' equal subintervals of width <math>\\Delta t>0</math>:\n\n::<math>0 = \\tau_{0} < \\tau_{1} < \\cdots < \\tau_{N} = T \\text{ and } \\Delta t = T/N;</math>\n\n* set ''Y''<sub>0</sub>&nbsp;=&nbsp;''x''<sub>0</sub>;\n* recursively define ''Y''<sub>''n''</sub> for 1&nbsp;≤&nbsp;''n''&nbsp;≤&nbsp;''N'' by\n\n::<math>\\, Y_{n + 1} = Y_n + a(Y_n) \\, \\Delta t + b(Y_n) \\, \\Delta W_n,</math>\n\n:where\n\n::<math>\\Delta W_n = W_{\\tau_{n + 1}} - W_{\\tau_n}.</math>\n\nThe [[random variable]]s Δ''W''<sub>''n''</sub> are [[independent and identically distributed]] [[normal distribution|normal random variables]] with [[expected value]] zero and [[variance]] <math>\\Delta t</math>.\n\n==Example==\n\n=== Numerical simulation ===\n[[File:Equação Diferencial Estocástica.jpg|thumbnail|Gene expression modelled as stochastic process]]\n\nAn area that has benefited significantly from SDE is biology or more precisely [[mathematical biology]]. Here the number of publications on the use of stochastic model grew, as most of the models are nonlinear, demanding numerical schemes.\n\nThe graphic depicts a stochastic differential equation being solved using the Euler Scheme. The deterministic counterpart is shown as well.\n\n=== Computer implementation ===\nThe following [[Python (programming language)|Python]] code implements the Euler–Maruyama method and uses it to solve the [[Ornstein–Uhlenbeck process]] defined by\n\n:<math> dY_t=\\theta \\cdot (\\mu-Y_t) \\, {\\mathrm d}t + \\sigma \\, {\\mathrm d}W_t</math>\n\n:<math> Y_0=Y_\\mathrm{init}.</math>\n\nThe random numbers for <math>{\\mathrm d}W_t</math> are generated using the [[NumPy]] mathematics package.\n\n<source lang=\"python\" line=\"1\">\n# -*- coding: utf-8 -*-\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnum_sims = 5 ### display five runs\n\nt_init = 3\nt_end  = 7\nN      = 1000 ### Compute 1000 grid points\ndt     = float(t_end - t_init) / N \ny_init = 0\n\nc_theta = 0.7\nc_mu    = 1.5\nc_sigma = 0.06\n\ndef mu(y, t): \n    \"\"\"Implement the Ornstein–Uhlenbeck mu.\"\"\" ## = \\theta (\\mu-Y_t)\n    return c_theta * (c_mu - y)\n\ndef sigma(y, t): \n    \"\"\"Implement the Ornstein–Uhlenbeck sigma.\"\"\" ## = \\sigma\n    return c_sigma\n    \ndef dW(delta_t): \n    \"\"\"Sample a random number at each call.\"\"\"\n    return np.random.normal(loc = 0.0, scale = np.sqrt(delta_t))\n\nts    = np.arange(t_init, t_end, dt)\nys    = np.zeros(N)\n\nys[0] = y_init\n\nfor _ in range(num_sims):\n    for i in range(1, ts.size):\n        t = (i-1) * dt\n        y = ys[i-1]\n        ys[i] = y + mu(y, t) * dt + sigma(y, t) * dW(dt)\n    plt.plot(ts, ys)\n\nplt.show()\n</source>\n\n== See also ==\n* [[Milstein method]]\n* [[Runge–Kutta method (SDE)]]\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Euler-Maruyama method}}\n[[Category:Numerical differential equations]]\n[[Category:Stochastic differential equations]]\n[[Category:Leonhard Euler]]\n[[Category:Articles with example Python code]]"
    },
    {
      "title": "Explicit and implicit methods",
      "url": "https://en.wikipedia.org/wiki/Explicit_and_implicit_methods",
      "text": "{{Unreferenced|date=December 2009}}\n'''Explicit and implicit methods''' are approaches used in [[numerical analysis]] for obtaining numerical approximations to the solutions of time-dependent [[ordinary differential equation|ordinary]] and [[partial differential equation]]s, as is required in [[computer simulation]]s of [[Process (science)|physical processes]].\n\n'''Explicit methods''' calculate the state of a system at a later time from the state of the system at the current time, while '''implicit methods''' find a solution by solving an equation involving both the current state of the system and the later one. Mathematically, if <math>Y(t)</math> is the current system state and <math>Y(t+\\Delta t)</math> is the state at the later time (<math>\\Delta t</math> is a small time step), then, for an explicit method \n: <math>Y(t+\\Delta t) = F(Y(t))\\,</math>\nwhile for an implicit method one solves an equation\n: <math>G\\Big(Y(t), Y(t+\\Delta t)\\Big)=0  \\qquad (1)\\,</math>\nto find <math>Y(t+\\Delta t).</math>\n\nIt is clear that implicit methods require an extra computation (solving the above equation), and they can be much harder to implement. Implicit methods are used because many problems arising in practice are [[Stiff equation|stiff]], for which the use of an explicit method requires impractically small time steps <math>\\Delta t</math> to keep the error in the result bounded (see [[numerical stability]]).  For such problems, to achieve given accuracy, it takes much less computational time to use an implicit method with larger time steps, even taking into account that one needs to solve an equation of the form (1) at each time step. That said, whether one should use an explicit or implicit method depends upon the problem to be solved. \n\nSince the implicit method cannot be carried out for each kind of differential operator, it is sometimes advisable to make use of the so called operator splitting method, which means that the differential operator is rewritten as the sum of two complementary operators\n:<math>Y(t+\\Delta t) = F(Y(t+\\Delta t))+G(Y(t)),\\,</math> \nwhile one is treated explicitly and the other implicitly.\nFor usual applications the implicit term is chosen to be linear while the explicit term can be nonlinear. This combination of the former method is called '''Implicit-Explicit Method''' (short IMEX <ref>U.M. Ascher, S.J. Ruuth, R.J. Spiteri: ''Implicit-Explicit Runge-Kutta Methods\nfor Time-Dependent Partial Differential Equations'', Appl Numer Math, vol. 25(2-3), 1997</ref>, <ref>L.Pareschi, G.Russo: ''Implicit-Explicit Runge-Kutta schemes for stiff systems of differential equations'', Recent Trends in Numerical Analysis, Vol. 3, 269-289, 2000</ref>).\n\n==Illustration using the forward and backward Euler methods==\nConsider the [[ordinary differential equation]]\n\n: <math>\\frac{dy}{dt} = -y^2, \\ t\\in [0, a]\\quad \\quad (2)</math>\n\nwith the initial condition <math>y(0)=1.</math> Consider a grid <math>t_k=a\\frac{k}{n}</math> for 0&nbsp;≤&nbsp;''k''&nbsp;≤&nbsp;''n'', that is, the time step is <math>\\Delta t=a/n,</math> and denote <math>y_k=y(t_k)</math> for each <math>k</math>. [[Discretization|Discretize]] this equation using the simplest explicit and implicit methods, which are the ''forward Euler'' and ''backward Euler '' methods (see [[numerical ordinary differential equations]]) and compare the obtained schemes.\n\n;Forward Euler method:\n[[File:Forward and backward Euler method.png|thumb|350px|The result of applying the two methods with <math>a = 5</math> and <math>n = 30</math>.]]\nThe forward [[Euler method]]\n:<math>\\left(\\frac{dy}{dt}\\right)_k \\approx \\frac{y_{k+1}-y_k}{\\Delta t} = - y_k^2</math>\nyields\n: <math>y_{k+1}=y_k-\\Delta t y_k^2 \\quad \\quad \\quad(3)\\, </math>\nfor each <math>k=0, 1, \\dots, n.</math> This is an explicit formula for <math>y_{k+1}</math>.\n\n;Backward Euler method:\nWith the [[backward Euler method]]\n:<math>\\frac{y_{k+1}-y_k}{\\Delta t} = - y_{k+1}^2</math>\n\none finds the implicit equation\n: <math>y_{k+1}+\\Delta t y_{k+1}^2=y_k</math>\nfor <math>y_{k+1}</math> (compare this with formula (3) where <math>y_{k+1}</math> was given explicitly rather than as an unknown in an equation).\n\nThis is a [[quadratic equation]], having one negative and one positive [[Root of a function|root]]. The positive root is picked because in the original equation the initial condition is positive, and then <math>y</math> at the next time step is given by\n: <math>y_{k+1}=\\frac{-1+\\sqrt{1+4\\Delta t y_k}}{2 \\Delta t}. \\quad \\quad (4)</math>\n\nIn the vast majority of cases, the equation to be solved when using an implicit scheme is much more complicated than a quadratic equation, and no analytical solution exists. Then one uses [[root-finding algorithm]]s, such as [[Newton's method]], to find the numerical solution.\n\n;Forward-Backward Euler method:\n[[File:Comparison_between_Foward-Backward-Euler_and_Foward-Euler.png|thumb|400px|The result of applying the both, the Forward Euler method as well as the Forward-Backward Euler method <math>a = 5</math> and <math>n = 30</math>.]]\nIn order to apply the IMEX-scheme, consider a slightly different differential equation:\n: <math>\\frac{dy}{dt} = y-y^2, \\ t\\in [0, a]\\quad \\quad (5)</math>\nIt follows that\n: <math>\\left(\\frac{dy}{dt}\\right)_k \\approx y_{k+1}-y_{k}^2, \\ t\\in [0, a]</math>\nand therefore\n: <math>y_{k+1}=\\frac{y_k(1-y_k\\Delta t)}{1-\\Delta t} \\quad\\quad(6)</math>\nfor each <math>k=0, 1, \\dots, n.</math>\n\n==See also==\n* [[Courant–Friedrichs–Lewy condition]]\n* [[SIMPLE algorithm]], a semi-implicit method for pressure-linked equations\n\n==Sources==\n{{reflist}}\n\n{{DEFAULTSORT:Explicit And Implicit Methods}}\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Extended discrete element method",
      "url": "https://en.wikipedia.org/wiki/Extended_discrete_element_method",
      "text": "[[File:Internal temperature distribution in a particle.png|thumb|An internal temperature distribution for a spherical particle versus radius and time under a time-varying [[heat flux]].]]\n\nThe '''extended discrete element method''' (XDEM) is a numerical technique that extends the dynamics of granular material or particles as described through the classical [[discrete element method]] (DEM) (Cundall<ref>{{cite journal\n| first1=P. A.\n| last1=Cundall\n| first2=O. D. L.\n| last2=Strack\n| title=A discrete numerical model for granular assemblies\n| journal=Geotechnique\n| year=1979\n| volume=29\n| pages=47–65\n| doi=10.1680/geot.1979.29.1.47\n}}</ref> and Allen<ref>{{cite book\n| first1=M. P.\n| last1=Allen\n| authorlink1=M. P. Allen\n| first2=D. J.\n| last2=Tildesley\n| authorlink2=D. J. Tildesley\n| title=Computer Simulation of Liquids\n| publisher=Claredon Press Oxford\n| year=1990}}</ref>) by additional properties such as the [[thermodynamic]] state, [[Stress (mechanical)|stress]]/[[Deformation (mechanics)|strain]] or [[electro-magnetic]] field for each particle. Contrary to a [[continuum mechanics]] concept, the XDEM aims at resolving the particulate phase with its various processes attached to the particles. While the discrete element method predicts position and orientation in space and time for each particle, the extended discrete element method additionally estimates properties such as internal [[temperature]]  and/or [[species]] distribution or mechanical impact with structures.\n\n==History==\n\nMolecular dynamics developed in the late 1950s by Alder et al.<ref>{{cite journal\n| first1=B. J.\n| last1=Alder\n| first2=T. E.\n| last2=Wainwright\n| title=Studies in Molecular Dynamics. I. General Method\n| journal=J. Chem. Phys.\n| year=1959\n| volume=31\n| issue=2\n| pages=459–466\n| doi=10.1063/1.1730376\n| bibcode=1959JChPh..31..459A}}</ref> and early 1960s by Rahman<ref>{{cite journal\n| first1=A.\n| last1=Rahman\n| title=Correlations in the Motion of Atoms in Liquid Argon\n| journal=Phys. Rev.\n| year=1964\n| volume=136\n| issue=2A\n| doi=10.1103/physrev.136.a405\n| pages=A405–A411\n|bibcode = 1964PhRv..136..405R }}</ref> may be regarded as a first step toward the extended discrete element method, although the forces due to collisions between particles were replaced by energy potentials e.g. [[Lennard-Jones]] potentials of [[molecules]] and [[atoms]] as long range forces to determine interaction.\n\nSimilarly, the fluid dynamic interaction of particles suspended in a flow were investigated. The [[drag (physics)|drag]] forces exerted on the particles by the relative velocity by them and the flow were treated as additional forces acting on the particles. Therefore, these [[multiphase flow]] phenomena including a solid e.g.~particulate and a gaseous or fluid phase resolve the particulate phase by discrete methods, while gas or liquid flow is described by continuous methods, and therefore, is labelled the combined continuum and discrete model (CCDM) as applied by Kawaguchi et al.,<ref>{{cite journal\n| first1=T.\n| last1=Kawaguchi\n| first2=Y.\n| last2=Tsuji\n| first3=T.\n| last3=Tanaka\n| title=Discrete particle simulation of two-dimensional fluidized bed\n| journal=Powder Technol.\n| year=1993\n| volume=77\n| doi=10.1016/0032-5910(93)85010-7\n| pages=79–87\n}}</ref> Hoomans,<ref>{{cite journal\n| first1=B. P. B.\n| last1=Hoomans\n| first2=J. A. M.\n| last2=Kuipers\n| first3=W. J.\n| last3=Briels\n| first4=W. P. M.\n| last4=Van Swaaij\n| title=Discrete particle simulation of bubble and slug formation in a two-dimensional gas-fluidized bed: A hard-sphere approach\n| journal=Chem. Eng. Sci.\n| year=1996\n| volume=51\n| doi=10.1016/0009-2509(95)00271-5\n| pages=99–118\n| citeseerx=10.1.1.470.6532\n}}</ref> Xu 1997<ref>{{cite journal\n| first1=B. H.\n| last1=Xu\n| first2=A. B.\n| last2=Yu\n| title=Numerical simulation of the gas-solid flow in a fluidized bed by combining discrete particle method with computational fluid dynamics\n| journal=Chemical Engineering Science\n| year=1997\n| volume=52\n| issue=16\n| pages=2785–2809\n| doi=10.1016/s0009-2509(97)00081-x\n}}</ref> and Xu 1998.<ref>{{cite journal\n| first1=B. H.\n| last1=Xu\n| first2=A. B.\n| last2=Yu\n| title=Comments on the paper numerical simulation of the gas-solid flow in a fluidized bed by combining discrete particle method with computational fluid dynamics\n| journal=Chemical Engineering Science\n| year=1998\n| volume=53\n| issue=14\n| pages=2646–2647\n| doi=10.1016/s0009-2509(98)00086-4\n}}</ref>  Due to a discrete description of the solid phase, [[constitutive equation|constitutive]] relations are omitted, and therefore, leads to a better understanding of the fundamentals. This was also concluded by Zhu 2007 et al.<ref>{{cite journal\n| first1=H. P.\n| last1=Zhu\n| first2=Z. Y.\n| last2=Zhou\n| first3=R. Y.\n| last3=Yang\n| first4=A. B.\n| last4=Yu\n| title=Discrete particle simulation of particulate systems: Theoretical developments\n| journal=Chemical Engineering Science\n| year=2007\n| volume=62\n| issue=13\n| pages=3378–3396\n| doi=10.1016/j.ces.2006.12.089\n}}</ref> and Zhu 2008 et al.<ref>{{cite journal\n| first1=H. P.\n| last1=Zhu\n| first2=Z. Y.\n| last2=Zhou\n| first3=R. Y.\n| last3=Yang\n| first4=A. B.\n| last4=Yu\n| title=Discrete particle simulation of particulate systems: A review of major applications and findings\n| journal=Chemical Engineering Science\n| year=2008\n| volume=63\n| issue=23\n| pages=5728–5770\n| doi=10.1016/j.ces.2008.08.006\n}}</ref> during a review on particulate flows modelled with the CCDM approach. It has seen a mayor development in last two decades and describes motion of the solid phase by the [[Discrete Element Method]] (DEM) on an individual particle scale and the remaining phases are treated by the [[Navier-Stokes]] equations. Thus, the method is recognized as an effective tool to investigate into the interaction between a particulate and fluid phase as reviewed by Yu and Xu,<ref>{{cite journal\n| first1=B. H.\n| last1=Xu\n| first2=A. B.\n| last2=Yu\n| title=Particle-scale modelling of gas-solid flow in fluidisation\n| journal=Journal of Chemical Technology and Biotechnology\n| year=2003\n| volume=78\n| issue=2–3\n| pages=111–121\n| doi=10.1002/jctb.788\n}}</ref> Feng and Yu <ref>{{cite journal\n| first1=Y. Q.\n| last1=Feng\n| first2=A. B.\n| last2=Yu\n| first3=A. B.\n| last3=Yu\n| first4=A.\n| last4=Vince\n| title=Assessment of model formulations in the discrete particle simulation of gas-solid flow\n| journal=Industrial & Engineering Chemistry Research\n| year=2004\n| volume=43\n| issue=26\n| pages=8378–8390\n| doi=10.1021/ie049387v\n}}</ref> and Deen et al.<ref>{{cite journal\n| first1=N. G.\n| last1=Deen\n| first2=M. V. S.\n| last2=Annaland\n| first3=M. A.\n| last3=Van Der Hoef\n| first4=J. A. M.\n| last4=Kuipers\n| title=Review of discrete particle modeling of fluidized beds\n| journal=Chemical Engineering Science\n| year=2007\n| volume=62\n| issue=1–2\n| pages=28–44\n| doi=10.1016/j.ces.2006.08.014\n}}</ref>  Based on the CCDM methodology the characteristics of spouted and fluidised beds are predicted by Gryczka et al.<ref>{{cite journal\n| first1=O.\n| last1=Gryczka\n| first2=S.\n| last2=Heinrich\n| first3=N. S.\n| last3=Deen\n| first4=M.\n| last4=van Sint Annaland\n| first5=J. A. M.\n| last5=Kuipers\n| first6=M.\n| last6=Mörl\n| title=CFD modeling of a prismatic spouted bed with two adjustable gas inlets\n| journal=Canadian Journal of Chemical Engineering\n| year=2009\n| volume=87\n| issue=2\n| pages=318–328\n| doi=10.1002/cjce.20143\n| citeseerx=10.1.1.335.4108\n}}</ref>\n\nThe theoretical foundation for the XDEM was developed in 1999 by Peters,<ref>{{cite journal\n| first1=B.\n| last1=Peters\n| title=Classification of combustion regimes in a packed bed based on the relevant time and length scales\n| journal=Combustion and Flame\n| year=1999\n| volume=116\n| issue=1–2\n| pages=297–301\n| doi=10.1016/s0010-2180(98)00048-0\n}}</ref> who described incineration of a wooden moving bed on a forward acting grate.<ref>{{cite journal\n| first1=B.\n| last1=Peters\n| title=Measurements and application of a discrete particle model (DPM) to simulate combustion of a packed bed of individual fuel particles\n| journal=Combustion and Flame\n| year=2002\n| volume=131\n| issue=1–2\n| pages=132–146\n| doi=10.1016/s0010-2180(02)00393-0\n}}</ref>  The concept was later also employed by Sismsek et al.<ref>{{cite journal\n| first1=E.\n| last1=Simsek\n| first2=B.\n| last2=Brosch\n| first3=S.\n| last3=Wirtz\n| first4=V.\n| last4=Scherer\n| first5=F.\n| last5=Kröll\n| title=Numerical simulation of grate firing systems using a coupled CFD/Discrete Element Method (DEM)\n| journal=Powder Technology\n| year=2009\n| volume=193\n| issue=3\n| pages=266–273\n| doi=10.1016/j.powtec.2009.03.011\n}}</ref> to predict the furnace process of a grate firing system. Applications to the complex processes of a blast furnace have been attempted by Shungo et al.<ref>{{cite journal\n| first1=Shungo\n| last1=Natsui\n| first2=Shigeru\n| last2=Ueda\n| first3=Zhengyun\n| last3=Fan\n| first4=Nils\n| last4=Andersson\n| first5=Junya\n| last5=Kano\n| first6=Ryo\n| last6=Inoue\n| first7=Tatsuro\n| last7=Ariyama\n| title=Characteristics of solid flow and stress distribution including asymmetric phenomena in blast furnace analyzed by discrete element method\n| journal=ISIJ International\n| year=2010\n| volume=50\n| issue=2\n| pages=207–214\n| doi=10.2355/isijinternational.50.207\n}}</ref> Numerical simulation of fluid injection into a gaseous environment nowadays is adopted by a large number of CFD-codes codes such as Star-CD of [[CD-adapco]], [[Ansys]] and [[AVL (Engineering Firm)|AVL]]-Fire. Droplets of a spray are treated by a zero-dimensional approach to account for heat and mass transfer to the fluid phase.\n\n==Methodology==\n[[File:Staggered methodology for software coupling.png|thumb|Staggered methodology for discrete/continuous applications.]]\n\nMany engineering problems exist that include continuous and discrete phases, and those problems cannot be simulated accurately by continuous or discrete approaches. XDEM provides a solution for some of those engineering applications.\n\nAlthough research and development of numerical methods in each domains of discrete and continuous solvers is still progressing, software tools are available. In order to couple discrete and continuous approaches, two major approaches are available:\n\n*'''Monolithic approach''': The equations describing multi-physics phenomena are solved simultaneously by a single solver producing a complete solution.\n*'''Partitioned or staggered approach''': The equations describing multi-physics phenomena are solved sequentially by appropriately tailored and distinct solvers with passing the results of one analysis as a load to the other.\n\nThe former approach requires a solver that handles all physical problems involved, therefore it requires a larger implementation effort. However, there exist scenarios for which it is difficult to arrange the coefficients of combined [[differential equations]] in one [[Matrix (mathematics)|matrix]].\n\nThe latter, partitioned, approach couples a number of solvers representing individual domains of physics offers advantages over a monolithic concept.  It encompasses a larger degree of flexibility because it can use many solvers. Furthermore, it allows a more modular software development. However, partitioned simulations require stable and accurate coupling algorithms.\n\nWithin the staggered concept of XDEM, continuous fields are described by the solution the respective continuous (conservation) equations. Properties of individual particles such as temperature are also resolved by solving respective conservation equations that yield both a spatial and temporal internal distribution of relevant variables. Major conservation principles with their equations and variables to be solved for and that are employed to an individual particle within XDEM are listed in the following table.\n\n{| border=\"2\" cellspacing=\"0\" align=\"right\" width=\"400\" cellpadding=\"3\" rules=\"all\" style=\"border-collapse:collapse; empty-cells:show; margin: 1em 0em 1em 1em; border: solid 1px #aaaaaa;\"\n|+ Conservation principles of Interfaces\n|- class=\"hintergrundfarbe6\"\n! [[Conservation law (physics)|Conservation law]]\n! [[Equation]]\n! [[Variable (mathematics)|Variable]]\n|-\n| Mass (compressible medium) || Continuity || Pressure/density\n|-\n| [[Linear Momentum]] || [[Navier-Stokes]] || Velocity\n|-\n| [[Energy]] || Energy || Temperature\n|-\n| Species mass || Species transport || Mass fractions\n|-\n| Charge, current || [[Maxwell's equations|Maxwell]] ||  electric, magnetic field, electric displacement field\n|}\n\nThe solution of these equations in principle defines a three-dimensional and transient field of the relevant variables such as temperature or species. However, the application of these conservation principles to a large number of particles usually restricts the resolution to at most one representative dimension and time due to CPU time consumption. Experimental evidence\nat least in reaction engineering supports the assumption of one-dimensionality as pointed out by Man and Byeong,<ref>{{cite journal\n| first1=Y. H.\n| last1=Man\n| first2=R. C.\n| last2=Byeong\n| title=A numerical study on the combustion of a single carbon particle entrained in a steady flow\n| journal=Combustion and Flame\n| year=1994\n| volume=97\n| pages=1–16\n| doi=10.1016/0010-2180(94)90112-0\n}}</ref> while the importance of a transient behaviour is stressed by Lee et al.<ref>{{cite journal\n| first1=J. C.\n| last1=Lee\n| first2=R. A.\n| last2=Yetter\n| first3=F. L.\n| last3=Dryer\n| title=Numerical simulation of laser ignition of an isolated carbon particle in quiescent environment\n| journal=Combustion and Flame\n| year=1996\n| volume=105\n| issue=4\n| pages=591–599\n| doi=10.1016/0010-2180(96)00221-0\n}}</ref>\n\n==Applications==\n\n[[File:Particles impacting on a conveyer belt.png|thumb|Deformation of a conveyor belt due to impacting granular material.]]\n\nProblems that involve both a continuous and a discrete phase are important in applications as diverse as pharmaceutical industry e.g.~drug production, agriculture food and processing industry, mining, construction and agricultural machinery, metals manufacturing, energy production and systems biology. Some predominant examples are coffee, corn flakes, nuts, coal, sand, renewable fuels e.g.~biomass for energy production and fertilizer.\n\nInitially, such studies were limited to simple flow configurations as pointed out by Hoomans,<ref>{{cite journal\n| first1=B. P. B.\n| last1=Hoomans\n| first2=J. A. M.\n| last2=Kuipers\n| first3=W. J.\n| last3=Briels\n| first4=W. P. M.\n| last4=Van Swaaij\n| title=Discrete particle simulation of bubble and slug formation in a two-dimensional gas-fluidized bed: A hard-sphere approach\n| journal=Chem. Eng. Sci.\n| year=1996\n| volume=51\n| doi=10.1016/0009-2509(95)00271-5\n| pages=99–118\n| citeseerx=10.1.1.470.6532\n}}</ref> however, Chu and Yu<ref>{{cite journal\n| first1=K. W.\n| last1=Chu\n| first2=A. B.\n| last2=Yu\n| title=Numerical simulation of complex particle-fluid flows\n| journal=Powder Technology\n| year=2008\n| volume=179\n| issue=3\n| pages=104–114\n| doi=10.1016/j.powtec.2007.06.017\n}}</ref> demonstrated that the method could be applied to a complex flow configuration consisting of a fluidized bed, conveyor belt and a cyclone. Similarly, Zhou et al.<ref>{{cite journal\n| first1=H.\n| last1=Zhou\n| first2=G.\n| last2=Mo\n| first3=J.\n| last3=Zhao\n| first4=K.\n| last4=Cen\n| title=DEM-CFD simulation of the particle dispersion in a gas-solid two-phase flow for a fuel-rich/lean burner\n| journal=Fuel\n| year=2011\n| volume=90\n| issue=4\n| pages=1584–1590\n| doi=10.1016/j.fuel.2010.10.017\n}}</ref> applied the CCDM approach to the complex geometry of fuel-rich/lean burner for pulverised coal combustion in a plant and Chu et al.<ref>{{cite journal\n| first1=K. W.\n| last1=Chu\n| first2=B.\n| last2=Wang\n| first3=A. B.\n| last3=Yu\n| first4=A.\n| last4=Vince\n| first5=G. D.\n| last5=Barnett\n| first6=P. J.\n| last6=Barnett\n| title=CFD-DEM study of the effect of particle density distribution on the multiphase flow and performance of dense medium cyclone\n| journal=Minerals Engineering\n| year=2009\n| volume=22\n| issue=11\n| pages=893–909\n| doi=10.1016/j.mineng.2009.04.008\n}}</ref> modelled the complex flow of air, water, coal and magnetite particles of different sizes in a dense medium [[cyclone]] (DMC).\n\nThe CCDM approach has also been applied to fluidised beds as reviewed by Rowe and Nienow<ref>{{cite journal\n| first1=P. N.\n| last1=Rowe\n| first2=A. W.\n| last2=Nienow\n| title=Particle mixing and segregation in gas fluidized beds: A review\n| journal=Powder Technology\n| year=1976\n| volume=15\n| issue=2\n| pages=141–147\n| doi=10.1016/0032-5910(76)80042-3\n}}</ref> and Feng and Yu<ref>{{cite journal\n| first1=Y. Q.\n| last1=Feng\n| first2=A. B.\n| last2=Yu\n| first3=A. B.\n| last3=Yu\n| first4=A.\n| last4=Vince\n| title=Assessment of model formulations in the discrete particle simulation of gas-solid flow\n| journal=Industrial & Engineering Chemistry Research\n| year=2004\n| volume=43\n| issue=26\n| pages=8378–8390\n| doi=10.1021/ie049387v\n}}</ref> and applied by Feng and Yu<ref>{{cite journal\n| first1=Y. Q.\n| last1=Feng\n| first2=A. B.\n| last2=Yu\n| title=An analysis of the chaotic motion of particles of different sizes in a gas fluidized bed\n| journal=Particuology\n| year=2008\n| volume=6\n| issue=6\n| pages=549–556\n| doi=10.1016/j.partic.2008.07.011\n}}</ref> to the chaotic motion of particles of different sizes in a gas fluidized bed. Kafuia et al.<ref>{{cite journal\n| first1=K. D.\n| last1=Kafuia\n| first2=C.\n| last2=Thornton\n| first3=M. J.\n| last3=Adams\n| title=Discrete particle-continuum fluid modelling of gas-solid fluidised beds\n| journal=Chemical Engineering Science\n| year=2002\n| volume=57\n| issue=13\n| pages=2395–2410\n| doi=10.1016/s0009-2509(02)00140-9\n}}</ref> describe discrete particle-continuum fluid modelling of gas-solid fluidised beds. Further applications of XDEM include thermal conversion of biomass on a backward and forward acting grate. Heat transfer in a [[packed bed]] reactor was also investigated for hot air streaming upward through the packed bed to heat the particles, which dependent on position and size experience different heat transfer rates. The [[deformation (engineering)|deformation]] of a conveyor belt due to impacting [[granular material]] that is discharged over a chute represents an application in the field of [[Stress (mechanical)|stress]]/[[Deformation (mechanics)|strain]] analysis.\n\n{|\n| [[File:Temperature distribution on a backward acting grate.png|thumb|Distribution of particles' surface temperature on a backward acting grate.]]\n| [[File:Char distribution on a forward acting grate.png|thumb|Progress of pyrolysis of straw blades on a forward acting grate, on which straw is converted into charred material]]\n| [[File:Particle temperature in a packed bed reactor.png|thumb|Distribution of porosity inside the packed bed and particle temperature]]\n|}\n\n==References==\n{{Reflist|30em}}\n\n{{Numerical PDE}}\n\n[[Category:Numerical differential equations]]\n[[Category:Computational physics]]"
    },
    {
      "title": "Extended finite element method",
      "url": "https://en.wikipedia.org/wiki/Extended_finite_element_method",
      "text": "[[Image:Example of 2D mesh.png|thumb|2D [[Finite element method|FEM]] [[mesh]], the triangles are the elements, the [[vertex (graph theory)|vertices]] are the [[node (graph theory)|node]]s. The [[finite element method]] ([[Finite element method|FEM]]) has been the tool of choice since civil engineer [[Ray W. Clough]] in 1940 derived the stiffness matrix of a 3-node triangular finite element (and coined the name). The precursors of FEM were elements built-up from bars ([[Alexander Hrennikoff|Hrennikoff]], [[John Argyris|Argyris]], Turner) and a conceptual variation approach suggested by R. [[Richard Courant|Courant]]. Today, the [[Finite element method|FEM]] is used to model a much wider range of physical phenomena.]] \n\nThe '''extended finite element method''' ('''XFEM'''), is a numerical technique based on the '''generalized finite element method''' ('''GFEM''') and the '''partition of unity method''' ('''PUM'''). It extends the classical [[finite element method]] (FEM) approach by enriching the solution space for solutions to [[differential equation]]s with discontinuous functions.\n\n== History ==\n\nThe extended finite element method (XFEM) was developed in 1999 by [[Ted Belytschko]] and collaborators,<ref>\n{{cite journal\n | first1= Nicolas\n | last1= Moës\n | first2= John\n | last2= Dolbow\n | first3= Ted\n | last3= Belytschko\n | title= A finite element method for crack growth without remeshing\n | journal= International Journal for Numerical Methods in Engineering\n | year= 1999\n | issue= 1\n | pages= 131–150\n | volume=46\n | doi= 10.1002/(sici)1097-0207(19990910)46:1<131::aid-nme726>3.3.co;2-a\n}}\n</ref>\nto help alleviate shortcomings of the finite element method and has been used to model the propagation of various discontinuities: strong ([[Fracture|cracks]]) and weak (material interfaces). The idea behind XFEM is to retain most advantages of meshfree methods while alleviating their negative sides.\n\n== Rationale ==\n\nThe extended finite element method was developed to ease difficulties in solving problems with localized features that are not efficiently resolved by mesh refinement. One of the initial applications was the modelling of [[fracture]]s in a material. In this original implementation, discontinuous basis functions are added to standard polynomial basis functions for nodes that belonged to elements that are intersected by a crack to provide a basis that included crack opening displacements. A key advantage of XFEM is that in such problems the finite element mesh does not need to be updated to track the crack path. Subsequent research has illustrated the more general use of the method for problems involving [[Mathematical singularity|singularities]], material interfaces, regular meshing of microstructural features such as voids, and other problems where a localized feature can be described by an appropriate set of basis functions.\n\n==Principle==\nEnriched finite element methods extend, or enrich, the\napproximation space so that it is able to naturally reproduce the\nchallenging feature associated with the problem of interest: the\ndiscontinuity, [[Mathematical singularity|singularity]], [[boundary layer]], etc. It was shown that\nfor some problems, such an embedding of the problem's feature into the approximation\nspace can significantly improve convergence rates and accuracy.\nMoreover, treating problems with discontinuities with eXtended\nFinite Element Methods suppresses the need to mesh and remesh the\ndiscontinuity surfaces, thus alleviating the computational costs and projection errors\nassociated with conventional finite element methods, at the cost of restricting the discontinuities to mesh edges. \n\n<!--\n\n== Enrichment ==\n\nto be written \n\n== Application to fracture mechanics ==\n\n[[Image:Classical enriched nodes1.pdf]]\n\n-->\n== Existing XFEM codes ==\n\nThere exists several research codes implementing this technique to various degrees.\n\n* [[GetFEM++]] \n* xfem++ \n* openxfem++\n* [https://blogs.princeton.edu/prevost/dynaflow/dynaflow-description/ Dynaflow]\n\nXFEM has also been implemented in code like '''Altair [[Radioss]]''', ASTER, Morfeo, and [[Abaqus]]. It is increasingly being adopted by other commercial finite element software, with a few plugins and actual core implementations available ([[ANSYS]], [[SAMCEF]], [[OOFELIE]], etc.).\n\n==References==\n{{Reflist}}\n\n{{Numerical PDE}}\n\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n[[Category:Continuum mechanics]]\n[[Category:Finite element method]]\n[[Category:Mechanics]]"
    },
    {
      "title": "False diffusion",
      "url": "https://en.wikipedia.org/wiki/False_diffusion",
      "text": "'''False diffusion''' is a type of error observed when the  [[upwind scheme]] is used to approximate the [[convection]] term in [[convection–diffusion equation]]s. The more accurate [[Finite difference#central difference|central difference scheme]] can be used for the [[convection]] term, but  for grids with cell [[Peclet number]] more than 2, the central difference scheme is unstable and the simpler upwind scheme is often used. The resulting error from the upwind differencing scheme has a diffusion-like appearance in two- or three-dimensional co-ordinate systems and is referred as \"false diffusion\". False-diffusion errors in numerical solutions of convection-diffusion problems, in two- and three-dimensions, arise from the numerical approximations of the convection term in the conservation equations. Over the past 20 years many [[numerical analysis|numerical]] techniques have been developed to solve convection-diffusion equations and none are problem-free, but false diffusion is one of the most serious problems and a major topic of controversy and confusion among [[numerical analysis|numerical analysts]].\n\n==Definition==\nFalse diffusion is defined as an error having a diffusion-like appearance, obtained when the ''upwind scheme'' is used in multidimensional cases to solve for the distribution of transported properties flowing non-orthogonally to one or more of the system's major axes. The error is absent when the flow is orthogonal or parallel to each major axis.\n\n==Example==\n[[File:Upwind differencing scheme.jpg|thumb|Fig 1:Flow domain illustrating false diffusion]]\nIn figure 1, ''u''&nbsp;=&nbsp;2 and ''v''&nbsp;=&nbsp;2&nbsp;m/s everywhere so the [[velocity field]] is uniform and [[parallel (geometry)|parallel]] to the [[diagonal]] (XX). The boundary conditions for  [[temperature]] on north and west wall is 100 ̊C and for east and south wall is 0 ̊C. This region is meshed into 10×10 equal grids. Take two cases, (i) with [[diffusion coefficient]] ≠ 0 and, case (ii) with diffusion coefficient = 0.\n\n===Case (i)===\n[[File:Convection.jpg|thumb|Fig 2: West face is at 100°C while south wall is at 0°C. Heat is diffused across the diagonal XX]]\nIn this case, heat from west and south wall is carried by [[convection]] flow towards north and east wall. Heat is also diffused across the diagonal XX from upper to lower triangle. Figure 2 shows the approximate temperature distribution.\n\n===Case (ii)===\nIn this case heat from west and south wall is convected by flow towards north and east. There will be no diffusion across the diagonal XX but, when the ''upwind scheme'' is applied the results are similar to case (i) where actual diffusion is occurring. This error is known as false diffusion.\n\n==Background==\nIn early approaches, [[derivative]]s in the ''[[differential form]]'' of the governing ''[[transport equation]]'' were replaced by finite difference approximations, usually central differencing approximations with second order accuracy. However, for large Peclet numbers (generally >&nbsp;2) this approximation gave inaccurate results. It was recognized independently by several investigators [1,2]<ref>{{cite journal |author= R. Courant,E.Isaacson and M.Rees|title= On the solution of non-linear hyperbolic differential equations by finite difference, Comm. Pure Appl. Math. 5(1952) 243–255}}</ref><ref>{{cite journal |author= K.E.Torrance,  |title= Comparison of finite difference computations of natural convection J.Res N.B.S 72B(1968)281–301.}}</ref> that the less expensive but only first order accurate ''upwind scheme'' can be employed but that this scheme produces results with false diffusion for  multidimensional cases. Many new schemes have been developed to counter false diffusion but a reliable, accurate and economical discretisation scheme is still unavailable.\n\n== Reducing errors ==\n[[File:Mesh size 8X8.jpg|thumb|Fig 3(a): Mesh size of 8×8]]\n[[File:Result with grid size 8X8.jpg|thumb|Fig 3(b): Result of upwind scheme with mesh size 8X8]]\n[[File:Mesh size 64X64.jpg|thumb|Fig 4(a): Mesh size of 64×64]]\n[[File:Result with grid size 64X64.jpg|thumb|Fig 4(b): Result of upwind scheme with mesh size 64×64]]\n\n=== Finer mesh===\nFalse diffusion with the ''upwind scheme'' is reduced by increasing the mesh density. In the results of figure 3 and 4 the false diffusion error is lowest in figure 4(b) with finer mesh size.\n\n=== Other schemes ===\nFalse diffusion error also can be reduced by using schemes such as the ''[[power law scheme]]'', ''[[QUICK scheme]]'', ''exponential scheme'', and ''SUCCA'', and others.<ref>{{cite book|last=Versteeg|first=H.K.|title=An introduction to computational fluid dynamics : the finite volume method|year=2007|publisher=Prentice Hall|location=Harlow|isbn=9780131274983|edition=2nd |author2=Malalasekera, W.}}</ref><ref>{{cite book|last=Patankar|first=Suhas V.|title=Numerical heat transfer and fluid flow|year=1980|publisher=Taylor & Francis|location=Bristol, PA|isbn=9780891165224|edition=14. printing.}}</ref>\n\n===Improving the upwind scheme===\nFalse diffusion with the simple ''upwind scheme'' occurs because the scheme does not take into account grid/flow direction inclination. An approximate expression for the false-diffusion term in two dimensions has been given by de Vahl Davis and Mallinson(1972)<ref>{{cite book|last=Patankar|first=Suhas V.|title=Numerical heat transfer and fluid flow page no:108|year=1980|publisher=Taylor & Francis|location=Bristol, PA|isbn=9780891165224|edition=14. printing.}}</ref>\n\n{{NumBlk|:|<math>{\\tau _{fc}^\\star= \\frac {\\rho\\ U \\,\\Delta x \\,\\Delta y \\sin 2\\theta}{4(\\Delta y \\sin ^3 \\theta+\\Delta x \\cos ^3 \\theta)}}</math>|{{EquationRef|1}}}} \n\nwhere ''U'' is the resultant velocity and ''θ'' is the angle made by the velocity vector with the ''x'' direction. False diffusion is absent when the resultant flow is aligned with either of the sets of grid lines and is greatest when the flow direction is 45˚ to the grid lines.\n\n===Determining the accuracy of approximation for the convection term===\nUsing ''[[Taylor series]]'' for <math> \\phi_{W} </math> and <math> \\phi_P </math> at the time ''t''&nbsp;+&nbsp;''kt'' are\n\n{{NumBlk|:|<math> \\phi_{Wk} = \\phi_{wk} - \\left(\\frac{\\delta x_i}{2}\\right)\\left(\\frac{\\partial \\phi}{\\partial x}\\right)_{wk}+\\frac{1}{2!}\\left(\\frac{\\delta x_i}{2} \\right)^2 \\left(\\frac{\\partial^2\\phi}{\\partial x^2}\\right)_{wk} + \\cdots. </math>|{{EquationRef|2a}}}}\n\n{{NumBlk|:|<math>\\phi_{Pk}=\\phi_{wk} - \\left(\\frac{\\delta x_i}{2}\\right) \\left(\\frac{\\partial \\phi}{\\partial x}\\right)_{wk} + \\frac{1}{2!}\\left(\\frac{\\delta x_i}{2} \\right)^2 \\left(\\frac{\\partial^2\\phi}{\\partial x^2}\\right)_{wk}+\\cdots.</math>|{{EquationRef|2b}}}}\n\naccording to the upwind approximation for convection (UAC),<math>{\\phi_{wk} = \\phi_{Wk}}</math>. Neglecting the higher order in equation (2a), the error of convected flux due to this approximation is <math>{-\\rho_w u_w \\delta y_i\\left(\\frac{\\delta x_i}{2} \\right) \\left( \\frac{\\partial \\phi}{\\partial x}\\right)_{wk}}</math>. It has the form of  flux of <math>{\\phi}</math> by false diffusion with a diffusion co-efficient<ref>{{cite journal |author=G.D Raithby |title= A critical evaluations of upstream differencing applied to problems involving fluid flow , COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING , 9(1976) 75–103}}</ref>\n{{NumBlk|:|<math>\\tau_{fc,UAC}^\\star ={\\rho_w u_w \\left(\\frac{\\Delta x_i}{2}\\right)}</math>|{{EquationRef|3}}}}\nThe subscript ''fc'' is a reminder that this is a false diffusion arising from the estimate of the convected flux at the instant <math>t+k\\,\\Delta t</math> using UAC.\n\n===''Skew upwind corner convection algorithm'' (''SUCCA'')===\n[[File:SUCCA scheme.jpg|thumb|Fig 5:''SUCCA'' grid cell cluster]]\n''SUCCA'' takes the local flow direction into account by introducing the influence of upwind corner cells into the discretized conservation equation in the general governing transport equation. In Fig 5, ''SUCCA'' is applied within nine cell grid cluster. Considering the SW corner inflow for cell P, the ''SUCCA'' equations for the convective transport of the conserved species <math>{\\phi}</math> are\n\n{{NumBlk|:|<math>C_P \\phi _P= \\left(\\dot m_w - \\frac {(\\dot m_s)^2} {\\dot m_w} \\right) \\phi_W + \\left(\\dot m_s + \\frac {(\\dot m_s) ^2} {\\dot m_w} \\right)\\phi_{SW} + 0.\\phi_S\\text{ for } 0<\\theta\\le 45</math>|{{EquationRef|4}}}}\n\ni.e.,\n\n{{NumBlk|:|<math>C_P \\phi_P = C_w \\phi_W + C_sw \\phi_{SW}</math>|{{EquationRef|5}}}}\n\n{{NumBlk|:|<math>C_P \\phi _P= \\left(\\dot m_s - \\frac {(\\dot m_w)^2} {\\dot m_s} \\right)\\phi_W +{\\left(\\dot m_w+  \\frac {(\\dot m_w) ^2} {\\dot m_s} \\right) \\phi _{SW}} + 0.\\phi_W \\text{ for }45<\\theta< 90 </math>|{{EquationRef|6}}}}\n\ni.e.,\n\n{{NumBlk|:|<math>C_P \\phi_P = C_s \\phi_S + C_sw \\phi_{SW}</math>|{{EquationRef|7}}}}\n\nThis formulation satisfies all the criteria of [[Convergence (mathematics)|convergence]] and stability.<ref>{{cite journal |author=C.Carey, T.J.Scanlon and S.M.Fraser |title= SUCCA- An alternative scheme to reduce the effects of multidimensional false diffusion, Appl. Math Modelling,1993 ,Vol.17, May 263–270}}</ref>\n\n[[File:Comparison of different schemes.jpg|thumb|Fig 6: Comparison of different schemes]]\nIn Fig. 6, as mesh is refined, the ''upwind scheme'' gives more accurate results but ''SUCCA'' offers a nearly exact solution and is more useful in avoiding multidimensional false diffusion errors.\n\n== See also ==\n\n*[[Computational fluid dynamics]]\n*[[Navier–Stokes equations]]\n*[[Finite volume method]]\n*[[Taylor series]]\n\n==References==\n{{reflist}}\n\n==Further reading==\n*{{Citation\n| publisher = Taylor & Francis Group\n| isbn = 9780891165224\n| last = Patankar\n| first = Suhas V.\n| title = Numerical Heat Transfer and Fluid Flow\n| year = 1980\n}}\n*{{Citation\n| publisher = Springer\n| isbn = 978-3-540-67853-3\n| last = Wesseling\n| first = Pieter\n| title = Principles of Computational Fluid Dynamics\n| year = 2001\n}}\n*{{Citation\n| publisher = Cambridge University Press\n| isbn = 9780521853262\n| last = Date\n| first = Anil W.\n| title = Introduction to Computational Fluid Dynamics\n| year = 2005\n}}\n\n[[Category:Computational fluid dynamics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Fast marching method",
      "url": "https://en.wikipedia.org/wiki/Fast_marching_method",
      "text": "The '''fast marching method'''<ref name=\"sethian_fmm\">J.A. Sethian. A Fast Marching Level Set Method for Monotonically Advancing Fronts, Proc. Natl. Acad. Sci., 93, 4, pp.1591--1595, 1996. [https://math.berkeley.edu/~sethian/2006/Papers/sethian.fastmarching.pdf]</ref> is a numerical method created by [[James Sethian]] for solving [[boundary value problem]]s of the [[Eikonal equation]]:\n\n: <math>|\\nabla u(x)|=1/f(x) \\text{ for } x \\in \\Omega</math>\n: <math>u(x) = 0 \\text{ for } x \\in \\partial\\Omega</math>\n\nTypically, such a problem describes the evolution of a closed surface as a function of time <math>u</math> with speed <math>f</math> in the normal direction at a point <math>x</math> on the propagating surface. The speed function is specified, and the time at which the contour crosses a point <math>x</math> is obtained by solving the equation. Alternatively, <math>u(x)</math> can be thought of as the minimum amount of time it would take to reach <math>\\partial\\Omega</math> starting from the point <math>x</math>. The fast marching method takes advantage of this [[optimal control]] interpretation of the problem in order to build a solution outwards starting from the \"known information\", i.e. the boundary values.\n\nThe algorithm is similar to [[Dijkstra's algorithm]] and uses the fact that information only flows outward from the seeding area. This problem is a special case of [[level-set method]]s. [[Eikonal equation#Computational algorithms|More general algorithms exist]] but are normally slower.\n\nExtensions to non-flat (triangulated) domains solving\n\n::<math>|\\nabla_S u(x)|=1 / f(x),\n</math>\n \nfor the surface <math>S</math> and <math>x\\in S</math>, were introduced by [[Ron Kimmel]] and [[James Sethian]].\n\n<gallery>\nImage:Fast_marching_maze.png| Maze as speed function shortest path\nImage:Fast_marching_multi_stencil_2nd_order.png|Distance map multi-stencils with random source points\n</gallery>\n\n==Algorithm==\n\nFirst, assume that the domain has been discretized into a mesh. We will refer to meshpoints as nodes. Each node <math>x_i</math> has a corresponding value <math>U_i = U(x_i) \\approx u(x_i)</math>.\n\nThe algorithm works just like Dijkstra's algorithm but differs in how the nodes' values are calculated. In Dijkstra's algorithm, a node's value is calculated using a single one of the neighboring nodes. However, in solving the PDE in <math>\\mathbb{R}^n</math>, between <math>1</math> and <math>n</math> of the neighboring nodes [[Eikonal equation#Numerical Approximation|are used]].\n\nNodes are labeled as ''far'' (not yet visited), ''considered'' (visited and value tentatively assigned), and ''accepted'' (visited and value permanently assigned).\n\n# Assign every node <math>x_i</math> the value of <math>U_i=+\\infty</math> and label them as ''far''; for all nodes <math>x_i \\in \\partial\\Omega</math> set <math>U_i = 0</math> and label <math>x_i</math> as ''accepted''.\n# For every far node <math>x_i</math>, use the [[Eikonal equation#Numerical approximation|Eikonal update formula]] to calculate a new value for <math>\\tilde{U}</math>. If <math>\\tilde{U} < U_i</math> then set <math>U_i = \\tilde{U}</math> and label <math>x_i</math> as ''considered''.\n# Let <math>\\tilde{x}</math> be the considered node with the smallest value <math>U</math>. Label <math>\\tilde{x}</math> as ''accepted''.\n# For every neighbor <math>x_i</math> of <math>\\tilde{x}</math> that is not-accepted, calculate a tentative value <math>\\tilde{U}</math>.\n# If <math>\\tilde{U} < U_i </math> then set <math>U_i = \\tilde{U}</math>. If <math>x_i</math> was labeled as ''far'', update the label to ''considered''.\n# If there exists a ''considered'' node, return to step 3. Otherwise, terminate.\n\n==See also==\n* [[Level-set method]]\n* [[Fast sweeping method]]\n* [[Bellman–Ford algorithm]]\n\n==External links==\n* [http://www.mit.edu/~jnt/dijkstra.html Dijkstra-like Methods for the Eikonal Equation J.N. Tsitsiklis, 1995]\n* [http://math.berkeley.edu/~sethian/ The Fast Marching Method and its Applications by James A. Sethian]\n* [https://web.archive.org/web/20110719232108/http://mecca.louisville.edu/~msabry/projects/msfm.htm Multi-Stencils Fast Marching Methods] \n* [http://www.mathworks.com/matlabcentral/fileexchange/24531 Multi-Stencils Fast Marching Matlab Implementation]\n* [http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/841/pdf/imm841.pdf Implementation Details of the Fast Marching Methods]\n* [https://rd.springer.com/article/10.1007/s11075-008-9183-x Generalized Fast Marching method] by Forcadel et al. [2008] for applications in image segmentation.\n* [https://github.com/scikit-fmm/scikit-fmm Python Implementation of the Fast Marching Method]\n*See Chapter 8 in [http://etd.fcla.edu/CF/CFE0001159/Rumpf_Raymond_C_200608_PhD.pdf Design and Optimization of Nano-Optical Elements by Coupling Fabrication to Optical Behavior]\n\n==Notes==\n{{Reflist}}\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Fast sweeping method",
      "url": "https://en.wikipedia.org/wiki/Fast_sweeping_method",
      "text": "In applied mathematics, the '''fast sweeping method''' is a [[numerical method]] for solving [[boundary value problem]]s of the [[Eikonal equation]].\n\n: <math>|\\nabla u(\\mathbf{x})| = \\frac 1 {f(\\mathbf{x})} \\text{ for } \\mathbf{x} \\in \\Omega \n</math>\n\n: <math>u(\\mathbf{x}) = 0 \\text{ for } \\mathbf{x} \\in \\partial \\Omega  \n</math>\n\nwhere <math>\\Omega </math> is an open set in <math>\\mathbb{R}^n</math>, <math>f(\\mathbf{x})</math> is a function with positive values, <math>\\partial \\Omega </math> is a well-behaved boundary of the open set and <math>|\\cdot|</math> is the <math>L^2</math> norm.\n\nThe fast sweeping method is an iterative method which uses upwind difference for discretization and uses [[Gauss–Seidel method|Gauss–Seidel iterations]] with alternating sweeping ordering to solve the discretized Eikonal equation on a rectangular grid. The origins of this approach lie in [[control theory]].  Although fast sweeping methods have existed in control theory, it was first proposed for Eikonal equations<ref>{{Cite journal|last=Zhao|first=Hongkai|date=2005-01-01|title=A fast sweeping method for Eikonal equations|journal=Mathematics of Computation|volume=74|issue=250|pages=603–627|doi=10.1090/S0025-5718-04-01678-3|issn=0025-5718}}</ref> by [[Hongkai Zhao]], an applied mathematician at the [[University of California, Irvine]].\n\nSweeping algorithms are highly efficient for solving Eikonal equations when the corresponding [[Method of characteristics|characteristic curves]] do not change direction very often.<ref name=\"chacon_twoscale\">A. Chacon and A. Vladimirsky. Fast two-scale methods for Eikonal equations. SIAM J. on Scientific Computing 34/2: A547-A578, 2012. [https://arxiv.org/abs/1110.6220]</ref> \n\n== References ==\n<references />\n\n== See also ==\n* [[Fast marching method]]\n\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n[[Category:Hyperbolic partial differential equations]]\n\n{{applied-math-stub}}"
    },
    {
      "title": "Finite difference methods for option pricing",
      "url": "https://en.wikipedia.org/wiki/Finite_difference_methods_for_option_pricing",
      "text": "'''Finite difference methods for option pricing''' are [[Numerical analysis|numerical methods]] used in [[mathematical finance]] for the valuation of [[Option (finance)|options]].<ref name=\"JHull\">{{cite book | last = Hull | first = John C. | edition = 5th | title = Options, Futures and Other Derivatives | year = 2002 | publisher = [[Prentice Hall]] | isbn = 978-0-13-009056-0 }}</ref>  [[Finite difference method]]s were first applied to [[Valuation of options|option pricing]] by [[Eduardo Schwartz]] in 1977.<ref name=\"Schwartz\">{{cite journal |last=Schwartz  |first= E.|authorlink= |date=January 1977|title= The Valuation of Warrants: Implementing a New Approach|journal= [[Journal of Financial Economics]]|volume= 4|issue= |pages= 79–94 |url= http://ideas.repec.org/a/eee/jfinec/v4y1977i1p79-93.html|accessdate= |doi=10.1016/0304-405X(77)90037-X }}</ref><ref name=\"Boyle\"> {{cite book | last = Boyle | first = Phelim |authorlink = Phelim Boyle|author2=Feidhlim Boyle | edition = | title =  Derivatives: The Tools That Changed Finance | year = 2001| publisher = Risk Publications | isbn = 978-1899332885}}</ref>{{rp|180}} \n\nIn general, finite difference methods are used to price options by approximating the (continuous-time) [[differential equation]] that describes how an option price evolves over time by a set of (discrete-time) [[difference equations]]. The discrete difference equations may then be solved iteratively to calculate a price for the option.<ref name=\"Goddard\"> Phil Goddard (N.D.).  [http://www.goddardconsulting.ca/option-pricing-finite-diff-index.html ''Option Pricing – Finite Difference Methods'']</ref>  The approach arises since the evolution of the option value can be modelled via a [[partial differential equation]] (PDE), as a [[function (mathematics)|function]] of (at least) time and price of underlying; see for example [[Black–Scholes#The Black–Scholes equation|Black–Scholes PDE]]. Once in this form, a finite difference model can be derived, and the valuation obtained.<ref name=\"Schwartz\"/> \n\nThe approach can be used to solve derivative pricing problems that have, in general, the same level of complexity as those problems solved by [[Lattice model (finance)|tree approaches]].<ref name=\"JHull\"/> \n\n==Method==\nAs above, the PDE is expressed in a discretized form, using [[finite difference]]s, and the evolution in the option price is then modelled using a lattice with corresponding [[dimension]]s: time runs from 0 to maturity; and price runs from 0 to a \"high\" value, such that the option is deeply [[moneyness|in or out of the money]]. The option is then valued as follows:<ref>{{cite book | title = The Mathematics of Financial Derivatives: A Student Introduction | author1 = Wilmott, P. | author2 = Howison, S. | author3 = Dewynne, J. | publisher = [[Cambridge University Press]] | year = 1995 | isbn = 978-0-521-49789-3}}</ref>\n# [[Option time value#Intrinsic value|Maturity values]] are simply the difference between the exercise price of the option and the value of the underlying at each point.\n# Values at the boundary prices are set based on [[moneyness]] or [[Put call parity#External links|arbitrage bounds on option prices]].\n# Values at other lattice points are calculated [[recursion|recursively]] (iteratively), starting at the time step preceding maturity and ending at time = 0. Here, using a technique such as [[Crank–Nicolson method#Application in financial mathematics|Crank–Nicolson]] or the [[Finite difference method#Explicit method|explicit method]]:\n::* the PDE is discretized per the technique chosen, such that the value at each lattice point is specified as a function of the value at later and adjacent points; see [[Stencil (numerical analysis)]];\n::* the value at each point is then found using the technique in question.\n:4. The value of the option today, where the [[underlying]] is at its [[spot price]], (or at any time/price combination,) is then found by [[interpolation]].\n\n==Application==\nAs above, these methods can solve derivative pricing problems that have, in general, the same level of complexity as those problems solved by [[Lattice model (finance)|tree approaches]],<ref name=\"JHull\"/> but, given their relative complexity, are usually employed only when other approaches are inappropriate;  an example here, being changing interest rates and / or  time linked [[dividend policy]].  At the same time, like tree-based methods, this approach is limited in terms of the number of underlying variables, and for problems with [[High-dimensional space|multiple dimensions]], [[Monte Carlo methods for option pricing]] are usually preferred. <ref name=\"Boyle\"/>{{rp|182}} Note that, when standard assumptions are applied, the explicit technique encompasses the [[Binomial options pricing model|binomial-]] and [[trinomial tree]] methods.<ref>{{cite journal |last=Brennan|first= M.|authorlink= |author2=Schwartz, E.|date=September 1978 |title= Finite Difference Methods and Jump Processes Arising in the Pricing of Contingent Claims: A Synthesis|journal= [[Journal of Financial and Quantitative Analysis]]|volume= 13|issue= 3|pages= 461–474 |jstor= 2330152|doi=10.2307/2330152 }}</ref> Tree based methods, then, suitably parameterized, are a [[special case]] of the explicit finite difference method.<ref>{{cite journal|last=Rubinstein |first=M. |authorlink= |year=2000 |title=On the Relation Between Binomial and Trinomial Option Pricing Models |journal=[[Journal of Derivatives]] |volume=8 |issue=2 |pages=47–50 |url=//www.in-the-money.com/pages/author.htm |accessdate= |doi=10.3905/jod.2000.319149 |deadurl=yes |archiveurl=https://web.archive.org/web/20070622150346/http://www.in-the-money.com/pages/author.htm |archivedate=June 22, 2007 |citeseerx=10.1.1.43.5394 }}</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n<!-- alphabetical by author -->\n* [http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN97-02.pdf Option Pricing Using Finite Difference Methods], Prof. Don M. Chance, [[Louisiana State University]]\n* [http://www.cs.cornell.edu/Info/Courses/Spring-98/CS522/content/lab4.pdf Finite Difference Approach to Option Pricing] (includes [[Matlab]] Code);  [http://www.cs.cornell.edu/Info/Courses/Spring-98/CS522/content/lecture2.math.pdf Numerical Solution of Black–Scholes Equation], Tom Coleman, [[Cornell University]]\n* [http://www.goddardconsulting.ca/option-pricing-finite-diff-index.html Option Pricing – Finite Difference Methods], Dr. Phil Goddard\n* [https://www.sfu.ca/~rjones/bus864/notes/notes2.pdf Numerically Solving PDE’s: Crank-Nicolson Algorithm], Prof. R. Jones, [[Simon Fraser University]]\n* [http://www.math.ust.hk/~maykwok/courses/ma571/06_07/Kwok_Chap_6.pdf Numerical Schemes for Pricing Options], Prof. Yue Kuen Kwok, [[Hong Kong University of Science and Technology]]\n* [https://web.archive.org/web/20110719120702/http://mit.econ.au.dk/vip_htm/cmunk/noter/PDENOTE.pdf Introduction to the Numerical Solution of Partial Differential Equations in Finance], Claus Munk, [[University of Aarhus]]\n* [http://users.aims.ac.za/~bundi/Thesis.pdf Numerical Methods for the Valuation of Financial Derivatives], D.B. Ntwiga, [[University of the Western Cape]]\n* [https://web.archive.org/web/20060821114429/http://www.puc-rio.br/marco.ind/katia-num.html#finite-differences The Finite Difference Method], Katia Rocha, [[Instituto de Pesquisa Econômica Aplicada]]\n* [http://janroman.dhis.org/doc/lnotes/AFI/Finite%20Difference%20and%20MC.pdf Analytical Finance: Finite difference methods], Jan Röman, [[Mälardalen University]]\n\n{{Derivatives market}}\n\n\n[[Category:Mathematical finance]]\n[[Category:Options (finance)]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Finite element method",
      "url": "https://en.wikipedia.org/wiki/Finite_element_method",
      "text": "{{short description|Numerical method for solving physical or engineering problems}}\n{{Redirect|Finite element|the elements of a [[poset]]|compact element}}\n{{Differential equations}}\n\nThe '''finite element method''' ('''FEM'''), is a [[numerical analysis|numerical method]] for solving problems of engineering and [[mathematical physics]]. Typical problem areas of interest include [[structural analysis]], [[heat transfer]], [[fluid flow]], mass transport, and [[electromagnetic potential]]. The [[Closed-form_expression| analytical solution]] of these problems generally require the solution to [[boundary value problem]]s for [[partial differential equations]]. The finite element method formulation of the problem results in a system of [[algebraic equation]]s. The method approximates the unknown function over the domain.<ref name=\"\">{{cite book\n  | title = A first course in the finite element method\n  | author = Daryl L. Logan\n  | publisher = Cengage Learning\n  | year = 2011\n  | isbn = 978-0495668251\n}}</ref> To solve the problem, it subdivides a large system into smaller, simpler parts that are called finite elements. The simple equations that model these finite elements are then assembled into a larger system of equations that models the entire problem. FEM then uses [[variational methods]] from the [[calculus of variations]] to approximate a solution by minimizing an associated error function.\n\nStudying or [[Analysis|analyzing]] a phenomenon with FEM is often referred to as '''finite element analysis''' ('''FEA''').\n\n==Basic concepts==\n\nThe subdivision of a whole domain into simpler parts has several advantages:<ref>{{cite book | first1=J. N. | last1= Reddy | title= An Introduction to the Finite Element Method | edition=Third | publisher=McGraw-Hill | year=2006 | isbn=9780071267618}}</ref>\n*Accurate representation of complex geometry\n*Inclusion of dissimilar material properties\n*Easy representation of the total solution\n*Capture of local effects.\n\nA typical work out of the method involves (1) dividing the domain of the problem into a collection of subdomains, with each subdomain represented by a set of element equations to the original problem, followed by (2) systematically recombining all sets of element equations into a global system of equations for the final calculation. The global system of equations has known solution techniques, and can be calculated from the [[initial value]]s of the original problem to obtain a numerical answer.\n\nIn the first step above, the element equations are simple equations that locally approximate the original complex equations to be studied, where the original equations are often  [[partial differential equation]]s (PDE). To explain the approximation in this process, FEM is commonly introduced as a special case of [[Galerkin method]]. The process, in mathematical language, is to construct an integral of the [[inner product]] of the residual and the [[weight function]]s and set the integral to zero. In simple terms, it is a procedure that minimizes the error of approximation by fitting trial functions into the PDE. The residual is the error caused by the trial functions, and the weight functions are [[polynomial]] approximation functions that project the residual. The process eliminates all the spatial derivatives from the PDE, thus approximating the PDE locally with\n*a set of [[algebraic equations]] for [[steady state]] problems,\n*a set of [[ordinary differential equation]]s for [[transient state|transient]] problems.\n\nThese equation sets are the element equations.  They are [[linear]] if the underlying PDE is linear, and vice versa. Algebraic equation sets that arise in the steady state problems are solved using [[numerical linear algebra]] methods, while ordinary differential equation sets that arise in the transient problems are solved by numerical integration using standard techniques such as [[Euler's method]] or the [[Runge-Kutta]] method.\n\nIn step (2) above, a global system of equations is generated from the element equations through a transformation of coordinates from the subdomains' local nodes to the domain's global nodes. This spatial transformation includes appropriate [[Transformation matrix|orientation adjustment]]s as applied in relation to the reference [[coordinate system]]. The process is often carried out by FEM software using [[coordinates|coordinate]] data generated from the subdomains.\n\nFEM is best understood from its practical application, known as '''finite element analysis (FEA)'''. FEA as applied in [[engineering]] is a computational tool for performing [[engineering analysis]]. It includes the use of [[mesh generation]] techniques for dividing a [[complex system|complex problem]] into small elements, as well as the use of [[software]] program coded with FEM algorithm. In applying FEA, the complex problem is usually a physical system with the underlying [[physics]] such as the [[Euler-Bernoulli beam equation]], the [[heat equation]], or the [[Navier-Stokes equations]] expressed in either PDE or [[integral equation]]s, while the divided small elements of the complex problem represent different areas in the physical system.\n\nFEA is a good choice for analyzing problems over complicated domains (like cars and oil pipelines), when the domain changes (as during a solid state reaction with a moving boundary), when the desired precision varies over the entire domain, or when the solution lacks smoothness. FEA simulations provide a valuable resource as they remove multiple instances of creation and testing of hard prototypes for various high fidelity situations.<ref>{{Cite web|url=http://www.manortool.com/finite-element-analysis.html|title=Finite Elements Analysis (FEA)|last=|first=|date=|website=www.manortool.com|language=EN|archive-url=|archive-date=|dead-url=|access-date=2017-07-28}}</ref> For instance, in a frontal crash simulation it is possible to increase prediction accuracy in \"important\" areas like the front of the car and reduce it in its rear (thus reducing cost of the simulation). Another example would be in [[numerical weather prediction]], where it is more important to have accurate predictions over developing highly nonlinear phenomena (such as [[tropical cyclone]]s in the atmosphere, or [[Eddy (fluid dynamics)|eddies]] in the ocean) rather than relatively calm areas.\n\n{{multiple image\n| align = left\n| image1 = Example of 2D mesh.png\n| width1 = 300\n| alt1 = Example of 2D mesh\n| caption1 = FEM [[Polygon mesh|mesh]] created by an analyst prior to finding a solution to a [[Magnetism|magnetic]] problem using FEM software. Colours indicate that the analyst has set material properties for each zone, in this case a [[Electrical conductor|conducting]] wire coil in orange; a [[Ferromagnetism|ferromagnetic]] component (perhaps [[iron]]) in light blue; and air in grey. Although the geometry may seem simple, it would be very challenging to calculate the magnetic field for this setup without FEM software, using [[Closed-form expression|equations alone]].\n| image2 = FEM_example_of_2D_solution.png\n| width2 = 300\n| alt2 = FEM_example_of_2D_solution\n| caption2 = FEM solution to the problem at left, involving a [[Cylinder (geometry)|cylindrically]] shaped [[Magnetic shielding|magnetic shield]]. The [[Ferromagnetism|ferromagnetic]] cylindrical part is shielding the area inside the cylinder by diverting the magnetic field [[Electromagnet|created]] by the coil (rectangular area on the right). The color represents the [[Norm (mathematics)|amplitude]] of the [[Magnetic field#Definitions, units, and measurement|magnetic flux density]], as indicated by the scale in the inset legend, red being high amplitude. The area inside the cylinder is low amplitude (dark blue, with widely spaced lines of magnetic flux), which suggests that the shield is performing as it was designed to.\n| footer = \n}}\n{{clear}}\n\n==History==\nWhile it is difficult to quote a date of the invention of the finite element method, the method originated from the need to solve complex [[Elasticity (physics)|elasticity]] and [[structural analysis]] problems in [[civil engineering|civil]] and [[aeronautical engineering]]. Its development can be traced back to the work by [[Alexander Hrennikoff|A. Hrennikoff]]<ref>{{Cite journal |last=Hrennikoff |first=Alexander |title=Solution of problems of elasticity by the framework method |journal=Journal of Applied Mechanics |volume=8.4 |pages=169–175 |year=1941 |doi= }}</ref> and [[Richard Courant|R. Courant]]<ref>{{Cite journal |last=Courant |first=R. |title=Variational methods for the solution of problems of equilibrium and vibrations |journal=Bulletin of the American Mathematical Society |volume=49 |pages=1–23 |year=1943 |doi= 10.1090/s0002-9904-1943-07818-4}}</ref> in the early 1940s. Another pioneer was [[Ioannis Argyris]]. In the USSR, the introduction of the practical application of the method is usually connected with name of [[Leonard Oganesyan]].<ref>{{cite web|url=http://emi.nw.ru/INDEX.html?0/resume/oganesan.htm|title=СПб ЭМИ РАН|author=|date=|website=emi.nw.ru|accessdate=17 March 2018}}</ref> In China, in the later 1950s and early 1960s, based on the computations of dam constructions, [[Feng Kang|K. Feng]] proposed a systematic numerical method for solving [[partial differential equation]]s.  The method was called the finite difference method based on variation principle, which was another independent invention of the finite element method. Although the approaches used by these pioneers are different, they share one essential characteristic: [[Polygon mesh|mesh]] [[discretization]] of a continuous domain into a set of discrete sub-domains, usually called elements.\n\nHrennikoff's work discretizes the domain by using a [[Lattice (group)|lattice]] analogy, while Courant's approach divides the domain into finite triangular subregions to solve [[second order equation|second order]] [[elliptic equation|elliptic]] partial differential equations (PDEs) that arise from the problem of [[torsion (mechanics)|torsion]] of a [[cylinder (geometry)|cylinder]]. Courant's contribution was evolutionary, drawing on a large body of earlier results for PDEs developed by [[John William Strutt, 3rd Baron Rayleigh|Rayleigh]], [[Walther Ritz|Ritz]], and [[Boris Galerkin|Galerkin]].\n\nThe finite element method obtained its real impetus in the 1960s and 1970s by the developments of [[John Argyris|J. H. Argyris]] with co-workers at the [[University of Stuttgart]], [[Ray W. Clough|R. W. Clough]] with co-workers at [[University of California, Berkeley|UC Berkeley]], [[Olgierd Zienkiewicz|O. C. Zienkiewicz]] with co-workers [[Ernest Hinton]], [[Bruce Irons (engineer)|Bruce Irons]]<ref>{{Cite journal |last1=Hinton |first1=Ernest |last2=Irons |first2=Bruce |author-link= |title=Least squares smoothing of experimental data using finite elements |journal=Strain |volume=4 |issue=3 |pages=24–27 |date=July 1968 |doi= 10.1111/j.1475-1305.1968.tb01368.x}}</ref> and others at the [[Swansea University|University of Swansea]], [[Philippe G. Ciarlet]] at the University of [[Pierre-and-Marie-Curie University|Paris 6]] and Richard Gallagher with co-workers at [[Cornell University]]. Further impetus was provided in these years by available open source finite element software programs. NASA sponsored the original version of [[NASTRAN]], and UC Berkeley made the finite element program SAP IV<ref>{{cite web|title=SAP-IV Software and Manuals | url= http://nisee.berkeley.edu/elibrary/getpkg?id=SAP4 | location=NISEE e-Library, The Earthquake Engineering Online Archive}}</ref> widely available. In Norway the ship classification society Det Norske Veritas (now [[DNV GL]]) developed [[SESAM (FEM)|Sesam]] in 1969 for use in analysis of ships.<ref>{{cite book|url=|title=Building Trust, The history of DNV 1864-2014|author1=Gard Paulsen|author2=Håkon With Andersen|author3=John Petter Collett|author4=Iver Tangen Stensrud|date=2014|publisher=Dinamo Forlag A/S|isbn=978-82-8071-256-1|location=Lysaker, Norway|pages=121, 436}}<!--|access-date=30 June 2015 --></ref> A rigorous mathematical basis to the finite element method was provided in 1973 with the publication by [[Gilbert Strang|Strang]] and [[George Fix|Fix]].<ref>{{cite book | first1=Gilbert | last1=Strang | authorlink1=Gilbert Strang | first2=George | last2=Fix | authorlink2=George Fix | title=An Analysis of The Finite Element Method | publisher=Prentice Hall | year=1973 | isbn=978-0-13-032946-2}}</ref> The method has since been generalized for the [[numerical analysis|numerical modeling]] of physical systems in a wide variety of [[engineering]] disciplines, e.g., [[electromagnetism]], [[heat transfer]], and [[fluid dynamics]].<ref>{{cite book | first1=O.C. | last1= Zienkiewicz | authorlink1= Olgierd Zienkiewicz | first2=R.L. | last2=Taylor | first3=J.Z. | last3=Zhu | title= The Finite Element Method: Its Basis and Fundamentals | edition=Sixth | publisher=Butterworth-Heinemann | year=2005 | isbn=978-0750663205}}</ref><ref>{{cite book | first1=K.J. | last1=Bathe | authorlink1= Klaus-Jürgen Bathe | title=Finite Element Procedures | publisher= Cambridge, MA: Klaus-Jürgen Bathe | year=2006 | isbn= 978-0979004902}}</ref>\n\n==Technical discussion==\n\n===The structure of finite element methods===\nFinite element methods are numerical methods for approximating the solutions of mathematical problems that are usually formulated so as to precisely state an idea of some aspect of physical reality.\n\nA finite element method is characterized by a [[Calculus of variations|variational formulation]], a discretization strategy, one or more solution algorithms and post-processing procedures.\n\nExamples of variational formulation are the [[Galerkin method]], the discontinuous Galerkin method, mixed methods, etc.\n \nA discretization strategy is understood to mean a clearly defined set of procedures that cover (a) the creation of finite element meshes, (b) the definition of basis function on reference elements (also called shape functions) and (c) the mapping of reference elements onto the elements of the mesh.  Examples of discretization strategies are the h-version, [[p-FEM|p-version]], [[Hp-FEM|hp-version]], [[Extended finite element method|x-FEM]], [[isogeometric analysis]], etc.  Each discretization strategy has certain advantages and disadvantages.  A reasonable criterion in selecting a discretization strategy is to realize nearly optimal performance for the broadest set of mathematical models in a particular model class.\n\nThere are various numerical solution algorithms that can be classified into two broad categories; direct and iterative solvers.  These algorithms are designed to exploit the sparsity of matrices that depend on the choices of variational formulation and discretization strategy.\n\nPostprocessing procedures are designed for the extraction of the data of interest from a finite element solution.  In order to meet the requirements of solution verification, postprocessors need to provide for ''a posteriori'' error estimation in terms of the quantities of interest. When the errors of approximation are larger than what is considered acceptable then the discretization has to be changed either by an automated adaptive process or by action of the analyst. There are some very efficient postprocessors that provide for the realization of [[superconvergence]].\n\n{{clear}}\n\n===Illustrative problems P1 and P2===\nWe will demonstrate the finite element method using two sample problems from which the general method can be extrapolated. It is assumed that the reader is familiar with [[calculus]] and [[linear algebra]].\n\nP1 is a ''' one-dimensional''' problem\n:<math>\\mbox{ P1 }:\\begin{cases}\nu''(x)=f(x) \\mbox{ in } (0,1), \\\\\nu(0)=u(1)=0,\n\\end{cases}</math>\nwhere <math>f</math> is given, <math>u</math> is an unknown function of <math>x</math>, and <math>u''</math> is the second derivative of <math>u</math> with respect to <math>x</math>.\n\nP2 is a ''' two-dimensional''' problem ([[Dirichlet problem]])\n:<math>\\mbox{P2 }:\\begin{cases}\nu_{xx}(x,y)+u_{yy}(x,y)=f(x,y) & \\mbox{ in } \\Omega, \\\\\nu=0 & \\mbox{ on } \\partial \\Omega,\n\\end{cases}</math>\n\nwhere <math>\\Omega</math> is a connected open region in the <math>(x,y)</math> plane whose boundary <math>\\partial \\Omega</math> is nice (e.g., a [[smooth manifold]] or a [[polygon]]), and <math>u_{xx}</math> and <math>u_{yy}</math> denote the second derivatives with respect to <math>x</math> and <math>y</math>, respectively.\n\nThe problem P1 can be solved directly by computing [[antiderivative]]s. However, this method of solving the [[boundary value problem]] (BVP) works only when there is one spatial dimension and does not generalize to higher-dimensional problems or to problems like <math>u+u''=f</math>. For this reason, we will develop the finite element method for P1 and outline its generalization to P2.\n\nOur explanation will proceed in two steps, which mirror two essential steps one must take to solve a boundary value problem (BVP) using the FEM.\n*In the first step, one rephrases the original BVP in its weak form. Little to no computation is usually required for this step.  The transformation is done by hand on paper.\n*The second step is the discretization, where the weak form is discretized in a finite-dimensional space.\nAfter this second step, we have concrete formulae for a large but finite-dimensional linear problem whose solution will approximately solve the original BVP. This finite-dimensional problem is then implemented on a [[computer]].<ref>{{cite book | first1=I.M. | last1= Smith | first2=D.V. | last2=Griffiths | first3=L. | last3=Margetts | title= Programming the Finite Element Method | edition=Fifth | publisher=Wiley | year=2014 | isbn=978-1-119-97334-8}}</ref>\n\n===Weak formulation===\nThe first step is to convert P1 and P2 into their equivalent [[weak formulation]]s.\n\n====The weak form of P1====\nIf <math>u</math> solves P1, then for any smooth function <math>v</math> that satisfies the displacement boundary conditions, i.e. <math>v=0</math> at <math>x=0</math> and <math>x=1</math>, we have\n\n(1) <math>\\int_0^1 f(x)v(x) \\, dx = \\int_0^1 u''(x)v(x) \\, dx.</math>\n\nConversely, if <math>u</math> with <math>u(0)=u(1)=0</math> satisfies (1) for every smooth function <math>v(x)</math> then one may show that this <math>u</math> will solve P1.  The proof is easier for twice continuously differentiable <math>u</math> ([[mean value theorem]]), but may be proved in a [[Distribution (mathematics)|distributional]] sense as well.\n\nWe define a new operator or map <math>\\phi(u,v)</math> by using [[integration by parts]] on the right-hand-side of (1):\n\n(2)<math>\n\\begin{align}\n \\int_0^1 f(x)v(x) \\, dx & = \\int_0^1 u''(x)v(x) \\, dx \\\\\n & = u'(x)v(x)|_0^1-\\int_0^1 u'(x)v'(x) \\, dx \\\\\n & = -\\int_0^1 u'(x)v'(x) \\, dx \\equiv -\\phi (u,v),\n\\end{align}\n</math>\n\nwhere we have used the assumption that <math>v(0)=v(1)=0</math>.\n\n====The weak form of P2====\nIf we integrate by parts using a form of [[Green's identities]], we see that if <math>u</math> solves P2, then we may define <math>\\phi(u,v)</math> for any <math>v</math> by\n\n:<math>\\int_\\Omega fv\\,ds = -\\int_\\Omega \\nabla u \\cdot \\nabla v \\, ds \\equiv -\\phi(u,v),</math>\n\nwhere <math>\\nabla</math> denotes the [[gradient]] and <math>\\cdot</math> denotes the [[dot product]] in the two-dimensional plane. Once more <math>\\,\\!\\phi</math> can be turned into an inner product on a suitable space <math>H_0^1(\\Omega)</math> of once differentiable functions of <math>\\Omega</math> that are zero on <math>\\partial \\Omega</math>. We have also assumed that <math>v \\in H_0^1(\\Omega)</math> (see [[Sobolev space]]s). Existence and uniqueness of the solution can also be shown.\n\n====A proof outline of existence and uniqueness of the solution====\nWe can loosely think of <math>H_0^1(0,1)</math> to be the [[absolutely continuous]] functions of <math>(0,1)</math> that are <math>0</math> at <math>x=0</math> and <math>x=1</math> (see [[Sobolev spaces]]). Such functions are (weakly) once differentiable and it turns out that the symmetric [[bilinear map]] <math>\\!\\,\\phi</math> then defines an [[inner product]] which turns <math>H_0^1(0,1)</math> into a [[Hilbert space]] (a detailed proof is nontrivial). On the other hand, the left-hand-side <math>\\int_0^1 f(x)v(x)dx</math> is also an inner product, this time on the [[Lp space]] <math>L^2(0,1)</math>. An application of the [[Riesz representation theorem]] for Hilbert spaces shows that there is a unique <math>u</math> solving (2) and therefore P1.  This solution is a-priori only a member of <math>H_0^1(0,1)</math>, but using [[elliptic operator|elliptic]] regularity, will be smooth if <math>f</math> is.\n\n==Discretization==\n[[File:Finite element method 1D illustration1.png|thumb|A function in <math>H_0^1,</math> with zero values at the endpoints (blue), and a piecewise linear approximation (red)]]\n\nP1 and P2 are ready to be discretized which leads to a common sub-problem (3). The basic idea is to replace the infinite-dimensional linear problem:\n:Find <math>u \\in  H_0^1</math>  such that\n:<math>\\forall v \\in H_0^1, \\; -\\phi(u,v)=\\int fv</math>\nwith a finite-dimensional version:\n\n:(3) Find <math>u \\in V</math> such that\n:<math>\\forall v \\in V, \\; -\\phi(u,v)=\\int fv</math>\n\nwhere <math>V</math> is a finite-dimensional [[Linear subspace|subspace]] of <math>H_0^1</math>. There are many possible choices for <math>V</math> (one possibility leads to the [[spectral method]]). However, for the finite element method we take <math>V</math> to be a space of piecewise polynomial functions.\n\n===For problem P1===\nWe take the interval <math>(0,1)</math>, choose <math>n</math> values of <math>x</math> with <math>0=x_0<x_1<\\cdots<x_n<x_{n+1}=1</math> and we define <math>V</math> by:\n\n:<math>V=\\{v:[0,1] \\rightarrow \\mathbb R\\;: v\\mbox{ is continuous, }v|_{[x_k,x_{k+1}]} \\mbox{ is linear for } k=0,\\dots,n \\mbox{, and } v(0)=v(1)=0 \\} </math>\n\nwhere we define <math>x_0=0</math> and <math>x_{n+1}=1</math>. Observe that functions in <math>V</math> are not differentiable according to the elementary definition of calculus. Indeed, if <math>v \\in V</math> then the derivative is typically not defined at any <math>x=x_k</math>, <math>k=1,\\ldots,n</math>. However, the derivative exists at every other value of <math>x</math> and one can use this derivative for the purpose of [[integration by parts]].\n\n[[File:Piecewise linear function2D.svg|thumb|A piecewise linear function in two dimensions]]\n\n===For problem P2===\nWe need <math>V</math> to be a set of functions of <math>\\Omega</math>. In the figure on the right, we have illustrated a [[Polygon triangulation|triangulation]] of a 15 sided [[polygon]]al region <math>\\Omega</math> in the plane (below), and a [[piecewise linear function]] (above, in color) of this polygon which is linear on each triangle of the triangulation; the space <math>V</math> would consist of functions that are linear on each triangle of the chosen triangulation.\n\nOne hopes that as the underlying triangular mesh becomes finer and finer, the solution of the discrete problem (3) will in some sense converge to the solution of the original boundary value problem P2. To measure this mesh fineness, the triangulation is indexed by a real valued parameter <math>h > 0</math> which one takes to be very small. This parameter will be related to the size of the largest or average triangle in the triangulation. As we refine the triangulation, the space of piecewise linear functions <math>V</math> must also change with <math>h</math>. For this reason, one often reads <math>V_h</math> instead of <math>V</math> in the literature. Since we do not perform such an analysis, we will not use this notation.\n\n===Choosing a basis===\n{{multiple image|caption_align=left|header_align=center\n | align = right\n | direction = vertical\n | width = 200\n | header = Interpolation of a [[Bessel function]]\n | image1 = Linear interpolation of J0 (basis set).svg\n | alt1 = Sixteen triangular basis functions used to reconstruct J0\n | caption1 = 16 scaled and shifted triangular basis functions (colors) used to reconstruct a zeroeth order Bessel function ''J''<sub>''0''</sub> (black).\n | image2 = Linear interpolation of J1 (basis set).svg\n | alt2 = Summation of basis functions\n | caption2  = The linear combination of basis functions (yellow) reproduces ''J''<sub>''0''</sub> (blue) to any desired accuracy.\n}}\nTo complete the discretization, we must select a [[Basis (linear algebra)|basis]] of <math>V</math>. In the one-dimensional case, for each control point <math>x_k</math> we will choose the piecewise linear function <math>v_k</math> in <math>V</math> whose value is <math>1</math> at <math>x_k</math> and zero at every <math>x_j,\\;j \\neq k</math>, i.e.,\n\n:<math>v_{k}(x)=\\begin{cases} {x-x_{k-1} \\over x_k\\,-x_{k-1}} & \\mbox{ if } x \\in [x_{k-1},x_k], \\\\\n{x_{k+1}\\,-x \\over x_{k+1}\\,-x_k} & \\mbox{ if } x \\in [x_k,x_{k+1}], \\\\\n0 & \\mbox{ otherwise},\\end{cases}</math>\n\nfor <math>k=1,\\dots,n</math>; this basis is a shifted and scaled [[tent function]]. For the two-dimensional case, we choose again one basis function <math>v_k</math> per vertex <math>x_k</math> of the triangulation of the planar region <math>\\Omega</math>. The function <math>v_k</math> is the unique function of <math>V</math> whose value is <math>1</math> at <math>x_k</math> and zero at every <math>x_j,\\;j \\neq k</math>.\n\nDepending on the author, the word \"element\" in \"finite element method\" refers either to the triangles in the domain, the piecewise linear basis function, or both. So for instance, an author interested in curved domains might replace the triangles with curved primitives, and so might describe the elements as being curvilinear. On the other hand, some authors replace \"piecewise linear\" by \"piecewise quadratic\" or even \"piecewise polynomial\". The author might then say \"higher order element\" instead of \"higher degree polynomial\". Finite element method is not restricted to triangles (or tetrahedra in 3-d, or higher order simplexes in multidimensional spaces), but can be defined on quadrilateral subdomains (hexahedra, prisms, or pyramids in 3-d, and so on). Higher order shapes (curvilinear elements) can be defined with polynomial and even non-polynomial shapes (e.g. ellipse or circle).\n\nExamples of methods that use higher degree piecewise polynomial basis functions are the\n[[hp-FEM]] and [[spectral element method|spectral FEM]].\n\nMore advanced implementations (adaptive finite element methods) utilize a method to assess the quality of the results (based on error estimation theory) and modify the mesh during the solution aiming to achieve approximate solution within some bounds from the exact solution of the continuum problem. Mesh adaptivity may utilize various techniques, the most popular are:\n*moving nodes (r-adaptivity)\n*refining (and unrefining) elements (h-adaptivity)\n*changing order of base functions (p-adaptivity)\n*combinations of the above ([[hp-FEM|hp-adaptivity]]).\n\n=== Small support of the basis ===\n[[File:Finite element triangulation.svg|thumb|Solving the two-dimensional problem <math>u_{xx}+u_{yy}=-4</math> in the disk centered at the origin and radius 1, with zero boundary conditions.<br />(a) The triangulation.]]\n[[File:Finite element sparse matrix.png|thumb|(b) The [[sparse matrix]] ''L'' of the discretized linear system]]\n[[File:Finite element solution.svg|thumb|(c) The computed solution, <math>u(x, y)=1-x^2-y^2.</math>]]\nThe primary advantage of this choice of basis is that the inner products\n:<math>\\langle v_j,v_k \\rangle=\\int_0^1 v_j v_k\\,dx</math>\nand\n:<math>\\phi(v_j,v_k)=\\int_0^1 v_j' v_k'\\,dx</math>\n\nwill be zero for almost all <math>j,k</math>.\n(The matrix containing <math>\\langle v_j,v_k \\rangle</math> in the <math>(j,k)</math> location is known as the [[Gramian matrix]].)\nIn the one dimensional case, the [[support (mathematics)|support]] of <math>v_k</math> is the interval <math>[x_{k-1},x_{k+1}]</math>. Hence, the integrands of <math>\\langle v_j,v_k \\rangle</math> and ''<math>\\phi(v_j,v_k)</math>'' are identically zero whenever <math>|j-k|>1</math>.\n\nSimilarly, in the planar case, if <math>x_j</math> and <math>x_k</math> do not share an edge of the triangulation, then the integrals\n:<math>\\int_{\\Omega} v_j v_k\\,ds</math>\nand\n:<math>\\int_{\\Omega} \\nabla v_j \\cdot \\nabla v_k\\,ds</math>\nare both zero.\n\n===Matrix form of the problem===\nIf we write <math>u(x)=\\sum_{k=1}^n u_k v_k(x)</math> and <math>f(x)=\\sum_{k=1}^n f_k v_k(x)</math> then problem (3), taking <math>v(x)=v_j(x)</math> for <math>j=1,\\dots,n</math>, becomes\n:<math>-\\sum_{k=1}^n u_k \\phi (v_k,v_j) = \\sum_{k=1}^n f_k \\int v_k v_j dx</math> for <math>j=1,\\dots,n.</math>  (4)\n\nIf we denote by <math>\\mathbf{u}</math> and <math>\\mathbf{f}</math> the column vectors <math>(u_1,\\dots,u_n)^t</math> and <math>(f_1,\\dots,f_n)^t</math>, and if we let\n:<math>L=(L_{ij})</math>\nand\n:<math>M=(M_{ij})</math>\nbe matrices whose entries are\n:<math>L_{ij}=\\phi (v_i,v_j)</math>\nand\n:<math>M_{ij}=\\int v_i v_j dx</math>\nthen we may rephrase (4) as\n:<math>-L \\mathbf{u} = M \\mathbf{f}.</math> (5)\n\nIt is not necessary to assume <math>f(x)=\\sum_{k=1}^n f_k v_k(x)</math>. For a general function  <math>f(x)</math>,  problem (3) with <math>v(x)=v_j(x)</math> for <math>j=1,\\dots,n</math> becomes actually simpler, since no matrix <math>M</math> is used,\n: <math>-L \\mathbf{u} = \\mathbf{b}</math>, (6)\nwhere <math>\\mathbf{b}=(b_1,\\dots,b_n)^t</math> and <math>b_j=\\int f v_j dx</math> for <math>j=1,\\dots,n</math>.\n\nAs we have discussed before, most of the entries of <math>L</math> and <math>M</math> are zero because the basis functions <math>v_k</math> have small support. So we now have to solve a linear system in the unknown <math>\\mathbf{u}</math> where most of the entries of the matrix <math>L</math>, which we need to invert, are zero.\n\nSuch matrices are known as [[sparse matrix|sparse matrices]], and there are efficient solvers for such problems (much more efficient than actually inverting the matrix.) In addition, <math>L</math> is symmetric and positive definite, so a technique such as the [[conjugate gradient method]] is favored. For problems that are not too large, sparse [[LU decomposition]]s and [[Cholesky decomposition]]s still work well. For instance, [[MATLAB]]'s backslash operator (which uses sparse LU, sparse Cholesky, and other factorization methods) can be sufficient for meshes with a hundred thousand vertices.\n\nThe matrix <math>L</math> is usually referred to as the [[stiffness matrix]], while the matrix <math>M</math> is dubbed the [[mass matrix]].\n\n===General form of the finite element method===\nIn general, the finite element method is characterized by the following process.\n\n*One chooses a grid for <math>\\Omega</math>. In the preceding treatment, the grid consisted of triangles, but one can also use squares or curvilinear polygons.\n*Then, one chooses basis functions. In our discussion, we used piecewise linear basis functions, but it is also common to use piecewise polynomial basis functions.\n\nA separate consideration is the smoothness of the basis functions. For second order [[elliptic boundary value problem]]s, piecewise polynomial basis function that are merely continuous suffice (i.e., the derivatives are discontinuous.) For higher order partial differential equations, one must use smoother basis functions. For instance, for a fourth order problem such as <math>u_{xxxx}+u_{yyyy}=f</math>, one may use piecewise quadratic basis functions that are [[Smooth function#Order of continuity|<math>C^1</math>]].\n\nAnother consideration is the relation of the finite-dimensional space <math>V</math> to its infinite-dimensional counterpart, in the examples above <math>H_0^1</math>. A [[conforming element method]] is one in which the space <math>V</math> is a subspace of the element space for the continuous problem. The example above is such a method. If this condition is not satisfied, we obtain a [[nonconforming element method]], an example of which is the space of piecewise linear functions over the mesh which are continuous at each edge midpoint. Since these functions are in general discontinuous along the edges, this finite-dimensional space is not a subspace of the original <math>H_0^1</math>.\n\nTypically, one has an algorithm for taking a given mesh and subdividing it. If the main method for increasing precision is to subdivide the mesh, one has an ''h''-method (''h'' is customarily the diameter of the largest element in the mesh.) In this manner, if one shows that the error with a grid <math>h</math> is bounded above by <math>Ch^p</math>, for some <math>C<\\infty</math> and <math>p>0</math>, then one has an order ''p'' method. Under certain hypotheses (for instance, if the domain is convex), a piecewise polynomial of order <math>d</math> method will have an error of order <math>p=d+1</math>.\n\nIf instead of making ''h'' smaller, one increases the degree of the polynomials used in the basis function, one has a ''p''-method. If one combines these two refinement types, one obtains an ''hp''-method ([[hp-FEM]]). In the hp-FEM, the polynomial degrees can vary from element to element. High order methods with large uniform ''p'' are called spectral finite element methods ([[spectral element method|SFEM]]). These are not to be confused with [[spectral method]]s.\n\nFor vector partial differential equations, the basis functions may take values in <math>\\mathbb{R}^n</math>.\n\n==Various types of finite element methods==\n\n===AEM===\nThe Applied Element Method, or AEM combines features of both FEM and [[Discrete element method]], or (DEM).\n{{Main|Applied element method}}\n\n=== Generalized finite element method ===\nThe generalized finite element method (GFEM) uses local spaces consisting of functions, not necessarily polynomials, that reflect the available information on the unknown solution and thus ensure good local approximation. Then a [[partition of unity]] is used to “bond” these spaces together to form the approximating subspace. The effectiveness of GFEM has been shown when applied to problems with domains having complicated boundaries, problems with micro-scales, and problems with boundary layers.<ref>{{cite journal | first1=Ivo | last1=Babuška | author1-link=Ivo Babuška | first2=Uday | last2=Banerjee | first3=John E. | last3=Osborn | author3-link=John E. Osborn (mathematician) |  title=Generalized Finite Element Methods: Main Ideas, Results, and Perspective | journal=[[International Journal of Computational Methods]] |date=June 2004 | issue=1  | pages= 67–103 | doi=10.1142/S0219876204000083 | volume=1}}</ref>\n\n===Mixed finite element method===\n{{Main|Mixed finite element method}}\nThe mixed finite element method is a type of finite element method in which extra independent variables are introduced as nodal variables during the discretization of a partial differential equation problem.\n\n===hp-FEM===\nThe [[hp-FEM]] combines adaptively, elements with variable size ''h'' and polynomial degree ''p'' in order to achieve exceptionally fast, exponential convergence rates.<ref>P. Solin, K. Segeth, I. Dolezel: Higher-Order Finite Element Methods, Chapman & Hall/CRC Press, 2003</ref>\n\n===hpk-FEM===\nThe [[hpk-FEM]] combines adaptively, elements with variable size ''h'', polynomial degree of the local approximations ''p'' and global differentiability of the local approximations ''(k-1)'' in order to achieve best convergence rates.\n\n===XFEM===\n{{main|Extended finite element method}}\n\nThe [[extended finite element method]] (XFEM) is a numerical technique based on the generalized finite element method (GFEM) and the partition of unity method (PUM). It extends the classical finite element method by enriching the solution space for solutions to differential equations with discontinuous functions. Extended finite element methods enrich the approximation space so that it is able to naturally reproduce the challenging feature associated with the problem of interest: the discontinuity, singularity, boundary layer, etc. It was shown that for some problems, such an embedding of the problem's feature into the approximation space can significantly improve convergence rates and accuracy. Moreover, treating problems with discontinuities with XFEMs suppresses the need to mesh and remesh the discontinuity surfaces, thus alleviating the computational costs and projection errors associated with conventional finite element methods, at the cost of restricting the discontinuities to mesh edges.\n\nSeveral research codes implement this technique to various degrees:\n1. GetFEM++\n2. xfem++\n3. openxfem++\n\nXFEM has also been implemented in codes like Altair Radioss, ASTER, Morfeo and Abaqus. It is increasingly being adopted by other commercial finite element software, with a few plugins and actual core implementations available (ANSYS, SAMCEF, OOFELIE, etc.).\n\n===Scaled boundary finite element method (SBFEM)===\n\nThe introduction of the scaled boundary finite element method (SBFEM) came from Song and Wolf (1997).<ref>{{cite journal |first=Chongmin |last=Song |first2=John P. |last2=Wolf |title=The scaled boundary finite-element method - alias consistent infinitesimal finite-element cell method - for elastodynamics |journal=Computer Methods in Applied Mechanics and Engineering |volume=147 |issue=3–4 |date=5 August 1997 |pages=329–355 |doi=10.1016/S0045-7825(97)00021-2|bibcode=1997CMAME.147..329S }}</ref> The SBFEM has been one of the most profitable contributions in the area of numerical analysis of fracture mechanics problems. It is a semi-analytical fundamental-solutionless method which combines the advantages of both the finite element formulations and procedures, and the boundary element discretization. However, unlike the boundary element method, no fundamental differential solution is required.\n\n===S-FEM===\n{{Main|Smoothed finite element method}}\nThe S-FEM, Smoothed Finite Element Methods, are a particular class of numerical simulation algorithms for the simulation of physical phenomena. It was developed by combining meshfree methods with the finite element method.\n\n===Spectral element method===\n{{Main|Spectral element method}}Spectral element methods combine the geometric flexibility of finite elements and the acute accuracy of spectral methods. Spectral methods are the approximate solution of weak form partial equations that are based on high-order Lagragian interpolants and used only with certain quadrature rules.<ref>{{Cite web|url=http://lsec.cc.ac.cn/~cjxu/SEM_mem.html|title=Spectral Element Methods|last=|first=|date=|website=State Key Laboratory of Scientific and Engineering Computing|archive-url=|archive-date=|dead-url=|access-date=2017-07-28}}</ref>\n\n===Meshfree methods===\n{{Main|Meshfree methods}}\n\n===Discontinuous Galerkin methods===\n{{Main|Discontinuous Galerkin method}}\n\n===Finite element limit analysis===\n{{Main|Finite element limit analysis}}\n\n===Stretched grid method===\n{{Main|Stretched grid method}}\n\n=== Loubignac iteration ===\n[[Loubignac iteration]] is an iterative method in finite element methods.\n\n==Link with the gradient discretisation method==\nSome types of finite element methods (conforming, nonconforming, mixed finite element methods) are particular cases of the [[gradient discretisation method]] (GDM). Hence the convergence properties of the GDM, which are established for a series of problems (linear and non linear elliptic problems, linear, nonlinear and degenerate parabolic problems), hold as well for these particular finite element methods.\n\n==Comparison to the finite difference method==\n{{Unreferenced section|date=November 2010}}\nThe [[finite difference method]] (FDM) is an alternative way of approximating solutions of PDEs. The differences between FEM and FDM are:\n\n*The most attractive feature of the FEM is its ability to handle complicated geometries (and boundaries) with relative ease. While FDM in its basic form is restricted to handle rectangular shapes and simple alterations thereof, the handling of geometries in FEM is theoretically straightforward.\n*FDM is not usually used for irregular CAD geometries but more often rectangular or block shaped models.<ref>{{Cite news|url=http://www.machinedesign.com/fea-and-simulation/what-s-difference-between-fem-fdm-and-fvm|title=What’s The Difference Between FEM, FDM, and FVM?|date=2016-04-18|work=Machine Design|access-date=2017-07-28}}</ref>\n*The most attractive feature of finite differences is that it is very easy to implement.\n*There are several ways one could consider the FDM a special case of the FEM approach. E.g., first order FEM is identical to FDM for [[Poisson's equation]], if the problem is [[Discretization|discretized]] by a regular rectangular mesh with each rectangle divided into two triangles.\n*There are reasons to consider the mathematical foundation of the finite element approximation more sound, for instance, because the quality of the approximation between grid points is poor in FDM.\n*The quality of a FEM approximation is often higher than in the corresponding FDM approach, but this is extremely problem-dependent and several examples to the contrary can be provided.\n\nGenerally, FEM is the method of choice in all types of analysis in structural mechanics (i.e. solving for deformation and stresses in solid bodies or dynamics of structures) while [[computational fluid dynamics]] (CFD) tends to use FDM or other methods like [[finite volume method]] (FVM). CFD problems usually require discretization of the problem into a large number of cells/gridpoints (millions and more), therefore cost of the solution favors simpler, lower order approximation within each cell. This is especially true for 'external flow' problems, like air flow around the car or airplane, or weather simulation.\n\n==Application==\n[[File:FAE visualization.jpg|thumb|250px|Visualization of how a car deforms in an asymmetrical crash using finite element analysis.[http://impact.sourceforge.net]]]\nA variety of specializations under the umbrella of the mechanical engineering discipline (such as aeronautical, biomechanical, and automotive industries) commonly use integrated FEM in design and development of their products. Several modern FEM packages include specific components such as thermal, electromagnetic, fluid, and structural working environments. In a structural simulation, FEM helps tremendously in producing stiffness and strength visualizations and also in minimizing weight, materials, and costs.<ref name=\"Engineering Asset Management\">{{cite journal|last=Kiritsis |first=D. |last2=Eemmanouilidis |first2=Ch. |last3=Koronios |first3=A. |last4=Mathew |first4=J. |date=2009 |title=Engineering Asset Management |journal=Proceedings of the 4th World Congress on Engineering Asset Management (WCEAM) |pages=591–592}}</ref>\n\nFEM allows detailed visualization of where structures bend or twist, and indicates the distribution of stresses and displacements. FEM software provides a wide range of simulation options for controlling the complexity of both modeling and analysis of a system. Similarly, the desired level of accuracy required and associated computational time requirements can be managed simultaneously to address most engineering applications. FEM allows entire designs to be constructed, refined, and optimized before the design is manufactured. The mesh is an integral part of the model and it must be controlled carefully to give the best results. Generally the higher the number of elements in a mesh, the more accurate the solution of the discretised problem. However, there is a value at which the results converge and further mesh refinement does not increase accuracy.<ref>{{Cite web|url=https://coventivecomposites.com/explainers/finite-element-analysis-how-to-create-a-great-model/|title=Finite Element Analysis: How to create a great model|date=2019-03-18|website=Coventive Composites|language=en-GB|access-date=2019-04-05}}</ref>\n[[File:Human knee joint FE model.png|thumb|245x245px|Finite Element Model of a human knee joint. <ref>{{Cite journal|last=Naghibi Beidokhti|first=Hamid|last2=Janssen|first2=Dennis|last3=Khoshgoftar|first3=Mehdi|last4=Sprengers|first4=Andre|last5=Perdahcioglu|first5=Emin Semih|last6=Boogaard|first6=Ton Van den|last7=Verdonschot|first7=Nico|title=A comparison between dynamic implicit and explicit finite element simulations of the native knee joint|journal=Medical Engineering & Physics|volume=38|issue=10|pages=1123–1130|doi=10.1016/j.medengphy.2016.06.001|pmid=27349493|year=2016}}</ref>]]\nThis powerful design tool has significantly improved both the standard of engineering designs and the methodology of the design process in many industrial applications.<ref name=Hastings>Hastings, J. K., Juds, M. A., Brauer, J. R., ''Accuracy and Economy of Finite Element Magnetic Analysis'', 33rd Annual National Relay Conference, April 1985.</ref> The introduction of FEM has substantially decreased the time to take products from concept to the production line.<ref name=Hastings/> It is primarily through improved initial prototype designs using FEM that testing and development have been accelerated.<ref name=\"McLaren-Mercedes\">{{cite web|title=McLaren Mercedes: Feature - Stress to impress |author=McLaren-Mercedes |year=2006 |url=http://www.mclaren.com/features/technical/stress_to_impress.php |accessdate=2006-10-03 |archiveurl=https://web.archive.org/web/20061030200423/http://www.mclaren.com/features/technical/stress_to_impress.php |archivedate=2006-10-30 |deadurl=yes |df= }}</ref> In summary, benefits of FEM include increased accuracy, enhanced design and better insight into critical design parameters, virtual prototyping, fewer hardware prototypes, a faster and less expensive design cycle, increased productivity, and increased revenue.<ref name=Hastings/>\n\nIn the 1990s FEA was proposed for use in stochastic modelling for numerically solving probability models<ref>{{cite journal |title=Methods with high accuracy for finite element probability computing |author1=Peng Long |author2=Wang Jinliang |author3=Zhu Qiding |journal=Journal of Computational and Applied Mathematics |volume=59 |issue=2 |date=19 May 1995 |pages=181–189 |doi=10.1016/0377-0427(94)00027-X}}</ref> and later for reliability assessment.<ref>{{cite book |first=Achintya |last=Haldar |first2=Sankaran |last2=Mahadevan |title=Reliability Assessment Using Stochastic Finite Element Analysis |publisher=John Wiley & Sons |isbn=978-0471369615 |year=2000}}</ref> The stochastic finite element method has since been applied to many branches of engineering, <ref name=\"arregui14\">{{cite journal | last1 = Arregui Mena | first1 = J.D. | last2 = Margetts | first2 = L. | display-authors = etal   | year = 2014 | title = Practical Application of the Stochastic Finite Element Method | url = https://www.researchgate.net/publication/269332552 | journal = Archives of Computational Methods in Engineering | volume = 23| issue = 1| pages = 171–190| doi = 10.1007/s11831-014-9139-3}}</ref> often being applied to characterise variability in material properties.<ref name=\"arregui18\">{{cite journal | last1 = Arregui Mena | first1 = J.D. | display-authors = etal   | year = 2018 | title = Characterisation of the spatial variability of material properties of Gilsocarbon and NBG-18 using random fields | url = https://www.researchgate.net/publication/327537624 | journal = Journal of Nuclear Materials | volume = 511 | issue = | pages = 91–108| doi = 10.1016/j.jnucmat.2018.09.008}}</ref>\n\n==See also==\n*[[Applied element method]]\n*[[Boundary element method]]\n*[[Céa's lemma]]\n*[[Computer experiment]]\n*[[Direct stiffness method]]\n*[[Discontinuity layout optimization]]\n*[[Discrete element method]]\n*[[Finite difference method]]\n*[[Finite element machine]]\n*[[Finite element method in structural mechanics]]\n*[[Finite volume method]]\n*[[Finite volume method for unsteady flow]]\n*[[Interval finite element]]\n*[[Isogeometric analysis]]\n*[[Lattice Boltzmann methods]]\n*[[List of finite element software packages]]\n*[[Meshfree methods]]\n*[[Movable cellular automaton]]\n*[[Multidisciplinary design optimization]]\n*[[Multiphysics]]\n*[[Patch test (finite elements)|Patch test]]\n*[[Rayleigh–Ritz method]]\n*[[Space mapping]]\n*[[Weakened weak form]]\n*[[Infinite element method]]\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n*G. Allaire and A. Craig : ''[https://books.google.com/books?id=HIwSDAAAQBAJ&printsec=frontcover#v=onepage&q=%22finite%20element%22&f=false Numerical Analysis and Optimization: An Introduction to Mathematical Modelling and Numerical Simulation]''\n*K. J. Bathe : ''Numerical methods in finite element analysis'', Prentice-Hall (1976).\n*Thomas J.R. Hughes : ''The Finite Element Method: Linear Static and Dynamic Finite Element Analysis,'' Prentice-Hall (1987).\n*J. Chaskalovic : ''Finite Elements Methods for Engineering Sciences'', Springer Verlag, (2008).\n*[[Endre Süli]] - [http://people.maths.ox.ac.uk/suli/fem.pdf Finite Element Methods for Partial Differential Equations]\n*O. C. Zienkiewicz, R. L. Taylor, J. Z. Zhu : ''The Finite Element Method: Its Basis and Fundamentals'', Butterworth-Heinemann, (2005).\n\n==External links==\n{{Commonscat}}\n*[http://homepage.usask.ca/~ijm451/finite/fe_resources/ IFER – Internet Finite Element Resources] – describes and provides access to finite element analysis software via the Internet\n*[http://www.nafems.org NAFEMS – International Association Engineering Modelling]\n*[http://math.nist.gov/mcsd/savg/tutorial/ansys/FEM/ Mathematics of the Finite Element Method]\n\n{{Numerical PDE}}\n{{Authority control}}\n\n[[Category:Continuum mechanics]]\n[[Category:Finite element method| ]]\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n[[Category:Structural analysis]]\n[[Category:Computational electromagnetics]]"
    },
    {
      "title": "Dynamic design analysis method",
      "url": "https://en.wikipedia.org/wiki/Dynamic_design_analysis_method",
      "text": "{{Use mdy dates|date=October 2017}}\n[[File:Underwater Explosion with a Blue Water Navy Ship.jpg|200px|right|thumb|All mission-essential equipment on board naval ships and submarines must be qualified for shock loads caused by underwater explosions.]]\n\nThe '''dynamic design analysis method (DDAM)''' is a [[US Navy]]-developed analytical procedure for evaluating the design of equipment subject to [[structural load|dynamic loading]] caused by [[underwater explosion]]s (UNDEX). The analysis uses a form of [[shock response spectrum|shock spectrum analysis]] that estimates the dynamic response of a component to shock loading caused by the sudden movement of a naval vessel. The analytical process simulates the interaction between the shock-loaded component and its fixed structure, and it is a standard [[Naval architecture|naval engineering]] procedure for shipboard [[structural dynamics]].\n\n== Background and rationale  ==\n\nAll mission-essential equipment on board military surface ships and submarines must be qualified for underwater shock loads caused by [[depth charge]]s, [[naval mine]]s, missiles, and [[torpedo]]es. An [[underwater explosion]] nearby a ship or submarine can be devastating to the combat readiness of the vessel. Damage may occur in the form of dished hull plating or even more serious holing of the hull. Moreover, some damage may not be obvious and can occur as a result of shock-wave loading of equipment and systems aboard the vessel. Equipment damage may incapacitate a vessel. Much research effort has been expended in the study of underwater shock, especially during the period after World War II where it became obvious that navy vessels could be disabled by a non-contact underwater explosion.<ref>{{cite web| url=http://www.mscsoftware.com/support/library/conf/wuc94/p03194.pdf |title=Dynamic Design Analysis Method (DDAM) Using MSC/NASTRAN |last1=Barber |first1=Pam |last2=Arden |first2=Kevin |date= |work= |publisher=Newport News Shipbuilding, Newport News, VA |accessdate=June 28, 2012}}</ref> Thus a concerted effort was made to try to make shipboard equipment more resistant to shock. This was achieved through laboratory shock testing of equipment prior to its installation aboard vessels. With the advances in [[computer simulation]] and modeling capabilities, it is now possible to simulate a vessel's response to an [[underwater explosion]] and to identify potential problems or failures without extensive field testing. By using DDAM analytical techniques, money and time are saved.<ref>{{cite web|url=http://www.everyspec.com/USN/NAVY-General/DSTO-GD-0109_42397/ |title=''DSTO-GD-0109, The Response of Surface Ships to Underwater Explosions'' |publisher=Defense Science and Technology Organization – Commonwealth of Australia |date=September 1996 |accessdate=2012-06-26}}</ref>\n\n== Analysis methodology ==\n\nThe DDAM simulates the interaction between the shock-loaded component and its fixed structure as the free motion of a naval vessel in water produces a higher shock spectrum than a heavy structure would when mounted to a terrestrial surface. The DDAM takes interaction into account in relation to the mass of the equipment, its mounting location, and the orientation of the equipment on the vessel.\n\nEngineers use [[finite element method]] analysis software to verify designs using DDAM computer simulations that model the known characteristics of underwater explosion phenomena as well as the surface ship or submarine body responses to shock loading and application of a [[shock response spectrum|shock spectra]] in order to apply the appropriate shock responses at the mountings of shipboard equipment (e.g., masts, propulsion shafts, rudders, rudderstocks, bearings, exhaust uptakes and other critical structures) due to underwater explosions.<ref>{{cite web|url=http://www.everyspec.com/USN/NAVY-General/TECH-RPT_SUPSHIP_280-2_42396/ |title=''SUPSHIP 280-2, Guide for Mathematical Modeling and Dynamic Shock Analysis of Rudders, Rudder Stocks, and Bearings'' |publisher=Supervisor of Shipbuilding, U.S. Navy |date=December 1970 |accessdate=2012-06-26}}</ref> The analytical process is described in ''NAVSEA 0908-LP-000-3010, Shock Design Criteria for Surface Ships''<ref>{{cite web|url=http://www.everyspec.com/USN/NAVY-General/NAVSEA_0908-LP-000-3010_REV-1_42398/ |title=''NAVSEA 0908-LP-000-3010 (Revision 1), Shock Design Criteria for Surface Ships'' |publisher=Naval Sea Systems Command  |date=September 1995 |accessdate=2012-06-26}}</ref> which provides technical criteria for shock design calculations, and provides general background and educational material concerning application of the DDAM.\n\nA number of commercially available computer modeling and simulation programs are available to assist in this task.<ref>{{cite web |url=http://www.nenastran.com/fea/ddam.php |title=''Nastran Finite Element Analysis and Simulation Software'' |publisher=NEi Software |date= |accessdate=2012-06-28 |deadurl=yes |archiveurl=https://archive.is/20130130074832/http://www.nenastran.com/fea/ddam.php |archivedate=January 30, 2013 |df= }}</ref><ref>{{cite web|url=\nhttp://download.autodesk.com/us/algor/userguides/mergedProjects/analysis_types/Linear/Dynamic_Design_Analysis_Method.htm |title=''Dynamic Design Analysis Method (DDAM)'' |publisher=Autodesk, Inc. |date= |accessdate=2012-06-30}}</ref> \nAfter the analyst performs a natural frequency analysis to determine the mode shapes and natural frequencies, the DDAM process then uses an input spectrum of shock design values (i.e., displacements or accelerations) based on data from a series of unclassified [[United States Naval Research Laboratory|Naval Research Laboratory]] reports (primarily ''MR-1396, Design Values for Shock Design of Shipboard Equipment''<ref>{{cite web|url=http://www.everyspec.com/USN/NAVY-General/NRL_MEMO_RPT_1396_42392/ |title=''MR-1396, Design Values for Shock Design of Shipboard Equipment'' |publisher=Naval Research Laboratory  |date=January 1965 |accessdate=2012-06-26}}</ref> and ''FR-6267, Background for Mechanical Shock Design of Ships''<ref>{{cite web|url=http://www.everyspec.com/USN/NAVY-General/NRL_Report__6267_42394/ |title=''FR-6267, Background for Mechanical Shock Design of Ship's Systems'' |publisher=Naval Research Laboratory  |date=March 12, 1975 |accessdate=2012-06-26}}</ref>). Compliance standards for DDAM simulation and analysis software are maintained by the [[Naval Sea Systems Command]] (NAVSEA).\n\n== Reporting formats ==\n\nThe [[Naval Sea Systems Command]] (NAVSEA) established a standardized format to describe the content and formats for publishing results of the DDAM analyses and technical reports. These templates are called [[Data Item Descriptions]] (DID); once these are specified or tailored for a specific contract, they become [[Contract Data Requirements List]] items (CDRLs) that represent the deliverable items of a contract. Exactly which data items are required for delivery depends on the nature of the project. The DIDs for DDAM activities are the Analysis Report, Dynamic Shock'', ''Mathematical Model Report, Dynamic Shock Analysis'', and ''Dynamic Shock Analysis Extension Request''.<ref>{{cite web|url=http://www.everyspec.com/DATA-ITEM-DESC-DIDs/DI-ENVR/DI-ENVR-81030_42435/ |title=''DI-ENVR-81030, Data Item Description: Analysis Report, Dynamic Shock'' |publisher=Naval Sea Systems Command  |date=September 26, 1990 |accessdate=2012-06-28}}</ref><ref>{{cite web|url=http://www.everyspec.com/DATA-ITEM-DESC-DIDs/DI-ENVR/DI-ENVR-81031_42437/ |title=''DI-ENVR-81031, Data Item Description: Mathematical Model Report, Dynamic Shock Analysis'' |publisher=Naval Sea Systems Command  |date=September 26, 1990 |accessdate=2012-06-28}}</ref><ref>{{cite web|url=http://www.everyspec.com/DATA-ITEM-DESC-DIDs/DI-ENVR/DI-ENVR-81279_42436/ |title=''DI-ENVR-81279, Data Item Description: Dynamic Shock Analysis Extension Request'' |publisher=Naval Sea Systems Command  |date=July 28, 1992 |accessdate=2012-06-28}}</ref>\n\n== References ==\n\n{{reflist|2}}\n\n{{DEFAULTSORT:Finite Element Method}}\n[[Category:Continuum mechanics]]\n[[Category:Nuclear technology]]\n[[Category:Explosions]]\n[[Category:Finite element method]]\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n[[Category:Structural analysis]]"
    },
    {
      "title": "Finite element method in structural mechanics",
      "url": "https://en.wikipedia.org/wiki/Finite_element_method_in_structural_mechanics",
      "text": "{{expert needed|date=October 2010}}\nThe '''[[finite element method]]''' (FEM) is a powerful technique originally developed for numerical solution of complex problems in [[structural mechanics]], and it remains the method of choice for complex systems. In the FEM, the structural system is modeled by a set of appropriate '''finite elements''' interconnected at discrete points called nodes. Elements may have physical properties such as thickness, [[coefficient of thermal expansion]], [[density]], [[Young's modulus]], [[shear modulus]] and [[Poisson's ratio]].\n\n== History ==\nThe origin of finite method can be traced to the matrix analysis of structures <ref>Matrix Analysis Of Framed Structures, 3rd Edition by Jr. William Weaver, James M. Gere, Springer-Verlag New York, LLC, {{ISBN|978-0-412-07861-3}}, 1966</ref><ref>[https://books.google.com/books?id=Jd6i0k4wvtQC&printsec=frontcover#v=snippet&q=%22finite%20element%22%20OR%20%22finite%20method%22&f=false Theory of Matrix Structural Analysis], J. S. Przemieniecki, McGraw-Hill Book Company, New York, 1968</ref> where the concept of a displacement or stiffness matrix approach was introduced. Finite element concepts were developed based on engineering methods in 1950s. The finite element method obtained its real impetus in the 1960s and 1970s by  [[John Argyris]], and co-workers; at the [[University of Stuttgart]], by [[Ray W. Clough]]; at the  [[University of California, Berkeley]], by [[Olgierd Zienkiewicz]], and co-workers [[Ernest Hinton]], [[Bruce Irons (engineer)|Bruce Irons]];<ref>{{Cite journal |last1=Hinton |first1=Ernest |last2=Irons |first2=Bruce |author-link= |title=Least squares smoothing of experimental data using finite elements |journal=Strain |volume=4 |pages=24–27 |date=July 1968 |doi= |url=https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1475-1305.1968.tb01368.x}}</ref> at the [[Swansea University|University of Swansea]], by [[Philippe G. Ciarlet]]; at the [[Pierre-and-Marie-Curie University|University of Paris]]; at [[Cornell University]], by Richard Gallagher and co-workers. The original works such as those by Argyris <ref>Argyris, J.H and Kelsey, S. [https://books.google.com/books?id=PCsDCAAAQBAJ&printsec=frontcover#v=onepage&q=%22finite%20element%22&f=false Energy theorems and Structural Analysis] Butterworth Scientific publications, London, 1954</ref> and Clough <ref>Clough, R.W, “The Finite Element in Plane Stress Analysis.” Proceedings, 2nd ASCE Conference on Electronic Computations, Pittsburgh, Sep 1960</ref> became the foundation for today’s finite element structural analysis methods. Earlier books such as by Zienkiewicz <ref>The Finite Element Method for Solid and Structural Mechanics, Zienkiewicz O. C and Taylor R L {{ISBN|978-0-7506-6321-2}}, 1967, McGraw Hill, New York</ref> and more recent books such as by Yang <ref>Finite Element Structural Analysis , T.Y Yang, Prentice-Hall, Inc, Englewood, NJ, 1986</ref> give comprehensive summary of developments in finite-element structural analysis. Implementing the method in software is described in the classic text by Smith, Griffiths and Margetts.<ref>{{Cite web|title = Wiley: Programming the Finite Element Method, 5th Edition - I. M. Smith, D. V. Griffiths, L. Margetts|url = http://eu.wiley.com/WileyCDA/WileyTitle/productCd-1119973341.html|website = eu.wiley.com|accessdate = 2015-09-18}}</ref>\n\n Straight or curved one-dimensional elements with physical properties such as axial, bending, and torsional stiffnesses. This type of element is suitable for modeling cables, braces, trusses, beams, stiffeners, grids and frames. Straight elements usually have two nodes, one at each end, while curved elements will need at least three nodes including the end-nodes. The elements are positioned at the [[centroid]]al axis of the actual members.\n* Two-dimensional elements that resist only in-plane forces by membrane action (plane [[Stress (physics)|stress]], plane [[Strain (materials science)|strain]]), and plates that resist transverse loads by transverse shear and  bending action (plates and [[Thin-shell structure|shells]]). They may have a variety of shapes such as flat or curved [[triangle]]s and [[quadrilateral]]s. Nodes are usually placed at the element corners, and if needed for higher accuracy, additional nodes can be placed along the element edges or even within the element. The elements are positioned at the mid-surface of the actual layer thickness.\n* [[Torus]]-shaped elements for axisymmetric problems such as membranes, thick plates, shells, and solids. The cross-section of the elements are similar to the previously described types: one-dimensional for thin plates and shells, and two-dimensional for solids, thick plates and shells.\n* Three-dimensional elements for modeling 3-D solids such as [[machine]] components, [[dam]]s, [[Embankment (transportation)|embankment]]s or soil masses. Common element shapes include [[tetrahedral]]s and [[hexahedral]]s. Nodes are placed at the vertexes and possibly in the element faces or within the element.\n\n===Element interconnection and displacement===\nThe elements are interconnected only at the exterior nodes, and altogether they should cover the entire domain as accurately as possible. Nodes will have nodal [[displacement (vector)|(vector) displacements]] or [[degrees of freedom (engineering)|degrees of freedom]] which may include translations, rotations, and for special applications, higher order [[derivative]]s of displacements. When the nodes displace, they will ''drag'' the elements along in a certain manner dictated by the element formulation. In other words, displacements of any points in the element will be [[interpolation|interpolated]] from the nodal displacements, and this is the main reason for the approximate nature of the solution.\n\n==Practical considerations==\nFrom the application point of view, it is important to model the system such that:\n* Symmetry or anti-symmetry conditions are exploited in order to reduce the size of the model.\n* Displacement compatibility, including any required discontinuity, is ensured at the nodes, and preferably, along the element edges as well, particularly when adjacent elements are of different types, material or thickness. Compatibility of displacements of many nodes can usually be imposed via constraint relations.\n* Elements' behaviours must capture the dominant actions of the actual system, both locally and globally.\n* The element mesh should be sufficiently fine in order to produce acceptable accuracy. To assess accuracy, the mesh is refined until the important results shows little change. For higher accuracy, the [[aspect ratio (image)|aspect ratio]] of the elements should be as close to unity as possible, and smaller elements are used over the parts of higher stress [[gradient]].\n* Proper support constraints are imposed with special attention paid to nodes on symmetry axes.\nLarge scale commercial software packages often provide facilities for generating the mesh, and the graphical display of input and output, which greatly facilitate the verification of both input data and interpretation of the results.\n\n==Theoretical overview of FEM-Displacement Formulation: From elements, to system, to solution==\nWhile the theory of FEM can be presented in different perspectives or emphases, its development for [[structural analysis]] follows the more traditional approach via the [[virtual work]] principle or the [[minimum total potential energy principle]]. The [[virtual work]] principle approach is more general as it is applicable to both linear and non-linear material behaviours. The virtual work method is an expression of [[conservation of energy]]: for conservative systems, the work added to the system by a set of applied forces is equal to the energy stored in the system in the form of strain energy of the structure's components.\n\nThe principle of [[virtual work|virtual displacements]] for the structural system expresses the mathematical identity of external and internal virtual work:\n:<math>\\mbox{External virtual work} = \\int_{V}\\delta\\boldsymbol{\\epsilon}^T \\boldsymbol{\\sigma} \\, dV \\qquad \\mathrm{(1)}</math>\n\nIn other words, the summation of the work done on the system by the set of external forces is equal to the work stored as strain energy in the elements that make up the system.\n\nThe virtual internal work in the right-hand-side of the above equation may be found by summing the virtual work done on the individual elements. The latter requires that force-displacement functions be used that describe the  response for each individual element. Hence, the displacement of the structure is described by the response of individual (discrete) elements collectively. The equations are written only for the small domain of individual  elements of the structure rather than a single equation that describes the response of the system as a whole (a continuum). The latter would result in an intractable problem, hence the utility of the finite element method. As shown in the subsequent sections, Eq.(1) leads to the following governing equilibrium equation for the system:\n\n:<math>\\mathbf{R} = \\mathbf{Kr} + \\mathbf{R}^o \\qquad \\qquad \\qquad \\mathrm{(2)}</math>\nwhere\n:<math>\\mathbf{R} </math> = vector of nodal forces, representing external forces applied to the system's nodes.\n:<math>\\mathbf{K} </math> = system stiffness matrix, which is the collective effect of the individual ''elements' stiffness matrices'' :<math>\\mathbf{k}^e </math>.\n:<math>\\mathbf{r} </math> = vector of the system's nodal displacements.\n:<math>\\mathbf{R}^o </math> = vector of equivalent nodal forces, representing all external effects other than the nodal forces which are already included in the preceding nodal force vector '''R'''. These external effects may include distributed or concentrated surface forces, body forces, thermal effects, initial stresses and strains.\n\nOnce the supports' constraints are accounted for, the nodal displacements are found by solving the [[system of linear equations]] (2), symbolically:\n:<math>\\mathbf{r} = \\mathbf{K}^{-1} (\\mathbf{R}-\\mathbf{R}^o ) \\qquad \\qquad \\qquad \\mathrm{(3)}</math>\n\nSubsequently, the strains and stresses in individual elements may be found as follows:\n:<math>\\mathbf{\\epsilon} = \\mathbf{Bq} \\qquad \\qquad \\qquad \\qquad \\mathrm{(4)}</math>\n:<math>\\mathbf{\\sigma} = \\mathbf{E}(\\mathbf{\\epsilon} - \\mathbf{\\epsilon}^o)+\\mathbf{\\sigma}^o = \\mathbf{E}(\\mathbf{Bq} - \\mathbf{\\epsilon}^o)+\\mathbf{\\sigma}^o\\qquad \\qquad \\qquad \\mathrm{(5)}</math>\nwhere\n:<math>\\mathbf{q} </math> = vector of a nodal displacements--a subset of the system displacement vector '''r''' that pertains to the elements under consideration.\n:<math>\\mathbf{B} </math> = strain-displacement matrix that transforms nodal displacements '''q''' to strains at any point in the element.\n:<math>\\mathbf{E} </math> = elasticity matrix that transforms effective strains to stresses at any point in the element.\n:<math>\\mathbf{\\epsilon}^o </math> = vector of initial strains in the elements.\n:<math>\\mathbf{\\sigma}^o </math> = vector of initial stresses in the elements.\n\nBy applying the [[virtual work]] equation (1) to the system, we can establish the element matrices <math>\\mathbf{B}</math>, <math>\\mathbf{k}^e</math> as well as the technique of assembling the system matrices <math>\\mathbf{R}^o</math> and <math>\\mathbf{K}</math>. Other matrices such as <math>\\mathbf{\\epsilon}^o </math>, <math>\\mathbf{\\sigma}^o </math>, <math>\\mathbf{R} </math> and <math>\\mathbf{E} </math>  are known values and can be directly set up from data input.\n\n==Interpolation or shape functions==\nLet <math>\\mathbf{q}</math> be the vector of nodal displacements of a typical element. The displacements at any other point of the element may be found by the use of [[interpolation]] functions as, symbolically:\n:<math>\\mathbf{u} = \\mathbf{N} \\mathbf{q} \\qquad \\qquad \\qquad \\mathrm{(6)}</math>\nwhere\n:<math>\\mathbf{u} </math> = vector of displacements at any point {x,y,z} of the element.\n:<math>\\mathbf{N} </math> = matrix of ''[[shape functions]]'' serving as [[interpolation]] functions.\n\nEquation (6) gives rise to other quantities of great interest:\n* Virtual displacements that are a function of virtual nodal displacements: <math> \\delta \\mathbf{u} = \\mathbf{N} \\delta \\mathbf{q} \\qquad \\qquad \\qquad \\mathrm{(6b)}</math>\n* Strains in the elements that result from displacements of the element's nodes:<math>\\mathbf{\\epsilon} = \\mathbf{Du} = \\mathbf{DNq} \\qquad \\qquad \\qquad \\qquad \\mathrm{(7)}</math>\n:where <math>\\mathbf{D} </math> = matrix of [[Strain-displacement relations|differential operators]] that convert displacements to strains using [[linear elasticity]] theory. Eq.(7) shows that matrix '''B''' in (4) is\n::<math>\\mathbf{B} = \\mathbf{DN} \\qquad \\qquad \\qquad \\qquad \\mathrm{(8)}</math>\n* Virtual strains consistent with element's virtual nodal displacements: <math> \\delta \\boldsymbol{\\epsilon} = \\mathbf{B} \\delta \\mathbf{q} \\qquad \\qquad \\qquad \\qquad \\mathrm{(9)}</math>\n\n==Internal virtual work in a typical element==\nFor a typical element of volume <math> V^e </math>, the internal virtual work due to virtual displacements is obtained by substitution of (5) and (9) into (1):\n\n:<math>\\mbox{Internal virtual work} = \\int_{V^e}\\delta\\boldsymbol{\\epsilon}^T \\boldsymbol{\\sigma} \\, dV^e = \\delta\\ \\mathbf{q}^T \\int_{V^e} \\mathbf{B}^T \\big\\{\\mathbf{E}(\\mathbf{Bq} - \\mathbf{\\epsilon}^o)+\\mathbf{\\sigma}^o\\big\\} \\, dV^e \\qquad \\mathrm{(10)}</math>\n\n===Element matrices===\nPrimarily for the convenience of reference, the following matrices pertaining to a typical elements may now be defined:\n\n: Element stiffness matrix <math> \\mathbf{K}^e = \\int_{V^e} \\mathbf{B}^T \\mathbf{E} \\mathbf{B} \\, dV^e \\qquad \\mathrm{(11)}</math>\n\n: Equivalent element load vector <math> \\mathbf{Q}^{oe} = \\int_{V^e} - \\mathbf{B}^T \\big( \\mathbf{E}\\mathbf{\\epsilon}^o - \\mathbf{\\sigma}^o\\big ) \\, dV^e \\qquad \\mathrm{(12)}</math>\n\nThese matrices are usually evaluated numerically using [[Gaussian quadrature]] for [[numerical integration]].\nTheir use simplifies (10) to the following:\n:<math>\\mbox{Internal virtual work} = \\delta\\ \\mathbf{q}^T \\big( \\mathbf{K}^e \\mathbf{q} + \\mathbf{Q}^{oe} \\big)  \\qquad \\mathrm{(13)}</math>\n\n===Element virtual work in terms of system nodal displacements===\nSince the nodal displacement vector '''q''' is a subset of the system nodal displacements '''r''' (for compatibility with adjacent elements), we can replace '''q''' with '''r''' by expanding the size of the element matrices with new columns and rows of zeros:\n\n:<math>\\mbox{Internal virtual work} = \\delta\\ \\mathbf{r}^T \\big( \\mathbf{K}^e \\mathbf{r} + \\mathbf{Q}^{oe} \\big)  \\qquad \\mathrm{(14)}</math>\nwhere, for simplicity, we use the same symbols for the element matrices, which now have expanded size as well as suitably rearranged rows and columns.\n\n==System virtual work==\nSumming the internal virtual work (14) for all elements gives the right-hand-side of (1):\n\n:<math>\\mbox{System internal virtual work} = \\sum_{e} \\delta\\ \\mathbf{r}^T \\big( \\mathbf{k}^e \\mathbf{r} + \\mathbf{Q}^{oe} \\big)  = \\delta\\ \\mathbf{r}^T \\big( \\sum_{e} \\mathbf{k}^e \\big)\\mathbf{r} + \\delta\\ \\mathbf{r}^T \\sum_{e} \\mathbf{Q}^{oe}    \\qquad \\mathrm{(15)}</math>\n\nConsidering now the left-hand-side of (1), the system external virtual work consists of:\n* The work done by the nodal forces '''R''': <math> \\delta\\ \\mathbf{r}^T \\mathbf{R} \\qquad \\mathrm{(16)}</math>\n* The work done by external forces <math> \\mathbf{T}^e </math> on the part <math> \\mathbf{S}^e </math> of the elements' edges or surfaces, and by the body forces <math> \\mathbf{f}^e </math>\n::<math> \\sum_{e} \\int_{S^e} \\delta\\ \\mathbf{u}^T \\mathbf{T}^e \\, dS^e +   \\sum_{e} \\int_{V^e} \\delta\\ \\mathbf{u}^T \\mathbf{f}^e \\, dV^e </math>\n: Substitution of (6b) gives:\n:: <math> \\delta\\ \\mathbf{q}^T \\sum_{e} \\int_{S^e} \\mathbf{N}^T \\mathbf{T}^e \\, dS^e +   \\delta\\ \\mathbf{q}^T \\sum_{e} \\int_{V^e} \\mathbf{N}^T \\mathbf{f}^e \\, dV^e  </math>\n\n:or <math> -\\delta\\ \\mathbf{q}^T \\sum_{e} (\\mathbf{Q}^{te} +  \\mathbf{Q}^{fe}) \\qquad \\mathrm{(17a)}</math>\n:where we have introduced additional element's matrices defined below:\n:: <math> \\mathbf{Q}^{te} =  -\\int_{S^e} \\mathbf{N}^T \\mathbf{T}^e \\, dS^e  \\qquad \\mathrm{(18a)}</math>\n:: <math> \\mathbf{Q}^{fe} =  -\\int_{V^e} \\mathbf{N}^T \\mathbf{f}^e \\, dV^e  \\qquad \\mathrm{(18b)}</math>\n:Again, [[numerical integration]] is convenient for their evaluation. A similar replacement of '''q''' in (17a) with '''r''' gives, after rearranging and expanding the vectors <math> \\mathbf{Q}^{te}, \\mathbf{Q}^{fe} </math>:\n::<math> -\\delta\\ \\mathbf{r}^T \\sum_{e} (\\mathbf{Q}^{te} +  \\mathbf{Q}^{fe}) \\qquad \\mathrm{(17b)}</math>\n\n==Assembly of system matrices==\nAdding (16), (17b) and equating the sum to (15) gives:\n<math> \\delta\\ \\mathbf{r}^T \\mathbf{R} -\\delta\\ \\mathbf{r}^T \\sum_{e} (\\mathbf{Q}^{te} +  \\mathbf{Q}^{fe}) =  \\delta\\ \\mathbf{r}^T \\big( \\sum_{e} \\mathbf{k}^e \\big)\\mathbf{r} + \\delta\\ \\mathbf{r}^T \\sum_{e} \\mathbf{Q}^{oe}  </math>\n\nSince the virtual displacements <math> \\delta\\ \\mathbf{r}</math> are arbitrary, the preceding equality reduces to:\n\n<math> \\mathbf{R} = \\big( \\sum_{e} \\mathbf{k}^e \\big)\\mathbf{r} + \\sum_{e} \\big( \\mathbf{Q}^{oe} + \\mathbf{Q}^{te} +  \\mathbf{Q}^{fe} \\big) </math>\n\nComparison with (2) shows that:\n* The system stiffness matrix is obtained by summing the elements' stiffness matrices:\n:<math> \\mathbf{K} = \\sum_{e} \\mathbf{k}^e </math>\n* The vector of equivalent nodal forces is obtained by summing the elements' load vectors:\n:<math> \\mathbf{R}^o = \\sum_{e} \\big( \\mathbf{Q}^{oe} + \\mathbf{Q}^{te} +  \\mathbf{Q}^{fe} \\big) </math>\n\nIn practice, the element matrices are neither expanded nor rearranged. Instead, the system stiffness matrix <math> \\mathbf{K} </math> is assembled by adding individual coefficients <math> {k}_{ij}^e </math> to <math> {K}_{kl} </math> where the subscripts ij, kl mean that the element's nodal displacements <math> {q}_{i}^e, {q}_{j}^e </math> match respectively with the system's nodal displacements <math> {r}_{k}, {r}_{l} </math>. Similarly, <math> \\mathbf{R}^o </math> is assembled by adding individual coefficients <math> {Q}_{i}^e </math> to <math> {R}^o_{k} </math> where <math> {q}_{i}^e </math> matches <math> {r}_{k} </math>. This direct addition of <math> {k}_{ij}^e </math> into <math> {K}_{kl} </math> gives the procedure the name ''[[Direct stiffness method|Direct Stiffness Method]]''.\n\n==See also==\n*[[Finite element method]]\n*[[Flexibility method]]\n*[[Matrix stiffness method]]\n*[[Modal analysis using FEM]]\n*[[List of finite element software packages]]\n*[[Structural analysis]]\n*[[Virtual work]]\n*[[Interval finite element]]\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Finite Element Method In Structural Mechanics}}\n[[Category:Finite element method]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Finite pointset method",
      "url": "https://en.wikipedia.org/wiki/Finite_pointset_method",
      "text": "In [[applied mathematics]], the name '''finite pointset method'''  is a general approach for the numerical solution of problems in [[continuum mechanics]], such as the simulation of [[fluid flow]]s. In this approach (often abbreviated as '''FPM''') the medium is represented by a finite set of points, each endowed with the relevant local properties of the medium such as [[density]], [[velocity]], [[pressure]], and [[temperature]].<ref name=Bely/>\n\nThe sampling points can move with the medium, as in the [[Lagrangian approach]] to fluid dynamics or they may be fixed in space while the medium flows through them, as in the [[Eulerian approach]]. A mixed Lagrangian-Eulerian approach may also be used.  The Lagrangian approach is also known (especially in the [[computer graphics]] field) as [[particle method]].\n\nFinite pointset methods are [[meshfree method]]s and therefore are easily adapted to domains with complex and/or time-evolving geometries and moving phase boundaries (such as a liquid splashing into a container, or the [[glass blowing|blowing of a glass bottle]]) without the software complexity that would be required to handle those features with [[topological data structure]]s.  They can be useful in non-linear problems involving [[viscosity|viscous]] fluids, [[heat transfer|heat]] and [[mass transfer]], linear and non-linear [[elastic deformation|elastic]] or [[plastic deformation]]s, etc.\n\n==Description==\nIn the simplest implementations, the finite point set is stored as an unstructured list of points in the medium.  In the Lagrangian approach the points move with the medium, and points may be added or deleted in order to maintain a prescribed sampling density.  The point density is usually prescribed by a ''smoothing length'' defined locally. In the Eulerian approach the points are fixed in space, but new points may be added where there is need for increased accuracy.  So, in both approaches the nearest neighbors of a point are not fixed, and are determined again at each time step.\n\n==Advantages==\nThis method has various advantages over grid-based techniques; for example, it can handle fluid domains, which change naturally, whereas grid based techniques require additional computational effort. The finite points have to completely cover the whole flow domain, i.e. the point cloud has to fulfill certain quality criteria (finite points are not allowed to form “holes” which means finite points have to find sufficiently numerous neighbours; also, finite points are not allowed to cluster; etc.).\n\nThe finite point cloud is a geometrical basis, which allows for a numerical formulation making FPM a general finite difference idea applied to continuum mechanics. That especially means, if the point reduced to a regular cubic point grid, then FPM would reduce to a classical finite difference method. The idea of general finite differences also means that FPM is not based on a weak formulation like Galerkin’s approach. Rather, FPM is a strong formulation which models differential equations by direct approximation of the occurring differential operators. The method used is a moving least squares idea which was especially developed for FPM.\n\n==History==\nIn order to overcome the disadvantages of the classical methods many approaches have been developed to simulate such flows (Hansbo 92, [[Francis H. Harlow|Harlow]] et al. 1965, Hirt et al. 1981, Kelecy et al. 1997, Kothe at el. 1992, Maronnier et al. 1999, Tiwari et al. 2000). A classical grid free Lagrangian method is Smoothed Particle Hydrodynamics (SPH), which was originally introduced to solve problems in astrophysics (Lucy 1977, Gingold et al. 1977).\n\nIt has since been extended to simulate the compressible Euler equations in fluid dynamics and applied to a wide range of problems, see (Monaghan 92, Monaghan et al. 1983, Morris et al. 1997). The method has also been extended to simulate inviscid incompressible free surface flows (Monaghan 94). The implementation of the boundary conditions is the main problem of the SPH method.\n\nAnother approach for solving fluid dynamic equations in a grid free framework is the moving least squares or least squares method (Belytschko et al. 1996, Dilts 1996, Kuhnert 99, Kuhnert 2000, Tiwari et al. 2001 and 2000). With this approach boundary conditions can be implemented in a natural way just by placing the finite points on boundaries and prescribing boundary conditions on them (Kuhnert 99). The robustness of this method is shown by the simulation results in the field of airbag deployment in car industry. Here, the membrane (or boundary) of the airbag changes very rapidly in time and takes a quite complicated shape (Kuhnert et al. 2000).\n\nTiwari et al. (2000) performed simulations of incompressible flows as the limit of the compressible [[Navier–Stokes equations]] with some stiff equation of state. This approach was first used in (Monaghan 92) to simulate incompressible free surface flows by SPH. The incompressible limit is obtained by choosing a very large speed of sound in the equation of state such that the Mach number becomes small. However the large value of the speed of sound restricts the time step to be very small due to the [[Courant–Friedrichs–Lewy condition|CFL-condition]].\n\nThe [[Projection method (fluid dynamics)|projection method]] of [[Alexandre Chorin|Chorin]] (Chorin 68) is a widely used approach to solve problems governed by the incompressible Navier–Stokes equation in a grid based structure. In (Tiwari et al. 2001), this method has been applied to a grid free framework with the help of the weighted least squares method. The scheme gives accurate results for the incompressible [[Navier–Stokes equations]]. The occurring Poisson equation for the pressure field is solved by a grid free method. In (Tiwari et al. 2001), it has been shown that the Poisson equation can be solved accurately by this approach for any boundary conditions. The Poisson solver can be adapted to the weighted least squares approximation procedure with the condition that the Poisson equation and the boundary condition must be satisfied on each finite point. This is a local iteration procedure.\n\n==Software==\n* Nogrid points\n* [http://www.meshfree.eu MESHFREE]\n\n==References==\n<references>\n\n<ref name=Bely>\n  Belytschko T., Krongauz Y., Flemming M., Organ D., Liu W.K.S., Smoothing and accelerated computations in the element free Galerkin method, J. Comp. Appl. Maths,. vol. 74, 1996, p. 111-126.\n</ref>\n\n</references>\n\n*Ash N., Poo J. Y., Coalescence and separation in binary collisions of liquid drops, J. Fluid Mech., vol. 221, 1990, p.&nbsp;183 - 204. \n*Chorin A., Numerical solution of the Navier-Stokes equations, J. Math. Comput,. vol. 22, 1968, p.&nbsp;745-762. \n*Dilts G. A., Moving least squares particle hydrodynamics. I: consistency and stability, Hydrodynamics methods group report, Los Alamos National Laboratory, 1996\n*Gingold R. A., Monaghan J. J., Smoothed particle hydrodynamics: theory and application to non-spherical stars, Mon. Not. R. Astron. Soc., vol. 181, 1977, p.&nbsp;375-389. \n*Ginzburg I., Wittum G., Two-phase flows on interface refined grids modeled with VOF, staggered finite volumes, and spline interpolants, J. Comput. Phys.,. vol. 166, 2001, p.&nbsp;302-335.\n*Hansbo P., The characteristic streamline diffusion method for the time dependent incompressible Navier-Stokes equations, Comp. Meth. Appl. Mech. Eng., vol. 99, 1992, p.&nbsp;171-186.\n*Harlow F. H., Welch J. E., Numerical study of large amplitude free surface motions, Phys. Fluids, vol.8, 1965, p.&nbsp;2182.\n*Hirt C. W., Nichols B. D., Volume of fluid (VOF) method for dynamic of free boundaries, J. Comput. Phys., vol. 39, 1981, p.&nbsp;201.\n*Kelecy F. J., Pletcher R. H., The development of free surface capturing approach for multi dimensional free surface flows in closed containers, J. Comput. Phys., vol. 138, 1997, p.&nbsp;939.\n*Kothe D. B., Mjolsness R. C., RIPPLE: A new model for incompressible flows with free surfaces, AIAA Journal, Vol. 30, No 11, 1992, p.&nbsp;2694-2700. \n*Kuhnert J., General smoothed particle hydrodynamics, Ph.D. thesis, Kaiserslautern University, Germany, 1999.\n*Kuhnert J., An upwind finite pointset method for compressible Euler and Navier-Stokes equations, preprint, ITWM, Kaiserslautern, Germany, 2000.\n*Kuhnert J., Tramecon A., Ullrich P., Advanced Air Bag Fluid Structure Coupled Simulations applied to out-of Position Cases, EUROPAM Conference Proceedings 2000, [[ESI Group]], Paris, France\n*Landau L. D., Lifshitz E. M., Fluid Mechanics, Pergamon, New York, 1959. \n*Lafaurie B., Nardone C., Scardovelli R., Zaleski S.,  Zanetti G., Modelling Merging and Fragmentation in Multiphase Flows with SURFER, J. Comput. Phys., vol. 113, 1994, p.&nbsp;134 - 147. \n*Lucy L. B., A numerical approach to the testing of the fission hypothesis, Astron. J., vol. 82, 1977, p.&nbsp;1013. \n*Maronnier V., Picasso M., Rappaz J., Numerical simulation of free surface flows, J. Comput. Phys. vol. 155, 1999, p.&nbsp;439.\n*Martin J. C., Moyce M. J., An experimental study of the collapse of liquid columns on a liquid horizontal plate, Philos. Trans. Roy. Soc. London, Ser. A 244, 1952, p.&nbsp;312.\n*Monaghan J. J., Smoothed particle hydrodynamics, Annu. Rev. Astron. Astrop, vol. 30, 1992, p.&nbsp;543-574.\n*Monaghan J. J., Simulating free surface flows with SPH, J. Comput. Phys., vol. 110, 1994, p.&nbsp;399.\n*Monaghan J. J., Gingold R. A., Shock Simulation by particle method SPH, J. Comput. Phys., vol. 52, 1983, p.&nbsp;374-389. \n*Morris J. P., Fox P. J., Zhu Y., Modeling Low Reynolds Number Incompressible Flows Using SPH, J. Comput. Phys., vol. 136, 1997, p.&nbsp;214-226.\n*Tiwari S., Kuhnert J., Grid free method for solving Poisson equation, Berichte des Fraunhofer ITWM, Kaiserslautern, Germany, Nr. 25, 2001.\n*Tiwari S., Kuhnert J., Finite pointset method based on the projection method for simulations of the incompressible Navier-Stokes equations, M. Griebel, M. A. Schweitzer (Eds.), Springer LNCSE: Meshfree Methods for Partial Differential Equations, Springer-Verlag, Berlin, 26, 2003, p.&nbsp;373-387.\n*Tiwari S., Kuhnert J., Particle method for simulations of free surface flows, preprint Fraunhofer ITWM, Kaiserslautern, Germany, 2000.\n*Tiwari S., A LSQ-SPH approach for compressible viscous flows,Hyperbolic Problems: Theory, Numerics, Applications: Eighth International Conference in Magdeburg, February/March 2000, Volume II (International Series of Numerical Mathematics), Vol. 141, 2000, 901-910.\n*Tiwari S., Manservisi S., Modeling incompressible Navier-Stokes flows by LSQ-SPH, Berichte des Fraunhofer ITWM, Kaiserslautern, Germany, 2000.\n\n{{DEFAULTSORT:Finite Pointset Method}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Finite-difference time-domain method",
      "url": "https://en.wikipedia.org/wiki/Finite-difference_time-domain_method",
      "text": "'''Finite-difference time-domain''' or '''Yee's method''' (named after the Chinese American applied mathematician [[Kane S. Yee]], born 1934) is a [[numerical analysis]] technique used for modeling [[computational electrodynamics]] (finding approximate solutions to the associated system of [[differential equation]]s).  Since it is a [[time domain|time-domain]] method, FDTD solutions can cover a wide [[frequency]] range with a single [[computer simulation|simulation]] run, and treat nonlinear material properties in a natural way.\n\nThe FDTD method belongs in the general class of [[Discretization|grid]]-based differential numerical modeling methods ([[finite difference methods]]). The time-dependent [[Maxwell's equations]] (in [[Partial differential equation|partial differential]] form) are discretized using [[central difference|central-difference]] approximations to the space and time [[partial derivative]]s. The resulting [[finite difference method|finite-difference]] equations are solved in either software or hardware in a [[leapfrog integration|leapfrog]] manner:  the [[electric field]] [[vector component]]s in a volume of space are solved at a given instant in time; then the [[magnetic field]] vector components in the same spatial volume are solved at the next instant in time; and the process is repeated over and over again until the desired transient or steady-state electromagnetic field behavior is fully evolved.\n\n== History ==\nFinite difference schemes for time-dependent [[partial differential equation]]s (PDEs) have been employed for many years in [[computational fluid dynamics]] problems,<ref name=\"vonneumann49\" /> including the idea of using centered finite difference operators on staggered grids in space and time to achieve second-order accuracy.<ref name=\"vonneumann49\" />\nThe novelty of Kane Yee's FDTD scheme, presented in his seminal 1966 paper,<ref name=\"yee66\" /> was to apply centered finite difference operators on staggered grids in space and time for each electric and magnetic vector field component in Maxwell's curl equations.\nThe descriptor \"Finite-difference time-domain\" and its corresponding \"FDTD\" acronym were originated by [[Allen Taflove]] in 1980.<ref name=\"taflove80\" />\nSince about 1990, FDTD techniques have emerged as primary means to computationally model many scientific and engineering problems dealing with [[electromagnetic wave]] interactions with material structures. Current FDTD modeling applications range from near-[[Direct current|DC]] (ultralow-frequency [[geophysics]] involving the entire Earth-[[ionosphere]] waveguide) through [[microwaves]] (radar signature technology, [[Antenna (radio)|antennas]], wireless communications devices, digital interconnects, biomedical imaging/treatment) to [[visible light]] ([[photonic crystal]]s, nano[[plasmon]]ics, [[soliton]]s, and [[biophotonics]]).<ref name=\"taflove05\" />  In 2006, an estimated 2,000 FDTD-related publications appeared in the science and engineering literature (see [[#Popularity|Popularity]]). As of 2013, there are at least 25 commercial/proprietary FDTD software vendors; 13 free-software/[[Open source|open-source]]-software FDTD projects; and 2 freeware/closed-source FDTD projects, some not for commercial use (see [[#External links|External links]]).\n\n=== Development of FDTD and Maxwell's equations===\nAn appreciation of the basis, technical development, and possible future of FDTD numerical techniques for Maxwell’s equations can be developed by first considering their history.  The following lists some of the key publications in this area.\n\n{| class=\"wikitable\" width=\"90%\" style=\"text-align:left\"\n! colspan=\"2\" | Partial chronology of FDTD techniques and applications for Maxwell's equations.<ref>Adapted with permission from Taflove and Hagness (2005).</ref>\n|-\n! width=\"10%\"  | year\n! width=\"80%\"  | event\n|-\n| 1928 || Courant, Friedrichs, and Lewy (CFL) publish seminal paper with the discovery of conditional stability of explicit time-dependent finite difference schemes, as well as the classic FD scheme for solving second-order wave equation in 1-D and 2-D.<ref name=\"courant1928\" />\n|-\n| 1950 || First appearance of von Neumann's method of stability analysis for implicit/explicit time-dependent finite difference methods.<ref name=\"obrien1950\" />\n|-\n| 1966 || Yee described the FDTD numerical technique for solving Maxwell’s curl equations on grids staggered in space and time.<ref name=\"yee66\" />\n|-\n| 1969 || Lam reported the correct numerical CFL stability condition for Yee’s algorithm by employing von Neumann stability analysis.<ref name=\"lam69\" />\n|-\n| 1975 || Taflove and Brodwin reported the first sinusoidal steady-state FDTD solutions of two- and three-dimensional electromagnetic wave interactions with material structures;<ref name=\"taflove75a\" /> and the first bioelectromagnetics models.<ref name=\"taflove75b\" />\n|-\n| 1977 || Holland and Kunz & Lee applied Yee’s algorithm to EMP problems.<ref name=\"holland77\" /><ref name=\"kunz77\" />\n|-\n| 1980 || Taflove coined the FDTD acronym and published the first validated FDTD models of sinusoidal steady-state electromagnetic wave penetration into a three-dimensional metal cavity.<ref name=\"taflove80\" />\n|- \n| 1981 || Mur published the first numerically stable, second-order accurate, absorbing boundary condition (ABC) for Yee’s grid.<ref name=\"mur81\" />\n|-\n| 1982–83 || Taflove and Umashankar developed the first FDTD electromagnetic wave scattering models computing sinusoidal steady-state near-fields, far-fields, and radar cross-section for two- and three-dimensional structures.<ref name=\"umashankar82\" /><ref name=\"taflove83\" />\n|-\n| 1984 || Liao ''et al'' reported an improved ABC based upon space-time extrapolation of the field adjacent to the outer grid boundary.<ref name=\"liao84\" />\n|-\n| 1985 || Gwarek introduced the lumped equivalent circuit formulation of FDTD.<ref name=\"gwarek85\" />\n|-\n| 1986 || Choi and Hoefer published the first FDTD simulation of waveguide structures.<ref name=\"choi86\" />\n|-\n| 1987–88 || Kriegsmann ''et al'' and Moore ''et al'' published the first articles on ABC theory in ''IEEE  Transactions on Antennas and Propagation''.<ref name=\"kriegsmann87\" /><ref name=\"moore88\" />\n|-\n| 1987–88, 1992  || Contour-path subcell techniques were introduced by Umashankar ''et al'' to permit FDTD modeling of thin wires and wire bundles,<ref name=\"umashankar87\" /> by Taflove ''et al'' to model penetration through cracks in conducting screens,<ref name=\"taflove88\" /> and by Jurgens ''et al'' to conformally model the surface of a smoothly curved scatterer.<ref name=\"jurgens92\" />\n|-\n| 1988 || Sullivan ''et al'' published the first 3-D FDTD model of sinusoidal steady-state electromagnetic wave absorption by a complete human body.<ref name=\"sullivan88\" />\n|-\n| 1988 || FDTD modeling of microstrips was introduced by Zhang ''et al''.<ref name=\"zhang88\" />\n|-\n| 1990–91 || FDTD modeling of frequency-dependent dielectric permittivity was introduced by Kashiwa and Fukai,<ref name=\"kashiwa90\" /> Luebbers ''et al'',<ref name=\"luebbers90\" /> and Joseph ''et al''.<ref name=\"joseph91\" />\n|-\n| 1990–91 || FDTD modeling of antennas was introduced by Maloney ''et al'',<ref name=\"maloney90\" /> Katz ''et al'',<ref name=\"katz91\" /> and Tirkas and Balanis.<ref name=\"tirkas91\" />\n|-\n| 1990 || FDTD modeling of picosecond optoelectronic switches was introduced by Sano and Shibata,<ref name=\"sano90\" /> and El-Ghazaly ''et al''.<ref name=\"el-ghazaly90\" />\n|-\n| 1992–94 || FDTD modeling of the propagation of optical pulses in nonlinear dispersive media was introduced, including the first temporal solitons in one dimension by Goorjian and Taflove;<ref name=\"goorjian92\" />  beam self-focusing by Ziolkowski and Judkins;<ref name=\"ziolkowski93\" /> the first temporal solitons in two dimensions by Joseph ''et al'';<ref name=\"joseph93\" />  and the first spatial solitons in two dimensions by Joseph and Taflove.<ref name=\"joseph94\" />\n|-\n| 1992 || FDTD modeling of lumped electronic circuit elements was introduced by Sui ''et al''.<ref name=\"sui92\" />\n|-\n| 1993 || Toland ''et al'' published the first FDTD models of gain devices (tunnel diodes and Gunn diodes) exciting cavities and antennas.<ref name=\"toland93\" />\n|-\n| 1993 || Aoyagi ''et al'' present a hybrid Yee algorithm/scalar-wave equation and demonstrate equivalence of Yee scheme to finite difference scheme for [[electromagnetic wave equation]].<ref name=\"aoyagi93\" />\n|-\n| 1994 || Thomas ''et al'' introduced a Norton’s equivalent circuit for the FDTD space lattice, which permits the SPICE circuit analysis tool to implement accurate subgrid models of nonlinear electronic components or complete circuits embedded within the lattice.<ref name=\"thomas94\" />\n|-\n| 1994 || Berenger introduced the highly effective, perfectly matched layer (PML) ABC for two-dimensional FDTD grids,<ref name=\"berenger94\" /> which was extended to three dimensions by Katz ''et al'',<ref name=\"katz94\" />  and to dispersive waveguide terminations by Reuter ''et al''.<ref name=\"reuter94\" />\n|-\n| 1994 || Chew and Weedon introduced the coordinate stretching PML that is easily extended to three dimensions, other coordinate systems and other physical equations.<ref name=\"chewweedon94\" />\n|-\n| 1995–96 || Sacks ''et al'' and Gedney introduced a physically realizable, uniaxial perfectly matched layer (UPML) ABC.<ref name=\"gedney96\" /><ref name=\"sacks95\" />\n|-\n| 1997 || Liu introduced the pseudospectral time-domain (PSTD) method, which permits extremely coarse spatial sampling of the electromagnetic field at the Nyquist limit.<ref name=\"liu97\" />\n|-\n| 1997 || Ramahi introduced the complementary operators method (COM) to implement highly effective analytical ABCs.<ref name=\"ramahi97\" />\n|-\n| 1998 || Maloney and Kesler introduced several novel means to analyze periodic structures in the FDTD space lattice.<ref name=\"maloney98\" />\n|-\n| 1998 || Nagra and York introduced a hybrid FDTD-quantum mechanics model of electromagnetic wave interactions with materials having electrons transitioning between multiple energy levels.<ref name=\"nagra98\" />\n|-\n| 1998 || Hagness ''et al'' introduced FDTD modeling of the detection of breast cancer using ultrawideband radar techniques.<ref name=\"hagness98\" />\n|-\n| 1999 || Schneider and Wagner introduced a comprehensive analysis of FDTD grid dispersion based upon complex wavenumbers.<ref name=\"schneider99\" />\n|-\n| 2000–01 || Zheng, Chen, and Zhang introduced the first three-dimensional alternating-direction implicit (ADI) FDTD algorithm with provable unconditional numerical stability.<ref name=\"zhen00\" /><ref name=\"zheng01\" />\n|-\n| 2000 || Roden and Gedney introduced the advanced convolutional PML (CPML) ABC.<ref name=\"roden00\" />\n|-\n| 2000 || Rylander and Bondeson introduced a provably stable FDTD - finite-element time-domain hybrid technique.<ref name=\"rylander00\" />\n|-\n| 2002 || Hayakawa ''et al'' and Simpson and Taflove independently introduced FDTD modeling of the global Earth-ionosphere waveguide for extremely low-frequency geophysical phenomena.<ref name=\"hayakawa02\" /><ref name=\"simpson02\" />\n|-\n| 2003 || DeRaedt introduced the unconditionally stable, “one-step” FDTD technique.<ref name=\"de_raedt03\" />\n|-\n| 2008 || Ahmed, Chua, Li and Chen introduced the three-dimensional locally one-dimensional (LOD)FDTD method and proved unconditional numerical stability.<ref name=\"Ahmed2008\" />\n|-\n| 2008 || Taniguchi, Baba, Nagaoka and Ametani introduced a Thin Wire Representation for FDTD Computations for conductive media<ref name=\"baba08\" />\n|-\n| 2009 || Oliveira and Sobrinho applied the FDTD method for simulating lightning strokes in a power substation<ref name=\"oliveira09\" />\n|-\n| 2010 || Chaudhury and Boeuf demonstrated the numerical procedure to couple FDTD and Plasma fluid model for studying Microwave Plasma Interaction.<ref name=\"Chaudhury2010\" />\n|-\n| 2012 || Moxley ''et al'' developed a generalized finite-difference time-domain quantum method for the N-body interacting Hamiltonian.<ref name=\"Moxley2012\" />\n|-\n| 2013 || Moxley ''et al'' developed a generalized finite-difference time-domain scheme for solving nonlinear Schrödinger equations.<ref name=\"Moxley2013\" />\n|-\n| 2014 || Moxley ''et al'' developed an implicit generalized finite-difference time-domain scheme for solving nonlinear Schrödinger equations.<ref name=\"Moxley2014\" />\n|-\n|}\n\n== FDTD models and methods ==\nWhen [[Maxwell's differential equations]] are examined, it can be seen that the change in the E-field in time (the time derivative) is dependent on the change in the H-field across space (the [[curl (mathematics)|curl]]).  This results in the basic FDTD time-stepping relation that, at any point in space, the updated value of the E-field in time is dependent on the stored value of the E-field and the numerical curl of the local distribution of the H-field in space.<ref name=\"yee66\" />\n\nThe H-field is time-stepped in a similar manner. At any point in space, the updated value of the H-field in time is dependent on the stored value of the H-field and the numerical curl of the local distribution of the E-field in space. Iterating the E-field and H-field updates results in a marching-in-time process wherein sampled-data analogs of the continuous electromagnetic waves under consideration propagate in a numerical grid stored in the computer memory.\n\n[[Image:FDTD Yee grid 2d-3d.svg|thumb|right|450px|Illustration of a standard Cartesian Yee cell used for FDTD, about which electric and magnetic field vector components are distributed.<ref name=\"yee66\" /> Visualized as a cubic [[voxel]], the electric field components form the edges of the cube, and the magnetic field components form the normals to the faces of the cube. A three-dimensional space lattice consists of a multiplicity of such Yee cells. An electromagnetic wave interaction structure is mapped into the space lattice by assigning appropriate values of permittivity to each electric field component, and permeability to each magnetic field component.]]\nThis description holds true for 1-D, 2-D, and 3-D FDTD techniques. When multiple dimensions are considered, calculating the numerical curl can become complicated. Kane Yee's seminal 1966 paper proposed spatially staggering the vector components of the E-field and H-field about rectangular unit cells of a Cartesian computational grid so that each E-field vector component is located midway between a pair of H-field vector components, and conversely.<ref name=\"yee66\" />  This scheme, now known as a '''Yee lattice''', has proven to be very robust, and remains at the core of many current FDTD software constructs.\n\nFurthermore, Yee proposed a leapfrog scheme for marching in time wherein the E-field and H-field updates are staggered so that E-field updates are conducted midway during each time-step between successive H-field updates, and conversely.<ref name=\"yee66\" /> On the plus side, this explicit time-stepping scheme avoids the need to solve simultaneous equations, and furthermore yields dissipation-free numerical wave propagation. On the minus side, this scheme mandates an upper bound on the time-step to ensure numerical stability.<ref name=\"taflove75a\" /> As a result, certain classes of simulations can require many thousands of time-steps for completion.\n\n=== Using the FDTD method ===\nTo implement an FDTD solution of Maxwell's equations, a computational domain must first be established. The computational domain is simply the physical region over which the simulation will be performed. The E and H fields are determined at every point in space within that computational domain. The material of each cell within the computational domain must be specified. Typically, the material is either free-space (air), [[metal]], or [[dielectric]].  Any material can be used as long as the [[Permeability (electromagnetism)|permeability]], [[permittivity]], and [[electrical conductivity|conductivity]] are specified.\n\nThe permittivity of dispersive materials in tabular form cannot be directly substituted into the FDTD scheme.\nInstead, it can be approximated using multiple Debye, Drude, Lorentz or critical point terms.\nThis approximation can be obtained using open fitting programs<ref name=\"fitting\" /> and does not necessarily have physical meaning.\n\nOnce the computational domain and the grid materials are established, a source is specified. The source can be current on a wire,  applied electric field or impinging plane wave.\nIn the last case FDTD can be used to simulate light scattering from arbitrary shaped objects, planar periodic structures at various incident angles,<ref name=\"obl_it\" /><ref name=\"obl_sfdtd\" /> and photonic band structure of infinite periodic structures.<ref name=\"TMatrix\" /><ref name=\"Hao\" />\n\nSince the E and H fields are determined directly, the output of the simulation is usually the E or H field at a point or a series of points within the computational domain. The simulation evolves the E and H fields forward in time.\n\nProcessing may be done on the E and H fields returned by the simulation. Data processing may also occur while the simulation is ongoing.\n\nWhile the FDTD technique computes electromagnetic fields within a compact spatial region, scattered and/or radiated far fields can be obtained via near-to-far-field transformations.<ref name=\"umashankar82\" />\n\n=== Strengths of FDTD modeling ===\nEvery modeling technique has strengths and weaknesses, and the FDTD method is no different.\n\n* FDTD is a versatile modeling technique used to solve Maxwell's equations. It is intuitive, so users can easily understand how to use it and know what to expect from a given model.\n* FDTD is a time-domain technique, and when a broadband pulse (such as a Gaussian pulse) is used as the source, then the response of the system over a wide range of frequencies can be obtained with a single simulation. This is useful in applications where resonant frequencies are not exactly known, or anytime that a broadband result is desired.\n* Since FDTD calculates the E and H fields everywhere in the computational domain as they evolve in time, it lends itself to providing animated displays of the electromagnetic field movement through the model. This type of display is useful in understanding what is going on in the model, and to help ensure that the model is working correctly.\n* The FDTD technique allows the user to specify the material at all points within the computational domain. A wide variety of linear and nonlinear dielectric and magnetic materials can be naturally and easily modeled.\n* FDTD allows the effects of apertures to be determined directly. Shielding effects can be found, and the fields both inside and outside a structure can be found directly or indirectly.\n* FDTD uses the E and H fields directly. Since most EMI/EMC modeling applications are interested in the E and H fields, it is convenient that no conversions must be made after the simulation has run to get these values.\n\n=== Weaknesses of FDTD modeling===\n* Since FDTD requires that the entire computational domain be gridded, and the grid spatial discretization must be sufficiently fine to resolve both the smallest electromagnetic wavelength and the smallest geometrical feature in the model, very large computational domains can be developed, which results in very long solution times. Models with long, thin features, (like wires) are difficult to model in FDTD because of the excessively large computational domain required. Methods such as [[Eigenmode Expansion]] can offer a more efficient alternative as they do not require a fine grid along the z-direction.<ref name=\"phot_cad\" />\n* There is no way to determine unique values for permittivity and permeability at a material interface.\n* Space and time steps must satisfy the [[Courant–Friedrichs–Lewy condition|CFL condition]], or the [[leapfrog integration]] used to solve the partial differential equation is likely to become unstable.\n* FDTD finds the E/H fields directly everywhere in the computational domain. If the field values at some distance are desired, it is likely that this distance will force the computational domain to be excessively large. Far-field extensions are available for FDTD, but require some amount of postprocessing.<ref name=\"taflove05\" />\n* Since FDTD simulations calculate the E and H fields at all points within the computational domain, the computational domain must be finite to permit its residence in the computer memory. In many cases this is achieved by inserting artificial boundaries into the simulation space. Care must be taken to minimize errors introduced by such boundaries. There are a number of available highly effective absorbing boundary conditions (ABCs) to simulate an infinite unbounded computational domain.<ref name=\"taflove05\" />  Most modern FDTD implementations instead use a special absorbing \"material\", called a [[perfectly matched layer]] (PML) to implement absorbing boundaries.<ref name=\"berenger94\" /><ref name=\"gedney96\" />\n* Because FDTD is solved by propagating the fields forward in the time domain, the electromagnetic time response of the medium must be modeled explicitly.  For an arbitrary response, this involves a computationally expensive time convolution, although in most cases the time response of the medium (or [[Dispersion (optics)]]) can be adequately and simply modeled using either the recursive convolution (RC) technique, the auxiliary differential equation (ADE) technique, or the Z-transform technique. An alternative way of solving [[Maxwell's equations]] that can treat arbitrary dispersion easily is the [[Computational electrodynamics#Pseudo-spectral spatial domain .28PSSD.29|Pseudospectral Spatial-Domain method\n(PSSD)]], which instead propagates the fields forward in space.\n\n===Grid truncation techniques===\nThe most commonly used grid truncation techniques for open-region FDTD modeling problems are the Mur absorbing boundary condition (ABC),<ref name=\"mur81\" /> the Liao ABC,<ref name=\"liao84\" /> and various [[perfectly matched layer]] (PML) formulations.<ref name=\"taflove05\" /><ref name=\"berenger94\" /><ref name=\"gedney96\" /> The Mur and Liao techniques are simpler than PML. However, PML (which is technically an absorbing region rather than a boundary condition ''per se'') can provide orders-of-magnitude lower reflections. The PML concept was introduced by J.-P. Berenger in a seminal 1994 paper in the Journal of Computational Physics.<ref name=\"berenger94\" />  Since 1994, Berenger's original split-field implementation has been modified and extended to the uniaxial PML (UPML), the convolutional PML (CPML), and the higher-order PML. The latter two PML formulations have increased ability to absorb evanescent waves, and therefore can in principle be placed closer to a simulated scattering or radiating structure than Berenger's original formulation.\n\nTo reduce undesired numerical reflection from the PML additional back absorbing layers technique can be used.<ref name=\"back_pml\" />\n\n== Popularity ==\n{{Original research|section|date=August 2013}}\n\n<!-- The following text is from Computational Electrodynamics:  The\nFinite-Difference Time-Domain Method, by Taflove.  Taflove and Artech House granted permission to use this text under the CC-A-SA-3.0 license; the permission was sent by the publisher to permissions-en@wikimedia.org on 21 February 2012. -->\n\nNotwithstanding both the general increase in academic publication\nthroughput during the same period and the overall expansion of interest\nin all Computational electromagnetics (CEM)  techniques, there are\nseven primary reasons for the tremendous expansion of interest in FDTD\ncomputational solution approaches for Maxwell’s equations:\n\n# FDTD uses no linear algebra.  Being a fully explicit computation, FDTD avoids the difficulties with linear algebra that limit the size of frequency-domain integral-equation and finite-element electromagnetics models to generally fewer than 10<sup>9</sup> electromagnetic field unknowns.<ref name=\"taflove05\" /> FDTD models with as many as 10<sup>9</sup> field unknowns have been run; there is no intrinsic upper bound to this number.<ref name=\"taflove05\" />\n# FDTD is accurate and robust.  The sources of error in FDTD calculations are well understood, and can be bounded to permit accurate models for a very large variety of electromagnetic wave interaction problems.<ref name=\"taflove05\" />\n# FDTD treats impulsive behavior naturally.  Being a time-domain technique, FDTD directly calculates the impulse response of an electromagnetic system.  Therefore, a single FDTD simulation can provide either ultrawideband temporal waveforms or the sinusoidal steady-state response at any frequency within the excitation spectrum.<ref name=\"taflove05\" />\n# FDTD treats nonlinear behavior naturally.  Being a time-domain technique, FDTD directly calculates the nonlinear response of an electromagnetic system.  This allows natural hybriding of FDTD with sets of auxiliary differential equations that describe nonlinearities from either the classical or semi-classical standpoint.<ref name=\"taflove05\" />  One research frontier is the development of hybrid algorithms which join FDTD classical electrodynamics models with phenomena arising from quantum electrodynamics, especially vacuum fluctuations, such as the [[Casimir effect]].<ref name=\"taflove05\" /><ref>S. G. Johnson, \"[https://arxiv.org/abs/arXiv:1007.0966 Numerical methods for computing Casimir interactions],\" in Casimir Physics (D. Dalvit, [[P. Milonni]], D. Roberts, and F. da Rosa, eds.), vol. 834 of ''Lecture Notes in Physics'', ch. 6, pp. 175–218, Berlin: Springer, June 2011.</ref>\n# FDTD is a systematic approach. With FDTD, specifying a new structure to be modeled is reduced to a problem of mesh generation rather than the potentially complex reformulation of an integral equation.  For example, FDTD requires no calculation of structure-dependent Green functions.<ref name=\"taflove05\" />\n# Parallel-processing computer architectures have come to dominate supercomputing.  FDTD scales with high efficiency on parallel-processing CPU-based computers, and extremely well on recently developed GPU-based accelerator technology.<ref name=\"taflove05\" />\n# Computer visualization capabilities are increasing rapidly. While this trend positively influences all numerical techniques, it is of particular advantage to FDTD methods, which generate time-marched arrays of field quantities suitable for use in color videos to illustrate the field dynamics.<ref name=\"taflove05\" />\n \nTaflove has argued that these factors combine to suggest that FDTD will remain one of\nthe dominant computational electrodynamics techniques (as well as potentially other multiphysics problems).<ref name=\"taflove05\" />\n\n=== Implementations ===\nThere are hundreds of simulation tools that implement FDTD algorithms, many optimized to run on parallel-processing clusters.\n\nFrederick Moxley suggests further applications with computational quantum mechanics and simulations.<ref name=\"Moxleylecture\" />\n\n==See also==\n* [[Computational electromagnetics]]\n* [[Eigenmode expansion]]\n* [[Beam propagation method]]\n* [[Finite-difference frequency-domain]]\n* [[Finite element method]]\n* [[Scattering Matrix Method]]\n* [[Discrete dipole approximation]]\n\n==References==\n{{Reflist|3|refs=\n<ref name=\"courant1928\">\n{{cite journal\n  |author1=Richard Courant |author2=Kurt Otto Friedrichs |author3=Hans Lewy | title = Über die partiellen Differenzengleichungen der mathematischen Physik\n  | journal = [[Mathematische Annalen]]\n  | volume = 100\n  | issue = 1\n  | pages = 32–74\n  | year = 1928\n  | language = German\n  | url = http://resolver.sub.uni-goettingen.de/purl?GDZPPN002272636\n  | doi = 10.1007/BF01448839\n  | jfm = 54.0486.01\n  | mr = 1512478\n |bibcode = 1928MatAn.100...32C }}</ref>\n\n<ref name=\"obrien1950\">\n{{cite journal\n  | author = G. G. O’Brien, M. A Hyman, and S. Kaplan\n  | title = A study of the numerical solution of partial differential equations\n  | journal = Journal of Mathematical Physics\n  | volume = 29\n  | issue = 1\n  | pages = 223–251\n  | year = 1950\n  | mr = 0040805\n | doi = 10.1002/sapm1950291223\n  }}</ref>\n\n<ref name=\"Moxley2012\">\n{{cite journal\n  |author1=F. I. Moxley III |author2=T. Byrnes |author3=F. Fujiwara |author4=W. Dai | title = A generalized finite-difference time-domain quantum method for the N-body interacting Hamiltonian\n  | journal = Computer Physics Communications\n  | volume = 183\n  | issue = 11\n  | pages = 2434–2440\n  | year = 2012\n  | doi=10.1016/j.cpc.2012.06.012\n |bibcode = 2012CoPhC.183.2434M }}</ref>\n\n<ref name=\"Moxley2014\">{{cite book \n  | author=[[Frederick Moxley]] \n  | display-authors=etal \n  | title=Contemporary Mathematics: Mathematics of Continuous and Discrete Dynamical Systems \n  | publisher=American Mathematical Society \n  | year=2014 \n  | isbn=978-0-8218-9862-8 \n  | url=http://www.ams.org/bookstore-getitem?item=CONM-618}}\n</ref>\n\n<ref name=\"Moxley2013\">\n{{cite journal\n  |author1=F. I. Moxley III |author2=D. T. Chuss |author3=W. Dai | title = A generalized finite-difference time-domain scheme for solving nonlinear Schrödinger equations\n  | journal = Computer Physics Communications\n  | volume = 184\n  | issue = 8\n  | pages = 1834–1841\n  | year = 2013\n  | doi=10.1016/j.cpc.2013.03.006\n |bibcode = 2013CoPhC.184.1834M }}</ref>\n\n<ref name=\"vonneumann49\">\n{{cite journal\n  |author1=J. von Neumann |author2=RD Richtmyer | title = A method for the numerical calculation of hydrodynamic shocks\n  | journal = Journal of Applied Physics\n  | volume = 21\n  |issue=3 | pages = 232–237\n  |date=March 1950\n  \n  | doi=10.1063/1.1699639\n |bibcode = 1950JAP....21..232V }}</ref>\n\n<ref name=\"phot_cad\">\n{{cite journal\n| author= D. Gallagher\n| url=http://www.photond.com/files/docs/leos_newsletter_feb08_article.pdf\n| title=Photonics CAD Matures\n| journal=LEOS Newsletter\n| year=2008\n}}</ref>\n\n<ref name=\"Moxleylecture\">\n{{cite journal\n|author1=Hartmut Ruhl |author2=Nils Moscḧuring |author3=Nina Elkina | url=http://www.physik.uni-muenchen.de/lehre/vorlesungen/wise_12_13/tvi_mas_compphys/material/lecture9.pdf\n| title=Computational Physics Course 17104 Lecture 9\n| year=2012\n}}</ref>\n\n<ref name=\"back_pml\">\n{{cite journal\n |author1=A. Deinega |author2=I. Valuev |url=http://www.sciencedirect.com/science/article/pii/S0010465510001839\n |title=Long-time behavior of PML absorbing boundaries for layered periodic structures\n |journal=Comp. Phys. Comm.\n |volume= 182\n |issue=1 |pages= 149–151\n |year=2011\n |doi=10.1016/j.cpc.2010.06.006\n|bibcode = 2011CoPhC.182..149D }}</ref>\n\n<ref name=\"berenger94\">{{cite journal \n  | author= J. Berenger \n  | title= A perfectly matched layer for the absorption of electromagnetic waves \n  | journal= Journal of Computational Physics \n  | year= 1994 \n  | volume= 114 \n  | pages= 185–200 \n  | url=http://www.stanford.edu/class/ee256/Berenger1994.pdf \n  | doi= 10.1006/jcph.1994.1159|bibcode = 1994JCoPh.114..185B \n  | issue= 2 }}\n</ref>\n\n<ref name=\"choi86\">{{cite journal \n  |author1=D. H. Choi |author2=W. J. Hoefer | title= The finite-difference time-domain method and its application to eigenvalue problems \n  | journal= IEEE Transactions on Microwave Theory and Techniques\n  | year= 1986 \n  | volume= 34 \n  | pages= 1464–1470  \n  | doi= 10.1109/TMTT.1986.1133564|bibcode = 1986ITMTT..34.1464C \n  | issue= 12 }}  \n</ref>\n\n<ref name=\"de_raedt03\">{{cite journal \n  |author1=H. De Raedt |author2=K. Michielsen |author3=J. S. Kole |author4=M. T. Figge | title= Solving the Maxwell equations by the Chebyshev method: A one-step finite difference time-domain algorithm \n  | journal= IEEE Transactions on Antennas and Propagation \n  | year= 2003 \n  | volume= 51 \n  | pages= 3155–3160  \n  | doi=10.1109/TAP.2003.818809|arxiv = physics/0208060 |bibcode = 2003ITAP...51.3155D \n  | issue= 11 }}\n</ref>\n\n<ref name=\"el-ghazaly90\">{{cite journal \n  |author1=S. M. El-Ghazaly |author2=R. P. Joshi |author3=R. O. Grondin | title= Electromagnetic and transport considerations in subpicosecond photoconductive switch modeling \n  | journal= IEEE Transactions on Microwave Theory and Techniques \n  | year= 1990 \n  | volume= 38 \n  | pages= 629–637  \n  | doi=10.1109/22.54932|bibcode = 1990ITMTT..38..629E \n  | issue= 5 }} \n</ref>\n\n.<ref name=\"fitting\">\n{{cite web\n |url=http://fdtd.kintechlab.com/en/fitting\n |title=Fitting of dielectric function\n}}</ref>\n\n<ref name=\"gedney96\">{{cite journal \n  | author= S. D. Gedney \n  | title= An anisotropic perfectly matched layer absorbing media for the truncation of FDTD lattices \n  | journal= IEEE Transactions on Antennas and Propagation\n  | year= 1996 \n  | volume= 44 \n  | pages= 1630–1639  \n  | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=11941&arnumber=546249&count=18&index=14 \n  | doi=10.1109/8.546249|bibcode = 1996ITAP...44.1630G \n  | issue= 12 }} \n</ref>\n\n<ref name=\"goorjian92\">{{cite journal \n  |author1=P. M. Goorjian |author2=A. Taflove | title= Direct time integration of Maxwell's equations in nonlinear dispersive media for propagation and scattering of femtosecond electromagnetic solitons \n  | journal= Optics Letters \n  | year= 1992 \n  | volume= 17 \n  | pages= 180–182 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper37.pdf \n  | doi= 10.1364/OL.17.000180|bibcode = 1992OptL...17..180G \n  | issue= 3 }} \n</ref>\n\n<ref name=\"gwarek85\">{{cite journal \n  | author= W. Gwarek \n  | title= Analysis of an arbitrarily shaped planar circuit — A time-domain approach \n  | journal= IEEE Transactions on Microwave Theory and Techniques\n  | year= 1985 \n  | volume= 33 \n  | pages= 1067–1072 \n  | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=25151&arnumber=1133170&count=34&index=26 \n  | doi= 10.1109/TMTT.1985.1133170|bibcode = 1985ITMTT..33.1067G \n  | issue= 10 }}  \n</ref>\n\n<ref name=\"hagness98\">{{cite journal \n  |author1=S. C. Hagness |author2=A. Taflove |author3=J. E. Bridges | title= Two-dimensional FDTD analysis of a pulsed microwave confocal system for breast cancer detection: Fixed-focus and antenna-array sensors \n  | journal= IEEE Transactions on Biomedical Engineering\n  | year= 1998 \n  | volume= 45 \n  | pages= 1470–1479 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper66.pdf \n  | doi= 10.1109/10.730440 \n  | pmid= 9835195 \n  | issue= 12}} \n</ref>\n\n<ref name=\"Hao\">{{cite book \n  |author1=Y. Hao |author2=R. Mittra | title=FDTD Modeling of Metamaterials: Theory and Applications\n  | publisher=Artech House Publishers \n  | year=2009\n  | url=http://www.artechhouse.com/Detail.aspx?strIsbn=978-1-59693-160-2}}\n</ref>\n\n<ref name=\"hayakawa02\">{{cite journal \n  |author1=M. Hayakawa |author2=T. Otsuyama | title= FDTD analysis of ELF wave propagation in inhomogeneous subionospheric waveguide models \n  | journal= ACES Journal  \n  | year= 2002 \n  | volume= 17 \n  | pages= 239–244 \n  | url=http://handle.dtic.mil/100.2/ADP013476}}\n</ref>\n\n<ref name=\"simpson02\">{{cite journal\n |doi         = 10.1109/LAWP.2002.805123\n |author1     = J. J. Simpson\n |author2     = A. Taflove\n |title       = Two-dimensional FDTD model of antipodal ELF propagation and Schumann resonance of the Earth\n |journal     = IEEE Antennas and Wireless Propagation Letters\n |year        = 2002\n |volume      = 1\n |pages       = 53–56\n |issue       = 2\n |url         = http://www.ece.unm.edu/~simpson/Paper1.pdf\n |bibcode     = 2002IAWPL...1...53S\n |deadurl     = yes\n |archiveurl  = https://web.archive.org/web/20100617131759/http://www.ece.unm.edu/~simpson/Paper1.pdf\n |archivedate = 2010-06-17\n |df          = \n|citeseerx     = 10.1.1.694.4837\n }}\n</ref>\n\n<ref name=\"holland77\">{{cite journal \n  | author= R. Holland \n  | title= Threde: A free-field EMP coupling and scattering code \n  | journal= IEEE Transactions on Nuclear Science\n  | year= 1977 \n  | volume= 24 \n  | pages= 2416–2421  \n  | doi= 10.1109/TNS.1977.4329229|bibcode = 1977ITNS...24.2416H \n  | issue= 6 }} \n</ref>\n\n<ref name=\"joseph91\">{{cite journal \n  |author1=R. M. Joseph |author2=S. C. Hagness |author3=A. Taflove | title= Direct time integration of Maxwell's equations in linear dispersive media with absorption for scattering and propagation of femtosecond electromagnetic pulses \n  | journal= Optics Letters \n  | year= 1991 \n  | volume= 16 \n  | pages= 1412–4 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper35.pdf \n  | doi= 10.1364/OL.16.001412 \n  | pmid= 19776986 \n  | issue= 18|bibcode = 1991OptL...16.1412J }} \n</ref>\n\n<ref name=\"joseph93\">{{cite journal \n  |author1=R. M. Joseph |author2=P. M. Goorjian |author3=A. Taflove | title= Direct time integration of Maxwell's equations in 2-D dielectric waveguides for propagation and scattering of femtosecond electromagnetic solitons \n  | journal= Optics Letters \n  | year= 1993 \n  | volume= 18 \n  | pages= 491–3 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper44.pdf \n  | doi= 10.1364/OL.18.000491 \n  | pmid= 19802177 \n  | issue= 7|bibcode = 1993OptL...18..491J }} \n</ref>\n\n<ref name=\"joseph94\">{{cite journal \n  |author1=R. M. Joseph |author2=A. Taflove | title= Spatial soliton deflection mechanism indicated by FDTD Maxwell's equations modeling \n  | journal= IEEE Photonics Technology Letters\n  | year= 1994 \n  | volume= 2 \n  |issue=10 | pages= 1251–1254 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper54.pdf\n  | doi=10.1109/68.329654|bibcode = 1994IPTL....6.1251J }} \n</ref>\n\n<ref name=\"jurgens92\">{{cite journal \n  |author1=T. G. Jurgens |author2=A. Taflove |author3=K. R. Umashankar |author4=T. G. Moore | title= Finite-difference time-domain modeling of curved surfaces \n  | journal= IEEE Transactions on Antennas and Propagation \n  | year= 1992 \n  | volume= 40 \n  | pages= 357–366 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper39.pdf \n  | doi= 10.1109/8.138836|bibcode = 1992ITAP...40..357J \n  | issue= 4 }} \n</ref>\n\n<ref name=\"kashiwa90\">{{cite journal \n  |author1=T. Kashiwa |author2=I. Fukai | title= A treatment by FDTD method of dispersive characteristics associated with electronic polarization \n  | journal= [[Microwave and Optical Technology Letters]] \n  | year= 1990 \n  | volume= 3 \n  | pages= 203–205 \n  | doi= 10.1002/mop.4650030606 \n  | issue= 6}} \n</ref>\n\n<ref name=\"katz91\">{{cite journal \n  |author1=D. S. Katz |author2=A. Taflove |author3=M. J. Piket-May |author4=K. R. Umashankar | title= FDTD analysis of electromagnetic wave radiation from systems containing horn antennas \n  | journal= IEEE Transactions on Antennas and Propagation \n  | year= 1991 \n  | volume= 39 \n  | pages= 1203–1212 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper34.pdf \n  | doi= 10.1109/8.97356|bibcode = 1991ITAP...39.1203K \n  | issue= 8 }} \n</ref>\n\n<ref name=\"katz94\">{{cite journal \n  |author1=D. S. Katz |author2=E. T. Thiele |author3=A. Taflove | title= Validation and extension to three dimensions of the Berenger PML absorbing boundary condition for FDTD meshes \n  | journal= IEEE Microwave and Guided Wave Letters\n  | year= 1994 \n  | volume= 4 \n  | pages= 268–270 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper51.pdf \n  | doi= 10.1109/75.311494 \n  | issue= 8}} \n</ref>\n\n<ref name=\"kriegsmann87\">{{cite journal \n  |author1=G. A. Kriegsmann |author2=A. Taflove |author3=K. R. Umashankar | title= A new formulation of electromagnetic wave scattering using an on-surface radiation boundary condition approach \n  | journal= IEEE Transactions on Antennas and Propagation\n  | year= 1987 \n  | volume= 35 \n  | pages= 153–161 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper14.pdf \n  | doi= 10.1109/TAP.1987.1144062|bibcode = 1987ITAP...35..153K \n  | issue= 2 }} \n</ref>\n\n<ref name=\"kunz77\">{{cite journal \n  |author1=K. S. Kunz |author2=K. M. Lee | title= A three-dimensional finite-difference solution of the external response of an aircraft to a complex transient EM environment \n  | journal= IEEE Transactions on Electromagnetic Compatibility\n  | year= 1978 \n  | volume= 20 \n  | pages= 333–341 \n  | doi=10.1109/TEMC.1978.303727 \n  | issue= 2}}  \n</ref>\n\n<ref name=\"liao84\">{{cite journal \n  |author1=Z. P. Liao |author2=H. L. Wong |author3=B. P. Yang |author4=Y. F. Yuan | title= A transmitting boundary for transient wave analysis\n  | journal= Scientia Sinica, Series A \n  | year= 1984 \n  | volume= 27 \n  | pages= 1063–1076}}\n</ref>\n\n<ref name=\"liu97\">{{cite book \n  | author= Q. H. Liu \n  | title= The pseudospectral time-domain (PSTD) method:  A new algorithm for solutions of Maxwell's equations \n  | journal= IEEE Antennas and Propagation Society International Symposium Digest\n  | year= 1997 \n  | volume= 1 \n  | pages= 122–125  \n  | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=13688&arnumber=630102&count=142&index=30 \n  | doi=10.1109/APS.1997.630102 \n  | isbn= 978-0-7803-4178-4}} \n</ref>\n\n<ref name=\"luebbers90\">{{cite journal \n  |author1=R. Luebbers |author2=F. Hunsberger |author3=K. Kunz |author4=R. Standler |author5=M. Schneider | title= A frequency-dependent finite-difference time-domain formulation for dispersive materials \n  | journal= IEEE Transactions on Electromagnetic Compatibility \n  | year= 1990 \n  | volume= 32 \n  | pages= 222–227  \n  | doi=10.1109/15.57116 \n  | issue= 3}} \n</ref>\n\n<ref name=\"maloney90\">{{cite journal \n  |author1=J. G. Maloney |author2=G. S. Smith |author3=W. R. Scott Jr. | title= Accurate computation of the radiation from simple antennas using the finite-difference time-domain method \n  | journal= IEEE Transactions on Antennas and Propagation \n  | year= 1990 \n  | volume= 38 \n  | pages= 1059–1068  \n  | doi=10.1109/8.55618|bibcode = 1990ITAP...38.1059M \n  | issue= 7 }} \n</ref>\n\n<ref name=\"maloney98\">{{cite journal \n  |author1=J. G. Maloney |author2=M. P. Kesler | title= Analysis of Periodic Structures \n  | journal= Chap. 6 in Advances in Computational Electrodynamics: The Finite-Difference Time-Domain Method, A. Taflove, Ed., Artech House, Publishers \n  | year= 1998}} \n</ref>\n\n<ref name=\"moore88\">{{cite journal \n  |author1=T. G. Moore |author2=J. G. Blaschak |author3=A. Taflove |author4=G. A. Kriegsmann | title= Theory and application of radiation boundary operators \n  | journal= IEEE Transactions on Antennas and Propagation\n  | year= 1988 \n  | volume= 36 \n  | pages= 1797–1812 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper20.pdf \n  | doi= 10.1109/8.14402|bibcode = 1988ITAP...36.1797M \n  | issue= 12 }} \n</ref>\n\n<ref name=\"mur81\">{{cite journal \n  | author= G. Mur \n  | title= Absorbing boundary conditions for the finite-difference approximation of the time-domain electromagnetic field equations \n  | journal= IEEE Transactions on Electromagnetic Compatibility\n  | year= 1981 \n  | volume= 23 \n  | pages= 377–382 \n  | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=4091487&arnumber=4091495 \n  | doi= 10.1109/TEMC.1981.303970 \n  | issue= 4}}\n</ref>\n\n<ref name=\"nagra98\">{{cite journal \n  |author1=A. S. Nagra |author2=R. A. York | title= FDTD analysis of wave propagation in nonlinear absorbing and gain media \n  | journal= IEEE Transactions on Antennas and Propagation\n  | year= 1998 \n  | volume= 46 \n  | pages= 334–340  \n  | doi=10.1109/8.662652|bibcode = 1998ITAP...46..334N \n  | issue= 3 }} \n</ref>\n\n<ref name=\"obl_it\">\n{{cite journal\n |author1=I. Valuev |author2=A. Deinega |author3=S. Belousov |url=http://www.opticsinfobase.org/ol/abstract.cfm?uri=ol-33-13-1491\n |title=Iterative technique for analysis of periodic structures at oblique incidence in the finite-difference time-domain method\n |journal=Opt. Lett.\n |volume= 33\n |issue=13 |pages= 1491\n |year=2008\n |doi=10.1364/ol.33.001491\n|bibcode = 2008OptL...33.1491V }}</ref>\n\n<ref name=\"obl_sfdtd\">\n{{cite journal\n |author1=A. Aminian |author2=Y. Rahmat-Samii |title=Spectral FDTD: a novel technique for the analysis of oblique incident plane wave on periodic structures\n |journal=IEEE Transactions on Antennas and Propagation\n |volume= 54\n |issue=6 |pages= 1818–1825\n |year=2006\n |doi=10.1109/tap.2006.875484\n|bibcode = 2006ITAP...54.1818A }}</ref>\n\n<ref name=\"ramahi97\">{{cite journal \n  | author= O. M. Ramahi \n  | title= The complementary operators method in FDTD simulations \n  | journal= IEEE Antennas and Propagation Magazine\n  | year= 1997 \n  | volume= 39 \n  | pages= 33–45  \n  | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=14102&arnumber=646801&count=10&index=4 \n  | doi=10.1109/74.646801|bibcode = 1997IAPM...39...33R \n  | issue= 6 }} \n</ref>\n\n<ref name=\"reuter94\">{{cite journal \n  |author1=C. E. Reuter |author2=R. M. Joseph |author3=E. T. Thiele |author4=D. S. Katz |author5=A. Taflove | title= Ultrawideband absorbing boundary condition for termination of waveguiding structures in FDTD simulations \n  | journal= IEEE Microwave and Guided Wave Letters\n  | year= 1994 \n  | volume= 4 \n  | pages= 344–346 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper53.pdf \n  | doi= 10.1109/75.324711 \n  | issue= 10}} \n</ref>\n\n<ref name=\"chewweedon94\">{{cite journal \n  |author1=W.C. Chew |author2=W.H. Weedon | title= A 3D perfectly matched medium from modified Maxwell's equations with stretched coordinates\n  | journal= Microwave and Optical Technology Letters \n  | year= 1994 \n  | volume= 7 \n  | pages= 599–604\n  | url=\n  | doi= 10.1002/mop.4650071304\n  | issue= 13}} \n</ref>\n\n<ref name=\"roden00\">{{cite journal \n  |author1=J. A. Roden |author2=S. D. Gedney | title= Convolution PML (CPML):  An efficient FDTD implementation of the CFS-PML for arbitrary media \n  | journal= [[Microwave and Optical Technology Letters]]  \n  | year= 2000 \n  | volume= 27 \n  | pages= 334–339 \n  | url=http://www3.interscience.wiley.com/journal/73504513/abstract\n  | doi=10.1002/1098-2760(20001205)27:5<334::AID-MOP14>3.0.CO;2-A \n  | issue= 5}}{{dead link|date=February 2019|bot=medic}}{{cbignore|bot=medic}}\n</ref>\n\n<ref name=\"rylander00\">{{cite journal \n  |author1=T. Rylander |author2=A. Bondeson | title= Stable FDTD-FEM hybrid method for Maxwell's equations \n  | journal= Computer Physics Communications  \n  | year= 2000 \n  | volume= 125 \n  |issue=1–3 | pages= 75–82 \n  | url=https://www.sciencedirect.com/science/article/pii/S0010465599004634?via%3Dihub\n  | doi=10.1016/S0010-4655(99)00463-4}}\n</ref>\n\n<ref name=\"sacks95\">{{cite journal \n  |author1=Z. S. Sacks |author2=D. M. Kingsland |author3=R. Lee |author4=J. F. Lee | title= A perfectly matched anisotropic absorber for use as an absorbing boundary condition \n  | journal= IEEE Transactions on Antennas and Propagation\n  | year= 1995 \n  | volume= 43 \n  | pages= 1460–1463  \n  | url=http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10144 \n  | doi=10.1109/8.477075|bibcode = 1995ITAP...43.1460S \n  | issue= 12 }} \n</ref>\n\n<ref name=\"sano90\">{{cite journal \n  |author1=E. Sano |author2=T. Shibata | title= Fullwave analysis of picosecond photoconductive switches \n  | journal= IEEE Journal of Quantum Electronics \n  | year= 1990 \n  | volume= 26 \n  | pages= 372–377  \n  | url=http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=1701&arnumber=44970&count=26&index=24 \n  | doi=10.1109/3.44970|bibcode = 1990IJQE...26..372S \n  | issue= 2 }} \n</ref>\n\n<ref name=\"schneider99\">{{cite journal \n  |author1=J. B. Schneider |author2=C. L. Wagner | title= FDTD dispersion revisited: Faster-than-light propagation \n  | journal= IEEE Microwave and Guided Wave Letters\n  | year= 1999 \n  | volume= 9 \n  | pages= 54–56  \n  | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=16327&arnumber=755044&count=12&index=3 \n  | doi=10.1109/75.755044 \n  | issue= 2|citeseerx=10.1.1.77.9132 }} \n</ref>\n\n<ref name=\"sui92\">{{cite journal \n  |author1=W. Sui |author2=D. A. Christensen |author3=C. H. Durney | title= Extending the two-dimensional FDTD method to hybrid electromagnetic systems with active and passive lumped elements \n  | journal= IEEE Transactions on Microwave Theory and Techniques \n  | year= 1992 \n  | volume= 40 \n  | pages= 724–730  \n  | url=http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=3573&arnumber=127522&count=28&index=15 \n  | doi=10.1109/22.127522|bibcode = 1992ITMTT..40..724S \n  | issue= 4 }} \n</ref>\n\n<ref name=\"sullivan88\">{{cite journal \n  |author1=D. M. Sullivan |author2=O. P. Gandhi |author3=A. Taflove | title= Use of the finite-difference time-domain method in calculating EM absorption in man models \n  | journal= IEEE Transactions on Biomedical Engineering\n  | year= 1988 \n  | volume= 35 \n  | pages= 179–186 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper18.pdf \n  | doi= 10.1109/10.1360 \n  | pmid= 3350546 \n  | issue= 3}} \n</ref>\n\n<ref name=\"taflove75a\">{{cite journal \n  |author1=A. Taflove |author2=M. E. Brodwin | title= Numerical solution of steady-state electromagnetic scattering problems using the time-dependent Maxwell's equations \n  | journal= IEEE Transactions on Microwave Theory and Techniques\n  | year= 1975 \n  | volume= 23 \n  | pages= 623–630\n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper2.pdf \n  | doi= 10.1109/TMTT.1975.1128640 |bibcode = 1975ITMTT..23..623T \n  | issue= 8 }}\n</ref>\n\n<ref name=\"taflove75b\">{{cite journal \n  |author1=A. Taflove |author2=M. E. Brodwin | title= Computation of the electromagnetic fields and induced temperatures within a model of the microwave-irradiated human eye \n  | journal= IEEE Transactions on Microwave Theory and Techniques\n  | year= 1975 \n  | volume= 23 \n  | pages= 888–896\n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper3.pdf \n  | doi= 10.1109/TMTT.1975.1128708 |bibcode = 1975ITMTT..23..888T \n  | issue= 11 }} \n</ref>\n\n<ref name=\"taflove80\">{{cite journal \n  | author= A. Taflove \n  | title= Application of the finite-difference time-domain method to sinusoidal steady state electromagnetic penetration problems \n  | journal= IEEE Transactions on Electromagnetic Compatibility\n  | year= 1980 \n  | volume= 22 \n  | pages= 191–202\n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper7.pdf \n  | doi= 10.1109/TEMC.1980.303879 \n  | issue= 3 }}\n</ref>\n\n<ref name=\"taflove83\">{{cite journal \n  |author1=A. Taflove |author2=K. R. Umashankar | title= Radar cross section of general three-dimensional scatterers \n  | journal= IEEE Transactions on Electromagnetic Compatibility\n  | year= 1983 \n  | volume= 25 \n  | pages= 433–440 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper10.pdf \n  | doi=10.1109/TEMC.1983.304133 \n  | issue= 4 }} \n</ref>\n\n<ref name=\"taflove88\">{{cite journal \n  |author1=A. Taflove |author2=K. R. Umashankar |author3=B. Beker |author4=F. A. Harfoush |author5=K. S. Yee | title= Detailed FDTD analysis of  electromagnetic fields penetrating narrow slots and lapped joints in thick conducting screens \n  | journal= IEEE Transactions on Antennas and Propagation \n  | year= 1988 \n  | volume= 36 \n  | pages= 247–257 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper17.pdf \n  | doi= 10.1109/8.1102|bibcode = 1988ITAP...36..247T \n  | issue= 2 }} \n</ref>\n\n<ref name=\"taflove05\">{{cite book \n  | author=[[Allen Taflove]] and Susan C. Hagness \n  | title=Computational Electrodynamics: The Finite-Difference Time-Domain Method, 3rd ed. \n  | publisher=Artech House Publishers \n  | year=2005 \n  | isbn=978-1-58053-832-9 \n  | url=http://www.artechhouse.com/Detail.aspx?strBookId=1123}}\n</ref>\n\n<ref name=\"thomas94\">{{cite journal \n  |author1=V. A. Thomas |author2=M. E. Jones |author3=M. J. Piket-May |author4=A. Taflove |author5=E. Harrigan | title= The use of SPICE lumped circuits as sub-grid models for FDTD high-speed electronic circuit design \n  | journal= IEEE Microwave and Guided Wave Letters\n  | year= 1994 \n  | volume= 4 \n  |issue=5 | pages= 141–143 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper49.pdf\n  | doi=10.1109/75.289516}} \n</ref>\n\n<ref name=\"tirkas91\">{{cite book \n  |author1=P. A. Tirkas |author2=C. A. Balanis | title= Finite-difference time-domain technique for radiation by horn antennas \n  | journal= IEEE Antennas and Propagation Society International Symposium Digest \n  | year= 1991 \n  | volume= 3 \n  | pages= 1750–1753  \n  | url=http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=4455&arnumber=175196&count=464&index=429 \n  | doi=10.1109/APS.1991.175196 \n  | isbn= 978-0-7803-0144-3}} \n</ref>\n\n<ref name=\"TMatrix\">\n{{cite journal\n |author1=A. Deinega |author2=S. Belousov |author3=I. Valuev |url=http://www.opticsinfobase.org/ol/abstract.cfm?uri=ol-34-6-860\n |title=Hybrid transfer-matrix FDTD method for layered periodic structures\n |journal=Opt. Lett. \n |volume= 34\n |issue=6 |pages= 860\n |year=2009\n |doi=10.1364/ol.34.000860\n|bibcode = 2009OptL...34..860D }}</ref>\n\n<ref name=\"toland93\">{{cite journal \n  |author1=B. Toland |author2=B. Houshmand |author3=T. Itoh | title= Modeling of nonlinear active regions with the FDTD method \n  | journal= IEEE Microwave and Guided Wave Letters \n  | year= 1993 \n  | volume= 3 \n  | pages= 333–335  \n  | url=http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=6289&arnumber=244870&count=17&index=14 \n  | doi=10.1109/75.244870 \n  | issue= 9}} \n</ref>\n\n<ref name=\"umashankar82\">{{cite journal \n  |author1=K. R. Umashankar |author2=A. Taflove | title= A novel method to analyze electromagnetic scattering of complex objects \n  | journal= IEEE Transactions on Electromagnetic Compatibility\n  | year= 1982 \n  | volume= 24 \n  | pages= 397–405\n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper9.pdf \n  | doi= 10.1109/TEMC.1982.304054 \n  | issue= 4 }}\n</ref>\n\n<ref name=\"umashankar87\">{{cite journal \n  |author1=K. R. Umashankar |author2=A. Taflove |author3=B. Beker | title= Calculation and experimental validation of induced currents on coupled wires in an arbitrary shaped cavity \n  | journal= IEEE Transactions on Antennas and Propagation \n  | year= 1987 \n  | volume= 35 \n  | pages= 1248–1257 \n  | url=http://www.ece.northwestern.edu/ecefaculty/taflove/Paper16.pdf \n  | doi= 10.1109/TAP.1987.1144000|bibcode = 1987ITAP...35.1248U \n  | issue= 11 }} \n</ref>\n\n<ref name=\"yee66\">{{cite journal \n  | author= Kane Yee \n  | title= Numerical solution of initial boundary value problems involving Maxwell's equations in isotropic media \n  | journal= IEEE Transactions on Antennas and Propagation\n  | year= 1966 \n  | volume= 14 \n  | pages= 302–307 \n  | doi= 10.1109/TAP.1966.1138693 \n  | format= |bibcode = 1966ITAP...14..302Y \n  | issue= 3 }}\n</ref>\n\n<ref name=\"lam69\">{{cite journal \n  | author= Dong-Hoa Lam\n  | title= Finite Difference Methods for Electromagnetic Scattering Problems\n  | journal= Mississippi State University, Interaction Notes\n  | volume= 44 \n  | year= 1969 }}\n</ref>\n\n<ref name=\"zhang88\">{{cite journal \n  |author1=X. Zhang |author2=J. Fang |author3=K. K. Mei |author4=Y. Liu | title= Calculation of the dispersive characteristics of microstrips by the time-domain finite-difference method \n  | journal= IEEE Transactions on Microwave Theory and Techniques\n  | year= 1988 \n  | volume= 36 \n  | pages= 263–267  \n  | url=http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=197&arnumber=3514&count=27&index=6 \n  | doi=10.1109/22.3514|bibcode = 1988ITMTT..36..263Z \n  | issue= 2 }}  \n</ref>\n\n<ref name=\"zhen00\">{{cite journal \n  |author1=F. Zhen |author2=Z. Chen |author3=J. Zhang | title= Toward the development of a three-dimensional unconditionally stable finite-difference time-domain method \n  | journal= IEEE Transactions on Microwave Theory and Techniques  \n  | year= 2000 \n  | volume= 48 \n  | pages= 1550–1558  \n  | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=18818&arnumber=869007&count=27&index=17 \n  | doi=10.1109/22.869007|bibcode = 2000ITMTT..48.1550Z \n  | issue= 9 }}\n</ref>\n\n<ref name=\"Chaudhury2010\">{{cite journal \n  |author1=B. Chaudhury |author2=J. P. Boeuf | title= Computational Studies of Filamentary Pattern Formation in a High Power Microwave Breakdown Generated Air Plasma\n  | journal= IEEE Transactions on Plasma Science\n  | year= 2010 \n  | volume= 38 \n  | pages= 2281–2288 \n  | url=http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5524004&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5524004\n  | doi= 10.1109/TPS.2010.2055893| issue= 9 |bibcode = 2010ITPS...38.2281C }} \n</ref>\n\n<ref name=\"zheng01\">{{cite journal \n  |author1=F. Zheng |author2=Z. Chen | title= Numerical dispersion analysis of the unconditionally stable 3-D ADI-FDTD method \n  | journal= IEEE Transactions on Microwave Theory and Techniques  \n  | year= 2001 \n  | volume= 49 \n  | pages= 1006–1009  \n  | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?isnumber=19889&arnumber=920165&count=26&index=25 \n  | doi=10.1109/22.920165|bibcode = 2001ITMTT..49.1006Z \n  | issue= 5 }}\n</ref>\n\n<ref name=\"ziolkowski93\">{{cite journal \n  |author1=R. W. Ziolkowski |author2=J. B. Judkins | title= Full-wave vector Maxwell's equations modeling of self-focusing of ultra-short optical pulses in a nonlinear Kerr medium exhibiting a finite response time \n  | journal= Journal of the Optical Society of America B\n  | year= 1993 \n  | volume= 10 \n  | pages= 186–198 \n  | doi= 10.1364/JOSAB.10.000186|bibcode = 1993JOSAB..10..186Z \n  | issue= 2 }} \n</ref>\n\n<ref name=\"Ahmed2008\">{{cite journal \n  |author1=I. Ahmed |author2=E. K. Chua |author3=E. P. Li |author4=Z. Chen | title= Development of the three-dimensional unconditionally stable LOD-FDTD method\n  | journal= IEEE Transactions on Antennas and Propagation\n  | year= 2008 \n  | volume= 56 \n  | pages= 3596–3600 \n  | url=http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4685909\n  | doi= 10.1109/TAP.2008.2005544|bibcode = 2008ITAP...56.3596A \n  | issue= 11 }} \n</ref>\n\n<ref name=\"aoyagi93\">{{cite journal \n  | title=A hybrid Yee algorithm/scalar-wave equation approach\n  | journal=IEEE Transactions on Microwave Theory and Techniques\n  |author=Aoyagi, P.H. |author2=Lee, J.F. |author3=Mittra, R.\n  | volume=41\n  | number=9\n  | pages=1593–1600\n  | year=1993\n  |bibcode = 1993ITMTT..41.1593A |doi = 10.1109/22.245683 }} \n</ref>\n\n<ref name=\"oliveira09\">{{cite journal \n  | title=Computational Environment for Simulating Lightning Strokes in a Power Substation by Finite-Difference Time-Domain Method\n  |author=R. M. S. de Oliveira |author2=C. L. S. S. Sobrinho\n  | journal=IEEE Transactions on Electromagnetic Compatibility\n  | volume=51\n  | issue=4\n  | pages=995–1000\n  | year=2009\n  | doi = 10.1109/TEMC.2009.2028879 }} \n</ref>\n\n<ref name=\"baba08\">{{cite journal \n  | title=An Improved Thin Wire Representation for FDTD Computations\n  |author= Taniguchi, Y. |author2=Baba, Y.  |author3=N. Nagaoka |author4=A. Ametani\n  | journal=IEEE Transactions on Antennas and Propagation\n  | volume=56\n  | number=10\n  | pages=3248–3252\n  | year=2008\n  | doi = 10.1109/TAP.2008.929447 |bibcode = 2008ITAP...56.3248T }}\n</ref>\n\n}}\n\n=== Further reading ===\n{{Refbegin}}\nThe following article in ''Nature Milestones: Photons'' illustrates the historical significance of the FDTD method as related to Maxwell's equations:\n*{{cite journal\n  | url=http://www.nature.com/milestones/milephotons/full/milephotons02.html\n  | journal=Nature Milestones: Photons \n  | title=Milestone 2 (1861) Maxwell's equations\n  | author=David Pile\n  |date=May 2010\n  | doi=10.1038/nmat2639\n  | accessdate=17 June 2010\n}}\n\nAllen Taflove's interview, \"Numerical Solution,\" in the January 2015 focus issue of ''Nature Photonics'' honoring the 150th anniversary of the publication of Maxwell's equations.  This interview touches on how the development of FDTD ties into the century and one-half history of Maxwell's theory of electrodynamics:\n*[http://www.nature.com/nphoton/focus/maxwell-anniversary/index.html ''Nature Photonics interview'']\n\nThe following university-level textbooks provide a good general introduction to the FDTD method:\n\n*{{cite book \n  |author=Karl S. Kunz |author2=[[Raymond Luebbers|Raymond J. Luebbers]] \n  | title=The Finite Difference Time Domain Method for Electromagnetics \n  | publisher=CRC Press \n  | year=1993 \n  | isbn=978-0-8493-8657-2 \n  | url=http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=8657&af=W1129 \n  | access-date=2006-08-05 \n  | archive-url=https://web.archive.org/web/20071210045441/http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=8657&af=W1129 \n  | archive-date=2007-12-10 \n  | dead-url=yes \n  | df= \n  }}\n \n*{{cite book\n  |author=[[Allen Taflove]] |author2=Susan C. Hagness \n  | title=Computational Electrodynamics: The Finite-Difference Time-Domain Method, 3rd ed. \n  | publisher=Artech House Publishers \n  | year=2005 \n  | isbn=978-1-58053-832-9 \n  | url=http://www.artechhouse.com/Detail.aspx?strBookId=1123}}\n\n*{{cite book\n  |author1=Wenhua Yu |author2=Raj Mittra |author3=Tao Su |author4=Yongjun Liu |author5=Xiaoling Yang | title=Parallel Finite-Difference Time-Domain Method \n  | publisher=Artech House Publishers \n  | year=2006 \n  | isbn=978-1-59693-085-8\n  | url=http://www.artechhouse.com/default.asp?frame=book.asp&book=1-59693-085-3&Country=US&Continent=NO&State=}}\n\n*{{cite book\n  | author=John B. Schneider \n  | title=Understanding the FDTD Method\n  | publisher=available online\n  | year=2010\n  | url=http://www.eecs.wsu.edu/~schneidj/ufdtd/index.php}}\n{{Refend}}\n* [http://emlab.utep.edu/pdfs/Poster_FDTD.pdf EM Lab Poster on FDTD]\n* [http://emlab.utep.edu/ee5390fdtd.htm Course Notes on Introduction to FDTD]\n\n=== External links ===\n[[Free software]]/[[Open-source software]] FDTD projects:\n* [http://www.fdtdxx.com FDTD++]: advanced, fully featured FDTD software, with included C++ source code, along with sophisticated material models and predefined fits as well as discussion/support forums and email support\n* [http://openEMS.de openEMS] (Fully 3D Cartesian & Cylindrical graded mesh EC-FDTD Solver, written in C++, using a [[Matlab]]/[[GNU Octave|Octave]]-Interface)\n* [https://web.archive.org/web/20110517102321/http://www.its.caltech.edu/~seheon/FDTD.html pFDTD] (3D C++ FDTD codes developed by Se-Heon Kim)\n* [https://web.archive.org/web/20090626051810/http://www.thecomputationalphysicist.com/ JFDTD] (2D/3D C++ FDTD codes developed for nanophotonics by Jeffrey M. McMahon)\n* [http://www.ece.ncsu.edu/oleg/wiki/WOLFSIM WOLFSIM] (NCSU) (2-D)\n* [http://ab-initio.mit.edu/meep/ Meep] ([[Massachusetts Institute of Technology|MIT]], 2D/3D/cylindrical parallel FDTD)\n* [http://freshmeat.net/projects/radarfdtd/ (Geo-) Radar FDTD]\n* [http://sourceforge.net/projects/bigboy bigboy] (unmaintained, no release files. must get source from cvs)\n* [http://www.cemtach.com/reference/software/toyFDTD/ toyFDTD]\n* [http://sourceforge.net/projects/pfdtd/files/ Parallel (MPI&OpenMP) FDTD codes in C++] (developed by Zs. Szabó)\n* [https://archive.today/20121217222254/http://cs.tu-berlin.de/~peutetre/sfdtd/ FDTD code in Fortran 90]\n* [http://code.google.com/p/emwave2d/ FDTD code in C for 2D EM Wave simulation]\n* [http://angorafdtd.org Angora] (3D parallel FDTD software package, maintained by Ilker R. Capoglu)\n* [http://gsvit.net/ GSvit] (3D FDTD solver with graphics card computing support, written in C, graphical user interface XSvit available)\n*[http://www.gprmax.com gprMax] (Open Source (GPLv3), 3D/2D FDTD modelling code in Python/Cython developed for GPR but can be used for general EM modelling.)\n[[Freeware]]/[[Closed source]] FDTD projects (some not for commercial use):\n* [http://fdtd.kintechlab.com/en/start EMTL (Electromagnetic Template Library)] (Free С++ library for electromagnetic simulations. The current version implements mainly the FDTD).\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Finite-Difference Time-Domain Method}}\n[[Category:Numerical software]]\n[[Category:Simulation software]]\n[[Category:Electromagnetic radiation]]\n[[Category:Numerical differential equations]]\n[[Category:Computational science]]\n[[Category:Computational electromagnetics]]\n[[Category:Electromagnetism]]\n[[Category:Electrodynamics]]\n[[Category:Scattering, absorption and radiative transfer (optics)]]"
    },
    {
      "title": "Five-point stencil",
      "url": "https://en.wikipedia.org/wiki/Five-point_stencil",
      "text": "[[Image:Five point stencil illustration.png|right|thumb|An illustration of the five-point stencil in one and two dimensions (top, and bottom, respectively).]]\nIn [[numerical analysis]], given a [[square grid]] in one or two dimensions, the '''five-point stencil''' of a point in the grid is a [[Stencil (numerical analysis)|stencil]] made up of the point itself together with its four \"neighbors\". It is used to write [[finite difference]] approximations to [[derivative]]s at grid points. It is an example for [[numerical differentiation]].\n\n== One dimension ==\n\nIn one dimension, if the spacing between points in the grid is ''h'', then the five-point stencil of a point ''x'' in the grid is\n\n:<math>\\ \\{x-2h, x-h, x, x+h, x+2h\\}.</math>\n\n=== First derivative<ref>{{Cite book|title=Numerical Analysis|last=Sauer|first=Timothy|publisher=Pearson|year=2012|isbn=978-0-321-78367-7|location=|pages=250}}</ref>===\nThe first derivative of a [[function (mathematics)|function]] &fnof; of a [[real number|real]] variable at a point ''x'' can be approximated using a five-point stencil as\n\n:<math>f'(x) \\approx \\frac{-f(x+2 h)+8 f(x+h)-8 f(x-h)+f(x-2h)}{12 h}</math>\n\n==== Obtaining the formula ====\nThis formula can be obtained by writing out the four [[Taylor series]] of &fnof;(''x''&nbsp;±&nbsp;''h'') and &fnof;(''x''&nbsp;±&nbsp;2''h'') up to terms of ''h''<sup>&nbsp;3</sup> (or up to terms of ''h''<sup>&nbsp;5</sup> to get an error estimation as well) and solving this system of four equations to get &fnof;<sup>&nbsp;&prime;</sup>(''x''). Actually, we have at points ''x''&nbsp;+&nbsp;''h'' and ''x''&nbsp;&minus;&nbsp;''h'':\n\n:<math>f(x \\pm h) = f(x) \\pm h f'(x) + \\frac{h^2}{2}f''(x) \\pm \\frac{h^3}{6} f^{(3)}(x) + O_{1\\pm}(h^4). \\qquad (E_{1\\pm}).</math>\n\nEvaluating <math>(E_{1+})-(E_{1-})</math> gives us\n\n:<math>f(x+h) - f(x-h) = 2hf'(x) + \\frac{h^3}{3}f^{(3)}(x) + O_1(h^4). \\qquad (E_1).</math>\n\nNote that the residual term O<sub>1</sub>(''h''<sup>&nbsp;4</sup>) should be of the order of ''h''<sup>&nbsp;5</sup> instead of ''h''<sup>&nbsp;4</sup> because if the terms of ''h''<sup>&nbsp;4</sup> had been written out in (''E''<sub>&nbsp;1+</sub>) and (''E''<sub>&nbsp;1&minus;</sub>), it can be seen that they would have canceled each other out by &fnof;(''x''&nbsp;+&nbsp;''h'')&nbsp;&minus;&nbsp;&fnof;(''x''&nbsp;&minus;&nbsp;''h'').  But for this calculation, it is left like that since the order of error estimation is not treated here (cf below).\n\nSimilarly, we have\n\n:<math>f(x \\pm 2h) = f(x) \\pm 2h f'(x) + \\frac{4h^2}{2!} f''(x) \\pm \\frac{8h^3}{3!} f^{(3)}(x) + O_{2\\pm}(h^4). \\qquad (E_{2\\pm})</math>\n\nand <math>(E_{2+})-(E_{2-})</math> gives us\n\n:<math>f(x+2h) - f(x-2h) = 4hf'(x) + \\frac{8h^3}{3}f^{(3)}(x) + O_2(h^4). \\qquad (E_2).</math>\n\nIn order to eliminate the terms of &fnof;<sup>&nbsp;(3)</sup>(''x''), calculate 8&nbsp;&times;&nbsp;(''E''<sub>1</sub>)&nbsp;&minus;&nbsp;(''E''<sub>2</sub>)\n\n:<math>8f(x+h) - 8f(x-h) - f(x+2h) + f(x-2h) = 12h f'(x) + O(h^4) \\,</math>\n\nthus giving the formula as above. Note: the coefficients of f in this formula, (8, -8,-1,1), represent a specific example of the more general [[Savitzky-Golay filter]]\n\n==== Estimated error ====\nThe error in this approximation is of [[Landau notation|order]] ''h''<sup>&nbsp;4</sup>. That can be seen from the expansion\n\n:<math> \\frac{-f(x+2 h)+8 f(x+h)-8 f(x-h)+f(x-2h)}{12 h}=f'(x)-\\frac{1}{30} f^{(5)}(x) h^4+O(h^5)</math> <ref name=\"as252\">Abramowitz & Stegun, Table 25.2</ref>\n\nwhich can be obtained by expanding the left-hand side in a [[Taylor series]]. Alternatively, apply [[Richardson extrapolation]] to the [[central difference]] approximation to <math>f'(x)</math> on grids with spacing 2''h'' and ''h''.\n\n=== Higher derivatives ===\nThe centered difference formulas for five-point stencils approximating second, third, and fourth derivatives are\n\n:<math> \n  f''(x)     \\approx \\frac{-f(x+2 h)+16 f(x+h)-30 f(x) + 16 f(x-h) - f(x-2h)}{12 h^2}\n </math> \n:<math> \n f^{(3)}(x) \\approx \\frac{f(x+2 h)-2 f(x+h) + 2 f(x-h) - f(x-2h)}{2 h^3}\n </math> \n:<math> \n  f^{(4)}(x) \\approx \\frac{f(x+2 h)-4 f(x+h)+6 f(x) - 4 f(x-h) + f(x-2h)}{h^4}\n </math>\n\n==== Estimated errors ====\nThe errors in these approximations are ''O''(''h''<sup>&nbsp;4</sup>), ''O''(''h''<sup>&nbsp;2</sup>) and ''O''(''h''<sup>&nbsp;2</sup>) respectively.<ref name=\"as252\"/>\n\n== Relationship to Lagrange interpolating polynomials ==\n\nAs an alternative to deriving the finite difference weights from the Taylor series, they may be obtained by differentiating the [[Lagrange polynomial]]s\n\n:<math>\\ell_j(\\xi) = \\prod_{i=0,\\, i\\neq j}^{k} \\frac{\\xi-x_i}{x_j-x_i}, </math>\n\nwhere the interpolation points are\n\n:<math> \nx_0=x-2h,\\quad x_1=x-h,\\quad x_2=x,\\quad x_3=x+h,\\quad x_4=x+2h.\n</math>\n\nThen, the quartic polynomial <math>p_4(x)</math> interpolating &fnof;(''x'') at these five points is\n\n:<math>\np_4(x) = \\sum\\limits_{j=0}^4 f(x_j) \\ell_j(x)\n</math>\n\nand its derivative is\n\n:<math> \n p_4'(x) = \\sum\\limits_{j=0}^4 f(x_j) \\ell'_j(x).\n </math>\n\nSo, the finite difference approximation of &fnof;<sup>&nbsp;&prime;</sup>(''x'') at the middle point ''x''&nbsp;=&nbsp;''x''<sub>2</sub> is\n\n:<math> \nf'(x_2) = \\ell_0'(x_2) f(x_0) + \\ell_1'(x_2) f(x_1) + \\ell_2'(x_2) f(x_2)  + \\ell_3'(x_2) f(x_3) + \\ell_4'(x_2) f(x_4) + O(h^4)  \n</math>\n\nEvaluating the derivatives of the five Lagrange polynomials at ''x''=''x''<sub>2</sub> gives the same weights as above. This method can be more flexible as the extension to a non-uniform grid is quite straightforward.\n\n== Two dimensions ==\n\nIn two dimensions, if for example the size of the squares in the grid is ''h'' by ''h'', the five point stencil of a point (''x'',&nbsp;''y'') in the grid is\n\n:<math>\\{(x-h, y), (x, y), (x+h, y), (x, y-h), (x, y+h)\\}, \\,</math>\nforming a pattern that is also called a [[quincunx]]. This stencil is often used to approximate the [[Laplacian]] of a function of two variables:\n\n:<math> \\Delta f(x,y) \\approx \\frac{f(x-h,y) + f(x+h,y) + f(x,y-h) + f(x,y+h) - 4f(x,y)}{h^2}. </math>\n\nThe error in this approximation is ''O''(''h''<sup>&nbsp;2</sup>),<ref>Abramowitz & Stegun, 25.3.30</ref> which may be explained as follows:\n\nFrom the 3 point stencils for the second derivative of a function with respect to x and y:\n\n<math>\\begin{array} {l}\n\\frac{\\partial ^2 f}{\\partial x^2}=\n\\frac{f\\left(x + \\Delta x,y\\right) + f\\left(x - \\Delta x,y\\right) - 2f(x,y)}{\\Delta x^2} - 2\\frac{f^{(4)}(x,y)}{4!}\\Delta x^2 + \\cdots\n\\end{array}</math>\n\n<math>\\begin{array} {l}\n\\frac{\\partial ^2 f}{\\partial y^2}=\n\\frac{f\\left(x, y + \\Delta y\\right) + f\\left(x, y - \\Delta y\\right) - 2f(x,y)}{\\Delta y^2} - 2\\frac{f^{(4)}(x,y)}{4!}\\Delta y^2 + \\cdots\n\\end{array}</math>\n\nIf we assume <math>\\Delta x=\\Delta y=h</math>:\n\n<math>\\begin{array} {ll}\n\\nabla^2 f &= \\frac{\\partial ^2 f}{\\partial x^2}+\\frac{\\partial ^2 f}{\\partial y^2}\\\\\n &= \\frac{f\\left(x + h,y\\right) + f\\left(x - h,y\\right) + f\\left(x, y + h\\right) + f\\left(x, y - h\\right) - 4f(x,y)}{h^2} - 4\\frac{f^{(4)}(x,y)}{4!}h^2 + \\cdots\\\\\n &= \\frac{f\\left(x + h,y\\right) + f\\left(x - h,y\\right) + f\\left(x, y + h\\right) + f\\left(x, y - h\\right) - 4f(x,y)}{h^2} + O\\left(h^2\\right)\\\\\n\\end{array}</math>\n\n==See also==\n* [[Stencil jumping]]\n* [[Finite difference coefficients]]\n\n== References ==\n{{Reflist}}\n* {{citation | first1=Milton | last1=Abramowitz | author1-link=Milton Abramowitz | first2=Irene A. | last2=Stegun | author2-link=Irene Stegun | year=1970 | title=[[Abramowitz and Stegun|Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables]] | publisher=Dover }}. Ninth printing. Table 25.2.\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Flux limiter",
      "url": "https://en.wikipedia.org/wiki/Flux_limiter",
      "text": "'''Flux limiters''' are used in [[high resolution scheme]]s – numerical schemes used to solve problems in science and engineering, particularly [[fluid dynamics]], described by [[partial differential equations]] (PDE's). They are used in high resolution schemes, such as the [[MUSCL scheme]], to avoid the spurious oscillations (wiggles) that would otherwise occur with high order spatial discretization schemes due to shocks, discontinuities or sharp changes in the solution domain. Use of flux limiters, together with an appropriate high resolution scheme, make the solutions [[total variation diminishing]] (TVD).\n\nNote that flux limiters are also referred to as '''slope limiters''' because they both have the same mathematical form, and both have the effect of limiting the solution gradient near shocks or discontinuities. In general, the term flux limiter is used when the limiter acts on system ''[[flux]]es'', and slope limiter is used when the limiter acts on system ''states'' (like pressure, velocity etc.).\n\n==How they work==\nThe main idea behind the construction of flux limiter schemes is to limit the spatial derivatives to realistic values – for scientific and engineering problems this usually means physically realisable and meaningful values. They are used in [[high resolution scheme]]s for solving problems described by PDEs and only come into operation when sharp wave fronts are present. For smoothly changing waves, the flux limiters do not operate and the spatial derivatives can be represented by higher order approximations without introducing spurious oscillations. Consider the 1D [[semi-discrete scheme]] below,\n\n:<math>\\frac{d u_i}{d t} + \\frac{1}{\\Delta x_i} \\left[ \nF \\left( u_{i + \\frac{1}{2}} \\right) - F \\left( u_{i - \\frac{1}{2}} \\right)  \\right] =0, </math>\n\nwhere, <math> F \\left( u_{i + \\frac{1}{2}} \\right) \\ </math> and <math> F \\left( u_{i - \\frac{1}{2}} \\right) \\ </math> represent edge fluxes for the ''ith'' cell. If these edge fluxes can be represented by ''low'' and ''high'' resolution schemes, then a flux limiter can switch between these schemes depending upon the gradients close to the particular cell, as follows,\n\n:<math>F \\left( u_{i + \\frac{1}{2}} \\right) = f^{low}_{i + \\frac{1}{2}}  - \\phi\\left( r_i \\right) \\left( f^{low}_{i + \\frac{1}{2}}  - f^{high}_{i + \\frac{1}{2}}  \\right)</math>,\n:<math>F \\left( u_{i - \\frac{1}{2}} \\right) = f^{low}_{i - \\frac{1}{2}}  - \\phi\\left( r_{i-1} \\right) \\left( f^{low}_{i - \\frac{1}{2}}  - f^{high}_{i - \\frac{1}{2}}  \\right) </math>,\n\nwhere\n\n:<math>f^{low} = \\ </math>low precision, high resolution flux,\n:<math>f^{high} = \\ </math>high precision, low resolution flux,\n:<math>\\phi\\ (r) = \\ </math> flux limiter function,\n\nand <math> r\\ </math> represents the ratio of successive gradients on the solution mesh, i.e.,\n\n:<math> r_{i} = \\frac{u_{i} - u_{i-1}}{u_{i+1} - u_{i}} </math>.\n\nThe limiter function is constrained to be greater than or equal to zero, i.e., <math>\\phi\\ (r) \\ge 0 </math>. Therefore, when the limiter is equal to zero (sharp gradient, opposite slopes or zero gradient), the flux is represented by a ''low resolution scheme''. Similarly, when the limiter is equal to 1 (smooth solution), it is represented by a ''high resolution scheme''. The various limiters have differing switching characteristics and are selected according to the particular problem and solution scheme. No particular limiter has been found to work well for all problems, and a particular choice is usually made on a trial and error basis.\n\n==Limiter functions==\n\nThe following are common forms of flux/slope limiter function, <math> \\phi\\ (r) </math>:\n\n'''CHARM''' [not 2nd order TVD] (Zhou, 1995)\n\n:<math> \n\\phi_{cm}(r)=\\left\\{ \\begin{array}{ll}\n\\frac{r\\left(3r+1\\right)}{\\left(r+1\\right)^{2}}, \\quad r>0, \\quad\\lim_{r\\rightarrow\\infty}\\phi_{cm}(r)=3 \\\\\n0 \\quad \\quad\\, , \\quad r\\le 0\n\\end{array}\\right.\n</math>\n\n'''HCUS''' [not 2nd order TVD] (Waterson & Deconinck, 1995)\n\n:<math>  \\phi_{hc}(r) =  \\frac{ 1.5 \\left(r+\\left| r \\right| \\right)}{ \\left(r+2 \\right)} ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{hc}(r) = 3</math>.\n\n'''HQUICK''' [not 2nd order TVD] (Waterson & Deconinck, 1995)\n\n:<math>  \\phi_{hq}(r) =  \\frac{2 \\left(r + \\left|r \\right| \\right)}{ \\left(r+3 \\right)} ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{hq}(r) = 4</math>.\n\n'''Koren''' (Koren, 1993) – third-order accurate for sufficiently smooth data<ref>{{Citation | first=D. |last=Kuzmin |title=On the design of general-purpose flux limiters for implicit FEM with a consistent mass matrix. I. Scalar convection |journal=Journal of Computational Physics |volume=219 |issue=2 |year=2006 |pages=513–531 |doi=10.1016/j.jcp.2006.03.034 |bibcode = 2006JCoPh.219..513K }}</ref>\n<!-- Please, double-check before changing (2 + r) / 3 to (1 + 2r) / 3. See talk page or ref article -->\n\n:<math>  \\phi_{kn}(r) = \\max \\left[ 0, \\min \\left(2 r, \\min \\left( \\dfrac{(1 + 2 r)}{3}, 2 \\right) \\right) \\right]; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{kn}(r) = 2</math>.\n\n'''minmod''' – symmetric ([[Philip L. Roe|Roe]], 1986)\n\n:<math> \\phi_{mm} (r) = \\max \\left[ 0 , \\min \\left( 1 , r \\right) \\right] ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{mm}(r) = 1</math>.\n\n'''monotonized central (MC)''' – symmetric (van Leer, 1977)\n\n:<math> \\phi_{mc} (r) = \\max \\left[ 0 , \\min \\left( 2 r, 0.5 (1+r), 2 \\right) \\right]  ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{mc}(r) = 2</math>.\n\n'''Osher''' (Chakravarthy and [[Stanley Osher|Osher]], 1983)\n\n:<math> \\phi_{os} (r) = \\max \\left[ 0 , \\min \\left( r, \\beta \\right) \\right], \\quad \\left(1 \\leq \\beta \\leq 2 \\right) ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{os} (r) = \\beta</math>.\n\n'''ospre''' – symmetric (Waterson & Deconinck, 1995)\n\n:<math> \\phi_{op} (r) = \\frac{1.5 \\left(r^2 + r  \\right) }{\\left(r^2 + r +1 \\right)}  ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{op} (r) = 1.5</math>.\n\n'''smart''' [not 2nd order TVD] (Gaskell & Lau, 1988)\n\n:<math>  \\phi_{sm}(r) = \\max \\left[ 0, \\min \\left(2 r, \\left(0.25 + 0.75 r \\right), 4 \\right)  \\right] ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{sm}(r) = 4</math>.\n\n'''superbee''' – symmetric (Roe, 1986)\n\n:<math> \\phi_{sb} (r) = \\max \\left[ 0, \\min \\left( 2 r , 1 \\right), \\min \\left( r, 2 \\right) \\right]  ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{sb} (r) = 2</math>.\n\n'''Sweby''' – symmetric (Sweby, 1984)\n\n:<math> \\phi_{sw} (r) = \\max \\left[ 0 , \\min \\left( \\beta r, 1 \\right), \\min \\left( r, \\beta \\right) \\right],  \\quad    \\left(1 \\leq \\beta \\leq 2 \\right) ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{sw} (r) = \\beta</math>.\n\n'''UMIST''' (Lien & Leschziner, 1994)\n\n:<math>  \\phi_{um}(r) = \\max \\left[ 0, \\min \\left(2 r, \\left(0.25 + 0.75 r \\right),  \\left(0.75 + 0.25 r \\right), 2 \\right)  \\right]  ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{um}(r) = 2</math>.\n\n'''van Albada 1''' – symmetric (van Albada, et al., 1982)\n\n:<math> \\phi_{va1} (r) = \\frac{r^2 + r}{r^2 + 1 }  ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{va1} (r) = 1</math>.\n\n'''van Albada 2''' – alternative form [not 2nd order TVD] used on high spatial order schemes (Kermani, 2003)\n\n:<math> \\phi_{va2} (r) = \\frac{2 r}{r^2 + 1} ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{va2} (r) = 0</math>.\n\n'''van Leer''' – symmetric ([[Bram van Leer|van Leer]], 1974)\n\n:<math> \\phi_{vl} (r) = \\frac{r + \\left| r \\right| }{1 +  \\left| r \\right| }  ; \\quad \\lim_{r \\rightarrow \\infty}\\phi_{vl} (r) = 2</math>.\n\nAll the above limiters indicated as being ''symmetric'', exhibit the following symmetry property,\n\n:<math>\\frac{ \\phi \\left( r \\right)}{r} = \\phi \\left( \\frac{1}{r} \\right) </math>.\n\nThis is a desirable property as it ensures that the limiting actions for forward and backward gradients operate in the same way.\n\n[[File:LimiterRegion.png|thumb|Admissible limiter region for second-order TVD schemes.|200px|right|Admissible limiter region for second-order TVD schemes.]]\n\nUnless indicated to the contrary, the above limiter functions are second order [[total variation diminishing|TVD]]. This means that they are designed such that they pass through a certain region of the solution, known as the TVD region, in order to guarantee stability of the scheme. Second-order, TVD limiters satisfy at least the following criteria:\n\n*<math> r \\le \\phi(r) \\le 2r, \\left( 0  \\le r \\le 1 \\right) \\ </math>,\n*<math> 1 \\le \\phi(r) \\le r, \\left( 1 \\le r \\le 2 \\right) \\ </math>, \n*<math> 1 \\le \\phi(r) \\le 2, \\left( r > 2 \\right) \\ </math>, \n*<math> \\phi(1) = 1 \\ </math>,\n\nThe admissible limiter region for second-order TVD schemes is shown in the ''Sweby Diagram'' opposite (Sweby, 1984), and plots showing limiter functions overlaid onto the TVD region are shown below. In this image, plots for the Osher and Sweby limiters have been generated using <math> \\beta = 1.5 </math>.\n\n<center>\n[[File:LimiterPlots1.png|thumb|Limiter functions overlaid onto second-order TVD region.|650px|none|Limiter functions overlaid onto second-order TVD region.]]\n</center>\n\n=== Generalised minmod limiter ===\n\nAn additional limiter that has an interesting form is the van-Leer's one-parameter family of  minmod limiters (van Leer, 1979; Harten and Osher, 1987; Kurganov and Tadmor, 2000). It is defined as follows\n\n:<math> \\phi_{mg}(u,\\theta)=\\max\\left(0,\\min\\left(\\theta r,\\frac{1+r}{2},\\theta\\right)\\right),\\quad\\theta\\in\\left[1,2\\right]. </math>\n\n'''Note:''' <math> \\phi_{mg} \\ </math>&nbsp; is most dissipative for &nbsp;&nbsp;<math> \\theta=1, \\ </math> &nbsp; when it reduces to <math>\\phi_{mm}, \\ </math> &nbsp; and is least dissipative for &nbsp; <math> \\theta=2 \\ </math>.\n\n==See also==\n\n*[[Godunov's theorem]]\n*[[High resolution scheme]]\n*[[MUSCL scheme]]\n*[[Sergei K. Godunov]] \n*[[Total variation diminishing]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*{{citation |last1=Chakravarthy |first1=S.R. |last2=Osher |first2=S. |year=1983 |contribution=High resolution applications of the Osher upwind scheme for the Euler equations |id=AIAA Paper 83-1943 | title=Proc. AIAA 6th Computational Fluid Dynamics Conference |pages=363–373 |url=http://www.aiaa.org/content.cfm?pageid=406&gTable=mtgpaper&gID=55466 }}\n*{{citation |last1=Gaskell |first1=P.H. |first2=A.K.C. |last2=Lau |year=1988 |title=Curvature-compensated convective transport: SMART, a new boundedness-preserving transport algorithm |journal=Int. J. Num. Meth. Fluids |volume=8 |pages=617–641 |doi=10.1002/fld.1650080602 |issue=6|bibcode = 1988IJNMF...8..617G }}\n*{{citation |last1=Harten |first1=A. |first2=S. |last2=Osher |year=1987 |title=Uniformly high-order accurate nonoscillatory schemes. I |journal=SIAM J. Numer. Anal. |volume=24 |pages=279–309 |doi=10.1137/0724022 |issue=2 |bibcode = 1987SJNA...24..279H |url=http://www.dtic.mil/get-tr-doc/pdf?AD=ADA158177 }}\n*{{citation |last=Hirsch |first=C. |year=1990 |title=Numerical Computation of Internal and External Flows. Volume 2: Computational Methods for Inviscid and Viscous Flows |publisher=Wiley }}\n*{{citation |last1=Kermani |first1=M.J. |last2=Gerber |first2=A.G. |last3=Stockie |first3=J.M. |year=2003 |contribution=Thermodynamically Based Moisture Prediction Using Roe’s Scheme |title=4th Conference of Iranian AeroSpace Society |location=Amir Kabir University of Technology, Tehran, Iran, January 27–29 }}\n*{{citation |last=Koren |first=B. |year=1993 |contribution=A robust upwind discretisation method for advection, diffusion and source terms |title=Numerical Methods for Advection–Diffusion Problems |editor1-first=C.B. |editor1-last=Vreugdenhil |editor2-first=B. |editor2-last=Koren |publisher=Vieweg |location=Braunschweig |page=117 |isbn=3-528-07645-3 }}\n*{{citation |last1=Kurganov |first1=A. |first2=E. |last2=Tadmor|author2-link=Eitan Tadmor |year=2000 |title=Solution of Two-Dimensional Riemann problems for Gas Dynamics without Riemann Problem Solvers |publisher=Report by Dept. of Mathematics, Univ. Michigan }} Available on-line at: [http://citeseer.ist.psu.edu/410715.html CiteSeer].\n*{{citation |last1=Lien |first1=F.S. |first2=M.A. |last2=Leschziner |year=1994 |title=Upstream monotonic interpolation for scalar transport with application to complex turbulent flows |journal=Int. J. Num. Meth. Fluids |volume=19 |pages=527–548 |doi=10.1002/fld.1650190606 |issue=6 |bibcode = 1994IJNMF..19..527L }}\n*{{citation |last1=Leonard |first1=B.P. |first2=M.A. |last2=Leschziner |first3=J. |last3=McGuirk |year=1978 |contribution=The QUICK algorithm: a uniformly 3rd-order finite-difference method for highly convective flows |title=Proc. 1st Conf. on Numerical Methods in Laminar & Turbulent Flow |location=Swansea |page=807 }}\n*{{citation |last=Roe |first=P.L. |year=1986 |title=Characteristic-based schemes for the Euler equations |journal=Annu. Rev. Fluid Mech. |volume=18 |pages=337–365 |doi=10.1146/annurev.fl.18.010186.002005 |bibcode = 1986AnRFM..18..337R }}\n*{{citation |last=Sweby |first=P.K. |year=1984 |title=High resolution schemes using flux-limiters for hyperbolic conservation laws |journal=SIAM J. Numer. Anal.| volume=21 |pages=995–1011 |doi=10.1137/0721062 |issue=5 |bibcode = 1984SJNA...21..995S }}\n*{{citation |last1=Van Albada |first1=G.D. |first2=B. |last2=Van Leer |first3=W.W. |last3=Roberts |year=1982 |title=A comparative study of computational methods in cosmic gas dynamics |journal=Astronomy and Astrophysics |volume=108 |pages=76–84 |bibcode=1982A&A...108...76V }}\n*{{citation |last=Van Leer |first=B. |year=1974 |title=Towards the ultimate conservative difference scheme II. Monotonicity and conservation combined in a second order scheme |journal=J. Comput. Phys. |volume=14 |pages=361–370 |doi=10.1016/0021-9991(74)90019-9 |issue=4 |bibcode = 1974JCoPh..14..361V }}\n*{{citation |last=Van Leer |first=B. |year=1977 |title=Towards the ultimate conservative difference scheme III. Upstream-centered finite-difference schemes for ideal compressible flow |journal=J. Comput. Phys. |volume=23 |pages=263–275 |doi=10.1016/0021-9991(77)90094-8 |issue=3 |bibcode = 1977JCoPh..23..263V }}\n*{{citation |last=Van Leer |first=B. |year=1979 |title=Towards the ultimate conservative difference scheme V. A second order sequel to Godunov's method |journal=J. Comput. Phys. |volume=32 |pages=101–136 |doi=10.1016/0021-9991(79)90145-1 |bibcode = 1979JCoPh..32..101V }}\n*{{citation |last1=Waterson |first1=N.P. |first2=H. |last2=Deconinck |year=1995 |title=A unified approach to the design and application of bounded higher-order convection schemes |type=[[Von Karman Institute|VKI]] Preprint 1995-21 }}\n*{{citation |last=Zhou |first=G. |year=1995 |title=Numerical simulations of physical discontinuities in single and multi-fluid flows for arbitrary Mach numbers |type=PhD Thesis |publisher=Chalmers Univ. of Tech. |location=Goteborg, Sweden }}\n\n==Further reading==\n\n*{{citation |last=Hirsch |first=C. |year=1990 |title=Numerical Computation of Internal and External Flows, Volume 2: Computational Methods for Inviscid and Viscous Flows |publisher=Wiley |isbn=978-0-471-92452-4 }}\n*{{citation |last=Laney |first=Culbert B. |year=1998 |title=Computational Gasdynamics |publisher=Cambridge University Press |doi=10.2277/0521570697 |isbn=978-0-521-57069-5 }}\n*{{citation |last=LeVeque |first=Randall |year=1990 |title=Numerical Methods for Conservation Laws |series=ETH Lectures in Mathematics Series |publisher=Birkhauser-Verlag |isbn=3-7643-2464-3 }}\n*{{citation |last=LeVeque |first=Randall |year=2002 |title=Finite Volume Methods for Hyperbolic Problems |publisher=Cambridge University Press |isbn=0-521-00924-3 }}\n*{{citation |last=Toro |first=E.F. |year=1999 |title=Riemann Solvers and Numerical Methods for Fluid Dynamics |publisher=Springer-Verlag |edition=2nd |isbn=3-540-65966-8 }}\n*{{citation | last1=Tannehill |first1=John C. |first2=Dale Arden |last2=Anderson |first3=Richard H. |last3=Pletcher |year=1997 |title=Computational Fluid Mechanics and Heat Transfer |edition=2nd |publisher=Taylor and Francis |isbn=1-56032-046-X }}\n*{{citation |last=Wesseling |first=Pieter |year=2001 |title=Principles of Computational Fluid Dynamics |publisher=Springer-Verlag |isbn=3-540-67853-0 }}\n\n[[Category:Computational fluid dynamics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "FTCS scheme",
      "url": "https://en.wikipedia.org/wiki/FTCS_scheme",
      "text": "{{Redirect|FTCS|the scientific conference|International Conference on Dependable Systems and Networks}}\n\nIn [[numerical analysis]], the '''FTCS''' (Forward-Time Central-Space) method is a [[finite difference method]] used for numerically solving the [[heat equation]] and similar [[parabolic partial differential equation]]s.<ref>{{cite book | title = Computational Fluid Mechanics and Heat Transfer | author1 = John C. Tannehill | author2 = Dale A. Anderson |authorlink2=Dale A. Anderson| author3 = Richard H. Pletcher | edition = 2nd | publisher = [[Taylor and Francis|Taylor & Francis]] | year = 1997 | isbn = 1-56032-046-X}}</ref> It is a first-order method in time, [[Explicit and implicit methods|explicit]] in time, and is [[Numerical stability|conditionally stable]] when applied to the heat equation.  When used as a method for [[advection|advection equations]], or more generally [[hyperbolic partial differential equation]], it is unstable unless artificial viscosity is included. The abbreviation FTCS was first used by Patrick Roache.<ref>{{cite book | title = Computational Fluid Dynamics | author = Patrick J. Roache | edition = 1st | publisher = [[Hermosa (publisher)|Hermosa]] | year = 1972 | isbn = 0-913478-05-9}}</ref><ref>{{cite book | title = Computational Fluid Dynamics | author = Patrick J. Roache | edition = 2nd | publisher = [[Hermosa (publisher)|Hermosa]] | year = 1998 | isbn = 0-913478-09-1}}</ref>\n\n==The method==\nThe FTCS method is based on [[central difference]] in space and the [[forward Euler method]] in time, giving first-order convergence in time and second-order convergence in space. For example, in one dimension, if the [[partial differential equation]] is\n\n:<math>\\frac{\\partial u}{\\partial t} = F\\left(u, x, t, \\frac{\\partial^2 u}{\\partial x^2}\\right)</math>\n\nthen, letting <math>u(i \\,\\Delta x, n\\, \\Delta t) = u_{i}^{n}\\,</math>, the forward Euler method is given by:\n\n:<math>\\frac{u_{i}^{n + 1} - u_{i}^{n}}{\\Delta t} = \nF_{i}^{n}\\left(u, x, t, \\frac{\\partial^2 u}{\\partial x^2}\\right) </math>\n\nThe function <math>F</math> must be discretized spatially with a [[central difference]] scheme. This is an [[explicit and implicit methods|explicit method]] which means that, <math>u_{i}^{n+1}</math> can be explicitly computed (no need of solving a system of algebraic equations) if values of <math>u</math> at previous time level <math>(n)</math> are known. FTCS method is computationally inexpensive since the method is explicit.\n\n==Illustration: one-dimensional heat equation==\nThe FTCS method is often applied to [[diffusion]] problems. As an example, for 1D [[heat equation]],\n\n:<math>\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}</math>\n\nthe FTCS scheme is given by:\n\n:<math>\\frac{u_{i}^{n + 1} - u_{i}^{n}}{\\Delta t} = \\frac{\\alpha}{\\Delta x^2} \\left(u_{i + 1}^{n} - 2 u_{i}^{n} + u_{i - 1}^{n}\n\\right)</math>\n\nor, letting <math>r = \\frac{\\alpha\\, \\Delta t}{\\Delta x^2}</math>:\n\n:<math>u_{i}^{n + 1} = u_{i}^{n} + r \\left(u_{i + 1}^{n} - 2 u_{i}^{n} + u_{i - 1}^{n}\n\\right)</math>\n\n==Stability==\nThe FTCS method, for one-dimensional equations, is [[numerical stability|numerically stable]] if and only if the following condition is satisfied:\n\n:<math> r = \\frac{\\alpha\\, \\Delta t}{\\Delta x^2} \\leq \\frac{1}{2}. </math>\n\nThe time step <math>\\Delta t </math> is subjected to the restriction given by the above stability condition. A major drawback of the method is for problems with large diffusivity the time step restriction can be too severe.\n\nFor [[hyperbolic partial differential equations]], the [[linear differential equation|linear test problem]] is the constant coefficient\n[[Advection|advection equation]], as opposed to the [[heat equation]] (or [[diffusion equation]]), which is the correct choice for a [[parabolic differential equation]].\nIt is well known that for these [[hyperbolic partial differential equations|hyperbolic problems]], ''any'' choice of\n<math> \\Delta t</math> results in an unstable scheme.<ref>{{cite book|last=LeVeque|first=Randall|title=Finite Volume Methods for Hyperbolic Problems|year=2002|publisher=Cambridge University Press|isbn=0-521-00924-3}}</ref>\n\n==See also==\n\n*[[Partial differential equations]]\n*[[Crank–Nicolson method]]\n\n==References==\n\n<references/>\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Ftcs Scheme}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "General linear methods",
      "url": "https://en.wikipedia.org/wiki/General_linear_methods",
      "text": "{{distinguish|text=[[general linear model]]s or [[generalized linear model]]s}}\n'''General linear methods''' ('''GLM'''s) are a large class of [[Numerical methods for ordinary differential equations|numerical methods]] used to obtain [[numerical ordinary differential equations|numerical]] solutions to [[differential equation]]s. This large class of methods in [[numerical analysis]] encompass multistage [[Runge–Kutta methods|Runge–Kutta]] methods that use intermediate [[Collocation method|collocation points]], as well as [[linear multistep method]]s that save a finite time history of the solution. [[John C. Butcher]] originally coined this term for these methods, and has written a series of review papers<ref>{{cite journal|last=Butcher|first=John C.|title=General linear methods|journal=Computers & Mathematics with Applications|date=February–March 1996|volume=31|issue=4–5|pages=105–112|doi=10.1016/0898-1221(95)00222-7}}</ref>\n<ref>{{cite journal|last=Butcher|first=John|title=General linear methods|journal=Acta Numerica|date=May 2006|volume=15|pages=157–256|doi=10.1017/S0962492906220014|bibcode=2006AcNum..15..157B}}</ref>\n<ref>{{cite journal|last=Butcher|first=John|title=General linear methods for ordinary differential equations|journal=Mathematics and Computers in Simulation|date=February 2009|volume=79|issue=6|pages=1834–1845|doi=10.1016/j.matcom.2007.02.006}}</ref>\na book chapter<ref>{{cite book|last=Butcher|first=John|title=Numerical Methods for Ordinary Differential Equations|year=2005|publisher=John Wiley & Sons, Ltd|isbn=9780470868270|pages=357–413|doi=10.1002/0470868279.ch5|chapter=General Linear Methods}}</ref>\nand a textbook<ref>{{cite book|last=Butcher|first=John|title=The numerical analysis of ordinary differential equations: Runge–Kutta and general linear methods|year=1987|publisher=Wiley-Interscience|isbn=978-0-471-91046-6|url=http://dl.acm.org/citation.cfm?id=22730}}</ref>\non the topic. His collaborator, Zdzislaw Jackiewicz also has an extensive textbook<ref>{{cite book|last=Jackiewicz|first=Zdzislaw|title=General Linear Methods for Ordinary Differential Equations|year=2009|publisher=Wiley|isbn=978-0-470-40855-1|url=http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470408553.html}}</ref> on the topic.  The original class of methods were originally proposed by\nButcher (1965), Gear (1965) and Gragg and Stetter (1964).\n\n== Some definitions ==\nNumerical methods for first-order ordinary differential equations approximate solutions to initial value problems of the form\n\n: <math> y' = f(t,y), \\quad y(t_0) = y_0. </math>\n\nThe result is approximations for the value of <math> y(t) </math> at discrete times <math> t_i </math>:\n\n: <math> y_i  \\approx y(t_i) \\quad\\text{where}\\quad t_i = t_0 + i h, </math>\n\nwhere ''h'' is the time step (sometimes referred to as <math> \\Delta t </math>).\n\n==A description of the method==\n\nWe follow Butcher (2006), pps 189–190 for our description,\nalthough we note that this method can be found elsewhere.\n\nGeneral linear methods make use of two integers, <math> r </math>, the number of time points in history and <math> s </math>, the number of collocation points.  In the case of <math>r=1</math>, these methods reduce to classical [[Runge–Kutta methods]],\nand in the case of <math>s=1</math>, these methods reduce to [[linear multistep method]]s.\n\nStage values <math> Y_i </math> and stage derivatives, <math> F_i, i=1,2,\\dots s </math> are computed from approximations, <math> y_i^{[n-1]}, i=1, \\dots, r </math>, at time step <math>n</math>:\n\n:<math>\ny^{[n-1]} = \n\\left[\n\\begin{matrix}\ny_1^{[n-1]} \\\\\ny_2^{[n-1]} \\\\\n\\vdots \\\\\ny_r^{[n-1]} \\\\\n\\end{matrix}\n\\right], \\quad\ny^{[n]} = \n\\left[\n\\begin{matrix}\ny_1^{[n]} \\\\\ny_2^{[n]} \\\\\n\\vdots \\\\\ny_r^{[n]} \\\\\n\\end{matrix}\n\\right], \\quad\nY = \n\\left[\n\\begin{matrix}\nY_1 \\\\\nY_2 \\\\\n\\vdots \\\\\nY_s\n\\end{matrix}\n\\right], \\quad\nF = \n\\left[\n\\begin{matrix}\nF_1 \\\\\nF_2 \\\\\n\\vdots \\\\\nF_s\n\\end{matrix}\n\\right].\n</math>\n\nThe stage values are defined by two matrices, <math> A = [a_{ij} ] </math> and <math> U = [ u_{ij} ]</math>:\n\n:<math>\nY_i = \n\\sum_{j=1}^s a_{ij} h F_j + \\sum_{j=1}^r u_{ij} y_j^{[n-1]}, \\qquad i=1,2, \\dots, s,\n</math>\n\nand the update to time <math>t^n</math> is defined by two matrices, <math> B = [b_{ij}] </math> and <math> V = [v_{ij}] </math>:\n\n:<math>\ny_i^{[n]} = \\sum_{j=1}^s b_{ij} h F_j + \\sum_{j=1}^r v_{ij} y_j^{[n-1]}, \\qquad i=1, 2, \\dots, r.\n</math>\n\nGiven the four matrices, <math>A, U, B</math> and <math>V</math>, one can compactly write the analogue of a [[Butcher tableau]] as,\n\n:<math>\n\\left[ \\begin{matrix}\nY \\\\\ny^{[n]}\n\\end{matrix} \\right]\n=\n\\left[ \\begin{matrix}\nA \\otimes I & U \\otimes I \\\\ \nB \\otimes I & V \\otimes I\n\\end{matrix} \\right]\n\\left[ \\begin{matrix}\nF \\\\\ny^{[n-1]}\n\\end{matrix} \\right],\n</math>\nwhere <math>\\otimes</math> stands for the\n[[tensor product]], and\n<math> F = f( Y ) </math>.\n\n==Examples==\n\nWe present an example described in (Butcher, 1996).<ref>{{harvnb|Butcher|1996|p=107}}</ref>  This method consists of a single 'predicted' step, and 'corrected' step, that uses extra information about the time history, as well as a single intermediate stage value.\n\nAn intermediate stage value is defined as something that looks like it came from a [[linear multistep method]]:\n\n:<math>\ny^*_{n-1/2} = y_{n-2} + h \\left( \\frac9 8 f( y_{n-1} ) + \\frac3 8 f( y_{n-2} ) \\right).\n</math>\n\nAn initial 'predictor' <math> y^*_n </math> uses the stage value <math>y^*_{n-1/2}</math> together with two pieces of time history:\n\n:<math>\ny^*_n = \\frac{28}{5} y_{n-1} - \\frac{23}{5} y_{n-2} + h \\left( \\frac{32}{15} f( y^*_{n-1/2} ) - 4 f( y_{n-1} ) - \\frac{26}{15} f( y_{n-2} ) \\right),\n</math>\n\nand the final update is given by:\n\n:<math>\ny_n = \\frac{32}{31} y_{n-1} - \\frac{1}{31} y_{n-2} + h \\left(\n\\frac{5}{31} f( y^*_n )  + \\frac{64}{93} f( y^*_{n-1/2} ) + \\frac{4}{31} f( y_{n-1} ) - \\frac{1}{93} f( y_{n-2} )\n\\right).\n</math>\n\nThe concise table representation for this method is given by:\n\n:<math>\n\\left[ \\begin{array}{ccc|cccc}\n0 & 0 & 0 & 0 & 1 & \\frac{9}{8} & \\frac{3}{8} \\\\\n\\frac{32}{15} & 0 & 0 & \\frac{28}{5} & -\\frac{23}{5} & -4 & -\\frac{26}{15} \\\\\n\\frac{64}{93} & \\frac{5}{31} & 0 & \\frac{32}{31} & -\\frac{1}{31} & \\frac{4}{31} & -\\frac{1}{93} \\\\\n\\hline \n\\frac{64}{93} & \\frac{5}{31} & 0 & \\frac{32}{31} & -\\frac{1}{31} & \\frac{4}{31} & -\\frac{1}{93} \\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n\\end{array}\n\\right].\n</math>\n\n== See also ==\n*[[Runge–Kutta methods]]\n*[[Linear multistep method]]s\n*[[Numerical methods for ordinary differential equations]]\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n* {{cite journal|last=Butcher|first=John C.|title=A Modified Multistep Method for the Numerical Integration of Ordinary Differential Equations|journal=Journal of the ACM|date=January 1965|volume=12|issue=1|pages=124–135|doi=10.1145/321250.321261}}\n* {{cite journal|last=Gear|first=C.W.|title=Hybrid Methods for Initial Value Problems in Ordinary Differential Equations|journal= Journal of the Society for Industrial and Applied Mathematics, Series B: Numerical Analysis|year=1965|volume=2|issue=1|pages=69–86|doi=10.1137/0702006|hdl=2027/uiuo.ark:/13960/t4rj60q8s|bibcode=1965SJNA....2...69G}}\n* {{cite journal|last=Gragg|first=William B.|author2=Hans J. Stetter|title=Generalized Multistep Predictor-Corrector Methods|journal=Journal of the ACM|date=April 1964|volume=11|issue=2|pages=188–209|doi=10.1145/321217.321223}}\n* {{citation | first1 = Ernst | last1 = Hairer | first2 = Wanner | last2 = Wanner | year = 1973 | title = Multistep-multistage-multiderivative methods for ordinary differential equations | journal = Computing | volume = 11 | issue = 3 | pages = 287–303 |\ndoi = 10.1007/BF02252917}}.\n\n== External links ==\n*[http://www.scholarpedia.org/article/General_linear_methods General Linear Methods]\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Geometric integrator",
      "url": "https://en.wikipedia.org/wiki/Geometric_integrator",
      "text": "In the mathematical field of [[numerical ordinary differential equations]], a '''geometric integrator''' is a numerical method that preserves geometric properties of the exact [[Vector field#Flow curves|flow]] of a differential equation.\n\n==Pendulum example==\nWe can motivate the study of geometric integrators by considering the motion of a [[simple pendulum|pendulum]].\n\nAssume that we have a pendulum whose bob has mass <math>m=1</math> and\nwhose rod is massless of length <math>\\ell=1</math>.  Take the\nacceleration due to gravity to be <math>g=1</math>.  Denote by\n<math>q(t)</math> the angular displacement of the rod from the vertical,\nand by <math>p(t)</math> the pendulum's momentum. The [[Hamiltonian mechanics|Hamiltonian]] of\nthe system, the sum of its [[kinetic energy|kinetic]] and [[potential energy|potential]] energies, is\n\n:<math>H(q,p) = T(p)+U(q) = \\frac{1}{2}p^2 - \\cos q, </math>\n\nwhich gives [[Hamilton's equations]]\n\n:<math>(\\dot q,\\dot p) = (p,-\\sin q). \\, </math>\n\nIt is natural to take the [[Configuration space (physics)|configuration space]] <math>Q</math> of all <math>q</math> to be the unit\ncircle <math>\\mathbb S^1</math>, so that <math>(q,p)</math> lies on the\ncylinder <math>\\mathbb S^1\\times\\mathbb R</math>.  However, we will take\n<math>(q,p)\\in\\mathbb R^2</math>, simply because <math>(q,p)</math>-space is\nthen easier to plot. Define <math>z(t) = (q(t),p(t))^{\\mathrm T}</math>\nand <math>f(z) = (p,-\\sin q)^{\\mathrm T}</math>.  Let us experiment by\nusing some simple numerical methods to integrate this system. As usual,\nwe select a constant step size, <math>h</math>, and for an arbitrary non-negative integer <math>k</math> we write\n<math>z_k:=z(kh)</math>.\nWe use the following methods.\n\n: <math> z_{k+1} = z_k + hf(z_k) \\, </math> ([[Euler method|explicit Euler]]),\n\n: <math> z_{k+1} = z_k + hf(z_{k+1}) \\, </math> ([[implicit Euler method|implicit Euler]]),\n\n: <math> z_{k+1} = z_k + hf(q_k,p_{k+1}) \\, </math> ([[Euler–Cromer algorithm|symplectic Euler]]),\n\n: <math> z_{k+1} = z_k + hf((z_{k+1}+z_k)/2) \\, </math> ([[implicit midpoint rule]]).\n\n(Note that the symplectic Euler method treats ''q'' by the explicit and <math>p</math> by the implicit Euler method.)\n\nThe observation that <math>H</math> is constant along the solution\ncurves of the Hamilton's equations allows us to describe the exact\ntrajectories of the system: they are the [[level set|level curves]] of <math>p^2/2 -\n\\cos q</math>. We plot, in <math>\\mathbb R^2</math>, the exact\ntrajectories and the numerical solutions of the system. For the explicit\nand implicit Euler methods we take <math>h=0.2</math>, and ''z''<sub>0</sub>&nbsp;=&nbsp;(0.5,&nbsp;0) and (1.5,&nbsp;0) respectively; for the other two methods we take <math>h=0.3</math>, and ''z''<sub>0</sub>&nbsp;=&nbsp;(0,&nbsp;0.7), (0,&nbsp;1.4) and (0,&nbsp;2.1).\n[[Image:pendulumtrajectories.png|thumb|300px|Simple pendulum: trajectories]]\nThe explicit (resp. implicit) Euler method spirals out from (resp. in to) the origin. The other two methods show the correct qualitative behaviour, with the implicit midpoint rule agreeing with the exact solution to a greater degree than the symplectic Euler method.\n\nRecall that the exact flow <math>\\phi_t</math> of a Hamiltonian system with one degree of freedom is\narea-preserving, in the sense that\n:<math>\\det\\frac{\\partial\\phi_t}{\\partial (q_0,p_0)} = 1</math> for all <math>t</math>.\nThis formula is easily verified by hand. For our pendulum\nexample we see that the numerical flow <math>\\Phi_{{\\mathrm{eE}},h}:z_k\\mapsto z_{k+1}</math> of the explicit Euler method is '''not''' area-preserving; viz.,\n\n:<math>\\det\\frac{\\partial}{\\partial (q_0,p_0)}\\Phi_{{\\mathrm{eE}},h}(z_0)\n    = \\begin{vmatrix}1&h\\\\-h\\cos q_0&1\\end{vmatrix}\n   = 1+h^2\\cos q_0.</math>\n\nA similar calculation can be carried out for the implicit Euler method,\nwhere the determinant is\n\n:<math>\\det\\frac{\\partial}{\\partial (q_0,p_0)}\\Phi_{{\\mathrm{iE}},h}(z_0)\n    = (1+h^2\\cos q_1)^{-1}.</math>\n\nHowever, the symplectic Euler method '''is''' area-preserving:\n\n:<math>\n    \\begin{pmatrix}1&-h\\\\0&1\\end{pmatrix}\\frac{\\partial}{\\partial (q_0,p_0)}\\Phi_{{\\mathrm{sE}},h}(z_0)\n    = \\begin{pmatrix}1&0\\\\-h\\cos q_0&1\\end{pmatrix},</math>\n\nthus <math>\\det(\\partial\\Phi_{{\\mathrm{sE}},h}/\\partial (q_0,p_0)) = 1</math>. The implicit midpoint rule has similar geometric properties.\n\nTo summarize: the pendulum example shows that, besides the explicit and\nimplicit Euler methods not being good choices of method to solve the\nproblem, the symplectic Euler method and implicit midpoint rule agree\nwell with the exact flow of the system, with the midpoint rule agreeing\nmore closely. Furthermore, these latter two methods are area-preserving,\njust as the exact flow is; they are two examples of geometric (in fact, [[symplectic integrator|symplectic]]) integrators.\n\n==Moving frame method==\n\nThe [[moving frame]] method can be used to construct numerical methods which preserve [[Lie group|Lie]] [[Symmetry group|symmetries]] of the ODE. Existing methods such as [[Runge-Kutta]] can be modified using moving frame method to produce invariant versions.<ref> Pilwon Kim (2006),  \" [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.527.93&rep=rep1&type=pdf Invariantization of Numerical Schemes Using Moving Frames]\"</ref>\n\n==See also==\n* [[Energy drift]]\n* [[Mimesis (mathematics)]]\n\n==References==\n{{Reflist}}\n\n==Further reading==\n* {{cite book\n  | first1 = Ernst | last1 = Hairer\n  | first2 = Christian | last2 = Lubich\n  | first3 = Gerhard | last3 = Wanner\n  | title = Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations\n  | year = 2002\n  | publisher = Springer-Verlag\n  | isbn = 3-540-43003-2\n  }} \n* {{cite book\n  | last1 = Ben | first1 = Leimkuhler\n  | last2 = Sebastian | first2 = Reich\n  | title = Simulating Hamiltonian Dynamics\n  | year = 2005\n  | publisher = Cambridge University Press\n  | isbn = 0-521-77290-7\n  }}\n* {{cite news\n  | first1 = C.J. | last1 = Budd\n  | first2 = M.D. | last2 = Piggott\n  | title = Geometric Integration and its Applications\n  | series = Handbook of Numerical Analysis\n  | volume = 11\n  | pages = 35–139\n  | year = 2003\n  | publisher = Elsevier\n  | doi = 10.1016/S1570-8659(02)11002-7\n  }} \n* {{cite news\n  | first1 = Pilwon | last1 = Kim\n  | title = Invariantization of Numerical Schemes Using Moving Frames\n  | series = BIT Numerical Mathematics\n  | volume = 47\n  | pages = 525–546\n  | year = 2007\n  | publisher = Springer\n  | doi = 10.1007/s10543-007-0138-8\n  }}\n\n\n\n{{DEFAULTSORT:Geometric Integrator}}\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Godunov's scheme",
      "url": "https://en.wikipedia.org/wiki/Godunov%27s_scheme",
      "text": "In [[numerical analysis]] and [[computational fluid dynamics]], '''Godunov's scheme''' is a [[Conservation law|conservative]] [[numerical analysis|numerical scheme]], suggested by [[Sergei K. Godunov|S. K. Godunov]] in 1959, for solving [[partial differential equations]].  One can think of this method as a conservative [[finite-volume method]] which solves exact, or approximate [[Riemann problem]]s at each inter-cell boundary.  In its basic form, Godunov's method is first order accurate in both space and time, yet can be used as a base scheme for developing higher-order methods.\n\n==Basic scheme==\n\nFollowing the classical [[Finite-volume method]] framework, we seek to track a finite set of discrete unknowns,\n\n: <math> Q^{n}_i = \\frac{1}{\\Delta x} \\int_{x_{i-1/2}} ^ { x_{i+1/2} } q(t^n, x)\\, dx </math>\n\nwhere the <math> x_{i-1/2} = x_{\\text{low}} + \\left( i - 1/2 \\right) \\Delta x </math> and <math> t^n = n \\Delta t </math> form a discrete set of points for the hyperbolic problem:\n\n: <math> q_t + ( f( q ) )_x = 0. </math>\n\nIf we integrate the hyperbolic problem over a control volume <math> [x_{i-1/2}, x_{i+1/2}], </math> we obtain a [[Method of lines]] (MOL) formulation for the spatial cell averages:\n\n: <math> \\frac{\\partial}{\\partial t} Q_i( t ) = -\\frac{1}{\\Delta x} \\left( f( q( t, x_{i+1/2} ) ) - f( q( t, x_{i-1/2} ) ) \\right), </math>\n\nwhich is a classical description of the first order, upwinded finite volume method.  (c.f. Leveque - Finite Volume Methods for Hyperbolic Problems )\n\nExact time integration of the above formula from time <math> t = t^n </math> to time <math> t = t^{n+1} </math> yields the exact update formula:\n\n: <math> Q^{n+1}_i = Q^n_i - \\frac{1}{\\Delta x } \\int_{ t^n }^{t^{n+1} } \\left( f( q( t, x_{i+1/2} ) ) - f( q( t, x_{i-1/2} ) ) \\right)\\, dt. </math>\n\nGodunov's method replaces the time integral of each \n\n: <math> \\int_{t^n}^{t^{n+1} }  f( q( t, x_{i-1/2} ) )\\, dt </math>\n\nwith a Forward [[Euler method]] which yields a fully discrete update formula for each of the unknowns <math> Q^n_i </math>.  That is, we approximate the integrals with\n\n: <math> \\int_{t^n}^{t^{n+1} }  f( q( t, x_{i-1/2} ) )\\, dt \\approx \\Delta t f^\\downarrow\\left( Q^n_{i-1}, Q^n_i \\right), </math>\n\nwhere <math> f^\\downarrow\\left( q_l, q_r \\right) </math> is an approximation to the exact solution of the Riemann problem.  For consistency, one assumes that \n\n: <math> f^\\downarrow( q_l , q_r ) = f( q_l ) \\quad \\text{ if } \\quad q_l = q_r, </math>\n\nand that <math> f^\\downarrow </math> is increasing in the first argument, and decreasing in the second argument.  \nFor scalar problems where <math> f'( q ) > 0 </math>, one can use the simple [[Upwind scheme]], which defines <math> f^\\downarrow( q_l, q_r ) = f( q_l ) </math>.\n\nThe full Godunov scheme requires the definition of an approximate, or an exact [[Riemann solver]], but in its most basic form, is given by:\n\n: <math> Q^{n+1}_i = Q^n_i - \\lambda \\left( \\hat{f}^n_{i+1/2} - \\hat{f}^n_{i-1/2}  \\right), \\quad \\lambda = \\frac{\\Delta t}{\\Delta x}, \\quad \\hat{f}^n_{i-1/2} = f^\\downarrow\\left( Q^n_{i-1}, Q^n_i \\right) </math>\n\n==Linear problem==\n\nIn the case of a linear problem, where <math> f(q) = a q </math>, and without loss of generality, we'll assume that <math> a > 0 </math>, the upwinded Godunov method yields:\n\n: <math> Q^{n+1}_i = Q^n_i - \\nu \\left( Q^{n}_i - Q^n_{i-1} \\right), \\quad \\nu = a \\frac{\\Delta t } {\\Delta x }, </math>\n\nwhich yields the classical first-order, upwinded Finite Volume scheme whose stability requires <math> \\nu  = \\left| a \\frac{\\Delta t}{\\Delta x} \\right| \\leq 1 </math>.\n\n==Three-step algorithm==\n\nFollowing ''Hirsch'', the scheme involves three distinct steps to obtain the solution at <math> t = (n+1) \\Delta t \\,</math> from the known solution at <math> {t = n \\Delta t} \\,</math>, as follows:\n\n'''''Step 1''''' Define piecewise constant approximation of the solution at <math> {t = (n+1) \\Delta t} \\,</math>. Since the piecewise constant approximation is an average of the solution over the cell of size <math> {\\Delta x} \\,</math>, the spatial error is of order <math> {\\Delta x} \\, </math>,  and hence the resulting scheme will be first-order accurate in space.\nNote that this approximation corresponds to a [[finite volume method]] representation whereby the discrete values represent averages of the state variables over the cells. Exact relations for the averaged cell values can be obtained from the integral conservation laws.\n\n'''''Step 2''''' Obtain the solution for the local [[Riemann problem]] at the cell interfaces. This is the only physical step of the whole procedure. The discontinuities at the interfaces are resolved in a superposition of waves satisfying locally the conservation equations. \nThe original Godunov method is based upon the exact solution of the Riemann problems. However, approximate solutions can be applied as an alternative.\n\n'''''Step 3''''' Average the state variables after a time interval <math> {\\Delta t} \\,</math>. The state variables obtained after Step 2 are averaged over each cell defining a new piecewise constant approximation resulting from the wave propagation during the time interval <math> {\\Delta t} \\,</math>. To be consistent, the time interval <math> {\\Delta t} \\,</math> should be limited such that the waves emanating from an interface do not interact with waves created at the adjacent interfaces. Otherwise the situation inside a cell would be influenced by interacting Riemann problems. This leads to the [[Courant–Friedrichs–Lewy condition|CFL]] condition <math>| a_\\max | \\Delta t <  \\Delta x/2 \\, </math> where <math> | a_\\max | \\, </math> is the maximum wave speed obtained from the cell eigenvalue(s) of the local ''[[Jacobian matrix and determinant|Jacobian]] matrix''.\n\nThe first and third steps are solely of a numerical nature and can be considered as a ''projection stage'', independent of the second, physical step, the ''evolution stage''. Therefore, they can be modified without influencing the physical input, for instance by replacing the piecewise constant approximation by a piecewise linear variation inside each cell, leading to the definition of second-order space-accurate schemes, such as the [[MUSCL scheme]].\n\n==See also==\n* [[Godunov's theorem]]\n* [[High-resolution scheme]]\n* [[Lax–Friedrichs method]]\n* [[MUSCL scheme]]\n* [[Sergei K. Godunov]]\n* [[Total variation diminishing]]\n* [[Lax&ndash;Wendroff theorem]]\n*[[AUSM]]\n\n==References==\n*{{cite journal |last=Godunov |first=S. K. |year=1959 |title=Разностный метод численного расчета разрывных решений уравнений гидродинамики |trans-title=A Difference Scheme for Numerical Solution of Discontinuous Solution of Hydrodynamic Equations |journal=[[Matematicheskii Sbornik|Math. Sbornik]] |volume=47 |pages=271–306 |mr=119433 |zbl=0171.46204 }} Translated US Joint Publ. Res. Service, JPRS 7226, 1969.\n*{{cite book |last=Hirsch |first=C. |year=1990 |title=Numerical Computation of Internal and External Flows |volume=vol 2 |publisher=Wiley |isbn=0-471-92452-0 }}\n*{{cite book |last=Leveque |first=Randy J. |year=2002 |title=Finite Volume Methods for Hyperbolic Problems |publisher=Cambridge University Press |isbn=0-521-81087-6 }}\n\n==Further reading==\n*{{cite book |last=Laney |first=Culbert B. |year=1998 |title=Computational Gasdynamics |location= |publisher=Cambridge University Press |isbn=0-521-57069-7 }}\n*{{cite book |last=Toro |first=E. F. |year=1999 |title=Riemann Solvers and Numerical Methods for Fluid Dynamics |location=Berlin |publisher=Springer-Verlag |isbn=3-540-65966-8 }}\n*{{cite book |last=Tannehill |first=John C. |first2=Dale A. |last2=Anderson |first3=Richard H. |last3=Pletcher |displayauthors=1 |year=1997 |title=Computational Fluid Mechanics and Heat Transfer |edition=2nd |location=Washington |publisher=Taylor and Francis |isbn=1-56032-046-X }}\n*{{cite book |last=Wesseling |first=Pieter |year=2001 |title=Principles of Computational Fluid Dynamics |location=Berlin |publisher=Springer-Verlag |isbn=3-540-67853-0 }}\n\n{{Numerical PDE}}\n\n[[Category:Computational fluid dynamics]]\n[[Category:Conservation equations]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Godunov's theorem",
      "url": "https://en.wikipedia.org/wiki/Godunov%27s_theorem",
      "text": "In [[numerical analysis]] and [[computational fluid dynamics]], '''Godunov's theorem''' — also known as '''Godunov's order barrier theorem''' — is a mathematical [[theorem]] important in the development of the theory of [[high resolution scheme]]s for the numerical solution of [[partial differential equations]].\n\nThe theorem states that: \n\n:''Linear numerical schemes for solving [[partial differential equations]] (PDE's), having the property of not generating new extrema ([[monotone scheme]]), can be at most first-order accurate.''\n\nProfessor [[Sergei K. Godunov]] originally proved the theorem as a Ph.D. student at [[Moscow State University]]. It is his most influential work in the area of applied and numerical mathematics and  has had a major impact on science and engineering, particularly in the development of methods used in [[computational fluid dynamics]] (CFD) and other computational fields. One of his major contributions was to prove the theorem (Godunov, 1954; Godunov, 1959), that bears his name.\n\n==The theorem==\nWe generally follow Wesseling (2001).\n\n'''Aside'''\n\nAssume a continuum problem described by a [[partial differential equations|PDE]] is to be computed using a numerical scheme based upon a uniform computational grid and a one-step, constant step-size, ''M'' grid point, integration algorithm, either implicit or explicit. Then if <math> x_{j}  = j\\,\\Delta x </math>  and <math>t^{n}  = n\\,\\Delta t </math>, such a scheme can be described by\n\n:<math>\n\\sum\\limits_{m=1}^{M} {\\beta _m } \\varphi _{j + m}^{n + 1}  = \\sum\\limits_{m=1}^{M} {\\alpha _m \\varphi _{j + m}^n }. \n\\quad  \\quad ( 1) </math>\n\nIn other words, the solution <math>\\varphi _j^{n + 1} </math> at time <math>n + 1</math> and location <math>j</math> is a linear function of the solution at the previous time step <math>n</math>. We assume that <math>\\beta _m </math> determines <math>\\varphi _j^{n + 1} </math> uniquely. Now, since the above equation represents a linear relationship between <math> \\varphi _j^{n } </math> and <math> \\varphi _j^{n + 1} </math> we can perform a linear transformation to obtain the following equivalent form,\n\n:<math>\\varphi _j^{n + 1}  = \\sum\\limits_m^{M} {\\gamma _m \\varphi _{j + m}^n }. \\quad  \\quad ( 2)\n</math>\n\n'''Theorem 1:''' ''Monotonicity preserving''\n\nThe above scheme of equation (2) is monotonicity preserving if and only if\n\n:<math>\\gamma _m  \\ge 0,\\quad \\forall m . \\quad  \\quad ( 3)</math>\n\n''Proof'' - Godunov (1959)\n\n'''Case 1: (sufficient condition)''' \n\nAssume (3) applies and that <math>\\varphi _j^n </math> is monotonically increasing with <math>j </math>.\n\nThen, because <math>\\varphi _j^n  \\le \\varphi _{j + 1}^n  \\le \\cdots  \\le \\varphi _{j + m}^n </math> it therefore follows that <math>\\varphi _j^{n + 1}  \\le \\varphi _{j + 1}^{n + 1} \\le \\cdots  \\le \\varphi _{j + m}^{n + 1} </math> because\n\n:<math>\n\\varphi _j^{n + 1}  - \\varphi _{j - 1}^{n + 1}  = \\sum\\limits_m^{M} {\\gamma _m \\left( {\\varphi _{j + m}^n  - \\varphi _{j + m - 1}^n } \\right)}  \\ge 0 . \\quad  \\quad ( 4)</math>\n\nThis means that monotonicity is preserved for this case.\n\n'''Case 2: (necessary condition)''' \n\nWe prove the necessary condition by contradiction. Assume that <math>\\gamma _p^{}  < 0 </math> for some <math>p </math> and choose the following monotonically increasing <math>\\varphi_j^n \\quad </math>,\n\n:<math>\\varphi _i^n  = 0, \\quad i < k;\\quad \\varphi _i^n  = 1, \\quad i \\ge k . \\quad  \\quad ( 5) </math>\n\nThen from equation (2) we get\n\n:<math> \\varphi _j^{n + 1}  - \\varphi _{j-1}^{n+1}  = \\sum\\limits_m^M {\\gamma _m } \\left( {\\varphi _{j + m}^{n}  - \\varphi _{j + m - 1}^{n} } \\right) = \\left\\{ {\\begin{array}{*{20}c}\n   {0,} & {\\left[ {j + m \\ne k} \\right]}  \\\\\n   {\\gamma _m ,} & {\\left[ {j + m = k} \\right]}  \\\\\n\\end{array}} \\right . \\quad  \\quad ( 6)</math>\n\nNow choose <math> j=k-p </math>, to give\n\n\t\t\t\n:<math>\n\\varphi _{k-p}^{n + 1}  - \\varphi _{k-p-1}^{n + 1}  =  {\\gamma _p \\left( {\\varphi _{k}^n  - \\varphi _{k - 1}^n } \\right)}  < 0  , \\quad  \\quad ( 7)</math>\n\nwhich implies that <math>\\varphi _j^{n + 1} </math> is '''NOT''' increasing, and we have a contradiction. Thus, monotonicity is '''NOT''' preserved for <math>\\gamma _p  < 0 </math>, which completes the proof.\n\n'''Theorem 2:''' ''Godunov’s Order Barrier Theorem''\n\nLinear one-step second-order accurate numerical schemes for the convection equation \n\n:<math> {{\\partial \\varphi } \\over {\\partial t}} + c{ { \\partial \\varphi } \\over {\\partial x}} = 0 , \\quad t > 0, \\quad x \\in \\mathbb{R} \\quad  \\quad (10)</math>\n\ncannot be monotonicity preserving unless\n\t\t\n:<math>\\sigma  = \\left| c \\right|{{\\Delta t} \\over {\\Delta x}} \\in \\mathbb{ N} , \\quad  \\quad (11)</math>\n\nwhere <math> \\sigma </math> is the signed [[Courant–Friedrichs–Lewy condition]] (CFL) number.\n\n''Proof'' - Godunov (1959)\n\nAssume a numerical scheme of the form described by equation (2) and choose\n\n:<math>\\varphi \\left( {0,x} \\right) = \\left( {{x \\over {\\Delta x}} - {1 \\over 2}} \\right)^2  - {1 \\over 4}, \\quad \\varphi _j^0  = \\left( {j - {1 \\over 2}} \\right)^2  - {1 \\over 4} . \\quad  \\quad (12)</math>\n\nThe exact solution is\n\t\t\t\n:<math>\n\\varphi \\left( {t,x} \\right) = \\left( {{{x - ct} \\over {\\Delta x}} - {1 \\over 2}} \\right)^2  - {1 \\over 4} . \\quad  \\quad (13)\n</math>\n\nIf we assume the scheme to be at least second-order accurate, it should produce the following solution exactly\n\n:<math>\n\\varphi _j^1  = \\left( {j - \\sigma  - {1 \\over 2}} \\right)^2  - {1 \\over 4}, \\quad \\varphi _j^0  = \\left( {j - {1 \\over 2}} \\right)^2  - {1 \\over 4}. \\quad  \\quad (14)\n</math>\n\nSubstituting into equation (2) gives:\n\n:<math>\n\\left( {j - \\sigma  - {1 \\over 2}} \\right)^2  - {1 \\over 4} = \\sum\\limits_m^{M} {\\gamma _m \\left\\{ {\\left( {j + m - {1 \\over 2}} \\right)^2  - {1 \\over 4}} \\right\\}}. \\quad  \\quad (15)\n</math>\n\nSuppose that the scheme '''IS''' monotonicity preserving, then according to the theorem 1 above, <math>\\gamma _m  \\ge 0 </math>.  \n\nNow, it is clear from equation (15) that\n\n:<math> \\left( {j - \\sigma  - {1 \\over 2}} \\right)^2  - {1 \\over 4} \\ge 0, \\quad \\forall j . \\quad  \\quad (16)</math>\n\nAssume <math>\\sigma  > 0, \\quad \\sigma  \\notin \\mathbb{ N} </math> and choose <math>j </math> such that <math> j > \\sigma  > \\left( j - 1 \\right) </math> . This implies that <math>\\left( {j - \\sigma } \\right) > 0 </math> and <math>\\left( {j - \\sigma  - 1} \\right) < 0 </math> .\n\nIt therefore follows that,\n\n:<math>\n\\left( {j - \\sigma  - {1 \\over 2}} \\right)^2  - {1 \\over 4} = \\left( j - \\sigma \\right) \\left(j - \\sigma - 1 \\right) < 0, \\quad   \\quad (17) </math>\n\nwhich contradicts equation (16) and completes the proof.\n\nThe exceptional situation whereby <math>\\sigma  = \\left| c \\right|{{\\Delta t} \\over {\\Delta x}} \\in \\mathbb{N} </math> is only of theoretical interest, since this cannot be realised with variable coefficients. Also, integer [[Courant–Friedrichs–Lewy condition|CFL]] numbers greater than unity would not be feasible for practical problems.\n\n==See also==\n*[[Finite volume method]]\n*[[Flux limiter]]\n*[[Total variation diminishing]]\n\n==References==\n*'''Godunov, Sergei K.''' (1954), ''Ph.D. Dissertation: Different Methods for Shock Waves'',  Moscow State University.\n*'''Godunov, Sergei K.''' (1959), A Difference Scheme for Numerical Solution of Discontinuous Solution of Hydrodynamic Equations, ''Math. Sbornik, 47, 271-306'', translated US Joint Publ. Res. Service, JPRS 7226, 1969.\n*'''Wesseling, Pieter ''' (2001), ''Principles of Computational Fluid Dynamics'', Springer-Verlag.\n\n==Further reading==\n*'''Hirsch, C.''' (1990), ''Numerical Computation of Internal and External Flows'', vol 2, Wiley.\n*'''Laney, Culbert B.''' (1998), ''Computational Gas Dynamics'', Cambridge University Press.\n*'''Toro, E. F.''' (1999), ''Riemann Solvers and Numerical Methods for Fluid Dynamics'', Springer-Verlag.\n*'''Tannehill, John C., et al.,''' (1997), ''Computational Fluid mechanics and Heat Transfer'', 2nd Ed., Taylor and Francis.\n\n[[Category:Numerical differential equations]]\n[[Category:Theorems in analysis]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Heun's method",
      "url": "https://en.wikipedia.org/wiki/Heun%27s_method",
      "text": "In [[mathematics]] and [[computational science]], '''Heun's method''' may refer to the '''improved'''<ref>{{Citation | last1=Süli | first1=Endre | last2=Mayers | first2=David | title=An Introduction to Numerical Analysis | publisher=[[Cambridge University Press]] | isbn=0-521-00794-1 | year=2003}}.</ref> or '''modified Euler's method''' (that is, the '''explicit trapezoidal rule'''<ref>\n{{Citation | last1=Ascher | first1=Uri M. | last2=Petzold | first2=Linda R.|author2-link=Linda Petzold | title=Computer Methods for Ordinary Differential Equations and Differential-Algebraic Equations | publisher=[[Society for Industrial and Applied Mathematics]] | location=Philadelphia | isbn=978-0-89871-412-8 | year=1998}}.</ref>), or a similar two-stage [[Runge–Kutta method]]. It is named after [[Karl Heun]] and is a [[numerical analysis|numerical]] procedure for solving [[ordinary differential equation]]s (ODEs) with a given [[Initial value problem|initial value]]. Both variants can be seen as extensions of the [[Euler method]] into two-stage second-order Runge–Kutta methods.\n\nThe procedure for calculating the numerical solution to the initial value problem via the improved Euler's method is:\n\n:<math>y'(t) = f(t,y(t)), \\qquad \\qquad y(t_0)=y_0, </math> \nby way of Heun's method, is to first calculate the intermediate value <math>\\tilde{y}_{i+1}</math> and then the final approximation  <math>y_{i+1}</math> at the next integration point.\n:<math>\\tilde{y}_{i+1} = y_i + h f(t_i,y_i)</math>\n:<math>y_{i+1} = y_i + \\frac{h}{2}[f(t_i, y_i) + f(t_{i+1},\\tilde{y}_{i+1})],</math>\n:\nwhere <math>h</math> is the step size and <math>t_{i+1}=t_i+h</math>.\n\n==Description==\nEuler’s method is used as the foundation for Heun’s method. Euler's method uses the line tangent to the function at the beginning of the interval as an estimate of the slope of the function over the interval, assuming that if the step size is small, the error will be small.  However, even when extremely small step sizes are used, over a large number of steps the error starts to accumulate and the estimate diverges from the actual functional value.\n\nWhere the solution curve is concave up, its tangent line will underestimate the vertical coordinate of the next point and vice versa for a concave down solution. The ideal prediction line would hit the curve at its next predicted point. In reality, there is no way to know whether the solution is concave-up or concave-down, and hence if the next predicted point will overestimate or underestimate its vertical value. The concavity of the curve cannot be guaranteed to remain consistent either and the prediction may overestimate and underestimate at different points in the domain of the solution.\nHeun’s Method addresses this problem by considering the interval spanned by the tangent line segment as a whole. Taking a concave-up example, the left tangent prediction line underestimates the slope of the curve for the entire width of the interval from the current point to the next predicted point. If the tangent line at the right end point is considered (which can be estimated using Euler’s Method), it has the opposite problem\n<ref>{{cite web\n|title=Numerical Methods for Solving Differential Equations \n|publisher=San Joaquin Delta College \n|url=http://calculuslab.deltacollege.edu/ODE/7-C-2/7-C-2-h.html \n|archiveurl=https://web.archive.org/web/20090212005921/http://calculuslab.deltacollege.edu/ODE/7-C-2/7-C-2-h.html\n|archivedate=2009-02-12}}</ref>\nThe points along the tangent line of the left end point have vertical coordinates which all underestimate those that lie on the solution curve, including the right end point of the interval under consideration. The solution is to make the slope greater by some amount. Heun’s Method considers the tangent lines to the solution curve at ''both'' ends of the interval, one which ''overestimates'', and one which ''underestimates'' the ideal vertical coordinates. A prediction line must be constructed based on the right end point tangent’s slope alone, approximated using Euler's Method. If this slope is passed through the left end point of the interval, the result is evidently too steep to be used as an ideal prediction line and overestimates the ideal point. Therefore, the ideal point lies approximately halfway between the erroneous overestimation and underestimation, the average of the two slopes.\n[[File:Heun's Method Diagram.jpg|thumb|right|alt=Heun's Method.|A diagram depicting the use of Heun's method to find a less erroneous prediction when compared to the lower order Euler's Method]]\nEuler’s Method is used to roughly estimate the coordinates of the next point in the solution, and with this knowledge, the original estimate is re-predicted or ''corrected''.<ref>\n{{Citation | last1=Chen\n| first1=Wenfang. \n| last2=Kee \n| first2=Daniel D. \n| title=Advanced Mathematics for Engineering and Science \n| publisher=World Scientific\n| location=MA, USA\n| isbn=981-238-292-5\n| year=2003}}.</ref> Assuming that the quantity <math>\\textstyle f(x, y)</math> on the right hand side of the equation can be thought of as the slope of the solution sought at any point <math>\\textstyle (x, y) </math>, this can be combined with the Euler estimate of the next point to give the slope of the tangent line at the right end-point. Next the average of both slopes is used to find the corrected coordinates of the right end interval.\n\n==Derivation==\n:<math>\\text{Slope}_{\\text{left}} = f(z_i, y_i)</math>\n:<math>\\text{Slope}_{\\text{right}} = f(z_i + h, y_i + h f(z_i, y_i))</math>\n:<math>\\text{Slope}_{\\text{ideal}} = (1/2) (\\text{Slope}_{\\text{left}} + \\text{Slope}_{\\text{right}})</math>\n\nUsing the principle that the slope of a line equates to the rise/run, the coordinates at the end of the interval can be found using the following formula:\n\n:<math>\\text{Slope}_{\\text{ideal}} = \\frac{\\Delta y}{h} </math>\n:<math>\\Delta y = h (\\text{Slope}_{\\text{ideal}})</math>\n\n:<math>x_{i+1} = x_i + h</math>, <math>\\textstyle y_{i+1} = y_i + \\Delta y</math>\n:<math>y_{i+1} = y_i + h \\text{Slope}_{\\text{ideal}}</math>\n:<math>y_{i+1} = y_{i} + \\frac{1}{2} h (\\text{Slope}_{\\text{left}} + \\text{Slope}_{\\text{right}})</math>\n\n:<math>y_{i+1} = y_{i} + \\frac{h}{2}(f(x_i, y_i) + f(x_i + h, y_i + hf(x_i, y_i)))</math>\n\nThe accuracy of the Euler method improves only linearly with the step size is decreased, whereas the Heun Method improves accuracy quadratically \n.<ref>{{cite web\n|title=The Euler-Heun Method\n|publisher=LiveToad.org \n|url=http://livetoad.org/Courses/Documents/214a/Notes/euler-heun_method.pdf \n}}</ref> The scheme can be compared with the [[Explicit and implicit methods|implicit]] [[trapezoidal method]], but with <math>f(t_{i+1},y_{i+1})</math> replaced by <math>f(t_{i+1},\\tilde{y}_{i+1})</math> in order to make it explicit. <math>\\tilde{y}_{i+1}</math> is the result of one step of [[Euler's method]] on the same initial value problem. So, Heun's method is a [[predictor-corrector method]] with forward [[Euler's method]] as predictor and [[trapezoidal method]] as corrector.\n\n==Runge–Kutta method==\n\nThe improved Euler's method is a two-stage [[Runge–Kutta method]], and can be written using the [[Butcher tableau]] (after [[John C. Butcher]]):\n\n{| cellpadding=3px cellspacing=0px\n|width=\"20px\"| || style=\"border-right:1px solid;\" | 0\n|- \n||| style=\"border-right:1px solid; border-bottom:1px solid;\" | 1 || style=\"border-bottom:1px solid;\" | 1\n| style=\"border-bottom:1px solid;\" |\n|-\n||| style=\"border-right:1px solid;\" | || 1/2 || 1/2\n|}\n\nThe other method referred to as Heun's method (also known as Ralston's method) has the Butcher table:<ref>\n{{Citation | last1=Leader | first1=Jeffery J.|  title=Numerical Analysis and Scientific Computation | publisher=[[Addison-Wesley]] | location=Boston | isbn=0-201-73499-0 | year=2004}}.</ref>\n\n{| cellpadding=3px cellspacing=0px\n|width=\"20px\"| || style=\"border-right:1px solid;\" | 0\n|- \n||| style=\"border-right:1px solid; border-bottom:1px solid;\" | 2/3 || style=\"border-bottom:1px solid;\" | 2/3\n| style=\"border-bottom:1px solid;\" |\n|-\n||| style=\"border-right:1px solid;\" | || 1/4 || 3/4\n|}\n\nThis method minimizes the truncation error.\n\n==References==\n{{commons category|Heun's method}}\n<references/>\n\n{{Numerical integrators}}\n\n[[Category:Numerical differential equations]]\n[[Category:Runge–Kutta methods]]"
    },
    {
      "title": "High-resolution scheme",
      "url": "https://en.wikipedia.org/wiki/High-resolution_scheme",
      "text": "{{short description|Scheme used in the numerical solution of partial differential equations}}\n[[Image:MUSCL HiRes.jpg|thumb|Typical high-resolution scheme based on MUSCL reconstruction.|300px|right|Typical high-resolution scheme based on MUSCL reconstruction.]]\n\n'''High-resolution schemes''' are used in the numerical solution of [[partial differential equations]] where high accuracy is required in the presence of shocks or discontinuities. They have the following properties:\n\n*Second- or higher-[[Order of accuracy|order]] spatial accuracy is obtained in smooth parts of the solution.\n*Solutions are free from spurious oscillations or wiggles.\n*High accuracy is obtained around shocks and discontinuities.\n*The number of mesh points containing the wave is small compared with a first-order scheme with similar accuracy.\n\nGeneral methods are often not adequate for accurate resolution of steep gradient phenomena; they usually introduce non-physical effects such as ''smearing'' of the solution or ''spurious oscillations''. Since publication of ''Godunov's order barrier theorem'', which proved that linear methods cannot provide non-oscillatory solutions higher than first order (Godunov 1954, Godunov 1959), these difficulties have attracted a lot of attention and a number of techniques have been developed that largely overcome these problems. To avoid spurious or non-physical oscillations where shocks are present, schemes that exhibit a [[Total Variation Diminishing]] (TVD) characteristic are especially attractive. Two techniques that are proving to be particularly effective are [[MUSCL scheme|MUSCL]] (''Monotone Upstream-Centered Schemes for Conservation Laws'') a [[flux limiter|flux/slope limiter]] method (van Leer 1979, Hirsch 1990, Tannehill 1997, Laney 1998, Toro 1999) and the WENO (''Weighted Essentially Non-Oscillatory'') method (Shu 1998, Shu 2009). Both methods are usually referred to as ''high resolution schemes'' (see diagram).\n\n[[MUSCL scheme|MUSCL]] methods are generally second-order accurate in smooth regions (although they can be formulated for higher orders) and provide good resolution, monotonic solutions around discontinuities. They are straightforward to implement and are computationally efficient.\n\nFor problems comprising both shocks and complex smooth solution structure, [[WENO methods|WENO schemes]] can provide higher accuracy than second-order schemes along with good resolution around discontinuities. Most applications tend to use a fifth order accurate WENO scheme, whilst higher order schemes can be used where the problem demands improved accuracy in smooth regions.\n\nThe method of [[holistic discretisation]] systematically analyses subgrid scale dynamics to algebraically construct closures for numerical discretisations that are both accurate to any specified order of error in smooth regions, and automatically adapt to cater for rapid grid variations through the algebraic learning of subgrid structures (Roberts 2003).  [http://www.maths.adelaide.edu.au/anthony.roberts/holistic1.php A web service analyses any PDE in a class that may be submitted]. \n\n==See also==\n*[[Godunov's theorem]]\n*[[Sergei K. Godunov]]\n*[[Total variation diminishing]]\n*[[Shock capturing method]]\n\n==References==\n*Godunov, Sergei K. (1954), ''Ph.D. Dissertation: Different Methods for Shock Waves'',  Moscow State University.\n*Godunov, Sergei K. (1959), A Difference Scheme for Numerical Solution of Discontinuous Solution of Hydrodynamic Equations, ''Math. Sbornik, 47, 271–306'', translated US Joint Publ. Res. Service, JPRS 7226, 1969.\n*Harten, A. (1983), High Resolution Schemes for Hyperbolic Conservation Laws. ''J. Comput. Phys''. 49, 357&ndash;393.\n*Hirsch, C. (1990), ''Numerical Computation of Internal and External Flows'', vol 2, Wiley.\n*Laney, Culbert B. (1998), ''Computational Gas Dynamics'', Cambridge University Press.\n*Roberts, A. J. (2003); A holistic finite difference approach models linear dynamics consistently; In ''Mathematics of Computation'' 72, pp. 247--262. doi:10.1090/S0025-5718-02-01448-5.\n*Shu, C-W. (1998), ''Essentially Non-oscillatory and Weighted Essential Non-oscillatory Schemes for Hyperbolic Conservation Laws''. In: Cockburn, B., Johnson, C., Shu, C-W., Tadmor, E. (Eds.), ''Advanced Numerical Approximation of Nonlinear Hyperbolic Equations'', Lecture Notes in Mathematics, vol 1697. Springer, 325–432.\n*Shu, C-W. (2009), High Order Weighted Essentially Non-oscillatory Schemes for Convection Dominated Problems, ''SIAM Review'' 51, No. 1, 82–126.\n*Tannehill, John C., et al. (1997), ''Computational Fluid mechanics and Heat Transfer'', 2nd Ed., Taylor and Francis.\n*Toro, E. F. (1999), ''Riemann Solvers and Numerical Methods for Fluid Dynamics'', Springer-Verlag.\n*Van Leer, B. (1979), Towards the ultimate conservative difference scheme V. A second order sequel to Godunov's method. ''Comp. Phys''. 32, 101–136.\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:High-Resolution Scheme}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "History of numerical solution of differential equations using computers",
      "url": "https://en.wikipedia.org/wiki/History_of_numerical_solution_of_differential_equations_using_computers",
      "text": "{{more footnotes|date=January 2015}}\n'''Differential equations''',<ref>{{Cite web|url=http://mathworld.wolfram.com/DifferentialEquation.html|title=Differential Equation|last=W.|first=Weisstein, Eric|website=mathworld.wolfram.com|language=en|access-date=2016-03-08}}</ref> in particular [[Euler equations]],<ref>{{Cite web|url=http://mathworld.wolfram.com/EulerDifferentialEquation.html|title=Euler Differential Equation|last=W.|first=Weisstein, Eric|website=mathworld.wolfram.com|language=en|access-date=2016-03-08}}</ref> rose in prominence during World War II in calculating the accurate trajectory<ref>{{Cite web|url=http://archive.geogebra.org/en/upload/files/nikenuke/projectile06d.html|title=Projectile motion - GeoGebra Dynamic worksheet|website=archive.geogebra.org|access-date=2016-03-08}}</ref> of ballistics,<ref>{{Cite web|url=http://www.exteriorballistics.com/ebexplained/4th/30.cfm|title=exterior ballistics|website=www.exteriorballistics.com|access-date=2016-03-08}}</ref> both rocket-propelled and gun or cannon type projectiles. Originally, mathematicians used the simpler [[calculus]]<ref>{{Cite web|url=http://mathworld.wolfram.com/topics/DifferentialEquations.html|title=Differential Equations -- from Wolfram MathWorld|last=W.|first=Weisstein, Eric|website=mathworld.wolfram.com|language=en|access-date=2016-03-08}}</ref> of earlier centuries to determine velocity, thrust, elevation, curve, distance, and other parameters.\n\nNew weapons, however, such as Germany's giant cannons,  the \"[[Paris Gun]]<ref>{{Cite web|url=http://www.astronautix.com/lvs/parisgun.htm|title=Paris Gun|website=www.astronautix.com|access-date=2016-03-08|deadurl=yes|archiveurl=https://web.archive.org/web/20171105000000/http://www.astronautix.com/lvs/parisgun.htm|archivedate=2017-11-05|df=}}</ref>\" (Encyclopedia Astronautica) and \"[[Big Bertha (howitzer)|Big Bertha]],\" and the [[V-2 rocket]], meant that projectiles would travel hundreds of miles in distance and dozens of miles in height, in all weathers. As a result, variables such as diminished wind resistance in thin atmospheres and changes in [[gravitational pull]] reduced accuracy using the historic methodology. There was the additional problem of planes that could now fly hundreds of miles an hour. Differential equations were applied to [[stochastic process]]es. Developing machines that could speed up human calculation of differential equations led in part to the creation of the modern computer through the efforts of [[Vannevar Bush]], [[John von Neumann]] and others.\n\nAccording to Mary Croarken in her paper \"Computing in Britain During World War II,\" by 1945, the Cambridge Mathematical Laboratory created by [[John Lennard-Jones]] utilized the latest computing devices to perform the equations. These devices included a model \"[[differential analyser]],\" and the [[Mallock machine]], described as \"an electrical simultaneous equation solver.\" According to Croarken, the Ministry was also interested in the new arrival of a differential analyzer accommodating eight integrators. This exotic computing device built by Metropolitan-Vickers in 1939 consisted of wheel and disk mechanisms that could provide descriptions and solutions  for differential equations. Output resulted in a plotted graph.\n\nAt the same time, in the United States, [[analog computer]] pioneer Vannevar Bush took on a similar role to that of Lennard-Jones in the military effort after President [[Franklin Delano Roosevelt]] entrusted him with the bulk of wartime research into automatic control of fire power using machines and computing devices.\n\nAccording to [[Sarah Bergbreiter]] in her paper \"Moving from Practice to Theory: Automatic Control after World War II,\" fire control for the downing of enemy aircraft by anti-aircraft guns was the priority. The analog electro-mechanical computing machines plotted the differential firing data while servos created by H.L. Hazen adapted the data to the guns for precise firing control and accuracy. Other improvements of a similar type by Bell Labs increased firing stability so that output from the differential engines could be fully used to compensate for stochastic behaviors of enemy aircraft and large guns. A new age of intelligent warfare had begun.\n\nThis work at [[MIT]] and Bell Labs would later lead to [[Norbert Wiener]]'s development of the electronic computer and the science of [[cybernetics]] for the same purpose, speeding the differential calculation process exponentially and taking one more giant step toward the creation of the modern digital computer using [[von Neumann architecture]]. Dr. von Neumann was one of the original mathematicians employed in the development of differential equations for ballistic warfare.\n\n== See also ==\n\n*[[Numerical ordinary differential equations]]\n*[[Numerical partial differential equations]]\n\n== References ==\n{{Reflist}}\n\n* Croarken, Mary. \"Computing in Britain During World War II,\" IEE History of Technology Summer Meeting 6 July 2002. [http://www.iee.org/OnComms/pn/History/HistoryWk_Computing_in_Britain.pdf]\n* Bergbreiter, Sarah. \"Moving from Practice to Theory: Automatic Control after World War II.\" Student paper: HIS 285S: History of Science, University of California, Berkeley. [http://www.eecs.berkeley.edu/~sbergbre/publications/BergbreiterHIS285S.pdf]\n* MacRae, Norman. ''John von Neumann: The Scientific Genius Who Pioneered the Modern Computer, Game Theory, Nuclear Deterrence, and Much More.'' N.Y.: Pantheon Books, 1992.\n\n[[Category:Numerical differential equations]]\n[[Category:History of computing]]"
    },
    {
      "title": "Immersed boundary method",
      "url": "https://en.wikipedia.org/wiki/Immersed_boundary_method",
      "text": "{{More footnotes|date=April 2017}}\n\nIn [[computational fluid dynamics]], the '''immersed boundary method''' originally referred to an approach developed by [[Charles S. Peskin|Charles Peskin]] in 1972 to simulate fluid-structure (fiber) interactions. Treating the coupling of the structure deformations and the fluid flow poses a number of challenging problems for [[Computer simulation|numerical simulations]] (the elastic boundary changes the flow of the fluid and the fluid moves the elastic boundary simultaneously). In the immersed boundary method the fluid is represented on an [[Lagrangian and Eulerian coordinates|Eulerian coordinate]] and the structure is represented on a [[Lagrangian and Eulerian coordinates|Lagrangian coordinate]]. For [[Newtonian fluids]] governed by the incompressible [[Navier–Stokes equations]], the fluid equations are\n\n:<math>\n\\rho\n\\left(\\frac{\\partial{u}({x},t)}{\\partial{t}} + {u}\\cdot\\nabla{u}\\right)\n= -\\nabla p + \\mu\\, \\Delta u(x,t) + f(x,t) \n</math>\n\nand in case of incompressible fluids (assuming constant density) we have the condition\n\n:<math>\n\\nabla \\cdot u = 0. \\,\n</math>\n\nThe immersed structures are typically represented as a collection of one-dimensional fibers, denoted by <math> \\Gamma </math>. Each fiber can be viewed as a parametric curve <math> X(s,t) </math> where <math> s </math> is the parameter and <math>t  </math> is time. Physics of the fiber is represented via the fiber force distribution <math> F(s,t) </math>. Spring forces, bending resistance or any other type of behavior can be built into this term. The force exerted by the structure on the fluid is then interpolated as a source term in the momentum equation using\n\n:<math>\nf(x,t) = \\int_\\Gamma F(s,t) \\, \\delta\\big(x - X(s,t)\\big) \\, ds,\n</math>\n\nwhere <math> \\delta </math> is the [[Dirac delta function|Dirac {{mvar|δ}} function]]. The forcing can be extended to multiple dimensions to model elastic surfaces or three-dimensional solids. Assuming a massless structure, the elastic fiber moves with the local fluid velocity and can be interpolated via the delta function\n\n:<math>\n\\frac{\\partial X(s,t)}{\\partial t} = u(X,t) = \\int_\\Omega u(x,t) \\, \\delta\\big(x - X(s,t)\\big)  \\, dx,\n</math>\n\nwhere <math> \\Omega </math> denotes the entire fluid domain. \nDiscretization of these equations can be done by assuming an Eulerian grid on the fluid and a separate Lagrangian grid on the fiber. \nApproximations of the Delta distribution by smoother functions will allow us to interpolate between the two grids. \nAny existing fluid solver can be coupled to a solver for the fiber equations to solve the Immersed Boundary equations.\nVariants of this basic approach have been applied to simulate a wide variety of mechanical systems involving elastic structures which interact with fluid flows.\n\nSince the original development of this method by Peskin, a variety of approaches have been developed to simulate flow over complicated immersed bodies on grids that do not conform to the surface of the body. These include methods such as the immersed interface method, the Cartesian grid method, the ghost fluid method and the cut-cell method. Mittal and Iaccarino<ref>{{harvnb|Mittal|Iaccarino|2005}}.</ref> refer to all these (and other related) methods as Immersed Boundary Methods and provide various categorizations of these methods. From the point of view of implementation, they categorize immersed boundary methods into ''continuous forcing'' and ''discrete forcing'' methods. In the former, a force term is added to the continuous Navier-Stokes equations before discretization, whereas in the latter, the forcing is applied (explicitly or implicitly) to the discretized equations. Under this taxonomy, Peskin's original method is a ''continuous forcing'' method whereas Cartesian grid, cut-cell and the ghost-fluid methods are ''discrete forcing'' methods.\n\n== See also ==\n*[[Stochastic Eulerian Lagrangian method]]\n*[[Stokesian dynamics]]\n*[[Volume of fluid method]]\n*[[Level-set method]]\n*[[Marker-and-cell method]]\n\n== Software: numerical codes ==\n* [[Advanced Simulation Library]]\n* [http://www.atzberger.org/mango-selm/ MANGO-SELM : Stochastic Eulerian Lagrangian Methods, P. Atzberger, UCSB]\n* [http://www.math.ucsb.edu/~atzberg/SIB_Codes/index.html Stochastic Immersed Boundary Methods in 3D, P. Atzberger, UCSB]\n* [http://www.math.utah.edu/IBIS/ Immersed Boundary Method for Uniform Meshes in 2D, A. Fogelson, Utah]\n* [https://github.com/IBAMR/IBAMR IBAMR : Immersed Boundary Method for Adaptive Meshes in 3D, B. Griffith, NYU.]\n* [http://espressomd.org/html/doc/advanced_methods.html#immersed-boundary-method-for-soft-elastic-objects ESPResSo: Immersed Boundary Method for soft elastic objects]\n* [https://sourceforge.net/projects/foam-extend/files/ foam extend]\n\n==Notes==\n{{Reflist}}\n\n==References==\n*{{Cite journal\n | last = Atzberger\n | first = Paul J.\n | title = Stochastic Eulerian Lagrangian Methods for Fluid Structure Interactions with Thermal Fluctuations\n | journal = Journal of Computational Physics\n | volume = 230\n | issue = 8\n | pages = 2821–2837\n | year = 2011\n | doi = 10.1016/j.jcp.2010.12.028\n | ref = harv\n| arxiv = 1009.5648\n | bibcode = 2011JCoPh.230.2821A\n }}\n*{{Cite journal\n | last1 = Atzberger\n | first1 = Paul J.\n | first2 = Peter R.\n | last2 = Kramer\n | first3 = Charles S.\n | last3 = Peskin\n | title = A Stochastic Immersed Boundary Method for Fluid-Structure Dynamics at Microscopic Length Scales\n | journal = Journal of Computational Physics\n | volume = 224\n | issue = 2\n | pages = 1255–1292\n | year = 2007\n | doi = 10.1016/j.jcp.2006.11.015\n | ref = harv\n| arxiv = 0910.5748\n | bibcode = 2007JCoPh.224.1255A\n }}\n*{{Citation\n | last1 = Jindal\n | first1 = S.\n | title = SAE Technical Paper Series\n | volume = 1\n | last2 = Khalighi\n | first2 = B.\n | last3 = Johnson\n | first3 = J.\n | last4 = Chen\n | first4 = K.\n | chapter = The Immersed Boundary CFD Approach for Complex Aerodynamics Flow Predictions\n | series = SAE Technical Paper\n | issue = 2007–01–0109\n | year = 2007\n | doi = 10.4271/2007-01-0109\n}}.\n*{{Cite journal\n | last1 = Kim\n | first1 = Jungwoo\n | last2 = Kim\n | first2 = Dongjoo\n | last3 = Choi\n | first3 = Haecheon\n | title = An Immersed-Boundary Finite Volume Method for Simulations of Flow in Complex Geometries\n | journal = Journal of Computational Physics\n | volume = 171\n | issue = 1\n | pages = 132–150\n | year = 2001\n | doi = 10.1006/jcph.2001.6778\n | ref = harv\n| bibcode = 2001JCoPh.171..132K\n }}\n*{{Cite journal\n | last1 = Mittal\n | first1 = Rajat\n | last2 = Iaccarino\n | first2 = Gianluca\n | title = Immersed Boundary Methods\n | journal = Annual Review of Fluid Mechanics\n | volume = 37\n | issue = 1\n | pages = 239–261\n | year = 2005\n | doi = 10.1146/annurev.fluid.37.061903.175743\n | ref = harv\n| bibcode = 2005AnRFM..37..239M\n }}\n*{{Cite journal\n | last1 = Moria\n | first1 = Yoichiro\n | last2 = Peskin\n | first2 = Charles S.\n | title = Implicit Second-Order Immersed Boundary Methods with Boundary Mass\n | journal = Computer Methods in Applied Mechanics and Engineering\n | volume = 197\n | issue = 25–28\n | pages = 2049–2067\n | year = 2008\n | doi = 10.1016/j.cma.2007.05.028\n | ref = harv\n| bibcode = 2008CMAME.197.2049M\n }}\n*{{Cite journal\n | last = Peskin\n | first = Charles S.\n | title = The immersed boundary method\n | journal = Acta Numerica\n | volume = 11\n | pages = 479–517\n | year = 2002\n | doi = 10.1017/S0962492902000077\n | ref = harv\n}}\n*{{Cite journal\n | last = Peskin\n | first = Charles S.\n | title = Numerical analysis of blood ﬂow in the heart\n | journal = Journal of Computational Physics\n | volume = 25\n | issue = 3\n | pages = 220–252\n | year = 1977\n | doi = 10.1016/0021-9991(77)90100-0\n | ref = harv\n| bibcode = 1977JCoPh..25..220P\n }}\n*{{Cite journal\n | last1 = Roma\n | first1 = Alexandre M.\n | last2 = Peskin\n | first2 = Charles S.\n | last3 = Berger\n | first3 = Marsha J.\n | title = An Adaptive Version of the Immersed Boundary Method\n | journal = Journal of Computational Physics\n | volume = 153\n | issue = 2\n | pages = 509–534\n | year = 1999\n | doi = 10.1006/jcph.1999.6293\n | ref = harv\n| bibcode = 1999JCoPh.153..509R\n }}\n*{{Cite journal\n | last1 = Singh Bhalla\n | first1 = Amneet Pal\n | last2 = Bale\n | first2 = Rahul\n | last3 = Griffith\n | first3 = Boyce E.\n | last4 = Patankar\n | first4 = Neelesh A.\n | title = A unified mathematical framework and an adaptive numerical method for fluid–structure interaction with rigid, deforming, and elastic bodies\n | journal = Journal of Computational Physics\n | volume = 250\n | pages = 446–476\n | year = 2013\n | doi = 10.1016/j.jcp.2013.04.033\n | ref = harv\n| bibcode = 2013JCoPh.250..446B\n }}\n*{{Cite journal\n | last1 = Zhu\n | first1 = Luoding\n | last2 = Peskin\n | first2 = Charles S.\n | title = Simulation of a Flapping Flexible Filament in a Flowing Soap Film by the Immersed Boundary Method\n | journal = Journal of Computational Physics\n | volume = 179\n | issue = 2\n | pages = 452–468\n | year = 2002\n | doi = 10.1006/jcph.2002.7066\n | ref = harv\n| bibcode = 2002JCoPh.179..452Z\n }}\n\n{{Numerical PDE}}\n\n[[Category:Fluid mechanics]]\n[[Category:Computational fluid dynamics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Infinite element method",
      "url": "https://en.wikipedia.org/wiki/Infinite_element_method",
      "text": "The '''infinite element method''' is a [[numerical analysis|numerical method]] for solving problems of engineering and [[mathematical physics]]. It is a modification of [[finite element method]]. The method divides the domain concerned into infinitely many sections. In the first instance this results in an infinite set of equations, which is then reduced to a finite set.<ref>{{Cite book|title=Infinite Element Methods|last=Ying|first=Lung-an|publisher=|year=1995|isbn=978-3-528-06610-9|location=|pages=}}</ref> The method is commonly used to solve acoustic problems. <ref>{{Cite book | doi=10.1007/978-94-015-9095-2_15|chapter = Infinite Element Methods|title = IUTAM Symposium on Computational Methods for Unbounded Domains| volume=49| pages=143–150|series = Fluid Mechanics and its Applications|year = 1998|last1 = Gerdes|first1 = K.| isbn=978-90-481-5106-6}}</ref><ref>{{Cite journal |last=Autrique |first=Jean-Christophe |last2=Magoulès |first2=Frédéric |date=July 2006 |title=Studies of an infinite element method for acoustical radiation |journal=Applied Mathematical Modelling |volume=30 |issue=7 |pages=641–655 |doi=10.1016/j.apm.2005.08.022 |issn=0307-904X}}</ref>\n==References==\n{{Reflist}}\n\n{{Numerical PDE}}\n\n{{Authority control}}\n\n[[Category:Continuum mechanics]]\n[[Category:Finite element method]]\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n[[Category:Structural analysis]]"
    },
    {
      "title": "Interval boundary element method",
      "url": "https://en.wikipedia.org/wiki/Interval_boundary_element_method",
      "text": "{{Underlinked|date=September 2016}}\n{{expert needed|mathematics|date=February 2009}}\n'''Interval boundary element method''' is classical [[boundary element method]] with the interval [[Parameter|parameters]].<BR>\nBoundary element method is based on the following [[integral equation]]\n\n<math> c\\cdot u=\\int\\limits_{\\partial \\Omega}\\left(G\\frac{\\partial u}{\\partial n} - \\frac{\\partial G}{\\partial n}u\\right)dS </math>\n\nThe exact interval solution on the boundary can be defined in the following way:\n\n<math> \\tilde{u}(x)=\\{u(x,p):c(p)\\cdot u(p)=\\int\\limits_{\\partial \\Omega}\\left(G(p)\\frac{\\partial u(p)}{\\partial n} - \\frac{\\partial G(p)}{\\partial n}u(p)\\right)dS, p\\in\\hat{p} \\}</math>\n\nIn practice we are interested in the smallest interval which contain the exact solution set\n\n<math> \\hat{u}(x)=hull \\ \\tilde {u}(x)=hull \\{u(x,p):c(p)\\cdot u(p)=\\int\\limits_{\\partial \\Omega}\\left(G(p)\\frac{\\partial u(p)}{\\partial n} - \\frac{\\partial G(p)}{\\partial n}u(p)\\right)dS, p\\in\\hat{p} \\}</math>\n\nIn similar way it is possible to calculate the interval solution inside the boundary <math> \\Omega </math>.\n\n==References==\n* T. Burczyński and J. Skrzypczyk, The fuzzy boundary element method: a new solution concept, Proceedings of XII Polish conference on computer methods in mechanics, Warsaw-Zegrze, Poland (1995), pp.&nbsp;65–66.\n* T. Burczynski, J. Skrzypczyk J. The fuzzy boundary element method: a new methodology. Series Civil Eng, Vol. 83. Gliwice: Sci Fasc of Silesian Tech Univ; 1995, pp.&nbsp;25–42. \n* J. Skrzypczyk, A Note on Interval Fredholm Integral Equations. Zeszyty Naukowe Politechniki Śląskiej, Seria Budownictwo, Z.85, pp.&nbsp;75–83, 1998\n* T. Burczynski, J. Skrzypczyk, Fuzzy aspects of the boundary element method, Engineering Analysis with Boundary Elements, Vol.19, No.3, pp.&nbsp;209–216, 1997\n* H. Witek, Boundary element method in analysis of civil engineering structures with uncertain parameters. Ph.D. Dissertation, Silesian University of Technology, Faculty of Civil Engineering, Poland, 2005\n* B.F. Zalewski, R.L. Mullen, R.L. Muhanna, “Boundary Element Analysis of Systems Using Interval Methods”, Proceedings of the NSF Workshop on Modeling Errors and Uncertainty in Engineering Computations, Georgia Tech Savannah, February 2006.\n* B.F. Zalewski and R.L. Mullen, \"Interval Bounds on the Local Discretization Error in Boundary Element Analysis for Domains with Singular Flux\", SAE 2008 Reliability and Robust Design in Automotive Engineering, SP-2170, Pages 237-246, 2008.\n* B.F. Zalewski and R.L. Mullen, \"Discretization Error in Boundary Element Analysis using Interval Methods\", SAE 2007 International Transactions Journal of Passenger Cars: Mechanical Systems, Volume 116, Issue 6, Pages 1353-1361, 2008.\n* B.F. Zalewski and R.L. Mullen, \"Point-wise Discretization Errors in Boundary Element Method for Elasticity Problem\", Third NSF Workshop on Reliable Engineering Computing, Pages 429-457, February 2008.\n* B.F. Zalewski, “Uncertainties in the Solutions to Boundary Element Method: An Interval Approach”, Case Western Reserve University, Ph.D. Dissertation, © 2008.\n* B.F. Zalewski and R.L. Mullen, “Local Discretization Error Bounds Using Interval Boundary Element Method”, International Journal for Numerical Methods in Engineering, Volume 78, Issue 4, April 2009, Pages 403-428.\n* A. Piasecka Belkhayat, Interval boundary element method for 2D transient diffusion problem, Engineering Analysis with Boundary Elements, Volume 32, Issue 5, May 2008, Pages 424-430\n* B.F. Zalewski, R.L. Mullena, and R.L. Muhanna, \"Interval Boundary Element Method in the Presence of Uncertain Boundary Conditions, Integration Errors, and Truncation Errors\", Engineering Analysis with Boundary Elements, Volume 33, Issue 4, April 2009, Pages 508-513. [https://dx.doi.org/10.1016/j.enganabound.2008.08.006]\n* B.F. Zalewski, R.L. Mullen, and R.L. Muhanna, “Fuzzy Boundary Element Method for Geometric Uncertainty in Elasticity Problem”, SAE 2009 International Journal of Materials and Manufacturing, Volume 2, Issue 1, Pages 310-316, 2009.\n* B.F. Zalewski and R.L. Mullen, “Worst Case Bounds on the Point-wise Discretization Error in Boundary Element Method for the Elasticity Problem”, Computer Methods in Applied Mechanics and Engineering, Volume 198, Issue 37-40, Pages 2996-3005, 2009.\n* B.F. Zalewski and R.L. Mullen, “Worst Case Point-wise Discretization Error Bounds for Systems with Geometrically Induced Singular Flux Solutions Using Interval Boundary Element Method”, ASCE Journal of Engineering Mechanics, Volume 136, Issue 6, Pages 710-720, 2010.\n* B.F. Zalewski, \"Fuzzy Boundary Element Method for Material Uncertainty in Steady State Heat Conduction\", SAE 2010 International Journal of Materials and Manufacturing, Volume 3, Issue 1, Pages 372-379, 2010.\n* B.F. Zalewski and W.B. Dial, \"Fuzzy Boundary Element Method with Uncertain Shear Modulus in Linear Plane Strain Elasticity\", SAE 2011 International Journal of Materials and Manufacturing, Volume 4, Issue 1, Pages 947-956, 2011.\n* A. Piasecka-Belkhayat, \"Interval Boundary Element Method for Transient Diffusion Problem in Two-Layered Domain\", Journal of Theoretical and Applied Mechanics, Volume 49, Issue 1, Pages 265-276, 2011.\n* A. Piasecka-Belkhayat, \"Interval Boundary Element Method for 2D Transient Diffusion Problem Using the Directed Interval Arithmetic\", Engineering Analysis with Boundary Elements, Volume 35, Issue 3, Pages 259-263, 2011.\n\n==See also==\n[[Interval finite element]]\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "L-stability",
      "url": "https://en.wikipedia.org/wiki/L-stability",
      "text": "{{context|date=March 2012}}\n\n'''L-stability''' is a special case of [[Stiff_equation#A-stability | A-stability]], a property of [[Runge–Kutta method]]s for solving  [[ordinary differential equations]].\nA method is L-stable if it is [[Stiff_equation#A-stability | A-stable]] and <math> \\phi(z) \\to 0 </math> as <math> z \\to \\infty </math>, where <math>\\phi</math> is the stability function of the method (the stability function of a Runge–Kutta method is a [[rational function]] and thus the limit as <math> z \\to +\\infty </math> is the same as the limit as <math> z \\to -\\infty</math>). L-stable methods are in general very good at integrating [[stiff equation]]s.\n\n== References ==\n* {{citation | first1 = Ernst | last1 = Hairer | first2 = Gerhard | last2 = Wanner | year = 1996 | title = Solving ordinary differential equations II: Stiff and differential-algebraic problems | edition = second | publisher = [[Springer-Verlag]] | location = Berlin | isbn = 978-3-540-60452-5 | at = section IV.3}}.\n\n[[Category:Numerical differential equations]]\n\n\n{{mathapplied-stub}}"
    },
    {
      "title": "Lax equivalence theorem",
      "url": "https://en.wikipedia.org/wiki/Lax_equivalence_theorem",
      "text": "In [[numerical analysis]], the '''Lax equivalence theorem''' is the fundamental theorem in the analysis of [[finite difference method]]s for the numerical solution of [[partial differential equation]]s. It states that for a [[Numerical_methods_for_ordinary_differential_equations#Consistency_and_order|consistent]] finite difference method for a [[well-posed]] linear [[initial value problem]], the method is [[Numerical_methods_for_ordinary_differential_equations#Convergence|convergent]] if and only if it is [[Numerical stability#Stability in numerical differential equations|stable]].<ref>{{Cite book\n  | last = Strikwerda\n  | first = John C.\n  | title = Finite Difference Schemes and Partial Differential Equations\n  | edition = 1st\n  | publisher = Chapman & Hall\n  | year = 1989\n  | pages = 26, 222\n  | isbn = 0-534-09984-X\n}}</ref>\n\nThe importance of the theorem is that while convergence of the solution of the finite difference method to the solution of the partial differential equation is what is desired, it is ordinarily difficult to establish because the numerical method is defined by a [[recurrence relation]] while the [[differential equation]] involves a [[Differentiable function|differentiable]] function. However, consistency—the requirement that the finite difference method approximate the correct partial differential equation—is straightforward to verify, and stability is typically much easier to show than convergence (and would be needed in any event to show that [[round-off error]] will not destroy the computation). Hence convergence is usually shown via the Lax equivalence theorem.\n\nStability in this context means that a [[matrix norm]] of the matrix used in the iteration is at most [[unity (mathematics)|unity]], called (practical) Lax–Richtmyer stability.<ref>\n{{Cite book\n | last = Smith\n | first = G. D.\n | title = Numerical Solution of Partial Differential Equations: Finite Difference Methods |edition=3rd\n | publisher = Oxford University Press\n | year = 1985\n | pages = 67–68\n | isbn = 0-19-859641-3\n}}</ref> Often a [[von Neumann stability analysis]] is substituted for convenience, although von Neumann stability only implies Lax–Richtmyer stability in certain cases.\n\nThis theorem is due to [[Peter Lax]]. It is sometimes called the '''Lax–Richtmyer theorem''', after Peter Lax and [[Robert D. Richtmyer]].<ref>{{cite journal |last=Lax |first=P. D. |last2=Richtmyer |first2=R. D. |title=Survey of the Stability of Linear Finite Difference Equations |journal=[[Communications on Pure and Applied Mathematics|Comm. Pure Appl. Math.]] |volume=9 |year=1956 |pages=267–293 |mr=79204 |doi=10.1002/cpa.3160090206 }}</ref>\n\n== References==\n{{Reflist}}\n\n\n[[Category:Numerical differential equations]]\n[[Category:Theorems in analysis]]\n\n\n{{mathapplied-stub}}"
    },
    {
      "title": "Lax–Friedrichs method",
      "url": "https://en.wikipedia.org/wiki/Lax%E2%80%93Friedrichs_method",
      "text": "The '''Lax–Friedrichs method''', named after [[Peter Lax]] and [[Kurt O. Friedrichs]], is a [[numerical analysis|numerical]] method for the solution of [[hyperbolic partial differential equation]]s based on [[finite difference]]s.  The method can be described as the [[FTCS scheme|FTCS (forward in time, centered in space) scheme]] with an [[artificial viscosity]] term of 1/2.  One can view the Lax–Friedrichs method as an alternative to [[Godunov's scheme]], where one avoids solving a [[Riemann problem]] at each cell interface, at the expense of adding artificial viscosity.\n\n==Illustration for a Linear Problem==\nConsider a one-dimensional, linear hyperbolic partial differential equation for <math>u(x,t)</math> of the form:\n\n: <math> u_t + au_x = 0\\,</math>\n\non the domain\n\n: <math> b \\leq x \\leq c,\\; 0 \\leq t \\leq d</math>\n\nwith initial condition\n\n: <math>u(x,0) = u_0(x)\\,</math>\n\nand the boundary conditions\n\n: <math>u(b,t) = u_b(t)\\,</math> \n: <math>u(c,t) = u_c(t).\\,</math>\n\nIf one discretizes the domain <math>(b, c) \\times (0, d)</math> to a grid with equally spaced points with a spacing of <math>\\Delta x</math> in the <math>x</math>-direction and <math>\\Delta t</math> in the <math>t</math>-direction, we define \n\n: <math>u_i^n = u(x_i, t^n) \\text{ with } x_i = b + i\\,\\Delta x ,\\, t^n = n\\,\\Delta t \\text{ for } i = 0,\\ldots,N ,\\, n = 0,\\ldots,M,</math> \n\nwhere \n\n: <math>N = \\frac{c - b}{\\Delta x} ,\\, M = \\frac{d}{\\Delta t}</math> \n\nare integers representing the number of grid intervals.  Then the Lax–Friedrichs method for solving the above partial differential equation is given by:\n\n: <math>\\frac{u_i^{n+1} - \\frac{1}{2}(u_{i+1}^n + u_{i-1}^n)}{\\Delta t} + a\\frac{u_{i+1}^n - u_{i-1}^n}{2\\,\\Delta x} = 0</math>\n\nOr, rewriting this to solve for the unknown <math>u_i^{n+1},</math>\n\n: <math> u_i^{n+1} = \\frac{1}{2}(u_{i+1}^n + u_{i-1}^n) - a\\frac{\\Delta t}{2\\,\\Delta x}(u_{i+1}^n - u_{i-1}^n)\\,</math>\n\nWhere the initial values and boundary nodes are taken from\n\n: <math>u_i^0 = u_0(x_i)</math>\n: <math>u_0^n = u_b(t^n)</math>\n: <math>u_N^n = u_c(t^n).</math>\n\n== Extensions to Nonlinear Problems ==\n\nA nonlinear hyperbolic conservation law is defined through a flux function <math> f </math>:\n\n: <math> u_t + ( f(u) )_x = 0. </math>\n\nIn the case of <math> f(u) = a u </math>, we end up with a scalar linear problem.  Note that in general, <math> u </math> is a vector with <math>m</math> equations in it.\nThe generalization of the Lax-Friedrichs method to nonlinear systems takes the form<ref>LeVeque, Randall J. ''Numerical Methods for Conservation Laws\", Birkhauser Verlag, 1992, p. 125.</ref>\n\n: <math>  u_i^{n+1} = \\frac{1}{2}(u_{i+1}^n + u_{i-1}^n) - \\frac{\\Delta t}{2\\,\\Delta x}( f( u_{i+1}^n ) - f( u_{i-1}^n ) ).</math>\n\nThis method is conservative and first order accurate, hence quite dissipative.  It can, however be used as a building block for building high-order numerical schemes for solving hyperbolic partial differential equations, much like Euler time steps can be used as a building block for creating high-order numerical integrators for ordinary differential equations.\n\nWe note that this method can be written in conservation form:\n\n:<math> u_i^{n+1} = u^n_i - \\frac{\\Delta t}{ \\Delta x} \\left( \\hat{f}^n_{i+1/2} - \\hat{f}^n_{i-1/2} \\right), </math>\n\nwhere\n\n:<math> \\hat{f}^n_{i-1/2} = \\frac{1}{2} \\left( f_{i-1} + f_{i} \\right) - \\frac{ \\Delta x}{ 2 \\Delta t  } \\left( u^n_{i} - u^n_{i-1} \\right). </math>\n\nWithout the extra terms <math> u^n_i </math> and <math> u^n_{i-1} </math>  in the discrete flux, <math> \\hat{f}^n_{i-1/2} </math>, one ends up with the [[FTCS scheme]], which is well known to be unconditionally unstable for hyperbolic problems.\n\n==Stability and accuracy==\n[[File:LF-Initial.png|thumb | 200px | Example problem initial condition]]\n[[File:LF-Solution.png|thumb| 200px | Lax-Friedrichs solution]]\n\nThis method is [[explicit method|explicit]] and [[Orders of approximation|first order accurate in time]] and [[Orders of approximation|first order accurate in space]] (<math> O(\\Delta t) + O(\\frac{\\Delta x^2}{\\Delta t})) </math>  provided <math>u_0(x),\\, u_b(t),\\, u_c(t)</math> are sufficiently-smooth functions.   Under these conditions, the method is [[numerical stability|stable]] if and only if the following condition is satisfied:\n\n:<math> \\left| a\\frac{\\Delta t}{\\Delta x} \\right| \\leq 1. </math>\n\n(A [[von Neumann stability analysis]] can show the necessity of this stability condition.)  The Lax–Friedrichs method is classified as having second-order [[dissipation]] and third order [[dispersion relation|dispersion]] {{harv|Chu|1978|loc=pg. 304}}. For functions that have [[discontinuity (mathematics)|discontinuities]], the scheme displays strong dissipation and dispersion {{harv|Thomas|1995|loc=§7.8}}; see figures at right.\n\n==References==\n\n{{reflist}}\n* {{Citation | last1=DuChateau | first1=Paul | last2=Zachmann | first2=David | title=Applied Partial Differential Equations | publisher=[[Dover Publications]] | location=New York | isbn=978-0-486-41976-3 | year=2002}}.\n* {{Citation | last1=Thomas | first1=J. W. | title=Numerical Partial Differential Equations: Finite Difference Methods | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Texts in Applied Mathematics | isbn=978-0-387-97999-1 | year=1995 | volume=22}}.\n* {{Citation | last1=Chu| first1=C. K. | title=Numerical Methods in Fluid Mechanics | publisher=[[Academic Press]] | location=New York | series=Advances in Applied Mechanics | isbn=978-0-12-002018-8 | year=1978 | volume=18}}.\n*{{Citation | last1=Press | first1=WH | last2=Teukolsky | first2=SA | last3=Vetterling | first3=WT | last4=Flannery | first4=BP | year=2007 | title=Numerical Recipes: The Art of Scientific Computing | edition=3rd | publisher=Cambridge University Press |  publication-place=New York | isbn=978-0-521-88068-8 | chapter=Section 10.1.2. Lax Method | chapter-url=http://apps.nrbook.com/empanel/index.html#pg=1034}}\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Lax-Friedrichs method}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Lax–Wendroff method",
      "url": "https://en.wikipedia.org/wiki/Lax%E2%80%93Wendroff_method",
      "text": "The '''Lax–Wendroff method''', named after [[Peter Lax]] and [[Burton Wendroff]], is a [[numerical analysis|numerical]] method for the solution of [[hyperbolic partial differential equation]]s, based on [[finite difference]]s. It is second-order accurate in both space and time. This method is an example of [[temporal discretization|explicit time integration]] where the function that defines governing equation is evaluated at the current time.\n\n== Definition ==\nSuppose one has an equation of the following form:\n\n: <math> \\frac{\\partial u(x,t)}{\\partial t}+\\frac{\\partial f(u(x,t))}{\\partial x}=0</math>\n\nwhere ''x'' and ''t'' are independent variables, and the initial state, u(''x'',&nbsp;0) is given.\n\n=== Linear case ===\nIn the linear case, where '' f(u) = Au '', and ''A'' is a constant,<ref>LeVeque, Randy J. ''Numerical Methods for Conservation Laws\", Birkhauser Verlag, 1992, p. 125.</ref>\n\n: <math> u_i^{n+1} = u_i^n - \\frac{\\Delta t}{2\\Delta x} A\\left[ u_{i+1}^{n} - u_{i-1}^{n} \\right] + \\frac{\\Delta t^2}{2\\Delta x^2} A^2\\left[ u_{i+1}^{n} -2 u_{i}^{n} + u_{i-1}^{n} \\right].</math>\n\nThis linear scheme can be extended to the general non-linear case in different ways. One of them is letting\n\n: <math> A(u) = f'(u) = \\frac{\\partial f}{\\partial u}</math>\n\n=== Non-linear case ===\nThe conservative form of Lax-Wendroff for a general non-linear equation is then:\n\n: <math> u_i^{n+1} = u_i^n - \\frac{\\Delta t}{2\\Delta x} \\left[ f(u_{i+1}^{n}) - f(u_{i-1}^{n}) \\right] + \\frac{\\Delta t^2}{2\\Delta x^2} \\left[ A_{i+1/2}\\left(f(u_{i+1}^{n}) - f(u_{i}^{n})\\right) - A_{i-1/2}\\left( f(u_{i}^{n})-f(u_{i-1}^{n})\\right) \\right].</math>\n\nwhere <math>A_{i\\pm 1/2}</math> is the Jacobian matrix evaluated at <math>\\frac{1}{2}(u^n_i + u^n_{i\\pm 1})</math>.\n\n== Jacobian free methods ==\nTo avoid the Jacobian evaluation, use a two-step procedure.\n\n=== Richtmyer method ===\nWhat follows is the Richtmyer two-step Lax–Wendroff method. The first step in the Richtmyer two-step Lax–Wendroff method calculates values for f(u(''x'',&nbsp;''t'')) at half time steps, ''t''<sub>''n''&nbsp;+&nbsp;1/2</sub> and half grid points, ''x''<sub>''i''&nbsp;+&nbsp;1/2</sub>. In the second step values at ''t''<sub>''n''&nbsp;+&nbsp;1</sub> are calculated using the data for ''t''<sub>''n''</sub> and ''t''<sub>''n''&nbsp;+&nbsp;1/2</sub>.\n\nFirst (Lax) steps:\n\n: <math> u_{i+1/2}^{n+1/2} = \\frac{1}{2}(u_{i+1}^n + u_{i}^n) - \\frac{\\Delta t}{2\\,\\Delta x}( f(u_{i+1}^n) - f(u_{i}^n) ),</math>\n: <math> u_{i-1/2}^{n+1/2}= \\frac{1}{2}(u_{i}^n + u_{i-1}^n) - \\frac{\\Delta t}{2\\,\\Delta x}( f(u_{i}^n) - f(u_{i-1}^n)  ).</math>\n\nSecond step:\n\n: <math> u_i^{n+1} = u_i^n - \\frac{\\Delta t}{\\Delta x} \\left[ f(u_{i+1/2}^{n+1/2}) - f(u_{i-1/2}^{n+1/2}) \\right].</math>\n\n=== MacCormack method ===\n\nAnother method of this same type was proposed by MacCormack. MacCormack's method uses first forward differencing and then backward differencing:\n\nFirst step:\n: <math> u_{i}^{*}= u_{i}^n - \\frac{\\Delta t}{\\Delta x}( f(u_{i+1}^n) - f(u_{i}^n)  ).</math>\nSecond step:\n: <math> u_i^{n+1} = \\frac{1}{2}(u_{i}^n + u_{i}^*) - \\frac{\\Delta t}{2 \\Delta x} \\left[ f(u_{i}^{*}) - f(u_{i-1}^{*}) \\right].</math>\n\nAlternatively,\nFirst step:\n: <math> u_{i}^{*}= u_{i}^n - \\frac{\\Delta t}{\\Delta x}( f(u_{i}^n) - f(u_{i-1}^n)  ).</math>\nSecond step:\n: <math> u_i^{n+1} = \\frac{1}{2}(u_{i}^n + u_{i}^*) - \\frac{\\Delta t}{2 \\Delta x} \\left[ f(u_{i+1}^{*}) - f(u_{i}^{*}) \\right].</math>\n\n==References==\n{{Reflist}}\n* {{ cite journal | author = P.D Lax |author2=B. Wendroff  | year = 1960 | title = Systems of conservation laws | journal = Commun. Pure Appl. Math. | volume = 13 | pages = 217–237 | doi = 10.1002/cpa.3160130205 | issue = 2 | url = http://www.dtic.mil/get-tr-doc/pdf?AD=ADA385056 }}\n* Michael J. Thompson, ''An Introduction to Astrophysical Fluid Dynamics'', Imperial College Press, London, 2006.\n*{{Cite book | last1=Press | first1=WH | last2=Teukolsky | first2=SA | last3=Vetterling | first3=WT | last4=Flannery | first4=BP | year=2007 | title=Numerical Recipes: The Art of Scientific Computing | edition=3rd | publisher=Cambridge University Press |  publication-place=New York | isbn=978-0-521-88068-8 | chapter=Section 20.1. Flux Conservative Initial Value Problems | chapter-url=http://apps.nrbook.com/empanel/index.html#pg=1040 | page=1040}}\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Lax-Wendroff Method}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Lax–Wendroff theorem",
      "url": "https://en.wikipedia.org/wiki/Lax%E2%80%93Wendroff_theorem",
      "text": "In [[computational mathematics]], the '''Lax&ndash;Wendroff theorem''', named after [[Peter Lax]] and [[Burton Wendroff]], states that if a [[Conservation law (physics)|conservative]] [[numerical analysis|numerical scheme]] for a [[Hyperbolic partial differential equation|hyperbolic system]] of [[Conservation law (physics)|conservation law]]s converges, then it converges towards a [[weak solution]].\n\n==See also==\n* [[Lax&ndash;Wendroff method]]\n* [[Godunov's scheme]]\n\n==References==\n* [[Randall J. LeVeque]], Numerical methods for conservation laws, Birkhäuser, 1992 {{ISBN|978-3-7643-2723-1}}\n\n{{DEFAULTSORT:Lax-Wendroff theorem}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]\n[[Category:Theorems in analysis]]\n\n\n{{Mathapplied-stub}}"
    },
    {
      "title": "Leapfrog integration",
      "url": "https://en.wikipedia.org/wiki/Leapfrog_integration",
      "text": "In [[numerical analysis]], '''leapfrog integration''' is a [[numerical methods for ordinary differential equations|method]] for numerically integrating [[differential equation]]s of the form\n:<math>\\ddot x = d^2 x/dt^2 = F(x)</math>,\nor equivalently of the form\n:<math>\\dot v = dv/dt = F(x),\\;\\dot x = dx/dt = v</math>,\nparticularly in the case of a [[dynamical system]] of [[classical mechanics]]. \n\nThe method is known by different names in different disciplines.  In particular, it is similar to the '''velocity Verlet''' method, which is a variant of [[Verlet integration]]. Leapfrog integration is equivalent to updating positions <math>x(t)</math> and velocities <math>v(t)=\\dot x(t)</math> at interleaved time points, staggered in such a way that they \"[[leapfrog]]\" over each other.\n\nLeapfrog integration is a second-order method, in contrast to [[Euler integration]], which is only first-order, yet requires the same number of function evaluations per step. Unlike Euler integration, it is stable for oscillatory motion, as long as the time-step <math>\\Delta t</math> is constant, and <math>\\Delta t \\leq 2/\\omega</math>.<ref>C. K. Birdsall and A. B. Langdon, ''Plasma Physics via Computer Simulations'', McGraw-Hill Book Company, 1985, p. 56.</ref>\n\nUsing Yoshida coefficients, applying the leapfrog integrator multiple times with the correct timesteps, a much higher order integrator can be generated.\n\n==Algorithm==\n\nIn leapfrog integration, the equations for updating position and velocity are\n:<math>\\begin{align}\n  a_i &= F(x_i), \\\\\n  v_{i+1/2} &= v_{i-1/2} + a_{i}\\, \\Delta t, \\\\\n  x_{i+1} &= x_{i} + v_{i+1/2}\\, \\Delta t,\n\\end{align}</math>\n\nwhere <math>x_i</math> is position at step <math>i</math>, <math>v_{i+1/2\\,}</math> is the velocity, or first derivative of <math>x</math>, at step <math>i+1/2\\,</math>, <math>a_{i}=F(x_i)</math> is the acceleration, or second derivative of <math>x</math>, at step <math>i</math>, and <math>\\Delta t</math> is the size of each time step. These equations can be expressed in a form that gives velocity at integer steps as well:<ref>[http://www.artcompsci.org/vol_1/v1_web/node34.html 4.1 Two Ways to Write the Leapfrog]</ref>\n:<math>\\begin{align}\n  x_{i+1} &= x_i + v_i\\, \\Delta t + \\tfrac{1}{2}\\,a_i\\, \\Delta t^{\\,2}, \\\\\n  v_{i+1} &= v_i + \\tfrac{1}{2}(a_i + a_{i+1})\\,\\Delta t.\n\\end{align}</math>\nHowever, even in this synchronized form, the time-step <math>\\Delta t</math> must be constant to maintain stability.<ref>[Skeel, R. D., \"Variable Step Size Destabilizes the Stömer/Leapfrog/Verlet Method\", BIT Numerical Mathematics, Vol. 33, 1993, p. 172–175.]</ref>\n\nThe synchronised form can be re-arranged to the 'kick-drift-kick' form;\n:<math>\\begin{align}\n  v_{i+1/2} &= v_i + a_i \\frac{\\Delta t}{2}, \\\\\n  x_{i+1} &= x_i +v_{i+1/2}\\Delta t,\\\\\n  v_{i+1} &= v_{i+1/2} + a_{i+1} \\frac{\\Delta t}{2},\n\\end{align}</math>\nwhich is primarily used where variable time-steps are required. The separation of the acceleration calculation onto the beginning and end of a step means that if time resolution is increased by a factor of two (<math>\\Delta t \\rightarrow \\Delta t/2</math>), then only one extra (computationally expensive) acceleration calculation is required.\n\nOne use of this equation is in gravity simulations, since in that case the acceleration depends only on the positions of the gravitating masses (and not on their velocities), although higher-order integrators (such as [[Runge–Kutta methods]]) are more frequently used.\n\nThere are two primary strengths to leapfrog integration when applied to mechanics problems. The first is the [[time-reversibility]] of the Leapfrog method. One can integrate forward ''n'' steps, and then reverse the direction of integration and integrate backwards ''n'' steps to arrive at the same starting position. The second strength is its [[Symplectic integrator|symplectic]] nature, which implies that it conserves the (slightly modified) energy of dynamical systems. This is especially useful when computing orbital dynamics, as many other integration schemes, such as the (order-4) Runge[[Runge–Kutta methods|–]]Kutta method, do not conserve energy and allow the system to drift substantially over time.\n\nBecause of its time-reversibility, and because it is a [[symplectic integrator]], leapfrog integration is also used in [[Hybrid Monte Carlo|Hamiltonian Monte Carlo]], a method for drawing random samples from a probability distribution whose overall normalization is unknown.<ref>{{cite book | last=Bishop | first=Christopher | title=Pattern Recognition and Machine Learning | year=2006 | publisher=[[Springer-Verlag]] | location=New York | isbn=978-0-387-31073-2 | pages=548–554}}</ref>\n\n==Yoshida algorithms==\nThe leapfrog integrator can be converted into higher order integrators using techniques due to [[Haruo Yoshida]]. In this approach, the leapfrog is applied over a number of different timesteps. It turns out that when the correct timesteps are used in sequence, the errors cancel and far higher order integrators can be easily produced.<ref>http://www.artcompsci.org/kali/vol/two_body_problem_2/ch07.html#rdocsect46</ref><ref name=Yoshida1990>Volume 150, number 5,6,7 PHYSICS LETTERS A 12 November 1990 Construction \nof higher order symplectic integrators Haruo Yoshida National Astronomical Observatory, Mitaka, Tokyo</ref>\n\n===4th order Yoshida integrator===\nOne step under the 4th order Yoshida integrator requires four intermediary steps. The position and velocity are computed at different times. Only three (computationally expensive) acceleration calculations are required. \n\nThe equations for the 4th order integrator to update position and velocity are\n\n:<math>\\begin{align}\n  x_i^1 &= x_i + c_1\\, v_i\\, \\Delta t, \\\\\n  v_i^1 &= v_i + d_1\\, a(x_i^1)\\, \\Delta t, \\\\\n  x_i^2 &= x_i^1 + c_2\\, v_i^1\\, \\Delta t, \\\\\n  v_i^2 &= v_i^1 + d_2\\, a(x_i^2)\\, \\Delta t, \\\\\n  x_i^3 &= x_i^2 + c_3\\, v_i^2\\, \\Delta t, \\\\\n  v_i^3 &= v_i^2 + d_3\\, a(x_i^3)\\, \\Delta t, \\\\\n  x_{i+1} &\\equiv x_i^4 = x_i^3 + c_4\\, v_i^3\\, \\Delta t, \\\\\n  v_{i+1} &\\equiv v_i^4 = v_i^3 \\\\\n\\end{align}</math>\n\nwhere <math>x_i, v_i</math> are the starting position and velocity, <math>x_i^n, v_i^n</math> are intermediary position and velocity at intermediary step <math>n</math>, <math>a(x_i^n)</math> is the acceleration at the position <math>x_i^n</math>, and <math>x_{i+1},v_{i+1}</math> are the final position and velocity under one 4th order Yoshida step.\n\nCoefficients <math>(c_1, c_2, c_3, c_4)</math> and <math>(d_1, d_2, d_3, d_4)</math> are derived in <ref name=Yoshida1990/> (see the equation (4.6))\n\n:<math>\\begin{align}\n  w_0 &\\equiv - \\frac{\\sqrt[3]{2}}{2-\\sqrt[3]{2}}, \\\\\n  w_1 &\\equiv \\frac{1}{2-\\sqrt[3]{2}}, \\\\\n  c_1 &= c_4 \\equiv \\frac{w_1}{2}, c_2 = c_3 \\equiv \\frac{w_0+w_1}{2}, \\\\\n  d_1 &= d_3 \\equiv w_1, d_2 \\equiv w_0 \\\\\n\\end{align}</math>\n\nAll intermediary steps form one <math>\\Delta t</math> step which implies that coefficients sum up to one: <math>\\sum_{i=1}^{4}c_i=1</math> and <math>\\sum_{i=1}^{3}d_i=1</math>. Please note that position and velocity are computed at different times and some intermediary steps are backwards in time. To illustrate this, we give the numerical values of <math>c_{n}</math> coefficients: <math>c_1=0.6756, c_2=-0.1756, c_3=-0.1756, c_4=0.6756.</math>\n\n==See also==\n*[[Numerical methods for ordinary differential equations]]\n*[[Symplectic integrator|Symplectic integration]]\n*[[Euler integration]]\n*[[Verlet integration]]\n*[[Runge–Kutta methods|Runge–Kutta integration]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*[https://www.physics.drexel.edu/students/courses/Comp_Phys/Integrators/leapfrog/], Drexel University Physics\n\n{{Numerical integrators}}\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "List of Runge–Kutta methods",
      "url": "https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods",
      "text": "'''[[Runge–Kutta methods]]''' are methods for the numerical solution of the [[ordinary differential equation]]\n\n:<math>\\frac{d y}{d t} = f(t, y).</math>\n\nExplicit Runge-Kutta methods take the form\n\n:<math>y_{n+1} = y_n + h \\sum_{i=1}^s b_i k_i</math>\n:<math>k_1 = f(t_n, y_n), </math>\n:<math>k_2 = f(t_n+c_2h, y_n+h(a_{21}k_1)), </math>\n:<math>k_3 = f(t_n+c_3h, y_n+h(a_{31}k_1+a_{32}k_2)), </math>\n:<math>\\vdots </math>\n:<math>k_i = f\\left(t_n + c_i h, y_n + h \\sum_{j = 1}^{i-1} a_{ij} k_j\\right). </math>\n\nStages for implicit methods of s stages take the more general form\n\n:<math>k_i = f\\left(t_n + c_i h, y_n + h \\sum_{j = 1}^{s} a_{ij} k_j\\right). </math>\n\nEach method listed on this page is defined by its [[Butcher tableau]], which puts the coefficients of the method in a table as follows:\n\n:<math>\n\\begin{array}{c|cccc}\nc_1    & a_{11} & a_{12}& \\dots & a_{1s}\\\\\nc_2    & a_{21} & a_{22}& \\dots & a_{2s}\\\\\n\\vdots & \\vdots & \\vdots& \\ddots& \\vdots\\\\\nc_s    & a_{s1} & a_{s2}& \\dots & a_{ss} \\\\\n\\hline\n       & b_1    & b_2   & \\dots & b_s\\\\\n\\end{array}\n</math>\n\n==Explicit methods==\n\nThe explicit methods are those where the matrix <math>[a_{ij}]</math> is lower [[triangular matrix|triangular]].\n\n===Forward Euler===\n\nThe [[Euler method]] is first order. The lack of stability and accuracy limits its popularity mainly to use as a simple introductory example of a numeric solution method.\n\n:<math>\n\\begin{array}{c|c}\n0 & 0 \\\\\n\\hline\n  & 1 \\\\\n\\end{array}\n</math>\n\n===Explicit midpoint method===\n\nThe (explicit) [[midpoint method]] is a second-order method with two stages (see also the implicit midpoint method below):\n\n: <math>\n\\begin{array}{c|cc}\n0   & 0   & 0  \\\\\n1/2 & 1/2 & 0  \\\\\n\\hline\n    & 0   & 1  \\\\\n\\end{array}\n</math>\n\n===Heun's method===\n\n[[Heun's method]] is a second-order method with two stages.  It is also known as the explicit trapezoid rule, improved Euler's method, or modified Euler's method.  (Note: The \"eu\" is pronounced the same way as in \"Euler\", so \"Heun\" rhymes with \"coin\"):\n\n: <math>\n\\begin{array}{c|cc}\n0   & 0   & 0  \\\\\n1 & 1 & 0  \\\\\n\\hline\n    & 1/2 & 1/2  \\\\\n\\end{array}\n</math>\n\n===Ralston's method===\n\nRalston's method is a second-order method<ref>{{cite journal |last1=Ralston |first1=Anthony |title=Runge-Kutta Methods with Minimum Error Bounds |journal=Math. Comput. |date=1962 |volume=16 |pages=431–437}}</ref> with two stages and a minimum local error bound:\n\n: <math>\n\\begin{array}{c|cc}\n0   & 0   & 0  \\\\\n2/3 & 2/3 & 0  \\\\\n\\hline\n    & 1/4   & 3/4  \\\\\n\\end{array}\n</math>\n\n===Generic second-order method===\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 0   & 0   \\\\\nx & x & 0   \\\\\n\\hline\n    & 1-\\frac{1}{2x} & \\frac{1}{2x} \\\\\n\\end{array}\n</math>\n\n===Kutta's third-order method===\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 0   & 0   & 0    \\\\\n1/2 & 1/2 & 0   & 0    \\\\\n1   & -1  & 2   & 0    \\\\\n\\hline\n    & 1/6 & 2/3 & 1/6  \\\\\n\\end{array}\n</math>\n\n===Heun's third-order method===\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 0   & 0   & 0    \\\\\n1/3 & 1/3 & 0   & 0    \\\\\n2/3 & 0   & 2/3 & 0    \\\\\n\\hline\n    & 1/4 & 0   & 3/4  \\\\\n\\end{array}\n</math>\n\n===Ralston's third-order method===\n\nRalston's third-order method<ref>{{cite journal |last1=Ralston |first1=Anthony |title=Runge-Kutta Methods with Minimum Error Bounds |journal=Math. Comput. |date=1962 |volume=16 |pages=431–437}}</ref> is used in the embedded [[Bogacki–Shampine method]].\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 0   & 0   & 0    \\\\\n1/2 & 1/2 & 0   & 0    \\\\\n3/4 & 0   & 3/4 & 0    \\\\\n\\hline\n    & 2/9 & 1/3 & 4/9  \\\\\n\\end{array}\n</math>\n\n===Third-order Strong Stability Preserving Runge-Kutta (SSPRK3)===\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 0   & 0   & 0    \\\\\n1   & 1   & 0   & 0    \\\\\n1/2 & 1/4 & 1/4 & 0    \\\\\n\\hline\n    & 1/6 & 1/6 & 2/3  \\\\\n\\end{array}\n</math>\n\n===Classic fourth-order method===\n\nThe \"original\" Runge–Kutta method.\n\n:<math>\n\\begin{array}{c|cccc}\n0   & 0   & 0   & 0   & 0\\\\\n1/2 & 1/2 & 0   & 0   & 0\\\\\n1/2 & 0   & 1/2 & 0   & 0\\\\\n1   & 0   & 0   & 1   & 0\\\\\n\\hline\n    & 1/6 & 1/3 & 1/3 & 1/6\\\\\n\\end{array}\n</math>\n\n===Ralston's fourth-order method===\n\nThis fourth order method<ref>{{cite journal |last1=Ralston |first1=Anthony |title=Runge-Kutta Methods with Minimum Error Bounds |journal=Math. Comput. |date=1962 |volume=16 |pages=431–437}}</ref> has minimum truncation error.\n:<math>\n\\begin{array}{c|cccc}\n0   & 0   & 0   & 0   & 0\\\\\n.4 & .4 & 0   & 0   & 0\\\\\n.45573725 & .29697761   & .15875964 & 0   & 0\\\\\n1   & .21810040   & -3.05096516   & 3.83286476   & 0\\\\\n\\hline\n    & .17476028 & -.55148066 & 1.20553560 & .17118478\\\\\n\\end{array}\n</math>\n\n===3/8-rule fourth-order method===\n\nThis method doesn't have as much notoriety as the \"classical\" method, but is just as classical because it was proposed in the same paper (Kutta, 1901).\n\n:<math>\n\\begin{array}{c|cccc}\n0   & 0   & 0   & 0   & 0\\\\\n1/3 & 1/3 & 0   & 0   & 0\\\\\n2/3 & -1/3   & 1 & 0   & 0\\\\\n1   & 1   & -1   & 1   & 0\\\\                   \n\\hline\n    & 1/8 & 3/8 & 3/8 & 1/8\\\\\n\\end{array}\n</math>\n\n==Embedded methods==\nThe embedded methods are designed to produce an estimate of the local truncation error of a single Runge-Kutta step, and as result, allow to control the error with [[adaptive stepsize]]. This is done by having two methods in the tableau, one with order p and one with order p-1.\n\nThe lower-order step is given by\n\n:<math>    y^*_{n+1} = y_n + h\\sum_{i=1}^s b^*_i k_i, </math>\n\nwhere the <math>k_i</math> are the same as for the higher order method. Then the error is\n\n:<math>    e_{n+1} = y_{n+1} - y^*_{n+1} = h\\sum_{i=1}^s (b_i - b^*_i) k_i, </math>\n\nwhich is <math>O(h^p)</math>. The Butcher Tableau for this kind of method is extended to give the values of <math>b^*_i</math>\n:<math>\n\\begin{array}{c|cccc}\nc_1    & a_{11} & a_{12}& \\dots & a_{1s}\\\\\nc_2    & a_{21} & a_{22}& \\dots & a_{2s}\\\\\n\\vdots & \\vdots & \\vdots& \\ddots& \\vdots\\\\\nc_s    & a_{s1} & a_{s2}& \\dots & a_{ss} \\\\\n\\hline\n       & b_1    & b_2   & \\dots & b_s\\\\\n       & b_1^*    & b_2^*   & \\dots & b_s^*\\\\\n\\end{array}\n</math>\n\n===Heun–Euler===\nThe simplest adaptive Runge–Kutta method involves combining [[Heun's method]], which is order 2, with the Euler method, which is order 1. Its extended Butcher Tableau is:\n:<math>\n\\begin{array}{c|cc}\n\t0&\\\\\n\t1& \t1 \\\\\n\\hline\n&\t1/2& \t1/2\\\\\n\t&\t1 &\t0\n\\end{array}\n</math>\n\nThe error estimate is used to control the stepsize.\n\n=== Fehlberg RK1(2) ===\nThe [[Fehlberg Method|Fehlberg method]]<ref>{{Cite journal\n| last = Fehlberg\n| first = E.\n| date = 1969-07-01\n| title = Low-order classical Runge-Kutta formulas with stepsize control and their application to some heat transfer problems\n| url = https://ntrs.nasa.gov/search.jsp?R=19690021375\n}}</ref> has two methods of orders 1 and 2. Its extended Butcher Tableau is:\n{| cellpadding=\"3px\" cellspacing=\"0px\"\n| width=\"20px\" | || style=\"border-right:1px solid;\" | 0\n|- \n||| style=\"border-right:1px solid;\" | 1/2 || 1/2\n|- \n||| style=\"border-right:1px solid; border-bottom:1px solid;\" |1|| style=\"border-bottom:1px solid;\" |1/256|| style=\"border-bottom:1px solid;\"|255/256 || style=\"border-bottom:1px solid;\" |\n|- \n||| style=\"border-right:1px solid;\" | ||1/256||255/256||0\n|-\n||| style=\"border-right:1px solid;\" | ||1/512||255/256||1/512\n|}\n\nThe first row of ''b'' coefficients gives the first-order accurate solution, and the second row has order two.\n\n===Bogacki–Shampine===\n\nThe [[Bogacki–Shampine method]] has two methods of orders 3 and 2. Its extended Butcher Tableau is:\n{| cellpadding=3px cellspacing=0px\n|width=\"20px\"| || style=\"border-right:1px solid;\" | 0\n|- \n||| style=\"border-right:1px solid;\" | 1/2 || 1/2\n|- \n||| style=\"border-right:1px solid;\" | 3/4 || 0 || 3/4\n|- \n||| style=\"border-right:1px solid; border-bottom:1px solid;\" | 1 || style=\"border-bottom:1px solid;\" | 2/9 || style=\"border-bottom:1px solid;\" | 1/3 || style=\"border-bottom:1px solid;\" | 4/9 || style=\"border-bottom:1px solid;\" | \n|- \n||| style=\"border-right:1px solid;\" | || 2/9 || 1/3 || 4/9 || 0\n|-\n||| style=\"border-right:1px solid;\" | || 7/24 || 1/4 || 1/3 || 1/8\n|}\n\nThe first row of ''b'' coefficients gives the third-order accurate solution, and the second row has order two.\n\n===Fehlberg===\n\nThe [[Runge–Kutta–Fehlberg method]] has two methods of orders 5 and 4. Its extended Butcher Tableau is:\n{| cellpadding=3px cellspacing=0px\n|width=\"20px\"| || style=\"border-right:1px solid;\" | 0\n|- \n||| style=\"border-right:1px solid;\" | 1/4 || 1/4\n|- \n||| style=\"border-right:1px solid;\" | 3/8 || 3/32 || 9/32\n|- \n||| style=\"border-right:1px solid;\" | 12/13  || 1932/2197 || −7200/2197 || 7296/2197\n|- \n||| style=\"border-right:1px solid;\" | 1  || 439/216 || −8 || 3680/513 || −845/4104\n|- \n||| style=\"border-right:1px solid; border-bottom:1px solid;\" | 1/2 || style=\"border-bottom:1px solid;\" | -8/27 || style=\"border-bottom:1px solid;\" | 2 || style=\"border-bottom:1px solid;\" | −3544/2565 || style=\"border-bottom:1px solid;\" | 1859/4104 || style=\"border-bottom:1px solid;\" | −11/40 || style=\"border-bottom:1px solid;\" |\n|-\n||| style=\"border-right:1px solid;\" | || 16/135 || 0 || 6656/12825 || 28561/56430 || −9/50 || 2/55 \n|- \n||| style=\"border-right:1px solid;\" | || 25/216 || 0 || 1408/2565 || 2197/4104 || −1/5 || 0\n|}\n\nThe first row of ''b'' coefficients gives the fifth-order accurate solution, and the second row has order four.\n\n===Cash-Karp===\n\nCash and Karp have modified Fehlberg's original idea. The extended tableau for the [[Cash–Karp method]] is\n\n{| cellpadding=3px cellspacing=0px\n|width=\"20px\"| || style=\"border-right:1px solid;\" | 0\n|- \n||| style=\"border-right:1px solid;\" | 1/5 || 1/5\n|- \n||| style=\"border-right:1px solid;\" | 3/10 || 3/40 || 9/40\n|- \n||| style=\"border-right:1px solid;\" | 3/5 || 3/10 || −9/10 || 6/5\n|- \n||| style=\"border-right:1px solid;\" | 1 || −11/54 || 5/2 || −70/27 || 35/27\n|- \n||| style=\"border-right:1px solid; border-bottom:1px solid;\" | 7/8 || style=\"border-bottom:1px solid;\" | 1631/55296 || style=\"border-bottom:1px solid;\" | 175/512 || style=\"border-bottom:1px solid;\" | 575/13824 || style=\"border-bottom:1px solid;\" | 44275/110592 || style=\"border-bottom:1px solid;\" | 253/4096 || style=\"border-bottom:1px solid;\" | \n|- \n||| style=\"border-right:1px solid;\" | || 37/378 || 0 || 250/621 || 125/594 || 0 || 512/1771\n|-\n||| style=\"border-right:1px solid;\" | || 2825/27648 || 0 || 18575/48384 || 13525/55296 || 277/14336 || 1/4\n|}\n\nThe first row of ''b'' coefficients gives the fifth-order accurate solution, and the second row has order four.\n\n===Dormand–Prince===\n\nThe extended tableau for the [[Dormand–Prince method]] is\n\n{| cellpadding=3px cellspacing=0px\n|width=\"20px\"| || style=\"border-right:1px solid;\" | 0\n|- \n||| style=\"border-right:1px solid;\" | 1/5 || 1/5\n|- \n||| style=\"border-right:1px solid;\" | 3/10 || 3/40 || 9/40\n|- \n||| style=\"border-right:1px solid;\" | 4/5  || 44/45 || −56/15 || 32/9\n|- \n||| style=\"border-right:1px solid;\" | 8/9  || 19372/6561 || −25360/2187 || 64448/6561 || −212/729\n|- \n||| style=\"border-right:1px solid;\" | 1 || 9017/3168 || −355/33 || 46732/5247 || 49/176 || −5103/18656\n|-\n||| style=\"border-right:1px solid; border-bottom:1px solid;\" | 1 || style=\"border-bottom:1px solid;\" | 35/384 || style=\"border-bottom:1px solid;\" | 0 || style=\"border-bottom:1px solid;\" | 500/1113 || style=\"border-bottom:1px solid;\" | 125/192 || style=\"border-bottom:1px solid;\" | −2187/6784 || style=\"border-bottom:1px solid;\" | 11/84 || style=\"border-bottom:1px solid;\" | \n|-\n||| style=\"border-right:1px solid;\" | || 35/384 || 0 || 500/1113 || 125/192 || −2187/6784 || 11/84 || 0\n|- \n||| style=\"border-right:1px solid;\" | || 5179/57600 || 0 || 7571/16695 || 393/640 || −92097/339200 || 187/2100 || 1/40\n|}\n\nThe first row of ''b'' coefficients gives the fifth-order accurate solution and the second row gives the fourth-order accurate solution.\n\n==Implicit methods==\n\n===Backward Euler===\n\nThe [[backward Euler method]] is first order. Unconditionally stable and non-oscillatory for linear diffusion problems.\n\n:<math>\n\\begin{array}{c|c}\n1 & 1 \\\\\n\\hline\n  & 1 \\\\\n\\end{array}\n</math>\n\n===Implicit midpoint===\n\nThe implicit midpoint method is of second order. It is the simplest method in the class of collocation methods known as the [[Gauss–Legendre method|Gauss methods]]. It is a [[symplectic integrator]].\n\n: <math>\n\\begin{array}{c|c}\n1/2 & 1/2 \\\\\n\\hline\n & 1\n\\end{array}\n</math>\n\n===Crank-Nicolson method===\n\nThe Crank-Nicolson method corresponds to the implicit trapezoidal rule and is a second-order accurate and A-stable method.\n\n: <math>\n\\begin{array}{c|cc}\n0   & 0   & 0   \\\\\n1   & 1/2 & 1/2 \\\\\n\\hline\n    & 1/2 & 1/2 \\\\\n\\end{array}\n</math>\n\n===Gauss–Legendre methods===\n\nThese methods are based on the points of Gauss–Legendre quadrature. The Gauss–Legendre method of order four has Butcher tableau:\n\n:<math>\n\\begin{array}{c|cc}\n\\frac{1}{2}-\\frac{\\sqrt3}{6} & \\frac{1}{4} & \\frac{1}{4}-\\frac{\\sqrt3}{6}  \\\\\n\\frac{1}{2}+\\frac{\\sqrt3}{6}  & \\frac{1}{4}+\\frac{\\sqrt3}{6} &\\frac{1}{4} \\\\\n\\hline \n    & \\frac{1}{2} & \\frac{1}{2}\\\\\n    & \\frac12+\\frac{\\sqrt3}{2} & \\frac12-\\frac{\\sqrt3}{2} \\\\\n\\end{array}\n</math>\n\nThe Gauss–Legendre method of order six has Butcher tableau:\n\n:<math>\n\\begin{array}{c|ccc}\n\\frac{1}{2} - \\frac{\\sqrt{15}}{10}   & \\frac{5}{36} &  \\frac{2}{9}- \\frac{\\sqrt{15}}{15} & \\frac{5}{36} - \\frac{\\sqrt{15}}{30} \\\\\n\\frac{1}{2} & \\frac{5}{36} + \\frac{\\sqrt{15}}{24} & \\frac{2}{9} & \\frac{5}{36} - \\frac{\\sqrt{15}}{24}\\\\\n\\frac{1}{2} + \\frac{\\sqrt{15}}{10} & \\frac{5}{36} + \\frac{\\sqrt{15}}{30} & \\frac{2}{9} + \\frac{\\sqrt{15}}{15} & \\frac{5}{36}  \\\\\n\\hline\n    & \\frac{5}{18} & \\frac{4}{9} & \\frac{5}{18}  \\\\\n    & -\\frac56 & \\frac83 & -\\frac56\n\\end{array}\n</math>\n\n===Diagonally Implicit Runge Kutta methods===\n\nDiagonally Implicit Runge-Kutta (DIRK) formulae have been widely used for the numerical solution of stiff initial value problems.  The simplest method from this class is the order 2 implicit [[midpoint method]].\n\nKraaijevanger and Spijker's two-stage Diagonally Implicit Runge Kutta method:\n\n:<math>\n\\begin{array}{c|cc}\n1/2  &  1/2   &  0    \\\\\n3/2  &  -1/2  &  2    \\\\\n\\hline \n     &  -1/2  &  3/2  \\\\\n\\end{array}\n</math>\n\nQin and Zhang's two-stage, 2nd order, symplectic Diagonally Implicit Runge Kutta method:\n\n:<math>\n\\begin{array}{c|cc}\n1/4  &  1/4  &  0    \\\\\n3/4  &  1/2  &  1/4  \\\\\n\\hline \n     &  1/2  &  1/2  \\\\\n\\end{array}\n</math>\n\nPareschi and Russo's two-stage 2nd order Diagonally Implicit Runge Kutta method:\n\n:<math>\n\\begin{array}{c|cc}\nx      &  x           &  0  \\\\\n1 - x  &  1 - 2x      &  x  \\\\\n\\hline \n       & \\frac{1}{2}  & \\frac{1}{2}\\\\\n\\end{array}\n</math>\n\nThis Diagonally Implicit Runge Kutta method is A-stable if and only if <math>x \\ge \\frac{1}{4}</math>.  Moreover, this method is L-stable if and only if <math>x</math> equals one of the roots of the polynomial <math>x^2 - 2x + \\frac{1}{2}</math>, i.e. if <math>x = 1 \\pm \\frac{\\sqrt2}{2}</math>.\nQin and Zhang's Diagonally Implicit Runge Kutta method corresponds to Pareschi and Russo's Diagonally Implicit Runge Kutta method with <math>x = 1/4</math>.\n\nTwo-stage 2nd order Diagonally Implicit Runge Kutta method:\n\n:<math>\n\\begin{array}{c|cc}\nx   &  x           &  0  \\\\\n1   &  1 - x       &  x  \\\\\n\\hline \n    & \\frac{1}{2}  & \\frac{1}{2}\\\\\n\\end{array}\n</math>\n\nAgain, this Diagonally Implicit Runge Kutta method is A-stable if and only if <math>x \\ge \\frac{1}{4}</math>.  As the previous method, this method is again L-stable if and only if <math>x</math> equals one of the roots of the polynomial <math>x^2 - 2x + \\frac{1}{2}</math>, i.e. if <math>x = 1 \\pm \\frac{\\sqrt2}{2}</math>.\n\nCrouzeix's two-stage, 3rd order Diagonally Implicit Runge Kutta method:\n\n:<math>\n\\begin{array}{c|cc}\n\\frac{1}{2}+\\frac{\\sqrt3}{6}  &  \\frac{1}{2}+\\frac{\\sqrt3}{6}  &  0                             \\\\\n\\frac{1}{2}-\\frac{\\sqrt3}{6}  &  -\\frac{\\sqrt3}{3}             &  \\frac{1}{2}+\\frac{\\sqrt3}{6}  \\\\\n\\hline \n                              & \\frac{1}{2}                    & \\frac{1}{2}\\\\\n\\end{array}\n</math>\n\nThree-stage, 3rd order, L-stable Diagonally Implicit Runge Kutta method:\n\n:<math>\n\\begin{array}{c|ccc}\nx              &  x               &  0              &  0   \\\\\n\\frac{1+x}{2}  &  \\frac{1-x}{2}   &  x              &  0   \\\\\n1              &  -3x^2/2+4x-1/4  &  3x^2/2-5x+5/4  &  x   \\\\\n\\hline \n               &  -3x^2/2+4x-1/4  &  3x^2/2-5x+5/4  &  x   \\\\\n\\end{array}\n</math>\n\nwith <math>x = 0.4358665215</math>\n\nNørsett's three-stage, 4th order Diagonally Implicit Runge Kutta method has the following Butcher tableau:\n\n:<math>\n\\begin{array}{c|ccc}\nx    &  x      &  0     &  0   \\\\\n1/2  &  1/2-x  &  x     &  0   \\\\\n1-x  &  2x     &  1-4x  &  x   \\\\\n\\hline\n     & \\frac{1}{6(1-2x)^2}  & \\frac{3(1-2x)^2 - 1}{3(1-2x)^2} & \\frac{1}{6(1-2x)^2} \\\\\n\\end{array}\n</math>\n\nwith <math>x</math> one of the three roots of the cubic equation <math>x^3 -3x^2/2 + x/2 - 1/24 = 0</math>.  The three roots of this cubic equation are approximately <math>x_1 = 1.06858</math>, <math>x_2 = 0.30254</math>, and <math>x_3 = 0.12889</math>.  The root <math>x_1</math> gives the best stability properties for initial value problems.\n\nFour-stage, 3rd order, L-stable Diagonally Implicit Runge Kutta method\n\n:<math>\n\\begin{array}{c|cccc}\n1/2  &  1/2   &  0     &  0    &  0    \\\\\n2/3  &  1/6   &  1/2   &  0    &  0    \\\\\n1/2  &  -1/2  &  1/2   &  1/2  &  0    \\\\\n1    &  3/2   &  -3/2  &  1/2  &  1/2  \\\\\n\\hline\n     &  3/2   &  -3/2  &  1/2  &  1/2  \\\\\n\\end{array}\n</math>\n\n===Lobatto methods===\n\nThere are three main families of Lobatto methods, called IIIA, IIIB and IIIC (in classial mathematical literature, the symbols I and II are reserved for two types of Radau methods).  These are named after [[Rehuel Lobatto]].  All are implicit methods, have order 2''s''&nbsp;&minus;&nbsp;2 and they all have ''c''<sub>1</sub>&nbsp;=&nbsp;0 and ''c''<sub>''s''</sub>&nbsp;=&nbsp;1.  Unlike any explicit method, it's possible for these methods to have the order greater than the number of stages. Lobatto lived before the classic fourth-order method was popularized by Runge and Kutta.\n\n====Lobatto IIIA methods====\n\nThe Lobatto IIIA methods are [[collocation method]]s. The second-order method is known as the [[trapezoidal rule (differential equations)|trapezoidal rule]]:\n\n:<math>\n\\begin{array}{c|cc}\n0   & 0   & 0  \\\\\n1   & 1/2 & 1/2\\\\\n\\hline\n    & 1/2 & 1/2\\\\\n& 1 & 0 \\\\\n\\end{array}\n</math>\n\nThe fourth-order method is given by\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 0   & 0   & 0    \\\\\n1/2 & 5/24& 1/3 & -1/24\\\\\n1   & 1/6 & 2/3 & 1/6  \\\\\n\\hline\n    & 1/6 & 2/3 & 1/6  \\\\\n& -\\frac12 & 2 & -\\frac12 \\\\\n\\end{array}\n</math>\n\nThis methods are A-stable, but not L-stable and B-stable.\n\n====Lobatto IIIB methods====\n\nThe Lobatto IIIB methods are not collocation methods, but they can be viewed as [[discontinuous collocation method]]s {{harv|Hairer|Lubich|Wanner|2006|loc=§II.1.4}}. The second-order method is given by\n\n:<math>\n\\begin{array}{c|cc}\n0   & 1/2 & 0  \\\\\n1   & 1/2 & 0  \\\\\n\n\\hline\n    & 1/2 & 1/2\\\\\n& 1 & 0 \\\\\n\n\\end{array}\n</math>\n\nThe fourth-order method is given by\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 1/6 & -1/6& 0    \\\\\n1/2 & 1/6 & 1/3 & 0    \\\\\n1   & 1/6 & 5/6 & 0    \\\\\n\\hline\n    & 1/6 & 2/3 & 1/6  \\\\\n& -\\frac12 & 2 & -\\frac12 \\\\\n\\end{array}\n</math>\n\nLobatto IIIB methods are A-stable, but not L-stable and B-stable.\n\n====Lobatto IIIC methods====\n\nThe Lobatto IIIC methods also are discontinuous collocation methods. The second-order method is given by\n\n:<math>\n\\begin{array}{c|cc}\n0   & 1/2 & -1/2\\\\\n1   & 1/2 & 1/2 \\\\\n\\hline\n    & 1/2 & 1/2 \\\\\n& 1 & 0 \\\\\n\\end{array}\n</math>\n\nThe fourth-order method is given by\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 1/6 & -1/3& 1/6  \\\\\n1/2 & 1/6 & 5/12& -1/12\\\\\n1   & 1/6 & 2/3 & 1/6  \\\\\n\\hline\n    & 1/6 & 2/3 & 1/6  \\\\\n& -\\frac12 & 2 & -\\frac12 \\\\\n\\end{array}\n</math>\n\nThey are L-stable. They are also algebraically stable and thus B-stable, that makes them suitable for stiff problems.\n\n====Lobatto IIIC* methods====\n\nThe Lobatto IIIC* methods are also known as Lobatto III methods (Butcher, 2008), Butcher’s Lobatto methods (Hairer et al, 1993), and Lobatto IIIC methods (Sun, 2000) in the literature.<ref>http://homepage.math.uiowa.edu/~ljay/publications.dir/Lobatto.pdf</ref> The second-order method is given by\n\n:<math>\n\\begin{array}{c|cc}\n0   & 0 & 0\\\\\n1   & 1 & 0 \\\\\n\\hline\n    & 1/2 & 1/2 \\\\\n\\end{array}\n</math>\n\nButcher's three-stage, fourth-order method is given by\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 0 & 0 & 0  \\\\\n1/2 & 1/4 & 1/4 & 0\\\\\n1   & 0 & 1 & 0  \\\\\n\\hline\n    & 1/6 & 2/3 & 1/6  \\\\\n\\end{array}\n</math>\n\nThese methods are not A-stable, B-stable or L-stable. The Lobatto IIIC* method for <math>s = 2</math> is sometimes called the explicit trapezoidal rule.\n\n====Generalized Lobatto methods====\nOne can consider a very general family of methods with three real parameters <math> (\\alpha_{A},\\alpha_{B},\\alpha_{C}) </math>\nby considering Lobatto coefficients of the form\n:<math>a_{i,j}(\\alpha_{A},\\alpha_{B},\\alpha_{C}) = \\alpha_{A}a_{i,j}^A + \\alpha_{B}a_{i,j}^B + \\alpha_{C}a_{i,j}^C + \\alpha_{C*}a_{i,j}^{C*} </math>,\nwhere\n:<math>\\alpha_{C*} = 1 - \\alpha_{A} - \\alpha_{B} - \\alpha_{C}</math>.\nFor example, Lobatto IIID family introduced in (Nørsett and Wanner, 1981), also called Lobatto IIINW, are given by\n:<math>\n\\begin{array}{c|cc}\n0   & 1/2 & 1/2\\\\\n1   & -1/2 & 1/2 \\\\\n\\hline\n    & 1/2 & 1/2 \\\\\n\\end{array}\n</math>\n\nand\n\n:<math>\n\\begin{array}{c|ccc}\n0   & 1/6 & 0 & -1/6  \\\\\n1/2 & 1/12 & 5/12 & 0\\\\\n1   & 1/2 & 1/3 & 1/6  \\\\\n\\hline\n    & 1/6 & 2/3 & 1/6  \\\\\n\\end{array}\n</math>\n\nThese methods correspond to <math>\\alpha_{A} = 2</math>, <math>\\alpha_{B} = 2</math>, <math>\\alpha_{C} = -1</math>, and <math>\\alpha_{C*} = -2</math>.  The methods are L-stable. They are algebraically stable and thus B-stable.\n\n===Radau methods===\n\nRadau methods are fully implicit methods (matrix ''A'' of such methods can have any structure). Radau methods attain order 2''s''&nbsp;&minus;&nbsp;1 for ''s'' stages. Radau methods are A-stable, but expensive to implement. Also they can suffer from order reduction.\nThe first order Radau method is similar to backward Euler method.\n\n====Radau IA methods====\nThe third-order method is given by\n\n:<math>\n\\begin{array}{c|cc}\n0   & 1/4  & -1/4  \\\\\n2/3 & 1/4  &  5/12 \\\\\n\\hline\n    & 1/4 & 3/4 \\\\\n\\end{array}\n</math>\n\nThe fifth-order method is given by\n\n:<math>\n\\begin{array}{c|ccc}\n0   & \\frac{1}{9} & \\frac{-1 - \\sqrt{6}}{18} & \\frac{-1 + \\sqrt{6}}{18} \\\\\n\\frac{3}{5} - \\frac{\\sqrt{6}}{10}  & \\frac{1}{9} & \\frac{11}{45} + \\frac{7\\sqrt{6}}{360} & \\frac{11}{45} - \\frac{43\\sqrt{6}}{360}\\\\\n\\frac{3}{5} + \\frac{\\sqrt{6}}{10} & \\frac{1}{9} & \\frac{11}{45} + \\frac{43\\sqrt{6}}{360} & \\frac{11}{45} - \\frac{7\\sqrt{6}}{360}  \\\\\n\\hline\n    & \\frac{1}{9} & \\frac{4}{9} + \\frac{\\sqrt{6}}{36} & \\frac{4}{9} - \\frac{\\sqrt{6}}{36}  \\\\\n\\end{array}\n</math>\n\n====Radau IIA methods====\nThe ''c''<sub>i</sub> of this method are zeros of\n:<math>P_{s}(2x-1) - P_{s-1}(2x-1) = 0,</math>\nwhere <math>P_s</math> is the Legendre polynomial of degree ''s''. \nThe third-order method is given by\n\n:<math>\n\\begin{array}{c|cc}\n1/3 & 5/12 & -1/12\\\\\n1   & 3/4  &  1/4 \\\\\n\\hline\n    & 3/4 & 1/4 \\\\\n\\end{array}\n</math>\n\nThe fifth-order method is given by\n\n:<math>\n\\begin{array}{c|ccc}\n\\frac{2}{5} - \\frac{\\sqrt{6}}{10}   & \\frac{11}{45} - \\frac{7\\sqrt{6}}{360} & \\frac{37}{225} - \\frac{169\\sqrt{6}}{1800} & -\\frac{2}{225} + \\frac{\\sqrt{6}}{75} \\\\\n\\frac{2}{5} + \\frac{\\sqrt{6}}{10}  & \\frac{37}{225} + \\frac{169\\sqrt{6}}{1800} & \\frac{11}{45} + \\frac{7\\sqrt{6}}{360} & -\\frac{2}{225} - \\frac{\\sqrt{6}}{75}\\\\\n1                   & \\frac{4}{9} - \\frac{\\sqrt{6}}{36} & \\frac{4}{9} + \\frac{\\sqrt{6}}{36} & \\frac{1}{9}  \\\\\n\\hline\n    & \\frac{4}{9} - \\frac{\\sqrt{6}}{36} & \\frac{4}{9} + \\frac{\\sqrt{6}}{36} & \\frac{1}{9}  \\\\\n\\end{array}\n</math>\n\n==References==\n{{Reflist}}\n\n* {{Citation | last1=Hairer | first1=Ernst | last2=Nørsett | first2=Syvert Paul | last3=Wanner | first3=Gerhard | title=Solving ordinary differential equations I: Nonstiff problems | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-56670-0 | year=1993}}.\n* {{Citation | last1=Hairer | first1=Ernst | last2=Wanner | first2=Gerhard | title=Solving ordinary differential equations II: Stiff and differential-algebraic problems | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-60452-5 | year=1996}}.\n* {{Citation | last1=Hairer | first1=Ernst | last2=Lubich | first2=Christian | last3=Wanner | first3=Gerhard | title=Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=2nd | isbn=978-3-540-30663-4 | year=2006}}.\n\n{{Numerical integrators}}\n\n{{DEFAULTSORT:List of Runge-Kutta methods}}\n[[Category:Numerical differential equations]]\n[[Category:Mathematics-related lists|Runge-Kutta methods]]\n[[Category:Runge–Kutta methods]]"
    },
    {
      "title": "Loubignac iteration",
      "url": "https://en.wikipedia.org/wiki/Loubignac_iteration",
      "text": "{{refimprove|date=December 2017}}\n\nIn applied mathematics, '''Loubignac iteration''' is an [[iterative method]] in [[finite element method]]s. It gives continuous [[stress field]]. It is named after Gilles Loubignac, who published the method in 1977.\n\n== References ==\n* [https://arc.aiaa.org/doi/abs/10.2514/3.7464 Loubignac's paper]\n\n{{Numerical PDE}}\n\n[[Category:Continuum mechanics]]\n[[Category:Finite element method]]\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n[[Category:Structural analysis]]"
    },
    {
      "title": "MacCormack method",
      "url": "https://en.wikipedia.org/wiki/MacCormack_method",
      "text": "In [[computational fluid dynamics]], the '''MacCormack method''' is a widely used discretization scheme for the numerical solution of [[hyperbolic partial differential equation]]s. This second-order [[finite difference method]] was introduced by Robert W. MacCormack in 1969.<ref>MacCormack, R. W., [http://www.worldscientific.com/doi/abs/10.1142/9789812810793_0002 The Effect of viscosity in hypervelocity impact cratering], AIAA Paper, 69-354 (1969).</ref> The MacCormack method is elegant and easy to understand and program.<ref>[[John D. Anderson|Anderson, J. D., Jr.]], Computational Fluid Dynamics: The Basics with Applications, McGraw Hill (1994).</ref>\n\n== The algorithm ==\nThe MacCormack method is a variation of the [[Lax–Wendroff method|two-step Lax–Wendroff scheme]] but is much simpler in application. To illustrate the algorithm, consider the following first order hyperbolic equation\n:<math>\n  \\qquad \\frac{\\partial u}{\\partial t} + a \\frac{\\partial u}{\\partial x} = 0 .\n</math>\nThe application of MacCormack method to the above equation proceeds in two steps; a ''predictor step'' which is followed by a ''corrector step''. \n\n'''Predictor step:''' In the predictor step, a \"provisional\" value of <math>u</math> at time level <math>n+1</math> (denoted by <math>u_i^{\\overline{n+1}}</math>) is estimated as follows\n:<math>\n  u_i^{\\overline{n+1}} = u_i^n - a \\frac{\\Delta t}{\\Delta x} \\left( u_{i+1}^n - u_i^n \\right)\n</math>\nThe above equation is obtained by replacing the spatial and temporal derivatives in the previous first order hyperbolic equation using [[Finite difference#Forward, backward, and central differences|forward difference]]s.\n\n'''Corrector step:''' In the corrector step, the predicted value <math>u_i^{\\overline{n+1}}</math> is corrected according to the equation \n:<math>\n  u_i^{n+1} = u_i^{n+1/2} - a \\frac{\\Delta t}{2\\Delta x} \\left( u_i^{\\overline{n+1}}  - u_{i-1}^{\\overline{n+1}} \\right)\n</math>\nNote that the corrector step uses [[Finite difference#Forward, backward, and central differences|backward finite difference]] approximations for spatial derivative. Note also that the time-step used in the corrector step is <math>\\Delta t/2</math> in contrast to the <math>\\Delta t</math> used in the predictor step.\n\nReplacing the <math>u_i^{n+1/2}</math> term by the temporal average\n:<math>\n  u_i^{n+1/2} = \\frac{u_i^n + u_i^{\\overline{n+1}}}{2}\n</math>\nto obtain the corrector step as\n:<math>\n  u_i^{n+1} = \\frac{u_i^n + u_i^{\\overline{n+1}}}{2} - a \\frac{\\Delta t}{2\\Delta x} \\left( u_i^{\\overline{n+1}}  - u_{i-1}^{\\overline{n+1}} \\right)\n</math>\n\n=== Some remarks ===\nThe MacCormack method is well suited for [[Nonlinear system#Nonlinear differential equations|nonlinear equations]] (Inviscid [[Burgers equation]], [[Euler equations]], etc.) The order of differencing can be reversed for the time step (i.e., forward/backward followed by backward/forward). For nonlinear equations, this procedure provides the best results. For linear equations, the MacCormack scheme is equivalent to the [[Lax–Wendroff method]].<ref>Tannehill, J. C., [[Dale A. Anderson|Anderson, D. A.]], and Pletcher, R. H., Computational Fluid Dynamics and Heat Transfer, 2nd ed., Taylor & Francis (1997).</ref>\n\nUnlike first-order [[upwind scheme]], the MacCormack does not introduce [[Numerical diffusion|diffusive errors]] in the solution. However, it is known to introduce dispersive errors ([[Gibbs phenomenon]]) in the region where the gradient is high.\n\n== See also ==\n*[[Lax–Wendroff method]]\n*[[Upwind scheme]]\n*[[Hyperbolic partial differential equation]]s\n\n==References==\n{{reflist|colwidth=30em}}\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Maccormack Method}}\n[[Category:Computational fluid dynamics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Method of lines",
      "url": "https://en.wikipedia.org/wiki/Method_of_lines",
      "text": "[[File:Method of lines.gif|thumb|Method of lines - the example, which shows the origin of the name of method.]]\nThe '''method of lines''' (MOL, NMOL, NUMOL<ref name=Schiesser1991>{{cite book|last=Schiesser|first=W. E.|year=1991|title=The Numerical Method of Lines|publisher=Academic Press|isbn=0-12-624130-9}}</ref><ref name=Hamdi2007>{{citation|author1=Hamdi, S.|author2=W. E. Schiesser|author3=G. W. Griffiths|year=2007|url=http://www.scholarpedia.org/article/Method_of_Lines|title= Method of lines|work=Scholarpedia|volume=2|issue=7|page=2859|doi=10.4249/scholarpedia.2859}}</ref><ref name=Schiesser2009>{{cite book|last=Schiesser|first=W. E. |author2= G. W. Griffiths|year=2009|title=A Compendium of Partial Differential Equation Models:  Method of Lines Analysis with Matlab|publisher=Cambridge University Press|isbn=978-0-521-51986-1}}</ref>) is a technique for solving [[partial differential equations]] (PDEs) in which all but one dimension is discretized.  MOL allows standard, general-purpose methods and software, developed for the numerical integration of ODEs and DAEs, to be used. A large number of integration routines have been developed over the years in many different programming languages, and some have been published as [[open source]] resources.<ref name=Lee2004>{{cite book|last=Lee|first=H. J.|author2=W. E. Schiesser|year=2004|title=Ordinary and Partial Differential Equation Routines in C, C++, Fortran, Java, Maple and Matlab|publisher=CRC Press|isbn=1-58488-423-1}}</ref>\n\nThe method of lines most often refers to the construction or analysis of numerical methods for partial differential equations that proceeds by first discretizing the spatial derivatives only and leaving the time variable continuous.  This leads to a system of ordinary differential equations to which a numerical method for initial value ordinary equations can be applied.  The method of lines in this context dates back to at least the early 1960s.<ref name=Sarmin1962>{{citation|author1=E. N. Sarmin|author2=L. A. Chudov|year=1963|title=On the stability of the numerical integration of systems of ordinary differential equations arising in the use of the straight line method|work=USSR Computational Mathematics and Mathematical Physics|volume=3|issue=6|pages=1537–1543|doi=10.1016/0041-5553(63)90256-8}}</ref>  Many papers discussing the  accuracy and stability of the method of lines for various types of partial differential equations have appeared since.<ref name=Zafarullah1970>{{citation|author1=A. Zafarullah|year=1970|title=Application of the Method of Lines to Parabolic Partial Differential Equations With Error Estimates|work=Journal of the Association for Computing Machinery|volume=17|issue=2|pages=294–302|doi=10.1145/321574.321583}}</ref><ref name=Verwer1984>{{citation|author1=J. G. Verwer|author2=J. M. Sanz-Serna|year=1984|title=Convergence of method of lines approximations to partial differential equations|work=Computing|volume=33|issue=3-4|pages=297–313|doi=10.1007/bf02242274}}</ref>\n\n== Application to elliptical equations ==\nMOL requires that the PDE problem is well-posed as an initial value ([[cauchy problem|Cauchy]]) problem in at least one dimension, because ODE and DAE integrators are [[initial value problem]] (IVP) solvers. Thus it cannot be used directly on purely [[elliptic partial differential equations]], such as [[Laplace's equation]]. However, MOL has been used to solve Laplace's equation by using the ''method of false transients''.<ref name=Schiesser1991 /><ref name=Schiesser1994>{{cite book|last=Schiesser|first=W. E.|year=1994|title=Computational mathematics in Engineering and Applied Science: ODEs, DAEs and PDEs|publisher=CRC Press|isbn=0-8493-7373-5}}</ref> In this method, a time derivative of the dependent variable is added to Laplace’s equation. Finite differences are then used to approximate the spatial derivatives, and the resulting system of equations is solved by MOL. It is also possible to solve elliptical problems by a ''semi-analytical method of lines''.<ref name=Subramanian2004>{{citation|last=Subramanian|first=V.R.|author2=R.E. White|year=2004|title=Semianalytical method of lines for solving elliptic partial differential equations|work=Chemical Engineering Science|volume=59|pages=781–788|doi=10.1016/j.ces.2003.10.019}}</ref> In this method, the discretization process results in a set of ODE's that are solved by exploiting  properties of the associated exponential matrix.\n\nRecently, to overcome the stability issues associated with the method of false transients, a perturbation approach was proposed which was found to be more robust than standard method of false transients for a wide range of elliptic PDEs.<ref>{{citation|author1=P. W. C. Northrop|author2=P. A. Ramachandran|author3=W. E. Schiesser|author4=V. R. Subramanian|year=2013|title=A Robust False Transient Method of Lines for Elliptic Partial Differential Equations|work=Chem. Eng. Sci.|volume= 90|pages= 32–39|doi=10.1016/j.ces.2012.11.033}}</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n*[http://www.maple.eece.wustl.edu/falsetransient.html False Transient Method of Lines - sample code]\n*[https://reference.wolfram.com/mathematica/tutorial/NDSolvePDE.html The Numerical Method of Lines]\n<!-- * {{cite book|last=Vande Wouwer | first=Alain|year=2001|title=Adaptive Method of Lines|publisher=Chapman & Hall/CRC|isbn=1-58488-231-X}} -->\n\n{{wikibooks|Partial Differential Equations|Method of Lines}}\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Method Of Lines}}\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n\n{{applied-math-stub}}"
    },
    {
      "title": "Microscale and macroscale models",
      "url": "https://en.wikipedia.org/wiki/Microscale_and_macroscale_models",
      "text": "[[File:Coexistence-Phalaris-CA-ODE-1400619436.png|thumb|right|upright=1.5|''Microscale and related macroscale models of coexistence in Phalaris arundinacea, a globally distributed grass. Each color represents the spatial extent of a distinct genotype in a microscale model using stochastic cellular automata. Each curve on the graph represents the population level of a corresponding genotype in a macroscale differential equation model.''<ref name=\"Nelson 2014\"/>]]\n\n'''Microscale models''' form a broad class of [[computational model]]s that simulate fine-scale details, in contrast with '''macroscale models''', which amalgamate details into select categories.<ref name=\"Gustafsson 2010\"/><ref name=\"Gustafsson 2007\"/> Microscale and macroscale models can be used together to understand different aspects of the same problem.\n\n== Applications ==\n\nMacroscale models can include [[ordinary differential equation|ordinary]], [[partial differential equation|partial]], and [[integro-differential equation|integro-differential]] equations, where categories and [[Flow (mathematics)|flows]] between the categories determine the dynamics, or may involve only [[algebraic equation]]s. An abstract macroscale model may be combined with more detailed microscale models. Connections between the two scales are related to [[multiscale modeling]]. One mathematical technique for multiscale modeling of nanomaterials is based upon the use of [[Multiscale Green's function]].\n\nIn contrast, microscale models can simulate a variety of details, such as individual bacteria in [[biofilm]]s,<ref name=\"Dillon 1996\"/> individual pedestrians in simulated neighborhoods,<ref name=\"Bandini 2007\"/> individual light beams in [[Ray tracing (graphics)|ray-tracing imagery]],<ref name=\"Gartley 2008\"/> individual houses in cities,<ref name=\"OSullivan 2002\"/> fine-scale pores and fluid flow in batteries,<ref name=\"Less 2012\"/> fine-scale compartments in meteorology,<ref name=\"Knutz 2000\"/> fine-scale structures in particulate systems,<ref name=\"Marchisio 2013\"/> and other models where interactions among individuals and background conditions determine the dynamics.\n\n[[discrete event simulation|Discrete-event]] models, [[individual-based model|individual-based]] models, and [[agent-based model|agent-based]] models are special cases of microscale models. However, microscale models do not require discrete individuals or discrete events. Fine details on topography, buildings, and trees can add microscale detail to [[Microscale meteorology|meteorological simulations]] and can connect to what are called mesoscale models in that discipline.<ref name=\"Knutz 2000\"/> Square-meter-sized landscape resolution available from {{Smallcaps|lidar}} images allow waterflow across land surfaces to be modeled, for example rivulets and water pockets, using gigabyte-sized arrays of detail.<ref name=\"Barnes 2014\"/> Models of [[Artificial neural network|neural networks]] may include individual neurons but may run in continuous time and thereby lack precise discrete events.<ref name=\"You 1993\"/>\n\n== History ==\n\nIdeas for computational microscale models arose in the earliest days of computing and were applied to complex systems that could not accurately be described by standard mathematical forms.\n\nTwo themes emerged in the work of two founders of modern computation around the middle of the 20th century. First, pioneer [[Alan Turing]] used simplified macroscale models to understand the chemical basis of [[the chemical basis of morphogenesis|morphogenesis]], but then proposed and used computational microscale models to understand the nonlinearities and other conditions that would arise in actual biological systems.<ref name=\"Turing 1952\"/> Second, pioneer [[John von Neumann]] created a [[cellular automaton]] to understand the possibilities for self-replication of arbitrarily complex entities,<ref name=\"Burks 1966\"/> which had a microscale representation in the cellular automaton but no simplified macroscale form. This second theme is taken to be part of [[agent based model|agent-based models]], where the entities ultimately can be artificially intelligent agents operating autonomously.\n\nBy the last quarter of the 20th century, [[Moore's Law|computational capacity]] had grown so far<ref name=\"Moore 1965\"/><ref name=\"Berezin 2004\"/> that up to tens of thousands of individuals or more could be included in microscale models, and that sparse arrays could be applied to also achieve high performance.<ref name=\"Brown 1988\"/> Continued increases in computing capacity allowed hundreds of millions of individuals to be simulated on ordinary computers with microscale models by the early 21st century.\n\nThe term \"microscale model\" arose later in the 20th century and now appears in the literature of many branches of physical and biological science.<ref name=\"Bandini 2007\"/><ref name=\"OSullivan 2002\"/><ref name=\"Less 2012\"/><ref name=\"Knutz 2000\"/><ref name=\"Frind 1987\"/>\n\n== Example ==\n\nFigure&nbsp;1 represents a fundamental macroscale model: [[exponential growth|population growth]] in an unlimited environment. Its equation is relevant elsewhere, such as compounding growth of [[capital (economics)|capital]] in economics or [[exponential decay]] in physics. It has one amalgamated variable, <math>N(t)</math>, the number of individuals in the population at some time <math>t</math>. It has an amalgamated parameter <math>r=\\beta-\\delta</math>, the annual growth rate of the population, calculated as the difference between the annual birth rate <math>\\beta</math> and the annual death rate <math>\\delta</math>. Time <math>t</math> can measured in years, as shown here for illustration, or in any other suitable unit.\n\nThe macroscale model of Figure&nbsp;1 amalgamates parameters and incorporates a number of simplifying approximations: \n#the birth and death rates are constant;\n#all individuals are identical, with no genetics or age structure;\n#fractions of individuals are meaningful;\n#parameters are constant and do not evolve;\n#habitat is perfectly uniform;\n#no immigration or emigration occurs; and \n#randomness does not enter. \nThese approximations of the macroscale model can all be refined in analogous microscale models.\n\nOn the first approximation listed above—that birth and death rates are constant—the macroscale model of the Figure&nbsp;1 is exactly the mean of a large number of stochastic trials with the growth rate fluctuating randomly in each instance of time.<ref name=\"May 1974\"/> Microscale stochastic details are subsumed into a partial differential [[diffusion equation]] and that equation is used to establish the equivalence.\n\nTo relax other assumptions, researchers have applied computational methods. Figure&nbsp;2 is a sample computational microscale algorithm that corresponds to the macroscale model of Figure&nbsp;1. When all individuals are identical and mutations in birth and death rates are disabled, the microscale dynamics closely parallel the macroscale dynamics (Figures&nbsp;3A and&nbsp;3B). The slight differences between the two models arise from stochastic variations in the microscale version not present in the deterministic macroscale model. These variations will be different each time the algorithm is carried out, arising from intentional variations in random number sequences.\n\nWhen not all individuals are identical, the microscale dynamics can differ significantly from the macroscale dynamics, simulating more realistic situations than can be modeled at the macroscale (Figures&nbsp;3C and&nbsp;3D). The microscale model does not explicitly incorporate the differential equation, though for large populations it simulates it closely. When individuals differ from one another, the system has a well defined behavior but the differential equations governing that behavior are difficult to codify. The algorithm of Figure&nbsp;2 is a basic example of what is called an [[equation-free modeling|equation-free model]].<ref name=\"Kevrekidis 2009\"/>\n\nWhen mutations are enabled in the microscale model (<math>\\sigma>0</math>), the population grows more rapidly than in the macroscale model (Figures&nbsp;3C and&nbsp;3D). Mutations in parameters allow some individuals to have higher birth rates and others to have lower death rates, and those individuals contribute proportionally more to the population. All else being equal, the average birth rate drifts to higher values and the average death rate drifts to lower values as the simulation progresses. This drift is tracked in the data structures named ''beta'' and ''delta'' of the microscale algorithm of Figure&nbsp;2.\n\nThe algorithm of Figure&nbsp;2 is a simplified a microscale model using the [[Euler method]]. Other algorithms such as the Gillespie method<ref name=\"Gillespie 1977\"/> and the [[discrete event simulation|discrete event method]]<ref name=\"Brown 1988\"/> are also used in practice. Versions of the algorithm in practical use include efficiencies such as removing individuals from consideration once they die (to reduce memory requirements and increase speed), and scheduling stochastic events into the future (to provide a continuous time scale and to further improve speed).<ref name=\"Brown 1988\"/> Such approaches can be orders of magnitude faster.\n\n== Complexity ==\n\nThe complexity of systems addressed by microscale models leads to complexity in the models themselves, and the specification of a microscale model can be tens or hundreds of times larger than its corresponding macroscale model. (The simplified example of Figure&nbsp;2 has 25 times as many lines in its specification as does Figure&nbsp;1.) Since bugs occur in computer software and cannot completely be removed by standard methods such as testing,<ref name=\"Dijkstra 1970\"/> and since complex models often are neither published in detail nor peer-reviewed, their validity has been called into question.<ref name=\"Saltelli 2014\"/> Guidelines on best practices for microscale models exist<ref name=\"Baxter 2006\"/> but no papers on the topic claim a full resolution of the problem of validating complex models.\n\n== Future ==\n\nComputing capacity is reaching levels where populations of entire countries or even the entire world are within the reach of microscale models, and improvements in census and travel data allow further improvements in parameterizing such models. Remote sensors from [[earth observation satellite|Earth-observing satellites]] and from ground-based observatories such as the [[National Ecological Observatory Network]] (NEON) provide large amounts of data for calibration. Potential applications range from predicting and reducing the spread of disease to helping understand the dynamics of the earth.\n\n== Figures ==\n\n[[File:MacroscaleModel-ExponentialGrowth-5769372.png|thumb|left|upright=2.5|Figure 1. Macroscale equations]]\n\n'''Figure&nbsp;1.''' ''One of the simplest of macroscale models: an [[ordinary differential equation]] describing continuous [[exponential growth]]. <math>N(t)</math> is the size of the population at time <math>t</math>, <math>dN(t)/dt</math> is the rate of change through time in the single dimension <math>N</math>. <math>N(0)</math> is the initial population at <math>t=0</math>, <math>\\beta</math> is a birth rate per time unit, and <math>\\delta</math> is a death rate per time unit. At the left is the differential form; at the right is the explicit solution in terms of standard mathematical functions, which follows in this case from the differential form. Almost all macroscale models are more complex than this example, in that they have multiple dimensions, lack explicit solutions in terms of standard mathematical functions, and must be understood from their differential forms.''\n{{clear left}}\n\n[[File:Microscale Algorithm, Exponential Growth, 1396584021.png|thumb|left|upright=2.5|Figure 2. Microscale algorithm corresponding to equations of Figure 1.]]\n'''Figure&nbsp;2.''' ''A basic algorithm applying the [[Euler method]] to an individual-based model. See text for discussion. The algorithm,  represented in [[pseudocode]], begins with invocation of procedure <math>\\operatorname{Microscale}()</math>, which uses the data structures to carry out the simulation according to the numbered steps described at the right. It repeatedly invokes function <math>\\operatorname{Mutation}(v)</math>, which returns its parameter perturbed by a random number drawn from a uniform distribution with standard deviation defined by the variable <math>sigma</math>. (The square root of 12 appears because the [[standard deviation]] of a [[uniform distribution (continuous)|uniform distribution]] includes that factor.) Function <math>\\operatorname{Rand}()</math> in the algorithm is assumed to return a uniformly distributed random number <math>0\\le Rand()<1</math>. The data are assumed to be reset to their initial values on each invocation of <math>\\operatorname{Microscale}()</math>.''\n{{clear left}}\n[[File:Microscale-Macroscale-ModelGraphs-ExponentialGrowth-1397621139.png|thumb|left|upright=2.5|Figure 3. Dynamics]]\n'''Figure&nbsp;3.''' ''Graphical comparison of the dynamics of macroscale and microscale simulations of Figures&nbsp;1 and&nbsp;2, respectively.''\n:'''(A)'''&nbsp;''The black curve plots the exact solution to the macroscale model of Figure&nbsp;1 with <math>\\beta=1/5</math> per year, <math>\\delta=1/10</math> per year, and <math>N_0=1000</math> individuals.''\n:'''(B)'''&nbsp;''Red dots show the dynamics of the microscale model of Figure&nbsp;2, shown at intervals of one year, using the same values of <math>\\alpha</math>, <math>\\beta</math>, and <math>N_0</math>, and with no mutations <math>(\\sigma=0)</math>.''\n:'''(C)'''&nbsp;''Blue dots show the dynamics of the microscale model with mutations having a standard deviation of <math>\\sigma=0.006</math>.'' \n:'''(D)'''&nbsp;''Green dots show results with larger mutations, <math>\\sigma=0.010</math>.''\n{{clear left}}\n== References ==\n\n{{reflist|30em|refs=\n<ref name=\"Bandini 2007\">{{cite journal\n|first1 = Stefania\n|last1  = Bandini\n|first2 = Mizar\n|last2  = Luca Federici\n|first3 = Sara\n|last3  = Manzoni\n|year = 2007\n|title = SCA approach to microscale modelling of paradigmatic emergent crowd behaviors\n|journal = SCSC\n|pages = 1051–1056\n}}\n</ref>\n\n<ref name=\"Barnes 2014\">{{cite journal\n|first1 = Richard\n|last1 = Barnes\n|first2 = Clarence\n|last2   = Lehman\n|first3 = David\n|last3  = Mulla\n|title = An efficient assignment of drainage direction over flat surfaces in raster digital elevation models\n|journal = Computers and Geosciences\n|volume = 62\n|pages = 128–135\n|doi=10.1016/j.cageo.2013.01.009\n|arxiv= 1511.04433\n|bibcode= 2014CG.....62..128B\n|year = 2014\n}}\n</ref>\n\n<ref name=\"Baxter 2006\">{{cite journal\n|year = 2006\n|first1 = Susan M.\n|last1 = Baxter\n|first2 = Steven W.\n|last2   = Day\n|first3 = Jacquelyn S.\n|last3  = Fetrow\n|first4 = Stephanie J.\n|last4  = Reisinger\n|title = Scientific software development is not an oxymoron\n|journal = PLOS Computational Biology\n|volume = 2\n|issue = 9\n|pages = 975–978\n|doi=10.1371/journal.pcbi.0020087\n|pmid = 16965174\n|bibcode= 2006PLSCB...2...87B\n}}\n</ref>\n\n<ref name=\"Berezin 2004\">{{cite book\n|first1 = A. A.\n|last1 = Berezin\n|first2 = A. M.\n|last2   = Ibrahim\n|year = 2004\n|chapter = Reliability of Moore's Law: A measure of maintained quality\n|title = Quality, Reliability and Maintenance |editor=G. J. McNulty |publisher=John Wiley and Sons\n}}\n</ref>\n\n<ref name=\"Brown 1988\">{{cite journal\n|first = Randy\n|last = Brown\n|year = 1988\n|title = Calendar Queues: A fast O(1) priority queue implementation for the simulation event set problem\n|journal = Communications of the ACM\n|volume = 31\n|issue = 10\n|pages = 1220–1227\n|doi=10.1145/63039.63045\n}}\n</ref>\n\n<ref name=\"Burks 1966\">{{cite book\n|first1 = A. W.\n|last1 = Burks\n|year = 1966\n|title = Theory of self-reproducing automata\n|publisher = University of Illinois Press\n}}\n</ref>\n\n<ref name=\"Dijkstra 1970\">{{cite book\n|first = Edsger\n|last = Dijkstra\n|year = 1970\n|title = Notes on structured programming\n|series= T.H. Report 70-WSK-03, EWD249\n|publisher = Technological University |location= Eindhoven, The Netherlands\n}}\n</ref>\n\n<ref name=\"Dillon 1996\">{{cite journal\n|first1 = Robert\n|last1 = Dillon\n|first2 = Lisa\n|last2   = Fauci | author2-link = Lisa Fauci\n|first3 = Aaron\n|last3  = Fogelson\n|first4 = Donald\n|last4  = Gaver III\n|year = 1996\n|title = Modeling biofilm processes using the immersed boundary method\n|journal = Journal of Computational Physics\n|volume = 129\n|issue = 1\n|pages = 57–73\n|doi=10.1006/jcph.1996.0233\n|bibcode= 1996JCoPh.129...57D\n}}\n</ref>\n\n<ref name=\"Frind 1987\">{{cite journal\n|first1 = E. O.\n|last1 = Frind\n|first2 = E. A.\n|last2   = Sudicky\n|first3 = S. L.\n|last3  = Schellenberg\n|year = 1987\n|title = Microscale modelling in the study of plume evolution in heterogeneous media\n|journal = Stochastic Hydrology and Hydraulics\n|volume = 1\n|issue = 4\n|pages = 263–279\n|doi=10.1007/bf01543098\n|bibcode = 1987SHH.....1..263F\n}}\n</ref>\n\n<ref name=\"Gartley 2008\">{{cite journal\n|first1 = M. G.\n|last1 = Gartley\n|first2 = J. R.\n|last2   = Schott\n|first3 = S. D.\n|last3  = Brown\n|year = 2008\n|title = Micro-scale modeling of contaminant effects on surface optical properties\n|journal = Optical Engineering Plus Applications, International Society for Optics and Photonics\n|pages = 70860H\n}}\n</ref>\n\n<ref name=\"Gillespie 1977\">{{cite journal\n|first = Daniel T.\n|last = Gillespie\n|year = 1977\n|title = Exact stochastic simulation of coupled chemical reactions\n|journal = Journal of Physical Chemistry\n|volume = 81\n|issue = 25\n|pages = 2340–2361\n|doi=10.1021/j100540a008\n|citeseerx = 10.1.1.704.7634\n}}\n</ref>\n\n<ref name=\"Gustafsson 2007\">{{cite journal\n|first1 = Leif\n|last1 = Gustafsson\n|first2 = Mikael\n|last2   = Sternad\n|year = 2007\n|title = Bringing consistency to simulation of population models: Poisson Simulation as a bridge between micro and macro simulation\n|journal = Mathematical Biosciences\n|volume = 209\n|issue = 2\n|pages = 361–385\n|doi=10.1016/j.mbs.2007.02.004\n|pmid = 17412368\n}}\n</ref>\n\n<ref name=\"Gustafsson 2010\">{{cite journal\n|first1 = Leif\n|last1 = Gustafsson\n|first2 = Mikael\n|last2   = Sternad\n|year = 2010\n|title = Consistent micro, macro, and state-based population modelling\n|journal = Mathematical Biosciences\n|volume = 225\n|pages = 94–107\n|doi=10.1016/j.mbs.2010.02.003\n|pmid=20171974\n|issue=2\n}}\n</ref>\n\n<ref name=\"Kevrekidis 2009\">{{cite journal\n|first1 = Ioannis G.\n|last1 = Kevrekidis\n|first2 = Giovanni\n|last2   = Samaey\n|year = 2009\n|title = Equation-free multiscale computation: Algorithms and applications\n|journal = Annual Review of Physical Chemistry\n|volume = 60\n|pages = 321–344\n|doi=10.1146/annurev.physchem.59.032607.093610\n|bibcode = 2009ARPC...60..321K\n}}\n</ref>\n\n<ref name=\"Knutz 2000\">{{cite journal\n|first1 = R.\n|last1 = Knutz\n|first2 = I.\n|last2   = Khatib\n|first3 = N.\n|last3  = [[Nicolas Moussiopoulos|Moussiopoulos]]\n|year = 2000\n|title = Coupling of mesoscale and microscale models—an approach to simulate scale interaction\n|journal = Environmental Modelling and Software\n|volume = 15\n|issue = 6–7\n|pages = 597–602\n|doi=10.1016/s1364-8152(00)00055-4\n}}\n</ref>\n\n<ref name=\"Less 2012\">{{cite journal\n|first1 = G. B.\n|last1 = Less\n|first2 = J. H.\n|last2   = Seo\n|first3 = S.\n|last3  = Han\n|first4 = A. M.\n|last4  = Sastry\n|first5 = J.\n|last5  = Zausch\n|first6 = A.\n|last6  = Latz\n|first7 = S.\n|last7  = Schmidt\n|first8 = C.\n|last8  = Wieser\n|first9 = D.\n|last9  = Kehrwald\n|first10 = S.\n|last10  = Fell\n|year = 2012\n|title = Microscale modeling of Li-Ion batteries: Parameterization and validation\n|journal = Journal of the Electrochemical Society\n|volume = 159\n|issue = 6\n|pages = A697–A704\n|doi=10.1149/2.096205jes\n}}\n</ref>\n\n<ref name=\"Marchisio 2013\">{{cite book\n|first1 = Daniele L.\n|last1 = Marchisio\n|first2 = Rodney O.\n|last2   = Fox\n|year = 2013\n|title = Computational models for polydisperse particulate and multiphase systems\n|publisher = Cambridge University Press\n}}\n</ref>\n\n<ref name=\"May 1974\">{{cite book\n|first1 = Robert\n|last1 = May\n|year = 1974\n|title = Stability and complexity in model ecosystems\n|publisher = Princeton University Press\n|pages = 114–117\n}}\n</ref>\n\n<ref name=\"Moore 1965\">{{cite journal\n|first = Gordon E.\n|last = Moore\n|year = 1965\n|title = Cramming more components onto integrated circuits\n|journal = Electronics\n|volume = 38\n|issue = 8\n}}\n</ref>\n\n<ref name=\"Nelson 2014\">{{cite thesis\n|first1 = Michael France\n|last1 = Nelson\n|year = 2014\n|title = Experimental and simulation studies of the population genetics, drought tolerance, and vegetative growth of ''Phalaris arundinacea''\n|type = Doctoral Dissertation\n|publisher = University of Minnesota, USA\n}}\n</ref>\n\n<ref name=\"OSullivan 2002\">{{cite journal\n|first = David\n|last = O'Sullivan\n|year = 2002\n|title = Toward microscale spatial modeling of gentrification\n|journal = Journal of Geographical Systems\n|volume = 4\n|issue = 3\n|pages = 251–274\n|doi=10.1007/s101090200086\n|bibcode = 2002JGS.....4..251O\n}}\n</ref>\n\n<ref name=\"Saltelli 2014\">{{cite journal\n|first1 = Andrea\n|last1 = Saltelli\n|first2 = Silvio\n|last2   = Funtowicz\n|title = When all models are wrong\n|year = 2014\n|journal = Issues in Science and Technology\n|volume = 30\n|issue = 2\n|pages = 79–85\n}}\n</ref>\n\n<ref name=\"Turing 1952\">{{cite journal\n|first = Alan M.\n|last = Turing\n|year = 1952\n|title = The chemical basis of morphogenesis\n|journal = Philosophical Transactions of the Royal Society of London B: Biological Sciences\n|volume = 237\n|issue = 641\n|pages = 37–72\n|doi=10.1098/rstb.1952.0012\n|bibcode = 1952RSPTB.237...37T\n}}\n</ref>\n\n<ref name=\"You 1993\">{{cite journal\n|title = Dynamic process modeling with recurrent neural networks\n|first1 = Yong\n|last1 = You\n|first2 = Michael\n|last2   = Nikolaou\n|journal = American Institute of Chemical Engineers Journal\n|volume = 39\n|issue = 10\n|pages = 1654–1667\n|doi=10.1002/aic.690391009\n|year = 1993\n}}\n</ref>\n\n}}\n\n{{DEFAULTSORT:Microscale and macroscale models}}\n[[Category:Dynamical systems]]\n[[Category:Mathematical and theoretical biology]]\n[[Category:Mathematical modeling]]\n[[Category:Numerical differential equations]]\n[[Category:Population models]]\n[[Category:Scientific modeling]]\n[[Category:Simulation]]\n[[Category:Crowds]]"
    },
    {
      "title": "Midpoint method",
      "url": "https://en.wikipedia.org/wiki/Midpoint_method",
      "text": "{{For|the midpoint rule in numerical [[Numerical integration|quadrature]]|rectangle method}}\n\n[[File:Midpoint method illustration.png|right|thumb|Illustration of the midpoint method assuming that <math>y_n</math> equals the exact value <math>y(t_n).</math> The midpoint method computes <math>y_{n+1}</math> so that the red chord is approximately parallel to the tangent line at the midpoint (the green line).]]\nIn [[numerical analysis]], a branch of [[applied mathematics]], the '''midpoint method''' is a one-step method for [[Numerical ordinary differential equations|numerically]] solving the [[ordinary differential equation|differential equation]],\n:<math> y'(t) = f(t, y(t)), \\quad y(t_0) = y_0 </math>.\nThe explicit midpoint method is given by the formula\n:<math> y_{n+1} = y_n + hf\\left(t_n+\\frac{h}{2},y_n+\\frac{h}{2}f(t_n, y_n)\\right),  \\qquad\\qquad (1e)</math>\nthe implicit midpoint method by\n:<math> y_{n+1} = y_n + hf\\left(t_n+\\frac{h}{2},\\frac12 (y_n+y_{n+1})\\right),  \\qquad\\qquad (1i)</math>\nfor <math>n=0, 1, 2, \\dots</math> Here, <math>h</math> is the ''step size'' &mdash; a small positive number, <math>t_n=t_0 + n h,</math> and <math>y_n</math> is the computed approximate value of <math>y(t_n).</math> The explicit midpoint method is also known as the '''modified Euler method''',<ref>{{harvnb|Süli|Mayers|2003|p=328}}</ref> the implicit method is the most simple [[collocation method]], and, applied to Hamiltonian dynamics, a [[symplectic integrator]].\n\nThe name of the method comes from the fact that in the formula above the function <math>f</math> giving the slope of the solution is evaluated at <math>t=t_n+h/2= \\tfrac{t_n+t_{n+1}}{2},</math> the midpoint between <math>t_n</math> at which the value of <math>y(t)</math> is known and <math>t_{n+1}</math> at which the value of <math>y(t)</math> needs to be found.\n\nA geometric interpretation may give a better intuitive understanding of the method (see figure at right). In the basic [[Euler's method]], the tangent of the curve at <math>(t_n, y_n)</math> is computed using <math>f(t_n, y_n)</math>.  The next value <math> y_{n+1}</math> is found where the tangent intersects the vertical line <math>t=t_{n+1}</math>.  However, if the second derivative is only positive between <math>t_n</math> and <math>t_{n+1}</math>, or only negative (as in the diagram), the curve will increasingly veer away from the tangent, leading to larger errors as <math>h</math> increases.  The diagram illustrates that the tangent at the midpoint (upper, green line segment) would most likely give a more accurate approximation of the curve in that interval.  This tangent is estimated by using the original Euler's method to estimate the value of <math>y(t)</math> at the midpoint, then computing the slope of the tangent with <math>f()</math>. Finally, the improved tangent is used to calculate the value of <math>y_{n+1}</math> from <math>y_n</math>.  This last step is represented by the red chord in the diagram.  Note that the red chord is not exactly parallel to the green segment (the true tangent), due to the error in estimating the value of <math>y(t)</math> at the midpoint.\n\nThe local error at each step of the midpoint method is of order <math>O\\left(h^3\\right)</math>, giving a global error of order <math>O\\left(h^2\\right)</math>.  Thus, while more computationally intensive than Euler's method, the midpoint method's error generally decreases faster as <math>h \\to 0</math>.\n\nThe methods are examples of a class of higher-order methods known as [[Runge–Kutta methods]].\n\n==Derivation of the midpoint method==\n[[File:Numerical integration illustration, step=1.svg|right|thumb|Illustration of numerical integration for the equation <math>y'=y, y(0)=1.</math> Blue: the [[Euler method]], green: the midpoint method, red: the exact solution, <math>y=e^t.</math> The step size is <math>h=1.0.</math>]]\n[[File:Numerical integration illustration step=0.25.svg|right|thumb|The same illustration for <math>h=0.25.</math> It is seen that the midpoint method converges faster than the Euler method.]]\n\nThe midpoint method is a refinement of the Euler's method\n:<math> y_{n+1} = y_n + hf(t_n,y_n),\\, </math>\nand is derived in a similar manner. \nThe key to deriving Euler's method is the approximate equality\n:<math> y(t+h) \\approx y(t) + hf(t,y(t)) \\qquad\\qquad (2)</math>\nwhich is obtained from the slope formula\n:<math> y'(t) \\approx \\frac{y(t+h) - y(t)}{h} \\qquad\\qquad (3)</math>\nand keeping in mind that <math> y' = f(t, y).</math>\n\nFor the midpoint methods, one replaces (3) with the more accurate\n:<math> y'\\left(t+\\frac{h}{2}\\right) \\approx \\frac{y(t+h) - y(t)}{h} </math>\nwhen instead of (2) we find\n:<math> y(t+h) \\approx y(t) + hf\\left(t+\\frac{h}{2},y\\left(t+\\frac{h}{2}\\right)\\right). \\qquad\\qquad (4)</math>\n\nOne cannot use this equation to find <math> y(t+h)</math> as one does not know <math>y</math> at <math>t+h/2</math>. The solution is then to use a [[Taylor series]] expansion exactly as if using the [[Euler method]] to solve for <math>y(t+h/2)</math>: \n:<math>y\\left(t + \\frac{h}{2}\\right) \\approx y(t) + \\frac{h}{2}y'(t)=y(t) + \\frac{h}{2}f(t, y(t)),</math>\nwhich, when plugged in (4), gives us\n:<math>y(t + h) \\approx y(t) + hf\\left(t + \\frac{h}{2}, y(t) + \\frac{h}{2}f(t, y(t))\\right)</math>\nand the explicit midpoint method (1e).\n\nThe implicit method (1i) is obtained by approximating the value at the half step <math>t+h/2</math> by the midpoint of the line segment from <math>y(t)</math> to <math>y(t+h)</math>\n:<math>y\\left(t+\\frac h2\\right)\\approx \\frac12\\bigl(y(t)+y(t+h)\\bigr)</math>\nand thus\n:<math>\\frac{y(t+h)-y(t)}{h}\\approx y'\\left(t+\\frac h2\\right)\\approx k=f\\left(t+\\frac h2,\\frac12\\bigl(y(t)+y(t+h)\\bigr)\\right)</math> \nInserting the approximation <math>y_n+h\\,k</math> for <math>y(t_n+h)</math>\nresults in the implicit Runge-Kutta method\n:<math>\\begin{align}\nk&=f\\left(t_n+\\frac h2,y_n+\\frac h2 k\\right)\\\\\ny_{n+1}&=y_n+h\\,k\n\\end{align}</math>\nwhich contains the implicit Euler method with step size <math>h/2</math> as its first part.\n\nBecause of the time symmetry of the implicit method, all\nterms of even degree in <math>h</math> of the local error cancel, so that the local error is automatically of order <math>\\mathcal O(h^3)</math>. Replacing the implicit with the explicit Euler method in the determination of <math>k</math> results again in the explicit midpoint method.\n\n==See also==\n* [[Rectangle method]]\n* [[Heun's method]]\n* [[Leapfrog integration]] and [[Verlet integration]]\n\n==Notes==\n{{reflist}}\n\n==References==\n\n* {{cite book\n|author1=Griffiths,D. V. |author2=Smith, I. M. |title=Numerical methods for engineers: a programming approach\n|publisher=CRC Press\n|location=Boca Raton\n|year=1991\n|isbn=0-8493-8610-1\n|oclc=\n|doi=\n|page=218\n}}\n* {{Citation | last1=Süli | first1=Endre | last2=Mayers | first2=David | title=An Introduction to Numerical Analysis | publisher=[[Cambridge University Press]] | isbn=0-521-00794-1 | year=2003}}.\n\n{{Numerical integrators}}\n\n[[Category:Numerical differential equations]]\n[[Category:Runge–Kutta methods]]"
    },
    {
      "title": "Milstein method",
      "url": "https://en.wikipedia.org/wiki/Milstein_method",
      "text": "In [[mathematics]], the '''Milstein method''' is a technique for the approximate [[numerical analysis|numerical solution]] of a [[stochastic differential equation]]. It is named after [[Grigori N. Milstein]] who first published the method in 1974.<ref>{{cite journal|first=G. N.|last=Mil'shtein|title=Approximate integration of stochastic differential equations|journal=Teoriya Veroyatnostei i ee Primeneniya|volume=19|issue=3|year=1974| pages=583–588| url =http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=tvp&paperid=2929&option_lang=eng|language=Russian}}</ref><ref>{{Cite journal | last1 = Mil’shtein | first1 = G. N. | title = Approximate Integration of Stochastic Differential Equations | doi = 10.1137/1119062 | journal = Theory of Probability & Its Applications | volume = 19 | issue = 3 | pages = 557–000 | year = 1975 | pmid =  | pmc = }}</ref>\n\n==Description==\nConsider the [[autonomous equation|autonomous]] [[Itō calculus|Itō]] stochastic differential equation\n\n:<math>\\mathrm{d} X_t = a(X_t) \\, \\mathrm{d} t + b(X_t) \\, \\mathrm{d} W_t,</math>\n\nwith [[initial condition]] ''X''<sub>0</sub>&nbsp;=&nbsp;''x''<sub>0</sub>, where ''W''<sub>''t''</sub> stands for the [[Wiener process]], and suppose that we wish to solve this SDE on some interval of time&nbsp;[0,&nbsp;''T'']. Then the '''Milstein approximation''' to the true solution ''X'' is the [[Markov chain]] ''Y'' defined as follows:\n\n* partition the interval [0,&nbsp;''T''] into ''N'' equal subintervals of width <math>\\Delta t>0</math>:\n\n:<math>0 = \\tau_0 < \\tau_1 < \\dots < \\tau_N = T\\text{ with }\\tau_n:=n\\Delta t\\text{ and }\\Delta t = \\frac{T}{N};</math>\n\n* set <math>Y_0 = x_0;</math>\n* recursively define <math>Y_n</math> for <math>1 \\leq n \\leq N</math> by\n\n:<math>Y_{n + 1} = Y_n + a(Y_n) \\Delta t + b(Y_n) \\Delta W_n + \\frac{1}{2} b(Y_n) b'(Y_n) \\left( (\\Delta W_n)^2 - \\Delta t \\right),</math>\n\nwhere <math>b'</math> denotes the [[derivative]] of <math>b(x)</math> with respect to <math>x</math> and\n\n:<math>\\Delta W_n = W_{\\tau_{n + 1}} - W_{\\tau_n}</math>\n\nare [[independent and identically distributed]] [[normal distribution|normal random variables]] with [[expected value]] zero and [[variance]] <math>\\Delta t</math>. Then <math>Y_n</math> will approximate <math>X_{\\tau_n}</math> for <math>0 \\leq n \\leq N</math>, and increasing <math>N</math> will yield a better approximation.\n\nNote that when <math> b'(Y_n) = 0 </math>, i.e. the diffusion term does not depend on <math>X_{t}</math> , this method is equivalent to the [[Euler–Maruyama method]]\n\nThe Milstein scheme has both weak and strong order of convergence, <math>\\Delta t</math>, which is superior to the [[Euler–Maruyama method]], which in turn has the same weak order of convergence, <math>\\Delta t</math>, but inferior strong order of convergence, <math>\\sqrt{\\Delta t}</math>.<ref>V. Mackevičius, ''Introduction to Stochastic Analysis'', Wiley 2011</ref>\n\n== Intuitive derivation ==\n\nFor this derivation, we will only look at [[geometric Brownian motion]] (GBM), the stochastic differential equation of which is given by\n\n:<math>\\mathrm{d} X_t = \\mu X \\mathrm{d} t + \\sigma X d W_t</math>\n\nwith real constants <math>\\mu</math> and <math>\\sigma</math>. Using [[Itō's lemma]] we get\n\n:<math>\\mathrm{d}\\ln X_t=\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\mathrm{d}t+\\sigma\\mathrm{d}W_t,</math>\nThus, the solution to the GBM SDE is\n\n:<math>\n\\begin{align}\nX_{t+\\Delta t}&=X_t\\exp\\left\\{\\int_t^{t+\\Delta t}\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\mathrm{d}t+\\int_t^{t+\\Delta t}\\sigma\\mathrm{d}W_u\\right\\} \\\\\n&\\approx X_t\\left(1+\\mu\\Delta t-\\frac{1}{2}\\sigma^2\\Delta t+\\sigma\\Delta W_t+\\frac{1}{2}\\sigma^2(\\Delta W_t)^2\\right) \\\\\n&= X_t + a(X_t)\\Delta t+b(X_t)\\Delta W_t+\\frac{1}{2}b(X_t)b'(X_t)((\\Delta W_t)^2-\\Delta t)\n\\end{align}\n</math>\n\nwhere\n\n:<math> a(x) = \\mu x, ~b(x) = \\sigma x </math>.\n\nSee numerical solution is presented above for three different trajectories.<ref>Umberto Picchini, SDE Toolbox: simulation and estimation of stochastic differential equations with Matlab. http://sdetoolbox.sourceforge.net/</ref>\n[[File:SDE 2.jpg|thumbnail|Numerical solution for the stochastic differential equation just presented, the drift is twice the diffusion coefficient.]]\n\n== See also ==\n* [[Euler–Maruyama method]]\n\n==References==\n\n{{Reflist}}\n\n==Further reading==\n* {{cite book | author=Kloeden, P.E., & Platen, E. | title=Numerical Solution of Stochastic Differential Equations | publisher=Springer, Berlin | year=1999 | isbn=3-540-54062-8 }}\n\n[[Category:Numerical differential equations]]\n[[Category:Stochastic differential equations]]"
    },
    {
      "title": "Mimesis (mathematics)",
      "url": "https://en.wikipedia.org/wiki/Mimesis_%28mathematics%29",
      "text": "In mathematics, '''mimesis''' is the quality of a numerical method which imitates some properties of the continuum problem. The goal of [[numerical analysis]] is to approximate the continuum, so instead of solving a [[partial differential equation]] one aims to solve a discrete version of the continuum problem. Properties of the continuum problem commonly imitated by numerical methods are [[Conservation law (physics)|conservation law]]s, [[symmetry in physics|solution symmetries]], and fundamental identities and theorems of vector and tensor calculus like the [[divergence theorem]].<ref>{{Citation | last1=Hyman | first1=James M. | last2=Morel | first2=Jim E. | last3=Shashkov | first3=Mikhail | last4=Steinberg | first4=Stanly L. | title=Mimetic finite difference methods for diffusion equations | doi=10.1023/A:1021282912658 | year=2002 | journal=Computational Geosciences | issn=1420-0597 | volume=6 | issue=3 | pages=333–352}}.</ref>\nBoth [[finite difference]] or [[finite element method]] can be mimetic; it depends on the properties that the method has.\n\nFor example, a mixed finite element method applied to [[Darcy's law|Darcy flows]] strictly [[conservation of mass|conserves the mass]] of the flowing fluid.  <!--there are analogies with heat conduction and elastics in mechanics, but i forget what they are offhand-->\n\nThe term ''[[geometric integrator|geometric integration]]'' denotes the same philosophy.\n\n==References==\n<references/>\n\n{{Mathapplied-stub}}\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Modal analysis using FEM",
      "url": "https://en.wikipedia.org/wiki/Modal_analysis_using_FEM",
      "text": "The goal of [[modal analysis]] in structural mechanics is to determine the natural mode shapes and frequencies of an object or structure during free [[vibration]]. It is common to use the [[finite element method]] (FEM) to perform this analysis because, like other calculations using the FEM, the object being analyzed can have arbitrary shape and the results of the\ncalculations are acceptable.  The types of equations which arise from modal analysis are those seen in [[eigensystem]]s.  The physical interpretation of the [[eigenvalues]] and [[eigenvectors]] which come from solving the system are that\nthey represent the frequencies and corresponding mode shapes. Sometimes, the only desired modes are the lowest frequencies because they can be the most prominent modes at which the object will vibrate, dominating all the higher frequency\nmodes.\n\nIt is also possible to test a physical object to determine its natural frequencies and mode shapes.  This is called an [[modal analysis|Experimental Modal Analysis]].  The results of the physical test can be used to calibrate a finite element model to determine if the underlying assumptions made were correct (for example, correct material properties and boundary conditions were used).\n\n== FEA eigensystems ==\n\nFor the most basic problem involving a linear elastic material which obeys [[Hooke's Law]],\nthe [[Matrix (mathematics)|matrix]] equations take the form of a dynamic three-dimensional spring mass system.\nThe generalized equation of motion is given as:<ref>Clough, Ray W. and Joseph Penzien, ''Dynamics of Structures'', 2nd Ed.,\nMcGraw-Hill Publishing Company, New York, 1993, page 173</ref>\n\n:<math>\n[M] [\\ddot U] +\n[C] [\\dot U] +\n[K] [U] =\n[F]\n</math>\n\nwhere <math> [M] </math> is the mass matrix,\n<math> [\\ddot U] </math> is the 2nd time derivative of the displacement\n<math> [U] </math> (i.e., the acceleration), <math> [\\dot U] </math>\nis the velocity, <math> [C] </math> is a damping matrix,\n<math> [K] </math> is the stiffness matrix, and <math> [F] </math>\nis the force vector.  The general problem, with nonzero damping, is a [[quadratic eigenvalue problem]]. However, for vibrational modal analysis, the damping is generally ignored, leaving only the 1st and 3rd terms on the left hand side:\n\n:<math>\n[M] [\\ddot U] + [K] [U]  = [0]\n</math>\n\nThis is the general form of the eigensystem encountered in structural\nengineering using the [[Finite element method|FEM]].  To represent the free-vibration solutions of the structure harmonic motion is assumed,<ref>Bathe, Klaus Jürgen, '' Finite Element Procedures'', 2nd Ed., Prentice-Hall Inc., New Jersey, 1996, page 786</ref> so that <math>[\\ddot U]</math>\nis taken to equal <math>\\lambda [U]</math>,\nwhere <math>\\lambda</math> is an eigenvalue (with units of reciprocal time squared, e.g., <math>\\mathrm{s}^{-2}</math>),\nand the equation reduces to:<ref>Clough, Ray W. and Joseph Penzien, ''Dynamics of Structures'', 2nd Ed.,\nMcGraw-Hill Publishing Company, New York, 1993, page 201</ref>\n\n:<math>[M][U] \\lambda + [K][U] = [0]</math>\n\nIn contrast, the equation for static problems is:\n\n:<math> [K][U] = [F] </math>\n\nwhich is expected when all terms having a time derivative are set to zero.\n\n=== Comparison to linear algebra ===\n\nIn [[linear algebra]], it is more common to see the standard form of an eigensystem which is\nexpressed as:\n\n:<math>[A][x] = [x]\\lambda</math>\n\nBoth equations can be seen as the same because if the general equation is\nmultiplied through by the inverse of the mass,\n<math> [M]^{-1} </math>,\nit will take the form of the latter.<ref>Thomson, William T., '' Theory of Vibration with Applications'', 3rd Ed., Prentice-Hall Inc., Englewood Cliffs, 1988, page 165</ref>\nBecause the lower modes are desired, solving the system\nmore likely involves the equivalent of multiplying through by the inverse of the stiffness,\n<math> [K]^{-1} </math>, a process called [[inverse iteration]].<ref>Hughes, Thomas J. R., ''The Finite Element Method'', Prentice-Hall Inc.,\nEnglewood Cliffs, 1987 page 582-584</ref>\nWhen this is done, the resulting eigenvalues, <math> \\mu </math>, relate to that of the original by:\n\n:<math>\n\\mu =  \\frac{1}{\\lambda}\n</math>\n\nbut the eigenvectors are the same.\n\n== See also ==\n\n*[[Finite element method]]\n*[[Finite element method in structural mechanics]]\n*[[Modal analysis]]\n*[[Seismic analysis]]\n*[[Structural Dynamics]]\n*[[Eigensystem]]\n*[[Eigenmode]]\n*[[Quadratic eigenvalue problem]]\n\n== References ==\n\n{{Reflist}}\n\n== External links ==\n*[http://frame3dd.sourceforge.net/ Frame3DD open source 3D structural modal analysis program]\n\n{{DEFAULTSORT:Modal Analysis Using Fem}}\n[[Category:Finite element method]]\n[[Category:Numerical differential equations]]\n[[Category:Numerical linear algebra]]"
    },
    {
      "title": "Momentum (electromagnetic simulator)",
      "url": "https://en.wikipedia.org/wiki/Momentum_%28electromagnetic_simulator%29",
      "text": "{{Infobox software\n| name                   = Momentum 3D Planar EM Simulator\n| logo                   = \n| screenshot             =\n| caption                = Momentum 3D Planar EM Simulator\n| collapsible            = \n| developer              = [[EEsof|Keysight EEsof EDA]]\n| released               = \n| programming language   = \n| platform               = Element in [[Advanced Design System|ADS]]\n| language               =\n| genre                  = EM simulation\n| license                = \n| website                = {{URL|keysight.com/find/eesof-momentum}}\n}}\n'''Momentum''' is 3-D planar [[EM simulation software]]<ref>{{cite web|url=https://www.keysight.com/en/pc-1887116/momentum-3d-planar-em-simulator?cc=US&lc=eng|title=Momentum 3D Planar EM Simulator|last=|first=|date=|work=agilent.com|archive-url=|archive-date=|dead-url=|accessdate=5 May 2015}}</ref> for [[electronics]] and [[Antenna (radio)|antenna]] analysis, a [[partial differential equation]] solver of [[Maxwell's equations]] based on the [[Boundary element method|method of moments]].<ref>[http://www-personal.ksu.edu/~wkuhn/ads_mom_tut.htm Momentum tutorial] by Bill Kuhn at Kansas State University</ref> It is a 3-D planar electromagnetic (EM) simulator used for passive [[circuit analysis]]. \n\nIt combines full-wave and quasi-static EM solvers to provide insight into EM behavior of [[Monolithic microwave integrated circuit|MMIC]], [[RFIC]], RF Board, [[Signal integrity|Signal Integrity]], and antenna designs. The Momentum simulation engine is integrated into [[Advanced Design System|Keysight ADS]] and Keysight Genesys. \n\nIt was originally developed by a [[Belgium|Belgian]] company, [[Alphabit]], a spinoff from the Electromagnetics Group<ref>{{cite web|url=http://emweb.intec.ugent.be|title=EM Group}}</ref> of [[Ghent University]] and [[Imec|IMEC]].<ref>[http://www10.edacafe.com/nbc/articles/view_article.php?section=Magazine&articleid=432065 \"Agilent EEsof, High Frequency Leader\"] by Jack Horgan, EDA Cafe</ref><ref>[http://www.itpro.co.uk/135906/focus-on-belgium-it-research-and-development-on-the-rise \"Focus on Belgium: IT research and development on the rise\"] by Chris Green for ITPro</ref> Early contributors to the technology include Niels Faché, Jan Van Hese, Frank Libbrecht, Jeannick Sercu, Luc Vandormael, Mieke Herreman, Peter Kok, Tom Dhaene and Krist Blomme.<ref>{{cite web|url=http://www.sumo.intec.ugent.be/?q=tdhaene|title=Prof. dr. ir. Tom Dhaene|work=ugent.be|accessdate=5 May 2015}}</ref>\n\nThe company was acquired by [[Hewlett-Packard]], later it became part of [[Agilent Technologies]] and since November 2014 it is part of [[Keysight Technologies]] [[EEsof]] division, the current owners.<ref>[https://www.keysight.com/en/pc-1887116/momentum-3d-planar-em-simulator?cc=US&lc=eng Home page of Momentum] at EEsof</ref>\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Momentum (Electromagnetic Simulator)}}\n[[Category:Numerical differential equations]]\n[[Category:Electronic design automation software]]"
    },
    {
      "title": "Moving particle semi-implicit method",
      "url": "https://en.wikipedia.org/wiki/Moving_particle_semi-implicit_method",
      "text": "The '''moving particle semi-implicit''' ('''MPS''') '''method''' is a computational method for the simulation of [[incompressible flow|incompressible]] [[free surface flow]]s. It is a macroscopic, deterministic particle method (Lagrangian [[meshfree method|mesh-free method]]) developed by Koshizuka and Oka (1996).\n\n==Method==\n\n{{expand section|date=July 2012}}\n\nThe MPS method is used to solve the Navier-Stokes equations in a Lagrangian framework. A fractional step method is applied which consists of splitting each time step in two steps of prediction and correction. The fluid is represented with particles, and the motion of each particle is calculated based on the interactions with the neighboring particles by means of a kernel function <ref>{{Cite journal|last=Nabian|first=Mohammad Amin|last2=Farhadi|first2=Leila|title=Multiphase Mesh-Free Particle Method for Simulating Granular Flows and Sediment Transport|journal=Journal of Hydraulic Engineering|language=en|volume=143|issue=4|pages=04016102|doi=10.1061/(asce)hy.1943-7900.0001275|year=2017}}</ref><ref>{{Cite book|last=Nabian|first=Mohammad Amin|last2=Farhadi|first2=Leila|date=2014-08-03|chapter=Numerical Simulation of Solitary Wave Using the Fully Lagrangian Method of Moving Particle Semi Implicit|pages=V01DT30A006|doi=10.1115/FEDSM2014-22237|title=Volume 1D, Symposia: Transport Phenomena in Mixing; Turbulent Flows; Urban Fluid Mechanics; Fluid Dynamic Behavior of Complex Particles; Analysis of Elementary Processes in Dispersed Multiphase Flows; Multiphase Flow with Heat/Mass Transfer in Process Technology; Fluid Mechanics of Aircraft and Rocket Emissions and Their Environmental Impacts; High Performance CFD Computation; Performance of Multiphase Flow Systems; Wind Energy; Uncertainty Quantification in Flow Measurements and Simulations|isbn=978-0-7918-4624-7}}</ref><ref>{{Cite book|last=Nabian|first=Mohammad Amin|last2=Farhadi|first2=Leila|date=2014-11-14|chapter=Stable Moving Particle Semi Implicit Method for Modeling Waves Generated by Submarine Landslides|pages=V007T09A019|doi=10.1115/IMECE2014-40419|title=Volume 7: Fluids Engineering Systems and Technologies|isbn=978-0-7918-4954-5}}</ref>. The MPS method is similar to the SPH ([[smoothed-particle hydrodynamics]]) method (Gingold and Monaghan, 1977; Lucy, 1977) in that both methods provide approximations to the strong form of the [[partial differential equations]] (PDEs) on the basis of integral interpolants. However, the MPS method applies simplified [[differential operator]] models solely based on a local [[Weighted average|weighted averaging]] process without taking the [[gradient]] of a kernel function. In addition, the solution process of MPS method differs to that of the original SPH method as the solutions to the PDEs are obtained through a semi-implicit prediction-correction process rather than the fully explicit one in original SPH method.\n\n==Applications==\nThrough the past years, the MPS method has been applied in a wide range of engineering applications including Nuclear Engineering (e.g. [https://dx.doi.org/10.1016/S0029-5493(98)00270-2 Koshizuka et al., 1999]; Koshizuka and Oka, 2001; [https://dx.doi.org/10.1016/j.nucengdes.2005.01.011 Xie et al., 2005]), Coastal Engineering (e.g. [https://dx.doi.org/10.1142/S0578563405001239 Gotoh et al., 2005]; [https://dx.doi.org/10.1016/j.coastaleng.2005.10.007 Gotoh and Sakai, 2006]), Environmental Hydraulics (e.g. [https://dx.doi.org/10.1002/fld.2132 Shakibaeina and Jin, 2009]; [http://ascelibrary.org/doi/10.1061/%28ASCE%29HY.1943-7900.0001275 Nabian and Farhadi, 2016]), Ocean Engineering ([https://dx.doi.org/10.1016/j.oceaneng.2005.12.012 Shibata and Koshizuka, 2007]; [http://www.springerlink.com/content/d887676m640343v2/ Sueyoshi et al., 2008]), Structural Engineering (e.g. [http://www.springerlink.com/content/60q68ha4pfl7n6nf/ Chikazawa et al., 2001]), Mechanical Engineering (e.g. [https://dx.doi.org/10.1016/S0017-9310(02)00011-X Heo et al., 2002]; [http://link.aip.org/link/?PHFLE6/21/032106/1 Sun et al., 2009]), Bioengineering (e.g. [http://www.jamstec.go.jp/esc/publication/journal/jes_vol.5/pdf/JES5_21-Tsubota.pdf Tsubota et al., 2006]) and Chemical Engineering (e.g. [https://dx.doi.org/10.1016/j.ces.2008.10.034 Sun et al., 2009]).\n\n==Improvements==\nImproved versions of MPS method have been proposed for enhancement of numerical stability (e.g. [https://archive.today/20130105131748/http://www3.interscience.wiley.com/journal/2910/abstract Koshizuka et al., 1998]; [https://dx.doi.org/10.1002/fld.1106 Zhang et al., 2005]; [https://dx.doi.org/10.1016/j.fluiddyn.2005.12.002 Ataie-Ashtiani and Farhadi, 2006];[https://dx.doi.org/10.1002/fld.2132 Shakibaeina and Jin, 2009] ), momentum conservation (e.g. Hamiltonian MPS by [https://dx.doi.org/10.1016/j.cma.2006.12.006 Suzuki et al., 2007]; Corrected MPS by [https://dx.doi.org/10.1142/S0578563408001788 Khayyer and Gotoh, 2008]), mechanical energy conservation (e.g. Hamiltonian MPS by [https://dx.doi.org/10.1016/j.cma.2006.12.006 Suzuki et al., 2007]), pressure calculation (e.g. [https://dx.doi.org/10.1016/j.coastaleng.2008.10.004 Khayyer and Gotoh, 2009], [https://dx.doi.org/10.1002/fld.2207 Kondo and Koshizuka, 2010], [https://dx.doi.org/10.1016/j.apor.2010.01.001 Khayyer and Gotoh, 2010]), and for simulation of multiphase and granular flows ([http://ascelibrary.org/doi/10.1061/%28ASCE%29HY.1943-7900.0001275 Nabian and Farhadi 2016]).\n\n== References ==\n\n* K.S. Kim, M.H. Kim and J.C. Park, \"Development of MPS (Moving Particle Simulation) method for Multi-liquid-layer Sloshing,\" Journal of Mathematical Problems in Engineering, Vol 2014, {{doi|10.1155/2014/350165}}\n* B. Ataie-Ashtiani and L. Farhadi, \"A stable moving particle semi-implicit method for free surface flows,\" Fluid Dynamics Research 38, 241–256, 2006.\n* Y. Chikazawa, S. Koshizuka, and Y. Oka, \"A particle method for elastic and visco-plastic structures and fluid-structure interactions,\" Comput. Mech. 27, pp.&nbsp;97–106, 2001.\n* R.A. Gingold and J.J. Monaghan, \"Smoothed particle hydrodynamics: theory and application to non-spherical stars,\" Mon. Not. R. Astron. Soc., Vol 181, pp.&nbsp;375–89, 1977.\n* H. Gotoh and T. Sakai, \"Key issues in the particle method for computation of wave breaking,\" Coastal Engineering, Vol 53, No 2–3, pp.&nbsp;171–179, 2006.\n* H. Gotoh, H. Ikari, T. Memita and T. Sakai, \"Lagrangian particle method for simulation of wave overtopping on a vertical seawall,\" Coast. Eng. J., Vol 47, No 2–3, pp.&nbsp;157–181, 2005.\n* S. Heo, S. Koshizuka and Y. Oka, \"Numerical analysis of boiling on high heat-flux and high subcooling condition using MPS-MAFL,\" International Journal of Heat and Mass Transfer, Vol 45, pp.&nbsp;2633–2642, 2002.\n* A. Khayyer and H. Gotoh, \"Development of CMPS method for accurate water-surface tracking in breaking waves,\" Coast. Eng. J., Vol 50, No 2, pp.&nbsp;179–207, 2008.\n* A. Khayyer and H. Gotoh, \"Modified Moving Particle Semi-implicit methods for the prediction of 2D wave impact pressure,\" Coastal Engineering, Vol 56, pp.&nbsp;419–440, 2009.\n* A. Khayyer and H. Gotoh, \"A higher order Laplacian model for enhancement and stabilization of pressure calculation by the MPS method,\" Applied Ocean Research, 2010 (in press).\n* M. Kondo and S. Koshizuka, \"Improvement of stability in moving particle semi-implicit method\", Int. J. Numer. Meth. Fluid, 2010 (in press).\n* S. Koshizuka and Y. Oka, \"Moving particle semi-implicit method for fragmentation of incompressible fluid,\" Nuclear Science and Engineering, Vol 123, pp.&nbsp;421–434, 1996.\n* S. Koshizuka, S. and Y. Oka, \"Application of Moving Particle Semi-implicit Method to Nuclear Reactor Safety,\" Comput. Fluid Dyn. J., Vol 9, pp.&nbsp;366–375, 2001.\n* S. Koshizuka, H. Ikeda and Y. Oka, \"Numerical analysis of fragmentation mechanisms in vapor explosions,\" Nuclear Engineering and Design, Vol 189, pp.&nbsp;423–433, 1999.\n* S. Koshizuka, A. Nobe and Y. Oka, \"Numerical Analysis of Breaking Waves Using the Moving Particle Semi-implicit Method,\" Int. J. Numer. Meth. Fluid, Vol 26, pp.&nbsp;751–769, 1998.\n* L.B. Lucy, \"A numerical approach to the testing of the fission hypothesis,\" Astron. J., Vol 82, pp.&nbsp;1013–1024, 1977.\n* M.A. Nabian and L. Farhadi, \"Multiphase Mesh-Free Particle Method for Simulating Granular Flows and Sediment Transport,\" Journal of Hydraulic Engineering, 2016.\n* K. Shibata and S. Koshizuka, \"Numerical analysis of shipping water impact on a deck using a particle method,\" Ocean Engineering, Vol 34, pp.&nbsp;585–593, 2007.\n* A. Shakibaeinia and Y.C. Jin \"A mesh-free particle model for simulation of mobile-bed dam break.\" Advances in Water Resources, 34 (6):794–807 {{doi|10.1016/j.advwatres.2011.04.011}}.\n* A. Shakibaeinia and Y.C. Jin \"A weakly compressible MPS method for simulation open-boundary free-surface flow.\" Int. J. Numer. Methods Fluids, 63 (10):1208–1232 (Published Online: 7 Aug 2009 {{doi|10.1002/fld.2132}}).\n* A. Shakibaeinia and Y.C. Jin \"Lagrangian Modeling of flow over spillways using moving particle semi-implicit method.\" Proc. 33rd IAHR Congress, Vancouver, Canada, 2009, 1809–1816.\n* A. Shakibaeinia and Y.C. Jin \"MPS Mesh-Free Particle Method for Multiphase Flows.\" Computer methods in Applied Mechanics and Engineering. 229–232: 13–26. 2012.\n* A. Shakibaeinia and Y.C. Jin \"A MPS Based Mesh-free Particle Method for Open Channel flow. Journal of Hydraulic Engineering ASCE. 137(11): 1375–1384. 2011.\n* M. Sueyoshi, M. Kashiwagi and S. Naito, \"Numerical simulation of wave-induced nonlinear motions of a two-dimensional floating body by the moving particle semi-implicit method,\" Journal of Marine Science and Technology, Vol 13, pp.&nbsp;85–94, 2008.\n* Z. Sun, G. Xi and X. Chen, \"A numerical study of stir mixing of liquids with particle method,\" Chemical Engineering Science, Vol 64, pp.&nbsp;341–350, 2009.\n* Z. Sun, G. Xi and X. Chen, \"Mechanism study of deformation and mass transfer for binary droplet collisions with particle method,\" Phys. Fluids, Vol 21, 032106, 2009.\n* K. Tsubota, S. Wada, H. Kamada, Y. Kitagawa, R. Lima and T. Yamaguchi, \"A Particle Method for Blood Flow Simulation – Application to Flowing Red Blood Cells and Platelets–,\" Journal of the Earth Simulator, Vol 5, pp.&nbsp;2–7, 2006.\n* H. Xie, S. Koshizuka and Y. Oka, \"Simulation of drop deposition process in annular mist flow using three-dimensional particle method,\" Nuclear Engineering and Design, Vol 235, pp.&nbsp;1687–1697, 2005.\n* S. Zhang, K. Morita, K. Fukuda and N. Shirakawa, \"An improved MPS method for numerical simulations of convective heat transfer problems,\" Int. J. Numer. Meth. Fluid, 51, 31–47, 2005.\n\n;Specific\n<references />\n\n== External links ==\n* [http://mps.q.t.u-tokyo.ac.jp/main.html Laboratory of Professor Seiichi Koshizuka at the University of Tokyo, Japan]\n* [http://particle.kuciv.kyoto-u.ac.jp/eindex.html Laboratory of Professor Hitoshi Gotoh at Kyoto University, Japan]\n* [http://www.ftr.co.jp/n/english/products/products_ryujin_fr.html MPS-RYUJIN by Fuji Technical Research]\n\n[[Category:Fluid dynamics]]\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Multiphase particle-in-cell method",
      "url": "https://en.wikipedia.org/wiki/Multiphase_particle-in-cell_method",
      "text": "The '''multiphase particle-in-cell method (MP-PIC)''' is a numerical method for modeling particle-fluid and particle-particle interactions in a [[computational fluid dynamics]] (CFD) calculation.  The MP-PIC method achieves greater stability than its [[particle-in-cell]] predecessor by simultaneously treating the solid particles as computational particles and as a continuum.  In the MP-PIC approach, the particle properties are mapped from the [[Lagrangian coordinates]] to an [[Continuum mechanics|Eulerian]] grid through the use of [[#Interpolation operators|interpolation functions]].  After evaluation of the continuum derivative terms, the particle properties are mapped back to the individual particles.<ref name=\"Andrews1996\" />  This method has proven to be stable in dense particle flows, computationally efficient,<ref name=\"Snider2001\" /> and physically accurate.<ref name=\"Snider2007\" />  This has  allowed the MP-PIC method to be used as particle-flow solver for the simulation of [[#Applications|industrial-scale chemical processes]] involving particle-fluid flows.\n\n==History==\nThe multiphase particle-in-cell (MP-PIC) method was originally developed for a one-dimensional case in the mid-1990s by P.J. O'Rourke ([[Los Alamos National Laboratory]]),<ref name=\"Andrews1996\" /> who also coined the term MP-PIC.  Subsequent extension of the method to two-dimensions was performed by D.M. Snider and O'Rourke.<ref name=\"Snider1997\" /> By 2001, D.M. Snider had extended the MP-PIC method to full three-dimensions.<ref name=\"Snider2001\" />  Currently, the MP-PIC method is used in [[#Software|commercial software]] for the simulation of particle-fluid systems.\n\n==Method==\nThe MP-PIC method is described by the [[#Governing equations|governing equations]], [[#Interpolation operators|interpolation operators]], and the [[#Particle stress model|particle stress model]].\n\n===Governing equations===\n\n====Fluid phase====\nThe multiphase particle-in-cell method assumes an incompressible fluid phase with the corresponding continuity equation,\n\n: <math>\\frac{\\partial \\theta_f}{\\partial t} + \\nabla \\cdot ( \\theta_f \\mathbf{u}_f ) = 0,</math>\n\nwhere the <math>\\theta_f\\;</math> is the fluid volume fraction and <math>\\mathbf{u}_f\\;</math> is the fluid velocity.  Momentum transport is given by a variation of the [[Navier–Stokes equations|Navier-Stokes equations]] where <math>\\rho_f\\;</math> is the fluid density, <math>p\\;</math> is the fluid pressure, and <math>\\mathbf{g}\\;</math> is the body force vector (gravity).\n\n: <math>\\frac{\\partial \\theta_f \\mathbf{u}_f}{\\partial t} + \\nabla \\cdot ( \\theta_f \\mathbf{u}_f \\mathbf{u}_f ) = - \\frac{\\nabla p}{\\rho_f} - \\frac{\\mathbf{F}}{\\rho_f}+\\theta_f \\mathbf{g}</math>\n\nThe laminar fluid viscosity terms, not included in the fluid momentum equation, can be included if necessary but will have a negligible effect on dense particle flow.  In the MP-PIC method, the fluid motion is coupled with the particle motion through <math>\\mathbf{F}\\;</math>, the rate of momentum exchange per volume between the fluid and particle phases.  The fluid phase equations are solved using a finite volume approach.\n\n====Particle phase====\nThe particle phase is described by a probability distribution function (PDF), <math>\\phi\\left(\\mathbf{x}, \\mathbf{u}_f, \\rho_p, \\Omega_p, t \\right); </math> which indicates the likelihood of finding a particle  with a velocity <math>\\mathbf{u}_f\\;</math>, particle density <math>\\rho_p\\;</math>, particle volume <math>\\Omega_p\\;</math> at location <math>\\mathbf{x}\\;</math> and time <math>t\\;</math>.  The particle PDF changes in time as described by\n\n: <math>\\frac{\\partial \\phi}{\\partial t} + \\nabla \\cdot ( \\phi \\mathbf{u}_p) + \\nabla_{\\mathbf{u}_p} \\cdot \\left(\\phi \\mathbf{A} \\right) = 0</math>\n\nwhere <math>\\mathbf{A}\\;</math> is the particle acceleration.\n\nA numerical solution of the particle phase is obtained by dividing the distribution into a finite number of \"computational particles\" that each represent a number of real particles with identical mass density, volume, velocity and location.  At each time step, the velocity and location of each computational particle are updated using a discretized form of the above equations.  The use of computational particles allows for a significant reduction in computational requirements with a negligible impact on accuracy under many conditions.  The use of the computational particle in the Multiphase Particle-in-Cell method allows a full particle size distribution (PSD) to be modeled within the system as well as the modeling of polydisperse solids.<ref name=\"Sundaresan2010\" />\n\n====Identities of the particle probability distribution function====\n\nThe following local particle properties are determined from integrating the particle probability distribution function:\n*Particle volume fraction: <math>\\theta_p = \\int\\!\\!\\!\\int \\!\\!\\! \\int\\phi\\Omega_p \\; d \\Omega_p d \\rho_p d \\mathbf{u}_p</math>\n*Average particle density: <math>\\overline{\\theta_p \\rho_p} = \\int\\!\\!\\!\\int \\!\\!\\! \\int\\phi\\Omega_p \\rho_p \\; d \\Omega_p d \\rho_p d \\mathbf{u}_p</math>\n*Mean particle velocity: <math>\\overline{\\mathbf{u}}_p = \\frac{1}{\\overline{\\theta_p \\rho_p}}\\int\\!\\!\\!\\int \\!\\!\\! \\int \\phi\\Omega_p \\rho_p \\mathbf{u}_p \\; d \\Omega_p d \\rho_p d \\mathbf{u}_p</math>\n\n====Interphase coupling====\nThe particle phase is coupled to the fluid phase through the particle acceleration term, <math>\\mathbf{A}\\;</math>, defined as\n\n: <math>\\mathbf{A}=D_p \\left(\\mathbf{u}_f - \\mathbf{u}_p\\right) - \\frac{\\nabla p}{\\rho_p} + \\mathbf{g} - \\frac{\\nabla \\tau}{\\theta_p \\rho_p}. </math>\n\nIn the acceleration term, <math>D_p\\;</math> is determined from the particle drag model and <math> \\tau\\;</math> is determined from the interparticle stress model.\n\nThe momentum of the fluid phase is coupled to the particle phase through the rate of momentum exchange, <math>\\mathbf{F}\\;</math>.  This is defined from the particle population distribution as\n\n: <math>\\mathbf{F} = \\int\\!\\!\\!\\int \\!\\!\\! \\int \\phi\\Omega_p \\rho_p \\left[ D_p \\left( \\mathbf{u}_f - \\mathbf{u}_p \\right) - \\frac{\\nabla p}{\\rho_p} \\right] \\; d \\Omega_p d \\rho_p d \\mathbf{u}_p</math>\n\n===Interpolation operators===\nThe transfer of particle properties between the Lagrangian particle space and the Eulerian grid is performed using linear interpolation functions.  Assuming a [[rectilinear grid]] consisting of rectangular [[Cuboids|cuboid]] cells, the scalar particle properties are interpolated to the cell centers while the vector properties are interpolated to cell faces.  In three dimensions, tri-linear interpolation functions and definitions for the products and gradients of interpolated properties are provided by Snider for three-dimensional models.<ref name=\"Snider2001\" />\n\n===Particle stress model===\nThe effects of particle packing are modeled in the MP-PIC method with the use of a function of particle stress.  Snider (2001) has suggested calculating the particle stress <math>\\tau\\;</math>, as\n\n: <math>\\tau = \\frac{P_s {\\theta_P}^\\beta}{\\max \\left[ \\theta_{cp} - \\theta_p, \\epsilon \\left(1-\\theta_p \\right) \\right]}</math>\n\nwhere <math>\\theta_{cp}\\;</math> is the close-pack volume fraction and <math>\\beta\\;</math>, <math>P_s\\;</math>, and <math>\\epsilon\\;</math> are constants.\n\n==Limitations of the multiphase particle-in-cell method==\n*'''Particle shape''' - In the MP-PIC method, all particles are assumed to be spherical.  Corrections for non-spherical particles can be included in particle drag model but for highly non-spherical particles, the true interactions may not be well represented.\n*'''Particle size with respect to grid size''' - The size of particles must be small compared to the Eulerian grid in the MP-PIC approach for accurate interpolation.\n\n==Extensions==\n*'''Chemical reactions''' – Coupling the local Eulerian values for fluid velocity in the MP-PIC method with equations for [[Fick's laws of diffusion|diffusional mass transfer]] allows the transport of a chemical species within the fluid-particle system to be modeled.  Reaction kinetics dependent on particle density, surface area, or volume can be included as well for applications in [[catalysis]],<ref name=\"Snider2010\" /> [[gasification]],<ref name=\"Snider2011\" /> or [[Chemical vapor deposition|solid deposition]].\n*'''Liquid Injection''' - MP-PIC method was extended by Zhao, O'Rourke, and Snider to model the coating of particle with a liquid.<ref name=\"Zhao2009\" />\n*'''Thermal Modeling''' - Conductive and convective heat transfer can be included by coupling MP-PIC variables with equations for heat transfer.  Commercial implementations of MP-PIC method include radiative heat transfer as well.<ref name=\"CPFD144release\" />\n\n==Applications==\n*Biomass gasifiers<ref name=\"Blaser2009\" />\n*[[Chemical looping combustion]] (CLC)<ref name=\"AIChE2010\" /><ref name=\"SniderGuenther2010\" /><ref name=\"Yeomans2006\" /><ref name=\"Blaser2006\" /><ref name=\"Shleg2003\" />\n*[[Fluidized bed combustion#Types|Circulating fluidized bed combustion]]<ref name=\"Weng2010\" />\n*[[Coal gasification|Coal gasifiers]]<ref name=\"Snider2011\" /><ref name=\"Snider2009\" />\n*[[Cyclonic separation|Cyclones]]<ref name=\"Williams2006\" />\n*[[Fluid catalytic cracking|Fluid catalytic cracking reactors and regenerators]]\n*Fluidized bed dryers<ref name=\"Cocco2004\" /><ref name=\"Parker2013\" />\n*[[Fluidized bed reactor]]s<ref name=\"Karimipour2009\" />\n*Liquid-solid settlers<ref name=\"Sundaresan2010\" />\n*[[Metal casting]]<ref name=\"Yeomans2006\" /><ref name=\"Lefebvre2005\" /><ref name=\"Winartomo2005\" />\n*Particle jets<ref name=\"ORourke2010\" />\n*Polysilicon deposition<ref name=\"Parker2011\" />\n*Spray coating<ref name=\"Zhao2009\" />\n\n==Software==\n*''Barracuda'' by [http://www.cpfd-software.com CPFD Software]\n\n==References==\n{{Reflist|refs=\n<ref name=\"Snider2001\">Snider, D.M. (2001). An Incompressible Three-Dimensional Multiphase Particle-in-Cell Model for Dense Particle Flows.  ''Journal of Computational Physics'', 170:523–549.</ref><ref name=\"Andrews1996\">Andrews, M.J. and O'Rourke, P.J. (1996). The Multiphase Particle-in-Cell (MP-PIC) Method for Dense Particle Flows.  ''International Journal of Multiphase Flow'', 22(2):379–402.</ref><ref name=\"Snider1997\">Snider, D.M., O'Rourke, P.J., and Andrews, M.J. (1997). An Incompressible Two-Dimensional Multiphase Particle-In-Cell Model for Dense Particle Flows, NM, LA-17280-MS (Los Alamos National Laboratories, Los Alamos, NM)</ref><ref name=\"Williams2006\">Williams, K., Snider, D., Badalassi, V., Reddy Karri, S.B., Knowlton, T.M., and Cocco, R.A. (2006).  Computational Particle Fluid Dynamics Simulations and Validation for Cyclones: High and Low Loadings. ''AIChE 2006 National Meeting'' http://aiche.confex.com/aiche/2006/preliminaryprogram/abstract_76001.htm Retrieved Feb. 19, 2011</ref><ref name=\"Snider2011\">Snider, D.M., Clark, S.M., O'Rourke, P.J. (2011).  Eulerian–Lagrangian method for three-dimensional thermal reacting flow with application to coal gasifiers. ''Chemical Engineering Science'' 66:1285–1295.</ref><ref name=\"Snider2009\">Snider, D., Clark, S.(2009).  CPFD Eulerian-Lagrangian Method for Three Dimensional Thermal Reacting Flow. ''2009 AIChE National Meeting'', http://www.aicheproceedings.org/2009/Fall/data/papers/Paper149130.html Retrieved Feb 19, 2011</ref><ref name=\"ORourke2010\">O'Rourke, P.J., Snider, D.M. (2010). An improved collision damping time for MP-PIC calculations of dense particle flows with applications to polydisperse sedimenting beds and colliding particle jets. ''Chemical Engineering Science'', 65:6014–6028.</ref><ref name=\"AIChE2010\">Williams, K., Snider, D., Guenther, C. (2010) CFD Simulations of the NETL Chemical Looping Experiment, ''AIChE 2010 National Meeting'',  http://www.aicheproceedings.org/2010/Fall/data/papers/Paper202402.html Retrieved Feb 8, 2011</ref><ref name=\"Snider2010\">Snider, D. and Banerjee, S. (2010). Heterogeneous gas chemistry in the CPFD Eulerian–Lagrangian numerical scheme (ozone decomposition). ''Powder Technology'' 199(1):100–106</ref><ref name=\"Zhao2009\">Zhao, P., O'Rourke, P.J., Snider, D. Three-dimensional simulation of liquid injection, film formation and transport, in fluidized beds. ''Particuology'' 7:337-346</ref><ref name=\"CPFD144release\">CPFD Software, LLC. ''Barracuda 14.4 Released''. http://www.cpfd-software.com/news/barracuda_14.4_released Retrieved Feb 8, 2011</ref><ref name=\"SniderGuenther2010\">Snider, D., Guenther, C., Dalton J., Williams, K. (2010) CPFD Eulerian-Lagrangian Numerical Scheme Applied to the NETL Bench-top Chemical Looping Experiment.  ''Proceedings of the 1st International Conference on Chemical Looping''</ref><ref name=\"Cocco2004\">Cocco, R. and Williams, K. (2004).  Optimization of Particle Residence Time Inside Commercial Dryers with Arena-flow.  ''AIChE 2004 National Meeting''</ref><ref name=\"Weng2010\">Weng, M., Nies, M., and Plackmeyer, J. (2010). Comparison between Measurements and Numerical Simulation of Particle Flow and Combustion at the CFBC Plant Duisburg.  ''5. Internationaler VGB-Workshop \"Betriebserfahrungen mit Wirbelschichtfeuerungen 2010\"''</ref><ref name=\"Snider2007\">Snider, D. (2007). Three fundamental granular flow experiments and CPFD predictions.  ''Powder Technology'' 176: 36-46.</ref><ref name=\"Shleg2003\">Schleg, P. (2003). Technology of Metalcasting, ''American Foundry Society'', Des Plaines, IL, pp. 1 and 39.</ref><ref name=\"Blaser2006\">Blaser, P., and Yeomans, N.  (2006). Sand Core Engineering & Process Modeling, ''Japan Foundry Society'', Vol. 2, No. 2, February 2006, pp. 420–427.</ref><ref name=\"Yeomans2006\">Yeomans, N., and Blaser, P.  (2006).  Predicting the Process, ''Foundry Management & Technology'', January 2006, pp 48–49.</ref><ref name=\"Winartomo2005\">Winartomo, B., Vroomen, U., and Buhrig-Polaczek, A., Pelzer, M. (2005). Multiphase modeling of core shooting processes, ''International Journal of Cast Metals Research'', Vol. 18, No. 1.</ref><ref name=\"Lefebvre2005\">Lefebvre, D., Mackenbrock, A., Vidal, V., and Haigh, P. (2005). Development and use of simulation in the design of blown cores and moulds, ''Foundry Trade Journal'', February 2005.</ref><ref name=\"Blaser2009\">Blaser, P. and Chandran, R.  (2009).  Computational Simulation of Fluidization Dynamics Inside a Commercial Biomass Gasifier.  ''AIChE 2009 Annual Meeting.''</ref><ref name=\"Karimipour2009\">Karimipour, S. and Pugsley, T.  (2009).  Application of the Particle-in-Cell Approach for the Simulation of Bubbling Fluidized Beds of Geldhart A Particles, ''Seventh International Conference on CFD in the Minerals and Process Industries''.</ref><ref name=\"Sundaresan2010\">Sundaresan, S. (2010).  Challenges in the Analysis of High-Velocity Gas-Particle Flows in Large Devices, ''University of Houston Neal Amundson Memorial Lecture Series, 2010''.</ref><ref name=\"Parker2011\">Parker, J. (2011).  Validation of CFD Model for Polysilicon Deposition and Production of Silicon Fines in a Silane Deposition FBR, ''International Journal of Chemical Reactor Engineering'', Vol. 9, A40</ref><ref name=\"Parker2013\">Parker, J., LaMarche, K., Chen, W., Williams, K., Stamato, H., Thibault, S. (2013) CFD simulations for prediction of scaling effects in pharmaceutical fluidized bed processors at three scales, ''Powder Technology'', 235: 115-120.</ref>\n}}\n\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Multisymplectic integrator",
      "url": "https://en.wikipedia.org/wiki/Multisymplectic_integrator",
      "text": "In [[mathematics]], a '''multisymplectic integrator''' is a [[numerical analysis|numerical method]] for the solution of a certain class of [[partial differential equation]]s, that are said to be multisymplectic. Multisymplectic integrators are [[geometric integrator]]s, meaning that they preserve the geometry of the problems; in particular, the numerical method preserves energy and momentum in some sense, similar to the partial differential equation itself. Examples of multisymplectic integrators include the Euler box scheme and the Preissman box scheme.\n\n== Multisymplectic equations ==\n\nA partial differential equation (PDE) is said to be a '''multisymplectic equation''' if it can be written in the form\n:<math> Kz_t + Lz_x = \\nabla S(z), </math>\nwhere <math> z(t,x) </math> is the unknown, <math> K </math> and <math> L </math> are (constant) [[skew-symmetric matrix|skew-symmetric matrices]] and <math> \\nabla S </math> denotes the [[gradient]] of <math> S </math>.<ref>{{harvnb|Bridges|1997}}, p. 1374; {{harvnb|Leimkuhler|Reich|2004}}, p. 335–336.</ref> This is a natural generalization of <math> Jz_t = \\nabla H(z) </math>, the form of a [[Hamiltonian mechanics|Hamiltonian ODE]].<ref>{{harvnb|Bridges|Reich|2001}}, p. 186.</ref>\n\nExamples of multisymplectic PDEs include the nonlinear [[Klein–Gordon equation]] <math> u_{tt} - u_{xx} = V'(u) </math>, or more generally the nonlinear wave equation <math> u_{tt} = \\partial_x \\sigma'(u_x) - f'(u) </math>,<ref>{{harvnb|Leimkuhler|Reich|2004}}, p. 335.</ref> and the [[KdV equation]] <math> u_t + uu_x + u_{xxx} = 0 </math>.<ref>{{harvnb|Leimkuhler|Reich|2004}}, p. 339–340.</ref>\n\nDefine the [[2-form]]s <math> \\omega </math> and <math> \\kappa </math> by \n:<math> \\omega(u,v) = \\langle Ku, v \\rangle \\quad\\text{and}\\quad \\kappa(u,v) = \\langle Lu, v \\rangle </math>\nwhere <math> \\langle \\,\\cdot\\, , \\,\\cdot\\, \\rangle </math> denotes the [[dot product]]. The differential equation preserves symplecticity in the sense that\n:<math> \\partial_t \\omega + \\partial_x \\kappa = 0. </math><ref>{{harvnb|Bridges|Reich|2001}}, p. 186; {{harvnb|Leimkuhler|Reich|2004}}, p. 336.</ref>\nTaking the dot product of the PDE with <math> u_t </math> yields the local [[Conservation law (physics)|conservation law]] for energy:\n:<math> \\partial_t E(u) + \\partial_x F(u) = 0 \\quad\\text{where}\\quad E(u) = S(u) - \\tfrac12 \\kappa(u_x,u) ,\\, F(u) = \\tfrac12 \\kappa(u_t,u). </math><ref name=BR187>{{harvnb|Bridges|Reich|2001}}, p. 187; {{harvnb|Leimkuhler|Reich|2004}}, p. 337–338.</ref>\nThe local conservation law for momentum is derived similarly:\n:<math> \\partial_t I(u) + \\partial_x G(u) = 0 \\quad\\text{where}\\quad I(u) = \\tfrac12 \\omega(u_x,u) ,\\, G(u) = S(u) - \\tfrac12 \\omega(u_t,u). </math><ref name=BR187 />\n\n== The Euler box scheme ==\n\nA multisymplectic integrator is a numerical method for solving multisymplectic PDEs whose numerical solution conserves a discrete form of symplecticity.<ref>{{harvnb|Bridges|Reich|2001|p=187}}; {{harvnb|Leimkuhler|Reich|2004|p=341}}.</ref> One example is the Euler box scheme, which is derived by applying the [[symplectic Euler method]] to each independent variable.<ref name=MR>{{harvnb|Moore|Reich|2003}}.</ref>\n\nThe Euler box scheme uses a splitting of the skewsymmetric matrices <math> K </math> and <math> L </math> of the form:\n:<math> \\begin{align}\nK &= K_+ + K_- \\quad\\text{with}\\quad K_- = -K_+^T, \\\\\nL &= L_+ + L_- \\quad\\text{with}\\quad L_- = -L_+^T. \n\\end{align} </math>\nFor instance, one can take <math> K_+ </math> and <math> L_+ </math> to be the upper triangular part of <math> K </math> and <math> L </math>, respectively.<ref>{{harvnb|Moore|Reich|2003}}; {{harvnb|Leimkuhler|Reich|2004|p=337}}.</ref>\n\nNow introduce a [[regular grid|uniform grid]] and let <math> u_{n,i} </math> denote the approximation to <math> u(n\\Delta{t}, i\\Delta{x}) </math> where <math> \\Delta{t} </math> and <math> \\Delta{x} </math> are the grid spacing in the time- and space-direction. Then the Euler box scheme is \n:<math> K_+ \\partial_t^+ u_{n,i} + K_- \\partial_t^- u_{n,i} + L_+ \\partial_x^+ u_{n,i} + L_- \\partial_x^- u_{n,i} = \\nabla{S}(u_{n,i}) </math>\nwhere the [[finite difference]] operators are defined by\n:<math> \\begin{align}\n\\partial_t^+ u_{n,i} &= \\frac{u_{n+1,i} - u_{n,i}}{\\Delta{t}}, & \\partial_x^+ u_{n,i} &= \\frac{u_{n,i+1} - u_{n,i}}{\\Delta{x}}, \\\\[1ex]\n\\partial_t^- u_{n,i} &= \\frac{u_{n,i} - u_{n-1,i}}{\\Delta{t}}, & \\partial_x^- u_{n,i} &= \\frac{u_{n,i} - u_{n,i-1}}{\\Delta{x}}.\n\\end{align} </math> <ref>{{harvnb|Moore|Reich|2003}}; {{harvnb|Leimkuhler|Reich|2004|p=342}}.</ref>\nThe Euler box scheme is a first-order method,<ref name=MR /> which satisfies the discrete conservation law\n:<math> \\partial_t^+ \\omega_{n,i} + \\partial_x^+ \\kappa_{n,i} = 0 \\quad\\text{where}\\quad \\omega_{n,i} = \\mathrm{d}u_{n,i-1} \\wedge K_+ \\, \\mathrm{d}u_{n,i} \\quad\\text{and}\\quad \\kappa_{n,i} = \\mathrm{d}u_{n-1,i} \\wedge L_+ \\, \\mathrm{d}u_{n,i}. </math><ref>{{harvnb|Moore|Reich|2003}}; {{harvnb|Leimkuhler|Reich|2004|p=343}}.</ref>\n\n== Preissman box scheme ==\n\nAnother multisymplectic integrator is the Preissman box scheme, which was introduced by Preissman in the context of hyperbolic PDEs.<ref>{{harvtxt|Bridges|Reich|2001|p=190}} refers to {{harvtxt|Abbott|Basco|1989}} for the work by Preissman.</ref> It is also known as the centred cell scheme.<ref>{{harvnb|Islas|Schober|date=2004|pp=591–593}}.</ref> The Preissman box scheme can be derived by applying the [[Midpoint method|Implicit midpoint rule]], which is a symplectic integrator, to each of the independent variables.<ref name=BR190>{{harvnb|Bridges|Reich|2001|p=190}}; {{harvnb|Leimkuhler|Reich|2004|p=344}}.</ref> This leads to the scheme\n:<math> K \\partial_t^+ u_{n,i+1/2} + L \\partial_x^+ u_{n+1/2,i} = \\nabla{S}(u_{n+1/2,i+1/2}), </math>\nwhere the finite difference operators <math> \\partial_t^+ </math> and <math> \\partial_x^+ </math> are defined as above and the values at the half-integers are defined by \n:<math> \nu_{n,i+1/2} = \\frac{u_{n,i}+u_{n,i+1}}{2}, \\quad u_{n+1/2,i} = \\frac{u_{n,i}+u_{n+1,i}}{2}, \nu_{n+1/2,i+1/2} = \\frac{u_{n,i}+u_{n,i+1}+u_{n+1,i}+u_{n+1,i+1}}{4}. \n </math> <ref name=BR190 /> \nThe Preissman box scheme is a second-order multisymplectic integrator which satisfies the discrete conservation law\n:<math> \\partial_t^+ \\omega_{n,i} + \\partial_x^+ \\kappa_{n,i} = 0 \\quad\\text{where}\\quad \\omega_{n,i} = \\mathrm{d}u_{n,i+1/2} \\wedge K \\, \\mathrm{d}u_{n,i+1/2} \\quad\\text{and}\\quad \\kappa_{n,i} = \\mathrm{d}u_{n+1/2,i} \\wedge L \\, \\mathrm{d}u_{n+1/2,i}. </math><ref>{{harvnb|Bridges|Reich|2001|loc=Thm 1}}; {{harvnb|Leimkuhler|Reich|2004|p=345}}.</ref>\n\n== Notes ==\n{{reflist|30em}}\n\n== References ==\n* {{citation | first1=M.B. | last1=Abbott | first2=D.R. | last2=Basco | title=Computational Fluid Dynamics | publisher=Longman Scientific | year=1989}}.\n* {{citation | first=Thomas J. | last=Bridges | title=A geometric formulation of the conservation of wave action and its implications for signature and the classification of instabilities | journal=Proc. R. Soc. Lond. A | volume=453 | issue=1962 | pages=1365–1395 | year=1997 | doi=10.1098/rspa.1997.0075}}.\n* {{citation | first1=Thomas J. | last1=Bridges | first2=Sebiastian | last2=Reich | title=Multi-Symplectic Integrators: Numerical schemes for Hamiltonian PDEs that conserve symplecticity | journal=Phys. Lett. A | volume=284 | issue=4–5 | pages=184–193 | year=2001 | doi=10.1016/S0375-9601(01)00294-8| citeseerx=10.1.1.46.2783 }}.\n* {{citation | first1=Benedict | last1=Leimkuhler | first2=Sebastian | last2=Reich | title=Simulating Hamiltonian Dynamics | publisher=Cambridge University Press | year=2004 | isbn=978-0-521-77290-7}}.\n* {{citation | first1=A.L. | last1=Islas | first2=C.M. | last2=Schober | title=On the preservation of phase space structure under multisymplectic discretization | journal=J. Comput. Phys. | volume=197 | issue=2 | pages=585–609 | year=2004 | doi=10.1016/j.jcp.2003.12.010 }}.\n* {{citation | first1=Brian | last1=Moore | first2=Sebastian | last2=Reich | title=Backward error analysis for multi-symplectic integration methods | journal=Numer. Math. | volume=95 | issue=4 | pages=625–652 | year=2003 | doi=10.1007/s00211-003-0458-9 | citeseerx=10.1.1.163.8683 }}.\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "MUSCL scheme",
      "url": "https://en.wikipedia.org/wiki/MUSCL_scheme",
      "text": "In the study of [[partial differential equation]]s, the '''MUSCL scheme''' is a [[finite volume method]] that can provide highly accurate numerical solutions for a given system, even in cases where the solutions exhibit shocks, discontinuities, or large gradients.  MUSCL stands for ''Monotonic Upwind Scheme for Conservation Laws'' (van Leer, 1979), and the term was introduced in a seminal paper by [[Bram van Leer]] (van Leer, 1979). In this paper he constructed the first ''high-order'', ''[[total variation diminishing]]'' (TVD) scheme where he obtained second order spatial accuracy.\n\nThe idea is to replace the piecewise constant approximation of [[Godunov's scheme]] by reconstructed states, derived from cell-averaged states obtained from the previous time-step. For each cell, slope limited, reconstructed left and right states are obtained and used to calculate fluxes at the cell boundaries (edges). These fluxes can, in turn, be used as input to a ''[[Riemann solver]]'', following which the solutions are averaged and used to advance the solution in time. Alternatively, the fluxes can be used in ''Riemann-solver-free'' schemes, which are basically Rusanov-like schemes.\n\n==Linear reconstruction==\n\n[[Image:StepFirstOrdUpwind.png|thumb|200px|right|1D advective equation <math>u_t+u_x=0</math>, with step wave propagating to the right. Shows the analytical solution along with a simulation based upon a first order upwind spatial discretization scheme.]]\n\nWe will consider the fundamentals of the MUSCL scheme by considering the following simple first-order, scalar, 1D system, which is assumed to have a wave propagating in the positive direction,\n\n:<math>u_t + F_x\\left(u \\right)=0. \\, </math>\n\nWhere <math>u</math> represents a state variable and <math>F</math> represents a [[flux]] variable.\n\nThe basic scheme of Godunov uses piecewise constant approximations for each cell, and results in a first-order upwind discretisation of the above problem with cell centres indexed as <math>i</math>.  A semi-discrete scheme can be defined as follows,\n\n:<math>\\frac{\\mathrm{d} u_i}{\\mathrm{d} t} + \\frac{1}{\\Delta x_i} \\left[ \nF \\left( u_{i} \\right) - F \\left( u_{i-1} \\right)  \\right] =0. </math>\n\nThis basic scheme is not able to handle shocks or sharp discontinuities as they tend to become smeared. An example of this effect is shown in the diagram opposite, which illustrates a 1D advective equation with a step wave propagating to the right. The simulation was carried out with a mesh of 200 cells and used a 4th order [[Runge–Kutta]] time integrator (RK4).\n\nTo provide higher resolution of discontinuities, Godunov's scheme can be extended to use piecewise linear approximations of each cell, which results in a ''central difference'' scheme that is ''second-order'' accurate in space. The piecewise linear approximations are obtained from\n\n:<math> u \\left( x \\right) = u_{i} +\n  \\frac{\\left( x - x_{i} \\right) }{ \\left( x_{i+1} - x_{i} \\right)}\n  \\left( u_{i+1} - u_{i}  \\right) \\qquad \\forall x \\in (x_{i}, x_{i+1}].</math>\n\nThus, evaluating fluxes at the cell edges we get the following semi-discrete scheme\n\n:<math>\\frac{\\mathrm{d} u_i}{\\mathrm{d} t} + \\frac{1}{\\Delta x_i} \\left[ \nF \\left( u_{i + 1/2} \\right) - F \\left( u_{i - 1/2} \\right)  \\right] =0, </math>\n\n[[Image:stepSecOrdCentralDifference.png|thumb|200px|right|1D advective equation <math>u_t+u_x=0</math>, with step wave propagating to the right. Shows the analytical solution along with a simulation based upon a second order, central difference spatial discretization scheme.]]\n\nwhere <math> u_{i + 1/2} </math> and <math> u_{i - 1/2} </math> are the piecewise approximate values of cell edge variables, ''i.e.'',\n\n:<math> u_{i + 1/2} = 0.5 \\left( u_{i} + u_{i + 1}  \\right), </math>\n:<math> u_{i - 1/2} = 0.5 \\left( u_{i-1} + u_{i}  \\right). </math>\n\nAlthough the above second-order scheme provides greater accuracy for smooth solutions, it is not a [[total variation diminishing]] (TVD) scheme and introduces spurious oscillations into the solution where discontinuities or shocks are present. An example of this effect is shown in the diagram opposite, which illustrates a 1D advective equation <math>\\, u_t+u_x=0 </math>, with a step wave propagating to the right. This loss of accuracy is to be expected due to [[Godunov's theorem]]. The simulation was carried out with a mesh of 200 cells and used RK4 for time integration.\n\n[[Image:LinExtrap.jpg|thumb|200px|right|An example of MUSCL type left and right state linear-extrapolation.]]\n\nMUSCL based numerical schemes extend the idea of using a linear piecewise approximation to each cell by using ''slope limited'' left and right extrapolated states. This results in the following high resolution, TVD discretisation scheme,\n\n:<math>\\frac{\\mathrm{d} u_i}{\\mathrm{d} t} + \\frac{1}{\\Delta x_i} \\left[ \nF \\left( u^*_{i + 1/2} \\right) - F \\left( u^*_{i - 1/2} \\right)  \\right] =0. </math>\n\nWhich, alternatively, can be written in the more succinct form,\n\n:<math>\\frac{\\mathrm{d} u_i}{\\mathrm{d} t} + \\frac{1}{\\Delta x_i} \\left[ \nF^*_{i + 1/2}  - F^*_{i - 1/2}  \\right] =0. </math>\n\nThe numerical fluxes <math>F^*_{i \\pm 1/2} </math> correspond to a nonlinear combination of first and second-order approximations to the continuous flux function.\n\nThe symbols <math> u^*_{i + 1/2} </math> and <math> u^*_{i - 1/2} </math> represent scheme dependent functions (of the limited extrapolated cell edge variables), ''i.e.'',\n\n:<math> u^*_{i + 1/2} = u^*_{i + 1/2}  \\left( u^L_{i + 1/2} , u^R_{i + 1/2}  \\right),\n\n  u^*_{i - 1/2} = u^*_{i - 1/2}  \\left( u^L_{i - 1/2} , u^R_{i - 1/2}  \\right), </math>\n\nwhere, using downwind slopes:\n:<math> u^L_{i + 1/2} = u_{i} + 0.5 \\phi \\left( r_i \\right) \\left( u_{i+1} - u_{i} \\right),\n  u^R_{i + 1/2} = u_{i+1} - 0.5 \\phi \\left( r_{i+1} \\right)  \\left( u_{i+2} - u_{i+1} \\right),</math>\n\n:<math> u^L_{i - 1/2} = u_{i-1} + 0.5 \\phi \\left( r_{i-1} \\right)  \\left( u_{i} - u_{i-1} \\right),\n  u^R_{i - 1/2} = u_i - 0.5 \\phi \\left( r_i \\right)  \\left( u_{i+1} - u_i \\right),</math>\n\nand\n:<math> r_{i} = \\frac{u_i - u_{i-1}}{u_{i+1} - u_i}.</math>\n\nThe function <math>\\phi \\left( r_i \\right)</math> is a limiter function that limits the slope of the piecewise approximations to ensure the solution is TVD, thereby avoiding the spurious oscillations that would otherwise occur around discontinuities or shocks - see [[Flux limiter]] section. The limiter is equal to zero when <math>r \\le 0</math> and is equal to unity when <math>r = 1</math>. Thus, the accuracy of a TVD discretization degrades to first order at local extrema, but tends to second order over smooth parts of the domain.\n\nThe algorithm is straight forward to implement. Once a suitable scheme for <math>F^*_{i + 1/2}</math> has been chosen, such as the ''Kurganov and Tadmor scheme'' (see below), the solution can proceed using standard numerical integration techniques.\n\n==Kurganov and Tadmor central scheme==\n\nA precursor to the ''Kurganov and Tadmor'' (KT) ''central scheme'', (Kurganov and Tadmor, 2000), is the ''Nessyahu and Tadmor'' (NT) a staggered ''central scheme'', (Nessyahu and Tadmor, 1990).  It is a Riemann-solver-free, second-order, [[high-resolution scheme]] that uses MUSCL reconstruction.  It is a fully discrete method that is straight forward to implement and can be used on [[scalar (mathematics)|scalar]] and [[vector (geometric)|vector]] problems, and can be viewed as a Rusanov flux (to an abusive extent, called Lax-Friedrichs flux) supplemented with high order reconstructions.  The algorithm is based upon [[finite difference|central differences]] with comparable performance to Riemann type solvers when used to obtain solutions for PDE's describing systems that exhibit high-gradient phenomena.\n\nThe KT scheme extends the NT scheme and has a smaller amount of numerical viscosity than the original NT scheme. It also has the added advantage that it can be implemented as either a ''fully discrete'' or ''semi-discrete'' scheme. Here we consider the semi-discrete scheme.\n\nThe calculation is shown below:\n: <math>F^*_{i-\\frac{1}{2}} =\\frac{1}{2} \\left\\{\n\\left[ F \\left(u^R_{i - \\frac{1}{2}} \\right) + F \\left(u^L_{i - \\frac{1}{2}} \\right) \\right]\n- a_{i - \\frac{1}{2} } \\left[u^R_{i - \\frac{1}{2}} - u^L_{i - \\frac{1}{2}} \\right] \\right\\}. </math>\n \n: <math>F^*_{i+\\frac{1}{2}} =\\frac{1}{2} \\left\\{\n\\left[ F \\left(u^R_{i + \\frac{1}{2}} \\right) + F \\left(u^L_{i + \\frac{1}{2}} \\right) \\right]\n- a_{i + \\frac{1}{2} } \\left[u^R_{i + \\frac{1}{2}} - u^L_{i + \\frac{1}{2}} \\right] \\right\\}. </math>\n\n[[Image:StepKTsuperbee.png|thumb|200px|right|1D advective equation <math>u_t+u_x=0</math>, with step wave propagating to the right. Shows the analytical solution along with a simulation based upon the Kurganov and Tadmor central scheme with SuperBee limiter.]]\n\nWhere the ''local propagation speed'', <math> a_{i \\pm \\frac{1}{2}} \\ </math>, is the maximum absolute value of the eigenvalue of the Jacobian of <math> F \\left( u \\left(x, t \\right) \\right)</math> over cells <math>{i} , {i \\pm 1}</math> given by\n\n: <math> a_{i + \\frac{1}{2} } \\left( t \\right) = \\max \\left[ \n\\rho \\left( \\frac{\\partial F \\left( u^L_{i+1/2}   \\left( t \\right) \\right)}{\\partial u} \\right) ,\n\\rho \\left( \\frac{\\partial F \\left( u^R_{i+1/2} \\left( t \\right) \\right)}{\\partial u} \\right), \n\\right] </math>\n\nand <math> \\rho \\ </math> represents the [[spectral radius]] of \n<math> \\frac{\\partial F \\left( u   \\left( t \\right) \\right)}{ \\partial u}.  </math>\n\nBeyond these [[Courant–Friedrichs–Lewy condition|CFL]] related speeds, no characteristic information is required.\n\nThe above flux calculation is most frequently called ''Lax-Friedrichs flux'' (though it's worth mentioning that such flux expression does not appear in Lax, 1954 but rather on Rusanov, 1961).\n\nAn example of the effectiveness of using a high resolution scheme is shown in the diagram opposite, which illustrates the 1D advective equation <math>u_t+u_x=0 \\ </math>, with a step wave propagating to the right. The simulation was carried out on a mesh of 200 cells, using the Kurganov and Tadmor central scheme with [[flux limiter|Superbee limiter]] and used RK-4 for time integration. This simulation result contrasts extremely well against the above first-order upwind and second-order central difference results shown above. This scheme also provides good results when applied to sets of equations - see results below for this scheme applied to the Euler equations. However, care has to be taken in choosing an appropriate limiter because, for example, the Superbee limiter can cause unrealistic sharpening for some smooth waves.\n\nThe scheme can readily include diffusion terms, if they are present. For example, if the above 1D scalar problem is extended to include a diffusion term, we get\n\n:<math>u_t + F_x\\left(u \\right) = Q_x \\left( u , u_x \\right), </math>\n\nfor which Kurganov and Tadmor propose the following central difference approximation,\n\n:<math>\\frac{\\mathrm{d} u_i}{\\mathrm{d} t} = \n- \\frac{1}{\\Delta x_i} \\left[ F^*_{i + \\frac{1}{2}}  - F^*_{i - \\frac{1}{2}}  \\right] \n+ \\frac{1}{\\Delta x_i} \\left[ P_{i + \\frac{1}{2}}  - P_{i - \\frac{1}{2}}  \\right]. </math>\n\nWhere,\n\n:<math>P_{i + \\frac{1}{2}} = \\frac{1}{2} \\left[ \nQ \\left( u_{i} ,   \\frac{u_{i+1} - u_i}{\\Delta x_i} \\right) + \nQ \\left( u_{i+1} , \\frac{u_{i+1} - u_i}{\\Delta x_i} \\right)\n   \\right], </math>\n\n:<math>P_{i - \\frac{1}{2}} = \\frac{1}{2} \\left[ \nQ \\left( u_{i-1} ,   \\frac{u_{i} - u_{i-1}}{\\Delta x_{i-1}} \\right) + \nQ \\left( u_{i} , \\frac{u_{i} - u_{i-1}}{\\Delta x_{i-1}} \\right).\n   \\right] </math>\n\nFull details of the algorithm (''full'' and ''semi-discrete'' versions) and its derivation can be found in the original paper (Kurganov and Tadmor, 2000), along with a number of 1D and 2D examples. Additional information is also available in the earlier related paper by Nessyahu and Tadmor (1990).\n\n'''Note:'''  This scheme was originally presented by Kurganov and Tadmor as a 2nd order scheme based upon ''linear extrapolation''.  A later paper (Kurganov and Levy, 2000) demonstrates that it can also form the basis of a third order scheme. A 1D advective example and an Euler equation example of their scheme, using parabolic reconstruction (3rd order), are shown in the ''parabolic reconstruction'' and ''Euler equation'' sections below.\n\n==Piecewise parabolic reconstruction==\n\n[[Image:ParabolicExtrap.jpg|thumb|200px|right|An example of MUSCL type state parabolic-reconstruction.]]\n\nIt is possible to extend the idea of linear-extrapolation to higher order reconstruction, and an example is shown in the diagram opposite. However, for this case the left and right states are estimated by interpolation of a second-order, upwind biased, difference equation. This results in a parabolic reconstruction scheme that is third-order accurate in space.\n\nWe follow the approach of Kermani (Kermani, et al., 2003), and present a third-order upwind biased scheme, where the symbols <math> u^*_{i + \\frac{1}{2}} </math> and <math> u^*_{i - \\frac{1}{2}} </math> again represent scheme dependent functions (of the limited reconstructed cell edge variables). But for this case they are based upon parabolically reconstructed states, ''i.e.'',\n\n:<math> u^*_{i + \\frac{1}{2}} = f \\left( u^L_{i + \\frac{1}{2}} , u^R_{i + \\frac{1}{2}}  \\right),\\quad\n\n  u^*_{i - \\frac{1}{2}} = f \\left( u^L_{i - \\frac{1}{2}} , u^R_{i - \\frac{1}{2}}  \\right), </math>\n\nand\n\n:<math> u^L_{i + \\frac{1}{2}} = u_{i} + \\frac{\\phi \\left( r_{i}    \\right)}{4}  \\left[  \n\\left( 1 - \\kappa \\right)  \\delta u_{i - \\frac{1}{2} } + \n\\left( 1 + \\kappa \\right)  \\delta u_{i + \\frac{1}{2} } \n\\right],</math>\n\n:<math>u^R_{i + \\frac{1}{2}} = u_{i+1} - \\frac{\\phi \\left( r_{i+1} \\right)}{4}  \\left[ \n\\left( 1 - \\kappa  \\right) \\delta u_{i + \\frac{3}{2} } + \n\\left( 1 + \\kappa  \\right) \\delta u_{i + \\frac{1}{2} } \n\\right], </math>\n\n:<math> u^L_{i - \\frac{1}{2}} = u_{i-1}   +  \\frac{\\phi \\left( r_{i-1} \\right)}{4} \\left[  \n\\left( 1 - \\kappa  \\right) \\delta u_{i - \\frac{3}{2}} + \n\\left( 1 + \\kappa  \\right) \\delta u_{i - \\frac{1}{2} } \n\\right],</math>\n\n:<math>u^R_{i - \\frac{1}{2}} = u_{i} - \\frac{\\phi \\left( r_{i}   \\right)}{4} \\left[ \n\\left( 1 - \\kappa  \\right) \\delta u_{i + \\frac{1}{2} } + \n\\left( 1 + \\kappa  \\right) \\delta u_{i - \\frac{1}{2} } \n\\right].</math>\n\n[[Image:StepParabolicKTalbada.png|thumb|200px|right|1D advective equation <math>u_t+u_x=0</math>, with step wave propagating to the right. Shows the analytical solution along with a simulation based upon the Kurganov and Tadmor Central Scheme with parabolic reconstruction and van Albada limiter.]]\n\nWhere <math> \\kappa \\  </math> = 1/3 and,\n:<math> \\delta u_{i + \\frac{1}{2} } = \\left( u_{i+1} - u_{i} \\right) ,\\quad  \n        \\delta u_{i - \\frac{1}{2} } = \\left( u_{i} - u_{i-1} \\right),</math>\n\n:<math> \\delta u_{i + \\frac{3}{2} } = \\left( u_{i+2} - u_{i+1} \\right) ,\\quad  \n        \\delta u_{i - \\frac{3}{2} } = \\left( u_{i-1} - u_{i-2} \\right),</math>\n\nand the limiter function <math> \\phi \\left( r \\right)\\ </math>, is the same as above.\n\nParabolic reconstruction is straight forward to implement and can be used with the Kurganov and Tadmor scheme in lieu of the linear extrapolation shown above. This has the effect of raising the spatial solution of the KT scheme to 3rd order. It performs well when solving the Euler equations, see below. This increase in spatial order has certain advantages over 2nd order schemes for smooth solutions, however, for shocks it is more dissipative - compare diagram opposite with above solution obtained using the KT algorithm with linear extrapolation and Superbee limiter. This simulation was carried out on a mesh of 200 cells using the same KT algorithm but with parabolic reconstruction. Time integration was by RK-4, and the alternative form of van Albada limiter, <math> \\phi_{va} (r) = \\frac{2 r}{1 + r^2 } \\ </math>, was used to avoid spurious oscillations.\n\n==Example: 1D Euler equations==\n\nFor simplicity we consider the 1D case without heat transfer and without body force. Therefore, in conservation vector form, the general [[Euler equations (fluid dynamics)|Euler equations]] reduce to\n\n:<math> \n\\frac{\\partial \\mathbf{U}}{\\partial t}+\n\\frac{\\partial \\mathbf{F}}{\\partial x}=0,\n</math>\n\nwhere\n\n:<math>\n\\mathbf{U}=\\begin{pmatrix}\\rho , \\\\  \\rho u  \\\\  E\\end{pmatrix}\\qquad\n\\mathbf{F}=\\begin{pmatrix}\\rho u\\\\p+\\rho u^2\\\\  u(E+p)\\end{pmatrix},\\qquad\n</math>\nand where '''<math> \\mbox{U} </math>''' is a vector of states and '''<math> \\mbox{F} </math>''' is a vector of fluxes.\n\nThe equations above represent conservation of '''mass''', '''momentum''', and '''energy'''.  There are thus three equations and four unknowns, <math> \\rho </math> (density) <math> u </math> (fluid velocity), <math> p </math> (pressure) and <math> E </math> (total energy). The total energy is given by,\n\n:<math>E=\\rho e + \\frac{1}{2} \\rho u^2,</math>\n\nwhere <math> e\\ </math> represents specific internal energy.\n\nIn order to close the system an [[equation of state]] is required. One that suits our purpose is\n\n:<math>p=\\rho \\left(\\gamma-1 \\right)e,</math>\n\nwhere <math> \\gamma\\ </math> is equal to the ratio of specific heats <math> \\left[ c_p/c_v \\right] </math> for the fluid.\n\nWe can now proceed, as shown above in the simple 1D example, by obtaining the left and right extrapolated states for each state variable. Thus, for density we obtain\n\n:<math> \\rho^*_{i + \\frac{1}{2}} = \\rho^*_{i + \\frac{1}{2}}  \\left( \\rho^L_{i + \\frac{1}{2}} , \\rho^R_{i + \\frac{1}{2}}  \\right), \\quad\n\n  \\rho^*_{i - \\frac{1}{2}} = \\rho^*_{i - \\frac{1}{2}}  \\left( \\rho^L_{i - \\frac{1}{2}} , \\rho^R_{i - \\frac{1}{2}}  \\right), </math>\n\nwhere\n\n:<math> \\rho^L_{i + \\frac{1}{2}} = \\rho_{i} + 0.5 \\phi \\left( r_{i} \\right) \\left( \\rho_{i} - \\rho_{i-1} \\right), \\quad \n  \\rho^R_{i + \\frac{1}{2}} = \\rho_{i+1} - 0.5 \\phi \\left( r_{i+1} \\right)  \\left( \\rho_{i+1} - \\rho_{i} \\right),</math>\n\n:<math> \\rho^L_{i - \\frac{1}{2}} = \\rho_{i-1} + 0.5 \\phi \\left( r_{i-1} \\right)  \\left( \\rho_{i} - \\rho_{i-1} \\right), \\quad\n  \\rho^R_{i - \\frac{1}{2}} = \\rho_{i}   - 0.5 \\phi \\left( r_{i} \\right)  \\left( \\rho_{i+1} - \\rho_{i} \\right).</math>\n\nSimilarly, for momentum <math> \\rho u </math>, and total energy <math> E </math>. Velocity <math> u </math>, is calculated from momentum, and pressure <math> p </math>, is calculated from the equation of state.\n\nHaving obtained the limited extrapolated states, we then proceed to construct the edge fluxes using these values. With the edge fluxes known, we can now construct the semi-discrete scheme, ''i.e.'',\n\n:<math>\\frac{\\mathrm{d} \\mathbf{U}_i}{\\mathrm{d} t} = - \\frac{1}{\\Delta x_i} \\left[ \n\\mathbf{F}^*_{i + \\frac{1}{2} }  - \\mathbf{F}^*_{i - \\frac{1}{2}}  \\right]. </math>\n\nThe solution can now proceed by integration using standard numerical techniques.\n\nThe above illustrates the basic idea of the MUSCL scheme. However, for a practical solution to the Euler equations, a suitable scheme (such as the above KT scheme), also has to be chosen in order to define the function <math>\\mathbf{F}^*_{i \\pm \\frac{1}{2} } </math>.\n\n[[Image:sodProbKTospre.png|thumb|200px|right|High resolution simulation of Euler equations based on G A Sod's 'Shock Tube' problem. Shows the analytical solutions along with simulated (2nd order) solutions based upon the Kuganov and Tadmor Central Scheme with Linear Extrapolation and Ospre limiter.]]\n\nThe diagram opposite shows a 2nd order solution to G A Sod's [[shock tube]] problem (Sod, 1978) using the above high resolution Kurganov and Tadmor Central Scheme (KT) with Linear Extrapolation and Ospre limiter. This illustrates clearly the effectiveness of the MUSCL approach to solving the Euler equations. The simulation was carried out on a mesh of 200 cells using Matlab code (Wesseling, 2001), adapted to use the KT algorithm and [[flux limiter|Ospre limiter]]. Time integration was performed by a 4th order SHK (equivalent performance to RK-4) integrator. The following initial conditions ([[SI]] units) were used:\n\n*pressure left = 100000 [Pa];  \n*pressure right= 10000 [Pa]; \n*density left = 1.0 [kg/m3];  \n*density right = 0.125 [kg/m3]; \n*length = 20 [m];\n*velocity left = 0 [m/s];  \n*velocity right = 0 [m/s]; \n*duration =0.01 [s]; \n*lambda = 0.001069 (Δt/Δx).\n\n[[Image:SodProbParabolicKTalbada.png|thumb|200px|right|High resolution simulation of Euler equations based on G A Sod's 'Shock Tube' problem - SI units. Shows the analytical solutions along with simulated (3rd order) solutions based upon the Kurganov and Tadmor Central Scheme with parabolic reconstruction and van Albada limiter.]]\n\nThe diagram opposite shows a 3rd order solution to G A Sod's [[shock tube]] problem (Sod, 1978) using the above high resolution Kurganov and Tadmor Central Scheme (KT) but with parabolic reconstruction and van Albada limiter. This again illustrates the effectiveness of the MUSCL approach to solving the Euler equations. The simulation was carried out on a mesh of 200 cells using Matlab code (Wesseling, 2001), adapted to use the KT algorithm with Parabolic Extrapolation and [[flux limiter|van Albada limiter]]. The alternative form of van Albada limiter, <math> \\phi_{va} (r) = \\frac{2 r}{1 + r^2 } \\ </math>, was used to avoid spurious oscillations. Time integration was performed by a 4th order SHK integrator. The same initial conditions were used.\n\nVarious other high resolution schemes have been developed that solve the Euler equations with good accuracy. Examples of such schemes are,\n\n*the '''Osher scheme''', and\n*the '''Liou-Steffen''' [[AUSM]] (advection upstream splitting method) scheme.\n\nMore information on these and other methods can be found in the references below. An open source implementation of the Kurganov and Tadmor central scheme can be found in the external links below.\n\n==See also==\n*[[Finite volume method]]\n*[[Flux limiter]]\n*[[Godunov's theorem]]\n*[[High resolution scheme]]\n*[[Method of lines]]\n*[[Sergei K. Godunov]] \n*[[Total variation diminishing]]\n*[[Sod shock tube]]\n\n==References==\n{{reflist}}\n*Kermani, M. J., Gerber, A. G., and Stockie, J. M. (2003), Thermodynamically Based Moisture Prediction Using Roe’s Scheme, ''The 4th Conference of Iranian AeroSpace Society'', Amir Kabir University of Technology, Tehran, Iran, January 27–29. [https://web.archive.org/web/20090530093444/http://me.aut.ac.ir/mkermani/PDF-files/Conferences/Amir_Kabir.pdf]\n*Kurganov, Alexander and [[Eitan Tadmor]] (2000), New High-Resolution Central Schemes for Nonlinear Conservation Laws and Convection-Diffusion Equations, ''J. Comput. Phys.'', ''160'', 241–282. [https://web.archive.org/web/20100606202150/http://www.cscamm.umd.edu/centpack/publications/files/KT_semi-discrete.JCP00-centpack.pdf]\n*Kurganov, Alexander and Doron Levy (2000), A Third-Order Semidiscrete Central Scheme for Conservation Laws and Convection-Diffusion Equations, ''SIAM J. Sci. Comput.'', ''22'', 1461–1488. [https://web.archive.org/web/20100607001557/http://www.cscamm.umd.edu/centpack/publications/files/Kur-Lev_3rd_semi_discrete.SINUM00-centpack.pdf]\n*Lax, P. D. (1954). Weak Solutions of Non-linear Hyperbolic Equations and Their Numerical Computation, ''[[Communications on Pure and Applied Mathematics|Comm. Pure Appl. Math.]]'', VII, pp159–193.\n*Leveque, R. J. (2002). ''Finite Volume Methods for Hyperbolic Problems'', Cambridge University Press.\n*van Leer, B. (1979), Towards the Ultimate Conservative Difference Scheme, V. A Second Order Sequel to Godunov's Method, ''J. Com. Phys.''., ''32'', 101–136.\n*Nessyahu, H.  and [[Eitan Tadmor|E. Tadmor]] (1990), Non-oscillatory central differencing for hyperbolic conservation laws, ''J. Comput. Phys.'', ''87'', 408–463. [https://web.archive.org/web/20100607024124/http://www.cscamm.umd.edu/centpack/publications/files/NT2.JCP90-centpack.pdf].\n*Rusanov, V. V. (1961). Calculation of Intersection of Non-Steady Shock Waves with Obstacles, ''J. Comput. Math. Phys. USSR'', '''1''', pp267–279.\n*Sod, G. A. (1978), A Numerical Study of a Converging Cylindrical Shock. ''J. Fluid Mechanics'', ''83'', 785–794.\n*Toro, E. F. (1999), ''Riemann Solvers and Numerical Methods for Fluid Dynamics'', Springer-Verlag.\n*Wesseling, Pieter (2001), ''Principles of Computational Fluid Dynamics'', Springer-Verlag.\n\n==Further reading==\n*Hirsch, C. (1990), ''Numerical Computation of Internal and External Flows'', vol 2, Wiley.\n*Laney, Culbert B. (1998), ''Computational Gas Dynamics'', Cambridge University Press.\n*Tannehill, John C., et al. (1997), ''Computational Fluid mechanics and Heat Transfer'', 2nd Ed., Taylor and Francis.\n\n== External links ==\n* [https://github.com/Azrael3000/gees GEES] – Open source code solving the Euler Equations using the Kurganov and Tadmor central scheme, written in [[Fortran]] (author: Arno Mayrhofer)\n\n{{Numerical PDE}}\n\n[[Category:Fluid dynamics]]\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Newmark-beta method",
      "url": "https://en.wikipedia.org/wiki/Newmark-beta_method",
      "text": "The '''Newmark-beta method''' is a [[Time integration method|method]] of [[numerical integration]] used to solve [[differential equations]].  It is widely used in numerical evaluation of the dynamic response of structures and solids such as in [[Finite element method in structural mechanics | finite element analysis]] to model dynamic systems. The method is named after [[Nathan M. Newmark]],<ref>{{citation|last=Newmark|first= Nathan M. |authorlink=Nathan M. Newmark|year=1959|title= A method of computation for structural dynamics|journal= Journal of Engineering Mechanics, ASCE|volume= 85 (EM3)|pages= 67-94}}</ref> former Professor of Civil Engineering at the [[University of Illinois at Urbana–Champaign]], who developed it in 1959 for use in [[structural dynamics]].\n\nUsing the [[extended mean value theorem]], the Newmark-<math>\\beta</math> method states that the first time derivative (velocity in the [[equation of motion]]) can be solved as,\n\n:<math>\\dot{u}_{n+1}=\\dot{u}_n+ \\Delta t~\\ddot{u}_\\gamma \\,</math>\n\nwhere\n\n:<math>\\ddot{u}_\\gamma = (1 - \\gamma)\\ddot{u}_n + \\gamma \\ddot{u}_{n+1}~~~~0\\leq \\gamma \\leq 1</math>\n\ntherefore\n\n:<math>\\dot{u}_{n+1}=\\dot{u}_n + (1 - \\gamma) \\Delta t~\\ddot{u}_n + \\gamma \\Delta t~\\ddot{u}_{n+1}.</math>\n\nBecause acceleration also varies with time, however, the extended mean value theorem must also be extended to the second time derivative to obtain the correct displacement.  Thus,\n\n:<math>u_{n+1}=u_n + \\Delta t~\\dot{u}_n+\\begin{matrix} \\frac 1 2 \\end{matrix} \\Delta t^2~\\ddot{u}_\\beta </math>\n\nwhere again\n\n:<math>\\ddot{u}_\\beta = (1 - 2\\beta)\\ddot{u}_n + 2\\beta\\ddot{u}_{n+1}~~~~0\\leq 2\\beta\\leq 1</math>\n\nNewmark showed that a reasonable value of <math>\\gamma</math> is&nbsp;0.5, therefore the update rules are,\n\n:<math>\\dot{u}_{n+1}=\\dot{u}_n + \\begin{matrix}\\frac{\\Delta t}{2}\\end{matrix}~(\\ddot{u}_n + \\ddot{u}_{n+1})</math>\n\n:<math>u_{n+1}=u_n + {\\Delta}t~\\dot{u}_n + \\begin{matrix}\\frac{1-2\\beta}{2}\\end{matrix} \\Delta t^2 \\ddot{u}_n + \\beta {\\Delta} t^2 \\ddot{u}_{n+1}</math>\n\nSetting <math>\\beta</math> to various values between 0 and 0.5 can give a wide range of results.  Typically <math>\\beta=1/4</math>, which yields the constant average acceleration method, is used.\n\n==References==\n\n{{Reflist}}\n\n{{Numerical integrators}}\n\n{{DEFAULTSORT:Newmark-Beta Method}}\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Non-compact stencil",
      "url": "https://en.wikipedia.org/wiki/Non-compact_stencil",
      "text": "[[Image:NonCompactStencil.svg|thumb|right|150px|A 2D non-compact stencil]]\nIn numerical mathematics, a '''non-compact [[Stencil (numerical analysis)|stencil]]''' is a type of [[discretization]] method, where any node surrounding the node of interest may be used in the calculation. A non-compact stencil's [[computational time]] increases with an increase of layers of nodes used. Non-compact stencils may be compared to [[Compact stencil]]s.<ref>W. F. Spotz. High-Order Compact Finite Difference Schemes for Computational Mechanics. PhD thesis, University of Texas at Austin, Austin, TX, 1995.</ref><ref>Communications in Numerical Methods in Engineering, Copyright © 2008 John Wiley & Sons, Ltd.</ref>\n\n==See also==\n*[[Five-point stencil]]\n\n== Notes ==\n{{reflist}}\n\n== External links ==\n*[http://www.cisl.ucar.edu/css/staff/spotz/research/hoc.html#stencil High-Order Compact Schemes]\n\n[[Category:Numerical differential equations]]\n\n\n{{applied-math-stub}}"
    },
    {
      "title": "Numerical resistivity",
      "url": "https://en.wikipedia.org/wiki/Numerical_resistivity",
      "text": "{{Noref|date=August 2011}}\n'''Numerical resistivity''' is a problem in [[computer simulation]]s of ideal [[magnetohydrodynamics]] (MHD).  It is a form of [[numerical diffusion]].  In near-ideal MHD systems, the magnetic field can diffuse only very slowly through the [[Plasma (physics)|plasma]] or [[fluid]] of the system; it is rate-limited by the inverse of the [[resistivity]] of the fluid.  In [[Eulerian method|Eulerian simulations]] where the field is arbitrarily aligned compared to the simulation grid, the [[numerical diffusion]] rate takes the form similar to an additional resistivity, causing non-physical and sometimes bursty [[magnetic reconnection]] in the simulation.  Numerical resistivity is a function of resolution, alignment of the magnetic field with the grid, and numerical method.  In general, numerical resistivity will not behave isotropically, and there can be different effective numerical resistivities in different parts of the computational domain.  For current (2005) simulations of the [[solar corona]] and inner [[heliosphere]], this numerical effect can be several orders of magnitude larger than the physical resistivity of the plasma.\n\n==See also==\n*[[Numerical diffusion]]\n\n[[Category:Numerical differential equations]]\n\n\n{{mathapplied-stub}}"
    },
    {
      "title": "Numerov's method",
      "url": "https://en.wikipedia.org/wiki/Numerov%27s_method",
      "text": "'''Numerov's method''' (also called  Cowell's method) is a numerical method to solve [[ordinary differential equation]]s of second order in which the first-order term does not appear. It is a fourth-order [[linear multistep method]]. The method is implicit, but can be made explicit if the differential equation is linear.\n\nNumerov's method was developed by the Russian astronomer [[Boris Vasil'evich Numerov]].\n\n==The method==\nThe Numerov method can be used to solve differential equations of the form\n\n:<math> \\frac{d^2 y}{dx^2} = - g(x) y(x) + s(x). </math>\n\nIn it, three values of <math> y_{n-1}, y_n, y_{n+1} </math> taken at three equidistant points <math> x_{n-1}, x_n, x_{n+1} </math> are related as follows:\n\n:<math> y_{n+1} \\left(1 + \\frac{h^2}{12} g_{n+1}\\right) = 2 y_n \\left(1 - \\frac{5 h^2}{12} g_n\\right) - y_{n-1} \\left(1 + \\frac{h^2}{12} g_{n-1}\\right) + \\frac{h^2}{12} (s_{n+1} + 10 s_n + s_{n-1}) + \\mathcal{O}(h^6), </math>\n\nwhere <math> y_n = y(x_n) </math>, <math> g_n = g(x_n) </math>, <math> s_n = s(x_n) </math>, and <math> h = x_{n+1} - x_n </math>.\n\n=== Nonlinear equations ===\n\nFor nonlinear equations of the form\n\n:<math> \\frac{d^2 y}{dx^2} = f(x,y), </math>\n\nthe method gives\n\n:<math> y_{n+1} - 2 y_n + y_{n-1} = \\frac{h^2}{12} (f_{n+1} + 10 f_n + f_{n-1}) + \\mathcal{O} (h^6). </math>\n\nThis is an implicit [[linear multistep method]], which reduces to the explicit method given above if <math> f </math> is linear in <math> y </math> by setting <math> f(x,y) = - g(x) y(x) + s(x) </math>. It achieves order-4 accuracy {{harv|Hairer|Nørsett|Wanner|1993|loc=§III.10}}.\n\n==Application==\n\nIn numerical physics the method is used to find solutions of the unidimensional [[Schrödinger equation]] for arbitrary potentials. An example of which is solving the radial equation for a spherically symmetric potential. In this example, after separating the variables and analytically solving the angular equation, we are left with the following equation of the radial function <math>R(r)</math>:\n\n:<math> \\frac{d}{dr} \\left(r^2 \\frac{dR}{dr} \\right) - \\frac{2 m r^2}{\\hbar^2} (V(r) - E) R(r) = l (l + 1) R(r). </math>\n\nThis equation can be reduced to the form necessary for the application of Numerov's method with the following substitution:\n\n:<math> u(r) = r R(r), </math>\n:<math> R(r) = \\frac{u(r)}{r}, </math>\n:<math> \\frac{dR}{dr} = \\frac{1}{r} \\frac{du}{dr} - \\frac{u(r)}{r^2} = \\frac{1}{r^2} \\left (r \\frac{du}{dr} - u(r) \\right), </math>\n:<math> \\frac{d}{dr} \\left(r^2 \\frac{dR}{dr} \\right) = \\frac{du}{dr} + r \\frac{d^2 u}{dr^2} - \\frac{du}{dr} = r \\frac{d^2 u}{dr^2}. </math>\n\nAnd when we make the substitution, the radial equation becomes\n\n:<math> r \\frac{d^2 u}{dr^2} - \\frac{2 m r}{\\hbar^2} (V(r) - E) u(r) = \\frac{l (l + 1)}{r} u(r), </math>\n\nor\n\n:<math> -\\frac{\\hbar^2}{2 m} \\frac{d^2 u}{dr^2} + \\left(V(r) + \\frac{\\hbar^2}{2 m} \\frac{l (l + 1)}{r^2} \\right) u(r) = E u(r), </math>\n\nwhich is equivalent to the one-dimensional Schrödinger equation, but with the modified effective potential\n\n:<math> V_\\text{eff}(r) = V(r) + \\frac{\\hbar^2}{2 m} \\frac{l (l + 1)}{r^2} = V(r) + \\frac{L^2}{2 m r^2}, \\quad L^2 = l (l + 1) \\hbar^2. </math>\n\nThis equation we can proceed to solve the same way we would have solved the one-dimensional Schrödinger equation. We can rewrite the equation a little bit differently and thus see the possible application of Numerov's method more clearly:\n\n:<math> \\frac{d^2 u}{dr^2} = - \\frac{2 m}{\\hbar^2} (E - V_\\text{eff}(r)) u(r), </math>\n\n:<math> g(r) = \\frac{2 m}{\\hbar^2} (E - V_\\text{eff}(r)), </math>\n\n:<math> s(r) = 0. </math>\n\n==Derivation==\nWe are given the differential equation\n\n:<math> y''(x) = - g(x) y(x) + s(x). </math>\n\nTo derive the Numerov's method for solving this equation, we begin with the [[Taylor expansion]] of the function we want to solve, <math> y(x) </math>, around the point <math> x_0 </math>:\n\n:<math> y(x) = y(x_0) + (x-x_0)y'(x_0) + \\frac{(x-x_0)^2}{2!}y''(x_0) + \\frac{(x-x_0)^3}{3!}y'''(x_0) + \\frac{(x-x_0)^4}{4!}y''''(x_0) + \\frac{(x-x_0)^5}{5!}y'''''(x_0) + \\mathcal{O}(h^6). </math>\n\nDenoting the distance from <math> x </math> to <math> x_0 </math> by <math> h = x - x_0 </math>, we can write the above equation as\n\n:<math> y(x_0 + h) = y(x_0) + hy'(x_0) + \\frac{h^2}{2!}y''(x_0) + \\frac{h^3}{3!}y'''(x_0) + \\frac{h^4}{4!}y''''(x_0) + \\frac{h^5}{5!}y'''''(x_0) + \\mathcal{O}(h^6). </math>\n\nIf we evenly discretize the space, we get a grid of <math> x </math> points, where <math> h = x_{n+1} - x_n </math>. By applying the above equations to this discrete space, we get a relation between the <math> y_n </math> and <math> y_{n+1} </math>:\n\n:<math> y_{n+1} = y_n + hy'(x_n) + \\frac{h^2}{2!}y''(x_n) + \\frac{h^3}{3!}y'''(x_n) + \\frac{h^4}{4!}y''''(x_n) + \\frac{h^5}{5!}y'''''(x_n) + \\mathcal{O}(h^6). </math>\n\nComputationally, this amounts to taking a step ''forward'' by an amount <math> h </math>. If we want to take a step ''backwards'', we replace every <math> h </math> with <math> - h </math> and get the expression for <math> y_{n-1} </math>:\n\n:<math> y_{n-1} = y_n - hy'(x_n) + \\frac{h^2}{2!}y''(x_n) - \\frac{h^3}{3!}y'''(x_n) + \\frac{h^4}{4!}y''''(x_n) - \\frac{h^5}{5!}y'''''(x_n) + \\mathcal{O}(h^6). </math>\n\nNote that only the odd powers of <math> h </math> experienced a sign change. By summing the two equations, we derive that\n\n:<math> y_{n+1} - 2 y_n + y_{n-1} = h^2 y''_n + \\frac{h^4}{12}y''''_n + \\mathcal{O}(h^6). </math>\n\nWe can solve this equation for <math> y_{n+1} </math> by substituting the expression given at the beginning, that is <math> y''_n = - g_n y_n + s_n </math>. To get an expression for the <math> y''''_n </math> factor, we simply have to differentiate <math> y''_n = - g_n y_n + s_n </math> twice and approximate it again in the same way we did this above:\n\n:<math> y''''_n = \\frac{d^2}{d x^2} (-g_n y_n + s_n), </math>\n:<math> h^2 y''''_n = -g_{n+1} y_{n+1} + s_{n+1} + 2 g_n y_n - 2 s_n - g_{n-1} y_{n-1} + s_{n-1} + \\mathcal{O}(h^4). </math>\n\nIf we now substitute this to the preceding equation, we get\n\n:<math> y_{n+1} - 2 y_n + y_{n-1} = {h^2} (- g_n y_n + s_n) + \\frac{h^2}{12} (- g_{n+1} y_{n+1} + s_{n+1} + 2 g_n y_n - 2 s_n - g_{n-1} y_{n-1} + s_{n-1}) + \\mathcal{O}(h^6), </math>\n\nor\n\n:<math> y_{n+1} \\left(1 + \\frac{h^2}{12} g_{n+1} \\right) - 2 y_n \\left(1 - \\frac{5 h^2}{12} g_n \\right) + y_{n-1} \\left(1 + \\frac{h^2}{12} g_{n-1} \\right) = \\frac{h^2}{12} (s_{n+1} + 10 s_n + s_{n-1}) + \\mathcal{O}(h^6). </math>\n\nThis yields the Numerov's method if we ignore the term of order <math> h^6 </math>. It follows that the order of convergence (assuming stability) is 4.\n\n== References ==\n* {{Citation | last1=Hairer | first1=Ernst | last2=Nørsett | first2=Syvert Paul | last3=Wanner | first3=Gerhard | title=Solving ordinary differential equations I: Nonstiff problems | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-56670-0 | year=1993}}. <br> This book includes the following references:\n* {{Citation | last1=Numerov | first1=Boris Vasil'evich | author1-link=Boris Vasil'evich Numerov | title=A method of extrapolation of perturbations | year=1924 | journal=[[Monthly Notices of the Royal Astronomical Society]] | volume=84 | pages=592–601|bibcode = 1924MNRAS..84..592N | doi = 10.1093/mnras/84.8.592 }}.\n* {{Citation | last1=Numerov | first1=Boris Vasil'evich | author1-link=Boris Vasil'evich Numerov | title=Note on the numerical integration of d<sup>2</sup>''x''/d''t''<sup>2</sup> = ''f''(''x'',''t'') | year=1927 | journal=[[Astronomische Nachrichten]] | volume=230 | pages=359–364|bibcode = 1927AN....230..359N | doi=10.1002/asna.19272301903}}.\n\n==External links==\n\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Orthogonal collocation",
      "url": "https://en.wikipedia.org/wiki/Orthogonal_collocation",
      "text": "'''Orthogonal collocation''' is a method for the [[numerical partial differential equations|numerical solution of partial differential equations]]. It uses [[collocation method|collocation]] at the zeros of some [[orthogonal polynomials]] to transform the [[partial differential equation]] (PDE) to a set of [[ordinary differential equation]]s (ODEs). The ODEs can then be solved by any method. It has been shown that it is usually advantageous to choose the collocation points as the zeros of the corresponding [[Jacobi polynomial]] (independent of the PDE system).\n\n[[Category:Numerical differential equations]]\n\n\n{{mathapplied-stub}}"
    },
    {
      "title": "P-FEM",
      "url": "https://en.wikipedia.org/wiki/P-FEM",
      "text": "{{lowercase}}\n'''p-FEM''' or the p-version of the [[finite element method]] is a [[Numerical analysis|numerical method]] for solving [[partial differential equations]]. It is a discretization strategy in which the finite element mesh is fixed and the polynomial degrees of elements are increased such that the lowest polynomial degree, denoted by <math>p_{\\min}</math>, approaches infinity. This is in contrast with the \"h-version\" or \"h-FEM\", a widely used discretization strategy, in which the polynomial degrees of elements are fixed and the mesh is refined such that the diameter of the largest element, denoted by <math>h_{\\max}</math> approaches zero.\n\nIt was demonstrated on the basis of a linear elastic fracture mechanics problem that sequences of finite element solutions based on the p-version converge faster than sequences based on the h-version by [[Barna A. Szabó|Szabó]] and [[Mehta A. K.|Mehta]] in 1978.<ref>Szabó, B. A. and Mehta, A. K., \"p-Convergent Finite Element Approximations in Fracture Mechanics.\" International Journal for Numerical Methods in Engineering 12, pp. 551-560, 1978.</ref> The theoretical foundations of the p-version were established in a paper published [[Ivo Babuska|Babuška]], Szabó and [[Katz, I. N.|Katz]] in 1981<ref>Babuška I, Szabó, B. A. and Katz, I. N., \"The p-version of the finite element method.\" SIAM Journal on Numerical Analysis 18, pp. 515-545, 1981.</ref> where it was shown that for a large class of problems the asymptotic rate of convergence of the p-version in energy norm is at least twice that of the h-version, assuming that quasi-uniform meshes are used. Additional computational results and evidence of faster convergence of the p-version were presented by Babuška and Szabó in 1982.<ref>Babuška, I. and Szabó, B. A., \"On the Rates of Convergence of the Finite Element Method.\" International Journal for Numerical Methods in Engineering 18, pp. 323-341, 1982.</ref>\n\nThe distinction between the h- and p-versions exists primarily for historical and theoretical reasons. In practical applications the design of the mesh and the choice polynomial degrees are both important. In fact, it is possible to realize exponential rates of convergence when the p-version is used in combination with proper mesh design. This point was discussed from the engineering perspective by Szabó and from the theoretical perspective by [[Guo, B|Guo]] and Babuška in 1986.<ref>Szabó, B. A., \"Mesh design for the p-version of the finite element method.\" Computer Methods in Applied Mechanics and Engineering 55(1), pp. 181-197, 1986.</ref><ref>Guo, B. and Babuška, I. \"The h-p version of the finite element method. Part 1. Basic approximation results.\" Computational Mechanics 55, pp. 21-41, 1986.</ref> Realization of exponential rates of convergence for Maxwell equations was discussed by [[Costabel, M.|Costabel]], [[Dauge, M.|Dauge]] and [[Schwab, C.|Schwab]] in 2005<ref>Costabel, M., Dauge, M., and Schwab, C., \"Exponential convergence of hp-FEM for Maxwell equations with weighted regularization in polygonal domains.\" Mathematical Models and Methods in Applied Sciences 15(04), pp. 575-622, 2005.</ref>\n\n==References==\n{{reflist}}\n\n[[Category:Finite element method]]\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]"
    },
    {
      "title": "Pantelides algorithm",
      "url": "https://en.wikipedia.org/wiki/Pantelides_algorithm",
      "text": "{{Context|date=August 2010}}\n\n'''Pantelides algorithm''' gives a systematic method for reducing high-index systems of [[Differential algebraic equation|differential-algebraic equations]] to lower index, by selectively adding differentiated forms of the equations already present in the system.<ref>C Pantelides, [https://dx.doi.org/10.1137/0909014 The Consistent Initialization of Differential-Algebraic Systems], SIAM J. Sci. and Stat. Comput. Volume 9, Issue 2, pp.&nbsp;213–231 (March 1988)  (the original paper where the algorithm is described)</ref><ref>Francois Cellier, ''[http://www.ece.arizona.edu/~cellier/ece449_lecture.html Lecture notes about Pantelides algorithm]''</ref><ref>John Pye, ''[http://jpye.dyndns.org/pantelides/ Pantelides Algorithm in PHP] {{webarchive|url=https://web.archive.org/web/20110413074018/http://jpye.dyndns.org/pantelides/ |date=2011-04-13 }}'' (source code in [[PHP]] language)</ref> It is possible for the [[algorithm]] to fail in some instances.\n\nPantelides algorithm is implemented in several significant equation-based simulation programs such as gPROMS, [[Modelica]] and [[EMSO simulator|EMSO]].<ref>Peter A. Fritzson, ''Principles of Object-Oriented Modeling and Simulation with Modelica 2.1'', Wiley, {{ISBN|0-471-47163-1}}</ref><ref>R de P. Soares and A R. Secchi, 2005, ''Direct initialisation and solution of high-index DAE systems'', Computer Aided Chemical Engineering '''20''', {{doi|10.1016/S1570-7946(05)80148-8}}.</ref><ref>[http://www.enq.ufrgs.br/trac/alsoc/wiki/EMSO EMSO] a free-to-use closed-source simulator/equation solver that includes implementation for the Pantelides algorithm.</ref>\n\n==References==\n{{reflist}}\n\n[[Category:Numerical differential equations]]\n\n\n{{algorithm-stub}}"
    },
    {
      "title": "Partial element equivalent circuit",
      "url": "https://en.wikipedia.org/wiki/Partial_element_equivalent_circuit",
      "text": "\n[[Image:cube PEEC LTU.png|thumb|right|200px|A 10x10x10 cm cube is modelled in the frequency domain. The cube is excited with a\nunitary current pulse in one corner.]]\n\n[[Image:case PEEC LTU.png|thumb|right|200px|A 19x43x38 cm (LxWxT) case with one opening (19x10) in the front is modeled in the time domain.]]\n\n'''Partial element equivalent circuit method (PEEC)''' is partial [[inductance]] calculation used for interconnect problems from early 1970s which is used for numerical modeling of [[Electromagnetism|electromagnetic]] (EM) properties. The transition from a design tool to the full wave method involves the [[capacitance]] representation, the inclusion of time retardation and the dielectric formulation. Using the PEEC method, the problem will be transferred from the electromagnetic domain to the circuit domain where conventional SPICE-like circuit solvers can be employed to analyze the equivalent circuit. By having the PEEC model one can easily include any electrical component e.g. passive components, sources, non-linear elements, ground, etc. to the model. Moreover, using the PEEC circuit, it is easy to exclude capacitive, inductive or resistive effects from the model when it is possible, in order to make the model smaller. As an example, in many application within power electronics, the magnetic field is a dominating factor over the electric field due to the high current in the systems. Therefore, the model can be simplified by just neglecting capacitive couplings in the model which can simply be done by excluding the capacitors from the PEEC model.\n\nNumerical modeling of electromagnetic properties are used by, for example, the electronics industry to:\n* Ensure functionality of electric systems\n* Ensure compliance with electromagnetic compatibility (EMC)\n\n==History==\nThe main research activity in this area has been and are performed, by [[Albert E. Ruehli|Albert Ruehli]]<ref>A. E. Ruehli: Equivalent Circuit Models for Three-Dimensional Multiconductor Systems, IEEE Transactions on Microwave Theory and Techniques, Vol. 22 (1974), Nr. 3</ref> at [[IBM Thomas J. Watson Research Center]], starting with a publication in 1972. At that time the foundation of the PEEC method was presented, i.e. the calculation of the partial inductances. The PEEC method was extended to more generalized problems, including dielectric material and retardation effect.\n\nThe PEEC method is not one of the most common techniques used in EM simulation software or as a research area but it has just been starting to gain recognition and for the first time there is a session at the 2001 [[IEEE]] EMC Symposium named after the technique. In the mid 90's, two researchers from the [[University of L'Aquila]] in Italy, Professor Antonio Orlandi and Professor Giulio Antonini, published their first PEEC paper and are now together with Dr. Ruehli considered the top researchers in the area. Starting year 2006, several research projects have been initiated by the faculty of Computer Science and Electrical Engineering of [[Luleå University of Technology]] in Sweden in the focus area of PEEC with the emphasis on computer based solvers for PEEC under the name [[MultiPEEC]].\n\n==Application==\nPEEC is widely used for combined electromagnetic and circuit problems in various areas such as power electronics, antenna design, signal integrity analysis, etc. Using PEEC the designed model of a physical structure is transferred from the electromagnetic domain into the circuit domain. Therefore, external electrical components and circuits can be connected to the equivalent circuit which consist of extracted partial elements, in a straightforward manner. Moreover, since the final model consist of circuit elements, various components can easily be excluded from the circuit to simplify the problem while the accuracy is still ensured. For instance, for low frequency problems, one can safely remove capacitive couplings without degrading the accuracy of the results and hence reduce the problem size and complexity.\n\n==Theory==\nThe classical PEEC method is derived from the equation for the total electric field at a point<ref>S. Ramo, J. R. Whinnery and T. Van Duzer: Fields and Waves in Communication Electronics, John Wiley and Sons, 1972</ref> written as\n\n[[File:PEEC_Model.png|thumb|right|An orthogonal metal strip with 3 nodes and 2 cells.]]\n[[File:PEEC_Circuit.png|thumb|right|The corresponding PEEC circuit.]]\n\n:<math>\n\\vec{E}^i(\\vec{r},t)  =   \\frac{\\vec{J}(\\vec{r},t)}{\\sigma} + \\frac {\\partial\n\\vec{A}(\\vec{r},t)}{\\partial t} + \\nabla \\phi (\\vec{r},t)\n</math>\n\nwhere <math>\\vec{E}^i</math> is an incident electric field, <math>\\vec{J}</math> is a current density, <math>\\vec{A}</math> is the magnetic vector potential, <math>\\phi</math> is the scalar electric potential, and <math>\\sigma</math> the electrical conductivity all at observation point <math>\\vec{r}</math>. In the figures on the right, an orthogonal metal strip with 3 nodes and 2 cells, and the corresponding PEEC circuit are shown.\n\nBy using the definitions of the scalar and vector potentials, the current- and charge-densities are discretized by defining pulse basis functions for the conductors and dielectric materials.  Pulse functions are also used for the weighting functions resulting in a Galerkin type solution.  By defining a suitable inner product, a weighted volume integral over the cells, the field equation can be interpreted as Kirchhoff's voltage law over a PEEC cell consisting of partial self inductances between the nodes and partial mutual inductances representing the magnetic field coupling in the equivalent circuit. The partial inductances are defined as\n\n:<math>\nL_{p_{\\alpha \\beta}} = \\frac {\\mu}{4 \\pi}\\frac{1}{a_{\\alpha}\na_{\\beta}} \\int_{v_{\\alpha}} \\int_{v_{\\beta}} \\frac {1} {|\n\\vec{r}_{\\alpha} - \\vec{r}_{\\beta}|} d v_{\\alpha} dv_{\\beta}\n</math>\n\nfor volume cell <math>\\alpha</math> and <math>\\beta</math>. Then, the coefficients of potentials are computed as\n\n:<math>\nP_{ij} = \\frac{1}{S_i S_j} \\frac{1}{4 \\pi \\epsilon_0} \\int_{S_i}\n\\int_{S_j} \\frac{1}{|\\vec{r}_i - \\vec{r}_j|} \\; dS_j \\; dS_i\n</math>\n\nand a resistive term between the nodes, defined as\n\n:<math>\nR_\\gamma = \\frac{l_\\gamma}{a_\\gamma \\sigma_\\gamma}.\n</math>\n\n===PEEC model reduction===\nThe rigorous full-wave version of the PEEC method is called (Lp,P,R,t) PEEC, where Lp is partial inductance, P is potential coefficient (inverse of capacitance), R is resistance, and t is delay. If available, reduced model of the full-wave version can be used. For example, if the EIP structure is electrically small, the delay term t can be omitted and the model can be reduced to (Lp,P,R) PEEC model. In addition, if frequency is sufficiently high so that w*Lp >> R, we can omit R term and use approximate (Lp,P) PEEC model. According to various modeling situations, (Lp) and (Lp,R) models are also useful.\n\n===Orthogonal PEEC===\n{{Empty section|date=January 2011}}\n\n===Nonorthogonal PEEC===\n{{Empty section|date=January 2011}}\n\n===Time domain analysis===\n{{Empty section|date=January 2011}}\n\n===Frequency domain analysis===\n{{Empty section|date=January 2011}}\n\n==Discretization==\n===Meshing basics in PEEC===\n{{Empty section|date=January 2011}}\n\n===Uniform meshing===\n{{Empty section|date=January 2011}}\n\n===Nonuniform meshing===\n{{Empty section|date=January 2011}}\n\n==PEEC solver==\n\n{{Empty section|date=July 2010}}\n\n==Case study==\n\n{{Empty section|date=July 2010}}\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://www.sm.luth.se/~jekman/PEEC/Program/ Partial Element Equivalent Circuit (PEEC) homepage]\n* [http://www.cedrat.com/fileadmin/user_upload/cedrat_groupe/Publications/Publications/2009/09/2009_PowerModulesEMC_ModellingProcess_Aime_ISEF.pdf   Electromagnetic Modelling Process to Improve Cabling of Power Electronic Structures]\n\n{{DEFAULTSORT:Partial Element Equivalent Circuit}}\n[[Category:Numerical differential equations]]\n[[Category:Computational science]]"
    },
    {
      "title": "Particle-in-cell",
      "url": "https://en.wikipedia.org/wiki/Particle-in-cell",
      "text": "The '''particle-in-cell''' ('''PIC''') method refers to a technique used to solve a certain class of [[partial differential equations]].  In this method, individual particles (or fluid elements) in a [[Lagrangian and Eulerian coordinates|Lagrangian]] frame are tracked in continuous [[phase space]], whereas moments of the distribution such as densities and currents are computed simultaneously on Eulerian (stationary) [[Mesh (mathematics)|mesh]] points.\n\nPIC methods were already in use as early as 1955,<ref>\n{{Cite journal\n|author=F.H. Harlow\n|author-link=Francis H. Harlow\n|title=A Machine Calculation Method for Hydrodynamic Problems\n|publisher=Los Alamos Scientific Laboratory report LAMS-1956\n|year=1955}}\n</ref>\neven before the first [[Fortran]] compilers were available. The method gained popularity for plasma simulation in the late 1950s and early 1960s by [[Oscar Buneman|Buneman]], [[John M. Dawson|Dawson]], Hockney, Birdsall, Morse and others. In [[Plasma (physics)|plasma physics]] applications, the method amounts to following the trajectories of charged particles in self-consistent electromagnetic (or electrostatic) fields computed on a fixed mesh. \n<ref>\n{{cite journal\n|author=Dawson, J.M.\n|author-link=John M. Dawson\n|title=Particle simulation of plasmas\n|journal=Reviews of Modern Physics\n|year=1983\n|volume=55\n|issue=2\n|pages=403–447\n|doi=10.1103/RevModPhys.55.403\n|bibcode=1983RvMP...55..403D}}\n</ref>\n\n== Technical aspects ==\n\nFor many types of problems, the classical PIC method invented by Buneman, Dawson, Hockney, Birdsall, Morse and others is relatively intuitive and straightforward to implement.  This probably accounts for much of its success, particularly for plasma simulation, for which the method typically includes the following procedures:\n* Integration of the equations of motion.\n* Interpolation of charge and current source terms to the field mesh.\n* Computation of the fields on mesh points.\n* Interpolation of the fields from the mesh to the particle locations.\n\nModels which include interactions of particles only through the average fields are called '''PM''' (particle-mesh). Those which include direct binary interactions are '''PP''' (particle-particle). Models with both types of interactions are called '''PP-PM''' or '''P<sup>3</sup>M'''.\n\nSince the early days, it has been recognized that the PIC method is susceptible to error from so-called ''discrete particle noise''.\n<ref>\n{{cite journal\n|author=Hideo Okuda\n|title=Nonphysical noises and instabilities in plasma simulation due to a spatial grid\n|journal=Journal of Computational Physics\n|year=1972\n|volume=10\n|issue=3\n|pages=475–486\n|doi=10.1016/0021-9991(72)90048-4|bibcode = 1972JCoPh..10..475O }}\n</ref>\nThis error is statistical in nature, and today it remains less-well understood than for traditional fixed-grid methods, such as [[Numerical partial differential equations|Eulerian]] or [[semi-Lagrangian scheme|semi-Lagrangian]] schemes.\n\nModern geometric PIC algorithms are based on a very different theoretical framework. These algorithms use tools of discrete manifold, interpolating differential forms, and canonical or non-canonical [[symplectic integrator]]s to guarantee gauge invariant and conservation of charge, energy-momentum, and more importantly the infinitely dimensional symplectic structure of the particle-field system.\n<ref>\n{{cite journal\n|author1=Qin, H. |author2=Liu, J. |author3=Xiao, J. |title= Canonical symplectic particle-in-cell method for long-term large-scale simulations of the Vlasov-Maxwell system\n|journal= Nuclear Fusion\n|year=2016\n|volume=56\n|issue=1\n|pages=014001\n|doi=10.1088/0029-5515/56/1/014001|bibcode=  2016NucFu..56a4001Q|display-authors=etal|arxiv = 1503.08334 }}\n</ref>\n<ref>\n{{cite journal\n|author1=Xiao, J. |author2=Qin, H. |author3=Liu, J. |title= Explicit high-order non-canonical symplectic particle-in-cell algorithms for Vlasov-Maxwell systems\n|journal= Physics of Plasmas\n|year=2015\n|volume=22\n|issue=11\n|pages=12504\n|doi=10.1063/1.4935904|bibcode=  2015PhPl...22k2504X|display-authors=etal|arxiv = 1510.06972 }}\n</ref>\nThese desired features are attributed to the fact that geometric PIC algorithms are built on the more fundamental field-theoretical framework and are directly linked to the perfect form, i.e., the variational principle of physics.\n\n== Basics of the PIC plasma simulation technique ==\n\nInside the plasma research community, systems of different species (electrons, ions, neutrals, molecules, dust particles, etc.) are investigated. The set of equations associated with PIC codes are therefore the [[Lorentz force]] as the equation of motion, solved in the so-called ''pusher'' or ''particle mover'' of the code, and [[Maxwell's equations]] determining the [[electric field|electric]] and [[magnetic field|magnetic]] fields, calculated in the ''(field) solver''.\n\n=== Super-particles ===\n\nThe real systems studied are often extremely large in terms of the number of particles they contain. In order to make simulations efficient or at all possible, so-called ''super-particles'' are used. A super-particle (or ''macroparticle'') is a computational particle that represents many real particles; it may be millions of electrons or ions in the case of a plasma simulation, or, for instance, a vortex element in a fluid simulation. It is allowed to rescale the number of particles, because the [[Lorentz force]] depends only on the charge-to-mass ratio, so a super-particle will follow the same trajectory as a real particle would.\n\nThe number of real particles corresponding to a super-particle must be chosen such that sufficient statistics can be collected on the particle motion. If there is a significant difference between the density of different species in the system (between ions and neutrals, for instance), separate real to super-particle ratios can be used for them.\n\n=== The particle mover ===\n\nEven with super-particles, the number of simulated particles is usually very large (> 10<sup>5</sup>), and often the particle mover is the most time consuming part of PIC, since it has to be done for each particle separately. Thus, the pusher is required to be of high accuracy and speed and much effort is spent on optimizing the different schemes.\n\nThe schemes used for the particle mover can be split into two categories, implicit and explicit solvers. While implicit solvers (e.g. implicit Euler scheme) calculate the particle velocity from the already updated fields, explicit solvers use only the old force from the previous time step, and are therefore simpler and faster, but require a smaller time step. In PIC simulation the [[leapfrog method]] is used, a second-order explicit method. <ref>{{cite book \n  | last1 = Birdsall\n  | first1 = Charles K. \n  | author2 = A. Bruce Langdon \n  | title = Plasma Physics via Computer Simulation \n  | publisher = McGraw-Hill \n  | year = 1985\n  | isbn = 0-07-005371-5\n}}</ref> Also the ''Boris algorithm'' is used which cancel out the magnetic field in the Newton-Lorentz equation. <ref>{{Cite conference\n| title = Relativistic plasma simulation-optimization of a hybrid code\n| last = Boris\n| first = J.P.\n|date=November 1970\n| booktitle = Proceedings of the ''4th Conference on Numerical Simulation of Plasmas''\n| publisher = Naval Res. Lab., Washington, D.C.\n| pages = 3&ndash;67\n}}</ref> \n<ref>\n{{cite journal\n|author1=Qin, H. |display-authors=etal |title=Why is Boris algorithm so good? \n|journal=Physics of Plasmas\n|year=2013\n|volume=20\n|issue=5\n|pages=084503 \n|doi=10.1063/1.4818428 |bibcode = 2013PhPl...20h4503Q }}\n</ref>.\n\nFor plasma applications, the [[leapfrog method]] takes the following form:\n:<math>\\frac{\\mathbf{x}_{k+1} - \\mathbf{x}_{k}}{\\Delta t} = \\mathbf{v}_{k+1/2},</math>\n:<math>\\frac{\\mathbf{v}_{k+1/2} - \\mathbf{v}_{k-1/2}}{\\Delta t} = \\frac{q}{m} \\left( \\mathbf{E}_k + \\frac{\\mathbf{v}_{k+1/2} + \\mathbf{v}_{k-1/2}}{2} \\times \\mathbf{B}_{k} \\right),</math>\n\nwhere the subscript <math>k</math> refers to \"old\" quantities from the previous time step, <math>k+1</math> to updated quantities from the next time step (i.e. <math>t_{k+1} = t_k + \\Delta t</math>), and velocities are calculated in-between the usual time steps <math>t_k</math>.\n\nThe equations of the Boris scheme which are substitute in the above equations are:\n:<math>\\mathbf{x}_{k+1} = \\mathbf{x}_{k} + {\\Delta t} \\mathbf{v}_{k+1/2},</math>\n:<math>\\mathbf{v}_{k+1/2} = \\mathbf{u}' + q' \\mathbf{E}_k,</math>\n\nwith \n:<math>\\mathbf{u}' = \\mathbf{u} + (\\mathbf{u} + (\\mathbf{u} \\times \\mathbf{h})) \\times \\mathbf{s},</math>\n:<math>\\mathbf{u} = \\mathbf{v}_{k-1/2} + q' \\mathbf{E}_k,</math>\n:<math>\\mathbf{h} = q' \\mathbf{B}_k,</math>\n:<math>\\mathbf{s} = 2 \\mathbf{h}/(1 + h^2)</math>\nand <math>q' = \\Delta t \\times (q/2m)</math>.\n\nBecause of its excellent long term accuracy, the Boris algorithm is the de facto standard for advancing a charged particle.  It was realized that the excellent long term accuracy of nonrelativistic Boris algorithm is due to the fact it conserves phase space volume, even though it is not symplectic. The global bound on energy error typically associated with symplectic algorithms still holds for the Boris algorithm, making it an effective algorithm for the multi-scale dynamics of plasmas.  It has also been shown\n<ref>\n{{cite journal\n| author1=Higuera, Adam V.\n| author2=John R. Cary\n| title=Structure-preserving second-order integration of relativistic charged particle trajectories in electromagnetic fields\n| journal=Physics of Plasmas\n| volume=24\n| issue=5\n| year=2017\n| pages=052104\n| doi=10.1016/j.jcp.2003.11.004\n| bibcode=2004JCoPh.196..448N\n}}</ref>\nthat one can improve on the relativistic Boris push to make it both volume preserving and have a constant-velocity solution in crossed E and B fields.\n\n=== The field solver ===\n\nThe most commonly used methods for solving Maxwell's equations (or more generally, [[partial differential equation]]s (PDE)) belong to one of the following three categories:\n* [[Finite difference method]]s (FDM)\n* [[Finite element method]]s (FEM)\n* [[Spectral method]]s\n\nWith the FDM, the continuous domain is replaced with a discrete grid of points, on which the [[electric field|electric]] and [[magnetic field|magnetic]] fields are calculated. Derivatives are then approximated with differences between neighboring grid-point values and thus PDEs are turned into algebraic equations.\n\nUsing FEM, the continuous domain is divided into a discrete mesh of elements. The PDEs are treated as an [[eigenvalue, eigenvector and eigenspace|eigenvalue problem]] and initially a trial solution is calculated using [[basis function]]s that are localized in each element. The final solution is then obtained by optimization until the required accuracy is reached.\n\nAlso spectral methods, such as the [[fast Fourier transform]] (FFT), transform the PDEs into an eigenvalue problem, but this time the basis functions are high order and defined globally over the whole domain. The domain itself is not discretized in this case, it remains continuous. Again, a trial solution is found by inserting the basis functions into the eigenvalue equation and then optimized to determine the best values of the initial trial parameters.\n\n=== Particle and field weighting ===\n\nThe name \"particle-in-cell\" originates in the way that plasma macro-quantities ([[number density]], [[current density]], etc.) are assigned to simulation particles (i.e., the ''particle weighting''). Particles can be situated anywhere on the continuous domain, but macro-quantities are calculated only on the mesh points, just as the fields are. To obtain the macro-quantities, one assumes that the particles have a given \"shape\" determined by the shape function\n:<math>S(\\mathbf{x}-\\mathbf{X}),</math>\n\nwhere <math>\\mathbf{x}</math> is the coordinate of the particle and <math>\\mathbf{X}</math> the observation point. Perhaps the easiest and most used choice for the shape function is the so-called ''cloud-in-cell'' (CIC) scheme, which is a first order (linear) weighting scheme. Whatever the scheme is, the shape function has to satisfy the following conditions:\n<ref name=Fehske>{{cite book\n| last = Tskhakaya \n| first = David\n| editor1-last = Fehske\n| editor1-first = Holger\n| editor2-last = Schneider\n| editor2-first = Ralf\n| editor3-last = Weiße\n| editor3-first = Alexander\n| title = Computational Many-Particle Physics\n| volume = 739\n| series = Lecture Notes in Physics 739\n| year = 2008\n| publisher = Springer, Berlin Heidelberg\n| isbn = 978-3-540-74685-0\n| doi = 10.1007/978-3-540-74686-7\n| chapter = Chapter 6: The Particle-in-Cell Method\n| chapter-url = http://cds.cern.ch/record/1105877\n}}</ref>\nspace isotropy, charge conservation, and increasing accuracy (convergence) for higher-order terms.\n\nThe fields obtained from the field solver are determined only on the grid points and can't be used directly in the particle mover to calculate the force acting on particles, but have to be interpolated via the ''field weighting'':\n:<math>\\mathbf{E}(\\mathbf{x}) = \\sum_{i}\\mathbf{E}_i S(\\mathbf{x}_i-\\mathbf{x}),</math>\n\nwhere the subscript <math>i</math> labels the grid point. To ensure that the forces acting on particles are self-consistently obtained, the way of calculating macro-quantities from particle positions on the grid points and interpolating fields from grid points to particle positions has to be consistent, too, since they both appear in [[Maxwell's equations]]. Above all, the field interpolation scheme should conserve [[momentum]]. This can be achieved by choosing the same weighting scheme for particles and fields and by ensuring the appropriate space symmetry (i.e. no self-force and fulfilling the [[Newton's laws of motion|action-reaction law]]) of the field solver at the same time<ref name=\"Fehske\"/>\n\n=== Collisions ===\n\nAs the field solver is required to be free of self-forces, inside a cell the field generated by a particle must decrease with decreasing distance from the particle, and hence inter-particle forces inside the cells are underestimated. This can be balanced with the aid of [[Coulomb collision]]s between charged particles. Simulating the interaction for every pair of a big system would be computationally too expensive, so several [[Monte Carlo method]]s have been developed instead. A widely used method is the ''binary collision model'',<ref>{{Cite journal \n | last1 = Takizuka\n | first1 = Tomonor\n | last2 = Abe\n | first2 = Hirotada\n | title = A binary collision model for plasma simulation with a particle code\n | journal = Journal of Computational Physics\n | volume = 25\n | issue = 3\n | year = 1977\n | pages = 205&ndash;219\n | doi = 10.1016/0021-9991(77)90099-7\n|bibcode = 1977JCoPh..25..205T }}</ref> in which particles are grouped according to their cell, then these particles are paired randomly, and finally the pairs are collided.\n\nIn a real plasma, many other reactions may play a role, ranging from elastic collisions, such as collisions between charged and neutral particles, over inelastic collisions, such as electron-neutral ionization collision, to chemical reactions; each of them requiring separate treatment. Most of the collision models handling charged-neutral collisions use either the ''direct Monte-Carlo'' scheme, in which all particles carry information about their collision probability, or the ''null-collision'' scheme,<ref>{{Cite journal \n | author = Birdsall, C.K.\n | title = Particle-in-cell charged-particle simulations, plus Monte Carlo collisions with neutral atoms, PIC-MCC \n | journal = IEEE Transactions on Plasma Science\n | volume = 19\n | issue = 2\n | year = 1991\n | pages = 65&ndash;85\n | doi = 10.1109/27.106800\n | issn = 0093-3813\n|bibcode = 1991ITPS...19...65B }}</ref><ref>{{Cite journal \n | last1 = Vahedi\n | first1 = V.\n | last2 = Surendra\n | first2 = M.\n | title = A Monte Carlo collision model for the particle-in-cell method: applications to argon and oxygen discharges\n | journal = Computer Physics Communications\n | volume = 87\n | issue = 1&ndash;2\n | year = 1995\n | pages = 179&ndash;198\n | doi = 10.1016/0010-4655(94)00171-W\n | issn = 0010-4655\n|bibcode = 1995CoPhC..87..179V | url = https://zenodo.org/record/1253854\n }}</ref> which does not analyze all particles but uses the maximum collision probability for each charged species instead.\n\n=== Accuracy and stability conditions ===\n\nAs in every simulation method, also in PIC, the time step and the grid size must be well chosen, so that the time and length scale phenomena of interest are properly resolved in the problem. In addition, time step and grid size affect the speed and accuracy of the code.\n\nFor an electrostatic plasma simulation using an explicit time integration scheme (e.g. leapfrog, which is most commonly used), two important conditions regarding the grid size <math>\\Delta x</math> and the time step <math>\\Delta t</math> should be fulfilled in order to ensure the stability of the solution:\n:<math>\\Delta x < 3.4 \\lambda_D,</math>\n:<math>\\Delta t \\leq 2 \\omega_{pe}^{-1},</math>\n\nwhich can be derived considering the harmonic oscillations of a one-dimensional unmagnetized plasma. The latter conditions is strictly required but practical considerations related to energy conservation suggest to use a much stricter constraint where the factor 2 is replaced by a number one order of magnitude smaller. The use of <math>\\Delta t \\leq 0.1 \\omega_{pe}^{-1},</math> is typical.<ref name=Fehske/><ref>{{Cite journal \n | last1 = Tskhakaya\n | first1 = D.\n | last2 = Matyash\n | first2 = K.\n | last3 = Schneider\n | first3 = R.\n | last4 = Taccogna\n | first4 = F.\n | title = The Particle-In-Cell Method\n | journal = Contributions to Plasma Physics\n | volume = 47 \n | issue = 8–9\n | year = 2007\n | pages = 563&ndash;594\n | doi = 10.1002/ctpp.200710072\n|bibcode = 2007CoPP...47..563T }}</ref> Not surprisingly, the natural time scale in the plasma is given by the inverse [[plasma oscillation|plasma frequency]] <math>\\omega_{pe}^{-1}</math> and length scale by the [[Debye length]] <math>\\lambda_D</math>.\n\nFor an explicit electromagnetic plasma simulation, the time step must also satisfy the [[Courant–Friedrichs–Lewy condition|CFL condition]]:\n:<math>\\Delta t < \\Delta x / c ,</math>\nwhere <math>\\Delta x \\sim \\lambda_D</math>, and <math> c</math> is the speed of light.\n\n== Applications ==\n\nWithin plasma physics, PIC simulation has been used successfully to study laser-plasma interactions, electron acceleration and ion heating in the auroral [[ionosphere]], [[magnetohydrodynamics]], [[magnetic reconnection]], as well as ion-temperature-gradient and other microinstabilities in [[tokamak]]s, furthermore [[vacuum arc|vacuum discharges]], and [[dusty plasma]]s.\n\nHybrid models may use the PIC method for the kinetic treatment of some species, while other species (that are [[Maxwell–Boltzmann distribution|Maxwellian]]) are simulated with a fluid model.\n\nPIC simulations have also been applied outside of plasma physics to problems in [[solid mechanics|solid]] and [[fluid mechanics]].\n<ref>{{cite book \n  | last1 = Liu\n  | first1 = G.R. \n  | author2 = M.B. Liu \n  | title =  Smoothed Particle Hydrodynamics: A Meshfree Particle Method\n  | publisher = World Scientific \n  | year = 2003\n  | isbn = 981-238-456-1}}\n</ref>\n<ref>{{Cite journal \n | author1 = Byrne, F. N.\n | author2 = Ellison, M. A. \n | author3 = Reid, J. H.\n | title = The particle-in-cell computing method for fluid dynamics\n | journal = Methods Comput. Phys.\n | volume = 3\n | year = 1964 \n | issue = 3\n | pages = 319&ndash;343 \n | doi = 10.1007/BF00230516 \n | bibcode = 1964SSRv....3..319B\n | id = \n }}</ref>\n\n==Electromagnetic particle-in-cell computational applications==\n{| class=\"wikitable\"\n|-\n! Computational application\n! Web site\n! License\n! Availability\n! Canonical Reference\n|-\n| SHARP\n| <ref name=\":0\">{{cite journal|title=SHARP: A Spatially Higher-order, Relativistic Particle-in-Cell Code|first1=Mohamad|last1=Shalaby|first2=Avery E.|last2=Broderick|first3=Philip|last3=Chang|first4=Christoph|last4=Pfrommer|first5=Astrid|last5=Lamberts|first6=Ewald|last6=Puchwein|date=23 May 2017|journal=The Astrophysical Journal|volume=841|issue=1|pages=52|doi=10.3847/1538-4357/aa6d13|arxiv=1702.04732|bibcode=2017ApJ...841...52S}}</ref>\n| Proprietary \n|\n| {{doi|10.3847/1538-4357/aa6d13}}\n|-\n| ALaDyn\n| <ref>{{cite web|url=https://aladyn.github.io/ALaDyn/|title=ALaDyn|website=ALaDyn|accessdate=1 December 2017}}</ref>\n| GPLv3+\n| Open Repo:<ref>{{cite web|url=https://github.com/ALaDyn/ALaDyn|title=ALaDyn: A High-Accuracy PIC Code for the Maxwell-Vlasov Equations|date=18 November 2017|accessdate=1 December 2017|website=GitHub.com}}</ref>\n| {{doi|10.5281/zenodo.49553}}\n|-\n| EPOCH\n| <ref>{{cite web|url=http://www.ccpp.ac.uk/codes.html|title=Codes|website=Ccpp.ac.uk|accessdate=1 December 2017}}</ref>\n| GPL\n| Open to academic users but signup required :<ref>{{cite web|url=https://cfsa-pmw.warwick.ac.uk|title=Sign in|website=GitLab|accessdate=1 December 2017}}</ref>\n| {{doi|10.1088/0741-3335/57/11/113001}}\n|-\n| FBPIC\n| <ref>{{cite web|url=https://fbpic.github.io/|title=FBPIC documentation — FBPIC 0.6.0 documentation|website=fbpic.github.io|accessdate=1 December 2017}}</ref>\n| 3-Clause-BSD-LBNL\n| Open Repo:<ref>{{cite web|url=https://github.com/fbpic/fbpic|title=fbpic: Spectral, quasi-3D Particle-In-Cell code, for CPU and GPU|date=8 November 2017|accessdate=1 December 2017|website=GitHub.com}}</ref>\n| {{doi|10.1016/j.cpc.2016.02.007}}\n|-\n| LSP\n| <ref>{{cite web|url=http://www.mrcwdc.com/lsp|title=Orbital ATK|website=Mrcwdc.com|accessdate=1 December 2017}}</ref>\n| Proprietary \n| Available from ATK\n| {{doi|10.1016/S0168-9002(01)00024-9}}\n|-\n| MAGIC\n| <ref>{{cite web|url=http://www.mrcwdc.com/magic|title=Orbital ATK|website=Mrcwdc.com|accessdate=1 December 2017}}</ref>\n| Proprietary\n| Available from ATK\n| {{doi|10.1016/0010-4655(95)00010-D}}\n|-\n| OSIRIS\n| <ref>{{cite web|url=http://picksc.idre.ucla.edu/software/software-production-codes/osiris|title=OSIRIS - PICKSC|website=Picksc.idre.ucla.edu|accessdate=1 December 2017}}</ref>\n| Proprietary\n| Closed (Collaborators)\n| {{doi|10.1007/3-540-47789-6_36}}\n|-\n| PICCANTE\n| <ref>{{cite web|url=https://aladyn.github.io/piccante/|title=Piccante|website=Aladyn.github.io|accessdate=1 December 2017}}</ref>\n| GPLv3+\n| Open Repo:<ref>{{cite web|url=https://github.com/ALaDyn/piccante|title=piccante: a spicy massively parallel fully-relativistic electromagnetic 3D particle-in-cell code|date=14 November 2017|accessdate=1 December 2017|website=GitHub.com}}</ref>\n| {{doi|10.5281/zenodo.48703}}\n|-\n| PICLas\n| <ref>{{cite web|url=http://www.irs.uni-stuttgart.de/forschung/numerische_modellierung_und_simulation/PICLas.en.html|title=PICLas}}</ref>\n| Proprietary\n| Available from [http://www.irs.uni-stuttgart.de/forschung/numerische_modellierung_und_simulation/PICLas.en.html Institute of Space Systems] and [https://nrg.iag.uni-stuttgart.de/ Institute of Aerodynamics and Gas Dynamics] at the University of Stuttgart\n| {{doi|10.1016/j.crme.2014.07.005}}\n|-\n| PIConGPU\n| <ref>{{cite web|url=http://picongpu.hzdr.de/|title=PIConGPU - A Many-GPGPU Particle-in-Cell Code - Helmholtz-Zentrum Dresden-Rossendorf, HZDR|website=picongpu.hzdr.de|accessdate=1 December 2017}}</ref>\n| GPLv3+\n| Open Repo:<ref>{{cite web|url=https://github.com/ComputationalRadiationPhysics/picongpu|title=picongpu: A particle-in-cell code for GPGPUs :sparkles|date=28 November 2017|accessdate=1 December 2017|website=GitHub.com}}</ref>\n| {{doi|10.1145/2503210.2504564}}\n|-\n| SMILEI\n| <ref>{{cite web|url=http://www.maisondelasimulation.fr/smilei/|title=Home — Smilei v3.3-32-g0d0bd90 documentation|website=Maisondelasimulation.fr|accessdate=1 December 2017}}</ref>\n| CeCILL (equivalent GPL)\n| Open source. Available from [http://www.maisondelasimulation.fr/projects/Smilei/html/index.html Smilei website]\n| {{doi|10.1016/j.cpc.2017.09.024}}\n|-\n| The Virtual Laser Plasma Library\n| <ref>{{cite web|url=http://www2.mpq.mpg.de/lpg/research/RelLasPlas/Rel-Las-Plas.html|title=Relativistic Laser Plasma|first=Matthias|last=Dreher|website=2.mpq.mpg.de|accessdate=1 December 2017}}</ref>\n| Proprietary\n| Unknown\n| {{doi|10.1017/S0022377899007515}}\n|-\n| VizGrain\n| <ref>{{cite web|url=http://esgeetech.com/products/vizgrain-particle-modeling/|title=VizGrain|website=esgeetech.com|accessdate=1 December 2017}}</ref>\n| Proprietary\n| Commercially available from Esgee Technologies Inc.\n| \n|-\n| VSim (Vorpal)\n| <ref>{{cite web|url=https://txcorp.com/vsim|title=Tech-X - VSim|website=Txcorp.com|accessdate=1 December 2017}}</ref>\n| Proprietary\n| Available from Tech-X Corporation\n| {{doi|10.1016/j.jcp.2003.11.004}}\n|-\n| WARP\n| <ref>{{cite web|url=http://warp.lbl.gov/|title=Warp|website=warp.lbl.gov|accessdate=1 December 2017}}</ref>\n| 3-Clause-BSD-LBNL\n| Open Repo:<ref>{{cite web|url=https://bitbucket.org/berkeleylab/warp|title=berkeleylab / Warp — Bitbucket|website=bitbucket.org|accessdate=1 December 2017}}</ref>\n| {{doi|10.1063/1.860024}}\n|}\n\n==See also==\n* [[Plasma modeling]]\n* [[Multiphase particle-in-cell method]]\n\n==References==\n{{Reflist}}\n\n==Bibliography==\n* {{cite book\n  | last1 = Birdsall\n  | first1 = Charles K. \n  | author2 = A. Bruce Langdon \n  | title = Plasma Physics via Computer Simulation \n  | publisher = McGraw-Hill \n  | year = 1985\n  | isbn = 0-07-005371-5}}\n\n* {{cite book\n  | last1 = Hockney\n  | first1 = Roger W.\n  | author2 = James W. Eastwood\n  | title = Computer Simulation Using Particles \n  | publisher = CRC Press \n  | year = 1988\n  | isbn =0-85274-392-0}}\n\n==External links==\n* [http://picksc.idre.ucla.edu Particle-In-Cell and Kinetic Simulation Software Center (PICKSC), UCLA.]\n* [http://dev.spis.org/projects/spine/home/picup Open source 3D Particle-In-Cell code for spacecraft plasma interactions (mandatory user registration required).]\n* [http://www.particleincell.com/2011/particle-in-cell-example/ Simple Particle-In-Cell code in MATLAB]\n* [https://web.archive.org/web/19970110233436/http://ptsg.eecs.berkeley.edu/ Plasma Theory and Simulation Group (Berkeley)] Contains links to freely available software.\n* [http://farside.ph.utexas.edu/teaching/329/lectures/node96.html Introduction to PIC codes (Univ. of Texas)]\n* [https://github.com/dozzes/open-pic open-pic - 3D Hybrid Particle-In-Cell simulation of plasma dynamics]\n\n{{Numerical PDE}}\n\n{{DEFAULTSORT:Particle-In-Cell}}\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]\n[[Category:Scientific modeling]]"
    },
    {
      "title": "Perfectly matched layer",
      "url": "https://en.wikipedia.org/wiki/Perfectly_matched_layer",
      "text": "A '''perfectly matched layer''' ('''PML''') is an artificial absorbing layer for [[wave equation]]s, commonly used to truncate computational regions in [[numerical method]]s to simulate problems with open boundaries, especially in the [[Finite-difference time-domain method|FDTD]] and [[finite element method|FE]] methods.<ref name=Taflove05>{{cite book | author=[[Allen Taflove]] and Susan C. Hagness | title=Computational Electrodynamics: The Finite-Difference Time-Domain Method, 3rd ed. | publisher=Artech House Publishers | year=2005 | isbn=978-1-58053-832-9 }}</ref><ref>S. G. Johnson, [http://math.mit.edu/~stevenj/18.369/pml.pdf Notes on Perfectly Matched Layers], online MIT course notes (Aug. 2007).</ref>  The key property of a PML that distinguishes it from an ordinary absorbing material is that it is designed so that waves incident upon the PML from a non-PML medium do not reflect at the interface—this property allows the PML to strongly absorb outgoing waves from the interior of a computational region without reflecting them back into the interior.\n\nPML was originally formulated by Berenger in 1994<ref>{{cite journal | author= J. Berenger | title= A perfectly matched layer for the absorption of electromagnetic waves | journal= Journal of Computational Physics | year= 1994 | volume= 114 | pages= 185&ndash;200 | doi= 10.1006/jcph.1994.1159 | issue= 2 | bibcode=1994JCoPh.114..185B}}</ref> for use with [[Maxwell's equations]], and since that time there have been several related reformulations of PML for both Maxwell's equations and for other wave-type equations, such as elastodynamics,<ref>{{cite journal |first1=Arash |last1=Fathi |first2=Babak |last2=Poursartip |first3=Loukas |last3=Kallivokas |title=Time‐domain hybrid formulations for wave simulations in three‐dimensional PML‐truncated heterogeneous media |journal=International Journal for Numerical Methods in Engineering |year=2015 |volume=101 |issue=3 |pages=165–198 |doi=10.1002/nme.4780|bibcode=2015IJNME.101..165F }}</ref> the linearized Euler equations, Helmholtz equations, and poroelasticity. Berenger's original formulation is called a '''split-field PML''', because it splits the [[electromagnetic field]]s into two unphysical fields in the PML region.  A later formulation that has become more popular because of its simplicity and efficiency is called '''uniaxial PML''' or '''UPML''',<ref>{{cite journal | author= S.D. Gedney | title= An anisotropic perfectly matched layer absorbing media for the truncation of FDTD latices| journal= IEEE Transactions on  Antennas and Propagation| year= 1996 | volume= 44 | pages= 1630&ndash;1639 | doi= 10.1109/8.546249 | issue= 12 | bibcode=1996ITAP...44.1630G}}</ref> in which the PML is described as an artificial [[birefringence|anisotropic]] absorbing material.  Although both Berenger's formulation and UPML were initially derived by manually constructing the conditions under which incident [[plane wave]]s do not reflect from the PML interface from a homogeneous medium, ''both'' formulations were later shown to be equivalent to a much more elegant and general approach: '''stretched-coordinate PML'''.<ref>{{cite journal | author= W. C. Chew and W. H. Weedon | title= A 3d perfectly matched medium from modified Maxwell's equations with stretched coordinates| journal= Microwave Optical Tech. Letters | year= 1994 | volume= 7 | pages= 599&ndash;604 | doi= 10.1002/mop.4650071304 | issue= 13 }}</ref><ref>{{cite journal | author= F. L. Teixeira W. C. Chew | title= General closed-form PML constitutive tensors to match arbitrary bianisotropic and dispersive linear media| journal= IEEE Microwave and Guided Wave Letters | year= 1998 | volume= 8 | pages= 223&ndash;225 | doi= 10.1109/75.678571 | issue= 6 }}</ref>  In particular, PMLs were shown to correspond to a [[coordinate transformation]] in which one (or more) coordinates are mapped to [[complex number]]s; more technically, this is actually an [[analytic continuation]] of the wave equation into complex coordinates, replacing propagating (oscillating) waves by [[exponentially decaying]] waves.  This viewpoint allows PMLs to be derived for inhomogeneous media such as [[waveguide]]s, as well as for other [[coordinate system]]s and wave equations.<ref>{{cite journal | author= V. Kalvin | title=Limiting absorption principle and perfectly matched layer method for Dirichlet Laplacian in quasi-cylindrical domains| journal=SIAM J. Math. Anal. | year= 2012 | volume= 44 | pages= 355&ndash;382 | doi= 10.1137/110834287  | arxiv=1110.4912}}</ref><ref>{{cite journal | author= V. Kalvin | title=Analysis of perfectly matched layer operators for acoustic scattering on manifolds with quasicylindrical ends| journal= J. Math. Pures Appl. | year= 2013 | volume=100  | issue=2| pages= 204&ndash;219 | doi= 10.1016/j.matpur.2012.12.001| arxiv=1212.5707}}</ref>\n\n==Technical description==\n\nSpecifically, for a PML designed to absorb waves propagating in the ''x'' direction, the following transformation is included in the wave equation.  Wherever an ''x'' derivative <math>\\partial/\\partial x</math> appears in the wave equation, it is replaced by:\n:<math>\\frac{\\partial}{\\partial x} \\to \\frac{1}{1 + \\frac{i\\sigma(x)}{\\omega}} \\frac{\\partial}{\\partial x}</math>\nwhere <math>\\omega</math> is the [[angular frequency]] and <math>\\sigma</math> is some [[function (mathematics)|function]] of ''x''.  Wherever <math>\\sigma</math> is positive, propagating waves are attenuated because:\n:<math>e^{i(kx - \\omega t)} \\to e^{i(kx - \\omega t) -  \\frac{k}{\\omega} \\int^x \\sigma(x') dx'} ,</math>\nwhere we have taken a planewave propagating in the +''x'' direction (for <math>k > 0</math>) and applied the transformation (analytic continuation) to complex coordinates: <math>x \\to x + \\frac{i}{\\omega} \\int^x \\sigma(x') dx'</math>, or equivalently <math>dx \\to dx (1 + i\\sigma/\\omega)</math>.  The same coordinate transformation causes waves to attenuate whenever their ''x'' dependence is in the form <math>e^{ikx}</math> for some [[propagation constant]] ''k'': this includes planewaves propagating at some angle with the ''x'' axis and also [[transverse mode]]s of a waveguide.\n\nThe above coordinate transformation can be left as-is in the transformed wave equations, or can be combined with the material description (e.g. the [[permittivity]] and [[Permeability (electromagnetism)|permeability]] in Maxwell's equations) to form a UPML description.  Note also that the coefficient &sigma;/&omega; depends upon frequency&mdash;this is so the attenuation rate is proportional to ''k''/&omega;, which is independent of frequency in a homogeneous material (not including [[material dispersion]], e.g. for [[vacuum]]) because of the [[dispersion relation]] between &omega; and ''k''.  However, this frequency-dependence means that a [[time domain]] implementation of PML, e.g. in the [[FDTD]] method, is more complicated than for a frequency-independent absorber, and involves the [[auxiliary differential equation]] (ADE) approach (equivalently, ''i''/&omega; appears as an [[integral]] or [[convolution]] in time domain).\n\nPerfectly matched layers, in their original form, only attenuate propagating waves; purely [[evanescent waves]] (exponentially decaying fields) oscillate in the PML but do not decay more quickly.  However, the attenuation of evanescent waves can also be  accelerated by including a [[real number|real]] coordinate stretching in the PML: this corresponds to making &sigma; in the above expression a [[complex number]], where the imaginary part yields a real coordinate stretching that causes evanescent waves to decay more quickly.\n\n==Limitations of perfectly matched layers==\nPML is widely used and has become the absorbing boundary technique of choice in much of computational electromagnetism.<ref name=Taflove05/>  Although it works well in most cases, there are a few important cases in which it breaks down, suffering from unavoidable reflections or even exponential growth.\n\nOne caveat with perfectly matched layers is that they are only reflectionless for the ''exact'', continuous wave equation.  Once the wave equation is [[discretization|discretized]] for simulation on a computer, some small numerical reflections appear (which vanish with increasing resolution).  For this reason, the PML absorption coefficient &sigma; is typically turned on gradually from zero (e.g. [[quadratic function|quadratically]]) over a short distance on the scale of the [[wavelength]] of the wave.<ref name=Taflove05/> In general, any absorber, whether PML or not, is reflectionless in the limit where it turns on sufficiently gradually (and the absorbing layer becomes thicker), but in a discretized system the benefit of PML is to reduce the finite-thickness \"transition\" reflection by many orders of magnitude compared to a simple isotropic absorption coefficient.<ref name=Oskooi08/>\n\nIn certain materials, there are \"backward-wave\" solutions in which [[Group velocity|group]] and [[phase velocity]] are opposite to one another.  This occurs in \"left-handed\" [[negative index metamaterials]] for electromagnetism and also for acoustic waves in certain solid materials, and in these cases the standard PML formulation is unstable: it leads to exponential growth rather than decay, simply because the sign of ''k'' is flipped in the analysis above.<ref>{{cite journal | author= E. Bécache, S. Fauqueux and P. Joly| title= Stability of perfectly matched layers, group velocities and anisotropic waves| journal= Journal of Computational Physics | year= 2003 | volume= 188 | pages= 399&ndash;433| doi=10.1016/S0021-9991(03)00184-0 | issue= 2| bibcode= 2003JCoPh.188..399B}} [http://hal.archives-ouvertes.fr/docs/00/07/22/83/PDF/RR-4304.pdf]</ref>  Fortunately, there is a simple solution in a left-handed medium (for which all waves are backwards): merely flip the sign of &sigma;.  A complication, however, is that physical left-handed materials are [[Dispersion (optics)|dispersive]]: they are only left-handed within a certain frequency range, and therefore the &sigma; coefficient must be made frequency-dependent.<ref>Steven A. Cummer, \"Perfectly Matched Layer Behavior in Negative Refractive Index Materials,\" ''IEEE Ant. Wireless Prop. Lett'' '''3''', 172–175 (2004).</ref><ref>X. T. Dong, X. S. Rao, Y. B. Gan, B. Guo, and W.-Y. Yin, \"Perfectly matched layer-absorbing boundary condition for left-handed materials,\" ''IEEE Microwave Wireless Components Lett.'' '''14''', 301-333 (2004).</ref>  Unfortunately, even without exotic materials, one can design certain waveguiding structures (such as a hollow metal tube with a high-index cylinder in its center) that exhibit ''both'' backwards- and forwards-wave solutions at the same frequency, such that any sign choice for &sigma; will lead to exponential growth, and in such cases PML appears to be irrecoverably unstable.<ref>P.-R. Loh, A. F. Oskooi, M. Ibanescu, M. Skorobogatiy, and S. G. Johnson,  \"[http://math.mit.edu/~stevenj/papers/LohOs09.pdf Fundamental relation between phase and group velocity, and application to the failure of perfectly matched layers in backward-wave structures],\" ''Phys. Rev. E'' '''79''' 065601(R) (2009).</ref>\n\nAnother important limitation of PML is that it requires that the medium be invariant in the direction orthogonal to the boundary, in order to support the analytic continuation of the solution to complex coordinates (the complex \"coordinate stretching\").   As a consequence, the PML approach is no longer valid (no longer reflectionless at infinite resolution) in the case of periodic media (e.g. [[photonic crystal]]s or [[Acoustic metamaterials|phononic crystals]])<ref name=Oskooi08>A. F. Oskooi, L. Zhang, Y. Avniel, and S. G. Johnson, [http://www.opticsinfobase.org/oe/abstract.cfm?uri=oe-16-15-11376 The failure of perfectly matched layers, and towards their redemption by adiabatic absorbers], ''Optics Express'' '''16''', 11376–11392 (2008).</ref> or even simply a waveguide that enters the boundary at an oblique angle.<ref>A. Oskooi and S. G. Johnson, \"[http://math.mit.edu/~stevenj/papers/OskooiJo11.pdf Distinguishing correct from incorrect PML proposals and a corrected unsplit PML for anisotropic, dispersive media],\" ''Journal of Computational Physics'', vol. 230, pp. 2369–2377 (2011).</ref>\n\n== See also ==\n*[http://emlab.utep.edu/ee5390cem.htm Notes and recorded lecture on the perfectly matched layer (see lecture 8)]\n*[[Cagniard–de Hoop method]]\n\n== References ==\n<references/>\n\n==External links==\n*[https://www.youtube.com/watch?v=XcL9iEK0GDY Animation on the effects of PML (YouTube)]\n\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]\n[[Category:Wave mechanics]]\n[[Category:Computational electromagnetics]]"
    },
    {
      "title": "Quantized state systems method",
      "url": "https://en.wikipedia.org/wiki/Quantized_state_systems_method",
      "text": "The '''quantized state systems (QSS) methods''' are a family of numerical integration solvers based on the idea of state quantization, [[dual (mathematics)|dual]] to the traditional idea of time discretization.\nUnlike traditional [[numerical methods for ordinary differential equations|numerical solution methods]], which approach the problem by [[Discretization|discretizing]] time and solving for the next (real-valued) state at each successive time step, QSS methods keep time as a continuous entity and instead [[Quantization (signal processing)|quantize]] the system's state, instead solving for the ''time'' at which the state deviates from its quantized value by a ''quantum''.\n\nThey can also have many advantages compared to classical algorithms.<ref>{{cite journal |authors=Migoni, Gustavo, Ernesto Kofman, and François Cellier |title=Quantization-based new integration methods for stiff ordinary differential equations|year=2011 |journal = Simulation |pages=387&ndash;407 |url=http://sim.sagepub.com/content/88/4/387 }}</ref>\nThey inherently allow for modeling discontinuities in the system due to their discrete-event nature and asynchronous nature. They also allow for explicit root-finding and detection of zero-crossing using ''explicit'' algorithms, avoiding the need for iteration---a fact which is especially important in the case of stiff systems, where traditional time-stepping methods require a heavy computational penalty due to the requirement to implicitly solve for the next system state. Finally, QSS methods satisfy remarkable global stability and error bounds, described below, which are not satisfied by classical solution techniques.\n\nBy their nature, QSS methods are therefore neatly modeled by the [[DEVS]] formalism, a [[discrete event simulation|discrete-event]] [[model of computation]], in contrast with traditional methods, which form [[Discrete time and continuous time#Discrete time|discrete-time]] models of the [[Discrete time and continuous time#Continuous time|continuous-time]] system. They have therefore been implemented in [[PowerDEVS#References|[PowerDEVS]]], a simulation engine for such discrete-event systems.\n\n==Theoretical properties==\n\nIn 2001, Ernesto Kofman proved<ref>{{cite journal | last=Kofman | first=Ernesto |title=A second-order approximation for DEVS simulation of continuous systems|year=2002 |journal = Simulation |volume=78 |pages=76&ndash;89 |url=http://sim.sagepub.com/content/78/2/76.short }}</ref> a remarkable property of the quantized-state system simulation method: namely, that when the technique is used to solve a [[Exponential stability|stable]] [[LTI system theory|linear time-invariant (LTI) system]], the global error is bounded by a constant that is proportional to the quantum, but (crucially) independent of the duration of the simulation. More specifically, for a stable multidimensional LTI system with the [[state-transition matrix]] <math>A</math> and [[State-space representation#Linear systems|input matrix]] <math>B</math>, it was shown in [CK06] that the absolute error vector <math>\\vec{e}(t)</math> is bounded above by\n\n:<math>\n\\left| \\vec{e}(t) \\right| \\leq\n\\left| V \\right|\\ \\left| \\Re\\left(\\Lambda\\right)^{-1} \\Lambda \\right|\\ \\left| V^{-1} \\right|\\ \\Delta\\vec{Q} +\n\\left| V \\right|\\ \\left| \\Re\\left(\\Lambda\\right)^{-1} V^{-1} B \\right|\\ \\Delta\\vec{u}</math>\n\nwhere <math>\\Delta\\vec{Q}</math> is the vector of state quanta, <math>\\Delta\\vec{u}</math> is the vector with quanta adopted in the input signals, <math>V \\Lambda V^{-1} = A</math> is the [[Eigendecomposition#Eigendecomposition of a matrix|eigendecomposition]] or [[Jordan canonical form]] of <math>A</math>, and <math>\\left|\\,\\cdot\\,\\right|</math> denotes the element-wise [[absolute value]] operator (not to be confused with the [[determinant]] or [[Norm (mathematics)|norm]]).\n\nIt is worth noticing that this remarkable error bound comes at a price: the global error for a stable LTI system is also, in a sense, bounded ''below'' by the quantum itself, at least for the first-order QSS1 method. This is because, unless the approximation happens to coincide ''exactly'' with the correct value (an event which will [[almost surely]] not happen), it will simply continue oscillating around the equilibrium, as the state is always (by definition) guaranteed to change by exactly one quantum outside of the equilibrium. Avoiding this condition would require finding a reliable technique for dynamically lowering the quantum in a manner analogous to [[adaptive stepsize]] methods in traditional discrete time simulation algorithms.\n\n==First-order QSS method – QSS1==\nLet an [[initial value problem]] be specified as follows.\n\n:<math> \\dot{x}(t) = f(x(t), t), \\quad x(t_0) = x_0. </math>\n\nThe first-order QSS method, known as QSS1, approximates the above system by\n\n:<math> \\dot{x}(t) = f(q(t), t), \\quad q(t_0) = x_0. </math>\n\nwhere <math>x</math> and <math>q</math> are related by a ''[[Hysteresis|hysteretic]] quantization function''\n\n:<math>q(t) = \\begin{cases}x(t) & \\text{if } \\left|x(t) - q(t^{-})\\right| \\geq \\Delta Q \\\\ q(t^{-}) & \\text{otherwise}\\end{cases}</math>\n\nwhere <math>\\Delta Q</math> is called a ''quantum''. Notice that this quantization function is '''hysteretic''' because it has ''memory'': not only is its output a function of the current state <math>x(t)</math>, but it also depends on its old value, <math>q(t^{-})</math>.\n\nThis formulation therefore approximates the state by a piecewise constant function, <math>q(t)</math>, that updates its value as soon as the state deviates from this approximation by one quantum.\n\nThe [[Multidimensional system|multidimensional]] formulation of this system is almost the same as the single-dimensional formulation above: the <math>k^\\text{th}</math> quantized state <math>q_k(t)</math> is a function of its corresponding state, <math>x_k(t)</math>, and the state vector <math>\\vec{x}(t)</math> is a function of the entire quantized state vector, <math>\\vec{q}(t)</math>:\n\n:<math>\\vec{x}(t) = f(\\vec{q}(t), t)</math>\n\n==High-order QSS methods – QSS2 and QSS3==\n\nThe second-order QSS method, QSS2, follows the same principle as QSS1, except that it defines <math>q(t)</math> as a [[piecewise linear function|piecewise linear]] approximation of the trajectory <math>x(t)</math> that updates its trajectory as soon as the two differ from each other by one quantum.\nThe pattern continues for higher-order approximations, which define the quantized state <math>q(t)</math> as successively higher-order polynomial approximations of the system's state.\n\nIt is important to note that, while in principle a QSS method of arbitrary order can be used to model a continuous-time system, it is seldom desirable to use methods of order higher than four, as the [[Abel–Ruffini theorem]] implies that the time of the next quantization, <math>t</math>, cannot (in general) be [[Explicit and implicit methods|explicitly solved]] for [[algebraic solution|algebraically]] when the polynomial approximation is of degree greater than four, and hence must be approximated iteratively using a [[root-finding algorithm]]. In practice, QSS2 or QSS3 proves sufficient for many problems and the use of higher-order methods results in little, if any, additional benefit.\n\n==Backward QSS method – BQSS==\n\n{{Empty section|date=May 2013}}\n\n==Linearly implicit QSS method – LIQSS==\n\n{{Empty section|date=May 2013}}\n\n==Software implementation==\nThe QSS Methods can be implemented as a discrete event system  and simulated in any [[DEVS]] simulator.\n\nQSS methods constitute the main numerical solver for  [[PowerDEVS]][[PowerDEVS#References|[BK011]]] software.\nThey have also been implemented in as a stand-alone version.\n\n== References ==\n{{Reflist}}\n* [CK06] {{cite book|author1=Francois E. Cellier  |author2=Ernesto Kofman |lastauthoramp=yes | year = 2006| title = Continuous System Simulation| publisher = Springer| isbn = 978-0-387-26102-7 |edition=first}}\n* [BK11] {{cite news|author1=Bergero, Federico  |author2=Kofman, Ernesto  |lastauthoramp=yes | year = 2011| title = PowerDEVS: a tool for hybrid system modeling and real-time simulation| publisher = Society for Computer Simulation International,San Diego  | id = |edition=first}}\n\n==External links==\n*[https://sourceforge.net/projects/qssengine/ Stand-alone implementation of QSS Methods]\n*[https://sourceforge.net/projects/powerdevs/ PowerDEVS at SourceForge]\n\n{{Numerical integrators}}\n\n{{DEFAULTSORT:Quantized State System Methods}}\n[[Category:Numerical differential equations]]"
    },
    {
      "title": "Raviart–Thomas basis functions",
      "url": "https://en.wikipedia.org/wiki/Raviart%E2%80%93Thomas_basis_functions",
      "text": "In applied mathematics, '''Raviart–Thomas basis functions''' are [[vector function|vector]] [[basis function]]s used in [[finite element method|finite element]] and [[boundary element method]]s. They are regularly used as basis functions when working in [[electromagnetics]]. They are sometimes called '''Rao-Wilton-Glisson basis functions'''.<ref>{{cite journal|last=Andriulli|first=Francesco P. |author2=Cools |author3=Bagci |author4=Olyslager |author5=Buffa |author6=Christiansen |author7=Michelssen |date=2008|title=A Mulitiplicative Calderon Preconditioner for the Electric Field Integral Equation|journal=IEEE Transactions on Antennas and Propagation|volume=56|issue=8|pages=2398–2412|doi=10.1109/tap.2008.926788}}</ref>\n\nThe [[function space|space]] <math>\\mathrm{RT}_q</math> spanned by the Raviart–Thomas basis functions of order <math>q</math> is the smallest polynomial space such that the [[divergence]] maps <math>\\mathrm{RT}_q</math> onto <math>\\mathrm{P}_q</math>, the space of piecewise polynomials of order <math>q</math>.<ref>{{cite web|url=http://www.logg.org/anders/pub/papers/KirbyLoggEtAl2012a.pdf|title=Common and Unusual Finite Elements|last=Kirby|first=Robert C. |author2=Anders Logg |author3=Andy R . Terrel |date=2010|accessdate=2 October 2015}}</ref>\n\n==Order 0 Raviart-Thomas Basis Functions in 2D==\n[[File:raviart_thomas_labelled.png|thumbnail|right]]In [[two-dimensional space]], the lowest order Raviart Thomas space, <math>\\mathrm{RT}_0</math>, has degrees of freedom on the edges of the elements of the finite element mesh. The <math>n</math>th edge has an associated basis function defined by<ref>{{Cite journal|last1=Bahriawati |first1=C. |last2=Carstensen |first2=C. |date=2005 |title=Three MATLAB Implementations Of The Lowest-Order Raviart-Thomas MFEM With a Posteriori Error Control |url=http://www2.mathematik.hu-berlin.de/~cc/cc_homepage/download/2005-BC_CC-Three_MATLAB_Implementations_Lowest-Order_Raviart-Thomas_MFEM.pdf |journal=Computational Methods in Applied Mathematics |volume=5 |issue=4 |pages=331–361 |access-date=8 October 2015 |doi=10.2478/cmam-2005-0016}}</ref>\n\n<math>\\mathbf{f}_n(\\mathbf{r})=\\left\\{\\begin{array}{ll}\n\\frac{l_n}{2A_n^+}(\\mathbf{r}-\\mathbf{p}_+)\\quad&\\mathrm{if\\ \\mathbf{r}\\in\\ T_+}\\\\\n-\\frac{l_n}{2A_n^-}(\\mathbf{r}-\\mathbf{p}_-)\\quad&\\mathrm{if\\ \\mathbf{r}\\in\\ T_-}\\\\\n\\mathbf{0}\\quad&\\mathrm{otherwise}\n\\end{array}\\right.</math>\n\nwhere <math>l_n</math> is the length of the edge, <math>T_+</math> and <math>T_-</math> are the two triangles adjacent to the edge, <math>A_n^+</math> and <math>A_n^-</math> are the areas of the triangles and <math>\\mathbf{p}_+</math> and <math>\\mathbf{p}_-</math> are the opposite corners of the triangles.\n\nSometimes the basis functions are alternatively defined as\n\n<math>\\mathbf{f}_n(\\mathbf{r})=\\left\\{\\begin{array}{ll}\n\\frac{1}{2A_n^+}(\\mathbf{r}-\\mathbf{p}_+)\\quad&\\mathrm{if\\ \\mathbf{r}\\in\\ T_+}\\\\\n-\\frac{1}{2A_n^-}(\\mathbf{r}-\\mathbf{p}_-)\\quad&\\mathrm{if\\ \\mathbf{r}\\in\\ T_-}\\\\\n\\mathbf{0}\\quad&\\mathrm{otherwise}\n\\end{array}\\right.</math>\n\nwith the length factor not included.\n\n==References==\n<references />\n\n{{DEFAULTSORT:Raviart-Thomas basis functions}}\n[[Category:Finite element method]]\n[[Category:Numerical differential equations]]\n[[Category:Partial differential equations]]"
    },
    {
      "title": "Rayleigh–Ritz method",
      "url": "https://en.wikipedia.org/wiki/Rayleigh%E2%80%93Ritz_method",
      "text": "{{Cleanup|reason=Example is difficult to follow |date=October 2014}}\n{{context|date=January 2017}}\nThe '''Rayleigh–Ritz method''' is a numerical method of finding approximations to [[eigenvalues and eigenvectors|eigenvalue]] equations that are difficult to solve analytically, particularly in the context of solving physical [[Boundary value problem|boundary value problems]] that can be expressed as [[Matrix differential equation|matrix differential equations]]. It is used in mechanical engineering to approximate the [[Normal mode|eigenmodes]] of a physical system, such as finding the [[Resonance|resonant frequencies]] of a structure to guide appropriate [[Damping ratio|damping]]. The name is a common misnomer used to describe the method that is more appropriately termed the [[Ritz method]] or the [[Galerkin method]].{{Citation needed|date=May 2019}}  This method was invented by [[Walther Ritz]] in 1909, but it bears some similarity to the [[Rayleigh quotient]] and so the misnomer persists.{{Citation needed|date=May 2019}}\n\n== Description of method ==\nThe '''Rayleigh–Ritz method''' allows for the computation of Ritz pairs <math>(\\tilde{\\lambda}_i,\\tilde{\\textbf{x}}_i)</math> which approximate the solutions to the eigenvalue problem<ref name=\"TrefethenIII1997\" />\n\n:<math> A \\textbf{x} = \\lambda \\textbf{x}</math>\nwhere <math> A \\in \\mathbb{C}^{N \\times N} </math>.\n\nThe procedure is as follows:<ref name=\"SchofieldChelikowsky2012\" />\n# Compute an orthonormal basis <math> V \\in \\mathbb{C}^{N \\times m} </math> approximating the [[eigenvalues and eigenvectors#eigenspace and spectrum|eigenspace]] corresponding to ''m'' eigenvectors\n# Compute <math> R \\gets V^* A V </math>\n# Compute the eigenvalues of R solving <math> R \\mathbf{v}_i = \\tilde{\\lambda}_i \\mathbf{v}_i</math>\n# Form the Ritz pairs <math>(\\tilde{\\lambda}_i,\\tilde{\\textbf{x}}_i) = (\\tilde{\\lambda}_i,V \\textbf{v}_i)</math>\n\nOne can always compute the accuracy of such an approximation via <math> \\| A \\tilde{\\textbf{x}}_i - \\tilde{\\lambda}_i \\tilde{\\textbf{x}}_i\\|</math>\n\nIf a [[Krylov subspace]] is used and A is a general matrix, then this is the [[Arnoldi iteration#Finding eigenvalues with the Arnoldi iteration|Arnoldi algorithm]].\n\n=== The method in calculus of variations  ===\nIn this technique, we approximate the [[variational method|variational]] problem and end up with a finite dimensional problem. So let us start with the problem of seeking a [[Function (mathematics)|function]] <math>y(x)</math> that extremizes an integral <math>I[y(x)]</math>. Assume that we are able to approximate y(x) by a linear combination of certain linearly independent functions of the type:\n\n<math>y(x)\\approx \\varphi_0 (x) + c_1 \\varphi_1 (x) + c_2 \\varphi_2 (x)+ \\cdots + c_N \\varphi_N (x)</math>\n\nwhere '''''<math>c_1,c_2,\\cdots,c_N</math>''''' are constants to be determined by a variational method, such as one which will be described below.\n\nThe selection of which approximating functions <math>\\varphi_i (x)</math> to use is arbitrary except for the following considerations:\n\n'''a)''' If the problem has [[Boundary value problem|boundary conditions]] such as fixed end points, then <math>\\varphi_0 (x)</math> is chosen to satisfy the problem’s boundary conditions, and all other <math>\\varphi_i (x)</math> vanish at the boundary.\n\n'''b)''' If the form of the solution is known, then <math>\\varphi_i (x)</math> can be chosen so that <math>y(x)</math> will have that form.\n\nThe expansion of <math>y(x)</math> in terms of approximating functions replaces the variational problem of extremising the functional integral <math>I[y(x)]</math> to a problem of finding a set of constants <math>c_1,c_2,\\cdots,c_N</math> that extremizes <math>I(c_1,c_2,\\cdots,c_N)</math>. We can now solve this by setting the partial derivatives to zero. For each value of i,\n\n<math>{\\partial I \\over \\partial c_i}=0</math>\n\nThe procedure is to first determine an initial estimate of <math>c_1</math> by the approximation <math>y(x)\\approx \\varphi_0 (x) + c_1 \\varphi_1 (x)</math>. Next, the approximation <math>y(x)\\approx \\varphi_0 (x) + c_1 \\varphi_1 (x) + c_2 \\varphi_2 (x)</math> is used (with <math>c_1</math> being redetermined). The process continues with <math>y(x)\\approx \\varphi_0 (x) + c_1 \\varphi_1 (x) + c_2 \\varphi_2 (x)+ c_3 \\varphi_3 (x)</math> as the third approximation and so on. At each stage the following two items are true:\n# At the ith stage, the terms <math>c_1,\\cdots,c_{i-1}</math> are redetermined\n# The approximation at the <math>i^{th}</math> stage <math>y(x)\\approx \\varphi_0 (x) + c_1 \\varphi_1 (x) + \\cdots + c_i \\varphi_i (x)</math>  will be no worse than the approximation at the <math>(i-1)^{th}</math> stage\n\nConvergence of the procedure means that as i tends to infinity, the approximation will tend towards the exact function <math>y(x)</math> that extremizes an integral <math>I[y(x)]</math>.\n\nIn many cases one uses a complete set of functions e. g. [[polynomial]]s or sines and [[Law of cosines|cosines]]. A set of functions <math>\\varphi_i (x)</math> is called complete over [a, b] if for each [[Bernhard Riemann|Riemann]] integrable function <math>f(x)</math>, there is a set of values of coefficients <math>c_1,c_2,\\cdots,c_N</math> that reproduces <math>f(x)</math>.\n\nThe above outlined procedure can be extended to cases with more than one independent variable.\n\n== Applications in mechanical engineering ==\nThe Rayleigh–Ritz method is often used in [[mechanical engineering]] for finding the approximate real [[resonant frequency|resonant frequencies]] of multi [[degrees of freedom (physics and chemistry)|degree of freedom]] systems, such as [[spring mass system]]s or [[flywheel]]s on a shaft with varying [[cross section (geometry)|cross section]]. It is an extension of Rayleigh's method. It can also be used for finding buckling loads and post-buckling behaviour for columns.\n\nConsider the case whereby we want to find the resonant frequency of oscillation of a system. First, write the oscillation in the form,\n\n<math>y(x,t)=Y(x)\\cos\\omega t</math>\n\nwith an unknown mode shape <math>Y(x)</math>. Next, find the total energy of the system, consisting of a kinetic energy term and a potential energy term. The kinetic energy term involves the square of the time derivative of <math>y(x,t)</math> and thus gains a factor of <math>\\omega ^2</math>. Thus, we can calculate the total energy of the system and express it in the following form:\n\n<math>E=T+V\\equiv A[Y(x)] \\omega^2\\sin^2 \\omega t + B[Y(x)] \\cos^2 \\omega t</math>\n\nBy conservation of energy, the average kinetic energy must be equal to the average potential energy. Thus,\n\n<math>\\omega^2=\\frac{B[Y(x)]}{A[Y(x)]}=R[Y(x)]</math>\n\nwhich is also known as the [[Rayleigh quotient]]. Thus, if we knew the mode shape <math>Y(x)</math>, we would be able to calculate <math>A[Y(x)]</math> and <math>B[Y(x)]</math>, and in turn get the eigenfrequency. However, we do not yet know the mode shape. In order to find this, we can approximate <math>Y(x)</math> as a combination of a few approximating functions <math>Y_i(x)</math>\n\n<math>Y(x)=\\sum_{i=1}^N c_iY_i(x)</math>\n\nwhere <math>c_1,c_2,\\cdots,c_N</math> are constants to be determined. In general, if we choose a random set of <math>c_1,c_2,\\cdots,c_N</math>, it will describe a superposition of the actual eigenmodes of the system. However, if we seek <math>c_1,c_2,\\cdots,c_N</math> such that the eigenfrequency <math>\\omega^2</math> is minimised, then the mode described by this set of <math>c_1,c_2,\\cdots,c_N</math> will be close to the lowest possible actual eigenmode of the system. Thus, this finds the lowest eigenfrequency. If we find eigenmodes orthogonal to this approximated lowest eigenmode, we can approximately find the next few eigenfrequencies as well.\n\nIn general, we can express <math>A[Y(x)]</math> and <math>B[Y(x)]</math> as a collection of terms quadratic in the coefficients <math>c_i</math>:\n\n<math>B[Y(x)]=\\sum_i\\sum_j c_i c_jK_{ij}=\\bf{c^T K c}</math>\n\n<math>A[Y(x)]=\\sum_i\\sum_j c_i c_jM_{ij}=\\bf{c^T M c}</math>\n\nThe minimization of <math>\\omega^2</math> becomes:\n\n<math>{\\partial \\omega^2 \\over \\partial c_i}={\\partial \\over \\partial c_i}\\frac{\\bf{c^T K c}}{\\bf{c^T M c}}=0</math>\n\nSolving this,\n\n<math>\\bf{c^T M c}{\\partial \\bf{c^T K c} \\over \\partial c}-\\bf{c^T K c}{\\partial \\bf{c^T M c} \\over \\partial c}=0</math>\n\n<math>\\bf{K c}-\\frac{\\bf{c^T K c}}{\\bf{c^T M c}}\\bf{M c}=0</math>\n\n<math>\\bf{K c}-\\omega^2\\bf{M c}=0</math>\n\nFor a non-trivial solution of c, we require determinant of the matrix coefficient of c to be zero.\n\n<math>\\det({\\bf{K}-\\omega^2\\bf{M}})=0</math>\n\nThis gives a solution for the first N eigenfrequencies and eigenmodes of the system, with N being the number of approximating functions.\n\n== Simple case of double spring-mass system ==\nThe following discussion uses the simplest case, where the system has two lumped springs and two lumped masses, and only two mode shapes are assumed. Hence ''M''&nbsp;=&nbsp;[''m''<sub>1</sub>,&nbsp;''m''<sub>2</sub>] and ''K''&nbsp;=&nbsp;[''k''<sub>1</sub>,&nbsp;''k''<sub>2</sub>].\n\nA [[mode shape]] is assumed for the system, with two terms, one of which is weighted by a factor&nbsp;''B'', e.g. ''Y'' =&nbsp;[1,&nbsp;1]&nbsp;+&nbsp;''B''[1,&nbsp;&minus;1].\n[[Simple harmonic motion]] theory says that the [[velocity]] at the time when deflection is zero, is the [[angular frequency]] <math>\\omega</math> times the deflection (y) at time of maximum deflection. In this example the [[kinetic energy]] (KE) for each mass is <math>\\frac{1}{2}\\omega^2 Y_1^2 m_1</math> etc., and the [[potential energy]] (PE) for each [[Spring (device)|spring]] is <math>\\frac{1}{2} k_1 Y_1^2</math> etc.\n\nWe also know that without damping, the maximal KE equals the maximal PE. Thus,\n\n: <math>\\sum_{i=1}^2 \\left(\\frac{1}{2} \\omega^2 Y_i^2 M_i\\right)=\\sum_{i=1}^2 \\left(\\frac{1}{2} K_i Y_i^2\\right)</math>\n\nNote that the overall amplitude of the mode shape cancels out from each side, always. That is, the actual size of the assumed deflection does not matter, just the mode ''shape''.\n\nMathematical manipulations then obtain an expression for <math>\\omega</math>, in terms of B, which can be [[derivative|differentiated]] with respect to B, to find the minimum, i.e. when <math>d\\omega/dB=0</math>. This gives the value of B for which <math>\\omega</math> is lowest. This is an upper bound solution for <math>\\omega</math> if <math>\\omega</math> is hoped to be the predicted fundamental frequency of the system because the mode shape is ''assumed'', but we have found the lowest value of that upper bound, given our assumptions, because B is used to find the optimal 'mix' of the two assumed mode shape functions.\n\nThere are many tricks with this method, the most important is to try and choose realistic assumed mode shapes. For example, in the case of [[beam deflection]] problems it is wise to use a deformed shape that is analytically similar to the expected solution.  A [[quartic function|quartic]] may fit most of the easy problems of simply linked beams even if the order of the deformed solution may be lower. The springs and masses do not have to be discrete, they can be continuous (or a mixture), and this method can be easily used in a [[spreadsheet]] to find the natural frequencies of quite complex distributed systems, if you can describe the distributed KE and PE terms easily, or else break the continuous elements up into discrete parts.\n\nThis method could be used iteratively, adding additional mode shapes to the previous best solution, or you can build up a long expression with many Bs and many mode shapes, and then differentiate them [[partial differentiation|partially]].\n\n== See also ==\n*[[Ritz method]]\n*[[Arnoldi iteration]]\n\n== Notes and references==\n{{Reflist|refs=\n<ref name=\"SchofieldChelikowsky2012\">{{cite journal|last1=Schofield|first1=Grady|last2=Chelikowsky|first2=James R.|last3=Saad|first3=Yousef|title=A spectrum slicing method for the Kohn–Sham problem|journal=Computer Physics Communications|volume=183|issue=3|year=2012|pages=497–505|issn=0010-4655|doi=10.1016/j.cpc.2011.11.005|url=http://www-users.cs.umn.edu/~saad/PDF/umsi-2011-142.pdf|citeseerx=10.1.1.228.9553}}</ref>\n<ref name=\"TrefethenIII1997\">{{cite book|last1=Trefethen|first1=Lloyd N. |last2= Bau, III|first2=David|title=Numerical Linear Algebra|url=https://books.google.com/books?id=JaPtxOytY7kC|year=1997|publisher=SIAM|isbn=978-0-89871-957-4|page=254}}</ref>\n\n}}\n\n==External links==\n*[https://web.archive.org/web/20081010161336/http://www.math.nps.navy.mil/~bneta/4311.pdf Course on Calculus of Variations, has a section on Rayleigh–Ritz method].\n\n{{DEFAULTSORT:Rayleigh-Ritz Method}}\n[[Category:Numerical differential equations]]\n[[Category:Dynamical systems]]"
    },
    {
      "title": "Reproducing kernel particle method",
      "url": "https://en.wikipedia.org/wiki/Reproducing_kernel_particle_method",
      "text": "{{Use American English|date = February 2019}}\n{{Short description|Method of computational hydrodynamics}}\nIn applied mathematics, the '''reproducing kernel particle method''' is a [[meshfree method|meshfree]] computational method introduced in Liu et al.<ref>{{cite journal|last=W.K. Liu |author2=S. Jun |author3=Y.F. Zhang|title=Reproducing kernel particle methods|journal=Int. J. Numer. Methods Eng.|year=1995|volume=20|issue=8–9|pages=1081–1106|doi=10.1002/fld.1650200824|bibcode = 1995IJNMF..20.1081L }}\n</ref> as an improvement of [[smoothed-particle hydrodynamics]].\n\n== References ==\n{{Reflist|30em}}\n\n{{fluiddynamics-stub}}\n\n[[Category:Numerical differential equations]]\n[[Category:Computational fluid dynamics]]"
    },
    {
      "title": "Roe solver",
      "url": "https://en.wikipedia.org/wiki/Roe_solver",
      "text": "{{Expert-subject|Physics|date=September 2008}}\n\nThe '''Roe approximate Riemann solver''', devised by [[Philip L. Roe|Phil Roe]], is an approximate [[Riemann solver]] based on the [[Godunov scheme]] and involves finding an estimate for the intercell numerical flux or Godunov flux <math>F_{i + \\frac{1}{2}}</math> at the interface between two computational cells <math>U_{i}</math> and <math>U_{i+1}</math>, on some discretised space-time computational domain.\n\n==The Roe Scheme==\n===Quasi-linear Hyperbolic system===\n \nA non-linear system of [[hyperbolic partial differential equations]] representing a set of [[conservation laws]] in one spatial dimension \ncan be written in the form\n:<math>\n\\frac{\\partial \\boldsymbol{U}}{\\partial t} + \\frac{\\partial \\boldsymbol{F}(\\boldsymbol{U})}{\\partial x} = 0.\n</math>\nApplying the [[chain rule]] to the second term we get the quasi-linear hyperbolic system\n:<math>\n\\frac{\\partial \\boldsymbol{U}}{\\partial t} + A(\\boldsymbol{U})\\frac{\\partial \\boldsymbol{U}}{\\partial x} = 0,\n</math>\nwhere <math>A</math> is the [[Jacobian matrix]] of the flux vector <math>\\boldsymbol{F}(\\boldsymbol{U})</math>.\n\n===The Roe Matrix===\nThe Roe method consists of finding a matrix <math>\\tilde{A}(\\boldsymbol{U}_i,\\boldsymbol{U}_{i+1})</math> that is assumed constant between two cells. The [[Riemann problem]] can then be solved as a truly linear hyperbolic system at each cell interface. The Roe matrix must obey the following conditions:\n* '''[[Diagonalizable]] with real eigenvalues''' Ensures that the new linear system is truly hyperbolic.\n* '''Consistency with the exact jacobian''' When <math>\\boldsymbol{U}_i,\\boldsymbol{U}_{i+1} \\rightarrow \\boldsymbol{U}</math> we demand that <math>\\tilde{A}(\\boldsymbol{U}_i,\\boldsymbol{U}_{i+1}) = A(\\boldsymbol{U})</math>\n* '''Conserving''' <math>\n\\boldsymbol{F}_{i+1}-\\boldsymbol{F}_{i} = \\tilde{A}(\\boldsymbol{U}_{i+1}-\\boldsymbol{U}_{i})\n</math>\n[[Philip L. Roe|Phil Roe]] introduced a method of parameter vectors<ref>P. L. Roe, [http://arrow.utias.utoronto.ca/~groth/aer1319/Handouts/Additional_Reading_Material/JCP-1981-roe.pdf Approximate riemann solvers, parameter vectors and difference schemes], Journal of Computational Physics, 43, 357-372, (1981)</ref> to find such a matrix for some systems of conservation laws.\n\n===The Intercell Flux===\nOnce the Roe matrix corresponding to the interface between two cells is found, the intercell flux is given by solving the quasi-linear system as a truly linear system.\n\n==See also==\n* [[Riemann solver]]\n\n==References==\n{{reflist}}\n\n==Further reading==\n* Toro, E. F. (1999), ''Riemann Solvers and Numerical Methods for Fluid Dynamics'', Springer-Verlag.\n\n[[Category:Numerical differential equations]]\n[[Category:Conservation equations]]"
    }
  ]
}