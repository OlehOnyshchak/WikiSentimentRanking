{
  "pages": [
    {
      "title": "Denjoy–Koksma inequality",
      "url": "https://en.wikipedia.org/wiki/Denjoy%E2%80%93Koksma_inequality",
      "text": "In mathematics, the '''Denjoy–Koksma inequality''', introduced by {{harvtxt|Herman|1979|loc=p.73}} as a combination of work of  [[Arnaud Denjoy]] and the [[Koksma–Hlawka inequality]] of [[Jurjen Ferdinand Koksma]], is a bound for [[Weyl sum]]s <math>\\sum_{k=0}^{m-1}f(x+k\\omega)</math> of functions ''f'' of [[bounded variation]].\n\n==Statement==\n\nSuppose that a map ''f'' from the circle ''T'' to itself has irrational rotation number ''α'', and ''p''/''q'' is a rational approximation to ''α'' with ''p'' and ''q'' [[coprime]], |''α''&nbsp;–&nbsp;''p''/''q''|&nbsp;<&nbsp;1/''q''<sup>2</sup>. Suppose that ''φ'' is a function of bounded variation, and ''μ'' a [[probability measure]] on the circle invariant under&nbsp;''f''. Then\n\n:<math>\\left|\\sum_{i=0}^{q-1} \\phi f^i(x) - q\\int_T \\phi \\, d\\mu \\right| \\leqslant \\operatorname{Var}(\\phi)</math>\n{{harv|Herman|1979|loc=p.73}}\n\n==References==\n\n*{{Citation | last1=Herman | first1=Michael-Robert | title=Sur la conjugaison différentiable des difféomorphismes du cercle à des rotations | url=http://www.numdam.org/item?id=PMIHES_1979__49__5_0 | mr=538680  | year=1979 | journal=[[Publications Mathématiques de l'IHÉS]] | issn=1618-1913 | issue=49 | pages=5–233}}\n*{{Citation | last1=Kuipers | first1=L. | last2=Niederreiter | first2=H. | author2-link = Harald Niederreiter | title=Uniform distribution of sequences | publisher=Wiley-Interscience [John Wiley & Sons] | location=New York | isbn=978-0-486-45019-3 | mr=0419394 |id= Reprinted by Dover 2006 | year=1974}}\n\n{{DEFAULTSORT:Denjoy-Koksma inequality}}\n[[Category:Theorems in analysis]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Dittert conjecture",
      "url": "https://en.wikipedia.org/wiki/Dittert_conjecture",
      "text": "The '''Dittert conjecture''', or '''Dittert–Hajek conjecture''', is a mathematical hypothesis (in [[combinatorics]]) concerning the maximum achieved by a particular function <math>\\phi</math> of matrices with real, nonnegative entries satisfying a summation condition. The conjecture is due to Eric Dittert and (independently) Bruce Hajek.<ref name=Hogben>{{cite book|editor=Hogben, Leslie|title=Handbook of Linear Algebra|edition=2nd|publisher=CRC Press|year=2014|pages=43–8|url=https://books.google.com/books?id=Er7MBQAAQBAJ&pg=SA42-PA42}}</ref><ref name=Cheon>{{cite journal|volume=436|issue=4|date=15 February 2012|pages=791–801|title=Some results towards the Dittert conjecture on permanents|journal=Linear Algebra and its Applications|author=Cheon, Gi-Sang|author2=Wanless, Ian M.|doi=10.1016/j.laa.2010.08.041}}</ref><ref>{{MathGenealogy|id=81909|title=Eric R. Dittert}}</ref><ref>{{MathGenealogy|id=14723|title=Bruce Edward Hajek}}</ref>\n\nLet <math>A = [a_{ij}]</math> be a square matrix of order <math>n</math> with nonnegative entries and with <math>\\sum_{i=1}^n \\left ( \\sum_{j=1}^n a_{ij} \\right ) = n</math>. Its [[Permanent (mathematics)|permanent]] is defined as <math> \\operatorname{per}(A)=\\sum_{\\sigma\\in S_n}\\prod_{i=1}^n a_{i,\\sigma(i)}</math>, where the sum extends over all elements <math>\\sigma</math> of the [[symmetric group]]. \n\nThe '''Dittert conjecture''' asserts that the function <math>\\operatorname{\\phi}(A)</math> defined by <math>\\prod_{i=1}^n \\left ( \\sum_{j=1}^n a_{ij} \\right ) + \\prod_{j=1}^n \\left ( \\sum_{i=1}^n a_{ij} \\right ) - \\operatorname{per}(A)</math> is (uniquely) maximized when <math>A = (1/n) J_n</math>, where <math>J_n</math> is defined to be the square matrix of order <math>n</math> with all entries equal to 1.<ref name=Hogben/><ref name=Cheon/>\n\n==References==\n{{reflist}}\n\n[[Category:Conjectures]]\n[[Category:Combinatorics]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Eilenberg's inequality",
      "url": "https://en.wikipedia.org/wiki/Eilenberg%27s_inequality",
      "text": "'''Eilenberg's inequality''' is a [[inequality (mathematics)|mathematical inequality]] for [[Lipschitz continuity|Lipschitz-continuous function]]s.\n\nLet ''&fnof;''&nbsp;:&nbsp;''X''&nbsp;→&nbsp;''Y'' be a Lipschitz-continuous function between [[separable space|separable]] [[metric space]]s whose Lipschitz constant is denoted by Lip&nbsp;''&fnof;''. Then, Eilenberg's inequality states that\n\n:<math>\\int_Y^* H_{m-n}(A\\cap f^{-1}(y)) \\, dH_n(y) \\leq \\frac{v_{m-n}v_n}{v_m}(\\text{Lip }f)^n H_m(A), </math>\n\nfor any ''A''&nbsp;⊂&nbsp;''X'' and all 0&nbsp;≤&nbsp;''n''&nbsp;≤&nbsp;''m'', where\n\n* the asterisk denotes the upper&nbsp;[[Lebesgue integral]],\n* ''v''<sub>''n''</sub> is the volume of the unit ball in&nbsp;'''R'''<sup>''n''</sup>,\n* ''H''<sub>''n''</sub> is the ''n''-dimensional [[Hausdorff measure]].\nThe Eilenberg's Inequality is a key ingredient for the proof of the [[Coarea formula]].\n==References==\n* Yu. D. Burago and V. A. Zalgaller, ''Geometric inequalities''. Translated from the Russian by A. B. Sosinskiĭ. Springer-Verlag, Berlin, 1988. {{ISBN|3-540-13615-0}}.\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Erdős–Turán inequality",
      "url": "https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Tur%C3%A1n_inequality",
      "text": "In mathematics, the '''Erdős–Turán inequality''' bounds the distance between a [[Probability distribution|probability measure]] on the circle and the [[Lebesgue measure]], in terms of [[Fourier coefficient]]s. It was proved by [[Paul Erdős]] and [[Pál Turán]] in 1948.<ref>{{cite journal|mr=0027895|last=Erdős|first=P.|last2=Turán|first2=P.|title=On a problem in the theory of uniform distribution. I.|journal=Nederl. Akad. Wetensch.|volume=51|year=1948|pages=1146–1154|zbl=0031.25402}}</ref><ref>{{cite journal|mr=0027895|last=Erdős|first=P.|last2=Turán|first2=P.|title=On a problem in the theory of uniform distribution. II.|journal=Nederl. Akad. Wetensch.|volume=51|year=1948|pages=1262–1269|zbl=0032.01601}}</ref>\n\nLet ''μ'' be a probability measure on the [[unit circle]] '''R'''/'''Z'''. The Erdős–Turán inequality states that, for any natural number ''n'',\n\n:<math> \\sup_A \\left| \\mu(A) - \\mathrm{mes}\\, A \\right| \n     \\leq C \\left( \\frac{1}{n} + \\sum_{k=1}^n \\frac{|\\hat{\\mu}(k)|}{k} \\right),\n</math>\n\nwhere the supremum is over all [[Arc (geometry)|arcs]] ''A'' ⊂ '''R'''/'''Z''' of the unit circle, ''mes'' stands for the Lebesgue measure,\n\n:<math> \\hat{\\mu}(k) = \\int \\exp(2 \\pi i k \\theta) \\, d\\mu(\\theta) </math>\n\nare the [[Fourier coefficients]] of μ, and ''C''&nbsp;>&nbsp;0 is a numerical constant.\n\n==Application to discrepancy==\n\nLet ''s''<sub>1</sub>, ''s''<sub>2</sub>, ''s''<sub>3</sub> ... ∈ '''R''' be a sequence. The Erdős–Turán inequality applied to the measure\n\n:<math> \\mu_m(S) = \\frac{1}{m} \\# \\{ 1 \\leq j \\leq m \\, | \\, s_j \\, \\mathrm{mod} \\, 1 \\in S \\}, \\quad S \\subset [0, 1), </math>\n\nyields the following bound for the [[Discrepancy_of_a_sequence#Discrepancy|discrepancy]]:\n\n:<math>\n\\begin{align}\nD(m) & \\left( = \\sup_{0 \\leq a \\leq b \\leq 1} \\Big| m^{-1} \\# \\{ 1 \\leq j \\leq m \\, | \\, a \\leq s_j \\, \\mathrm{mod} \\, 1 \\leq b  \\} - (b-a) \\Big| \\right) \\\\[8pt]\n&  \\leq C \\left( \\frac{1}{n} + \\frac{1}{m} \\sum_{k=1}^n \\frac{1}{k} \\left| \\sum_{j=1}^m e^{2 \\pi i s_j k} \\right|\\right). \n\\end{align} \\qquad (1)\n</math>\n\nThis inequality holds for arbitrary natural numbers ''m,n'', and gives a quantitative form of [[Weyl's criterion]] for [[equidistribution]].\n\nA multi-dimensional variant of (1) is known as the [[Low-discrepancy_sequence#The_Erd.C5.91s.E2.80.93Turan.E2.80.93Koksma_inequality|Erdős–Turán–Koksma inequality]].\n\n==Notes==\n{{Reflist}}\n\n==Additional references==\n* {{cite book | last=Harman | first=Glyn | author-link= Glyn Harman | title=Metric Number Theory | series=London Mathematical Society Monographs. New Series | volume=18 | location=Oxford | publisher=[[Clarendon Press]] | year=1998 | isbn=0-19-850083-1 | zbl=1081.11057 }}\n\n{{DEFAULTSORT:Erdos-Turan inequality}}\n[[Category:Inequalities]]\n[[Category:Paul Erdős]]\n[[Category:Theorems in approximation theory]]"
    },
    {
      "title": "Fannes–Audenaert inequality",
      "url": "https://en.wikipedia.org/wiki/Fannes%E2%80%93Audenaert_inequality",
      "text": "The '''Fannes&ndash;Audenaert inequality''' is a mathematical bound on the difference between the [[von Neumann entropy|von Neumann entropies]] of two [[density matrix|density matrices]] as a function of their [[trace distance]].  It was proved by Koenraad M. R. Audenaert in 2007<ref>Koenraad M. R. Audenaert, [http://iopscience.iop.org/1751-8121/40/28/S18/ \"A sharp continuity estimate for the von Neumann entropy\"], J. Phys. A: Math. Theor. '''40''' 8127 (2007).  Preprint: [https://arxiv.org/abs/quant-ph/0610146 arXiv:quant-ph/0610146].</ref> as an optimal refinement of Mark Fannes' original inequality, which was published in 1973.<ref>M. Fannes, [http://www.springerlink.com/content/k7254x6466633837/ \"A continuity property of the entropy density for spin lattice systems \"], Communications in Mathematical Physics '''31''' 291&ndash;294 (1973).</ref> Mark Fannes is a Belgian physicist specialised in mathematical quantum mechanics. He works at the [[Katholieke Universiteit Leuven|KU Leuven]]. Koenraad M. R. Audenaert is a Belgian physicist and civil engineer. He currently works at [[Royal Holloway, University of London]].\n\n== Statement of inequality ==\n\nFor any two density matrices <math>\\rho</math> and <math>\\sigma</math> of dimensions <math>d</math>,\n\n:<math>|S(\\rho)-S(\\sigma)| \\le T \\log (d-1) + H[\\{T,1-T\\}] </math>\n\nwhere\n\n:<math>H[\\{p_i\\}] = - \\sum p_i \\log p_i </math>\n\nis the ([[Shannon entropy|Shannon]]) entropy of the probability distribution <math>\\{p_i\\}</math>,\n\n:<math>S(\\rho) = H[\\{\\lambda_i\\}] </math>\n\nis the (von Neumann) entropy of a matrix <math>\\rho</math> with eigenvalues <math>\\lambda_i</math>, and\n\n:<math>T(\\rho,\\sigma) = \\frac{1}{2}||\\rho-\\sigma||_{1} = \\frac{1}{2}\\mathrm{Tr} \\left[ \\sqrt{(\\rho-\\sigma)^\\dagger (\\rho-\\sigma)} \\right]</math>\n\nis the trace distance between the two matrices.  Note that the base for the [[logarithm]] is arbitrary, so long as the same base is used on both sides of the inequality.\n\nAudenaert also proved that&mdash;given only the trace distance ''T'' and the dimension&nbsp;''d''&mdash;this is the ''optimal'' bound.  He did this by directly exhibiting a pair of matrices which saturate the bound for any values of ''T'' and&nbsp;''d''.  The matrices (which are diagonal in the same basis, i.e. they commute) are\n\n:<math>\\rho = \\mathrm{Diag}(1-T, T/(d-1),\\dots,T/(d-1)) </math>\n:<math>\\sigma = \\mathrm{Diag}(1,0,\\dots,0) </math>\n\n==Fannes' inequality and Audenaert's refinement==\n\nThe original inequality proved by Fannes was\n\n:<math>|S(\\rho)-S(\\sigma)| \\le 2T \\log (d) -2T \\log 2T </math>\n\nwhen <math>T \\le 1/2e</math>.  He also proved the weaker inequality\n\n:<math>|S(\\rho)-S(\\sigma)| \\le 2T \\log (d) + 1 / (e \\log 2) </math>\n\nwhich can be used for larger&nbsp;''T''.\n\nFannes proved this inequality as a means to prove the [[Continuity (mathematics)|continuity]] of the [[von Neumann entropy]], which did not require an optimal bound.  The proof is very compact, and can be found in the textbook by Nielsen and Chuang.<ref>{{cite book |title= [[Quantum Computation and Quantum Information (book)|Quantum Computation and Quantum Information]]|last= Nielsen|first= Michael A|authorlink= |author2=Chuang, Isaac L|year= 2000|publisher= [[Cambridge University Press]]|location= [[Cambridge]]; [[New York City|New York]]|isbn= 978-0-521-63235-5|oclc= 43641333|pages= }}</ref>  Audenaert's proof of the optimal inequality, on the other hand, is significantly more complicated.\n\n==References==\n<references/>\n\n{{DEFAULTSORT:Fannes-Audenaert inequality}}\n[[Category:Inequalities]]"
    },
    {
      "title": "Fano's inequality",
      "url": "https://en.wikipedia.org/wiki/Fano%27s_inequality",
      "text": "In [[information theory]], '''Fano's inequality''' (also known as the '''Fano converse''' and the '''Fano lemma''') relates the average information lost in a noisy channel to the probability of the categorization error.  It was derived by [[Robert Fano]] in the early 1950s while teaching a [[Ph.D.]] seminar in information theory at [[MIT]], and later recorded in his 1961 textbook.\n\nIt is used to find a lower bound on the error probability of any decoder as well as the lower bounds for [[minimax risk]]s in [[density estimation]].\n\nLet the [[random variables]] ''X'' and ''Y'' represent input and output messages with a [[joint probability]] <math>P(x,y)</math>. Let ''e'' represent an occurrence of error; i.e., that <math>X\\neq \\tilde{X}</math>, with <math>\\tilde{X}=f(Y)</math> being an approximate version of <math>X</math>. Fano's inequality is\n:<math>H(X|Y)\\leq H(e)+P(e)\\log(|\\mathcal{X}|-1),</math>\n\nwhere <math>\\mathcal{X}</math> denotes the support of ''X'',\n:<math>H\\left(X|Y\\right)=-\\sum_{i,j} P(x_i, y_j)\\log P\\left(x_i|y_j\\right)</math>\n\nis the [[conditional entropy]],\n:<math>P(e)=P(X\\neq  \\tilde{X})</math>\n\nis the probability of the communication error, and\n:<math>H(e)=-P(e)\\log P(e)-(1-P(e))\\log(1-P(e))</math>\n\nis the corresponding [[Binary entropy function|binary entropy]].\n\n==Alternative formulation==\nLet ''X'' be a [[random variable]] with [[Probability density function|density]] equal to one of <math>r+1</math> possible densities <math>f_1,\\ldots,f_{r+1}</math>. Furthermore, the [[Kullback–Leibler divergence]] between any pair of densities cannot be too large,\n:<math> D_{KL}(f_i\\|f_j)\\leq \\beta</math> for all <math>i\\not = j.</math>\n\nLet <math>\\psi(X)\\in\\{1,\\ldots, r+1\\}</math> be an estimate of the index. Then\n\n:<math>\\sup_i P_i(\\psi(X)\\not = i) \\geq 1-\\frac{\\beta+\\log 2}{\\log r}</math>\nwhere <math>P_i</math> is the [[probability]] induced by <math>f_i</math>\n\n==Generalization==\nThe following generalization is due to Ibragimov and Khasminskii (1979), Assouad and Birge (1983).\n\nLet '''F''' be a class of densities with a subclass of ''r''&nbsp;+&nbsp;1 densities ''&fnof;''<sub>''&theta;''</sub> such that for any ''&theta;''&nbsp;≠&nbsp;''&theta;''<nowiki>&prime;</nowiki>\n\n:<math>\\|f_{\\theta}-f_{\\theta'}\\|_{L_1}\\geq \\alpha,</math>\n:<math>D_{KL}(f_\\theta\\|f_{\\theta'})\\leq \\beta.</math>\n\nThen in the worst case the [[expected value]] of error of estimation is bound from below,\n\n:<math>\\sup_{f\\in \\mathbf{F}} E \\|f_n-f\\|_{L_1}\\geq \\frac{\\alpha}{2}\\left(1-\\frac{n\\beta+\\log 2}{\\log r}\\right)</math>\n\nwhere ''&fnof;''<sub>''n''</sub> is any [[density estimation|density estimator]] based on a [[sample (statistics)|sample]] of size ''n''.\n\n==References==\n* P. Assouad, \"Deux remarques sur l'estimation\", ''Comptes Rendus de l'Académie des Sciences de Paris'', Vol. 296, pp.&nbsp;1021–1024, 1983.\n* L. Birge, \"Estimating a density under order restrictions: nonasymptotic minimax risk\", Technical report, UER de Sciences Économiques, Universite Paris X, Nanterre, France, 1983.\n* {{cite book|isbn=978-0-471-06259-2 | year=1991|author=T. Cover, J. Thomas|title=Elements of Information Theory|pages=38–42|url=http://www.cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf}}\n* L. Devroye, ''A Course in Density Estimation''. Progress in probability and statistics, Vol 14. Boston, Birkhauser, 1987. {{ISBN|0-8176-3365-0}}, {{ISBN|3-7643-3365-0}}.\n* {{cite book | last=Fano | first=Robert | title=Transmission of information: a statistical theory of communications | publisher=MIT Press | publication-place=Cambridge, Mass | year=1968 | url=https://archive.org/details/TransmissionOfInformationAStatisticalTheoryOfCommunicationRobertFano| isbn=978-0-262-56169-3 | oclc=804123877 | ref=harv}}\n** also: Cambridge, Massachusetts, M.I.T. Press, 1961. {{ISBN|0-262-06001-9}}\n* R. Fano, ''[http://www.scholarpedia.org/article/Fano_inequality Fano inequality]'' [[Scholarpedia]], 2008.\n* I. A. Ibragimov, R. Z. Has′minskii, ''Statistical estimation, asymptotic theory''. Applications of Mathematics, vol. 16, Springer-Verlag, New York, 1981. {{ISBN|0-387-90523-5}}\n\n[[Category:Information theory]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Fatou's lemma",
      "url": "https://en.wikipedia.org/wiki/Fatou%27s_lemma",
      "text": "In [[mathematics]], '''Fatou's lemma''' establishes an [[inequality (mathematics)|inequality]] relating the [[Lebesgue integral]] of the [[limit superior and limit inferior|limit inferior]] of a [[sequence]] of [[function (mathematics)|function]]s to the limit inferior of integrals of these functions.  The [[Lemma (mathematics)|lemma]] is named after [[Pierre Fatou]].\n\nFatou's lemma can be used to prove the [[Fatou–Lebesgue theorem]] and Lebesgue's [[dominated convergence theorem]].\n\n==Standard statement of Fatou's lemma==\nIn what follows, <math>\\operatorname{\\mathcal B}_{\\R_{\\geq 0}}</math> denotes the <math>\\sigma</math>-algebra of Borel sets on <math>[0,+\\infty]</math>.\n\n'''Fatou's lemma.''' Given a [[measure (mathematics)|measure space]] <math>(\\Omega,\\mathcal{F},\\mu)</math> and a  set <math>X \\in \\mathcal{F},</math> let <math>\\{f_n\\}</math> be a sequence of <math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable non-negative functions <math>f_n: X\\to [0,+\\infty]</math>. Define the function <math>f: X\\to [0,+\\infty]</math> by setting\n:<math>\nf(x) =\\liminf_{n\\to\\infty} f_n(x),\n</math>\nfor every <math>x\\in X</math>.\nThen <math>f</math> is <math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable, and \n:<math>\n\\int_X f\\,d\\mu \\le \\liminf_{n\\to\\infty} \\int_X f_n\\,d\\mu.\n</math>\n\n'''Remark 1.''' The integrals may be finite or infinite.\n\n'''Remark 2.''' Fatou's lemma remains true if its assumptions hold <math>\\mu</math>-almost everywhere. In other words, it is enough that there is a [[null set]] <math>N</math> such that the sequence <math>\\{f_n(x)\\}</math> non-decreases for every <math>{x\\in X\\setminus N}.</math> To see why this is true, we start with an observation that allowing the sequence <math>\\{ f_n \\}</math> to pointwise non-decrease almost everywhere causes its pointwise limit <math>f</math> to be undefined on some null set <math>N</math>. On that null set, <math>f</math> may then be defined arbitrarily, e.g. as zero, or in any other way that preserves measurability. To see why this will not affect the outcome, note that since <math>{\\mu(N)=0},</math> we have, for every <math>k,</math>\n\n:<math> \\int_X f_k \\,d\\mu = \\int_{X \\setminus N} f_k \\,d\\mu</math> and <math>\\int_X f \\,d\\mu = \\int_{X \\setminus N} f \\,d\\mu, </math>\n\nprovided that <math>f</math> is <math>(\\mathcal{F},\\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable.  (These equalities follow directly from the definition of Lebesgue integral for a non-negative function).\n\nFor use in the proof, define a sequence of functions by <math>\\textstyle g_n(x):=\\inf_{k\\geq n}f_k(x)</math>.\n\n'''Remark 3.''' For every <math>x\\in X</math>,\n{{ordered list|type=lower-alpha\n|The non-negative sequence <math>\\{g_n(x)\\}_n</math> is non-decreasing, i.e.\n<math>g_n(x)\\leq g_{n+1}(x)</math>, for every <math>n\\geq 1</math>;\n|By definition of [[limit inferior]], <math>f(x) =\\liminf_{n\\to\\infty} f_n(x) := \\lim_{n\\to \\infty} \\inf_{k\\geq n} f_k(x) = \\lim_{n\\to\\infty} g_n(x)</math>}}\n\n'''Remark 4.''' The proof below does not use any properties of Lebesgue integral except those established here.\n\n'''Remark 5 (monotonicity of Lebesgue integral).''' In the proof below, we apply the monotonic property of Lebesgue integral to non-negative functions only. Specifically (see Remark 4), let the functions <math>f,g : X \\to [0,+\\infty]</math> be <math>(\\mathcal{F},\\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable.\n\n*If <math>f \\leq g</math> everywhere on <math>X,</math> then\n\n:<math>\\int_X f\\,d\\mu \\leq \\int_X g\\,d\\mu.</math>\n\n*If <math> X_1,X_2 \\in \\mathcal{F} </math> and <math>X_1 \\subseteq X_2, </math> then\n\n:<math>\\int_{X_1} f\\,d\\mu \\leq \\int_{X_2} f\\,d\\mu.</math>\n\n'''Proof.''' Denote <math>\\operatorname{SF}(h)</math> the set of simple <math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable functions <math>s:X\\to [0,\\infty)</math> such that\n<math>0\\leq s\\leq h</math> everywhere on <math>X.</math> \n\n'''1.''' Since <math>f \\leq g,</math> we have\n\n:<math> \\operatorname{SF}(f) \\subseteq \\operatorname{SF}(g). </math>\n\nBy definition of Lebesgue integral and the properties of supremum,\n\n:<math>\\int_X f\\,d\\mu = \\sup_{s\\in {\\rm SF}(f)}\\int_X s\\,d\\mu \\leq \\sup_{s\\in {\\rm SF}(g)}\\int_X s\\,d\\mu = \\int_X g\\,d\\mu.</math>\n\n'''2.''' Let <math>{\\mathbf 1}_{X_1}</math> be the indicator function of the set <math>X_1.</math> It can be deduced from the definition of Lebesgue integral that\n\n:<math> \\int_{X_2} f\\cdot {\\mathbf 1}_{X_1} \\,d\\mu = \\int_{X_1} f \\,d\\mu</math>\n\nif we notice that, for every <math>s \\in {\\rm SF}(f\\cdot {\\mathbf 1}_{X_1}),</math> <math>s=0</math> outside of <math>X_1.</math> Combined with the previous property, the inequality <math> f\\cdot {\\mathbf 1}_{X_1} \\leq f</math> implies\n\n:<math> \\int_{X_1} f \\,d\\mu = \\int_{X_2} f\\cdot {\\mathbf 1}_{X_1} \\,d\\mu \\leq \\int_{X_2} f \\,d\\mu. </math>\n\n===Proof===\nThis proof does ''not'' rely on the [[monotone convergence theorem]]. However, we do explain how that theorem may be applied.\n\nFor those not interested in independent proof, the intermediate results below may be skipped.\n====Intermediate results====\n=====Lebesgue integral as measure=====\n'''Lemma 1.''' Let <math>(\\Omega,\\mathcal{F},\\mu)</math> be a measurable space. Consider a simple <math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable non-negative function <math>s:\\Omega\\to{\\mathbb R_{\\geq 0}}</math>. For a subset <math>S\\subseteq\\Omega</math>, define\n:<math>\\nu(S)=\\int_Ss\\,d\\mu</math>.\nThen <math>\\nu</math> is a measure on <math>\\Omega</math>.\n\n======Proof======\nWe will only prove countable additivity, leaving the rest up to the reader. Let\n<math>S=\\cup^\\infty_{i=1}S_i</math>, where all the sets <math>S_i</math> are pairwise disjoint. Due to simplicity,\n:<math>s=\\sum^n_{i=1}c_i\\cdot {\\mathbf 1}_{A_i}</math>,\nfor some finite non-negative constants <math>c_i\\in{\\mathbb R}_{\\geq 0}</math> and pairwise disjoint sets <math>A_i\\in\\mathcal{F}</math> such that <math>\\cup^n_{i=1}A_i=\\Omega</math>. By definition of Lebesgue integral,\n:<math>\n\\begin{align}\n\\nu(S)&=\\\\\n      &=\\sum^n_{i=1}c_i\\cdot\\mu(S\\cap A_i)\\\\\n      &=\\sum^n_{i=1}c_i\\cdot\\mu\\bigl((\\cup^\\infty_{j=1}S_j)\\cap A_i\\bigr)\\\\\n      &=\\sum^n_{i=1}c_i\\cdot\\mu\\bigl(\\cup^\\infty_{j=1}(S_j\\cap A_i)\\bigr)\n\\end{align}\n</math>\nSince all the sets <math>S_j\\cap A_i</math> are pairwise disjoint, the countable additivity of <math>\\mu</math>\ngives us\n:<math>\n\\sum^n_{i=1}c_i\\cdot\\mu\\bigl(\\cup^\\infty_{j=1}(S_j\\cap A_i)\\bigr)=\\sum^n_{i=1}c_i\\cdot\\sum^\\infty_{j=1}\\mu(S_j\\cap A_i).\n</math>\nSince all the summands are non-negative, the sum of the series, whether this sum is finite or infinite, cannot change if summation order does because the series is either absolutely convergent or diverges to <math> +\\infty. </math> For that reason,\n:<math>\n\\begin{align}\n\\sum^n_{i=1}c_i\\cdot\\sum^\\infty_{j=1}\\mu(S_j\\cap A_i)&=\\sum^\\infty_{j=1}\\sum^n_{i=1}c_i\\cdot\n\\mu(S_j\\cap A_i)\\\\\n&=\\sum^\\infty_{j=1}\\int_{S_j} s\\,d\\mu\\\\\n&=\\sum^\\infty_{j=1}\\nu(S_j),\n\\end{align}\n</math>\nas required.\n\n=====\"Continuity from below\"=====\nThe following property is a direct consequence of the definition of measure.\n\n'''Lemma 2.''' Let <math>\\mu</math> be a measure, and <math>S=\n\\cup^\\infty_{i=1}S_i</math>, where\n:<math>\nS_1\\subseteq\\ldots\\subseteq S_i\\subseteq S_{i+1}\\subseteq\\ldots\\subseteq S\n</math>\nis a non-decreasing chain with all its sets <math>\\mu</math>-measurable. Then\n:<math>\\mu(S)=\\lim_i\\mu(S_i)</math>.\n\n====Proof of theorem====\n'''Step 1.''' <math>g_n=g_n(x)</math> is <math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable, for every <math>n\\geq 1</math>.\n\nIndeed, since the Borel <math>\\sigma</math>-algebra on <math>\\R\\cup\\{\\pm\\infty\\}</math> is generated by the closed intervals <math>\\{[t, +\\infty]\\}_{-\\infty \\leq t \\leq +\\infty}</math>, it suffices to show that, <math>g^{-1}_n([t,+\\infty])\\in\\mathcal{F}</math>, for every <math>t\\in [-\\infty,+\\infty]</math>, where <math>g^{-1}_n([t,+\\infty])</math> denotes the inverse image of <math>[t,+\\infty]</math> under <math>g_n</math>.\n\nObserve that\n\n:<math>g_n(x)\\geq t\\quad\\Leftrightarrow\\quad\\Bigl(\\forall k\\geq n\\quad f_k(x)\\geq t\\Bigr)</math>,\n\nor equivalently,\n\n:<math>\\begin{align}\ng^{-1}_n([t,+\\infty])&=\\left\\{x\\in X\\mid g_n(x)\\geq t\\right\\}\\\\[3pt]\n                     &=\\bigcap_{k}\\left\\{x\\in X\\mid f_k(x)\\geq t\\right\\}\\\\[3pt]\n                     &=\\bigcap_{k} f^{-1}_k([t,+\\infty])\n\\end{align}</math>\n\nNote that every set on the right-hand side is from <math>\\mathcal{F}</math>. Since, by definition, <math>\\mathcal{F}</math> is closed under countable intersections, we conclude that the left-hand side is also a member of <math>\\mathcal{F}</math>. The <math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurability of <math>g_n</math> follows.\n\n'''Step 2.''' Now, we want to show that the function <math>f</math> is\n<math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable.\n\nIf we were to use the monotone convergence theorem, the measurability of <math>f</math> would follow easily from Remark 3.\n\nAlternatively, using the technique from Step 1, it is enough to verify that <math>f^{-1}([0,t])\\in\\mathcal{F}</math>, for every <math>t\\in [-\\infty,+\\infty]</math>. Since the sequence <math>\\{g_n(x)\\}</math> pointwise non-decreases (see Remark 3),  arguing as above, we get\n\n:<math>0\\leq f(x)\\leq t\\quad\\Leftrightarrow\\quad\\Bigl(\\forall n\\quad 0\\leq g_n(x)\\leq t\\Bigr)</math>.\n\nDue to the measurability of <math>g_n</math>, the above equivalency implies that\n\n:<math>f^{-1}([0,t])=\\bigcap_{n}g^{-1}_n([0,t])\\in\\mathcal{F}</math>.\n\n'''End of Step 2.'''\n\nThe proof can proceed in two ways.\n\n'''Proof using the monotone convergence theorem.''' By definition, <math>\\textstyle g_n(x)=\\inf_{k\\geq n}f_k(x)</math>, so we have <math>g_n\\leq f_n</math>, <math>\\forall n \\in \\N</math>, and furthermore the sequence <math>\\{g_n(x)\\}_n</math>is non-decreasing <math>\\forall x\\in X</math>. Recall that <math>f(x) =\\liminf_{n\\to\\infty} f_n(x) = \\lim_{n\\to \\infty} \\inf_{k\\geq n} f_k(x)</math>, and therefore:\n\n:<math>\\begin{align}\n\\int_X f\\,d\\mu&=\\int_X\\lim_n g_n\\,d\\mu\\\\\n              &=\\lim_n\\int_X g_n\\,d\\mu\\\\\n              &=\\liminf_n\\int_X g_n\\,d\\mu\\\\\n              &\\leq \\liminf_n\\int_X f_n\\,d\\mu,\n\\end{align}</math>\n\nas required.\n\n'''Independent proof.''' To prove the inequality ''without'' using the monotone convergence theorem, we need some extra machinery. Denote <math>\\operatorname{SF}(f)</math> the set of simple <math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable functions <math>s:X\\to [0,\\infty)</math> such that\n<math>0\\leq s\\leq f</math> on <math>X</math>.\n\n'''Step 3.''' Given a simple function <math>s\\in\\operatorname{SF}(f)</math> and a real number <math>t\\in (0,1)</math>, define\n\n:<math>B^{s,t}_k=\\{x\\in X\\mid t\\cdot s(x)\\leq g_k(x)\\}\\subseteq X.</math>\n\nThen <math>B^{s,t}_k\\in\\mathcal{F}</math>, <math>B^{s,t}_k\\subseteq B^{s,t}_{k+1}</math>, and <math>\\textstyle X=\\bigcup_k B^{s,t}_k</math>.\n\n'''Step 3a.''' To prove the first claim, let \n\n:<math>s=\\sum^m_{i=1}c_i\\cdot\\mathbf{1}_{A_i},</math>\n\nfor some finite collection of pairwise disjoint measurable sets <math>A_1,\\ldots,A_m\\in\\mathcal{F}</math> such that <math>\\textstyle X=\\cup^m_{i=1}A_i</math>, some (finite) real values <math>c_1, \\ldots, c_m</math>, and <math>\\mathbf{1}_{A_i}</math> denoting the indicator function of the set <math>A_i</math>. Then\n\n:<math>B^{s,t}_k=\\bigcup^m_{i=1}\\Bigl(g^{-1}_k\\Bigl([t\\cdot c_i,+\\infty]\\Bigr)\\cap A_i\\Bigr)</math>.\n\nSince the pre-image <math>g^{-1}_k\\Bigl([t\\cdot c_i,+\\infty]\\Bigr)</math> of the Borel set <math>[t\\cdot c_i,+\\infty]</math> under the measurable function <math>g_k</math> is measurable, and <math>\\sigma</math>-algebras, by definition, are closed under finite intersection and unions, the first claim follows.\n\n'''Step 3b.''' To prove the second claim, note that, for each <math>k</math> and every <math>x\\in X</math>, <math>g_k(x) \\leq g_{k+1}(x).</math>\n\n'''Step 3c.''' To prove the third claim, we show that <math>\\textstyle X\\subseteq\\bigcup_k B^{s,t}_k</math>.\n\nIndeed, if, to the contrary, <math>\\textstyle X\\not\\subseteq\\bigcup_k B^{s,t}_k</math>, then an element\n\n:<math>x_0\\in X\\setminus\\bigcup_k B^{s,t}_k=\\bigcap_k(X\\setminus B^{s,t}_k)</math>\n\nexists such that <math>g_k(x_0)<t\\cdot s(x_0)</math>, for every <math>k</math>. Taking the limit as <math>k\\to\\infty</math>, get\n\n:<math>f(x_0)\\leq t\\cdot s(x_0)<s(x_0).</math>\n\nBut by initial assumption, <math>s\\leq f</math>. This is a contradiction.\n\n'''Step 4.''' For every simple <math>(\\mathcal{F}, \\operatorname{\\mathcal B}_{\\R_{\\geq 0}})</math>-measurable non-negative function <math>s_2</math>,\n\n:<math>\\lim_n\\int_{B^{s,t}_n}s_2\\,d\\mu=\\int_Xs_2\\,d\\mu.</math>\n\nTo prove this, define <math>\\textstyle\\nu(S)=\\int_S s_2\\,d\\mu</math>. By Lemma 1, <math>\\nu(S)</math> is a measure on <math>\\Omega</math>. By \"continuity from below\" (Lemma 2),\n:<math>\\lim_n\\int_{B^{s,t}_n}s_2\\,d\\mu=\\lim_n\\nu(B^{s,t}_n)=\\nu(X)=\\int_Xs_2\\,d\\mu</math>,\nas required.\n\n'''Step 5.''' We now prove that, for every <math>s\\in\\operatorname{SF}(f)</math>,\n\n:<math>\\int_X s\\,d\\mu\\leq \\lim_k\\int_X g_k\\,d\\mu</math>.\n\nIndeed, using the definition of <math>B^{s,t}_k</math>, the non-negativity of <math>g_k</math>, and the monotonicity of Lebesgue integral, we have\n\n:<math>\\forall k \\geq 1 \\qquad \\int_{B^{s,t}_k}t\\cdot s\\,d\\mu\\leq \\int_{B^{s,t}_k} g_k\\,d\\mu\\leq \\int_X g_k\\,d\\mu</math>.\n\nIn accordance with Step 4, as <math>k\\to\\infty</math> the inequality becomes\n\n:<math>t\\int_X s\\,d\\mu\\leq\\lim_k\\int_X g_k\\,d\\mu</math>.\n\nTaking the limit as <math>t\\uparrow 1</math> yields\n\n:<math>\\int_X s\\,d\\mu\\leq\\lim_k\\int_X g_k\\,d\\mu</math>,\n\nas required.\n\n'''Step 6.''' To complete the proof, we apply the definition of Lebesgue integral to the inequality established in Step 5 and take into account that <math>g_n\\leq f_n</math>:\n\n:<math>\\begin{align}\n\\int_X f \\,d\\mu&=\\sup_{s\\in\\operatorname{SF}(f)}\\int_X s\\,d\\mu\\\\\n&\\leq\\lim_k\\int_X g_k\\,d\\mu\\\\\n&=\\liminf_k\\int_X g_k\\,d\\mu\\\\\n&\\leq\\liminf_k\\int_X f_k\\,d\\mu\n\\end{align}</math>\nThe proof is complete.\n\n==Examples for strict inequality==\nEquip the space <math>S</math> with the [[Borel algebra|Borel &sigma;-algebra]] and the [[Lebesgue measure]].\n* Example for a [[probability space]]: Let <math>S=[0,1]</math> denote the [[unit interval]]. For every [[natural number]] <math>n</math> define\n::<math>\nf_n(x)=\\begin{cases}n&\\text{for }x\\in (0,1/n),\\\\\n0&\\text{otherwise.}\n\\end{cases}</math>\n* Example with [[uniform convergence]]: Let <math>S</math> denote the set of all [[real number]]s. Define \n::<math>\nf_n(x)=\\begin{cases}\\frac1n&\\text{for }x\\in [0,n],\\\\\n0&\\text{otherwise.}\n\\end{cases}</math>\n\nThese sequences <math>(f_n)_{n\\in\\N}</math> converge on <math>S</math> pointwise (respectively uniformly) to the [[zero function]] (with zero integral), but every <math>f_n</math> has integral one.\n\n==The role of non-negativity==\nA suitable assumption concerning the negative parts of the sequence ''f''<sub>1</sub>, ''f''<sub>2</sub>, .&nbsp;.&nbsp;. of functions is necessary for Fatou's lemma, as the following example shows. Let ''S'' denote the half line [0,∞) with the Borel σ-algebra and the Lebesgue measure. For every natural number ''n'' define\n:<math>\nf_n(x)=\\begin{cases}-\\frac1n&\\text{for }x\\in [n,2n],\\\\\n0&\\text{otherwise.}\n\\end{cases}</math>\nThis sequence converges uniformly on ''S'' to the zero function (with zero integral) and for every ''x''&nbsp;≥&nbsp;0 we even have ''f<sub>n</sub>''(''x'')&nbsp;=&nbsp;0 for all ''n''&nbsp;>&nbsp;''x'' (so for every point ''x'' the limit 0 is reached in a finite number of steps). However, every function ''f<sub>n</sub>'' has integral &minus;1, hence the inequality in Fatou's lemma fails.\nAs shown below the problem is that there is no uniform integrable bound on the sequence from below, while 0 is the uniform bound from above.\n\n==Reverse Fatou lemma==\nLet ''f''<sub>1</sub>, ''f''<sub>2</sub>, .&nbsp;.&nbsp;. be a sequence of [[extended real number line|extended real]]-valued measurable functions defined on a measure space (''S'',''Σ'',''μ''). If there exists a non-negative integrable function ''g'' on ''S'' such that ''f''<sub>''n''</sub>&nbsp;≤&nbsp;''g'' for all ''n'', then\n:<math>\n\\limsup_{n\\to\\infty}\\int_S f_n\\,d\\mu\\leq\\int_S\\limsup_{n\\to\\infty}f_n\\,d\\mu.\n</math>\n\n'''Note:''' Here ''g&nbsp;integrable'' means that ''g'' is measurable and that <math>\\textstyle\\int_S g\\,d\\mu<\\infty</math>.\n\n===Sketch of proof===\nWe apply linearity of Lebesgue integral and Fatou's lemma to the sequence <math>g - f_n.</math>  Since <math>\\textstyle\\int_Sg\\,d\\mu < +\\infty,</math> this sequence is defined <math>\\mu</math>-almost everywhere and non-negative.\n\n==Extensions and variations of Fatou's lemma==\n\n===Integrable lower bound===\nLet ''f''<sub>1</sub>, ''f''<sub>2</sub>, .&nbsp;.&nbsp;. be a sequence of extended real-valued measurable functions defined on a measure space (''S'',''Σ'',''μ''). If there exists an integrable function ''g'' on ''S'' such that ''f''<sub>''n''</sub>&nbsp;≥&nbsp;&minus;''g'' for all ''n'', then\n:<math>\n\\int_S \\liminf_{n\\to\\infty} f_n\\,d\\mu\n \\le \\liminf_{n\\to\\infty} \\int_S f_n\\,d\\mu.\n</math>\n\n====Proof====\nApply Fatou's lemma to the non-negative sequence given by ''f''<sub>''n''</sub>&nbsp;+&nbsp;''g''.\n\n===Pointwise convergence===\nIf in the previous setting the sequence ''f''<sub>1</sub>, ''f''<sub>2</sub>, .&nbsp;.&nbsp;. [[Pointwise convergence|converges pointwise]] to a function ''f'' ''μ''-[[almost everywhere]] on ''S'', then\n:<math>\\int_S f\\,d\\mu \\le \\liminf_{n\\to\\infty} \\int_S f_n\\,d\\mu\\,.</math>\n\n====Proof====\nNote that ''f'' has to agree with the limit inferior of the functions ''f''<sub>''n''</sub> almost everywhere, and that the values of the integrand on a set of  measure zero have no influence on the value of the integral.\n\n===Convergence in measure===\nThe last assertion also holds, if the sequence ''f''<sub>1</sub>, ''f''<sub>2</sub>, .&nbsp;.&nbsp;. [[Convergence in measure|converges in measure]] to a function ''f''.\n\n====Proof====\nThere exists a subsequence such that\n:<math>\\lim_{k\\to\\infty} \\int_S f_{n_k}\\,d\\mu=\\liminf_{n\\to\\infty} \\int_S f_n\\,d\\mu.</math>\nSince this subsequence also converges in measure to ''f'', there exists a further subsequence, which converges pointwise to ''f'' almost everywhere, hence the previous variation of Fatou's lemma is applicable to this subsubsequence.\n\n===Fatou's Lemma with Varying Measures===\nIn all of the above statements of Fatou's Lemma, the integration was carried out with respect to a single fixed measure μ. Suppose that μ<sub>n</sub> is a sequence of measures on the measurable space (''S'',''Σ'') such that (see [[Convergence of measures]])\n:<math>\\mu_n(E)\\to \\mu(E),~\\forall E\\in \\mathcal{F}. </math>\nThen, with ''f<sub>n</sub>'' non-negative integrable functions and ''f'' being their pointwise limit inferior, we have\n:<math> \\int_S f\\,d\\mu \\leq \\liminf_{n\\to \\infty} \\int_S f_n\\, d\\mu_n. </math>\n\n:{| class=\"toccolours collapsible collapsed\" width=\"90%\" style=\"text-align:left\"\n!Proof\n|-\n|We will prove something a bit stronger here. Namely, we will allow ''f''<sub>n</sub> to converge μ-[[almost everywhere]] on a subset E of S. We seek to show that\n:<math>\n\\int_E f\\,d\\mu \\le \\liminf_{n\\to\\infty} \\int_E f_n\\,d\\mu_n\\,.\n</math>\nLet \n:<math> K=\\{x\\in E|f_n(x)\\rightarrow f(x)\\} </math>.\nThen ''μ(E-K)=0'' and \n:<math> \\int_{E}f\\,d\\mu=\\int_{E-K}f\\,d\\mu,~~~\\int_{E}f_n\\,d\\mu=\\int_{E-K}f_n\\,d\\mu ~\\forall n\\in \\N. </math>\nThus, replacing ''E'' by ''E-K'' we may assume that ''f''<sub>n</sub> converge to ''f'' [[pointwise convergence|pointwise]] on E. Next, note that for any simple function ''φ'' we have\n:<math> \\int_{E}\\phi\\, d\\mu=\\lim_{n\\to \\infty} \\int_{E} \\phi\\, d\\mu_n. </math>\nHence, by the definition of the Lebesgue Integral, it is enough to show that if ''φ'' is any non-negative simple function less than or equal to ''f,'' then \n:<math> \n\\int_{E}\\phi \\,d\\mu\\leq \\liminf_{n\\rightarrow \\infty} \\int_{E}f_n\\,d\\mu_n\n</math>\nLet ''a'' be the minimum non-negative value of ''φ.'' Define\n:<math> \nA=\\{x\\in E |\\phi(x)>a\\}\n</math>\n\nWe first consider the case when <math>\\int_{E}\\phi\\, d\\mu=\\infty</math>. \nWe must have that ''μ(A)'' is infinite since  \n:<math>\\int_{E}\\phi\\, d\\mu \\leq M\\mu(A),</math>\nwhere ''M'' is the (necessarily finite) maximum value of that ''φ'' attains.\n\nNext, we define\n:<math> \nA_n=\\{x\\in E |f_k(x)>a~\\forall k\\geq n \\}.\n</math>\nWe have that\n:<math> \nA\\subseteq \\bigcup_n A_n \\Rightarrow \\mu(\\bigcup_n A_n)=\\infty.\n</math>\nBut ''A<sub>n</sub>'' is a nested increasing sequence of functions and hence, by the continuity from below ''μ'',\n:<math> \n\\lim_{n\\rightarrow \\infty} \\mu(A_n)=\\infty.\n</math>.\nThus, \n:<math> \n\\lim_{n\\to\\infty}\\mu_n(A_n)=\\mu(A_n)=\\infty.\n</math>.\nAt the same time, \n:<math> \n\\int_E f_n\\, d\\mu_n \\geq a \\mu_n(A_n) \\Rightarrow \\liminf_{n\\to \\infty}\\int_E f_n \\, d\\mu_n = \\infty = \\int_E \\phi\\, d\\mu,\n</math>\nproving the claim in this case.\n\nThe remaining case is when <math>\\int_{E}\\phi\\, d\\mu<\\infty</math>. We must have that ''μ(A)'' is finite. Denote, as above, by ''M'' the maximum value of ''φ'' and fix ''ε>0.'' Define\n:<math> \nA_n=\\{x\\in E|f_k(x)>(1-\\epsilon)\\phi(x)~\\forall k\\geq n\\}.\n</math>\nThen ''A<sub>n</sub>'' is a nested increasing sequence of sets whose union contains ''A.'' Thus, ''A-A<sub>n</sub>'' is a decreasing sequence of sets with empty intersection. Since ''A'' has finite measure (this is why we needed to consider the two separate cases),\n:<math> \n\\lim_{n\\rightarrow \\infty} \\mu(A-A_n)=0.\n</math>\nThus, there exists n such that \n:<math> \n\\mu(A-A_k)<\\epsilon ,~\\forall k\\geq n.\n</math>\nTherefore, since\n:<math> \n\\lim_{n\\to \\infty} \\mu_n(A-A_k)=\\mu(A-A_k),\n</math>\nthere exists N such that \n:<math> \n\\mu_k(A-A_k)<\\epsilon,~\\forall k\\geq N.\n</math>\nHence, for <math>k\\geq N</math>\n:<math> \n\\int_E f_k \\, d\\mu_k \\geq \\int_{A_k}f_k \\, d\\mu_k \\geq (1-\\epsilon)\\int_{A_k}\\phi\\, d\\mu_k.\n</math>\nAt the same time, \n:<math> \n\\int_E \\phi \\, d\\mu_k = \\int_A \\phi \\, d\\mu_k = \\int_{A_k} \\phi \\, d\\mu_k + \\int_{A-A_k} \\phi \\, d\\mu_k.\n</math>\nHence, \n:<math> \n(1-\\epsilon)\\int_{A_k} \\phi \\, d\\mu_k \\geq (1-\\epsilon)\\int_E \\phi \\, d\\mu_k -  \\int_{A-A_k} \\phi \\, d\\mu_k.\n</math>\nCombining these inequalities gives that\n:<math> \n\\int_{E} f_k \\, d\\mu_k \\geq (1-\\epsilon)\\int_E \\phi \\, d\\mu_k -  \\int_{A-A_k} \\phi \\, d\\mu_k \\geq \\int_E \\phi \\, d\\mu_k -  \\epsilon\\left(\\int_{E} \\phi \\, d\\mu_k+M\\right).\n</math>\nHence, sending ''ε'' to 0 and taking the liminf in n, we get that\n:<math> \n\\liminf_{n\\rightarrow \\infty} \\int_{E} f_n \\, d\\mu_k \\geq \\int_E \\phi \\, d\\mu,\n</math>\ncompleting the proof.\n|}\n\n==Fatou's lemma for conditional expectations==\nIn [[probability theory]], by a change of notation, the above versions of Fatou's lemma are applicable to sequences of [[random variables]] ''X''<sub>1</sub>, ''X''<sub>2</sub>, .&nbsp;.&nbsp;. defined on a [[probability space]] <math>\\scriptstyle(\\Omega,\\,\\mathcal F,\\,\\mathbb P)</math>; the integrals turn into [[expected value|expectation]]s. In addition, there is also a version for [[conditional expectation]]s.\n\n===Standard version===\nLet ''X''<sub>1</sub>, ''X''<sub>2</sub>, .&nbsp;.&nbsp;. be a sequence of non-negative random variables on a probability space <math>\\scriptstyle(\\Omega,\\mathcal F,\\mathbb P)</math> and let\n<math>\\scriptstyle \\mathcal G\\,\\subset\\,\\mathcal F</math> be a sub-[[σ-algebra]]. Then\n:<math>\\mathbb{E}\\Bigl[\\liminf_{n\\to\\infty}X_n\\,\\Big|\\,\\mathcal G\\Bigr]\\le\\liminf_{n\\to\\infty}\\,\\mathbb{E}[X_n|\\mathcal G]</math>&nbsp;&nbsp;&nbsp;[[almost surely]].\n\n'''Note:''' Conditional expectation for non-negative random variables is always well defined, finite expectation is not needed.\n\n====Proof====\nBesides a change of notation, the proof is very similar to the one for the standard version of Fatou's lemma above, however the [[monotone convergence theorem|monotone convergence theorem for conditional expectations]] has to be applied.\n\nLet ''X'' denote the limit inferior of the ''X''<sub>''n''</sub>. For every natural number ''k'' define pointwise the random variable\n:<math>Y_k=\\inf_{n\\ge k}X_n.</math>\nThen the sequence ''Y''<sub>1</sub>,  ''Y''<sub>2</sub>, .&nbsp;.&nbsp;. is increasing and converges pointwise to ''X''.\nFor ''k''&nbsp;≤&nbsp;''n'', we have ''Y''<sub>''k''</sub>&nbsp;≤&nbsp;''X''<sub>''n''</sub>, so that\n:<math>\\mathbb{E}[Y_k|\\mathcal G]\\le\\mathbb{E}[X_n|\\mathcal G]</math>&nbsp;&nbsp;&nbsp;almost surely\nby the [[Conditional expectation#Basic properties|monotonicity of conditional expectation]], hence\n:<math>\\mathbb{E}[Y_k|\\mathcal G]\\le\\inf_{n\\ge k}\\mathbb{E}[X_n|\\mathcal G]</math>&nbsp;&nbsp;&nbsp;almost surely,\nbecause the countable union of the exceptional sets of probability zero is again a [[null set]].\nUsing the definition of ''X'', its representation as pointwise limit of the ''Y''<Sub>''k''</sub>, the monotone convergence theorem for conditional expectations, the last inequality, and the definition of the limit inferior, it follows that almost surely\n:<math>\n\\begin{align}\n\\mathbb{E}\\Bigl[\\liminf_{n\\to\\infty}X_n\\,\\Big|\\,\\mathcal G\\Bigr]\n&=\\mathbb{E}[X|\\mathcal G]\n=\\mathbb{E}\\Bigl[\\lim_{k\\to\\infty}Y_k\\,\\Big|\\,\\mathcal G\\Bigr]\n=\\lim_{k\\to\\infty}\\mathbb{E}[Y_k|\\mathcal G]\\\\\n&\\le\\lim_{k\\to\\infty} \\inf_{n\\ge k}\\mathbb{E}[X_n|\\mathcal G]\n=\\liminf_{n\\to\\infty}\\,\\mathbb{E}[X_n|\\mathcal G].\n\\end{align}\n</math>\n\n===Extension to uniformly integrable negative parts===\nLet ''X''<sub>1</sub>, ''X''<sub>2</sub>, .&nbsp;.&nbsp;. be a sequence of random variables on a probability space <math>\\scriptstyle(\\Omega,\\mathcal F,\\mathbb P)</math> and let\n<math>\\scriptstyle \\mathcal G\\,\\subset\\,\\mathcal F</math> be a sub-[[σ-algebra]]. If the negative parts\n\n:<math>X_n^-:=\\max\\{-X_n,0\\},\\qquad n\\in{\\mathbb N},</math>\n\nare uniformly integrable with respect to the conditional expectation, in the sense that, for ''ε''&nbsp;>&nbsp;0 there exists a ''c''&nbsp;>&nbsp;0 such that\n\n:<math>\\mathbb{E}\\bigl[X_n^-1_{\\{X_n^->c\\}}\\,|\\,\\mathcal G\\bigr]<\\varepsilon,  \n\\qquad\\text{for all }n\\in\\mathbb{N},\\,\\text{almost surely}</math>, \nthen\n\n:<math>\\mathbb{E}\\Bigl[\\liminf_{n\\to\\infty}X_n\\,\\Big|\\,\\mathcal G\\Bigr]\\le\\liminf_{n\\to\\infty}\\,\\mathbb{E}[X_n|\\mathcal G]</math>&nbsp;&nbsp;&nbsp;almost surely.\n\n'''Note:''' On the set where\n\n:<math>X:=\\liminf_{n\\to\\infty}X_n</math>\n\nsatisfies\n\n:<math>\\mathbb{E}[\\max\\{X,0\\}\\,|\\,\\mathcal G]=\\infty,</math>\n\nthe left-hand side of the inequality is considered to be plus infinity. The conditional expectation of the limit inferior might not be well defined on this set, because the conditional expectation of the negative part might also be plus infinity.\n\n====Proof====\nLet ''ε''&nbsp;>&nbsp;0. Due to uniform integrability with respect to the conditional expectation, there exists a ''c''&nbsp;>&nbsp;0 such that\n\n:<math>\\mathbb{E}\\bigl[X_n^-1_{\\{X_n^->c\\}}\\,|\\,\\mathcal G\\bigr]<\\varepsilon\n\\qquad\\text{for all }n\\in\\mathbb{N},\\,\\text{almost surely}.</math>\n\nSince\n\n:<math>X+c\\le\\liminf_{n\\to\\infty}(X_n+c)^+,</math>\n\nwhere ''x''<sup>+</sup> := max{''x'',0} denotes the positive part of a real ''x'', monotonicity of conditional expectation (or the above convention) and the standard version of Fatou's lemma for conditional expectations imply\n\n:<math>\\mathbb{E}[X\\,|\\,\\mathcal G]+c\n\\le\\mathbb{E}\\Bigl[\\liminf_{n\\to\\infty}(X_n+c)^+\\,\\Big|\\,\\mathcal G\\Bigr]\n\\le\\liminf_{n\\to\\infty}\\mathbb{E}[(X_n+c)^+\\,|\\,\\mathcal G]</math>&nbsp;&nbsp;&nbsp;almost surely.\n\nSince\n\n:<math>(X_n+c)^+=(X_n+c)+(X_n+c)^-\\le X_n+c+X_n^-1_{\\{X_n^->c\\}},</math>\n\nwe have\n\n:<math>\\mathbb{E}[(X_n+c)^+\\,|\\,\\mathcal G]\n\\le\\mathbb{E}[X_n\\,|\\,\\mathcal G]+c+\\varepsilon</math>&nbsp;&nbsp;&nbsp;almost surely,\n\nhence\n\n:<math>\\mathbb{E}[X\\,|\\,\\mathcal G]\\le\n\\liminf_{n\\to\\infty}\\mathbb{E}[X_n\\,|\\,\\mathcal G]+\\varepsilon</math>&nbsp;&nbsp;&nbsp;almost surely.\n\nThis implies the assertion.\n\n==References==\n* {{cite book |first=N. L. |last=Carothers |title=Real Analysis |location=New York |publisher=Cambridge University Press |year=2000 |isbn=0-521-49756-6 |pages=321–22 |url=https://books.google.com/books?id=4VFDVy1NFiAC&pg=PA321 }}\n*{{cite book\n | last = Royden\n | first = H. L.\n | title = Real Analysis\n | edition = 3rd\n | location = London\n | publisher = Collier Macmillan\n | year = 1988\n | isbn = 0-02-404151-3\n}}\n* {{cite book |first=Alan J. |last=Weir |title=Lebesgue Integration and Measure |location=Cambridge |publisher=Cambridge University Press |year=1973 |pages=93–118 |chapter=The Convergence Theorems |isbn=0-521-08728-7 }}\n\n==External links==\n*{{planetmath reference|id=3678|title=Fatou's lemma}}\n\n[[Category:Inequalities]]\n[[Category:Lemmas]]\n[[Category:Theorems in measure theory]]\n[[Category:Real analysis]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Fekete–Szegő inequality",
      "url": "https://en.wikipedia.org/wiki/Fekete%E2%80%93Szeg%C5%91_inequality",
      "text": "In mathematics, the '''Fekete–Szegő inequality''' is an inequality for the coefficients of [[univalent function|univalent]] [[analytic functions]] found by {{harvs|txt|last=Fekete|authorlink=Michael Fekete|last2=Szegő|author2-link=Gábor Szegő|year=1933}}, related to the [[Bieberbach conjecture]]. Finding similar estimates for other classes of functions is called the '''Fekete–Szegő problem'''.\n\nThe Fekete–Szegő inequality states that if\n\n:<math>f(z)=z+a_2z^2+a_3z^3+\\cdots</math>\n\nis a univalent analytic function on  the unit disk and 0&nbsp;≤&nbsp;λ&nbsp;<&nbsp;1, then\n\n:<math>|a_3-\\lambda a_2^2|\\leq 1+2\\exp(-2\\lambda /(1-\\lambda)).</math>\n\n==References==\n*{{Citation | last1=Fekete | first1=M. | author1-link=Michael Fekete | last2=Szegő | first2=G. | author2-link=Gábor Szegő | title= Eine Bemerkung über ungerade schlichte Funktionen | doi=10.1112/jlms/s1-8.2.85  | year=1933 | volume=8 | pages=85–89}}\n\n{{DEFAULTSORT:Fekete-Szego inequality}}\n[[Category:Inequalities]]"
    },
    {
      "title": "Fischer's inequality",
      "url": "https://en.wikipedia.org/wiki/Fischer%27s_inequality",
      "text": "{{about|determinants of matrices|statistical block design theory|Fisher's inequality}}\n{{short description|mathematical bound}}\n\nIn [[mathematics]], '''Fischer's inequality''' gives an upper bound for the [[determinant]] of a [[Positive-definite matrix | positive-semidefinite matrix]] whose entries are complex numbers in terms of the determinants of its principal diagonal blocks. \nSuppose ''A'', ''C'' are respectively ''p''&times;''p'', ''q''&times;''q'' positive-semidefinite complex matrices and ''B'' is a ''p''&times;''q'' complex matrix.\nLet \n:<math>M := \\left[\\begin{matrix} A & B \\\\ B^* & C \\end{matrix}\\right]</math> \nso that ''M'' is a (''p''+''q'')&times;(''p''+''q'') matrix.\n\nThen Fischer's inequality states that \n:<math> \\det (M) \\le \\det(A) \\det(C).</math> \nIf ''M'' is positive-definite, equality is achieved in Fischer's inequality if and only if all the entries of ''B'' are 0. Inductively one may conclude that a similar inequality holds for a block decomposition of ''M'' with multiple principal diagonal blocks. Considering 1&times;1 blocks, a corollary is [[Hadamard's inequality]].\n\n==Proof==\nAssume that ''A'' and ''C'' are positive-definite. We have <math>A^{-1}</math> and <math>C^{-1}</math> are positive-definite. Let \n:<math>D := \\left[\\begin{matrix} A & 0 \\\\ 0 & C \\end{matrix}\\right].</math> \nWe note that\n:<math>D^{-\\frac{1}{2}} M D^{-\\frac{1}{2} } = \\left[\\begin{matrix} A^{-\\frac{1}{2}} & 0 \\\\ 0 & C^{-\\frac{1}{2}} \\end{matrix}\\right] \\left[\\begin{matrix} A & B \\\\ B^* & C \\end{matrix}\\right] \\left[\\begin{matrix} A^{-\\frac{1}{2}} & 0 \\\\ 0 & C^{-\\frac{1}{2}} \\end{matrix}\\right] = \\left[\\begin{matrix} I_{p} & A^{\\frac{1}{2}} BC^{-\\frac{1}{2}} \\\\ C^{-\\frac{1}{2}}B^*A^{-\\frac{1}{2}} & I_{q}\\end{matrix}\\right]</math>\nApplying the [[inequality of arithmetic and geometric means | AM-GM inequality]] to the eigenvalues of <math>D^{-\\frac{1}{2}} M D^{-\\frac{1}{2} }</math>, we see\n:<math>\\det (D^{-\\frac{1}{2}} M D^{-\\frac{1}{2}}) \\le \\left({1 \\over p + q} \\mathrm{tr} (D^{-\\frac{1}{2}} M D^{-\\frac{1}{2}}) \\right)^{p+q} = 1^{p+q} = 1.</math>\nBy multiplicativity of [[determinant]], we have \n:<math>\n\\begin{align}\n\\det(D^{-\\frac{1}{2}} ) \\det(M) \\det(D^{-\\frac{1}{2}} ) \\le 1 \\\\\n\\Longrightarrow \\det(M) \\le \\det(D) = \\det(A) \\det(C).\n\\end{align}</math>\nIn this case, equality holds if and only if ''M'' = ''D'' that is, all entries of ''B'' are 0.\n\nFor <math>\\varepsilon > 0</math>, as <math>A + \\varepsilon I_p</math> and <math>C + \\varepsilon I_q</math> are positive-definite, we have \n:<math>\\det(M+ \\varepsilon I_{p+q}) \\le \\det(A + \\varepsilon I_p) \\det(C + \\varepsilon I_q).</math>\n\nTaking the limit as <math>\\varepsilon \\rightarrow 0</math> proves the inequality. From the inequality we note that if ''M'' is invertible, then both ''A'' and ''C'' are invertible and we get the desired equality condition.\n\n== Improvements ==\nIf ''M'' can be partitioned in square blocks ''M<sub>ij</sub>'', then the following inequality by Thompson is valid:<ref>{{Cite journal|last=Thompson|first=R. C.|title=A determinantal inequality for positive definite matrices|url=https://doi.org/10.4153/cmb-1961-010-9|journal=Canadian Mathematical Bulletin|volume=4|issue=0|pages=57–62|doi=10.4153/cmb-1961-010-9}}</ref>\n\n: <math>\\det(M) \\le \\det([\\det(M_{ij})])  </math>\n\nwhere [det(''M<sub>ij</sub>'')] is the matrix whose (''i'',''j'') entry is det(''M<sub>ij</sub>'').\n\nIn particular, if the block matrices ''B'' and ''C'' are also square matrices, then the following inequality by Everett is valid:<ref>{{Cite journal|last=Everitt|first=W. N.|title=A note on positive definite matrices|url=https://www.cambridge.org/core/journals/glasgow-mathematical-journal/article/note-on-positive-definite-matrices/B3561E2DD3457ADF41C49D744AA9F089|journal=Glasgow Mathematical Journal|volume=3|issue=4|pages=173–175|doi=10.1017/S2040618500033670|issn=2051-2104}}</ref>\n\n: <math>\\det(M) \\le \\det \\begin{bmatrix} \\det(A) && \\det(B) \\\\ \\det(B^*) && \\det(D) \\end{bmatrix}</math>\n\nThompson's inequality can also be generalized by an inequality in terms of the coefficients of the [[characteristic polynomial]] of the block matrices. Expressing the characteristic polynomial of the matrix ''A'' as\n\n: <math>p_A (t) = \\sum_{k=0}^n t^{n-k} (-1)^k \\operatorname{tr}(\\Lambda^k A)</math>\n\nand supposing that the blocks ''M<sub>ij</sub>'' are ''m'' x ''m'' matrices, the following inequality by Lin and Zhang is valid:<ref>{{Cite journal|last=Lin|first=Minghua|last2=Zhang|first2=Pingping|title=Unifying a result of Thompson and a result of Fiedler and Markham on block positive definite matrices|url=https://doi.org/10.1016/j.laa.2017.07.032|journal=Linear Algebra and its Applications|volume=533|pages=380–385|doi=10.1016/j.laa.2017.07.032}}</ref>\n\n: <math>\\det(M) \\le \\left(\\frac{\\det([\\operatorname{tr}(\\Lambda^r M_{ij}]))}{ \\binom{m}r} \\right)^{\\frac{m}{r}},\\quad r=1, \\ldots, m</math>\n\nNote that if ''r'' = ''m'', then this inequality is identical to Thompson's inequality.\n\n==See also==\n* [[Hadamard's inequality]]\n* [[Koteljanskii's inequality]]\n\n== Notes ==\n{{Reflist}}\n\n==References==\n\n* {{citation\n | last = Fischer | first = Ernst | authorlink = Ernst Sigismund Fischer\n | journal = Arch. Math. u. Phys. (3)\n | pages = 32–40\n | title = Über den Hadamardschen Determinentsatz\n | volume = 13\n | year = 1907}}.\n* {{citation\n | last = Horn | first = Roger A. | last2 = Johnson | first2 = Charles R.\n | title=Matrix Analysis\n | url=https://doi.org/10.1017/cbo9781139020411}}.\n\n{{DEFAULTSORT:Fischer's Inequality}}\n[[Category:Inequalities]]\n[[Category:Determinants]]"
    },
    {
      "title": "Fishburn–Shepp inequality",
      "url": "https://en.wikipedia.org/wiki/Fishburn%E2%80%93Shepp_inequality",
      "text": "In [[combinatorics|combinatorial]] mathematics, the '''Fishburn–Shepp inequality''' is an inequality for the number of extensions of [[partial order]]s to [[linear order]]s, found by {{harvtxt|Fishburn|1984}} and {{harvtxt|Shepp|1982}}.  \n\nIt states that if ''x'', ''y'', and ''z'' are incomparable elements of a finite [[poset]], then;-\n\n:<math> P(x<y)P(x<z) \\leqslant P((x<y) \\wedge (x<z))</math>\n\nwhere ''P''(*) is the probability that a linear order < extending the partial order has the property *. \n\nIn other words the probability that ''x''&nbsp;<&nbsp;''z'' strictly increases if one adds the condition that ''x''&nbsp;<&nbsp;''y''.  In the language of [[conditional probability]],\n\n: <math> P(x < z) < P(x < z \\mid x < y).</math>\n\nThe proof uses the [[Ahlswede–Daykin inequality]].\n\n==References==\n*{{Citation | authorlink=Peter Fishburn | last1=Fishburn | first1=Peter C. | title=A correlational inequality for linear extensions of a poset | doi=10.1007/BF00565648 | mr=764320  | year=1984 | journal=Order | issn=0167-8094 | volume=1 | issue=2 | pages=127–137}}\n*{{springer|id=f/f110080|first=P.C. |last=Fishburn|first2=L.A.|last2= Shepp}}\n*{{Citation | doi=10.1214/aop/1176993791 | authorlink=Lawrence Alan Shepp | last1=Shepp | first1=L. A. | title=The XYZ conjecture and the FKG inequality | jstor=2243391 | mr=659563  | year=1982 | journal=The Annals of Probability | issn=0091-1798 | volume=10 | issue=3 | pages=824–827 | publisher=Institute of Mathematical Statistics}}\n\n{{DEFAULTSORT:Fishburn-Shepp inequality}}\n[[Category:Inequalities]]\n[[Category:Combinatorics]]\n[[Category:Independence (probability theory)]]"
    },
    {
      "title": "FKG inequality",
      "url": "https://en.wikipedia.org/wiki/FKG_inequality",
      "text": "In mathematics, the '''Fortuin–Kasteleyn–Ginibre (FKG) inequality''' is a [[correlation]] inequality, a fundamental tool in [[statistical mechanics]] and [[Combinatorics#Probabilistic combinatorics|probabilistic combinatorics]] (especially [[random graph]]s and the [[probabilistic method]]), due to {{harvs | last1=Fortuin | author1-link=Cees M. Fortuin | first1=Cees M. | last2=Kasteleyn | author2-link=Pieter Kasteleyn | first2=Pieter W. | last3=Ginibre | author3-link=Jean Ginibre | first3=Jean | title=Correlation inequalities on some partially ordered sets | url=http://projecteuclid.org/euclid.cmp/1103857443 | mr=0309498 | year=1971 | journal=Communications in Mathematical Physics   | volume=22 | pages=89–103|txt}}. Informally, it says that in many random systems, increasing events are positively correlated, while an increasing and a decreasing event are negatively correlated. It was obtained by studying the [[random cluster model]].\n\nAn earlier version, for the special case of [[i.i.d.]] variables, called '''Harris inequality''', is due to {{harvs|last=[[Ted Harris (mathematician)|Harris]] |first=Theodore Edward|year=1960|txt}}, see [[#A special case: the Harris inequality|below]]. One generalization of the FKG inequality is the [[#A generalization: the Holley inequality|Holley inequality (1974)]] below, and an even further generalization is the [[Ahlswede–Daykin inequality|Ahlswede–Daykin \"four functions\" theorem (1978)]]. Furthermore, it has the same conclusion as the [[Griffiths inequalities]], but the hypotheses are different.\n\n==The inequality==\nLet <math>X</math> be a finite [[distributive lattice]], and ''μ'' a nonnegative function on it, that is assumed to satisfy the ('''FKG''') '''lattice condition''' (sometimes a function satisfying this condition is called '''log supermodular''') i.e.,\n:<math>\\mu(x\\wedge y)\\mu(x\\vee y) \\ge \\mu(x)\\mu(y)</math>\nfor all ''x'', ''y'' in the lattice <math>X</math>.\n\nThe FKG inequality then says that for any two monotonically increasing functions ''ƒ'' and ''g'' on <math>X</math>, the following positive correlation inequality holds:\n:<math> \\left(\\sum _{x\\in X}f(x)g(x)\\mu(x)\\right)\\left(\\sum _{x\\in X}\\mu(x)\\right) \\ge \\left(\\sum _{x\\in X}f(x)\\mu(x)\\right)\\left(\\sum _{x\\in X}g(x)\\mu(x)\\right).</math>\n\nThe same inequality (positive correlation) is true when both ''ƒ'' and ''g'' are decreasing.  If one is increasing and the other is decreasing, then they are negatively correlated and the above inequality is reversed.\n\nSimilar statements hold more generally, when <math>X</math> is not necessarily finite, not even countable. In that case, ''μ'' has to be a finite measure, and the lattice condition has to be defined using [[cylinder (algebra)|cylinder]] events; see, e.g., Section 2.2 of {{harvtxt|Grimmett|1999}}.\n\nFor proofs, see the original {{harvtxt|Fortuin|Kasteleyn|Ginibre|1971}} or the [[Ahlswede–Daykin inequality|Ahlswede–Daykin inequality (1978)]]. Also, a rough sketch is given below, due to {{harvtxt|Holley|1974}}, using a [[Markov chain]] [[coupling (probability)|coupling]] argument.\n\n==Variations on terminology==\n\nThe lattice condition for ''μ'' is also called '''multivariate total positivity''', and sometimes the '''strong FKG condition'''; the term ('''multiplicative''') '''FKG condition''' is also used in older literature.\n\nThe property of ''μ'' that increasing functions are positively correlated is also called having '''positive associations''', or the '''weak FKG condition'''.\n\nThus, the FKG theorem can be rephrased as \"the strong FKG condition implies the weak FKG condition\".\n\n==A special case: the Harris inequality==\n\nIf the lattice <math>X</math> is [[totally ordered]], then the lattice condition is satisfied trivially for any measure ''μ''. For this case, the FKG inequality is [[Chebyshev's sum inequality]]: if the two increasing functions take on values <math>a_1\\leq a_2 \\leq \\cdots \\leq a_n</math> and <math>b_1\\leq b_2 \\leq \\cdots \\leq b_n</math>,  then (we may assume that the measure ''μ'' is uniform) \n:<math>\\frac{a_1b_1+\\cdots+a_nb_n}{n} \\geq \\frac{a_1+\\cdots+a_n}{n} \\; \\frac{b_1+\\cdots+b_n}{n}.</math>\n\nMore generally, for any probability measure ''μ'' on <math>\\R</math> and increasing functions ''ƒ'' and ''g'', \n:<math> \\int_\\R f(x)g(x) \\,d\\mu(x) \\geq \\int_\\R f(x)\\,d\\mu(x) \\, \\int_\\R g(x)\\,d\\mu(x),</math>\nwhich follows immediately from\n:<math>\\int_\\R\\int_\\R [f(x)-f(y)][g(x)-g(y)]\\,d\\mu(x)\\,d\\mu(y) \\geq 0.</math>\n\nThe lattice condition is trivially satisfied also when the lattice is the product of totally ordered lattices, <math>X=X_1\\times\\cdots\\times X_n</math>, and <math>\\mu=\\mu_1\\otimes\\cdots\\otimes\\mu_n</math> is a product measure. Often all the factors (both the lattices and the measures) are identical, i.e., ''μ'' is the probability distribution of [[i.i.d.]] random variables.\n\nThe FKG inequality for the case of a product measure is known also as  the '''Harris inequality''' after [[Ted Harris (mathematician)|Harris]]  {{harv|Harris|1960}}, who found and used it in his study of [[percolation theory|percolation]] in the plane.  A proof of the Harris inequality that uses the above double integral trick on <math>\\R</math> can be found, e.g., in Section 2.2 of {{harvtxt|Grimmett|1999}}.\n\n===Simple examples===\n\nA typical example is the following. Color each hexagon of the infinite [[honeycomb lattice]] black with probability <math>p</math> and white with probability <math>1-p</math>, independently of each other. Let ''a, b, c, d'' be four hexagons, not necessarily distinct. Let <math>a \\leftrightarrow b</math> and <math>c\\leftrightarrow d</math> be the events that there is a black path from ''a'' to ''b'', and a black path from ''c'' to ''d'', respectively. Then the Harris inequality says that these events are positively correlated: <math>\\Pr(a \\leftrightarrow b,\\ c\\leftrightarrow d) \\geq \\Pr(a \\leftrightarrow b)\\Pr(c\\leftrightarrow d)</math>. In other words, assuming the presence of one path can only increase the probability of the other.\n\nSimilarly, if we randomly color the hexagons inside an <math>n\\times n</math> rhombus-shaped [[hex (board game)|hex board]], then the events that there is black crossing from the left side of the board to the right side is positively correlated with having a black crossing  from the top side to the bottom. On the other hand, having a left-to-right black crossing is negatively correlated with having a top-to-bottom white crossing, since the first is an increasing event (in the amount of blackness), while the second is decreasing. In fact, in any coloring of the hex board exactly one of these two events happen — this is why hex is a well-defined game.\n\nIn the [[Erdos–Renyi model|Erdős–Rényi random graph]], the existence of a [[Hamiltonian cycle]] is negatively correlated with the [[graph coloring|3-colorability of the graph]], since the first is an increasing event, while the latter is decreasing.\n\n==Examples from statistical mechanics==\nIn statistical mechanics, the usual source of measures that satisfy the lattice condition (and hence the FKG inequality) is the following:\n\nIf <math>S</math> is an ordered set (such as <math>\\{-1,+1\\}</math>), and <math>\\Gamma</math> is a finite or infinite [[Graph (discrete mathematics)|graph]], then the set <math>S^\\Gamma</math> of <math>S</math>-valued configurations is a [[poset]] that is a distributive lattice.\n\nNow, if <math>\\Phi</math> is a '''submodular [[Gibbs measure|potential]]''' (i.e., a family of functions\n:<math>\\Phi_\\Lambda: S^\\Lambda \\longrightarrow \\R\\cup\\{\\infty\\},</math>\none for each finite <math>\\Lambda \\subset \\Gamma</math>, such that each <math>\\Phi_\\Lambda</math> is [[submodular]]), then one defines the corresponding [[Gibbs measure|Hamiltonian]]s as\n:<math>H_\\Lambda(\\varphi):=\\sum_{\\Delta\\cap\\Lambda\\not=\\emptyset} \\Phi_\\Delta(\\varphi).</math>\n\nIf ''μ'' is an [[Gibbs measure|extremal Gibbs measure]] for this Hamiltonian on the set of configurations <math>\\varphi</math>, then it is easy to show that ''μ'' satisfies the lattice condition, see {{harvtxt|Sheffield|2005}}.\n\nA key example is the [[Ising model]] on a graph <math>\\Gamma</math>. Let <math>S=\\{-1,+1\\}</math>, called spins, and <math>\\beta\\in [0,\\infty]</math>. Take the following potential:\n\n:<math>\\Phi_\\Lambda(\\varphi)=\\begin{cases} \n\\beta 1_{\\{\\varphi(x)\\not=\\varphi(y)\\}} & \\text{if }\\Lambda=\\{x,y\\}\\text{ is a pair of adjacent vertices of }\\Gamma;\\\\\n0 & \\text{otherwise.}\\end{cases}\n</math>\n\nSubmodularity is easy to check; intuitively, taking the min or the max of two configurations tends to decrease the number of disagreeing spins. Then, depending on the graph <math>\\Gamma</math> and the value of <math>\\beta</math>, there could be one or more extremal Gibbs measures, see, e.g., {{harvtxt|Georgii|Häggström|Maes|2001}} and {{harvtxt|Lyons|2000}}.\n\n==A generalization: the Holley inequality==\n\nThe '''Holley inequality''', due to {{harvs|last=Holley|first=Richard|year=1974|txt}}, states that the [[expected value|expectations]]\n:<math> \\langle f\\rangle_i = \\frac{\\sum _{x\\in X}f(x)\\mu_i(x)}{\\sum_{x\\in X}\\mu_i(x)} </math>\n\nof a monotonically increasing function ''ƒ'' on a finite [[distributive lattice]] <math>X</math> with respect to two positive functions ''μ''<sub>1</sub>, ''μ''<sub>2</sub> on the lattice  satisfy the condition\n\n:<math> \\langle f\\rangle_1 \\ge \\langle f\\rangle_2, </math>\n\nprovided the functions satisfy the '''Holley condition''' ('''criterion''')\n\n:<math>\\mu_2(x\\wedge y)\\mu_1(x\\vee y) \\ge \\mu_1(x)\\mu_2(y)</math>\n\nfor all ''x'', ''y'' in the lattice.\n\nTo recover the [[#The inequality|FKG inequality]]: If ''μ'' satisfies the lattice condition and ''ƒ'' and ''g'' are increasing functions on <math>X</math>, then ''μ''<sub>1</sub>(''x'')&nbsp;=&nbsp;''g''(''x'')''μ''(''x'')  and ''μ''<sub>2</sub>(''x'')&nbsp;=&nbsp;''μ''(''x'') will satisfy the lattice-type condition of the Holley inequality. Then the Holley inequality states that\n\n:<math> \\frac{ \\langle fg\\rangle_\\mu }{\\langle g\\rangle_\\mu} = \\langle f\\rangle_1 \\ge \\langle f\\rangle_2 =\\langle f\\rangle_\\mu, </math>\n\nwhich is just the FKG inequality.\n\nAs for FKG, the Holley inequality follows from the [[Ahlswede–Daykin inequality]].\n\n==Weakening the lattice condition: monotonicity==\nConsider the usual case of <math>X</math> being a product <math>\\R^V</math> for some finite set <math>V</math>. The lattice condition on ''μ'' is easily seen to imply the following '''monotonicity''', which has the virtue that it is often easier to check than the lattice condition:\n\nWhenever one fixes a vertex <math>v \\in V</math> and two configurations ''φ'' and ''ψ'' outside ''v'' such that <math>\\varphi(w) \\geq \\psi(w)</math> for all <math>w\\not=v</math>, the ''μ''-conditional distribution of ''φ''(''v'') given <math>\\{\\varphi(w) : w\\not=v\\}</math> [[stochastic ordering|stochastically dominates]] the ''μ''-conditional distribution of ''ψ''(''v'') given <math>\\{\\psi(w) : w\\not=v\\}</math>.\n\nNow, if ''μ'' satisfies this monotonicity property, that is already enough for the FKG inequality (positive associations) to hold.\n\nHere is a rough sketch of the proof, due to {{harvtxt|Holley|1974}}: starting from any initial configuration on <math>V</math>, one can run a simple [[Markov chain]] (the [[Metropolis algorithm]]) that uses independent Uniform[0,1] random variables to update the configuration in each step, such that the chain has a unique stationary measure, the given ''μ''. The monotonicity of ''μ'' implies that the configuration at each step is a monotone function of independent variables, hence the [[#A special case: the Harris inequality|product measure version of Harris]] implies that it has positive associations. Therefore, the limiting stationary measure ''μ'' also has this property.\n\nThe monotonicity property has a natural version for two measures, saying that ''μ''<sub>1</sub> conditionally pointwise dominates ''μ''<sub>2</sub>. It is again easy to see that if ''μ''<sub>1</sub> and ''μ''<sub>2</sub> satisfy the lattice-type condition of the [[#A generalization: the Holley inequality|Holley inequality]], then  ''μ''<sub>1</sub> conditionally pointwise dominates ''μ''<sub>2</sub>. On the other hand, a Markov chain [[coupling (probability)|coupling]] argument similar to the above, but now without invoking the Harris inequality, shows that conditional pointwise domination, in fact,  implies [[stochastic ordering|stochastically domination]]. Stochastic domination is equivalent to saying that <math> \\langle f\\rangle_1 \\ge \\langle f\\rangle_2</math> for all increasing ''ƒ'', thus we get a proof of the Holley inequality. (And thus also a proof of the FKG inequality, without using the Harris inequality.)\n\nSee {{harvtxt|Holley|1974}} and {{harvtxt|Georgii|Häggström|Maes|2001}} for details.\n\n==See also==\n*[[Ahlswede–Daykin inequality]]\n\n==References==\n*{{springer|id=f/f110120|first=P.C.|last= Fishburn}}\n*{{Citation | last1=Fortuin | first1=C. M. | last2=Kasteleyn | first2=P. W. | last3=Ginibre | first3=J. | title=Correlation inequalities on some partially ordered sets | url=http://projecteuclid.org/euclid.cmp/1103857443 | mr=0309498 | year=1971 | journal=Communications in Mathematical Physics   | volume=22 | pages=89–103 | doi=10.1007/BF01651330 | issue=2| bibcode=1971CMaPh..22...89F }}\n*{{cite book |last1=Friedli |first=S. |last2=Velenik |first2=Y. |title=Statistical Mechanics of Lattice Systems: a Concrete Mathematical Introduction |publisher=Cambridge University Press |location=Cambridge |year=2017 |isbn=9781107184824 |url=http://www.unige.ch/math/folks/velenik/smbook/index.html}} \n*{{Citation | first1=H-O.|last1=Georgii| last2=Häggström| first2=O.| last3=Maes| first3=C.| chapter=The random geometry of equilibrium phases| arxiv=math/9905031| year=2001|title=[[Phase transitions and critical phenomena]] |volume=18|pages=1–142|publisher=Academic Press, San Diego, CA|mr=2014387| doi=10.1016/S1062-7901(01)80008-2}}\n*{{Citation | last=Grimmett | first=G. R. | title=Percolation. Second edition| publisher=Springer-Verlag | year=1999|mr=1707339| isbn=3-540-64902-6 | doi=10.1007/978-3-662-03981-6}}\n*{{Citation | last=Harris | first=T. E. | title=A lower bound for the critical probability in a certain percolation | year=1960 | journal=Proceedings of the Cambridge Philosophical Society | volume=56 | pages=13–20|mr=0115221 | doi=10.1017/S0305004100034241| bibcode=1960PCPS...56...13H }}\n*{{Citation | last1=Holley | first1=R. | title=Remarks on the  FKG inequalities | url=http://projecteuclid.org/euclid.cmp/1103859732 | mr=0341552 | year=1974 | journal=Communications in Mathematical Physics   | volume=36 | pages=227–231 | doi=10.1007/BF01645980 | issue=3| bibcode=1974CMaPh..36..227H }}\n*{{citation|last=Lyons|first=R.|year=2000|title=Phase transitions on nonamenable graphs|arxiv=math/9908177|journal=J. Math. Phys.|volume=41|pages=1099–1126|mr=1757952|doi=10.1063/1.533179|issue=3|bibcode=2000JMP....41.1099L}}\n*{{Citation|last=Sheffield|first=S.|title=Random surfaces|arxiv=math/0304049|journal=Astérisque|volume=304|year=2005| mr=2251117|bibcode=2003math......4049S}}\n\n{{DEFAULTSORT:Fkg Inequality}}\n[[Category:Inequalities]]\n[[Category:Statistical mechanics]]\n[[Category:Covariance and correlation]]"
    },
    {
      "title": "Friedrichs's inequality",
      "url": "https://en.wikipedia.org/wiki/Friedrichs%27s_inequality",
      "text": "In [[mathematics]], '''Friedrichs's inequality''' is a [[theorem]] of [[functional analysis]], due to [[Kurt O. Friedrichs|Kurt Friedrichs]]. It places a bound on the [[Lp space|''L<sup>p</sup>'' norm]] of a function using ''L<sup>p</sup>'' bounds on the [[weak derivative]]s of the function and the [[geometry]] of the [[Domain (mathematics)|domain]], and can be used to show that certain [[norm (mathematics)|norms]] on [[Sobolev space]]s are equivalent. Friedrichs's inequality is a general case of the [[Poincaré–Wirtinger inequality]] which deals with the case&nbsp;''k''&nbsp;=&nbsp;1.\n\n==Statement of the inequality==\nLet <math>\\Omega</math> be a [[bounded set|bounded subset]] of [[Euclidean space]] <math>\\mathbb R^n</math> with [[diameter]] <math>d</math>. Suppose that <math>u:\\Omega\\to\\mathbb R</math> lies in the Sobolev space <math>W_0^{k, p} (\\Omega)</math>, i.e., <math>u\\in W^{k,p}(\\Omega)</math> and the [[Sobolev space#Traces|trace]] of <math>u</math> on the boundary <math>\\partial\\Omega</math> is zero. Then\n\n:<math>\\| u \\|_{L^p (\\Omega)} \\leq d^k \\left( \\sum_{| \\alpha | = k} \\| \\mathrm{D}^{\\alpha} u \\|_{L^p (\\Omega)}^p \\right)^{1/p}.</math>\n\nIn the above\n* <math>\\| \\cdot \\|_{L^p (\\Omega)}</math> denotes the [[Lp space|''L<sup>p</sup>'' norm]];\n* ''&alpha;'' = (''&alpha;''<sub>1</sub>, ..., ''&alpha;''<sub>''n''</sub>) is a [[multi-index]] with norm |''&alpha;''| = ''&alpha;''<sub>1</sub> + ... + ''&alpha;''<sub>''n''</sub>;\n* D<sup>&alpha;</sup>''u'' is the mixed [[partial derivative]]\n::<math>\\mathrm{D}^\\alpha u = \\frac{\\partial^{| \\alpha |} u}{\\partial_{x_1}^{\\alpha_1} \\cdots \\partial_{x_n}^{\\alpha_n} }.</math>\n\n==See also==\n*[[Poincaré inequality]]\n\n==References==\n*{{cite book |first=Karel |last=Rektorys |chapter=The Friedrichs Inequality. The Poincaré inequality |title=Variational Methods in Mathematics, Science and Engineering |location=Dordrecht |publisher=Reidel |origyear=1977 |edition=2nd |year=2001 |isbn=1-4020-0297-1 |pages=188–198 |chapterurl=https://books.google.com/books?id=Kob1CAAAQBAJ&pg=PA188 }}\n\n[[Category:Sobolev spaces]]\n[[Category:Inequalities]]\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Gagliardo–Nirenberg interpolation inequality",
      "url": "https://en.wikipedia.org/wiki/Gagliardo%E2%80%93Nirenberg_interpolation_inequality",
      "text": "In [[mathematics]], the '''Gagliardo–Nirenberg interpolation inequality''' is a result in the theory of [[Sobolev spaces]] that estimates the [[weak derivative]]s of a function.  The estimates are in terms of [[Lp space|''L''<sup>''p''</sup> norms]] of the function and its derivatives, and the inequality “interpolates” among various values of ''p'' and orders of differentiation, hence the name.  The result is of particular importance in the theory of [[elliptic partial differential equation]]s. It was proposed by [[Louis Nirenberg]] and [[Emilio Gagliardo]].\n\n==Statement of the inequality==\n\nThe inequality concerns functions ''u'':&nbsp;'''R'''<sup>''n''</sup>&nbsp;&rarr;&nbsp;'''R'''.  Fix 1&nbsp;&le;''q'', ''r''&nbsp;&le;&nbsp;&infin; and a [[natural number]] ''m''.  Suppose also that a real number ''&alpha;'' and a natural number ''j'' are such that\n:<math>\n\\frac{1}{p} = \\frac{j}{n} + \\left( \\frac{1}{r} - \\frac{m}{n} \\right) \\alpha + \\frac{1 - \\alpha}{q}\n</math>\nand\n:<math>\n\\frac{j}{m} \\leq \\alpha \\leq 1.\n</math>\nThen \n# every function ''u'':&nbsp;'''R'''<sup>''n''</sup>&nbsp;&rarr;&nbsp;'''R''' that lies in ''L''<sup>''q''</sup>('''R'''<sup>''n''</sup>) with ''m''<sup>th</sup> derivative in ''L''<sup>''r''</sup>('''R'''<sup>''n''</sup>) also has ''j''<sup>th</sup> derivative in ''L''<sup>''p''</sup>('''R'''<sup>''n''</sup>);\n# and, furthermore, there exists a constant ''C'' depending only on ''m'', ''n'', ''j'', ''q'', ''r'' and ''&alpha;'' such that\n::<math>\n\\| \\mathrm{D}^{j} u \\|_{L^{p}} \\leq C \\| \\mathrm{D}^{m} u \\|_{L^{r}}^{\\alpha} \\| u \\|_{L^{q}}^{1 - \\alpha}.\n</math>\n\nThe result has two exceptional cases:\n# If ''j''&nbsp;=&nbsp;0, ''mr''&nbsp;&lt;&nbsp;''n'' and ''q''&nbsp;=&nbsp;&infin;, then it is necessary to make the additional assumption that either ''u'' tends to zero at infinity or that ''u'' lies in ''L''<sup>''s''</sup> for some finite ''s''&nbsp;&gt;&nbsp;0.\n# If 1&nbsp;&lt;&nbsp;''r''&nbsp;&lt;&nbsp;&infin; and ''m''&nbsp;&minus;&nbsp;''j''&nbsp;&minus;&nbsp;''n''/''r'' is a non-negative integer, then it is necessary to assume also that ''&alpha;''&nbsp;&ne;&nbsp;1.\n\nFor functions ''u'':&nbsp;&Omega;&nbsp;&rarr;&nbsp;'''R''' defined on a [[bounded set|bounded]] [[Lipschitz domain]] &Omega;&nbsp;&sube;&nbsp;'''R'''<sup>''n''</sup>, the interpolation inequality has the same hypotheses as above and reads\n\n:<math>\n\\| \\mathrm{D}^{j} u \\|_{L^{p}} \\leq C_{1} \\| \\mathrm{D}^{m} u \\|_{L^{r}}^{\\alpha} \\| u \\|_{L^{q}}^{1 - \\alpha} + C_{2} \\| u \\|_{L^{s}}\n</math>\n\nwhere ''s''&nbsp;&gt;&nbsp;0 is arbitrary;  naturally, the constants ''C''<sub>1</sub> and ''C''<sub>2</sub> depend upon the domain &Omega; as well as ''m'', ''n'' etc.\n\n==Consequences==\n\n* When ''&alpha;''&nbsp;=&nbsp;1, the ''L''<sup>''q''</sup> norm of ''u'' vanishes from the inequality, and the Gagliardo–Nirenberg interpolation inequality then implies the [[Sobolev embedding theorem]].  (Note, in particular, that ''r'' is permitted to be 1.)\n* Another special case of the Gagliardo–Nirenberg interpolation inequality is [[Ladyzhenskaya's inequality]], in which ''m''&nbsp;=&nbsp;1, ''j''&nbsp;=&nbsp;0, ''n''&nbsp;=&nbsp;2 or 3, ''q'' and ''r'' are both 2, and ''p''&nbsp;=&nbsp;4.\n\n==References==\n* ''[https://it.wikipedia.org/wiki/Emilio_Gagliardo E. Gagliardo]''. Ulteriori proprietà di alcune classi di funzioni in più variabili. Ricerche Mat.,8:24–51, 1959.\n* {{cite journal\n| last = Nirenberg\n| first = L.\n| authorlink = Louis Nirenberg\n| title = On elliptic partial differential equations\n| journal = Ann. Scuola Norm. Sup. Pisa (3)\n| volume = 13\n| year = 1959\n| pages = 115–162}}\n* Leoni, Giovanni (2017). ''[http://bookstore.ams.org/gsm-181/ A First Course in Sobolev Spaces: Second Edition]''. [[Graduate Studies in Mathematics]]. '''181'''. American Mathematical Society. pp.&nbsp;734. '''{{ISBN|978-1-4704-2921-8}}'''\n* Nguyen-Anh Dao, Jesus Ildefonso Diaz,  Quoc-Hung Nguyen (2018), [https://www.sciencedirect.com/science/article/pii/S0362546X18300804/  Generalized Gagliardo-Nirenberg  inequalities using Lorentz spaces and BMO], Nonlinear Analysis, Volume 173, Pages 146-153.\n\n{{DEFAULTSORT:Gagliardo-Nirenberg interpolation inequality}}\n[[Category:Inequalities]]\n[[Category:Sobolev spaces]]"
    },
    {
      "title": "Gårding's inequality",
      "url": "https://en.wikipedia.org/wiki/G%C3%A5rding%27s_inequality",
      "text": "In [[mathematics]], '''Gårding's inequality''' is a result that gives a lower bound for the [[bilinear form]] induced by a real [[Elliptic operator|linear elliptic partial differential operator]]. The inequality is named after [[Lars Gårding]].\n\n==Statement of the inequality==\n\nLet Ω be a [[bounded set|bounded]], [[open set|open domain]] in ''n''-[[dimension]]al [[Euclidean space]] and let ''H''<sup>''k''</sup>(Ω) denote the [[Sobolev space]] of ''k''-times weakly differentiable functions ''u''&nbsp;:&nbsp;Ω&nbsp;→&nbsp;'''R''' with weak derivatives in ''L''<sup>2</sup>. Assume that Ω satisfies the ''k''-extension property, i.e., that there exists a [[bounded linear operator]] ''E''&nbsp;:&nbsp;''H''<sup>''k''</sup>(Ω)&nbsp;→&nbsp;''H''<sup>''k''</sup>('''R'''<sup>''n''</sup>) such that (''Eu'')|<sub>Ω</sub>&nbsp;=&nbsp;''u'' for all ''u'' in ''H''<sup>''k''</sup>(Ω).\n\nLet ''L'' be a linear partial differential operator of even order ''2k'', written in divergence form\n\n:<math>(L u)(x) = \\sum_{0 \\leq | \\alpha |, | \\beta | \\leq k} (-1)^{| \\alpha |} \\mathrm{D}^{\\alpha} \\left( A_{\\alpha \\beta} (x) \\mathrm{D}^{\\beta} u(x) \\right),</math>\n\nand suppose that ''L'' is uniformly elliptic, i.e., there exists a constant ''&theta;'' > 0 such that\n\n:<math>\\sum_{| \\alpha |, | \\beta | = k} \\xi^{\\alpha} A_{\\alpha \\beta} (x) \\xi^{\\beta} > \\theta | \\xi |^{2 k} \\mbox{ for all } x \\in \\Omega, \\xi \\in \\mathbb{R}^{n} \\setminus \\{ 0 \\}.</math>\n\nFinally, suppose that the coefficients ''A<sub>&alpha;&beta;</sub>'' are [[bounded function|bounded]], [[continuous function]]s on the [[closure (topology)|closure]] of Ω for |''&alpha;''| = |''&beta;''| = ''k'' and that\n\n:<math>A_{\\alpha \\beta} \\in L^{\\infty} (\\Omega) \\mbox{ for all } | \\alpha |, | \\beta | \\leq k.</math>\n\nThen '''Gårding's inequality''' holds: there exist constants ''C''&nbsp;>&nbsp;0 and ''G''&nbsp;≥&nbsp;0\n\n:<math>B[u, u] + G \\| u \\|_{L^{2} (\\Omega)}^{2} \\geq C \\| u \\|_{H^{k} (\\Omega)}^{2} \\mbox{ for all } u \\in H_{0}^{k} (\\Omega),</math>\n\nwhere\n\n:<math>B[v, u] = \\sum_{0 \\leq | \\alpha |, | \\beta | \\leq k} \\int_{\\Omega} A_{\\alpha \\beta} (x) \\mathrm{D}^{\\alpha} u(x) \\mathrm{D}^{\\beta} v(x) \\, \\mathrm{d} x</math>\n\nis the bilinear form associated to the operator ''L''.\n\n==Application: the Laplace operator and the Poisson problem==\n\n'''Be careful, in this application, Garding's Inequality seems useless here as the final result is a direct consequence of Poincaré's Inequality, or Friedrich Inequality. (See talk on the article).''' \n\nAs a simple example, consider the [[Laplace operator]] Δ.  More specifically, suppose that one wishes to solve, for ''f''&nbsp;∈&nbsp;''L''<sup>2</sup>(Ω) the [[Poisson equation]]\n\n:<math>\\begin{cases} - \\Delta u(x) = f(x), & x \\in \\Omega; \\\\ u(x) = 0, & x \\in \\partial \\Omega; \\end{cases}</math>\n\nwhere Ω is a bounded [[Lipschitz domain]] in '''R'''<sup>''n''</sup>.  The corresponding weak form of the problem is to find ''u'' in the Sobolev space ''H''<sub>0</sub><sup>1</sup>(Ω) such that\n\n:<math>B[u, v] = \\langle f, v \\rangle \\mbox{ for all } v \\in H_{0}^{1} (\\Omega),</math>\n\nwhere\n\n:<math>B[u, v] = \\int_{\\Omega} \\nabla u(x) \\cdot \\nabla v(x) \\, \\mathrm{d} x,</math>\n:<math>\\langle f, v \\rangle = \\int_{\\Omega} f(x) v(x) \\, \\mathrm{d} x.</math>\n\nThe [[Lax–Milgram lemma]] ensures that if the bilinear form ''B'' is both continuous and elliptic with respect to the norm on ''H''<sub>0</sub><sup>1</sup>(Ω), then, for each ''f''&nbsp;∈&nbsp;''L''<sup>2</sup>(Ω), a unique solution ''u'' must exist in ''H''<sub>0</sub><sup>1</sup>(Ω).  The hypotheses of Gårding's inequality are easy to verify for the Laplace operator Δ, so there exist constants ''C'' and ''G''&nbsp;≥&nbsp;0\n\n:<math>B[u, u] \\geq C \\| u \\|_{H^{1} (\\Omega)}^{2} - G \\| u \\|_{L^{2} (\\Omega)}^{2}  \\mbox{ for all } u \\in H_{0}^{1} (\\Omega).</math>\n\nApplying the [[Poincaré inequality]] allows the two terms on the right-hand side to be combined, yielding a new constant ''K''&nbsp;&gt;&nbsp;0 with\n\n:<math>B[u, u] \\geq K \\| u \\|_{H^{1} (\\Omega)}^{2} \\mbox{ for all } u \\in H_{0}^{1} (\\Omega),</math>\n\nwhich is precisely the statement that ''B'' is elliptic.  The continuity of ''B'' is even easier to see:  simply apply the [[Cauchy–Schwarz inequality]] and the fact that the Sobolev norm is controlled by the ''L''<sup>2</sup> norm of the gradient.\n\n==References==\n\n* {{cite book\n|author1=Renardy, Michael  |author2=Rogers, Robert C.\n|    title = An introduction to partial differential equations\n|   series = Texts in Applied Mathematics 13\n|  edition = Second\n|publisher = Springer-Verlag\n| location = New York\n|     year = 2004\n|     isbn = 0-387-00444-0\n|    page = 356\n}} (Theorem 9.17)\n\n{{DEFAULTSORT:Garding's inequality}}\n[[Category:Theorems in functional analysis]]\n[[Category:Inequalities]]\n[[Category:Partial differential equations]]\n[[Category:Sobolev spaces]]"
    },
    {
      "title": "Generalized mean",
      "url": "https://en.wikipedia.org/wiki/Generalized_mean",
      "text": "{{Unreferenced|date=November 2009}}\nIn mathematics, '''generalized means''' are a family of functions for aggregating sets of numbers, that include as special cases the [[Pythagorean means]] ([[arithmetic mean|arithmetic]], [[geometric mean|geometric]], and [[harmonic mean|harmonic]] [[mean]]s). The generalized mean is also known as '''power mean''' or '''Hölder mean''' (named after [[Otto Hölder]]).\n\n==Definition==\nIf ''p'' is a non-zero [[real number]], and <math>x_1,\\dots,x_n</math> are [[positive real numbers]], then the '''generalized mean''' or '''power mean''' with exponent ''p'' of these positive real numbers is:\n\n:<math>M_p(x_1,\\dots,x_n) = \\left( \\frac{1}{n} \\sum_{i=1}^n x_i^p \\right)^{\\frac{1}{p}} .</math>\n\nNote the relationship to the [[Norm (mathematics)#p-norm|''p''-norm]]. For {{nowrap|1=''p'' = 0}} we set it equal to the geometric mean (which is the limit of means with exponents approaching zero, as proved below):\n\n:<math>M_0(x_1, \\dots, x_n) = \\sqrt[n]{\\prod_{i=1}^n x_i}</math>\n\nFurthermore, for a sequence of positive weights ''w<sub>i</sub>'' with sum <math>\\sum w_i = 1</math> we define the '''weighted power mean''' as:\n\n:<math>\\begin{align}\n  M_p(x_1,\\dots,x_n) &= \\left(\\sum_{i=1}^n w_i x_i^p \\right)^{\\frac{1}{p}} \\\\\n  M_0(x_1,\\dots,x_n) &= \\prod_{i=1}^n x_i^{w_i}\n\\end{align}</math>\n\nThe unweighted means correspond to setting all {{nowrap|1=''w<sub>i</sub>'' = 1/''n''}}.\n\n== Special cases ==\n[[Image:MathematicalMeans.svg|thumb|A visual depiction of some of the specified cases for {{math|1=''n'' = 2}} with {{math|1=''a'' = ''x''{{sub|1}} = ''M''{{sub|∞}}}} and {{math|1=''b'' = ''x''{{sub|2}} = ''M''{{sub|−∞}}}}:\n{{legend|magenta|harmonic mean, {{math|''H'' {{=}} ''M''{{sub|−1}}(''a'', ''b'')}},}}\n{{legend|blue|geometric mean, {{math|''G'' {{=}} ''M''{{sub|0}}(''a'', ''b'')}}}}\n{{legend|red|arithmetic mean, {{math|''A'' {{=}} ''M''{{sub|1}}(''a'', ''b'')}}}}\n{{legend|lime|quadratic mean, {{math|''Q'' {{=}} ''M''{{sub|2}}(''a'', ''b'')}}}}]]\n{| style=\"border:none; padding:20px\"\n|<math>M_{-\\infty}(x_1,\\dots,x_n) = \\lim_{p\\to-\\infty} M_p(x_1,\\dots,x_n) = \\min \\{x_1,\\dots,x_n\\}</math>\n|style=\"padding-left:20px\"| [[minimum]]\n|-\n|<math>M_{-1}(x_1,\\dots,x_n) = \\frac{n}{\\frac{1}{x_1}+\\dots+\\frac{1}{x_n}}</math>\n|style=\"padding-left:20px\"| [[harmonic mean]]\n|-\n|<math>M_0(x_1,\\dots,x_n) = \\lim_{p\\to0} M_p(x_1,\\dots,x_n) = \\sqrt[n]{x_1\\cdot\\dots\\cdot x_n}</math>\n|style=\"padding-left:20px\"| [[geometric mean]]\n|-\n|<math>M_1(x_1,\\dots,x_n) = \\frac{x_1 + \\dots + x_n}{n}</math>\n|style=\"padding-left:20px\"| [[arithmetic mean]]\n|-\n|<math>M_2(x_1,\\dots,x_n) = \\sqrt{\\frac{x_1^2 + \\dots + x_n^2}{n}}</math>\n|style=\"padding-left:20px\"| [[quadratic mean]]{{anchor|Quadratic}}\n|-\n|<math>M_3(x_1,\\dots,x_n) = \\sqrt[3]{\\frac{x_1^3 + \\dots + x_n^3}{n}}</math>\n|style=\"padding-left:20px\"| [[cubic mean]]\n|-\n|<math>M_{+\\infty}(x_1,\\dots,x_n) = \\lim_{p\\to\\infty} M_p(x_1,\\dots,x_n) = \\max \\{x_1,\\dots,x_n\\}</math>\n|style=\"padding-left:20px\"| [[maximum]]\n|}\n\n:{| class=\"toccolours collapsible collapsed\" width=\"90%\" style=\"text-align:left\"\n!Proof of <math>\\textstyle \\lim_{p \\to 0} M_p = M_0</math> (geometric mean)\n|-\n|\nWe can rewrite the definition of ''M<sub>p</sub>'' using the [[exponential function]]\n\n:<math>M_p(x_1,\\dots,x_n) = \\exp{\\left( \\ln{\\left[\\left(\\sum_{i=1}^n w_ix_{i}^p \\right)^{1/p}\\right]} \\right) } = \\exp{\\left( \\frac{\\ln{\\left(\\sum_{i=1}^n w_ix_{i}^p \\right)}}{p} \\right) }</math>\n\nIn the limit ''p'' → 0, we can apply [[L'Hôpital's rule]] to the argument of the exponential function. Differentiating the numerator and denominator with respect to p, we have\n:<math>\\lim_{p \\to 0} \\frac{\\ln{\\left(\\sum_{i=1}^n w_ix_{i}^p \\right)}}{p} = \\lim_{p \\to 0} \\frac{\\frac{\\sum_{i=1}^n w_i x_i^p \\ln{x_i}}{\\sum_{i=1}^n w_i x_i^p}}{1} = \\lim_{p \\to 0} \\frac{\\sum_{i=1}^n w_i x_i^p \\ln{x_i}}{\\sum_{i=1}^n w_i x_i^p} = \\sum_{i=1}^n w_i \\ln{x_i} = \\ln{\\left(\\prod_{i=1}^n x_i^{w_i} \\right)}</math>\n\nBy the continuity of the exponential function, we can substitute back into the above relation to obtain\n\n:<math>\\lim_{p \\to 0} M_p(x_1,\\dots,x_n) = \\exp{\\left( \\ln{\\left(\\prod_{i=1}^n x_i^{w_i} \\right)} \\right)} = \\prod_{i=1}^n x_i^{w_i} = M_0(x_1,\\dots,x_n)</math>\n\nas desired. \n|}\n\n:{| class=\"toccolours collapsible collapsed\" width=\"90%\" style=\"text-align:left\"\n!Proof of <math>\\textstyle \\lim_{p \\to \\infty} M_p = M_\\infty</math> and <math>\\textstyle \\lim_{p \\to -\\infty} M_p = M_{-\\infty}</math>\n|-\n|\nAssume (possibly after relabeling and combining terms together) that <math>x_1 \\geq \\dots \\geq x_n</math>. Then\n\n:<math>\\lim_{p \\to \\infty} M_p(x_1,\\dots,x_n) = \\lim_{p \\to \\infty} \\left( \\sum_{i=1}^n w_i x_i^p \\right)^{1/p} = x_1 \\lim_{p \\to \\infty} \\left( \\sum_{i=1}^n w_i \\left( \\frac{x_i}{x_1} \\right)^p \\right)^{1/p} = x_1 = M_\\infty (x_1,\\dots,x_n).</math>\n\nThe formula for <math>M_{-\\infty}</math> follows from <math>M_{-\\infty} (x_1,\\dots,x_n) = \\frac{1}{M_\\infty (1/x_1,\\dots,1/x_n)}.</math>\n|}\n\n==Properties==\n<!--\nThe case ''t'' = 1 yields the [[arithmetic mean]] and the case ''t'' = −1 yields the [[harmonic mean]]. The case ''t'' = 2 yields the [[root mean square]].  As ''t'' approaches 0, the [[Limit (mathematics)|limit]] of ''M''(''t'') is the [[geometric mean]] of the given numbers, and so it makes sense to ''define'' ''M''(0) to be the geometric mean. Furthermore, as ''t'' approaches ∞, ''M''(''t'') approaches the maximum of the given numbers, and as ''t'' approaches −∞, ''M''(''t'') approaches the minimum of the given numbers.\n-->\n* Each generalized mean always lies between the smallest and largest of the ''x'' values.\n* Each generalized mean is a symmetric function of its arguments; permuting the arguments of a generalized mean does not change its value.\n* Like most [[Mean#Properties|mean]]s, the generalized mean is a [[homogeneous function]] of its arguments ''x''<sub>1</sub>, ..., ''x<sub>n</sub>''. That is, if ''b'' is a positive real number, then the generalized mean with exponent ''p'' of the numbers <math>b\\cdot x_1,\\dots, b\\cdot x_n</math> is equal to ''b'' times the generalized mean of the numbers ''x''<sub>1</sub>, …, ''x<sub>n</sub>''.\n* Like the [[quasi-arithmetic mean]]s, the computation of the mean can be split into computations of equal sized sub-blocks. This enables use of a [[divide and conquer algorithm]] to calculate the means, when desirable.\n*:<math>M_p(x_1, \\dots, x_{n \\cdot k}) = M_p\\left[M_p(x_1, \\dots, x_{k}), M_p(x_{k + 1}, \\dots, x_{2 \\cdot k}), \\dots, M_p(x_{(n - 1) \\cdot k + 1}, \\dots, x_{n \\cdot k})\\right]</math>\n\n=== Generalized mean inequality ===\nIn general, \n: if ''p'' < ''q'', then <math>M_p(x_1,\\dots,x_n) \\le M_q(x_1,\\dots,x_n)</math>\n\nand the two means are equal if and only if ''x''<sub>1</sub> = ''x''<sub>2</sub> = ... = ''x<sub>n</sub>''.\n\nThe inequality is true for real values of ''p'' and ''q'', as well as positive and negative infinity values.\n\nIt follows from the fact that, for all real ''p'',\n\n: <math>\\frac{\\partial}{\\partial p}M_p(x_1, \\dots, x_n) \\geq 0</math>\n\nwhich can be proved using [[Jensen's inequality]].\n\nIn particular, for ''p'' in {−1, 0, 1}, the generalized mean inequality implies the [[Pythagorean means]] inequality as well as the [[inequality of arithmetic and geometric means]].\n\n==Proof of power means inequality==\nWe will prove weighted power means inequality, for the purpose of the proof we will assume the following without loss of generality:\n\n:<math>\\begin{align}\n  w_i \\in [0, 1] \\\\\n  \\sum_{i=1}^nw_i = 1\n\\end{align}</math>\n\nProof for unweighted power means is easily obtained by substituting ''w<sub>i</sub>'' = 1/''n''.\n\n===Equivalence of inequalities between means of opposite signs===\nSuppose an average between power means with exponents ''p'' and ''q'' holds:\n\n:<math>\\sqrt[p]{\\sum_{i=1}^nw_ix_i^p}\\geq \\sqrt[q]{\\sum_{i=1}^nw_ix_i^q}</math>\n\napplying this, then:\n\n:<math>\\sqrt[p]{\\sum_{i=1}^n\\frac{w_i}{x_i^p}}\\geq \\sqrt[q]{\\sum_{i=1}^n\\frac{w_i}{x_i^q}}</math>\n\nWe raise both sides to the power of −1 (strictly decreasing function in positive reals):\n\n:<math>\\sqrt[-p]{\\sum_{i=1}^nw_ix_i^{-p}}=\\sqrt[p]{\\frac{1}{\\sum_{i=1}^nw_i\\frac{1}{x_i^p}}}\\leq \\sqrt[q]{\\frac{1}{\\sum_{i=1}^nw_i\\frac{1}{x_i^q}}}=\\sqrt[-q]{\\sum_{i=1}^nw_ix_i^{-q}}</math>\n\nWe get the inequality for means with exponents −''p'' and −''q'', and we can use the same reasoning backwards, thus proving the inequalities to be equivalent, which will be used in some of the later proofs.\n\n===Geometric mean===\nFor any ''q'' &gt; 0 and non-negative weights summing to 1, the following inequality holds:\n\n:<math>\\sqrt[-q]{\\sum_{i=1}^n w_i x_i^{-q}} \\leq \\prod_{i=1}^n x_i^{w_i} \\leq \\sqrt[q]{\\sum_{i=1}^n w_i x_i^q}.</math>\n\nThe proof follows from [[Jensen's inequality]], making use of the fact the [[logarithm]] is concave:\n\n:<math>\\log \\prod_{i=1}^n x_i^{w_i} = \\sum_{i=1}^n w_i\\log x_i \\leq \\log \\sum_{i=1}^n w_i x_i.</math>\n\nBy applying the [[exponential function]] to both sides and observing that as a strictly increasing function it preserves the sign of the inequality, we get\n\n:<math>\\prod_{i=1}^n x_i^{w_i} \\leq \\sum_{i=1}^n w_i x_i.</math>\n\nTaking ''q''th powers of the ''x''<sub>''i''</sub>, we are done for the inequality with positive ''q''; the case for negatives is identical.\n\n===Inequality between any two power means===\nWe are to prove that for any ''p'' < ''q'' the following inequality holds:\n\n:<math>\\sqrt[p]{\\sum_{i=1}^nw_ix_i^p}\\leq \\sqrt[q]{\\sum_{i=1}^nw_ix_i^q}</math>\n\nif ''p'' is negative, and ''q'' is positive, the inequality is equivalent to the one proved above:\n\n:<math>\\sqrt[p]{\\sum_{i=1}^nw_ix_i^p}\\leq \\prod_{i=1}^nx_i^{w_i} \\leq\\sqrt[q]{\\sum_{i=1}^nw_ix_i^q}</math>\n\nThe proof for positive ''p'' and ''q'' is as follows: Define the following function: ''f'' : '''R'''<sub>+</sub> → '''R'''<sub>+</sub> <math>f(x)=x^{\\frac{q}{p}}</math>. ''f'' is a power function, so it does have a second derivative:\n\n: <math>f''(x) = \\left(\\frac{q}{p} \\right) \\left( \\frac{q}{p}-1 \\right)x^{\\frac{q}{p}-2}</math>\n\nwhich is strictly positive within the domain of ''f'', since ''q'' > ''p'', so we know ''f'' is convex.\n\nUsing this, and the Jensen's inequality we get:\n\n:<math>\\begin{align}\n     f \\left( \\sum_{i=1}^nw_ix_i^p \\right) &\\leq \\sum_{i=1}^nw_if(x_i^p) \\\\[3pt]\n  \\sqrt[\\frac{p}{q}]{\\sum_{i=1}^nw_ix_i^p} &\\leq \\sum_{i=1}^nw_ix_i^q\n\\end{align}</math>\n\nafter raising both side to the power of 1/''q'' (an increasing function, since 1/''q'' is positive) we get the inequality which was to be proven:\n\n:<math>\\sqrt[p]{\\sum_{i=1}^nw_ix_i^p}\\leq\\sqrt[q]{\\sum_{i=1}^nw_ix_i^q}</math>\n\nUsing the previously shown equivalence we can prove the inequality for negative ''p'' and ''q'' by substituting them with, respectively, −''q'' and −''p'', QED.\n\n== Generalized ''f''-mean ==\n{{Main|Generalized f-mean|l1=Generalized {{mvar|f}}-mean}}\n\nThe power mean could be generalized further to the [[generalized f-mean|generalized ''f''-mean]]:\n\n:<math> M_f(x_1,\\dots,x_n) = f^{-1} \\left({\\frac{1}{n}\\cdot\\sum_{i=1}^n{f(x_i)}}\\right) </math>\n\nThis covers the geometric mean without using a limit with ''f''(''x'') = ''log''(''x''). The power mean is obtained for ''f''(''x'') = ''x<sup>p</sup>''.\n\n== Applications ==\n\n===Signal processing===\nA power mean serves a non-linear [[moving average]] which is shifted towards small signal values for small ''p'' and emphasizes big signal values for big ''p''. Given an efficient implementation of a [[lowpass|moving arithmetic mean]] called <code>smooth</code> one can implement a moving power mean according to the following [[Haskell (programming language)|Haskell]] code.\n\n<source lang=\"haskell\">\n powerSmooth :: Floating a => ([a] -> [a]) -> a -> [a] -> [a]\n powerSmooth smooth p = map (** recip p) . smooth . map (**p)\n</source>\n\n* For big ''p'' it can serve an [[envelope detector]] on a [[rectifier|rectified]] signal.\n* For small ''p'' it can serve an [[Baseline (spectrometry)|baseline detector]] on a [[mass spectrum]].\n\n==See also==\n* [[Arithmetic mean]]\n* [[Arithmetic-geometric mean]]\n* [[Average]]\n* [[Geometric mean]]\n* [[Harmonic mean]]\n* [[Heronian mean]]\n* [[Inequality of arithmetic and geometric means]]\n* [[Lehmer mean]] &ndash; also a mean related to [[Power (mathematics)|powers]]\n* [[Pythagorean means]]\n* [[Root mean square]]\n* [[Minkowski distance]]\n\n==External links==\n*[http://mathworld.wolfram.com/PowerMean.html Power mean at MathWorld]\n*[http://people.revoledu.com/kardi/tutorial/BasicMath/Average/Generalized%20mean.html Examples of Generalized Mean]\n*A [https://planetmath.org/ProofOfGeneralMeansInequality proof of the Generalized Mean] on [[PlanetMath]]\n\n[[Category:Means]]\n[[Category:Inequalities]]\n[[Category:Articles with example Haskell code]]"
    },
    {
      "title": "Gibbs' inequality",
      "url": "https://en.wikipedia.org/wiki/Gibbs%27_inequality",
      "text": "[[FILE:Josiah Willard Gibbs -from MMS-.jpg|thumb|200px|Josiah Willard Gibbs]]\nIn [[information theory]], '''Gibbs' inequality''' is a statement about the [[entropy (information theory)|mathematical entropy]] of a discrete [[probability distribution]]. Several other bounds on the entropy of probability distributions are derived from Gibbs' inequality, including [[Fano's inequality]].\nIt was first presented by [[J. Willard Gibbs]] in the 19th century.\n\n==Gibbs' inequality==\nSuppose that\n\n:<math> P = \\{ p_1 , \\ldots , p_n \\} </math>\n\nis a [[probability distribution]]. Then for any other probability distribution\n\n:<math> Q = \\{ q_1 , \\ldots , q_n \\} </math>\n\nthe following inequality between positive quantities (since p<sub>i</sub> and q<sub>i</sub> are between zero and one) holds:<ref name=\"Bremaud2012\">{{cite book|author=Pierre Bremaud|title=An Introduction to Probabilistic Modeling|date=6 December 2012|publisher=Springer Science & Business Media|isbn=978-1-4612-1046-7}}</ref>{{rp|68}}\n\n:<math> - \\sum_{i=1}^n p_i \\log p_i \\leq - \\sum_{i=1}^n p_i \\log q_i </math>\n\nwith equality if and only if\n\n:<math> p_i = q_i </math>\n\nfor all ''i''. Put in words, the [[information entropy]] of a distribution P is less than or equal to its [[cross entropy]] with any other distribution Q.\n\nThe difference between the two quantities is the [[Kullback–Leibler divergence]] or relative entropy, so the inequality can also be written:<ref name=\"MacKay2003\">{{cite book|author=David J. C. MacKay|title=Information Theory, Inference and Learning Algorithms|publisher=Cambridge University Press|isbn=978-0-521-64298-9}}</ref>{{rp|34}}\n\n:<math> D_{\\mathrm{KL}}(P\\|Q) \\equiv \\sum_{i=1}^n p_i \\log \\frac{p_i}{q_i} \\geq 0.</math>\n\nNote that the use of base-2 [[logarithm]]s is optional, and \nallows one to refer to the quantity on each side of the inequality as an \n\"average [[surprisal]]\" measured in [[bit]]s.\n\n==Proof==\nFor simplicity, we prove the statement using the natural logarithm (ln), since\n\n:<math> \\log a = \\frac{ \\ln a }{ \\ln 2 },</math>\n\nthe particular logarithm we choose only scales the relationship.\n\nLet <math>I</math> denote the set of all <math>i</math> for which ''p<sub>i</sub>'' is non-zero. Then, since <math> \\ln x \\leq x-1 </math> for all ''x > 0'', with equality if and only if ''x=1'', we have:\n\n:<math>- \\sum_{i \\in I} p_i \\ln \\frac{q_i}{p_i} \\geq  - \\sum_{i \\in I} p_i \\left( \\frac{q_i}{p_i} - 1 \\right) </math><math> = - \\sum_{i \\in I} q_i + \\sum_{i \\in I} p_i = - \\sum_{i \\in I} q_i + 1 \\geq 0</math>\n\nThe last inequality is a consequence of the ''p<sub>i</sub>'' and ''q<sub>i</sub>'' being part of a probability distribution. Specifically, the sum of all non-zero values is 1. Some non-zero ''q<sub>i</sub>'', however, may have been excluded since the choice of indices is conditioned upon the ''p<sub>i</sub>'' being non-zero. Therefore the sum of the ''q<sub>i</sub>'' may be less than 1.\n\nSo far, over the index set  <math>I</math>, we have:\n\n:<math> - \\sum_{i \\in I} p_i \\ln \\frac{q_i}{p_i} \\geq 0 </math>,\n\nor equivalently\n \n:<math> - \\sum_{i \\in I} p_i \\ln q_i \\geq - \\sum_{i \\in I} p_i \\ln p_i </math>.\n\nBoth sums can be extended to all <math>i=1, \\ldots, n</math>, i.e. including <math>p_i=0</math>, by recalling that the expression <math>p \\ln p</math> tends to 0 as <math>p</math> tends to 0, and <math>\\ln q</math> tends to <math>\\infty</math> as <math>q</math> tends to 0. We arrive at \n\n:<math> - \\sum_{i=1}^n p_i \\ln q_i \\geq - \\sum_{i=1}^n p_i \\ln p_i </math>\n\nFor equality to hold, we require\n# <math> \\frac{q_i}{p_i} = 1</math> for all <math>i \\in I </math> so that the equality <math>\\ln \\frac{q_i}{p_i} = \\frac{q_i}{p_i} -1 </math> holds, \n# and <math> \\sum_{i \\in I} q_i = 1</math> which means <math>q_i=0</math> if <math>i\\notin I</math>, that is, <math>q_i=0</math> if <math>p_i=0</math>. \n\nThis can happen if and only if <math>p_i = q_i </math> for <math>i = 1, \\ldots, n</math>.\n\n==Alternative proofs==\nThe result can alternatively be proved using [[Jensen's inequality]], the [[log sum inequality]], or the fact that the Kullback-Leibler divergence is a form of [[Bregman divergence]]. Below we give a proof based on Jensen's inequality:\n\nBecause log is a concave function, we have that:\n\n:<math>\\sum_i p_i \\log\\frac{q_i}{p_i} \\le \\log\\sum_i p_i\\frac{q_i}{p_i} = \\log\\sum_i q_i = 0</math>\n\nWhere the first inequality is due to Jensen's inequality, and the last equality is because <math>q</math> is a probability distribution.\n\nFurther, because <math>\\log</math> is not linear, therefore by the equality condition of Jensen's inequality, we get equality when\n\n:<math>\\frac{q_1}{p_1} = \\frac{q_2}{p_2} = \\cdots = \\frac{q_n}{p_n}</math>\n\nSuppose that this ratio is <math>\\sigma</math>, then we have that\n\n:<math>1 = \\sum_i q_i = \\sum_i \\sigma p_i = \\sigma</math>\n\nWhere we use the fact that <math>p, q</math> are probability distributions. Therefore the equality happens when <math>p = q</math>.\n\n==Corollary==\nThe [[information entropy|entropy]] of <math>P</math> is bounded by:<ref name=\"Bremaud2012\"/>{{rp|68}}\n\n:<math>H(p_1, \\ldots , p_n) \\leq \\log n. </math>\n\nThe proof is trivial – simply set <math>q_i = 1/n </math> for all ''i''.\n\n==See also==\n* [[Information entropy]]\n* [[Bregman divergence]]\n\n==References==\n{{Reflist}}\n\n[[Category:Information theory]]\n[[Category:Coding theory]]\n[[Category:Inequalities]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Golden–Thompson inequality",
      "url": "https://en.wikipedia.org/wiki/Golden%E2%80%93Thompson_inequality",
      "text": "In [[physics]] and [[mathematics]], the '''Golden–Thompson inequality''' is a [[Trace inequalities|trace inequality]] between [[Matrix_exponential|exponentials]] of matrices proved independently by {{harvtxt|Golden|1965}} and {{harvtxt|Thompson|1965}}. It has been developed in the context of [[statistical mechanics]], where it has come to have a particular significance.\n\n== Introduction ==\nIf ''a'' and ''b'' are two real numbers, then the [[Exponential_function|exponential]] of ''a+b'' is the product of the exponential of ''a'' with the exponential of ''b'':\n:<math> e^{a+b} = e^a e^b .</math>\nThis relationship is '''not''' true if we replace ''a'' and ''b'' with square matrices ''A'' and ''B''. Golden and Thompson proved that, while the matrix given by <math>e^{A+B}</math> is not always equal to the matrix given by <math>e^A e^B</math>, their [[trace (linear algebra)|traces]] are related by the following inequality:\n\n:<math> \\operatorname{tr}\\, e^{A+B} \\le \\operatorname{tr} \\left(e^A e^B\\right).</math>\n\nThe inequality is well defined as the expression on right hand side of the inequality is a positive real number, as can be seen by rewriting it as <math>\\operatorname{tr}\\left(e^{\\frac{A}{2}}e^B e^{\\frac{A}{2}}\\right)</math> (using the cyclic property of the trace).\n\nIf ''A'' and ''B'' [[Commuting matrices|commute]], then the equality <math> e^{A+B} = e^A e^B</math> holds, just like in the case of real number. In this situation the Golden-Thompson inequality is actually an equality. {{harvtxt|Petz|1994}} proved that this is the only situation in which this happens: if ''A'' and ''B'' are two Hermitian matrices for which the Golden-Thomposon inequality is verified as an equality, then the two matrices commute.\n\n== Generalizations ==\nThe inequality has been generalized to three matrices by {{harvtxt|Lieb|1973}} and furthermore to any arbitrary number of matrices by {{harvtxt|Sutter|Berta|Tomamichel|2016}}. For three matrices, it takes the following formulation:\n\n:<math> \\operatorname{tr}\\, e^{A+B+C} \\le \\operatorname{tr} \\left(e^A \\mathcal{T}_{e^{-B}} e^C\\right)\n</math>\n\nwhere the operator <math>\\mathcal{T}_f</math> is the derivative of the matrix logarithm given by <math> \\mathcal{T}_f(g) = \\int_0^\\infty \\operatorname{d}t \\, (f+t)^{-1} g (f+t)^{-1} </math>. \nNote that, if <math>f</math> and <math>g</math> [[Commuting_matrices|commute]], then <math> \\mathcal{T}_f(g) = gf^{-1}</math>, and the inequality for three matrices reduces to the original from Golden and Thompson.\n\n{{harvs|txt|first=Bertram|last=Kostant|year=1973|authorlink=Bertram Kostant}} used the [[Kostant convexity theorem]] to generalize the Golden–Thompson inequality to all compact Lie groups.\n\n==References==\n\n*{{Citation | last1=Bhatia | first1=Rajendra | title=Matrix analysis | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics | isbn=978-0-387-94846-1 |mr=1477662 | year=1997 | volume=169 | doi=10.1007/978-1-4612-0653-8}}\n* J.E. Cohen, S. Friedland, T. Kato, F. Kelly, ''Eigenvalue inequalities for products of matrix exponentials'', Linear algebra and its applications, Vol. 45, pp.&nbsp;55&ndash;95, 1982. {{doi|10.1016/0024-3795(82)90211-7}}\n*{{Citation |last1=Lieb|first1=Elliott H|title=Convex trace functions and the Wigner-Yanase-Dyson conjecture|journal=Advances in Mathematics|date=1973|volume=11|issue=3|pages=267–288|doi=10.1016/0001-8708(73)90011-X}}\n*{{Citation | last1=Golden | first1=Sidney | title=Lower bounds for the Helmholtz function | doi= 10.1103/PhysRev.137.B1127 |mr=0189691 | year=1965 | journal=Phys. Rev. | series = Series II | volume=137 | issue=4B | pages=B1127–B1128| bibcode=1965PhRv..137.1127G }}\n*{{Citation | last1=Kostant | first1=Bertram | title=On convexity, the Weyl group and the Iwasawa decomposition | url= http://www.numdam.org/item?id=ASENS_1973_4_6_4_413_0 |mr=0364552 | year=1973 | journal=Annales Scientifiques de l'École Normale Supérieure |series=Série 4 | issn=0012-9593 | volume=6 | issue=4 | pages=413–455 | doi=10.24033/asens.1254}}\n* D. Petz, [http://www.renyi.hu/%7Epetz/pdf/64.pdf A survey of trace inequalities], in Functional Analysis and Operator Theory, 287&ndash;298, Banach Center Publications, 30 (Warszawa 1994).\n*{{Citation|last1=Sutter|first1=David|last2=Berta|first2=Mario|last3=Tomamichel|first3=Marco|title=Multivariate Trace Inequalities|journal=Communications in Mathematical Physics|date=2016|volume=352|issue=1|pages=37–58|doi=10.1007/s00220-016-2778-5|arxiv=1604.03023|bibcode=2017CMaPh.352...37S}}\n*{{Citation|last1=Thompson |first1=Colin J. |title=Inequality with applications in statistical mechanics |doi=10.1063/1.1704727 |mr=0189688 |year=1965 |journal=[[Journal of Mathematical Physics]] |issn=0022-2488 |volume=6 |issue=11 |pages=1812–1813 |bibcode=1965JMP.....6.1812T }}\n\n\n==External links==\n*{{citation|last=Tao|first=T.|url=http://terrytao.wordpress.com/2010/07/15/the-golden-thompson-inequality/|year=2010|title=The Golden–Thompson inequality}}\n*{{Cite journal|arxiv=1408.2008|last1=Forrester|first1=Peter J|title=The Golden-Thompson inequality --- historical aspects and random matrix applications|journal=Journal of Mathematical Physics|volume=55|issue=2|pages=023503|last2=Thompson|first2=Colin J|year=2014|doi=10.1063/1.4863477|bibcode=2014JMP....55b3503F}}\n{{DEFAULTSORT:Golden-Thompson inequality}}\n[[Category:Linear algebra]]\n[[Category:Matrix theory]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Greater-than sign",
      "url": "https://en.wikipedia.org/wiki/Greater-than_sign",
      "text": "{{for | the use of the \"&gt;\" sign as punctuation | Bracket#Angle brackets}}\n[[File:Greater than sign.png|thumb|Greater-than sign]]\nThe '''greater-than sign''' is a mathematical symbol that denotes an [[Inequality (mathematics)|inequality]] between two values. The widely adopted form of two equal-length strokes connecting in an [[acute angle]] at the right, '''>''', has been found in documents dated as far back as the 1560s. In typical mathematical usage, the greater-than sign is typically placed between the two values being compared and signals that the first number is greater than the second number. Examples of typical usage include {{math|1{{sfrac|1|2}}&nbsp;>&nbsp;1}} and {{math|1&nbsp;>&nbsp;−2}}. Since the development of computer [[programming language]]s, the greater-than sign and the [[less-than sign]] have been repurposed for a range of uses and operations.\n\n==History==\nThe symbols < and > first appear in {{lang|la|Artis Analyticae Praxis ad Aequationes Algebraicas Resolvendas}} (''The Analytical Arts Applied to Solving Algebraic Equations'') by [[Thomas Harriot]] (1560–1621), which was published posthumously in 1631. The text states: \"{{lang|la|Signum majoritatis ut}} a&nbsp;>&nbsp;b {{lang|la|significet}} a {{lang|la|majorem quam}} b\" and \"{{lang|la|Signum minoritatis ut}} a < b {{lang|la|significet}} a {{lang|la|minorem quam}} b.\"\n\nAccording to historian Art Johnson (page 144), while Harriot was surveying North America, he saw a [[Native Americans in the United States|Native American]] with a symbol that resembled the greater-than sign both backwards and forwards (&nbsp;>&nbsp;and&nbsp;<&nbsp;).<ref name=ArtJohnson> Johnson, Art. \"History of Mathematical Symbols\". Classic Math: History Topics for the Classroom. Dale Seymour Publications, 1994.</ref> Johnson says it is likely he developed the two symbols from this symbol.<ref name=ArtJohnson/>\n\n==Computing==\nThe '''greater-than sign''' ({{mono|&gt;}}) is an original [[ASCII]] character (hex 3E, decimal 62).\n\nThe [[character (computing)|character]] in [[Unicode]] is {{unichar|003E|GREATER-THAN SIGN|html=}}; this is inherited from the same value in [[ASCII]].\n\n===Angle brackets===\nThe greater-than sign is used for an approximation of the closing [[Bracket#Angle brackets|angle bracket]] (⟩). The proper Unicode character is {{unichar|232A|RIGHT-POINTING ANGLE BRACKET|html=}}. ASCII does not have angular brackets.\n\n===Programming language===\n[[BASIC]] and [[C (programming language)|C]]-family languages, (including [[Java (programming language)|Java]] and [[C++]]) use the operator {{mono|&gt;}} to mean \"greater than\". In [[Lisp (programming language)|Lisp]]-family languages, {{mono|&gt;}}  is a function used to mean \"greater than\".\nIn [[Coldfusion]] and [[Fortran]], operator {{mono|.GT.}} means \"greater than\".\n\n===Double greater-than sign===\nThe double greater-than sign ({{mono|&gt;&gt;}}) is used for an approximation of the much greater than sign (≫). ASCII does not have the much greater-than sign.\n\nThe double greater-than sign ({{mono|&gt;&gt;}}) is also used for an approximation of the closing [[guillemet]] (»).\n\nIn [[Java (programming language)|Java]], [[C (programming language)|C]], and [[C++]], the operator {{mono|&gt;&gt;}} is the [[right-shift operator]]. In C++ it is also used to get input from a [[Stream (computing)|stream]], similar to the C functions {{mono|getchar}} and {{mono|fgets}}.\n\nIn [[Haskell (programming language)|Haskell]], the {{mono|&gt;&gt;}} function is a monadic operator. It is used for sequentially composing two actions, discarding any value produced by the first. In that regard, it is like the statement sequencing operator in imperative languages, such as the semicolon in C.\n\n===Triple greater-than sign===\nThe triple greater-than sign (>>>) is the unsigned-right-shift operator in [[JavaScript]]. Three greater-than signs form the distinctive \"three chevron prompt\" of the firmware console in [[MicroVAX]], [[VAXstation]], and [[DEC Alpha]] computers (known as the [[System Reference Manual|SRM console]] in the latter). This is also the default prompt of the [[Python (programming language)|Python]] interactive shell, often seen for code examples that can be executed interactively in the interpreter:\n<syntaxhighlight lang=\"python\">\n~:$ python\nPython 2.7.5 (default, Mar  9 2014, 22:15:05) \n[GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> print(\"Hello World\")\nHello World\n>>> \n</syntaxhighlight>\n\n===Greater-than sign with equals sign===\nThe greater-than sign plus the equals sign ({{mono|<nowiki>&gt;=</nowiki>}}) is used for an approximation of the [[greater than or equal to]] sign (≥, the opposite of ≤). ASCII doesn't have a greater-than-or-equal-to sign.\n\nIn [[BASIC]], [[Lisp (programming language)|Lisp]]-family languages, and [[C (programming language)|C]]-family languages (including [[Java (programming language)|Java]] and [[C++]]), operator {{mono|<nowiki>&gt;=</nowiki>}} means \"greater than or equal to\". In [[Sinclair BASIC]] it is encoded as a single-byte code point token.\n\nIn [[Fortran]], operator {{mono|.GE.}} means \"greater than or equal to\".\n\nIn [[Bourne shell]] and [[Windows PowerShell]], the operator {{mono|-ge}} means \"greater than or equal to\".\n\n===Hyphen-minus with greater-than sign===\nIn some programming languages (for example [[F Sharp (programming language)|F#]]), the greater-than sign is used in conjunction with a [[hyphen-minus]] to create an arrow ({{mono|-&gt;}}). Arrows like these could also be used in text where other [[Arrow (symbol)|arrow symbols]] are unavailable.  In the R programming language, this can be used as the right assignment operator. In the C, C++, and C# programming languages, this is used as a member access operator.\n\n===Shell scripts===\nIn [[Bourne shell]] (and many other shells), greater-than sign is used to [[Redirection (Unix)|redirect]] output to a file. Greater-than plus ampersand ({{mono|&gt;&amp;}}) is used to redirect to a [[file descriptor]].\n\n===Spaceship operator===\nGreater-than sign is used in the [[spaceship operator]].\n\n===HTML===\nIn [[HTML]] (and [[SGML]] and [[XML]]), the greater-than sign is used at the end of tags. The greater-than sign may be included with {{mono|&amp;gt;}}, while {{mono|&amp;ge;}} produces the greater-than or equal to sign.\n\n===E-mail and the Internet===\nThe greater-than sign is used to denote [[quotation]]s in the [[e-mail]] and [[newsgroup]] formats, and this has been taken into use also in forums. It is also used before a sentence for a sense of implication. (>implying)\n\n==See also==\n*[[Inequality (mathematics)]]\n*[[Less-than sign]]\n*[[Relational operator]]\n*[[Mathematical operators and symbols in Unicode]]\n*[[Much-greater-than sign]]\n*[[Guillemet]]\n*[[Material conditional]]\n\n==References==\n{{Reflist}}\n\n[[Category:Typographical symbols]]\n[[Category:Mathematical symbols]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Griffiths inequality",
      "url": "https://en.wikipedia.org/wiki/Griffiths_inequality",
      "text": "In [[statistical mechanics]], the '''Griffiths inequality''', sometimes also called '''Griffiths&ndash;Kelly&ndash;Sherman inequality''' or '''GKS inequality''', named after [[Robert B. Griffiths]], is a [[correlation inequality]] for [[ferromagnetic]] spin systems. Informally, it says that in ferromagnetic spin systems, if the 'a-priori distribution' of the spin is invariant under spin flipping, the correlation of any monomial of the spins is non-negative; and the two point correlation of two monomial of the spins is non-negative.\n\nThe inequality was proved by Griffiths for Ising ferromagnets with two-body interactions,<ref name=gr1>{{cite journal|last=Griffiths|first=R.B.|authorlink=Robert Griffiths (physicist)|title=Correlations in Ising Ferromagnets. I|journal=J. Math. Phys.|year=1967|volume=8|issue=3|pages=478&ndash;483|doi=10.1063/1.1705219}}</ref> then generalised by Kelly and Sherman to interactions involving an arbitrary number of spins,<ref name=ks>{{cite journal|last=Kelly|first=D.J.|last2=Sherman|first2=S.|title=General Griffiths' inequalities on correlations in Ising ferromagnets|journal=J. Math. Phys.|year=1968|volume=9|pages=466|doi=10.1063/1.1664600}}</ref> and then by Griffiths to systems with arbitrary spins.<ref>{{cite journal|last=Griffiths|first=R.B.|authorlink=Robert Griffiths (physicist)|title=Rigorous  Results  for  Ising  Ferromagnets  of Arbitrary  Spin|journal=J. Math. Phys.|year=1969|volume=10|pages=1559|doi=10.1063/1.1665005}}</ref> A more general formulation was given by [[Jean Ginibre|Ginibre]],<ref name=g>{{cite journal|last=Ginibre|first=J.|authorlink=Jean Ginibre|title=General formulation of Griffiths' inequalities|journal=Comm. Math. Phys.|year=1970|volume=16|issue=4|pages=310&ndash;328|doi=10.1007/BF01646537}}</ref> and is now called the '''Ginibre inequality'''.\n\n==Definitions==\nLet <math> \\textstyle \\sigma=\\{\\sigma_j\\}_{j \\in \\Lambda}</math> be a configuration of (continuous or discrete) spins on a [[lattice (group)|lattice]] ''Λ''. If  ''A'' ⊂ ''Λ'' is a list of lattice sites, possibly with duplicates, let <math> \\textstyle \\sigma_A = \\prod_{j \\in A} \\sigma_j </math>  be the product of the spins in ''A''.\n\nAssign an ''a-priori'' measure ''dμ(σ)'' on the spins;\nlet ''H'' be an energy functional of the form\n\n:<math>H(\\sigma)=-\\sum_{A} J_A \\sigma_A ~,</math>\n\nwhere the sum is over lists of sites ''A'', and let\n\n:<math> Z=\\int d\\mu(\\sigma) e^{-H(\\sigma)} </math>\n\nbe the [[partition function (statistical mechanics)|partition function]]. As usual,\n\n:<math> \\langle \\cdot \\rangle = \\frac{1}{Z} \\sum_\\sigma \\cdot(\\sigma) e^{-H(\\sigma)} </math>\n\nstands for the [[ensemble average]].\n\nThe system is called ''ferromagnetic'' if, for any list of sites ''A'', ''J<sub>A</sub> ≥ 0''. The system is called ''invariant under spin flipping'' if, for any ''j'' in ''Λ'', the measure ''μ'' is preserved under the sign flipping map ''σ → τ'', where\n\n:<math> \\tau_k = \\begin{cases} \n\\sigma_k, &k\\neq j, \\\\\n- \\sigma_k, &k = j.\n\\end{cases}\n</math>\n\n==Statement of inequalities==\n\n===First Griffiths inequality===\nIn a ferromagnetic spin system which is invariant under spin flipping,\n:<math> \\langle \\sigma_A\\rangle \\geq 0</math>\nfor any list of spins ''A''.\n\n===Second Griffiths inequality===\nIn a ferromagnetic spin system which is invariant under spin flipping,\n:<math> \\langle \\sigma_A\\sigma_B\\rangle \\geq \n\\langle \\sigma_A\\rangle \\langle \\sigma_B\\rangle </math>\nfor any lists of spins ''A'' and ''B''.\n\nThe first inequality is a special case of the second one, corresponding to ''B'' = ∅.\n\n==Proof==\nObserve that the partition function is non-negative by definition.\n\n''Proof of first inequality'': Expand\n\n:<math> e^{-H(\\sigma)} = \\prod_{B} \\sum_{k \\geq 0} \\frac{J_B^k \\sigma_B^k}{k!} = \\sum_{\\{k_C\\}_C} \\prod_B \\frac{J_B^{k_B} \\sigma_B^{k_B}}{k_B!}~,</math>\n\nthen\n\n:<math>\\begin{align}Z \\langle \\sigma_A \\rangle \n&= \\int d\\mu(\\sigma) \\sigma_A e^{-H(\\sigma)} \n=  \\sum_{\\{k_C\\}_C} \\prod_B \\frac{J_B^{k_B}}{k_B!} \\int d\\mu(\\sigma) \\sigma_A \\sigma_B^{k_B} \\\\\n&= \\sum_{\\{k_C\\}_C} \\prod_B \\frac{J_B^{k_B}}{k_B!} \\int d\\mu(\\sigma) \\prod_{j \\in \\Lambda} \\sigma_j^{n_A(j) + n_B(j)}~,\\end{align}</math>\n\nwhere ''n<sub>A</sub>(j)'' stands for the number of times that ''j'' appears in ''A''. Now, by invariance under spin flipping,\n\n:<math>\\int d\\mu(\\sigma) \\prod_j \\sigma_j^{n(j)} = 0 </math>\n\nif at least one ''n(j)'' is odd, and the same expression is obviously non-negative for even values of ''n''. Therefore, ''Z''<''σ<sub>A</sub>''>≥0, hence also <''σ<sub>A</sub>''>≥0.\n\n''Proof of second inequality''. For the second Griffiths inequality, double the random variable, i.e. consider a second copy of the spin,  <math>\\sigma'</math>, with the same distribution of  <math>\\sigma</math>. Then\n\n:<math> \\langle \\sigma_A\\sigma_B\\rangle-\n\\langle \\sigma_A\\rangle \\langle \\sigma_B\\rangle=\n\\langle\\langle\\sigma_A(\\sigma_B-\\sigma'_B)\\rangle\\rangle~.\n</math>\n\nIntroduce the new variables\n:<math>\n\\sigma_j=\\tau_j+\\tau_j'~,\n\\qquad\n\\sigma'_j=\\tau_j-\\tau_j'~.\n</math>\n\nThe doubled system <math>\\langle\\langle\\;\\cdot\\;\\rangle\\rangle</math> is ferromagnetic in <math>\\tau, \\tau'</math> because <math>-H(\\sigma)-H(\\sigma')</math> is a  polynomial in <math>\\tau, \\tau'</math> with positive coefficients\n\n:<math>\\begin{align}\n\\sum_A J_A (\\sigma_A+\\sigma'_A) &= \\sum_A J_A\\sum_{X\\subset A} \n    \\left[1+(-1)^{|X|}\\right] \\tau_{A \\setminus X} \\tau'_X\n\\end{align}</math>\n\nBesides the measure on <math>\\tau,\\tau'</math> is invariant under spin flipping because <math>d\\mu(\\sigma)d\\mu(\\sigma')</math> is. \nFinally the monomials <math>\\sigma_A</math>, <math>\\sigma_B-\\sigma'_B</math> are polynomials in <math>\\tau,\\tau'</math> with positive coefficients\n\n:<math>\\begin{align}\n\\sigma_A &=  \\sum_{X \\subset A} \\tau_{A \\setminus X} \\tau'_{X}~, \\\\\n\\sigma_B-\\sigma'_B &= \\sum_{X\\subset B} \n    \\left[1-(-1)^{|X|}\\right] \\tau_{B \\setminus X} \\tau'_X~.\n\\end{align}</math>\n\nThe first Griffiths inequality applied to <math>\\langle\\langle\\sigma_A(\\sigma_B-\\sigma'_B)\\rangle\\rangle</math> gives the result.\n\nMore details are in <ref>{{cite book|last1=Glimm|first=J.|author1-link=James Glimm|last2=Jaffe|first2=A.|author2-link=Arthur Jaffe|title=Quantum Physics. A functional integral point of view|publisher=Springer-Verlag|year=1987|isbn=0-387-96476-2|location=New York}}</ref> and <ref>{{cite book|last1=Friedli|first=S.|last2=Velenik|first2=Y.|title=Statistical Mechanics of Lattice Systems: a Concrete Mathematical Introduction|publisher=Cambridge University Press|location=Cambridge |year=2017 |isbn=9781107184824 |url=http://www.unige.ch/math/folks/velenik/smbook/index.html}}</ref>.\n\n==Extension: Ginibre inequality==\n\nThe '''Ginibre inequality''' is an extension, found by Jean Ginibre,<ref name=g/> of the Griffiths inequality.\n\n===Formulation===\nLet (Γ,&nbsp;''μ'') be a [[probability space]]. For functions ''f'',&nbsp;''h'' on Γ, denote\n\n: <math> \\langle f \\rangle_h = \\int f(x) e^{-h(x)} \\, d\\mu(x) \\Big/ \\int e^{-h(x)} \\, d\\mu(x). </math>\n\nLet '''A''' be a set of real functions on ''Γ'' such that. for every ''f''<sub>1</sub>,''f''<sub>2</sub>,...,''f''<sub>''n''</sub> in '''A''', and for any choice of signs ±,\n\n:<math> \\iint d\\mu(x) \\, d\\mu(y) \\prod_{j=1}^n (f_j(x) \\pm f_j(y)) \\geq 0. </math>\n\nThen, for any ''f'',''g'',&minus;''h'' in the [[convex cone]] generated by '''A''',\n\n:<math> \\langle fg\\rangle_h - \\langle f \\rangle_h \\langle g \\rangle_h \\geq 0. </math>\n\n===Proof===\nLet\n\n: <math> Z_h = \\int e^{-h(x)} \\, d\\mu(x).</math>\n\nThen\n\n: <math>\\begin{align}\n&Z_h^2 \\left( \\langle fg\\rangle_h - \\langle f \\rangle_h \\langle g \\rangle_h \\right)\\\\\n  &\\qquad= \\iint d\\mu(x) \\, d\\mu(y) f(x) (g(x) - g(y)) e^{-h(x)-h(y)} \\\\\n  &\\qquad= \\sum_{k=0}^\\infty\n        \\iint d\\mu(x) \\, d\\mu(y) f(x) (g(x) - g(y)) \\frac{(-h(x)-h(y))^k}{k!}.\n\\end{align} </math>\n\nNow the inequality follows from the assumption and from the identity\n:<math> f(x) = \\frac{1}{2} (f(x)+f(y)) + \\frac{1}{2} (f(x)-f(y)). </math>\n\n===Examples===\n* To recover the (second) Griffiths inequality, take Γ = {&minus;1, +1}<sup>Λ</sup>, where Λ is a lattice, and let ''&mu;'' be a measure on Γ that is invariant under sign flipping. The cone '''A''' of polynomials with positive coefficients satisfies the assumptions of the Ginibre inequality.\n* (Γ,&nbsp;''μ'') is a [[commutative]] [[compact group]] with the [[Haar measure]], '''A''' is the cone of real [[Positive-definite function#In complex analysis and statistics and harmonic analysis|positive definite functions]] on Γ.\n* Γ is a [[totally ordered set]], '''A''' is the cone of real positive non-decreasing functions on Γ. This yields [[Chebyshev's sum inequality]]. For extension to partially ordered sets, see [[FKG inequality]].\n\n==Applications==\n* The [[thermodynamic limit]] of the correlations of the ferromagnetic Ising model (with non-negative external field ''h'' and free boundary conditions) exists.\n\n:This is because increasing the volume is the same as switching on new couplings ''J''<sub>''B''</sub> for a certain subset ''B''. By the second Griffiths inequality\n::<math>\\frac{\\partial}{\\partial J_B}\\langle \\sigma_A\\rangle=\n\\langle \\sigma_A\\sigma_B\\rangle-\n\\langle \\sigma_A\\rangle \\langle \\sigma_B\\rangle\\geq 0\n</math>\n:Hence  <math>\\langle \\sigma_A\\rangle</math> is monotonically increasing with the volume; then it converges since it is bounded by 1.\n\n* The one-dimensional, ferromagnetic Ising model with interactions <math> J_{x,y}\\sim |x-y|^{-\\alpha} </math> displays a phase transition if <math> 1<\\alpha <2 </math>.\n\n:This property can be shown in a hierarchical approximation, that differs from the full model by the absence of some interactions: arguing as above with the second Griffiths inequality, the results carries over the full model.<ref>{{cite journal|last=Dyson|first=F.J.|authorlink=Freeman Dyson|title=Existence of a phase-transition in a one-dimensional Ising ferromagnet|journal=Comm. Math. Phys.|year=1969|volume=12|pages=91&ndash;107|doi=10.1007/BF01645907}}</ref>\n\n*The Ginibre inequality provides the existence of the thermodynamic limit for the [[Thermodynamic free energy|free energy]] and spin correlations for the two-dimensional [[classical XY model]].<ref name=g/> Besides, through Ginibre inequality, Kunz and Pfister proved the presence of a phase transition for the ferromagnetic XY model with interaction <math> J_{x,y}\\sim |x-y|^{-\\alpha} </math> if <math> 2<\\alpha < 4 </math>.\n* Aizenman and Simon<ref>{{cite journal|last1=Aizenman|first1=M.|author1-link=Michael Aizenman|last2=Simon|first2=B.|author2-link=Barry Simon|title=A comparison of plane rotor and Ising models|journal=Phys. Lett. A|year=1980|volume=76|url=http://www.sciencedirect.com/science/article/pii/0375960180904934|doi=10.1016/0375-9601(80)90493-4}}</ref> used the Ginibre inequality to prove that the two point spin correlation of the ''ferromagnetic'' classical XY model in dimension <math>D</math>, coupling <math>J>0</math> and inverse temperature <math>\\beta</math> is ''dominated'' by (i.e. has upper bound given by) the two point correlation of the ''ferromagnetic'' [[Ising model]] in dimension <math>D</math>, coupling <math>J>0</math>, and inverse temperature <math>\\beta/2</math>\n::<math>\\langle \\mathbf{s}_i\\cdot \\mathbf{s}_j\\rangle_{J,2\\beta}\n\\le \\langle \\sigma_i\\sigma_j\\rangle_{J,\\beta}</math>\n:Hence the critical <math>\\beta</math> of the XY model cannot be smaller than the double of the critical temperature of the Ising model\n::<math> \\beta_c^{XY}\\ge 2\\beta_c^{\\rm Is}~;</math>\n:in dimension ''D'' = 2 and coupling ''J'' = 1, this gives\n::<math> \\beta_c^{XY} \\ge \\ln(1 + \\sqrt{2}) \\approx 0.88~.</math>\n   \n* There exists a version of the Ginibre inequality for the [[Coulomb gas]] that implies the existence of thermodynamic limit of correlations.<ref>{{cite journal|last=Fröhlich|first=J.|author1-link=Jürg Fröhlich|last2=Park|first2=Y.M.|title=Correlation inequalities and the thermodynamic limit for classical and quantum continuous systems|journal=Comm. Math. Phys.|year=1978|volume=59|issue=3|pages=235&ndash;266|doi=10.1007/BF01611505}}</ref>\n* Other applications (phase transitions in spin systems, XY model, XYZ quantum chain) are reviewed in.<ref>{{cite book|last=Griffiths|first=R.B.|title=[[Phase Transitions and Critical Phenomena]]|volume=1|year=1972|publisher=Academic Press|location=New York|pages=7|authorlink=Robert Griffiths (physicist)|editor=C. Domb and M.S.Green|chapter=Rigorous results and theorems}}</ref>\n\n==References==\n{{Reflist}}\n\n[[Category:Inequalities]]\n[[Category:Statistical mechanics]]"
    },
    {
      "title": "Grothendieck inequality",
      "url": "https://en.wikipedia.org/wiki/Grothendieck_inequality",
      "text": "In [[mathematics]], the '''Grothendieck inequality''' states that there is a universal constant ''k'' with the following property. If ''a''<sub>''i'',''j''</sub> is an ''n'' by ''n'' ([[real number|real]] or [[complex number|complex]]) [[matrix (mathematics)|matrix]] with\n:<math> \\left| \\sum_{i,j} a_{ij} s_i t_j \\right|\\le 1</math>\n\nfor all (real or complex) numbers ''s''<sub>''i''</sub>, ''t''<sub>''j''</sub> of absolute value at most 1, then\n:<math> \\left| \\sum_{i,j} a_{ij} \\langle S_i , T_j \\rangle \\right|\\le k</math>,\n\nfor all [[vector (mathematics)|vectors]] ''S''<sub>''i''</sub>, ''T''<sub>''j''</sub> in the [[unit ball]] ''B''(''H'')  of a (real or complex) [[Hilbert space]] ''H'', the constant ''k'' being independent of ''n''. For a fixed ''n'', the smallest constant which satisfies this property for all ''n'' by ''n''  matrices is called a '''Grothendieck constant''' and denoted ''k''(''n''). In fact there are two Grothendieck constants ''k''<sub>'''R'''</sub>(''n'') and ''k''<sub>'''C'''</sub>(''n'') for each ''n'' depending on whether one works with real or complex numbers, respectively.<ref>{{Citation | last = Pisier  | first = Gilles  | authorlink = Gilles Pisier |date=April 2012 | title = Grothendieck's Theorem, Past and Present  | journal = [[Bulletin of the American Mathematical Society]]  | volume = 49 | issue = 2  | pages = 237–323  | doi = 10.1090/S0273-0979-2011-01348-9 | arxiv = 1101.4195}}.</ref>\n\nThe Grothendieck inequality and Grothendieck constants are named after [[Alexander Grothendieck]], who proved the inequality and the existence of the constants in a paper published in 1953.<ref name=\"a\"/>\n\n==Bounds on the constants==\nThe sequences ''k''<sub>'''R'''</sub>(''n'') and ''k''<sub>'''C'''</sub>(''n'') are easily seen to be increasing, and Grothendieck's result states that they are [[bounded sequence|bounded]],<ref name=\"a\">{{Citation | last1=Grothendieck | first1=Alexander | author1-link=Alexander Grothendieck | title=Résumé de la théorie métrique des produits tensoriels topologiques | mr=0094682  | year=1953 | journal=Bol. Soc. Mat. Sao Paulo | volume=8 | pages=1–79}}</ref><ref>{{Citation | last1=Blei | first1=Ron C. | title=An elementary proof of the Grothendieck inequality | jstor=2046119 | mr=883401  | year=1987 | journal=[[Proceedings of the American Mathematical Society]] | issn=0002-9939 | volume=100 | issue=1 | pages=58–60 | doi=10.2307/2046119 | publisher=American Mathematical Society}}</ref> so they have [[limit of a sequence|limits]].\n\nWith ''k''<sub>'''R'''</sub> defined to be sup<sub>''n''</sub> ''k''<sub>'''R'''</sub>(''n'')<ref>{{Citation | last1=Finch | first1=Steven R. | title=Mathematical constants | publisher=[[Cambridge University Press]] | isbn=978-0-521-81805-6 | year=2003}}</ref> then Grothendieck proved that: <math> 1.57 \\approx \\frac{\\pi}{2} \\leq k_{\\R} \\leq \\mathrm{sinh}(\\frac{\\pi}{2}) \\approx 2.3</math>.\n\n{{harvtxt|Krivine|1979}}<ref name=\"krivine\">{{Citation | last1=Krivine | first1=J.-L. | title=Constantes de Grothendieck et fonctions de type positif sur les sphères | doi=10.1016/0001-8708(79)90017-3 | mr=521464  | year=1979 | journal=Advances in Mathematics | issn=0001-8708 | volume=31 | issue=1 | pages=16–30}}</ref>  improved the result by proving: ''k''<sub>'''R'''</sub> ≤ 1.7822139781...=<math> \\frac{\\pi}{2 \\ln(1+\\sqrt{2})}</math>, conjecturing that the upper bound is tight. However, this conjecture was disproved by {{harvtxt|Braverman|Makarychev|Makarychev|Naor|2011}}.<ref name=\"braverman\">{{citation\n | last1 = Braverman | first1 = Mark\n | last2 = Makarychev | first2 = Konstantin\n | last3 = Makarychev | first3 = Yury\n | last4 = Naor | first4 = Assaf\n | arxiv = 1103.6161\n | contribution = The Grothendieck Constant is Strictly Smaller than Krivine's Bound\n | doi = 10.1109/FOCS.2011.77\n | pages = 453–462\n | title = [[Symposium on Foundations of Computer Science|52nd Annual IEEE Symposium on Foundations of Computer Science (FOCS)]]\n | year = 2011}}</ref>\n\n==Grothendieck constant of order ''d''==\n\nIf we replace the (real or complex) Hilbert space ''H'' in the above definition with a (real or complex) ''d''-dimensional [[Euclidean space]], we get the constants ''k''<sub>'''R'''</sub>(''n'', ''d'') and ''k''<sub>'''C'''</sub>(''n'', ''d'') for the real and complex case, respectively. With increasing ''d'' these constants are monotone increasing and their limit is ''k''<sub>'''R'''</sub>(''n'') and ''k''<sub>'''C'''</sub>(''n''), respectively. For each ''d'', with increasing ''n'' the constants are also increasing and their limit is the Grothendieck constant of order ''d'' which can be denoted as ''k''<sub>'''R'''</sub>(∞, ''d'') and ''k''<sub>'''C'''</sub>(∞, ''d''), respectively.\n\nThe Grothendieck constant ''k''<sub>'''R'''</sub>(∞, 3) plays an essential role in the [[quantum nonlocality]] problem of the two-qubit [[Werner state]]s.\n<ref>{{Citation | last1=Acín | first1=Antonio | last2=Gisin | first2=Nicolas | last3=Toner | first3=Benjamin  | title=Grothendieck’s constant and local models for noisy entangled quantum states | publisher=[[Physical Review A]] | year=2006}}</ref>\n\n===Lower bounds===\n\nSome historical data on best known lower bounds of ''k''<sub>'''R'''</sub>(∞, ''d'') is summarized in the following table.\nImplied bounds are shown in italics.\n\n{| class=\"wikitable\"\n! ''d''\n! Grothendieck, 1953<ref name=\"a\"/>\n! Clauser et al., 1969<ref>{{Citation | last1=Clauser | first1=John F. | last2=Horne | first2=Michael A. | last3=Shimony | first3=Abner | last4=Holt | first4=Richard A. | title=Proposed Experiment to Test Local Hidden-Variable Theories | publisher=[[Physical Review Letters]] | volume = 23 | pages = 880 | year=1969}}</ref>\n! Davie, 1984<ref>{{Citation | last1=Davie | first1=A. M. | title=Unpublished | year=1984}}</ref>\n! Fishburn et al., 1994<ref>{{Citation | last1=Fishburn | first1=P. C. | last2=Reeds | first2=J. A. | title=Bell Inequalities, Grothendieck’s Constant, and Root Two | publisher=[[SIAM Journal on Discrete Mathematics]]  | volume = 7 | issue = 1 | pages = 48–56 | year=1994 | doi = 10.1137/S0895480191219350}}</ref>\n! Vértesi, 2008<ref>{{Citation | last1=Vértesi | first1=Tamás | title=More efficient Bell inequalities for Werner states | publisher=[[Physical Review A]] | year=2008}}</ref>\n! Briët et al., 2011<ref>{{Citation | last1=Briët | first1=Jop | last2=Buhrman | first2=Harry | last3=Toner | first3=Ben  | title=A Generalized Grothendieck Inequality and Nonlocal Correlations that Require High Entanglement | publisher=[[Communications in Mathematical Physics]] | year=2011}}</ref>\n! Hua et al., 2015<ref>{{Citation | last1=Hua | first1=Bobo | last2=Li | first2=Ming | last3=Zhang | first3=Tinggui | last4=Zhou | first4=Chunqin | last5=Li-Jost | first5=Xianqing | last6=Fei | first6=Shao-Ming  | title=Towards Grothendieck Constants and LHV Models in Quantum Mechanics | publisher=[[Journal of Physics A]] | volume=48 | issue=6 | pages=065302 | doi=10.1088/1751-8113/48/6/065302 | year=2015| arxiv=1501.05507 | bibcode=2015JPhA...48f5302H }}</ref>\n! Diviánszky et al., 2017<ref>{{Citation | last1=Diviánszky | first1=Péter | last2=Bene | first2=Erika | last3=Vértesi | first3=Tamás | title=Qutrit witness from the Grothendieck constant of order four | publisher=[[Physical Review A]] | volume=96 | pages=012113 | year=2017}}</ref>\n|-\n! 2\n| || <math>\\sqrt{2}</math> ≈ 1.41421 || || || || || ||\n|-\n! 3\n| || ''1.41421'' || || || 1.41724 ||  || 1.41758 || 1.4359\n|-\n! 4\n| || || || || 1.44521 ||  || 1.44566 || 1.4841\n|-\n! 5\n| || || || <math>\\frac{10}{7}</math> ≈ 1.42857 || 1.46007 ||  || 1.46112 || ''1.4841''\n|-\n! 6\n| || || || || ''1.46007'' || || 1.47017 || ''1.4841''\n|-\n! 7\n| || || || || || 1.46286 || 1.47583 || ''1.4841''\n|-\n! 8\n| || || || || || 1.47586 || 1.47972 || ''1.4841''\n|-\n! 9\n| || || || || || 1.48608 || ||\n|-\n! ...\n|-\n! ∞\n| <math>\\frac{\\pi}{2}</math> ≈ 1.57079 || || 1.67696 || || || || ||\n|}\n\n===Upper bounds===\n\nSome historical data on best known upper bounds of ''k''<sub>'''R'''</sub>(∞, ''d''):\n\n{| class=\"wikitable\"\n! ''d''\n! Grothendieck, 1953<ref name=\"a\"/>\n! Rietz, 1974<ref>{{Citation | last1=Rietz | first1=Ronald E. | title=A proof of the Grothendieck inequality | publisher=[[Israel Journal of Mathematics]]  | volume = 19 | issue = 3 | pages = 271–276 | year=1974 | doi = 10.1007/BF02757725}}</ref>\n! Krivine, 1979<ref name=\"krivine\"/>\n! Braverman et al., 2011<ref name=\"braverman\"/>\n! Hirsch et al., 2016<ref>{{Citation | last1=Hirsch | first1=Flavien | last2=Quintino | first2=Marco Túlio | last3=Vértesi | first3=Tamás | last4=Navascués | first4=Miguel | last5=Brunner | first5=Nicolas | title=Better local hidden variable models for two-qubit Werner states and an upper bound on the Grothendieck constant | arxiv = 1609.06114 | url=https://arxiv.org/pdf/1609.06114.pdf| bibcode=2016arXiv160906114H }}</ref>\n|-\n! 2\n| || || <math>\\sqrt{2}</math> ≈ 1.41421 || ||\n|-\n! 3\n| || || 1.5163 || || 1.4644\n|-\n! 4\n| || || <math>\\frac{\\pi}{2}</math> ≈ 1.5708 || ||\n|-\n! ...\n|-\n! 8\n| || || 1.6641 || ||\n|-\n! ...\n|-\n! ∞\n| <math>\\mathrm{sinh}\\left(\\frac{\\pi}{2}\\right)</math> ≈ 2.30130 || 2.261 || <math>\\frac{\\pi}{2\\ln(1+\\sqrt{2})}</math> ≈ 1.78221 || <math>\\frac{\\pi}{2\\ln(1+\\sqrt{2})}-\\varepsilon</math> ||\n|}\n\n==See also==\n*[[Pisier–Ringrose inequality]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*{{MathWorld|urlname=GrothendiecksConstant|title=Grothendieck's Constant}} (NB: the historical part is not exact there.)\n\n[[Category:Theorems in functional analysis]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Hadamard's inequality",
      "url": "https://en.wikipedia.org/wiki/Hadamard%27s_inequality",
      "text": "{{Hatnote|Another inequality is called the [[Hermite–Hadamard inequality]].}}\n\nIn [[mathematics]], '''Hadamard's inequality''', first published by [[Jacques Hadamard]] in 1893,<ref name=MandS>Maz'ya & Shaposhnikova</ref> is a bound on the [[determinant]] of a [[matrix (mathematics)|matrix]] whose entries are [[complex number]]s in terms of the lengths of its column vectors. In geometrical terms, when restricted to real numbers, it bounds the [[volume]] in [[Euclidean space]] of ''n'' dimensions marked out by ''n'' vectors ''v<sub>i</sub>'' for 1 ≤ ''i'' ≤ ''n'' in terms of the lengths of these vectors ||''v<sub>i</sub>''||.\n\nSpecifically, Hadamard's inequality states that if ''N'' is the matrix having columns<ref>The result is sometimes stated in terms of row vectors. That this is equivalent is seen by applying the transpose.</ref> ''v<sub>i</sub>'',  then\n:<math> \\left| \\det(N) \\right| \\le \\prod_{i=1}^n \\|v_i\\|.</math>\nIf the n vectors are linearly independent, equality in Hadamard's inequality is achieved if and only if the vectors are [[orthogonal]].\n\n==Alternate forms and corollaries==\nA corollary is that if the entries of an ''n'' by ''n'' matrix ''N'' are bounded by ''B'', so |''N<sub>ij</sub>''|≤''B'' for all ''i'' and ''j'', then\n:<math>\\left| \\det(N) \\right| \\le B^nn^{n/2}.</math>\nIn particular, if the entries of ''N'' are +1 and &minus;1 only then<ref>Garling</ref>\n:<math>\\left| \\det(N) \\right| \\le n^{n/2}.</math>\nIn [[combinatorics]], matrices ''N'' for which equality holds, i.e. those with orthogonal columns, are called [[Hadamard matrix|Hadamard matrices]].\n\nA [[positive-semidefinite matrix]] ''P'' can be written as ''N''<sup>*</sup>''N'', where ''N''<sup>*</sup> denotes the [[conjugate transpose]] of ''N'' (see [[Cholesky decomposition]]). Then\n:<math>\\det(P)=\\det(N)^2 \\le \\prod_{i=1}^n \\|v_i\\|^2 = \\prod_{i=1}^n p_{ii}.</math>\nSo, the determinant of a [[positive definite matrix]] is less than or equal to the product of its diagonal entries. Sometimes this is also known as Hadamard's inequality.<ref name=MandS/><ref>{{Cite journal|last=Różański|first=Michał|last2=Wituła|first2=Roman|last3=Hetmaniok|first3=Edyta|title=More subtle versions of the Hadamard inequality|url=http://linkinghub.elsevier.com/retrieve/pii/S0024379517304135|journal=Linear Algebra and its Applications|volume=532|pages=500–511|doi=10.1016/j.laa.2017.07.003}}</ref>\n\n==Proof==\nThe result is trivial if the matrix N is [[Invertible matrix|singular]], so assume the columns of N are linearly independent. By dividing each column by its length, it can be seen that the result is equivalent to the special case where each column has length 1, in other words if ''e<sub>i</sub>'' are unit vectors and ''M'' is the matrix having the ''e<sub>i</sub>'' as columns then\n:<math>\\left| \\det M \\right| \\le 1,</math>\nand equality is achieved if and only if the vectors are an [[orthogonal set]], that is when the matrix is [[Unitary matrix|unitary]]. The general result now follows:\n:<math>\\left| \\det N \\right|  = \\bigg (\\prod_{i=1}^n \\|v_i\\| \\bigg) \\left|\\det M\\right| \\leq \\prod_{i=1}^n \\|v_i\\|.</math>\n\nFor the positive definite case, let ''P'' =''M<sup>*</sup>M'' and let the eigenvalues of ''P'' be λ<sub>1</sub>, λ<sub>2</sub>, … λ<sub>''n''</sub>. By assumption, each entry in the diagonal of ''P'' is 1, so the [[Trace (linear algebra)|trace]] of ''P'' is ''n''. Applying the [[inequality of arithmetic and geometric means]],\n:<math>\\det P=\\prod_{i=1}^n \\lambda_i \\le \\bigg({1 \\over n}\\sum_{i=1}^n \\lambda_i\\bigg)^n = \\left({1 \\over n} \\operatorname{tr} P \\right)^n = 1^n = 1,</math>\nso\n:<math> \\left| \\det M \\right| = \\sqrt{\\det P} \\le 1.</math>\n\nIf there is equality then each of the ''λ''<sub>''i''</sub>'s must all be equal and their sum is ''n'', so they must all be 1. The matrix ''P'' is Hermitian, therefore diagonalizable, so it is the identity matrix—in other words the columns of ''M'' are an orthonormal set and the columns of ''N'' are an orthogonal set.<ref>Proof follows, with minor modifications, the second proof given in Maz'ya & Shaposhnikova. See also {{PlanetMath|urlname=7541|title=Proof of Hadamard's inequality}}.</ref>\n\nMany other proofs can be found in the literature.\n\n==See also==\n*[[Fischer's inequality]]\n*[[Koteljanskii's inequality]]\n\n==Notes==\n{{Reflist}}\n\n== References ==\n*{{cite book |title=Jacques Hadamard: A Universal Mathematician\n|first1=Vladimir|last1=Maz'ya|first2=T. O.|last2=Shaposhnikova\n|publisher=AMS|year=1999|isbn=0-8218-1923-2|pages=383ff.}}\n*{{cite book |title=Inequalities: A Journey into Linear Analysis\n|first=D. J. H.|last=Garling\n|publisher=Cambridge|year=2007|isbn=0-521-69973-8|page=233}}\n*{{cite book |title=Functional Analysis\n|first1=Frigyes|last1=Riesz|first2=Béla|last2=Szőkefalvi-Nagy\n|publisher=Dover|year=1990|isbn=0-486-66289-6|page=176}}\n*{{MathWorld|title=Hadamard's Inequality|urlname=HadamardsInequality}}\n\n==Further reading==\n*{{cite book |title=Inequalities\n|first1=Edwin F|last1=Beckenbach|first2=Richard Ernest|last2=Bellman\n|publisher=Springer|year=1965|page=64}}\n\n{{DEFAULTSORT:Hadamard's Inequality}}\n[[Category:Inequalities]]\n[[Category:Determinants]]"
    },
    {
      "title": "Hanner's inequalities",
      "url": "https://en.wikipedia.org/wiki/Hanner%27s_inequalities",
      "text": "In [[mathematics]], '''Hanner's inequalities''' are results in the theory of [[Lp space|''L''<sup>''p''</sup> spaces]]. Their proof was published in 1956 by [[Olof Hanner]]. They provide a simpler way of proving the [[Uniformly convex space|uniform convexity]] of ''L''<sup>''p''</sup> spaces for ''p''&nbsp;∈&nbsp;(1,&nbsp;+∞) than the approach proposed by [[James A. Clarkson]] in 1936.\n\n==Statement of the inequalities==\nLet ''f'',&nbsp;''g''&nbsp;∈&nbsp;''L''<sup>''p''</sup>(''E''), where ''E'' is any [[measure space]]. If ''p''&nbsp;∈&nbsp;[1,&nbsp;2], then\n\n:<math>\\|f+g\\|_p^p + \\|f-g\\|_p^p \\geq \\big( \\|f\\|_p + \\|g\\|_p \\big)^p + \\big| \\|f\\|_p-\\|g\\|_p \\big|^p.</math>\n\nThe substitutions ''F''&nbsp;=&nbsp;''f''&nbsp;+&nbsp;''g'' and ''G''&nbsp;=&nbsp;''f''&nbsp;&minus;&nbsp;''g'' yield the second of Hanner's inequalities:\n\n:<math>2^p \\big( \\|F\\|_p^p + \\|G\\|_p^p \\big) \\geq \\big( \\|F+G\\|_p + \\|F-G\\|_p \\big)^p + \\big| \\|F+G\\|_p-\\|F-G\\|_p \\big|^p.</math>\n\nFor ''p''&nbsp;∈&nbsp;[2,&nbsp;+∞) the inequalities are reversed (they remain non-strict).\n\nNote that for <math>p = 2</math> the inequalities become equalities which are both the [[parallelogram rule]].\n\n==References==\n* {{cite journal\n| last = Clarkson\n| first = James A.\n| title = Uniformly convex spaces\n| journal = Trans. Amer. Math. Soc.\n| volume = 40\n| year = 1936\n| issue = 3\n| pages = 396&ndash;414\n| doi = 10.2307/1989630\n| publisher = American Mathematical Society\n| jstor = 1989630\n}} {{MathSciNet|id=1501880}}\n* {{cite journal\n| last = Hanner\n| first = Olof\n| title = On the uniform convexity of ''L''<sup>''p''</sup> and ''ℓ''<sup>''p''</sup>\n| journal = Ark. Mat.\n| volume = 3\n| issue = 3\n| year = 1956\n| pages = 239&ndash;244\n| doi = 10.1007/BF02589410\n}} {{MathSciNet|id=0077087}}\n\n[[Category:Banach spaces]]\n[[Category:Inequalities]]\n[[Category:Measure theory]]"
    },
    {
      "title": "Hardy–Littlewood inequality",
      "url": "https://en.wikipedia.org/wiki/Hardy%E2%80%93Littlewood_inequality",
      "text": "In [[mathematical analysis]], the '''Hardy–Littlewood inequality''', named after [[G. H. Hardy]] and [[John Edensor Littlewood]], states that if ''f'' and ''g'' are nonnegative [[measurable function|measurable]] [[real functions]] vanishing at [[infinity]] that are defined on ''n''-[[dimension]]al [[Euclidean space]] '''R'''<sup>''n''</sup> then\n\n:<math>\\int_{\\mathbb{R}^n} f(x)g(x) \\, dx \\leq \\int_{\\mathbb{R}^n} f^*(x)g^*(x) \\, dx</math>\n\nwhere  ''f''<sup>*</sup> and ''g''<sup>*</sup> are the [[symmetric decreasing rearrangement]]s of ''f''(''x'') and ''g''(''x''), respectively.<ref name=liebloss>{{cite book|last1=Lieb|first1=Elliott|authorlink1=Elliott H. Lieb|last2=Loss|first2=Michael|author2-link=Michael Loss|title=Analysis|year=2001|edition=2nd|publisher=[[American Mathematical Society]]|series=Graduate Studies in Mathematics|volume=14|isbn=978-0821827833}}\n</ref><ref name=burchard>{{cite book|title=A Short Course on Rearrangement Inequalities|first=Almut|last=Burchard|url=http://www.math.toronto.edu/almut/rearrange.pdf}}</ref>\n\n==Proof==\nFrom [[layer cake representation]] we have:<ref name=liebloss/><ref name=burchard/>\n:<math>f(x)= \\int_0^\\infty \\chi_{f(x)>r} \\, dr</math>\n:<math>g(x)= \\int_0^\\infty \\chi_{g(x)>s} \\, ds</math>\n\nwhere <math>\\chi_{f(x)>r}</math> denotes the [[indicator function]] of the subset ''E''<sub> ''f''</sub> given by\n\n:<math>E_f=\\left\\{x\\in X: f(x)>r\\right\\} </math>\n\nAnalogously, <math>\\chi_{g(x)>s}</math> denotes the indicator function of the subset ''E''<sub> ''g''</sub> given by\n\n:<math>E_g=\\left\\{x\\in X: g(x)>s\\right\\} </math>\n\n:<math>\n\\int_{\\mathbb{R}^n} f(x)g(x) \\, dx = \\displaystyle\\int_{\\mathbb{R}^n}\\int_0^\\infty \\int_0^\\infty \\chi_{f(x)>r}\\chi_{g(x)>s} \\, dr \\, ds \\, dx </math>\n:::<math>= \\int_0^\\infty \\int_0^\\infty \\int_{\\mathbb{R}^n}\\chi_{f(x)>r\\cap g(x)>s} \\, dx \\, dr \\, ds </math>\n:::<math>= \\int_0^\\infty \\int_0^\\infty \\mu\\left(\\left\\{f(x)>r\\right\\}\\cap\\left\\{ g(x)>s\\right\\}\\right) \\, dr \\, ds</math>\n:::<math>\\leq \\int_0^\\infty \\int_0^\\infty \\min\\left(\\mu\\left(f(x)>r\\right);\\mu\\left(g(x)>s\\right)\\right) \\, dr \\, ds</math>\n:::<math>= \\int_0^\\infty \\int_0^\\infty \\min\\left(\\mu\\left(f^*(x)>r\\right);\\mu\\left(g^*(x)>s\\right)\\right) \\, dr \\, ds</math>\n:::<math>= \\int_0^\\infty \\int_0^\\infty \\mu\\left(\\left\\{f^\\ast(x)>r\\right\\}\\cap\\left\\{ g^\\ast(x)>s\\right\\}\\right) \\, dr \\, ds</math>\n:::<math>= \\int_{\\mathbb{R}^n} f^*(x)g^*(x) \\, dx </math>\n\n==See also==\n* [[Rearrangement inequality]]\n* [[Chebyshev's sum inequality]]\n* [[Lorentz space]]\n\n==References==\n<references/>\n\n{{DEFAULTSORT:Hardy-Littlewood inequality}}\n[[Category:Inequalities]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Hardy's inequality",
      "url": "https://en.wikipedia.org/wiki/Hardy%27s_inequality",
      "text": "'''Hardy's inequality''' is an [[inequality (mathematics)|inequality]] in [[mathematics]], named after [[G. H. Hardy]]. It states that if <math>a_1, a_2, a_3, \\dots </math> is a [[sequence]] of [[non-negative]] [[real number]]s, then for every real number ''p'' > 1 one has\n\n:<math>\\sum_{n=1}^\\infty \\left (\\frac{a_1+a_2+\\cdots +a_n}{n}\\right )^p\\leq\\left (\\frac{p}{p-1}\\right )^p\\sum_{n=1}^\\infty a_n^p.</math>\n\nIf the right-hand side is finite, equality holds [[if and only if]] <math>a_n = 0</math> for all ''n''.\n\nAn [[integral]] version of Hardy's inequality states the following: if ''f'' is a [[measurable function]] with non-negative values, then\n\n:<math>\\int_0^\\infty \\left (\\frac{1}{x}\\int_0^x f(t)\\, dt\\right)^p\\, dx\\le\\left (\\frac{p}{p-1}\\right )^p\\int_0^\\infty f(x)^p\\, dx.</math>\n\nIf the right-hand side is finite, equality holds [[if and only if]] ''f''(''x'') = 0 [[almost everywhere]].\n\nHardy's inequality was first published and proved (at least the discrete version with a worse constant) in 1920 in a note by Hardy.<ref name=Hardy1920>{{Cite journal | last1 = Hardy | first1 = G. H. | title = Note on a theorem of Hilbert | doi = 10.1007/BF01199965 | journal = Mathematische Zeitschrift | volume = 6 | issue = 3–4 | pages = 314–317 | year = 1920 | pmid =  | pmc = | url = https://zenodo.org/record/2411518 }}</ref> The original formulation was in an integral form slightly different from the above.\n\n==Proof of the inequality==\n* Integral version: a [[Integration by substitution|change of variables]] gives <br /> <math>\\left(\\int_0^\\infty\\left(\\frac{1}{x}\\int_0^x f(t)\\,dt\\right)^p\\ dx\\right)^{1/p}=\\left(\\int_0^\\infty\\left(\\int_0^1 f(sx)\\,ds\\right)^p\\,dx\\right)^{1/p}</math>, <br /> which is less or equal than <math>\\int_0^1\\left(\\int_0^\\infty f(sx)^p\\,dx\\right)^{1/p}\\,ds</math> by [[Minkowski_inequality#Minkowski's integral inequality|Minkowski's integral inequality]]. Finally, by another change of variables, the last expression equals <br /> <math>\\int_0^1\\left(\\int_0^\\infty f(x)^p\\,dx\\right)^{1/p}s^{-1/p}\\,ds=\\frac{p}{p-1}\\left(\\int_0^\\infty f(x)^p\\,dx\\right)^{1/p}</math>.\n* Discrete version: assuming the right-hand side to be finite, we must have <math>a_n\\to 0</math> as <math>n\\to\\infty</math>. Hence, for any positive integer ''j'', there are only finitely many terms bigger than <math>2^{-j}</math>. This allows us to construct a decreasing sequence <math>b_1\\ge b_2\\ge\\cdots</math> containing the same positive terms as the original sequence (but possibly no zero terms). Since <math>a_1+a_2+\\cdots +a_n\\le b_1+b_2+\\cdots +b_n</math> for every ''n'', it suffices to show the inequality for the new sequence. This follows directly from the integral form, defining <math>f(x)=b_n</math> if <math>n-1<x<n</math> and <math>f(x)=0</math> otherwise. Indeed, one has <br /> <math>\\int_0^\\infty f(x)^p\\,dx=\\sum_{n=1}^\\infty b_n^p</math> <br /> and, for <math>n-1<x<n</math>, there holds <br /> <math>\\frac{1}{x}\\int_0^x f(t)\\,dt=\\frac{b_1+\\dots+b_{n-1}+(x-n+1)b_n}{x} \\ge \\frac{b_1+\\dots+b_n}{n}</math> <br /> (the last inequality is equivalent to <math>(n-x)(b_1+\\dots+b_{n-1})\\ge (n-1)(n-x)b_n</math>, which is true as the new sequence is decreasing) and thus <br /> <math>\\sum_{n=1}^\\infty\\left(\\frac{b_1+\\dots+b_n}{n}\\right)^p\\le\\int_0^\\infty\\left(\\frac{1}{x}\\int_0^x f(t)\\,dt\\right)^p\\,dx</math>.\n\n==See also==\n* [[Carleman's inequality]]\n\n==Notes==\n<references />\n\n==References==\n*{{cite book\n | last       = Hardy\n | first      = G. H. |author2=Littlewood J.E. |author3=Pólya, G. \n | title      = Inequalities, 2nd ed\n | publisher  = Cambridge University Press\n | year       = 1952\n | pages      = \n | isbn       = 0-521-35880-9 \n}}\n\n*{{cite book\n | last       = Kufner\n | first      = Alois\n |author2=Persson, Lars-Erik \n | title      = Weighted inequalities of Hardy type\n | publisher  = World Scientific Publishing\n | year       = 2003\n | pages      = \n | isbn       = 981-238-195-3 \n}}\n\n* {{citation|last=Masmoudi|first=Nader|chapter=About the Hardy Inequality|title=An Invitation to Mathematics|editors=Dierk Schleicher, Malte Lackmann|year=2011|publisher=Springer Berlin Heidelberg|isbn=    978-3-642-19533-4}}.\n\n\n==External links==\n* {{springer|title=Hardy inequality|id=p/h046340}}\n\n[[Category:Inequalities]]\n[[Category:Theorems in real analysis]]"
    },
    {
      "title": "Harnack's inequality",
      "url": "https://en.wikipedia.org/wiki/Harnack%27s_inequality",
      "text": "In mathematics, '''Harnack's inequality''' is an inequality relating the values of a positive [[harmonic function]] at two points, introduced by {{harvs|txt|authorlink=Carl Gustav Axel Harnack|first=A.|last=Harnack|year=1887}}. {{harvs|txt|first=J. |last=Serrin|authorlink=James Serrin|year=1955}}, and {{harvs|txt|last=Moser|first=J.|authorlink=Jürgen Moser |year1=1961|year4=1964}} generalized Harnack's inequality to solutions of elliptic or parabolic [[partial differential equation]]s.  [[Grigori Perelman|Perelman]]'s solution of the Poincaré conjecture uses a version of the Harnack inequality, found by {{harvs|txt|first=R.|last=Hamilton|authorlink=Richard S. Hamilton|year=1993|txt}}, for the Ricci flow. Harnack's inequality is used to prove [[Harnack's theorem]] about the convergence of sequences of harmonic functions. Harnack's inequality can also be used to show the interior [[Hölder condition|regularity]] of weak solutions of partial differential equations.\n\n==The statement==\n\n[[Image:Harnack.png|thumb|200px|A harmonic function (green) over a disk (blue) is bounded from above by a function (red) that coincides with the harmonic function at the disk center and approaches infinity towards the disk boundary.]]\n'''Harnack's inequality''' applies to a non-negative function  ''f''  defined on a closed ball in '''R'''<sup>''n''</sup> with radius ''R'' and centre ''x''<sub>0</sub>. It states that, if ''f'' is continuous on the closed ball and [[harmonic function|harmonic]] on its interior, then for every point ''x'' with |''x''&nbsp;−&nbsp;''x''<sub>0</sub>|&nbsp;=&nbsp;''r''&nbsp;<&nbsp;''R'',\n\n:<math> \\frac{1-(r/R)} {[1+(r/R)]^{n-1}} f(x_0)\\le f(x) \\le  {1+(r/R)\\over [1 - (r/R)]^{n-1}} f(x_0).</math>\n\nIn the plane '''R'''<sup>2</sup>  (''n'' = 2) the inequality can be written:\n\n:<math>{R-r\\over R+r} f(x_0)\\le f(x)\\le {R+r\\over R-r}f(x_0).</math>\n\nFor general domains <math>\\Omega</math> in <math>\\mathbf{R}^n</math> the inequality can be stated as follows: If <math>\\omega</math> is a bounded domain with <math>\\bar{\\omega} \\subset \\Omega</math>, then there is a constant <math>C</math> such that \n\n:<math> \\sup_{x \\in \\omega} u(x) \\le C \\inf_{x \\in \\omega} u(x)</math>\n\nfor every twice differentiable, harmonic and nonnegative function <math>u(x)</math>. The constant <math>C</math> is independent of <math>u</math>; it depends only on the domains <math>\\Omega</math> and <math>\\omega</math>.\n\n==Proof of Harnack's inequality in a ball==\nBy [[Poisson kernel|Poisson's formula]]\n\n:<math> f(x) = \\frac 1 {\\omega_{n-1}} \\int_{|y-x_0|=R} \\frac{R^2 -r^2}{R|x - y|^n} \\cdot f(y) \\, dy, </math>\n\nwhere ''ω''<sub>''n'' − 1</sub> is the area of the unit sphere in '''R'''<sup>''n''</sup> and ''r'' = |''x'' − ''x''<sub>0</sub>|.\n\nSince\n\n:<math> R-r \\le |x-y| \\le R+r,</math>\n \nthe kernel in the integrand satisfies\n\n:<math> \\frac{R -r}{R (R+r)^{n-1}} \\le \\frac{R^2 -r^2}{R|x-y|^n}\\le \\frac{R+r}{R(R-r)^{n-1}}. </math>\n\nHarnack's inequality follows by substituting this inequality in the above integral and using the fact that the average of a harmonic function over a sphere equals its value at the center of the sphere:\n\n: <math> f(x_0)= \\frac 1 {R^{n-1}\\omega_{n-1}} \\int_{|y-x_0|=R} f(y)\\, dy. </math>\n\n==Elliptic partial differential equations==\nFor elliptic partial differential equations, Harnack's inequality states that the supremum of a positive solution in some connected open region is bounded by some constant times the infimum, possibly with an added term containing a functional [[norm (mathematics)|norm]] of the data:\n\n: <math>\\sup u \\le C ( \\inf u + \\|f\\|)</math>\n\nThe constant depends on the ellipticity of the equation and the connected open region.\n\n==Parabolic partial differential equations==\n\nThere is a version of Harnack's inequality for linear parabolic PDEs such as [[heat equation]].\n\nLet <math>\\mathcal{M}</math> be a smooth (bounded) domain in <math>\\mathbb{R}^n</math> and consider the linear elliptic operator\n\n: <math>\\mathcal{L}u=\\sum_{i,j=1}^n a_{ij}(t,x)\\frac{\\partial^2 u}{\\partial x_i\\,\\partial x_j} + \\sum_{i=1}^n b_i(t,x)\\frac{\\partial u}{\\partial x_i} + c(t,x)u</math>\n\nwith smooth and bounded coefficients and a [[positive definite]] matrix <math>(a_{ij})</math>. Suppose that <math>u(t,x)\\in C^2((0,T)\\times\\mathcal{M})</math> is a solution of\n\n: <math>\\frac{\\partial u}{\\partial t}-\\mathcal{L}u\\ge0</math> in <math>(0,T)\\times\\mathcal{M}</math>\n\nsuch that\n\n: <math>\\quad u(t,x)\\ge0 \\text{ in } (0,T)\\times\\mathcal{M}.</math>\n\nLet <math>K</math> be compactly contained in <math>\\mathcal{M}</math> and choose <math>\\tau\\in(0,T)</math>. Then there exists a constant ''C''&nbsp;>&nbsp;0 (depending only on ''K'', <math>\\tau</math> and the coefficients of <math>\\mathcal{L}</math>) such that, for each <math>t\\in(\\tau,T)</math>,\n\n: <math>\\sup_K u(t-\\tau,\\cdot)\\le C \\inf_K u(t,\\cdot).</math>\n\n==See also==\n\n*[[Harnack's theorem]]\n*[[Harmonic function]]\n\n==References==\n\n*{{Citation |title=Fully Nonlinear Elliptic Equations |last1=Caffarelli |first1=Luis A. |first2=Xavier|last2=Cabré |year=1995 |publisher=American Mathematical Society |location=Providence, Rhode Island |pages=31–41 |isbn=0-8218-0437-5}}\n*{{citation|last=Folland|first= Gerald B.|title= Introduction to partial differential equations|edition=2nd|publisher=Princeton University Press|year=1995|isbn= 0-691-04361-2}}\n*{{Citation |title= Elliptic Partial Differential Equations of Second Order |last1=Gilbarg |first1=David |first2=Neil S.|last2=Trudinger | year=1988| publisher=Springer |isbn=3-540-41160-7}}\n*{{Citation | last1=Hamilton | first1=Richard S. | title=The Harnack estimate for the Ricci flow |mr=1198607 | year=1993 | journal=Journal of Differential Geometry | issn=0022-040X | volume=37 | issue=1 | pages=225–243}}\n*{{citation|first=A. |last=Harnack|title=Die Grundlagen der Theorie des logarithmischen Potentiales und der eindeutigen Potentialfunktion in der Ebene|publisher=V. G. Teubner|place= Leipzig  |year=1887|url=https://archive.org/details/vorlesunganwend00weierich}}\n*{{citation|last=John|first= Fritz|title=Partial differential equations|edition=4th|series= Applied Mathematical Sciences|volume= 1|publisher= Springer-Verlag|year= 1982|isbn= 0-387-90609-6}}\n*{{springer|id=h/h046620|title=Harnack theorem|first=L.I.|last= Kamynin}}\n*{{springer|id=H/h046600|first1=L.I.|last1= Kamynin|first2=L.P.|last2= Kuptsov}}\n*Kassmann, Moritz (2007), \"Harnack Inequalities: An Introduction\" Boundary Value Problems '''2007''':081415, [[Digital object identifier|doi]]: [[doi:10.1155/2007/81415|10.1155/2007/81415]], [[MathSciNet|MR]] [https://mathscinet.ams.org/mathscinet-getitem?mr=2291922 2291922]\n*{{Citation | last1=Moser | first1=Jürgen | title=On Harnack's theorem for elliptic differential equations |mr=0159138 | year=1961 | journal=[[Communications on Pure and Applied Mathematics]] | volume=14 | issue=3 | pages=577–591 | doi=10.1002/cpa.3160140329}}\n*{{Citation | last1=Moser | first1=Jürgen | title=A Harnack inequality for parabolic differential equations |mr=0159139 | year=1964 | journal=[[Communications on Pure and Applied Mathematics]] | volume=17 | issue=1 | pages=101–134 | doi=10.1002/cpa.3160170106}}\n*{{Citation | last1=Serrin | first1=James | title=On the Harnack inequality for linear elliptic equations |mr=0081415 | year=1955 | journal=Journal d'Analyse Mathématique | volume=4 | issue=1 | pages=292–308 | doi=10.1007/BF02787725}}\n*L. C. Evans (1998), ''Partial differential equations''. American Mathematical Society, USA. For elliptic PDEs see Theorem 5, p.&nbsp;334 and for parabolic PDEs see Theorem 10, p.&nbsp;370.\n\n{{Authority control}}\n\n[[Category:Harmonic functions]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Hausdorff–Young inequality",
      "url": "https://en.wikipedia.org/wiki/Hausdorff%E2%80%93Young_inequality",
      "text": "{{Short description|bound on the norm of Fourier coefficients}}\nIn mathematics, the '''Hausdorff−Young inequality''' bounds the [[Lp-norm|''L''<sup>''q''</sup>-norm]] of the [[Fourier coefficient]]s of a [[periodic function]] for ''q''&nbsp;≥&nbsp;2. {{harvs|txt|authorlink=William Henry Young|first=William Henry|last=Young|year=1913}} proved the inequality for some special values of ''q'', and {{harvs|txt|authorlink=Felix Hausdorff|last=Hausdorff|year=1923}} proved it in general. More generally the inequality also applies to the [[Fourier transform]] of a function on a [[locally compact group]], such as '''R'''<sup>''n''</sup>, and in this case {{harvtxt|Babenko|1961}} and {{harvtxt|Beckner|1975}} gave a sharper form of it called the [[Babenko–Beckner inequality]].\n\nWe consider the [[Fourier series|Fourier operator]], namely let ''T'' be the operator that takes a function <math>f</math> on the [[unit circle]] and outputs the sequence of its Fourier coefficients\n\n: <math>\\widehat{f}(n)=\\frac{1}{2\\pi}\\int_0^{2\\pi}e^{-inx}f(x)\\,dx,\\quad n=0,\\pm1,\\pm2,\\dots.</math>\n\n[[Parseval's theorem]] shows that ''T'' is bounded from <math>L^2</math> to <math>\\ell^2</math> with norm 1. On the other hand, clearly,\n\n:<math>|(Tf)(n)|=|\\widehat{f}(n)|=\\left|\\frac{1}{2\\pi}\\int_0^{2\\pi}e^{-int}f(t)\\,dt\\right|\\leq \\frac{1}{2\\pi} \\int_0^{2\\pi}|f(t)|\\,dt</math>\n\nso ''T'' is bounded from <math>L^1</math> to <math>\\ell^\\infty</math> with norm&nbsp;1. Therefore we may invoke the [[Riesz–Thorin theorem]] to get, for any 1&nbsp;<&nbsp;''p''&nbsp;<&nbsp;2 that ''T'', as an operator from <math>L^p</math> to <math>\\ell^q</math>, is bounded with norm&nbsp;1, where\n\n:<math>\\frac{1}{p}+\\frac{1}{q}=1.</math>\n\nIn a short formula, this says that\n\n:<math>\\left(\\sum_{n=-\\infty}^\\infty |\\widehat{f}(n)|^q\\right)^{1/q}\\leq\n\\left( \\frac{1}{2\\pi}\\int_0^{2\\pi}|f(t)|^p\\,dt\\right)^{1/p}.</math>\n\nThis is the well known '''Hausdorff–Young inequality'''. For ''p''&nbsp;>&nbsp;2 the natural extrapolation of this inequality fails, and the fact that a function belongs to <math>L^p</math>, does not give any additional information on the order of growth of its Fourier series beyond the fact that it is in <math>\\ell^2</math>.\n\n==Optimal estimates==\nThe constant involved in the Hausdorff–Young inequality can be made optimal by using careful estimates from the theory of [[Harmonic analysis (mathematics)|harmonic analysis]].  If <math>f\\in L^p</math> for <math>1<p\\leq 2</math>, the optimal bound is\n:<math>\\|\\hat{f}\\|_{L^q}\\leq p^{1/2p}q^{-1/2q}\\|f\\|_{L^p}</math>\nwhere <math>q=p/(p-1)</math> is the Hölder conjugate of <math>p</math> {{harv|Cifuentes|2010}}\n\n==References==\n*{{Citation | last1=Babenko | first1=K. Ivan | title=An inequality in the theory of Fourier integrals |mr=0138939 | year=1961 | journal=Izvestiya Akademii Nauk SSSR. Seriya Matematicheskaya | issn=0373-2436 | volume=25 | pages=531–542}} English transl., Amer. Math. Soc. Transl. (2) 44, pp.&nbsp;115–128\n*{{Citation | doi=10.2307/1970980 | last1=Beckner | first1=William | author1-link=William Beckner (mathematician) | title=Inequalities in Fourier analysis |mr=0385456 | year=1975 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=102 | issue=1 | pages=159–182 | jstor=1970980}}\n*{{citation|title=Harmonic Analysis and Partial Differential Equations|volume=505|series=Contemporary Mathematics|first=Patricio|last=Cifuentes|publisher=American Mathematical Society|year=2010|isbn=9780821858318|page=94|url=https://books.google.com/books?id=ern6j-9vjSgC&pg=PA94}}.\n*{{Citation | last1=Hausdorff | first1=Felix | author1-link=Felix Hausdorff | title=Eine Ausdehnung des Parsevalschen Satzes über Fourierreihen | doi=10.1007/BF01175679 | year=1923 | volume=16 | pages=163–169 | journal=Mathematische Zeitschrift}}\n*{{Citation | last1=Young | first1=W. H. | author1-link=William Henry Young | title=On the Determination of the Summability of a Function by Means of its Fourier Constants | doi=10.1112/plms/s2-12.1.7 | year=1913 | journal=Proc. London Math. Soc. | volume=12 | pages=71–88}}\n\n{{DEFAULTSORT:Hausdorff-Young inequality}}\n[[Category:Inequalities]]\n[[Category:Fourier analysis]]"
    },
    {
      "title": "Hermite–Hadamard inequality",
      "url": "https://en.wikipedia.org/wiki/Hermite%E2%80%93Hadamard_inequality",
      "text": "{{distinguish|Hadamard's inequality}}\n\nIn [[mathematics]], the '''Hermite–Hadamard inequality''', named after [[Charles Hermite]] and [[Jacques Hadamard]] and sometimes also called '''Hadamard's inequality''', states that if a function ƒ&nbsp;:&nbsp;[''a'',&nbsp;''b'']&nbsp;→&nbsp;'''R''' is [[convex function|convex]], then the following chain of inequalities hold:\n\n: <math> f\\left( \\frac{a+b}{2}\\right) \\le \\frac{1}{b - a}\\int_a^b f(x)\\,dx \\le \\frac{f(a) + f(b)}{2}. </math>\n\n== A corollary on Vandermonde-type integrals ==\n{{Expert needed|Mathematics|talk=Section \"A corollary on Vandermonde-type integrals\"|reason=This section is not really on the main topic of this article.|date=July 2018}}\nSuppose that {{math|&minus;∞ < ''a'' < ''b'' < ∞}}, and choose {{mvar|n}} distinct values {{math|{''x''{{sub|''j''}}}{{su|b=''j''{{=}}1|p=n}}}} from {{math|(''a'', ''b'')}}.  Let {{math|''f'':[''a'', ''b''] → '''ℝ'''}} be convex, and let {{mvar|I}} denote the [[Volterra operator|\"integral starting at {{mvar|a}}\" operator]]; that is, \n:<math>(If)(x)=\\int_a^x{f(t)\\,dt}</math>.  \n\nThen\n\n: <math>\\sum_{i=1}^n \\frac {(I^{n-1}F)(x_i)}{\\prod_{j\\neq i}{(x_i-x_j)}}\\leq \\frac {1}{n!} \\sum_{i=1}^n f(x_i)</math>\n\nEquality holds for all {{math|{''x''{{sub|''j''}}}{{su|b=''j''{{=}}1|p=n}}}} iff {{mvar|f}} is linear, and for all {{mvar|f}} iff {{math|{''x''{{sub|''j''}}}{{su|b=''j''{{=}}1|p=n}}}} is constant, in the sense that \n: <math> \\lim_{\\{x_j\\}_j\\to\\alpha}{\\sum_{i=1}^n \\frac {(I^{n-1}F)(x_i)}{\\prod_{j\\neq i}{(x_i-x_j)}}}=\\frac{f(\\alpha)}{(n-1)!}</math>\n\n== References ==\n\n* [[Jacques Hadamard]], \"Étude sur les propriétés des [[entire function|fonctions entières]] et en particulier d'une fonction considérée par [[Bernhard Riemann|Riemann]]\", ''[[Journal de Mathématiques Pures et Appliquées]]'', volume 58, 1893, pages 171&ndash;215.\n* Zoltán Retkes, \"An extension of the Hermite&ndash;Hadamard [[Inequality (mathematics)|Inequality]]\", ''[[Acta Sci. Math. (Szeged)]]'', 74 (2008), pages 95&ndash;106.\n* Mihály Bessenyei, \"The Hermite&ndash;Hadamard [[Inequality (mathematics)|Inequality]] on [[simplex|Simplices]]\", ''[[American Mathematical Monthly]]'', volume 115, April 2008, pages 339&ndash;345.\n* Flavia-Corina Mitroi, Eleutherius Symeonidis, \"The converse of the Hermite-Hadamard inequality on simplices\", Expo. Math. 30 (2012), pp.&nbsp;389–396. DOI:10.1016/j.exmath.2012.08.011; {{ISSN|0723-0869}}\n\n{{DEFAULTSORT:Hermite-Hadamard inequality}}\n[[Category:Inequalities]]"
    },
    {
      "title": "Hilbert's inequality",
      "url": "https://en.wikipedia.org/wiki/Hilbert%27s_inequality",
      "text": "In [[mathematical analysis|analysis]], a branch of mathematics, '''Hilbert's inequality''' states that\n\n: <math>\n\\left|\\sum_{r\\neq s}\\dfrac{u_{r}\\overline{u_{s}}}{r-s}\\right|\\le\\pi\\displaystyle\\sum_{r}|u_{r}|^2.\n</math>\n\nfor any sequence ''u''<sub>1</sub>,''u''<sub>2</sub>,... of complex numbers. It was first demonstrated by [[David Hilbert]] with the constant 2{{pi}} instead of {{pi}}; the sharp constant was found by [[Issai Schur]]. It implies that the [[Hilbert transform#Discrete Hilbert transform|discrete Hilbert transform]] is a bounded operator in ''ℓ''<sub>2</sub>.\n\n==Formulation==\n\nLet (''u''<sub>''m''</sub>) be a sequence of complex numbers. If the sequence is infinite, assume that it is square-summable:\n\n:<math> \\sum_m |u_m|^2 < \\infty </math>\n\nHilbert's inequality (see {{harvtxt|Steele|2004}}) asserts that\n\n: <math>\n\\left|\\sum_{r\\neq s}\\dfrac{u_{r}\\overline{u_{s}}}{r-s}\\right|\\le\\pi\\displaystyle\\sum_{r}|u_{r}|^2.\n</math>\n\n==Extensions==\n\nIn 1973, [[#MV|Montgomery & Vaughan]] reported several generalizations of Hilbert's inequality, considering the bilinear forms\n\n: <math> \\sum_{r\\neq s}u_r\\overline u_s\\csc\\pi(x_r-x_s) </math>\n\nand\n\n: <math>\\sum_{r\\neq s}\\dfrac{u_r\\overline u_s}{\\lambda_r-\\lambda_s},</math>\n\nwhere ''x''<sub>1</sub>,''x''<sub>2</sub>,...,''x''<sub>''m''</sub> are distinct real numbers modulo&nbsp;1 (i.e. they belong to distinct classes in the [[quotient group]] '''R'''/'''Z''') and ''&lambda;''<sub>1</sub>,...,''&lambda;''<sub>''m''</sub> are distinct real numbers. [[#MV|Montgomery & Vaughan]]'s generalizations of Hilbert's inequality are then given by\n\n: <math>\n\\left|\\sum_{r\\neq s} u_r \\overline{u_s}\\csc\\pi(x_r-x_s)\\right|\\le\\delta^{-1}\\sum_r |u_r|^2.\n</math>\n\nand\n\n: <math>\n\\left|\\sum_{r\\neq s}\\dfrac{u_r\\overline{u_s}}{\\lambda_r-\\lambda_s}\\right|\\le\\pi\\tau^{-1} \\sum_r |u_r|^2.\n</math>\n\nwhere\n\n:<math>\\delta={\\min_{r,s}}{}_{+}\\|x_{r}-x_{s}\\|, \\quad \\tau=\\min_{r,s}{}_{+}\\|\\lambda_r-\\lambda_s\\|, </math>\n\n:<math>\\|s\\|= \\min_{m\\in\\mathbb{Z}}|s-m|</math>\n\nis the distance from ''s'' to the nearest integer, and min<sub>+</sub> denotes the smallest positive value. Moreover, if\n\n:<math>0<\\delta_r \\le {\\min_s}{}_{+}\\|x_r-x_s\\| \\quad \\text{and} \\quad 0<\\tau_{r}\\le {\\min_{s}}{}_{+}\\|\\lambda_r-\\lambda_s\\|,</math>\n\nthen the following inequalities hold:\n\n: <math>\n\\left|\\sum_{r\\neq s} u_r\\overline{u_s}\\csc\\pi(x_r-x_s)\\right|\\le\\dfrac{3}{2} \\sum_r |u_r|^2 \\delta_r^{-1}.\n</math>\n\nand\n\n: <math>\\left|\\sum_{r\\neq s}\\dfrac{u_r \\overline{u_s}}{\\lambda_r-\\lambda_s}\\right|\\le \\dfrac{3}{2} \\pi \\sum_r |u_r|^2\\tau_r^{-1}.\n</math>\n\n==References==\n\n* Online book chapter [http://www-stat.wharton.upenn.edu/~steele/Publications/Books/CSMC/CSMC_HilbertandCompensatingDifficulties.pdf Hilbert’s Inequality and Compensating Difficulties] extracted from {{cite book |title=The Cauchy-Schwarz master class: an introduction to the art of mathematical inequalities |first=J. Michael|last= Steele |pages=155–165 |chapter=Chapter 10: Hilbert’s Inequality and Compensating Difficulties |url=https://books.google.com/books?id=bvgBdZKEYAEC&pg=PA155  |year=2004 |isbn=0-521-54677-X |publisher=Cambridge University Press|ref=harv}}.\n* {{cite journal\n|    last1 = Montgomery\n|   first1 = H. L.\n|   author-link = Hugh Montgomery (mathematician)\n|    last2 = Vaughan\n|   first2 = R. C.\n|    title = Hilbert's inequality\n|  journal = J. London Math. Soc. |series=Series 2\n|   volume = 8\n|     year = 1974\n|    pages = 73–82\n|     issn = 0024-6107\n|      ref = MV\n}}\n\n==External links==\n* {{SpringerEOM|title=Hilbert inequality|id=Hilbert_inequality| last=Godunova|first=E.K.}}\n\n[[Category:Inequalities]]\n[[Category:Complex analysis]]\n[[Category:Number theory]]"
    },
    {
      "title": "Entropic uncertainty",
      "url": "https://en.wikipedia.org/wiki/Entropic_uncertainty",
      "text": "{{Short description|Concept in information theory}}\n\nIn [[Uncertainty principle#Quantum entropic uncertainty principle|quantum mechanics]], [[information theory]], and [[Fourier analysis]], the '''entropic uncertainty''' or '''Hirschman uncertainty''' is defined as the sum of the temporal and spectral [[Shannon entropy|Shannon entropies]].  It turns out that Heisenberg's [[uncertainty principle]] can be expressed as a lower bound on the sum of these entropies.  This is ''stronger'' than the usual statement of the uncertainty principle in terms of the product of standard deviations.\n\nIn 1957,<ref name=Hirschman>{{Citation |first=I. I., Jr. |last=Hirschman |title=A note on entropy |journal=[[American Journal of Mathematics]] |year=1957 |volume=79 |issue=1 |pages=152–156 |doi=10.2307/2372390 |postscript=. |jstor=2372390 }}</ref> [[Isidore Isaac Hirschman, Jr.|Hirschman]] considered a function ''f'' and its [[Fourier transform]] ''g'' such that\n:<math>g(y) \\approx \\int_{-\\infty}^\\infty \\exp (-2\\pi ixy) f(x)\\, dx,\\qquad f(x) \\approx \\int_{-\\infty}^\\infty \\exp (2\\pi ixy) g(y)\\, dy  ~,</math>\nwhere the   \"≈\" indicates convergence in {{mvar|L}}<sup>2</sup>, and normalized so that (by [[Plancherel theorem|Plancherel's theorem]]),\n:<math> \\int_{-\\infty}^\\infty |f(x)|^2\\, dx = \\int_{-\\infty}^\\infty |g(y)|^2 \\,dy = 1~.</math>\n\nHe showed that for any such functions the sum of the Shannon entropies is non-negative,\n:<math> H(|f|^2) + H(|g|^2) \\equiv - \\int_{-\\infty}^\\infty |f(x)|^2 \\log |f(x)|^2\\, dx - \\int_{-\\infty}^\\infty |g(y)|^2 \\log |g(y)|^2 \\,dy \\ge 0. </math>\n\nA tighter bound,\n{{Equation box 1\n|indent =:\n|equation =  <math> H(|f|^2) + H(|g|^2) \\ge \\log \\frac e 2   ~,</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|bgcolor=#F9FFF7}}\nwas conjectured by Hirschman<ref name=Hirschman/> and [[Hugh Everett|Everett]],<ref>[[Hugh Everett]], III.  The Many-Worlds Interpretation of Quantum Mechanics: the theory of the universal wave function. [https://www.pbs.org/wgbh/nova/manyworlds/pdf/dissertation.pdf Everett's Dissertation]</ref> proven in 1975 by [[William Beckner (mathematician)|W. Beckner]]<ref name=\"Beckner\">{{Citation |first=W. |last=Beckner |title=Inequalities in Fourier analysis |journal=[[Annals of Mathematics]] |volume=102 |issue=6 |year=1975 |pages=159–182 |doi=10.2307/1970980 |postscript=. |jstor=1970980 }}</ref> and in the same year interpreted by as a generalized quantum mechanical uncertainty principle by [[:pl:Iwo Białynicki-Birula|Białynicki-Birula]] and Mycielski.<ref name=\"BBM\">{{Citation |first=I. |last=Bialynicki-Birula|last2= Mycielski|first2=J.|title=Uncertainty Relations for Information Entropy in Wave Mechanics|journal=[[Communications in Mathematical Physics]] |volume=44 |year=1975 |pages=129 |doi=10.1007/BF01608825 |issue=2|bibcode = 1975CMaPh..44..129B }}</ref>\nThe equality holds in the case of [[Gaussian distribution]]s.<ref>{{cite journal |last1=Ozaydin |first1=Murad |last2=Przebinda |first2=Tomasz |year=2004 |title=An Entropy-based Uncertainty Principle for a Locally Compact Abelian Group |journal=Journal of Functional Analysis |volume=215 |issue=1 |pages=241–252  |publisher=Elsevier Inc.|doi= 10.1016/j.jfa.2003.11.008|url=http://redwood.berkeley.edu/w/images/9/95/2002-26.pdf |accessdate=2011-06-23 }}</ref>\n\nNote, however, that the above entropic uncertainty function is distinctly ''different'' from the quantum [[Von Neumann entropy]] represented in [[phase space]].\n\n==Sketch of proof==\nThe proof of this tight inequality depends on the so-called '''(''q'',&nbsp;''p'')-norm''' of the Fourier transformation.  (Establishing this norm is the most difficult part of the proof.)\n\nFrom this norm, one is able to establish a lower bound on the sum of the (differential) [[Rényi entropy|Rényi entropies]], {{math| ''H<sub>α</sub>({{!}}f{{!}}²)+H<sub>β</sub>({{!}}g{{!}}²)'' }}, where {{math|''1/α + 1/β'' {{=}} 2}}, which generalize the Shannon entropies.  For simplicity, we consider this inequality only in one dimension; the extension to multiple dimensions is straightforward and can be found in the literature cited.\n\n===Babenko–Beckner inequality===\nThe '''(''q'',&nbsp;''p'')-norm''' of the Fourier transform is defined to be<ref name=Bialynicki>{{Cite journal | doi = 10.1103/PhysRevA.74.052101| title = Formulation of the uncertainty relations in terms of the Rényi entropies| journal = Physical Review A| volume = 74| issue = 5| year = 2006| last1 = Bialynicki-Birula | first1 = I. |arxiv = quant-ph/0608116 |bibcode = 2006PhRvA..74e2101B }}</ref>\n\n:<math>\\|\\mathcal F\\|_{q,p} = \\sup_{f\\in L^p(\\mathbb R)} \\frac{\\|\\mathcal Ff\\|_q}{\\|f\\|_p},</math>   where <math>1 < p \\le 2~,</math> &nbsp; and <math>\\frac 1 p + \\frac 1 q = 1.</math>\n\nIn 1961, Babenko<ref>K.I. Babenko.  ''An inequality in the theory of Fourier integrals.'' Izv. Akad. Nauk SSSR, Ser. Mat. '''25''' (1961) pp. 531&ndash;542 English transl., Amer. Math. Soc. Transl. (2) '''44''', pp. 115-128</ref> found this norm for ''even'' integer values of ''q''.  Finally, in 1975,\nusing [[Hermite functions]] as eigenfunctions of the Fourier transform, Beckner<ref name=Beckner/> proved that the value of this norm (in one dimension) for all ''q''  ≥  2  is\n:<math>\\|\\mathcal F\\|_{q,p} = \\sqrt{p^{1/p}/q^{1/q}}.</math>\nThus we have the '''[[Babenko–Beckner inequality]]''' that\n:<math>\\|\\mathcal Ff\\|_q \\le \\left(p^{1/p}/q^{1/q}\\right)^{1/2} \\|f\\|_p.</math>\n\n===Rényi entropy bound===\nFrom this inequality, an expression of the uncertainty principle in terms of the [[Rényi entropy]] can be derived.<ref name=Bialynicki/><ref>H.P. Heinig and M. Smith, ''Extensions of the Heisenberg–Weil inequality.'' Internat. J. Math. & Math. Sci., Vol. 9, No. 1 (1986) pp. 185&ndash;192. [http://www.hindawi.com/GetArticle.aspx?doi=10.1155/S0161171286000212]</ref>\n\nLetting <math>g=\\mathcal Ff</math>,  2''α''=''p'',  and 2''β''=''q'',   so that  {{math|''1/α + 1/β'' {{=}} 2}}  and   1/2<''α''<1<''β'',  we have\n:<math>\\left(\\int_{\\mathbb R} |g(y)|^{2\\beta}\\,dy\\right)^{1/2\\beta}\n       \\le \\frac{(2\\alpha)^{1/4\\alpha}}{(2\\beta)^{1/4\\beta}}\n       \\left(\\int_{\\mathbb R} |f(x)|^{2\\alpha}\\,dx\\right)^{1/2\\alpha}.\n</math>\nSquaring both sides and taking the logarithm, we get\n:<math>\\frac 1\\beta \\log\\left(\\int_{\\mathbb R} |g(y)|^{2\\beta}\\,dy\\right)\n       \\le \\frac 1 2 \\log\\frac{(2\\alpha)^{1/\\alpha}}{(2\\beta)^{1/\\beta}}\n       + \\frac 1\\alpha \\log \\left(\\int_{\\mathbb R} |f(x)|^{2\\alpha}\\,dx\\right).\n</math>\n\nMultiplying both sides by \n:<math>\\frac{\\beta}{1-\\beta}=-\\frac{\\alpha}{1-\\alpha}</math> \nreverses the sense of the inequality,\n:<math>\\frac {1}{1-\\beta} \\log\\left(\\int_{\\mathbb R} |g(y)|^{2\\beta}\\,dy\\right)\n       \\ge \\frac\\alpha{2(\\alpha-1)}\\log\\frac{(2\\alpha)^{1/\\alpha}}{(2\\beta)^{1/\\beta}}\n       - \\frac{1}{1-\\alpha} \\log \\left(\\int_{\\mathbb R} |f(x)|^{2\\alpha}\\,dx\\right) ~.\n</math>\n\nRearranging terms, finally yields  an inequality in terms of the sum of the Rényi entropies,\n:<math>\\frac{1}{1-\\alpha} \\log \\left(\\int_{\\mathbb R} |f(x)|^{2\\alpha}\\,dx\\right)\n       + \\frac {1}{1-\\beta} \\log\\left(\\int_{\\mathbb R} |g(y)|^{2\\beta}\\,dy\\right)\n       \\ge \\frac\\alpha{2(\\alpha-1)}\\log\\frac{(2\\alpha)^{1/\\alpha}}{(2\\beta)^{1/\\beta}};\n</math>\n:<math> H_\\alpha(|f|^2) + H_\\beta(|g|^2) \\ge \\frac 1 2 \\left(\\frac{\\log\\alpha}{\\alpha-1}+\\frac{\\log\\beta}{\\beta-1}\\right) - \\log 2     ~.</math>\n\nNote that this inequality is symmetric with respect to  {{mvar|α}}  and {{mvar|β}}:  One no longer need assume that {{math|'' α<β''}};  only that they are positive and not both one, and that  ''1/α + 1/β''   = 2.    To see this symmetry, simply exchange the rôles of  ''i''  and −''i''  in the Fourier transform.\n\n===Shannon entropy bound===\nTaking the limit of this last inequality as ''α, β''  → 1 yields the less general Shannon entropy inequality,\n:<math>H(|f|^2) + H(|g|^2) \\ge \\log\\frac e 2,\\quad\\textrm{where}\\quad g(y) \\approx \\int_{\\mathbb R} e^{-2\\pi ixy}f(x)\\,dx~,</math>\nvalid for any base of logarithm, as long as we choose an appropriate unit of information, [[bit]], [[Nat (unit)|nat]], etc.\n\nThe constant will be different, though, for a different normalization of the Fourier transform, (such as is usually used in physics, with normalizations chosen so that ''ħ''=1 ), i.e.,\n:<math>H(|f|^2) + H(|g|^2) \\ge \\log(\\pi e)\\quad\\textrm{for}\\quad g(y) \\approx \\frac 1{\\sqrt{2\\pi}}\\int_{\\mathbb R} e^{-ixy}f(x)\\,dx~.</math>\nIn this case, the dilation of the Fourier transform absolute squared by a factor of 2{{mvar|π}}  simply adds log(2{{mvar|π}}) to its entropy.\n\n==Entropy versus variance bounds==\nThe Gaussian or [[normal probability distribution]] plays an important role in the relationship between [[variance]] and [[Differential entropy|entropy]]:  it is a problem of the [[calculus of variations]] to show that this distribution maximizes entropy for a given variance, and at the same time minimizes the variance for a given entropy.  In fact, for any probability density function  ''φ'' on the real line, Shannon's entropy inequality specifies:\n:<math>H(\\phi) \\le \\log \\sqrt {2\\pi eV(\\phi)},</math>\nwhere ''H'' is the Shannon entropy and ''V'' is the variance, an inequality that is saturated only in the case of a [[normal distribution]].\n\nMoreover, the Fourier transform of a Gaussian probability amplitude function is also Gaussian—and the absolute squares of both of these are Gaussian, too.  This  can then be used to derive the usual Robertson variance uncertainty inequality from the above entropic inequality, enabling ''the latter to be tighter than the former''. That is (for ''ħ''=1), exponentiating the Hirschman inequality and using Shannon's expression above, \n:<math>1/2 \\le \\exp (H(|f|^2)+H(|g|^2))         /(2e\\pi)    \\le \\sqrt {V(|f|^2)V(|g|^2)}~.</math>\n\nHirschman<ref name=Hirschman/> explained that entropy—his version of entropy was the negative of Shannon's—is a \"measure of the concentration of [a probability distribution] in a set of small measure.\"  Thus ''a low or large negative Shannon entropy means that a considerable mass of the probability distribution is confined to a set of small measure''.\n\nNote that this set of small measure need not be contiguous; a probability distribution can have several concentrations of mass in intervals of small measure, and the entropy may still be low no matter how widely scattered those intervals are.  This is not the case with the variance:  variance measures the concentration of mass about the mean of the distribution, and a low variance means that a considerable mass of the probability distribution is concentrated in a ''contiguous interval'' of small measure.\n\nTo formalize this distinction,  we say that two probability density functions  ''φ''<sub>1</sub>  and ''φ''<sub>2</sub> are '''equimeasurable''' if\n:<math>\\forall \\delta > 0,\\,\\mu\\{x\\in\\mathbb R|\\phi_1(x)\\ge\\delta\\} = \\mu\\{x\\in\\mathbb R|\\phi_2(x)\\ge\\delta\\},</math>\nwhere {{mvar|μ}}  is the [[Lebesgue measure]].  Any two equimeasurable probability density functions have the same Shannon entropy, and in fact the same Rényi entropy, of any order.  The same is not true of variance, however.  Any probability density function has a radially decreasing equimeasurable \"rearrangement\" whose variance is less (up to translation) than any other rearrangement of the function; and there exist rearrangements of arbitrarily high variance, (all having the same entropy.)\n\n==See also==\n* [[Inequalities in information theory]]\n* [[Uncertainty principle]]\n* [[Riesz–Thorin theorem]]\n* [[Fourier Transform]]\n\n==References==\n<references/>\n\n==Further reading==\n* Jizba, P.; Ma,Y.; Hayes, A.; Dunningham, J.A. (2016). \"One-parameter class of uncertainty relations based on entropy power\". ''Phys. Rev. E'' '''93''' (6): 060104(R). [https://journals.aps.org/pre/abstract/10.1103/PhysRevE.93.060104 doi:10.1103/PhysRevE.93.060104]. \n* {{Cite journal | last1 = Zozor | first1 = S. | last2 = Vignat | first2 = C. | doi = 10.1016/j.physa.2006.09.019 | title = On classes of non-Gaussian asymptotic minimizers in entropic uncertainty principles | journal = Physica A: Statistical Mechanics and its Applications | volume = 375 | issue = 2 | pages = 499 | year = 2007 | pmid =  | pmc = |arxiv = math/0605510 |bibcode = 2007PhyA..375..499Z }}    [https://arxiv.org/abs/math/0605510v1 arXiv:math/0605510v1]\n* {{Cite journal | last1 = Maassen | first1 = H. | last2 = Uffink | first2 = J. | doi = 10.1103/PhysRevLett.60.1103 | title = Generalized entropic uncertainty relations | journal = Physical Review Letters | volume = 60 | issue = 12 | pages = 1103–1106 | year = 1988 | pmid =  10037942| pmc = |bibcode = 1988PhRvL..60.1103M | url = https://pure.uva.nl/ws/files/2210736/46650_28y.pdf }}\n* {{Cite journal | doi = 10.1103/PhysRevA.75.022319| title = Entropic uncertainty relations and locking: Tight bounds for mutually unbiased bases| journal = Physical Review A| volume = 75| issue = 2| year = 2007| last1 = Ballester | first1 = M. | last2 = Wehner | first2 = S. |arxiv = quant-ph/0606244 |bibcode = 2007PhRvA..75b2319B }}\n* {{Cite journal | doi = 10.1016/j.physleta.2003.08.029| title = An optimal entropic uncertainty relation in a two-dimensional Hilbert space| journal = Physics Letters A| volume = 317| pages = 32| year = 2003| last1 = Ghirardi | first1 = G. | last2 = Marinatto | first2 = L. | last3 = Romano | first3 = R. |arxiv = quant-ph/0310120 |bibcode = 2003PhLA..317...32G }}\n* {{Cite journal | doi = 10.1023/A:1007464229188| title = Minimum uncertainty for antisymmetric wave functions| journal = Letters in Mathematical Physics| volume = 43| pages = 233| year = 1998| last1 = Salcedo | first1 = L. L. |arxiv = quant-ph/9706015 |bibcode = 1997quant.ph..6015S}}\n\n{{DEFAULTSORT:Hirschman Uncertainty}}\n[[Category:Quantum mechanical entropy]]\n[[Category:Information theory]]\n[[Category:Concepts in physics]]\n[[Category:Inequalities]]"
    },
    {
      "title": "HM-GM-AM-QM inequalities",
      "url": "https://en.wikipedia.org/wiki/HM-GM-AM-QM_inequalities",
      "text": "{{multiple issues|\n{{notability|date=March 2019}}\n{{one source|date=March 2019}}\n{{Orphan|date=June 2019}}\n}}\n{{short description|mathematical relationships}}\n\nIn mathematincs, the '''HM-GM-AM-QM inequalities''' state the relationship between the [[harmonic mean]], [[geometric mean]], [[arithmetic mean]], and [[Root mean square|quadratic mean]] (aka root mean square, RMS). Suppose that   <math>x_1,x_2,\\ldots,x_n</math>are positive real numbers. Then\n\n: <math>0<\\frac{n}{1/x_1+1/x_2+\\cdots+1/x_n}\\leq\\sqrt[n]{x_1x_2\\cdots x_n}\\leq\\frac{x_1+x_2+\\cdots+x_n}{n} \\leq\\sqrt{\\frac{x_1^2+x_2^2+\\cdots+x_n^2}{n}}.</math>\n\nThese inequalities often appear in mathematical competitions and have applications in many science fields.\n\n== Proof ==\nThere are various methods to prove, including [[mathematical induction]], the [[Cauchy–Schwarz inequality]], [[Lagrange multiplier]]s, and [[Jensen's inequality]]. The links to some methods of proof are included below.\n\n== The ''n'' = 2 case ==\n[[File:HM-GM-AM-QM inequality n=2 case visualization .jpg|thumb|The semi-circle used to visualize the inequalities]]\nWhen ''n''&nbsp;=&nbsp;2, the inequalities become <math>\\frac 2 {\\frac{1}{x_1}+\\frac{1}{x_2}} \\leq \\sqrt{x_1x_2} \\leq \\frac{x_1+x_2}{2}\\leq\\sqrt{\\frac{x_1^2+x_2^2}{2}}</math>which can be visualized in a semi-circle whose diameter is [''AB''] and center&nbsp;''D''.\n\nSuppose ''AC''&nbsp;=&nbsp;''a'' and ''BC''&nbsp;=&nbsp;''b''. Construct perpendiculars to [''AB''] at ''D'' and ''C'' respectively. Join [''CE''] and [''DF''] and further construct a perpendicular [''CG''] to [''DF''] at ''G''. Then the length of ''DF'' can be calculated to be ''HM'', ''CF'' to be ''GM'', ''DE'' to be ''AM'', and ''CE'' to be ''QM'' (or RMS). By the [[Pythagorean theorem]] the inequalities are easy to show.\n\n== External links ==\n*[https://www.maa.org/sites/default/files/gwan01200422828.pdf Data]\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Hölder's inequality",
      "url": "https://en.wikipedia.org/wiki/H%C3%B6lder%27s_inequality",
      "text": "In [[mathematical analysis]], '''Hölder's inequality''', named after [[Otto Hölder]], is a fundamental [[inequality (mathematics)|inequality]] between [[Lebesgue integration|integrals]] and an indispensable tool for the study of [[Lp space|{{math|''L<sup>p</sup>''}} spaces]].\n\n:'''Theorem (Hölder's inequality).''' Let {{math|(''S'', Σ, ''μ'')}} be a [[measure space]] and let {{math|''p'', ''q'' ∈}} {{closed-closed|1, ∞}} with {{math|1/''p'' + 1/''q'' {{=}} 1}}. Then, for all [[measurable function|measurable]] [[real number|real]]- or [[complex number|complex]]-valued [[function (mathematics)|functions]] {{mvar|f}} and {{mvar|g}} on {{mvar|S}},\n\n::<math>\\|fg\\|_1 \\le \\|f\\|_p \\|g\\|_q.</math>\n\n:If, in addition, {{math|''p'', ''q'' ∈}} {{open-open|1, ∞}} and {{math|''f'' ∈ ''L<sup>p</sup>''(''μ'')}} and {{math|''g'' ∈ ''L<sup>q</sup>''(''μ'')}}, then Hölder's inequality becomes an equality iff {{math|{{abs|''f''&thinsp;}}<sup>''p''</sup>}} and {{math|{{!}}''g''{{!}}<sup>''q''</sup>}} are [[Linear dependence|linearly dependent]] in {{math|''L''<sup>1</sup>(''μ'')}}, meaning that there exist real numbers {{math|''α'', ''β'' ≥ 0}}, not both of them zero, such that {{math|''α''{{!}}''f''&thinsp;{{!}}<sup>''p''</sup> {{=}} ''β'' {{!}}''g''{{!}}<sup>''q''</sup>}} {{mvar|μ}}-[[almost everywhere]].\n\nThe numbers {{mvar|p}} and {{mvar|q}} above are said to be '''Hölder conjugates''' of each other. The special case {{math|''p'' {{=}} ''q'' {{=}} 2}} gives a form of the [[Cauchy–Schwarz inequality]]. Hölder's inequality holds even if {{math|{{norm|''fg''}}<sub>1</sub>}} is infinite, the right-hand side also being infinite in that case. Conversely, if {{mvar|f}}&thinsp; is in {{math|''L<sup>p</sup>''(''μ'')}} and {{mvar|g}} is in {{math|''L<sup>q</sup>''(''μ'')}}, then the pointwise product {{math|''fg''}} is in {{math|''L''<sup>1</sup>(''μ'')}}.\n\nHölder's inequality is used to prove the [[Minkowski inequality]], which is the [[triangle inequality]] in the space {{math|''L<sup>p</sup>''(''μ'')}}, and also to establish that {{math|''L<sup>q</sup>''(''μ'')}} is the [[dual space]] of {{math|''L<sup>p</sup>''(''μ'')}} for {{math|''p'' ∈}} {{closed-open|1, ∞}}.\n\nHölder's inequality was first found by [[Leonard James Rogers]] ({{harvtxt|Rogers|1888}}), and discovered independently by {{harvtxt|Hölder|1889}}.\n\n==Remarks==\n\n===Conventions===\nThe brief statement of Hölder's inequality uses some conventions.\n\n* In the definition of Hölder conjugates, {{math|1/&thinsp;∞}} means zero.\n* If {{math|''p'', ''q'' ∈}} {{closed-open|1, ∞}}, then {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub>}} and {{math|{{norm|''g''}}<sub>''q''</sub>}} stand for the (possibly infinite) expressions\n::<math>\\begin{align}\n&\\left(\\int_S |f|^p\\,\\mathrm{d}\\mu\\right)^{\\frac{1}{p}} \\\\\n&\\left(\\int_S |g|^q\\,\\mathrm{d}\\mu\\right)^{\\frac{1}{q}}\n\\end{align}</math>\n\n* If {{math|''p'' {{=}} ∞}}, then {{math|{{norm|''f''&thinsp;}}<sub>∞</sub>}} stands for the [[essential supremum]] of {{math|{{abs|''f''&thinsp;}}}}, similarly for {{math|{{norm|''g''}}<sub>∞</sub>}}.\n* The notation {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub>}} with {{math|1 ≤ ''p'' ≤ ∞}} is a slight abuse, because in general it is only a [[norm (mathematics)|norm]] of {{mvar|f}}&thinsp; if {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub>}} is finite and {{mvar|f}}&thinsp; is considered as [[equivalence class]] of {{mvar|μ}}-almost everywhere equal functions. If  {{math|''f'' ∈ ''L<sup>p</sup>''(''μ'')}} and {{math|''g'' ∈ ''L<sup>q</sup>''(''μ'')}}, then the notation is adequate.\n* On the right-hand side of Hölder's inequality, 0 × ∞ as well as ∞ × 0 means&nbsp;0. Multiplying {{math|''a'' > 0}} with ∞ gives&nbsp;∞.\n\n===Estimates for integrable products===\nAs above, let {{mvar|f}}&thinsp; and {{mvar|g}} denote measurable real- or complex-valued functions defined on {{mvar|S}}. If {{math|{{norm|''fg''}}<sub>1</sub>}} is finite, then the pointwise products of {{mvar|f}}&thinsp; with {{mvar|g}} and its [[complex conjugate]] function are {{mvar|μ}}-integrable, the estimate\n\n:<math>\\biggl|\\int_S f\\bar g\\,\\mathrm{d}\\mu\\biggr|\\le\\int_S|fg|\\,\\mathrm{d}\\mu =\\|fg\\|_1</math>\n\nand the similar one for {{math|''fg''}} hold, and Hölder's inequality can be applied to the right-hand side. In particular, if {{mvar|f}}&thinsp; and {{mvar|g}} are in the [[Hilbert space]] {{math|''L''<sup>2</sup>(''μ'')}}, then Hölder's inequality for {{math|''p'' {{=}} ''q'' {{=}} 2}} implies\n\n:<math>|\\langle f,g\\rangle| \\le \\|f\\|_2 \\|g\\|_2,</math>\n\nwhere the angle brackets refer to the [[inner product]] of {{math|''L''<sup>2</sup>(''μ'')}}. This is also called [[Cauchy–Schwarz inequality]], but requires for its statement that {{math|{{norm|''f''&thinsp;}}<sub>2</sub>}} and {{math|{{norm|''g''}}<sub>2</sub>}} are finite to make sure that the inner product of {{mvar|f}}&thinsp; and {{mvar|g}} is well defined. We may recover the original inequality (for the case {{math|''p'' {{=}} 2}}) by using the functions {{math|{{abs|''f''&thinsp;}}}} and {{math|{{abs|''g''}}}} in place of {{mvar|f}}&thinsp; and {{mvar|g}}.\n\n===Generalization for probability measures===\nIf {{math|(''S'',&thinsp;Σ,&thinsp;''μ'')}} is a [[probability space]], then {{math|''p'', ''q'' ∈}} {{closed-closed|1, ∞}} just need to satisfy {{math|1/''p'' + 1/''q'' ≤ 1}}, rather than being Hölder conjugates. A combination of Hölder's inequality and [[Jensen's inequality]] implies that\n\n:<math>\\|fg\\|_1 \\le \\|f\\|_p \\|g\\|_q</math>\n\nfor all measurable real- or complex-valued functions {{mvar|f}}&thinsp; and {{mvar|g}} on&nbsp;{{mvar|S}}.\n\n==Notable special cases==\nFor the following cases assume that {{mvar|p}} and {{mvar|q}} are in the open interval {{open-open|1,∞}} with {{math|1/''p'' + 1/''q'' {{=}} 1}}.\n\n===Counting measure===\nFor the {{mvar|n}}-dimensional [[Euclidean space]], when the set {{mvar|S}} is {{math|{{mset|1, ..., ''n''}}}} with the [[counting measure]], we have\n\n:<math>\\sum_{k=1}^n |x_k\\,y_k| \\le \\biggl( \\sum_{k=1}^n |x_k|^p \\biggr)^{\\frac{1}{p}} \\biggl( \\sum_{k=1}^n |y_k|^q \\biggr)^{\\frac{1}{q}}\n\\text{ for all }(x_1,\\ldots,x_n),(y_1,\\ldots,y_n)\\in\\mathbb{R}^n\\text{ or }\\mathbb{C}^n.</math>\n\nIf {{math|''S'' {{=}} '''N'''}} with the counting measure, then we get Hölder's inequality for [[sequence space]]s:\n\n:<math>\\sum_{k=1}^{\\infty} |x_k\\,y_k| \\le \\biggl( \\sum_{k=1}^{\\infty} |x_k|^p \\biggr)^{\\frac{1}{p}} \\left( \\sum_{k=1}^{\\infty} |y_k|^q \\right)^{\\frac{1}{q}}\n\\text{ for all }(x_k)_{k\\in\\mathbb N}, (y_k)_{k\\in\\mathbb N}\\in\\mathbb{R}^{\\mathbb N}\\text{ or }\\mathbb{C}^{\\mathbb N}.</math>\n\n===Lebesgue measure===\nIf {{mvar|S}} is a measurable subset of {{math|'''R'''<sup>''n''</sup>}} with the [[Lebesgue measure]], and {{mvar|f}}&thinsp; and {{mvar|g}} are measurable real- or complex-valued functions on&nbsp;{{mvar|S}}, then Hölder inequality is\n\n:<math>\\int_S \\bigl| f(x)g(x)\\bigr| \\,\\mathrm{d}x \\le\\biggl(\\int_S |f(x)|^p\\,\\mathrm{d}x\\biggr)^{\\frac{1}{p}} \\biggl(\\int_S |g(x)|^q\\,\\mathrm{d}x\\biggr)^{\\frac{1}{q}}.</math>\n\n===Probability measure===\nFor the [[probability space]] <math>(\\Omega, \\mathcal{F}, \\mathbb{P}),</math> let <math>\\mathbb{E}</math> denote the [[expected value|expectation operator]]. For real- or complex-valued [[random variable]]s <math>X</math> and <math>Y</math> on <math>\\Omega,</math> Hölder's inequality reads\n\n:<math>\\mathbb{E}[|XY|] \\leqslant \\left (\\mathbb{E}\\bigl[ |X|^p\\bigr]\\right)^{\\frac{1}{p}} \\left(\\mathbb{E}\\bigl[|Y|^q\\bigr]\\right)^{\\frac{1}{q}}.</math>\n\nLet <math>0 < r< s</math>  and define <math>p = \\tfrac{s}{r}.</math> Then <math>q = \\tfrac{p}{p-1}</math> is the Hölder conjugate of <math>p.</math> Applying Hölder's inequality to the random variables <math>|X|^r</math> and <math>1_{\\Omega}</math> we obtain\n\n:<math>\\mathbb{E}\\bigl[|X|^r\\bigr]\\leqslant \\left(\\mathbb{E}\\bigl[|X|^s\\bigr]\\right)^{\\frac{r}{s}}.</math>\n\nIn particular, if the {{mvar|s}}<sup>th</sup> absolute [[moment (mathematics)|moment]] is finite, then the {{mvar|r}}<sup>&nbsp;th</sup> absolute moment is finite, too. (This also follows from [[Jensen's inequality]].)\n\n===Product measure===\nFor two [[σ-finite measure|σ-finite]] measure spaces {{math|(''S''<sub>1</sub>, Σ<sub>1</sub>, ''μ''<sub>1</sub>)}} and {{math|(''S''<sub>2</sub>, Σ<sub>2</sub>, ''μ''<sub>2</sub>)}} define the [[product measure space]] by\n\n:<math>S=S_1\\times S_2,\\quad \\Sigma=\\Sigma_1\\otimes\\Sigma_2,\\quad \\mu=\\mu_1\\otimes\\mu_2,</math>\n\nwhere {{mvar|S}} is the [[Cartesian product]] of {{math|''S''<sub>1</sub>}} and {{math|''S''<sub>2</sub>}}, the {{nowrap|[[σ-algebra]] {{math|Σ}}}} arises as [[product σ-algebra]] of {{math|Σ<sub>1</sub>}} and {{math|Σ<sub>2</sub>}}, and {{mvar|μ}} denotes the [[product measure]] of {{math|''μ''<sub>1</sub>}} and {{math|''μ''<sub>2</sub>}}. Then [[Fubini's theorem#Tonelli.27s theorem|Tonelli's theorem]] allows us to rewrite  Hölder's inequality using iterated integrals: If&nbsp;{{mvar|f}}&thinsp; and {{mvar|g}} are {{nowrap|{{math|Σ}}-measurable}} real- or complex-valued functions on the Cartesian product&nbsp;{{mvar|S}}, then\n\n:<math>\\int_{S_1}\\int_{S_2}|f(x,y)\\,g(x,y)|\\,\\mu_2(\\mathrm{d}y)\\,\\mu_1(\\mathrm{d}x) \\le\\left(\\int_{S_1}\\int_{S_2}|f(x,y)|^p\\,\\mu_2(\\mathrm{d}y)\\,\\mu_1(\\mathrm{d}x)\\right)^{\\frac{1}{p}}\\left(\\int_{S_1}\\int_{S_2}|g(x,y)|^q\\,\\mu_2(\\mathrm{d}y)\\,\\mu_1(\\mathrm{d}x)\\right)^{\\frac{1}{q}}.</math>\n\nThis can be generalized to more than two {{nowrap|σ-finite}} measure spaces.\n\n===Vector-valued functions===\nLet {{math|(''S'', Σ, ''μ'')}} denote a {{nowrap|σ-finite}} measure space and suppose that {{math|''f'' {{=}} (''f''<sub>1</sub>, ..., ''f<sub>n</sub>'')}} and {{math|''g'' {{=}} (''g''<sub>1</sub>, ..., ''g<sub>n</sub>'')}} are {{math|Σ}}-measurable functions on {{mvar|S}}, taking values in the {{mvar|n}}-dimensional real- or complex Euclidean space. By taking the product with the counting measure on {{math|{{mset|1, ..., ''n''}}}}, we can rewrite the above product measure version of Hölder's inequality in the form\n\n:<math> \\int_S \\sum_{k=1}^n|f_k(x)\\,g_k(x)|\\,\\mu(\\mathrm{d}x) \\le \\left(\\int_S\\sum_{k=1}^n|f_k(x)|^p\\,\\mu(\\mathrm{d}x)\\right)^{\\frac{1}{p}}\\left(\\int_S\\sum_{k=1}^n|g_k(x)|^q\\,\\mu(\\mathrm{d}x)\\right)^{\\frac{1}{q}}.</math>\n\nIf the two integrals on the right-hand side are finite, then equality holds if and only if there exist real numbers {{math|''α'', ''β'' ≥ 0}}, not both of them zero, such that\n\n:<math>\\alpha \\left (|f_1(x)|^p,\\ldots,|f_n(x)|^p \\right )= \\beta \\left (|g_1(x)|^q,\\ldots,|g_n(x)|^q \\right ),</math>\n\nfor {{mvar|μ}}-almost all {{mvar|x}} in {{mvar|S}}.\n\nThis finite-dimensional version generalizes to functions {{mvar|f}}&thinsp; and {{mvar|g}} taking values in a [[normed space]] which could be for example a [[sequence space]] or an [[inner product space]].\n\n== Proof of Hölder's inequality ==\nThere are several proofs of Hölder's inequality; the main idea in the following is [[Young's inequality for products]].\n\nIf {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub> {{=}} 0}}, then {{mvar|f}}&thinsp; is zero {{mvar|μ}}-almost everywhere, and the product {{math|''fg''}} is zero {{mvar|μ}}-almost everywhere, hence the left-hand side of Hölder's inequality is zero. The same is true if {{math|{{norm|''g''}}<sub>''q''</sub> {{=}} 0}}. Therefore, we may assume {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub> > 0}} and {{math|{{norm|''g''}}<sub>''q''</sub> > 0}} in the following.\n\nIf {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub> {{=}} ∞}} or {{math|{{norm|''g''}}<sub>''q''</sub> {{=}} ∞}}, then the right-hand side of Hölder's inequality is infinite. Therefore, we may assume that {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub>}} and {{math|{{norm|''g''}}<sub>''q''</sub>}} are in {{open-open|0,&thinsp;∞}}.\n\nIf {{math|''p'' {{=}} ∞}} and {{math|''q'' {{=}} 1}}, then {{math|{{abs|''fg''}} ≤ {{norm|''f''&thinsp;}}<sub>∞</sub> {{abs|''g''}}}} almost everywhere and Hölder's inequality follows from the monotonicity of the Lebesgue integral. Similarly for {{math|''p'' {{=}} 1}} and {{math|''q'' {{=}} ∞}}. Therefore, we may also assume {{math|''p'', ''q'' ∈}} {{open-open|1,&thinsp;∞}}.\n\nDividing {{mvar|f}}&thinsp; and {{mvar|g}} by {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub>}} and {{math|{{norm|''g''}}<sub>''q''</sub>}}, respectively, we can assume that\n\n:<math>\\|f\\|_p = \\|g\\|_q = 1.</math>\n\nWe now use [[Young's inequality for products]], which states that\n\n:<math>a b \\le \\frac{a^p}p + \\frac{b^q}q</math>\n\nfor all nonnegative {{mvar|a}} and {{mvar|b}}, where equality is achieved if and only if {{math|''a<sup>p</sup>'' {{=}} ''b<sup>q</sup>''}}. Hence\n\n:<math>|f(s)g(s)| \\le \\frac{|f(s)|^p}p + \\frac{|g(s)|^q}q,\\qquad s\\in S.</math>\n\nIntegrating both sides gives\n\n:<math>\\|fg\\|_1 \\le \\frac{\\|f\\|_p^p}{p} + \\frac{\\|g\\|_q^q}{q} = \\frac{1}{p} + \\frac{1}{q} = 1,</math>\n\nwhich proves the claim.\n\nUnder the assumptions {{math|''p'' ∈}} {{open-open|1,&thinsp;∞}} and {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub> {{=}} {{norm|''g''}}<sub>''q''</sub>}}, equality holds if and only if {{math|{{abs|''f''&thinsp;}}<sup>''p''</sup> {{=}} {{abs|''g''}}<sup>''q''</sup>}} almost everywhere. More generally, if {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub>}} and {{math|{{norm|''g''}}<sub>''q''</sub>}} are in {{open-open|0,&thinsp;∞}}, then Hölder's inequality becomes an equality if and only if there exist real numbers {{math|''α'', ''β'' > 0}}, namely\n\n:<math>\\alpha=\\|g\\|_q^q, \\qquad \\beta=\\|f\\|_p^p,</math>\n\nsuch that\n\n:<math>\\alpha |f|^p = \\beta |g|^q</math>&nbsp;&nbsp;&nbsp;''μ''-almost everywhere&nbsp;&nbsp;&nbsp;(*).\n\nThe case {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub> {{=}} 0}} corresponds to {{math|''β'' {{=}} 0}} in (*). The case {{math|{{norm|''g''}}<sub>''q''</sub> {{=}} 0}} corresponds to {{math|''α'' {{=}} 0}} in (*).\n\n<div style=\"clear:both;width:95%;\" class=\"NavFrame\">\n<div class=\"NavHead\" style=\"background-color:#FFFAF0; text-align:left; font-size:larger;\">Alternate proof using Jensen's inequality</div>\n<div class=\"NavContent\" style=\"text-align:left;display:none;\">\nRecall the [[Jensen's inequality]] for the convex function <math>x^p</math> (it is convex because obviously <math>p\\geq1</math>):\n\n:<math>\\int hd\\nu\\leq\\left(\\int h^pd\\nu \\right )^{\\frac{1}{p}}</math>\n\nwhere {{mvar|ν}} is any probability distribution and {{mvar|''h''}} any {{mvar|ν}}-measurable function. Let {{mvar|μ}} be any measure, and {{mvar|ν}} the distribution whose density w.r.t. {{mvar|μ}} is proportional to <math>g^q</math>, i.e.\n\n:<math>d\\nu = \\frac{g^q}{\\int g^q\\,d\\mu}d\\mu</math>\n\nHence we have, using <math>\\frac{1}{p}+\\frac{1}{q}=1</math>, hence <math>p(1-q)+q=0</math>, and letting <math>h=fg^{1-q}</math>,\n\n:<math>\\int fg\\,d\\mu = \\left (\\int g^q\\,d\\mu \\right )\\int \\underbrace{fg^{1-q}}_h\\underbrace{\\frac{g^q}{\\int g^q\\,d\\mu}d\\mu}_{d\\nu} \\leq \\left (\\int g^qd\\mu \\right ) \\left (\\int \\underbrace{f^pg^{p(1-q)}}_{h^p}\\underbrace{\\frac{g^q}{\\int g^q\\,d\\mu}\\,d\\mu}_{d\\nu} \\right )^{\\frac{1}{p}} = \\left (\\int g^q\\,d\\mu \\right ) \\left (\\int \\frac{f^p}{\\int g^q\\,d\\mu}\\,d\\mu \\right )^{\\frac{1}{p}}</math>\n\nFinally, we get\n\n:<math>\\int fg\\,d\\mu \\leq \\left(\\int f^p\\,d\\mu \\right )^{\\frac{1}{p}} \\left(\\int g^q\\,d\\mu \\right )^{\\frac{1}{q}}</math>\n\nThis assumes <math>f,g</math> real and non negative, but the extension to complex functions is straightforward (use the modulus of <math>f,g</math>). It also assumes that <math>\\|f\\|_p,\\|g\\|_q</math> are neither null nor infinity, and that <math>p,q>1</math>: all these assumptions can also be lifted as in the proof above.\n</div>\n</div>\n\n== Extremal equality ==\n\n=== Statement ===\nAssume that {{math|1 ≤ ''p'' < ∞}} and let {{mvar|q}} denote the Hölder conjugate. Then, for every {{math|''f'' ∈ ''L<sup>p</sup>''(''μ'')}},\n\n:<math>\\|f\\|_p = \\max \\left \\{ \\left| \\int_S f g \\, \\mathrm{d}\\mu \\right | : g\\in L^q(\\mu), \\|g\\|_q \\le 1 \\right\\},</math>\n\nwhere max indicates that there actually is a {{mvar|g}} maximizing the right-hand side. When {{math|''p'' {{=}} ∞}} and if each set {{mvar|A}} in the {{nowrap|σ-field}} {{math|Σ}} with {{math|''μ''(''A'') {{=}} ∞}} contains a subset {{math|''B'' ∈ Σ}} with {{math|0 < ''μ''(''B'') < ∞}} (which is true in particular when {{mvar|μ}} is {{nowrap|[[σ-finite]]}}), then\n\n:<math>\\|f\\|_\\infty = \\sup \\left\\{ \\left| \\int_S f g \\,\\mathrm{d}\\mu \\right| : g\\in L^1(\\mu), \\|g\\|_1 \\le 1 \\right \\}.</math>\n\n<div style=\"clear:both;width:95%;\" class=\"NavFrame\">\n<div class=\"NavHead\" style=\"background-color:#FFFAF0; text-align:left; font-size:larger;\">Proof of the extremal equality</div>\n<div class=\"NavContent\" style=\"text-align:left;display:none;\">\n\nBy Hölder's inequality, the integrals are well defined and, for {{math|1 ≤ ''p'' ≤ ∞}},\n\n:<math>\\left |\\int_S fg\\,\\mathrm{d}\\mu\\right|\\le\\int_S|fg|\\,\\mathrm{d}\\mu\\le\\|f\\|_p,</math>\n\nhence the left-hand side is always bounded above by the right-hand side.\n\nConversely, for {{math|1 ≤ ''p'' ≤ ∞}}, observe first that the statement is obvious when {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub> {{=}} 0}}. Therefore, we assume {{math|{{norm|''f''&thinsp;}}<sub>''p''</sub> > 0}} in the following.\n\nIf {{math|1 ≤ ''p'' < ∞}}, define {{mvar|g}} on {{mvar|S}} by\n\n:<math>g(x) = \\begin{cases}\\|f\\|_p^{1-p} \\, |f(x)|^p / f(x)&\\text{if }f(x)\\not=0,\\\\ 0&\\text{otherwise.}\\end{cases}</math>\n\nBy checking the cases {{math|''p'' {{=}} 1}} and {{math|1 < ''p'' < ∞}} separately, we see that {{math|{{norm|''g''}}<sub>''q''</sub> {{=}} 1}} and\n\n:<math>\\int_S f g \\, \\mathrm{d}\\mu = \\|f\\|_p.</math>\n\nIt remains to consider the case {{math|''p'' {{=}} ∞}}. For {{math|''ε'' ∈}} {{open-open|0,&thinsp;1}} define\n\n:<math>A=\\left \\{x\\in S:|f(x)|>(1-\\varepsilon)\\|f\\|_\\infty\\right\\}.</math>\n\nSince {{mvar|f}}&thinsp; is measurable, {{math|''A'' ∈ Σ}}. By the definition of {{math|{{norm|''f''&thinsp;}}<sub>∞</sub>}} as the [[essential supremum]] of {{mvar|f}}&thinsp; and the assumption {{math|{{norm|''f''&thinsp;}}<sub>∞</sub> > 0}}, we have {{math|''μ''(''A'') > 0}}. Using the additional assumption on the {{nowrap|σ-field}} {{math|Σ}} if necessary, there exists a subset {{math|''B'' ∈ Σ}} of {{mvar|A}} with {{math|0 < ''μ''(''B'') < ∞}}. Define {{mvar|g}} on {{mvar|S}} by\n\n:<math>g(x)=\\begin{cases}\\frac{1-\\varepsilon}{\\mu(B)}\\frac{\\|f\\|_\\infty}{f(x)}&\\text{if }x\\in B,\\\\0&\\text{otherwise.}\\end{cases}</math>\n\nThen {{mvar|g}} is well-defined, measurable and {{math|{{abs|''g''(''x'')}} ≤ 1/''μ''(''B'')}} for {{math|''x'' ∈ ''B''}}, hence {{math|{{norm|''g''}}<sub>1</sub> ≤ 1}}. Furthermore,\n\n:<math>\\left |\\int_S fg\\,\\mathrm{d}\\mu\\right| = \\int_B\\frac{1-\\varepsilon}{\\mu(B)}\\|f\\|_\\infty\\,\\mathrm{d}\\mu = (1-\\varepsilon)\\|f\\|_\\infty.</math>\n</div>\n</div>\n\n=== Remarks and examples ===\n\n* The equality for <math>p = \\infty</math> fails whenever there exists a set <math>A</math> of infinite measure in the <math>\\sigma</math>-field <math>\\Sigma</math> with that has no subset <math>B \\in \\Sigma</math> that satisfies: <math>0 < \\mu(B) < \\infty.</math> (the simplest example is the <math>\\sigma</math>-field  <math>\\Sigma</math> containing just the empty set and <math>S,</math> and the measure <math>\\mu</math> with <math>\\mu(S) = \\infty.</math>) Then the [[indicator function]] <math>1_A</math> satisfies <math>\\|1_A\\|_{\\infty} = 1,</math> but every <math>g \\in L^1 (\\mu)</math> has to be <math>\\mu</math>-almost everywhere constant on <math>A,</math> because it is <math>\\Sigma</math>-measurable, and this constant has to be zero, because <math>g</math> is <math>\\mu</math>-integrable. Therefore, the above supremum for the indicator function <math>1_A</math> is zero and the extremal equality fails.\n* For <math>p = \\infty,</math> the supremum is in general not attained. As an example, let <math>S = \\mathbb{N}, \\Sigma = \\mathcal{P}(\\mathbb{N})</math> and <math>\\mu</math> the counting measure. Define:\n\n::<math>\\begin{cases} f: \\mathbb{N} \\to \\mathbb{R} \\\\ f(n) = \\frac{n-1}{n} \\end{cases}</math>\n\n:Then <math>\\|f\\|_{\\infty} = 1.</math> For <math>g \\in L^1 (\\mu, \\mathbb{N})</math> with <math>0 < \\|g\\|_1 \\leqslant 1,</math> let <math>m</math> denote the smallest natural number with <math>g(m) \\neq 0.</math> Then\n\n::<math>\\left |\\int_S fg\\,\\mathrm{d}\\mu\\right| \\leqslant \\frac{m-1}{m}|g(m)|+\\sum_{n=m+1}^\\infty|g(n)| = \\|g\\|_1-\\frac{|g(m)|}m<1.</math>\n\n=== Applications ===\n*The extremal equality is one of the ways for proving the triangle inequality {{math|{{norm|''f''<sub>1</sub> + ''f''<sub>2</sub>}}<sub>''p''</sub> ≤ {{norm|''f''<sub>1</sub>}}<sub>''p''</sub> + {{norm|''f''<sub>2</sub>}}<sub>''p''</sub>}} for all {{math|''f''<sub>1</sub>}} and {{math|''f''<sub>2</sub>}} in {{math|''L<sup>p</sup>''(''μ'')}}, see [[Minkowski inequality]].\n*Hölder's inequality implies that every {{math|''f'' ∈ ''L<sup>p</sup>''(''μ'')}} defines a bounded (or continuous) linear functional {{math|''κ<sub>f</sub>''}}&thinsp; on {{math|''L<sup>q</sup>''(''μ'')}} by the formula\n::<math>\\kappa_f(g) = \\int_S f g \\, \\mathrm{d}\\mu,\\qquad g\\in L^q(\\mu).</math>\n:The extremal equality (when true) shows that the norm of this functional {{math|''κ<sub>f</sub>''}}&thinsp; as element of the [[continuous dual space]] {{math|''L<sup>q</sup>''(''μ'')<sup>*</sup>}} coincides with the norm of {{mvar|f}}&thinsp; in {{math|''L<sup>p</sup>''(''μ'')}} (see also the {{nowrap|[[L^p-space|{{math|''L<sup>p</sup>''}}-space]]}} article).\n\n==Generalization of Hölder's inequality==\nAssume that {{math|''r'' ∈}} {{open-closed|0,&thinsp;∞}} and {{math|''p''<sub>1</sub>, …, ''p<sub>n</sub>'' ∈ }} {{open-closed|0,&thinsp;∞}} such that\n\n:<math>\\sum_{k=1}^n \\frac1{p_k}=\\frac1r</math>\n\n(where we interpret 1/∞ as 0 in this equation).  Then, for all measurable real- or complex-valued functions {{math|''f''<sub>1</sub>, …, ''f<sub>n</sub>''}} defined on {{mvar|S}},\n\n:<math>\\left\\|\\prod_{k=1}^n f_k\\right\\|_r\\le \\prod_{k=1}^n\\|f_k\\|_{p_k}</math>\n\n(where we interpret any product with a factor of ∞ as ∞ if all factors are positive, but the product is 0 if any factor is 0).\n\nIn particular,\n\n:<math>f_k\\in L^{p_k}(\\mu)\\;\\;\\forall k\\in\\{1,\\ldots,n\\}\\implies\\prod_{k=1}^n f_k \\in L^r(\\mu).</math>\n\n'''Note:''' For {{math|''r'' ∈ (0, 1)}}, contrary to the notation, {{math|{{norm|.}}<sub>''r''</sub>}} is in general not a norm, because it doesn't satisfy the [[triangle inequality]].\n\n<div style=\"clear:both;width:95%;\" class=\"NavFrame\">\n<div class=\"NavHead\" style=\"background-color:#FFFAF0; text-align:left; font-size:larger;\">Proof of the generalization</div>\n<div class=\"NavContent\" style=\"text-align:left;display:none;\">\n\nWe use Hölder's inequality and [[mathematical induction]]. For {{math|''n'' {{=}} 1}}, the result is obvious. Let us now pass from {{math|''n'' − 1}} to {{mvar|n}}. Without loss of generality assume that {{math|''p''<sub>1</sub> ≤ … ≤ ''p<sub>n</sub>''}}.\n\n'''Case 1:''' If {{math|''p<sub>n</sub>'' {{=}} ∞}}, then\n\n:<math>\\sum_{k=1}^{n-1}\\frac1{p_k}=\\frac1r.</math>\n\nPulling out the essential supremum of {{math|{{abs|''f<sub>n</sub>''}}}} and using the induction hypothesis, we get\n:<math>\\begin{align}\n\\left \\|f_1\\cdots f_n \\right \\|_r &\\le \\|f_1\\cdots f_{n-1}\\|_r \\|f_n\\|_\\infty\\\\ \n&\\le\\|f_1\\|_{p_1}\\cdots\\|f_{n-1}\\|_{p_{n-1}}\\|f_n\\|_\\infty.\n\\end{align}</math>\n\n'''Case 2:''' If {{math|''p<sub>n</sub>'' < ∞}}, then necessarily {{math|''r'' < ∞}} as well, and then\n\n:<math>p:=\\frac{p_n}{p_n-r}, \\qquad q:=\\frac{p_n}r</math>\n\nare Hölder conjugates in {{open-open|1,&thinsp;∞}}. Application of Hölder's inequality gives\n\n:<math>\\left \\||f_1\\cdots f_{n-1}|^r\\,|f_n|^r\\right \\|_1 \\le\\left \\||f_1\\cdots f_{n-1}|^r\\right \\|_p\\,\\left \\||f_n|^r\\right \\|_q.</math>\n\nRaising to the power {{math|1/''r''}} and rewriting,\n\n:<math>\\|f_1\\cdots f_n\\|_r \\le \\|f_1\\cdots f_{n-1}\\|_{pr}\\|f_n\\|_{qr}.</math>\n\nSince {{math|''qr'' {{=}} ''p<sub>n</sub>''}} and\n\n:<math>\\sum_{k=1}^{n-1}\\frac1{p_k} = \\frac1r-\\frac1{p_n} = \\frac{p_n-r}{rp_n} = \\frac1{pr},</math>\n\nthe claimed inequality now follows by using the induction hypothesis.\n\n</div>\n</div>\n\n===Interpolation===\nLet {{math|''p''<sub>1</sub>, ..., ''p<sub>n</sub>'' ∈}}  {{open-closed|0,&thinsp;∞}} and let {{math|''θ''<sub>1</sub>, ..., ''θ<sub>n</sub>'' ∈ (0, 1)}} denote weights with {{math|''θ''<sub>1</sub> + ... + ''θ<sub>n</sub>'' {{=}} 1}}. Define {{mvar|p}} as the weighted [[harmonic mean]], i.e.,\n\n:<math> \\frac1p = \\sum_{k=1}^n \\frac{\\theta_k}{p_k}.</math>\n\nGiven measurable real- or complex-valued functions <math>f_k</math> on {{mvar|S}}, then the above generalization of Hölder's inequality gives\n:<math>\\left\\| |f_1|^{\\theta_1}\\cdots |f_n|^{\\theta_n}\\right\\|_p \\le \\left\\||f_1|^{\\theta_1}\\right\\|_{\\frac{p_1}{\\theta_1}}\\cdots \\left\\| |f_n|^{\\theta_n}\\right\\|_{\\frac{p_n}{\\theta_n}} = \\|f_1\\|_{p_1}^{\\theta_1}\\cdots \\|f_n\\|_{p_n}^{\\theta_n}.</math>\n\nIn particular, taking <math>f_1=\\cdots =f_n=:f</math> gives\n:<math>\\|f\\|_p\\leqslant \\prod_{k=1}^n \\|f\\|_{p_k}^{\\theta_k}.</math>\n\nSpecifying further {{math|''θ''<sub>1</sub> {{=}} ''θ''}} and {{math|''θ''<sub>2</sub> {{=}} 1-''θ''}}, in the case {{math|''n'' {{=}} 2}}, we obtain the [[Riesz-Thorin theorem|interpolation]] result (Littlewood's inequality)\n\n:<math>\\| f\\|_{p_\\theta}\\leqslant  \\|f\\|_{p_1}^\\theta\\cdot \\|f\\|_{p_0}^{1-\\theta},</math>\n\nfor <math>\\theta\\in(0,1)</math> and\n\n:<math>\\frac {1}{p_\\theta}= \\frac{\\theta}{p_1}+ \\frac {1-\\theta}{p_0}.</math>\n\nAn application of Hölder gives Lyapunov's inequality: If\n\n:<math>p=(1-\\theta) p_0+\\theta p_1, \\qquad \\theta\\in(0,1),</math>\n\nthen\n\n:<math>\\left\\| |f_0|^{\\frac{p_0(1-\\theta)}{p}}\\cdot |f_1|^{\\frac{p_1 \\theta}{p}}\\right\\|_p^p\\le \\|f_0\\|_{p_0}^{p_0(1-\\theta)} \\|f_1\\|_{p_1}^{p_1\\theta}</math>\n\nand in particular\n\n:<math>\\|f\\|_p^p\\leqslant \\|f\\|_{p_0}^{p_0(1-\\theta)}\\cdot\\|f\\|_{p_1}^{p_1\\theta}.</math>\n\nBoth Littlewood and Lyapunov imply that if <math>f\\in L^{p_0}\\cap L^{p_1},</math> then <math>f\\in L^p</math> for all <math>p_0<p<p_1.</math>\n\n<!--P. Wojtaszczyk, Banach Spaces for Analysts, Cambridge University Presse 1991, [https://books.google.com/books?id=Re4pqY72Bo8C&printsec=frontcover&dq=banach+spaces+for+analysts+wojtaszczyk&ei=HP2pSrX9H6CGygS7qfmGCg&hl=de#v=onepage&q=&f=false]</ref>-->\n\n== Reverse Hölder inequality ==\nAssume that {{math|''p'' ∈ (1, ∞)}} and that the measure space {{math|(''S'', Σ, ''μ'')}} satisfies {{math|''μ''(''S'') > 0}}. Then, for all measurable real- or complex-valued functions {{mvar|f}}&thinsp; and {{mvar|g}} on {{mvar|S}} such that {{math|''g''(''s'') ≠ 0}} for {{nowrap|{{mvar|μ}}-almost}} all {{math|''s'' ∈ ''S''}},\n\n:<math>\\|fg\\|_1\\geqslant \\|f\\|_{\\frac{1}{p}}\\,\\|g\\|_{\\frac{-1}{p-1}}.</math>\n\nIf\n\n:<math>\\|fg\\|_1 < \\infty \\quad \\text{and} \\quad \\|g\\|_{\\frac{-1}{p-1}} > 0, </math>\n\nthen the reverse Hölder inequality is an equality if and only if\n\n:<math>\\exists \\alpha \\geqslant 0 \\quad |f| = \\alpha|g|^{\\frac{-p}{p-1}} \\qquad \\mu\\text{-almost everywhere}.</math>\n\n'''Note:''' The expressions:\n\n:<math> \\|f\\|_{\\frac{1}{p}} \\quad \\text{and} \\quad \\|g\\|_{\\frac{-1}{p-1}},</math>\n\nare not norms, they are just compact notations for\n\n:<math>\\left (\\int_S|f|^{\\frac{1}{p}}\\,\\mathrm{d}\\mu\\right)^{p} \\quad \\text{and} \\quad \\left (\\int_S|g|^{\\frac{-1}{p-1}}\\,\\mathrm{d}\\mu\\right)^{-(p-1)}.</math>\n\n<div style=\"clear:both;width:95%;\" class=\"NavFrame\">\n<div class=\"NavHead\" style=\"background-color:#FFFAF0; text-align:left; font-size:larger;\">Proof of the reverse Hölder inequality</div>\n<div class=\"NavContent\" style=\"text-align:left;display:none;\">\n\nNote that {{mvar|p}} and\n\n:<math>q:=\\frac{p}{p-1}\\in(1,\\infty)</math>\n\nare Hölder conjugates. Application of Hölder's inequality gives\n\n:<math>\\begin{align}\n\\left \\||f|^{\\frac{1}{p}}\\right \\|_1 &= \\left \\||fg|^{\\frac{1}{p}}\\,|g|^{-\\frac{1}{p}}\\right \\|_1\\\\\n&\\leqslant \\left \\| |fg|^{\\frac{1}{p}} \\right \\|_p \\left \\| |g|^{-\\frac{1}{p}}\\right \\|_q \\\\\n&=\\|fg\\|_1^{\\frac{1}{p}}\\left \\||g|^{\\frac{-1}{p-1}}\\right \\|_1^{\\frac{p-1}{p}}\n\\end{align}</math>\n\nRaising to the power {{mvar|p}} gives us:\n\n:<math>\\left \\||f|^{\\frac{1}{p}}\\right \\|_1^p \\leqslant \\|fg\\|_1  \\left \\||g|^{\\frac{-1}{p-1}}\\right \\|_1^{p-1}.</math>\n\nTherefore:\n\n:<math>\\left \\||f|^{\\frac{1}{p}}\\right \\|_1^p   \\left \\||g|^{\\frac{-1}{p-1}}\\right \\|_1^{-(p-1)} \\leqslant \\|fg\\|_1 .</math>\n\nNow we just need to recall our notation.\n\nSince {{mvar|g}} is not almost everywhere equal to the zero function, we can have equality if and only if there exists a constant {{math|''α'' ≥ 0}} such that {{math|{{abs|''fg''}} {{=}} ''α''&thinsp;{{abs|''g''}}<sup>−''q''/''p''</sup>}} almost everywhere. Solving for the absolute value of {{mvar|f}}&thinsp; gives the claim.\n\n</div>\n</div>\n\n== Conditional Hölder inequality ==\nLet {{math|(Ω,&thinsp;{{mathcal|F}},&thinsp;ℙ)}} be a probability space, {{math|{{mathcal|G}} ⊂ {{mathcal|F}}}} a {{nowrap|sub-[[σ-algebra]]}}, and {{math|''p'', ''q'' ∈}} {{open-open|1,&thinsp;∞}} Hölder conjugates, meaning that {{math|1/''p'' + 1/''q'' {{=}} 1}}. Then, for all real- or complex-valued random variables {{mvar|X}} and {{mvar|Y}} on&nbsp;{{math|Ω}},\n\n:<math>\\mathbb{E}\\bigl[|XY|\\big|\\,\\mathcal{G}\\bigr] \\le \\bigl(\\mathbb{E}\\bigl[|X|^p\\big|\\,\\mathcal{G}\\bigr]\\bigr)^{\\frac{1}{p}} \\,\\bigl(\\mathbb{E}\\bigl[|Y|^q\\big|\\,\\mathcal{G}\\bigr]\\bigr)^{\\frac{1}{q}}\n\n\\qquad\\mathbb{P}\\text{-almost surely.}</math>\n\n'''Remarks:'''\n* If a non-negative random variable {{mvar|Z}} has infinite [[expected value]], then its [[conditional expectation]] is defined by\n::<math>\\mathbb{E}[Z|\\mathcal{G}] = \\sup_{n\\in\\mathbb{N}}\\,\\mathbb{E}[\\min\\{Z,n\\}|\\mathcal{G}]\\quad\\text{a.s.}</math>\n\n* On the right-hand side of the conditional Hölder inequality, 0 times ∞ as well as ∞ times 0 means&nbsp;0. Multiplying {{math|''a'' > 0}} with ∞ gives&nbsp;∞.\n\n<div style=\"clear:both;width:95%;\" class=\"NavFrame\">\n<div class=\"NavHead\" style=\"background-color:#FFFAF0; text-align:left; font-size:larger;\">Proof of the conditional Hölder inequality</div>\n<div class=\"NavContent\" style=\"text-align:left;display:none;\">\n\nDefine the random variables\n\n:<math>U=\\bigl(\\mathbb{E}\\bigl[|X|^p\\big|\\,\\mathcal{G}\\bigr]\\bigr)^{\\frac{1}{p}},\\qquad V=\\bigl(\\mathbb{E}\\bigl[|Y|^q\\big|\\,\\mathcal{G}\\bigr]\\bigr)^{\\frac{1}{q}}</math>\n\nand note that they are measurable with respect to the {{nowrap|sub-σ-algebra}}. Since\n\n:<math>\\mathbb{E}\\bigl[|X|^p1_{\\{U=0\\}}\\bigr] = \\mathbb{E}\\bigl[1_{\\{U=0\\}}\\underbrace{\\mathbb{E}\\bigl[|X|^p\\big|\\,\\mathcal{G}\\bigr]}_{=\\,U^p}\\bigr]=0,</math>\n\nit follows that {{math|{{abs|''X''&thinsp;}} {{=}} 0}} a.s. on the set {{math|{{mset|''U'' {{=}} 0}}}}. Similarly, {{math|{{abs|''Y''&thinsp;}} {{=}} 0}} a.s. on the set {{math|{{mset|''V'' {{=}} 0}}}}, hence\n\n:<math>\\mathbb{E}\\bigl[|XY|\\big|\\,\\mathcal{G}\\bigr]=0\\qquad\\text{a.s. on }\\{U=0\\}\\cup\\{V=0\\}</math>\n\nand the conditional Hölder inequality holds on this set. On the set\n\n:<math>\\{U=\\infty, V>0\\}\\cup\\{U>0, V=\\infty\\}</math>\n\nthe right-hand side is infinite and the conditional Hölder inequality holds, too. Dividing by the right-hand side, it therefore remains to show that\n\n:<math>\\frac{\\mathbb{E}\\bigl[|XY|\\big|\\,\\mathcal{G}\\bigr]}{UV}\\le1\n\\qquad\\text{a.s. on the set }H:=\\{0<U<\\infty,\\,0<V<\\infty\\}.</math>\n\nThis is done by verifying that the inequality holds after integration over an arbitrary\n\n:<math>G\\in\\mathcal{G},\\quad G\\subset H.</math>\n\nUsing the measurability of {{mvar|U, V, 1<sub>''G''</sub>}} with respect to the {{nowrap|sub-σ-algebra}}, the rules for conditional expectations, Hölder's inequality and {{math|1/''p'' + 1/''q'' {{=}} 1}}, we see that\n\n:<math>\\begin{align}\n\\mathbb{E}\\biggl[\\frac{\\mathbb{E}\\bigl[|XY|\\big|\\,\\mathcal{G}\\bigr]}{UV}1_G\\biggr]\n&=\\mathbb{E}\\biggl[\\mathbb{E}\\biggl[\\frac{|XY|}{UV}1_G\\bigg|\\,\\mathcal{G}\\biggr]\\biggr]\\\\\n&=\\mathbb{E}\\biggl[\\frac{|X|}{U}1_G\\cdot\\frac{|Y|}{V}1_G\\biggr]\\\\\n&\\le\\biggl(\\mathbb{E}\\biggl[\\frac{|X|^p}{U^p}1_G\\biggr]\\biggr)^{\\frac{1}{p}}\n\\biggl(\\mathbb{E}\\biggl[\\frac{|Y|^q}{V^q}1_G\\biggr]\\biggr)^{\\frac{1}{q}}\\\\\n&=\\biggl(\\mathbb{E}\\biggl[\\underbrace{\\frac{\\mathbb{E}\\bigl[|X|^p\\big|\\,\\mathcal{G}\\bigr]}{U^p}}_{=\\,1\\text{ a.s. on }G}1_G\\biggr]\\biggr)^{\\frac{1}{p}}\n\\biggl(\\mathbb{E}\\biggl[\\underbrace{\\frac{\\mathbb{E}\\bigl[|Y|^q\\big|\\,\\mathcal{G}\\bigr]}{V^p}}_{=\\,1\\text{ a.s. on }G}1_G\\biggr]\\biggr)^{\\frac{1}{q}}\\\\\n&=\\mathbb{E}\\bigl[1_G\\bigr].\n\\end{align}</math>\n</div>\n</div>\n\n{{more footnotes|date=April 2012}}\n\n==Hölder's inequality for increasing seminorms==\nLet {{mvar|S}} be a set and let <math>F(S, \\mathbb{C})</math> be the space of all complex-valued functions on {{mvar|S}}. Let {{mvar|N}} be an increasing [[seminorm]] on <math>F(S, \\mathbb{C}),</math> meaning that, for all real-valued functions <math>f, g \\in F(S, \\mathbb{C})</math> we have the following implication (the seminorm is also allowed to attain the value ∞):\n\n:<math> \\forall s \\in S \\quad  f(s) \\geqslant g(s) \\geqslant 0  \\qquad \\Rightarrow \\qquad  N(f) \\geqslant N(g).</math>\n\nThen:\n\n:<math>\\forall f, g \\in F(S, \\mathbb{C}) \\qquad N(|fg|) \\leqslant \\bigl(N(|f|^p)\\bigr)^{\\frac{1}{p}} \\bigl(N(|g|^q)\\bigr)^{\\frac{1}{q}},</math>\n\nwhere the numbers <math>p</math> and <math>q</math> are Hölder conjugates.<ref>For a proof see {{harv|Trèves|1967|loc=Lemma&nbsp;20.1, pp.&nbsp;205–206}}.</ref>\n\n'''Remark:''' If {{math|(''S'', Σ, ''μ'')}} is a [[measure space]] and <math>N(f)</math> is the upper Lebesgue integral of <math>|f|</math> then the restriction of {{mvar|N}} to all {{nowrap|{{math|Σ}}-measurable}} functions gives the usual version of Hölder's inequality.\n\n== See also ==\n* [[Cauchy–Schwarz inequality]]\n* [[Minkowski inequality]]\n* [[Jensen's inequality]]\n* [[Young's inequality for products]]\n* [[Clarkson's inequalities]]\n* [[Brascamp–Lieb inequality]]\n\n==Citations==\n{{reflist}}\n\n==References==\n*{{Citation | last1=Grinshpan | first1=A. Z. | title=Weighted inequalities and negative binomials | doi=10.1016/j.aam.2010.04.004 | year=2010 | \njournal=Advances in Applied Mathematics | volume=45 | issue=4 | pages=564–606 }}\n*{{citation\n|first=G. H. \n|last=Hardy\n|author-link = Godfrey Harold Hardy\n|first2= J. E. \n|last2=Littlewood\n|author2-link=John Edensor Littlewood\n|first3= G.\n|last3= Pólya\n|author3-link= George Pólya\n|title=Inequalities\n|publisher= [[Cambridge University Press]] \n|pages=XII+314\n|year=1934\n|isbn=0-521-35880-9\n|jfm=60.0169.01 \n|mr=\n|zbl=0010.10703\n}}.\n*{{citation\n|first=O.\n|last= Hölder\n|author-link = Otto Hölder\n|title= Ueber einen Mittelwertsatz \n|journal= Nachrichten von der Königl. Gesellschaft der Wissenschaften und der Georg-Augusts-Universität zu Göttingen\n|series=Band\n|url = http://resolver.sub.uni-goettingen.de/purl?GDZPPN00252421X\n|volume = 1889\n|issue =2\n|year = 1889\n|language = German\n|pages = 38–47\n|jfm = 21.0260.07\n}}. Available at [https://web.archive.org/web/20090908025223/http://www.digizeitschriften.de/index.php?id=64&L=2 Digi Zeitschriften].\n*{{springer\n | id = H/h047514\n | first = L. P. \n | last = Kuptsov\n | title = Hölder inequality\n}}.\n*{{Citation\n  | last = Rogers\n  | first = L. J.\n  | author-link = Leonard James Rogers\n  | title = An extension of a certain theorem in inequalities\n  | journal = [[Messenger of Mathematics]]\n  | series = New Series\n  | volume = XVII\n  | issue = 10\n  | pages = 145–150\n  |date=February 1888\n  | url = https://archive.org/details/messengermathem01unkngoog\n  | archiveurl = https://archive.org/stream/messengermathem01unkngoog#page/n183/mode/1up\n  | archivedate = August 21, 2007\n  | jfm = 20.0254.02\n}}.\n*{{Citation\n  | last = Trèves\n  | first = François\n  | title = Topological Vector Spaces, Distributions and Kernels\n  | publisher = Academic Press\n  | place = New York, London\n  | series = Pure and Applied Mathematics. A Series of Monographs and Textbooks\n  | volume = 25\n  | year = 1967\n  | mr = 0225131\n  | zbl = 0171.10402\n}}.\n\n==External links==\n*{{Citation\n | last=Kuttler\n | first=Kenneth\n | title=An Introduction to Linear Algebra\n | publisher=Online e-book in PDF format, Brigham Young University\n | url=http://www.math.byu.edu/~klkuttle/Linearalgebra.pdf\n | year=2007\n}}.\n*{{Citation\n|last=Lohwater\n|first=Arthur\n|title=Introduction to Inequalities\n|format=PDF\n|url=http://www.mediafire.com/?1mw1tkgozzu\n|year=1982\n}}.\n*{{Citation\n | last=Tisdell\n | first=Chris\n | title=Holder's Inequality\n | publisher=Online video on Dr Chris Tisdell's YouTube channel\n | url=https://www.youtube.com/watch?v=kxQiKaIuyOg\n | year=2012\n}}.\n\n{{DEFAULTSORT:Holder's inequality}}\n[[Category:Inequalities]]\n[[Category:Probabilistic inequalities]]\n[[Category:Theorems in functional analysis]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Inequality of arithmetic and geometric means",
      "url": "https://en.wikipedia.org/wiki/Inequality_of_arithmetic_and_geometric_means",
      "text": "In [[mathematics]], the '''inequality of arithmetic and geometric means''', or more briefly the '''AM–GM inequality''', states that the [[arithmetic mean]] of a list of non-negative [[real number]]s is greater than or equal to the [[geometric mean]] of the same list; and further, that the two means are equal [[if and only if]] every number in the list is the same.\n\nThe simplest non-trivial case — i.e., with more than one variable — for two non-negative numbers {{mvar|x}} and&nbsp;{{mvar|y}}, is the statement that \n:<math>\\frac{x+y}2 \\ge \\sqrt{xy}</math>\nwith equality if and only if {{math|''x'' {{=}} ''y''}}. \nThis case can be seen from the fact that the square of a real number is always non-negative (greater than or equal to zero) and from the elementary case {{math|(''a'' ± ''b'')<sup>2</sup> {{=}} ''a''<sup>2</sup> ± 2''ab'' + ''b''<sup>2</sup>}} of the [[binomial formula]]:\n:<math>\\begin{align}\n0 & \\le (x-y)^2 \\\\\n& = x^2-2xy+y^2 \\\\\n& = x^2+2xy+y^2 - 4xy \\\\\n& = (x+y)^2 - 4xy.\n\\end{align}</math>\n<span style=\"line-height:1.5\">Hence {{math|(''x'' + ''y'')<sup>2</sup> ≥ 4''xy''}}, with equality precisely when {{math|(''x'' − ''y'')<sup>2</sup> {{=}} 0}}, i.e. {{math|''x'' {{=}} ''y''}}. The AM-GM inequality then follows from taking the positive square root of both sides.\n\nFor a geometrical interpretation, consider a [[rectangle]] with sides of length&nbsp;{{mvar|x}} and&nbsp;{{mvar|y}}, hence it has [[perimeter]] {{math|2''x'' +  2''y''}} and [[area]]&nbsp;{{mvar|xy}}. Similarly, a [[square]] with all sides of length {{math|{{radical|''xy''}}}} has the perimeter {{math|4{{radical|''xy''}}}} and the same area as the rectangle. The simplest non-trivial case of the AM–GM inequality implies for the perimeters that {{math|2''x'' +  2''y'' ≥ 4{{radical|''xy''}}}} and that only the square has the smallest perimeter amongst all rectangles of equal area.</span>\n\nExtensions of the AM–GM inequality are available to include [[#Weighted_AM.E2.80.93GM_inequality|weights]] or [[generalized mean]]s.\n\n== Background ==\n\nThe ''arithmetic mean'', or less precisely the ''average'', of a list of {{mvar|n}} numbers {{math|''x''<sub>1</sub>, ''x''<sub>2</sub>, . . . , ''x<sub>n</sub>''}} is the sum of the numbers divided by&nbsp;{{mvar|n}}:\n\n:<math>\\frac{x_1 + x_2 + \\cdots + x_n}{n}.</math>\n\nThe ''geometric mean'' is similar, except that it is only defined for a list of ''nonnegative'' real numbers, and uses multiplication and a [[Nth root|root]] in place of addition and division:\n\n:<math>\\sqrt[n]{x_1 \\cdot x_2 \\cdots x_n}.</math>\n\nIf {{math|''x''<sub>1</sub>, ''x''<sub>2</sub>, . . . , ''x<sub>n</sub>'' > 0}}, this is equal to the [[exponential function|exponential]] of the arithmetic mean of the [[natural logarithm]]s of the numbers:\n\n:<math>\\exp \\left( \\frac{\\ln {x_1} + \\ln {x_2} + \\cdots + \\ln {x_n}}{n} \\right).</math>\n\n== The inequality ==\n\nRestating the inequality using mathematical notation, we have that for any list of {{mvar|n}} nonnegative real numbers {{math|''x''<sub>1</sub>, ''x''<sub>2</sub>, . . . , ''x<sub>n</sub>''}},\n\n:<math>\\frac{x_1 + x_2 + \\cdots + x_n}{n} \\ge \\sqrt[n]{x_1 \\cdot x_2 \\cdots x_n}\\,,</math>\n\nand that equality holds if and only if {{math|''x''<sub>1</sub> {{=}} ''x''<sub>2</sub> {{=}} · · · {{=}} ''x<sub>n</sub>''}}.\n\n== Geometric interpretation ==\n\nIn two dimensions, {{math|2''x''<sub>1</sub> +  2''x''<sub>2</sub>}} is the [[perimeter]] of a rectangle with sides of length&nbsp;{{math|''x''<sub>1</sub>}} and&nbsp;{{math|''x''<sub>2</sub>}}. Similarly, {{math|4{{radical|''x''<sub>1</sub>''x''<sub>2</sub>}}}} is the perimeter of a square with the same [[area]], {{math|''x''<sub>1</sub>''x''<sub>2</sub>}}, as that rectangle. Thus for {{math|''n'' {{=}} 2}} the AM–GM inequality states that a rectangle of a given area has the smallest perimeter if that rectangle is also a square.\n\nThe full inequality is an extension of this idea to {{mvar|n}} dimensions. Every vertex of an {{mvar|n}}-dimensional box is connected to {{mvar|n}} edges. If these edges' lengths are {{math|''x''<sub>1</sub>, ''x''<sub>2</sub>, . . . , ''x<sub>n</sub>''}}, then {{math|''x''<sub>1</sub> + ''x''<sub>2</sub> +  · · · + ''x<sub>n</sub>''}} is the total length of edges incident to the vertex. There are {{math|2<sup>''n''</sup>}} vertices, so we multiply this by&nbsp;{{math|2<sup>''n''</sup>}}; since each edge, however, meets two vertices, every edge is counted twice. Therefore, we divide by&nbsp;{{math|2}} and conclude that there are {{math|2<sup>''n''−1</sup>''n''}} edges. There are equally many edges of each length and {{mvar|n}} lengths; hence there are {{math|2<sup>''n''−1</sup>}} edges of each length and the total of all edge lengths is {{math|2<sup>''n''−1</sup>(''x''<sub>1</sub> + ''x''<sub>2</sub> + · · · + ''x<sub>n</sub>'')}}. On the other hand,\n\n:<math>2^{n-1}(x_1+\\ldots+x_n)= 2^{n-1} n \\sqrt[n]{x_1 x_2 \\cdots x_n}</math>\n\nis the total length of edges connected to a vertex on an {{mvar|n}}-dimensional cube of equal volume, since in this case {{math|''x''<sub>1</sub>{{=}}...{{=}}''x''<sub>''n''</sub>}}. Since the inequality says\n\n:<math>{x_1 + x_2 +\\cdots + x_n \\over n} \\ge \\sqrt[n]{x_1 x_2\\cdots x_n}, </math>\n\nit can be restated by multiplying through by {{math|''n''2<sup>''n''–1</sup>}} to obtain\n\n:<math>2^{n-1}(x_1 + x_2 + \\cdots + x_n) \\ge 2^{n-1} n \\sqrt[n]{x_1 x_2\\cdots x_n}</math>\n\nwith equality if and only if \n{{math|''x''<sub>1</sub> {{=}} ''x''<sub>2</sub> {{=}} · · · {{=}} ''x<sub>n</sub>''}}.\n\nThus the AM–GM inequality states that only the [[Hypercube|{{mvar|n}}-cube]] has the smallest sum of lengths of edges connected to each vertex amongst all {{mvar|n}}-dimensional boxes with the same volume.<ref>{{cite book\n| last = Steele\n| first = J. Michael\n| title = The Cauchy-Schwarz Master Class: An Introduction to the Art of Mathematical Inequalities\n| publisher = Cambridge University Press\n| series = MAA Problem Books Series\n| year = 2004\n| isbn = 978-0-521-54677-5\n| oclc = 54079548\n}}</ref>\n\n==Example application==\n\nConsider the function\n\n:<math>f(x,y,z) = \\frac{x}{y} + \\sqrt{\\frac{y}{z}} + \\sqrt[3]{\\frac{z}{x}}</math>\n\nfor all positive real numbers {{mvar|x}}, {{mvar|y}} and&nbsp;{{mvar|z}}. Suppose we wish to find the minimal value of this function. First we rewrite it a bit:\n:<math>\n\\begin{align}\nf(x,y,z)\n&= 6 \\cdot \\frac{ \\frac{x}{y} + \\frac{1}{2} \\sqrt{\\frac{y}{z}} + \\frac{1}{2} \\sqrt{\\frac{y}{z}} + \\frac{1}{3} \\sqrt[3]{\\frac{z}{x}} + \\frac{1}{3} \\sqrt[3]{\\frac{z}{x}} + \\frac{1}{3} \\sqrt[3]{\\frac{z}{x}} }{6}\\\\\n&=6\\cdot\\frac{x_1+x_2+x_3+x_4+x_5+x_6}{6}\n\\end{align}</math>\nwith\n:<math> x_1=\\frac{x}{y},\\qquad x_2=x_3=\\frac{1}{2} \\sqrt{\\frac{y}{z}},\\qquad x_4=x_5=x_6=\\frac{1}{3} \\sqrt[3]{\\frac{z}{x}}.</math>\n\nApplying the AM–GM inequality for {{math|''n'' {{=}} 6}}, we get\n\n:<math>\n\\begin{align}\nf(x,y,z)\n&\\ge 6 \\cdot \\sqrt[6]{ \\frac{x}{y} \\cdot \\frac{1}{2} \\sqrt{\\frac{y}{z}} \\cdot \\frac{1}{2} \\sqrt{\\frac{y}{z}} \\cdot \\frac{1}{3} \\sqrt[3]{\\frac{z}{x}} \\cdot \\frac{1}{3} \\sqrt[3]{\\frac{z}{x}} \\cdot \\frac{1}{3} \\sqrt[3]{\\frac{z}{x}} }\\\\\n&= 6 \\cdot \\sqrt[6]{ \\frac{1}{2 \\cdot 2 \\cdot 3 \\cdot 3 \\cdot 3} \\frac{x}{y} \\frac{y}{z} \\frac{z}{x} }\\\\\n&= 2^{2/3} \\cdot 3^{1/2}.\n\\end{align}</math>\n\nFurther, we know that the two sides are equal exactly when all the terms of the mean are equal:\n\n:<math>f(x,y,z) = 2^{2/3} \\cdot 3^{1/2} \\quad \\mbox{when} \\quad \\frac{x}{y} = \\frac{1}{2} \\sqrt{\\frac{y}{z}} = \\frac{1}{3} \\sqrt[3]{\\frac{z}{x}}.</math>\n\nAll the points {{math|(''x'', ''y'', ''z'')}} satisfying these conditions lie on a half-line starting at the origin and are given by\n\n:<math>(x,y,z)=\\biggr(t,\\sqrt[3]{2}\\sqrt{3}\\,t,\\frac{3\\sqrt{3}}{2}\\,t\\biggr)\\quad\\mbox{with}\\quad t>0.</math>\n\n==Practical applications==\nAn important practical application in [[financial mathematics]] is to computing the [[rate of return]]: the [[annualized return]], computed via the geometric mean, is less than the average annual return, computed by the arithmetic mean (or equal if all returns are equal). This is important in analyzing investments, as the average return overstates the cumulative effect.\n\n==Proofs of the AM–GM inequality==\n===Proof using Jensen's inequality===\n\n[[Jensen's inequality]] states that the value of a [[concave function]] of an arithmetic mean is greater than or equal to the arithmetic mean of the function's values. Since the [[logarithm]] function is concave, we have\n\n:<math>\\log  \\left(\\frac { \\sum_i x_i}{n} \\right) \\ge \\sum  \\frac{1}{n} \\log x_i  = \\sum \\left( \\log x_i^{1/n}\\right) = \\log \\left( \\prod x_i^{1/n}\\right). </math>\n\nTaking [[antilog]]s of the far left and far right sides, we have the AM-GM inequality.\n\n===Proofs by induction===\n\nWe have to show that\n\n:<math>\\frac{x_1+x_2+\\cdots+x_n}{n} \\ge \\sqrt[n]{x_1x_2 \\cdots x_n}</math>\n\nwith equality only when all numbers are equal. If {{math|''x<sub>i</sub>'' ≠ ''x<sub>j</sub>''}}, then replacing both {{mvar|x<sub>i</sub>}} and {{mvar|x<sub>j</sub>}} by\n{{math|(''x<sub>i</sub>'' + ''x<sub>j</sub>'')/2}} will leave the arithmetic mean on the left-hand side unchanged, but will increase the geometric mean on the right-hand side because\n\n:<math>\\Bigl(\\frac{x_i+x_j}{2}\\Bigr)^2-x_ix_j=\\Bigl(\\frac{x_i-x_j}{2}\\Bigr)^2>0 .</math>\n\nThus the right-hand side will be largest when all {{mvar|x<sub>i</sub>}}s are equal to the arithmetic mean\n\n:<math>\\alpha=\\frac{x_1+x_2+\\cdots+x_n}{n},</math>\n\nthus as this is then the largest value of right-hand side of the expression, we have\n\n:<math>\\frac{x_1+x_2+\\cdots+x_n}{n}=\\alpha=\\sqrt[n]{\\alpha\\alpha \\cdots \\alpha}\\ge\\sqrt[n]{x_1x_2 \\cdots x_n}.</math>\n\nThis is a valid proof for the case {{math|''n'' {{=}} 2}}, but the procedure of taking iteratively pairwise averages may fail to produce {{mvar|n}} equal numbers in the case {{math|''n'' ≥ 3}}. An example of this case is {{math|''x''<sub>1</sub> {{=}} ''x''<sub>2</sub> ≠ ''x''<sub>3</sub>}}: Averaging two different numbers produces two equal numbers, but the third one is still different. Therefore, we never actually get an inequality involving the geometric mean of three equal numbers.\n\nHence, an additional trick or a modified argument is necessary to turn the above idea into a valid proof for the case {{math|''n'' ≥ 3}}.\n\n====Proof by induction #1====\n\nWith the arithmetic mean\n:<math>\\alpha=\\frac{\\ x_1 + \\cdots + x_n}n</math>\nof the non-negative real numbers {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>''}}, the AM–GM statement is equivalent to\n:<math>\\alpha^n\\ge x_1  x_2 \\cdots x_n</math>\nwith equality if and only if {{math|''α'' {{=}} ''x<sub>i</sub>''}} for all {{math|''i'' ∈ {1, . . . , ''n''<nowiki>}</nowiki>}}.\n\nFor the following proof we apply [[mathematical induction]] and only well-known rules of arithmetic.\n\n'''Induction basis:'''  For {{math|''n'' {{=}} 1}} the statement is true with equality.\n\n'''Induction hypothesis:''' Suppose that the AM–GM statement holds for all choices of {{mvar|n}} non-negative real numbers.\n\n'''Induction step:''' Consider {{math|''n'' + 1}} non-negative real numbers {{math|''x''<sub>1</sub>, . . . , ''x''<sub>''n''+1</sub>}}, . Their arithmetic mean {{mvar|α}} satisfies\n:<math> (n+1)\\alpha=\\ x_1 + \\cdots + x_n + x_{n+1}.</math>\nIf all the {{mvar|x<sub>i</sub>}} are equal to {{mvar|α}}, then we have equality in the AM–GM statement and we are done. In the case where some are not equal to {{mvar|α}}, there must exist one number that is greater than the arithmetic mean {{mvar|α}}, and one that is smaller than {{mvar|α}}. Without loss of generality, we can reorder our {{mvar|x<sub>i</sub>}} in order to place these two particular elements at the end: {{math|''x<sub>n</sub>'' > ''α''}} and  {{math|''x''<sub>''n''+1</sub> < ''α''}}. Then\n\n:<math>x_n - \\alpha > 0\\qquad \\alpha-x_{n+1}>0</math>\n\n:<math>\\implies (x_n-\\alpha)(\\alpha-x_{n+1})>0\\,.\\qquad(*)</math>\n\nNow define {{math|''y''}} with\n:<math>y:=x_n+x_{n+1}-\\alpha\\ge x_n-\\alpha>0\\,,</math>\nand consider the {{mvar|n}} numbers {{math|''x''<sub>1</sub>, . . . , ''x''<sub>''n''–1</sub>, y}} which are all non-negative. Since\n\n:<math>(n+1)\\alpha=x_1 + \\cdots + x_{n-1} + x_n + x_{n+1}</math>\n\n:<math>n\\alpha=x_1 + \\cdots + x_{n-1} + \\underbrace{x_n+x_{n+1}-\\alpha}_{=\\,y},</math>\n\nThus, {{mvar|α}} is also the arithmetic mean of {{mvar|n}} numbers {{math|''x''<sub>1</sub>, . . . , ''x''<sub>''n''–1</sub>, ''y''}} and the induction hypothesis implies\n\n:<math>\\alpha^{n+1}=\\alpha^n\\cdot\\alpha\\ge x_1x_2 \\cdots x_{n-1} y\\cdot\\alpha.\\qquad(**)</math>\n\nDue to (*) we know that\n\n:<math>(\\underbrace{x_n+x_{n+1}-\\alpha}_{=\\,y})\\alpha-x_nx_{n+1}=(x_n-\\alpha)(\\alpha-x_{n+1})>0,</math>\n\nhence\n\n:<math>y\\alpha>x_nx_{n+1}\\,,\\qquad({*}{*}{*})</math>\n\nin particular {{math|''α'' > 0}}. Therefore, if at least one of the numbers {{math|''x''<sub>1</sub>, . . . , ''x''<sub>''n''–1</sub>}} is zero, then we already have strict inequality in (**). Otherwise the right-hand side of (**) is positive and strict inequality is obtained by using the estimate (***) to get a lower bound of the right-hand side of (**). Thus, in both cases we can substitute (***) into (**) to get\n\n:<math>\\alpha^{n+1}>x_1x_2 \\cdots x_{n-1} x_nx_{n+1}\\,,</math>\n\nwhich completes the proof.\n\n==== Proof by induction #2 ====\n\nFirst of all we shall prove that for real numbers {{math|''x''<sub>1</sub> < 1}} and {{math|''x''<sub>2</sub> > 1}} there follows\n\n:<math> x_1 + x_2 > x_1x_2+1.</math>\n \nIndeed, multiplying both sides of the inequality {{math|''x''<sub>2</sub> > 1}} by {{math| 1 – ''x''<sub>1</sub>}}, gives\n\n:<math> x_2 - x_1x_2 > 1 - x_1,</math>\n\nwhence the required inequality is obtained immediately.\n\nNow, we are going to prove that for positive real numbers {{math|''x''<sub>1</sub>, . . . , ''x''<sub>''n''</sub>}} satisfying\n{{math|''x''<sub>1</sub> . . . ''x''<sub>''n''</sub> {{=}} 1}}, there holds\n\n:<math>x_1 + \\cdots +  x_n \\ge n.</math>\n\nThe equality holds only if {{math|''x''<sub>1</sub> {{=}} ... {{=}} ''x''<sub>''n''</sub> {{=}} 1}}.\n\n'''Induction basis:'''  For {{math|''n'' {{=}} 2}} the statement is true because of the above property.\n\n'''Induction hypothesis:''' Suppose that the statement is true for all natural numbers up to {{math|''n'' – 1}}.\n\n'''Induction step:''' Consider natural number {{math|''n''}}, i.e. for positive real numbers {{math|''x''<sub>1</sub>, . . . , ''x''<sub>''n''</sub>}}, there holds {{math|''x''<sub>1</sub> . . . ''x''<sub>''n''</sub> {{=}} 1}}. There exists at least one {{math|''x<sub>k</sub>'' < 1}}, so there must be at least one {{math|''x<sub>j</sub>'' > 1}}. Without loss of generality, we let {{math|''k'' {{=}}''n'' – 1}} and {{math|''j'' {{=}} ''n''}}.\n\nFurther, the equality {{math|''x''<sub>1</sub> . . . ''x''<sub>''n''</sub> {{=}} 1}} we shall write in the form of {{math|(''x''<sub>1</sub> . . . ''x''<sub>''n''–2</sub>) (''x''<sub>''n''–1</sub> ''x''<sub>''n''</sub>) {{=}} 1}}. Then, the induction hypothesis implies\n\n:<math>(x_1 + \\cdots + x_{n-2}) + (x_{n-1} x_n ) > n - 1.</math>\n\nHowever, taking into account the induction basis, we have\n\n:<math>\\begin{align}\nx_1 + \\cdots + x_{n-2} + x_{n-1} + x_n & = (x_1 + \\cdots + x_{n-2}) + (x_{n-1} + x_n ) \n\\\\ &> (x_1 + \\cdots + x_{n-2}) + x_{n-1} x_n + 1 \n\\\\ & > n,\n\\end{align}</math>\n\nwhich completes the proof.\n\nFor positive real numbers {{math|''a''<sub>1</sub>, . . . , ''a''<sub>''n''</sub>}}, let's denote\n\n:<math>x_1 = \\frac{a_1}{\\sqrt[n]{a_1\\cdots a_n}}, . . ., x_n = \\frac{a_n}{\\sqrt[n]{a_1\\cdots a_n}}. </math>\n\nThe numbers {{math|''x''<sub>1</sub>, . . . , ''x''<sub>''n''</sub>}} satisfy the condition {{math|''x''<sub>1</sub> . . . ''x''<sub>''n''</sub> {{=}} 1}}. So we have\n\n:<math>\\frac{a_1}{\\sqrt[n]{a_1\\cdots a_n}} + \\cdots + \\frac{a_n}{\\sqrt[n]{a_1\\cdots a_n}} \\ge n, </math>\n\nwhence we obtain\n\n:<math>\\frac{a_1 + \\cdots + a_n}n \\ge \\sqrt[n]{a_1\\cdots a_n}, </math>\n\nwith the equality holding only for  {{math|''a''<sub>1</sub> {{=}} ... {{=}} ''a''<sub>''n''</sub> {{=}} 1}}.\n\n===Proof by Cauchy using forward–backward induction===\n\nThe following proof by cases relies directly on well-known rules of arithmetic but employs the rarely used technique of forward-backward-induction. It is essentially from [[Augustin Louis Cauchy]] and can be found in his ''[[Augustin Louis Cauchy#Cours d.27Analyse|Cours d'analyse]]''.<ref>Cauchy, Augustin-Louis (1821). [http://visualiseur.bnf.fr/Visualiseur?Destination=Gallica&O=NUMM-29058 ''Cours d'analyse de l'École Royale Polytechnique, première partie, Analyse algébrique,''] Paris. The proof of the inequality of arithmetic and geometric means can be found on pages 457ff.</ref>\n\n==== The case where all the terms are equal ====\n\nIf all the terms are equal:\n\n:<math>x_1 = x_2 = \\cdots = x_n,</math>\n\nthen their sum is {{math|''nx''<sub>1</sub>}}, so their arithmetic mean is&nbsp;{{math|''x''<sub>1</sub>}}; and their product is {{math|''x''<sub>1</sub><sup>''n''</sup>}}, so their geometric mean is&nbsp;{{math|''x''<sub>1</sub>}}; therefore, the arithmetic mean and geometric mean are equal, as desired.\n\n==== The case where not all the terms are equal ====\n\nIt remains to show that if ''not'' all the terms are equal, then the arithmetic mean is greater than the geometric mean. Clearly, this is only possible when {{math|''n'' > 1}}.\n\nThis case is significantly more complex, and we divide it into subcases.\n\n===== The subcase where ''n'' <nowiki>=</nowiki> 2 =====\n\nIf {{math|''n'' {{=}} 2}}, then we have two terms, {{math|''x''<sub>1</sub>}} and {{math|''x''<sub>2</sub>}}, and since (by our assumption) not all terms are equal, we have:\n\n:<math>\\begin{align}\n\\Bigl(\\frac{x_1+x_2}{2}\\Bigr)^2-x_1x_2\n&=\\frac14(x_1^2+2x_1x_2+x_2^2)-x_1x_2\\\\\n&=\\frac14(x_1^2-2x_1x_2+x_2^2)\\\\\n&=\\Bigl(\\frac{x_1-x_2}{2}\\Bigr)^2>0,\n\\end{align} </math>\n\nhence\n\n:<math>\n\\frac{x_1 + x_2}{2} > \\sqrt{x_1 x_2}</math>\n\nas desired.\n\n===== The subcase where ''n'' <nowiki>=</nowiki> 2<sup>''k''</sup> =====\n\nConsider the case where {{math|''n'' {{=}} 2<sup>''k''</sup>}}, where {{mvar|k}} is a positive integer. We proceed by mathematical induction.\n\nIn the base case, {{math|''k'' {{=}} 1}}, so {{math|''n'' {{=}} 2}}. We have already shown that the inequality holds when {{math|''n'' {{=}} 2}}, so we are done.\n\nNow, suppose that for a given {{math|''k'' > 1}}, we have already shown that the inequality holds for {{math|''n'' {{=}} 2<sup>''k''−1</sup>}}, and we wish to show that it holds for {{math|''n'' {{=}} 2<sup>''k''</sup>}}. To do so, we apply the inequality twice for {{math|2<sup>''k''-1</sup>}} numbers and once for {{math|2}} numbers to obtain:\n\n:<math>\n\\begin{align}\n\\frac{x_1 + x_2 + \\cdots + x_{2^k}}{2^k} & {} =\\frac{\\frac{x_1 + x_2 + \\cdots + x_{2^{k-1}}}{2^{k-1}} + \\frac{x_{2^{k-1} + 1} + x_{2^{k-1} + 2} + \\cdots + x_{2^k}}{2^{k-1}}}{2} \\\\[7pt]\n& \\ge \\frac{\\sqrt[2^{k-1}]{x_1 x_2 \\cdots x_{2^{k-1}}} + \\sqrt[2^{k-1}]{x_{2^{k-1} + 1} x_{2^{k-1} + 2} \\cdots x_{2^k}}}{2} \\\\[7pt]\n& \\ge \\sqrt{\\sqrt[2^{k-1}]{x_1 x_2 \\cdots x_{2^{k-1}}} \\sqrt[2^{k-1}]{x_{2^{k-1} + 1} x_{2^{k-1} + 2} \\cdots x_{2^k}}} \\\\[7pt]\n& = \\sqrt[2^k]{x_1 x_2 \\cdots x_{2^k}}\n\\end{align}\n</math>\n\nwhere in the first inequality, the two sides are equal only if\n\n:<math>x_1 = x_2 = \\cdots = x_{2^{k-1}}</math>\n\nand\n\n:<math>x_{2^{k-1}+1} = x_{2^{k-1}+2} = \\cdots = x_{2^k}</math>\n\n(in which case the first arithmetic mean and first geometric mean are both equal to&nbsp;{{math|''x''<sub>1</sub>}}, and similarly with the second arithmetic mean and second geometric mean); and in the second inequality, the two sides are only equal if the two geometric means are equal. Since not all {{math|2<sup>''k''</sup>}} numbers are equal, it is not possible for both inequalities to be equalities, so we know that:\n\n:<math>\\frac{x_1 + x_2 + \\cdots + x_{2^k}}{2^k} > \\sqrt[2^k]{x_1 x_2 \\cdots x_{2^k}}</math>\n\nas desired.\n\n===== The subcase where ''n'' < 2<sup>''k''</sup> =====\n\nIf {{mvar|n}} is not a natural power of&nbsp;{{math|2}}, then it is certainly ''less'' than some natural power of 2, since the sequence {{math|2, 4, 8, . . . , 2<sup>''k''</sup>, . . .}} is unbounded above. Therefore, without loss of generality, let {{mvar|m}} be some natural power of {{math|2}} that is greater than&nbsp;{{mvar|n}}.\n\nSo, if we have {{mvar|n}} terms, then let us denote their arithmetic mean by&nbsp;{{mvar|α}}, and expand our list of terms thus:\n\n:<math>x_{n+1} = x_{n+2} = \\cdots = x_m = \\alpha.</math>\n\nWe then have:\n\n: <math>\n\\begin{align}\n\\alpha & = \\frac{x_1 + x_2 + \\cdots + x_n}{n} \\\\[6pt]\n& = \\frac{\\frac{m}{n} \\left( x_1 + x_2 + \\cdots + x_n \\right)}{m} \\\\[6pt]\n& = \\frac{x_1 + x_2 + \\cdots + x_n + \\frac{m-n}{n} \\left( x_1 + x_2 + \\cdots + x_n \\right)}{m} \\\\[6pt]\n& = \\frac{x_1 + x_2 + \\cdots + x_n + \\left( m-n \\right) \\alpha}{m} \\\\[6pt]\n& = \\frac{x_1 + x_2 + \\cdots + x_n + x_{n+1} + \\cdots + x_m}{m} \\\\[6pt]\n& > \\sqrt[m]{x_1 x_2 \\cdots x_n x_{n+1} \\cdots x_m} \\\\[6pt]\n& = \\sqrt[m]{x_1 x_2 \\cdots x_n \\alpha^{m-n}}\\,,\n\\end{align}\n</math>\n\nso\n\n:<math>\\alpha^m > x_1 x_2 \\cdots x_n \\alpha^{m-n}</math>\n\nand\n\n:<math>\\alpha > \\sqrt[n]{x_1 x_2 \\cdots x_n}</math>\n\nas desired.\n\n===Proof by induction using basic calculus===\n\nThe following proof uses mathematical induction and some basic [[differential calculus]].\n\n'''Induction basis''': For {{math|''n'' {{=}} 1}} the statement is true with equality.\n\n'''Induction hypothesis''': Suppose that the AM–GM statement holds for all choices of {{mvar|n}} non-negative real numbers.\n\n'''Induction step''': In order to prove the statement for {{math|''n'' + 1}} non-negative real numbers {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>'', ''x''<sub>''n''+1</sub>}}, we need to prove that\n\n:<math>\\frac{x_1 + \\cdots + x_n + x_{n+1}}{n+1} - ({x_1 \\cdots x_n x_{n+1}})^{\\frac{1}{n+1}}\\ge0</math>\n\nwith equality only if all the {{math|''n'' + 1}} numbers are equal.\n\nIf all numbers are zero, the inequality holds with equality. If some but not all numbers are zero, we have strict inequality. Therefore, we may assume in the following, that all {{math|''n'' + 1}} numbers are positive.\n\nWe consider the last number {{math|''x''<sub>''n''+1</sub>}} as a variable and define the function\n:<math> f(t)=\\frac{x_1 + \\cdots + x_n + t}{n+1} - ({x_1 \\cdots x_n t})^{\\frac{1}{n+1}},\\qquad t>0.</math>\n\nProving the induction step is equivalent to showing that {{math|''f''(''t'') ≥ 0}} for all {{math|''t'' > 0}}, with {{math|''f''(''t'') {{=}} 0}} only if {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>''}} and&nbsp;{{mvar|t}} are all equal. This can be done by analyzing the [[critical point (mathematics)|critical points]] of&nbsp;{{mvar|f}} using some basic calculus.\n\nThe first [[derivative]] of {{mvar|f}} is given by\n\n:<math>f'(t)=\\frac{1}{n+1}-\\frac{1}{n+1}({x_1 \\cdots x_n})^{\\frac{1}{n+1}}t^{-\\frac{n}{n+1}},\\qquad t>0.</math>\n\nA critical point {{math|''t''<sub>0</sub>}} has to satisfy {{math|''f′''(''t''<sub>0</sub>) {{=}} 0}}, which means\n\n:<math>({x_1 \\cdots x_n})^{\\frac{1}{n+1}}t_0^{-\\frac{n}{n+1}}=1.</math>\n\nAfter a small rearrangement we get\n:<math>t_0^{\\frac{n}{n+1}}=({x_1 \\cdots x_n})^{\\frac{1}{n+1}},</math>\n\nand finally\n\n:<math>t_0=({x_1 \\cdots x_n})^{\\frac{1}n},</math>\n\nwhich is the geometric mean of {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>''}}. This is the only critical point of&nbsp;{{mvar|f}}. Since {{math|''f′′''(''t'') > 0}} for all {{math|''t'' > 0}}, the function&nbsp;{{mvar|f}} is [[strictly convex function|strictly convex]] and has a strict [[global minimum]] at&nbsp;{{math|''t''<sub>0</sub>}}. Next we compute the value of the function at this global minimum:\n\n:<math>\n\\begin{align}\nf(t_0) &= \\frac{x_1 + \\cdots + x_n + ({x_1 \\cdots x_n})^{1/n}}{n+1} - ({x_1 \\cdots x_n})^{\\frac{1}{n+1}}({x_1 \\cdots x_n})^{\\frac{1}{n(n+1)}}\\\\\n&= \\frac{x_1 + \\cdots + x_n}{n+1} + \\frac{1}{n+1}({x_1 \\cdots x_n})^{\\frac{1}n} - ({x_1 \\cdots x_n})^{\\frac{1}n}\\\\\n&= \\frac{x_1 + \\cdots + x_n}{n+1} - \\frac{n}{n+1}({x_1 \\cdots x_n})^{\\frac{1}n}\\\\\n&= \\frac{n}{n+1}\\Bigl(\\frac{x_1 + \\cdots + x_n}n - ({x_1 \\cdots x_n})^{\\frac{1}n}\\Bigr)\n\\\\ &\\ge0,\n\\end{align}</math>\n\nwhere the final inequality holds due to the induction hypothesis. The hypothesis also says that we can have equality only when {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>''}} are all equal. In this case, their geometric mean &nbsp;{{math|''t''<sub>0</sub>}} has the same value, Hence, unless {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>'', ''x''<sub>''n''+1</sub>}} are all equal, we have {{math|''f''(''x''<sub>''n''+1</sub>) > 0}}. This completes the proof.\n\nThis technique can be used in the same manner to prove the generalized AM–GM inequality and [[Cauchy–Schwarz inequality]] in Euclidean space {{math|'''R'''<sup>''n''</sup>}}.\n\n===Proof by Pólya using the exponential function===\n\n[[George Pólya]] provided a proof similar to what follows. Let {{math|''f''(''x'') {{=}} e<sup>''x''–1</sup>  – ''x''}} for all real&nbsp;{{mvar|x}}, with first [[derivative (mathematics)|derivative]] {{math|''f′''(''x'') {{=}} e<sup>''x''–1</sup> – 1}} and second derivative {{math|''f′′''(''x'') {{=}} e<sup>''x''–1</sup>}}. Observe that {{math|''f''(1) {{=}} 0}}, {{math|''f′''(1) {{=}} 0}} and {{math|''f′′''(''x'') > 0}} for all real&nbsp;{{mvar|x}}, hence {{mvar|f}} is strictly convex with the absolute minimum at {{math|''x'' {{=}} 1}}. Hence {{math|''x'' ≤ e<sup>''x''–1</sup>}} for all real&nbsp;{{mvar|x}} with equality only for {{math|''x'' {{=}} 1}}.\n\nConsider a list of non-negative real numbers {{math|''x''<sub>1</sub>, ''x''<sub>2</sub>, . . . , ''x<sub>n</sub>''}}. If they are all zero, then the AM–GM inequality holds with equality. Hence we may assume in the following for their arithmetic mean {{math|''α'' > 0}}. By {{mvar|n}}-fold application of the above inequality, we obtain that\n\n:<math>\\begin{align}{ \\frac{x_1}{\\alpha} \\frac{x_2}{\\alpha} \\cdots \\frac{x_n}{\\alpha} } &\\le { e^{\\frac{x_1}{\\alpha} - 1} e^{\\frac{x_2}{\\alpha} - 1} \\cdots e^{\\frac{x_n}{\\alpha} - 1} }\\\\\n& = \\exp \\Bigl( \\frac{x_1}{\\alpha} - 1 + \\frac{x_2}{\\alpha} - 1 + \\cdots + \\frac{x_n}{\\alpha} - 1 \\Bigr), \\qquad (*)\n\\end{align}</math>\n\nwith equality if and only if {{math|''x<sub>i</sub>'' {{=}} ''α''}} for every {{math|''i'' ∈ <nowiki>{</nowiki>1, . . . , ''n''<nowiki>}</nowiki>}}. The argument of the exponential function can be simplified:\n\n:<math>\\begin{align}\n\\frac{x_1}{\\alpha} - 1 + \\frac{x_2}{\\alpha} - 1 + \\cdots + \\frac{x_n}{\\alpha} - 1 & = \\frac{x_1 + x_2 + \\cdots + x_n}{\\alpha} - n \\\\\n&  = \\frac{n \\alpha}{\\alpha} - n \\\\\n& = 0.\n\\end{align}</math>\n\nReturning to {{math|(*)}},\n\n:<math>\\frac{x_1 x_2 \\cdots x_n}{\\alpha^n} \\le e^0 = 1,</math>\n\nwhich produces {{math|''x''<sub>1</sub> ''x''<sub>2</sub> ·  ·  · ''x<sub>n</sub>'' ≤ ''α<sup>n</sup>''}}, hence the result<ref>{{cite book\n| last1 = Arnold\n| first1 = Denise\n| last2 = Arnold\n| first2 = Graham\n| title = Four unit mathematics\n| publisher = Hodder Arnold H&S\n| year = 1993\n| isbn = 978-0-340-54335-1\n| oclc = 38328013\n| page = 242\n}}</ref>\n:<math>\\sqrt[n]{x_1 x_2 \\cdots x_n} \\le \\alpha.</math>\n\n===Proof by Lagrangian Multipliers===\n\nIf any of the <math>x_i</math> are <math>0</math>, then there is nothing to prove. So we may assume all the <math>x_i</math> are strictly positive.\n\nBecause the arithmetic and geometric means are homogeneous of degree 1, without loss of generality assume that <math>\\prod_{i=1}^n x_i = 1</math>. Set <math>G(x_1,x_2,\\ldots,x_n)=\\prod_{i=1}^n x_i</math>, and <math>F(x_1,x_2,\\ldots,x_n) = \\frac{1}{n}\\sum_{i=1}^n x_i</math>. The inequality will be proved (together with the equality case) if we can show that the minimum of <math>F(x_1,x_2,...,x_n),</math> subject to the constraint <math>G(x_1,x_2,\\ldots,x_n) = 1,</math> is equal to <math>1</math>, and the minimum is only achieved when <math>x_1 = x_2 = \\cdots = x_n = 1</math>. Let us first show that the constraint problem has a global minimum.\n\nSet <math>K = \\{(x_1,x_2,\\ldots,x_n) \\colon x_1,x_2,\\ldots,x_n \\leq n\\}</math>. Since the intersection <math>K \\cap \\{G = 1\\}</math> is compact, the [[extreme value theorem]] guarantees that the minimum of <math>F(x_1,x_2,...,x_n)</math> subject to the constraints <math>G(x_1,x_2,\\ldots,x_n) = 1</math> and <math> (x_1,x_2,\\ldots,x_n) \\in K </math> is attained at some point inside <math>K</math>. On the other hand, observe that if any of the <math>x_i > n</math>, then <math>F(x_1,x_2,\\ldots,x_n) > 1 </math>, while <math>F(1,1,\\ldots,1) = 1</math>, and <math>(1,1,\\ldots,1) \\in K \\cap \\{G = 1\\} </math>. This means that the minimum inside <math>K \\cap \\{G = 1\\}</math> is in fact a global minimum, since the value of <math>F</math> at any point inside <math>K \\cap \\{G = 1\\}</math> is certainly no smaller than the minimum, and the value of <math>F</math> at any point <math>(y_1,y_2,\\ldots, y_n)</math> not inside <math>K</math> is strictly bigger than the value at <math>(1,1,\\ldots,1)</math>, which is no smaller than the minimum.\n\nThe method of [[Lagrange multipliers]] says that the global minimum is attained at a point <math>(x_1,x_2,\\ldots,x_n)</math> where the gradient of <math>F(x_1,x_2,\\ldots,x_n)</math> is <math>\\lambda</math> times the gradient of <math>G(x_1,x_2,\\ldots,x_n)</math>, for some <math>\\lambda</math>. We will show that the only point at which this happens is when <math>x_1 = x_2 = \\cdots = x_n = 1</math> and  <math>F(x_1,x_2,...,x_n) = 1.</math> \n\nCompute \n<math>\\frac{\\partial F}{\\partial x_i} = \\frac{1}{n}</math> \nand\n\n<math>\\frac{\\partial G}{\\partial x_i} = \\prod_{j \\neq i}x_j = \\frac{G(x_1,x_2,\\ldots,x_n)}{x_i} = \\frac{1}{x_i}</math> \n\nalong the constraint. Setting the gradients proportional to one another therefore gives for each <math>i</math> that <math>\\frac{1}{n} = \\frac{\\lambda}{x_i},</math> and so <math>n\\lambda= x_i.</math> Since the left-hand side does not depend on <math>i</math>, it follows that <math>x_1 = x_2 = \\cdots = x_n</math>, and since <math>G(x_1,x_2,\\ldots, x_n) = 1</math>, it follows that <math> x_1 = x_2 = \\cdots = x_n = 1</math> and <math>F(x_1,x_2,\\ldots,x_n) = 1</math>, as desired.\n\n==Generalizations==\n\n===Weighted AM–GM inequality===\n\nThere is a similar inequality for the [[weighted arithmetic mean]] and [[weighted geometric mean]]. Specifically, let the nonnegative numbers  {{math|''x''<sub>1</sub>, ''x''<sub>2</sub>, . . . , ''x<sub>n</sub>''}} and the nonnegative weights {{math|''w''<sub>1</sub>, ''w''<sub>2</sub>, . . . , ''w<sub>n</sub>''}} be given. Set {{math|''w'' {{=}} ''w''<sub>1</sub> + ''w''<sub>2</sub> +  · · · + ''w<sub>n</sub>''}}. If&nbsp;{{math|''w'' > 0}}, then the inequality\n\n: <math>\\frac{w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n}{w} \\ge \\sqrt[w]{x_1^{w_1} x_2^{w_2} \\cdots x_n^{w_n}}</math>\n\nholds with equality if and only if all the {{mvar|x<sub>k</sub>}} with {{math|''w<sub>k</sub>'' > 0}} are equal. Here the convention {{math|0<sup>0</sup> {{=}} 1}} is used.\n\nIf all {{math|''w<sub>k</sub>'' {{=}} 1}}, this reduces to the above inequality of arithmetic and geometric means.\n\n===Proof using Jensen's inequality===\n\nUsing the finite form of [[Jensen's inequality]] for the [[natural logarithm]], we can prove the inequality between the weighted arithmetic mean and the weighted geometric mean stated above.\n\nSince an {{mvar|x<sub>k</sub>}} with weight {{math|''w<sub>k</sub>'' {{=}} 0}} has no influence on the inequality, we may assume in the following that all weights are positive. If all {{mvar|x<sub>k</sub>}} are equal, then equality holds. Therefore, it remains to prove strict inequality if they are not all equal, which we will assume in the following, too. If at least one {{mvar|x<sub>k</sub>}} is zero (but not all), then the weighted geometric mean is zero, while the weighted arithmetic mean is positive, hence strict inequality holds. Therefore, we may assume also that all {{mvar|x<sub>k</sub>}} are positive.\n\nSince the natural logarithm is [[concave function|strictly concave]], the finite form of Jensen's inequality and the [[functional equation]]s of the natural logarithm imply\n:<math>\\begin{align}\n\\ln\\Bigl(\\frac{w_1x_1+\\cdots+w_nx_n}w\\Bigr) & >\\frac{w_1}w\\ln x_1+\\cdots+\\frac{w_n}w\\ln x_n \\\\\n& =\\ln \\sqrt[w]{x_1^{w_1} x_2^{w_2} \\cdots x_n^{w_n}}.\n\\end{align}</math>\n\nSince the natural logarithm is [[monotonic function|strictly increasing]],\n:<math>\n\\frac{w_1x_1+\\cdots+w_nx_n}w\n>\\sqrt[w]{x_1^{w_1} x_2^{w_2} \\cdots x_n^{w_n}}.\n</math>\n\n===Other generalizations===\nOther generalizations of the inequality of arithmetic and geometric means include:\n\n* [[Muirhead's inequality]],\n* [[Maclaurin's inequality]],\n* [[Generalized mean|Generalized mean inequality]].\n\n==See also==\n*[[Ky Fan inequality]]\n*[[Young's inequality for products]]\n\n==Notes==\n{{reflist|group=note}}\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{cite web|title=Introduction to Inequalities|url=http://www.mediafire.com/?1mw1tkgozzu |author=Arthur Lohwater|year=1982|publisher=Online e-book in PDF format}}\n\n{{DEFAULTSORT:Inequality Of Arithmetic And Geometric Means}}\n[[Category:Inequalities]]\n[[Category:Means]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Ingleton's inequality",
      "url": "https://en.wikipedia.org/wiki/Ingleton%27s_inequality",
      "text": "In mathematics, '''Ingleton's inequality''' is an [[Inequality (mathematics)|inequality]] that is satisfied by the [[Matroid rank|rank]] function of any [[Matroid representation|representable matroid]]. In this sense it is a necessary condition for representability of a [[matroid]] over a finite field.  Let ''M'' be a matroid and let ''ρ'' be its rank function, Ingleton inequality states that for any subsets ''X''<sub>1</sub>, ''X''<sub>2</sub>, ''X''<sub>3</sub> and ''X''<sub>4</sub> in the [[Support (mathematics)|support]] of ''M'', the inequality\n\n:''ρ''(''X''<sub>1</sub>)+''ρ''(''X''<sub>2</sub>)+''ρ''(''X''<sub>1</sub>∪''X''<sub>2</sub>∪''X''<sub>3</sub>)+''ρ''(''X''<sub>1</sub>∪''X''<sub>2</sub>∪''X''<sub>4</sub>)+''ρ''(''X''<sub>3</sub>∪''X''<sub>4</sub>) ≤ ''ρ''(''X''<sub>1</sub>∪''X''<sub>2</sub>)+''ρ''(''X''<sub>1</sub>∪''X''<sub>3</sub>)+''ρ''(''X''<sub>1</sub>∪''X''<sub>4</sub>)+''ρ''(''X''<sub>2</sub>∪''X''<sub>3</sub>)+''ρ''(''X''<sub>2</sub>∪''X''<sub>4</sub>)'' is satisfied.\n\n[[Aubrey William Ingleton]], an English mathematician, wrote an important paper in 1969<ref name=Ing71>{{Cite book | zbl=0222.05025 | last=Ingleton | first=A.W. | chapter=Representation of matroids | pages=149–167 | title=Combinatorial mathematics and its applications.  Proceedings, Oxford, 1969 | editor-last=Welsh | editor-first=D.J.A. | year=1971 | publisher=Academic Press | isbn=0-12-743350-3   }}</ref> in which he surveyed the representability problem in matroids.  Although the article is mainly expository, in this paper Ingleton stated and proved Ingleton's inequality, which has found interesting applications in [[information theory]], [[matroid|matroid theory]], and [[network coding]].<ref name=\"Ahlswede2000\">{{cite journal| first=Rudolf| last=Ahlswede| authorlink=Rudolf Ahlswede|author2= N. Cai|author3=Shuo-Yen Robert Li|author4=Raymond Wai-Ho Yeung| title=Network Information Flow| journal=IEEE Transactions on Information Theory| pages= 1204–1216| year= 2000| doi=10.1109/18.850663| volume=46| issue=4}}</ref>\n\n== Importance of inequality ==\n\nThere are interesting connections between [[matroids]], the [[Entropic vector|entropy region]] and [[group theory]]. Some of those connections are revealed by Ingleton's Inequality.\n\nPerhaps, the more interesting application of Ingleton's Inequality concerns the computation of [[network coding]] capacities.  [[Linear network coding|Linear coding solutions]] are constrained by the inequality and it has an important consequence:\n\n:The region of achievable rates using [[linear network coding]] could be, in some cases, strictly smaller than the region of achievable rates using general network coding.<ref name=\"Dougherty2005\">{{cite journal| first=R.| last= Dougherty|author2=C. Freiling|author2-link=Chris Freiling |author3=K. Zeger | title=Insufficiency of Linear Network Codes| journal=IEEE International Symposium on Information Theory Adelaide, Australia| pages= 264–267| year= 2005}}</ref><ref name=\"Dougherty2007\">{{cite journal| first=R.| last= Dougherty|author2=C. Freiling|author2-link=Chris Freiling |author3=K. Zeger | title=Networks, matroids, and non-Shannon information inequalities| journal=IEEE Transactions on Information Theory| pages= 1949–1969| year= 2007| volume=53| issue=6| doi=10.1109/TIT.2007.896862}}</ref><ref>{{cite journal|doi=10.1109/TIT.2002.807285|title=Linear network coding|journal=IEEE Transactions on Information Theory|volume=49|issue=2|pages=371|year=2003|last1=Li|first1=S.-Y.R.|last2=Yeung|first2=R.W.|last3=Ning Cai|url=ftp://doc.nit.ac.ir/cee/m.zahabi/Articles/network%20coding/10[1].1.1.84.8088.pdf}}</ref>\n \nFor definitions see, e.g.<ref>{{cite journal|doi=10.1109/SURV.2013.013013.00104 |title=Network Coding Theory: A Survey |journal=IEEE Communications Surveys & Tutorials |volume=15 |issue=4 |pages=1950 |year=2013 |last1=Bassoli |first1=Riccardo |last2=Marques |first2=Hugo |last3=Rodriguez |first3=Jonathan |last4=Shum |first4=Kenneth W. |last5=Tafazolli |first5=Rahim }}\n</ref>\n\n== Proof ==\n\n'''Theorem''' (Ingleton's Inequality):<ref>Oxley, James (1992), Matroid Theory, Oxford: Oxford University Press, {{ISBN|0-19-853563-5}}, [[Mathematical Reviews|MR]] [http://www.ams.org/mathscinet-getitem?mr=1207587 1207587], [[Zentralblatt MATH|Zbl]] [http://www.zentralblatt-math.org/zmath/en/search/?format=complete&q=an:0784.05002 0784.05002].</ref> Let ''M'' be a [[Linear matroid|representable matroid]] with rank function ''ρ'' and let ''X''<sub>1</sub>, ''X''<sub>2</sub>, ''X''<sub>3</sub> and ''X''<sub>4</sub> be subsets of the support set of ''M'', denoted by the symbol ''E''(''M'').  Then:\n\n:''ρ''(''X''<sub>1</sub>)+''ρ''(''X''<sub>2</sub>)+''ρ''(''X''<sub>1</sub>∪''X''<sub>2</sub>∪''X''<sub>3</sub>)+''ρ''(''X''<sub>1</sub>∪''X''<sub>2</sub>∪''X''<sub>4</sub>)+''ρ''(''X''<sub>3</sub>∪''X''<sub>4</sub>) ≤ ''ρ''(''X''<sub>1</sub>∪''X''<sub>2</sub>)+''ρ''(''X''<sub>1</sub>∪''X''<sub>3</sub>)+''ρ''(''X''<sub>1</sub>∪''X''<sub>4</sub>)+''ρ''(''X''<sub>2</sub>∪''X''<sub>3</sub>)+''ρ''(''X''<sub>2</sub>∪''X''<sub>4</sub>)''.\n\nTo prove the inequality we have to show the following result:\n\n'''Proposition''':  Let ''V''<sub>1</sub>,''V''<sub>2</sub>, ''V''<sub>3</sub> and ''V''<sub>4</sub>  be subspaces of a [[vector space]] ''V'', then\n\n# dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>) ≥ dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>3</sub>) − dim(''V''<sub>1</sub>+''V''<sub>3</sub>) − dim(''V''<sub>2</sub>+''V''<sub>3</sub>)                                 + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>)\n# dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>∩''V''<sub>4</sub>) ≥ dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>) + dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>4</sub>) − dim(''V''<sub>1</sub>∩''V''<sub>2</sub>)\n# dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>∩''V''<sub>4</sub>) ≥ dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>3</sub>) + dim(''V''<sub>4</sub>) − dim(''V''<sub>1</sub>+''V''<sub>3</sub>) − dim(''V''<sub>2</sub>+''V''<sub>3</sub>) − dim(''V''<sub>1</sub>+''V''<sub>4</sub>) − dim(''V''<sub>2</sub>+''V''<sub>4</sub>) − dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>4</sub>)\n# dim (''V''<sub>1</sub>) + dim(''V''<sub>2</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>4</sub>) + dim(''V''<sub>3</sub>+''V''<sub>4</sub>) ≤ dim(''V''<sub>1</sub>+''V''<sub>2</sub>) + dim(''V''<sub>1</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>4</sub>) + dim(''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>2</sub>+''V''<sub>4</sub>)\n   \nWhere ''V''<sub>i</sub>+''V''<sub>j</sub> represent the [[direct sum]] of the two subspaces.\n\n'''Proof (proposition)''':  We will use frequently the standard vector space identity:\ndim(''U'') + dim(''W'') = dim(''U''+''W'') + dim(''U''∩''W'').\n\n1. It is clear that (''V''<sub>1</sub>∩''V''<sub>2</sub>) + ''V''<sub>3</sub> ⊆ (''V''<sub>1</sub>+ ''V''<sub>3</sub>) ∩ (''V''<sub>2</sub>+''V''<sub>3</sub>), then\n{|\n|-\n| dim((''V''<sub>1</sub>∩''V''<sub>2</sub>)+''V''<sub>3</sub>) || ≤ || dim((''V''<sub>1</sub>+''V''<sub>2</sub>)∩(''V''<sub>2</sub>+''V''<sub>3</sub>)), || hence\n|}\n \n{|\n|-\n| dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>) || = ||  dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>3</sub>) − dim((''V''<sub>1</sub>∩''V''<sub>2</sub>)+''V''<sub>3</sub>)\n|-\n|  || ≥ || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>3</sub>) − dim((''V''<sub>1</sub>+''V''<sub>3</sub>)∩(''V''<sub>2</sub>+''V''<sub>3</sub>))\n|-\n|  || = || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>3</sub>) – {dim(''V''<sub>1</sub>+''V''<sub>3</sub>) + dim(''V''<sub>2</sub>+''V''<sub>3</sub>)                                              – dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>)}\n|-\n|  || = || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>3</sub>) – dim(''V''<sub>1</sub>+''V''<sub>3</sub>) − dim(''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>)\n|}\n\n2. It is clear that (''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>) + (''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>4</sub>) ⊆ (''V''<sub>1</sub>∩''V''<sub>2</sub>), then\n{|\n|-\n| dim{(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>)+(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>4</sub>)} || ≤ || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>), || hence\n|}\n\n{|\n|-\n| dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>∩''V''<sub>4</sub>) || = || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>) + dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>4</sub>) − dim{(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>) + (''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>4</sub>)}\n|-\n|  || ≥ || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>) + dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>4</sub>) − dim(''V''<sub>1</sub>∩''V''<sub>2</sub>)\n|}\n\n3. From (1) and (2) we have:\n\n{|\n|-\n| dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>∩''V''<sub>4</sub>) || ≥ || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>) + dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>4</sub>) − dim(''V''<sub>1</sub>∩''V''<sub>2</sub>)\n|-\n|  || ≥ || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>3</sub>) − dim(''V''<sub>1</sub>+''V''<sub>3</sub>) − dim(''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>4</sub>) − dim(''V''<sub>1</sub>+''V''<sub>4</sub>) − dim(''V''<sub>2</sub>+''V''<sub>4</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>4</sub>) − dim(''V''<sub>1</sub>∩''V''<sub>2</sub>)\n|-\n|  || = || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>3</sub>) + dim(''V''<sub>4</sub>) − dim(''V''<sub>1</sub>+''V''<sub>3</sub>) − dim(''V''<sub>2</sub>+''V''<sub>3</sub>) − dim(''V''<sub>1</sub>+''V''<sub>4</sub>) − dim(''V''<sub>2</sub>+''V''<sub>4</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>)\n|}\n \n4.  From (3) we have\n\n{|\n|-\n| dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>4</sub>) || ≤ || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>∩''V''<sub>4</sub>) − dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) − dim(''V''<sub>3</sub>) − dim(''V''<sub>4</sub>) + dim(''V''<sub>1</sub>+''V''<sub>3</sub>)+ dim(''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>4</sub>) + dim(''V''<sub>2</sub>+''V''<sub>4</sub>)\n|}\n \nIf we add (dim(''V''<sub>1</sub>)+dim(''V''<sub>2</sub>)+dim(''V''<sub>3</sub>+''V''<sub>4</sub>)) at both sides  of the last inequality, we get\n\n{|\n|-\n| dim(''V''<sub>1</sub>) + dim(''V''<sub>2</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>2</sub>+''V''<sub>4</sub>) + dim(''V''<sub>3</sub>+''V''<sub>4</sub>) ||  ≤  || dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>∩''V''<sub>4</sub>) − dim(''V''<sub>1</sub>∩''V''<sub>2</sub>) + dim(''V''<sub>1</sub>+dim(''V''<sub>2</sub>) + dim(''V''<sub>3</sub>+''V''<sub>4</sub>) − dim(''V''<sub>3</sub>) − dim(''V''<sub>4</sub>) + dim(''V''<sub>1</sub>+''V''<sub>3</sub>) + dim(''V''<sub>2</sub>+''V''<sub>3</sub>) + dim(''V''<sub>1</sub>+''V''<sub>4</sub>) + dim(''V''<sub>2</sub>+''V''<sub>4</sub>)\n|}\n                                          \nSince the inequality dim(''V''<sub>1</sub>∩''V''<sub>2</sub>∩''V''<sub>3</sub>∩''V''<sub>4</sub>) ≤  dim(''V''<sub>3</sub>∩''V''<sub>4</sub>) holds, we have finished with the proof.♣\n\n'''Proof (Ingleton's inequality)''':  Suppose that ''M'' is a representable matroid and let ''A'' = [''v''<sub>1</sub> ''v''<sub>2</sub> … ''v''<sub>n</sub>] be a matrix such that ''M'' = ''M''(''A'').\nFor  ''X'', ''Y'' ⊆ E(''M'') = {1,2, … ,n}, define  ''U'' = <{''V''<sub>i</sub> : i ∈ ''X'' }>, as the [[Linear subspace|span of the vectors]] in ''V''<sub>i</sub>,  and we define ''W'' = <{''V''<sub>j</sub> : j  ∈ Y }> accordingly.\n\nIf we suppose that ''U'' = <{''u''<sub>1</sub>, ''u''<sub>2</sub>, … ,''u''<sub>m</sub>}>  and  ''W'' = <{''w''<sub>1</sub>, ''w''<sub>2</sub>, … ,''w''<sub>r</sub>}>  then clearly we have <{''u''<sub>1</sub>, ''u''<sub>2</sub>, …, ''u''<sub>m</sub>, ''w''<sub>1</sub>, ''w''<sub>2</sub>, …, ''w''<sub>r</sub> }> = ''U'' + ''W''.\n\nHence:\n''r''(''X''∪''Y'') = dim <{''v''<sub>i</sub> : i  ∈ ''X'' } ∪ {''v''<sub>j</sub> : j  ∈ ''Y'' }> = dim(''V'' + ''W'').\n\nFinally, if we define  ''V''<sub>i</sub> = {''v''<sub>r</sub> : ''r'' ∈ ''X''<sub>i</sub> } for  i = 1,2,3,4, then by last inequality and the item (4) of the above proposition, we get the result.\n\n== References ==\n\n{{reflist}}\n\n== External links ==\n* {{springer|title=Transmission rate of a channel|id=p/t093890}}\n\n[[Category:Inequalities]]\n[[Category:Matroid theory]]"
    },
    {
      "title": "Interpolation inequality",
      "url": "https://en.wikipedia.org/wiki/Interpolation_inequality",
      "text": "In the field of [[mathematical analysis]], an '''interpolation inequality''' is an inequality of the form\n\n:<math>\n\\| u_{0} \\|_{0} \\leq C \\| u_{1} \\|_{1}^{\\alpha_{1}} \\| u_{2} \\|_{2}^{\\alpha_{2}} \\dots \\| u_{n} \\|_{n}^{\\alpha_{n}}, \\quad n \\geq 2,\n</math>\n\nvalid for all ''u''<sub>0</sub>, ..., ''u''<sub>''n''</sub> in some (subsets of) [[vector space]]s ''X''<sub>0</sub>, ..., ''X''<sub>n</sub> equipped with [[norm (mathematics)|norms]] ‖&middot;‖<sub>0</sub>, ‖&middot;‖<sub>1</sub>, ..., ‖&middot;‖<sub>''n''</sub>, and where ''C'' is a constant independent of ''u''<sub>0</sub>, ..., ''u''<sub>''n''</sub> and ''&alpha;''<sub>1</sub>, ..., ''&alpha;''<sub>''n''</sub> are some [[real number|real]] powers.  Usually, the elements ''u''<sub>0</sub>, ..., ''u''<sub>''n''</sub> are all the same element ''u'' and only the norms differ (as in [[Ladyzhenskaya's inequality]] below), but some interpolation inequalities use different ''u''<sub>0</sub>, ..., ''u''<sub>''n''</sub> (as in [[Young's inequality for convolutions]] below).\n\nThe main applications of interpolation inequalities lie in the theory of [[Sobolev spaces]], where spaces of functions that have a non-[[integer]] number of [[weak derivative|derivatives]] are interpolated from the spaces of functions with integer number of derivatives.  The abstract structure of interpolation inequalities is formalized in the notion of an [[interpolation space]].\n\nA simple example of an interpolation inequality — one in which all the ''u''<sub>''k''</sub> are the same ''u'', but the norms ‖&middot;‖<sub>''k''</sub> are different — is [[Ladyzhenskaya's inequality]] for functions ''u'':&nbsp;ℝ<sup>2</sup>&nbsp;&rarr;&nbsp;ℝ, which states that whenever ''u'' is a [[compactly supported]] function such that both ''u'' and its [[gradient]] &nabla;''u'' are square integrable, it follows that the fourth power of ''u'' is integrable and\n\n:<math>\n\\int_{\\mathbb{R}^{2}} | u(x) |^{4} \\, \\mathrm{d} x \\leq 2 \\int_{\\mathbb{R}^{2}} | u(x) |^{2} \\, \\mathrm{d} x \\int_{\\mathbb{R}^{2}} | \\nabla u(x) |^{2} \\, \\mathrm{d} x,\n</math>\n\ni.e.\n\n:<math>\n\\| u \\|_{L^{4}} \\leq \\sqrt[4]{2} \\, \\| u \\|_{L^{2}}^{1/2} \\, \\| \\nabla u \\|_{L^{2}}^{1/2}.\n</math>\n\n(Since Ladyzhenskaya's inequality considers compactly supported functions ''u'', [[Friedrichs' inequality]] implies that the ''L''<sup>2</sup> norm of &nabla;''u'' is equivalent to the ''H''<sup>1</sup> Sobolev norm of ''u'', and so Ladyzhenskaya's inequality really does only treat a single function ''u'', not distinct functions ''u''<sub>0</sub>&nbsp;=&nbsp;''u''<sub>1</sub>&nbsp;=&nbsp;''u'' and ''u''<sub>2</sub>&nbsp;=&nbsp;&nabla;''u''.)\n\nAnother simple example of an interpolation inequality — one in which the ''u''<sub>''k''</sub> and the norms ‖&middot;‖<sub>''k''</sub> are different — is [[Young's inequality for convolutions|Young's inequality]] for the [[convolution]] of two functions ''f'', ''g'':&nbsp;ℝ<sup>''d''</sup>&nbsp;&rarr;&nbsp;ℝ:\n\n:<math>\\|f \\star g\\|_{L^{s}} \\leq \\|f\\|_{L^{r}} \\|g\\|_{L^{p}},</math>\n\nwhere the exponents ''p'', ''r'' and ''s''&nbsp;&ge;&nbsp;1 are related by\n\n:<math>\\frac{1}{r}+\\frac{1}{p}=1+\\frac{1}{s}.</math>\n\n==Examples of interpolation inequalities==\n\n* [[Agmon's inequality]]\n* [[Gagliardo–Nirenberg interpolation inequality]]\n* [[Ladyzhenskaya's inequality]]\n* [[Landau–Kolmogorov inequality]]\n* [[Marcinkiewicz interpolation theorem]]\n* [[Sobolev inequality#Nash inequality|Nash's inequality]]\n* [[Riesz–Thorin theorem]]\n* [[Young's inequality for convolutions]]\n\n[[Category:Inequalities]]\n[[Category:Sobolev spaces]]"
    },
    {
      "title": "Jackson's inequality",
      "url": "https://en.wikipedia.org/wiki/Jackson%27s_inequality",
      "text": "In [[approximation theory]], '''Jackson's inequality'''  is an inequality bounding the value of function's best approximation by [[polynomials|algebraic]] or [[trigonometric polynomials]] in terms of the [[modulus of continuity]] or [[modulus of smoothness]] of the function or of its derivatives.<ref>{{cite book|last=Achieser|first=N.I.|author-link=Naum Akhiezer|title=Theory of Approximation|year=1956|publisher=Frederick Ungar Publishing Co|location=New York}}</ref> Informally speaking, the smoother the function is, the better it can be approximated by polynomials.\n\n==Statement: trigonometric polynomials==\n\nFor trigonometric polynomials, the following was proved by [[Dunham Jackson]]:\n\n:'''Theorem 1''': If <math>f:[0,2\\pi]\\to \\C</math> is an <math>r</math> times differentiable [[periodic function]] such that\n::<math> \\left |f^{(r)}(x) \\right | \\leq 1, \\qquad x\\in[0,2\\pi],</math>\n:then, for every positive integer <math>n</math>, there exists a [[trigonometric polynomial]] <math>T_{n-1}</math> of degree at most <math>n-1</math> such that\n::<math>\\left |f(x) - T_{n-1}(x) \\right | \\leq \\frac{C(r)}{n^r}, \\qquad x\\in[0,2\\pi], </math>\n:where <math>C(r)</math> depends only on <math>r</math>.\n\nThe '''[[Naum Akhiezer|Akhiezer]]&ndash;[[Mark Krein|Krein]]&ndash;[[Jean Favard|Favard]] theorem''' gives the sharp value of <math>C(r)</math> (called the [[Favard constant|Akhiezer&ndash;Krein&ndash;Favard constant]]):\n\n: <math> C(r) = \\frac{4}{\\pi} \\sum_{k=0}^\\infty \\frac{(-1)^{k(r+1)}}{(2k+1)^{r+1}}~.</math>\n\nJackson also proved the following generalisation of Theorem 1:\n\n:'''Theorem 2''': One can find a [[trigonometric polynomial]] <math>T_n</math> of degree <math>\\le n</math> such that\n::<math>|f(x) - T_n(x)| \\leq \\frac{C(r) \\omega \\left (\\frac{1}{n}, f^{(r)} \\right )}{n^r}, \\qquad x\\in[0,2\\pi],</math>\n:where <math>\\omega(\\delta, g)</math> denotes the [[modulus of continuity]] of function <math>g</math> with the step <math>\\delta.</math>\n\nAn even more general result of four authors can be formulated as the following Jackson theorem. \n\n:'''Theorem 3''': For every natural number <math>n</math>, if <math>f</math> is <math>2\\pi</math>-periodic continuous function, there exists a [[trigonometric polynomial]] <math>T_n</math> of degree <math>\\le n</math> such that\n::<math>|f(x)-T_n(x)|\\leq c(k)\\omega_k\\left(\\tfrac{1}{n},f\\right),\\qquad x\\in[0,2\\pi],</math>\n:where constant <math>c(k)</math> depends on <math>k\\in\\N,</math> and <math>\\omega_k</math> is the <math>k</math>-th order [[modulus of smoothness]].\n\nFor <math>k=1</math> this result was proved by Dunham Jackson. [[Antoni Zygmund]] proved the inequality in the case when <math>k=2, \\omega_2(t,f)\\le ct, t>0</math> in 1945. [[Naum Akhiezer]] proved the theorem in the case <math>k=2</math> in 1956. For <math>k>2</math> this result was established by [[Sergey Stechkin]] in 1967.\n\n==Further remarks==\n\nGeneralisations and extensions are called Jackson-type theorems. A converse to Jackson's inequality is given by [[Bernstein's theorem (approximation theory)|Bernstein's theorem]]. See also [[constructive function theory]].\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{SpringerEOM|id=Jackson_inequality|first1=N.P.|last1=Korneichuk|first2=V.P.|last2=Motornyi}}\n* {{MathWorld|title=Jackson's Theorem|id=JacksonsTheorem}}\n\n{{DEFAULTSORT:Jackson's Inequality}}\n[[Category:Approximation theory]]\n[[Category:Inequalities]]\n[[Category:Theorems in approximation theory]]\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Jensen's inequality",
      "url": "https://en.wikipedia.org/wiki/Jensen%27s_inequality",
      "text": "{{Use American English|date = March 2019}}\n{{Short description|Theorem of convex functions}}\n{{For|Jensen's inequality for analytic functions|Jensen's formula}}\n{{refimprove|date=October 2011}}\n[[File:ConvexFunction.svg|thumb|right|400px|'''Jensen's inequality''' generalizes the statement that a secant line of a convex function lies above the graph.]]\nIn [[mathematics]], '''Jensen's inequality''', named after the Danish mathematician [[Johan Jensen (mathematician)|Johan Jensen]], relates the value of a [[convex function]] of an [[integral]] to the integral of the convex function. It was proven by Jensen in 1906.<ref>{{cite journal |last=Jensen |first=J. L. W. V. |authorlink=Johan Jensen (mathematician) |date=1906 |title=Sur les fonctions convexes et les inégalités entre les valeurs moyennes |journal=[[Acta Mathematica]] |volume=30 |issue=1 |pages=175–193 |doi=10.1007/BF02418571 }}</ref> Given its generality, the inequality appears in many forms depending on the context, some of which are presented below. In its simplest form the inequality states that the convex transformation of a mean is less than or equal to the mean applied after convex transformation; it is a simple corollary that the opposite is true of concave transformations.\n\nJensen's inequality generalizes the statement that the [[secant line]] of a convex function lies ''above'' the graph of the function, which is Jensen's inequality for two points: the secant line consists of weighted means of the convex function (for ''t''&nbsp;∈&nbsp;[0,1]),\n\n:<math>t f(x_1) + (1-t) f(x_2),</math>\n\nwhile the graph of the function is the convex function of the weighted means,\n\n:<math>f \\left (t x_1 + (1-t) x_2 \\right ).</math>\n\nThus, Jensen's inequality is\n:<math>f \\left (t x_1 + (1-t) x_2 \\right ) \\leq t f(x_1)+ (1-t) f(x_2).</math>\n\nIn the context of [[probability theory]], it is generally stated in the following form: if ''X'' is a [[random variable]] and {{mvar|φ}} is a convex function, then\n\n:<math>\\varphi\\left(\\operatorname{E}[X]\\right) \\leq \\operatorname{E} \\left[\\varphi(X)\\right].</math>\n\n==Statements==\nThe classical form of Jensen's inequality involves several numbers and weights. The inequality can be stated quite generally using either the language of [[measure (mathematics)|measure theory]] or (equivalently) probability. In the probabilistic setting, the inequality can be further generalized to its ''full strength''.\n\n===Finite form===\nFor a real [[convex function]] <math>\\varphi</math>, numbers <math>x_1, x_2, \\ldots, x_n</math> in its domain, and positive weights <math>a_i</math>, Jensen's inequality can be stated as:\n\n:<math>\\varphi\\left(\\frac{\\sum a_i x_i}{\\sum a_i}\\right) \\le \\frac{\\sum a_i \\varphi (x_i)}{\\sum a_i} \\qquad\\qquad (1)</math>\n\nand the inequality is reversed if <math>\\varphi</math> is [[concave function|concave]], which is\n\n:<math>\\varphi\\left(\\frac{\\sum a_i x_i}{\\sum a_i}\\right) \\geq \\frac{\\sum a_i \\varphi (x_i)}{\\sum a_i}.\\qquad\\qquad(2) </math>\n\nEquality holds if and only if <math>x_1=x_2=\\cdots =x_n</math> or <math>\\varphi</math> is linear.\n\nAs a particular case, if the weights <math>a_i</math> are all equal, then (1) and (2) become\n\n:<math>\\varphi\\left(\\frac{\\sum x_i}{n}\\right) \\le \\frac{\\sum \\varphi (x_i)}{n} \\qquad\\qquad (3) </math>\n:<math>\\varphi\\left(\\frac{\\sum x_i}{n}\\right) \\geq \\frac{\\sum \\varphi (x_i)}{n} \\qquad\\qquad (4) </math>\n\nFor instance, the function [[Logarithm|{{math|log(''x'')}}]] is ''[[concave function|concave]]'', so substituting <math>\\varphi(x) = \\log(x)</math> in the previous formula (4) establishes the (logarithm of the) familiar [[AM-GM inequality|arithmetic mean-geometric mean inequality]]:\n\n:<math>\\log\\!\\left( \\frac{\\sum_{i=1}^n x_i}{n}\\right) \\geq \\frac{\\sum_{i=1}^n \\log\\!\\left( x_i \\right)}{n} \\quad \\text{or} \\quad\n\\frac{x_1 + x_2 + \\cdots + x_n}{n} \\geq \\sqrt[n]{x_1 \\cdot x_2 \\cdots x_n}</math>\n\nA common application has <math>x</math> as a function of another variable (or set of variables) <math>t</math>, that is, <math>x_i = g(t_i)</math>. All of this carries directly over to the general continuous case: the weights {{math|''a<sub>i</sub>''}} are replaced by a non-negative integrable function {{math| ''f'' (''x'')}}, such as a probability distribution, and the summations are replaced by integrals.\n\n===Measure-theoretic and probabilistic form===\nLet <math>(\\Omega, A, \\mu)</math> be a [[probability space]], such that <math>\\mu(\\Omega)= 1</math>. If <math>g</math> is a [[real number|real]]-valued function that is <math>\\mu</math>-[[Integrable function|integrable]], and if <math>\\varphi</math> is a [[convex function]] on the real line, then:\n\n:<math>\\varphi\\left(\\int_\\Omega g\\, d\\mu\\right) \\le \\int_\\Omega \\varphi \\circ g\\, d\\mu. </math>\n\nIn real analysis, we may require an estimate on\n\n:<math>\\varphi\\left(\\int_a^b f(x)\\, dx\\right),</math>\n\nwhere <math>a, b \\in \\mathbb{R}</math>, and <math>f:[a, b] \\to \\R</math> is a non-negative  Lebesgue-[[Integrable function|integrable]] function. In this case, the Lebesgue measure of <math>[a, b]</math> need not be unity. However, by integration by substitution, the interval can be rescaled so that it has measure unity. Then Jensen's inequality can be applied to get<ref>Niculescu, Constantin P. [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.625.7106&rep=rep1&type=pdf \"Integral inequalities\"], P. 12.</ref>\n\n:<math>\\varphi\\left(\\frac{1}{b-a}\\int_a^b  f(x)\\, dx\\right) \\le \\frac{1}{b-a} \\int_a^b \\varphi(f(x)) \\,dx. </math>\n\nThe same result can be equivalently stated in a [[probability theory]] setting, by a simple change of notation. Let <math>(\\Omega, \\mathfrak{F},\\operatorname{P})</math> be a [[probability space]], ''X'' an [[integrable function|integrable]] real-valued [[random variable]] and {{mvar|φ}} a [[convex function]]. Then:\n\n:<math>\\varphi\\left(\\operatorname{E}[X]\\right) \\leq \\operatorname{E} \\left[ \\varphi(X) \\right].</math>\n\nIn this probability setting, the measure {{mvar|μ}} is intended as a probability <math>\\operatorname{P}</math>, the integral with respect to {{mvar|μ}} as an [[expected value]] <math>\\operatorname{E}</math>, and the function <math>g</math> as a [[random variable]] ''X''.\n\nNotice that the equality holds if ''X'' is constant (degenerate random variable) or if {{mvar|φ}} is linear, and even if there is <math>A\\subset\\R</math> (a Borel set, in fact)  such that\n\n:<math>\\Pr(X \\in A)=1</math>\n\nand {{mvar|φ}} is a linear function over A (that is, there are <math>a,b \\in \\R</math> such that <math>\\varphi(x)=ax+b, \\forall x \\in A</math>).\n\n===General inequality in a probabilistic setting===\nMore generally, let ''T'' be a real [[topological vector space]], and ''X'' a ''T''-valued [[integrable function|integrable]] random variable. In this general setting, ''integrable'' means that there exists an element <math>\\operatorname{E}[X]</math> in ''T'', such that for any element ''z'' in the [[dual space]] of ''T'': <math>\\operatorname{E}|\\langle z, X \\rangle|<\\infty </math>, and <math>\\langle z, \\operatorname{E}[X]\\rangle = \\operatorname{E}[\\langle z, X \\rangle]</math>. Then, for any measurable convex function {{mvar|φ}} and any sub-[[sigma algebra|σ-algebra]] <math>\\mathfrak{G}</math> of <math>\\mathfrak{F}</math>:\n\n:<math>\\varphi\\left(\\operatorname{E}\\left[X\\mid\\mathfrak{G}\\right]\\right) \\leq  \\operatorname{E}\\left[\\varphi(X)\\mid\\mathfrak{G}\\right].</math>\n\nHere <math>\\operatorname{E}[\\cdot\\mid\\mathfrak{G}]</math> stands for the [[conditional expectation|expectation conditioned]] to the σ-algebra <math>\\mathfrak{G}</math>. This general statement reduces to the previous ones when the topological vector space {{mvar|T}} is the [[real axis]], and <math>\\mathfrak{G}</math> is the trivial {{mvar|σ}}-algebra {{math|{∅, Ω}.}}<ref>Attention: In this generality additional assumptions on the convex function and/ or the topological vector space are needed, see Example (1.3) on p.&nbsp;53 in {{cite journal |last=Perlman |first=Michael D. |title=Jensen's Inequality for a Convex Vector-Valued Function on an Infinite-Dimensional Space |journal=Journal of Multivariate Analysis |volume=4 |issue=1 |pages=52–65 |year=1974 |doi=10.1016/0047-259X(74)90005-0 }}</ref>\n\n=== A sharpened and generalized form ===\nLet ''X'' be a one-dimensional random variable with mean <math>\\mu</math> and variance <math>\\sigma^2\\ge 0</math>.  Let <math>\\varphi(x)</math> be a twice differentiable function, and define the function\n\n:<math>\nh(x)\\triangleq\\frac{\\varphi \\left(x\\right)-\\varphi \\left(\\mu \\right)}{\\left(x-\\mu\n\\right)^2}-\\frac{\\varphi '\\left(\\mu \\right)}{x-\\mu}.\n</math>\n\nThen<ref name=\"Liao & Berg\">{{cite article | last = Liao | first = J. | last2 = Berg | first2 = A | year = 2018 | title = Sharpening Jensen's Inequality |journal=[[American Statistician]] | doi=10.1080/00031305.2017.1419145}}</ref>\n\n:<math>\n\\sigma^2\\inf \\frac{\\varphi''(x)}{2} \\le \\sigma^2\\inf h(x) \\leq E\\left[\\varphi \\left(X\\right)\\right]-\\varphi\\left(E[X]\\right)\\le \\sigma^2\\sup h(x) \\le \\sigma^2\\sup \\frac{\\varphi''(x)}{2}.\n</math>\n\nIn particular, when <math>\\varphi(x)</math> is convex, then <math>\\varphi''(x)\\ge 0</math>, and the standard form of Jensen's inequality immediately follows.\n\n==Proofs==\n[[File:Jensen graph.svg|350px|thumb|right|A graphical \"proof\" of Jensen's inequality for the probabilistic case. The dashed curve along the {{mvar|X}} axis is the hypothetical distribution of {{mvar|X}}, while the dashed curve along the {{mvar|Y}} axis is the corresponding distribution of {{mvar|Y}} values. Note that the convex mapping {{math|''Y''(''X'')}} increasingly \"stretches\" the distribution for increasing values of {{mvar|X}}.]]\n\nJensen's inequality can be proved in several ways, and three different proofs corresponding to the different statements above will be offered. Before embarking on these mathematical derivations, however, it is worth analyzing an intuitive graphical argument based on the probabilistic case where {{mvar|X}} is a real number (see figure). Assuming a hypothetical distribution of {{mvar|X}} values, one can immediately identify the position of <math>\\operatorname{E}[X]</math> and its image <math> \\varphi(\\operatorname{E}[X])</math> in the graph. Noticing that for convex mappings {{math|''Y'' {{=}} ''φ''(''X'')}} the corresponding distribution of {{mvar|Y}} values is increasingly \"stretched out\" for increasing values of {{mvar|X}}, it is easy to see that the distribution of {{mvar|Y}} is broader in the interval corresponding to {{math|''X'' > ''X''<sub>0</sub>}} and narrower in {{math|''X'' < ''X''<sub>0</sub>}} for any {{math|''X''<sub>0</sub>}}; in particular, this is also true for <math>  X_0 = \\operatorname{E}[X]</math>. Consequently, in this picture the expectation of {{mvar|Y}} will always shift upwards with respect to the position of <math> \\varphi(\\operatorname{E}[X])</math>. A similar reasoning holds if the distribution of {{mvar|X}} covers a decreasing portion of the convex function, or both a decreasing and an increasing portion of it. This \"proves\" the inequality, i.e.\n\n:<math>\\varphi(\\operatorname{E}[X]) \\leq  \\operatorname{E}[\\varphi(X)] = \\operatorname{E}[Y], </math>\n\nwith equality when {{math|''φ''(''X'')}} is not strictly convex, e.g. when it is a straight line, or when {{mvar|X}} follows a [[degenerate distribution]] (i.e. is a constant).\n\nThe proofs below formalize this intuitive notion.\n\n===Proof 1 (finite form)===\nIf {{math|''λ''<sub>1</sub>}} and {{math|''λ''<sub>2</sub>}} are two arbitrary nonnegative real numbers such that {{math|''λ''<sub>1</sub> + ''λ''<sub>2</sub> {{=}} 1}} then convexity of {{mvar|φ}} implies\n\n:<math>\\forall x_1, x_2: \\qquad \\varphi \\left (\\lambda_1 x_1+\\lambda_2 x_2 \\right )\\leq \\lambda_1\\,\\varphi(x_1)+\\lambda_2\\,\\varphi(x_2).</math>\n\nThis can be easily generalized: if {{math|''λ''<sub>1</sub>, ..., ''λ<sub>n</sub>''}} are nonnegative real numbers such that {{math|''λ''<sub>1</sub> + ... + ''λ<sub>n</sub>'' {{=}} 1}}, then\n\n:<math>\\varphi(\\lambda_1 x_1+\\lambda_2 x_2+\\cdots+\\lambda_n x_n)\\leq \\lambda_1\\,\\varphi(x_1)+\\lambda_2\\,\\varphi(x_2)+\\cdots+\\lambda_n\\,\\varphi(x_n),</math>\n\nfor any {{math|''x''<sub>1</sub>, ..., ''x<sub>n</sub>''}}. This ''finite form'' of the Jensen's inequality can be proved by [[mathematical induction|induction]]: by convexity hypotheses, the statement is true for ''n''&nbsp;=&nbsp;2. Suppose it is true also for some ''n'', one needs to prove it for {{math|''n'' + 1}}. At least one of the {{math|''λ<sub>i</sub>''}} is strictly positive, say {{math|''λ''<sub>1</sub>}}; therefore by convexity inequality:\n\n:<math>\\begin{align}\n\\varphi\\left(\\sum_{i=1}^{n+1}\\lambda_i x_i\\right) &= \\varphi\\left(\\lambda_1 x_1+(1-\\lambda_1)\\sum_{i=2}^{n+1} \\frac{\\lambda_i}{1-\\lambda_1} x_i \\right) \\\\\n&\\leq \\lambda_1\\,\\varphi(x_1)+(1-\\lambda_1) \\varphi\\left(\\sum_{i=2}^{n+1} \\frac{\\lambda_i}{1-\\lambda_1} x_i \\right).\n\\end{align}</math>\n\nSince\n\n:<math>\\sum_{i=2}^{n+1} \\frac{\\lambda_i}{1-\\lambda_1} = 1,</math>\n\none can apply the induction hypotheses to the last term in the previous formula to obtain the result, namely the finite form of the Jensen's inequality.\n\nIn order to obtain the general inequality from this finite form, one needs to use a density argument. The finite form can  be rewritten as:\n\n:<math>\\varphi\\left(\\int x\\,d\\mu_n(x) \\right)\\leq \\int \\varphi(x)\\,d\\mu_n(x),</math>\n\nwhere ''μ''<sub>''n''</sub> is a measure given by an arbitrary [[convex combination]] of [[Dirac delta]]s:\n\n:<math>\\mu_n= \\sum_{i=1}^n \\lambda_i \\delta_{x_i}.</math>\n\nSince convex functions are [[continuous function|continuous]], and since convex combinations of Dirac deltas are [[weak topology|weakly]] [[dense set|dense]] in the set of probability measures (as could be easily verified), the general statement is obtained simply by a limiting procedure.\n\n===Proof 2 (measure-theoretic form)===\nLet ''g'' be a real-valued μ-integrable function on a probability space Ω, and let {{mvar|φ}} be a convex function on the real numbers. Since {{mvar|φ}} is convex, at each real number {{mvar|x}} we have a nonempty set of [[subderivative]]s, which may be thought of as lines touching the graph of {{mvar|φ}} at {{mvar|x}}, but which are at or below the graph of {{mvar|φ}} at all points (support lines of the graph).\n\nNow, if we define\n:<math>x_0:=\\int_\\Omega g\\, d\\mu,</math>\nbecause of the existence of subderivatives for convex functions, we may choose ''a'' and ''b'' such that\n:<math>ax + b \\leq \\varphi(x),</math>\nfor all real {{mvar|x}} and\n:<math>ax_0+ b = \\varphi(x_0).</math>\nBut then we have that\n:<math>\\varphi \\circ g (x) \\geq ag(x)+ b</math>\nfor all {{mvar|x}}. Since we have a probability measure, the integral is monotone with {{math|''μ''(Ω) {{=}} 1}} so that\n\n:<math>\\int_\\Omega \\varphi \\circ g\\, d\\mu  \\geq \\int_\\Omega (ag + b)\\, d\\mu  = a\\int_\\Omega g\\, d\\mu + b\\int_\\Omega d\\mu = ax_0 + b = \\varphi (x_0) = \\varphi \\left (\\int_\\Omega g\\, d\\mu \\right ),</math>\n\nas desired.\n\n===Proof 3 (general inequality in a probabilistic setting)===\nLet ''X'' be an integrable random variable that takes values in a real topological vector space ''T''. Since <math>\\varphi: T \\to \\R</math> is convex, for any <math>x,y \\in T</math>, the quantity\n\n:<math>\\frac{\\varphi(x+\\theta\\,y)-\\varphi(x)}{\\theta},</math>\n\nis decreasing as {{mvar|θ}} approaches 0<sup>+</sup>. In particular, the ''subdifferential'' of <math>\\varphi</math> evaluated at {{mvar|x}} in the direction {{mvar|y}} is well-defined by\n\n:<math>(D\\varphi)(x)\\cdot y:=\\lim_{\\theta \\downarrow 0} \\frac{\\varphi(x+\\theta\\,y)-\\varphi(x)}{\\theta}=\\inf_{\\theta \\neq 0} \\frac{\\varphi(x+\\theta\\,y)-\\varphi(x)}{\\theta}.</math>\n\nIt is easily seen that the subdifferential is linear in {{mvar|y}} {{Citation needed|date=October 2013}} (that is false and the assertion requires Hahn-Banach theorem to be proved) and, since the infimum taken in the right-hand side of the previous formula is smaller than the value of the same term for {{math|''θ'' {{=}} 1}}, one gets\n\n:<math>\\varphi(x)\\leq \\varphi(x+y)-(D\\varphi)(x)\\cdot y.</math>\n\nIn particular, for an arbitrary sub-{{mvar|σ}}-algebra <math> \\mathfrak{G}</math> we can evaluate the last inequality when <math>  x = \\operatorname{E}[X\\mid\\mathfrak{G}],\\,y=X-\\operatorname{E}[X\\mid\\mathfrak{G}]</math> to obtain\n\n:<math>\\varphi(\\operatorname{E}[X\\mid\\mathfrak{G}]) \\leq \\varphi(X)-(D\\varphi)(\\operatorname{E}[X\\mid\\mathfrak{G}])\\cdot (X-\\operatorname{E}[X\\mid\\mathfrak{G}]).</math>\n\nNow, if we take the expectation conditioned to <math> \\mathfrak{G}</math> on both sides of the previous expression, we get the result since:\n\n:<math>\\operatorname{E} \\left [\\left[(D\\varphi)(\\operatorname{E}[X\\mid\\mathfrak{G}])\\cdot (X-\\operatorname{E}[X\\mid\\mathfrak{G}])\\right]\\mid\\mathfrak{G} \\right] = (D\\varphi)(\\operatorname{E}[X\\mid\\mathfrak{G}])\\cdot \\operatorname{E}[\\left( X-\\operatorname{E}[X\\mid\\mathfrak{G}] \\right) \\mid \\mathfrak{G}]=0,</math>\n\nby the linearity of the subdifferential in the ''y'' variable, and the following well-known property of the [[conditional expectation]]:\n\n:<math>\\operatorname{E} \\left [ \\left(\\operatorname{E}[X\\mid\\mathfrak{G}] \\right) \\mid\\mathfrak{G} \\right ] = \\operatorname{E}[ X \\mid\\mathfrak{G}].</math>\n\n==Applications and special cases==\n\n===Form involving a probability density function===\nSuppose {{math|Ω}} is a measurable subset of the real line and ''f''(''x'') is a non-negative function such that\n\n:<math>\\int_{-\\infty}^\\infty f(x)\\,dx = 1.</math>\n\nIn probabilistic language, ''f'' is a [[probability density function]].\n\nThen Jensen's inequality becomes the following statement about convex integrals:\n\nIf ''g'' is any real-valued measurable function and <math display=\"inline\">\\varphi</math> is convex over the range of ''g'', then\n\n:<math> \\varphi\\left(\\int_{-\\infty}^\\infty g(x)f(x)\\, dx\\right) \\le \\int_{-\\infty}^\\infty \\varphi(g(x)) f(x)\\, dx. </math>\n\nIf ''g''(''x'') = ''x'', then this form of the inequality reduces to a commonly used special case:\n\n:<math>\\varphi\\left(\\int_{-\\infty}^\\infty x\\, f(x)\\, dx\\right) \\le \\int_{-\\infty}^\\infty \\varphi(x)\\,f(x)\\, dx.</math>\n\n===Example: even [[moment (mathematics)|moment]]s of a random variable===\n\nIf ''g''(''x'') = ''x<sup>2n</sup>'', and ''X'' is a random variable, then ''g'' is convex as\n:<math> \\frac{d^{2}g}{dx^{2}}(x) = 2n(2n - 1)x^{2n - 2} \\geq 0\\quad \\forall\\ x \\in \\R</math>\nand so \n:<math>\ng(\\operatorname{E}[X]) = (\\operatorname{E}[X])^{2n} \\leq\\operatorname{E}[X^{2n}].\n</math>\n\nIn particular, if some even moment ''2n'' of ''X'' is finite, ''X'' has a finite mean. An extension of this argument shows ''X'' has finite moments of every order <math>l\\in\\N</math> dividing ''n''.\n\n===Alternative finite form===\nLet {{math|Ω {{=}} {''x''<sub>1</sub>, ... ''x<sub>n</sub>''},}} and take {{mvar|μ}} to be the [[counting measure]] on {{math|Ω}}, then the general form reduces to a statement about sums:\n\n:<math> \\varphi\\left(\\sum_{i=1}^{n} g(x_i)\\lambda_i \\right) \\le \\sum_{i=1}^{n} \\varphi(g(x_i)) \\lambda_i, </math>\n\nprovided that {{math|''λ<sub>i</sub>'' ≥ 0}} and\n\n:<math>\\lambda_1 + \\cdots + \\lambda_n = 1.</math>\n\nThere is also an infinite discrete form.\n\n===Statistical physics===\nJensen's inequality is of particular importance in statistical physics when the convex function is an exponential, giving:\n\n:<math> e^{\\operatorname{E}[X]} \\leq \\operatorname{E} \\left [ e^X \\right ],</math>\n\nwhere the [[expected value]]s are with respect to some [[probability distribution]] in the [[random variable]] {{mvar|X}}.\n\nThe proof in this case is very simple (cf. Chandler, Sec. 5.5).  The desired inequality follows directly, by writing\n\n:<math> \\operatorname{E} \\left [ e^X \\right ] = e^{\\operatorname{E}[X]} \\operatorname{E} \\left [ e^{X - \\operatorname{E}[X]} \\right]</math>\n\nand then applying the inequality {{math|''e<sup>X</sup>'' ≥ 1 + ''X''}} to the final exponential.\n\n===Information theory===\nIf {{math|''p''(''x'')}} is the true probability density for {{mvar|X}}, and {{math|''q''(''x'')}} is another density, then applying Jensen's inequality for the random variable {{math|''Y''(''X'') {{=}} ''q''(''X'')/''p''(''X'')}} and the convex function {{math|''φ''(''y'') {{=}} −log(''y'')}} gives\n\n:<math>\\operatorname{E}[\\varphi(Y)] \\ge \\varphi(\\operatorname{E}[Y])</math>\n\nTherefore:\n\n:<math>-D(p(x)\\|q(x))=\\int p(x) \\log \\left (\\frac{q(x)}{p(x)} \\right ) \\, dx \\le \\log \\left ( \\int p(x) \\frac{q(x)}{p(x)}\\,dx \\right ) = \\log \\left (\\int q(x)\\,dx \\right ) =0 </math>\n\na result called [[Gibbs' inequality]].\n\nIt shows that the average message length is minimised when codes are assigned on the basis of the true probabilities ''p'' rather than any other distribution ''q''. The quantity that is non-negative is called the [[Kullback–Leibler divergence]] of ''q'' from ''p''.\n\nSince {{math|−log(''x'')}} is a strictly convex function for {{math|''x'' > 0}}, it follows that equality holds when {{math|''p''(''x'')}} equals {{math|''q''(''x'')}} almost everywhere.\n\n===Rao–Blackwell theorem===\n{{main article|Rao–Blackwell theorem}}\n\nIf ''L'' is a convex function and <math>\\mathfrak{G}</math> a sub-sigma-algebra, then, from the conditional version of Jensen's inequality, we get\n\n:<math>L(\\operatorname{E}[\\delta(X) \\mid \\mathfrak{G}]) \\le \\operatorname{E}[L(\\delta(X)) \\mid \\mathfrak{G}] \\quad \\Longrightarrow \\quad \\operatorname{E}[L(\\operatorname{E}[\\delta(X) \\mid \\mathfrak{G}])] \\le \\operatorname{E}[L(\\delta(X))].</math>\n\nSo if δ(''X'') is some [[estimator]] of an unobserved parameter θ given a vector of observables ''X''; and if ''T''(''X'') is a [[sufficient statistic]] for θ; then an improved estimator, in the sense of having a smaller expected loss ''L'', can be obtained by calculating\n\n:<math>\\delta_1 (X) = \\operatorname{E}_{\\theta}[\\delta(X') \\mid T(X')= T(X)], </math>\n\nthe expected value of δ with respect to θ, taken over all possible vectors of observations ''X'' compatible with the same value of ''T''(''X'') as that observed.\n\nThis result is known as the [[Rao–Blackwell theorem]].\n\n==See also==\n* [[Karamata's inequality]] for a more general inequality\n* [[Popoviciu's inequality]]\n* [[Law of averages]]\n* [[Proof without words#Jensen.27s inequality|A proof without words of Jensen's inequality]]\n\n==Notes==\n{{Reflist}}\n\n==References==\n* {{cite book|author=David Chandler|title=Introduction to Modern Statistical Mechanics|publisher=Oxford|year=1987| isbn=0-19-504277-8 |authorlink=David Chandler (chemist)}}\n* [[Tristan Needham]] (1993) \"A Visual Explanation of Jensen's Inequality\", [[American Mathematical Monthly]] 100(8):768–71.\n* {{cite book | author= [[Nicola Fusco]], [[Paolo Marcellini]], Carlo Sbordone| title= Analisi Matematica Due | publisher= Liguori | year= 1996| isbn=978-88-207-2675-1}}\n* {{cite book|author=Walter Rudin|title=Real and Complex Analysis|publisher=McGraw-Hill|year=1987|isbn=0-07-054234-1| authorlink=Walter Rudin}}\n\n==External links==\n* [https://arxiv.org/abs/math/0204049 Jensen's Operator Inequality] of Hansen and Pedersen.\n* {{springer|title=Jensen inequality|id=p/j054220}}\n* {{MathWorld|urlname=JensensInequality|title=Jensen's inequality}}\n*{{cite web|title=Introduction to Inequalities|url=http://www.mediafire.com/?1mw1tkgozzu |author=Arthur Lohwater|date=1982|publisher=Online e-book in PDF format}}\n\n[[Category:Inequalities]]\n[[Category:Probabilistic inequalities]]\n[[Category:Statistical inequalities]]\n[[Category:Theorems in analysis]]\n[[Category:Articles containing proofs]]\n[[Category:Convex analysis]]"
    },
    {
      "title": "Jordan's inequality",
      "url": "https://en.wikipedia.org/wiki/Jordan%27s_inequality",
      "text": "[[File:Jordan inequality.svg|thumb|upright=1.2|<math>\\frac{2}{\\pi}x\\leq \\sin(x) \\leq x\\text{ for }x \\in \\left[0,\\frac{\\pi}{2}\\right]</math>]]\n[[File:Jordans inequality.svg|thumb|upright=1.2|[[unit circle]] with angle x and a second circle with radius <math>|EG|=\\sin(x)</math> around E. <math>\\begin{align}&|DE|\\leq|\\widehat{DC}|\\leq|\\widehat{DG}|\\\\ \\Leftrightarrow &\\sin(x) \\leq x \\leq\\tfrac{\\pi}{2}\\sin(x)\\\\ \\Rightarrow &\\tfrac{2}{\\pi}x \\leq \\sin(x)\\leq x  \\end{align}</math>]]\n\nIn mathematics, '''Jordan's inequality''', named after [[Camille Jordan]], states that<ref>{{MathWorld|title=Jordan's inequality|urlname=JordansInequality}}</ref>\n\n: <math>\\frac{2}{\\pi}x\\leq \\sin(x) \\leq x\\text{ for }x \\in \\left[0,\\frac{\\pi}{2}\\right].</math>\n\nIt can be proven through the [[geometry]] of [[circles]] (see drawing).<ref>Nach Feng Yuefeng, Proof without words: Jordan`s inequality, Mathematics Magazine, volume 69, no. 2, 1996, p. 126</ref>\n\n==Notes==\n<references/>\n\n==Further reading==\n*Serge Colombo: ''Holomorphic Functions of One Variable''. Taylor & Francis 1983, {{ISBN|0677059507}}, p.&nbsp;167-168 ([https://books.google.com/books?id=pFEOAAAAQAAJ&pg=PA167 online copy])\n*Da-Wei Niu, Jian Cao, Feng Qi: [http://www.scientificbulletin.upb.ro/rev_docs_arhiva/full3105.pdf ''Generealizations of Jordan's Inequality and Concerned Relations'']. U.P.B. Sci. Bull., Series A, Volume 72, Issue 3, 2010, {{issn|1223-7027}}\n*Feng Qi: [http://www.ajmaa.org/RGMIA/papers/v9n3/refine-jordan-kober.pdf ''Jordan's Inequality: Refinements, Generealizations, Applications and related Problems''].  RGMIA Res Rep Coll (2006), Volume: 9, Issue: 3, Pages: 243–259\n*Meng-Kuang Kuo: [http://www.journalofinequalitiesandapplications.com/content/2011/1/130 ''Refinements of Jordan's inequality'']. Journal of Inequalities and Applications 2011, 2011:130, doi:10.1186/1029-242X-2011-130\n\n==External links==\n*[https://proofwiki.org/wiki/Jordan%27s_Inequality Jordan's inequality] at the Proof Wiki\n*[https://www.cut-the-knot.org/pythagoras/JordanKober.shtml#book Jordan's and Kober's inequalities] at cut-the-knot.org\n*{{MathWorld|title=Jordan's inequality|urlname=JordansInequality}}\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Kallman–Rota inequality",
      "url": "https://en.wikipedia.org/wiki/Kallman%E2%80%93Rota_inequality",
      "text": "In mathematics, the '''Kallman–Rota inequality''', introduced by {{harvtxt|Kallman|Rota|1970}}, is a generalization of the [[Landau–Kolmogorov inequality]] to [[Banach spaces]].  It states that \nif ''A'' is the [[Lie algebra|infinitesimal generator]] of a one-parameter [[Contraction (operator theory)|contraction]] [[semigroup]] then\n\n: <math> \\|Af\\|^2 \\le 4\\|f\\|\\|A^2f\\|. </math>\n\n==References==\n*{{citation\n | last1 = Kallman | first1 = Robert R.\n | last2 = Rota | first2 = Gian-Carlo | author2-link = Gian-Carlo Rota\n | contribution = On the inequality <math>\\Vert f^{\\prime} \\Vert^{2}\\leqq4\\Vert f\\Vert\\cdot\\Vert f''\\Vert</math>\n | location = New York\n | mr = 0278059\n | pages = 187–192\n | publisher = Academic Press\n | title = Inequalities, II (Proc. Second Sympos., U.S. Air Force Acad., Colo., 1967)\n | year = 1970}}.\n\n{{DEFAULTSORT:Kallman-Rota inequality}}\n[[Category:Inequalities]]"
    },
    {
      "title": "Kantorovich inequality",
      "url": "https://en.wikipedia.org/wiki/Kantorovich_inequality",
      "text": "In [[mathematics]], the '''Kantorovich inequality''' is a particular case of the [[Cauchy–Schwarz inequality]], which is itself a generalization of the [[triangle inequality]].\n\nThe triangle inequality states that the length of two sides of any triangle, added together, will be equal to or greater than the length of the third side.  In simplest terms, the Kantorovich inequality translates the basic idea of the triangle inequality into the terms and notational conventions of [[linear programming]]. (See [[vector space]], [[inner product]], and [[normed vector space]] for other examples of how the basic ideas inherent in the triangle inequality—line segment and distance—can be generalized into a broader context.)\n\nMore formally, the Kantorovich inequality can be expressed this way:\n\n:Let\n\n:: <math>p_i \\geq 0,\\quad 0 < a \\leq x_i \\leq b\\text{ for }i=1, \\dots ,n.</math> \n \n:Let <math>A_n=\\{1,2,\\dots ,n\\}.</math> \n \n:Then \n \n:: <math>\n\\begin{align}\n& {} \\qquad \\left( \\sum_{i=1}^n p_ix_i \\right ) \\left (\\sum_{i=1}^n \\frac{p_i}{x_i} \\right) \\\\\n& \\leq \\frac{(a+b)^2}{4ab} \\left (\\sum_{i=1}^n p_i \\right )^2\n-\\frac{(a-b)^2}{4ab} \\cdot \\min \\left\\{ \\left (\\sum_{i \\in X}p_i-\\sum_{j \\in Y}p_j \\right )^2\\,:\\, {X \\cup Y=A_n},{X \\cap Y=\\varnothing} \\right\\}.\n\\end{align}\n</math>\n\nThe Kantorovich inequality is used in [[convergence analysis]]; it bounds the convergence rate of Cauchy's [[steepest descent]].\n\nEquivalents of the Kantorovich inequality have arisen in a number of different fields.  For instance, the [[Cauchy&ndash;Schwarz&ndash;Bunyakovsky inequality]] and the [[Wielandt inequality]] are equivalent to the Kantorovich inequality and all of these are, in turn, special cases of the [[Hölder inequality]].\n\nThe Kantorovich inequality is named after Soviet economist, mathematician, and [[Nobel Prize]] winner [[Leonid Kantorovich]], a pioneer in the field of [[linear programming]].\n\nThere is also Matrix version of the Kantrovich inequality due to Marshall and Olkin.\n\n==References==\n* {{MathWorld|urlname=KantorovichInequality|title=Kantorovich Inequality}}\n* {{PlanetMath|urlname=KantorovichInequality|title=Cauchy-Schwarz inequality}}\n* [http://carbon.cudenver.edu/~hgreenbe/glossary/index.php?page=K.html Mathematical Programming Glossary entry on \"Kantorovich inequality\"]\n* MARSHALL A. W. and OLKIN, I., Matrix  versions  of the  Cauchy and Kantorovieh inequatities. [[Aequationes Mathematicae]] 40 (1990), pp. 89–93.\n\n==External links==\n*[http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Kantorovich.html Biography of Leonid Vitalyevich Kantorovich]\n\n[[Category:Theorems in analysis]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Karamata's inequality",
      "url": "https://en.wikipedia.org/wiki/Karamata%27s_inequality",
      "text": "In [[mathematics]], '''Karamata's inequality''',<ref>{{Citation\n  | last = Kadelburg\n  | first = Zoran\n  | last2 = Đukić\n  | first2 = Dušan\n  | last3 = Lukić\n  | first3 = Milivoje\n  | last4 = Matić\n  | first4 = Ivan\n  | title = Inequalities of Karamata, Schur and Muirhead, and some applications\n  | journal = The Teaching of Mathematics\n  | issn = 1451-4966\n  | volume = 8\n  | issue = 1\n  | pages = 31–45\n  | year = 2005\n  | url = http://elib.mi.sanu.ac.rs/files/journals/tm/14/tm813.pdf\n}}</ref> named after [[Jovan Karamata]],<ref>{{Citation\n  | last = Karamata\n  | first = Jovan\n  | author-link = Jovan Karamata\n  | title = Sur une inégalité relative aux fonctions convexes\n  | journal = Publ. Math. Univ. Belgrade\n  | volume = 1\n  | pages = 145–148\n  | year = 1932\n  | language = French\n  | url = http://elib.mi.sanu.ac.rs/files/journals/publ/1/11.pdf\n  | zbl = 0005.20101\n}}</ref> also known as the '''majorization inequality''', is a theorem in [[elementary algebra]] for convex and concave real-valued functions, defined on an interval of the real line. It generalizes the discrete form of [[Jensen's inequality]], and generalizes in turn to the concept of [[Schur-convex function]]s.\n\n==Statement of the inequality==\nLet {{math|''I''}} be an [[interval (mathematics)|interval]] of the [[real line]] and let {{math|''f''}} denote a real-valued, [[convex function]] defined on {{math|''I''}}. If {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>''}} and {{math|''y''<sub>1</sub>, . . . , ''y<sub>n</sub>''}} are numbers in {{math|''I''}} such that {{math|(''x''<sub>1</sub>, . . . , ''x<sub>n</sub>'')}} [[majorization|majorizes]] {{math|(''y''<sub>1</sub>, . . . , ''y<sub>n</sub>'')}}, then\n\n{{NumBlk|:|<math>f(x_1)+\\cdots+f(x_n) \\ge f(y_1)+\\cdots+f(y_n).</math>|{{EquationRef|1}}}}\n\nHere majorization means that {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>''}} and {{math|''y''<sub>1</sub>, . . . , ''y<sub>n</sub>''}} satisfies\n\n{{NumBlk|:|<math>x_1\\ge x_2\\ge\\cdots\\ge x_n</math>&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;&nbsp;&nbsp;&nbsp;<math>y_1\\ge y_2\\ge\\cdots\\ge y_n,</math>|{{EquationRef|2}}}}\n\nand we have the inequalities\n\n{{NumBlk|:|<math>x_1+\\cdots+x_i\\ge y_1+\\cdots+y_i</math>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for all {{math|''i'' ∈ {1, . . . , ''n'' − 1}}}.|{{EquationRef|3}}}}\n\nand the equality\n\n{{NumBlk|:|<math>x_1+\\cdots+x_n=y_1+\\cdots+y_n</math>|{{EquationRef|4}}}}\n\nIf {{math|''f''}}&thinsp; is a [[strictly convex function]], then the inequality ({{EquationNote|1}}) holds with equality if and only if we have {{math|''x<sub>i</sub>'' {{=}} ''y<sub>i</sub>''}} for all {{math|''i'' ∈ {1, . . . , ''n''}}}.\n\n==Remarks==\n* If the convex function {{math|''f''}}&thinsp; is [[non-decreasing function|non-decreasing]], then the proof of ({{EquationNote|1}}) below and the discussion of equality in case of strict convexity shows that the equality ({{EquationNote|4}}) can be relaxed to\n{{NumBlk|::|<math>x_1+\\cdots+x_n\\ge y_1+\\cdots+y_n.</math>|{{EquationRef|5}}}}\n\n* The inequality ({{EquationNote|1}}) is reversed if {{math|''f''}}&thinsp; is [[concave function|concave]], since in this case the function {{math|−''f''}}&thinsp; is convex.\n\n==Example==\nThe finite form of [[Jensen's inequality]] is a special case of this result. Consider the real numbers {{math|''x''<sub>1</sub>, . . . , ''x<sub>n</sub>'' ∈ ''I''}} and let \n\n:<math>a := \\frac{x_1+x_2+\\cdots+x_n}{n}</math>\n\ndenote their [[arithmetic mean]]. Then {{math|(''x''<sub>1</sub>, . . . , ''x<sub>n</sub>'')}} majorizes the {{math|''n''}}-tuple {{math|(''a'', ''a'', . . . , ''a'')}}, since the arithmetic mean of the {{math|''i''}} largest numbers of {{math|(''x''<sub>1</sub>, . . . , ''x<sub>n</sub>'')}} is at least as large as the arithmetic mean {{math|''a''}} of all the {{math|''n''}} numbers, for every {{math|''i'' ∈ {1, . . . , ''n'' − 1}}}. By Karamata's inequality ({{EquationNote|1}}) for the convex function {{math|''f''}},\n\n:<math>f(x_1)+f(x_2)+ \\cdots +f(x_n) \\ge f(a)+f(a)+\\cdots+f(a) = nf(a).</math> \n\nDividing by {{math|''n''}} gives Jensen's inequality. The sign is reversed if {{math|''f''}}&thinsp; is concave.\n\n==Proof of the inequality==\nWe may assume that the numbers are in decreasing order as specified in ({{EquationNote|2}}).\n\nIf {{math|''x<sub>i</sub>'' {{=}} ''y<sub>i</sub>''}} for all {{math|''i'' ∈ {1, . . . , ''n''}}}, then the inequality ({{EquationNote|1}}) holds with equality, hence we may assume in the following that {{math|''x<sub>i</sub>'' ≠ ''y<sub>i</sub>''}} for at least one {{math|''i''}}.\n\nIf {{math|''x<sub>i</sub>'' {{=}} ''y<sub>i</sub>''}} for an {{math|''i'' ∈ {1, . . . , ''n'' − 1}}}, then the inequality ({{EquationNote|1}}) and the majorization properties ({{EquationNote|3}}) and ({{EquationNote|4}}) are not affected if we remove {{math|''x<sub>i</sub>''}} and {{math|''y<sub>i</sub>''}}. Hence we may assume that {{math|''x<sub>i</sub>'' ≠ ''y<sub>i</sub>''}} for all {{math|''i'' ∈ {1, . . . , ''n'' − 1}}}.\n\nIt is a [[convex function#Properties|property of convex functions]] that for two numbers {{math|''x'' ≠ ''y''}} in the interval {{math|''I''}} the [[slope]]\n\n:<math>\\frac{f(x)-f(y)}{x-y}</math>\n\nof the [[secant line]] through the points {{math|(''x'', ''f''&thinsp;(''x''))}} and {{math|(''y'', ''f''&thinsp;(''y''))}} of the [[graph of a function|graph]] of {{math|''f''}}&thinsp; is a [[monotonically non-decreasing]] function in {{math|''x''}} for {{math|''y''}} fixed (and [[List of Latin phrases: V#vice_versa|vice versa]]). This implies that\n\n{{NumBlk|:|<math>c_{i+1}:=\\frac{f(x_{i+1})-f(y_{i+1})}{x_{i+1}-y_{i+1}}\\le\\frac{f(x_i)-f(y_i)}{x_i-y_i}=:c_i</math>|{{EquationRef|6}}}}\n\nfor all {{math|''i'' ∈ {1, . . . , ''n'' − 1}}}. Define {{math|''A''<sub>0</sub> {{=}} ''B''<sub>0</sub> {{=}} 0}} and \n\n:<math>A_i=x_1+\\cdots+x_i,\\qquad B_i=y_1+\\cdots+y_i</math>\n\nfor all {{math|''i'' ∈ {1, . . . , ''n''}}}. By the majorization property ({{EquationNote|3}}), {{math|''A<sub>i</sub>'' ≥ ''B<sub>i</sub>''}} for all {{math|''i'' ∈ {1, . . . , ''n'' − 1}}} and by ({{EquationNote|4}}), {{math|''A<sub>n</sub>'' {{=}} ''B<sub>n</sub>''}}. Hence,\n\n{{NumBlk|:|<math>\\begin{align}\n\\sum_{i=1}^n \\bigl(f(x_i) - f(y_i)\\bigr)\n&=\\sum_{i=1}^n c_i (x_i - y_i)\\\\\n&=\\sum_{i=1}^n c_i \\bigl(\\underbrace{A_i - A_{i-1}}_{=\\,x_i}{} - (\\underbrace{B_i - B_{i-1}}_{=\\,y_i})\\bigr)\\\\\n&=\\sum_{i=1}^n c_i (A_i - B_i) - \\sum_{i=1}^n c_i (A_{i-1} - B_{i-1})\\\\\n&=c_n (\\underbrace{A_n-B_n}_{=\\,0}) + \\sum_{i=1}^{n-1}(\\underbrace{c_i - c_{i + 1}}_{\\ge\\,0})(\\underbrace{A_i - B_i}_{\\ge\\,0}) - c_1(\\underbrace{A_0-B_0}_{=\\,0})\\\\\n&\\ge0,\n\\end{align}</math>|{{EquationRef|7}}}}\n\nwhich proves Karamata's inequality ({{EquationNote|1}}).\n\nTo discuss the case of equality in ({{EquationNote|1}}), note that {{math|''x''<sub>1</sub> > ''y''<sub>1</sub>}} by ({{EquationNote|3}}) and our assumption {{math|''x<sub>i</sub>'' ≠ ''y<sub>i</sub>''}} for all {{math|''i'' ∈ {1, . . . , ''n'' − 1}}}. Let {{math|''i''}} be the smallest index such that {{math|(''x<sub>i</sub>'', ''y<sub>i</sub>'') ≠ (''x''<sub>''i''+1</sub>, ''y''<sub>''i''+1</sub>)}}, which exists due to ({{EquationNote|4}}). Then {{math|''A<sub>i</sub>'' > ''B<sub>i</sub>''}}. If {{math|''f''}}&thinsp; is strictly convex, then there is strict inequality in ({{EquationNote|6}}), meaning that {{math|''c''<sub>''i''+1</sub> < ''c<sub>i</sub>''}}. Hence there is a strictly positive term in the sum on the right hand side of ({{EquationNote|7}}) and equality in ({{EquationNote|1}}) cannot hold.\n\nIf the convex function {{math|''f''}}&thinsp; is non-decreasing, then {{math|''c<sub>n</sub>'' ≥ 0}}. The relaxed condition ({{EquationNote|5}}) means that {{math|''A<sub>n</sub>'' ≥ ''B<sub>n</sub>''}}, which is enough to conclude that {{math|''c<sub>n</sub>''(''A<sub>n</sub>''−''B<sub>n</sub>'') ≥ 0}} in the last step of ({{EquationNote|7}}).\n\nIf the function {{math|''f''}}&thinsp; is strictly convex and non-decreasing, then {{math|''c<sub>n</sub>'' > 0}}. It only remains to discuss the case {{math|''A<sub>n</sub>'' > ''B<sub>n</sub>''}}. However, then there is a strictly positive term on the right hand side of ({{EquationNote|7}}) and equality in ({{EquationNote|1}}) cannot hold.\n\n==References==\n{{reflist}}\n\n==External links==\nAn explanation of Karamata's inequality and majorization theory can be found [http://www.artofproblemsolving.com/Forum/viewtopic.php?highlight=majorization+karamata&t=14975 here].\n\n[[Category:Inequalities]]\n[[Category:Convex analysis]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Khabibullin's conjecture on integral inequalities",
      "url": "https://en.wikipedia.org/wiki/Khabibullin%27s_conjecture_on_integral_inequalities",
      "text": "{{cleanup|date=May 2010}}\nIn mathematics, '''Khabibullin's conjecture''', named after [[B. N. Khabibullin]], is related to [[Raymond Paley|Paley]]'s problem<ref name=hab_01>{{cite journal |author=Khabibullin B.N. |title=Paley problem for [[plurisubharmonic function]]s of finite lower order |journal=Sbornik: Mathematics|year=1999 |volume=190 |issue=2 |pages=309&ndash;321}}</ref> for plurisubharmonic functions and to various [[extremal problem]]s in the theory of [[entire function]]s of several variables.\n\n== The first statement in terms of logarithmically convex functions ==\n'''Khabibullin's conjecture''' (version 1, 1992). ''Let <math>\\displaystyle S</math> be a non-negative [[increasing function]] on the half-line <math>[0,+\\infty)</math> such that <math>\\displaystyle S(0)=0</math>. Assume that <math>\\displaystyle S(e^x)</math> is a convex function of <math>x\\in[-\\infty,+\\infty)</math>. Let <math>\\lambda\\geq 1/2</math>, <math>n\\geq 2</math>, and <math>n\\in\\mathbb N</math>. If'' \n{{NumBlk|:|<math>\n\\int^1_0 S(tx)\\,(1-x^2)^{n-2}\\,x\\,dx\\leq t^\\lambda\\text{ for all }t\\in[0,+\\infty),</math>|{{EquationRef|1}}}}\n\n''then''\n{{NumBlk|:|<math>\n\\int^{+\\infty}_0 S(t)\\,\\frac{t^{2\\lambda-1}}{(1+t^{2\\lambda})^2}\\,dt\\leq \\frac{\\pi\\,(n-1)}{2\\lambda}\\prod_{k=1}^{n-1} \\Bigl(1+\\frac{\\lambda}{2k}\\Bigr).</math>|{{EquationRef|2}}}}\n\nThis statement of the Khabibullin's conjecture completes his survey.<ref name=hab_02>{{cite journal |author=Khabibullin BN |title=The representation of a meromorphic function as the quotient of entire functions and Paley problem in <math>\\displaystyle\\mathbb C^n</math>: a survey of some results |journal=Mat. Fizika, analiz, geometria |year=2002 |volume=9 |issue=2 |pages=146&ndash;167 |arxiv=math.CV/0502433 }}</ref>\n\n== Relation to Euler's Beta function ==\n\nNote that the product in the right hand side of the inequality ({{EquationNote|2}}) is related to the Euler's [[Beta function]] <math>\\Beta</math>:\n:<math>\n\\frac{\\pi\\,(n-1)}{2\\lambda}\\prod_{k=1}^{n-1} \\Bigl(1+\\frac{\\lambda}{2k}\\Bigr)=\\frac{\\pi\\,(n-1)}{\\lambda^2}\\cdot\\frac{1}{\\Beta(\\lambda/2,n)}\n</math>\n\n== Discussion ==\n\nFor each fixed <math>\\lambda\\geq 1/2</math> the function\n:<math>\nS(t)=2(n-1)\\prod_{k=1}^{n-1} \\Bigl(1+\\frac{\\lambda}{2k}\\Bigr)\n\\, t^{\\lambda},\n</math>\n\nturns the inequalities ({{EquationNote|1}}) and ({{EquationNote|2}}) to equalities.\n\nThe Khabibullin's conjecture is valid for <math>\\lambda\\leq 1</math> without the assumption of convexity of <math>S(e^x)</math>. Meanwhile, one can show that this conjecture is not valid without some convexity conditions for <math>S</math>. In 2010, [[R. A. Sharipov]] showed that the conjecture fails in the case <math>n=2</math> and for <math>\\lambda=2</math>.<ref name=hab_03>{{cite journal |author=Sharipov, R. A. |title=A Counterexample to Khabibullin's Conjecture for Integral Inequalities |journal=Ufa Mathematical Journal  |year=2010 |volume=2 |issue=4 |pages=99&ndash;107 |arxiv=1008.2738|bibcode=2010arXiv1008.2738S }}</ref>\n\n== The second statement in terms of increasing functions ==\n'''Khabibullin's conjecture''' (version 2). ''Let <math>\\displaystyle h</math> be a non-negative increasing function on the half-line <math>[0,+\\infty)</math> and <math>\\alpha>1/2</math>. If''\n\n:<math>\n \\int_0^1 \\frac{h(tx)}{x} \\,(1-x)^{n-1}\\,dx \\leq t^\\alpha\\text{ for all }t\\in[0,+\\infty),</math>\n\n''then''\n:<math>\n\\int_0^{+\\infty}\\frac{h(t)}{t}\\,\\frac{dt}{1+t^{2\\alpha}}\\leq\n\\frac{\\pi}{2} \\prod_{k=1}^{n-1} \\Bigl(1+\\frac{\\alpha}{k}\\Bigr)=\n\\frac{\\pi}{2\\alpha} \\cdot \\frac{1}{\\mathrm B (\\alpha, n)}.\n</math>\n\n== The third statement in terms of non-negative functions ==\n'''Khabibullin's conjecture''' (version 3). ''Let <math>\\displaystyle q</math> be a non-negative continuous function on the half-line <math>[0,+\\infty)</math> and <math>\\alpha>1/2</math>. If'' \n:<math>\n\\int_0^1 \\Bigl(\\,\\int_x^1 (1-y)^{n-1} \\frac{dy}{y}\\Bigr)q(tx)\\,dx\n\\leq t^{\\alpha-1}\\text{ for all }t\\in[0,+\\infty),</math>\n\n''then''\n:<math>\n\\int_0^{+\\infty} q(t)\\log \\Bigl(1+\\frac1{t^{2\\alpha}}\\Bigr)\\,dt\\leq\n\\pi \\alpha \\prod_{k=1}^{n-1} \\Bigl(1+\\frac{\\alpha}{k}\\Bigr)=\n \\frac{\\pi}{\\mathrm B (\\alpha, n)}.\n</math>\n\n== References ==\n<references />\n\n[[Category:Conjectures]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Korn's inequality",
      "url": "https://en.wikipedia.org/wiki/Korn%27s_inequality",
      "text": "In [[mathematical analysis]], '''Korn's inequality''' is an inequality concerning the [[gradient]] of a [[vector field]] that generalizes the following classical theorem: if the gradient of a vector field is [[skew-symmetric matrix|skew-symmetric]] at every point, then the gradient must be equal to a constant skew-symmetric matrix.  Korn's theorem is a quantitative version of this statement, which intuitively says that if the gradient of a vector field is on average not far from the space of skew-symmetric matrices, then the gradient must not be far from a ''particular'' skew-symmetric matrix.  The statement that Korn's inequality generalizes thus arises as a special case of [[rigidity (mathematics)|rigidity]].\n\nIn (linear) [[elasticity theory]], the symmetric part of the gradient is a measure of the [[deformation (mechanics)|strain]] that an elastic body experiences when it is deformed by a given vector-valued function.  The inequality is therefore an important tool as an [[a priori estimate]] in linear elasticity theory.\n\n==Statement of the inequality==\n\nLet {{math|Ω}} be an [[open set|open]], [[connected space|connected]] domain in {{math|''n''}}-[[dimension]]al [[Euclidean space]] {{math|'''R'''<sup>''n''</sup>}}, {{math|''n''&nbsp;≥&nbsp;2}}.  Let {{math|''H''<sup>1</sup>(Ω)}} be the [[Sobolev space]] of all [[vector field]]s {{math|''v''&nbsp;<nowiki>=</nowiki>&nbsp;(''v''<sup>1</sup>,&nbsp;...,&nbsp;''v''<sup>''n''</sup>)}} on {{math|Ω}} that, along with their (first) weak derivatives, lie in the [[Lp space|Lebesgue space]] {{math|''L''<sup>2</sup>(Ω)}}.  Denoting the [[partial derivative]] with respect to the ''i''<sup>th</sup> component by {{math|∂<sub>''i''</sub>}}, the [[norm (mathematics)|norm]] in {{math|''H''<sup>1</sup>(Ω)}} is given by\n\n:<math>\\| v \\|_{H^{1} (\\Omega)} := \\left( \\int_{\\Omega} \\sum_{i = 1}^{n} | v^{i} (x) |^{2} \\, \\mathrm{d} x+\\int_{\\Omega} \\sum_{i, j = 1}^{n} | \\partial_{j} v^{i} (x) |^{2} \\, \\mathrm{d} x \\right)^{1/2}.</math>\n\nThen there is a constant {{math|''C''&nbsp;≥&nbsp;0}}, known as the '''Korn constant''' of {{math|Ω}}, such that, for all {{math|''v''&nbsp;∈&nbsp;''H''<sup>1</sup>(Ω)}},\n\n{{NumBlk|:|<math>\\| v \\|_{H^{1} (\\Omega)}^{2} \\leq C \\int_{\\Omega} \\sum_{i, j = 1}^{n} \\left( | v^{i} (x) |^{2} + | (e_{ij} v) (x) |^{2} \\right) \\, \\mathrm{d} x</math>|{{EquationRef|1}}}}\n\nwhere {{math|''e''}} denotes the symmetrized gradient given by\n\n:<math>e_{ij} v = \\frac1{2} ( \\partial_{i} v^{j} + \\partial_{j} v^{i} ).</math>\n\nInequality {{EquationNote|1|(1)}} is known as '''Korn's inequality'''.\n\n==See also==\n\n*[[Linear elasticity]]\n*[[Hardy inequality]]\n*[[Poincaré inequality]]\n\n==References==\n\n*{{Citation\n | last = Cioranescu\n | first = Doina\n | author-link = \n | last2 = Oleinik\n | first2 = Olga Arsenievna\n | author2-link =Olga Oleinik\n | last3 = Tronel\n | first3 = Gérard\n | author3-link =\n | title = On Korn's inequalities for frame type structures and junctions\n | journal = [[Comptes rendus hebdomadaires des séances de l'Académie des Sciences]]\n | series = Série I: Mathématiques\n | volume = 309\n | issue =9\n | pages =591–596\n | date =1989\n | url =http://gallica.bnf.fr/ark:/12148/bpt6k6216350r/f603.image\n | mr =1053284\n | zbl =0937.35502\n}}.\n* {{citation\n| last = Horgan\n| first = Cornelius O.\n| title = Korn's inequalities and their applications in continuum mechanics\n| journal = [[SIAM Review]]\n| volume = 37\n| year = 1995\n| pages = 491–511\n| issn = 0036-1445\n| doi = 10.1137/1037123\n| issue = 4\n| mr =1368384\n| zbl =0840.73010\n}}.\n*{{Citation\n | last = Oleinik\n | first = Olga Arsenievna\n | author-link =Olga Oleinik\n | last2 = Kondratiev\n | first2 = Vladimir Alexandrovitch\n | author2-link =\n | title = On Korn's inequalities\n | journal = [[Comptes rendus hebdomadaires des séances de l'Académie des Sciences]]\n | series = Série I: Mathématiques\n | volume = 308\n | issue =16\n | pages =483–487\n | date =1989\n | url =http://gallica.bnf.fr/ark:/12148/bpt6k6236782n/f497.image\n | mr =0995908\n | zbl =0698.35067\n}}.\n*{{Citation\n| last =Oleinik\n| first =Olga A.\n| author-link =Olga Oleinik\n| editor1-last = Amaldi\n| editor1-first = E.\n| editor1-link = Edoardo Amaldi\n| editor2-last = Amerio\n| editor2-first = L. \n| editor2-link = Luigi Amerio \n| editor3-last =Fichera\n| editor3-first =G.\n| editor3-link =Gaetano Fichera\n| editor4-last =Gregory\n| editor4-first =T.\n| editor4-link =\n| editor5-last =Grioli\n| editor5-first =G.\n| editor5-link =Giuseppe Grioli\n| editor6-last =Martinelli\n| editor6-first =E.\n| editor6-link =Enzo Martinelli\n| editor7-last =Montalenti\n| editor7-first =G.\n| editor8-last =Pignedoli\n| editor8-first =A.\n| editor8-link =Antonio Pignedoli\n| editor9-last =Salvini\n| editor9-first =Giorgio\n| editor9-link =Giorgio Salvini\n| editor10-last =Scorza Dragoni\n| editor10-first =Giuseppe\n| editor10-link =Giuseppe Scorza Dragoni\n| contribution =Korn's Type inequalities and applications to elasticity\n| contribution-url = \n| title = Convegno internazionale in memoria di Vito Volterra (8–11 ottobre 1990)\n| url = http://www.lincei.it/pubblicazioni/catalogo/volume.php?rid=32862\n| language = Italian\n| series = Atti dei Convegni Lincei\n| volume = 92\n| year = 1992\n| pages = 183–209\n| place = Roma\n| publisher = [[Accademia Nazionale dei Lincei]]\n| doi = \n| issn = 0391-805X\n| mr =1783034\n| zbl =0972.35013\n}}.\n\n==External links==\n*{{SpringerEOM\n | title=Korn inequality\n | id=Korn_inequality&oldid=30665\n | last=Voitsekhovskii\n | first=M. I.\n | author-link=\n}}\n\n[[Category:Inequalities]]\n[[Category:Sobolev spaces]]\n[[Category:Solid mechanics]]"
    },
    {
      "title": "Kraft–McMillan inequality",
      "url": "https://en.wikipedia.org/wiki/Kraft%E2%80%93McMillan_inequality",
      "text": "In [[coding theory]], the '''Kraft–McMillan inequality''' gives a necessary and sufficient condition for the existence of a [[prefix code]]<ref name=\"EIT\" /> (in Leon G. Kraft's version) or a uniquely decodable code (in [[Brockway McMillan]]'s version) for a given set of [[codeword]] lengths. Its applications to prefix codes and trees often find use in [[computer science]] and [[information theory]].\n\nKraft's inequality was published in {{harvtxt|Kraft|1949}}. However, Kraft's paper discusses only prefix codes, and attributes the analysis leading to the inequality to [[Raymond Redheffer]]. The result was independently discovered in {{harvtxt|McMillan|1956}}. McMillan proves the result for the general case of uniquely decodable codes, and attributes the version for prefix codes to a spoken observation in 1955 by [[Joseph Leo Doob]].\n\n== Applications and intuitions ==\n\nKraft's inequality limits the lengths of codewords in a [[prefix code]]: if one takes an [[exponential function|exponential]] of the length of each valid codeword, the resulting set of values must look like a [[probability mass function]], that is, it must have total measure less than or equal to one. Kraft's inequality can be thought of in terms of a constrained budget to be spent on codewords, with shorter codewords being more expensive. Among the useful properties following from the inequality are the following statements:\n\n* If Kraft's inequality holds with strict inequality, the code has some [[Redundancy (information theory)|redundancy]].\n* If Kraft's inequality holds with equality, the code in question is a complete code. \n* If Kraft's inequality does not hold, the code is not [[Variable-length code#Uniquely decodable codes|uniquely decodable]].\n* For every uniquely decodable code, there exists a prefix code with the same length distribution.\n\n== Formal statement ==\nLet each source symbol from the alphabet\n:<math>S=\\{\\,s_1,s_2,\\ldots,s_n\\,\\}</math>\n\nbe encoded into a uniquely decodable code over an alphabet of size <math>r</math> with codeword lengths\n\n:<math>\\ell_1,\\ell_2,\\ldots,\\ell_n.</math>\n\nThen\n\n:<math>\\sum_{i=1}^{n} r^{-\\ell_i} \\leqslant 1.</math>\n\nConversely, for a given set of natural numbers <math>\\ell_1,\\ell_2,\\ldots,\\ell_n</math> satisfying the above inequality, there exists a uniquely decodable code over an alphabet of size <math>r</math> with those codeword lengths.\n\n== Example: binary trees ==\n\n[[Image:AVLtreef.svg|thumb|9, 14, 19, 67 and 76 are leaf nodes at depths of 3, 3, 3, 3 and 2, respectively.]]\n\nAny [[binary tree]] can be viewed as defining a prefix code for the [[leaf node|leaves]] of the tree. Kraft's inequality states that\n\n: <math> \\sum_{\\ell \\in \\text{leaves}} 2^{-\\text{depth}(\\ell)} \\leqslant 1. </math>\n\nHere the sum is taken over the leaves of the tree, i.e. the nodes without any children. The depth is the distance to the root node. In the tree to the right, this sum is\n\n:<math> \\frac{1}{4} + 4 \\left( \\frac{1}{8} \\right) = \\frac{3}{4} \\leqslant 1.</math>\n\n== Proof ==\n\n=== Proof for prefix codes ===\n[[Image:Kraft inequality example.png|upright=1.5|thumb|Example for binary tree. Red nodes represent a prefix tree. The method for calculating the number of descendant leaf nodes in the full tree is shown.]]\nFirst, let us show that the Kraft inequality holds whenever <math>S</math> is a prefix code.\n\nSuppose that <math>\\ell_1 \\leqslant \\ell_2 \\leqslant \\cdots \\leqslant \\ell_n </math>. Let <math>A</math> be the full <math>r</math>-ary tree of depth <math>\\ell_n</math> (thus, every node of <math>A</math> at level <math>< \\ell_n</math> has <math>r</math> children, while the nodes at level <math>\\ell_n</math> are leaves). Every word of length <math>\\ell \\leqslant \\ell_n</math> over an <math>r</math>-ary alphabet corresponds to a node in this tree at depth <math>\\ell</math>. The <math>i</math>th word in the [[prefix code]] corresponds to a node <math>v_i</math>; let <math>A_i</math> be the set of all leaf nodes (i.e. of nodes at depth <math>\\ell_n</math>) in the subtree of <math>A</math> rooted at <math>v_i</math>. That subtree being of height <math>\\ell_n-\\ell_i</math>, we have\n\n:<math>|A_i| = r^{\\ell_n-\\ell_i}.</math> \nSince the code is a prefix code, those subtrees cannot share any leaves, which means that\n\n:<math>A_i \\cap A_j = \\varnothing,\\quad i\\neq j.</math>\n\nThus, given that the total number of nodes at depth <math>\\ell_n</math> is <math>r^{\\ell_n}</math>, we have\n\n:<math> \\left|\\bigcup_{i=1}^n A_i\\right|= \\sum_{i=1}^n |A_i| = \\sum_{i=1}^n r^{\\ell_n-\\ell_i} \\leqslant r^{\\ell_n}</math>\n\nfrom which the result follows.\n\nConversely, given any ordered sequence of <math>n</math> natural numbers,\n\n:<math>\\ell_1 \\leqslant \\ell_2 \\leqslant \\cdots \\leqslant \\ell_n</math>\n\nsatisfying the Kraft inequality, one can construct a prefix code with codeword lengths equal to each <math>\\ell_i</math> by choosing a word of length <math>\\ell_i</math> arbitrarily, then ruling out all words of greater length that have it as a prefix. There again, we shall interpret this in terms of leaf nodes of an <math>r</math>-ary tree of depth <math>\\ell_n</math>.  First choose any node from the full tree at depth <math>\\ell_1</math>; it corresponds to the first word of our new code. Since we are building a prefix code, all the descendants of this node (i.e., all words that have this first word as a prefix) become unsuitable for inclusion in the code. We consider the descendants at depth <math>\\ell_n</math> (i.e., the leaf nodes among the descendants); there are  <math>r^{\\ell_n-\\ell_1}</math> such descendant nodes that are removed from consideration. The next iteration picks a (surviving) node at depth <math>\\ell_2</math> and removes <math>r^{\\ell_n-\\ell_2}</math> further leaf nodes, and so on.  After <math>n</math> iterations, we have removed a total of\n\n:<math>\\sum_{i=1}^n r^{\\ell_n-\\ell_i}</math>\n\nnodes. The question is whether we need to remove more leaf nodes than we actually have available &mdash; <math> r^{\\ell_n}</math> in all &mdash; in the process of building the code. Since the Kraft inequality holds, we have indeed\n\n:<math> \\sum_{i=1}^n r^{\\ell_n-\\ell_i} \\leqslant r^{\\ell_n}</math>\n\nand thus a prefix code can be built. Note that as the choice of nodes at each step is largely arbitrary, many different suitable prefix codes can be built, in general.\n\n=== Proof of the general case ===\nNow we will prove that the Kraft inequality holds whenever <math>S</math> is a uniquely decodable code. (The converse needs not be proven, since we have already proven it for prefix codes, which is a stronger claim.)\n\nDenote <math>C = \\sum_{i=1}^n r^{-l_i}</math>. The idea of the proof is to get an upper bound on <math>C^m</math> for <math>m \\in \\mathbb{N}</math> and show that it can only hold for all <math>m</math> if <math>C \\leq 1</math>. Rewrite <math>C^m</math> as\n\n:<math>\n\\begin{align}\nC^m & = \\left( \\sum_{i=1}^n r^{-l_i} \\right)^m \\\\\n& = \\sum_{i_1=1}^n \\sum_{i_2=1}^n \\cdots \\sum_{i_m=1}^n r^{-\\left(l_{i_1} + l_{i_2} + \\cdots + l_{i_m} \\right)} \\\\\n\\end{align}\n</math>\n\nConsider all [[Cartesian product#Cartesian power|''m''-powers]] <math>S^m</math>, in the form of words <math>s_{i_1}s_{i_2}\\dots s_{i_m}</math>, where <math>i_1, i_2, \\dots, i_m</math> are indices between 1 and <math>n</math>. Note that, since ''S'' was assumed to uniquely decodable,\n<math>s_{i_1}s_{i_2}\\dots s_{i_m}=s_{j_1}s_{j_2}\\dots s_{j_m}</math> implies <math>i_1=j_1, i_2=j_2, \\dots, i_m=j_m</math>. This means that each summand corresponds to exactly one word in <math>S^m</math>. This allows us to rewrite the equation to\n\n:<math>\nC^m = \\sum_{\\ell=1}^{m \\cdot \\ell_{max}} q_\\ell \\, r^{-\\ell}\n</math>\n\nwhere <math>q_\\ell</math> is the number of codewords in <math>S^m</math> of length <math>\\ell</math> and <math>\\ell_{max}</math> is the length of the longest codeword in <math>S</math>. For an <math>r</math>-letter alphabet there are only <math>r^\\ell</math> possible words of length <math>\\ell</math>, so <math>q_\\ell \\leq r^\\ell</math>. Using this, we upper bound <math>C^m</math>:\n\n:<math>\n\\begin{align}\nC^m & = \\sum_{\\ell=1}^{m \\cdot \\ell_{max}} q_\\ell \\, r^{-\\ell} \\\\\n& \\leq \\sum_{\\ell=1}^{m \\cdot \\ell_{max}} r^\\ell \\, r^{-\\ell} = m \\cdot \\ell_{max}\n\\end{align}\n</math>\n\nTaking the <math>m</math>-th root, we get\n:<math>\nC = \\sum_{i=1}^n r^{-l_i} \\leq \\left( m \\cdot \\ell_{max} \\right)^{\\frac{1}{m}}\n</math>\n\nThis bound holds for any <math>m \\in \\mathbb{N}</math>. The right side is 1 asymptotically, so <math>\\sum_{i=1}^n r^{-l_i} \\leq 1</math> must hold (otherwise the inequality would be broken for a large enough <math>m</math>).\n\n=== Alternative construction for the converse ===\nGiven a sequence of <math>n</math> natural numbers,\n\n:<math>\\ell_1 \\leqslant \\ell_2 \\leqslant \\cdots \\leqslant \\ell_n</math>\n\nsatisfying the Kraft inequality, we can construct a prefix code as follows.  Define the ''i''<sup>th</sup> codeword, ''C''<sub>i</sub>, to be the first <math>\\ell_i</math> digits after the [[radix point]] (e.g. decimal point) in the base ''r'' representation of\n\n:<math>\\sum_{j = 1}^{i - 1} r^{-\\ell_j}.</math>\n\nNote that by Kraft's inequality, this sum is never more than 1.  Hence the codewords capture the entire value of the sum.  Therefore, for ''j'' > ''i'', the first <math>\\ell_i</math> digits of ''C''<sub>''j''</sub> form a larger number than ''C''<sub>''i''</sub>, so the code is prefix free.\n\n== Notes ==\n{{Reflist|refs=\n<ref name=\"EIT\">{{citation\n | last1 = Cover | first1 = Thomas M.\n | last2 = Thomas | first2 = Joy A.\n | title = Elements of Information Theory\n | edition = 2nd\n | year = 2006 \n | publisher = John Wiley & Sons, Inc\n | isbn = 978-0-471-24195-9\n | pages = 108–109\n | doi = 10.1002/047174882X.ch5\n | chapter = Data Compression\n }}</ref>\n}}\n\n== References ==\n* {{citation\n | last = Kraft | first = Leon G.\n | title = A device for quantizing, grouping, and coding amplitude modulated pulses\n | publisher = MS Thesis, Electrical Engineering Department, [[Massachusetts Institute of Technology]]\n | location = Cambridge, MA\n | year = 1949\n | hdl = 1721.1/12390\n }}.\n\n* {{citation\n | last = McMillan | first = Brockway\n | title = Two inequalities implied by unique decipherability\n | journal = IEEE Trans. Inf. Theory\n | volume = 2 | issue = 4 | year = 1956 | pages = 115–116\n | url = http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1056818\n | doi = 10.1109/TIT.1956.1056818}}.\n\n==See also==\n*[[Chaitin's constant]]\n*[[Canonical Huffman code]]\n\n{{DEFAULTSORT:Kraft-McMillan inequality}}\n[[Category:Coding theory]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Ky Fan inequality",
      "url": "https://en.wikipedia.org/wiki/Ky_Fan_inequality",
      "text": "In [[mathematics]], there are two different results that share the common name of the '''Ky Fan inequality'''.  One is an [[inequality (mathematics)|inequality]] involving the [[geometric mean]] and [[arithmetic mean]] of two sets of [[real number]]s of the [[unit interval]]. The result was published on page&nbsp;5 of the book ''Inequalities'' by [[Edwin F. Beckenbach]] and [[Richard E. Bellman]] (1961), who refer to an unpublished result of [[Ky Fan]]. They mention the result in connection with the [[inequality of arithmetic and geometric means]] and [[Augustin Louis Cauchy]]'s proof of this inequality by forward-backward-induction; a method which can also be used to prove the Ky Fan inequality.\n\nThis Ky Fan inequality is a special case of [[Levinson's inequality]] and also the starting point for several generalizations and refinements; some of them are given in the references below.\n\nThe second Ky Fan inequality is used in [[game theory]] to investigate the existence of an equilibrium.\n\n==Statement of the classical version==\nIf ''x<sub>i</sub>'' with 0&nbsp;≤&nbsp;''x<sub>i</sub>''&nbsp;≤&nbsp;<math> \\frac{1}{2} </math> for ''i'' = 1, ..., ''n'' are real numbers, then\n\n:<math> \\frac{ \\bigl(\\prod_{i=1}^n x_i\\bigr)^{1/n} }\n             { \\bigl(\\prod_{i=1}^n (1-x_i)\\bigr)^{1/n} } \n    \\le \n        \\frac{ \\frac1n \\sum_{i=1}^n x_i }\n             { \\frac1n \\sum_{i=1}^n (1-x_i) }\n</math>\n\nwith equality if and only if ''x''<sub>1</sub> = ''x''<sub>2</sub> = .&nbsp;.&nbsp;. = ''x<sub>n</sub>''.\n\n==Remark==\nLet\n:<math>A_n:=\\frac1n\\sum_{i=1}^n x_i,\\qquad G_n=\\biggl(\\prod_{i=1}^n x_i\\biggr)^{1/n}</math>\n\ndenote the arithmetic and geometric mean, respectively, of ''x''<sub>1</sub>, .&nbsp;.&nbsp;., ''x<sub>n</sub>'', and let\n\n:<math>A_n':=\\frac1n\\sum_{i=1}^n (1-x_i),\\qquad G_n'=\\biggl(\\prod_{i=1}^n (1-x_i)\\biggr)^{1/n}</math>\n\ndenote the arithmetic and geometric mean, respectively, of 1&nbsp;&minus;&nbsp;''x''<sub>1</sub>, .&nbsp;.&nbsp;., 1&nbsp;&minus;&nbsp;''x<sub>n</sub>''. Then the Ky Fan inequality can be written as\n\n:<math>\\frac{G_n}{G_n'}\\le\\frac{A_n}{A_n'},</math>\n\nwhich shows the similarity to the [[inequality of arithmetic and geometric means]] given by ''G<sub>n</sub>''&nbsp;≤&nbsp;''A<sub>n</sub>''.\n\n==Generalization with weights==\nIf ''x<sub>i</sub>''&nbsp;∈&nbsp;[0,½] and ''γ<sub>i</sub>''&nbsp;∈&nbsp;[0,1] for ''i''&nbsp;= 1, .&nbsp;.&nbsp;., ''n'' are real numbers satisfying ''γ''<sub>1</sub> + .&nbsp;.&nbsp;. + ''γ<sub>n</sub>'' = 1, then\n\n:<math> \\frac{ \\prod_{i=1}^n x_i^{\\gamma_i} }\n             { \\prod_{i=1}^n (1-x_i)^{\\gamma_i} } \n    \\le \n        \\frac{ \\sum_{i=1}^n \\gamma_i x_i }\n             { \\sum_{i=1}^n \\gamma_i (1-x_i) }\n</math>\n\nwith the convention 0<sup>0</sup> := 0. Equality holds if and only if either\n*''γ<sub>i</sub>x<sub>i</sub>'' = 0 for all ''i''&nbsp;= 1, .&nbsp;.&nbsp;., ''n'' or\n*all ''x<sub>i</sub>''&nbsp;>&nbsp;0 and there exists ''x''&nbsp;∈&nbsp;(0,½] such that ''x''&nbsp;=&nbsp;''x<sub>i</sub>'' for all ''i''&nbsp;= 1, .&nbsp;.&nbsp;., ''n'' with ''γ<sub>i</sub>''&nbsp;>&nbsp;0.\n\nThe classical version corresponds to ''γ<sub>i</sub>'' = 1/''n'' for all ''i''&nbsp;= 1, .&nbsp;.&nbsp;., ''n''.\n\n==Proof of the generalization==\n'''Idea:''' Apply [[Jensen's inequality]] to the strictly concave function\n\n:<math>f(x):= \\ln x-\\ln(1-x) = \\ln\\frac x{1-x},\\qquad x\\in(0,\\tfrac12].</math>\n\n'''Detailed proof:''' (a) If at least one ''x<sub>i</sub>'' is zero, then the left-hand side of the Ky Fan inequality is zero and the inequality is proved. Equality holds if and only if the right-hand side is also zero, which is the case when ''γ<sub>i</sub>x<sub>i</sub>'' = 0 for all ''i''&nbsp;= 1, .&nbsp;.&nbsp;., ''n''.\n\n(b) Assume now that all ''x<sub>i</sub>'' > 0. If there is an ''i'' with ''γ<sub>i</sub>''&nbsp;=&nbsp;0, then the corresponding ''x<sub>i</sub>''&nbsp;>&nbsp;0 has no effect on either side of the inequality, hence the ''i''<sup>th</sup> term can be omitted. Therefore, we may assume that ''γ<sub>i</sub>''&nbsp;>&nbsp;0 for all ''i'' in the following. If ''x''<sub>1</sub> = ''x''<sub>2</sub> = .&nbsp;.&nbsp;. = ''x<sub>n</sub>'', then equality holds. It remains to show strict inequality if not all ''x<sub>i</sub>'' are equal.\n\nThe function ''f'' is strictly concave on (0,½], because we have for its second derivative\n\n:<math>f''(x)=-\\frac1{x^2}+\\frac1{(1-x)^2}<0,\\qquad x\\in(0,\\tfrac12).</math>\n\nUsing the [[functional equation]] for the [[natural logarithm]] and Jensen's inequality for the strictly concave ''f'', we obtain that\n\n:<math>\n\\begin{align}\n\\ln\\frac{ \\prod_{i=1}^n x_i^{\\gamma_i}}\n        { \\prod_{i=1}^n (1-x_i)^{\\gamma_i} }\n&=\\ln\\prod_{i=1}^n\\Bigl(\\frac{x_i}{1-x_i}\\Bigr)^{\\gamma_i}\\\\\n&=\\sum_{i=1}^n \\gamma_i f(x_i)\\\\\n&<f\\biggl(\\sum_{i=1}^n \\gamma_i x_i\\biggr)\\\\\n&=\\ln\\frac{ \\sum_{i=1}^n \\gamma_i x_i }\n          { \\sum_{i=1}^n \\gamma_i (1-x_i) },\n\\end{align}\n</math>\n\nwhere we used in the last step that the ''γ<sub>i</sub>'' sum to one. Taking the exponential of both sides gives the Ky Fan inequality.\n\n==The Ky Fan inequality in game theory==\n\nA second inequality is also called the Ky Fan Inequality, because of a 1972 paper, \"A minimax inequality and its applications\". This second inequality is equivalent to the [[Brouwer Fixed Point Theorem]], but is often more convenient.  Let ''S'' be a [[compact space|compact]] [[convex set|convex]] subset of a finite-dimensional [[vector space]] ''V'', and let <math>f(x,y)</math> be a function from <math>S \\times S</math> to the [[real numbers]] that is [[lower semicontinuous]] in ''x'', [[concave function|concave]] in ''y'' and has <math>f(z,z) \\le 0</math> for all ''z'' in ''S''. Then there exists <math>x^* \\in S</math> such that  <math>f( x^*, y ) \\le 0 </math> for all <math>y \\in S</math>.  This Ky Fan Inequality is used to establish the existence of equilibria in various games studied in economics.\n\n==References==\n*{{cite journal\n |last    = Alzer\n |first   = Horst\n |title   = Verschärfung einer Ungleichung von Ky Fan\n |journal = [[Aequationes Mathematicae]]\n |volume  = 36\n |issue   = 2–3\n |pages   = 246–250\n |year    = 1988\n |url     = http://dz-srv1.sub.uni-goettingen.de/sub/digbib/loader?did=D171447\n |mr      = 972289\n |doi     = 10.1007/BF01836094\n}}{{dead link|date=December 2017 |bot=InternetArchiveBot |fix-attempted=yes }}\n  \n*{{cite book\n  | last = Beckenbach\n  | first = Edwin Ford\n  |author2=Bellman, Richard Ernest |authorlink2=Richard E. Bellman \n  | title = Inequalities\n  | publisher = Springer-Verlag\n  | year = 1961\n  | location = Berlin–Göttingen–Heidelberg\n  |mr=158038\n  | isbn = 978-3-7643-0972-5\n  }}\n\n*{{cite journal\n  | last = Moslehian\n  | first = M. S.\n  | title = Ky Fan inequalities\n  | journal = Linear and Multilinear Algebra\n  | volume = to appear\n  | arxiv = 1108.1467| bibcode = 2011arXiv1108.1467S\n  | year = 2011\n  }}\n\n*{{cite journal\n  | last = Neuman\n  | first = Edward\n  |author2=Sándor, József\n  | title = On the Ky Fan inequality and related inequalities I\n  | journal = Mathematical Inequalities & Applications\n  | volume = 5\n  | issue = 1\n  | pages = 49–56\n  | year = 2002\n  | url = http://www.ele-math.com/files/mia/05-1/full/mia-05-06.pdf\n  |mr=1880271\n  | doi = 10.7153/mia-05-06\n  }}\n\n*{{cite journal\n  | last = Neuman\n  | first = Edward\n  |author2=Sándor, József\n  | title = On the Ky Fan inequality and related inequalities II\n  | journal = Bulletin of the Australian Mathematical Society\n  | volume = 72\n  | issue = 1\n  | pages = 87–107\n  |date=August 2005\n  | url = http://www.austms.org.au/Publ/Bulletin/V72P1/pdf/721-5068-NeSa.pdf\n  |mr=2162296\n  | doi = 10.1017/S0004972700034894\n  }}\n \n*{{cite journal\n  | last = Sándor\n  | first = József\n  |author2=Trif, Tiberiu\n   | title = A new refinement of the Ky Fan inequality\n  | journal = Mathematical Inequalities & Applications\n  | volume = 2\n  | issue = 4\n  | pages = 529–533\n  | year = 1999\n  | url = http://www.ele-math.com/files/mia/02-4/full/mia-02-43.pdf\n  |mr=1717045\n  | doi = 10.7153/mia-02-43\n  }}\n\n==External links==\n*{{Mathgenealogy|name = Ky Fan|id = 15631}}\n\n[[Category:Inequalities]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Ladyzhenskaya's inequality",
      "url": "https://en.wikipedia.org/wiki/Ladyzhenskaya%27s_inequality",
      "text": "In [[mathematics]], '''Ladyzhenskaya's inequality''' is any of a number of related functional inequalities named after the [[Soviet people|Soviet]] [[Russians|Russian]] [[mathematician]] [[Olga Aleksandrovna Ladyzhenskaya]].  The original such inequality, for functions of two real variables, was introduced by Ladyzhenskaya in 1958 to prove the existence and uniqueness of long-time solutions to the [[Navier–Stokes equations]] in two spatial dimensions (for smooth enough initial data).  There is an analogous inequality for functions of three real variables, but the exponents are slightly different;  much of the difficulty in establishing existence and uniqueness of solutions to the three-dimensional Navier–Stokes equations stems from these different exponents.  Ladyzhenskaya's inequality is one member of a broad class of inequalities known as [[interpolation inequality|interpolation inequalities]].\n\nLet &Omega; be a [[Lipschitz domain]] in '''R'''<sup>''n''</sup> for ''n''&nbsp;=&nbsp;2 or 3, and let ''u'':&nbsp;&Omega;&nbsp;&rarr;&nbsp;'''R''' be a [[weak derivative|weakly differentiable]] function that vanishes on the boundary of &Omega; in the sense of [[trace operator|trace]] (that is, ''u'' is a limit in the [[Sobolev space]] ''H''<sup>1</sup>(&Omega;) of a sequence of [[smooth function]]s that are [[compactly supported]] in &Omega;).  Then there exists a constant ''C'' depending only on &Omega; such that, in the case ''n''&nbsp;=&nbsp;2,\n\n:<math>\n\\| u \\|_{L^{4}} \\leq C \\| u \\|_{L^{2}}^{1/2} \\| \\nabla u \\|_{L^{2}}^{1/2},\n</math>\n\nand, in the case ''n''&nbsp;=&nbsp;3,\n\n:<math>\n\\| u \\|_{L^4} \\leq C \\| u \\|_{L^2}^{1/4} \\| \\nabla u \\|_{L^2}^{3/4}.\n</math>\n\n==Generalizations==\n\n* Both the two- and three-dimensional versions of Ladyzhenskaya's inequality are special cases of the [[Gagliardo–Nirenberg interpolation inequality]]\n\n::<math>\n\\| u \\|_{L^p} \\leq C \\| u \\|_{L^q}^\\alpha \\| u \\|_{H_0^s}^{1-\\alpha},\n</math>\n\n:which holds whenever\n\n::<math>\np > q \\geq 1, s > n ( \\tfrac{1}{2} - \\tfrac{1}{p} ), \\text{ and } \\tfrac{1}{p} = \\tfrac{\\alpha}{q} + (1 - \\alpha) ( \\tfrac{1}{2} - \\tfrac{s}{n} ).\n</math>\n\n:Ladyzhenskaya's inequalities are the special cases ''p''&nbsp;=&nbsp;4, ''q''&nbsp;=&nbsp;2, ''s''&nbsp;=&nbsp;1, and ''&alpha;''&nbsp;=&nbsp;&frac12; when ''n''&nbsp;=&nbsp;2 and ''&alpha;''&nbsp;=&nbsp;&frac14; when ''n''&nbsp;=&nbsp;3.\n\n* A simple modification of the argument used by Ladyzhenskaya in her 1958 paper (see e.g. Constantin &amp; Seregin 2010) yields the following inequality for ''u'':&nbsp;'''R'''<sup>2</sup>&nbsp;&rarr;&nbsp;'''R''', valid for all ''r''&nbsp;&ge;&nbsp;2:\n\n::<math>\n\\| u \\|_{L^{2r}} \\leq C r \\| u \\|_{L^r}^{1/2} \\| \\nabla u \\|_{L^2}^{1/2}.\n</math>\n\n* The usual Ladyzhenskaya inequality on '''R'''<sup>''n''</sup>, ''n''&nbsp;=&nbsp;2 or 3, can be generalized (see McCormick &amp; al. 2013) to use the [[Lp space#Weak Lp|weak ''L''<sup>2</sup> “norm”]] of ''u'' in place of the usual ''L''<sup>2</sup> norm:\n\n::<math>\n\\| u \\|_{L^{4}} \\leq \n\\begin{cases}\nC \\| u \\|_{L^{2,\\infty}}^{1/2} \\| \\nabla u \\|_{L^{2}}^{1/2}, & n = 2, \\\\\nC \\| u \\|_{L^{2,\\infty}}^{1/4} \\| \\nabla u \\|_{L^{2}}^{3/4}, & n = 3.\n\\end{cases}\n</math>\n\n==See also==\n\n* [[Agmon's inequality]]\n\n==References==\n\n* {{citation\n| last = Constantin\n| first = P.\n| last2 = Seregin\n| first2 = G.\n| chapter = Hölder continuity of solutions of 2D Navier–Stokes equations with singular forcing\n| title = Nonlinear partial differential equations and related topics\n| series = Amer. Math. Soc. Transl. Ser. 2\n| volume = 229\n| pages = 87–95\n| publisher = Amer. Math. Soc.\n| location = Providence, RI\n| year = 2010\n}}\n* {{cite journal\n| last = Ладыженская\n| first = О. А.\n| authorlink = Olga Ladyzhenskaya\n| title = Решение \"в целом\" краевой задачи для уравнений Навье – Стокса в случае двух пространственных переменных\n| journal = Доклады Академии наук СССР\n| volume = 123\n| issue = 3\n| year = 1958\n| pages = 427–429\n}} [{{cite journal\n| last = Ladyzhensakya\n| first = O. A.\n| authorlink = Olga Ladyzhenskaya\n| title = Solution in the large to the boundary-value problem for the Navier–Stokes equations in two space variables \n| journal = Soviet Physics Dokl.\n| volume = 123\n| issue = 3\n| year = 1958\n| pages = 1128–1131\n}}]\n* {{cite journal\n| last = McCormick\n| first = D. S.\n| last2 = Robinson\n| first2 = J. C.\n| last3 = Rodrigo\n| first3 = J. L.\n| title = Generalised Gagliardo&ndash;Nirenberg inequalities using weak Lebesgue spaces and BMO\n| journal = Milan J. Math.\n| volume = 81\n| issue = 2\n| pages = 265–289\n| year = 2013\n| doi = 10.1007/s00032-013-0202-6\n| arxiv = 1303.6351\n| citeseerx = 10.1.1.758.7957\n}}\n\n[[Category:Inequalities]]\n[[Category:Fluid dynamics]]\n[[Category:Sobolev spaces]]"
    },
    {
      "title": "Landau–Kolmogorov inequality",
      "url": "https://en.wikipedia.org/wiki/Landau%E2%80%93Kolmogorov_inequality",
      "text": "In [[mathematics]], the '''Landau&ndash;Kolmogorov inequality''', named after [[Edmund Landau]] and [[Andrey Kolmogorov]], is the following family of [[interpolation inequality|interpolation inequalities]] between different derivatives of a function ''f'' defined on a subset ''T'' of the real numbers:<ref>{{cite web|last=Weisstein|first=E.W.|title=Landau-Kolmogorov Constants|publisher= MathWorld--A Wolfram Web Resource|url=http://mathworld.wolfram.com/Landau-KolmogorovConstants.html}}</ref>\n\n: <math> \\|f^{(k)}\\|_{L_\\infty(T)} \\le C(n, k, T)  {\\|f\\|_{L_\\infty(T)}}^{1-k/n} {\\|f^{(n)}\\|_{L_\\infty(T)}}^{k/n} \\text{ for } 1\\le k < n.</math>\n\n==On the real line==\n\nFor ''k'' = 1, ''n'' = 2, ''T''='''R''' the inequality was first proved by Edmund Landau<ref>{{cite journal|first=E.|last= Landau|title=Ungleichungen für zweimal differenzierbare Funktionen|journal=Proc. London Math. Soc.|volume=13|year=1913|pages=43&ndash;49|doi=10.1112/plms/s2-13.1.43 |url= https://zenodo.org/record/1447772}}</ref> with the sharp constant ''C''(2, 1, '''R''') = 2. Following contributions by [[Jacques Hadamard]] and [[Georgiy Shilov]], Andrey Kolmogorov found the sharp constants and arbitrary ''n'', ''k'':<ref>{{cite journal|last=Kolmogorov|first=A.|title=On Inequalities Between the Upper Bounds of the Successive Derivatives of an Arbitrary Function on an Infinite Interval|journal=Amer. Math. Soc. Transl.|series=1&ndash;2|pages=233&ndash;243|year=1949}}</ref>\n\n:<math> C(n, k, \\mathbb R) = a_{n-k} a_n^{-1+k/n}~, </math>\n\nwhere ''a''<sub>''n''</sub> are the [[Favard constant]]s.\n\n==On the half-line==\n\nFollowing work by Matorin and others, the extremising functions were found by [[Isaac Jacob Schoenberg]],<ref>{{cite journal|last=Schoenberg|first=I.J.|title=The Elementary Case of Landau's Problem of Inequalities Between Derivatives.|journal=Amer. Math. Monthly|volume= 80|issue=2|pages=121&ndash;158|year=1973|doi=10.2307/2318373|jstor=2318373}}</ref> explicit forms for the sharp constants are however still unknown.\n\n==Generalisations==\n\nThere are many generalisations, which are of the form\n\n: <math>\\|f^{(k)}\\|_{L_q(T)} \\le K \\cdot {\\|f\\|^\\alpha_{L_p(T)}} \\cdot {\\|f^{(n)}\\|^{1-\\alpha}_{L_r(T)}}\\text{ for }1\\le k < n.</math>\n\nHere all three norms can be different from each other (from ''L<sub>1</sub>'' to ''L<sub>∞</sub>'', with ''p''=''q''=''r''=∞ in the classical case) and ''T'' may be the real axis, semiaxis or a closed segment.\n\nThe [[Kallman–Rota inequality]] generalizes the Landau–Kolmogorov inequalities from the derivative operator to more general [[Contraction (operator theory)|contractions]] on [[Banach space]]s.<ref>{{citation\n | last1 = Kallman | first1 = Robert R.\n | last2 = Rota | first2 = Gian-Carlo | author2-link = Gian-Carlo Rota\n | contribution = On the inequality <math>\\Vert f^{\\prime} \\Vert^{2}\\leqq4\\Vert f\\Vert\\cdot\\Vert f''\\Vert</math>\n | location = New York\n | mr = 0278059\n | pages = 187–192\n | publisher = Academic Press\n | title = Inequalities, II (Proc. Second Sympos., U.S. Air Force Acad., Colo., 1967)\n | year = 1970}}.</ref>\n\n==Notes==\n{{Reflist}}\n\n{{DEFAULTSORT:Landau-Kolmogorov Inequality}}\n[[Category:Inequalities]]\n→"
    },
    {
      "title": "Lebedev–Milin inequality",
      "url": "https://en.wikipedia.org/wiki/Lebedev%E2%80%93Milin_inequality",
      "text": "In mathematics, the '''Lebedev–Milin inequality''' is any of several inequalities for the coefficients of the exponential of a power series, found by {{harvs|txt|last1=Lebedev|author1-link=Nikolai Andreevich Lebedev|last2=Milin|year=1965}} and {{harvs|txt|first=Isaak Moiseevich|last=Milin|authorlink=Isaak Moiseevich Milin|year=1977}}. It was used in the proof of the [[Bieberbach conjecture]], as it shows that the [[Milin conjecture]] implies the [[Robertson conjecture]].\n\nThey state that if\n\n:<math>\\sum_{k\\ge 0} \\beta_kz^k = \\exp\\left(\\sum_{k\\ge 1} \\alpha_kz^k\\right)</math>\n\nfor complex numbers β<sub>''k''</sub> and α<sub>''k''</sub>, and ''n'' is a positive integer,  then\n\n:<math>\\sum_{k=0}^{\\infty}|\\beta_k|^2 \\le \n\\exp\\left(\\sum_{k=1}^\\infty k|\\alpha_k|^2\\right),</math>\n\n:<math>\\sum_{k=0}^{n}|\\beta_k|^2 \\le \n(n+1)\\exp\\left(\\frac{1}{n+1}\\sum_{m=1}^{n}\\sum_{k=1}^m(k|\\alpha_k|^2 -1/k)\\right),</math>\n\n:<math>|\\beta_n|^2 \\le \n\\exp\\left(\\sum_{k=1}^n(k|\\alpha_k|^2 -1/k)\\right).</math>\n\nSee also [[exponential formula]] (on exponentiation of power series).\n\n==References==\n* {{Citation | last1=Conway | first1=John B. | author1-link=John B. Conway | title=Functions of One Complex Variable II | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-0-387-94460-9 | year=1995 | oclc=32014394}}\n*{{Citation | last1=Grinshpan | first1=A. Z. | title=The Bieberbach conjecture and Milin's functionals | doi=10.2307/2589676 | mr=1682341 | year=1999 | \njournal=The American Mathematical Monthly | volume=106 | issue=3 | pages=203–214 |jstor=2589676 }}\n*{{Citation\n | last =Grinshpan\n | first =Arcadii Z.\n | author-link =\n | contribution =Logarithmic Geometry, Exponentiation, and Coefficient Bounds in the Theory of Univalent Functions and Nonoverlapping Domains\n | contribution-url =\n | editor-last =Kuhnau\n | editor-first =Reiner\n | title =Geometric Function Theory\n | place =[[Amsterdam]]\n | publisher =[[North-Holland Publishing Company|North-Holland]]\n | series =Handbook of Complex Analysis\n | volume =Volume 1\n | year =2002\n | pages =273–332\n | url =\n | doi =\n | id =\n | isbn =0-444-82845-1\n | mr =1966197\n | zbl =1083.30017\n}}.\n*{{Citation | last1=Korevaar | first1=Jacob | title=Ludwig Bieberbach's conjecture and its proof by [[Louis de Branges]] | jstor=2323021 | mr=856290  | year=1986 | journal=[[American Mathematical Monthly|The American Mathematical Monthly]] | issn=0002-9890 | volume=93 | issue=7 | pages=505–514 | doi=10.2307/2323021}}\n*{{Citation | last1=Lebedev | first1=N. A. | last2=Milin | first2=I. M. | title=An inequality | mr=0186793  | year=1965 | journal=Vestnik Leningrad University. Mathematics | issn=0146-924X | volume=20 | issue=19 | pages=157–158}}\n*{{Citation\n | last1=Milin\n | first1=I. M.\n | author-link=\n | title=Univalent functions and orthonormal systems\n | publisher=[[American Mathematical Society]]\n | place=Providence, R.I.\n | series =Translations of Mathematical Monographs\n | volume =49\n | year=1977\n | origyear =1971\n | pages=iv+202\n | isbn=0-8218-1599-7\n | mr=0369684\n | zbl=0342.30006\n}} (Translation of the 1971 Russian edition, edited by P. L. Duren).\n\n{{DEFAULTSORT:Lebedev-Milin inequality}}\n[[Category:Inequalities]]"
    },
    {
      "title": "Leggett inequality",
      "url": "https://en.wikipedia.org/wiki/Leggett_inequality",
      "text": "The '''Leggett inequalities''',<ref name=\"Leggett2003\">{{cite journal|last1=Leggett|first1=A. J.|title=Nonlocal Hidden-Variable Theories and Quantum Mechanics: An Incompatibility Theorem|journal=Foundations of Physics|volume=33|issue=10|year=2003|pages=1469–1493|issn=00159018|doi=10.1023/A:1026096313729}}</ref> named for [[Anthony James Leggett]], who derived them, are a related pair of mathematical expressions concerning the correlations of properties of [[quantum entanglement|entangled]] particles.  (As published by Leggett, the inequalities were exemplified in terms of relative angles of elliptical and linear [[polarization (waves)|polarizations]].)  They are fulfilled by a large class of physical theories based on particular [[Quantum nonlocality|non-local]] and [[Philosophical realism|realistic]] assumptions, that may be considered to be plausible or intuitive according to common physical [[reasoning]].\n\nThe Leggett inequalities are violated by [[quantum mechanics|quantum mechanical theory]].  The results of experimental tests in 2007 and 2010 have shown agreement with quantum mechanics rather than the Leggett inequalities.<ref name=\"GröblacherPaterek2007\">{{cite journal|last1=Gröblacher|first1=Simon|last2=Paterek|first2=Tomasz|last3=Kaltenbaek|first3=Rainer|last4=Brukner|first4=Časlav|last5=Żukowski|first5=Marek|last6=Aspelmeyer|first6=Markus|last7=Zeilinger|first7=Anton|title=An experimental test of non-local realism|journal=Nature|volume=446|issue=7138|year=2007|pages=871–875|issn=0028-0836|doi=10.1038/nature05677|arxiv=0704.2529}}</ref><ref name=\"RomeroLeach2010\">{{cite journal|last1=Romero|first1=J|last2=Leach|first2=J|last3=Jack|first3=B|last4=Barnett|first4=S M|last5=Padgett|first5=M J|last6=Franke-Arnold|first6=S|title=Violation of Leggett inequalities in orbital angular momentum subspaces|journal=New Journal of Physics|volume=12|issue=12|year=2010|pages=123007|issn=1367-2630|doi=10.1088/1367-2630/12/12/123007}}</ref> Given that experimental tests of [[Bell's inequalities]] have ruled out [[local realism]] in quantum mechanics, the violation of Leggett's inequalities is considered to have falsified [[Philosophical realism|realism]] in quantum mechanics.<ref>{{cite web|url=http://physicsworld.com/cws/article/news/2007/apr/20/quantum-physics-says-goodbye-to-reality|title=Quantum physics says goodbye to reality|date=20 Apr 2007|accessdate=29 Mar 2019|author=Jon Cartwright|publisher=Physics World}}</ref> In quantum mechanics \"realism\" means \"notion that physical systems possess complete sets of definite values for various parameters prior to, and independent of, measurement\".<ref name=\"FormaggioKaiser2016\">{{cite journal|last1=Formaggio|first1=J. A.|last2=Kaiser|first2=D. I.|last3=Murskyj|first3=M. M.|last4=Weiss|first4=T. E.|title=Violation of the Leggett-Garg Inequality in Neutrino Oscillations|journal=Physical Review Letters|volume=117|issue=5|year=2016|issn=0031-9007|doi=10.1103/PhysRevLett.117.050402}}</ref>\n\n==See also==\n* [[Leggett-Garg inequality]]\n\n==References==\n{{reflist}}\n\n==External links==\n* [http://seedmagazine.com/content/article/the_reality_tests/ \"The Reality Tests\", Joshua Roebke, SEED, June 2008.]\n* [http://vcq.quantum.at/publications/all-publications/details/572.html \"A quantum renaissance\", Markus Aspelmeyer and Anton Zeilinger, Physics World, July 2008.]\n* [http://physicsworld.com/cws/article/news/44580 \"Quantum theory survives latest challenge\", Kate McAlpine, Physics World, December 2010.]\n\n{{DEFAULTSORT:Leggett Inequality}}\n[[Category:Concepts in physics]]\n[[Category:Quantum information science]]\n[[Category:Quantum measurement]]\n[[Category:Physics theorems]]\n[[Category:Quantum mechanics]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Leggett–Garg inequality",
      "url": "https://en.wikipedia.org/wiki/Leggett%E2%80%93Garg_inequality",
      "text": "{{Quantum mechanics|cTopic=Experiments}}\nThe '''Leggett–Garg inequality''',<ref name=\"LeggettGarg\">Quantum Mechanics versus macroscopic realism: is the flux there when nobody looks? A. J. Leggett and Anupam Garg. Phys. Rev. Lett. '''54''', 857 (1985)</ref> named for [[Anthony James Leggett]] and [[Anupam Garg]], is a mathematical inequality fulfilled by all macrorealistic physical theories. Here, macrorealism (macroscopic realism) is a classical [[worldview]] defined by the conjunction of two postulates:<ref name=\"LeggettGarg\" />\n\n# Macrorealism per se: \"A macroscopic object, which has available to it two or more macroscopically distinct states, is at any given time in a definite one of those states.\"\n# Noninvasive measurability: \"It is possible in principle to determine which of these states the system is in without any effect on the state itself, or on the subsequent system dynamics.\"\n\n==In quantum mechanics==\nIn [[quantum mechanics]], the Leggett–Garg inequality is violated, meaning that the time evolution of a system cannot be understood classically. The situation is similar to the violation of [[Bell's theorem|Bell's inequalities]] in [[Bell test experiments]] which plays an important role in understanding the nature of the [[EPR paradox|Einstein–Podolsky–Rosen paradox]]. Here [[quantum entanglement]] plays the central role.\n\n==Two-state example==\nThe simplest form of the Leggett–Garg inequality derives from examining a system that has only two possible states. These states have corresponding  measurement values <math>Q=\\pm 1</math>. The key here is that we have measurements at two different times, and one or more times between the first and last measurement. The simplest example is where the system is measured at three successive times <math>t_1 < t_2 < t_3 </math>. Now suppose, for instance, that there is a perfect correlation <math> C_{13} </math> of 1 between times <math> t_1 </math> and <math> t_3 </math>. That is to say, that for N realisations of the experiment, the temporal correlation reads\n\n: <math>C_{13}=\\frac{1}{N} \\sum_{r=1}^N Q_r(t_1) Q_r(t_3)=1. </math>\n\nWe look at this case in some detail. What can be said about what happens at time <math> t_2</math>? Well, it is possible   that <math>C_{12} =C_{23} =1</math>, so that if the value at\n<math> t_1=\\pm 1 </math>, then it is also <math> \\pm 1 </math> for both times \n<math> t_2 </math> and <math> t_3 </math>. It is also quite possible that <math> C_{12}=C_{23}=-1 </math>, so that the value at <math>t_1</math> is\nflipped twice, and so has the same value at <math>t_3</math> as it did at\n<math> t_1 </math>. So, we can have both <math> Q(t_1) </math> and \n<math> Q(t_2) </math> anti-correlated as long as we have <math> Q(t_2) </math>\nand <math> Q(t_3) </math> anti-correlated. Yet another possibility is \nthat there is no correlation between  <math> Q(t_1) </math> and \n<math> Q(t_2) </math>. That is we could have <math> C_{12}=C_{23}=0 </math>.\nSo, although it is known that if <math>Q=\\pm 1</math> at <math> t_1</math>\nit must also be <math> \\pm 1 </math> at <math> t_3 </math>, the value\nat <math> t_2 </math> may as well be determined by the toss of a coin.\nWe define <math> K </math> as <math>K= C_{12}+C_{23}-C_{13}</math>.\nIn these three cases, we have  \n<math>K=1, -3,</math> and <math> -1</math>, respectively.\n\nAll that was for 100% correlation between times <math>t_1 </math> \nand  <math>t_3 </math>. In fact, for any correlation between these\ntimes  <math> K= C_{12}+C_{23}-C_{13} \\le 1</math>. To see this, we note that\n\n: <math>K=\\frac{1}{N} \\sum_{r=1}^N \\left ( Q(t_1)Q(t_2)+Q(t_2)Q(t_3)\n-Q(t_1)Q(t_3) \\right )_r. </math>\n\nIt is easily seen that for every realisation <math> r</math>, the term in the\nparentheses must be less than or equal to unity, so that the result for the sum is also less than (or equal to) unity. If we have four distinct times rather than three, we have <math> K= C_{12}+C_{23}+C_{34}-C_{14} \\le 2</math> and so on. These are the Leggett–Garg  inequalities. They say something definite about the relation between the temporal correlations of <math> \\langle Q(\\text{start}) Q(\\text{end}) \\rangle </math>\nand the correlations between successive times in going from the start to the end.\n\nIn the derivations above, it has been assumed that the quantity Q, representing the state of the system, always has a definite value (macrorealism per se) and that its measurement at a certain time does not change this value nor its subsequent evolution (noninvasive measurability). A violation of the Leggett–Garg inequality implies that at least one of these two assumptions fails.\n\n==Experimental violations==\nOne of the first proposed experiments for demonstrating a violation of macroscopic realism employs superconducting quantum interference devices. There, using [[Josephson junction]]s, one should be able to prepare macroscopic superpositions of left and right rotating macroscopically large electronic currents in a superconducting ring. Under sufficient suppression of decoherence one should be able to demonstrate a violation of the Leggett–Garg inequality.<ref name=\"Leggett\">Testing the limits of quantum mechanics: motivation, state of play, prospects. A. J. Leggett. J. Phys.: Condens. Matter '''14''', R414-R451 (2002)</ref> However, some criticism has been raised concerning the nature of indistinguishable electrons in a Fermi sea.<ref name=\"Korsbakken\">Electronic structure of superposition states in flux qubits. J. I. Korsbakken, F. K. Wilhelm, and K. B. Whaley, Physica Scripta '''137''', 4022 (2009). https://link.springer.com/article/10.1007%2Fs10701-011-9598-4</ref><ref name=\"Laloy\">Superconducting qubit in a resonator: test of the Leggett-Garg inequality and single-shot readout, A. Palacios-Laloy, PhD thesis (2010). http://iramis.cea.fr/spec/Pres/Quantro/static/wp-content/uploads/2010/10/Palacios-Laloy-Thesis1.pdf</ref>\n\nA criticism of some other proposed experiments on the Leggett–Garg inequality is that they do not really show a violation of macrorealism because they are essentially about measuring spins of individual particles.<ref name=\"Interp\">Foundations and Interpretation of Quantum Mechanics. [[Gennaro Auletta]] and [[Giorgio Parisi]], World Scientific, 2001 {{isbn|981-02-4614-5}}, {{isbn|978-981-02-4614-3}}</ref> In 2015 Robens ''et al.''<ref name=\"Robens2015\">[https://journals.aps.org/prx/abstract/10.1103/PhysRevX.5.011003 \"Ideal Negative Measurements in Quantum Walks Disprove Theories Based on Classical Trajectories\"]. Carsten Robens, Wolfgang Alt, Dieter Meschede, Clive Emary, and Andrea Alberti, Physical Review X '''5''', 011003 (2015).</ref> demonstrated an experimental violation of the Leggett–Garg inequality using superpositions of positions instead of spin with a massive particle. At that time, and so far up until today, the Cesium atoms employed in their experiment represent the largest quantum objects which have been used to experimentally test the Leggett–Garg inequality.<ref name=\"Knee2015\">[http://physics.aps.org/articles/v8/6 \"Do Quantum Superpositions Have a Size Limit?\"] , George C. Knee,  Physics '''8''', 6 (2015).</ref>\n\nThe experiments of Robens ''et al.''<ref name=Robens2015 /> as well as Knee ''et al.'',<ref name=\"Knee2012\">[http://www.nature.com/articles/ncomms1614 \"Violation of a Leggett–Garg inequality with ideal non-invasive measurements\"] , George C. Knee, Stephanie Simmons, Erik M. Gauger, John J.L. Morton, Helge Riemann, Nikolai V. Abrosimov, Peter Becker, Hans-Joachim Pohl, Kohei M. Itoh, Mike L.W. Thewalt, G. Andrew D. Briggs & Simon C. Benjamin,  Nature Communications '''3''' 606 (2012).</ref> using ideal negative measurements, also avoid a second criticism (referred to as “clumsiness loophole”<ref name=\"Wilde2012\">[https://link.springer.com/article/10.1007%2Fs10701-011-9598-4 \"Addressing the Clumsiness Loophole in a Leggett-Garg Test of Macrorealism\"]. Mark M. Wilde and Ari Mizel,  Foundations of Physics '''42''', 256 (2012).</ref>) that has been directed to previous experiments using measurement protocols that could be interpreted as invasive, thereby conflicting with postulate 2.\n\nSeveral other experimental violations have been reported, including in 2016 with neutrino particles using the [[MINOS]] dataset.<ref>[http://journals.aps.org/prl/abstract/10.1103/PhysRevLett.117.050402 \"Violation of the Leggett-Garg Inequality in Neutrino Oscillations\". J. A. Formaggio, D. I. Kaiser, M. M. Murskyj, and T. E. Weiss, Physical Review Letters '''117''', 050402 (2016)].</ref>\n\nBrukner and Kofler have also demonstrated that quantum violations can be found for arbitrarily large ''macroscopic'' systems. As an alternative to [[quantum decoherence]], Brukner and Kofler are proposing a solution of the quantum-to-classical transition in terms of ''coarse-grained'' quantum measurements under which usually no violation of the Leggett–Garg inequality can be seen anymore.<ref name=\"KoflerPaper\">Classical world arising out of quantum physics under the restriction of coarse-grained measurements. Johannes Kofler and Caslav Brukner. Phys. Rev. Lett. '''99''', 180403 (2007), ArXiv 0609079 [quant-ph] Sept. 2006\nhttps://arxiv.org/abs/quant-ph/0609079</ref><ref name=\"KoflerPaper2\">The conditions for quantum violation of macroscopic realism. Johannes Kofler and Caslav Brukner. Phys. Rev. Lett. '''101''', 090403 (2008), ArXiv 0706.0668 [quant-ph] June 2007\nhttps://arxiv.org/abs/0706.0668</ref>\n\nExperiments proposed by Mermin<ref name=\"Mermin\">Extreme quantum entanglement in a superpostion of macroscopically distinct states. David Mermin, Phys. Rev. Lett. '''65''' 1838-1840 (1990)</ref> and Braunstein and Mann<ref name=\"Braunstein\" >Noise in Mermin's n-particle Bell inequality. Braunstein, S.L. and Mann, A., Phys. Rev. A '''47''', R2427-R2430 (1993)</ref> would be better for testing macroscopic realism, but warns that the experiments may be complex enough to admit unforeseen loopholes in the analysis. A detailed discussion of the subject can be found in the review by Emary et al.<ref name=\"Emary2014\">Leggett–Garg inequalities. C. Emary, N. Lambert, and F. Nori, Rep. Prog. Phys. '''77''', 016001 (2014). https://arxiv.org/abs/1304.5133</ref>\n\n==Related inequalities==\nThe four-term Leggett–Garg inequality can be seen to be similar to the [[CHSH inequality]]. Moreover, ''equalities'' were proposed by Jaeger ''et al.''<ref>Bell type equalities for SQUIDs on the assumptions of macroscopic realism and non-invasive measurability. Gregg Jaeger, Chris Viger and Sahotra Sarkar. Phys. Lett. A '''210''', 5-10 (1996)</ref>\n\n==See also==\n* [[Leggett inequality]]\n\n==References==\n{{reflist}}\n\n{{Quantum mechanics topics}}\n\n{{DEFAULTSORT:Leggett-Garg Inequality}}\n[[Category:Quantum information science]]\n[[Category:Interpretations of quantum mechanics]]\n[[Category:Physics theorems]]\n[[Category:Inequalities]]\n[[Category:Quantum measurement]]\n[[Category:Physics experiments]]\n[[Category:Thought experiments in quantum mechanics]]"
    },
    {
      "title": "Less-than sign",
      "url": "https://en.wikipedia.org/wiki/Less-than_sign",
      "text": "{{Unreferenced|date=June 2019|bot=noref (GreenC bot)}}\n{{for|the use of the \"&lt;\" sign as punctuation | Bracket#Angle brackets}}\n[[File:Less than sign.png|thumb|Less-than sign]]\nThe ''less-than sign'' is a mathematical symbol that denotes an [[Inequality (mathematics)|inequality]] between two values. The widely adopted form of two equal-length strokes connecting in an [[acute angle]] at the left, '''<''', has been found in documents dated as far back as the 1560s. In typical mathematical usage, the less-than sign is typically placed between the two values being compared and signals that the first number is less than the second number. Examples of typical usage include ''½ < 1'' and ''−2 < 1''. Since the development of computer [[programming languages]], the less-than sign and the [[greater-than sign]] have been repurposed for a range of uses and operations.\n\n==Computing==\nThe '''less-than sign''' (<code>&lt;</code>) is an original [[ASCII]] character (hex 3C, decimal 60).\n\nThe less-than sign is used for an approximation of the opening [[Bracket|angle bracket]] (⟨). ASCII does not have angle brackets.\n\n===Programming language===\nIn [[BASIC]], [[Lisp (programming language)|Lisp]]-family languages, and [[C (programming language)|C]]-family languages (including [[Java (programming language)|Java]] and [[C++]]), operator <code>&lt;</code> means \"less than\".\n\nIn [[Coldfusion]], operator <code>.lt.</code> means \"less than\".\n\nIn [[Fortran]], operator <code>.LT.</code> means \"less than\"; later versions allow <code>&lt;</code>.\n\nIn [[Bourne shell]], operator <code>-lt</code> means \"less than\".\n\n===Double less-than sign===\nThe double less-than sign (<code>&lt;&lt;</code>) is used for an approximation of the [[much-less-than sign]] (≪) or of the opening [[Guillemets|guillemet]] («). ASCII does not have a much-less-than sign.\n\nIn [[Bash (Unix shell)|Bash]], [[Perl]], and [[Ruby (programming language)|Ruby]], operator <code>&lt;&lt;EOF</code> (where \"EOF\" is an arbitrary string, but commonly \"EOF\" denoting \"end of file\") is used to denote the beginning of a [[here document]].\n\nIn [[C (programming language)|C]] and [[C++]], operator <code>&lt;&lt;</code> represents a [[Bitwise operation#Shifts in C, C++, C#, Python|binary left shift]].\n\nIn the [[C++ Standard Library]], operator <code>&lt;&lt;</code>, when applied on an output stream, acts as ''insertion operator'' and performs an output operation on the stream.\n\nIn [[Ruby (programming language)|Ruby]], operator <code>&lt;&lt;</code> acts as ''append operator'' when used between an array and the value to be appended.\n\n===Triple less-than sign===\nIn [[PHP]], operator <code>&lt;&lt;&lt;OUTPUT</code> is used to denote the beginning of a [[here document|heredoc]] statement (where <code>OUTPUT</code> is an arbitrary named variable.)\n\nIn Bash, <code>&lt;&lt;&lt;word</code> is used as a \"here string\", where <code>word</code> is expanded and supplied to the command on its standard input, similar to a heredoc.\n\n===Less-than sign plus equals sign===\nThe less-than sign plus the equals sign (<code>&lt;=</code>) is used for an approximation of the [[Inequality (mathematics)|less-than-or-equal-to sign]] (≤). ASCII does not have a less-than-or-equal-to sign, but [[Unicode]] defines it at code point U+2264.\n\nIn [[BASIC]], [[Lisp (programming language)|Lisp]]-family languages, and [[C (programming language)|C]]-family languages (including [[Java (programming language)|Java]] and [[C++]]), operator <code>&lt;=</code> means \"less than or equal to\". In [[Sinclair BASIC]] it is encoded as a single-byte code point token.\n\nIn [[Fortran]], operator <code>.LE.</code> means \"less than or equal to\".\n\nIn [[Bourne shell]] and [[Windows PowerShell]], the operator <code>-le</code> means \"less than or equal to\".\n\n=== Less-than sign plus Hyphen-minus ===\nIn the [[R (programming language)|R programming language]], the less-than sign is used in conjunction with a [[hyphen-minus]] to create an arrow (<code><-</code>), this can be used as the left assignment operator.\n\n===Shell scripts===\nIn [[Bourne shell]] (and many other shells), less-than sign is used to [[Redirection (computing)|redirect]] input from a file. Less-than plus ampersand (<code>&lt;&amp;</code>) is used to redirect from a [[file descriptor]].\n\n===Spaceship operator===\nLess-than sign is used in the [[spaceship operator]].\n\n===HTML===\nIn [[HTML]] (and [[Standard Generalized Markup Language|SGML]] and [[XML]]), the less-than sign is used at the beginning of tags. The less-than sign may be included with <code>&amp;lt;</code>. The less-than-or-equal-to sign may be included with <code>&amp;le;</code>.\n\n==Mathematics==\nIn an inequality, the less-than sign always \"points\" to the smaller number. Put another way, the \"jaws\" (the wider section of the symbol) always direct to the larger number.\n\n==See also==\n*[[Inequality (mathematics)]]\n*[[Greater-than sign]]\n*[[Relational operator]]\n*[[Much-less-than sign]]\n*[[Guillemet]]\n\n[[Category:Typographical symbols]]\n[[Category:Mathematical symbols]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Levinson's inequality",
      "url": "https://en.wikipedia.org/wiki/Levinson%27s_inequality",
      "text": "In [[mathematics]], '''Levinson's inequality ''' is the following inequality, due to [[Norman Levinson]], involving positive numbers.  Let <math>a>0</math> and let <math>f</math> be a given function having a third derivative on the range <math>(0,2a)</math>, and such that \n\n:<math>f'''(x)\\geq 0</math> \n\nfor all <math>x\\in (0,2a)</math>.  Suppose <math>0<x_i\\leq a</math> and <math>0<p_i</math> for <math> i = 1, \\ldots, n</math>.  Then \n\n: <math>\\frac{\\sum_{i=1}^np_i f(x_i)}{\\sum_{i=1}^np_i}-f\\left(\\frac{\\sum_{i=1}^np_ix_i}{\\sum_{i=1}^np_i}\\right)\\le\\frac{\\sum_{i=1}^np_if(2a-x_i)}{\\sum_{i=1}^np_i}-f\\left(\\frac{\\sum_{i=1}^np_i(2a-x_i)}{\\sum_{i=1}^np_i}\\right).</math>\n\nThe [[Ky Fan inequality]] is the special case of Levinson's inequality, where \n\n:<math>p_i=1,\\  a=\\frac{1}{2},</math> \n\nand \n\n:<math>f(x)=\\log x. </math>\n\n==References== \n*Scott Lawrence and Daniel Segalman: ''A generalization of two inequalities involving means'', Proceedings of the American Mathematical Society. Vol 35 No. 1, September 1972.\n*[[Norman Levinson]]: ''Generalization of an inequality of Ky Fan'', Journal of Mathematical Analysis and Applications. Vol 8 (1964), 133–134.\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Lieb–Oxford inequality",
      "url": "https://en.wikipedia.org/wiki/Lieb%E2%80%93Oxford_inequality",
      "text": "In  [[quantum chemistry]] and [[physics]], the '''Lieb–Oxford inequality''' provides a lower bound for the indirect part of the [[Coulomb energy]] of a [[Quantum Mechanics|quantum mechanical]] system. It is named after [[Elliott H. Lieb]] and [[Stephen Oxford]].\n\nThe inequality is of importance for [[density functional theory]] and plays a role in the proof of [[Lieb–Thirring inequality#The stability of matter|stability of matter]].\n\n==Introduction==\n\nIn classical physics, one can calculate the [[Coulomb energy]] of a configuration of charged particles in the following way. First, calculate the [[charge density]] {{math|''ρ''}}, where {{math|''ρ''}} is a function of the coordinates  {{math|''x'' &isin; ℝ{{sup|3}}}}. Second, calculate the Coulomb energy by integrating:\n\n: <math>\\frac{1}{2}\\int_{\\mathbb{R}^3}\\int_{\\mathbb{R}^3}\\frac{\\rho(x)\\rho(y)}{|x-y|} \\, \\mathrm{d}^3 x \\, \\mathrm{d}^3 y.</math>\n\nIn other words, for each pair of points {{math|''x''}} and {{math|''y''}}, this expression calculates the energy related to the fact that the charge at  {{math|''x''}} is attracted to or repelled from the charge at {{math|''y''}}. The factor of {{frac|1|2}} corrects for double-counting the pairs of points.\n\nIn quantum mechanics, it is ''also'' possible to calculate a charge density {{math|''ρ''}}, which is a function of  {{math|''x'' &isin; ℝ{{sup|3}}}}. More specifically, {{math|''ρ''}} is defined as the [[expectation value (quantum mechanics)|expectation value]] of charge density at each point. But in this case, the above formula for Coulomb energy is not correct, due to [[exchange interaction|exchange]] and [[electronic correlation|correlation]] effects. The above, classical formula for Coulomb energy is then called the \"direct\" part of Coulomb energy. To get the ''actual'' Coulomb energy, it is necessary to add a correction term, called the \"indirect\" part of Coulomb energy. The Lieb–Oxford inequality concerns this indirect part. It is relevant in [[density functional theory]], where the expectation value ρ plays a central role.\n\n==Statement of the inequality==\nFor a [[quantum mechanics|quantum mechanical]] system of {{math|''N''}} particles, each with charge {{math|''e''}}, the {{math|''N''}}-particle density is denoted by\n\n:<math>P(x_1,\\dots,x_N).</math>\n\nThe function {{math|''P''}} is only assumed to be non-negative and [[Wave function#Normalized components and probabilities|normalized]]. Thus the following applies to particles with any \"statistics\". For example, if the system is described by a normalised [[square integrable]] {{math|''N''}}-particle [[wave function]]\n\n:<math>\\psi\\in L^2(\\mathbb{R}^{3N}),</math>\n\nthen\n\n:<math>P(x_1,\\dots,x_N)=|\\psi(x_1,\\dots,x_N)|^2.</math>\n\nMore generally, in the case of particles with [[Spin (physics)|spin]] having {{math|''q''}} spin states per particle and with corresponding wave function\n:<math>\\psi(x_1,\\sigma_1,\\dots,x_N,\\sigma_N)</math>\nthe {{math|''N''}}-particle density is given by \n:<math>P(x_1,\\dots,x_N)=\\sum_{\\sigma_1=1}^q\\cdots\\sum_{\\sigma_N=1}^q|\\psi(x_1,\\sigma_1,\\dots,x_N,\\sigma_N)|^2.</math>\nAlternatively, if the system is described by a density matrix {{math|''&gamma;''}}, then {{math|''P''}} is the diagonal\n:<math>\\gamma(x_1, ... , x_N;  x_1, ..., x_N ).</math>\n\nThe electrostatic energy of the system is defined as\n\n:<math>I_P=e^2\\sum_{1\\le i<j\\le N}\\int_{\\mathbb{R}^{3N}}\\frac{P(x_1,\\dots,x_i,\\dots,x_j,\\dots,x_N)}{|x_i-x_j|} \\, \\mathrm{d}^3 x_1\\cdots\\mathrm{d}^3 x_N.</math>\n\nFor {{math|''x'' ∈ ℝ{{sup|3}}}}, the single particle charge density is given by\n\n:<math>\\rho(x)=|e|\\sum_{i=1}^N\\int_{\\mathbb{R}^{3(N-1)}}P(x_1,\\dots,x_{i-1},x,x_{i+1},\\dots,x_N) \\, \\mathrm{d}^3 x_1\\cdots\\mathrm{d}^3 x_{i-1} \\, \\mathrm{d}^3 x_{i+1}\\cdots\\mathrm{d}^3 x_N</math>\n\nand the direct part of the Coulomb energy of the system of {{math|''N''}} particles is defined as the electrostatic energy associated with the charge density {{math|''ρ''}}, i.e.\n\n: <math>D(\\rho)=\\frac12\\int_{\\mathbb{R}^3} \\int_{\\mathbb{R}^3} \\frac{\\rho(x)\\rho(y)}{|x-y|} \\, \\mathrm{d}^3 x \\, \\mathrm{d}^3 y.</math>\n\nThe '''Lieb–Oxford inequality''' states that the difference between the true energy {{math|''I''{{sub|''P''}}}} and its semiclassical approximation {{math|''D''(''ρ'')}} is bounded from below as\n\n{{NumBlk|:|<math>\nE_P=I_P-D(\\rho)\\ge -C|e|^\\frac23\\int_{\\mathbb{R}^3}|\\rho(x)|^\\frac43 \\, \\mathrm{d}^3 x,\n</math>|{{EquationRef|1}}}}\nwhere {{math|''C'' ≤ 1.68}} is a constant independent of the particle number {{math|''N''}}. {{math|''E''{{sub|''P''}}}} is referred to as the indirect part of the Coulomb energy and in density functional theory more commonly as the [[Density functional theory#Derivation and formalism|exchange plus correlation energy]]. A similar bound exists if the particles have different charges {{math|''e''{{sub|1}}, ... , ''e''{{sub|''N''}}}}. No upper bound is possible for {{math|''E''{{sub|''P''}}}}.\n\n==The optimal constant==\nWhile the original proof yielded the constant {{math|1=''C'' = 8.52}},<ref>\n{{cite journal\n |last1=Lieb |first1=E. H.\n |year=1979\n |title=A lower bound for Coulomb energies\n |journal=[[Physics Letters A]]\n |volume=70 |issue=5–6 |pages=444–446\n |bibcode=1979PhLA...70..444L\n |doi=10.1016/0375-9601(79)90358-X\n}}</ref> Lieb and Oxford managed to refine this result to {{math|1=''C'' = 1.68}}.<ref name=\"LO1981\">\n{{cite journal\n |last1=Lieb|first1=E. H.\n |last2=Oxford |first2=S.\n |year=1981\n |title=Improved lower bound on the indirect Coulomb energy\n |journal=[[International Journal of Quantum Chemistry]]\n |volume=19 |issue=3 |pages=427\n |doi=10.1002/qua.560190306\n}}</ref> Later, the same method of proof was used to further improve the constant to {{math|1=''C'' = 1.64}}.<ref>\n{{cite journal\n |last1=Kin-Lic Chan |first1=G.\n |last2=Handy |first2=N. C.\n |year=1999\n |title=Optimized Lieb-Oxford bound for the exchange-correlation energy\n |journal=[[Physical Review A]]\n |volume=59 |issue=4 |pages=3075\n |bibcode=1999PhRvA..59.3075K\n |doi=10.1103/PhysRevA.59.3075\n}}</ref> With these constants the inequality holds for any particle number {{math|''N''}}.\n\nThe constant can be further improved if the particle number {{math|''N''}} is restricted. In the case of a single particle {{math|1=''N'' = 1}} the Coulomb energy vanishes, {{math|1=''I''{{sub|''P''}} = 0}}, and the smallest possible constant can be computed explicitly as {{math|1=''C''{{sub|1}} = 1.092}}.<ref name=\"LO1981\"/> The corresponding [[Calculus of variations|variational equation]] for the optimal {{math|''&rho;''}} is the [[Lane–Emden equation]] of order 3. For two particles ({{math|1=''N'' = 2}}) it is known that the smallest possible constant satisfies {{math|''C''{{sub|2}} ≥ 1.234}}.<ref name=\"LO1981\"/> In general it can be proved that the optimal constants {{math|''C''{{sub|''N''}}}} increase with the number of particles, i.e {{math|''C''{{sub|''N''}} ≤ ''C''{{sub|''N'' + 1}}}}.<ref name=\"LO1981\"/> Any lower bound on the optimal constant for fixed particle number {{math|''N''}} is also a lower bound on the optimal constant in ({{EquationNote|1}}) for arbitrary particle number. The largest presently known numerically obtained lower bound on {{math|''C''}} was proved for {{math|1=''N'' = 60}} where {{math|''C''{{sub|60}} ≥ 1.41}}.<ref>{{cite journal|last2=Vuckovic|first2=S.|last3=Gori-Giorgi|first3=P.|year=2016|title=Challenging the Lieb–Oxford bound in a systematic way. Molecular Physics|journal=[[Molecular Physics (journal)|Molecular Physics]]|volume=114|issue=7-8|pages=1076–1085|doi=10.1080/00268976.2015.1136440|last1=Seidl|first1=M.|arxiv=1508.01715|bibcode=2016MolPh.114.1076S}}</ref> This bound has been obtained by considering an exponential density. For the same particle number a uniform density gives {{Math|''C''{{sub|60}} ≥ 1.34}}. Contrary to previous believes, these results suggest that a uniform density is not the most challenging one for setting the lower bound to {{Math|''C''}}. To summarise, the best known bounds for {{math|''C''}} are {{math|1.41 ≤ ''C'' ≤ 1.64}}.\n\n==The Dirac constant==\nHistorically, the first approximation of the indirect part {{math|''E''{{sub|''P''}}}} of the Coulomb energy in terms of the single particle charge density was given by [[Paul Dirac]] in 1930 for [[fermions]].<ref>\n{{cite journal\n |last1=Dirac |first1=P. A. M.\n |year=2008\n |title=Note on Exchange Phenomena in the Thomas Atom\n |journal=[[Mathematical Proceedings of the Cambridge Philosophical Society]]\n |volume=26 |issue=3 |pages=376\n |bibcode=1930PCPS...26..376D\n |doi=10.1017/S0305004100016108\n}}</ref> The wave function under consideration is\n:<math>\\psi(x_1,\\sigma_1,\\dots,x_N,\\sigma_N)= \\frac{\\det(\\varphi_i(x_j,\\sigma_j))}{\\sqrt{N!}}.</math>\n \nWith the aim of evoking perturbation theory, one considers the eigenfunctions of the [[Laplacian]] in a large cubic box of volume {{math|{{!}}''&Lambda;''{{!}}}} and sets\n\n: <math>\\varphi_{\\alpha,k}(x,\\sigma) = \\frac{\\chi_\\alpha(\\sigma)\\mathrm{e}^{2\\pi\\mathrm{i} k\\cdot x}}{\\sqrt{|\\Lambda|}},</math>\n\nwhere {{math|''&chi;''{{sub|1}}, ..., ''&chi;''{{sub|''q''}}}} forms an orthonormal basis of {{math|ℂ{{sup|''q''}}}}. The allowed values of {{math|''k'' &isin; ℝ{{sup|3}}}} are {{math|''n''/{{!}}''&Lambda;''{{!}}{{sup|{{frac|1|3}}}}}} with {{math|''n'' &isin; ℤ{{su|p=3|b=+}}}}. For large {{math|''N''}}, {{math|{{!}}''&Lambda;''{{!}}}}, and fixed {{math|1=''&rho;'' = ''N'' {{!}}''e''{{!}}/{{!}}''&Lambda;''{{!}}}}, the indirect part of the Coulomb energy can be computed to be\n\n: <math>E_P(\\mathrm{Dirac})=-C |e|^{2/3} q^{-1/3}\\rho^{4/3}|\\Lambda|,</math>\n\nwith {{math|1=''C'' = 0.93}}.\n\nThis result can be compared to the lower bound ({{EquationNote|1}}).  In contrast to Dirac's approximation the Lieb–Oxford inequality does not include the number {{math|''q''}} of spin states on the right-hand side. The dependence on {{math|''q''}} in Dirac's formula is a consequence of his specific choice of wave functions and not a general feature.\n\n==Generalisations==\nThe constant {{math|''C''}} in ({{EquationNote|1}}) can be made smaller at the price of adding another term to the right-hand side. By including a term that involves the [[gradient]] of a power of the single particle charge density {{math|''&rho;''}}, the constant {{math|''C''}} can be improved to {{math|1.45}}.<ref>\n{{cite journal\n |last1=Benguria |first1=R. D.\n |last2=Gallegos |first2=P.\n |last3=Tušek |first3=M.\n |year=2012\n |title=A New Estimate on the Two-Dimensional Indirect Coulomb Energy\n |journal=[[Annales Henri Poincaré]]\n |volume=13 |issue=8 |pages=1733\n |bibcode=2012AnHP...13.1733B\n |doi=10.1007/s00023-012-0176-x\n|arxiv = 1106.5772 }}</ref><ref>\n{{cite journal\n |last1=Lewin |first1=Mathieu\n |last2=Lieb |first2=Elliott H.\n |year=2015\n |title=Improved Lieb-Oxford exchange-correlation inequality with a gradient correction\n |journal=[[Physical Review A]]\n |volume=91 |issue=2 |pages=022507\n |bibcode=2015PhRvA..91b2507L\n |doi=10.1103/PhysRevA.91.022507\n|arxiv = 1408.3358 }}</ref> Thus, for a uniform density system {{math|''C'' ≤ 1.45}}.\n\n==References==\n{{reflist}}\n\n==Further reading==\n* {{cite book\n |last1=Lieb |first1=E. H.\n |last2=Seiringer |first2=R.\n |year=2010\n |title=The Stability of Matter in Quantum Mechanics\n |publisher=[[Cambridge University Press]]\n |isbn=978-0-521-19118-0\n}}\n\n{{DEFAULTSORT:Lieb-Oxford inequality}}\n[[Category:Inequalities]]\n[[Category:Density functional theory]]"
    },
    {
      "title": "Lieb–Thirring inequality",
      "url": "https://en.wikipedia.org/wiki/Lieb%E2%80%93Thirring_inequality",
      "text": "{{distinguish|text=[[Trace inequalities#Araki–Lieb–Thirring inequality|Araki–Lieb–Thirring inequality]]}}\n\nIn [[mathematics]] and [[physics]], '''Lieb–Thirring inequalities''' provide an upper bound on the sums of powers of the negative [[eigenvalues]] of a [[Schrödinger operator]] in terms of integrals of the potential. They are named after [[Elliott H. Lieb|E. H. Lieb]] and [[Walter Thirring|W. E. Thirring]].\n\nThe inequalities are useful in studies of [[quantum mechanics]] and [[differential equations]] and imply, as a corollary, a lower bound on the [[kinetic energy]] of <math>N</math> quantum mechanical particles that plays an important role in the proof of stability of [[matter]].<ref name=\"LT1976\">E. H. Lieb, W. E. Thirring, Inequalities for the moments of the eigenvalues of the Schrödinger hamiltonian and their relation to Sobolev inequalities, Studies in Mathematical Physics, Princeton University Press (1976), 269–303</ref>\n\n==Statement of the inequalities==\nFor the Schrödinger operator <math>-\\Delta+V(x)=-\\nabla^2+V(x)</math> on  <math>\\mathbb{R}^n</math> with real-valued potential <math>V(x):\\mathbb{R}^n\\to\\mathbb{R}</math>, the numbers <math>\\lambda_1\\le\\lambda_2\\le\\dots\\le0</math> denote the (not necessarily finite) sequence of negative eigenvalues. Then, for <math>\\gamma</math> and <math>n</math> satisfying one of the conditions\n\n:<math>\\begin{align}\n\\gamma\\ge\\frac12&,\\,n=1,\\\\\n\\gamma>0&,\\,n=2,\\\\\n\\gamma\\ge0&,\\,n\\ge3,\n\\end{align}</math>\n\nthere exists a constant <math>L_{\\gamma,n}</math>, which only depends on <math>\\gamma</math> and <math>n</math>, such that\n\n{{NumBlk|:|<math>\n\\sum_{j\\ge1}|\\lambda_j|^\\gamma\\le L_{\\gamma,n}\\int_{\\R^n}V(x)_-^{\\gamma+\\frac n2}\\mathrm{d}^n x\n</math>|{{EquationRef|1}}}}\n\nwhere <math>V(x)_-:=\\max(-V(x),0)</math> is the negative part of the potential <math>V</math>. The cases <math>\\gamma>1/2,n=1</math> as well as <math>\\gamma>0,n\\ge2</math> were proven by E. H. Lieb and W. E. Thirring in 1976 <ref name=\"LT1976\"/> and used in their proof of stability of matter. \nIn the case <math>\\gamma=0, n\\ge3</math> the left-hand side is simply the number of negative eigenvalues, and proofs were given independently by M. Cwikel.,<ref>M. Cwikel, Weak type estimates for singular values and the number of bound states of Schrödinger operators, Ann. of Math. (2) 106 (1977), no. 1, 93–100</ref> E. H. Lieb <ref name =\"L1976\">E. H. Lieb, Bounds on the eigenvalues of the Laplace and Schroedinger operators, Bull. Amer. Math. Soc. 82 (1976), no. 5, 751–753</ref> and G. V. Rozenbljum.<ref>G. V. Rozenbljum, Distribution of the discrete spectrum of singular differential operators, Izv. Vysš. Učebn. Zaved. Matematika (1976), no. 1(164), 75–86</ref> The resulting <math>\\gamma=0</math> inequality is thus also called the Cwikel–Lieb–Rosenbljum bound. The remaining critical case <math>\\gamma=1/2, n=1</math> was proven to hold by T. Weidl <ref>T. Weidl, On the Lieb–Thirring constants <math>L_{\\gamma,1}</math> for <math>\\gamma \\ge 1/2</math>, Comm. Math. Phys. 178 (1996), no. 1, 135–146</ref>\nThe conditions on <math>\\gamma</math> and <math>n</math> are necessary and cannot  be relaxed.\n\n==Lieb–Thirring constants==\n\n===Semiclassical approximation===\nThe Lieb–Thirring inequalities can be compared to the semi-classical limit.  \nThe classical [[phase space]] consists of pairs <math>(p,x)\\in\\mathbb{R}^{2n}</math>. Identifying the [[momentum operator]] <math>-\\mathrm{i}\\nabla</math> with <math>p</math> and assuming that every quantum state is contained in a volume <math>(2\\pi)^n</math> in the <math>2n</math>-dimensional phase space, the semi-classical approximation\n\n:<math>\n\\sum_{j\\ge 1}|\\lambda_j|^\\gamma\\approx \\frac{1}{(2\\pi)^n}\\int_{\\mathbb{R}^n}\\int_{\\mathbb{R}^n}\\big(p^2+V(x)\\big)_-^\\gamma\\mathrm{d}^n p\\mathrm{d}^n x\n=L^{\\mathrm{cl}}_{\\gamma,n}\\int_{\\mathbb{R}^n} V(x)_-^{\\gamma+\\frac n2}\\mathrm{d}^n x\n</math>\n\nis derived with the constant\n\n:<math>\nL_{\\gamma,n}^{\\mathrm{cl}}=(4\\pi)^{-\\frac n2}\\frac{\\Gamma(\\gamma+1)}{\\Gamma(\\gamma+1+\\frac n2)}\\,.\n</math>\n\nWhile the semi-classical approximation does not need any assumptions on <math>\\gamma>0</math>, the Lieb–Thirring inequalities only hold for suitable <math>\\gamma</math>.\n\n===Weyl asymptotics and sharp constants===\nNumerous results have been published about the best possible constant <math>L_{\\gamma,n}</math> in ({{EquationNote|1}}) but this problem is still partly open.\nThe semiclassical approximation becomes exact in the limit of large coupling, that is for potentials <math>\\beta V</math> the [[Hermann Weyl|Weyl]] asymptotics\n\n:<math>\n\\lim_{\\beta\\to\\infty}\\frac{1}{\\beta^{\\gamma+\\frac n2}}\\mathrm{tr} (-\\Delta+\\beta V)_-^\\gamma=L^\\mathrm{cl}_{\\gamma,n}\\int_{\\mathbb{R}^n} V(x)_-^{\\gamma+\\frac n2}\\mathrm{d}^n x\n</math>\n\nhold.  This implies that <math>L_{\\gamma,n}^{\\mathrm{cl}}\\le L_{\\gamma,n}</math>. \nLieb and Thirring<ref name =\"LT1976\"/> were able to show that  <math> L_{\\gamma,n}=L_{\\gamma,n}^{\\mathrm{cl}}</math> for <math>\\gamma\\ge 3/2, n=1</math>. [[Michael Aizenman|M. Aizenman]] and E. H. Lieb <ref>M. Aizenman and E. H. Lieb, On semiclassical bounds for eigenvalues of Schrödinger operators, Phys. Lett. A 66 (1978), no. 6, 427–429</ref>\nproved that for fixed dimension <math>n</math> the ratio <math>L_{\\gamma,n}/L_{\\gamma,n}^{\\mathrm{cl}}</math> is a [[Monotonic function|monotonic]], non-increasing function of <math>\\gamma</math>.  Subsequently <math>L_{\\gamma,n}=L_{\\gamma,n}^{\\mathrm{cl}}</math> was also shown to hold for all <math>n</math> when <math>\\gamma\\ge 3/2</math>  by [[Ari Laptev|A. Laptev]] and T. Weidl.<ref>A. Laptev and T. Weidl, Sharp Lieb–Thirring inequalities in high dimensions, Acta Math. 184 (2000), no. 1, 87–111</ref> \nFor <math>\\gamma=1/2,\\,n=1</math> D. Hundertmark, E. H. Lieb and L. E. Thomas <ref>D. Hundertmark, E. H. Lieb and L. E. Thomas, A sharp bound for an eigenvalue moment of the one-dimensional Schrödinger operator, Adv. Theor. Math. Phys. 2 (1998), no. 4, 719–731</ref> proved that the best constant is given by <math>L_{1/2,1}=2L_{1/2,1}^{\\mathrm{cl}}=1/2</math>.\n\nOn the other hand, it is known that <math>L^\\mathrm{cl}_{\\gamma,n}<L_{\\gamma,n}</math> for <math>1/2\\le\\gamma<3/2, n=1</math><ref name =\"LT1976\"/> and for <math>\\gamma<1,d\\ge1</math>.<ref>B. Helffer and D. Robert, Riesz means of bounded states and semi-classical limit connected with a Lieb–Thirring conjecture. II, Ann. Inst. H. Poincaré Phys. Théor. 53 (1990), no. 2, 139–147</ref> \nIn the former case Lieb and Thirring conjectured that the sharp constant is given by\n\n:<math>\nL_{\\gamma,1}=2L^\\mathrm{cl}_{\\gamma,1}\\left(\\frac{\\gamma-\\frac12}{\\gamma+\\frac12}\\right)^{\\gamma-\\frac12}.\n</math>\n\nThe best known value for the physical relevant constant <math>L_{1,3}</math> is <math>\\pi L_{1,3}^\\mathrm{cl}/\\sqrt{3}</math> <ref>J. Dolbeault, A. Laptev, and M. Loss, Lieb–Thirring inequalities with improved constants, J. Eur. Math. Soc. (JEMS) 10 (2008), no. 4, 1121–1126</ref> and the smallest known constant in the Cwikel–Lieb–Rosenbljum inequality is <math>6.869L_{0,n}^\\mathrm{cl} </math>.<ref name =\"L1976\"/> \nA complete survey of the presently best known values for <math>L_{\\gamma,n}</math> can be found in the literature.<ref>A. Laptev, Spectral inequalities for partial differential equations and their applications, Fifth International Congress of Chinese Mathematicians. Part 1, 2, AMS/IP Stud. Adv. Math., 51, pt. 1, vol. 2, Amer. Math. Soc., Providence, RI, 2012, pp. 629–643</ref>\n\n==Kinetic energy inequalities==\nThe Lieb–Thirring inequality  for <math>\\gamma=1</math> is equivalent to a lower bound on the kinetic energy of a given normalised <math>N</math>-particle [[wave function]] <math>\\psi\\in L^2(\\mathbb{R}^{Nn})</math> in terms of the one-body density.  For an anti-symmetric wave function such that\n\n:<math>\n\\psi(x_1,\\dots,x_i,\\dots,x_j,\\dots,x_N)=-\\psi(x_1,\\dots,x_j,\\dots,x_i,\\dots,x_N)\n</math>\n\nfor all <math>1\\le i,j\\le N</math>, the one-body density is defined as\n\n:<math>\n\\rho_\\psi(x)\n=N\\int_{\\mathbb{R}^{(N-1)n}}|\\psi(x,x_2\\dots,x_N)|^2\n\\mathrm{d}^n x_2\\cdots\\mathrm{d}^n x_{N},\\, x\\in\\mathbb{R}^n.\n</math>\n\nThe Lieb–Thirring inequality ({{EquationNote|1}})  for <math>\\gamma=1</math> is equivalent to the statement that\n\n{{NumBlk|:|<math>\n\\sum_{i=1}^N \\int_{\\mathbb{R}^n}|\\nabla_i\\psi|^2\\mathrm{d}^n x_i\\ge K_n\\int_{\\mathbb{R}^n}{\\rho_\\psi(x)^{1+\\frac 2n}}\\mathrm{d}^n x\n</math>|{{EquationRef|2}}}}\n\nwhere the sharp constant <math>K_n</math> is defined via\n\n:<math>\n\\left(\\left(1+\\frac2n\\right)K_n\\right)^{1+\\frac n2}\\left(\\left(1+\\frac n2\\right)L_{1,n}\\right)^{1+\\frac2n}=1\\,.\n</math>\n\nThe inequality can be extended to particles with [[Spin (physics)|spin]] states by replacing the one-body density by the spin-summed one-body density. The constant <math>K_n</math> then has to be replaced by <math>K_n/q^{2/n}</math> where <math>q</math> is the number of quantum spin states available to each particle (<math>q=2</math> for electrons). If the wave function is symmetric, instead of anti-symmetric, such that\n\n:<math>\n\\psi(x_1,\\dots,x_i,\\dots,x_j,\\dots,x_n)=\\psi(x_1,\\dots,x_j,\\dots,x_i,\\dots,x_n)\n</math>\n\nfor all <math>1\\le i,j\\le N</math>, the constant <math>K_n</math> has to be replaced by <math>K_n/N^{2/n}</math>. \nInequality  ({{EquationNote|2}})  describes the minimum kinetic energy necessary to achieve a given density <math>\\rho_\\psi</math> with <math>N</math> particles in <math>n</math> dimensions. \nIf <math>L_{1,3}=L^\\mathrm{cl}_{1,3}</math> was proven to hold, the right-hand side of ({{EquationNote|2}}) for <math>n=3</math> would be precisely the kinetic energy term in [[Thomas–Fermi model|Thomas–Fermi]] theory.\n\nThe inequality can be compared to the [[Sobolev inequality]]. M. Rumin<ref>M. Rumin, Balanced distribution-energy inequalities and related entropy bounds, Duke Math. J. 160 (2011), no. 3, 567–597</ref> derived the kinetic energy inequality  ({{EquationNote|2}}) (with a smaller constant) directly without the use of the Lieb–Thirring inequality.\n\n==The stability of matter==\nThe kinetic energy inequality plays an important role in the proof of stability of matter as presented by Lieb and Thirring.<ref name = \"LT1976\"/> The [[Hamiltonian (quantum mechanics)|Hamiltonian]] under consideration describes a system of <math>N</math> particles with <math>q</math> spin states and <math>M</math> fixed [[Atomic nucleus|nuclei]] at locations <math>R_j\\in\\mathbb{R}^3</math> with [[Electric charge|charges]] <math>Z_j>0</math>.  The particles and nuclei interact with each other through the electrostatic [[Coulomb force]] and an arbitrary [[magnetic field]] can be introduced. If the particles under consideration are [[fermions]] (i.e. the wave function <math>\\psi</math> is antisymmetric), then the kinetic energy inequality  ({{EquationNote|2}}) holds with the constant <math>K_n/q^{2/n}</math> (not <math>K_n/N^{2/n}</math>). This is a crucial ingredient in the proof of stability of matter for a system of fermions. It ensures that the [[ground state]] energy <math>E_{N,M}(Z_1,\\dots,Z_M)</math> of the system can be bounded from below by a constant depending only on the maximum of the nuclei charges, <math>Z_{\\max}</math>, times the number of particles,\n\n:<math>\nE_{N,M}(Z_1,\\dots,Z_M)\\ge -C(Z_{\\max}) (M+N)\\,.\n</math>\n\nThe system is then stable of the first kind since the ground-state energy is bounded from below and also stable of the second kind, i.e. the energy of decreases linearly with the number of particles and nuclei. In comparison, if the particles are assumed to be [[bosons]] (i.e. the wave function <math>\\psi</math> is symmetric), then the kinetic energy inequality  ({{EquationNote|2}}) holds only with the constant <math>K_n/N^{2/n}</math>  and for the ground state energy only a bound of the form <math>-CN^{5/3}</math> holds. Since the power <math>5/3</math> can be shown to be optimal, a system of bosons is stable of the first kind but unstable of the second kind.\n\n==Generalisations==\n\nIf the Laplacian <math>-\\Delta=-\\nabla^2</math> is replaced by <math>(\\mathrm{i}\\nabla+A(x))^2</math>, where <math>A(x)</math> is a magnetic field vector potential in <math>\\mathbb{R}^n</math>, the Lieb–Thirring inequality  ({{EquationNote|1}}) remains true. The proof of this statement uses the diamagnetic inequality. Although all presently known constants <math>L_{\\gamma,n}</math> remain unchanged, it is not known whether this is true in general for the best possible constant.\n\nThe Laplacian can also be replaced by other powers of <math>-\\Delta</math>. In particular for the operator <math>\\sqrt{-\\Delta}</math>, a Lieb–Thirring inequality similar to  ({{EquationNote|1}}) holds with a different constant <math>L_{\\gamma,n}</math> and with the power on the right-hand side replaced by <math>\\gamma+n</math>. Analogously a kinetic inequality similar to  ({{EquationNote|2}}) holds, with <math>1+2/n</math> replaced by <math>1+1/n</math>, which can be used to prove stability of matter for the relativistic Schrödinger operator under additional assumptions on the charges <math>Z_k</math>.<ref>R. L. Frank, E. H. Lieb, and [[Robert Seiringer|R. Seiringer]], Hardy–Lieb–Thirring inequalities for fractional Schrödinger operators, J. Amer. Math. Soc. 21 (2008), no. 4, 925–950</ref>\n\nIn essence, the Lieb–Thirring inequality  ({{EquationNote|1}}) gives an upper bound on the distances of the eigenvalues <math>\\lambda_j</math> to the [[essential spectrum]] <math>[0,\\infty)</math> in terms of the perturbation <math>V</math>. Similar inequalities can be proved for [[Jacobi operator]]s.<ref>D. Hundertmark and [[Barry Simon|B. Simon]], Lieb–Thirring inequalities for Jacobi matrices, J. Approx. Theory 118 (2002), no. 1, 106–130</ref>\n\n==References==\n{{reflist}}\n\n==Literature==\n* {{cite book |author1=Lieb, E.H.  |author2=Seiringer, R.| title=The stability of matter in quantum mechanics | year=2010 | edition=1st | publisher=Cambridge University Press, Cambridge | isbn=9780521191180}}\n*{{cite journal|last1=Hundertmark|first1=D.|title=Some bound state problems in quantum mechanics|journal=Proc. Sympos. Pure Math.|date=2007|volume=76|pages=463–496|issue=Spectral theory and mathematical physics: a Festschrift in honor of Barry Simon’s 60th birthday|publisher=Amer. Math. Soc.|location=Providence, RI}}\n\n{{DEFAULTSORT:Lieb-Thirring inequality}}\n[[Category:Inequalities]]"
    },
    {
      "title": "Littlewood's 4/3 inequality",
      "url": "https://en.wikipedia.org/wiki/Littlewood%27s_4%2F3_inequality",
      "text": "In [[mathematical analysis]], '''Littlewood's 4/3 inequality''', named after [[John Edensor Littlewood]],<ref>{{cite journal|last1=Littlewood|first1=J. E.|title=On bounded bilinear forms in an infinite number of variables|journal=The Quarterly Journal of Mathematics|date=1930|issue=1|pages=164–174|doi=10.1093/qmath/os-1.1.164|bibcode=1930QJMat...1..164L}}</ref> is an inequality that holds for every complex-valued [[bilinear form]] defined on [[c0 space|''c''<sub>0</sub>]], the [[Banach space]] of scalar sequences that converge to zero.\n\nPrecisely, let ''B'':''c''<sub>0</sub> × ''c''<sub>0</sub> → ℂ or IR be a bilinear form. Then the following holds:\n\n:<math>\\left( \\sum_{i,j=1}^\\infty |B(e_i,e_j)|^{4/3} \\right)^{3/4} \\le \\sqrt{2} \\| B \\|,</math>\n\nwhere \n:<math>\\| B \\| = \\sup \\{|B(x_1,x_2)|: \\|x_i\\|_\\infty \\le 1 \\}.</math>\n\nThe exponent 4/3 is optimal, i.e., cannot be improved by a smaller exponent.<ref>{{cite journal|last1=Littlewood|first1=J. E.|title=On bounded bilinear forms in an infinite number of variables|journal=The Quarterly Journal of Mathematics|date=1930|issue=1|pages=164–174|doi=10.1093/qmath/os-1.1.164|bibcode=1930QJMat...1..164L}}</ref> It is also known that for real scalars the aforementioned constant is sharp.<ref>{{cite journal|last1=Diniz|first1=D. E.|last2=Munoz|first2=G.|last3=Pellegrino|first3=D.|last4=Seoane|first4=J.|title=Lower bounds for the Bohnenblust--Hille inequalities: the case of real scalars|journal=Proceedings of the American Mathematical Society|date=2014|issue=132|pages=575–580|doi=10.1090/S0002-9939-2013-11791-0 |arxiv=1111.3253}}</ref>\n\n==Generalizations==\n\n===Bohnenblust–Hille inequality===\nBohnenblust–Hille inequality<ref>{{cite journal|last1=Bohnenblust|first1=H. F.|last2=Hille|first2=Einar|title=On the Absolute Convergence of Dirichlet Series|journal=The Annals of Mathematics|date=1931|volume=32|issue=3|pages=600–622|doi=10.2307/1968255}}</ref> is a [[multilinear]] extension of Littlewood's inequality that states that for all ''m''-linear mapping ''M'':''c''<sub>0</sub> × ... × ''c''<sub>0</sub> → ℂ the following holds:\n\n:<math>\\left( \\sum_{i_1,\\ldots,i_m=1}^\\infty |M(e_{i_1},\\ldots,e_{i_m})|^{2m/(m+1)} \\right)^{(m+1)/(2m)} \\le 2^{(m-1)/2} \\| M \\|,</math>\n\n==See also==\n* [[Grothendieck inequality]]\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Littlewood's 4 3 inequality}}\n[[Category:Theorems in analysis]]\n[[Category:Inequalities]]\n\n\n{{Mathanalysis-stub}}"
    },
    {
      "title": "Log sum inequality",
      "url": "https://en.wikipedia.org/wiki/Log_sum_inequality",
      "text": "__NOTOC__\nThe '''log sum inequality''' is an [[inequality (mathematics)|inequality]], which is useful for proving several theorems in [[information theory]].\n\n==Statement==\nLet <math>a_1,\\ldots,a_n</math> and <math>b_1,\\ldots,b_n</math> be nonnegative numbers.  Denote the sum of all <math>a_i</math>s by <math>a</math> and the sum of all <math>b_i</math>s by <math>b</math>.  The log sum inequality states that\n\n:<math>\\sum_{i=1}^n a_i\\log\\frac{a_i}{b_i}\\geq a\\log\\frac{a}{b},</math>\n\nwith equality if and only if <math>\\frac{a_i}{b_i}</math> are equal for all <math>i</math>, in other words <math>a_i =c b_i</math> for all <math>i</math>.\n\n==Proof==\n\nNotice that after setting <math>f(x)=x\\log x</math> we have\n\n:<math>\n\\begin{align}\n\\sum_{i=1}^n a_i\\log\\frac{a_i}{b_i} & {} = \\sum_{i=1}^n b_i f\\left(\\frac{a_i}{b_i}\\right)\n = b\\sum_{i=1}^n \\frac{b_i}{b} f\\left(\\frac{a_i}{b_i}\\right) \\\\\n& {} \\geq b f\\left(\\sum_{i=1}^n \\frac{b_i}{b}\\frac{a_i}{b_i}\\right) = b f\\left(\\frac{1}{b}\\sum_{i=1}^n a_i\\right)\n= b f\\left(\\frac{a}{b}\\right) \\\\\n& {} = a\\log\\frac{a}{b},\n\\end{align}\n</math>\nwhere the inequality follows from [[Jensen's inequality]] since <math>\\frac{b_i}{b}\\geq 0</math>, <math>\\sum_i\\frac{b_i}{b}= 1</math>, and <math>f</math> is convex.\n\n==Applications==\n\nThe log sum inequality can be used to prove several inequalities in information theory such as [[Gibbs' inequality]] or the convexity of [[KL-divergence|Kullback-Leibler divergence]].\n\nFor example, to prove Gibbs' inequality it is enough to substitute <math>p_i</math>s for <math>a_i</math>s, and <math>q_i</math>s for <math>b_i</math>s to get\n\n:<math>\\mathbb{D}_{\\mathrm{KL}}(P\\|Q) \\equiv \\sum_{i=1}^n p_i \\log_2 \\frac{p_i}{q_i} \\geq 1\\log\\frac{1}{1} = 0.</math>\n\n==Generalizations==\n\nThe inequality remains valid for <math>n=\\infty</math> provided that <math>a<\\infty</math> and <math>b<\\infty</math>.\nThe proof above holds for any function <math>g</math> such that <math>f(x)=xg(x)</math> is convex, such as all continuous non-decreasing functions. Generalizations to convex functions other than the logarithm is given in Csiszár, 2004.\n\n==References==\n* T.S. Han, K. Kobayashi, ''Mathematics of information and coding.'' American Mathematical Society, 2001. {{isbn|0-8218-0534-7}}.\n* Information Theory course materials, Utah State University [http://ocw.usu.edu/Electrical_and_Computer_Engineering/Information_Theory/lecture3.pdf]. Retrieved on 2009-06-14.\n* {{cite journal\n |first1=I. |last1=Csiszár |authorlink1=Imre Csiszár\n |first2=P. |last2=Shields \n |year=2004\n |title=Information Theory and Statistics: A Tutorial\n |journal=Foundations and Trends in Communications and Information Theory\n |volume=1 |issue=4 |pages=417&ndash;528\n |doi=10.1561/0100000004\n |url=http://www.renyi.hu/~csiszar/Publications/Information_Theory_and_Statistics:_A_Tutorial.pdf |accessdate=2009-06-14\n}}\n\n[[Category:Inequalities]]\n[[Category:Information theory]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Łojasiewicz inequality",
      "url": "https://en.wikipedia.org/wiki/%C5%81ojasiewicz_inequality",
      "text": "In [[real algebraic geometry]], the ''' Łojasiewicz inequality''', named after [[Stanisław Łojasiewicz]], gives an upper bound for the distance of a point to the nearest zero of a given [[real analytic function]].  Specifically, let ƒ&nbsp;:&nbsp;''U''&nbsp;→&nbsp;'''R''' be a real analytic function on an [[open set]] ''U'' in '''R'''<sup>''n''</sup>, and let ''Z'' be the zero [[locus (mathematics)|locus]] of ƒ. Assume that ''Z'' is not empty.  Then for any [[compact set]] ''K'' in ''U'', there exist positive constants α and ''C'' such that, for all  ''x'' in ''K'' \n\n:<math>\\operatorname{dist}(x,Z)^\\alpha \\le C|f(x)|. </math>\n\nHere α can be large.\n\nThe following form of this inequality is often seen in more analytic contexts:  with the same assumptions on ƒ, for every ''p''&nbsp;∈&nbsp;''U'' there is a possibly smaller open neighborhood ''W'' of ''p'' and constants θ&nbsp;∈&nbsp;(0,1) and ''c''&nbsp;>&nbsp;0 such that\n\n:<math>|f(x)-f(p)|^\\theta\\le c|\\nabla f(x)|. </math>\n\n==References==\n*{{Citation | last1=Bierstone | first1=Edward | last2=Milman | first2=Pierre D. | title=Semianalytic and subanalytic sets |mr=972342 | year=1988 | journal=[[Publications Mathématiques de l'IHÉS]] | issn=1618-1913 | issue=67 | pages=5–42|url=http://www.numdam.org/item?id=PMIHES_1988__67__5_0}}\n*{{Citation | doi=10.2307/2153965 | last1=Ji | first1=Shanyu | last2=Kollár | first2=János | last3=Shiffman | first3=Bernard | title=A global Łojasiewicz inequality for algebraic varieties |mr=1046016 | url=http://www.ams.org/journals/tran/1992-329-02/S0002-9947-1992-1046016-6/ | year=1992 | journal=[[Transactions of the American Mathematical Society]] | issn=0002-9947 | volume=329 | issue=2 | pages=813–818 | jstor=2153965}}\n\n{{mathanalysis-stub}}\n{{DEFAULTSORT:Lojasiewicz inequality}}\n[[Category:Inequalities]]\n[[Category:Mathematical analysis]]\n[[Category:Real algebraic geometry]]"
    },
    {
      "title": "Lubell–Yamamoto–Meshalkin inequality",
      "url": "https://en.wikipedia.org/wiki/Lubell%E2%80%93Yamamoto%E2%80%93Meshalkin_inequality",
      "text": "In [[combinatorics|combinatorial]] [[mathematics]], the '''Lubell–Yamamoto–Meshalkin inequality''', more commonly known as the '''LYM inequality''', is an inequality on the sizes of sets in a [[Sperner family]], proved by {{harvtxt|Bollobás|1965}}, {{harvtxt|Lubell|1966}}, {{harvtxt|Meshalkin|1963}}, and  {{harvtxt|Yamamoto|1954}}. It is named for the initials of three of its discoverers.\n\nThis inequality belongs to the field of [[combinatorics]] of sets, and has many applications in combinatorics. In particular, it can be used to prove [[Sperner's theorem]]. Its name is also used for similar inequalities.\n\n==Statement of the theorem==\nLet ''U'' be an ''n''-element set, let ''A'' be a family of subsets of ''U'' such that no set in ''A'' is a subset of another set in ''A'', and let ''a<sub>k</sub>'' denote the number of sets of size ''k'' in ''A''. Then\n: <math>\\sum_{k=0}^n\\frac{a_k}{{n \\choose k}} \\le 1.</math>\n\n==Lubell's proof==\n{{harvtxt|Lubell|1966}} proves the Lubell–Yamamoto–Meshalkin inequality by a [[double counting (proof technique)|double counting argument]] in which he counts the [[permutation]]s of ''U'' in two different ways. First, by counting all permutations of ''U'' directly, one finds that there are ''n''! of them. But secondly, one can generate a permutation (i.e., an order) of the elements of ''U'' by selecting a set ''S'' in ''A'' and concatenating a permutation of the elements of ''S'' with a permutation of the nonmembers (elements of ''U\\S''). If |''S''|&nbsp;=&nbsp;''k'', it will be associated in this way with ''k''!(''n''&nbsp;&minus;&nbsp;''k'')! permutations, and in each of them the first ''k'' elements will be just the elements of ''S''. Each permutation can only be associated with a single set in ''A'', for if two prefixes of a permutation both formed sets in ''A'' then one would be a subset of the other. Therefore, the number of permutations that can be generated by this procedure is\n:<math>\\sum_{S\\in A}|S|!(n-|S|)!=\\sum_{k=0}^n a_k k! (n-k)!.</math>\nSince this number is at most the total number of all permutations,\n:<math>\\sum_{k=0}^n a_k k! (n-k)!\\le n!.</math>\nFinally dividing the above inequality by ''n''! leads to the result.\n\n== References ==\n\n*{{citation\n | first = B. | last = Bollobás | authorlink = Béla Bollobás\n | title = On generalized graphs\n | journal = Acta Mathematica Academiae Scientiarum Hungaricae\n | volume = 16 | issue = 3–4 | pages = 447–452 | year = 1965\n | doi = 10.1007/BF01904851 |mr=0183653 }}.\n\n*{{citation\n | last = Lubell | first = D.\n | year = 1966\n | title = A short proof of Sperner's lemma\n | journal = Journal of Combinatorial Theory\n | volume = 1 | issue = 2 | pages = 299\n | doi = 10.1016/S0021-9800(66)80035-2 |mr=0194348 }}.\n\n*{{citation\n | last = Meshalkin | first = L. D.\n | year = 1963\n | title = Generalization of Sperner's theorem on the number of subsets of a finite set\n | journal = Theory of Probability and Its Applications\n | volume = 8 | issue = 2 | pages = 203–204\n | doi = 10.1137/1108023 |mr=0150049 }}.\n\n*{{citation\n | last = Yamamoto | first = Koichi\n | year = 1954\n | title = Logarithmic order of free distributive lattice\n | journal = Journal of the Mathematical Society of Japan\n | volume = 6 | pages = 343–353\n |mr=0067086\n | doi=10.2969/jmsj/00630343}}.\n\n{{DEFAULTSORT:Lubell-Yamamoto-Meshalkin inequality}}\n[[Category:Combinatorics]]\n[[Category:Inequalities]]\n[[Category:Order theory]]\n[[Category:Set families]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Mahler's inequality",
      "url": "https://en.wikipedia.org/wiki/Mahler%27s_inequality",
      "text": "In [[mathematics]], '''Mahler's inequality''', named after [[Kurt Mahler]], states that the [[geometric mean]] of the term-by-term sum of two finite sequences of positive numbers is greater than or equal to the sum of their two separate geometric means:\n\n:<math>\\prod_{k=1}^n (x_k + y_k)^{1/n} \\ge \\prod_{k=1}^n x_k^{1/n} + \\prod_{k=1}^n y_k^{1/n}</math>\n\nwhen ''x''<sub>''k''</sub>, ''y''<sub>''k''</sub> > 0 for all ''k''.\n\n== Proof ==\nBy the [[inequality of arithmetic and geometric means]], we have:\n\n:<math>\\prod_{k=1}^n \\left({x_k \\over x_k + y_k}\\right)^{1/n} \\le {1 \\over n} \\sum_{k=1}^n {x_k \\over x_k + y_k},</math>\n\nand\n\n: <math>\\prod_{k=1}^n \\left({y_k \\over x_k + y_k}\\right)^{1/n} \\le {1 \\over n} \\sum_{k=1}^n {y_k \\over x_k + y_k}.</math>\n\nHence,\n\n:<math>\\prod_{k=1}^n \\left({x_k \\over x_k + y_k}\\right)^{1/n}  + \\prod_{k=1}^n \\left({y_k \\over x_k + y_k}\\right)^{1/n} \\le {1 \\over n} n = 1.</math>\n\n[[Clearing denominators]] then gives the desired result.\n\n== See also ==\n*[[Minkowski's inequality]]\n\n== References ==\n*http://eom.springer.de/M/m064060.htm\n\n[[Category:Inequalities]]\n[[Category:Articles containing proofs]]\n\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Markov brothers' inequality",
      "url": "https://en.wikipedia.org/wiki/Markov_brothers%27_inequality",
      "text": "In [[mathematics]], the '''Markov brothers' inequality''' is an [[inequality (mathematics)|inequality]] proved in the 1890s by brothers [[Andrey Markov]] and [[Vladimir Andreevich Markov|Vladimir Markov]], two Russian mathematicians. This inequality bounds the maximum of the [[derivative]]s of a polynomial on an interval in terms of the maximum of the polynomial.<ref>{{cite book|last=Achiezer|first=N.I.|authorlink=Naum Akhiezer|title=Theory of approximation|publisher=Dover Publications, Inc.|location=New York|year=1992}}</ref> For ''k'' = 1 it was proved by Andrey Markov,<ref>{{cite journal|last=Markov|first=A.A.|authorlink=Andrey Markov|title=On a question by D. I. Mendeleev|journal=Zap. Imp. Akad. Nauk. St. Petersburg|volume=62|year=1890|pages=1&ndash;24}}</ref> and for ''k'' = 2,3,... by his brother Vladimir Markov.<ref>{{cite journal|last=Markov|first=V.A.|authorlink=Vladimir Andreevich Markov|title=О функциях, наименее уклоняющихся от нуля в данном промежутке (On Functions of Least Deviation from Zero in a Given Interval)|year=1892}} Appeared in German with a foreword by [[Sergei Bernstein]] as {{cite journal|last=Markov|first=V.A.|authorlink=Vladimir Andreevich Markov|title=Über Polynome, die in einem gegebenen Intervalle möglichst wenig von Null abweichen|journal=Math. Ann.|volume=77|year=1916|pages=213–258|doi=10.1007/bf01456902|url=https://zenodo.org/record/1428284}}</ref>\n\n==The statement==\nLet ''P'' be a polynomial of degree ≤ ''n''.  Then\n\n: <math> \\max_{-1 \\leq x \\leq 1} |P^{(k)}(x)| \\leq \\frac{n^2 (n^2 - 1^2) (n^2 - 2^2) \\cdots (n^2 - (k-1)^2)}{1 \\cdot 3 \\cdot 5 \\cdots (2k-1)} \\max_{-1 \\leq x \\leq 1} |P(x)|. </math>\n\nEquality is attained for [[Chebyshev polynomials]] of the first kind.\n\n==Related inequalities==\n* [[Bernstein's inequality (mathematical analysis)]]\n* [[Remez inequality]]\n\n==Applications==\nMarkov's inequality is used to obtain lower bounds in [[computational complexity theory]] via the so-called [http://www.scottaaronson.com/talks/polymeth.ppt \"Polynomial Method\"].\n\n==References==\n{{Reflist}}\n\n[[Category:Theorems in analysis]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Mashreghi–Ransford inequality",
      "url": "https://en.wikipedia.org/wiki/Mashreghi%E2%80%93Ransford_inequality",
      "text": "In [[Mathematics]], the '''Mashreghi–Ransford inequality''' is a bound on the growth rate of certain [[sequences]].  It is named after J.&nbsp;Mashreghi and [[Thomas Ransford|T.&nbsp;Ransford]].\n\nLet <math>(a_n)_{n \\geq 0}</math> be a sequence of [[complex number]]s, and let\n\n: <math> b_n = \\sum_{k=0}^n {n\\choose k} a_k, \\qquad (n \\geq 0),</math>\n\nand\n\n: <math> c_n = \\sum_{k=0}^n (-1)^{k} {n\\choose k} a_k, \\qquad (n \\geq 0).</math>\n\nWe remind that the [[binomial coefficients]] are defined by\n\n: <math> {n\\choose k} = \\frac{n!}{k! (n-k)!}.</math>\n\nAssume that, for some <math>\\beta>1</math>, we have <math>b_n = O(\\beta^n)</math> and <math>c_n = O(\\beta^n)</math> as <math>n \\to \\infty</math>. Then\n\n: <math>a_n = O(\\alpha^n)</math>, as <math>n \\to \\infty</math>,\n\nwhere <math>\\alpha=\\sqrt{\\beta^2-1}.</math>\n\nMoreover, there is a [[universal constant]] <math>\\kappa</math> such that\n\n:<math> \\left( \\limsup_{n \\to \\infty} \\frac{|a_n|}{\\alpha^n} \\right) \\leq \\kappa \\, \\left( \\limsup_{n \\to \\infty} \\frac{|b_n|}{\\beta^n} \\right)^{\\frac{1}{2}}  \\left( \\limsup_{n \\to \\infty} \\frac{|c_n|}{\\beta^n} \\right)^{\\frac{1}{2}}.</math>\n\nThe precise value of <math>\\kappa</math> is unknown. However, it is known that\n\n: <math> \\frac{2}{\\sqrt{3}}\\leq \\kappa \\leq 2.</math>\n\n==References==\n\n* {{cite journal |  last1=Mashreghi | first1=J. | last2=Ransford | first2=T. | title=Binomial sums and functions of exponential type | journal=Bull. London Math. Soc. | volume=37 | number=01 | pages=15–24 | year=2005 | url=http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=277266}}.\n\n{{DEFAULTSORT:Mashreghi-Ransford inequality}}\n[[Category:Inequalities]]"
    },
    {
      "title": "Max–min inequality",
      "url": "https://en.wikipedia.org/wiki/Max%E2%80%93min_inequality",
      "text": "In mathematics, the '''max–min inequality''' is as follows:  for any function ''f'': ''Z'' × ''W'' → ℝ,\n: <math>\n\\sup_{z \\in Z} \\inf_{w \\in W} f(z, w) \\leq \\inf_{w \\in W} \\sup_{z \\in Z} f(z, w).\n</math>\n\nWhen equality holds one says that ''f'', ''W'' and ''Z'' satisfies a strong max–min property (or a [[saddle point|saddle-point]] property). As the function ''f''(''z'',''w'')=sin(''z''+''w'')  illustrates, this equality does not always hold. A theorem giving conditions on ''f'', ''W'' and ''Z'' in order to guarantee the saddle point property is called a [[minimax theorem]].\n\n== Intuitive Proof ==\nThis is essentially the same proof used below.\n\nSuppose you have a plot of land, which need not be rectangular; two different directions that you consider horizontal and vertical, which need not be orthogonal, and where either <math> z </math> or <math> w </math> can be the horizontal or vertical direction; and where <math>f(z,w)</math> is the elevation of the plot of land at <math> z </math> and <math> w </math> as measured by our horizontal and vertical directions. Now suppose you cut up this plot of land into tiny horizontal strips. Each strip that the plot of land is cut into will have some lowest elevation such that there is nowhere on that strip that has a lower elevation, but at least one point will have that same elevation. Now let's suppose that we put one red pebble on each strip of land at a point that is equal to that elevation. No matter where we go in our plot of land, the red pebble to the left or the right of the strip that we are on (or perhaps even under our feet) will be either lower than us or at the same elevation as us.\n\nWe must now do the same thing with blue pebbles, but with vertical strips and with points that are at a highest elevation on each strip. Are there any red pebbles which are higher than blue pebbles? Suppose we have one red pebble higher than a blue pebble. That would mean that the lowest piece of the horizontal strip of land the red pebble is on is higher than the vertical strip of land the blue pebble is on. Now think about walking from the blue pebble to one of the points where the two pieces of land intersect. Because the blue pebble is at a highest point, this means that we must have gone down in elevation. Because we are on the horizontal piece of land that the red pebble is on, and the red pebble has a higher elevation than the blue pebble, and we have gone down in elevation since we were on the blue pebble, that means we must be well below the red pebble. However, the red pebble was supposed to be at the lowest point on the horizontal strip of land that we are standing on. We have thus proven by contradiction that there is no red pebble higher than any blue pebble. If our land is completely flat, and so there is the same elevation everywhere, that means that we can have a situation where there is a red pebble at the same elevation as a blue pebble. That means that the highest of the red pebbles is no higher, but can be as high as, the lowest of the blue pebbles.\n\nIf we put that more succinctly, that means that we have proven that the highest of the lowest of the horizontal strip's points is no higher than the lowest of the highest of the vertical strip's points. If we cut the strips into narrower and narrower strips, we can see that this intuitive proof holds for continuums. We can see that this proof holds for any coordinate system as well by imagining twisting the strip of land into various rough shapes where <math>f(z,w)</math> is the \"elevation\" at that point from the \"ideal\" shape.\n\nIn fact, we can show intuitively that this holds for discrete sets as well. Suppose that <math>W</math> is the set <math>\\{\\text{plate}, \\text{bowl}\\}</math>, and <math>Z</math> is the set <math>\\{\\text{cat}, \\text{dog}, \\text{mouse}\\}</math>, and we define <math>f(z,w)</math> completely as follows:\n\n<math>f(\\text{cat},\\text{plate}) = 1</math>\n\n<math>f(\\text{cat},\\text{bowl}) = 3</math>\n\n<math>f(\\text{dog},\\text{plate}) = 6</math>\n\n<math>f(\\text{dog},\\text{bowl}) = 2</math>\n\n<math>f(\\text{mouse},\\text{plate}) = 4</math>\n\nWe can see that:\n\n<math>\\inf_{z\\in Z} f(z,\\text{plate}) = 1</math>\n\n<math>\\inf_{z\\in Z} f(z,\\text{bowl}) = 2</math>\n\nWhich means that their supremum is:\n\n<math>\\sup_{w\\in W}\\inf_{z\\in Z} f(z,w) = 2</math>\n\nWe can also see that:\n\n<math>\\sup_{w\\in W} f(\\text{cat},w) = 3</math>\n\n<math>\\sup_{w\\in W} f(\\text{dog},w) = 6</math>\n\n<math>\\sup_{w\\in W} f(\\text{mouse},w) = 4</math>\n\nWhich means that their infimum is:\n\n<math>\\inf_{z\\in Z}\\sup_{w\\in W} f(z,w) = 3</math>\n\nAnd so since <math>2\\le3</math>,\n\n<math>\\sup_{w\\in W}\\inf_{z\\in Z} f(z,w)\\le\\inf_{z\\in Z}\\sup_{w\\in W} f(z,w)</math>\n\nAnd one can play around with different numbers and discrete sets to convince oneself of this fact. Another, perhaps more geometric, way of imagining discrete sets is to imagine the plot of land with the red and blue pebbles again, but cut into a grid with some of the squares potentially missing, and we just ignore those squares (they are not negative infinity). A more rigorous symbolic proof is given in the next section.\n\n== Symbolic Proof ==\nDefine <math> g(z) \\triangleq \\inf_{w \\in W} f(z, w) </math>. \n\n<math>\\Longrightarrow g(z) \\leq f(z, w), \\forall z \\forall w </math>\n\n<math>\\Longrightarrow \\sup_z g(z) \\leq \\sup_z f(z, w) , \\forall w </math>\n\n<math>\\Longrightarrow \\sup_z \\inf_w f(z,w) \\leq \\sup_z f(z, w), \\forall w </math>\n\n<math>\\Longrightarrow \\sup_z \\inf_w f(z,w) \\leq \\inf_w \\sup_z f(z, w) \\qquad \\square</math>\n\n==References==\n*{{citation\n|first=Stephen\n|last=Boyd\n|first2=Lieven\n|last2=Vandenberghe\n|title=Convex Optimization\n|url=https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf\n|publisher=[[Cambridge University Press]] \n|year=2004}}\n\n==See also==\n* [[Minimax theorem]]\n\n{{DEFAULTSORT:Max-min inequality}}\n[[Category:Mathematical optimization]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Minkowski inequality",
      "url": "https://en.wikipedia.org/wiki/Minkowski_inequality",
      "text": "{{hatnote|This page is about Minkowski's inequality for norms. See [[Minkowski's first inequality for convex bodies]] for Minkowski's inequality in convex geometry.}}\n\nIn [[mathematical analysis]], the '''Minkowski inequality''' establishes that the [[Lp space|L<sup>''p''</sup> spaces]] are [[normed vector space]]s. Let ''S'' be a [[measure space]], let {{nowrap|1 ≤ ''p'' ≤ ∞}} and let ''f'' and ''g'' be elements of L<sup>''p''</sup>(''S''). Then {{nowrap|''f'' + ''g''}} is in L<sup>''p''</sup>(''S''), and we have the [[triangle inequality]]\n\n:<math>\\|f+g\\|_p \\le \\|f\\|_p + \\|g\\|_p</math>\n\nwith equality for {{nowrap|1 < ''p'' < ∞}} if and only if ''f'' and ''g'' are positively [[linearly dependent]], i.e., {{nowrap|1=''f'' = ''λg''}} for some {{nowrap|''λ'' ≥ 0}} or {{nowrap|1=''g'' = 0}}. Here, the norm is given by:\n:<math>\\|f\\|_p = \\left( \\int |f|^p d\\mu \\right)^{\\frac{1}{p}}</math>\nif ''p'' < ∞, or in the case ''p'' = ∞ by the [[essential supremum]]\n:<math>\\|f\\|_\\infty = \\operatorname{ess\\ sup}_{x\\in S}|f(x)|.</math>\n\nThe Minkowski inequality is the triangle inequality in L<sup>''p''</sup>(''S''). In fact, it is a special case of the more general fact\n:<math>\\|f\\|_p = \\sup_{\\|g\\|_q = 1} \\int |fg| d\\mu, \\qquad \\tfrac{1}{p} + \\tfrac{1}{q} = 1</math>\n<!--, which is probably easier to prove -->where it is easy to see that the right-hand side satisfies the triangular inequality.\n\nLike [[Hölder's inequality]], the Minkowski inequality can be specialized to sequences and vectors by using the [[counting measure]]:\n\n:<math>\\biggl( \\sum_{k=1}^n |x_k + y_k|^p \\biggr)^{1/p} \\le \\biggl( \\sum_{k=1}^n |x_k|^p \\biggr)^{1/p} + \\biggl( \\sum_{k=1}^n |y_k|^p \\biggr)^{1/p}</math>\n\nfor all [[real number|real]] (or [[complex number|complex]]) numbers ''x''<sub>1</sub>, ..., ''x''<sub>''n''</sub>, ''y''<sub>1</sub>, ..., ''y''<sub>''n''</sub> and where ''n'' is the [[cardinality]] of ''S'' (the number of elements in ''S'').\n\n==Proof==\nFirst, we prove that ''f''+''g'' has finite ''p''-norm if ''f'' and ''g'' both do, which follows by\n:<math>|f + g|^p \\le 2^{p-1}(|f|^p + |g|^p).</math>\nIndeed, here we use the fact that <math>h(x)=x^p</math> is [[convex function|convex]] over {{math|'''R'''<sup>+</sup>}} (for {{math|''p'' > 1}}) and so,  by the definition of convexity,\n:<math>\\left|\\tfrac{1}{2} f + \\tfrac{1}{2} g\\right|^p\\le\\left|\\tfrac{1}{2} |f| + \\tfrac{1}{2} |g|\\right|^p \\le \\tfrac{1}{2}|f|^p + \\tfrac{1}{2} |g|^p.</math>\nThis means that\n:<math>|f+g|^p \\le \\tfrac{1}{2}|2f|^p + \\tfrac{1}{2}|2g|^p=2^{p-1}|f|^p + 2^{p-1}|g|^p.</math>\n\nNow, we can legitimately talk about <math>(\\|f + g\\|_p)</math>. If it is zero, then Minkowski's inequality holds. We now assume that <math>(\\|f + g\\|_p)</math> is not zero. Using the triangle inequality and then [[Hölder's inequality]], we find that\n\n:<math>\\begin{align}\n\\|f + g\\|_p^p &= \\int |f + g|^p \\, \\mathrm{d}\\mu \\\\\n&= \\int |f + g| \\cdot |f + g|^{p-1} \\, \\mathrm{d}\\mu \\\\\n&\\le \\int (|f| + |g|)|f + g|^{p-1} \\, \\mathrm{d}\\mu \\\\\n&=\\int |f||f + g|^{p-1} \\, \\mathrm{d}\\mu+\\int |g||f + g|^{p-1} \\, \\mathrm{d}\\mu \\\\\n&\\le \\left( \\left(\\int |f|^p \\, \\mathrm{d}\\mu\\right)^{\\frac{1}{p}} + \\left (\\int |g|^p \\,\\mathrm{d}\\mu\\right)^{\\frac{1}{p}} \\right) \\left(\\int |f + g|^{(p-1)\\left(\\frac{p}{p-1}\\right)} \\, \\mathrm{d}\\mu \\right)^{1-\\frac{1}{p}} && \\text{ Hölder's inequality} \\\\\n&= \\left (\\|f\\|_p + \\|g\\|_p \\right )\\frac{\\|f + g\\|_p^p}{\\|f + g\\|_p}\n\\end{align}</math>\n\nWe obtain Minkowski's inequality by multiplying both sides by\n\n:<math>\\frac{\\|f + g\\|_p}{\\|f + g\\|_p^p}.</math>\n\n==Minkowski's integral inequality==\nSuppose that  {{nowrap|(''S''<sub>1</sub>, ''μ''<sub>1</sub>)}} and {{nowrap|(''S''<sub>2</sub>, ''μ''<sub>2</sub>)}} are two ''σ''-finite measure spaces and {{nowrap|''F''′ : ''S''<sub>1</sub> × ''S''<sub>2</sub> → '''R'''}} is measurable.  Then Minkowski's integral inequality is {{harv|Stein|1970|loc=§A.1}}, {{harv|Hardy|Littlewood|Pólya|1988|loc=Theorem 202}}:\n\n:<math> \\left[\\int_{S_2}\\left|\\int_{S_1}F(x,y)\\, \\mu_1(\\mathrm{d}x)\\right|^p \\mu_2(\\mathrm{d}y)\\right]^{\\frac{1}{p}} \\le \\int_{S_1}\\left(\\int_{S_2}|F(x,y)|^p\\,\\mu_2(\\mathrm{d}y)\\right)^{\\frac{1}{p}}\\mu_1(\\mathrm{d}x),</math>\n\nwith obvious modifications in the case {{nowrap|1=''p'' = ∞}}.  If {{nowrap|''p'' > 1}}, and both sides are finite, then equality holds only if {{nowrap|1={{abs|''F''(''x'', ''y'')}} = ''φ''(''x'')''ψ''(''y'')}} a.e. for some non-negative measurable functions ''φ'' and ''ψ''.\n\nIf μ<sub>1</sub> is the counting measure on a two-point set {{nowrap|1=''S''<sub>1</sub> = {1,2},}} then Minkowski's integral inequality gives the usual Minkowski inequality as a special case: for putting {{nowrap|1=''f''<sub>''i''</sub>(''y'') = ''F''(''i'', ''y'')}} for {{nowrap|1=''i'' = 1, 2}}, the integral inequality gives\n\n:<math>\\|f_1 + f_2\\|_p  = \\left(\\int_{S_2}\\left|\\int_{S_1}F(x,y)\\,\\mu_1(\\mathrm{d}x)\\right|^p\\mu_2(\\mathrm{d}y)\\right)^{\\frac{1}{p}} \\le\\int_{S_1}\\left(\\int_{S_2}|F(x,y)|^p\\,\\mu_2(\\mathrm{d}y)\\right)^{\\frac{1}{p}}\\mu_1(\\mathrm{d}x)=\\|f_1\\|_p + \\|f_2\\|_p.</math>\n\nThis notation has been generalized to\n\n:<math>\\|f\\|_{p,q}  = \\left(\\int_{\\mathbb{R}^m} \\left[\\int_{\\mathbb{R}^n}|f(x,y)|^q\\mathrm{d}y\\right]^{\\frac{p}{q}} \\mathrm{d}x \\right)^{\\frac{1}{p}}</math>\n\nfor <math>f:\\mathbb{R}^{m+n}\\to E</math>, with <math>\\mathcal{L}_{p,q}(\\mathbb{R}^{m+n},E) = \\{f\\in E^{\\mathbb{R}^{m+n}} : \\|f\\|_{p,q} < \\infty\\}</math>.\n\n== See also ==\n*[[Cauchy–Schwarz inequality]]\n*[[Mahler's inequality]]\n*[[Hölder's inequality]]\n\n==References==\n* {{Cite book|last1=Hardy|first1=G. H.|author1-link=G. H. Hardy|last2=Littlewood|first2=J. E.|author2-link=John Edensor Littlewood|last3= Pólya|  first3  = G.| author3-link = George Pólya|    title = Inequalities|series = Cambridge Mathematical Library|  edition = second| publisher = Cambridge University Press| location = Cambridge|     year = 1952|isbn  = 0-521-35880-9}}\n* {{Cite journal|first=H.|last=Minkowski|authorlink=Hermann Minkowski|title=Geometrie der Zahlen| publisher=Chelsea |year=1953 |ref=harv| postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}}}.\n* {{Cite journal|first=Elias|last=Stein|authorlink=Elias Stein|title=Singular integrals and differentiability properties of functions|publisher=Princeton University Press|year=1970|ref=harv|postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}}}.\n*{{springer|id=M/m064060|title=Minkowski inequality|author=M.I. Voitsekhovskii}}\n*{{cite web|title=Introduction to Inequalities|url= |author=Arthur Lohwater|year=1982}}\n\n[[Category:Inequalities]]\n[[Category:Articles containing proofs]]\n[[Category:Measure theory]]"
    },
    {
      "title": "Morse inequalities",
      "url": "https://en.wikipedia.org/wiki/Morse_inequalities",
      "text": "#redirect [[Morse theory#Morse inequalities]]\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Muirhead's inequality",
      "url": "https://en.wikipedia.org/wiki/Muirhead%27s_inequality",
      "text": "In [[mathematics]], '''Muirhead's inequality''', named after [[Robert Franklin Muirhead]], also known as the \"bunching\" method, generalizes the [[inequality of arithmetic and geometric means]].\n\n==Preliminary definitions==\n\n===''a''-mean===\n\nFor any [[real number|real]] [[vector space|vector]]\n\n:<math>a=(a_1,\\dots,a_n)</math>\n\ndefine the \"''a''-mean\" [''a''] of positive real numbers ''x''<sub>1</sub>, ..., ''x''<sub>''n''</sub> by\n\n:<math>[a]=\\frac{1}{n!}\\sum_\\sigma x_{\\sigma_1}^{a_1}\\cdots x_{\\sigma_n}^{a_n},</math>\n\nwhere the sum extends over all [[permutation]]s σ of { 1, ..., ''n'' }.\n\nWhen the elements of ''a'' are nonnegative integers,  the ''a''-mean can be equivalently defined via the [[monomial symmetric polynomial]] <math>m_a(x_1,\\dots,x_n)</math> as\n:<math>[a] = \\frac{k_1!\\cdots k_l!}{n!} m_a(x_1,\\dots,x_n),</math>\nwhere ''l'' is the number of distinct elements in ''a'', and ''k''<sub>1</sub>, ..., ''k''<sub>''l''</sub> are their multiplicities.\n\nNotice that the ''a''-mean as defined above only has the usual properties of a [[mean]] (e.g., if the mean of equal numbers is equal to them) if <math>a_1+\\cdots+a_n=1</math>. In the general case, one can consider instead <math>[a]^{1/(a_1+\\cdots+a_n)}</math>, which is called a [[Muirhead mean]].<ref>Bullen, P. S. Handbook of means and their inequalities. Kluwer Academic Publishers Group, Dordrecht, 2003. {{isbn|1-4020-1522-4}}</ref>\n\n; Examples\n* For ''a'' = (1, 0, ..., 0), the ''a''-mean is just the ordinary [[arithmetic mean]] of ''x''<sub>1</sub>, ..., ''x''<sub>''n''</sub>.\n* For ''a'' = (1/''n'', ..., 1/''n''), the ''a''-mean is the [[geometric mean]] of ''x''<sub>1</sub>, ..., ''x''<sub>''n''</sub>. \n* For ''a'' = (''x'', 1-''x''), the ''a''-mean is the [[Heinz mean]].\n\n===Doubly stochastic matrices===\n{{main|Doubly stochastic matrix}}\n\nAn ''n'' &times; ''n'' matrix ''P'' is ''[[doubly stochastic matrix|doubly stochastic]]'' precisely if both ''P'' and its transpose ''P''<sup>T</sup> are [[stochastic matrix|stochastic matrices]].  A ''stochastic matrix'' is a square matrix of nonnegative real entries in which the sum of the entries in each column is 1.  Thus, a doubly stochastic matrix is a square matrix of nonnegative real entries in which the sum of the entries in each row and the sum of the entries in each column is 1.\n\n== Statement ==\n\nMuirhead's inequality states that [''a''] ≤ [''b''] for all ''x'' such that ''x''<sub>''i''</sub> > 0 for every ''i'' ∈ { 1, ..., ''n'' } if and only if there is some doubly stochastic matrix ''P'' for which ''a'' = ''Pb''.\n\nFurthermore, in that case we have [''a''] = [''b''] if and only if ''a'' = ''b'' or all ''x''<sub>''i''</sub> are equal.\n\nThe latter condition can be expressed in several equivalent ways; one of them is given below.\n\nThe proof makes use of the fact that every doubly stochastic matrix is a weighted average of [[permutation matrix|permutation matrices]] ([[Birkhoff-von Neumann theorem]]).\n\n===Another equivalent condition===\nBecause of the symmetry of the sum, no generality is lost by sorting the exponents into decreasing order:\n\n:<math>a_1 \\geq a_2 \\geq \\cdots \\geq a_n</math>\n\n:<math>b_1 \\geq b_2 \\geq \\cdots \\geq b_n.</math>\n\nThen the existence of a doubly stochastic matrix ''P'' such that ''a'' = ''Pb'' is equivalent to the following system of inequalities:\n\n:<math>\n\\begin{align}\na_1 & \\leq b_1 \\\\\na_1+a_2 & \\leq b_1+b_2 \\\\\na_1+a_2+a_3 & \\leq b_1+b_2+b_3 \\\\\n& \\,\\,\\, \\vdots \\\\\na_1+\\cdots +a_{n-1} & \\leq b_1+\\cdots+b_{n-1} \\\\\na_1+\\cdots +a_n & = b_1+\\cdots+b_n.\n\\end{align}\n</math>\n\n(The ''last'' one is an equality; the others are weak inequalities.)\n\nThe sequence <math>b_1, \\ldots, b_n</math> is said to [[Majorization|'''majorize''']] the sequence <math>a_1, \\ldots, a_n</math>.\n\n== Symmetric sum notation==\nIt is convenient to use a special notation for the sums. A success in reducing an inequality in this form means that the only condition for testing it is to verify whether one exponent sequence (<math>\\alpha_1, \\ldots, \\alpha_n</math>) majorizes the other one.\n\n:<math>\\sum_\\text{sym} x_1^{\\alpha_1} \\cdots x_n^{\\alpha_n}</math>\n\nThis notation requires developing every permutation, developing an expression made of ''n''! [[monomials]], for instance:\n\n:<math>\n\\begin{align}\n& \\sum_\\text{sym} x^3 y^2 z^0  = x^3 y^2 z^0 + x^3 z^2 y^0 + y^3 x^2 z^0 + y^3 z^2 x^0 + z^3 x^2 y^0 + z^3 y^2 x^0 \\\\\n= {} & x^3 y^2  + x^3 z^2  + y^3 x^2 + y^3 z^2  + z^3 x^2  + z^3 y^2\n\\end{align}\n</math>\n\n==Examples==\n=== Arithmetic-geometric mean inequality ===\n{{main|Inequality of arithmetic and geometric means}}\n\nLet\n:<math>a_G = \\left( \\frac 1 n , \\ldots ,  \\frac 1 n \\right)</math>\nand\n:<math>a_A = ( 1 , 0, 0, \\ldots ,  0 ).</math>\n\nWe have\n:<math>\n\\begin{align}\na_{A1} = 1 & > a_{G1} = \\frac 1 n, \\\\\na_{A1} + a_{A2} = 1 & > a_{G1} + a_{G2} = \\frac 2 n, \\\\\n& \\,\\,\\,  \\vdots \\\\\na_{A1} + \\cdots + a_{An} & = a_{G1} + \\cdots + a_{Gn} = 1.\n\\end{align}\n</math>\nThen\n: [''a<sub>A</sub>''] &ge; [''a<sub>G</sub>''],\nwhich is\n:<math>\\frac 1 {n!} (x_1^1 \\cdot x_2^0 \\cdots x_n^0 + \\cdots + x_1^0 \\cdots x_n^1) (n-1)! \\geq \\frac 1 {n!} (x_1 \\cdot \\cdots \\cdot x_n)^{1/n} n!</math>\nyielding the inequality.\n\n=== Other examples ===\nWe seek to prove that ''x''<sup>2</sup> + ''y''<sup>2</sup> ≥ 2''xy'' by using bunching (Muirhead's inequality).\nWe transform it in the symmetric-sum notation:\n\n:<math>\\sum_ \\mathrm{sym} x^2 y^0 \\ge \\sum_\\mathrm{sym} x^1 y^1.</math>\n\nThe sequence (2, 0) majorizes the sequence (1, 1), thus the inequality holds by bunching.  \n\nSimilarly, we can prove the inequality\n\n:<math>x^3+y^3+z^3 \\ge 3 x y z</math>\n\nby writing it using the symmetric-sum notation as\n\n:<math>\\sum_ \\mathrm{sym} x^3 y^0 z^0 \\ge \\sum_\\mathrm{sym} x^1 y^1 z^1, </math>\n\nwhich is the same as\n\n:<math> 2 x^3 + 2 y^3 + 2 z^3 \\ge 6 x y z. </math>\n\nSince the sequence (3, 0, 0) majorizes the sequence (1, 1, 1), the inequality holds by bunching.\n\n== See also ==\n* [[Inequality of arithmetic and geometric means]]\n* [[Doubly stochastic matrix]]\n* [[Monomial symmetric polynomial]]\n\n== Notes ==\n{{Reflist}}\n\n==References==\n*''Combinatorial Theory'' by John N. Guidi, based on lectures given by [[Gian-Carlo Rota]] in 1998, MIT Copy Technology Center, 2002.\n* Kiran Kedlaya, [https://artofproblemsolving.com/articles/files/KedlayaInequalities.pdf ''A'' < ''B'' (''A'' less than ''B'')], a guide to solving inequalities\n* {{PlanetMath |urlname=muirheadstheorem |title=Muirhead's theorem}}\n*  Hardy, G.H.; Littlewood, J.E.; Pólya, G. (1952), Inequalities, Cambridge Mathematical Library (2. ed.), Cambridge: Cambridge University Press, {{isbn|0-521-05206-8}}, {{MR|0046395}}, {{Zbl|0047.05302}}, Section&nbsp;2.18, Theorem&nbsp;45.\n\n[[Category:Inequalities]]\n[[Category:Means]]"
    },
    {
      "title": "Nesbitt's inequality",
      "url": "https://en.wikipedia.org/wiki/Nesbitt%27s_inequality",
      "text": "In [[mathematics]], '''Nesbitt's [[inequality (mathematics)|inequality]]''' is a special case of the [[Shapiro inequality]].  It states that for positive real numbers ''a'', ''b'' and ''c'' we have:\n:<math>\\frac{a}{b+c}+\\frac{b}{a+c}+\\frac{c}{a+b}\\geq\\frac{3}{2}.</math>\n\n==Proof==\n===First proof: AM-HM===\nBy the [[Arithmetic mean|AM]]-[[Harmonic mean|HM]] inequality on <math>(a+b),(b+c),(c+a)</math>,\n:<math>\\frac{(a+b)+(a+c)+(b+c)}{3}\\geq\\frac{3}{\\displaystyle\\frac{1}{a+b}+\\frac{1}{a+c}+ \\frac{1}{b+c}}.</math>\n[[Clearing denominators]] yields\n:<math>((a+b)+(a+c)+(b+c))\\left(\\frac{1}{a+b}+\\frac{1}{a+c}+\\frac{1}{b+c}\\right)\\geq 9,</math>\nfrom which we obtain\n:<math>2\\frac{a+b+c}{b+c}+2\\frac{a+b+c}{a+c}+2\\frac{a+b+c}{a+b}\\geq9</math>\nby expanding the product and collecting like denominators.  This then simplifies directly to the final result.\n\n===Second proof: Rearrangement===\nSuppose <math> a \\ge b \\ge c </math>, we have that \n:<math>\\frac 1 {b+c} \\ge \\frac 1 {a+c} \\ge \\frac 1 {a+b} </math>\ndefine\n:<math>\\vec x = (a, b, c) </math>\n:<math>\\vec y = \\left(\\frac 1 {b+c} , \\frac 1 {a+c} , \\frac 1 {a+b}\\right) </math>\nThe scalar product of the two sequences is maximum because of the [[rearrangement inequality]] if they are arranged the same way, call <math>\\vec y_1 </math> and <math>\\vec y_2</math> the vector <math>\\vec y</math> shifted by one and by two, we have:\n:<math>\\vec x \\cdot \\vec y \\ge \\vec x \\cdot \\vec y_1</math>\n:<math>\\vec x \\cdot \\vec y \\ge \\vec x \\cdot \\vec y_2</math>\n\nAddition yields Nesbitt's inequality.\n\n===Third proof: Hilbert's Seventeenth Problem===\nThe following identity is true for all <math>a,b,c:</math>\n\n:<math>\\frac{a}{b+c}+\\frac{b}{a+c}+\\frac{c}{a+b} = \\frac{3}{2} + \\frac{1}{2} \\left(\\frac{(a-b)^2}{(a+c)(b+c)}+\\frac{(a-c)^2}{(a+b)(b+c)}+\\frac{(b-c)^2}{(a+b)(a+c)}\\right)\n\n</math>\nThis clearly proves that the left side is no less than <math>\\frac{3}{2}</math> for positive a, b and c.\n\nNote: every rational inequality can be solved by transforming it to the appropriate identity, see [[Hilbert's seventeenth problem]].\n\n===Fourth proof: Cauchy–Schwarz===\nInvoking the [[Cauchy–Schwarz inequality]] on the vectors <math>\\displaystyle\\left\\langle\\sqrt{a+b},\\sqrt{b+c},\\sqrt{c+a}\\right\\rangle,\\left\\langle\\frac{1}{\\sqrt{a+b}},\\frac{1}{\\sqrt{b+c}},\\frac{1}{\\sqrt{c+a}}\\right\\rangle</math> yields\n:<math>((b+c)+(a+c)+(a+b))\\left(\\frac{1}{b+c}+\\frac{1}{a+c}+\\frac{1}{a+b}\\right)\\geq 9,</math>\nwhich can be transformed into the final result as we did in [[Nesbitt's inequality#First proof: AM-HM|the AM-HM proof]].\n\n===Fifth proof: AM-GM===\nWe first employ a [[Ravi substitution]]: let <math>x=a+b,y=b+c,z=c+a</math>.  We then apply the [[Arithmetic mean-geometric mean inequality|AM-GM inequality]] to the set of six values <math>\\left\\{x^2z,z^2x,y^2z,z^2y,x^2y,y^2x\\right\\}</math> to obtain\n:<math>\\frac{\\left(x^2z+z^2x\\right)+\\left(y^2z+z^2y\\right)+\\left(x^2y+y^2x\\right)}{6}\\geq\\sqrt[6]{x^2z\\cdot z^2x\\cdot y^2z\\cdot z^2y\\cdot x^2y\\cdot y^2x}=xyz.</math>\nDividing by <math>xyz/6</math> yields\n:<math>\\frac{x+z}{y}+\\frac{y+z}{x}+\\frac{x+y}{z}\\geq6.</math>\nSubstituting out the <math>x,y,z</math> in favor of <math>a,b,c</math> yields\n:<math>\\frac{2a+b+c}{b+c}+\\frac{a+b+2c}{a+b}+\\frac{a+2b+c}{c+a}\\geq6</math>\n:<math>\\frac{2a}{b+c}+\\frac{2c}{a+b}+\\frac{2b}{a+c}+3\\geq6</math>\nwhich then simplifies to the final result.\n\n===Sixth proof: Titu's Screw lemma===\nTitu's lemma, a direct consequence of the [[Cauchy–Schwarz inequality]], states that for any sequence of <math>n</math> real numbers <math>(x_k)</math> and any sequence of <math>n</math> positive numbers <math>(a_k)</math>, <math>\\displaystyle\\sum_{k=1}^n\\frac{x_k^2}{a_k}\\geq\\frac{(\\sum_{k=1}^n x_k)^2}{\\sum_{k=1}^n a_k}</math>.  We use its three-term instance with <math>x</math>-sequence <math>a,b,c</math> and <math>a</math>-sequence <math>a(b+c),b(c+a),c(a+b)</math>:\n:<math>\\frac{a^2}{a(b+c)}+\\frac{b^2}{b(c+a)}+\\frac{c^2}{c(a+b)}\\geq\\frac{(a+b+c)^2}{a(b+c)+b(c+a)+c(a+b)}</math>\nBy multiplying out all the products on the lesser side and collecting like terms, we obtain\n:<math>\\frac{a^2}{a(b+c)}+\\frac{b^2}{b(c+a)}+\\frac{c^2}{c(a+b)}\\geq\\frac{a^2+b^2+c^2+2(ab+bc+ca)}{2(ab+bc+ca)},</math>\nwhich simplifies to\n:<math>\\frac{a}{b+c}+\\frac{b}{c+a}+\\frac{c}{a+b}\\geq\\frac{a^2+b^2+c^2}{2(ab+bc+ca)}+1.</math>\nBy the [[rearrangement inequality]], we have <math>a^2+b^2+c^2\\geq ab+bc+ca</math>, so the fraction on the lesser side must be at least <math>\\displaystyle\\frac{1}{2}</math>.  Thus,\n:<math>\\frac{a}{b+c}+\\frac{b}{c+a}+\\frac{c}{a+b}\\geq\\frac{3}{2}.</math>\n===Seventh proof:  Homogeneous===\nAs the left side of the inequality is homogeneous, we may assume <math>a+b+c=1</math>.  Now define <math>x=a+b</math>, <math>y=b+c</math>, and <math>z=c+a</math>.  The desired inequality turns into <math>\\frac{1-x}{x}+\\frac{1-y}{y}+\\frac{1-z}{z}\\ge \\frac{3}{2}</math>, or, equivalently, <math>\\frac{1}{x}+\\frac{1}{y}+\\frac{1}{z}\\ge 9/2</math>.  This is clearly true by Titu's Lemma.\n\n== References ==\n* Nesbitt, A.M., Problem 15114, Educational Times, 3(2), 1903.\n* Ion Ionescu, Romanian Mathematical Gazette, Volume XXXII (September 15, 1926 - August 15, 1927), page 120 \n*{{cite web|title=Introduction to Inequalities|url=http://www.mediafire.com/?1mw1tkgozzu |author=Arthur Lohwater|year=1982|publisher=Online e-book in PDF format}}\n\n==External links==\n* See [http://www.mathlinks.ro/viewtopic.php?t=207221 AoPS] for more proofs of this inequality.\n* {{PlanetMath reference|id=2875|title=Nesbitt's inequality}}\n* {{PlanetMath reference|id=2876|title=proof of Nesbitt's inequality}}\n\n{{DEFAULTSORT:Nesbitt's Inequality}}\n[[Category:Inequalities]]"
    },
    {
      "title": "Noether inequality",
      "url": "https://en.wikipedia.org/wiki/Noether_inequality",
      "text": "In [[mathematics]], the '''Noether inequality''', named after [[Max Noether]], is a property of [[compact space|compact]] minimal [[complex surface]]s that restricts the topological type of the underlying topological [[4-manifold]]. It holds more generally for minimal projective surfaces of general type over an algebraically closed field.\n\n==Formulation of the inequality==\nLet ''X'' be a smooth [[Minimal model (birational geometry)|minimal]] [[Algebraic variety#Projective varieties|projective]] [[surface of general type]] defined over an [[algebraically closed field]] (or a smooth minimal compact complex surface of general type) with canonical divisor ''K'' = −''c''<sub>1</sub>(''X''), and let ''p''<sub>g</sub> = ''h''<sup>0</sup>(''K'') be the dimension of the space of holomorphic two forms, then\n:<math> p_g \\le \\frac{1}{2} c_1(X)^2 + 2.  </math>\n\nFor complex surfaces, an alternative formulation expresses this inequality in terms of topological invariants of the underlying real oriented  four manifold. Since a surface of general type is a [[Kähler manifold|Kähler]] surface, the dimension of the maximal positive subspace in intersection form on the second cohomology is given by ''b''<sub>+</sub> =&nbsp;1&nbsp;+&nbsp;2''p''<sub>g</sub>. Moreover, by the [[Hirzebruch signature theorem]] ''c''<sub>1</sub><sup>2</sup> (''X'')&nbsp;=&nbsp;2''e''&nbsp;+&nbsp;3''σ'', where ''e'' = ''c''<sub>2</sub>(''X'') is the topological [[Euler characteristic]] and ''σ'' = ''b''<sub>+</sub>&nbsp;−&nbsp;''b''<sub>−</sub> is the signature of the [[Intersection form (4-manifold)|intersection form]]. Therefore, the Noether inequality can also be expressed as\n:<math> b_+ \\le 2 e + 3 \\sigma + 5 </math>\n\nor equivalently using ''e'' = 2 – 2 ''b''<sub>1</sub> + ''b''<sub>+</sub> + ''b''<sub>−</sub>\n:<math> b_- + 4 b_1 \\le 4b_+  + 9. </math>\n\nCombining the Noether inequality with the [[Noether formula]] 12χ=''c''<sub>1</sub><sup>2</sup>+''c''<sub>2</sub> gives\n:<math>  5 c_1(X)^2 - c_2(X) + 36 \\ge 12q </math>\nwhere ''q'' is the [[irregularity of a surface]], which leads to\na slightly weaker inequality, which is also often called the Noether inequality:\n:<math>  5 c_1(X)^2 - c_2(X) + 36 \\ge 0 \\quad (c_1^2(X)\\text{ even}) </math>\n:<math>  5 c_1(X)^2 - c_2(X) + 30 \\ge 0 \\quad (c_1^2(X)\\text{ odd}).  </math>\n\nSurfaces where equality holds (i.e. on the Noether line) are called [[Surfaces of general type#Horikawa surfaces|Horikawa surfaces]].\n\n==Proof sketch==\nIt follows from the minimal general type condition that ''K''<sup>2</sup> > 0. We may thus assume that ''p''<sub>g</sub> > 1, since the inequality is otherwise automatic.  In particular, we may assume there is an effective divisor ''D'' representing ''K''.  We then have an exact sequence\n:<math> 0 \\to H^0(\\mathcal{O}_X) \\to H^0(K) \\to H^0( K|_D) \\to H^1(\\mathcal{O}_X) \\to   </math>\n\nso <math> p_g - 1 \\le h^0(K|_D).  </math>\n\nAssume that ''D'' is smooth. By the [[adjunction formula]] ''D'' has a canonical linebundle <math>\\mathcal{O}_D(2K)</math>, therefore <math>K|_D</math> is a [[special divisor]] and the [[Clifford's theorem on special divisors|Clifford inequality]] applies, which gives\n:<math> h^0(K|_D) - 1 \\le \\frac{1}{2}\\mathrm{deg}_D(K) = \\frac{1}{2}K^2.</math>\n\nIn general, essentially the same argument applies using a more general version of the Clifford inequality for local complete intersections with a dualising line bundle and 1-dimensional sections in the trivial line bundle.  These conditions are satisfied for the curve ''D'' by the adjunction formula and the fact that ''D'' is numerically connected.\n\n==References==\n* {{Citation | last1=Barth | first1=Wolf P. | last2=Hulek | first2=Klaus | last3=Peters | first3=Chris A.M. | last4=Van de Ven | first4=Antonius | title=Compact Complex Surfaces | publisher= Springer-Verlag, Berlin | series=Ergebnisse der Mathematik und ihrer Grenzgebiete. 3. Folge. | isbn=978-3-540-00832-3 |mr=2030225 | year=2004 | volume=4}}\n*{{Citation| last1=Liedtke |first1=Christian|title=Algebraic Surfaces of general type with small c<sub>1</sub><sup>2</sup> in positive characteristic|journal=Nagoya Math. J.|volume=191|year=2008|pages=111–134|\nurl=http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&id=pdf_1&handle=euclid.nmj/1221656783 }}\n*{{Citation |doi=10.1007/BF02106598 |last1=Noether |first1 = Max| title=Zur Theorie der eindeutigen Entsprechungen algebraischer Gebilde|journal=Math. Ann.|volume=8 |issue=4| year=1875|pages=495–533}}\n\n[[Category:Inequalities]]\n[[Category:Algebraic surfaces]]"
    },
    {
      "title": "Oscillatory integral operator",
      "url": "https://en.wikipedia.org/wiki/Oscillatory_integral_operator",
      "text": "In [[mathematics]], in the field of [[harmonic analysis]], an '''oscillatory integral operator''' is an [[integral operator]] of the form\n\n:<math>T_\\lambda u(x)=\\int_{\\mathbf{R}^n}e^{i\\lambda S(x,y)}a(x,y)u(y)\\,dy, \\qquad x\\in\\mathbf{R}^m, \\quad y\\in\\mathbf{R}^n,</math>\n\nwhere the function ''S(x,y)'' is called the [[phase (waves)|phase]] of the operator and the function ''a(x,y)'' is called the [[symbol of a differential operator|symbol]] of the operator.  λ is a parameter. One often considers ''S(x,y)'' to be real-valued and smooth, and ''a(x,y)'' smooth and [[compact support|compactly supported]]. Usually one is interested in the behavior of ''T''<sub>λ</sub> for large values of λ.\n\nOscillatory integral operators often appear in many fields of mathematics ([[mathematical analysis|analysis]], [[partial differential equations]], [[integral geometry]], [[number theory]]) and in physics.  Properties of oscillatory integral operators have been studied by [[Elias M. Stein|E. Stein]] and his school.<ref>Elias Stein, ''Harmonic Analysis: Real-variable Methods, Orthogonality and Oscillatory Integrals''. Princeton University Press, 1993. {{ISBN|0-691-03216-5}}</ref>\n\n==Hörmander's theorem==\nThe following bound on the ''L''<sup>2</sup> → ''L''<sup>2</sup> action of oscillatory integral operators (or [[L^2|''L''<sup>2</sup> → ''L''<sup>2</sup>]] [[operator norm]]) was obtained by [[Lars Hörmander]] in his paper on [[Fourier integral operator]]s:<ref>L. Hörmander ''Fourier integral operators'', Acta Math. '''127''' (1971), 79–183. doi 10.1007/BF02392052, http://www.springerlink.com/content/t202410l4v37r13m/fulltext.pdf</ref>\n\nAssume that ''x,y'' ∈ '''R'''<sup>''n''</sup>, ''n'' ≥ 1. Let ''S(x,y)'' be real-valued and smooth, and let ''a(x,y)'' be smooth and [[compact support|compactly supported]]. If <math>\\mathop{\\rm det}_{j,k} \\frac{\\partial^2 S}{\\partial x_j \\partial y_k}(x,y)\\ne 0</math> everywhere on the support of ''a(x,y)'', then there is a constant ''C'' such that ''T''<sub>λ</sub>, which is initially defined on [[smooth functions]], [[continuous linear extension|extends]] to a [[continuous operator]] from ''L''<sup>2</sup>('''R'''<sup>''n''</sup>) to ''L''<sup>2</sup>('''R'''<sup>''n''</sup>), with the [[operator norm|norm]] bounded by <math>C \\lambda^{-n/2} </math>, for any λ ≥ 1:\n\n:<math>||T_\\lambda||_{L^2(\\mathbf{R}^n)\\to L^2(\\mathbf{R}^n)}\\le C\\lambda^{-n/2}.</math>\n\n==References==\n<references />\n\n[[Category:Microlocal analysis]]\n[[Category:Harmonic analysis]]\n[[Category:Singular integrals]]\n[[Category:Fourier analysis]]\n[[Category:Integral transforms]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Peetre's inequality",
      "url": "https://en.wikipedia.org/wiki/Peetre%27s_inequality",
      "text": "In [[mathematics]], '''Peetre's inequality,''' named after [[Jaak Peetre]], says that for any [[real number]] ''t'' and any [[Vector space|vector]]s ''x'' and ''y'' in '''R'''<sup>n</sup>, the following [[Inequality (mathematics)|inequality]] holds:\n\n:<math> \\left( \\frac{1+|x|^2}{1+|y|^2} \\right)^t \\le 2^{|t|} (1+|x-y|^2)^{|t|}.</math>\n\n==References==\n*{{citation|title=Introduction to the Theory of Linear Partial Differential Equations|series=Studies in Mathematics and its Applications|first1=J.|last1=Chazarain|first2=A.|last2=Piriou|publisher=Elsevier|year=2011|isbn=9780080875354|page=90|url=https://books.google.com/books?id=Gh9XeWnOzagC&pg=PA90}}.\n*{{citation|title=Pseudo-Differential Operators and Symmetries: Background Analysis and Advanced Topics|volume=2|series=Pseudo-Differential Operators, Theory and Applications|first1=Michael|last1=Ruzhansky|first2=Ville|last2=Turunen|publisher=Springer|year=2009|isbn=9783764385132|page=321|url=https://books.google.com/books?id=DDpz_MfxZrUC&pg=PA321}}.\n*{{citation|title=Elementary Introduction to the Theory of Pseudodifferential Operators|volume=3|series=Studies in Advanced Mathematics|first=Xavier|last=Saint Raymond|publisher=CRC Press|year=1991|isbn=9780849371585|page=21|url=https://books.google.com/books?id=kD5ZCJDIg4oC&pg=PA21}}.\n\n{{PlanetMath attribution|id=4681|title=Peetre's inequality}}\n\n{{mathanalysis-stub}}\n\n[[Category:Linear algebra]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Poincaré inequality",
      "url": "https://en.wikipedia.org/wiki/Poincar%C3%A9_inequality",
      "text": "In [[mathematics]], the '''Poincaré inequality''' is a result in the theory of [[Sobolev space]]s, named after the [[France|French]] [[mathematician]] [[Henri Poincaré]]. The inequality allows one to obtain bounds on a function using bounds on its derivatives and the geometry of its domain of definition. Such bounds are of great importance in the modern, [[Direct method in calculus of variations|direct methods of the calculus of variations]]. A very closely related result is [[Friedrichs' inequality]].\n\n==Statement of the inequality==\n\n===The classical Poincaré inequality===\n\nLet ''p'', so that 1&nbsp;≤&nbsp;''p''&nbsp;<&nbsp;∞ and Ω a subset with at least one bound. Then there exists a constant ''C'', depending only on Ω and ''p'', so that, for every function ''u'' of the [[Sobolev space]] ''W''<sub>0</sub><sup>1,''p''</sup>(Ω) of zero-trace functions,\n\n:<math>\\| u \\|_{L^{p} (\\Omega)} \\leq C \\| \\nabla u \\|_{L^{p} (\\Omega)}.</math>\n\n===Poincaré–Wirtinger inequality===\n\nAssume that 1&nbsp;≤&nbsp;''p''&nbsp;≤&nbsp;∞ and that Ω is a [[bounded set|bounded]] [[connected set|connected]] [[open set|open subset]] of the ''n''-[[dimension]]al [[Euclidean space]] '''R'''<sup>''n''</sup> with a [[Lipschitz boundary]] (i.e., Ω is a [[Lipschitz domain|Lipschitz]] [[Domain (mathematical analysis)|domain]]). Then there exists a constant ''C'', depending only on Ω and ''p'', such that for every function ''u'' in the Sobolev space ''W''<sup>1,''p''</sup>(Ω),\n\n:<math>\\| u - u_{\\Omega} \\|_{L^{p} (\\Omega)} \\leq C \\| \\nabla u \\|_{L^{p} (\\Omega)},</math>\n\nwhere\n\n:<math>u_{\\Omega} = \\frac{1}{|\\Omega|} \\int_{\\Omega} u(y) \\, \\mathrm{d} y</math>\n\nis the average value of ''u'' over Ω, with |Ω| standing for the [[Lebesgue measure]] of the domain Ω. When Ω is a ball, the above inequality is\ncalled a (p,p)-Poincaré inequality; for more general domains Ω, the above is more familiarly known as a Sobolev inequality.\n\n===Generalizations===\n\nIn the context of metric measure spaces (for example, sub-Riemannian manifolds), such spaces support a (q,p)-Poincare inequality for some <math>1\\le q,p<\\infty</math> if there are constants C and <math>\\lambda\\ge 1</math> so that for each ball B in the space,\n\n:<math>\\mu(B)^{-\\frac{1}{q}} \\left \\|u-u_B \\right \\|_{L^q(B)}\\le C \\operatorname{rad}(B) \\mu(B)^{-\\frac{1}{p}} \\| \\nabla u\\|_{L^p(\\lambda B)}.</math>\n\nIn the context of metric measure spaces, <math>|\\nabla u|</math> is the minimal p-weak upper gradient of u in the sense of \nHeinonen and Koskela [J. Heinonen and P. Koskela, Quasiconformal maps in metric spaces with controlled geometry, Acta Math. 181 (1998), 1–61]\n\nThere exist other generalizations of the Poincaré inequality to other Sobolev spaces.  For example, the following (taken from {{harvtxt|Garroni|Müller|2005}}) is a Poincaré inequality for the Sobolev space ''H''<sup>1/2</sup>('''T'''<sup>2</sup>), i.e. the space of functions ''u'' in the [[Lp space|''L''<sup>2</sup> space]] of the unit [[torus]] '''T'''<sup>2</sup> with [[Fourier transform]] ''û'' satisfying\n\n:<math>[u]_{H^{1/2} (\\mathbf{T}^{2})}^2 = \\sum_{k \\in \\mathbf{Z}^2} | k | \\left | \\hat{u} (k) \\right |^2 < + \\infty:</math>\n\nthere exists a constant ''C'' such that, for every ''u''&nbsp;∈&nbsp;''H''<sup>1/2</sup>('''T'''<sup>2</sup>) with ''u'' identically zero on an open set ''E''&nbsp;⊆&nbsp;'''T'''<sup>2</sup>,\n\n:<math>\\int_{\\mathbf{T}^2} | u(x) |^2 \\, \\mathrm{d} x \\leq C \\left( 1 + \\frac1{\\operatorname{cap} (E \\times \\{ 0 \\})} \\right) [ u ]_{H^{1/2} (\\mathbf{T}^2)}^2,</math>\n\nwhere cap(''E''&nbsp;&times;&nbsp;{0}) denotes the [[harmonic capacity]] of ''E''&nbsp;&times;&nbsp;{0} when thought of as a subset of '''R'''<sup>3</sup>.\n\n==The Poincaré constant==\n\nThe optimal constant ''C'' in the Poincaré inequality is sometimes known as the '''Poincaré constant''' for the domain Ω. Determining the Poincaré constant is, in general, a very hard task that depends upon the value of ''p'' and the geometry of the domain Ω. Certain special cases are tractable, however. For example, if Ω is a [[bounded set|bounded]], [[convex set|convex]], Lipschitz domain with [[diameter]] ''d'', then the Poincaré constant is at most ''d''/2 for ''p''&nbsp;=&nbsp;1, <math>d/\\pi</math> for ''p''&nbsp;=&nbsp;2 ({{harvnb|Acosta|Durán|2004}}; {{harvnb|Payne|Weinberger|1960}}), and this is the best possible estimate on the Poincaré constant in terms of the diameter alone. For smooth functions, this can be understood as an application of the [[isoperimetric inequality]] to the function's [[level sets]]. [http://maze5.net/?page_id=790] In one dimension, this is [[Wirtinger's inequality for functions]].\n\nHowever, in some special cases the constant ''C'' can be determined concretely. For example, for ''p''&nbsp;=&nbsp;2, it is well known that over the domain of unit isosceles right triangle, ''C''&nbsp;=&nbsp;1/π (&nbsp;<&nbsp;''d''/π where <math>d=\\sqrt{2}</math>). (See, for instance, {{harvtxt|Kikuchi|Liu|2007}}.)\n\nFurthermore, for a smooth, bounded domain <math>\\Omega</math>, since the [[Rayleigh quotient]] for the [[Laplace operator]] in the space <math>W^{1,2}_0(\\Omega)</math> is minimized by the eigenfunction corresponding to the minimal eigenvalue λ<sub>1</sub> of the (negative) Laplacian, it is a simple consequence that, for any <math>u\\in W^{1,2}_0(\\Omega)</math>,\n\n:<math> \\|u\\|_{L^2}^2\\leq \\lambda_1^{-1} \\left \\|\\nabla u\\right \\|_{L^2}^2</math>\n\nand furthermore, that the constant λ<sub>1</sub> is optimal.\n\n==See also==\n*[[Friedrichs' inequality]]\n*[[Korn's inequality]]\n\n==References==\n\n* {{citation\n| last1 = Acosta|first1=Gabriel|last2=Durán|first2=Ricardo G.\n| title = An optimal Poincaré inequality in ''L''<sup>1</sup> for convex domains\n| journal = Proc. Amer. Math. Soc.\n| volume = 132\n| year = 2004\n| issue = 1\n| pages = 195–202 (electronic)\n| doi = 10.1090/S0002-9939-03-07004-7\n}}\n* {{citation\n| last = Evans|first=Lawrence C. \n| title = Partial differential equations \n| location = Providence, RI \n| publisher = American Mathematical Society \n| year = 1998\n| isbn = 0-8218-0772-2\n}}\n* {{citation\n| first1 = Fumio\n| last1 = Kikuchi \n| first2= Xuefeng|last2=Liu\n| title = Estimation of interpolation error constants for the P0 and P1 triangular finite elements\n| journal = Comput. Methods. Appl. Mech. Engrg.\n| volume = 196\n| year = 2007\n| pages = 3750–3758\n| doi = 10.1016/j.cma.2006.10.029\n| issue = 37–40\n}} {{MathSciNet|id=2340000}}\n* {{citation\n| last1 = Garroni\n| first1 = Adriana\n| last2 = Müller |first2 = Stefan\n| title = &Gamma;-limit of a phase-field model of dislocations\n| journal = SIAM J. Math. Anal.\n| volume = 36\n| year = 2005\n| issue = 6\n| pages = 1943–1964 (electronic)\n| doi = 10.1137/S003614100343768X\n}} {{MathSciNet|id=2178227}}\n* Leoni, Giovanni (2009), ''[http://bookstore.ams.org/gsm-105 A First Course in Sobolev Spaces]'', Graduate Studies in Mathematics, American Mathematical Society, pp. xvi+607 {{isbn|978-0-8218-4768-8}}, {{MR|2527916}}, {{Zbl|1180.46001}}, [http://www.maa.org/press/maa-reviews/a-first-course-in-sobolev-spaces MAA]\n*{{Citation | last1=Payne | first1=L. E. | last2=Weinberger | first2=H. F. | title=An optimal Poincaré inequality for convex domains | year=1960 | journal=Archive for Rational Mechanics and Analysis | issn=0003-9527 | pages=286–292 | doi=10.1007/BF00252910 }}\n*{{Citation | last1=Heinonen | first1=J. | last2=Koskela | first2=P. | title=Quasiconformal maps in metric spaces with controlled geometry | journal=Acta Mathematica |   doi=  10.1007/BF02392747 |issn=  1871-2509 | year=1998 | pages=1–61}}\n\n{{DEFAULTSORT:Poincare inequality}}\n[[Category:Theorems in analysis]]\n[[Category:Inequalities]]\n[[Category:Sobolev spaces]]"
    },
    {
      "title": "Poincaré separation theorem",
      "url": "https://en.wikipedia.org/wiki/Poincar%C3%A9_separation_theorem",
      "text": "In [[mathematics]], the '''Poincaré separation theorem''' gives the upper and lower bounds of [[eigenvalue]]s of a real [[symmetric matrix]] ''B<nowiki>'</nowiki>AB'' that can be considered as the [[orthogonal projection]] of a larger real symmetric matrix ''A'' onto a linear subspace spanned by the columns of&nbsp;''B''.  The theorem is named after [[Henri Poincaré]].\n\nMore specifically, let ''A'' be an ''n''&nbsp;×&nbsp;''n'' real symmetric matrix and ''B'' an ''n''&nbsp;×&nbsp;''r'' [[semi-orthogonal matrix]] such that ''B<nowiki>'</nowiki>B'' = ''I''<sub>''r''</sub>. Denote by <math>\\lambda_i</math>, ''i''&nbsp;=&nbsp;1,&nbsp;2,&nbsp;...,&nbsp;''n'' and <math>\\mu_i</math>, ''i''&nbsp;=&nbsp;1,&nbsp;2,&nbsp;...,&nbsp;''r'' the eigenvalues of ''A'' and ''B<nowiki>'</nowiki>AB'', respectively (in descending order). We have\n\n: <math>\\lambda_i \\geq \\mu_i \\geq \\lambda_{n-r+i},</math>\n\n== Proof ==\n\nAn algebraic proof, based on the [[Min-max theorem|variational interpretation of eigenvalues]], has been published in Magnus' ''Matrix Differential Calculus with Applications in Statistics and Econometrics''.<ref>{{cite book |title=Matrix Differential Calculus with Applications in Statistics and Econometrics\n|first1=Jan R.|last1=Magnus|first2=Heinz|last2=Neudecker\n|publisher=John Wiley & Sons|year=1988|isbn=0-471-91516-5|pages=209.}}</ref>   From the geometric point of view, ''B'AB'' can be considered as the [[orthogonal projection]] of ''A'' onto the linear subspace spanned by ''B'', so the above results follow immediately.<ref name=\"Bellman1997\">{{cite book|author=Richard Bellman|title=Introduction to Matrix Analysis: Second Edition|url=https://books.google.com/books?id=sP8J4oqwlLkC&pg=PA118|date=1 December 1997|publisher=SIAM|isbn=978-0-89871-399-2|pages=118–}}</ref>\n\n== References ==\n\n{{Reflist}}\n\n{{DEFAULTSORT:Poincare Separation Theorem}}\n[[Category:Inequalities]]\n[[Category:Matrix theory]]"
    },
    {
      "title": "Pólya-Vinogradov inequality",
      "url": "https://en.wikipedia.org/wiki/P%C3%B3lya-Vinogradov_inequality",
      "text": "#REDIRECT [[Character sum]]\n\n{{DEFAULTSORT:Polya-Vinogradov inequality}}\n[[Category:Inequalities]]\n[[Category:Analytic number theory]]"
    },
    {
      "title": "Popoviciu's inequality",
      "url": "https://en.wikipedia.org/wiki/Popoviciu%27s_inequality",
      "text": "{{distinguish|Popoviciu's inequality on variances}}\n{{for|a more general discussion|Bookmaker|Odds}}\n\nIn [[convex analysis]], '''Popoviciu's inequality''' is an [[inequality (mathematics)|inequality]] about [[convex function]]s. It is similar to [[Jensen's inequality]] and was found in 1965 by [[Tiberiu Popoviciu]],<ref>{{citation | author=Tiberiu Popoviciu | title=Sur certaines inégalités qui caractérisent les fonctions convexes | year=1965 | journal=Analele ştiinţifice Univ. \"Al.I. Cuza\" Iasi, Secţia I a Mat. | volume=11 | pages=155–164}}</ref> a Romanian mathematician. It states:\n\n<blockquote>Let ''f'' be a function from an interval <math>I \\subseteq \\mathbb{R}</math> to <math>\\mathbb{R}</math>. If ''f'' is [[convex function|convex]], then for any three points ''x'', ''y'', ''z'' in ''I'',\n\n:<math>\\frac{f(x)+f(y)+f(z)}{3} + f\\left(\\frac{x+y+z}{3}\\right) \\ge \\frac{2}{3}\\left[ f\\left(\\frac{x+y}{2}\\right) + f\\left(\\frac{y+z}{2}\\right) + f\\left(\\frac{z+x}{2}\\right) \\right].</math>\n\nIf a function ''f'' is [[Continuous function|continuous]], then it is convex if and only if the above inequality holds for all ''x'',&nbsp;''y'',&nbsp;''z'' from <math>I</math>.  When ''f'' is strictly convex, the inequality is strict except for&nbsp;''x''&nbsp;=&nbsp;''y''&nbsp;=&nbsp;''z''.<ref>{{citation | year=2006 | title = Convex functions and their applications: a contemporary approach | author1=Constantin Niculescu | author2= [[Lars-Erik Persson]] | publisher=Springer Science &amp; Business | isbn=978-0-387-24300-9 | page=12 | url=https://books.google.com/books?id=M5tYCzB8FQcC&pg=PA12&dq=Popoviciu%27s+inequality}}</ref></blockquote>\n\nIt can be generalised to any finite number ''n'' of points instead of&nbsp;3, taken on the right-hand side ''k'' at a time instead of 2 at a time:<ref>{{citation | year=1992 | title = Convex functions, partial orderings, and statistical applications | author1=J. E. Pečarić | author2=Frank Proschan | author3=Yung Liang Tong | publisher=Academic Press | isbn=978-0-12-549250-8 | page=171 | url=https://books.google.com/books?id=rCAOFpic7AkC&pg=PA171&dq=Popoviciu}}</ref>\n\n<blockquote>Let ''f'' be a continuous function from an interval <math>I \\subseteq \\mathbb{R}</math> to <math>\\mathbb{R}</math>. Then ''f'' is [[convex function|convex]] if and only if, for any integers ''n'' and ''k'' where ''n'' ≥ 3 and <math>2 \\leq k \\leq n-1</math>, and any ''n'' points <math>x_1, \\dots, x_n</math> from ''I'',\n\n:<math>\\frac{1}{k} \\binom{n-2}{k-2} \\left( \\frac{n-k}{k-1} \\sum_{i=1}^{n}f(x_i) + nf\\left(\\frac1n\\sum_{i=1}^{n}x_i\\right) \\right)\\ge \\sum_{1 \\le i_1 < \\dots < i_k \\le n} f\\left( \\frac1k \\sum_{j=1}^{k} x_{i_j} \\right)</math></blockquote>\n\nPopoviciu's inequality can also be generalised to a [[weighted inequality]].<ref>{{citation | year = 1976 | author1=P. M. Vasić | author2=Lj. R. Stanković | title = Some inequalities for convex functions | periodical=Math. Balkanica | issue = 6 (1976) | pages=281–288}} </ref><ref>{{cite arXiv |last=Grinberg |first=Darij |eprint=0803.2958v1 |title=Generalizations of Popoviciu's inequality |class=math.FA |year=2008}}</ref> <ref>{{cite | author1=M.Mihai | author2=[[F.-C. Mitroi-Symeonidis]] | title = New extensions of Popoviciu's inequality | periodical=Mediterr. J. Math., Volume 13 | issue =  5|  year = 2016 |  pages=3121-3133 |doi=10.1007/s00009-015-0675-3 | issn=1660-5446 }}</ref>Popoviciu's paper has been published in Romanian language, but the interested reader can find his results in the review {{Zbl|0166.06303}}. [https://zbmath.org/scans/166/063.gif Page 1] [https://zbmath.org/scans/166/064.gif Page 2]\n\n==Notes==\n{{reflist}}\n\n[[Category:Inequalities]]\n[[Category:Convex analysis]]"
    },
    {
      "title": "Purchasing power parity",
      "url": "https://en.wikipedia.org/wiki/Purchasing_power_parity",
      "text": "'''Purchasing power parity''' ('''PPP''') is a way of measuring economic variables in different countries so that ''irrelevant exchange rate variations'' do not distort comparisons. Purchasing power exchange rates are such that it would cost exactly the same number of, for example, [[US dollar]]s to buy [[euro]]s and then buy a basket of goods in the market as it would cost to purchase the same goods directly with dollars. The purchasing power exchange rate used in this conversion equals the ratio of the currencies' respective [[purchasing power]]s (reciprocals of their [[price level]]s).\n\nIn [[Neoclassical economics|neoclassical]] [[economic theory]], the ''purchasing power parity theory'' assumes that the exchange rate between two currencies actually observed in the [[foreign exchange market]] is the one that is used in the purchasing power parity comparisons, so that the same amount of goods could actually be purchased in either currency with the same beginning amount of funds. Depending on the particular theory, purchasing power parity is assumed to hold either in the [[long run]] or, more strongly, in the [[short run]]. Theories that invoke purchasing power parity assume that in some circumstances a fall in either currency's purchasing power (a rise in its price level) would lead to a proportional decrease in that currency's valuation on the [[foreign exchange market]].\n\nThe concept of purchasing power parity allows one to estimate what the exchange rate between two currencies would have to be to equate the purchasing power of the two currencies. Observed deviations of the exchange rate from purchasing power parity are measured by deviations of the [[real exchange rate]] from its PPP value. \n\nPPP exchange rates help [[costing]] but exclude profits and above all do not consider the different [[Quality (business)|quality of goods]] among countries. The same product, for instance, can have a different level of quality and even safety in different countries, and may be subject to different taxes and transport costs. Since market exchange rates fluctuate substantially, when the GDP of one country measured in its own currency is converted to the other country's currency using market exchange rates, one country might be inferred to have higher [[real GDP]] than the other country in one year but lower in the other; both of these inferences would fail to reflect the reality of their ''relative levels of production''. But if one country's GDP is converted into the other country's currency using PPP exchange rates instead of observed market exchange rates, the false inference will not occur. Essentially GDP measured at PPP controls for the different costs of living and price levels, usually relative to the United States dollar, enabling a more accurate estimate of a nation's level of production.\n\n==Concept==\n\nThe idea originated with the [[School of Salamanca]] in the 16th century, and was developed in its modern form by [[Gustav Cassel]] in 1916, in ''The Present Situation of the Foreign Trade''.<ref>{{cite journal|last=Cassel|first=Gustav|date=December 1918|title=Abnormal Deviations in International Exchanges|journal=The Economic Journal|volume= 28|issue=112|pages=413–415|jstor=2223329|doi=10.2307/2223329|url=https://zenodo.org/record/1759129}}</ref><ref name=princetonenc>{{cite encyclopedia |last=Cheung |first=Yin-Wong|editor-last=Reinert|editor-first=Kenneth A.|editor2-last=Rajan |editor2-first=Ramkishen S.|editor3-last=Glass|editor3-first=Amy Jocelyn|editor4-first=Lewis S. |display-editors = 3 |editor4-last=Davis|title=purchasing power parity|encyclopedia=The Princeton Encyclopedia of the World Economy|url=https://books.google.com/books?id=BnEDno1hTegC&pg=PA942|accessdate=2 October 2011|volume=I|year=2009|publisher=Princeton University Press |location=Princeton |isbn=978-0-691-12812-2 |page=942}}</ref>\nWhile Gustav Cassel’s use of PPP concept has been traditionally interpreted as his attempt to formulate a positive theory of exchange rate determination, the policy and theoretical context in which Cassel wrote about exchange rates suggests different interpretation.  In the years immediately preceding the end of WWI and following it economists and politicians were involved in discussions on possible ways of restoring the [[gold standard]], which would automatically restore the system of [[Fixed exchange-rate system|fixed exchange rates]] among participating nations.  The stability of exchange rates was widely believed to be crucial for restoring the international trade and for its further stable and balanced growth.  Nobody then was mentally prepared for the idea that flexible exchange rates determined by market forces do not necessarily cause chaos and instability in the peaceful time (and that is what the abandoning of the gold standard during the war was blamed for).  Gustav Cassel was among those who supported the idea of restoring the gold standard, although with some alterations.  The question, which Gustav Cassel tried to answer in his works written during that period, was not how exchange rates are determined in the free market, but rather how to determine the appropriate level at which exchange rates were to be fixed during the restoration of the system of fixed exchange rates.  His recommendation was to fix exchange rates at the level corresponding to the PPP, as he believed that this would prevent trade imbalances between trading nations.  Thus, PPP doctrine proposed by Cassel was not really a positive theory of exchange rate determination (as Cassel was perfectly aware of numerous factors that prevent exchange rates from stabilizing at PPP level if allowed to float), but rather a normative policy advice, formulated in the context of discussions on returning to the gold standard<ref>{{Cite journal|last=Kadochnikov|first=Denis|date=2013|title=Gustav Cassel's purchasing power parity doctrine in the context of his views on international economic policy coordination|journal=European Journal of the History of Economic Thought|volume=20|issue=6|pages=1101–1121|doi=10.1080/09672567.2013.824999}}</ref>. \n\nThe PPP concept is based on the [[law of one price]], where in the absence of [[transaction cost]]s and official [[trade barrier]]s, identical goods will have the same price in different markets when the prices are expressed in the same currency.<ref name=\"Krugman2\">{{cite book|last=Krugman and Obstfeld|title=International Economics|year=2009|publisher=Pearson Education, Inc.}}</ref>\n\nAnother interpretation is that the difference in the rate of change in prices at home and abroad—the difference in the inflation rates—is equal to the percentage depreciation or appreciation of the exchange rate.\n\nDeviations from parity imply differences in purchasing power of a \"basket of goods\" across countries, which means that for the purposes of many international comparisons, countries' GDPs or other national income statistics need to be \"PPP-adjusted\" and converted into common units. The best-known purchasing power adjustment is the [[Geary–Khamis dollar]] (the \"international dollar\"). The [[Exchange rate#Nominal and real exchange rates|real exchange rate]] is then equal to the nominal exchange rate, adjusted for differences in price levels. If purchasing power parity held exactly, then the real exchange rate would always equal one. However, in practice the real exchange rates exhibit both short run and long run deviations from this value, for example due to reasons illuminated in the [[Balassa–Samuelson theorem]].\n\nThere can be marked differences between purchasing power adjusted incomes and those converted via market exchange rates.<ref>{{cite web|url=http://www.ft.com/cms/s/0/36a2d566-ad82-11dc-9386-0000779fd2ac.html|title=China, India economies '40% smaller'|first=Scheherazade|last= Daneshkhu|date=18 December 2007|work=Financial Times}}</ref> For example, the [[World Bank|World Bank's]] ''World Development Indicators 2005'' estimated that in 2003, one [[Geary-Khamis dollar]] was equivalent to about 1.8 [[Renminbi|Chinese yuan]] by purchasing power parity<ref>[http://devdata.worldbank.org/wdi2005/Table5_7.htm 2005 World Development Indicators: Table 5.7 | Relative prices and exchange rates] {{webarchive|url=https://web.archive.org/web/20070223140429/http://devdata.worldbank.org/wdi2005/Table5_7.htm |date=2007-02-23 }}</ref>—considerably different from the nominal exchange rate. This discrepancy has large implications; for instance, when converted via the nominal exchange rates [[List of countries by GDP (nominal) per capita|GDP per capita]] in [[India]] is about [[United States dollar|US$]]1,965<ref>[[List of countries by past and future GDP (nominal)]]</ref> while on a PPP basis it is about US$7,197.<ref>[[List of countries by future GDP (PPP) per capita estimates]]</ref> At the other extreme, for instance [[Denmark|Denmark's]] nominal GDP per capita is around US$53,242, but its PPP figure is US$46,602, in line with other [[developed nations]].\n\n==Uses==\nThe purchasing power parity exchange rate serves two main functions. PPP exchange rates can be useful for making comparisons between countries because they stay fairly constant from day to day or week to week and only change modestly if at all, from year to year. Second, over a period of years, exchange rates do tend to move in the general direction of the PPP exchange rate and there is some value to knowing in which direction the exchange rate is more likely to shift over the long run.\n\n==Measurement==\nThe PPP exchange-rate calculation is controversial because of the difficulties of finding comparable [[Market basket|baskets of goods]] to compare purchasing power across countries.<ref>{{Cite journal|last=Taylor and Taylor|first=Alan and Mark|date=Fall 2004|title=The Purchasing Power Parity Debate|url=http://www.ssc.wisc.edu/~mchinn/taylor&taylor_PPP_JEP.pdf|journal=Journal of Economic Perspectives|volume=18| issue = 4|pages=135–158|via=|doi=10.1257/0895330042632744}}</ref>{{Citation needed|date=April 2012}}\n\nEstimation of purchasing power parity is complicated by the fact that countries do not simply differ in a uniform [[price level]]; rather, the difference in food prices may be greater than the difference in housing prices, while also less than the difference in entertainment prices. People in different countries typically consume different baskets of goods. It is necessary to compare the cost of baskets of goods and services using a [[price index]]. This is a difficult task because purchasing patterns and even the goods available to purchase differ across countries.\n\nThus, it is necessary to make adjustments for differences in the quality of goods and services. Furthermore, the basket of goods representative of one economy will vary from that of another: Americans eat more bread; Chinese more rice. Hence a PPP calculated using the US consumption as a base will differ from that calculated using China as a base. Additional statistical difficulties arise with multilateral comparisons when (as is usually the case) more than two countries are to be compared.\n\nVarious ways of averaging bilateral PPPs can provide a more stable multilateral comparison, but at the cost of distorting bilateral ones. These are all general issues of indexing; as with other [[price index|price indices]] there is no way to reduce complexity to a single number that is equally satisfying for all purposes. Nevertheless, PPPs are typically robust in the face of the many problems that arise in using market exchange rates to make comparisons.\n\nFor example, in 2005 the price of a gallon of gasoline in Saudi Arabia was US$0.91, and in Norway the price was US$6.27.<ref>{{cite web|url=http://money.cnn.com/pf/features/lists/global_gasprices/|work=CNN/Money|title=Global gas prices|date=23 March 2005}}</ref> The significant differences in price would not contribute to accuracy in a PPP analysis, despite all of the variables that contribute to the significant differences in price. More comparisons have to be made and used as variables in the overall formulation of the PPP.\n\nWhen PPP comparisons are to be made over some interval of time, proper account needs to be made of [[inflation]]ary effects.\n\n===Law of one price===\nAlthough it may seem as if PPPs and the [[law of one price]] are the same, there is a difference: the law of one price applies to individual commodities whereas PPP applies to the general price level. If the law of one price is true for all commodities then PPP is also therefore true; however, when discussing the validity of PPP, some argue that the law of one price does not need to be true exactly for PPP to be valid. If the law of one price is not true for a certain commodity, the price levels will not differ enough from the level predicted by PPP.<ref name=\"Krugman\"/>\n\nThe purchasing power parity theory states that the exchange rate between one currency and another currency is in equilibrium when their domestic purchasing powers at that rate of exchange are equivalent.\n\n===Big Mac Index===\n{{Main|Big Mac Index}}\n[[File:Big Mac hamburger - Japan (3).jpg|thumb|[[Big Mac]] [[hamburger]]s, like this one from [[Japan]], are similar worldwide.]]\nAnother example of one measure of the [[law of one price]], which underlies purchasing power parity, is the Big Mac Index, popularized by ''[[The Economist]]'', which compares the prices of a [[Big Mac]] burger in [[McDonald's Corporation|McDonald's]] restaurants in different countries. The Big Mac Index is presumably useful because although it is based on a single consumer product that may not be typical, it is a relatively standardized product that includes input costs from a wide range of sectors in the local economy, such as agricultural commodities (beef, bread, lettuce, cheese), labor (blue and white collar), advertising, rent and real estate costs, transportation, etc.\n\nIn theory, the law of one price would hold that if, to take an example, the Canadian dollar were to be significantly overvalued relative to the U.S. dollar according to the Big Mac Index, that gap should be unsustainable because Canadians would import their Big Macs from or travel to the U.S. to consume them, thus putting upward demand pressure on the U.S. dollar by virtue of Canadians buying the U.S. dollars needed to purchase the U.S.-made Big Macs and simultaneously placing downward supply pressure on the Canadian dollar by virtue of Canadians selling their currency in order to buy those same U.S. dollars.<ref>{{Cite web|url=http://www.economist.com/content/big-mac-index|title=The Big Mac index|website=The Economist|access-date=2017-06-13}}</ref><ref>{{Cite web|url=http://bigmacindex.org/|title=The Big Mac Index|website=The Big Mac Index|language=en-US|access-date=2017-06-13}}</ref>{{Citation needed|date=April 2015}}\n\nThe alternative to this exchange rate adjustment would be an adjustment in prices, with Canadian McDonald's stores compelled to lower prices to remain competitive. Either way, the valuation difference should be reduced assuming [[perfect competition]] and a perfectly [[Tradability|tradable good]]. In practice, of course, the Big Mac is not a perfectly tradable good and there may also be capital flows that sustain relative demand for the Canadian dollar.  The difference in price may have its origins in a variety of factors besides direct input costs such as government regulations and [[product differentiation]].<ref name=\"Krugman\"/>\n\nIn some emerging economies, Western fast food represents an expensive niche product priced well above the price of traditional staples—i.e. the Big Mac is not a mainstream 'cheap' meal as it is in the West, but a luxury import. This relates back to the idea of product differentiation: the fact that few [[substitute good|substitutes]] for the Big Mac are available confers [[market power]] on McDonald's. For example, in India, the costs of local fast food like [[vada pav]] are comparative to what the Big Mac signifies in the U.S.<ref>{{cite news|first=Anand|last= Narasimhan|first2=Aparna |last2=Dogra|title=The case study: Goli Vada Pav|url=http://www.ft.com/cms/s/0/ce990f92-f2b1-11e1-86e0-00144feabdc0.html#axzz30MFTybRw|accessdate=30 April 2014|newspaper=Financial Times|date=3 September 2012}}</ref> Additionally, with countries such as Argentina that have abundant beef resources, consumer prices in general may not be as cheap as implied by the price of a Big Mac.\n\nThe following table, based on data from ''The Economist'''s January 2013 calculations, shows the under (−) and over (+) valuation of the local currency against the U.S. dollar in %, according to the Big Mac index. To take an example calculation, the local price of a Big Mac in Hong Kong when converted to U.S. dollars at the market exchange rate was $2.19, or 50% of the local price for a Big Mac in the U.S. of $4.37. Hence the Hong Kong dollar was deemed to be 50% undervalued relative to the U.S. dollar on a PPP basis.\n\n{| class=\"sortable wikitable\"\n|-\n! Country or region !! Price level<br>(% difference<br>from US)<ref>{{cite web|url=http://www.economist.com/content/big-mac-index|title=Interactive currency-comparison tool|work=The Economist}}</ref>\n|-\n| India || -58\n|-\n| South Africa || -54\n|-\n| Hong Kong || -50\n|-\n| Ukraine || -47\n|-\n| Egypt || -45\n|-\n| Russia || -45\n|-\n| Taiwan || -42\n|-\n| China || -41\n|-\n| Malaysia || -41\n|-\n| Sri Lanka || -37\n|-\n| Indonesia || -35\n|-\n| Mexico || -34\n|-\n| Philippines || -33\n|-\n| Poland || -33\n|-\n| Bangladesh || -32\n|-\n| Saudi Arabia || -33\n|-\n| Thailand || -33\n|-\n| Pakistan || -32\n|-\n| Lithuania || -30\n|-\n| Latvia || -25\n|-\n| UAE || -25\n|-\n| South Korea || -22\n|-\n| Japan || -20\n|-\n| Singapore || -17\n|-\n| Estonia || -16\n|-\n| Czech Republic || -15\n|-\n| Argentina || -13\n|-\n| Hungary || -13\n|-\n| Peru || -11\n|-\n| Israel || -8\n|-\n| Portugal || -8\n|-\n| United Kingdom || -3\n|-\n| New Zealand || -1\n|-\n| Chile || 0\n|-\n| '''United States''' || '''0 (by definition)'''\n|-\n| Costa Rica || +1\n|-\n| Greece || +3\n|-\n| Austria || +5\n|-\n| Netherlands || +7\n|-\n| Ireland || +8\n|-\n| Spain || +9\n|-\n| Turkey || +10\n|-\n| Colombia || +11\n|-\n| Australia || +12\n|-\n| Euro area || +12\n|-\n| France || +12\n|-\n| Germany || +13\n|-\n| Finland || +17\n|-\n| Belgium || +18\n|-\n| Denmark || +19\n|-\n| Italy || +20\n|-\n| Canada || +24\n|-\n| Uruguay || +25\n|-\n| Brazil || +29\n|-\n| Switzerland || +63\n|-\n| Sweden || +75\n|-\n| Norway || +80\n|-\n| Venezuela || +108\n|}\n\n===iPad Index===\nLike the [[Big Mac Index]], the iPad index (elaborated by [[Commonwealth Securities|CommSec]]) compares an item's price in various locations.  Unlike the Big Mac, however, each iPad is produced in the same place (except for the model sold in Brazil) and all iPads (within the same model) have identical performance characteristics.  Price differences are therefore a function of transportation costs, taxes, and the prices that may be realized in individual markets.  An iPad will cost about twice as much in Argentina as in the United States.\n\n{| class=\"sortable wikitable\"\n|-\n! Country or region !! Price<br>(US Dollars)<br><ref>{{cite web|url=http://www.theage.com.au/business/markets/is-the-aussie-too-expensive-ipad-index-says-no-20130923-2u9jj.html|title=Is the Aussie too expensive? iPad index says no|author=Glenda Kwek|work=The Age}}</ref><ref>[http://www.comsec.com.au/redir.asp?ID=media2 ''23rd Sep 2013, CommSec Economic Insight: CommSec iPad Index'']{{dead link|date=April 2018 |bot=InternetArchiveBot |fix-attempted=yes }}</ref><ref>[https://www.comsec.com.au/] ''[[Commonwealth Securities]]'' 23 September 2013</ref><ref>{{cite web |url=http://www.businessinsider.com/how-much-an-ipad-costs-in-46-countries-2013-9 |title=Here's How Much An iPad Costs In 46 Countries |author=Liz Tay |publisher=Business Insider Australia |date=September 23, 2013}}</ref>\n\n|-\n| Argentina || $1,094.11\n|-\n| Australia || $506.66\n|-\n| Austria || $674.96\n|-\n| Belgium || $618.34\n|-\n| Brazil || $791.40\n|-\n| Brunei || $525.52\n|-\n| Canada (Montréal) || $557.18\n|-\n| Canada (no tax) || $467.36\n|-\n| Chile || $602.13\n|-\n| China || $602.52\n|-\n| Czech Republic || $676.69\n|-\n| Denmark || $725.32\n|-\n| Finland || $695.25\n|-\n| France || $688.49\n|-\n| Germany || $618.34\n|-\n| Greece || $715.54\n|-\n| Hong Kong || $501.52\n|-\n| Hungary || $679.64\n|-\n| India || $512.61\n|-\n| Ireland || $630.73\n|-\n| Italy || $674.96\n|-\n| Japan || $501.56\n|-\n| Luxembourg || $641.50\n|-\n| Malaysia || $473.77\n|-\n| Mexico || $591.62\n|-\n| Netherlands || $683.08\n|-\n| New Zealand || $610.45\n|-\n| Norway || $655.92\n|-\n| Philippines || $556.42\n|-\n| Pakistan    || $550.00\n|-\n| Poland || $704.51\n|-\n| Portugal || $688.49\n|-\n| Russia || $596.08\n|-\n| Singapore || $525.98\n|-\n| Slovakia || $674.96\n|-\n| Slovenia || $674.96\n|-\n| South Africa || $559.38\n|-\n| South Korea || $576.20\n|-\n| Spain || $674.96\n|-\n| Sweden || $706.87\n|-\n| Switzerland || $617.58\n|-\n| Taiwan || $538.34\n|-\n| Thailand || $530.72\n|-\n| Turkey || $656.96\n|-\n| UAE || $544.32\n|-\n| United Kingdom || $638.81\n|-\n| US (California) || $546.91\n|-\n| United States (no tax) || $499.00\n|-\n| Vietnam || $554.08\n|-\n|}\n\n===KFC Index===\n{{Main|KFC Index}}\n\nSimilar to the [[Big Mac Index]], the [[KFC Index]] measures PPP amongst African countries, created by Sagaci Research (a [[market research]] firm focusing solely on Africa). Instead of comparing a [[Big Mac]], this index compares a [[KFC]] Original 12/15 pc. bucket.\n\nFor example, the average price of KFC's Original 12 pc. Bucket in the United States in January 2016 was $20.50; while in Namibia it was only $13.40 at market exchange rates. Therefore, the index states the Namibian dollar was undervalued by 33% at that time.\n\n===OECD comparative price levels===\nEach month, the [[Organisation for Economic Co-operation and Development]] (OECD) measures the differences in price levels between its member countries by calculating the ratios of PPPs for [[household final consumption expenditure|private final consumption expenditure]] to exchange rates. The OECD table below indicates the number of US dollars needed in each of the countries listed to buy the same representative basket of consumer goods and services that would cost US$100 in the United States.\n\nAccording to the table, an American living or travelling in Switzerland on an income denominated in US dollars would find that country to be the most expensive of the group, having to spend 62% more US dollars to maintain a standard of living comparable to the US in terms of [[Consumption (economics)|consumption]].\n\n{| class=\"sortable wikitable\"\n|-\n! Country\n!  Price level<br>(US = 100)<ref>as of 14 Apr 2015 {{cite web |url=http://stats.oecd.org/Index.aspx?DataSetCode=CPL |publisher=OECD |date=14 April 2015 |title=Monthly comparative price levels}}</ref>\n|-\n| Australia || 123\n|-\n| Austria || 99\n|-\n| Belgium || 101\n|-\n| Canada || 105\n|-\n| Chile || 67\n|-\n| Czech Republic || 59\n|-\n| Denmark || 128\n|-\n| Estonia || 71\n|-\n| Finland || 113\n|-\n| France || 100\n|-\n| Germany || 94\n|-\n| Greece || 78\n|-\n| Hungary || 52\n|-\n| Iceland || 111\n|-\n| Ireland || 109\n|-\n| Israel || 109\n|-\n| Italy || 94\n|-\n| Japan || 96\n|-\n| South Korea || 84\n|-\n| Luxembourg || 112\n|-\n| Mexico || 66\n|-\n| Netherlands || 102\n|-\n| New Zealand || 118\n|-\n| Norway || 134\n|-\n| Poland || 51\n|-\n| Portugal || 73\n|-\n| Slovak Republic || 63\n|-\n| Slovenia || 75\n|-\n| Spain || 84\n|-\n| Sweden || 109\n|-\n| Switzerland || 162\n|-\n| Turkey || 61\n|-\n| United Kingdom || 121\n|-\n| United States || 100\n|}\n\n===[[International Comparison Program]]===\n2011: https://ec.europa.eu/eurostat/statistics-explained/index.php/Purchasing_power_parities_in_Europe_and_the_world\n\n===Measurement issues===\n\nIn addition to methodological issues presented by the selection of a basket of goods, PPP estimates can also vary based on the statistical capacity of participating countries. The [[International Comparison Program]], which PPP estimates are based on, require the disaggregation of national accounts into production, expenditure or (in some cases) income, and not all participating countries routinely disaggregate their data into such categories.\n\nSome aspects of PPP comparison are theoretically impossible or unclear. For example, there is no basis for comparison between the Ethiopian laborer who lives on teff with the Thai laborer who lives on rice, because teff is not commercially available in Thailand and rice is not in Ethiopia, so the price of rice in Ethiopia or teff in Thailand cannot be determined. As a general rule, the more similar the price structure between countries, the more valid the PPP comparison.\n\nPPP levels will also vary based on the formula used to calculate price matrices. Different possible formulas include GEKS-Fisher, Geary-Khamis, IDB, and the superlative method. Each has advantages and disadvantages.\n\nLinking regions presents another methodological difficulty. In the 2005 ICP round, regions were compared by using a list of some 1,000 identical items for which a price could be found for 18 countries, selected so that at least two countries would be in each region. While this was superior to earlier \"bridging\" methods, which do not fully take into account differing quality between goods, it may serve to overstate the PPP basis of poorer countries, because the price indexing on which PPP is based will assign to poorer countries the greater weight of goods consumed in greater shares in richer countries.\n\n==Need for adjustments to GDP==\n{{multiple image\n| align = right\n| width = 400\n| direction = vertical\n}}\n\nThe exchange rate reflects transaction values for [[tradable goods|traded goods]] ''between'' countries in contrast to non-traded goods, that is, goods produced for home-country use. Also, currencies are traded for purposes other than trade in goods and services, ''e.g.'', to buy [[capital asset]]s whose prices vary more than those of physical goods. Also, different [[interest rate]]s, [[speculation]], [[Hedge (finance)|hedging]] or interventions by [[central bank]]s can influence the [[foreign exchange market|foreign-exchange market]].\n\nThe PPP method is used as an alternative to correct for possible statistical bias. The [[Penn World Table]] is a widely cited source of PPP adjustments, and the associated [[Penn effect]] reflects such a [[systematic bias]] in using exchange rates to outputs among countries.\n\nFor example, if the value of the [[Mexican peso]] falls by half compared to the [[US dollar]], the Mexican [[Gross Domestic Product]] measured in dollars will also halve. However, this exchange rate results from international trade and financial markets. It does not necessarily mean that Mexicans are poorer by a half; if incomes and prices measured in pesos stay the same, they will be no worse off assuming that imported goods are not essential to the quality of life of individuals. Measuring income in different countries using PPP exchange rates helps to avoid this problem.\n\nPPP exchange rates are especially useful when official exchange rates are artificially manipulated by governments. Countries with strong government control of the economy sometimes enforce official exchange rates that make their own currency artificially strong. By contrast, the currency's black market exchange rate is artificially weak. In such cases, a PPP exchange rate is likely the most realistic basis for economic comparison. Similarly, when exchange rates deviate significantly from their long term equilibrium due to speculative attacks or carry trade, a PPP exchange rate offers a better alternative for comparison.\n\n===Extrapolating PPP rates===\n\nSince global PPP estimates—such as those provided by the ICP— are not calculated annually, but for a single year, PPP exchange rates for years other than the benchmark year need to be extrapolated.<ref>{{cite journal |url=http://www.oecd.org/std/prices-ppp/2078177.pdf |title=Purchasing power parities – measurement and uses |authors=Paul Schreyer and Francette Koechlin |date=March 2002 |number=3 |journal=Statistics Brief |publisher=OECD}}</ref> One way of doing this is by using the country's [[GDP deflator]]. To calculate a country's PPP exchange rate in Geary–Khamis dollars for a particular year, the calculation proceeds in the following manner:<ref>{{cite web|url=http://siteresources.worldbank.org/ICPINT/Resources/270056-1255977254560/6483625-1291755426408/18_ICPBook_Extrapolating_FINAL.pdf|title=Chapter 18: Extrapolating PPPs and Comparing ICP Benchmark Results|publisher=[[World Bank]]|work=[[International Comparison Program]]|author=Paul McCarthy|page=29}}</ref>\n\n<math>\\textrm{PPPrate}_{X,i}=\\frac{\\textrm{PPPrate}_{X,b}\\cdot \\frac{\\textrm{GDPdef}_{X,i}}{\\textrm{GDPdef}_{X,b}}}{\\textrm{PPPrate}_{U,b}\\cdot \\frac{\\textrm{GDPdef}_{U,i}}{\\textrm{GDPdef}_{U,b}}}</math>\n\nWhere PPPrate<sub>X,i</sub> is the PPP exchange rate of country X for year i, PPPrate<sub>X,b</sub> is the PPP exchange rate of country X for the benchmark year, PPPrate<sub>U,b</sub> is the PPP exchange rate of the [[United States]] (US) for the benchmark year (equal to 1), GDPdef<sub>X,i</sub> is the GDP deflator of country X for year i, GDPdef<sub>X,b</sub> is the GDP deflator of country X for the benchmark year, GDPdef<sub>U,i</sub> is the GDP deflator of the US for year i, and GDPdef<sub>U,b</sub> is the GDP deflator of the US for the benchmark year.\n\n==Difficulties==\nThere are a number of reasons that different measures do not perfectly reflect standards of living.\n\n===Range and quality of goods===\nThe goods that the currency has the \"power\" to purchase are a basket of goods of different types:\n# Local, non-tradable goods and services (like electric power) that are produced and sold domestically.\n# Tradable goods such as non-perishable [[Commodity|commodities]] that can be sold on the international market (like [[diamond]]s).\n\nThe more that a product falls into category 1, the further its price will be from the currency [[exchange rate]], moving towards the PPP exchange rate. Conversely, category 2 products tend to trade close to the currency exchange rate. (See also [[Penn effect]]).\n\nMore processed and expensive products are likely to be [[tradable]], falling into the second category, and drifting from the PPP exchange rate to the currency exchange rate. Even if the PPP \"value\" of the Ethiopian currency is three times stronger than the currency exchange rate, it won't buy three times as much of internationally traded goods like steel, cars and microchips, but non-traded goods like housing, services (\"haircuts\"), and domestically produced crops. The relative price differential between tradables and non-tradables from high-income to low-income countries is a consequence of the [[Balassa–Samuelson effect]] and gives a big cost advantage to labour-intensive production of tradable goods in low income countries (like [[Ethiopia]]), as against high income countries (like [[Switzerland]]).\n\nThe corporate cost advantage is nothing more sophisticated than access to cheaper workers, but because the pay of those workers goes farther in low-income countries than high, the relative pay differentials (inter-country) can be sustained for longer than would be the case otherwise. (This is another way of saying that the wage rate is based on average local productivity and that this is below the per capita productivity that factories selling tradable goods to international markets can achieve.) An equivalent [[cost]] benefit comes from non-traded goods that can be sourced locally (nearer the PPP-exchange rate than the nominal exchange rate in which receipts are paid). These act as a cheaper [[factor of production]] than is available to factories in richer countries. It's difficult by the GDP PPP to consider the different quality of goods among the different countries.\n\nThe Bhagwati–Kravis–Lipsey view provides a somewhat different explanation from the Balassa–Samuelson theory. This view states that price levels for nontradables are lower in poorer countries because of differences in endowment of labor and capital, not because of lower levels of productivity. Poor countries have more labor relative to capital, so marginal productivity of labor is greater in rich countries than in poor countries. Nontradables tend to be labor-intensive; therefore, because labor is less expensive in poor countries and is used mostly for nontradables, nontradables are cheaper in poor countries. Wages are high in rich countries, so nontradables are relatively more expensive.<ref name=\"Krugman\"/>\n\nPPP calculations tend to overemphasise the primary sectoral contribution, and underemphasise the industrial and service sectoral contributions to the economy of a nation.\n\n===Trade barriers and nontradables===\nThe law of one price, the underlying mechanism behind PPP, is weakened by transport costs and governmental trade restrictions, which make it expensive to move goods between markets located in different countries. Transport costs sever the link between exchange rates and the prices of goods implied by the law of one price. As transport costs increase, the larger the range of exchange rate fluctuations. The same is true for official trade restrictions because the customs fees affect importers' profits in the same way as shipping fees. According to Krugman and Obstfeld, \"Either type of trade impediment weakens the basis of PPP by allowing the purchasing power of a given currency to differ more widely from country to country.\"<ref name=Krugman>{{cite book|last=Krugman and Obstfeld|title=International Economics|year=2009|publisher=Pearson Education, Inc.|pages=394–395}}</ref>  They cite the example that a dollar in London should purchase the same goods as a dollar in Chicago, which is certainly not the case.\n\nNontradables are primarily services and the output of the construction industry. Nontradables also lead to deviations in PPP because the prices of nontradables are not linked internationally. The prices are determined by domestic supply and demand, and shifts in those curves lead to changes in the market basket of some goods relative to the foreign price of the same basket. If the prices of nontradables rise, the purchasing power of any given currency will fall in that country.<ref name=\"Krugman\"/>\n\n===Departures from free competition===\nLinkages between national price levels are also weakened when trade barriers and imperfectly competitive market structures occur together. Pricing to market occurs when a firm sells the same product for different prices in different markets. This is a reflection of inter-country differences in conditions on both the demand side (''e.g.'', virtually no demand for pork in Islamic states) and the supply side (''e.g.'', whether the existing market for a prospective entrant's product features few suppliers or instead is already near-saturated). According to Krugman and Obstfeld, this occurrence of product differentiation and segmented markets results in violations of the law of one price and absolute PPP. Over time, shifts in market structure and demand will occur, which may invalidate relative PPP.<ref name=\"Krugman\"/>\n\n===Differences in price level measurement===\nMeasurement of price levels differ from country to country. Inflation data from different countries are based on different commodity baskets; therefore, exchange rate changes do not offset official measures of inflation differences. Because it makes predictions about price changes rather than price levels, relative PPP is still a useful concept. However, change in the relative prices of basket components can cause relative PPP to fail tests that are based on official price indexes.<ref name=\"Krugman\"/>\n\n==Global poverty line==\nThe global poverty line is a worldwide count of people who live below an international [[poverty line]], referred to as the dollar-a-day line. This line represents an average of the national poverty lines of the [[least developed country|world's poorest countries]], expressed in international dollars.  These national poverty lines are converted to international currency and the global line is converted back to local currency using the PPP exchange rates from the ICP. PPP exchange rates include data from the sales of high end non-poverty related items which skews the value of food items and necessary goods which is 70 percent of poor peoples' consumption.<ref>[http://www.policyinnovations.org/ideas/briefings/data/000201 Thomas Pogge on Global Poverty]</ref> Angus Deaton argues that PPP indices need to be reweighted for use in poverty measurement; they need to be redefined to reflect local poverty measures, not global measures, weighing local food items and excluding luxury items that are not prevalent or are not of equal value in all localities.<ref>[http://www.princeton.edu/~deaton/downloads/presidential%20address%2019january%202010%20all.pdf Price indexes, inequality, and the measurement of world poverty Angus Deaton, Princeton University]</ref>\n\n==See also==\n{{Portal|Business and economics}}\n* [[List of countries by GDP (PPP)]]\n* [[List of countries by GDP (PPP) per capita]]\n* [[List of IMF ranked countries by GDP]], Includes IMF ranked PPP of 186 countries\n* [[Measures of national income and output]]\n* [[Relative purchasing power parity]]\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://cid.econ.ucdavis.edu/pwt.html Penn World Table]\n* [http://salaryconverter.tk/ Salary Converter using PPP]\n* [http://data.oecd.org/conversion/purchasing-power-parities-ppp.htm Purchasing power parities updated by Organisation of Cooperation and Development (OECD)] from OECD data\n* [http://fx.sauder.ubc.ca/PPP.html Explanations from the U. of British Columbia] (also provides daily updated PPP charts)\n* [http://epp.eurostat.ec.europa.eu/statistics_explained/index.php/Purchasing_power_parities_as_example_of_international_statistical_cooperation Purchasing power parities as example of international statistical cooperation] from Eurostat - Statistics Explained\n* [http://www.worldbank.org/data/icp World Bank International Comparison Project] provides PPP estimates for a large number of countries\n* [http://arquivo.pt/wayback/20080224132512/http://www.ubs.com/1/ShowMedia/ubs_ch/wealth_mgmt_ch?contentId=103982&name=eng.pdf UBS's \"Prices and Earnings\" Report 2006] Good report on purchasing power containing a Big Mac index as well as for staples such as bread and rice for 71 world cities.\n* [https://web.archive.org/web/20100524214313/http://pwt.econ.upenn.edu/papers/deaton%20heston%20complete%20nov10.pdf \"Understanding PPPs and PPP based national accounts\"] provides an overview of methodological issues in calculating PPP and in designing the ICP under which the main PPP tables (Maddison, Penn World Tables, and World Bank WDI) are based.\n**  [http://data.worldbank.org/indicator/PA.NUS.PPPC.RF List of Countries by Purchasing Power Parity] since 1990 ([[World Bank]])\n{{economics}}\n\n\n{{DEFAULTSORT:Purchasing Power Parity}}\n[[Category:Purchasing power]]\n[[Category:Gross domestic product]]\n[[Category:International economics]]\n[[Category:Inequalities]]\n[[Category:Trade]]\n[[Category:Currency]]"
    },
    {
      "title": "Rearrangement inequality",
      "url": "https://en.wikipedia.org/wiki/Rearrangement_inequality",
      "text": "In [[mathematics]], the '''rearrangement inequality'''<ref>{{Citation | last1 = Hardy | first1 = G.H. | authorlink =  G. H. Hardy | last2 = Littlewood | first2 = J.E. | author2-link = John Edensor Littlewood | last3 = Pólya | first3 = G. | author3-link = George Pólya | title = Inequalities | publisher = [[Cambridge University Press]] | series = Cambridge Mathematical Library | edition = 2. | year = 1952 | location = [[Cambridge]] | isbn = 0-521-05206-8 | mr = 0046395 | zbl = 0047.05302}}, Section&nbsp;10.2, Theorem&nbsp;368</ref> states that\n\n:<math>x_ny_1 + \\cdots + x_1y_n\n\\le x_{\\sigma (1)}y_1 + \\cdots + x_{\\sigma (n)}y_n\n\\le x_1y_1 + \\cdots + x_ny_n</math>\n\nfor every choice of [[real number]]s\n\n:<math>x_1\\le\\cdots\\le x_n\\quad\\text{and}\\quad y_1\\le\\cdots\\le y_n</math>\n\nand every [[permutation]]\n\n:<math>x_{\\sigma(1)},\\dots,x_{\\sigma(n)}</math>\n\nof ''x''<sub>1</sub>, .&nbsp;.&nbsp;., ''x<sub>n</sub>''. If the numbers are different, meaning that\n\n:<math>x_1<\\cdots<x_n\\quad\\text{and}\\quad y_1<\\cdots<y_n,</math>\n\nthen the lower bound is attained only for the permutation which reverses the order, i.e. σ(''i'')&nbsp;= ''n''&nbsp;&minus;&nbsp;''i''&nbsp;+&nbsp;1 for all ''i''&nbsp;= 1,&nbsp;...,&nbsp;''n'', and the upper bound is attained only for the identity, i.e. σ(''i'')&nbsp;=&nbsp;''i'' for all ''i''&nbsp;= 1,&nbsp;...,&nbsp;''n''.\n\nNote that the rearrangement inequality makes no assumptions on the signs of the real numbers.\n\n==Applications==\n\nMany important inequalities can be proved by the rearrangement inequality, such as the [[inequality of arithmetic and geometric means|arithmetic mean – geometric mean inequality]], the [[Cauchy–Schwarz inequality]], and [[Chebyshev's sum inequality]].\n\n==Proof==\n\nThe lower bound follows by applying the upper bound to\n\n:<math>-x_n\\le\\cdots\\le-x_1.</math>\n\nTherefore, it suffices to prove the upper bound. Since there are only finitely many permutations, there exists at least one for which\n\n:<math>x_{\\sigma (1)}y_1 + \\cdots + x_{\\sigma (n)}y_n</math>\n\nis maximal. In case there are several permutations with this property, let σ denote one with the highest number of [[fixed point (mathematics)|fixed points]].\n\nWe will now [[reductio ad absurdum|prove by contradiction]], that σ has to be the identity (then we are done). Assume that σ is {{em|not}} the identity. Then there exists a ''j'' in {1,&nbsp;...,&nbsp;''n''&nbsp;&minus;&nbsp;1} such that σ(''j'')&nbsp;≠&nbsp;''j'' and σ(''i'')&nbsp;=&nbsp;''i'' for all ''i'' in {1,&nbsp;...,&nbsp;''j''&nbsp;&minus;&nbsp;1}. Hence σ(''j'')&nbsp;>&nbsp;''j'' and there exists a ''k'' in {''j''&nbsp;+&nbsp;1,&nbsp;...,&nbsp;''n''} with σ(''k'')&nbsp;=&nbsp;''j''. Now\n\n:<math>j<k\\Rightarrow y_j\\le y_k\n\\qquad\\text{and}\\qquad\nj<\\sigma(j)\\Rightarrow x_j\\le x_{\\sigma(j)}.\\quad(1)</math>\n \nTherefore,\n\n:<math>0\\le(x_{\\sigma(j)}-x_j)(y_k-y_j). \\quad(2)</math>\n\nExpanding this product and rearranging gives\n\n:<math>x_{\\sigma(j)}y_j+x_jy_k\\le x_jy_j+x_{\\sigma(j)}y_k\\,, \\quad(3)</math>\n\nhence the permutation\n\n:<math>\\tau(i):=\\begin{cases}i&\\text{for }i\\in\\{1,\\ldots,j\\},\\\\\n\\sigma(j)&\\text{for }i=k,\\\\\n\\sigma(i)&\\text{for }i\\in\\{j+1,\\ldots,n\\}\\setminus\\{k\\},\\end{cases}</math>\n\nwhich arises from σ by exchanging the values σ(''j'') and σ(''k''), has at least one additional fixed point compared to σ, namely at ''j'', and also attains the maximum. This contradicts the choice of σ.\n\nIf\n\n:<math>x_1<\\cdots<x_n\\quad\\text{and}\\quad y_1<\\cdots<y_n,</math>\n\nthen we have strict inequalities at (1), (2), and (3), hence the maximum can only be attained by the identity, any other permutation σ cannot be optimal.\n\n==Proof by induction==\nObserve first that \n:<math> x_1 > x_2 \\quad\\text{and}\\quad y_1 > y_2 </math>\nimplies \n:<math> (x_1-x_2)(y_1-y_2) > 0 \\quad \\text{or}\\quad x_1y_1 + x_2y_2 > x_2y_1 + x_1y_2,</math>\nhence the result is true if ''n'' = 2. \nAssume it is true at rank ''n-1'', and let \n:<math>x_1>\\cdots>x_n,\\quad \\text{and}\\quad y_1>\\cdots>y_n</math>.\nChoose a permutation σ for which the arrangement gives rise a maximal result.\n\nIf σ(''n'') were different from ''n'', say σ(''n'') = ''k'', \nthere would exist ''j'' < ''n'' such that σ(''j'') = ''n''. \nBut  \n:<math> x_k > x_n \\quad\\text{and}\\quad y_j > y_n, \\quad\\text{hence}\\quad  x_ny_n + x_ky_j > x_ky_n + x_ny_j </math>\nby what has just been proved.\nConsequently, it would follow that the permutation τ coinciding with σ, except at ''j'' and ''n'', where \nτ(''j'') = ''k'' and τ(''n'') = ''n'', gives rise a better result. This contradicts the choice of σ.\nHence σ(''n'') = ''n'', and from the induction hypothesis, σ(''i'') = ''i'' for every ''i'' < ''n''.\n\nThe same proof holds if one replace strict inequalities by non strict ones.\n\n==Generalization==\nA Generalization of the Rearrangement inequality states that for all [[real number]]s <math> x_1\\le\\cdots\\le x_n </math> and any choice of functions <math> f_i: [x_1,x_n]\\rightarrow \\mathbb{R}, i=1,2,...,n </math> such that\n\n:<math> f'_1(x) \\le f'_2(x) \\le ...\\le f'_n(x) \\quad \\forall x\\in [x_1,x_n] </math>\n\nthe inequality\n\n:<math> \\sum_{i=1}^n f_i(x_{n-i+1}) \\le \\sum_{i=1}^n f_i(x_{\\sigma(i)}) \\le \\sum_{i=1}^n f_i(x_i) </math>\n\nholds for every [[permutation]] <math> x_{\\sigma(1)},\\dots,x_{\\sigma(n)} </math> of <math> x_1,\\dots,x_n </math><ref>{{citation | year=2017 | last=Holstermann | first=Jan | title=A Generalization of the Rearrangement Inequality | periodical=Mathematical Reflections | issue = 5 (2017) | url=https://www.awesomemath.org/wp-pdf-files/math-reflections/mr-2017-05/rearrangement_inequality.pdf}}</ref>.\n\n==See also==\n* [[Hardy–Littlewood inequality]]\n* [[Chebyshev's sum inequality]]\n* Functional Reciprocal Sum inequality, [[Aditya Guha Roy]] (2016) http://www.ssmrmh.ro/wp-content/uploads/2016/12/FUNCTIONAL-RECIPROCAL-THEORY-DEGREE-2.pdf , Romanian Mathematical Magazine\n\n==References==\n\n<references/>\n\n[[Category:Inequalities]]\n[[Category:Rearrangement inequalities]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Remez inequality",
      "url": "https://en.wikipedia.org/wiki/Remez_inequality",
      "text": "In [[mathematics]], the '''Remez inequality''', discovered by the Soviet mathematician [[Evgeny Yakovlevich Remez]] {{harv|Remez|1936}}, gives a bound on the [[sup norms]] of certain polynomials, the bound being attained by the [[Chebyshev polynomials]].\n\n==The inequality==\nLet σ be an arbitrary fixed positive number. Define the class of polynomials π<sub>''n''</sub>(σ) to be those polynomials ''p'' of the ''n''th degree for which\n\n:<math>\n|p(x)| \\le 1\n</math>\n\non some set of measure ≥ 2 contained in the closed interval [&minus;1,&nbsp;1+σ]. Then the '''Remez inequality''' states that\n\n:<math>\\sup_{p \\in \\pi_n(\\sigma)} \\|p\\|_\\infty=\\|T_n\\|_\\infty</math>\n\nwhere ''T''<sub>''n''</sub>(''x'') is the Chebyshev polynomial of degree ''n'', and the supremum norm is taken over the interval [&minus;1,&nbsp;1+σ].\n\nObserve that ''T''<sub>''n''</sub> is increasing on <math>[1, +\\infty]</math>, hence \n:<math> \\|T_n\\|_\\infty = T_n(1+\\sigma). </math>\n\nThe R.i., combined with an estimate on Chebyshev polynomials, implies the following\ncorollary: If ''J''&nbsp;&sub;&nbsp;'''R''' is a finite interval, and ''E''&nbsp;&sub;&nbsp;''J'' is an arbitrary measurable set, then\n:<math>  \\max_{x \\in J} |p(x)| \\leq \\left( \\frac{4 \\,\\, \\textrm{mes } J}{\\textrm{mes } E} \\right)^n \\sup_{x \\in E} |p(x)| \\qquad\\qquad(*) </math>\nfor any polynomial ''p'' of degree ''n''.\n\n==Extensions: Nazarov–Turán lemma==\n\nInequalities similar to (<sub>*</sub>) have been proved for different classes of functions, and are known as Remez-type inequalities. One important example is [[Fedor Nazarov|Nazarov]]'s inequality for exponential sums {{harv|Nazarov|1993}}:\n\n:'''Nazarov's Inequality.''' Let\n:: <math> p(x) = \\sum_{k = 1}^n a_k e^{\\lambda_k x} </math>\n:be an [[exponential sum]] (with arbitrary ''λ''<sub>''k''</sub>&nbsp;∈'''C'''), and let ''J''&nbsp;⊂&nbsp;'''R''' be a finite interval, ''E''&nbsp;⊂&nbsp;''J''—an arbitrary measurable set. Then\n::<math> \\max_{x \\in J} |p(x)| \\leq e^{\\max_k |\\Re \\lambda_k| \\, \\mathrm{mes} J} \\left( \\frac{C \\,\\, \\textrm{mes} J}{\\textrm{mes} E} \\right)^{n-1} \\sup_{x \\in E} |p(x)|~, </math>\n:where ''C'' > 0 is a numerical constant.\n\nIn the special case when ''λ<sub>k</sub>'' are pure imaginary and integer, and the subset ''E'' is itself an interval, the inequality was proved by [[Pál Turán]] and is known as Turán's lemma.\n\nThis inequality also extends to <math>L^p(\\mathbb{T}),\\ 0\\leq p\\leq2</math> in the following way\n\n:<math> \\|p\\|_{L^p(\\mathbb{T})}\\leq e^{A(n-1)\\textrm{mes }(\\mathbb{T}\\setminus E)}\\|p\\|_{L^p(E)} </math>\n\nfor some ''A''>0 independent of ''p'', ''E'', and ''n''. When\n\n:<math>\\mathrm{mes} E <1-\\frac{\\log n}{n}</math>\n\na similar inequality holds for ''p'' > 2. For ''p''=∞ there is an extension to multidimensional polynomials.\n\n'''Proof:''' Applying Nazarov's lemma to <math>E=E_\\lambda=\\{x\\,:\\ |p(x)|\\leq\\lambda\\},\\ \\lambda>0</math> leads to\n\n:<math>\\max_{x \\in J} |p(x)| \\leq e^{\\max_k |\\Re \\lambda_k| \\, \\mathrm{mes} J} \\left( \\frac{C \\,\\, \\textrm{mes} J}{\\textrm{mes} E_\\lambda} \\right)^{n-1} \\sup_{x \\in E_\\lambda} |p(x)| \\leq e^{\\max_k |\\Re \\lambda_k| \\, \\mathrm{mes} J} \\left( \\frac{C \\,\\, \\textrm{mes} J}{\\textrm{mes} E_\\lambda} \\right)^{n-1} \\lambda </math>\n\nthus\n\n:<math>\\textrm{mes} E_\\lambda\\leq C \\,\\, \\textrm{mes} J\\left(\\frac{\\lambda e^{\\max_k |\\Re \\lambda_k| \\, \\mathrm{mes} J}}{\\max_{x \\in J} |p(x)|} \\right )^{\\frac{1}{n-1}}</math>\n\nNow fix a set <math>E</math> and choose <math>\\lambda</math> such that <math>\\textrm{mes} E_\\lambda\\leq\\tfrac{1}{2}\\textrm{mes} E</math>, that is\n\n:<math>\\lambda =\\left(\\frac{\\textrm{mes} E}{2C \\mathrm{mes} J}\\right)^{n-1}e^{-\\max_k |\\Re \\lambda_k| \\, \\mathrm{mes} J}\\max_{x \\in J} |p(x)| </math>\n\nNote that this implies: \n\n:<math>\\textrm{mes} E\\cap (J\\setminus E_\\lambda)\\geq  \\textrm{mes}E-\\textrm{mes}E_\\lambda \\geq \\tfrac{1}{2} \\textrm{mes} E</math>\n\nNow\n\n:<math>\\begin{align}\n\\int_{x\\in E}|p(x)|^p\\,\\mbox{d}x &\\geq \\int_{x\\in E\\cap (J\\setminus E_\\lambda)}|p(x)|^p\\,\\mbox{d}x \\\\[6pt]\n&\\geq \\lambda^p\\mathrm{mes} E\\cap (J\\setminus E_\\lambda)\\\\[6pt]\n&\\geq \\frac{1}{2}\\textrm{mes} E \\left(\\frac{\\textrm{mes} E}{2C \\mathrm{mes} J}\\right)^{p(n-1)}e^{-p\\max_k |\\Re \\lambda_k| \\, \\mathrm{mes} J}\\max_{x \\in J} |p(x)|^p \\\\[6pt]\n&\\geq \\frac{1}{2} \\frac{\\textrm{mes} E}{\\textrm{mes} J}\\left(\\frac{\\textrm{mes} E}{2C \\mathrm{mes} J}\\right)^{p(n-1)}e^{-p\\max_k |\\Re \\lambda_k| \\, \\mathrm{mes} J}\\int_{x \\in J} |p(x)|^p\\,\\mbox{d}x\n\\end{align}</math>\n\nwhich completes the proof.\n\n==Pólya inequality==\n\nOne of the corollaries of the R.i. is the '''Pólya inequality''', which was proved by [[George Pólya]]  {{harv|Pólya|1928}}, and states that the Lebesgue measure of a sub-level set of a polynomial ''p'' of degree ''n'' is bounded in terms of the leading coefficient LC(''p'') as follows:\n\n:<math> \\textrm{mes} \\left\\{ x \\in \\mathbb{R} \\, \\mid \\, |P(x)| \\leq a \\right\\} \\leq 4 \\left(\\frac{a}{2 \\mathrm{LC}(p)}\\right)^{1/n}~, \\quad a > 0~.</math>\n\n==References==\n*{{cite journal|last = Remez|first = E. J.|author-link=Evgeny Yakovlevich Remez|title = Sur une propriété des polynômes de Tchebyscheff|journal = Comm. Inst. Sci. Kharkow|volume = 13|year = 1936|pages = 93–95|ref=harv}}\n*{{cite journal|last = Bojanov|first = B.|title = Elementary Proof of the Remez Inequality|journal = The American Mathematical Monthly|volume = 100|issue = 5|date = May 1993|pages = 483–485|doi = 10.2307/2324304|jstor = 2324304|publisher = Mathematical Association of America|ref=harv}}\n*{{cite journal|last = Fontes-Merz|first = N.|title = A multidimensional version of Turan's lemma|journal = Journal of Approximation Theory|volume = 140 |issue = 1|pages = 27–30|ref=harv|year=2006}}\n*{{cite journal|last = Nazarov|first = F.|author-link=Fedor Nazarov|title = Local estimates for exponential polynomials and their applications to inequalities of the uncertainty principle type|journal = Algebra i Analiz|volume = 5|issue = 4|pages = 3–66|ref=harv|year=1993}}\n*{{cite book|last = Nazarov|first = F.|author-link=Fedor Nazarov|title = Complete Version of Turan’s Lemma for Trigonometric Polynomials on the Unit Circumference|journal = Complex Analysis, Operators, and Related Topics |volume = 113|pages =239–246|ref=harv|year=2000}}\n*{{cite journal|last = Pólya|first = G.|author-link=George Pólya| title = Beitrag zur Verallgemeinerung des Verzerrungssatzes auf mehrfach zusammenhängende Gebiete|journal = Sitzungsberichte Akad. Berlin|year = 1928|pages = 280–282|ref=harv}}\n\n[[Category:Theorems in analysis]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Riesz rearrangement inequality",
      "url": "https://en.wikipedia.org/wiki/Riesz_rearrangement_inequality",
      "text": "In [[mathematics]], the '''Riesz rearrangement inequality''' (sometimes called '''Riesz-Sobolev''' inequality) states that for any three non-negative functions <math>f : \\mathbb{R}^n \\to \\mathbb{R}^+</math>, <math>g : \\mathbb{R}^n \\to \\mathbb{R}^+</math> and <math>h : \\mathbb{R}^n \\to \\mathbb{R}^+</math> satisfies the inequality\n:<math>\\iint_{\\mathbb{R}^n\\times \\mathbb{R}^n} f(x) g(x-y) h(y) \\, dx\\,dy\n\\le \\iint_{\\mathbb{R}^n\\times \\mathbb{R}^n} f^*(x) g^*(x-y) h^*(y) \\, dx\\,dy,\n</math>\nwhere <math>f^* : \\mathbb{R}^n \\to \\mathbb{R}^+</math>, <math>g^* : \\mathbb{R}^n \\to \\mathbb{R}^+</math> and <math>h^* : \\mathbb{R}^n \\to \\mathbb{R}^+</math> are the [[symmetric decreasing rearrangement]]s of the functions <math>f</math>, <math>g</math> and <math>h</math> respectively.\n\n== History ==\nThe inequality was first proved by [[Frigyes Riesz]] in 1930,<ref>{{Cite journal|last=Riesz |first=Frigyes |authorlink=Frigyes Riesz|year=1930|title=Sur une inégalité intégrale|periodical=[[Journal of the London Mathematical Society]]|volume=5|issue=3 |pages=162–168|doi=10.1112/jlms/s1-5.3.162|mr=1574064}}</ref> \nand independently reproved by S.L.Sobolev in 1938. It can be generalized to arbitrarily (but finitely) many functions acting on arbitrarily many variables.<ref>{{Cite journal|last1=Brascamp|first1=H.J.|last2=Lieb|first2=Elliott H.|author-link2=Elliott H. Lieb|last3=Luttinger|first3=J.M.|year=1974|title=A general rearrangement inequality for multiple integrals|periodical=Journal of Functional Analysis|volume=17|pages=227–237|mr=0346109}}</ref>\n\n== Applications ==\nThe Riesz rearrangement inequality can be used to prove the [[Pólya–Szegő inequality]].\n\n== Proofs ==\n\n=== One-dimensional case ===\n\nIn the one-dimensional case, the inequality is first proved when the functions <math>f</math>, <math>g</math> and <math>h</math> are [[characteristic functions]] of a finite unions of intervals. Then the inequality can be extended to characteristic functions of measurable sets, to measurable functions taking a finite number of values and finally to nonnegative measurable functions.<ref>{{cite book |first1=G. H. |last1=Hardy|authorlink1=G. H. Hardy |last2=Littlewood|first2=J. E.|authorlink2=J. E. Littlewood|last3=Polya|first3=G.|authorlink3=G. Polya|title=Inequalities|year=1952 |publisher=Cambridge University Press|location=Cambridge |isbn=978-0-521-35880-4}}</ref>\n\n=== Higher-dimensional case===\n\nIn order to pass from the one-dimensional case to the higher-dimensional case, the spherical rearrangement is approximated by Steiner symmetrization for which the one-dimensional argument applies directly by Fubini's theorem.<ref>\n{{cite book\n|last1=Lieb\n|first1=Elliott\n|authorlink1=Elliott H. Lieb\n|last2=Loss\n|first2=Michael|author2-link=Michael Loss\n|title=Analysis\n|year=2001|edition=2nd\n|publisher=[[American Mathematical Society]]\n|series=[[Graduate Studies in Mathematics]]|volume=14\n|isbn=978-0821827833}}</ref>\n\n== Equality cases ==\nIn the case where any one of the three functions is a strictly symmetric-decreasing function, equality holds only when the other two functions are equal, up to translation, to their symmetric-decreasing rearrangements.<ref>{{Cite journal|last=Burchard|first=Almut|year=1996|title=Cases of Equality in the Riesz Rearrangement Inequality|jstor=2118534|journal=Annals of Mathematics|volume=143|issue=3|pages=499–527|doi=10.2307/2118534|citeseerx=10.1.1.55.3241}}</ref>\n\n==References==\n{{Reflist}}\n\n[[Category:Inequalities]]\n[[Category:Rearrangement inequalities]]\n[[Category:Real analysis]]"
    },
    {
      "title": "Saint-Venant's theorem",
      "url": "https://en.wikipedia.org/wiki/Saint-Venant%27s_theorem",
      "text": "In [[solid mechanics]], it is common to analyze the properties of [[Beam (structure)|beams]] with constant cross section. '''Saint-Venant's theorem'''  states that the [[simply connected]] cross section with maximal [[Torsion (mechanics)|torsion]]al [[Rigidity (mathematics)|rigidity]] is a circle.<ref name=\"Makai\">E. Makai, A proof of Saint-Venant's theorem on torsional rigidity, Acta Mathematica Hungarica, Volume 17, Numbers 3&ndash;4 / September, 419&ndash;422,1966{{DOI|10.1007/BF01894885}}</ref> It is named after the French mathematician [[Adhémar Jean Claude Barré de Saint-Venant]].\n\nGiven a [[simply connected]]  domain ''D'' in the plane with area ''A'', <math>\\rho</math> the radius and <math>\\sigma</math> the area of its greatest inscribed circle, the torsional rigidity ''P'' \nof ''D'' is defined by\n\n:<math> P= 4\\sup_f \\frac{\\left( \\iint\\limits_D f\\, dx\\, dy\\right)^2}{\\iint\\limits_D {f_x}^2+{f_y}^2\\, dx\\, dy}.</math>\n\nHere the [[supremum]] is taken over all the continuously differentiable functions vanishing on the boundary of ''D''. The existence of this supremum is a consequence of [[Poincaré inequality]].\n\nSaint-Venant<ref>A J-C Barre de Saint-Venant,popularly known as संत वनंत Mémoire sur la torsion des prismes, Mémoires présentés par divers savants à l'Académie des Sciences, 14 (1856), pp. 233&ndash;560.</ref> conjectured in 1856 that\nof all domains ''D'' of equal area ''A'' the circular one has the greatest torsional rigidity, that is\n\n:<math> P \\le P_{\\text{circle}} \\le \\frac{A^2}{2 \\pi}.</math> \n\nA rigorous proof of this inequality was not given until  1948 by [[George Pólya|Pólya]].<ref>G. Pólya, Torsional rigidity, principal frequency, electrostatic capacity and symmetrization, Quarterly of Applied Math., 6 (1948), pp. 267, 277.</ref> Another proof was given by [[Harold Davenport|Davenport]] and reported in.<ref>G. Pólya and G. Szegő, Isoperimetric inequalities in Mathematical Physics (Princeton Univ.Press, 1951).</ref>  A more general proof and an estimate \n:<math>P< 4 \\rho^2 A</math>\n\nis given by Makai.<ref name=\"Makai\"/>\n\n==Notes==\n<references />\n\n[[Category:Elasticity (physics)]]\n[[Category:Calculus of variations]]\n[[Category:Inequalities]]\n[[Category:Physics theorems]]"
    },
    {
      "title": "Schur test",
      "url": "https://en.wikipedia.org/wiki/Schur_test",
      "text": "In [[mathematical analysis]], the '''Schur test''', named after German mathematician [[Issai Schur]], is a bound on the <math>L^2\\to L^2</math> [[operator norm]] of an [[integral operator]] in terms of its [[Schwartz kernel]] (see [[Schwartz kernel theorem]]).\n\nHere is one version.<ref>[[Paul Richard Halmos]] and Viakalathur Shankar Sunder, ''Bounded integral operators on <math>L^{2}</math> spaces'', Ergebnisse der Mathematik und ihrer Grenzgebiete (Results in Mathematics and Related Areas), vol. 96., Springer-Verlag, Berlin, 1978. Theorem 5.2.</ref>  Let <math>X,\\,Y</math> be two [[measurable space]]s  (such as <math>\\mathbb{R}^n</math>). Let <math>\\,T</math> be an [[integral operator]] with the non-negative Schwartz kernel <math>\\,K(x,y)</math>, <math>x\\in X</math>, <math>y\\in Y</math>:\n\n:<math>T f(x)=\\int_Y K(x,y)f(y)\\,dy.</math>\n\nIf there exist real functions <math>\\,p(x)>0</math> and <math>\\,q(y)>0</math> and numbers <math>\\,\\alpha,\\beta>0</math> such that\n\n:<math> (1)\\qquad \\int_Y K(x,y)q(y)\\,dy\\le\\alpha p(x) </math>\n\nfor [[almost everywhere|almost all]] <math>\\,x</math> and\n\n:<math> (2)\\qquad \\int_X p(x)K(x,y)\\,dx\\le\\beta q(y)</math>\n\nfor almost all <math>\\,y</math>, then <math>\\,T</math> extends to a [[continuous operator]] <math>T:L^2\\to L^2</math> with the [[operator norm]]\n\n:<math> \\Vert T\\Vert_{L^2\\to L^2} \\le\\sqrt{\\alpha\\beta}.</math>\n\nSuch functions <math>\\,p(x)</math>, <math>\\,q(y)</math> are called the Schur test functions.\n\nIn the original version, <math>\\,T</math> is a matrix and <math>\\,\\alpha=\\beta=1</math>.<ref>[[I. Schur]], ''Bemerkungen zur Theorie der Beschränkten Bilinearformen mit unendlich vielen Veränderlichen'', J. reine angew. Math. 140 (1911), 1–28.</ref>\n\n==Common usage and Young's inequality==\n\nA common usage of the Schur test is to take <math>\\,p(x)=q(y)=1.</math> Then we get:\n\n:<math>\n\\Vert T\\Vert^2_{L^2\\to L^2}\\le\n\\sup_{x\\in X}\\int_Y|K(x,y)| \\, dy\n\\cdot\n\\sup_{y\\in Y}\\int_X|K(x,y)| \\, dx.\n</math>\n\nThis inequality is valid no matter whether the Schwartz kernel <math>\\,K(x,y)</math> is non-negative or not.\n\nA similar statement about <math>L^p\\to L^q</math> operator norms is known as [[Young's inequality for integral operators]]:<ref>Theorem 0.3.1 in: [[Christopher D. Sogge|C. D. Sogge]], ''Fourier integral operators in classical analysis'', Cambridge University Press, 1993. {{ISBN|0-521-43464-5}}</ref>\n\nif\n\n:<math>\\sup_x\\Big(\\int_Y|K(x,y)|^r\\,dy\\Big)^{1/r} + \\sup_y\\Big(\\int_X|K(x,y)|^r\\,dx\\Big)^{1/r}\\le C,</math>\n\nwhere <math>r</math> satisfies <math>\\frac 1 r=1-\\Big(\\frac 1 p-\\frac 1 q\\Big)</math>, for some <math>1\\le p\\le q\\le\\infty</math>, then the operator <math>Tf(x)=\\int_Y K(x,y)f(y)\\,dy</math> extends to a continuous operator <math>T:L^p(Y)\\to L^q(X)</math>, with <math>\\Vert T\\Vert_{L^p\\to L^q}\\le C.</math>\n\n==Proof==\n\nUsing the [[Cauchy–Schwarz inequality]] and the inequality (1), we get:\n\n:<math>\n\\begin{align} |Tf(x)|^2=\\left|\\int_Y K(x,y)f(y)\\,dy\\right|^2\n&\\le \\left(\\int_Y K(x,y)q(y)\\,dy\\right) \n\\left(\\int_Y \\frac{K(x,y)f(y)^2}{q(y)} dy\\right)\\\\\n&\\le\\alpha p(x)\\int_Y \\frac{K(x,y)f(y)^2}{q(y)} \\, dy.\n\\end{align}\n</math>\n\nIntegrating the above relation in <math>x</math>, using [[Fubini's Theorem]], and applying the inequality (2), we get:\n\n:<math> \\Vert T f\\Vert_{L^2}^2 \n\\le \\alpha \\int_Y \\left(\\int_X p(x)K(x,y)\\,dx\\right) \\frac{f(y)^2}{q(y)} \\, dy\n\\le\\alpha\\beta \\int_Y f(y)^2 dy =\\alpha\\beta\\Vert f\\Vert_{L^2}^2. </math>\n\nIt follows that <math>\\Vert T f\\Vert_{L^2}\\le\\sqrt{\\alpha\\beta}\\Vert f\\Vert_{L^2}</math> for any <math>f\\in L^2(Y)</math>.\n\n==See also==\n\n* [[Hardy–Littlewood–Sobolev inequality]]\n\n==References==\n<references />\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Schur-convex function",
      "url": "https://en.wikipedia.org/wiki/Schur-convex_function",
      "text": "In mathematics, a '''Schur-convex function''', also known as '''S-convex''', '''isotonic function''' and '''order-preserving function''' is a [[function (mathematics)|function]] <math>f: \\mathbb{R}^d\\rightarrow \\mathbb{R}</math> that for all <math>x,y\\in \\mathbb{R}^d </math> such that <math>x</math> is [[majorization|majorized]] by <math>y</math>, one has that <math>f(x)\\le f(y)</math>. Named after [[Issai Schur]], Schur-convex functions are used in the study of [[majorization]]. Every function that is [[Convex function|convex]] and [[Symmetric function|symmetric]] is also Schur-convex.  The opposite [[Strict conditional|implication]] is not  true, but all Schur-convex functions are symmetric (under permutations of the arguments).<ref>{{cite book|last1=Roberts|first1=A. Wayne|last2=Varberg|first2=Dale E.|title=Convex functions|date=1973|publisher=Academic Press|location=New York|isbn=9780080873725|page=258}}</ref>\n\n== Schur-concave function ==\nA function ''f'' is 'Schur-concave' if its negative, -''f'', is Schur-convex.\n\n== Schur-Ostrowski criterion==\n\nIf ''f'' is symmetric and all first partial derivatives exist, then \n''f'' is Schur-convex if and only if\n\n<math>(x_i - x_j)\\left(\\frac{\\partial f}{\\partial x_i} - \\frac{\\partial f}{\\partial x_j}\\right) \\ge 0 </math> for all <math>x \\in \\mathbb{R}^d</math>\n\nholds for all 1≤''i''≠''j''≤''d''.<ref>{{cite book|last1=E. Peajcariaac|first1=Josip|last2=L. Tong|first2=Y.|title=Convex Functions, Partial Orderings, and Statistical Applications|publisher=Academic Press|isbn=9780080925226|page=333}}</ref>\n\n== Examples ==\n* <math> f(x)=\\min(x) </math> is Schur-concave while <math> f(x)=\\max(x) </math> is Schur-convex. This can be seen directly from the definition.\n* The [[Shannon entropy]] function <math>\\sum_{i=1}^d{P_i \\cdot \\log_2{\\frac{1}{P_i}}}</math> is Schur-concave.\n* The [[Rényi entropy]] function is also Schur-concave.\n* <math> \\sum_{i=1}^d{x_i^k},k \\ge 1 </math> is Schur-convex.\n* The function <math> f(x) = \\prod_{i=1}^n x_i  </math> is Schur-concave, when we assume all <math> x_i > 0 </math>. In the same way, all the [[Elementary symmetric polynomial|Elementary symmetric function]]s are Schur-concave, when <math> x_i > 0 </math>.\n* A natural interpretation of [[majorization]] is that if <math> x \\succ y </math> then <math> x </math> is less spread out than <math> y </math>. So it is natural to ask if statistical measures of variability are Schur-convex. The [[variance]] and [[standard deviation]] are Schur-convex functions, while the [[Median absolute deviation]] is not.\n* If <math> g </math> is a convex function defined on a real interval, then <math> \\sum_{i=1}^n g(x_i) </math> is Schur-convex.\n* A probability example: If  <math> X_1, \\dots, X_n </math> are [[exchangeable random variables]], then the function <math>  \\text{E} \\prod_{j=1}^n X_j^{a_j} </math> is Schur-convex as a function of <math> a=(a_1, \\dots, a_n) </math>, assuming that the expectations exist.\n* The [[Gini coefficient]] is strictly Schur convex.\n\n== References ==\n{{Reflist}}\n\n==See also==\n* [[Quasiconvex function]]\n\n[[Category:Convex analysis]]\n[[Category:Inequalities]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Schur's inequality",
      "url": "https://en.wikipedia.org/wiki/Schur%27s_inequality",
      "text": "In [[mathematics]], '''Schur's [[inequality (mathematics)|inequality]]''', named after [[Issai Schur]],\nestablishes that for all [[Nonnegative number|non-negative]] [[real number]]s\n''x'', ''y'', ''z'' and a [[positive number]] ''t'',\n\n:<math>x^t (x-y)(x-z) + y^t (y-z)(y-x) + z^t (z-x)(z-y) \\ge 0</math>\n\nwith equality if and only if ''x = y = z'' or two of them are equal and the other is zero. When ''t'' is an even positive [[integer]], the inequality holds for all real numbers ''x'', ''y'' and ''z''.\n\nWhen <math>t=1</math>, the following well-known special case can be derived:\n:<math>x^3 + y^3 + z^3 + 3xyz \\geq xy(x+y) + xz(x+z) + yz(y+z)</math>\n\n== Proof ==\nSince the inequality is symmetric in <math>x,y,z</math> we may assume without loss of generality that <math> x \\geq y \\geq z</math>. Then the inequality\n\n: <math>(x-y)[x^t(x-z)-y^t(y-z)]+z^t(x-z)(y-z) \\geq 0</math>\n\nclearly holds, since every term on the left-hand side of the inequality is non-negative. This rearranges to Schur's inequality.\n\n== Extensions ==\nA [[generalization]] of Schur's inequality is the following:\nSuppose ''a,b,c'' are positive real numbers. If the triples ''(a,b,c)'' and ''(x,y,z)'' are [[Order isomorphic|similarly sorted]], then the following inequality holds:\n\n:<math>a (x-y)(x-z) + b (y-z)(y-x) + c (z-x)(z-y) \\ge 0.</math>\n\nIn 2007, [[Romania]]n mathematician [[Valentin Vornicu]] showed that a yet further generalized form of Schur's inequality holds: \n\nConsider <math>a,b,c,x,y,z \\in \\mathbb{R}</math>, where <math>a \\geq b \\geq c</math>, and either <math>x \\geq y \\geq z</math> or <math>z \\geq y \\geq x</math>. Let <math>k \\in \\mathbb{Z}^{+}</math>, and let <math>f:\\mathbb{R} \\rightarrow \\mathbb{R}_{0}^{+}</math> be either [[convex function|convex]] or [[monotonic]]. Then,\n: <math>{f(x)(a-b)^k(a-c)^k+f(y)(b-a)^k(b-c)^k+f(z)(c-a)^k(c-b)^k \\geq 0}.</math>\t\nThe standard form of Schur's is the case of this inequality where ''x'' = ''a'', ''y'' = ''b'', ''z'' = ''c'', ''k'' = 1, ''ƒ''(''m'') = ''m''<sup>''r''</sup>.<ref>Vornicu, Valentin; ''Olimpiada de Matematica... de la provocare la experienta''; GIL Publishing House; Zalau, Romania.</ref>\n\nAnother possible extension states that if the non-negative real numbers <math> x \\geq y \\geq z \\geq v </math> with  and the positive real number ''t'' are such that ''x''&nbsp;+&nbsp;''v''&nbsp;≥&nbsp;''y''&nbsp;+&nbsp;''z'' then<ref>{{cite journal|last1=Finta|first1=Béla|title=A Schur Type Inequality for Five Variables|journal=Procedia Technology|date=2015|volume=19|pages=799–801|doi=10.1016/j.protcy.2015.02.114|url=http://www.sciencedirect.com/science/article/pii/S2212017315001152}}</ref>\n\n: <math>x^t (x-y)(x-z)(x-v) + y^t (y-x)(y-z)(y-v) + z^t (z-x)(z-y)(z-v) + v^t (v-x)(v-y)(v-z) \\ge 0. </math>\n\n==Notes==\n{{reflist}}\n\n[[Category:Inequalities]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Sedrakyan's inequality",
      "url": "https://en.wikipedia.org/wiki/Sedrakyan%27s_inequality",
      "text": "{{mi|\n{{Orphan|date=August 2018}}\n{{notability|date=September 2018}}\n{{COI|date=September 2018}}\n}}\nThe following inequality is known as '''Sedrakyan's inequality''', '''Engel’s form''' or '''Titu’s lemma''', respectively, referring to the article “''About the applications of one useful inequality''” of [[Nairi Sedrakyan]] published in 1997,<ref name=\"A useful inequality\">{{cite web |last=Sedrakyan |first=Nairi |year=1997 |title=About the applications of one useful inequality |publisher=Kvant Journal |pages=42–44, 97(2), Moscow |url=http://kvant.mccme.ru/au/sedrakyan_n.htm}}</ref> to the book ''Problem-solving strategies'' of [[Arthur Engel (mathematician)]] published in 1998 and to the book ''Mathematical Olympiad Treasures'' of [[Titu Andreescu]] published in 2003.<ref name=\"Algebraic inequalities (English) preview\">{{cite web |last=Sedrakyan |first=Nairi |year=1997 |title=A useful inequality |publisher=Springer International publishing |page=107 |url=https://books.google.com/books?id=8DNjDwAAQBAJ&pg=PA106&lpg=PA106&dq=algebraic+inequalities+sedrakyan+one+useful+inequality&source=bl&ots=s5Av4qHefJ&sig=yf_TL3eyhGhgLWo7oTTuVsMj8VI&hl=fr&sa=X&ved=2ahUKEwiqjfqy25DdAhULPN8KHY_CATUQ6AEwDXoECAUQAQ#v=onepage&q=algebraic%20inequalities%20sedrakyan%20one%20useful%20inequality&f=false}}</ref><ref name=\"Statement of the inequality\">{{cite web |title=Statement of the inequality |year=2018 |publisher=Brilliant Math & Science |url=https://brilliant.org/wiki/titus-lemma/}}</ref>\nIt is a direct consequence of [[Cauchy-Bunyakovsky-Schwarz inequality]]. Nevertheless, in his article (1997) Sedrakyan has noticed that written in this form this inequality can be used as a mathematical proof technique and it has very useful '''new applications'''. In the book ''Algebraic Inequalities'' (Sedrakyan) are provided several generalizations of this inequality.<ref name=\"Algebraic inequalities\">{{cite web |last=Sedrakyan |first=Nairi |year=2018 |title=Algebraic inequalities |publisher=Springer International publishing |pages=107–109 |url=https://www.springer.com/us/book/9783319778358#aboutAuthors}}</ref>\n\n== Statement of the inequality ([[Nairi Sedrakyan]] (1997), [[Arthur Engel (mathematician)]] (1998), [[Titu Andreescu]] (2003)) ==\nFor any reals <math> a_1, a_2, a_3,\\ldots, a_n </math> and positive reals <math> b_1, b_2, b_3,\\ldots, b_n </math>, we have <math> \\frac{a^2_1}{b_1}+\\frac{a^2_2}{b_2}+\\cdots+\\frac{a^2_n}{b_n} \\geq \\frac{(a_1+a_2+\\cdots+a_n)^2}{b_1 + b_2 +\\cdots+ b_n}. </math>\n\n== Direct applications ==\n'''Example 1.''' [[Nesbitt's inequality]].\n\nFor positive real numbers <math> a,b,c </math> we have that \n<math> \\frac{a}{b+c}+\\frac{b}{a+c}+\\frac{c}{a+b} \\geq \\frac{3}{2}. </math>\n\n'''Example 2.''' [[International Mathematical Olympiad]] (IMO) 1995.\n\nFor positive real numbers <math> a,b,c </math>, where <math> abc=1 </math> we have that <math> \\frac{1}{a^3(b+c)}+\\frac{1}{b^3(b+c)}+\\frac{1}{c^3(a+b)} \\geq \\frac{3}{2}. </math>\n\n'''Example 3.'''\n\nFor positive real numbers <math> a,b </math> we have that <math> 8(a^4+b^4) \\geq (a+b)^4. </math>\n\n'''Example 4.'''\n\nFor positive real numbers <math> a,b,c </math> we have that <math> \\frac{1}{a+b}+\\frac{1}{b+c}+\\frac{1}{a+c} \\geq \\frac{9}{2(a+b+c)}. </math>\n\n== Proofs ==\n'''Example 1.'''\n\nWe have that <math> \\frac{a}{b+c}+\\frac{b}{a+c}+\\frac{c}{a+b} = \\frac{a^2}{a(b+c)}+\\frac{b^2}{b(a+c)}+\\frac{c^2}{c(a+b)} = \\frac{(a+b+c)^2}{2(ab+bc+ac)} \\geq \\frac{3}{2}. </math>\n\n'''Example 2.'''\n\nWe have that <math> \\frac{\\Big(\\frac{1}{a}\\Big)^2}{a(b+c)} + \\frac{\\Big(\\frac{1}{b}\\Big)^2}{b(a+c)} + \\frac{\\Big(\\frac{1}{c}\\Big)^2}{c(a+b)} \\geq \\frac{\\Big(\\frac{1}{a}+\\frac{1}{b}+\\frac{1}{c}\\Big)^2}{2(ab+bc+ac)} = \\frac{ab+bc+ac}{2} \\geq \\frac{3 \\sqrt[3]{a^2 b^2 c^2}}{2} = \\frac{3}{2}. </math>\n\n'''Example 3.'''\n\nWe have that <math> a^4+b^4 =\\frac{a^4}{1}+\\frac{b^4}{1} \\geq \\frac{(a^2+b^2)^2}{2} \\geq \\frac{\\Big( \\frac{(a+b)^2}{2} \\Big)^2}{2} = \\frac{(a+b)^4}{8}. </math>\n\n'''Example 4.'''\n\nWe have that <math> \\frac{1}{a+b}+\\frac{1}{b+c}+\\frac{1}{a+c} \\geq \\frac{(1+1+1)^2}{2(a+b+c)} = \\frac{9}{2(a+b+c)}. </math>\n\n{{Linear algebra}}\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Sedrakyan's inequality}}\n[[Category:Inequalities]]\n[[Category:Linear algebra]]\n[[Category:Operator theory]]\n[[Category:Articles containing proofs]]\n[[Category:Mathematical analysis]]\n[[Category:Probabilistic inequalities]]"
    },
    {
      "title": "Shapiro inequality",
      "url": "https://en.wikipedia.org/wiki/Shapiro_inequality",
      "text": "In [[mathematics]], the '''Shapiro inequality''' is an [[inequality (mathematics)|inequality]] proposed by H. Shapiro in 1954.\n\n==Statement of the inequality==\n\nSuppose <math>n</math> is a [[natural number]] and <math>x_1, x_2, \\dots, x_n</math> are [[positive number]]s and:\n\n* <math>n</math> is even and less than or equal to <math>12</math>, or\n* <math>n</math> is odd and less than or equal to <math>23</math>.\n\nThen the '''Shapiro inequality''' states that\n\n:<math>\\sum_{i=1}^{n} \\frac{x_i}{x_{i+1}+x_{i+2}} \\geq \\frac{n}{2}</math>\n\nwhere <math>x_{n+1}=x_1, x_{n+2}=x_2</math>.\n\nFor greater values of <math>n</math> the inequality does not hold and the strict lower bound is <math>\\gamma \\frac{n}{2}</math> with <math>\\gamma \\approx 0.9891\\dots</math>.\n\nThe initial proofs of the inequality in the pivotal cases <math>n=12</math> (Godunova and Levin, 1976) and <math>n=23</math> (Troesch, 1989) rely on numerical computations. In 2002, P.J. Bushell and J.B. McLeod published an analytical proof for&nbsp;<math>n=12</math>.\n\nThe value of <math>\\gamma</math> was determined in 1971 by [[Vladimir Drinfeld]], who won a [[Fields Medal]] in 1990.  Specifically, Drinfeld showed that the strict lower bound <math>\\gamma</math> is given by <math>\\frac{1}{2} \\psi(0)</math>, where <math>\\psi</math> is the function convex hull of <math>f(x)=e^{-x}</math></sup> and <math>g(x) = \\frac{2}{e^x+e^{\\frac{x}{2}}}</math>. (That is, the region above the graph of <math>\\psi</math> is the [[convex hull]] of the union of the regions above the graphs of '<math>f</math> and <math>g</math>.)\n\nInterior local minima of the left-hand side are always<math>\\ge\\frac{n}2</math> (Nowosad, 1968).\n\n==Counter-examples for higher <math>n</math>==\n\nThe first counter-example was found by Lighthill in 1956, for <math>n=20</math>:\n:<math>x_{20} = (1+5\\epsilon,\\ 6\\epsilon,\\ 1+4\\epsilon,\\ 5\\epsilon,\\ 1+3\\epsilon,\\ 4\\epsilon,\\ 1+2\\epsilon,\\ 3\\epsilon,\\ 1+\\epsilon,\\ 2\\epsilon,\\ 1+2\\epsilon,\\ \\epsilon,\\ 1+3\\epsilon,\\ 2\\epsilon,\\ 1+4\\epsilon,\\ 3\\epsilon,\\ 1+5\\epsilon,\\ 4\\epsilon,\\ 1+6\\epsilon,\\ 5\\epsilon)</math> where <math>\\epsilon</math> is close to&nbsp;0.\nThen the left-hand side is equal to <math>10 - \\epsilon^2 + O(\\epsilon^3)</math>, thus lower than 10 when <math>\\epsilon</math> is small enough.\n\nThe following counter-example for <math>n=14</math> is by Troesch (1985):\n:<math>x_{14} = (0, 42, 2, 42, 4, 41, 5, 39, 4, 38, 2, 38, 0, 40)</math> (Troesch, 1985)<!--this example has been double-checked by user:FvdP, 2010/01/12-->\n<!-- Next counter-example is cited in A M Fink 1998 as from Troesch 1985. Sadly, it seems wrong: I compute LHS = 0.50010878... there probably is a typo in it.\n:<math>x_{25} = (25, 0, 29, 0, 34, 5, 35, 13, 30, 17, 24, 18, 18, 17, 13, 16, 9, 16, 5, 16, 2, 18, 0, 20, 0)</math>\n-->\n\n==References==\n* {{cite book | zbl=0895.26001 | last=Fink | first=A.M. | chapter=Shapiro's inequality | editor=Gradimir V. Milovanović, G. V. | title=Recent progress in inequalities. Dedicated to Prof. Dragoslav S. Mitrinović | location=Dordrecht | publisher=Kluwer Academic Publishers. | series=Mathematics and its Applications (Dordrecht) | volume=430 | pages=241–248 | year=1998 | isbn=0-7923-4845-1 }}\n* {{cite journal | zbl=1018.26010 | last1=Bushell | first1=P.J. | last2=McLeod | first2=J.B. | title=Shapiro's cyclic inequality for even n | journal=J. Inequal. Appl. | volume=7 | number=3 | pages=331–348 | year=2002 | issn=1029-242X |url=ftp://ftp.sam.math.ethz.ch/EMIS/journals/HOA/JIA/40a3.pdf}} They give an analytic proof of the formula for even <math>n\\le12</math>, from which the result for all <math>n\\le12</math> follows. They state <math>n=23</math> as an open problem.\n\n==External links==\n* [https://web.archive.org/web/20100630173514/http://www.math.niu.edu/~rusin/known-math/99/shapiro Usenet discussion in 1999] (Dave Rusin's notes)\n* [http://planetmath.org/encyclopedia/ShapiroInequality.html PlanetMath]\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Shearer's inequality",
      "url": "https://en.wikipedia.org/wiki/Shearer%27s_inequality",
      "text": "{{context|date=November 2010}}\n\nIn [[information theory]], '''Shearer's inequality''',<ref>{{cite journal|last1=Chung|first1=F.R.K.|last2=Graham|first2=R.L.|last3=Frankl|first3=P.|last4=Shearer|first4=J.B.|title=Some Intersection Theorems for Ordered Sets and Graphs|journal=J. Comb. Theory A|date=1986|volume=43|pages=23–37}}</ref> named after James Shearer, states that if ''X''<sub>1</sub>,&nbsp;...,&nbsp;''X''<sub>''d''</sub> are [[random variable]]s and ''S''<sub>1</sub>,&nbsp;...,&nbsp;''S''<sub>''n''</sub> are subsets of {1,&nbsp;2,&nbsp;...,&nbsp;''d''} such that every integer between 1 and ''d'' lies in at least ''r'' of these subsets, then\n\n: <math> H[(X_1,\\dots,X_d)] \\leq \\frac{1}{r}\\sum_{i=1}^n H[(X_j)_{j\\in S_i}]</math>\n\nwhere <math> (X_{j})_{j\\in S_{i}}</math> is the [[Cartesian product]] of random variables <math>X_{j}</math> with indices ''j'' in <math>S_{i}</math> (so the dimension of this vector is equal to the size of <math>S_{i}</math>).\n\n== References ==\n{{Reflist}}\n\n{{DEFAULTSORT:Shearer's Inequality}}\n[[Category:Information theory]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Singleton bound",
      "url": "https://en.wikipedia.org/wiki/Singleton_bound",
      "text": "In [[coding theory]], the '''Singleton bound''', named after Richard Collom Singleton, is a relatively crude upper bound on the size of an arbitrary [[block code]] <math>C</math> with block length <math>n</math>, size <math>M</math> and minimum distance <math>d</math>.\n\n==Statement of the bound==\nThe minimum distance of a set <math>C</math> of codewords of length <math>n</math> is defined as \n:<math>d = \\min_{\\{x,y \\in C : x \\neq y\\}} d(x,y)</math> \nwhere <math>d(x,y)</math> is the [[Hamming distance]] between <math>x</math> and <math>y</math>. The expression <math>A_{q}(n,d)</math> represents the maximum number of possible codewords in a <math>q</math>-ary block code of length <math>n</math> and minimum distance&nbsp;<math>d</math>.\n\nThen the Singleton bound states that\n\n:<math>A_q(n,d) \\leq q^{n-d+1}.</math>\n\n==Proof==\nFirst observe that the number of <math>q</math>-ary words of length <math>n</math> is <math>q^n</math>, since each letter in such a word may take one of <math>q</math> different values, independently of the remaining letters.\n\nNow let <math>C</math> be an arbitrary <math>q</math>-ary block code of minimum distance <math>d</math>. Clearly, all codewords <math>c \\in C</math> are distinct. If we [[Puncturing|puncture]] the code by deleting the first <math>d-1</math> letters of each codeword, then all resulting codewords must still be pairwise different, since all of the original codewords in <math>C</math> have [[Hamming distance]] at least <math>d</math> from each other. Thus the size of the altered code is the same as the original code.\n\nThe newly obtained codewords each have length\n\n:<math>n-(d-1)=n-d+1</math>,\n\nand thus, there can be at most <math>q^{n-d+1}</math> of them. Since <math>C</math> was arbitrary, this bound must hold for the largest possible code with these parameters, thus:<ref>{{harvnb|Ling|Xing|2004|loc=p. 93}}</ref>\n\n:<math>|C| \\le A_q(n,d) \\leq q^{n-d+1}.</math>\n\n==Linear codes==\n\nIf <math>C</math> is a [[linear code]] with block length <math>n</math>, dimension <math>k</math> and minimum distance <math>d</math> over the [[finite field]] with <math>q</math> elements, then the maximum number of codewords is <math>q^k</math> and the Singleton bound implies:\n:<math>q^k \\leq q^{n-d+1}</math>,\nso that\n:<math>k \\leq n - d + 1</math>,\nwhich is usually written as<ref>{{harvnb|Roman|1992|loc=p. 175}}</ref>\n:<math>d \\leq n - k + 1</math>.\n\nIn the linear code case a different proof of the Singleton bound can be obtained by observing that rank of the [[parity check matrix]] is <math> n - k</math>.<ref>{{harvnb|Pless|1998|loc=p. 26}}</ref> Another simple proof follows from observing that the rows of any generator matrix in standard form have weight at most <math>n - k + 1</math>.\n\n==History==\nThe usual citation given for this result is {{harvtxt|Singleton|1964}}, but according to {{harvtxt|Welsh|1988|loc=p. 72}} the result can be found in a 1953 paper of Komamiya.<ref>{{citation|first=Y.|last=Komamiya|year=1953|title=Application of logical mathematics to information theory|journal=Proc. 3rd Japan. Nat. Cong. Appl. Math.|page=437}}</ref>\n\n==MDS codes==\n\nLinear block codes that achieve equality in the Singleton bound are called '''MDS (maximum distance separable) codes'''. Examples of such codes include codes that have only two codewords (the all-zero word and the all-one word, having thus minimum distance <math>n</math>), codes that use the whole of <math>(\\mathbb{F}_{q})^{n}</math> (minimum distance 1), codes with a single parity symbol (minimum distance 2) and their [[dual code]]s. These are often called ''trivial'' MDS codes.\n\nIn the case of binary alphabets, only trivial MDS codes exist.<ref>{{harvnb|Vermani|1996|loc= Proposition 9.2}}</ref><ref>{{harvnb|Ling|Xing|2004|loc=p. 94 Remark 5.4.7}}</ref>\n\nExamples of non-trivial MDS codes include [[Reed–Solomon error correction|Reed-Solomon codes]] and their extended versions.<ref>{{harvnb|MacWilliams|Sloane|1977|loc= Ch. 11}}</ref><ref>{{harvnb|Ling|Xing|2004|loc=p. 94}}</ref>\n\nMDS codes are an important class of block codes since, for a fixed <math>n</math> and <math>k</math>, they have the greatest error correcting and detecting capabilities. There are several ways to characterize MDS codes:<ref>{{harvnb|Roman|1992|loc=p. 237, Theorem 5.3.7}}</ref>\n\n:''Theorem'': Let <math>C</math> be a linear <nowiki>[</nowiki><math>n,k,d</math><nowiki>]</nowiki> code over <math>\\mathbb{F}_q</math>. The following are equivalent:\n:* <math>C</math> is an MDS code.\n:* Any <math>k</math> columns of a [[generator matrix]] for <math>C</math> are [[linearly independent]].\n:* Any <math>n-k</math> columns of a [[parity check matrix]] for <math>C</math> are linearly independent.\n:* <math>C^{\\perp}</math> is an MDS code.\n:* If <math>G = (I|A)</math> is a generator matrix for <math>C</math> in standard form, then every square submatrix of <math>A</math> is [[nonsingular]].\n:* Given any <math>d</math> coordinate positions, there is a (minimum weight) codeword whose [[support (mathematics)|support]] is precisely these positions.\n\nThe last of these characterizations permits, by using the [[MacWilliams identities]], an explicit formula for the complete weight distribution of an MDS code.<ref>{{harvnb|Roman|1992|loc=p. 240}}</ref>\n\n:''Theorem'': Let <math>C</math> be a linear <nowiki>[</nowiki><math>n,k,d</math><nowiki>]</nowiki> MDS code over <math>\\mathbb{F}_q</math>. If <math>A_w</math> denotes the number of codewords in <math>C</math> of weight <math>w</math>, then\n::<math>A_w = \\binom{n}{w} \\sum_{j=0}^{w-d} (-1)^j \\binom{w}{j} (q^{w-d+1-j} -1) = \\binom{n}{w}(q-1)\\sum_{j=0}^{w-d} (-1)^j \\binom{w-1}{j}q^{w-d-j}.</math>\n\n===Arcs in projective geometry===\n\nThe linear independence of the columns of a generator matrix of an MDS code permits a construction of MDS codes from objects in [[Finite geometry|finite]] [[projective geometry]]. Let <math>PG(N,q)</math> be the finite [[projective space]] of (geometric) dimension <math>N</math> over the finite field <math>\\mathbb{F}_q</math>. Let <math>K = \\{P_1,P_2,\\dots,P_m \\}</math> be a set of points in this projective space represented with [[homogeneous coordinates]]. Form the <math>(N+1) \\times m</math> matrix <math>G</math> whose columns are the homogeneous coordinates of these points. Then,<ref>{{citation|first1=A.A.|last1=Bruen|first2=J.A.|last2=Thas|first3=A.|last3=Blokhuis|title=On M.D.S. codes, arcs in PG(n,q), with q even, and a solution of three fundamental problems of B. Segre|journal=Invent. Math.|volume=92|year=1988|pages=441–459|doi=10.1007/bf01393742}}</ref>\n\n:''Theorem'': <math>K</math> is a (spatial) [[Arc (projective geometry)|<math>m</math>-arc]] if and only if <math>G</math> is the generator matrix of an <math>[m,N+1,m-N]</math> MDS code over <math>\\mathbb{F}_q</math>.\n\n==See also==\n*[[Gilbert–Varshamov bound]]\n*[[Plotkin bound]]\n*[[Hamming bound]]\n*[[Johnson bound]]\n*[[Griesmer bound]]\n\n==Notes==\n{{reflist|3}}\n\n==References==\n* {{citation|first1=San|last1=Ling|first2=Chaoping|last2=Xing|title=Coding Theory / A First Course|publisher=Cambridge University Press|year=2004|isbn=0-521-52923-9}}\n* {{citation | first1=F.J.|last1=MacWilliams | author1-link=Jessie MacWilliams | first2=N.J.A.|last2=Sloane|author2-link= Neil Sloane| title=The Theory of Error-Correcting Codes | publisher=North-Holland | date=1977 | isbn=0-444-85193-3 | pages=33, 37 }}\n* {{citation|first=Vera|last=Pless|author-link=Vera Pless|title=Introduction to the Theory of Error-Correcting Codes|edition=3rd|publisher=Wiley Interscience|year=1998|isbn=0-471-19047-0}}\n* {{citation|first=Steven|last=Roman|title=Coding and Information Theory|series=[[Graduate Texts in Mathematics|GTM]]|volume=134|publisher=Springer-Verlag|year=1992|isbn=0-387-97812-7}}\n* {{citation| first=R.C.|last=Singleton | title=Maximum distance q-nary codes | journal=IEEE Trans. Inf. Theory | volume=10 | pages=116–118 | year=1964 | doi=10.1109/TIT.1964.1053661 | issue=2 }} \n* {{citation|first=L. R.|last= Vermani|title=Elements of algebraic coding theory|publisher=Chapman & Hall|year= 1996}}\n* {{citation|first=Dominic|last=Welsh|title=Codes and Cryptography|year=1988|publisher=Oxford University Press|isbn=0-19-853287-3}}\n\n==Further reading==\n* {{cite book | author=J.H. van Lint | authorlink=Jack van Lint | title=Introduction to Coding Theory | edition=2nd | publisher=Springer-Verlag | series=[[Graduate Texts in Mathematics|GTM]] | volume=86 | date=1992 | isbn=3-540-54894-7 | page=61 }}\n* {{cite book | last1=Niederreiter | first1=Harald | author1-link = Harald Niederreiter | last2=Xing | first2=Chaoping | title=Rational points on curves over finite fields. Theory and Applications | series=London Mathematical Society Lecture Note Series | volume=285 | location=[[Cambridge]] | publisher=[[Cambridge University Press]] | year=2001 | chapter=6.  Applications to algebraic coding theory | isbn=0-521-66543-4 | zbl=0971.11033 }}\n\n{{DEFAULTSORT:Singleton Bound}}\n[[Category:Coding theory]]\n[[Category:Inequalities]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Sobolev inequality",
      "url": "https://en.wikipedia.org/wiki/Sobolev_inequality",
      "text": "In [[mathematics]], there is in [[mathematical analysis]] a class of '''Sobolev inequalities''', relating norms including those of [[Sobolev space]]s. These are used to prove the '''Sobolev embedding theorem''', giving inclusions between certain [[Sobolev space]]s, and the [[Rellich–Kondrachov theorem]] showing that under slightly stronger conditions some Sobolev spaces are [[compactly embedded]] in others. They are named after [[Sergei Lvovich Sobolev]].\n\n==Sobolev embedding theorem==\n\n[[File:Sobolev embedding theorem.svg|thumb|250px|Graphical representation of the embedding conditions. The space {{math|''W<sup>&thinsp;3,p</sup>''}}, represented by a blue dot at the point {{math|''(1/p, 3)''}}, embeds into the spaces indicated by red dots, all lying on a line with slope {{math|''n''}}. The white circle at {{math|''(0,0)''}} indicates the impossibility of optimal embeddings into {{math|''L<sup>&thinsp;∞</sup>''}}.]]\nLet {{math|''W<sup>&thinsp;k,p</sup>''('''R'''<sup>''n''</sup>)}} denote the Sobolev space consisting of all real-valued functions on {{math|'''R'''<sup>''n''</sup>}} whose first {{mvar|k}} [[weak derivative]]s are functions in [[Lp space|{{math|''L<sup>p</sup>''}}]].  Here {{mvar|k}} is a non-negative integer and {{math|1 ≤ ''p'' < ∞}}.  The first part of the Sobolev embedding theorem states that if {{math|''k'' > ''ℓ''}} and {{math|1 ≤ ''p'' < ''q'' < ∞}} are two real numbers such that\n\n:<math>\\frac{1}{p}-\\frac{k}{n} = \\frac{1}{q} -\\frac{\\ell}{n},</math>\n\nthen\n\n:<math>W^{k,p}(\\mathbf{R}^n)\\subseteq W^{\\ell,q}(\\mathbf{R}^n)</math>\n\nand the embedding is continuous. In the special case of {{math|''k'' {{=}} 1}} and {{math|''ℓ'' {{=}} 0}}, Sobolev embedding gives\n\n:<math>W^{1,p}(\\mathbf{R}^n) \\subseteq L^{p^*}(\\mathbf{R}^n)</math>\n\nwhere {{math|''p''<sup>∗</sup>}} is the '''[[Sobolev conjugate]]''' of {{mvar|p}}, given by\n\n:<math>\\frac{1}{p^*} = \\frac{1}{p} - \\frac{1}{n}.</math>\n\nThis special case of the Sobolev embedding is a direct consequence of the [[#Gagliardo–Nirenberg–Sobolev inequality|Gagliardo–Nirenberg–Sobolev inequality]].\n\n[[File:Sobolev embedding theorem (Morrey case).svg|thumb|250px|If the line from the picture above intersects the x-axis at ''s = r + α'', the embedding into a Hölder space {{math|''C<sup>&thinsp;r, α</sup>''}} (red) holds. White circles indicate intersection points at which ''optimal'' embeddings are not valid.]]\n\nThe second part of the Sobolev embedding theorem applies to embeddings in [[Hölder space]]s {{math|''C<sup>&thinsp;r,α</sup>''('''R'''<sup>''n''</sup>)}}. If {{math|''n'' < ''p''}} and\n\n:<math>\\frac{1}{p}-\\frac{k}{n} = -\\frac{r + \\alpha}{n},</math>\n\nwith {{math|''α'' ∈ (0, 1]}} then one has the embedding\n\n:<math>W^{k,p}(\\mathbf{R}^n)\\subset C^{r,\\alpha}(\\mathbf{R}^n).</math>\n\nThis part of the Sobolev embedding is a direct consequence of [[#Morrey's inequality|Morrey's inequality]]. Intuitively, this inclusion expresses the fact that the existence of sufficiently many weak derivatives implies some continuity of the classical derivatives.\n\n===Generalizations===\nThe Sobolev embedding theorem holds for Sobolev spaces {{math|''W<sup>&thinsp;k,p</sup>''(''M'')}} on other suitable domains {{mvar|M}}. In particular ({{harvnb|Aubin|1982|loc=Chapter 2}}; {{harvnb|Aubin|1976}}), both parts of the Sobolev embedding hold when\n* {{mvar|M}} is a [[bounded set|bounded]] [[open set]] in {{math|'''R'''<sup>''n''</sup>}} with [[Lipschitz continuity|Lipschitz]] boundary (or whose boundary satisfies the [[cone condition]]; {{harvnb|Adams|1975|loc=Theorem 5.4}})\n* {{mvar|M}} is a [[compact space|compact]] [[Riemannian manifold]]\n* {{mvar|M}} is a compact Riemannian [[manifold with boundary]] with Lipschitz boundary\n* {{mvar|M}} is a [[complete manifold|complete]] Riemannian manifold with [[injectivity radius]] {{math|''δ'' > 0}} and bounded [[sectional curvature]].\n\n===Kondrachov embedding theorem===\n{{main article|Rellich–Kondrachov theorem}}\nOn a compact manifold with {{math|''C''<sup>1</sup>}} boundary, the '''Kondrachov embedding theorem''' states that if {{math|''k'' > ''ℓ''}} and<math display=\"block\">\\frac{1}{p}-\\frac{k}{n} < \\frac{1}{q} -\\frac{\\ell}{n}</math>then the Sobolev embedding\n\n:<math>W^{k,p}(M)\\subset W^{\\ell,q}(M)</math>\n\nis [[completely continuous]] (compact). Note that the condition is just as in the first part of the Sobolev embedding theorem, with the equality replaced by an inequality, thus requiring a more regular space {{math|''W<sup>&thinsp;k,p</sup>''('''M''')}}.\n\n==Gagliardo–Nirenberg–Sobolev inequality==\nAssume that {{mvar|u}} is a continuously differentiable real-valued function on {{math|'''R'''<sup>''n''</sup>}} with [[compact support]]. Then for {{math|1 &le; ''p'' < ''n''}} there is a constant {{mvar|C}} depending only on {{mvar|n}} and {{mvar|p}} such that\n\n: <math>\\|u\\|_{L^{p^*}(\\mathbf{R}^n)}\\leq C \\|Du\\|_{L^{p}(\\mathbf{R}^n)}.</math>\n\nwith 1/p* = 1/p - 1/n.\nThe case <math> 1< p < n </math> is due to Sobolev, <math>  p =1 </math> to Gagliardo and Nirenberg independently.  The Gagliardo–Nirenberg–Sobolev inequality implies directly the Sobolev embedding\n\n:<math>W^{1,p}(\\mathbf{R}^n) \\sub L^{p^*}(\\mathbf{R}^n).</math>\n\nThe embeddings in other orders on {{math|'''R'''<sup>''n''</sup>}} are then obtained by suitable iteration.\n\n==Hardy–Littlewood–Sobolev lemma==\nSobolev's original proof of the Sobolev embedding theorem relied on the following, sometimes known as the Hardy–Littlewood–Sobolev [[fractional integration]] theorem. An equivalent statement is known as the '''Sobolev lemma''' in {{harv|Aubin|1982|loc=Chapter 2}}.  A proof is in {{harv|Stein|loc=Chapter V, §1.3}}.\n\nLet {{math|0 < ''α'' < ''n''}} and {{math|1 < ''p'' < ''q'' < ∞}}.  Let {{math|''I<sub>α</sub>'' {{=}} (−Δ)<sup>−''α''/2</sup>}} be the [[Riesz potential]] on {{math|'''R'''<sup>''n''</sup>}}.  Then, for {{mvar|q}} defined by\n\n:<math>\\frac 1 q = \\frac 1 p - \\frac \\alpha n</math>\n\nthere exists a constant {{mvar|C}} depending only on {{mvar|p}} such that\n\n:<math>\\left \\|I_\\alpha f \\right \\|_q \\le C \\|f\\|_p.</math>\n\nIf {{math|''p'' {{=}} 1}}, then one has two possible replacement estimates.  The first is the more classical weak-type estimate:\n\n:<math>m \\left \\{x : \\left |I_\\alpha f(x) \\right | > \\lambda \\right \\} \\le C \\left( \\frac{\\|f\\|_1}{\\lambda} \\right )^q,</math>\n\nwhere {{math|1/''q'' {{=}} 1 − ''α''/''n''}}.  Alternatively one has the estimate<math display=\"block\">\\left \\|I_\\alpha f \\right \\|_q \\le C \\|Rf\\|_1,</math>where <math> Rf </math> is the vector-valued [[Riesz transform]], c.f.   {{harv|Schikorra | Spector | Van Schaftingen}}.  The boundedness of the [[Riesz transform]]s implies that the latter inequality gives a unified way to write the family of inequalities for the Riesz potential.\n\nThe Hardy–Littlewood–Sobolev lemma implies the Sobolev embedding essentially by the relationship between the [[Riesz transform]]s and the Riesz potentials.\n\n==Morrey's inequality==\nAssume {{math|''n'' < ''p'' ≤ ∞}}. Then there exists a constant {{mvar|C}}, depending only on {{mvar|p}} and {{mvar|n}}, such that\n\n:<math>\\|u\\|_{C^{0,\\gamma}(\\mathbf{R}^n)}\\leq C \\|u\\|_{W^{1,p}(\\mathbf{R}^n)}</math>\n\nfor all {{math|''u'' ∈ ''C''<sup>1</sup>('''R'''<sup>''n''</sup>) ∩ ''L<sup>p</sup>''('''R'''<sup>''n''</sup>)}}, where\n\n:<math>\\gamma=1-\\frac{n}{p}.</math>\n\nThus if {{math|''u'' ∈ ''W''<sup>&thinsp;1,''p''</sup>('''R'''<sup>''n''</sup>)}}, then {{mvar|u}} is in fact [[Hölder continuous]] of exponent {{mvar|γ}}, after possibly being redefined on a set of measure 0.\n\nA similar result holds in a bounded domain {{mvar|U}} with {{math|''C''<sup>1</sup>}} boundary.  In this case,\n\n:<math>\\|u\\|_{C^{0,\\gamma}(U)}\\leq C \\|u\\|_{W^{1,p}(U)}</math>\n\nwhere the constant {{mvar|C}} depends now on {{math|''n'', ''p''}} and {{mvar|U}}.  This version of the inequality follows from the previous one by applying the norm-preserving extension of {{math|''W''<sup>&thinsp;1,''p''</sup>(''U'')}} to {{math|''W''<sup>&thinsp;1,''p''</sup>('''R'''<sup>''n''</sup>)}}.\n\n==General Sobolev inequalities==\nLet {{mvar|U}} be a bounded open subset of {{math|'''R'''<sup>''n''</sup>}}, with a {{math|''C''<sup>1</sup>}} boundary. ({{mvar|U}} may also be unbounded, but in this case its boundary, if it exists, must be sufficiently well-behaved.) Assume {{math|''u'' ∈ ''W<sup>&thinsp;k,p</sup>''(''U'')}}, then we consider two cases:\n\n==={{math|''k'' < ''n''/''p''}}===\nIn this case {{math|''u'' ∈ ''L<sup>q</sup>''(''U'')}}, where\n\n:<math>\\frac{1}{q}=\\frac{1}{p}-\\frac{k}{n}.</math>\n\nWe have in addition the estimate\n\n:<math>\\|u\\|_{L^q(U)}\\leq C \\|u\\|_{W^{k,p}(U)}</math>,\n\nthe constant {{mvar|C}} depending only on {{math|''k'', ''p'', ''n''}}, and {{mvar|U}}.\n\n==={{math|''k'' > ''n''/''p''}}===\nHere, {{mvar|u}} belongs to a [[Hölder space]], more precisely:\n\n:<math> u \\in C^{k-\\left[\\frac{n}{p}\\right]-1,\\gamma}(U),</math>\n\nwhere\n\n:<math>\\gamma = \\begin{cases}\n\\left[\\frac{n}{p}\\right]+1-\\frac{n}{p} & \\frac{n}{p} \\notin \\mathbf{Z} \\\\\n\\text{any element in } (0, 1) & \\frac{n}{p} \\in \\mathbf{Z}\n\\end{cases}</math>\n\nWe have in addition the estimate\n\n:<math>\\|u\\|_{C^{k-\\left[\\frac{n}{p}\\right]-1,\\gamma}(U)}\\leq C \\|u\\|_{W^{k,p}(U)},</math>\n\nthe constant {{mvar|C}} depending only on {{math|''k'', ''p'', ''n'', ''γ''}}, and {{mvar|U}}.\n\n==Case <math>p=n, k=1</math>==\nIf <math>u\\in W^{1,n}(\\mathbf{R}^n)</math>, then {{mvar|u}} is a function of [[bounded mean oscillation]] and\n\n:<math>\\|u\\|_{BMO} \\leq C \\|Du\\|_{L^n(\\mathbf{R}^n)},</math>\n\nfor some constant {{mvar|C}} depending only on {{mvar|n}}. This estimate is a corollary of the [[Poincaré inequality]].\n\n==Nash inequality==\nThe Nash inequality, introduced by {{harvs|first=John|last=Nash|authorlink=John Forbes Nash, Jr.|year=1958|txt}}, states that there exists a constant {{math|''C'' > 0}}, such that for all {{math|''u'' ∈ ''L''<sup>1</sup>('''R'''<sup>''n''</sup>) ∩ ''W''<sup>&thinsp;1,2</sup>('''R'''<sup>''n''</sup>)}},\n\n:<math>\\|u\\|_{L^2(\\mathbf{R}^n)}^{1+2/n} \\leq C\\|u\\|_{L^1(\\mathbf{R}^n)}^{2/n} \\| Du\\|_{L^2(\\mathbf{R}^n)}.</math>\n\nThe inequality follows from basic properties of the [[Fourier transform]].  Indeed, integrating over the complement of the ball of radius {{mvar|ρ}},\n\n{{NumBlk|:|<math>\\int_{|x|\\ge\\rho} \\left |\\hat{u}(x) \\right |^2\\,dx \\le \\int_{|x|\\ge\\rho} \\frac{|x|^2}{\\rho^2} \\left |\\hat{u}(x) \\right |^2\\,dx\\le \\rho^{-2}\\int_{\\mathbf{R}^n}|D u|^2\\,dx</math>|{{EquationRef|1}}}}\n\nby [[Parseval's theorem]]. On the other hand, one has\n\n:<math>|\\hat{u}| \\le \\|u\\|_{L^1}</math>\n\nwhich, when integrated over the ball of radius {{mvar|ρ}} gives\n\n{{NumBlk|:|<math>\\int_{|x|\\le\\rho} |\\hat{u}(x)|^2\\,dx \\le \\rho^n\\omega_n \\|u\\|_{L^1}^2</math>|{{EquationRef|2}}}}\n\nwhere {{math|''ω<sub>n</sub>''}} is the volume of the [[n sphere|{{mvar|n}}-ball]].  Choosing {{mvar|ρ}} to minimize the sum of ({{EquationNote|1}}) and ({{EquationNote|2}}) and again applying Parseval's theorem:\n\n:<math>\\|\\hat{u}\\|_{L^2} = \\|u\\|_{L^2}</math>\n\ngives the inequality.\n\nIn the special case of {{math|''n'' {{=}} 1}}, the Nash inequality can be extended to the {{math|''L<sup>p</sup>''}} case, in which case it is a generalization of the Gagliardo-Nirenberg-Sobolev inequality ({{harvnb|Brezis|2011}}, Comments on Chapter 8). In fact, if {{mvar|I}} is a bounded interval, then for all {{math|1 ≤ ''r'' < ∞}} and all {{math|1 ≤ ''q'' ≤ ''p'' < ∞}} the following inequality holds\n\n:<math>\\| u\\|_{L^p(I)}\\le C\\| u\\|^{1-a}_{L^q(I)} \\|u\\|^a_{W^{1,r}(I)},</math>\n\nwhere:\n\n:<math>a\\left(\\frac{1}{q}-\\frac{1}{r}+1\\right)=\\frac{1}{q}-\\frac{1}{p}.</math>\n\n==References==\n*{{citation|mr=0450957|last= Adams|first= Robert A.|title=Sobolev Spaces|series=Pure and Applied Mathematics |volume=65|publisher= Academic Press | year= 1975| isbn=978-0-12-044150-1 }}.\n*{{Citation|last1=Aubin| first1=Thierry | title=Espaces de Sobolev sur les variétés riemanniennes | mr=0488125 | year=1976 | journal=Bulletin des Sciences Mathématiques |series=2e Série | volume=100 | issue=2 | pages=149–173}}\n*{{Citation|last1=Aubin| first1=Thierry | title=Nonlinear analysis on manifolds. Monge-Ampère equations | publisher=[[Springer-Verlag]] | series=Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences] | isbn=978-0-387-90704-8 | mr=681859 | year=1982 | volume=252 | doi=10.1007/978-1-4612-5734-9}}.\n*{{citation|first=Haïm|last=Brezis|authorlink=Haïm Brezis|title=Analyse Fonctionnelle: théorie et applications|publisher=[[Masson (publisher)|Masson]]|location=Paris|year=1983|isbn=0-8218-0772-2}}\n*{{citation|first=Haïm|last=Brezis|authorlink=Haïm Brezis|title=Functional Analysis, Sobolev Spaces and Partial Differential Equations|publisher=[[Springer Science & Business Media]]|year=2011|ISBN=978-0-387-70913-0}}\n*{{citation|first=Lawrence|last=Evans|authorlink=Lawrence C. Evans| title=Partial Differential Equations | publisher= [[American Mathematical Society]] |location=Providence RI | year=1998 | isbn=0-8218-0772-2}}\n*{{citation| last= Leoni | first= Giovanni | year= 2009 | url= http://bookstore.ams.org/gsm-105 | title= A First Course in Sobolev Spaces | series=  Graduate Studies in Mathematics | publisher= [[American Mathematical Society]]| isbn= 978-0-8218-4768-8}} {{MR|2527916}}, {{Zbl|1180.46001}}, [http://www.maa.org/press/maa-reviews/a-first-course-in-sobolev-spaces MAA review]\n*{{citation|last=Maz'ja|first=Vladimir G.|authorlink= Vladimir Maz'ja|title=Sobolev Spaces|series=Springer Series in Soviet Mathematics|publisher=Springer-Verlag|year=1985}}, Translated from the Russian by T. O. Shaposhnikova.\n*{{citation|last=Nash|first=J.|authorlink=John Forbes Nash, Jr.|title=Continuity of solutions of parabolic and elliptic equations|journal= [[American Journal of Mathematics]] |volume=80|year=1958|pages=931&ndash;954| doi=10.2307/2372841 |jstor=2372841| issue=4}}.\n*{{springer|id=i/i050230|title=Imbedding theorems|first=S.M.|last= Nikol'skii}}\n*{{Citation| title=An <math> L^1 </math>-type estimate for Riesz potentials|last1=Schikorra|last2=Spector|last3= Van Schaftingen| first1=Armin | first2=Daniel | first3=Jean |journal= Revista Matemática Iberoamericana |volume=33 |year=2017 |issue=1 |pages=291-304|arxiv=1411.2318 | doi=10.4171/rmi/937}}\n*{{citation|first=Elias|last=Stein|authorlink=Elias Stein|title=Singular Integrals and Differentiability Properties of Functions|publisher=[[Princeton University Press]]|location=Princeton, NJ|year=1970|isbn=0-691-08079-8}}\n\n[[Category:Inequalities]]\n[[Category:Sobolev spaces]]\n[[Category:Compactness theorems]]"
    },
    {
      "title": "Stechkin's lemma",
      "url": "https://en.wikipedia.org/wiki/Stechkin%27s_lemma",
      "text": "In [[mathematics]] &mdash; more specifically, in [[functional analysis]] and [[numerical analysis]] &mdash; '''Stechkin's lemma''' is a result about the [[Lp space|ℓ<sup>''q''</sup> norm]] of the tail of a [[sequence (mathematics)|sequence]], when the whole sequence is known to have finite ℓ<sup>''p''</sup> norm.  Here, the term \"tail\" means those terms in the sequence that are not among the ''N'' largest terms, for an arbitrary [[natural number]] ''N''.  Stechkin's lemma is often useful when [[approximation theory|analysing]] best-''N''-term approximations to [[function (mathematics)|functions]] in a given basis of a [[function space]].  The result was originally proved by Stechkin in the case <math>q = 2</math>.\n\n==Statement of the lemma==\n\nLet <math>0 < p < q < \\infty</math> and let <math>I</math> be a countable [[index set]].  Let <math>(a_{i})_{i \\in I}</math> be any sequence indexed by <math>I</math>, and for <math>N \\in \\mathbb{N}</math> let <math>I_{N} \\subset I</math> be the indices of the <math>N</math> largest terms of the sequence <math>(a_{i})_{i \\in I}</math> in [[absolute value]].  Then\n\n:<math>\\left( \\sum_{i \\in I \\setminus I_{N}} | a_{i} |^{q} \\right)^{1/q} \\leq \\left( \\sum_{i \\in I} | a_{i} |^{p} \\right)^{1/p} \\frac{1}{N^{r}}</math>\n\nwhere\n\n:<math>r = \\frac{1}{p} - \\frac{1}{q} > 0</math>.\n\nThus, Stechkin's lemma controls the ℓ<sup>''q''</sup> norm of the tail of the sequence <math>(a_{i})_{i \\in I}</math> (and hence the ℓ<sup>''q''</sup> norm of the difference between the sequence and its approximation using its <math>N</math> largest terms)  in terms of the ℓ<sup>''p''</sup> norm of the full sequence and an rate of decay.\n\n==References==\n\n* {{cite journal\n| last1 = Schneider\n| first1 = Reinhold\n| last2 = Uschmajew\n| first2 = André\n| title = Approximation rates for the hierarchical tensor format in periodic Sobolev spaces\n| journal = Journal of Complexity\n| volume = 30\n| year = 2014\n| issue = 2\n| pages = 56&ndash;71\n| issn = 0885-064X\n| doi = 10.1016/j.jco.2013.10.001| citeseerx = 10.1.1.690.6952\n}}  See Section 2.1 and Footnote 5.\n\n[[Category:Functional analysis]]\n[[Category:Numerical analysis]]\n[[Category:Inequalities]]\n[[Category:Lemmas]]"
    },
    {
      "title": "Steffensen's inequality",
      "url": "https://en.wikipedia.org/wiki/Steffensen%27s_inequality",
      "text": "'''Steffensen's inequality''' is an equation in [[mathematics]] named after [[Johan Frederik Steffensen]].  \n\nIt is an [[integral]] [[inequality (mathematics)|inequality]] in real analysis, stating: \n: If ƒ&nbsp;:&nbsp;[''a'',&nbsp;''b'']&nbsp;→&nbsp;'''R''' is a non-negative, [[monotonic function|monotonically decreasing]], [[integrable function]] \n: and ''g''&nbsp;:&nbsp;[''a'',&nbsp;''b'']&nbsp;→&nbsp;[0,&nbsp;1] is another integrable function, then\n\n::<math>\\int_{b - k}^{b} f(x) \\, dx \\leq \\int_{a}^{b} f(x) g(x) \\, dx \\leq \\int_{a}^{a + k} f(x) \\, dx,</math>\n:where\n::<math>k = \\int_{a}^{b} g(x) \\, dx.</math>\n\n==External links==\n* {{MathWorld |title=Steffensen's Inequality |urlname=SteffensensInequality}}\n\n[[Category:Inequalities]]\n[[Category:Real analysis]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Stein–Strömberg theorem",
      "url": "https://en.wikipedia.org/wiki/Stein%E2%80%93Str%C3%B6mberg_theorem",
      "text": "In [[mathematics]], the '''Stein–Strömberg theorem''' or '''Stein–Strömberg inequality''' is a result in [[measure theory]] concerning the [[Hardy–Littlewood maximal operator]].  The result is foundational in the study of the problem of [[differentiation of integrals]].  The result is named after the [[mathematician]]s [[Elias M. Stein]] and [[Jan-Olov Strömberg]].\n\n==Statement of the theorem==\nLet ''&lambda;''<sup>''n''</sup> denote ''n''-[[dimension]]al [[Lebesgue measure]] on ''n''-dimensional [[Euclidean space]] '''R'''<sup>''n''</sup> and let ''M'' denote the Hardy–Littlewood maximal operator: for a function ''f''&nbsp;:&nbsp;'''R'''<sup>''n''</sup>&nbsp;→&nbsp;'''R''', ''Mf''&nbsp;:&nbsp;'''R'''<sup>''n''</sup>&nbsp;→&nbsp;'''R''' is defined by\n\n:<math>Mf(x) = \\sup_{r > 0} \\frac1{\\lambda^{n} \\big( B_{r} (x) \\big)} \\int_{B_{r} (x)} | f(y) | \\, \\mathrm{d} \\lambda^{n} (y),</math>\n\nwhere ''B''<sub>''r''</sub>(''x'') denotes the [[open ball]] of [[radius]] ''r'' with center ''x''.  Then, for each ''p''&nbsp;&gt;&nbsp;1, there is a constant ''C''<sub>''p''</sub>&nbsp;&gt;&nbsp;0 such that, for all [[natural number]]s ''n'' and functions ''f''&nbsp;∈&nbsp;''L''<sup>''p''</sup>('''R'''<sup>''n''</sup>;&nbsp;'''R'''),\n\n:<math>\\| Mf \\|_{L^{p}} \\leq C_{p} \\| f \\|_{L^{p}}.</math>\n\nIn general, a maximal operator ''M'' is said to be of '''strong type''' (''p'',&nbsp;''p'') if\n\n:<math>\\| Mf \\|_{L^{p}} \\leq C_{p, n} \\| f \\|_{L^{p}}</math>\n\nfor all ''f''&nbsp;∈&nbsp;''L''<sup>''p''</sup>('''R'''<sup>''n''</sup>;&nbsp;'''R''').  Thus, the Stein–Strömberg theorem is the statement that the Hardy–Littlewood maximal operator is of strong type (''p'',&nbsp;''p'') uniformly with respect to the dimension ''n''.\n\n==References==\n* {{cite journal\n| last = Stein\n| first = Elias M.\n| authorlink = Elias M. Stein\n|author2=Strömberg, Jan-Olov\n| title = Behavior of maximal functions in '''R'''<sup>''n''</sup> for large ''n''\n| journal = Ark. Mat.\n| volume = 21\n| year = 1983\n| issue = 2\n| pages = 259–269\n| doi = 10.1007/BF02384314\n}} {{MathSciNet|id=727348}}\n* {{cite journal\n| last = Tišer\n| first = Jaroslav\n| title = Differentiation theorem for Gaussian measures on Hilbert space\n| journal = Trans. Amer. Math. Soc.\n| volume = 308\n| year = 1988\n| issue = 2\n| pages = 655&ndash;666\n| doi = 10.2307/2001096\n}} {{MathSciNet|id=951621}}\n\n{{DEFAULTSORT:Stein-Stromberg theorem}}\n[[Category:Inequalities]]\n[[Category:Theorems in measure theory]]\n[[Category:Operator theory]]"
    },
    {
      "title": "Three spheres inequality",
      "url": "https://en.wikipedia.org/wiki/Three_spheres_inequality",
      "text": "{{Multiple issues|\n{{orphan|date=November 2016}}\n{{unreferenced|date=November 2016}}\n}}\n\nIn [[mathematics]], the '''three spheres inequality''' bounds the <math>L^2</math> norm of a [[harmonic function]] on a given [[sphere]] in terms of the <math>L^2</math> norm of this function on two spheres, one with bigger radius and one with smaller radius.\n\n== Statement of the three spheres inequality ==\n\nLet <math>u</math> be an harmonic function on <math>\\mathbb R^n</math>. Then for all <math>0 < r_1 < r <r_2</math> one has\n:<math>\\| u \\|_{L^2(S_r)} \\leq \\| u \\|^\\alpha_{L^2(S_{r_1})} \\| u \\|^{1-\\alpha}_{L^2(S_{r_2})} </math>\nwhere <math>S_\\rho := \\{ x \\in \\mathbb R^n \\colon \\vert x \\vert = \\rho\\}</math> for <math>\\rho>0</math> is the sphere of radius <math>\\rho</math> centred at the origin and where\n:<math>\\alpha:=\\frac{\\log(r_2/r)}{\\log(r_2/r_1)}.</math>\nHere we use the following normalisation for the <math>L^2</math> norm:\n:<math> \\| u \\|^2_{L^2(S_\\rho)} := \\rho^{1-n} \\int_{\\mathbb S^{n-1}} \\vert u(\\rho \\hat x) \\vert^2\\, d\\sigma(\\hat x).</math>\n\n==References==\n\n*{{citation|mr=1302068\n|last=Korevaar|first= J.|last2=Meyers|first2= J. L. H.\n|title=Logarithmic convexity for supremum norms of harmonic functions\n|journal=Bull. London Math. Soc.|volume= 26 |year=1994|issue= 4|pages= 353–362|doi=10.1112/blms/26.4.353}}\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Trace inequality",
      "url": "https://en.wikipedia.org/wiki/Trace_inequality",
      "text": "In [[mathematics]], there are many kinds of [[inequality (mathematics)|inequalities]] involving [[matrix (mathematics)|matrices]] and [[linear operator]]s on [[Hilbert space]]s. This article covers some important operator inequalities connected with [[Trace (linear algebra)|traces]] of matrices.<ref name=\"C09\">E. Carlen, Trace Inequalities and Quantum Entropy: An Introductory Course, Contemp. Math. 529 (2010) 73–140 {{doi|10.1090/conm/529/10428}} </ref><ref>R. Bhatia, Matrix Analysis, Springer, (1997).</ref><ref name=\"B05\">B. Simon, Trace Ideals and their Applications, Cambridge Univ. Press, (1979); Second edition. Amer. Math. Soc., Providence, RI, (2005).</ref><ref>M. Ohya, D. Petz, Quantum Entropy and Its Use, Springer, (1993).</ref>\n\n==Basic definitions==\nLet '''H'''<sub>''n''</sub> denote the space of [[Hermitian matrix|Hermitian]] {{mvar|n}}×{{mvar|n}} matrices,  '''H'''<sub>''n''</sub><sup>+</sup> denote the set consisting of [[Positive-definite matrix#Negative-definite, semidefinite and indefinite matrices|positive semi-definite]] {{mvar|n}}×{{mvar|n}} Hermitian matrices and '''H'''<sub>''n''</sub><sup>++</sup> denote the set of [[Positive-definite matrix#Negative-definite, semidefinite and indefinite matrices|positive definite]] Hermitian matrices. For operators on an infinite dimensional Hilbert space we require that they be [[trace class]] and [[self-adjoint operator|self-adjoint]], in which case  similar definitions apply, but we discuss only matrices, for simplicity.\n\nFor any real-valued function {{mvar|f}} on an interval {{mvar|I}} ⊂  ℝ,   one  may define a [[matrix function]] {{math|''f(A)''}} for any operator {{math|''A'' ∈ '''H'''<sub>''n''</sub>}} with [[eigenvalues and eigenvectors|eigenvalues]]  {{mvar|λ}} in {{mvar|I}} by defining it on the eigenvalues and corresponding [[Projection (linear algebra)|projectors]] {{mvar|P}} as \n:<math>f(A)\\equiv  \\sum_j f(\\lambda_j)P_j ~,</math>    given  the [[Spectral theorem|spectral decomposition]]  <math>A=\\sum_j\\lambda_j P_j. </math>\n\n===Operator monotone===\nA function {{math|''f'': ''I'' → ℝ}} defined on an interval {{mvar|I}} ⊂ ℝ is said to be '''operator monotone''' if ∀{{mvar|n}}, and all {{math|''A,B'' ∈ '''H'''<sub>''n''</sub>}} with eigenvalues in {{mvar|I}}, the following holds,\n:<math>A \\geq B \\Rightarrow f(A) \\geq f(B),</math>\nwhere the inequality {{math|''A ≥ B''}} means that the operator {{math|''A'' − ''B'' ≥ 0}} is positive semi-definite. One may check that {{math|''f(A){{=}}A''<sup>2</sup>}} is, in fact, ''not'' operator monotone!\n\n===Operator convex===\nA function <math>f: I \\rightarrow \\mathbb{R}</math> is said to be '''operator convex''' if for all <math>n</math> and all {{math|''A,B'' ∈ '''H'''<sub>''n''</sub>}}  with eigenvalues in {{mvar|I}}, and <math>0 < \\lambda < 1</math>, the following holds\n:<math>\nf(\\lambda A + (1-\\lambda)B) \\leq \\lambda f(A) + (1 -\\lambda)f(B) .\n</math>\nNote that the operator <math>\\lambda A + (1-\\lambda)B </math> has eigenvalues in <math>I</math>, since <math> A</math> and <math>B </math> have eigenvalues in {{mvar|I}}.\n\nA function <math>f</math> is '''operator concave''' if <math>-f</math> is operator convex, i.e. the inequality above for <math>f</math> is reversed.\n\n=== {{anchor|Joint_convexity_function_2016_10}}Joint convexity ===\nA function <math>g: I\\times J \\rightarrow \\mathbb{R}</math>, defined on intervals <math>I,J\\subset \\mathbb{R} </math> is said to be ''' jointly convex'''  if for all <math>n</math> and all\n<math>A_1, A_2\\in \\mathbf{H}_n</math> with eigenvalues in <math>I</math> and all <math>B_1,B_2\\in \\mathbf{H}_n</math> with eigenvalues in <math>J</math>, and any <math> 0\\leq \\lambda\\leq 1</math> the following holds\n:<math>\ng(\\lambda A_1 + (1-\\lambda)A_2,\\lambda B_1 + (1-\\lambda)B_2 ) \\leq \\lambda g(A_1, B_1) + (1 -\\lambda)g(A_2, B_2).\n</math>\n\nA function  {{mvar|g}}  is '''jointly concave''' if  −{{mvar|g}} is jointly convex, i.e. the inequality above for {{mvar|g}} is reversed.\n\n===Trace function===\nGiven a function {{mvar|f}}: ℝ → ℝ, the associated '''trace function''' on '''H'''<sub>''n''</sub> is given by\n:<math> A\\mapsto \\operatorname{Tr} f(A)=\\sum_j f(\\lambda_j),</math>\nwhere {{mvar|A}} has eigenvalues {{mvar|λ}}  and Tr stands for a [[Trace (linear algebra)|trace]] of the operator.\n\n==Convexity and monotonicity of the trace function==\nLet  {{mvar|f}}: ℝ → ℝ be continuous, and let {{mvar|n}} be any integer. Then, if <math>t\\mapsto f(t)</math> is monotone increasing, so \nis <math>A \\mapsto \\operatorname{Tr} f(A)</math> on '''H'''<sub>''n''</sub>.\n\nLikewise, if <math>t \\mapsto f(t)</math> is [[Convex function|convex]], so is <math>A \\mapsto \\operatorname{Tr} f(A)</math> on  '''H'''<sub>''n''</sub>, and\nit is strictly convex if {{mvar|f}} is strictly convex.\n\nSee proof and discussion in,<ref name=\"C09\" /> for example.\n\n==Löwner–Heinz theorem==\nFor <math>-1\\leq p \\leq 0</math>, the function <math>f(t) = -t^p</math> is operator monotone and operator concave.\n\nFor <math>0 \\leq p \\leq 1</math>, the function <math>f(t) = t^p</math> is operator monotone and operator concave.\n\nFor <math>1 \\leq p \\leq 2</math>, the function <math>f(t) = t^p</math> is operator convex. Furthermore, \n:<math>f(t) = \\log(t)</math> is operator concave and operator monotone, while \n:<math>f(t) = t \\log(t)</math> is operator convex.\n\nThe original proof of this theorem is due to K. Löwner who gave a necessary and sufficient condition for {{mvar|f}} to be operator monotone.<ref>K. Löwner, \"Uber monotone Matrix funktionen\", Math. Z. 38, 177–216, (1934).</ref>  An elementary proof of the theorem is discussed in <ref name=\"C09\" /> and a more general version of it in.<ref>W.F. Donoghue, Jr., Monotone Matrix Functions and Analytic Continuation, Springer, (1974).</ref>\n\n== {{anchor|Klein2016_10}}Klein's inequality ==\nFor all Hermitian {{mvar|n}}×{{mvar|n}} matrices  {{mvar|A}} and  {{mvar|B}} and all differentiable [[convex function]]s\n{{mvar|f}}: ℝ → ℝ with [[derivative]]  {{math|''f ' ''}}, or for all positive-definite Hermitian  {{mvar|n}}×{{mvar|n}} matrices  {{mvar|A}} and  {{mvar|B}}, and all differentiable\nconvex functions {{mvar|f}}:(0,∞) → ℝ, the following inequality holds,\n{{Equation box 1\n|indent =:\n|equation =  <math> \\operatorname{Tr}[f(A)- f(B)- (A - B)f'(B)] \\geq 0~.</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|bgcolor=#F9FFF7}} \nIn either case, if {{mvar|f}} is strictly convex, equality holds if and only if {{mvar|A}} = {{mvar|B}}.\nA popular choice in applications is {{math|''f''(''t'') {{=}} ''t'' log ''t''}}, see below.\n\n===Proof===\nLet {{math|''C'' {{=}} ''A'' − ''B''}} so that, for 0 < {{mvar|t}} < 1, \n:<math>B + tC = (1 -t)B + tA.</math>\nDefine\n:<math>\\varphi(t) = \\operatorname{Tr}[f(B + tC)]~.</math> \nBy convexity and monotonicity of trace functions,  {{mvar|φ}}  is convex, and so for all 0 < {{mvar|t}} < 1, \n:<math> \\varphi(1) - \\varphi(0) \\geq \\frac{\\varphi(t) - \\varphi(0)}{t},</math>\nand, in fact, the right hand side is monotone decreasing in {{mvar|t}}. Taking the limit {{mvar|t}}→0 yields Klein's inequality.\n\nNote that if  {{mvar|f}}  is strictly convex and {{mvar|C}} ≠ 0, then  {{mvar|φ}} is strictly convex. The final assertion follows from this and the fact that <math>\\tfrac{\\varphi(t) -\\varphi(0)}{t}</math> is monotone decreasing in {{mvar|t}}.\n\n==Golden–Thompson inequality==\n\n{{main|Golden–Thompson inequality}}\n\nIn 1965, S. Golden <ref>S. Golden, Lower Bounds for Helmholtz Functions, Phys. Rev. 137, B 1127–1128 (1965)</ref> and C.J. Thompson <ref>C.J. Thompson, Inequality with Applications in Statistical Mechanics, J. Math. Phys. 6, 1812–1813, (1965).</ref> independently discovered that\n\nFor any matrices <math>A, B\\in\\mathbf{H}_n</math>,\n:<math>\\operatorname{Tr} e^{A+B}\\leq \\operatorname{Tr} e^A e^B.</math>\n\nThis inequality can be generalized for three operators:<ref name=\"L73\">E. H. Lieb, Convex Trace Functions and the Wigner–Yanase–Dyson Conjecture, Advances in Math. 11, 267–288 (1973).</ref> for non-negative operators <math>A, B, C\\in\\mathbf{H}_n^+</math>,\n:<math>\\operatorname{Tr} e^{\\ln A -\\ln B+\\ln C}\\leq \\int_0^\\infty dt\\, \\operatorname{Tr} A(B+t)^{-1}C(B+t)^{-1}.</math>\n\n==Peierls–Bogoliubov inequality==\nLet <math>R, F\\in \\mathbf{H}_n</math> be such that Tr e<sup>''R''</sup> = 1.\nDefining {{math|''g'' {{=}} Tr ''Fe<sup>R</sup>''}}, we have \n:<math>\\operatorname{Tr} e^F e^R \\geq \\operatorname{Tr} e^{F+R}\\geq e^g.</math>\n\nThe proof of this inequality follows from the above combined with [[#Klein's inequality|Klein's inequality]]. Take {{math|''f''(''x'') {{=}} exp(''x''),  ''A''{{=}}''R'' + ''F'',  and ''B'' {{=}} ''R'' + ''gI''}}.<ref name=\"R69\">D. Ruelle, Statistical Mechanics: Rigorous Results, World Scient. (1969).</ref>\n\n==Gibbs variational principle==\nLet <math>H</math> be a self-adjoint operator such that <math>e^{-H}</math> is [[trace class]]. Then for any <math>\\gamma\\geq 0 </math> with <math>\\operatorname{Tr}\\gamma=1,</math>\n:<math>\\operatorname{Tr}\\gamma H+\\operatorname{Tr}\\gamma\\ln\\gamma\\geq -\\ln \\operatorname{Tr} e^{-H},</math>\nwith equality if and only if <math>\\gamma=\\exp(-H)/\\operatorname{Tr} \\exp(-H).</math>\n\n==Lieb's concavity theorem==\nThe following theorem was proved by [[Elliott Lieb|E. H. Lieb]] in.<ref name=\"L73\" /> It proves and generalizes a conjecture of  E. P. Wigner, M. M. Yanase and F. J. Dyson.<ref name=\"WY64\">E. P. Wigner, M. M. Yanase, On the Positive Semi-Definite Nature of a Certain Matrix Expression, Can. J. Math. 16, 397–406, (1964).</ref> Six years later other proofs were given by T. Ando <ref name=\"A79\">. Ando, Convexity of Certain Maps on Positive Definite Matrices and Applications to Hadamard Products, Lin. Alg. Appl. 26, 203–241 (1979).</ref> and B. Simon,<ref name=\"B05\" /> and several more have been given since then.\n\nFor all <math>m\\times n</math> matrices <math>K</math>, and all <math>q </math> and <math>r</math> such that <math>0 \\leq q\\leq 1</math> and <math>0\\leq r \\leq 1</math>, with <math>q + r \\leq 1</math> the real valued map on <math>\\mathbf{H}^+_m \\times \\mathbf{H}^+_n</math> given by\n:<math>\n        F(A,B,K) = \\operatorname{Tr}(K^*A^qKB^r)\n</math>\n* is jointly concave in <math>(A,B)</math>\n* is convex in <math>K</math>.\n\nHere <math>K^* </math> stands for the  [[Hermitian adjoint|adjoint operator]] of <math>K.</math>\n\n==Lieb's theorem==\nFor a fixed Hermitian matrix <math>L\\in\\mathbf{H}_n</math>, the function\n:<math> f(A)=\\operatorname{Tr} \\exp\\{L+\\ln A\\} </math>\nis concave on <math>\\mathbf{H}_n^{++}</math>.\n\nThe theorem and proof are due to E. H. Lieb,<ref name=\"L73\" /> Thm 6, where he obtains this theorem as a corollary  of Lieb's concavity Theorem.\nThe most direct proof is due to H. Epstein;<ref name=\"E73\">H. Epstein, Remarks on Two Theorems of E. Lieb, Comm. Math. Phys., 31:317–325, (1973).</ref> see M.B. Ruskai papers,<ref name=\"R02\">M. B. Ruskai, Inequalities for Quantum Entropy: A Review With Conditions for Equality, J. Math. Phys., 43(9):4358–4375, (2002).</ref><ref name=\"R06\">M. B. Ruskai, Another Short and Elementary Proof of Strong Subadditivity of Quantum Entropy, Reports Math. Phys. 60, 1–12 (2007).</ref> for a review of this argument.\n\n==Ando's convexity theorem==\nT. Ando's proof <ref name=\"A79\" /> of [[#Lieb's concavity theorem|Lieb's concavity theorem]] led to the following significant complement to it:\n\nFor all <math>m \\times n</math> matrices <math>K</math>, and all <math>1 \\leq q \\leq 2</math> and <math>0 \\leq r \\leq 1</math> with <math>q-r \\geq 1</math>, the real valued map on <math>\\mathbf{H}^{++}_m \\times \\mathbf{H}^{++}_n</math> given by\n:<math> (A,B) \\mapsto \\operatorname{Tr}(K^*A^qKB^{-r})</math>\nis convex.\n\n== {{anchor|Joint_convexity_2016_10}}Joint convexity of relative entropy ==\nFor two operators <math>A, B\\in\\mathbf{H}^{++}_n </math> define the following map\n:<math> R(A\\parallel B):= \\operatorname{Tr}(A\\log A) - \\operatorname{Tr}(A\\log B).</math>\n\nFor [[Density matrix|density matrices]] <math>\\rho</math> and <math>\\sigma</math>, the map <math>R(\\rho\\parallel\\sigma)=S(\\rho\\parallel\\sigma)</math> is the Umegaki's [[quantum relative entropy]].\n\nNote that the non-negativity of <math>R(A\\parallel B)</math> follows from Klein's inequality with <math>f(x)=x\\log x</math>.\n\n===Statement===\nThe map <math>R(A\\parallel B): \\mathbf{H}^{++}_n \\times \\mathbf{H}^{++}_n \\rightarrow \\mathbf{R}</math> is jointly convex.\n\n===Proof===\nFor all <math>0 < p < 1</math>, <math>(A,B) \\mapsto \\operatorname{Tr}(B^{1-p}A^p)</math> is jointly concave, by [[#Lieb's concavity theorem|Lieb's concavity theorem]], and thus\n:<math>(A,B)\\mapsto \\frac{1}{p-1}(\\operatorname{Tr}(B^{1-p}A^p)-\\operatorname{Tr}A)</math>\nis convex. But\n:<math>\\lim_{p\\rightarrow 1}\\frac{1}{p-1}(\\operatorname{Tr}(B^{1-p}A^p)-\\operatorname{Tr}A)=R(A\\parallel B),</math>\nand convexity is preserved in the limit.\n\nThe proof is due to G. Lindblad.<ref name=\"Ldb74\">G. Lindblad, Expectations and Entropy Inequalities, Commun. Math. Phys. 39, 111–119 (1974).</ref>\n\n==Jensen's operator and trace inequalities==\nThe operator version of [[Jensen's inequality]] is due to C. Davis.<ref name=\"D57\">C. Davis, A Schwarz inequality for convex operator functions, Proc. Amer. Math. Soc. 8, 42–44, (1957).</ref>\n\nA continuous, real function <math>f</math> on an interval <math>I</math> satisfies '''Jensen's Operator Inequality''' if the following holds\n:<math> f\\left(\\sum_kA_k^*X_kA_k\\right)\\leq\\sum_k A_k^*f(X_k)A_k, </math>\nfor operators <math>\\{A_k\\}_k</math> with <math>\\sum_k A^*_kA_k=1</math> and for [[self-adjoint operator]]s <math>\\{X_k\\}_k</math> with [[Spectrum (functional analysis)|spectrum]] on <math>I</math>.\n\nSee,<ref name=\"D57\" /><ref name=\"HP02\">F. Hansen, G. K. Pedersen, Jensen's Operator Inequality, Bull. London Math. Soc.  35 (4): 553–564, (2003).</ref> for the proof of the following two theorems.\n\n===Jensen's trace inequality===\nLet {{mvar|f}} be a continuous function defined on an interval {{mvar|I}}  and let  {{mvar|m}} and  {{mvar|n}} be natural numbers. If  {{mvar|f}} is convex, we then have the inequality\n:<math> \\operatorname{Tr}\\Bigl(f\\Bigl(\\sum_{k=1}^nA_k^*X_kA_k\\Bigr)\\Bigr)\\leq \\operatorname{Tr}\\Bigl(\\sum_{k=1}^n A_k^*f(X_k)A_k\\Bigr),</math>\nfor all ({{mvar|X}}<sub>1</sub>, ... ,  {{mvar|X}}<sub>''n''</sub>) self-adjoint {{mvar|m}} × {{mvar|m}} matrices with spectra contained in {{mvar|I}}  and\nall ({{mvar|A}}<sub>1</sub>, ... ,  {{mvar|A}}<sub>''n''</sub>) of {{mvar|m}} × {{mvar|m}}  matrices with \n:<math>\\sum_{k=1}^nA_k^*A_k=1.</math>\n\nConversely, if the above inequality is satisfied for some  {{mvar|n}}   and  {{mvar|m}}, where  {{mvar|n}} > 1, then  {{mvar|f}} is convex.\n\n===Jensen's operator inequality===\nFor a continuous function <math>f</math> defined on an interval <math>I</math> the following conditions are equivalent:\n* <math>f</math> is operator convex.\n* For each natural number <math>n</math> we have the inequality\n:<math> f\\Bigl(\\sum_{k=1}^nA_k^*X_kA_k\\Bigr)\\leq\\sum_{k=1}^n A_k^*f(X_k)A_k, </math>\nfor all <math>(X_1, \\ldots , X_n)</math> bounded, self-adjoint operators on an arbitrary [[Hilbert space]] <math>\\mathcal{H}</math> with\nspectra contained in <math>I</math> and all <math>(A_1, \\ldots , A_n)</math> on <math>\\mathcal{H}</math> with <math>\\sum_{k=1}^n A^*_kA_k=1.</math>\n* <math>f(V^*XV) \\leq V^*f(X)V</math> for each isometry <math>V</math> on an infinite-dimensional Hilbert space <math>\\mathcal{H}</math> and\nevery self-adjoint operator <math>X</math> with spectrum in <math>I</math>.\n* <math>Pf(PXP + \\lambda(1 -P))P \\leq Pf(X)P</math> for each projection <math>P</math> on an infinite-dimensional Hilbert space <math>\\mathcal{H}</math>, every self-adjoint operator <math>X</math> with spectrum in <math>I</math> and every <math>\\lambda</math> in <math>I</math>.\n\n==Araki–Lieb–Thirring inequality==\nE. H. Lieb and W. E. Thirring proved the following inequality in <ref>E. H. Lieb, W. E. Thirring, Inequalities for the Moments of the Eigenvalues of the Schrödinger Hamiltonian and Their Relation to Sobolev Inequalities, in Studies in Mathematical Physics, edited E. Lieb, B. Simon, and A. Wightman, Princeton University Press, 269–303 (1976).</ref> in 1976: For any <math> A\\geq 0 </math>, <math>B\\geq 0 </math> and <math>r\\geq 1, </math>\n:<math>\\operatorname{Tr} (BAB)^r\\leq \\operatorname{Tr} (B^{r}A^{r}B^{r}).</math>\n\nIn 1990 <ref>H. Araki, On an Inequality of Lieb and Thirring, Lett. Math. Phys. 19, 167–170 (1990).</ref> H. Araki generalized the above inequality to the following one: For any <math>A\\geq 0 </math>, <math>B\\geq 0 </math> and <math>q\\geq 0, </math>\n:<math>\\operatorname{Tr}(BAB)^{rq}\\leq \\operatorname{Tr}(B^{r}A^rB^{r})^q,</math> for <math>r\\geq 1, </math>\nand\n:<math>\\operatorname{Tr}(B^{r}A^rB^{r})^q\\leq \\operatorname{Tr}(BAB)^{rq},</math> for <math>0\\leq r\\leq 1. </math>\n\nThe Lieb–Thirring inequality also enjoys the following generalization:<ref>Z. Allen-Zhu, Y. Lee, L. Orecchia, Using Optimization to Obtain a Width-Independent, Parallel, Simpler, and Faster Positive SDP Solver, in ACM-SIAM Symposium on Discrete Algorithms, 1824–1831 (2016).</ref> for any <math>A\\geq 0 </math>, <math>B\\geq 0 </math> and <math>\\alpha \\in [0,1], </math>\n:<math>\\operatorname{Tr} (B A^\\alpha B B A^{1-\\alpha} B) \\leq \\operatorname{Tr} (B^2AB^2).</math>\n\n==Effros's theorem and its extension==\nE. Effros in <ref name=\"E09\">E. Effros, A Matrix Convexity Approach to Some Celebrated Quantum Inequalities, Proc. Natl. Acad. Sci. USA, 106, n.4, 1006–1008 (2009).</ref> proved the following theorem.\n\nIf <math>f(x)</math> is an operator convex function, and <math>L</math> and <math>R</math> are commuting bounded linear operators, i.e. the commutator <math>[L,R]=LR-RL=0</math>, the ''perspective''\n:<math>g(L, R):=f(LR^{-1})R </math>\nis jointly convex, i.e. if <math>L=\\lambda L_1+(1-\\lambda)L_2</math> and <math>R=\\lambda R_1+(1-\\lambda)R_2</math> with <math>[L_i, R_i]=0</math> (i=1,2), <math>0\\leq\\lambda\\leq 1</math>,\n:<math>g(L,R)\\leq \\lambda g(L_1,R_1)+(1-\\lambda)g(L_2,R_2).</math>\n\nEbadian et al. later extended the inequality to the case where <math>L</math> and <math>R</math> do not commute . <ref>A. Ebadian, I. Nikoufar, and M. Gordjic, \"Perspectives of matrix convex functions,\" Proc. Natl Acad. Sci. USA, 108(18), 7313–7314 (2011)</ref>\n\n==Von Neumann's trace inequality and related results==\nVon Neumann's trace inequality, named after its originator [[John von Neumann]], states that for any ''n''&nbsp;&times;&nbsp;''n'' complex matrices ''A'',&nbsp;''B'' with [[singular value]]s <math>\\alpha_1 \\ge \\alpha_2 \\ge \\cdots \\ge \\alpha_n</math> and <math>\\beta_1 \\ge \\beta_2 \\ge \\cdots \\ge \\beta_n</math> respectively,<ref>{{cite journal|last1=Mirsky|first1=L.|title=A trace inequality of John von Neumann|journal=Monatshefte für Mathematik|date=December 1975|volume=79|issue=4|pages=303–306|doi=10.1007/BF01647331}}</ref>\n\n:<math>\\left| \\operatorname{Tr} (AB) \\right| \\le \\sum_{i=1}^n \\alpha_i \\beta_i\\,.</math>\n\nA simple corollary to this is the following result<ref>{{cite book|last1=Marshall|first1=Albert W.|last2=Olkin|first2=Ingram|last3=Arnold|first3=Barry|title=Inequalities: Theory of Majorization and Its Applications|date=2011|edition=2nd|location=New York |publisher=Springer|page=340-341|isbn=978-0-387-68276-1}}</ref>: For [[Hermitian matrix|hermitian]] ''n''&nbsp;&times;&nbsp;''n'' complex matrices ''A'',&nbsp;''B'' where now the [[eigenvalue]]s are sorted decreasingly (<math> a_1 \\ge  a_2 \\ge \\cdots \\ge  a_n</math> and <math> b_1 \\ge  b_2 \\ge \\cdots \\ge  b_n</math>, respectively),\n\n:<math> \\sum_{i=1}^n  a_i b_{n-i+1}\\leq \\operatorname{Tr}(AB)\\leq \\sum_{i=1}^n a_i b_i\\,.</math>\n\n== See also ==\n* [[von Neumann entropy]]\n* [[Lieb–Thirring inequality]]\n* [[Schur–Horn theorem]]\n\n==References==\n{{reflist}}\n*[http://www.scholarpedia.org/article/Matrix_and_Operator_Trace_Inequalities#Gibbs_variational_principle Scholarpedia] primary source.\n\n[[Category:Operator theory]]\n[[Category:Matrix theory]]\n[[Category:Inequalities]]"
    },
    {
      "title": "Trudinger's theorem",
      "url": "https://en.wikipedia.org/wiki/Trudinger%27s_theorem",
      "text": "In [[mathematical analysis]], '''Trudinger's theorem''' or the '''Trudinger inequality''' (also sometimes called the '''Moser–Trudinger inequality''') is a result of [[functional analysis]] on [[Sobolev space]]s. It is named after [[Neil Trudinger]] (and [[Jürgen Moser]]).\n\nIt provides an inequality between a certain [[Sobolev space]] norm and an [[Orlicz space]] norm of a function. The inequality is a [[limiting case (mathematics)|limiting case]] of Sobolev imbedding and can be stated as the following theorem:\n\nLet <math>\\Omega</math> be a bounded domain in <math>\\mathbb{R}^n</math> satisfying the [[cone condition]]. Let <math>mp=n</math> and <math>p>1</math>. Set\n\n:<math>\nA(t)=\\exp\\left( t^{n/(n-m)} \\right)-1.\n</math>\n\nThen there exists the embedding\n:<math>\nW^{m,p}(\\Omega)\\hookrightarrow L_A(\\Omega)\n</math>\n\nwhere \n:<math>\nL_A(\\Omega)=\\left\\{ u\\in M_f(\\Omega):\\|u\\|_{A,\\Omega}=\\inf\\{ k>0:\\int_\\Omega A\\left( \\frac{|u(x)|}{k} \\right)~dx\\leq 1 \\}<\\infty \\right\\}.\n</math>\n\nThe space \n\n:<math>L_A(\\Omega)</math> \n\nis an example of an [[Orlicz space]].\n\n==References==\n{{reflist}}\n*{{citation|last=Moser|first=J.|authorlink=Jürgen Moser|title=A Sharp form of an Inequality by N. Trudinger|journal=Indiana Univ. Math.|volume=20|year=1971|pages=1077&ndash;1092}}. \n*{{citation|last=Trudinger|first=N. S.|authorlink=Neil Trudinger|title=On imbeddings into Orlicz spaces and some applications|journal=J. Math. Mech. |volume=17|year=1967|pages=473&ndash;483}}.\n\n[[Category:Sobolev spaces]]\n[[Category:Inequalities]]\n[[Category:Theorems in analysis]]"
    },
    {
      "title": "Tupper's self-referential formula",
      "url": "https://en.wikipedia.org/wiki/Tupper%27s_self-referential_formula",
      "text": "'''Tupper's self-referential formula''' is a [[formula]] that visually represents itself when graphed at a specific location in the (''x'', ''y'') plane.\n\n== History ==\n\nThe formula was defined by Jeff Tupper and appears as an example in Tupper's 2001 [[SIGGRAPH]] paper on reliable two-dimensional computer graphing algorithms.\n<ref>* [http://www.dgp.toronto.edu/people/mooncake/papers/SIGGRAPH2001_Tupper.pdf Tupper, Jeff. \"Reliable Two-Dimensional Graphing Methods for Mathematical Formulae with Two Free Variables\"]</ref> This paper discusses methods related to the GrafEq formula-graphing program developed by Tupper.<ref>{{cite web|url=http://www.peda.com/grafeq/|title=Pedagoguery Software: GrafEq|publisher=}}</ref> \n\nAlthough the formula is called \"[[self-reference|self-referential]]\", Tupper did not name it as such.<ref>{{cite web|last1=Narayanan |first1=Arvind |title=Tupper’s Self-Referential Formula Debunked |url=http://arvindn.livejournal.com/132943.html |accessdate=20 February 2015 |deadurl=yes |archiveurl=https://web.archive.org/web/20150424181239/http://arvindn.livejournal.com/132943.html |archivedate=24 April 2015 |df= }}</ref>\n\n== Formula ==\n\nThe formula is an [[inequality (mathematics)|inequality]] defined as:\n\n: <math>{1\\over 2} < \\left\\lfloor \\mathrm{mod}\\left(\\left\\lfloor {y \\over 17} \\right\\rfloor 2^{-17 \\lfloor x \\rfloor - \\mathrm{mod}(\\lfloor y\\rfloor, 17)},2\\right)\\right\\rfloor</math>\nor, as plaintext,\n{{quotation|1/2 < floor(mod(floor(y/17)*2^(-17*floor(x)-mod(floor(y), 17)),2))}}\n\nwhere ⌊&nbsp;⌋ denotes the [[Floor and ceiling functions|floor function]], and mod is the [[modulo operation]].\n\nLet ''k'' equal the following 543-digit integer:\n\n{{quotation|960 939 379 918 958 884 971 672 962 127 852 754 715 004 339 660 129 306 651 505 519 271 702 802 395 266 424 689 642 842 174 350 718 121 267 153 782 770 623 355 993 237 280 874 144 307 891 325 963 941 337 723 487 857 735 749 823 926 629 715 517 173 716 995 165 232 890 538 221 612 403 238 855 866 184 013 235 585 136 048 828 693 337 902 491 454 229 288 667 081 096 184 496 091 705 183 454 067 827 731 551 705 405 381 627 380 967 602 565 625 016 981 482 083 418 783 163 849 115 590 225 610 003 652 351 370 343 874 461 848 378 737 238 198 224 849 863 465 033 159 410 054 974 700 593 138 339 226 497 249 461 751 545 728 366 702 369 745 461 014 655 997 933 798 537 483 143 786 841 806 593 422 227 898 388 722 980 000 748 404 719}}\n\nIf one [[Graph of a function|graphs]] the set of points (''x'',&nbsp;''y'') in 0&nbsp;≤&nbsp;''x''&nbsp;<&nbsp;106 and ''k''&nbsp;≤&nbsp;''y''&nbsp;<&nbsp;''k''&nbsp;+&nbsp;17 satisfying the inequality given above, the resulting graph looks like this (the axes in this plot have been reversed, otherwise the picture would be upside-down and mirrored):\n\n[[File:Tupper's self referential formula plot.svg]]\n[[File:Tupper_formula_constant_derivation.svg|thumb|91px<!-- 91px gives acceptable text rendering with least overshoot or ugly gaps -->|Derivation of ''k'']]\n\nThe formula is a general-purpose method of decoding a bitmap stored in the constant&nbsp;''k'', and it could actually be used to draw any other image.  When applied to the unbounded positive range 0&nbsp;≤&nbsp;''y'', the formula tiles a vertical swath of the plane with a pattern that contains all possible 17-pixel-tall bitmaps.  One horizontal slice of that infinite bitmap depicts the drawing formula itself, but this is not remarkable, since other slices depict all other possible formulae that might fit in a 17-pixel-tall bitmap. Tupper has created extended versions of his original formula that rule out all but one slice.<ref>http://www.peda.com/selfplot/selfplot3big.png</ref><ref>http://www.peda.com/selfplot/selfplot2.png</ref><ref>http://www.peda.com/selfplot/selfplot.png</ref>\n\nThe constant ''k'' is a simple [[1-bit color|monochrome]] [[bitmap|bitmap image]] of the formula treated as a binary number and multiplied by 17.  If ''k'' is divided by 17, the [[least significant bit]] encodes the upper-right corner (''k'',&nbsp;0); the 17 least significant bits encode the rightmost column of pixels; the next 17 least significant bits encode the 2nd-rightmost column, and so on.\n\n== See also ==\n* [[Bitmap]]\n* [[Quine (computing)]]\n* [[Recursion]]\n* [[Strange loop]]\n\n== References ==\n===Notes===\n{{reflist}}\n\n===Sources===\n{{refbegin}}\n* [http://mathworld.wolfram.com/TuppersSelf-ReferentialFormula.html Weisstein, Eric W. \"Tupper's Self-Referential Formula.\" From MathWorld—A Wolfram Web Resource.]\n* [http://crd-legacy.lbl.gov/~dhbailey/dhbpapers/hpmpd.pdf Bailey, D. H.; Borwein, J. M.; Calkin, N. J.; Girgensohn, R.; Luke, D. R.; and Moll, V. H. Experimental Mathematics in Action. Natick, MA: A. K. Peters, p.&nbsp;289, 2006.]\n* \"Self-Answering Problems.\" Math. Horizons 13, No. 4, 19, April 2006\n* [http://stanwagon.com/wagon/Misc/bestpuzzles.html Wagon, S. Problem 14 in stanwagon.com]\n{{refend}}\n\n== External links ==\n* {{official|http://www.dgp.toronto.edu/people/mooncake/ }}\n* [http://www.peda.com/selfplot/ Extensions of Tupper's original self-referential formula]\n* [https://amcrae.github.io/TupperPlot/TupperPlot.html TupperPlot], an implementation in JavaScript\n* [https://web.archive.org/web/20130319093833/http://www.pypedia.com/index.php/Tupper_self_referential_formula Tupper self referential formula], an implementation in Python\n* [http://avitzur.hax.com/2007/01/the_library_of_babel_function.html The Library of Babel function], a detailed explanation of the workings of Tupper's self-referential formula\n* [https://tuppers-formula.ovh Tupper's Formula Tools], an implementation in JavaScript\n* [http://jtra.cz/stuff/essays/math-self-reference/index.html Trávník's formula that draws itself close to the origin]\n* [https://www.youtube.com/watch?v=_s5RFgd59ao A video explaining the formula]\n\n[[Category:Inequalities]]\n[[Category:Self-reference]]\n[[Category:2001 introductions]]\n[[Category:Computer graphics]]"
    },
    {
      "title": "Turán–Kubilius inequality",
      "url": "https://en.wikipedia.org/wiki/Tur%C3%A1n%E2%80%93Kubilius_inequality",
      "text": "The '''Turán–Kubilius inequality''' is a [[mathematical theorem]] in [[probabilistic number theory]]. It is useful for proving results about the [[normal order of an arithmetic function]].<ref name=\"Tenenbaum\" />{{Rp|305–308}} The theorem was proved in a [[special case]] in 1934 by [[Pál Turán]] and generalized in 1956 and 1964 by [[Jonas Kubilius]].<ref name=\"Tenenbaum\">\n{{cite book | title=Introduction to Analytic and Probabilistic Number Theory | last=Tenenbaum | first=Gérald | series=Cambridge studies in advanced mathematics | volume=46 | publisher=Cambridge University Press | year=1995 | isbn=0-521-41261-7 }}\n</ref>{{Rp|316}}\n\n==Statement of the theorem==\n\nThis formulation is from Tenenbaum.<ref name=\"Tenenbaum\" />{{Rp|302}} Other formulations are in Narkiewicz<ref>\n{{cite book | last = Narkiewicz | first = Władysław | title = Number Theory |url= https://books.google.com/books?id=4CUUmYrem2YC |publisher = World Scientific | location = Singapore | year = 1983 | isbn = 978-9971-950-13-2 }}</ref>{{Rp|243}}\nand in Cojocaru & Murty.<ref>\n{{cite book | last1 = Cojocaru | first1= Alina Carmen|author1-link= Alina Carmen Cojocaru | last2 = Murty | first2 = M. Ram | authorlink2 = M. Ram Murty | title=An Introduction to Sieve Methods and Their Applications | series=London Mathematical Society Student Texts | volume=66 | publisher=Cambridge University Press | isbn=0-521-61275-6 | year = 2005 }}\n</ref>{{Rp|45–46}}\n\nSuppose ''f'' is an [[Additive map|additive]] complex-valued [[arithmetic function]], and write ''p'' for an arbitrary prime and {{math|''&nu;''}} for an arbitrary positive integer. Write\n\n:<math>A(x)=\\sum_{p^\\nu \\le x} f(p^\\nu) p^{-\\nu}(1-p^{-1})</math>\n\nand\n\n:<math>B(x)^2 = \\sum_{p^\\nu \\le x} \\left| f(p^\\nu) \\right| ^2 p^{-\\nu}.</math>\n\nThen there is a function ε(''x'') that goes to zero when ''x'' goes to infinity, and such that for ''x'' ≥ 2 we have\n\n:<math>\\frac{1}{x} \\sum_{n \\le x} |f(n) - A(x)|^2 \\le (2 + \\varepsilon(x)) B(x)^2. </math>\n\n==Applications of the theorem==\n[[Pál Turán|Turán]] developed the inequality to create a simpler proof of the [[Hardy–Ramanujan theorem]] about the [[normal order of an arithmetic function|normal order]] of the number ω(''n'') of distinct prime divisors of an integer ''n''.<ref name=\"Tenenbaum\" />{{Rp|316}} There is an exposition of Turán's proof in Hardy & Wright, §22.11.<ref>\n{{cite book | last1 = Hardy | first1 = G. H. | authorlink1=G. H. Hardy | last2 = Wright | first2 = E. M. | authorlink2 = E. M. Wright |others = Revised by [[Roger Heath-Brown|D. R. Heath-Brown]] and [[Joseph H. Silverman]]| title = An Introduction to the Theory of Numbers |edition = Sixth | publisher = Oxford University Press | location = Oxford, Oxfordshire | year = 2008 |origyear = First edition 1938| isbn = 978-0-19-921986-5 }}</ref>\nTenenbaum<ref name=\"Tenenbaum\" />{{Rp|305–308}} gives a proof of the Hardy–Ramanujan theorem using the Turán–Kubilius inequality and states without proof several other applications.\n\n==Notes==\n{{reflist}}\n\n{{DEFAULTSORT:Turan-Kubilius inequality}}\n[[Category:Inequalities]]\n[[Category:Theorems in number theory]]"
    },
    {
      "title": "Uncertainty principle",
      "url": "https://en.wikipedia.org/wiki/Uncertainty_principle",
      "text": "{{Use American English|date=January 2019}}\n{{short description|Foundational principle in quantum physics}}\n{{Other uses}}\n{{Quantum mechanics}}\nIn [[quantum mechanics]], the '''uncertainty principle''' (also known as '''Heisenberg's uncertainty principle''') is any of a variety of [[Inequality (mathematics)|mathematical inequalities]]<ref name=Sen2014>{{Cite journal |last1 = Sen | first1 = D. | title = The Uncertainty relations in quantum mechanics | url = http://www.currentscience.ac.in/Volumes/107/02/0203.pdf | journal = Current Science | volume = 107| issue = 2| year = 2014| pages = 203–218 }}</ref> asserting a fundamental limit to the precision with which certain pairs of physical properties of a [[particle]], known as [[Complementarity (physics)|complementary variables]] or canonically conjugate variables such as [[Position (vector)|position]] ''x'' and [[momentum]] ''p'', can be known.\n\nIntroduced first in 1927, by the German physicist  [[Werner Heisenberg]], it states that the more precisely the position of some particle is determined, the less precisely its momentum can be known, and vice versa.<ref name=\"Heisenberg_1927\">{{Citation |first=W. |last=Heisenberg |title=Über den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik  |language=de|journal=[[Zeitschrift für Physik]] |volume=43 |issue=3–4 |year=1927 |pages=172–198 |doi=10.1007/BF01397280 |postscript=. |bibcode = 1927ZPhy...43..172H }}.\nAnnotated pre-publication proof sheet of [http://osulibrary.oregonstate.edu/specialcollections/coll/pauling/bond/papers/corr155.1.html Über den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik], March 21, 1927.</ref> The formal inequality relating the [[standard deviation]] of position ''σ<sub>x</sub>'' and the standard deviation of momentum ''σ<sub>p</sub>'' was derived by [[Earle Hesse Kennard]]<ref name=\"Kennard\">{{Citation |first=E. H. |last=Kennard |title=Zur Quantenmechanik einfacher Bewegungstypen  |language=de|journal=Zeitschrift für Physik |volume=44 |issue=4–5 |year=1927 |pages=326–352 |doi=10.1007/BF01391200 |postscript=. |bibcode = 1927ZPhy...44..326K }}</ref> later that year and by [[Hermann Weyl]]<ref name=\"Weyl1928\">{{Citation|last=Weyl|first=H.|title=Gruppentheorie und Quantenmechanik|year=1928|publisher=Hirzel|location=Leipzig}}</ref> in 1928:\n{{Equation box 1\n|indent =::\n|equation = <math> \\sigma_{x}\\sigma_{p} \\geq \\frac{\\hbar}{2} ~~</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere {{mvar|ħ}} is the reduced [[Planck constant]], {{math|''h''/(2&pi;}}).\n\nHistorically, the uncertainty principle has been confused<ref>{{Citation|last=Furuta|first=Aya|title=One Thing Is Certain: Heisenberg's Uncertainty Principle Is Not Dead|journal=Scientific American|year=2012|url=https://www.scientificamerican.com/article/heisenbergs-uncertainty-principle-is-not-dead/}}</ref><ref name=\"Ozawa2003\">{{Citation|last=Ozawa|first=Masanao|title=Universally valid reformulation of the Heisenberg uncertainty principle on noise and disturbance in measurement|journal=Physical Review A|volume=67|year=2003|doi=10.1103/PhysRevA.67.042105|arxiv = quant-ph/0207121 |bibcode = 2003PhRvA..67d2105O|issue=4 |pages=42105}}</ref> with a related effect in [[physics]], called the [[observer effect (physics)|observer effect]], which notes that measurements of certain systems cannot be made without affecting the systems, that is, without changing something in a system. Heisenberg utilized such an observer effect at the quantum level (see below) as a physical \"explanation\" of quantum uncertainty.<ref>Werner Heisenberg, ''The Physical Principles of the Quantum Theory'', p. 20</ref> It has since become clearer, however, that the uncertainty principle is inherent in the properties of all [[wave|wave-like systems]],<ref name=\"Rozema\">{{Cite journal | last1 = Rozema | first1 = L. A. | last2 = Darabi | first2 = A. | last3 = Mahler | first3 = D. H. | last4 = Hayat | first4 = A. | last5 = Soudagar | first5 = Y. | last6 = Steinberg | first6 = A. M. | doi = 10.1103/PhysRevLett.109.100404 |arxiv = 1208.0034v2| title = Violation of Heisenberg's Measurement–Disturbance Relationship by Weak Measurements | journal = Physical Review Letters | volume = 109 | issue = 10 | year = 2012 | pmid =  23005268| pmc = |bibcode = 2012PhRvL.109j0404R | page=100404}}</ref> and that it arises in quantum mechanics simply due to the [[matter wave]] nature of all quantum objects. Thus, ''the uncertainty principle actually states a fundamental property of quantum systems and is not a statement about the observational success of current technology''.<ref name=nptel>{{YouTube|TcmGYe39XG0|Indian Institute of Technology Madras, Professor V. Balakrishnan, Lecture 1 – Introduction to Quantum Physics; Heisenberg's uncertainty principle, National Programme of Technology Enhanced Learning}}</ref> It must be emphasized that ''measurement'' does not mean only a process in which a physicist-observer takes part, but rather any interaction between classical and quantum objects regardless of any observer.<ref name=\"L&L\"/>{{refn|name=precision|group=note|N.B. on ''precision'': If <math>\\delta x</math> and <math>\\delta p</math> are the precisions of position and momentum obtained in an ''individual'' measurement and <math>\\sigma_{x}</math>, <math>\\sigma_{p}</math> their standard deviations in an ''ensemble'' of individual measurements on similarly prepared systems, then \"''There are, in principle, no restrictions on the precisions of individual measurements <math>\\delta x</math> and <math>\\delta p</math>, but the standard deviations will always satisfy <math>\\sigma_{x}\\sigma_{p} \\ge \\hbar/2</math>''\".<ref name=\"ballentine1970\">Section 3.2 of {{Citation|last=Ballentine|first=Leslie E.|title=The Statistical Interpretation of Quantum Mechanics|journal=Reviews of Modern Physics|volume=42|pages=358–381|year=1970|doi=10.1103/RevModPhys.42.358|issue=4|bibcode=1970RvMP...42..358B|url=http://nthur.lib.nthu.edu.tw/dspace/handle/987654321/65291}}.  This fact is experimentally well-known for example in quantum optics (see e.g. chap. 2 and Fig. 2.1  {{Citation|last=Leonhardt|first=Ulf|title=Measuring the Quantum State of Light|year=1997|publisher=Cambridge University Press|location=Cambridge|isbn=0 521 49730 2}}</ref>}}\n\nSince the uncertainty principle is such a basic result in quantum mechanics, typical experiments in quantum mechanics routinely observe aspects of it. Certain experiments, however, may deliberately test a particular form of the uncertainty principle as part of their main research program. These include, for example, tests of number–phase uncertainty relations in [[superconductivity|superconducting]]<ref>{{Citation|last=Elion|first=W. J.|author2=M. Matters, U. Geigenmüller & J. E. Mooij|title=Direct demonstration of Heisenberg's uncertainty principle in a superconductor|journal=Nature|volume=371|pages=594–595|year=1994|doi=10.1038/371594a0|bibcode = 1994Natur.371..594E|issue=6498 |last3=Geigenmüller|first3=U.|last4=Mooij|first4=J. E.}}</ref> or [[quantum optics]]<ref>{{Citation|last=Smithey|first=D. T.|author2=M. Beck, J. Cooper, M. G. Raymer|title=Measurement of number–phase uncertainty relations of optical fields|journal=Phys. Rev. A|volume=48|pages=3159–3167|year=1993|doi=10.1103/PhysRevA.48.3159|bibcode = 1993PhRvA..48.3159S|issue=4|pmid=9909968 |last3=Cooper|first3=J.|last4=Raymer|first4=M. G.}}</ref> systems. Applications dependent on the uncertainty principle for their operation include extremely low-noise technology such as that required in [[gravitational-wave interferometer|gravitational wave interferometer]]s.<ref>{{Citation|last=Caves|first=Carlton|title=Quantum-mechanical noise in an interferometer|journal=Phys. Rev. D|volume=23|pages=1693–1708|year=1981|doi=10.1103/PhysRevD.23.1693|bibcode = 1981PhRvD..23.1693C|issue=8 }}</ref>\n\n==Introduction==\n{{Main article|Introduction to quantum mechanics}}\n[[File:Uncertainty principle.gif|360px|\"360px\"|right|thumb| Click to see animation. The evolution of an initially very localized gaussian wave function of a free particle in two-dimensional space, with color and intensity indicating phase and amplitude. The spreading of the wave function in all directions shows that the initial momentum has a spread of values, unmodified in time; while the spread in position increases in time: as a result, the uncertainty Δ''x''&nbsp;Δ''p'' increases in time.]]\n\n[[File:Sequential superposition of plane waves.gif|360px|\"360px\"|right|thumb|The superposition of several plane waves to form a wave packet. This wave packet becomes increasingly localized with the addition of many waves. The Fourier transform is a mathematical operation that separates a wave packet into its individual plane waves. Note that the waves shown here are real for illustrative purposes only, whereas in quantum mechanics the wave function is generally complex.]]\n\nThe uncertainty principle is not readily apparent on the macroscopic scales of everyday experience.<ref>{{cite journal|last1=Jaeger|first1=Gregg|title=What in the (quantum) world is macroscopic?|journal=American Journal of Physics|date=September 2014|volume=82|issue=9|pages=896–905|doi=10.1119/1.4878358|bibcode = 2014AmJPh..82..896J }}</ref> So it is helpful to demonstrate how it applies to more easily understood physical situations. Two alternative frameworks for quantum physics offer different explanations for the uncertainty principle. The [[Schrödinger equation|wave mechanics]] picture of the uncertainty principle is more visually intuitive, but the more abstract [[matrix mechanics]] picture formulates it in a way that generalizes more easily.\n\nMathematically, in wave mechanics, the uncertainty relation between position and momentum arises because the expressions of the wavefunction in the two corresponding [[orthonormal]] [[basis (linear algebra)|bases]] in [[Hilbert space]] are [[Fourier transforms]] of one another (i.e., position and momentum are [[conjugate variables]]). A nonzero function and its Fourier transform cannot both be sharply localized. A similar tradeoff between the variances of Fourier conjugates arises in all systems underlain by Fourier analysis, for example in sound waves: A pure tone is a [[Dirac delta function|sharp spike]] at a single frequency, while its Fourier transform gives the shape of the sound wave in the time domain, which is a completely delocalized sine wave. In quantum mechanics, the two key points are that the position of the particle takes the form of a [[matter wave]], and momentum is its Fourier conjugate, assured by the de Broglie relation {{math|''p'' {{=}} ''ħk''}}, where {{mvar|k}} is the [[wavenumber]].\n\nIn [[matrix mechanics]], the [[mathematical formulation of quantum mechanics#Postulates of quantum mechanics|mathematical formulation of quantum mechanics]], any pair of non-[[commutator|commuting]] [[self-adjoint operator]]s representing [[observable]]s are subject to similar uncertainty limits. An eigenstate of an observable represents the state of the wavefunction for a certain measurement value (the eigenvalue). For example, if a measurement of an observable {{mvar|A}} is performed, then the system is in a particular eigenstate {{mvar|Ψ}} of that observable. However, the particular eigenstate of the observable {{mvar|A}} need not be an eigenstate of another observable {{mvar|B}}: If so, then it does not have a unique associated measurement for it, as the system is not in an eigenstate of that observable.<ref>{{Citation|author1=Claude Cohen-Tannoudji |author2=Bernard Diu |author3=Franck Laloë |title=Quantum mechanics|year=1996|publisher=Wiley|location=Wiley-Interscience|isbn=978-0-471-56952-7|pages=231–233}}</ref>\n\n===Wave mechanics interpretation===\n(Ref <ref name=\"L&L\">{{cite book\n |author=[[Lev Landau|L.D. Landau]], [[Evgeny Lifshitz|E. M. Lifshitz]]\n |year=1977\n |title=Quantum Mechanics: Non-Relativistic Theory\n |edition=3rd |volume=Vol. 3\n |publisher=[[Pergamon Press]]\n |isbn=978-0-08-020940-1\n}}   [https://archive.org/details/QuantumMechanics_104 Online copy].</ref>)\n\n{{multiple image\n| align = right\n| direction = vertical\n| footer = Propagation of [[matter wave|de Broglie waves]] in 1d—real part of the [[complex number|complex]] amplitude is blue, imaginary part is green. The probability (shown as the colour [[opacity (optics)|opacity]]) of finding the particle at a given point ''x'' is spread out like a waveform, there is no definite position of the particle. As the amplitude increases above zero the [[curvature]] reverses sign, so the amplitude begins to decrease again, and vice versa—the result is an alternating amplitude: a wave.\n| image1 = Propagation of a de broglie plane wave.svg\n| caption1 = [[Plane wave]]\n| width1 = 250\n| image2 = Propagation of a de broglie wavepacket.svg\n| caption2 = [[Wave packet]]\n| width2 = 250\n}}\n{{Main article|Wave packet}}\n{{Main article|Schrödinger equation}}\nAccording to the [[Matter wave|de Broglie hypothesis]], every object in the universe is a [[wave]], i.e., a situation which gives rise to this phenomenon. The position of the particle is described by a [[wave function]] <math>\\Psi(x,t)</math>. The time-independent wave function of a single-moded plane wave of wavenumber ''k''<sub>0</sub> or momentum ''p''<sub>0</sub> is\n\n:<math>\\psi(x) \\propto e^{ik_0 x} = e^{ip_0 x/\\hbar} ~.</math>\n\nThe [[Born rule]] states that this should be interpreted as a [[probability density function|probability density amplitude function]] in the sense that the probability of finding the particle between ''a'' and ''b'' is\n\n:<math> \\operatorname P [a \\leq X \\leq b] = \\int_a^b |\\psi(x)|^2 \\, \\mathrm{d}x ~.</math>\n\nIn the case of the single-moded plane wave, <math>|\\psi(x)|^2</math> is a [[uniform distribution (continuous)|uniform distribution]]. In other words, the particle position is extremely uncertain in the sense that it could be essentially anywhere along the wave packet. \n\nOn the other hand, consider a wave function that is a [[superposition principle|sum of many waves]], which we may write this as\n\n:<math>\\psi(x) \\propto \\sum_n A_n e^{i p_n x/\\hbar}~, </math>\nwhere ''A''<sub>''n''</sub> represents the relative contribution of the mode ''p''<sub>''n''</sub> to the overall total. The figures to the right show how with the addition of many plane waves, the wave packet can become more localized. We may take this a step further to the continuum limit, where the wave function is an [[integral]] over all possible modes\n\n:<math>\\psi(x) = \\frac{1}{\\sqrt{2 \\pi \\hbar}} \\int_{-\\infty}^\\infty \\varphi(p) \\cdot e^{i p x/\\hbar} \\, dp ~, </math>\n\nwith <math>\\varphi(p)</math> representing the amplitude of these modes and is called the wave function in [[momentum space]]. In mathematical terms, we say that <math>\\varphi(p)</math> is the ''[[Fourier transform]]'' of <math>\\psi(x)</math> and that ''x'' and ''p'' are [[conjugate variables]]. Adding together all of these plane waves comes at a cost, namely the momentum has become less precise, having become a mixture of waves of many different momenta.\n\nOne way to quantify the precision of the position and momentum is the [[standard deviation]]&nbsp;''σ''. Since <math>|\\psi(x)|^2</math> is a probability density function for position, we calculate its standard deviation.\n\nThe precision of the position is improved, i.e. reduced σ<sub>x</sub>, by using many plane waves, thereby weakening the precision of the momentum, i.e. increased σ<sub>p</sub>. Another way of stating this is that σ<sub>x</sub> and σ<sub>p</sub> have an [[inverse relationship]] or are at least bounded from below. This is the uncertainty principle, the exact limit of which is the Kennard bound. Click the ''show'' button below to see a semi-formal derivation of the Kennard inequality using wave mechanics.\n{| class=\"toccolours collapsible collapsed\" width=\"60%\" style=\"text-align:left\"\n!Proof of the Kennard inequality using wave mechanics\n|-\n|We are interested in the [[variance]]s of position and momentum, defined as\n\n:<math>\\sigma_x^2 = \\int_{-\\infty}^\\infty x^2 \\cdot |\\psi(x)|^2 \\, dx - \\left( \\int_{-\\infty}^\\infty x \\cdot |\\psi(x)|^2 \\, dx \\right)^2</math>\n\n:<math>\\sigma_p^2 = \\int_{-\\infty}^\\infty p^2 \\cdot |\\varphi(p)|^2 \\, dp - \\left( \\int_{-\\infty}^\\infty p \\cdot |\\varphi(p)|^2 \\, dp \\right)^2~.</math>\n\n[[Without loss of generality]], we will assume that the [[expected value|means]] vanish, which just amounts to a shift of the origin of our coordinates. (A more general proof that does not make this assumption is given below.) This gives us the simpler form\n\n:<math>\\sigma_x^2 = \\int_{-\\infty}^\\infty x^2 \\cdot |\\psi(x)|^2 \\, dx</math>\n:<math>\\sigma_p^2 = \\int_{-\\infty}^\\infty p^2 \\cdot |\\varphi(p)|^2 \\, dp~.</math>\n\nThe function <math>f(x) = x \\cdot \\psi(x)</math> can be interpreted as a [[vector space|vector]] in a [[function space]]. We can define an [[inner product]] for a pair of functions ''u''(''x'') and ''v''(''x'') in this vector space:\n\n:<math>\\langle u \\mid v \\rangle = \\int_{-\\infty}^\\infty u^*(x) \\cdot v(x) \\, dx,</math>\n\nwhere the asterisk denotes the [[complex conjugate]].\n\nWith this inner product defined, we note that the variance for position can be written as\n: <math>\\sigma_x^2 = \\int_{-\\infty}^\\infty |f(x)|^2 \\, dx = \\langle f \\mid f \\rangle ~.</math>\n\nWe can repeat this for momentum by interpreting the function <math>\\tilde{g}(p)=p \\cdot \\varphi(p)</math> as a vector, but we can also take advantage of the fact that <math>\\psi(x)</math> and <math>\\varphi(p)</math> are Fourier transforms of each other. We evaluate the inverse Fourier transform through [[integration by parts]]:\n\n: <math>\\begin{align} g(x) &= \\frac{1}{\\sqrt{2 \\pi \\hbar}} \\cdot \\int_{-\\infty}^\\infty \\tilde{g}(p) \\cdot e^{ipx/\\hbar} \\, dp \\\\\n&= \\frac{1}{\\sqrt{2 \\pi \\hbar}} \\int_{-\\infty}^\\infty p \\cdot \\varphi(p) \\cdot e^{ipx/\\hbar} \\, dp \\\\\n&= \\frac{1}{2 \\pi \\hbar} \\int_{-\\infty}^\\infty \\left[ p \\cdot \\int_{-\\infty}^\\infty \\psi(\\chi) e^{-ip\\chi/\\hbar} \\, d\\chi \\right] \\cdot e^{ipx/\\hbar} \\, dp \\\\\n&= \\frac{i}{2 \\pi} \\int_{-\\infty}^\\infty \\left[ \\cancel{ \\left. \\psi(\\chi) e^{-ip\\chi/\\hbar} \\right|_{-\\infty}^\\infty } - \\int_{-\\infty}^\\infty \\frac{d\\psi(\\chi)}{d\\chi} e^{-ip\\chi/\\hbar} \\, d\\chi \\right] \\cdot e^{ipx/\\hbar} \\, dp \\\\\n&= \\frac{-i}{2 \\pi} \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty \\frac{d\\psi(\\chi)}{d\\chi} e^{-ip\\chi/\\hbar} \\, d\\chi \\, e^{ipx/\\hbar} \\, dp \\\\\n&= \\left( -i \\hbar \\frac{d}{dx} \\right) \\cdot \\psi(x) ,\\end{align}</math>\nwhere the canceled term vanishes because the wave function vanishes at infinity. Often the term <math>-i \\hbar \\frac{d}{dx}</math> is called the momentum operator in position space. Applying [[Parseval's theorem]], we see that the variance for momentum can be written as\n\n: <math>\\sigma_p^2 = \\int_{-\\infty}^\\infty |\\tilde{g}(p)|^2 \\, dp = \\int_{-\\infty}^\\infty |g(x)|^2 \\, dx = \\langle g \\mid g \\rangle.</math>\n\nThe [[Cauchy–Schwarz inequality]] asserts that\n:<math>\\sigma_x^2 \\sigma_p^2 = \\langle f \\mid f \\rangle \\cdot \\langle g \\mid g \\rangle \\ge |\\langle f \\mid g \\rangle|^2 ~.</math>\n\nThe modulus squared of any complex number ''z'' can be expressed as\n:<math>|z|^{2} = \\Big(\\text{Re}(z)\\Big)^{2}+\\Big(\\text{Im}(z)\\Big)^{2} \\geq \\Big(\\text{Im}(z)\\Big)^{2}=\\Big(\\frac{z-z^{\\ast}}{2i}\\Big)^{2}. </math>\nwe let <math>z=\\langle f|g\\rangle</math> and <math>z^{*}=\\langle g\\mid f\\rangle</math> and substitute these into the equation above to get\n\n:<math>|\\langle f\\mid g\\rangle|^2 \\geq \\bigg(\\frac{\\langle f\\mid g\\rangle-\\langle g \\mid f \\rangle}{2i}\\bigg)^2 ~.</math>\n\nAll that remains is to evaluate these inner products.\n\n: <math>\\begin{align}\\langle f\\mid g\\rangle-\\langle g\\mid f\\rangle = {} & \\int_{-\\infty}^\\infty \\psi^*(x) \\, x \\cdot \\left(-i \\hbar \\frac{d}{dx}\\right) \\, \\psi(x) \\, dx \\\\\n&{} - \\int_{-\\infty}^\\infty \\psi^*(x) \\, \\left(-i \\hbar \\frac{d}{dx}\\right) \\cdot x \\, \\psi(x) \\, dx \\\\\n= {} & i \\hbar \\cdot \\int_{-\\infty}^\\infty \\psi^*(x) \\left[ \\left(-x \\cdot \\frac{d\\psi(x)}{dx}\\right) + \\frac{d(x \\psi(x))}{dx} \\right] \\, dx \\\\\n= {} & i \\hbar \\cdot \\int_{-\\infty}^\\infty \\psi^*(x) \\left[ \\left(-x \\cdot \\frac{d\\psi(x)}{dx}\\right) + \\psi(x) + \\left(x \\cdot \\frac{d\\psi(x)}{dx}\\right)\\right] \\, dx \\\\\n= {} & i \\hbar \\cdot \\int_{-\\infty}^\\infty \\psi^*(x) \\psi(x) \\, dx \\\\\n= {} & i \\hbar \\cdot \\int_{-\\infty}^\\infty |\\psi(x)|^2 \\, dx \\\\\n= {} & i \\hbar\\end{align}</math>\n\nPlugging this into the above inequalities, we get\n\n:<math>\\sigma_x^2 \\sigma_p^2 \\ge |\\langle f \\mid g \\rangle|^2 \\ge \\left(\\frac{\\langle f\\mid g\\rangle-\\langle g\\mid f\\rangle}{2i}\\right)^2 = \\left(\\frac{i \\hbar}{2 i}\\right)^2 = \\frac{\\hbar^2}{4}</math>\nor taking the square root\n\n:<math>\\sigma_x \\sigma_p \\ge \\frac{\\hbar}{2}~.</math>\n\nNote that the only ''physics'' involved in this proof was that <math>\\psi(x)</math> and <math>\\varphi(p)</math> are wave functions for position and momentum, which are Fourier transforms of each other. A similar result would hold for ''any'' pair of conjugate variables.\n|}\n\n===Matrix mechanics interpretation===\n(Ref <ref name=\"L&L\"/>) \n{{Main article|Matrix mechanics}}\nIn matrix mechanics, observables such as position and momentum are represented by [[self-adjoint operator]]s. When considering pairs of observables,  an important quantity is the ''[[commutator]]''. For a pair of operators {{mvar|Â}} and {{mvar|B̂}},  one defines their commutator as\n:<math>[\\hat{A},\\hat{B}]=\\hat{A}\\hat{B}-\\hat{B}\\hat{A}.</math>\nIn the case of position and momentum, the commutator is the [[canonical commutation relation]]\n:<math>[\\hat{x},\\hat{p}]=i \\hbar.</math>\n\nThe physical meaning of the non-commutativity can be understood by considering the effect of the commutator on position and momentum [[eigenstate]]s. Let <math>|\\psi\\rangle</math> be a right eigenstate of position with a constant eigenvalue {{math|''x''<sub>0</sub>}}. By definition, this means that <math>\\hat{x}|\\psi\\rangle = x_0 |\\psi\\rangle.</math> Applying the commutator to <math>|\\psi\\rangle</math> yields\n:<math>[\\hat{x},\\hat{p}] | \\psi \\rangle = (\\hat{x}\\hat{p}-\\hat{p}\\hat{x}) | \\psi \\rangle = (\\hat{x} - x_0 \\hat{I}) \\hat{p} \\, | \\psi \\rangle = i \\hbar | \\psi \\rangle,</math>\nwhere {{mvar|Î}} is  the [[identity matrix|identity operator]].\n\nSuppose, for the sake of [[proof by contradiction]], that <math>|\\psi\\rangle</math> is also a right eigenstate of momentum, with constant eigenvalue {{mvar|''p''<sub>0</sub>}}. If this were true, then  one could write\n:<math>(\\hat{x} - x_0 \\hat{I}) \\hat{p} \\, | \\psi \\rangle = (\\hat{x} - x_0 \\hat{I}) p_0 \\, | \\psi \\rangle = (x_0 \\hat{I} - x_0 \\hat{I})  p_0 \\, | \\psi \\rangle=0.</math>\nOn the other hand, the above canonical commutation relation requires that\n:<math>[\\hat{x},\\hat{p}] | \\psi \\rangle=i \\hbar | \\psi \\rangle \\ne 0.</math>\nThis implies that no quantum state can simultaneously be both a position and a momentum eigenstate.\n\nWhen a state is measured, it is projected onto an eigenstate in the basis of the relevant observable. For example, if a particle's position is measured, then the state amounts to a position eigenstate. This means that the state is ''not'' a momentum eigenstate, however, but rather it can be represented  as a sum of multiple momentum basis eigenstates. In other words, the momentum must be less precise. This precision may be quantified by the [[standard deviation]]s,  \n:<math>\\sigma_x=\\sqrt{\\langle \\hat{x}^2 \\rangle-\\langle \\hat{x}\\rangle^2}</math>\n:<math>\\sigma_p=\\sqrt{\\langle \\hat{p}^2 \\rangle-\\langle \\hat{p}\\rangle^2}.</math>\n\nAs in the wave mechanics interpretation above, one sees a tradeoff between the respective precisions of the two, quantified by the uncertainty principle.\n\n==Robertson–Schrödinger uncertainty relations==\nThe most common general form of the uncertainty principle is the ''[[Howard Percy Robertson|Robertson]] uncertainty relation''.<ref name=\"Robertson1929\">{{Citation|last=Robertson|first=H. P.|title=The Uncertainty Principle|journal=Phys. Rev.|year=1929|volume=34|pages=163–64|bibcode = 1929PhRv...34..163R |doi = 10.1103/PhysRev.34.163 }}</ref>\n\nFor an arbitrary [[Self-adjoint operator|Hermitian operator]] <math>\\hat{\\mathcal{O}}</math> we can associate a standard deviation\n\n:::<math>\\sigma_{\\mathcal{O}} = \\sqrt{\\langle \\hat{\\mathcal{O}}^2 \\rangle-\\langle \\hat{\\mathcal{O}}\\rangle^2},</math>\n\nwhere the brackets <math>\\langle\\mathcal{O}\\rangle</math> indicate an [[expectation value (quantum mechanics)|expectation value]]. For a pair of operators <math>\\hat{A}</math> and <math>\\hat{B}</math>, we may define their ''[[commutator]]'' as\n\n:::<math>[\\hat{A},\\hat{B}]=\\hat{A}\\hat{B}-\\hat{B}\\hat{A},</math>\n\nIn this notation, the Robertson uncertainty relation is given by\n\n::: <math>\\sigma_A \\sigma_B \\geq \\left| \\frac{1}{2i}\\langle[\\hat{A},\\hat{B}]\\rangle \\right| = \\frac{1}{2}\\left|\\langle[\\hat{A},\\hat{B}]\\rangle \\right|,</math>\n\nThe Robertson uncertainty relation immediately [[Logical consequence|follows from]] a slightly stronger inequality, the ''Schrödinger uncertainty relation'',<ref name=\"Schrodinger1930\">{{Citation | last = Schrödinger |first = E. | title = Zum Heisenbergschen Unschärfeprinzip | journal = Sitzungsberichte der Preussischen Akademie der Wissenschaften, Physikalisch-mathematische Klasse | volume = 14 | pages = 296–303 | year = 1930}}</ref>\n{{Equation box 1\n|indent =::\n|equation = <math>\\sigma_A^2\\sigma_B^2 \\geq \\left| \\frac{1}{2}\\langle\\{\\hat{A}, \\hat{B}\\}\\rangle - \\langle \\hat{A} \\rangle\\langle \\hat{B}\\rangle \\right|^2+ \\left|\\frac{1}{2i} \\langle[ \\hat{A}, \\hat{B}] \\rangle\\right|^2,</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere we have introduced the ''anticommutator'',\n:::<math>\\{\\hat{A},\\hat{B}\\}=\\hat{A}\\hat{B}+\\hat{B}\\hat{A}.</math>\n\n{| class=\"toccolours collapsible collapsed\" width=\"60%\" style=\"text-align:left\"\n!Proof of the Schrödinger uncertainty relation\n|-\n|The derivation shown here incorporates and builds off of those shown in Robertson,<ref name=\"Robertson1929\" /> Schrödinger<ref name=\"Schrodinger1930\" /> and standard textbooks such as Griffiths.<ref name=\"Griffiths2005\">{{Citation|last=Griffiths|first=David|title=Quantum Mechanics|year=2005|publisher=Pearson|location=New Jersey}}</ref> For any Hermitian operator <math>\\hat{A}</math>, based upon the definition of [[variance]], we have\n\n:::<math> \\sigma_A^2 = \\langle(\\hat{A}-\\langle \\hat{A} \\rangle)\\Psi|(\\hat{A}-\\langle \\hat{A} \\rangle)\\Psi\\rangle. </math>\n\nwe let <math>|f\\rangle=|(\\hat{A}-\\langle \\hat{A} \\rangle)\\Psi\\rangle </math> and thus\n\n:::<math> \\sigma_A^2 = \\langle f\\mid f\\rangle\\, .</math>\n\nSimilarly, for any other Hermitian operator <math> \\hat{B} </math> in the same state\n\n:::<math> \\sigma_B^2 = \\langle(\\hat{B}-\\langle \\hat{B} \\rangle)\\Psi|(\\hat{B}-\\langle \\hat{B} \\rangle)\\Psi\\rangle = \\langle g\\mid g\\rangle </math>\n\nfor <math> |g\\rangle=|(\\hat{B}-\\langle \\hat{B} \\rangle)\\Psi \\rangle.</math>\n\nThe product of the two deviations can thus be expressed as\n\n:::{{NumBlk|:|<math> \\sigma_A^2\\sigma_B^2 = \\langle f\\mid f\\rangle\\langle g\\mid g\\rangle. </math>|{{EquationRef|1}}}}\n\nIn order to relate the two vectors <math>|f\\rangle</math> and <math>|g\\rangle</math>, we use the [[Cauchy–Schwarz inequality]]<ref name=\"Riley2006\">{{Citation | last = Riley | first = K. F. | author2 = M. P. Hobson and S. J. Bence | title = Mathematical Methods for Physics and Engineering | publisher = Cambridge | year = 2006 | pages = 246 }}</ref> which is defined as\n\n:::<math>\\langle f\\mid f\\rangle\\langle g\\mid g\\rangle \\geq |\\langle f\\mid g\\rangle|^2, </math>\n\nand thus Eq. ({{EquationNote|1}}) can be written as\n\n:::{{NumBlk|:|<math>\\sigma_A^2\\sigma_B^2 \\geq |\\langle f\\mid g\\rangle|^2.</math>|{{EquationRef|2}}}}\n\nSince <math> \\langle f\\mid g\\rangle</math> is in general a complex number, we use the fact that the modulus squared of any complex number <math>z</math> is defined as <math>|z|^2=zz^{*}</math>, where <math>z^{*}</math> is the complex conjugate of <math>z</math>. The modulus squared can also be expressed as\n\n:::{{NumBlk|:|<math> |z|^2 = \\Big(\\operatorname{Re}(z)\\Big)^2+\\Big(\\operatorname{Im}(z)\\Big)^2 = \\Big(\\frac{z+z^\\ast}{2}\\Big)^2 +\\Big(\\frac{z-z^\\ast}{2i}\\Big)^2. </math>|{{EquationRef|3}}}}\n\nwe let <math>z=\\langle f\\mid g\\rangle</math> and <math>z^{*}=\\langle g \\mid f \\rangle </math> and substitute these into the equation above to get\n\n:::{{NumBlk|:|<math>|\\langle f\\mid g\\rangle|^2 = \\bigg(\\frac{\\langle f\\mid g\\rangle+\\langle g\\mid f\\rangle}{2}\\bigg)^2 + \\bigg(\\frac{\\langle f\\mid g\\rangle-\\langle g\\mid f\\rangle}{2i}\\bigg)^2 </math>|{{EquationRef|4}}}}\n\nThe inner product <math>\\langle f\\mid g\\rangle </math> is written out explicitly as\n\n:::<math>\\langle f\\mid g\\rangle = \\langle(\\hat{A}-\\langle \\hat{A} \\rangle)\\Psi|(\\hat{B}-\\langle \\hat{B} \\rangle)\\Psi\\rangle,</math>\n\nand using the fact that <math>\\hat{A}</math> and <math>\\hat{B}</math> are Hermitian operators, we find\n\n:<math>\n\\begin{align}\n\\langle f\\mid g\\rangle & = \\langle\\Psi|(\\hat{A}-\\langle \\hat{A}\\rangle)(\\hat{B}-\\langle \\hat{B}\\rangle)\\Psi\\rangle \\\\[4pt]\n& = \\langle\\Psi\\mid(\\hat{A}\\hat{B}-\\hat{A}\\langle \\hat{B}\\rangle - \\hat{B}\\langle \\hat{A}\\rangle + \\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle)\\Psi\\rangle \\\\[4pt]\n& = \\langle\\Psi\\mid\\hat{A}\\hat{B}\\Psi\\rangle-\\langle\\Psi\\mid\\hat{A}\\langle \\hat{B}\\rangle\\Psi\\rangle\n-\\langle\\Psi\\mid\\hat{B}\\langle \\hat{A}\\rangle\\Psi\\rangle+\\langle\\Psi\\mid\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle\\Psi\\rangle \\\\[4pt]\n& =\\langle \\hat{A}\\hat{B}\\rangle-\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle-\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle+\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle \\\\[4pt]\n& =\\langle \\hat{A}\\hat{B}\\rangle-\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle.\n\\end{align}\n</math>\n\nSimilarly it can be shown that <math>\\langle g\\mid f\\rangle = \\langle \\hat{B}\\hat{A}\\rangle-\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle.</math>\n\nThus we have\n\n:::<math>\n\\langle f\\mid g\\rangle-\\langle g\\mid f\\rangle = \\langle \\hat{A}\\hat{B}\\rangle-\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle-\\langle \\hat{B}\\hat{A}\\rangle+\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle = \\langle [\\hat{A},\\hat{B}]\\rangle\n</math>\n\nand\n\n:::<math>\\langle f\\mid g\\rangle+\\langle g\\mid f\\rangle = \\langle \\hat{A}\\hat{B}\\rangle-\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle+\\langle \\hat{B}\\hat{A}\\rangle-\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle = \\langle \\{\\hat{A},\\hat{B}\\}\\rangle -2\\langle \\hat{A}\\rangle\\langle \\hat{B}\\rangle. </math>\n\nWe now substitute the above two equations above back into Eq. ({{EquationNote|4}}) and get\n:::<math>\n|\\langle f\\mid g\\rangle|^2=\\Big(\\frac{1}{2}\\langle\\{\\hat{A},\\hat{B}\\}\\rangle - \\langle \\hat{A} \\rangle\\langle \\hat{B}\\rangle\\Big)^2 + \\Big(\\frac{1}{2i} \\langle[\\hat{A},\\hat{B}]\\rangle\\Big)^{2}\\, .\n</math>\n\nSubstituting the above into Eq. ({{EquationNote|2}}) we get the Schrödinger uncertainty relation\n\n:::<math>\n\\sigma_A\\sigma_B \\geq \\sqrt{\\Big(\\frac{1}{2}\\langle\\{\\hat{A},\\hat{B}\\}\\rangle - \\langle \\hat{A} \\rangle\\langle \\hat{B}\\rangle\\Big)^2 + \\Big(\\frac{1}{2i} \\langle[\\hat{A},\\hat{B}]\\rangle\\Big)^2}.\n</math>\n\nThis proof has an issue<ref>{{Citation|last=Davidson|first=E. R.|title=On Derivations of the Uncertainty Principle|journal=J. Chem. Phys.|volume=42|year=1965|doi=10.1063/1.1696139|bibcode = 1965JChPh..42.1461D|issue=4|pages=1461 }}</ref> related to the domains of the operators involved. For the proof to make sense, the vector <math> \\hat{B} |\\Psi \\rangle</math> has to be in the domain of the [[unbounded operator]] <math> \\hat{A}</math>, which is not always the case. In fact, the Robertson uncertainty relation is false if <math>\\hat{A}</math> is an angle variable and <math>\\hat{B}</math> is the derivative with respect to this variable. In this example, the commutator is a nonzero constant—just as in the Heisenberg uncertainty relation—and yet there are states where the product of the uncertainties is zero.<ref name=\"Hall2013\">{{Citation | last = Hall | first = B. C. | title = Quantum Theory for Mathematicians | publisher = Springer | year = 2013 | pages = 245 }}</ref> (See the counterexample section below.) This issue can be overcome by using a [[variational method]] for the proof.,<ref>{{Citation|last=Jackiw|first=Roman|title=Minimum Uncertainty Product, Number‐Phase Uncertainty Product, and Coherent States|journal=J. Math. Phys.|volume=9|year=1968|doi=10.1063/1.1664585|bibcode = 1968JMP.....9..339J|issue=3|pages=339 }}</ref><ref name=\"CarruthersNieto\">{{Citation|first=P. |last=Carruthers|last2= Nieto|first2=M. M.|title=Phase and Angle Variables in Quantum Mechanics|journal=Rev. Mod. Phys.|volume=40|year=1968|doi=10.1103/RevModPhys.40.411|bibcode = 1968RvMP...40..411C|issue=2|pages=411–440 }}</ref> or by working with an exponentiated version of the canonical commutation relations.<ref name=\"Hall2013\"/>\n\nNote that in the general form of the Robertson–Schrödinger uncertainty relation, there is no need to assume that the operators <math>\\hat{A}</math> and <math>\\hat{B}</math> are [[Self-adjoint operator#Self-adjoint operators|self-adjoint operators]]. It suffices to assume that they are merely [[Self-adjoint operator#Symmetric operators|symmetric operators]]. (The distinction between these two notions is generally glossed over in the physics literature, where the term ''Hermitian'' is used for either or both classes of operators. See Chapter 9 of Hall's book<ref>{{Citation | last = Hall | first = B. C. | title = Quantum Theory for Mathematicians | publisher = Springer | year = 2013 }}</ref> for a detailed discussion of this important but technical distinction.)\n|}\n\n===Examples===\n\nSince the Robertson and Schrödinger relations are for general operators, the relations can be applied to any two observables to obtain specific uncertainty relations. A few of the most common relations found in the literature are given below.\n* For position and linear momentum, the [[canonical commutation relation]] <math>[\\hat{x}, \\hat{p}] = i\\hbar</math> implies the Kennard inequality from above:\n:: <math>\\sigma_x \\sigma_p \\geq \\frac{\\hbar}{2}.</math>\n* For two orthogonal components of the [[angular momentum|total angular momentum]] operator of an object:\n:: <math>\\sigma_{J_i} \\sigma_{J_j} \\geq \\frac{\\hbar}{2} \\big|\\langle J_k\\rangle\\big|,</math>\n: where ''i'', ''j'', ''k'' are distinct, and ''J''<sub>''i''</sub> denotes angular momentum along the ''x''<sub>''i''</sub> axis. This relation implies that unless all three components vanish together, only a single component of a system's angular momentum can be defined with arbitrary precision, normally the component parallel to an external (magnetic or electric) field. Moreover, for <math>[J_x, J_y] = i \\hbar \\varepsilon_{xyz} J_z</math>, a choice <math>\\hat{A} = J_x</math>, <math>\\hat{B} = J_y</math>, in angular momentum multiplets, ''ψ'' = |''j'', ''m''〉, bounds the [[Casimir invariant]] (angular momentum squared, <math>\\langle J_x^2+ J_y^2 + J_z^2 \\rangle</math>) from below and thus yields useful constraints such as {{nobr|''j''(''j'' + 1) ≥ ''m''(''m'' + 1)}}, and hence ''j'' ≥ ''m'', among others.\n*{{anchor|Time–energy uncertainty relation}} In non-relativistic mechanics, time is privileged as an [[independent variable]]. Nevertheless, in 1945, [[Leonid Mandelshtam|L. I. Mandelshtam]] and [[Igor Tamm|I. E. Tamm]] derived a non-relativistic '''''time–energy uncertainty relation''''', as follows.<ref>L. I. Mandelshtam, I. E. Tamm, [http://daarb.narod.ru/mandtamm/index-eng.html ''The uncertainty relation between energy and time in nonrelativistic quantum mechanics''], 1945.</ref><ref>{{cite journal | last1 = Hilgevoord | first1 = Jan | year = 1996 | title = The uncertainty principle for energy and time | url = http://www.phy.pku.edu.cn/~qhcao/resources/class/QM_panel_13/ajp_uncert_energy_time1.pdf | format = PDF | journal = American Journal of Physics | volume = 64 | issue = 12| pages = 1451–1456 | doi=10.1119/1.18410| bibcode = 1996AmJPh..64.1451H }}; {{cite journal | last1 = Hilgevoord | first1 = Jan | year = 1998 | title = The uncertainty principle for energy and time. II. | url = http://scitation.aip.org/content/aapt/journal/ajp/66/5/10.1119/1.18880 | journal = American Journal of Physics | volume = 66 | issue = 5| pages = 396–402 | doi=10.1119/1.18880| bibcode = 1998AmJPh..66..396H }}</ref> For a quantum system in a non-stationary state {{mvar|ψ}} and an observable ''B'' represented by a self-adjoint operator <math>\\hat B</math>, the following formula holds:\n:: <math> \\sigma_E \\frac{\\sigma_B}{\\left| \\frac{\\mathrm{d}\\langle \\hat B \\rangle}{\\mathrm{d}t}\\right |} \\ge \\frac{\\hbar}{2},</math>\n: where σ<sub>''E''</sub> is the standard deviation of the energy operator (Hamiltonian) in the state {{mvar|ψ}}, σ<sub>''B''</sub> stands for the standard deviation of ''B''. Although the second factor in the left-hand side has dimension of time, it is different from the time parameter that enters the [[Schrödinger equation]]. It is a ''lifetime'' of the state {{mvar|ψ}} with respect to the observable ''B'': In other words, this is the ''time interval'' (Δ''t'') after which the expectation value <math>\\langle\\hat B\\rangle</math> changes appreciably.\n: An informal, heuristic meaning of the principle is the following: A state that only exists for a short time cannot have a definite energy. To have a definite energy, the frequency of the state must be defined accurately, and this requires the state to hang around for many cycles, the reciprocal of the required accuracy. For example, in [[Electromagnetic spectroscopy|spectroscopy]], excited states have a finite lifetime. By the time–energy uncertainty principle, they do not have a definite energy, and, each time they decay, the energy they release is slightly different. The average energy of the outgoing photon has a peak at the theoretical energy of the state, but the distribution has a finite width called the [[Spectral linewidth|''natural linewidth'']]. Fast-decaying states have a broad linewidth, while slow-decaying states have a narrow linewidth.<ref>The broad linewidth of fast-decaying states makes it difficult to accurately measure the energy of the state, and researchers have even used detuned microwave cavities to slow down the decay rate, to get sharper peaks. {{Citation |last=Gabrielse |first=Gerald |author2=H. Dehmelt |title=Observation of Inhibited Spontaneous Emission |journal=Physical Review Letters |volume=55 |pages=67–70 |year=1985 |doi=10.1103/PhysRevLett.55.67 |pmid=10031682 |issue=1 |bibcode=1985PhRvL..55...67G}}</ref>\n: The same linewidth effect also makes it difficult to specify the [[rest mass]] of unstable, fast-decaying particles in [[particle physics]]. The faster the [[particle decay]]s (the shorter its lifetime), the less certain is its mass (the larger the particle's [[Resonance (particle physics)|width]]).\n* For the number of electrons in a [[superconductor]] and the [[Phase factor|phase]] of its [[Ginzburg–Landau theory|Ginzburg–Landau order parameter]]<ref>{{Citation |last=Likharev |first=K. K. |author2=A. B. Zorin |title=Theory of Bloch-Wave Oscillations in Small Josephson Junctions |journal=J. Low Temp. Phys. |volume=59 |issue=3/4 |pages=347–382 |year=1985 |doi=10.1007/BF00683782 |bibcode=1985JLTP...59..347L}}</ref><ref>{{Citation |first=P. W. |last=Anderson |editor-last=Caianiello |editor-first=E. R. |contribution=Special Effects in Superconductivity |title=Lectures on the Many-Body Problem, Vol. 2 |year=1964 |place=New York |publisher=Academic Press}}</ref>\n::<math> \\Delta N \\, \\Delta \\varphi \\geq 1. </math>\n<!--\n===Energy–time uncertainty principle{{anchors|Energy–time uncertainty principle}}===\nOther than the position–momentum uncertainty relation, the most important uncertainty relation is that between energy and time. The energy–time uncertainty relation is not, however, an obvious consequence of the general Robertson–Schrödinger relation. Since energy bears the same relation to time as momentum does to space in [[special relativity]], it was clear to many early founders, [[Niels Bohr]] among them, that the following relation should hold:<ref name=\"Heisenberg_1927\"/><ref name=\"Heisenberg_1930\"/>\n\n::<math> \\Delta E \\Delta t \\gtrsim h,</math>\n\nbut it was not always obvious what <math>\\Delta t</math> precisely meant. The problem is that the time at which the particle has a given state is not an operator belonging to the particle, it is a parameter describing the evolution of the system. As [[Lev Landau]] once joked \"To violate the time–energy uncertainty relation all I have to do is measure the energy very precisely and then look at my watch!\"<ref name=\"C Jansson\">[https://arxiv.org/pdf/0802.3625 The GMc-interpretation of Quantum Mechanics], by Christian Jansson, February 25, 2008</ref>\n\nOne ''false'' formulation of the energy–time uncertainty principle says that measuring the energy of a quantum system to an accuracy <math>\\Delta E</math> requires a time interval <math>\\Delta t > h/\\Delta E</math>. This formulation is similar to the one alluded to in Landau's joke, and was explicitly invalidated by [[Yakir Aharonov|Y. Aharonov]] and [[David Bohm|D. Bohm]] in 1961.<ref>http://148.216.10.84/archivoshistoricosMQ/ModernaHist/Aharonov%20a.pdf</ref> The time <math>\\Delta t</math> in the uncertainty relation is the time during which the system exists unperturbed, not the time during which the experimental equipment is turned on, whereas the position in the other version of the principle refers to where the particle has some probability to be and not where the observer might look.\n\nAnother common misconception is that the energy–time uncertainty principle says that the [[conservation of energy]] can be temporarily violated—energy can be \"borrowed\" from the universe as long as it is \"returned\" within a short amount of time.<ref name=\"Griffiths2005\"/>   Although this agrees with the ''spirit'' of [[relativistic quantum mechanics]], it is based on the false axiom that the energy of the universe is an exactly known parameter at all times. More accurately, when events transpire at shorter time intervals, there is a greater uncertainty in the energy of these events. Therefore it is not that the conservation of energy is ''violated'' when [[quantum field theory]] uses temporary electron–positron pairs in its calculations, but that the energy of quantum systems is not known with enough precision to limit their behavior to a single, simple history. Thus the influence of ''all histories'' must be incorporated into quantum calculations, including those with much greater or much less energy than the mean of the measured/calculated energy distribution.\n\nIn 1932 Dirac offered a precise definition and derivation of the time–energy uncertainty relation in a relativistic quantum theory of \"events\".<ref>see here, and the linked references: http://www.springerlink.com/content/nwq557633112kxk2/</ref>\n-->\n\n===A counterexample===\nSuppose we consider a quantum [[particle in a ring|particle on a ring]], where the wave function depends on an angular variable <math>\\theta</math>, which we may take to lie in the interval <math>[0,2\\pi]</math>. Define \"position\" and \"momentum\" operators <math>\\hat{A}</math> and <math>\\hat{B}</math> by\n\n: <math>\\hat{A}\\psi(\\theta)=\\theta\\psi(\\theta),\\quad \\theta\\in [0,2\\pi],</math>\n\nand\n\n:<math>\\hat{B}\\psi=-i\\hbar\\frac{d\\psi}{d\\theta},</math>\n\nwhere we impose periodic boundary conditions on <math>\\hat{B}</math>. Note that the definition of <math>\\hat{A}</math> depends on our choice to have <math>\\theta</math> range from 0 to <math>2\\pi</math>. These operators satisfy the usual commutation relations for position and momentum operators, <math>[\\hat{A},\\hat{B}]=i\\hbar</math>.<ref>More precisely, <math>\\hat{A}\\hat{B}\\psi-\\hat{B}\\hat{A}\\psi=i\\hbar\\psi</math> whenever both <math>\\hat{A}\\hat{B}\\psi</math> and <math>\\hat{B}\\hat{A}\\psi</math> are defined, and the space of such <math>\\psi</math> is a dense subspace of the quantum Hilbert space. See  {{Citation | last = Hall | first = B. C. | title = Quantum Theory for Mathematicians | publisher = Springer | year = 2013 | pages = 245 }}</ref>\n\nNow let <math>\\psi</math> be any of the eigenstates of <math>\\hat{B}</math>, which are given by <math>\\psi(\\theta)=e^{2\\pi in\\theta}</math>. Note that these states are normalizable, unlike the eigenstates of the momentum operator on the line. Note also that the operator <math>\\hat{A}</math> is bounded, since <math>\\theta</math> ranges over a bounded interval. Thus, in the state <math>\\psi</math>, the uncertainty of <math>B</math> is zero and the uncertainty of <math>A</math> is finite, so that \n:<math>\\sigma_A\\sigma_B=0.</math>\nAlthough this result appears to violate the Robertson uncertainty principle, the paradox is resolved when we note that <math>\\psi</math> is not in the domain of the operator <math>\\hat{B}\\hat{A}</math>, since multiplication by <math>\\theta</math> disrupts the periodic boundary conditions imposed on <math>\\hat{B}</math>.<ref name=\"Hall2013\"/> Thus, the derivation of the Robertson relation, which requires <math>\\hat{A}\\hat{B}\\psi</math> and <math>\\hat{B}\\hat{A}\\psi</math> to be defined, does not apply. (These also furnish an example of operators satisfying the canonical commutation relations but not the [[Canonical commutation relation#The Weyl relations|Weyl relations]].<ref>{{Citation | last = Hall | first = B. C. | title = Quantum Theory for Mathematicians | publisher = Springer | year = 2013 | pages = 285 }}</ref>)\n\nFor the usual position and momentum operators <math>\\hat{X}</math> and <math>\\hat{P}</math> on the real line, no such counterexamples can occur. As long as <math>\\sigma_x</math> and <math>\\sigma_p</math> are defined in the state <math>\\psi</math>, the Heisenberg uncertainty principle holds, even if <math>\\psi</math> fails to be in the domain of <math>\\hat{X}\\hat{P}</math> or of <math>\\hat{P}\\hat{X}</math>.<ref>{{Citation | last = Hall | first = B. C. | title = Quantum Theory for Mathematicians | publisher = Springer | year = 2013 | pages = 246 }}</ref>\n\n==Examples==\n(Refs <ref name=\"L&L\"/><ref name=\"Griffiths2005\"/>)\n\n===Quantum harmonic oscillator stationary states===\n{{Main article|Quantum harmonic oscillator|Stationary state}}\nConsider a one-dimensional quantum harmonic oscillator (QHO). It is possible to express the position and momentum operators in terms of the [[creation and annihilation operators]]:\n:<math>\\hat x = \\sqrt{\\frac{\\hbar}{2m\\omega}}(a+a^\\dagger)</math>\n:<math>\\hat p = i\\sqrt{\\frac{m \\omega\\hbar}{2}}(a^\\dagger-a).</math>\n\nUsing the standard rules for creation and annihilation operators on the eigenstates of the QHO,\n:<math>a^{\\dagger}|n\\rangle=\\sqrt{n+1}|n+1\\rangle</math>\n:<math>a|n\\rangle=\\sqrt{n}|n-1\\rangle, </math> \nthe [[variance]]s may be computed directly,\n:<math>\\sigma_x^2 = \\frac{\\hbar}{m\\omega} \\left( n+\\frac{1}{2}\\right)</math>\n:<math>\\sigma_p^2 = \\hbar m\\omega \\left( n+\\frac{1}{2}\\right)\\, .</math>\nThe product of these standard deviations is then\n:<math>\\sigma_x \\sigma_p = \\hbar \\left(n+\\frac{1}{2}\\right) \\ge \\frac{\\hbar}{2}.~</math>\n\nIn particular, the above Kennard bound<ref name=\"Kennard\" /> is saturated for the [[ground state]] {{math|''n''{{=}}0}}, for which the probability density is just the [[normal distribution]].\n\n===Quantum harmonic oscillator with Gaussian initial condition===\n{{multiple image\n| align = right\n| direction = vertical\n| footer =\nPosition (blue) and momentum (red) probability densities for an initially Gaussian distribution. From top to bottom, the animations show the cases Ω=ω, Ω=2ω, and Ω=ω/2. Note the tradeoff between the widths of the distributions.\n| width1 = 360\n| image1 = Position_and_momentum_of_a_Gaussian_initial_state_for_a_QHO,_balanced.gif\n| width2 = 360\n| image2 = Position_and_momentum_of_a_Gaussian_initial_state_for_a_QHO,_narrow.gif\n| width3 = 360\n| image3 = Position_and_momentum_of_a_Gaussian_initial_state_for_a_QHO,_wide.gif\n}}\n\nIn a quantum harmonic oscillator of characteristic angular frequency ω, place a state that is offset from the bottom of the potential by some displacement ''x''<sub>0</sub> as\n:<math>\\psi(x)=\\left(\\frac{m \\Omega}{\\pi \\hbar}\\right)^{1/4} \\exp{\\left( -\\frac{m \\Omega (x-x_0)^2}{2\\hbar}\\right)},</math>\nwhere Ω describes the width of the initial state but need not be the same as ω. Through integration over the [[Propagator#Basic Examples: Propagator of Free Particle and Harmonic Oscillator|propagator]], we can solve for the {{Not a typo|full time}}-dependent solution. After many cancelations, the probability densities reduce to\n:<math>|\\Psi(x,t)|^2 \\sim \\mathcal{N}\\left( x_0 \\cos{(\\omega t)} , \\frac{\\hbar}{2 m \\Omega} \\left( \\cos^2(\\omega t) + \\frac{\\Omega^2}{\\omega^2} \\sin^2{(\\omega t)} \\right)\\right)</math>\n:<math>|\\Phi(p,t)|^2 \\sim \\mathcal{N}\\left( -m x_0 \\omega \\sin(\\omega t), \\frac{\\hbar m \\Omega}{2} \\left( \\cos^2{(\\omega t)} + \\frac{\\omega^2}{\\Omega^2} \\sin^2{(\\omega t)} \\right)\\right),</math>\nwhere we have used the notation <math>\\mathcal{N}(\\mu, \\sigma^2)</math> to denote a normal distribution of mean μ and variance σ<sup>2</sup>. Copying the variances above and applying [[list of trigonometric identities|trigonometric identities]], we can write the product of the standard deviations as\n\n: <math>\n\\begin{align}\n\\sigma_x \\sigma_p&=\\frac{\\hbar}{2}\\sqrt{\\left( \\cos^2{(\\omega t)} + \\frac{\\Omega^2}{\\omega^2} \\sin^2{(\\omega t)} \\right)\\left( \\cos^2{(\\omega t)} + \\frac{\\omega^2}{\\Omega^2} \\sin^2{(\\omega t)} \\right)} \\\\\n&= \\frac{\\hbar}{4}\\sqrt{3+\\frac{1}{2}\\left(\\frac{\\Omega^2}{\\omega^2}+\\frac{\\omega^2}{\\Omega^2}\\right)-\\left(\\frac{1}{2}\\left(\\frac{\\Omega^2}{\\omega^2}+\\frac{\\omega^2}{\\Omega^2}\\right)-1\\right) \\cos{(4 \\omega t)}}\n\\end{align}\n</math>\n\nFrom the relations\n\n:<math>\\frac{\\Omega^2}{\\omega^2}+\\frac{\\omega^2}{\\Omega^2} \\ge 2, \\quad |\\cos(4 \\omega t)| \\le 1,</math>\n\nwe can conclude the following: (the right most equality holds only when Ω&nbsp;=&nbsp;''ω'') .\n:<math>\\sigma_x \\sigma_p \\ge \\frac{\\hbar}{4}\\sqrt{3+\\frac{1}{2} \\left(\\frac{\\Omega^2}{\\omega^2}+\\frac{\\omega^2}{\\Omega^2}\\right)-\\left(\\frac{1}{2} \\left(\\frac{\\Omega^2}{\\omega^2}+\\frac{\\omega^2}{\\Omega^2}\\right)-1\\right)} = \\frac{\\hbar}{2}. </math>\n\n===Coherent states===\n{{Main article|Coherent state}}\nA coherent state is a right eigenstate of the [[annihilation operator]],\n:<math>\\hat{a}|\\alpha\\rangle=\\alpha|\\alpha\\rangle</math>,\nwhich may be represented in terms of [[Fock state]]s as\n:<math>|\\alpha\\rangle =e^{-{|\\alpha|^2\\over2}} \\sum_{n=0}^\\infty {\\alpha^n \\over \\sqrt{n!}}|n\\rangle</math>\n\nIn the picture where the coherent state is a massive particle in a QHO, the position and momentum operators may be expressed in terms of the annihilation operators in the same formulas above and used to calculate the variances,\n:<math>\\sigma_x^2 = \\frac{\\hbar}{2 m \\omega},</math>\n:<math>\\sigma_p^2 = \\frac{\\hbar m \\omega}{2}.</math>\nTherefore, every coherent state saturates the Kennard bound\n\n:<math>\\sigma_x \\sigma_p = \\sqrt{\\frac{\\hbar}{2 m \\omega}} \\, \\sqrt{\\frac{\\hbar m \\omega}{2}} = \\frac{\\hbar}{2}.</math>\n\nwith position and momentum each contributing an amount <math>\\sqrt{\\hbar/2}</math> in a \"balanced\" way. Moreover, every [[squeezed coherent state]] also saturates the Kennard bound although the individual contributions of position and momentum need not be balanced in general.\n\n===Particle in a box===\n{{Main article|Particle in a box}}\nConsider a particle in a one-dimensional box of length <math>L</math>. The [[Particle in a box#Wavefunctions|eigenfunctions in position and momentum space]] are\n:<math>\\psi_n(x,t) =\n\\begin{cases}\nA \\sin(k_n x)\\mathrm{e}^{-\\mathrm{i}\\omega_n t}, & 0 < x < L,\\\\\n0, & \\text{otherwise,}\n\\end{cases}\n</math>\nand\n:<math>\\varphi_n(p,t)=\\sqrt{\\frac{\\pi L}{\\hbar}}\\,\\,\\frac{n\\left(1-(-1)^ne^{-ikL} \\right) e^{-i \\omega_n t}}{\\pi ^2 n^2-k^2 L^2},</math>\nwhere <math>\\omega_n=\\frac{\\pi^2 \\hbar n^2}{8 L^2 m}</math> and we have used the [[de Broglie relation]] <math>p=\\hbar k</math>. The variances of <math>x</math> and <math>p</math> can be calculated explicitly:\n:<math>\\sigma_x^2=\\frac{L^2}{12}\\left(1-\\frac{6}{n^2\\pi^2}\\right)</math>\n:<math>\\sigma_p^2=\\left(\\frac{\\hbar n\\pi}{L}\\right)^2. </math>\n\nThe product of the standard deviations is therefore\n:<math>\\sigma_x \\sigma_p = \\frac{\\hbar}{2} \\sqrt{\\frac{n^2\\pi^2}{3}-2}.</math>\nFor all <math>n=1, \\, 2, \\, 3,\\, \\ldots</math>, the quantity <math>\\sqrt{\\frac{n^2\\pi^2}{3}-2}</math> is greater than 1, so the uncertainty principle is never violated. For numerical concreteness, the smallest value occurs when <math>n=1</math>, in which case\n\n:<math>\\sigma_x \\sigma_p = \\frac{\\hbar}{2} \\sqrt{\\frac{\\pi^2}{3}-2} \\approx 0.568 \\hbar > \\frac{\\hbar}{2}.</math>\n\n===Constant momentum===\n{{Main article|Wave packet}}\n[[File:Guassian Dispersion.gif|360 px|thumb|right|Position space probability density of an initially Gaussian state moving at minimally uncertain, constant momentum in free space]]\nAssume a particle initially has a [[momentum space]] wave function described by a normal distribution around some constant momentum ''p''<sub>0</sub> according to\n\n:<math>\\varphi(p) = \\left(\\frac{x_0}{\\hbar \\sqrt{\\pi}} \\right)^{1/2} \\cdot \\exp{\\left(\\frac{-x_0^2 (p-p_0)^2}{2\\hbar^2}\\right)},</math>\n\nwhere we have introduced a reference scale <math>x_0=\\sqrt{\\hbar/m\\omega_0}</math>, with <math>\\omega_0>0</math> describing the width of the distribution−−cf. [[nondimensionalization]]. If the state is allowed to evolve in free space, then the time-dependent momentum and position space wave functions are\n\n:<math>\\Phi(p,t) = \\left(\\frac{x_0}{\\hbar \\sqrt{\\pi}} \\right)^{1/2} \\cdot \\exp{\\left(\\frac{-x_0^2 (p-p_0)^2}{2\\hbar^2}-\\frac{ip^2 t}{2m\\hbar}\\right)},</math>\n:<math>\\Psi(x,t) = \\left(\\frac{1}{x_0 \\sqrt{\\pi}} \\right)^{1/2} \\cdot \\frac{e^{-x_0^2 p_0^2 /2\\hbar^2}}{\\sqrt{1+i\\omega_0 t}} \\cdot \\exp{\\left(-\\frac{(x-ix_0^2 p_0/\\hbar)^2}{2x_0^2 (1+i\\omega_0 t)}\\right)}.</math>\n\nSince <math> \\langle p(t) \\rangle = p_0</math> and <math>\\sigma_p(t) = \\hbar / x_0 \\sqrt{2},</math> this can be interpreted as a particle moving along with constant momentum at arbitrarily high precision. On the other hand, the standard deviation of the position is\n:<math>\\sigma_x = \\frac{x_0}{\\sqrt{2}} \\sqrt{1+\\omega_0^2 t^2}</math>\nsuch that the uncertainty product can only increase with time as\n:<math>\\sigma_x(t) \\sigma_p(t) = \\frac{\\hbar}{2} \\sqrt{1+\\omega_0^2 t^2}</math>\n\n==Additional uncertainty relations==\n\n===Mixed states===\nThe Robertson–Schrödinger uncertainty relation may be generalized in a straightforward way to describe [[density matrix|mixed states]].<ref>{{cite web|last=Steiger|first=Nathan|title=Quantum Uncertainty and Conservation Law Restrictions on Gate Fidelity|url=http://www.physics.byu.edu/Thesis/view.aspx?id=270|publisher=Brigham Young University|accessdate=19 June 2011}}</ref>\n\n:::<math>\\sigma_A^2 \\sigma_B^2 \\geq \\left(\\frac{1}{2}\\operatorname{tr}(\\rho\\{A,B\\}) - \\operatorname{tr}(\\rho A)\\operatorname{tr}(\\rho B)\\right)^2 +\\left(\\frac{1}{2i} \\operatorname{tr}(\\rho[A,B])\\right)^2</math>\n\n===The Maccone–Pati uncertainty relations===\nThe Robertson–Schrödinger uncertainty relation can be trivial if the state of the system is chosen to be eigenstate of one of the observable. The stronger uncertainty relations proved by Maccone and Pati give non-trivial bounds on the sum of the variances for two incompatible observables.<ref>{{cite journal|last1=Maccone|first1=Lorenzo|last2=Pati|first2=Arun K.|title=Stronger Uncertainty Relations for All Incompatible Observables|journal=Physical Review Letters|date=31 December 2014|volume=113|issue=26|page=260401|doi=10.1103/PhysRevLett.113.260401|arxiv=1407.0338|bibcode=2014PhRvL.113z0401M}}</ref> (Earlier works on uncertainty relations formulated as the sum of variances include, e.g., Ref. <ref>{{cite journal |last1=Huang |first1=Yichen |title=Variance-based uncertainty relations |journal=Physical Review A |date=10 August 2012 |volume=86 |issue=2 |page=024101 |doi=10.1103/PhysRevA.86.024101}}</ref> due to Huang.)  For two non-commuting observables <math>A</math> and <math>B</math> the first stronger uncertainty relation is given by \n:<math> \\sigma_{A}^2 + \\sigma_{ B}^2 \\ge \\pm i \\langle \\Psi\\mid [A, B]|\\Psi \\rangle  + \\mid \\langle \\Psi\\mid(A \\pm i B)\\mid{\\bar \\Psi} \\rangle|^2, </math>\nwhere <math> \\sigma_{A}^2 = \\langle \\Psi |A^2 |\\Psi \\rangle - \\langle \\Psi \\mid A \\mid \\Psi \\rangle^2   </math>, <math> \\sigma_{B}^2 = \\langle \\Psi |B^2 |\\Psi \\rangle - \\langle \\Psi \\mid B \\mid\\Psi \\rangle^2 </math>, <math>|{\\bar \\Psi} \\rangle </math> is a normalized vector that is orthogonal to the state of the system <math>|\\Psi \\rangle </math> and  one should choose the sign of  <math>\\pm i \\langle \\Psi\\mid[A, B]\\mid\\Psi \\rangle </math> to make this real quantity a positive number.\n\nThe second stronger uncertainty  relation is given by\n:<math> \\sigma_A^2 + \\sigma_B^2 \\ge \\frac{1}{2}| \\langle {\\bar \\Psi}_{A+B} \\mid(A + B)\\mid \\Psi \\rangle|^2 </math>\nwhere <math>| {\\bar \\Psi}_{A+B} \\rangle </math>  is a state orthogonal to <math> |\\Psi \\rangle </math>.\nThe form of <math>| {\\bar \\Psi}_{A+B} \\rangle  </math> implies that the right-hand side of the new uncertainty relation \nis nonzero unless <math>| \\Psi\\rangle  </math> is an eigenstate of <math>(A + B)</math>.  One may note that <math>|\\Psi \\rangle </math> can be an eigenstate of <math>( A+ B)</math> without being an eigenstate of either\n<math> A</math> or <math> B </math>. However,  when <math> |\\Psi \\rangle </math>  is an eigenstate of one of the two observables the Heisenberg–Schrödinger uncertainty relation becomes trivial. But the lower bound in the new relation is nonzero \nunless <math> |\\Psi \\rangle </math>  is an eigenstate of both.\n\n===Phase space===\nIn the [[phase space formulation]] of quantum mechanics, the Robertson–Schrödinger relation follows from a positivity condition on a real star-square function. Given a [[Wigner quasi-probability distribution|Wigner function]] <math>W(x,p)</math> with [[Moyal product|star product]] ★ and a function ''f'', the following is generally true:<ref>{{Cite journal | last1 = Curtright | first1 = T. |last2= Zachos | first2= C. | title = Negative Probability and Uncertainty Relations| journal = Modern Physics Letters A  | volume = 16 | issue = 37 | pages = 2381–2385 | doi = 10.1142/S021773230100576X | year = 2001 | pmid =  | pmc = |arxiv = hep-th/0105226 |bibcode = 2001MPLA...16.2381C }}</ref>\n\n:<math>\\langle f^* \\star f \\rangle =\\int (f^* \\star f) \\, W(x,p) \\, dx \\, dp \\ge 0.</math>\n\nChoosing <math>f=a+bx+cp</math>, we arrive at\n\n:<math>\\langle f^* \\star f \\rangle =\\begin{bmatrix}a^* & b^* & c^* \\end{bmatrix}\\begin{bmatrix}1 & \\langle x \\rangle & \\langle p \\rangle \\\\ \\langle x \\rangle & \\langle x \\star x \\rangle & \\langle x \\star p \\rangle \\\\ \\langle p \\rangle & \\langle p \\star x \\rangle & \\langle p \\star p \\rangle \\end{bmatrix}\\begin{bmatrix}a \\\\ b \\\\ c\\end{bmatrix} \\ge 0.</math>\n\nSince this positivity condition is true for ''all'' ''a'', ''b'', and ''c'', it follows that all the eigenvalues of the matrix are positive. The positive eigenvalues then imply a corresponding positivity condition on the [[determinant]]:\n\n:<math>\\det\\begin{bmatrix}1 & \\langle x \\rangle & \\langle p \\rangle \\\\ \\langle x \\rangle & \\langle x \\star x \\rangle & \\langle x \\star p \\rangle \\\\ \\langle p \\rangle & \\langle p \\star x \\rangle & \\langle p \\star p \\rangle \\end{bmatrix} = \\det\\begin{bmatrix}1 & \\langle x \\rangle & \\langle p \\rangle \\\\ \\langle x \\rangle & \\langle x^2 \\rangle & \\left\\langle xp + \\frac{i\\hbar}{2} \\right\\rangle \\\\ \\langle p \\rangle & \\left\\langle xp - \\frac{i\\hbar}{2} \\right\\rangle & \\langle p^2 \\rangle \\end{bmatrix} \\ge 0,</math>\n\nor, explicitly, after algebraic manipulation,\n\n:<math>\\sigma_x^2 \\sigma_p^2 = \\left( \\langle x^2 \\rangle - \\langle x \\rangle^2 \\right)\\left( \\langle p^2 \\rangle - \\langle p \\rangle^2 \\right)\\ge \\left( \\langle xp \\rangle - \\langle x \\rangle \\langle p \\rangle \\right)^2 + \\frac{\\hbar^2}{4} ~.</math>\n\n===Systematic and statistical errors===\n\nThe inequalities above focus on the ''statistical imprecision'' of observables as quantified by the standard deviation <math>\\sigma</math>. Heisenberg's original version, however, was dealing with the ''systematic error'', a disturbance of the quantum system produced by the measuring apparatus, i.e., an [[Observer effect (physics)|observer effect]].\n\nIf we let <math>\\varepsilon_A</math> represent the error (i.e., [[accuracy|inaccuracy]]) of a measurement of an observable ''A'' and <math>\\eta_B</math> the disturbance produced on a subsequent measurement of the conjugate variable ''B'' by the former measurement of ''A'', then the inequality proposed by Ozawa<ref name=\"Ozawa2003\"/> — encompassing both systematic and statistical errors — holds:\n{{Equation box 1\n|indent =::\n|equation = <math> \\varepsilon_A\\, \\eta_B + \\varepsilon_A \\, \\sigma_B + \\sigma_A \\, \\eta_B \\,\\ge\\,  \\frac{1}{2} \\, \\left| \\langle [\\hat{A},\\hat{B}] \\rangle \\right|</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\n\nHeisenberg's uncertainty principle, as originally described in the 1927 formulation, mentions only the first term of Ozawa inequality, regarding the ''systematic error''.   Using the notation above to describe the ''error/disturbance'' effect of ''sequential measurements'' (first ''A'', then ''B''), it could be written as\n{{Equation box 1\n|indent =::\n|equation = <math> \\varepsilon_{A} \\, \\eta_{B} \\, \\ge \\,   \\frac{1}{2} \\, \\left| \\langle [\\hat{A},\\hat{B}] \\rangle \\right|</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nThe formal derivation of the Heisenberg relation is possible but far from intuitive. It was ''not'' proposed by Heisenberg, but formulated in a mathematically consistent way only in recent years.<ref>{{Cite journal | doi = 10.1103/PhysRevLett.111.160405| title = Proof of Heisenberg's Error-Disturbance Relation| journal = Physical Review Letters| volume = 111| issue = 16| year = 2013| last1 = Busch | first1 = P. | last2 = Lahti | first2 = P. | last3 = Werner | first3 = R. F. |arxiv = 1306.1565 |bibcode = 2013PhRvL.111p0405B | pmid=24182239 | page=160405}}</ref><ref>{{Cite journal | doi = 10.1103/PhysRevA.89.012129| title = Heisenberg uncertainty for qubit measurements| journal = Physical Review A| volume = 89| year = 2014| last1 = Busch | first1 = P. | last2 = Lahti | first2 = P. | last3 = Werner | first3 = R. F. |arxiv = 1311.0837 |bibcode = 2014PhRvA..89a2129B }}</ref>\nAlso, it must be stressed that the Heisenberg formulation is not taking into account the intrinsic statistical errors <math>\\sigma_A</math> and <math>\\sigma_B</math>.  There is increasing experimental evidence<ref name=\"Rozema\"/><ref>{{Cite journal| last1 = Erhart | first1 = J.| last2 = Sponar | first2 =S.| last3 = Sulyok | first3 = G. | last4 = Badurek | first4 = G. | last5 = Ozawa | first5 = M. | last6 =  Hasegawa | first6 = Y.| title = Experimental demonstration of a universally valid error-disturbance uncertainty relation in spin measurements | journal = Nature Physics | volume=8 | pages=185–189 | year=2012 | doi=10.1038/nphys2194 | arxiv = 1201.1833 | bibcode = 2012NatPh...8..185E | issue=3 }}</ref><ref>{{Cite journal| last1 = Baek | first1 =  S.-Y. | last2 = Kaneda  | first2 = F. | last3 = Ozawa | first3 = M. | last4 = Edamatsu | first4 = K. | title =  Experimental violation and reformulation of the Heisenberg's error-disturbance uncertainty relation |journal = Scientific Reports |volume= 3 |pages= 2221 |year= 2013 |doi= 10.1038/srep02221 | url = http://www.nature.com/articles/srep02221 |bibcode = 2013NatSR...3E2221B | pmid=23860715 | pmc=3713528}}</ref><ref>{{Cite journal| last1 = Ringbauer | first1 = M. | last2 = Biggerstaff | first2 = D.N. | last3 = Broome | first3 = M.A. | last4 =  Fedrizzi  | first4 = A.  | last5 =   Branciard | first5 = C. | last6 = White | first6 = A.G. | title = Experimental Joint Quantum Measurements with Minimum Uncertainty |journal =  Physical Review Letters |volume= 112 |pages= 020401 |year= 2014 |doi= 10.1103/PhysRevLett.112.020401 | url = http://journals.aps.org/prl/abstract/10.1103/PhysRevLett.112.020401 |arxiv = 1308.5688 |bibcode = 2014PhRvL.112b0401R | pmid=24483993}}</ref> that the total quantum uncertainty cannot be described by the Heisenberg term alone, but requires the presence of all the three terms of the Ozawa inequality. \n \nUsing the same formalism,<ref name=\"Sen2014\"/> it is also possible to introduce the other kind of physical situation, often confused with the previous one, namely the case of ''simultaneous measurements'' (''A'' and ''B'' at the same time):\n{{Equation box 1\n|indent =::\n|equation = <math> \\varepsilon_A \\, \\varepsilon_B  \\, \\ge  \\, \\frac{1}{2} \\, \\left| \\langle [\\hat{A},\\hat{B}] \\rangle \\right|</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nThe two simultaneous measurements on ''A'' and ''B'' are necessarily<ref>{{Cite journal | last1 = Björk | first1 = G. | last2 = Söderholm | first2 = J. | last3 = Trifonov | first3 = A. | last4 = Tsegaye | first4 = T. | last5 = Karlsson | first5 =  A. |\ntitle = Complementarity and the uncertainty relations | doi = 10.1103/PhysRevA.60.1874 | journal = Physical Review | volume = A60 | year = 1999| page = 1878 |arxiv = quant-ph/9904069 |bibcode = 1999PhRvA..60.1874B }}</ref>  ''unsharp'' or [[weak measurement|''weak'']].\n\nIt is also possible to derive an uncertainty relation that, as the Ozawa's one, combines both the statistical and systematic error components, but keeps a form very close to the Heisenberg original inequality.  By adding Robertson<ref name=\"Sen2014\"/> \n{{Equation box 1\n|indent =::\n|equation = <math> \\sigma_{A} \\, \\sigma_{B}  \\, \\ge  \\, \\frac{1}{2} \\, \\left| \\langle [\\hat{A},\\hat{B}] \\rangle \\right|</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nand Ozawa relations we obtain\n:: <math>\\varepsilon_A \\eta_B + \\varepsilon_A \\, \\sigma_B + \\sigma_A \\, \\eta_B + \\sigma_A \\sigma_B \\geq \\left|\\langle[\\hat{A},\\hat{B}]\\rangle \\right| .</math>\nThe four terms can be written as: \n:: <math>(\\varepsilon_A + \\sigma_A) \\, (\\eta_B + \\sigma_B) \\, \\geq \\,  \\left|\\langle[\\hat{A},\\hat{B}]\\rangle \\right| .</math>\nDefining:\n:: <math>\\bar \\varepsilon_A \\, \\equiv \\, (\\varepsilon_A + \\sigma_A)</math>\nas the ''inaccuracy'' in the measured values of the variable ''A'' and\n:: <math>\\bar \\eta_B \\, \\equiv \\, (\\eta_B + \\sigma_B)</math>\nas the ''resulting fluctuation'' in the conjugate variable ''B'',\nFujikawa<ref>{{Cite journal|last = Fujikawa|first = Kazuo|title = Universally valid Heisenberg uncertainty relation|journal = Physical Review A|volume=85|year=2012|doi=10.1103/PhysRevA.85.062117|arxiv = 1205.1360 |bibcode = 2012PhRvA..85f2117F|issue=6 }}</ref> established \nan uncertainty relation similar to the Heisenberg original one, but valid both for ''systematic and statistical errors'':\n{{Equation box 1\n|indent =::\n|equation = <math> \\bar \\varepsilon_A \\,  \\bar \\eta_B \\, \\ge  \\, \\left| \\langle [\\hat{A},\\hat{B}] \\rangle \\right|</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\n\n=== Quantum entropic uncertainty principle ===\n\nFor many distributions, the standard deviation is not a particularly natural way of quantifying the structure. For example, uncertainty relations in which one of the observables is an angle has little physical meaning for fluctuations larger than one period.<ref name=\"CarruthersNieto\" /><ref>{{Citation |first=D. |last=Judge |title=On the uncertainty relation for angle variables|journal=Il Nuovo Cimento|year=1964|volume=31|issue=2|pages=332–340|doi=10.1007/BF02733639|bibcode=1964NCim...31..332J}}</ref><ref>{{Citation |first1= M. |last1= Bouten |first2= N. |last2= Maene \n| first3= P. | last3= Van Leuven|title=On an uncertainty relation for angle variables|journal=Il Nuovo Cimento|year=1965|volume=37|issue=3|pages=1119–1125|doi=10.1007/BF02773197|bibcode=1965NCim...37.1119B}}</ref><ref>{{Citation |first=W. H. |last=Louisell|title=Amplitude and phase uncertainty relations|journal=Physics Letters|year=1963|volume=7|issue=1|pages=60–61|doi=10.1016/0031-9163(63)90442-6|bibcode = 1963PhL.....7...60L }}</ref> Other examples include highly [[bimodal distribution]]s, or [[unimodal distribution]]s with divergent variance.\n\nA solution that overcomes these issues is an uncertainty based on [[entropic uncertainty]] instead of the product of variances. While formulating the [[many-worlds interpretation]] of quantum mechanics in 1957, [[Hugh Everett III]] conjectured a stronger extension of the uncertainty principle based on entropic certainty.<ref>{{Citation |last=DeWitt |first=B. S. |last2=Graham |first2=N. |year=1973 |title=The [[Many-Worlds Interpretation]] of Quantum Mechanics |location=Princeton |publisher=Princeton University Press |pages=52–53 |isbn=0-691-08126-3 }}</ref> This conjecture, also studied by Hirschman<ref>{{Citation |first=I. I., Jr. |last=Hirschman |title=A note on entropy |journal=[[American Journal of Mathematics]] |year=1957 |volume=79 |issue=1 |pages=152–156 |doi=10.2307/2372390 |postscript=. |jstor=2372390 }}</ref> and proven in 1975 by Beckner<ref name=\"Beckner\">{{Citation |first=W. |last=Beckner |title=Inequalities in Fourier analysis |journal=[[Annals of Mathematics]] |volume=102 |issue=6 |year=1975 |pages=159–182 |doi=10.2307/1970980 |postscript=. |jstor=1970980 }}</ref> and by Iwo Bialynicki-Birula and Jerzy Mycielski<ref name=\"BBM\">{{Citation |first=I. |last=Bialynicki-Birula|last2= Mycielski|first2=J.|title=Uncertainty Relations for Information Entropy in Wave Mechanics|journal=[[Communications in Mathematical Physics]] |volume=44 |year=1975 |pages=129–132 |doi=10.1007/BF01608825 |issue=2|bibcode = 1975CMaPh..44..129B }}</ref> is that, for two normalized, dimensionless [[Fourier transform]] pairs {{math|''f(a)''}} and {{math|''g(b)''}} where\n\n:<math>f(a) = \\int_{-\\infty}^\\infty g(b)\\ e^{2\\pi i a b}\\,db</math>&nbsp;&nbsp;&nbsp; and &nbsp;&nbsp;&nbsp; <math> \\,\\,\\,g(b) = \\int_{-\\infty}^\\infty f(a)\\ e^{- 2\\pi i a b}\\,da</math>\n\nthe Shannon [[Information entropy|information entropies]]\n\n:<math>H_a = \\int_{-\\infty}^\\infty f(a) \\log(f(a))\\,da,</math>\n\nand \n\n:<math>H_b = \\int_{-\\infty}^\\infty g(b) \\log(g(b))\\,db</math>\n\nare subject to the following constraint,\n{{Equation box 1\n|indent =:\n|equation =<math>H_a + H_b \\ge \\log (e/2)</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere the logarithms may be in any base.\n\nThe probability distribution functions associated with the position wave function {{math|''&psi;(x)''}} and the momentum wave function {{math|''&phi;(x)''}} have dimensions of inverse length and momentum respectively, but the entropies may be rendered dimensionless by\n\n:<math>H_x = - \\int |\\psi(x)|^2 \\ln (x_0\\,|\\psi(x)|^2 ) \\,dx =-\\left\\langle \\ln (x_0\\mid\\psi(x)|^2 ) \\right\\rangle</math>\n:<math>H_p = - \\int |\\varphi(p)|^2 \\ln (p_0\\,|\\varphi(p)|^2) \\,dp =-\\left\\langle \\ln (p_0\\left|\\varphi(p)\\right|^2 ) \\right\\rangle</math>\n\nwhere {{math|''x''<sub>0</sub>}} and {{math|''p''<sub>0</sub>}} are some arbitrarily chosen length and momentum respectively, which render the arguments of the logarithms dimensionless. Note that the entropies will be functions of these chosen parameters. Due to the [[Wavefunction#Relation between wave functions|Fourier transform relation]] between the position wave function {{math|''&psi;(x)''}} and the momentum wavefunction {{math|''&phi;''(''p'')}}, the above constraint can be written for the corresponding entropies as\n{{Equation box 1\n|indent =:\n|equation = <math>H_x + H_p \\ge \\log \\left(\\frac{e\\,h}{2\\,x_0\\,p_0}\\right)</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere {{mvar|h}} is [[Planck's constant]].\n\nDepending on one's choice of the {{math|''x<sub>0</sub> p<sub>0</sub>''}} product, the expression may be written in many ways. If {{math|''x<sub>0</sub> p<sub>0</sub>''}} is chosen to be {{mvar|h}}, then\n:<math>H_x + H_p \\ge \\log \\left(\\frac{e}{2}\\right)</math>\n\nIf, instead,  {{math|''x''<sub>0</sub> ''p''<sub>0</sub>}} is chosen to be {{mvar|ħ}}, then\n:<math>H_x + H_p \\ge \\log (e\\,\\pi)</math>\n\nIf {{math|''x<sub>0</sub>''}} and {{math|''p<sub>0</sub>''}} are chosen to be unity in whatever system of units are being used, then\n:<math>H_x + H_p \\ge \\log \\left(\\frac{e\\,h }{2}\\right)</math>\nwhere {{mvar|h}} is interpreted as a dimensionless number equal to the value of Planck's constant in the chosen system of units. Note that these inequalities can be extended to multimode quantum states, or wavefunctions in more than one spatial dimension.<ref>{{cite journal |last1=Huang |first1=Yichen |title=Entropic uncertainty relations in multidimensional position and momentum spaces |journal=Physical Review A |date=24 May 2011 |volume=83 |issue=5 |page=052124 |doi=10.1103/PhysRevA.83.052124}}</ref>\n\nThe quantum entropic uncertainty principle is more restrictive than the Heisenberg uncertainty principle. From the inverse logarithmic Sobolev inequalities<ref>{{citation |first=D. |last=Chafaï |title=Gaussian maximum of entropy and reversed log-Sobolev inequality|arxiv=math/0102227 |doi=10.1007/978-3-540-36107-7_5 |year=2003 |isbn=978-3-540-00072-3 |pages=194–200}}</ref>\n:<math>H_x \\le \\frac{1}{2} \\log ( 2e\\pi \\sigma_x^2 / x_0^2 )~,</math>\n:<math>H_p \\le \\frac{1}{2} \\log ( 2e\\pi \\sigma_p^2 /p_0^2 )~,</math>\n(equivalently, from the fact that normal distributions maximize the entropy of all such with a given variance), it readily follows that this entropic uncertainty principle is ''stronger than the one based on standard deviations'', because\n\n:<math>\\sigma_x \\sigma_p \\ge \\frac{\\hbar}{2} \\exp\\left(H_x + H_p - \\log \\left(\\frac{e\\,h}{2\\,x_0\\,p_0}\\right)\\right) \\ge \\frac{\\hbar}{2}~.</math>\n\nIn other words, the Heisenberg uncertainty principle, is a consequence of the quantum entropic uncertainty principle, but not vice versa.  A few remarks on these inequalities. First, the choice of [[base e]] is a matter of popular convention in physics. The logarithm can alternatively be in any base, provided that it be consistent on both sides of the inequality.  Second, recall the [[Shannon entropy]] has been used, ''not'' the quantum [[von Neumann entropy]].  Finally, the normal distribution saturates the inequality, and it is the only distribution with this property, because it is the [[maximum entropy probability distribution]] among those with fixed variance (cf. [[differential entropy#Maximization in the normal distribution|here]] for proof).\n\n{| class=\"toccolours collapsible collapsed\" width=\"70%\" style=\"text-align:left\"\n!Entropic uncertainty of the normal distribution\n|-\n|We demonstrate this method on the ground state of the QHO, which as discussed above saturates the usual uncertainty based on standard deviations. The length scale can be set to whatever is convenient, so we assign\n\n:<math>x_0=\\sqrt{\\frac{\\hbar}{2m\\omega}}</math>\n:<math>\\begin{align}\\psi(x) &= \\left(\\frac{m \\omega}{\\pi \\hbar}\\right)^{1/4} \\exp{\\left( -\\frac{m \\omega x^2}{2\\hbar}\\right)} \\\\\n&= \\left(\\frac{1}{2\\pi x_0^2}\\right)^{1/4} \\exp{\\left( -\\frac{x^2}{4x_0^2}\\right)} \\end{align}</math>\n\nThe probability distribution is the normal distribution\n:<math>|\\psi(x)|^2 = \\frac{1}{x_0 \\sqrt{2\\pi}} \\exp{\\left( -\\frac{x^2}{2x_0^2}\\right)}</math>\n\nwith Shannon entropy\n:<math>\\begin{align}H_x &= - \\int |\\psi(x)|^2 \\ln (|\\psi(x)|^2 \\cdot x_0 ) \\,dx \\\\\n&= -\\frac{1}{x_0 \\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\exp{\\left( -\\frac{x^2}{2x_0^2}\\right)} \\ln \\left[\\frac{1}{\\sqrt{2\\pi}} \\exp{\\left( -\\frac{x^2}{2x_0^2}\\right)}\\right] \\, dx \\\\\n&= \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\exp{\\left( -\\frac{u^2}{2}\\right)} \\left[\\ln(\\sqrt{2\\pi}) + \\frac{u^2}{2}\\right] \\, du\\\\\n&= \\ln(\\sqrt{2\\pi}) + \\frac{1}{2}.\\end{align}</math>\n\nA completely analogous calculation proceeds for the momentum distribution. Choosing a standard momentum of <math>p_0=\\hbar/x_0</math>:\n:<math>\\varphi(p) = \\left(\\frac{2 x_0^2}{\\pi \\hbar^2}\\right)^{1/4} \\exp{\\left( -\\frac{x_0^2 p^2}{\\hbar^2}\\right)}</math>\n:<math>|\\varphi(p)|^2 = \\sqrt{\\frac{2 x_0^2}{\\pi \\hbar^2}} \\exp{\\left( -\\frac{2x_0^2 p^2}{\\hbar^2}\\right)}</math>\n:<math>\\begin{align}H_p &= - \\int |\\varphi(p)|^2 \\ln (|\\varphi(p)|^2 \\cdot \\hbar / x_0 ) \\,dp \\\\\n&= -\\sqrt{\\frac{2 x_0^2}{\\pi \\hbar^2}} \\int_{-\\infty}^\\infty \\exp{\\left( -\\frac{2x_0^2 p^2}{\\hbar^2}\\right)} \\ln \\left[\\sqrt{\\frac{2}{\\pi}} \\exp{\\left( -\\frac{2x_0^2 p^2}{\\hbar^2}\\right)}\\right] \\, dp \\\\\n&= \\sqrt{\\frac{2}{\\pi}} \\int_{-\\infty}^\\infty \\exp{\\left( -2v^2\\right)} \\left[\\ln\\left(\\sqrt{\\frac{\\pi}{2}}\\right) + 2v^2 \\right] \\, dv \\\\\n&= \\ln\\left(\\sqrt{\\frac{\\pi}{2}}\\right) + \\frac{1}{2}.\\end{align}</math>\n\nThe entropic uncertainty is therefore the limiting value\n\n:<math>\\begin{align}H_x+H_p &= \\ln(\\sqrt{2\\pi}) + \\frac{1}{2} + \\ln\\left(\\sqrt{\\frac{\\pi}{2}}\\right) + \\frac{1}{2}\\\\\n&= 1 + \\ln \\pi = \\ln(e\\pi).\\end{align}</math>\n|}\n\nA measurement apparatus will have a finite resolution set by the discretization of its possible outputs into bins, with the probability of lying within one of the bins given by the Born rule. We will consider the most common experimental situation, in which the bins are of uniform size. Let ''δx'' be a measure of the spatial resolution. We take the zeroth bin to be centered near the origin, with possibly some small constant offset ''c''. The probability of lying within the jth interval of width ''δx'' is\n\n:<math>\\operatorname P[x_j]= \\int_{(j-1/2)\\delta x-c}^{(j+1/2)\\delta x-c}| \\psi(x)|^2 \\, dx</math>\n\nTo account for this discretization, we can define the Shannon entropy of the wave function for a given measurement apparatus as\n\n: <math>H_x=-\\sum_{j=-\\infty}^\\infty \\operatorname P[x_j] \\ln \\operatorname P[x_j].</math>\n\nUnder the above definition, the entropic uncertainty relation is\n\n:<math>H_x+H_p>\\ln\\left(\\frac{e}{2}\\right)-\\ln\\left(\\frac{\\delta x \\delta p}{h} \\right).</math>\n\nHere we note that {{math|''δx''&nbsp;''δp''/''h''}} is a typical infinitesimal phase space volume used in the calculation of a [[partition function (statistical mechanics)|partition function]]. The inequality is also strict and not saturated. Efforts to improve this bound are an active area of research.\n\n{| class=\"toccolours collapsible collapsed\" width=\"70%\" style=\"text-align:left\"\n!Normal distribution example\n|-\n|We demonstrate this method first on the ground state of the QHO, which as discussed above saturates the usual uncertainty based on standard deviations.\n:<math>\\psi(x)=\\left(\\frac{m \\omega}{\\pi \\hbar}\\right)^{1/4} \\exp{\\left( -\\frac{m \\omega x^2}{2\\hbar}\\right)}</math>\n\nThe probability of lying within one of these bins can be expressed in terms of the [[error function]].\n\n:<math>\\begin{align}\\operatorname P[x_j] &= \\sqrt{\\frac{m \\omega}{\\pi \\hbar}} \\int_{(j-1/2)\\delta x}^{(j+1/2)\\delta x} \\exp\\left( -\\frac{m \\omega x^2}{\\hbar}\\right) \\, dx \\\\\n&= \\sqrt{\\frac{1}{\\pi}} \\int_{(j-1/2)\\delta x\\sqrt{m \\omega / \\hbar}}^{(j+1/2)\\delta x\\sqrt{m \\omega / \\hbar}} e^{u^2} \\, du \\\\\n&= \\frac{1}{2} \\left[ \\operatorname{erf} \\left( \\left(j+\\frac{1}{2}\\right)\\delta x \\cdot \\sqrt{\\frac{m \\omega}{\\hbar}}\\right)- \\operatorname {erf} \\left( \\left(j-\\frac{1}{2}\\right)\\delta x \\cdot \\sqrt{\\frac{m \\omega}{\\hbar}}\\right) \\right]\\end{align}</math>\n\nThe momentum probabilities are completely analogous.\n\n:<math>\\operatorname P[p_j] = \\frac{1}{2} \\left[ \\operatorname{erf} \\left( \\left(j+\\frac{1}{2}\\right)\\delta p \\cdot \\frac{1}{\\sqrt{\\hbar m \\omega}}\\right)- \\operatorname{erf} \\left( \\left(j-\\frac{1}{2}\\right)\\delta x \\cdot \\frac{1}{\\sqrt{\\hbar m \\omega}}\\right) \\right]</math>\n\nFor simplicity, we will set the resolutions to\n\n:<math>\\delta x = \\sqrt{\\frac{h}{m \\omega}}</math>\n:<math>\\delta p = \\sqrt{h m \\omega}</math>\n\nso that the probabilities reduce to\n\n:<math>\\operatorname P[x_j] = \\operatorname P[p_j] = \\frac{1}{2} \\left[ \\operatorname {erf} \\left( \\left(j+\\frac{1}{2}\\right) \\sqrt{2\\pi} \\right)- \\operatorname {erf} \\left( \\left(j-\\frac{1}{2}\\right) \\sqrt{2\\pi} \\right) \\right]</math>\n\nThe Shannon entropy can be evaluated numerically.\n:<math>\\begin{align}H_x = H_p &= -\\sum_{j=-\\infty}^\\infty \\operatorname P[x_j] \\ln \\operatorname P[x_j] \\\\\n&= -\\sum_{j=-\\infty}^\\infty \\frac{1}{2} \\left[ \\operatorname {erf} \\left( \\left(j+\\frac{1}{2}\\right) \\sqrt{2\\pi} \\right)- \\operatorname {erf} \\left( \\left(j-\\frac{1}{2}\\right) \\sqrt{2\\pi} \\right) \\right] \\ln \\frac{1}{2} \\left[ \\operatorname {erf} \\left( \\left(j+\\frac{1}{2}\\right) \\sqrt{2\\pi} \\right)- \\operatorname {erf} \\left( \\left(j-\\frac{1}{2}\\right) \\sqrt{2\\pi} \\right) \\right]\n&\\approx 0.3226\\end{align}</math>\n\nThe entropic uncertainty is indeed larger than the limiting value.\n:<math>H_x+H_p \\approx 0.3226 + 0.3226 = 0.6452 >\\ln\\left(\\frac{e}{2}\\right)-\\ln 1 \\approx 0.3069</math>\n\nNote that despite being in the optimal case, the inequality is not saturated.\n|}\n\n{| class=\"toccolours collapsible collapsed\" width=\"70%\" style=\"text-align:left\"\n!Sinc function example\n|-\n|An example of a unimodal distribution with infinite variance is the [[sinc function]]. If the wave function is the correctly normalized uniform distribution,\n:<math>\n\\psi(x)=\\begin{cases}\n\\frac{1}{\\sqrt{2a}} & \\text{for } |x| \\le a, \\\\[8pt]\n0 & \\text{for } |x|>a\n\\end{cases}\n</math>\nthen its Fourier transform is the sinc function,\n:<math>\\varphi(p)=\\sqrt{\\frac{a}{\\pi \\hbar}} \\cdot \\operatorname{sinc}\\left(\\frac{a p}{\\hbar}\\right)</math>\nwhich yields infinite momentum variance despite having a centralized shape. The entropic uncertainty, on the other hand, is finite. Suppose for simplicity that the spatial resolution is just a two-bin measurement, ''δx''&nbsp;=&nbsp;''a'', and that the momentum resolution is ''δp''&nbsp;=&nbsp;''h''/''a''.\n\nPartitioning the uniform spatial distribution into two equal bins is straightforward. We set the offset ''c''&nbsp;=&nbsp;1/2 so that the two bins span the distribution.\n:<math>\\operatorname P[x_0] = \\int_{-a}^0 \\frac{1}{2a} \\, dx = \\frac{1}{2}</math>\n:<math>\\operatorname P[x_1] = \\int_0^a \\frac{1}{2a} \\, dx = \\frac{1}{2}</math>\n:<math>H_x = -\\sum_{j=0}^{1} \\operatorname P[x_j] \\ln \\operatorname P[x_j] = -\\frac{1}{2} \\ln \\frac{1}{2} - \\frac{1}{2} \\ln \\frac{1}{2} = \\ln 2</math>\n\nThe bins for momentum must cover the entire real line. As done with the spatial distribution, we could apply an offset. It turns out, however, that the Shannon entropy is minimized when the zeroth bin for momentum is centered at the origin. (The reader is encouraged to try adding an offset.) The probability of lying within an arbitrary momentum bin can be expressed in terms of the [[sine integral]].\n\n:<math>\\begin{align}\\operatorname P[p_j] &= \\frac{a}{\\pi \\hbar} \\int_{(j-1/2)\\delta p}^{(j+1/2)\\delta p} \\operatorname{sinc}^2\\left(\\frac{a p}{\\hbar}\\right) \\, dp \\\\\n&= \\frac{1}{\\pi} \\int_{2\\pi (j-1/2)}^{2\\pi (j+1/2)} \\operatorname{sinc}^2(u) \\, du \\\\\n&= \\frac{1}{\\pi} \\left[ \\operatorname {Si} ((4j+2)\\pi)- \\operatorname {Si} ((4j-2)\\pi) \\right]\\end{align}</math>\n\nThe Shannon entropy can be evaluated numerically.\n:<math>H_p = -\\sum_{j=-\\infty}^\\infty \\operatorname P[p_j] \\ln \\operatorname P[p_j] = -\\operatorname P[p_0] \\ln \\operatorname P[p_0]-2 \\cdot \\sum_{j=1}^{\\infty} \\operatorname P[p_j] \\ln \\operatorname P[p_j] \\approx 0.53</math>\n\nThe entropic uncertainty is indeed larger than the limiting value.\n:<math>H_x+H_p \\approx 0.69 + 0.53 = 1.22 >\\ln\\left(\\frac{e}{2}\\right)-\\ln 1 \\approx 0.31</math>\n|}\n\n==Harmonic analysis==\n{{main article|Fourier transform#Uncertainty principle}}\nIn the context of [[harmonic analysis]], a branch of mathematics, the uncertainty principle implies that one cannot at the same time localize the value of a function and its [[Fourier transform]]. To wit, the following inequality holds,\n:<math>\\left(\\int_{-\\infty}^\\infty x^2 |f(x)|^2\\,dx\\right)\\left(\\int_{-\\infty}^\\infty \\xi^2 |\\hat{f}(\\xi)|^2\\,d\\xi\\right)\\ge \\frac{\\|f\\|_2^4}{16\\pi^2}.</math>\n\nFurther mathematical uncertainty inequalities, including the above [[entropic uncertainty]], hold between a function {{mvar|f}} and its Fourier transform {{math| ƒ̂}}:<ref>{{Citation|first1=V.|last1=Havin|first2= B.|last2=Jöricke|title=The Uncertainty Principle in Harmonic Analysis|publisher=Springer-Verlag|year=1994}}</ref><ref>{{Citation\n| last1 = Folland\n| first1 = Gerald\n| last2 = Sitaram |first2 = Alladi\n| title = The Uncertainty Principle: A Mathematical Survey\n| journal = Journal of Fourier Analysis and Applications\n|date=May 1997\n| volume = 3\n| issue = 3\n| pages = 207–238\n| doi = 10.1007/BF02649110\n| mr=1448337\n}}</ref><ref>{{springer|title=Uncertainty principle, mathematical|id=U/u130020|first=A|last=Sitaram|year=2001}}</ref>\n\n:<math>H_x+H_\\xi \\ge \\log(e/2)</math>\n\n===Signal processing {{anchor|Gabor limit}}===\nIn the context of [[signal processing]], and in particular [[time–frequency analysis]], uncertainty principles are referred to as the '''Gabor limit''', after [[Dennis Gabor]], or sometimes the ''Heisenberg–Gabor limit''. The basic result, which follows from \"Benedicks's theorem\", below, is that a function cannot be both [[time limited]] and [[band limited]] (a function and its Fourier transform cannot both have bounded domain)—see [[Bandlimiting#Bandlimited versus timelimited|bandlimited versus timelimited]]. Thus\n\n: <math>\\sigma_t \\cdot \\sigma_f \\ge \\frac{1}{4\\pi} \\approx 0.08 \\text{ cycles}</math>\n\nwhere <math>\\sigma_t</math> and <math>\\sigma_f</math> are the standard deviations of the time and frequency estimates respectively <ref>Matt Hall, [https://agilescientific.com/blog/2014/1/15/what-is-the-gabor-uncertainty-principle.html \"What is the Gabor uncertainty principle?\"]</ref>.\n\nStated alternatively, \"One cannot simultaneously sharply localize a signal (function {{mvar|f}} ) in both the [[time domain]] and [[frequency domain]] ({{math| ƒ̂}}, its Fourier transform)\".\n\nWhen applied to filters, the result implies that one cannot achieve high temporal resolution and frequency resolution at the same time; a concrete example are the [[Short-time Fourier transform#Resolution issues|resolution issues of the short-time Fourier transform]]—if one uses a wide window, one achieves good frequency resolution at the cost of temporal resolution, while a narrow window has the opposite trade-off.\n\nAlternate theorems give more precise quantitative results, and, in time–frequency analysis, rather than interpreting the (1-dimensional) time and frequency domains separately, one instead interprets the limit as a lower limit on the support of a function in the (2-dimensional) time–frequency plane. In practice, the Gabor limit limits the ''simultaneous'' time–frequency resolution one can achieve without interference; it is possible to achieve higher resolution, but at the cost of different components of the signal interfering with each other.\n\n===DFT-Uncertainty principle===\nThere is an uncertainty principle that uses signal sparsity (or the number of non-zero coefficients).<ref name=\"Donoho\">{{cite journal |last1=Donoho |first1=D.L. |last2=Stark |first2=P.B |year=1989 |title=Uncertainty principles and signal recovery |journal=SIAM Journal on Applied Mathematics |volume=49 |issue=3 |pages=906–931 |doi=10.1137/0149053}}</ref>\n\nLet <math>\\left \\{ \\mathbf{ x_n } \\right \\} := x_0, x_1, \\ldots, x_{N-1}</math> be a sequence of ''N'' complex numbers and <math>\\left \\{ \\mathbf{X_k} \\right \\} := X_0, X_1, \\ldots, X_{N-1},</math> its [[discrete Fourier transform]].\n\nDenote by <math>\\|x\\|_0</math> the number of non-zero elements in the time sequence <math>x_0,x_1,\\ldots,x_{N-1}</math> and by <math>\\|X\\|_0</math> the number of non-zero elements in the frequency sequence <math>X_0,X_1,\\ldots,X_{N-1}</math>. Then, \n:<math>N\\leq \\|x\\|_0 \\cdot \\|X\\|_0.</math>\n\n===Benedicks's theorem===\nAmrein–Berthier<ref>{{Citation\n| last1 = Amrein | first1 = W.O.\n| last2 = Berthier | first2 = A.M.\n| year = 1977\n| title = On support properties of ''L''<sup>''p''</sup>-functions and their Fourier transforms\n| journal = Journal of Functional Analysis\n| volume = 24 | issue = 3 | pages = 258–267\n| doi = 10.1016/0022-1236(77)90056-8\n| ref = harv\n| postscript = .\n}}</ref> and Benedicks's theorem<ref>{{Citation|first=M.|last=Benedicks|authorlink=Michael Benedicks|title=On Fourier transforms of functions supported on sets of finite Lebesgue measure|journal=J. Math. Anal. Appl.|volume=106|year=1985|issue=1|pages=180–183|doi=10.1016/0022-247X(85)90140-4}}</ref> intuitively says that the set of points where {{mvar|f}} is non-zero and the set of points where {{math| ƒ̂}} is non-zero cannot both be small.\n\nSpecifically, it is impossible for a function {{mvar|f}} in {{math|''L''<sup>2</sup>('''R''')}} and its Fourier transform {{math| ƒ̂}} to both be [[support of a function|supported]] on sets of finite [[Lebesgue measure]]. A more quantitative version is<ref>{{Citation|first=F.|last=Nazarov|authorlink=Fedor Nazarov|title=Local estimates for exponential polynomials and their applications to inequalities of the uncertainty principle type,|journal=St. Petersburg Math. J.|volume=5|year=1994|pages=663–717}}</ref><ref>{{Citation|first=Ph.|last=Jaming|title=Nazarov's uncertainty principles in higher dimension|journal= J. Approx. Theory|volume=149|year=2007|issue=1|pages=30–41|doi=10.1016/j.jat.2007.04.005|arxiv=math/0612367}}</ref>\n: <math>\\|f\\|_{L^2(\\mathbf{R}^d)}\\leq Ce^{C|S||\\Sigma|} \\bigl(\\|f\\|_{L^2(S^c)} + \\| \\hat{f} \\|_{L^2(\\Sigma^c)} \\bigr) ~.</math>\n\nOne expects that the factor {{math|''Ce<sup>C{{!}}S{{!}}{{!}}Σ{{!}}</sup>''}}  may be replaced by {{math|''Ce''<sup>''C''({{!}}''S''{{!}}{{!}}''Σ''{{!}})<sup>1/''d''</sup></sup>}},   \nwhich is only known if either {{mvar|S}} or {{mvar|Σ}} is convex.\n\n===Hardy's uncertainty principle===\nThe mathematician [[G. H. Hardy]] formulated the following uncertainty principle:<ref>{{Citation|first=G.H.|last=Hardy|authorlink=G. H. Hardy|title=A theorem concerning Fourier transforms|journal=Journal of the London Mathematical Society|volume=8|year=1933|issue=3|pages=227–231|doi=10.1112/jlms/s1-8.3.227}}</ref> it is not possible for {{mvar|f}} and {{math| ƒ̂}} to both be \"very rapidly decreasing\". Specifically, if {{mvar|f}} in <math>L^2(\\mathbb{R})</math> is such that\n:<math>|f(x)|\\leq C(1+|x|)^Ne^{-a\\pi x^2}</math>\nand\n:<math>|\\hat{f}(\\xi)|\\leq C(1+|\\xi|)^Ne^{-b\\pi \\xi^2}</math> (<math>C>0,N</math> an integer),\n\nthen, if {{math|1=''ab'' > 1, ''f'' = 0}}, while if {{math|1=''ab'' = 1}}, then there is a polynomial {{mvar|P}} of degree {{math| ≤ ''N''}} such that\n\n::<math>f(x)=P(x)e^{-a\\pi x^2}. </math>\n\nThis was later improved as follows: if <math>f \\in L^2(\\mathbb{R}^d)</math> is such that\n\n:<math>\\int_{\\mathbb{R}^d}\\int_{\\mathbb{R}^d}|f(x)||\\hat{f}(\\xi)|\\frac{e^{\\pi|\\langle x,\\xi\\rangle|}}{(1+|x|+|\\xi|)^N} \\, dx \\, d\\xi < +\\infty ~,</math>\nthen\n::<math>f(x)=P(x)e^{-\\pi\\langle Ax,x\\rangle} ~,</math>\nwhere {{mvar|P}} is a polynomial of degree {{math|(''N'' − ''d'')/2}} and {{mvar|A}} is a real {{math|''d''×''d''}} positive definite matrix.\n\nThis result was stated in Beurling's complete works without proof and proved in Hörmander<ref>{{Citation|first=L.|last=Hörmander|authorlink=Lars Hörmander|title=A uniqueness theorem of Beurling for Fourier transform pairs|journal= Ark. Mat.|volume=29|year=1991|pages=231–240|bibcode=1991ArM....29..237H|doi=10.1007/BF02384339}}</ref> (the case <math>d=1,N=0</math>) and Bonami, Demange, and Jaming<ref>{{Citation|first1=A.|last1=Bonami|author1-link= Aline Bonami |first2=B.|last2=Demange|first3=Ph.|last3=Jaming|title=Hermite functions and uncertainty principles for the Fourier and the windowed Fourier transforms |journal= Rev. Mat. Iberoamericana|volume=19|year=2003|pages=23–55.|bibcode=2001math......2111B|arxiv=math/0102111| doi=10.4171/RMI/337}}</ref> for the general case. Note that Hörmander–Beurling's version implies the case {{math|''ab'' > 1}} in Hardy's Theorem while the version by Bonami–Demange–Jaming covers the full strength of Hardy's Theorem. A different proof of Beurling's theorem based on Liouville's theorem appeared in\nref.<ref>{{Citation|first=H.|last=Hedenmalm|title=Heisenberg's uncertainty principle in the sense of Beurling|journal=J. Anal. Math.|volume=118|issue=2|year=2012|pages=691–702|doi=10.1007/s11854-012-0048-9|url=https://arxiv.org/pdf/1203.5222|arxiv=1203.5222}}</ref>\n\nA full description of the case {{math|''ab'' < 1}} as well as the following extension to Schwartz class distributions appears in ref.<ref>{{Citation|first=Bruno|last=Demange|title=Uncertainty Principles Associated to Non-degenerate Quadratic Forms|year=2009|publisher= Société Mathématique de France|isbn=978-2-85629-297-6}}</ref>\n\n'''Theorem.''' If a tempered distribution <math>f\\in\\mathcal{S}'(\\R^d)</math> is such that\n\n:<math>e^{\\pi|x|^2}f\\in\\mathcal{S} '(\\R^d)</math>\nand\n:<math>e^{\\pi|\\xi|^2}\\hat f\\in\\mathcal{S}'(\\R^d) ~,</math>\nthen\n::<math>f(x)=P(x)e^{-\\pi\\langle Ax,x\\rangle} ~,</math>\nfor some convenient polynomial {{mvar|P}} and real positive definite matrix {{mvar|A}} of type {{math|''d'' × ''d''}}.\n\n==History==\n[[Werner Heisenberg]] formulated the uncertainty principle at [[Niels Bohr]]'s institute in Copenhagen, while working on the mathematical foundations of quantum mechanics.<ref>\n[http://www.aip.org/history/heisenberg/p08.htm American Physical Society online exhibit on the Uncertainty Principle]</ref>\n[[File:Heisenbergbohr.jpg|thumb|Werner Heisenberg and Niels Bohr]]\nIn 1925, following pioneering work with [[Hendrik Kramers]], Heisenberg developed [[matrix mechanics]], which replaced the ad hoc [[old quantum theory]] with modern quantum mechanics. The central premise was that the classical concept of motion does not fit at the quantum level, as [[electron]]s in an atom do not travel on sharply defined orbits. Rather, their motion is smeared out in a strange way: the [[Fourier transform]] of its time dependence only involves those frequencies that could be observed in the quantum jumps of their radiation.\n\nHeisenberg's paper did not admit any unobservable quantities like the exact position of the electron in an orbit at any time; he only allowed the theorist to talk about the Fourier components of the motion. Since the Fourier components were not defined at the classical frequencies, they could not be used to construct an exact [[trajectory]], so that the formalism could not answer certain overly precise questions about where the electron was or how fast it was going.\n\nIn March 1926, working in Bohr's institute, Heisenberg realized that the non-[[commutativity]] implies the uncertainty principle. This implication provided a clear physical interpretation for the non-commutativity, and it laid the foundation for what became known as the [[Copenhagen interpretation]] of quantum mechanics. Heisenberg showed that the commutation relation implies an uncertainty, or in Bohr's language a [[complementarity (physics)|complementarity]].<ref>{{Citation |first=Niels |last=Bohr |year=1958 |title=Atomic Physics and Human Knowledge |location=New York |publisher=Wiley |page=38 |isbn= |bibcode=1958AmJPh..26..596B |volume=26 |journal=American Journal of Physics |doi=10.1119/1.1934707 |issue=8 |last2=Noll |first2=Waldemar }}</ref> Any two variables that do not commute cannot be measured simultaneously—the more precisely one is known, the less precisely the other can be known. Heisenberg wrote:<blockquote>It can be expressed in its simplest form as follows: One can never know with perfect accuracy both of those two important factors which determine the movement of one of the smallest particles—its position and its velocity. It is impossible to determine accurately ''both'' the position and the direction and speed of a particle ''at the same instant''.<ref>Heisenberg, W., ''Die Physik der Atomkerne'', Taylor & Francis, 1952, p. 30.</ref></blockquote>\n\nIn his celebrated 1927 paper, \"Über den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik\" (\"On the Perceptual Content of Quantum Theoretical Kinematics and Mechanics\"), Heisenberg established this expression as the minimum amount of unavoidable momentum disturbance caused by any position measurement,<ref name=\"Heisenberg_1927\"/> but he did not give a precise definition for the uncertainties Δx and Δp. Instead, he gave some plausible estimates in each case separately. In his Chicago lecture<ref name=\"Heisenberg_1930\">{{Citation |first=W. |last=Heisenberg |year=1930 |title=Physikalische Prinzipien der Quantentheorie  |language=de|location=Leipzig |publisher=Hirzel }} English translation ''The Physical Principles of Quantum Theory''. Chicago: University of Chicago Press, 1930.</ref> he refined his principle:\n\n{{NumBlk|::|<math>\\Delta x \\, \\Delta p\\gtrsim h</math>|1}}\n\n[[Earle Hesse Kennard|Kennard]]<ref name=\"Kennard\" /> in 1927 first proved the modern inequality:\n\n{{NumBlk|::|<math>\\sigma_x\\sigma_p\\ge\\frac{\\hbar}{2}</math>|2}}\n\nwhere {{math|''ħ'' {{=}} {{sfrac|''h''|2{{pi}}}}}}, and {{math|''σ<sub>x</sub>''}}, {{math|''σ<sub>p</sub>''}} are the standard deviations of position and momentum. Heisenberg only proved relation ({{EquationNote|2}}) for the special case of Gaussian states.<ref name=\"Heisenberg_1930\"/>\n\n===Terminology and translation===\nThroughout the main body of his original 1927 paper, written in German, Heisenberg used the word, \"Ungenauigkeit\" (\"indeterminacy\"),<ref name=\"Heisenberg_1927\" />\nto describe the basic theoretical principle. Only in the endnote did he switch to the word, \"Unsicherheit\" (\"uncertainty\"). When the English-language version of Heisenberg's textbook, ''The Physical Principles of the Quantum Theory'', was published in 1930, however, the translation \"uncertainty\" was used, and it became the more commonly used term in the English language thereafter.<ref>{{Citation |first=David |last=Cassidy |year=2009 |title=Beyond Uncertainty: Heisenberg, Quantum Physics, and the Bomb |location= New York |publisher=Bellevue Literary Press |page=185 |isbn= |bibcode=2010PhT....63a..49C |last2=Saperstein |first2=Alvin M. |volume=63 |journal=Physics Today |doi=10.1063/1.3293416 }}</ref>\n\n===Heisenberg's microscope===\n[[File:Heisenberg gamma ray microscope.svg|thumb|200px|right|Heisenberg's gamma-ray microscope for locating an electron (shown in blue). The incoming gamma ray (shown in green) is scattered by the electron up into the microscope's aperture angle ''θ''. The scattered gamma-ray is shown in red. Classical [[optics]] shows that the electron position can be resolved only up to an uncertainty Δ''x'' that depends on ''θ'' and the wavelength ''λ'' of the incoming light.]]\n{{Main article|Heisenberg's microscope}}\n\nThe principle is quite counter-intuitive, so the early students of quantum theory had to be reassured that naive measurements to violate it were bound always to be unworkable. One way in which Heisenberg originally illustrated the intrinsic impossibility of violating the uncertainty principle is by utilizing the [[observer effect (physics)|observer effect]] of  an imaginary microscope as a measuring device.<ref name=\"Heisenberg_1930\"/>\n\nHe imagines an experimenter trying to measure the position and momentum of an [[electron]] by shooting a [[photon]] at it.<ref name=GreensteinZajonc2006>{{cite book|author1=George Greenstein|author2=Arthur Zajonc|title=The Quantum Challenge: Modern Research on the Foundations of Quantum Mechanics|year=2006|publisher=Jones & Bartlett Learning|isbn=978-0-7637-2470-2}}</ref>{{rp|49–50}}\n:Problem 1 – If the photon has a short [[wavelength]], and therefore, a large momentum, the position can be measured accurately. But the photon scatters in a random direction, transferring a large and uncertain amount of momentum to the electron. If the photon has a long [[wavelength]] and low momentum, the collision does not disturb the electron's momentum very much, but the scattering will reveal its position only vaguely.\n\n:Problem 2 – If a large [[aperture]] is used for the microscope, the electron's location can be well resolved (see [[Rayleigh criterion]]); but by the principle of [[conservation of momentum]], the transverse momentum of the incoming photon affects the electron's beamline momentum and hence, the new momentum of the electron resolves poorly. If a small aperture is used, the accuracy of both resolutions is the other way around.\n\nThe combination of these trade-offs implies that no matter what photon wavelength and aperture size are used, the product of the uncertainty in measured position and measured momentum is greater than or equal to a lower limit, which is (up to a small numerical factor) equal to [[Planck's constant]].<ref>{{Citation |last=Tipler |first=Paul A. |first2=Ralph A. |last2=Llewellyn |title=Modern Physics |edition=3rd |publisher=W. H. Freeman and Co. |year=1999 |isbn=1-57259-164-1 |chapter=5–5 }}</ref> Heisenberg did not care to formulate the uncertainty principle as an exact limit (which is elaborated below), and preferred to use it instead, as a heuristic quantitative statement, correct up to small numerical factors, which makes the radically new noncommutativity of quantum mechanics inevitable.\n\n==Critical reactions==\n{{Main article|Bohr–Einstein debates}}\n\nThe Copenhagen interpretation of quantum mechanics and Heisenberg's Uncertainty Principle were, in fact, seen as twin targets by detractors who believed in an underlying [[determinism]] and [[Scientific realism|realism]]. According to the [[Copenhagen interpretation]] of quantum mechanics, there is no fundamental reality that the [[quantum state]] describes, just a prescription for calculating experimental results. There is no way to say what the state of a system fundamentally is, only what the result of observations might be.\n\n[[Albert Einstein]] believed that randomness is a reflection of our ignorance of some fundamental property of reality, while [[Niels Bohr]] believed that the probability distributions are fundamental and irreducible, and depend on which measurements we choose to perform. [[Bohr–Einstein debates|Einstein and Bohr debated]] the uncertainty principle for many years.\n\n===The ideal of the detached observer===\n[[Wolfgang Pauli]] called Einstein's fundamental objection to the uncertainty principle \"the ideal of the detached observer\" (phrase translated from the German):\n{{blockquote|\"Like the moon has a definite position\" Einstein said to me last winter, \"whether or not we look at the moon, the same must also hold for the atomic objects, as there is no sharp distinction possible between these and macroscopic objects. Observation cannot ''create'' an element of reality like a position, there must be something contained in the complete description of physical reality which corresponds to the ''possibility'' of observing a position, already before the observation has been actually made.\" I hope, that I quoted Einstein correctly; it is always difficult to quote somebody out of memory with whom one does not agree. It is precisely this kind of postulate which I call the ideal of the detached observer.\n*Letter from Pauli to Niels Bohr, February 15, 1955<ref>{{cite book|editor=Enz, Charles P.|editor2=Meyenn, Karl von|title=Writings on physics and philosophy by Wolfgang Pauli|publisher=Springer-Verlag|year=1994|page=43|postscript=; translated by Robert Schlapp|isbn=3-540-56859-X|url=https://books.google.com/books?id=ueTd4g7pc5MC&pg=PA43}}</ref>}}\n===Einstein's slit===\nThe first of Einstein's [[thought experiment]]s challenging the uncertainty principle went as follows:\n\n:Consider a particle passing through a slit of width {{mvar|d}}. The slit introduces an uncertainty in momentum of approximately {{mvar|{{sfrac|h|d}}}} because the particle passes through the wall. But let us determine the momentum of the particle by measuring the recoil of the wall. In doing so, we find the momentum of the particle to arbitrary accuracy by conservation of momentum.\n\nBohr's response was that the wall is quantum mechanical as well, and that to measure the recoil to accuracy {{math|Δ''p''}}, the momentum of the wall must be known to this accuracy before the particle passes through. This introduces an uncertainty in the position of the wall and therefore the position of the slit equal to {{math|{{sfrac|''h''|Δ''p''}}}}, and if the wall's momentum is known precisely enough to measure the recoil, the slit's position is uncertain enough to disallow a position measurement.\n\nA similar analysis with particles diffracting through multiple slits is given by [[Richard Feynman]].<ref>Feynman lectures on Physics, vol 3, 2–2</ref>\n\n===Einstein's box===\nBohr was present when Einstein proposed the thought experiment which has become known as [[Einstein's box]]. Einstein argued that \"Heisenberg's uncertainty equation implied that the uncertainty in time was related to the uncertainty in energy, the product of the two being related to [[Planck's constant]].\"<ref name=\"Gamow\">Gamow, G., ''The great physicists from Galileo to Einstein'', Courier Dover, 1988, p.260.</ref> Consider, he said, an ideal box, lined with mirrors so that it can contain light indefinitely. The box could be weighed before a clockwork mechanism opened an ideal shutter at a chosen instant to allow one single photon to escape. \"We now know, explained Einstein, precisely the time at which the photon left the box.\"<ref>Kumar, M., ''Quantum: Einstein, Bohr and the Great Debate About the Nature of Reality'', Icon, 2009, p. 282.</ref> \"Now, weigh the box again. The change of mass tells the energy of the emitted light. In this manner, said Einstein, one could measure the energy emitted and the time it was released with any desired precision, in contradiction to the uncertainty principle.\"<ref name=\"Gamow\" />\n\nBohr spent a sleepless night considering this argument, and eventually realized that it was flawed. He pointed out that if the box were to be weighed, say by a spring and a pointer on a scale, \"since the box must move vertically with a change in its weight, there will be uncertainty in its vertical velocity and therefore an uncertainty in its height above the table. ... Furthermore, the uncertainty about the elevation above the earth's surface will result in an uncertainty in the rate of the clock,\"<ref>Gamow, G., ''The great physicists from Galileo to Einstein'', Courier Dover, 1988, p. 260–261.</ref> because of Einstein's own theory of [[Gravitational time dilation|gravity's effect on time]].\n\"Through this chain of uncertainties, Bohr showed that Einstein's light box experiment could not simultaneously measure exactly both the energy of the photon and the time of its escape.\"<ref>Kumar, M., ''Quantum: Einstein, Bohr and the Great Debate About the Nature of Reality'', Icon, 2009, p. 287.</ref>\n\n===EPR paradox for entangled particles===\nBohr was compelled to modify his understanding of the uncertainty principle after another thought experiment by Einstein. In 1935, Einstein, Podolsky and Rosen (see [[EPR paradox]]) published an analysis of widely separated [[Quantum entanglement|entangled]] particles. Measuring one particle, Einstein realized, would alter the probability distribution of the other, yet here the other particle could not possibly be disturbed. This example led Bohr to revise his understanding of the principle, concluding that the uncertainty was not caused by a direct interaction.<ref>{{Citation |first=Walter |last=Isaacson |year=2007 |title=Einstein: His Life and Universe |location=New York |publisher=Simon & Schuster |page=452 |isbn=978-0-7432-6473-0 }}</ref>\n\nBut Einstein came to much more far-reaching conclusions from the same thought experiment. He believed the \"natural basic assumption\" that a complete description of reality would have to predict the results of experiments from \"locally changing deterministic quantities\" and therefore would have to include more information than the maximum possible allowed by the uncertainty principle.\n\nIn 1964, [[John Stewart Bell|John Bell]] showed that this assumption can be falsified, since it would imply a certain inequality between the probabilities of different experiments. Experimental results confirm the predictions of quantum mechanics, ruling out Einstein's basic assumption that led him to the suggestion of his ''hidden variables''. These hidden variables may be \"hidden\" because of an illusion that occurs during observations of objects that are too large or too small.  This illusion can be likened to rotating fan blades that seem to pop in and out of existence at different locations and sometimes seem to be in the same place at the same time when observed.  This same illusion manifests itself in the observation of subatomic particles.  Both the fan blades and the subatomic particles are moving so fast that the illusion is seen by the observer.  Therefore, it is possible that there would be predictability of the subatomic particles behavior and characteristics to a recording device capable of very high speed tracking....Ironically this fact is one of the best pieces of evidence supporting [[Karl Popper]]'s philosophy of [[Falsifiability|invalidation of a theory by falsification-experiments]]. That is to say, here Einstein's \"basic assumption\" became falsified by [[Bell test experiments|experiments based on Bell's inequalities]]. For the objections of Karl Popper to the Heisenberg inequality itself, see below.\n\nWhile it is possible to assume that quantum mechanical predictions are due to nonlocal, hidden variables, and in fact [[David Bohm]] invented such a formulation, this resolution is not satisfactory to the vast majority of physicists. The question of whether a random outcome is predetermined by a nonlocal theory can be philosophical, and it can be potentially intractable. If the hidden variables are not constrained, they could just be a list of random digits that are used to produce the measurement outcomes. To make it sensible, the assumption of nonlocal hidden variables is sometimes augmented by a second assumption—that the [[size of the observable universe]] puts a limit on the computations that these variables can do. A nonlocal theory of this sort predicts that a [[quantum computer]] would encounter fundamental obstacles when attempting to factor numbers of approximately 10,000 digits or more; a potentially [[Shor's algorithm|achievable task]] in quantum mechanics.<ref>[[Gerardus 't Hooft]] has at times advocated this point of view.</ref>{{full citation needed|date=February 2017}}\n\n=== Popper's criticism ===\n{{main article|Popper's experiment}}\n[[Karl Popper]] approached the problem of indeterminacy as a logician and [[Philosophical realism|metaphysical realist]].<ref name=\"Popper1959\">{{Citation | last1 = Popper | first1 = Karl | authorlink1 = Karl Popper | title = [[The Logic of Scientific Discovery]] | publisher = Hutchinson & Co. | year = 1959}}</ref> He disagreed with the application of the uncertainty relations to individual particles rather than to [[Quantum ensemble|ensembles]] of identically prepared particles, referring to them as \"statistical scatter relations\".<ref name=\"Popper1959\" /><ref name=\"Jarvie2006\">{{Citation | last1 = Jarvie | first1 = Ian Charles | last2 = Milford | first2 = Karl | last3 = Miller | first3 = David W | title = Karl Popper: a centenary assessment, | volume = 3 | publisher = Ashgate Publishing | year = 2006 | isbn = 978-0-7546-5712-5}}</ref> In this statistical interpretation, a ''particular'' measurement may be made to arbitrary precision without invalidating the quantum theory. This directly contrasts with the [[Copenhagen interpretation]] of quantum mechanics, which is [[Determinism|non-deterministic]] but lacks local hidden variables.\n\nIn 1934, Popper published ''Zur Kritik der Ungenauigkeitsrelationen'' (''Critique of the Uncertainty Relations'') in ''[[Naturwissenschaften]]'',<ref name=\"Popper1934\">{{Citation | title = Zur Kritik der Ungenauigkeitsrelationen (Critique of the Uncertainty Relations) | journal = Naturwissenschaften | year = 1934 | first = Karl | last = Popper | author2 = Carl Friedrich von Weizsäcker | volume = 22 | issue = 48 | pages = 807–808 | doi=10.1007/BF01496543|bibcode = 1934NW.....22..807P | postscript = . }}</ref> and in the same year ''[[The Logic of Scientific Discovery|Logik der Forschung]]'' (translated and updated by the author as ''The Logic of Scientific Discovery'' in 1959), outlining his arguments for the statistical interpretation. In 1982, he further developed his theory in ''Quantum theory and the schism in Physics'', writing:\n<blockquote>[Heisenberg's] formulae are, beyond all doubt, derivable ''statistical formulae'' of the quantum theory. But they have been ''habitually misinterpreted'' by those quantum theorists who said that these formulae can be interpreted as determining some upper limit to the ''precision of our measurements''. [original emphasis]<ref>Popper, K. ''Quantum theory and the schism in Physics'', Unwin Hyman Ltd, 1982, pp. 53–54.</ref></blockquote>\n\nPopper proposed an experiment to [[Falsifiability|falsify]] the uncertainty relations, although he later withdrew his initial version after discussions with [[Carl Friedrich von Weizsäcker|Weizsäcker]], [[Werner Heisenberg|Heisenberg]], and [[Albert Einstein|Einstein]]; this experiment may have influenced the formulation of the [[EPR paradox|EPR experiment]].<ref name=\"Popper1959\" /><ref name=\"Mehra2001\">{{Citation | last1 = Mehra | first1 = Jagdish | last2 = Rechenberg | first2 = Helmut | title = The Historical Development of Quantum Theory | publisher = Springer | year = 2001 | isbn = 978-0-387-95086-0}}</ref>\n\n=== Many-worlds uncertainty ===\n{{main article|Many-worlds interpretation}}\n\nThe [[many-worlds interpretation]] originally outlined by [[Hugh Everett III]] in 1957 is partly meant to reconcile the differences between Einstein's and Bohr's views by replacing Bohr's [[wave function collapse]] with an ensemble of deterministic and independent universes whose ''distribution'' is governed by [[wave function]]s and the [[Schrödinger equation]]. Thus, uncertainty in the many-worlds interpretation follows from each observer within any universe having no knowledge of what goes on in the other universes.\n\n=== Free will ===\n\nSome scientists including [[Arthur Compton]]<ref>{{Cite journal | doi = 10.1126/science.74.1911.172| title = The Uncertainty Principle and Free Will| journal = Science| volume = 74| issue = 1911| pages = 172| year = 1931| last1 = Compton | first1 = A. H. | pmid=17808216|bibcode = 1931Sci....74..172C }}</ref> and [[Martin Heisenberg]]<ref>{{Cite journal | doi = 10.1038/459164a| title = Is free will an illusion?| journal = Nature| volume = 459| issue = 7244| pages = 164–165| year = 2009| last1 = Heisenberg | first1 = M. |bibcode = 2009Natur.459..164H }}</ref> have suggested that the uncertainty principle, or at least the general probabilistic nature of quantum mechanics, could be evidence for the two-stage model of free will. One critique, however, is that apart from the basic role of quantum mechanics as a foundation for chemistry, [[Quantum biology|nontrivial biological mechanisms requiring quantum mechanics]] are unlikely, due to the rapid [[decoherence]] time of quantum systems at room temperature.<ref name=\"ReferenceA\">{{Cite journal | doi = 10.1016/j.biosystems.2004.07.001| pmid = 15555759| title = Does quantum mechanics play a non-trivial role in life?| journal = Biosystems| volume = 78| issue = 1–3| pages = 69–79| year = 2004| last1 = Davies | first1 = P. C. W. }}</ref> The standard view, however, is that this decoherence is  overcome by both screening and decoherence-free subspaces found in biological cells.<ref name=\"ReferenceA\"/>\n\n==The second law of thermodynamics==\n\nThere is reason to believe that violating the uncertainty principle also strongly implies the violation of the [[second law of thermodynamics]].<ref>E. Hanggi, S. Wehner, A violation of the uncertainty principle also implies the violation of the second law of thermodynamics; 2012, arXiv:1205.6894v1 (quant-phy).</ref>\n\n==See also==\n{{Div col|colwidth=20em}}\n* [[Afshar experiment]]\n* [[Canonical commutation relation]]\n* [[Correspondence principle]]\n* [[Correspondence rules]]\n* [[Gromov's non-squeezing theorem]]\n* [[Discrete Fourier transform#Uncertainty principle]]\n* [[Einstein's thought experiments]]\n* [[Heisenbug]]\n* [[Introduction to quantum mechanics]]\n* [[Operationalization]]\n* [[Observer effect (information technology)]]\n* [[Observer effect (physics)]]\n* [[Quantum indeterminacy]]\n* [[Quantum non-equilibrium]]\n* [[Quantum tunnelling]]\n* ''[[Physics and Beyond]]'' (book)\n* [[Stronger uncertainty relations]]\n* [[Weak measurement]]\n{{div col end}}\n\n==Notes==\n{{reflist|group=note}}\n\n==References==\n{{Reflist|30em}}\n\n==External links==\n{{wikiquote}}\n* {{springer|title=Uncertainty principle|id=p/u095100}}\n* [http://www.lightandmatter.com/html_books/6mr/ch04/ch04.html Matter as a Wave] – a chapter from an online textbook\n* [https://arxiv.org/abs/quant-ph/0609163 Quantum mechanics: Myths and facts]\n* [http://plato.stanford.edu/entries/qt-uncertainty/ Stanford Encyclopedia of Philosophy entry]\n* [http://www.mathpages.com/home/kmath488/kmath488.htm Fourier Transforms and Uncertainty] at MathPages\n* [http://www.aip.org/history/heisenberg/p08.htm aip.org: Quantum mechanics 1925–1927 – The uncertainty principle]\n* [http://scienceworld.wolfram.com/physics/UncertaintyPrinciple.html Eric Weisstein's World of Physics – Uncertainty principle]\n* [http://math.ucr.edu/home/baez/uncertainty.html John Baez on the time–energy uncertainty relation]\n* [http://daarb.narod.ru/tcpr-eng.html The certainty principle]\n* [https://www.scientificamerican.com/article/common-interpretation-of-heisenbergs-uncertainty-principle-is-proven-false/ Common Interpretation of Heisenberg's Uncertainty Principle Is Proved False]\n\n{{Quantum mechanics topics}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Uncertainty Principle}}\n[[Category:Quantum mechanics]]\n[[Category:Principles]]\n[[Category:Mathematical physics]]\n[[Category:Inequalities]]\n[[Category:Werner Heisenberg]]\n[[Category:Scientific laws]]\n[[Category:1927 in science]]\n[[Category:1927 in Germany]]"
    },
    {
      "title": "Van der Corput inequality",
      "url": "https://en.wikipedia.org/wiki/Van_der_Corput_inequality",
      "text": "In [[mathematics]], the '''van der Corput inequality''' is a [[corollary]] of the [[Cauchy–Schwarz inequality]] that is useful in the study of [[correlation]]s among vectors, and hence [[random variable]]s.  It is also useful in the study of [[equidistributed sequence]]s, for example in the [[Weyl equidistribution estimate]].  Loosely stated, the van der Corput inequality asserts that if a [[unit vector]] <math>v</math> in an [[inner product space]] <math>V</math> is strongly correlated with many unit vectors <math>u_{1}, \\dots, u_{n} \\in V</math>, then many of the pairs <math>u_{i}, u_{j}</math> must be strongly correlated with each other.  Here, the notion of correlation is made precise by the [[inner product]] of the space <math>V</math>:  when the [[absolute value]] of <math>\\langle u, v \\rangle</math> is close to <math>1</math>, then <math>u</math> and <math>v</math> are considered to be strongly correlated.  (More generally, if the vectors involved are not unit vectors, then strong correlation means that <math>| \\langle u, v \\rangle | \\approx \\| u \\| \\| v \\|</math>.)\n\n==Statement of the inequality==\n\nLet <math>V</math> be a real or complex inner product space with inner product <math>\\langle \\cdot , \\cdot \\rangle</math> and induced [[norm (mathematics)|norm]] <math>\\| \\cdot \\|</math>.  Suppose that <math>v, u_1, \\dots, u_n \\in V</math> and that <math>\\| v \\| = 1</math>.  Then\n:<math>\\displaystyle \\left( \\sum_{i = 1}^{n} | \\langle v, u_{i} \\rangle | \\right)^{2} \\leq \\sum_{i, j = 1}^{n} | \\langle u_{i}, u_{j} \\rangle | .</math>\n\nIn terms of the correlation heuristic mentioned above, if <math>v</math> is strongly correlated with many unit vectors <math>u_1, \\dots, u_n \\in V</math>, then the left-hand side of the inequality will be large, which then forces a significant proportion of the vectors <math>u_{i}</math> to be strongly correlated with one another.\n\n===Proof of the inequality===\n\n:<math>\\left| \\sum_{i = 1}^{n} \\langle v, u_{i} \\rangle \\right|^{2}</math>\n:<math>= \\left| \\left\\langle v, \\sum_{i = 1}^{n} u_{i} \\right\\rangle \\right|^{2}</math> since the inner product is [[bilinear map|bilinear]]\n:<math>\\leq \\| v \\|^{2} \\left\\| \\sum_{i = 1}^{n} u_{i} \\right\\|^{2}</math> by the [[Cauchy–Schwarz inequality]]\n:<math>= \\| v \\|^{2} \\left\\langle \\sum_{i = 1}^{n} u_{i}, \\sum_{j = 1}^{n} u_{j} \\right\\rangle</math> by the definition of the induced norm\n:<math>= 1 \\cdot \\sum_{i, j = 1}^{n} \\langle u_{i}, u_{j} \\rangle</math> since <math>v</math> is a unit vector, and the inner product is bilinear\n:<math>= \\sum_{i, j = 1}^{n} | \\langle u_{i}, u_{j} \\rangle | .</math>\n\n==External links==\n\n* A blog post by [[Terence Tao]] on correlation transitivity, including the van der Corput inequality [https://terrytao.wordpress.com/2014/06/05/when-is-correlation-transitive/]\n\n[[Category:Inequalities]]\n[[Category:Diophantine approximation]]"
    },
    {
      "title": "Van der Corput lemma (harmonic analysis)",
      "url": "https://en.wikipedia.org/wiki/Van_der_Corput_lemma_%28harmonic_analysis%29",
      "text": "In [[mathematics]], in the field of [[harmonic analysis]],\nthe '''van der Corput lemma''' is an estimate for [[oscillatory integral]]s\nnamed after the [[Netherlands|Dutch]] mathematician [[Johannes van der Corput|J. G. van der Corput]].\n\nThe following result\nis stated by [[Elias M. Stein|E. Stein]]:<ref>Elias Stein, ''Harmonic Analysis: Real-variable Methods, Orthogonality and Oscillatory Integrals''. Princeton University Press, 1993. {{ISBN|0-691-03216-5}}</ref>\n\nSuppose that a real-valued function <math>\\phi(x)</math> is smooth in an open interval <math>(a,b)</math>,\nand that <math>|\\phi^{(k)}(x)|\\ge 1</math> for all <math>x\\in (a,b)</math>.\nAssume that either <math>k\\ge 2</math>, or that\n<math>k=1</math> and <math>\\phi'(x)</math> is monotone for <math>x\\in\\R</math>.\nThere is a constant <math>c_k</math>, which does not depend on <math>\\phi</math>,\nsuch that\n:<math>\n\\Big|\\int_a^b e^{i\\lambda\\phi(x)}\\Big|\\le c_k\\lambda^{-1/k},\n</math>\n\nfor any <math>\\lambda\\in\\R</math>.\n\n==Sublevel set estimates==\n\nThe van der Corput lemma is closely related to the [[sublevel set]] estimates\n(see for example\n<ref>M. Christ, ''Hilbert transforms along curves'', Ann. of Math. '''122''' (1985), 575--596</ref>),\nwhich give the upper bound on the [[Measure (mathematics)|measure]] of the set\nwhere a function takes values not larger than <math>\\epsilon</math>.\n\nSuppose that a real-valued function <math>\\phi(x)</math> is smooth\non a finite or infinite interval <math>I\\subset\\R</math>,\nand that <math>|\\phi^{(k)}(x)|\\ge 1</math> for all <math>x\\in I</math>.\nThere is a constant <math>c_k</math>, which does not depend on <math>\\phi</math>,\nsuch that\nfor any <math>\\epsilon\\ge 0</math>\nthe measure of the sublevel set\n<math>\\{x\\in I:|\\phi(x)|\\le\\epsilon\\}</math>\nis bounded by <math>c_k\\epsilon^{1/k}</math>.\n\n==References==\n<references />\n\n[[Category:Inequalities]]\n[[Category:Harmonic analysis]]\n[[Category:Fourier analysis]]"
    },
    {
      "title": "Von Neumann's inequality",
      "url": "https://en.wikipedia.org/wiki/Von_Neumann%27s_inequality",
      "text": "In [[operator theory]], '''von Neumann's inequality''', due to [[John von Neumann]], states that, for a fixed contraction ''T'', the [[polynomial functional calculus]] map is itself a contraction.\n\n==Formal statement==\nFor a [[Contraction (operator theory)|contraction]] ''T'' acting on a [[Hilbert space]] and a polynomial ''p'', then the norm of ''p''(''T'') is bounded by the [[supremum]] of |''p''(''z'')| for ''z'' in the [[unit disk]].\"<ref>{{Cite web |url=http://www.math.vanderbilt.edu/~colloq/ |title=Department of Mathematics, Vanderbilt University Colloquium, AY 2007-2008 |access-date=2008-03-11 |archive-url=https://web.archive.org/web/20080316073544/http://www.math.vanderbilt.edu/~colloq/ |archive-date=2008-03-16 |dead-url=yes |df= }}</ref> \n\n==Proof==\nThe inequality can be proved by considering the [[unitary dilation]] of ''T'', for which the inequality is obvious.\n\n==Generalizations==\nThis inequality is a specific case of Matsaev's conjecture. That is that for any polynomial ''P'' and contraction ''T'' on <math>L^p</math>\n\n:<math>||P(T)||_{L^p} \\le ||P(S)||_{\\ell^p}</math>\n\nwhere ''S'' is the right-shift operator. The von Neumann inequality proves it true for <math>p=2</math> and for <math>p=1</math> and <math>p=\\infty</math> it is true by straightforward calculation. \nS.W.&nbsp;Drury has shown in 2011 that the conjecture fails in the general case.<ref>[http://www.sciencedirect.com/science/article/pii/S0024379511000589 S.W. Drury, \"A counterexample to a conjecture of Matsaev\",  Linear Algebra and its Applications, Volume 435, Issue 2, 15 July 2011, Pages 323-329 ]</ref>\n\n==References==\n<references/>\n\n[[Category:Operator theory]]\n[[Category:Inequalities]]\n[[Category:John von Neumann]]"
    },
    {
      "title": "Weierstrass product inequality",
      "url": "https://en.wikipedia.org/wiki/Weierstrass_product_inequality",
      "text": "In [[mathematics]], the '''Weierstrass product inequality''' states that,\n\nFor given real numbers 0&nbsp;≤&nbsp;''a<sub>1</sub>'', ''a<sub>2</sub>'', ''a<sub>3</sub>'', ''a<sub>4</sub>, ..., a<sub>n</sub>'' ≤ 1\n\n:<math>(1-a_1)(1-a_2)(1-a_3)(1-a_4)....(1-a_n) \\geq 1-S_n. </math>\n:<math>(1+a_1)(1+a_2)(1+a_3)(1+a_4)....(1+a_n) \\geq 1+S_n.</math>\nWhere,<math>S_n=a_1+a_2+a_3+a_4+....+a_n.</math>\n\nThe inequality is named after the [[Germany|German]] [[mathematician]] [[Karl Weierstrass]]. It can be proved by [[mathematical induction]].\n\n\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Welch bounds",
      "url": "https://en.wikipedia.org/wiki/Welch_bounds",
      "text": "In [[mathematics]], '''Welch bounds''' are a family of [[inequality (mathematics)|inequalities]] pertinent to the problem of evenly spreading a set of unit [[vector space|vectors]] in a [[vector space]]. The bounds are important tools in the design and analysis of certain methods in [[telecommunication]] engineering, particularly in [[coding theory]]. The bounds were originally published in a 1974 paper by [[Lloyd R. Welch|L. R. Welch]].\n\n==Mathematical statement==\n\nIf <math>\\{x_1,\\ldots,x_m\\}</math> are unit vectors in <math>\\mathbb{C}^n</math>, define <math>c_\\max = \\max_{i\\neq j} |\\langle x_i, x_j \\rangle|</math>, where <math>\\langle\\cdot,\\cdot\\rangle</math> is the usual [[inner product]] on <math>\\mathbb{C}^n</math>. Then the following inequalities hold for <math>k=1,2,\\dots</math>:\n\n: <math>(c_\\max)^{2k} \\geq \\frac{1}{m-1} \\left[ \\frac{m}{\\binom{n+k-1}{k}}-1 \\right]</math>\n\n==Applicability==\n\nIf <math>m\\leq n</math>, then the vectors <math>\\{x_i\\}</math> can form an [[orthonormal set]] in <math>\\mathbb{C}^n</math>.  In this case, <math>c_\\max=0</math> and the bounds are vacuous.  Consequently, interpretation of the bounds is only meaningful if <math>m>n</math>. This will be assumed throughout the remainder of this article.\n\n==Proof for ''k'' = 1==\n\nThe \"first Welch bound,\" corresponding to <math>k=1</math>, is by far the most commonly used in applications.  Its proof proceeds in two steps, each of which depends on a more basic mathematical inequality. The first step invokes the [[Cauchy–Schwarz inequality]] and begins by considering the <math>m\\times m</math> [[Gram matrix]] <math>G</math> of the vectors <math>\\{x_i\\}</math>; i.e.,\n\n: <math>G=\\left[ \\begin{array}{ccc} \\langle x_1, x_1 \\rangle & \\cdots & \\langle x_1, x_m \\rangle \\\\ \\vdots & \\ddots & \\vdots \\\\   \\langle x_m, x_1 \\rangle & \\cdots & \\langle x_m, x_m \\rangle \\end{array}\\right]</math>\n\nThe [[trace (linear algebra)|trace]] of <math>G</math> is equal to the sum of its eigenvalues. Because the [[rank (linear algebra)|rank]] of <math>G</math> is at most <math>n</math>, and it is a [[positive-semidefinite matrix|positive semidefinite]] matrix, <math>G</math> has at most <math>n</math> positive [[eigenvalue]]s with its remaining eigenvalues all equal to zero. Writing the non-zero eigenvalues of <math>G</math> as <math>\\lambda_1,\\ldots,\\lambda_r</math> with <math>r\\leq n</math> and applying the Cauchy-Schwarz inequality to the inner product of an <math>r</math>-vector of ones with a vector whose components are these eigenvalues yields\n\n: <math>(\\mathrm{Tr}\\;G)^2 = \\left( \\sum_{i=1}^r \\lambda_i \\right)^2 \\leq r \\sum_{i=1}^r \\lambda_i^2 \\leq n \\sum_{i=1}^m \\lambda_i^2 </math>\n\nThe square of the [[Frobenius norm]] (Hilbert&ndash;Schmidt norm) of <math>G</math> satisfies\n\n: <math> ||G||^2 = \\sum_{i=1}^{m} \\sum_{j=1}^m |\\langle x_i , x_j \\rangle|^2 = \\sum_{i=1}^m \\lambda_i^2</math>\n\nTaking this together with the preceding inequality gives\n\n: <math>\\sum_{i=1}^m \\sum_{j=1}^m |\\langle x_i , x_j \\rangle|^2\\geq \\frac{(\\mathrm{Tr}\\;G)^2}{n}</math>\n\nBecause each <math>x_i</math> has unit length, the elements on the main diagonal of <math>G</math> are ones, and hence its trace is <math>\\mathrm{Tr}\\;G = m</math>.  So,\n\n: <math>\\sum_{i=1}^{m} \\sum_{j=1}^m |\\langle x_i , x_j \\rangle|^2 = m+\\sum_{i\\neq j} |\\langle x_i , x_j \\rangle|^2 \\geq \\frac{m^2}{n}</math>\n\nor\n\n: <math>\\sum_{i\\neq j} |\\langle x_i , x_j \\rangle|^2 \\geq \\frac{m(m-n)}{n}</math>\n\nThe second part of the proof uses an inequality encompassing the simple observation that the average of a set of non-negative numbers can be no greater than the largest number in the set.  In mathematical notation, if <math>a_{\\ell}\\geq 0</math> for <math>\\ell=1,\\ldots, L</math>, then\n\n: <math>\\frac{1}{L}\\sum_{\\ell=1}^L a_{\\ell} \\leq \\max a_{\\ell}</math>\n\nThe previous expression has <math>m(m-1)</math> non-negative terms in the sum,the largest of which is <math>c_\\max^2</math>.  So,\n\n: <math>(c_\\max)^2\\geq \\frac{1}{m(m-1)}\\sum_{i\\neq j} |\\langle x_i , x_j \\rangle|^2\\geq\\frac{m-n}{n(m-1)}</math>\n\nor \n \n: <math>(c_\\max)^2\\geq \\frac{m-n}{n(m-1)}</math>\n\nwhich is precisely the inequality given by Welch in the case that <math>k=1</math>.\n\n==Achieving Welch bound equality==\n\nIn certain telecommunications applications, it is desirable to construct sets of vectors that meet the Welch bounds with equality.  Several techniques have been introduced to obtain so-called '''Welch Bound Equality''' (WBE) sets of vectors for the ''k''&nbsp;=&nbsp;1 bound.\n\nThe proof given above shows that two separate mathematical inequalities are incorporated into the Welch bound when <math>k=1</math>.  The Cauchy&ndash;Schwarz inequality is met with equality when the two vectors involved are collinear.  In the way it is used in the above proof, this occurs when all the non-zero eigenvalues of the Gram matrix <math>G</math> are equal, which happens precisely when the vectors <math>\\{x_1,\\ldots,x_m\\}</math> constitute a [[tight frame]] for <math>\\mathbb{C}^n</math>.\n\nThe other inequality in the proof is satisfied with equality if and only if <math>|\\langle x_i, x_j \\rangle|</math> is the same for every choice of <math>i\\neq j</math>.  In this case, the vectors are [[equiangular lines|equiangular]]. So this Welch bound is met with equality if and only if the set of vectors <math>\\{x_i\\}</math> is an equiangular tight frame in <math>\\mathbb{C}^n</math>.\n\n==References==\n{{refbegin}}\n*{{cite journal |first1=S. |last1=Datta |first2=S.D. |last2=Howard |first3=D. |last3=Cochran |title=Geometry of the Welch Bounds |journal=Linear Algebra and its Applications |volume=437 |issue=10 |pages=2455–70 |year=2012 |doi=10.1016/j.laa.2012.05.036 |url=http://www.sciencedirect.com/science/article/pii/S0024379512004405 |arxiv=0909.0206}}\n*{{cite journal |first=L.R. |last=Welch |title=Lower Bounds on the Maximum Cross Correlation of Signals |journal=IEEE Transactions on Information Theory |volume=20 |issue=3 |pages=397–9 |date=May 1974 |doi=10.1109/TIT.1974.1055219 |url=http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1055219}}\n{{refend}}\n\n[[Category:Inequalities]]"
    },
    {
      "title": "Weyl's inequality",
      "url": "https://en.wikipedia.org/wiki/Weyl%27s_inequality",
      "text": "In mathematics, there are at least two results known as '''''Weyl's inequality'''''.\n\n==Weyl's inequality in number theory==\nIn [[number theory]], '''Weyl's inequality''', named for [[Hermann Weyl]], states that if ''M'', ''N'', ''a'' and ''q'' are integers, with ''a'' and ''q'' [[coprime]], ''q''&nbsp;>&nbsp;0, and ''f'' is a [[real number|real]] [[polynomial]] of degree ''k'' whose leading coefficient ''c'' satisfies\n\n:<math>|c-a/q|\\le tq^{-2},</math>\n\nfor some ''t'' greater than or equal to 1, then for any positive real number <math>\\scriptstyle\\varepsilon</math> one has\n\n:<math>\\sum_{x=M}^{M+N}\\exp(2\\pi if(x))=O\\left(N^{1+\\varepsilon}\\left({t\\over q}+{1\\over N}+{t\\over N^{k-1}}+{q\\over N^k}\\right)^{2^{1-k}}\\right)\\text{ as }N\\to\\infty.</math>\n\nThis inequality will only be useful when\n\n:<math>q < N^k,</math>\n\nfor otherwise estimating the modulus of the [[exponential sum]] by means of the [[triangle inequality]] as <math>\\scriptstyle\\le\\, N</math> provides a better bound.\n\n==Weyl's inequality in matrix theory==\n\n====Weyl's inequality about perturbation====\n\nIn linear algebra, '''Weyl's inequality''' is a theorem about the changes to [[eigenvalues]] of a [[Hermitian matrix]] that is perturbed.  It is useful if we wish to know the eigenvalues of a Hermitian matrix but there is an uncertainty about its entries.  We let ''H'' be the exact matrix and ''P'' be a perturbation matrix that represents the uncertainty.  The matrix we 'measure' is <math>\\scriptstyle M \\,=\\, H \\,+\\, P</math>.\n\nThe theorem says that if any two of ''M'', ''H'' and ''P'' are ''n'' by ''n'' Hermitian matrices, where ''M'' has eigenvalues\n\n:<math>\\mu_1 \\ge \\cdots \\ge \\mu_n</math>\n\nand ''H'' has eigenvalues\n\n:<math>\\nu_1 \\ge \\cdots \\ge \\nu_n</math>\n\nand ''P'' has eigenvalues\n\n:<math>\\rho_1 \\ge \\cdots \\ge \\rho_n</math>\n\nthen the following inequalities hold for <math>\\scriptstyle i \\,=\\, 1,\\dots ,n</math>:\n\n:<math>\\nu_i + \\rho_n \\le \\mu_i \\le \\nu_i + \\rho_1</math>\n\nMore generally, if  <math>\\scriptstyle j+k-n \\,\\ge\\, i \\,\\ge\\, r+s-1</math>, we have\n\n:<math>\\nu_j + \\rho_k \\le \\mu_i \\le \\nu_r + \\rho_s</math>\n\nIf ''P'' is positive definite (that is, <math>\\scriptstyle\\rho_n \\,>\\, 0</math>) then this implies\n\n:<math>\\mu_i > \\nu_i \\quad   \\forall i = 1,\\dots,n.</math>\n\nNote that we can order the eigenvalues because the matrices are Hermitian and therefore the eigenvalues are real.\n\n====Weyl's inequality between eigenvalues and singular values====\nLet <math>A \\in \\mathbb{C}^{n \\times n}</math> have singular values <math>\\sigma_1(A) \\geq \\cdots \\geq \\sigma_n(A) \\geq 0</math> and eigenvalues ordered so that <math>|\\lambda_1(A)| \\geq \\cdots \\geq |\\lambda_n(A)|</math>. Then\n\n:<math> |\\lambda_1(A) \\cdots \\lambda_k(A)| \\leq \\sigma_1(A) \\cdots \\sigma_k(A)</math>\n\nFor <math>k = 1, \\ldots, n</math>, with equality for <math>k=n</math>.\n<ref>Toger A. Horn, and Charles R. Johnson Topics in Matrix Analysis. Cambridge, 1st Edition, 1991. p.171</ref>\n\n==Applications==\n\n=== Estimating perturbations of the spectrum ===\n\nAssume that we have a bound on ''P'' in the sense that we know that its spectral norm (or, indeed, any consistent matrix norm) satisfies <math>\\|P\\|_2 \\le \\epsilon</math>. Then it follows that all its eigenvalues are bounded in absolute value by <math>\\epsilon</math>. Applying Weyl's inequality, it follows that the spectra of ''M'' and ''H'' are close in the sense that<ref>\nWeyl, Hermann. [https://link.springer.com/article/10.1007/BF01456804 \"Das asymptotische Verteilungsgesetz der Eigenwerte linearer partieller Differentialgleichungen (mit einer Anwendung auf die Theorie der Hohlraumstrahlung).\"] Mathematische Annalen 71, no. 4 (1912): 441-479.</ref>\n\n:<math>|\\mu_i - \\nu_i| \\le \\epsilon \\qquad \\forall i=1,\\ldots,n.</math>\n\n=== Weyl's inequality for singular values ===\nThe [[singular value]]s {''&sigma;<sub>k</sub>''} of a square matrix ''M'' are the square roots of eigenvalues of ''M*M'' (equivalently ''MM*''). Since Hermitian matrices follow Weyl's inequality, if we take any matrix ''A'' then its singular values will be the square root of the eigenvalues of ''B=A*A'' which is a Hermitian matrix. Now since Weyl's inequality hold for B, therefore for the singular values of ''A''.<ref>{{cite web|last1=Tao|first1=Terence|title=254A, Notes 3a: Eigenvalues and sums of Hermitian matrices|url=https://terrytao.wordpress.com/2010/01/12/254a-notes-3a-eigenvalues-and-sums-of-hermitian-matrices/|website=Terence Tao's blog|accessdate=25 May 2015|date=2010-01-13}}</ref>\n\nThis result gives the bound for the perturbation in the singular values of a matrix ''A''  due to perturbation in ''A''.\n\n==Notes==\n{{Reflist}}\n==References==\n\n* ''Matrix Theory'', Joel N. Franklin, (Dover Publications, 1993) {{ISBN|0-486-41179-6}}\n* \"Das asymptotische Verteilungsgesetz der Eigenwerte linearer partieller Differentialgleichungen\", H. Weyl, Math. Ann., 71 (1912), 441–479\n\n\n\n{{DEFAULTSORT:Weyl's Inequality}}\n[[Category:Diophantine approximation]]\n[[Category:Inequalities]]\n[[Category:Linear algebra]]"
    }
  ]
}