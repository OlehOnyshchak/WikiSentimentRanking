{
  "pages": [
    {
      "title": "Central simple algebra",
      "url": "https://en.wikipedia.org/wiki/Central_simple_algebra",
      "text": "In [[ring theory]] and related areas of [[mathematics]] a '''central simple algebra''' ('''CSA''') over a [[field (mathematics)|field]] ''K'' is a finite-dimensional [[associative algebra]] ''A'', which is [[simple algebra|simple]], and for which the [[Center (ring theory)|center]] is exactly ''K''. As an example, note that any simple algebra is a central simple algebra over its center.\n\nFor example, the [[complex number]]s '''C''' form a CSA over themselves, but not over the [[real number]]s '''R''' (the center of '''C''' is all of '''C''', not just '''R'''). The [[quaternion]]s '''H''' form a 4-dimensional CSA over '''R''', and in fact represent the only non-trivial element of the [[Brauer group]] of the reals (see below).\n\nGiven two central simple algebras ''A'' ~ ''M''(''n'',''S'') and ''B'' ~ ''M''(''m'',''T'') over the same field ''F'', ''A'' and ''B'' are called ''similar'' (or ''[[Brauer equivalent]]'') if their division rings ''S'' and ''T'' are isomorphic. The set of all [[equivalence class]]es of central simple algebras over a given field ''F'', under this equivalence relation, can be equipped with a [[group operation]] given by the [[tensor product of algebras]]. The resulting group is called the [[Brauer group]] Br(''F'') of the field ''F''.<ref name=L159>Lorenz (2008) p.159</ref>  It is always a [[torsion group]].<ref name=L194>Lorenz (2008) p.194</ref>\n\n==Properties==\n* According to the [[Artin–Wedderburn theorem]] a finite-dimensional simple algebra ''A'' is isomorphic to the matrix algebra [[matrix ring|''M''(''n'',''S'')]] for some [[division ring]] ''S''. Hence, there is a unique division algebra in each Brauer equivalence class.<ref name=L160>Lorenz (2008) p.160</ref>\n* Every [[automorphism]] of a central simple algebra is an [[inner automorphism]] (follows from [[Skolem–Noether theorem]]).\n* The [[Dimension (vector space)|dimension]] of a central simple algebra as a vector space over its centre is always a square: the '''degree''' is the square root of this dimension.<ref name=GS21>Gille & Szamuely (2006) p.21</ref>  The '''Schur index''' of a central simple algebra is the degree of the equivalent division algebra:<ref name=L163>Lorenz (2008) p.163</ref> it depends only on the [[Brauer class]] of the algebra.<ref name=GS100>Gille & Szamuely (2006) p.100</ref>\n* The '''period''' or '''exponent''' of a central simple algebra is the order of its Brauer class as an element of the Brauer group.  It is a divisor of the index,<ref name=Jac60>Jacobson (1996) p.60</ref> and the two numbers are composed of the same prime factors.<ref name=Jac61>Jacobson (1996) p.61</ref><ref name=GS104>Gille & Szamuely (2006) p.104</ref><ref>{{cite book | title=Further Algebra and Applications | first=Paul M. | last=Cohn | publisher=[[Springer-Verlag]] | year=2003 | isbn=1852336676 | page=208 }}</ref>\n* If ''S'' is a simple [[subalgebra]] of a central simple algebra ''A'' then dim<sub>''F''</sub>&nbsp;''S'' divides dim<sub>''F''</sub>&nbsp;''A''.\n* Every 4-dimensional central simple algebra over a field ''F'' is isomorphic to a [[quaternion algebra]]; in fact, it is either a two-by-two [[matrix algebra]], or a [[division algebra]].\n* If ''D'' is a central division algebra over ''K'' for which the index has prime factorisation\n::<math>\\mathrm{ind}(D) = \\prod_{i=1}^r p_i^{m_i} \\ </math>\n:then ''D'' has a tensor product decomposition\n::<math>D = \\bigotimes_{i=1}^r D_i \\ </math>\n:where each component ''D''<sub>''i''</sub> is a central division algebra of index <math>p_i^{m_i}</math>, and the components are uniquely determined up to isomorphism.<ref name=GS105>Gille & Szamuely (2006) p.105</ref>\n\n==Splitting field==\nWe call a field ''E'' a ''splitting field'' for ''A'' over ''K'' if ''A''⊗''E'' is isomorphic to a matrix ring over ''E''.  Every finite dimensional CSA has a splitting field: indeed, in the case when ''A'' is a division algebra, then a [[maximal subfield]] of ''A'' is a splitting field.  In general by theorems of [[Joseph Wedderburn|Wedderburn]] and Koethe there is a splitting field which is a [[separable extension]] of ''K'' of degree equal to the index of ''A'', and this splitting field is isomorphic to a subfield of ''A''.<ref name=Jac2728>Jacobson (1996) pp.27-28</ref><ref name=GS101>Gille & Szamuely (2006) p.101</ref>  As an example, the field '''C''' splits the quaternion algebra '''H''' over '''R''' with\n\n:<math> t + x \\mathbf{i} + y \\mathbf{j} + z \\mathbf{k} \\leftrightarrow\n\\left({\\begin{array}{*{20}c} t + x i & y + z i \\\\ -y + z i & t - x i \\end{array}}\\right) . </math>\n\nWe can use the existence of the splitting field to define '''reduced norm''' and '''reduced trace''' for a CSA ''A''.<ref name=GS378>Gille & Szamuely (2006) pp.37-38</ref>  Map ''A'' to a matrix ring over a splitting field and define the reduced norm and trace to be the composite of this map with determinant and trace respectively.  For example, in the quaternion algebra '''H''', the splitting above shows that the element ''t'' + ''x'' '''i''' + ''y'' '''j''' + ''z'' '''k''' has reduced norm ''t''<sup>2</sup> + ''x''<sup>2</sup> + ''y''<sup>2</sup> + ''z''<sup>2</sup> and reduced trace 2''t''.\n\nThe reduced norm is multiplicative and the reduced trace is additive.  An element ''a'' of ''A'' is invertible if and only if its reduced norm in non-zero: hence a CSA is a division algebra if and only if the reduced norm is non-zero on the non-zero elements.<ref name=GS38>Gille & Szamuely (2006) p.38</ref>\n\n==Generalization==\nCSAs over a field ''K'' are a non-commutative analog to [[extension field]]s over ''K'' – in both cases, they have no non-trivial 2-sided ideals, and have a distinguished field in their center, though a CSA can be non-commutative and need not have inverses (need not be a [[division algebra]]). This is of particular interest in [[noncommutative number theory]] as generalizations of [[number field]]s (extensions of the rationals '''Q'''); see [[noncommutative number field]].\n\n==See also==\n* [[Azumaya algebra]], generalization of CSAs where the base field is replaced by a commutative local ring\n* [[Severi–Brauer variety]]\n* [[Posner's theorem]]\n\n==References==\n{{reflist}}\n* {{cite book | title=Further Algebra and Applications | first=P.M. | last=Cohn | authorlink=Paul Cohn | edition=2nd | publisher=Springer | year=2003 | isbn=1852336676 | zbl=1006.00001 }}\n* {{cite book | last=Jacobson | first=Nathan | authorlink=Nathan Jacobson | title=Finite-dimensional division algebras over fields | zbl=0874.16002 | location=Berlin | publisher=[[Springer-Verlag]] | isbn=3-540-57029-2 | year=1996 }}\n* {{cite book | title=Introduction to Quadratic Forms over Fields | volume=67 | series=[[Graduate Studies in Mathematics]] | first=Tsit-Yuen | last=Lam |authorlink=T. Y. Lam | publisher=American Mathematical Society | year=2005 | isbn=0-8218-1095-2 | zbl=1068.11023 | mr = 2104929 }}\n* {{cite book | first=Falko | last=Lorenz | title=Algebra.  Volume II: Fields with Structure, Algebras and Advanced Topics | year=2008 | publisher=Springer | isbn=978-0-387-72487-4 | zbl=1130.12001 }}\n\n===Further reading===\n* {{cite book | title=Structure of Algebras | volume=24 | series=Colloquium Publications | first=A.A. | last=Albert | authorlink=Abraham Adrian Albert | edition=7th revised reprint | publisher=American Mathematical Society | year=1939 | isbn=0-8218-1024-3 | zbl=0023.19901 }}\n* {{cite book | last1=Gille | first1=Philippe | last2=Szamuely | first2=Tamás | title=Central simple algebras and Galois cohomology | series=Cambridge Studies in Advanced Mathematics | volume=101 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2006 | isbn=0-521-86103-9 | zbl=1137.12001 }}\n\n[[Category:Algebras]]\n[[Category:Ring theory]]"
    },
    {
      "title": "Cluster algebra",
      "url": "https://en.wikipedia.org/wiki/Cluster_algebra",
      "text": "'''Cluster algebras''' are a class of [[commutative ring]]s introduced by {{harvs|txt|last=Fomin|author1-link=Sergey Fomin|last2=Zelevinsky|author2-link=Andrei Zelevinsky|year=2002|year2=2003|year3=2007}}.  A cluster algebra of rank ''n'' is an [[integral domain]] ''A'', together with some subsets of size ''n'' called clusters whose union generates the algebra ''A'' and which satisfy various conditions.\n\n==Definitions==\n\nSuppose that ''F'' is an integral domain, such as the field '''Q'''(''x''<sub>1</sub>,...,''x''<sub>''n''</sub>) of rational functions in ''n'' variables over the rational numbers '''Q'''.\n\nA '''cluster''' of '''rank''' ''n'' consists of a set of ''n'' elements {''x'', ''y'', ...} of ''F'', usually assumed to be an algebraically independent set of generators of a field extension ''F''.\n\nA '''seed''' consists of a cluster {''x'',''y'',...}  of ''F'', together with an '''exchange matrix'''  ''B'' with integer entries ''b''<sub>''x'',''y''</sub> indexed by  pairs of elements ''x'', ''y'' of the cluster. The matrix is sometimes assumed to be skew symmetric, so that ''b''<sub>''x'',''y''</sub> = –''b''<sub>''y'',''x''</sub>. More generally the matrix might be skew symmetrizable, meaning there are positive integers ''d''<sub>''x''</sub> associated with the elements of the cluster such that ''d''<sub>''x''</sub>''b''<sub>''x'',''y''</sub> = –''d''<sub>''y''</sub>''b''<sub>''y'',''x''</sub>. It is common to picture a seed as a [[quiver (mathematics)|quiver]] with vertices the generating set, by drawing ''b''<sub>''x'',''y''</sub> arrows from ''x'' to ''y'' if this number is positive. When ''b''<sub>''x'',''y''</sub> is skew symmetrizable the quiver has no loops or 2-cycles.\n\nA '''mutation''' of a seed, depending on a choice of vertex ''y'' of the cluster,  is a new seed given by a generalization of [[Tilting theory|tilting]] as follows. Exchange the values of ''b''<sub>''x'',''y''</sub> and ''b''<sub>''y'',''x''</sub> for all ''x'' in the cluster. If  ''b''<sub>''x'',''y''</sub> > 0 and ''b''<sub>''y'',''z''</sub> > 0  then replace ''b''<sub>''x'',''z''</sub> by  ''b''<sub>''x'',''y''</sub>''b''<sub>''y'',''z''</sub> + ''b''<sub>''x'',''z''</sub>. If  ''b''<sub>''x'',''y''</sub> < 0 and ''b''<sub>''y'',''z''</sub> < 0  then replace ''b''<sub>''x'',''z''</sub> by  -''b''<sub>''x'',''y''</sub>''b''<sub>''y'',''z''</sub> + ''b''<sub>''x'',''z''</sub>. If ''b''<sub>''x'',''y''</sub> ''b''<sub>''y'',''z''</sub> <= 0 do not change ''b''<sub>''x'',''z''</sub>. Finally replace ''y'' by a new generator ''w'', where \n:<math>wy=\\prod_{t,b_{t,y}>0}t^{b_{t,y}} + \\prod_{t,b_{t,y}<0}t^{-b_{t,y}}</math>\nwhere the products run through the elements ''t'' in the cluster of the seed such that ''b''<sub>''t'',''y''</sub> is positive or negative respectively. The inverse of a mutation is also a mutation: in other words, if ''A'' is a mutation of ''B'', then ''B'' is a mutation of ''A''.\n\nA '''cluster algebra''' is constructed from a seed as follows. \nIf we repeatedly mutate the seed in all possible ways, we get a finite or infinite graph of seeds, where two seeds are joined if one can be obtained by mutating the other. The underlying algebra of the cluster algebra is the algebra generated by all the clusters of all the seeds in this graph. The cluster algebra  also comes with the extra structure of the seeds of this graph.\n\nA cluster algebra is said to be of '''finite type''' if it has only a finite number of seeds. {{harvtxt|Fomin|Zelevinsky|2003}} showed that the cluster algebras of finite type can be classified in terms of the  [[Dynkin diagram]]s of finite-dimensional [[simple Lie algebra]]s.\n\n==Examples==\n\n===Cluster algebras of rank 1===\n\nIf {''x''} is the cluster of a seed of rank 1, then the only mutation takes this to {2''x''<sup>−1</sup>}. So a cluster algebra of rank 1 is just a ring ''k''[''x'',''x''<sup>−1</sup>] of Laurent polynomials, and it has just two clusters, {''x''} and {2''x''<sup>−1</sup>}. In particular it is of finite type and is associated with the Dynkin diagram A<sub>1</sub>.\n\n===Cluster algebras of rank 2===\n\nSuppose that we start with the cluster {''x''<sub>1</sub>, ''x''<sub>2</sub>} and take the exchange matrix with ''b''<sub>12</sub>=–b<sub>21</sub>=1. Then mutation gives a sequence of variables ''x''<sub>1</sub>, ''x''<sub>2</sub>, ''x''<sub>3</sub>, ''x''<sub>4</sub>,... such that the clusters are given by adjacent pairs {''x''<sub>''n''</sub>,''x''<sub>''n''+1</sub>}. The variables are related by \n:<math>\\displaystyle x_{n-1}x_{n+1}=1+x_n</math>\nso are given by the sequence\n\n:<math> x_1, x_2, x_3=\\frac{1+x_2}{x_1}, x_4=\\frac{1+x_3}{x_2}=\\frac{1+x_1+x_2}{x_1x_2},  </math>\n: <math> x_5=\\frac{1+x_4}{x_3}=\\frac{1+x_1}{x_2},\nx_6=\\frac{1+x_5}{x_4}=x_1,x_7=\\frac{1+x_6}{x_5}=x_2,\\ldots</math>\nwhich repeats with period 5. So this cluster algebra has exactly 5 clusters, and in particular is of finite type. It is associated with the Dynkin diagram A<sub>2</sub>.\n\nThere are similar examples with ''b''<sub>12</sub> = 1, –''b''<sub>21</sub> = 2 or 3, where the analogous sequence of cluster variables repeats with period 6 or 8. These are also of finite type, and are associated with the Dynkin diagrams B<sub>2</sub> and G<sub>2</sub>. However if |''b''<sub>12</sub>''b''<sub>21</sub>| ≥ 4 then the sequence of cluster variables is not periodic and the cluster algebra is of infinite type.\n\n===Cluster algebras of rank 3===\n\nSuppose we start with the quiver ''x''<sub>1</sub>→''x''<sub>2</sub>→''x''<sub>3</sub>. Then the 14 clusters are:\n:<math>\\left\\{ x_1,x_2,x_3 \\right\\},</math>\n:<math>\\left\\{\\frac{1+x_2}{x_1},x_2,x_3 \\right\\},</math>\n:<math>\\left\\{x_1, \\frac{x_1 + x_3}{x_2},x_3 \\right\\},</math> \n:<math>\\left\\{x_1,x_2,\\frac{1+x_2}{x_3}\\right\\},</math>\n:<math>\\left\\{\\frac{1+x_2}{x_1}, \\frac{x_1 +(1+x_2)x_3}{x_1 x_2},x_3 \\right\\},</math>\n:<math>\\left\\{\\frac{1+x_2}{x_1},x_2,\\frac{1+x_2}{x_3} \\right\\},</math>\n:<math>\\left\\{\\frac{x_1+(1+x_2)x_3}{x_1x_2},\\frac{x_1 + x_3}{x_2},x_3 \\right\\},</math>\n:<math>\\left\\{x_1,\\frac{x_1+x_3}{x_2},\\frac{(1+x_2)x_1+x_3}{x_2x_3} \\right\\},</math> \n:<math>\\left\\{x_1,\\frac{(1+x_2)x_1 + x_3}{x_2 x_3},\\frac{1+x_2}{x_3} \\right\\},</math>\n:<math>\\left\\{\\frac{1+x_2}{x_1},\\frac{x_1+(1+x_2)x_3}{x_1 x_2},\\frac{(1+x_2)x_1 +(1+x_2)x_3}{x_1 x_2x_3}\\right\\},</math>\n:<math>\\left\\{\\frac{1+x_2}{x_1},\\frac{(1+x_2)x_1 +(1+x_2)x_3}{x_1 x_2x_3},\n\\frac{1+x_2}{x_3} \\right\\},</math>\n:<math>\\left\\{\\frac{x_1+(1+x_2)x_3}{x_1x_2},\\frac{x_1+x_3}{x_2},\\frac{(1+x_2)x_1+(1+x_2)x_3}{x_1 x_2 x_3} \\right\\},</math>\n:<math>\\left\\{\\frac{(1+x_2)x_1 +(1+x_2)x_3}{x_1 x_2x_3},\\frac{x_1+x_3}{x_2},\\frac{(1+x_2)x_1+x_3}{x_2 x_3} \\right\\},</math> \n:<math>\\left\\{\\frac{(1+x_2)x_1+(1+x_2)x_3}{x_1 x_2 x_3},\\frac{(1+x_2)x_1+x_3}{x_2 x_3},\\frac{1+x_2}{x_3} \\right\\}.</math>\n\nThere are 6 cluster variables other than the 3 initial ones ''x''<sub>1</sub>, ''x''<sub>2</sub>, ''x''<sub>3</sub> given by\n:<math>\\frac{1+x_2}{x_1},\\frac{x_1 + x_3}{x_2},\\frac{1+x_2}{x_3}, \\frac{x_1+(1+x_2)x_3}{x_1x_2}, \\frac{(1+x_2)x_1+x_3}{x_2 x_3}, \\frac{(1+x_2)x_1 +(1+x_2)x_3}{x_1 x_2x_3}</math>. \nThey correspond to the 6 positive roots of the Dynkin diagram A<sub>3</sub>: more precisely the denominators are monomials in ''x''<sub>1</sub>, ''x''<sub>2</sub>, ''x''<sub>3</sub>, corresponding to the expression of positive roots as the sum of simple roots. \nThe 3+6 cluster variables generate a cluster algebra of finite type, associated with the Dynkin diagram A<sub>3</sub>.\nThe 14 clusters are the vertices of the cluster graph, which is an [[associahedron]].\n\n===Grassmannians===\nSimple examples are given by the algebras of homogeneous functions on the [[Grassmannian]]s. The [[Plücker coordinates]] provide some of the distinguished elements.\n\n[[File:Cluster algebra.svg|thumb|300px|Mutation between two triangulations of the heptagon]]\nFor the Grassmannian of planes in ℂ<sup>''n''</sup>, the situation is even more simple. In that case, the Plücker coordinates provide all the distinguished elements and the clusters can be completely described using [[Polygon triangulation|triangulation]]s of a [[regular polygon]] with ''n'' vertices. More precisely, clusters are in one-to-one correspondence with triangulations and the distinguished elements are in one-to-one correspondence with diagonals (line segments joining two vertices of the polygon). One can distinguish between diagonals in the boundary, which belong to every cluster, and diagonals in the interior. This corresponds to a general distinction between coefficient variables and cluster variables.\n\n===Cluster algebras arising from surfaces===\nSuppose '''S''' is a compact connected oriented Riemann surface and '''M''' is a non-empty finite set of points in '''S''' that contains at least one point from each boundary component of '''S''' (the boundary of '''S''' is not assumed to be either empty or non-empty). The pair ('''S''','''M''') is often referred to as a ''bordered surface with marked points''. It has been shown by Fomin-Shapiro-Thurston that if '''S''' is not a closed surface, or if '''M''' has more than one point, then the (tagged) arcs on ('''S''','''M''') parameterize the set of cluster variables of certain cluster algebra ''A''('''S''','''M'''), which depends only on ('''S''','''M''') and the choice of some coefficient system, in such a way that the set of (tagged) triangulations of ('''S''','''M''') is in one-to-one correspondence with the set of clusters of ''A''('''S''','''M'''), two (tagged) triangulations being related by a ''flip'' if and only if the clusters they correspond to are related by cluster mutation.\n\n===Double Bruhat Cells===\n\nFor '''G''' a reductive group such as <math>GL_n</math> with [[Borel subgroup]]s <math>B_\\pm</math> then on <math>G^{u,v} = B u B \\bigcap B_- v B_-</math> (where u,v are in the [[Weyl group]]) there are cluster coordinate charts depending on reduced word decompositions of u,v. These are called factorization parameters and their structure is encoded in a wiring diagram. With only B or only <math>B_-</math>, this is [[Bruhat decomposition]].\n\n==References==\n*{{Citation | last1=Berenstein | first1=Arkady | last2=Fomin | first2=Sergey | last3=Zelevinsky | first3=Andrei | title=Cluster algebras. III. Upper bounds and double Bruhat cells | doi=10.1215/S0012-7094-04-12611-9 | mr=2110627 | year=2005 | journal=[[Duke Mathematical Journal]] | volume=126 | issue=1 | pages=1–52| arxiv=math/0305434 }}\n*{{Citation | last1=Fomin | first1=Sergey | last2=Shapiro | first2=Michael | last3=Thurston | first3=Dylan | title=Cluster algebras and triangulated surfaces, part I: Cluster complexes. | year=2008 | journal=[[Acta Mathematica]] | volume=201 | issue= | pages=83–146 | doi=10.1007/s11511-008-0030-7| arxiv=math/0608367 }}\n*{{Citation | last1=Fomin | first1=Sergey | last2=Zelevinsky | first2=Andrei | title=Cluster algebras. I. Foundations | doi=10.1090/S0894-0347-01-00385-X | mr=1887642 | year=2002 | journal=[[Journal of the American Mathematical Society]]   | volume=15 | issue=2 | pages=497–529| arxiv=math/0104151 }}\n*{{Citation | last1=Fomin | first1=Sergey | last2=Zelevinsky | first2=Andrei | title=Cluster algebras. II. Finite type classification | doi=10.1007/s00222-003-0302-y | mr=2004457 | year=2003 | journal=[[Inventiones Mathematicae]]   | volume=154 | issue=1 | pages=63–121| arxiv=math/0208229 | bibcode=2003InMat.154...63F }}\n*{{Citation | last1=Fomin | first1=Sergey | last2=Zelevinsky | first2=Andrei | title=Cluster algebras. IV. Coefficients | doi=10.1112/S0010437X06002521 | mr=2295199 | year=2007 | journal=Compositio Mathematica   | volume=143 | issue=1 | pages=112–164| arxiv=math/0602259 }}\n*{{Citation | last1=Fomin | first1=Sergey | last2=Reading | first2=Nathan | editor1-last=Miller | editor1-first=Ezra | editor2-last=Reiner | editor2-first=Victor | editor3-last=Sturmfels | editor3-first=Bernd | editor3-link=Bernd Sturmfels | title=Geometric combinatorics |chapter=Root systems and generalized associahedra |publisher=Amer. Math. Soc. | location=Providence, R.I. | series=IAS/Park City Math. Ser. | mr=2383126 | year=2007 | volume=13 | isbn=978-0-8218-3736-8|arxiv=math/0505518| bibcode=2005math......5518F }}\n*{{citation|MR=3155783 \n|last=Marsh|first= Robert J.\n|title=Lecture notes on cluster algebras. \n|series=Zurich Lectures in Advanced Mathematics|publisher= European Mathematical Society (EMS)|place= Zürich|year= 2013|isbn=  978-3-03719-130-9|doi=10.4171/130 }}\n*{{Citation | last1=Reiten | first1=Idun | title=Tilting theory and cluster algebras | arxiv=1012.6014| series=Trieste Proceedings of Workshop | year=2010| bibcode=2010arXiv1012.6014R}}\n* {{citation | first = Andrei | last = Zelevinsky | title = What Is . . . a Cluster Algebra? | journal = AMS Notices | volume = 54 | issue = 11 | pages = 1494–1495 | year = 2007 | url = http://www.ams.org/notices/200711/tx071101494p.pdf }}.\n\n==External links==\n*Fomin's [http://www.math.lsa.umich.edu/~fomin/cluster.html Cluster algebra portal]\n*[http://www.math.lsa.umich.edu/~fomin/papers.html Fomin's papers on cluster algebras]\n*[http://front.math.ucdavis.edu/author/A.Zelevinsky Zelevinsky's papers on cluster algebras]\n\n[[Category:Algebras]]\n[[Category:Commutative algebra]]"
    },
    {
      "title": "Colombeau algebra",
      "url": "https://en.wikipedia.org/wiki/Colombeau_algebra",
      "text": "In [[mathematics]], a '''Colombeau algebra''' is an [[associative algebra|algebra]] of a certain kind containing the space of [[distribution (mathematics)|Schwartz distributions]]. While in classical distribution theory a general multiplication of distributions is not possible, Colombeau algebras provide a rigorous framework for this.\n\nSuch a multiplication of distributions has long been believed to be impossible because of L. Schwartz' impossibility result, which basically states that there cannot be a differential algebra containing the space of distributions and preserving the product of continuous functions. However, if one only wants to preserve the product of smooth functions instead such a construction becomes possible, as demonstrated first by Colombeau.\n\nAs a mathematical tool, Colombeau algebras can be said to combine a treatment of singularities, differentiation and nonlinear operations in one framework, lifting the limitations of distribution theory. These algebras have found numerous applications in the fields of partial differential equations, geophysics, microlocal analysis and general relativity so far.\n\n== Schwartz' impossibility result ==\n\nAttempting to embed the space <math>\\mathcal{D}'(\\mathbb{R})</math> of distributions on <math>\\mathbb{R}</math> into an associative algebra <math>(A(\\mathbb{R}), \\circ, +)</math>, the following requirements seem to be natural:\n\n# <math>\\mathcal{D}'(\\mathbb{R})</math> is linearly embedded into <math>A(\\mathbb{R})</math> such that the constant function <math>1</math> becomes the unity in <math>A(\\mathbb{R})</math>,\n# There is a partial derivative operator <math>\\partial</math> on <math>A(\\mathbb{R})</math> which is linear and satisfies the Leibniz rule,\n# the restriction of <math>\\partial</math> to <math>\\mathcal{D}'(\\mathbb{R})</math> coincides with the usual partial derivative,\n# the restriction of <math>\\circ</math> to <math>C(\\mathbb{R}) \\times C(\\mathbb{R})</math> coincides with the pointwise product.\n\nHowever, L. Schwartz' result<ref>L. Schwartz, 1954, \"Sur l'impossibilité de la multiplication des distributions\", ''Comptes Rendus de L'Académie des Sciences'' 239, pp. 847–848 [http://gallica.bnf.fr/ark:/12148/bpt6k3191m/f847.image.langFR]</ref> implies that these requirements cannot hold simultaneously. The same is true even if, in 4., one replaces <math>C(\\mathbb{R})</math> by <math>C^k(\\mathbb{R})</math>, the space of <math>k</math> times continuously differentiable functions. While this result has often been interpreted as saying that a general multiplication of distributions is not possible, in fact it only states that one cannot unrestrictedly combine differentiation, multiplication of continuous functions and the presence of singular objects like the Dirac delta.\n\nColombeau algebras are constructed to satisfy conditions 1.–3. and a condition like 4., but with <math>C(\\mathbb{R}) \\times C(\\mathbb{R})</math> replaced by <math>C^\\infty(\\mathbb{R}) \\times C^\\infty(\\mathbb{R})</math>, i.e., they preserve the product of smooth (infinitely differentiable) functions only.\n\n== Basic idea ==\n\nThe Colombeau Algebra<ref>{{cite ArXiv|last = Gratus|first =  J.|title = Colombeau Algebra: A pedagogical introduction| \nurl=https://arxiv.org/abs/1308.0257|arxiv=1308.0257}}</ref> is defined as the [[quotient associative algebra|quotient algebra]]\n\n:<math>C^\\infty_M(\\mathbb{R}^n)/C^\\infty_N(\\mathbb{R}^n).</math>\n\nHere the algebra of ''moderate functions'' <math>C^\\infty_M(\\mathbb{R}^n)</math> on <math>\\mathbb{R}^n</math> is the algebra of families of smooth ''regularisations'' (''f<sub>ε</sub>'')\n\n:<math>{f:} \\mathbb{R}_+ \\to C^\\infty(\\mathbb{R}^n)</math>\nof [[smooth function]]s on <math>\\mathbb{R}^n</math>\n(where '''R'''<sub>+</sub>&nbsp;=&nbsp;(0,∞) is the \"[[regularization (mathematics)|regularization]]\" parameter ε), such that for all compact subsets ''K'' of <math>\\mathbb{R}^n</math> and all [[multiindices]] α, there is an ''N'' > 0 such that\n\n:<math>\\sup_{x\\in K}\\left|\\frac{\\partial^{|\\alpha|}}{(\\partial x_1)^{\\alpha_1}\\cdots(\\partial x_n)^{\\alpha_n}}f_\\varepsilon(x)\\right| = O(\\varepsilon^{-N})\\qquad(\\varepsilon\\to 0).</math>\n\nThe [[ideal (ring theory)|ideal]] <math>C^\\infty_N(\\mathbb{R}^n)</math> of ''negligible functions'' is defined in the same way but with the partial derivatives instead bounded by O(''ε<sup>+N</sup>'') for '''all''' ''N'' > 0.\n\n== Embedding of distributions ==\nThe space(s) of [[Schwartz distribution]]s can be embedded into the ''simplified'' algebra by (component-wise) [[convolution]] with any element of the algebra having as representative a ''[[e-net (probability theory)|&delta;-net]]'', i.e. a family of smooth functions <math>\\varphi_\\varepsilon</math> such that <math>\\varphi_\\varepsilon\\to\\delta</math> in '' D' '' as&nbsp;''ε''&nbsp;→&nbsp;0.\n\nThis embedding is non-canonical, because it depends on the choice of the δ-net. However, there are versions of Colombeau algebras (so called ''full'' algebras) which allow for canonical embeddings of distributions. A well known ''full'' version is obtained by adding the mollifiers as second indexing set.\n\n== See also ==\n* [[Generalized function]]\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n* Colombeau, J. F., ''New Generalized Functions and Multiplication of the Distributions''. North Holland, Amsterdam, 1984.\n* Colombeau, J. F., ''Elementary introduction to new generalized functions''. North-Holland, Amsterdam, 1985.\n* Nedeljkov, M., [[Stevan Pilipović|Pilipović, S.]], Scarpalezos, D., ''Linear Theory of Colombeau's Generalized Functions'', Addison Wesley, Longman, 1998.\n* Grosser, M., Kunzinger, M., Oberguggenberger, M., Steinbauer, R.; ''Geometric Theory of Generalized Functions with Applications to General Relativity'', Springer Series Mathematics and Its Applications, Vol. 537, 2002; {{isbn|978-1-4020-0145-1}}.\n\n[[Category:Smooth functions]]\n[[Category:Functional analysis]]\n[[Category:Algebras]]"
    },
    {
      "title": "Derivative algebra (abstract algebra)",
      "url": "https://en.wikipedia.org/wiki/Derivative_algebra_%28abstract_algebra%29",
      "text": "In [[abstract algebra]], a '''derivative algebra''' is an [[algebraic structure]] of the signature   \n    \n:<''A'', ·, +, ', 0, 1, <sup>D</sup>>   \n    \nwhere    \n\n:<''A'', ·, +, ', 0, 1>   \n\nis a [[Boolean algebra (structure)|Boolean algebra]] and <sup>D</sup> is a [[unary operator]], the '''derivative operator''', satisfying the identities:    \n    \n# 0<sup>D</sup> = 0    \n# ''x''<sup>DD</sup> ≤ ''x'' + ''x''<sup>D</sup>    \n# (''x'' + ''y'')<sup>D</sup> = ''x''<sup>D</sup> + ''y''<sup>D</sup>.  \n\nx<sup>D</sup> is called the '''[[derivative]]''' of x. Derivative algebras provide an algebraic abstraction of the '''[[derived set (mathematics)|derived set]]''' operator in [[topological space|topology]]. They also [[Lindenbaum–Tarski algebra|play the same role]] for the [[modal logic]] ''wK4'' = ''K''&nbsp;+ ''p''∧?''p''&nbsp;→&nbsp;??''p'' that [[Boolean algebra (structure)|Boolean algebra]]s play for ordinary [[propositional logic]].   \n\n==References==   \n* Esakia, L., ''Intuitionistic logic and modality via topology'', Annals of Pure and Applied Logic, 127 (2004) 155-170\n* McKinsey, J.C.C. and [[Alfred Tarski|Tarski, A.]], ''The Algebra of Topology'', Annals of Mathematics, 45 (1944) 141-191\n\n[[Category:Algebras]]\n[[Category:Boolean algebra]]\n[[Category:Topology]]\n\n{{algebra-stub}}"
    },
    {
      "title": "Difference algebra",
      "url": "https://en.wikipedia.org/wiki/Difference_algebra",
      "text": "'''Difference algebra''' is a branch of [[mathematics]] concerned with the study of [[difference equation|difference]] (or [[functional equation|functional]]) equations from the algebraic point of view. Difference algebra is analogous to [[differential algebra]] but concerned with difference equations rather than differential equations. As an independent subject it was initiated by [[Joseph Ritt]] and his student Richard Cohn.\n\n== Difference rings, difference fields and difference algebras ==\n\nA ''difference ring'' is a [[commutative ring]] <math> R </math> together with a ring endomorphism <math>\\sigma\\colon R\\to R</math>. Often it is assumed that <math>\\sigma</math> is injective. When <math>R</math> is a field one speaks of a ''difference field''. A classical example of a difference field is the field <math>K=\\mathbb{C}(x)</math> of rational functions with the difference operator <math>\\sigma</math> given by <math>\\sigma(f(x))=f(x+1)</math>. The role of difference rings in difference algebra is similar to the role of commutative rings in [[commutative algebra]] and [[algebraic geometry]]. A morphism of difference rings is a morphism of rings that commutes with <math>\\sigma</math>. A ''difference algebra'' over a difference field <math>K</math> is a difference ring <math>R</math> with a <math>K</math>-algebra structure such that <math>K\\to R</math> is a morphism of difference rings, i.e. <math>\\sigma\\colon R\\to R</math> extends <math>\\sigma\\colon K\\to K</math>. A difference algebra which is a field is called a ''difference field extension''.\n\n== Algebraic difference equations ==\n\nThe difference polynomial ring <math>K\\{y\\}=K\\{y_1,\\ldots,y_n\\}</math> over a difference field <math>K</math> in the (difference) variables <math>y_1,\\ldots,y_n</math> is the polynomial ring over <math>K</math> in the infinitely many variables <math>\\sigma^i(y_j),\\ (i\\in\\mathbb{N}, 1\\leq j\\leq n)</math>. It becomes a difference algebra over <math>K</math> by extending <math>\\sigma</math> from <math>K</math> to <math>K\\{y\\}</math> as suggested by the naming of the variables.\n\nBy a ''system of algebraic difference'' equations over <math>K</math> one means any subset <math>F</math> of <math>K\\{y\\}</math>. If <math>R</math> is a difference algebra over <math>K</math> the solutions of <math>F</math> in <math>R</math> are\n\n:<math>\\mathbb{V}_R(F)=\\{a\\in R^n|\\ f(a)=0 \\text{ for all } f\\in F\\}.</math>\n\nClassically one is mainly interested in solutions in difference field extensions of <math>K</math>. For example, if <math>K=\\mathbb{C}(x)</math> and <math>R</math> is the field of meromorphic functions on <math>\\mathbb{C}</math> with difference operator <math>\\sigma</math> given by <math>\\sigma(f(x))=f(x+1)</math>, then the fact that the [[gamma function]] <math>\\Gamma</math> satisfies the functional equation <math>\\Gamma(x+1)=x\\Gamma(x)</math> can be restated abstractly as <math>\\Gamma\\in\\mathbb{V}_R(\\sigma(y_1)-xy_1)</math>.\n\n== Difference varieties ==\n\nIntuitively, a ''difference variety'' over a difference field <math>K</math> is the set of solutions of a system of algebraic difference equations over <math>K</math>. This definition has to be made more precise by specifying where one is looking for the solutions. Usually one is looking for solutions in the so-called universal family of difference field extensions of <math>K</math>.<ref name=Cohn>{{cite book|last=Cohn|title=Difference algebra}} Chapter 4</ref><ref name=Levin>{{cite book|last=Levin|title=Difference algebra}} Section 2.6</ref> Alternatively, one may define a difference variety as a [[functor]] from the [[category (mathematics)|category]] of difference field extensions of <math>K</math> to the category of sets, which is of the form <math>R\\rightsquigarrow \\mathbb{V}_R(F)</math> for some <math>F\\subset K\\{y\\}.</math>.\n\nThere is a one-to-one correspondence between the difference varieties defined by algebraic difference equations in the variables <math>y_1,\\ldots,y_n</math> and certain ideals in <math>K\\{y\\}</math>, namely the perfect difference ideals of <math>K\\{y\\}</math>.<ref>{{cite book|last=Levin|title=Difference algebra}} Theorem 2.6.4</ref> One of the basic theorems in difference algebra asserts that every ascending chain of perfect difference ideals in <math>K\\{y\\}</math> is finite. This result can be seen as a difference analog of [[Hilbert's basis theorem]].\n\n== Applications ==\n\nDifference algebra is related to many other mathematical areas, such as discrete dynamical systems, combinatorics, number theory or model theory. While some real life problems, such as population dynamics, can be modeled by algebraic difference equations, difference algebra also has applications in pure mathematics. For example, there is a proof of the [[Manin-Mumford conjecture]] using methods of difference algebra.<ref>{{cite journal|last=Hrushovski|first=Ehud|title=The Manin–Mumford conjecture and the model theory of difference fields|journal=Annals of Pure and Applied Logic|year=2001|volume=112|issue=1|pages=43–115|doi=10.1016/S0168-0072(01)00096-3}}</ref> The [[model theory]] of difference fields has been studied.\n\n== See also ==\n* [[Finite difference]]\n* [[Recurrence relation]]\n* [[Functional equation]]\n* [[Differential algebra]]\n\n==Notes==\n{{Reflist}}\n\n==References==\n\n*Alexander Levin (2008), [https://books.google.com/books?id=15pgjT5PeY0C Difference algebra], Springer, {{isbn|978-1-4020-6946-8}}\n*Richard M. Cohn (1979), [https://books.google.com/books?id=Fs8oAAAACAAJ& Difference algebra], R.E. Krieger Pub. Co., {{isbn|978-0-88275-651-6}}\n\n==External links==\n*{{cite book|last=Wibmer|first=Michael|title=Lecture Notes - Algebraic difference equations|year=2013|pages=80 pages|url=http://www.algebra.rwth-aachen.de/de/Mitarbeiter/Wibmer/Algebraic%20difference%20equations.pdf}}\n* The [http://www.logique.jussieu.fr/~zoe/ home page] of [[Zoé Chatzidakis]] has several online surveys discussing (the model theory of) difference fields.\n\n[[Category:Algebras]]"
    },
    {
      "title": "Differential graded algebra",
      "url": "https://en.wikipedia.org/wiki/Differential_graded_algebra",
      "text": "In [[mathematics]], in particular [[abstract algebra]] and [[topology]], a '''differential graded algebra''' is a [[graded algebra]] with an added [[chain complex]] structure that respects the algebra structure.\n\n__TOC__\n\n== Definition ==\nA '''differential graded algebra''' (or simply '''DG-algebra''') ''A'' is a graded algebra equipped with a map <math>d\\colon A \\to A</math> which is either degree 1 (cochain complex convention) or degree <math>-1</math> (chain complex convention) that satisfies two conditions:\n\n{{ordered list|type=lower-roman\n  | <math>d \\circ d=0</math>. <br />This says that ''d'' gives ''A'' the structure of a [[chain complex]] or [[cochain complex]] (accordingly as the differential reduces or raises degree).\n  | <math>d(a \\cdot b)=(da) \\cdot b + (-1)^{\\operatorname{deg}(a)}a \\cdot (db)</math>, where deg is the [[Graded ring|degree]] of homogeneous elements.{{Anchor|Graded Leibniz rule}} <br />This says that the [[chain complex|differential]] ''d'' respects the '''graded [[Product rule|Leibniz rule]]'''.}}\n\nA more succinct (but esoteric) way to state the same definition is to say that a DG-algebra is a [[monoid object]] in the [[monoidal category]] of chain complexes.\nA DG morphism between DG-algebras is a graded algebra homomorphism which respects the differential ''d''.\n\nA '''differential graded [[augmented algebra]]''' (also called a '''DGA-algebra''',\nan augmented DG-algebra or simply a '''DGA''') is a DG-algebra equipped with a DG morphism to the ground ring (the terminology is due to [[Henri Cartan]]).<ref>H. Cartan, Sur les groupes d'Eilenberg-Mac Lane H(Π,n), Proc. Natl. Acad. Sci. U.S.A. 40, (1954). 467–471</ref>\n\n<i>Warning:</i> some sources use the term ''DGA'' for a DG-algebra.\n\n== Examples of DG-algebras ==\n*The [[Koszul complex]] is a DG-algebra.\n*The [[tensor algebra]] is a DG-algebra with differential similar to that of the Koszul complex.\n*The [[singular cohomology]] of a topological space with coefficients in '''Z'''/''p'''''Z''' is a DG-algebra: the differential is given by the [[Bockstein homomorphism]] associated to the short exact sequence 0 → '''Z'''/''p'''''Z''' → '''Z'''/''p''<sup>2</sup>'''Z''' → '''Z'''/''p'''''Z''' → 0, and the product is given by the [[cup product]].\n*[[Differential forms]] on a [[manifold]], together with the [[Exterior derivative|exterior derivation]] and the [[Differential form|wedge product]] form a DG-algebra. See also [[de Rham cohomology]].\n\n== Other facts about DG-algebras ==\n* The ''[[Homology (mathematics)|homology]]'' <math>H_*(A) = \\ker(d) / \\operatorname{im}(d)</math> of a DG-algebra <math>(A,d)</math> is a graded algebra. The homology of a DGA-algebra is an [[augmented algebra]].\n\n== See also ==\n<!-- * [[Commutative ring spectrum]]; relation? -->\n* [[Differential graded category]]\n* [[Differential graded Lie algebra]]\n* [[Differential graded scheme]] (which is obtained by gluing the spectra of graded-commutative differential graded algebras with respect to the étale topology.)\n\n== References ==\n{{reflist}}\n\n* {{Citation | last1=Manin | first1=Yuri Ivanovich | author1-link=Yuri Ivanovich Manin | last2=Gelfand | first2=Sergei I. | title=Methods of Homological Algebra | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-43583-9 | year=2003}}, see sections V.3 and V.5.6\n\n[[Category:Algebras]]\n[[Category:Differential algebra]]"
    },
    {
      "title": "Division algebra",
      "url": "https://en.wikipedia.org/wiki/Division_algebra",
      "text": "In the field of [[mathematics]] called [[abstract algebra]], a '''division algebra''' is, roughly speaking, an [[algebra over a field]] in which [[division (mathematics)|division]], except by zero, is always possible.\n\n==Definitions==\nFormally, we start with a [[Zero object (algebra)|non-zero]] [[Algebra over a field|algebra]] ''D'' over a [[field (mathematics)|field]]. We call ''D'' a '''division algebra''' if for any element ''a'' in ''D'' and any non-zero element ''b'' in ''D'' there exists precisely one element ''x'' in ''D'' with ''a'' = ''bx'' and precisely one element ''y'' in ''D'' such that {{nowrap|1=''a'' = ''yb''}}.\n\nFor [[associative algebra]]s, the definition can be simplified as follows: a non-zero associative algebra over a field is a '''division algebra''' [[if and only if]] it has a multiplicative [[identity element]] 1 and every non-zero element ''a'' has a multiplicative inverse (i.e. an element ''x'' with {{nowrap|1=''ax'' = ''xa'' = 1}}).\n\n==Associative division algebras==\n\nThe best-known examples of associative division algebras are the finite-dimensional real ones (that is, algebras over the field '''R''' of [[real number]]s, which are finite-[[Hamel dimension|dimensional]] as a [[vector space]] over the reals). The [[Frobenius theorem (real division algebras)|Frobenius theorem]] states that [[up to]] [[isomorphism]] there are three such algebras: the reals themselves (dimension 1), the field of [[complex number]]s (dimension 2), and the [[quaternions]] (dimension 4).\n\n[[Wedderburn's little theorem]] states that if ''D'' is a finite division algebra, then ''D'' is a [[finite field]].<ref>Lam (2001), [{{Google books|plainurl=y|id=f15FyZuZ3-4C|page=203|text=Wedderburn's \"little\" theorem}} p. 203]</ref>\n\nOver an [[algebraically closed field]] ''K'' (for example the [[complex number]]s '''C'''), there are no finite-dimensional associative division algebras, except ''K'' itself.<ref>Cohn (2003), [{{Google books|plainurl=y|id=VESm0MJOiDQC|page=150|text=only division algebra}} Proposition 5.4.5, p. 150]</ref>\n\nAssociative division algebras have no [[zero divisor]]s. A ''finite-dimensional'' [[unital algebra|unital]] [[associative algebra]] (over any field) is a division algebra ''if and only if'' it has no zero divisors.\n\nWhenever ''A'' is an associative [[unital algebra]] over the [[field (mathematics)|field]] ''F'' and ''S'' is a [[simple module]] over ''A'', then the [[endomorphism ring]] of ''S'' is a division algebra over ''F''; every associative division algebra over ''F'' arises in this fashion.\n\nThe [[center (ring theory)|center]] of an associative division algebra ''D'' over the field ''K'' is a field containing ''K''. The dimension of such an algebra over its center, if finite, is a [[square number|perfect square]]: it is equal to the square of the dimension of a maximal subfield of ''D'' over the center. Given a field ''F'', the [[Brauer equivalence]] classes of simple (contains only trivial two-sided ideals) associative division algebras whose center is ''F'' and which are finite-dimensional over ''F'' can be turned into a group, the [[Brauer group]] of the field ''F''.\n\nOne way to construct finite-dimensional associative division algebras over arbitrary fields is given by the [[quaternion algebra]]s (see also [[quaternion]]s).\n\nFor infinite-dimensional associative division algebras, the most important cases are those where the space has some reasonable [[topology]]. See for example [[normed division algebra]]s and [[Banach algebra]]s.\n\n==Not necessarily associative division algebras==<!-- This section is linked from [[Division ring]] -->\n\nIf the division algebra is not assumed to be associative, usually some weaker condition (such as [[alternativity]] or [[power associativity]]) is imposed instead.  See [[algebra over a field]] for a list of such conditions.\n\nOver the reals there are (up to isomorphism) only two unitary [[commutative]] finite-dimensional division algebras: the reals themselves, and the complex numbers.  These are of course both associative.  For a non-associative example, consider the complex numbers with multiplication defined by taking the [[complex conjugate]] of the usual multiplication:\n:<math>a*b=\\overline{ab}.</math>\n[[Example of a non-associative algebra|This]] is a commutative, non-associative division algebra of dimension 2 over the reals, and has no unit element. There are infinitely many other non-isomorphic commutative, non-associative, finite-dimensional real divisional algebras, but they all have dimension 2.\n\nIn fact, every finite-dimensional real commutative division algebra is either 1- or 2-dimensional. This is known as [[Heinz Hopf|Hopf's]] theorem, and was proved in 1940. The proof uses methods from [[topology]]. Although a later proof was found using [[algebraic geometry]], no direct algebraic proof is known. The [[fundamental theorem of algebra]] is a corollary of Hopf's theorem.\n\nDropping the requirement of commutativity, Hopf generalized his result: Any finite-dimensional real division algebra must have dimension a power of 2.\n\nLater work showed that in fact, any finite-dimensional real division algebra must be of dimension 1, 2, 4, or 8. This was independently proved by [[Michel Kervaire]] and [[John Milnor]] in 1958, again using techniques of [[algebraic topology]], in particular [[K-theory]]. [[Adolf Hurwitz]] had shown in 1898 that the identity <math>q\\overline{q} = \\text{sum of squares}</math> held only for dimensions 1, 2, 4 and 8.<ref>{{cite book|title=The Road To Reality|authorlink=Roger Penrose|author=Roger Penrose|year=2005|publisher=Vintage|isbn=0-09-944068-7}}, p.202</ref> (See [[Hurwitz's theorem (normed division algebras)|Hurwitz's theorem]].) The challenge of constructing a division algebra of three dimensions was tackled by several early mathematicians. [[Kenneth O. May]] surveyed these attempts in 1966.<ref>[[Kenneth O. May]] (1966) \"The Impossiblility of a Division Algebra of Vectors in Three Dimensional Space\", [[American Mathematical Monthly]] 73(3): 289–91 {{doi| 10.2307/2315349}}</ref>\n\nAny real finite-dimensional division algebra\nover the reals must be\n* isomorphic to '''R''' or '''C''' if unitary and commutative (equivalently: associative and commutative)\n* isomorphic to the quaternions if noncommutative but associative\n* isomorphic to the [[octonions]] if non-associative but [[alternative algebra|alternative]].\n\nThe following is known about the dimension of a finite-dimensional division algebra ''A'' over a field ''K'':\n* dim ''A'' = 1 if ''K'' is [[algebraically closed]],\n* dim ''A'' = 1, 2, 4 or 8 if ''K'' is [[real closed]], and\n* If ''K'' is neither algebraically nor real closed, then there are infinitely many dimensions in which there exist division algebras over ''K''.\n\n==See also==\n* [[Normed division algebra]]\n* [[Division (mathematics)]]\n* [[Division ring]]\n* [[Semifield]]\n* [[Cayley–Dickson construction]]\n\n==Notes==\n<references/>\n\n==References==\n* {{cite book |last1=Cohn |first1=Paul Moritz |authorlink1= |last2= |first2= |authorlink2= |title=Basic algebra: groups, rings, and fields |url= |edition= |series= |volume= |year=2003 |publisher=Springer |location= |isbn=978-1-85233-587-8 |id= }}\n* {{cite book |last1=Lam |first1=Tsit-Yuen |authorlink1= |last2= |first2= |authorlink2= |title=A first course in noncommutative rings |url= |edition=2 |series=[[Graduate Texts in Mathematics]] |volume=131 |year=2001 |publisher=Springer |location= |isbn=0-387-95183-0 |id= }}\n\n==External links==\n* {{springer|title=Division algebra|id=p/d033680}}\n\n[[Category:Algebras]]\n[[Category:Ring theory]]"
    },
    {
      "title": "Double affine Hecke algebra",
      "url": "https://en.wikipedia.org/wiki/Double_affine_Hecke_algebra",
      "text": "In mathematics, a '''double affine Hecke algebra''', or '''Cherednik algebra''',  is an algebra containing the [[affine Hecke algebra|Hecke algebra]] of an [[affine Weyl group]], given as the quotient of the group ring of a [[double affine braid group]]. They were introduced by [[Ivan Cherednik|Cherednik]], who  used them to prove [[Macdonald's constant term conjecture]] for [[Macdonald polynomial]]s. Infinitesimal Cherednik algebras have significant implications in [[representation theory]], and therefore have important applications in [[particle physics]] and in [[chemistry]].\n\n==References==\n\n*{{Citation | last1=Cherednik | first1=Ivan | title=Double affine Hecke algebras | publisher=[[Cambridge University Press]] | series=London Mathematical Society Lecture Note Series | isbn=978-0-521-60918-0 | mr=2133033 | year=2005 | volume=319}}\n*{{citation |mr=2275709\n|last=Haiman |first= Mark\n|chapter=Cherednik algebras, Macdonald polynomials and combinatorics |title= International Congress of Mathematicians. Vol. III |pages= 843–872 |publisher= Eur. Math. Soc., Zürich |year= 2006 |isbn=978-3-03719-022-7 |url=http://mathunion.org/ICM/ICM2006.3/ |chapter-url=}} \n*A. A. Kirillov [http://www.ams.org/bull/1997-34-03/S0273-0979-97-00727-1/home.html Lectures on affine Hecke algebras and Macdonald's conjectures]  Bull. Amer. Math. Soc. 34 (1997), 251–292.\n*[[Ian G. Macdonald|Macdonald, I. G.]] ''Affine Hecke algebras and orthogonal polynomials.'' Cambridge Tracts in Mathematics, 157. Cambridge University Press, Cambridge, 2003. x+175 pp.&nbsp;{{ISBN|0-521-82472-9}} {{DOI|10.2277/0521824729}} {{mr|1976581 }}\n\n[[Category:Algebras]]\n[[Category:Representation theory]]"
    },
    {
      "title": "Duffin–Kemmer–Petiau algebra",
      "url": "https://en.wikipedia.org/wiki/Duffin%E2%80%93Kemmer%E2%80%93Petiau_algebra",
      "text": "In [[mathematical physics]], the '''Duffin–Kemmer–Petiau algebra (DKP algebra)''', introduced by [[Richard Duffin|R.J. Duffin]], [[Nicholas Kemmer]] and G. Petiau, is the [[algebra]] which is generated by the Duffin–Kemmer–Petiau matrices. These matrices form part of the '''Duffin–Kemmer–Petiau equation''' that provides a relativistic description of spin-0 and spin-1 particles.\n\nThe DKP algebra is also referred to as the '''meson algebra'''.<ref>Jacques Helmstetter, Artibano Micali: ''About the Structure of Meson Algebras'', Advances in Applied Clifford Algebras, vol.&nbsp;20, no.&nbsp;3-4, pp.&nbsp;617-629, {{doi|10.1007/s00006-010-0213-0}}, [http://www.springerlink.com/content/u452170x4v707p71/ abstract]</ref>\n\n== Defining relations ==\nThe Duffin–Kemmer–Petiau matrices have the defining relation<ref name=\"pavlov\">See introductory section of: Yu V. Pavlov: [https://arxiv.org/PS_cache/gr-qc/pdf/0610/0610115v1.pdf ''Duffin–Kemmer–Petiau equation with nonminimal coupling to curvature''], Gravitation & Cosmology, vol.&nbsp;12 (2006), no.2–3, pp.&nbsp;205–208</ref>\n:<math>\\beta^{a} \\beta^{b} \\beta^{c} + \\beta^{c} \\beta^{b} \\beta^{a} =  \\beta^{a} \\eta^{b c} + \\beta^{c} \\eta^{b a}</math>\nwhere <math>\\eta^{a b}</math> stand for a constant [[diagonal matrix]]. The Duffin–Kemmer–Petiau matrices <math>\\beta</math> for which <math>\\eta^{a b}</math> consists in diagonal elements (+1,-1,…,-1) form part of the Duffin–Kemmer–Petiau equation. Five-dimensional DKP matrices can be represented as:<ref name=\"boztosun\">See for example I. Boztosun, M. Karakoc, F. Yasuk, A. Durmus: ''Asymptotic Iteration Method Solutions to the Relativistic Duffin-Kemmer-Petiau Equation'', Journal of Mathematical Physics vol.&nbsp;47, 062301 (2006), {{doi|10.1063/1.2203429}}, arXiv:math-ph/0604040v1 (submitted 18 April 2006) [https://arxiv.org/PS_cache/math-ph/pdf/0604/0604040v1.pdf#page=5]</ref><ref name=\"Capri-P25\">Anton Z. Capri: ''Relativistic quantum mechanics and introduction to quantum field theory'', World Scientific, 2002, {{ISBN|981-238-136-8}}, [https://books.google.com/books?id=tTJHB5hepQUC&pg=PA25 p. 25]</ref>\n:<math>\n\\beta^{0} =\n\\begin{pmatrix}\n0&1&0&0&0\\\\\n1&0&0&0&0\\\\\n0&0&0&0&0\\\\\n0&0&0&0&0\\\\\n0&0&0&0&0\n\\end{pmatrix}\n</math>, <math>\\quad\n\\beta^{1} =\n\\begin{pmatrix}\n0&0&-1&0&0\\\\\n0&0&0&0&0\\\\\n1&0&0&0&0\\\\\n0&0&0&0&0\\\\\n0&0&0&0&0\n\\end{pmatrix}\n</math>, <math>\\quad\n\\beta^{2} =\n\\begin{pmatrix}\n0&0&0&-1&0\\\\\n0&0&0&0&0\\\\\n0&0&0&0&0\\\\\n1&0&0&0&0\\\\\n0&0&0&0&0\n\\end{pmatrix}\n</math>, <math>\\quad\n\\beta^{3} =\n\\begin{pmatrix}\n0&0&0&0&-1\\\\\n0&0&0&0&0\\\\\n0&0&0&0&0\\\\\n0&0&0&0&0\\\\\n1&0&0&0&0\n\\end{pmatrix}\n</math>\nThese five-dimensional DKP matrices represent spin-0 particles. The DKP matrices for spin-1 particles are 10-dimensional.<ref name=\"boztosun\"/> The DKP-algebra can be reduced to a direct sum of irreducible subalgebras for spin‐0 and spin‐1 bosons, the subalgebras being defined by multiplication rules for the linearly independent basis elements.<ref>Ephraim Fischbach, Michael Martin Nieto, C. K. Scott: ''Duffin‐Kemmer‐Petiau subalgebras: Representations and applications'', Journal of Mathematical Physics, vol.&nbsp;14, no.&nbsp;12, 1760 (1973), {{doi|10.1063/1.1666249}} ([http://jmp.aip.org/resource/1/jmapaq/v14/i12/p1760_s1 abstract])</ref>\n\n== Duffin–Kemmer–Petiau equation ==\nThe ''Duffin–Kemmer–Petiau equation'' (''DKP equation'', also: ''Kemmer equation'') is a [[relativistic wave equation]] which describes spin-0 and spin-1 particles in the description of the [[standard model]]. For particles with nonzero mass, the DKP equation is<ref name=\"pavlov\"/>\n:<math>(i \\hbar \\beta^{a} \\partial_a - m c) \\psi = 0</math>\nwhere <math>\\beta^{a}</math> are Duffin–Kemmer–Petiau matrices, <math>m</math> is the particle's [[mass]], <math>\\psi</math> its [[wavefunction]], <math>\\hbar</math> the reduced [[Planck constant]], <math>c</math> the [[speed of light]]. For massless particles, the term <math>m c</math> is replaced by a singular matrix <math>\\gamma</math> that obeys the relations <math>\\beta^{a} \\gamma + \\gamma \\beta^{a} = \\beta^{a}</math> and <math>\\gamma^2 = \\gamma</math>.\n\nThe DKP equation for spin-0 is closely linked to the [[Klein–Gordon equation]].<ref name=\"Capri-P25\"/><ref>R. Casana, V.Ya. Fainberg, J.T. Lunardi, R.G. Teixeira, B.M. Pimentel: [http://www.sbf1.sbfisica.org.br/eventos/enfpc/xxii/procs/trb0124.pdf ''Massless DKP fields in Riemann-Cartan space-times'']{{dead link|date=December 2016 |bot=InternetArchiveBot |fix-attempted=yes }}, arXiv:gr-qc/0209083v2 (submitted 23 September 2002, version of 12 March 2003)</ref> and the equation for spin-1 to the [[Proca action|Proca equations]]<ref name=\"Kruglov-P26\">Sergey Kruglov: ''Symmetry and electromagnetic interaction of fields with multi-spin. A Volume in Contemporary Fundamental Physics'', {{ISBN|1-56072-880-9}}, 2000, [https://books.google.com/books?id=E6Elkxs9PaIC&pg=PA26 p. 26]</ref> It suffers the same drawback as the Klein–Gordon equation in that it calls for [[negative probability|negative probabilities]].<ref name=\"Capri-P25\"/> Also the [[De Donder–Weyl theory|De Donder–Weyl covariant Hamiltonian field equations]] can be formulated in terms of DKP matrices.<ref>Igor V. Kanatchikov: [https://arxiv.org/abs/hep-th/9911175v1 ''On the Duffin–Kemmer–Petiau formulation of the covariant Hamiltonian dynamics in field theory''], hep-th/9911/9911175v1 (submitted 23. November 1999)</ref>\n\n== History ==\nThe Duffin–Kemmer–Petiau algebra was introduced in the 1930s by R.J. Duffin,<ref>R.J. Duffin: [http://prola.aps.org/abstract/PR/v54/i12/p1114_1 ''On The Characteristic Matrices of Covariant Systems''], Phys. Rev. Lett., vol.&nbsp;54, 1114 (1938), {{doi|10.1103/PhysRev.54.1114}}</ref> [[Nicholas Kemmer|N. Kemmer]]<ref>N. Kemmer: [http://rspa.royalsocietypublishing.org/content/173/952/91.full.pdf+html ''The particle aspect of meson theory''], Proceedings of the Royal Society A, vol.&nbsp;173, pp.&nbsp;91–116 (1939), {{doi|10.1098/rspa.1939.0131}}</ref> and G. Petiau.<ref>G. Petiau, University of Paris thesis (1936), published in Acad. Roy. de Belg., A. Sci. Mem. Collect.vol.&nbsp;16, N 2, 1 (1936)</ref>\n\n== Further reading ==\n* M. C. B. Fernandes, J. D. M. Vianna: ''On the generalized phase space approach to Duffin–Kemmer–Petiau particles'', Foundations of Physics, vol.&nbsp;29, no.&nbsp;2, pp.&nbsp;201–219, 1999, {{doi|10.1023/A:1018869505031}} ([http://www.springerlink.com/content/qx60511224071gx2/ abstract])\n* Marco Cezar B. Fernandes, J. David M. Vianna: ''On the Duffin-Kemmer-Petiau algebra and the generalized phase space'', Brazilian Journal of Physics, vol.&nbsp;28 n.&nbsp;4, São Paulo, December 1998, ISSN 0103-9733, {{doi|10.1590/S0103-97331998000400024}} ([http://www.scielo.br/scielo.php?pid=S0103-97331998000400024&script=sci_arttext full text])\n* Pavel Winternitz et al. (eds.): ''Symmetry in physics: in memory of Robert T. Sharp'', CRM Proceedings and Lecture Notes, 2004, {{ISBN|0-8218-3409-6}}, [https://books.google.com/books?id=2AqekbVZX4AC&pg=PA50 section \"Bhabha and Duffin–Kemmer–Petiau equations: spin zero and spin one\"], p.&nbsp;50 ff.\n* V. Ya. Fainberg, B. M. Pimentel: ''Duffin–Kemmer–Petiau and Klein–Gordon–Fock Equations for Electromagnetic, Yang–Mills and external Gravitational Field Interactions: proof of equivalence'', [https://arxiv.org/abs/hep-th/0003283 hep-th/0003283], submitted 30. March 2000\n\n== References ==\n{{reflist}}\n\n{{DEFAULTSORT:Duffin-Kemmer-Petiau algebra}}\n[[Category:Algebras]]"
    },
    {
      "title": "Exterior algebra",
      "url": "https://en.wikipedia.org/wiki/Exterior_algebra",
      "text": "{{short description|Algebraic construction used in multilinear algebra and geometry}}\n{{multiple image\n   | left\n   | footer    = Geometric interpretation of grade ''n'' elements in a real exterior algebra for {{nowrap|1=''n'' = 0}} (signed point), 1 (directed line segment, or vector), 2 (oriented plane element), 3 (oriented volume). The exterior product of ''n'' vectors can be visualized as any ''n''-dimensional shape (e.g. ''n''-[[Parallelepiped#Parallelotope|parallelotope]], ''n''-[[ellipsoid]]); with magnitude ([[hypervolume]]), and [[Orientation (vector space)|orientation]] defined by that of its {{nowrap|(''n'' − 1)}}-dimensional boundary and on which side the interior is.<ref>{{cite book |author=R. Penrose| title=[[The Road to Reality]]| publisher= Vintage books| year=2007 | isbn=0-679-77631-1}}</ref><ref>{{cite book|title=Gravitation|author1=J.A. Wheeler |author2=C. Misner |author3=K.S. Thorne |publisher=W.H. Freeman & Co|year=1973|page=83|isbn=0-7167-0344-0}}</ref>\n   | width1    = 220\n   | image1    = N vector positive.svg\n   | caption1  = Orientation defined by an ordered set of vectors.\n   | width2    = 220\n   | image2    = N vector negative.svg\n   | caption2  = Reversed orientation corresponds to negating the exterior product.\n  }}\nIn [[mathematics]], the '''exterior product''' or '''wedge product''' of vectors is an algebraic construction used in [[geometry]] to study [[area]]s, [[volume]]s, and their higher-dimensional analogues. The exterior product of two vectors ''u'' and&nbsp;''v'', denoted by {{nowrap|''u'' ∧ ''v''}}, is called a [[bivector]] and lives in a space called the ''exterior square'', a [[vector space]] that is distinct from the original space of vectors.  The [[magnitude (mathematics)|magnitude]]<ref>Strictly speaking, the magnitude depends on some additional structure, namely that the vectors be in a [[Euclidean space]].  We do not generally assume that this structure is available, except where it is helpful to develop intuition on the subject.</ref> of {{nowrap|''u'' ∧ ''v''}} can be interpreted as the area of the parallelogram with sides ''u'' and&nbsp;''v'', which in three dimensions can also be computed using the [[cross product]] of the two vectors. Like the cross product, the exterior product is [[anticommutativity|anticommutative]], meaning that {{nowrap|1=''u'' ∧ ''v'' = −(''v'' ∧ ''u'')}} for all vectors ''u'' and ''v'', but, unlike the cross product, the exterior product is [[associative]].  One way to visualize a bivector is as a family of [[parallelograms]] all lying in the same plane, having the same area, and with the same [[orientation (mathematics)|orientation]]&mdash;a choice of clockwise or counterclockwise.\n\nWhen regarded in this manner, the exterior product of two vectors is called a [[blade (geometry)|2-blade]].  More generally, the exterior product of any number ''k'' of vectors can be defined and is sometimes called a ''k''-blade.  It lives in a space known as the ''k''th exterior power.  The magnitude of the resulting ''k''-blade is the volume of the ''k''-dimensional [[Parallelepiped#Parallelotope|parallelotope]] whose edges are the given vectors, just as the magnitude of the [[scalar triple product]] of vectors in three dimensions gives the volume of the parallelepiped generated by those vectors.\n\nThe '''exterior algebra''', or '''Grassmann algebra''' after [[Hermann Grassmann]],<ref>{{harvcoltxt|Grassmann|1844}} introduced these as ''extended'' algebras (cf. {{harvnb|Clifford|1878}}). He used the word ''äußere'' (literally translated as ''outer'', or ''exterior'') only to indicate the ''produkt'' he defined, which is nowadays conventionally called ''exterior product'', probably to distinguish it from the ''[[outer product]]'' as defined in modern [[linear algebra]].</ref> is the algebraic system whose product is the exterior product.  The exterior algebra provides an algebraic setting in which to answer geometric questions.  For instance, blades have a concrete geometric interpretation, and objects in the exterior algebra can be manipulated according to a set of unambiguous rules. The exterior algebra contains objects that are not only ''k''-blades, but sums of ''k''-blades; such a sum is called a [[Multivector|''k''-vector]].<ref>The term ''k-vector'' is not equivalent to and should not be confused with similar terms such as ''[[4-vector]]'', which in a different context could mean a 4-dimensional vector. A minority of authors use the term ''k''-multivector instead of ''k''-vector, which avoids this confusion.</ref>  The ''k''-blades, because they are simple products of vectors, are called the simple elements of the algebra.  The ''rank'' of any ''k''-vector is defined to be the smallest number of simple elements of which it is a sum.  The exterior product extends to the full exterior algebra, so that it makes sense to multiply any two elements of the algebra.  Equipped with this product, the exterior algebra is an [[associative algebra]], which means that {{nowrap|1=''α'' ∧ (''β'' ∧ ''γ'') = (''α'' ∧ ''β'') ∧ ''γ''}} for any elements ''α'', ''β'', ''γ''.  The ''k''-vectors have degree ''k'', meaning that they are sums of products of ''k'' vectors.  When elements of different degrees are multiplied, the degrees add like multiplication of polynomials.  This means that the exterior algebra is a [[graded algebra]].\n\nThe definition of the exterior algebra makes sense for spaces not just of geometric vectors, but of other vector-like objects such as [[vector field]]s or [[function (mathematics)|functions]].  In full generality, the exterior algebra can be defined for [[module (mathematics)|modules]] over a [[commutative ring]], and for other structures of interest in [[abstract algebra]].  It is one of these more general constructions where the exterior algebra finds one of its most important applications, where it appears as the algebra of [[differential forms]] that is fundamental in areas that use [[differential geometry]].  Differential forms are mathematical objects that evaluate the length of infinitesimal vectors, areas of infinitesimal parallelograms, and volumes of [[Parallelepiped#Parallelotope|higher-dimensional bodies]], so they can be [[integral|integrated]] over curves, surfaces and higher dimensional [[manifold]]s in a way that generalizes the [[line integral]]s and [[Surface integral|surface integrals]] from calculus. The exterior algebra also has many algebraic properties that make it a convenient tool in algebra itself.  The association of the exterior algebra to a vector space is a type of [[functor]] on vector spaces, which means that it is compatible in a certain way with linear transformations of vector spaces. The exterior algebra is one example of a [[bialgebra]], meaning that its [[dual space]] also possesses a product, and this dual product is compatible with the exterior product. This dual algebra is precisely the algebra of [[alternating multilinear form]]s,  and the pairing between the exterior algebra and its dual is given by the [[interior product]].\n\n==Motivating examples==\n<!--The purpose of this section is to motivate the skewness of the exterior product on vectors in ''V''-->\n\n===Areas in the plane===\n[[Image:Area parallellogram as determinant.svg|thumb|right|The area of a parallelogram in terms of the determinant of the matrix of coordinates of two of its vertices.]]\n\nThe [[Cartesian plane]] '''R'''<sup>2</sup> is a vector space equipped with a [[basis of a vector space|basis]] consisting of a pair of [[unit vector]]s\n\n:<math>{\\mathbf e}_1 = \\begin{bmatrix}1\\\\0\\end{bmatrix},\\quad {\\mathbf e}_2 = \\begin{bmatrix}0\\\\1\\end{bmatrix}.</math>\n\nSuppose that\n\n:<math>{\\mathbf v} = \\begin{bmatrix}a\\\\b\\end{bmatrix} = a {\\mathbf e}_1 + b {\\mathbf e}_2, \\quad {\\mathbf w} = \\begin{bmatrix}c\\\\d\\end{bmatrix} = c {\\mathbf e}_1 + d {\\mathbf e}_2</math>\n\nare a pair of given vectors in '''R'''<sup>2</sup>, written in components. There is a unique parallelogram having '''v''' and '''w''' as two of its sides. The ''area'' of this parallelogram is given by the standard [[determinant]] formula:\n\n:<math> \\text{Area} = \\left| \\det \\begin{bmatrix} {\\mathbf v} & {\\mathbf w} \\end{bmatrix} \\right| = \\left| \\det \\begin{bmatrix} a & c \\\\ b & d \\end{bmatrix} \\right| = \\left| ad - bc \\right| .</math>\n\nConsider now the exterior product of '''v''' and '''w''':\n\n:<math>\n\\begin{align}\n{\\mathbf v}\\wedge {\\mathbf w} & = (a{\\mathbf e}_1 + b{\\mathbf e}_2) \\wedge (c{\\mathbf e}_1 + d{\\mathbf e}_2) \\\\\n& = ac{\\mathbf e}_1 \\wedge {\\mathbf e}_1+ ad{\\mathbf e}_1 \\wedge {\\mathbf e}_2+bc{\\mathbf e}_2 \\wedge {\\mathbf e}_1+bd{\\mathbf e}_2 \\wedge {\\mathbf e}_2 \\\\\n& = \\left ( ad - bc \\right ){\\mathbf e}_1 \\wedge {\\mathbf e}_2\n\\end{align}\n</math>\n\nwhere the first step uses the distributive law for the [[#Formal_definitions_and_algebraic_properties|exterior product]], and the last uses the fact that the exterior product is alternating, and in particular {{nowrap|1='''e'''<sub>2</sub> ∧ '''e'''<sub>1</sub> = −('''e'''<sub>1</sub> ∧ '''e'''<sub>2</sub>)}}. (Note that the fact that the exterior product is alternating also forces <math> \\mathbf e_1 \\wedge \\mathbf e_1 = \\mathbf e_2 \\wedge \\mathbf e_2 = 0 </math>.) Note that the coefficient in this last expression is precisely the determinant of the matrix {{nowrap|1=['''v''' '''w''']}}. The fact that this may be positive or negative has the intuitive meaning that '''v''' and '''w''' may be oriented in a counterclockwise or clockwise sense as the vertices of the parallelogram they define. Such an area is called the ''signed area'' of the parallelogram: the absolute value of the signed area is the ordinary area, and the sign determines its orientation.\n\nThe fact that this coefficient is the signed area is not an accident. In fact, it is relatively easy to see that the exterior product should be related to the signed area if one tries to axiomatize this area as an algebraic construct. In detail, if {{nowrap|1=A('''v''', '''w''')}} denotes the signed area of the parallelogram of which the pair of vectors '''v''' and '''w''' form two adjacent sides, then A must satisfy the following properties:\n# {{nowrap|1=A(''j'''''v''', ''k'''''w''') = ''jk''A('''v''', '''w''')}} for any real numbers ''j'' and ''k'', since rescaling either of the sides rescales the area by the same amount (and reversing the direction of one of the sides reverses the orientation of the parallelogram).\n# {{nowrap|1=A('''v''', '''v''') = 0}}, since the area of the [[degenerate (mathematics)|degenerate]] parallelogram determined by '''v''' (i.e., a [[line segment]]) is zero.\n# {{nowrap|1=A('''w''', '''v''') = −A('''v''', '''w''')}}, since interchanging the roles of '''v''' and '''w''' reverses the orientation of the parallelogram.\n# {{nowrap|1=A('''v''' + ''j'''''w''', '''w''') = A('''v''', '''w''')}}, for real ''j'', since adding a multiple of '''w''' to '''v''' affects neither the base nor the height of the parallelogram and consequently preserves its area.\n# {{nowrap|1=A('''e'''<sub>1</sub>, '''e'''<sub>2</sub>) = 1}}, since the area of the unit square is one.\nWith the exception of the last property, the exterior product of two vectors satisfies the same properties as the area. In a certain sense, the exterior product generalizes the final property by allowing the area of a parallelogram to be compared to that of any \"standard\" chosen parallelogram in a parallel plane (here, the one with sides '''e'''<sub>1</sub> and '''e'''<sub>2</sub>). In other words, the exterior product provides a ''basis-independent'' formulation of area.<ref>This axiomatization of areas is due to [[Leopold Kronecker]] and [[Karl Weierstrass]]; see {{harvtxt|Bourbaki|1989|loc=Historical Note}}. For a modern treatment, see {{harvtxt|Mac Lane|Birkhoff|1999|loc=Theorem IX.2.2}}. For an elementary treatment, see {{harvtxt|Strang|1993|loc=Chapter 5}}.</ref>\n\n===Cross and triple products===\n[[Image:Exterior calc cross product.svg|250px|thumb|The cross product ('''<span style=\"color:blue;\">blue</span>''' vector) in relation to the exterior product ('''<span style=\"color:#779ECB;\">light blue</span>''' parallelogram). The length of the cross product is to the length of the parallel unit vector ('''<span style=\"color:#CC0000;\">red</span>''') as the size of the exterior product is to the size of the reference parallelogram ('''<span style=\"color:#CC4E5C;\">light red</span>''').]]\n\nFor vectors in '''R'''<sup>3</sup>, the exterior algebra is closely related to the [[cross product]] and [[triple product]]. Using the [[standard basis]] {{nowrap|{'''e'''<sub>1</sub>, '''e'''<sub>2</sub>, '''e'''<sub>3</sub>},}} the exterior product of a pair of vectors\n\n:<math> \\mathbf{u} = u_1 \\mathbf{e}_1 + u_2 \\mathbf{e}_2 + u_3 \\mathbf{e}_3 </math>\n\nand\n\n:<math> \\mathbf{v} = v_1 \\mathbf{e}_1 + v_2 \\mathbf{e}_2 + v_3 \\mathbf{e}_3 </math>\n\nis\n\n:<math> \\mathbf{u} \\wedge \\mathbf{v} = (u_1 v_2 - u_2 v_1) (\\mathbf{e}_1 \\wedge \\mathbf{e}_2) + (u_3 v_1 - u_1 v_3) (\\mathbf{e}_3 \\wedge \\mathbf{e}_1) + (u_2 v_3 - u_3 v_2) (\\mathbf{e}_2 \\wedge \\mathbf{e}_3) </math>\n\nwhere {'''e'''<sub>1</sub> ∧ '''e'''<sub>2</sub>, '''e'''<sub>3</sub> ∧ '''e'''<sub>1</sub>, '''e'''<sub>2</sub> ∧ '''e'''<sub>3</sub>} is the basis for the three-dimensional space Λ<sup>2</sup>('''R'''<sup>3</sup>). The coefficients above are the same as those in the usual definition of the [[cross product]] of vectors in three dimensions, the only difference being that the exterior product is not an ordinary vector, but instead is a [[Two-vector|2-vector]].\n\nBringing in a third vector\n\n:<math> \\mathbf{w} = w_1 \\mathbf{e}_1 + w_2 \\mathbf{e}_2 + w_3 \\mathbf{e}_3, </math>\n\nthe exterior product of three vectors is\n\n:<math> \\mathbf{u} \\wedge \\mathbf{v} \\wedge \\mathbf{w} = (u_1 v_2 w_3 + u_2 v_3 w_1 + u_3 v_1 w_2 - u_1 v_3 w_2 - u_2 v_1 w_3 - u_3 v_2 w_1) (\\mathbf{e}_1 \\wedge \\mathbf{e}_2 \\wedge \\mathbf{e}_3) </math>\n\nwhere {{nowrap|'''e'''<sub>1</sub> ∧ '''e'''<sub>2</sub> ∧ '''e'''<sub>3</sub>}} is the basis vector for the one-dimensional space Λ<sup>3</sup>('''R'''<sup>3</sup>). The scalar coefficient is the [[triple product]] of the three vectors.\n\nThe cross product and triple product in three dimensions each admit both geometric and algebraic interpretations. The cross product {{nowrap|'''u''' × '''v'''}} can be interpreted as a vector which is perpendicular to both '''u''' and '''v''' and whose magnitude is equal to the area of the parallelogram determined by the two vectors. It can also be interpreted as the vector consisting of the [[minor (mathematics)|minors]] of the matrix with columns '''u''' and '''v'''. The triple product of '''u''', '''v''', and&nbsp;'''w''' is geometrically a (signed) volume. Algebraically, it is the determinant of the matrix with columns '''u''', '''v''', and&nbsp;'''w'''. The exterior product in three dimensions allows for similar interpretations: it, too, can be identified with oriented areas or volumes spanned by the two or three vectors involved. In fact, in the presence of a positively oriented [[orthonormal basis]], the exterior product generalizes these geometric notions to higher dimensions.\n\n==Formal definitions and algebraic properties==\nThe exterior algebra {{math|Λ(''V'')}} of a vector space {{math|''V''}} over a [[field (mathematics)|field]] {{math|''K''}} is defined as the [[Quotient ring|quotient algebra]] of the [[tensor algebra]] {{math|''T''(''V'')}} by the two-sided [[Ideal (ring theory)|ideal]] {{math|''I''}} generated by all elements of the form {{math|1=''x'' ⊗ ''x''}} for {{math|1=''x'' ∈ ''V''}} (i.e. all tensors that can be expressed as the tensor product of a vector in {{math|''V''}} by itself).<ref>{{harvtxt|Mac Lane|Birkhoff|1999}}</ref>. The ideal ''I'' contains the ideal ''J'' generated by elements of the form <math>x\\otimes y + y \\otimes x = (x+y)\\otimes (x+y) - x\\otimes x - y\\otimes y </math> and  these ideals coincide if (and only if) <math>\\operatorname{char}(K) \\ne 2</math>:\n: <math>I \\supseteq J \\text{ with equality iff } \\operatorname{char}(K) \\ne 2</math>. \nWe define \n:<math>\\Lambda(V) = T(V)/I </math>\nThe exterior product {{math|∧}} of two elements of {{math|Λ(''V'')}} is the product induced by the tensor product {{math|⊗}} of {{math|''T''(''V'')}}. That is, if\n:<math>\\pi:T(V)\\to \\Lambda(V) = T(V)/I</math>\nis the [[canonical projection map|canonical surjection]], and {{mvar|a}} and {{mvar|b}} are in {{math|Λ(''V'')}}, then there are <math>\\alpha</math> and <math>\\beta</math> in {{math|''T''(''V'')}} such that <math>a=\\pi(\\alpha)</math> and <math>b=\\pi(\\beta),</math> and\n:<math>a\\wedge b = \\pi(\\alpha\\otimes\\beta).</math>\nIt results from the definition of a quotient algebra that the value of <math>a\\wedge b</math> does not depend on a particular choice of <math>\\alpha</math> and <math>\\beta.</math>. We have (in all characteristics) <math> x \\otimes y = - y \\otimes x \\mod I</math>. \n\nAs {{math|1=''T''<sup>0</sup> = ''K''}}, {{math|1=''T''<sup>1</sup> = ''V''}}, and <math>\\left(T^0(V)\\oplus T^1(V)\\right)\\cap I= \\{ 0 \\} </math>, the inclusions of {{math|''K''}} and {{math|''V''}} in {{math|''T''(''V'')}} induce injections of {{math|''K''}} and {{math|''V''}} into {{math|Λ(''V'')}}. These injections are commonly considered as inclusions, and called ''natural embeddings'', ''natural injections'' or ''natural inclusions''. The word ''canonical'' is also commonly used in place of ''natural''.\n\n===Alternating product===\nThe exterior product is by construction [[Alternating algebra|''alternating'']] on elements of ''V'', which means that {{nowrap|1=''x'' ∧ ''x'' = 0}} for all {{nowrap|''x'' ∈ ''V''}}, by the above construction.  It follows that the product is also [[anticommutative]] on elements of ''V'', for supposing that {{nowrap|''x'', ''y'' ∈ ''V''}},\n\n:<math>0 = (x+y)\\wedge (x+y) = x\\wedge x + x\\wedge y + y\\wedge x + y\\wedge y = x\\wedge y + y\\wedge x</math>\n\nhence\n\n:<math> x \\wedge y = - ( y \\wedge x ) .</math>\n\nMore generally, if ''σ'' is a [[permutation group|permutation]] of the integers {{nowrap|[1, ..., ''k'']}}, and ''x''<sub>1</sub>, ''x''<sub>2</sub>, ..., ''x''<sub>''k''</sub> are elements of ''V'', it follows that\n\n:<math>x_{\\sigma(1)}\\wedge x_{\\sigma(2)}\\wedge\\cdots\\wedge x_{\\sigma(k)} = \\operatorname{sgn}(\\sigma)x_1\\wedge x_2\\wedge\\cdots \\wedge x_k,</math>\n\nwhere sgn(''σ'') is the [[signature of a permutation|signature of the permutation]] ''σ''.<ref>A proof of this can be found in more generality in {{harvtxt|Bourbaki|1989}}.</ref>\n\nIn particular, if ''x''<sub>''i''</sub> = ''x''<sub>''j''</sub> for some {{nowrap|''i'' ≠ ''j''}}, then the following generalization of the alternating property also holds:\n:<math>x_{1}\\wedge x_{2}\\wedge\\cdots\\wedge x_{k} = 0.</math>\n\n===Exterior power===\n\nThe ''k''th '''exterior power''' of ''V'', denoted Λ<sup>''k''</sup>(''V''), is the [[vector subspace]] of Λ(''V'') [[linear span|spanned]] by elements of the form\n:<math>x_1\\wedge x_2\\wedge\\cdots\\wedge x_k,\\quad x_i\\in V, i=1,2,\\ldots, k.</math>\n\nIf {{nowrap|''α'' ∈ Λ<sup>''k''</sup>(''V'')}}, then ''α'' is said to be a '''[[p-vector|''k''-vector]]'''. If, furthermore, ''α'' can be expressed as an exterior product of ''k'' elements of ''V'', then ''α'' is said to be '''decomposable'''. Although decomposable ''k''-vectors span Λ<sup>''k''</sup>(''V''), not every element of Λ<sup>''k''</sup>(''V'') is decomposable. For example, in '''R'''<sup>4</sup>, the following 2-vector is not decomposable:\n:<math>\\alpha = e_1\\wedge e_2 + e_3\\wedge e_4.</math>\n(This is a [[symplectic form]], since {{nowrap|''α'' ∧ ''α'' ≠ 0}}.<ref>See {{harvtxt|Sternberg|1964|loc=§III.6}}.</ref>)\n\n====Basis and dimension====\n\nIf the [[dimension (linear algebra)|dimension]] of ''V'' is ''n'' and {{nowrap|{''e''<sub>1</sub>, ..., ''e''<sub>''n''</sub>}{{void}}}} is a [[basis (linear algebra)|basis]] of ''V'', then the set\n:<math>\\{e_{i_1}\\wedge e_{i_2}\\wedge\\cdots\\wedge e_{i_k} \\mid 1\\le i_1 < i_2 < \\cdots < i_k \\le n\\}</math>\nis a basis for Λ<sup>''k''</sup>(''V''). The reason is the following: given any exterior product of the form\n:<math>v_1\\wedge\\cdots\\wedge v_k ,</math>\nevery vector ''v''<sub>''j''</sub> can be written as a [[linear combination]] of the basis vectors ''e''<sub>''i''</sub>; using the bilinearity of the exterior product, this can be expanded to a linear combination of exterior products of those basis vectors. Any exterior product in which the same basis vector appears more than once is zero; any exterior product in which the basis vectors do not appear in the proper order can be reordered, changing the sign whenever two basis vectors change places. In general, the resulting coefficients of the basis ''k''-vectors can be computed as the [[minor (linear algebra)|minor]]s of the [[matrix (mathematics)|matrix]] that describes the vectors ''v''<sub>''j''</sub> in terms of the basis ''e''<sub>''i''</sub>.\n\nBy counting the basis elements, the dimension of Λ<sup>''k''</sup>(''V'') is equal to a [[binomial coefficient]]:\n:<math>\\dim \\Lambda^k(V) = \\binom{n}{k} .</math>\nIn particular, {{nowrap|1=Λ<sup>''k''</sup>(''V'') = {0}{{void}}}} for {{nowrap|''k'' > ''n''}}.\n\nAny element of the exterior algebra can be written as a sum of [[p-vector|''k''-vector]]s. Hence, as a vector space the exterior algebra is a [[Direct sum of modules|direct sum]]\n:<math>\\Lambda(V) = \\Lambda^0(V)\\oplus \\Lambda^1(V) \\oplus \\Lambda^2(V) \\oplus \\cdots \\oplus \\Lambda^n(V)</math>\n(where by convention {{nowrap|1=Λ<sup>0</sup>(''V'') = ''K''}} and {{nowrap|1=Λ<sup>1</sup>(''V'') = ''V''}}), and therefore its dimension is equal to the sum of the binomial coefficients, which is 2<sup>''n''</sup>.\n\n====Rank of a ''k''-vector====\n\nIf {{nowrap|''α'' ∈ Λ<sup>''k''</sup>(''V'')}}, then it is possible to express ''α'' as a linear combination of decomposable [[p-vector|''k''-vector]]s:\n\n:<math> \\alpha = \\alpha^{(1)} + \\alpha^{(2)} + \\cdots + \\alpha^{(s)}</math>\n\nwhere each ''α''<sup>(''i'')</sup> is decomposable, say\n\n:<math>\\alpha^{(i)} = \\alpha^{(i)}_1\\wedge\\cdots\\wedge\\alpha^{(i)}_k,\\quad i=1,2,\\ldots, s.</math>\n\nThe '''rank''' of the ''k''-vector ''α'' is the minimal number of decomposable ''k''-vectors in such an expansion of ''α''. This is similar to the notion of [[tensor rank]].\n\nRank is particularly important in the study of 2-vectors {{harv|Sternberg|1974|loc=§III.6}} {{harv|Bryant|Chern|Gardner|Goldschmidt|1991}}. The rank of a 2-vector ''α'' can be identified with half the [[rank of a matrix|rank of the matrix]] of coefficients of ''α'' in a basis. Thus if ''e''<sub>''i''</sub> is a basis for ''V'', then ''α'' can be expressed uniquely as\n\n:<math>\\alpha = \\sum_{i,j}a_{ij}e_i\\wedge e_j</math>\n\nwhere {{nowrap|1=''a''<sub>''ij''</sub> = −''a''<sub>''ji''</sub>}} (the matrix of coefficients is [[skew-symmetric matrix|skew-symmetric]]). The rank of the matrix ''a''<sub>''ij''</sub> is therefore even, and is twice the rank of the form ''α''.\n\nIn characteristic 0, the 2-vector ''α'' has rank ''p'' if and only if\n\n:<math>\\underset{p}{\\underbrace{\\alpha\\wedge\\cdots\\wedge\\alpha}}\\not= 0</math>\n\nand\n\n:<math>\\underset{p+1}{\\underbrace{\\alpha\\wedge\\cdots\\wedge\\alpha}} = 0.</math>\n\n===Graded structure===\nThe exterior product of a ''k''-vector with a ''p''-vector is a {{nowrap|(''k'' + ''p'')}}-vector, once again invoking bilinearity. As a consequence, the direct sum decomposition of the preceding section\n\n:<math>\\Lambda(V) = \\Lambda^0(V)\\oplus \\Lambda^1(V) \\oplus \\Lambda^2(V) \\oplus \\cdots \\oplus \\Lambda^n(V)</math>\n\ngives the exterior algebra the additional structure of a [[graded algebra]], that is\n\n:<math>\\Lambda^k(V)\\wedge\\Lambda^p(V)\\sub \\Lambda^{k+p}(V).</math>\n\nMoreover, if {{math|''K''}} is the basis field, we have\n:<math>\\Lambda^0(V)=K</math>\nand\n:<math>\\Lambda^1(V)=V.</math>\n\nThe exterior product is graded anticommutative, meaning that if {{nowrap|''α'' ∈ Λ<sup>''k''</sup>(''V'')}} and {{nowrap|''β'' ∈ Λ<sup>''p''</sup>(''V'')}}, then\n\n:<math>\\alpha\\wedge\\beta = (-1)^{kp}\\beta\\wedge\\alpha.</math>\n\nIn addition to studying the graded structure on the exterior algebra, {{harvtxt|Bourbaki|1989}} studies additional graded structures on exterior algebras, such as those on the exterior algebra of a [[graded module]] (a module that already carries its own gradation).\n\n===Universal property===\nLet {{math|''V''}} be a vector space over the field {{math|''K''}}. Informally, multiplication in {{math|Λ(''V'')}} is performed by manipulating symbols and imposing a [[distributive law]], an [[associative law]], and using the identity {{math|1=''v'' ∧ ''v'' = 0}} for {{math|''v'' ∈ ''V''}}. Formally, {{math|Λ(''V'')}} is the \"most general\" algebra in which these rules hold for the multiplication, in the sense that any unital associative {{math|''K''}}-algebra containing {{math|''V''}} with alternating multiplication on {{math|''V''}} must contain a homomorphic image of {{math|Λ(''V'')}}. In other words, the exterior algebra has the following [[universal property]]:<ref>See {{harvtxt|Bourbaki|1989|loc=§III.7.1}}, and {{harvtxt|Mac Lane|Birkhoff|1999|loc=Theorem XVI.6.8}}. More detail on universal properties in general can be found in {{harvtxt|Mac Lane|Birkhoff|1999|loc=Chapter VI}}, and throughout the works of Bourbaki.</ref>\n\n<div style=\"margin-left: 2em; margin-right: 2em\">\nGiven any unital associative {{math|''K''}}-algebra {{math|''A''}} and any {{math|''K''}}-[[linear map]] {{math|1=''j'' : ''V'' → ''A''}} such that {{math|1=''j''(''v'')''j''(''v'') = 0}} for every {{math|''v''}} in {{math|''V''}}, then there exists ''precisely one'' unital [[algebra homomorphism]] {{math|1=''f'' : Λ(''V'') → ''A''}} such that {{math|1=''j''(''v'') = ''f''(''i''(''v''))}} for all {{math|''v''}} in {{math|''V''}} (here {{math|''i''}} is the natural inclusion of {{math|''V''}} in {{math|Λ(''V'')}}, see above).\n</div>\n\n[[Image:ExteriorAlgebra-01.png|center|Universal property of the exterior algebra]]\n\nTo construct the most general algebra that contains {{math|''V''}} and whose multiplication is alternating on {{math|''V''}}, it is natural to start with the most general associative algebra that contains {{math|''V''}}, the [[tensor algebra]] {{math|''T''(''V'')}}, and then enforce the alternating property by taking a suitable [[quotient ring|quotient]]. We thus take the two-sided [[ideal (ring theory)|ideal]] {{math|''I''}} in {{math|''T''(''V'')}} generated by all elements of the form {{math|''v'' ⊗ ''v''}} for {{math|''v''}} in {{math|''V''}}, and define {{math|Λ(''V'')}} as the quotient\n\n:<math>\\Lambda(V) = T(V)/I\\ </math>\n\n(and use {{math|∧}} as the symbol for multiplication in {{math|Λ(''V''))}}. It is then straightforward to show that {{math|Λ(''V'')}} contains {{math|''V''}} and satisfies the above universal property.\n\nAs a consequence of this construction, the operation of assigning to a vector space {{math|''V''}} its exterior algebra {{math|Λ(''V'')}} is a [[functor]] from the [[category (mathematics)|category]] of vector spaces to the category of algebras.\n\nRather than defining {{math|Λ(''V'')}} first and then identifying the exterior powers {{math|Λ<sup>''k''</sup>(''V'')}} as certain subspaces, one may alternatively define the spaces {{math|Λ<sup>''k''</sup>(''V'')}} first and then combine them to form the algebra {{math|Λ(''V'')}}. This approach is often used in differential geometry and is described in the next section.\n\n===Generalizations===\n\nGiven a [[commutative ring]] ''R'' and an ''R''-[[module (mathematics)|module]] ''M'', we can define the exterior algebra Λ(''M'') just as above, as a suitable quotient of the tensor algebra '''T'''(''M''). It will satisfy the analogous universal property. Many of the properties of Λ(''M'') also require that ''M'' be a [[projective module]]. Where finite dimensionality is used, the properties further require that ''M'' be [[finitely generated module|finitely generated]] and projective. Generalizations to the most common situations can be found in {{harv|Bourbaki|1989}}.\n\nExterior algebras of [[vector bundle]]s are frequently considered in geometry and topology. There are no essential differences between the algebraic properties of the exterior algebra of finite-dimensional vector bundles and those of the exterior algebra of finitely generated projective modules, by the [[Serre–Swan theorem]]. More general exterior algebras can be defined for [[sheaf (mathematics)|sheaves]] of modules.\n\n==Duality==\n\n===Alternating operators===\n\nGiven two vector spaces ''V'' and ''X'', an '''alternating operator''' from ''V''<sup>''k''</sup> to ''X'' is a [[multilinear map]]\n\n:<math> f\\colon V^k \\to X </math>\n\nsuch that whenever ''v''<sub>1</sub>, ..., ''v''<sub>''k''</sub> are [[linearly dependent]] vectors in ''V'', then\n\n:<math> f(v_1,\\ldots, v_k)=0</math>\n\nThe map\n\n:<math> w\\colon V^k \\to \\Lambda^k(V) </math>\n\nwhich associates to ''k'' vectors from ''V'' their exterior product, i.e. their corresponding ''k''-vector, is also alternating. In fact, this map is the \"most general\" alternating operator defined on ''V''<sup>''k''</sup>: given any other alternating operator {{nowrap|''f'' : ''V''<sup>''k''</sup> → ''X''}}, there exists a unique [[linear map]] {{nowrap|''φ'' : Λ<sup>''k''</sup>(''V'') → ''X''}} with {{nowrap|1=''f'' = ''φ'' ∘ ''w''}}. This [[universal property]] characterizes the space Λ<sup>''k''</sup>(''V'') and can serve as its definition.\n\n=== Alternating multilinear forms ===\n<!-- Alternating form redirects here -->\n\n[[File:N-form.svg|thumb|125px|Geometric interpretation for the '''exterior product''' of ''n'' [[1-form]]s ('''ε''', '''η''', '''ω''') to obtain an ''n''-form (\"mesh\" of [[coordinate surface]]s, here planes),<ref>{{cite book |author=R. Penrose| title=[[The Road to Reality]]| publisher= Vintage books| year=2007 | isbn=0-679-77631-1}}</ref> for {{nowrap|1=''n'' = 1, 2, 3}}. The \"circulations\" show [[Orientation (vector space)|orientation]].<ref>{{cite book|title=Gravitation|author1=J.A. Wheeler |author2=C. Misner |author3=K.S. Thorne |publisher=W.H. Freeman & Co|year=1973|pages=58–60, 83, 100–109, 115–119|isbn=0-7167-0344-0}}</ref>]]\n\nThe above discussion specializes to the case when {{nowrap|1=''X'' = ''K''}}, the base field. In this case an alternating multilinear function\n:<math>f : V^k \\to K\\ </math>\nis called an '''alternating multilinear form'''. The set of all [[Alternating map|alternating]] [[Multilinear form|multilinear forms]] is a vector space, as the sum of two such maps, or the product of such a map with a scalar, is again alternating. By the universal property of the exterior power, the space of alternating forms of degree ''k'' on ''V'' is [[natural transformation|naturally]] isomorphic with the [[dual vector space]] (Λ<sup>''k''</sup>''V'')<sup>∗</sup>.  If ''V'' is finite-dimensional, then the latter is naturally isomorphic to  Λ<sup>''k''</sup>(''V''<sup>∗</sup>). In particular, the dimension of the space of alternating maps from ''V''<sup>''k''</sup> to ''K'' is [[binomial coefficient|''n'' choose ''k'']].\n\nUnder this identification, the exterior product takes a concrete form: it produces a new anti-symmetric map from two given ones. Suppose {{nowrap|''ω'' : ''V''<sup>''k''</sup> → ''K''}} and {{nowrap|''η'' : ''V''<sup>''m''</sup> → ''K''}} are two anti-symmetric maps. As in the case of [[tensor product]]s of multilinear maps, the number of variables of their exterior product is the sum of the numbers of their variables. It is defined as follows:<ref>Some conventions, particularly in physics, define the exterior product as\n\n:<math>\\omega\\wedge\\eta=\\operatorname{Alt}(\\omega\\otimes\\eta).</math>\n\nThis convention is not adopted here, but is discussed in connection with [[Exterior algebra#Alternating tensor algebra|alternating tensors]].</ref>\n\n:<math>\\omega\\wedge\\eta=\\frac{(k+m)!}{k!\\,m!}\\operatorname{Alt}(\\omega\\otimes\\eta),</math>\n\nwhere the alternation Alt of a multilinear map is defined to be the average of the sign-adjusted values over all the [[permutation]]s of its variables:\n\n:<math>\\operatorname{Alt}(\\omega)(x_1,\\ldots,x_k)=\\frac{1}{k!}\\sum_{\\sigma\\in S_k}\\operatorname{sgn}(\\sigma)\\,\\omega(x_{\\sigma(1)},\\ldots,x_{\\sigma(k)}).</math>\n\nThis definition of the exterior product is well-defined even if the [[field (mathematics)|field]] ''K'' has [[characteristic of a field|finite characteristic]], if one considers an equivalent version of the above that does not use factorials or any constants:\n\n:<math>{\\omega \\wedge \\eta(x_1,\\ldots,x_{k+m})} = \\sum_{\\sigma \\in Sh_{k,m}} \\operatorname{sgn}(\\sigma)\\,\\omega(x_{\\sigma(1)}, \\ldots, x_{\\sigma(k)}) \\eta(x_{\\sigma(k+1)}, \\ldots, x_{\\sigma(k+m)}),</math>\n\nwhere here {{nowrap|Sh<sub>''k'',''m''</sub> ⊂ ''S''<sub>''k''+''m''</sub>}} is the subset of [[(p,q) shuffle|(''k'',''m'') shuffles]]: [[permutation]]s ''σ'' of the set {{nowrap|{1, 2, ..., ''k'' + ''m''}{{void}}}} such that {{nowrap|''σ''(1) < ''σ''(2) < ... < ''σ''(''k'')}}, and {{nowrap|''σ''(''k'' + 1) < ''σ''(''k'' + 2) < ... < ''σ''(''k'' + ''m'')}}.\n\n===Bialgebra structure===\nThere is a correspondence between the graded dual of the graded algebra Λ(''V'') and alternating multilinear forms on ''V''. The exterior algebra (as well as the [[symmetric algebra]]) inherits a bialgebra structure, and, indeed, a [[Hopf algebra]] structure, from the [[tensor algebra]]. See the article on [[tensor algebra]]s for a detailed treatment of the topic.\n\nThe exterior product of multilinear forms defined above is dual to a [[coproduct]] defined on Λ(''V''), giving the structure of a [[coalgebra]]. The '''coproduct''' is a linear function {{nowrap|Δ : Λ(''V'') → Λ(''V'') ⊗ Λ(''V'')}} which is given by\n:<math>\\Delta(v) = 1 \\otimes v + v \\otimes 1</math>\n\non elements ''v''∈''V''. The symbol 1 stands for the unit element of the field ''K''. Recall that {{nowrap|''K'' ⊂ Λ(''V''),}} so that the above really does lie in {{nowrap|Λ(''V'') ⊗ Λ(''V'').}} This definition of the coproduct is extended to the full space Λ(''V'') by (linear) homomorphism. That is, for ''v'',''w''∈''V'', one has, by definition, the homomorphism\n:<math>\\Delta(v\\wedge w)= \\Delta(v) \\wedge \\Delta(w)</math>\n\nThe correct form of this homomorphism is not what one might naively write, but has to be the one carefully defined in the [[coalgebra]] article.  In this case, one obtains\n:<math>\n\\Delta(v \\wedge w) = 1 \\otimes (v \\wedge w) + v \\otimes w - w \\otimes v + (v \\wedge w) \\otimes 1.\n</math>\n\nExtending to the full space Λ(''V''), one has, in general,\n:<math>\\Delta(x_1\\wedge\\cdots\\wedge x_k) = \\Delta(x_1) \\wedge\\cdots \\wedge \\Delta(x_k)</math>\n\nExpanding this out in detail, one obtains the following expression on decomposable elements:\n:<math>\\Delta(x_1\\wedge\\cdots\\wedge x_k) = \\sum_{p=0}^k \\; \\sum_{\\sigma\\in Sh(p+1,k-p)} \\; \\operatorname{sgn}(\\sigma) (x_{\\sigma(0)}\\wedge\\cdots\\wedge x_{\\sigma(p)})\\otimes (x_{\\sigma(p+1)}\\wedge\\cdots\\wedge x_{\\sigma(k)}).</math>\n\nwhere the second summation is taken over all [[(p,q) shuffle|{{nowrap|(''p''+1, ''k''−''p'')}}-shuffles]].  The above is written with a notational trick, to keep track of the field element 1: the trick is to write <math>x_0=1</math>, and this is shuffled into various locations during the expansion of the sum over shuffles.  The shuffle follows directly from the first axiom of a co-algebra: the relative order of the elements <math>x_k</math> is ''preserved'' in the riffle shuffle: the riffle shuffle merely splits the ordered sequence into two ordered sequences, one on the left, and one on the right.\n\nObserve that the coproduct preserves the grading of the algebra. That is, one has that\n:<math>\\Delta:\\Lambda^k(V) \\to \\bigoplus_{p=0}^k \\Lambda^p(V) \\otimes\\Lambda^{k-p}(V)</math>\n\nThe tensor symbol ⊗ used in this section should be understood with some caution: it is ''not'' the same tensor symbol as the one being used in the definition of the alternating product.  Intuitively, it is perhaps easiest to think it as just another, but different, tensor product: it is still (bi-)linear, as tensor products should be, but it is the product that is appropriate for the definition of a bialgebra, that is, for creating the object {{nowrap|Λ(''V'') ⊗ Λ(''V'').}} Any lingering doubt can be shaken by pondering the equalities {{nowrap|1=(1 ⊗ ''v'') ∧ (1 ⊗ ''w'') = 1 ⊗ (''v'' ∧ ''w'')}} and {{nowrap|1=(''v'' ⊗ 1) ∧ (1 ⊗ ''w'') = ''v'' ⊗ ''w''}}, which follow from the definition of the coalgebra, as opposed to naive manipulations involving the tensor and wedge symbols. This distinction is developed in greater detail in the article on [[tensor algebra]]s. Here, there is much less of a problem, in that the alternating product Λ clearly corresponds to multiplication in the bialgebra, leaving the symbol ⊗ free for use in the definition of the bialgebra. In practice, this presents no particular problem, as long as one avoids the fatal trap of replacing alternating sums of ⊗ by the wedge symbol, with one exception. One can construct an alternating product from ⊗, with the understanding that it works in a different space. Immediately below, an example is given: the alternating product for the ''dual space'' can be given in terms of the coproduct. The construction of the bialgebra here parallels the construction in the [[tensor algebra]] article almost exactly, except for the need to correctly track the alternating signs for the exterior algebra.\n\nIn terms of the coproduct, the exterior product on the dual space is just the graded dual of the coproduct:\n\n:<math>(\\alpha\\wedge\\beta)(x_1\\wedge\\cdots\\wedge x_k) = (\\alpha\\otimes\\beta)\\left(\\Delta(x_1\\wedge\\cdots\\wedge x_k)\\right)</math>\n\nwhere the tensor product on the right-hand side is of multilinear linear maps (extended by zero on elements of incompatible homogeneous degree: more precisely, {{nowrap|1=''α'' ∧ ''β'' = ''ε'' ∘ (''α'' ⊗ ''β'') ∘ Δ}}, where ''ε'' is the counit, as defined presently).\n\nThe '''counit''' is the homomorphism {{nowrap|1=''ε'' : Λ(''V'') → ''K''}} that returns the 0-graded component of its argument. The coproduct and counit, along with the exterior product, define the structure of a [[bialgebra]] on the exterior algebra.\n\nWith an '''antipode''' defined on homogeneous elements by <math>S(x)=(-1)^{\\binom{\\text{deg}\\,  x\\, +1}{2}}x</math>, the exterior algebra is furthermore a [[Hopf algebra]].<ref>Indeed, the exterior algebra of ''V'' is the [[Universal enveloping algebra|enveloping algebra]] of the abelian [[Lie superalgebra]] structure on ''V''.</ref>\n\n===Interior product===\n{{See also|Interior product}}\nSuppose that ''V'' is finite-dimensional. If ''V''<sup>∗</sup> denotes the [[dual space]] to the vector space ''V'', then for each {{nowrap|''α'' ∈ ''V''<sup>∗</sup>}}, it is possible to define an [[derivation (abstract algebra)|antiderivation]] on the algebra Λ(''V''),\n\n:<math>i_\\alpha:\\Lambda^k V\\rightarrow\\Lambda^{k-1}V.</math>\n\nThis derivation is called the '''interior product''' with ''α'', or sometimes the '''insertion operator''', or '''contraction''' by ''α''.\n\nSuppose that {{nowrap|'''w''' ∈ Λ<sup>''k''</sup>''V''}}. Then '''w''' is a multilinear mapping of ''V''<sup>∗</sup> to ''K'', so it is defined by its values on the ''k''-fold [[Cartesian product]] {{nowrap|''V''<sup>∗</sup> × ''V''<sup>∗</sup> × ... × ''V''<sup>∗</sup>}}. If ''u''<sub>1</sub>, ''u''<sub>2</sub>, ..., ''u''<sub>''k''−1</sub> are {{nowrap|''k'' − 1}} elements of ''V''<sup>∗</sup>, then define\n\n:<math>(i_\\alpha {\\mathbf w})(u_1,u_2,\\ldots,u_{k-1})={\\mathbf w}(\\alpha,u_1,u_2,\\ldots, u_{k-1}).</math>\n\nAdditionally, let {{nowrap|1=''i''<sub>''α''</sub>''f'' = 0}} whenever ''f'' is a pure scalar (i.e., belonging to Λ<sup>0</sup>''V'').\n\n====Axiomatic characterization and properties====\nThe interior product satisfies the following properties:\n\n# For each ''k'' and each {{nowrap|''α'' ∈ ''V''<sup>∗</sup>}},\n#::<math>i_\\alpha:\\Lambda^kV\\rightarrow \\Lambda^{k-1}V.</math>\n#:(By convention, {{nowrap|1=Λ<sup>−1</sup>''V'' = {0}.}})\n# If ''v'' is an element of ''V'' (= Λ<sup>1</sup>''V''), then {{nowrap|1=''i''<sub>''α''</sub>''v'' = ''α''(''v'')}} is the dual pairing between elements of ''V'' and elements of ''V''<sup>∗</sup>.\n# For each {{nowrap|''α'' ∈ ''V''<sup>∗</sup>}}, ''i''<sub>''α''</sub> is a [[graded derivation]] of degree −1:\n#::<math>i_\\alpha (a\\wedge b) = (i_\\alpha a)\\wedge b + (-1)^{\\deg a}a\\wedge (i_\\alpha b).</math>\n\nThese three properties are sufficient to characterize the interior product as well as define it in the general infinite-dimensional case.\n\nFurther properties of the interior product include:\n:* <math>i_\\alpha\\circ i_\\alpha = 0.</math>\n:* <math>i_\\alpha\\circ i_\\beta = -i_\\beta\\circ i_\\alpha.</math>\n<!--\nIt may be worth saying something about this, but has already been mentioned in passing above.\n\n===The duality isomorphism===\nIn general, there are two different kinds of alternating structures defined via duality:\n* The structure of alternating multilinear forms on Λ(''V''). The space of all such forms is the graded dual Λ(''V'')<sup>∗</sup>, and the product of such forms dualizes the coproduct on the exterior algebra.\n* The exterior algebra of the dual vector space Λ(''V''<sup>∗</sup>).\nIf ''V'' is finite-dimensional, then these two exterior algebras are naturally isomorphic.\n-->\n\n===Hodge duality===\n{{main article|Hodge star operator}}\nSuppose that ''V'' has finite dimension ''n''. Then the interior product induces a canonical isomorphism of vector spaces\n:<math>\\Lambda^k(V^*) \\otimes \\Lambda^n(V) \\to \\Lambda^{n-k}(V) </math>\nby the recursive definition\n:<math>i_{\\alpha \\wedge \\beta} = i_\\beta \\circ i_\\alpha .</math>\n\nIn the geometrical setting, a non-zero element of the top exterior power Λ<sup>''n''</sup>(''V'') (which is a one-dimensional vector space) is sometimes called a '''[[volume form]]''' (or '''orientation form''', although this term may sometimes lead to ambiguity). The name orientation form comes from the fact that a choice of preferred top element determines an orientation of the whole exterior algebra, since it is tantamount to fixing an ordered basis of the vector space. Relative to the preferred volume form ''σ'', the isomorphism between an element <math>\\alpha \\in \\wedge^k(V^*)</math>and its Hodge dual is given explicitly by\n\n:<math> \\Lambda^k(V^*) \\to \\Lambda^{n-k}(V) : \\alpha \\mapsto i_\\alpha\\sigma .</math>\n\nIf, in addition to a volume form, the vector space ''V'' is equipped with an [[inner product]] identifying ''V'' with ''V''<sup>∗</sup>, then the resulting isomorphism is called the '''Hodge star operator''', which maps an element to its '''Hodge dual''':\n\n:<math>\\star : \\Lambda^k(V) \\rightarrow \\Lambda^{n-k}(V) .</math>\n\nThe composition of <math>\\star</math> with itself maps {{nowrap|Λ<sup>''k''</sup>(''V'') → Λ<sup>''k''</sup>(''V'')}} and is always a scalar multiple of the identity map. In most applications, the volume form is compatible with the inner product in the sense that it is an exterior product of an [[orthonormal basis]] of ''V''. In this case,\n:<math>\\star \\circ \\star : \\Lambda^k(V) \\to \\Lambda^k(V) = (-1)^{k(n-k) + q}\\mathrm{id}</math>\nwhere id is the identity mapping, and the inner product has [[metric signature]] {{nowrap|(''p'', ''q'')}} — ''p'' pluses and ''q'' minuses.\n\n===Inner product===\nFor ''V'' a finite-dimensional space, an [[inner product]] on ''V'' defines an isomorphism of ''V'' with ''V''<sup>∗</sup>, and so also an isomorphism of Λ<sup>''k''</sup>''V'' with (Λ<sup>''k''</sup>''V'')<sup>∗</sup>.  The pairing between these two spaces also takes the form of an inner product.  On decomposable ''k''-vectors,\n:<math>\\left\\langle v_1\\wedge\\cdots\\wedge v_k, w_1\\wedge\\cdots\\wedge w_k\\right\\rangle = \\det(\\langle v_i,w_j\\rangle),</math>\nthe determinant of the matrix of inner products.  In the special case {{nowrap|1=''v''<sub>''i''</sub> = ''w''<sub>''i''</sub>}}, the inner product is the square norm of the ''k''-vector, given by the determinant of the [[Gramian matrix]] {{nowrap|({{langle}}''v''<sub>''i''</sub>, ''v''<sub>''j''</sub>{{rangle}})}}.  This is then extended bilinearly (or sesquilinearly in the complex case) to a non-degenerate inner product on Λ<sup>''k''</sup>''V''.  If ''e''<sub>''i''</sub>, {{nowrap|1=''i'' = 1, 2, ..., ''n''}}, form an [[orthonormal basis]] of ''V'', then the vectors of the form\n:<math>e_{i_1}\\wedge\\cdots\\wedge e_{i_k},\\quad i_1 < \\cdots < i_k,</math>\nconstitute an orthonormal basis for Λ<sup>''k''</sup>(''V'').\n\nWith respect to the inner product, exterior multiplication and the interior product are mutually adjoint.  Specifically, for {{nowrap|'''v''' ∈ Λ<sup>''k''&minus;1</sup>(''V'')}}, {{nowrap|'''w''' ∈ Λ<sup>''k''</sup>(''V'')}}, and {{nowrap|''x'' ∈ ''V''}},\n:<math>\\langle x\\wedge\\mathbf{v}, \\mathbf{w}\\rangle = \\langle \\mathbf{v}, i_{x^\\flat}\\mathbf{w}\\rangle</math>\nwhere {{nowrap|''x''<sup>♭</sup> ∈ ''V''<sup>∗</sup>}} is the linear functional defined by\n:<math>x^\\flat(y) = \\langle x, y\\rangle</math>\nfor all {{nowrap|''y'' ∈ ''V''}}.  This property completely characterizes the inner product on the exterior algebra.\n\nIndeed, more generally for {{nowrap|'''v''' ∈ Λ<sup>''k''&minus;''l''</sup>(''V'')}}, {{nowrap|'''w''' ∈ Λ<sup>''k''</sup>(''V'')}}, and {{nowrap|'''x''' ∈ Λ<sup>''l''</sup>(''V'')}}, iteration of the above adjoint properties gives\n:<math>\\langle \\mathbf{x} \\wedge\\mathbf{v}, \\mathbf{w}\\rangle = \\langle \\mathbf{v}, i_{\\mathbf{x}^\\flat}\\mathbf{w}\\rangle</math>\nwhere now {{nowrap|'''x'''<sup>♭</sup> ∈ Λ<sup>''l''</sup>(''V''<sup>∗</sup>) ≃ (Λ<sup>''l''</sup>(''V''))<sup>∗</sup>}} is the dual ''l''-vector defined by\n:<math>\\mathbf{x}^\\flat(\\mathbf{y}) = \\langle \\mathbf{x}, \\mathbf{y}\\rangle</math>\nfor all {{nowrap|'''y''' ∈ Λ<sup>''l''</sup>(''V'')}}.\n\n==Functoriality==\nSuppose that ''V'' and ''W'' are a pair of vector spaces and {{nowrap|''f'' : ''V'' → ''W''}} is a [[linear transformation]]. Then, by the universal construction, there exists a unique homomorphism of graded algebras\n\n:<math>\\Lambda(f) : \\Lambda(V)\\rightarrow \\Lambda(W)</math>\n\nsuch that\n\n:<math>\\Lambda(f)\\left|_{\\Lambda^1(V)}\\right. = f : V=\\Lambda^1(V)\\rightarrow W=\\Lambda^1(W).</math>\n\nIn particular, Λ(''f'') preserves homogeneous degree. The ''k''-graded components of Λ(''f'') are given on decomposable elements by\n:<math>\\Lambda(f)(x_1\\wedge \\cdots \\wedge x_k) = f(x_1)\\wedge\\cdots\\wedge f(x_k).</math>\n\nLet\n\n:<math>\\Lambda^k(f) = \\Lambda(f)\\left|_{\\Lambda^k(V)}\\right. : \\Lambda^k(V) \\rightarrow \\Lambda^k(W).</math>\n\nThe components of the transformation Λ(''f'') relative to a basis of ''V'' and ''W'' is the matrix of {{nowrap|''k'' × ''k''}} minors of ''f''. In particular, if {{nowrap|1=''V'' = ''W''}} and ''V'' is of finite dimension ''n'', then Λ<sup>''n''</sup>(''f'') is a mapping of a one-dimensional vector space Λ<sup>''n''</sup>''V'' to itself, and is therefore given by a scalar: the [[determinant]] of ''f''.\n\n===Exactness===\nIf\n\n:<math>0\\rightarrow U\\rightarrow V\\rightarrow W\\rightarrow 0</math>\n\nis a [[short exact sequence]] of vector spaces, then\n\n:<math>0\\to \\Lambda^1(U)\\wedge\\Lambda(V) \\to \\Lambda(V)\\rightarrow \\Lambda(W)\\rightarrow 0</math>\n\nis an exact sequence of graded vector spaces<ref>This part of the statement also holds in greater generality if ''V'' and ''W'' are modules over a commutative ring: That Λ converts epimorphisms to epimorphisms. See {{harvtxt|Bourbaki|1989|loc=Proposition 3, §III.7.2}}.</ref> as is\n:<math>0\\to \\Lambda(U)\\to\\Lambda(V).</math><ref>This statement generalizes only to the case where ''V'' and ''W'' are projective modules over a commutative ring. Otherwise, it is generally not the case that Λ converts monomorphisms to monomorphisms. See {{harvtxt|Bourbaki|1989|loc=Corollary to Proposition 12, §III.7.9}}.</ref>\n\n=== Direct sums ===\nIn particular, the exterior algebra of a direct sum is isomorphic to the tensor product of the exterior algebras:\n\n:<math>\\Lambda(V\\oplus W)\\cong\\Lambda(V)\\otimes\\Lambda(W).</math>\n\nThis is a graded isomorphism; i.e.,\n\n:<math>\\Lambda^k(V\\oplus W)\\cong\\bigoplus_{p+q=k} \\Lambda^p(V)\\otimes\\Lambda^q(W).</math>\n\nSlightly more generally, if\n\n:<math>0\\rightarrow U\\rightarrow V\\rightarrow W\\rightarrow 0</math>\n\nis a [[short exact sequence]] of vector spaces then Λ''<sup>k</sup>(V)'' has a [[Filtration (mathematics)|filtration]]\n\n:<math>0 = F^0 \\subseteq F^1 \\subseteq \\cdots \\subseteq F^k \\subseteq F^{k+1} = \\Lambda^k(V)</math>\n\nwith quotients :<math>F^{p+1}/F^p = \\Lambda^{k-p}(U) \\otimes \\Lambda^p(W)</math>. In particular, if ''U'' is 1-dimensional then\n\n:<math>0\\rightarrow U \\otimes \\Lambda^{k-1}(W) \\rightarrow \\Lambda^k(V)\\rightarrow \\Lambda^k(W)\\rightarrow 0</math>\n\nis exact, and if ''W'' is 1-dimensional then\n\n:<math>0\\rightarrow \\Lambda^k(U) \\rightarrow \\Lambda^k(V)\\rightarrow \\Lambda^{k-1}(U) \\otimes W\\rightarrow 0</math>\n\nis exact.<ref>Such a filtration also holds for [[vector bundle]]s, and projective modules over a commutative ring. This is thus more general than the result quoted above for direct sums, since not every short exact sequence splits in other [[abelian category|abelian categories]].</ref>\n\n==Alternating tensor algebra==\nIf ''K'' is a field of characteristic 0,<ref>See {{harvtxt|Bourbaki|1989|loc=§III.7.5}} for generalizations.</ref> then the exterior algebra of a vector space ''V'' can be canonically identified with the vector subspace of T(''V'') consisting of [[antisymmetric tensor]]s. Recall that the exterior algebra is the quotient of T(''V'') by the ideal ''I'' generated by {{nowrap|''x'' ⊗ ''x''}}.\n\nLet T<sup>''r''</sup>(''V'') be the space of homogeneous tensors of degree ''r''. This is spanned by decomposable tensors\n\n:<math>v_1\\otimes\\cdots\\otimes v_r,\\quad v_i\\in V.</math>\n\nThe '''antisymmetrization''' (or sometimes the '''skew-symmetrization''') of a decomposable tensor is defined by\n\n:<math>\\operatorname{Alt}(v_1\\otimes\\cdots\\otimes v_r) = \\frac{1}{r!}\\sum_{\\sigma\\in\\mathfrak{S}_r} \\operatorname{sgn}(\\sigma) v_{\\sigma(1)}\\otimes\\cdots\\otimes v_{\\sigma(r)}</math>\n\nwhere the sum is taken over the [[symmetric group]] of permutations on the symbols {{nowrap|{1, ..., ''r''}.}} This extends by linearity and homogeneity to an operation, also denoted by Alt, on the full tensor algebra T(''V''). The image Alt(T(''V'')) is the '''alternating tensor algebra''', denoted A(''V''). This is a vector subspace of T(''V''), and it inherits the structure of a graded vector space from that on T(''V''). It carries an associative graded product <math>\\widehat{\\otimes}</math> defined by\n\n:<math>t~\\widehat{\\otimes}~s = \\operatorname{Alt}(t\\otimes s).</math>\n\nAlthough this product differs from the tensor product, the kernel of ''Alt'' is precisely the ideal ''I'' (again, assuming that ''K'' has characteristic 0), and there is a canonical isomorphism\n\n:<math>A(V)\\cong \\Lambda(V).</math>\n\n===Index notation===\nSuppose that ''V'' has finite dimension ''n'', and that a basis {{nowrap|'''e'''<sub>1</sub>, ..., '''e'''<sub>''n''</sub>}} of ''V'' is given. then any alternating tensor {{nowrap|''t'' ∈ A<sup>''r''</sup>(''V'') ⊂ ''T''<sup>''r''</sup>(''V'')}} can be written in [[index notation]] as\n\n:<math>t = t^{i_1i_2\\cdots i_r}\\, {\\mathbf e}_{i_1}\\otimes {\\mathbf e}_{i_2}\\otimes\\cdots\\otimes {\\mathbf e}_{i_r},</math>\n\nwhere ''t''<sup>''i''<sub>1</sub>⋅⋅⋅''i''<sub>''r''</sub></sup> is [[antisymmetric tensor|completely antisymmetric]] in its indices.\n\nThe exterior product of two alternating tensors ''t'' and ''s'' of ranks ''r'' and ''p'' is given by\n\n:<math>t~\\widehat{\\otimes}~s = \\frac{1}{(r+p)!}\\sum_{\\sigma\\in {\\mathfrak S}_{r+p}}\\operatorname{sgn}(\\sigma)t^{i_{\\sigma(1)}\\cdots i_{\\sigma(r)}} s^{i_{\\sigma(r+1)} \\cdots i_{\\sigma(r+p)}} {\\mathbf e}_{i_1}\\otimes {\\mathbf e}_{i_2} \\otimes \\cdots\\otimes {\\mathbf e}_{i_{r+p}}.</math>\n\nThe components of this tensor are precisely the skew part of the components of the tensor product {{nowrap|''s'' ⊗ ''t''}}, denoted by square brackets on the indices:\n\n:<math>(t~\\widehat{\\otimes}~s)^{i_1\\cdots i_{r+p}} = t^{[i_1\\cdots i_r}s^{i_{r+1}\\cdots i_{r+p}]}.</math>\n\n<!--For the interior product-->\nThe interior product may also be described in index notation as follows. Let <math>t = t^{i_0i_1\\cdots i_{r-1}}</math> be an antisymmetric tensor of rank ''r''. Then, for {{nowrap|''α'' ∈ ''V''<sup>∗</sup>}}, ''i''<sub>''α''</sub>''t'' is an alternating tensor of rank {{nowrap|''r'' − 1}}, given by\n\n:<math>(i_\\alpha t)^{i_1\\cdots i_{r-1}}=r\\sum_{j=0}^n\\alpha_j t^{ji_1\\cdots i_{r-1}}.</math>\n\nwhere ''n'' is the dimension of ''V''.\n\n==Applications==\n\n===Linear algebra===\nIn applications to [[linear algebra]], the exterior product provides an abstract algebraic manner for describing the [[determinant]] and the [[minor (matrix)|minors]] of a [[matrix (mathematics)|matrix]].  For instance, it is well known that the magnitude of the determinant of a square matrix is equal to the volume of the parallelotope whose sides are the columns of the matrix.  This suggests that the determinant can be ''defined'' in terms of the exterior product of the column vectors.  Likewise, the {{nowrap|''k'' × ''k''}} minors of a matrix can be defined by looking at the exterior products of column vectors chosen ''k'' at a time.  These ideas can be extended not just to matrices but to [[linear transformation]]s as well: the magnitude of the determinant of a linear transformation is the factor by which it scales the volume of any given reference parallelotope.  So the determinant of a linear transformation can be defined in terms of what the transformation does to the top exterior power.  The action of a transformation on the lesser exterior powers gives a [[basis of a vector space|basis]]-independent way to talk about the minors of the transformation.\n\n====Technical details: Definitions====\nLet<ref>S.Winitzki, ''Lineaer Algebra via Exterior Products'', https://sites.google.com/site/winitzki/linalg</ref> <math>V</math> be an ''n''-dimensional vector space over field <math>K</math> with basis <math>\\{e_1,\\ldots,e_n\\}</math>. \n* For <math>A \\in \\operatorname{End}(V)</math>, define <math>\\Lambda^k A \\in \\operatorname{End}(\\Lambda^k V) </math> on simple tensors by\n\n:: <math>\\Lambda^k A(v_1 \\wedge\\cdots\\wedge v_k)=Av_1 \\wedge \\cdots \\wedge Av_k </math>\n\n:and expand the definition linearly to all tensors. More generally, we can define <math>\\Lambda^p A^k \\in \\operatorname{End}(\\Lambda^p V), (p \\geq k) </math> on simple tensors by\n\n:: <math>(\\Lambda^p A^k)(v_1 \\wedge \\cdots \\wedge v_p)=\\sum_{0 \\leq i_1 < \\cdots < i_k \\leq p} v_1 \\wedge \\cdots \\wedge Av_{i_1} \\wedge \\cdots \\wedge Av_{i_k} \\wedge \\cdots \\wedge v_p</math>\n\n:i.e. choose ''k'' components on which ''A'' would act, then sum up all results obtained from different choices. If <math>p<k</math>, define <math>\\Lambda^pA^k=0 </math>. Since <math>\\Lambda^n V </math> is 1-dimensional with basis <math>e_1 \\wedge \\cdots \\wedge e_n</math>, we can identify <math>\\Lambda^n A^k </math> with the unique number <math>\\kappa \\in K </math> satisfying\n\n:: <math>\\Lambda^n A^k (e_1 \\wedge \\cdots \\wedge e_n) = \\kappa (e_1 \\wedge \\cdots \\wedge e_n) .</math>\n\n* For <math>\\varphi \\in \\operatorname{End}(\\Lambda^p V)</math>, define the '''exterior transpose''' <math>\\varphi^\\mathrm{T} \\in \\operatorname{End}(\\Lambda^{n-p} V)</math> to be the unique operator satisfying\n\n:: <math>\\forall \\omega_p \\in \\Lambda^p V, \\omega_{n-p} \\in \\Lambda^{n-p}V, (\\varphi^\\mathrm{T}\\omega_{n-p})\\wedge\\omega_p=\\omega_{n-p}\\wedge(\\varphi \\omega_p)</math>\n\n* For <math>A \\in \\operatorname{End}(V)</math>, define <math>\\det A=\\Lambda^n A^n, \\operatorname{Tr}(A)=\\Lambda^n A^1, \\operatorname{adj} A=(\\Lambda^{n-1} A^{n-1})^\\mathrm{T} </math>. These definitions is equivalent to the other versions.\n\n====Basic Properties====\nAll results obtained from other definitions of the determinant, trace and adjoint can be obtained from this definition (since these definitions are equivalent). Here are some basic properties related to these new definitions:\n\n* <math>(\\cdot)^\\mathrm{T}</math> is <math>K</math>-linear.\n\n* <math>(AB)^\\mathrm{T} = B^\\mathrm{T} A^\\mathrm{T}.</math>\n\n* We have a canonical isomorphism \n::<math>\\begin{cases}\\psi:\\operatorname{End}(\\Lambda^k V) \\cong \\operatorname{End}(\\Lambda^{n-k} V) \\\\ A \\mapsto A^\\mathrm{T} \\end{cases}</math>\n:However, there is no canonical isomorphism between <math>\\Lambda^k V</math> and <math>\\Lambda^{n-k} V.</math>\n\n* <math>\\operatorname{Tr}(\\Lambda^k A) = \\Lambda^n A^k.</math> The entries of the transposed matrix of <math>\\Lambda^k A</math> are <math>k \\times k</math>-minors of <math>A</math>.\n\n* <math>\\forall k \\leqslant n-1, p \\leqslant k, A \\in \\operatorname{End}(V),</math> \n::<math>\\sum_{q=0}^p \\left (\\Lambda^{n-k} A^{p-q} \\right )^\\mathrm{T} \\left (\\Lambda^k A^q \\right ) = \\left (\\Lambda^n A^p \\right ) \\operatorname{Id} \\in \\operatorname{End}(V).</math> \n:In particular,\n::<math> \\left (\\Lambda^{n-1} A^{p-1} \\right )^\\mathrm{T} A + (\\Lambda^{n-1} A^p)^\\mathrm{T} = (\\Lambda^n A^p) \\operatorname{Id}</math>\n:and hence\n::<math>(\\operatorname{adj} A)A = \\left (\\Lambda^{n-1} A^{n-1} \\right )^\\mathrm{T} A =(\\Lambda^n A^n) \\operatorname{Id} =(\\det A)\\operatorname{Id}.</math>\n\n* <math>(\\Lambda^{n-1} A^p)^T = \\sum_{q=0}^p (\\Lambda^n A^{p-q})(-A)^q = \\sum_{q=0}^p \\operatorname{Tr}(\\Lambda^{p-q} A)(-A)^q.</math>\n:In particular, \n::<math>\\operatorname{adj} A = \\sum_{q=0}^{n-1} \\left (\\Lambda^n A^{n-q-1} \\right )(-A)^q.</math>\n\n* <math>\\operatorname{Tr}(\\Lambda^k \\operatorname{adj} A) = \\Lambda^n (\\operatorname{adj} A)^k = (\\det A)^{k-1} (\\Lambda^n A^{n-k}) = (\\det A)^{k-1} \\operatorname{Tr}(\\Lambda^{n-k} A).</math>\n\n* <math>\\operatorname{Tr}((\\Lambda^{n-1} A^k)^\\mathrm{T})=(n-k) \\Lambda^n A^p=(n-k) \\operatorname{Tr}(\\Lambda^p A)</math>.\n\n* The characteristic polynomial <math>\\operatorname{ch}_A(t)</math> of <math>A \\in \\operatorname{End}(V)</math> can be given by\n::<math>\\operatorname{ch}_A(t)=\\sum_{k=0}^n \\operatorname{Tr}(\\Lambda^k A)(-t)^{n-k} = \\sum_{k=0}^n (\\Lambda^n A^k)(-t)^{n-k} .</math>\n:Similarly,\n::<math>\\operatorname{ch}_{\\operatorname{adj} A}(t)=\\sum_{k=0}^n (\\Lambda^n(\\operatorname{adj} A)^k)(-t)^{n-k} = \\sum_{k=0}^n (\\det A)^{k-1}(\\Lambda^n A^{n-k})(-t)^{n-k}</math>\n\n====Leverrier's Algorithm====\n<math>\\Lambda^n A^k</math> is the coefficient of <math>(-t)^{n-k}</math> term in the characteristic polynomial. They also appear in the expressions of <math>(\\Lambda^{n-1} A^p)^\\mathrm{T}</math> and <math>\\Lambda^n (\\operatorname{adj} A)^k</math>. Leverrier's Algorithm<ref>W.Kahan (2009), ''Jordan's normal form''. https://www.cs.berkeley.edu/~wkahan/MathH110/jordan.pdf</ref> is an economical way of computing <math>\\Lambda^n A^k</math> and <math>\\Lambda^{n-1} A^k</math>:\n\n::Set <math>\\Lambda^{n-1} A^0 = 1</math>;\n\n::For <math>k=n-1,n-2,\\ldots,1,0</math>,\n\n:::<math>\\Lambda^n A^{n-k} = \\frac{1}{n-k} \\operatorname{Tr}(A \\circ \\Lambda^{n-1} A^{n-k-1})</math>;\n\n:::<math>\\Lambda^{n-1} A^{n-k} = \\Lambda^n A^{n-k} \\cdot \\operatorname{Id} - A \\circ \\Lambda^{n-1} A^{n-k-1}</math>.\n\n===Physics===\nIn physics, many quantities are naturally represented by alternating operators. For example, if the motion of a charged particle is described by velocity and acceleration vectors in four-dimensional spacetime, then normalization of the velocity vector requires that the electromagnetic force must be an alternating operator on the velocity. Its six degrees of freedom are identified with the electric and magnetic fields.\n\n===Linear geometry===\nThe decomposable ''k''-vectors have geometric interpretations: the bivector {{math|''u'' ∧ ''v''}} represents the plane spanned by the vectors, \"weighted\" with a number, given by the area of the oriented [[parallelogram]] with sides ''u'' and ''v''. Analogously, the 3-vector {{math|''u'' ∧ ''v'' ∧ ''w''}} represents the spanned 3-space weighted by the volume of the oriented [[parallelepiped]] with edges ''u'', ''v'', and ''w''.\n\n===Projective geometry===\nDecomposable ''k''-vectors in Λ<sup>''k''</sup>''V'' correspond to weighted ''k''-dimensional [[linear subspace]]s of ''V''. In particular, the [[Grassmannian]] of ''k''-dimensional subspaces of ''V'', denoted ''Gr''<sub>''k''</sub>(''V''), can be naturally identified with an [[algebraic variety|algebraic subvariety]] of the [[projective space]] '''P'''(Λ<sup>''k''</sup>''V''). This is called the [[Plücker embedding]].\n\n===Differential geometry===\nThe exterior algebra has notable applications in [[differential geometry]], where it is used to define [[differential form]]s. A [[differential form]] at a point of a [[differentiable manifold]] is an alternating multilinear form on the [[tangent space]] at the point. Equivalently, a differential form of degree ''k'' is a [[linear functional]] on the ''k''-th exterior power of the tangent space. As a consequence, the exterior product of multilinear forms defines a natural exterior product for differential forms. Differential forms play a major role in diverse areas of differential geometry.\n\nIn particular, the [[exterior derivative]] gives the exterior algebra of differential forms on a manifold the structure of a [[differential algebra]]. The exterior derivative commutes with [[pullback (differential geometry)|pullback]] along smooth mappings between manifolds, and it is therefore a [[natural transformation|natural]] [[differential operator]]. The exterior algebra of differential forms, equipped with the exterior derivative, is a [[cochain complex]] whose cohomology is called the [[de Rham cohomology]] of the underlying manifold and plays a vital role in the [[algebraic topology]] of differentiable manifolds.\n\n===Representation theory===\nIn [[representation theory]], the exterior algebra is one of the two fundamental [[Schur functor]]s on the category of vector spaces, the other being the [[symmetric algebra]]. Together, these constructions are used to generate the [[irreducible representation]]s of the [[general linear group]]; see [[fundamental representation]].\n\n===Superspace===\nThe exterior algebra over the complex numbers is the archetypal example of a [[superalgebra]], which plays a fundamental role in physical theories pertaining to [[fermion]]s and [[supersymmetry]]. A single element of the exterior algebra is called a '''supernumber'''<ref>[[Bryce DeWitt]], ''Supermanifolds'', (1984) Cambridge University Press {{ISBN|0-521-42377-5}}. ''(See Chapter 1, page 1.)''</ref> or [[Grassmann number]]. The exterior algebra itself is then just a one-dimensional [[superspace]]: it is just the set of all of the points in the exterior algebra. The topology on this space is essentially the [[weak topology]], the [[open sets]] being the [[cylinder set]]s.  An {{math|''n''}}-dimensional superspace is just the {{math|''n''}}-fold product of exterior algebras.\n\n===Lie algebra homology===\nLet ''L'' be a Lie algebra over a field ''K'', then it is possible to define the structure of a [[chain complex]] on the exterior algebra of ''L''. This is a ''K''-linear mapping\n:<math>\\partial : \\Lambda^{p+1}L\\to\\Lambda^pL</math>\ndefined on decomposable elements by\n:<math>\\partial (x_1\\wedge\\cdots\\wedge x_{p+1}) = \\frac{1}{p+1}\\sum_{j<\\ell}(-1)^{j+\\ell+1}[x_j,x_\\ell]\\wedge x_1\\wedge\\cdots\\wedge \\hat{x}_j\\wedge\\cdots\\wedge\\hat{x}_\\ell\\wedge\\cdots\\wedge x_{p+1}.</math>\nThe [[Jacobi identity]] holds if and only if {{nowrap|1=∂∂ = 0}}, and so this is a necessary and sufficient condition for an anticommutative nonassociative algebra ''L'' to be a Lie algebra.  Moreover, in that case Λ''L'' is a [[chain complex]] with boundary operator ∂.  The [[homology theory|homology]] associated to this complex is the [[Lie algebra homology]].\n\n===Homological algebra===\nThe exterior algebra is the main ingredient in the construction of the [[Koszul complex]], a fundamental object in [[homological algebra]].\n\n== History ==\nThe exterior algebra was first introduced by [[Hermann Grassmann]] in 1844 under the blanket term of ''Ausdehnungslehre'', or ''Theory of Extension''.<ref>{{harvcoltxt|Kannenberg|2000}} published a translation of Grassmann's work in English; he translated ''Ausdehnungslehre'' as ''Extension Theory''.</ref>\nThis referred more generally to an algebraic (or axiomatic) theory of extended quantities and was one of the early precursors to the modern notion of a [[vector space]]. [[Adhémar Jean Claude Barré de Saint-Venant|Saint-Venant]] also published similar ideas of exterior calculus for which he claimed priority over Grassmann.<ref>J Itard, Biography in Dictionary of Scientific Biography (New York 1970–1990).</ref>\n\nThe algebra itself was built from a set of rules, or axioms, capturing the formal aspects of Cayley and Sylvester's theory of multivectors. It was thus a ''calculus'', much like the [[propositional calculus]], except focused exclusively on the task of formal reasoning in geometrical terms.<ref>Authors have in the past referred to this calculus variously as the ''calculus of extension'' ({{harvnb|Whitehead|1898}}; {{harvnb|Forder|1941}}), or ''extensive algebra'' {{harv|Clifford|1878}}, and recently as ''extended vector algebra'' {{harv|Browne|2007}}.</ref>\nIn particular, this new development allowed for an ''axiomatic'' characterization of dimension, a property that had previously only been examined from the coordinate point of view.\n\nThe import of this new theory of vectors and [[multivector]]s was lost to mid 19th century mathematicians,<ref>{{harvnb|Bourbaki|1989|p=661}}.</ref>\nuntil being thoroughly vetted by [[Giuseppe Peano]] in 1888. Peano's work also remained somewhat obscure until the turn of the century, when the subject was unified by members of the French geometry school (notably [[Henri Poincaré]], [[Élie Cartan]], and [[Gaston Darboux]]) who applied Grassmann's ideas to the calculus of [[differential form]]s.\n\nA short while later, [[Alfred North Whitehead]], borrowing from the ideas of Peano and Grassmann, introduced his [[universal algebra]]. This then paved the way for the 20th century developments of [[abstract algebra]] by placing the axiomatic notion of an algebraic system on a firm logical footing.\n\n==See also==\n\n*[[Symmetric algebra]], the symmetric analog\n*[[Clifford algebra]], a [[quantum group|quantum deformation]] of the exterior algebra by a [[quadratic form]]\n*[[Weyl algebra]], a [[quantum group|quantum deformation]] of the symmetric algebra by a [[symplectic form]]\n*[[Multilinear algebra]]\n*[[Tensor algebra]]\n*[[Geometric algebra]]\n*[[Koszul complex]]\n*[[Wedge sum]]\n\n== Notes ==\n{{reflist|30em}}\n\n== References ==\n\n===Mathematical references===\n* {{citation |last1=Bishop |first1=R. |author1-link=Richard L. Bishop |last2=Goldberg |first2=S. I. |year=1980 |title=Tensor analysis on manifolds |publisher=Dover |isbn=0-486-64039-6}}\n:: Includes a treatment of alternating tensors and alternating forms, as well as a detailed discussion of Hodge duality from the perspective adopted in this article.\n* {{citation |last=Bourbaki |first=Nicolas |authorlink=Nicolas Bourbaki |year=1989 |title=Elements of mathematics, Algebra I |publisher=Springer-Verlag |isbn=3-540-64243-9}}\n:: This is the ''main mathematical reference'' for the article. It introduces the exterior algebra of a module over a commutative ring (although this article specializes primarily to the case when the ring is a field), including a discussion of the universal property, functoriality, duality, and the bialgebra structure. See §III.7 and §III.11.\n* {{citation |last1=Bryant |first1=R. L. |author1-link=Robert Bryant (mathematician) |last2=Chern |first2=S. S. |authorlink2=Shiing-Shen Chern |last3=Gardner |first3=R. B. |last4=Goldschmidt |first4=H. L. |last5=Griffiths |first5=P. A. |authorlink5=Philip A. Griffiths |year=1991 |title=Exterior differential systems |publisher=Springer-Verlag}}\n:: This book contains applications of exterior algebras to problems in [[partial differential equations]]. Rank and related concepts are developed in the early chapters.\n* {{citation |last1=Mac Lane |first1=S. |authorlink1=Saunders Mac Lane |last2=Birkhoff |first2=G. |authorlink2=Garrett Birkhoff |year=1999 |title=Algebra |publisher=AMS Chelsea |isbn=0-8218-1646-2}}\n:: Chapter XVI sections 6–10 give a more elementary account of the exterior algebra, including duality, determinants and minors, and alternating forms.\n* {{citation |last=Sternberg |first=Shlomo |authorlink=Shlomo Sternberg |year=1964 |title=Lectures on Differential Geometry |publisher=Prentice Hall}}\n:: Contains a classical treatment of the exterior algebra as alternating tensors, and applications to differential geometry.\n\n===Historical references===\n* {{citation |last=Bourbaki |first=Nicolas |authorlink=Nicolas Bourbaki |year=1989 |title=Elements of mathematics, Algebra I |chapter=Historical note on chapters II and III |publisher=Springer-Verlag}}\n* {{citation |last=Clifford |first=W. |authorlink=William Kingdon Clifford |year=1878 |title=Applications of Grassmann's Extensive Algebra |journal=American Journal of Mathematics |publisher=The Johns Hopkins University Press |doi=10.2307/2369379 |jstor=2369379 |volume=1 |issue=4 |pages=350–358}}\n* {{citation |last=Forder |first=H. G. |year=1941 |title=The Calculus of Extension |publisher=Cambridge University Press}}\n* {{citation |last=Grassmann |first=Hermann |authorlink=Hermann Grassmann |year=1844 |title=Die Lineale Ausdehnungslehre – Ein neuer Zweig der Mathematik |language=German |url=https://books.google.com/books?id=bKgAAAAAMAAJ&pg=PA1&dq=Die+Lineale+Ausdehnungslehre+ein+neuer+Zweig+der+Mathematik}} (The Linear Extension Theory – A new Branch of Mathematics) [http://resolver.sub.uni-goettingen.de/purl?PPN534901565 alternative reference]\n* {{citation |last=Kannenberg |first=Lloyd |year=2000 |title=Extension Theory (translation of Grassmann's ''Ausdehnungslehre'') |publisher=American Mathematical Society |isbn=0-8218-2031-1}}\n* {{citation |last=Peano |first=Giuseppe |authorlink=Giuseppe Peano |year=1888 |title=Calcolo Geometrico secondo l'Ausdehnungslehre di H. Grassmann preceduto dalle Operazioni della Logica Deduttiva}}; {{citation |last=Kannenberg |first=Lloyd |year=1999 |title=Geometric calculus: According to the Ausdehnungslehre of H. Grassmann |publisher=Birkhäuser |isbn=978-0-8176-4126-9}}.\n* {{citation |last=Whitehead |first=Alfred North |authorlink=Alfred North Whitehead |year=1898 |title=A Treatise on Universal Algebra, with Applications |publisher=Cambridge |url=http://historical.library.cornell.edu/cgi-bin/cul.math/docviewer?did=01950001&seq=5}}\n\n===Other references and further reading===\n<!--For works inessential to the article, though these may also have been referenced in passing.-->\n* {{citation |last=Browne |first=J. M. |year=2007 |title=Grassmann algebra – Exploring applications of Extended Vector Algebra with Mathematica |url=http://www.grassmannalgebra.info/grassmannalgebra/book/index.htm}}\n:: An introduction to the exterior algebra, and [[geometric algebra]], with a focus on applications. Also includes a history section and bibliography.\n* {{citation |last=Spivak |first=Michael |authorlink=Michael Spivak |year=1965 |title=Calculus on manifolds |publisher=Addison-Wesley |isbn=978-0-8053-9021-6}}\n:: Includes applications of the exterior algebra to differential forms, specifically focused on [[integral|integration]] and [[Stokes's theorem]]. The notation Λ<sup>''k''</sup>''V'' in this text is used to mean the space of alternating ''k''-forms on ''V''; i.e., for Spivak Λ<sup>''k''</sup>''V'' is what this article would call Λ<sup>''k''</sup>''V''<sup>∗</sup>. Spivak discusses this in Addendum 4.\n* {{citation |last=Strang |first=G. |authorlink=Gilbert Strang |year=1993 |title=Introduction to linear algebra |publisher=Wellesley-Cambridge Press |isbn=978-0-9614088-5-5}}\n:: Includes an elementary treatment of the axiomatization of determinants as signed areas, volumes, and higher-dimensional volumes.\n* {{springer|id=E/e037080|title=Exterior algebra|author=Onishchik, A.L.}}\n* Wendell H. Fleming (1965) ''Functions of Several Variables'', [[Addison-Wesley]].\n:: Chapter 6: Exterior algebra and differential calculus, pages 205–38. This textbook in [[multivariate calculus]] introduces the exterior algebra of differential forms adroitly into the calculus sequence for colleges.\n* {{citation |last=Winitzki |first=S. |year=2010 |title=Linear Algebra via Exterior Products |url=http://sites.google.com/site/winitzki/linalg}}\n:: An introduction to the coordinate-free approach in basic finite-dimensional linear algebra, using exterior products.\n* {{cite book\n  | last1 = Shafarevich | first1 = I. R. | authorlink1 = Igor Shafarevich\n  | last2=Remizov |first2=A. O.\n  | year = 2012\n  | title = Linear Algebra and Geometry\n  | publisher = [[Springer Science+Business Media|Springer]]\n  | isbn = 978-3-642-30993-9\n  | url = https://www.springer.com/mathematics/algebra/book/978-3-642-30993-9}}\n:: Chapter 10: The Exterior Product and Exterior Algebras\n* [http://neo-classical-physics.info/uploads/3/0/6/5/3065888/burali-forti_-_grassman_and_proj._geom..pdf \"The Grassmann method in projective geometry\"] A compilation of English translations of three notes by Cesare Burali-Forti on the application of exterior algebra to projective geometry\n* [http://neo-classical-physics.info/uploads/3/0/6/5/3065888/burali-forti_-_diff._geom._following_grassmann.pdf C. Burali-Forti, \"Introduction to Differential Geometry, following the method of H. Grassmann\"] An English translation of an early book on the geometric applications of exterior algebras\n* [http://neo-classical-physics.info/uploads/3/0/6/5/3065888/grassmann_-_mechanics_and_extensions.pdf \"Mechanics, according to the principles of the theory of extension\"] An English translation of one Grassmann's papers on the applications of exterior algebra\n\n{{Linear algebra}}\n{{tensors}}\n\n[[Category:Algebras]]\n[[Category:Multilinear algebra]]\n[[Category:Differential forms]]"
    },
    {
      "title": "Filtered algebra",
      "url": "https://en.wikipedia.org/wiki/Filtered_algebra",
      "text": "In [[mathematics]], a '''filtered algebra''' is a generalization of the notion of a [[graded algebra]]. Examples appear in many branches of [[mathematics]], especially in [[homological algebra]] and [[representation theory]]. \n\nA filtered algebra over the [[field (mathematics)|field]] <math>k</math> is an [[Algebra over a field|algebra]] <math>(A,\\cdot)</math> over <math>k</math> which has an increasing sequence <math> \\{0\\} \\subseteq F_0 \\subseteq F_1 \\subseteq \\cdots \\subseteq F_i \\subseteq \\cdots \\subseteq A </math> of subspaces of <math>A</math> such that \n\n:<math>A=\\bigcup_{i\\in \\mathbb{N}} F_{i}</math>\n\nand that is compatible with the multiplication in the following sense:  \n\n:<math> \\forall m,n \\in \\mathbb{N},\\qquad F_m\\cdot F_n\\subseteq F_{n+m}.</math>\n\n==Associated graded algebra==\nIn general there is the following construction that produces a graded algebra out of a filtered algebra. \n\nIf <math>A</math> is a filtered algebra then the ''[[associated graded algebra]]''  <math>\\mathcal{G}(A)</math> is defined as follows: {{unordered list\n|1= As a [[linear space|vector space]]  \n\n:<math> \\mathcal{G}(A)=\\bigoplus_{n\\in \\mathbb{N}}G_n\\,, </math>\n\nwhere,  \n\n:<math> G_0=F_0,</math>   and \n\n:<math> \\forall n>0, \\quad G_n=F_n/F_{n-1}\\,,</math>\n\n|2= the multiplication is defined by  \n\n:<math> (x+F_{n-1})(y+F_{m-1})=x\\cdot y+F_{n+m-1}</math>\n\nfor all <math>x\\in F_n</math> and <math>y\\in F_m</math>. (More precisely, the multiplication map <math> \\mathcal{G}(A)\\times \\mathcal{G}(A) \\to \\mathcal{G}(A)</math> is combined from the maps\n\n:<math> (F_n / F_{n-1}) \\times (F_m / F_{m-1}) \\to F_{n+m}/F_{n+m-1}, \\ \\ \\ \\ \\ \\left(x+F_{n-1},y+F_{m-1}\\right) \\mapsto x\\cdot y+F_{n+m-1}</math>\n\nfor all <math>n\\geq 0</math> and <math>m\\geq 0</math>.) \n}}\nThe multiplication is well defined and endows  <math>\\mathcal{G}(A)</math> with the structure of a graded algebra, with gradation  <math>\\{G_n\\}_{n \\in \\mathbb{N}}.</math> Furthermore if <math>A</math> is [[associative]] then so is  <math>\\mathcal{G}(A)</math>. Also if <math>A</math> is unital, such that the unit lies in <math>F_0</math>, then <math>\\mathcal{G}(A)</math> will be unital as well.\n\nAs algebras <math>A</math> and  <math>\\mathcal{G}(A)</math> are distinct (with the exception of the trivial case that <math>A</math> is graded) but as vector spaces they are [[isomorphism|isomorphic]].{{Citation needed|reason=This is a highly unintuitive result, and I'm not convinced its true.|date=April 2018}}\n\n==Examples==\nAny [[graded algebra]] graded by ℕ, for example <math>A =  \\oplus_{n\\in \\mathbb{N}} A_n </math>, has a filtration given by <math> F_n = \\oplus_{i=0}^n A_i </math>. \n\nAn example of a filtered algebra is the [[Clifford algebra]]  <math>\\mathrm{Cliff}(V,q)</math> of a vector space <math>V</math> endowed with a [[polarization identity|quadratic form]] <math>q.</math> The associated graded algebra is  <math>\\bigwedge V</math>, the [[exterior algebra]] of <math>V.</math> \n\nThe [[symmetric algebra]] on the dual of an [[affine space]] is a filtered algebra of polynomials; on a [[vector space]], one instead obtains a graded algebra.\n\nThe [[universal enveloping algebra]] of a [[Lie algebra]] <math>\\mathfrak{g}</math> is also naturally filtered.  The [[PBW theorem]] states that the associated graded algebra is simply <math>\\mathrm{Sym} (\\mathfrak{g})</math>.\n\nScalar [[differential operator]]s on a manifold <math>M</math> form a filtered algebra where the filtration is given by the degree of differential operators. The associated graded algebra is the commutative algebra of smooth functions on the cotangent bundle <math>T^*M</math> which are polynomial along the fibers of the projection <math>\\pi\\colon T^*M\\rightarrow M</math>.\n\nThe [[group ring|group algebra]] of a group with a [[length function]] is a filtered algebra.\n\n==See also==\n* [[Filtration (mathematics)]]\n* [[Length function]]\n\n==References==\n*{{cite book|last=Abe|first=Eiichi|title=Hopf Algebras|year=1980|publisher=Cambridge University Press|location=Cambridge|isbn=0-521-22240-0|url=https://books.google.ch/books?id=D0AIcewz5-8C&pg=PR4&lpg=PR4&dq=isbn+0-521-22240-0&source=bl&ots=hghAhwKyW6&sig=q9kGyfSJ3GeWFgO51uecxVCu7bo&hl=en&sa=X&ei=1AVNT7HjDtP64QTx08TyAg&ved=0CCUQ6AEwAQ#v=onepage&q=isbn%200-521-22240-0&f=false}}\n\n{{PlanetMath attribution|id=3938|title=Filtered algebra}}\n\n[[Category:Algebras]]\n[[Category:Homological algebra]]"
    },
    {
      "title": "Finitely generated algebra",
      "url": "https://en.wikipedia.org/wiki/Finitely_generated_algebra",
      "text": "{{unreferenced|date=August 2012}}\nIn [[mathematics]], a '''finitely generated algebra''' (also called an '''algebra of finite type''') is an [[associative algebra]] ''A'' over a [[field (mathematics)|field]] ''K'' where there exists a finite set of elements ''a''<sub>1</sub>,…,''a''<sub>''n''</sub> of ''A'' such that every element of ''A'' can be expressed as a [[polynomial]] in ''a''<sub>1</sub>,…,''a''<sub>''n''</sub>, with coefficients in ''K''. If it is necessary to emphasize the field ''K'' then the algebra is said to be finitely generated '''over ''K'' '''. Algebras that are not finitely generated are called '''infinitely generated'''. Finitely generated [[reduced ring|reduced]] [[commutative ring|commutative algebras]] are basic objects of consideration in modern [[algebraic geometry]], where they correspond to [[affine algebraic variety|affine algebraic varieties]]; for this reason, these algebras are also referred to as (commutative) '''affine algebras'''.\n\n== Examples ==\n\n* The [[polynomial algebra]] ''K''[''x''<sub>1</sub>,…,''x''<sub>''n''</sub>] is finitely generated. The polynomial algebra in infinitely [[countable|countably many]] generators is infinitely generated. \n* The field ''E''&nbsp;=&nbsp;''K''(''t'') of [[rational function]]s in one variable over an infinite field ''K'' is ''not'' a finitely generated algebra over ''K''. On the other hand, ''E'' is generated over ''K'' by a single element, ''t'', ''as a field''.\n* If ''E''/''F'' is a [[finite field extension]] then it follows from the definitions that ''E'' is a finitely generated algebra over ''F''.\n* Conversely, if ''E'' /''F'' is a field extension and ''E'' is a finitely generated algebra over ''F'' then the field extension is finite. This is called [[Zariski's lemma]]. See also [[integral extension]].\n* If ''G'' is a [[finitely generated group]] then the [[group ring]] ''KG'' is a finitely generated algebra over ''K''.\n\n== Properties ==\n\n* A [[homomorphism|homomorphic image]] of a finitely generated algebra is itself finitely generated. However,  a similar property for [[subalgebra]]s does not hold in general.\n* [[Hilbert's basis theorem]]: if ''A'' is a finitely generated commutative algebra over a Noetherian ring then every [[Ideal (ring theory)|ideal]] of ''A'' is finitely generated, or equivalently, ''A'' is a [[Noetherian ring]].\n\n== See also ==\n\n* [[Finitely generated module]]\n* [[Finitely generated field extension]]\n\n[[Category:Algebras]]\n[[Category:Commutative algebra]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Fourier algebra",
      "url": "https://en.wikipedia.org/wiki/Fourier_algebra",
      "text": "{{citation style|date=February 2012}}\n'''Fourier''' and related [[Associative algebra|algebras]] occur naturally in the [[harmonic analysis]] of [[locally compact]] [[Group (mathematics)|groups]]. They play an important role in the [[duality theory|duality theories]] of these groups. The Fourier–Stieltjes algebra and the Fourier–Stieltjes transform on the Fourier algebra of a locally compact group were introduced by [[Pierre Eymard]] in 1964.\n\n==Definition==\n\n===Informal===\nLet G be a locally compact abelian group, and Ĝ the [[Pontryagin dual|dual group]] of G. Then <math> L_1(\\hat{\\mathit{G}}) </math> is the space of all functions on Ĝ which are integrable with respect to the [[Haar measure]] on Ĝ, and it has a [[Banach algebra]] structure where the product of two functions is [[convolution]]. We define <math>A(G) </math> to be the set of Fourier transforms of functions in <math> L_1(\\hat{\\mathit{G}}) </math>, and it is a closed sub-algebra of <math>CB(G) </math>, the space of bounded continuous complex-valued functions on G with pointwise multiplication. We call <math>A(G) </math> the Fourier algebra of G.\n\nSimilarly, we write <math> M(\\hat{\\mathit{G}}) </math> for the measure algebra on Ĝ, meaning the space of all finite regular [[Borel measure|Borel measures]] on Ĝ.  We define <math>B(G) </math> to be the set of Fourier-Stieltjes transforms of measures in <math> M(\\hat{\\mathit{G}}) </math>. It is a closed sub-algebra of <math>CB(G) </math>, the space of bounded continuous complex-valued functions on G with pointwise multiplication. We call <math>B(G) </math> the Fourier-Stieltjes algebra of G. Equivalently, <math>B(G) </math> can be defined as the linear span of the set <math>P(G) </math> of continuous [[Positive-definite function|positive-definite functions]] on G.<ref>{{SpringerEOM|id=Fourier-algebra(2)|first=Jean|last=Renault}}</ref>\n\nSince <math> L_1(\\hat{\\mathit{G}}) </math> is naturally included in <math> M(\\hat{\\mathit{G}}) </math>, and since the Fourier-Stieltjes transform of an <math> L_1(\\hat{\\mathit{G}}) </math> function is just the Fourier transform of that function, we have that <math>A(G) \\subset B(G) </math>. In fact, <math>A(G) </math> is a closed ideal in <math>B(G) </math>.\n\n===Formal===\nLet <math> B(\\mathit{G}) </math> be a Fourier–Stieltjes algebra and <math> A(\\mathit{G}) </math> be a Fourier algebra such that the locally compact group <math> \\mathit{G} </math> is [[Abelian group|abelian]]. Let <math> M(\\widehat{\\mathit{G}}) </math> be the measure algebra of finite measures on <math> \\widehat{G} </math> and let <math> L_1(\\widehat{\\mathit{G}}) </math> be the [[Group algebra#The convolution algebra L1.28G.29|convolution algebra]] of [[Haar measure#Haar integral|integrable]] [[Function (mathematics)|function]]s on <math> \\widehat{G} </math>, where <math> \\widehat{\\mathit{G}} </math> is the character group of the Abelian group <math> \\mathit{G} </math>.\n\nThe Fourier–Stieltjes transform of a finite measure <math> \\mu </math> on <math> \\widehat{\\mathit{G}} </math> is the function <math> \\widehat{\\mu} </math> on <math> \\mathit{G} </math> defined by\n\n: <math> \\widehat{\\mu}(x) =  \\int_{\\widehat{G}} \\overline{X(x)} \\, d \\mu(X), \\quad x \\in G </math>\n\nThe space <math> B(\\mathit{G}) </math> of these functions is an algebra under pointwise multiplication is isomorphic to the measure algebra <math> M(\\widehat{\\mathit{G}}) </math>. Restricted to <math> L_1(\\widehat{\\mathit{G}}) </math>, viewed as a subspace of <math> M(\\widehat{\\mathit{G}}) </math>, the Fourier–Stieltjes transform is the [[Fourier transform]] on <math> L_1(\\widehat{\\mathit{G}}) </math> and its image is, by definition, the Fourier algebra <math> A(\\mathit{G}) </math>. The generalized [[Bochner theorem]] states that a measurable function on <math> \\mathit{G} </math> is equal, [[almost everywhere]], to the Fourier–Stieltjes transform of a non-negative finite measure on <math> \\widehat{G} </math> if and only if it is positive definite. Thus, <math> B(\\mathit{G}) </math> can be defined as the [[linear span]] of the set of continuous positive-definite functions on <math> \\mathit{G} </math>. This definition is still valid when <math> \\mathit{G} </math> is not Abelian.\n\n===Helson–Kahane–Katznelson–Rudin theorem===\nLet A(G) be the Fourier algebra of a compact group G. Building upon the work of [[Norbert Wiener|Wiener]], [[Paul Lévy (mathematician)|Lévy]], [[Israel Gelfand|Gelfand]], and [[Arne Beurling|Beurling]], in 1959 [[Henry Helson|Helson]], [[Jean-Pierre Kahane|Kahane]], [[Yitzhak Katznelson|Katznelson]], and [[Walter Rudin|Rudin]] proved that, when G is compact and abelian, a function f defined on a closed convex subset of the plane operates in A(G) if and only if f is real analytic.<ref>{{cite journal|author1=H. Helson |author2=J.-P. Kahane |author3=Y. Katznelson |author4=W. Rudin |title=The functions which operate on Fourier transforms|journal=Acta Mathematica|volume=102|issue=1–2 |year=1959|pages=135–157|url=http://www.kryakin.com/files/Acta_Mat_(2_55)/acta106_57/102/102_10.pdf|doi=10.1007/bf02559571}}</ref> In 1969 [[Charles F. Dunkl|Dunkl]] proved the result holds when G is compact and contains an infinite abelian subgroup.\n\n==References==\n{{reflist}}\n\n* {{SpringerEOM|id=Fourier-algebra(2)|first=Jean|last=Renault}}\n* \"Functions that Operate in the Fourier Algebra of a Compact Group\" Charles F. Dunkl ''Proceedings of the American Mathematical Society'', Vol. 21, No. 3. (Jun., 1969), pp.&nbsp;540–544. Stable URL:[https://www.jstor.org/stable/2036416]\n* \"Functions which Operate in the Fourier Algebra of a Discrete Group\" Leonede de Michele; Paolo M. Soardi, ''Proceedings of the American Mathematical Society'', Vol. 45, No. 3. (Sep., 1974), pp.&nbsp;389–392. Stable URL:[https://www.jstor.org/stable/2039963]\n* \"Uniform Closures of Fourier-Stieltjes Algebras\", Ching Chou, ''Proceedings of the American Mathematical Society'', Vol. 77, No. 1. (Oct., 1979), pp.&nbsp;99–102.  Stable URL: [https://www.jstor.org/stable/2042723]\n* \"Centralizers of the Fourier Algebra of an Amenable Group\", P. F. Renaud, ''Proceedings of the American Mathematical Society'', Vol. 32, No. 2. (Apr., 1972), pp.&nbsp;539–542.  Stable URL: [https://www.jstor.org/stable/2037854]\n\n[[Category:Harmonic analysis]]\n[[Category:Algebras]]"
    },
    {
      "title": "Free algebra",
      "url": "https://en.wikipedia.org/wiki/Free_algebra",
      "text": "{{About|free algebras in ring theory|the more general free algebras in [[universal algebra]]|free object}}\nIn [[mathematics]], especially in the area of [[abstract algebra]] known as [[ring theory]], a '''free algebra''' is the noncommutative analogue of a [[polynomial ring]] since its elements may be described as \"polynomials\" with non-commuting variables. Likewise, the [[polynomial ring]] may be regarded as a '''free commutative algebra'''.\n\n==Definition==\nFor ''R'' a [[commutative ring]], the free ([[associative]], [[unital algebra|unital]]) [[algebra (ring theory)|algebra]] on ''n'' [[indeterminate (variable)|indeterminate]]s {''X''<sub>1</sub>,...,''X<sub>n</sub>''} is the [[free module|free ''R''-module]] with a basis consisting of all [[Word (mathematics)|words]] over the alphabet {''X''<sub>1</sub>,...,''X<sub>n</sub>''} (including the empty word, which is the unit of the free algebra). This ''R''-module becomes an [[algebra (ring theory)|''R''-algebra]] by defining a multiplication as follows: the product of two basis elements is the [[concatenation]] of the corresponding words:\n\n:<math>\\left(X_{i_1}X_{i_2} \\cdots X_{i_l}\\right) \\cdot \\left(X_{j_1}X_{j_2} \\cdots X_{j_m}\\right) = X_{i_1}X_{i_2} \\cdots X_{i_l}X_{j_1}X_{j_2} \\cdots X_{j_m},</math>\n\nand the product of two arbitrary ''R''-module elements is thus uniquely determined (because the multiplication in an ''R''-algebra must be ''R''-bilinear). This ''R''-algebra is denoted ''R''⟨''X''<sub>1</sub>,...,''X<sub>n</sub>''⟩. This construction can easily be generalized to an arbitrary set ''X'' of indeterminates.\n\nIn short, for an arbitrary set <math>X=\\{X_i\\,;\\; i\\in I\\}</math>, the '''free ([[associative]], [[unital algebra|unital]]) ''R''-[[algebra (ring theory)|algebra]] on ''X''''' is \n:<math>R\\langle X\\rangle:=\\bigoplus_{w\\in X^\\ast}R w</math>\nwith the ''R''-bilinear multiplication that is concatenation on words, where ''X''* denotes the [[free monoid]] on ''X'' (i.e. words on the letters ''X''<sub>i</sub>), <math>\\oplus</math> denotes the external [[Direct sum of modules|direct sum]], and ''Rw'' denotes the [[free module|free ''R''-module]] on 1 element, the word ''w''.\n\nFor example, in ''R''⟨''X''<sub>1</sub>,''X''<sub>2</sub>,''X''<sub>3</sub>,''X''<sub>4</sub>⟩, for scalars ''α, β, γ, δ'' ∈ ''R'', a concrete example of a product of two elements is \n\n<math>(\\alpha X_1X_2^2 + \\beta X_2X_3)\\cdot(\\gamma X_2X_1 + \\delta X_1^4X_4) = \\alpha\\gamma X_1X_2^3X_1 + \\alpha\\delta X_1X_2^2X_1^4X_4 + \\beta\\gamma X_2X_3X_2X_1 + \\beta\\delta X_2X_3X_1^4X_4</math>.\n\nThe non-commutative polynomial ring may be identified with the [[monoid ring]] over ''R'' of the [[free monoid]] of all finite words in the ''X''<sub>''i''</sub>.\n\n==Contrast with Polynomials==\nSince the words over the alphabet {''X''<sub>1</sub>, ...,''X<sub>n</sub>''} form a basis of ''R''⟨''X''<sub>1</sub>,...,''X<sub>n</sub>''⟩, it is clear that any element of ''R''⟨''X''<sub>1</sub>, ...,''X<sub>n</sub>''⟩ can be written uniquely in the form:\n\n:<math>\\sum\\limits_{k = 0}^\\infty \\, \\, \\, \\sum\\limits_{i_1,i_2, \\cdots ,i_k\\in\\left\\lbrace 1,2, \\cdots ,n\\right\\rbrace} a_{i_1,i_2, \\cdots ,i_k} X_{i_1} X_{i_2} \\cdots X_{i_k},</math>\n\nwhere <math>a_{i_1,i_2,...,i_k}</math> are elements of ''R'' and all but finitely many of these elements are zero. This explains why the elements of ''R''⟨''X''<sub>1</sub>,...,''X<sub>n</sub>''⟩ are often denoted as \"non-commutative polynomials\" in the \"variables\" (or \"indeterminates\") ''X''<sub>1</sub>,...,''X<sub>n</sub>''; the elements <math> a_{i_1,i_2,...,i_k}</math> are said to be \"coefficients\" of these polynomials, and the ''R''-algebra ''R''⟨''X''<sub>1</sub>,...,''X<sub>n</sub>''⟩ is called the \"non-commutative polynomial algebra over ''R'' in ''n'' indeterminates\". Note that unlike in an actual [[polynomial ring]], the variables do not [[commutative operation|commute]]. For example, ''X''<sub>1</sub>''X''<sub>2</sub> does not equal ''X''<sub>2</sub>''X''<sub>1</sub>.\n\nMore generally, one can construct the free algebra ''R''⟨''E''⟩ on any set ''E'' of [[generating set|generators]]. Since rings may be regarded as '''Z'''-algebras, a '''free ring''' on ''E'' can be defined as the free algebra '''Z'''⟨''E''⟩.\n\nOver a [[field (mathematics)|field]], the free algebra on ''n'' indeterminates can be constructed as the [[tensor algebra]] on an ''n''-dimensional [[vector space]].  For a more general coefficient ring, the same construction works if we take the [[free module]] on ''n'' [[generating set|generators]].\n\nThe construction of the free algebra on ''E'' is [[functor]]ial in nature and satisfies an appropriate [[universal property]]. The free algebra functor is [[left adjoint]] to the [[forgetful functor]] from the category of ''R''-algebras to the [[category of sets]].\n\nFree algebras over [[division ring]]s are [[free ideal ring]]s.\n\n==See also==\n\n*[[Cofree coalgebra]]\n*[[Tensor algebra]]\n*[[Free object]]\n*[[Noncommutative ring]]\n*[[Rational series]]\n\n==References==\n* {{cite book | last1=Berstel | first1=Jean | last2=Reutenauer | first2=Christophe | title=Noncommutative rational series with applications | series=Encyclopedia of Mathematics and Its Applications | volume=137 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2011 | isbn=978-0-521-19022-0 | zbl=1250.68007 }}\n* {{springer|id=f/f041520|author=L.A. Bokut'|title=Free associative algebra}}\n\n[[Category:Algebras]]\n[[Category:Ring theory]]\n[[Category:Free algebraic structures]]"
    },
    {
      "title": "Frobenius algebra",
      "url": "https://en.wikipedia.org/wiki/Frobenius_algebra",
      "text": "{{Use American English|date = February 2019}}\n{{Short description|Algebraic structure with \"nice\" duality properties}}\n{{dablink|\"Frobenius algebra\" is also an archaic name for the [[group ring]] of a finite group}}\nIn [[mathematics]], especially in the fields of [[representation theory]] and [[module theory]], a '''Frobenius algebra''' is a [[dimension (vector space)|finite-dimensional]] [[unital ring|unital]] [[associative algebra]] with a special kind of [[bilinear form]] which gives the algebras particularly nice duality theories.  Frobenius algebras began to be studied in the 1930s by [[Richard Brauer|Brauer]] and [[Cecil J. Nesbitt|Nesbitt]] and were named after [[Ferdinand Georg Frobenius|Frobenius]].  [[Tadashi Nakayama (mathematician)|Nakayama]] discovered the beginnings of a rich duality theory {{harv|Nakayama|1939}}, {{harv|Nakayama|1941}}.  [[Jean Dieudonné|Dieudonné]] used this to characterize Frobenius algebras {{harv|Dieudonné|1958}}.  Frobenius algebras were generalized to [[quasi-Frobenius ring]]s, those [[Noetherian ring]]s whose right [[regular representation]] is [[injective module|injective]]. In recent times, interest has been renewed in Frobenius algebras due to connections to [[topological quantum field theory]].\n\n==Definition==\nA finite-dimensional, unital, [[associative algebra]] ''A'' defined over a [[field (mathematics)|field]] ''k'' is said to be a '''Frobenius algebra''' if ''A'' is equipped with a [[nondegenerate bilinear form|nondegenerate]] [[bilinear form]] σ:''A'' × ''A'' → ''k'' that satisfies the following equation: ''σ''(''a''·''b'',''c'')=''σ''(''a'',''b''·''c'').  This bilinear form is called the '''Frobenius form''' of the algebra.\n\nEquivalently, one may equip ''A'' with a [[linear functional]] ''λ'' : ''A'' → ''k'' such that the [[kernel (algebra)|kernel]] of ''λ'' contains no nonzero left [[ideal (ring theory)|ideal]] of ''A''.\n\nA Frobenius algebra is called '''symmetric''' if ''σ'' is [[symmetric bilinear form|symmetric]], or equivalently ''λ'' satisfies ''λ''(''a''·''b'') = ''λ''(''b''·''a'').\n\nThere is also a different, mostly unrelated notion of the [[symmetric algebra]] of a [[vector space]].\n\n==Examples==\n# Any [[matrix ring|matrix algebra]] defined over a field ''k'' is a Frobenius algebra with Frobenius form ''σ''(''a'',''b'')=tr(''a''·''b'') where tr denotes the [[trace (linear algebra)|trace]].\n# Any finite-dimensional unital associative algebra ''A'' has a natural homomorphism to its own endomorphism ring End(''A''). A bilinear form can be defined on ''A'' in the sense of the previous example. If this bilinear form is nondegenerate, then it equips ''A'' with the structure of a Frobenius algebra.\n# Every [[group ring]] of a [[finite group]] over a field is a Frobenius algebra, with Frobenius form ''σ''(''a'',''b'') the coefficient of the identity element in ''a''·''b''. This is a special case of example 2.\n# For a field ''k'', the four-dimensional ''k''-algebra ''k''[''x'',''y'']/ (''x''<sup>2</sup>, ''y''<sup>2</sup>) is a Frobenius algebra. This follows from the characterization of commutative local Frobenius rings below, since this ring is a local ring with its maximal ideal generated by ''x'' and ''y'', and unique minimal ideal generated by ''xy''. \n# For a field ''k'', the three-dimensional ''k''-algebra ''A''=''k''[''x'',''y'']/ (''x'', ''y'')<sup>2</sup> is '''not''' a Frobenius algebra. The ''A'' homomorphism from ''xA'' into ''A'' induced by ''x'' ↦ ''y'' cannot be extended to an ''A'' homomorphism from ''A'' into ''A'', showing that the ring is not self-injective, thus not Frobenius.\n#Any finite-dimensional [[Hopf algebra]], by a 1969 theorem of Larson-Sweedler on Hopf modules and integrals.\n\n==Properties==\n* The [[product of rings|direct product]] and [[tensor product]] of Frobenius algebras are Frobenius algebras.\n* A finite-dimensional [[commutative ring|commutative]] [[local ring|local]] algebra over a field is Frobenius if and only if the right [[regular module]] is injective, if and only if the algebra has a unique [[minimal ideal]].\n* Commutative, local Frobenius algebras are precisely the [[Krull dimension|zero-dimensional]] local [[Gorenstein ring]]s containing their [[residue field]] and finite-dimensional over it.\n* Frobenius algebras are [[quasi-Frobenius ring]]s, and in particular, they are left and right [[Artinian ring|Artinian]] and left and right [[self-injective ring|self-injective]].\n* For a field ''k'', a finite-dimensional, unital, [[associative algebra]] is Frobenius if and only if the [[injective object|injective]] right ''A''-module Hom<sub>''k''</sub>(''A'',''k'') is isomorphic to the right [[regular representation]] of ''A''.\n* For an infinite field ''k'', a finite-dimensional, unitial, associative ''k''-algebra is a Frobenius algebra if it has only finitely many minimal [[right ideal]]s.\n* If ''F'' is a finite-dimensional [[extension field]] of ''k'', then a finite-dimensional ''F''-algebra is naturally a finite-dimensional ''k''-algebra via [[restriction of scalars]], and is a Frobenius ''F''-algebra if and only if it is a Frobenius ''k''-algebra.  In other words, the Frobenius property does not depend on the field, as long as the algebra remains a finite-dimensional algebra.\n* Similarly, if ''F'' is a finite-dimensional extension field of ''k'', then every ''k''-algebra  ''A'' gives rise naturally to a ''F'' algebra, ''F'' ⊗<sub>''k''</sub> ''A'', and ''A'' is a Frobenius ''k''-algebra if and only if ''F'' ⊗<sub>''k''</sub> ''A'' is a Frobenius ''F''-algebra.\n* Amongst those finite-dimensional, unital, associative algebras whose right regular representation is injective, the Frobenius algebras ''A'' are precisely those whose [[simple module]]s ''M'' have the same dimension as their ''A''-duals, Hom<sub>''A''</sub>(''M'',''A'').  Amongst these algebras, the ''A''-duals of simple modules are always simple.\n\n==Category-theoretical definition==\nIn [[category theory]], the notion of '''Frobenius object''' is an abstract definition of a Frobenius algebra in a category. A Frobenius object <math>(A,\\mu,\\eta,\\delta,\\varepsilon)</math> in a [[monoidal category]] <math>(C,\\otimes,I)</math> consists of an object ''A'' of ''C'' together with four morphisms\n\n:<math>\\mu:A\\otimes A\\to A,\\qquad \\eta:I\\to A,\\qquad\\delta:A\\to A\\otimes A\\qquad\\mathrm{and}\\qquad\\varepsilon:A\\to I</math>\n\nsuch that\n\n* <math>(A,\\mu,\\eta)\\,</math> is a [[monoid object]] in ''C'',\n* <math>(A,\\delta,\\varepsilon)</math> is a [[comonoid object]] in ''C'',\n* the diagrams\n:[[Image:Frobenius obj coh 1.png]]\nand\n:[[Image:Frobenius obj coh 2.png]]\ncommute (for simplicity the diagrams are given here in the case where the monoidal category ''C'' is strict) and are known as '''Frobenius conditions'''.<ref>{{citation|author=Pavlovic, Dusko|url=https://www.sciencedirect.com/science/article/pii/S0890540113000254|title=Monoidal computer I: Basic computability by string diagrams|journal=Information and Computation|volume=226|pages=94–116|year=2013|doi=10.1016/j.ic.2013.03.007|arxiv=1208.5205}}</ref>\n\nMore compactly, a Frobenius algebra in '''C''' is a so-called Frobenius monoidal functor A:'''1''' → '''C''', where '''1''' is the category consisting of one object and one arrow.\n\nA Frobenius algebra is called '''isometric''' or '''special''' if <math>\\mu\\circ\\delta = \\mathrm{Id}_A</math>.\n\n==Applications==\nFrobenius algebras originally were studied as part of an investigation into the [[representation theory of finite groups]], and have contributed to the study of [[number theory]], [[algebraic geometry]], and [[combinatorics]].  They have been used to study [[Hopf algebra]]s, [[coding theory]], and [[cohomology ring]]s of [[compact space|compact]] [[orientability|oriented]] [[manifold]]s.\n\n=== Topological quantum field theories ===\n[[File:Pair of pants cobordism (pantslike).svg|thumb|The product and coproduct on a Frobenius algebra can be interpreted as the functor of a (1+1)-dimensional [[topological quantum field theory]], applied to a [[pair of pants (mathematics)|pair of pants]].]]\n{{details|Topological quantum field theory}}\n\nRecently, it has been seen that they play an important role in the algebraic treatment and axiomatic foundation of [[topological quantum field theory]].  A commutative Frobenius algebra determines uniquely (up to isomorphism) a (1+1)-dimensional TQFT.  More precisely, the [[category (category theory)|category]] of commutative Frobenius ''K''-algebras is [[equivalence of categories|equivalent]] to the category of [[symmetric monoidal functor|symmetric strong monoidal functors]] from 2-'''Cob''' (the category of 2-dimensional [[cobordism]]s between 1-dimensional manifolds) to '''Vect'''<sub>''K''</sub> (the category of [[vector space]]s over ''K'').\n\nThe correspondence between TQFTs and Frobenius algebras is given as follows:\n* 1-dimensional manifolds are disjoint unions of circles: a TQFT associates a vector space with a circle, and the tensor product of vector spaces with a disjoint union of circles,\n* a TQFT associates (functorially) to each cobordism between manifolds a map between vector spaces,\n* the map associated with a [[pair of pants (mathematics)|pair of pants]] (a cobordism between 1 circle and 2 circles) gives a product map ''V'' ⊗ ''V'' → ''V'' or a coproduct map ''V'' → ''V'' ⊗ ''V'', depending on how the boundary components are grouped – which is commutative or cocommutative, and\n* the map associated with a disk gives a counit (trace) or unit (scalars), depending on grouping of boundary.\n\nThis relation between Frobenius-algebras and (1+1)-dimensional TQFTs can be used to explain the [[Khovanov homology|Khovanov's categorification]] of the [[Jones polynomial]].<ref>{{citation|author=Bar-Natan, Dror|arxiv=math/0410495|title=Khovanov's homology for tangles and cobordisms|journal=Geom. Topol.|volume=9|issue=9|pages=1443–1499|year=2005|bibcode=2004math.....10495B|doi=10.2140/gt.2005.9.1443}}</ref><ref>{{citation|title=Five Lectures on Khovanov Homology|author=Paul Turner|arxiv=math/0606464v1|year=2006|bibcode=2006math......6464T}}</ref>\n\n== Generalization: Frobenius extension ==\nLet ''B'' be a subring sharing the identity element of a unital associative ring ''A''. This is also known as ring extension ''A'' | ''B''. Such a ring extension is called '''Frobenius''' if\n\n* There is a linear mapping ''E'': ''A'' → ''B'' satisfying the bimodule condition ''E(bac)'' = ''bE(a)c'' for all ''b,c'' ∈ ''B'' and ''a'' ∈ ''A''.\n*There are elements in ''A'' denoted <math>\\{x_i \\}^n_{i=1}</math> and <math> \\{y_i \\}^n_{i=1} </math> such that for all ''a'' ∈ ''A'' we have:\n\n:<math> \\sum_{i=1}^n E(ax_i) y_i = a = \\sum_{i=1}^n x_i E(y_i a)</math>\n\nThe map ''E'' is sometimes referred to as a Frobenius homomorphism and the elements <math>x_i, y_i</math> as dual bases. (As an exercise it is possible to give an equivalent definition of Frobenius extension as a Frobenius algebra-coalgebra object in the category of ''B''-''B''-bimodules, where the equations just given become the counit equations for the counit ''E''.)\n\nFor example, a Frobenius algebra ''A'' over a commutative ring ''K'', with associative nondegenerate bilinear form (-,-) and projective K-bases <math> x_i, y_i</math> is a Frobenius extension ''A'' | ''K'' with ''E(a)'' = (''a'',1). Other examples of Frobenius extensions are pairs of group algebras associated to a subgroup of finite index, Hopf subalgebras of a semisimple Hopf algebra, Galois extensions and certain von Neumann algebra subfactors of finite index. Another source of examples of Frobenius extensions (and twisted versions) are certain subalgebra pairs of Frobenius algebras, where the subalgebra is stabilized by the symmetrizing automorphism of the overalgebra.\n\nThe details of the [[group ring]] example are the following application of elementary notions in [[group theory]]. Let ''G'' be a group and ''H'' a subgroup of finite index ''n'' in ''G''; let ''g''<sub>1</sub>, ..., ''g<sub>n</sub>''. be left coset representatives, so that ''G'' is a disjoint union of the cosets ''g''<sub>1</sub>''H'', ..., ''g<sub>n</sub>H''. Over any commutative base ring k define the group algebras ''A'' = ''k[G]'' and ''B'' = ''k[H]'', so ''B'' is a subalgebra of ''A''. Define a Frobenius homomorphism ''E'': ''A'' → ''B'' by letting ''E(h)'' = ''h'' for all ''h'' in ''H'', and ''E(g)'' = 0 for ''g'' not in ''H'' : extend this linearly from the basis group elements to all of ''A'', so one obtains the ''B''-''B''-bimodule projection\n\n:<math>E \\left (\\sum_{g \\in G} n_g g \\right ) = \\sum_{h \\in H} n_h h \\ \\ \\ \\text{ for } n_g \\in k </math>\n\n(The orthonormality condition <math>E(g_i^{-1}g_j) = \\delta_{ij} 1</math> follows.)  The dual base  is given by <math>x_i = g_i, y_i = g_i^{-1} </math>, since\n\n:<math> \\sum_{i=1}^n g_i E(g_i^{-1} \\sum_{g \\in G} n_g g) = \\sum_i \\sum_{h \\in H} n_{g_ih} g_ih = \\sum_{g \\in G} n_g g </math>\n\nThe other dual base equation may be derived from the observation that G is also a disjoint union of the right cosets <math> Hg_1^{-1},\\ldots,Hg_n^{-1}</math>.\n\nAlso Hopf-Galois extensions are Frobenius extensions by a theorem of Kreimer and Takeuchi from 1989.  A simple example of this is a finite group ''G'' acting by automorphisms on an algebra ''A'' with subalgebra of invariants:\n\n:<math>B = \\{ x \\in A | \\forall g \\in G, g(x) = x \\}.</math>\n\nBy DeMeyer's criterion ''A'' is ''G''-Galois over ''B'' if there are elements <math>\\{ a_i \\}_{i=1}^n,  \\{ b_i \\}_{i=1}^n </math> in ''A'' satisfying:\n\n:<math> \\forall g \\in G: \\ \\  \\sum_{i=1}^n a_i g(b_i) = \\delta_{g,1_G}1_A </math>\n\nwhence also\n\n:<math> \\forall g \\in G: \\ \\ \\sum_{i=1}^n g(a_i) b_i = \\delta_{g,1_G}1_A.</math>\n\nThen ''A'' is a Frobenius extension of ''B'' with ''E'': ''A'' → ''B'' defined by\n\n:<math> E(a) = \\sum_{g \\in G} g(a)</math>\n\nwhich satisfies\n\n:<math> \\forall x \\in A: \\ \\ \\sum_{i=1}^n E(xa_i)b_i = x = \\sum_{i=1}^n a_i E(b_i x). </math>\n\n(Furthermore, an example of a [[separable algebra]] extension since <math>e = \\sum_{i=1}^n a_i \\otimes_B b_i</math> is a separability element satisfying ''ea = ae'' for all ''a'' in ''A'' as well as <math>\\sum_{i=1}^n a_i b_i = 1</math>. Also an example of a [[depth two subring]] (''B'' in ''A'') since\n\n:<math> a \\otimes_B 1 = \\sum_{g \\in G} t_g g(a)</math>\n\nwhere\n\n:<math> t_g = \\sum_{i=1}^n a_i \\otimes_B g(b_i)</math>\n\nfor each ''g'' in ''G'' and ''a'' in ''A''.)\n\nFrobenius extensions have a well-developed theory of induced representations investigated in papers by  Kasch and Pareigis, Nakayama and Tzuzuku in the 1950s and 1960s. For example, for each ''B''-module ''M'', the induced module ''A'' ⊗<sub>''B''</sub> ''M'' (if ''M'' is a left module) and co-induced module Hom<sub>''B''</sub>(''A, M'') are naturally isomorphic as ''A''-modules (as an exercise one defines the isomorphism given ''E'' and dual bases). The endomorphism ring theorem of Kasch from 1960 states that if ''A'' | ''B'' is a Frobenius extension, then so is ''A'' → End(''A<sub>B</sub>'') where the mapping is given by ''a'' ↦ ''λ<sub>a</sub>(x)'' and ''λ<sub>a</sub>(x) = ax'' for each ''a,x'' ∈ ''A''. Endomorphism ring theorems and converses were investigated later by Mueller, Morita, Onodera and others.\n\n==See also==\n{{colbegin}}\n* [[Bialgebra]]\n* [[Frobenius category]]\n* [[Frobenius norm]]\n* [[Frobenius inner product]]\n* [[Hopf algebra]]\n* [[Quasi-Frobenius Lie algebra]]\n* [[Dagger compact category]]\n{{colend}}\n\n==References==\n{{Reflist}}\n*{{Citation | last1=Brauer | first1=R. | author1-link=Richard Brauer | last2=Nesbitt | first2=C. | author2-link=Cecil J. Nesbitt | title=On the regular representations of algebras. | pmid=16588158 | pmc=1076908 | doi=10.1073/pnas.23.4.236 | year=1937 | journal=Proc. Natl. Acad. Sci. USA | volume=23 | issue=4 | pages=236–240| bibcode=1937PNAS...23..236B }}\n* {{Citation | last1=DeMeyer, F. | first1=Ingraham, E. | title=Separable Algebras over Commutative Rings | publisher=Springer | series=Lect. Notes Math 181 | year=1971}}\n* {{Citation | last1=Dieudonné | first1=Jean | author1-link=Jean Dieudonné | title=Remarks on quasi-Frobenius rings | mr=0097427  | year=1958 | journal=Illinois Journal of Mathematics | issn=0019-2082 | volume=2 | issue=3 | pages=346–354| doi=10.1215/ijm/1255454538 }}\n* {{Citation | last1=Frobenius | first1=Ferdinand Georg | author1-link=Ferdinand Georg Frobenius | title=Theorie der hyperkomplexen Größen I | language=German | year=1903 | journal=Sitzungsberichte der Preussischen Akademie der Wissenschaften | pages=504–537 | jfm=34.0238.02}}\n* {{Citation | last1=Kock | first1=Joachim | title=Frobenius Algebras and 2D Topological Quantum Field Theories | publisher=Cambridge University Press | location=Cambridge | series=London Mathematical Society student texts | isbn=978-0-521-83267-0 | year=2003}}\n* {{Citation | last1=Lam | first1=T. Y. | title=Lectures on modules and rings | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics No. 189 | isbn=978-0-387-98428-5 | year=1999}}\n* {{Citation | last=Lurie | first=Jacob | title = On the Classification of Topological Field Theories\n|url = http://www-math.mit.edu/~lurie/papers/cobordism.pdf }}\n* {{Citation | last1=Nakayama | first1=Tadasi | author1-link=Tadashi Nakayama (mathematician) | title=On Frobeniusean algebras. I | doi=10.2307/1968946 | mr=0000016  | year=1939 | journal=[[Annals of Mathematics]] |series=Second Series | volume=40 | pages=611–633 | issue=3 | publisher=Annals of Mathematics | jstor=1968946}}\n* {{Citation | last1=Nakayama | first1=Tadasi | author1-link=Tadashi Nakayama (mathematician) | title=On Frobeniusean algebras. II | doi=10.2307/1968984 | mr=0004237  | year=1941 | journal=[[Annals of Mathematics]] |series=Second Series | volume=42 | pages=1–21 | issue=1 | publisher=Annals of Mathematics | jstor=1968984}}\n* {{Citation | last1=Nesbitt | first1=C. | author1-link=Cecil J. Nesbitt | title=On the regular representations of algebras | doi=10.2307/1968639 | mr=1503429  | year=1938 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=39 | issue=3 | pages=634–658 | jstor=1968639 }}\n* {{Citation | last1=Onodera | first1=T. | title=Some studies on projective Frobenius extensions | year=1964 | journal=[[Hokkaido Univ. Ser. 1]] | volume=18 | issue=1–2 | pages=89–107| doi=10.14492/hokmj/1530691549 }}\n\n==External links==\n* Ross Street, [http://www.maths.mq.edu.au/~street/FAMC.pdf Frobenius algebras and monoidal categories]\n\n{{DEFAULTSORT:Frobenius Algebra}}\n[[Category:Algebras]]\n[[Category:Module theory]]\n[[Category:Monoidal categories]]"
    },
    {
      "title": "Functional-theoretic algebra",
      "url": "https://en.wikipedia.org/wiki/Functional-theoretic_algebra",
      "text": "Any vector space can be made into a [[unital algebra|unital]] [[associative algebra]], called '''functional-theoretic algebra''',  by defining products in terms of two linear [[functional (mathematics)|functionals]]. In general, it is a [[non-commutative algebra]]. It becomes commutative when the two functionals are the same. \n==Definition==\nLet ''A<sub>F</sub>'' be a [[vector space]] over a [[field (mathematics)|field]] ''F'', and let ''L''<sub>1</sub> and ''L''<sub>2</sub> be two [[linear functional]]s on A<sub>F</sub> with the property ''L''<sub>1</sub>(''e'') = ''L''<sub>2</sub>(''e'') = 1<sub>''F''</sub>  for some ''e'' in ''A<sub>F</sub>''. We define multiplication of two elements ''x'', ''y'' in ''A<sub>F</sub>''  by\n:<math> x \\cdot y = L_1(x)y + L_2(y)x - L_1(x) L_2(y) e. </math>\nIt can be verified that the above multiplication is associative and that ''e'' is the identity of this multiplication. \n\nSo, A<sub>F</sub> forms an associative algebra with unit ''e'' and is called a ''functional theoretic algebra''(FTA).\n\nSuppose the two linear functionals ''L''<sub>1</sub> and ''L''<sub>2</sub> are the same, say ''L.'' Then ''A<sub>F</sub>'' becomes a commutative algebra with multiplication defined by\n:<math> x \\cdot y = L(x)y + L(y)x - L(x)L(y)e. </math>\n\n==Example==\n''X'' is a nonempty set and ''F'' a field. ''F''<sup>''X''</sup> is the set of functions from ''X''  to ''F''.\n\nIf ''f, g'' are in ''F''<sup>''X''</sup>, ''x'' in ''X'' and ''α''  in ''F'', then define \n\n:<math> (f+g)(x) = f(x) + g(x)\\,</math>\n\nand \n\n:<math> (\\alpha f)(x)=\\alpha f(x).\\,</math>\n\nWith addition and scalar multiplication defined as this, ''F''<sup>''X''</sup> is a vector space over ''F.''\n\nNow, fix two elements ''a, b'' in ''X'' and define a function ''e'' from ''X'' to ''F'' by ''e''(''x'') = 1<sub>''F''</sub> for all ''x'' in ''X''. \n\nDefine ''L''<sub>1</sub> and ''L<sub>2</sub>'' from ''F''<sup>''X''</sup> to ''F'' by ''L''<sub>1</sub>(''f'') = ''f''(''a'') and ''L''<sub>2</sub>(''f'') = ''f''(''b'').  \n\nThen ''L''<sub>1</sub> and ''L''<sub>2</sub> are two linear functionals on ''F''<sup>''X''</sup> such that ''L''<sub>1</sub>(''e'')= ''L''<sub>2</sub>(''e'')= 1<sub>''F''</sub>\nFor ''f, g'' in ''F''<sup>''X''</sup> define \n\n:<math> f \\cdot g = L_1(f)g + L_2(g)f - L_1(f) L_2(g) e = f(a)g + g(b)f - f(a)g(b)e. </math>\n\nThen ''F''<sup>''X''</sup> becomes a non-commutative function algebra with the function ''e'' as the identity of multiplication.\n\nNote that \n:<math> (f \\cdot g)(a) = f(a)g(a)\\mbox{ and }  (f \\cdot g)(b) = f(b)g(b). </math>\n\n==FTA of Curves in the Complex Plane==\nLet '''C''' denote the [[field (mathematics)|field]] of\n[[Complex numbers.]] \nA continuous function ''γ'' from the closed\ninterval [0, 1] of real numbers to the field '''C''' is called a\ncurve. The complex numbers ''γ''(0) and ''γ''(1) are, respectively,\nthe initial and terminal points of the curve. \nIf they coincide, the\ncurve is called a ''loop''. \nThe set ''V''[0, 1] of all the curves is a\nvector space over '''C'''.\n\nWe can make this vector space of curves into an\nalgebra by defining multiplication as above.\nChoosing <math>e(t) = 1, \\forall \\in [0, 1] </math> we have for  ''α,β'' in ''C''[0, 1],\n:<math> {\\alpha} \\cdot {\\beta} = {\\alpha}(0){\\beta} + {\\beta}(1){\\alpha} - {\\alpha}(0){\\beta}(1)e </math>\nThen, ''V''[0, 1] is a non-commutative algebra with ''e'' as the unity.\n\nWe illustrate\nthis with an example.\n\n==Example of f-Product of Curves==\nLet us take (1) the line segment joining the points (1, 0) and (0, 1) and (2) the unit circle with center at the\norigin.\nAs curves in ''V''[0, 1], their equations can be obtained as \n:<math> f(t)=1 - t + it \\mbox{ and } g(t)= \\cos(2\\pi t)+ i\\sin(2\\pi t)\n</math>  \n\nSince <math>g(0)=g(1)=1</math> the circle ''g''\nis a loop. \nThe line segment  ''f'' starts from :<math> f(0)=1 </math>\nand ends at <math> f(1)= i </math> \n\nNow, we get two ''f''-products\n<math> f \\cdot g \\mbox{ and } g \\cdot f</math> given by \n\n:<math>(f\\cdot g)(t)=[-t+\\cos (2\\pi t)]+i[t+\\sin(2\\pi t)]</math> \nand\n:<math>(g\\cdot f)(t)=[1-t - \\sin (2\\pi t)] +i[t-1+\\cos(2\\pi t)]\n</math>\nSee the Figure.\n[[File:curve2.jpg]]\n\nObserve that <math> f\\cdot g \\neq g\\cdot f</math> showing that \nmultiplication is non-commutative. Also both the products starts from <math> f(0)g(0)=1 \\mbox{ and ends at }\n f(1)g(1)= i. </math>\n\n==See also==\n* [[N-curve]]\n\n==References==\n{{refbegin}}\n* Sebastian Vattamattam and R. Sivaramakrishnan, ``A Note on Convolution Algebras\", in ''Recent Trends in Mathematical Analysis'', Allied Publishers, 2003.\n* Sebastian Vattamattam and R. Sivaramakrishnan, ''Associative Algebras via Linear Functionals'', Proceedings of the Annual Conference of K.M.A., Jan. 17 - 19, 2000, pp.&nbsp;81-89  \n* Sebastian Vattamattam, ``Non-Commutative Function Algebras'', in ``Bulletin of [[Kerala Mathematical Association]]'', Vol. 4, No. 2, December 2007 \n* Sebastian Vattamattam, ``Transforming Curves by n-Curving'', in ``Bulletin of Kerala Mathematics Association'', Vol. 5, No. 1, December 2008\n* Sebastian Vattamattam, ``Book of Beautiful Curves'', January 2015\n[https://www.amazon.com/dp/B00U7LTB2A Book of Beautiful Curves]\n* R. Sivaramakrishnan, ``Certain Number Theoretic Episodes in Algebra'', Chapman and Hall/CRC\n[http://www.tower.com/certain-number-theoretic-episodes-in-algebra-r-sivaramakrishnan-hardcover/wapi/101300456 Certain Number Theoretic Episodes in Algebra]\n{{refend}}\n\n[[Category:Algebras]]"
    },
    {
      "title": "Generalized Clifford algebra",
      "url": "https://en.wikipedia.org/wiki/Generalized_Clifford_algebra",
      "text": "{{About|the algebra called generalized Clifford algebra (GCA)|(orthogonal) Clifford algebra|Clifford algebra|symplectic Clifford algebra|Weyl algebra}}\n\nIn [[mathematics]], a '''Generalized Clifford algebra''' (GCA) is an [[associative algebra]] that generalizes the [[Clifford algebra]], and goes back to the work of [[Hermann Weyl]],<ref>[[Hermann Weyl|Weyl, H.]], \"Quantenmechanik und Gruppentheorie\", ''Zeitschrift für Physik'',  '''46''' (1927) pp. 1–46, \n{{doi|10.1007/BF02055756}}. Weyl, H., ''The Theory of Groups and Quantum Mechanics'' (Dover, New York, 1931)</ref> who  utilized and formalized  these [[Generalizations of Pauli matrices|'''clock-and-shift''']] operators introduced by [[James Joseph Sylvester|J. J. Sylvester]] (1882),<ref>Sylvester, J. J., (1882), ''Johns Hopkins University Circulars'' '''I''': 241-242; ibid '''II''' (1883) 46;\nibid '''III''' (1884) 7–9. Summarized in ''The Collected Mathematics Papers of James Joseph Sylvester'' (Cambridge University Press, 1909) v '''III''' . \n[http://quod.lib.umich.edu/u/umhistmath/aas8085.0003.001/664?rgn=full+text;view=pdf;q1=nonions online]  and [http://quod.lib.umich.edu/u/umhistmath/AAS8085.0004.001/165?cite1=Sylvester;cite1restrict=author;rgn=full+text;view=pdf  further].\n</ref> and organized by  [[Élie Cartan|Cartan]] (1898)<ref>Cartan, E. (1898). \"Les groupes bilinéaires et les systèmes de nombres complexes.\" ''Annales de la faculté \ndes sciences de Toulouse'' '''12.1''' B65-B99. [http://archive.numdam.org/ARCHIVE/AFST/AFST_1898_1_12_2/AFST_1898_1_12_2_B65_0/AFST_1898_1_12_2_B65_0.pdf online]</ref>  and  [[Julian Schwinger|Schwinger]].<ref>[[Julian Schwinger|Schwinger, J.]] (1960), \"Unitary operator bases\", ''Proc Natl Acad Sci U S A'', April; 46(4): 570–579, {{PMC|222876}}; ''ibid'', \"Unitary transformations and the action principle\", 46(6): 883–897, {{PMC|222951}}</ref>\n\nClock and shift matrices find routine applications in numerous areas of mathematical physics, providing the cornerstone of '''quantum mechanical dynamics in finite-dimensional vector spaces'''.<ref>{{Cite journal | last1 = Santhanam | first1 = T. S. | last2 = Tekumalla | first2 = A. R. | doi = 10.1007/BF00715110 | title = Quantum mechanics in finite dimensions | journal = Foundations of Physics | volume = 6 | issue = 5 | pages = 583 | year = 1976 | pmid =  | pmc = | bibcode = 1976FoPh....6..583S }}</ref><ref name=\"granik-et-al-1996\"/><ref>A. K. Kwaśniewski: ''On Generalized Clifford Algebra C4(n) and GLq(2;C) quantum group''</ref> The concept of a [[spinor]] can further be linked to these algebras.<ref name=\"granik-et-al-1996\"/>\n\nThe term Generalized Clifford Algebras can also refer to associative algebras that are constructed using forms of higher degree instead of quadratic forms.<ref>{{cite book|last1=Tesser|first1=Steven Barry|editor1-last=Micali|editor1-first=A.|editor2-last=Boudet|editor2-first=R.|editor3-last=Helmstetter|editor3-first=J.|title=Clifford algebras and their applications in mathematical physics|date=2011|publisher=Springer|location=Dordrecht|isbn=978-90-481-4130-2|pages=133–141|chapter=Generalized Clifford algebras and their representations}}</ref><ref>{{cite journal|last1=Childs|first1=Lindsay N.|title=Linearizing of n-ic forms and generalized Clifford algebras|journal=Linear and Multilinear Algebra|date=30 May 2007|volume=5|issue=4|pages=267–278|doi=10.1080/03081087808817206}}</ref><ref>{{cite journal|last1=Pappacena|first1=Christopher J.|title=Matrix pencils and a generalized Clifford algebra|journal=Linear Algebra and its Applications|date=July 2000|volume=313|issue=1-3|pages=1–20|doi=10.1016/S0024-3795(00)00025-2}}</ref><ref>{{cite journal|last1=Chapman|first1=Adam|last2=Kuo|first2=Jung-Miao|title=On the generalized Clifford algebra of a monic polynomial|journal=Linear Algebra and its Applications|date=April 2015|volume=471|pages=184–202|doi=10.1016/j.laa.2014.12.030|arxiv=1406.1981}}</ref>\n\n== Definition and properties ==\n\n===  Abstract definition ===\nThe {{mvar|n}}-dimensional generalized Clifford algebra is defined as an associative algebra over a field {{mvar|F}}, generated by<ref>For a serviceable review, \nsee  Vourdas A. (2004), \"Quantum systems with finite Hilbert space\",  ''Rep. Prog. Phys.''  '''67'''  267.  {{doi|10.1088/0034-4885/67/3/R03}}.</ref>\n:<math>e_j e_k = \\omega_{jk} e_k e_j \\,</math>\n:<math>\\omega_{jk} e_l = e_l \\omega_{jk} \\,</math>\n:<math>\\omega_{jk} \\omega_{lm} = \\omega_{lm} \\omega_{jk} \\,</math>\nand\n:<math>e_j^{N_j} = 1 = \\omega_{jk}^{N_j} = \\omega_{jk}^{N_k} \\,</math>\n{{math|∀ ''j'',''k'',''l'',''m'' {{=}} 1,...,''n''}}.\n\nMoreover, in any irreducible matrix representation, relevant for physical applications, it is required that\n:<math>\\omega_{jk} = \\omega_{kj}^{-1} = e^{2\\pi i \\nu_{kj}/N_{kj}}</math>\n{{math|∀ ''j'',''k'' {{=}} 1,...,''n''}},  &nbsp; and <math>N_{kj} =</math>[[Greatest common divisor|gcd]]<math> (N_j,N_k)</math>.  The field {{mvar|F}} is usually taken to be the complex numbers '''C'''.\n\n=== More specific definition ===\n {{Main article|Generalizations of Pauli matrices}}\nIn the more common cases of GCA,<ref name=\"granik-et-al-1996\">See for example: A. Granik, M. Ross: ''On a new basis for a Generalized Clifford Algebra and its application to quantum mechanics'', in: Rafal Ablamowicz, Joseph Parra, Pertti Lounesto (eds.): ''Clifford Algebras with Numeric and Symbolic Computation Applications'', Birkhäuser, 1996, {{ISBN|0-8176-3907-1}}, [https://books.google.com/books?id=OpbY_abijtwC&pg=PA101 p. 101]–110</ref> the {{mvar|n}}-dimensional generalized Clifford algebra of order {{mvar|p}} has the property {{math| ''ω<sub>kj</sub>'' {{=}} ''ω''}}, <math>N_k=p</math> &nbsp;  for all ''j'',''k'', and <math>\\nu_{kj}=1</math>.  It follows that \n:<math>e_j e_k = \\omega \\, e_k e_j \\,</math>\n:<math>\\omega e_l = e_l \\omega \\,</math>\nand\n:<math>e_j^{p} = 1 = \\omega^{p} \\,</math>\nfor all ''j'',''k'',l = 1,...,''n'', and \n:<math>\\omega = \\omega^{-1} = e^{2\\pi i /p}</math>\nis the {{mvar|p}}th root of 1.\n\nThere exist several definitions of a Generalized Clifford Algebra in the literature.<ref>See for example the review provided in: Tara L. Smith: [https://math.uc.edu/~tsmith/papers/CliffAlg.pdf ''Decomposition of Generalized Clifford Algebras'']</ref>\n\n;Clifford algebra\nIn the (orthogonal) Clifford algebra, the elements follow an anticommutation rule, with {{math|''ω'' {{=}} −1, and ''p'' {{=}} 2}}.\n\n== Matrix representation ==\n{{Main article|Generalizations of Pauli matrices#Construction: The clock and shift matrices}}\nThe Clock and Shift matrices can be represented<ref>[[Alladi Ramakrishnan]]: ''Generalized Clifford Algebra and its applications – A new approach to internal quantum numbers'', [http://www.imsc.res.in/xmlui/bitstream/handle/123456789/227/MR60.pdf Proceedings of the Conference on Clifford algebra, its Generalization and Applications], January 30 – February 1, 1971, [[Matscience]], Madras 20, pp.&nbsp;87–96</ref> by {{math|''n×n''}} matrices in Schwinger's canonical notation as\n:<math>\nV =\n\\begin{pmatrix}\n0&1&0&\\cdots&0\\\\\n0&0&1&\\cdots&0\\\\\n0&0&\\cdots&1&0\\\\\n\\cdots&\\cdots&\\cdots&\\cdots&\\cdots\\\\\n1&0&0&\\cdots&0\n\\end{pmatrix}\n</math> , &nbsp;&nbsp;&nbsp;<math>U =\n\\begin{pmatrix}\n1&0&0&\\cdots&0\\\\\n0&\\omega&0&\\cdots&0\\\\\n0&0&\\omega^2&\\cdots&0\\\\\n\\cdots&\\cdots&\\cdots&\\cdots&\\cdots\\\\\n0&0&0&\\cdots&\\omega^{(n-1)}\n\\end{pmatrix}\n</math> , &nbsp;&nbsp;&nbsp;<math>\nW =\n\\begin{pmatrix}\n1&1&1&\\cdots&1\\\\\n1&\\omega&\\omega^2&\\cdots&\\omega^{n-1}\\\\\n1&\\omega^2&(\\omega^2)^2&\\cdots&\\omega^{2(n-1)}\\\\\n\\cdots&\\cdots&\\cdots&\\cdots&\\cdots\\\\\n1&\\omega^{n-1}&\\omega^{2(n-1)}&\\cdots&\\omega^{(n-1)^2}\n\\end{pmatrix}\n</math> .\n\nNotably, {{math|''V<sup>n</sup>'' {{=}} 1}},  {{math|''VU'' {{=}} ''ωUV''}} (the [[Stone–von Neumann theorem#Uniqueness of representation|Weyl braiding relations]]), and {{math| ''W<sup>−1</sup>VW'' {{=}} ''U''}} (the [[Discrete Fourier transform]]). \nWith {{math|''e''<sub>1</sub> {{=}} ''V'' , ''e''<sub>2</sub> {{=}} ''VU'', and ''e''<sub>3</sub> {{=}} ''U''}}, one has  three basis elements which, together with {{mvar|ω}}, fulfil the above conditions of the Generalized Clifford Algebra (GCA).\n\nThese matrices, {{mvar|V}} and {{mvar|U}}, normally referred to as \"[[Generalizations of Pauli matrices#Construction 2|shift and clock matrices]]\",  were introduced by  [[James Joseph Sylvester|J. J. Sylvester]] in the 1880s. (Note that the matrices   {{mvar|V}} are cyclic [[permutation matrices]] that perform a [[circular shift]]; ''they are not to be confused'' with [[shift matrix|upper and lower shift matrices]] which have ones only either above or below the diagonal, respectively).\n\n=== Specific examples ===\n;Case {{math|''n'' {{=}} ''p'' {{=}} 2}}.\nIn this case,  we have  {{mvar|ω}} =  −1, and\n:<math>\nV =\n\\begin{pmatrix}\n0&1\\\\\n1&0\n\\end{pmatrix}\n</math> , &nbsp;&nbsp;&nbsp;<math>\nU =\n\\begin{pmatrix}\n1&0\\\\\n0&-1\n\\end{pmatrix}\n</math> , &nbsp;&nbsp;&nbsp;<math>\nW =\n\\begin{pmatrix}\n1&1\\\\\n1&-1\n\\end{pmatrix}\n</math>\nthus\n:<math>\ne_1 =\n\\begin{pmatrix}\n0&1\\\\\n1&0\n\\end{pmatrix}\n</math> , &nbsp;&nbsp;&nbsp;<math>\ne_2 =\n\\begin{pmatrix}\n0&-1\\\\\n1&0\n\\end{pmatrix}\n</math> , &nbsp;&nbsp;&nbsp;<math>\ne_3 =\n\\begin{pmatrix}\n1&0\\\\\n0&-1\n\\end{pmatrix}\n</math> ,\nwhich constitute the [[Pauli matrices]].\n\n;Case {{math|''n'' {{=}} ''p'' {{=}} 4}}, \nIn this case we have  {{mvar|ω}} = {{mvar|i}},  and\n:<math>\nV =\n\\begin{pmatrix}\n0&1&0&0\\\\\n0&0&1&0\\\\\n0&0&0&1\\\\\n1&0&0&0\n\\end{pmatrix}\n</math>  , &nbsp;&nbsp;&nbsp;<math>\nU =\n\\begin{pmatrix}\n1&0&0&0\\\\\n0&i&0&0\\\\\n0&0&-1&0\\\\\n0&0&0&-i\n\\end{pmatrix}\n</math>  , &nbsp;&nbsp;&nbsp;<math>\nW =\n\\begin{pmatrix}\n1&1&1&1\\\\\n1&i&-1&-i\\\\\n1&-1&1&-1\\\\\n1&-i&-1&i\n\\end{pmatrix} \n</math>\nand {{math|''e''<sub>1</sub>, ''e''<sub>2</sub>, ''e''<sub>3</sub>}} may be determined accordingly.\n\n== See also ==\n*[[Clifford algebra]]\n*[[Generalizations of Pauli matrices]]\n*[[DFT matrix]]\n*[[Circulant matrix]]\n\n== References ==\n{{reflist}}\n\n== Further reading ==\n* R. Jagannathan, [https://arxiv.org/abs/1005.4300/ On generalized Clifford algebras and their physical applications]\n* K. Morinaga, T. Nono (1952): ''On the linearization of a form of higher degree and its representation'', J. Sci. Hiroshima Univ. Ser. A, '''16''', pp.&nbsp;13–41\n* O. Morris (1967): ''On a Generalized Clifford Algebra'', Quart. J. Math (Oxford), '''18''', pp.&nbsp;7–12\n* O. Morris (1968): ''On a Generalized Clifford Algebra II'', Quart. J. Math (Oxford), '''19''', pp.&nbsp;289–299\n\n{{DEFAULTSORT:Generalized Clifford Algebra}}\n[[Category:Algebras]]\n[[Category:Clifford algebras]]\n[[Category:Ring theory]]\n[[Category:Quadratic forms]]\n[[Category:Mathematical physics]]"
    },
    {
      "title": "Gerstenhaber algebra",
      "url": "https://en.wikipedia.org/wiki/Gerstenhaber_algebra",
      "text": "[[File:Gerstenhaber.jpg|220px|thumb|[[Murray Gerstenhaber]] at [[Mathematical Research Institute of Oberwolfach|Oberwolfach]] in 2010]]\nIn mathematics and [[theoretical physics]], a '''Gerstenhaber algebra''' (sometimes called an '''antibracket algebra''' or '''braid algebra''') is an [[algebraic structure]] discovered by [[Murray Gerstenhaber]] (1963) that combines the structures of a [[supercommutative ring]] and a [[graded Lie superalgebra]]. It is used in the [[Batalin–Vilkovisky formalism]]. It appears also in the generalization of Hamiltonian \nformalism known as the [[De Donder–Weyl theory]] as the algebra of generalized [[Poisson bracket]]s defined on differential forms.\n\n==Definition==\nA '''Gerstenhaber algebra''' is a graded-commutative algebra with a [[Lie algebra|Lie bracket]] of degree -1 satisfying the [[Poisson algebra|Poisson identity]]. Everything is understood to satisfy the usual [[superalgebra]] sign conventions. More precisely, the algebra has two products, one written as ordinary multiplication and one written as [,], and a '''Z'''-grading called '''degree''' (in theoretical physics sometimes called '''ghost number'''). The '''degree''' of an element ''a'' is denoted by |''a''|. These satisfy the identities\n*|''ab''| = |''a''| + |''b''|      (The product has degree 0)\n*|[''a'',''b'']| = |''a''| + |''b''| - 1  (The Lie bracket has degree -1)\n*(''ab'')''c'' = ''a''(''bc'')   (The product is associative)\n*''ab'' = (&minus;1)<sup>|''a''||''b''|</sup>''ba''   (The product is (super) commutative)\n*[''a'',''bc''] = [''a'',''b'']''c'' + (&minus;1)<sup>(|''a''|-1)|''b''|</sup>''b''[''a'',''c''] (Poisson identity)\n*[''a'',''b''] = &minus;(&minus;1)<sup>(|''a''|-1)(|''b''|-1)</sup> [''b'',''a''] (Antisymmetry of Lie bracket)\n*[''a'',[''b'',''c'']] = [[''a'',''b''],''c''] + (&minus;1)<sup>(|''a''|-1)(|''b''|-1)</sup>[''b'',[''a'',''c'']]  (The Jacobi identity for the Lie bracket)\n\nGerstenhaber algebras differ from [[Poisson superalgebra]]s in that the Lie bracket has degree -1 rather than degree 0. The Jacobi identity may also be expressed in a symmetrical form\n:<math>(-1)^{(|a|-1)(|c|-1)}[a,[b,c]]+(-1)^{(|b|-1)(|a|-1)}[b,[c,a]]+(-1)^{(|c|-1)(|b|-1)}[c,[a,b]] = 0.\\,</math>\n\n==Examples==\n*Gerstenhaber showed that the [[Hochschild cohomology]] H<sup>*</sup>(''A'',''A'') of an algebra ''A'' is a Gerstenhaber algebra.\n*A [[Batalin–Vilkovisky algebra]] has an underlying Gerstenhaber algebra if one forgets its second order Δ operator.\n*The [[exterior algebra]] of a [[Lie algebra]] is a Gerstenhaber algebra.\n*The differential forms on a [[Poisson manifold]] form a Gerstenhaber algebra.\n*The multivector fields on a [[manifold]] form a Gerstenhaber algebra using the [[Schouten–Nijenhuis bracket]]\n\n==References==\n*{{Cite journal |last=Gerstenhaber |first=Murray |title=The cohomology structure of an associative ring |jstor=1970343 |journal=[[Annals of Mathematics]] |volume=78 |year=1963 |issue=2 |pages=267–288 |doi=10.2307/1970343 }}\n*{{Cite journal |last=Getzler |first=Ezra |authorlink=Ezra Getzler | title=Batalin-Vilkovisky algebras and two-dimensional topological field theories |journal=[[Communications in Mathematical Physics]] |volume=159 |issue=2 |year=1994 |pages=265–285 |doi=10.1007/BF02102639 |arxiv = hep-th/9212043 |bibcode = 1994CMaPh.159..265G }}\n*{{springer|id=p/p110170|title=Poisson algebra|first=Yvette|last=Kosmann-Schwarzbach|authorlink=Yvette Kosmann-Schwarzbach}} \n*{{Cite journal |last=Kanatchikov |first=Igor V. |title=On field theoretic generalizations of a Poisson algebra  |journal=[[Reports of Mathematical Physics]] |volume=40 |year=1997 |issue=2 |pages=225–234 |doi=10.1016/S0034-4877(97)85919-8 |arxiv = hep-th/9710069 |bibcode=1997RpMP...40..225K }}\n\n[[Category:Algebras]]\n[[Category:Theoretical physics]]\n[[Category:Symplectic geometry]]"
    },
    {
      "title": "Graded ring",
      "url": "https://en.wikipedia.org/wiki/Graded_ring",
      "text": "{{Algebraic structures |Algebra}}\nIn [[mathematics]], in particular [[abstract algebra]], a '''graded ring''' is a [[ring (mathematics)|ring]] that is a [[direct sum of abelian groups]] <math>R_i</math> such that <math>R_i R_j \\subseteq R_{i+j}</math>. The index set is usually the set of nonnegative integers or the set of integers, but can be any [[monoid]]. The direct sum decomposition is usually referred to as '''gradation''' or '''grading'''.\n\nA '''graded module''' is defined similarly (see below for the precise definition). It generalizes [[graded vector space]]s. A graded module that is also a graded ring is called a '''graded algebra'''. A graded ring could also be viewed as a graded '''Z'''-algebra.\n\nThe associativity is not important (in fact not used at all) in the definition of a graded ring; hence, the notion applies to a [[non-associative algebra]] as well; e.g., one can consider a [[graded Lie algebra]].\n\n== First properties ==\nLet \n:<math>R = \\bigoplus_{n\\in \\mathbb N_0}R_n = R_0 \\oplus R_1 \\oplus R_2 \\oplus \\cdots</math>\nbe a graded ring. Elements of any factor <math>R_n</math> of the decomposition are called '''homogeneous elements''' of '''degree''' ''n''. Every element ''a'' of ''R'' may be uniquely written as a sum ''a''&nbsp;=&nbsp;''a''<sub>1</sub>&nbsp;+&nbsp;''a''<sub>2</sub>&nbsp;+&nbsp;...&nbsp;+&nbsp;''a''<sub>''n''</sub> with all ''a''<sub>''i''</sub> homogeneous elements of distinct ''R''<sub>''i''</sub>. These ''a''<sub>''i''</sub> are called the '''homogeneous components''' of&nbsp;''a''.\n\nSome basic properties are:\n*<math>R_0</math> is a subring of ''R''; in particular, the additive identity 0 and the multiplicative identity 1 are homogeneous elements of degree zero.\n*A commutative <math>\\mathbb{N}_0</math>-graded ring <math>R=\\bigoplus_{i=0}^\\infty R_i</math> is a [[Noetherian ring]] if and only if <math>R_0</math> is Noetherian and ''R'' is finitely generated as an algebra over <math>R_0</math>.<ref>{{harvnb|Matsumura|1986|loc=Theorem 13.1}}</ref>\n\nAn [[ideal (ring theory)|ideal]] <math>I\\subseteq R</math> is '''homogeneous''' if, for every element <math>a \\in I</math>, its homogeneous components belong also to <math>I.</math> (Equivalently, they are graded submodules of ''R''; see {{section link||Graded module}}.) The intersections of a homogeneous ideal <math>I</math> with the <math>R_i</math> are called the '''homogeneous parts''' of <math>I</math>. A homogeneous ideal is the direct sum of its homogeneous parts.\n\nIf ''I'' is a homogeneous ideal in ''R'', then <math>R/I</math> is also a graded ring, and has decomposition\n\n: <math>R/I = \\bigoplus_{n\\in \\mathbb N}(R_n + I)/I.</math>\n\n==Basic examples==\n*Any (non-graded) ring ''R'' can be given a gradation by letting <math>R_0=R</math>, and <math>R_i=0</math> for ''i'' ≠ 0.  This is called the '''trivial gradation''' on&nbsp;''R''.\n*The polynomial ring <math>R = k[t_1, \\ldots, t_n]</math> is graded by degree: it is a direct sum of <math>R_i</math> consisting of homogeneous polynomials of degree ''i''.\n*Let ''S'' be the set of all nonzero homogeneous elements in a graded integral domain ''R''. Then the [[localization of a ring|localization]] of ''R'' with respect to ''S'' is a '''Z'''-graded ring.\n*If ''I'' is an ideal in a commutative ring ''R'', then <math>\\oplus_0^{\\infty} I^n/I^{n+1}</math> is a graded ring called the [[associated graded ring]] of ''R'' along ''I''; geometrically, it is the coordinate ring of the [[normal cone]] along the subvariety defined by ''I''.\n\n==Graded module==\nThe corresponding idea in [[module theory]] is that of a '''graded module''', namely a left [[module (mathematics)|module]] ''M'' over a graded ring ''R'' such that also\n:<math>M = \\bigoplus_{i\\in \\mathbb{N}_0}M_i ,</math>\nand\n:<math>R_iM_j \\subseteq M_{i+j}.</math>\n\n'''Example''': a [[graded vector space]] is an example of a graded module over a field (with the field having trivial grading).\n\n'''Example''': a graded ring is a graded module over itself. An ideal in a graded ring is homogeneous if and only if it is a graded submodule. The [[annihilator (ring theory)|annihilator]] of a graded module is a homogeneous ideal.\n\n'''Example''': Given an ideal ''I'' in a commutative ring ''R'' and an ''R''-module ''M'', <math>\\bigoplus_{n=0}^{\\infty} I^n M/I^{n+1} M</math>\nis a graded module over the associated graded ring <math>\\oplus_0^{\\infty} I^n/I^{n+1}</math>.\n\nA morphism <math>f: N \\to M</math> between graded modules, called a '''graded morphism''', is a morphism of underlying modules that respects grading; i.e., <math>f(N_i) \\subseteq M_i</math>. A '''graded submodule''' is a submodule that is a graded module in own right and such that the set-theoretic inclusion is a morphism of graded modules. Explicitly, a graded module ''N'' is a graded submodule of ''M'' if and only if it is a submodule of ''M'' and satisfies <math>N_i = N \\cap M_i</math>. The kernel and the image of a morphism of graded modules are graded submodules.\n\nRemark: To give a graded morphism from a graded ring to a graded ring with the image lying in the center is the same as to give the structure of a graded algebra to the latter ring.\n\nGiven a graded module ''M'', the ''ℓ''-twist of <math>M(\\ell)</math> is a graded module defined by <math>M(\\ell)_n = M_{n+\\ell}</math>. (cf. [[Serre's twisting sheaf]] in algebraic geometry.)\n\nLet ''M'' and ''N'' be graded modules. If <math>f: M \\to N</math> is a morphism of modules, then ''f'' is said to have degree ''d'' if <math>f(M_n) \\subseteq N_{n+d}</math>. An [[exterior derivative]] of differential forms in differential geometry is an example of such a morphism having degree 1.\n\n== Invariants of graded modules ==\n\nGiven a graded module ''M'' over a commutative graded ring ''R'', one can associate the formal power series <math>P(M, t) \\in \\mathbb{Z}[\\![t]\\!]</math>:\n:<math>P(M, t) = \\sum \\ell(M_n) t^n</math>\n(assuming <math>\\ell(M_n)</math> are finite.) It is called the [[Hilbert–Poincaré series]] of ''M''.\n\nA graded module is said to be finitely generated if the underlying module is finitely generated. The generators may be taken to be homogeneous (by replacing the generators by their homogeneous parts.)\n\nSuppose ''R'' is a polynomial ring <math>k[x_0, \\dots, x_n]</math>, ''k'' a field, and ''M'' a finitely generated graded module over it. Then the function <math>n \\mapsto \\dim_k M_n</math> is called the Hilbert function of ''M''. The function coincides with the [[integer-valued polynomial]] for large ''n'' called the [[Hilbert polynomial]] of ''M''.\n\n==Graded algebra ==\n{{seealso|Graded Lie algebra}}\nAn [[algebra (ring theory)|algebra]] ''A'' over a ring ''R'' is a '''graded algebra''' if it is graded as a ring.\n\nIn the usual case where the ring ''R'' is not graded (in particular if ''R'' is a field), it is given the trivial grading (every element of ''R'' is of degree 0). Thus, {{nowrap|''R'' ⊆ ''A''<sub>0</sub>}} and the ''A''<sub>''i''</sub> are ''R''-modules.\n\nIn the case where the ring ''R'' is also a graded ring, then one requires that \n:<math>A_iR_j \\subseteq A_{i+j}</math>\nand\n:<math>R_iA_j \\subseteq A_{i+j}.</math>\n\nIn other words, we require ''A'' to be a left and right graded module over ''R''.\n\nExamples of graded algebras are common in mathematics:\n\n* [[Polynomial ring]]s. The homogeneous elements of degree ''n'' are exactly the homogeneous [[polynomial]]s of degree ''n''.\n* The [[tensor algebra]] ''T''<sup>•</sup>''V'' of a [[vector space]] ''V''. The homogeneous elements of degree ''n'' are the [[tensor]]s of order ''n'', ''T''<sup>''n''</sup>''V''.\n* The [[exterior algebra]] Λ<sup>•</sup>''V'' and [[symmetric algebra]] ''S''<sup>•</sup>''V'' are also graded algebras.\n* The [[cohomology ring]] ''H''<sup>•</sup> in any [[cohomology theory]] is also graded, being the direct sum of the ''H''<sup>''n''</sup>.\n\nGraded algebras are much used in [[commutative algebra]] and [[algebraic geometry]], [[homological algebra]] and [[algebraic topology]]. One example is the close relationship between homogeneous [[polynomial]]s and [[projective variety|projective varieties]]. (cf. [[homogeneous coordinate ring]].)\n\n== ''G''-graded rings and algebras ==\nThe above definitions have been generalized to gradings ring using any [[monoid]] ''G'' as an index set.  A '''''G''-graded ring''' ''R'' is a ring with a direct sum decomposition\n:<math>R = \\bigoplus_{i\\in G}R_i </math>\nsuch that\n:<math> R_i R_j \\subseteq R_{i \\cdot j}. </math>\nElements of ''R'' that lie inside <math>R_i</math> for some <math>i \\in G</math> are said to be '''homogeneous''' of '''grade''' ''i''.\n\nThe previously defined notion of \"graded ring\" now becomes the same thing as a '''N'''-graded ring, where '''N''' is the monoid of [[natural number|non-negative integers]] under addition. The definitions for graded modules and algebras can also be extended this way replacing the indexing set '''N''' with any monoid ''G''.\n\nRemarks:\n*If we do not require that the ring have an identity element, [[semigroup]]s may replace [[monoid]]s.\n\nExamples:\n*A group naturally grades the corresponding [[group ring]]; similarly, [[monoid ring]]s are graded by the corresponding monoid.\n*An (associative) [[superalgebra]] is another term for a [[cyclic group|Z<sub>2</sub>]]-graded algebra. Examples include [[Clifford algebra]]s. Here the homogeneous elements are either of degree 0 (even) or 1 (odd).\n\n===Anticommutativity===\nSome graded rings (or algebras) are endowed with an [[anticommutative]] structure.  This notion requires a [[Monoid#Monoid homomorphisms|homomorphism]] of the monoid of the gradation into the additive monoid of '''Z'''/2'''Z''', the field with two elements.  Specifically, a '''signed monoid''' consists of a pair {{nowrap|(Γ, ''ε'')}} where Γ is a monoid and {{nowrap|''ε'' : Γ → '''Z'''/2'''Z'''}} is a homomorphism of additive monoids.  An '''anticommutative Γ-graded ring''' is a ring ''A'' graded with respect to Γ such that:\n:<math>xy=(-1)^{\\varepsilon (\\deg x) \\varepsilon (\\deg y)}yx ,</math>\nfor all homogeneous elements ''x'' and ''y''.\n\n===Examples===\n*An [[exterior algebra]] is an example of an anticommutative algebra, graded with respect to the structure {{nowrap|('''Z''', ''ε'')}} where {{nowrap|''ε'' : '''Z''' → '''Z'''/2'''Z'''}} is the quotient map.\n*A [[supercommutative algebra]] (sometimes called a '''skew-commutative associative ring''') is the same thing as an anticommutative {{nowrap|('''Z'''/2'''Z''', ''ε'')}}-graded algebra, where ''ε'' is the identity [[endomorphism]] of the additive structure of '''Z'''/2'''Z'''.\n\n== Graded monoid ==\nIntuitively, a graded [[monoid]] is the subset of a graded ring, <math>\\bigoplus_{n\\in \\mathbb N_0}R_n</math>, generated by the <math>R_n</math>'s, without using the additive part. That is, the set of elements of the graded rings is <math>\\bigcup_{n\\in\\mathbb N_0}R_n</math>.\n\nFormally, a graded monoid<ref>{{cite book | last=Sakarovitch | first=Jacques | title=Elements of automata theory | translator-first=Reuben|translator-last=Thomas | location=Cambridge | publisher=Cambridge University Press | year=2009 | isbn=978-0-521-84425-3 | zbl=1188.68177 | chapter = Part II: The power of algebra | page=384 }}</ref> is a monoid <math>(M,\\cdot)</math>, with a gradation function <math>\\phi:M\\to\\mathbb N_0</math> such that <math>\\phi(m\\cdot m')=\\phi(m)+\\phi(m')</math>. Note that the gradation of <math>1_M</math> is necessarily 0. Some authors request furthermore that <math>\\phi(m)\\ne 0</math>\nwhen '''m''' is not the identity.\n\nAssuming the gradations of non identity elements are non zero, the number of elements of gradation '''n''' is at most <math>\\frac{g^{n+1}-1}{g-1}</math> where '''g''' is the cardinality of a [[generator (monoid)|generator]] '''G''' of the monoid. Indeed, each such element is the product of at most '''n''' elements of '''G''', and only <math>\\frac{g^{n+1}-1}{g-1}</math> such product exists.  Similarly, the identity element can not be written as the product of two non-identity elements. That is, there is no unit divisor in such a graded monoid.\n\n\n===Power series indexed by a graded monoid===\nThis notions allows to extends the notion of [[power series ring]]. Instead of having the indexing family being <math>\\mathbb N</math>, the indexing family could be any graded monoid, assuming that the number of elements of degree '''n''' is finite, for each integer '''n'''.\n\nMore formally, let <math>(K,+_K,\\times_K)</math> be an arbitrary [[semiring]] and <math>(R,\\cdot,\\phi)</math> a graded monoid. Then <math>K\\langle\\langle R\\rangle\\rangle</math> denote the power series with coefficient in '''K''' indexed by '''R'''. Its elements are functions from '''R''' to '''K'''. The sum of two elements <math>s,s'\\in K\\langle\\langle R\\rangle\\rangle</math> is defined point-wise, it is the function sending <math>m\\in R</math> to <math>s(m)+_Ks'(m)</math>. And the product is the function sending  defined as the infinite sum <math>\\sum_{p,q\\in R,p\\cdot q=m}s(p)\\times_K s'(q)</math>. This sum is correctly defined since, for each '''m''', only a finite number of such '''p''' and '''q''' may exists. Thus, this sum is in fact finite.\n\n===Example===\nIn [[formal language theory]], given an alphabet '''A''', the [[free monoid]] of words over '''A''' can be considered as a graded monoid, where the gradation of a word is its length.\n\nGiven a monoid <math>(M,\\cdot)</math>, not assumed to be graded, the monoid of finite subsets of '''M''', with product <math>S\\times S'=\\{s\\cdot s'\\mid s\\in S,s'\\in S'\\}</math> is a graded monoid, where the graded function is the cardinality of the set.\n\n==See also==\n* [[Associated graded ring]]\n* [[Differential graded algebra]]\n* [[Filtered algebra]], a generalization\n* [[Graded (mathematics)]]\n* [[Graded category]]\n* [[Graded vector space]]\n* [[Tensor algebra]]<!-- if I remember correctly, any graded algebra is a quotient of a tensor algebra. -->\n\n==References==\n{{reflist}}\n* {{Lang Algebra}}.\n* Bourbaki, N. (1974) ''Algebra I'' (Chapters 1-3), {{ISBN|978-3-540-64243-5}}, Chapter 3, Section 3.\n* H. Matsumura ''Commutative ring theory.'' Translated from the Japanese by M. Reid. Second edition. Cambridge Studies in Advanced Mathematics, 8.\n\n[[Category:Algebras]]\n[[Category:Ring theory]]"
    },
    {
      "title": "Group algebra",
      "url": "https://en.wikipedia.org/wiki/Group_algebra",
      "text": "{{about|topological algebras associated to topological groups|the purely algebraic case (without any topology)|group ring}}{{Short description|Topological algebra associated to continuous groups}}In [[mathematics]], the '''group algebra''' is any of various constructions to assign to a [[locally compact group]]  an [[operator algebra]] (or more generally a [[Banach algebra]]), such that representations of the algebra are related to representations of the group.  \n\nAs such, they are similar to the [[group ring]] associated to a discrete group. In particular, these all use convolution to extend the [[group Hopf algebra]] from the set of functions with finite support to more useful classes of functions.\n\n== Group algebras of topological groups: ''C<sub>c</sub>''(''G'')==\nFor the purposes of [[functional analysis]], and in particular of [[harmonic analysis]], one wishes to carry over the group ring construction to [[topological group]]s ''G''. In case ''G'' is a [[locally compact group|locally compact Hausdorff group]], ''G'' carries an essentially unique left-invariant countably additive [[Borel measure]] μ called a [[Haar measure]].  Using the Haar measure, one can define a [[convolution]] operation on the space ''C<sub>c</sub>''(''G'') of complex-valued continuous functions on ''G'' with [[compact support]]; ''C<sub>c</sub>''(''G'') can then be given any of various [[norm (mathematics)|norm]]s and the [[completeness (order theory)|completion]] will be a group algebra.\n\nTo define the convolution operation, let ''f'' and ''g'' be two functions in ''C<sub>c</sub>''(''G'').  For ''t'' in ''G'', define\n\n:<math> [f * g](t) = \\int_G f(s) g \\left (s^{-1} t \\right )\\, d \\mu(s).</math>\n\nThe fact that ''f'' * ''g'' is continuous is immediate from the [[dominated convergence theorem]]. Also\n\n:<math> \\operatorname{Support}(f * g) \\subseteq \\operatorname{Support}(f) \\cdot \\operatorname{Support}(g) </math>\n\nwhere the dot stands for the product in ''G''. ''C<sub>c</sub>''(''G'') also has a natural [[involution (mathematics)|involution]] defined by:\n\n:<math>  f^*(s) = \\overline{f(s^{-1})} \\, \\Delta(s^{-1}) </math>\n\nwhere Δ is the [[Haar measure#The modular function|modular function]] on ''G''.  With this involution, it is a [[*-algebra]].\n\n<blockquote>'''Theorem.''' With the norm:\n\n:<math> \\|f\\|_1 := \\int_G |f(s)| \\, d\\mu(s), </math>\n\n''C<sub>c</sub>''(''G'') becomes an involutive [[normed algebra]] with an [[approximate identity]].</blockquote>\n\nThe approximate identity can be indexed on a neighborhood basis of the identity consisting of compact sets.  Indeed, if ''V'' is a compact neighborhood of the identity, let ''f<sub>V</sub>'' be a non-negative continuous function supported in ''V'' such that\n\n:<math> \\int_V f_{V}(g)\\, d \\mu(g) =1.</math>\n\nThen {''f<sub>V</sub>''}<sub>''V''</sub> is an approximate identity. A group algebra has an identity, as opposed to just an approximate identity, if and only if the topology on the group is the [[discrete topology]].\n\nNote that for discrete groups, ''C<sub>c</sub>''(''G'') is the same thing as the complex group ring '''C'''[''G''].\n\nThe importance of the group algebra is that it captures the [[unitary representation]] theory of ''G'' as shown in the following\n\n<blockquote>'''Theorem.''' Let ''G'' be a locally compact group.  If ''U'' is a strongly continuous unitary representation of ''G'' on a Hilbert space ''H'', then\n\n: <math> \\pi_U (f) = \\int_G f(g) U(g)\\, d \\mu(g)</math>\n\nis a non-degenerate bounded *-representation of the normed algebra ''C<sub>c</sub>''(''G'').  The map\n\n: <math> U \\mapsto \\pi_U</math>\n\nis a bijection between the set of strongly continuous unitary representations of ''G'' and non-degenerate bounded *-representations of ''C<sub>c</sub>''(''G'').  This bijection respects unitary equivalence and [[strong containment]]. In particular, π<sub>''U''</sub> is irreducible if and only if ''U'' is irreducible.</blockquote>\n\nNon-degeneracy of a representation π of ''C<sub>c</sub>''(''G'') on a Hilbert space ''H''<sub>π</sub>  means that\n\n:<math> \\left \\{\\pi(f) \\xi : f \\in \\operatorname{C}_c(G), \\xi \\in H_\\pi \\right \\} </math>\n\nis dense in ''H''<sub>π</sub>.\n\n== The convolution algebra ''L''<sup>1</sup>(''G'') ==\nIt is a standard theorem of [[measure theory]] that the completion of ''C<sub>c</sub>''(''G'') in the ''L''<sup>1</sup>(''G'') norm is isomorphic to the space [[Lp space|''L''<sup>1</sup>(''G'')]] of equivalence classes of functions which are integrable with respect to the [[Haar measure]], where, as usual, two functions are regarded as equivalent if and only if they differ only on a set of Haar measure zero.\n\n<blockquote>'''Theorem.''' ''L''<sup>1</sup>(''G'') is a [[Banach *-algebra]] with the convolution product and involution defined above and with the ''L''<sup>1</sup> norm.  ''L''<sup>1</sup>(''G'') also has a bounded approximate identity.</blockquote>\n\n== The group C*-algebra ''C*''(''G'') ==\nLet  '''C'''[''G''] be the [[group ring]] of a [[discrete group]] ''G''.\n\nFor a locally compact group ''G'', the group [[C*-algebra]] ''C*''(''G'') of ''G'' is defined to be the C*-enveloping algebra of ''L''<sup>1</sup>(''G''), i.e. the completion of ''C<sub>c</sub>''(''G'') with respect to the largest C*-norm:\n\n:<math> \\|f\\|_{C^*} := \\sup_\\pi \\|\\pi(f)\\|,</math>\n\nwhere π ranges over all non-degenerate *-representations of ''C<sub>c</sub>''(''G'') on Hilbert spaces. When ''G'' is discrete, it follows from the triangle inequality that, for any such π, one has:\n\n:<math> \\|\\pi (f)\\| \\leq \\| f \\|_1,</math>\n\nhence the norm is well-defined.\n\nIt follows from the definition that ''C*''(''G'') has the following [[universal property]]: any *-homomorphism from '''C'''[''G''] to some  '''B'''(''H'') (the C*-algebra of [[bounded operator]]s on some [[Hilbert space]] ''H'') factors through the [[inclusion map]]:\n\n:<math>\\mathbf{C}[G] \\hookrightarrow C^*_{\\max}(G).</math>\n\n=== The reduced group C*-algebra ''C<sub>r</sub>*''(''G'') ===\nThe reduced group C*-algebra ''C<sub>r</sub>*''(''G'') is the completion of ''C<sub>c</sub>''(''G'') with respect to the norm\n\n:<math> \\|f\\|_{C^*_r} := \\sup \\left \\{ \\|f*g\\|_2: \\|g\\|_2 = 1 \\right \\},</math>\n\nwhere\n\n:<math> \\|f\\|_2 = \\sqrt{\\int_G |f|^2 \\, d\\mu}</math>\n\nis the ''L''<sup>2</sup> norm.  Since the completion of ''C<sub>c</sub>''(''G'') with regard to the ''L''<sup>2</sup> norm is a Hilbert space, the ''C<sub>r</sub>*'' norm is the norm of the bounded operator acting on ''L''<sup>2</sup>(''G'') by convolution with ''f'' and thus a C*-norm.\n\nEquivalently, ''C<sub>r</sub>*''(''G'') is the C*-algebra generated by the image of the left regular representation on ''ℓ''<sup>2</sup>(''G'').\n\nIn general, ''C<sub>r</sub>*''(''G'') is a quotient of ''C*''(''G''). The reduced group C*-algebra is isomorphic to the non-reduced group C*-algebra defined above if and only if ''G'' is [[Amenable group|amenable]].\n\n== von Neumann algebras associated to groups ==\nThe group von Neumann algebra ''W*''(''G'') of ''G'' is the enveloping von Neumann algebra of ''C*''(''G'').\n\nFor a discrete group ''G'', we can consider the [[Hilbert space]] ℓ<sup>2</sup>(''G'') for which ''G'' is an [[orthonormal basis]].  Since ''G'' operates on ℓ<sup>2</sup>(''G'') by permuting the basis vectors, we can identify the complex group ring '''C'''[''G''] with a subalgebra of the algebra of [[bounded operator]]s on ℓ<sup>2</sup>(''G'').  The weak closure of this subalgebra, ''NG'', is a [[von Neumann algebra]].\n\nThe center of ''NG'' can be described in terms of those elements of ''G'' whose [[conjugacy class]] is finite.  In particular, if the identity element of ''G'' is the only group element with that property (that is, ''G'' has the [[infinite conjugacy class property]]), the center of ''NG'' consists only of complex multiples of the identity.\n\n''NG'' is isomorphic to the [[hyperfinite type II-1 factor|hyperfinite type II<sub>1</sub> factor]] if and only if ''G'' is [[countable]], [[Amenable group|amenable]], and has the infinite conjugacy class property.\n\n== Stereotype group algebras ==\n\nIn [[Stereotype space|stereotype theory]] there is a series of natural group algebras that includes the following four main examples.\n\n* On each locally compact group <math>G</math> one can consider the algebra <math>{\\mathcal C}(G)</math> of all continuous functions <math>f:G\\to{\\mathbb C}</math> with the topology of uniform convergence on compact sets <math>T\\subseteq G</math>. The [[Stereotype space#Definition|stereotype dual space]] <math>{\\mathcal C}^\\star(G)</math>, which consists of [[Radon measure]]s with compact support on a [[locally compact group]] <math>G</math>, is a [[stereotype algebra]] with respect to the operation of [[convolution#Convolution of measures|convolution]]:{{sfn|Akbarov|2003|p=272}} <math>\n\\alpha * \\beta (f)=\n\\int_G \\left( \\int_G f(s\\cdot t)\\, \\alpha(ds) \\right) \\beta(dt), \\quad \\alpha,\\beta\\in {\\mathcal C}^\\star(G), \\ f\\in {\\mathcal C}(G).\n</math> \n: The algebra <math>{\\mathcal C}^\\star(G)</math> is called the ''stereotype group algebra of measures'' on the locally compact group <math>G</math>.<ref>If <math>G</math> is an infinite locally compact group then the algebra <math>{\\mathcal C}^\\star(G)</math> of measures on <math>G</math> is not a [[Fréchet algebra]]. In the case when <math>G</math> is compact, <math>{\\mathcal C}^\\star(G)</math> is a [[Smith space]]. If <math>G</math> is <math>\\sigma</math>-compact, then <math>{\\mathcal C}^\\star(G)</math> is a [[Brauner space]].</ref>\n\n* On each [[real Lie group]] <math>G</math> one can consider the algebra <math>{\\mathcal E}(G)</math> of all smooth functions <math>f:G\\to{\\mathbb C}</math> with the  topology of uniform convergence with all derivatives on compact sets <math>T\\subseteq G</math>. The [[Stereotype space#Definition|stereotype dual space]] <math>{\\mathcal E}^\\star(G)</math>, which consists of [[distribution (mathematics)|distribution]]s with compact support on <math>G</math>, is a [[stereotype algebra]] with respect to the operation of convolution of distributions. The algebra <math>{\\mathcal E}^\\star(G)</math> is called the ''stereotype group algebra of distributions'' on the real Lie group <math>G</math>.\n\n* On each Stein group<ref name=Stein-group>A ''Stein group'' is a [[complex Lie group]] <math>G</math> which is a [[Stein manifold]].</ref>  <math>G</math> one can consider the algebra <math>{\\mathcal O}(G)</math> of all holomorphic functions <math>f:G\\to{\\mathbb C}</math> with the  topology of uniform convergence on compact sets <math>T\\subseteq G</math>. The [[Stereotype space#Definition|stereotype dual space]] <math>{\\mathcal O}^\\star(G)</math>, which consists of holomorphic fuhctionals on <math>G</math>, is a [[stereotype algebra]] with respect to the operation of convolution of functionals. The algebra <math>{\\mathcal O}^\\star(G)</math> is called the ''stereotype group algebra of analytic functionals'' on the Stein group <math>G</math>.\n\n* On each [[affine algebraic group]] <math>G</math> one can consider the algebra <math>{\\mathcal P}(G)</math> of all polynomials (or regular functions) <math>f:G\\to{\\mathbb C}</math> with the strongest locally convex topology. The [[Stereotype space#Definition|stereotype dual space]] <math>{\\mathcal P}^\\star(G)</math>, which consists of currents on <math>G</math>, is a [[stereotype algebra]] with respect to the operation of convolution of currents. The algebra <math>{\\mathcal P}^\\star(G)</math> is called the ''stereotype group algebra of currents'' on the affine algebraic group <math>G</math>.\n\nA map <math>\\pi:G\\to A</math> of a group <math>G</math> into an associative unital algebra <math>A</math> is called a ''representation of <math>G</math> in <math>A</math>'', if it is a group homomorphism into the group of invertible elements of <math>A</math>, i.e. if it satisfies the following identities:\n\n<math>\\pi(1_G)=1_A, \\qquad \\pi(x\\cdot y)=\\pi(x)\\cdot\\pi(y),\n\\qquad x,y\\in G.</math>\n\nThe representation <math>\\delta: G\\to {\\mathcal C}^\\star(G)</math>, <math>\\delta(x)(u)=u(x)</math>, <math>x\\in G</math>, <math>u\\in {\\mathcal C}^\\star(G)</math> is called the ''representation as delta-functionals''.\n\nThe representations <math>\\delta: G\\to {\\mathcal E}^\\star(G)</math>, <math>\\delta: G\\to {\\mathcal O}^\\star(G)</math>, <math>\\delta: G\\to {\\mathcal P}^\\star(G)</math>, are defined similarly.\n\nThe following two results distinguish the stereotype group algebras among the other models of group algebras in analysis.\n\n:'''Theorem ([[Group ring#Universal Property|universal property]])'''.{{sfn|Akbarov|2003|p=275}} ''For any stereotype algebra <math>A</math> the formula''\n\n:<math>\\pi=\\varphi\\circ\\delta</math>\n\n:''establishes a one-to-one correspondence between''\n[[File:Group-algebras-1.jpg|thumb|Main property of group algebras.]]\n\n:* ''the continuous representations <math>\\pi:G\\to A</math> of a locally compact group <math>G</math> in the stereotype algebra <math>A</math> and the morphisms of stereotype algebras <math>\\varphi:{\\mathcal C}^\\star(G)\\to A</math>,'' \n\n:* ''the smooth<ref name=smooth-maps>A map <math>\\xi:M\\to X</math> of a [[smooth manifold]] <math>M</math> into a stereotype space <math>X</math> is said to be ''smooth'' if for each functional <math>f\\in X^\\star</math> the composition <math>f\\circ\\xi</math> is a smooth function on <math>M</math>, and the map <math>f\\in X^\\star\\mapsto f\\circ\\xi\\in {\\mathcal E}(M)</math> is continuous.</ref> representations <math>\\pi:G\\to A</math> of a real Lie group <math>G</math> in the stereotype algebra <math>A</math> and the morphisms of stereotype algebras <math>\\varphi:{\\mathcal E}^\\star(G)\\to A</math>,'' \n\n:* ''the holomorphic<ref name=holomorphic-maps>A map <math>\\xi:M\\to X</math> of a [[Stein manifold]] <math>M</math> into a stereotype space <math>X</math> is said to be ''holomorphic'' if for each functional <math>f\\in X^\\star</math> the composition <math>f\\circ\\xi</math> is a holomorphic function on <math>M</math>, and the map <math>f\\in X^\\star\\mapsto f\\circ\\xi\\in {\\mathcal O}(M)</math> is continuous.</ref> representations <math>\\pi:G\\to A</math> of a Stein group <math>G</math> in the stereotype algebra <math>A</math> and the morphisms of stereotype algebras <math>\\varphi:{\\mathcal O}^\\star(G)\\to A</math>,'' \n\n:* ''the polynomial (regular)<ref name=polynomial-maps>A map <math>\\xi:M\\to X</math> of an [[affine algebraic variety]] <math>M</math> over <math>{\\mathbb C}</math> into a stereotype space <math>X</math> is said to be ''polynomial'' (or ''regular'') if for each functional <math>f\\in X^\\star</math> the composition <math>f\\circ\\xi</math> is a polynomial on <math>M</math>, and the map <math>f\\in X^\\star\\mapsto f\\circ\\xi\\in {\\mathcal P}(M)</math> is continuous.</ref> representations <math>\\pi:G\\to A</math> of an affine algebraic group <math>G</math> in the stereotype algebra <math>A</math> and the morphisms of stereotype algebras <math>\\varphi:{\\mathcal P}^\\star(G)\\to A</math>.''\n\n:'''Theorem'''.{{sfn|Akbarov|2009|p=507}} ''The group algebras <math>{\\mathcal C}^\\star(G)</math>, <math>{\\mathcal E}^\\star(G)</math>, <math>{\\mathcal O}^\\star(G)</math>, <math>{\\mathcal P}^\\star(G)</math> are [[Hopf algebra]]s in the [[Stereotype space#Ste as a *-autonomous category|monoidal category ('''Ste''',<math>\\circledast</math>,<math>{\\mathbb C}</math>)]] of stereotype spaces.''\n\n==See also==\n* [[Graph algebra]]\n* [[Incidence algebra]]\n* [[Path algebra]]\n* [[Groupoid algebra]]\n* [[Stereotype algebra]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*J, Dixmier, ''C* algebras'', {{ISBN|0-7204-0762-1}}\n*A. A. Kirillov, ''Elements of the theory of representations'', {{ISBN|0-387-07476-7}}\n*L. H. Loomis, \"Abstract Harmonic Analysis\", ASIN B0007FUU30\n*{{springer|id=G/g045230|title=Group algebra of a locally compact group|author=A.I. Shtern}} {{PlanetMath attribution|id=3628|title=Group $C^*$-algebra}}\n*{{cite journal|last=Akbarov|first=S.S.|title=Pontryagin duality in the theory of topological vector spaces and in topological algebra|journal=Journal of Mathematical Sciences|year=2003|volume=113|issue=2|pages=179–349|doi=10.1023/A:1020929201133|url=http://www.springerlink.com/content/k62m72960101g6q2/| ref = harv}}\n*{{cite journal|last=Akbarov|first=S.S.|title=Holomorphic functions of exponential type and duality for Stein groups with algebraic connected component of identity|journal=Journal of Mathematical Sciences|year=2009|volume=162|issue=4|pages=459–586|arxiv=0806.3205|doi=10.1007/s10958-009-9646-1| ref = harv}}\n\n\n[[Category:Algebras]]\n[[Category:C*-algebras]]\n[[Category:von Neumann algebras]]\n[[Category:Unitary representation theory]]\n[[Category:Harmonic analysis]]\n[[Category:Lie groups]]"
    },
    {
      "title": "Hall algebra",
      "url": "https://en.wikipedia.org/wiki/Hall_algebra",
      "text": "{{for|the more general Hall algebra of a category|Ringel–Hall algebra}}\nIn [[mathematics]], the '''Hall algebra''' is an [[associative algebra]] with a basis corresponding to isomorphism classes of finite abelian [[p-group|''p''-groups]]. It was first discussed by {{harvtxt|Steinitz|1901}} but forgotten until it was rediscovered by {{harvs|txt|authorlink=Philip Hall|first= Philip|last= Hall|year=1959}}, both of whom published no more than brief summaries of their work. The '''Hall polynomials''' are the [[structure constants]] of  the '''Hall algebra'''. The Hall algebra plays an important role in the theory of [[Masaki Kashiwara]] and [[George Lusztig]] regarding [[crystal basis|canonical bases]] in [[quantum group]]s. {{harvtxt|Ringel|1990}} generalized Hall algebras to more general [[Category theory|categories]], such as the category of representations of a [[quiver (mathematics)|quiver]].\n\n== Construction ==\nA [[finite set|finite]] [[abelian group|abelian]] [[p-group|''p''-group]] ''M'' is a direct sum of [[cyclic group|cyclic]] ''p''-power components <math>C_{p^{\\lambda_i}},</math> where\n<math>\\lambda=(\\lambda_1,\\lambda_2,\\ldots)</math> is a [[Partition (number theory)|partition]] of <math>n</math> called the ''type'' of ''M''.  Let <math>g^\\lambda_{\\mu,\\nu}(p)</math> be the number of subgroups ''N'' of ''M'' such that ''N'' has type <math>\\nu</math> and the quotient ''M/N'' has type <math>\\mu</math>.  Hall proved that the functions ''g'' are [[polynomial]] functions of ''p'' with integer coefficients. Thus we may replace ''p'' with an indeterminate ''q'', which results in the '''Hall polynomials''' \n\n: <math>g^\\lambda_{\\mu,\\nu}(q)\\in\\mathbb{Z}[q]. \\, </math>\n\nHall next constructs an [[associative ring]] <math>H</math> over <math>\\mathbb{Z}[q]</math>, now called the '''Hall algebra'''. This ring has a basis consisting of the symbols <math>u_\\lambda</math> and the structure constants of the multiplication in this basis are given by the Hall polynomials: \n\n:<math> u_\\mu u_\\nu = \\sum_\\lambda g^\\lambda_{\\mu,\\nu}(q) u_\\lambda. \\, </math>\n\nIt turns out that ''H'' is a commutative ring, freely generated by the elements <math>u_{\\mathbf1^n}</math> corresponding to the [[elementary abelian group|elementary ''p''-groups]]. The linear map from ''H'' to the algebra of [[symmetric function]]s defined on the generators by the formula\n\n: <math>u_{\\mathbf 1^n} \\mapsto q^{-n(n-1)/2}e_n \\, </math>\n\n(where ''e''<sub>''n''</sub> is the ''n''th [[elementary symmetric function]]) uniquely extends to a [[ring homomorphism]] and the images of the basis elements <math>u_\\lambda</math> may be interpreted via the [[Hall–Littlewood polynomial|Hall–Littlewood symmetric functions]]. Specializing ''q'' to 0, these symmetric functions become [[Schur polynomial|Schur functions]], which are thus closely connected with the theory of Hall polynomials.\n\n==References==\n*{{citation|first=Philip|last=Hall|authorlink=Philip Hall|\nyear=1959|chapter=The algebra of partitions|title=Proceedings of the 4th Canadian mathematical congress, Banff|pages=147–159}}\n* [[George Lusztig]], ''Quivers, perverse sheaves, and quantized enveloping algebras'', [[Journal of the American Mathematical Society]] 4 (1991), no. 2, 365&ndash;421.\n* {{Citation | last1=Macdonald | first1=Ian G. | author1-link=Ian G. Macdonald | title=Symmetric functions and Hall polynomials | url=http://global.oup.com/academic/product/symmetric-functions-and-hall-polynomials-9780198504504 | publisher=The Clarendon Press Oxford University Press | edition=2nd | series=Oxford Mathematical Monographs | isbn=978-0-19-853489-1 | mr=1354144 | year=1995 }}\n* {{Citation | last1=Ringel | first1=Claus Michael | title=Hall algebras and quantum groups | doi=10.1007/BF01231516 | mr=1062796 | year=1990 | journal=[[Inventiones Mathematicae]]   | volume=101 | issue=3 | pages=583–591| bibcode=1990InMat.101..583R }}\n*{{citation|contribution=Lectures on Hall algebras|last=Schiffmann|first=Olivier|title=Geometric methods in representation theory. II | pages=1–141| \nseries=Sémin. Congr.|volume= 24-II|publisher= Soc. Math. France| location=Paris|year= 2012|arxiv=math/0611617|mr=3202707 |bibcode=2006math.....11617S}}\n*{{citation|authorlink=Ernst Steinitz|last=Steinitz|first=Ernst|title=Zur Theorie der Abel'schen Gruppen|journal=[[Jahresbericht der Deutschen Mathematiker-Vereinigung]]|year=1901|volume=9|pages=80–85}}\n\n[[Category:Algebras]]\n[[Category:Invariant theory]]\n[[Category:Symmetric functions]]"
    },
    {
      "title": "Hecke algebra of a finite group",
      "url": "https://en.wikipedia.org/wiki/Hecke_algebra_of_a_finite_group",
      "text": "The '''Hecke algebra of a finite group''' is the [[algebra]] spanned by the double [[coset]]s ''HgH'' of a finite index subgroup ''H'' of a group ''G''.{{fact|reason=need a ref for an infinite group|date=November 2017}}\n\n== Definition ==\nLet ''F'' be a field of characteristic zero, ''G'' a finite group and ''H'' a subgroup of ''G''. Let <math>F[G]</math> denote the\n[[group algebra]] of ''G'': the space of ''F''-valued functions on ''G'' with the multiplication given by convolution. We write <math>F[G/H]</math> for the space of ''F''-valued functions on <math>G/H</math>. An (''F''-valued) function on ''G''/''H'' determines and is determined by a function on ''G'' that is invariant under the right action of ''H''. That is, there is the natural identification:\n:<math>F[G/H] = F[G]^H.</math>\nSimilarly, there is the identification\n:<math>R := \\operatorname{End}_G(F[G/H]) = F[G]^{H \\times H}</math>\ngiven by sending a ''G''-linear map ''f'' to the value of ''f'' evaluated at the characteristic function of ''H''. For each double coset <math>HgH</math>, let <math>T_g</math> denote the characteristic function of it. Then those <math>T_g</math>'s form a basis of ''R''.\n\n== See also ==\n*[[Gelfand pair]]\n\n== References ==\n*[[Claudio Procesi]] (2007) ''Lie Groups: an approach through invariants and representations'', Springer, {{isbn|9780387260402}}.\n\n[[Category:Algebras]]\n[[Category:Representation theory of Lie groups]]\n\n{{algebra-stub}}"
    },
    {
      "title": "Hurwitz quaternion order",
      "url": "https://en.wikipedia.org/wiki/Hurwitz_quaternion_order",
      "text": "The '''Hurwitz quaternion order''' is a specific [[order (ring theory)|order]] in a [[quaternion algebra]] over a suitable [[number field]].  The order is of particular importance in [[Riemann surface]] theory, in connection with surfaces with maximal [[symmetry]], namely the [[Hurwitz surface]]s.<ref>{{citation\n | last = Vogeler | first = Roger\n | publisher = Florida State University\n | series = PhD thesis\n | title = On the geometry of Hurwitz surfaces\n | year = 2003}}.</ref>  The Hurwitz quaternion order was studied in 1967 by [[Goro Shimura]],<ref>{{citation\n | last = Shimura | first = Goro | authorlink = Goro Shimura\n | doi = 10.2307/1970526\n | mr = 0204426\n | journal = [[Annals of Mathematics]] | series = Second Series\n | pages = 58–159\n | title = Construction of class fields and zeta functions of algebraic curves\n | volume = 85\n | year = 1967}}.</ref> but first explicitly described by [[Noam Elkies]] in 1998.<ref>{{citation\n | last = Elkies | first = Noam D. | authorlink = Noam Elkies\n | contribution = Shimura curve computations\n | doi = 10.1007/BFb0054850\n | arxiv = math.NT/0005160\n | mr = 1726059\n | location = Berlin\n | pages = 1–47\n | publisher = Springer-Verlag\n | series = Lecture Notes in Computer Science\n | title = Algorithmic number theory (Portland, OR, 1998)\n | volume = 1423\n | year = 1998}}.</ref>  For an alternative use of the term, see [[Hurwitz quaternion]] (both usages are current in the literature).\n\n==Definition==\nLet <math>K</math> be the maximal real subfield of <math>\\mathbb{Q}</math><math>(\\rho)</math> where <math>\\rho</math> is a 7th-primitive [[root of unity]]. \nThe [[ring of integers]] of <math>K</math> is <math>\\mathbb{Z}[\\eta]</math>, where the element <math>\\eta=\\rho+ \\bar\\rho</math> can be identified with the positive real <math>2\\cos(\\tfrac{2\\pi}{7})</math>. Let <math>D</math> be the [[quaternion algebra]], or symbol algebra \n\n:<math>D:=\\,(\\eta,\\eta)_{K},</math>\n\nso that <math>i^2=j^2=\\eta</math> and <math>ij=-ji</math> in <math>D.</math>  Also let <math>\\tau=1+\\eta+\\eta^2</math> and <math>j'=\\tfrac{1}{2}(1+\\eta i + \\tau j)</math>.  Let \n\n:<math>\\mathcal{Q}_{\\mathrm{Hur}}=\\mathbb{Z}[\\eta][i,j,j'].</math>\n\nThen <math>\\mathcal{Q}_{\\mathrm{Hur}}</math> is a maximal [[Order (ring theory)|order]] of <math>D</math>, described explicitly by [[Noam Elkies]].<ref>{{citation\n | last = Elkies | first = Noam D. | authorlink = Noam Elkies\n | contribution = The Klein quartic in number theory\n | mr = 1722413\n | location = Cambridge\n | pages = 51–101\n | publisher = Cambridge Univ. Press\n | series = Math. Sci. Res. Inst. Publ.\n | title = The eightfold way\n | volume = 35\n | year = 1999}}.</ref>\n\n==Module structure==\nThe order <math>Q_{\\mathrm{Hur}}</math> is also generated by elements\n\n:<math>g_2= \\tfrac{1}{\\eta}ij</math>\n\nand\n\n:<math>g_3=\\tfrac{1}{2}(1+(\\eta^2-2)j+(3-\\eta^2)ij).</math>\n\nIn fact, the order is a free <math>\\mathbb Z[\\eta]</math>-module over\nthe basis <math>\\,1,g_2,g_3, g_2g_3</math>.  Here the generators satisfy the relations\n\n:<math>g_2^2=g_3^3= (g_2g_3)^7=-1,</math>\n\nwhich descend to the appropriate relations in the [[(2,3,7) triangle group]], after quotienting by the center.\n\n==Principal congruence subgroups==\nThe principal congruence subgroup defined by an ideal <math>I \\subset \\mathbb{Z}[\\eta]</math> is by definition the group\n\n:<math>\\mathcal{Q}^1_{\\mathrm{Hur}}(I) = \\{x \\in \\mathcal{Q}_{\\mathrm{Hur}}^1 : x \\equiv 1  (</math>mod <math>I\\mathcal{Q}_{\\mathrm{Hur}})\\},</math>\n\nnamely, the group of elements of [[reduced norm]] 1 in <math>\\mathcal{Q}_{\\mathrm{Hur}}</math> equivalent to 1 modulo the ideal <math>I\\mathcal{Q}_{\\mathrm{Hur}}</math>.  The corresponding Fuchsian group is obtained as the image of the principal congruence subgroup under a representation to P[[SL(2,R)]].\n==Application==\nThe order was used by Katz, Schaps, and Vishne<ref>{{citation\n | last1 = Katz | first1 = Mikhail G. | author1-link = Mikhail Katz\n | last2 = Schaps | first2 = Mary\n | last3 = Vishne | first3 = Uzi\n | author3-link = Uzi Vishne\n | arxiv = math.DG/0505007\n | mr = 2331526\n | issue = 3\n | journal = Journal of Differential Geometry\n | pages = 399–422\n | title = Logarithmic growth of systole of arithmetic Riemann surfaces along congruence subgroups\n | url = http://projecteuclid.org/getRecord?id=euclid.jdg/1180135693\n | volume = 76\n | year = 2007}}.</ref> to construct a family of Hurwitz surfaces satisfying an asymptotic lower bound for the systole: <math>sys > \\frac{4}{3}\\log g</math> where g is the genus, improving an earlier result of [[Peter Buser]] and [[Peter Sarnak]];<ref>{{citation\n | last1 = Buser | first1 = P.\n | last2 = Sarnak | first2 = P.\n | doi = 10.1007/BF01232233\n | mr = 1269424\n | issue = 1\n | journal = Inventiones Mathematicae\n | pages = 27–56\n | title = On the period matrix of a Riemann surface of large genus\n | volume = 117\n | year = 1994\n | postscript = . With an appendix by J. H. Conway and N. J. A. Sloane.| bibcode = 1994InMat.117...27B\n }}</ref> see [[systoles of surfaces]].\n\n==See also==\n*[[(2,3,7) triangle group]]\n*[[Klein quartic]]\n*[[Macbeath surface]]\n*[[First Hurwitz triplet]]\n\n==References==\n{{reflist|30em}}\n\n[[Category:Riemann surfaces]]\n[[Category:Differential geometry of surfaces]]\n[[Category:Algebras]]\n[[Category:Quaternions|Algebra]]\n[[Category:Systolic geometry]]"
    },
    {
      "title": "Iwahori–Hecke algebra",
      "url": "https://en.wikipedia.org/wiki/Iwahori%E2%80%93Hecke_algebra",
      "text": "In mathematics, the '''Iwahori–Hecke algebra''', or '''Hecke algebra''',  named for [[Erich Hecke]] and [[Nagayoshi Iwahori]], is a deformation of the [[group algebra]] of a [[Coxeter group]].\n\nHecke algebras are quotients of the group rings of [[Artin braid group]]s. This connection found a spectacular application in [[Vaughan Jones]]' construction of [[Jones polynomial|new invariants of knots]]. Representations of Hecke algebras led to discovery of [[quantum group]]s by [[Michio Jimbo]]. [[Michael Freedman]] proposed Hecke algebras as a foundation for [[topological quantum computer|topological quantum computation]].\n\n==Hecke algebras of Coxeter groups==\nStart with the following data:\n\n* (''W'', ''S'') is a [[Coxeter system]] with the Coxeter matrix ''M'' = (''m''<sub>''st''</sub>), \n* ''R'' is a commutative ring with identity.\n* {''q<sub>s</sub>'' | ''s'' &isin; ''S''} is a family of units of ''R'' such that ''q<sub>s</sub>'' = ''q<sub>t</sub>'' whenever ''s'' and ''t'' are conjugate in ''W''\n* ''A'' is the ring of [[Laurent polynomial]]s over '''Z''' with indeterminates ''q<sub>s</sub>'' (and the above restriction that ''q<sub>s</sub>'' = ''q<sub>t</sub>'' whenever ''s'' and ''t'' are conjugated), that is ''A'' = '''Z''' [''q''{{su|p=±1|b=s}}]\n\n===Multiparameter Hecke Algebras===\nThe ''multiparameter Hecke algebra'' ''H<sub>R</sub>(W,S,q)'' is a unital, associative ''R''-algebra with generators ''T<sub>s</sub>'' for all ''s'' &isin; ''S'' and relations:\n* '''Braid Relations:''' ''T<sub>s</sub> T<sub>t</sub> T<sub>s</sub>'' ... = ''T<sub>t</sub> T<sub>s</sub> T<sub>t</sub>'' ..., where each side has ''m<sub>st</sub>'' < &infin; factors and ''s,t'' belong to ''S''.\n* '''Quadratic Relation:''' For all ''s'' in ''S'' we have: (''T<sub>s</sub>'' - ''q<sub>s</sub>'')(''T<sub>s</sub>'' + 1) = 0.\n\n'''Warning''': in recent books and papers, Lusztig has been using a modified form of the quadratic relation that reads <math>(T_s-q_s^{1/2})(T_s+q_s^{-1/2})=0.</math> After extending the scalars to include the half integer powers ''q''{{su|p=±½|b=s}} the resulting Hecke algebra is isomorphic to the previously defined one (but the ''T<sub>s</sub>'' here corresponds to ''q''{{su|p=-½|b=s}} ''T''<sub>s</sub> in our notation). While this does not change the general theory, many formulae look different.\n\n===Generic Multiparameter Hecke Algebras===\n''H<sub>A</sub>(W,S,q)'' is the ''generic'' multiparameter Hecke algebra. This algebra is universal in the sense that every other multiparameter Hecke algebra can be obtained from it via the (unique) ring homomorphism ''A'' → ''R'' which maps the indeterminate ''q<sub>s</sub>'' &isin; ''A'' to the unit ''q<sub>s</sub>'' &isin; ''R''. This homomorphism turns ''R'' into a ''A''-algebra and the scalar extension ''H<sub>A</sub>(W,S)'' &otimes;<sub>''A''</sub> ''R'' is canonically isomorphic to the Hecke algebra ''H<sub>R</sub>(W,S,q)'' as constructed above. One calls this process ''specialization'' of the generic algebra.\n\n=== One-parameter Hecke Algebras ===\nIf one specializes every indeterminate ''q<sub>s</sub>'' to a single indeterminate ''q'' over the integers (or ''q''{{su|p=½|b=s}} to ''q''<sup>½</sup> respectively), then one obtains the so-called generic one-parameter Hecke algebra of ''(W,S)''.\n\nSince in Coxeter groups with single laced Dynkin diagrams (for example groups of type A and D) every pair of Coxeter generators is conjugated, the above-mentioned restriction of ''q<sub>s</sub>'' being equal ''q<sub>t</sub>'' whenever ''s'' and ''t'' are conjugated in ''W'' forces the multiparameter and the one-parameter Hecke algebras to be equal. Therefore, it is also very common to only look at one-parameter Hecke algebras.\n\n=== Coxeter groups with weights ===\nIf an integral weight function is defined on ''W'' (i.e. a map ''L:W'' → '''Z''' with ''L(vw)=L(v)+L(w)'' for all ''v,w'' &isin; ''W'' with ''l(vw)=l(v)+l(w)''), then a common specialization to look at is the one induced by the homomorphism ''q<sub>s</sub>'' ↦ ''q<sup>L(s)</sup>'', where ''q'' is a single indeterminate over '''Z'''.\n\nIf one uses the convention with half-integer powers, then weight function ''L:W'' → ½'''Z''' may be permitted as well. For technical reasons it is also often convenient only to consider positive weight functions.\n\n== Properties ==\n1. The Hecke algebra has a basis <math>(T_w)_{w\\in W}</math> over ''A'' indexed by the elements of the Coxeter group ''W''. In particular, ''H'' is a free ''A''-module. If <math>w=s_1 s_2 \\ldots s_n</math> is a [[reduced decomposition]] of ''w'' &isin; ''W'', then <math>T_w=T_{s_1}T_{s_2}\\ldots T_{s_n}</math>. This basis of Hecke algebra is sometimes called the '''natural basis'''. The [[neutral element]] of ''W'' corresponds to the identity of ''H'': ''T<sub>e</sub>'' = 1.\n\n2. The elements of the natural basis are ''multiplicative'', namely, ''T''<sub>yw</sub>=''T''<sub>y</sub> ''T''<sub>w</sub> whenever ''l(yw)=l(y)+l(w)'', where ''l'' denotes the [[length function]] on the Coxeter group ''W''.\n\n3. Elements of the natural basis are invertible. For example, from the quadratic relation we conclude that ''T''{{su|p=−1|b=s}} = ''q''{{su|p=−1|b=s}} ''T<sub>s</sub>'' + (''q''{{su|p=−1|b=s}}-1).\n\n4. Suppose that ''W'' is a finite group and the ground ring is the field '''C''' of complex numbers. [[Jacques Tits]] has proved that if the indeterminate ''q'' is specialized to any complex number outside of an explicitly given list (consisting of roots of unity), then the resulting one parameter Hecke algebra is [[semisimple algebra|semisimple]] and isomorphic to the complex group algebra '''C'''[''W''] (which also corresponds to the specialization ''q'' ↦ 1.\n\n5. More generally, if ''W'' is a finite group and the ground ring ''R'' is a field of [[characteristic zero]], then the one parameter Hecke algebra is a [[semisimple algebra|semisimple associative algebra]] over ''R''[''q''<sup>±1</sup>]. Moreover, extending earlier results of Benson and Curtis, George Lusztig provided an explicit isomorphism between the Hecke algebra and the group algebra after the extension of scalars to the quotient field of ''R''[''q''<sup>±½</sup>]\n<!--\nthat if ''A'' is extended to the field <math>K=R(q^{\\frac12}) then the ''K''-algebra <math>H_K=H\\otimes_A K</math> obtained from ''H'' by the change of scalars is isomorphic over ''K'' to the group algebra ''K[W]'' of the Coxeter group ''W''.\n\n Lusztig, George. On a theorem of Benson and Curtis. J. Algebra 71 (1981), no. 2, 490–498.\nHowever, it seems excessive to give this reference in an article in an encyclopedia!\n-->\n\n== Canonical basis ==\n{{main article|Kazhdan–Lusztig polynomial}}\nA great discovery of Kazhdan and Lusztig was that a Hecke algebra admits a ''different'' basis, which in a way controls representation theory of a variety of related objects.\n\nThe generic multiparameter Hecke algebra, ''H<sub>A</sub>(W,S,q)'', has an involution ''bar'' that maps ''q''<sup>½</sup> to ''q''<sup>−½</sup> and acts as identity on '''Z'''. Then ''H'' admits a unique ring automorphism ''i'' that is [[semilinear map|semilinear]] with respect to the bar involution of ''A'' and maps ''T<sub>s</sub>'' to ''T{{su|p=−1|b=s}}''. It can further be proved that this automorphism is involutive (has order two) and takes any ''T<sub>w</sub>'' to <math>T^{-1}_{w^{-1}}.</math>\n\n<blockquote> '''Kazhdan - Lusztig Theorem:''' For each ''w'' ∈ ''W'' there exists a unique element <math>C^{\\prime}_w</math> which is invariant under the involution ''i'' and if one writes its expansion in terms of the natural basis:\n::<math> C'_w= \\left (q^{-1/2} \\right )^{l(w)}\\sum_{y\\leq w}P_{y,w}T_y, </math>\none has the following:\n* ''P''<sub>w,w</sub>=1, \n* ''P''<sub>y,w</sub> in '''Z'''[''q''] has degree less than or equal to ½''(l(w)-l(y)-1)'' if ''y<w'' in the [[Bruhat order]],\n* ''P''<sub>y,w</sub>=0 if <math>y\\nleq w.</math></blockquote>\n\nThe elements <math>C^{\\prime}_w</math> where ''w'' varies over ''W'' form a basis of the algebra ''H'', which is called the ''dual canonical basis'' of the Hecke algebra ''H''. The ''canonical basis'' {''C''<sub>w</sub> | ''w'' &isin; ''W''} is obtained in a similar way. The polynomials ''P''<sub>y,w</sub>(''q'') making appearance in this theorem are the [[Kazhdan–Lusztig polynomials]].\n\nThe Kazhdan–Lusztig notions of left, right and two-sided ''cells'' in Coxeter groups are defined through the behavior of the canonical basis under the action of ''H''.\n\n== Hecke algebra of a locally compact group ==\nIwahori–Hecke algebras first appeared as an important special case of a very general construction in group theory. Let ''(G,K)'' be a pair consisting of a [[unimodular group|unimodular]] [[locally compact topological group]] ''G'' and a closed subgroup ''K'' of ''G''. Then the space of ''K''-biinvariant [[continuous function]]s of [[compact support]], ''C<sub>c</sub>(K\\G/K)'', can be endowed with a structure of an associative algebra under the operation of [[convolution]]. This algebra is denoted by ''H(G//K)'' and called the '''Hecke ring''' of the pair ''(G,K)''.\n\n'''Example:''' If ''G'' = SL(''n'','''Q'''<sub>''p''</sub>) and ''K'' = SL(''n'','''Z'''<sub>''p''</sub>) then the Hecke ring is commutative and its representations were studied by [[Ian G. Macdonald]]. More generally if ''(G,K)'' is a [[Gelfand pair]] then the resulting algebra turns out to be commutative.\n\n'''Example:''' If ''G'' = SL(2,'''Q''') and ''K'' = SL(2,'''Z''') we get the abstract ring behind [[Hecke operators]] in the theory of [[modular forms]], which gave the name to Hecke algebras in general.\n\nThe case leading to the Hecke algebra of a finite Weyl group is when ''G'' is the finite [[Chevalley group]] over a [[finite field]] with ''p''<sup>k</sup> elements, and ''B'' is its [[Borel subgroup]]. Iwahori showed that the Hecke ring ''H(G//B)'' is obtained from the generic Hecke algebra ''H''<sub>q</sub> of the [[Weyl group]] ''W'' of ''G'' by specializing the indeterminate ''q'' of the latter algebra to ''p''<sup>k</sup>, the cardinality of the finite field. George Lusztig remarked in 1984 (''Characters of reductive groups over a finite field'', xi, footnote):\n\n:''I think it would be most appropriate to call it the Iwahori algebra, but the name Hecke ring (or algebra) given by Iwahori himself has been in use for almost 20 years and it is probably too late to change it now.''\n\nIwahori and Matsumoto (1965) considered the case when ''G'' is a group of points of a [[reductive algebraic group]] over a non-archimedean [[local field]] ''K'', such as '''Q'''<sub>''p''</sub>, and ''K'' is what is now called an [[Iwahori subgroup]] of ''G''. The resulting Hecke ring is isomorphic to the Hecke algebra of the [[affine Weyl group]] of ''G'', or the [[affine Hecke algebra]], where the indeterminate ''q'' has been specialized to the cardinality of the [[residue field]] of ''K''.\n\nWork of Roger Howe in the 1970s and his papers with Allen Moy on representations of ''p''-adic GL(''n'') opened a possibility of classifying irreducible admissible representations of reductive groups over local fields in terms of appropriately constructed Hecke algebras. (Important contributions were also made by Joseph Bernstein and [[Andrey Zelevinsky]].) These ideas were taken much further in [[Colin Bushnell]] and [[Philip Kutzko]]'s ''[[theory of types (mathematics)|theory of types]]'', allowing them to complete the classification in the general linear case. Many of the techniques can be extended to other reductive groups, which remains an area of active research. It has been conjectured that all Hecke algebras that are ever needed are mild generalizations of affine Hecke algebras.\n\n== Representations of Hecke algebras ==\nIt follows from Iwahori's work that complex representations of Hecke algebras of finite type are intimately related with the structure of the spherical [[principal series representation]]s of finite Chevalley groups.\n\nGeorge Lusztig pushed this connection much further and was able to describe most of the characters of finite groups of Lie type in terms of representation theory of Hecke algebras. This work used a mixture of geometric techniques and various reductions, led to introduction of various objects generalizing Hecke algebras and detailed understanding of their representations (for ''q'' not a root of unity). [[Modular representation]]s of Hecke algebras and representations at roots of unity turned out to be related with the theory of canonical bases in [[affine quantum group]]s and very interesting combinatorics.\n\nRepresentation theory of affine Hecke algebras was developed by Lusztig with a view towards applying it to description of representations of ''p''-adic groups. It is in many ways quite different in flavor from the finite case. A generalization of affine Hecke algebras, called ''double affine Hecke algebra'', was used by [[Ivan Cherednik]] in his proof of the [[Macdonald's constant term conjecture]].\n\n== References ==\n*David Goldschmidt [http://www.ams.org/online_bks/ulect4/ Group Characters, Symmetric Functions, and the Hecke Algebra] {{MR|1225799}},{{ISBN|0-8218-3220-4}} \n*Iwahori, Nagayoshi; Matsumoto, Hideya [http://www.numdam.org/item?id=PMIHES_1965__25__5_0 ''On some Bruhat decomposition and the structure of the Hecke rings of p-adic Chevalley groups.''] Publications Mathématiques de l'IHÉS, 25 (1965), pp.&nbsp;5–48. {{MR|0185016}}\n* Alexander Kleshchev, ''Linear and projective representations of symmetric groups'', Cambridge tracts in mathematics, vol. 163. Cambridge University Press, 2005. {{MR|2165457}}, {{ISBN|0-521-83703-0}}\n* George Lusztig, [http://www.ams.org/bookstore-getitem/item=CRMM-18 Hecke algebras with unequal parameters], CRM monograph series, vol.18, American Mathematical Society, 2003. {{MR|1658581}}, {{ISBN|0-8218-3356-1}}\n* Andrew Mathas, [http://www.ams.org/bookstore-getitem/item=ULECT-15 Iwahori-Hecke algebras and Schur algebras of the symmetric group], University Lecture Series, vol.15, American Mathematical Society, 1999. {{MR|1711316}}, {{ISBN|0-8218-1926-7}}\n* Lusztig, George, ''On a theorem of Benson and Curtis'', J. Algebra 71 (1981), no. 2, 490–498. {{MR|0630610}}, {{DOI|10.1016/0021-8693(81)90188-5}}\n* Colin Bushnell and Philip Kutzko, ''The admissible dual of GL(n) via compact open subgroups'', Annals of Mathematics Studies, vol. 129, Princeton University Press, 1993. {{MR|1204652}}, {{ISBN|0-691-02114-7}}\n\n{{DEFAULTSORT:Iwahori-Hecke algebra}}\n[[Category:Algebras]]\n[[Category:Representation theory]]"
    },
    {
      "title": "Koszul algebra",
      "url": "https://en.wikipedia.org/wiki/Koszul_algebra",
      "text": "In [[abstract algebra]], a '''Koszul algebra''' <math>R</math> is a [[graded algebra|graded]]  <math>k</math>-[[algebra over a field|algebra]] over which the [[ground field]] <math>k</math> has a linear minimal graded free resolution, ''i.e.'', there exists an [[exact sequence]]:\n \n:<math>\\cdots \\rightarrow R(-i)^{b_i} \\rightarrow \\cdots \\rightarrow R(-2)^{b_2} \\rightarrow R(-1)^{b_1} \\rightarrow R \\rightarrow k \\rightarrow 0.</math>\nIt is named after the French mathematician [[Jean-Louis Koszul]].\n\nHere, <math>R(-j)</math> is the graded algebra <math>R</math> with grading shifted up by <math>j</math>, ''i.e.'' <math>R(-j)_i = R_{i-j}</math>. The exponents <math>b_i</math> refer to the <math>b_i</math>-fold direct sum.\n\nWe can choose bases for the free modules in the resolution; then the maps can be written as matrices. For a Koszul algebra, the entries in the matrices are zero or linear forms.\n\nAn example of a Koszul algebra is a [[polynomial ring]] over a field, for which the [[Koszul complex]] is the minimal graded free resolution of the ground field. There are Koszul algebras whose ground fields have infinite minimal graded free resolutions, ''e.g'', <math>R = k[x,y]/(xy) </math>\n\n== See also ==\n*[[Koszul duality]]\n\n== References ==\n*{{citation\n | last = Fröberg | first = R.\n | contribution = Koszul algebras\n | location = New York\n | mr = 1767430\n | pages = 337–350\n | publisher = Marcel Dekker\n | series = Lecture Notes in Pure and Applied Mathematics\n | title = Advances in commutative ring theory (Fez, 1997)\n | volume = 205\n | year = 1999}}.\n*{{citation\n | last1 = Loday | first1 = Jean-Louis\n | last2 = Vallette | first2 = Bruno\n | doi = 10.1007/978-3-642-30362-3\n | isbn = 978-3-642-30361-6\n | location = Heidelberg\n | mr = 2954392\n | publisher = Springer\n | series = Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]\n | title = Algebraic operads\n | url = https://www.math.univ-paris13.fr/~vallette/Operads.pdf\n | volume = 346\n | year = 2012}}.\n*{{citation\n | last1 = Beilinson | first1 = Alexander\n | last2 = Ginzburg | first2 = Victor\n | last3 = Soergel | first3 = Wolfgang\n | doi = 10.1090/S0894-0347-96-00192-0\n | issue = 2\n | journal = [[Journal of the American Mathematical Society]]\n | mr = 1322847\n | pages = 473–527\n | title = Koszul duality patterns in representation theory\n | volume = 9\n | year = 1996}}.\n*{{citation\n | last1 = Mazorchuk | first1 = Volodymyr\n | last2 = Ovsienko | first2 = Serge\n | last3 = Stroppel | first3 = Catharina | author3-link = Catharina Stroppel\n | doi = 10.1090/S0002-9947-08-04539-X\n | issue = 3\n | journal = [[Transactions of the American Mathematical Society]]\n | mr = 2457393\n | pages = 1129–1172\n | title = Quadratic duals, Koszul dual functors, and applications\n | volume = 361\n | year = 2009| arxiv = math/0603475}}.\n\n[[Category:Algebras]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Koszul duality",
      "url": "https://en.wikipedia.org/wiki/Koszul_duality",
      "text": "In [[mathematics]], '''Koszul duality''', named after the French mathematician [[Jean-Louis Koszul]], is any of various kinds of dualities found in representation theory of [[Lie algebra]]s, abstract algebras ([[semisimple algebra]])<ref>Ben Webster, [http://sbseminar.wordpress.com/2007/11/01/koszul-algebras-and-koszul-duality/ Koszul algebras and Koszul duality]. November 1, 2007</ref> as well as topology (e.g., [[equivariant cohomology]]<ref>[[Mark Goresky]], [[Robert Kottwitz]], and [[Robert MacPherson (mathematician)|Robert MacPherson]]. Equivariant cohomology, Koszul duality, and the localization theorem. [[Inventiones Mathematicae]] '''131''' (1998).</ref>). The prototype example, due to [[Joseph Bernstein]], [[Israel Gelfand]], and Sergei Gelfand,<ref>[[Joseph Bernstein]], [[Israel Gelfand]], and Sergei Gelfand. ''Algebraic bundles over <math>P^n</math> and problems of linear algebra''. Funkts. Anal. Prilozh. 12 (1978); English translation in Functional Analysis and its Applications 12 (1978), 212-214</ref> is the rough duality between the [[derived category]] of a [[symmetric algebra]] and that of an [[exterior algebra]]. The importance of the notion rests on the suspicion that Koszul duality seems quite ubiquitous in nature.{{citation needed|date=April 2014}}\n\n==Koszul Duality for modules over Koszul algebras==\nThe simplest, and in a sense prototypical case of Koszul duality arises as follows: for a 1-dimensional vector space ''V'' over a field ''k'', with [[dual vector space]] <math>V^*</math>, the [[exterior algebra]] of ''V'' has two non-trivial components, namely\n\n:<math>\\bigwedge^1 V=V, \\bigwedge^0 V = k.</math>\n\nThis exterior algebra and the [[symmetric algebra]] of <math>V^*</math>, <math>Sym(V^*)</math>, serve to build a two-step [[chain complex]]\n\n:<math>V \\otimes_k Sym(V^*) \\to k \\otimes_k Sym(V^*)</math>\n\nwhose differential is induced by natural evaluation map\n\n:<math>V \\otimes_k V^* \\to k, v \\otimes \\varphi \\mapsto \\varphi(v).</math>\nChoosing a basis of ''V'', <math>Sym(V^*)</math> can be identified with the [[polynomial ring]] in one variable, <math>k[t]</math>, and the previous chain complex becomes isomorphic to the complex\n\n:<math>k[t] \\stackrel t \\to k[t]</math>\n\nwhose differential is multiplication by ''t''. This computation shows that the cohomology of the above complex is 0 at the left hand term, and is ''k'' at the right hand term. In other words, ''k'' (regarded as a chain complex concentrated in a single degree) is [[quasi-isomorphic]] to the above complex, which provides a close link between the exterior algebra of ''V'' and the symmetric algebra of its dual.\n===Koszul dual of a Koszul algebra===\nKoszul duality, as treated by [[Alexander Beilinson]], [[Victor Ginzburg]], and Wolfgang Soergel<ref>[[Alexander Beilinson]], [[Victor Ginzburg]], Wolfgang Soergel. ''Koszul duality patterns in representation theory'', [[Journal of the American Mathematical Society]] '''9''' (1996), no. 2, 473-527.</ref> can be formulated using the notion of [[Koszul algebra]]. An example of such a Koszul algebra ''A'' is the [[symmetric algebra]] <math>S(V)</math> on a finite-dimensional vector space. More generally, any Koszul algebra can be shown to be a [[quadratic algebra]], i.e., of the form\n:<math>A = T(V) / R,</math>\nwhere <math>T(V)</math> is the [[tensor algebra]] on a finite-dimensional vector space, and <math>R</math> is a submodule of <math>T^2(V) = V \\otimes V</math>. The ''Koszul dual'' then coincides with the quadratic dual\n:<math>A^! := T(V^*) / R'</math>\nwhere <math>V^*</math> is the (''k''-linear) dual and <math>R' \\subset V^* \\otimes V^*</math> consists of those elements on which the elements of ''R'' (i.e., the relations in ''A'') vanish. The Koszul dual of <math>A=S(V)</math> is given by <math>A^! = \\Lambda(V^*)</math>, the [[exterior algebra]] on the dual of ''V''. In general, the dual of a Koszul algebra is again a Koszul algebra. Its [[opposite ring]] is given by the graded ring of self-[[Ext functor|extensions]] of the underlying field ''k,'' thought of as an ''A''-module:\n:<math>(A^!)^{\\text{opp}} = \\operatorname{Ext}^*_A(k, k).</math>\n\n===Koszul duality===\nIf an algebra <math>A</math> is Koszul, there is an equivalence between certain subcategories of the [[derived category|derived categories]] of [[graded module|graded]] <math>A</math>- and <math>A^!</math>-modules. These subcategories are defined by certain boundedness conditions on the grading vs. the cohomological degree of a complex.\n\n===Variants===\nAs an alternative to passing to certain subcategories of the derived categories of <math>A</math> and <math>A^!</math> to obtain equivalences, it is possible instead to obtain equivalences between certain quotients of the homotopy categories.<ref>{{Cite journal|last = Fløystad|first = Gunnar|date = 2006-01-01|title = Koszul duality and equivalences of categories|url = http://www.ams.org/tran/2006-358-06/S0002-9947-05-04035-3/|journal = Transactions of the American Mathematical Society|volume = 358|issue = 6|pages = 2373–2398|doi = 10.1090/S0002-9947-05-04035-3|issn = 0002-9947}}</ref> Usually these quotients are larger than the derived category, as they are obtained by factoring out some subcategory of the category of acyclic complexes, but they have the advantage that every complex of modules determines some element of the category, without needing to impose boundedness conditions. A different reformulation gives an equivalence between the derived category of <math>A</math> and the 'coderived' category of the coalgebra <math>(A^!)^*</math>.\n\nAn extension of Koszul duality to [[D-modules|''D''-modules]] states a similar equivalence of derived categories between dg-modules over the [[dg-algebra]] <math>\\Omega_X</math> of [[Kähler differential]]s on a smooth [[algebraic variety]] ''X'' and the <math>D_X</math>-modules.\n<ref>Kapranov, Mikhail M.  ''On DG-modules over the de Rham complex and the vanishing cycles functor''.  Algebraic geometry (Chicago, IL, 1989),  57–86, Lecture Notes in Math., 1479, Springer, Berlin, 1991.</ref><ref>Positselski, Leonid: {{arxiv|0905.2621}} ''Two kinds of derived categories, Koszul duality, and comodule-contramodule correspondence.'',  Mem. Amer. Math. Soc.  212  (2011),  no. 996, vi+133 pp. {{isbn|978-0-8218-5296-5}}, see Appendix B</ref><ref>[[Gerd Faltings|Faltings, Gerd]]; Chai, Ching-Li. ''Degeneration of abelian varieties.'' With an appendix by [[David Mumford]]. Springer-Verlag, Berlin, 1990. xii+316 pp. {{isbn|3-540-52015-5}}. Section VI.3</ref>\n\n==Koszul duality for operads==\nAn extension of the above concept of Koszul duality was formulated by Ginzburg and Kapranov who introduced the notion of a quadratic [[operad]] and defined the quadratic dual of such an operad.<ref>Ginzburg, Victor; Kapranov, Mikhail. ''Koszul duality for operads.''  Duke Math. J.  76  (1994),  no. 1, 203–272.</ref>  Very roughly, an operad is an algebraic structure consisting of an object of ''n''-ary operations for all ''n''. An algebra over an operad is an object on which these ''n''-ary operations act. For example, there is an operad called the [[associative operad]] whose algebras are associative algebras, i.e., depending on the precise context, non-commutative rings (or, depending on the context, non-commutative graded rings, differential graded rings). Algebras over the so-called [[commutative operad]] are commutative algebras, i.e., commutative (possibly graded, differential graded) rings. Yet another example is the [[Lie operad]] whose algebras are [[Lie algebra]]s. The quadratic duality mentioned above is such that the associative operad is self-dual, while the commutative and the Lie operad correspond to each other under this duality.\n\nKoszul duality for operads states an equivalence between algebras over dual operads. The special case of associative algebras gives back the functor <math>A \\mapsto A^!</math> mentioned above.\n\n== See also ==\n*[[Zinbiel algebra]]\n\n== Notes ==\n{{reflist}}\n\n== References ==\n*Priddy, Stewart B. ''Koszul resolutions''.  [[Transactions of the American Mathematical Society]]  152 (1970), 39–60.\n\n== External links ==\n*http://www.math.harvard.edu/~lurie/282ynotes/LectureXXIII-Koszul.pdf\n*http://people.mpim-bonn.mpg.de/geordie/Soergel.pdf\n*http://arxiv.org/pdf/1109.6117v1.pdf\n\n[[Category:Algebras]]\n[[Category:Duality theories]]"
    },
    {
      "title": "List of algebras",
      "url": "https://en.wikipedia.org/wiki/List_of_algebras",
      "text": "This is a list of possibly [[nonassociative algebra]]s. An algebra is a [[module (mathematics)|module]], wherein you can also [[tensor product|multiply]] two module elements. (The multiplication in the module is compatible with multiplication-by-scalars from the base [[ring (mathematics)|ring]]).\n\n* [[Akivis algebra]]\n* [[Albert algebra]]\n* [[Alternative algebra]]\n* [[Azumaya algebra]]\n* [[Banach algebra]]\n* [[Birman–Wenzl algebra]]\n* [[Boolean algebra]]\n* [[Borcherds algebra]]\n* [[Brauer algebra]]\n* [[C*-algebra]]\n* [[Central simple algebra]]\n* [[Clifford algebra]]\n* [[Cluster algebra]]\n* Dendriform algebra\n* [[Differential graded algebra]]\n* [[Differential graded Lie algebra]]\n* [[Exterior algebra]]\n* [[F-algebra]]\n* [[Filtered algebra]]\n* [[Flexible algebra]]\n* [[Freudenthal algebra]]\n* [[Genetic algebra]]\n* [[Geometric algebra]]\n* [[Gerstenhaber algebra]]\n* [[Graded algebra]]\n* [[Griess algebra]]\n* [[Group algebra]]\n* [[Hall algebra]]\n* [[Hecke algebra of a locally compact group]]\n* [[Heyting algebra]]\n* [[Hopf algebra]]\n* [[Hurwitz algebra]]\n* [[Incidence algebra]]\n* [[Iwahori–Hecke algebra]]\n* [[Jordan algebra]]\n* [[Kac-Moody algebra]]\n* [[Kleene algebra]]\n* [[Leibniz algebra]]\n* [[Lie algebra]]\n* [[Lie superalgebra]]\n* [[Malcev algebra]]\n* [[Non-associative algebra]]\n* [[Octonion algebra]]\n* [[Pre-Lie algebra]]\n* [[Poisson algebra]]\n* [[Process algebra]]\n* [[Quadratic algebra]]\n* [[Quaternion algebra]]\n* [[Rees algebra]]\n* [[Relation algebra]]\n* [[Relational algebra]]\n* [[Schur algebra]]\n* [[Semisimple algebra]]\n* [[Separable algebra]]\n* [[Shuffle algebra]]\n* [[Sigma algebra]]\n* [[Simple algebra]]\n* [[Structurable algebra]]\n* [[Supercommutative algebra]]\n* [[Symmetric algebra]]\n* [[Tensor algebra]]\n* [[Universal enveloping algebra]]\n* [[Vertex algebra]]\n* [[von Neumann algebra]]\n* [[zinbieL algebra]]\n\n\nThis is a list of fields of algebra.\n\n* [[Linear algebra]]\n* [[Homological algebra]]\n* [[Universal algebra]]\n\n\n[[Category:Algebras]]"
    },
    {
      "title": "Max-plus algebra",
      "url": "https://en.wikipedia.org/wiki/Max-plus_algebra",
      "text": "#REDIRECT [[Tropical semiring#max-plus algebra]] {{R to anchor}} {{R from alternative name}} {{R from merge}}\n[[Category:Algebras]]\n[[Category:Tropical analysis]]\n[[fr:Algèbre max-plus]]"
    },
    {
      "title": "Normed algebra",
      "url": "https://en.wikipedia.org/wiki/Normed_algebra",
      "text": "In mathematics, a '''normed algebra''' ''A'' is an [[algebra over a field]] which has a sub-multiplicative [[norm (mathematics)|norm]]:\n\n: <math>\\forall x,y\\in A\\qquad \\|xy\\|\\le\\|x\\|\\|y\\|.</math>\n\nSome authors require it to have a [[Algebra_over_a_field#Unital_algebras|multiplicative identity]] 1{{sub|''A''}} such that ║1{{sub|''A''}}║ = 1.\n\n==See also==\n* [[Banach algebra]]\n* [[Composition algebra]]\n* [[Division algebra]]\n* [[Gelfand–Mazur theorem]]\n* [[Hurwitz's theorem (composition algebras)]]\n\n==External reading==\n{{cite web|url=https://www.encyclopediaofmath.org/index.php/Normed_algebra|title=Normed Algebra|work=Encyclopaedia of Mathematics|accessdate=20 May 2018}}\n\n{{algebra-stub}}\n\n[[Category:Algebras]]"
    },
    {
      "title": "Partial group algebra",
      "url": "https://en.wikipedia.org/wiki/Partial_group_algebra",
      "text": "A '''partial group algebra''' is an [[associative algebra]] related to the [[partial representation]]s of a [[group (mathematics)|group]].\n\n== Examples ==\n* The partial group algebra <math>\\mathbb{C}_{\\text{par}}\\left(\\mathbb{Z}_4\\right)</math> is isomorphic to the direct sum:<ref>R. Exel (1998)</ref>\n*: <math>\\mathbb{C}\\oplus \\mathbb{C}\\oplus\\mathbb{C}\\oplus\\mathbb{C}\\oplus\\mathbb{C}\\oplus\\mathbb{C}\\oplus\\mathbb{C}\\oplus M_2\\left(\\mathbb{C}\\right) \\oplus M_3\\left(\\mathbb{C}\\right)</math>\n\n== See also ==\n* [[Group algebra]]\n* [[Group representation]]\n\n== Notes ==\n<references/>\n\n== References ==\n* R. Exel. ''Partial Actions of Groups and Actions of Semigroups''. Proc. Am. Math. Soc. 126 no. 12 (1998), 3481–3494.\n\n[[Category:Algebras]]\n[[Category:Representation theory of groups]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Peak algebra",
      "url": "https://en.wikipedia.org/wiki/Peak_algebra",
      "text": "{{Underlinked|date=September 2016}}\n\nIn mathematics, the '''peak algebra''' is a (non-unital) subalgebra of the group algebra of the symmetric group ''S''<sub>''n''</sub>, studied by {{harvtxt|Nyman|2003}}. It consists of the elements of the group algebra of the symmetric group whose coefficients are the same for permutations with the same peaks. (Here a peak of a permutation σ on {1,2,...,''n''} is an index ''i'' such that σ(''i''–1)<σ(''i'')>σ(''i''+1).) It is a left ideal of the [[descent algebra]]. The direct sum of the peak algebras for all ''n'' has a natural structure of a [[Hopf algebra]].\n\n==References==\n\n*{{citation|mr=2001673 \n|last=Nyman|first= Kathryn L.\n|title=The peak algebra of the symmetric group\n|journal=J. Algebraic Combin.|volume= 17 |year=2003|issue= 3|pages= 309–322\n|doi=10.1023/A:1025000905826}}\n\n[[Category:Algebras]]"
    },
    {
      "title": "Peirce decomposition",
      "url": "https://en.wikipedia.org/wiki/Peirce_decomposition",
      "text": "In algebra, a '''Peirce decomposition''' {{IPAc-en|ˈ|p|ɜr|s}} is a decomposition of an algebra as a sum of [[eigenspace]]s of commuting [[idempotent element (ring theory)|idempotent element]]s. \nThe Peirce decomposition for associative algebras was introduced by {{harvs|txt|authorlink=Benjamin Peirce|first=Benjamin|last= Peirce|year=1870|loc=proposition 41, page 13}}. A similar but more complicated  Peirce decomposition for [[Jordan algebra]]s was introduced by {{harvtxt|Albert|1947}}.\n\n==Peirce decomposition for associative algebras==\n\nIf ''e'' is an idempotent (''e''<sup>2</sup>=''e'') in an associative algebra ''A'', then the two-sided Peirce decomposition writes ''A'' as the direct sum of ''eAe'', ''eA''(1&minus;''e''), (1&minus;''e'')''Ae'', and (1&minus;''e'')''A''(1&minus;''e''). There are also left and right Peirce decompositions, where the left decomposition writes ''A'' as the direct sum of ''eA'' and (1&minus;''e'')''A'', and the right one writes ''A'' as the direct sum of ''Ae'' and ''A''(1&minus;''e'').\n\nMore generally, if ''e''<sub>1</sub>,...,''e''<sub>''n''</sub> are mutually orthogonal idempotents with sum 1, then ''A'' is the direct sum of the spaces ''e''<sub>''i''</sub>''Ae''<sub>''j''</sub> for 1≤''i'',''j''≤''n''.\n\n==Blocks==\n\nAn idempotent of a ring is called '''central''' if it commutes with all elements of the ring.\n\nTwo idempotents ''e'', ''f'' are called '''orthogonal''' if ''ef''=''fe''=0.\n\nAn idempotent is called '''primitive''' if it is nonzero and cannot be written as the sum of two orthogonal nonzero idempotents.\n\nAn idempotent ''e'' is called a '''block''' or '''centrally primitive''' if it is nonzero and central and cannot be written as the sum of two orthogonal nonzero central idempotents. In this case the ideal ''eR'' is also sometimes called a block.\n\nIf the identity 1 of a ring ''R'' can be written as the sum \n:1=''e''<sub>1</sub>+...+''e''<sub>''n''</sub>\nof orthogonal nonzero centrally primitive idempotents, then these idempotents are unique up to order and are called the '''blocks''' or the ring ''R''. In this case the ring ''R'' can be written as a direct sum \n:''R'' = ''e''<sub>1</sub>''R''+...+''e''<sub>''n''</sub>''R''\nof indecomposable rings, which are sometimes also called the blocks of ''R''.\n\n==References==\n\n*{{Citation | last1=Albert | first1=A. Adrian | title=A structure theory for Jordan algebras | jstor=1969128 | mr=0021546 | year=1947 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=48 | pages=546–567 | doi=10.2307/1969128}}\n*{{Citation | last1=Lam | first1=T. Y. | title=A first course in noncommutative rings | url=https://books.google.com/books?isbn=0387951830 | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=2nd | series=Graduate Texts in Mathematics | isbn=978-0-387-95183-6 | mr=1838439 | year=2001 | volume=131}}\n*{{citation|first=Benjamin|last=Peirce| title=Linear associative algebra|year=1870|url=https://archive.org/details/linearassociati00peirgoog | isbn=978-0-548-94787-6}}\n*{{eom|id=P/p071970 | first= L.A. | last= Skornyakov}}\n\n==External links==\n* {{springer|title=Peirce decomposition|id=p/p071970}}\n*[http://www.tricki.org/article/Decompose_your_ring_using_idempotents Peirce decomposition] on [http://www.tricki.org/ http://www.tricki.org/]\n\n[[Category:Algebras]]"
    },
    {
      "title": "Poisson algebra",
      "url": "https://en.wikipedia.org/wiki/Poisson_algebra",
      "text": "In [[mathematics]], a '''Poisson algebra''' is an [[associative algebra]] together with a [[Lie algebra|Lie bracket]] that also satisfies [[product rule|Leibniz's law]]; that is, the bracket is also a [[derivation (abstract algebra)|derivation]]. Poisson algebras appear naturally in [[Hamiltonian mechanics]], and are also central in the study of  [[quantum group]]s. [[Manifold]]s with a Poisson algebra structure are known as [[Poisson manifold]]s, of which the [[symplectic manifold]]s and the [[Poisson–Lie group]]s are a special case.  The algebra is named in honour of [[Siméon Denis Poisson]].\n\n==Definition==\nA Poisson algebra is a [[vector space]] over a [[field (mathematics)|field]] ''K'' equipped with two [[bilinear map|bilinear]] products, ⋅ and {, }, having the following properties:\n\n* The product ⋅ forms an  [[associative algebra|associative ''K''-algebra]].\n* The product {, }, called the [[Poisson bracket]], forms a [[Lie algebra]], and so it is anti-symmetric, and obeys the [[Jacobi identity]].\n* The Poisson bracket acts as a [[Derivation (abstract algebra)|derivation]] of the associative product ⋅, so that for any three elements ''x'', ''y'' and ''z'' in the algebra, one has {''x'', ''y'' ⋅ ''z''} = {''x'', ''y''} ⋅ ''z'' + ''y'' ⋅ {''x'', ''z''}.\n\nThe last property often allows a variety of different formulations of the algebra to be given, as noted in the examples below.\n\n== Examples ==\nPoisson algebras occur in various settings.\n\n===Symplectic manifolds===\nThe space of real-valued [[smooth function]]s over a [[symplectic manifold]] forms a Poisson algebra. On a symplectic manifold, every real-valued  function ''H'' on the manifold induces a vector field ''X<sub>H</sub>'', the [[Hamiltonian vector field]].  Then, given any two smooth functions ''F'' and ''G'' over the symplectic manifold, the Poisson bracket may be defined as:\n\n:<math>\\{F,G\\}=dG(X_F) = X_F(G)\\,</math>.\n\nThis definition is consistent in part because the Poisson bracket acts as a derivation. Equivalently, one may define the bracket {,} as\n\n:<math>X_{\\{F,G\\}}=[X_F,X_G]\\,</math>\n\nwhere [,] is the [[Lie derivative]].  When the symplectic manifold is '''R'''<sup>2''n''</sup> with the standard symplectic structure, then the Poisson bracket takes on the well-known form\n\n:<math>\\{F,G\\}=\\sum_{i=1}^n \\frac{\\partial F}{\\partial q_i}\\frac{\\partial G}{\\partial p_i}-\\frac{\\partial F}{\\partial p_i}\\frac{\\partial G}{\\partial q_i}.</math>\n\nSimilar considerations apply for [[Poisson manifold]]s, which generalize symplectic manifolds by allowing the symplectic bivector to be vanishing on some (or trivially, all) of the manifold.\n\n===Lie algebras===\nThe [[tensor algebra]] of a [[Lie algebra]] has a Poisson algebra structure. A very explicit construction of this is given on the article on [[universal enveloping algebra]]s.\n\nThe construction proceeds by first building the [[tensor algebra]] of the underlying vector space of the Lie algebra. The tensor algebra is simply the [[disjoint union]] ([[direct sum]] ⊕) of all tensor products of this vector space. One can then show that the Lie bracket can be consistently lifted to the entire tensor algebra: it obeys both the product rule, and the Jacobi identity of the Poisson bracket, and thus is the Poisson bracket, when lifted. The pair of products {,} and ⊗ then form a Poisson algebra. Observe that ⊗ is neither commutative nor is it anti-commutative: it is merely associative.  \n\nThus, one has the general statement that the tensor algebra of any Lie algebra is a Poisson algebra.  The universal enveloping algebra is obtained by modding out the Poisson algebra structure.\n\n===Associative algebras===\nIf ''A'' is an [[associative algebra]], then imposing the commutator [''x'',''y'']=''xy''&minus;''yx'' turns it into a Poisson algebra (and thus, also a Lie algebra) ''A''<sub>''L''</sub>. Note that the resulting ''A''<sub>''L''</sub> should not be confused with the tensor algebra construction described in the previous section. If one wished, one could also apply that construction as well, but that would give a different Poisson algebra, one that would be much larger.\n\n===Vertex operator algebras===\nFor a [[vertex operator algebra]] ''(V,Y, ω, 1)'', the space ''V/C<sub>2</sub>(V)'' is a Poisson algebra with ''{a, b}'' = ''a<sub>0</sub>b'' and ''a'' ⋅ ''b'' = ''a<sub>−1</sub>b''.  For certain vertex operator algebras, these Poisson algebras are finite-dimensional.\n\n==See also==\n*[[Poisson superalgebra]]\n*[[Antibracket algebra]]\n*[[Moyal bracket]]\n*[[Kontsevich quantization formula]]\n\n==References==\n*{{springer|id=p/p110170|title=Poisson algebra|author=[[Yvette Kosmann-Schwarzbach|Y. Kosmann-Schwarzbach]]}}\n*{{cite book|first = K. H.|last = Bhaskara|first2 = K.|last2 = Viswanath|title = Poisson algebras and Poisson manifolds|location = |publisher = Longman|year = 1988|isbn = 0-582-01989-3}}\n\n[[Category:Algebras]]\n[[Category:Symplectic geometry]]"
    },
    {
      "title": "Quadratic algebra",
      "url": "https://en.wikipedia.org/wiki/Quadratic_algebra",
      "text": "In [[mathematics]], a '''quadratic algebra''' is a [[filtered algebra]] generated by degree one elements, with defining relations of degree 2. It was pointed out by [[Yuri Manin]] that such algebras play an important role in the theory of [[quantum group]]s. The most important class of graded quadratic algebras is [[Koszul algebra]]s.\n\n== Definition ==\n\nA '''graded quadratic algebra''' ''A'' is determined by a [[vector space]] of generators ''V'' = ''A''<sub>1</sub> and a subspace of homogeneous quadratic relations ''S'' ⊂ ''V'' ⊗ ''V'' {{harv| Polishchuk | Positselski | 2005 | p=6 }}. Thus\n\n: <math> A=T(V)/\\langle S\\rangle </math>\n\nand inherits its grading from the [[tensor algebra]] ''T''(''V''). \n\nIf the subspace of relations is instead allowed to  also contain inhomogeneous degree 2 elements,  i.e. ''S'' ⊂ ''k'' ⊕ ''V'' ⊕ (''V'' ⊗ ''V''), this construction results in a '''filtered quadratic algebra'''.\n\nA graded quadratic algebra ''A'' as above admits a '''quadratic dual''': the quadratic algebra generated by ''V''<sup>*</sup> and with quadratic relations forming the orthogonal complement of ''S'' in ''V''<sup>*</sup> ⊗ ''V''<sup>*</sup>.\n\n== Examples ==\n\n* [[Tensor algebra]], [[symmetric algebra]] and [[exterior algebra]] of a finite-dimensional [[vector space]] are graded quadratic (in fact, Koszul) algebras.\n* [[Universal enveloping algebra]] of a finite-dimensional [[Lie algebra]] is a filtered quadratic algebra.\n\n== References ==\n\n* {{Citation | last1=Polishchuk | first1=Alexander | last2=Positselski | first2=Leonid | title=Quadratic algebras | url=https://books.google.com/books?id=5_ZrCKU4NpAC&pg=PA6 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=University Lecture Series | isbn=978-0-8218-3834-1 |mr=2177131 | year=2005 | volume=37}}\n* {{Citation | last1=Mazorchuk | first1=Volodymyr | last2=Ovsienko | first2=Serge | last3=Stroppel | first3=Catharina|author3-link= Catharina Stroppel |title=Quadratic duals, Koszul dual functors, and applications | url=http://www.ams.org/journals/tran/2009-361-03/S0002-9947-08-04539-X/home.html | year=2009 | volume=361| pages=1129–1172 | issue=3 | journal=Trans. Amer. Math. Soc. | doi=10.1090/S0002-9947-08-04539-X | arxiv=math.RT/0603475}}\n\n[[Category:Algebras]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "R-algebroid",
      "url": "https://en.wikipedia.org/wiki/R-algebroid",
      "text": "In [[mathematics]], '''R-algebroids''' are constructed starting from [[groupoid]]s. These are more abstract concepts than the [[Lie algebroid]]s that play a similar role in the theory of [[Lie groupoid]]s to that of [[Lie algebra]]s in the theory of [[Lie group]]s. (Thus, a Lie algebroid can be thought of as 'a ''[[Lie algebra]] with [[categorification|many objects]]'' ').\n\n==Definition==\nAn '''R-algebroid''', <math>R\\mathsf{G}</math>, is constructed from a groupoid <math>\\mathsf{G}</math> as follows. The object set of <math>R\\mathsf{G}</math> is the same as that of <math>\\mathsf{G}</math> and <math>R\\mathsf{G}(b,c)</math> is the [[Free module|free]] [[R-module]] on the set <math>\\mathsf{G}(b,c)</math>, with composition given by the usual bilinear rule, extending the composition of <math>\\mathsf{G}</math>.<ref>G. H. Mosa: ''Higher dimensional algebroids and Crossed complexes'', PhD Thesis, University of Wales, Bangor, (1986). (supervised by [[Ronald Brown (mathematician)|Ronald Brown]])</ref>\n\n==R-category==\nA groupoid <math>\\mathsf{G}</math> can be regarded as a [[category (mathematics)|category]] with invertible morphisms.\nThan an '''R-category''' is defined as an extension of the '''R'''-algebroid concept by replacing the groupoid <math>\\mathsf{G}</math> in this construction with a general category '''C''' that does not have all morphisms invertible.\n\n==R-algebroids ''via'' convolution products==\nOne can also define the '''R-algebroid''', <math>{\\bar R}\\mathsf{G}:=R\\mathsf{G}(b,c)</math>, to be the '''set of functions''' <math>\\mathsf{G}(b,c){\\longrightarrow}R</math> '''with [[finite support]]''', and with the '''[[convolution]] product''' defined as follows:\n<math>\\displaystyle (f*g)(z)= \\sum \\{(fx)(gy)\\mid z=x\\circ y \\}</math> .<ref>R. Brown and G. H. Mosa. ''Double algebroids and crossed modules of algebroids'', University of Wales-Bangor, Maths ''Preprint'', 1986.</ref>\n\nOnly this second construction is natural for the topological case, when one needs to replace '[[Function (mathematics)|function]]' by '[[continuous function]] with [[compact support]]', and in this case <math>R\\cong \\mathbb{C}</math>.\n\n== Examples ==\n*Every [[Lie algebra]] is a Lie algebroid over the one point [[manifold]].\n*The Lie algebroid associated to a [[Lie groupoid]].\n\n==See also==\n{{columns-list|colwidth=30em|\n* [[Algebraic category]]\n* [[Algebroid (disambiguation)]]\n* [[Bialgebra]]\n* [[Bicategory]]\n* [[Convolution|Convolution product]]\n* [[Crossed module]]\n* [[Double groupoid]]\n* [[Higher-dimensional algebra]]\n* [[Hopf algebra]]\n* [[Module (mathematics)]]\n* [[Ring (mathematics)]]\n}}\n\n==References==\n<references/>\n{{PlanetMath attribution|urlname=SetOfFunctionsWithFiniteSupport|title=Algebroid Structures and Algebroid Extended Symmetries}}\n\n;Sources\n*R. Brown and G. H. Mosa. ''Double algebroids and crossed modules of algebroids'', University of Wales-Bangor, Maths ''Preprint'', 1986.\n*G. H. Mosa: ''Higher dimensional algebroids and Crossed complexes'', PhD Thesis, University of Wales, Bangor, (1986). (supervised by [[Ronald Brown (mathematician)|Ronald Brown]]).\n*Kirill Mackenzie, ''Lie Groupoids and Lie Algebroids in Differential Geometry'', Cambridge U. Press, 1987.\n*Kirill Mackenzie, ''General Theory of Lie Groupoids and Lie Algebroids'', Cambridge U. Press, 2005\n*Charles-Michel Marle, ''Differential calculus on a Lie algebroid and Poisson manifolds'' (2002). Also available in [https://arxiv.org/abs/0804.2451v1 arXiv:0804.2451]\n*Alan Weinstein, Groupoids: unifying internal and external symmetry, ''AMS Notices'', '''43''' (1996), 744-752. Also available as [https://arxiv.org/abs/math/9602220 arXiv:math/9602220]\n\n{{DEFAULTSORT:R-Algebroid}}\n[[Category:Algebras]]\n[[Category:Algebraic topology]]\n[[Category:Category theory]]\n[[Category:Lie algebras]]\n[[Category:Lie groupoids]]"
    },
    {
      "title": "2 × 2 real matrices",
      "url": "https://en.wikipedia.org/wiki/2_%C3%97_2_real_matrices",
      "text": "{{Short description|Algebra over the real numbers}}\nIn [[mathematics]], the [[associative algebra]] of '''{{gaps|2|×|2}} [[real number|real]] [[matrix (mathematics)|matrices]]''' is denoted by M(2,&thinsp;'''R'''). Two matrices ''p'' and ''q'' in M(2,&thinsp;'''R''') have a sum ''p''&nbsp;+&nbsp;''q'' given by [[matrix addition]]. The product matrix {{nowrap|''p&thinsp;q''}} is formed from the [[dot product]] of the rows and columns of its factors through [[matrix multiplication]]. For\n\n: <math>q = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}, </math>\n\nlet\n\n: <math>q^* = \\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}. </math>\n\nThen ''q&thinsp;q''{{sup|*}} = ''q''{{sup|*}}&thinsp;''q'' = (''ad'' − ''bc'') {{serif|''I''}}, where {{serif|''I''}} is the {{gaps|2|×|2}} identity matrix. The real number  ''ad''&nbsp;−&nbsp;''bc''  is called the [[determinant]] of ''q''. When  ''ad''&nbsp;−&nbsp;''bc''&nbsp;≠&nbsp;0, ''q'' is an [[invertible matrix]], and then\n\n:<math>q^{-1} = \\frac{q^*}{ad - bc}.</math>\n\nThe collection of all such invertible matrices constitutes the [[general linear group]] GL(2,&thinsp;'''R'''). In terms of [[abstract algebra]], M(2,&thinsp;'''R''') with the associated addition and multiplication operations forms a [[ring (mathematics)|ring]], and GL(2,&thinsp;'''R''') is its [[group of units]].  M(2,&thinsp;'''R''') is also a four-dimensional [[vector space]], so it is considered an [[associative algebra]]. It is [[Ring isomorphism|ring-isomorphic]] to the [[coquaternion]]s, but has a different profile.{{Clarify|reason=What does profile mean here?|date=March 2019}}\n\nThe '''{{gaps|2|×|2}} real matrices''' are in [[one-one correspondence]] with the [[linear mapping]]s of the [[Cartesian coordinate system#Cartesian coordinates in two dimensions|two-dimensional Cartesian coordinate system]] into itself by the rule\n\n:<math>\n  \\begin{pmatrix}x \\\\ y\\end{pmatrix} \\mapsto\n    \\begin{pmatrix}a & b \\\\ c & d\\end{pmatrix} \\begin{pmatrix}x \\\\ y\\end{pmatrix} = \n    \\begin{pmatrix}ax + by \\\\ cx + dy\\end{pmatrix}.\n</math>\n\n==Profile==\nWithin M(2, '''R'''), the multiples by real numbers of the [[identity matrix]] {{serif|''I''}} may be considered a [[real line]]. This real line is the place where all commutative [[subring]]s come together:\n\nLet ''P''<sub>''m''</sub>&nbsp;=&nbsp;{''x{{serif|I}}''&nbsp;+&nbsp;''ym''&nbsp;:&nbsp;''x'',&nbsp;''y''&nbsp;∈&nbsp;'''R'''} where ''m''<sup>2</sup>&nbsp;∈&nbsp;{−{{serif|''I''}},&nbsp;0,&nbsp;{{serif|''I''}}&nbsp;}. Then ''P''<sub>''m''</sub> is a commutative subring and M(2,&nbsp;'''R''') = ⋃''P''<sub>''m''</sub>&nbsp; where the union is over all ''m'' such that ''m''<sup>2</sup>&nbsp;∈&nbsp;{−{{serif|''I''}},&nbsp;0,&nbsp;{{serif|''I''}}&nbsp;}.\n\nTo identify such ''m'', first square the generic matrix:\n:<math>\\begin{pmatrix}aa + bc & ab + bd \\\\ ac + cd & bc + dd \\end{pmatrix}.</math>\n\nWhen ''a'' + ''d'' = 0 this square is a [[diagonal matrix]].\n\nThus one assumes ''d''&nbsp;=&nbsp;−''a'' when looking for ''m'' to form commutative subrings. When ''mm''&nbsp;=&nbsp;−{{serif|''I''}}, then ''bc''&nbsp;=&nbsp;−1&nbsp;−&nbsp;''aa'', an equation describing a [[hyperbolic paraboloid]] in the space of parameters (''a'',&nbsp;''b'',&nbsp;''c''). Such an ''m'' serves as an [[imaginary unit]]. In this case P<sub>''m''</sub> is isomorphic to the field of (ordinary) [[complex number]]s.\n\nWhen ''mm''&nbsp;=&nbsp;+{{serif|''I''}}, ''m'' is an [[involutory matrix]]. Then ''bc''&nbsp;=&nbsp;+1&nbsp;−&nbsp;''aa'', also giving a hyperbolic paraboloid. If a matrix is an [[idempotent matrix]], it must lie in such a P<sub>''m''</sub> and in this case P<sub>''m''</sub> is [[ring isomorphism|isomorphic]] to the ring of [[split-complex number]]s.\n\nThe case of a [[nilpotent matrix]], ''mm''&nbsp;=&nbsp;0, arises when only one of ''b'' or ''c'' is non-zero, and the commutative subring P<sub>''m''</sub> is then a copy of the [[dual number]] plane.\n\nWhen M(2, '''R''') is reconfigured with a [[change of basis]], this profile changes to the [[coquaternion#Profile|profile of split-quaternions]] where the sets of square roots of {{serif|''I''}} and −{{serif|''I''}} take a symmetrical shape as [[hyperboloid]]s.\n\n==Equi-areal mapping==\n<!-- This section is linked from [[Area]] -->\n{{main|Equiareal map}}\nFirst transform one differential vector into another:\n:<math>\n  \\begin{pmatrix}du \\\\ dv \\end{pmatrix} =\n    \\begin{pmatrix}p & r\\\\ q & s \\end{pmatrix} \\begin{pmatrix}dx \\\\ dy \\end{pmatrix} = \n    \\begin{pmatrix}p\\, dx + r\\, dy \\\\  q\\, dx + s\\, dy\\end{pmatrix}.\n</math>\n\n[[Area]]s are measured with ''density'' <math>dx \\wedge dy</math>, a [[differential form|differential 2-form]] which involves the use of [[exterior algebra]]. The transformed density is\n\n:<math>\\begin{align}\n  du \\wedge dv &= 0 + ps\\ dx \\wedge dy + qr\\ dy \\wedge dx + 0 \\\\\n               &= (ps - qr)\\ dx \\wedge dy \\\\\n               &= \\det(g)\\ dx \\wedge dy.\n\\end{align}</math>\n\nThus the equi-areal mappings are identified with [[SL2(R)|SL(2,&#8239;R)]]&nbsp;=&nbsp;{''g''&nbsp;∈&nbsp;M(2,&#8239;R)&nbsp;:&nbsp;det(''g'')&nbsp;=&nbsp;1}, the [[special linear group]]. Given the profile above, every such ''g'' lies in a commutative subring P<sub>''m''</sub> representing a type of complex plane according to the square of ''m''.  Since ''g&#8239;g''{{sup|*}}&nbsp;=&nbsp;{{serif|''I''}}, one of the following three alternatives occurs:\n* ''mm'' = −{{serif|''I''}} and ''g'' is on a circle of Euclidean [[rotation (mathematics)|rotations]]; or\n* ''mm'' = {{serif|''I''}} and ''g'' is on an hyperbola of [[squeeze mapping]]s; or\n* ''mm'' = 0 and ''g'' is on a line of [[shear mapping]]s.\n\nWriting about [[affine group#Planar affine group|planar affine mapping]], [[Rafael Artzy]] made a similar trichotomy of planar, linear mapping in his book ''Linear Geometry'' (1965).\n\n==Functions of 2 × 2 real matrices==\nThe commutative subrings of M(2, '''R''') determine the function theory; in particular the three types of subplanes have their own algebraic structures which set the value of algebraic expressions. Consideration of the square root function and the logarithm function serves to illustrate the constraints implied by the special properties of each type of subplane P<sub>''m''</sub> described in the above profile.\nThe concept of [[identity component]] of the [[group of units]] of P<sub>''m''</sub> leads to the [[polar decomposition]] of elements of the group of units:\n*If ''mm'' = −{{serif|''I''}}, then ''z'' =&nbsp;ρ&nbsp;exp(θ''m'').\n*If ''mm'' = 0, then ''z'' =&nbsp;ρ&nbsp;exp(s&nbsp;''m'')  or ''z'' =&nbsp;−ρ&nbsp;exp(s&nbsp;''m'').\n*If ''mm'' = &nbsp;{{serif|''I''}}, then ''z'' =&nbsp;ρ&nbsp;exp(''a&nbsp;m'') or ''z'' =&nbsp;−ρ&nbsp;exp(''a&nbsp;m'') or ''z'' =&nbsp;''m''&nbsp;ρ&nbsp;exp(''a&nbsp;m'') or ''z'' =&nbsp;−''m''&nbsp;ρ&nbsp;exp(''a&nbsp;m'').\n\nIn the first case exp(θ&nbsp;''m'') =&nbsp;cos(θ)&nbsp;+&nbsp;''m''&nbsp;sin(θ). In the case of the dual numbers exp(''s&nbsp;m'') =&nbsp;1&nbsp;+&nbsp;''s&nbsp;m''. Finally, in the case of split complex numbers there are four components in the group of units. The identity component is parameterized by ρ and exp(''a&nbsp;m'') =&nbsp;cosh(''a'')&nbsp;+&nbsp;''m''&nbsp;sinh(''a'').\n \nNow <math display=\"inline\">\\sqrt{\\rho\\ \\exp(am)} = \\sqrt{\\rho}\\ \\exp\\left(\\frac{1}{2}am\\right)</math> regardless of the subplane P<sub>''m''</sub>, but the argument of the function must be taken from the ''identity component of its group of units''. Half the plane is lost in the case of the dual number structure; three-quarters of the plane must be excluded in the case of the split-complex number structure.\n\nSimilarly, if ρ&nbsp;exp(''a&nbsp;m'') is an element of the identity component of the group of units of a plane associated with {{gaps|2|×|2}} matrix&nbsp;''m'', then the logarithm function results in a value log&nbsp;ρ&nbsp;+&nbsp;''a m''. The domain of the logarithm function suffers the same constraints as does the square root function described above: half or three-quarters of P<sub>''m''</sub> must be excluded in the cases ''mm'' =&nbsp;0 or ''mm'' =&nbsp;{{serif|''I''}}.\n\nFurther function theory can be seen in the article [[complex functions]] for the C structure, or in the article [[motor variable]] for the split-complex structure.\n\n== 2 × 2 real matrices as complex numbers ==\n{{anchor|2 × 2 real matrices as complex numbers}}<!-- \"Dual number\" links here -->\nEvery {{gaps|2|×|2}} real matrix can be interpreted as one of three types of (generalized<ref>Anthony A. Harkin & Joseph B. Harkin (2004) [http://people.rit.edu/harkin/research/articles/generalized_complex_numbers.pdf Geometry of Generalized Complex Numbers], [[Mathematics Magazine]] 77(2):118–29</ref>) complex numbers: standard [[complex number]]s, [[dual number]]s, and [[split-complex number]]s. Above, the algebra of {{gaps|2|×|2}} matrices is profiled as a union of complex planes, all sharing the same real axis. These planes are presented as [[commutative]] [[subring]]s ''P''<sub>''m''</sub>. We can determine to which complex plane a given {{gaps|2|×|2}} matrix belongs as follows and classify which kind of complex number that plane represents.\n\nConsider the {{gaps|2|×|2}} matrix\n:<math>z = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}.</math>\n\nWe seek the complex plane ''P''<sub>''m''</sub> containing ''z''.\n\nAs noted above, the square of the matrix ''z'' is diagonal when ''a'' + ''d'' = 0. The matrix ''z'' must be expressed as the sum of a multiple of the [[identity matrix]] {{serif|''I''}} and a matrix in the [[hyperplane]] ''a'' + ''d'' = 0. [[projection (linear algebra)|Projecting]] ''z'' alternately onto these subspaces of R<sup>4</sup> yields\n:<math>z = xI + n ,\\quad x = \\frac{a + d}{2}, \\quad n = z - xI.</math>\n\nFurthermore, \n:<math>n^2 = pI</math> where <math>p = \\frac{(a - d)^2}{4} + bc</math>.\n\nNow ''z'' is one of three types of complex number:\n* If ''p'' < 0, then it is an ordinary [[complex number]]:\n*: Let <math>q = 1/\\sqrt{-p}, \\quad m = qn</math>. Then <math>m^2 = -I, \\quad z = xI + m\\sqrt{-p}</math>.\n* If ''p'' = 0, then it is the [[dual number]]: \n*: <math>z = xI + n</math>. \n*If ''p'' > 0, then ''z'' is a [[split-complex number]]:\n*: Let <math>q = 1/\\sqrt{p}, \\quad m = qn</math>. Then <math>m^2 = +I, \\quad z = xI + m\\sqrt{p}</math>.\n\nSimilarly, a {{gaps|2|×|2}} matrix can also be expressed in [[polar decomposition#Alternative planar decompositions|polar coordinates]] with the caveat that there are two [[connected space|connected components]] of the group of units in the dual number plane, and four components in the split-complex number plane.\n\n==Projective group==\n{{Main|Real projective line}}\nA given 2 × 2 real matrix with ''ad'' ≠ ''bc'' acts on [[projective coordinates]] [''x'' : ''y''] of the real projective line '''P'''(R) as a [[linear fractional transformation]]:\n:<math>[x : y] \\begin{pmatrix}a & c \\\\ b & d \\end{pmatrix} \\ = \\ [ax + by: \\ cx + dy].</math> When ''cx'' + ''dy'' = 0, the image point is the [[point at infinity]], otherwise\n:<math>[ax + by:\\ cx + dy] \\ \\thicksim \\ [\\frac{ax + by} {cx + dy} : \\ 1] .</math>\nRather than acting on the plane as in the section above, a matrix acts on the projective line '''P'''(R), and all proportional matrices act the same way.\n\nLet ''p'' = ''ad'' – ''bc'' ≠ 0. Then\n:<math>\\begin{pmatrix}a & c \\\\ b & d \\end{pmatrix} \\times \\begin{pmatrix} d & -c \\\\ -b & a \\end{pmatrix} \\ = \\ \\begin{pmatrix} p & 0 \\\\ 0 & p \\end{pmatrix} .</math>\nThe action of this matrix on the real projective line is\n:<math>[x : y] \\begin{pmatrix}p & 0 \\\\ 0 & p \\end{pmatrix} \\ = \\ [px : py] \\thicksim [x : y] </math> because of projective coordinates, so that the action is that of the identity mapping on the real projective line. Therefore, \n:<math>\\begin{pmatrix}a & c \\\\ b & d \\end{pmatrix} \\ \\text{and} \\ \\begin{pmatrix} d & -c \\\\ -b & a \\end{pmatrix} </math> act as [[multiplicative inverse]]s.\nThe projective group starts with the group of units GL(2,R) of M(2,R), and then relates two elements if they are proportional, since proportional actions on '''P'''(R) are identical:\n:[[PGL(2,R)]] = GL(2,R)/~ where ~ relates proportional matrices. Every element of the [[projective linear group]] PGL(2,R) is an [[equivalence class]] under ~ of proportional 2 × 2 real matrices.\n\n==References==\n{{Reflist}}\n* [[Rafael Artzy]] (1965) ''Linear Geometry'', Chapter 2-6 Subgroups of the Plane Affine Group over the Real Field, p.&nbsp;94, [[Addison-Wesley]].\n* Helmut Karzel & Gunter Kist (1985) \"Kinematic Algebras and their Geometries\", found in\n** ''Rings and Geometry'', R. Kaya, P. Plaumann, and K. Strambach editors, pp.&nbsp;437–509, esp 449,50, [[D. Reidel]] {{isbn|90-277-2112-2}} .\n* Svetlana Katok (1992) ''Fuchsian groups'', pp.&nbsp;113ff, [[University of Chicago Press]] {{isbn|0-226-42582-7}} .\n* {{cite book|author=Garret Sobczyk|title=New Foundations in Mathematics: The Geometric Concept of Number|year=2012|publisher=Birkhäuser|isbn=978-0-8176-8384-9|chapter=Chapter 2: Complex and Hyperbolic Numbers}}\n\n{{DEFAULTSORT:Real Matrices (2 by 2)}}\n[[Category:Affine geometry]]\n[[Category:Functions and mappings]]\n[[Category:Linear algebra]]\n[[Category:Algebras]]\n[[Category:Area]]\n[[Category:Matrices]]"
    },
    {
      "title": "Rota–Baxter algebra",
      "url": "https://en.wikipedia.org/wiki/Rota%E2%80%93Baxter_algebra",
      "text": "In [[mathematics]], a '''Rota&ndash;Baxter algebra''' is an [[associative algebra]], together with a particular [[linear map]] ''R'' which satisfies the '''Rota&ndash;Baxter identity'''. It appeared first in the work of the American mathematician [[Glen E. Baxter]]<ref>{{Cite journal |first=G. |last=Baxter |title=An analytic problem whose solution follows from a simple algebraic identity |journal=Pacific J. Math. |volume=10 |issue= 3|pages=731–742 |year=1960 |mr=0119224 |doi=10.2140/pjm.1960.10.731}}</ref>  in the realm of [[probability theory]]. Baxter's work was further explored from different angles by [[Gian-Carlo Rota]],<ref>{{Cite journal |first=G.-C. |last=Rota |title=Baxter algebras and combinatorial identities, I, II |journal=Bull. Amer. Math. Soc. |volume=75 |pages=325–329 |year=1969 |doi=10.1090/S0002-9904-1969-12156-7 |issue=2 }}; ibid. 75, 330&ndash;334, (1969). Reprinted in: ''Gian-Carlo Rota on Combinatorics: Introductory papers and commentaries'', J.P.S. Kung Ed., Contemp. Mathematicians, Birkhäuser Boston, Boston, MA, 1995.</ref><ref>G.-C. Rota, ''Baxter operators, an introduction'', In: ''Gian-Carlo Rota on Combinatorics, Introductory papers and commentaries'', J.P.S. Kung Ed., Contemp. Mathematicians, Birkhäuser Boston, Boston, MA, 1995.</ref><ref>G.-C. Rota and D. Smith, ''Fluctuation theory and Baxter algebras'', Instituto Nazionale di Alta Matematica, IX, 179&ndash;201, (1972). Reprinted in: ''Gian-Carlo Rota on Combinatorics: Introductory papers and commentaries'', J.P.S. Kung Ed., Contemp. Mathematicians, Birkhäuser Boston, Boston, MA, 1995.</ref> [[Pierre Cartier (mathematician)|Pierre Cartier]],<ref>{{Cite journal |first=P. |last=Cartier |title=On the structure of free Baxter algebras |journal=Advances in Mathematics |volume=9 |issue= 2|pages=253–265 |year=1972 |doi=10.1016/0001-8708(72)90018-7 }}</ref> and [[Frederic V. Atkinson]],<ref>{{Cite journal |first=F. V. |last=Atkinson |title=Some aspects of Baxter's functional equation |journal=J. Math. Anal. Appl. |volume=7 |issue= |pages=1–30 |year=1963 |doi=10.1016/0022-247X(63)90075-1 }}</ref> among others. Baxter’s derivation of this identity that later bore his name emanated from some of the fundamental results of the famous probabilist [[Frank Spitzer]] in [[random walk]] theory.<ref>{{Cite journal |first=F. |last=Spitzer |title=A combinatorial lemma and its application to probability theory |journal=Trans. Amer. Math. Soc. |volume=82 |issue= 2|pages=323–339 |year=1956 |doi=10.1090/S0002-9947-1956-0079851-X }}</ref><ref>{{Cite journal |first=F. |last=Spitzer |title=Principles of random walks |edition=Second |series=Graduate Texts in Mathematics |volume=34 |publisher=Springer-Verlag |location=New York, Heidelberg |year=1976 }}</ref>\n\nIn the 1980s, the Rota-Baxter operator of weight 0 in the context of Lie algebras was rediscovered as the operator form of the classical [[Yang-Baxter equation]],<ref>{{Cite journal |first=M.A. |last=Semenov-Tian-Shansky |title=What is a classical ''r''-matrix? |journal=Func. Anal. Appl. |volume=17 |issue= 4|pages=259–272 |year=1983 }}</ref> named after the well-known physicists [[Chen-Ning Yang]] and [[Rodney Baxter]].\n\nThe study of Rota–Baxter algebras experienced a renaissance this century, beginning with several developments, in the algebraic approach to renormalization of perturbative quantum field theory,<ref>{{cite journal|last1=Connes|first1=A.|last2=Kreimer|first2=D.|title=Renormalization in quantum field theory and the Riemann-Hilbert problem. I. The Hopf algebra structure of graphs and the main theorem|journal=Comm. Math. Phys.|date=2000|volume=210|issue=1|pages=249–273|doi=10.1007/s002200050779|arxiv=hep-th/9912092}}</ref> [[dendriform algebra]]s, associative analogue of the classical Yang-Baxter equation<ref>{{Cite journal |first=M. |last=Aguiar |title=Infinitesimal Hopf algebras |journal=Contemp. Math. |volume=267 |issue= |pages=1–29 |year=2000 }}</ref> and mixable shuffle product constructions.<ref>{{cite journal|last1=Guo|first1=L.|last2=Keigher|first2=W.|title=Baxter algebras and shuffle products|journal=Adv. Math.|date=2000|volume=150|pages=117–149|doi=10.1006/aima.1999.1858|doi-access=free|arxiv=math/0407155}}</ref>\n\n==Definition and first properties==\nLet ''k'' be a commutative ring and let <math>\\lambda</math> be given. A linear operator ''R'' on a ''k''-algebra ''A'' is called a '''Rota-Baxter operator of weight <math>\\lambda</math>''' if it satisfies the '''Rota-Baxter relation of weight <math>\\lambda</math>''':\n\n:<math> R(x)R(y)=R(R(x)y) + R(xR(y)) + \\lambda R(xy)</math>\n\nfor all <math>x, y \\in A</math>. Then the pair <math>(A,R)</math> or simply ''A'' is called a '''Rota–Baxter algebra of weight <math>\\lambda</math>'''. In some literature, <math>\\theta=-\\lambda</math> is used in which case the above equation becomes\n\n:<math> R(x)R(y)+\\theta R(xy) = R(R(x)y) + R(xR(y)),</math>\n\ncalled the '''Rota-Baxter equation of weight <math>\\theta</math>'''. The terms Baxter operator algebra and Baxter algebra are also used.\n\nLet <math>R</math> be a Rota-Baxter of weight <math>\\lambda</math>. Then <math>-\\lambda Id - R</math> is also a Rota-Baxter operator of weight <math>\\lambda</math>. Further, for  <math>\\mu</math> in ''k'', <math>\\mu R</math> is a Rota-Baxter operator of weight <math>\\mu\\lambda</math>.\n\n==Examples==\n'''Integration by Parts'''\n\n[[Integration by parts]] is an example of a Rota–Baxter algebra of weight 0.  Let <math>C(R)</math> be the algebra of [[continuous functions]] from the real line to the real line. Let :<math>f(x) \\in C(R)</math> be a continuous function. Define [[integral|integration]] as the Rota&ndash;Baxter operator\n\n:<math>I(f)(x) = \\int_0^x f(t) dt \\;.</math>\n\nLet ''G(x)'' = ''I(g)(x)'' and ''F(x)'' = ''I(f)(x)''. Then the formula for integration for parts can be written in terms of these variables as\n\n:<math> F(x)G(x) = \\int_0^x f(t) G(t) dt + \\int_0^x F(t)g(t) dt \\;.</math>\n\nIn other words\n\n:<math> I(f)(x)I(g)(x) = I(fI(g)(t))(x) + I(I(f)(t)g)(x) \\; , </math>\n\nwhich shows that ''I'' is a Rota&ndash;Baxter algebra of weight 0.\n\n==Spitzer identity==\nThe Spitzer identity appeared is named after the American mathematician [[Frank Spitzer]]. It is regarded as a remarkable \nstepping stone in the theory of sums of independent random variables in fluctuation theory of probability. It can naturally be understood in terms of Rota&ndash;Baxter operators.\n\n===Bohnenblust&ndash;Spitzer identity===\n{{Empty section|date=August 2010}}\n\n==Notes==\n{{Reflist|colwidth=30em}}\n\n==External links==\n* Li Guo. [http://www.ams.org/notices/200911/rtx091101436p.pdf WHAT IS...a Rota-Baxter Algebra?] Notices of the AMS, December 2009, Volume 56 Issue 11\n\n{{DEFAULTSORT:Rota-Baxter Algebra}}\n[[Category:Algebras]]\n[[Category:Combinatorics]]"
    },
    {
      "title": "Semisimple algebra",
      "url": "https://en.wikipedia.org/wiki/Semisimple_algebra",
      "text": "{{see also|Semisimple module}}\n{{refimprove|date=July 2014}}\nIn [[ring theory]], a branch of mathematics, a '''semisimple algebra''' is an [[associative algebra|associative]] [[artinian ring|artinian]] algebra over a [[field (mathematics)|field]] which has trivial [[Jacobson radical]] (only the zero element of the algebra is in the Jacobson radical). If the algebra is finite-dimensional this is equivalent to saying that it can be expressed as a Cartesian product of [[simple algebra|simple subalgebras]].\n\n==Definition==\nThe [[Jacobson radical]] of an algebra over a field is the ideal consisting of all elements that annihilate every simple left-module. The radical contains all nilpotent ideals, and if the algebra is finite-dimensional, the radical itself is a nilpotent ideal.  A finite-dimensional algebra is then said to be ''semisimple'' if its radical contains only the zero element.\n\nAn algebra ''A'' is called ''simple'' if it has no proper ideals and ''A''<sup>2</sup> = {''ab'' | ''a'', ''b'' ∈ ''A''}  ≠ {0}. As the terminology suggests, simple algebras are semisimple. The only possible ideals of a simple algebra ''A'' are ''A'' and {0}. Thus if ''A'' is simple, then ''A'' is not nilpotent. Because ''A''<sup>2</sup> is an ideal of ''A'' and ''A'' is simple, ''A''<sup>2</sup> = ''A''. By induction, ''A<sup>n</sup>'' = ''A'' for every positive integer ''n'', i.e. ''A'' is not nilpotent.\n\nAny self-adjoint subalgebra ''A'' of ''n'' &times; ''n'' matrices with complex entries is semisimple. Let Rad(''A'') be the radical of ''A''. Suppose a matrix ''M'' is in Rad(''A''). Then ''M*M'' lies in some nilpotent ideals of ''A'', therefore (''M*M'')''<sup>k</sup>'' = 0 for some positive integer ''k''. By positive-semidefiniteness of ''M*M'', this implies ''M*M'' = 0. So ''M x'' is the zero vector for all ''x'', i.e. ''M'' = 0.\n\nIf {''A<sub>i</sub>''} is a finite collection of simple algebras, then their Cartesian product ∏ ''A<sub>i</sub>'' is semisimple. If (''a<sub>i</sub>'') is an element of Rad(''A'') and ''e''<sub>1</sub> is the multiplicative identity in ''A''<sub>1</sub> (all simple algebras possess a multiplicative identity), then (''a''<sub>1</sub>, ''a''<sub>2</sub>, ...) · (''e''<sub>1</sub>, 0, ...) = (''a''<sub>1</sub>, 0..., 0) lies in some nilpotent ideal of ∏ ''A<sub>i</sub>''. This implies, for all ''b'' in ''A''<sub>1</sub>, ''a''<sub>1</sub>''b'' is nilpotent in ''A''<sub>1</sub>, i.e. ''a''<sub>1</sub> ∈ Rad(''A''<sub>1</sub>). So ''a''<sub>1</sub> = 0. Similarly, ''a<sub>i</sub>'' = 0 for all other ''i''.\n\nIt is less apparent from the definition that the converse of the above is also true, that is, any finite-dimensional semisimple algebra is isomorphic to a Cartesian product of a finite number of simple algebras. The following is a semisimple algebra that appears not to be of this form. Let ''A'' be an algebra with Rad(''A'') ≠ ''A''. The quotient algebra ''B'' = ''A'' ⁄ Rad(''A'') is semisimple: If ''J'' is a nonzero nilpotent ideal in ''B'', then its preimage under the natural projection map is a nilpotent ideal in ''A'' which is strictly larger than Rad(''A''), a contradiction.\n\n==Characterization==\nLet ''A'' be a finite-dimensional semisimple algebra, and\n\n:<math>\\{0\\} = J_0 \\subset \\cdots \\subset J_n \\subset A</math>\n\nbe a [[composition series]] of ''A'', then ''A'' is isomorphic to the following Cartesian product:\n\n:<math>A \\simeq J_1 \\times J_2/J_1 \\times J_3/J_2 \\times ... \\times J_n/ J_{n-1} \\times A / J_n </math>\n\nwhere each\n\n:<math>J_{i+1}/J_i \\,</math>\n \nis a simple algebra.\n\nThe proof can be sketched as follows. First, invoking the assumption that ''A'' is semisimple, one can show that the ''J''<sub>1</sub> is a simple algebra (therefore unital). So ''J''<sub>1</sub> is a unital subalgebra and an ideal of ''J''<sub>2</sub>. Therefore one can decompose\n\n:<math>J_2 \\simeq J_1 \\times J_2/J_1 .</math>\n\nBy maximality of ''J''<sub>1</sub> as an ideal in ''J''<sub>2</sub> and also the semisimplicity of ''A'', the algebra\n\n:<math>J_2/J_1 \\,</math>\n\nis simple. Proceed by induction in similar fashion proves the claim. For example, ''J''<sub>3</sub> is the Cartesian product of simple algebras\n\n:<math>J_3 \\simeq J_2 \\times J_3 / J_2 \\simeq J_1 \\times J_2/J_1 \\times J_3 / J_2.</math>\n\nThe above result can be restated in a different way. For a semisimple algebra ''A'' = ''A''<sub>1</sub> &times;...&times; ''A<sub>n</sub>'' expressed in terms of its simple factors, consider the units ''e<sub>i</sub>'' ∈ ''A<sub>i</sub>''. The elements ''E<sub>i</sub>'' = (0,...,''e<sub>i</sub>'',...,0) are [[idempotent element (ring theory)|idempotent element]]s in ''A'' and they lie in the center of ''A''. Furthermore, ''E<sub>i</sub> A'' = ''A<sub>i</sub>'', ''E<sub>i</sub>E<sub>j</sub>'' = 0 for ''i'' ≠ ''j'',  and Σ ''E<sub>i</sub>'' = 1, the multiplicative identity in ''A''.\n\nTherefore, for every semisimple algebra ''A'', there exists idempotents {''E<sub>i</sub>''} in the center of ''A'', such that\n\n#''E<sub>i</sub>E<sub>j</sub>'' = 0 for ''i'' ≠ ''j'' (such a set of idempotents is called ''[[Idempotent element (ring theory)#Types of ring idempotents|central orthogonal]]''), \n#Σ ''E<sub>i</sub>'' = 1, \n#''A'' is isomorphic to the Cartesian product of simple algebras ''E''<sub>1</sub> ''A'' &times;...&times; ''E<sub>n</sub> A''.\n\n==Classification==\n\nA theorem due to [[Joseph Wedderburn]] completely classifies finite-dimensional semisimple algebras over a field <math> k</math>.  Any such algebra is isomorphic to a finite product <math> \\prod M_{n_i}(D_i) </math> where the <math> n_i </math> are natural numbers, the <math> D_i </math> are [[division algebra]]s over <math>k </math>, and <math> M_{n_i}(D_i) </math> is the algebra of <math> n_i \\times n_i </math> matrices over <math> D_i</math>. This product is unique up to permutation of the factors.<ref name=\"Beachy1999\">{{cite book|author=Anthony Knapp|title=Advanced Algebra, Chap. II: Wedderburn-Artin Ring Theory|url=http://www.math.sunysb.edu/~aknapp/books/advanced-alg/a-alg-Ch2-sample.pdf|year=2007|publisher=Springer Verlag}}</ref>\n\nThis theorem was later generalized by [[Emil Artin]] to semisimple rings. This more general result is called the [[Artin-Wedderburn theorem]].\n\n==References==\n{{Reflist}}\n[http://www.encyclopediaofmath.org/index.php/Semi-simple_algebra Springer Encyclopedia of Mathematics]\n\n{{DEFAULTSORT:Semisimple Algebra}}\n[[Category:Algebras]]"
    },
    {
      "title": "Separable algebra",
      "url": "https://en.wikipedia.org/wiki/Separable_algebra",
      "text": "{{Confuse|text = an [[étale algebra]]}}\n\nIn mathematics, a '''separable algebra''' is a kind of [[semisimple algebra]].  It is a generalization to [[associative algebra]]s of the notion of a [[separable extension|separable field extension]].\n\n== Definition and First Properties ==\nA [[ring homomorphism]] (of unital, but not necessarily [[commutative ring]]s)\n\n:<math>K \\to A</math>\n\nis called ''separable'' (or a ''separable extension'') if the multiplication map\n\n:<math>\\mu : A \\otimes_K A \\to A, a \\otimes b \\mapsto ab</math>\n\nadmits a [[section (category theory)|section]]\n\n:<math>\\sigma: A \\to A \\otimes_K A</math>\n\nby means of a homomorphism &sigma; of ''A''-''A''-[[bimodule]]s. Such a section &sigma; is determined by its value\n\n:<math>p := \\sigma(1) = \\sum a_i \\otimes b_i</math>\n\n&sigma;(1). The condition that &sigma; is a section of &mu; is equivalent to\n\n:<math>\\sum a_i b_i = 1</math>\n\nand the condition to be an homomorphism of ''A''-''A''-bimodules is equivalent to the following requirement for any ''a'' in ''A'':\n\n:<math>\\sum a a_i \\otimes b_i = \\sum a_i \\otimes b_i a.</math>\nSuch an element ''p'' is called a ''separability idempotent'', since it satisfies <math>p^2 = p</math>.\n\n==Examples==\nFor any commutative ring ''R'', the (non-commutative) ring of ''n''-by-''n'' [[matrix (mathematics)|matrices]] <math>M_n(R)</math> is a separable ''R''-algebra. For any <math>1 \\le j \\le n</math>, a separability idempotent is given by <math>\\sum_{i=1}^n e_{ij} \\otimes e_{ji}</math>, where <math>e_{ij}</math> denotes the [[elementary matrix]] which is 0 except for the entry in position (''i'', ''j''), which is 1. In particular, this shows that separability idempotents need not be unique.\n\n===Separable algebras over a field===\n\nIf <math>\\scriptstyle L/K</math> is a [[field extension]], then ''L'' is separable as an associative ''K''-algebra if and only if the extension of fields is [[separable extension|separable]].\nIf ''L''/''K'' has a [[Primitive element (field theory)|primitive element]] <math> a</math> with irreducible polynomial <math> p(x) = (x - a) \\sum_{i=0}^{n-1} b_i x^i</math>, then a separability idempotent is given by <math> \\sum_{i=0}^{n-1} a^i \\otimes_K \\frac{b_i}{p'(a)}</math>.   The tensorands are dual bases for the trace map: if <math> \\sigma_1,\\ldots,\\sigma_{n} </math> are the distinct ''K''-monomorphisms of ''L'' into an algebraic closure of ''K'', the trace mapping Tr of ''L'' into ''K'' is defined by <math>Tr(x) =  \\sum_{i=1}^{n} \\sigma_i(x)</math>.  The trace map and its dual bases make explicit ''L'' as a [[Frobenius algebra]] over K.\n\nMore generally, separable algebras over a field ''K'' can be classified as follows: they are the same as finite products of matrix algebras over finite-dimensional [[division algebras]] whose centers are finite-dimensional [[separable extension|separable field extensions]] of the field ''K''. In particular: Every separable algebra is itself finite-dimensional. If ''K'' is a [[perfect field]] --- for example a field of characteristic zero, or a finite field, or an algebraically closed field --- then every extension of ''K'' is separable so that separable ''K''-algebras are finite products of matrix algebras over finite-dimensional division algebras over field ''K''.  In other words, if ''K'' is a perfect field, there is no difference between a separable algebra over ''K'' and a finite-dimensional [[semisimple algebra]] over ''K''.\nIt can be shown by a generalized theorem of Maschke that an associative ''K''-algebra ''A'' is separable if for every [[field extension]] <math>\\scriptstyle L/K</math> the algebra <math>\\scriptstyle A\\otimes_K L</math> is semisimple.\n\n===Group rings===\n\nIf ''K'' is commutative ring and ''G'' is a finite group such that the [[Order (ring theory)|order]] of ''G'' is invertible in ''K'', then the [[group ring]] ''K''[''G''] is a separable ''K''-algebra.<ref>{{harvtxt|Ford|2017|loc=§4.2}}</ref> A separability idempotent is given by <math> \\frac{1}{o(G)} \\sum_{g \\in G} g \\otimes g^{-1}</math>.\n\n==Equivalent characterizations of separability==\nThere are a several equivalent definitions of separable algebras. A ''K''-algebra ''A'' is separable if and only if it is [[projective module|projective]] when considered as a left module of <math>A^e</math> in the usual way.<ref>{{harvtxt|Reiner|2003|loc=p. 102}}</ref> Moreover, an algebra ''A'' is separable if and only if it is [[flat module|flat]] when considered as a right module of <math>A^e</math> in the usual  way. \nSeparable extensions can also be characterized by means of split extensions: ''A'' is separable over ''K'' if all [[short exact sequence]]s of ''A''-''A''-bimodules that are split as ''A''-''K''-bimodules also split as ''A''-''A''-bimodules. Indeed, this condition is necessary since the multiplication mapping <math>\\mu : A \\otimes_K A \\rightarrow A </math> arising in the definition above is a ''A''-''A''-bimodule epimorphism, which is split as an ''A''-''K''-bimodule map by the right inverse mapping <math> A \\rightarrow A \\otimes_K A</math> given by <math> a \\mapsto a \\otimes 1 </math>. The converse can be proven by a judicious use of the separability idempotent (similarly to the proof of [[Maschke's theorem]], applying its components within and without the splitting maps).<ref>{{harvtxt|Ford|2017|Theorem 4.4.1}}</ref>\n\nEquivalently, the relative [[Hochschild cohomology]] groups <math> H^n(R,S;M)</math> of (R,S) in any coefficient bimodule ''M'' is zero for ''n'' > 0. Examples of separable extensions are many including first separable algebras where R = separable algebra and S = 1 times the ground field. Any ring R with elements a and b satisfying ab = 1, but ba different from 1, is a separable extension over the subring S generated by 1 and bRa.\n\n==Relation to Frobenius algebras==\nA separable algebra is said to be ''strongly separable'' if there exists a separability idempotent that is ''symmetric'', meaning\n\n:<math> e = \\sum_{i=1}^n x_i \\otimes y_i = \\sum_{i=1}^n y_i \\otimes x_i</math>\n\nAn algebra is strongly separable if and only if its trace form is nondegenerate, thus making the algebra into a particular kind of [[Frobenius algebra]] called a symmetric algebra (not to be confused with the [[symmetric algebra]] arising as the quotient of the [[tensor algebra]]).\n\nIf ''K'' is commutative, ''A'' is a [[finitely generated module|finitely generated]] [[projective module|projective]] separable ''K''-module, then ''A'' is a symmetric Frobenius algebra.<ref>{{harvtxt|Endo|Watanabe|1967|loc=Theorem 4.2}}. If ''A'' is commutative, the proof is simpler, see {{harvtxt|Kadison|1999|loc=Lemma 5.11}}</ref>\n==Relation to formally unramified and formally étale extensions==\n\nAny separable extension ''A'' / ''K'' of commutative rings is [[formally unramified]]. The converse holds if ''A'' is a finitely generated ''K''-algebra.<ref>{{harvtxt|Ford|2017|loc=Corollary 4.7.2, Theorem 8.3.6}}</ref> A separable [[flat module|flat]] (commutative) ''K''-algebra ''A'' is [[formally étale]].<ref>{{harvtxt|Ford|2017|loc=Corollary 4.7.3}}</ref>\n\n==Further results==\n\nA theorem in the area is that of J. Cuadra that a separable Hopf-Galois extension R | S has finitely generated natural S-module R.   A fundamental fact about a separable extension R | S is that it is left or right semisimple extension:  a short exact sequence of left or right R-modules that is split as S-modules, is split as R-modules.  In terms of G. Hochschild's relative homological algebra, one says that all R-modules are relative (R,S)-projective. Usually relative properties of subrings or ring extensions, such as the notion of separable extension, serve to promote theorems that say that the over-ring shares a property of the subring.  For example, a separable extension R of a semisimple algebra S has R semisimple, which follows from the preceding discussion.\n\nThere is the celebrated Jans theorem that a finite group algebra A over a field of\ncharacteristic p is of finite representation type if and only if its Sylow p-subgroup is cyclic: the clearest proof is to note this fact for p-groups, then note that the group algebra is a separable extension of its Sylow p-subgroup algebra B as the index is coprime to the characteristic.  The separability condition above will imply every finitely generated A-module M is isomorphic to a direct summand\nin its restricted, induced module.  But if B has finite representation type, the restricted module\nis uniquely a direct sum of multiples of finitely many indecomposables, which induce to a finite number of constituent indecomposable modules of which M is a direct sum.  Hence A is of finite representation type if B is.  The converse is proven by a similar argument noting that every subgroup algebra B is a B-bimodule direct summand of a group algebra A.\n\n== References ==\n{{reflist}}\n* {{cite book | last1=DeMeyer | first1=F. | last2=Ingraham | first2=E. | title=Separable algebras over commutative rings | series=Lecture Notes in Mathematics | volume=181 | location=Berlin-Heidelberg-New York | publisher=[[Springer-Verlag]] | year=1971 | isbn=978-3-540-05371-2 | zbl=0215.36602 }}\n* [[Samuel Eilenberg]] and Tadasi Nakayama, [https://web.archive.org/web/20110120012931/http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.nmj%2F1118799677 On the dimension of modules and algebras. II. Frobenius algebras and quasi-Frobenius rings], Nagoya Math. J. Volume 9 (1955), 1-16.\n* {{Citation|author1=Endo|first1=Shizuo|author2=Watanabe|first2=Yutaka|title=On separable algebras over a commutative ring|journal=Osaka Journal of Mathematics|volume=4|year=1967|pages=233&mdash;242|mr=0227211|url=http://projecteuclid.org/euclid.ojm/1200691953}}\n\n* {{Citation|author=Ford|first=Timothy J.|title=Separable algebras|publisher=American Mathematical Society|location=Providence, RI|year=2017|isbn=978-1-4704-3770-1|mr=3618889}}\n* {{Citation|author=Hirata|first=H.|author2=Sugano|first2=K.|title=On semisimple and separable extensions of noncommutative rings|journal=J. Math. Soc. Japan|volume=18|year=1966|pages=360&mdash;373}}.\n\n* {{Citation|author=Kadison|first=Lars|author-link=Lars Kadison|title=New examples of Frobenius extensions|series=University Lecture Series|volume=14|publisher=American Mathematical Society|location=Providence, RI|year=1999|isbn=0-8218-1962-3|mr=1690111|doi=10.1090/ulect/014}}\n\n* {{Citation | last=Reiner | first=I. | authorlink=Irving Reiner | title=Maximal Orders | series=London Mathematical Society Monographs.  New Series | volume=28 | publisher=[[Oxford University Press]] | year=2003 | isbn=0-19-852673-3 | zbl=1024.16008 }}\n* {{Weibel IHA}}\n\n\n[[Category:Algebras]]"
    },
    {
      "title": "Simple algebra",
      "url": "https://en.wikipedia.org/wiki/Simple_algebra",
      "text": "In [[mathematics]], specifically in [[ring theory]], an [[algebra (ring theory)|algebra]] is '''simple''' if it contains no non-trivial two-sided [[ideal (ring theory)|ideal]]s and the multiplication operation is ''not'' zero (that is, there is some ''a'' and some ''b'' such that {{nowrap|''ab'' ≠ 0}}).\n\nThe second condition in the definition precludes the following situation; consider the algebra with the usual matrix operations:\n\n:<math>\n\\left\\{\\left.\n\\begin{bmatrix}\n0 & \\alpha \\\\\n0 & 0 \\\\\n\\end{bmatrix}\\,\n\\right| \\,\n\\alpha \\in \\mathbb{C}\n\\right\\}\n</math>\n\nThis is a one-dimensional algebra in which the product of any two elements is zero. This condition ensures that the algebra has a minimal nonzero left ideal, which simplifies certain arguments.\n\nAn immediate example of simple algebras are [[division algebra]]s, where every nonzero element has a multiplicative inverse, for instance, the real algebra of [[quaternions]]. Also, one can show that the algebra of ''n'' &times; ''n'' matrices with entries in a division ring is simple. In fact, this characterizes all finite-dimensional simple algebras up to isomorphism, i.e. any finite-dimensional simple algebra is isomorphic to a [[matrix algebra]] over some [[division ring]]. This result was given in 1907 [[Joseph Wedderburn]] in his doctoral thesis, ''On hypercomplex numbers'', which appeared in the [[Proceedings of the London Mathematical Society]]. Wedderburn's thesis classified simple and [[semisimple algebra]]s. Simple algebras are building blocks of semi-simple algebras: any finite-dimensional semi-simple algebra is a Cartesian product, in the sense of algebras, of simple algebras.\n\nWedderburn's result was later generalized to [[semisimple ring]]s in the [[Artin–Wedderburn theorem]].\n\n== Examples ==\n\n* A [[central simple algebra]] (sometimes called Brauer algebra) is a simple finite-dimensional algebra over a [[field (mathematics)|field]] ''F'' whose [[center of an algebra|center]] is ''F''.\n\n== Simple universal algebras ==\n\nIn [[universal algebra]], an abstract algebra ''A'' is called ''simple'' [[if and only if]] it has no nontrivial [[congruence relation]]s, or equivalently, if every homomorphism with domain  ''A''  is either [[injective]] or constant.\n\nAs congruences on rings are characterized by their ideals, this notion is a straightforward generalization of the notion from ring theory: a ring is simple in the sense that it has no nontrivial ideals if and only if it is simple in the sense of universal algebra. The same remark applies with respect to groups and normal subgroups; hence the universal notion is also a generalization of a [[simple group]] (it is a matter of convention whether a one-element algebra should be or should not be considered simple, hence only in this special case the notions might not match).\n\nA theorem by [[Roberto Magari]] in 1969 asserts that every  variety contains a simple algebra.<ref>{{cite journal|url=http://www.springerlink.com/content/d50428g471274371/ |title=Simple algebras in varieties |last=Lampe |first=W.A. |last2=Taylor|first2= W. |journal=Algebra Universalis |volume=14 |year=1982 |issue=1 |pages=36–43 |doi=10.1007/BF02483905}} The original paper is  {{cite journal|last=Magari |first=R. |title=Una dimostrazione del fatto che ogni varietà ammette algebre semplici |journal=Annalli dell'Università di Ferrara, Sez. VII |volume=14 |issue=1 |pages=1–4 |year=1969 |url=http://www.springerlink.com/content/13v2x670035vl116/ |doi=10.1007/BF02896794|language=italian}}</ref>\n\n== See also ==\n\n* [[simple group]]\n* [[simple ring]]\n* [[central simple algebra]]\n\n==References==\n{{Reflist}}\n* [[A. A. Albert]], ''Structure of algebras'', Colloquium publications '''24''', [[American Mathematical Society]], 2003, {{isbn|0-8218-1024-3}}.  P.37.\n\n[[Category:Algebras]]\n[[Category:Ring theory]]"
    },
    {
      "title": "Superalgebra",
      "url": "https://en.wikipedia.org/wiki/Superalgebra",
      "text": "In [[mathematics]] and [[theoretical physics]], a '''superalgebra''' is a '''Z'''<sub>2</sub>-[[graded algebra]].<ref>{{harvnb|Kac|Martinez|Zelmanov|2001|p=3}}</ref> That is, it is an [[algebra (ring theory)|algebra]] over a [[commutative ring]] or [[field (mathematics)|field]] with a decomposition into \"even\" and \"odd\" pieces and a multiplication operator that respects the grading.\n\nThe prefix ''super-'' comes from the theory of [[supersymmetry]] in theoretical physics. Superalgebras and their representations, [[supermodule]]s, provide an algebraic framework for formulating supersymmetry. The study of such objects is sometimes called [[super linear algebra]]. Superalgebras also play an important role in related field of [[supergeometry]] where they enter into the definitions of [[graded manifold]]s, [[supermanifold]]s and [[superscheme]]s.\n\n==Formal definition==\n\nLet ''K'' be a [[commutative ring]]. In most applications, ''K'' is a [[field (mathematics)|field]] [[Characteristic (algebra)|characteristic]] 0, such as '''R''' or '''C'''.\n\nA '''superalgebra''' over ''K'' is a [[module (mathematics)|''K''-module]] ''A'' with a [[direct sum of modules|direct sum]] decomposition\n:<math>A = A_0\\oplus A_1</math>\ntogether with a [[bilinear map|bilinear]] multiplication ''A'' &times; ''A'' &rarr; ''A'' such that\n:<math>A_iA_j \\sube A_{i+j}</math>\nwhere the subscripts are read [[Modular arithmetic|modulo]] 2, i.e. they are thought of as elements of '''Z'''<sub>2</sub>.\n\nA '''superring''', or '''Z'''<sub>2</sub>-[[graded ring]], is a superalgebra over the ring of [[integer]]s '''Z'''.\n\nThe elements of each of the ''A''<sub>''i''</sub> are said to be '''homogeneous'''. The '''parity''' of a homogeneous element ''x'', denoted by {{abs|''x''}}, is 0 or 1 according to whether it is in ''A''<sub>0</sub> or ''A''<sub>1</sub>. Elements of parity 0 are said to be '''even''' and those of parity 1 to be '''odd'''. If ''x'' and ''y'' are both homogeneous then so is the product ''xy'' and <math>|xy| = |x| + |y|</math>.\n\nAn '''associative superalgebra''' is one whose multiplication is [[associative]] and a '''unital superalgebra''' is one with a multiplicative [[identity element]]. The identity element in a unital superalgebra is necessarily even. Unless otherwise specified, all superalgebras in this article are assumed to be associative and unital.\n\nA '''[[commutative superalgebra]]''' (or supercommutative algebra) is one which satisfies a graded version of [[commutativity]]. Specifically, ''A'' is commutative if\n\n:<math>yx = (-1)^{|x||y|}xy\\,</math>\n\nfor all homogeneous elements ''x'' and ''y'' of ''A''. There are superalgebras that are commutative in the ordinary sense, but not in the superalgebra sense. For this reason, commutative superalgebras are often called ''supercommutative'' in order to avoid confusion.<ref>{{harvnb|Varadarajan|2004|p=87}}</ref>\n\n==Examples==\n*Any algebra over a commutative ring ''K'' may be regarded as a purely even superalgebra over ''K''; that is, by taking ''A''<sub>1</sub> to be trivial.\n*Any '''Z'''- or '''N'''-[[graded algebra]] may be regarded as superalgebra by reading the grading modulo 2. This includes examples such as [[tensor algebra]]s and [[polynomial ring]]s over ''K''.\n*In particular, any [[exterior algebra]] over ''K'' is a superalgebra. The exterior algebra is the standard example of a [[supercommutative algebra]].\n*The [[symmetric polynomials]] and [[alternating polynomials]] together form a superalgebra, being the even and odd parts, respectively. Note that this is a different grading from the grading by degree.\n*[[Clifford algebra]]s are superalgebras. They are generally noncommutative.\n*The set of all [[endomorphism]]s (denoted <math>\\mathbf{End} (V) \\equiv \\mathbf{Hom}(V,V)</math>, where the boldface <math>\\mathrm {Hom}</math> is referred to as ''internal'' <math>\\mathrm {Hom}</math>, composed of ''all'' linear maps) of a [[super vector space]] forms a superalgebra under composition.\n*The set of all square [[supermatrices]] with entries in ''K'' forms a superalgebra denoted by ''M''<sub>''p''|''q''</sub>(''K''). This algebra may be identified with the algebra of endomorphisms of a free supermodule over ''K'' of rank ''p''|''q'' and is the internal Hom of above for this space.\n*[[Lie superalgebra]]s are a graded analog of [[Lie algebra]]s. Lie superalgebras are nonunital and nonassociative; however, one may construct the analog of a [[universal enveloping algebra]] of a Lie superalgebra which is a unital, associative superalgebra.\n\n==Further definitions and constructions==\n\n===Even subalgebra===\n\nLet ''A'' be a superalgebra over a commutative ring ''K''. The [[submodule]] ''A''<sub>0</sub>, consisting of all even elements, is closed under multiplication and contains the identity of ''A'' and therefore forms a [[subalgebra]] of ''A'', naturally called the '''even subalgebra'''. It forms an ordinary [[algebra (ring theory)|algebra]] over ''K''.\n\nThe set of all odd elements ''A''<sub>1</sub> is an ''A''<sub>0</sub>-[[bimodule]] whose scalar multiplication is just multiplication in ''A''. The product in ''A'' equips ''A''<sub>1</sub> with a [[bilinear form]]\n:<math>\\mu:A_1\\otimes_{A_0}A_1 \\to A_0</math>\nsuch that\n:<math>\\mu(x\\otimes y)\\cdot z = x\\cdot\\mu(y\\otimes z)</math>\nfor all ''x'', ''y'', and ''z'' in ''A''<sub>1</sub>. This follows from the associativity of the product in ''A''.\n\n===Grade involution===\n\nThere is a canonical [[Involution (mathematics)|involutive]] [[automorphism]] on any superalgebra called the '''grade involution'''. It is given on homogeneous elements by\n:<math>\\hat x = (-1)^{|x|}x</math>\nand on arbitrary elements by\n:<math>\\hat x = x_0 - x_1</math>\nwhere ''x''<sub>''i''</sub> are the homogeneous parts of ''x''. If ''A'' has no [[torsion (algebra)|2-torsion]] (in particular, if 2 is invertible) then the grade involution can be used to distinguish the even and odd parts of ''A'':\n:<math>A_i = \\{x \\in A : \\hat x = (-1)^i x\\}.</math>\n\n===Supercommutativity===\n\nThe '''[[supercommutator]]''' on ''A'' is the binary operator given by\n:<math>[x,y] = xy - (-1)^{|x||y|}yx</math>\non homogeneous elements, extended to all of ''A'' by linearity. Elements ''x'' and ''y'' of ''A'' are said to '''supercommute''' if {{nowrap|1=[''x'', ''y''] = 0}}.\n\nThe '''supercenter''' of ''A'' is the set of all elements of ''A'' which supercommute with all elements of ''A'':\n:<math>\\mathrm{Z}(A) = \\{a\\in A : [a,x]=0 \\text{ for all } x\\in A\\}.</math>\nThe supercenter of ''A'' is, in general, different than the [[center of an algebra|center]] of ''A'' as an ungraded algebra. A commutative superalgebra is one whose supercenter is all of ''A''.\n\n===Super tensor product===\n\nThe graded [[tensor product of algebras|tensor product]] of two superalgebras ''A'' and ''B'' may be regarded as a superalgebra ''A'' &otimes; ''B'' with a multiplication rule determined by:\n:<math>(a_1\\otimes b_1)(a_2\\otimes b_2) = (-1)^{|b_1||a_2|}(a_1a_2\\otimes b_1b_2).</math>\nIf either ''A'' or ''B'' is purely even, this is equivalent to the ordinary ungraded tensor product (except that the result is graded). However, in general, the super tensor product is distinct from the tensor product of ''A'' and ''B'' regarded as ordinary, ungraded algebras.\n\n==Generalizations and categorical definition==\n\nOne can easily generalize the definition of superalgebras to include superalgebras over a commutative superring. The definition given above is then a specialization to the case where the base ring is purely even.\n\nLet ''R'' be a commutative superring. A '''superalgebra''' over ''R'' is a [[supermodule|''R''-supermodule]] ''A'' with a ''R''-bilinear multiplication ''A'' &times; ''A'' &rarr; ''A'' that respects the grading. Bilinearity here means that\n:<math>r\\cdot(xy) = (r\\cdot x)y = (-1)^{|r||x|}x(r\\cdot y)</math>\nfor all homogeneous elements ''r'' &isin; ''R'' and ''x'', ''y'' &isin; ''A''.\n\nEquivalently, one may define a superalgebra over ''R'' as a superring ''A'' together with an superring homomorphism ''R'' &rarr; ''A'' whose image lies in the supercenter of ''A''.\n\nOne may also define superalgebras [[category theory|categorically]]. The [[category (mathematics)|category]] of all ''R''-supermodules forms a [[monoidal category]] under the super tensor product with ''R'' serving as the unit object. An associative, unital superalgebra over ''R'' can then be defined as a [[monoid (category theory)|monoid]] in the category of ''R''-supermodules. That is, a superalgebra is an ''R''-supermodule ''A'' with two (even) morphisms\n:<math>\\begin{align}\\mu &: A\\otimes A \\to A\\\\ \\eta &: R\\to A\\end{align}</math>\nfor which the usual diagrams commute.\n\n== Notes ==\n<references/>\n\n==References==\n*{{cite conference | ref = harv | authorlink = Pierre Deligne | first = P. | last = Deligne |first2=J. W.|last2 = Morgan  | title = Notes on Supersymmetry (following Joseph Bernstein) | booktitle = Quantum Fields and Strings: A Course for Mathematicians | volume = 1 | pages = 41–97 | publisher = American Mathematical Society | year = 1999 | isbn = 0-8218-2012-5}}\n\n*{{cite book | ref = harv| first1 = V. G. | last1 = Kac | authorlink1 = Victor Kac | first2 = C.| last2 = Martinez | first3 = E. | last3 = Zelmanov | authorlink3 = Efim Zelmanov | year = 2001 | title = Graded simple Jordan superalgebras of growth one | series = Memoirs of the AMS Series | volume = 711 | publisher = AMS Bookstore | isbn = 978-0-8218-2645-4 | url = https://books.google.com/books?id=aJHUCQAAQBAJ&printsec=frontcover&dq=bibliogroup:%22Graded+simple+Jordan+superalgebras+of+growth+one%22&hl=sv&sa=X&ved=0ahUKEwj9romE55TSAhVGLZoKHUqHCKAQ6AEIHDAA#v=onepage&q&f=false}}\n\n*{{cite book | last = Manin | first = Y. I. | authorlink = Yuri Manin| title = Gauge Field Theory and Complex Geometry | publisher = Springer | location = Berlin | year = 1997 | edition = (2nd ed.) | isbn = 3-540-61378-1}}\n\n*{{cite book|ref=harv|last=Varadarajan|first=V. S.|authorlink=V. S. Varadarajan|title=Supersymmetry for Mathematicians: An Introduction|year=2004|publisher=American Mathematical Society|isbn=978-0-8218-3574-6|url=https://books.google.com/books?id=sZ1-G4hQgIIC&pg=PA1&lpg=PA1&dq=supersymmetry+for+mathematicians&source=bl&ots=an8OHbS6p2&sig=MBKgS0GLd7-hF16lA1VSLtoWR0Q&hl=sv&sa=X&sqi=2&ved=0ahUKEwjJ9aDD0trRAhUkDJoKHZttDiUQ6AEISDAH#v=onepage&q=supersymmetry%20for%20mathematicians&f=false|series=Courant Lecture Notes in Mathematics|volume=11}}\n\n[[Category:Algebras]]\n[[Category:Super linear algebra]]"
    },
    {
      "title": "Supercommutative algebra",
      "url": "https://en.wikipedia.org/wiki/Supercommutative_algebra",
      "text": "{{Short description|Type of associative algebra that \"almost commutes\"}}{{refimprove|date=October 2014}}\nIn [[mathematics]], a '''supercommutative (associative) algebra''' is a [[superalgebra]] (i.e. a '''Z'''<sub>2</sub>-[[graded algebra]]) such that for any two [[homogeneous element]]s ''x'', ''y'' we have<ref name=Varadarajan>{{cite book|last1=Varadarajan|first1=V. S.|title=Supersymmetry for Mathematicians: An Introduction|publisher=American Mathematical Society|isbn=9780821883518|page=76}}</ref>\n\n:<math>yx = (-1)^{|x| |y|}xy ,</math>\n\nwhere |''x''| denotes the grade of the element and is 0 or 1 (in '''Z'''{{sub|2}}) according to whether the grade is even or odd, respectively.\n\nEquivalently, it is a superalgebra where the [[supercommutator]]\n\n:<math>[x,y] = xy - (-1)^{|x| |y|}yx</math>\n\nalways vanishes. Algebraic structures which supercommute in the above sense are sometimes referred to as '''skew-commutative associative algebras''' to emphasize the anti-commutation, or, to emphasize the grading, '''graded-commutative''' or, if the supercommutativity is understood, simply '''commutative'''.\n\nAny [[commutative algebra]] is a supercommutative algebra if given the trivial gradation (i.e. all elements are even). [[Grassmann algebra]]s (also known as [[exterior algebra]]s) are the most common examples of nontrivial supercommutative algebras.  The '''supercenter''' of any superalgebra is the set of elements that supercommute with all elements, and is a supercommutative algebra.\n\nThe [[even subalgebra]] of a supercommutative algebra is always a [[commutative algebra]]. That is, even elements always commute. Odd elements, on the other hand, always anticommute. That is,\n:<math>xy + yx = 0\\,</math>\nfor odd ''x'' and ''y''. In particular, the square of any odd element ''x'' vanishes whenever 2 is invertible:\n:<math>x^2 = 0 .</math>\nThus a commutative superalgebra (with 2 invertible and nonzero degree one component) always contains [[nilpotent]] elements.\n\nA '''Z'''-graded anticommutative algebra with the property that {{nowrap|1=''x''{{sup|2}} = 0}} for every element ''x'' of odd grade (irrespective of whether 2 is invertible) is called an [[alternating algebra]].\n\n==See also==\n*[[Graded-commutative ring]]\n*[[Lie superalgebra]]\n\n==References==\n{{reflist}}\n\n{{DEFAULTSORT:Supercommutative Algebra}}\n[[Category:Algebras]]\n[[Category:Super linear algebra]]"
    },
    {
      "title": "Symmetric algebra",
      "url": "https://en.wikipedia.org/wiki/Symmetric_algebra",
      "text": "{{Use American English|date = February 2019}}\n{{Short description|Algebra of all possible symmetric tensors over a vector space or ring module}}\n{{distinguish|text=the related notion of [[symmetric tensor]]s, which inhabit this algebra}}\nIn [[mathematics]], the '''symmetric algebra''' ''S''(''V'') (also denoted Sym(''V'')) on a [[vector space]] ''V'' over a [[field (mathematics)|field]] ''K'' is the [[Free object|free]] [[commutative]] [[unital algebra|unital]] [[associative algebra]] over ''K'' containing ''V''.\n\nIt corresponds to polynomials with indeterminates in ''V'', without choosing coordinates. The dual, ''S''(''V''<sup>∗</sup>) corresponds to polynomials ''on'' ''V''.\n\nA [[Frobenius algebra]] whose [[bilinear form]] is [[symmetric bilinear form|symmetric]] is also called a ''symmetric algebra'', but is not discussed here.\n\n==Construction==\nIt is possible to use the [[tensor algebra]] ''T''(''V'') to describe the symmetric algebra ''S''(''V''). In fact we pass from the tensor algebra to the symmetric algebra by forcing it to be commutative; if elements of ''V'' commute, then tensors in them must, so that we construct the symmetric algebra from the tensor algebra by taking the [[quotient associative algebra|quotient algebra]] of ''T''(''V'') by the [[ideal (ring theory)|ideal]] generated by the differences of products\n\n:<math>v\\otimes w - w\\otimes v.</math>\n\nfor all ''v'' and ''w'' in ''V''.\n\nIn effect, ''S''(''V'') is the same as the [[polynomial ring]] over ''K'' in indeterminates that are a [[Basis (linear algebra)|basis]] for ''V''.\n\n===Grading===\nJust as with a polynomial ring, there is a [[direct sum of modules|direct sum]] decomposition of ''S''(''V'') as a [[graded algebra]], into summands\n\n:''S<sup>k</sup>''(''V'')\n\nwhich consist of the linear span of the [[monomial]]s in vectors of ''V'' of degree ''k'', for ''k'' = 0, 1, 2, ... (with {{nowrap|1=''S''<sup>0</sup>(''V'') = ''K''}} and {{nowrap|1=''S''<sup>1</sup>(''V'') = ''V''}}). The ''K''-vector space ''S<sup>k</sup>''(''V'') is the '''''k''-th [[symmetric power]]''' of ''V''. (The case {{nowrap|1=''k'' = 2}}, for example, is the '''symmetric square''' and denoted Sym<sup>2</sup>(''V'').) It has a universal property with respect to symmetric [[multilinear]] operators defined on ''V''<sup>''k''</sup>.\n\nIn terms of the tensor algebra grading, ''S<sup>k</sup>''(''V'') is the quotient space of ''T<sup>k</sup>''(''V'') by the subspace generated by all differences of products\n\n:<math>v\\otimes w - w\\otimes v.</math>\n\nand products of these with other algebra elements.\n\n===Distinction from symmetric tensors===\nThe symmetric algebra and [[symmetric tensor]]s are easily confused: the symmetric algebra is a ''quotient'' of the tensor algebra, while the symmetric tensors are a ''subspace'' of the tensor algebra.\n\nBy expressing the symmetric algebra as a quotient, it inherits the [[universal property]] already present in the [[tensor algebra]]; that is, quotienting preserves the universal property. That is, the symmetric algebra is the \"most general\" symmetric algebra, in that any other symmetric algebra (defined by some symmetric product <math>F(V,W)</math>)  is homomorphic to the symmetric algebra.\n\nSymmetric tensors are defined as invariants: given the natural action of the [[symmetric group]] on the tensor algebra, the symmetric tensors are the subspace on which the symmetric group acts trivially. Note that under the tensor product, symmetric tensors are not a subalgebra: given linearly independent vectors ''v'' and ''w'', they are trivially symmetric 1-tensors, but {{nowrap|''v'' ⊗ ''w''}} is not a symmetric 2-tensor.\n\nThe grade 2 part of this distinction is the difference between [[symmetric bilinear form]]s (symmetric 2-tensors) and [[quadratic form]]s (elements of the symmetric square), as described in [[ε-quadratic form]]s.\n\nIn characteristic 0, symmetric tensors and the symmetric algebra can be identified. In any characteristic, there is a [[symmetrization]] map from the symmetric algebra to the symmetric tensors, given by:\n:<math>v_1\\cdots v_k \\mapsto \\sum_{\\sigma \\in S_k} v_{\\sigma(1)}\\otimes \\cdots \\otimes v_{\\sigma(k)}.</math>\nThe composition of this map with the inclusion of the symmetric tensors in the tensor algebra and the quotient to the symmetric algebra is multiplication by ''k''! on the ''k''th graded component of the symmetric tensors.\n\nThus in characteristic 0, the symmetrization map is an isomorphism of graded vector spaces, and one can identify symmetric tensors with elements of the symmetric algebra. One divides by ''k''! to make this a [[Section (category theory)|section]] of the quotient map:\n:<math>v_1\\cdots v_k \\mapsto \\frac{1}{k!} \\sum_{\\sigma \\in S_k} v_{\\sigma(1)}\\otimes \\cdots \\otimes v_{\\sigma(k)}.</math>\nFor instance, <math>vw \\mapsto \\frac{1}{2}(v\\otimes w + w \\otimes v)</math>.\n\nThis is related to the [[representation theory]] of the symmetric group: in characteristic 0, over an algebraically closed field, the [[group algebra]] is [[Semisimple algebra|semisimple]], so every representation splits into a direct sum of irreducible representations, and if {{nowrap|1=''T'' = ''S'' ⊕ ''V''}}, one can identify ''S'' as either a subspace of ''T'' or as the quotient ''T''/''V''.\n\n==Interpretation as polynomials==\n{{main|Ring of polynomial functions}}\n\nGiven a vector space ''V'', the polynomials on this space are ''S''(''V''<sup>∗</sup>), the symmetric algebra of the ''dual'' space: a polynomial on a space ''evaluates'' vectors on the space, via the pairing <math>S(V^*) \\times V \\to K</math>.\n\nFor instance, given the plane with a basis {{nowrap|{(1,0), (0,1)},}} the (homogeneous) linear polynomials on ''K''<sup>2</sup> are generated by the coordinate [[functional (mathematics)|functional]]s ''x'' and ''y''. These coordinates are [[covector]]s: given a vector, they evaluate to their coordinate, for instance:\n:<math>x(2,3) = 2, \\text{ and } y(2,3)=3.</math>\nGiven monomials of higher degree, these are elements of various symmetric powers, and a general polynomial is an element of the symmetric algebra. Without a choice of basis for the vector space, the same holds, but one has a polynomial algebra without choice of basis.\n\nConversely, the symmetric algebra of the vector space itself can be interpreted, not as polynomials ''on'' the vector space (since one cannot evaluate an element of the symmetric algebra of a vector space against a vector in that space: there is no pairing between ''S''(''V'') and ''V''), but polynomials ''in'' the vectors, such as {{nowrap|''v''<sup>2</sup> − ''vw'' + ''uv''}}.\n\n===Symmetric algebra of an affine space===\nOne can analogously construct the symmetric algebra on an [[affine space]] (or its dual, which corresponds to polynomials on that affine space). The key difference is that the symmetric algebra of an affine space is not a graded algebra, but a [[filtered algebra]]: one can determine the degree of a polynomial on an affine space, but not its homogeneous parts.\n\nFor instance, given a linear polynomial on a vector space, one can determine its constant part by evaluating at 0. On an affine space, there is no distinguished point, so one cannot do this (choosing a point turns an affine space into a vector space).\n\n==Universal properties==\nThe symmetric algebra on a vector space is a [[free object]] in the category of commutative unital associative algebras (in the sequel, \"commutative algebras\").\n\nFormally, the map that sends a vector space to its symmetric algebra is a [[functor]] from vector spaces over ''K'' to commutative algebras over ''K'', and is a ''free object'', meaning that it is [[Adjoint functors|left adjoint]] to the [[forgetful functor]] that sends a commutative algebra to its underlying vector space.\n\nThe unit of the adjunction is the map {{nowrap|''V'' → ''S''(''V'')}} that embeds a vector space in its symmetric algebra.\n\nCommutative algebras are a [[reflective subcategory]] of algebras; given an algebra ''A'', one can quotient out by its commutator ideal generated by {{nowrap|''ab'' – ''ba''}}, obtaining a commutative algebra, analogously to [[abelianization]] of a group. The construction of the symmetric algebra as a quotient of the tensor algebra is, as functors, a composition of the free algebra functor with this reflection.  The universal property can thus be seen as being inherited from the tensor algebra.\n\n==Analogy with exterior algebra==\nThe ''S''<sup>''k''</sup> are [[functor]]s comparable to the [[exterior power]]s; here, though, the [[dimension (linear algebra)|dimension]] grows with ''k''; it is given by\n:<math>\\operatorname{dim}(S^k(V)) = \\binom{n+k-1}{k}</math>\nwhere ''n'' is the dimension of ''V''.  This binomial coefficient is the number of ''n''-variable monomials of degree ''k''.\n\n==Module analog==\nThe construction of the symmetric algebra generalizes to the symmetric algebra ''S''(''M'') of a [[module (mathematics)|module]] ''M'' over a [[commutative ring]]. If ''M'' is a [[free module]] over the ring ''R'', then its symmetric algebra is isomorphic to the polynomial algebra over ''R'' whose indeterminates are a basis of ''M'', just like the symmetric algebra of a vector space.  However, if ''M'' is not free then ''S''(''M'') is more complicated.\n\n==As a Hopf algebra==\nThe symmetric algebra can be given the structure of a [[Hopf algebra]]. The article on the [[tensor algebra]] provides highly detailed mechanics showing how this is done.\n\n==As a universal enveloping algebra==\nThe symmetric algebra ''S''(''V'') is the [[universal enveloping algebra]] of an [[abelian Lie algebra]], i.e. one in which the Lie bracket is identically 0.\n\n==See also==\n* [[exterior algebra]], the [[alternating algebra]] analog\n* [[graded-symmetric algebra]], a common generalization of a symmetric algebra and an exterior algebra\n* [[Weyl algebra]], a [[quantum group|quantum deformation]] of the symmetric algebra by a [[symplectic form]]\n* [[Clifford algebra]], a [[quantum group|quantum deformation]] of the exterior algebra by a [[quadratic form]]\n\n==References==\n* {{citation|first = Nicolas|last=Bourbaki|authorlink=Nicolas Bourbaki | title = Elements of mathematics, Algebra I| publisher = Springer-Verlag | year = 1989|isbn=3-540-64243-9}}\n\n[[Category:Algebras]]\n[[Category:Multilinear algebra]]\n[[Category:Polynomials]]\n[[Category:Ring theory]]"
    },
    {
      "title": "Tensor algebra",
      "url": "https://en.wikipedia.org/wiki/Tensor_algebra",
      "text": "{{Short description|Universal construction in multilinear algebra}}In [[mathematics]], the '''tensor algebra''' of a [[vector space]] ''V'', denoted ''T''(''V'') or ''T''{{i sup|•}}(''V''), is the [[algebra over a field|algebra]] of [[tensor]]s on ''V'' (of any rank) with multiplication being the [[tensor product]]. It is the [[free algebra]] on ''V'', in the sense of being [[left adjoint]] to the [[forgetful functor]] from algebras to vector spaces: it is the \"most general\" algebra containing ''V'', in the sense of the corresponding [[universal property]] (see [[#Adjunction and universal property|below]]).\n\nThe tensor algebra is important because many other algebras arise as [[quotient associative algebra|quotient algebra]]s of ''T''(''V'').  These include the [[exterior algebra]], the [[symmetric algebra]], [[Clifford algebra]]s, the [[Weyl algebra]] and [[universal enveloping algebra]]s.\n\nThe tensor algebra also has two [[coalgebra]] structures; one simple one, which does not make it a bialgebra, but does lead to the concept of a [[cofree coalgebra]], and a more complicated one, which yields a [[bialgebra]], and can be extended by giving an antipode to create a [[Hopf algebra]] structure.\n\n''Note'': In this article, all algebras are assumed to be [[unital algebra|unital]] and [[associative algebra|associative]]. The unit is explicitly required to define the coproduct.\n\n==Construction==\nLet ''V'' be a [[vector space]] over a [[field (mathematics)|field]] ''K''. For any nonnegative [[integer]] ''k'', we define the '''''k''th tensor power''' of ''V'' to be the [[tensor product]] of ''V'' with itself ''k'' times:\n:<math>T^kV = V^{\\otimes k} = V\\otimes V \\otimes \\cdots \\otimes V.</math>\nThat is, ''T''<sup>''k''</sup>''V'' consists of all tensors on ''V'' of [[tensor order|order]] ''k''. By convention ''T''<sup>0</sup>''V'' is the [[ground field]] ''K'' (as a one-dimensional vector space over itself).\n\nWe then construct ''T''(''V'') as the [[direct sum of vector spaces|direct sum]] of ''T''<sup>''k''</sup>''V'' for ''k'' = 0,1,2,…\n:<math>T(V)= \\bigoplus_{k=0}^\\infty T^kV = K\\oplus V \\oplus (V\\otimes V) \\oplus (V\\otimes V\\otimes V) \\oplus \\cdots.</math>\nThe multiplication in ''T''(''V'') is determined by the canonical isomorphism\n:<math>T^kV \\otimes T^\\ell V \\to T^{k + \\ell}V</math>\ngiven by the tensor product, which is then extended by linearity to all of ''T''(''V''). This multiplication rule implies that the tensor algebra ''T''(''V'') is naturally a [[graded algebra]] with ''T''<sup>''k''</sup>''V'' serving as the grade-''k'' subspace. This grading can be extended to a '''Z''' grading by appending subspaces <math>T^{k}V=\\{0\\}</math> for negative integers ''k''.\n\nThe construction generalizes in straightforward manner to the tensor algebra of any [[module (mathematics)|module]] ''M'' over a [[commutative ring|''commutative'' ring]]. If ''R'' is a [[non-commutative ring]], one can still perform the construction for any ''R''-''R'' [[bimodule]] ''M''. (It does not work for ordinary ''R''-modules because the iterated tensor products cannot be formed.)\n\n==Adjunction and universal property==\nThe tensor algebra ''T''(''V'') is also called the '''[[free algebra]]''' on the vector space ''V'', and is functorial. As with other [[free object|free constructions]], the functor ''T'' is [[adjoint functor|left adjoint]] to some [[forgetful functor]]. In this case, it's the functor which sends each ''K''-algebra to its underlying vector space.\n\nExplicitly, the tensor algebra satisfies the following [[universal property]], which formally expresses the statement that it is the most general algebra containing ''V'':\n: Any [[linear transformation]] ''f'' : ''V'' &rarr; ''A'' from ''V'' to an algebra ''A'' over ''K'' can be uniquely extended to an [[algebra homomorphism]] from ''T''(''V'') to ''A'' as indicated by the following [[commutative diagram]]:\n\n[[Image:TensorAlgebra-01.png|center|Universal property of the tensor algebra]]\n\nHere ''i'' is the [[Inclusion map|canonical inclusion]] of ''V'' into ''T''(''V'') (the unit of the adjunction). One can, in fact, define the tensor algebra ''T''(''V'') as the unique algebra satisfying this property (specifically, it is unique [[up to]] a unique isomorphism), but one must still prove that an object satisfying this property exists.\n\nThe above universal property shows that the construction of the tensor algebra is ''functorial'' in nature. That is, ''T'' is a [[functor]] from '''''K''-Vect''', the [[category of vector spaces]] over ''K'', to '''''K''-Alg''', the category of ''K''-algebras. The functoriality of ''T'' means that any linear map from ''V'' to ''W'' extends uniquely to an algebra homomorphism from ''T''(''V'') to ''T''(''W'').\n\n==Non-commutative polynomials==\nIf ''V'' has finite dimension ''n'', another way of looking at the tensor algebra is as the \"algebra of polynomials over ''K'' in ''n'' non-commuting variables\". If we take [[basis vector]]s for ''V'', those become non-commuting variables (or [[Indeterminate (variable)|''indeterminates'']]) in ''T''(''V''), subject to no constraints beyond [[associativity]], the [[distributive law]] and ''K''-linearity.\n\nNote that the algebra of polynomials on ''V'' is not <math>T(V)</math>, but rather <math>T(V^*)</math>: a (homogeneous) linear function on ''V'' is an element of <math>V^*,</math> for example coordinates <math>x^1,\\dots,x^n</math> on a vector space are covectors, as they take in a vector and give out a scalar (the given coordinate of the vector).\n\n==Quotients==\n\nBecause of the generality of the tensor algebra, many other algebras of interest can be constructed by starting with the tensor algebra and then imposing certain relations on the generators, i.e. by constructing certain [[quotient associative algebra|quotient algebra]]s of ''T''(''V'').  Examples of this are the [[exterior algebra]], the [[symmetric algebra]], [[Clifford algebra]]s, the [[Weyl algebra]] and [[universal enveloping algebra]]s.\n\n==Coalgebra==\nThe tensor algebra has two different [[coalgebra]] structures. One is compatible with the tensor product, and thus can be extended to a [[bialgebra]], and can be further be extended with an antipode to a [[Hopf algebra]] structure. The other structure, although simpler, cannot be extended to a bialgebra. The first structure is developed immediately below; the second structure is given in the section on the [[cofree coalgebra]], further down.\n\nThe development provided below can be equally well applied to the [[exterior algebra]], using the wedge symbol <math>\\wedge</math> in place of the tensor symbol <math>\\otimes</math>; a sign must also be kept track of, when permuting elements of the exterior algebra. This correspondence also lasts through the definition of the bialgebra, and on to the definition of a Hopf algebra. That is, the exterior algebra can also be given a Hopf algebra structure.\n\nSimilarly, the [[symmetric algebra]] can also be given the structure of a Hopf algebra, in exactly the same fashion, by replacing everywhere the tensor product <math>\\otimes</math> by the symmetrized tensor product <math>\\otimes_\\mathrm{Sym}</math>, i.e. that product where <math>v\\otimes_\\mathrm{Sym} w = w\\otimes_\\mathrm{Sym} v.</math>\n\nIn each case, this is possible because the alternating product <math>\\wedge</math> and the symmetric product <math>\\otimes_\\mathrm{Sym}</math> obey the required consistency conditions for the definition of a bialgebra and Hopf algebra; this can be explicitly checked in the manner below. Whenever one has a product obeying these consistency conditions, the construction goes thorough; insofar as such a product gave rise to a quotient space, the quotient space inherits the Hopf algebra structure.\n\nIn the language of [[category theory]], one says that there is a [[functor]] {{math|''T''}} from the category of {{math|''K''}}-vector spaces to the category of {{math|''K''}}-associate algebras. But there is also a functor {{math|''Λ''}} taking vector spaces to the category of exterior algebras, and a functor {{math|''Sym''}} taking vector spaces to symmetric algebras. There is a [[natural transformation|natural map]] from {{math|''T''}} to each of these. Verifying that quotienting preserves the Hopf algebra structure is the same as verifying that the maps are indeed natural.\n\n=== Coproduct ===\nThe coalgebra is obtained by defining a [[coproduct]] or diagonal operator\n\n:<math>\\Delta: TV\\to TV\\boxtimes TV</math>\n\nHere, <math>TV</math> is used as a short-hand for <math>T(V)</math> to avoid an explosion of parenthesis. The <math>\\boxtimes</math> symbol is used to denote the \"external\" tensor product, needed for the definition of a coalgebra.  It is being used to distinguish it from the \"internal\" tensor product <math>\\otimes</math>, which is already \"taken\" and being used to denote multiplication in the tensor algebra (see the section ''Multiplication'', below, for further clarification on this issue). In order to avoid confusion between these two symbols, most texts will replace <math>\\otimes</math> by a plain dot, or even drop it altogether, with the understanding that it is implied from context. This then allows the <math>\\otimes</math> symbol to be used in place of the <math>\\boxtimes</math> symbol. This is not done below, and the two symbols are used independently and explicitly, so as to show the proper location of each.  The result is a bit more verbose, but should be easier to comprehend.\n\nThe definition of the operator <math>\\Delta</math> is most easily built up in stages, first by defining it for elements <math>v\\in V\\subset TV</math> and then by homomorphically extending it to the whole algebra.  A suitable choice for the coproduct is then\n\n:<math>\\Delta: v \\mapsto v\\boxtimes 1 + 1\\boxtimes v</math>\nand\n:<math>\\Delta: 1 \\mapsto 1 \\boxtimes 1</math>\n\nwhere <math>1\\in K=T^0V\\subset TV</math> is the unit of the field <math>K</math>. By linearity, one obviously has\n:<math>\\Delta(k)=k(1\\boxtimes 1)=k\\boxtimes 1=1\\boxtimes k</math>\n\nfor all <math>k\\in K.</math> It is straight-forward to verify that this definition satisfies the axioms of a coalgebra: that is, that\n:<math>(\\mathrm{id}_{TV} \\boxtimes \\Delta) \\circ \\Delta = (\\Delta \\boxtimes \\mathrm{id}_{TV}) \\circ \\Delta</math>\n\nwhere <math>\\mathrm{id}_{TV}: x\\mapsto x</math> is the identity map on <math>TV</math>.  Indeed, one gets\n:<math>\n((\\mathrm{id}_{TV} \\boxtimes \\Delta) \\circ \\Delta)(v) =\nv\\boxtimes 1 \\boxtimes 1 + 1\\boxtimes v \\boxtimes 1 + 1 \\boxtimes 1 \\boxtimes v\n</math>\nand likewise for the other side. At this point, one could invoke a lemma, and say that <math>\\Delta</math> extends trivially, by linearity, to all of <math>TV</math>, because <math>TV</math> is a [[free object]] and <math>V</math> is a [[generator (mathematics)|generator]] of the free algebra, and <math>\\Delta</math> is a homomorphism. However, it is insightful to provide explicit expressions. So, for <math>v\\otimes w \\in T^2V</math>, one has (by definition) the homomorphism\n\n:<math>\\Delta: v\\otimes w \\mapsto \\Delta(v)\\otimes \\Delta(w)</math>\nExpanding, one has\n:<math>\\begin{align} \\Delta (v\\otimes w) &= (v\\boxtimes 1 + 1\\boxtimes v) \\otimes (w\\boxtimes 1 + 1\\boxtimes w) \\\\\n&= (v\\otimes w) \\boxtimes 1 + v\\boxtimes w +  w\\boxtimes v + 1 \\boxtimes (v\\otimes w) \\end{align}</math>\n\nIn the above expansion, there is no need to ever write <math>1\\otimes v</math> as this is just plain-old scalar multiplication in the algebra; that is, one trivially has that <math>1\\otimes v = 1\\cdot v = v.</math>\n\nThe extension above preserves the algebra grading. That is,\n:<math>\\Delta: T^2V \\to \\bigoplus_{k=0}^2 T^kV \\boxtimes T^{(2-k)}V</math>\n\nContinuing in this fashion, one can obtain an explicit expression for the coproduct acting on a homogenous element of order ''m'':\n:<math>\n\\begin{align}\n\\Delta(v_1\\otimes\\cdots\\otimes v_m) &=\n\\Delta(v_1)\\otimes\\cdots\\otimes\\Delta(v_m) \\\\\n&= \\sum_{p=0}^m \\left(v_0\\otimes \\cdots \\otimes v_p\\right) \\;\\omega\n\\; \\left(v_{p+1}\\otimes \\cdots \\otimes v_m\\right) \\\\ \n&= \\sum_{p=0}^m \\; \\sum_{\\sigma\\in\\mathrm{Sh}(p,m-p+1)} \\;\n\\left(v_{\\sigma(0)}\\otimes\\dots\\otimes v_{\\sigma(p)}\\right) \\boxtimes \n\\left(v_{\\sigma(p+1)}\\otimes\\dots\\otimes v_{\\sigma(m)}\\right)\n\\end{align}\n</math>\nwhere the <math>\\omega</math> symbol, which should appear as ш, the sha, denotes the [[shuffle product]]. This is expressed in the second summation, which is taken over all [[(p,q) shuffle|(p,m-p+1)-shuffles]].  The above is written with a notational trick, to keep track of the field element 1: the trick is to write <math>v_0=1</math>, and this is shuffled into various locations during the expansion of the sum over shuffles.  The shuffle follows directly from the first axiom of a co-algebra: the relative order of the elements <math>v_k</math> is ''preserved'' in the riffle shuffle: the riffle shuffle merely splits the ordered sequence into two ordered sequences, one on the left, and one on the right. Any one given shuffle obeys\n:<math>\\sigma(0)< \\cdots < \\sigma(p)\\quad\\mbox{ and }\\quad \\sigma(p+1) < \\cdots < \\sigma(m)</math>\n\nAs before, the algebra grading is preserved:\n:<math>\\Delta: T^mV \\to \\bigoplus_{k=0}^m T^kV \\boxtimes T^{(m-k)}V</math>\n\n===Counit===\nThe counit <math>\\epsilon : TV \\to K</math> is given by the projection of the field component out from the algebra. This can be written as <math>\\epsilon: v\\mapsto 0 </math> for <math>v\\in V</math> and <math>\\epsilon: k\\mapsto k </math> for <math>k\\in K=T^0V</math>.  By homomorphism under the tensor product <math>\\otimes</math>, this extends to \n:<math>\\epsilon: x\\mapsto 0 </math>\nfor all <math>x\\in T^1V \\oplus T^2V\\oplus \\cdots</math>\nIt is a straight-forward matter to verify that this counit satisfies the needed axiom for the coalgebra:\n:<math>(\\mathrm{id} \\boxtimes \\epsilon) \\circ \\Delta = \\mathrm{id} = (\\epsilon \\boxtimes \\mathrm{id}) \\circ \\Delta.</math>\nWorking this explicitly, one has\n:<math>\n\\begin{align}\n((\\mathrm{id} \\boxtimes \\epsilon) \\circ \\Delta)(x)\n&=(\\mathrm{id} \\boxtimes \\epsilon)(1\\boxtimes x + x \\boxtimes 1) \\\\\n&=1\\boxtimes  \\epsilon(x) + x \\boxtimes  \\epsilon(1) \\\\\n&=0 + x \\boxtimes 1 \\\\\n&\\cong x\n\\end{align}\n</math>\nwhere, for the last step, one has made use of the isomorphism <math>TV\\boxtimes K \\cong TV</math>, as is appropriate for the defining axiom of the counit.\n\n== Bialgebra==\nA [[bialgebra]] defines both multiplication, and comultiplication, and requires them to be compatible.\n\n=== Multiplication ===\nMultiplication is given by an operator\n:<math>\\nabla: TV\\boxtimes TV\\to TV</math>\nwhich, in this case, was already given as the \"internal\" tensor product. That is,\n:<math>\\nabla: x\\boxtimes y\\mapsto x \\otimes y</math>\nThat is, <math>\\nabla(x\\boxtimes y) = x \\otimes y.</math> The above should make it clear why the <math>\\boxtimes</math> symbol needs to be used: the <math>\\otimes</math> was actually one and the same thing as <math>\\nabla</math>; and notational sloppiness here would lead to utter chaos.  To strengthen this: the tensor product <math>\\otimes</math> of the tensor algebra corresponds to the multiplication <math>\\nabla</math> used in the definition of an algebra, whereas the tensor product <math>\\boxtimes</math> is the one required in the definition of comultiplication in a coalgebra.  These two tensor products are ''not'' the same thing!\n\n=== Unit ===\nThe unit for the algebra\n:<math>\\eta: K\\to TV</math>\nis just the embedding, so that\n:<math>\\eta: k\\mapsto k</math>\nThat the unit is compatible with the tensor product <math>\\otimes</math> is \"trivial\": it is just part of the standard definition of the tensor product of vector spaces.  That is, <math>k\\otimes x = kx</math> for field element ''k'' and any <math>x\\in TV.</math>  More verbosely, the axioms for an [[associative algebra]] require the two homomorphisms (or commuting diagrams):\n:<math>\\nabla\\circ(\\eta \\boxtimes\\mathrm{id}_{TV}) = \\eta\\otimes \\mathrm{id}_{TV} = \\eta\\cdot \\mathrm{id}_{TV}</math>\non <math>K\\boxtimes TV</math>, and that symmetrically, on <math>TV\\boxtimes K</math>, that\n:<math>\\nabla\\circ(\\mathrm{id}_{TV}\\boxtimes\\eta) = \\mathrm{id}_{TV}\\otimes\\eta = \\mathrm{id}_{TV}\\cdot\\eta</math>\nwhere the right-hand side of these equations should be understood as the scalar product.\n\n=== Compatibility ===\nThe unit and counit, and multiplication and comultiplication, all have to satisfy compatibility conditions. It is straightforward to see that \n:<math>\\eta \\circ \\epsilon = \\mathrm{id}_K.</math>\nSimilarly, the unit is compatible with comultiplication:\n:<math>\\Delta \\circ \\eta = \\eta \\boxtimes \\eta \\cong \\eta</math>\nThe above requires the use of the isomorphism <math>K\\boxtimes K \\cong K</math> in order to work; without this, one loses linearity. Component-wise,\n:<math>(\\Delta \\circ \\eta)(k) = \\Delta(k) = k(1 \\boxtimes 1) \\cong k \\boxtimes k</math>\nwith the right-hand side making use of the isomorphism.\n\nMultiplication and the counit are compatible:\n:<math>(\\epsilon \\circ \\nabla)(x\\boxtimes y) = \\epsilon(x\\otimes y) = 0</math>\nwhenever ''x'' or ''y'' are not elements of <math>K</math>, and otherwise, one has scalar multiplication on the field: <math>k_1\\otimes k_2=k_1 k_2.</math>  The most difficult to verify is the compatibility of multiplication and comultiplication:\n:<math>\\Delta \\circ\\nabla = (\\nabla \\boxtimes \\nabla) \n\\circ (\\mathrm{id} \\boxtimes \\tau \\boxtimes \\mathrm{id}) \n\\circ (\\Delta \\boxtimes \\Delta)</math>\nwhere <math>\\tau(x\\boxtimes y)= y \\boxtimes x</math> exchanges elements. The compatibility condition only needs to be verified on <math>V\\subset TV</math>; the full compatibility follows as a homomorphic extension to all of <math>TV.</math> The verification is verbose but straight-forward; it is not given here, except for the final result:\n:<math>(\\Delta \\circ\\nabla)(v\\boxtimes w) = \\Delta(v\\otimes w)</math>\nFor <math>v,w\\in V,</math> an explicit expression for this was given in the coalgebra section, above.\n\n==Hopf algebra==\nThe [[Hopf algebra]] adds an antipode to the bialgebra axioms.  The antipode <math>S</math> on <math>k\\in K=T^0V</math> is given by\n:<math>S(k)=1</math>\nThis is sometimes called the \"anti-identity\". The antipode on <math>v\\in V=T^1V</math> is given by\n:<math>S(v)=-v</math>\nand on <math>v \\otimes w\\in T^2V</math> by\n:<math>S(v \\otimes w) = S(w) \\otimes S(v) = w\\otimes v</math>\nThis extends homomorphically to\n:<math>\n\\begin{align}\nS(v_1 \\otimes \\cdots \\otimes v_m) \n&= S(v_m) \\otimes\\cdots\\otimes S(v_1) \\\\\n&= (-1)^m v_m \\otimes\\cdots\\otimes v_1\n\\end{align}</math>\n\n=== Compatibility ===\nCompatibility of the antipode with multiplication and comultiplication requires that\n:<math>\\nabla \\circ (S \\boxtimes \\mathrm{id}) \\circ \\Delta\n= \\eta \\circ \\epsilon\n= \\nabla \\circ (\\mathrm{id} \\boxtimes S) \\circ \\Delta</math>\nThis is straight-forward to verify componentwise on <math>k\\in K</math>:\n:<math>\n\\begin{align}\n(\\nabla \\circ (S \\boxtimes \\mathrm{id}) \\circ \\Delta)(k)\n&= (\\nabla \\circ (S \\boxtimes \\mathrm{id})) (k\\boxtimes k) \\\\\n&= \\nabla(1 \\boxtimes k) \\\\\n&= 1 \\otimes k \\\\\n&= k\n\\end{align}</math>\nSimilarly, on <math>v\\in V</math>:\n:<math>\n\\begin{align}\n(\\nabla \\circ (S \\boxtimes \\mathrm{id}) \\circ \\Delta)(v)\n&= (\\nabla \\circ (S \\boxtimes \\mathrm{id})) (v\\boxtimes 1 + 1 \\boxtimes v) \\\\\n&= \\nabla(-v \\boxtimes 1 + 1 \\boxtimes v) \\\\\n&= -v \\otimes 1 + 1 \\otimes v \\\\\n&= -v + v\\\\\n&= 0\n\\end{align}</math>\nRecall that\n:<math>(\\eta \\circ \\epsilon)(k)=\\eta(k)=k</math>\nand that \n:<math>(\\eta \\circ \\epsilon)(x)=\\eta(0)=0</math>\nfor any <math>x\\in TV</math> that is ''not'' in <math>K.</math>\n\nOne may proceed in a similar manner, by homomorphism, verifying that the antipode inserts the appropriate cancellative signs in the shuffle, starting with the compatibility condition on <math>T^2V</math> and proceeding by induction.\n\n==Cofree coalgebra==\n{{main article|Cofree coalgebra}}\nOne may define a different coproduct on the tensor algebra, simpler than the one given above.  It is given by\n:<math>\\Delta(v_1 \\otimes \\dots \\otimes v_k) := \\sum_{j=0}^{k} (v_0 \\otimes \\dots \\otimes v_j) \\boxtimes (v_{j+1} \\otimes \\dots \\otimes v_{k+1})</math>\n\nHere, as before, one uses the notational trick <math>v_0=v_{k+1}=1\\in K</math> (recalling that <math>v\\otimes 1=v</math> trivially).\n\nThis coproduct gives rise to a coalgebra. It describes a coalgebra that is [[duality (linear algebra)|dual]] to the algebra structure on ''T''(''V''<sup>&lowast;</sup>), where ''V''<sup>&lowast;</sup> denotes the [[dual vector space]] of linear maps ''V'' → '''F'''. In the same way that the tensor algebra is a [[free algebra]], the corresponding coalgebra is termed (conilpotent) co-free.  With the usual product this is not a bialgebra. It ''can'' be turned into a bialgebra with the product <math>v_i\\cdot v_j=(i,j)v_{i+j}</math> where ''(i,j)'' denotes the binomial coefficient for <math>\\tbinom{i+j}{i}</math>. This bialgebra is known as the [[divided power structure|divided power Hopf algebra]].\n\nThe difference between this, and the other coalgebra is most easily seen in the <math>T^2V</math> term.  Here, one has that\n:<math>\\Delta(v\\otimes w) = 1\\boxtimes (v\\otimes w) + v \\boxtimes w + (v\\otimes w) \\boxtimes 1</math>\nfor <math>v,w\\in V</math>, which is clearly missing a shuffled term, as compared to before.\n\n==See also==\n*[[Braided vector space]]\n*[[Braided Hopf algebra]]\n*[[Monoidal category]]\n*[[Multilinear algebra]]\n*[[q:Stanisław Lem#Love and Tensor Algebra|Stanisław Lem's ''Love and Tensor Algebra'']]\n*[[Fock space]]\n\n==References==\n*{{cite book\n  | last = Bourbaki\n  | first = Nicolas\n  | title = Algebra I. Chapters 1-3\n  | url = https://books.google.com/books/about/Algebra.html?id=STS9aZ6F204C&redir_esc=y\n  | publisher = [[Springer-Verlag]]\n  | series = Elements of Mathematics\n  | year = 1989\n  | isbn = 3-540-64243-9\n}} ''(See Chapter 3 §5)''\n\n* {{citation | author=Serge Lang | authorlink=Serge Lang | title=Algebra | series=[[Graduate Texts in Mathematics]] | volume=211 | edition=3rd | publisher=[[Springer Verlag]] | year=2002 | isbn=978-0-387-95385-4 }}\n\n{{Tensors}}\n\n[[Category:Algebras]]\n[[Category:Multilinear algebra]]\n[[Category:Tensors]]\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Tensor product of algebras",
      "url": "https://en.wikipedia.org/wiki/Tensor_product_of_algebras",
      "text": "{{Short description|Tensor product of algebras over a field; itself another algebra}}In [[mathematics]], the [[tensor product]] of two [[algebra (ring theory)|algebras]] over a [[commutative ring]] ''R'' is also an ''R''-algebra. This gives the '''tensor product of algebras'''. When the ring is a field, the most common application of such products is to describe the [[tensor product of representations|product of algebra representations]].\n\n==Definition==\nLet ''R'' be a commutative ring and let ''A'' and ''B'' be [[associative algebra|''R''-algebras]]. Since ''A'' and ''B'' may both be regarded as [[module (mathematics)|''R''-module]]s, their [[tensor product of modules|tensor product]]\n:<math>A \\otimes_R B</math>\nis also an ''R''-module. The tensor product can be given the structure of a ring by defining the product on elements of the form {{nowrap|''a'' ⊗ ''b''}} by<ref>Kassel (1995), [{{Google books|plainurl=y|id=S1KE_pToY98C|page=32|text=we put an algebra structure on the tensor product}} p. 32].</ref>{{sfn|Lang|2002|pp=629-630}}\n:<math>(a_1\\otimes b_1)(a_2\\otimes b_2) = a_1 a_2\\otimes b_1b_2</math>\nand then extending by linearity to all of {{nowrap|''A'' ⊗<sub>''R''</sub> ''B''}}. This ring is an ''R''-algebra, associative and unital with identity element given by {{nowrap|1<sub>''A''</sub> ⊗ 1<sub>''B''</sub>}}.<ref>Kassel (1995), [{{Google books|plainurl=y|id=S1KE_pToY98C|page=32|text=Its unit is}} p. 32].</ref> where 1<sub>''A''</sub> and 1<sub>''B''</sub> are the identity elements of ''A'' and ''B''. If ''A'' and ''B'' are commutative, then the tensor product is commutative as well.\n\nThe tensor product turns the [[category (mathematics)|category]] of ''R''-algebras into a [[symmetric monoidal category]].{{citation needed|date=October 2015}}\n\n==Further properties==\nThere are natural homomorphisms of ''A'' and ''B'' to {{nowrap|''A''&thinsp;⊗<sub>''R''</sub>&thinsp;''B''}} given by<ref>Kassel (1995), [{{Google books|plainurl=y|id=S1KE_pToY98C|page=32|text=get algebra morphisms}} p. 32].</ref>\n:<math>a\\mapsto a\\otimes 1_B</math>\n:<math>b\\mapsto 1_A\\otimes b</math>\nThese maps make the tensor product the [[coproduct]] in the [[category of commutative algebras|category of commutative ''R''-algebras]]. The tensor product is ''not'' the coproduct in the category of all ''R''-algebras. There the coproduct is given by a more general [[free product of algebras]]. Nevertheless, the tensor product of non-commutative algebras can be described by a [[universal property]] similar to that of the coproduct:\n:<math>Hom(A\\otimes B,X) \\cong \\lbrace (f,g)\\in Hom(A,X)\\times Hom(B,X) \\mid \\forall a\\in A, b\\in B: [f(a),g(b)] = 0\\rbrace</math>\nThe [[natural isomorphism]] is given by identifying a morphism <math>\\phi:A\\otimes B\\to X</math> on the left hand side with the pair of morphisms <math>(f,g)</math> on the right hand side where <math>f(a):=\\phi(a\\otimes 1)</math> and similarly <math>g(b):=\\phi(1\\otimes b)</math>.\n\n==Applications==\nThe tensor product of commutative algebras is of constant use in [[algebraic geometry]]. For [[affine scheme]]s ''X'', ''Y'', ''Z'' with morphisms from ''X'' and ''Z'' to ''Y'', so ''X'' = Spec(''A''), ''Y'' = Spec(''B''), and ''Z'' = Spec(''C'') for some commutative rings ''A'',''B'',''C'', the [[fiber product of schemes|fiber product scheme]] is the affine scheme corresponding to the tensor product of algebras:\n:<math>X\\times_Y Z = \\operatorname{Spec}(A\\otimes_B C).</math>\nMore generally, the fiber product of schemes is defined by gluing together affine fiber products of this form.\n\n==Examples==\n{{see also|tensor product of modules#Examples}}\n* The tensor product can be used as a means of taking [[scheme-theoretic intersection|intersections]] of two subschemes in a [[Scheme (mathematics)|scheme]]: consider the <math>\\mathbb{C}[x,y]</math>-algebras <math>\\mathbb{C}[x,y]/f</math>, <math>\\mathbb{C}[x,y]/g</math>, then their tensor product is <math>\\mathbb{C}[x,y]/(f) \\otimes_{\\mathbb{C}[x,y]} \\mathbb{C}[x,y]/(g) \\cong \\mathbb{C}[x,y]/(f,g)</math>, which describes the intersection of the [[algebraic curve]]s ''f'' = 0 and ''g'' = 0 in the affine plane over '''C'''.\n* Tensor products can be used as a means of changing coefficients. For example, <math>\\mathbb{Z}[x,y]/(x^3 + 5x^2 + x - 1)\\otimes_\\mathbb{Z} \\mathbb{Z}/5 \\cong \\mathbb{Z}/5[x,y]/(x^3 + x - 1)</math> and <math>\\mathbb{Z}[x,y]/(f)\\otimes_\\mathbb{Z} \\mathbb{C} \\cong \\mathbb{C}[x,y]/(f)</math>.\n* Tensor products also can be used for taking [[Fiber product|products]] of affine schemes over a [[field (mathematics)|field]]. For example, <math>\\mathbb{C}[x_1,x_2]/(f(x)) \\otimes_\\mathbb{C} \\mathbb{C}[y_1,y_2]/(g(y))</math> is isomorphic to the algebra <math>\\mathbb{C}[x_1,x_2,y_1,y_2]/(f(x),g(y))</math> which corresponds to an affine surface in <math>\\mathbb{A}^4_\\mathbb{C}</math> if ''f'' and ''g'' are not zero.\n\n==See also==\n*[[Extension of scalars]]\n*[[Tensor product of modules]]\n*[[Tensor product of fields]]\n*[[Linearly disjoint]]\n*[[Multilinear subspace learning]]\n\n== Notes ==\n{{reflist|25em}}\n\n== References ==\n* {{Citation| last1=Kassel| first1=Christian| date=1995| title=Quantum groups| volume = 155| series=Graduate texts in mathematics | publisher=Springer| isbn= 978-0-387-94370-1 |ref=harv}}.\n* {{cite book |last=Lang |first=Serge |title=Algebra |series=Graduate Texts in Mathematics |volume=21 |publisher=Springer |year=2002 |origyear=first published in 1993 |ISBN=0-387-95385-X |ref=harv}}\n\n{{DEFAULTSORT:Tensor Product Of Algebras}}\n[[Category:Algebras]]\n[[Category:Ring theory]]\n[[Category:Commutative algebra]]\n[[Category:Multilinear algebra]]"
    },
    {
      "title": "Ternary commutator",
      "url": "https://en.wikipedia.org/wiki/Ternary_commutator",
      "text": "In [[mathematical physics]], the '''ternary commutator''' is an additional [[ternary operation]] on a [[triple system]] defined by\n:<math>[a,b,c] = abc-acb-bac+bca+cab-cba. \\, </math>\nAlso called the '''ternutator''' or '''alternating ternary sum''', it is a special case of the [[n-commutator|''n''-commutator]] for ''n'' = 3, whereas the 2-commutator is the ordinary [[commutator]].\n\n==Further reading==\n*{{Citation |last=Bremner |first=Murray R. |date=15 August 1998 |title=Identities for the Ternary Commutator |journal=Journal of Algebra |volume=206 |issue=2 |pages=615–623 |doi=10.1006/jabr.1998.7433 |url=http://math.usask.ca/~bremner/research/publications/Bitc.pdf |deadurl=yes |archiveurl=https://web.archive.org/web/20061002152039/http://math.usask.ca/~bremner/research/publications/Bitc.pdf |archivedate=2 October 2006 |df= }}\n*{{Citation |last=Bremner |first=Murray R. |last2=Ortega |first2=Juana Sánchez |date=25 October 2010 |title=The partially alternating ternary sum in an associative dialgebra |journal=Journal of Physics A: Mathematical and Theoretical |volume=43 |issue=56 |doi=10.1088/1751-8113/43/45/455215 |arxiv=1008.2721|bibcode=2010JPhA...43S5215B }}\n*{{Citation |last=Bremner |first=Murray R. |last2=Peresi |first2=Luiz A. |date=1 April 2006 |title=Ternary analogues of Lie and Malcev algebras |journal=Linear Algebra and its Applications |volume=414 |issue=1 |pages=1–18 |doi=10.1016/j.laa.2005.09.004 |url=http://math.usask.ca/~bremner/research/publications/BPtalma.pdf |deadurl=yes |archiveurl=https://web.archive.org/web/20061002152356/http://math.usask.ca/~bremner/research/publications/BPtalma.pdf |archivedate=2 October 2006 |df= }}\n*{{Citation |last=Bremner |first=Murray R. |last2=Peresi |first2=Luiz A. |date=26 July 2012 |title=Higher identities for the ternary commutator |arxiv=1207.6312|bibcode=2012JPhA...45X5201B }}\n*{{Citation |last=Devchand |first=Chandrashekar |last2=Fairlie |first2=David |last3=Nuyts |first3=Jean |last4=Weingart |first4=Gregor |date=6 November 2009 |title=Ternutator identities |journal=Journal of Physics A: Mathematical and Theoretical |volume=42 |issue=47 |doi=10.1088/1751-8113/42/47/475209 |arxiv=0908.1738|bibcode=2009JPhA...42U5209D }}\n*{{Citation |last=Nambu |first=Yoichiro |authorlink=Yoichiro Nambu |year=1973 |title=Generalized Hamiltonian Dynamics |journal=Physical Review D |volume=7 |issue=8 |pages=2405–2412 |doi=10.1103/PhysRevD.7.2405|bibcode=1973PhRvD...7.2405N }}\n\n[[Category:Algebras]]\n[[Category:Ternary operations]]\n\n{{abstract-algebra-stub}}"
    },
    {
      "title": "Topological algebra",
      "url": "https://en.wikipedia.org/wiki/Topological_algebra",
      "text": "In [[mathematics]], a '''topological algebra''' <math>A</math> is an [[algebra over a field|algebra]] and at the same time a [[topological space]], where the algebraic and the topological structures are coherent in a specified sense. \n\n==Definition==\nA '''topological algebra''' <math>A</math> over a [[topological field]] <math>K</math> is a [[topological vector space]] together with a bilinear multiplication \n\n:<math>\\cdot :A\\times A \\longrightarrow A</math>, \n:<math>(a,b)\\longmapsto a\\cdot b</math>\n\nthat turns <math>A</math> into an [[algebra over a field|algebra]] over <math>K</math> and is continuous in a definite sense. Usually (but not always<ref>See [[stereotype algebra]].</ref>) the ''continuity of the multiplication'' is expressed by one of the following two (non-equivalent) requirements: \n\n* ''joint continuity''{{sfn|Beckenstein|Narici|Suffel|1977}}: for each neighbourhood of zero <math>U\\subseteq A</math> there are neighbourhoods of zero <math>V\\subseteq A</math> and <math>W\\subseteq A</math> such that <math>V\\cdot W\\subseteq U</math> (in other words, this condition means that the multiplication is continuous as a map between topological spaces <math>A\\times A \\longrightarrow A</math>), or\n\n* ''separate continuity''{{sfn|Mallios|1986}}: for each element <math>a\\in A</math> and for each neighbourhood of zero <math>U\\subseteq A</math> there is a neighbourhood of zero <math>V\\subseteq A</math> such that <math>a\\cdot V\\subseteq U</math> and <math>V\\cdot a\\subseteq U</math>.\n\nIn the first case <math>A</math> is called a ''topological algebra with jointly continuous multiplication'', and in the second ''- with separately continuous multiplication''.\n\nA unital [[associative algebra|associative]] topological algebra is (sometimes) called a [[topological ring]].\n\n==History==\nThe term was coined by [[David van Dantzig]]; it appears in the title of his [[Thesis|doctoral dissertation]] (1931).\n\n== Examples ==\n:1. [[Fréchet algebra]]s are examples of associative topological algebras with jointly continuous multiplication.\n:2. [[Banach algebra]]s are special cases of [[Fréchet algebra]]s.\n:3. [[Stereotype algebra]]s are examples of associative topological algebras with separately continuous multiplication.\n\n== External links ==\n* {{nlab|id=topological+algebra|title=Topological algebra}}\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{cite book | last1=Beckenstein | first1=E. |  last2=Narici | first2=L. | last3=Suﬀel | first3=C. | title=Topological Algebras | publisher=North Holland | location=Amsterdam | year=1977 | isbn=9780080871356 | ref = harv}}\n\n* {{cite book | last=Mallios | first=A. | title=Topological Algebras | publisher=North Holland | location=Amsterdam | year=1986 | isbn=9780080872353 | ref = harv}}\n\n\n[[Category:Topological vector spaces]]\n[[Category:Topological algebra| ]]\n[[Category:Algebras]]\n\n{{topology-stub}}"
    },
    {
      "title": "Weyl algebra",
      "url": "https://en.wikipedia.org/wiki/Weyl_algebra",
      "text": "In [[abstract algebra]], the '''Weyl algebra''' is the [[ring (mathematics)|ring]] of [[differential operator]]s with [[polynomial]] coefficients (in one variable), namely expressions of the form\n\n:<math> f_m(X) \\partial_X^m + f_{m-1}(X) \\partial_X^{m-1} + \\cdots + f_1(X) \\partial_X + f_0(X).</math>\n\nMore precisely, let ''F'' be the underlying [[field (mathematics)|field]], and let ''F''[''X''] be the [[polynomial ring|ring of polynomials]] in one variable, ''X'', with coefficients in ''F''.  Then each ''f<sub>i</sub>'' lies in ''F''[''X''].\n\n''∂<sub>X</sub>'' is the [[derivative]] with respect to ''X''.  The algebra is generated by ''X'' and ''∂<sub>X</sub>'' .\n\nThe Weyl algebra is an example of a [[simple ring]] that is not a [[matrix ring]] over a [[division ring]].  It is also a noncommutative example of a [[domain (ring theory)|domain]], and an example of an [[Ore extension]].\n\nThe Weyl algebra is isomorphic to the [[quotient ring|quotient]] of the [[free algebra]] on two generators, ''X'' and ''Y'', by the [[ideal (ring theory)|ideal]] generated by the element\n:<math>YX - XY - 1~.</math>\n\nThe Weyl algebra is the first in an infinite family of algebras, also known as Weyl algebras.  The '''''n''-th Weyl algebra''', ''A<sub>n</sub>'', is the ring of differential operators with polynomial coefficients in ''n'' variables.  It is generated by ''X<sub>i</sub>'' and ''∂<sub>X<sub>i</sub></sub>'', {{nowrap|1=''i'' = 1, ..., ''n''}}.\n\nWeyl algebras are named after [[Hermann Weyl]], who introduced them to study the [[Werner Heisenberg|Heisenberg]] [[uncertainty principle]] in [[quantum mechanics]].  It is a [[quotient ring|quotient]] of the [[universal enveloping algebra]] of the [[Heisenberg algebra]], the [[Lie algebra]] of the [[Heisenberg group]], by setting the central element of\nthe Heisenberg algebra (namely [''X'',''Y'']) equal to the unit of the universal enveloping algebra (called 1 above).\n\nThe Weyl algebra is also referred to as the '''symplectic Clifford algebra'''.<ref name=\"helmstetter-2008-p12\">Jacques Helmstetter, Artibano Micali: ''Quadratic Mappings and Clifford Algebras'', Birkhäuser, 2008, {{ISBN|978-3-7643-8605-4}} [https://books.google.com/books?id=x_VfARQsSO8C&pg=PR12 p. xii]</ref><ref name=\"ablamowicz-Pxvi\">Rafał Abłamowicz: ''Clifford algebras: applications to mathematics, physics, and engineering'' (dedicated to Pertti Lounesto), Progress in Mathematical Physics, Birkhäuser Boston, 2004, {{ISBN|0-8176-3525-4}}. Foreword, [https://books.google.com/books?id=b6mbSCv_MHMC&pg=PR16 p. xvi]</ref><ref>Z. Oziewicz, Cz. Sitarczyk: ''Parallel treatment of Riemannian and symplectic Clifford algebras'', pp. 83–96. In: Artibano Micali, Roger Boudet, Jacques Helmstetter (eds.): ''Clifford algebras and their applications in mathematical physics'', Kluwer, 1989, {{ISBN|0-7923-1623-1}}, [https://books.google.com/books?id=FhU9QpPIscoC&pg=PA92 p. 92]</ref> Weyl algebras represent the same structure for symplectic [[bilinear form]]s that [[Clifford algebra]]s represent for non-degenerate symmetric bilinear forms.<ref name=\"helmstetter-2008-p12\"/>\n\n== Generators and relations ==\nOne may give an abstract construction of the algebras ''A<sub>n</sub>'' in terms of generators and relations. Start with an abstract [[vector space]] ''V'' (of dimension 2''n'') equipped with a [[symplectic form]] ''ω''. Define the Weyl algebra ''W''(''V'') to be\n\n:<math>W(V) := T(V) / (\\!( v \\otimes u - u \\otimes v - \\omega(v,u), \\text{ for } v,u \\in V )\\!),</math>\n\nwhere ''T''(''V'') is the [[tensor algebra]] on ''V'', and  the notation <math>(\\!( )\\!)</math> means \"the [[ideal (ring theory)|ideal]] generated by\".\n\nIn other words, ''W''(''V'') is the algebra generated by ''V'' subject only to the relation {{math|''vu'' − ''uv'' {{=}} ''ω''(''v'', ''u'')}}. Then, ''W''(''V'') is isomorphic to ''A<sub>n</sub>'' via the choice of a Darboux basis for {{mvar|ω}}.\n\n=== Quantization ===\nThe algebra ''W''(''V'') is a [[quantization (physics)|quantization]] of the [[symmetric algebra]] Sym(''V'').  If ''V'' is over a field of characteristic zero, then ''W''(''V'') is naturally isomorphic to the underlying vector space of the [[symmetric algebra]] Sym(''V'') equipped with a deformed product – called the Groenewold–[[Moyal product]] (considering the symmetric algebra to be polynomial functions on ''V''<sup>∗</sup>, where the variables span the vector space ''V'', and replacing ''iħ''  in the Moyal product formula with 1).\n\nThe isomorphism is given by the symmetrization map from Sym(''V'') to ''W''(''V'')\n:<math>a_1 \\cdots a_n \\mapsto \\frac{1}{n!} \\sum_{\\sigma \\in S_n} a_{\\sigma(1)} \\otimes \\cdots \\otimes a_{\\sigma(n)}~.</math>\n\nIf one prefers to have the ''iħ'' and work over the complex numbers, one could have instead defined the Weyl algebra above as generated by ''X''<sub>''i''</sub> and ''iħ∂<sub>X<sub>i</sub></sub>''  (as per [[quantum mechanics]] usage).\n\nThus, the Weyl algebra is a quantization of the symmetric algebra, which is essentially the same as the [[Moyal product|Moyal quantization]] (if for the latter one restricts to polynomial functions), but the former is in terms of generators and relations (considered to be differential operators) and the latter is in terms of a deformed multiplication.\n\nIn the case of [[exterior algebra]]s, the analogous quantization to the Weyl one is the [[Clifford algebra]], which is also referred to as the ''orthogonal Clifford algebra''.<ref name=\"ablamowicz-Pxvi\"/><ref>Z. Oziewicz, Cz. Sitarczyk: ''Parallel treatment of Riemannian and symplectic Clifford algebras'', pp. 83–96. In: Artibano Micali, Roger Boudet, Jacques Helmstetter (eds.): ''Clifford algebras and their applications in mathematical physics'', Kluwer, 1989, {{ISBN|0-7923-1623-1}}, [https://books.google.com/books?id=FhU9QpPIscoC&pg=PA83 p. 83]</ref>\n\n==Properties of the Weyl algebra==\n{{further|Stone–von Neumann theorem}}\nIn the case that the ground field {{mvar|F}} has characteristic zero, the ''n''th Weyl algebra is a [[simple ring|simple]] [[Noetherian ring|Noetherian]] [[domain (ring theory)|domain]].  It has [[global dimension]] ''n'', in contrast to the ring it deforms, Sym(''V''), which has global dimension 2''n''.\n\nIt has no finite-dimensional representations. Although this follows from simplicity, it can be more directly shown by taking the trace ''σ''(''X'') and ''σ''(''Y'') for some finite-dimensional representation ''σ'' (where {{nowrap|1=[''X'',''Y''] = 1}}).\n:<math> tr([\\sigma(X),\\sigma(Y)])=tr(1)~.</math>\nSince the trace of a commutator is zero, and the trace of the identity is the dimension of the matrix, the representation must be zero dimensional.\n\nIn fact, there are stronger statements than the absence of finite-dimensional representations.  To any finitely generated ''A<sub>n</sub>''-module ''M'', there is a corresponding subvariety Char(''M'') of {{nowrap|''V'' × ''V''<sup>∗</sup>}} called the 'characteristic variety'{{what|date=August 2016}} whose size roughly corresponds to the size{{what|date=August 2016}} of ''M'' (a finite-dimensional module would have zero-dimensional characteristic variety).  Then [[Bernstein's inequality (mathematical analysis)|Bernstein's inequality]] states that for ''M'' non-zero,\n:<math>\\dim(\\operatorname{char}(M))\\geq n</math>\nAn even stronger statement is [[Gabber's theorem]], which states that Char(''M'') is a [[Lagrangian submanifold|co-isotropic]] subvariety of {{nowrap|''V'' × ''V''<sup>∗</sup>}} for the natural symplectic form.\n\n===Positive characteristic===\nThe situation is considerably different in the case of a Weyl algebra over a field of [[characteristic (algebra)|characteristic]] {{nowrap|''p'' > 0}}.\n\nIn this case, for any element ''D'' of the Weyl algebra, the element ''D<sup>p</sup>'' is central, and so the Weyl algebra has a very large center.  In fact, it is a finitely generated module over its center; even more so, it is an [[Azumaya algebra]] over its center.  As a consequence, there are many finite-dimensional representations which are all built out of simple representations of dimension ''p''.\n\n== Generalizations ==\nFor more details about this quantization in the case ''n'' = 1 (and an extension using the [[Fourier transform]] to a class of integrable functions larger than the polynomial functions), see [[Wigner–Weyl transform]].\n\nWeyl algebras and Clifford algebras admit a further structure of a [[*-algebra]], and can be unified as even and odd terms of a [[superalgebra]], as discussed in [[CCR and CAR algebras]].\n\n=== Affine Varieties ===\nWeyl algebras also generalize in the case of algebraic varieties. Consider a polynomial ring\n:<math>R = \\frac{\\mathbb{C}[x_1,\\ldots,x_n]}{I} </math>\nthen a differential operator is defined as a composition <math>\\mathbb{C}</math>-linear derivations of <math>R</math>. This can be described explicitly as the quotient ring\n:<math> \\text{Diff}(R) = \\frac{\\{ D \\in A_n : D(I) \\subseteq I \\}}{ I\\cdot A_n}</math>\n\n\n==References==\n* M. Rausch de Traubenberg, M. J. Slupinski, A. Tanasa, ''[https://arxiv.org/abs/math/0504224 Finite-dimensional Lie subalgebras of the Weyl algebra]'', (2005) ''(Classifies subalgebras of the one-dimensional Weyl algebra over the complex numbers; shows relationship to [[SL(2,C)]])''\n* [[Tsit Yuen Lam]], ''A first course in noncommutative rings''. Volume 131 of [[Graduate texts in mathematics]]. 2ed. Springer, 2001. p.&nbsp;6. {{ISBN|978-0-387-95325-0}}\n* S. C. Coutinho, [http://www.maa.org/programs/maa-awards/writing-awards/the-many-avatars-of-a-simple-algebra ''The many avatars of a simple algebra'']. [[American Mathematical Monthly]], Vol. 104, (1997), pp.&nbsp;593–604\n* [https://link.springer.com/chapter/10.1007/978-0-8176-4875-6_10 Differential Operations on Grassmann Varieties] - Will Traves\n\n{{Reflist}}\n\n[[Category:Algebras]]\n[[Category:Differential operators]]\n[[Category:Ring theory]]"
    },
    {
      "title": "Banach algebra",
      "url": "https://en.wikipedia.org/wiki/Banach_algebra",
      "text": "In [[mathematics]], especially [[functional analysis]], a '''Banach algebra''', named after [[Stefan Banach]], is an [[associative algebra]] ''A'' over the [[real number|real]] or [[complex number|complex]] numbers (or over a [[nonarchimedean field|non-Archimedean]] complete [[normed field]]) that at the same time is also a [[Banach space]], i.e. a [[normed space]] and [[complete metric space|complete]] in the metric induced by the norm. The norm is required to satisfy\n\n:<math> \\forall x, y \\in A : \\|x \\, y\\| \\ \\leq  \\|x \\| \\, \\| y\\|. </math>\n\nThis ensures that the multiplication operation is [[continuous function (topology)|continuous]].\n\nA Banach algebra is called ''unital'' if it has an [[identity element]] for the multiplication whose norm is 1, and ''commutative'' if its multiplication is [[commutative]].\nAny Banach algebra <math>A</math> (whether it has an [[identity element]] or not) can be embedded isometrically into a unital Banach algebra <math>A_e</math> so as to form a closed ideal of <math>A_e</math>. Often one assumes ''a priori'' that the algebra under consideration is unital: for one can develop much of the theory by considering <math>A_e</math> and then applying the outcome in the original algebra. However, this is not the case all the time. For example, one cannot define all the trigonometric functions in a Banach algebra without identity.\n\nThe theory of real Banach algebras can be very different from the theory of complex Banach algebras. For example, the [[Spectrum (functional analysis)|spectrum]] of an element of a nontrivial complex Banach algebra can never be empty, whereas in a real Banach algebra it could be empty for some elements.\n\nBanach algebras can also be defined over fields of [[p-adic number]]s. This is part of [[p-adic analysis]].\n\n== Examples ==\nThe prototypical example of a Banach algebra is <math>C_0(X)</math>, the space of (complex-valued) continuous functions on a locally compact (Hausdorff) space that vanish at infinity. <math>C_0(X)</math> is unital if and only if ''X'' is compact. The complex conjugation being an involution, <math>C_0(X)</math> is in fact a [[C*-algebra]]. More generally, every C*-algebra is a Banach algebra.\n\n* The set of real (or complex) numbers is a Banach algebra with norm given by the [[absolute value]].\n* The set of all real or complex ''n''-by-''n'' [[matrix (mathematics)|matrices]] becomes a [[unital algebra|unital]] Banach algebra if we equip it with a sub-multiplicative [[matrix norm]].\n* Take the Banach space '''R'''<sup>''n''</sup>  (or '''C'''<sup>''n''</sup>) with norm ||''x''|| = max |''x''<sub>''i''</sub>| and define multiplication componentwise: (''x''<sub>1</sub>,...,''x''<sub>''n''</sub>)(''y''<sub>1</sub>,...,''y''<sub>''n''</sub>) = (''x''<sub>1</sub>''y''<sub>1</sub>,...,''x''<sub>''n''</sub>''y''<sub>''n''</sub>).\n* The [[quaternion]]s form a 4-dimensional real Banach algebra, with the norm being given by the absolute value of quaternions.\n* The algebra of all bounded real- or complex-valued functions defined on some set (with pointwise multiplication and the [[supremum]] norm) is a unital Banach algebra.\n* The algebra of all bounded [[continuous function (topology)|continuous]] real- or complex-valued functions on some [[locally compact space]] (again with pointwise operations and supremum norm) is a Banach algebra.\n* The algebra of all [[continuous function (topology)|continuous]] [[linear transformation|linear]] operators on a Banach space ''E'' (with functional composition as multiplication and the [[operator norm]] as norm) is a unital Banach algebra. The set of all [[compact operator]]s on E is a Banach algebra and closed ideal. It is without identity if {{math|dim ''E'' {{=}} ∞}}.<ref>{{harvnb|Conway|1990|loc=Example VII.1.8.}}</ref>\n* If ''G'' is a [[locally compact]] [[Hausdorff space|Hausdorff]] [[topological group]] and μ its [[Haar measure]], then the Banach space L<sup>1</sup>(''G'') of all μ-integrable functions on ''G'' becomes a Banach algebra under the [[convolution]] ''xy''(''g'') = ∫ ''x''(''h'') ''y''(''h''<sup>−1</sup>''g'') dμ(''h'') for ''x'', ''y'' in L<sup>1</sup>(''G'').<ref>{{harvnb|Conway|1990|loc=Example VII.1.9.}}</ref>\n* [[Uniform algebra]]: A Banach algebra that is a subalgebra of the complex algebra C(X) with the supremum norm and that contains the constants and separates the points of X (which must be a compact Hausdorff space).\n* [[Uniform algebra|Natural Banach function algebra]]: A uniform algebra all of whose characters are evaluations at points of X.\n* [[C*-algebra]]: A Banach algebra that is a closed *-subalgebra of the algebra of bounded operators on some [[Hilbert space]].\n* [[Measure algebra]]: A Banach algebra consisting of all [[Radon measure]]s on some [[locally compact group]], where the product of two measures is given by [[Convolution#Measures|convolution of measures]].<ref>{{harvnb|Conway|1990|loc=Example VII.1.9.}}</ref>\n\n== Counterexamples ==\nThe algebra of the [[quaternion]]s <math>\\H</math> is not a complex Banach algebra (for any norm on <math>\\H</math>), for if <math>\\mathcal A</math> is a complex Banach algebra that is also a [[division algebra]], then <math>\\mathcal A \\approx \\C</math> ([[Gelfand&ndash;Mazur theorem]]), since if <math>\\lambda \\in \\C</math> is a point in the non-empty<ref>{{harvnb|Conway|1990|loc=Theorem 7.3.6.}}</ref> [[Spectrum (functional analysis)|spectrum]] <math>\\sigma(a) \\subset \\C</math> of <math>a \\in \\mathcal A</math>, <math>a - \\lambda 1</math> is not invertible, hence <math>a - \\lambda 1 = 0</math> since <math>\\mathcal A</math> is a division algebra, whence <math>a = \\lambda 1</math><ref> {{harvnb|Conway|1990|loc=Corollary to theorem 8.1.}}</ref> (which also proves the Gelfand&ndash;Mazur theorem).\n\n== Properties ==\nSeveral [[list of functions|elementary functions]] which are defined via [[power series]] may be defined in any unital Banach algebra; examples include the [[exponential function]] and the [[trigonometric functions]], and more generally any [[entire function]]. (In particular, the exponential map can be used to define [[abstract index group]]s.) The formula for the [[geometric series]] remains valid in general unital Banach algebras. The [[binomial theorem]] also holds for two commuting elements of a Banach algebra.\n\nThe set of [[invertible element]]s in any unital Banach algebra is an [[open set]], and the inversion operation on this set is continuous, (and hence is a homeomorphism) so that it forms a [[topological group]] under multiplication.<ref>{{harvnb|Conway|1990|loc=Theorem VII.2.2.}}</ref>\n\nIf a Banach algebra has unit '''1''', then '''1''' cannot be a [[commutator (ring theory)|commutator]]; i.e., <math>xy - yx \\ne \\mathbf{1}</math>&thinsp; for any ''x'', ''y''&nbsp;∈&nbsp;''A''. This is because ''xy'' and ''yx'' have the same [[spectrum (functional analysis)|spectrum]] except possibly ''0''.\n\nThe various algebras of functions given in the examples above have very different properties from standard examples of algebras such as the reals. For example:\n\n* Every real Banach algebra which is a [[division algebra]] is isomorphic to the reals, the complexes, or the quaternions. Hence, the only complex Banach algebra which is a division algebra is the complexes. (This is known as the [[Gelfand–Mazur theorem]].)\n* Every unital real Banach algebra with no [[zero divisor]]s, and in which every [[principal ideal]] is [[closed set|closed]], is isomorphic to the reals, the complexes, or the quaternions.\n* Every commutative real unital [[Noetherian ring|Noetherian]] Banach algebra with no zero divisors is isomorphic to the real or complex numbers.\n* Every commutative real unital Noetherian Banach algebra (possibly having zero divisors) is finite-dimensional.\n* Permanently singular elements in Banach algebras are [[topological divisor of zero|topological divisors of zero]], ''i.e.'', considering extensions ''B'' of Banach algebras ''A'' some elements that are singular in the given algebra ''A'' have a multiplicative inverse element in a Banach algebra extension ''B''.  Topological divisors of zero in ''A'' are permanently singular in all Banach extension ''B'' of&nbsp;''A''.\n\n== Spectral theory ==\n{{main|Spectral theory}}\n\nUnital Banach algebras over the complex field provide a general setting to develop spectral theory. The ''spectrum'' of an element ''x''&nbsp;∈&nbsp;''A'', denoted by <math>\\sigma(x)</math>, consists of all those complex [[scalar (mathematics)|scalar]]s ''λ'' such that ''x''&nbsp;&minus;&nbsp;''λ'''''1''' is not invertible in ''A''.  The spectrum of any element ''x'' is a closed subset of the closed disc in '''C''' with radius ||''x''|| and center 0, and thus is  [[Compact space|compact]]. Moreover, the spectrum <math>\\sigma(x)</math> of an element ''x'' is [[non-empty]] and satisfies the [[spectral radius]] formula:\n\n:<math>\\sup \\{ |\\lambda| : \\lambda \\in \\sigma(x) \\} = \\lim_{n \\to \\infty} \\|x^n\\|^{1/n}.</math>\n\nGiven ''x''&nbsp;&isin;&nbsp;''A'', the [[holomorphic functional calculus]] allows to define ''ƒ''(''x'')&nbsp;∈ ''A'' for any function ''ƒ'' [[holomorphic function|holomorphic]] in a neighborhood of <math>\\sigma(x).</math>  Furthermore, the spectral mapping theorem holds:\n\n:<math>\\sigma(f(x)) = f(\\sigma(x)).</math><ref>{{harvnb|Takesaki|1979|loc=Proposition 2.8.}}</ref>\n\nWhen the Banach algebra ''A'' is the algebra L(''X'') of bounded linear operators on a complex Banach space ''X''&thinsp; (e.g., the algebra of square matrices), the notion of the spectrum in ''A'' coincides with the usual one in the operator theory. For ''ƒ''&nbsp;&isin; ''C''(''X'') (with a compact Hausdorff space&nbsp;''X''), one sees that:\n\n:<math>\\sigma(f) = \\{ f(t) : t \\in X \\}.</math>\n\nThe norm of a normal element ''x'' of a C*-algebra coincides with its spectral radius.  This generalizes an analogous fact for normal operators.\n\nLet ''A''&thinsp; be a complex unital Banach algebra in which every non-zero element ''x'' is invertible (a division algebra).  For every ''a''&nbsp;&isin; ''A'', there is ''λ''&nbsp;&isin; '''C''' such that\n''a''&nbsp;&minus;&nbsp;''λ'''''1''' is not invertible (because the spectrum of ''a'' is not empty) hence ''a''&nbsp;=&nbsp;''λ'''''1'''&nbsp;:  this algebra ''A'' is naturally isomorphic to '''C''' (the complex case of the Gelfand–Mazur theorem).\n\n== Ideals and characters ==\nLet ''A''&thinsp; be a unital ''commutative'' Banach algebra over '''C'''. Since ''A'' is then a commutative ring with unit, every non-invertible element of ''A'' belongs to some [[maximal ideal]] of ''A''. Since a maximal ideal <math>\\mathfrak m</math> in ''A'' is closed, <math>A / \\mathfrak m</math> is a Banach algebra that is a field, and it follows from the Gelfand–Mazur theorem that there is a bijection between the set of all maximal ideals of ''A'' and the set Δ(''A'') of all nonzero homomorphisms from ''A''&thinsp; to '''C'''. The set Δ(''A'') is called the \"[[structure space]]\" or \"character space\" of ''A'', and its members \"characters.\"\n\nA character χ is a linear functional on ''A'' which is at the same time multiplicative, χ(''ab'') = χ(''a'') χ(''b''), and satisfies ''χ''('''1''') = 1.  Every character is automatically continuous from ''A''&thinsp; to '''C''', since the kernel of a character is a maximal ideal, which is closed. Moreover, the norm (''i.e.'', operator norm) of a character is one. Equipped with the topology of pointwise convergence on ''A'' (''i.e.'', the topology induced by the weak-* topology of&nbsp;''A''<sup>∗</sup>), the character space, Δ(''A''), is a Hausdorff compact space.\n\nFor any ''x'' ∈ ''A'',\n\n:<math>\\sigma(x) = \\sigma(\\hat x)</math>\n\nwhere <math>\\hat x</math> is the [[Gelfand representation]] of ''x'' defined as follows: <math>\\hat x</math> is the continuous function from Δ(''A'') to '''C''' given by <math>\\hat x(\\chi) = \\chi(x).</math>&thinsp;  The spectrum of <math>\\hat x,</math> in the formula above, is the spectrum as element of the algebra ''C''(Δ(''A'')) of complex continuous functions on the compact space Δ(''A'').  Explicitly,\n\n:<math>\\sigma(\\hat x) = \\{ \\chi(x) : \\chi \\in \\Delta(A) \\}</math>.\n\nAs an algebra, a unital commutative Banach algebra is [[semisimple algebra|semisimple]] (i.e., its [[Jacobson radical]] is zero) if and only if its Gelfand representation has trivial kernel. An important example of such an algebra is a commutative C*-algebra. In fact, when ''A'' is a commutative unital C*-algebra, the Gelfand representation is then an isometric *-isomorphism between ''A'' and  ''C''(Δ(''A'')) .<ref group=nb>Proof: Since every element of a commutative C*-algebra is normal, the Gelfand representation is isometric; in particular, it is injective and its image is closed. But the image of the Gelfand representation is dense by the [[Stone-Weierstrass theorem]].</ref>\n\n== See also ==\n* [[Operator algebra]]\n* [[Shilov boundary]]\n* [[Automatic continuity]]\n* [[Kaplansky's conjecture]]\n* [[Approximate identity]]\n\n==Remarks==\n{{Reflist|group=nb}}\n\n==Notes==\n{{Reflist}}\n\n==References==\n* {{cite book|ref=harv|first=B|last=Bollobás|authorlink=Béla Bollobás|title=Linear Analysis|publisher=Cambridge University Press|year=1990|isbn=0-521-38729-9}}\n* {{cite book|ref=harv|first1=F. F.|last1=Bonsall|authorlink1=Frank Bonsall|first2=J.|last2=Duncan|title=Complete Normed Algebras|publisher=Springer-Verlag|location=New York|year=1973|isbn=0-387-06386-2}}\n* {{cite book|ref=harv|last=Conway|first=J. B.|authorlink=John B. Conway|title=A Course in Functional Analysis|year=1990|series=Graduate Texts in Mathematics|volume=96|publisher=[[Springer Verlag]]|isbn=0-387-97245-5}}\n* {{cite book|ref=harv|first1=H. G.|last1=Dales|first2=P.|last2=Aeina|first3=J|last3=Eschmeier|first4=K.|last4=Laursen|first5=G. A.|last5=Willis|title=Introduction to Banach Algebras, Operators and Harmonic Analysis|publisher=Cambridge University Press|year=2003|isbn=0-521-53584-0}}\n* {{cite book|ref=harv|first=R. D.|last=Mosak|title=Banach algebras|series=Chicago Lectures in Mathematics|year=1975|publisher=University of Chicago Press)|isbn=0-226-54203-3}}\n*{{cite book|ref=harv|last=Takesaki|first=M.|authorlink=Masamichi Takesaki|title=Theory of Operator Algebras I|year=1979|edition=1st|series=Encyclopaedia of Mathematical Sciences|volume=124|publisher=Springer-Verlag|location=Berlin Heidelberg|issn=0938-0396|isbn=978-3-540-42248-8}}\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Banach Algebra}}\n[[Category:Banach algebras| ]]\n[[Category:Fourier analysis]]\n[[Category:Science and technology in Poland]]"
    },
    {
      "title": "Abstract index group",
      "url": "https://en.wikipedia.org/wiki/Abstract_index_group",
      "text": "In [[operator theory]], every [[Banach algebra]] can be associated with a group called its '''abstract index group'''. \n\n== Definition ==\nLet ''A'' be a Banach algebra and ''G'' the group of invertible elements in ''A''. The set ''G'' is open and a [[topological group]]. Consider the [[identity component]] \n\n:''G''<sub>0</sub>,\n\nor in other words the [[connected space|connected component]] containing the identity 1 of ''A''; ''G''<sub>0</sub> is a [[normal subgroup]] of ''G''. The [[quotient group]] \n\n:Λ<sub>''A''</sub> = ''G''/''G''<sub>0</sub> \n\nis the '''abstract index group''' of ''A''. Because ''G''<sub>0</sub>, being the component of an open set, is both open and closed in ''G'', the index group is a [[discrete group]].\n\n== Examples ==\n\nLet ''L''(''H'') be the Banach algebra of bounded operators on a Hilbert space. The set of invertible elements in ''L''(''H'') is path connected. Therefore, Λ<sub>''L''(''H'')</sub> is the trivial group.\n\nLet '''T''' denote the unit circle in the complex plane. The algebra ''C''('''T''') of continuous functions from '''T''' to the [[complex number]]s is a Banach algebra, with the topology of uniform convergence. A function in ''C''('''T''') is invertible (meaning that it has a [[pointwise]] [[multiplicative inverse]], not that it is an [[invertible function]]) if it does not map any element of '''T''' to zero. The group ''G''<sub>0</sub> consists of elements [[homotopic]], in ''G'', to the identity in ''G'', the constant function '''1'''. One can choose the functions  ''f<sub>n</sub>''(''z'') = ''z<sup>n</sup>'' as representatives in G of distinct homotopy classes of maps '''T'''→'''T'''. Thus the index group Λ<sub>''C''('''T''')</sub> is the set of homotopy classes, indexed by the [[winding number]] of its members. Thus Λ<sub>''C''('''T''')</sub> is isomorphic to the [[fundamental group]] of '''T'''. It is a countable discrete group.\n\nThe [[Calkin algebra]] ''K'' is the quotient [[C*-algebra]] of ''L''(''H'') with respect to the [[compact operator on Hilbert space|compact operators]]. Suppose π is the quotient map. By [[Atkinson's theorem]], an invertible elements in ''K'' is of the form π(''T'') where ''T'' is a [[Fredholm operator]]s. The index group Λ<sub>''K''</sub> is again a countable discrete group. In fact, Λ<sub>''K''</sub> is isomorphic to the additive group of integers '''Z''', via the [[Fredholm index]]. In other words, for Fredholm operators, the two notions of index coincide.\n\n==References==\n* [[Kehe Zhu|Zhu, Kehe]] (1993). ''An Introduction to Operator Algebras'', CRC Press, Boca Raton, LA, {{OCLC|27680761}}\n\n[[Category:Operator theory]]\n[[Category:Banach algebras]]\n[[Category:Discrete groups]]"
    },
    {
      "title": "Amenable Banach algebra",
      "url": "https://en.wikipedia.org/wiki/Amenable_Banach_algebra",
      "text": "A [[Banach algebra]], ''A'',  is '''amenable''' if all [[bounded linear map|bounded]] [[Differential algebra|derivation]]s from ''A'' into [[dual module|dual]] [[Banach module|Banach ''A''-bimodules]] are [[inner derivation|inner]] (that is of the form <math>a\\mapsto a.x-x.a</math> for some <math>x</math> in the dual module).\n\nAn equivalent characterization is that ''A'' is amenable if and only if it has a [[virtual diagonal]].\n\n==Examples==\n* If ''A'' is a [[group algebra]] <math>L^1(G)</math> for some [[locally compact group]] ''G'' then ''A'' is amenable if and only if ''G'' is [[amenable group|amenable]].\n* If ''A'' is a [[C*-algebra]] then ''A'' is amenable if and only if it is [[nuclear C*-algebra|nuclear]].\n* If ''A'' is a [[uniform algebra]] on a [[compact space|compact]] [[Hausdorff space]] then ''A'' is amenable if and only if it is trivial (i.e. the algebra ''C(X)'' of all [[continuous function|continuous]] [[complex number|complex]] [[function (mathematics)|functions]] on ''X'').\n* If ''A'' is amenable and there is a continuous algebra homomorphism <math>\\theta</math> from ''A'' to another Banach algebra, then the closure of <math>\\overline{\\theta(A)}</math> is amenable.\n\n==References==\n* F.F. Bonsall, J. Duncan, \"Complete normed algebras\", Springer-Verlag (1973).\n* H.G. Dales, \"Banach algebras and automatic continuity\", Oxford University Press (2001).\n* B.E. Johnson, \"Cohomology in Banach algebras\", Memoirs of the AMS '''127''' (1972).\n* J.-P. Pier, \"Amenable Banach algebras\", Longman Scientific and Technical (1988).\n\n{{Mathanalysis-stub}}\n\n[[Category:Banach algebras]]"
    },
    {
      "title": "Approximate identity",
      "url": "https://en.wikipedia.org/wiki/Approximate_identity",
      "text": "{{About|the Banach algebra concept||Approximation to the identity (disambiguation){{!}}Approximation to the identity}}\nIn [[mathematics]], particularly in [[functional analysis]] and [[ring theory]], an approximate identity is a [[net (mathematics)|net]] in a [[Banach algebra]] or [[ring (mathematics)|ring]] (generally without an identity) that acts as a substitute for an identity element.\n\n== Definition ==\n\nA '''right approximate identity''' in a Banach algebra ''A'' is a net <math>\\{\\,e_\\lambda \\colon \\lambda \\in \\Lambda\\,\\}</math> such that for every element ''a'' of ''A'', <math>\\lim_{\\lambda\\in\\Lambda}\\lVert ae_\\lambda - a \\rVert = 0.</math> Similarly, a '''left approximate identity''' in a Banach algebra ''A'' is a net <math>\\{\\,e_\\lambda \\colon \\lambda \\in \\Lambda\\,\\}</math> such that for every element ''a'' of ''A'', <math>\\lim_{\\lambda\\in\\Lambda}\\lVert e_\\lambda a - a \\rVert = 0.</math> An '''approximate identity''' is a net which is both a right approximate identity and a left approximate identity.\n\n== C*-algebras ==\n\nFor [[C*-algebra]]s, a right (or left) approximate identity consisting of [[self-adjoint]] elements is the same as an approximate identity. The net of all positive elements in ''A'' of norm &le; 1 with its natural order is an approximate identity for any C*-algebra. This is called the '''canonical approximate identity''' of a C*-algebra. Approximate identities are not unique. For example, for compact operators acting on a Hilbert space, the net consisting of finite rank projections would be another approximate identity.\n\nIf an approximate identity is a [[sequence (mathematics)|sequence]], we call it a '''sequential approximate identity''' and a C*-algebra with a sequential approximate identity is called '''&sigma;-unital'''. Every [[separable space|separable]] C*-algebra is &sigma;-unital, though the converse is false. A commutative C*-algebra is &sigma;-unital if and only if its [[spectrum of a C*-algebra|spectrum]] is [[&sigma;-compact]]. In general, a C*-algebra ''A'' is &sigma;-unital if and only if ''A'' contains a strictly positive element, i.e. there exists ''h'' in ''A''<sub>+</sub> such that the [[hereditary C*-subalgebra]] generated by ''h'' is ''A''.\n\nOne sometimes considers approximate identities consisting of specific types of elements. For example, a C*-algebra has [[Real rank (C*-algebras)#Real rank zero|real rank zero]] if and only if every hereditary C*-subalgebra has an approximate identity consisting of projections. This was known as property (HP) in earlier literature.\n\n== Convolution algebras ==\n\nAn approximate identity in a [[convolution]] algebra plays the same role as a sequence of function approximations to the [[Dirac delta function]] (which is the identity element for convolution). For example, the [[Fejér kernel]]s of [[Fourier series]] theory give rise to an approximate identity.\n\n== Rings ==\n\nIn ring theory, an approximate identity is defined in a similar way, except that the ring is given the discrete topology so that ''a''=''ae''<sub>λ</sub> for some λ.\n\nA module over a ring with approximate identity is called '''non-degenerate''' if for every ''m'' in the module there is some λ with ''m''=''me''<sub>λ</sub>.\n\n== See also ==\n* [[Mollifier]]\n* [[Nascent delta function]]\n* [[Summability kernel]]\n\n[[Category:Banach algebras]]"
    },
    {
      "title": "Banach *-algebra",
      "url": "https://en.wikipedia.org/wiki/Banach_%2A-algebra",
      "text": "A '''Banach *-algebra''' ''A'' is a [[Banach algebra]] over the field of [[complex number]]s, together with a map * : ''A'' → ''A'', called ''[[Involution (mathematics)|involution]]'', that has the following properties:\n# (''x'' + ''y'')* = ''x''* + ''y''* for all ''x'', ''y'' in ''A''.\n# <math>(\\lambda x)^* = \\bar{\\lambda}x^*</math> for every λ in '''C''' and every ''x'' in ''A''; here, <math>\\bar{\\lambda}</math> denotes the complex conjugate of λ.\n# (''xy'')* = ''y''* ''x''* for all ''x'', ''y'' in ''A''.\n# (''x''*)* = ''x'' for all ''x'' in ''A''.\n\nIn other words, a Banach *-algebra is a Banach algebra over <math>\\mathbb{C}</math> which is also a [[*-algebra]].\n\nIn most natural examples, one also has that the involution is [[isometry|isometric]], i.e.\n* ||''x''*|| = ||''x''||,\nSome authors include this isometric property in the definition of a Banach *-algebra.\n\n==See also==\n*[[Algebra over a field]]\n*[[Associative algebra]]\n*[[*-algebra]]\n*[[C*-algebra]].\n\n{{DEFAULTSORT:Banach algebra}}\n[[Category:Banach algebras]]"
    },
    {
      "title": "Banach algebra cohomology",
      "url": "https://en.wikipedia.org/wiki/Banach_algebra_cohomology",
      "text": "In [[mathematics]], '''Banach algebra cohomology''' of a [[Banach algebra]] with coefficients in a bimodule is a [[cohomology]] theory defined in a similar way to [[Hochschild cohomology]] of an [[abstract algebra]], except that one takes the topology into account so that all cochains and so on are continuous.\n\n==References==\n\n*{{Citation | last1=Johnson | first1=Barry Edward | title=Cohomology in Banach algebras | url=https://books.google.com/books?id=WgYuKl1Y340C | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Memoirs of the American Mathematical Society | isbn=978-0-8218-1827-5 | mr=0374934 | year=1972 | volume=127}}\n*{{Citation | last1=Helemskii | first1=Alexander Ya. | title=The homology of Banach and topological algebras | origyear=1986 | url=https://books.google.com/books?id=0897Z7xv_ksC | publisher=Kluwer Academic Publishers Group | location=Dordrecht | series=Mathematics and its Applications (Soviet Series) | isbn=978-0-7923-0217-9 | mr=1093462 | year=1989 | volume=41}}\n*{{eom|id=c/c023120|first=A.Ya. |last=Khelemskii|title=Cohomology of Banach algebras}}\n\n[[Category:Homological algebra]]\n[[Category:Banach algebras]]"
    },
    {
      "title": "Banach function algebra",
      "url": "https://en.wikipedia.org/wiki/Banach_function_algebra",
      "text": "In [[functional analysis]] a '''Banach function algebra''' on a [[compact space|compact]] [[Hausdorff space]] ''X'' is [[unital algebra|unital]] [[subalgebra]], ''A'' of the [[commutative]] [[C*-algebra]]  ''C(X)'' of all [[continuous function|continuous]], [[complex number|complex]] valued functions from ''X'', together with a norm on ''A'' which makes it a [[Banach algebra]].\n\nA function algebra is said to vanish at a point p if f(p) = 0 for all <math> (f\\in A) </math>. A function algebra [[separating set|separates points]] if for each distinct pair of points <math> (p,q \\in X) </math>, there is a function <math> (f\\in A) </math> such that <math> f(p) \\neq f(q) </math>.\n\nFor every <math>x\\in X</math> define <math>\\varepsilon_x(f)=f(x)\\ (f\\in A)</math>. Then <math>\\varepsilon_x</math>\nis a non-zero homomorphism (character) on <math>A</math>.\n\n'''Theorem:''' A Banach function algebra is [[semisimple algebra|semisimple]] (that is its [[Jacobson radical]] is equal to zero) and  each commutative [[unital ring|unital]], semisimple Banach algebra is [[isomorphic]] (via the [[Gelfand transform]]) to a Banach function algebra on its [[character space]] (the space of algebra homomorphisms from ''A'' into the complex numbers given the [[relative topology|relative]] [[weak* topology]]).\n\nIf the norm on <math>A</math> is the uniform norm (or sup-norm) on <math>X</math>, then <math>A</math> is called\na '''uniform algebra'''. Uniform algebras are an important special case of Banach function algebras.\n==References==\n* [[Andrew Browder]] (1969) ''Introduction to Function Algebras'', [[W. A. Benjamin]]\n* H.G. Dales (2000) ''Banach Algebras and Automatic Continuity'', [[London Mathematical Society]] Monographs 24, [[Clarendon Press]] {{ISBN|0-19-850013-0}}\n* [[Graham Allan]] & H. Garth Dales (2011) ''Introduction to Banach Spaces and Algebras'', [[Oxford University Press]] {{ISBN|978-0-19-920654-4}}\n\n{{Mathanalysis-stub}}\n[[Category:Banach algebras]]"
    },
    {
      "title": "Cohen–Hewitt factorization theorem",
      "url": "https://en.wikipedia.org/wiki/Cohen%E2%80%93Hewitt_factorization_theorem",
      "text": "In [[mathematics]], the '''Cohen–Hewitt factorization theorem''' states that if <math> V </math> is a [[left module]] over a [[Banach algebra]] <math> B </math> with a left approximate unit <math> (u_{i})_{i \\in I} </math>, then an element <math> v </math> of <math> V </math> can be factorized as a product <math> v = b w </math> (for some <math> b \\in B </math> and <math> w \\in V </math>) whenever <math> \\displaystyle \\lim_{i \\in I} u_{i} v = v </math>. The theorem was introduced by {{harvs|txt|authorlink=Paul Cohen (mathematician)|last=Cohen|first=Paul|year=1959}} and {{harvs|txt|last=Hewitt|first=Edwin|authorlink=Edwin Hewitt|year=1964}}.\n\n==References==\n*{{citation|mr = 0104982\n|last = Cohen|first = Paul J.|authorlink = Paul Cohen (mathematician)\n|title = Factorization in group algebras\n|journal = [[Duke Mathematical Journal]]|volume = 26|year = 1959|pages = 199–205|doi = 10.1215/s0012-7094-59-02620-1}}\n*{{citation|mr = 0187016\n|last = Hewitt|first = Edwin|authorlink = Edwin Hewitt\n|title = The ranges of certain convolution operators\n|journal = Mathematica Scandinavica|volume = 15|year = 1964|pages = 147–155}}\n\n{{DEFAULTSORT:Cohen-Hewitt factorization theorem}}\n[[Category:Banach algebras]]\n[[Category:Theorems in functional analysis]]\n\n{{analysis-stub}}"
    },
    {
      "title": "Corona theorem",
      "url": "https://en.wikipedia.org/wiki/Corona_theorem",
      "text": "In [[mathematics]], the '''corona theorem''' is a result about the [[spectrum of a commutative Banach algebra|spectrum]] of the [[Bounded function|bounded]] [[holomorphic function]]s on the [[open unit disc]],  conjectured by {{harvtxt|Kakutani|1941}} and proved by  {{harvs|authorlink=Lennart Carleson|first=Lennart|last=Carleson|year=1962|txt=yes}}.\n\nThe commutative [[Banach algebra]] and [[Hardy space]] ''H''<sup>&infin;</sup> consists of the bounded [[holomorphic function]]s on the [[open unit disc]] ''D''. Its [[spectrum of a commutative Banach algebra|spectrum]] ''S'' (the closed [[maximal ideal]]s) contains ''D'' as an open subspace because for each ''z'' in ''D'' there is a  [[maximal ideal]] consisting of functions ''f'' with\n\n:''f''(''z'') = 0.\n\nThe subspace ''D'' cannot make up the entire spectrum ''S'', essentially because the spectrum is a [[compact space]] and ''D'' is not. The complement of the closure of ''D'' in ''S'' was called the '''corona''' by {{harvtxt|Newman|1959}}, and the corona theorem states that the corona is empty, or in other words the open unit disc ''D'' is dense in the spectrum. A more elementary formulation is that elements ''f''<sub>1</sub>,...,''f''<sub>''n''</sub> generate the unit ideal of ''H''<sup>∞</sup> if and only if there is some δ>0 such that \n:<math>|f_1|+\\cdots+|f_n|\\ge\\delta</math> everywhere in the unit ball.\n\nNewman showed that the corona theorem can be reduced to an interpolation problem, which was then proved by Carleson.\n\nIn 1979 [[Thomas Wolff]] gave a simplified (but unpublished) proof of the corona theorem, described in {{harv|Koosis|1980}} and {{harv|Gamelin|1980}}.\n\nCole later showed that this result cannot be extended to all [[open Riemann surface]]s {{harv|Gamelin|1978}}.\n\nAs a by-product, of Carleson's work, the [[Carleson measure]] was invented which itself is a very useful tool in modern function theory.  It remains an open question whether there are versions of the corona theorem for every planar domain or for higher-dimensional domains.\n\nNote that if one assume the continuity up to the boundary in Corona's theorem, then the conclusion follows easily from the theory of Commutative Banach algebra {{harv|Rudin}}.\n\n==See also==\n*[[Corona set]]\n\n==References==\n*{{citation|mr=0141789 | zbl = 0112.29702\n|last= Carleson\n|first= Lennart \n|author-link= Lennart Carleson\n|title=Interpolations by bounded analytic functions and the corona problem\n|journal= [[Annals of Mathematics]]\n|issue= 3\n|volume=76 \n|year= 1962 \n|pages=547–559\n|doi=10.2307/1970375\n|jstor=1970375\n}}\n*{{citation|mr=0521440  | zbl = 0418.46042\n|last=Gamelin|first= T. W.\n|title=Uniform algebras and Jensen measures.\n|series=London Mathematical Society Lecture Note Series\n|volume= 32\n|publisher= [[Cambridge University Press]]\n|place= Cambridge-New York\n|year= 1978\n|pages= iii+162\n|isbn= 978-0-521-22280-8}}\n*{{citation|mr=0599306 | zbl = 0466.46050\n|last=Gamelin|first= T. W.\n|title=Wolff's proof of the corona theorem\n|journal=[http://www.ma.huji.ac.il/~ijmath/ Israel Journal of Mathematics]\n|volume= 37 \n|year=1980\n|issue= 1–2\n|pages= 113–119\n|doi=10.1007/BF02762872}} \n*{{citation|mr=0565451 | zbl = 0435.30001\n|last=Koosis|first= Paul\n|title=Introduction to H<sup>p</sup>-spaces. With an appendix on Wolff's proof of the corona theorem\n|series=London Mathematical Society Lecture Note Series\n|volume= 40\n|publisher= [[Cambridge University Press]]\n|place= Cambridge-New York\n|year=1980\n|pages= xv+376 \n|isbn= 0-521-23159-0}} \n*{{citation|mr=0106290 | zbl = 0092.11802\n|last= Newman\n|first= D. J.\n|title= Some remarks on the maximal ideal structure of H<sup>&infin;</sup>\n|journal=  [[Annals of Mathematics]] \n|issue= 2\n|volume= 70 \n|year= 1959\n|pages= 438–445\n|doi=10.2307/1970324\n|jstor=1970324\n}}\n*{{citation\n|last=Rudin\n|first= Walter\n|title=Functional Analysis\n|year=1991 \n|pages=279}}.\n*{{citation\n|mr=0125442 | zbl = 0139.30402\n|last=Schark\n|first= I. J.\n|title=Maximal ideals in an algebra of bounded analytic functions\n|journal=[[Indiana University Mathematics Journal|Journal of Mathematics and Mechanics]]\n|volume= 10 \n|url=http://www.iumj.indiana.edu/IUMJ/FULLTEXT/1961/10/10050\n|year=1961 \n|pages=735–746}}.\n\n[[Category:Banach algebras]]\n[[Category:Hardy spaces]]\n[[Category:Theorems in complex analysis]]"
    },
    {
      "title": "Disk algebra",
      "url": "https://en.wikipedia.org/wiki/Disk_algebra",
      "text": "In [[functional analysis|functional]] and [[complex analysis]], the '''disk algebra''' ''A''('''D''') (also spelled '''disc algebra''') is the set of [[holomorphic function]]s\n\n:''f'' : '''D''' &rarr; '''C''',\n\nwhere '''D''' is the [[open unit disk]] in the [[complex plane]] '''C''', ''f'' extends to a continuous function on the [[closure (topology)|closure]] of '''D'''.  That is,\n:<math>A(\\mathbf{D}) = H^\\infty(\\mathbf{D})\\cap C(\\overline{\\mathbf{D}}),</math>\nwhere <math>H^\\infty(\\mathbf{D})</math> denotes the Banach space of bounded analytic functions on the unit disc '''D''' (i.e. a [[Hardy space]]).\nWhen endowed with the pointwise addition, \n(f+g)(z)=f(z)+g(z),\nand pointwise multiplication,\n:(fg)(z)=f(z)g(z),\n\nthis set becomes an [[algebra over a field|algebra]] over '''C''', since if ''&fnof;'' and ''g'' belong to the disk algebra then so do ''ƒ''&nbsp;+&nbsp;''g'' and  ''ƒg''.\n\nGiven the [[uniform norm]],\n:<math>\\|f\\| = \\sup\\{|f(z)|\\mid z\\in \\mathbf{D}\\}=\\max\\{ |f(z)|\\mid z\\in \\overline{\\mathbf{D}}\\},</math>\nby construction it becomes a [[uniform algebra]] and a commutative [[Banach algebra]].\n\nBy construction the disc algebra is a closed subalgebra of the [[Hardy space]] [[H infinity|''H''<sup>&infin;</sup>]]. In contrast to the stronger requirement that a continuous extension to the circle exists, it is [[Fatou's lemma|a lemma of Fatou]] that a general element of [[H infinity|''H''<sup>&infin;</sup>]] can be radially extended to the circle [[almost everywhere]].\n\n[[Category:Functional analysis]]\n[[Category:Complex analysis]]\n[[Category:Banach algebras]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Gelfand representation",
      "url": "https://en.wikipedia.org/wiki/Gelfand_representation",
      "text": "In [[mathematics]], the '''Gelfand representation''' in [[functional analysis]] (named after [[I. M. Gelfand]]) has two related meanings:\n\n* a way of representing [[commutative]] [[Banach algebra]]s as algebras of continuous functions;\n* the fact that for commutative [[C*-algebra]]s, this representation is an isometric isomorphism.\n\nIn the former case, one may regard the Gelfand representation as a far-reaching generalization of the [[Fourier transform]] of an integrable function. In the latter case, the Gelfand–Naimark representation theorem is one avenue in the development of [[spectral theory]] for [[normal operator]]s, and generalizes the notion of diagonalizing a normal matrix.\n\n== Historical remarks ==\nOne of Gelfand's original applications (and one which historically motivated much of the study of Banach algebras{{Citation needed|date=December 2011}}) was to give a much shorter and more conceptual proof of a celebrated lemma of [[Norbert Wiener]] (see the citation below), characterizing the elements of the [[group algebra]]s ''L''<sup>1</sup>('''R''') and <math>\\ell^1({\\mathbf Z})</math> whose translates span dense subspaces in the respective algebras.\n\n== The model algebra ==\nFor any [[locally compact space|locally compact]] [[Hausdorff space|Hausdorff]] [[topological space]] ''X'', the space ''C''<sub>0</sub>(''X'') of continuous complex-valued functions on ''X'' which [[vanish at infinity]] is in a natural way a commutative C*-algebra:\n* The structure of algebra over the complex numbers is obtained by considering  the pointwise operations of addition and multiplication.\n* The involution is pointwise complex conjugation.\n* The norm is the [[uniform norm]] on functions.\n\nNote that  ''C''<sub>0</sub>(''X'')  is [[unital algebra|unital]] if and only if ''X'' is [[compact space|compact]], in which  case ''C''<sub>0</sub>(''X'') is equal to ''C''(''X''), the algebra of all continuous complex-valued functions on ''X''.\n\n== Gelfand representation of a commutative Banach algebra ==\nLet ''A'' be a commutative [[Banach algebra]], defined over the field ℂ of complex numbers. A non-zero [[algebra homomorphism]] φ: ''A'' → ℂ is called a ''character'' of ''A''; the set of all characters of ''A'' is denoted by Φ<sub>''A''</sub>.\n\nIt can be shown that every character on ''A'' is automatically continuous, and hence Φ<sub>''A''</sub> is a subset of the space ''A''* of continuous linear functionals on ''A''; moreover, when equipped with the relative [[Weak topology#The weak-* topology|weak-* topology]], Φ<sub>''A''</sub> turns out to be locally compact and Hausdorff. (This follows from the [[Banach–Alaoglu theorem]].) The space Φ<sub>''A''</sub> is compact (in the topology just defined) if{{Citation needed|date=October 2009}} and only if the algebra ''A'' has an identity element.\n\nGiven ''a'' ∈ ''A'', one defines the function <math>\\widehat{a}:\\Phi_A\\to{\\mathbb C}</math> by <math>\\widehat{a}(\\phi)=\\phi(a)</math>. The definition of Φ<sub>''A''</sub> and the topology on it ensure that <math>\\widehat{a}</math> is continuous and [[vanish at infinity|vanishes at infinity]]{{Citation needed|date=October 2009}}, and that the map <math>a\\mapsto \\widehat{a}</math> defines a norm-decreasing, unit-preserving algebra homomorphism from ''A'' to ''C''<sub>0</sub>(Φ<sub>''A''</sub>). This homomorphism is the ''Gelfand representation of A'', and <math>\\widehat{a}</math> is the ''Gelfand transform'' of the element ''a''. In general, the representation is neither injective nor surjective.\n\nIn the case where ''A'' has an identity element, there is a bijection between Φ<sub>''A''</sub> and the set of maximal ideals in ''A'' (this relies on the [[Gelfand–Mazur theorem]]). As a consequence, the kernel of the Gelfand representation ''A'' → ''C''<sub>0</sub>(Φ<sub>''A''</sub>) may be identified with the [[Jacobson radical]] of ''A''. Thus the Gelfand representation is injective if and only if ''A'' is [[Semiprimitive ring|(Jacobson) semisimple]].\n\n=== Examples ===\nIn the case where ''A'' = ''L''<sup>1</sup>('''R'''), the group algebra of '''R''', then Φ<sub>''A''</sub> is homeomorphic to '''R''' and the Gelfand transform of ''f'' ∈ ''L''<sup>1</sup>('''R''') is the [[Fourier transform]] <math>\\tilde{f}</math>.\n\nIn the case where ''A'' = ''L''<sup>1</sup>('''R'''<sub>+</sub>), the L<sup>1</sup>-convolution algebra of the real half-line, then Φ<sub>''A''</sub> is homeomorphic to {''z'' ∈ '''C''': Re(''z'') ≥ 0}, and the Gelfand transform of an element ''f'' ∈ ''L''<sup>1</sup>('''R'''<sub>+</sub>) is the [[Laplace transform]] <math>{\\mathcal L}f</math>.\n\n== The C*-algebra case ==\nAs motivation, consider the special case ''A'' = ''C''<sub>0</sub>(''X''). Given ''x'' in ''X'', let <math>\\varphi_x \\in A^*</math> be pointwise evaluation at ''x'', i.e. <math>\\varphi_x(f) = f(x)</math>. Then <math>\\varphi_x</math> is a character on ''A'', and it can be shown that all characters of ''A'' are of this form; a more precise analysis shows that we may identify Φ<sub>''A''</sub> with ''X'', not just as sets but as topological spaces. The Gelfand representation is then an isomorphism\n:<math>C_0(X)\\to C_0(\\Phi_A).\\ </math>\n\n=== The spectrum of a commutative C*-algebra ===\n{{See also|Spectrum of a C*-algebra}}\n\nThe '''spectrum''' or '''Gelfand space''' of a commutative C*-algebra ''A'', denoted ''Â'', consists of the set of ''non-zero'' *-homomorphisms from ''A'' to the complex numbers. Elements of the spectrum are called '''characters''' on ''A''. (It can be shown that every algebra homomorphism from ''A'' to the complex numbers is automatically a [[*-algebra|*-homomorphism]], so that this definition of the term 'character' agrees with the one above.)\n\nIn particular, the spectrum of a commutative C*-algebra is a locally compact Hausdorff space: In the unital case, i.e. where the C*-algebra has a multiplicative unit element 1, all characters ''f'' must be unital, i.e. ''f''(1) is the complex number one. This excludes the zero homomorphism. So ''Â'' is closed under weak-* convergence and the spectrum is actually ''compact''. In the non-unital case, the weak-* closure of ''Â'' is ''Â'' ∪ {0}, where 0 is the zero homomorphism, and the removal of a single point from a compact Hausdorff space yields a locally compact Hausdorff space.\n\nNote that ''spectrum'' is an overloaded word.  It also refers to the spectrum σ(''x'') of an element ''x'' of an algebra with unit 1, that is the set of complex numbers ''r'' for which ''x'' - ''r'' 1 is not invertible in ''A''. For unital C*-algebras, the two notions are connected in the following way: σ(''x'') is the set of complex numbers ''f''(''x'') where ''f'' ranges over Gelfand space of ''A''. Together with the [[spectral radius|spectral radius formula]], this shows that ''Â'' is a subset of the unit ball of ''A*'' and as such can be given the relative weak-* topology. This is the topology of pointwise convergence. A [[net (mathematics)|net]] {''f''<sub>''k''</sub>}<sub>''k''</sub> of elements of the spectrum of ''A'' converges to ''f'' [[if and only if]] for each ''x'' in ''A'', the net of complex numbers {''f''<sub>''k''</sub>(''x'')}<sub>''k''</sub> converges to ''f''(''x'').\n\nIf ''A'' is a [[separable space|separable]] C*-algebra, the weak-* topology is [[metrizable]] on bounded subsets.  Thus the spectrum of a separable commutative C*-algebra ''A'' can be regarded as a metric space. So the topology can be characterized via convergence of sequences.\n\nEquivalently, σ(''x'') is the [[Range (mathematics)|range]] of γ(''x''), where γ is the Gelfand representation.\n\n=== Statement of the commutative Gelfand–Naimark theorem ===\nLet ''A'' be a commutative C*-algebra and let ''X'' be the spectrum of ''A''. Let \n:<math>\\gamma:A \\to C_0(X)</math>\n\nbe the Gelfand representation defined above.\n\n'''Theorem'''. The Gelfand map γ is an isometric *-isomorphism from ''A'' onto ''C''<sub>0</sub>(''X'').\n\nSee the Arveson reference below.\n\nThe spectrum of a commutative C*-algebra can also be viewed as the set of all [[maximal ideal]]s ''m'' of ''A'', with the [[hull-kernel topology]]. (See the earlier remarks for the general, commutative Banach algebra case.) For any such ''m'' the quotient algebra ''A/m'' is  one-dimensional (by the Gelfand-Mazur theorem), and therefore any ''a'' in ''A'' gives rise to a complex-valued function on ''Y''.\n\nIn the case of C*-algebras with unit, the spectrum map gives rise to  a contravariant [[functor]] from the category of C*-algebras with unit and unit-preserving continuous *-homomorphisms, to the category of compact Hausdorff spaces and continuous maps. This functor is one half of a [[Equivalence of categories|contravariant equivalence]] between these two categories (its [[adjoint functor|adjoint]] being the functor that assigns to each compact Hausdorff space ''X'' the C*-algebra ''C''<sub>0</sub>(''X'')). In particular, given compact Hausdorff spaces ''X'' and ''Y'', then ''C''(''X'') is isomorphic to ''C''(''Y'') (as a C*-algebra) if and only if ''X'' is [[homeomorphic]] to ''Y''.\n\nThe 'full' [[Gelfand–Naimark theorem]] is a result for arbitrary (abstract) [[noncommutative]] C*-algebras ''A'', which though not quite analogous to the Gelfand representation, does provide a concrete representation of ''A'' as an algebra of operators.\n\n== Applications ==\n\nOne of the most significant applications is the existence of a continuous ''functional calculus'' for normal elements in C*-algebra ''A'': An element ''x'' is normal if and only if ''x'' commutes with its adjoint ''x*'', or equivalently if and only if it generates a commutative C*-algebra C*(''x''). By the Gelfand isomorphism applied to C*(''x'') this is *-isomorphic to an algebra of continuous functions on a locally compact space.  This observation leads almost immediately to:\n\n'''Theorem'''.  Let ''A'' be a C*-algebra with identity and ''x'' an element of ''A''.  Then there is a *-morphism ''f'' → ''f''(''x'') from the algebra of continuous functions on the spectrum σ(''x'') into ''A'' such that\n* It maps 1 to the multiplicative identity of ''A'';\n* It maps the identity function on the spectrum to ''x''.\n\nThis allows us to apply continuous functions to bounded normal operators on Hilbert space.\n\n==References==\n\n*{{cite book|ref=harv|last=Arveson|first=W.|authorlink=William Arveson|title=An Invitation to C*-Algebras|publisher=Springer-Verlag|year=1981|isbn=0-387-90176-0}}\n*{{cite book|ref=harv|first1=F. F.|last1=Bonsall|first2=J.|last2=Duncan|title=Complete Normed Algebras|publisher=Springer-Verlag|location=New York|year=1973| isbn=0-387-06386-2}}\n*{{cite book|ref=harv|last=Conway|first=J. B.|authorlink=John B. Conway|title=A Course in Functional Analysis|year=1990|series=Graduate Texts in Mathematics|volume=96|publisher=[[Springer Verlag]]|isbn=0-387-97245-5}}\n*{{cite journal|ref=harv|authorlink=Norbert Wiener|last=Wiener|first=N.|title=Tauberian theorems|journal=Ann. of Math.|series=II|volume=33|year=1932|pages=1&ndash;100|doi= 10.2307/1968102|jstor=1968102| issue=1|publisher=Annals of Mathematics}}\n\n[[Category:Functional analysis]]\n[[Category:Banach algebras]]\n[[Category:C*-algebras]]"
    },
    {
      "title": "Gelfand–Mazur theorem",
      "url": "https://en.wikipedia.org/wiki/Gelfand%E2%80%93Mazur_theorem",
      "text": "In [[operator theory]], the '''Gelfand–Mazur theorem''' is a [[theorem]] named after [[Israel Gelfand]] and [[Stanisław Mazur]] which states that a [[Banach algebra]] with unit over the [[complex number]]s in which every nonzero element is [[invertible]] is [[isometry|isometrically]] [[isomorphic]] to the [[complex number]]s, i.&nbsp;e., the only complex Banach algebra that is a [[division algebra]] is the complex numbers '''C'''.\n\nThe theorem follows from the fact that the [[spectrum (functional analysis)|spectrum]] of any element of a complex Banach algebra is nonempty: for every element ''a'' of a complex Banach algebra ''A'' there is some complex number ''λ'' such that ''λ''1&nbsp;&minus;&nbsp;''a'' is not invertible. This is a consequence of the complex-analyticity of the [[Resolvent formalism|resolvent]] function. By assumption, ''λ''1&nbsp;&minus;&nbsp;''a'' = 0. So ''a'' = ''λ&nbsp;·&nbsp;''1. This gives an isomorphism from ''A'' to '''C'''.\n\nA stronger and harder theorem was proved first by Stanisław Mazur alone, but it was published in France without a proof, when the author refused the editor's request to shorten his already short proof. Mazur's theorem states that there are (up to isomorphism) exactly three real Banach division algebras: the fields of reals '''R''', of complex numbers '''C''', and the division algebra of quaternions '''H'''. Gelfand proved (independently) the easier, special, complex version a few years later, after Mazur. However, it was Gelfand's work which influenced the further progress in the area.{{Citation needed|date=April 2016}}\n\n==References==\n* {{Citation| first=Walter|last=Rudin|authorlink=Walter Rudin|title=Functional analysis|publisher=Tata MacGraw-Hill|year=1973}}.\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Gelfand-Mazur Theorem}}\n[[Category:Banach algebras]]\n[[Category:Theorems in functional analysis]]"
    },
    {
      "title": "Noncommutative topology",
      "url": "https://en.wikipedia.org/wiki/Noncommutative_topology",
      "text": "In [[mathematics]], '''noncommutative topology''' is a term used for the relationship between [[topological]] and [[C*-algebra]]ic concepts. The term has its origins in the [[Gelfand-Naimark theorem]], which implies the [[Equivalence of categories|duality]] of the [[category (mathematics)|category]] of [[locally compact]] [[Hausdorff space]]s and the category of [[commutative operation|commutative]] C*-algebras. Noncommutative topology is related to analytic [[noncommutative geometry]].\n\n== Examples ==\n\nThe premise behind noncommutative topology is that a noncommutative C*-algebra can be treated like the algebra of complex-valued [[continuous function]]s on a 'noncommutative space' which does not exist classically. Several topological properties can be formulated as properties for the C*-algebras without making reference to commutativity or the underlying space, and so have an immediate generalization.\nAmong these are:\n* [[compact space|compactness]] ([[unital algebra|unital]])\n* [[σ-compact space|σ-compactness]] ([[σ-unital algebra|σ-unital]])\n* [[Lebesgue covering dimension|dimension]] ([[real rank (C*-algebras)|real]] or [[topological stable rank|stable rank]])\n* [[connected space|connectedness]] ([[projectionless C*-algebra|projectionless]])\n* [[extremally disconnected space]]s ([[AW*-algebra]]s)\n\nIndividual elements of a commutative C*-algebra correspond with continuous functions. And so certain types of functions can correspond to certain properties of a C*-algebra. For example, [[self-adjoint]] elements of a commutative C*-algebra correspond to real-valued continuous functions. Also, [[projection (linear algebra)#Orthogonal projections|projections]] (i.e. self-adjoint [[idempotent]]s) correspond to [[indicator function]]s of [[clopen set]]s.\n\nCategorical constructions lead to some examples. For example, the [[coproduct]] is the [[Disjoint union (topology)|disjoint union]] and thus corresponds to the [[direct sum of algebras]], which is the [[product (category theory)|product]] of C*-algebras. Similarly, [[Product topology]] corresponds to the coproduct of C*-algebras, the [[tensor product of algebras]]. In a more specialized setting,\ncompactifications of topologies correspond to unitizations of algebras. So the [[Alexandroff extension|one-point compactification]] corresponds to the minimal unitization of C*-algebras, the [[Stone-Čech compactification]] corresponds to the [[multiplier algebra]], and [[corona set]]s corresponds with [[corona algebra]]s.\n\nThere are certain examples of properties where multiple generalizations are possible and it is not clear which is preferable. For example, [[probability measure]]s can correspond either to [[state (functional analysis)|states]] or tracial states. Since all states are vacuously \ntracial states in the commutative case, so it is not clear whether the tracial condition is necessary to be a useful generalization.\n\n== K-theory ==\nOne of the major examples of this idea is the generalization of [[topological K-theory]] to noncommutative C*-algebras in the form of [[operator K-theory]].\n\nA further development in this is a [[functor#Bifunctors|bivariant]] version of K-theory called [[KK-theory]], which has a composition product \n\n<math>KK(A,B)\\times KK(B,C)\\rightarrow KK(A,C)</math>\n\nof which the ring structure in ordinary K-theory is a special case. The product gives the structure of a [[Category (topology)|category]] to KK. It has been related to [[Correspondence (algebraic geometry)|correspondences]] of algebraic varieties.<ref>{{citation\n | last1 = Connes | first1 = Alain | author1-link = Alain Connes\n | last2 = Consani | first2 = Caterina | author2-link = Caterina Consani\n | last3 = Marcolli | first3 = Matilde | author3-link = Matilde Marcolli\n | arxiv = math.QA/0512138\n | doi = 10.1016/j.aim.2007.03.006\n | issue = 2\n | journal = Advances in Mathematics\n | mr = 2349719\n | pages = 761–831\n | title = Noncommutative geometry and motives: the thermodynamics of endomotives\n | volume = 214\n | year = 2007}}</ref>\n\n== References ==\n<references/>\n\n{{DEFAULTSORT:Noncommutative Topology}}\n[[Category:Banach algebras]]\n[[Category:C*-algebras]]\n[[Category:Topology]]\n\n\n{{topology-stub}}"
    },
    {
      "title": "Shilov boundary",
      "url": "https://en.wikipedia.org/wiki/Shilov_boundary",
      "text": "In [[functional analysis]], a branch of mathematics, the '''Shilov boundary''' is the smallest   [[closed set|closed]] subset of the [[structure space]] of a [[commutative]] [[Banach algebra]] where an analog of the [[maximum modulus principle]] holds. It is named after its discoverer, [[Georgii Evgen'evich Shilov]].\n\n== Precise definition and existence ==\nLet <math>\\mathcal A</math> be a [[commutative]] [[Banach algebra]] and let <math>\\Delta \\mathcal A</math> be its [[structure space]] equipped with the [[relative topology|relative]] [[weak topology|weak*-topology]] of the [[continuous dual space|dual]] <math>{\\mathcal A}^*</math>. A closed (in this topology) subset <math>F</math> of <math>\\Delta {\\mathcal A}</math> is called a '''boundary''' of <math>{\\mathcal A}</math> if <math>\\max_{f \\in \\Delta {\\mathcal A}} |x(f)|=\\max_{f \\in F} |x(f)|</math> for all <math>x \\in \\mathcal A</math>.\nThe set <math>S=\\bigcap\\{F:F \\text{ is a boundary of } {\\mathcal A}\\}</math> is called the '''Shilov boundary'''. It has been proved by Shilov<ref>Theorem 4.15.4 in [[Einar Hille]], [[Ralph S. Phillips]]: [http://www.ams.org/online_bks/coll31/coll31-chIV.pdf Functional analysis and semigroups]. -- AMS, Providence 1957.</ref> that <math>S</math> is a boundary of <math>{\\mathcal A}</math>.\n\nThus one may also say that Shilov boundary is the unique set <math>S \\subset \\Delta \\mathcal A</math> which satisfies\n#<math>S</math> is a boundary of <math>\\mathcal A</math>, and\n#whenever <math>F</math> is a boundary of <math>\\mathcal A</math>, then <math>S \\subset F</math>.\n\n== Examples ==\n*Let <math>\\mathbb D=\\{z \\in \\mathbb C:|z|<1\\}</math> be the [[open unit disc]] in the [[complex plane]] and let \n<math>{\\mathcal A}= H^\\infty(\\mathbb D)\\cap {\\mathcal C}(\\bar{\\mathbb D})</math> be the [[disc algebra]], i.e. the functions [[Holomorphic function|holomorphic]] in <math>\\mathbb D</math> and [[continuous function|continuous]] in the [[closure (topology)|closure]] of <math>\\mathbb D</math> with [[supremum norm]] and usual algebraic operations. Then <math>\\Delta {\\mathcal A}=\\bar{\\mathbb D}</math> and <math>S=\\{|z|=1\\}</math>.\n\n== References ==\n*{{Springer|id=B/b110310|title=Bergman-Shilov boundary}}\n\n==Notes==\n{{Reflist}}\n\n== See also ==\n*[[James boundary]]\n*[[Furstenberg boundary]]\n\n[[Category:Banach algebras]]"
    },
    {
      "title": "Structure space",
      "url": "https://en.wikipedia.org/wiki/Structure_space",
      "text": "{{unreferenced|date=April 2013}}\nIn mathematics, the '''structure space''' of a [[commutative]] [[Banach algebra]] is an analog of the [[spectrum of a C*-algebra]]. It consists of all multiplicative [[linear functional]]s on the algebra. The [[Gelfand representation]] of the Banach algebra is a map taking the Banach algebra elements to [[continuous function]]s on the structure space.\n\n\n[[Category:Banach algebras]]\n\n\n{{Mathanalysis-stub}}"
    },
    {
      "title": "Uniform algebra",
      "url": "https://en.wikipedia.org/wiki/Uniform_algebra",
      "text": "A '''uniform algebra''' ''A'' on a [[compact space|compact]] [[Hausdorff space |Hausdorff]] [[topological space]] ''X'' is a  closed (with respect to the [[uniform norm]]) [[algebra over a field|subalgebra]] of the [[C*-algebra]] ''C(X)'' (the continuous complex valued functions on ''X'') with the following properties:\n:the constant functions are contained in ''A''\n: for every ''x'', ''y'' <math>\\in</math> ''X'' there is f<math>\\in</math>''A'' with f(x)<math>\\ne</math>f(y). This is called separating the points of ''X''.\n\nAs a closed subalgebra of the [[commutative]] [[Banach algebra]] ''C(X)'' a uniform algebra is itself a unital commutative Banach algebra (when equipped with the uniform norm). Hence, it is, (by definition) a [[Banach function algebra]].\n\nA uniform algebra ''A'' on ''X'' is said to be '''natural''' if the [[maximal ideal]]s of ''A'' precisely are the ideals <math>M_x</math> of functions vanishing at a point ''x'' in ''X''.\n\n==Abstract characterization==\nIf ''A'' is a [[unital algebra|unital]] [[commutative]] [[Banach algebra]] such that <math>||a^2|| = ||a||^2</math> for all ''a'' in ''A'', then there is a [[compact space|compact]] [[Hausdorff space |Hausdorff]] ''X'' such that ''A'' is isomorphic as a Banach algebra to a uniform algebra on ''X''. This result follows from the spectral radius formula and the Gelfand representation.\n\n{{mathanalysis-stub}}\n\n[[Category:Functional analysis]]\n\n[[Category:Banach algebras]]"
    },
    {
      "title": "Wiener algebra",
      "url": "https://en.wikipedia.org/wiki/Wiener_algebra",
      "text": "In mathematics, the '''Wiener algebra''', named after [[Norbert Wiener]] and usually denoted by {{math|''A''('''T''')}}, is the space of [[absolute convergence|absolutely convergent]] [[Fourier series]].<ref>{{MathWorld|title=Wiener algebra|urlname=WienerAlgebra|last=Moslehian|first=M.S.}}\n</ref> Here {{math|'''T'''}} denotes the [[circle group]].\n\n==Banach algebra structure==\nThe norm of a function {{math|''f''&nbsp;&isin;&nbsp;''A''('''T''')}} is given by\n\n:<math>\\|f\\|=\\sum_{n=-\\infty}^\\infty |\\hat{f}(n)|,\\,</math>\n\nwhere\n\n:<math>\\hat{f}(n)= \\frac{1}{2\\pi}\\int_{-\\pi}^\\pi f(t)e^{-int} \\, dt</math>\n\nis the {{mvar|n}}th Fourier coefficient of {{math|''f''}}. The Wiener algebra {{math|''A''('''T''')}} is closed under pointwise multiplication of functions. Indeed,\n\n:<math>\n\\begin{align}\nf(t)g(t) & = \\sum_{m\\in\\mathbb{Z}} \\hat{f}(m)e^{imt}\\,\\cdot\\,\\sum_{n\\in\\mathbb{Z}} \\hat{g}(n)e^{int} \\\\\n& = \\sum_{n,m\\in\\mathbb{Z}} \\hat{f}(m)\\hat{g}(n)e^{i(m+n)t} \\\\\n& = \\sum_{n\\in\\mathbb{Z}} \\left\\{ \\sum_{m \\in \\mathbb{Z}} \\hat{f}(n-m)\\hat{g}(m) \\right\\}e^{int}\n,\\qquad f,g\\in A(\\mathbb{T});\n\\end{align}\n</math>\n\ntherefore\n\n:<math> \n\\|f g\\| \n= \\sum_{n\\in\\mathbb{Z}} \\left| \\sum_{m \\in \\mathbb{Z}} \\hat{f}(n-m)\\hat{g}(m) \\right| \n\\leq \\sum_{m} |\\hat{f}(m)| \\sum_n |\\hat{g}(n)| = \\|f\\| \\, \\|g\\|.\\,</math>\n\nThus the Wiener algebra is a commutative unitary [[Banach algebra]]. Also, {{math|''A''('''T''')}} is isomorphic to the Banach algebra {{math|''l''<sub>1</sub>('''Z''')}}, with the isomorphism given by the Fourier transform.\n\n== Properties ==\n\nThe sum of an absolutely convergent Fourier series is continuous, so\n:<math>A(\\mathbb{T})\\subset C(\\mathbb{T})</math>\nwhere {{math|''C''('''T''')}} is the ring of continuous functions on the unit circle.\n\nOn the other hand an [[integration by parts]], together with the [[Cauchy–Schwarz inequality]] and [[Parseval's formula]], shows that\n\n: <math>C^1(\\mathbb{T})\\subset A(\\mathbb{T}).\\,</math>\n\nMore generally,\n\n: <math>\\mathrm{Lip}_\\alpha(\\mathbb{T})\\subset A(\\mathbb{T})\\subset C(\\mathbb{T})</math>\n\nfor <math>\\alpha>1/2</math> (see {{harvtxt|Katznelson|2004}}).\n\n==Wiener's 1/''f'' theorem==\n{{main|Wiener tauberian theorem}}\n\n{{harvs|txt|last=Wiener|year1=1932|year2=1933}} proved that if {{math|''f''}} has absolutely convergent Fourier series and is never zero, then its inverse {{math|1/''f''}} also has an absolutely convergent Fourier series. Many other proofs have appeared since then, including an elementary one by {{harvs|txt|last=[[Donald J. Newman|Newman]]|year1=1975}}.\n\n{{harvs|txt|last=Gelfand|year1=1941|year2=1941b}} used the theory of Banach algebras that he developed to show that the maximal ideals of {{math|''A''('''T''')}} are of the form\n\n:<math> M_x = \\left\\{ f \\in A(\\mathbb{T}) \\, \\mid \\, f(x) = 0 \\right\\}, \\quad x \\in \\mathbb{T}~,</math>\n\nwhich is equivalent to Wiener's theorem.\n\n==See also==\n*[[Wiener–Lévy theorem]]\n\n==Notes==\n{{Reflist}}\n\n== References ==\n* {{springer\n| title= A Short Course on Spectral Theory\n| id= 10.1007/b97227\n| last=Arveson\n| first=William\n}}\n*{{Citation | last1=Gelfand | first1=I. | title=Normierte Ringe | year=1941a | journal=Rec. Math. (Mat. Sbornik) N.S.| volume=9 | issue = 51  | pages=3–24 | mr=0004726}}\n*{{Citation | last1=Gelfand | first1=I. | title=Über absolut konvergente trigonometrische Reihen und Integrale | year=1941b | journal=Rec. Math. (Mat. Sbornik) N.S.| volume=9 | issue = 51  | pages=51–66 | mr=0004727}}\n* {{citation | last=Katznelson| first= Yitzhak| title=An introduction to harmonic analysis| edition =Third | publisher =Cambridge Mathematical Library | year=2004 | location=New York | isbn=978-0-521-54359-0}}\n*{{Citation | last1=Newman | first1=D. J. | title=A simple proof of Wiener's 1/''f'' theorem | year=1975 | journal=[[Proceedings of the American Mathematical Society]] | issn=0002-9939 | volume=48 | pages=264–265 | mr=0365002 | doi=10.2307/2040730}}\n*{{Citation | last=Wiener|first=Norbert|title=Tauberian Theorems|journal=Annals of Mathematics|volume=33|issue=1|year=1932|pages=1&ndash;100|doi=10.2307/1968102}}\n*{{Citation | last1=Wiener | first1=Norbert | title=The Fourier integral and certain of its applications | publisher=[[Cambridge University Press]] | series=Cambridge Mathematical Library | isbn=978-0-521-35884-2 | doi=10.1017/CBO9780511662492 | year=1933 | mr=983891}}\n\n[[Category:Banach algebras]]\n[[Category:Fourier series]]"
    },
    {
      "title": "C*-algebra",
      "url": "https://en.wikipedia.org/wiki/C%2A-algebra",
      "text": "{{Use American English|date=January 2019}}{{Short description|Topological complex vector space\n}}\n{{refimprove|date=February 2013}}\n'''C<sup>∗</sup>-algebras''' <!-- \"C*\" is almost fine, but some fonts render the star like ∗, i.e., not superscirpt, nor small. -->(pronounced \"C-star\") are subjects of research in [[functional analysis]], a branch of [[mathematics]].  A C*-algebra is a [[complex number|complex]] [[algebra over a field|algebra]] ''A'' of [[continuous linear operator]]s on a [[complex number|complex]] [[Hilbert space]] with two additional properties:\n\n* ''A'' is a topologically [[closed set]] in the [[norm topology]] of operators.\n* ''A'' is closed under the operation of taking [[adjoint of an operator|adjoint]]s of operators.\n\nC*-algebras were first considered primarily for their use in [[quantum mechanics]] to [[model (abstract)|model]] algebras of physical [[observable]]s.  This line of research began with [[Werner Heisenberg]]'s [[matrix mechanics]] and in a more mathematically developed form with [[Pascual Jordan]] around 1933.  Subsequently, [[John von Neumann]] attempted to establish a general framework for these algebras which culminated in a series of papers on rings of operators.  These papers considered a special class of C*-algebras which are now known as [[von Neumann algebra]]s.\n\nAround 1943, the work of [[Israel Gelfand]] and [[Mark Naimark]] yielded an abstract characterisation of C*-algebras making no reference to operators on a Hilbert space.\n\nC*-algebras are now an important tool in the theory of [[unitary representation]]s of [[locally compact group]]s, and are also used in algebraic formulations of quantum mechanics. Another active area of research is the program to obtain classification, or to determine the extent of which classification is possible, for separable simple [[nuclear C*-algebra]]s.\n\n== Abstract characterization ==\n\nWe begin with the abstract characterization of C*-algebras given in the 1943 paper by Gelfand and Naimark.\n\nA C*-algebra, ''A'', is a [[Banach algebra]] over the field of [[complex number]]s, together with a [[Map (mathematics)|map]] <math display=\"inline\"> x \\mapsto x^* </math> for <math display=\"inline\"> x\\in A</math>     with the following properties:\n\n* It is an [[Semigroup with involution|involution]], for every ''x'' in ''A'':\n::<math> x^{**} = (x^*)^* =  x </math>\n\n* For all ''x'', ''y'' in ''A'':\n::<math> (x + y)^* = x^* + y^* </math>\n::<math> (x y)^* = y^* x^*</math>\n\n* For every complex number λ in '''C''' and every ''x'' in ''A'':\n::<math> (\\lambda x)^* = \\overline{\\lambda} x^* .</math>\n\n* For all ''x'' in ''A'':\n::<math>  \\|x^* x \\| = \\|x\\|\\|x^*\\|.</math>\n\n'''Remark.''' The first three identities say that ''A'' is a [[*-algebra]]. The last identity is called the '''C* identity''' and is equivalent to:\n\n<math>\\|xx^*\\| = \\|x\\|^2,</math>\n\nwhich is sometimes called the B*-identity. For history behind the names C*- and B*-algebras, see the [[#Some_history:_B.2A-algebras_and_C.2A-algebras|history]] section below.\n\nThe C*-identity is a very strong requirement. For instance, together with the [[spectral radius|spectral radius formula]], it implies that the C*-norm is uniquely determined by the algebraic structure:\n\n::<math> \\|x\\|^2 = \\|x^* x\\| = \\sup\\{|\\lambda| : x^* x - \\lambda \\,1 \\text{ is not invertible} \\}.</math>\n\nA [[bounded linear map]], π : ''A'' → ''B'', between C*-algebras ''A'' and ''B'' is called a '''*-homomorphism''' if\n\n* For ''x'' and ''y'' in ''A''\n\n::<math> \\pi(x y) = \\pi(x) \\pi(y) \\,</math>\n\n* For ''x'' in ''A''\n\n::<math> \\pi(x^*) = \\pi(x)^* \\,</math>\n\nIn the case of C*-algebras, any *-homomorphism π between C*-algebras is [[Contraction (operator theory)|contractive]], i.e. bounded with norm ≤ 1. Furthermore, an injective *-homomorphism between C*-algebras is [[isometry|isometric]]. These are consequences of the C*-identity.\n\nA bijective *-homomorphism π is called a '''C*-isomorphism''', in which case ''A'' and ''B'' are said to be '''isomorphic'''.\n\n== Some history: B*-algebras and C*-algebras ==\nThe term B*-algebra was introduced by C. E. Rickart in 1946 to describe [[Banach *-algebra]]s that satisfy the condition:\n\n* <math>\\lVert x x^* \\rVert = \\lVert x \\rVert ^2</math> for all ''x'' in the given B*-algebra. (B*-condition)\n\nThis condition automatically implies that the *-involution is isometric, that is, <math>\\lVert x \\rVert = \\lVert x^* \\rVert </math>. Hence, <math>\\lVert xx^*\\rVert = \\lVert x \\rVert \\lVert x^*\\rVert</math>, and therefore, a B*-algebra is also a C*-algebra. Conversely, the C*-condition implies the B*-condition. This is nontrivial, and can be proved without using the condition <math>\\lVert x \\rVert = \\lVert x^* \\rVert</math>.<ref>{{harvnb|Doran|Belfi|1986|pp=5–6}}, [https://books.google.com/books?id=6jNbsnJVjMoC&pg=PA5 Google Books].</ref> For these reasons, the term B*-algebra is rarely used in current terminology, and has been replaced by the term 'C*-algebra'.\n\nThe term C*-algebra was introduced by [[Irving Segal|I. E. Segal]] in 1947 to describe norm-closed subalgebras of ''B''(''H''), namely, the space of bounded operators on some Hilbert space ''H''. 'C' stood for 'closed'.<ref>{{harvnb|Doran|Belfi|1986|p=6}}, [https://books.google.com/books?id=6jNbsnJVjMoC&pg=PA6 Google Books].</ref><ref>{{harvnb|Segal|1947}}</ref> In his paper Segal defines a C*-algebra as a \"uniformly closed, self-adjoint algebra of bounded operators on a Hilbert space\".<ref>{{harvnb|Segal|1947|p=75}}</ref>\n\n== Structure of C*-algebras ==\n\nC*-algebras have a large number of properties that are technically convenient. Some of these properties can be established by using the [[continuous functional calculus]] or by reduction to commutative  C*-algebras.  In the latter case, we can use the fact that the structure of these is completely determined by the [[Gelfand isomorphism]].\n\n=== Self-adjoint elements ===\n\nSelf-adjoint elements are those of the form ''x''=''x''*. The set of elements of a C*-algebra ''A'' of the form ''x*x'' forms a closed [[convex cone]].  This cone is identical to the elements of the form ''xx*''. Elements of this cone are called ''non-negative'' (or sometimes ''positive'', even though this terminology conflicts with its use for elements of '''R'''.)\n\nThe set of self-adjoint elements of a C*-algebra ''A'' naturally has the structure of a [[partial order|partially ordered]] [[vector space]]; the ordering is usually denoted ≥. In this ordering, a self-adjoint element ''x'' of ''A'' satisfies ''x'' ≥ 0 if and only if the [[Spectrum (functional analysis)|spectrum]] of ''x''  is non-negative,{{clarify|Under the Gelfand representation?|date=August 2014}} if and only if ''x'' = ''s*s'' for some ''s''. Two self-adjoint elements ''x'' and ''y'' of ''A'' satisfy ''x'' ≥ ''y'' if ''x''−''y'' ≥ 0.\n\nThis partially ordered subspace allows the definition of a [[positive linear functional]] on a C*-algebra, which in turn is used to define the [[State (functional analysis)|states]] of a C*-algebra, which in turn can be used to construct the [[spectrum of a C*-algebra]] using the [[GNS construction]].\n\n=== Quotients and approximate identities ===\n\nAny C*-algebra ''A'' has an [[approximate identity]].  In fact, there is a directed family {''e''<sub>λ</sub>}<sub>λ∈I</sub> of self-adjoint elements of ''A'' such that\n\n:: <math> x e_\\lambda \\rightarrow x </math>\n:: <math> 0 \\leq e_\\lambda \\leq e_\\mu \\leq 1\\quad \\mbox{ whenever } \\lambda \\leq \\mu. </math>\n\n: In case ''A'' is separable, ''A'' has a sequential approximate identity. More generally, ''A'' will have a sequential approximate identity if and only if ''A'' contains a '''[[Hereditary C*-subalgebra|strictly positive element]]''', i.e. a positive element ''h'' such that ''hAh'' is dense in ''A''.\n\nUsing approximate identities, one can show that the algebraic [[quotient]] of a C*-algebra by a closed proper two-sided [[Ideal (ring theory)|ideal]], with the natural norm, is a C*-algebra.\n\nSimilarly, a closed two-sided ideal of a C*-algebra is itself a C*-algebra.\n\n== Examples ==\n\n=== Finite-dimensional C*-algebras ===\nThe algebra M(''n'', '''C''') of ''n'' × ''n'' [[matrix (mathematics)|matrices]] over '''C''' becomes a C*-algebra if we consider matrices as operators on the Euclidean space, '''C'''<sup>''n''</sup>, and  use the [[operator norm]] ||&middot;|| on matrices. The involution is given by the [[conjugate transpose]].  More generally, one can consider finite [[direct sum of modules|direct sum]]s of matrix algebras. In fact, all C*-algebras that are finite dimensional as vector spaces are of this form, up to isomorphism. The self-adjoint requirement means finite-dimensional C*-algebras are [[Semisimple algebra|semisimple]], from which fact one can deduce the following theorem of [[Artin–Wedderburn theorem|Artin–Wedderburn]] type:\n\n<blockquote>'''Theorem.'''  A finite-dimensional C*-algebra, ''A'', is [[Canonical form|canonically]] isomorphic to a finite direct sum\n:<math> A = \\bigoplus_{e \\in \\min A } A e</math>\nwhere min ''A'' is the set of minimal nonzero self-adjoint central projections of ''A''.</blockquote>\n\nEach C*-algebra, ''Ae'', is isomorphic (in a noncanonical way) to the full matrix algebra M(dim(''e''), '''C'''). The finite family indexed on min ''A'' given by {dim(''e'')}<sub>''e''</sub> is called the ''dimension vector'' of ''A''.  This vector uniquely determines the isomorphism class of a finite-dimensional C*-algebra. In the language of [[operator K-theory|K-theory]], this vector is the [[ordered group|positive cone]] of the ''K''<sub>0</sub> group of ''A''.\n\nA '''†-algebra''' (or, more explicitly, a ''†-closed algebra'') is the name occasionally used in [[physics]]<ref>John A. Holbrook, David W. Kribs, and Raymond Laflamme. \"Noiseless Subsystems and the Structure of the Commutant in Quantum Error Correction.\" ''Quantum Information Processing''. Volume 2, Number 5, pp. 381&ndash;419.  Oct 2003.</ref> for a finite-dimensional C*-algebra.  The [[dagger (typography)|dagger]], †, is used in the name because physicists typically use the symbol to denote a [[Hermitian adjoint]], and are often not worried about the subtleties associated with an infinite number of dimensions.  (Mathematicians usually use the asterisk, *, to denote the Hermitian adjoint.) †-algebras feature prominently in [[quantum mechanics]], and especially [[quantum information science]].\n\nAn immediate generalization of finite dimensional C*-algebras are the [[approximately finite dimensional C*-algebra]]s.\n\n=== C*-algebras of operators ===\nThe prototypical example of a C*-algebra is the algebra ''B(H)'' of bounded (equivalently continuous) [[linear operator]]s defined on a complex [[Hilbert space]] ''H''; here ''x*'' denotes the [[adjoint operator]] of the operator ''x'' : ''H'' → ''H''. In fact, every C*-algebra, ''A'', is *-isomorphic to a norm-closed adjoint closed subalgebra of ''B''(''H'') for a suitable Hilbert space, ''H''; this is the content of the [[Gelfand–Naimark theorem]].\n\n=== C*-algebras of compact operators ===\nLet ''H'' be a [[separable space|separable]] infinite-dimensional Hilbert space. The algebra ''K''(''H'') of [[Compact operator on Hilbert space|compact operator]]s on ''H'' is a [[norm closed]] subalgebra of ''B''(''H''). It is also closed under involution; hence it is a  C*-algebra.\n\nConcrete C*-algebras of compact operators admit a characterization similar to Wedderburn's theorem for finite dimensional C*-algebras:\n\n<blockquote>'''Theorem.''' If ''A'' is a C*-subalgebra of ''K''(''H''), then there exists Hilbert spaces {''H<sub>i</sub>''}<sub>''i''∈''I''</sub> such that\n:<math> A \\cong \\bigoplus_{i \\in I } K(H_i),</math>\nwhere the (C*-)direct sum consists of elements (''T<sub>i</sub>'') of the Cartesian product Π ''K''(''H<sub>i</sub>'') with ||''T<sub>i</sub>''|| → 0.</blockquote>\n\nThough ''K''(''H'')  does not have an identity element, a sequential [[approximate identity]] for ''K''(''H'') can be developed. To be specific, ''H'' is isomorphic to the space  of square summable sequences ''l''<sup>2</sup>; we may assume that ''H'' = ''l''<sup>2</sup>.  For each natural number ''n'' let ''H<sub>n</sub>'' be the subspace of sequences of ''l''<sup>2</sup> which vanish for indices ''k'' ≤ ''n'' and let ''e<sub>n</sub>'' be the orthogonal projection onto ''H<sub>n</sub>''. The sequence {''e<sub>n</sub>''}<sub>''n''</sub> is an approximate identity for ''K''(''H'').\n\n''K''(''H'') is a two-sided closed ideal of ''B''(''H''). For separable Hilbert spaces, it is the unique ideal. The [[quotient]] of ''B''(''H'') by ''K''(''H'') is the [[Calkin algebra]].\n\n=== Commutative C*-algebras ===\nLet ''X'' be a [[locally compact]] Hausdorff space.  The space <math>C_0(X)</math> of complex-valued continuous functions on ''X'' that ''vanish at infinity'' (defined in the article on [[locally compact|local compactness]]) form a commutative C*-algebra <math>C_0(X)</math> under pointwise multiplication and addition. The involution is pointwise conjugation. <math>C_0(X)</math> has a multiplicative unit element if and only if <math>X</math> is  compact.  As does any C*-algebra, <math>C_0(X)</math> has an [[approximate identity]]. In the case of <math>C_0(X)</math> this is immediate: consider the directed set of compact subsets of <math>X</math>, and for each compact <math>K</math> let <math>f_K</math> be a function of compact support which is identically 1 on <math>K</math>.  Such functions exist by the [[Tietze extension theorem]] which applies to locally compact Hausdorff spaces. Any such sequence of functions <math>\\{f_K\\}</math> is an approximate identity.\n\nThe [[Gelfand representation]] states that every commutative C*-algebra is *-isomorphic to the algebra <math>C_0(X)</math>, where <math>X</math> is the space of [[Character (mathematics)|characters]] equipped with the [[Weak topology|weak* topology]]. Furthermore, if <math>C_0(X)</math> is [[isomorphism|isomorphic]] to <math>C_0(Y)</math> as C*-algebras, it follows that <math>X</math> and <math>Y</math> are [[homeomorphism|homeomorphic]]. This characterization is one of the motivations for the [[noncommutative topology]] and [[noncommutative geometry]] programs.\n\n=== C*-enveloping algebra ===\nGiven a Banach *-algebra ''A'' with an [[approximate identity]], there is a unique (up to C*-isomorphism) C*-algebra '''E'''(''A'') and *-morphism π from ''A'' into '''E'''(''A'') which is [[universal morphism|universal]], that is, every other continuous *-morphism {{nowrap|π ' : ''A'' → ''B''}} factors uniquely through π.  The algebra '''E'''(''A'') is called the '''C*-enveloping algebra''' of the Banach *-algebra ''A''.\n\nOf particular importance is the C*-algebra of a [[locally compact group]] ''G''.  This is defined as the enveloping C*-algebra of the [[group algebra]] of ''G''.  The  C*-algebra of ''G''  provides context for general [[harmonic analysis]] of ''G'' in the case ''G'' is non-abelian.  In particular, the dual of a locally compact group is defined to be the primitive ideal space of the group C*-algebra.  See [[spectrum of a C*-algebra]].\n\n=== Von Neumann algebras ===\n\n[[Von Neumann algebra]]s, known as W* algebras before the 1960s, are a special kind of C*-algebra. They are required to be closed in the [[weak operator topology]], which is weaker than the norm topology.\n\nThe [[Sherman–Takeda theorem]] implies that any C*-algebra has a universal enveloping W*-algebra, such that any homomorphism to a W*-algebra factors through it.\n\n== Type for C*-algebras ==\nA C*-algebra ''A'' is of type I if and only if for all non-degenerate representations π of ''A'' the von Neumann algebra π(''A'')′′ (that is, the bicommutant of π(''A'')) is a type I von Neumann algebra. In fact it is sufficient to consider only factor representations, i.e. representations π for which π(''A'')′′ is a factor.\n\nA locally compact group is said to be of type I if and only if its [[group C^*-algebra|group C*-algebra]] is type I.\n\nHowever, if a C*-algebra has non-type I representations, then by results of [[James Glimm]] it also has representations of type II and type III. Thus for C*-algebras and locally compact groups, it is only meaningful to speak of type I and non type I properties.\n\n== C*-algebras and quantum field theory ==\nIn [[quantum mechanics]], one typically describes a physical system with a C*-algebra ''A'' with unit element; the self-adjoint elements of ''A'' (elements ''x'' with ''x*'' = ''x'') are thought of as the ''observables'', the measurable quantities, of the system. A ''state'' of the system is defined as a positive functional on ''A'' (a '''C'''-linear map φ : ''A'' → '''C''' with φ(''u*u'') ≥ 0 for all ''u'' ∈ ''A'') such that φ(1) = 1. The expected value of the observable ''x'', if the system is in state φ, is then φ(''x'').\n\nThis C*-algebra approach is used in the Haag-Kastler axiomatization of [[local quantum field theory]], where every open set of [[Minkowski spacetime]] is associated with a C*-algebra.\n\n== See also ==\n* [[Banach algebra]]\n* [[Star-algebra|*-algebra]]\n* [[Hilbert C*-module]]\n* [[Operator K-theory]]\n* [[Operator system]], a unital subspace of a C*-algebra that is *-closed.\n* [[Gelfand–Naimark–Segal construction]]\n\n== Notes ==\n{{reflist}}\n\n== References ==\n* {{citation|first=W.|last=Arveson|authorlink=William Arveson|title=An Invitation to C*-Algebra|publisher=Springer-Verlag|year=1976|isbn=0-387-90176-0}}. An excellent introduction to the subject, accessible for those with a knowledge of basic [[functional analysis]].\n* {{citation|first=Alain|last=Connes|authorlink=Alain Connes|url=http://www.alainconnes.org/docs/book94bigpdf.pdf|title=Non-commutative geometry|isbn=0-12-185860-X}}.  This book is widely regarded as a source of new research material, providing much supporting intuition, but it is difficult.\n* {{citation|first=Jacques|last=Dixmier|authorlink=Jacques Dixmier|title=Les C*-algèbres et leurs représentations|publisher=Gauthier-Villars|year=1969|isbn=0-7204-0762-1}}. This is a somewhat dated reference, but is still considered as a high-quality technical exposition. It is available in English from North Holland press.\n* {{citation|last1=Doran|first1=Robert S.|authorlink=Robert S. Doran|first2=Victor A.|last2=Belfi|title=Characterizations of C*-algebras: The Gelfand-Naimark Theorems|publisher=CRC Press|year=1986|isbn=978-0-8247-7569-8}}.\n* {{citation|first=G.|last1=Emch|title=Algebraic Methods in Statistical Mechanics and Quantum Field Theory|publisher=Wiley-Interscience|year=1972|isbn=0-471-23900-3}}. Mathematically rigorous reference which provides extensive physics background.\n*{{springer|id=c/c020020|title=C* algebra|author=A.I. Shtern}}\n* {{citation|first=S.|last=Sakai|authorlink=Shoichiro Sakai|title=C*-algebras and W*-algebras|publisher=Springer|year=1971|isbn=3-540-63633-1}}.\n*{{citation|first=Irving|last=Segal|authorlink=Irving Segal|title=Irreducible representations of operator algebras|journal=Bulletin of the American Mathematical Society|year=1947|volume=53|pages=73–88|doi=10.1090/S0002-9904-1947-08742-5|issue=2}}.\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:C*-Algebra}}\n[[Category:C*-algebras|*]]\n[[Category:Functional analysis]]"
    },
    {
      "title": "Multiplier algebra",
      "url": "https://en.wikipedia.org/wiki/Multiplier_algebra",
      "text": "In [[mathematics]], the '''multiplier algebra''', denoted by ''M''(''A''), of a [[C*-algebra]] ''A'' is a unital C*-algebra which is the largest unital C*-algebra that contains ''A'' as an [[Ideal (ring theory)|ideal]] in a \"non-degenerate\" way. It is the [[noncommutative topology|noncommutative]] generalization of [[Stone–Čech compactification]]. Multiplier algebras were introduced by {{harvtxt|Busby|1968}}.\n\nFor example, if ''A'' is the C*-algebra of [[compact operator on Hilbert space|compact operators on a separable Hilbert space]], ''M''(''A'') is ''B''(''H''), the C*-algebra of all [[bounded operator]]s on ''H''.\n\n== Definition ==\n\nAn ideal ''I'' in a C*-algebra ''B'' is said to be '''essential''' if ''I'' ∩ ''J'' is non-trivial for all ideal ''J''. An ideal ''I'' is  essential if and only if ''I''<sup>⊥</sup>, the \"orthogonal complement\" of ''I'' in the [[Hilbert C*-module]] ''B'' is {0}.\n\nLet ''A'' be a C*-algebra. Its multiplier algebra ''M''(''A'') is any C*-algebra satisfying the following [[universal property]]: for all C*-algebra ''D'' containing ''A'' as an ideal, there exists a unique *-homomorphism φ ''D'' → ''M''(''A'') such that ''φ'' extends the identity homomorphism on ''A'' and ''φ''(''A''<sup>⊥</sup>) = {0}.\n\nUniqueness up to [[isomorphism]] is specified by the universal property. When ''A'' is unital, ''M''(''A'') = ''A''. It also follows from the definition that for any ''D'' containing ''A'' as an essential ideal, the multiplier algebra ''M''(''A'') contains ''D'' as a C*-subalgebra.\n\nThe existence of ''M''(''A'') can be shown in several ways.\n\nA '''double centralizer''' of a C*-algebra ''A'' is a pair (''L'', ''R'') of bounded linear maps on ''A'' such that ''aL''(''b'') = ''R''(''a'')''b'' for all ''a'' and ''b'' in ''A''. This implies that ||''L''|| = ||''R''||. The set of double centralizers of ''A'' can be given a C*-algebra structure. This C*-algebra contains ''A'' as an essential ideal and can be identified as the multiplier algebra ''M''(''A''). For instance, if ''A'' is the compact operators ''K''(''H'') on a separable Hilbert space, then each ''x'' ∈ ''B''(''H'') defines a double centralizer of ''A'' by simply multiplication from the left and right.\n\nAlternatively, ''M''(''A'') can be obtained via representations. The following fact will be needed:\n\n'''Lemma.''' If ''I'' is an ideal in a C*-algebra ''B'', then any faithful nondegenerate representation ''π'' of ''I'' can be extended ''uniquely'' to ''B''.\n\nNow take any faithful nondegenerate representation ''π'' of ''A'' on a Hilbert space ''H''. The above lemma, together with the universal property of the multiplier algebra, yields that ''M''(''A'') is isomorphic to the [[idealizer]] of ''π''(''A'') in ''B''(''H''). It is immediate that ''M''(''K''(''H'')) = ''B''(''H'').\n\nLastly, let ''E'' be a Hilbert C*-module and ''B''(''E'') (resp. ''K''(''E'')) be the adjointable (resp. compact) operators on ''E'' ''M''(''A'') can be identified via a *-homomorphism of ''A'' into ''B''(''E''). Something similar to the above lemma is true:\n\n'''Lemma.''' If ''I'' is an ideal in a C*-algebra ''B'', then any faithful nondegenerate *-homomorphism ''π'' of ''I'' into  ''B''(''E'')can be extended ''uniquely'' to ''B''.\n\nConsequently, if ''π'' is a faithful nondegenerate *-homomorphism of ''A'' into ''B''(''E''), then ''M''(''A'') is isomorphic to the idealizer of ''π''(''A''). For instance, ''M''(''K''(''E'')) = ''B''(''E'') for any Hilbert module ''E''.\n\nThe C*-algebra ''A'' is isomorphic to the compact operators on the Hilbert module ''A''. Therefore, ''M''(''A'') is the adjointable operators on ''A''.\n\n== Strict topology ==\n\nConsider the topology on ''M''(''A'') specified by the [[seminorm]]s {''l<sub>a</sub>'', ''r<sub>a</sub>''}<sub>''a'' ∈ ''A''</sub>, where\n\n:<math>l_a (x) = \\|ax\\|,  \\; r_a(x) = \\| xa \\|.</math>\n\nThe resulting topology is called the '''strict topology''' on ''M''(''A''). ''A'' is strictly dense in ''M''(''A'') .\n\nWhen ''A'' is unital, ''M''(''A'') = ''A'', and the strict topology coincides with the norm topology. For ''B''(''H'') = ''M''(''K''(''H'')), the strict topology is the [[Topologies on the set of operators on a Hilbert space|&sigma;-strong* topology]]. It follows from above that ''B''(''H'') is complete in the σ-strong* topology.\n\n== Commutative case ==\n\nLet ''X'' be a [[locally compact]] [[Hausdorff space]], ''A'' = ''C''<sub>0</sub>(''X''), the commutative C*-algebra of continuous functions that [[vanish at infinity]]. Then ''M''(''A'') is ''C''<sub>''b''</sub>(''X''), the continuous bounded functions on ''X''. By the [[Gelfand-Naimark theorem]], one has the isomorphism of C*-algebras\n\n:<math>C_b(X) \\simeq C(Y)</math>\n\nwhere ''Y'' is the [[spectrum of a C*-algebra|spectrum]] of ''C''<sub>''b''</sub>(''X''). ''Y'' is in fact homeomorphic to the [[Stone–Čech compactification]] ''βX'' of ''X''.\n\n==Corona algebra==\n\nThe '''corona''' or '''corona algebra''' of ''A'' is the quotient ''M''(''A'')/''A''.\nFor example, the corona algebra of the algebra of compact operators on a Hilbert space is the [[Calkin algebra]].\n\nThe corona algebra is a noncommutative analogue of the [[corona set]] of a topological space.\n\n==References==\n\n*B. Blackadar,  ''K-Theory for Operator Algebras'', MSRI Publications, 1986.\n*{{Citation | last1=Busby | first1=Robert C. | title=Double centralizers and extensions of C*-algebras | jstor=1994883 | mr=0225175 | year=1968 | journal=[[Transactions of the American Mathematical Society]] | issn=0002-9947 | volume=132 | pages=79–99 | doi=10.2307/1994883}}\n*{{eom|id=m/m130260|title=Multipliers of C*-algebras|first=Gert K.|last= Pedersen}}\n\n[[Category:C*-algebras|*]]"
    },
    {
      "title": "Approximately finite-dimensional C*-algebra",
      "url": "https://en.wikipedia.org/wiki/Approximately_finite-dimensional_C%2A-algebra",
      "text": "In [[mathematics]], an '''approximately finite-dimensional (AF) C*-algebra''' is a [[C*-algebra]] that is the [[inductive limit]] of a [[sequence]] of [[dimension (linear algebra)|finite-dimensional]] C*-algebras. Approximate finite-dimensionality was first defined and described combinatorially by [[Ola Bratteli]]. Later, [[George A. Elliott]] gave a complete classification of AF algebras using the ''K''<sub>0</sub> functor whose range consists of [[ordered group|ordered abelian group]]s with sufficiently nice order structure.\n\nThe classification theorem for AF-algebras serves as a prototype for classification results for larger classes of [[separable space|separable]] [[simple algebra|simple]] [[nuclear C*-algebra|nuclear]] stably finite C*-algebras. Its proof divides into two parts. The invariant here is ''K''<sub>0</sub> with its natural order structure; this is a [[functor]]. First, one proves ''existence'': a homomorphism between invariants must lift to a *-homomorphism of algebras. Second, one shows ''uniqueness'': the lift must be unique up to approximate unitary equivalence. Classification then follows from what is known as ''the intertwining argument''. For unital AF algebras, both existence and uniqueness follow from the fact the Murray-von Neumann semigroup of projections in an AF algebra is cancellative.\n\nThe counterpart of simple AF C*-algebras in the [[von Neumann algebra]] world are the hyperfinite factors, which were classified by [[Alain Connes|Connes]] and [[Uffe Haagerup|Haagerup]].\n\nIn the context of [[noncommutative geometry]] and [[noncommutative topology|topology]], AF C*-algebras are noncommutative generalizations of ''C''<sub>0</sub>(''X''), where ''X'' is a [[totally disconnected]] [[metrizable]] space.\n\n== Definition and basic properties ==\n\n=== Finite-dimensional C*-algebras ===\n\nAn arbitrary finite-dimensional C*-algebra ''A'' takes the following form, up to isomorphism:\n\n:<math> \\oplus _k M_{n_k},</math>\n\nwhere ''M<sub>i</sub>'' denotes the full matrix algebra of ''i'' &times; ''i'' matrices.\n\nUp to unitary equivalence, a unital *-homomorphism Φ : ''M<sub>i</sub>'' → ''M<sub>j</sub>'' is necessarily of the form\n\n:<math>\\Phi (a) = a \\otimes I_r,</math>\n\nwhere ''r''·''i'' = ''j''. The number ''r'' is said to be the multiplicity of Φ. In general, a unital homomorphism between finite-dimensional C*-algebras\n\n:<math>\\Phi: \\oplus _1 ^s M_{n_k} \\rightarrow \\oplus _1 ^t M_{m_l}</math>\n\nis specified, up to unitary equivalence, by a ''t'' &times; ''s'' matrix of ''partial multiplicities'' (''r''<sub>''l k''</sub>) satisfying, for all ''l''\n\n:<math>\\sum_k r_{l k} n_k = m_l.\\;</math>\n\nIn the non-unital case, the equality is replaced by ≤. Graphically, Φ, equivalently (''r''<sub>''l k''</sub>), can be represented by its [[Bratteli diagram]]. The Bratteli diagram is a [[directed graph]] with nodes corresponding to each ''n<sub>k</sub>'' and ''m<sub>l</sub>'' and the number of arrows from ''n<sub>k</sub>'' to ''m<sub>l</sub>'' is the partial multiplicity ''r<sub>lk</sub>''.\n\nConsider the [[Category (mathematics)|category]] whose objects are isomorphism classes of finite-dimensional C*-algebras and whose morphisms are *-homomorphisms modulo unitary equivalence. By the above discussion, the objects can be viewed as vectors with entries in '''N''' and morphisms are the partial multiplicity matrices.\n\n=== AF algebras ===\n\nA C*-algebra is '''AF''' if it is the [[direct limit]] of a sequence of finite-dimensional C*-algebras:\n\n:<math> A = \\varinjlim \\cdots \\rightarrow A_i \\, \\stackrel{\\alpha_i}{\\rightarrow} A_{i+1} \\rightarrow \\cdots ,</math>\n\nwhere each ''A''<sub>''i''</sub> is a finite-dimensional C*-algebra and the connecting maps ''α''<sub>''i''</sub> are *-homomorphisms. We will assume that each ''α<sub>i</sub>'' is unital. The inductive system specifying an AF algebra is not unique. One can always drop to a subsequence. Suppressing the connecting maps, ''A'' can also be written as\n\n:<math>A = \\overline {\\cup_n A_n}.</math>\n\nThe '''[[Bratteli diagram]]''' of ''A'' is formed by the Bratteli diagrams of {''α<sub>i</sub>''} in the obvious way. For instance, the [[Pascal triangle]], with the nodes connected by appropriate downward arrows, is the Bratteli diagram of an AF algebra. A Bratteli diagram of the [[CAR algebra]] is given on the right. The two arrows between nodes means each connecting map is an embedding of multiplicity 2.\n\n:<math>1\\rightrightarrows2\\rightrightarrows4\\rightrightarrows8\\rightrightarrows\\dots</math>\n:(A Bratteli diagram of the CAR algebra)\n\nIf an AF algebra ''A'' = (∪<sub>''n''</sub>''A<sub>n</sub>'')<sup>−</sup>, then an ideal ''J'' in ''A'' takes the form  ∪<sub>''n''</sub> (''J'' ∩ ''A<sub>n</sub>'')<sup>−</sup>. In particular, ''J'' is itself an AF algebra. Given a Bratteli diagram of ''A'' and some subset ''S'' of nodes, the subdiagram generated by ''S'' gives inductive system that specifies an ideal of ''A''. In fact, every ideal arises in this way.\n\nDue to the presence of matrix units in the inductive sequence, AF algebras have the following local characterization: a C*-algebra ''A'' is AF if and only if ''A'' is separable and any finite subset of ''A'' is \"almost contained\" in some finite-dimensional C*-subalgebra.\n\nThe projections in ∪<sub>''n''</sub>''A<sub>n</sub>'' in fact form an [[approximate identity|approximate unit]] of ''A''.\n\nIt is clear that the extension of a finite-dimensional C*-algebra by another finite-dimensional C*-algebra is again finite-dimensional. More generally, the extension of an AF algebra by another AF algebra is again AF.<ref>Lawrence G. Brown. Extensions of AF Algebras: The Projection Lifting Problem. Operator Algebras and Applications, Proceedings of symposia in pure mathematics, vol. 38, Part 1, pp. 175-176, American Mathematical Soc., 1982</ref>\n\n== Classification ==\n\n=== K<sub>0</sub> ===\n\nThe [[Operator K-theory|K-theoretic]] group ''K<sub>0</sub>'' is an invariant of C*-algebras. It has its origins in [[topological K-theory]] and serves as the range of a kind of \"dimension function.\" For an AF algebra ''A'', ''K''<sub>0</sub>(''A'') can be defined as follows.\nLet ''M''<sub>''n''</sub>(''A'') be the C*-algebra of ''n'' &times; ''n'' matrices whose entries are elements of ''A''. ''M''<sub>''n''</sub>(''A'') can be embedded into ''M''<sub>''n'' + 1</sub>(''A'') canonically, into the \"upper left corner\". Consider the algebraic direct limit\n\n:<math> M _\\infty (A) = \\varinjlim \\cdots \\rightarrow M_n(A) \\rightarrow M_{n+1}(A) \\rightarrow \\cdots .</math>\n\nDenote the [[Projection (linear algebra)|projection]]s (self-adjoint idempotents) in this algebra by ''P''(''A''). Two elements ''p'' and ''q'' are said to be '''[[von Neumann algebra|Murray-von Neumann equivalent]]''', denoted by ''p'' ~ ''q'', if ''p'' = ''vv*'' and ''q'' = ''v*v'' for some [[partial isometry]] ''v'' in ''M''<sub>∞</sub>(''A''). It is clear that ~ is an equivalence relation. Define a binary operation + on the set of equivalences ''P''(''A'')/~ by\n\n:<math>[p] + [q] = [p \\oplus q]</math>\n\nwhere  ⊕ is the [[orthogonal direct sum]].{{clarify|reason=Do we require p orthogonal to q, and how does this affect the well-definedness?|date=September 2015}} This makes ''P''(''A'')/~ a [[semigroup]] that has the [[cancellation property]]. We denote this semigroup by ''K<sub>0</sub>''(''A'')<sup>+</sup>. Performing the [[Grothendieck group]] construction gives an abelian group, which is ''K<sub>0</sub>''(''A'').\n\n''K<sub>0</sub>''(''A'') carries a natural order structure: we say [''p''] ≤ [''q''] if ''p'' is Murray-von Neumann equivalent to a subprojection of ''q''. This makes ''K<sub>0</sub>''(''A'') an [[ordered group]] whose positive cone is ''K<sub>0</sub>''(''A'')<sup>+</sup>.\n\nFor example, for a finite-dimensional C*-algebra\n\n:<math> A = \\oplus _{k = 1} ^m M_{n_k},</math>\n\none has\n\n:<math> (K_0(A), K_0(A)^+) = (\\mathbb{Z}^m, \\mathbb{Z}_+ ^m).</math>\n\nTwo essential features of the mapping ''A'' {{mapsto}} ''K''<sub>0</sub>(''A'') are:\n#''K''<sub>0</sub> is a (covariant) [[functor]]. A *-homomorphism  ''α'' : ''A'' → ''B'' between AF algebras induces a group homomorphism ''α''<sub>*</sub> : ''K''<sub>0</sub>(''A'') → ''K''<sub>0</sub>(''B''). In particular, when ''A'' and ''B'' are both finite-dimensional, ''α''<sub>*</sub> can be identified with the partial multiplicities matrix of ''α''.\n#''K''<sub>0</sub> respects direct limits. If ''A'' = ∪<sub>''n''</sub>''α<sub>n</sub>''(''A<sub>n</sub>'')<sup>−</sup>, then ''K''<sub>0</sub>(''A'') is the direct limit ∪<sub>''n''</sub>''α''<sub>''n''*</sub>(''K''<sub>0</sub>(''A''<sub>''n''</sub>)).\n\n=== The dimension group ===\n\nSince ''M''<sub>∞</sub>(''M''<sub>∞</sub>(''A'')) is isomorphic to  ''M''<sub>∞</sub>(''A''), ''K''<sub>0</sub> can only distinguish AF algebras up to ''stable isomorphism''. For example, ''M''<sub>2</sub> and ''M''<sub>4</sub> are not isomorphic but stably isomorphic; ''K''<sub>0</sub>(''M''<sub>2</sub>) = ''K''<sub>0</sub>(''M''<sub>4</sub>) = '''Z'''.\n\nA finer invariant is needed to detect isomorphism classes. For an AF algebra ''A'', we define the '''scale''' of ''K''<sub>0</sub>(''A''), denoted by Γ(''A''), to be the subset whose elements are represented by projections in ''A'':\n\n:<math>\\Gamma(A) = \\{ [p] \\,|\\,  p^* = p^2 = p \\in A \\} .</math>\n\nWhen ''A'' is unital with unit 1<sub>''A''</sub>, the ''K''<sub>0</sub> element [1<sub>''A''</sub>] is the maximal element of Γ(''A'') and in fact,\n\n:<math>\\Gamma(A) = \\{x \\in K_0(A)\\,|\\, 0 \\leq x \\leq [1_A]\\}.</math>\n\nThe triple (''K''<sub>0</sub>, ''K''<sub>0</sub><sup>+</sup>, Γ(''A'')) is called the '''dimension group''' of ''A''.\nIf ''A'' = ''M<sub>s</sub>'', its dimension group is ('''Z''', '''Z'''<sup>+</sup>, {1, 2,..., ''s''}).\n\nA group homomorphism between dimension group is said to be '''contractive''' if it is scale-preserving. Two dimension group are said to be isomorphic if there exists a contractive group isomorphism between them.\n\nThe dimension group retains the essential properties of ''K''<sub>0</sub>:\n\n#A *-homomorphism  ''α'' : ''A'' → ''B'' between AF algebras in fact induces a contractive group homomorphism ''α''<sub>*</sub> on the dimension groups. When ''A'' and ''B'' are both finite-dimensional, corresponding to each partial multiplicities matrix ''ψ'', there is a unique, up to unitary equivalence, *-homomorphism ''α'' : ''A'' → ''B'' such that ''α''<sub>*</sub> = ''ψ''.\n#If ''A'' = ∪<sub>''n''</sub>''α<sub>n</sub>''(''A<sub>n</sub>'')<sup>−</sup>, then the dimension group of ''A'' is the direct limit of those of ''A<sub>n</sub>''.\n\n=== Elliott's theorem ===\n\n[[Image:Elliott's theorem.png|thumb|260px|right|Commutative diagrams for Elliott's theorem.]]\n\nElliott's theorem says that the dimension group is a complete invariant of AF algebras: two AF algebras ''A'' and ''B'' are isomorphic if and only if their dimension groups are isomorphic.\n\nTwo preliminary facts are needed before one can sketch a proof of Elliott's theorem. The first one summarizes the above discussion on finite-dimensional C*-algebras.\n\n'''Lemma'''  For two finite-dimensional C*-algebras ''A'' and ''B'', and a contractive homomorphism ''ψ'': ''K''<sub>0</sub>(''A'') → ''K''<sub>0</sub>(''B''), there exists a *-homomorphism ''φ'': ''A'' → ''B'' such that ''φ''<sub>*</sub> = ''ψ'', and ''φ'' is unique up to unitary equivalence.\n\nThe lemma can be extended to the case where ''B'' is AF. A map ''ψ'' on the level of ''K''<sub>0</sub> can be \"moved back\", on the level of algebras, to some finite stage in the inductive system.\n\n'''Lemma''' Let ''A'' be finite-dimensional and ''B'' AF, ''B'' = (∪<sub>''n''</sub>''B<sub>n</sub>'')<sup>−</sup>. Let ''β<sub>m</sub>'' be the canonical homomorphism of ''B<sub>m</sub>'' into ''B''. Then for any a contractive homomorphism ''ψ'': ''K''<sub>0</sub>(''A'') → ''K''<sub>0</sub>(''B''), there exists a *-homomorphism ''φ'': ''A'' → ''B<sub>m</sub>'' such that ''β<sub>m*</sub> φ''<sub>*</sub> = ''ψ'', and ''φ'' is unique up to unitary equivalence in ''B''.\n\nThe proof of the lemma is based on the simple observation that ''K''<sub>0</sub>(''A'') is finitely generated and, since ''K''<sub>0</sub> respects direct limits, ''K''<sub>0</sub>(''B'') = ∪<sub>''n''</sub> ''β<sub>n*</sub>'' ''K''<sub>0</sub> (''B<sub>n</sub>'').\n\n'''Theorem (Elliott)''' Two AF algebras ''A'' and ''B'' are isomorphic if and only if their dimension groups (''K''<sub>0</sub>(''A''), ''K''<sub>0</sub><sup>+</sup>(''A''), Γ(''A'')) and (''K''<sub>0</sub>(''B''), ''K''<sub>0</sub><sup>+</sup>(''B''), Γ(''B'')) are isomorphic.\n\nThe crux of the proof has become known as ''Elliott's intertwining argument''. Given an isomorphism between dimension groups, one constructs a diagram of commuting triangles between the direct systems of ''A'' and ''B'' by applying the second lemma.\n\nWe sketch the proof for the non-trivial part of the theorem, corresponding to the sequence of commutative diagrams on the right.\n\nLet Φ: (''K''<sub>0</sub>(''A''), ''K''<sub>0</sub><sup>+</sup>(''A''), Γ(''A'')) → (''K''<sub>0</sub>(''B''), ''K''<sub>0</sub><sup>+</sup>(''B''), Γ(''B'')) be a dimension group isomorphism.\n\n#Consider the composition of maps Φ ''α''<sub>1*</sub> : ''K''<sub>0</sub>(''A''<sub>1</sub>) →  ''K''<sub>0</sub>(''B''). By the previous lemma, there exists ''B''<sub>1</sub> and a *-homomorphism ''φ''<sub>1</sub>: ''A''<sub>1</sub> → ''B''<sub>1</sub> such that the first diagram on the right commutes.\n#Same argument applied to ''β''<sub>1*</sub> Φ<sup>−1</sup> shows that the second diagram commutes for some ''A''<sub>2</sub>. \n#Comparing diagrams 1 and 2 gives diagram 3.\n#Using the property of the direct limit and moving ''A''<sub>2</sub> further down if necessary, we obtain diagram 4, a commutative triangle on the level of ''K''<sub>0</sub>.\n#For finite-dimensional algebras, two *-homomorphisms induces the same map on ''K''<sub>0</sub> if and only if they are unitary equivalent. So, by composing ''ψ''<sub>1</sub> with a unitary conjugation if needed, we have a commutative triangle on the level of algebras.\n#By induction, we have a diagram of commuting triangles as indicated in the last diagram. The map ''φ'': ''A'' → ''B'' is the direct limit of the sequence {''φ<sub>n</sub>''}. Let ''ψ'': ''B'' → ''A'' is the direct limit of the sequence {''ψ<sub>n</sub>''}. It is clear that ''φ'' and ''ψ'' are mutual inverses. Therefore, ''A'' and ''B'' are isomorphic.\n\n[[Image:Elliott's theorem 2.png|thumb|170px|left]]\n\nFurthermore, on the level of ''K''<sub>0</sub>, the adjacent diagram commutates for each ''k''. By uniqueness of direct limit of maps, ''φ''<sub>*</sub> = Φ.\n\n{{clear}}\n\n===The Effros-Handelman-Shen theorem===\n\nThe dimension group of an AF algebra is a [[ordered group|Riesz group]]. The Effros-Handelman-Shen theorem says the converse is true. Every Riesz group, with a given scale, arises as the dimension group of some AF algebra. This specifies the range of the classifying functor ''K''<sub>0</sub> for AF-algebras and completes the classification.\n\n==== Riesz groups ====\n\nA group ''G'' with a partial order is called an [[ordered group]]. The set ''G''<sup>+</sup> of elements ≥ 0 is called the ''positive cone'' of ''G''. One says that ''G'' is unperforated if ''k''·''g'' ∈ ''G''<sup>+</sup>  implies ''g'' ∈ ''G''<sup>+</sup>.\n\nThe following property is called the '''Riesz decomposition property''': if ''x'', ''y<sub>i</sub>'' ≥ 0 and ''x'' ≤ ∑ ''y<sub>i</sub>'', then there exists ''x<sub>i</sub>'' ≥ 0 such that ''x'' = ∑ ''x<sub>i</sub>'', and ''x<sub>i</sub>'' ≤ ''y<sub>i</sub>'' for each ''i''.\n\nA '''Riesz group''' (''G'', ''G''<sup>+</sup>) is an ordered group that is unperforated and has the Riesz decomposition property.\n\nIt is clear that if ''A'' is finite-dimensional, (''K''<sub>0</sub>, ''K''<sub>0</sub><sup>+</sup>) is a Riesz group, where '''Z'''<sup>''k''</sup> is given entrywise order. The two properties of Riesz groups are preserved by direct limits, assuming the order structure on the direct limit comes from those in the inductive system. So (''K''<sub>0</sub>, ''K''<sub>0</sub><sup>+</sup>) is a Riesz group for an AF algebra ''A''.\n\nA key step towards the Effros-Handelman-Shen theorem is the fact that every Riesz group is the direct limit of '''Z'''<sup>''k''</sup> 's, each with the canonical order structure. This hinges on the following technical lemma, sometimes referred to as the '''Shen criterion''' in the literature.\n\n[[Image:Shen.png|right|thumb|260px|The Shen criterion.]]\n\n'''Lemma''' Let (''G'', ''G''<sup>+</sup>) be a Riesz group, ''ϕ'': ('''Z'''<sup>''k''</sup>, '''Z'''<sup>''k''</sup><sub>+</sub>) → (''G'', ''G''<sup>+</sup>) be a positive homomorphism. Then there exists maps ''σ'' and ''ψ'', as indicated in the adjacent diagram, such that ker(''σ'') = ker(''ϕ'').\n\n'''Corollary''' Every Riesz group (''G'', ''G''<sup>+</sup>) can be expressed as a direct limit\n\n:<math>(G, G^+) = \\varinjlim (\\mathbb{Z}^{n_k}, \\mathbb{Z}^{n_k}_+) ,</math>\n\nwhere all the connecting homomorphisms in the directed system on the right hand side are positive.\n\n==== The theorem ====\n\n'''Theorem''' If (''G'', ''G''<sup>+</sup>) is a countable Riesz group with scale Γ(''G''), then there exists an AF algebra ''A'' such that (''K''<sub>0</sub>, ''K''<sub>0</sub><sup>+</sup>, Γ(''A'')) = (''G'', ''G''<sup>+</sup>, Γ(''G'')). In particular, if Γ(''G'') = [0, ''u<sub>G</sub>''] with maximal element ''u<sub>G</sub>'', then ''A'' is unital with [1<sub>A</sub>] = [''u<sub>G</sub>''].\n\nConsider first the special case where Γ(''G'') = [0, ''u<sub>G</sub>''] with maximal element ''u<sub>G</sub>''. Suppose\n\n:<math>(G, G^+) = \\varinjlim (H_k, H_k^+) , \\quad \\mbox{where} \\quad (H, H_k^+) = (\\mathbb{Z}^{n_k}, \\mathbb{Z}^{n_k}_+).</math>\n\nDropping to a subsequence if necessary, let\n\n:<math>\\Gamma(H_1) = \\{ v \\in H_1^+ | \\phi_1(v) \\in \\Gamma(G) \\},</math>\n\nwhere ''φ''<sub>1</sub>(''u''<sub>1</sub>) = ''u<sub>G</sub>'' for some element ''u''<sub>1</sub>. Now consider the order ideal ''G''<sub>1</sub> generated by ''u''<sub>1</sub>. Because each ''H''<sub>1</sub>  has the canonical order structure, ''G''<sub>1</sub> is a direct sum of '''Z''' 's (with the number of copies possible less than that in ''H''<sub>1</sub>). So this gives a finite-dimensional algebra ''A''<sub>1</sub> whose dimension group is (''G''<sub>1</sub> ''G''<sub>1</sub><sup>+</sup>, [0, ''u''<sub>1</sub>]). Next move ''u''<sub>1</sub> forward by defining ''u''<sub>2</sub> = ''φ''<sub>12</sub>(''u''<sub>1</sub>). Again ''u''<sub>2</sub> determines a finite-dimensional algebra ''A''<sub>2</sub>. There is a corresponding homomorphism  ''α''<sub>12</sub> such that ''α''<sub>12*</sub> =  φ<sub>12</sub>. Induction gives a directed system\n\n:<math>A = \\varinjlim A_k ,</math>\n\nwhose ''K''<sub>0</sub> is\n\n:<math> \\varinjlim (G_k, G_k^+),</math>\n\nwith scale\n\n:<math>\\cup_k \\phi_k [0, u_k] = [0, u_G].</math>\n\nThis proves the special case.\n\nA similar argument applies in general. Observe that the scale is by definition a [[directed set]]. If Γ(''G'') = {''v<sub>k</sub>''}, one can choose ''u<sub>k</sub>'' ∈ Γ(''G'') such that ''u<sub>k</sub>''  ≥ ''v''<sub>1</sub>  ... ''v<sub>k</sub>''. The same argument as above proves the theorem.\n\n== Examples ==\n\nBy definition, [[uniformly hyperfinite algebra]]s are AF and unital. Their dimension groups are the subgroups of '''Q'''. For example, for the 2 &times; 2 matrices ''M''<sub>2</sub>, ''K''<sub>0</sub>(''M''<sub>2</sub>) is the group of rational numbers of the form ''a''/2 for ''a'' in '''Z'''. The scale is Γ(''M''<sub>2</sub>) = {0, ½, 1}. For the [[CAR algebra]] ''A'', ''K''<sub>0</sub>(''A'') is the group of [[dyadic rational]]s with scale ''K''<sub>0</sub>(''A'') ∩ [0, 1], with 1 = [1<sub>''A''</sub>]. All such groups are [[simple group|simple]], in a sense appropriate for ordered groups. Thus UHF algebras are simple C*-algebras. In general, the groups which are not dense in '''Q''' are the dimension groups of ''M<sub>k</sub>'' for some ''k''.\n\nCommutative C*-algebras, which were characterized by [[Gelfand representation|Gelfand]], are AF precisely when the [[spectrum of a C*-algebra|spectrum]] is [[totally disconnected]].<ref>Davidson 1996, p. 77.</ref> The continuous functions ''C''(''X'') on the [[Cantor set]] ''X'' is one such example.\n\n== Elliott's classification program ==\n\nIt was proposed by Elliott that other classes of C*-algebras may be classifiable by K-theoretic invariants. For a C*-algebra ''A'', the ''Elliott invariant'' is defined to be\n\n:<math>\\mbox{Ell}(A) \\; \\stackrel{\\mbox{def}}{=}\\; (\\; (K_0(A), K_0(A)^+, \\Gamma(A) ), K_1(A), T^+(A), \\rho_A \\;),</math>\n\nwhere ''T''<sup>+</sup>(''A'') is the tracial positivel linear functionals in the weak-* topology, and ''ρ<sub>A</sub>'' is the natural pairing between ''T''<sup>+</sup>(''A'') and ''K''<sub>0</sub>(''A'').\n\nThe original [[Elliott's classification program|conjecture]] by Elliott stated that the Elliott invariant classifies simple unital separable nuclear C*-algebras.\n\nIn the literature, one can find several conjectures of this kind with corresponding modified/refined Elliott invariants.\n\n== Von Neumann algebras ==\n\nIn a related context, an '''[[Von Neumann algebra#Amenable von Neumann algebras|approximately finite-dimensional]]''', or '''hyperfinite''', [[von Neumann algebra]] is one with a separable predual and contains a weakly dense AF C*-algebra. Murray and von Neumann showed that, up to isomorphism, there exists a unique  hyperfinite type II<sub>1</sub> factor. [[Alain Connes|Connes]] obtained the analogous result for the II<sub>∞</sub> factor. [[R.T. Powers|Powers]] exhibited a family of non-isomorphic type III hyperfinite factors with cardinality of the continuum. Today we have a complete classification of hyperfinite factors.\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n\n*Bratteli, O. (1972), ''[http://www.ams.org/tran/1972-171-00/S0002-9947-1972-0312282-2/S0002-9947-1972-0312282-2.pdf Inductive limits of finite dimensional C*-algebras]'', Trans. Amer. Math. Soc. '''171''', 195-234.\n*Davidson, K.R. (1996), ''C*-algebras by Example'', Field Institute Monographs '''6''', American Mathematical Society.\n*Effros, E.G., Handelman, D.E., and Shen C.L. (1980), ''Dimension groups and their affine representations'', Amer. J. Math. '''102''', 385-402.\n*Elliott, G.A. (1976), ''[http://www.sciencedirect.com/science/article/pii/0021869376902428/pdf?md5=fb0b57a59f1e6910a9abb5dbd8d9f626&pid=1-s2.0-0021869376902428-main.pdf&_valck=1 On the Classification of Inductive Limits of Sequences of Semisimple Finite-Dimensional Algebras]'', J. Algebra '''38''', 29-44.\n*Elliott, G.A. and Toms, A.S. (2008), ''[http://www.ams.org/bull/2008-45-02/S0273-0979-08-01199-3/S0273-0979-08-01199-3.pdf Regularity properties in the classification program for separable amenable C-algebras]'', Bull. Amer. Math. Soc. '''45''', 229-245.\n*Fillmore, P.A.(1996), ''A User's Guide for Operator Algebras'', Wiley-Interscience.\n*Rørdam, M. (2002), ''Classification of Nuclear C*-Algebras'', Encyclopaedia of Mathematical Sciences '''126''', Springer-Verlag.\n\n==External links==\n* {{springer|title=AF-algebra|id=p/a110420}}\n\n{{DEFAULTSORT:Approximately finite dimensional C-algebra}}\n[[Category:C*-algebras]]"
    },
    {
      "title": "Approximately finite-dimensional",
      "url": "https://en.wikipedia.org/wiki/Approximately_finite-dimensional",
      "text": "In [[operator algebra]]s, an algebra is said to be '''approximately finite-dimensional''' if it contains an increasing sequence of finite-dimensional subalgebras that is dense. One can consider\n\n*[[Approximately finite dimensional C*-algebra]]s, or\n*[[Von Neumann algebra#Amenable von Neumann algebras|Approximately finite-dimensional von Neumann algebra]]s.\n\n{{disambiguation}}\n[[Category:C*-algebras]]\n[[Category:Von Neumann algebras]]"
    },
    {
      "title": "AW*-algebra",
      "url": "https://en.wikipedia.org/wiki/AW%2A-algebra",
      "text": "In [[mathematics]], an '''AW*-algebra''' is an algebraic generalization of a [[W*-algebra]]. They were introduced by [[Irving Kaplansky]] in 1951.<ref name=kaplansky>{{cite journal|last=Kaplansky|first=Irving|title=Projections in Banach algebras|journal=Annals of Mathematics|year=1951|volume=53|pages=235–249|doi=10.2307/1969540|issue=2}}</ref> As [[operator algebra]]s, von Neumann algebras, among all [[C*-algebra]]s, are typically handled using one of two means: they are the dual space of some [[Banach space]], and they are determined to a large extent by their projections. The idea behind AW*-algebras is to forgo the former, topological, condition, and use only the latter, algebraic, condition.\n\n== Definition ==\n\nRecall that a [[Projection (linear algebra)#Orthogonal_projections|projection]] of a C*-algebra is a [[self-adjoint]] [[idempotent element (ring theory)|idempotent element]]. A C*-algebra ''A'' is an AW*-algebra if for every subset ''S'' of ''A'', the left [[annihilator (ring theory)|annihilator]]\n:<math>\\mathrm{Ann}_L(S)=\\{a\\in A\\mid \\forall s\\in S, as=0 \\}\\,</math>\nis generated as a left [[ideal (ring theory)|ideal]] by some projection ''p'' of ''A'', and similarly the right annihilator is generated as a right ideal by some projection ''q'':\n:<math>\\forall S \\subseteq A\\, \\exists p,q \\in \\mathrm{Proj}(A) \\colon \\mathrm{Ann}_L(S)=Ap, \\quad \\mathrm{Ann}_R(S)=qA</math>.\n\nHence an AW*-algebra is a C*-algebras that is at the same time a [[Baer *-ring]].\n\nThe original definition of Kaplansky states that an AW*-algebra is a C*-algebra such that (1) any set of orthogonal projections has a least upper bound, and (2) that each maximal commutative C*-subalgebra is generated by its projections. The first condition states that the projections have an interesting structure, while the second condition ensures that there are enough projections for it to be interesting <ref name=kaplansky></ref>. Note that the second condition is equivalent to the condition that each maximal commutative C*-subalgebra is monotone complete.\n\n== Structure theory ==\n\nMany results concerning von Neumann algebras carry over to AW*-algebras. For example, AW*-algebras can be classified according to the behavior of their projections, and decompose into [[W*-algebra#Factors|types]].<ref>{{cite book|last=Berberian|first=Sterling|title=Baer *-rings|year=1972|publisher=Springer}}</ref> For another example, [[normal matrix|normal matrices]] with entries in an AW*-algebra can always be diagonalized.<ref>{{cite journal|last=Heunen|first=Chris|author2=Reyes, Manuel L.|title=Diagonalizing matrices over AW*-algebras|journal=Journal of Functional Analysis|year=2013|volume=264|issue=8|pages=1873–1898|doi=10.1016/j.jfa.2013.01.022|arxiv=1208.5120}}</ref> AW*-algebras also always have [[polar decomposition]].<ref>{{cite journal|last=Ara|first=Pere|title=Left and right projections are equivalent in Rickart C*-algebras|journal=Journal of Algebra|year=1989|volume=120|pages=433–448|doi=10.1016/0021-8693(89)90209-3|issue=2}}</ref>\n\nHowever, there are also ways in which AW*-algebras behave differently from von Neumann algebras.<ref>{{cite web|last=Wright|first=J. D. Maitland|title=AW*-algebra|url=http://www.encyclopediaofmath.org/index.php/AW*-algebra|publisher=Springer}}</ref> For example, AW*-algebras of type I can exhibit pathological properties,<ref>{{cite journal|last=Ozawa|first=Masanao|title=Nonuniqueness of the cardinality attached to homogeneous AW*-algebras|journal=Proceedings of the American Mathematical Society|volume=93|year=1984|pages=681–684|doi=10.2307/2045544}}</ref> even though Kaplansky already showed that such algebras with trivial center are automatically von Neumann algebras.\n\n== The commutative case ==\nA commutative C*-algebra is an AW*-algebra if and only if its [[spectrum of a C*-algebra|spectrum]] is a [[Stonean space]]. Via [[Stone duality]], commutative AW*-algebras therefore correspond to [[complete lattice|complete]] [[Boolean algebra]]s. The projections of a commutative AW*-algebra form a complete Boolean algebra, and conversely, any complete Boolean algebra is isomorphic to the projections of some commutative AW*-algebra.\n\n== References ==\n{{reflist}}\n\n{{DEFAULTSORT:AW-algebra}}\n[[Category:C*-algebras]]\n[[Category:Operator theory]]"
    },
    {
      "title": "Baum–Connes conjecture",
      "url": "https://en.wikipedia.org/wiki/Baum%E2%80%93Connes_conjecture",
      "text": "In [[mathematics]], specifically in [[operator K-theory]], the '''Baum&ndash;Connes conjecture''' suggests a link between the [[operator K-theory|K-theory]] of the  [[reduced C*-algebra]] of a [[group theory|group]] and the [[K-homology]] of the [[classifying space]] of [[proper action]]s of that group. The conjecture sets up a correspondence between different areas of mathematics, with the K-homology of the classifying space being related to geometry, [[differential operator]] theory, and [[homotopy theory]], while the K-theory of the group's reduced C*-algebra is a purely analytical object.\n\nThe conjecture, if true, would have some older famous conjectures as consequences. For instance, the surjectivity part implies the Kadison–[[Kaplansky conjecture]] for a discrete [[torsion-free group]], and the injectivity is closely related to the [[Novikov conjecture]].\n\nThe conjecture is also closely related to [[index theory]], as the [[assembly map]] <math>\\mu</math> is a sort of index, and it plays a major role in [[Alain Connes]]' [[noncommutative geometry]] program.\n\nThe origins of the conjecture go back to [[Fredholm theory]], the [[Atiyah–Singer index theorem]] and the interplay of geometry with operator K-theory as expressed in the works of Brown, Douglas and Fillmore, among many other motivating subjects.\n\n==Formulation==\nLet Γ be a [[Second-countable space|second countable]] [[locally compact group]] (for instance a countable [[discrete group]]). One can define a [[morphism]]\n:<math> \\mu\\colon RK^\\Gamma_*(\\underline{E\\Gamma}) \\to K_*(C^*_r(\\Gamma)),</math>\ncalled the '''assembly map''', from the equivariant K-homology with <math>\\Gamma</math>-compact supports of the classifying space of proper actions <math>\\underline{E\\Gamma}</math> to the K-theory of the [[reduced C*-algebra]] of Γ. The subscript index <sub>*</sub> can be 0 or 1.\n\n[[Paul Baum (mathematician)|Paul Baum]] and [[Alain Connes]] introduced the following conjecture (1982) about this morphism:\n\n:The assembly map μ is an [[isomorphism]].\n\nAs the left hand side tends to be more easily accessible than the right hand side, because there are hardly any general structure theorems of the <math>C^*</math>-algebra, one usually views the conjecture as an \"explanation\" of the right hand side.\n\nThe original formulation of the conjecture was somewhat different, as the notion of equivariant K-homology was not yet common in 1982.\n\nIn case <math>\\Gamma</math> is discrete and torsion-free, the left hand side reduces to the non-equivariant K-homology with compact supports of the ordinary classifying space <math>B\\Gamma</math> of <math>\\Gamma</math>.\n\nThere is also more general form of the conjecture, known as Baum–Connes conjecture with coefficients, where both sides have coefficients in the form of a <math>C^*</math>-algebra <math>A</math> on which <math>\\Gamma</math> acts by <math>C^*</math>-automorphisms. It says in [[KK-theory|KK-language]] that the assembly map\n:<math> \\mu_{A,\\Gamma}\\colon RKK^\\Gamma_*(\\underline{E\\Gamma},A) \\to K_*(A\\rtimes_\\lambda \\Gamma),</math>\nis an isomorphism, containing the case without coefficients as the case <math>A=\\mathbb{C}</math>.\n\nHowever, counterexamples to the conjecture with coefficients were found in 2002 by [[Nigel Higson]], [[Vincent Lafforgue]] and [[Georges Skandalis]]. However, the conjecture with coefficients remains an active area of research, since it is, not unlike the classical conjecture, often seen as a statement concerning particular groups or class of groups.\n\n==Examples==\n\nLet <math>\\Gamma</math> be the integers <math>\\Z</math>. Then the left hand side is the [[K-homology]] of <math>B\\Z</math> which is the circle. The <math>C^*</math>-algebra of the integers is by the commutative Gelfand–Naimark transform, which reduces to the [[Fourier transform]] in this case, isomorphic to the algebra of continuous functions on the circle. So the right hand side is the topological K-theory of the circle. One can then show that the assembly map is [[KK-theory|KK-theoretic]] [[Poincaré duality]] as defined by [[Gennadi Kasparov]], which is an isomorphism.\n\n\n==Results==\n\nThe conjecture without coefficients is still open, although the field has received great attention since 1982.\nThe conjecture is proved for the following classes of groups:\n* Discrete subgroups of [[Indefinite orthogonal group|<math>SO(n,1)</math>]] and <math>SU(n,1)</math>.\n* Groups with the [[Haagerup property]], sometimes called [[a-T-menability|a-T-menable groups]]. These are groups that admit an isometric action on an affine Hilbert space <math>H</math> which is proper in the sense that <math>\\lim_{n\\to\\infty} g_n\\xi\\to\\infty</math> for all <math>\\xi\\in H</math> and all sequences of group elements <math>g_n</math> with <math>\\lim_{n\\to\\infty}g_n\\to\\infty</math>. Examples of a-T-menable groups are [[amenable group]]s, [[Coxeter group]]s, groups acting properly on [[Tree (graph theory)|trees]], and groups acting properly on simply connected [[CAT(k) space|<math>CAT(0)</math>]] cubical complexes.\n* Groups that admit a [[Presentation of a group|finite presentation]] with only one relation.\n* Discrete cocompact subgroups of real Lie groups of real rank 1.\n* Cocompact lattices in <math>SL(3,\\mathbb{R})</math>,<math>SL(3,\\mathbb{C})</math> or <math>SL(3,\\mathbb{Q}_p)</math>. It was a long-standing problem since the first days of the conjecture to expose a single infinite [[Kazhdan's property (T)|property T-group]] that satisfies it. However, such a group was given by V. Lafforgue in 1998 as he showed that cocompact lattices in <math>SL(3,\\mathbb{R})</math> have the property of rapid decay and thus satisfy the conjecture.\n* [[Hyperbolic group|Gromov hyperbolic groups]] and their subgroups.\n* Among non-discrete groups, the conjecture has been shown in 2003 by J. Chabert, S. Echterhoff and R. Nest for the vast class of all almost connected groups (i. e. groups having a cocompact connected component), and all groups of <math>k</math>-rational points of a [[linear algebraic group]] over a [[local field]] <math>k</math> of characteristic zero (e.g. <math>k = \\mathbb{Q}_p</math>). For the important subclass of real reductive groups, the conjecture had already been shown in 1987 by [[Antony Wassermann]].<ref>[https://mathscinet.ams.org/mathscinet-getitem?mr=894996 MathSciNet bibliographic data]</ref>\nInjectivity is known for a much larger class of groups thanks to the Dirac-dual-Dirac method. This goes back to ideas of [[Michael Atiyah]] and was developed in great generality by [[Gennadi Kasparov]] in 1987.\nInjectivity is known for the following classes:\n* Discrete subgroups of connected Lie groups or virtually connected Lie groups.\n* Discrete subgroups of [[P-adic number|p-adic groups]].\n* Bolic groups (a certain generalization of hyperbolic groups).\n* Groups which admit an amenable action on some compact space.\n\nThe simplest example of a group for which it is not known whether it satisfies the conjecture is <math>SL_3(\\Z)</math>.\n\n==References==\n<references />\n*{{Citation |first=Guido |last=Mislin |lastauthoramp=yes |first2=Alain |last2=Valette |year=2003 |title=Proper Group Actions and the Baum–Connes Conjecture |location=Basel |publisher=Birkhäuser |isbn=0-8176-0408-1 }}.\n*{{Citation |first=Alain |last=Valette |lastauthoramp=yes |year=2002 |title=Introduction to the Baum-Connes Conjecture |location=Basel |publisher=Birkhäuser |isbn=978-3-7643-6706-0}}.\n\n==External links==\n*[https://web.archive.org/web/20080221181939/http://www.math.ist.utl.pt/~matsnev/BCexpository.pdf On the Baum-Connes conjecture] by Dmitry Matsnev.\n\n{{DEFAULTSORT:Baum-Connes conjecture}}\n[[Category:C*-algebras]]\n[[Category:K-theory]]\n[[Category:Surgery theory]]\n[[Category:Conjectures]]"
    },
    {
      "title": "Bunce–Deddens algebra",
      "url": "https://en.wikipedia.org/wiki/Bunce%E2%80%93Deddens_algebra",
      "text": "{{Multiple issues|\n{{refimprove|date=August 2012}}\n{{one source|date=August 2012}}\n}}\n\n<!-- This will add a notice to the bottom of the page and won't blank it! The new template which says that your draft is waiting for a review will appear at the bottom; simply ignore the old (grey) drafted templates and the old (red) decline templates. A bot will update your article submission. Until then, please don't change anything in this text box and press \"Save page\". -->\n\nIn [[mathematics]], a '''Bunce–Deddens algebra''', named after [[John W. Bunce]] and [[James A. Deddens]], is a certain type of [[direct limit]] of matrix algebras over the continuous functions on the circle. They are therefore examples of simple unital '''[[AT algebra]]s'''. In the inductive system defining these algebras, the connecting maps between each stage are given by embeddings between families of [[shift operator]]s with periodic weights.\n\nEach inductive system defining a Bunce–Deddens algebra is associated with a [[supernatural number]], which is a complete invariant for these algebras. In the language of [[operator K-theory|K-theory]], the supernatural number correspond to the ''K''<sub>0</sub> group of the algebra. Also, Bunce–Deddens algebras can be expressed as the C*-[[crossed product]] of the [[Cantor set]] with a certain natural minimal action, so-called ''odometer action''. They also admit a unique [[tracial state]]. Together with the fact that they are AT, this implies they have [[real rank (C*-algebras)#Real rank zero|real rank zero]].\n\nIn a broader context of the classification program for [[simple (abstract algebra)|simple]] [[separable (topology)|separable]] [[nuclear C*-algebra]]s, AT-algebras of real rank zero were shown to be completely classified by their [[operator K-theory|K-theory]], the [[Choquet theory|Choquet simplex]] of [[state (functional analysis)|tracial state]]s, and the natural pairing between ''K''<sub>0</sub> and traces. The classification of Bunce–Deddens algebras is thus a precursor to the general result.\n\nIt is also known that, in general, crossed products arising from minimal homeomorphism on the Cantor set are simple AT-algebras of real rank zero.\n\n== Definition and basic properties ==\n\n=== Definition ===\n\nLet ''C''( '''T''' ) denote continuous functions on the circle and ''M<sub>r</sub>''(''C''('''T''')) be the C*-algebra of ''r'' &times; ''r'' matrices with entries in ''C''('''T'''). For a supernatural number {''n''<sub>''k''</sub>}, the corresponding '''Bunce–Deddens algebra''' ''B''({''n''<sub>''k''</sub>}) is the direct limit:\n\n:<math> \nB(\\{n_k\\}) = \\varinjlim \\cdots \\rightarrow M_{n_k}(C( \\mathbb{T} )) \\; \\stackrel{\\beta_k}{\\rightarrow} \\; M_{n_{k+1}}( C(\\mathbb{T} )  ) \\rightarrow \\cdots .\n</math>\n \nOne needs to define the embeddings\n\n:<math>\\beta_k : M_{n_k}(C( \\mathbb{T} )) \\; \\rightarrow \\; M_{n_{k+1}}(C( \\mathbb{T}  )).</math>\n\nThese imbedding maps arise from the natural embeddings between C*-algebras generated by shifts with periodic weights. For integers ''n'' and ''m'', we define an embedding ''&beta;'' : ''M<sub>n</sub>''(''C''('''T''')) &rarr; ''M<sub>nm</sub>''(''C''('''T''')) as follows. On a separable Hilbert space ''H'', consider the C*-algebra ''W''(''n'') generated by weighted shifts of fixed period ''n'' with respect to a fixed basis. ''W''(''n'') embedds into ''W''(''nm'') in the obvious way; any ''n''-periodic weighted shift is also a ''nm''-periodic weighted shift. ''W''(''n'') is isomorphic to ''M<sub>n</sub>''(''C''*(''T<sub>z</sub>'')), where ''C''*(''T<sub>z</sub>'') denotes the [[Toeplitz algebra]]. Therefore, ''W'' contains the [[compact operator on Hilbert space|compact operator]]s as an ideal, and modulo this ideal it is ''M<sub>n</sub>''(''C''('''T''')). Because the map from ''W''(''n'') into ''W''(''nm'') preserves the compact operators, it descends into an embedding ''&beta;'' : ''M<sub>n</sub>''(''C''('''T''')) &rarr; ''M<sub>nm</sub>''(''C''('''T''')). It is this embedding that is used in the definition of Bunce–Deddens algebras.\n\n=== The connecting maps ===\n\nThe ''&beta;<sub>k</sub>'''s can be computed more explicitly and we now sketch this computation. This will be useful in obtaining an alternative characterization description of the Bunce–Deddens algebras, and also the classification of these algebras.\n\nThe C*-algebra ''W''(''n'') is in fact singly generated. A particular generator of ''W''(''n'') is the  weighted shift ''T'' of period ''n'' with periodic weights ½, &hellip;, ½, 1, ½, &hellip;, ½, 1, &hellip;. In the appropriate basis of ''H'', ''T'' is represented by the ''n'' &times; ''n'' operator matrix\n\n:<math>T = \n\\begin{bmatrix}\n0              & \\;           & \\cdots            & T_z          \\\\\n\\frac{1}{2}I   & \\ddots       & \\ddots            & \\;           \\\\\n\\;             & \\ddots       & \\ddots            & \\vdots       \\\\\n\\;             & \\;           & \\frac{1}{2}I      & 0      \n\\end{bmatrix},\n</math>\n \nwhere ''T<sub>z</sub>'' is the [[unilateral shift]]. A direct calculation using [[functional calculus]] shows that the C*-algebra generated by ''T'' is ''M<sub>n</sub>''(''C''*(''T<sub>z</sub>'')), where ''C''*(''T<sub>z</sub>'') denotes the [[Toeplitz algebra]], the C*-algebra generated by the unilateral shift. Since it is clear that ''M<sub>n</sub>''(''C''*(''T<sub>z</sub>'')) contains ''W''(''n''), this shows ''W''(''n'') = ''M<sub>n</sub>''(''C''*(''T<sub>z</sub>'')).\n\nFrom the Toeplitz [[short exact sequence]],\n\n:<math>0 \\rightarrow  \\mathcal{K} \\; {\\rightarrow} \\; C^*(T_z) \\; {\\rightarrow} \\; C( \\mathbb{T} ) \\rightarrow 0,</math>\n\none has,\n\n:<math>0 \\rightarrow  M_n(\\mathcal{K}) \\; \\stackrel{i}{\\hookrightarrow} \\; M_n(C^*(T_z)) \\; \\stackrel{j}{\\rightarrow} \\; M_n(C( \\mathbb{T} )) \\rightarrow 0,</math>\n\nwhere ''i'' is the entrywise embedding map and ''j'' the entrywise quotient map on the Toeplitz algebra. So the C*-algebra ''M<sub> n<sub>k</sub> </sub>''(''C'' ('''T''')) is singly generated by\n\n:<math>\\tilde{T} = \n\\begin{bmatrix}\n0              & \\;           & \\cdots            & z          \\\\\n\\frac{1}{2}    & \\ddots       & \\ddots            & \\;           \\\\\n\\;             & \\ddots       & \\ddots            & \\vdots       \\\\\n\\;             & \\;           & \\frac{1}{2}      & 0      \n\\end{bmatrix},\n</math>\n\nwhere the scalar entries denote constant functions on the circle and ''z'' is the identity function.\n\nFor integers ''n<sub>k</sub>'' and ''n''<sub>''k'' + 1</sub>, where ''n<sub>k</sub>'' divides ''n''<sub>''k'' + 1</sub>, the natural embedding of ''W''(''n<sub>k</sub>'') into ''W''(''n''<sub>''k'' + 1</sub>) descends into an (unital) embedding from  \n''M<sub>n<sub>k</sub></sub>''(''C''('''T''')) into ''M''<sub> ''n''<sub>''k'' + 1</sub></sub>(''C''('''T''')). This is the connecting map ''&beta;<sub>k</sub>'' from the definition of the Bunce–Deddens algebra that we need to analyze.\n\nFor simplicity, assume ''n<sub>k</sub>'' = ''n'' and ''n''<sub>''k'' + 1</sub> = 2''n<sub>k</sub>''. \nThe image of the above operator ''T'' &isin; ''W''(''n'') under the natural embedding is the following 2''n'' &times; 2''n'' operator matrix in ''W''(2''n''):\n\n:<math>T \\mapsto \n\\begin{bmatrix}\n0              & \\;        &                &        &            & \\;      &              & T_z          \\\\\n\\frac{1}{2}I   & \\ddots    &                &        &            &         &              & 0            \\\\\n\\;             & \\ddots    & \\ddots         &        &            &         &              & \\vdots       \\\\\n\\;             & \\;        & \\frac{1}{2}I   & 0      &            & \\;      &              &              \\\\\n               & \\;        &                & I      & 0          &         &              &              \\\\\n               &           &                & \\;     &\\frac{1}{2}I& \\ddots  &              & \\;           \\\\\n\\;             &           &                &        &\\;          & \\ddots  & \\ddots       & \\vdots       \\\\\n\\;             & \\;        &                &        &\\;          & \\;       & \\frac{1}{2}I      & 0          \n\\end{bmatrix} \n.\n</math>\n\nTherefore, the action of the ''&beta;<sub>k</sub>'' on the generator is\n\n:<math> \\beta_k (\\tilde{T}) =  \n\\begin{bmatrix}\n0              & \\;        &                &        &            & \\;      &              &   z          \\\\\n\\frac{1}{2}    & \\ddots    &                &        &            &         &              & 0            \\\\\n\\;             & \\ddots    & \\ddots         &        &            &         &              & \\vdots       \\\\\n\\;             & \\;        & \\frac{1}{2}    & 0      &            & \\;      &              &              \\\\\n               & \\;        &                & 1      & 0          &         &              &              \\\\\n               &           &                & \\;     &\\frac{1}{2} & \\ddots  &              & \\;           \\\\\n\\;             &           &                &        &\\;          & \\ddots  & \\ddots       & \\vdots       \\\\\n\\;             & \\;        &                &        &\\;          & \\;      & \\frac{1}{2}  & 0          \n\\end{bmatrix} \n.\n</math>\n\nA computation with matrix units yields that\n\n:<math>\\beta_k (E_{ij}) = E_{ij} \\otimes I_2</math>\n\nand\n\n:<math>\\beta_k(z E_{11}) = E_{11} \\otimes \\Zeta_2,</math>\n\nwhere\n\n:<math>\\Zeta_2 = \n\\begin{bmatrix}\n0              & z    \\\\\n1              & 0          \n\\end{bmatrix} \\in M_2(C( \\mathbb{T})).\n</math>\n\nSo\n\n:<math>\\beta_k( f_{ij}(z) ) = f_{ij}(\\Zeta_2).\\;</math>\n\nIn this particular instance, ''&beta;<sub>k</sub>'' is called a '''twice-around embedding'''. The reason for the terminology is as follows: as ''z'' varies on the circle, the eigenvalues of Z<sub>2</sub> traces out the two disjoint arcs connecting 1 and -1. An explicit computation of eigenvectors shows that the circle of unitaries implementing the diagonalization of Z<sub>2</sub> in fact connect the beginning and end points of each arc. So in this sense the circle gets wrap around twice by Z<sub>2</sub>. In general, when  ''n''<sub>''k'' + 1</sub> = ''m''&middot;''n''<sub>''k''</sub>, one has a similar '''''m''-times around embedding'''.\n\n== K-theory and classification ==\n\nBunce–Deddens algebras are classified by their ''K''<sub>0</sub> groups. Because all finite-dimensional [[vector bundle]]s over the circle are homotopically trivial, the ''K''<sub>0</sub> of ''M<sub>r</sub>''(''C''('''T''')), as an [[ordered group|ordered abelian group]], is the integers '''Z''' with canonical ordered unit ''r''. According to the above calculation of the connecting maps, given a supernatural number {''n<sub>k</sub>''}, the ''K''<sub>0</sub> of the corresponding Bunce–Deddens algebra is precisely the corresponding dense subgroup of the rationals '''Q'''.\n\nAs it follows from the definition that two Bunce–Deddens algebras with the same supernatural number, in the sense that the two supernatural numbers formally divide each other, are isomorphic, ''K''<sub>0</sub> is a complete invariant of these algebras.\n\nIt also follows from the previous section that the ''K''<sub>1</sub> group of any Bunce–Deddens algebra is '''Z'''.\n\n== As a crossed product ==\n\n=== C*-crossed product ===\n{{Further information| Crossed product}}\n\nA '''C*-dynamical system''' is a triple (''A'', ''G'', ''&sigma;''), where ''A'' is a C*-algebra, ''G'' a group, and ''&sigma;'' an action of ''G'' on ''A'' via C*-automorphisms. A '''covariant representation''' of (''A'', ''G'', ''&sigma;'') is a representation ''&pi;'' of ''A'', and a [[unitary representation]] ''t'' <math>\\mapsto</math> ''U<sub>t</sub>'' of ''G'', on the same Hilbert space, such that\n\n:<math>U_t \\pi(a) U_t^* = \\pi(\\sigma(t)(a)),</math>\n\nfor all ''a'', ''t''.\n\nAssume now ''A'' is unital and ''G'' is discrete. The (C*-)'''crossed product''' given by (''A'', ''G'', ''&sigma;''), denoted by\n\n:<math>A \\rtimes_{\\sigma} G,</math>\n\nis defined to be the C*-algebra with the following [[universal property]]: for any covariant representation (''&pi;'', ''U''), the C*-algebra generated by its image is a quotient of\n\n:<math>A \\rtimes_{\\sigma} G.</math>\n\n=== Odometer action on Cantor set ===\n\nThe Bunce–Deddens algebras in fact are crossed products of the [[Cantor set]]s with a natural action by the integers '''Z'''.  Consider, for example, the Bunce–Deddens algebra of type 2<sup>&infin;</sup>. Write the Cantor set ''X'' as sequences of 0's and 1's,\n\n:<math>X = \\prod \\{ 0,1 \\} ,</math>\n\nwith the product topology. Define a homeomorphism\n\n:<math>\\alpha: X \\rightarrow X</math>\n\nby\n\n:<math>\\alpha (x) = x + (\\cdots, 0, 0, 1)</math>\n\nwhere + denotes addition with carryover. This is called the '''odometer action'''. The homeomorphism ''&alpha;'' induces\nan action on ''C''(''X'') by pre-composition with ''&alpha;''. The Bunce–Deddens algebra of type 2<sup>&infin;</sup> is isomorphic to the resulting crossed product.\n\n== References ==\n*{{citation|first=K.R.|last= Davidson|title=C*-algebras by Example|publisher=American Mathematical Society  |year=1996| isbn =978-0821805992}}\n\n{{DEFAULTSORT:Bunce-Deddens algebra}}\n[[Category:C*-algebras]]"
    },
    {
      "title": "Calkin algebra",
      "url": "https://en.wikipedia.org/wiki/Calkin_algebra",
      "text": "In [[functional analysis]], the '''Calkin algebra''', named after John Wilson Calkin<ref>https://www.genealogy.math.ndsu.nodak.edu/id.php?id=22867</ref>, is the [[quotient space (linear algebra)|quotient]] of ''B''(''H''), the [[ring (algebra)|ring]] of [[bounded linear operator]]s on a [[separable space|separable]] infinite-dimensional [[Hilbert space]] ''H'', by the [[ideal (ring theory)|ideal]] ''K''(''H'') of [[Compact operator on Hilbert space|compact operator]]s.<ref>{{cite journal|last=Calkin|first=J. W.|title=Two-Sided Ideals and Congruences in the Ring of Bounded Operators in Hilbert Space|journal=The Annals of Mathematics|date=1 October 1941|volume=42|issue=4|pages=839|doi=10.2307/1968771}}</ref> Here the addition in ''B''(''H'') is addition of operators and the multiplication in ''B''(''H'') is composition of operators; it is easy to verify that these operations make ''B''(''H'') into a ring. When scalar multiplication is also included, ''B''(''H'') becomes in fact an algebra over the same field over which ''H'' is a Hilbert space.\n\n== Properties ==\n\n* Since ''K''(''H'') is a maximal norm-closed ideal in ''B''(''H''), the Calkin algebra is [[simple algebra|simple]]. In fact, ''K''(''H'') is the only closed ideal in ''B''(''H'').\n\n* As a quotient of a [[C* algebra]] by a two-sided ideal, the Calkin algebra is a C* algebra itself and there is a [[short exact sequence]]\n::<math>0 \\to K(H) \\to B(H) \\to B(H)/K(H) \\to 0</math>\n:which induces a [[Bott periodicity|six-term cyclic exact sequence]] in [[operator K-theory|K-theory]]. Those operators in ''B''(''H'') which are mapped to an invertible element of the Calkin algebra are called [[Fredholm operator]]s, and their [[linear map#Index|index]] can be described both using K-theory and directly. One can conclude, for instance, that the collection of unitary operators in the Calkin algebra consists of homotopy classes indexed by the integers '''Z'''. This is in contrast to ''B''(''H''), where the unitary operators are path connected.\n\n* As a C*-algebra, the Calkin algebra is not isomorphic to an algebra of operators on a separable Hilbert space. The [[Gelfand-Naimark-Segal construction]] implies that the Calkin algebra isomorphic to an algebra of operators on a nonseparable Hilbert space, but while for many other C*-algebras there are explicit descriptions of such Hilbert spaces, the Calkin algebra does not have an explicit representation.{{citation needed|date=January 2016}}\n\n* The existence of an outer automorphism of the Calkin algebra is shown to be independent of [[ZFC]], by work of Phillips and Weaver, and Farah.<ref>{{cite journal|last=Phillips|first=N. Christopher|author2=Weaver, Nik|title=The Calkin algebra has outer automorphisms|journal=Duke Mathematical Journal|date=1 July 2007|volume=139|issue=1|pages=185–202|doi=10.1215/S0012-7094-07-13915-2|arxiv=math/0606594}}</ref><ref>{{cite journal|last=Farah|first=Ilijas|title=All automorphisms of the Calkin algebra are inner|journal=Annals of Mathematics|date=1 March 2011|volume=173|issue=2|pages=619–661|doi=10.4007/annals.2011.173.2.1|arxiv=0705.3085}}</ref>\n\n== Generalizations ==\n\n* One can define a Calkin algebra for any infinite-dimensional complex Hilbert space, not just separable ones.\n\n* An analogous construction can be made by replacing ''H'' with a [[Banach space]], which is also called a Calkin algebra.<ref>{{cite journal|last=Appell|first=Jürgen|title=Measures of noncompactness, condensing operators and fixed points: An application-oriented survey |journal=Fixed Point Theory|volume=6|issue=2|pages=157–229|year=2005}}</ref>\n\n* The Calkin algebra is the [[Corona algebra]] of the algebra of compact operators on a Hilbert space.\n\n==References==\n<references />\n\n[[Category:Operator theory]]\n[[Category:C*-algebras]]\n[[Category:K-theory]]"
    },
    {
      "title": "Compact quantum group",
      "url": "https://en.wikipedia.org/wiki/Compact_quantum_group",
      "text": "{{Refimprove|date=December 2009}}\n\nIn [[mathematics]], a '''compact quantum group''' is an abstract structure on a unital separable [[C*-algebra]] axiomatized from those that exist on the commutative C*-algebra of \"continuous complex-valued functions\" on a compact quantum group.\n\nThe basic motivation for this theory comes from the following analogy. The space of  complex-valued functions on a compact Hausdorff topological space forms a ''commutative'' C*-algebra. On the other hand, by the [[Gelfand representation|Gelfand Theorem]], a commutative C*-algebra is isomorphic to the C*-algebra of continuous complex-valued functions on a compact Hausdorff topological space, and the topological space is uniquely determined by the C*-algebra up to [[homeomorphism]].\n\n[[S. L. Woronowicz]] <ref>Woronowicz, S.L. \"Compact Matrix Pseudogrooups\", Commun. Math. Phys. 111 (1987), 613-665</ref> introduced the important concept of '''compact matrix quantum groups''', which he initially called '''compact pseudogroups'''. Compact matrix quantum groups are abstract structures on which the \"continuous functions\" on the structure are given by elements of a C*-algebra. The geometry of a compact matrix quantum group is a special case of a [[noncommutative geometry]].\n\n==Formulation==\nFor a compact [[topological group]], {{mvar|G}}, there exists a C*-algebra homomorphism\n\n:<math> \\Delta : C(G) \\to C(G) \\otimes C(G) </math>\n\nwhere {{math|''C''(''G'') ⊗ ''C''(''G'')}} is the minimal C*-algebra tensor product &mdash; the completion of the algebraic [[tensor product]] of {{math|''C''(''G'')}} and {{math|''C''(''G'')}}) &mdash; such that\n\n:<math>\\Delta(f)(x,y) = f(xy)</math>\n\nfor all <math> f \\in C(G) </math>, and for all <math>x, y \\in G</math>, where\n\n:<math> (f \\otimes g)(x,y) = f(x) g(y) </math>\n\nfor all <math> f, g \\in C(G) </math> and all <math> x, y \\in G </math>.  There also exists a linear multiplicative mapping\n\n:<math> \\kappa : C(G) \\to C(G) </math>,\n\nsuch that\n\n:<math>\\kappa(f)(x) = f(x^{-1})</math>\n\nfor all <math> f \\in C(G) </math> and all <math> x \\in G </math>. Strictly speaking, this does not make {{math|''C''(''G'')}} into a [[Hopf algebra]], unless {{mvar|G}} is finite.\n\nOn the other hand, a finite-dimensional [[group representation|representation]] of {{mvar|G}} can be used to generate a [[*-algebra|*-subalgebra]] of {{math|''C''(''G'')}} which is also a Hopf *-algebra.  Specifically, if\n\n:<math>g \\mapsto (u_{ij}(g))_{i,j}</math>\n\nis an {{mvar|n}}-dimensional representation of {{mvar|G}}, then\n\n:<math>u_{ij} \\in C(G)</math>\n\nfor all {{math|''i'', ''j''}}, and\n\n:<math>\\Delta(u_{ij}) = \\sum_k u_{ik} \\otimes u_{kj}</math>\n\nfor all {{math|''i'', ''j''}}. It follows that the [[*-algebra]] generated by <math>u_{ij}</math> for all {{math|''i'', ''j''}} and <math>\\kappa(u_{ij})</math> for all {{math|''i'', ''j''}} is a Hopf *-algebra: the counit is determined by\n\n:<math>\\epsilon(u_{ij}) = \\delta_{ij}</math>\n\nfor all <math>i, j</math> (where <math>\\delta_{ij}</math> is the [[Kronecker delta]]), the antipode is {{mvar|κ}}, and the unit is given by\n\n:<math>1 = \\sum_k u_{1k} \\kappa(u_{k1}) = \\sum_k \\kappa(u_{1k}) u_{k1}.</math>\n\n==Compact Matrix Quantum Groups==\nAs a generalization, a '''compact matrix quantum group''' is defined as a pair {{math|(''C'', ''u'')}}, where {{mvar|C}} is a C*-algebra and\n\n:<math>u = (u_{ij})_{i,j = 1,\\dots,n}</math>\n\nis a matrix with entries in {{mvar|C}} such that\n\n* The *-subalgebra, {{math|''C''<sub>0</sub>}}, of {{mvar|C}}, which is generated by the matrix elements of {{mvar|u}}, is dense in {{mvar|C}};\n* There exists a C*-algebra homomorphism, called the comultiplication, {{math|Δ : ''C'' → ''C'' ⊗ ''C''}} (here {{math|''C'' ⊗ ''C''}} is the C*-algebra tensor product - the completion of the algebraic tensor product of {{mvar|C}} and {{mvar|C}}) such that \n::<math>\\forall i, j: \\qquad \\Delta(u_{ij}) = \\sum_k u_{ik} \\otimes u_{kj};</math>\n\n* There exists a linear antimultiplicative map, called the coinverse, {{math|''κ'' : ''C''<sub>0</sub> → ''C''<sub>0</sub>}} such that <math>\\kappa(\\kappa(v*)*) = v</math> for all <math>v \\in C_0</math> and <math>\\sum_k \\kappa(u_{ik}) u_{kj} = \\sum_k u_{ik} \\kappa(u_{kj}) = \\delta_{ij} I,</math> where {{mvar|I}} is the identity element of {{mvar|C}}. Since {{mvar|κ}} is antimultiplicative, {{math|''κ''(''vw'') {{=}} ''κ''(''w'')''κ''(''v'')}} for all <math>v, w \\in C_0</math>.\n\nAs a consequence of continuity, the comultiplication on {{mvar|C}} is coassociative.\n\nIn general, {{mvar|C}} is a bialgebra, and {{math|''C''<sub>0</sub>}} is a Hopf *-algebra.\n\nInformally, {{mvar|C}} can be regarded as the *-algebra of continuous complex-valued functions over the compact matrix quantum group, and {{mvar|u}} can be regarded as a finite-dimensional representation of the compact matrix quantum group.\n\n==Compact Quantum Groups==\nFor  C*-algebras {{mvar|A}} and {{mvar|B}} acting on the Hilbert spaces {{mvar|H}} and {{mvar|K}} respectively, their minimal tensor product is defined to be the norm completion of the algebraic tensor product {{math|''A'' ⊗ ''B''}} in {{math|''B''(''H'' ⊗ ''K'')}}; the norm completion is also denoted by {{math|''A'' ⊗ ''B''}}.\n\nA compact quantum group<ref>Woronowicz, S.L. \"Compact Quantum Groups\". Notes from http://www.fuw.edu.pl/~slworono/PDF-y/CQG3.pdf</ref><ref>van Daele, A. and Maes, Ann. \"Notes on compact quantum groups\", arXiv:math/9803122</ref> is defined as a pair {{math|(''C'', Δ)}}, where {{mvar|C}} is a unital separable C*-algebra and\n\n*{{math|Δ : ''C'' → ''C'' ⊗ ''C''}} is a C*-algebra unital homomorphism satisfying {{math|(Δ ⊗ id) Δ {{=}} (id ⊗ Δ) Δ}};\n* the sets {{math|{(''C'' ⊗ 1) Δ(''C'')} }} and {{math|{(1 ⊗ ''C'') Δ(''C'')} }} are dense in {{math|''C'' ⊗ ''C''}}.\n\n==Representations==\nA representation of the compact matrix quantum group is given by a [[coalgebra|corepresentation]] of the Hopf *-algebra<ref>a corepresentation of a counital coassiative coalgebra {{mvar|A}} is a square matrix\n\n:<math>v = (v_{ij})_{i,j = 1,\\dots,n}</math>\n\nwith entries in {{mvar|A}} (so that {{math|''v'' ∈ M(''n'', ''A'')}}) such that\n\n:<math>\\forall i, j: \\qquad \\Delta(v_{ij}) = \\sum_{k=1}^n v_{ik} \\otimes v_{kj}</math>\n:<math>\\forall i, j: \\qquad \\epsilon(v_{ij}) = \\delta_{ij}.</math></ref> Furthermore, a representation, ''v'', is called unitary if the matrix for ''v'' is unitary, or equivalently, if\n\n:<math>\\forall i, j: \\qquad \\kappa(v_{ij}) = v^*_{ji}.</math>\n\n==Example==\nAn example of a compact matrix quantum group is {{math|SU<sub>''μ''</sub>(2)}},<ref>van Daele, A. and Wang, S. \"Universal quantum groups\" Int. J. Math. (1996), 255-263.</ref> where the parameter {{mvar|μ}} is a positive real number.\n\n===First Definition===\n{{math|SU<sub>''μ''</sub>(2) {{=}} (''C''(SU<sub>''μ''</sub>(2)), ''u'')}}, where {{math|''C''(SU<sub>''μ''</sub>(2))}} is the C*-algebra generated by {{mvar|α}} and {{mvar|γ}}, subject to\n\n:<math>\\gamma \\gamma^* = \\gamma^* \\gamma, \\ \\alpha \\gamma = \\mu \\gamma \\alpha, \\ \\alpha \\gamma^* = \\mu \\gamma^* \\alpha, \\ \\alpha \\alpha^* + \\mu \\gamma^* \\gamma = \\alpha^* \\alpha + \\mu^{-1} \\gamma^* \\gamma = I,</math>\n\nand\n\n:<math>u = \\left( \\begin{matrix} \\alpha & \\gamma \\\\ - \\gamma^* & \\alpha^* \\end{matrix} \\right),</math>\n\nso that the comultiplication is determined by <math>\\Delta(\\alpha) = \\alpha \\otimes \\alpha - \\gamma \\otimes \\gamma^*, \\Delta(\\gamma) = \\alpha \\otimes \\gamma + \\gamma \\otimes \\alpha^*</math>, and the coinverse is determined by <math>\\kappa(\\alpha) = \\alpha^*, \\kappa(\\gamma) = - \\mu^{-1} \\gamma, \\kappa(\\gamma^*) = - \\mu \\gamma^*, \\kappa(\\alpha^*) = \\alpha</math>. Note that {{mvar|u}} is a representation, but not a [[unitary representation]]. {{mvar|u}} is equivalent to the unitary representation \n:<math>v = \\left( \\begin{matrix} \\alpha & \\sqrt{\\mu} \\gamma \\\\ - \\frac{1}{\\sqrt{\\mu}} \\gamma^* & \\alpha^* \\end{matrix} \\right).</math>\n\n===Second Definition===\n{{math|SU<sub>''μ''</sub>(2) {{=}} (''C''(SU<sub>''μ''</sub>(2)), ''w'')}}, where  {{math|''C''(SU<sub>''μ''</sub>(2))}} is the C*-algebra generated by {{mvar|α}} and {{mvar|β}}, subject to\n\n:<math>\\beta \\beta^* = \\beta^* \\beta, \\ \\alpha \\beta = \\mu \\beta \\alpha, \\ \\alpha \\beta^* = \\mu \\beta^* \\alpha, \\ \\alpha \\alpha^* + \\mu^2 \\beta^* \\beta = \\alpha^* \\alpha + \\beta^* \\beta = I,</math>\n\nand \n:<math>w = \\left( \\begin{matrix} \\alpha & \\mu \\beta \\\\ - \\beta^* & \\alpha^* \\end{matrix} \\right),</math>\n\nso that the comultiplication is determined by <math>\\Delta(\\alpha) = \\alpha \\otimes \\alpha - \\mu \\beta \\otimes \\beta^*, \\Delta(\\beta) = \\alpha \\otimes \\beta + \\beta \\otimes \\alpha^*</math>, and the coinverse is determined by <math>\\kappa(\\alpha) = \\alpha^*, \\kappa(\\beta) = - \\mu^{-1} \\beta, \\kappa(\\beta^*) = - \\mu \\beta^*</math>, <math>\\kappa(\\alpha^*) = \\alpha</math>.  Note that {{mvar|w}} is a unitary representation.  The realizations can be identified by equating <math>\\gamma = \\sqrt{\\mu} \\beta</math>.\n\n===Limit Case===\nIf {{math|''μ'' {{=}} 1}}, then {{math|SU<sub>''μ''</sub>(2)}} is equal to the concrete compact group {{math|SU(2)}}.\n\n== References ==\n{{reflist}}\n\n{{DEFAULTSORT:Compact Quantum Group}}\n[[Category:Quantum groups]]\n[[Category:C*-algebras]]\n[[Category:Hopf algebras]]"
    },
    {
      "title": "Completely positive map",
      "url": "https://en.wikipedia.org/wiki/Completely_positive_map",
      "text": "{{Use American English|date=January 2019}}{{Short description|C*-algebra mapping preserving positive elements\n}}\nIn [[mathematics]] a '''positive map''' is a map between [[C*-algebra]]s that sends positive elements to positive elements. A completely positive map is one which satisfies a stronger, more robust condition.\n\n== Definition ==\n\nLet <math>A</math> and <math>B</math> be [[C*-algebra]]s. A linear map <math>\\phi: A\\to B</math> is called '''positive map''' if <math>\\phi</math> maps [[positive element]]s to positive elements: <math>a\\geq 0 \\implies \\phi(a)\\geq 0</math>.\n\nAny linear map <math>\\phi:A\\to B</math> induces another map\n\n:<math>\\textrm{id} \\otimes \\phi : \\mathbb{C}^{k \\times k} \\otimes A \\to \\mathbb{C}^{k \\times k} \\otimes B</math>\n\nin a natural way. If <math>\\mathbb{C}^{k\\times k}\\otimes A</math> is identified with the C*-algebra <math>A^{k\\times k}</math> of <math>k\\times k</math>-matrices with entries in <math>A</math>, then <math>\\textrm{id}\\otimes\\phi</math> acts as\n:<math>\n\\begin{pmatrix}\na_{11} & \\cdots & a_{1k} \\\\\n\\vdots & \\ddots & \\vdots \\\\\na_{k1} & \\cdots & a_{kk}\n\\end{pmatrix} \\mapsto \\begin{pmatrix}\n\\phi(a_{11}) & \\cdots & \\phi(a_{1k}) \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\phi(a_{k1}) & \\cdots & \\phi(a_{kk})\n\\end{pmatrix}.\n</math>\n\nWe say that <math>\\phi</math> is '''k-positive''' if <math>\\textrm{id}_{\\mathbb{C}^{k\\times k}} \\otimes \\phi</math> is a positive map, and <math>\\phi</math> is called '''completely positive''' if <math>\\phi</math> is k-positive for all k.\n\n== Properties ==\n\n* Positive maps are monotone, i.e. <math>a_1\\leq a_2\\implies \\phi(a_1)\\leq\\phi(a_2)</math> for all [[self-adjoint]] elements <math>a_1,a_2\\in A_{sa}</math>.\n* Since <math>-\\|a\\|_A 1_A \\leq a \\leq \\|a\\|_A 1_A</math> every positive map is automatically continuous w.r.t. the C*-norms and its [[operator norm]] equals <math>\\|\\phi(1_A)\\|_B</math>. A similar statement with approximate units holds for non-unital algebras.\n* The set of positive functionals <math>\\to\\mathbb{C}</math> is the [[dual cone]] of the cone of positive elements of <math>A</math>.\n\n== Examples ==\n\n* Every *-[[homomorphism]] is completely positive.\n* For every linear operator <math>V:H_1\\to H_2</math> between Hilbert spaces, the map <math>L(H_1)\\to L(H_2), \\ A\\mapsto VAV^\\ast</math> is completely positive. [[Stinespring factorization theorem|Stinespring's theorem]] says that all completely positive maps are compositions of *-homomorphisms and these special maps.\n* Every positive functional <math>\\phi:A\\to\\mathbb{C}</math> (in particular every [[State (functional analysis)|state]]) is automatically completely positive.\n* Every positive map <math>C(X)\\to C(Y)</math> is completely positive.\n* The [[Transpose|transposition of matrices]] is a standard example of a positive map that fails to be 2-positive. Let T denote this map on <math>\\mathbb{C}^{n\\times n}</math>. The following is a positive matrix in <math>\\mathbb{C}^{2\\times 2} \\otimes \\mathbb{C}^{2\\times 2}</math>:\n\n::<math>\n\\begin{bmatrix}\n\\begin{pmatrix}1&0\\\\0&0\\end{pmatrix}&\n\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\\\\n\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}&\n\\begin{pmatrix}0&0\\\\0&1\\end{pmatrix}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 & 0 & 1 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 1 \\\\\n\\end{bmatrix}.\n</math>\n\nThe image of this matrix under <math>I_2 \\otimes T</math> is\n\n:<math>\n\\begin{bmatrix}\n\\begin{pmatrix}1&0\\\\0&0\\end{pmatrix}^T&\n\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}^T\\\\\n\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}^T&\n\\begin{pmatrix}0&0\\\\0&1\\end{pmatrix}^T\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n\\end{bmatrix} ,\n</math>\n\n:which is clearly not positive, having determinant -1. Moreover, the [[eigenvalues]] of this matrix are 1,1,1 and -1.\n\n:Incidentally, a map Φ is said to be '''co-positive''' if the composition Φ <math>\\circ</math> ''T'' is positive. The transposition map itself is a co-positive map.\n\n==See also==\n* [[Choi's theorem on completely positive maps]]\n\n[[Category:C*-algebras]]"
    },
    {
      "title": "Continuous functional calculus",
      "url": "https://en.wikipedia.org/wiki/Continuous_functional_calculus",
      "text": "{{Short description|branch of functional analysis}}\nIn [[mathematics]], particularly in [[operator theory]] and [[C*-algebra]] theory, a '''continuous functional calculus''' is a [[functional calculus]] which allows the application of a [[continuous function]] to normal elements of a C*-algebra.  \n\n==Theorem ==\n'''Theorem'''.  Let ''x'' be a [[normal operator|normal]] element of a C*-algebra ''A'' with an identity element e. Then there is a unique mapping  π : ''f'' → ''f''(''x'') defined for a continuous function ''f'' on the [[spectrum (functional analysis)|spectrum]] σ(''x'') of ''x'', such that π is a unit-preserving morphism of C*-algebras and π(1) = e and π(id) = ''x'', where id denotes the function ''z'' → ''z'' on σ(''x'').<ref>Theorem VII.1 p.&nbsp;222 in Modern methods of mathematical physics, Vol. 1, Reed M., Simon B.</ref>\n\nThe proof of this fact is almost immediate from the [[Gelfand representation]]: it suffices to assume ''A'' is the C*-algebra of continuous functions on some compact space ''X'' and define \n:<math> \\pi(f) = f \\circ x. </math>\nUniqueness follows from application of the [[Stone-Weierstrass theorem]].\n\nIn particular, this implies that bounded normal operators on a [[Hilbert space]] have a continuous functional calculus.\n\n==See also==\n* [[Borel functional calculus]]\n* [[Holomorphic functional calculus]]\n\n==References==\n{{reflist}}\n\n==External links==\n* [http://planetmath.org/continuousfunctionalcalculus Continuous functional calculus on PlanetMath]\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Continuous Functional Calculus}}\n[[Category:Functional calculus]]\n[[Category:Continuous mappings]]\n[[Category:C*-algebras]]"
    },
    {
      "title": "Cuntz algebra",
      "url": "https://en.wikipedia.org/wiki/Cuntz_algebra",
      "text": "In mathematics, the '''Cuntz algebra''' <math>\\mathcal{O}_n </math>, named after [[Joachim Cuntz]], is the [[universal C*-algebra]] generated by ''n'' isometries satisfying certain relations.<ref>{{cite article|first=Joachim|last=Cuntz|authorlink=Joachim Cuntz|title=Simple C*-algebras generated by isometries |journal=[[Comm. Math. Phys.]] | volume=57 |pages=173–185 | year=1977 |doi=10.1007/bf01625776|bibcode = 1977CMaPh..57..173C|zbl=0399.46045}}</ref> It is the first concrete example of a [[Separable space|separable]] infinite simple C*-algebra.\n\nEvery simple infinite C*-algebra contains, for any given ''n'', a subalgebra that has <math>\\mathcal{O}_n </math> as quotient.\n\n== Definition and basic properties ==\nLet ''n'' ≥  2 and ''H'' be a [[separable space|separable]] [[Hilbert space]]. Consider the [[C*-algebra]] <math>\\mathcal{A}</math> generated by a set\n\n::<math> \\{ S_i \\}_{i=1}^n </math>\n\nof isometries (i.e. <math> S_i^*S_i=1 </math>) acting on ''H'' satisfying\n\n::<math> \\sum_{i=1}^n S_i S_i^* = I.</math>\n\n'''Theorem.''' The concrete C*-algebra <math>\\mathcal{A}</math> is isomorphic to the universal C*-algebra <math>\\mathcal{L}</math> generated by ''n'' generators ''s''<sub>1</sub>... ''s''<sub>''n''</sub> subject to relations ''s<sub>i</sub>*s<sub>i</sub>'' = 1 for all ''i'' and &sum; ''s<sub>i</sub>s<sub>i</sub>''* = 1.\n\nThe proof of the theorem hinges on the following fact: any C*-algebra generated by ''n'' isometries ''s''<sub>1</sub>... ''s''<sub>''n''</sub> with orthogonal ranges contains a copy of the [[UHF algebra]] <math>\\mathcal{F}</math> type ''n''<sup>&infin;</sup>. Namely <math>\\mathcal{F}</math> is spanned by words of the form\n\n:<math>s_{i_1}\\cdots s_{i_k}s_{j_1}^* \\cdots s_{j_k}^*, k \\geq 0.</math>\n\nThe *-subalgebra <math>\\mathcal{F}</math>, being [[Approximately finite-dimensional C*-algebra|approximately finite-dimensional]], has a unique C*-norm.\nThe subalgebra <math>\\mathcal{F}</math> plays role of the space of ''[[Fourier coefficient]]s'' for elements of the algebra. A key technical lemma, due to Cuntz, is that an element in the algebra is zero if and only if all its Fourier coefficients vanish. Using this, one can show that the quotient map from  <math>\\mathcal{L}</math> to  <math>\\mathcal{A}</math> is injective, which proves the theorem.\n\nThis universal C*-algebra is called the '''Cuntz algebra''', denoted by <math>\\mathcal{O}_n </math>.\n\nA [[simple algebra|simple]]  C*-algebra is said to be '''purely infinite''' if every [[hereditary C*-subalgebra]] of it is infinite. <math>\\mathcal{O}_n </math>  is a separable, simple, purely infinite C*-algebra.\n\nAny simple infinite C*-algebra contains a subalgebra that has <math>\\mathcal{O}_n</math> as a quotient.\n\nThe UHF algebra <math>\\mathcal{F}</math> has a non-unital subalgebra <math>\\mathcal{F}'</math> that is canonically isomorphic to <math>\\mathcal{F}</math> itself: In the M''<sub>n</sub>'' stage of the direct system defining <math>\\mathcal{F}</math>, consider the rank-1 projection ''e''<sub>11</sub>, the matrix that is 1 in the upper left corner and zero elsewhere. Propagate this projection through the direct system. At the M''<sub>n<sup>k</sup></sub>'' stage of the direct system, one has a rank ''n''<sup>''k'' - 1</sup> projection. In the [[direct limit]], this gives a projection ''P'' in <math>\\mathcal{F}</math>. The corner\n\n:<math>P \\mathcal{F} P  = \\mathcal{F'} </math>\n\nis isomorphic to <math>\\mathcal{F}</math>. The *-endomorphism &Phi; that maps <math>\\mathcal{F}</math> onto <math>\\mathcal{F}'</math> is implemented by the isometry ''s''<sub>1</sub>, i.e. &Phi;(&middot;) = ''s''<sub>1</sub>(&middot;)''s''<sub>1</sub>*. <math>\\;\\mathcal{O}_n </math>is in fact the [[crossed product]] of <math>\\mathcal{F}</math> with the endomorphism &Phi;.\n\n== Classification ==\nThe Cuntz algebras are pairwise non-isomorphic, i.e. <math>\\mathcal{O}_n </math> and <math>\\mathcal{O}_m </math> are non-isomorphic for ''n'' &ne; ''m''. The [[operator K-theory|''K''<sub>0</sub>]] group of <math>\\mathcal{O}_n</math> is '''Z'''<sub>''n'' &minus; 1</sub>, the [[cyclic group]] of order ''n''&nbsp;&minus;&nbsp;1. Since ''K''<sub>0</sub> is a [[functor]], <math>\\mathcal{O}_n </math> and <math>\\mathcal{O}_m </math> are non-isomorphic.\n\n== Generalisations ==\nCuntz algebras have been generalised in many ways. Notable amongst which are the [[Cuntz-Krieger algebra|Cuntz–Krieger algebras]], [[graph C*-algebra]]s and [[k-graph C*-algebra]]s.\n\n== Applied mathematics ==\nIn [[signal processing]], [[subband coding|subband filter]] with exact reconstruction give rise to representations of Cuntz algebra. The same filter also comes from the [[multiresolution analysis]] construction in [[wavelet]] theory.<ref>{{cite book|title=Analysis and Probability: Wavelets, Signals, Fractals|volume=234|series=[[Graduate Texts in Mathematics]] |first1=Palle E. T.|last1=Jørgensen|first2=Brian|last2=Treadway |publisher=[[Springer-Verlag]]|isbn=0-387-29519-4 }}</ref>\n\n==References==\n<references/>\n[[Category:C*-algebras]]"
    },
    {
      "title": "Dirichlet algebra",
      "url": "https://en.wikipedia.org/wiki/Dirichlet_algebra",
      "text": "In [[mathematics]], a '''Dirichlet algebra''' is a particular type of [[C* algebra|algebra]]  associated to a [[compact Hausdorff space]] ''X''.  It is a closed subalgebra of ''C''(''X''), the [[uniform algebra]] of bounded [[continuous functions]] on ''X'', whose real parts are dense in the algebra of bounded continuous real functions on ''X''. The concept was introduced by {{harvs|first=Andrew|last=Gleason|authorlink=Andrew Gleason|year=1957|txt}}.\n\n==Example==\n\nLet <math>\\mathcal{R}(X)</math> be the set of all [[rational function]]s that are continuous on <math>X</math>; in other words functions that have no [[Pole (complex analysis)|poles]] in <math>X</math>. Then \n\n:<math>\\mathcal{S} = \\mathcal{R}(X) + \\bar{\\mathcal{R}(X)}</math>\n\nis a *-subalgebra of <math>C(X)</math>, and of <math>C\\left(\\partial X\\right)</math>. If <math>\\mathcal{S}</math> is [[Dense set|dense]] in <math>C\\left(\\partial X\\right)</math>, we say <math>\\mathcal{R}(X)</math> is a '''Dirichlet algebra'''.\n\nIt can be shown that if an operator <math>T</math> has <math>X</math> as a [[spectral set]], and <math>\\mathcal{R}(X)</math> is a Dirichlet algebra, then <math>T</math> has a [[Dilation (operator theory)|normal boundary dilation]]. This generalises [[Sz.-Nagy's dilation theorem]], which can be seen as a consequence of this by letting \n\n:<math>X=\\mathbb{D}.</math>\n\n==See also==\n\n* [[Subdiagonal algebra]]\n\n==References==\n\n*{{Citation | last1=Gleason | first1=Andrew M. | authorlink = Andrew Gleason | editor1-last=Morse | editor1-first=Marston | editor2-last=Beurling | editor2-first=Arne | editor3-last=Selberg | editor3-first=Atle | title=Seminars on analytic functions: seminar III : Riemann surfaces ; seminar IV : theory of automorphic functions ; seminar V : analytic functions as related to Banach algebras | publisher=Institute for Advanced Study, Princeton | zbl=0095.10103 | year=1957 | volume=2 | chapter=Function algebras | pages=213–226}}\n*{{eom|id=d/d120180|title=Dirichlet algebra|first=T. |last=Nakazi}}\n*''Completely Bounded Maps and Operator Algebras'' Vern Paulsen, 2002 {{ISBN|0-521-81669-6}}\n*{{citation|last=Wermer|first=John|title=Gleason's work on Banach algebras|department=Andrew M. Gleason 1921–2008|editor-first=Ethan D.|editor-last=Bolker|journal=Notices of the American Mathematical Society|volume=56|issue=10|date=November 2009|pages=1248–1251|url=http://www.ams.org/notices/200910/rtx091001236p.pdf}}.\n\n[[Category:Functional analysis]]\n[[Category:C*-algebras]]\n\n\n{{Mathanalysis-stub}}"
    },
    {
      "title": "Enveloping von Neumann algebra",
      "url": "https://en.wikipedia.org/wiki/Enveloping_von_Neumann_algebra",
      "text": "In [[operator algebras]], the '''enveloping von Neumann algebra''' of a [[C*-algebra]] is a [[von Neumann algebra]] that contains all the operator-algebraic information about the given C*-algebra. This may also be called the '''''universal'' enveloping von Neumann algebra''', since it is given by a [[universal property]]; and (as always with von Neumann algebras) the term ''W*-algebra'' may be used in place of ''von Neumann algebra''.\n\n== Definition ==\n\nLet ''A'' be a [[C*-algebra]] and ''&pi;''<sub>''U''</sub> be its [[GNS construction|universal representation]], acting on Hilbert space ''H''<sub>''U''</sub>. The image of ''&pi;''<sub>''U''</sub>, ''&pi;''<sub>''U''</sub>(''A''), is a C*-subalgebra of bounded operators on ''H''<sub>''U''</sub>. The '''enveloping von Neumann algebra''' of ''A'' is the closure of ''&pi;''<sub>''U''</sub>(''A'') in the weak operator topology. It is sometimes denoted by ''A''&prime;&prime;.\n\n== Properties ==\n\nThe universal representation ''&pi;''<sub>''U''</sub> and ''A''&prime;&prime; satisfies the following [[universal property]]: for any representation ''&pi;'', there is a unique *-homomorphism\n\n:<math> \\Phi: \\pi_U(A)'' \\rightarrow \\pi(A)'' </math>\n \nthat is continuous in the weak operator topology and the restriction of &Phi; to ''&pi;''<sub>''U''</sub>(''A'') is ''&pi;''.\n\nAs a particular case, one can consider the [[continuous functional calculus]], whose unique extension gives a canonical [[Borel functional calculus]].\n \nBy the [[Sherman–Takeda theorem]], the double dual of a C*-algebra ''A'', ''A''**, can be identified with ''A''&prime;&prime;, as [[Banach space]]s.\n\nEvery representation of ''A'' uniquely determines a central projection (i.e. a projection in the center of the algebra) in ''A''&prime;&prime;; it is called the '''central cover''' of that projection.\n\n==See also==\n* [[Universal enveloping algebra]]\n\n[[Category:C*-algebras]]\n{{mathanalysis-stub}}"
    },
    {
      "title": "Exact C*-algebra",
      "url": "https://en.wikipedia.org/wiki/Exact_C%2A-algebra",
      "text": "{{DISPLAYTITLE:Exact C*-algebra}}\n\nIn mathematics, an '''exact C*-algebra''' is a [[C*-algebra]] that preserves [[exact sequence]]s under the [[minimum tensor product]].\n\n==Definition==\n\nA [[C*-algebra]] ''E'' is exact if, for any [[short exact sequence]],\n\n:<math>0 \\;\\xrightarrow{}\\; A \\;\\xrightarrow{f}\\; B \\;\\xrightarrow{g}\\; C \\;\\xrightarrow{}\\; 0</math>\n\nthe sequence\n\n:<math>0\\;\\xrightarrow{}\\; A \\otimes_\\min E\\;\\xrightarrow{f\\otimes \\operatorname{id}}\\; B\\otimes_\\min E \\;\\xrightarrow{g\\otimes \\operatorname{id}}\\; C\\otimes_\\min E \\;\\xrightarrow{}\\; 0,</math>\n\nwhere &otimes;<sub>min</sub> denotes the minimum [[tensor product]], is also exact.\n\n==Properties==\n\nExact C*-algebras have the following equivalent characterizations:\n\n*A C*-algebra ''A'' is exact if and only if ''A'' is nuclearly embeddable into ''B''(''H''), the C*-algebra of all bounded operators on a Hilbert space ''H''.\n*A separable C*-algebra ''A'' is exact if and only if it is isomorphic to a subalgebra of the [[Cuntz algebra]] <math>\\mathcal{O}_2</math>.\n\nAll [[nuclear C*-algebra]]s and their C*-subalgebras are exact.\n\n==References==\n{{reflist}}\n<!--- After listing your sources please cite them using inline citations and place them after the information they cite. Please see http://en.wikipedia.org/wiki/Wikipedia:REFB for instructions on how to add citations. --->\n*{{cite book\n|first1=Nathanial P.\n|last1=Brown\n|first2=Narutaka\n|last2=Ozawa\n|title=C*-algebras and Finite-Dimensional Approximations\n|publisher=AMS\n|location=Providence\n|year=2008\n|isbn=978-0-8218-4381-9\n}}\n\n{{DEFAULTSORT:Exact C-algebra}}\n[[Category:C*-algebras]]"
    },
    {
      "title": "Gelfand–Naimark–Segal construction",
      "url": "https://en.wikipedia.org/wiki/Gelfand%E2%80%93Naimark%E2%80%93Segal_construction",
      "text": "In [[functional analysis]], a discipline within [[mathematics]], given a [[C*-algebra]] ''A'',  the '''Gelfand–Naimark–Segal construction''' establishes a correspondence between cyclic *-representations of ''A'' and certain [[linear functional]]s on ''A'' (called ''states'').  The correspondence is shown by an explicit construction of the *-representation from the state. It is named for [[Israel Gelfand]], [[Mark Naimark]], and [[Irving Segal]].\n\n== States and representations ==\n\nA '''*-representation''' of a [[C*-algebra]] ''A'' on a [[Hilbert space]] ''H'' is a [[map (mathematics)|map]]ping\nπ from ''A'' into the algebra of [[bounded operator]]s on ''H'' such that\n* π is a [[ring homomorphism]] which carries [[Involution (mathematics)|involution]] on ''A'' into involution on operators\n* π is [[nondegenerate]], that is the space of vectors π(''x'') ξ is dense as ''x'' ranges through ''A'' and ξ ranges through ''H''. Note that if ''A'' has an identity, nondegeneracy means exactly π is unit-preserving, i.e. π maps the identity of ''A'' to the identity operator on ''H''.\n\nA [[state (functional analysis)|state]] on  C*-algebra ''A'' is a [[positive linear functional]] ''f'' of norm 1. If ''A'' has a multiplicative unit element this condition is equivalent to ''f''(1) = 1.\n\nFor a representation π of a C*-algebra ''A'' on a Hilbert space ''H'', an element ξ is called a '''cyclic vector'''  if the set of vectors\n:<math>\\{\\pi(x)\\xi:x\\in A\\}</math>\nis norm dense in ''H'', in which case π is called a '''cyclic representation'''. Any non-zero vector of an [[irreducible representation]] is cyclic. However, non-zero vectors in a cyclic representation may fail to be cyclic.\n\n===The GNS construction===\nLet π be a *-representation of a C*-algebra ''A''  on the Hilbert space ''H'' and ξ be a unit norm cyclic vector for π. Then\n:<math> a \\mapsto \\langle \\pi(a) \\xi, \\xi\\rangle </math>\nis a state of ''A''.\n\nIn fact, every state of ''A'' may be viewed as a [[State (functional analysis)#Vector states|vector state]] as above, under a suitable canonical representation.\n\n:'''Theorem.'''<ref>[[Kadison, R. V.]], Theorem 4.5.2, Fundamentals of the Theory of Operator Algebras, Vol. I : Elementary Theory, American Mathematical Society. {{ISBN|978-0821808191}}</ref> Given a state ρ of ''A'', there is a *-representation π of ''A'' acting on a Hilbert space ''H'' with distinguished unit cyclic vector ξ such that <math>\\rho(a)=\\langle \\pi(a) \\xi, \\xi \\rangle</math> for every ''a'' in ''A''.\n\n:'''Proof.'''\n:1) '''Construction of the Hilbert space ''H'' '''\n\n:Define on ''A'' a semi-definite [[sesquilinear form]]\n::<math> \\langle a, b \\rangle =\\rho(b^*a), \\; a, b \\in A.</math>\n:By the [[Positive linear functional#Cauchy-Schwarz inequality|Cauchy–Schwarz inequality]], the degenerate elements, ''a'' in ''A'' satisfying ρ(''a* a'')= 0, form a vector subspace ''I'' of ''A''. By a C*-algebraic argument, one can show that ''I'' is a [[left ideal]] of ''A'' (known as the left kernel of ρ). In fact, it is the largest left ideal in the null space of ρ. The [[quotient space (linear algebra)|quotient space]] of ''A'' by the vector subspace ''I'' is an inner product space with the inner product defined by<math>\\langle a+I,b+I\\rangle :=\\rho(b^*a),\\; a,b\\in A</math>. The [[Cauchy completion]] of ''A''/''I'' in the norm induced by this inner product is a Hilbert space, which we denote by ''H''.\n\n:2) '''Construction of the representation π '''\n\n:Define the action π of ''A'' on ''A''/''I'' by π(''a'')(''b''+''I'') = ''ab''+''I'' of ''A'' on ''A''/''I''. The same argument showing ''I'' is a left ideal also implies that π(''a'') is a bounded operator on ''A''/''I'' and therefore can be extended uniquely to the completion. Unravelling the definition of the [[adjoint]] of an operator on a Hilbert space, π turns out to be *-preserving. This proves the existence of a  *-representation π.\n\n:3) '''Identifying the unit norm cyclic vector ξ '''\n\n:If ''A'' has a multiplicative identity 1, then it is immediate that the equivalence class ξ in the GNS Hilbert space ''H'' containing 1 is a cyclic vector for the above representation. If ''A'' is non-unital, take  an [[approximate identity]] {''e<sub>&lambda;</sub>''} for ''A''. Since positive linear functionals are bounded, the equivalence classes of the net {''e<sub>&lambda;</sub>''} converges to some vector ξ in ''H'', which is a cyclic vector for π.\n\n:It is clear from the definition of the inner product on the GNS Hilbert space ''H'' that the state ρ can be recovered as a vector state on ''H''. This proves the theorem.\n\nThe method used to produce a *-representation from a state of ''A'' in the proof of the above theorem is called the '''GNS construction'''.\nFor a state of a C*-algebra ''A'', the corresponding GNS representation is essentially uniquely determined by the condition, <math>\\rho(a) = \\langle \\pi(a) \\xi, \\xi \\rangle</math> as seen in the theorem below.\n:'''Theorem.'''<ref>[[Kadison, R. V.]], Proposition 4.5.3, Fundamentals of the Theory of Operator Algebras, Vol. I : Elementary Theory, American Mathematical Society. {{ISBN|978-0821808191}}</ref> Given a state ρ of ''A'', let π, π' be *-representations of ''A'' on Hilbert spaces ''H'', ''K'' respectively each with unit norm cyclic vectors ξ ∈ ''H'', ξ' ∈ ''K'' such that <math>\\rho(a) = \\langle \\pi(a) \\xi, \\xi \\rangle = \\langle \\pi'(a) \\xi ', \\xi ' \\rangle</math> for all <math>a \\in A</math>. Then π, π' are unitarily equivalent *-representations i.e. there is a unitary operator ''U'' from ''H'' to ''K'' such that π'(''a'') = Uπ(''a'')U* for all ''a'' in ''A''. The operator ''U'' that  implements the unitary equivalence maps π(''a'')ξ to π'(''a'')ξ' for all ''a'' in ''A''.\n\n===Significance of the GNS construction===\nThe GNS construction is at the heart of the proof of the [[Gelfand–Naimark theorem]] characterizing C*-algebras as algebras of operators. A C*-algebra has sufficiently many pure states (see below) so that the direct sum of corresponding irreducible GNS representations is [[Faithful group action|faithful]].\n\nThe direct sum of the corresponding GNS representations of all states is called the '''[[universal representation (C*-algebra)|universal representation]]''' of ''A''. The universal representation of ''A'' contains every cyclic representation. As every *-representation is a direct sum of cyclic representations, it follows that every *-representation of ''A'' is a direct summand of some sum of copies of the universal representation.\n\nIf Φ is the universal representation of a C*-algebra ''A'', the closure of Φ(''A'') in the weak operator topology is called the '''[[enveloping von Neumann algebra]]''' of ''A''. It can be identified with the double dual ''A**''.\n\n== Irreducibility ==\n\nAlso of significance is the relation between [[irreducible representation|irreducible]] *-representations and extreme points of the convex set of states.  A representation π on ''H'' is irreducible if and only if there are no closed subspaces of ''H'' which are invariant under all the operators π(''x'') other than ''H'' itself and the trivial subspace {0}.\n\n:'''Theorem'''.  The set of states of a C*-algebra ''A'' with a unit element is a compact [[convex set]] under the weak-* topology.  In general, (regardless of whether or not ''A'' has a unit element) the set of positive functionals of norm ≤ 1 is a compact convex set.\n\nBoth of these results follow immediately from the [[Banach–Alaoglu theorem]].\n\nIn the unital commutative case, for the C*-algebra ''C''(''X'') of continuous functions on some compact ''X'', [[Riesz–Markov–Kakutani representation theorem]] says that the positive functionals of norm ≤ 1 are precisely the Borel positive measures on ''X'' with total mass ≤ 1. It follows from [[Krein–Milman theorem]] that the extremal states are the Dirac point-mass measures.\n\nOn the other hand, a representation of ''C''(''X'') is irreducible if and only if it is one-dimensional. Therefore, the GNS representation of ''C''(''X'') corresponding to a measure μ is irreducible if and only if μ is an extremal state. This is in fact true for C*-algebras in general.\n\n:'''Theorem'''. Let ''A'' be a C*-algebra.  If π is a *-representation of ''A''  on the Hilbert space ''H'' with unit norm cyclic vector ξ, then π is irreducible if and only if the corresponding state ''f'' is an [[extreme point]] of the convex set of positive linear functionals on ''A'' of norm ≤ 1.\n\nTo prove this result one notes first that a representation is irreducible if and only if the [[commutant]] of π(''A''), denoted by π(''A'')', consists of scalar multiples of the identity.\n\nAny positive linear functionals ''g'' on ''A'' dominated by ''f'' is of the form\n\n:<math> g(x^*x) = \\langle \\pi(x) \\xi,  \\pi(x) T_g \\, \\xi \\rangle </math>\n\nfor some positive operator ''T<sub>g</sub>'' in π(''A'')' with 0 ≤ ''T'' ≤ 1 in the operator order. This is a version of the [[Radon–Nikodym theorem]].\n\nFor such ''g'', one can write ''f'' as a sum of positive linear functionals: ''f'' = ''g'' + ''g' ''. So π is unitarily equivalent to a subrepresentation of π<sub>''g''</sub> ⊕ π<sub>''g' ''</sub>. This shows that π is irreducible if and only if any such π<sub>''g''</sub> is unitarily equivalent to π, i.e. ''g'' is a scalar multiple of ''f'', which proves the theorem.\n\nExtremal states are usually called [[State (functional analysis)#Pure states|pure states]].  Note that a state is a pure state if and only if it is extremal in the convex set of states.\n\nThe theorems above for C*-algebras are valid more generally in the context of  [[B-star algebra|B*-algebra]]s with approximate identity.\n\n== Generalizations ==\n\nThe [[Stinespring factorization theorem]] characterizing [[completely positive map]]s is an important generalization of the GNS construction.\n\n== History ==\nGelfand and Naimark's paper on the Gelfand–Naimark theorem was published in 1943.<ref>{{cite journal |author=[[I. M. Gelfand]], [[M. A. Naimark]] |title=On the imbedding of normed rings into the ring of operators on a Hilbert space |journal=[[Matematicheskii Sbornik]] |volume=12 |issue=2 |year=1943 |pages=197–217 |url=http://mi.mathnet.ru/eng/msb6155}} (also [https://www.google.com/books?id=DYCUp0JYU6sC&printsec=frontcover#PPA3,M1 Google Books], see pp.&nbsp;3–20)</ref> Segal recognized the construction that was implicit in this work and presented it in sharpened form.<ref>[[Richard V. Kadison]]: ''Notes on the Gelfand–Neimark theorem''. In: Robert C. Doran (ed.): ''C*-Algebras: 1943–1993. A Fifty Year Celebration'', AMS special session commemorating the first fifty years of C*-algebra theory, January 13–14, 1993, San Antonio, Texas, American Mathematical Society, pp.&nbsp;21–54, {{ISBN|0-8218-5175-6}} ([https://www.google.com/books?id=DYCUp0JYU6sC&printsec=frontcover#PPA3,M1 available from Google Books], see pp.&nbsp;21 ff.)</ref>\n\nIn his paper of 1947 Segal showed that it is sufficient, for any physical system that can be described by an algebra of operators on a Hilbert space, to consider the ''irreducible'' representations of a C*-algebra. In quantum theory this means that the C*-algebra is generated by the observables. This, as Segal pointed out, had been shown earlier by [[John von Neumann]] only for the specific case of the non-relativistic Schrödinger-Heisenberg theory.<ref>{{cite journal |author=[[I. E. Segal]]|title=Irreducible representations of operator algebras |journal=Bull. Am. Math. Soc. |volume=53 |issue= |year=1947 |pages=73–88 |url=http://www.ams.org/journals/bull/1947-53-02/S0002-9904-1947-08742-5/S0002-9904-1947-08742-5.pdf |doi=10.1090/s0002-9904-1947-08742-5}}</ref>\n\n==References==\n\n* [[William Arveson]], ''An Invitation to C*-Algebra'', Springer-Verlag, 1981\n*[[Kadison, Richard]], ''Fundamentals of the Theory of Operator Algebras, Vol. I : Elementary Theory'', American Mathematical Society. {{ISBN|978-0821808191}}.\n* [[Jacques Dixmier]], ''Les C*-algèbres et leurs Représentations'', Gauthier-Villars, 1969.<br/>English translation: {{cite book\n  | last =Dixmier\n  | first =Jacques\n  | authorlink =\n  | coauthors =\n  | title = C*-algebras\n  | publisher =North-Holland\n  | year = 1982\n  | location =\n  | pages =\n  | url =\n  | doi =\n  | id =  \n  | isbn = 0-444-86391-5}}\n* Thomas Timmermann, ''An invitation to quantum groups and duality: from Hopf algebras to multiplicative unitaries and beyond'', European Mathematical Society, 2008, {{ISBN|978-3-03719-043-2}} – [https://books.google.com/books?id=S8sZiieo-04C&pg=PA371 Appendix 12.1, section: GNS construction (p. 371)]\n* Stefan Waldmann: ''On the representation theory of [[deformation quantization]]'', In: ''Deformation Quantization: Proceedings of the Meeting of Theoretical Physicists and Mathematicians, Strasbourg, May 31-June 2, 2001 (Studies in Generative Grammar) '', Gruyter, 2002, {{ISBN|978-3-11-017247-8}}, p.&nbsp;107–134 – [https://books.google.com/books?id=xuq8CHNEFKoC&pg=PA113 section 4. The GNS construction (p. 113)]\n*{{cite book\n | author = G. Giachetta, L. Mangiarotti, [[Gennadi Sardanashvily|G. Sardanashvily]]\n | year = 2005\n | title = Geometric and Algebraic Topological Methods in Quantum Mechanics\n | publisher = World Scientific\n | isbn = 981-256-129-3\n | url =\n}}\n\n;Inline references:\n{{reflist}}\n\n{{DEFAULTSORT:Gelfand-Naimark-Segal construction}}\n[[Category:Functional analysis]]\n[[Category:C*-algebras]]\n[[Category:Quantum field theory]]\n\n[[ru:Алгебраическая квантовая теория]]"
    },
    {
      "title": "Graph C*-algebra",
      "url": "https://en.wikipedia.org/wiki/Graph_C%2A-algebra",
      "text": "In [[mathematics]], particularly the theory of [[C*-algebras]], a '''graph C*-algebra''' is a [[universal C*-algebra]] associated to a [[directed graph]]. They form a rich class of C*-algebras encompassing [[Cuntz algebra]]s, [[Cuntz-Krieger algebra]]s, the [[Toeplitz algebra]], etc. Also every [[approximately finite-dimensional C*-algebra|AF-algebra]] is [[Morita equivalence|Morita equivalent]]<ref>D. Drinen,''[http://www.ams.org/proc/2000-128-07/S0002-9939-99-05286-7/S0002-9939-99-05286-7.pdf Viewing AF-algebras as graph algebras]'', Proc. Amer. Math. Soc., 128 (2000), pp. 1991–2000.</ref> to a graph C*-algebra. As the structure of graph C*-algebras is fairly tractable with computable invariants, they play an important part in the classification theory of C*-algebras.\n\n==Definition==\nLet <math>E=(E^0, E^1, r, s)</math> be a [[directed graph]] with a countable set of vertices <math>E^0</math>, a countable set of edges <math>E^1</math>, and maps <math>r, s : E^1 \\rightarrow E^0</math> identifying the range and source of each edge, respectively. The graph C*-algebra corresponding to <math>E</math>, denoted by <math>C^*(E)</math>, is the universal C*-algebra generated by mutually orthogonal projections <math>\\{ p_v : v \\in E^0 \\}</math> and partial isometries <math>\\{ s_e : e \\in E^1 \\}</math> with mutually orthogonal ranges such that :\n\n(i) <math>s_e^*s_e = p_{r(e)}</math> for all <math>e \\in E^1</math>\n\n(ii) <math>p_v = \\sum_{s(e)=v} s_e s_e^*</math> whenever <math>0 < |s^{-1}(v)| < \\infty </math>\n\n(iii) <math>s_e s_e^* \\le p_{s(e)}</math> for all <math>e \\in E^1</math>.\n\n==Examples of graph C*-algebras==\n{| class=\"wikitable\"\n|-\n! Directed graph (E) !! Graph C*-algebra (C*(E))\n|-\n| [[File:Graph complex numbers.png]] || <math>\\mathbb{C}</math> - the set of [[complex number]]s\n|-\n| [[File:Graph circle algebra.png]] || <math>C(S^1)</math> - the set of complex-valued continuous functions on the circle\n|-\n| [[File:Directed graph matrix.png]]|| <math>M_n(\\mathbb{C})</math> - the set of n x n matrices over <math>\\mathbb{C}</math>\n|-\n| [[File:Graph circle matrix.png]] || <math>M_n(C(S^1))</math> - the set of n x n matrices over <math>C(S^1)</math>\n|-\n| [[File:Graph compact.png]] || <math>\\mathcal{K}</math> - the set of [[compact operator]]s over a separable Hilbert space\n|-\n| [[File:Graph Toeplitz algebra.png]] || <math>\\mathcal{T}</math> - [[Toeplitz algebra]]\n|-\n| [[File:Graph cuntz.png]] || <math>\\mathcal{O}_n</math> - [[Cuntz algebra]]\n|}\n\n==Notes==\n{{Reflist}}\n\n==References==\n\n{{DEFAULTSORT:Graph C}}\n[[Category:C*-algebras]]"
    },
    {
      "title": "Hereditary C*-subalgebra",
      "url": "https://en.wikipedia.org/wiki/Hereditary_C%2A-subalgebra",
      "text": "In [[mathematics]], a '''hereditary C*-subalgebra''' of a [[C*-algebra]] is a particular type of C*-subalgebra whose structure is closely related to that of the larger C*-algebra. A C*-subalgebra  ''B'' of ''A'' is a hereditary C*-subalgebra if for all ''a'' ∈ ''A'' and ''b'' ∈ ''B'' such that 0 ≤ ''a'' ≤ ''b'', we have ''a'' ∈ ''B''.<ref>{{cite book|last=Blackadar |first=Bruce|title=Operator Algebras: Theory of C*-Algebras and von Neumann Algebras|year=2006|publisher=Springer|isbn=978-3-540-28517-5|pages=75–79}}</ref>\n\n== Properties ==\n* A hereditary C*-subalgebra of an [[approximately finite-dimensional C*-algebra]] is also AF. This is not true for subalgebras that are not hereditary. For instance, every [[abelian group|abelian]] C*-algebra can be embedded into an AF C*-algebra.\n* A C*-subalgebra is called '''full''' if it is not contained in any proper (two-sided) closed ideal. Two C*-algebras ''A'' and ''B'' are called '''stably isomorphic''' if ''A''&nbsp;&otimes;&nbsp;''K''&nbsp;&cong;&nbsp;''B''&nbsp;&otimes;&nbsp;''K'', where ''K'' is the C*-algebra of [[compact operator on Hilbert space|compact operators]] on a separable infinite-dimensional [[Hilbert space]]. C*-algebras are stably isomorphic to their full hereditary C*-subalgebras.<ref>{{Cite journal|doi=10.2140/pjm.1977.71.335|last=Brown|first=Lawrence G.|authorlink = Lawrence G. Brown|year = 1977|title=Stable Isomorphism of Hereditary Subalgebras of C*-algebras|journal=Pacific Journal of Mathematics|volume=71|issue=2|pages=335&ndash;348|zbl=0362.46042}}</ref> Hence, two C*-algebras are stably isomorphic if they contain stably isomorphic full hereditary C*-subalgebras.\n* Also hereditary C*-subalgebras are those C*-subalgebras in which the restriction of any [[irreducible representation]] is also irreducible.\n\n== Correspondence with closed left ideals ==\nThere is a bijective correspondence between closed left ideals and hereditary C*-subalgebras of ''A''. If ''L'' ⊂ ''A'' is a closed left ideal, let ''L''* denote the image of ''L'' under the *-operation. The set ''L''* is a right ideal and ''L''* ∩ ''L'' is a C*-subalgebra.  In fact, ''L''* ∩ ''L'' is hereditary and the map ''L'' {{mapsto}} ''L''* ∩ ''L'' is a bijection. It follows from this correspondence that every closed ideal is a hereditary C*-subalgebra. Another corollary is that a hereditary C*-subalgebra of a simple C*-algebra is also simple.\n\n== Connections with positive elements ==\nIf ''p'' is a projection of ''A'' (or a projection of the [[multiplier algebra]] of ''A''), then ''pAp'' is a hereditary C*-subalgebra known as a '''corner''' of ''A''. More generally, given a positive ''a''&nbsp;∈&nbsp;''A'', the closure of the set ''aAa'' is the smallest hereditary C*-subalgebra containing ''a'', denoted by Her(''a''). If ''A'' is [[separable space|separable]], then every hereditary C*-subalgebra has this form.\n\nThese hereditary C*-subalgebras can bring some insight into the notion of Cuntz subequivalence. In particular, if ''a'' and ''b'' are positive elements of a C*-algebra ''A'', then <math>a \\precsim b</math> if and only if ''b''&nbsp;&isin;&nbsp;Her(''a''). Hence, ''a''&nbsp;~&nbsp;''b'' if and only if Her(''a'')&nbsp;=&nbsp;Her(''b'').\n\nIf ''A'' is unital and the positive element ''a'' is invertible, then Her(''a'') = ''A''. This suggests the following notion for the non-unital case: ''a'' ∈ ''A'' is said to be '''strictly positive''' if Her(''a'') = ''A''. For example, in the C*-algebra ''K''(''H'') of compact operators acting on Hilbert space ''H'', a compact operator is strictly positive if and only if its range is dense in ''H''. A commutative C*-algebra contains a strictly positive element if and only if the [[spectrum of a C*-algebra|spectrum]] of the algebra is [[&sigma;-compact]]. More generally, a C*-algebra contains a strictly positive element if and only if the algebra has a [[sequence (mathematics)|sequential]] [[approximate identity]].\n\n== References ==\n<references />\n\n{{DEFAULTSORT:Hereditary C-subalgebra}}\n[[Category:C*-algebras]]"
    },
    {
      "title": "Hilbert C*-module",
      "url": "https://en.wikipedia.org/wiki/Hilbert_C%2A-module",
      "text": "'''Hilbert C*-modules''' are [[mathematical object]]s which generalise the notion of a [[Hilbert space]] (which itself is a generalisation of [[Euclidean space]]), in that they endow a [[vector space|linear space]] with an \"[[inner product]]\" which takes values in a [[C*-algebra]].  Hilbert C*-modules were first introduced in the work of [[Irving Kaplansky]] in [[1953 in science|1953]], which developed the theory for [[commutative]], [[unital algebra]]s (though Kaplansky observed that the assumption of a unit element was not \"vital\").<ref>{{cite journal| last = Kaplansky| first = I.| authorlink = Irving Kaplansky| title = Modules over operator algebras| journal = [[American Journal of Mathematics]]| volume = 75| issue = 4| pages = 839–853| year = 1953| doi = 10.2307/2372552| jstor = 2372552}}</ref> In the 1970s the theory was extended to non-commutative C*-algebras independently by William Lindall Paschke<ref>{{cite journal| last = Paschke| first = W. L.| title = Inner product modules over B*-algebras| journal = [[Transactions of the American Mathematical Society]]| volume = 182| pages = 443–468| year = 1973| doi = 10.2307/1996542| jstor = 1996542}}</ref> and [[Marc Rieffel]], the latter in a paper which used Hilbert C*-modules to construct a theory of [[induced representation]]s of C*-algebras.<ref>{{cite journal| last = Rieffel| first = M. A.| title = Induced representations of C*-algebras| journal = Advances in Mathematics| volume = 13| pages = 176–257| publisher = Elsevier| year = 1974| doi = 10.1016/0001-8708(74)90068-1| issue = 2}}</ref> Hilbert C*-modules are crucial to Kasparov's formulation of [[KK-theory]],<ref>{{cite journal| last = Kasparov| first = G. G.| title = Hilbert C*-modules: Theorems of Stinespring and Voiculescu| journal = Journal of Operator Theory| volume = 4| pages = 133–150| publisher = Theta Foundation| year = 1980}}</ref> and provide the right framework to extend the notion of [[Morita equivalence]] to C*-algebras.<ref>{{cite journal| last = Rieffel| first = M. A.| title = Morita equivalence for operator algebras| journal = Proceedings of Symposia in Pure Mathematics| volume = 38| pages = 176–257| publisher = American Mathematical Society| year = 1982}}</ref> They can be viewed as the generalization of [[vector bundles]] to noncommutative C*-algebras and as such play an important role in [[noncommutative geometry]], notably in [[C*-algebraic quantum group theory]],<ref>{{cite journal| last = Baaj| first = S.|author2=Skandalis, G.| title = Unitaires multiplicatifs et dualité pour les produits croisés de C*-algèbres| journal = [[Annales Scientifiques de l'École Normale Supérieure]]| volume = 26| issue = 4| pages = 425–488| year = 1993}}</ref><ref>{{cite journal| last = Woronowicz| first = S. L.| authorlink = S. L. Woronowicz| title = Unbounded elements affiliated with C*-algebras and non-compact quantum groups| journal = Communications in Mathematical Physics| volume = 136| pages = 399–432| year = 1991| doi = 10.1007/BF02100032|bibcode = 1991CMaPh.136..399W| issue = 2 }}</ref> and [[groupoid]] C*-algebras.\n\n== Definitions ==\n\n=== Inner-product ''A''-modules ===\nLet ''A'' be a C*-algebra (not assumed to be commutative or unital), its [[Involution (mathematics)|involution]] denoted by *. An '''inner-product ''A''-module''' (or '''pre-Hilbert ''A''-module''') is a [[complex number|complex]] linear space ''E'' which is equipped with a compatible right [[Module (mathematics)|''A''-module]] structure, together with a map\n:<math> \\langle \\cdot, \\cdot \\rangle : E \\times E \\rightarrow A </math>\nwhich satisfies the following properties:\n\n*For all ''x'', ''y'', ''z'' in ''E'', and α, β in '''C''':\n\n::<math> \\langle x, \\alpha y + \\beta z \\rangle = \\alpha \\langle x, y \\rangle + \\beta \\langle x, z \\rangle</math>\n\n:(''i.e.'' the inner product is linear in its second argument).\n\n*For all ''x'', ''y'' in ''E'', and a in ''A'':\n::<math> \\langle x, y a \\rangle = \\langle x, y \\rangle a </math>\n\n*For all ''x'', ''y'' in ''E'':\n\n::<math> \\langle x, y \\rangle = \\langle y, x \\rangle^*,</math>\n\n:from which it follows that the inner product is [[conjugate linear]] in its first argument (''i.e.'' it is a [[sesquilinear form]]).\n\n*For all ''x'' in ''E'':\n\n::<math> \\langle x, x \\rangle \\geq 0</math>\n\n:and\n\n::<math> \\langle x, x \\rangle = 0 \\iff x = 0.</math>\n\n:(An element of a C*-algebra ''A'' is said to be ''positive'' if it is [[self-adjoint]] with non-negative [[Spectrum (functional analysis)|spectrum]].)<ref>{{cite book| last = Arveson| first = William| authorlink = William Arveson|title = An Invitation to C*-Algebras| publisher = Springer-Verlag| year = 1976| page = 35}}</ref><ref>In the case when ''A'' is non-unital, the spectrum of an element is calculated in the C*-algebra generated by adjoining a unit to ''A''.</ref>\n\n=== Hilbert ''A''-modules ===\nAn analogue to the [[Cauchy–Schwarz inequality]] holds for an inner-product ''A''-module ''E'':<ref>This result in fact holds for semi-inner-product ''A''-modules, which may have non-zero elements ''x'' such that <''x'',''x''> = 0, as the proof does not rely on the [[nondegeneracy]] property.</ref>\n\n:<math>\\langle x, y \\rangle \\langle y, x \\rangle \\leq \\Vert \\langle y, y \\rangle \\Vert \\langle x, x \\rangle</math>\n\nfor ''x'', ''y'' in ''E''.\n\nOn the pre-Hilbert module ''E'', define a norm by\n\n:<math>\\Vert x \\Vert = \\Vert \\langle x, x \\rangle \\Vert^\\frac{1}{2}.</math>\n\nThe norm-completion of ''E'', still denoted by ''E'', is said to be a '''Hilbert ''A''-module''' or a '''Hilbert C*-module over the C*-algebra ''A'''''.\nThe Cauchy–Schwarz inequality implies the inner product is jointly continuous in norm and can therefore be extended to the completion.\n\nThe action of ''A'' on ''E'' is continuous: for all ''x'' in ''E''\n\n:<math>a_{\\lambda} \\rightarrow a \\Rightarrow xa_{\\lambda} \\rightarrow xa.</math>\n\nSimilarly, if {''e<sub>λ</sub>''} is an [[Approximate identity|approximate unit]] for ''A'' (a [[Net (mathematics)|net]] of self-adjoint elements of ''A'' for which ''ae''<sub>λ</sub> and ''e''<sub>λ</sub>''a'' tend to ''a'' for each ''a'' in ''A''), then for ''x'' in ''E''\n\n:<math> xe_\\lambda \\rightarrow x</math>\n\nwhence it follows that ''EA'' is [[Dense set|dense]] in ''E'', and ''x''1 = ''x'' when ''A'' is unital.\n \nLet\n\n:<math> \\langle E, E \\rangle = \\operatorname{span} \\{ \\langle x, y \\rangle | x, y \\in E \\},</math>\n\nthen the [[Closure (topology)|closure]] of <''E'',''E''> is a two-sided ideal in ''A''. Two-sided ideals are C*-subalgebras and therefore possess approximate units. One can verify that ''E''<''E'',''E''> is dense in ''E''. In the case when <''E'',''E''> is dense in ''A'', ''E'' is said to be '''full'''. This does not generally hold.\n\n== Examples ==\n\n=== Hilbert spaces ===\nA complex Hilbert space ''H'' is a Hilbert '''C'''-module under its inner product, the complex numbers being a C*-algebra with an involution given by [[complex conjugation]].\n\n===Vector bundles===\nIf ''X'' is a [[locally compact Hausdorff space]] and ''E'' a [[vector bundle]] over ''X'' with a [[Riemannian metric]] ''g'', then the space of continuous sections of ''E'' is a Hilbert ''C(X)''-module. The inner product is given by\n::<math> \\langle f,h\\rangle (x):=g(f(x),h(x)).</math>\n\nThe converse holds as well: Every countably generated Hilbert C*-module over a commutative C*-algebra ''A = C(X)''  is isomorphic to the space of sections vanishing at infinity of a continuous field of Hilbert spaces over ''X''.\n\n=== C*-algebras ===\nAny C*-algebra ''A'' is a Hilbert ''A''-module under the inner product <''a'',''b''> = ''a''*''b''.  By the C*-identity, the Hilbert module norm coincides with C*-norm on ''A''.\n\nThe (algebraic) [[direct sum of modules|direct sum]] of ''n'' copies of ''A''\n\n:<math> A^n = \\oplus_1^n A</math>\n\ncan be made into a Hilbert ''A''-module by defining\n\n:<math>\\langle (a_i), (b_i) \\rangle = \\sum a_i^* b_i.</math>\n\nOne may also consider the following subspace of elements in the countable direct product of ''A''\n\n:<math> \\ell_2(A)= \\mathcal{H}_A = \\{ (a_i) | \\sum a_i^{*}a_i\\text{ converges in }A \\}.</math>\n\nEndowed with the obvious inner product (analogous to that of ''A<sup>n</sup>''), the resulting Hilbert ''A''-module is called the '''standard Hilbert module'''.\n\n== See also ==\n* [[Operator algebra]]\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n* {{cite book |last=Lance |first=E. Christopher|title=Hilbert C*-modules: A toolkit for operator algebraists |series=London Mathematical Society Lecture Note Series|year=1995 |publisher=Cambridge University Press |location=Cambridge, England}}\n\n== External links ==\n* {{MathWorld |title=Hilbert C*-Module |urlname=HilbertC-Star-Module}}\n* [http://www.imn.htwk-leipzig.de/~mfrank/hilmod.html Hilbert C*-Modules Home Page], a literature list\n\n{{DEFAULTSORT:Hilbert C-module}}\n[[Category:C*-algebras]]\n[[Category:Operator theory]]\n[[Category:Theoretical physics]]"
    },
    {
      "title": "K-graph C*-algebra",
      "url": "https://en.wikipedia.org/wiki/K-graph_C%2A-algebra",
      "text": "{{Multiple issues|\n{{cleanup-reorganize|date=June 2012}}\n{{confusing|date=June 2012}}\n{{context|date=June 2012}}\n{{technical|date=May 2012}}\n{{expert-subject|Mathematics|date=June 2012}}\n}}\n\n{{lowercase}}\nIn [[mathematics]], a '''k-graph''' (or higher-rank [[graph theory|graph]], graph of rank k) is a [[countable]] [[category (mathematics)|category]] <math>\\Lambda</math> with [[domain of a function|domain]] and [[codomain]] maps <math>r</math> and <math>s</math>, together with a [[functor]] <math>d : \\Lambda \\to \\mathbb{N}^k</math> which satisfies the following [[factorisation]] property: if <math>d ( \\lambda ) = m+n</math> then there are unique <math>\\mu , \\nu \\in \\Lambda</math> with <math>d ( \\mu ) = m , d ( \\nu ) = n</math> such that <math>\\lambda = \\mu \\nu</math>.\n\nAside from its category theory definition, one can think of k-graphs as higher dimensional analogue of directed graphs (digraphs). k- here signifies the number of \"colors\" of edges that are involved in the graph. \nIf k=1, k-graph is just a regular directed graph.\nIf k=2, there are two different colors of edges involved in the graph and additional factorization rules of 2-color equivalent classes should be defined. The factorization rule on k-graph skeleton is what distinguishes one k-graph defined on the same skeleton from another k-graph. k- can be any natural number greater than or equal to 1. \n\nThe reason k-graphs were first introduced by Kumjian, Pask et. al. was to create examples of C*-algebra from them. k-graphs consist of two parts: skeleton and factorization rules defined on the given skeleton. Once k-graph is well-defined, one can define functions called 2-cocycles on each graph, and C*-algebras can be built from k-graphs and 2-cocycles. k-graphs are relatively simple to understand from graph theory perspective, yet just complicated enough to reveal different interesting properties in the C*-algebra level. The properties such as homotopy and cohomology on the 2-cocycles defined on k-graphs have implications to C*-algebra and K-theory research efforts. No other known use of k-graphs exist to this day. k-graphs are studied solely for the purpose of creating C*-algebras from them.\n\n== Background ==\nThe finite graph theory in a directed graph form a mathematics category under concatenation called the free object category (which is generated by a graph). The length of a path in <math>E</math> gives a\nfunctor from this category into the [[natural number]]s <math>\\mathbb{N}</math>.\nA ''k-graph'' is a natural generalisation of this concept which was introduced in 2000 by Alex Kumjian and David Pask.<ref>{{citation |first1=A.|last1=Kumjian |first2=D.A. |last2=Pask |title=''Higher rank graph C*-algebras'' |journal=[[The New York Journal of Mathematics]] | volume=6 |pages=1–20 | year=2000 |url=http://nyjm.albany.edu/j/2000/6-1.html}}</ref>\n\n\n\n== Examples ==\n* It can be shown that a 1-graph is precisely the path category of a directed graph.\n* The category <math>T^k</math> consisting of a single object and ''k'' commuting morphisms <math>{f_1,...,f_k}</math>, together with the map <math>d:T^k\\to\\mathbb{N}^k</math> defined <math>d(f_1^{n_1}...f_k^{n_k})=(n_1 , \\ldots , n_k)</math>, is a k-graph.\n* Let <math>\\Omega_k = \\{ (m,n) : m,n \\in \\mathbb{Z}^k , m \\le n \\}</math> then <math>\\Omega_k</math> is a k-graph when gifted with the structure maps <math>r(m,n)=(m,m)</math>, <math>s(m,n)=(n,n)</math>, <math>(m,n)(n,p)=(m,p)</math> and <math>d(m,n) = n-m</math>.\n\n== Notation ==\nThe notation for k-graphs is borrowed extensively from the corresponding notation for categories:\n* For <math>n \\in \\mathbb{N}^k</math> let <math>\\Lambda^n = d^{-1} (n)</math>.\n* By the factorisation property it follows that <math>\\Lambda^0 = \\operatorname{Obj} ( \\Lambda )</math>.\n* For <math>v,w \\in \\Lambda^0</math> and <math>X \\subseteq \\Lambda</math> we have <math>v X = \\{ \\lambda \\in X : r ( \\lambda ) = v \\}</math>, <math>X w = \\{ \\lambda \\in X : s ( \\lambda ) = w \\}</math> and <math> v X w = v X \\cap X w</math>.\n* If <math> 0 < \\# v \\Lambda^n < \\infty</math> for all <math>v \\in \\Lambda^0</math> and <math>n \\in \\mathbb{N}^k</math> then <math>\\Lambda</math> is said to be row-finite with no sources.\n\n== Visualisation - Skeletons ==\nA k-graph is best visualised by drawing its 1-skeleton as a [[edge coloring|k-coloured graph]] <math>E=(E^0,E^1,r,s,c)</math> where\n<math>E^0 = \\Lambda^0</math>, <math>E^1 = \\cup_{i=1}^k \\Lambda^{e_i}</math>, <math>r,s</math> inherited\nfrom <math>\\Lambda</math>\nand <math> c: E^1 \\to \\{ 1 , \\ldots , k \\}</math> defined by <math>c (e) = i</math>\nif and only if <math>e \\in \\Lambda^{e_i}</math> where <math>e_1 , \\ldots , e_n</math> are the canonical\ngenerators for <math>\\mathbb{N}^k</math>. The factorisation property in <math>\\Lambda</math> for elements\nof degree <math>e_i+e_j</math> where <math>i \\neq j </math> gives rise to relations between the edges of\n<math>E</math>.\n\n== C*-algebra ==\nAs with graph-algebras one may associate a C*-algebra to a k-graph:\n\nLet <math>\\Lambda</math> be a row-finite k-graph with no sources then a '''Cuntz–Krieger <math>\\Lambda</math> family''' in a [[C*-algebra]] B is a collection <math>\\{ s_\\lambda : \\lambda \\in \\Lambda \\}</math> of [[operator (mathematics)|operators]] in B such that\n#  <math>s_\\lambda s_\\mu = s_{\\lambda \\mu}</math> if <math> \\lambda , \\mu  , \\lambda \\mu \\in \\Lambda</math>;\n# <math> \\{ s_v : v \\in \\Lambda^0 \\}</math> are mutually orthogonal [[projection (linear algebra)|projections]];\n# if <math> d ( \\mu ) = d ( \\nu )</math> then <math> s_\\mu^* s_\\nu = \\delta_{\\mu , \\nu} s_{s ( \\mu )}</math>;\n# <math>s_v = \\sum_{\\lambda \\in v \\Lambda^n} s_\\lambda s_\\lambda^*</math> for all <math>n \\in \\mathbb{N}^k</math> and <math>v \\in \\Lambda^0</math>.\n\n<math>C^* ( \\Lambda )</math> is then the [[universal property|universal]] C*-algebra generated by a Cuntz–Krieger <math>\\Lambda</math>-family.\n\n== References ==\n{{reflist}}\n* {{citation|title=Graph algebras |volume=103 |series=CBMS Regional Conference Series in Mathematics |first1=I. |last1=Raeburn |publisher=[[American Mathematical Society]] }}\n\n{{DEFAULTSORT:K-graph C-algebra}}\n[[Category:C*-algebras]]"
    },
    {
      "title": "Kadison–Kastler metric",
      "url": "https://en.wikipedia.org/wiki/Kadison%E2%80%93Kastler_metric",
      "text": "{{short description|Metric on the C*-algebras on a fixed Hilbert space}}\n\nIn [[mathematics]], the '''Kadison–Kastler metric''' is a [[metric space|metric]] on the space of [[C*-algebra|C<sup>*</sup>-algebras]] on a fixed [[Hilbert space]]. It is the [[Hausdorff distance]] between the [[unit ball]]s of the two C<sup>*</sup>-algebras, under the norm-induced metric on the space of all [[bounded operator]]s on that Hilbert space.\n\nIt was used by [[Richard Kadison]] and [[Daniel Kastler]] to study the perturbation theory of [[von Neumann algebra]]s.<ref>{{Cite journal|last=Kadison|first=Richard V.|last2=Kastler|first2=Daniel|date=January 1972|title=Perturbations of Von Neumann Algebras I Stability of Type|url=http://dx.doi.org/10.2307/2373592|journal=American Journal of Mathematics|volume=94|issue=1|pages=38|doi=10.2307/2373592|issn=0002-9327}}</ref>\n\n==Formal definition==\nLet <math>\\mathcal{H}</math> be a Hilbert space and <math>B(\\mathcal{H})</math> denote the set of all bounded operators on <math>\\mathcal{H}</math>. If <math>\\mathfrak{A}</math> and <math>\\mathfrak{B}</math> are linear subspaces of <math>B(\\mathcal{H})</math> and <math>\\mathfrak{A}_1, \\mathfrak{B}_1</math> denote their unit balls, respectively, the ''Kadison–Kastler'' distance between them is defined as,\n:<math>\\| \\mathfrak{A} - \\mathfrak{B} \\| := \\sup \\{ \\|A - \\mathfrak{B}_1\\|, \\|B - \\mathfrak{A}_1 \\| : A \\in \\mathfrak{A}_1, B \\in \\mathfrak{B}_1 \\}.</math>\nThe above notion of distance defines a metric on the space of C<sup>*</sup>-algebras which is called the ''Kadison-Kastler metric''.\n\n==References==\n{{reflist}}\n\n{{DEFAULTSORT:Kadison-Kastler metric}}\n[[Category:C*-algebras]]"
    },
    {
      "title": "KK-theory",
      "url": "https://en.wikipedia.org/wiki/KK-theory",
      "text": "{{DISPLAYTITLE:''KK''-theory}}\n{{about|KK-theory in mathematics|an epistemological concept|KK-principle|the Kaluza-Klein theory of electromagnetism and gravity|Kaluza–Klein theory}}\nIn [[mathematics]], '''''KK''-theory''' is a common generalization both of [[K-homology]] and [[operator K-theory|K-theory]] as an additive [[functor#Bifunctors|bivariant functor]] on [[separable space|separable]] [[C*-algebras]].  This notion was introduced by the Russian mathematician [[Gennadi Kasparov]]<ref>G. Kasparov. The operator K-functor and extensions of C*-algebras. Izv. Akad. Nauk. SSSR\nSer. Mat. 44 (1980), 571-636</ref> in 1980.\n\nIt was influenced by Atiyah's concept of [[Fredholm module]]s for the [[Atiyah–Singer index theorem]], and the classification of [[Ideal_(ring_theory)|extension]]s of [[C*-algebra]]s by [[Lawrence G. Brown]], [[Ronald G. Douglas]], and Peter Arthur Fillmore in 1977.<ref>Brown, L. G.; Douglas, R. G.; Fillmore, P. A., \"Extensions of  C*-algebras and K-homology\", ''[[Annals of Mathematics]]'' (2) 105 (1977), no. 2, 265&ndash;324.  {{MathSciNet|id=0458196}}</ref>  In turn, it has had great success in operator algebraic formalism toward the index theory and the classification of [[nuclear C*-algebra]]s, as it was the key to the solutions of many problems in operator K-theory, such as, for instance, the mere calculation of ''K''-groups.  Furthermore, it was essential in the development of the [[Baum–Connes conjecture]] and plays a crucial role in [[noncommutative topology]].\n\n''KK''-theory was followed by a series of similar bifunctor constructions such as the '''''E''-theory'''<!--boldface per WP:R#PLA--> and the [[bivariant periodic cyclic theory]], most of them having more [[Category theory|category-theoretic]] flavors, or concerning another class of algebras rather than that of the separable ''C''*-algebras, or incorporating [[Group action (mathematics)|group action]]s.\n\n== Definition ==\nThe following definition is quite close to the one originally given by Kasparov. This is the form in which most KK-elements arise in applications.\n\nLet ''A'' and ''B'' be separable ''C''*-algebras, where ''B'' is also assumed to be σ-unital. The set of cycles is the set of triples (''H'', ρ, ''F''), where ''H'' is a countably generated graded [[Hilbert module]] over ''B'', ρ is a *-representation of ''A'' on ''H'' as even bounded operators which commute with ''B'', and ''F'' is a bounded operator on ''H'' of degree 1 which again commutes with ''B''.  They are required to fulfill the condition that\n\n:<math>[F, \\rho(a)], (F^2-1)\\rho(a), (F-F^*)\\rho(a)</math>\n\nfor ''a'' in ''A'' are all ''B''-compact operators.  A cycle is said to be degenerate if all three expressions are 0 for all ''a''.\n\nTwo cycles are said to be homologous, or homotopic, if there is a cycle between ''A'' and ''IB'', where ''IB'' denotes the ''C''*-algebra of continuous functions from [0,1] to ''B'', such that there is an even unitary operator from the 0-end of the homotopy to the first cycle, and a unitary operator from the 1-end of the homotopy to the second cycle.\n\nThe '''KK-group KK(A, B) between A and B''' is then defined to be the set of cycles modulo homotopy.  It becomes an abelian group under the direct sum operation of bimodules as the addition, and the class of the degenerate modules as its neutral element.\n\nThere are various, but equivalent definitions of the KK-theory, notably the one due to [[Joachim Cuntz]]<ref>J. Cuntz. A new look at KK-theory. K-Theory 1 (1987), 31-51</ref> which eliminates bimodule and 'Fredholm' operator F from the picture and puts the accent entirely on the homomorphism ρ. More precisely it can be defined as the set of homotopy classes\n\n:<math>KK(A,B) = [qA, K(H) \\otimes B]</math>,\n\nof *-homomorphisms from the classifying algebra ''qA'' of quasi-homomorphisms to the ''C''*-algebra of compact operators of an infinite dimensional separable Hilbert space tensored with ''B''. Here, ''qA'' is defined as the kernel of the map from the ''C''*-algebraic free product ''A''*''A'' of ''A'' with itself to ''A'' defined by the identity on both factors.\n\n== Properties ==\nWhen one takes the ''C''*-algebra '''C''' of the complex numbers as the first argument of ''KK'' as in ''KK''('''C''', ''B'') this additive group is naturally isomorphic to the ''K''<sub>0</sub>-group ''K''<sub>0</sub>(''B'') of the second argument ''B''.  In the Cuntz point of view, a ''K''<sub>0</sub>-class of ''B'' is nothing but a homotopy class of *-homomorphisms from the complex numbers to the stabilization of ''B''. Similarly when one takes the algebra ''C''<sub>0</sub>('''R''') of the continuous functions on the real line decaying at infinity as the first argument, the obtained group ''KK''(''C''<sub>0</sub>('''R'''), ''B'') is naturally [[isomorphic]] to ''K''<sub>1</sub>(''B'').\n\nAn important property of ''KK''-theory is the so-called '''Kasparov product''', or the composition product,\n\n:<math>KK(A,B) \\times KK(B,C) \\to KK(A,C)</math>,\n\nwhich is bilinear with respect to the additive group structures.  In particular each element of ''KK''(''A'', ''B'') gives a homomorphism of ''K''<sub>*</sub>(''A'') → ''K''<sub>*</sub>(''B'') and another homomorphism ''K''*(''B'') → ''K''*(''A'').\n\nThe product can be defined much more easily in the Cuntz picture given that there are natural maps from ''QA'' to ''A'', and from ''B'' to ''K''(''H'') ⊗ ''B'' which induce ''KK''-equivalences.\n\nThe composition product gives a new [[Category (mathematics)|category]] <math>\\mathsf{KK}</math>, whose objects are given by the separable ''C''*-algebras while the morphisms between them are given by elements of the corresponding KK-groups.  Moreover, any *-homomorphism of ''A'' into ''B'' induces an element of ''KK''(''A'', ''B'') and this correspondence gives a functor from the original category of the separable ''C''*-algebras into <math>\\mathsf{KK}</math>.  The approximately inner automorphisms of the algebras become identity morphisms in <math>\\mathsf{KK}</math>.\n\nThis functor <math>\\mathsf{C^*\\!-\\!alg} \\to \\mathsf{KK}</math> is universal among the [[split-exact]], homotopy invariant and stable additive functors on the category of the separable ''C''*-algebras.  Any such theory satisfies [[Bott periodicity]] in the appropriate sense since <math>\\mathsf{KK}</math> does.\n\nThe Kasparov product can be further generalized to the following form:\n\n:<math>KK(A, B \\otimes E) \\times KK(B \\otimes D, C) \\to KK(A \\otimes D, C \\otimes E).</math>\n\nIt contains as special cases not only the K-theoretic [[cup product]], but also the K-theoretic [[Cap product|cap]], cross, and slant products and the product of extensions.\n\n== Notes ==\n{{reflist}}\n\n== References ==\n{{refbegin}}\n* B. Blackadar, [https://books.google.com/books?id=wfoCkgAACAAJ ''Operator Algebras: Theory of C*-Algebras and Von Neumann Algebras''], Encyclopaedia of Mathematical Sciences '''122''', Springer (2005)\n* A. Connes, ''Noncommutative Geometry'', Academic Press (1994)\n{{refend}}\n\n==External links==\n*{{nlab|id=KK-theory}}\n*{{nlab|id=E-theory}}\n\n[[Category:K-theory]]\n[[Category:C*-algebras]]"
    },
    {
      "title": "Locally compact quantum group",
      "url": "https://en.wikipedia.org/wiki/Locally_compact_quantum_group",
      "text": "{{Context|date=October 2009}}\n\nA '''locally compact quantum group''' is a relatively new [[C*-algebra]]ic approach toward [[quantum group]]s that generalizes the [[Kac algebra]], [[compact quantum group|compact-quantum-group]] and [[Hopf algebra|Hopf-algebra]] approaches. Earlier attempts at a unifying definition of quantum groups using, for example, multiplicative unitaries have enjoyed some success but have also encountered several technical problems.\n\nOne of the main features distinguishing this new approach from its predecessors is the axiomatic existence of left and right invariant weights. This gives a [[noncommutative geometry|noncommutative]] analogue of left and right [[Haar measure|Haar measures]] on a locally compact Hausdorff group.\n\n== Definitions ==\nBefore we can even begin to properly define a locally compact quantum group, we first need to define a number of preliminary concepts and also state a few theorems.\n\n'''Definition (weight).''' Let <math> A </math> be a [[C*-algebra]], and let <math> A_{\\geq 0} </math> denote the set of [[C*-algebra#Self-adjoint elements|positive elements]] of <math> A </math>. A [[von Neumann algebra#Weights, states, and traces|'''weight''']] on <math> A </math> is a function <math> \\phi: A_{\\geq 0} \\to [0,\\infty] </math> such that\n* <math> \\phi(a_{1} + a_{2}) = \\phi(a_{1}) + \\phi(a_{2}) </math> for all <math> a_{1},a_{2} \\in A_{\\geq 0} </math>, and\n* <math> \\phi(r \\cdot a) = r \\cdot \\phi(a) </math> for all <math> r \\in [0,\\infty) </math> and <math> a \\in A_{\\geq 0} </math>.\n\n'''Some notation for weights.''' Let <math> \\phi </math> be a weight on a C*-algebra <math> A </math>. We use the following notation:\n* <math> \\mathcal{M}_{\\phi}^{+} := \\{ a \\in A_{\\geq 0} \\mid \\phi(a) < \\infty \\} </math>, which is called the set of all '''positive <math> \\phi </math>-integrable elements''' of <math> A </math>.\n* <math> \\mathcal{N}_{\\phi} := \\{ a \\in A \\mid \\phi(a^{*} a) < \\infty \\} </math>, which is called the set of all '''<math> \\phi </math>-square-integrable elements''' of <math> A </math>.\n* <math> \\mathcal{M}_{\\phi} := \\text{Span} ~ \\mathcal{M}_{\\phi}^{+} = \\mathcal{N}_{\\phi}^{*} \\mathcal{N}_{\\phi} </math>, which is called the set of all '''<math> \\phi </math>-integrable''' elements of <math> A </math>.\n\n'''Types of weights.''' Let <math> \\phi </math> be a weight on a C*-algebra <math> A </math>.\n* We say that <math> \\phi </math> is '''faithful''' if and only if <math> \\phi(a) \\neq 0 </math> for each non-zero <math> a \\in A_{\\geq 0} </math>.\n* We say that <math> \\phi </math> is '''lower semi-continuous''' if and only if the set <math> \\{ a \\in A_{\\geq 0} \\mid \\phi(a) \\leq \\lambda \\} </math> is a closed subset of <math> A </math> for every <math> \\lambda \\in [0,\\infty] </math>.\n* We say that <math> \\phi </math> is '''densely defined''' if and only if <math> \\mathcal{M}_{\\phi}^{+} </math> is a dense subset of <math> A_{\\geq 0} </math>, or equivalently, if and only if either <math> \\mathcal{N}_{\\phi} </math> or <math> \\mathcal{M}_{\\phi} </math> is a dense subset of <math> A </math>.\n* We say that <math> \\phi </math> is '''proper''' if and only if it is non-zero, lower semi-continuous and densely defined.\n\n'''Definition (one-parameter group).''' Let <math> A </math> be a C*-algebra. A '''one-parameter group''' on <math> A </math> is a family <math> \\alpha = (\\alpha_{t})_{t \\in \\mathbb{R}} </math> of *-automorphisms of <math> A </math> that satisfies <math> \\alpha_{s} \\circ \\alpha_{t} = \\alpha_{s + t} </math> for all <math> s,t \\in \\mathbb{R} </math>. We say that <math> \\alpha </math> is '''norm-continuous''' if and only if for every <math> a \\in A </math>, the mapping <math> \\mathbb{R} \\to A </math> defined by <math> t \\mapsto {\\alpha_{t}}(a) </math> is continuous.\n\n'''Definition (analytic extension of a one-parameter group).''' Given a norm-continuous one-parameter group <math> \\alpha </math> on a C*-algebra <math> A </math>, we are going to define an [[analytic continuation|analytic extension]] of <math> \\alpha </math>. For each <math> z \\in \\mathbb{C} </math>, let\n:<math> I(z) := \\{ y \\in \\mathbb{C} \\mid |\\Im(y)| \\leq |\\Im(z)| \\} </math>,\nwhich is a horizontal strip in the complex plane. We call a function <math> f: I(z) \\to A </math> '''norm-regular''' if and only if the following conditions hold:\n* It is analytic on the interior of <math> I(z) </math>, i.e., for each <math> y_{0} </math> in the interior of <math> I(z) </math>, the limit <math> \\displaystyle \\lim_{y \\to y_{0}} \\frac{f(y) - f(y_{0})}{y - y_{0}} </math> exists with respect to the norm topology on <math> A </math>.\n* It is norm-bounded on <math> I(z) </math>.\n* It is norm-continuous on <math> I(z) </math>.\nSuppose now that <math> z \\in \\mathbb{C} \\setminus \\mathbb{R} </math>, and let\n:<math>\nD_{z} := \\{ a \\in A \\mid \\text{There exists a norm-regular} ~ f: I(z) \\to A ~ \\text{such that} ~ f(t) = {\\alpha_{t}}(a) ~ \\text{for all} ~ t \\in \\mathbb{R} \\}.\n</math>\nDefine <math> \\alpha_{z}: D_{z} \\to A </math> by <math> {\\alpha_{z}}(a) := f(z) </math>. The function <math> f </math> is uniquely determined (by the theory of complex-analytic functions), so <math> \\alpha_{z} </math> is well-defined indeed. The family <math> (\\alpha_{z})_{z \\in \\mathbb{C}} </math> is then called the '''analytic extension''' of <math> \\alpha </math>.\n\n'''Theorem 1.''' The set <math> \\cap_{z \\in \\mathbb{C}} D_{z} </math>, called the set of '''analytic elements''' of <math> A </math>, is a dense subset of <math> A </math>.\n\n'''Definition (K.M.S. weight).''' Let <math> A </math> be a C*-algebra and <math> \\phi: A_{\\geq 0} \\to [0,\\infty] </math> a weight on <math> A </math>. We say that <math> \\phi </math> is a '''K.M.S. weight''' ('K.M.S.' stands for 'Kubo-Martin-Schwinger') on <math> A </math> if and only if <math> \\phi </math> is a ''proper weight'' on <math> A </math> and there exists a norm-continuous one-parameter group <math> (\\sigma_{t})_{t \\in \\mathbb{R}} </math> on <math> A </math> such that\n* <math> \\phi </math> is invariant under <math> \\sigma </math>, i.e., <math> \\phi \\circ \\sigma_{t} = \\phi </math> for all <math> t \\in \\mathbb{R} </math>, and\n* for every <math> a \\in \\text{Dom}(\\sigma_{i / 2}) </math>, we have <math> \\phi(a^{*} a) = \\phi(\\sigma_{i / 2}(a) [\\sigma_{i / 2}(a)]^{*}) </math>.\n\nWe denote by <math>M(A)</math> the multiplier algebra of <math>A</math>.\n\n'''Theorem 2.''' If <math> A </math> and <math> B </math> are C*-algebras and <math> \\pi: A \\to M(B) </math> is a non-degenerate *-homomorphism (i.e., <math> \\pi[A] B </math> is a dense subset of <math> B </math>), then we can uniquely extend <math> \\pi </math> to a *-homomorphism <math> \\overline{\\pi}: M(A) \\to M(B) </math>.\n\n'''Theorem 3.''' If <math> \\omega: A \\to \\mathbb{C} </math> is a state (i.e., a positive linear functional of norm <math> 1 </math>) on <math> A </math>, then we can uniquely extend <math> \\omega </math> to a state <math> \\overline{\\omega}: M(A) \\to \\mathbb{C} </math> on <math> M(A) </math>.\n\n'''Definition (Locally compact quantum group).''' A (C*-algebraic) '''locally compact quantum group''' is an ordered pair <math> \\mathcal{G} = (A,\\Delta) </math>, where <math> A </math> is a C*-algebra and <math> \\Delta: A \\to M(A \\otimes A) </math> is a ''non-degenerate'' *-homomorphism called the [[coalgebra|'''co-multiplication''']], that satisfies the following four conditions:\n* The co-multiplication is co-associative, i.e., <math> \\overline{\\Delta \\otimes \\iota} \\circ \\Delta = \\overline{\\iota \\otimes \\Delta} \\circ \\Delta </math>.\n* The sets <math> \\left\\{ \\overline{\\omega \\otimes \\text{id}}(\\Delta(a)) ~ \\big| ~ \\omega \\in A^{*}, ~ a \\in A \\right\\} </math> and <math> \\left\\{ \\overline{\\text{id} \\otimes \\omega}(\\Delta(a)) ~ \\big| ~ \\omega \\in A^{*}, ~ a \\in A \\right\\} </math> are linearly dense subsets of <math> A </math>.\n* There exists a faithful K.M.S. weight <math> \\phi </math> on <math> A </math> that is left-invariant, i.e., <math> \\phi \\! \\left( \\overline{\\omega \\otimes \\text{id}}(\\Delta(a)) \\right) = \\overline{\\omega}(1_{M(A)}) \\cdot \\phi(a) </math> for all <math> \\omega \\in A^{*} </math> and <math> a \\in \\mathcal{M}_{\\phi}^{+} </math>.\n* There exists a K.M.S. weight <math> \\psi </math> on <math> A </math> that is right-invariant, i.e., <math> \\psi \\! \\left( \\overline{\\text{id} \\otimes \\omega}(\\Delta(a)) \\right) = \\overline{\\omega}(1_{M(A)}) \\cdot \\psi(a) </math> for all <math> \\omega \\in A^{*} </math> and <math> a \\in \\mathcal{M}_{\\phi}^{+} </math>.\n\nFrom the definition of a locally compact quantum group, it can be shown that the right-invariant K.M.S. weight <math> \\psi </math> is automatically faithful. Therefore, the faithfulness of <math> \\psi </math> is a redundant condition and does not need to be postulated.\n\n== Duality ==\nThe category of locally compact quantum groups allows for a dual construction with which one can prove that the bi-dual of a locally compact quantum group is isomorphic to the original one. This result gives a far-reaching generalization of [[Pontryagin duality]] for locally compact Hausdorff abelian groups.\n\n== Alternative formulations ==\nThe theory has an equivalent formulation in terms of [[von Neumann algebra]]s.\n\n== See also ==\n* [[Locally compact space]]\n* [[Locally compact field]]\n* [[Locally compact group]]\n\n== References ==\n*Johan Kustermans & Stefaan Vaes. \"[http://ac.els-cdn.com/S0012959300010557/1-s2.0-S0012959300010557-main.pdf?_tid=c4b7ba68-d3dd-11e4-be2d-00000aab0f26&acdnat=1427391197_20003d7195c234c79d91d9881103d7dd Locally Compact Quantum Groups.]\" Annales Scientifiques de l’École Normale Supérieure. Vol. 33, No. 6 (2000), pp. 837-934.\n* Thomas Timmermann. \"An Invitation to Quantum Groups and Duality - From Hopf Algebras to Multiplicative Unitaries and Beyond.\" EMS Textbooks in Mathematics, European Mathematical Society (2008).\n\n[[Category:C*-algebras]]\n[[Category:Functional analysis]]\n[[Category:Quantum groups]]\n[[Category:Harmonic analysis]]\n[[Category:Representation theory]]"
    },
    {
      "title": "Naimark's problem",
      "url": "https://en.wikipedia.org/wiki/Naimark%27s_problem",
      "text": "'''Naimark's problem''' is a question in [[functional analysis]] asked by {{harvs|txt|authorlink=Mark Naimark|last=Naimark|year=1951}}. It asks whether every [[C*-algebra]] that has only one [[irreducible representation|irreducible <math> * </math>-representation]] up to [[Self-adjoint operator#Spectral theorem|unitary equivalence]] is [[isomorphic]] to the <math> * </math>-algebra of [[Compact operator on Hilbert space|compact operator]]s on some (not necessarily separable) [[Hilbert space]].\n\nThe problem has been solved in the affirmative for special cases (specifically for separable and Type-I C*-algebras). {{harvtxt|Akemann|Weaver|2004}} used the [[diamond principle|<math> \\diamondsuit </math>-Principle]] to construct a [[C*-algebra]] with <math> \\aleph_{1} </math> generators that serves as a counterexample to Naimark's Problem. More precisely, they showed that the existence of a counterexample generated by [[Aleph One|<math> \\aleph_{1} </math>]] elements is independent of the axioms of [[Zermelo–Fraenkel set theory]] and the [[axiom of choice|Axiom of Choice]] (<math> \\mathsf{ZFC} </math>).\n\nWhether Naimark's problem itself is independent of <math> \\mathsf{ZFC} </math> remains unknown.\n\n==See also==\n*[[List of statements undecidable in ZFC|List of statements undecidable in <math> \\mathsf{ZFC} </math>]]\n*[[Gelfand–Naimark theorem|Gelfand-Naimark Theorem]]\n\n==References==\n*{{Citation | last1 = Akemann | first1 = Charles | last2 = Weaver | first2 = Nik | title = Consistency of a counterexample to Naimark's problem | doi = 10.1073/pnas.0401489101 | mr = 2057719 | year = 2004 | journal = [[Proceedings of the National Academy of Sciences|Proceedings of the National Academy of Sciences of the United States of America]] | volume = 101 | issue = 20 | pages = 7522–7525 | arxiv = math.OA/0312135| bibcode = 2004PNAS..101.7522A }}\n*{{citation|first=M. A. |last=Naimark|title= Rings with involutions|journal= Uspehi Matem. Nauk |volume=3 |year=1948|pages= 52–145}}\n*{{citation|first=M. A. |last=Naimark|title=On a problem in the theory of rings with involution|journal= Uspehi Matem. Nauk |volume=6 |year=1951|pages= 160–164}}\n\n\n[[Category:Conjectures]]\n[[Category:C*-algebras]]\n[[Category:Independence results]]\n\n\n{{Mathanalysis-stub}}"
    },
    {
      "title": "Noncommutative torus",
      "url": "https://en.wikipedia.org/wiki/Noncommutative_torus",
      "text": "{{Expand German|Irrationale Rotationsalgebra|date=January 2018|topic=sci}}\n\nIn [[mathematics]], and more specifically in the theory of [[C*-algebra]]s, the '''noncommutative tori''' ''A''<sub>θ</sub>, also known as '''irrational rotation algebras''' for [[irrational number|irrational]] values of θ, form a family of noncommutative C*-algebras which generalize the [[C*-algebra#Commutative C.2A-algebras|algebra of continuous functions]] on the [[Torus|2-torus]]. Many topological and geometric properties of the classical 2-torus have algebraic analogues for the noncommutative tori, and as such they are fundamental examples of a [[Noncommutative geometry|noncommutative space]] in the sense of [[Alain Connes]].\n\n== Definition ==\nFor any real number ''θ'', the noncommutative torus ''A''<sub>''θ''</sub> is the C*-subalgebra of ''B''(''L''<sup>2</sup>('''S'''<sup>1</sup>)), the algebra of [[bounded linear operator]]s of [[square-integrable function]]s on the [[unit circle]] '''S'''<sup>1</sup> of '''C''', generated by the [[unitary operator|unitary]] elements ''U'' and ''V'', where ''U''(''f'')(''z'')=''zf''(''z'') and ''V''(''f'')(''z'')=''f''(''e''<sup>−2π ''i''θ</sup>''z''). A quick calculation shows that ''VU'' = ''e''<sup>−2π''i''θ</sup>''UV''.<ref name=\"Davidson97\">\n{{cite book\n|last=Davidson |first=Kenneth\n|title=C*-Algebras by Example\n|year=1997\n|publisher=Fields Institute\n|isbn=0-8218-0599-1\n|pages=166, 218–219, 234}}</ref>\n\n== Alternative characterizations ==\n* '''Universal property:''' ''A''<sub>''θ''</sub> can be defined (up to isomorphism) as the [[universal C*-algebra]] generated by two unitary elements ''U'' and ''V'' satisfying the relation ''VU''&nbsp;=&nbsp;e<sup>2π''i''θ</sup>''UV''.<ref name=\"Davidson97\" /> This definition extends to the case when ''θ'' is rational. In particular when ''θ''&nbsp;=&nbsp;0, ''A''<sub>''θ''</sub> is isomorphic to continuous functions on the [[torus|2-torus]] by the [[Gelfand representation#The C.2A-algebra case|Gelfand transform]].\n* '''Irrational rotation algebra:''' Let the infinite cyclic group '''Z''' act on the circle '''S'''<sup>1</sup> by the [[irrational rotation|rotation action]] by angle 2{{pi}}''iθ''. This induces an action of '''Z''' by automorphisms on the algebra of continuous functions ''C''('''S'''<sup>1</sup>). The resulting C*-[[crossed product]] ''C''('''S'''<sup>1</sup>) ⋊ '''Z''' is isomorphic to ''A''<sub>''θ''</sub>. The generating unitaries are the generator of the group '''Z''' and the identity function on the circle ''z'' : '''S'''<sup>1</sup> → '''C'''.<ref name=\"Davidson97\" />\n* '''Twisted group algebra:''' The function σ : '''Z'''<sup>2</sup> × '''Z'''<sup>2</sup> → '''C'''; σ((''m'',''n''), (''p'',''q'')) = ''e''<sup>2π''inpθ''</sup> is a [[group cohomology|group 2-cocycle]] on '''Z'''<sup>2</sup>, and the corresponding twisted [[group algebra]] ''C*''('''Z'''<sup>2</sup>;&nbsp;''σ'') is isomorphic to ''A''<sub>''θ''</sub>.\n\n== Classification and K-theory ==\nThe [[Operator K-theory|K-theory]] of ''A''<sub>''θ''</sub> is '''Z'''<sup>2</sup> in both even dimension and odd dimension, and so does not distinguish the irrational rotation algebras. But as an [[partially ordered group|ordered group]], ''K''<sub>0</sub> ≃ '''Z''' + ''θ'''''Z'''. Therefore, two noncommutative tori ''A''<sub>''θ''</sub> and ''A''<sub>''η''</sub> are isomorphic if and only if either ''θ''&nbsp;+&nbsp;''η'' or ''θ''&nbsp;−&nbsp;''η'' is an integer.<ref name=Davidson97 /><ref name=Rieffel81>{{cite journal|last=[[Marc Rieffel|Rieffel]]|first=Marc A.|title=C*-Algebras Associated with Irrational Rotations|journal=Pacific Journal of Mathematics|year=1981|volume=93|issue=2|doi=10.2140/pjm.1981.93.415|pages=415–429 [416]|url=http://msp.org/pjm/1981/93-2/pjm-v93-n2-p12-s.pdf|accessdate=28 February 2013}}</ref>\n\nTwo irrational rotation algebras ''A''<sub>''θ''</sub> and ''A''<sub>''η''</sub> are [[Morita equivalence#Further directions|strongly Morita equivalent]] if and only if ''θ'' and ''η'' are in the same orbit of the action of SL(2,&nbsp;'''Z''') on '''R''' by [[fractional linear transformations]]. In particular, the noncommutative tori with θ rational are Morita equivalent to the classical torus. On the other hand, the noncommutative tori with θ irrational are simple C*-algebras.<ref name=Rieffel81 />\n\n== References ==\n<references/>\n\n[[Category:C*-algebras]]\n[[Category:Noncommutative geometry]]"
    },
    {
      "title": "Nuclear C*-algebra",
      "url": "https://en.wikipedia.org/wiki/Nuclear_C%2A-algebra",
      "text": "In mathematics, a '''nuclear C*-algebra''' is a [[C*-algebra]] ''A'' such that the injective and projective C*-cross norms on ''A''⊗''B'' are the same for every C*-algebra ''B''. This property was first studied by {{harvtxt|Takesaki|1964}} under the name \"Property T\", which is not related to [[Kazhdan's property T]].\n\n== Characterizations ==\nNuclearity admits the following equivalent characterizations:\n\n* The identity map, as a [[completely positive map]], approximately factors through matrix algebras. By this equivalence, nuclearity can be considered a [[noncommutative topology|noncommutative]] analogue of the existence of [[partitions of unity]].\n* The [[enveloping von Neumann algebra]] is [[Von Neumann algebra#Amenable von Neumann algebras|injective]].\n* It is [[Amenable Banach algebra|amenable]] as a Banach algebra.\n* It is isomorphic to a C*-subalgebra ''B'' of the [[Cuntz algebra]] <math>\\mathcal{O}_2</math> with the property that there exists a [[conditional expectation]] from <math>\\mathcal{O}_2</math> to ''B''. This condition is only equivalent to the others for [[separable space|separable]] C*-algebras.\n\n==See also==\n*[[Nuclear space]]\n*[[Exact C*-algebra]]\n\n==References==\n*{{Citation | last1=Connes | first1=Alain | author1-link=Alain Connes | title=Classification of injective factors.  | jstor=1971057 | mr=0454659  | year=1976 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=104 | issue=1 | pages=73–115 | doi=10.2307/1971057}}\n*{{Citation | last1=Effros | first1=Edward G. | last2=Ruan | first2=Zhong-Jin | title=Operator spaces | url=http://www.oup.com/us/catalog/general/subject/Mathematics/PureMathematics/?ci=9780198534822 | publisher=The Clarendon Press Oxford University Press | series=London Mathematical Society Monographs. New Series | isbn=978-0-19-853482-2 | mr=1793753  | year=2000 | volume=23}}\n*{{Citation | last1=Lance | first1=E. Christopher | title=Operator algebras and applications, Part I (Kingston, Ont., 1980) | publisher=Amer. Math. Soc. | location=Providence, R.I. | series=Proc. Sympos. Pure Math. | mr=679721  | year=1982 | volume=38 | chapter=Tensor products and nuclear C*-algebras | pages=379–399}}\n*{{Citation | last1=Pisier | first1=Gilles | title=Introduction to operator space theory | publisher=[[Cambridge University Press]] | series=London Mathematical Society Lecture Note Series | isbn=978-0-521-81165-1 | mr=2006539  | year=2003 | volume=294}}\n*{{Citation | last1=Rørdam | first1=M. | title=Classification of nuclear C*-algebras. Entropy in operator algebras | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Encyclopaedia Math. Sci. | mr=1878882  | year=2002 | volume=126 | chapter=Classification of nuclear simple C*-algebras | pages=1–145}}\n*{{Citation | last1=Takesaki | first1=Masamichi | title=On the cross-norm of the direct product of C*-algebras | mr=0165384  | year=1964 | journal=The Tohoku Mathematical Journal. Second Series | issn=0040-8735 | volume=16 | pages=111–122 | doi=10.2748/tmj/1178243737}}\n*{{Citation | last1=Takesaki | first1=Masamichi | title=Theory of operator algebras. III | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Encyclopaedia of Mathematical Sciences | isbn=978-3-540-42913-5 | mr=1943007  | year=2003 | volume=127 | chapter=Nuclear C*-algebras | pages=153–204}}\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Nuclear C-algebra}}\n[[Category:C*-algebras]]\n\n[[it:C*-algebra#C*-algebra nucleare]]"
    },
    {
      "title": "Operator K-theory",
      "url": "https://en.wikipedia.org/wiki/Operator_K-theory",
      "text": "{{DISPLAYTITLE:Operator ''K''-theory}}\nIn [[mathematics]], '''operator K-theory''' is a [[noncommutative topology|noncommutative]] analogue of [[topological K-theory]] for [[Banach algebras]] with most applications used for [[C*-algebras]].\n\n==Overview==\nOperator K-theory resembles topological K-theory more than [[algebraic K-theory]]. In particular, a [[Bott periodicity theorem]] holds. So there are only two K-groups, namely ''K''<sub>0</sub>, which is equal to algebraic ''K''<sub>0</sub>, and ''K''<sub>1</sub>. As a consequence of the periodicity theorem, it satisfies [[excision theorem|excision]]. This means that it associates to an [[Algebraic extension|extension]] of [[C*-algebra]]s to a [[long exact sequence]], which, by Bott periodicity, reduces to an exact cyclic 6-term-sequence.\n\nOperator K-theory is a generalization of [[topological K-theory]], defined by means of [[vector bundle]]s on [[locally compact]] [[Hausdorff space]]s. Here, a vector bundle over a topological space ''X'' is associated to a projection in the C* algebra of matrix-valued—that is, <math>M_n(\\mathbb{C})</math>-valued—continuous functions over ''X''. Also, it is known that isomorphism of vector bundles translates to Murray-von Neumann equivalence of the associated projection in ''K''&nbsp;&otimes;&nbsp;''C''(''X''), where ''K'' is the compact operators on a separable Hilbert space.\n\nHence, the ''K''<sub>0</sub> group of a (not necessarily commutative) C*-algebra ''A'' is defined as [[Grothendieck group]] generated by the Murray-von Neumann equivalence classes of projections in ''K''&nbsp;&otimes;&nbsp;''C''(''X''). ''K''<sub>0</sub> is a functor from the category of C*-algebras and *-homomorphisms, to the category of abelian groups and group homomorphisms. The higher K-functors are defined via a C*-version of the suspension: ''K''<sub>n</sub>(''A'')&nbsp;=&nbsp;''K''<sub>0</sub>(''S''<sup>''n''</sup>(''A'')), where\n''SA''&nbsp;=&nbsp;''C''<sub>0</sub>(0,1)&nbsp;&otimes;&nbsp;''A''.\n\nHowever, by Bott periodicity, it turns out that ''K''<sub>''n''+2</sub>(''A'') and ''K''<sub>''n''</sub>(''A'') are isomorphic for each ''n'', and thus the only groups produced by this construction are ''K''<sub>0</sub> and ''K''<sub>1</sub>.\n\nThe key reason for the introduction of K-theoretic methods into the study of C*-algebras was the [[Fredholm index]]: Given a bounded linear operator on a Hilbert space that has finite-dimensional kernel and cokernel, one can associate to it an integer, which, as it turns out, reflects the 'defect' on the operator - i.e. the extent to which it is not invertible. The Fredholm index map appears in the 6-term exact sequence given by the [[Calkin algebra]]. In the analysis on manifolds, this index and its generalizations played a crucial role in the [[Atiyah-Singer index theorem|index theory]] of Atiyah and Singer, where the topological index of the manifold can be expressed via the index of elliptic operators on it. Later on, [[Lawrence G. Brown|Brown]], [[Ronald G. Douglas|Douglas]] and [[Peter A. Fillmore|Fillmore]] observed that the Fredholm index was the missing ingredient in classifying [[essentially normal operator]]s up to certain natural equivalence. These ideas, together with [[George A. Elliott|Elliott]]'s classification of [[AF C*-algebra]]s via K-theory led to a great deal of interest in adapting methods such as K-theory from algebraic topology into the study of operator algebras.\n\nThis, in turn, led to [[K-homology]], [[Gennadi Kasparov|Kasparov]]'s bivariant [[KK-theory]], and, more recently, [[Alain Connes|Connes]] and [[Nigel Higson|Higson]]'s [[E-theory]].\n\n==References==\n* {{Citation | last1=Rordam | first1=M. | last2=Larsen | first2=Finn | last3=Laustsen | first3=N. | title=An introduction to ''K''-theory for ''C<sup>∗</sup>-algebras | publisher=[[Cambridge University Press]] | series=London Mathematical Society Student Texts | isbn=978-0-521-78334-7| year=2000 | volume=49}}\n\n[[Category:K-theory]]\n[[Category:Operator algebras]]\n[[Category:C*-algebras]]"
    },
    {
      "title": "Partial isometry",
      "url": "https://en.wikipedia.org/wiki/Partial_isometry",
      "text": "In [[functional analysis]] a '''partial isometry''' is a linear map between Hilbert spaces such that it is an [[isometry]] on the [[orthogonal complement]] of its [[kernel (algebra)|kernel]].\n\nThe orthogonal complement of its kernel is called the '''initial subspace''' and its range is called the '''final subspace'''.\n\nPartial isometries appear in the [[polar decomposition]].\n\n== General ==\n\nThe concept of partial isometry can be defined in other equivalent ways.  If ''U'' is an isometric map defined on a closed subset  ''H''<sub>1</sub> of a Hilbert space ''H'' then we can define an extension ''W'' of ''U'' to all of ''H'' by the condition that ''W'' be zero on the orthogonal complement of ''H''<sub>1</sub>. Thus a partial isometry is also sometimes defined as a closed partially defined isometric map.\n\nPartial isometries (and projections) can be defined in the more abstract setting of a [[semigroup with involution]]; the definition coincides with the one herein.\n\n== Operator Algebras ==\n\nFor [[operator algebra]]s one introduces the initial and final subspaces:\n:<math>\\mathcal{I}W:=\\mathcal{R}W^*W,\\,\\mathcal{F}W:=\\mathcal{R}WW^*</math>\n\n== C*-Algebras ==\n\nFor [[C*-algebra]]s one has the chain of equivalences due to the C*-property:\n:<math>(W^*W)^2=W^*W\\iff WW^*W=W\\iff W^*WW^*=W^*\\iff(WW^*)^2=WW^*</math>\nSo one defines partial isometries by either of the above and declares the initial resp. final projection to be '''W*W''' resp. '''WW*'''.\n\nA pair of projections are partitioned by the [[equivalence relation]]:\n:<math>P=W^*W,\\,Q=WW^*</math>\nIt plays an important role in [[K-theory]] for C*-algebras and in the [[Francis Joseph Murray (mathematician)|Murray]]-[[John von Neumann|von Neumann]] theory of projections in a [[von Neumann algebra]].\n\n== Special Classes ==\n\n=== Projections ===\n\nAny orthogonal projection is one with common initial and final subspace:\n\n:<math>P:\\mathcal{H}\\rightarrow\\mathcal{H}:\\quad\\mathcal{I}P=\\mathcal{F}P</math>\n\n=== Embeddings ===\n\nAny isometric embedding is one with full initial subspace:\n\n:<math>J:\\mathcal{H}\\hookrightarrow\\mathcal{K}:\\quad\\mathcal{I}J=\\mathcal{H}</math>\n\n=== Unitaries ===\n\nAny [[unitary operator]] is one with full initial and final subspace:\n\n:<math>U:\\mathcal{H}\\leftrightarrow\\mathcal{K}:\\quad\\mathcal{I}U=\\mathcal{H},\\,\\mathcal{F}U=\\mathcal{K}</math>\n\n''(Apart from these there are far more partial isometries.)''\n\n== Examples ==\n\n=== Nilpotents ===\n\nOn the two-dimensional complex Hilbert space the matrix\n\n:<math> \\begin{pmatrix}0 & 1 \\\\ 0 & 0 \\end{pmatrix} </math>\n\nis a partial isometry with initial subspace\n\n: <math> \\{0\\} \\oplus \\mathbb{C}</math>\n\nand final subspace\n\n: <math>  \\mathbb{C} \\oplus \\{0\\}. </math>\n\n=== Leftshift and Rightshift ===\n\nOn the square summable sequences the operators\n\n:<math>R:\\ell^2(\\mathbb{N})\\to\\ell^2(\\mathbb{N}):(x_1,x_2,\\ldots)\\mapsto(0,x_1,x_2,\\ldots)</math>\n\n:<math>L:\\ell^2(\\mathbb{N})\\to\\ell^2(\\mathbb{N}):(x_1,x_2,\\ldots)\\mapsto(x_2,x_3,\\ldots)</math>\n\nwhich are related by\n\n:<math>R^*=L</math>\n\nare partial isometries with initial subspace\n\n:<math>LR(x_1,x_2,\\ldots)=(x_1,x_2,\\ldots)</math>\n\nand final subspace:\n\n:<math>RL(x_1,x_2,\\ldots)=(0,x_2,\\ldots)</math>.\n\n== References ==\n*John B. Conway (1999). \"A course in operator theory\", AMS Bookstore, {{ISBN|0-8218-2065-6}}\n*Alan L. T. Paterson (1999). \"[https://books.google.com/books?id=aUPhBwAAQBAJ&printsec=frontcover#v=onepage&q=%22Partial%20isometry%22&f=false Groupoids, inverse semigroups, and their operator algebras]\", Springer, {{ISBN|0-8176-4051-7}}\n*Mark V. Lawson (1998). \"[https://books.google.com/books?id=2805q4tFiCkC&printsec=frontcover#v=onepage&q=%22partial%20isometry%22&f=false Inverse semigroups: the theory of partial symmetries]\". [[World Scientific]] {{ISBN|981-02-3316-7}}\n\n==External links ==\n*[https://web.archive.org/web/20141027161712/http://www.math.tamu.edu/~pskoufra/OANotes-PartialIsometries.pdf Important properties and proofs]\n*[http://math.stackexchange.com/questions/614331/equivalent-algebraic-definition-of-a-partial-isometry-in-a-c-algebra Alternative proofs]\n\n{{DEFAULTSORT:Partial Isometry}}\n[[Category:Operator theory]]\n[[Category:C*-algebras]]\n[[Category:Semigroup theory]]"
    },
    {
      "title": "Projectionless C*-algebra",
      "url": "https://en.wikipedia.org/wiki/Projectionless_C%2A-algebra",
      "text": "In [[mathematics]], a  '''projectionless C*-algebra''' is a [[C*-algebra]] with no nontrivial [[projection (linear algebra)#Orthogonal projections|projection]]s. For a unital C*-algebra, the projections 0 and 1 are trivial. While for a non-unital C*-algebra, only 0 is considered trivial. The problem of whether [[simple algebra|simple]] [[dimension (vector space)|infinite-dimensional]] C*-algebras with this property exist was posed in 1958 by [[Irving Kaplansky]],<ref name=\"b81\">{{citation\n | last = Blackadar | first = Bruce E.\n | issue = 1\n | journal = Journal of Operator Theory\n | mr = 613047\n | pages = 63–71\n | title = A simple unital projectionless C*-algebra\n | volume = 5\n | year = 1981}}.</ref> and the first example of one was published in 1981 by [[Bruce Blackadar]].<ref name=\"b81\"/><ref>{{citation|title=C*-algebras by Example|volume=6|series=Fields Institute Monographs|first=Kenneth R.|last=Davidson|publisher=American Mathematical Society|isbn=9780821871898|contribution=IV.8 Blackadar's Simple Unital Projectionless C*-algebra|pages=124–129|url=https://books.google.com/books?id=0TXteNfrzvcC&pg=PA124}}.</ref> For [[commutative property|commutative]] C*-algebras, being projectionless is equivalent to its [[spectrum of a C*-algebra|spectrum]] being [[connected space|connected]]. Due to this, being projectionless can be considered as a [[noncommutative topology|noncommutative]] analogue of a connected space.\n\n==Examples==\n* '''C''', the algebra of [[complex number]]s.\n* The [[Group algebra#The reduced group C.2A-algebra Cr.2A.28G.29|reduced group C*-algebra]] of the [[free group]] on finitely many generators.<ref>{{citation\n | last1 = Pimsner | first1 = M.\n | last2 = Voiculescu | first2 = D.\n | issue = 1\n | journal = Journal of Operator Theory\n | mr = 670181\n | pages = 131–156\n | title = ''K''-groups of reduced crossed products by free groups\n | volume = 8\n | year = 1982}}.</ref>\n* The [[Jiang-Su algebra]] is simple, projectionless, and [[KK-theory|KK-equivalent]] to '''C'''.<ref>{{citation\n| last1 = Jiang | first1 = Xinhui | last2 = Su | first2 = Hongbing | issue = 2 | journal = American Journal of Mathematics\n| pages = 359–413 | title = On a simple unital projectionless C*-algebra | volume = 121 | year = 1999 | doi = 10.1353/ajm.1999.0012}}</ref>\n\n==References==\n{{reflist}}\n\n{{DEFAULTSORT:Projectionless C-algebra}}\n[[Category:C*-algebras]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Real rank (C*-algebras)",
      "url": "https://en.wikipedia.org/wiki/Real_rank_%28C%2A-algebras%29",
      "text": "In [[mathematics]], the '''real rank''' of a [[C*-algebra]] is a [[noncommutative topology|noncommutative]] analogue of [[Lebesgue covering dimension]]. The notion was first introduced by [[Lawrence G. Brown]] and [[Gert K. Pedersen]].<ref>{{cite journal|last1=Brown|first1=Lawrence G|last2=Pedersen|authorlink1=Lawrence G. Brown|first2=Gert K|title=C*-algebras of real rank zero|journal=Journal of Functional Analysis|date=July 1991|volume=99|issue=1|pages=131–149|doi=10.1016/0022-1236(91)90056-B|zbl=0776.46026}}</ref>\n\n== Definition ==\nThe real rank of a unital C*-algebra ''A'' is the smallest non-negative integer ''n'', denoted RR(''A''), such that for every (''n''&nbsp;+&nbsp;1)-tuple (''x''<sub>0</sub>, ''x''<sub>1</sub>, ... ,''x''<sub>''n''</sub>) of [[self-adjoint]] elements of ''A'' and every ''ε''&nbsp;>&nbsp;0, there exists an (''n''&nbsp;+&nbsp;1)-tuple (''y''<sub>0</sub>, ''y''<sub>1</sub>, ... ,''y''<sub>''n''</sub>)\nof self-adjoint elements of ''A'' such that <math>\\sum_{i=0}^n y_i^2</math> is [[inverse element|invertible]] and\n<math>\\lVert \\sum_{i=0}^n (x_i - y_i)^2 \\rVert < \\varepsilon</math>. If no such integer exists, then the real rank of ''A'' is infinite. The real rank of a non-unital C*-algebra is defined to be the real rank of its [[unitization]].\n\n== Comparisons with dimension ==\nIf ''X'' is a [[locally compact space|locally compact]] [[Hausdorff space]], then RR(''C''<sub>0</sub>(''X'')) = dim(''X''), where dim is the Lebesgue covering dimension of ''X''. As a result, real rank is considered a noncommutative generalization of dimension, but real rank can be rather different when compared to dimension. For example, most [[noncommutative torus|noncommutative tori]] have real rank zero, despite being a noncommutative version of the two-dimensional [[torus]]. For locally compact Hausdorff spaces, being [[zero-dimensional space|zero-dimensional]] is equivalent to being [[totally disconnected space|totally disconnected]]. The analogous relationship fails for C*-algebras; while [[approximately finite-dimensional C*-algebra|AF-algebras]] have real rank zero, the converse is false. Formulas that hold for dimension may not generalize for real rank. For example, Brown and Pedersen conjectured that RR(''A'' &otimes; ''B'') ≤ RR(''A'') + RR(''B''), since it is true that dim(''X''&nbsp;&times;&nbsp;''Y'') ≤ dim(''X'')&nbsp;+&nbsp;dim(''Y''). They proved a special case that if ''A'' is AF and ''B'' has real rank zero, then ''A''&nbsp;&otimes;&nbsp;''B'' has real rank zero. But in general their conjecture is false, there are C*-algebras ''A'' and ''B'' with real rank zero such that ''A''&nbsp;&otimes;&nbsp;''B'' has real rank greater than zero.<ref>{{cite journal|last1=Kodaka|first1=Kazunori|last2=Osaka|first2=Hiroyuki|title=Real Rank of Tensor Products of C*-algebras|journal=Proceedings of the American Mathematical Society|date=July 1995|volume=123|issue=7|pages=2213–2215|doi=10.1090/S0002-9939-1995-1264820-4|zbl=0835.46053}}</ref>\n\n== Real rank zero ==\nC*-algebras with real rank zero are of particular interest. By definition, a unital C*-algebra has real rank zero if and only if the invertible self-adjoint elements of ''A'' are [[dense set|dense]] in the self-adjoint elements of ''A''. This condition is equivalent to the previously studied conditions:\n\n* (FS) The self-adjoint elements of ''A'' with finite [[spectrum (functional analysis)|spectrum]] are dense in the self-adjoint elements of ''A''.\n* (HP) Every [[hereditary C*-subalgebra]] of ''A'' has an [[approximate identity]] consisting of [[Projection (linear algebra)#Orthogonal projections|projections]].\n\nThis equivalence can be used to give many examples of C*-algebras with real rank zero including [[AW*-algebra]]s, [[Bunce–Deddens algebra]]s,<ref>{{cite journal|last1=Blackadar|first1=Bruce|last2=Kumjian|first2=Alexander|title=Skew Products of Relations and the Structure of Simple C*-Algebras|journal=Mathematische Zeitschrift|date=March 1985|volume=189|issue=1|pages=55–63|doi=10.1007/BF01246943|zbl=0613.46049}}</ref> and [[von Neumann algebra]]s. More broadly, [[simple algebra|simple]] unital [[purely infinite]] C*-algebras have real rank zero including the [[Cuntz algebra]]s and [[Cuntz–Krieger algebra]]s. Since simple [[graph C*-algebra]]s are either AF or purely infinite, every simple graph C*-algebra has real rank zero.\n\nHaving real rank zero is a property closed under taking [[direct limit]]s, hereditary C*-subalgebras, and [[Morita equivalence#Further directions|strong Morita equivalence]]. In particular, if ''A'' has real rank zero, then ''M''<sub>''n''</sub>(''A'') the algebra of ''n''&nbsp;×&nbsp;''n'' matrices over ''A'' has real rank zero for any integer ''n''&nbsp;&ge;&nbsp;1.\n\n== References ==\n{{reflist}}\n\n{{DEFAULTSORT:Real rank (C-algebras)}}\n[[Category:C*-algebras]]\n[[Category:Operator theory]]"
    },
    {
      "title": "Russo–Dye theorem",
      "url": "https://en.wikipedia.org/wiki/Russo%E2%80%93Dye_theorem",
      "text": "In [[mathematics]], the '''Russo–Dye theorem''' is a result in the field of [[functional analysis]]. It states that in a [[unital algebra|unital]] [[C*-algebra]], the closure of the [[convex hull]] of the [[unitary element]]s is the closed [[unit ball]].<ref name=\"Doran Belfi\">\n{{cite book | last = Doran | first = Robert S. |author2=Victor A. Belfi  | title = Characterizations of C*-Algebras: The Gelfand–Naimark Theorems | publisher = Marcel Dekker | location = New York | year = 1986 | isbn = 0-8247-7569-4 }}\n</ref>{{Rp|44}}\nThe theorem was published by B. Russo and H. A. Dye in 1966.<ref name=\"Russo Dye\">\n{{cite journal |last=Russo |first=B. |author2=H. A. Dye  |year=1966|title=A Note on Unitary Operators in C*-Algebras |journal=Duke Mathematical Journal |volume=33 |pages=413–416 |doi=10.1215/S0012-7094-66-03346-1 |issue=2 }}\n</ref>\n\n==Other formulations and generalizations==\n\nResults similar to the Russo–Dye theorem hold in more general contexts. For example, in a unital *-Banach algebra, the closed [[unit ball]] is contained in the closed [[convex hull]] of the [[unitary element]]s.<ref name=\"Doran Belfi\" />{{Rp|73}}\n\nA more precise result is true for the [[C*-algebra]] of all [[bounded linear operator]]s on a [[Hilbert space]]: If ''T'' is such an operator and ||''T''|| < 1&nbsp;&minus;&nbsp;2/''n'' for some integer ''n'' > 2, then ''T'' is the mean of ''n'' [[unitary operator]]s.<ref name=\"Analysis Now\">\n{{cite book | last = Pedersen | first = Gert K. | title = Analysis Now | publisher = Springer-Verlag | location = Berlin | year = 1989 | isbn = 0-387-96788-5 }}\n</ref>{{Rp|98}}\n\n==Applications==\n\nThis example is due to Russo & Dye,<ref name=\"Russo Dye\" /> Corollary 1: If ''U''(''A'') denotes the [[unitary element]]s of a [[C*-algebra]] ''A'', then the [[Operator norm|norm]] of a [[linear mapping]] ''f'' from ''A'' to a [[normed linear space]] ''B'' is\n:<math>\\sup_{U \\in U(A)} ||f(U)||.</math>\nIn other words, the norm of an operator can be calculated using only the unitary elements of the algebra.\n\n==Further reading==\n*  An especially simple proof of the theorem is given in: {{cite journal |last=Gardner |first=L. T. |year=1984 |title=An elementary proof of the Russo–Dye theorem |jstor=2044692 |journal=Proceedings of the American Mathematical Society |volume=90 |issue=1|pages=171 |doi=10.2307/2044692 }}\n\n==Notes==\n<references />\n\n{{DEFAULTSORT:Russo-Dye theorem}}\n[[Category:C*-algebras]]\n[[Category:Theorems in functional analysis]]\n[[Category:Unitary operators]]"
    },
    {
      "title": "Schröder–Bernstein theorems for operator algebras",
      "url": "https://en.wikipedia.org/wiki/Schr%C3%B6der%E2%80%93Bernstein_theorems_for_operator_algebras",
      "text": "The [[Schröder–Bernstein theorem]] from [[set theory]] has analogs in the context [[operator algebras]]. This article discusses such operator-algebraic results.\n\n== For von Neumann algebras ==\nSuppose '''M''' is a [[von Neumann algebra]] and ''E'', ''F'' are projections in '''M'''. Let ~ denote the [[Von Neumann algebra#Projections|Murray-von Neumann equivalence relation]] on '''M'''. Define a partial order « on the family of projections by ''E'' « ''F'' if ''E'' ~ ''F' '' ≤ ''F''. In other words, ''E'' « ''F'' if there exists a partial isometry ''U'' ∈ '''M''' such that ''U*U'' = ''E'' and ''UU*'' ≤ ''F''.\n\nFor closed subspaces ''M'' and ''N'' where projections ''P<sub>M</sub>'' and ''P<sub>N</sub>'', onto ''M'' and ''N'' respectively, are elements of '''M''', ''M'' « ''N'' if ''P<sub>M</sub>'' « ''P<sub>N</sub>''.\n\nThe '''Schröder–Bernstein theorem''' states that if ''M'' « ''N'' and ''N'' « ''M'', then ''M'' ~ ''N''.\n\nA proof, one that is similar to a set-theoretic argument, can be sketched as follows. Colloquially, ''N'' « ''M'' means that ''N'' can be isometrically embedded in ''M''. So\n\n:<math>M = M_0 \\supset N_0</math>\n\nwhere ''N''<sub>0</sub> is an isometric copy of ''N'' in ''M''. By assumption, it is also true that, ''N'', therefore ''N''<sub>0</sub>, contains an isometric copy ''M''<sub>1</sub> of ''M''. Therefore one can write\n\n:<math>M = M_0 \\supset N_0 \\supset M_1.</math>\n\nBy induction,\n\n:<math>M = M_0 \\supset N_0 \\supset M_1 \\supset N_1 \\supset M_2 \\supset N_2 \\supset \\cdots .</math>\n\nIt is clear that\n\n:<math>R = \\cap_{i \\geq 0} M_i = \\cap_{i \\geq 0} N_i.</math>\n\nLet\n\n:<math>M \\ominus N \\stackrel{\\mathrm{def}}{=} M \\cap (N)^{\\perp}.</math>\n\nSo\n\n:<math>\nM = \\oplus_{i \\geq 0} ( M_i \\ominus N_i ) \\quad \\oplus \\quad \\oplus_{j \\geq 0} ( N_j \\ominus M_{j+1}) \\quad \\oplus R\n</math>\n\nand\n\n:<math>\nN_0 = \\oplus_{i \\geq 1} ( M_i \\ominus N_i ) \\quad \\oplus \\quad \\oplus_{j \\geq 0} ( N_j \\ominus M_{j+1}) \\quad \\oplus R.\n</math>\n\nNotice\n\n:<math>M_i \\ominus N_i \\sim M \\ominus N \\quad \\mbox{for all} \\quad i.</math>\n\nThe theorem now follows from the countable additivity of  ~.\n\n== Representations of C*-algebras ==\nThere is also an analog of Schröder–Bernstein for representations of [[C*-algebras]]. If ''A'' is a C*-algebra, a '''[[Gelfand Naimark theorem|representation]]''' of ''A''  is a *-homomorphism ''φ'' from ''A'' into ''L''(''H''), the bounded operators on some Hilbert space ''H''.\n\nIf there exists a projection ''P'' in ''L''(''H'') where ''P'' ''φ''(''a'') = ''φ''(''a'') ''P'' for every ''a'' in ''A'', then a '''subrepresentation''' ''σ'' of ''φ'' can be defined in a natural way: ''σ''(''a'') is ''φ''(''a'') restricted to the range of ''P''. So ''φ'' then can be expressed as a direct sum of two subrepresentations ''φ'' = ''φ' '' ⊕ ''σ''.\n\nTwo representations ''φ''<sub>1</sub> and ''φ''<sub>2</sub>, on ''H''<sub>1</sub> and ''H''<sub>2</sub> respectively, are said to be '''unitarily equivalent''' if there exists an unitary operator ''U'': ''H''<sub>2</sub> → ''H''<sub>1</sub> such that ''φ''<sub>1</sub>(''a'')''U'' = ''Uφ''<sub>2</sub>(''a''), for every ''a''.\n\nIn this setting, the '''Schröder–Bernstein theorem''' reads:\n\n:If two representations ''&rho;'' and ''&sigma;'', on Hilbert spaces ''H'' and ''G'' respectively, are each unitarily equivalent to a subrepresentation of the other, then they are unitarily equivalent.\n\nA proof that resembles the previous argument can be outlined. The assumption implies that there exist surjective partial isometries from ''H'' to ''G'' and from ''G'' to ''H''. Fix two such partial isometries for the argument. One has\n\n:<math>\\rho = \\rho_1 \\simeq \\rho_1 ' \\oplus \\sigma_1 \\quad \\mbox{where} \\quad \\sigma_1 \\simeq \\sigma.</math>\n\nIn turn,\n\n:<math>\\rho_1 \\simeq \\rho_1 ' \\oplus (\\sigma_1 ' \\oplus \\rho_2) \\quad \\mbox{where} \\quad \\rho_2 \\simeq \\rho .</math>\n\nBy induction,\n\n:<math>\n\\rho_1 \\simeq \\rho_1 ' \\oplus \\sigma_1 ' \\oplus \\rho_2' \\oplus \\sigma_2 ' \\cdots \\simeq ( \\oplus_{i \\geq 1} \\rho_i ' ) \\oplus \n( \\oplus_{i \\geq 1} \\sigma_i '),\n</math>\n\nand\n\n:<math>\n\\sigma_1 \\simeq \\sigma_1 ' \\oplus \\rho_2' \\oplus \\sigma_2 ' \\cdots \\simeq ( \\oplus_{i \\geq 2} \\rho_i ' ) \\oplus \n( \\oplus_{i \\geq 1} \\sigma_i ').\n</math>\n\nNow each additional summand in the direct sum expression is obtained using one of the two fixed partial isometries, so\n\n:<math>\n\\rho_i ' \\simeq \\rho_j ' \\quad \\mbox{and} \\quad \\sigma_i ' \\simeq \\sigma_j ' \\quad \\mbox{for all} \\quad i,j \\;. \n</math>\n\nThis proves the theorem.\n\n==See also==\n* [[Schröder–Bernstein theorem for measurable spaces]]\n* [[Schröder–Bernstein property]]\n\n==References==\n*B. Blackadar, ''Operator Algebras'', Springer, 2006.\n\n{{DEFAULTSORT:Schroder-Bernstein theorems for operator algebras}}\n[[Category:Von Neumann algebras]]\n[[Category:C*-algebras]]"
    },
    {
      "title": "Spectrum of a C*-algebra",
      "url": "https://en.wikipedia.org/wiki/Spectrum_of_a_C%2A-algebra",
      "text": "In mathematics, the '''spectrum of a [[C*-algebra]]''' or '''dual of a C*-algebra''' ''A'', denoted ''Â'', is the set of [[unitary representation|unitary equivalence]] classes of  [[irreducible representation|irreducible]] *-representations of ''A''. A [[*-representation]] π of ''A'' on a [[Hilbert space]] ''H'' is '''irreducible''' if, and only if, there is no closed subspace ''K'' different from ''H'' and {0} which is invariant under all operators π(''x'') with ''x'' ∈ ''A''. We implicitly assume that irreducible representation means ''non-null'' irreducible representation, thus excluding trivial (i.e. identically 0) representations on one-[[dimension]]al [[space (mathematics)|spaces]]. As explained below, the spectrum ''Â'' is also naturally a [[topological space]]; this is similar to the notion of the [[spectrum of a ring]].\n\nOne of the most important applications of this concept is to provide a notion of [[duality (mathematics)|dual]] object for any [[locally compact group]].  This dual object is suitable for formulating a [[Fourier transform]] and a [[Plancherel theorem]] for [[unimodular group|unimodular]] [[separable space|separable]] locally compact groups of type I and a decomposition theorem for arbitrary representations of separable locally compact groups of type I.  The resulting duality theory for locally compact groups is however much weaker than the [[Tannaka–Krein duality]] theory for [[compact topological group]]s or [[Pontryagin duality]] for locally compact ''abelian'' groups, both of which are complete invariants. That the dual is not a complete invariant is easily seen as the  dual of any finite-dimensional full matrix algebra M<sub>''n''</sub>('''C''') consists of a single point.\n\n== Primitive spectrum ==\nThe [[topology]] of ''Â'' can be defined in several equivalent ways.  We first define it in terms of the '''primitive spectrum''' .\n\nThe primitive spectrum of ''A'' is the set of [[primitive ideal]]s Prim(''A'') of ''A'', where a primitive ideal is the kernel of an irreducible *-representation. The set of primitive ideals is a [[topological space]] with the '''hull-kernel topology''' (or '''Jacobson topology'''). This is defined as follows: If ''X'' is a set of primitive ideals, its '''hull-kernel closure''' is\n\n:<math> \\overline{X} = \\left \\{\\rho \\in \\operatorname{Prim}(A): \\rho \\supseteq \\bigcap_{\\pi \\in X} \\pi \\right \\}. </math>\n\nHull-kernel closure is easily shown to be an [[idempotent]] operation, that is\n\n:<math> \\overline{\\overline{X}} = \\overline{X},</math>\n\nand it can be shown to satisfy the [[Kuratowski closure axioms]]. As a consequence, it can be shown that there is a unique topology τ on Prim(''A'') such that the closure of a set ''X'' with  respect to τ is identical to the hull-kernel closure of ''X''.\n\nSince unitarily equivalent representations have the same kernel, the map π ↦ ker(π) factors through a [[surjective]] map\n\n:<math> \\operatorname{k}: \\hat{A} \\to \\operatorname{Prim}(A). </math>\n\nWe use the map ''k'' to define the topology on ''Â'' as follows:\n\n'''Definition'''. The open sets of ''Â'' are inverse images ''k''<sup>−1</sup>(''U'') of open subsets ''U'' of Prim(''A''). This is indeed a topology.\n\nThe hull-kernel topology is an analogue for non-commutative rings of the [[Zariski topology]] for commutative rings.\n\nThe topology on ''Â'' induced from the hull-kernel topology has other characterizations in terms of [[state (functional analysis)|state]]s of ''A''.\n\n== Examples ==\n\n=== Commutative C*-algebras ===\n[[File:3-dim commut algebra, subalgebras, ideals.svg|thumb|right|224px|3-dimensional  commutative C*-algebra and its ideals. Each of 8 ideals corresponds to a closed subset of discrete 3-points space (or to an open complement). Primitive ideals correspond to closed [[singleton (mathematics)|singletons]]. See details at the image description page.]]\n\nThe spectrum of a commutative C*-algebra ''A'' coincides with the [[Gelfand transformation|Gelfand dual]] of ''A'' (not to be confused with the [[Banach space|dual]] ''A''' of the Banach space ''A'').  In particular, suppose ''X'' is a [[compact space|compact]] [[Hausdorff space]].  Then there is a [[natural transformation|natural]] [[homeomorphism]]\n\n:<math> \\operatorname{I}: X \\cong \\operatorname{Prim}( \\operatorname{C}(X)).</math>\n\nThis mapping is defined by\n\n: <math>  \\operatorname{I}(x) = \\{f \\in \\operatorname{C}(X): f(x) = 0 \\}.</math>\n\nI(''x'') is a closed maximal ideal in C(''X'') so is in fact primitive. For details of the proof, see the Dixmier reference.  For a commutative C*-algebra,\n\n:<math> \\hat{A} \\cong \\operatorname{Prim}(A).</math>\n\n=== The C*-algebra of bounded operators ===\nLet ''H'' be a separable [[Hilbert space]]. ''L''(''H'') has two norm-closed *-ideals: ''I''<sub>0</sub>&nbsp;=&nbsp;{0} and the ideal ''K''&nbsp;=&nbsp;''K''(''H'') of compact operators.  Thus as a set, Prim(''L''(''H'')) =&nbsp;{''I''<sub>0</sub>,&nbsp;''K''}. Now\n\n* {''K''} is a closed subset of Prim(''L''(''H'')).\n* The closure of {''I''<sub>0</sub>} is Prim(''L''(''H'')).\n\nThus Prim(''L''(''H'')) is a non-Hausdorff space.\n\nThe spectrum of ''L''(''H'') on the other hand is much larger.  There are many inequivalent irreducible representations with kernel ''K''(''H'') or with kernel&nbsp;{0}.\n\n=== Finite-dimensional C*-algebras ===\nSuppose ''A'' is a finite-dimensional C*-algebra.  It is known ''A'' is isomorphic to a finite direct sum of full matrix algebras:\n\n:<math> A \\cong \\bigoplus_{e \\in \\operatorname{min}(A)} Ae, </math>\n\nwhere min(''A'') are the minimal central projections of ''A''.  The spectrum of ''A'' is canonically isomorphic to min(''A'') with the [[discrete topology]].  For finite-dimensional C*-algebras, we also have the isomorphism\n\n:<math> \\hat{A} \\cong \\operatorname{Prim}(A).</math>\n\n== Other characterizations of the spectrum ==\nThe hull-kernel topology is easy to describe abstractly, but in practice for C*-algebras associated to [[locally compact]] [[topological group]]s, other characterizations of the topology on the spectrum in terms of positive definite functions are desirable.\n\nIn fact, the topology on ''Â'' is intimately connected with the concept of [[weak containment]] of representations as is shown by the following:\n\n:'''Theorem'''. Let ''S'' be a subset of ''Â''. Then the following are equivalent for an irreducible representation π;\n:# The equivalence class of π in ''Â'' is in the closure of ''S''\n:# Every state associated to π, that is one of the form\n:::<math> f_\\xi(x) = \\langle \\xi  \\mid \\pi(x) \\xi \\rangle </math>\n::with ||ξ|| = 1, is the weak limit of states associated to representations in ''S''.\n\nThe second condition means exactly that π is weakly contained in ''S''.\n\nThe [[GNS construction]] is a recipe for associating states of a C*-algebra ''A'' to representations of ''A''. By one of the basic theorems associated to the GNS construction, a state ''f'' is [[pure state|pure]] if and only if the associated representation π<sub>''f''</sub> is irreducible. Moreover, the mapping κ : PureState(''A'') → ''Â'' defined by ''f'' ↦ π<sub>''f''</sub> is a surjective map.\n\nFrom the previous theorem one can easily prove the following;\n\n:'''Theorem''' The mapping\n::<math> \\kappa: \\operatorname{PureState}(A) \\to \\hat{A} </math>\n:given by the GNS construction is continuous and open.\n\n=== The space Irr<sub>''n''</sub>(''A'') ===\nThere is yet another characterization of the topology on ''Â'' which arises by considering the space of representations as a topological space with an appropriate pointwise convergence topology.  More precisely, let ''n'' be a cardinal number and let ''H<sub>n</sub>'' be the canonical Hilbert space of dimension ''n''.\n\nIrr<sub>''n''</sub>(''A'') is the space of irreducible *-representations of ''A'' on ''H<sub>n</sub>'' with the point-weak topology.  In terms of convergence of nets, this topology is defined by π<sub>''i''</sub> → π; if and only if\n\n:<math>\\langle \\pi_i(x) \\xi \\mid \\eta \\rangle \\to \\langle \\pi(x) \\xi \\mid \\eta \\rangle \\quad \\forall \\xi, \\eta \\in H_n \\ x \\in A. </math>\n\nIt turns out that this topology on Irr<sub>''n''</sub>(''A'') is the same as the point-strong topology, i.e. π<sub>''i''</sub> → π if and only if\n\n:<math> \\pi_i(x) \\xi \\to \\pi(x) \\xi \\quad \\mbox{ normwise } \\forall \\xi \\in H_n \\ x \\in A. </math>\n\n:'''Theorem'''. Let ''Â<sub>n</sub>'' be the subset of ''Â'' consisting of equivalence classes of representations whose underlying  Hilbert space has dimension ''n''. The canonical map Irr<sub>''n''</sub>(''A'') → ''Â<sub>n</sub>'' is continuous and open. In particular, ''Â<sub>n</sub>'' can be regarded as the quotient topological space of Irr<sub>''n''</sub>(''A'') under unitary equivalence.\n\n'''Remark'''.  The piecing together of the various ''Â<sub>n</sub>'' can be quite complicated.\n\n== Mackey–Borel structure ==\n''Â'' is a topological space and thus can also be regarded as a [[Borel set|Borel space]].  A famous conjecture of [[G. Mackey]] proposed that a ''separable'' locally compact group is of type I if and only if the Borel space is standard, i.e. is isomorphic (in the category of Borel spaces) to the underlying Borel space of a [[Polish space|complete separable metric space]].  Mackey called Borel spaces with this property '''smooth'''. This conjecture was proved by [[James Glimm]] for separable C*-algebras in the 1961 paper listed in the references below.\n\n'''Definition'''.  A non-degenerate *-representation π of a separable C*-algebra ''A'' is a '''factor representation''' if and only if the center of the von Neumann algebra generated by π(''A'') is one-dimensional.  A C*-algebra ''A'' is of type I if and only if any separable factor representation of ''A'' is a finite or countable multiple of an irreducible one.\n\nExamples of separable locally compact groups ''G'' such that C*(''G'') is of type I are [[connected space|connected]] (real) [[nilpotent]] [[Lie group]]s and connected real [[semi-simple]] Lie groups.  Thus the [[Heisenberg group]]s are all of type I. Compact and abelian groups are also of type I.\n\n:'''Theorem'''. If ''A'' is separable, ''Â'' is smooth if and only if ''A'' is of type I.\n\nThe result implies a far-reaching generalization of the structure of representations of separable type I C*-algebras and correspondingly of separable locally compact groups of type I.\n\n== Algebraic primitive spectra  ==\n{{see also|Primitive spectrum}}\nSince a C*-algebra ''A'' is a [[ring (mathematics)|ring]], we can also consider the set of [[primitive ideal]]s of ''A'', where ''A'' is regarded algebraically.  For a ring an ideal is primitive if and only if it is the [[Annihilator (ring theory)|annihilator]] of a [[simple module]].  It turns out that for a C*-algebra ''A'', an ideal is algebraically primitive [[if and only if]] it is primitive in the sense defined above.\n\n:'''Theorem'''.  Let ''A'' be a C*-algebra.  Any algebraically irreducible representation of ''A'' on a complex vector space is algebraically equivalent to a topologically irreducible *-representation on a Hilbert space.  Topologically irreducible *-representations on a Hilbert space are algebraically isomorphic if and only if they are unitarily equivalent.\n\nThis is the Corollary of Theorem 2.9.5 of the Dixmier reference.\n\nIf ''G'' is a locally compact group, the topology on dual space of the [[group algebra|group C*-algebra]] C*(''G'') of ''G'' is called the '''Fell topology''', named after [[J. M. G. Fell]].\n\n== References ==\n* J.  Dixmier, ''Les C*-algèbres et leurs représentations'', Gauthier-Villars, 1969.\n* J. Glimm, ''Type I C*-algebras'', Annals of Mathematics, vol 73, 1961.\n* G. Mackey, ''The Theory of Group Representations'', The University of Chicago Press, 1955.\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Spectrum of a C-algebra}}\n[[Category:C*-algebras]]\n[[Category:Spectral theory]]"
    },
    {
      "title": "State (functional analysis)",
      "url": "https://en.wikipedia.org/wiki/State_%28functional_analysis%29",
      "text": "In [[functional analysis]], a '''state''' of an [[operator system]] is a [[positive linear functional]] of [[operator norm|norm]] 1. States in functional analysis [[generalization|generalize]] the notion of [[density matrix|density matrices]] in quantum mechanics, which represent [[quantum state]]s, both {{section link|quantum state|Mixed states|Pure states|nopage=y}}. Density matrices in turn generalize [[quantum state|state vectors]], which only represent pure states.  For ''M'' an operator system in a [[C*-algebra]] ''A'' with identity, the set of all states of'' ''M, sometimes denoted by S(''M''),  is convex, weak-* closed in the Banach dual space ''M''<sup>*</sup>. Thus the set of all states of ''M'' with the weak-* topology forms a compact Hausdorff space, known as the '''state space of ''M'' '''.\n\nIn the C*-algebraic formulation of quantum mechanics, states in this previous sense correspond to physical states, i.e. mappings from physical observables (self-adjoint elements of the C*-algebra) to their expected measurement outcome (real number).\n\n== Jordan decomposition ==\n\nStates can be viewed as noncommutative generalizations of [[probability measure]]s. By [[Gelfand representation]], every commutative C*-algebra ''A'' is of the form ''C''<sub>0</sub>(''X'') for some locally compact Hausdorff ''X''. In this case, ''S''(''A'') consists of positive [[Radon measure]]s on ''X'', and the {{section link||pure states}} are the evaluation functionals on ''X''.\n\nMore generally, the [[GNS construction]] shows that every state is, after choosing a suitable representation, a [[State (functional analysis)#Vector states|vector state]].\n\nA bounded linear functional on a C*-algebra ''A'' is said to be '''self-adjoint''' if it is real-valued on the self-adjoint elements of ''A''. Self-adjoint functionals are noncommutative analogues of [[signed measure]]s.\n\nThe [[Hahn decomposition theorem|Jordan decomposition]] in measure theory says that every signed measure can be expressed as the difference of two positive measures supported on disjoint sets. This can be extended to the noncommutative setting.\n\n:'''Theorem''' Every self-adjoint ''f'' in ''A''<sup>*</sup> can be written as ''f'' = ''f''<sub>+</sub> &minus; ''f''<sub>&minus;</sub> where ''f''<sub>+</sub> and ''f''<sub>&minus;</sub> are positive functionals and ||''f''|| = ||''f''<sub>+</sub>|| + ||''f''<sub>&minus;</sub>||.\n\nA proof can be sketched as follows: Let Ω be the weak*-compact set of positive linear functionals on ''A'' with norm ≤ 1, and ''C''(Ω) be the continuous functions on Ω. ''A'' can be viewed as a closed linear subspace of ''C''(Ω) (this is ''[[Richard V. Kadison|Kadison]]'s function representation''). By Hahn–Banach, ''f'' extends to a ''g'' in ''C''(Ω)* with ||g|| = ||f||.\n\nUsing results from measure theory quoted above, one has\n\n:<math>g(\\cdot) = \\int \\cdot \\; d \\mu</math>\n\nwhere, by the self-adjointness of ''f'', ''μ'' can be taken to be a signed measure. Write\n\n:<math>\\mu = \\mu_+ - \\mu_-, \\;</math>\n\na difference of positive measures. The restrictions of the functionals ∫ · d''μ''<sub>+</sub>  and ∫ · d''μ''<sub>&minus;</sub> to ''A'' has the required properties of ''f''<sub>+</sub> and ''f''<sub>&minus;</sub>. This proves the theorem.\n\nIt follows from the above decomposition that ''A*'' is the linear span of states.\n\n==Some important classes of states==\n\n===Pure states===\nBy the [[Krein-Milman theorem]], the state space of ''M'' has extreme points{{clarify|date=September 2018}}. The extreme points of the state space are termed '''pure states''' and other states are known as '''mixed states'''.\n\n===Vector states===\nFor a Hilbert space ''H'' and a vector ''x'' in ''H'', the equation &omega;<sub>''x''</sub>(''A'') := ⟨''Ax'',''x''⟩ (for ''A'' in ''B(H)'' ), defines a positive linear functional on ''B(H)''. Since &omega;<sub>''x''</sub>(''1'')=||''x''||<sup>2</sup>, &omega;<sub>''x''</sub> is a state if ||''x''||=1. If ''A'' is a C*-subalgebra of ''B(H)'' and ''M'' an operator system in ''A'', then the restriction of &omega;<sub>''x''</sub> to ''M'' defines a positive linear functional on ''M''. The states of ''M'' that arise in this manner, from unit vectors in ''H'', are termed '''vector states''' of ''M''.\n\n===Normal states===\nA state <math>\\tau</math> is called '''normal''', iff for every monotone, increasing [[net (mathematics)|net]] <math>H_\\alpha</math> of operators with upper bound <math>H</math>,  <math>\\tau(H_\\alpha)\\;</math> converges to <math>\\tau(H)\\;</math>.\n\n===Tracial states===\nA '''tracial state''' is a state <math>\\tau</math> such that\n\n:<math>\\tau(AB)=\\tau (BA)\\;.</math>\n\nFor any separable C*-algebra, the set of tracial states is a [[Choquet theory|Choquet simplex]].\n\n===Factorial states===\nA '''factorial state''' of a C*-algebra ''A'' is a state such that the commutant of the corresponding GNS representation of ''A'' is a [[Von Neumann algebra#Factors|factor]].\n\n==See also==\n*[[Quantum state]]\n*[[Gelfand–Naimark–Segal construction]]\n*[[Quantum mechanics]]\n**[[Quantum state]]\n**[[Density matrix]]\n\n==References==\n*{{citation|first=H.|last= Lin|title=An Introduction to the Classification of Amenable C*-algebras|publisher=World Scientific|year=2001}}\n\n[[Category:Functional analysis]]\n[[Category:C*-algebras]]"
    },
    {
      "title": "Toeplitz algebra",
      "url": "https://en.wikipedia.org/wiki/Toeplitz_algebra",
      "text": "In [[operator algebras]], the '''Toeplitz algebra''' is the [[C*-algebra]] generated by the [[unilateral shift]] on the [[Hilbert space]] [[sequence space|''l''<sup>2</sup>('''N''')]].<ref>{{citation|title=A Short Course in Spectral Theory|volume=209|series=Graduate Texts in Mathematics|first=Arveson|last=William|publisher=Springer|isbn=0387953000}}</ref> Taking ''l''<sup>2</sup>('''N''') to be the [[Hardy space]] [[H square|''H''<sup>2</sup>]], the Toeplitz algebra consists of elements of the form\n\n:<math>T_f + K\\;</math>\n\nwhere ''T<sub>f</sub>'' is a [[Toeplitz operator]] with continuous symbol and ''K'' is a [[compact operator on Hilbert space|compact operator]]. \n\nToeplitz operators with continuous symbols commute modulo the compact operators. So the Toeplitz algebra  can be viewed as the C*-algebra extension of continuous functions on the circle by the compact operators. This extension is called the '''Toeplitz extension'''. \n\nBy [[Atkinson's theorem]], an element of the Toeplitz algebra ''T<sub>f</sub>'' + ''K'' is a [[Fredholm operator]] if and only if the symbol ''f'' of ''T<sub>f</sub>'' is invertible. In that case, the Fredholm index of ''T<sub>f</sub>'' + ''K'' is precisely the [[winding number]] of ''f'', the equivalence class of ''f'' in the [[fundamental group]] of the circle. This is a special case of the [[Atiyah-Singer index theorem]].\n\n[[Wold decomposition]] characterizes [[isometry|proper isometries]] acting on a Hilbert space. From this, together with properties of Toeplitz operators, one can conclude that the Toeplitz algebra is the [[universal C*-algebra]] generated by a proper isometry; this is ''Coburn's theorem''.\n\n== References ==\n<references />\n\n{{DEFAULTSORT:Toeplitz Algebra}}\n[[Category:C*-algebras]]"
    }
  ]
}