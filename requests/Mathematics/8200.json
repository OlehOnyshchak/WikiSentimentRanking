{
  "pages": [
    {
      "title": "Multidisciplinary design optimization",
      "url": "https://en.wikipedia.org/wiki/Multidisciplinary_design_optimization",
      "text": "{{refimprove|date=April 2017}}\n'''Multi-disciplinary design optimization''' ('''MDO''') is a field of [[engineering]] that uses [[optimization (mathematics)|optimization]] methods to solve [[design]] problems incorporating a number of disciplines. It is also known as multidisciplinary system design optimization (MSDO).\n\nMDO allows designers to incorporate all relevant disciplines simultaneously.  The optimum of the simultaneous problem is superior to the design found by optimizing each discipline sequentially, since it can exploit the interactions between the disciplines.  However, including all disciplines simultaneously significantly increases the [[computational complexity theory|complexity]] of the problem.\n\nThese techniques have been used in a number of fields, including [[automobile]] design, [[naval architecture]], [[electronics]], [[architecture]], [[computer]]s, and [[electricity distribution]].  However, the largest number of applications have been in the field of [[aerospace engineering]], such as [[aircraft]] and [[spacecraft]] design.  For example, the proposed [[Boeing]] [[blended wing body]] (BWB) aircraft concept has used MDO extensively in the conceptual and preliminary design stages.  The disciplines considered in the BWB design are [[aerodynamics]], [[structural analysis]], [[Air propulsion|propulsion]], [[control theory]], and [[economics]].\n\n==History==\nTraditionally engineering has normally been performed by teams, each with expertise in a specific discipline, such as aerodynamics or structures.  Each team would use its members' experience and judgement to develop a workable design, usually sequentially.  For example, the aerodynamics experts would outline the shape of the body, and the structural experts would be expected to fit their design within the shape specified.  The goals of the teams were generally performance-related, such as maximum speed, minimum [[drag (physics)|drag]], or minimum structural weight.\n\nBetween 1970 and 1990, two major developments in the aircraft industry changed the approach of aircraft design engineers to their design problems.  The first was [[computer-aided design]], which allowed designers to quickly modify and analyse their designs.  The second was changes in the procurement policy of most [[airline]]s and military organizations, particularly the [[military of the United States]], from a performance-centred approach to one that emphasized [[Product lifecycle management|lifecycle]] cost issues.  This led to an increased concentration on economic factors and the attributes known as the \"[[ilities]]\" including [[manufacturability]], [[reliability (engineering)|reliability]], [[maintainability]], etc.\n\nSince 1990, the techniques have expanded to other industries.  Globalization has resulted in more distributed, decentralized design teams.  The high-performance [[personal computer]] has largely replaced the centralized [[supercomputer]] and the [[Internet]] and [[local area network]]s have facilitated sharing of design information. Disciplinary design software in many disciplines (such as [[OptiStruct]] or [[NASTRAN]], a [[finite element analysis]] program for structural design) have become very mature.  In addition, many optimization algorithms, in particular the population-based algorithms, have advanced significantly.\n\n=== Origins in structural optimization ===\nWhereas optimization methods are nearly as old as [[calculus]], dating back to [[Isaac Newton]], [[Leonhard Euler]], [[Daniel Bernoulli]], and [[Joseph Louis Lagrange]], who used them to solve problems such as the shape of the [[catenary]] curve, numerical optimization reached prominence in the digital age. Its systematic application to structural design dates to its advocacy by Schmit in 1960. The success of structural optimization in the 1970s motivated the emergence of multidisciplinary design optimization (MDO) in the 1980s. Jaroslaw Sobieski championed decomposition methods specifically designed for MDO applications. The following synopsis focuses on optimization methods for MDO. First, the popular gradient-based methods used by the early structural optimization and MDO community are reviewed. Then those methods developed in the last dozen years are summarized.\n\n=== Gradient-based methods ===\nThere were two schools of structural optimization practitioners using [[Gradient|gradient]]-based methods during the 1960s and 1970s: optimality criteria and [[Mathematical optimization|mathematical programming]]. The optimality criteria school derived recursive formulas based on the [[Karush–Kuhn–Tucker conditions|Karush–Kuhn–Tucker (KKT) necessary conditions]] for an optimal design. The KKT conditions were applied to classes of structural problems such as minimum weight design with constraints on stresses, displacements, buckling, or frequencies [Rozvany, Berke, Venkayya, Khot, et al.] to derive resizing expressions particular to each class. The mathematical programming school employed classical gradient-based methods to structural optimization problems. The method of usable feasible directions, Rosen’s gradient projection (generalized reduce gradient) method, sequential unconstrained minimization techniques, sequential linear programming and eventually sequential quadratic programming methods were common choices. Schittkowski et al. reviewed the methods current by the early 1990s.\n\nThe gradient methods unique to the MDO community derive from the combination of optimality criteria with math programming, first recognized in the seminal work of Fleury and Schmit who constructed a framework of approximation concepts for structural optimization. They recognized that optimality criteria were so successful for stress and displacement constraints, because that approach amounted to solving the dual problem for [[Lagrange multipliers]] using linear Taylor series approximations in the reciprocal design space. In combination with other techniques to improve efficiency, such as constraint deletion, regionalization, and design variable linking, they succeeded in uniting the work of both schools. This approximation concepts based approach forms the basis of the optimization modules in modern structural design software such as Altair – Optistruct, ASTROS, MSC.Nastran, PHX [[ModelCenter]], Genesis, iSight, and I-DEAS.\n\nApproximations for structural optimization were initiated by the reciprocal approximation Schmit and Miura for stress and displacement response functions. Other intermediate variables were employed for plates. Combining linear and reciprocal variables, Starnes and Haftka developed a conservative approximation to improve buckling approximations. Fadel chose an appropriate intermediate design variable for each function based on a gradient matching condition for the previous point. Vanderplaats initiated a second generation of high quality approximations when he developed the force approximation as an intermediate response approximation to improve the approximation of stress constraints. Canfield developed a [[Rayleigh quotient]] approximation to improve the accuracy of eigenvalue approximations. Barthelemy and Haftka published a comprehensive review of approximations in 1993.\n\n=== Non-gradient-based methods  ===\nIn recent years, non-gradient-based evolutionary methods including [[Genetic algorithm|genetic algorithms]], [[Simulated annealing|simulated annealing]], and [[Ant colony optimization algorithms|ant colony algorithms]] came into existence. At present, many researchers are striving to arrive at a consensus regarding the best modes and methods for complex problems like impact damage, dynamic failure, and [[Real-time analyzer|real-time analyses]]. For this purpose, researchers often employ multiobjective and multicriteria design methods.\n\n=== Recent MDO methods ===\nMDO practitioners have investigated [[Optimization (mathematics)|optimization]] methods in several broad areas in the last dozen years. These include decomposition methods, [[approximation]] methods, [[evolutionary algorithm]]s, [[memetic algorithm]]s, [[response surface methodology]], reliability-based optimization, and [[multi-objective optimization]] approaches.\n\nThe exploration of decomposition methods has continued in the last dozen years with the development and comparison of a number of approaches, classified variously as hierarchic and non hierarchic, or collaborative and non collaborative. \nApproximation methods spanned a diverse set of approaches, including the development of approximations based on [[surrogate model]]s (often referred to as metamodels), variable fidelity models, and trust region management strategies. The development of multipoint approximations blurred the distinction with response surface methods. Some of the most popular methods include [[Kriging]] and the [[moving least squares]] method.\n\n[[Response surface methodology]], developed extensively by the statistical community, received much attention in the MDO community in the last dozen years. A driving force for their use has been the development of massively parallel systems for high performance computing, which are naturally suited to distributing the function evaluations from multiple disciplines that are required for the construction of response surfaces. Distributed processing is particularly suited to the design process of complex systems in which analysis of different disciplines may be accomplished naturally on different computing platforms and even by different teams.\n\nEvolutionary methods led the way in the exploration of non-gradient methods for MDO applications. They also have benefited from the availability of massively parallel high performance computers, since they inherently require many more function evaluations than gradient-based methods. Their primary benefit lies in their ability to handle discrete design variables and the potential to find globally optimal solutions.\n\nReliability-based optimization (RBO) is a growing area of interest in MDO. Like response surface methods and evolutionary algorithms, RBO benefits from parallel computation, because the numeric integration to calculate the probability of failure requires many function evaluations. One of the first approaches employed approximation concepts to integrate the probability of failure. The classical first-order reliability method (FORM) and second-order reliability method (SORM) are still popular. Professor Ramana Grandhi used appropriate normalized variables about the most probable point of failure, found by a two-point adaptive nonlinear approximation to improve the accuracy and efficiency. [[Southwest Research Institute]] has figured prominently in the development of RBO, implementing state-of-the-art reliability methods in commercial software. RBO has reached sufficient maturity to appear in commercial structural analysis programs like Altair's [[OptiStruct|Optistruct]] and MSC's [[Nastran]].\n\nUtility-based probability maximization (Bordley and Pollock, Operations Research, Sept, 2009, pg.1262) was developed in response to some logical concerns (e.g., Blau's Dilemma) with reliability-based design optimization. This approach focuses on maximizing the joint probability of both the objective function exceeding some value and of all the constraints being satisfied.  When there is no objective function, utility-based probability maximization reduces to a probability-maximization problem.   When there are no uncertainties in the constraints, it reduces to a constrained utility-maximization problem.  (This second equivalence arises because the utility of a function can always be written as the probability of that function exceeding some random variable.)   Because it changes the constrained optimization problem associated with reliability-based optimization into an unconstrained optimization problem, it often leads to computationally more tractable problem formulations.\n\nIn the marketing field there is a huge literature about optimal design for multiattribute products and services, based on experimental analysis to estimate models of consumers' utility functions. These methods are known as [[Conjoint analysis|Conjoint Analysis]]. Respondents are presented with alternative products, measuring preferences about the alternatives using a variety of scales and the utility function is estimated with different methods (varying from regression and surface response methods to choice models). The best design is formulated after estimating the model. The experimental design is usually optimized to minimize the variance of the estimators. These methods are widely used in practice.\n\n==Problem formulation==\n\nProblem formulation is normally the most difficult part of the process.  It is the selection of design variables, constraints, objectives, and models of the disciplines.  A further consideration is the strength and breadth of the interdisciplinary coupling in the problem.\n\n===Design variables===\n\nA design variable is a specification that is controllable from the point of view of the designer.  For instance, the thickness of a structural member can be considered a design variable.  Another might be the choice of material.  Design variables can be continuous (such as a wing span), discrete (such as the number of ribs in a wing), or boolean (such as whether to build a monoplane or a [[biplane]]).  Design problems with continuous variables are normally solved more easily.\n\nDesign variables are often bounded, that is, they often have maximum and minimum values.  Depending on the solution method, these bounds can be treated as constraints or separately.\n\nOne of the important variables that needs to be accounted is an uncertainty. Uncertainty, often referred to as epistemic uncertainty, arises due to lack of knowledge or incomplete information. Uncertainty is essentially unknown variable but it may causes the failure of system.\n\n===Constraints===\n\nA constraint is a condition that must be satisfied in order for the design to be feasible.  An example of a constraint in aircraft design is that the [[lift (force)|lift]] generated by a wing must be equal to the weight of the aircraft.  In addition to physical laws, constraints can reflect resource limitations, user requirements, or bounds on the validity of the analysis models.  Constraints can be used explicitly by the solution algorithm or can be incorporated into the objective using [[Lagrange multiplier]]s.\n\n===Objectives===\n\nAn objective is a numerical value that is to be maximized or minimized.  For example, a designer may wish to maximize profit or minimize weight.  Many solution methods work only with single objectives.  When using these methods, the designer normally weights the various objectives and sums them to form a single objective.  Other methods allow multiobjective optimization, such as the calculation of a [[Pareto efficiency|Pareto front]].\n\n===Models===\n\nThe designer must also choose models to relate the constraints and the objectives to the design variables.  These models are dependent on the discipline involved.  They may be empirical models, such as a [[regression analysis]] of aircraft prices, theoretical models, such as from [[computational fluid dynamics]], or reduced-order models of either of these.  In choosing the models the designer must trade off fidelity with analysis time.\n\nThe multidisciplinary nature of most design problems complicates model choice and implementation.  Often several iterations are necessary between the disciplines in order to find the values of the objectives and constraints.  As an example, the aerodynamic loads on a wing affect the structural deformation of the wing.  The structural deformation in turn changes the shape of the wing and the aerodynamic loads.  Therefore, in analysing a wing, the aerodynamic and structural analyses must be run a number of times in turn until the loads and deformation converge.\n\n===Standard form===\n\nOnce the design variables, constraints, objectives, and the relationships between them have been chosen, the problem can be expressed in the following form:\n\n: find <math>\\mathbf{x}</math>  that minimizes <math>J(\\mathbf{x})</math> subject to <math>\\mathbf{g}(\\mathbf{x})\\leq\\mathbf{0} </math>, <math>\\mathbf{h}(\\mathbf{x}) = \\mathbf{0} </math> and  <math>\\mathbf{x}_{lb}\\leq \\mathbf{x} \\leq \\mathbf{x}_{ub} </math>\n\nwhere <math>J</math> is an objective, <math>\\mathbf{x}</math> is a [[Vector (geometric)|vector]] of design variables, <math>\\mathbf{g}</math> is a vector of inequality constraints, <math>\\mathbf{h}</math> is a vector of equality constraints, and <math>\\mathbf{x}_{lb}</math> and <math>\\mathbf{x}_{ub}</math> are vectors of lower and upper bounds on the design variables.  Maximization problems can be converted to minimization problems by multiplying the objective by -1.  Constraints can be reversed in a similar manner.  Equality constraints can be replaced by two inequality constraints.\n\n==Problem solution==\n\nThe problem is normally solved using appropriate techniques from the field of optimization.  These include [[gradient]]-based algorithms, population-based algorithms, or others.  Very simple problems can sometimes be expressed linearly; in that case the techniques of [[linear programming]] are applicable.\n\n===Gradient-based methods===\n*[[Adjoint equation]]\n*[[Newton's method]]\n*[[Steepest descent]]\n*[[Conjugate gradient]]\n*[[Sequential quadratic programming]]\n\n===Gradient-free methods===\n* Hooke-Jeeves pattern search\n* [[Nelder-Mead method]]\n\n===Population-based methods===\n*[[Genetic algorithm]]\n*[[Memetic algorithm]]\n*[[Particle swarm optimization]]\n*[[Harmony search]]\n*[[ODMA]]\n\n===Other methods===\n*Random search\n*[[Grid search]]\n*[[Simulated annealing]]\n*[[Brute-force search|Direct search]]\n*[[IOSO]] (Indirect Optimization based on Self-Organization)\n\nMost of these techniques require large numbers of evaluations of the objectives and the constraints.  The disciplinary models are often very complex and can take significant amounts of time for a single evaluation.  The solution can therefore be extremely time-consuming.  Many of the optimization techniques are adaptable to [[parallel computing]].  Much current research is focused on methods of decreasing the required time.\n\nAlso, no existing solution method is guaranteed to find the [[global optimization|global optimum]] of a general problem (see [[No free lunch in search and optimization]]). Gradient-based methods find local optima with high reliability but are normally unable to escape a local optimum.  Stochastic methods, like simulated annealing and genetic algorithms, will find a good solution with high probability, but very little can be said about the mathematical properties of the solution.  It is not guaranteed to even be a local optimum.  These methods often find a different design each time they are run.\n\n==See also==\n* [[List of optimization software]]\n* [[ModelCenter]]\n* [[pSeven]]\n* [[OpenMDAO]]\n\n==References==\n{{reflist}}\n* Avriel, M., Rijckaert, M.J. and Wilde, D.J. (eds.), ''Optimization and Design'', Prentice-Hall, 1973.\n* Avriel, M. and Dembo, R.S. (eds.), ''Mathematical Programming Studies on Engineering Optimization'', North-Holland, 1979.\n* Cramer, E.J., Dennis Jr., J.E., Frank, P.D., Lewis, R.M., and Shubin, G.R., ''Problem Formulation for Multidisciplinary Optimization'', SIAM J. Optim., 4 (4): 754-776, 1994.\n* Deb, K. \"Current trends in evolutionary multi-objective optimization\", Int. J. Simul. Multi. Design Optim., 1 1 (2007) 1-8.\n* Martins, J. R. R. A. and Lambe, A. B., \"[http://mdolab.engin.umich.edu/content/multidisciplinary-design-optimization-survey-architectures-1 Multidisciplinary design optimization: A Survey of architectures]\", AIAA Journal, 51(9), 2013. [http://arc.aiaa.org/doi/full/10.2514/1.J051895 DOI: 10.2514/1.J051895]\n* Lambe, A. B. and Martins, J. R. R. A. \"[http://mdolab.engin.umich.edu/content/extensions-design-structure-matrix Extensions to the design structure matrix for the description of multidisciplinary design, analysis, and optimization processes]\". Structural and Multidisciplinary Optimization, 46:273–284, August 2012. [https://link.springer.com/article/10.1007%2Fs00158-012-0763-y doi:10.1007/s00158-012-0763-y].\n* Siddall, J.N., ''Optimal Engineering Design'', CRC, 1982.\n* Vanderplaats, G. N., ''Multidiscipline Design Optimization'', Vanderplaatz R&D, Inc., 2007.\n* Viana, F.A.C., Simpson, T.W., Balabanov, V. and Toropov, V. \"[http://arc.aiaa.org/doi/abs/10.2514/1.J052375 Metamodeling in multidisciplinary design optimization: How far have we really come?]\" AIAA Journal 52 (4) 670-690, 2014 (DOI: 10.2514/1.J052375)\n\n[[Category:Engineering disciplines]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "No free lunch in search and optimization",
      "url": "https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization",
      "text": "{{about|mathematical analysis of computing|associated folklore and broad implications of the theorem|No free lunch theorem}}\n\n[[File:No free lunch theorems figure.png|right|thumb|305px|The problem is to rapidly find a solution among candidates a, b, and c that is as good as any other, where goodness is either 0 or 1. There are eight instances (\"lunch plates\") f''xyz'' of the problem, where ''x,'' ''y,'' and ''z'' indicate the goodness of a, b, and c, respectively. Procedure (\"restaurant\") A evaluates candidates in the order a, b, c, and B evaluates candidates in reverse that order, but each \"charges\" 1 evaluation in 5 cases, 2 evaluations in 2 cases, and 3 evaluations in 1 case.]]\n\n<!-- \n\nThis figure contradicts the text of the article, and uses terms that are not defined in the article.\n\n[[File:Effects of NFL Therorem.PNG|right|thumb|450px|Graphical explanation of the consequences of the NFL theorems for [[heuristic algorithm]]s: all heuristics have the same average performance. A given heuristic may outperform another one for a given problem or problem domain, but it will be worse in others problem domains. Furthermore, the better it is in that domain, the worse it will be in other domains]]\n\n-->\nIn [[Computational complexity theory|computational complexity]] and [[optimization (mathematics)|optimization]] the '''no free lunch theorem''' is a result that states that for certain types of mathematical problems, the [[computational cost]] of finding a solution, averaged over all problems in the class, is the same for any solution method. No solution therefore offers a \"short cut\".  In computing, there are circumstances in which the outputs of all procedures solving a particular type of problem are statistically identical. A colourful way of describing such a circumstance, introduced by [[David Wolpert]] and [[William G. Macready]] in connection with the problems of search<!-- \n--><ref name=WM95>Wolpert, D.H., Macready, W.G. (1995), [https://pdfs.semanticscholar.org/8bdf/dc2c2777b395c086810c03a8cdeccc55c4db.pdf No Free Lunch Theorems for Search], Technical Report SFI-TR-95-02-010 (Santa Fe Institute).</ref><!-- \n-->\nand optimization,<!-- \n--><ref name=WM97>Wolpert, D.H., Macready, W.G. (1997), \"[http://georgemaciunas.com/wp-content/uploads/2012/07/Wolpert_NLFoptimization-1.pdf No Free Lunch Theorems for Optimization],\" ''IEEE Transactions on Evolutionary Computation'' '''1''', 67. http://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf</ref><!-- \n-->\nis to say that  '''[[TANSTAAFL|there is no free lunch]]'''. Wolpert had previously derived no free lunch theorems for [[machine learning]] ([[statistical inference]]).<!-- \n\n--><ref name=Wolpert96>Wolpert, David (1996), \"[https://pdfs.semanticscholar.org/4344/3dea498843ce1b148e7c8c1e64cdf1953ca7.pdf The Lack of A Priori Distinctions between Learning Algorithms],\" ''Neural Computation'', pp. 1341–1390.\n</ref> \nBefore Wolpert's article was published, Cullen Schaffer independently proved a restricted version of one of Wolpert's theorems and used it to critique the current state of machine learning research on the problem of induction.<!-- \n\n--><ref name=Schaffer94>Schaffer, Cullen (1994), \"[http://dml.cs.byu.edu/~cgc/docs/mldm_tools/Reading/LCG.pdf A conservation law for generalization performance],\" ''International Conference on Machine Learning,'' H. Willian and W. Cohen, Editors. San Francisco: Morgan Kaufmann, pp.259–265.\n</ref>\n\nIn the \"no free lunch\" [[metaphor]], each \"restaurant\" (problem-solving procedure) has a \"menu\" associating each \"lunch plate\" (problem) with a \"price\" (the performance of the procedure in solving the problem). The menus of restaurants are identical except in one regard – the prices are shuffled from one restaurant to the next. For an [[omnivore]] who is as likely to order each plate as any other, the average cost of lunch does not depend on the choice of restaurant. But a [[vegan]] who goes to lunch regularly with a [[carnivore]] who seeks economy might pay a high average cost for lunch. To methodically reduce the average cost, one must use advance knowledge of a) what one will order and b) what the order will cost at various restaurants. That is, improvement of performance in problem-solving hinges on using prior information to match procedures to problems.<ref name=WM97/><ref name=Schaffer94/> \n\nIn formal terms, there is no free lunch when the [[probability distribution]] on problem instances is such that all problem solvers have identically distributed results. In the case of [[search algorithm|search]], a problem instance is an [[objective function]], and a result is a [[sequence]] of values obtained in evaluation of [[candidate solutions]] in the [[function domain|domain]] of the function. For typical interpretations of results, search is an [[Optimization (mathematics)|optimization]] process. There is no free lunch in search if and only if the distribution on objective functions is [[invariant (mathematics)|invariant]] under [[permutation]] of the space of candidate solutions.<!-- \n--><ref name=Streeter>Streeter, M. (2003) \"[https://www.cs.york.ac.uk/rts/docs/GECCO_2003/papers/2724/27241418.pdf Two Broad Classes of Functions for Which a No Free Lunch Result Does Not Hold],\" ''Genetic and Evolutionary Computation – GECCO 2003'', pp. 1418–1430.</ref><!--\n--><ref name=Igel>Igel, C., and Toussaint, M. (2004) \"[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.158.9715&rep=rep1&type=pdf A No-Free-Lunch Theorem for Non-Uniform Distributions of Target Functions],\" ''Journal of Mathematical Modelling and Algorithms'' '''3''', pp. 313–322.</ref><!--\n--><ref name=\"English2004\">English, T. (2004) [https://sites.google.com/site/boundedtheoretics/CEC04.pdf No More Lunch: Analysis of Sequential Search], ''Proceedings of the 2004 IEEE Congress on Evolutionary Computation'', pp. 227–234.</ref> This condition does not hold precisely in practice,<ref name=Igel/> but an \"(almost) no free lunch\" theorem suggests that it holds approximately.<ref name=ANFL>S. Droste, T. Jansen, and I. Wegener. 2002. \"[https://www.sciencedirect.com/science/article/pii/S0304397502000944/pdf?md5=4464a32c6ad989dbea47d759973008dc&pid=1-s2.0-S0304397502000944-main.pdf&_valck=1 Optimization with randomized search heuristics: the (A)NFL theorem, realistic scenarios, and difficult functions],\" ''Theoretical Computer Science,'' vol. 287, no. 1, pp. 131–144.</ref>\n\n==Overview==\n\nSome computational problems are solved by searching for good solutions in a space of [[candidate solution]]s. A description of how to repeatedly select candidate solutions for evaluation is called a [[search algorithm]]. On a particular problem, different search algorithms may obtain different results, but over all problems, they are indistinguishable. It follows that if an algorithm achieves superior results on some problems, it must pay with inferiority on other problems. In this sense there is [[no free lunch]] in search.<ref name=WM95/> Alternatively, following Schaffer,<ref name=Schaffer94/> search performance is [[Conservation law (physics)|conserved]]. Usually search is interpreted as [[Optimization (mathematics)|optimization]], and this leads to the observation that there is no free lunch in optimization.<ref name=WM97/>\n\n\"The 'no free lunch' theorem of Wolpert and Macready,\" as stated in plain language by Wolpert and Macready themselves, is that \"any two algorithms are equivalent when their performance is averaged across all possible problems.\"<ref name=WM-coev>Wolpert, D.H., and Macready, W.G. (2005) \"[https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20060007558.pdf Coevolutionary free lunches],\" ''IEEE Transactions on Evolutionary Computation'', 9(6): 721–735</ref> The \"no free lunch\" results indicate that matching algorithms to problems gives higher average performance than does applying a fixed algorithm to all.{{Citation needed|date=April 2019}}  Igel and Toussaint<ref name=Igel/> and English<ref name=English2004/> have established a general condition under which there is no free lunch. While it is physically possible, it does not hold precisely.<ref name=Igel/> Droste, Jansen, and Wegener have proved a theorem they interpret as indicating that there is \"(almost) no free lunch\" in practice.<ref name=ANFL/>\n\nTo make matters more concrete, consider an optimization practitioner confronted with a problem. Given some knowledge of how the problem arose, the practitioner may be able to exploit the knowledge in selection of an algorithm that will perform well in solving the problem. If the practitioner does not understand how to exploit the knowledge, or simply has no knowledge, then he or she faces the question of whether some algorithm generally outperforms others on real-world problems. The authors of the \"(almost) no free lunch\" theorem say that the answer is essentially no, but admit some reservations as to whether the theorem addresses practice.<ref name=ANFL/>\n\n==No free lunch (NFL)==\n\nA \"problem\" is, more formally, an [[objective function]] that associates [[candidate solution]]s with goodness values. A [[search algorithm]] takes an objective function as input and evaluates candidate solutions one-by-one. The output of the algorithm is the [[sequence]] of observed goodness values.<ref>A search algorithm also outputs the sequence of candidate solutions evaluated, but that output is unused in this article.</ref><ref name=English2000>English, T. M. 2000. \"Optimization Is Easy and Learning Is Hard in the Typical Function,\" ''Proceedings of the 2000 Congress on Evolutionary Computation: CEC00'', pp. 924–931. http://www.BoundedTheoretics.com/cec2000.pdf</ref>\n\nWolpert and Macready stipulate that an algorithm never reevaluates a candidate solution, and that algorithm performance is measured on outputs.<ref name=WM97/>  For simplicity, we disallow randomness in algorithms. Under these conditions, when a search algorithm is run on every possible input, it generates each possible output exactly once.<ref name=English2004/> Because performance is measured on the outputs, the algorithms are indistinguishable in how often they achieve particular levels of performance.\n\nSome measures of performance indicate how well search algorithms do at [[Optimization (mathematics)|optimization]] of the objective function. Indeed, there seems to be no interesting application of search algorithms in the class under consideration but to optimization problems. A common performance measure is the least index of the least value in the output sequence. This is the number of evaluations required to minimize the objective function. For some algorithms, the time required to find the minimum is proportional to the number of evaluations.<ref name=English2004/>\n\nThe original no free lunch (NFL) theorems assume that all objective functions are equally likely to be input to search algorithms.<ref name=WM97/> It has since been established that there is NFL if and only if, loosely speaking, \"shuffling\" objective functions has no impact on their probabilities.<ref name=Igel/><ref name=English2004/> Although this condition for NFL is physically possible, it has been argued that it certainly does not hold precisely.<ref name=Igel/>\n\nThe obvious interpretation of \"not NFL\" is \"free lunch,\" but this is misleading. NFL is a matter of degree, not an all-or-nothing proposition. If the condition for NFL holds approximately, then all algorithms yield approximately the same results over all objective functions.<ref name=English2004/> Note also that \"not NFL\" implies only that algorithms are inequivalent overall by ''some'' measure of performance. For a performance measure of interest, algorithms may remain equivalent, or nearly so.<ref name=English2004/>\n\n===NFL and Kolmogorov randomness===\n\nAlmost all elements of the set of all possible functions (in the set-theoretic sense of \"function\") are [[Kolmogorov randomness | Kolmogorov random]], and hence the NFL theorems apply to a set of functions almost all of which cannot be expressed more compactly than as a lookup table that contains a distinct (and random) entry for each point in the search space. Functions that can be expressed more compactly (for example, by a mathematical expression of reasonable size) are by definition not Kolmogorov random.\n\nFurther, within the set of all possible objective functions, levels of goodness are equally represented among candidate solutions, hence good solutions are scattered throughout the space of candidates. Accordingly, a search algorithm will rarely evaluate more than a small fraction of the candidates before locating a very good solution.<ref name=English2000/>\n\nAlmost all objective functions are of such high [[Kolmogorov complexity]] that they cannot arise.<ref name=Streeter/><ref name=English2004/><ref name=English2000/> There is more information in the typical objective function or algorithm than [[Seth Lloyd]] estimates the observable universe is capable of registering.<ref name=Lloyd2002>Lloyd, S. (2002) \"Computational capacity of the universe,\" ''Physical Review Letters'' '''88''', pp. 237901–237904. https://arxiv.org/abs/quant-ph/0110141</ref> For instance, if each candidate solution is encoded as a sequence of 300 0's and 1's, and the goodness values are 0 and 1, then most objective functions have Kolmogorov complexity of at least 2<sup>300</sup> bits,<ref name=LV>Li, M., and Vitányi, P. (1997) ''An Introduction to Kolmogorov Complexity and Its Applications'' (2nd ed.), New York: Springer.</ref> and this is greater than Lloyd's bound of 10<sup>90</sup> ≈ 2<sup>299</sup> bits. It follows that not all of \"no free lunch\" theory applies to physical reality. In a practical sense, algorithms \"small enough\" for application in physical reality are superior in performance to those that are not. It has also been shown that NFL results apply to incomputable functions <ref>\n\"Woodward, John R; \",[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.158.7782&rep=rep1&type=pdf Computable and incomputable functions and search algorithms],\"Intelligent Computing and Intelligent Systems, 2009. ICIS 2009. IEEE International Conference on\",1,,871-875,2009,IEEE</ref>\n\n==Formal synopsis of NFL==\n\n<math>Y^X</math> is the set of all [[objective function]]s ''f'':''X''→''Y'', where <math>X</math> is a finite [[solution space]] and <math>Y</math> is a finite [[poset]]. The set of all [[permutation]]s of ''X'' is ''J''. A [[random variable]] ''F'' is distributed on <math>Y^X</math>. For all ''j'' in ''J'', ''F'' o ''j'' is a random variable distributed on <math>Y^X</math>, with P(''F'' o ''j'' = ''f'') = P(''F'' = ''f'' o ''j''<sup>−1</sup>) for all ''f'' in <math>Y^X</math>.\n\nLet ''a''(''f'') denote the output of search algorithm ''a'' on input ''f''. If ''a''(''F'') and ''b''(''F'') are identically distributed for all search algorithms ''a'' and ''b'', then ''F'' has an ''NFL distribution''. This condition holds if and only if ''F'' and ''F'' o ''j'' are identically distributed for all ''j'' in ''J''.<ref name=Igel/><ref name=English2004/> In other words, there is no free lunch for search algorithms if and only if the distribution of objective functions is invariant under permutation of the solution space.  \n\nThe \"only if\" part was first published by C. Schumacher in his PhD dissertation \"Black Box Search – Framework and Methods\" (The University of Tennessee, Knoxville (2000)).\nSet-theoretic NFL theorems have recently been generalized to arbitrary cardinality <math>X</math> and <math>Y</math>.<ref name=Rowe>Rowe, Vose, and Wright, \"[https://scholarworks.umt.edu/cgi/viewcontent.cgi?article=1008&context=cs_pubs Reinterpreting No Free Lunch],\" ''Evolutionary Computation'' 17(1): 117–129</ref>\n\n==Original NFL theorems==\n\nWolpert and Macready give two principal NFL theorems, the first regarding objective functions that do not change while search is in progress, and the second regarding objective functions that may change.<ref name=WM97/> \n\n:''Theorem 1'': For any pair of algorithms ''a''<sub>1</sub> and ''a''<sub>2</sub>\n\n::<math>\\sum_f P(d_m^y | f, m, a_1) = \\sum_f P(d_m^y | f, m, a_2),</math>\n\nwhere <math>d_m^y</math> denotes the ordered set of size <math>m</math> of the cost values <math>y \\in Y</math> associated to input values <math>x \\in X</math>, <math>f:X \\rightarrow Y </math> is the function being optimized and <math>P(d_m^y | f, m, a)</math> is the conditional probability of obtaining a given sequence of cost values from algorithm <math>a</math> run <math>m</math> times on function <math>f</math>.\n\nIn essence, this says that when all functions ''f'' are equally likely, the probability of observing an arbitrary sequence of ''m'' values in the course of search does not depend upon the search algorithm. Theorem 1 establishes a \"more subtle\" NFL result for time-varying objective functions.\n\n==Interpretations of NFL results==\n\nA conventional, but not entirely accurate, interpretation of the NFL results is that \"a general-purpose universal optimization strategy is theoretically impossible, and the only way one strategy can outperform another is if it is specialized to the specific problem under consideration\".<ref>Ho, Y.C., Pepyne, D.L. (2002), \"[https://link.springer.com/article/10.1023/A:1021251113462 Simple Explanation of the No-Free-Lunch Theorem and Its Implications],\" ''Journal of Optimization Theory and Applications'' '''115''', 549-570.</ref> Several comments are in order:\n\n:''A general-purpose almost-universal optimizer exists theoretically.'' Each search algorithm performs well on almost all objective functions.<ref name=English2000/>\n\n:''An algorithm may outperform another on a problem when neither is specialized to the problem.'' It may be that both algorithms are among the worst for the problem. Wolpert and Macready have developed a measure of the degree of \"match\" between an algorithm and a problem.<ref name=WM97/> To say that one algorithm matches a problem better than another is not to say that either is specialized to the problem. <!-- The term should be \"alignment,\" perhaps. Mention inner product? -->\n\n:''In practice, some algorithms reevaluate candidate solutions.'' The superiority of an algorithm that never reevaluates candidates over another that does on a particular problem may have nothing to do with specialization to the problem.\n\n:''For almost all objective functions, specialization is essentially accidental.'' Incompressible, or [[Kolmogorov randomness|Kolmogorov random]], objective functions have no regularity for an algorithm to exploit. Given an incompressible objective function, there is no basis for choosing one algorithm over another. If a chosen algorithm performs better than most, the result is happenstance.<ref name=English2000>English, T. M. 2000. \"Optimization Is Easy and Learning Is Hard in the Typical Function,\" ''Proceedings of the 2000 Congress on Evolutionary Computation: CEC00'', pp. 924–931. http://www.BoundedTheoretics.com/cec2000.pdf</ref> It should be noted that a Kolmogorov random function has no representation smaller than a lookup table that contains a (random) value corresponding to each point in the search space; ''any'' function that can be expressed more compactly is, by definition, not Kolmogorov random.\n\nIn practice, only highly compressible (far from random) objective functions fit in the storage of computers, and it is not the case that each algorithm performs well on almost all compressible functions. There is generally a performance advantage in incorporating prior knowledge of the problem into the algorithm. While the NFL results constitute, in a strict sense, [[full employment theorem]]s for optimization professionals, it is important not to take the term literally. For one thing, humans often have little prior knowledge to work with. For another, incorporating prior knowledge does not give much of a performance gain on some problems. Finally, human time is very expensive relative to computer time. There are many cases in which a company would choose to optimize a function slowly with an unmodified computer program rather than rapidly with a human-modified program.\n\nThe NFL results do not indicate that it is futile to take \"pot shots\" at problems with unspecialized algorithms. No one has determined the fraction of practical problems for which an algorithm yields good results rapidly. And there is a practical free lunch, not at all in conflict with theory. Running an implementation of an algorithm on a computer costs very little relative to the cost of human time and the benefit of a good solution. If an algorithm succeeds in finding a satisfactory solution in an acceptable amount of time, a small investment has yielded a big payoff. If the algorithm fails, then little is lost.\n\n==Coevolutionary free lunches==\n\nWolpert and Macready have proved that there are [[free lunch]]es in [[coevolution]]ary optimization.<ref name=WM-coev>Wolpert, D.H., and Macready, W.G. (2005) \"[https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20060007558.pdf Coevolutionary free lunches],\" ''IEEE Transactions on Evolutionary Computation'', 9(6): 721–735</ref> Their analysis \"covers 'self-play' problems. In these problems, the set of players work together to produce a champion, who then engages one or more antagonists in a subsequent multiplayer game.\"<ref name=WM-coev/> That is, the objective is to obtain a good player, but without an objective function. The goodness of each player (candidate solution) is assessed by observing how well it plays against others. An algorithm attempts to use players and their quality of play to obtain better players. The player deemed best of all by the algorithm is the champion. Wolpert and Macready have demonstrated that some coevolutionary algorithms are generally superior to other algorithms in quality of champions obtained. Generating a champion through self-play is of interest in [[evolutionary computation]] and [[game theory]]. The results are inapplicable to coevolution of biological species, which does not yield champions.<ref name=WM-coev/>\n\n==See also==\n* [[Evolutionary informatics]]\n* [[Inductive bias]]\n* [[Occam's razor]]\n* [[Simplicity]]\n* [[Ugly duckling theorem]]\n\n== Notes ==\n{{reflist|30em}}\n\n==External links==\n* http://www.no-free-lunch.org\n*[http://citeseer.ist.psu.edu/radcliffe95fundamental.html Radcliffe and Surry, 1995, \"Fundamental Limitations on Search Algorithms: Evolutionary Computing in Perspective\" (the first published paper on NFL, available in various formats)]\n*[http://boundedtheoretics.com/bt/Publications.php NFL publications by Thomas English]\n*[http://www.neuroinformatik.ruhr-uni-bochum.de/PEOPLE/igel/publications.html NFL publications by Christian Igel and Marc Toussaint]\n*[http://www.cs.colostate.edu/~genitor/Pubs.html NFL and \"free lunch\" publications by Darrell Whitley]\n*[http://ti.arc.nasa.gov/profile/dhw/optimization/ Publications by David Wolpert, William Macready, and Mario Koeppen on optimization and search]\n\n[[Category:Mathematical optimization]]\n[[Category:Theorems in computational complexity theory]]"
    },
    {
      "title": "NP-completeness",
      "url": "https://en.wikipedia.org/wiki/NP-completeness",
      "text": "{{confusing |date = July 2012}}\n\n[[File:P np np-complete np-hard.svg|thumb|300px|right|[[Euler diagram]] for [[P (complexity)|P]], [[NP (complexity)|NP]], NP-complete, and [[NP-hard]] set of problems.  The left side is valid under the assumption that [[P versus NP problem|P≠NP]], while the right side is valid under the assumption that P=NP (except that the empty language and its complement are never NP-complete, and in general, not every problem in P or NP is NP-complete)]]\n\nIn [[computational complexity theory]], a problem is '''NP-complete''' when it can be solved by a restricted class of [[brute force search]] algorithms and it can be used to simulate any other problem with a similar algorithm. More precisely, each input to the problem should be associated with a set of solutions of polynomial length, whose validity can be tested quickly (in [[polynomial time]]<ref>{{Cite book| last=Cobham | first=Alan | authorlink=Alan Cobham | year = 1965 | chapter = The intrinsic computational difficulty of functions | title = Proc. Logic, Methodology, and Philosophy of Science II | publisher = North Holland}}</ref>), such that the output for any input is \"yes\" if the solution set is non-empty and \"no\" if it is empty. The complexity class of problems of this form is called [[NP (complexity)|NP]], an abbreviation for \"[[Non-deterministic Turing machine#Deterministic Turing Machine|nondeterministic]] polynomial time\". A problem is said to be [[NP-hard]] if everything in NP can be transformed in polynomial time into it, and a problem is NP-complete if it is both in NP and NP-hard. The NP-complete problems represent the hardest problems in NP. If any NP-complete problem has a polynomial time algorithm, all problems in NP do. The set of NP-complete problems is often denoted by '''NP-C''' or '''NPC'''.\n\nAlthough a solution to an NP-complete problem can be ''verified'' \"quickly\", there is no known way to ''find'' a solution quickly. That is, the time required to solve the problem using any currently known [[algorithm]] increases rapidly as the size of the problem grows. As a consequence, determining whether it is possible to solve these problems quickly, called the [[P versus NP problem]], is one of the fundamental [[List of open problems in computer science|unsolved problems in computer science]] today.\n\nWhile a method for computing the solutions to NP-complete problems quickly remains undiscovered, [[computer scientist]]s and [[computer programmer|programmer]]s still frequently encounter NP-complete problems. NP-complete problems are often addressed by using [[heuristic (computer science)|heuristic]] methods and [[approximation algorithm]]s.\n\n== Overview ==\nNP-complete problems are in [[NP (complexity)|NP]], the set of all [[decision problem]]s whose solutions can be verified in polynomial time; ''NP'' may be equivalently defined as the set of decision problems that can be solved in polynomial time on a [[non-deterministic Turing machine]]. A problem ''p'' in NP is NP-complete if every other problem in NP can be transformed (or reduced) into ''p'' in polynomial time.\n\nIt is not known whether every problem in NP can be quickly solved—this is called the [[P versus NP problem]]. But if ''any NP-complete problem'' can be solved quickly, then ''every problem in NP'' can, because the definition of an NP-complete problem states that every problem in NP must be quickly reducible to every NP-complete problem (that is, it can be reduced in polynomial time). Because of this, it is often said that NP-complete problems are ''harder'' or ''more difficult'' than NP problems in general.\n\n== Formal definition ==\n{{See also |P %3D NP problem#NP-completeness |l1 = formal definition for NP-completeness (article ''P = NP'')}}\n\nA decision problem <math>\\scriptstyle C</math> is NP-complete if:\n# <math>\\scriptstyle C</math> is in NP, and\n# Every problem in NP is [[Many-one reduction|reducible]] to <math>\\scriptstyle C</math> in polynomial time.<ref>{{cite book |author = J. van Leeuwen |year = 1998 |title = Handbook of Theoretical Computer Science |publisher = Elsevier |isbn = 978-0-262-72014-4 |page = 84}}</ref>\n\n<math>\\scriptstyle C</math> can be shown to be in NP by demonstrating that a candidate solution to <math>\\scriptstyle C</math> can be verified in polynomial time.\n\nNote that a problem satisfying condition 2 is said to be [[NP-hard]], whether or not it satisfies condition 1.<ref>{{cite book |author = J. van Leeuwen |year = 1998 |title = Handbook of Theoretical Computer Science |publisher = Elsevier |isbn = 978-0-262-72014-4 |page = 80}}</ref>\n\nA consequence of this definition is that if we had a polynomial time algorithm (on a [[Universal Turing machine|UTM]], or any other [[Turing completeness|Turing-equivalent]] [[abstract machine]]) for <math>\\scriptstyle C</math>, we could solve all problems in NP in polynomial time.\n\n== Background ==\n\nThe concept of NP-completeness was introduced in 1971 (see [[Cook–Levin theorem]]), though the term ''NP-complete'' was introduced later. At the 1971 [[STOC]] conference, there was a fierce debate between the computer scientists about whether NP-complete problems could be solved in polynomial time on a [[deterministic]] [[Turing machine]]. [[John Hopcroft]] brought everyone at the conference to a consensus that the question of whether NP-complete problems are solvable in polynomial time should be put off to be solved at some later date, since nobody had any formal proofs for their claims one way or the other.  This is known as the question of whether P=NP.\n\nNobody has yet been able to determine conclusively whether NP-complete problems are in fact solvable in polynomial time, making this one of the great [[unsolved problems of mathematics]].  The [[Clay Mathematics Institute]] is offering a US$1 million reward to anyone who has a formal proof that P=NP or that P≠NP.\n\nThe [[Cook–Levin theorem]] states that the [[Boolean satisfiability problem]] is NP-complete. In 1972, [[Richard Karp]] proved that several other problems were also NP-complete (see [[Karp's 21 NP-complete problems]]); thus there is a class of NP-complete problems (besides the Boolean satisfiability problem). Since the original results, thousands of other problems have been shown to be NP-complete by reductions from other problems previously shown to be NP-complete; many of these problems are collected in [[Michael Garey|Garey]] and [[David S. Johnson|Johnson's]] 1979 book ''[[Computers and Intractability: A Guide to the Theory of NP-Completeness]]''.<ref name=\"GareyJohnson\">{{cite book |last1=Garey |first1=Michael&nbsp;R. |authorlink1 = Michael R. Garey |last2=Johnson |first2 = D.&nbsp;S. |authorlink2=David S. Johnson |title=Computers and Intractability: A Guide to the Theory of NP-Completeness |year=1979 |isbn = 978-0-7167-1045-5 |pages=x+338 |url= |doi= |series=A Series of Books in the Mathematical Sciences|editor=[[Victor Klee]] |publisher=W.&nbsp;H.&nbsp;Freeman and Co. |location=San Francisco, Calif. |mr=519066 |ref=harv|title-link=Computers and Intractability: A Guide to the Theory of NP-Completeness }}</ref>\n\n== NP-complete problems ==\n[[File:Relative NPC chart.svg|thumb|right|Some NP-complete problems, indicating the [[reduction (complexity)|reductions]] typically used to prove their NP-completeness]]\n{{Main|List of NP-complete problems}}\n\nAn interesting example is the [[graph isomorphism problem]], the [[graph theory]] problem of determining whether a [[graph isomorphism]] exists between two graphs.  Two graphs are [[isomorphic]] if one can be [[isomorphism|transformed]] into the other simply by renaming [[vertex (graph theory)|vertices]]. Consider these two problems:\n* Graph Isomorphism: Is graph G<sub>1</sub> isomorphic to graph G<sub>2</sub>?\n* Subgraph Isomorphism: Is graph G<sub>1</sub> isomorphic to a subgraph of graph G<sub>2</sub>?\n\nThe Subgraph Isomorphism problem is NP-complete. The graph isomorphism problem is suspected to be neither in P nor NP-complete, though it is in NP. This is an example of a problem that is thought to be '''hard''', but is not thought to be NP-complete.\n\nThe easiest way to prove that some new problem is NP-complete is first to prove that it is in NP, and then to reduce some known NP-complete problem to it. Therefore, it is useful to know a variety of NP-complete problems. The list below contains some well-known problems that are NP-complete when expressed as decision problems.\n{{div col|colwidth=25em}}\n* [[Boolean satisfiability problem|Boolean satisfiability problem (SAT)]]\n* [[Knapsack problem]]\n* [[Hamiltonian path problem]]\n* [[Travelling salesman problem]] (decision version)\n* [[Subgraph isomorphism problem]]\n* [[Subset sum problem]]\n* [[Clique problem]]\n* [[Vertex cover problem]]\n* [[Independent set problem]]\n* [[Dominating set problem]]\n* [[Graph coloring problem]]\n{{div col end}}\n\nTo the right is a diagram of some of the problems and the [[reduction (complexity)|reductions]] typically used to prove their NP-completeness. In this diagram, problems are reduced from bottom to top. Note that this diagram is misleading as a description of the mathematical relationship between these problems, as there exists a [[polynomial-time reduction]] between any two NP-complete problems; but it indicates where demonstrating this polynomial-time reduction has been easiest.\n\nThere is often only a small difference between a problem in P and an NP-complete problem. For example, the [[3-satisfiability]] problem, a restriction of the boolean satisfiability problem, remains NP-complete, whereas the slightly more restricted [[2-satisfiability]] problem is in P (specifically, [[NL-complete]]), and the slightly more general max. 2-sat. problem is again NP-complete. Determining whether a graph can be colored with 2 colors is in P, but with 3 colors is NP-complete, even when restricted to [[planar graph]]s. Determining if a graph is a [[cycle graph|cycle]] or is [[bipartite graph|bipartite]] is very easy (in [[L (complexity)|L]]), but finding a maximum bipartite or a maximum cycle subgraph is NP-complete. A solution of the [[knapsack problem]] within any fixed percentage of the optimal solution can be computed in polynomial time, but finding the optimal solution is NP-complete.\n\n== Solving NP-complete problems ==\nAt present, all known algorithms for NP-complete problems require time that is [[superpolynomial]] in the input size, and it is unknown whether there are any faster algorithms.\n\nThe following techniques can be applied to solve computational problems in general, and they often give rise to substantially faster algorithms:\n* [[Approximation algorithm|Approximation]]: Instead of searching for an optimal solution, search for a solution that is at most a factor from an optimal one.\n* [[Randomized algorithm|Randomization]]: Use randomness to get a faster average [[running time]], and allow the algorithm to fail with some small probability. Note: The [[Monte Carlo method]] is not an example of an efficient algorithm in this specific sense, although evolutionary approaches like [[Genetic algorithm]]s may be.\n* Restriction: By restricting the structure of the input (e.g., to planar graphs), faster algorithms are usually possible.\n* [[Parameterized complexity|Parameterization]]: Often there are fast algorithms if certain parameters of the input are fixed.\n* [[Heuristic (computer science)|Heuristic]]: An algorithm that works \"reasonably well\" in many cases, but for which there is no proof that it is both always fast and always produces a good result.  [[Metaheuristic]] approaches are often used.\n\nOne example of a heuristic algorithm is a suboptimal <math>\\scriptstyle O(n\\log n)</math> [[greedy coloring|greedy coloring algorithm]] used for [[graph coloring problem|graph coloring]] during the [[register allocation]] phase of some compilers, a technique called [[graph-coloring global register allocation]]. Each vertex is a variable, edges are drawn between variables which are being used at the same time, and colors indicate the register assigned to each variable. Because most [[RISC]] machines have a fairly large number of general-purpose registers, even a heuristic approach is effective for this application.\n\n== Completeness under different types of reduction ==\nIn the definition of NP-complete given above, the term ''reduction'' was used in the technical meaning of a polynomial-time [[many-one reduction]].\n\nAnother type of reduction is polynomial-time Turing reduction.  A problem <math>\\scriptstyle X</math> is polynomial-time Turing-reducible to a problem <math>\\scriptstyle Y</math> if, given a subroutine that solves <math>\\scriptstyle Y</math> in polynomial time, one could write a program that calls this subroutine and solves <math>\\scriptstyle X</math> in polynomial time.  This contrasts with many-one reducibility, which has the restriction that the program can only call the subroutine once, and the return value of the subroutine must be the return value of the program.\n\nIf one defines the analogue to NP-complete with Turing reductions instead of  many-one reductions, the resulting set of problems won't be smaller than NP-complete; it is an open question whether it will be any larger.\n\nAnother type of reduction that is also often used to define NP-completeness is the [[logarithmic-space many-one reduction]] which is a many-one reduction that can be computed with only a logarithmic amount of space. Since every computation that can be done in [[logarithmic space]] can also be done in polynomial time it follows that if there is a logarithmic-space many-one reduction then there is also a polynomial-time many-one reduction. This type of reduction is more refined than the more usual polynomial-time many-one reductions and it allows us to distinguish more classes such as [[P-complete]]. Whether under these types of reductions the definition of NP-complete changes is still an open problem. All currently known NP-complete problems are NP-complete under log space reductions. All currently known NP-complete problems remain NP-complete even under much weaker reductions.<ref>{{Cite journal | doi=10.1006/jcss.1998.1583 | last1=Agrawal | first1=M. | author1-link=Manindra Agrawal | last2=Allender | first2=E. | last3=Rudich | first3=Steven | author3-link=Steven Rudich | title=Reductions in Circuit Complexity: An Isomorphism Theorem and a Gap Theorem | year=1998 | journal=Journal of Computer and System Sciences | issn=1090-2724 | volume=57 | issue=2 | pages=127–143 | postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. --> | ref=harv}}</ref> It is known, however, that [[AC0|AC<sup>0</sup>]] reductions define a strictly smaller class than polynomial-time reductions.<ref>{{Cite journal | last1=Agrawal | first1=M. | author1-link=Manindra Agrawal | last2=Allender | first2=E. | last3=Impagliazzo | first3=R. | last4=Pitassi | first4=T. | author4-link = Toniann Pitassi | last5=Rudich | first5=Steven | author5-link=Steven Rudich | title=Reducing the complexity of reductions | doi=10.1007/s00037-001-8191-1 | year=2001 | journal=Computational Complexity | issn=1016-3328 | volume=10 | pages=117–138 | issue=2 | postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}} | ref=harv}}\n</ref>\n\n== Naming ==\nAccording to [[Donald Knuth]], the name \"NP-complete\" was popularized by [[Alfred Aho]], [[John Hopcroft]] and [[Jeffrey Ullman]] in their celebrated textbook \"The Design and Analysis of Computer Algorithms\".  He reports that they introduced the change in the [[galley proofs]] for the book (from \"polynomially-complete\"), in accordance with the results of a poll he had conducted of the [[theoretical computer science]] community.<ref>[[Don Knuth]], Tracy Larrabee, and Paul M. Roberts, ''[http://tex.loria.fr/typographie/mathwriting.pdf Mathematical Writing]'' § 25, ''MAA Notes No. 14'', MAA, 1989 (also [[Stanford University|Stanford]] Technical Report, 1987).</ref> Other suggestions made in the poll<ref>{{Cite journal\n|doi = 10.1145/1811129.1811130\n|volume = 6\n|issue = 1\n|pages = 12–18\n|last = Knuth\n|first = D. F.\n|title = A terminological proposal\n|journal = SIGACT News\n|accessdate = 2010-08-28\n|year = 1974\n|url = http://portal.acm.org/citation.cfm?id=1811130\n|ref = harv\n}}</ref> included  \"[[Labours of Hercules|Herculean]]\", \"formidable\", [[Kenneth Steiglitz|Steiglitz]]'s \"hard-boiled\" in honor of Cook, and Shen Lin's acronym \"PET\", which stood for \"probably exponential time\", but depending on which way the [[P versus NP problem]] went, could stand for \"provably exponential time\" or \"previously exponential time\".<ref>See the poll, or [http://www.cs.princeton.edu/~wayne/kleinberg-tardos/08np-complete-2x2.pdf].</ref>\n\n== Common misconceptions ==\nThe following misconceptions are frequent.<ref>{{Cite news|url=http://www.nature.com/news/2000/000113/full/news000113-10.html\n|doi = 10.1038/news000113-10\n|title = DNA computer helps travelling salesman\n|first = Philip |last= Ball\n}}</ref> \n* ''\"NP-complete problems are the most difficult known problems.\"'' Since NP-complete problems are in NP, their running time is at most exponential. However, some problems <!-- the next word is PROVABLY (as in \"to prove\" something), not PROBABLY. Do not 'fix' it! -->provably<!-- proVVVVably --> require more time, for example [[Presburger arithmetic]].\n* ''\"NP-complete problems are difficult because there are so many different solutions.\"'' On the one hand, there are many problems that have a solution space just as large, but can be solved in polynomial time (for example [[minimum spanning tree]]). On the other hand, there are NP-problems with at most one solution that are NP-hard under randomized polynomial-time reduction (see [[Valiant–Vazirani theorem]]).\n* ''\"Solving NP-complete problems requires exponential time.\"'' First, this would imply P ≠ NP, which is still an unsolved question. Further, some NP-complete problems actually have algorithms running in superpolynomial, but subexponential time such as O(2<sup>{{sqrt|''n''}}</sup>''n''). For example, the [[Independent set problem|independent set]] and [[Dominating set problem|dominating set]] problems for [[planar graph]]s are NP-complete, but can be solved in subexponential time using the [[planar separator theorem]].<ref>{{harvtxt|Bern|1990}}; {{harvtxt|Deĭneko|Klinz|Woeginger|2006}}; {{harvtxt|Dorn|Penninks|Bodlaender|Fomin|2005}}; {{harvtxt|Lipton|Tarjan|1980}}.</ref>\n* ''\"All instances of an NP-complete problem are difficult.\"'' Often some instances, or even most instances, may be easy to solve within polynomial time. However, unless P=NP, any polynomial-time algorithm must asymptotically be wrong on more than polynomially many of the exponentially many inputs of a certain size.<ref>{{Cite journal | last1 = Hemaspaandra | first1 = L. A. | last2 = Williams | first2 = R. | doi = 10.1145/2421119.2421135 | title = SIGACT News Complexity Theory Column 76 | journal = ACM SIGACT News | volume = 43 | issue = 4 | page = 70 | year = 2012 | pmid =  | pmc = }}</ref>\n* ''\"If P=NP, all cryptographic ciphers can be broken.\"'' A polynomial-time problem can be very difficult to solve in practice if the polynomial's degree or constants are large enough. For example, ciphers with a fixed key length, such as [[Advanced Encryption Standard]], can all be broken in constant time (and are thus already known to be in P), though with current technology that constant may exceed the age of the universe. In addition, [[information-theoretic security]] provides cryptographic methods that cannot be broken even with unlimited computing power.\n\n== Properties ==\nViewing a [[decision problem#Definition|decision problem]] as a formal language in some fixed encoding, the set NPC of all NP-complete problems is '''not closed''' under:\n* [[Union (set theory)|union]]\n* [[intersection]]\n* [[concatenation]]\n* [[Kleene star]]\n\nIt is not known whether NPC is closed under [[Complement (complexity)|complementation]], since NPC=[[co-NP-complete|co-NPC]] if and only if NP=[[co-NP]], and whether NP=co-NP is an [[Open problem|open question]].<ref>{{citation |title = Complexity and Cryptography: An Introduction |first1 = John |last1 = Talbot|first2=D. J. A.|last2 = Welsh |author2-link = Dominic Welsh |publisher = Cambridge University Press |year = 2006 |isbn = 9780521617710 |page=57 |url = https://books.google.com/books?id=y_ZwupY8pzUC&pg=PA57 |quote = The question of whether NP and co-NP are equal is probably the second most important open problem in complexity theory, after the P versus NP question.}}</ref>\n\n== See also ==\n{{Portal|Computer science}}\n* [[Almost complete]]\n* [[Gadget (computer science)]]\n* [[Ladner's theorem]]\n* [[List of NP-complete problems]]\n* [[NP-hard]]\n* [[P = NP problem]]\n* [[Strongly NP-complete]]\n\n== References ==\n=== Citations ===\n{{Reflist|30em}}\n\n=== Sources ===\n{{refbegin |colwidth = 30em}}\n* {{Cite book\n |last1 = Garey\n |first1 = M.R.\n |author1-link = Michael Garey\n |author2 = Johnson, D.S.\n |author2-link = David S. Johnson \n |title = Computers and Intractability: A Guide to the Theory of NP-Completeness\n |year = 1979\n |publisher = W.H. Freeman\n |location = New York\n |isbn = 978-0-7167-1045-5\n|title-link = Computers and Intractability: A Guide to the Theory of NP-Completeness\n }}  This book is a classic, developing the theory, then cataloguing ''many'' NP-Complete problems.\n* {{Cite conference\n |last = Cook\n |first = S.A.\n |authorlink = Stephen A. Cook\n |title = The complexity of theorem proving procedures\n |booktitle = Proceedings, Third Annual ACM Symposium on the Theory of Computing, ACM, New York\n |year = 1971\n |pages = 151–158\n |doi = 10.1145/800157.805047\n }}\n* {{cite web\n |last = Dunne\n |first = P.E\n |title = An annotated list of selected NP-complete problems\n |publisher = COMP202, Dept. of Computer Science, [[University of Liverpool]]\n |url = http://www.csc.liv.ac.uk/~ped/teachadmin/COMP202/annotated_np.html\n |accessdate = 2008-06-21\n}}\n* {{cite web\n |last = Crescenzi\n |first = P.\n |author2=Kann, V. |author3=Halldórsson, M. |author4=[[Marek Karpinski|Karpinski, M.]] |author5=[[Gerhard J. Woeginger|Woeginger, G]]\n |title = A compendium of NP optimization problems\n |publisher = KTH NADA, Stockholm\n |url = http://www.nada.kth.se/~viggo/problemlist/compendium.html\n |accessdate = 2008-06-21\n}}\n* {{cite web\n |last = Dahlke\n |first = K\n |title = NP-complete problems\n |work = Math Reference Project\n |url = http://www.mathreference.com/lan-cx-np,intro.html\n |accessdate = 2008-06-21\n}}\n* {{cite web |last = Karlsson |first = R |title = Lecture 8: NP-complete problems |publisher = Dept. of Computer Science, Lund University, Sweden |url = http://www.cs.lth.se/home/Rolf_Karlsson/bk/lect8.pdf |accessdate = 2008-06-21 |deadurl = yes |archiveurl = https://web.archive.org/web/20090419082030/http://www.cs.lth.se/home/Rolf_Karlsson/bk/lect8.pdf |archivedate = April 19, 2009 }} \n* {{cite web\n |last = Sun\n |first = H.M\n |title = The theory of NP-completeness\n |publisher = Information Security Laboratory, Dept. of Computer Science, [[National Tsing Hua University]], Hsinchu City, Taiwan\n |url = http://is.cs.nthu.edu.tw/course/2008Spring/cs431102/hmsunCh08.ppt\n |format = PPT\n |accessdate = 2008-06-21\n}}\n* {{cite web\n |last = Jiang\n |first = J.R\n |title = The theory of NP-completeness\n |publisher = Dept. of Computer Science and Information Engineering, [[National Central University]], Jhongli City, Taiwan\n |url = http://www.csie.ncu.edu.tw/%7Ejrjiang/alg2006/NPC-3.ppt\n |format = PPT\n |accessdate = 2008-06-21\n}}\n* {{Cite book\n |last = Cormen\n |first = T.H.\n |authorlink = Thomas H. Cormen\n |author2=[[Charles E. Leiserson|Leiserson, C.E.]] |author3=[[Ronald L. Rivest|Rivest, R.L.]] |author4=[[Clifford Stein|Stein, C.]]\n |title = Introduction to Algorithms\n |edition = 2nd\n |year = 2001\n |publisher = MIT Press and McGraw-Hill\n |isbn = 978-0-262-03293-3\n |chapter = Chapter 34: NP–Completeness\n |pages = 966–1021\n|title-link = Introduction to Algorithms\n }}\n* {{Cite book\n |last = Sipser\n |first = M.\n |authorlink = Michael Sipser\n |title = Introduction to the Theory of Computation\n |year = 1997\n |publisher = PWS Publishing\n |chapter = Sections 7.4–7.5 (NP-completeness, Additional NP-complete Problems)\n |pages = 248–271\n |isbn = 978-0-534-94728-6\n}}\n* {{Cite book\n |last = Papadimitriou\n |first = C.\n |authorlink = Christos Papadimitriou\n |title = Computational Complexity\n |edition = 1st\n |year = 1994\n |publisher = Addison Wesley\n |chapter = Chapter 9 (NP-complete problems)\n |pages = 181–218\n |isbn = 978-0-201-53082-7\n}}\n* [http://www.ics.uci.edu/~eppstein/cgt/hard.html Computational Complexity of Games and Puzzles]\n* [https://arxiv.org/abs/cs.CC/0210020 Tetris is Hard, Even to Approximate]\n* [http://for.mat.bham.ac.uk/R.W.Kaye/minesw/ordmsw.htm Minesweeper is NP-complete!]\n* {{Cite journal\n |last = Bern |first = Marshall\n |doi = 10.1002/net.3230200110\n |issue = 1\n |journal = Networks\n |pages = 109–120\n |title = Faster exact algorithms for Steiner trees in planar networks\n |volume = 20\n |year = 1990\n |ref = harv\n |postscript = <!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}}}.\n* {{Cite journal\n |last1 = Deĭneko |first1 = Vladimir G.\n |last2 = Klinz |first2 = Bettina\n |last3 = Woeginger |first3 = Gerhard J. |author3-link = Gerhard J. Woeginger\n |doi = 10.1016/j.orl.2005.04.013\n |issue = 3\n |journal = Operations Research Letters\n |pages = 269–274\n |title = Exact algorithms for the Hamiltonian cycle problem in planar graphs\n |volume = 34\n |year = 2006\n |ref = harv\n |postscript = <!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}}}.\n* {{Cite book\n |last1 = Dorn |first1 = Frederic\n |last2 = Penninkx |first2 = Eelko\n |last3 = Bodlaender |first3 = Hans L.  author3-link = Hans L. Bodlaender\n |last4 = Fomin |first4 = Fedor V.\n |doi = 10.1007/11561071_11\n |pages = 95–106\n |publisher = Springer-Verlag\n |series = Lecture Notes in Computer Science\n |title = Proc. 13th European Symposium on Algorithms (ESA '05)\n |volume = 3669\n |year = 2005\n |chapter = Efficient Exact Algorithms on Planar Graphs: Exploiting Sphere Cut Branch Decompositions\n |isbn = 978-3-540-29118-3\n |ref = harv\n |postscript = <!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}}}.\n* {{Cite journal\n |last1 = Lipton |first1 = Richard J. |author1-link = Richard J. Lipton\n |last2 = Tarjan |first2 = Robert E. |author2-link = Robert Tarjan\n |doi = 10.1137/0209046\n |journal = [[SIAM Journal on Computing]]\n |pages = 615–627\n |title = Applications of a planar separator theorem\n |volume = 9\n |year = 1980\n |issue = 3\n |ref = harv\n |postscript = <!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}}}.\n{{refend}}\n\n== Further reading ==\n{{refbegin}}\n* [[Scott Aaronson]], ''[https://arxiv.org/abs/quant-ph/0502072 NP-complete Problems and Physical Reality]'', ACM [[SIGACT]] News, Vol. 36, No. 1. (March 2005), pp.&nbsp;30–52.\n* [[Lance Fortnow]], ''[http://people.cs.uchicago.edu/~fortnow/papers/pnp-cacm.pdf The status of the P versus NP problem]'', [[Commun. ACM]], Vol. 52, No. 9. (2009), pp.&nbsp;78–86.\n{{refend}}\n\n{{ComplexityClasses}}\n\n{{DEFAULTSORT:Np-Complete}}\n[[Category:1971 in computer science]]\n[[Category:NP-complete problems| ]]\n[[Category:Complexity classes]]\n[[Category:Mathematical optimization]]\n[[Category:Articles with inconsistent citation formats]]"
    },
    {
      "title": "Online optimization",
      "url": "https://en.wikipedia.org/wiki/Online_optimization",
      "text": "'''Online optimization''' is a field of [[optimization]] theory, more popular in [[computer science]] and [[operations research]], that deals with optimization problems having no or incomplete knowledge of the future (online). These kind of problems are denoted as online problems and are seen as opposed to the classical optimization problems where complete information is assumed (offline). The research on online optimization can be distinguished into online problems where multiple decisions are made sequentially based on a piece-by-piece input and those where a decision is made only once. A famous online problem where a decision is made only once is the [[Ski rental problem]]. In general, the output of an [[online algorithm]] is compared to the solution of a corresponding offline algorithm which is necessarily always optimal and knows the entire input in advance (competitive analysis).\n\nIn many situations, present decisions (for example, resources allocation) must be made with incomplete knowledge of the future or distributional assumptions on the future are not reliable. In such cases, online optimization<ref>Jaillet, Patrick, and Michael R. Wagner. Online Optimization. Springer Publishing Company, Incorporated, 2012.</ref>  can be used, which is different from other approaches such as [[robust optimization]], [[stochastic optimization]] and Markov decision processes.\n\n== Online problems ==\nA problem exemplifying the concepts of online algorithms is the [[Canadian traveller problem]]. The goal of this problem is to minimize the cost of reaching a target in a weighted graph where some of the edges are unreliable and may have been removed from the graph. However, that an edge has been removed (''failed'') is only revealed to ''the traveller'' when she/he reaches one of the edge's endpoints. The worst case for this problem is simply that all of the unreliable edges fail and the problem reduces to the usual [[shortest path problem]]. An alternative analysis of the problem can be made with the help of competitive analysis. For this method of analysis, the offline algorithm knows in advance which edges will fail and the goal is to minimize the ratio between the online and offline algorithms' performance. This problem is [[PSPACE-complete]].\n\nThere are many formal problems that offer more than one ''online algorithm'' as solution:\n* [[K-server problem]]\n* [[Job shop scheduling|Job shop scheduling problem]]\n* [[List update problem]]\n* [[Bandit problem]]\n* [[Secretary problem]]\n* [[Search games]]\n* [[Ski rental problem]]\n* [[Linear search problem]]\n* Portfolio selection problem<ref name=doc16>{{cite book|last1=Dochow|first1=Robert|title=Online Algorithms for the Portfolio Selection Problem|date=2016|publisher=Springer Gabler|url=https://www.springer.com/de/book/9783658135270|}}</ref>\n\n==References==\n{{reflist}}\n\n{{Computer science stub}}\n\n[[Category:Mathematical optimization]]\n[[Category:Algorithms]]"
    },
    {
      "title": "Open energy system models",
      "url": "https://en.wikipedia.org/wiki/Open_energy_system_models",
      "text": "{{about||sources of the open data required for open modeling|open energy system databases}}\n{{use dmy dates|date=May 2016}}\n{{use American English|date=May 2016}}\n\n{{broader|energy modeling}}\n\n'''Open energy system models''' are [[energy system]] [[Energy modeling|models]] that are [[open source software|open source]].{{efn|\nThe terminology is not settled.  These models can also be known as '''open energy models''' or '''open source energy system models''' or some combination thereof.\n}}  Similarly open energy system data employs [[open data]] methods to produce and distribute [[dataset]]s primarily for use by open energy system models.\n\nEnergy system models are used to explore future energy systems and are often applied to questions involving [[energy policy|energy]] and [[Politics of global warming|climate policy]].  The models themselves vary widely in terms of their type, design, [[Programming language|programming]], application, scope, level of detail, sophistication, and shortcomings.<ref name=\"pye-and-bataille-2016\">{{cite journal\n | first1 = Steve | last1 = Pye\n | first2 = Chris | last2 = Bataille\n | title = Improving deep decarbonization modelling capacity for developed and developing country contexts\n | year = 2016\n | journal = Climate Policy\n | volume = 16\n | number = S1\n | pages = S27–S46\n | doi = 10.1080/14693062.2016.1173004\n}}\n</ref>{{rp|S30–S34}}  The open energy modeling projects listed here fall exclusively within the bottom-up paradigm, in which a model is a relatively literal representation of the underlying system.<ref name=\"kolstad-etal-2014\">\n{{cite book\n | first1 = Charles | last1 = Kolstad\n | first2 = Kevin | last2 = Urama\n | first3 = John | last3 = Broome\n | first4 = Annegrete | last4 = Bruvoll\n | first5 = Micheline Cariño | last5 = Olvera\n | first6 = Don | last6 = Fullerton\n | first7 = Christian | last7 = Gollier\n | first8 = William Michael | last8 = Hanemann\n | first9 = Rashid | last9 = Hassan\n | first10 = Frank | last10 = Jotzo\n | first11 = Mizan R | last11 = Khan\n | first12 = Lukas | last12 = Meyer\n | first13 = Luis | last13 = Mundaca\n | editor = IPCC\n | year = 2014\n | title = Climate change 2014: mitigation of climate change. Contribution of Working Group III to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change\n | chapter = Chapter 3: Social, economic, and ethical concepts and methods\n | publisher = [[Cambridge University Press]]\n | location = Cambridge, United Kingdom and New York, NY, USA\n | pages = 207–282\n | isbn = 978-1-107-65481-5\n | url = http://www.ipcc.ch/pdf/assessment-report/ar5/wg3/ipcc_wg3_ar5_full.pdf\n | access-date = 2016-05-09\n}}\n</ref>{{rp|238}}  For many models, some form of [[mathematical optimization]] is used to inform the solution process.\n\nSeveral drivers favor the development of open models and open data.  There is an increasing interest in making [[public policy]] energy models more transparent to improve their acceptance by policymakers and the public.<ref name=\"acatech-etal-2016\">\n<!-- alternative URL: http://www.akademienunion.de/fileadmin/redaktion/user_upload/Publikationen/Stellungnahmen/Stellungnahme_Energy_scenarios.pdf -->\n{{cite book\n | editor1 = acatech\n | editor2 = Lepoldina\n | editor3 = Akademienunion\n | title = Consulting with energy scenarios: requirements for scientific policy advice\n | date = 2016\n | publisher = acatech — National Academy of Science and Engineering\n | place = Berlin, Germany\n | isbn = 978-3-8047-3550-7\n | url = http://www.acatech.de/fileadmin/user_upload/Baumstruktur_nach_Website/Acatech/root/de/Publikationen/Kooperationspublikationen/ESYS_Position_Paper_Energy_scenarios.pdf\n | access-date = 2016-12-19\n}}\n</ref>  There is also a desire to leverage the benefits that open data and [[open-source software development|open software development]] can bring, including reduced duplication of effort, better sharing of ideas and information, improved quality, and wider engagement and adoption.<ref name=\"bazilian-etal-2012\"/>  Model development is therefore usually a [[collaborative software development model|team effort]] and constituted as either an academic project, a commercial venture, or a genuinely inclusive community initiative.\n\nThis article does not cover projects which simply make their [[source code]] or [[spreadsheet]]s available for public download, but which omit a recognized [[free software license|free and open-source software license]].  The absence of a [[License|license agreement]] creates a state of legal uncertainty whereby potential users cannot know which limitations the owner may want to enforce in the future.<ref name=\"morin-etal-2012\">\n<!-- website URL: http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002598 -->\n{{cite journal\n | last1 = Morin | first1 = Andrew\n | last2 = Urban | first2 = Jennifer\n | last3 = Sliz | first3 = Piotr\n | title = A quick guide to software licensing for the scientist-programmer\n | date = 26 July 2012\n | journal = PLOS Computational Biology\n | volume = 8\n | issue = 7\n | pages = e1002598\n | doi = 10.1371/journal.pcbi.1002598\n | issn = 1553-7358\n | url = http://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1002598&type=printable\n | access-date = 2016-12-10\n| bibcode = 2012PLSCB...8E2598M\n }} {{open access}}\n</ref>{{rp|1}}  The projects listed here are deemed suitable for inclusion through having pending or published academic literature or by being reported in secondary sources.\n\n== General considerations ==\n\n{{see also|Energy modeling|Open-source software development}}\n\n=== Organization ===\n\nAn open energy system modeling project typically comprises a [[codebase]], [[dataset]]s, and [[software documentation]] and perhaps [[Scientific literature|scientific publications]].<ref name=\"bazilian-etal-2012\">\n{{cite journal\n | last1 = Bazilian | first1 = Morgan\n | last2 = Rice | first2 = Andrew\n | last3 = Rotich | first3 = Juliana\n | last4 = Howells | first4 = Mark\n | last5 = DeCarolis | first5 = Joseph\n | last6 = Macmillan | first6 = Stuart\n | last7 = Brooks | first7 = Cameron\n | last8 = Bauer | first8 = Florian\n | last9 = Liebreich | first9 = Michael\n | title = Open source software and crowdsourcing for energy analysis\n | year = 2012\n | journal = Energy Policy\n | volume = 49\n | pages = 149–153\n | doi = 10.1016/j.enpol.2012.06.032\n | url = http://www.ourenergypolicy.org/wp-content/uploads/2012/07/BNEF_open_source_software_and_crowdsourcing_for_energy_analysis.pdf\n | access-date = 2016-06-17\n}}\n</ref>  The project repository may be hosted on an institutional server or on a public [[Comparison of open source software hosting facilities|code-hosting site]], such as [[GitHub]].  Some projects release only their [[codebase]], while others ship some or all of their [[dataset]]s as well.  Projects may also offer [[Electronic mailing list|email lists]], [[Online chat|chat rooms]], and [[Internet forum|web forums]] to aid collaboration.\n\nThe majority of projects are based within university research groups, either individually or as academic collaborations.\n\nA 2017 paper lists the benefits of open data and models and discusses the reasons that many projects nonetheless remain closed.<ref name=\"pfenninger-etal-2017\">\n{{cite journal\n | last1 = Pfenninger | first1 = Stefan\n | last2 = DeCarolis | first2 = Joseph\n | last3 = Hirth | first3 = Lion\n | last4 = Quoilin | first4 = Sylvain\n | last5 = Staffell | first5 = Iain\n | date = February 2017\n | title = The importance of open data and software: is energy research lagging behind?\n | journal = Energy Policy\n | volume = 101\n | pages = 211–215\n | doi = 10.1016/j.enpol.2016.11.046\n | issn = 0301-4215\n | url = http://www.sciencedirect.com/science/article/pii/S0301421516306516/pdfft?md5=97ab263abcdfa8b8853c52dda11d7592&pid=1-s2.0-S0301421516306516-main.pdf\n | access-date = 2017-02-03\n}} {{open access}}\n</ref>{{rp|211–213}}  The paper makes a number of recommendations for projects wishing to transition to a more open approach.<ref name=\"pfenninger-etal-2017\"/>{{rp|214}}  The authors also conclude that, in terms of openness, energy research has lagged behind other fields, most notably physics, biotechnology, and medicine.<ref name=\"pfenninger-etal-2017\"/>{{rp|213–214}}\n\n=== Growth ===\n\nOpen energy system modeling came of age in the 2010s.  Just two projects were cited in a 2011 paper on the topic: [[#OSeMOSYS|OSeMOSYS]] and [[#TEMOA|TEMOA]].<ref name=\"howells-etal-2011\"/>{{rp|5861}}  [[#Balmorel|Balmorel]] was also active at that time, having been made public in 2001.{{efn|\n[[#NEMO|NEMO]] was also under development in 2011 but it is unclear whether its codebase was public at that point.\n}}  {{as of|2017|03}}, this article lists 25 such undertakings (with a further six waiting to be [[Talk:Open energy system models#Further models|added]]).\n\n=== Transparency, comprehensibility, and reproducibility ===\n\n{{see also|Open Energy Modelling Initiative#Context}}\n\nThe use of open energy system models and open energy data represents one attempt to improve the transparency, comprehensibility, and reproducibility of energy system models, particularly those used to aid public policy development.<ref name=\"acatech-etal-2016\"/>\n\nA 2010 paper concerning energy efficiency modeling argues that \"an open peer review process can greatly support model verification and validation, which are essential for model development\".<ref name=\"mundaca-etal-2010a\"><!--\ndocument listing: http://www.osti.gov/scitech/biblio/1001644\ndocument listing: https://eta.lbl.gov/publications/evaluating-energy-efficiency-policies\nalternative download: http://www.osti.gov/scitech/servlets/purl/1001644\n-->\n{{cite book|url=https://ies.lbl.gov/sites/all/files/lbnl-3862e_1.pdf|title=Evaluating energy efficiency policies with energy-economy models — Report number LBNL-3862E|last1=Mundaca|first1=Luis|last2=Neij|first2=Lena|last3=Worrell|first3=Ernst|last4=McNeil|first4=Michael A|date=1 August 2010|publisher=Ernest Orlando Lawrence Berkeley National Laboratory|location=Berkeley, CA, US|doi=10.1146/annurev-environ-052810-164840|osti=1001644|access-date=2016-11-15}}\n</ref>{{rp|17}}<ref name=\"mundaca-etal-2010b\">\n{{cite journal\n | last1 = Mundaca | first1 = Luis\n | last2 = Neij | first2 = Lena\n | last3 = Worrell | first3 = Ernst\n | last4 = McNeil | first4 = Michael A\n | title = Evaluating energy efficiency policies with energy-economy models\n | date = 22 October 2010\n | journal = Annual Review of Environment and Resources\n | volume = 35\n | issue = 1\n | pages = 305–344\n | doi = 10.1146/annurev-environ-052810-164840\n | issn = 1543-5938\n}}\n</ref>  To further honor the process of [[peer review]], researchers argue, in a 2012 paper, that it is essential to place both the [[source code]] and [[dataset]]s under publicly accessible [[version control]] so that third-parties can run, verify, and scrutinize specific models.<ref name=\"decarolis-etal-2012\"/>  A 2016 paper contends that model-based energy scenario studies, seeking to influence decision-makers in government and industry, must become more comprehensible and more transparent.  To these ends, the paper provides a [[checklist]] of transparency criteria that should be completed by modelers.  The authors however state that they \"consider open source approaches to be an extreme case of transparency that does not automatically facilitate the comprehensibility of studies for policy advice.\"<ref name=\"cao-etal-2016\">\n<!-- license: Creative Commons Attribution 4.0 International License (https://creativecommons.org/licenses/by/4.0/) which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. -->\n{{cite journal\n | last1 = Cao | first1 = Karl-Kiên\n | last2 = Cebulla | first2 = Felix\n | last3 = Gómez Vilchez | first3 = Jonatan J\n | last4 = Mousavi | first4 = Babak\n | last5 = Prehofer | first5 = Sigrid\n | date = 28 September 2016\n | title = Raising awareness in model-based energy scenario studies — a transparency checklist\n | journal = Energy, Sustainability and Society\n | volume = 6\n | issue = 1\n | pages = 28–47\n | doi = 10.1186/s13705-016-0090-z\n | issn = 2192-0567\n | url = https://link.springer.com/article/10.1186/s13705-016-0090-z\n | access-date = 2016-10-04\n}} {{open access}}\n</ref>{{rp|4}}\n\nA one-page opinion piece from 2017 advances the case for using open energy data and modeling to build public trust in policy analysis.  The article also argues that [[academic journal|scientific journals]] have a responsibility to require that data and code be submitted alongside text for [[peer review]].<ref name=\"pfenninger-2017\"><!-- alternative url: http://www.nature.com/news/energy-scientists-must-show-their-workings-1.21517 -->\n{{cite journal|last=Pfenninger|first=Stefan|date=23 February 2017|title=Energy scientists must show their workings|url=http://www.nature.com/polopoly_fs/1.21517!/menu/main/topColumns/topLeftColumn/pdf/542393a.pdf|journal=Nature News|volume=542|issue=7642|pages=393|bibcode=2017Natur.542..393P|doi=10.1038/542393a|access-date=2017-02-26}}\n</ref>\n\n=== State projects ===\n\nState-sponsored open source projects in any domain are a relatively new phenomena.\n\n{{as of|2017}}, the [[European Commission]] now supports several open source energy system modeling projects to aid the transition to a low-carbon energy system for Europe.  The Dispa-SET project ([[#Dispa-SET|below]]) is modeling the European electricity system and hosts its codebase on [[GitHub]].  The MEDEAS project, which will design and implement a new open source energy-economy model for Europe, held its kick-off meeting in February 2016.<ref name=\"set-plan-2016-one\">\n{{cite journal\n | author = <!-- staff writer, no by-line -->\n | date = November 2016\n | title = SET-Plan update\n | journal = SETIS magazine\n | number = 13\n | pages = 5–7\n | issn = 2467-382X\n | url = http://publications.jrc.ec.europa.eu/repository/bitstream/JRC103767/2016_no.13_modelling%20magazine_web-version.pdf\n | access-date = 2017-03-01\n}}\n</ref>{{rp|6}}<ref name=\"medeas-website\">\n{{cite web\n | title = Medeas: modeling the renewable energy transition in Europe\n | work = Spanish National Research Council (CSIC)\n | location = Barcelona, Spain\n | url = http://www.medeas.eu\n | access-date = 2017-03-01\n}}\n</ref>  {{as of|2017|02}}, the project had yet to publish any source code.  The established OSeMOSYS project ([[#OSeMOSYS|below]]) is developing a multi-sector energy model for Europe with Commission funding to support stakeholder outreach.<ref name=\"howells-2016\">\n{{cite journal\n | first1 = Mark | last1 = Howells\n | date = November 2016\n | title = OSeMOSYS: open source software for energy modelling\n | journal = SETIS magazine\n | number = 13\n | pages = 37–38\n | issn = 2467-382X\n | url = http://publications.jrc.ec.europa.eu/repository/bitstream/JRC103767/2016_no.13_modelling%20magazine_web-version.pdf\n | access-date = 2017-03-01\n}}\n</ref>  The flagship {{nowrap|JRC-EU-TIMES}} model however remains closed source.<ref name=\"simoes-etal-2013\">\n{{cite book\n | first1 = Sofia | last1 = Simoes\n | first2 = Wouter | last2 = Nijs\n | first3 = Pablo | last3 = Ruiz\n | first4 = Alessandra | last4 = Sgobbi\n | first5 = Daniela | last5 = Radu\n | first6 = Pelin | last6 = Bolat\n | first7 = Christian | last7 = Thiel\n | first8 = Stathis | last8 = Peteves\n | date = 2013\n | title = The JRC-EU-TIMES model: assessing the long-term role of the SET Plan energy technologies — LD-NA-26292-EN-N\n | publisher = Publications Office of the European Union\n | location = Luxembourg\n | doi = 10.2790/97596\n | issn = 1831-9424\n | isbn = 978-92-79-34506-7\n | url = http://publications.jrc.ec.europa.eu/repository/bitstream/JRC85804/jrc_times_%20eu_overview_online.pdf\n | access-date = 2017-03-03\n}}  The DOI, ISBN, and ISSN refer to the online version.\n</ref>\n\nThe United States [[National Energy Modeling System|NEMS]] national model is available but nonetheless difficult to use.  NEMS does not classify as an open source project in the accepted sense.<ref name=\"pfenninger-2017\"/>\n\n== Open electricity sector models ==\n\nOpen electricity sector models are confined to just the electricity sector.  These models invariably have a temporal resolution of one hour or less.  Some models concentrate on the engineering characteristics of the system, including a good representation of [[Electric power transmission|high-voltage transmission networks]] and [[Power-flow study|AC power flow]].  Others models depict electricity [[spot market]]s and are known as dispatch models.  While other models embed [[Agent-based model|autonomous agents]] to capture, for instance, [[Auction|bidding decisions]] using techniques from [[bounded rationality]].  The ability to handle [[variable renewable energy]], transmission systems, and [[Grid energy storage|grid storage]] are becoming important considerations.\n\n{| class=\"wikitable sortable\"\n|+ {{anchor|table-open-electricity-sector-models}} Open electricity sector models\n|-\n! Project\n! Host\n! License\n! Access\n! Coding\n! Documentation\n! Scope/type\n|-\n| [[#DIETER|DIETER]]\n| [[German Institute for Economic Research|DIW Berlin]]\n| [[MIT license|MIT]]\n| download\n| [[General Algebraic Modeling System|GAMS]]\n| publication\n| dispatch and investment\n|-\n| [[#Dispa-SET|Dispa-SET]]\n| [[European Commission|EC]] [[Joint Research Centre]]\n| [[European Union Public Licence|EUPL{{nbsp}}1.1]]\n| [[GitHub]]\n| [[General Algebraic Modeling System|GAMS]], [[Python (programming language)|Python]]\n| website\n| European transmission and dispatch\n|-\n| [[#EMLab-Generation|EMLab-Generation]]\n| [[Delft University of Technology]]\n| [[Apache License|Apache 2.0]]\n| [[GitHub]]\n| [[Java (programming language)|Java]]\n| manual, website\n| [[agent-based model|agent-based]]\n|-\n| [[#EMMA|EMMA]]\n| Neon Neue Energieökonomik\n| [[Creative Commons license|CC BY-SA 3.0]]\n| download\n| [[General Algebraic Modeling System|GAMS]]\n| website\n| electricity market\n|-\n| [[#GENESYS|GENESYS]]\n| [[RWTH Aachen University]]\n| [[GNU Lesser General Public License|LGPLv2.1]]\n| on application\n| [[C++]]\n| website\n| European electricity system\n|-\n| [[#NEMO|NEMO]]\n| [[University of New South Wales]]\n| [[GNU General Public License|GPLv3]]\n| git repository\n| [[Python (programming language)|Python]]\n| website, list\n| [[National Electricity Market|Australian NEM]] market\n|-\n| [[#OnSSET|OnSSET]]\n| [[Royal Institute of Technology|KTH Royal Institute of Technology]]\n| [[MIT License|MIT]]\n| [[GitHub]]\n| [[Python (programming language)|Python]]\n| website, GitHub\n| cost-effective electrification\n|-\n| [[#pandapower|pandapower]]\n| {{unbulleted list|[[University of Kassel]]|[[Fraunhofer Institute]] IEE}}\n| [[BSD-new]]\n| [[GitHub]]\n| [[Python (computer language)|Python]]\n| website\n| automated power system analysis\n|-\n| [[#PowerMatcher|PowerMatcher]]\n| Flexiblepower Alliance Network\n| [[Apache License|Apache 2.0]]\n| [[GitHub]]\n| [[Java (programming language)|Java]]\n| website\n| smart grid\n|-\n| [[#renpass|renpass]]\n| [[University of Flensburg]]\n| [[GNU General Public License|GPLv3]]\n| by invitation\n| [[R (programming language)|R]], [[MySQL]]\n| manual\n| renewables pathways\n|-\n| [[#SciGRID|SciGRID]]\n| DLR Institute of Networked Energy Systems\n| [[Apache License|Apache 2.0]]\n| git repository\n| [[Python (programming language)|Python]]\n| website, newsletter\n| European transmission grid\n|-\n| [[#SIREN|SIREN]]\n| Sustainable Energy Now\n| [[Affero General Public License|AGPLv3]]\n| [[GitHub]]\n| [[Python (programming language)|Python]]\n| website\n| renewable generation\n|-\n| [[#SWITCH|SWITCH]]\n| [[University of Hawai'i]]\n| [[Apache License|Apache 2.0]]\n| [[GitHub]]\n| [[Python (programming language)|Python]]\n| website\n| optimal planning\n|-\n| [[#URBS|URBS]]\n| [[Technical University of Munich]]\n| [[GNU General Public License|GPLv3]]\n| [[GitHub]]\n| [[Python (programming language)|Python]]\n| website\n| distributed energy systems\n|- class=\"sortbottom\"\n| colspan=\"7\" style=\"font-size: smaller\" | {{plainlist|\n* '''Access''' refers to the methods offered for accessing the codebase.\n}}\n|}\n\n=== DIETER ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | DIETER\n|-\n! Host\n| [[German Institute for Economic Research|DIW Berlin]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| dispatch and investment\n|-\n! Code license\n| [[MIT license|MIT]]\n|-\n! Data license\n| [[MIT license|MIT]]\n|-\n! Website\n| {{url|http://www.diw.de/dieter}}\n|}\n\nDIETER stands for Dispatch and Investment Evaluation Tool with Endogenous Renewables.  DIETER is a dispatch and investment model. It was first used to study the role of [[Grid energy storage|power storage]] and other flexibility options in a future [[Greenfield project|greenfield]] setting with high shares of renewable generation.  DIETER is being developed at the [[German Institute for Economic Research]] (DIW), [[Berlin]], Germany.  The [[codebase]] and [[Data (computing)|datasets]] for Germany can be downloaded from the project website.  The basic model is fully described in a DIW working paper and a journal article.<ref name=\"zerrahn-and-schill-2015\">\n{{cite book\n | last1 = Zerrahn | first1 = Alexander\n | last2 = Schill | first2 = Wolf-Peter\n | title = A greenfield model to evaluate long-run power storage requirements for high shares of renewables — DIW discussion paper 1457\n | year = 2015\n | publisher = German Institute for Economic Research (DIW)\n | location = Berlin, Germany\n | issn = 1619-4535\n | url = http://www.diw.de/documents/publikationen/73/diw_01.c.498475.de/dp1457.pdf\n | access-date = 2016-07-07\n}}\n</ref><ref>{{Cite journal|last=Zerrahn|first=Alexander|last2=Schill|first2=Wolf-Peter|title=Long-run power storage requirements for high shares of renewables: review and a new model|url=https://doi.org/10.1016/j.rser.2016.11.098|journal=Renewable and Sustainable Energy Reviews|doi=10.1016/j.rser.2016.11.098|volume=79|year=2017|pages=1518–1534}}</ref>  DIETER is written in [[General Algebraic Modeling System|GAMS]] and was developed using the [[CPLEX]] commercial solver.\n\nDIETER is framed as a pure [[Linear programming|linear]] (no integer variables) cost minimization problem.  In the initial formulation, the decision variables include the investment in and dispatch of generation, storage, and [[Energy demand management|DSM]] capacities in the German wholesale and balancing electricity markets.  Later model extensions include [[vehicle-to-grid]] interactions and prosumage of solar electricity.<ref>{{Cite journal|last=Schill|first=Wolf-Peter|last2=Niemeyer|first2=Moritz|last3=Zerrahn|first3=Alexander|last4=Diekmann|first4=Jochen|date=2016-06-01|title=Bereitstellung von Regelleistung durch Elektrofahrzeuge: Modellrechnungen für Deutschland im Jahr 2035|url=https://link.springer.com/article/10.1007/s12398-016-0174-7|journal=Zeitschrift für Energiewirtschaft|language=de|volume=40|issue=2|pages=73–87|doi=10.1007/s12398-016-0174-7|issn=0343-5377}}</ref><ref>{{Cite journal|last=Schill|first=Wolf-Peter|last2=Zerrahn|first2=Alexander|last3=Kunz|first3=Friedrich|date=2017-06-01|title=Prosumage of solar electricity: pros, cons, and the system perspective|url=https://doi.org/10.5547/2160-5890.6.1.wsch|journal=Economics of Energy & Environmental Policy|language=en-US|volume=6|issue=1|doi=10.5547/2160-5890.6.1.wsch|issn=2160-5882}}</ref>\n\nThe first study using DIETER examines the power storage requirements for renewables uptake ranging from 60% to 100%.  Under the baseline scenario of 80% (the lower bound German government target for 2050), [[Grid energy storage|grid storage]] requirements remain moderate and other options on both the supply side and demand side offer flexibility at low cost.  Nonetheless storage plays an important role in the provision of reserves.  Storage becomes more pronounced under higher shares of renewables, but strongly depends on the costs and availability of other flexibility options, particularly biomass availability.<ref>{{Cite journal|last=Schill|first=Wolf-Peter|last2=Zerrahn|first2=Alexander|title=Long-run power storage requirements for high shares of renewables: Results and sensitivities|url=https://doi.org/10.1016/j.rser.2017.05.205|journal=Renewable and Sustainable Energy Reviews|doi=10.1016/j.rser.2017.05.205|year=2017}}</ref>\n\n{{clear}}\n\n=== Dispa-SET ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | Dispa-SET\n|-\n! Host\n| [[European Commission|EC]] [[Joint Research Centre]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| European transmission and dispatch\n|-\n! Code license\n| [[European Union Public Licence|EUPL{{nbsp}}1.1]]\n|-\n! Data license\n| [[European Union Public Licence|EUPL{{nbsp}}1.1]]\n|-\n! Website\n| {{url|http://www.dispaset.eu}}\n|-\n! Repository\n| {{url|https://github.com/energy-modelling-toolkit/Dispa-SET}}\n|-\n! Documentation\n| {{url|http://www.dispaset.eu}}\n|}\n\nUnder development at the [[European Commission]]'s [[Joint Research Centre]] (JRC), [[Petten]], the Netherlands, {{nowrap|Dispa-SET}} is a unit commitment and dispatch model intended primarily for Europe.  It is written in [[Python (programming language)|Python]] (with [[Pyomo]]) and [[General Algebraic Modeling System|GAMS]] and uses Python for data processing.  A valid GAMS license is required.  The model is formulated as a [[Linear programming#Integer unknowns|mixed integer]] problem and JRC uses the proprietary [[CPLEX]] sover although open source libraries may also be deployed.  Technical descriptions are available for versions{{nbsp}}2.0{{nnbsp}}<ref name=\"hidalgo-gonzalez-etal-2014\">\n{{cite book\n | last1 = Hidalgo González | first1 = Ignacio\n | last2 = Quoilin | first2 = Sylvain\n | last3 = Zucker | first3 = Andreas\n | date = 2014\n | title = Dispa-SET 2.0: unit commitment and power dispatch model: description, formulation, and implementation — EUR 27015 EN\n | publisher = Publications Office of the European Union\n | location = Luxembourg\n | doi = 10.2790/399921\n | isbn = 978-92-79-44690-0\n | url = http://publications.jrc.ec.europa.eu/repository/bitstream/JRC93780/report%20dispa-set%202.0%2020150108%20online.pdf\n | access-date = 2017-03-01\n}}  The DOI and ISBN refer to the online version.\n</ref> and{{nbsp}}2.1.<ref name=\"quoilin-etal-2017\">\n{{cite book\n | last1 = Quoilin | first1 = Sylvain\n | last2 = Hidalgo González | first2 = Ignacio\n | last3 = Zucker | first3 = Andreas\n | date = 2017\n | title = Modelling future EU power systems under high shares of renewables: the Dispa-SET 2.1 open-source model — EUR 28427 EN\n | publisher = Publications Office of the European Union\n | location = Luxembourg\n | doi = 10.2760/25400\n | isbn = 978-92-79-65265-3\n | url = http://publications.jrc.ec.europa.eu/repository/bitstream/JRC105452/dispaset2.1_technical_report.pdf\n | access-date = 2017-03-01\n}}\n</ref>  {{nowrap|Dispa-SET}} is hosted on [[GitHub]], together with a trial dataset, and third-party contributions are encouraged.  The [[codebase]] has been tested on Windows, macOS, and Linux.  Online documentation is available.<ref name=\"dispa-set-documentation\">\n{{cite web\n | title = Dispa-SET documentation\n | url = https://dispa-set.readthedocs.io/en/latest/\n | access-date = 2017-03-02\n}}  Automatically the latest version.\n</ref>\n\nThe SET in the project name refers to the European Strategic Energy Technology Plan (SET-Plan), which seeks to make Europe a leader in energy technologies that can fulfill future (2020 and 2050) energy and climate targets.  Energy system modeling, in various forms, is central to this [[European Commission]] initiative.<ref name=\"set-plan-2016-two\">\n{{cite journal\n | author = <!-- staff writer, no by-line -->\n | date = November 2016\n | title = SET-Plan Update\n | journal = SETIS magazine\n | number = 13\n | pages = 5–7\n | issn = 2467-382X\n | url = http://publications.jrc.ec.europa.eu/repository/bitstream/JRC103767/2016_no.13_modelling%20magazine_web-version.pdf\n | access-date = 2017-03-01\n}}\n</ref>\n\n[[File:Rolling horizon.png|thumb|left|48{{nbsp}}hour rolling horizon optimization for any given 24{{nbsp}}hour day]]\n\nThe model power system is managed by a single operator with full knowledge of the economic and technical characteristics of the generation units, the loads at each node, and the heavily simplified transmission network.  Demand is deemed fully [[Elasticity (economics)|inelastic]].  The system is subject to intra-period and inter-period [[Unit commitment problem in electrical power production|unit commitment]] constraints (the latter covering nuclear and thermal generation for the most part) and operated under [[economic dispatch]].<ref name=\"quoilin-etal-2017\"/>{{rp|4}}  Hourly data is used and the simulation horizon is normally one year.  But to ensure the model remains tractable, two day rolling horizon optimization is employed.  The model advances in steps of one day, optimizing the next 48{{nbsp}}hours ahead but retaining results for just the first 24{{nbsp}}hours.<ref name=\"quoilin-etal-2017\"/>{{rp|14–15}}\n\nTwo related publications describe the role and representation of flexibility measures within power systems facing ever greater shares of [[variable renewable energy]] (VRE).<ref name=\"hidalgo-gonzalez-etal-2015\">\n{{cite report\n | first1 = Ignacio | last1 = Hidalgo González\n | first2 = Pablo | last2 = Ruiz Castello\n | first3 = Alessandra | last3 = Sgobbi\n | first4 = Wouter | last4 = Nijs\n | first5 = Sylvain | last5 = Quoilin\n | first6 = Andreas | last6 = Zucker\n | first7 = Christian | last7 = Thiel\n | date = 2015\n | title = Addressing flexibility in energy system models — EUR 27183 EN\n | publisher = Publications Office of the European Union\n | location = Luxembourg\n | doi = 10.2790/925\n | isbn = 978-92-79-47235-0\n | url = http://publications.jrc.ec.europa.eu/repository/bitstream/JRC95354/addressing%20flexibility%20in%20energy%20system%20models%20%28online%29%2020150413.pdf\n | access-date = 2017-03-02\n}}  The DOI and ISBN refer to the online version.\n</ref><ref name=\"quoilin-etal-2015\">\n{{cite conference\n | first1 = Sylvain | last1 = Quoilin\n | first2 = Wouter | last2 = Nijs\n | first3 = Ignacio | last3 = Hidalgo González\n | first4 = Andreas | last4 = Zucker\n | first5 = Christian | last5 = Thiel\n | date = 19 May 2015\n | title = Evaluation of simplified flexibility evaluation tools using a unit commitment model\n | conference = 2015 12th International Conference on the European Energy Market (EEM)\n | pages = 1–5\n | doi = 10.1109/EEM.2015.7216757\n | isbn = 978-1-4673-6692-2\n | issn = 2165-4077\n}}\n</ref>  These flexibility measures comprise: dispatchable generation (with constraints on efficiency, ramp rate, part load, and up and down times), conventional storage (predominantly [[pumped-storage hydroelectricity|pumped-storage hydro]]), cross-border interconnectors, [[Energy demand management|demand side management]], renewables curtailment, last resort [[rolling blackout|load shedding]], and nascent [[power-to-X]] solutions (with X being gas, heat, or mobility).  The modeler can set a target for renewables and place caps on {{CO2}} and other pollutants.<ref name=\"quoilin-etal-2017\"/>  Planned extensions to the software include support for simplified AC power flow{{nnbsp}}{{efn|The simplified AC power-flow method is also referred to as the DC load-flow method because the active power flow equation for fixed-frequency AC is ''analogous'' to [[Ohm's law]] applied to a resistor carrying DC current.<ref name=\"andersson-2008\">\n{{cite book\n | last1 = Andersson | first1 = Göran\n | date = 2008\n | title = Modelling and analysis of electric power systems: power flow analysis fault analysis power systems dynamics and stability\n | publisher = ETH Zurich\n | location = Zürich, Switzerland\n | url = http://www.eeh.ee.ethz.ch/uploads/tx_ethstudies/modelling_hs08_script_02.pdf\n | access-date = 2017-02-02\n}}\n</ref>{{rp|59}}  For the purposes of optimization, the quadratic loss function is also piecewise linearized.\n}} (transmission is currently treated as a [[Flow network|transportation problem]]), new constraints (like [[Water cooling|cooling water]] supply), [[stochastic]] scenarios, and the inclusion of markets for [[Ancillary services (electric power)|ancillary{{nbsp}}services]].<ref name=\"dispa-set-documentation\"/>\n\n{{nowrap|Dispa-SET}} has been or is being applied to case studies in Belgium, Bolivia, Greece, Ireland, and the Netherlands.  A 2014 Belgium study investigates [[Sensitivity analysis|what if]] scenarios for different mixes of nuclear generation, combined cycle gas turbine (CCGT) plant, and VRE and finds that the CCGT plants are subject to more aggressive cycling as renewable generation penetrates.<ref name=\"quoilin-etal-2014\">\n<!-- alternative url: http://orbi.ulg.be/handle/2268/172402 -->\n{{cite conference\n | first1 = Sylvain | last1 = Quoilin\n | first2 = Ignacio | last2 = Hidalgo González\n | first3 = Andreas | last3 = Zucker\n | first4 = Christian | last4 = Thiel\n | date = September 2014\n | title = Available technical flexibility for balancing variable renewable energy sources: case study in Belgium\n | book-title = Proceedings of the 9th Conference on Sustainable Development of Energy, Water and Environment Systems\n | url = http://orbi.ulg.be/bitstream/2268/172402/1/Paper%20SDEWES%20SQ140923.pdf\n | access-date = 2017-03-02\n}}\n</ref>\n\n{{clear}}\n\n=== EMLab-Generation ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | EMLab-Generation\n|-\n! Host\n| [[Delft University of Technology]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| agent-based\n|-\n! Code license\n| [[Apache License|Apache 2.0]]\n|-\n! Website\n| {{url|http://emlab.tudelft.nl/generation.html}}\n|-\n! Repository\n| {{url|https://github.com/EMLab/emlab-generation}}\n|}\n\nEMLab-Generation is an [[agent-based model]] covering two interconnected electricity markets – be they two adjoining countries or two groups of countries.  The software is being developed at the [http://emlab.tudelft.nl/ Energy Modelling Lab], [[Delft University of Technology]], [[Delft]], the Netherlands.  A factsheet is available.<ref name=\"emlab-factsheet\">\n{{cite book\n | title = EMLab — Generation Factsheet\n | publisher = Energy Modelling Lab, Delft University of Technology\n | location = Delft, The Netherlands\n | url = http://emlab.tudelft.nl/generation/emlab-generation-factsheet.pdf\n | access-date = 2016-07-09\n}}\n</ref>  And software documentation is available.<ref name=\"laurens-etal-2015\">\n{{cite book\n | first1 = Laurens J | last1 = de Vries\n | first2 = Émile JL | last2 = Chappin\n | first3 = Jörn C | last3 = Richstein\n | title = EMLab-Generation: an experimentation environment for electricity policy analysis — Project report — Version 1.2\n | date = August 2015\n | publisher = Energy Modelling Lab, Delft University of Technology\n | location = Delft, The Netherlands\n | url = http://emlab.tudelft.nl/generation/emlab-generation-report-1.2.pdf\n | access-date = 2016-07-09\n}}\n</ref>  EMLab-Generation is written in [[Java (programming language)|Java]].\n\nEMLab-Generation simulates the actions of [[Electric power industry|power companies]] investing in generation capacity and uses this to explore the long-term effects of various [[Energy policy|energy]] and [[Climate change mitigation|climate protection]] policies.  These policies may target renewable generation, {{CO2}} emissions, security of supply, and/or energy affordability.  The power companies are the main agents: they bid into power markets and they invest based on the [[net present value]] (NPV) of prospective power plant projects.  They can adopt a variety of technologies, using scenarios from the 2011 [[International Energy Agency|IEA]] [[World Energy Outlook]].<ref name=\"iea-2011\">\n{{cite book\n | title = World energy outlook 2011\n | year = 2011\n | publisher = International Energy Agency (IEA)\n | location = Paris, France\n | isbn = 978-92-64-12413-4\n | url = https://www.iea.org/publications/freepublications/publication/WEO2011_WEB.pdf\n | access-date = 2016-07-09\n}}\n</ref>  The agent-based methodology enables different sets of assumptions to be tested, such as the heterogeneity of actors, the consequences of imperfect expectations, and the behavior of investors outside of ideal conditions.\n\nEMLab-Generation offers a new way of modeling the effects of public policy on electricity markets.  It can provide insights into actor and system behaviors over time – including such things as investment cycles, abatement cycles, delayed responses, and the effects of uncertainty and risk on investment decisions.\n\nA 2014 study using EMLab-Generation investigates the effects of introducing floor and ceiling prices for {{CO2}} under the [[European Union Emission Trading Scheme|EU ETS]].  And in particular, their influence on the dynamic investment pathway of two interlinked electricity markets (loosely Great Britain and Central Western Europe).  The study finds a common, moderate {{CO2}} auction reserve price results in a more continuous decarbonisation pathway and reduces {{CO2}} price volatility.  Adding a ceiling price can shield consumers from extreme price shocks.  Such price restrictions should not lead to an overshoot of emissions targets in the long-run.<ref name=\"richstein-etal-2014\">\n{{cite journal\n | first1 = Jörn C | last1 = Richstein\n | first2 = Emile JL | last2 = Chappin\n | first3 = Laurens J | last3 = de Vries\n | year = 2014\n | title = Cross-border electricity market effects due to price caps in an emission trading system: an agent-based approach\n | journal = Energy Policy\n | volume = 71\n | pages = 139–158\n | doi = 10.1016/j.enpol.2014.03.037\n | url = http://www.sciencedirect.com/science/article/pii/S0301421514002043/pdfft?md5=f586bdc740bb1562a3e5aefc012d26e9&pid=1-s2.0-S0301421514002043-main.pdf\n | access-date = 2016-07-07\n}}\n</ref>\n\n{{clear}}\n\n=== EMMA ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | EMMA\n|-\n! Host\n| [http://neon-energie.de/en/ Neon Neue Energieökonomik]\n|-\n! Status\n| active\n|-\n! Scope/type\n| electricity market\n|-\n! Code license\n| [[Creative Commons license|{{nowrap|CC BY-SA 3.0}}]]\n|-\n! Data license\n| [[Creative Commons license|{{nowrap|CC BY-SA 3.0}}]]\n|-\n! Website\n| {{url|http://neon-energie.de/emma/}}\n|}\n\nEMMA is the European Electricity Market Model.  It is a techno-economic model covering the integrated Northwestern European power system.  EMMA is being developed by the energy economics consultancy Neon Neue Energieökonomik, [[Berlin]], Germany.  The [[source code]] and [[Data (computing)|datasets]] can be downloaded from the project website.  A manual is available.<ref name=\"hirth-2016\">\n{{cite book\n | first = Lion | last = Hirth\n | title = The European Electricity Market Model EMMA — Model documentation — Version 2016-04-12\n | date = 12 April 2016\n | publisher = Neon Neue Energieökonomik\n | location = Berlin, Germany\n | url = http://neon-energie.de/EMMA.pdf\n | access-date = 2016-07-09\n}}\n</ref>  EMMA is written in [[General Algebraic Modeling System|GAMS]] and uses the [[CPLEX]] commercial solver.\n\nEMMA models electricity dispatch and investment, minimizing the total cost with respect to investment, generation, and trades between market areas.  In economic terms, EMMA classifies as a [[partial equilibrium]] model of the wholesale [[electricity market]] with a focus on the supply-side.  EMMA identifies short-term or long-term optima (or equilibria) and estimates the corresponding capacity mix, hourly prices, dispatch, and cross-border trading.  Technically, EMMA is a pure [[Linear programming|linear program]] (no integer variables) with about two million {{nowrap|non-zero}} variables.  {{as of|2016}}, the model covers Belgium, France, Germany, the Netherlands, and Poland and supports conventional generation, renewable generation, and [[cogeneration]].<ref name=\"hirth-2016\"/><ref name=\"hirth-2014\">\n{{cite book\n | first = Leon | last = Hirth\n | title = The economics of wind and solar variability: how the variability of wind and solar power affects their marginal value, optimal deployment, and integration costs — PhD thesis\n | publisher = Technical University of Berlin\n | location = Berlin, Germany\n | doi = 10.14279/depositonce-4291\n | url = https://depositonce.tu-berlin.de/bitstream/11303/4588/2/hirth_lion.pdf\n | access-date = 2016-07-07\n}}\n</ref>\n\nEMMA has been used to study the economic effects of the increasing penetration of [[variable renewable energy]] (VRE), specifically solar power and wind power, in the Northwestern European power system.  A 2013 study finds that increasing VRE shares will depress prices and, as a consequence, the competitive large-scale deployment of renewable generation will be more difficult to accomplish than many anticipate.<ref name=\"hirth-2013\">\n{{cite journal\n | first = Lion | last = Hirth\n | title = The market value of variable renewables: the effect of solar wind power variability on their relative price\n | journal = Energy Economics\n | volume = 38\n | pages = 218–236\n | year = 2013\n | doi = 10.1016/j.eneco.2013.02.004\n | url = http://www.neon-energie.de/Hirth-2013-Market-Value-Renewables-Solar-Wind-Power-Variability-Price.pdf\n | access-date = 2016-07-09\n}}\n</ref>  A 2015 study estimates the welfare-optimal market share for wind and solar power.  For wind, this is 20%, three-fold more than at present.<ref name=\"hirth-2015\">\n{{cite journal\n | first = Leon | last = Hirth\n | title = The optimal share of variable renewables: how the variability of wind and solar power affects their welfare-optimal deployment\n | year = 2015\n | journal = The Energy Journal\n | volume = 36\n | number = 1\n | pages = 127–162\n | doi = 10.5547/01956574.36.1.6\n | url = http://www.neon-energie.de/Hirth-2015-Optimal-Share-Variable-Renewables-Wind-Solar-Power-Welfare.pdf\n | access-date = 2016-07-07\n}}\n</ref>\n\nAn independent 2015 study reviews the EMMA model and comments on the high assumed specific costs for renewable investments.<ref name=\"zerrahn-and-schill-2015\"/>{{rp|6}}\n\n{{clear}}\n\n=== GENESYS ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | GENESYS\n|-\n! Host\n| [[RWTH Aachen University]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| European electricity system\n|-\n! Code license\n| [[GNU Lesser General Public License|LGPLv2.1]]\n|-\n! Data license\n| [[GNU Lesser General Public License|LGPLv2.1]]\n|-\n! Website\n| {{url|1=http://www.genesys.rwth-aachen.de/index.php?id=12&L=3}}\n|}\n\nGENESYS stands for Genetic Optimisation of a European Energy Supply System.  The software is being developed jointly by the [http://www.iaew.rwth-aachen.de/?lang=en Institute of Power Systems and Power Economics] (IAEW) and the [https://www2.isea.rwth-aachen.de/de Institute for Power Electronics and Electrical Drives] (ISEA), both of [[RWTH Aachen University]], [[Aachen]], Germany.  The project maintains a website where potential users can request access to the [[codebase]] and the [[Data (computing)|dataset]] for the 2050 base scenario only.<ref>\n{{cite web\n | title = The Project\n | website = GENESYS project\n | url = http://www.genesys.rwth-aachen.de/index.php?id=projekt&L=3\n | access-date = 2016-07-09\n}}\n</ref>  Detailed descriptions of the software are available.<ref name=\"bussar-etal-2014\"/><ref name=\"bussar-etal-2016\"/>  GENESYS is written in [[C++]] and uses [[Boost (C++ libraries)|Boost]] libraries, the [[MySQL]] relational database, the [[Qt (software)|Qt{{nbsp}}4]] application framework, and optionally the [[CPLEX]] solver.\n\nThe GENESYS simulation tool is designed to optimize a future [[EUMENA]] (Europe, Middle East, and North Africa) power system and assumes a high share of renewable generation.  It is able to find an economically optimal distribution of generator, storage, and transmission capacities within a 21{{nbsp}}region EUMENA.  It allows for the optimization of this energy system in combination with an evolutionary method.  The optimization is based on a [[CMA-ES|covariance matrix adaptation evolution strategy]] (CMA-ES), while the operation is simulated as a hierarchical set-up of system elements which balance the load between the various regions at minimum cost using the [[network simplex algorithm]].  GENESYS ships with a set of input time series and a set of parameters for the year 2050, which the user can modify.\n\nA future EUMENA energy supply system with a high share of renewable energy sources (RES) will need a strongly interconnected energy transport grid and significant energy storage capacities.  GENESYS was used to dimension the storage and transmission between the 21{{nbsp}}different regions.  Under the assumption of 100% self-supply, about {{val|2500|u=GW}} of RES in total and a storage capacity of about {{val|240000|u=GWh}} are needed, corresponding to 6% of the annual energy demand, and a HVDC transmission grid of {{val|375000|u=GW·km}}.  The combined cost estimate for generation, storage, and transmission, excluding distribution, is 6.87{{nbsp}}¢/kWh.<ref name=\"bussar-etal-2014\">\n{{cite journal\n | first1 = Christian | last1 = Bussar\n | first2 = Melchior | last2 = Moos\n | first3 = Ricardo | last3 = Alvarez\n | first4 = Philipp | last4 = Wolf\n | first5 = Tjark | last5 = Thien\n | first6 = Hengsi | last6 = Chen\n | first7 = Zhuang | last7 = Cai\n | first8 = Matthias | last8 = Leuthold\n | first9 = Dirk Uwe | last9 = Sauer\n | first10 = Albert | last10 = Moser\n | title = Optimal allocation and capacity of energy storage systems in a future European power system with 100% renewable energy generation\n | year = 2014\n | journal = Energy Procedia\n | volume = 46\n | pages = 40–47\n | doi = 10.1016/j.egypro.2014.01.156\n | url = http://www.sciencedirect.com/science/article/pii/S1876610214001726/pdf?md5=7920a65166f703f26648e73f5ee8a7be&pid=1-s2.0-S1876610214001726-main.pdf\n | access-date = 2016-07-07\n}}\n</ref>\n\nA 2016 study looked at the relationship between storage and transmission capacity under high shares of renewable energy sources (RES) in an EUMENA power system.  It found that, up to a certain extent, transmission capacity and storage capacity can substitute for each other.  For a transition to a fully renewable energy system by 2050, major structural changes are required.  The results indicate the optimal allocation of photovoltaics and wind power, the resulting demand for storage capacities of different technologies (battery, pumped hydro, and hydrogen storage) and the capacity of the transmission grid.<ref name=\"bussar-etal-2016\">\n{{cite journal\n | first1 = Christian | last1 = Bussar\n | first2 = Philipp | last2 = Stöcker\n | first3 = Zhuang | last3 = Cai\n | first4 = Luiz | last4 = Moraes Jr\n | first5 = Dirk | last5 = Magnor\n | first6 = Pablo | last6 = Wiernes\n | first7 = Niklas | last7 = van Bracht\n | first8 = Albert | last8 = Moser\n | first9 = Dirk Uwe | last9 = Sauer\n | title = Large-scale integration of renewable energies and impact on storage demand in a European renewable power system of 2050 – Sensitivity study\n | journal = Journal of Energy Storage\n | volume = 6\n | pages = 1–10\n | year = 2016\n | doi = 10.1016/j.est.2016.02.004\n}}\n</ref>\n\n{{clear}}\n\n=== NEMO ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | NEMO\n|-\n! Host\n| [[University of New South Wales]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| Australian NEM market\n|-\n! Code license\n| [[GNU General Public License|GPLv3]]\n|-\n! Website\n| {{url|https://nemo.ozlabs.org}}\n|-\n! Repository\n| {{url|1=http://git.ozlabs.org/?p=nemo.git}}\n|-\n! Documentation\n| {{url|http://nbviewer.jupyter.org/urls/nemo.ozlabs.org/guide.ipynb}}\n|}\n\nNEMO, the National Electricity Market Optimiser, is a chronological dispatch model for testing and optimizing different portfolios of conventional and renewable electricity generation technologies.  It applies solely to the Australian [[National Electricity Market]] (NEM), which, despite its name, is limited to east and south Australia.  NEMO has been in development at the [http://www.ceem.unsw.edu.au/ Centre for Energy and Environmental Markets] (CEEM), [[University of New South Wales]] (UNSW), [[Sydney]], Australia since 2011.<ref name=\"nemo-website\">\n{{cite web\n | title = NEMO\n | website = OzLabs\n | location = Australia\n | url = https://nemo.ozlabs.org\n | access-date = 2016-12-03\n}}\n</ref>  The project maintains a small website and runs an [[Electronic mailing list|email list]].  NEMO is written in [[Python (programming language)|Python]].  NEMO itself is described in two publications.<ref name=\"elliston-etal-2012\"/>{{rp|sec{{nnbsp}}2}}<ref name=\"elliston-etal-2016\"/>{{rp|sec{{nnbsp}}2}}  The data sources are also noted.<ref name=\"elliston-etal-2012\"/>{{rp|sec{{nnbsp}}3}}  Optimizations are carried out using a single-objective evaluation function, with penalties.  The solution space of generator capacities is searched using the [[CMA-ES]] (covariance matrix adaptation evolution strategy) algorithm.  The timestep is arbitrary but one hour is normally employed.\n\nNEMO has been used to explore generation options for the year 2030 under a variety of renewable energy (RE) and abated fossil fuel technology scenarios.  A 2012 study investigates the feasibility of a fully renewable system using [[concentrated solar power]] (CSP) with thermal storage, [[Wind power|windfarms]], [[photovoltaics]], existing [[hydroelectricity]], and [[biofuel]]led [[gas turbine]]s.  A number of potential systems, which also meet NEM reliability criteria, are identified.  The principal challenge is servicing peak demand on winter evenings following overcast days and periods of low wind.<ref name=\"elliston-etal-2012\">\n{{cite journal\n | last1 = Elliston | first1 = Ben\n | last2 = Diesendorf | first2 = Mark\n | last3 = MacGill | first3 = Iain\n | title = Simulations of scenarios with 100% renewable electricity in the Australian National Electricity Market\n | date = June 2012\n | journal = Energy Policy\n | volume = 45\n | pages = 606–613\n | doi = 10.1016/j.enpol.2012.03.011\n | issn = 0301-4215\n | url = https://www.researchgate.net/publication/241756578_Simulations_of_scenarios_with_100_renewable_electricity_in_the_Australian_National_Electricity_Market\n | access-date = 2016-12-19\n}} Preprint URL given.  This paper does not mention NEMO explicitly.\n</ref>  A 2014 study investigates three scenarios using coal-fired thermal generation with [[carbon capture and storage]] (CCS) and gas-fired gas turbines with and without capture.  These scenarios are compared to the 2012 analysis using fully renewable generation.  The study finds that \"only under a few, and seemingly unlikely, combinations of costs can any of the fossil fuel scenarios compete economically with 100% renewable electricity in a carbon constrained world\".<ref name=\"elliston-etal-2014\">\n{{cite journal\n | last1 = Elliston | first1 = Ben\n | last2 = MacGill | first2 = Iain\n | last3 = Diesendorf | first3 = Mark\n | title = Comparing least cost scenarios for 100% renewable electricity with low emission fossil fuel scenarios in the Australian National Electricity Market\n | date = June 2014\n | journal = Renewable Energy\n | volume = 66\n | pages = 196–204\n | doi = 10.1016/j.renene.2013.12.010\n | issn = 0960-1481\n | url = http://images.smh.com.au/file/2013/09/04/4718532/coalpaper.pdf\n}} Draft URL given.\n</ref>{{rp|196}}  A 2016 study evaluates the incremental costs of increasing renewable energy shares under a range of greenhouse gas caps and carbon prices.  The study finds that incremental costs increase linearly from zero to 80% RE and then escalate moderately.  The study concludes that this cost escalation is not a sufficient reason to avoid renewables targets of 100%.<ref name=\"elliston-etal-2016\">\n<!-- alternative URL: http://www.sciencedirect.com/science/article/pii/S0960148116302646 -->\n{{cite journal\n | last1 = Elliston | first1 = Ben\n | last2 = Riesz | first2 = Jenny\n | last3 = MacGill | first3 = Iain\n | title = What cost for more renewables? The incremental cost of renewable generation — An Australian National Electricity Market case study\n | date = September 2016\n | journal = Renewable Energy\n | volume = 95\n | pages = 127–139\n | doi = 10.1016/j.renene.2016.03.080\n | issn = 0960-1481\n | url = http://ceem.unsw.edu.au/sites/default/files/documents/WhatCostMoreRenewables-preprint_0.pdf\n | access-date = 2016-12-03\n}} Preprint URL given.\n</ref>\n\n{{clear}}\n\n=== {{anchor|ONSSET}} OnSSET ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | OnSSET\n|-\n! Host\n| [[Royal Institute of Technology|KTH Royal Institute of Technology]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| cost-effective electrification\n|-\n! Code license\n| [[MIT License|MIT]]\n|-\n! Website\n| {{url|http://www.onsset.org}}\n|-\n! Forum\n| {{url|https://www.reddit.com/r/optimuscommunity/comments/8phv04/onsset_qa_2018/}}\n|-\n! Repository\n| {{url|https://github.com/KTH-dESA/PyOnSSET}}\n|-\n! Documentation\n| {{url|https://onsset-manual.readthedocs.io}}\n|-\n! Datasets\n| {{url|https://energydata.info}}\n|}\n\nOnSSET is the OpeN Source Spatial Electrification Toolkit.  OnSSET is being developed by the [https://www.kth.se/en/itm/inst/energiteknik/forskning/desa Energy Systems Analysis Group] (dESA), [[Royal Institute of Technology|KTH Royal Institute of Technology]], [[Stockholm]], Sweden.  The software is used to examine areas not served by grid-based electricity and identify the technology options and investment requirements that will provide least-cost access to electricity services.  OnSSET is designed to support the [[United Nations]]' [[Sustainable Development Goals|SDG{{nnbsp}}7]]: the provision of affordable, reliable, sustainable, and modern energy for all.  The [[Python (programming language)|Python]] implementation of the toolkit is known as PyOnSSET and was released on 26{{nbsp}}November 2016.  PyOnSSET does not ship with data, but suitable datasets are available from [[Open energy system databases#energydata.info|energydata.info]].  The project maintains a website and hosts a forum on [[Reddit]].<ref name=\"onsset-website\">\n{{cite web\n | title = OnSSET: open source spatial electrification tool\n | work = OnSSET\n | location = Stockholm, Sweden\n | url = http://www.onsset.org/\n | access-date = 2017-03-08\n}}\n</ref><ref name=\"kth-onsset\">\n{{cite web\n | title = OpeN Source Spatial Electrification Toolkit (OnSSET)\n | website = Department of Energy Technology, KTH Royal Institute of Technology\n | location = Stockholm, Sweden\n | url = https://www.kth.se/en/itm/inst/energiteknik/forskning/desa/projects/sustainable-energy-f/open-source-spatial-electrification-toolkit-onsset-1.663655\n | access-date = 2016-12-05\n}}\n</ref><ref name=\"mentis-etal-2015-presentation\">\n{{cite conference\n | last1 = Mentis | first1 = Dimitrios\n | last2 = Korkovelos | first2 = Alexandros\n | last3 = Shahid Siyal | first3 = Shahid\n | last4 = Paritosh | first4 = Deshpante\n | last5 = Broad | first5 = Oliver\n | last6 = Howells | first6 = Mark\n | last7 = Rogner | first7 = Holger\n | date = 13 November 2015\n | title = Lighting up the world: the first global application of the open source, spatial electrification tool (OnSSET) — Presentation\n | conference = 2015 International Workshop on Environment and Alternative Energy\n | url = http://presentations.copernicus.org/EGU2016-14161_presentation.pptx\n | access-date = 2017-03-07\n}}\n</ref>\n\n[[File:Least cost electricity mapping for tanzania from onsset model.png|thumb|left|A least-cost electrification mapping for Tanzania]]\n\nOnSSET can estimate, analyze, and visualize the most cost-effective electrification access options, be they [[Electrical grid|conventional grid]], mini-grid, or stand-alone.<ref name=\"nerini-etal-2016\">\n{{cite journal\n | last1 = Nerini | first1 = Francesco Fuso\n | last2 = Broad | first2 = Oliver\n | last3 = Mentis | first3 = Dimitris\n | last4 = Welsch | first4 = Manuel\n | last5 = Bazilian | first5 = Morgan\n | last6 = Howells | first6 = Mark\n | date = 15 January 2016\n | title = A cost comparison of technology approaches for improving access to electricity services\n | journal = Energy\n | volume = 95\n | pages = 255–265\n | doi = 10.1016/j.energy.2015.11.068\n | issn = 0360-5442\n}}\n</ref>  The toolkit supports a range of conventional and renewable energy technologies, including photovoltaics, wind turbines, and [[small hydro]] generation.  {{as of|2017}}, [[bioenergy]] and hybrid technologies, such as [[Wind hybrid power systems|wind-diesel]], are being added.\n\nOnSSET utilizes energy and geographic information, the latter may include settlement size and location, existing and planned transmission and generation infrastructure, economic activity, renewable energy resources, roading networks, and nighttime lighting needs.  The [[Geographic information system|GIS]] information can be supported using the proprietary [[ArcGIS]] package or an open source equivalent such as [[GRASS GIS|GRASS]] or [[QGIS]].<ref name=\"berndtsson-2016-msc\">\n{{cite thesis\n | last = Berndtsson | first = Carl\n | title = Open geospatial data for energy planning\n | type = MSc\n | date = 2016\n | publisher = KTH School of Industrial Engineering and Management\n | location = Stockholm, Sweden\n | url = http://www.diva-portal.org/smash/get/diva2:927179/FULLTEXT02\n | access-date = 2017-03-07\n}}\n</ref>\n\nOnSSET has been used for case studies in [[Afghanistan]],<ref name=\"korkovelos-etal-2017\">\n{{cite book\n | last1 = Korkovelos | first1 = Alexandros\n | last2 = Bazilian | first2 = Morgan\n | last3 = Mentis | first3 = Dimitrios\n | last4 = Howells | first4 = Mark\n | title = A GIS approach to planning electrification in Afghanistan\n | date = 2017\n | publisher = The World Bank\n | location = Washington DC, USA\n | url = https://kth.app.box.com/s/oj480x3a7qqeegw187pstfn100r7d7do\n | access-date = 2018-06-16\n}}\n</ref> [[Bolivia]],<ref name=\"arderne-2016-msc\">\n{{cite thesis\n | last = Arderne | first = Christopher\n | title = A climate, land-use, energy and water nexus assessment of Bolivia\n | type = MSc\n | date = June 2016\n | publisher = KTH School of Industrial Engineering and Management\n | location = Stockholm, Sweden\n | url = http://kth.diva-portal.org/smash/get/diva2:946272/FULLTEXT01.pdf\n | access-date = 2017-03-07\n}}\n</ref> [[Ethiopia]],<ref name=\"nerini-etal-2016\"/><ref name=\"mentis-etal-2016\">\n{{cite journal\n | last1 = Mentis | first1 = Dimitrios\n | last2 = Andersson | first2 = Magnus\n | last3 = Howells | first3 = Mark\n | last4 = Rogner | first4 = Holger\n | last5 = Siyal | first5 = Shahid\n | last6 = Broad | first6 = Oliver\n | last7 = Korkovelos | first7 = Alexandros\n | last8 = Bazilian | first8 = Morgan\n | date = July 2016\n | title = The benefits of geospatial planning in energy access: a case study on Ethiopia\n | journal = Applied Geography\n | volume = 72\n | pages = 1–13\n | doi = 10.1016/j.apgeog.2016.04.009\n | issn = 0143-6228\n}}\n</ref> [[Nigeria]],<ref name=\"nerini-etal-2016\"/><ref name=\"mentis-etal-2015\">\n{{cite journal\n | last1 = Mentis | first1 = Dimitrios\n | last2 = Welsch | first2 = Manuel\n | last3 = Fuso Nerini | first3 = Francesco\n | last4 = Broad | first4 = Oliver\n | last5 = Howells | first5 = Mark\n | last6 = Bazilian | first6 = Morgan\n | last7 = Rogner | first7 = Holger\n | date = December 2015\n | title = A GIS-based approach for electrification planning: a case study on Nigeria\n | journal = Energy for Sustainable Development\n | volume = 29\n | pages = 142–150\n | doi = 10.1016/j.esd.2015.09.007\n | issn = 0973-0826\n}}\n</ref> and [[Tanzania]].<ref name=\"berndtsson-2016-msc\"/>  OnSSET has also been applied in [[India]], [[Kenya]], and [[Zimbabwe]].  In addition, continental studies have been carried out for [[Sub-Saharan Africa]] and [[Latin America]].<ref name=\"desa-electrification-website\">\n{{cite web\n | title = Universal electrification access\n | work = United Nations Department of Economic and Social Affairs (UN DESA)\n | location = New York, USA\n | url = https://un-desa-modelling.github.io/electrification-paths-presentation/\n | access-date = 2017-03-09\n}}\n</ref>  {{as of|2017}}, there are plans to apply OnSSET in developing Asia, to increase the resolution of the analysis, and to extend support for various productive uses of electricity.\n\nOnSSET results have contributed to the [[International Energy Agency|IEA]] ''World Energy Outlook'' reports for 2014{{nnbsp}}<ref name=\"iea-weo-2014\">\n{{cite book\n | author = International Energy Agency\n | title = World Energy Outlook 2014\n | date = 2014\n | publisher = OECD/IEA\n | location = Paris, France\n | isbn = 978-92-64-20805-6\n | url = https://www.iea.org/publications/freepublications/publication/WEO2014.pdf\n | access-date = 2017-03-09\n}}\n</ref> and 2015{{nnbsp}}<ref name=\"iea-weo-2015\">\n{{cite book\n | author = International Energy Agency\n | title = World Energy Outlook 2015\n | date = 2015\n | publisher = OECD/IEA\n | location = Paris, France\n | isbn = 978-92-64-24366-8\n}}\n</ref> and the World Bank Global Tracking Framework report in 2015.<ref name=\"iea-world-bank-sustainable-energy-2015\">\n{{cite book\n | author = International Energy Agency (IEA) and the World Bank\n | title = Sustainable energy for all 2015: progress toward sustainable energy\n | date = June 2015\n | publisher = World Bank\n | location = Washington DC, USA\n | isbn = 978-1-4648-0690-2\n | doi = 10.1596/978-1-4648-0690-2\n | url = http://www.se4all.org/sites/default/files/GTF-2105-Full-Report.pdf\n | access-date = 2017-03-09\n}}  Licensed under Creative Commons {{nowrap|CC BY 3.0 IGO}}.\n</ref>\n\n{{clear}}\n\n=== pandapower ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | pandapower\n|-\n! Host\n| {{plainlist|\n* [[University of Kassel]]\n* Fraunhofer Institute IEE\n}}\n|-\n! Status\n| active\n|-\n! Scope/type\n| automated power system analysis\n|-\n! Code license\n| [[BSD-new]]\n|-\n! Website\n| {{url|http://www.pandapower.org}}\n|-\n! Repository\n| {{url|https://github.com/e2nIEE/pandapower}}\n|-\n! Python package\n| {{url|https://pypi.org/project/pandapower/}}\n|-\n! Documentation\n| {{url|https://pandapower.readthedocs.io}}\n|}\n\npandapower is a power system analysis and optimization program being jointly developed by the Energy Management and Power System Operation research group, [[University of Kassel]] and the Department for Distribution System Operation, [[Fraunhofer Institute]] for Energy Economics and Energy System Technology (IEE), both of [[Kassel]], Germany.  The codebase is hosted on [[GitHub]] and is also available as a [[Python Package Index|package]].  The project maintains a website, an [[Electronic mailing list|emailing list]], and online documentation.  pandapower is written in [[Python (programming language)|Python]].  It uses the [[pandas (software)|pandas]] library for data manipulation and analysis and the PYPOWER library{{nnbsp}}<ref name=\"pypower-website\">\n{{cite web\n | title = PYPOWER\n | website = Python Software Foundation\n | location =  Beaverton, OR, USA\n | url = https://pypi.python.org/pypi/PYPOWER\n | access-date = 2016-12-02\n}}\n</ref> to solve for [[Power-flow study|power flow]].  Unlike some open source power system tools, pandapower does not depend on proprietary platforms like [[MATLAB]].\n\npandapower supports the automated analysis and optimization of [[Electric power distribution|distribution]] and transmission networks.  This allows a large of number of scenarios to be explored, based on different future grid configurations and technologies.  pandapower offers a collection of power system elements, including: lines, 2-winding transformers, 3-winding transformers, and ward-equivalents.  It also contains a switch model that allows the modeling of ideal bus-bus switches as well as bus-line/bus-trafo switches.  The software supports topological searching.  The network itself can be plotted, with or without geographical information, using the [[matplotlib]] and [[plotly]] libraries.\n\nA 2016 publication evaluates the usefulness of the software by undertaking several case studies with major distribution system operators (DSO).  These studies examine the integration of increasing levels of [[photovoltaics]] into existing distribution grids.  The study concludes that being able to test a large number of detailed scenarios is essential for robust grid planning.  Notwithstanding, issues of data availability and problem dimensionality will continue to present challenges.<ref name=\"scheidler-etal-2016\">\n{{cite conference\n | first1 = Alexander | last1 = Scheidler\n | first2 = Leon | last2 = Thurner\n | first3 = Markus | last3 = Kraiczy\n | first4 = Martin | last4 = Braun\n | title = Automated grid planning for distribution grids with increasing PV penetration\n | date = 14–15 November 2016\n | conference = 6th Solar Integration Workshop: International Workshop on Integration of Solar Power into Power Systems\n | conference-url = http://solarintegrationworkshop.org/vienna2016/\n | location = Vienna, Austria\n | url = https://www.uni-kassel.de/eecs/fileadmin/datas/fb16/Fachgebiete/energiemanagement/Mitarbeitende/Scheidler__Thurner__Kraiczy__Braun_-_Automated_Grid_Planning_for_Distribution_Grids_with_Increasing_PV_Penetration.pdf\n | access-date = 2016-12-02\n}}\n</ref>\n\nA 2018 paper describes the package and its design and provides an example case study.  The article explains how users work with an element-based model (EBM) which is converted internally to a bus-branch model (BBM) for computation.  The package supports power system simulation, optimal power flow calculations (cost information is required), state estimation (should the system characterization lacks fidelity), and [[graph theory|graph]]-based network analysis.  The case study shows how a few tens of lines of scripting can interface with pandapower to advance the design of a system subject to diverse operating requirements.  The associated code is hosted on GitHub as [[Project Jupyter|jupyter notebooks]].<ref name=\"thurner-etal-2018\">\n{{cite journal\n | last1 = Thurner | first1 = Leon\n | last2 = Scheidler | first2 = Alexander\n | last3 = Schäfer | first3 = Florian\n | last4 = Menke | first4 = Jan-Hendrik\n | last5 = Dollichon | first5 = Julian\n | last6 = Meier | first6 = Friederike\n | last7 = Meinecke | first7 = Steffen\n | last8 = Braun | first8 = Martin\n | title = Pandapower: an open source python tool for convenient modeling, analysis and optimization of electric power systems\n | date = 2018\n | journal = IEEE Transactions on Power Systems\n | volume =\n | issue =\n | pages =\n | doi = 10.1109/TPWRS.2018.2829021\n | issn = 0885-8950\n | url = https://arxiv.org/pdf/1709.06743\n | access-date = 2018-05-04\n}}  The arXiv link given is for version{{nbsp}}3.\n</ref>\n\n{{as of|2018}}, [[Federal Network Agency|BNetzA]], the German network regulator, is using pandapower for automated grid analysis.<ref name=\"thurner-2018\">\n{{cite mailing list\n | last1 = Thurner | first1 = Leon\n | title = pandapower news: reference paper published / unbalanced calculations / BNetzA adopts pandapower\n | date = 4 May 2018\n | mailing-list = openmod-initiative\n | url = https://groups.google.com/forum/#!topic/openmod-initiative/FYDJXndCZ98\n | access-date = 2018-05-04\n | quote = We are especially proud to say that the German Federal Network Agency (Bundesnetzagentur) is also adopting pandapower for automated grid analysis.\n}}\n</ref>  Energy research institutes in Germany are also following the development of pandapower.<ref name=\"degner-etal-2017\">\n{{cite book\n | last1 = Degner | first1 = Thomas\n | last2 = Rohrig | first2 = Kurt\n | last3 = Strauß | first3 = Philipp\n | last4 = Braun | first4 = Martin\n | last5 = Wurdinger | first5 = Kerstin\n | last6 = Korte | first6 = Klaas\n | title = Forschung für die Energiewende – Die Gestaltung des Energiesystems Beiträge zur FVEE-Jahrestagung 2016\n | trans-title = Research for the energiewende — the design of the energy system contributions to the FVEE Annual Conference 2016\n | language = German\n | date = 22 March 2017\n | chapter = Anforderungen an ein zukunftsfähiges Stromnetz\n | trans-chapter = Requirements for a sustainable power grid\n | pages = 88–95\n | publisher = Forschungsverbund Erneuerbare Energien (FVEE)\n | location = Berlin, Germany\n | url = http://www.fvee.de/fileadmin/publikationen/Themenhefte/th2016/th2016.pdf\n | access-date = 2018-05-04\n}}\n</ref>{{rp|90}}\n\n{{clear}}\n\n=== PowerMatcher ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | PowerMatcher\n|-\n! Host\n| [http://flexible-energy.eu/ Flexiblepower Alliance Network]\n|-\n! Status\n| active\n|-\n! Scope/type\n| smart grid\n|-\n! Code license\n| [[Apache License|Apache 2.0]]\n|-\n! Website\n| {{url|https://flexiblepower.github.io}}\n|-\n! Repository\n| {{url|https://github.com/flexiblepower/powermatcher}}\n|}\n\nThe PowerMatcher software implements a [[smart grid]] coordination mechanism which balances [[Distributed generation|distributed energy resources]] (DER) and flexible loads through autonomous [[bidding]].  The project is managed by the Flexiblepower Alliance Network (FAN) in [[Amsterdam]], the Netherlands.  The project maintains a website and the [[source code]] is hosted on [[GitHub]].  {{as of|2016|06}}, existing datasets are not available.  PowerMatcher is written in [[Java (programming language)|Java]].\n\nEach device in the smart grid system – whether a washing machine, a wind generator, or an industrial turbine – expresses its willingness to consume or produce electricity in the form of a bid.  These bids are then collected and used to determine an equilibrium price.  The PowerMatcher software thereby allows high shares of renewable energy to be integrated into existing electricity systems and should also avoid any local overloading in possibly aging distribution networks.<ref name=\"kok-2013\">\n{{cite thesis\n | first = Koen | last = Kok\n | title = The PowerMatcher: smart coordination for the smart electricity grid\n | type = PhD\n | date = 13 May 2013\n | publisher = [[Vrije Universiteit Amsterdam]]\n | location = Amsterdam, The Netherlands\n | url = http://dare.ubvu.vu.nl/bitstream/handle/1871/43567/dissertation.pdf\n | access-date = 2016-07-08\n}}\n</ref>\n\n{{clear}}\n\n=== renpass ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | renpass\n|-\n! Host\n| [[University of Flensburg]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| renewables pathways\n|-\n! Code license\n| [[GNU General Public License|GPLv3]]\n|-\n! Website\n| {{url|https://github.com/fraukewiese/renpass}}\n<!-- alternative: {{https://www.uni-flensburg.de/index.php?id=18227}} -->\n|}\n\nrenpass is an acronym for Renewable Energy Pathways Simulation System.  renpass is a simulation electricity model with high regional and temporal resolution, designed to capture existing systems and future systems with up to 100% renewable generation.  The software is being developed by the [http://www.znes-flensburg.de/index.php?id=165&L=1 Centre for Sustainable Energy Systems] (CSES or ZNES), [[University of Flensburg]], Germany.  The project runs a website, from where the [[codebase]] can be download.  renpass is written in [[R (programming language)|R]] and links to a [[MySQL]] database.  A PDF manual is available.<ref name=\"wiese-2014\">\n{{cite book\n | first = Frauke | last = Wiese\n | title = renpass: Renewable Energy Pathways Simulation System — Manual\n | date = 16 November 2014\n | url = https://github.com/fraukewiese/renpass/blob/master/docs/manual_renpass_11_2014.pdf\n | access-date = 2017-03-13\n}}\n</ref>  renpass is also described in a PhD thesis.<ref name=\"wiese-2015\">\n<!-- alternative url: http://www.coastdat.de/imperia/md/content/coastdat/publications/dissertation_frauke_wiese_april2015_digitalversion.pdf -->\n{{cite thesis\n | first = Frauke | last = Wiese\n | title = renpass: Renewable Energy Pathways Simulation System: Open source as an approach to meet challenges in energy modeling\n | type = PhD\n | year = 2015\n | publisher = Shaker Verlag\n | location = Aachen, Germany\n | isbn = 978-3-8440-3705-0\n | url = http://www.reiner-lemoine-stiftung.de/pdf/dissertationen/Dissertation_Frauke_Wiese.pdf\n | access-date = 2016-07-12\n}} University of Flensburg, Flensburg, Germany.\n</ref>  {{as of|2015}}, renpass is being extended as renpassG!S, based on [[#oemof|oemof]].\n\nrenpass is an electricity dispatch model which minimizes system costs for each time step (optimization) within the limits of a given infrastructure (simulation).  Time steps are optionally 15 minutes or one hour.  The method assumes perfect foresight.  renpass supports the electricity systems found in Austria, Belgium, the Czech Republic, Denmark, Estonia, France, Finland, Germany, Latvia, Lithuania, Luxembourg, the Netherlands, Norway, Poland, Sweden, and Switzerland.\n\nThe optimization problem for each time step is to minimize the electricity supply cost using the existing power plant fleet for all regions.  After this regional dispatch, the exchange between the regions is carried out and is restricted by the grid capacity.  This latter problem is solved with a heuristic procedure rather than calculated deterministically.  The input is the merit order, the marginal power plant, the excess energy (renewable energy that could be curtailed), and the excess demand (the demand that cannot be supplied) for each region.  The exchange algorithm seeks the least cost for all regions, thus the target function is to minimize the total costs of all regions, given the existing grid infrastructure, storage, and generating capacities.  The total cost is defined as the residual load multiplied by the price in each region, summed over all regions.\n\nA 2012 study uses renpass to examine the feasibility of a 100% renewable electricity system for the [[Baltic Sea]] region (Denmark, Estonia, Finland, Germany, Latvia, Lithuania, Poland, and Sweden) in the year 2050.  The base scenario presumes conservative renewable potentials and grid enhancements, a 20% drop in demand, a moderate uptake of storage options, and the deployment of biomass for flexible generation.  The study finds that a 100% renewable electricity system is possible, albeit with occasional imports from abutting countries, and that biomass plays a key role in system stability.  The costs for this transition are estimated at 50{{nbsp}}€/MWh.<ref name=\"bernhardi-etal-2012\">\n{{cite book\n | last1 = Bernhardi | first1 = Nicolas\n | last2 = Bökenkamp | first2 = Gesine\n | last3 = Bons | first3 = Marian\n | last4 = Borrmann | first4 = Rasmus\n | last5 = Christ | first5 = Marion\n | last6 = Grüterich | first6 = Lauren\n | last7 = Heidtmann | first7 = Emilie\n | last8 = Jahn | first8 = Martin\n | last9 = Janssen | first9 = Tomke\n | last10 = Lesch | first10 = Jonas\n | last11 = Müller | first11 = Ulf Philipp\n | last12 = Pelda | first12 = Johannes\n | last13 = Stein | first13 = Isabelle\n | last14 = Veddeler | first14 = Eike\n | last15 = Voß | first15 = David\n | last16 = Wienholt | first16 = Lukas\n | last17 = Wiese | first17 = Frauke\n | last18 = Wingenbach | first18 = Clemens\n | title = Modeling sustainable electricity systems for the Baltic Sea region — Discussion paper 3\n | date = November 2012\n | publisher = Centre for Sustainable Energy Systems (CSES), University of Flensburg\n | location = Flensburg, Germany\n | issn = 2192-4597\n | url = http://www.znes.fh-flensburg.de/fileadmin/templates/multiflex4/Downloads/Reports/Sustainable_electricity_System_Baltic_Region.pdf\n | access-date = 2016-06-17\n}}\n</ref>  A 2014 study uses renpass to model Germany and its neighbors.<ref name=\"wiechers-etal-2014\">\n{{cite book\n | first1 = Eva | last1 = Wiechers\n | first2 = Hendrik | last2 = Böhm\n | first3 = Wolf Dieter | last3 = Bunke\n | first4 = Cord | last4 = Kaldemeyer\n | first5 = Tim | last5 = Kummerfeld\n | first6 = Martin | last6 = Söthe\n | first7 = Henning | last7 = Thiesen\n | title = Modelling sustainable electricity systems for Germany and neighbours in 2050\n | year = 2014\n | publisher = Centre for Sustainable Energy Systems (CSES), University of Flensburg\n | location = Flensburg, Germany \n}}\n</ref>  A 2014 thesis uses renpass to examine the benefits of both a new cable between Germany and Norway and new [[Pumped-storage hydroelectricity|pumped storage]] capacity in [[Norway]], given 100% renewable electricity systems in both countries.<ref name=\"boekenkamp-2014\">\n{{cite thesis\n | last = Bökenkamp | first = Gesine\n | date = October 2014\n | title = The role of Norwegian hydro storage in future renewable electricity supply systems in Germany: analysis with a simulation model\n | type = PhD\n | publisher = University of Flensburg\n | location = Flensburg, German\n | url = https://www.zhb-flensburg.de/fileadmin/content/spezial-einrichtungen/zhb/dokumente/dissertationen/boekenkamp/dissertation-boekenkamp.pdf\n | access-date = 2016-07-12\n}}\n</ref>  Another 2014 study uses renpass to examine the German ''[[Energiewende]]'', the transition to a sustainable energy system for Germany.  The study also argues that the public trust needed to underpin such a transition can only be built through the use of transparent open source energy models.<ref name=\"wiese-etal-2014\">\n{{cite journal\n | last1 = Wiese | first1 = Frauke\n | last2 = Bökenkamp | first2 = Gesine\n | last3 = Wingenbach | first3 = Clemens\n | last4 = Hohmeyer | first4 = Olav\n | title = An open source energy system simulation model as an instrument for public participation in the development of strategies for a sustainable future\n | year = 2014\n | journal = Wiley Interdisciplinary Reviews: Energy and Environment\n | volume = 3\n | number = 5\n | pages = 490–504\n | issn = 2041-840X\n | doi = 10.1002/wene.109\n}}\n</ref>\n\n{{clear}}\n\n=== SciGRID ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | SciGRID\n|-\n! Host\n| [[Deutsches Zentrum für Luft- und Raumfahrt]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| European transmission grid\n|-\n! Code license\n| [[Apache License|Apache 2.0]]\n|-\n! Website\n| {{url|http://www.scigrid.de}}\n|}\n\nSciGRID, short for Scientific Grid, is an open source model of the German and European [[Electric power transmission|electricity transmission networks]].  The research project is managed by [[German Aerospace Center|DLR]] [https://www.dlr.de/ve/en/ Institute of Networked Energy Systems] located in [[Oldenburg (Oldenburg)|Oldenburg]], Germany.  The project maintains a website and an email newsletter.  SciGRID is written in [[Python (programming language)|Python]] and uses a [[PostgreSQL]] database.  The first release (v0.1) was made on 15{{nbsp}}June 2015.\n\nSciGRID aims to rectify the lack of open research data on the structure of electricity transmission networks within Europe.  This lack of data frustrates attempts to build, characterise, and compare high resolution energy system models.  SciGRID utilizes transmission network data available from the [[OpenStreetMap]] project, available under the [[Open Database License]] (ODbL), to automatically author transmission connections.  SciGRID will not use data from closed sources.  SciGRID can also mathematically decompose a given network into a simpler representation for use in energy models.<ref name=\"matke-etal-2015\">\n{{cite conference\n | first1 = Carsten | last1 = Matke\n | first2 = Wided | last2 = Medjroubi\n | first3 = David | last3 = Kleinhans\n | title = SciGRID: an open source model of the European power transmission network — Poster\n | year = 2015\n | conference = Mathematics and Physics of Multilayer Complex Networks\n | location = Dresden, Germany\n | url = http://www.scigrid.de/publications/15_dresden_poster.pdf\n | access-date = 2016-07-08\n}}</ref><ref name=\"wiegmans-2015\">\n{{cite book\n | last = Wiegmans | first = Bart\n | title = Improving the topology of an electric network model based on Open Data\n | type = MSc\n | year = 2015\n | publisher = Energy and Sustainability Research Institute, [[University of Groningen]]\n | location = Groningen, The Netherlands\n | url = http://www.scigrid.de/publications/16_1_BWiegmans_Master_Thesis_2015.pdf\n | access-date = 2016-07-08\n}}\n</ref>\n\nA related project is [https://github.com/bdw/GridKit GridKit], released under an [[MIT license]].  GridKit is being developed to investigate the possibility of a 'heuristic' analysis to augment the route-based analysis used in SciGRID.  Data is available for network models of the European and North-American high-voltage electricity grids.<ref name=\"wiegmans-47317\">\n{{cite journal\n | last = Wiegmans | first = Bart\n | title = GridKit: European and North-American extracts\n | journal = Zenodo\n | doi = 10.5281/zenodo.47317\n | url = https://zenodo.org/record/47317\n | access-date = 2016-12-06\n}}\n</ref>\n\n{{clear}}\n\n=== SIREN ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | SIREN\n|-\n! Host\n| [http://www.sen.asn.au/ Sustainable Energy Now]\n|-\n! Status\n| active\n|-\n! Scope/type\n| renewable generation\n|-\n! Code license\n| [[Affero General Public License|AGPLv3]]\n|-\n! Website\n| {{url|http://www.sen.asn.au/modelling_overview}}\n|-\n! Repository\n| {{url|https://sourceforge.net/projects/sensiren/}}\n|}\n\nSIREN stands for SEN Integrated Renewable Energy Network Toolkit.  The project is run by Sustainable Energy Now, an [[Non-governmental organization|NGO]] based in [[Perth]], Australia.  The project maintains a website.  SIREN runs on Windows and the [[source code]] is hosted on [[SourceForge]].  The software is written in [[Python (computer language)|Python]] and uses the SAM model (System Advisor Model) from the US [[National Renewable Energy Laboratory]] to perform energy calculations.  SIREN uses hourly datasets to model a given geographic region.  Users can use the software to explore the location and scale of renewable energy sources to meet a specified electricity demand.  SIREN utilizes a number of open or publicly available data sources: maps can be created from [[OpenStreetMap]] tiles and weather datasets can be created using [[NASA]] MERRA-2 satellite data.{{efn|name=merra-2|\nMERRA-2 stands for Modern-Era Retrospective analysis for Research and Applications, Version 2.  The [[Remote sensing|remote-sensed]] data is provided unencumbered by the [[NASA]] [[Goddard Space Flight Center]] research laboratory.\n}}<ref name=\"bosilovich-etal-2016\">\n{{cite book\n | first1 = Michael G | last1 = Bosilovich\n | first2 = Rob | last2 = Lucches\n | first3 = M | last3 = Suarez\n | title = MERRA-2: File specification — GMAO Office Note No. 9 (Version 1.1)\n | date = 12 March 2016\n | publisher = Global Modeling and Assimilation Office (GMAO), Earth Sciences Division, NASA Goddard Space Flight Center\n | location = Greenbelt, Maryland, USA\n | url = https://gmao.gsfc.nasa.gov/pubs/docs/Bosilovich785.pdf\n | access-date = 2016-07-08\n}}\n</ref>\n\nA 2016 study using SIREN to analyze Western Australia's South-West Interconnected System (SWIS) finds that it can transition to 85% renewable energy (RE) for the same cost as new coal and gas.  In addition, 11.1{{nbsp}}million tonnes of {{CO2}}eq emissions would be avoided.  The modeling assumes a carbon price of [[Australian dollar|AUD]]{{nbsp}}$30/t{{CO2}}.  Further scenarios examine the goal of 100% renewable generation.<ref name=\"rose-2016\">\n{{cite book\n | first = Ben | last = Rose\n | title = Clean electricity Western Australia 2030: modelling renewable energy scenarios for the South West Integrated System\n | date = April 2016\n | publisher = Sustainable Energy Now\n | location = West Perth, WA, Australia\n | url = https://d3n8a8pro7vhmx.cloudfront.net/sen/pages/134/attachments/original/1464007346/RE_Scenarios_for_SWIS_2030_Study_-_April_2016_BR.pdf\n | access-date = 2017-12-05\n}}\n</ref>\n\n{{clear}}\n\n=== SWITCH ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | SWITCH\n|-\n! Host\n| [[University of Hawai'i]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| optimal planning\n|-\n! Code license\n| [[Apache License|Apache 2.0]]\n|-\n! Website\n| {{url|http://switch-model.org}}\n|-\n! Repository\n| {{url|https://github.com/switch-model}}\n|}\n\nSWITCH is a loose acronym for solar, wind, conventional and hydroelectric generation, and transmission.  SWITCH is an optimal planning model for power systems with large shares of renewable energy.  SWITCH is being developed by the Department of Electrical Engineering, [[University of Hawai'i]], [[Mānoa]], [[Hawaii]], USA.  The project runs a small website and hosts its [[codebase]] and [[Data (computing)|datasets]] on [[GitHub]].  SWITCH is written in [[Pyomo]], an optimization components library programmed in [[Python (programming language)|Python]].  It can use either the open source [[GLPK]] solver or the commercial [[CPLEX]] and [[Gurobi]] solvers.\n\nSWITCH is a power system model, focused on renewables integration.  It can identify which generator and transmission projects to build in order to satisfy electricity demand at the lowest cost over a several year period while also reducing {{CO2}} emissions.  SWITCH utilizes multi-stage [[Stochastic linear program|stochastic linear optimization]] with the objective of minimizing the present value of the cost of power plants, transmission capacity, fuel usage, and an arbitrary per-tonne {{CO2}} charge (to represent either a carbon tax or a certificate price), over the course of a multi-year investment period.  It has two major sets of decision variables.  First, at the start of each investment period, SWITCH selects how much generation capacity to build in each of several geographic load zones, how much power transfer capability to add between these zones, and whether to operate existing generation capacity during the investment period or to temporarily mothball it to avoid fixed operation and maintenance costs.  Second, for a set of sample days within each investment period, SWITCH makes hourly decisions about how much power to generate from each dispatchable power plant, store at each [[Pumped-storage hydroelectricity|pumped hydro]] facility, or transfer along each transmission interconnector.  The system must also ensure enough generation and transmission capacity to provide a planning reserve margin of 15% above the load forecasts.  For each sampled hour, SWITCH uses electricity demand and renewable power production based on actual measurements, so that the weather-driven correlations between these elements remain intact.\n\nFollowing the optimization phase, SWITCH is used in a second phase to test the proposed investment plan against a more complete set of weather conditions and to add backstop generation capacity so that the planning reserve margin is always met.  Finally, in a third phase, the costs are calculated by freezing the investment plan and operating the proposed power system over a full set of weather conditions.\n\nA 2012 paper uses [[California]] from 2012 to 2027 as a [[case study]] for SWITCH.  The study finds that there is no ceiling on the amount of wind and solar power that could be used and that these resources could potentially reduce emissions by 90% or more (relative to 1990 levels) without reducing reliability or severely raising costs.  Furthermore, policies that encourage electricity customers to shift demand to times when renewable power is most abundant (for example, though the well-timed charging of [[electric vehicle]]s) could achieve radical emission reductions at moderate cost.<ref name=\"fripp-2012\">\n<!-- alternative URL: https://www.academia.edu/download/21117660/Switch_Calif_paper_and_supp_info.pdf -->\n{{cite journal\n | last = Fripp | first = Matthius\n | date = 2012\n | title = Switch: a planning tool for power systems with large shares of intermittent renewable energy\n | journal = Environmental Science and Technology\n | volume = 46\n | number = 11\n | pages = 6371–6378\n | doi = 10.1021/es204645c\n | issn = 0013-936X\n | url = http://www2.hawaii.edu/~mfripp/papers/Fripp_2012_Switch_Calif_Renewables.pdf\n | access-date = 2016-07-11\n| bibcode = 2012EnST...46.6371F\n }}\n</ref>\n\nSWITCH was used more recently to underpin consensus-based power system planning in [[Hawaii]].<ref name=\"fripp-2016\">\n{{cite book\n | last1 = Fripp | first1 = Matthias\n | title = Consensus-based power system planning using open assumptions and models — Presentation\n | date = 29 June 2016\n | publisher = University of Hawaii\n | location = Manoa, Hawaii, USA\n | url = http://ee.hawaii.edu/~mfripp/talks/Fripp_2016-06-29_HECO_Consensus.pdf\n | access-date = 2019-01-31\n}}\n</ref>  The model is also being applied in [[Chile]], [[Mexico]], and elsewhere.<ref name=\"johnston-etal-2018\"/>\n\nMajor version{{nbsp}}2.0 was released in late{{nbhyph}}2018.<ref name=\"johnston-etal-2018\">\n{{cite journal\n | last1 = Johnston | first1 = Josiah\n | last2 = Henríquez | first2 = Rodrigo\n | last3 = Maluenda | first3 = Benjamín\n | last4 = Fripp | first4 = Matthias\n | title = Switch 2.0: a modern platform for planning high-renewable power systems\n | date = 17 October 2018\n | journal =\n | volume =\n | issue =\n | pages =\n | arxiv = 1804.05481\n | doi =\n | issn =\n | url = http://arxiv.org/pdf/1804.05481\n | access-date = 2019-02-01\n}}  arXiv preprint v3.  The release date for 2.0.0 was 1{{nbsp}}August 2018 under GitHub commit fc19cfe.\n</ref>  An investigation that year favorably compared SWITCH with the proprietary [[General Electric]] MAPS model using Hawaii as a case study.<ref name=\"fripp-2018\">\n{{cite journal\n | last1 = Fripp | first1 = Matthias\n | title = Intercomparison between Switch 2.0 and GE MAPS models for simulation of high-renewable power systems in Hawaii\n | date = 27 December 2018\n | journal = Energy, Sustainability and Society\n | volume = 8\n | issue = 1\n | pages = 41\n | doi = 10.1186/s13705-018-0184-x\n | issn = 2192-0567\n | url = https://energsustainsoc.biomedcentral.com/track/pdf/10.1186/s13705-018-0184-x\n | access-date = 2019-02-01\n}}  {{open access}}\n</ref>\n\n{{clear}}\n\n=== URBS ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | URBS\n|-\n! Host\n| [[Technical University of Munich]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| distributed energy systems\n|-\n! Code license\n| [[GNU General Public License|GPLv3]]\n|-\n! Repository\n| {{url|https://github.com/tum-ens/urbs}}\n|}\n\nURBS, [[Latin]] for city, is a [[linear programming]] model for exploring capacity expansion and unit commitment problems and is particularly suited to [[Distributed generation|distributed energy systems]] (DES).  It is being developed by the [https://www.ens.ei.tum.de/en/ Institute for Renewable and Sustainable Energy Systems], [[Technical University of Munich]], Germany.  The [[codebase]] is hosted on [[GitHub]].  URBS is written in [[Python (programming language)|Python]] and uses the [[Pyomo]] optimization packages.\n\nURBS classes as an energy modeling framework and attempts to minimize the total discounted cost of the system.  A particular model selects from a set of technologies to meet a predetermined electricity demand.  It uses a time resolution of one hour and the spatial resolution is model-defined.  The decision variables are the capacities for the production, storage, and transport of electricity and the time scheduling for their operation.<ref name=\"huber-etal-2012\">\n{{cite book\n | first1 = Matthias | last1 = Huber\n | first2 = Johannes | last2 = Dorfner\n | first3 = Thomas | last3 = Hamacher\n | title = Electricity system optimization in the EUMENA region — Technical report\n | date = 18 January 2012\n | publisher = Institute for Energy Economy and Application Technology, Technical University of Munich\n | location = Munich, Germany\n | doi = 10.14459/2013md1171502\n | url = https://mediatum.ub.tum.de/doc/1171502/1171502.pdf\n | access-date = 2016-07-07\n}}\n</ref>{{rp|11–14}}\n\nThe software has been used to explore cost-optimal extensions to the European [[Electric power transmission|transmission grid]] using projected wind and solar capacities for 2020.  A 2012 study, using high spatial and technological resolutions, found [[variable renewable energy]] (VRE) additions cause lower revenues for conventional power plants and that grid extensions redistribute and alleviate this effect.<ref name=\"schaber-etal-2012\">\n{{cite journal\n | first1 = Katrin | last1 = Schaber\n | first2 = Florian | last2 = Steinke\n | first3 = Thomas | last3 = Hamacher\n | title = Transmission grid extensions for the integration of variable renewable energies in Europe: who benefits where?\n | date = April 2012\n | journal = Energy Policy\n | volume = 43\n | pages = 123–135\n | doi = 10.1016/j.enpol.2011.12.040\n}}\n</ref>  The software has also been used to explore energy systems spanning Europe, the Middle East, and North Africa (EUMENA)<ref name=\"huber-etal-2012\"/> and Indonesia, Malaysia, and Singapore.<ref name=\"stich-etal-2014\">\n{{cite conference\n | first1 = Juergen | last1 = Stich\n | first2 = Melanie | last2 = Mannhart\n | first3 = Thomas | last3 = Zipperle\n | first4 = Tobias | last4 = Massier\n | first5 = Matthias | last5 = Huber\n | first6 = Thomas | last6 = Hamacher\n | title = Modelling a low-carbon power system for Indonesia, Malaysia and Singapore\n | year = 2014\n | conference = 33rd IEW International Energy Workshop, Peking, China\n | url = https://mediatum.ub.tum.de/doc/1233948/1233948.pdf\n | access-date = 2016-07-07\n}}\n</ref>\n\n{{clear}}\n\n== Open energy system models ==\n\nOpen energy system models capture some or all of the energy commodities found in an energy system.  All models include the electricity sector.  Some models add the heat sector, which can be important for countries with significant [[district heating]].  Other models add gas networks.  With the advent of [[Electric vehicle|emobility]], other models still include aspects of the transport sector.  Indeed, coupling these various sectors using [[power-to-X]] technologies is an emerging area of research.<ref name=\"bussar-etal-2014\"/>\n\n{| class=\"wikitable sortable\"\n|+ {{anchor|table-open-energy-system-models}} Open energy system models <span style=\"font-weight: normal\">(bottom-up, with support for heat, gas, and such, as well as electricity)</span>\n|-\n! Project\n! Host\n! License\n! Access\n! Coding\n! Documentation\n! Scope/type\n|-\n| [[#Balmorel|Balmorel]]\n| Denmark\n| [[ISC license|ISC]]\n| registration\n| [[General Algebraic Modeling System|GAMS]]\n| manual\n| energy markets\n|-\n| [[#Calliope|Calliope]]\n| [[ETH Zurich]]\n| [[Apache License|Apache 2.0]]\n| download\n| [[Python (programming language)|Python]]\n| manual, website, list\n| dispatch and investment\n|-\n| [[#DESSTinEE|DESSTinEE]]\n| [[Imperial College London]]\n| [[Creative Commons license|{{nowrap|CC BY-SA 3.0}}]]\n| download\n| [[Microsoft Excel|Excel]]/[[Visual Basic for Applications|VBA]]\n| website\n| simulation\n|-\n| [[#Energy Transition Model|Energy Transition Model]]\n| Quintel Intelligence\n| [[MIT license|MIT]]\n| [[GitHub]]\n| [[Ruby (programming language)|Ruby]] (on [[Ruby on Rails|Rails]])\n| website\n| web-based\n|-\n| [[#EnergyPATHWAYS|EnergyPATHWAYS]]\n| Evolved Energy Research\n| [[MIT license|MIT]]\n| [[GitHub]]\n| [[Python (computer language)|Python]]\n| website\n| mostly simulation\n|-\n| [[#ETEM|ETEM]]\n| ORDECSYS, Switzerland\n| [[Eclipse Public License|Eclipse 1.0]]\n| registration\n| [[MathProg]]\n| manual\n| municipal\n|-\n| [[#ficus|ficus]]\n| [[Technical University of Munich]]\n| [[GNU General Public License|GPLv3]]\n| [[GitHub]]\n| [[Python (programming language)|Python]]\n| manual\n| local electricity and heat\n|-\n| [[#oemof|oemof]]\n| oemof community supported by {{plainlist|\n* Reiner Lemoine Institute\n* [[University of Flensburg]]\n* [[Fachhochschule Flensburg|Flensburg University of Applied Sciences]]\n}}\n| [[GNU General Public License|GPLv3]]\n| [[GitHub]]\n| [[Python (programming language)|Python]]\n| website\n| framework - dispatch, investment, all sectors, LP/MILP\n|-\n| [[#OSeMOSYS|OSeMOSYS]]\n| OSeMOSYS community\n| [[Apache License|Apache 2.0]]\n| [[GitHub]]\n| {{plainlist|\n* [[General Algebraic Modeling System|GAMS]]\n* [[MathProg]]\n* [[Python (programming language)|Python]]\n}}\n| website, forum\n| planning at all scales\n|-\n| [[#PyPSA|PyPSA]]\n| [[Goethe University Frankfurt]]\n| [[GNU General Public License|GPLv3]]\n| [[GitHub]]\n| [[Python (programming language)|Python]]\n| website\n| electric power systems with [[sector coupling]]\n|-\n| [[#TEMOA|TEMOA]]\n| [[North Carolina State University]]\n| [[GNU General Public License|GPLv2+]]\n| [[GitHub]]\n| [[Python (programming language)|Python]]\n| website, forum\n| system planning\n|- class=\"sortbottom\"\n| colspan=\"7\" style=\"font-size: smaller\" | {{plainlist|\n* '''Access''' refers to the methods offered for accessing the codebase.\n}}\n|}\n\n=== Balmorel ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | Balmorel\n|-\n! Host\n| stand-alone from Denmark\n|-\n! Status\n| active\n|-\n! Scope/type\n| energy markets\n|-\n! Code license\n| [[ISC license|ISC]]\n|-\n! Website\n| {{url|http://www.balmorel.com/}}\n<!-- alternative URL: http://eabalmorel.dk/ -->\n|}\n\nBalmorel is a market-based energy system model from Denmark.  Development was originally financed by the Danish Energy Research Program in 2001.<ref name=\"wiese-2015\"/>{{rp|23}}  The codebase was made public in March 2001.<ref>Personal email from Hans Ravn dated 11{{nbsp}}December 2016.  This makes Balmorel the first open energy modeling project to go public by quite a margin.</ref>  The Balmorel project maintains an extensive website, from where the [[codebase]] and [[Data (computing)|dataset]]s can be download as a [[Zip (file format)|zip file]].  Users are encouraged to register.  Documentation is available from the same site.<ref name=\"ravn-2001\">\n{{cite book\n | first = Hans F | last = Ravn\n | title = The Balmorel model: theoretical background\n | date = March 2001\n | publisher = Balmorel Project\n | url = http://www.eabalmorel.dk/files/download/The%20Balmorel%20Mode%20Theoretical%20Background.pdf\n | access-date = 2016-07-12\n}}</ref><ref name=\"ravn-2012\">\n{{cite book\n | first = Hans F | last = Ravn\n | title = The Balmorel model structure — Version 3.02 (September 2011)\n | date = 2 July 2012\n | publisher = Balmorel Project\n | url = http://www.eabalmorel.dk/files/download/TheBalmorelModelStructure-BMS302.pdf\n | access-date = 2016-07-12\n}}</ref><ref name=\"grohnheit-and-larsen-2001\">\n{{cite book\n | first = Poul Erik | last1 = Grohnheit\n | first2 = Helge V | last2 = Larsen\n | title = Balmorel: data and calibration — Version 2.05\n | date = March 2001\n | publisher = Balmorel Project\n | url = http://www.eabalmorel.dk/files/download/Balmorel%20Data%20and%20Calibration%20Version%202.05.pdf\n | access-date = 2016-07-12\n}}\n</ref>  Balmorel is written in [[General Algebraic Modeling System|GAMS]].\n\nThe original aim of the Balmorel project was to construct a [[partial equilibrium]] model of the electricity and [[Cogeneration|CHP]] sectors in the [[Baltic Sea]] region, for the purposes of policy analysis.<ref name=\"ravn-etal-2001\">\n{{cite book\n | first1 = Hans F | last1 = Ravn\n | display-authors = etal\n | title = Balmorel: a model for analyses of the electricity and CHP markets in the Baltic Sea region\n | year = 2001\n | publisher = Balmorel Project\n | location = Denmark\n | isbn = 87-986969-3-9\n | url = http://www.eabalmorel.dk/files/download/Balmorel%20A%20Model%20for%20Analyses%20of%20the%20Electricity%20and%20CHP%20Markets%20in%20the%20Baltic%20Sea%20Region.pdf\n | access-date = 2016-07-12\n}}\n</ref>  These ambitions and limitations have long since been superseded and Balmorel is no longer tied to its original geography and policy questions.<ref name=\"ravn-2012\"/>  Balmorel classes as a dispatch and investment model and uses a time resolution of one hour.  It models electricity and heat supply and demand, and supports the intertemporal storage of both.  Balmorel is structured as a pure [[linear programming|linear program]] (no integer variables).\n\n{{as of|2016}}, Balmorel has been the subject of some 22{{nbsp}}publications.  A 2008 study uses Balmorel to explore the Nordic energy system in 2050.  The focus is on renewable energy supply and the deployment of hydrogen as the main transport fuel.  Given certain assumptions about the future price of oil and carbon and the uptake of hydrogen, the model shows that it is economically optimal to cover, using renewable energy, more than 95% of the primary energy consumption for electricity and district heat and 65% of the transport.<ref name=\"karlsson-and-meibom-2008\">\n{{cite journal\n | last1 = Karlsson | first1 = Kenneth Bernard\n | last2 = Meibom | first2 = Peter\n | title = Optimal investment paths for future renewable based energy systems: using the optimisation model Balmorel\n | year = 2008\n | journal = International Journal of Hydrogen Energy\n | volume = 33\n | number = 7\n | pages = 1777–1787\n | doi = 10.1016/j.ijhydene.2008.01.031\n}}\n</ref>  A 2010 study uses Balmorel to examine the integration of [[Plug-in hybrid|plug-in hybrid vehicle]]s (PHEV) into a system comprising one quarter wind power and three quarters thermal generation.  The study shows that PHEVs can reduce the {{CO2}} emissions from the power system if actively integrated, whereas a hands-off approach – letting people charge their cars at will – is likely to result in an increase in emissions.<ref name=\"goeransson-etal-2010\">\n{{cite journal\n | first1 = Lisa | last1 = Göransson\n | first2 = Sten | last2 = Karlsson\n | first3 = Filip | last3 = Johnsson\n | title = Integration of plug-in hybrid electric vehicles in a regional wind-thermal power system\n | date = October 2010\n | journal = Energy Policy\n | volume = 38\n | number = 10\n | pages = 5482–5492\n | doi = 10.1016/j.enpol.2010.04.001\n}}\n</ref>  A 2013 study uses Balmorel to examine cost-optimized wind power investments in the Nordic-Germany region.  The study investigates the best placement of wind farms, taking into account wind conditions, distance to load, and the generation and transmission infrastructure already in place.<ref name=\"goeransson-and-johnsson-2013\">\n{{cite journal\n | last1 = Göransson | first1 = Lisa\n | last2 = Johnsson | first2 = Filip\n | date = May 2013\n | title = Cost-optimized allocation of wind power investments: a Nordic-German perspective\n | journal = Wind Energy\n | volume = 16\n | number = 4\n | pages = 587–604\n | doi = 10.1002/we.1517\n| bibcode = 2013WiEn...16..587G}}\n</ref>\n\n{{clear}}\n\n=== Calliope ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | Calliope\n|-\n! Host\n| [[ETH Zurich]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| dispatch and investment\n|-\n! Code license\n| [[Apache License|Apache 2.0]]\n|-\n! Website\n| {{url|http://www.callio.pe}}\n<!-- the .pe top-level domain is correct, it is actually for Peru -->\n|-\n! Repository\n| {{url|https://github.com/calliope-project/calliope}}\n|-\n! Documentation\n| {{url|http://docs.callio.pe/en/stable/}}\n|}\n\nCalliope is an energy system modeling framework, with a focus on flexibility, high spatial and temporal resolution, and the ability to execute different runs using the same base-case dataset.  The project is being developed at the [https://www.usys.ethz.ch/en/ Department of Environmental Systems Science], [[ETH Zurich]], [[Zürich]], Switzerland.  The project maintains a website, hosts the [[codebase]] at [[GitHub]], operates an [https://github.com/calliope-project/calliope/issues issues tracker], and runs two [[Electronic mailing list|email lists]].  Calliope is written in [[Python (programming language)|Python]] and uses the [[Pyomo]] library.  It can link to the open source [[GLPK]] solver and the commercial [[CPLEX]] and [[Gurobi]] solvers.  PDF documentation is available.<ref name=\"pfenninger-2016\">\n{{cite book\n | first1 = Stefan | last1 = Pfenninger\n | title = Calliope documentation — Release 0.3.7\n | date = 10 March 2016\n | url = https://media.readthedocs.org/pdf/calliope/stable/calliope.pdf\n | access-date = 2016-07-11\n}} The release version may be updated.\n</ref>\n\nA Calliope model consists of a collection of structured text files, in [[YAML]] and [[Comma-separated values|CSV]] formats, that define the technologies, locations, and resource potentials.  Calliope takes these files, constructs a pure [[Linear programming|linear optimization]] (no integer variables) problem, solves it, and reports the results in the form of [[pandas (software)|pandas]] [[data structures]] for analysis.  The framework contains five [[Abstract type|abstract]] base technologies – supply, demand, conversion, storage, transmission – from which new concrete technologies can be derived.  The design of Calliope enforces the clear separation of framework (code) and model (data).\n\nA 2015 study uses Calliope to compare the future roles of [[nuclear power]] and [[Concentrated solar power|CSP]] in [[South Africa]].  It finds CSP could be competitive with nuclear by 2030 for baseload and more competitive when producing above baseload.  CSP also offers less investment risk, less environmental risk, and other co-benefits.<ref name=\"pfenninger-and-keirstead-2015-a\">\n{{cite journal\n | first1 = Stefan | last1 = Pfenninger\n | first2 = James | last2 = Keirstead\n | title = Comparing concentrating solar and nuclear power as baseload providers using the example of South Africa\n | year = 2015\n | journal = Energy\n | volume = 87\n | pages = 303–314\n | doi = 10.1016/j.energy.2015.04.077\n}}\n</ref>  A second 2015 study compares a large number of cost-optimal future power systems for [[Great Britain]].  Three generation technologies are tested: renewables, nuclear power, and fossil fuels with and without [[carbon capture and storage]] (CCS).  The scenarios are assessed on financial cost, emissions reductions, and energy security.  Up to 60% of [[Variable renewable energy|variable renewable]] capacity is possible with little increase in cost, while higher shares require large-scale [[Grid energy storage|storage]], imports, and/or [[Dispatchable generation|dispatchable]] renewables such as [[Tidal power|tidal range]].<ref name=\"pfenninger-and-keirstead-2015-b\">\n{{cite journal\n | first1 = Stefan | last1 = Pfenninger\n | first2 = James | last2 = Keirstead\n | title = Renewables, nuclear, or fossil fuels? Scenarios for Great Britain's power system considering costs, emissions and energy security\n | year = 2015\n | journal = Applied Energy\n | volume = 152\n | pages = 83–93\n | doi = 10.1016/j.apenergy.2015.04.102\n | url = http://www.sciencedirect.com/science/article/pii/S0306261915005656/pdfft?md5=c2e6e2b14ecc752dd3cb455859a49c42&pid=1-s2.0-S0306261915005656-main.pdf\n | access-date = 2016-07-07\n}}\n</ref>\n\n{{clear}}\n\n=== DESSTinEE ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | DESSTinEE\n|-\n! Host\n| [[Imperial College London]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| simulation\n|-\n! Code license\n| [[Creative Commons license|{{nowrap|CC BY-SA 3.0}}]]\n|-\n! Website\n| {{url|https://sites.google.com/site/2050desstinee/}}\n|}\n\nDESSTinEE stands for Demand for Energy Services, Supply and Transmission in EuropE.  DESSTinEE is a model of the European energy system in 2050 with a focus on the electricity system.  DESSTinEE is being developed primarily at the [[Imperial College Business School]], [[Imperial College London]] (ICL), [[London]], United Kingdom.  The software can be downloaded from the project website.  DESSTinEE is written in [[Microsoft Excel|Excel]]/[[Visual Basic for Applications|VBA]] and comprises a set of standalone [[spreadsheet]]s.  A flier is available.<ref name=\"desstinee-2015\">\n{{cite book\n | title = DESSTinEE: an energy transfer reference case\n | year = 2015\n | url = http://www.topandtail.org.uk/publications/outcomes/Planning_a_Transcontinental_Interconnected_System/An%20Energy%20Transfer%20Reference%20Case.pdf\n | access-date = 2016-07-11\n}}\n</ref>\n\nDESSTinEE is designed to investigate assumptions about the technical requirements for energy transport – particularly electricity – and the scale of the economic challenge to develop the necessary infrastructure.  Forty countries are considered in and around Europe and ten forms of primary and secondary energy are supported.  The model uses a predictive simulation technique, rather than solving for either [[Partial equilibrium|partial]] or [[Computable general equilibrium|general equilibrium]].  The model projects annual energy demands for each country to 2050, synthesizes hourly profiles for electricity demand in 2010 and 2050, and simulates the least-cost generation and transmission of electricity around the region.<ref name=\"openmod-wiki-desstinee\">\n{{cite web\n | title = DESSTinEE\n | publisher = Open Energy Modelling Initiative\n | url = http://wiki.openmod-initiative.org/wiki/DESSTinEE\n | access-date = 2016-12-03\n}} [[File:CC-BY icon.svg|50px]] Material was copied from this source, which is available under a [https://creativecommons.org/licenses/by/4.0/ Creative Commons Attribution 4.0 International {{nowrap|(CC BY 4.0)}} license].\n</ref>\n\nA 2016 study using DESSTinEE (and a second model eLOAD) examines the evolution of electricity load curves in Germany and Britain from the present until 2050.  In 2050, peak loads and ramp rates rise 20–60% and system utilization falls 15–20%, in part due to the substantial uptake of [[heat pump]]s and [[electric vehicle]]s.  These are significant changes.<ref name=\"bossmann-and-staffell-2016\">\n{{cite journal\n | last1 = Boßmann | first1 = Tobias\n | last2 = Staffell | first2 = Iain\n | title = The shape of future electricity demand: exploring load curves in 2050s Germany and Britain\n | year = 2016\n | journal = Energy\n | volume = 90\n | number = 20\n | pages = 1317–1333\n | doi = 10.1016/j.energy.2015.06.082\n}}\n</ref>\n\n{{clear}}\n\n=== Energy Transition Model ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | Energy Transition Model\n|-\n! Host\n| [http://quintel.com/ Quintel Intelligence]\n|-\n! Status\n| active\n|-\n! Scope/type\n| web-based\n|-\n! Code license\n| [[MIT license|MIT]]\n|-\n! Website\n| {{url|https://energytransitionmodel.com}}\n|-\n! Interactive website\n| {{url|https://pro.energytransitionmodel.com}}\n|-\n! Repository\n| {{url|https://github.com/quintel/documentation}}\n|}\n\nThe Energy Transition Model (ETM) is an interactive web-based model using a holistic description of a country's energy system.  It is being developed by Quintel Intelligence, [[Amsterdam]], the Netherlands.  The project maintains a project website, an interactive website, and a [[GitHub]] repository.  ETM is written in [[Ruby (programming language)|Ruby]] (on [[Ruby on Rails|Rails]]) and displays in a [[web browser]].  ETM consists of several software components as described in the documentation.\n\nETM is fully interactive.  After selecting a region (France, Germany, the Netherlands, Poland, Spain, United Kingdom, EU-27, or Brazil) and a year (2020, 2030, 2040, or 2050), the user can set 300 sliders (or enter numerical values) to explore the following:\n\n* targets: set goals for the scenario and see if they can be achieved, targets comprise: {{CO2}} reductions, renewables shares, total cost, and caps on imports \n* demands: expand or restrict energy demand in the future\n* costs: project the future costs of energy carriers and energy technologies, these costs do not include taxes or subsidies\n* supplies: select which technologies can be used to produce heat or electricity\n\nETM is based on an energy graph ([[Directed graph|digraph]]) where nodes ([[Glossary of graph theory#vertex|vertices]]) can convert from one type of energy to another, possibly with losses.  The connections ([[Glossary of graph theory#edge|directed edges]]) are the energy flows and are characterized by volume (in [[megajoule]]s) and carrier type (such as coal, electricity, usable-heat, and so forth).  Given a demand and other choices, ETM calculates the primary energy use, the total cost, and the resulting {{CO2}} emissions.  The model is demand driven, meaning that the digraph is traversed from ''useful demand'' (such as space heating, hot water usage, and car-kilometers) to ''primary demand'' (the extraction of gas, the import of coal, and so forth).\n\n{{clear}}\n\n=== EnergyPATHWAYS ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | EnergyPATHWAYS\n|-\n! Host\n| [http://www.evolved.energy/ Evolved Energy Research]\n|-\n! Status\n| active\n|-\n! Scope/type\n| mostly simulation\n|-\n! Code license\n| [[MIT license|MIT]]\n|-\n! Repository\n| {{url|https://github.com/energyPATHWAYS/energyPATHWAYS}}\n|}\n\nEnergyPATHWAYS is a bottom-up energy sector model used to explore the near-term implications of long-term deep decarbonization.  The lead developer is energy and climate protection consultancy, Evolved Energy Research, [[San Francisco]], USA.  The code is hosted on [[GitHub]].  EnergyPATHWAYS is written in [[Python (computer language)|Python]] and links to the open source [[COIN-OR#CBC|Cbc]] solver.  Alternatively, the [[GLPK]], [[CPLEX]], or [[Gurobi]] solvers can be employed.  EnergyPATHWAYS utilizes the [[PostgreSQL]] [[object-relational database management system]] (ORDBMS) to manage its [[Data (computing)|data]].\n\nEnergyPATHWAYS is a comprehensive accounting framework used to construct economy-wide energy infrastructure scenarios.  While portions of the model do use [[linear programming]] techniques, for instance, for electricity dispatch, the EnergyPATHWAYS model is not fundamentally an optimization model and embeds few decision dynamics.  EnergyPATHWAYS offers detailed energy, cost, and emissions accounting for the energy flows from primary supply to final demand.  The energy system representation is flexible, allowing for differing levels of detail and the nesting of cities, states, and countries.  The model uses hourly least-cost electricity dispatch and supports [[power-to-gas]], short-duration energy storage, long-duration energy storage, and [[demand response]].  Scenarios typically run to 2050.\n\nA predecessor of the EnergyPATHWAYS software, named simply PATHWAYS, has been used to construct policy models.  The California PATHWAYS model was used to inform Californian state climate targets for 2030.<ref name=\"williams-etal-2012\">\n{{cite journal\n | last1 = Williams | first1 = James H\n | last2 = DeBenedictis | first2 = Andrew\n | last3 = Ghanadan | first3 = Rebecca\n | last4 = Mahone | first4 = Amber\n | last5 = Moore | first5 = Jack\n | last6 = Morrow | first6 = William R\n | last7 = Price | first7 = Snuller\n | last8 = Torn | first8 = Margaret S\n | title = The technology path to deep greenhouse gas emissions cuts by 2050: the pivotal role of electricity\n | year = 2012\n | journal = Science\n | volume = 335\n | number = 6064\n | pages = 53–59\n | doi = 10.1126/science.1208365\n| bibcode = 2012Sci...335...53W}} See also published [http://science.sciencemag.org/content/336/6079/296.2 correction].\n</ref>  And the US PATHWAYS model contributed to the [[United Nations|UN]] [[Deep Decarbonization Pathways Project]] (DDPP) assessments for the United States.<ref name=\"us-ddpp\">\n{{cite web\n | title = The US Deep Decarbonization Pathways Project (USDDPP)\n | publisher = Deep Decarbonization Pathways Project (DDPP)\n | location = New York, NY, USA\n | url = http://usddpp.org\n | access-date = 2016-12-06\n}}\n</ref>  {{as of|2016}}, the DDPP plans to employ EnergyPATHWAYS for future analysis.\n\n{{clear}}\n\n=== ETEM ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | ETEM\n|-\n! Host\n| [http://www.ordecsys.com/en/home ORDECSYS]\n|-\n! Status\n| active\n|-\n! Scope/type\n| municipal\n|-\n! Code license\n| [[Eclipse Public License|Eclipse 1.0]]\n|-\n! Website\n| {{plainlist|\n* {{url|http://apps.ordecsys.com/etem}}\n* {{url|http://www.energyplan.eu/othertools/local/etem/}}\n}}\n|}\n\nETEM stands for Energy Technology Environment Model.  The ETEM model offers a similar structure to [[#OSeMOSYS|OSeMOSYS]] but is aimed at urban planning.  The software is being developed by the ORDECSYS company, [[Chêne-Bougeries]], Switzerland, supported with European Union and national research grants.  The project has two websites.  The software can be downloaded from first of these websites (but {{as of|lc=yes|2016|07}}, this looks out of date).  A manual is available with the software.<ref name=\"drouet-and-thenie-2009\">\n{{cite book\n | last1 = Drouet | first1 = Laurent\n | last2 = Thénié | first2 = Julie\n | title = ETEM: an energy–technology–environment model to assess urban sustainable development policies — Reference manual version 2.1\n | year = 2009\n | publisher = ORDECSYS (Operations Research Decisions and Systems)\n | location = Chêne-Bougeries, Switzerland\n}} This PDF is part of the software bundle.\n</ref>  ETEM is written in [[MathProg]].{{efn|\nNote that GMPL, referred to in the documentation, is an alternative name for [[MathProg]].\n}}  Presentations describing ETEM are available.<ref name=\"drouet-and-zachary-2010\">\n{{cite book\n | last1 = Drouet | first1 = Laurent\n | last2 = Zachary | first2 = D\n | title = Economic aspects of the ETEM model — Presentation\n | date = 21 May 2010\n | publisher = Resource Centre for Environmental Technologies, Public Research Centre Henri Tudor\n | location = Esch-sur-Alzette, Luxembourg\n | url = http://crteweb.tudor.lu/leaq/uploads/etem-economy.pdf\n | access-date = 2016-07-12\n}}</ref><ref name=\"ordecsys-2015\">\n{{cite book\n | title = Spatial simulation and optimization with ETEM-SG: Energy–Technology–Environment-Model for smart cities — Presentation\n | date = 2015\n | publisher = ORDECSYS\n | location = Chêne-Bougeries, Switzerland\n | url = http://www.ordecsys.com/fr/system/files/u1/Ordecsys-ETEM-SG.pdf\n | access-date = 2016-07-12\n}}\n</ref>\n\nETEM is a bottom-up model that identifies the optimal energy and technology options for a regional or city.  The model finds an energy policy with minimal cost, while investing in new equipment (new technologies), developing production capacity (installed technologies), and/or proposing the feasible import/export of primary energy.  ETEM typically casts forward 50{{nbsp}}years, in two or five year steps, with time slices of four seasons using typically individual days or finer.  The spatial resolution can be highly detailed.  Electricity and heat are both supported, as are [[district heating]] networks, household energy systems, and grid storage, including the use of [[plug-in hybrid|plug-in hybrid electric vehicles]] (PHEV).  ETEM-SG, a development, supports [[demand response]], an option which would be enabled by the development of [[smart grid]]s.\n\nThe ETEM model has been applied to Luxembourg, the Geneva and Basel-Bern-Zurich cantons in Switzerland, and the Grenoble metropolitan and Midi-Pyrénées region in France.  A 2005 study uses ETEM to study climate protection in the Swiss housing sector.  The ETEM model was coupled with the GEMINI-E3 world [[Computable general equilibrium|computable general equilibrium model]] (CGEM) to complete the analysis.<ref name=\"drouet-etal-2005\">\n{{cite book\n | last1 = Drouet | first1 = Laurent\n | last2 = Haurie | first2 = Alain\n | last3 = Labriet | first3 = Maryse\n | last4 = Thalmann | first4 = Philippe\n | last5 = Vielle | first5 = Marc\n | last6 = Viguier | first6 = Laurent\n | title = A coupled bottom-up/top-down model for GHG abatement scenarios in the Swiss housing sector\n | year = 2005\n | doi = 10.1007/0-387-25352-1_2\n | url = http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.8420&rep=rep1&type=pdf\n | access-date = 2016-06-17\n}}\n</ref>  A 2012 study examines the design of [[smart grid]]s.  As distribution systems become more intelligent, so must the models needed to analysis them.  ETEM is used to assess the potential of smart grid technologies using a [[case study]], roughly calibrated on the [[Geneva]] canton, under three scenarios.  These scenarios apply different constraints on {{CO2}} emissions and electricity imports.  A stochastic approach is used to deal with the uncertainty in future electricity prices and the uptake of electric vehicles.<ref name=\"babonneau-2012\">\n{{cite journal\n | first1 = Frédéric | last1 = Babonneau\n | first2 = Alain | last2 = Haurie\n | first3 = Guillaume Jean | last3 = Tarel\n | first4 = Julien | last4 = Thénié\n | title = Assessing the future of renewable and smart grid technologies in regional energy systems\n | date = June 2012\n | journal = Swiss Journal of Economics and Statistics (SJES)\n | volume = 148\n | number = 2\n | pages = 229–273\n | doi =10.1007/bf03399367\n | url = http://www.sjes.ch/papers/2012-II-6.pdf\n | access-date = 2016-07-12\n}}\n</ref>\n\n{{clear}}\n\n=== ficus ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | ficus\n|-\n! Host\n| [[Technical University of Munich]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| local electricity and heat\n|-\n! Code license\n| [[GNU General Public License|GPLv3]]\n|-\n! Repository\n| {{url|https://github.com/yabata/ficus}}\n|-\n! Documentation\n| {{url|https://ficus.readthedocs.io/en/latest/}}\n|}\n\nficus is a [[Mixed integer program|mixed integer]] optimization model for local energy systems.  It is being developed at the [https://www.ewk.ei.tum.de/en/startseite/ Institute for Energy Economy and Application Technology], [[Technical University of Munich]], [[Munich]], Germany.  The project maintains a website.  The project is hosted on [[GitHub]].  ficus is written in [[Python (programming language)|Python]] and uses the [[Pyomo]] library.  The user can choose between the open source [[GLPK]] solver or the commercial [[CPLEX]] and [[Gurobi]] solvers.\n\nBased on [[#URBS|URBS]], ficus was originally developed for optimizing the energy systems of factories and has now been extended to include local energy systems.  ficus supports multiple energy commodities – goods that can be imported or exported, generated, stored, or consumed – including electricity and heat.  It supports multiple-input and multiple-output energy conversion technologies with load-dependent efficiencies.  The objective of the model is to supply the given demand at minimal cost.  ficus uses exogenous cost time series for imported commodities as well as peak demand charges with a configurable timebase for each commodity in use.\n\n{{clear}}\n\n=== oemof ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | oemof\n|-\n! Host\n| oemof community supported by {{plainlist|\n* [http://reiner-lemoine-institut.de/en/ Reiner Lemoine Institute]\n* [[University of Flensburg]]\n* [[Fachhochschule Flensburg|Flensburg University of Applied Sciences]]\n}}\n|-\n! Status\n| active\n|-\n! Scope/type\n| electricity, heat, mobility, gas\n|-\n! Code license\n| [[GNU General Public License|GPLv3]]\n|-\n! Website\n| {{plainlist|\n* {{url|https://oemof.org}}\n<!-- * {{url|http://reiner-lemoine-institut.de/en/oemof/}} -->\n}}\n|-\n! Repository\n| {{url|https://github.com/oemof/}}\n|-\n! Documentation\n| {{url|https://oemof.readthedocs.io}}\n|}\n\noemof stands for Open Energy Modelling Framework.  The project is managed by the Reiner Lemoine Institute, [[Berlin]], Germany and the [http://www.znes-flensburg.de/ Center for Sustainable Energy Systems] (CSES or ZNES) at the [[University of Flensburg]] and the [[Fachhochschule Flensburg|Flensburg University of Applied Sciences]], both [[Flensburg]], Germany.  The project runs two websites and a [[GitHub]] repository.  oemof is written in [[Python (computer language)|Python]] and uses [[Pyomo]] and [[COIN-OR]] components for optimization.  Energy systems can be represented using spreadsheets ([[Comma-separated values|CSV]]) which should simplify data preparation.  {{nowrap|Version 0.1.0}} was released on 1{{nbsp}}December 2016.\n\noemof classes as an energy modeling framework.  It consists of a [[Linear programming|linear]] or [[Mixed integer program|mixed integer]] optimization problem formulation library (solph), an input data generation library (feedin-data), and other auxiliary libraries.  The solph library is used to represent multi-regional and multi-sectoral (electricity, heat, gas, mobility) systems and can optimize for different targets, such as financial cost or {{CO2}} emissions.  Furthermore, it is possible to switch between dispatch and investment modes.  In terms of scope, oemof can capture the European power system or alternatively it can describe a complex local power and heat sector scheme.\n\n{{clear}}\n\n=== OSeMOSYS ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | OSeMOSYS\n|-\n! Host\n| community project\n|-\n! Status\n| active\n|-\n! Scope/type\n| planning at all scales\n|-\n! Code license\n| [[Apache License|Apache 2.0]]\n|-\n! Website\n| {{url|http://www.osemosys.org}}\n|-\n! Forum\n| {{url|https://www.reddit.com/r/optimuscommunity/comments/837cvn/osemosys_qa_part_3/}}\n|-\n! Repository\n| {{url|https://github.com/KTH-dESA/OSeMOSYS}}\n|}\n\nOSeMOSYS stands for Open Source Energy Modelling System.  OSeMOSYS is intended for national and regional policy development and uses an intertemperal optimization framework.  The model posits a single socially motivated operator/investor with perfect foresight.  The OSeMOSYS project is a community endeavor, supported by the Energy Systems Analysis Group (dESA), [[Royal Institute of Technology|KTH Royal Institute of Technology]], [[Stockholm]], Sweden.  The project maintains a website providing background. The project also offers several active [[internet forum]]s on [[Reddit]].  OSeMOSYS was originally written in [[MathProg]], a high-level [[Mathematical optimization|mathematical programming]] language.  It was subsequently reimplemented in [[General Algebraic Modeling System|GAMS]] and [[Python (programming language)|Python]] and all three codebases are now maintained.  The project also provides a test model called UTOPIA.<ref name=\"lavigne-2017\"/>  A manual is available.<ref name=\"moksnes-etal-2015\">\n{{cite book\n | first1 = Nandi | last1 = Moksnes\n | first2 = Manuel | last2 = Welsch\n | first3 = Francesco | last3 = Gardumi\n | first4 = Abhishek | last4 = Shivakumar\n | first5 = Oliver | last5 = Broad\n | first6 = Mark | last6 = Howells\n | first7 = Constantinos | last7 = Taliotis\n | first8 = Vignesh | last8 = Sridharan\n | title = 2015 OSeMOSYS user manual — Working Paper Series DESA/15/11\n | date = November 2015\n | publisher = Division of Energy Systems Analysis, KTH Royal Institute of Technology\n | location = Stockholm, Sweden\n | url = http://www.osemosys.org/uploads/1/8/5/0/18504136/osemosys_manual_-_working_with_text_files_-_2015-11-05.pdf\n | access-date = 2016-07-12\n}} The version referred to in the manual is OSeMOSYS_2013_05_10.\n</ref>\n\nOSeMOSYS provides a framework for the analysis of energy systems over the medium (10–15 years) and long term (50–100 years).  OSeMOSYS uses pure [[Linear programming|linear optimization]], with the option of [[mixed integer programming]] for the treatment of, for instance, discrete power plant capacity expansions.  It covers most energy sectors, including heat, electricity, and transport.  OSeMOSYS is driven by exogenously defined [[Energy system#Energy-services|energy services]] demands.  These are then met through a set of technologies which draw on a set of resources, both characterized by their potentials and costs.  These resources are not limited to energy commodities and may include, for example, water and [[Land use, land-use change and forestry|land-use]].  This enables OSeMOSYS to be applied in domains other than energy, such as water systems.  Technical constraints, economic restrictions, and/or environmental targets may also be imposed to reflect policy considerations.  OSeMOSYS is available in extended and compact MathProg formulations, either of which should give identical results.  In its extended version, OSeMOSYS comprises a little more than 400 [[Source lines of code|lines of code]].\n\n[[File:Osemosys energy model results for fictitious atlantis.png|thumb|left|Simplified results for a fictitious country called Atlantis used for training purposes]]\n\nA key paper describing OSeMOSYS is available.<ref name=\"howells-etal-2011\">\n{{cite journal\n | last1 = Howells | first1 = Mark\n | last2 = Rogner | first2 = Holger\n | last3 = Strachan | first3 = Neil\n | last4 = Heaps | first4 = Charles\n | last5 = Huntington | first5 = Hillard\n | last6 = Kypreos | first6 = Socrates\n | last7 = Hughes | first7 = Alison\n | last8 = Silveira | first8 = Semida\n | last9 = DeCarolis | first9 = Joe\n | last10 = Bazilian | first10 = Morgan\n | last11 = Roehrl | first11 = Alexander\n | title = OSeMOSYS: the open source energy modeling system : an introduction to its ethos, structure and development\n | year = 2011\n | journal = Energy Policy\n | volume = 39\n | issue = 10\n | pages = 5850–5870\n | doi = 10.1016/j.enpol.2011.06.033\n}} The name Morgan Bazillian has been corrected.  ResearchGate [https://www.researchgate.net/publication/229284137_OSeMOSYS_The_Open_Source_Energy_Modeling_System_An_introduction_to_its_ethos_structure_and_development version].\n</ref>  A 2011 study uses OSeMOSYS to investigate the role of household investment decisions.<ref name=\"warren-2011\">\n{{cite conference\n | last = Warren | first = Peter\n | title = Incorporating behavioural complexity into the Open Source Energy Modelling System using intangible costs and benefits\n | date = 23 September 2011\n | conference = People and Buildings\n | place = London, UK\n | url = https://www.researchgate.net/publication/268352013_Incorporating_behavioural_complexity_into_the_Open_Source_Energy_Modelling_System_using_intangible_costs_and_benefits\n | access-date = 2016-06-17\n}}\n</ref>  A 2012 study extends OSeMOSYS to capture the salient features of a [[smart grid]].  The paper explains how to model variability in generation, flexible demand, and [[Grid energy storage|grid storage]] and how these impact on the stability of the grid.<ref name=\"welsch-etal-2012\">\n{{cite journal\n | first1 = Manuel | last1 = Welsch\n | first2 = Mark | last2 = Howells\n | first3 = Morgan | last3 = Bazilian\n | first4 = Joseph F | last4 = DeCarolis\n | first5 = Sebastian | last5 = Hermann\n | first6 = Holger H | last6 = Rogner\n | title = Modelling elements of smart grids: enhancing the OSeMOSYS (Open Source Energy Modelling System) code\n | year = 2012\n | journal = Energy\n | volume = 46\n | number = 1\n | pages = 337–350\n | doi = 10.1016/j.energy.2012.08.017\n}}\n</ref>  OSeMOSYS has been applied to village systems.  A 2015 paper compares the merits of stand-alone, mini-grid, and grid electrification for rural areas in [[East Timor|Timor-Leste]] under differing levels of access.<ref name=\"fuso-nerini-etal-2015\">\n{{cite journal\n | last1 = Fuso Nerini | first1 = Francesco\n | last2 = Dargaville | first2 = Roger\n | last3 = Howells | first3 = Mark\n | last4 = Bazilian | first4 = Morgan\n | date = 1 January 2015\n | title = Estimating the cost of energy access: the case of the village of Suro Craic in Timor Leste\n | journal = Energy\n | volume = 79\n | pages = 385–397\n | doi = 10.1016/j.energy.2014.11.025\n | issn = 0360-5442\n}}\n</ref>  In a 2016 study, OSeMOSYS is modified to take into account realistic consumer behavior.<ref name=\"fragniere-etal-2016\">\n{{cite journal\n | last1 =Fragnière | first1 = Emmanuel\n | last2 = Kanala | first2 = Roman\n | last3 = Moresino | first3 = Francesco\n | last4 = Reveiu | first4 = Adriana\n | last5 = Smeureanu | first5 = Ion\n | title = Coupling techno-economic energy models with behavioral approaches\n | year = 2016\n | journal = Operational Research\n | volume = <!-- not stated on journal website -->\n | pages = 1–15\n | doi = 10.1007/s12351-016-0246-9\n}}\n</ref>  Another 2016 study uses OSeMOSYS to build a local multi-regional energy system model of the [[Lombardy]] region in Italy.  One of the aims of the exercise was to encourage citizens to participate in the energy planning process.  Preliminary results indicate that this was successful and that open modeling is needed to properly include both the technological dynamics and the non-technological issues.<ref name=\"fattori-etal-2016\">\n{{cite journal\n | first1 = Fabrizio | last1 = Fattori\n | first2 = Davide | last2 = Albini\n | first3 = Norma | last3 = Anglani\n | title = Proposing an open-source model for unconventional participation to energy planning\n | year = 2016\n | journal = Energy Research and Social Science\n | volume = 15\n | pages = 12–33\n | doi = 10.1016/j.erss.2016.02.005\n}}\n</ref>  A 2017 paper covering [[Alberta]], Canada factors in the risk of overrunning specified emissions targets because of technological uncertainty.  Among other results, the paper finds that solar and wind technologies are built out seven and five years earlier respectively when emissions risks are included.<ref name=\"niet-etal-2017\">\n{{cite journal\n | last1 = Niet | first1 = T\n | last2 = Lyseng | first2 = B\n | last3 = English | first3 = J\n | last4 = Keller | first4 = V \n | last5 = Palmer-Wilson | first5 = K\n | last6 = Moazzen | first6 = I\n | last7 = Robertson | first7 = B\n | last8 = Wild | first8 = P\n | last9 = Rowe | first9 = A\n | date = June 2017 <!-- the publisher notes: this issue is in progress but contains articles that are final and fully citable / so a forward date is okay -->\n | title = Hedging the risk of increased emissions in long term energy planning\n | journal = Energy Strategy Reviews\n | volume = 16\n | pages = 1–12\n | doi = 10.1016/j.esr.2017.02.001\n | issn = 2211-467X\n}}\n</ref>  Another 2017 paper analyses the electricity system in [[Cyprus]] and finds that, after European Union environmental regulations are applied post-2020, a switch from oil-fired to natural gas generation is indicated.<ref name=\"taliotis-etal-2017\">\n{{cite journal\n | last1 = Taliotis | first1 = Constantinos\n | last2 = Rogner | first2 = Holger\n | last3 = Ressl | first3 = Stephan\n | last4 = Howells | first4 = Mark\n | last5 = Gardumi | first5 = Francesco\n | title = Natural gas in Cyprus: the need for consolidated planning\n | date = August 2017\n | journal = Energy Policy\n | volume = 107\n | pages = 197–209\n | doi = 10.1016/j.enpol.2017.04.047\n | issn = 0301-4215\n | url = http://www.sciencedirect.com/science/article/pii/S0301421517302720\n | access-date = 2017-05-04\n}}\n</ref>\n\nOSeMOSYS has been used to construct wide-area electricity models for [[Africa]], comprising 45{{nbsp}}countries<ref name=\"taliotis-etal-2016\">\n{{cite journal\n | last1 = Taliotis | first1 = Constantinos\n | last2 = Shivakumar | first2 = Abhishek\n | last3 = Ramos | first3 = Eunice\n | last4 = Howells | first4 = Mark\n | last5 = Mentis | first5 = Dimitris\n | last6 = Sridharan | first6 = Vignesh\n | last7 = Broad | first7 = Oliver\n | last8 = Mofor | first8 = Linus\n | date = April 2016\n | title = An indicative analysis of investment opportunities in the African electricity supply sector — Using TEMBA (The Electricity Model Base for Africa)\n | journal = Energy for Sustainable Development\n | volume = 31\n | pages = 50–66\n | doi = 10.1016/j.esd.2015.12.001\n | issn = 0973-0826\n}}\n</ref><ref name=\"osemosys-website-temba\">\n{{cite web\n | title = The Electricity Model Base for Africa (TEMBA)\n | work = OSeMOSYS\n | url = http://www.osemosys.org/temba.html\n | access-date = 2017-01-13\n}}\n</ref> and [[South America]], comprising 13{{nbsp}}countries.<ref name=\"moura-and-howells-2015\">\n{{cite book\n | first1 = Gustavo | last1 = Moura\n | first2 = Mark | last2 = Howells\n | title = SAMBA: the open source South American model base: a Brazilian perspective on long term power systems investment and integration — Working paper dESA /5/8/11\n | date = August 2015\n | publisher = Royal Institute of Technology (KTH)\n | location = Sockholm, Sweden\n | doi = 10.13140/RG.2.1.3038.7042\n}} Available for download from [[ResearchGate]].\n</ref><ref name=\"osemosys-website-samba\">\n{{cite web\n | title = South American Model Base (SAMBA)\n | work = OSeMOSYS\n | url = http://www.osemosys.org/samba-south-american-model-base.html\n | access-date = 2017-01-13\n}}\n</ref>  It has also been used to support United Nations' regional climate, land, energy, and water strategies (CLEWS)<ref name=\"global-clews-website\">\n{{cite web\n | title = Global CLEWS (Climate, Land, Energy, and Water Strategies)\n | publisher = Division for Sustainable Development, Department of Economic and Social Affairs (DESA), United Nations\n | location = New York, USA\n | url = https://unite.un.org/sites/unite.un.org/files/app-globalclews-v-1-0/landingpage.html\n | access-date = 2017-01-13\n}}\n</ref> for the [[Sava]] river basin, central Europe,<ref name=\"de-strasser-etal-2016\">\n<!-- UN document reference: ECE/MP.WAT/NONE/3 -->\n{{cite book\n | first1 = Lucia | last1 = de Strasser\n | first2 = Dimitris | last2 = Mentis\n | first3 = Eunice | last3 = Ramos\n | first4 = Vignesh | last4 = Sridharan\n | first5 = Manuel | last5 = Welsch\n | first6 = Mark | last6 = Howells\n | first7 = Gia | last7 = Destouni\n | first8 = Lea | last8 = Levi\n | first9 = Stephen | last9 = Stec\n | first10 = Ad de | last10 = Roo\n | date = 2016\n | title = Reconciling resource uses in transboundary basins: assessment of the water-food-energy-ecosystems nexus in the Sava River Basin\n | publisher = United Nations Economic Commission for Europe (UNECE)\n | location = Geneva, Switzerland\n | url = https://www.unece.org/fileadmin/DAM/env/water/publications/GUIDELINES/2017/nexus_in_Sava_River_Basin/Nexus-SavaRiverBasin_ECE-MP.WAT-NONE-3_WEB_final_corrected_for_gDoc.pdf\n | access-date = 2017-03-17\n}}\n</ref> the [[Syr Darya]] river basin, eastern Europe,<ref name=\"unece-2016\">\n{{cite book\n | author = <!-- not specified -->\n | title = Reconciling resource uses in transboundary basins: assessment of the water-food-energy-ecosystems nexus in the Syr Darya River basin\n | date = 2016\n | publisher = United Nations Economic Commission for Europe (UNECE)\n | url = https://www.unece.org/fileadmin/DAM/env/water/publications/WAT_Nexus/ECE_MP.WAT_46_Chap.7_ENG_Syr-Daria-Web_TF.pdf\n | access-date = 2017-01-13\n}}\n</ref>{{rp|29}} and Mauritius.<ref name=\"desa-clews-mauritius\">\n{{cite web\n | title = Mauritius CLEWS (Climate, Land, Energy, and Water Strategies)\n | publisher = Division for Sustainable Development, Department of Economic and Social Affairs (DESA), United Nations\n | location = New York, USA\n | url = https://un-desa-modelling.github.io/clews-mauritius-presentation/\n | access-date = 2017-01-13\n}}\n</ref>  Models have previously been built for the [[Baltic States]], [[Bolivia]], [[Nicaragua]], and [[Sweden]].\n\nIn 2016, work started on a [[Web browser|browser]]-based interface to OSeMOSYS, known as the Model Management Infrastructure (MoManI).  Lead by the [[United Nations Department of Economic and Social Affairs|UN Department of Economic and Social Affairs]] (DESA), MoManI is being trialled in selected countries.  The interface can be used to construct models, visualize results, and develop better scenarios.  Atlantis is the name of a fictional country case-study for training purposes.<ref name=\"howells-etal-2016\">\n{{cite book\n | first1 = Mark | last1 = Howells\n | first2 = Abhishek | last2 = Shivakumar\n | first3 = Martynas | last3 = Pelakaukas\n | first4 = Yousef | last4 = Allmulla\n | first5 = Andrii | last5 = Gritsevskyi\n | date = 17 February 2016\n | title = Model Management Interface (MoManI) for OSeMOSYS: supporting development investments and INDCs — Presentation\n | publisher = KTH Royal Institute of Technology and UN Department of Economic and Social Affairs (DESA)\n | location = Stockholm, Sweden and New York, USA\n | url = https://github.com/UN-DESA-Modelling/Atlantis/raw/master/MoManI%20Training%20Overview.pdf\n | access-date = 2017-01-17\n}}\n</ref><ref name=\"atlantis-website\">\n{{cite web\n | title = Atlantis — Integrated Systems Analysis of Energy\n | website = United Nations\n | location = New York, USA\n | url = https://unite.un.org/sites/unite.un.org/files/app-desa-atlantis/index.html\n | access-date = 2017-01-16\n}}\n</ref><ref name=\"un-desa-github-atlantis\">\n{{cite web\n | author = United Nations Department of Economic and Social Affairs (DESA)\n | title = Atlantis\n | website = GitHub\n | url = https://github.com/UN-DESA-Modelling/Atlantis\n | access-date = 2017-01-16\n}}\n</ref>\n\nThe OSeMBE reference model covering western and central Europe was announced on 27 April 2018.<ref name=\"osembe-2018\">\n{{cite web\n | author = OSeMOSYS\n | title = The open source energy model base for the European Union (OSeMBE)\n | date = 2018\n | work = OSeMOSYS\n | location = Stockholm, Sweden\n | url = http://www.osemosys.org/osembe.html\n | access-date = 2018-04-30\n}}\n</ref><ref name=\"beltramo-2018\">\n{{cite mailing list\n | last1 = Beltramo | first1 = Agnese\n | title = first OSeMBE EU-28 model released\n | date = 27 April 2018\n | mailing-list = openmod-initiative@googlegroups.com\n | url = https://groups.google.com/forum/#!topic/openmod-initiative/LIdokK1UY5I\n | access-date = 2018-04-30\n}}\n</ref>  The model uses the MathProg implemention of OSeMOSYS but requires a small [[Patch (computing)|patch]] first.  The model, funded as part of [[Horizon 2020]] and falling under work package WP7 of the REEEM project, will be used to help stakeholders engage with a range of sustainable energy futures for Europe.<ref name=\"reeem-work-packages\">\n{{cite web\n | title = REEEM – Energy Systems Modelling Project\n | website = Modelling the transformation of the European Energy System\n | access-date = 2017-02-16\n | url = http://www.reeem.org/work-packages/\n}}\n</ref>  The REEEM project runs from early-2016 till mid-2020.\n\nOSeMOSYS is used for university teaching.<ref name=\"lavigne-2016\">\n{{cite journal\n | first = Denis | last = Lavigne\n | title = Initiatives for teaching energy modelling to graduate students\n | date = 2016\n | journal = Universal Journal of Management\n | volume = 4\n | number = 8\n | pages = 451–458\n | doi = 10.13189/ujm.2016.040805\n | url = http://www.hrpub.org/download/20160730/UJM5-12107423.pdf\n | access-date = 2017-01-12\n}}\n</ref>  To that end, a 2017 paper describes the basic UTOPIA model, with an explanation on how to generate [[Pareto efficiency|Pareto frontiers]] for a given system.<ref name=\"lavigne-2017\">\n{{cite journal\n | first = Denis | last = Lavigne\n | title = OSeMOSYS energy modeling using an extended UTOPIA model\n | date = 2017\n | journal = Universal Journal of Educational Research\n | volume = 5\n | number = 1\n | pages = 162–169\n | doi = 10.13189/ujer.2017.050120\n | url = http://www.hrpub.org/download/20161230/UJER20-19508357.pdf\n | access-date = 2017-01-12\n}}\n</ref>{{rp|166–167}}\n\n{{clear}}\n\n=== PyPSA ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | PyPSA\n|-\n! Host\n| [[Karlsruhe Institute of Technology]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| electric power systems with [[sector coupling]]\n|-\n! Code license\n| [[GNU General Public License|GPLv3+]]\n|-\n! Website\n| {{url|http://www.pypsa.org}}\n|-\n! Repository\n| {{url|https://github.com/PyPSA/PyPSA}}\n|-\n! Python package\n| {{url|https://pypi.org/project/pypsa}}\n|-\n! Mailing list\n| {{url|https://groups.google.com/group/pypsa}}\n|}\n\nPyPSA stands for Python for Power System Analysis.  PyPSA is a free software toolbox for simulating and optimizing electric power systems and allied sectors.  It supports conventional generation, variable wind and solar generation, electricity storage, [[Power-to-X#Sector coupling concepts|coupling]] to the natural gas, hydrogen, heat, and transport sectors, and hybrid alternating and direct current networks.  Moreover, PyPSA is designed to scale well.  The project is managed by the [https://www.iai.kit.edu/english/index.php Institute for Automation and Applied Informatics] (IAI), [[Karlsruhe Institute of Technology]] (KIT), [[Karlsruhe]], Germany, although the project itself exists independently under its own name and accounts.  The project maintains a website and runs an [[Electronic mailing list|email list]].  PyPSA itself is written in [[Python (programming language)|Python]] and uses the [[Pyomo]] library.  The [[source code]] is hosted on [[GitHub]] and is also released periodically as a [[Python Package Index|PyPI]] package.\n\n[[File:Simulated locational marginal prices produced by PyPSA energy system model.svg|thumb|left|Simulated [[Electricity market#Bid-based, security-constrained, economic dispatch with nodal prices|locational marginal prices]] across [[Germany]] under conditions of high wind and low load.  Bottlenecks in north/south power transmission elicit the large differences.<ref name=\"brown-etal-2018-pypsa\"/>{{rp|11}}]]\n\nThe basic functionality of PyPSA is described in a 2018 paper.  PyPSA sits between traditional steady-state power flow analysis software and full multi-period energy system models.  It can be invoked using either non-linear power flow equations for system simulation or linearized approximations to enable the joint optimization of operations and investment across multiple periods.  Generator ramping and multi-period up and down-times can be specified, [[demand side management|DSM]] is supported, but demand remains [[price elasticity of demand|price inelastic]].<ref name=\"brown-etal-2018-pypsa\">\n{{cite journal\n | last1 = Brown | first1 = Tom\n | last2 = Hörsch | first2 = Jonas\n | last3 = Schlachtberger | first3 = David\n | title = PyPSA: Python for Power System Analysis\n | date = 16 January 2018\n | journal = Journal of Open Research Software\n | volume = 6\n | issue = 1\n | pages = 4\n | doi = 10.5334/jors.188\n | issn = 2049-9647\n | url = https://openresearchsoftware.metajnl.com/articles/10.5334/jors.188/galley/289/download/\n | access-date = 2018-08-26\n}} {{open access}}\n</ref>\n\nA 2018 study examines potential synergies between [[power-to-X#sector coupling concepts|sector coupling]] and [[electric power transmission|transmission]] reinforcement in a future European energy system constrained to reduce [[carbon dioxide equivalent|carbon]] emissions by 95%.  The PyPSA-Eur-Sec-30 model captures the [[energy demand management|demand-side management]] potential of [[battery electric vehicle]]s (BEV) as well as the role that [[power-to-gas]], long-term [[thermal energy storage]], and related technologies can play.  Results indicate that BEVs can smooth the daily variations in solar power while the remaining technologies smooth the [[wiktionary:synoptic|synoptic]] and seasonal variations in both demand and renewable supply.  Substantial [[wiktionary:buildout|buildout]] of the electricity grid is required for a least-cost configuration.  More generally, such a system is both feasible and affordable.  The underlying datasets are available from [[Zenodo]].<ref name=\"brown-etal-2018-synergies\">\n{{cite journal\n | last1 = Brown | first1 = Tom\n | last2 = Schlachtberger | first2 = David\n | last3 = Kies | first3 = Alexander\n | last4 = Schramm | first4 = Stefan\n | last5 = Greiner | first5 = Martin\n | title = Synergies of sector coupling and transmission reinforcement in a cost-optimised, highly renewable European energy system\n | date = 1 October 2018\n | journal = Energy\n | volume = 160\n | pages = 720–739\n | doi = 10.1016/j.energy.2018.06.222\n | issn = 0360-5442\n}}  {{closed access}}  Content identical arXiv [https://arxiv.org/abs/1801.05290v2 postprint].\n</ref>\n\n{{as of|2018|01}}, PyPSA is used by more than a dozen research institutes and companies worldwide.<ref name=\"brown-etal-2018-pypsa\"/>{{rp|2}}  Some research groups have independently extended the software, for instance to model integer transmission expansion.<ref name=\"gorenstein-dedecca-etal-2017\">\n{{cite journal\n | last1 = Gorenstein Dedecca | first1 = João\n | last2 = Hakvoort | first2 = Rudi A\n | last3 = Herder | first3 = Paulien M\n | title = Transmission expansion simulation for the European Northern Seas offshore grid\n | date = 15 April 2017\n | journal = Energy\n | volume = 125\n | pages = 805–824\n | doi = 10.1016/j.energy.2017.02.111\n | issn = 0360-5442\n | url = https://www.sciencedirect.com/science/article/pii/S0360544217302931/pdf\n | access-date = 2018-08-27\n}}  {{open access}}\n</ref>  On 9{{nbsp}}January 2019, the project released an interactive web-interfaced \"toy\" model, using the [[COIN-OR#CBC|Cbc]] solver, to allow the public to experiment with different future costs and technologies.  Each run takes about {{val|40|u=second}}.<ref name=\"whobs-server\">\n{{cite web\n | author = PyPSA contributors\n | title = Meet constant demand from wind+solar+storage with zero-direct-emissions using your own assumptions\n | work = PyPSA project\n | url = https://whobs.org\n | access-date = 2019-01-07\n}}  Caveats apply.\n</ref><ref name=\"whobs-github\">\n{{cite web\n | author = PyPSA constributors\n | title = Online optimisation tool for wind+solar+storage systems: PyPSA/whobs-server\n | work = PyPSA Project\n | url = https://github.com/PyPSA/whobs-server\n | access-date = 2019-01-07\n}}  GitHub repository.\n</ref>\n\n{{clear}}\n\n=== TEMOA ===\n\n{| class=\"infobox\" style=\"width: 28em\"\n|-\n! style=\"width: 35%\" | Project\n| style=\"width: 55%\" | TEMOA\n|-\n! Host\n| [[North Carolina State University]]\n|-\n! Status\n| active\n|-\n! Scope/type\n| system planning\n|-\n! Code license\n| [[GNU General Public License|GPLv2+]]\n|-\n! Website\n| {{url|http://temoaproject.org}}\n|-\n! Repository\n| {{url|https://github.com/TemoaProject/temoa/}}\n\n|}\n\nTEMOA stands for Tools for Energy Model Optimization and Analysis.  The software is being developed by the Department of Civil, Construction, and Environmental Engineering, [[North Carolina State University]], [[Raleigh, North Carolina]], USA.  The project runs a website and a forum.  The [[source code]] is hosted on [[GitHub]].  The model is programmed in [[Pyomo]], an optimization components library written in [[Python (programming language)|Python]].  TEMOA can be used with any solver that [[Pyomo]] supports, including the open source [[GLPK]] solver.  TEMOA uses [[version control]] to publicly archive [[source code]] and [[Data (computing)|datasets]] and thereby enable third-parties to verify all published modeling work.<ref name=\"decarolis-etal-2012\">\n{{cite journal\n | first1 = Joseph F | last1 = DeCarolis\n | first2 = Kevin | last2 = Hunter\n | first3 = Sarat | last3 = Sreepathi\n | year = 2012\n | title = The case for repeatable analysis with energy economy optimization models\n | journal = Energy Economics\n | volume = 34\n | pages = 1845–1853\n | doi = 10.1016/j.eneco.2012.07.004\n | url = http://temoaproject.org/publications/DeCarolis_etal_2012.pdf\n | access-date = 2016-07-08\n}}\n</ref>\n\nTEMOA classes as a modeling framework and is used to conduct analysis using a bottom-up, technology rich energy system model.  The model objective is to minimize the system-wide cost of energy supply by deploying and utilizing energy technologies and commodities over time to meet a set of [[wiktionary:exogenous|exogenously]] specified end-use demands.<ref name=\"hunter-etal-2013\">\n{{cite journal\n | last1 = Hunter | first1 = Kevin\n | last2 = Sreepathi | first2 = Sarat\n | last3 = DeCarolis | first3 = Joseph F\n | title = Modeling for insight using Tools for Energy Model Optimization and Analysis (TEMOA)\n | year = 2013\n | journal = Energy Economics\n | volume = 40\n | pages = 339–349\n | doi = 10.1016/j.eneco.2013.07.014\n | url = http://www4.ncsu.edu/~jfdecaro/papers/Hunter_etal_2013.pdf\n | access-date = 2016-07-08\n}}\n</ref>  TEMOA is \"strongly influenced by the well-documented [[Energy modeling#MARKAL/TIMES|MARKAL/TIMES]] model generators\".<ref name=\"decarolis-etal-2010\">\n{{cite book\n | last1 = DeCarolis | first1 = Joseph\n | last2 = Hunter | first2 = Kevin\n | last3 = Sreepathi | first3 = Sarat\n | title = The TEMOA project: Tools for Energy Model Optimization and Analysis\n | year = 2010\n | publisher = Department of Civil, Construction, and Environmental Engineering, North Carolina State University\n | location = Raleigh, North Carolina, USA\n | url = http://www.temoaproject.org/publications/DeCarolis_IEW2010_paper.pdf\n | access-date = 2016-06-17\n}}\n</ref>{{rp|4}}\n\n{{clear}}\n\n== Project statistics ==\n\nStatistics for the 25 open energy modeling projects listed are as follows:\n\n{|\n| style=\"vertical-align: top\" |\n\n  {| class=\"wikitable sortable\" style=\"font-size: 100%\"\n  |+ Core programming language\n  |-\n  ! Paradigm\n  ! Language\n  ! Count\n  |-\n  | rowspan=\"1\" | [[Imperative programming]]\n  | [[R (programming language)|R]]\n  | align=\"right\" |  1\n  |-\n  | rowspan=\"4\" | [[Object-oriented programming]]{{pad|1em}}\n  | style=\"background-color: #EEEEB2\" | [[C++]]\n  | align=\"right\" |  1\n  |-\n  | style=\"background-color: #EEEEB2\" | [[Java (programming language)|Java]]\n  | align=\"right\" |  2\n  |-\n  | [[Python (programming language)|Python]]\n  | align=\"right\" | 13\n  |-\n  | [[Ruby (programming language)|Ruby]]\n  | align=\"right\" |  1\n  |-\n  | rowspan=\"2\" | [[Mathematical optimization|Mathematical programming]]\n  | style=\"background-color: #EED0B2\" | [[General Algebraic Modeling System|GAMS]]\n  | align=\"right\" |  4\n  |-\n  | [[MathProg]]\n  | align=\"right\" |  2\n  |-\n  | [[Spreadsheet]]\n  | style=\"background-color: #EED0B2\" | [[Microsoft Excel|Excel]]/[[Visual Basic for Applications|VBA]]\n  | align=\"right\" |  1\n  |- class=\"sortbottom\"\n  | colspan=\"3\" style=\"font-size: smaller\" | {{plainlist|\n* {{background color|#EEEEB2|{{pad|2em}}}} indicates a compiled language.\n* {{background color|#EED0B2|{{pad|2em}}}} indicates a commercial software license is required.\n}} \n  |}\n\n| {{pad|5em}}    <!-- gutter between tables -->\n| style=\"vertical-align: top\" |\n\n  {| class=\"wikitable sortable\" style=\"font-size: 100%\"\n  |+ Primary origin\n  |-\n  ! Country                   !! Count\n  |-\n  | Australia                 || style=\"text-align: right\" |  2\n  |-\n  | Denmark                   || style=\"text-align: right\" |  1\n  |-\n  | European Union            || style=\"text-align: right\" |  1\n  |-\n  | Germany                   || style=\"text-align: right\" | 11\n  |-\n  | Netherlands               || style=\"text-align: right\" |  3\n  |-\n  | Sweden{{nnbsp}}{{efn|[[#OSeMOSYS|OSeMOSYS]] is deemed to reside in Sweden due to the influence of the [[Royal Institute of Technology|KTH Royal Institute of Technology]] on the project.}} || style=\"text-align: right\" |  2\n  |-\n  | Switzerland               || style=\"text-align: right\" |  2\n  |-\n  | United Kingdom{{pad|1em}} || style=\"text-align: right\" |  1\n  |-\n  | United States             || style=\"text-align: right\" |  2\n  |}\n\n| {{pad|5em}}    <!-- gutter between tables -->\n| style=\"vertical-align: top\" |\n\n  {| class=\"wikitable sortable\" style=\"font-size: 100%\"\n  |+ Project host\n  |-\n  ! Type                 !! Count\n  |-\n  | Academic institution || style=\"text-align: right\" | 16\n  |-\n  | Commercial entity    || style=\"text-align: right\" |  5\n  |-\n  | Community-based      || style=\"text-align: right\" |  1\n  |-\n  | Non-profit entity    || style=\"text-align: right\" |  2\n  |-\n  | State-sponsored      || style=\"text-align: right\" |  1\n  |}\n\n|}\n\nThe [[General Algebraic Modeling System|GAMS]] language requires a proprietary environment and its significant cost effectively limits participation to those who can access an institutional copy.<ref name=\"gams-2016\">\n{{cite book\n | title = GAMS — Commercial Price List\n | date = 15 March 2016\n | url = http://www.gams.de/sales/commercialp.pdf\n | access-date = 2016-07-11\n}}\n</ref>\n\n== Programming components ==\n\n=== Component models ===\n\nA number of technical component models are now also open source.  While these component models do not constitute systems models aimed at public policy development (the focus of this page), they nonetheless warrant a mention.  Component models can be linked or otherwise adapted into these broader initiatives.\n* Sandia photovoltaic array performance model<ref name=\"king-etal-2004\">\n{{cite book\n | last1 = King | first1 = David L\n | last2 = Boyson | first2 = William E\n | last3 = Kratochvill | first3 = Jay A\n | title = Photovoltaic array performance model — Sandia report SAND2004-3535\n | year = 2004\n | publisher = Sandia Corporation\n | location = USA\n | url = http://prod.sandia.gov/techlib/access-control.cgi/2004/043535.pdf\n | access-date = 2016-06-17\n}}\n</ref>\n\nA number of electricity auction models have been written in [[General Algebraic Modeling System|GAMS]], [[AMPL]], [[MathProg]], and other languages.{{efn|\n[[MathProg]] is a subset of [[AMPL]].  It is sometimes possible to convert an AMPL model into MathProg without much effort.\n}}  These include:\n\n* the EPOC [[Electricity market#Bid-based, security-constrained, economic dispatch with nodal prices|nodal pricing]] model<ref name=\"guan-etal-2011\">\n{{cite book\n | last1 = Guan | first1 = Ziming\n | last2 = Philpott | first2 = Andy\n | title = Modelling summary for the paper \"Production inefficiency of electricity markets with hydro generation\"\n | year = 2011\n | publisher = Electric Power Optimization Centre (EPOC), University of Auckland\n | location = Auckland, New Zealand\n | url = http://www.epoc.org.nz/presentations/Modellingsummary.pdf\n | access-date = 2016-06-17\n}}\n</ref>\n\n* [https://github.com/ElectricityAuthority/vSPD vSPD] [[Electricity market#Bid-based, security-constrained, economic dispatch with nodal prices|nodal pricing]] model<ref name=\"naidoo-2012\">\n{{cite book\n | last = Naidoo | first = Ramu\n | title = Vectorised schedule, pricing and dispatch (vSPD) v1.2: a guide to the Excel-based interface\n | year = 2012\n | publisher = Electricity Authority New Zealand\n | location = Wellington, New Zealand\n | url = http://code.google.com/p/vspd\n | access-date = 2016-06-17\n}}\n</ref>\n\n* Australian [[National Electricity Market]] examples using [[MathProg]] can be found at [[wikibooks:GLPK/Electricity markets]]\n\n=== Open solvers ===\n\nMany projects rely on a [[Linear programming|pure linear]] or [[Mixed integer program|mixed integer]] solver to perform classical optimization, constraint satisfaction, or some mix of the two.  While there are several open source solver projects, the most commonly deployed solver is [[GLPK]].  GLPK has been adopted by [[#Calliope|Calliope]], [[#ETEM|ETEM]], [[#ficus|ficus]], [[#OSeMOSYS|OSeMOSYS]], [[#SWITCH|SWITCH]], and [[#TEMOA|TEMOA]].  Another alternative is the Clp solver.<ref name=\"clp-homepage\">\n{{cite web\n | title = Clp homepage\n | url = https://www.coin-or.org/Clp/index.html\n | access-date = 2017-04-23\n}}\n</ref><ref name=\"coin-or-linear-solver-website\">\n{{cite web\n | title = COIN-OR linear programming solver\n | url = https://projects.coin-or.org/Clp\n | access-date = 2017-04-23\n}}\n</ref>  Proprietary solvers outperform open source solvers by a considerable margin (perhaps ten-fold), so choosing an open solver will limit performance in terms of both speed and memory consumption.<ref name=\"koch-etal-2011\">\n{{cite journal\n | last1 = Koch | first1 = Thorsten\n | last2 = Achterberg | first2 = Tobias\n | last3 = Andersen | first3 = Erling\n | last4 = Bastert | first4 = Oliver\n | last5 = Berthold | first5 = Timo\n | last6 = Bixby | first6 = Robert E\n | last7 = Danna | first7 = Emilie\n | last8 = Gamrath | first8 = Gerald\n | last9 = Gleixner | first9 = Ambros M\n | title = MIPLIB 2010: mixed integer programming library version 5\n | year = 2011\n | journal = Mathematical Programming Computation\n | volume = 3\n | issue = 2\n | pages = 103–163\n | doi = 10.1007/s12532-011-0025-9\n | url = http://mpc.zib.de/index.php/MPC/article/viewFile/56/28\n | access-date = 2016-06-17\n}}\n</ref>\n\n== See also ==\n\n'''General'''\n\n* [[Building energy simulation]] – the modeling of energy flows in buildings\n* [[Climate change mitigation scenarios]]\n* [[Energy modeling]] – the process of building computer models of energy systems\n* [[Energy system]] – the interpretation of the energy sector in system terms\n* [[Open Energy Modelling Initiative]] – a European-based energy modeling community\n* [[Open energy system databases]] – database projects which collect, clean, and republish energy-related datasets\n* [[Unit commitment problem in electrical power production]]\n\n'''Software'''\n\n* [[List of optimization software#Free and open-source software|List of free and open-source optimization solvers]]\n* [[COIN-OR#CBC|Cbc]] (COIN-OR Branch and Cut) – an open source optimization solver\n* [[COIN-OR#CLP|Clp]] (COIN-OR LP) – an open source linear optimization solver\n* [[Community Climate System Model]] – a mostly open source coupled global climate model\n* [[Earth System Modeling Framework|ESMF]] (Earth System Modeling Framework) – open source software for building [[Climate model|climate]], [[numerical weather prediction]], and [[data assimilation]] applications\n* [[GHGProof]] – an open source land-use model\n* [[GLPK]] (GNU Linear Programming Kit) – an open source linear and mixed integer optimization solver\n\n== Notes ==\n\n{{notelist}}\n\n== References ==\n\n{{reflist|30em}}\n\n== Further information ==\n\n* [http://wiki.openmod-initiative.org/wiki/Open_Models Open energy models wiki] maintained by the [[Open Energy Modelling Initiative]]\n\n== External links ==\n\n* [https://www.einstein-energy.net/ Expert system for an Intelligent Supply of Thermal Energy in Industry] (EINSTEIN) – a project for single-facility analysis\n* [http://oep.iks.cs.ovgu.de/factsheets/models/ OpenEnergy Platform factsheets] – structured summaries covering a range of open and closed energy system models\n* [http://openenergymonitor.org/emon/ OpenEnergyMonitor] – an open source energy use monitoring project\n* [http://open-power-system-data.org/ Open Power System Data] – an open electricity data project for Germany and beyond\n* [http://en.openei.org/wiki/System_Advisor_Model_%28SAM%29 SAM Solar Advisor Model] – a project for evaluating [[photovoltaic]] installations\n* [http://www.trnsys.com/ TRNSYS] – the transient system simulation tool\n\n<!-- templates and categories -->\n{{Energy modeling}}\n{{Computer modeling}}\n{{FOSS}}\n\n[[Category:Climate change policy]]\n[[Category:Computational science]]\n[[Category:Economics models]]\n[[Category:Energy policy]]\n[[Category:Open data]]\n[[Category:Open science]]\n[[Category:Systems theory]]\n[[Category:Scientific modeling]]\n[[Category:Climate change mitigation]]\n[[Category:Computer programming]]\n[[Category:Energy models]]\n[[Category:Mathematical modeling]]\n[[Category:Mathematical optimization]]\n[[Category:Simulation]]"
    },
    {
      "title": "Optimal control",
      "url": "https://en.wikipedia.org/wiki/Optimal_control",
      "text": "'''Optimal control theory''' deals with the problem of finding a control law for a given system such that a certain [[optimality criterion]] is achieved.\n\nIt is an extension of the [[calculus of variations]], and is a [[mathematical optimization]] method for deriving [[control theory|control policies]]. The method is largely due to the work of [[Lev Pontryagin]] and [[Richard Bellman]] in the 1950s, after contributions to calculus of variations by [[Edward J. McShane]].<ref>{{cite journal |first=A. E. |last=Bryson |authorlink=Arthur E. Bryson |year=1996 |title=Optimal Control—1950 to 1985 |journal= IEEE Control Systems Magazine |volume=16 |issue=3 |pages=26–33 |doi=10.1109/37.506395 }}</ref> Optimal control can be seen as a [[control strategy]] in [[control theory]].\n\n==General method==\nOptimal control deals with the problem of finding a control law for a given system such that a certain [[optimality criterion]] is achieved. A control problem includes a [[cost functional]] that is a [[function (mathematics)|function]] of state and control variables. An '''optimal control''' is a set of [[differential equation]]s describing the paths of the control variables that minimize the cost function. The optimal control can be derived using [[Pontryagin's minimum principle|Pontryagin's maximum principle]] (a [[necessary condition]] also known as Pontryagin's minimum principle or simply Pontryagin's Principle),<ref>{{cite book |first=I. M. |last=Ross |authorlink=I. Michael Ross |year=2009 |title=A Primer on Pontryagin's Principle in Optimal Control |location= |publisher=Collegiate Publishers |isbn=978-0-9843571-0-9 }}</ref> or by solving the [[Hamilton–Jacobi–Bellman equation]] (a [[sufficient condition]]).\n\nWe begin with a simple example. Consider a car traveling in a straight line on a hilly road. The question is, how should the driver press the accelerator pedal in order to ''minimize'' the total traveling time? In this example, the term ''control law'' refers specifically to the way in which the driver presses the accelerator and shifts the gears. The ''system'' consists of both the car and the road, and the ''optimality criterion'' is the minimization of the total traveling time. Control problems usually include ancillary [[Constraint (mathematics)|constraint]]s. For example, the amount of available fuel might be limited, the accelerator pedal cannot be pushed through the floor of the car, speed limits, etc.\n\nA proper cost function will be a mathematical expression giving the traveling time as a function of the speed, geometrical considerations, and [[initial condition]]s of the system. It is often the case that the [[constraint (mathematics)|constraint]]s are interchangeable with the cost function.\n\nAnother optimal control problem is to find the way to drive the car so as to minimize its fuel consumption, given that it must complete a given course in a time not exceeding some amount. Yet another control problem is to minimize the total monetary cost of completing the trip, given assumed monetary prices for time and fuel.\n\nA more abstract framework goes as follows.  Minimize the continuous-time cost functional\n\n:<math>J=\\Phi\\,[\\,\\textbf{x}(t_0),t_0,\\textbf{x}(t_f),t_f\\,] + \\int_{t_0}^{t_f} \\mathcal{L}\\,[\\,\\textbf{x}(t),\\textbf{u}(t),t\\,] \\,\\operatorname{d}t</math>\n\nsubject to the first-order dynamic constraints (the '''state equation''')\n\n:<math> \\dot{\\textbf{x}}(t) = \\textbf{a}\\,[\\,\\textbf{x}(t),\\textbf{u}(t),t\\,],</math>\n\nthe algebraic ''path constraints''\n\n:<math> \\textbf{b}\\,[\\,\\textbf{x}(t),\\textbf{u}(t),t\\,] \\leq \\textbf{0},</math>\n\nand the [[boundary condition]]s\n\n:<math>\\boldsymbol{\\phi}\\,[\\,\\textbf{x}(t_0),t_0,\\textbf{x}(t_f),t_f\\,] = 0</math>\n\nwhere <math>\\textbf{x}(t)</math> is the ''state'', <math>\\textbf{u}(t)</math> is the ''control'', <math>t</math> is the independent variable (generally speaking, time), <math>t_0</math> is the initial time, and <math>t_f</math> is the terminal time.  The terms <math>\\Phi</math> and <math>\\mathcal{L}</math> are called the ''endpoint cost '' and ''[[Lagrange multiplier|Lagrangian]]'', respectively.  Furthermore, it is noted that the path constraints are in general ''inequality'' constraints and thus may not be active (i.e., equal to zero) at the optimal solution.  It is also noted that the optimal control problem as stated above may have multiple solutions (i.e., the solution may not be unique).  Thus, it is most often the case that any solution <math>[\\textbf{x}^*(t^*),\\textbf{u}^*(t^*),t^*]</math> to the optimal control problem is ''locally minimizing''.\n\n==Linear quadratic control==\nA special case of the general nonlinear optimal control problem given in the previous section is the [[Linear-quadratic regulator|''linear quadratic'' (LQ) optimal control problem]].  The LQ problem is stated as follows.  Minimize the ''quadratic'' continuous-time cost functional\n\n:<math>J=\\tfrac{1}{2} \\mathbf{x}^{\\mathsf{T}}(t_f)\\mathbf{S}_f\\mathbf{x}(t_f) + \\tfrac{1}{2} \\int_{t_0}^{t_f} [\\,\\mathbf{x}^{\\mathsf{T}}(t)\\mathbf{Q}(t)\\mathbf{x}(t) + \\mathbf{u}^{\\mathsf{T}}(t)\\mathbf{R}(t)\\mathbf{u}(t)\\,]\\, \\operatorname{d}t</math>\n\nSubject to the ''linear'' first-order dynamic constraints\n\n:<math>\\dot{\\mathbf{x}}(t)=\\mathbf{A}(t) \\mathbf{x}(t) + \\mathbf{B}(t) \\mathbf{u}(t), </math>\n\nand the initial condition\n\n:<math> \\mathbf{x}(t_0) = \\mathbf{x}_0</math>\n\nA particular form of the LQ problem that arises in many control system problems is that of the ''linear quadratic regulator'' (LQR) where all of the matrices (i.e., <math>\\mathbf{A}</math>, <math>\\mathbf{B}</math>, <math>\\mathbf{Q}</math>, and <math>\\mathbf{R}</math>) are ''constant'', the initial time is arbitrarily set to zero, and the terminal time is taken in the limit <math>t_f\\rightarrow\\infty</math> (this last assumption is what is known as ''infinite horizon'').  The LQR problem is stated as follows.  Minimize the infinite horizon quadratic continuous-time cost functional\n\n:<math>J=\\tfrac{1}{2} \\int_{0}^{\\infty}[\\,\\mathbf{x}^{\\mathsf{T}}(t)\\mathbf{Q}\\mathbf{x}(t) + \\mathbf{u}^{\\mathsf{T}}(t)\\mathbf{R}\\mathbf{u}(t)\\,]\\, \\operatorname{d}t</math>\n\nSubject to the ''linear time-invariant'' first-order dynamic constraints\n\n:<math>\\dot{\\mathbf{x}}(t)=\\mathbf{A} \\mathbf{x}(t) + \\mathbf{B} \\mathbf{u}(t), </math>\n\nand the initial condition\n\n:<math> \\mathbf{x}(t_0) = \\mathbf{x}_0</math>\n\nIn the finite-horizon case the matrices are restricted in that <math>\\mathbf{Q}</math> and <math>\\mathbf{R}</math> are positive semi-definite and positive definite, respectively.  In the infinite-horizon case, however, the [[matrix (mathematics)|matrices]] <math>\\mathbf{Q}</math> and <math>\\mathbf{R}</math> are not only positive-semidefinite and positive-definite, respectively, but are also ''constant''.  These additional restrictions on\n<math>\\mathbf{Q}</math> and <math>\\mathbf{R}</math> in the infinite-horizon case are enforced to ensure that the cost functional remains positive.  Furthermore, in order to ensure that the cost function is ''bounded'', the additional restriction is imposed that the pair <math>(\\mathbf{A},\\mathbf{B})</math> is ''[[Controllability|controllable]]''.  Note that the LQ or LQR cost functional can be thought of physically as attempting to minimize the ''control energy'' (measured as a quadratic form).\n\nThe infinite horizon problem (i.e., LQR) may seem overly restrictive and essentially useless because it assumes that the operator is driving the system to zero-state and hence driving the output of the system to zero. This is indeed correct. However the problem of driving the output to a desired nonzero level can be solved ''after'' the zero output one is. In fact, it can be proved that this secondary LQR problem can be solved in a very straightforward manner.  It has been shown in classical optimal control theory that the LQ (or LQR) optimal control has the feedback form\n\n:<math>\\mathbf{u}(t)=-\\mathbf{K}(t)\\mathbf{x}(t)</math>\n\nwhere <math>\\mathbf{K}(t)</math> is a properly dimensioned matrix, given as\n\n:<math>\\mathbf{K}(t)=\\mathbf{R}^{-1}\\mathbf{B}^{\\mathsf{T}}\\mathbf{S}(t),</math>\n\nand <math>\\mathbf{S}(t)</math> is the solution of the differential [[Riccati equation]].  The differential Riccati equation is given as\n\n:<math>\\dot{\\mathbf{S}}(t) = -\\mathbf{S}(t)\\mathbf{A}-\\mathbf{A}^{\\mathsf{T}}\\mathbf{S}(t)+\\mathbf{S}(t)\\mathbf{B}\\mathbf{R}^{-1}\\mathbf{B}^{\\mathsf{T}}\\mathbf{S}(t)-\\mathbf{Q}</math>\n\nFor the finite horizon LQ problem, the Riccati equation is integrated backward in time using the terminal boundary condition\n\n:<math>\\mathbf{S}(t_f) = \\mathbf{S}_f</math>\n\nFor the infinite horizon LQR problem, the differential Riccati equation is replaced with the ''algebraic'' Riccati equation (ARE) given as\n\n:<math>\\mathbf{0} = -\\mathbf{S}\\mathbf{A}-\\mathbf{A}^{\\mathsf{T}}\\mathbf{S}+\\mathbf{S}\\mathbf{B}\\mathbf{R}^{-1}\\mathbf{B}^{\\mathsf{T}}\\mathbf{S}-\\mathbf{Q}</math>\n\nUnderstanding that the ARE arises from infinite horizon problem, the matrices <math>\\mathbf{A}</math>, <math>\\mathbf{B}</math>, <math>\\mathbf{Q}</math>, and <math>\\mathbf{R}</math> are all ''constant''.  It is noted that there are in general multiple solutions to the algebraic Riccati equation and the ''positive definite'' (or positive semi-definite) solution is the one that is used to compute the feedback gain.  The LQ (LQR) problem was elegantly solved by [[Rudolf Kalman]].<ref>Kalman, Rudolf. ''A new approach to linear filtering and prediction problems''. Transactions of the ASME, Journal of Basic Engineering, 82:34–45, 1960</ref>\n\n==Numerical methods for optimal control==\nOptimal control problems are generally nonlinear and therefore, generally do not have analytic solutions (e.g., like the linear-quadratic optimal control problem).  As a result, it is necessary to employ numerical methods to solve optimal control problems.  In the early years of optimal control ({{abbr|c.|circa}} 1950s to 1980s) the favored approach for solving optimal control problems was that of ''indirect methods''.  In an indirect method, the calculus of variations is employed to obtain the first-order optimality conditions.  These conditions result in a two-point (or, in the case of a complex problem, a multi-point) [[boundary-value problem]].  This boundary-value problem actually has a special structure because it arises from taking the derivative of a [[Hamiltonian (control theory)|Hamiltonian]].  Thus, the resulting [[dynamical system]] is a [[Hamiltonian system]] of the form\n\n: <math>\\begin{array}{lcl} \\dot{\\textbf{x}} & = & \\partial H/\\partial\\boldsymbol{\\lambda} \\\\ \\dot{\\boldsymbol{\\lambda}} & = & -\\partial H/\\partial\\textbf{x} \\end{array}</math>\n\nwhere\n\n: <math>H=\\mathcal{L}+\\boldsymbol{\\lambda}^{\\mathsf{T}}\\textbf{a}-\\boldsymbol{\\mu}^{\\mathsf{T}}\\textbf{b}</math>\n\nis the ''augmented Hamiltonian'' and in an indirect method, the boundary-value problem is solved (using the appropriate boundary or ''transversality'' conditions).  The beauty of using an indirect method is that the state and adjoint (i.e., <math>\\boldsymbol{\\lambda}</math>) are solved for and the resulting solution is readily verified to be an extremal trajectory.  The disadvantage of indirect methods is that the boundary-value problem is often extremely difficult to solve (particularly for problems that span large time intervals or problems with interior point constraints).   A well-known software program that implements indirect methods is BNDSCO.<ref>Oberle, H. J. and Grimm, W., \"BNDSCO-A Program for the Numerical Solution of Optimal Control Problems,\" Institute for Flight Systems Dynamics, DLR, Oberpfaffenhofen, 1989</ref>\n\nThe approach that has risen to prominence in numerical optimal control since the 1980s is that of so-called ''direct methods''.  In a direct method, the state and/or control are approximated using an appropriate function approximation (e.g., polynomial approximation or piecewise constant parameterization).  Simultaneously, the cost functional is approximated as a ''cost function''.  Then, the coefficients of the function approximations are treated as optimization variables and the problem is \"transcribed\" to a nonlinear optimization problem of the form:\n\nMinimize\n\n: <math> F(\\textbf{z})\\,</math>\n\nsubject to the algebraic constraints\n\n: <math> \\begin{array}{lcl} \\textbf{g}(\\textbf{z}) & = & \\textbf{0} \\\\ \\textbf{h}(\\textbf{z}) & \\leq & \\textbf{0} \\end{array} </math>\n\nDepending upon the type of direct method employed, the size of the nonlinear optimization problem can be quite small (e.g., as in a direct shooting or quasilinearization method), moderate (e.g. [[pseudospectral optimal control]]<ref name=\"ReviewPOC\">{{cite journal |authorlink=I. Michael Ross |first=I. M. |last=Ross |first2=M. |last2=Karpenko |title=A Review of [[Pseudospectral optimal control|Pseudospectral Optimal Control]]: From Theory to Flight |journal=Annual Reviews in Control |volume=36 |issue=2 |pages=182–197 |year=2012 |doi=10.1016/j.arcontrol.2012.09.002 }}</ref>) or may be quite large (e.g., a direct [[collocation method]]<ref>{{cite book |last=Betts |first=J. T. |title=Practical Methods for Optimal Control Using Nonlinear Programming |publisher=SIAM Press |location=Philadelphia, Pennsylvania |edition=2nd |year=2010 |isbn=978-0-89871-688-7 }}</ref>). In the latter case (i.e., a collocation method), the nonlinear optimization problem may be literally thousands to tens of thousands of variables and constraints. Given the size of many NLPs arising from a direct method, it may appear somewhat counter-intuitive that solving the nonlinear optimization problem is easier than solving the boundary-value problem. It is, however, the fact that the NLP is easier to solve than the boundary-value problem. The reason for the relative ease of computation, particularly of a direct collocation method, is that the NLP is ''sparse'' and many well-known software programs exist (e.g., [[SNOPT]]<ref>Gill, P. E., Murray, W. M., and Saunders, M. A., ''User's Manual for SNOPT Version 7: Software for Large-Scale Nonlinear Programming'', University of California, San Diego Report, 24 April 2007</ref>) to solve large sparse NLPs. As a result, the range of problems that can be solved via direct methods (particularly direct ''collocation methods'' which are very popular these days) is significantly larger than the range of problems that can be solved via indirect methods. In fact, direct methods have become so popular these days that many people have written elaborate software programs that employ these methods. In particular, many such programs include ''DIRCOL'',<ref>von Stryk, O., ''User's Guide for DIRCOL (version 2.1): A Direct Collocation Method for the Numerical Solution of Optimal Control Problems'', Fachgebiet Simulation und Systemoptimierung (SIM), Technische Universität Darmstadt (2000, Version of November 1999).</ref> SOCS,<ref>Betts, J.T. and Huffman, W. P., ''Sparse Optimal Control Software, SOCS'', Boeing Information and Support Services, Seattle, Washington, July 1997</ref> OTIS,<ref>{{cite journal |last=Hargraves |first=C. R. |last2=Paris |first2=S. W. |title=Direct Trajectory Optimization Using Nonlinear Programming and Collocation |journal=Journal of Guidance, Control, and Dynamics |volume=10 |issue=4 |year=1987 |pages=338–342 |doi=10.2514/3.20223 }}</ref> GESOP/[[ASTOS]],<ref>Gath, P.F., Well, K.H., \"Trajectory Optimization Using a Combination of Direct Multiple Shooting and Collocation\", AIAA 2001–4047, AIAA Guidance, Navigation, and Control Conference, Montréal, Québec, Canada, 6–9 August 2001</ref> DITAN.<ref>Vasile M., Bernelli-Zazzera F., Fornasari N., Masarati P., \"Design of Interplanetary and Lunar Missions Combining Low-Thrust and Gravity Assists\", Final Report of the ESA/ESOC Study Contract No. 14126/00/D/CS, September 2002</ref> and PyGMO/PyKEP.<ref>Izzo, Dario. \"PyGMO and PyKEP: open source tools for massively parallel optimization in astrodynamics (the case of interplanetary trajectory optimization).\" Proceed. Fifth International Conf. Astrodynam. Tools and Techniques, ICATT. 2012.</ref> In recent years, due to the advent of the [[MATLAB]] programming language, optimal control software in MATLAB has become more common. Examples of academically developed MATLAB software tools implementing direct methods include ''RIOTS'',<ref>[http://www.schwartz-home.com/RIOTS/ RIOTS], based on {{cite thesis |type=Ph.D. |last=Schwartz |first=Adam |date=1996 |title=Theory and Implementation of Methods based on Runge–Kutta Integration for Solving Optimal Control Problems |publisher=University of California at Berkeley |url= |oclc=35140322 }}</ref>''[[DIDO (optimal control)|DIDO]]'',<ref>Ross, I. M. and Fahroo, F., ''User's Manual for DIDO: A MATLAB Package for Dynamic Optimization'', Dept. of Aeronautics and Astronautics, Naval Postgraduate School Technical Report, 2002</ref> ''DIRECT'',<ref>Williams, P., ''User's Guide to DIRECT, Version 2.00,'' Melbourne, Australia, 2008</ref> and ''GPOPS,''<ref>[http://gpops.sourceforge.net GOPS], described in Rao, A. V., Benson, D. A., Huntington, G. T., Francolin, C., Darby, C. L., and Patterson, M. A., ''User's Manual for GPOPS: A MATLAB Package for Dynamic Optimization Using the [[Gauss pseudospectral method|Gauss Pseudospectral Method]]'', University of Florida Report, August 2008.</ref> while an example of an industry developed MATLAB tool is ''[[PROPT]]''.<ref>Rutquist, P. and Edvall, M. M, ''PROPT – MATLAB Optimal Control Software,\" 1260 S.E. Bishop Blvd Ste E, Pullman, WA 99163, USA: Tomlab Optimization, Inc.</ref> These software tools have increased significantly the opportunity for people to explore complex optimal control problems both for academic research and industrial problems. Finally, it is noted that general-purpose MATLAB optimization environments such as [[TOMLAB]] have made coding complex optimal control problems significantly easier than was previously possible in languages such as C and [[FORTRAN]].\n\n==Discrete-time optimal control==\nThe examples thus far have shown [[continuous time]] systems and control solutions. In fact, as optimal control solutions are now often implemented [[Digital data|digital]]ly, contemporary control theory is now primarily concerned with [[discrete time]] systems and solutions.  The Theory of [[Consistent Approximations]]<ref>E. Polak, ''On the use of consistent approximations in the solution of semi-infinite optimization and optimal control problems'' Math. Prog. 62 pp. 385–415 (1993).</ref> provides conditions under which solutions to a series of increasingly accurate discretized optimal control problem converge to the solution of the original, continuous-time problem.  Not all discretization methods have this property, even seemingly obvious ones.  For instance, using a variable step-size routine to integrate the problem's dynamic equations may generate a gradient which does not converge to zero (or point in the right direction) as the solution is approached.   The direct method ''[http://www.schwartz-home.com/RIOTS RIOTS]'' is based on the Theory of Consistent Approximation.\n\n==Examples==\n{{unreferenced section|date=April 2018}}\nA common solution strategy in many optimal control problems is to solve for the costate (sometimes called the [[shadow price]]) <math>\\lambda(t)</math>. The costate summarizes in one number the marginal value of expanding or contracting the state variable next turn. The marginal value is not only the gains accruing to it next turn but associated with the duration of the program. It is nice when <math>\\lambda(t)</math> can be solved analytically, but usually the most one can do is describe it sufficiently well that the intuition can grasp the character of the solution and an equation solver can solve numerically for the values.\n\nHaving obtained <math>\\lambda(t)</math>, the turn-t optimal value for the control can usually be solved as a differential equation conditional on knowledge of <math>\\lambda(t)</math>. Again it is infrequent, especially in continuous-time problems, that one obtains the value of the control or the state explicitly. Usually the strategy is to solve for thresholds and regions that characterize the optimal control and use a numerical solver to isolate the actual choice values in time.\n\n===Finite time===\n{{confusing|section|small=left|reason=the law of evolution mentioned in the example is not mentioned in the article and is probably not the same as [[evolution]]|date=October 2018}}\nConsider the problem of a mine owner who must decide at what rate to extract ore from their mine. They own rights to the ore from date <math>0</math> to date <math>T</math>. At date <math>0</math> there is <math>x_0</math> ore in the ground, and the time-dependent amount of ore <math>x(t)</math> left in the ground declines at the rate of <math>u(t)</math> that the mine owner extracts it. The mine owner extracts ore at cost <math>u(t)^2/x(t)</math> (the cost of extraction increasing with the square of the extraction speed and the inverse of the amount of ore left) and sells ore at a constant price <math>p</math>. Any ore left in the ground at time <math>T</math> cannot be sold and has no value (there is no \"scrap value\"). The owner chooses the rate of extraction varying with time <math>u(t)</math> to maximize profits over the period of ownership with no time discounting.\n\n{| cellpadding=\"2\" style=\"border:1px solid darkgray;\"\n|- border=0;\n| 1. Discrete-time version\n\nThe manager maximizes profit <math>\\Pi</math>:\n:<math>\\Pi = \\sum_{t=0}^{T-1} \\left[ pu_t - \\frac{u_t^2}{x_t} \\right] </math>\nsubject to the law of evolution for the state variable <math>x_t</math>\n:<math>x_{t+1} - x_t = - u_t\\!</math>\n\nForm the Hamiltonian and differentiate:\n:<math>H = pu_t - \\frac{u_t^2}{x_t} - \\lambda_{t+1} u_t</math>\n::<math>\\frac{\\partial H}{\\partial u_t} = p - \\lambda_{t+1} - 2\\frac{u_t}{x_t} = 0</math>\n::<math>\\lambda_{t+1} - \\lambda_t = -\\frac{\\partial H}{\\partial x_t} = -\\left( \\frac{u_t}{x_t} \\right)^2</math>\n\nAs the mine owner does not value the ore remaining at time <math>T</math>,\n::<math>\\lambda_T = 0\\!</math>\n\nUsing the above equations, it is easy to solve for the <math>x_t</math> and <math>\\lambda_t</math> series\n:<math>\\lambda_t = \\lambda_{t+1} + \\frac{(p-\\lambda_{t+1})^2}{4}</math>\n:<math>x_{t+1} = x_t \\frac{2 - p + \\lambda_{t+1}}{2}</math>\nand using the initial and turn-T conditions, the <math>x_t</math> series can be solved explicitly, giving <math>u_t</math>.\n\n!width=\"50\"|\n| 2. Continuous-time version\n\nThe manager maximizes profit <math>\\Pi</math>:\n:<math>\\Pi = \\int_0^T \\left[ pu(t) - \\frac{u(t)^2}{x(t)} \\right] dt </math>\nwhere the state variable <math>x(t)</math> evolves as follows:\n:<math> \\dot x(t) = - u(t) </math>\n\nForm the Hamiltonian and differentiate:\n:<math>H = pu(t) - \\frac{u(t)^2}{x(t)} - \\lambda(t) u(t) </math>\n::<math>\\frac{\\partial H}{\\partial u} = p - \\lambda(t) - 2\\frac{u(t)}{x(t)} = 0</math>\n::<math>\\dot\\lambda(t) = -\\frac{\\partial H}{\\partial x} = -\\left( \\frac{u(t)}{x(t)} \\right)^2</math>\n\nAs the mine owner does not value the ore remaining at time <math>T</math>,\n::<math>\\lambda(T) = 0</math>\n\nUsing the above equations, it is easy to solve for the differential equations governing <math>u(t)</math> and <math>\\lambda(t)</math>\n:<math>\\dot\\lambda(t) = -\\frac{(p-\\lambda(t))^2}{4}  </math>\n:<math>u(t) = x(t) \\frac{p- \\lambda(t)}{2}</math>\nand using the initial and turn-T conditions, the functions can be solved to yield\n:<math>x(t) = \\frac{(4-pt+pT)^2}{(4+pT)^2} x_0  </math>\n|}\n\n==See also==\n{{colbegin|colwidth=22em}}\n* [[Active inference]]\n* [[APMonitor]] (Dynamic optimization platform for Python and MATLAB)\n* [[Bellman equation]]\n* [[Bellman pseudospectral method]]\n* [[Brachistochrone]]\n* [[DIDO (optimal control)|DIDO]]\n* [[DNSS point]]\n* [[Dynamic programming]]\n* [[Gauss pseudospectral method]]\n* [[Gekko (optimization software)|GEKKO]]\n* [[Generalized filtering]]\n* [[GPOPS-II]]\n* [[JModelica.org]] (Modelica-based open source platform for dynamic optimization)\n* [[Kalman filter]]\n* [[Linear-quadratic regulator]]\n* [[Model Predictive Control]]\n* [[PID controller]]\n* [[PROPT| PROPT (Optimal Control Software for MATLAB)]]\n* [[Pseudospectral optimal control]]\n* [[Pursuit-evasion]] games\n* [[Sliding mode control]]\n* [[SNOPT]]\n* [[Stochastic control]]\n* [[Trajectory optimization]]\n{{colend}}\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n* {{cite book |first=D. P. |last=Bertsekas |authorlink=Dimitri Bertsekas |title=Dynamic Programming and Optimal Control |location=Belmont |publisher=Athena |year=1995 |isbn=1-886529-11-6 |url= }}\n* {{cite book |last=Bryson |first=A. E. |authorlink=Arthur E. Bryson |last2=Ho |first2=Y.-C. |authorlink2=Yu-Chi Ho |title=Applied Optimal Control: Optimization, Estimation and Control |edition=Revised |publisher=John Wiley and Sons |location=New York |year=1975 |isbn=0-470-11481-9 |url=https://books.google.com/books?id=P4TKxn7qW5kC }}\n* {{cite book |first=R. F. |last=Stengel |authorlink=Robert Stengel |title=Optimal Control and Estimation |location=New York |publisher=Dover (Courier) |year=1994 |isbn=0-486-68200-5 |url=https://books.google.com/books/about/Optimal_Control_and_Estimation.html?id=jDjPxqm7Lw0C }}\n* {{cite book |first=W. H. |last=Fleming |authorlink=Wendell Fleming |first2=R. W. |last2=Rishel |authorlink2=Raymond Rishel |title=Deterministic and Stochastic Optimal Control |location=New York |publisher=Springer |year=1975 |isbn=0-387-90155-8 |url=https://books.google.com/books?id=qJDbBwAAQBAJ }}\n* {{cite book |first=M. I. |last=Kamien |authorlink=Morton Kamien |first2=N. L. |last2=Schwartz |authorlink2=Nancy Schwartz |title=Dynamic Optimization: The Calculus of Variations and Optimal Control in Economics and Management |location=New York |publisher=Elsevier |edition=Second |year=1991 |isbn=0-444-01609-0 |url=https://books.google.com/books?id=0IoGUn8wjDQC }}\n* {{cite book |last=Kirk |first=D. E. |authorlink=Donald E. Kirk |year=1970 |title=Optimal Control Theory: An Introduction |location=Englewood Cliffs |publisher=Prentice-Hall |isbn=0-13-638098-0 |url=https://books.google.com/books?id=onuH0PnZwV4C }}\n\n==External links==\n* [http://apmonitor.com/do Optimal Control Course Online]\n* Dr. Benoît CHACHUAT: [http://lawww.epfl.ch/page4234.html Automatic Control Laboratory] – Nonlinear Programming, Calculus of Variations and Optimal Control.\n* [http://www.mathworks.com/products/connections/product_detail/product_61633.html DIDO - MATLAB tool for optimal control]\n* [https://gekko.readthedocs.io/en/latest/ GEKKO - Python package for optimal control] \n* [http://www.astos.de/products/gesop GESOP – Graphical Environment for Simulation and OPtimization]\n{{Use dmy dates|date=September 2010}}\n* [http://gpops2.com/ GPOPS-II – General-Purpose MATLAB Optimal Control Software]\n* [http://tomdyn.com/ PROPT – MATLAB Optimal Control Software]\n* [https://openocl.org/ OpenOCL – Open Optimal Control Library]\n* Elmer G. Wiens: [http://www.egwald.ca/optimalcontrol/index.php Optimal Control] – Applications of Optimal Control Theory Using the Pontryagin Maximum Principle with interactive models.\n* [http://www.elissarglobal.com/home/get-chapter-2-free/ Pontryagin's Principle Illustrated with Examples]\n* [http://blog.sciencenet.cn/home.php?mod=space&uid=1565&do=blog&id=209522 On Optimal Control] by Yu-Chi Ho\n* [https://www.youtube.com/watch?v=faQeCI1IgoQ Pseudospectral optimal control: Part 1]\n* [https://www.youtube.com/watch?v=jRmJwQI_JZw Pseudospectral optimal control: Part 2]\n\n{{DEFAULTSORT:Optimal Control}}\n[[Category:Mathematical optimization]]\n[[Category:Optimal control| ]]"
    },
    {
      "title": "Optimal design",
      "url": "https://en.wikipedia.org/wiki/Optimal_design",
      "text": "{{about|the topic in the [[design of experiments]]|the topic in optimal control theory|shape optimization}}\n\n<!-- {{Context|date=May 2012}} -->\n[[Image:Theb1982.jpg|thumb|right|alt=Picture of a man taking measurements with a theodolite in a frozen environment.|[[Gustav Elfving]] developed the optimal design of experiments, and so minimized surveyors' need for  [[theodolite|theodolite measurements]] ''(pictured)'', while trapped in his tent in storm-ridden [[Greenland]].<ref name=\"Nord76\">{{harvtxt|Nordström|1999|p=176}}</ref>]]\n\nIn the [[design of experiments]], '''optimal designs''' (or '''optimum designs'''<ref>The adjective \"optimum\" (and not \"optimal\") \"is the slightly older form in English and avoids the construction 'optim(um) + al´—there is no 'optimalis' in Latin\" (page x in ''Optimum Experimental Designs, with SAS'', by Atkinson, Donev, and Tobias).</ref>) are a class of [[design of experiments|experimental designs]] that are [[Optimization (mathematics)|optimal]] with respect to some [[statistical theory|statistical]] [[objective function|criterion]]. The creation of this field of statistics has been credited to Danish statistician [[Kirstine Smith]].<ref name=GL2009>{{cite journal |last=Guttorp |first=P. |last2=Lindgren |first2=G. |title= Karl Pearson and the Scandinavian school of statistics |journal= International Statistical Review |volume=77 |year=2009 |page=64 |doi=10.1111/j.1751-5823.2009.00069.x|citeseerx=10.1.1.368.8328 }}</ref><ref name=KS1918>{{cite journal |last=Smith |first=Kirstine |title=On the standard deviations of adjusted and interpolated values of an observed polynomial function and its constants and the guidance they give towards a proper choice of the distribution of observations |journal=Biometrika |volume=12 |issue=1/2 |pages=1–85 |year=1918 |doi=10.2307/2331929|jstor=2331929 }}</ref>\n\nIn the [[design of experiments]] for [[estimation theory|estimating]] [[statistical model]]s, '''optimal designs''' allow parameters to be [[bias of an estimator|estimated without bias]] and with [[Minimum-variance unbiased estimator|minimum variance]]. A non-optimal design requires a greater number of [[replication (statistics)|experimental runs]] to [[estimation theory|estimate]] the [[parametric model|parameters]] with the same [[efficiency (statistics)|precision]] as an optimal design. In practical terms, optimal experiments can reduce the costs of experimentation.\n\nThe optimality of a design depends on the [[statistical model]] and is assessed with respect to a statistical criterion, which is related to the variance-matrix of the estimator. Specifying an appropriate model and specifying a suitable criterion function both require understanding of [[statistical theory]] and practical knowledge with [[design of experiments|designing experiments]].\n\n==Advantages==\n\nOptimal designs offer three advantages over suboptimal [[Design of experiments|experimental designs]]:<ref>These three advantages (of optimal designs) are documented in the textbook by Atkinson, Donev, and Tobias.</ref>\n#Optimal designs reduce the costs of experimentation by allowing [[statistical model]]s to be estimated with fewer experimental runs.\n#Optimal designs can accommodate multiple types of factors, such as process, mixture, and discrete factors.\n#Designs can be optimized when the design-space is constrained, for example, when the mathematical process-space contains factor-settings that are practically infeasible (e.g. due to safety concerns).\n\n==Minimizing the variance of estimators==\nExperimental designs are evaluated using statistical criteria.<ref>Such criteria are called [[objective function]]s in [[Optimization (mathematics)|optimization theory]].</ref>\n\nIt is known that the [[least squares]] estimator minimizes the [[variance]] of [[Expected value|mean]]-[[Bias of an estimator|unbiased]] [[estimators]] (under the conditions of the [[Gauss–Markov theorem]]). In the [[estimation]] theory for [[statistical model]]s with one [[real number|real]] [[parameter]], the [[reciprocal (mathematics)|reciprocal]] of the variance of an ([[statistical efficiency|\"efficient\"]]) estimator is called the \"[[Fisher information]]\" for that estimator.<ref>The [[Fisher information]] and other \"[[entropy (information theory)|information]]\" [[functional (mathematics)|functional]]s are fundamental concepts in [[statistical theory]].\n</ref> Because of this reciprocity, '''''minimizing'' the ''variance''''' corresponds to '''''maximizing'' the ''information'''''.\n\nWhen the [[statistical model]] has several [[parameter]]s, however, the [[Expected value|mean]] of the parameter-estimator is a [[Coordinate vector|vector]] and its [[covariance matrix|variance]] is a [[Matrix (mathematics)|matrix]]. The [[inverse matrix]] of the variance-matrix is called the \"information matrix\". Because the variance of the estimator of a parameter vector is a matrix, the problem of \"minimizing the variance\" is complicated. Using [[statistical theory]], statisticians compress the  information-matrix using real-valued [[summary statistics]]; being real-valued functions, these \"information criteria\" can be maximized.<ref>Traditionally, statisticians have evaluated estimators and designs by considering some [[summary statistics|summary statistic]] of the covariance matrix (of a [[Expected value|mean]]-[[Bias of an estimator|unbiased estimator]]), usually with positive real values (like the [[determinant]] or [[matrix trace]]). Working with positive real-numbers brings several advantages: If the estimator of a single parameter has a positive variance, then the variance and the Fisher information are both positive real numbers; hence they are members of the convex cone of nonnegative real numbers (whose nonzero members have reciprocals in this same cone). <br />\nFor several parameters, the covariance-matrices and information-matrices are elements of the convex cone of nonnegative-definite symmetric matrices in a [[partial order|partially]] [[ordered vector space]], under the [[Charles Loewner|Loewner]] (Löwner) order. This cone is closed under matrix-matrix addition, under matrix-inversion, and under the multiplication of positive real-numbers and matrices.\n\nAn exposition of matrix theory and the Loewner-order appears in Pukelsheim.\n</ref> The traditional optimality-criteria are [[Invariant theory|invariants]] of the [[Fisher information|information]] matrix; algebraically, the traditional optimality-criteria are [[Functional (mathematics)|functionals]] of the [[eigenvalue]]s of the information matrix.\n\n*'''A'''-optimality (\"'''average'''\" or '''trace''')\n**One criterion is '''A-optimality''', which seeks to minimize the [[trace (linear algebra)|trace]] of the [[invertible matrix|inverse]] of the information matrix. This criterion results in minimizing the average variance of the estimates of the regression coefficients.\n*'''C'''-optimality\n**This criterion minimizes the variance of a [[best linear unbiased estimator]] of a predetermined linear combination of model parameters.\n*{{anchor|D-optimality}}'''D'''-optimality ('''determinant''')\n**A popular criterion is '''D-optimality''', which seeks to minimize |(X'X)<sup>−1</sup>|, or equivalently maximize the [[determinant]] of the [[information matrix]] X'X of the design. This criterion results in maximizing the [[Differential entropy|differential Shannon information]] content of the parameter estimates.\n*'''E'''-optimality ('''eigenvalue''')\n**Another design is '''E-optimality''', which maximizes the minimum [[eigenvalue]] of the information matrix.\n*'''T'''-optimality\n**This criterion maximizes the [[trace (linear algebra)|trace]] of the information matrix.\n\nOther optimality-criteria are concerned with the variance of [[Predictive inference|predictions]]:\n*'''G'''-optimality\n**A popular criterion is '''G-optimality''', which seeks to minimize the maximum entry in the [[diagonal#Matrices|diagonal]] of the [[hat matrix]] X(X'X)<sup>−1</sup>X'. This has the effect of minimizing the maximum variance of the predicted values.\n*'''I'''-optimality ('''integrated''')\n**A second criterion on prediction variance is '''I-optimality''', which seeks to minimize  the average prediction variance ''over the design space''.\n*'''V'''-optimality ('''variance''')\n**A third criterion on prediction variance is '''V-optimality''', which seeks to minimize the average prediction variance over a set of m specific points.<ref>The above optimality-criteria are convex functions on domains of [[Semidefinite programming|symmetric positive-semidefinite matrices]]: See an on-line textbook for practitioners, which has many illustrations and statistical applications:\n* {{cite book|title=Convex Optimization|first1=Stephen P.|last1=Boyd|first2=Lieven|last2=Vandenberghe|year=2004|publisher=Cambridge University Press|isbn=978-0-521-83378-3|url=http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf|accessdate=October 15, 2011}}  (book in pdf)\nBoyd and Vandenberghe discuss optimal experimental designs on pages 384–396.\n</ref>\n\n===Contrasts===\n{{Main|Contrast (statistics)}} {{See also|Nuisance parameter}}\nIn many applications, the statistician is most concerned with a [[Nuisance parameter|\"parameter of interest\"]] rather than with [[Nuisance parameter|\"nuisance parameters\"]]. More generally, statisticians consider [[linear combination]]s of parameters, which are estimated via linear combinations of treatment-means in the [[design of experiments]] and in the [[analysis of variance]]; such linear combinations are called [[contrast (statistics)|contrasts]]. Statisticians can use appropriate optimality-criteria for such [[Nuisance parameter|parameters of interest]] and for more generally for [[Contrast (statistics)|contrasts]].<ref>Optimality criteria for [[nuisance parameter|\"parameters of interest\"]] and for [[Contrast (statistics)|contrasts]] are discussed by Atkinson, Donev and Tobias.</ref>\n\n==Implementation==\n\nCatalogs of optimal designs occur in books and in software libraries.\n\nIn addition, major [[List of statistical packages|statistical systems]] like [[SAS System|SAS]] and [[R (programming language)|R]] have procedures for optimizing a design according to a user's specification. The experimenter must specify a [[Statistical model|model]] for the design and an optimality-criterion before the method can compute an optimal design.<ref>Iterative methods and approximation algorithms are surveyed in the textbook by Atkinson, Donev and Tobias and in the monographs of Fedorov (historical) and Pukelsheim, and in the survey article by Gaffke and Heiligers.\n</ref>\n\n==Practical considerations==\n\nSome advanced topics in optimal design require more [[statistical theory]] and practical knowledge in designing experiments.\n\n===Model dependence and robustness===\nSince the optimality criterion of most optimal designs is based on some function of the information matrix, the 'optimality' of a given design is ''[[Statistical model|model]] dependent'': While an optimal design is best for that [[Statistical model|model]], its performance may deteriorate on other [[Statistical model|models]]. On other [[Statistical model|models]], an ''optimal'' design can be either better or worse than a non-optimal design.<ref>See Kiefer (\"Optimum Designs for Fitting Biased Multiresponse Surfaces\" pages 289–299).</ref> Therefore, it is important to [[Benchmarking|benchmark]] the performance of designs under alternative [[Statistical model|models]].<!--  and for several criteria --><ref>Such benchmarking is discussed in the textbook by Atkinson et al. and in the papers of Kiefer. ''[[Statistical model|Model]]-[[Robust statistics|robust]]'' designs (including \"Bayesian\" designs) are surveyed by Chang and Notz.\n</ref>\n\n===Choosing an optimality criterion and robustness===\nThe choice of an appropriate optimality criterion requires some thought, and it is useful to benchmark the performance of designs with respect to several optimality criteria. Cornell writes that\n\n{{quote|since the [traditional optimality] criteria . . . are variance-minimizing criteria, . . .  a design that is optimal for a given model using one of the . . . criteria is usually near-optimal for the same model with respect to the other criteria.|<ref>{{cite book\n|author=Cornell, John\n|title=Experiments with Mixtures: Designs, Models, and the Analysis of Mixture Data\n|edition=third\n|publisher=Wiley\n|year=2002\n|isbn=978-0-471-07916-3\n}} (Pages 400-401)\n</ref>}}\n\nIndeed, there are several classes of designs for which all the traditional optimality-criteria agree, according to the theory of \"universal optimality\" of [[Jack Kiefer (mathematician)|Kiefer]].<ref>An introduction to \"universal optimality\" appears in the textbook of Atkinson, Donev, and Tobias. More detailed expositions occur in the advanced textbook of Pukelsheim and the papers of Kiefer.</ref> The experience of practitioners like Cornell and the \"universal optimality\" theory of Kiefer suggest that robustness with respect to changes in the ''optimality-criterion'' is much greater than is robustness with respect to changes in the ''model''.\n\n====Flexible optimality criteria and convex analysis====\n\nHigh-quality statistical software provide a combination of libraries of optimal designs or iterative methods for constructing approximately optimal designs, depending on the model specified and the optimality criterion. Users may use a standard optimality-criterion or may program a custom-made criterion.\n\nAll of the traditional optimality-criteria are [[Convex function|convex (or concave) functions]], and therefore optimal-designs are amenable to the mathematical theory of [[convex analysis]] and their computation can use specialized methods of [[Convex optimization|convex minimization]].<ref>Computational methods are discussed by Pukelsheim and by Gaffke and Heiligers.</ref> The practitioner need not select ''exactly one'' traditional, optimality-criterion, but can specify a custom criterion. In particular, the practitioner can specify a convex criterion using the maxima of convex optimality-criteria and [[Conical combination|nonnegative combinations]] of optimality criteria (since these operations preserve [[convex functions]]). For ''convex'' optimality criteria, the [[Jack Kiefer (mathematician)|Kiefer]]-[[Jacob Wolfowitz|Wolfowitz]] [https://books.google.com/books?id=5ZcfDZUJ4F8C&pg=PA212&lpg=PA212&dq=Kiefer+Wolfowitz&source=bl&ots=u0F1j-W3CF&sig=-bWiYksuk7RIOeZ_qZnB9Jpj0tk&hl=sv&ei=izghSvvUCs6zsgajuo24Bg&sa=X&oi=book_result&ct=result&resnum=10 equivalence theorem] allows the practitioner to verify that a given design is globally optimal.<ref>The [[Jack Kiefer (mathematician)|Kiefer]]-[[Jacob Wolfowitz|Wolfowitz]] [https://books.google.com/books?id=5ZcfDZUJ4F8C&pg=PA212&lpg=PA212&dq=Kiefer+Wolfowitz&source=bl&ots=u0F1j-W3CF&sig=-bWiYksuk7RIOeZ_qZnB9Jpj0tk&hl=sv&ei=izghSvvUCs6zsgajuo24Bg&sa=X&oi=book_result&ct=result&resnum=10 equivalence theorem] is discussed in Chapter 9 of Atkinson, Donev, and Tobias.</ref> The [[Jack Kiefer (mathematician)|Kiefer]]-[[Jacob Wolfowitz|Wolfowitz]] [https://books.google.com/books?id=5ZcfDZUJ4F8C&pg=PA212&lpg=PA212&dq=Kiefer+Wolfowitz&source=bl&ots=u0F1j-W3CF&sig=-bWiYksuk7RIOeZ_qZnB9Jpj0tk&hl=sv&ei=izghSvvUCs6zsgajuo24Bg&sa=X&oi=book_result&ct=result&resnum=10 equivalence theorem] is related with the [[Legendre transformation|Legendre]]-[[Fenchel's duality theorem|Fenchel]] [[Convex conjugate|conjugacy]] for [[convex function]]s.<ref>Pukelsheim uses [[convex analysis]] to study [[Jack Kiefer (mathematician)|Kiefer]]-[[Jacob Wolfowitz|Wolfowitz]] [https://books.google.com/books?id=5ZcfDZUJ4F8C&pg=PA212&lpg=PA212&dq=Kiefer+Wolfowitz&source=bl&ots=u0F1j-W3CF&sig=-bWiYksuk7RIOeZ_qZnB9Jpj0tk&hl=sv&ei=izghSvvUCs6zsgajuo24Bg&sa=X&oi=book_result&ct=result&resnum=10 equivalence theorem] in relation to the [[Legendre transformation|Legendre]]-[[Fenchel's duality theorem|Fenchel]] [[Convex conjugate|conjugacy]] for [[convex function]]s\n\nThe [[convex optimization|minimization]] of [[convex function]]s on domains of [[Semidefinite programming|symmetric positive-semidefinite matrices]] is explained in an on-line textbook for practitioners, which has many illustrations and statistical applications:\n* {{cite book|title=Convex Optimization|publisher=Cambridge University Press|year=2004|url=http://www.stanford.edu/~boyd/cvxbook/| author9=Boyd, Stephen and Vandenberghe, Lieven}}  (book in pdf)\nBoyd and Vandenberghe discuss optimal experimental designs on pages 384–396.\n</ref>\n\nIf an optimality-criterion lacks [[Quasiconvex function|convexity]], then finding a [[Global optimization|global optimum]] and verifying its optimality often are difficult.\n\n===Model uncertainty and Bayesian approaches===\n\n====Model selection====\n{{See also|Model selection}}\nWhen scientists wish to test several theories, then a statistician can design an experiment that allows optimal tests between specified models. Such \"discrimination experiments\" are especially important in the [[biostatistics]] supporting  [[pharmacokinetics]] and [[pharmacodynamics]], following the work of [[David R. Cox|Cox]] and Atkinson.<ref>See Chapter 20 in Atkinison, Donev, and Tobias.</ref>\n\n====Bayesian experimental design====\n{{Main|Bayesian experimental design}}\nWhen practitioners need to consider multiple [[statistical model|models]], they can specify a [[Probability measure|probability-measure]] on the models and then select any design maximizing the [[expected value]] of such an experiment. Such probability-based optimal-designs are called optimal [[Bayesian inference|Bayesian]] [[Bayesian experimental design|designs]]. Such [[Bayesian experimental design|Bayesian designs]] are used especially for [[generalized linear models]] (where the response follows an [[Exponential family|exponential-family]] distribution).<ref>[[Bayesian experimental design|Bayesian designs]] are discussed in Chapter 18 of the textbook by Atkinson, Donev, and Tobias. More advanced discussions occur in the monograph by Fedorov and Hackl, and the articles by Chaloner and Verdinelli and by DasGupta. [[Bayesian experimental design|Bayesian designs]] and other aspects of \"model-robust\" designs are discussed by Chang and Notz.</ref>\n\nThe use of a [[Bayesian experimental design|Bayesian design]] does not force statisticians to use [[Bayesian inference|Bayesian methods]] to analyze the data, however. Indeed, the \"Bayesian\" label for probability-based experimental-designs is disliked by some researchers.<ref>As an alternative to \"''Bayesian'' optimality\", \"''on-average'' optimality\" is advocated in Fedorov and Hackl.</ref>  Alternative terminology for \"Bayesian\" optimality includes \"on-average\" optimality or \"population\" optimality.\n\n==Iterative experimentation==\nScientific experimentation is an iterative process, and statisticians have developed several approaches to the optimal design of sequential experiments.\n\n===Sequential analysis===\n{{Main|Sequential analysis}}\n[[Sequential analysis]] was pioneered by [[Abraham Wald]].<ref>{{Cite journal\n | authorlink = Abraham Wald\n | first = Abraham\n | last = Wald\n | title = Sequential Tests of Statistical Hypotheses\n | journal = The Annals of Mathematical Statistics\n | volume = 16\n | issue = 2\n |date=June 1945\n | pages = 117–186\n | doi = 10.1214/aoms/1177731118\n| jstor=2235829\n}}\n</ref> In 1972, [[Herman Chernoff]] wrote an overview of optimal sequential designs,<ref>Chernoff, H. (1972) ''Sequential Analysis and Optimal Design,'' SIAM Monograph.</ref> while [[Minimisation (clinical trials)|adaptive designs]] were surveyed later by S. Zacks.<ref>Zacks, S. (1996) \"Adaptive Designs for Parametric Models\". In: Ghosh, S. and Rao, C. R., (Eds) (1996). ''Design and Analysis of Experiments,'' Handbook of Statistics, Volume 13. North-Holland. {{isbn|0-444-82061-2}}.  (pages 151–180)</ref> Of course, much work on the optimal design of experiments is related to the theory of [[optimal decision]]s, especially the [[statistical decision theory]] of [[Abraham Wald]].<ref>\n[http://www.lse.ac.uk/collections/cats/People/HenryPage.htm Henry P. Wynn] wrote, \"the modern theory of optimum design has its roots in the decision theory school of U.S. statistics founded by [[Abraham Wald]]\" in his introduction \"Jack Kiefer's Contributions to Experimental Design\", which is pages xvii–xxiv in the following volume:\n* {{cite book |author=[[Jack Kiefer (mathematician)|Kiefer, Jack Carl]]. |title=Jack Carl Kiefer Collected Papers III Design of Experiments | editors=[[Lawrence D. Brown|Brown, Lawrence D.]] and [http://www-stat.stanford.edu/people/faculty/olkin/ Olkin, Ingram] and [http://www.niss.org/people/sacks.html Jerome Sacks] and [http://www.lse.ac.uk/collections/cats/People/HenryPage.htm Wynn, Henry P]|publisher=Springer-Verlag and the [[Institute of Mathematical Statistics]] |year=1985 | pages=718+xxv |isbn=978-0-387-96004-3 |oclc= |doi=|title-link=Jack Kiefer (mathematician) }}\n\n[[Jack Kiefer (mathematician)|Kiefer]] acknowledges Wald's influence and results on many pages – 273 (page 55 in the reprinted volume), 280 (62), 289-291 (71-73), 294 (76), 297 (79),  315 (97) 319 (101) – in this article:\n* {{cite journal\n|first=J.\n|last=Kiefer\n|authorlink=Jack Kiefer (mathematician)\n|title=Optimum Experimental Designs\n|journal=Journal of the Royal Statistical Society, Series B\n|volume=21\n|year=1959\n|pages=272–319\n}}\n\n</ref>\n\n===Response-surface methodology===\n{{Main|Response surface methodology}}\nOptimal designs for [[Response surface methodology|response-surface models]] are discussed in the textbook by Atkinson, Donev and Tobias, and in the survey of Gaffke and Heiligers and in the mathematical text of Pukelsheim. The [[Blocking (statistics)|blocking]] of optimal designs is discussed in the textbook of Atkinson, Donev and Tobias and also in the monograph by Goos.\n\nThe earliest optimal designs were developed to estimate the parameters of regression models with continuous variables, for example, by [[Joseph Diaz Gergonne|J. D. Gergonne]] in 1815 (Stigler).  In English, two early contributions were made by [[Charles Sanders Peirce|Charles S. Peirce]] and [https://web.archive.org/web/20090810040534/http://www.webdoe.cc/publications/kirstine.php Kirstine Smith].\n\nPioneering designs for multivariate [[Response surface methodology|response-surfaces]] were proposed by [[George E. P. Box]]. However, Box's designs have few optimality properties. Indeed, the [[Box–Behnken design]] requires excessive experimental runs when the number of variables exceeds three.<ref>In the field of [[response surface methodology]], the [[Statistical efficiency|inefficiency]] of the [[Box–Behnken design]] is noted by Wu and Hamada (page 422).\n* {{cite book |author1=Wu, C. F. Jeff  |author2=Hamada, Michael  |lastauthoramp=yes |title=Experiments: Planning, Analysis, and Parameter Design Optimization |publisher=Wiley |year=2002 |isbn=978-0-471-25511-6}}\nOptimal designs for \"follow-up\" experiments are discussed by Wu and Hamada.\n</ref>\nBox's [[Central composite design|\"central-composite\" designs]] require more experimental runs than do the optimal designs of Kôno.<ref>The [[Statistical efficiency|inefficiency]] of [[George E. P. Box|Box]]'s [[Central composite design|\"central-composite\" designs]] are discussed by according to Atkinson, Donev, and Tobias (page 165). These authors also discuss the [[Blocking (statistics)|blocking]] of Kôno-type designs for quadratic [[response surface methodology|response-surfaces]].</ref>\n\n===System identification and stochastic approximation===\n{{See also|System identification|Stochastic approximation}}\nThe optimization of sequential experimentation is studied also in [[stochastic programming]] and in [[Systems analysis|systems]] and [[Control theory|control]]. Popular methods include [[stochastic approximation]] and other methods of [[stochastic optimization]]. Much of this research has been associated with the subdiscipline of [[system identification]].<ref>In system identification, the following books have chapters on optimal experimental design:\n* {{cite book |author1=Goodwin, Graham C.  |author2=Payne, Robert L. |lastauthoramp=yes |title=Dynamic System Identification: Experiment Design and Data Analysis | publisher=Academic Press | year=1977 |isbn=978-0-12-289750-4|title-link=System identification }}\n* {{cite book |author1=Walter, Éric  |author2=Pronzato, Luc  |lastauthoramp=yes |title=Identification of Parametric Models from Experimental Data |publisher=Springer |year=1997|title-link=System identification  }}\n</ref>\nIn computational [[optimal control]], D. Judin & A. Nemirovskii and [http://www.ipu.ru/labs/lab7/eng/staff/polyak.htm Boris Polyak] has described methods that are more efficient than the ([[Armijo rule|Armijo-style]]) [[Subgradient method#Step size rules|step-size rules]] introduced by [[George E. P. Box|G. E. P. Box]] in [[Response surface methodology|response-surface methodology]].<ref>Some step-size rules for of Judin & Nemirovskii and of [http://www.ipu.ru/labs/lab7/eng/staff/polyak.htm Polyak] are explained in the textbook by Kushner and Yin:\n* {{cite book |author=[[Harold J. Kushner|Kushner, Harold J.]] and Yin, G. George|title=Stochastic Approximation and Recursive Algorithms and Applications |edition=Second | publisher=Springer  | year=2003 |isbn=978-0-387-00894-3|title-link=Stochastic approximation }}\n</ref>\n\n[[Minimisation (clinical trials)|Adaptive designs]] are used in [[clinical trials]], and optimal [[Minimisation (clinical trials)|adaptive designs]] are surveyed in the ''Handbook of Experimental Designs'' chapter by Shelemyahu Zacks.\n\n==Specifying the number of experimental runs==\n\n===Using a computer to find a good design===\n\nThere are several methods of finding an optimal design, given an ''a priori'' restriction on the number of experimental runs or replications. Some of these methods are discussed by Atkinson, Donev and Tobias and in the paper by Hardin and [[Neil Sloane|Sloane]]. Of course, fixing the number of experimental runs ''a priori'' would be impractical.  Prudent statisticians examine the other optimal designs, whose number of experimental runs differ.\n\n===Discretizing probability-measure designs===\n\nIn the mathematical theory on optimal experiments, an optimal design can be a [[probability measure]] that is [[Support (measure theory)|supported]] on an infinite set of observation-locations. Such optimal probability-measure designs solve a mathematical problem that neglected to specify the cost of observations and experimental runs. Nonetheless, such optimal probability-measure designs can be [[Discretization|discretized]] to furnish [[Approximation|approximately]] optimal designs.<ref>The [[discretization]] of optimal probability-measure designs to provide [[Approximation|approximately]] optimal designs is discussed by Atkinson, Donev, and Tobias and by Pukelsheim (especially Chapter 12).</ref>\n\nIn some cases, a finite set of observation-locations suffices to [[Support (measure theory)|support]] an optimal design. Such a result was proved by Kôno and [[Jack Kiefer (mathematician)|Kiefer]] in their works on [[Response surface methodology|response-surface designs]] for quadratic models. The Kôno–Kiefer analysis explains why optimal designs for response-surfaces can have discrete supports, which are very similar as do the less efficient designs that have been traditional in [[response surface methodology]].<ref>Regarding designs for quadratic [[response surface methodology|response-surfaces]], the results of Kôno and [[Jack Kiefer (mathematician)|Kiefer]] are discussed in Atkinson, Donev, and Tobias.\n\nMathematically, such results are associated with [[Chebyshev polynomials]], \"Markov systems\", and \"moment spaces\": See\n* {{cite journal| author=[[Samuel Karlin|Karlin, Samuel]] and [[Lloyd Shapley|Shapley, Lloyd]]|title=Geometry of moment spaces| journal=Mem. Amer. Math. Soc. | volume=12| year=1953}}\n* {{cite book | author=[[Samuel Karlin|Karlin, Samuel]] and Studden, William J.| title=Tchebycheff systems: With applications in analysis and statistics| publisher=Wiley-Interscience| year=1966| title-link=Chebyshev polynomials}}\n* {{cite book|author1=Dette, Holger  |author2=Studden, William J. |lastauthoramp=yes |title=The Theory of canonical moments with applications in statistics, probability, and analysis| publisher=John Wiley & Sons Inc.|year=1997|title-link=Moment problem }}\n</ref>\n\n==History==\nIn 1815, an article on optimal designs for [[polynomial regression]] was published by [[Joseph Diaz Gergonne]], according to [[Stephen M. Stigler|Stigler]].\n\n[[Charles Sanders Peirce|Charles S. Peirce]] proposed an economic theory of scientific experimentation in 1876, which sought to maximize the precision of the estimates. Peirce's optimal allocation immediately improved the accuracy of gravitational experiments and was used for decades by Peirce and his colleagues. In his 1882 published lecture at [[Johns Hopkins University]], Peirce introduced experimental design with these words:\n<blockquote>\nLogic will not undertake to inform you what kind of experiments you ought to make in order best to determine the acceleration of gravity, or the value of the Ohm; but it will tell you how to proceed to form a plan of experimentation.<br />\n<br />[....] Unfortunately practice generally precedes theory, and it is the usual fate of mankind to get things done in some boggling way first, and find out afterward how they could have been done much more easily and perfectly.<ref>Peirce, C. S. (1882), \"Introductory Lecture on the Study of Logic\" delivered September 1882, published in ''Johns Hopkins University Circulars'', v. 2, n. 19, pp. 11–12, November 1882, see p. 11, ''Google Books'' [https://books.google.com/books?id=E0YFAAAAQAAJ&pg=PA11&dq=%22Logic+will+not+undertake+to+inform%22+%22unfortunately+practice+generally%22 Eprint]. Reprinted in ''Collected Papers'' v. 7, paragraphs 59–76, see 59, 63, ''Writings of Charles S. Peirce'' v. 4, pp. 378–82, see 378, 379, and ''The Essential Peirce'' v. 1, pp. 210–14, see 210–1, also lower down on 211.</ref>\n</blockquote>\n\n[[Kirstine Smith]] proposed optimal designs for polynomial models in 1918. (Kirstine Smith had been a student of the Danish statistician [[Thorvald N. Thiele]] and was working with [[Karl Pearson]] in London.)\n\n==See also==\n{{col-begin}}\n{{col-1-of-3}}\n*[[Bayesian experimental design]]\n*[[Blocking (statistics)]]\n*[[Computer experiment]]\n*[[Convex function]]\n*[[Convex optimization|Convex minimization]]\n*[[Design of experiments]]\n{{col-2-of-3}}\n*[[Efficiency (statistics)]]\n*[[Entropy (information theory)]]\n*[[Fisher information]]\n*[[Glossary of experimental design]]\n*[[Hadamard's maximal determinant problem]]\n*[[Information theory]]\n{{col-3-of-3}}\n*[[Jack Kiefer (mathematician)|Kiefer, Jack]]\n*[[Replication (statistics)]]\n*[[Response surface methodology]]\n*[[Statistical model]]\n*[[Abraham Wald|Wald, Abraham]]\n*[[Jacob Wolfowitz|Wolfowitz, Jacob]]\n{{col-end}}\n\n==Notes==\n{{Reflist|30em}}\n\n==References==\n* {{cite book\n    |first1=A. C.\n    |last1=Atkinson\n    |first2=A. N.\n    |last2=Donev\n    |first3=R. D.\n    |last3=Tobias    |url=http://www.us.oup.com/us/catalog/general/subject/Mathematics/ProbabilityStatistics/~~/dmlldz11c2EmY2k9OTc4MDE5OTI5NjYwNg\n    |title=Optimum experimental designs, with '''SAS'''\n    |publisher=[[Oxford University Press]]\n    |year=2007\n    |pages=511+xvi\n    |isbn=978-0-19-929660-6\n    |ref=harv\n}}\n* {{cite book\n    |authorlink=Herman Chernoff\n    |last=Chernoff\n    |first=Herman\n    |title=Sequential analysis and optimal design\n    |publisher=Society for Industrial and Applied Mathematics\n    |year=1972\n    |isbn=978-0-89871-006-9\n}}\n* {{cite book\n    | last=Fedorov\n    | first=V. V.\n    | title=Theory of Optimal Experiments\n    | publisher=Academic Press\n    | year=1972\n}}\n* {{cite book\n    | last1=Fedorov\n    | first1=Valerii V.\n    | last2=Hackl\n    | first2=Peter\n    | title=Model-Oriented Design of Experiments\n    | series=Lecture Notes in Statistics\n    | volume=125\n    | publisher=Springer-Verlag\n    | year=1997\n    | ref=harv\n}}\n* {{cite book\n    | last=Goos\n    | first=Peter\n    | title=The Optimal Design of Blocked and Split-plot Experiments\n    | url=http://users.telenet.be/peter.goos/springer.htm\n    | series=[https://www.springer.com/series/694 Lecture Notes in Statistics]\n    | volume=164\n    | publisher=Springer\n    | year=2002\n    |ref=harv\n}}\n* {{cite book\n    |authorlink=Jack Kiefer (mathematician)\n    |last=Kiefer\n    |first=Jack&nbsp;Carl\n    |title=Jack&nbsp;Carl Kiefer: Collected papers&nbsp;III—Design of experiments\n    |editor1-link=Lawrence D. Brown\n    |editor1-last=Brown\n    |editor2-first=Ingram\n    |editor2-link=Ingram Olkin\n    |editor2-last=Olkin\n    |editor3-first=Jerome\n    |editor3-last=Sacks\n    |editor3-link=Jerome Sacks\n    |editor4-first=Henry P.\n    |display-editors = 3\n    |editor4-last=Wynn\n    |editor4-link=Henry P. Wynn\n    |publisher=Springer-Verlag and the Institute of Mathematical Statistics\n    |year=1985\n    |pages=718+xxv\n    |isbn=978-0-387-96004-3\n    |ref=harv\n}}\n* {{cite book\n    |last1=Logothetis\n    |first1=N.\n    |authorlink=Nicholas Logothetis\n    |last2=Wynn\n    |first2=H.&nbsp;P.\n    |authorlink2=Henry&nbsp;P. Wynn\n    |title=Quality through design: Experimental design, off-line quality&nbsp;control, and Taguchi's contributions\n    |publisher=Oxford U.&nbsp;P.\n    |year=1989\n    |pages=464+xi\n    |isbn=978-0-19-851993-5\n    |ref=harv\n}}\n* {{cite journal\n    |first=Kenneth\n    |last=Nordström\n    |date=May 1999\n    |title=The life and work of Gustav Elfving\n    |journal=Statistical Science\n    |volume=14\n    |issue=2\n    |pages=174–196\n    |mr=1722074\n    |doi=10.1214/ss/1009212244\n    |jstor=2676737\n    |ref=harv\n}}\n* {{cite book\n    |last=Pukelsheim\n    |first=Friedrich\n    |authorlink=Friedrich Pukelsheim\n    |url=http://www.ec-securehost.com/SIAM/CL50.html\n    |title=Optimal design of experiments\n    |publisher=[[Society for Industrial and Applied Mathematics]]\n    |series=Classics in Applied Mathematics\n    |volume=50|year=2006\n    |edition=republication with errata-list and new preface of Wiley (0-471-61971-X) 1993\n    | pages=454+xxxii\n    |isbn=978-0-89871-604-7\n    |ref=harv\n}}\n* {{cite book\n    |author1=Shah, Kirti R.  |author2=Sinha, Bikas K.\n     |lastauthoramp=yes | title=Theory of Optimal Designs\n    | series=[https://www.springer.com/series/694 Lecture Notes in Statistics]\n    | volume=54\n    | publisher=Springer-Verlag\n    | year=1989\n    | pages=171+viii\n    |isbn=978-0-387-96991-6\n}}\n\n==Further reading==\n\n===Textbooks for practitioners and students===\n\n====Textbooks emphasizing regression and response-surface methodology====\nThe textbook by Atkinson, Donev and Tobias has been used for [https://www.amstat.org/meetings/jsm/2009/index.cfm?fuseaction=workshops#mon short courses for industrial practitioners] as well as [http://www.maths.manchester.ac.uk/undergraduate/ugstudies/units/2008-09/level3/MATH38082/index.php university courses].\n\n* {{cite book\n    |first1=A. C.\n    |last1=Atkinson\n    |first2=A. N.\n    |last2=Donev\n    |first3=R. D.\n    |last3=Tobias\n    |title=Optimum experimental designs, with '''SAS'''\n    |publisher= Oxford University Press\n    | url = http://www.us.oup.com/us/catalog/general/subject/Mathematics/ProbabilityStatistics/~~/dmlldz11c2EmY2k9OTc4MDE5OTI5NjYwNg\n    |year=2007\n    |pages=511+xvi\n    |isbn=978-0-19-929660-6\n    |oclc= \n    |doi=\n    |ref=harv\n}}\n\n* {{cite book\n    |last1=Logothetis\n    |first1=N.\n    |authorlink=Nicholas Logothetis\n    |last2=Wynn|first2=H. P.\n    |authorlink2=Henry P. Wynn\n    |title=Quality through design: Experimental design, off-line quality control, and Taguchi's contributions\n    |publisher=Oxford U. P.\n    |year=1989\n    |pages=464+xi\n    |isbn=978-0-19-851993-5\n    |ref=harv\n}}\n\n====Textbooks emphasizing block designs====\nOptimal [[Randomized block design|block designs]] are discussed by Bailey and by Bapat. The first chapter of Bapat's book reviews the [[linear algebra]] used by Bailey (or the advanced books below). Bailey's exercises and discussion of [[random assignment|randomization]] both emphasize statistical concepts (rather than algebraic computations).\n\n* {{cite book\n    | last=Bailey\n    | first=R. A.\n    | authorlink=Rosemary A. Bailey\n    | title=Design of Comparative Experiments\n    | publisher= Cambridge U. P.\n    | year=2008\n    | isbn=978-0-521-68357-9\n    | url=http://www.maths.qmul.ac.uk/~rab/DOEbook\n}} Draft available on-line. (Especially Chapter 11.8 \"Optimality\")\n\n* {{cite book\n    | author=[http://www.isid.ac.in/~rbb/ Bapat, R. B.]\n    | title=Linear Algebra and Linear Models\n    | url=https://www.springer.com/math/algebra/book/978-0-387-98871-9?cm_mmc=Google-_-Book%20Search-_-Springer-_-0\n    | edition=Second\n    | publisher=Springer\n    | year=2000\n    | isbn=978-0-387-98871-9\n}} (Chapter 5 \"Block designs and optimality\", pages 99–111)\nOptimal [[Randomized block design|block designs]] are discussed in the advanced monograph by Shah and Sinha and in the survey-articles by Cheng and by Majumdar.\n\n===Books for professional statisticians and researchers===\n\n* {{cite book\n    | author=[[Herman Chernoff|Chernoff, Herman]]\n    | title=Sequential Analysis and Optimal Design \n    | publisher=[[Society for Industrial and Applied Mathematics|SIAM]]\n    | year=1972 \n    | isbn=978-0-89871-006-9\n| title-link=Sequential analysis \n    }}\n\n* {{cite book\n    | author=[http://www.cceb.upenn.edu/faculty/index.php?id=60 Fedorov, V. V.]\n    | title=Theory of Optimal Experiments\n    | publisher=Academic Press\n    | year=1972\n}}\n\n* {{cite book\n    | author=[http://www.cceb.upenn.edu/faculty/index.php?id=60 Fedorov, Valerii V.] and Hackl, Peter\n    | title=Model-Oriented Design of Experiments\n    | series=[https://www.springer.com/series/694 Lecture Notes in Statistics]\n    | volume=125\n    | publisher=Springer-Verlag\n    | year=1997\n}}\n\n* {{cite book\n    | author=[http://www.biw.kuleuven.be/biosyst/mebios/biostatistics-group Goos, Peter]\n    | title=The Optimal Design of Blocked and Split-plot Experiments\n    | url=http://users.telenet.be/peter.goos/springer.htm\n    | series=[https://www.springer.com/series/694 Lecture Notes in Statistics]\n    | volume=164\n    | publisher=Springer\n    | year=2002\n}}\n\n* {{cite book\n    |author1=[http://www.biw.kuleuven.be/biosyst/mebios/biostatistics-group Goos, Peter]\n    |author2=[https://www.jmp.com/en_nl/events/analytically-speaking/thought-leaders/jones-bradley.html Jones, Bradley]\n    |lastauthoramp=yes \n    |title=Optimal design of experiments: a case study approach\n    |url=http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470744618.html\n    |publisher=Chichester Wiley\n    |year=2011\n    |pages=304\n    |isbn=978-0-470-74461-1\n}}\n\n* {{cite book\n    |author=[[Jack Kiefer (mathematician)|Kiefer, Jack Carl]].\n    |title=Jack Carl Kiefer Collected Papers III Design of Experiments\n    | editors=[[Lawrence D. Brown|Brown, Lawrence D.]] and [[Ingram Olkin|Olkin, Ingram]] and [http://www.niss.org/people/sacks.html Jerome Sacks] and [http://www.lse.ac.uk/collections/cats/People/HenryPage.htm Wynn, Henry P]\n    | publisher=Springer-Verlag and the [[Institute of Mathematical Statistics]]\n    |year=1985\n    | pages=718+xxv\n    | isbn=978-0-387-96004-3\n|title-link=Jack Kiefer (mathematician)\n    }}\n\n* {{cite book\n    |author=[http://www.math.uni-augsburg.de/stochastik/pukelsheim/ Pukelsheim, Friedrich]\n    |title=Optimal Design of Experiments \n    |url=https://books.google.com/books?id=5ZcfDZUJ4F8C |publisher=[[Society for Industrial and Applied Mathematics]]\n    | series=[http://www.siam.org/books/series/cl.php Classics in Applied Mathematics]\n    | volume=50|year=2006\n    | edition=republication with errata-list and new preface of Wiley (0-471-61971-X) 1993\n    | pages=454+xxxii\n    |isbn=978-0-89871-604-7\n}}\n\n* {{cite book\n    |author1=Shah, Kirti R.  |author2=Sinha, Bikas K.\n     |lastauthoramp=yes | title=Theory of Optimal Designs\n    | series=[https://www.springer.com/series/694 Lecture Notes in Statistics]\n    | volume=54\n    | publisher=Springer-Verlag\n    | year=1989\n    | pages=171+viii\n    |isbn=978-0-387-96991-6\n}}\n\n<!--\n* {{cite book\n    |author=Silvey, S. D.\n    |title=Optimal Design: An Introduction to the Theory for [[Parameter estimation|Parameter Estimation]]\n    |publisher=Chapman and Hall\n    |year=1980\n    |pages=86+viii\n    |isbn=0-412-22910-2\n}} -->\n\n===Articles and chapters===\n* {{cite journal\n    | doi=10.1214/ss/1177009939\n    |author1=Chaloner, Kathryn  |author2=Verdinelli, Isabella\n     |lastauthoramp=yes | year=1995\n    |  title=Bayesian Experimental Design: A Review\n    | journal=[[Statistical Science]]\n    | volume=10\n    |issue=3\n    | pages=273–304\n|citeseerx=10.1.1.29.5355|title-link=Bayesian experimental design  }}\n\n* {{cite book\n    | title=Design and Analysis of Experiments\n    | series=Handbook of Statistics\n    | volume=13\n    |editor=Ghosh, S. |editor2=[[Calyampudi Radhakrishna Rao|Rao, C. R.]]\n    | publisher=North-Holland\n    | year=1996\n    | isbn=978-0-444-82061-7\n}}\n** {{cite book\n    | title=Design and Analysis of Experiments\n    | series=Handbook of Statistics\n    | chapter=[[Statistical model|Model]] [[Robust statistics|Robust]] Designs\n    |pages=1055–1099\n}}\n** {{cite book\n    | author=Cheng, C.-S\n    | title=Design and Analysis of Experiments\n    | series=Handbook of Statistics\n    | chapter=Optimal Design: Exact Theory\n    |pages=977–1006\n}}\n** {{cite book\n    | author=DasGupta, A\n    | title=Design and Analysis of Experiments\n    | series=Handbook of Statistics\n    | chapter=Review of Optimal [[Bayesian experimental design|Bayesian Designs]] |pages=1099–1148\n}}\n** {{cite book\n    |author1=Gaffke, N.  |author2=Heiligers, B\n     |lastauthoramp=yes | title=Design and Analysis of Experiments\n    | series=Handbook of Statistics\n    | chapter=Approximate Designs for [[Response surface methodology|Polynomial Regression]]: [[Invariant estimator|Invariance]], [[Admissible decision rule|Admissibility]], and Optimality\n    |pages=1149–1199\n}}\n** {{cite book\n    | title=Design and Analysis of Experiments\n    | series=Handbook of Statistics\n    | author=Majumdar, D\n    | chapter=Optimal and Efficient Treatment-Control Designs\n    |pages=1007–1054\n}}\n** {{cite book\n    | title=Design and Analysis of Experiments\n    | series=Handbook of Statistics\n    | author=Stufken, J\n    | chapter=Optimal [[Crossover study|Crossover Designs]]\n    |pages=63–90\n}}\n** {{cite book\n    | title=Design and Analysis of Experiments\n    | series=Handbook of Statistics\n    | author=Zacks, S\n    | chapter=Adaptive Designs for Parametric Models\n    |pages=151–180\n}}\n\n* {{cite journal\n    |author=Kôno, Kazumasa\n    |year=1962\n    |title=Optimum designs for quadratic regression on ''k''-cube\n    |journal=Memoirs of the Faculty of Science. Kyushu University. Series '''A'''. Mathematics\n    |volume=16\n    |pages=114–122\n    |url=http://www.ams.org/mathscinet/pdf/153090.pdf\n    |doi=10.2206/kyushumfs.16.114\n    |issue=2\n}}\n\n===Historical===\n*{{cite journal\n    |title=The application of the method of least squares to the interpolation of sequences\n    |author=[[Joseph Diaz Gergonne|Gergonne, J. D.]]\n    |journal=Historia Mathematica\n    |volume=1\n    |issue=4\n    |date=November 1974 |origyear=1815\n    |pages=439–447\n    |edition=Translated by Ralph St. John and [[Stephen M. Stigler|S. M. Stigler]] from the 1815 French\n    |doi=10.1016/0315-0860(74)90034-2\n    |url=http://www.sciencedirect.com/science/article/B6WG9-4D7JMHH-20/2/df451ec5fbb7c044d0f4d900af80ec86\n}}\n\n*{{cite journal\n    |title=Gergonne's 1815 paper on the design and analysis of polynomial regression experiments\n    |author=[[Stephen M. Stigler|Stigler, Stephen M.]]\n    |journal=Historia Mathematica\n    |volume=1\n    |issue=4\n    |date=November 1974\n    |pages=431–439\n    |doi=10.1016/0315-0860(74)90033-0\n    |url=http://www.sciencedirect.com/science/article/B6WG9-4D7JMHH-1Y/2/680c7ada0198761e9866197d53512ab4\n}}\n\n* {{cite journal\n| author=[[Charles Sanders Peirce|Peirce, C. S]] | year=1876| title=Note on the Theory of the Economy of Research | journal=Coast Survey Report | pages=197–201}} (Appendix No. 14). [http://docs.lib.noaa.gov/rescue/cgs/001_pdf/CSC-0025.PDF#page=222 NOAA PDF Eprint]. Reprinted in {{cite book| year=1958 | title=Collected Papers of Charles Sanders Peirce | volume=7 | title-link=Charles Sanders Peirce bibliography#CP }} paragraphs 139–157, and in {{cite journal\n| last1=Peirce\n| first1=C. S.\n|date=July–August 1967| title=Note on the Theory of the Economy of Research\n| journal=Operations Research\n|volume=15 | issue=4\n| pages=643–648\n| doi=10.1287/opre.15.4.643\n}} [https://www.jstor.org/stable/168276 Abstract at JSTOR].\n\n* {{cite journal\n|author=[http://www.webdoe.cc/publications/kirstine.php Smith, Kirstine]\n|title=On the Standard Deviations of Adjusted and Interpolated Values of an Observed Polynomial Function and its Constants and the Guidance They Give Towards a Proper Choice of the Distribution of the Observations\n|year=1918\n|journal= Biometrika\n|volume=12\n|issue=1/2\n|pages=1–85\n|jstor=2331929\n|doi=10.2307/2331929}}\n\n{{Experimental design|state=expanded}}\n<!-- {{Least Squares and Regression Analysis|state=collapsed}} -->\n{{Statistics|collection|state=collapsed}}\n\n<!-- Many Optimal designs are optimal for ANOVA or model-discrimination tests -->\n\n[[Category:Design of experiments]]\n[[Category:Regression analysis]] <!-- Many Optimal designs are optimal for estimating regression coefficients -->\n[[Category:Statistical theory]]\n[[Category:Optimal decisions]]\n[[Category:Mathematical optimization]]\n[[Category:Industrial engineering]]\n[[Category:Systems engineering]]\n[[Category:Statistical process control]]"
    },
    {
      "title": "Optimistic knowledge gradient",
      "url": "https://en.wikipedia.org/wiki/Optimistic_knowledge_gradient",
      "text": "{{Orphan|date=June 2015}}\n\nIn [[statistics]] The '''optimistic knowledge gradient'''<ref>[http://www.jmlr.org/papers/volume16/chen15a/chen15a.pdf] Statistical Decision Making for Optimal Budget Allocation in Crowd Labeling Xi Chen, Qihang Lin, Dengyong Zhou; 16(Jan):1−46, 2015.</ref> is  a new approximation policy proposed by Xi Chen, Qihang Lin and Dengyong Zhou in 2013.  This policy is created to solve the challenge of computationally intractable of large size of [[optimal computing budget allocation]] problem in binary/multi-class crowd labeling where each label from the crowd has a certain cost.<ref>[https://www.cs.cmu.edu/~xichen/images/ICML_Crowd_Budget.pdf] Proceedings of the 30-th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR:W&CP volume 28.  Xi Chen, Qihang Lin, Dengyong Zhou</ref>\n\n==Motivation==\nThe [[optimal computing budget allocation]] problem is formulated as a Bayesian [[Markov decision process]]<ref>*[http://www.eecs.umich.edu/~baveja/Papers/Thesis.ps.gz Learning to Solve Markovian Decision Processes] by [http://www.eecs.umich.edu/~baveja/ Satinder P. Singh]</ref>(MDP) and is solved by using the [[dynamic programming]] (DP) algorithm where the Optimistic knowledge gradient policy is used to solve the computationally intractable of the [[dynamic programming]]<ref>[http://20bits.com/articles/introduction-to-dynamic-programming/ An Introduction to Dynamic Programming]</ref> (DP) algorithm.\n\nConsider a budget allocation issue in [[crowdsourcing]]. The particular crowdsourcing problem we considering is crowd labeling. Crowd labeling is a large amount of [[labeling]] tasks which are hard to solve by machine, turn out to easy to solve by human beings, then we just outsourced to an unidentified group of random people in a distributed environment.\n\n==Methodology==\nWe want to finish this labeling tasks rely on the power of the crowd hopefully. For example, suppose we want to identify a picture according to the people in a picture is adult or not, this is a [[Bernoulli distribution|Bernoulli]] labeling problem, and all of us can do in one or two seconds, this is an easy task for human being. However, if we have tens of thousands picture like this, then this is no longer the easy task any more. That's why we need to rely on [[crowdsourcing]] framework to make this fast. [[Crowdsourcing]] framework of this consists of two steps. Step one, we just dynamically acquire from the crowd for items. On the other sides, this is dynamic procedure. We don't just send out this picture to everyone and we focus every response, instead, we do this in quantity. We are going to decide which picture we send it in the next, and which worker we are going to hire in the crowd in the next. According to his or her historical labeling results. And each picture can be sent to multiple workers and every worker can also work on different pictures. Then after we collect enough number of labels for different picture, we go to the second steps where we want to infer true label of each picture based on the collected labels. So there are multiple ways we can do inference. For instance, the simplest we can do this is just majority vote. The problem is that no free lunch, we have to pays for worker for each label he or she provides and we only have a limited project budget. So the question is how to spend the limited budget in a smart way.\n\n==Challenges==\nBefore showing the mathematic model, the paper mentions what kinds of challenges we are facing.\n\n=== Challenge 1 ===\nFirst of all, the items have a different level of difficulty to compute the label, in a previous example, some picture are easy to classify. In this case, you will usually see very consistent labels from the crowd. However, if some pictures are ambiguous, people may disagree with each other resulting in highly inconsistent labelling. So we may allocate more resources on this ambiguous task.\n\n===Challenge 2===\nAnd another difficulty we often have is that the worker are not perfect, sometimes this worker are not responsible, they just provide the [[random]] label, therefore, of course, we would not spend our budget on this no reliable workers. Now the problem is both the difficulty of the pictures and the reliability of the worker we completely unknown at the beginning. We can only estimate them during the procedure. Therefore, we are naturally facing to exploration and exploitation, and our goal is to give a reasonable good policy to spend money to the right way–maximize the overall accuracy of final inferred labels.\n\n==Mathematical model==\nFor the mathematical model, we have the ''K'' items, <math>i = \\{1,2,\\ldots,k\\}</math>, and total budget is ''T'' and we assume each label cost 1 so we are going to have ''T'' labels eventually. We assume each items has true label <math>Z_i</math>which positive or negative, this binomial cases and we can extended to multiple class, labeling cases, this a singular idea. And the positive set <math>H^*</math> is defined as the set of items whose true label is positive. And <math>\\theta_i</math> also defined a soft-label, <math>\\theta_i</math> for each item which number between 0 and 1, and we define <math>\\theta_i</math> as underlying probability of being labeled as positive by a member randomly picked from a group of perfect workers.\n\nIn this first case, we assume for every worker is perfect, it means they all reliable, but being perfect doesn’t means this worker gives the same answer or right answer. It just means they will try their best to figure out the best answer in their mind, and suppose everyone is perfect worker, just randomly picked one of them, and with <math>\\theta_i</math> probability, we going to get a guy who believe this one is positive. That is how we explain <math>\\theta_i</math>. So we are assume a label <math>Y_i</math> is drawn from Bernoulli(<math>\\theta_i</math>), and <math>\\theta_i</math> must be consistent with the true label, which means <math>\\theta_i</math> is greater or equal to 0.5 if and only if this item is positive with a true positive label. So our goal is to learn H*, the set of positive items. In other word, we want to make an inferred positive set H based on collected labels to maximize:\n\n: <math>\n\\sum_{i=1}^k (\\textbf{1}_{(i\\in H)}\\textbf{1}_{(i\\in H^\\star)}+\\textbf{1}_{(i\\notin H)} \\textbf{1}_{(i\\notin H^\\star)})\n</math>\n\nIt can also be written as:\n\n: <math>|H\\cap H^\\star| + |H^c\\cap H^{\\star c}|</math>\n\n=== step1: Bayesian decision process===\nBefore show the Bayesian framework, the paper use an example to mention why we choose Bayesian instead of frequency approach, such that we can propose some posterior of prior distribution on the soft-label <math>\\theta_i</math>. We assume each <math>\\theta_i</math> is drawn from a known Beta prior:\n\n: <math>\\theta_i \\sim \\mathrm{Beta}(a_i^o,b_i^o)</math>\n\nAnd the matrix:\n\n: <math>s^o = \\left \\langle (a_i^o,b_i^o)\\right \\rangle_{i=1}^k \\in \\textbf{R}^{k\\times2}</math>\n\nSo we know that the Bernoulli conjugate of beta, so once we get a new label for item i, we going to update posterior distribution, the beta distribution by:\n\n: <math>\\theta_i \\sim \\mathrm{Beta}(a_i^t,b_i^t)</math>\n\n: <math>y_i\\mid \\theta_i\\sim \\mathrm{Bernoulli}(\\theta_i)</math>\n\n: <math>\\theta_i\\mid y_i = 1\\sim \\mathrm{Beta}(a_i^t+1,b_i^t)</math>\n\n: <math>\\theta_i\\mid y_i = -1\\sim \\mathrm{Beta}(a_i^t+1,b_i^t)</math>\n\nDepending on the label is positive or negative.\n\nHere is the whole procedure in the high level, we have T stage, <math>0\\le t \\le T-1</math>. And in current stage we look at matrix S, which summarized the posterior distribution information for all the <math>\\theta_i</math>\n\n: <math>s^t = \\left \\langle (a_i^t,b_i^t)\\right \\rangle_{i=1}^k \\in \\textbf{R}^{k\\times2}</math>\n\nWe are going to make a decision, choose the next item to label <math>i_t</math>, <math>i_t \\in \\{1,2,\\ldots,k\\}</math>.\n\nAnd depending what the label is positive or negative, we add a matrix to getting a label:\n\n: <math>\\theta_i \\sim \\mathrm{Beta}(a_i^t,b_i^t)</math>\n\n: <math>y_i\\mid \\theta_i\\sim \\mathrm{Bernoulli}(\\theta_i)</math>\n\n: <math>\\theta_i\\mid y_i = 1\\sim \\mathrm{Beta}(a_i^t+1,b_i^t)</math>\n\n: <math>\\theta_i\\mid y_i = -1\\sim \\mathrm{Beta}(a_i^t+1,b_i^t)</math>\n\nAbove all, this is the whole framework.\n\n=== step2: Inference on positive set===\nWhen the ''t'' labels are collected, we can make an inference about the positive set ''H''<sub>''t''</sub> based on posterior distribution given by ''S''<sub>''t''</sub>\n\n: <math>\n\\begin{align}\nH_t & = \\operatorname{argmax}\\limits_{H \\subset\\{1,2,\\ldots,k\\}} E \\left( \\sum_{i=1}^k (\\textbf{1}(i\\in H)\\textbf{1}(i\\in H^\\star)+\\textbf{1}(i\\notin H) \\textbf{1}{(i\\notin H^{\\star})})\\mid S^\\star\\right) \\\\\n& =\\operatorname{argmax}\\limits_{H \\subset\\{1,2,\\ldots,k\\}} \\sum_{i=1}^k (\\textbf{1}(i\\in H) \\Pr(i\\in H^\\star\\mid S^t) +\\textbf{1}(i\\notin H) \\Pr(i\\notin H^\\star \\mid S^t)) \\\\\n& =\\{i:\\Pr(i\\in H^\\star\\mid S^t)\\geq0.5\\}\n\\end{align}\n</math>\n\nSo here become the Bernoulli selection problem, we just take to look at the probability of being positive or being negative conditional <math>S_t</math> to see is greater than 0.5 or not, if it is greater than 0.5, then we prove this item into the current infer positive set <math>H_t</math> so this is a cost form for current optimal solution <math>H_t</math> based on the information in <math>S_t</math>.\n\nAfter know what is optimal solution, then the paper show what is the optimal value. Plug <math>t</math> in the optimal function,\n\n: <math>h(x) = \\max(x,1-x)</math>\n\nThis function is just a single function which choose the larger one between the conditional probability of being positive and being negative. Once we get one more label for item i, we take a difference between this value, before and after we get a new label, we can see this conditional probability can actually simplify as follows:\n\n: <math>\n\\begin{align}\nR(s^t,i_t,y_{i_t}) & = \\sum_{i=1}^k h(\\Pr{(i\\in H^\\star\\mid s^{t+1})})-\\sum_{i=1}^k h(\\Pr(i\\in H^\\star\\mid s^t)) \\\\\n& = \\sum_{i=1}^k h(\\Pr{(a_i^{t+1,b_i^{t+1}})})-\\sum_{i=1}^k h(\\Pr(a_i^t,b_i^t)).\n\\end{align}\n</math>\n\nThe positive item being positive only depends on the beta posterior, therefore, if only the function of parameter of beta distribution function are ''a'' and ''b'', as\n\n: <math>h(\\Pr(a_{i_t}^{t+1},b_{i_t}^{t+1}))-h(\\Pr(a_{i_t}^t,b_{i_t}^t))</math>\n\nOne more label for this particular item, we double change the posterior function, so all of this items can be cancel except 1, so this is the change for whole accuracy and we defined as stage-wise reward: improvement the inference accuracy by one more sample. Of course this label have two positive value, we’ve get positive label or negative label, take average for this two, get expect reward. We just choose item to be label such that the expect reward is maximized using '''Knowledge Gradient''':\n\n: <math>\n\\begin{align}\ni_t & = \\operatorname{argmax}\\limits_{i \\in\\{1,2,\\ldots,k\\}} E(R(s^t,i,y_i)\\mid s^t) \\\\\n& = \\operatorname{argmax}\\limits_{i \\in\\{1,2,\\ldots,k\\}} \\left(\\frac{a_i^t}{a_i^t+b_i^t} R(s^t,i,1)+\\frac{b_i^t}{a_i^t+b_i^t}R(s^t,i,-1)\\right)\n\\end{align}\n</math>\n\nThey are multiple items, let us know how do we break the ties. If we break the tie deterministically, which means we choose the smallest index. We are going to have a problem because this is not consistent which means the positive stage <math>H_t</math> does not converge to the true positive stage <math>H^*</math>.\n\nSo we can also try to break the ties randomly, it works, however, we will see the performance is almost like uniform sampling, is the best reward. The writer’s policy is kinds of more greedy, instead of choosing the average in stage once reward, we can actually calculate the larger one, the max of the two stage possible reward, so '''Optimistic Knowledge Gradient''':\n\n: <math>i_t = \\operatorname{argmax}\\limits_{i\\in\\{1,\\ldots,k\\}}(R^+(S^t,i)) = \\max(R(S^t,i,1),R(S^t,i,-1))</math>\n\nAnd we know under optimistic knowledge gradient, the final inference accuracy converge to 100%. Above is based on every worker is perfect, however, in practice, workers are not always responsible. So if in imperfect workers, we assume K items, <math>1\\leq i \\leq k</math>.\n\n: <math>\\theta_i\\in(0,1)\\sim \\mathrm{Bet}a(a_i^o,b_i^o)</math>\n\nThe probability of item <math>i</math> being labeled as positive by a perfect worker.\nM workers, <math>1\\leq j \\leq M</math> , <math>\\rho_j\\in (0,1)\\sim \\mathrm{Beta}(c_j^o,d_j^o)</math>\nThe probability of worker <math>j</math> giving the same label as a perfect worker. Distribution of the label <math>Z_{ij}</math> from worker <math>j</math> to item <math>i</math>:\n\n: <math>\\Pr(Z_{ij}=1\\mid \\theta_i,\\rho_j) = \\Pr(Z_{ij}=1\\mid Y_i =1) \\Pr(Y_i=1)+\\Pr(Z_{ij}=1\\mid Y_i = -1)\\Pr(Y_i = -1)=\\rho_j\\theta_i t (1-\\rho_j)(1-\\theta_i)</math>\n\nAnd the action space is that\n\n: <math>\n\\Pr(Z_{ij}=1\\mid \\theta_i,\\rho_j) = Pr(Z_{ij}=1\\mid Y_i =1) \\Pr(Y_i=1)+\\Pr(Z_{ij}=1\\mid Y_i = -1)\\Pr(Y_i = -\n1)=\\rho_j\\theta_i t (1-\\rho_j)(1-\\theta_i)=\\rho_j\\theta_i t (1-\\rho_j)(1-\\theta_i),\n</math>\n\nwhere <math>\\qquad\\qquad (i,j)\\in \\{1,2,\\ldots,k\\}\\times\\{1,2,\\ldots,M\\}</math>, label matrix: <math>Z_{ij}\\in\\{-1,1\\}</math>\n\nIt is difficult to calculate, so we can use [[Variational Bayesian methods]]<ref>* [http://www.gatsby.ucl.ac.uk/vbayes/ Variational-Bayes Repository] A repository of papers, software, and links related to the use of variational methods for approximate Bayesian learning \n</ref> of <math>\\Pr(i\\in H^\\star\\mid S^t)</math>\n\n== References ==\n{{Reflist}}\n\n\n\n[[Category:Mathematical optimization]]\n[[Category:Markov processes]]"
    },
    {
      "title": "P versus NP problem",
      "url": "https://en.wikipedia.org/wiki/P_versus_NP_problem",
      "text": "{{pp-move-indef}}{{pp-semi-sock|small=yes}}\n{{Lead too long|date=April 2019}}\n{{unsolved|computer science|If the solution to a problem is easy to check for correctness, must the problem be easy to solve?}}\n[[File:Complexity classes.svg|thumb|250px|Diagram of complexity classes provided that '''P'''&nbsp;[[≠]]&nbsp;'''NP'''. The existence of problems within '''NP''' but outside both '''P''' and '''NP'''-complete, under that assumption, was established by [[NP-intermediate|Ladner's theorem]].<ref name=\"Ladner75\">R. E. Ladner \"On the structure of polynomial time reducibility,\" ''[[Journal of the ACM]]'' 22, pp. 151–171, 1975. Corollary 1.1. [http://portal.acm.org/citation.cfm?id=321877&dl=ACM&coll=&CFID=15151515&CFTOKEN=6184618 ACM site].</ref>]]\n{{Millennium Problems}}\n\nThe '''P versus NP problem''' is a major [[List of unsolved problems in computer science|unsolved problem in computer science]]. It asks whether every problem whose solution can be quickly verified (technically, verified in [[polynomial time]]) can also be solved quickly (again, in polynomial time).\n\nThe underlying issues were first discussed in the 1950s, in letters from [[John Forbes Nash Jr.]] to the [[National Security Agency]], and from [[Kurt Gödel]] to [[John von Neumann]]. The precise statement of the '''P''' versus '''NP''' problem was introduced in 1971 by [[Stephen Cook]] in his seminal paper \"The complexity of theorem proving procedures\"<ref>{{Cite book|last=Cook|first=Stephen|authorlink=Stephen Cook|year=1971|chapter=The complexity of theorem proving procedures|chapterurl=http://portal.acm.org/citation.cfm?coll=GUIDE&dl=GUIDE&id=805047|title=Proceedings of the Third Annual ACM Symposium on Theory of Computing|pages=151–158}}</ref> (and independently by [[Leonid Levin]] in 1973<ref>{{cite journal |author = L. A. Levin |editor=  |format= |url= http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=ppi&paperid=914&option_lang=rus |title= Универсальные задачи перебора |type=  |origyear= | agency =  |edition= Problems of Information Transmission  |location=  |date=  1973  |volume= 9 |number= 3|pages = 115–116 |series=  |isbn =  |issn =  |doi =  |bibcode =  |pmid =  |ref=  |archiveurl =  |archivedate =  |language= ru |quote=  }}</ref>) and is considered by many to be the most important open problem in [[computer science]].<ref>{{cite journal | last1 = Fortnow | first1 = Lance | authorlink = Lance Fortnow | year = 2009 | title = The status of the '''P''' versus '''NP''' problem | url = http://www.cs.uchicago.edu/~fortnow/papers/pnp-cacm.pdf | journal = Communications of the ACM | volume = 52 | issue = 9| pages = 78–86 | doi = 10.1145/1562164.1562186 }}</ref> It is one of the seven [[Millennium Prize Problems]] selected by the [[Clay Mathematics Institute]], each of which carries a US$1,000,000 prize for the first correct solution.\n\nThe informal term ''quickly'', used above, means the existence of an algorithm solving the task that runs in [[polynomial time]], such that the time to complete the task varies as a polynomial function on the size of the input to the algorithm (as opposed to, say, [[exponential time]]). The general class of questions for which some algorithm can provide an answer in polynomial time is called \"class '''P'''\" or just \"'''[[P (complexity)|P]]'''\". For some questions, there is no known way to find an answer quickly, but if one is provided with information showing what the answer is, it is possible to verify the answer quickly. The class of questions for which an answer can be ''verified'' in polynomial time is called '''[[NP (complexity)|NP]]''', which stands for \"nondeterministic polynomial time\".<ref group=\"Note\">A nondeterministic [[Turing machine]] can move to a state that is not determined by the previous state. Such a machine could solve an '''NP''' problem in polynomial time by falling into the correct answer state (by luck), then conventionally verifying it. Such machines are not practical for solving realistic problems but can be used as theoretical models.</ref>\n\nConsider [[Sudoku]], a game where the player is given a partially filled-in grid of numbers and attempts to complete the grid following certain rules. Given an incomplete Sudoku grid, of any size, is there at least one legal solution?  Any proposed solution is easily verified, and the time to check a solution grows slowly (polynomially) as the grid gets bigger.  However, all known algorithms for finding solutions take, for difficult examples, time that grows exponentially as the grid gets bigger.  So, Sudoku is in '''NP''' (quickly checkable) but does not seem to be in '''P''' (quickly solvable).  Thousands of other problems seem similar, in that they are fast to check but slow to solve.  Researchers have shown that many of the problems in '''NP''' have the extra property that a fast solution to any one of them could be used to build a quick solution to any other problem in '''NP''', a property called [[NP-complete|'''NP'''-completeness]].  Decades of searching have not yielded a fast solution to any of these problems, so most scientists suspect that none of these problems can be solved quickly.  This, however, has never been proven.\n\nAn answer to the '''P'''&nbsp;=&nbsp;'''NP''' question would determine whether problems that can be verified in polynomial time, like Sudoku, can also be solved in polynomial time. If it turned out that '''P'''&nbsp;≠&nbsp;'''NP''', it would mean that there are problems in '''NP'''  that are harder to compute than to verify: they could not be solved in polynomial time, but the answer could be verified in polynomial time.\n\nAside from being an important problem in computational theory, a proof either way would have profound implications for mathematics, cryptography, algorithm research, [[artificial intelligence]], [[game theory]], multimedia processing, [[philosophy]], [[economics]] and many other fields.<ref>{{Cite book|title=The Golden Ticket: P, NP, and the Search for the Impossible|last=Fortnow|first=Lance|publisher=Princeton University Press|year=2013|isbn=9780691156491|location=Princeton, NJ|pages=}}</ref>\n\n==History==\nAlthough the '''P''' versus '''NP''' problem was formally defined in 1971, there were previous inklings of the problems involved, the difficulty of proof, and the potential consequences.  In 1955, mathematician John Nash wrote a letter to the NSA, where he speculated that cracking a sufficiently complex code would require time exponential in the length of the key.<ref>{{cite web |title=Letters from John Nash |url=https://www.nsa.gov/Portals/70/documents/news-features/declassified-documents/nash-letters/nash_letters1.pdf |author=NSA |year=2012}} </ref>  If proved (and Nash was suitably skeptical) this would imply what is now called '''P'''&nbsp;≠&nbsp;'''NP''', since a proposed key can easily be verified in polynomial time. Another mention of the underlying problem occurred in a 1956 letter written by [[Kurt Gödel]] to [[John von Neumann]].  Gödel asked whether theorem-proving (now known to be [[co-NP-complete|'''co-NP'''-complete]]) could be solved in [[quadratic time|quadratic]] or [[linear time]],<ref>{{cite journal | last1 = Hartmanis | first1 = Juris | year = | title = Gödel, von Neumann, and the '''P''' = '''NP''' problem | url = http://ecommons.library.cornell.edu/bitstream/1813/6910/1/89-994.pdf | journal = Bulletin of the European Association for Theoretical Computer Science | volume = 38 | issue = | pages = 101–107 }}</ref> and pointed out one of the most important consequences—that if so, then the discovery of mathematical proofs could be automated.\n\n==Context==\nThe relation between the [[complexity class]]es '''P''' and '''NP''' is studied in [[computational complexity theory]], the part of the [[theory of computation]] dealing with the resources required during computation to solve a given problem. The most common resources are time (how many steps it takes to solve a problem) and space (how much memory it takes to solve a problem).\n\nIn such analysis, a model of the computer for which time must be analyzed is required. Typically such models assume that the computer is ''[[Deterministic computation|deterministic]]'' (given the computer's present state and any inputs, there is only one possible action that the computer might take) and ''sequential'' (it performs actions one after the other).\n\nIn this theory, the class '''P''' consists of all those ''[[decision problem]]s'' (defined [[#Formal definitions|below]]) that can be solved on a deterministic sequential machine in an amount of time that is [[polynomial]] in the size of the input; the class '''[[NP (complexity)|NP]]''' consists of all those decision problems whose positive solutions can be verified in [[polynomial time]] given the right information, or equivalently, whose solution can be found in polynomial time on a [[Non-deterministic Turing machine|non-deterministic]] machine.<ref>Sipser, Michael: ''Introduction to the Theory of Computation, Second Edition, International Edition'', page 270. Thomson Course Technology, 2006. Definition 7.19 and Theorem 7.20.</ref> Clearly, '''P''' ⊆ '''NP'''. Arguably the biggest open question in [[theoretical computer science]] concerns the relationship between those two classes:\n:Is '''P''' equal to '''NP'''?\nSince 2002, [[William Gasarch]] has conducted three polls of researchers concerning this and related questions.<ref name=\"poll\">{{Cite journal|author=William I. Gasarch| author1-link=William Gasarch | title=The '''P'''=?'''NP''' poll.|journal=[[SIGACT News]]|volume=33|issue=2|pages=34–47|date=June 2002| url=http://www.cs.umd.edu/~gasarch/papers/poll.pdf|doi=10.1145/564585.564599|accessdate=26 September 2018| citeseerx=10.1.1.172.1005 }}</ref><ref name=\"poll2\">{{Cite journal|author=William I. Gasarch| author1-link=William Gasarch | title=The Second '''P'''=?'''NP''' poll|journal=SIGACT News|volume=74|url=http://www.cs.umd.edu/~gasarch/papers/poll2012.pdf}}</ref><ref name=\"poll3\">{{cite web |url=https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper3.pdf |title=Guest Column: The Third P =? NP Poll1}}</ref>  Confidence that '''P'''&nbsp;≠&nbsp;'''NP''' has been increasing - in 2019, 88% believed '''P'''&nbsp;≠&nbsp;'''NP''', as opposed to 83% in 2012 and 61% in 2002.  When restricted to experts, the 2019 answers became 99% '''P'''&nbsp;≠&nbsp;'''NP'''.<ref name=\"poll3\" />\n\n==NP-completeness==\n[[File:P np np-complete np-hard.svg|thumb|300px|right|[[Euler diagram]] for '''[[P (complexity)|P]]''', '''[[NP (complexity)|NP]]''', '''NP'''-complete, and '''NP'''-hard set of problems (excluding the empty language and its complement, which belong to '''P''' but are not '''NP'''-complete)]]\n{{Main article|NP-completeness}}\nTo attack the '''P''' = '''NP''' question, the concept of '''NP'''-completeness is very useful. '''NP'''-complete problems are a set of problems to each of which any other '''NP'''-problem can be reduced in polynomial time and whose solution may still be verified in polynomial time. That is, any '''NP''' problem can be transformed into any of the '''NP'''-complete problems. Informally, an '''NP'''-complete problem is an '''NP '''problem that is at least as \"tough\" as any other problem in '''NP'''.\n\n[[NP-hard|'''NP'''-hard]] problems are those at least as hard as '''NP''' problems, i.e., all '''NP''' problems can be reduced (in polynomial time) to them. '''NP'''-hard problems need not be in '''NP''', i.e., they need not have solutions verifiable in polynomial time.\n\nFor instance, the [[Boolean satisfiability problem]] is '''NP'''-complete by the [[Cook–Levin theorem]], so ''any'' instance of ''any'' problem in '''NP''' can be transformed mechanically into an instance of the Boolean satisfiability problem in polynomial time. The Boolean satisfiability problem is one of many such '''NP'''-complete problems. If any '''NP'''-complete problem is in '''P''', then it would follow that '''P''' = '''NP'''. However, many important problems have been shown to be '''NP'''-complete, and no fast algorithm for any of them is known.\n\nBased on the definition alone it is not obvious that '''NP'''-complete problems exist; however, a trivial and contrived '''NP'''-complete problem can be formulated as follows: given a description of a [[Turing machine]] ''M'' guaranteed to halt in polynomial time, does there exist a polynomial-size input that ''M'' will accept?<ref name=\"Scott\">{{Cite web|author=Scott Aaronson|title=PHYS771 Lecture 6: '''P''', '''NP''', and Friends|url=http://www.scottaaronson.com/democritus/lec6.html |accessdate=27 August 2007}}</ref> It is in '''NP''' because (given an input) it is simple to check whether ''M'' accepts the input by simulating ''M''; it is '''NP'''-complete because the verifier for any particular instance of a problem in '''NP''' can be encoded as a polynomial-time machine ''M'' that takes the solution to be verified as input. Then the question of whether the instance is a yes or no instance is determined by whether a valid input exists.\n\nThe first natural problem proven to be '''NP'''-complete was the Boolean satisfiability problem, also known as SAT. As noted above, this is the Cook–Levin theorem; its proof that satisfiability is '''NP'''-complete contains technical details about Turing machines as they relate to the definition of '''NP'''. However, after this problem was proved to be '''NP'''-complete, [[reduction (complexity)|proof by reduction]] provided a simpler way to show that many other problems are also '''NP'''-complete, including the game Sudoku discussed earlier. In this case, the proof shows that a solution of Sudoku in polynomial time could also be used to complete [[Latin square]]s in polynomial time.<ref>{{cite web |title=NP-completeness of Sudoku |url=http://www.cs.ox.ac.uk/people/paul.goldberg/FCS/sudoku.html}}</ref>  This in turn gives a solution to the problem of partitioning [[multipartite graph|tri-partite graphs]] into triangles,<ref>{{cite article |author=Colbourn, Charles J. |title=The complexity of completing partial Latin squares |journal=Discrete Applied Mathematics |volume=8 |issue=1 |year=1984 |pages=25–30 }}</ref> which could then be used to find solutions for the special case of SAT known as 3-SAT,<ref>{{cite article |author=I. Holyer |title=The '''NP'''-completeness of some edge-partition problems |journal=SIAM J. Comput. |volume=10 |year=1981 |pages=713&ndash;717}}</ref> which then provides a solution for general Boolean satisfiability.  So a polynomial time solution to Sudoku leads, by a series of mechanical transformations, to a polynomial time solution of satisfiability, which in turn can be used to solve any other '''NP'''-problem in polynomial time.  Using transformations like this, a vast class of seemingly unrelated problems are all reducible to one another, and are in a sense \"the same problem\".\n\n==Harder problems==\n{{See also|Complexity class}}\n\nAlthough it is unknown whether '''P''' = '''NP''', problems outside of '''P''' are known. Just as the class '''P''' is defined in terms of polynomial running time, the class '''[[EXPTIME]]''' is the set of all decision problems that have ''exponential'' running time. In other words, any problem in '''EXPTIME''' is solvable by a [[deterministic Turing machine]] in [[big O notation|O]](2<sup>''p''(''n'')</sup>) time, where ''p''(''n'') is a polynomial function of ''n''. A decision problem is [[EXPTIME#EXPTIME-complete|'''EXPTIME'''-complete]] if it is in '''EXPTIME''', and every problem in '''EXPTIME''' has a [[polynomial-time many-one reduction]] to it. A number of problems are known to be '''EXPTIME'''-complete. Because it can be shown that '''P''' ≠ '''EXPTIME''', these problems are outside '''P''', and so require more than polynomial time. In fact, by the [[time hierarchy theorem]], they cannot be solved in significantly less than exponential time. Examples include finding a perfect strategy for [[chess]] positions on an ''N'' × ''N'' board<ref name=\"Fraenkel1981\">{{Cite journal| author = [[Aviezri Fraenkel]] and D. Lichtenstein| title = Computing a perfect strategy for ''n'' × ''n'' chess requires time exponential in ''n''| journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series A]]| volume = 31| issue = 2| year = 1981| pages = 199–214 | doi = 10.1016/0097-3165(81)90016-9}}</ref> and similar problems for other board games.<ref>{{Cite web|title=Computational Complexity of Games and Puzzles |url=http://www.ics.uci.edu/~eppstein/cgt/hard.html |author=[[David Eppstein]]}}</ref>\n\nThe problem of deciding the truth of a statement in [[Presburger arithmetic]] requires even more time. Fischer and [[Michael O. Rabin|Rabin]] proved in 1974<ref>{{cite journal | first1=Michael J. | last1=Fischer | authorlink1=Michael J. Fischer | first2=Michael O. | last2=Rabin | authorlink2=Michael O. Rabin | date=1974 | title=Super-Exponential Complexity of Presburger Arithmetic | url=http://www.lcs.mit.edu/publications/pubs/ps/MIT-LCS-TM-043.ps | journal=Proceedings of the SIAM-AMS Symposium in Applied Mathematics | volume=7 | pages=27–41 | ref=harv }}</ref> that every algorithm that decides the truth of Presburger statements of length ''n'' has a runtime of at least <math>2^{2^{cn}}</math> for some constant ''c''. Hence, the problem is known to need more than exponential run time. Even more difficult are the [[undecidable problem]]s, such as the [[halting problem]]. They cannot be completely solved by any algorithm, in the sense that for any particular algorithm there is at least one input for which that algorithm will not produce the right answer; it will either produce the wrong answer, finish without giving a conclusive answer, or otherwise run forever without producing any answer at all.\n\nIt is also possible to consider questions other than decision problems.  One such class, consisting of counting problems, is called [[Sharp-P#P|'''#P''']]: whereas an '''NP''' problem asks \"Are there any solutions?\", the corresponding '''#P''' problem asks \"How many solutions are there?\"  Clearly, a '''#P''' problem must be at least as hard as the corresponding '''NP''' problem, since a count of solutions immediately tells if at least one solution exists, if the count is greater than zero. Surprisingly, some '''#P''' problems that are believed to be difficult correspond to easy (for example linear-time) '''P''' problems.<ref>{{cite journal |author=Valiant, Leslie G. |title=The complexity of enumeration and reliability problems |journal=SIAM Journal on Computing |volume=8 |issue=3 |year=1979 |pages=410–421 |doi=10.1137/0208032}}</ref>  For these problems, it is very easy to tell whether solutions exist, but thought to be very hard to tell how many.  Many of these problems are [[Sharp-P-complete|'''#P'''-complete]], and hence among the hardest problems in '''#P''', since a polynomial time solution to any of them would allow a polynomial time solution to all other '''#P''' problems.\n\n==Problems in NP not known to be in P or NP-complete==\n{{Main article|NP-intermediate|l1='''NP'''-intermediate}}\nIn 1975, [[Richard E. Ladner]] showed that if '''P''' ≠ '''NP''' then there exist problems in '''NP''' that are neither in '''P''' nor '''NP'''-complete.<ref name=\"Ladner75\" /> Such problems are called '''NP'''-intermediate problems. The [[graph isomorphism problem]], the [[discrete logarithm problem]] and the [[integer factorization problem]] are examples of problems believed to be '''NP'''-intermediate. They are some of the very few '''NP''' problems not known to be in '''P''' or to be '''NP'''-complete.\n\nThe graph isomorphism problem is the computational problem of determining whether two finite [[Graph (discrete mathematics)|graph]]s are [[graph isomorphism|isomorphic]]. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in '''P''', '''NP'''-complete, or '''NP'''-intermediate. The answer is not known, but it is believed that the problem is at least not '''NP'''-complete.<ref name=\"AK06\">{{cite journal\n | first1 = Vikraman\n | last1 = Arvind\n | first2 = Piyush P.\n | last2 = Kurur\n | title = Graph isomorphism is in '''SPP'''\n | journal = Information and Computation\n | volume = 204\n | issue = 5\n | year = 2006\n | pages = 835–852\n | doi = 10.1016/j.ic.2006.02.002\n }}</ref> If graph isomorphism is '''NP'''-complete, the [[polynomial time hierarchy]] collapses to its second level.<ref>{{cite book | last1 = Schöning | first1 = Uwe | authorlink = Uwe Schöning | year = 1987| title = Graph isomorphism is in the low hierarchy | url = | journal = Proceedings of the 4th Annual Symposium on Theoretical Aspects of Computer Science | volume = 1987 | issue = | pages = 114–124 | doi=10.1007/bfb0039599| series = Lecture Notes in Computer Science | isbn = 978-3-540-17219-2 }}</ref><ref>{{cite journal | last1 = Schöning | first1 = Uwe | authorlink = Uwe Schöning | year = 1988 | title = Graph isomorphism is in the low hierarchy | url = | journal = Journal of Computer and System Sciences | volume = 37 | issue = 3| pages = 312–323 | doi=10.1016/0022-0000(88)90010-4}}</ref> Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not '''NP'''-complete. The best algorithm for this problem, due to [[László Babai]] and [[Eugene Luks]], has run time 2<sup>O({{radic|''n'' log ''n''}})</sup> for graphs with ''n'' vertices.\n\nThe [[integer factorization problem]] is the computational problem of determining the [[prime factorization]] of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a factor less than ''k''. No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the [[RSA (algorithm)|RSA]] algorithm. The integer factorization problem is in '''NP''' and in '''[[co-NP]]''' (and even in '''UP''' and '''co-UP'''<ref>[[Lance Fortnow]]. Computational Complexity Blog: [http://weblog.fortnow.com/2002/09/complexity-class-of-week-factoring.html Complexity Class of the Week: Factoring]. 13 September 2002.</ref>). If the problem is '''NP'''-complete, the polynomial time hierarchy will collapse to its first level (i.e., '''NP''' = '''co-NP'''). The best known algorithm for integer factorization is the [[general number field sieve]], which takes expected time\n\n:<math>O\\left (\\exp \\left ( \\left (\\tfrac{64n}{9} \\log(2) \\right )^{\\frac{1}{3}} \\left ( \\log(n\\log(2)) \\right )^{\\frac{2}{3}} \\right) \\right )</math>\n\nto factor an ''n''-bit integer. However, the best known [[quantum algorithm]] for this problem, [[Shor's algorithm]], does run in polynomial time, although this does not indicate where the problem lies with respect to non-quantum complexity classes.\n\n==Does P mean \"easy\"?==\n[[File:KnapsackEmpComplexity.GIF|thumb|310 px|The graph shows time (average of 100 instances in ms using a 933 MHz Pentium III) vs.problem size for knapsack problems for a state-of-the-art specialized algorithm. Quadratic fit suggests that empirical algorithmic complexity for instances with 50–10,000 variables is O((log(''n''))<sup>2</sup>).<ref name=Pisinger2003>Pisinger, D. 2003. \"Where are the hard knapsack problems?\" Technical Report 2003/08, Department of Computer Science, University of Copenhagen, Copenhagen, Denmark</ref>]]\nAll of the above discussion has assumed that '''P''' means \"easy\" and \"not in '''P'''\" means \"hard\", an assumption known as ''[[Cobham's thesis]]''. It is a common and reasonably accurate assumption in complexity theory; however, it has some caveats.\n\nFirst, it is not always true in practice. A theoretical polynomial algorithm may have extremely large constant factors or exponents thus rendering it impractical. On the other hand, even if a problem is shown to be '''NP'''-complete, and even if '''P''' ≠ '''NP''', there may still be effective approaches to tackling the problem in practice. There are algorithms for many '''NP'''-complete problems, such as the [[knapsack problem]], the [[traveling salesman problem]] and the [[Boolean satisfiability problem]], that can solve to optimality many real-world instances in reasonable time. The empirical [[average-case complexity]] (time vs. problem size) of such algorithms can be surprisingly low.  An example is the [[simplex algorithm]] in [[linear programming]], which works surprisingly well in practice; despite having exponential worst-case [[time complexity]] it runs on par with the best known polynomial-time algorithms.<ref>{{cite book|last1=Gondzio|first1=Jacek|last2=Terlaky|first2=Tamás|chapter=3 A computational view of interior point methods |mr=1438311 |title=Advances in linear and integer programming|pages=103–144|editor=J.&nbsp;E. Beasley|location=New York|publisher=Oxford University Press|year=1996|series=Oxford Lecture Series in Mathematics and its Applications |volume=4 |chapter-url=http://www.maths.ed.ac.uk/~gondzio/CV/oxford.ps |ref=harv|id=[http://www.maths.ed.ac.uk/~gondzio/CV/oxford.ps Postscript file at website of Gondzio] and [http://www.cas.mcmaster.ca/~terlaky/files/dut-twi-94-73.ps.gz at McMaster University website of Terlaky]}}</ref>\n\nSecond, there are types of computations which do not conform to the Turing machine model on which '''P''' and '''NP''' are defined, such as [[quantum computation]] and [[randomized algorithm]]s.\n\n==Reasons to believe P ≠ NP==\nAccording to polls,<ref name=\"poll\"/><ref>{{cite journal|title='''P''' vs. '''NP''' poll results|journal=Communications of the ACM|date=May 2012|volume=55|issue=5|page=10|first=Jack|last=Rosenberger|url=http://mags.acm.org/communications/201205?pg=12}}</ref> most computer scientists believe that '''P'''&nbsp;≠&nbsp;'''NP'''. A key reason for this belief is that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known '''NP'''-complete problems (see [[List of NP-complete problems|List of '''NP'''-complete problems]]). These algorithms were sought long before the concept of '''NP'''-completeness was even defined ([[Karp's 21 NP-complete problems|Karp's 21 '''NP'''-complete problems]], among the first found, were all well-known existing problems at the time they were shown to be '''NP'''-complete). Furthermore, the result '''P''' = '''NP''' would imply many other startling results that are currently believed to be false, such as '''NP''' = '''[[co-NP]]''' and '''P''' = '''[[PH (complexity)|PH]]'''.\n\nIt is also intuitively argued that the existence of problems that are hard to solve but for which the solutions are easy to verify matches real-world experience.<ref>{{Cite web|url=http://scottaaronson.com/blog/?p=122 |author=Scott Aaronson |title=Reasons to believe}}, point 9.</ref>\n{{quote|If '''P''' <nowiki>=</nowiki> '''NP''', then the world would be a profoundly different place than we usually assume it to be. There would be no special value in \"creative leaps,\" no fundamental gap between solving a problem and recognizing the solution once it's found.| [[Scott Aaronson]], then at [[MIT]]}}\n\nOn the other hand, some researchers believe that there is overconfidence in believing '''P''' ≠ '''NP''' and that researchers should explore proofs of '''P''' = '''NP''' as well. For example, in 2002 these statements were made:<ref name=\"poll\" />\n{{quote|The main argument in favor of '''P'''&nbsp;≠&nbsp;'''NP''' is the total lack of fundamental progress in the area of exhaustive search. This is, in my opinion, a very weak argument. The space of algorithms is very large and we are only at the beginning of its exploration. [...] The resolution of [[Fermat's Last Theorem]] also shows that very simple questions may be settled only by very deep theories.|[[Moshe Y. Vardi]], [[Rice University]]}}\n{{quote|Being attached to a speculation is not a good guide to research planning. One should always try both directions of every problem. Prejudice has caused famous mathematicians to fail to solve famous problems whose solution was opposite to their expectations, even though they had developed all the methods required.|[[Anil Nerode]], [[Cornell University]]}}\n\n==Consequences of solution==\nOne of the reasons the problem attracts so much attention is the consequences of the answer.  Either direction of resolution would advance theory enormously, and perhaps have huge practical consequences as well.\n\n===P = NP===\nA proof that '''P''' = '''NP''' could have stunning practical consequences if the proof leads to efficient methods for solving some of the important problems in '''NP'''. It is also possible that a proof would not lead directly to efficient methods, perhaps if the proof is [[non-constructive proof|non-constructive]], or the size of the bounding polynomial is too big to be efficient in practice. The consequences, both positive and negative, arise since various '''NP'''-complete problems are fundamental in many fields.\n\nCryptography, for example, relies on certain problems being difficult. A constructive and efficient solution<ref group=\"Note\">Exactly how efficient a solution must be to pose a threat to cryptography depends on the details.  A solution of <math>O(N^2)</math> with a reasonable constant term would be disastrous.  On the other hand, a solution that is <math>\\Omega(N^4)</math> in almost all cases would not pose an immediate practical danger.</ref> to an '''NP'''-complete problem such as [[Boolean satisfiability problem#3-satisfiability|3-SAT]] would break most existing cryptosystems including:\n* Existing implementations of [[public-key cryptography]],<ref>See {{cite book |title=Hard instance generation for SAT |author=Horie, S. and Watanabe, O. |journal=Algorithms and Computation |pages=22–31 |year=1997\n|publisher=Springer |arxiv=cs/9809117 |bibcode=1998cs........9117H |last2=Watanabe |doi=10.1007/3-540-63890-3_4 |series=Lecture Notes in Computer Science |isbn=978-3-540-63890-2 |volume=1350}} for a reduction of factoring to SAT.  A 512 bit factoring problem (8400 MIPS-years when factored) translates to a SAT problem of 63,652 variables and 406,860 clauses.</ref> a foundation for many modern security applications such as secure financial transactions over the Internet.\n* [[Symmetric cipher]]s such as [[Advanced Encryption Standard|AES]] or [[Triple DES|3DES]],<ref>See, for example, {{cite journal |title=Logical cryptanalysis as a SAT problem |author1=Massacci, F.  |author2=Marraro, L.  |lastauthoramp=yes |journal=Journal of Automated Reasoning |volume=24 |issue=1 |pages=165–203 |year=2000 |citeseerx=10.1.1.104.962 |doi=10.1023/A:1006326723002}} in which an instance of DES is encoded as a SAT problem with 10336 variables and 61935 clauses.  A 3DES problem instance would be about 3 times this size.</ref> used for the encryption of communications data.\n* [[Cryptographic hash function|Cryptographic hashing]] as the problem of finding a pre-image that hashes to a given value must be difficult in order to be useful, and ideally should require exponential time. However, if '''P'''='''NP''', then finding a pre-image ''M'' can be done in polynomial time, through reduction to SAT.<ref>{{cite news |title=Inversion attacks on secure hash functions using SAT solvers\n  |author=De, Debapratim and Kumarasubramanian, Abishek and Venkatesan, Ramarathnam\n  |booktitle=Theory and Applications of Satisfiability Testing--SAT 2007\n  |pages=377–382\n  |year=2007\n  |publisher=Springer\n  |doi=10.1007/978-3-540-72788-0_36\n  }}</ref>\nThese would need to be modified or replaced by [[information-theoretic security|information-theoretically secure]] solutions not inherently based on '''P'''-'''NP''' equivalence.\n\nOn the other hand, there are enormous positive consequences that would follow from rendering tractable many currently mathematically intractable problems. For instance, many problems in [[operations research]] are '''NP'''-complete, such as some types of [[integer programming]] and the [[travelling salesman problem]]. Efficient solutions to these problems would have enormous implications for logistics. Many other important problems, such as some problems in [[protein structure prediction]], are also '''NP'''-complete;<ref name=\"Berger\">{{Cite journal|author=[[Bonnie Berger|Berger B]], [[F. Thomson Leighton|Leighton T]] |title=Protein folding in the hydrophobic-hydrophilic (HP) model is '''NP'''-complete |journal=J. Comput. Biol. |volume=5 |issue=1 |pages=27–40 |year=1998 |pmid=9541869 |doi=10.1089/cmb.1998.5.27 |citeseerx=10.1.1.139.5547 }}</ref> if these problems were efficiently solvable it could spur considerable advances in life sciences and biotechnology.\n\nBut such changes may pale in significance compared to the revolution an efficient method for solving '''NP'''-complete problems would cause in mathematics itself. Gödel, in his early thoughts on computational complexity, noted that a mechanical method that could solve any problem would revolutionize mathematics:<ref>History of this letter and its translation from {{cite web |title=The History and Status of the '''P''' versus '''NP''' question |author=Michael Sipser |url=http://cs.stanford.edu/people/trevisan/cs172-07/sipser92history.pdf}}</ref><ref>{{cite web |url=http://www.research.att.com/techdocs/TD_100899.pdf |title=A Brief History of NP-Completeness, 1954–2012 |author=David S. Johnson}} From pages 359–376 of Optimization Stories, [[Martin Grötschel|M. Grötschel]] (editor), a special issue of ¨ Documenta Mathematica, published in August 2012 and distributed to attendees at the 21st International Symposium on Mathematical Programming in Berlin.</ref>\n{{quote|If there really were a machine with φ(n) ∼ k ⋅ n (or even ∼ k ⋅ n<sup>2</sup>), this would have consequences of the greatest importance. Namely, it would obviously mean that in spite of the undecidability of the [[Entscheidungsproblem]], the mental work of a mathematician concerning Yes-or-No questions could be completely replaced by a machine. After all, one would simply have to choose the natural number n so large that when the machine does not deliver a result, it makes no sense to think more about the problem.}}\nSimilarly, [[Stephen Cook]] says<ref name=\"Official Problem Description\">{{Cite journal|last=Cook|first=Stephen|authorlink=Stephen Cook|title=The '''P''' versus '''NP''' Problem|publisher=[[Clay Mathematics Institute]] |date=April 2000 |url=http://www.claymath.org/sites/default/files/pvsnp.pdf |accessdate=18 October 2006}}</ref>\n\n{{quote|...it would transform mathematics by allowing a computer to find a formal proof of any theorem which has a proof of a reasonable length, since formal proofs can easily be recognized in polynomial time. Example problems may well include all of the [[Clay Math Institute#Millennium Prize Problems|CMI prize problems]].}}\n\nResearch mathematicians spend their careers trying to prove theorems, and some proofs have taken decades or even centuries to find after problems have been stated—for instance, [[Fermat's Last Theorem]] took over three centuries to prove. A method that is guaranteed to find proofs to theorems, should one exist of a \"reasonable\" size, would essentially end this struggle.\n\n[[Donald Knuth]] has stated that he has come to believe that '''P''' = '''NP''', but is reserved about the impact of a possible proof:<ref>{{cite web|url=http://www.informit.com/articles/article.aspx?p=2213858&WT.rss_f=Article&WT.rss_a=Twenty%20Questions%20for%20Donald%20Knuth&WT.rss_ev=a|title=Twenty Questions for Donald Knuth|date=May 20, 2014|work=informit.com|publisher=[[InformIT (publisher)|InformIT]]|last=Knuth|first=Donald E.|authorlink=Donald Knuth|accessdate=20 July 2014}}</ref>\n{{quote|1=[...] I don't believe that the equality '''P''' = '''NP''' will turn out to be helpful even if it is proved, because such a proof will almost surely be nonconstructive.}}\n\n===P ≠ NP===\nA proof that showed that '''P''' ≠ '''NP''' would lack the practical computational benefits of a proof that '''P''' = '''NP''', but would nevertheless represent a very significant advance in computational complexity theory and provide guidance for future research. It would allow one to show in a formal way that many common problems cannot be solved efficiently, so that the attention of researchers can be focused on partial solutions or solutions to other problems. Due to widespread belief in '''P''' ≠ '''NP''', much of this focusing of research has already taken place.<ref>{{Cite journal|title=The Heuristic Problem-Solving Approach |author=L. R. Foulds |journal=[[Journal of the Operational Research Society]] |volume=34 |issue=10 |date=October 1983 |pages=927–934 |jstor=2580891 |doi=10.2307/2580891}}</ref>\n\nAlso '''P''' ≠ '''NP''' still leaves open the [[average-case complexity]] of hard problems in '''NP'''.  For example, it is possible that SAT requires exponential time in the worst case, but that almost all randomly selected instances of it are efficiently solvable. [[Russell Impagliazzo]] has described five hypothetical \"worlds\" that could result from different possible resolutions to the average-case complexity question.<ref>R. Impagliazzo, [http://cseweb.ucsd.edu/~russell/average.ps \"A personal view of average-case complexity,\"] sct, pp.134, 10th Annual Structure in Complexity Theory Conference (SCT'95), 1995</ref>  These range from \"Algorithmica\", where '''P''' = '''NP''' and problems like SAT can be solved efficiently in all instances, to \"Cryptomania\", where '''P''' ≠ '''NP''' and generating hard instances of problems outside '''P''' is easy, with three intermediate possibilities reflecting different possible distributions of difficulty over instances of '''NP'''-hard problems.  The \"world\" where '''P''' ≠ '''NP''' but all problems in '''NP''' are tractable in the average case is called \"Heuristica\" in the paper. A [[Princeton University]] workshop in 2009 studied the status of the five worlds.<ref>{{Cite web|url = http://intractability.princeton.edu/blog/2009/05/program-for-workshop-on-impagliazzos-worlds/|title = Tentative program for the workshop on \"Complexity and Cryptography: Status of Impagliazzo's Worlds\"|date = |accessdate = |website = |archiveurl = https://web.archive.org/web/20131115034042/http://intractability.princeton.edu/blog/2009/05/program-for-workshop-on-impagliazzos-worlds/|archivedate = 2013-11-15}}</ref>\n\n==Results about difficulty of proof==\nAlthough the '''P''' = '''NP''' problem itself remains open despite a million-dollar prize and a huge amount of dedicated research, efforts to solve the problem have led to several new techniques.  In particular, some of the most fruitful research related to the '''P''' = '''NP''' problem has been in showing that existing proof techniques are not powerful enough to answer the question, thus suggesting that novel technical approaches are required.\n\nAs additional evidence for the difficulty of the problem, essentially all known proof techniques in [[computational complexity theory]] fall into one of the following classifications, each of which is known to be insufficient to prove that '''P''' ≠ '''NP''':\n{| class=\"wikitable\"\n|-\n!Classification\n!Definition\n|-\n|[[Relativizing proof]]s\n|Imagine a world where every algorithm is allowed to make queries to some fixed subroutine called an ''[[oracle machine|oracle]]'' (a black box which can answer a fixed set of questions in constant time, such as a black box that solves any given traveling salesman problem in 1 step), and the running time of the oracle is not counted against the running time of the algorithm. Most proofs (especially classical ones) apply uniformly in a world with oracles regardless of what the oracle does. These proofs are called ''relativizing''. In 1975, Baker, Gill, and [[Robert M. Solovay|Solovay]] showed that '''P''' = '''NP''' with respect to some oracles, while '''P''' ≠ '''NP''' for other oracles.<ref>{{cite journal |author1=T. P. Baker |author2=J. Gill |author3=R. Solovay. |title=Relativizations of the '''P''' =? '''NP''' Question |journal=[[SIAM Journal on Computing]] |volume=4 |issue=4 |pages=431–442 |year=1975 |doi=10.1137/0204037}}</ref> Since relativizing proofs can only prove statements that are uniformly true with respect to all possible oracles, this showed that relativizing techniques cannot resolve '''P''' = '''NP'''.\n|-\n|[[Natural proof]]s\n|In 1993, [[Alexander Razborov]] and [[Steven Rudich]] defined a general class of proof techniques for circuit complexity lower bounds, called ''[[natural proof]]s''.<ref>{{cite journal |author1=Razborov, Alexander A. |author2=Steven Rudich |title=Natural proofs |journal=Journal of Computer and System Sciences |volume=55 |issue=1 |year=1997 |pages=24–35 |url=http://www.sciencedirect.com/science/article/pii/S002200009791494X |doi=10.1006/jcss.1997.1494}}</ref> At the time all previously known circuit lower bounds were natural, and circuit complexity was considered a very promising approach for resolving '''P''' = '''NP'''. However, Razborov and Rudich showed that, if [[one-way functions]] exist, then no natural proof method can distinguish between '''P''' and '''NP'''. Although one-way functions have never been formally proven to exist, most mathematicians believe that they do, and a proof of their existence would be a much stronger statement than '''P''' ≠ '''NP'''. Thus it is unlikely that natural proofs alone can resolve '''P''' = '''NP'''.\n|-\n|Algebrizing proofs\n|After the Baker-Gill-Solovay result, new non-relativizing proof techniques were successfully used to prove that [[IP (complexity)|IP]] = [[PSPACE]]. However, in 2008, [[Scott Aaronson]] and [[Avi Wigderson]] showed that the main technical tool used in the '''IP''' = '''PSPACE''' proof, known as ''arithmetization'', was also insufficient to resolve '''P''' = '''NP'''.<ref>{{cite conference |author1=S. Aaronson  |author2=A. Wigderson  |lastauthoramp=yes |title=Algebrization: A New Barrier in Complexity Theory |conference=Proceedings of ACM STOC'2008 |year=2008 |url=http://www.scottaaronson.com/papers/alg.pdf |doi=10.1145/1374376.1374481 |pages=731–740}}</ref>\n|}\n\nThese barriers are another reason why '''NP'''-complete problems are useful: if a polynomial-time algorithm can be demonstrated for an '''NP'''-complete problem, this would solve the '''P''' = '''NP''' problem in a way not excluded by the above results.\n\nThese barriers have also led some computer scientists to suggest that the '''P''' versus '''NP''' problem may be [[Independence (mathematical logic)|independent]] of standard axiom systems like [[ZFC]] (cannot be proved or disproved within them). The interpretation of an independence result could be that either no polynomial-time algorithm exists for any '''NP'''-complete problem, and such a proof cannot be constructed in (e.g.) ZFC, or that polynomial-time algorithms for '''NP'''-complete problems may exist, but it is impossible to prove in ZFC that such algorithms are correct.<ref>{{Cite web|url=http://www.scottaaronson.com/papers/indep.pdf|first=Scott|last=Aaronson|authorlink=Scott Aaronson|title=Is '''P''' Versus '''NP''' Formally Independent?|postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}}}.</ref> However, if it can be shown, using techniques of the sort that are currently known to be applicable, that the problem cannot be decided even with much weaker assumptions extending the [[Peano axioms]] (PA) for integer arithmetic, then there would necessarily exist nearly-polynomial-time algorithms for every problem in '''NP'''.<ref>{{Cite journal|title=On the independence of '''P''' versus '''NP'''|first1=Shai|last1=Ben-David |first2=Shai|last2=Halevi |series=Technical Report|volume=714|publisher=Technion|year=1992|url=http://www.cs.technion.ac.il/~shai/ph.ps.gz|postscript=<!-- Bot inserted parameter. Either remove it; or change its value to \".\" for the cite to end in a \".\", as necessary. -->{{inconsistent citations}}}}.</ref> Therefore, if one believes (as most complexity theorists do) that not all problems in '''NP''' have efficient algorithms, it would follow that proofs of independence using those techniques cannot be possible. Additionally, this result implies that proving independence from PA or ZFC using currently known techniques is no easier than proving the existence of efficient algorithms for all problems in '''NP'''.\n\n==Claimed solutions <span id=\"Deolalikar\"></span>==\nWhile the '''P''' versus '''NP''' problem is generally considered unsolved,<ref>{{Cite news|author=[[John Markoff]] |url=https://www.nytimes.com/2009/10/08/science/Wpolynom.html |title=Prizes Aside, the P-NP Puzzler Has Consequences|newspaper=The New York Times|date=8 October 2009}}</ref> many amateur and some professional researchers have claimed solutions. [[Gerhard J. Woeginger]] maintains a list that, as of 2018, contains 62 purported proofs of '''P''' = '''NP''', 50 of '''P'''&nbsp;≠&nbsp;'''NP''', 2 proofs the problem is unprovable, and one proof that it is undecidable.<ref>{{Cite web|title=The '''P'''-versus-'''NP''' page|url=http://www.win.tue.nl/~gwoegi/P-versus-NP.htm|author=Gerhard J. Woeginger|authorlink=Gerhard J. Woeginger|accessdate=2018-06-24}}</ref>  An August 2010 claim of proof that '''P''' ≠ '''NP''', by Vinay Deolalikar, a researcher at [[HP Labs]], received heavy Internet and press attention after two leading specialists described it as \"{{nowrap|seem[ing]}} to be a relatively serious attempt\".<ref name=\"NYT2010\">{{Cite news|last=Markoff|first=John|title=Step 1: Post Elusive Proof. Step 2: Watch Fireworks. |url=https://www.nytimes.com/2010/08/17/science/17proof.html?_r=1 |accessdate=20 September 2010|newspaper=The New York Times|date=16 August 2010}}</ref> The proof has been reviewed publicly by academics,<ref>{{Cite web |url=http://michaelnielsen.org/polymath1/index.php?title=Deolalikar_P_vs_NP_paper |author=[[Polymath Project]] wiki |title=Deolalikar's '''P''' vs '''NP''' paper}}</ref><ref>Science News, [http://www.sciencenews.org/index/generic/activity/view/id/63252/title/Crowdsourcing_peer_review \"Crowdsourcing peer review\"]</ref> and [[Neil Immerman]], an expert in the field, has pointed out two possibly fatal errors in the proof.<ref>{{Cite web |title=Fatal Flaws in Deolalikar's Proof?\n |url=http://rjlipton.wordpress.com/2010/08/12/fatal-flaws-in-deolalikars-proof/ |author=[[Richard J. Lipton|Dick Lipton]] |date=12 August 2010}}</ref>\nIn September 2010, Deolalikar was reported to be working on a detailed expansion of his attempted proof.<ref>{{Cite web\n|url=http://rjlipton.wordpress.com/2010/09/15/an-update-on-vinay-deolalikars-proof/ |title=An Update on Vinay Deolalikar's Proof\n|author=[[Richard J. Lipton|Dick Lipton]] |date=15 September 2010 |accessdate=31 December 2010 }}</ref> However, opinions expressed by several notable theoretical computer scientists indicate that the attempted proof is neither correct nor a significant advancement in the understanding of the problem.<ref>Gödel’s Lost Letter and '''P'''='''NP''', [http://rjlipton.wordpress.com/2010/08/10/update-on-deolalikars-proof-that-p%E2%89%A0np/#comment-4885 Update on Deolalikar’s Proof that P≠NP]</ref>  This assessment prompted a May 2013 article in ''[[The New Yorker]]'' to call the proof attempt \"thoroughly discredited\".<ref>{{Cite web\n|url=http://www.newyorker.com/online/blogs/elements/2013/05/a-most-profound-math-problem.html\n|title=A Most Profound Math Problem\n|author=Alexander Nazaryan|date=2 May 2013 |accessdate=1 May 2014}}</ref>\n\n==Logical characterizations==\nThe '''P''' = '''NP''' problem can be restated in terms of expressible certain classes of logical statements, as a result of work in [[descriptive complexity]].\n\nConsider all languages of finite structures with a fixed [[signature (logic)|signature]] including a [[linear order]] relation. Then, all such languages in '''P''' can be expressed in [[first-order logic]] with the addition of a suitable least [[fixed-point combinator]]. Effectively, this, in combination with the order, allows the definition of recursive functions. As long as the signature contains at least one predicate or function in addition to the distinguished order relation, so that the amount of space taken to store such finite structures is actually polynomial in the number of elements in the structure, this precisely characterizes '''P'''.\n\nSimilarly, '''NP''' is the set of languages expressible in existential [[second-order logic]]—that is, second-order logic restricted to exclude [[universal quantification]] over relations, functions, and subsets. The languages in the [[polynomial hierarchy]], '''[[PH (complexity)|PH]]''', correspond to all of second-order logic. Thus, the question \"is '''P''' a proper subset of '''NP'''\" can be reformulated as \"is existential second-order logic able to describe languages (of finite linearly ordered structures with nontrivial signature) that first-order logic with least fixed point cannot?\".<ref>Elvira Mayordomo. [http://www.unizar.es/acz/05Publicaciones/Monografias/MonografiasPublicadas/Monografia26/057Mayordomo.pdf \"P versus NP\"] {{webarchive|url=https://web.archive.org/web/20120216154228/http://www.unizar.es/acz/05Publicaciones/Monografias/MonografiasPublicadas/Monografia26/057Mayordomo.pdf |date=16 February 2012 }} ''Monografías de la Real Academia de Ciencias de Zaragoza'' '''26''': 57–68 (2004).</ref> The word \"existential\" can even be dropped from the previous characterization, since '''P''' = '''NP''' if and only if '''P''' = '''PH''' (as the former would establish that '''NP''' = '''co-NP''', which in turn implies that '''NP''' = '''PH''').\n\n==Polynomial-time algorithms==\nNo algorithm for any '''NP'''-complete problem is known to run in polynomial time. However, there are algorithms known for '''NP'''-complete problems with the property that if '''P''' = '''NP''', then the algorithm runs in polynomial time on accepting instances (although with enormous constants, making the algorithm impractical). However, these algorithms do not qualify as polynomial time because their running time on rejecting instances are not polynomial. The following algorithm, due to [[Leonid Levin|Levin]] (without any citation), is such an example below. It correctly accepts the '''NP'''-complete language [[subset sum problem|SUBSET-SUM]]. It runs in polynomial time on inputs that are in SUBSET-SUM if and only if '''P''' = '''NP''':\n\n ''// Algorithm that accepts the '''NP'''-complete language SUBSET-SUM.\n ''//\n ''// this is a polynomial-time algorithm if and only if '''P''' = '''NP'''.\n ''//\n ''// \"Polynomial-time\" means it returns \"yes\" in polynomial time when\n ''// the answer should be \"yes\", and runs forever when it is \"no\".\n ''//\n ''// Input: S = a finite set of integers\n ''// Output: \"yes\" if any subset of S adds up to 0.\n ''// Runs forever with no output otherwise.\n ''// Note: \"Program number M\" is the program obtained by\n ''// writing the integer M in binary, then\n ''// considering that string of bits to be a\n ''// program. Every possible program can be\n ''// generated this way, though most do nothing\n ''// because of syntax errors.''\n FOR K = 1...∞\n   FOR M = 1...K\n     Run program number M for K steps with input S\n     IF the program outputs a list of distinct integers\n       AND the integers are all in S\n       AND the integers sum to 0\n     THEN\n       OUTPUT \"yes\" and HALT\n\nIf, and only if, '''P''' = '''NP''', then this is a polynomial-time algorithm accepting an '''NP'''-complete language. \"Accepting\" means it gives \"yes\" answers in polynomial time, but is allowed to run forever when the answer is \"no\" (also known as a ''semi-algorithm'').\n\nThis algorithm is enormously impractical, even if '''P''' = '''NP'''. If the shortest program that can solve SUBSET-SUM in polynomial time is ''b'' bits long, the above algorithm will try at least {{math|2<sup>''b''</sup> − 1}} other programs first.\n\n==Formal definitions==\n\n===P and NP===\nConceptually speaking, a ''decision problem'' is a problem that takes as input some [[String (computer science)|string]] ''w'' over an alphabet Σ, and outputs \"yes\" or \"no\". If there is an [[algorithm]] (say a [[Turing machine]], or a [[Computer programming|computer program]] with unbounded memory) that can produce the correct answer for any input string of length ''n'' in at most ''cn<sup>k</sup>'' steps, where ''k'' and ''c'' are constants independent of the input string, then we say that the problem can be solved in ''polynomial time'' and we place it in the class '''P'''. Formally, '''P''' is defined as the set of all languages that can be decided by a deterministic polynomial-time Turing machine. That is,\n:<math>\\mathbf{P} = \\{ L : L=L(M) \\text{ for some deterministic polynomial-time Turing machine } M \\}</math>\nwhere\n:<math>L(M) = \\{ w\\in\\Sigma^{*}: M \\text{ accepts } w \\}</math>\nand a deterministic polynomial-time Turing machine is a deterministic Turing machine ''M'' that satisfies the following two conditions:\n\n# ''M'' halts on all inputs ''w'' and\n# there exists <math>k \\in N</math> such that <math>T_M(n)\\in O(n^k)</math>, where ''O'' refers to the [[Big O notation#Formal definition|big O notation]] and\n::<math>T_M(n) = \\max\\{ t_M(w) : w\\in\\Sigma^{*}, |w| = n \\}</math>\n::<math>t_M(w) = \\text{ number of steps }M\\text{ takes to halt on input }w.</math>\n\n'''NP''' can be defined similarly using nondeterministic Turing machines (the traditional way). However, a modern approach to define '''NP''' is to use the concept of ''[[Certificate (complexity)|certificate]]'' and ''verifier''. Formally, '''NP''' is defined as the set of languages over a finite alphabet that have a verifier that runs in polynomial time, where the notion of \"verifier\" is defined as follows.\n\nLet ''L'' be a language over a finite alphabet, Σ.\n\n''L'' ∈ '''NP''' if, and only if, there exists a binary relation <math>R\\subset\\Sigma^{*}\\times\\Sigma^{*}</math> and a positive integer ''k'' such that the following two conditions are satisfied:\n\n# <abbr title=\"For all strings x in Σ*, x is in L if and only if there is a y in Σ* such that (x, y) is in R and the length of y is polynomial in the length of x\">For all <math>x\\in\\Sigma^{*}</math>, <math>x\\in L \\Leftrightarrow\\exists y\\in\\Sigma^{*}</math> such that (''x'', ''y'') ∈ ''R'' and <math>|y|\\in O(|x|^k)</math></abbr>; and\n# the language <abbr title=\"L[R], consisting of x followed by y with a delimiter in the middle\"><math>L_{R} = \\{ x\\# y:(x,y)\\in R\\}</math> over <math>\\Sigma\\cup\\{\\#\\}</math></abbr> is decidable by a deterministic Turing machine in polynomial time.\n\nA Turing machine that decides ''L<sub>R</sub>'' is called a ''verifier'' for ''L'' and a ''y'' such that (''x'', ''y'') ∈ ''R'' is called a ''certificate of membership'' of ''x'' in ''L''.\n\nIn general, a verifier does not have to be polynomial-time. However, for ''L'' to be in '''NP''', there must be a verifier that runs in polynomial time.\n\n====Example====\nLet\n:<math>\\mathrm{COMPOSITE} = \\left \\{x\\in\\mathbb{N} \\mid x=pq \\text{ for integers } p, q > 1 \\right \\}</math>\n:<math>R = \\left \\{(x,y)\\in\\mathbb{N} \\times\\mathbb{N} \\mid 1<y \\leq \\sqrt x \\text{ and } y \\text{ divides } x \\right \\}.</math>\nClearly, the question of whether a given ''x'' is a [[Composite number|composite]] is equivalent to the question of whether ''x'' is a member of COMPOSITE. It can be shown that COMPOSITE ∈ '''NP''' by verifying that it satisfies the above definition (if we identify natural numbers with their binary representations).\n\nCOMPOSITE also happens to be in '''P''', a fact demonstrated by the invention of the [[AKS primality test]].<ref name=\"Agrawal\">{{cite journal |first=Manindra |last=Agrawal |first2=Neeraj |last2=Kayal |first3=Nitin |last3=Saxena |url=http://www.cse.iitk.ac.in/users/manindra/algebra/primality_v6.pdf |title=PRIMES is in '''P''' |journal=[[Annals of Mathematics]] |volume=160 |year=2004 |issue=2 |pages=781–793 |doi=10.4007/annals.2004.160.781 |jstor=3597229 }}</ref>\n\n===NP-completeness===\n{{Main|NP-completeness}}\n\nThere are many equivalent ways of describing '''NP'''-completeness.\n\nLet ''L'' be a language over a finite alphabet Σ.\n\n''L'' is '''NP'''-complete if, and only if, the following two conditions are satisfied:\n\n# ''L'' ∈ '''NP'''; and\n# any ''L′'' in '''NP''' is polynomial-time-reducible to ''L'' (written as <math>L' \\leq_{p} L</math>), where <math>L' \\leq_{p} L</math> if, and only if, the following two conditions are satisfied:\n## There exists ''f'' : Σ* → Σ* such that for all ''w'' in Σ* we have: <math>(w\\in L' \\Leftrightarrow f(w)\\in L)</math>; and\n## there exists a polynomial-time Turing machine that halts with ''f''(''w'') on its tape on any input ''w''.\n\nAlternatively, if ''L'' ∈ '''NP''', and there is another '''NP'''-complete problem that can be polynomial-time reduced to ''L'', then ''L'' is '''NP'''-complete. This is a common way of proving some new problem is '''NP'''-complete.\n\n==Popular culture==\nThe film ''[[Travelling Salesman (2012 film)|Travelling Salesman]]'', by director Timothy Lanzone, is the story of four mathematicians hired by the US government to solve the '''P''' versus '''NP''' problem.<ref>{{cite journal|last=Geere|first=Duncan|title='Travelling Salesman' movie considers the repercussions if P equals NP|journal=Wired UK|url=https://www.wired.co.uk/news/archive/2012-04/26/travelling-salesman|accessdate=26 April 2012|date=2012-04-26}}</ref>\n\nIn the sixth episode of ''[[The Simpsons]]''{{'}} seventh season \"[[Treehouse of Horror VI]]\", the equation '''P'''='''NP''' is seen shortly after Homer accidentally stumbles into the \"third dimension\".<ref>{{cite web|last=Hardesty|first=Larry|title=Explained: '''P''' vs. '''NP'''|url=http://news.mit.edu/2009/explainer-pnp}}</ref><ref>{{cite web|last=Shadia|first=Ajam|title=What is the '''P''' vs. '''NP''' problem? Why is it important?|url=http://science.nd.edu/news/what-is-the-p-vs-np-problem-and-why-is-it-important/}}</ref>\n\nIn the second episode of season 2 of ''[[Elementary (TV series)|Elementary]]'', [[List of Elementary episodes#Season 2 (2013–14)|\"Solve for X\"]] revolves around Sherlock and Watson investigating the murders of mathematicians who were attempting to solve '''P''' versus '''NP'''.<ref>{{Cite web|url=https://blog.computationalcomplexity.org/2013/10/p-vs-np-is-elementary-no-p-vs-np-is-on.html|title=P vs NP is Elementary? No— P vs NP is ON Elementary|website=blog.computationalcomplexity.org|date=2013-10-07|last=Gasarch|first=William|language=en|access-date=2018-07-06}}</ref><ref>{{Cite news|url=http://www.tv.com/news/elementary-solve-for-x-review-sines-of-murder-138084402962/|title=Elementary Solve for X Review: Sines of Murder|last=Kirkpatrick|first=Noel|date=2013-10-04|work=TV.com|access-date=2018-07-06}}</ref>\n\n==See also==\n* [[Game complexity]]\n* [[List of unsolved problems in mathematics]]\n* [[Unique games conjecture]]\n* [[Unsolved problems in computer science]]\n\n==Notes==\n{{reflist|group=Note}}\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n* {{cite book | last1 = Garey | first1 = Michael | last2 = Johnson | first2 = David | title = Computers and Intractability: A Guide to the Theory of NP-Completeness | publisher = [[W. H. Freeman and Company]] | location = San Francisco | year = 1979 | isbn = 978-0-7167-1045-5 }}\n* {{cite book | last = Goldreich | first = Oded | title = P, NP, and NP-Completeness | publisher = Cambridge University Press | location = Cambridge | year = 2010 | isbn = 978-0-521-12254-2 }} [http://www.wisdom.weizmann.ac.il/~oded/bc-drafts.html Online drafts]\n* {{Cite journal | last1 = Immerman | first1 = N. | title = Languages which capture complexity classes | pages = 760–778 | year = 1987 | journal=SIAM Journal on Computing | volume=16 | issue = 4 |doi=10.1137/0216051| citeseerx=10.1.1.75.3035 }}\n* {{cite book | last = Cormen | first = Thomas | title = Introduction to Algorithms | publisher = [[MIT Press]] | location = Cambridge | year = 2001 | isbn = 978-0-262-03293-3 | title-link = Introduction to Algorithms }}\n* {{cite book | last = Papadimitriou | first = Christos | title = Computational Complexity | publisher = Addison-Wesley | location = Boston | year = 1994 | isbn = 978-0-201-53082-7 }}\n* {{cite web | last1= Fortnow | first1 = L. | last2 = Gasarch | first2 = W. | title = Computational complexity | url =  http://weblog.fortnow.com }}\n\n==External links==\n{{Sister project links| wikt=no | commons=no | b=no | n=no | q=P versus NP problem | s=no | v=no | voy=no | species=no | d=no}}\n\n* [https://www2.eecs.berkeley.edu/Pubs/TechRpts/2017/EECS-2017-146.pdf Aviad Rubinstein's ''Hardness of Approximation Between '''P''' and '''NP'''''], winner of the [[Association for Computing Machinery|ACM]]'s [https://awards.acm.org/about/2017-doctoral-dissertation 2017 Doctoral Dissertation Award].\n{{ComplexityClasses}}\n\n{{Use dmy dates|date=May 2012}}\n\n{{DEFAULTSORT:P Versus Np Problem}}\n[[Category:1956 in computer science]]\n[[Category:Structural complexity theory]]\n[[Category:Mathematical optimization]]\n[[Category:Conjectures]]\n[[Category:Unsolved problems in mathematics]]\n[[Category:Unsolved problems in computer science]]\n[[Category:Millennium Prize Problems]]\n[[Category:Computer-related introductions in 1956]]"
    },
    {
      "title": "Paper bag problem",
      "url": "https://en.wikipedia.org/wiki/Paper_bag_problem",
      "text": "In [[geometry]], the '''paper bag problem''' or '''teabag problem''' is to calculate the maximum possible inflated volume of an initially flat sealed rectangular bag which has the same shape as a [[cushion]] or [[pillow]], made out of two pieces of material which can bend but not stretch.\n\n[[Image:Cushion.jpg|right|thumb|A cushion filled with stuffing]]\n\n[[Image:teabag.jpg|right|thumb|A numerical simulation of an inflated teabag (with crimping smoothed out)]]\n\nAccording to [[Anthony C. Robin]], an approximate formula for the capacity of a sealed expanded bag is:\n\n:<math>V=w^3 \\left (h/ \\left (\\pi  w \\right ) -0.142  \\left (1-10^ \\left (-h/w \\right ) \\right ) \\right ),</math>\n\nwhere ''w'' is the width of the bag (the shorter dimension), ''h'' is the height (the longer dimension), and ''V'' is the maximum volume. The approximation ignores the crimping round the equator of the bag.\n\nA very rough approximation to the capacity of a bag that is open at one edge is:\n \n:<math>V=w^3  \\left (h/ \\left (\\pi  w \\right ) -0.071 \\left (1-10^ \\left (-2h/w \\right ) \\right ) \\right )</math>\n\n(This latter formula assumes that the corners at the bottom of the bag are linked by a single edge, and that the base of the bag is not a more complex shape such as a [[lens (geometry)|lens]]).\n\n== The square teabag ==\nIn the special case where the bag is sealed on all edges and is square with unit sides, ''h'' = ''w'' = 1, and so the first formula estimates a volume for this of roughly:\n\n:<math>V=\\frac 1 {\\pi} - 0.142 \\cdot 0.9  </math>\n\nor roughly 0.19. According to [[Andrew Kepert]] at the [[University of Newcastle, Australia]], an upper bound for this version of the teabag problem is 0.217+, and he has made a construction that appears to give a volume of 0.2055+.\n\nIn the article referred to above A C  Robin also found a more complicated formula for the general paper bag. Whilst this is beyond the scope of a general work, it is of interest to note that for the tea bag case this formula gives 0.2017, unfortunately not within the bounds given by Kepert (i.e., 0.2055+ ≤ maximum volume ≤ 0.217+).\n\n== See also ==\n* [[Biscornu]], a shape formed by attaching two squares in a different way, with the corner of one at the midpoint of the other\n* [[Mylar balloon (geometry)]]\n\n== References ==\n* {{MathWorld|title=Paper Bag|urlname=PaperBag}}\n* {{cite journal|author1=Baginski, F. |author2=Chen, Q. |author3=Waldman, I. |last-author-amp=yes |\nyear=2001|\ntitle=Modeling the Design Shape of a Large Scientific Balloon|\njournal=[[Applied Mathematical Modelling]]|\nvolume=25|\npages=953–956|\ndoi=10.1016/S0307-904X(01)00024-5|\nissue=11}}\n* {{cite journal|\nauthor=Mladenov, I. M.|\nyear=2001|\ntitle=On the Geometry of the Mylar Balloon|\njournal=[[Comptes Rendus de l'Académie Bulgare des Sciences|C. R. Acad. Bulg. Sci.]]|\nvolume=54|\npages=39–44}}\n* {{cite journal|\nauthor=Paulsen, W. H.|\nyear=1994|\ntitle=What Is the Shape of a Mylar Balloon?|\njournal=[[American Mathematical Monthly]]|\nvolume=101|\npages=953–958|\ndoi=10.2307/2975161|\njstor=2975161|\nissue=10}}\n* {{cite journal|\nauthor=Anthony C Robin|\nyear=2004|\ntitle=Paper Bag Problem|\njournal=[[Institute of Mathematics and its Applications#Mathematics Today|Mathematics Today]]|\npublisher=[[Institute of Mathematics and its Applications]]|\nissn=1361-2042 |\nvolume=June|\npages=104–107}}\n\n== External links ==\n* [http://www.ics.uci.edu/~eppstein/junkyard/teabag.html The original statement of the teabag problem]\n* [https://web.archive.org/web/20030506080953/http://maths.newcastle.edu.au/~andrew/teabag/ Andrew Kepert's work on the teabag problem (mirror)]\n* [https://web.archive.org/web/20050616180606/http://frey.newcastle.edu.au/~andrew/teabag/folding/curvedFold.html Curved folds for the teabag problem]\n* [https://web.archive.org/web/20050410213151/http://www.dse.nl/%7Eandreas/teabag.html A numerical approach to the teabag problem by Andreas Gammel]\n* {{MathWorld|title=Paper Bag|urlname=PaperBag}}\n\n[[Category:Geometric shapes]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Pareto efficiency",
      "url": "https://en.wikipedia.org/wiki/Pareto_efficiency",
      "text": "{{Use mdy dates|date=January 2016}}\n\n'''Pareto efficiency''' or '''Pareto optimality''' is a state of allocation of resources from which it is impossible to reallocate so as to make any one individual or preference criterion better off without making at least one  individual or preference criterion worse off. The concept is named after [[Vilfredo Pareto]] (1848–1923), Italian engineer and economist, who used the concept in his studies of [[economic efficiency]] and [[income distribution]]. \n\nThe '''Pareto frontier''' is the set of all Pareto efficient allocations, conventionally shown [[Chart|graphically]]. It also is variously known as the '''Pareto front''' or '''Pareto set'''.<ref>{{Cite web|url=http://www.cenaero.be/Page.asp?docid=27103&|title=Pareto Front|last=proximedia|date=|website=www.cenaero.be|archive-url=|archive-date=|dead-url=|access-date=2018-10-08}}</ref>\n\nA '''Pareto improvement''' is a change to a different allocation that makes at least one individual or preference criterion [[utility|better off]] without making any other individual or preference criterion worse off, given a certain initial allocation of [[good (economics)|good]]s among a set of [[agent (economics)|individuals]]. An allocation is defined as \"Pareto efficient\" or \"Pareto optimal\" when no further Pareto improvements can be made, in which case we are assumed to have reached '''Pareto optimality'''.\n\n\"Pareto efficiency\" is considered as a minimal notion of efficiency that does not necessarily result in a socially desirable distribution of resources: it makes no statement about [[Social equality|equality]], or the overall well-being of a society.<ref>{{cite book |first=N. |last=Barr |author-link=Nicholas Barr|chapter=3.2.2 The relevance of efficiency to different theories of society |title=Economics of the Welfare State |chapterurl=https://books.google.com/books?id=DOg0BM1XiqQC&pg=PA46 |year=2012 |publisher=Oxford University Press |isbn=978-0-19-929781-8 |pages=46 |edition=5th}}</ref><ref>{{cite journal |authorlink=Amartya Sen |first=A. |last=Sen |title=Markets and freedom: Achievements and limitations of the market mechanism in promoting individual freedoms |journal=Oxford Economic Papers |volume=45 |issue=4 |pages=519–541 |date=October 1993 |jstor=2663703 |url=http://www.cs.princeton.edu/courses/archive/spr06/cos444/papers/sen.pdf |doi=10.1093/oxfordjournals.oep.a042106 }}</ref> It is simply a statement of impossibility of improving one variable without harming other variables in the subject of [[multi-objective optimization]] (also termed '''Pareto optimization'''). \n\nBesides economics, the notion of Pareto efficiency has been applied to the selection of alternatives in [[engineering]] and [[biology]]. Each option is first assessed, under multiple criteria, and then a subset of options is ostensibly identified with the property that no other option can categorically outperform the specified option.\n\nIn addition to the context of efficiency in ''allocation'', the concept of Pareto efficiency also arises in the context of [[productive efficiency|''efficiency in production'']]: a set of outputs of goods is Pareto efficient if there is no feasible re-allocation of productive inputs such that output of one product increases while the outputs of all other goods either increase or remain the same.\n\n== Overview ==\n\n\"Pareto optimality\" is a formally defined concept used to determine when an [[resource allocation|allocation]] is optimal. An allocation is ''not'' Pareto optimal if there is an alternative allocation where improvements can be made to at least one participant's well-being without reducing any other participant's well-being. If there is a transfer that satisfies this condition, the reallocation is called a \"Pareto improvement.\" When no further Pareto improvements are possible, the allocation is a \"Pareto optimum.\"\n\nThe formal presentation of the concept in an economy is as follows: Consider an economy with <math> n</math> agents and <math> k </math> goods. Then an allocation <math> \\{x_1, ..., x_n\\} </math>, where <math> x_i \\in \\mathbb{R}^k </math> for all ''i'', is ''Pareto optimal'' if there is no other feasible allocation <math> \\{x_1', ..., x_n'\\} </math> such that, for utility function <math> u_i </math> for each agent <math> i </math>, <math> u_i(x_i') \\geq u_i(x_i) </math> for all <math> i \\in \\{1, ..., n\\} </math> with <math> u_i(x_i') > u_i(x_i) </math> for some <math> i</math>.<ref name=\"AndreuMas95\">{{citation|author-link=Andreu Mas-Colell|last1=Mas-Colell|first1=A.| first2=Michael D.|last2=Whinston|first3=Jerry R.|last3=Green|year=1995|title=Microeconomic Theory|chapter=Chapter 16: Equilibrium and its Basic Welfare Properties|publisher=Oxford University Press|isbn= 978-0-19-510268-0}}</ref> Here, in this simple economy, \"feasibility\" refers to an allocation where the total amount of each good that is allocated sums to no more than the total amount of the good in the economy. In a more complex economy with production, an allocation would consist both of consumption [[Vector space|vector]]s and production vectors, and feasibility would require that the total amount of each consumed good is no greater than the initial endowment plus the amount produced.\n\nIn principle, a change from a generally inefficient economic allocation to an efficient one is not necessarily considered to be a Pareto improvement. Even when there are overall gains in the economy, if a single agent is disadvantaged by the reallocation, the allocation is not Pareto optimal. For instance, if a change in economic policy eliminates a monopoly and that market subsequently becomes competitive, the gain to others may be large. However, since the monopolist is disadvantaged, this is not a Pareto improvement. In theory, if the gains to the economy are larger than the loss to the monopolist, the monopolist could be compensated for its loss while still leaving a net gain for others in the economy, allowing for a Pareto improvement. Thus, in practice, to ensure that nobody is disadvantaged by a change aimed at achieving Pareto efficiency, [[compensation principle|compensation]] of one or more parties may be required. It is acknowledged, in the real world, that such compensations may have [[unintended consequences]] leading to incentive distortions over time, as agents supposedly anticipate such compensations and change their actions accordingly.<ref>See [[Ricardian equivalence]]</ref>\n\nUnder the idealized conditions of the [[first welfare theorem]], a system of [[free market]]s, also called a \"[[competitive equilibrium]],\" leads to a Pareto-efficient outcome. It was first demonstrated mathematically by economists [[Kenneth Arrow]] and [[Gérard Debreu]]. \n\nHowever, the result only holds under the restrictive assumptions necessary for the proof: markets exist for all possible goods, so there are no [[externality|externalities]]; all markets are in full equilibrium; markets are perfectly competitive; transaction costs are negligible; and market participants have [[perfect information]]. \n\nIn the absence of perfect information or complete markets, outcomes will generally be Pareto inefficient, per the [[Joseph Stiglitz#Information asymmetry|Greenwald-Stiglitz theorem]].<ref>{{Cite journal |doi=10.2307/1891114 |last1=Greenwald |first1=B. |last2=Stiglitz |first2=J. E. |author1-link=Bruce Greenwald |author2-link=Joseph E. Stiglitz |journal=Quarterly Journal of Economics |volume=101 |issue=2 |pages=229–64 |year=1986 |title=Externalities in economies with imperfect information and incomplete markets |jstor=1891114}}</ref> \n\nThe [[second welfare theorem]] is essentially the reverse of the first welfare-theorem. It states that under similar, ideal assumptions, any Pareto optimum can be obtained by some [[competitive equilibrium]], or [[free market]] system, although it may also require a [[lump-sum]] transfer of wealth.<ref name=\"AndreuMas95\">{{citation|author-link=Andreu Mas-Colell|last1=Mas-Colell|first1=A.| first2=Michael D.|last2=Whinston|first3=Jerry R.|last3=Green|year=1995|title=Microeconomic Theory|chapter=Chapter 16: Equilibrium and its Basic Welfare Properties|publisher=Oxford University Press|isbn= 978-0-19-510268-0}}</ref>\n\n==Weak Pareto efficiency==\nA \"weak Pareto optimum\" (WPO) is an allocation for which there are no possible alternative allocations whose realization would cause every individual to gain.<ref>{{Cite book | doi=10.1007/978-1-4020-9160-5_341|chapter = Pareto Optimality|title = Encyclopedia of Global Justice| pages=808–809|year = 2011|last1 = Mock|first1 = William B T.| isbn=978-1-4020-9159-9}}</ref> Thus, an alternative allocation is considered to be a Pareto improvement ''if and only if'' the alternative allocation is strictly preferred by ''all'' individuals. When contrasted with weak Pareto efficiency, a standard Pareto optimum as described above may be referred to as a \"strong Pareto optimum\" (SPO).\n\nWeak Pareto-optimality is \"weaker\" than strong Pareto-optimality in the sense that any SPO also qualifies as a WPO, but a WPO allocation is not necessarily an SPO.\n\nA market doesn't require [[local nonsatiation]] to get to a weak Pareto-optimum.<ref>Markey‐Towler, Brendan and John Foster. \"Why economic theory has little to say about the causes and effects of inequality\", School of Economics, [[University of Queensland]], Australia, 21 February 2013, RePEc:qld:uq2004:476</ref>\n\n== Constrained Pareto efficiency {{anchor|Constrained Pareto efficiency}}==\nThe condition of '''constrained Pareto optimality''' is a weaker version of the standard condition of Pareto optimality employed in [[economics]], which ostensibly accounts for the fact that a potential planner (e.g., the government) may not be able to improve upon a decentralized market outcome, even if that outcome is inefficient. This will occur if it is limited by the same informational or institutional constraints as are individual agents.<ref>Magill, M., & Quinzii, M., ''Theory of Incomplete Markets'', MIT Press, 2002, p. 104 [https://books.google.com/books?id=d66GXq2F2M0C&pg=PA104&lpg=PA104&dq=constrained+pareto+optimality&source=web&ots=IQFRM9b00n&sig=LHWki_HOLB77G8xw3RiT0-0DSeY&hl=en&sa=X&oi=book_result&resnum=4&ct=result].</ref>\n\nThe most commonly proffered example is of a setting where individuals have private information (for example, a labor market where the worker's own productivity is known to the worker but not to a potential employer, or a used-car market where the quality of a car is known to the seller but not to the buyer) which results in [[moral hazard]] or an [[adverse selection]] and a sub-optimal outcome. In such a case, a planner who wishes to improve the situation is deemed unlikely to have access to any information that the participants in the markets do not have. Hence, the planner cannot implement allocation rules which are based on the idiosyncratic characteristics of individuals; for example, \"if a person is of type A, they pay price p1, but if of type B, they pay price p2\" (see [[Lindahl prices]]). Essentially, only anonymous rules are allowed (of the sort \"Everyone pays price p\") or rules based on observable behavior; \"if any person chooses x at price px, then they get a subsidy of ten dollars, and nothing otherwise\". If there exists no allowed rule that can successfully improve upon the market outcome, then that outcome is said to be \"constrained Pareto-optimal.\"\n\nNote that the concept of constrained Pareto optimality assumes benevolence on the part of the planner and hence it is distinct from the concept of [[government failure]], which occurs when the policy making politicians fail to achieve an optimal outcome simply because they are not necessarily acting in the public's best interest.\n\n== Pareto-efficiency and welfare-maximization ==\n{{See also|Pareto-efficient envy-free division}}\nSuppose each agent ''i'' is assigned a positive weight ''a<sub>i</sub>''. For every allocation ''x'', define the ''welfare'' of ''x'' as the weighted sum of utilities of all agents in ''x'', i.e: \n\n<math>W_a(x) := \\sum_{i=1}^n a_i u_i(x)</math>. \n\nLet ''x<sub>a</sub>'' be an allocation that maximizes the welfare over all allocations, i.e:\n\n<math>x_a \\in \\arg \\max_{x} W_a(x)</math>. \n\nIt is easy to show that the allocation ''x<sub>a</sub>'' is Pareto-efficient: since all weights are positive, any Pareto-improvement would increase the sum, contradicting the definition of ''x<sub>a</sub>''.\n\n[[Takashi Negishi]] proved<ref>{{cite journal |last=Negishi |first=Takashi |date=1960 |title=Welfare Economics and Existence of an Equilibrium for a Competitive Economy |journal=Metroeconomica |volume=12 |issue=2-3 |pages=92–97 |doi=10.1111/j.1467-999X.1960.tb00275.x }}</ref> that, under certain assumptions, the opposite is also true: for ''every'' Pareto-efficient allocation ''x'', there exists a positive vector ''a'' such that ''x'' maximizes ''W''<sub>a</sub>. A shorter proof is provided by [[Hal Varian]].<ref>{{cite journal |doi=10.1016/0047-2727(76)90018-9 |title=Two problems in the theory of fairness |journal=Journal of Public Economics |volume=5 |issue=3–4 |pages=249–260 |year=1976 |last1=Varian |first1=Hal R. }}</ref>\n\n== Use in engineering==\n\n[[File:Front pareto.svg|thumb|300px|Example of a Pareto frontier. The boxed points represent feasible choices, and smaller values are preferred to larger ones. Point ''C'' is not on the Pareto frontier because it is dominated by both point ''A'' and point ''B''. Points ''A'' and ''B'' are not strictly dominated by any other, and hence do lie on the frontier.]] \n[[File:Pareto Efficient Frontier 1024x1024.png|thumb|256px|A [[production-possibility frontier]]. The red line is an example of a Pareto-efficient frontier, where the frontier and the area left and below it are a continuous set of choices. The red points on the frontier are examples of Pareto-optimal choices of production. Points off the frontier, such as N and K, are not Pareto-efficient, since there exist points on the frontier which Pareto-dominate them.]]\n\nThe notion of Pareto efficiency has been used in engineering. Given a set of choices and a way of valuing them, the '''Pareto frontier''' or '''Pareto set''' or '''Pareto front''' is the set of choices that are Pareto efficient. By restricting attention to the set of choices that are Pareto-efficient, a designer can make [[Trade-off|tradeoffs]] within this set, rather than considering the full range of every parameter.\n\n=== Pareto frontier ===\n\nFor a given system, the '''Pareto frontier''' or '''Pareto set''' is the set of parameterizations (allocations) that are all Pareto efficient. Finding Pareto frontiers is particularly useful in engineering. By yielding all of the potentially optimal solutions, a designer can make focused [[Trade-off|tradeoffs]] within this constrained set of parameters, rather than needing to consider the full ranges of parameters.\n\nThe Pareto frontier, ''P''(''Y''), may be more formally described as follows. Consider a system with function <math>f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m</math>, where ''X'' is a [[compact space|compact set]] of feasible decisions in the [[metric space]] <math>\\mathbb{R}^n</math>, and ''Y'' is the feasible set of criterion vectors in <math>\\mathbb{R}^m</math>, such that <math>Y = \\{ y \\in \\mathbb{R}^m:\\; y = f(x), x \\in X\\;\\}</math>.\n\nWe assume that the preferred directions of criteria values are known. A point <math>y^{\\prime\\prime} \\in \\mathbb{R}^m</math> is preferred to (strictly dominates) another point <math>y^{\\prime} \\in \\mathbb{R}^m</math>, written as <math>y^{\\prime\\prime} \\succ y^{\\prime}</math>. The Pareto frontier is thus written as:\n\n: <math>P(Y) = \\{ y^\\prime \\in Y: \\; \\{y^{\\prime\\prime} \\in Y:\\; y^{\\prime\\prime} \\succ y^\\prime, y^{\\prime\\prime} \\neq y^\\prime \\; \\} = \\empty \\}. </math>\n\n=== Marginal rate of substitution ===\nA significant aspect of the Pareto frontier in economics is that, at a Pareto-efficient allocation, the [[marginal rate of substitution]] is the same for all consumers.  A formal statement can be derived by considering a system with ''m'' consumers and ''n'' goods, and a utility function of each consumer as <math>z_i=f^i(x^i)</math> where <math>x^i=(x_1^i, x_2^i, \\ldots, x_n^i)</math> is the vector of goods, both for all ''i''. The feasibility constraint is <math>\\sum_{i=1}^m x_j^i = b_j</math> for <math>j=1,\\ldots,n</math>. To find the Pareto optimal allocation, we maximize the [[Lagrangian mechanics|Lagrangian]]:\n\n: <math>L_i((x_j^k)_{k,j}, (\\lambda_k)_k, (\\mu_j)_j)=f^i(x^i)+\\sum_{k=2}^m \\lambda_k(z_k- f^k(x^k))+\\sum_{j=1}^n \\mu_j \\left( b_j-\\sum_{k=1}^m x_j^k \\right)</math>\n\nwhere <math>(\\lambda_k)_k</math> and <math>(\\mu_j)_j</math> are the vectors of multipliers. Taking the partial derivative of the Lagrangian with respect to each good <math>x_j^k</math> for <math>j=1,\\ldots,n</math> and <math>k=1,\\ldots, m</math> and gives the following system of first-order conditions:\n\n: <math>\\frac{\\partial L_i}{\\partial x_j^i} = f_{x^i_j}^1-\\mu_j=0\\text{ for }j=1,\\ldots,n,</math>\n\n: <math>\\frac{\\partial L_i}{\\partial x_j^k} = -\\lambda_k f_{x^k_j}^i-\\mu_j=0 \\text{ for }k= 2,\\ldots,m \\text{ and }j=1,\\ldots,n,</math>\n\nwhere <math>f_{x^i_j}</math> denotes the partial derivative of <math>f</math> with respect to <math>x_j^i</math>. Now, fix any <math>k\\neq i</math> and <math>j,s\\in \\{1,\\ldots,n\\}</math>. The above first-order condition imply that\n\n: <math>\\frac{f_{x_j^i}^i}{f_{x_s^i}^i}=\\frac{\\mu_j}{\\mu_s}=\\frac{f_{x_j^k}^k}{f_{x_s^k}^k}.</math>\n\nThus, in a Pareto-optimal allocation, the marginal rate of substitution must be the same for all consumers.\n\n=== Computation ===\n[[Algorithm]]s for computing the Pareto frontier of a finite set of alternatives have been studied in [[computer science]] and power engineering.<ref>{{cite journal |doi=10.3390/en6031439 |last1=Tomoiagă |first1=Bogdan |last2=Chindriş |first2=Mircea |last3=Sumper |first3=Andreas |last4=Sudria-Andreu |first4=Antoni |last5=Villafafila-Robles |first5=Roberto |title=Pareto Optimal Reconfiguration of Power Distribution Systems Using a Genetic Algorithm Based on NSGA-II |journal=Energies |year=2013 |volume=6 |pages=1439–55 }}</ref> They include:\n\n* \"The maximum vector problem\" or the [[Skyline operator|skyline query]].<ref>{{cite journal |doi=10.1016/0020-0190(96)00116-0 |last1=Nielsen |first1=Frank |title=Output-sensitive peeling of convex and maximal layers |journal=Information Processing Letters |volume=59 |pages=255–9 |year=1996 |issue=5 |citeseerx=10.1.1.259.1042 }}</ref><ref>{{cite journal |doi=10.1145/321906.321910 |last1=Kung |first1=H. T. |last2=Luccio |first2=F. |last3=Preparata |first3=F.P. |title=On finding the maxima of a set of vectors |journal=Journal of the ACM |volume=22 |pages=469–76 |year=1975 |issue=4 }}</ref><ref>{{cite journal |doi=10.1007/s00778-006-0029-7 |last1=Godfrey |first1=P. |last2=Shipley |first2=R. |last3=Gryz |first3=J. |journal=VLDB Journal |volume=16 |pages=5–28 |year=2006 |title=Algorithms and Analyses for Maximal Vector Computation |citeseerx=10.1.1.73.6344 }}</ref>\n* \"The scalarization algorithm\" or the method of weighted sums.{{cn|date=June 2017}}\n\n== Use in biology ==\nPareto optimisation has also been studied in biological processes. In bacteria, genes were shown to be either inexpensive to make (resource efficient) or easier to read (translation efficient). Natural selection acts to push highly expressed genes towards the Pareto frontier for resource use and translational efficiency. Genes near the Pareto frontier were also shown to evolve more slowly (indicating that they are providing a selective advantage).<ref>{{Cite journal|doi=10.1186/s13059-018-1480-7|pmid=30064467|last1=Seward|first1=Emily A. |last2=Kelly|first2=Steven|title=Selection-driven cost-efficiency optimization of transcripts modulates gene evolutionary rate in bacteria.|journal=Genome Biology|volume=19|pages=102|year=2018}}</ref>\n\n==Criticisms==\n{{no references|section|date=June 2019}}\nIt would be incorrect to treat Pareto efficiency as equivalent to {{clarify-inline|text=societal optimization|reason=This term not defined & no corresponding article|date=June 2019}}, as the latter is a [[normative]] concept that is a matter of interpretation that typically would account for the consequence of degrees of inequality of distribution. An example would be a school district with low property tax revenue versus one with much higher revenue. Generally, more equal distribution occurs with the help of government redistribution.{{Citation needed|reason=A statement is made here that has strong political implications. Furthermore, the definition of equality is not well defined here|date=May 2018}}\n\nPareto efficiency does not require a totally equitable distribution of wealth. An economy in which a wealthy few hold the [[Wealth condensation|vast majority of resources]] can be Pareto efficient. This possibility is inherent in the definition of Pareto efficiency; often the [[status quo]] is Pareto efficient regardless of the degree to which wealth is equitably distributed. A simple example is the distribution of a pie among three people. The most equitable distribution would assign one third to each person. However the assignment of, say, a half section to each of two individuals and none to the third is also Pareto optimal despite not being equitable, because none of the recipients could be made better off without decreasing someone else's share; and there are many other such distribution examples. An example of a Pareto inefficient distribution of the pie would be allocation of a quarter of the pie to each of the three, with the remainder discarded. The origin (and utility value) of the pie is conceived as immaterial in these examples. In such cases, whereby a \"windfall\" is gained that none of the potential distributees actually produced (e.g., land, inherited wealth, a portion of the broadcast spectrum, or some other resource), the criterion of Pareto efficiency does not determine a unique optimal allocation. Wealth consolidation may exclude others from wealth accumulation because of bars to market entry, etc.\n\nThe [[liberal paradox]] elaborated by [[Amartya Sen]] shows that when people have preferences about what other people do, the goal of Pareto efficiency can come into conflict with the goal of individual liberty.\n\n==See also==\n* [[Admissible decision rule]], analog in [[decision theory]]\n* [[Arrow's impossibility theorem]]\n* [[Bayesian efficiency]]\n* [[Fundamental theorems of welfare economics]]\n* [[Deadweight loss]]\n* [[Economic efficiency]]\n* [[Highest and best use]]\n* [[Kaldor–Hicks efficiency]]\n* [[Market failure]], when a market result is not Pareto optimal\n* [[Maximal element]], concept in [[order theory]]\n* [[Maxima of a point set]]\n* [[Multi-objective optimization]]\n* [[Pareto-efficient envy-free division]]\n* ''[[Social Choice and Individual Values]]'' for the '(weak) Pareto principle'\n* [[Trade-off talking rational economic person|TOTREP]]\n* [[Welfare economics]]\n\n==References==\n{{reflist|30em}}\n\n== Further reading ==\n* {{Cite Fudenberg Tirole 1991|pages=18–23}}\n* {{Cite journal |last1=Bendor | first1=Jonathan |last2= Mookherjee | first2=Dilip | title = Communitarian versus Universalistic norms | journal = [[Quarterly Journal of Political Science]] | volume = 3 | issue = 1 | pages = 33–61 | doi = 10.1561/100.00007028 | date = April 2008 | ref = harv }}\n* {{Cite journal | last = Kanbur | first = Ravi| author-link = Ravi Kanbur | title = Pareto's revenge | journal = Journal of Social and Economic Development | volume = 7 | issue = 1 | pages = 1–11 | date = January–June 2005 | url = http://www.arts.cornell.edu/poverty/kanbur/ParRev.pdf | ref = harv }}\n* {{cite book | last = Ng | first = Yew-Kwang | author-link = Yew-Kwang Ng | title = Welfare economics towards a more complete analysis | publisher = Palgrave Macmillan | location = Basingstoke, Hampshire New York | year = 2004 | isbn = 9780333971215 }}\n* {{Citation | author-first1=Ariel | author-last1=Rubinstein | author-first2=Martin J. | author-last2=Osborne | author-link1 = Ariel Rubinstein | contribution = Introduction | editor-first1=Ariel | editor-last1=Rubinstein | editor-first2=Martin J. | editor-last2=Osborne | editor-link1 = Ariel Rubinstein | title = A course in game theory | pages = 6–7 | publisher = MIT Press | location = Cambridge, Massachusetts | year = 1994 | isbn = 9780262650403 }} [https://books.google.com/books?id=5ntdaYX4LPkC&pg=PA6 Book preview.]\n* {{Cite journal | last = Mathur | first = Vijay K. | title = How well do we know Pareto optimality? | journal = The Journal of Economic Education | volume = 22 | issue = 2 | pages = 172–178 | doi = 10.2307/1182422 | date = Spring 1991 | ref = harv | jstor = 1182422 }}\n* {{Cite journal | last1 = Newbery | first1 = David M.G. | last2 = Stiglitz | first2 = Joseph E. | author-link1 = David Newbery | author-link2 = Joseph Stiglitz | title = Pareto inferior trade | journal = Review of Economic Studies | volume = 51 | issue = 1 | pages = 1–12 | doi = 10.2307/2297701 | date = January 1984 | ref = harv | jstor = 2297701 }}\n\n{{Economics}}\n{{Game theory}}\n{{Voting systems}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Pareto Efficiency}}\n[[Category:Game theory]]\n[[Category:Law and economics]]\n[[Category:Welfare economics]]\n[[Category:Pareto efficiency]]\n[[Category:Mathematical optimization]]\n[[Category:Electoral system criteria]]\n[[Category:Vilfredo Pareto]]"
    },
    {
      "title": "Proximal operator",
      "url": "https://en.wikipedia.org/wiki/Proximal_operator",
      "text": "In [[mathematical optimization]], the '''proximal''' operator is an [[Operator (mathematics)|operator]] associated with a [[convex function]] <math>f</math>\nfrom a [[vector space]] <math>\\mathcal{X}</math>\nto <math>\\mathbb{R}</math>, and is defined by:\n<ref>{{cite journal|url=https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf |title=Proximal Algorithms |author=Neal Parikh and Stephen Boyd |journal= Foundations and Trends in Optimization |volume=1 |issue=3 |year=2013 |pages=123–231 |accessdate=2019-01-29}}</ref>\n\n::<math>\\operatorname{prox}_f(v) = \\arg \\min_{x\\in\\mathcal{X}} \\left(f(x) + \\frac 1 2 \\|x - v\\|_2^2\\right).</math>\n\nIt is frequently used in optimization algorithms associated with non-[[Differentiable function|differentiable]] optimization problems such as [[total variation denoising]].\n\nThe proximal operator reduces to the operator that projects a point onto a convex set if <math> f(x) </math> is the [[Characteristic function (convex_analysis)| 0-<math>\\infty</math> indicator function]] of that convex set.\n==See also==\n* [[Proximal gradient method]]\n\n==References==\n{{Reflist}}\n\n[[Category:Mathematical optimization]]\n\n==External links==\n* The [http://proximity-operator.net/ Proximity Operator repository]: a collection of proximity operators implemented in [[Matlab]] and [[Python (programming language)|Python]].\n* [https://github.com/kul-forbes/ProximalOperators.jl ProximalOperators.jl]: a [[Julia_(programming_language)|Julia]] package implementing proximal operators.\n* [https://github.com/odlgroup/odl ODL]: a Python library for [[inverse problems]] that utilizes proximal operators."
    },
    {
      "title": "Pseudo-Boolean function",
      "url": "https://en.wikipedia.org/wiki/Pseudo-Boolean_function",
      "text": "In [[mathematics]] and [[optimization]], a '''pseudo-Boolean function''' is a [[function (mathematics)|function]] of the form\n:<math>f:\\mathbf{B}^n \\rightarrow \\mathbb{R}</math>,\nwhere '''B'''&nbsp;=&nbsp;{0,&nbsp;1} is a ''[[Boolean domain]]'' and ''n'' is a nonnegative integer called the [[arity]] of the function.  A [[Boolean function]] is then a special case, where the values are also restricted to 0,1.\n\n==Representations==\n\nAny pseudo-Boolean function can be written uniquely as a [[multi-linear]] polynomial:<ref>{{Cite journal|url = |title = On the determination of the minima of pseudo-Boolean functions|last = Hammer|first = P.L.|date = 1963|journal = Studii ¸si Cercetari Matematice|doi = |pmid = |access-date = |last2 = Rosenberg|first2 = I.|last3 = Rudeanu|first3 = S.|issue = 14|publisher = |pages = 359–364|language = Romanian|issn = 0039-4068}}</ref><ref>{{Cite book|title = Boolean Methods in Operations Research and Related Areas|last = Hammer|first = Peter L.|publisher = Springer|year = 1968|isbn = 978-3-642-85825-3|location = |pages = |last2 = Rudeanu|first2 = Sergiu}}</ref>\n:<math>f(\\boldsymbol{x}) = a + \\sum_i a_ix_i + \\sum_{i<j}a_{ij}x_ix_j + \\sum_{i<j<k}a_{ijk}x_ix_jx_k + \\ldots</math>\nThe '''degree''' of the pseudo-Boolean function is simply the degree of the [[polynomial]] in this representation.\n\nIn many settings (e.g., in [[Analysis of Boolean functions|Fourier analysis of pseudo-Boolean functions]]), a pseudo-Boolean function is viewed as a function <math>f</math> that maps <math>\\{-1,1\\}^n</math> to <math>\\mathbb{R}</math>. Again in this case we can uniquely write  <math>f</math> as a multi-linear polynomial:\n<math> f(x)= \\sum_{I\\subseteq [n]}\\hat{f}(I)\\prod_{i\\in I}x_i, </math> where <math> \\hat{f}(I) </math> are Fourier coefficients of <math>f</math> and <math>[n]=\\{1,...,n\\}</math>.\n\n==Optimization==\nMinimizing (or, equivalently, maximizing) a pseudo-Boolean function is [[NP-hard]]. This can easily be seen by formulating, for example, the [[maximum cut]] problem as maximizing a pseudo-Boolean function.<ref name=\"boroshammer\" />\n\n===Submodularity===\nThe [[submodular set function]]s can be viewed as a special class of pseudo-Boolean functions, which is equivalent to the condition\n:<math> f(\\boldsymbol{x}) + f(\\boldsymbol{y}) \\ge  f(\\boldsymbol{x} \\wedge \\boldsymbol{y}) + f(\\boldsymbol{x} \\vee \\boldsymbol{y}), \\; \\forall \\boldsymbol{x}, \\boldsymbol{y}\\in \\mathbf{B}^n\\,. </math>\nThis is an important class of pseudo-boolean functions, because they can be [[Submodular set function#Submodular Minimization|minimized in polynomial time]].\n\n===Roof Duality===\nIf ''f'' is a quadratic polynomial, a concept called ''roof duality'' can be used to obtain a lower bound for its minimum value.<ref name=\"boroshammer\">Boros and Hammer, 2002</ref> Roof duality may also provide a partial assignment of the variables, indicating some of the values of a minimizer to the polynomial. Several different methods of obtaining lower bounds were developed only to later be shown to be equivalent to what is now called roof duality.<ref name=\"boroshammer\" />\n\n===Reductions===\nIf the degree of ''f'' is greater than 2, one can always employ ''reductions'' to obtain an equivalent quadratic problem with additional variables.<ref name=\"ishikawa2011\">Ishikawa, 2011</ref> One possible reduction is\n:<math>\\displaystyle  \t-x_1x_2x_3=\\min_{z\\in\\mathbf{B}}z(2-x_1-x_2-x_3)</math>\nThere are other possibilities, for example,\n:<math> \\displaystyle  \t-x_1x_2x_3=\\min_{z\\in\\mathbf{B}}z(-x_1+x_2+x_3)-x_1x_2-x_1x_3+x_1. </math>\nDifferent reductions lead to different results. Take for example the following cubic polynomial:<ref name=\"kahlstrandmark\">Kahl and Strandmark, 2011</ref>\n:<math> \\displaystyle  \tf(\\boldsymbol{x})=-2x_1+x_2-x_3+4x_1x_2+4x_1x_3-2x_2x_3-2x_1x_2x_3. </math>\nUsing the first reduction followed by roof duality, we obtain a lower bound of -3 and no indication on how to assign the three variables. Using the second reduction, we obtain the (tight) lower bound of -2 and the optimal assignment of every variable (which is <math> {(0,1,1)}</math>).\n\n===Polynomial Compression Algorithms===\nConsider a pseudo-Boolean function <math> f </math> as a mapping from <math>\\{-1,1\\}^n</math> to <math>\\mathbb{R}</math>. Then <math> f(x)= \\sum_{I\\subseteq [n]}\\hat{f}(I)\\prod_{i\\in I}x_i. </math> Assume that each coefficient <math>\\hat{f}(I)</math> is integral. \nThen for an integer <math> k </math> the problem P of deciding whether <math> f(x) </math> is more or equal to <math> k </math> is NP-complete. It is proved in <ref name=\"crow\">Crowston et al., 2011</ref> that\nin polynomial time we can either solve P or reduce the number of variables to <math> O(k^2\\log k) </math>.\nLet <math> r </math> be the degree of the above multi-linear polynomial for <math> f </math>. Then <ref name=\"crow\">Crowston et al., 2011</ref> proved that in polynomial time we can either solve P or reduce the number of variables to <math> r(k-1) </math>.\n\n==See also==\n*[[Boolean function]]\n*[[Quadratic pseudo-Boolean optimization]]\n\n==References==\n* {{cite journal|last=Boros|author2=Hammer |title=Pseudo-Boolean Optimization|journal=Discrete Applied Mathematics|year=2002|volume=123|issue=1–3 |pages=155–225 |doi=10.1016/S0166-218X(01)00341-9}}\n* {{cite journal|last=Crowston |author2=Fellows, Gutin |author3=Jones, Rosamond |author4=Thomasse, Yeo|title=Simultaneously Satisfying Linear Equations Over GF(2): MaxLin2 and Max-r-Lin2 Parameterized Above Average.|journal=Proc. Of FSTTCS 2011|year=2011|arxiv=1104.1135|bibcode=2011arXiv1104.1135C}}\n* {{cite journal|last=Ishikawa|title=Transformation of general binary MRF minimization to the first order case|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|year=2011|volume=33|number=6|pages=1234–1249|doi=10.1109/tpami.2010.91|pmid=20421673|citeseerx=10.1.1.675.2183}}\n* {{cite journal|last=Rother|author2=Kolmogorov|author3=Lempitsky|author4=Szummer|title=Optimizing Binary MRFs via Extended Roof Duality|journal=International Conference on Computer Vision and Pattern Recognition|year=2007|url=http://research.microsoft.com/pubs/67978/cvpr07-QPBOpi.pdf}}\n* {{cite journal|last=Kahl|author2=Strandmark |title=Generalized Roof Duality for Pseudo-Boolean Optimization|journal=International Conference on Computer Vision |year=2011|url=http://www.maths.lth.se/vision/publdb/reports/pdf/kahl-strandmark-iccv-11.pdf}}\n* {{cite journal|last=O'Donnell|first=Ryan|title=Some topics in analysis of Boolean functions|journal={{ECCC|2008|08|055}}|year=2008|url=http://www.eccc.uni-trier.de/eccc-reports/2008/TR08-055/}}\n\n==Notes==\n<references />\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Quadratically constrained quadratic program",
      "url": "https://en.wikipedia.org/wiki/Quadratically_constrained_quadratic_program",
      "text": "In [[mathematical optimization]], a '''quadratically constrained quadratic program''' ('''QCQP''') is an [[optimization problem]] in which both the [[objective function]] and the [[constrained optimization|constraints]] are [[quadratic function]]s. It has the form\n\n:<math> \\begin{align}\n& \\text{minimize} && \\tfrac12 x^\\mathrm{T} P_0 x + q_0^\\mathrm{T} x \\\\\n& \\text{subject to} && \\tfrac12 x^\\mathrm{T} P_i x + q_i^\\mathrm{T} x + r_i \\leq 0 \\quad \\text{for } i = 1,\\dots,m , \\\\\n&&& Ax = b, \n\\end{align} </math>\n\nwhere ''P''<sub>0</sub>, &hellip; ''P''<sub>''m''</sub> are ''n''-by-''n'' matrices and ''x'' &isin; '''R'''<sup>''n''</sup> is the optimization variable.\n\nIf ''P''<sub>0</sub>, &hellip; ''P''<sub>''m''</sub> are all [[Positive-definite matrix|positive semidefinite]], then the problem is [[Convex set|convex]]. If these matrices are neither positive nor negative semidefinite, the problem is non-convex. If ''P''<sub>1</sub>, &hellip; ''P''<sub>''m''</sub> are all zero, then the constraints are in fact [[Linear map|linear]] and the problem is a [[quadratic program]].\n\n== Hardness ==\nSolving the general case is an [[NP-hard]] problem. To see this, note that the two constraints ''x''<sub>1</sub>(''x''<sub>1</sub> − 1) &le; 0 and ''x''<sub>1</sub>(''x''<sub>1</sub> − 1) &ge; 0 are equivalent to the constraint ''x''<sub>1</sub>(''x''<sub>1</sub> − 1) = 0, which is in turn equivalent to the constraint ''x''<sub>1</sub> &isin; {0, 1}. Hence, any [[0–1 integer program]] (in which all variables have to be either 0 or 1) can be formulated as a quadratically constrained quadratic program. Since 0–1 integer programming is NP-hard in general, QCQP is also NP-hard.\n\n== Relaxation ==\nThere are two main relaxations of QCQP: using [[semidefinite programming]] (SDP), and using the [[reformulation-linearization technique]] (RLT).\n\n=== Semidefinite programming ===\nWhen ''P''<sub>0</sub>, &hellip; ''P''<sub>''m''</sub> are all [[Positive-definite matrix|positive-definite matrices]], the problem is [[Convex optimization|convex]] and can be readily solved using [[interior point method]]s, as done with [[semidefinite programming]].\n\n== Example ==\n[[Cut (graph theory)|Max Cut]] is a problem in graph theory, which is NP-hard. Given a graph, the problem is to divide the vertices in two sets, so that as many edges as possible go from one set to the other. Max Cut can be formulated as a QCQP, and SDP relaxation of the dual provides good lower bounds.\n\n==Solvers and scripting (programming) languages==\n\n{| class=\"wikitable\"\n|-\n!Name\n!Brief info\n|-\n|[[Artelys Knitro]]|| Knitro is a solver specialized in nonlinear optimization, but also solves linear programming problems, quadratic programming problems, second-order cone programming, systems of nonlinear equations, and problems with equilibrium constraints.\n|-\n|[[FICO Xpress]]|| A commercial optimization solver for linear programming, non-linear programming, mixed integer linear programming, convex quadratic programming, convex quadratically constrained quadratic programming, second-order cone programming and their mixed integer counterparts.\n|-\n|[[AMPL]]||\n|-\n|[[CPLEX]]|| Popular solver with an API for several programming languages.  Free for academics.\n|-\n|[[Gurobi]]|| Solver with parallel algorithms for large-scale linear programs, quadratic programs and mixed-integer programs. Free for academic use.\n|- \n|[[MOSEK]]|| A solver for large scale optimization with API for several languages (C++,java,.net, Matlab and python)\n|-\n|[[TOMLAB]]||Supports global optimization, integer programming, all types of least squares, linear, quadratic and unconstrained programming for [[MATLAB]]. TOMLAB supports solvers like [[Gurobi]], [[CPLEX]], [[SNOPT]] and [[KNITRO]].\n|}\n\n== References ==\n* {{cite book\n  | last = Boyd\n  | first = Stephen\n  |author2=Lieven Vandenberghe\n   | title = Convex Optimization\n  | publisher = Cambridge University Press\n  | year = 2004\n  | location = Cambridge\n  | url = http://www.stanford.edu/~boyd/cvxbook/\n  | isbn = 978-0-521-83378-3}}\n\n== Further reading ==\n\n=== In statistics ===\n* {{cite journal |author=Albers CJ, Critchley F, Gower, JC |title=Quadratic Minimisation Problems in Statistics |journal=Journal of Multivariate Analysis |volume=102 |issue=3 |pages=698–713 |year=2011 |doi=10.1016/j.jmva.2009.12.018 }}\n\n==External links==\n* [http://neos-guide.org/content/quadratic-constrained-quadratic-programming NEOS Optimization Guide: Quadratic Constrained Quadratic Programming]\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Rastrigin function",
      "url": "https://en.wikipedia.org/wiki/Rastrigin_function",
      "text": "{{multiple image\n   | direction = vertical\n   | width     = 300\n   | header    = Rastrigin function of two variables\n   | image1    = Rastrigin_function.png\n   | caption1  = In 3D\n   | image2    = Rastrigin Contour.jpg\n   | caption2  = Contour\n}}\n\nIn [[mathematical optimization]], the '''Rastrigin function''' is a non-[[convex function]] used as a performance test problem for [[optimization algorithm]]s. It is a typical example of non-linear multimodal function. It was first proposed by Rastrigin <ref>Rastrigin, L. A. \"Systems of extremal control.\" Mir, Moscow (1974).</ref> as a 2-dimensional function and has been generalized by Mühlenbein et al.<ref>H. Mühlenbein, D. Schomisch and J. Born. \"The Parallel Genetic Algorithm as Function Optimizer \". Parallel Computing, 17, pages 619&ndash;632, 1991.</ref> Finding the minimum of this function is a fairly difficult problem due to its large search space and its large number of [[local minimum|local minima]].\n\nOn an n-dimensional domain it is defined by:\n: <math>f(\\mathbf{x}) = A n + \\sum_{i=1}^n \\left[x_i^2 - A\\cos(2 \\pi x_i)\\right]</math>\nwhere  <math>A=10</math> and <math>x_i\\in[-5.12,5.12] </math>. It has a global minimum at <math>\\mathbf{x} = \\mathbf{0}</math> where <math>f(\\mathbf{x})=0</math>.\n\n== See also ==\n*[[Test functions for optimization]]\n\n==Notes==\n<references/>\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Response surface methodology",
      "url": "https://en.wikipedia.org/wiki/Response_surface_methodology",
      "text": "[[File:Response surface metodology.jpg|thumb|Designed experiments with full factorial design (left), response surface with second-degree polynomial (right)]]\n\nIn statistics, '''response surface methodology (RSM)''' explores the relationships between several [[explanatory variable]]s and one or more [[response variable]]s.  The method was introduced by [[George E. P. Box]] and K. B. Wilson in 1951.  The main idea of RSM is to use a sequence of [[design of experiments|designed experiments]] to obtain an optimal response.  Box and Wilson suggest using a [[Degree of a polynomial|second-degree]] [[polynomial]] model to do this.  They acknowledge that this model is only an approximation, but they use it because such a model is easy to estimate and apply, even when little is known about the process.\n\nStatistical approaches such as RSM can be employed to maximize the production of a special substance by optimization of operational factors. In contrast to conventional methods, the interaction among process variables can be determined by statistical techniques.<ref name=\"Organosolv\">{{cite journal|last1=Asadi|first1=Nooshin|last2=Zilouei|first2=Hamid|title=Optimization of organosolv pretreatment of rice straw for enhanced biohydrogen production using Enterobacter aerogenes|journal=Bioresource Technology|date=March 2017|volume=227|pages=335–344|doi=10.1016/j.biortech.2016.12.073|pmid=28042989|url=https://www.researchgate.net/publication/311881656}}</ref><ref>Ahmed Maged, Salah Haridy, Mohammad Shamsuzzaman, Imad Alsyouf, and Roubi Zaied. (2018).[https://www.researchgate.net/publication/326072519_Statistical_Monitoring_and_Optimization_of_Electrochemical_Machining_using_Shewhart_Charts_and_Response_Surface_Methodology Statistical Monitoring and Optimization of Electrochemical Machining using Shewhart Charts and Response Surface Methodology.] 3(2), 68-77. https://doi.org/10.26776/ijemm.03.02.2018.01</ref> The work by Box and co-workers was summarized in the book <ref>{{Cite book|title=Response Surfaces, Mixtures, and Ridge Analyses|last=Box|first=George E. P.|last2=Draper|first2=Norman R.|date=2007-03-09|publisher=John Wiley & Sons, Inc.|isbn=9780470072769|location=Hoboken, NJ, USA|doi = 10.1002/0470072768}}</ref>.  Other important textbooks in RSM with a more recent set of topics other than those originally studied by Box and co-workers in the 50's and 60's are <ref>{{Cite book|title=Response Surfaces: Design and Analyses|last=Khuri, A.I., and Cornell, J.A|publisher=Marcel Dekker|year=1996|isbn=|location=|pages=}}</ref><ref>{{Cite book|title=Process optimization : a statistical approach|last=del Castillo|first=Enrique|date=2007|publisher=Springer|isbn=9780387714349|location=|pages=|oclc=783405607}}</ref>.\n\n==Basic approach of response surface methodology==\nAn easy way to estimate a first-degree polynomial model is to use a [[factorial experiment]] or a [[fractional factorial design]].  This is sufficient to determine which explanatory variables affect the response variable(s) of interest.  Once it is suspected that only significant explanatory variables are left, then a more complicated design, such as a [[central composite design]] can be implemented to estimate a second-degree polynomial model, which is still only an approximation at best.  However, the second-degree model can be used to optimize (maximize, minimize, or attain a specific target for) the response variable(s) of interest.\n\n==Important RSM properties and features==\n\n''ORTHOGONALITY:''\nThe property that allows individual effects of the k-factors to be estimated independently without (or with minimal) confounding. Also orthogonality provides minimum variance estimates of the model coefficient so that they are uncorrelated.\n\n''ROTATABILITY'':\nThe property of rotating points of the design about the center of the factor space. The moments of the distribution of the design points are constant.\n\n''UNIFORMITY:''\nA third property of CCD designs used to control the number of center points is uniform precision (or Uniformity).\n\n==Special geometries==\n\n===Cube===\nCubic designs are discussed by Kiefer, by Atkinson, Donev, and Tobias and by Hardin and Sloane.\n\n===Sphere===\n[[Spherical design]]s are discussed by Kiefer and by Hardin and Sloane.\n\n===Simplex geometry and mixture experiments===\nMixture experiments are discussed in many books on the [[design of experiments]], and in the response-surface methodology textbooks of Box and Draper and of Atkinson, Donev and Tobias. An extensive discussion and survey appears in the advanced textbook by John Cornell.\n\n==Extensions==\n\n<!-- ===Constraints=== -->\n\n===Multiple objective functions===\n{{see also|Multiobjective optimization|Pareto efficiency}}\nSome extensions of response surface methodology deal with the multiple response problem.  Multiple response variables create difficulty because what is optimal for one response may not be optimal for other responses.  Other extensions are used to reduce variability in a single response while targeting a specific value, or attaining a near maximum or minimum while preventing variability in that response from getting too large.\n\n==Practical concerns==\nResponse surface methodology uses statistical models, and therefore practitioners need to be aware that even the best statistical model is an approximation to reality. In practice, both the models and the parameter values are unknown, and subject to uncertainty on top of ignorance. Of course, an estimated optimum point need not be optimum in reality, because of the errors of the estimates and of the inadequacies of the model.\n\nNonetheless, response surface methodology has an effective track-record of helping researchers improve products and services: For example, Box's original response-surface modeling enabled chemical engineers to improve a process that had been stuck at a saddle-point for years. The engineers had not been able to afford to fit a cubic three-level design to estimate a quadratic model, and their [[Bias (statistics)|biased]] linear-models estimated the gradient to be zero. Box's design reduced the costs of experimentation so that a quadratic model could be fit, which led to a (long-sought) ascent direction.<ref>Box, G. E. P. and Wilson, K.B. (1951) On the Experimental Attainment of Optimum Conditions (with discussion).  ''[[Journal of the Royal Statistical Society]]'' Series B'''13'''(1):1&ndash;45.</ref><ref>''Improving Almost Anything: Ideas and Essays'', Revised Edition (Wiley Series in Probability and Statistics) George E. P. Box</ref>\n\n==See also==\n* [[Plackett–Burman design]]\n* [[Box–Behnken design]]\n* [[Central composite design]]\n* [[IOSO]] method based on response-surface methodology\n* [[Optimal design]]s\n* [[Polynomial regression]]\n* [[Polynomial and rational function modeling]]\n* [[Surrogate model]]\n* [[Probabilistic design]]\n* [[Gradient-Enhanced Kriging (GEK)]]\n\n==References==\n{{reflist}}\n\n* Box, G. E. P. and Wilson, K.B. (1951) On the Experimental Attainment of Optimum Conditions (with discussion).  ''[[Journal of the Royal Statistical Society]]'' Series B '''13'''(1):1&ndash;45.\n* Box, G. E. P. and Draper, Norman. 2007. ''Response Surfaces, Mixtures, and Ridge Analyses'', Second Edition [of ''Empirical Model-Building and Response Surfaces'', 1987], Wiley.\n* {{cite book |author=[http://stats.lse.ac.uk/atkinson/ Atkinson, A. C.] and [http://www.maths.manchester.ac.uk/~adonev/ Donev, A. N.] and [http://support.sas.com/publishing/bbu/companion_site/index_author.html#tobias Tobias, R. D.]|title=Optimum Experimental Designs, with '''SAS''' |url=https://books.google.com/books?id=oIHsrw6NBmoC|publisher=[http://www.us.oup.com/us/catalog/general/subject/Mathematics/ProbabilityStatistics/~~/dmlldz11c2EmY2k9OTc4MDE5OTI5NjYwNg== Oxford University Press]|year=2007 |pages=511+xvi |isbn=978-0-19-929660-6 |oclc= |doi=}}\n* {{cite book\n|author=Cornell, John\n|title=Experiments with Mixtures: Designs, Models, and the Analysis of Mixture Data\n|edition=third\n|publisher=Wiley\n|year=2002\n|isbn=978-0-471-07916-3\n}}\n\n* {{cite book |author=[http://www.ua.ac.be/main.aspx?c=peter.goos Goos, Peter]|title=The Optimal Design of Blocked and Split-plot Experiments |url=http://users.telenet.be/peter.goos/springer.htm|series=[https://www.springer.com/series/694 Lecture Notes in Statistics]| volume=164 | publisher=[https://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-95515-5 Springer] | year=2002}}\n* {{cite book |author=[[Jack Kiefer (mathematician)|Kiefer, Jack Carl]]. |title=Jack Carl Kiefer Collected Papers III Design of Experiments | editor=[[Lawrence D. Brown|L. D. Brown]]|publisher=Springer-Verlag|year=1985|isbn=978-0-387-96004-3|display-editors=etal|title-link=Jack Kiefer (mathematician) }}\n* {{cite book |author=[http://www.math.uni-augsburg.de/stochastik/pukelsheim/ Pukelsheim, Friedrich] |title=Optimal Design of Experiments  |url=https://books.google.com/books?id=5ZcfDZUJ4F8C |publisher=[http://www.ec-securehost.com/SIAM/CL50.html [[Society for Industrial and Applied Mathematics|SIAM]]]|year=2006 |isbn=978-0-89871-604-7}}\n* R. H. Hardin and [[Neil Sloane|N. J. A. Sloane]], [http://neilsloane.com/doc/design.pdf \"A New Approach to the Construction of Optimal Designs\", ''Journal of Statistical Planning and Inference'', vol. 37, 1993, pp. 339-369]\n* R. H. Hardin and [[Neil Sloane|N. J. A. Sloane]], [http://neilsloane.com/doc/doeh.pdf \"Computer-Generated Minimal (and Larger) Response Surface Designs: (I) The Sphere\"]\n* R. H. Hardin and [[Neil Sloane|N. J. A. Sloane]], [http://neilsloane.com/doc/meatball.pdf \"Computer-Generated Minimal (and Larger) Response Surface Designs: (II) The Cube\"]\n*  {{cite book| title=Design and Analysis of Experiments | series=Handbook of Statistics| volume=13|editor=Ghosh, S. |editor2=[[Calyampudi Radhakrishna Rao|Rao, C. R.]] | publisher=North-Holland| year=1996| isbn=978-0-444-82061-7}}\n**  {{cite book|author1=Draper, Norman  |author2=Lin, Dennis K. J. |lastauthoramp=yes | chapter=Response Surface Designs |pages=343–375}}\n**  {{cite book|chapter-url=http://www.sciencedirect.com/science/article/pii/S0169716196130327|title=Handbook of Statistics, Volume 13|volume=13|publisher=Design and Analysis of Experiments|year=1996|isbn=9780444820617|location=|pages=1149–1199| chapter=Approximate Designs for Polynomial Regression: Invariance, Admissibility, and Optimality |doi=10.1016/S0169-7161(96)13032-7 |author1=Gaffke, N |author2=Heiligers, B |lastauthoramp=yes |series=Handbook of Statistics}}\n\n===Historical===\n\n*{{cite journal\n|title=The application of the method of least squares to the interpolation of sequences\n|author=Gergonne, J. D.\n|journal=Historia Mathematica\n|volume=1\n|issue=4 <!-- |month=November -->\n|year=1974 |origyear=1815 \n|pages=439–447\n|edition=Translated by Ralph St. John and [[Stephen M. Stigler|S. M. Stigler]] from the 1815 French\n|doi=10.1016/0315-0860(74)90034-2\n|url=http://www.sciencedirect.com/science/article/B6WG9-4D7JMHH-20/2/df451ec5fbb7c044d0f4d900af80ec86\n|author-link=Joseph Diaz Gergonne\n}}\n*{{cite journal\n|title=Gergonne's 1815 paper on the design and analysis of polynomial regression experiments\n|author=Stigler, Stephen M.\n|journal=Historia Mathematica\n|volume=1\n|issue=4 <!-- |month=November -->\n|year=1974\n|pages=431–439\n|doi=10.1016/0315-0860(74)90033-0\n|url=http://www.sciencedirect.com/science/article/B6WG9-4D7JMHH-1Y/2/680c7ada0198761e9866197d53512ab4|author-link=Stephen M. Stigler\n}}\n\n* {{cite journal| author=Peirce, C. S | year=1876| title=Note on the Theory of the Economy of Research | journal=Coast Survey Report | pages=197–201| author-link=Charles Sanders Peirce}} (Appendix No. 14). [http://docs.lib.noaa.gov/rescue/cgs/001_pdf/CSC-0025.PDF#page=222 NOAA PDF Eprint]. Reprinted in {{cite book| year=1958 | title=Collected Papers of Charles Sanders Peirce | volume=7 | title-link=Charles Sanders Peirce bibliography#CP }} paragraphs 139–157, and in {{cite journal| last1=Peirce| first1=C. S.|date=July–August 1967| title=Note on the Theory of the Economy of Research\n| journal=Operations Research\n|volume=15 | issue=4|pages=643–648|doi=10.1287/opre.15.4.643}} [https://www.jstor.org/stable/168276 Abstract at JSTOR].\n\n* {{cite journal\n|author=[http://www.webdoe.cc/publications/kirstine.php Smith, Kirstine]\n|title=On the Standard Deviations of Adjusted and Interpolated Values of an Observed Polynomial Function and its Constants and the Guidance They Give Towards a Proper Choice of the Distribution of the Observations\n|year=1918\n|journal=Biometrika\n|volume=12 \n|issue=1/2\n|pages=1–85\n|jstor=2331929\n|doi=10.2307/2331929|url=https://zenodo.org/record/1431591\n}}\n\n==External links==\n* [http://www.itl.nist.gov/div898/handbook/pri/section3/pri336.htm Response surface designs]\n{{Experimental design|state=expanded}}\n<!-- {{Statistics}} -->\n{{Least Squares and Regression Analysis|state=collapsed}}\n\n[[Category:Sequential experiments]]\n[[Category:Design of experiments]]\n[[Category:Optimal decisions]]\n[[Category:Mathematical optimization]]\n[[Category:Industrial engineering]]\n[[Category:Systems engineering]]\n[[Category:Statistical process control]]"
    },
    {
      "title": "Robust optimization",
      "url": "https://en.wikipedia.org/wiki/Robust_optimization",
      "text": "'''Robust optimization''' is a field of [[optimization (mathematics)|optimization]] theory that deals with optimization problems in which a certain measure of robustness is sought against [[uncertainty]] that can be represented as deterministic variability in the value of the parameters of the problem itself and/or its solution.\n\n== History ==\nThe origins of robust optimization date back to the establishment of modern [[decision theory]] in the 1950s and the use of '''worst case analysis''' and [[Wald's maximin model]]  as a tool for the treatment of severe uncertainty.  It became a discipline of its own in the 1970s with parallel developments in several scientific and technological fields. Over the years, it has been applied in [[statistics]],  but also in [[operations research]],<ref>{{cite journal|last=Bertsimas|first=Dimitris|author2=Sim, Melvyn |title=The Price of Robustness|journal=Operations Research|year=2004|volume=52|issue=1|pages=35–53|doi=10.1287/opre.1030.0065}}</ref>[[electrical engineering]],<ref name=\"VPP Robust 2015\">{{Cite journal| title = The design of a risk-hedging tool for virtual power plants via robust optimization approach | journal= Applied Energy | date = October 2015 | doi = 10.1016/j.apenergy.2015.06.059 | author = Shabanzadeh M | volume = 155 | pages = 766–777 | last2 = Sheikh-El-Eslami | first2 = M-K |last3 = Haghifam | first3 = P|last4 = M-R}}</ref><ref name=\"RO2015\">{{Cite book| title = Generation Maintenance Scheduling via robust optimization | journal=  23rd Iranian Conference in Electrical Engineering (ICEE) | pages=  1504–1509 | date = July 2015 | doi = 10.1109/IranianCEE.2015.7146458 | author = Shabanzadeh M | last2 = Fattahi | first2 = M | isbn=  978-1-4799-1972-7 }}</ref> [[control theory]],<ref>{{cite journal|last=Khargonekar|first=P.P.|author2=Petersen, I.R. |author3=Zhou, K. |title=Robust stabilization of uncertain linear systems: quadratic stabilizability and H/sup infinity / control theory|journal=IEEE Transactions on Automatic Control|volume=35|issue=3|pages=356–361|doi=10.1109/9.50357|year=1990}}</ref> [[finance]],<ref>[https://books.google.com/books?id=p6UHHfkQ9Y8C&lpg=PR11&ots=AqlJfX5Z0X&dq=economics%20robust%20optimization&lr&hl=it&pg=PR11#v=onepage&q&f=false%20 Robust portfolio optimization]</ref> [[Investment management|portfolio management]]<ref>Md. Asadujjaman and Kais Zaman, \"Robust Portfolio Optimization under Data Uncertainty\" 15th National Statistical Conference, December 2014, Dhaka, Bangladesh.</ref> [[logistics]],<ref>{{cite journal|last=Yu|first=Chian-Son|author2=Li, Han-Lin |title=A robust optimization model for stochastic logistic problems|journal=International Journal of Production Economics|volume=64|issue=1–3|pages=385–397|doi=10.1016/S0925-5273(99)00074-2|year=2000}}</ref> [[manufacturing engineering]],<ref>{{cite journal|last=Strano|first=M|title=Optimization under uncertainty of sheet-metal-forming processes by the finite element method|journal=Proceedings of the Institution of Mechanical Engineers, Part B: Journal of Engineering Manufacture|volume=220|issue=8|pages=1305–1315|doi=10.1243/09544054JEM480|year=2006}}</ref> [[chemical engineering]],<ref>{{cite journal|last=Bernardo|first=Fernando P.|author2=Saraiva, Pedro M. |title=Robust optimization framework for process parameter and tolerance design|journal=AIChE Journal|year=1998|volume=44|issue=9|pages=2007–2017|doi=10.1002/aic.690440908}}</ref>  [[medicine]],<ref>{{cite journal|last=Chu|first=Millie|author2=Zinchenko, Yuriy |author3=Henderson, Shane G |author4= Sharpe, Michael B |title=Robust optimization for intensity modulated radiation therapy treatment planning under uncertainty|journal=Physics in Medicine and Biology|year=2005|volume=50|issue=23|pages=5463–5477|doi=10.1088/0031-9155/50/23/003}}</ref> and [[computer science]]. In [[engineering]] problems, these formulations often take the name of \"Robust Design Optimization\", RDO or \"Reliability Based Design Optimization\", RBDO.\n\n== Example 1==\n\nConsider the following [[linear programming]] problem\n\n:<math> \\max_{x,y} \\ \\{3x + 2y\\} \\ \\ \\mathrm { subject \\ to }\\ \\  x,y\\ge 0; cx + dy \\le 10, \\forall (c,d)\\in P </math>\nwhere <math>P</math> is a given subset of <math>\\mathbb{R}^{2}</math>.\n\nWhat makes this a 'robust optimization' problem is the <math>\\forall (c,d)\\in P</math> clause in the constraints. Its implication is that for a pair <math>(x,y)</math> to be admissible, the constraint <math>cx + dy \\le 10</math> must be satisfied by the '''worst'''  <math>(c,d)\\in P</math> pertaining to <math>(x,y)</math>, namely the pair <math>(c,d)\\in P</math> that maximizes the value of <math>cx + dy</math> for the given value of <math>(x,y)</math>.\n\nIf the parameter space <math>P</math> is finite (consisting of finitely many elements), then this robust optimization problem itself is a [[linear programming]] problem: for each <math>(c,d)\\in P</math> there is a linear constraint <math>cx + dy \\le 10</math>.\n\nIf <math>P</math> is not a finite set, then this problem is a linear [[semi-infinite programming]] problem, namely a linear programming problem with finitely many (2) decision variables and infinitely many constraints.\n\n== Classification ==\nThere are a number of classification criteria for robust optimization problems/models. In particular, one can distinguish between problems dealing with '''local''' and '''global''' models of robustness; and between '''probabilistic''' and '''non-probabilistic''' models of robustness. Modern robust optimization deals primarily with non-probabilistic models of robustness that are [[worst case]] oriented and as such usually deploy [[Wald's maximin model]]s.\n\n=== Local robustness ===\n\nThere are cases where robustness is sought against small perturbations in a nominal value of a parameter. A very popular model of local robustness is the [[stability radius|radius of stability]] model:\n\n: <math>\\hat{\\rho}(x,\\hat{u}):= \\max_{\\rho\\ge 0}\\ \\{\\rho: u\\in S(x), \\forall u\\in B(\\rho,\\hat{u})\\}</math>\n\nwhere <math>\\hat{u}</math> denotes the nominal value of the parameter, <math>B(\\rho,\\hat{u})</math> denotes a ball of radius <math>\\rho</math> centered at <math>\\hat{u}</math> and <math>S(x)</math> denotes the set of values of <math>u</math> that satisfy given stability/performance conditions associated with decision <math>x</math>.\n\nIn words, the robustness (radius of stability) of decision <math>x</math> is the radius of the largest ball centered at <math>\\hat{u}</math> all of whose elements satisfy the stability requirements imposed on <math>x</math>. The picture is this:\n\n[[Image:Local robustness.png|500px]]\n\nwhere the rectangle <math>U(x)</math> represents the set of all the values <math>u</math> associated with decision <math>x</math>.\n\n=== Global robustness ===\n\nConsider the simple abstract robust optimization problem\n\n: <math>\\max_{x\\in X}\\ \\{f(x): g(x,u)\\le b, \\forall u\\in U\\}</math>\n\nwhere <math>U</math> denotes the set of all ''possible'' values of <math>u</math> under consideration.\n\nThis is a ''global'' robust optimization problem in the sense that the robustness constraint <math>g(x,u)\\le b, \\forall u\\in U</math> represents all the ''possible'' values of <math>u</math>.\n\nThe difficulty is that such a \"global\" constraint can be too demanding in that there is no <math>x\\in X</math> that satisfies this constraint. But even if such an <math>x\\in X</math> exists, the constraint can be too \"conservative\" in that it yields a solution <math>x\\in X</math> that generates a very small payoff <math>f(x)</math> that is not representative of the performance of other decisions in <math>X</math>. For instance, there could be an <math>x'\\in X</math> that only slightly violates the robustness constraint but yields a very large payoff <math>f(x')</math>. In such cases it might be  necessary to relax a bit the robustness constraint and/or modify the statement of the problem.\n\n==== Example 2====\nConsider the case where the objective is to satisfy a constraint  <math>g(x,u)\\le b,</math>. where <math>x\\in X</math> denotes the decision variable and <math>u</math> is a parameter whose set of possible values in <math>U</math>. If there is no <math>x\\in X</math> such that <math>g(x,u)\\le b,\\forall u\\in U</math>, then the following intuitive measure of robustness suggests itself:\n\n: <math>\\rho(x):= \\max_{Y\\subseteq U} \\ \\{size(Y): g(x,u)\\le b, \\forall u\\in Y\\} \\ , \\ x\\in X</math>\n\nwhere <math>size(Y)</math> denotes an appropriate measure of the \"size\" of set <math>Y</math>. For example, if <math>U</math> is a finite set, then <math>size(Y)</math> could be defined as the [[cardinality]] of set <math>Y</math>.\n\nIn words, the robustness of decision is the size of the largest subset of <math>U</math> for which the constraint <math>g(x,u)\\le b</math> is satisfied for each <math>u</math> in this set. An optimal decision is then a decision whose robustness is the largest.\n\nThis yields the following robust optimization problem:\n\n: <math>\\max_{x\\in X, Y\\subseteq U} \\ \\{size(Y): g(x,u) \\le b, \\forall u\\in Y\\}</math>\n\nThis intuitive notion of global robustness is not used often in practice because the robust optimization problems that it induces are usually (not always) very difficult to solve.\n\n====Example 3====\nConsider the robust optimization problem\n:<math>z(U):= \\max_{x\\in X}\\ \\{f(x): g(x,u)\\le b, \\forall u\\in U\\}</math>\nwhere <math>g</math> is a real-valued function on <math>X\\times U</math>, and assume that there is no feasible solution to this problem because the robustness constraint <math>g(x,u)\\le b, \\forall u\\in U</math> is too demanding.\n\nTo overcome this difficulty, let <math>\\mathcal{N}</math> be a relatively small subset of <math>U</math> representing \"normal\" values of <math>u</math> and consider the following robust optimization problem: \n:<math>z(\\mathcal{N}):= \\max_{x\\in X}\\ \\{f(x): g(x,u)\\le b, \\forall u\\in \\mathcal{N}\\}</math>\n\nSince <math>\\mathcal{N}</math> is much smaller than <math>U</math>, its optimal solution may not perform well on a large portion of <math>U</math> and therefore may not be robust against the variability of <math>u</math> over <math>U</math>.\n\nOne way to fix this difficulty  is to relax the constraint <math>g(x,u)\\le b</math> for values of <math>u</math> outside the set <math>\\mathcal{N}</math> in a controlled manner so that larger violations are allowed as the distance of  <math>u</math> from <math>\\mathcal{N}</math> increases. For instance, consider the relaxed robustness constraint\n: <math>g(x,u) \\le b + \\beta \\cdot dist(u,\\mathcal{N}) \\ , \\ \\forall u\\in U</math>\n\nwhere <math>\\beta \\ge 0</math> is a control parameter and <math>dist(u,\\mathcal{N})</math> denotes the distance of <math>u</math> from <math>\\mathcal{N}</math>. Thus, for <math>\\beta =0</math> the relaxed robustness constraint reduces back to the original robustness constraint.\nThis yields the following (relaxed) robust optimization problem:\n\n:<math>z(\\mathcal{N},U):= \\max_{x\\in X}\\ \\{f(x): g(x,u)\\le b + \\beta \\cdot dist(u,\\mathcal{N}) \\ , \\  \\forall u\\in U\\}</math>\n\nThe function <math>dist</math> is defined in such a manner that  \n:<math>dist(u,\\mathcal{N})\\ge 0,\\forall u\\in U</math>\n\nand \n \n: <math>dist(u,\\mathcal{N})= 0,\\forall u\\in \\mathcal{N}</math>\n\nand therefore the optimal solution to the relaxed problem satisfies the original constraint <math>g(x,u)\\le b</math> for all values of <math>u</math> in <math>\\mathcal{N}</math>. It also satisfies the relaxed constraint\n: <math>g(x,u)\\le b + \\beta \\cdot dist(u,\\mathcal{N})</math>\n\noutside <math>\\mathcal{N}</math>.\n\n===Non-probabilistic robust optimization models===\n\nThe dominating paradigm in this area of robust optimization is [[Wald's maximin model]], namely\n\n: <math>\\max_{x\\in X}\\min_{u\\in U(x)} f(x,u)</math>\n\nwhere the <math>\\max</math> represents the decision maker,  the <math>\\min</math> represents Nature, namely [[uncertainty]], <math>X</math> represents the decision space and <math>U(x)</math> denotes the set of possible values of <math>u</math> associated with decision <math>x</math>.  This is the ''classic'' format of the generic model, and is often referred to as ''minimax'' or ''maximin'' optimization problem. The non-probabilistic ('''deterministic''') model has been and is being extensively used for robust optimization especially in the field of signal processing.<ref>{{cite journal | last1 = Verdu | first1 = S. | last2 = Poor | first2 = H. V. | year = 1984 | title = On Minimax Robustness: A general approach and applications | url = | journal = IEEE Transactions on Information Theory | volume = 30 | issue = 2| pages = 328–340 | doi=10.1109/tit.1984.1056876| citeseerx = 10.1.1.132.837 }}</ref><ref>{{cite journal | last1 = Kassam | first1 = S. A. | last2 = Poor | first2 = H. V. | year = 1985 | title = Robust Techniques for Signal Processing: A Survey | url = | journal = Proceedings of the IEEE | volume = 73 | issue = 3| pages = 433–481 | doi=10.1109/proc.1985.13167}}</ref><ref>M. Danish Nisar. [http://www.shaker.eu/shop/978-3-8440-0332-1 \"Minimax Robustness in Signal Processing for Communications\"], Shaker Verlag, {{ISBN|978-3-8440-0332-1}}, August 2011.</ref>\n\nThe equivalent [[mathematical programming]] (MP) of the classic format above is\n\n:<math>\\max_{x\\in X,v\\in \\mathbb{R}} \\ \\{v: v\\le f(x,u), \\forall u\\in U(x)\\}</math>\n\nConstraints can be incorporated explicitly in these models. The generic constrained classic format is\n\n: <math>\\max_{x\\in X}\\min_{u\\in U(x)} \\ \\{f(x,u): g(x,u)\\le b,\\forall u\\in U(x)\\}</math>\n\nThe equivalent constrained MP format is defined as:\n\n:<math>\\max_{x\\in X,v\\in \\mathbb{R}} \\ \\{v: v\\le f(x,u), g(x,u)\\le b, \\forall u\\in U(x)\\}</math>\n\n===Probabilistically robust optimization models===\nThese models quantify the uncertainty in the \"true\" value of the parameter of interest by probability distribution functions. They have been traditionally classified as [[stochastic programming]] and [[stochastic optimization]] models. Recently, probabilistically robust optimization has gained popularity by the introduction of rigorous theories such as [[scenario optimization]] able to quantify the robustness level of solutions obtained by randomization. These methods are also relevant to data-driven optimization methods. \n\n===Robust counterpart===\nThe solution method to many robust program involves creating a deterministic equivalent, called the robust counterpart. The practical difficulty of a robust program depends on if its robust counterpart is  computationally tractable.<ref>Ben-Tal A., El Ghaoui, L. and  Nemirovski, A. (2009). Robust Optimization. ''Princeton Series in Applied Mathematics,'' Princeton University Press, 9-16.</ref>\n\n== See also ==\n* [[Stability radius]]\n* [[Minimax]]\n* [[Minimax estimator]]\n* [[Minimax regret]]\n* [[Robust statistics]]\n* [[Robust decision making]]\n* [[Stochastic programming]]\n* [[Stochastic optimization]]\n* [[Info-gap decision theory]]\n* [[Taguchi methods]]\n\n== References ==\n\n{{Reflist}}\n\n== Further reading ==\n*H.J. Greenberg. Mathematical Programming Glossary. World Wide Web, http://glossary.computing.society.informs.org/, 1996-2006. Edited by the INFORMS Computing Society.\n*{{cite journal | last1 = Ben-Tal | first1 = A. | last2 = Nemirovski | first2 = A. | year = 1998 | title = Robust Convex Optimization | url = | journal = Mathematics of Operations Research | volume = 23 | issue = 4| pages = 769–805 | doi=10.1287/moor.23.4.769| citeseerx = 10.1.1.135.798 }}\n*{{cite journal | last1 = Ben-Tal | first1 = A. | last2 = Nemirovski | first2 = A. | year = 1999 | title = Robust solutions to uncertain linear programs | url = | journal = Operations Research Letters | volume = 25 | issue = | pages = 1–13 | doi=10.1016/s0167-6377(99)00016-4| citeseerx = 10.1.1.424.861 }}\n*{{cite journal | last1 = Ben-Tal | first1 = A. | last2 = Arkadi Nemirovski | first2 = A. | year = 2002 | title = Robust optimization—methodology and applications | url = | journal = Mathematical Programming, Series B | volume = 92 | issue = 3| pages = 453–480 | doi=10.1007/s101070100286| citeseerx = 10.1.1.298.7965 }}\n*Ben-Tal A., El Ghaoui, L. and  Nemirovski, A. (2006).  ''Mathematical Programming, Special issue on Robust Optimization,'' Volume 107(1-2).\n*Ben-Tal A., El Ghaoui, L. and  Nemirovski, A. (2009). Robust Optimization. ''Princeton Series in Applied Mathematics,'' Princeton University Press.\n*{{cite journal | last1 = Bertsimas | first1 = D. | last2 = Sim | first2 = M. | year = 2003 | title = Robust Discrete Optimization and Network Flows | url = | journal = Mathematical Programming | volume = 98 | issue = 1–3| pages = 49–71 | doi=10.1007/s10107-003-0396-4| citeseerx = 10.1.1.392.4470 }}\n*{{cite journal | last1 = Bertsimas | first1 = D. | last2 = Sim | first2 = M. | year = 2006 | title = Tractable Approximations to Robust Conic Optimization Problems Dimitris Bertsimas | url = | journal = Mathematical Programming | volume = 107 | issue = 1| pages = 5–36 | doi=10.1007/s10107-005-0677-1| citeseerx = 10.1.1.207.8378 }}\n*{{cite journal | last1 = Chen | first1 = W. | last2 = Sim | first2 = M. | year = 2009 | title = Goal Driven Optimization | url = | journal = Operations Research | volume = 57 | issue = 2| pages = 342–357 | doi=10.1287/opre.1080.0570}}\n*{{cite journal | last1 = Chen | first1 = X. | last2 = Sim | first2 = M. | last3 = Sun | first3 = P. | last4 = Zhang | first4 = J. | year = 2008 | title = A Linear-Decision Based Approximation Approach to Stochastic Programming | url = | journal = Operations Research | volume = 56 | issue = 2| pages = 344–357 | doi=10.1287/opre.1070.0457}}\n*{{cite journal | last1 = Chen | first1 = X. | last2 = Sim | first2 = M. | last3 = Sun | first3 = P. | year = 2007 | title = A Robust Optimization Perspective on Stochastic Programming | url = | journal = Operations Research | volume = 55 | issue = 6| pages = 1058–1071 | doi=10.1287/opre.1070.0441}}\n*{{cite journal | last1 = Dembo | first1 = R | year = 1991 | title = Scenario optimization | url = | journal = Annals of Operations Research | volume = 30 | issue = 1| pages = 63–80 | doi=10.1007/bf02204809}}\n*{{cite journal | last1 = Gupta | first1 = S.K. | last2 = Rosenhead | first2 = J. | year = 1968 | title = Robustness in sequential investment decisions | doi = 10.1287/mnsc.15.2.B18 | journal = Management Science | volume = 15 | issue = 2| pages = 18–29 }}\n*Kouvelis P. and  Yu G. (1997). ''Robust Discrete Optimization and Its Applications,'' Kluwer.\n*{{cite journal | last1 = Mutapcic | first1 = Almir | last2 = Boyd | first2 = Stephen | year = 2009 | title = Cutting-set methods for robust convex optimization with pessimizing oracles | url = | journal = Optimization Methods and Software | volume = 24 | issue = 3| pages = 381–406 | doi=10.1080/10556780802712889| citeseerx = 10.1.1.416.4912 }}\n*{{cite journal | last1 = Mulvey | first1 = J.M. | last2 = Vanderbei | first2 = R.J. | last3 = Zenios | first3 = S.A. | year = 1995 | title = Robust Optimization of Large-Scale Systems | url = | journal = Operations Research | volume = 43 | issue = 2| pages = 264–281 | doi=10.1287/opre.43.2.264}}\n*{{cite journal | last1 = Rosenblat | first1 = M.J. | year = 1987 | title = A robust approach to facility design | url = | journal = International Journal of Production Research | volume = 25 | issue = 4| pages = 479–486 | doi = 10.1080/00207548708919855 }}\n*{{cite journal | last1 = Rosenhead | first1 = M.J | last2 = Elton | first2 = M | last3 = Gupta | first3 = S.K. | year = 1972 | title = Robustness and Optimality as Criteria for Strategic Decisions | url = | journal = Operational Research Quarterly | volume = 23 | issue = 4| pages = 413–430 | doi=10.2307/3007957| jstor = 3007957 }}\n*Rustem B. and Howe M. (2002). ''Algorithms for Worst-case Design and Applications to Risk Management,'' Princeton University Press.\n*{{cite journal | last1 = Sniedovich | first1 = M | year = 2007 | title = The art and science of modeling decision-making under severe uncertainty | url = | journal = Decision Making in Manufacturing and Services | volume = 1 | issue = 1–2| pages = 111–136 | doi = 10.7494/dmms.2007.1.2.111 }}\n*{{cite journal | last1 = Sniedovich | first1 = M | year = 2008 | title = Wald's Maximin Model: a Treasure in Disguise! | url = | journal = Journal of Risk Finance | volume = 9 | issue = 3| pages = 287–291 | doi=10.1108/15265940810875603}}\n*{{cite journal | last1 = Sniedovich | first1 = M | year = 2010 | title = A bird's view of info-gap decision theory | url = | journal = Journal of Risk Finance | volume = 11 | issue = 3| pages = 268–283 | doi=10.1108/15265941011043648}}\n*{{cite journal | last1 = Wald | first1 = A | year = 1939 | title = Contributions to the theory of statistical estimation and testing hypotheses | url = | journal = The Annals of Mathematics | volume = 10 | issue = 4| pages = 299–326 | doi=10.1214/aoms/1177732144}}\n*{{cite journal | last1 = Wald | first1 = A | year = 1945 | title = Statistical decision functions which minimize the maximum risk | url = | journal = The Annals of Mathematics | volume = 46 | issue = 2| pages = 265–280 | doi=10.2307/1969022| jstor = 1969022 }}\n*Wald, A.  (1950). ''Statistical Decision Functions,'' John Wiley, NY.\n*M. Shabanzadeh, M. Fattahi. Generation Maintenance Scheduling via robust optimization. DOI: 10.1109/IranianCEE.2015.7146458, 2015\n\n==External links==\n* [http://www.robustopt.com ROME: Robust Optimization Made Easy]\n* [http://robust.moshe-online.com: Robust Decision-Making Under Severe Uncertainty]\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Rosenbrock function",
      "url": "https://en.wikipedia.org/wiki/Rosenbrock_function",
      "text": "[[Image:Rosenbrock function.svg|thumb|right|300 px|Plot of the Rosenbrock function of two variables. Here <math>a=1, b=100</math>, and the minimum value of zero is at <math>(1,1)</math>.]]\nIn [[mathematical optimization]], the '''Rosenbrock function''' is a non-[[convex function]], introduced by [[Howard Harry Rosenbrock|Howard H. Rosenbrock]] in 1960, which is used as a [[Test functions for optimization|performance test problem]] for optimization [[algorithm]]s.<ref>{{cite journal|last=Rosenbrock|first=H.H.|title=An automatic method for finding the greatest or least value of a function|journal=The Computer Journal|year=1960|volume=3|issue=3|pages=175–184|doi=10.1093/comjnl/3.3.175| issn=0010-4620 }}</ref> It is also known as '''Rosenbrock's valley''' or '''Rosenbrock's banana function'''.\n\nThe global minimum is inside a long, narrow, [[parabola|parabolic]] shaped flat valley. To find the valley is trivial. To converge to the global [[minimum]], however, is difficult.\n\nThe function is defined by\n\n<math>f(x, y) = (a-x)^2 + b(y-x^2)^2</math>\n\nIt has a global minimum at <math>(x, y)=(a, a^2)</math>, where <math>f(x, y)=0</math>. Usually these parameters are set such that <math>a = 1</math> and <math>b = 100</math>. Only in the trivial case where <math>a=0</math> is the function symmetric and the minimum at the origin.\n\n==Multidimensional generalisations==\n\nTwo variants are commonly encountered.  \n\n[[File:Rosenbrock3.gif|thumb|300px|Animation of Rosenbrock's function of three variables. <ref>{{cite book|last=Simionescu|first=P.A.|title=Computer Aided Graphing and Simulation Tools for AutoCAD users|year=2014|publisher=CRC Press|location=Boca Raton, FL|isbn=978-1-4822-5290-3|edition=1st}}</ref>]]\n\nOne is the sum of <math>N/2</math> uncoupled 2D Rosenbrock problems, and is defined only for even <math>N</math>s:\n: <math>f(\\mathbf{x}) = f(x_1, x_2, \\dots, x_N) = \\sum_{i=1}^{N/2} \\left[100(x_{2i-1}^2 - x_{2i})^2\n+ (x_{2i-1} - 1)^2 \\right].</math><ref>{{cite journal |first=L. C. W. |last=Dixon |first2=D. J. |last2=Mills |title=Effect of Rounding Errors on the Variable Metric Method |journal=Journal of Optimization Theory and Applications |volume=80 |issue= |pages=175–179 |year=1994 |url=http://portal.acm.org/citation.cfm?id=179711 |doi=10.1007/BF02196600 }}</ref>\n\nThis variant has predictably simple solutions.\n\nA second, more involved variant is\n: <math>f(\\mathbf{x}) = \\sum_{i=1}^{N-1} [100 (x_{i+1} - x_i^2 )^2 + (1-x_i)^2] \\quad \\mbox{where} \\quad \\mathbf{x} = [x_1, \\ldots, x_N] \\in \\mathbb{R}^N.</math><ref>{{cite web |url = http://docs.scipy.org/doc/scipy-0.14.0/reference/tutorial/optimize.html#unconstrained-minimization-of-multivariate-scalar-functions-minimize|title = Generalized Rosenbrock's function|accessdate = 2008-09-16|website = |publisher = |date = }}</ref>\n\nhas exactly one minimum for <math>N=3</math> (at <math>(1, 1, 1)</math>) and exactly two minima for <math>4 \\le N \\le 7</math>—the global minimum of all ones and a local minimum near <math>(x_1, x_2, \\dots, x_N) = (-1, 1, \\dots, 1)</math>.  This result is obtained by setting the gradient of the function equal to zero, noticing that the resulting equation is a rational function of <math>x</math>.  For small <math>N</math> the polynomials can be determined exactly and [[Sturm's theorem]] can be used to determine the number of real roots, while the roots can be [[Fundamental theorem of algebra#Bounds on the zeroes of a polynomial|bounded]] in the region of <math>|x_i| < 2.4</math>.<ref name=\"kok2009\">{{cite journal |first=Schalk |last=Kok |first2=Carl |last2=Sandrock |title=Locating and Characterizing the Stationary Points of the Extended Rosenbrock Function |journal=Evolutionary Computation |volume=17 |issue= 3|pages=437–53 |year=2009 |doi=10.1162/evco.2009.17.3.437 |pmid=19708775 }}</ref>  For larger <math>N</math> this method breaks down due to the size of the coefficients involved.\n\n==Stationary points==\n\nMany of the stationary points of the function exhibit a regular pattern when plotted.<ref name=\"kok2009\"/>  This structure can be exploited to locate them.\n[[Image:Rosenbrock roots exhibiting hump structures.pdf|thumb|right|300 px|Rosenbrock roots exhibiting hump structures]]\n\n==Optimization examples==\n[[File:Rosenbrock.png|thumb|left|200px]]\n\n[[File:Nelder-Mead Rosenbrock.gif|thumb|200px|text-top|left|alt=Rosenbrock function Nelder-Mead|Nelder-Mead method applied to the Rosenbrock function]]\n\nThe Rosenbrock function can be efficiently optimized by adapting appropriate coordinate system without using any [[gradient descent|gradient information]] and without building local approximation models (in contrast to many derivate-free optimizers). The following figure illustrates an example of 2-dimensional Rosenbrock function optimization by\n[[adaptive coordinate descent]] from starting point <math>x_0=(-3,-4)</math>. The solution with the function value <math>10^{-10}</math> can be found after 325 function evaluations.\n\nUsing the [[Nelder–Mead method]] from starting point <math>x_0=(-1,1)</math> with a regular initial simplex a minimum is found with function value <math>1.36 \\cdot 10^{-10}</math> after 185 function evaluations. The figure below visualizes the evolution of the algorithm.\n\n{{clear}}\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://www.gnuplot.info/screenshots/figs/pm3d-Rosenbrock.png Rosenbrock function plot in 3D]\n* {{MathWorld |title=Rosenbrock Function |urlname=RosenbrockFunction}}\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "S-procedure",
      "url": "https://en.wikipedia.org/wiki/S-procedure",
      "text": "{{Orphan|date=December 2015}}\n\nThe '''S-procedure''' or '''S-lemma''' is a [[mathematics|mathematical]] result that gives conditions under which a particular quadratic inequality is a consequence of another quadratic inequality. The S-procedure was developed independently in a number of different contexts<ref>Frank Uhlig, ''[https://dx.doi.org/10.1016/0024-3795(79)90020-X A recurring theorem about pairs of quadratic forms and extensions: a survey]'', Linear Algebra and its Applications, Volume 25, 1979, pages 219–237.</ref><ref>Imre Pólik and Tamás Terlaky, ''[https://dx.doi.org/10.1137/S003614450444614X A Survey of the S-Lemma]'', SIAM Review, Volume 49, 2007, Pages 371–418.</ref> and has applications in [[control theory]], [[linear algebra]] and [[mathematical optimization]].\n\n== Statement of the S-procedure == \nLet F<sub>1</sub> and F<sub>2</sub> be symmetric matrices, g<sub>1</sub> and g<sub>2</sub> be vectors and h<sub>1</sub> and h<sub>2</sub> be real numbers. Assume that there is some x<sub>0</sub> such that the strict inequality <math>x_0^T F_1 x_0 + 2g_1^T x_0 + h_1 < 0</math> holds. Then the implication \n::<math>x^T F_1 x + 2g_1^T x + h_1 \\le 0 \\Longrightarrow x^T F_2 x + 2g_2^T x + h_2 \\le 0</math>\nholds if and only if there exists some nonnegative number λ such that \n::<math> \\lambda \\begin{bmatrix} F_1 & g_1 \\\\ g_1^T & h_1 \\end{bmatrix} - \\begin{bmatrix} F_2 & g_2 \\\\ g_2^T & h_2 \\end{bmatrix}</math> \nis [[positive semidefinite matrix|positive semidefinite]].<ref>Stephen Boyd and Lieven Vandenberghe ''[http://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf Convex Optimization]'', Cambridge University Press, 2004, p.655.</ref>\n\n== References ==\n<!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using<ref></ref> tags, these references will then appear here automatically -->\n{{Reflist}}\n\n<!--- Categories --->\n[[Category:Control theory]]\n[[Category:Linear algebra]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Semi-continuity",
      "url": "https://en.wikipedia.org/wiki/Semi-continuity",
      "text": "{{For|the notion of upper or lower semicontinuous [[multivalued function]]|Hemicontinuity}}\n\nIn [[mathematical analysis]], '''semi-continuity''' (or '''semicontinuity''') is a property of [[extended real number|extended real]]-valued [[function (mathematics)|function]]s that is weaker than [[continuous function|continuity]]. An extended real-valued function ''f'' is '''upper''' (respectively, '''lower''') '''semi-continuous''' at a point ''x''<sub>0</sub> if, roughly speaking, the function values for arguments near ''x''<sub>0</sub> are either close to ''f''(''x''<sub>0</sub>) or less than (respectively, greater than) ''f''(''x''<sub>0</sub>).\n\n== Examples ==\n[[Image:Upper semi.svg|thumb|right|An upper semi-continuous function. The solid blue dot indicates ''f''(''x''<sub>0</sub>).]]\nConsider the  function ''f'', [[piecewise]] defined by ''f''(''x'')&nbsp;= –1 for ''x''&nbsp;<&nbsp;0 and ''f''(''x'')&nbsp;=&nbsp;1 for ''x''&nbsp;≥&nbsp;0. This function is upper semi-continuous at ''x''<sub>0</sub>&nbsp;=&nbsp;0, but not lower semi-continuous.\n\n[[Image:Lower semi.svg|thumb|right|A lower semi-continuous function. The solid blue dot indicates ''f''(''x''<sub>0</sub>).]]\nThe [[indicator function]] of a [[closed set]] is upper semi-continuous, whereas the indicator function of an [[open set]] is lower semi-continuous. The [[floor function]] <math>f(x)=\\lfloor x \\rfloor</math>, which returns the greatest integer less than or equal to a given real number ''x'', is everywhere upper semi-continuous. Similarly, the [[ceiling function]] <math>f(x)=\\lceil x \\rceil</math> is lower semi-continuous.\n\nA function may be upper or lower semi-continuous without being either [[Continuous function#Directional and semi-continuity|left or right continuous]]. For example, the function\n:<math>f(x) = \\begin{cases}\n               1   & \\mbox{if } x < 1,\\\\\n               2   & \\mbox{if } x = 1,\\\\\n               1/2 & \\mbox{if } x > 1,\n               \\end{cases} </math>\nis upper semi-continuous at ''x'' = 1 although not left or right continuous.  The limit from the left is equal to 1 and the limit from the right is equal to 1/2, both of which are different from the function value of 2.  Similarly the function\n:<math> f(x) = \\begin{cases}\n                \\sin(1/x) & \\mbox{if } x \\neq 0,\\\\\n                1         & \\mbox{if } x = 0,\n                \\end{cases}</math>\nis upper semi-continuous at ''x'' = 0 while the function limits from the left or right at zero do not even exist.\n\nIf <math>X=\\mathbb R^n</math> is a Euclidean space (or more generally, a metric space) and <math>\\Gamma=C([0,1],X)</math> is the space of [[curve]]s in <math>X</math> (with the [[supremum norm|supremum distance]] <math>d_\\Gamma(\\alpha,\\beta)=\\sup_t\\ d_X(\\alpha(t),\\beta(t))</math>, then the length functional <math>L:\\Gamma\\to[0,+\\infty]</math>, which assigns to each curve <math>\\alpha</math> its [[Curve#Length of curves|length]] <math>L(\\alpha)</math>, is lower semicontinuous.\n\nLet <math>(X,\\mu)</math> be a measure space and let <math>L^+(X,\\mu)</math> denote the set of positive measurable functions endowed with the\ntopology of [[convergence in measure]] with respect to <math>\\mu</math>.  Then by [[Fatou's lemma]] the integral, seen as an operator from <math>L^+(X,\\mu)</math> to <math>[-\\infty,+\\infty]</math> is lower semi-continuous.\n\n== Formal definition ==\n\nSuppose <math>X</math> is a [[topological space]], <math>x_0</math> is a point in <math>X</math> and <math>f\\colon X \\to \\mathbb{R} \\cup \\{ -\\infty, \\infty \\}</math> is an extended real-valued function.\n\nWe say that <math>f</math> is '''upper semi-continuous''' at <math>x_0</math> if for every <math>\\epsilon > 0</math> there exists a [[neighborhood (topology)|neighborhood]] <math>U</math> of <math>x_0</math> such that <math>f(x) \\leq f(x_0) + \\epsilon</math> for all <math>x \\in U</math> when <math>f(x_0) > -\\infty</math>, and <math>f(x)</math> tends to <math>-\\infty</math> as <math>x</math> tends towards <math>x_0</math> when <math>f(x_0) = -\\infty</math>.\n\nFor the particular case of a metric space, this can be expressed as\n\n:<math>\\limsup_{x\\to x_{0}} f(x)\\le f(x_0)</math>\n\nwhere lim sup is the [[limit superior]] (of the function <math>f</math> at point <math>x_0</math>). (For non-metric spaces, an equivalent definition using [[net (mathematics)|net]]s may be stated.)\n\nThe function <math>f</math> is called upper semi-continuous if it is upper semi-continuous at every point of its [[domain (function)|domain]]. A function is upper semi-continuous if and only if <math>\\{x \\in X: ~f(x) < \\alpha\\}</math> is an [[open set]] for every <math>\\alpha \\in \\mathbb{R}</math>.\n\nWe say that <math>f</math> is '''lower semi-continuous''' at <math>x_0</math> if for every <math>\\epsilon > 0</math> there exists a [[neighborhood (topology)|neighborhood]] <math>U</math> of <math>x_0</math> such that <math>f(x) \\geq f(x_0) - \\epsilon</math> for all <math>x</math> in <math>U</math> when <math>f(x_0) < +\\infty</math>, and <math>f(x)</math> tends to <math>+\\infty</math> as <math>x</math> tends towards <math>x_0</math> when <math>f(x_0) = +\\infty</math>. Equivalently, in the case of a metric space, this can be expressed as\n\n:<math>\\liminf_{x\\to x_0} f(x)\\ge f(x_0)</math>\n\nwhere <math>\\liminf</math> is the [[limit inferior]] (of the function <math>f</math> at point <math>x_0</math>).\n\nThe function ''f'' is called lower semi-continuous if it is lower semi-continuous at every point of its domain. A function is lower semi-continuous if and only if <math>\\{x\\in X : ~f(x)>\\alpha\\}</math> is an [[open set]] for every α&nbsp;∈&nbsp;'''R'''; alternatively, a function is lower semi-continuous if and only if all of its lower [[level set]]s <math>\\{x\\in X: ~f(x)\\leq\\alpha\\}</math> are [[closed set|closed]]<!-- a formulation useful in [[optimization theory|minimization theory]], for [[Weierstrauss's theorem]] on the existence of a minimum for an inf-compact function, or for the definition of a quasi-convex function by the convexity of lower level sets, etc. -->. Lower level sets are also called ''[[level set|sublevel sets]]'' or ''trenches''.<ref>{{Cite news|last=Kiwiel|first=Krzysztof C.|title=Convergence and efficiency of subgradient methods for quasiconvex minimization|journal=Mathematical Programming, Series A|publisher=Springer|location=Berlin, Heidelberg|issn=0025-5610|pages=1–25|volume=90|issue=1|doi=10.1007/PL00011414|year=2001|mr=1819784}}</ref>\n\n== Properties ==\n\nA function is [[continuous function|continuous]] at ''x''<sub>0</sub> if and only if it is upper and lower semi-continuous there. Therefore, semi-continuity can be used to prove continuity.\n\nIf ''f'' and ''g'' are two real-valued functions which are both upper semi-continuous at ''x''<sub>0</sub>, then so is ''f'' + ''g''. If both functions are non-negative, then the product function ''fg'' will also be upper semi-continuous at ''x''<sub>0</sub>. The same holds for functions lower semi-continuous at ''x''<sub>0</sub>.<ref>{{cite book|last1=Puterman|first1=Martin L.|title=Markov Decision Processes Discrete Stochastic Dynamic Programming|date=2005|publisher=Wiley-Interscience|isbn=978-0-471-72782-8|pages=602}}</ref>\n\nThe [[Function composition|composition]] ''f''∘''g'' of upper semi-continuous functions ''f'' and ''g'' is not necessarily upper semi-continuous, but if ''f'' is also non-decreasing, then ''f''∘''g'' is upper semi-continuous.<ref>{{cite book|last1=Moore|first1=James C.|title=Mathematical methods for economic theory|date=1999|publisher=Springer|location=Berlin|isbn=9783540662358|page=143}}</ref>\n\nMultiplying a positive upper semi-continuous function with a negative number turns it into a lower semi-continuous function.\n\nIf ''C'' is a [[compact space]] (for instance a [[closed set|closed]], [[bounded set|bounded]] [[interval (mathematics)|interval]] [''a'',&nbsp;''b'']) and ''f'' : ''C''&nbsp;→&nbsp;[–∞,∞) is upper semi-continuous, then ''f'' has a maximum on ''C''. The analogous statement for (–∞,∞]-valued lower semi-continuous functions and minima is also true. (See the article on the [[extreme value theorem]] for a proof.)\n\nSuppose ''f''<sub>''i''</sub> : ''X''&nbsp;→&nbsp;[–∞,∞] is a lower semi-continuous function for every index ''i'' in a nonempty set ''I'', and define ''f'' as pointwise [[supremum]], i.e.,\n\n:<math>f(x)=\\sup_{i\\in I}f_i(x),\\qquad x\\in X.</math>\n\nThen ''f'' is lower semi-continuous<ref>{{Cite web|url=https://www.encyclopediaofmath.org/index.php/Baire_theorem#Baire.27s_theorem_on_semi-continuous_functions|title=Baire theorem|last=|first=|date=|website=Encyclopedia of Mathematics|archive-url=|archive-date=|dead-url=|access-date=}}</ref>. Even if all the ''f''<sub>''i''</sub> are continuous, ''f'' need not be continuous: indeed every lower semi-continuous function on a [[uniform space]] (e.g. a [[metric space]]) arises as the supremum of a sequence of continuous functions.\n\nLikewise, the pointwise [[infimum]] of an arbitrary collection of upper semicontinuous functions is upper semicontinuous.\n\nThe [[indicator function]] of any open set is lower semicontinuous. The indicator function of a closed set is upper semicontinuous. However, in convex analysis, the term \"indicator function\" often refers to the [[Characteristic function (convex analysis)|characteristic function]], and the characteristic function of any ''closed'' set is lower semicontinuous, and the characteristic function of any ''open'' set is upper semicontinuous.\n\nA function ''f''&nbsp;:&nbsp;'''R'''<sup>n</sup>→'''R''' is lower semicontinuous if and only if its [[epigraph (mathematics)|epigraph]] (the set of points lying on or above its [[graph of a function|graph]]) is [[Closed set|closed]].\n\nA function ''f''&nbsp;:&nbsp;''X''→'''R''', for some topological space ''X'', is lower semicontinuous if and only if it is continuous with respect to the [[Scott topology]] on '''R'''.\n\nAny upper semicontinuous function ''f''&nbsp;:&nbsp;''X''→'''N''' on an arbitrary topological space ''X'' is locally constant on some [[dense set|dense open subset]] of ''X''.\n\nThe maximum and minimum of finitely many upper semicontinuous functions is upper semicontinuous, and the same holds true of lower semicontinuous functions.\n\n\n== See also ==\n* [[left-continuous|Directional continuity]]\n* [[Hemicontinuity|Semicontinuous multivalued function]]\n\n== References ==\n{{Reflist}}\n\n== Further reading ==\n* {{cite journal | last1 = Benesova | first1 = B. | last2 = Kruzik | first2 = M. | year = 2017 | title =  Weak Lower Semicontinuity of Integral Functionals and Applications| doi = 10.1137/16M1060947 | journal = SIAM Review | volume = 59 | issue = 4| pages = 703–766 | arxiv = 1601.00390 }}\n*{{cite book\n | last       = Bourbaki\n | first      = Nicolas\n | title      = Elements of Mathematics: General Topology, 1–4\n | publisher  = Springer\n | year       = 1998\n | pages      = \n | isbn       = 0-201-00636-7\n}}\n*{{cite book\n | last       = Bourbaki\n | first      = Nicolas\n | title      = Elements of Mathematics: General Topology, 5–10\n | publisher  = Springer\n | year       = 1998\n | pages      = \n | isbn       = 3-540-64563-2\n}}\n*{{cite book\n | last       = Gelbaum\n | first      = Bernard R.\n |author2=Olmsted, John M.H.\n  | title      = Counterexamples in analysis\n | publisher  = Dover Publications\n | year       = 2003\n | pages      = \n | isbn       = 0-486-42875-3\n}}\n*{{cite book\n | last       = Hyers\n | first      = Donald H. |author2=Isac, George |author3=Rassias, Themistocles M.\n | title      = Topics in nonlinear analysis & applications\n | publisher  = World Scientific\n | year       = 1997\n | pages      = \n | isbn       = 981-02-2534-2\n}}\n\n{{DEFAULTSORT:Semi-Continuity}}\n[[Category:Mathematical analysis]]\n[[Category:Variational analysis]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Shekel function",
      "url": "https://en.wikipedia.org/wiki/Shekel_function",
      "text": "\n'''Shekel function''' is a multidimensional, multimodal, continuous, deterministic [[function (mathematics)|function]] commonly used as a test function for testing [[optimization (mathematics)|optimization]] techniques.\n\nThe mathematical form of a function in <math>n</math> dimensions with <math>m</math> maxima is:\n\n<math>\nf(\\vec{x}) = \\sum_{i = 1}^{m} \\; \\left( c_{i} + \\sum\\limits_{j = 1}^{n} (x_{j} - a_{ji})^2 \\right)^{-1}\n</math>\n\nor, similarly,\n\n<math>\nf(x_1,x_2,...,x_{n-1},x_n) = \\sum_{i = 1}^{m} \\; \\left( c_{i} + \\sum\\limits_{j = 1}^{n} (x_{j} - a_{ij})^2 \\right)^{-1}\n</math>\n\n[[Image:Shekel_2D.jpg|right|thumb|400px|A Shekel function in 2 dimensions and with 10 maxima]]\n\n== Global minima ==\n\nNumerically certified global minima and the corresponding solutions were obtained using interval methods for up to <math>n = 10</math><ref name=\"Vanaret2014\">Vanaret C., Gotteland J-B., Durand N., Alliot J-M. (2014) [https://hal-enac.archives-ouvertes.fr/hal-00996713/document Certified Global Minima for a Benchmark of Difficult Optimization Problems.] Technical report. Ecole Nationale de l'Aviation Civile. Toulouse, France.</ref>.\n\n== References ==\n\nShekel, J. 1971. \"Test Functions for Multimodal Search Techniques.\" ''Fifth Annual Princeton Conference on Information Science and Systems''.\n\n<references/>\n\n== See also ==\n*[[Test functions for optimization]]\n\n[[Category:Mathematical optimization]]\n[[Category:Functions and mappings]]\n\n{{Mathanalysis-stub}}\n{{Mathapplied-stub}}"
    },
    {
      "title": "Signomial",
      "url": "https://en.wikipedia.org/wiki/Signomial",
      "text": "A '''signomial''' is an algebraic [[function (mathematics)|function]] of one or more independent variables.  It is perhaps most easily thought of as an algebraic extension of multivariable [[polynomial]]s—an extension that permits exponents to be arbitrary real numbers (rather than just non-negative integers) while requiring the independent variables to be strictly positive (so that division by zero and other inappropriate algebraic operations are not encountered).\n\nFormally, a signomial is a function with domain <math>\\mathbb{R}_{>0}^n</math> which takes values\n\n: <math>f(x_1, x_2, \\dots, x_n) = \\sum_{i=1}^M \\left(c_i \\prod_{j=1}^n x_j^{a_{ij}}\\right)</math>\n\nwhere the coefficients <math>c_k</math> and the exponents <math>a_{ij}</math> are real numbers.  Signomials are [[Closure (mathematics)|closed]] under addition, subtraction, multiplication, and scaling.\n\nIf we restrict all <math>c_i</math> to be positive, then the function f is a [[posynomial]]. Consequently, each signomial is either a posynomial, the negative of a posynomial, or the difference of two posynomials.  If, in addition, all exponents <math>a_{ij}</math> are  non-negative integers, then the signomial becomes a [[polynomial]] whose domain is the positive [[orthant]].\n\nFor example, \n\n: <math>f(x_1, x_2, x_3) = 2.7 x_1^2x_2^{-1/3}x_3^{0.7} - 2x_1^{-4}x_3^{2/5}</math>\n\nis a signomial. \n\nThe term \"signomial\" was introduced by Richard J. Duffin and Elmor L. Peterson in their seminal joint work on general algebraic optimization—published in the late 1960s and early 1970s.  A recent introductory exposition involves [[optimization problem]]s.<ref>C. Maranas and C. Floudas, ''Global optimization in generalized geometric programming'', pp. 351–370, 1997.</ref>  [[Nonlinear optimization]] problems with [[constrained optimization|constraints]] and/or [[objective function|objectives]] defined by signomials are harder to solve than those defined by only posynomials, because (unlike posynomials) signomials cannot necessarily be made [[convex function|convex]] by applying a logarithmic change of variables. Nevertheless, signomial optimization problems often provide a much more accurate mathematical representation of real-world nonlinear optimization problems.\n\n==References==\n{{reflist}}\n\n==External links==\n* S. Boyd, S. J. Kim, L. Vandenberghe, and A. Hassibi, [https://web.archive.org/web/20070308160245/http://www.stanford.edu/~boyd/gp_tutorial.html A Tutorial on Geometric Programming]\n\n[[Category:Functions and mappings]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Simulation-based optimization",
      "url": "https://en.wikipedia.org/wiki/Simulation-based_optimization",
      "text": "'''Simulation-based optimization''' integrates [[optimization (mathematics)|optimization]] techniques into [[computer simulation|simulation]] analysis. Because of the complexity of the simulation, the [[objective function]] may become difficult and expensive to evaluate.\n\nOnce a system is mathematically modeled, computer-based simulations provide information about its behavior. Parametric simulation methods can be used to improve the performance of a system. In this method, the input of each variable is varied with other parameters remaining constant and the effect on the design objective is observed. This is a time-consuming method and improves the performance partially. To obtain the optimal solution with minimum computation and time, the problem is solved iteratively where in each iteration the solution moves closer to the optimum solution. Such methods are known as ‘numerical optimization’ or ‘simulation-based optimization’.<ref>Nguyen, Anh-Tuan, Sigrid Reiter, and Philippe Rigo. \"[https://orbi.uliege.be/bitstream/2268/155988/1/Nguyen%20AT.pdf A review on simulation-based optimization methods applied to building performance analysis].\"''Applied Energy'' 113 (2014): 1043–1058.</ref>\n\nIn simulation experiment, the goal is to evaluate the effect of different values of input variables on a system. However, the interest is sometimes in finding the optimal value for input variables in terms of the system outcomes. One way could be running simulation experiments for all possible input variables. However, this approach is not always practical due to several possible situations and it just makes it intractable to run experiments for each scenario. For example, there might be too many possible values for input variables, or the simulation model might be too complicated and expensive to run for suboptimal input variable values. In these cases, the goal is to find optimal values for the input variables rather than trying all possible values. This process is called simulation optimization.<ref>Carson, Yolanda, and Anu Maria. \"[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.9192&rep=rep1&type=pdf Simulation optimization: methods and applications].\" ''Proceedings of the 29th conference on Winter simulation''. IEEE Computer Society, 1997.</ref>\n\nSpecific simulation–based optimization methods can be chosen according to figure 1 based on the decision variable types.<ref>Jalali, Hamed, and Inneke Van Nieuwenhuyse. \"[https://core.ac.uk/download/pdf/34623919.pdf Simulation optimization in inventory replenishment: a classification].\" IIE Transactions 47.11 (2015): 1217-1235.</ref>\n[[File:Slide1 1.jpg|thumb|Fig.1 Classification of simulation based optimization according to variable types]]\n[[Optimization (computer science)|Optimization]] exists in two main branches of operational research:\n\n''Optimization [[Parametric programming|parametric]] (static)'' – The objective is to find the values of the parameters, which are “static” for all states, with the goal of maximizing or minimizing a function. In this case, one can use [[mathematical programming]], such as [[linear programming]]. In this scenario, simulation helps when the parameters contain noise or the evaluation of the problem would demand excessive computer time, due to its complexity.<ref name=\":0\" />\n\n''Optimization [[Optimal control|control]] (dynamic)'' – This is used largely in [[computer science]] and [[electrical engineering]]. The optimal control is per state and the results change in each of them. One can use mathematical programming, as well as dynamic programming. In this scenario, simulation can generate random samples and solve complex and large-scale problems.<ref name=\":0\">Abhijit Gosavi, [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.462.5587&rep=rep1&type=pdf Simulation‐Based Optimization: Parametric Optimization Techniques and Reinforcement Learning], Springer, 2nd Edition (2015)</ref>\n\n== Simulation-based optimization methods ==\nThe main approaches in simulation optimization are discussed below. \n<ref name=Fu>{{cite book|last=Fu|first=Michael, editor|title=Handbook of Simulation Optimization|publisher=Springer|year=2015|url=https://www.springer.com/us/book/9781493913831}}</ref>\n\n=== Statistical ranking and selection methods (R/S) ===\nRanking and selection methods are designed for problems where the alternatives are fixed and known, and simulation is used to estimate the system performance. \nIn the simulation optimization setting, applicable methods include indifference zone approaches, optimal computing budget allocation, and knowledge gradient algorithms.\n\n=== Response surface methodo<nowiki/>logy (RSM)===\nIn [[response surface methodology]], the objective is to find the relationship between the input variables and the response variables. The process starts from trying to fit a linear regression model. If the P-value turns out to be low, then a higher degree polynomial regression, which is usually quadratic, will be implemented. The process of finding a good relationship between input and response variables will be done for each simulation test. In simulation optimization, response surface method can be used to find the best input variables that produce desired outcomes in terms of response variables.<ref>Rahimi Mazrae Shahi, M., Fallah Mehdipour, E. and Amiri, M. (2016), [https://onlinelibrary.wiley.com/doi/abs/10.1111/itor.12150 Optimization using simulation and response surface methodology with an application on subway train scheduling]. Intl. Trans. in Op. Res., 23: 797–811. doi:10.1111/itor.12150</ref>\n\n=== Heuristic methods ===\n[[Heuristic (computer science)|Heuristic methods]] change accuracy by speed. Their goal is to find a good solution faster than the traditional methods, when they are too slow or fail in solving the problem. Usually they find local optimal instead of the optimal value; however, the values are considered close enough of the final solution. Examples of this kind of method is [[tabu search]] or [[Genetic algorithm]].<ref name=\":0\" />\n\nMetamodels enable researchers to obtain reliable approximate model outputs without running expensive and time-consuming computer simulations. Therefore, the process of model optimization can take less computation time and cost. <ref>{{Cite journal|last=Yousefi|first=Milad|last2=Yousefi|first2=Moslem|last3=Ferreira|first3=Ricardo Poley Martins|last4=Kim|first4=Joong Hoon|last5=Fogliatto|first5=Flavio S.|title=Chaotic genetic algorithm and Adaboost ensemble metamodeling approach for optimum resource planning in emergency departments|journal=Artificial Intelligence in Medicine|volume=84|pages=23–33|doi=10.1016/j.artmed.2017.10.002|pmid=29054572|year=2018}}</ref>\n\n=== Stochastic approximation ===\n[[Stochastic approximation]] is used when the function cannot be computed directly, only estimated via noisy observations. In this scenarios, this method (or family of methods) looks for the extrema of these function. The objective function would be:<ref>Powell, W. (2011). ''Approximate Dynamic Programming Solving the Curses of Dimensionality'' (2nd ed., Wiley Series in Probability and Statistics). Hoboken: Wiley.</ref>\n\n:<math>\\underset{\\text{x}\\in\\theta}{\\min}f\\bigl(\\text{x}\\bigr) = \\underset{\\text{x}\\in\\theta}{\\min}\\Epsilon[F\\bigl(\\text{x,y})]</math>\n\n:<math>y</math>  is a random variable that represents the noise.\n\n:<math>x</math> is the parameter that minimizes  <math>f\\bigl(\\text{x}\\bigr)</math>.\n\n:<math>\\theta</math>  is the domain of the parameter <math>x</math>.\n\n=== Derivative-free optimization methods ===\n[[Derivative-free optimization]] is a subject of mathematical optimization. This method is applied to a certain optimization problem when its derivatives are unavailable or unreliable. Derivative-free methods establish a model based on sample function values or directly draw a sample set of function values without exploiting a detailed model. Since it needs no derivatives, it cannot be compared to derivative-based methods.<ref>Conn, A. R.; [[Katya Scheinberg|Scheinberg, K.]]; Vicente, L. N. (2009). [http://www.mat.uc.pt/~lnv/idfo/ ''Introduction to Derivative-Free Optimization'']. MPS-SIAM Book Series on Optimization. Philadelphia: SIAM. Retrieved 2014-01-18.</ref>\n\nFor unconstrained optimization problems, it has the form:\n\n:<math>\\underset{\\text{x}\\in\\R^n}{\\min}f\\bigl(\\text{x}\\bigr)</math>\n\nThe limitations of derivative-free optimization:\n\n1. It is usually cannot handle optimization problems with a few tens of variables; the results via this method are usually not so accurate.\n\n2. When confronted with minimizing non-convex functions, it will show its limitation.\n\n3. Derivative-free optimization methods are simple and easy; however, they are not so good in theory and in practice.\n\n=== Dynamic programming and neuro-dynamic programming ===\n\n==== Dynamic programming ====\n[[Dynamic programming]] deals with situations where decisions are made in stages. The key to this kind of problems is to trade off the present and future costs.<ref>Cooper, Leon; Cooper, Mary W. Introduction to dynamic programming. New York: Pergamon Press, 1981</ref>\n\nOne dynamic basic model has two features:\n\n1) It has a discrete time dynamic system.\n\n2) The cost function is additive over time.\n\nFor discrete features, dynamic programming has the form:\n\n:<math>x_{k+1} = f_k(x_{k},u_{k},w_{k}) , k=0,1,...,N-1</math>\n\n:<math>k</math> represents the index of discrete time.\n\n:<math>x_k</math> is the state of the time k, it contains the past information and prepare it for the future optimization.\n\n:<math>u_k</math> is the control variable.\n\n:<math>w_k</math> is the random parameter.\n\nFor the cost function, it has the form:\n\n:<math>g_N(X_N) + \\sum_{k=0}^{N-1} gk(x_k,u_k,W_k)</math>\n\n<math>g_N(X_N)</math> is the cost at the end of the process.\n\nAs the cost cannot be optimized meaningfully, it can be used the expect value:\n\n:<math>E\\{g_N(X_N) + \\sum_{k=0}^{N-1} g_k(x_k,u_k,W_k) \\}</math>\n\n==== Neuro-dynamic programming ====\nNeuro-dynamic programming is the same as dynamic programming except that the former has the concept of approximation architectures. It combines [[artificial intelligence]], simulation-base algorithms, and functional approach techniques. “Neuro” in this term origins from artificial intelligence community. It means learning how to make improved decisions for the future via built-in mechanism based on the current behavior. The most important part of neuro-dynamic programming is to build a trained neuro network for the optimal problem.<ref>Van Roy, B., Bertsekas, D., Lee, Y., & [[John Tsitsiklis|Tsitsiklis, J.]] (1997). [https://web.stanford.edu/~bvr/pubs/retail.pdf Neuro-dynamic programming approach to retailer inventory management]. ''Proceedings of the IEEE Conference on Decision and Control,'' ''4'', 4052-4057.</ref>\n\n== Limitations ==\nSimulation based optimization has some limitations, such as the difficulty of creating a model that imitates the dynamic behavior of a system in a way that is considered good enough for its representation. Another problem is complexity in the determining uncontrollable parameters of both real-world system and simulation. Moreover, only a statistical estimation of real values can be obtained. It is not easy to determine the objective function, since it is a result of measurements, which can be harmful for the solutions.<ref>Prasetio, Y. (2005). ''[https://elibrary.ru/item.asp?id=9387151 Simulation-based optimization for complex stochastic systems]''. University of Washington.</ref><ref>Deng, G., & Ferris, Michael. (2007). ''Simulation-based Optimization,'' ProQuest Dissertations and Theses</ref>\n\n==References==\n{{Reflist}}\n\n[[Category:Mathematical optimization]]\n[[Category:Simulation]]"
    },
    {
      "title": "Sion's minimax theorem",
      "url": "https://en.wikipedia.org/wiki/Sion%27s_minimax_theorem",
      "text": "In [[mathematics]], and in particular [[game theory]], '''Sion's minimax theorem''' is a generalization of [[John von Neumann]]'s [[minimax theorem]], named after [[Maurice Sion]].\n\nIt states:\n\nLet <math>X</math> be a [[compact space|compact]] [[Convex set|convex]] subset of a [[linear topological space]] and <math>Y</math> a convex subset of a linear topological space.  If <math>f</math> is a real-valued [[Function (mathematics)|function]] on <math>X\\times Y</math> with\n\n: <math>f(x,\\cdot)</math> [[upper semicontinuous]]  and [[quasiconvex function|quasiconcave]] on <math>Y</math>, <math>\\forall x\\in X</math>, and\n: <math>f(\\cdot,y)</math> lower semicontinuous and quasi-convex on <math>X</math>, <math>\\forall y\\in Y</math>\n\nthen,\n\n: <math>\\min_{x\\in X}\\sup_{y\\in Y} f(x,y)=\\sup_{y\\in Y}\\min_{x\\in X}f(x,y).</math>\n\n==See also==\n*[[Parthasarathy's theorem]]\n*[[Saddle point]]\n\n==References==\n* {{cite journal |first=Maurice |last=Sion |title=On general minimax theorems |journal=[[Pacific Journal of Mathematics]] |volume=8 |issue=1 |year=1958 |pages=171–176 |zbl=0081.11502 |mr=0097026 |doi=10.2140/pjm.1958.8.171}}\n* {{cite journal |first=Hidetoshi |last=Komiya |year=1988 |title=Elementary proof for Sion's minimax theorem |journal=[[Kodai Mathematical Journal]] |volume=11 |issue=1 |pages=5–7 |mr=0930413 |zbl=0646.49004 |doi=10.2996/kmj/1138038812}}\n\n{{DEFAULTSORT:Sion's Minimax Theorem}}\n[[Category:Game theory]]\n[[Category:Mathematical optimization]]\n[[Category:Mathematical theorems]]\n\n\n{{mathanalysis-stub}}\n{{gametheory-stub}}"
    },
    {
      "title": "Smoothed analysis",
      "url": "https://en.wikipedia.org/wiki/Smoothed_analysis",
      "text": "'''Smoothed analysis''' is a way of measuring the [[Analysis of algorithms|complexity of an algorithm]]. It gives a more realistic analysis of the practical performance of the algorithm,  such as its running time, than using worst-case or average-case scenarios.\n\n==Introduction==\n[[Average-case analysis]] was first introduced to overcome the limitations of [[worst-case analysis]], however the difficulty is saying what an average case is. The actual inputs and distribution of inputs may be different in practice from the assumptions made during the analysis: a random input may be very unlike a typical input.\n\nSmoothed analysis is a hybrid of worst-case and average-case analyses that inherits advantages of both, by measuring the expected performance of algorithms under slight random perturbations of worst-case inputs. If the smoothed complexity of an algorithm is low, then it is unlikely that the algorithm will take long time to solve practical instances whose data are subject to slight noises and imprecisions.\n\n==Use==\nSince its introduction in 2001, smoothed analysis has been used as a basis for considerable research, for problems ranging from [[mathematical programming]], [[numerical analysis]], [[machine learning]], and [[data mining]].<ref>D. A. Spielman, S. H. Teng. ''Smoothed analysis: an attempt to explain the behavior of algorithms in practice'', Communications of the ACM, 52(10):76–84, 2009.</ref>\n\n==Example==\nThe [[simplex algorithm]] is a very efficient algorithm in practice, and it is one of the dominant algorithms for linear programming in practice. Yet in the theoretical worst case it runs in exponential-time for most successfully analyzed pivot rules. This was one of the main motivations for developing smoothed analysis.\n\nIn smoothed analysis of linear programming, the typical input model has mean data <math>\\bar{\\mathbf A} \\in \\mathbb{R}^{n\\times d}, \\bar{\\mathbf b} \\in \\mathbb{R}^n, b \\in \\mathbb{R}^d</math> that satisfies <math>\\|(\\bar{\\mathbf a}_i, \\bar{\\mathbf b}_i)\\|_2 \\leq 1</math> for all rows of the matrix <math>(\\bar{\\mathbf A}, \\bar{\\mathbf b})</math>. The noise data <math>\\|(\\hat{\\mathbf A}, \\hat{\\mathbf b})\\|</math> has its entries independently distributed entries sampled from a [[Gaussian distribution]] with mean <math>0</math> and standard deviation <math>\\sigma</math>. The smoothed input data consists of <math>\\mathbf A = \\bar{\\mathbf A} + \\hat{\\mathbf A}, \\mathbf b = \\bar{\\mathbf b} + \\hat{\\mathbf b}</math>. The smoothed complexity of an algorithm is the maximum over admissible <math>\\bar{\\mathbf A}, \\bar{\\mathbf b}, \\mathbf c</math> of the expectation over <math>\\hat{\\mathbf A}, \\hat{\\mathbf b}</math> of the time it takes to solve the linear program\n:maximize\n::<math>\\mathbf{c^T} \\cdot \\mathbf{x}</math>\n:subject to\n::<math>\\mathbf{A}\\mathbf{x} \\leq \\mathbf{b}</math>.\n\nAn algorithm has polynomial smoothed complexity if its expected running time is bounded by a polynomial in <math>n, d, \\sigma^{-1}</math>.\n\n==History==\n[[Association for Computing Machinery|ACM]] and [[EATCS|the European Association for Theoretical Computer Science]] awarded the 2008 [[Gödel Prize]] to [[Daniel Spielman]] and [[Shanghua Teng]] for developing smoothed analysis. In 2010 Spielman received the [[Nevanlinna Prize]] for developing smoothed analysis.  Spielman and Teng's JACM paper \"Smoothed analysis of algorithms: Why the simplex algorithm usually takes polynomial time\" was also one of the three winners of the 2009 [[Fulkerson Prize]] sponsored jointly by the [[Mathematical Programming Society]] (MPS)  and the [[American Mathematical Society]] (AMS).\n\n==See also==\n*[[Structural stability]]\n\n==References==\n{{Reflist}}\n{{Citation | last1=Spielman | first1=Daniel | last2=Teng | first2=Shang-Hua | author1-link=Daniel Spielman | author2-link=Shanghua Teng | title=Proceedings of the Thirty-Third Annual ACM Symposium on Theory of Computing | publisher=ACM | isbn=978-1-58113-349-3 | doi=10.1145/380752.380813 | year=2001 | chapter=Smoothed analysis of algorithms: why the simplex algorithm usually takes polynomial time | pages=296–305 | arxiv=cs/0111050}}.\n\n==External links==\n*[http://www.cs.yale.edu/homes/spielman/SmoothedAnalysis/index.html Smoothed Analysis Homepage]\n\n[[Category:Computational complexity theory]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Steiner's calculus problem",
      "url": "https://en.wikipedia.org/wiki/Steiner%27s_calculus_problem",
      "text": "[[File:Mplwp Steiners problem.svg|right|300px]]\n'''Steiner's problem''', asked and answered by {{harvtxt|Steiner|1850}}, is the problem of finding the [[maxima and minima|maximum]] of the [[function (mathematics)|function]]\n\n: <math>f(x)=x^{1/x}.\\,</math><ref>{{cite web\n| url = http://mathworld.wolfram.com/SteinersProblem.html\n| title = Steiner's Problem\n| author = Eric W. Weisstein\n| publisher = MathWorld\n|accessdate=December 8, 2010 }}</ref>\n\nIt is named after [[Jakob Steiner]].\n\nThe maximum is at <math>x=e</math>, where ''e'' denotes the [[e (mathematical constant)|base of natural logarithms]]. One can determine that by solving the equivalent problem of maximizing \n\n: <math>g(x)=\\ln f(x) = \\frac{\\ln x}{x}.</math>\n\nThe [[derivative]] of <math>g</math> can be calculated to be \n\n: <math>g'(x)= \\frac{1-\\ln x}{x^2}.</math>\n\nIt follows that <math>g'(x)</math> is positive for <math>0<x<e</math> and negative for <math>x>e</math>, which implies that <math>g(x)</math> (and therefore <math>f(x)</math>) increases for <math>0<x<e</math> and decreases for <math>x>e.</math> Thus,  <math>x=e</math> is the unique global maximum of <math>f(x).</math>\n\n==References==\n<references />\n*{{citation|title=Über das größte Product der Theile oder Summanden jeder Zahl\n|first=J. |last=Steiner|journal=Crelle|volume=40|year=1850|pages=208|url=http://gdz.sub.uni-goettingen.de/en/dms/loader/toc/?PID=PPN243919689_0040}}\n\n{{DEFAULTSORT:Steiner's calculus Problem}}\n[[Category:Functions and mappings]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Stochastic multicriteria acceptability analysis",
      "url": "https://en.wikipedia.org/wiki/Stochastic_multicriteria_acceptability_analysis",
      "text": "'''Stochastic multicriteria acceptability analysis''' ('''SMAA''') is a [[multiple-criteria decision analysis]] method for problems with missing or incomplete information.\n\n==Description==\nThis means that criteria and preference information can be uncertain, inaccurate or partially missing. Incomplete information is represented in SMAA using suitable probability distributions. The method is based on stochastic simulation by drawing random values for criteria measurements and weights from their corresponding distributions.<ref>{{cite journal | last1 = Lahdelma | first1 = R. | last2 = Salminen | first2 = P. | year = 2001 | title = SMAA-2: Stochastic Multicriteria Acceptability Analysis for Group Decision Making | doi = 10.1287/opre.49.3.444.11220 | journal = Operations Research | volume = 49 | issue = 3| pages = 444–454 | citeseerx = 10.1.1.138.4807 }}</ref>\n\nSMAA can handle mixed [[cardinal numbers|cardinal]] and [[ordinal numbers|ordinal]] information. Ordinal information is treated by a special joint distribution that preserves the ordinal information.<ref>Sousa R., Yevseyeva I., Pinto da Costa J.F., Cardoso J.S. (2013). Multicriteria models for learning ordinal data: A literature review. In Yang X.S. Artificial Intelligence, Evolutionary Computing and Metaheuristics: In the Footsteps of Alan Turing. Studies in Computational Intelligence 427, Springer.</ref>\n\nA survey on different variants and applications of SMAA can be found in this article.<ref>{{cite journal | last1 = Tervonen | first1 = T. | last2 = Figueira | first2 = J. | year = 2008 | title = A survey on stochastic multicriteria acceptability analysis methods | doi = 10.1002/mcda.407 | journal = Journal of Multi-Criteria Decision Analysis | volume = 15 | issue = 1–2| pages = 1–14 }}</ref>\n\nOpen source implementations of SMAA can be found at the website SMAA.fi.<ref>{{cite web|last1=Tervonen|first1=Tommi|title=Open source decision aiding software for real-life applications|url=http://smaa.fi/|website=SMAA.fi|accessdate=17 December 2016}}</ref>\n\n==References==\n{{Reflist}}\n\n[[Category:Decision analysis]]\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis]]"
    },
    {
      "title": "Stress majorization",
      "url": "https://en.wikipedia.org/wiki/Stress_majorization",
      "text": "'''Stress majorization''' is an [[optimization (mathematics)|optimization strategy]] used in [[multidimensional scaling]] (MDS) where, for a set of ''n'' ''m''-dimensional data items, a configuration ''X'' of ''n'' points in ''r(<<m)''-dimensional space is sought that minimizes the so-called ''stress'' function <math>\\sigma(X)</math>.  Usually ''r'' is 2 or 3, i.e. the ''(''n'' x ''r'')'' matrix ''X'' lists points in 2- or 3-dimensional [[Euclidean space]] so that the result may be visualised (i.e. an [[MDS plot]]).  The function <math>\\sigma</math> is a cost or [[loss function]] that measures the squared differences between ideal (<math>m</math>-dimensional) distances and actual distances in ''r''-dimensional space.  It is defined as:\n\n: <math>\\sigma(X)=\\sum_{i<j\\le n}w_{ij}(d_{ij}(X)-\\delta_{ij})^2</math>\n\nwhere <math>w_{ij}\\ge 0</math> is a weight for the measurement between a pair of points <math>(i,j)</math>, <math>d_{ij}(X)</math> is the [[euclidean distance]] between <math>i</math> and <math>j</math> and <math>\\delta_{ij}</math> is the ideal distance between the points (their separation) in the <math>m</math>-dimensional data space.  Note that <math>w_{ij}</math> can be used to specify a degree of confidence in the similarity between points (e.g. 0 can be specified if there is no information for a particular pair).\n\nA configuration <math>X</math> which minimizes <math>\\sigma(X)</math> gives a plot in which points that are close together correspond to points that are also close together in the original <math>m</math>-dimensional data space.\n\nThere are many ways that <math> \\sigma(X)</math> could be minimized.  For example, Kruskal<ref>{{citation|last=Kruskal|first=J. B.|authorlink=Joseph Kruskal|title=Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis|journal=Psychometrika|volume=29|issue=1|pages=1–27|year=1964|doi=10.1007/BF02289565}}.</ref> recommended an iterative [[steepest descent]] approach. However, a significantly better (in terms of guarantees on, and rate of, convergence) method for minimizing stress was introduced by [[Jan de Leeuw]].<ref name=\"de Leeuw\">{{citation|last=de Leeuw|first=J.|contribution=Applications of convex analysis to multidimensional scaling|editor1-first=J. R.|editor1-last=Barra|editor2-first=F.|editor2-last=Brodeau|editor3-first=G.|editor3-last=Romie|editor4-first=B.|display-editors = 3 |editor4-last=van Cutsem|title=Recent developments in statistics|pages=133–145|year=1977}}.</ref>  De Leeuw's ''iterative majorization'' method at each step minimizes a simple convex function which both bounds <math>\\sigma</math> from above and touches the surface of <math>\\sigma</math> at a point <math>Z</math>, called the ''supporting point''.  In [[convex analysis]] such a function is called a ''majorizing'' function.  This iterative majorization process is also referred to as the SMACOF algorithm (\"Scaling by MAjorizing a COmplicated Function\").\n\n== The SMACOF algorithm ==\nThe stress function <math>\\sigma</math> can be expanded as follows:\n\n: <math>\n\\sigma(X)=\\sum_{i<j\\le n}w_{ij}(d_{ij}(X)-\\delta_{ij})^2\n=\\sum_{i<j}w_{ij}\\delta_{ij}^2 + \\sum_{i<j}w_{ij}d_{ij}^2(X)-2\\sum_{i<j}w_{ij}\\delta_{ij}d_{ij}(X)\n</math>\n\nNote that the first term is a constant <math>C</math> and the second term is quadratic in X (i.e. for the [[Hessian matrix]] V the second term is equivalent to [[Matrix trace|tr]]<math>X'VX</math>) and therefore relatively easily solved.  The third term is bounded by:\n\n: <math>\n\\sum_{i<j}w_{ij}\\delta_{ij}d_{ij}(X)=\\,\\operatorname{tr}\\, X'B(X)X \\ge \\,\\operatorname{tr}\\, X'B(Z)Z\n</math>\n\nwhere <math>B(Z)</math> has:\n\n: <math>b_{ij}=-\\frac{w_{ij}\\delta_{ij}}{d_{ij}(Z)}</math> for <math>d_{ij}(Z)\\ne 0, i \\ne j</math>\n\nand <math>b_{ij}=0</math> for <math>d_{ij}(Z)=0, i\\ne j</math>\n\nand <math>b_{ii}=-\\sum_{j=1,j\\ne i}^n b_{ij}</math>.\n\nProof of this inequality is by the [[Cauchy-Schwarz]] inequality, see Borg<ref name=\"borg\">{{citation|last1=Borg|first1=I.|last2=Groenen|first2=P.|author-link2=Patrick Groenen|title=Modern Multidimensional Scaling: theory and applications|publisher=Springer-Verlag|location=New York|year=1997}}.</ref> (pp.&nbsp;152–153).\n\nThus, we have a simple quadratic function <math>\\tau(X,Z)</math> that majorizes stress:\n\n: <math>\\sigma(X)=C+\\,\\operatorname{tr}\\, X'VX - 2 \\,\\operatorname{tr}\\, X'B(X)X\n</math>\n: <math>\\le C+\\,\\operatorname{tr}\\, X' V X - 2 \\,\\operatorname{tr}\\, X'B(Z)Z = \\tau(X,Z)\n</math>\n\n\nThe iterative minimization procedure is then:\n\n* at the k<sup>th</sup> step we set <math>Z\\leftarrow X^{k-1}</math>\n* <math>X^k\\leftarrow \\min_X \\tau(X,Z)</math>\n* stop if <math>\\sigma(X^{k-1})-\\sigma(X^{k})<\\epsilon</math> otherwise repeat.\n\nThis algorithm has been shown to decrease stress monotonically (see de Leeuw<ref name=\"de Leeuw\"/>).\n\n== Use in graph drawing ==\nStress majorization and algorithms similar to SMACOF also have application in the field of [[graph drawing]].<ref>{{citation|last1=Michailidis|first1=G.|last2=de Leeuw|first2=J.|title=Data visualization through graph drawing|journal=Computation Stat.|year=2001|volume=16|issue=3|pages=435–450|doi=10.1007/s001800100077|citeseerx=10.1.1.28.9372}}.</ref><ref>{{citation|first1=E.|last1=Gansner|first2=Y.|last2=Koren|first3=S.|last3=North|contribution=Graph Drawing by Stress Majorization|title=Proceedings of 12th Int. Symp. Graph Drawing (GD'04)|series=Lecture Notes in Computer Science|volume=3383|publisher=Springer-Verlag|pages=239–250|year=2004|title-link=International Symposium on Graph Drawing}}.</ref> That is, one can find a reasonably aesthetically appealing layout for a network or graph by minimizing a stress function over the positions of the nodes in the graph.  In this case, the <math>\\delta_{ij}</math> are usually set to the graph-theoretic distances between nodes ''i'' and ''j'' and the weights <math>w_{ij}</math> are taken to be <math>\\delta_{ij}^{-\\alpha}</math>.  Here, <math>\\alpha</math> is chosen as a trade-off between preserving long- or short-range ideal distances.  Good results have been shown for <math>\\alpha=2</math>.<ref>{{citation|last=Cohen|first=J.|title=Drawing graphs to convey proximity: an incremental arrangement method|journal=ACM Transactions on Computer-Human Interaction|volume=4|issue=3|year=1997|pages=197–229|doi=10.1145/264645.264657}}.</ref>\n\n== References ==\n{{reflist}}\n\n[[Category:Graph drawing]]\n[[Category:Dimension reduction]]\n[[Category:Mathematical optimization]]\n[[Category:Mathematical analysis]]"
    },
    {
      "title": "Sum-of-squares optimization",
      "url": "https://en.wikipedia.org/wiki/Sum-of-squares_optimization",
      "text": ":''This article deals with sum-of-squares constraints. For problems with sum-of-squares cost functions, see [[Least squares]].''\n\nA '''sum-of-squares optimization''' program is an [[optimization]] problem with a linear [[loss function|cost function]] and a particular type of constraint on the decision variables. These constraints are of the form that when the decision variables are used as coefficients in certain [[polynomials]], those polynomials should have the [[polynomial SOS]] property. When fixing the maximum degree of the polynomials involved, sum-of-squares optimization is also known as the '''Lasserre hierarchy''' of relaxations in [[semidefinite programming]].\n\nSum-of-squares optimization techniques have been successfully applied by researchers in the [[control engineering]] field, in special in the search for polynomial Lyapunov functions for dynamical systems described by polynomial vector fields.<ref>Tan, W., Packard, A., 2004. \"[http://jagger.me.berkeley.edu/papers/weehong_3.pdf Searching for control Lyapunov functions using sums of squares programming]\". In: ''Allerton Conf. on Comm., Control and\nComputing''. pp. 210&ndash;219.</ref><ref>Tan, W., Topcu, U., Seiler, P., Balas, G., Packard, A., 2008. Simulation-aided\nreachability and local gain analysis for nonlinear dynamical systems. In:\nProc. of the IEEE Conference on Decision and Control. pp. 4097–4102.</ref><ref>A. Chakraborty, P. Seiler, and G. Balas, “Susceptibility of F/A-18 Flight Controllers to the Falling-Leaf Mode: Nonlinear Analysis,” AIAA Journal of Guidance, Control, and Dynamics, Vol.34 No.1, 2011, 73–85.</ref>\n\n==Optimization problem==\n\nThe problem can be expressed as\n\n:<math> \\max_{u\\in\\R^n} c^T u  </math>\nsubject to\n:<math> a_{k,0}(x) + a_{k,1}(x)u_1 + \\cdots + a_{k,n}(x)u_n \\in \\text{SOS}\n\\quad (k=1,\\ldots, N_s).</math>\n\nHere \"SOS\" represents the class of sum-of-squares (SOS) polynomials.\nThe vector <math>c\\in \\R^n </math> and polynomials <math>\\{ a_{k,j} \\} </math> are given as part of the  data for the optimization problem. The quantities <math>u\\in \\R^n </math> are the decision variables. SOS programs can be converted to [[semidefinite programming|semidefinite programs]] (SDPs) using the\n[[Duality (optimization)|duality]] of the [[Polynomial SOS|SOS polynomial]] program and a relaxation for constrained polynomial optimization using [[positive-semidefinite matrix|positive-semidefinite matrices]], see the following section.\n\n== Dual problem: constrained polynomial optimization ==\nSuppose we have an <math> n  </math>-variate polynomial <math> p(x): \\mathbb{R}^n \\to \\mathbb{R}  </math> , and suppose that we would like to minimize this polynomial over a subset <math display=\"inline\"> A \\subseteq \\mathbb{R}^n  </math>.\nSuppose furthermore that the constraints on the subset <math display=\"inline\"> A  </math> can be encoded using <math display=\"inline\"> m  </math> polynomial equalities of degree at most <math> 2d\n  </math>, each of the form <math display=\"inline\"> a_i(x) = 0\n  </math> where <math> a_i: \\mathbb{R}^n \\to \\mathbb{R}  </math> is a polynomial of degree at most <math> 2d\n  </math>. \nA natural, though generally non-convex program for this optimization problem is the following:\n\n:<math> \\min_{x \\in \\mathbb{R}^{n}} \\langle C, x^{\\le d} (x^{\\le d})^\\top \\rangle  </math>\n\nsubject to:\n\n:<math> \n\\langle A_i, x^{\\le d}(x^{\\le d})^\\top \\rangle = 0 \\qquad \\forall \\ i \\in [m]\n\n</math>, &nbsp;&nbsp; ({{EquationRef|1}})\n\n:<math> x_{\\emptyset} = 1\n  </math>,\n\nwhere <math display=\"inline\"> \n x^{\\le d}\n\n  </math> is the <math> \n n^{O(d)}\n\n  </math>-dimensional vector with one entry for every monomial in <math> \n x\n\n  </math> of degree at most <math> \n d\n\n  </math>, so that for each multiset <math> \n S \\subset [n], |S| \\le d,\n\n  </math> <math> x_S = \\prod_{i \\in S}x_i  </math>, <math display=\"inline\"> \n C\n\n  </math> is a matrix of coefficients of the polynomial  <math display=\"inline\"> \np(x)\n\n  </math> that we want to minimize, and <math display=\"inline\"> \n A_i\n\n  </math> is a matrix of coefficients of the polynomial <math display=\"inline\"> \na_i(x)\n\n  </math> encoding the <math> \ni\n\n  </math>th constraint on the subset <math> \nA \\subset \\mathbb{R}^n\n\n  </math>. The additional, fixed constant index in our search space, <math> x_{\\emptyset} = 1\n  </math>, is added for the convenience of writing the polynomials <math display=\"inline\"> \np(x)\n\n  </math> and <math display=\"inline\"> \na_i(x)\n\n  </math> in a matrix representation.\n\nThis program is generally non-convex, because the constraints ({{EquationNote|1}}) are not convex. One possible convex relaxation for this minimization problem uses [[semidefinite programming]] to replace the rank-one matrix of variables <math> \nx^{\\le d}(x^{\\le d})^\\top\n\n  </math> with a positive-semidefinite matrix <math> X\n  </math>: we index each monomial of size at most <math> 2d\n  </math> by a multiset <math>  S  </math> of at most <math> 2d\n  </math> indices,  <math>  S \\subset [n], |S| \\le 2d  </math>. For each such monomial, we create a variable <math> X_S\n  </math> in the program, and we arrange the variables <math> X_S\n  </math> to form the matrix <math display=\"inline\"> X \\in \\mathbb{R}^{[n]^{\\le d} \\times [n]^{\\le d}}  </math>, where <math> \n \\mathbb{R}^{[n]^{\\le d}\\times [n]^{\\le d}}\n\n  </math>is the set of real matrices whose rows and columns are identified with multisets of elements from <math> \n n\n\n  </math> of size at most <math> \n d\n\n  </math>. We then write the following semidefinite program in the variables <math> X_S\n  </math>:\n\n:<math> \\min_{X \\in \\mathbb{R}^{[n]^{\\le d} \\times [n]^{\\le d} }}\\langle C, X \\rangle  </math>\n\nsubject to:\n\n:<math> \n\\langle A_i, X \\rangle =0 \\qquad \\forall \\ i \\in [m]\n\n  </math>,<math display=\"inline\"> \nQ\n\n  </math>\n\n:<math> X_{\\emptyset} = 1  </math>,\n\n:<math> \nX_{U \\cup V} = X_{S \\cup T} \\qquad  \\forall \\  U,V,S,T \\subseteq [n], |U|,|V|,|S|,|T| \\le d,\\text{ and} \\ U \\cup V = S \\cup T\n\n  </math>,\n\n:<math> \nX \\succeq 0\n\n  </math>,\n\nwhere again <math display=\"inline\"> \n C\n\n  </math> is the matrix of coefficients of the polynomial  <math display=\"inline\"> \np(x)\n\n  </math> that we want to minimize, and<math display=\"inline\"> \n A_i\n\n  </math> is the matrix of coefficients of the polynomial <math display=\"inline\"> \na_i(x)\n\n  </math> encoding the <math> \ni\n\n  </math>th constraint on the subset <math> \nA \\subset \\mathbb{R}^n\n\n  </math>. \n\nThe third constraint ensures that the value of a monomial that appears several times within the matrix is equal throughout the matrix, and is added to make <math> X\n  </math> respect the symmetries present in the quadratic form <math> \nx^{\\le d}(x^{\\le d})^\\top\n\n  </math>. \n\n=== Duality ===\nOne can take the dual of the above semidefinite program and obtain the following program:\n\n:<math> \n\\max_{y \\in \\mathbb{R}^{m'}} y_0\n\n  </math>,\n\nsubject to:\n\n:<math> \nC  - y_0 e_{\\emptyset}- \\sum_{i \\in [m]} y_i A_i - \\sum_{S\\cup T = U\\cup V} y_{S,T,U,V} (e_{S,T} - e_{U,V})\\succeq 0\n\n  </math>.\n\nWe have a variable <math> \ny_0\n\n  </math>corresponding to the constraint  <math> \n\\langle e_{\\emptyset}, X\\rangle = 1\n\n  </math>(where <math> \ne_{\\emptyset}\n\n  </math>is the matrix with all entries zero save for the entry indexed by <math> \n(\\emptyset,\\emptyset)\n  </math>), a real variable <math> \ny_i\n\n  </math>for each polynomial constraint <math> \n\\langle X,A_i \\rangle = 0 \\quad s.t. i \\in [m],\n\n  </math>and for each group of multisets <math> \nS,T,U,V \\subset [n], |S|,|T|,|U|,|V| \\le d, S\\cup T = U \\cup V\n\n  </math>, we have a dual variable <math> \ny_{S,T,U,V}\n\n  </math>for the symmetry constraint <math> \n\\langle X, e_{S,T} - e_{U,V} \\rangle = 0\n\n  </math>.  The positive-semidefiniteness constraint ensures that <math> \np(x) - y_0\n\n  </math> is a sum-of-squares of polynomials over <math> \nA \\subset \\mathbb{R}^n\n\n  </math>: by a characterization of positive-semidefinite matrices, for any positive-semidefinite matrix <math display=\"inline\"> \nQ\\in \\mathbb{R}^{m \\times m}\n\n  </math>, we can write  <math display=\"inline\"> \nQ = \\sum_{i \\in [m]} f_i f_i^\\top\n\n  </math> for vectors <math display=\"inline\"> \nf_i \\in \\mathbb{R}^m\n\n  </math>. Thus for any <math display=\"inline\"> \n x \\in A \\subset \\mathbb{R}^n\n\n  </math>,\n\n:<math> \n \\begin{align}\np(x) - y_0\n&= p(x) - y_0 - \\sum_{i \\in [m']} y_i a_i(x) \\qquad \\text{since } x \\in A\\\\\n&=(x^{\\le d})^\\top \\left( C - y_0 e_{\\emptyset} - \\sum_{i\\in [m']} y_i A_i - \\sum_{S\\cup T = U \\cup V} y_{S,T,U,V}(e_{S,T}-e_{U,V}) \\right)x^{\\le d}\\qquad \\text{by symmetry}\\\\\n&= (x^{\\le d})^\\top \\left( \\sum_{i} f_i f_i^\\top \\right)x^{\\le d} \\\\ \n&= \\sum_{i} \\langle x^{\\le d}, f_i\\rangle^2 \\\\\n&= \\sum_{i} f_i(x)^2,\n\\end{align}\n\n  </math>\n\nwhere we have identified the vectors  <math display=\"inline\"> \nf_i\n\n  </math> with the coefficients of a polynomial of degree at most <math> d\n  </math>. This gives a sum-of-squares proof that the value <math display=\"inline\"> p(x) \\ge y_0  </math> over <math> \nA \\subset \\mathbb{R}^n\n\n  </math>.\n\nThe above can also be extended to regions <math> A \\subset \\mathbb{R}^n\n  </math>defined by polynomial inequalities.\n\n== Sum-of-squares hierarchy ==\nThe sum-of-squares hierarchy (SOS hierarchy), also known as the Lasserre hierarchy, is a hierarchy of convex relaxations of increasing power and increasing computational cost. For each natural number <math display=\"inline\">d \\in \\mathbb{N}</math> the corresponding convex relaxation is known as the ''<math display=\"inline\">d</math>th level'' or ''<math display=\"inline\">d</math>th round of the SOS hierarchy.'' The <math display=\"inline\">1</math>st round, when <math display=\"inline\">d=1</math>, corresponds to a basic [[Semidefinite programming|semidefinite program]], or to sum-of-squares optimization over polynomials of degree at most <math>2</math>. To augment the basic convex program at the <math display=\"inline\">1</math>st level of the hierarchy to <math display=\"inline\">d</math>th level, additional variables and constraints are added to the program to have the program consider polynomials of degree at most <math>2d</math>. \n\nThe SOS hierarchy derives its name from the fact that the value of the objective function at the <math display=\"inline\">d</math>th level is bounded with a sum-of-squares proof using polynomials of degree at most <math display=\"inline\">2d</math> via the dual (see \"Duality\" above). Consequently, any sum-of-squares proof that uses polynomials of degree at most <math display=\"inline\">2d</math> can be used to bound the objective value, allowing one to prove guarantees on the tightness of the relaxation. \n\nIn conjunction with a theorem of Berg, this further implies that given sufficiently many rounds, the relaxation becomes arbitrarily tight on any fixed interval. Berg's result<ref>{{Cite journal|url = |title = The multidimensional moment problem and semigroups|last = Berg|first = Christian|date = 1987|journal = Proceedings of Symposia in Applied Mathematics|doi = |pmid = |access-date = |editor-last = Landau|editor-first = Henry J.}}</ref><ref>{{Cite journal|title = A Sum of Squares Approximation of Nonnegative Polynomials|url = http://epubs.siam.org/doi/abs/10.1137/070693709|journal = SIAM Review|date = 2007-01-01|issn = 0036-1445|pages = 651-669|volume = 49|issue = 4|doi = 10.1137/070693709|first = J.|last = Lasserre|arxiv = math/0412398}}</ref> states that every non-negative real polynomial within a bounded interval can be approximated within accuracy <math display=\"inline\">\\epsilon</math> on that interval with a sum-of-squares of real polynomials of sufficiently high degree, and thus if <math display=\"inline\">OBJ(x)</math> is the polynomial objective value as a function of the point <math display=\"inline\">x</math>, if the inequality <math display=\"inline\">c +\\epsilon - OBJ(x) \\ge 0</math> holds for all <math display=\"inline\">x</math> in the region of interest, then there must be a sum-of-squares proof of this fact. Choosing <math display=\"inline\">c</math> to be the minimum of the objective function over the feasible region, we have the result.\n\n=== Computational cost ===\nWhen optimizing over a function in <math display=\"inline\">n</math> variables, the <math display=\"inline\">d</math>th level of the hierarchy can be written as a semidefinite program over <math display=\"inline\">n^{O(d)}</math> variables, and can be solved in time <math display=\"inline\">n^{O(d)}</math> using the ellipsoid method. \n\n==Sum-of-squares background==\nA polynomial <math> p </math> is a ''sum of squares'' (''SOS'') if there exist polynomials <math> \\{f_i\\}_{i=1}^m </math>\nsuch that  <math> p = \\sum_{i=1}^m f_i^2 </math>.  For example,\n:<math>p=x^2 - 4xy + 7y^2</math>\nis a sum of squares since\n:<math> p = f_1^2 + f_2^2</math>\nwhere  \n:<math>f_1 = (x-2y)\\text{ and  }f_2 = \\sqrt{3}y.</math>\nNote that if <math> p </math> is a sum of squares\nthen <math>p(x) \\ge 0 </math> for all <math> x \\in \\R^n</math>. Detailed descriptions of [[polynomial SOS]] are available.<ref>Parrilo, P., (2000) ''Structured semidefinite programs and semialgebraic geometry\nmethods in robustness and optimization''. Ph.D. thesis, California\nInstitute of Technology.</ref><ref>\nParrilo, P. (2003) \"Semidefinite programming relaxations for semialgebraic\nproblems\". ''[[Mathematical Programming]]'' Ser. B 96 (2), 293–320.</ref><ref>\nLasserre, J. (2001) \"Global optimization with polynomials and the problem of\nmoments\". ''SIAM Journal on Optimization'', 11 (3), 796{817.</ref>\n\n[[Quadratic forms]] can be expressed as <math> p(x)=x^T Q x</math> where <math> Q </math> is a symmetric matrix.  Similarly, polynomials of degree&nbsp;≤&nbsp;2''d'' can be expressed as \n:<math> p(x)=z(x)^T Q z(x) ,</math>\nwhere the vector <math>z</math> contains all monomials of degree <math> \\le d </math>.  This is known as the [[Gram matrix]] form.  An important fact is that\n<math> p </math> is SOS if and only if there exists a symmetric and [[positive-semidefinite matrix]] <math> Q </math> such that <math>p(x)=z(x)^T Q z(x) </math>.\nThis provides a connection between SOS polynomials and positive-semidefinite matrices.\n\n== Software tools ==\n* [http://www.cds.caltech.edu/sostools/ SOSTOOLS], licensed under the [[GNU GPL]].  The reference guide is available at [[arxiv:1310.4716|arXiv:1310.4716 <nowiki>[</nowiki>math.OC<nowiki>]</nowiki>]].  \n* [https://github.com/JuliaOpt/SumOfSquares.jl SumOfSquares.jl].\n* For the dual problem of constrained polynomial optimization, [http://homepages.laas.fr/henrion/software/gloptipoly/ GloptiPoly] for MATLAB and [https://github.com/peterwittek/ncpol2sdpa Ncpol2sdpa] for Python.\n\n== References ==\n<references/>\n<!--- After listing your sources please cite them using inline citations and place them after the information they cite. Please see http://en.wikipedia.org/wiki/Wikipedia:REFB for instructions on how to add citations. --->\n\n[[Category:Mathematical optimization]]\n[[Category:Real algebraic geometry]]"
    },
    {
      "title": "Superiority and inferiority ranking method",
      "url": "https://en.wikipedia.org/wiki/Superiority_and_inferiority_ranking_method",
      "text": "{{Multiple issues|\n{{no footnotes|date=January 2009}}\n{{technical|date=January 2009}}\n{{context|date=January 2009}}\n}}\n\nThe '''superiority and inferiority ranking method''' (or '''SIR method''') is a [[Multiple-criteria_decision_analysis|multi-criteria decision making]] [[Scientific modelling|model]] ('''MCDA''') which can handle real [[data]] and provides six different preference structures for the [[system]] user.\n\n==Description==\nIt also incorporates outranking rationale to deal with the 'poor' true-criteria preference structure which appears in selecting proper equipment. The superiority and inferiority scores are produced through the generalized criteria. The SIR method can also analyze different criteria without compiling them into a small scale as GAs.\n\n==References==\n<!--- See [[Wikipedia:Footnotes]] on how to create references using <ref></ref> tags which will then appear here automatically -->\n{{Reflist|30em}}\n\n==Sources==\n* Tam CM,Tong TKL,Wong YW, (2004), Selection of Concrete Pump Using the Superiority and Inferiority Ranking Method, Journal of Construction Engineering and Management, Volume 130, Issue 6, pp.&nbsp;827&ndash;834 (November/December)\n* Free Multi-criteria Decision Aiding (MCDA) Tools for Research Students http://sites.google.com/site/mcdafreeware/\n\n[[Category:Conceptual models]]\n[[Category:Decision analysis]]\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis]]\n[[Category:Scientific modeling| ]]"
    },
    {
      "title": "Topological derivative",
      "url": "https://en.wikipedia.org/wiki/Topological_derivative",
      "text": "The '''topological derivative''' is, conceptually, a [[derivative]] of a shape functional with respect to infinitesimal changes in its topology, such as adding an infinitesimal hole or crack. When used in higher dimensions than one, the term '''topological gradient''' is also used to name the first-order term of the topological asymptotic expansion, dealing only with infinitesimal singular domain perturbations. It has applications in [[shape optimization]], [[topology optimization]], [[image processing]] and mechanical modeling.\n\n== Definition ==\n\nLet <math> \\Omega </math> be an open bounded domain of <math> \\mathbb{R}^d </math>, with <math> d \\geq 2 </math>, which is subject to a nonsmooth perturbation confined in a small region <math> \\omega_\\varepsilon(\\tilde{x}) = \\tilde{x} + \\varepsilon \\omega </math> of size <math> \\varepsilon </math> with <math> \\tilde{x} </math> an arbitrary point of <math> \\Omega </math> and <math> \\omega </math> a fixed domain of <math> \\mathbb{R}^d </math>. Let <math> \\Psi </math> be a characteristic function associated to the unperturbed domain and <math> \\Psi_\\varepsilon </math> be a characteristic function associated to the perforated domain <math> \\Omega_\\varepsilon = \\Omega \\backslash \\overline{\\omega_\\varepsilon} </math>. A given shape functional <math> \\Phi(\\Psi_\\varepsilon(\\tilde{x})) </math> associated to the topologically perturbed domain, admits the following '''topological asymptotic expansion''':\n\n<center><math> \\Phi(\\Psi_\\varepsilon(\\tilde{x})) = \\Phi(\\Psi) + f(\\varepsilon) g(\\tilde{x}) + o(f(\\varepsilon)) </math></center>\n\nwhere <math> \\Phi(\\Psi) </math> is the shape functional associated to the reference domain, <math> f(\\varepsilon) </math> is a positive first order correction function of <math> \\Phi(\\Psi) </math> and  <math> o(f(\\varepsilon)) </math> is the remainder. The function <math> g(\\tilde{x}) </math> is called the topological derivative of <math> \\Phi </math> at <math> \\tilde{x} </math>.\n\n== Applications ==\n\n=== Structural mechanics ===\nThe topological derivative can be applied to shape optimization problems in structural mechanics.<ref>J. Sokolowski and A. Zochowski, [http://hal.inria.fr/docs/00/07/35/18/PDF/RR-3170.pdf 44On topological derivative in shape optimization44], 1997</ref> The topological derivative can be considered as the singular limit of the shape derivative. It is a generalization of this classical tool in shape optimization.<ref>[http://www.lama.univ-savoie.fr/ANR-GAOS/CIRM2012/Conferences/Jan-LUMINY.pdf Topological Derivatives in Shape Optimization], Jan Sokołowski, May 28, 2012. Retrieved November 9, 2012</ref> Shape optimization concerns itself with finding an optimal shape. That is, find <math>\\Omega</math> to minimize some scalar-valued [[objective function]], <math>J(\\Omega)</math>. The topological derivative technique can be coupled with [[level-set method]].<ref>G. Allaire, F. Jouve, ''Coupling the level set method and the topological gradient in structural optimization'', in IUTAM symposium on topological design optimization of structures, machines and materials, M. Bendsoe et al. eds., pp3-12, Springer (2006).</ref>\n\nIn 2005, the topological asymptotic expansion for the [[Laplace equation]] with respect to the insertion of a short crack inside a plane domain had been found. It allows to detect and locate cracks for a simple model problem: the steady-state heat equation with the heat flux imposed and the temperature measured on the boundary.<ref>S. Amstutz, I. Horchani, and M. Masmoudi. ''[http://matwbn.icm.edu.pl/ksiazki/cc/cc34/cc3415.pdf Crack detection by the topological gradient method]''. Control and Cybernetics, 34(1):81–101, 2005.</ref> The topological derivative had been fully developed for a wide range of second-order differential operators and in 2011, it had been applied to [[Kirchhoff–Love plate theory|Kirchhoff plate bending problem]] with a fourth-order operator.<ref>S. Amstutz, A.A. Novotny, [http://www.univ-avignon.fr/fileadmin/documents/Users/Fiches_X_P/platesfi.pdf Topological asymptotic analysis of the Kirchhoff plate bending problem]. ESAIM: COCV 17(3), pp. 705-721, 2011</ref>\n\n{{Expand section|date=December 2011}}\n\n=== Image processing ===\nIn the field of image processing, in 2006, the topological derivative has been used to perform [[edge detection]] and [[image restoration]]. The impact of an insulating crack in the domain is studied. The topological sensitivity gives information on the image edges. The presented  algorithm is non-iterative and thanks to the use of spectral methods has a short computing time.<ref>L. J. Belaid, M. Jaoua, M. Masmoudi, and L. Siala. ''Image restoration and edge detection by topological asymptotic expansion''. CRAS Paris, 342(5):313–318, March 2006.</ref> Only <math>O(Nlog(N))</math> operations are needed to detect edges, where <math>N</math> is the number of pixels.<ref name=\"Image processing by topological asymptotic analysis\">D. Auroux and M. Masmoudi. ''Image processing by topological asymptotic analysis''. ESAIM: Proc. Mathematical methods for imaging and inverse problems, 26:24–44, April 2009.</ref> During the following years, other problems have been considered: classification, [[segmentation (image processing)|segmentation]], [[inpainting]] and [[super-resolution]].<ref name=\"Image processing by topological asymptotic analysis\"/><ref>D. Auroux, M. Masmoudi, and L. Jaafar Belaid. [http://math.unice.fr/~auroux/Work/Articles/16-CIMNE.pdf ''Image restoration and classification by topological asymptotic expansion''], pp. 23–42, Variational Formulations in Mechanics: Theory and Applications, E. Taroco, E.A. de Souza Neto and A.A. Novotny (Eds), CIMNE, Barcelona, Spain, 2007.</ref><ref>D. Auroux and M. Masmoudi. ''A one-shot inpainting algorithm based on the topological asymptotic analysis''. Computational and Applied Mathematics, 25(2-3):251–267, 2006.</ref><ref>D. Auroux and M. Masmoudi. ''Image processing by topological asymptotic expansion''. J. Math. Imaging Vision, 33(2):122–134, February 2009.</ref><ref name=larnier2012>S. Larnier, J. Fehrenbach and M. Masmoudi, [http://homepages.laas.fr/slarnier/The_topological_gradient_method_From_optimal_design_to_image_processing.pdf The topological gradient method: From optimal design to image processing], Milan Journal of Mathematics, vol. 80, issue 2, pp. 411–441, December 2012.</ref> This approach can be applied to gray-level or color images.<ref>D. Auroux, L. Jaafar Belaid, and B. Rjaibi. ''[http://math.unice.fr/~auroux/Work/Articles/DZ.pdf Application of the topological gradient method to color image restoration]''. SIAM J. Imaging Sci., 3(2):153–175, 2010.</ref> Until 2010, isotropic diffusion was used for image reconstructions. The topological gradient is also able to provide edge orientation and this information can be used to perform [[anisotropic diffusion]].<ref>S. Larnier and J. Fehrenbach. ''[http://homepages.laas.fr/slarnier/Edge_detection_and_anisotropic_diffusion_with_anisotropic_topological_gradient.pdf Edge detection and image restoration with anisotropic topological gradient]''. In 2010 IEEE [[International Conference on Acoustics, Speech, and Signal Processing]] (ICASSP), pages 1362–1365, March 2010.</ref>\n\nIn 2012, a general framework is presented to reconstruct an image <math> u \\in L^2(\\Omega) </math> given some noisy observations <math> Lu+n </math> in a Hilbert space <math> E </math> where <math> \\Omega </math> is the domain where the image <math> u </math> is defined.<ref name=larnier2012/> The observation space <math> E </math> depends on the specific application as well as the linear observation operator <math> L : L^2(\\Omega) \\rightarrow E </math>. The norm on the space <math> E </math> is <math> \\|.\\|_E </math>. The idea to recover the original image is to minimize the following functional for <math> u \\in H^1(\\Omega) </math>:\n<center><math>  \\| C^{1/2} \\nabla u \\|_{L^2(\\Omega)}^2 + \\|Lu-v\\|_E^2</math></center>\nwhere <math> C </math> is a positive definite tensor. The first term of the equation ensures that the recovered image <math> u </math> is regular, and the second term measures the discrepancy with the data.\nIn this general framework, different types of image reconstruction can be performed such as<ref name=larnier2012/>\n* [[image denoising]] with <math> E=L^2(\\Omega) </math> and <math> Lu=u </math>,\n* image denoising and deblurring with <math> E=L^2(\\Omega) </math> and <math> Lu=\\phi \\ast u </math> with <math> \\phi </math> a [[motion blur]] or [[Gaussian blur]],\n* [[inpainting|image inpainting]] with <math> E=L^2(\\Omega\\backslash\\omega) </math> and <math> Lu=u|_{\\Omega\\backslash\\omega} </math>, the subset <math> \\omega \\subset\\Omega </math> is the region where the image has to be recovered.\nIn this framework, the asymptotic expansion of the cost function <math> J_\\Omega(u_\\Omega) = \\frac{1}{2} \\int_\\Omega u_\\Omega^2 </math> in the case of a crack provides the same topological derivative <math>g(x,n) = - \\pi c (\\nabla u_0.n) (\\nabla p_0.n) - \\pi(\\nabla u_0.n)^2</math> where <math> n </math> is the normal to the crack and <math> c </math> a constant diffusion coefficient. The functions <math> u_0 </math> and <math> p_0 </math> are solutions of the following direct and adjoint problems.<ref name=larnier2012/>\n<center><math> -\\nabla ( c \\nabla u_0 ) + L^* L u_0 = L^* v</math> in <math>\\Omega</math> and <math> \\partial_n u_0 = 0</math> on <math>\\partial \\Omega</math> </center>\n<center><math> -\\nabla ( c \\nabla p_0 ) + L^* L p_0 = \\Delta u_0</math> in <math>\\Omega</math> and <math> \\partial_n p_0 = 0</math> on <math>\\partial \\Omega</math> </center>\nThanks to the topological gradient, it is possible to detect the edges and their orientation and to define an appropriate <math> C </math> for the image reconstruction process.<ref name=larnier2012/>\n\nIn image processing, the topological derivatives have also been studied in the case of a multiplicative noise of gamma law or in presence of Poissonian statistics.<ref>A. Drogoul, G. Aubert, [http://hal.archives-ouvertes.fr/docs/01/01/82/00/PDF/drogoul_aubert_Two_Column.pdf The topological gradient method for semi-linear problems and application to edge detection and noise removal.]</ref>\n\n=== Inverse problems ===\nIn 2009, the topological gradient method has been applied to [[tomographic reconstruction]].<ref>D. Auroux, L. Jaafar Belaid, and B. Rjaibi. ''[http://math.unice.fr/~auroux/Work/Articles/tamtam09.pdf Application of the topological gradient method to tomography]''. In ARIMA Proc. TamTam'09, 2010.</ref> The coupling between the topological derivative and the level set has also been investigated in this application.<ref>T. Rymarczyk, P. Tchórzewski, J. Sikora, [https://scholar.google.fr/scholar_url?hl=fr&q=http://www.thinkmind.org/download.php%3Farticleid%3Dadvcomp_2014_2_40_20085&sa=X&scisig=AAGBfm2yKjihVzWwJdrscxbau7m6cTVcQQ&oi=scholaralrt ''Topological Approach to Image Reconstruction in Electrical Impedance Tomography''], ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Science</ref>\n\n{{Expand section|date=December 2011}}\n\n== References ==\n{{Reflist}}\n\n== Books ==\nA. A. Novotny and J. Sokolowski, ''Topological derivatives in shape optimization'', Springer, 2013.\n\n== External links ==\n* Allaire and al. [http://www.cmap.polytechnique.fr/~jouve/papers/toplev.pdf Structural optimization using topological and shape sensitivity via a level set method]\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Topology optimization",
      "url": "https://en.wikipedia.org/wiki/Topology_optimization",
      "text": "'''Topology optimization ''' ('''TO''') is a mathematical method that optimizes material layout within a given design space, for a given set of loads, [[boundary conditions]] and constraints with the goal of maximizing the performance of the system. TO is different from [[shape optimization]] and sizing optimization in the sense that the design can attain any shape within the design space, instead of dealing with predefined configurations. \n\nThe conventional TO formulation uses a [[finite element method]] (FEM) to evaluate the design performance. The design is optimized using either gradient-based [[mathematical programming]] techniques such as the optimality criteria algorithm and the [[method of moving asymptotes]] or non gradient-based algorithms such as [[genetic algorithms]].\n\nTopology Optimization has a wide range of applications in aerospace, mechanical, bio-chemical and civil engineering. Currently, engineers mostly use TO at the concept level of a design process. Due to the free forms that naturally occur, the result is often difficult to manufacture. For that reason the result emerging from TO is often fine-tuned for manufacturability. Adding constraints to the formulation in order to [[design for manufacturability|increase the manufacturability]] is an active field of research. In some cases results from TO can be directly manufactured using [[additive manufacturing]]; TO is thus a key part of [[design for additive manufacturing]].\n\n== Problem statement ==\n\nA topology optimization problem can be written in the general form of an [[optimization problem]] as:\n\n: <math>\\begin{align}\n&\\underset{\\rho}{\\operatorname{minimize}} & &F = F(\\mathbf{u(\\rho), \\rho}) =  \\int_{\\Omega}  f(\\mathbf{u(\\rho), \\rho}) \\mathrm{d}V \\\\\n&\\operatorname{subject\\;to} \n& &G_0(\\rho) = \\int_{\\Omega} \\rho \\mathrm{d}V - V_0 \\leq 0 \\\\\n&&&G_j(\\mathbf{u}(\\rho), \\rho) \\leq 0 \\text{ with } j = 1, ..., m\n\\end{align}</math>\n\nThe problem statement includes the following:\n\n* An [[objective function]] <math>F(\\mathbf{u(\\rho), \\rho})</math>. This function represents the quantity that is being minimized for best performance. The most common objective function is compliance, where minimizing compliance leads to maximizing the stiffness of a structure.\n* The material distribution as a problem variable. This is described by the density of the material at each location <math> \\rho(\\mathbf{u}) </math>. Material is either present, indicated by a 1, or absent, indicated by a 0. <math> \\mathbf{u}</math> is a state field that satisfies a linear or nonlinear state equation.<ref>2</ref>\n* The design space <math> (\\Omega)</math>. This indicates the allowable volume within which the design can exist.  Assembly and packaging requirements, human and tool accessibility are some of the factors that need to be considered in identifying this space . With the definition of the design space, regions or components in the model that cannot be modified during the course of the optimization are considered as non-design regions.\n* <math>\\scriptstyle m </math> [[constraint (mathematics)|constraint]]s <math> G_j(\\mathbf{u}(\\rho), \\rho) \\leq 0 </math> a characteristic that the solution must satisfy. Examples are the maximum amount of material to be distributed (volume constraint) or maximum stress values.\n\nEvaluating <math> \\mathbf{u(\\rho)} </math> often includes solving a differential equation. This is most commonly done using the [[finite element method]] since these equations do not have a known analytical solution.\n\n== Implementation methodologies ==\nThere are various implementation methodologies that have been used to solve TO problems.\n\n=== Discrete ===\nSolving TO problems in a discrete sense is done by discretizing the design domain into finite elements. The material densities inside these elements are then treated as the problem variables. In this case material density of one indicates the presence of material, while zero indicates an absence of material. Owing to the attainable topological complexity of the design being dependent on the number of elements, a large number is preferred. Large numbers of finite elements increases the attainable topological complexity, but come at a cost. Firstly, solving the FEM system becomes more expensive. Secondly, algorithms that can handle a large number (several thousands of elements is not uncommon) of discrete variables with multiple constraints are unavailable. Moreover, they are impractically sensitive to parameter variations.<ref>Sigmund, O., Maute, K., ''[https://link.springer.com/article/10.1007/s00158-013-0978-6 Topology optimization approaches: A comparative review]''. Structural and Multidisciplinary Optimization, 2013, p. 1031-1055</ref> In literature problems with up to 30000 variables have been reported.<ref>Beckers, M. [http://empslocal.ex.ac.uk/people/staff/reverson/uploads/MoodSwings/beckers.pdf Topology optimization using a dual method with discrete variables]. Structural Optimization, p. 14-24</ref>\n\n=== Solving the problem with continuous variables ===\nThe earlier stated complexities with solving TO problems using binary variables has caused the community to search for other options. One is the modelling of the densities with continuous variables. The material densities can now also attain values between zero and one. Gradient based algorithms that handle large amounts of continuous variables and multiple constraints are available. But the material properties have to be modelled in a continuous setting. This is done through interpolation. One of the most implemented interpolation methodologies is the SIMP method (Solid Isotropic Material with Penalisation<ref>Bendsøe, MP. ''[https://www.researchgate.net/profile/Martin_Bendsoe/publication/226693813_Bendsoe_MP_Optimal_Shape_Design_as_a_Material_Distribution_Problem_Structural_Optimization_1_193-202/links/5410685f0cf2d8daaad3cbec/Bendsoe-MP-Optimal-Shape-Design-as-a-Material-Distribution-Problem-Structural-Optimization-1-193-202.pdf Optimal shape design as a material distribution problem].''. Structural Optimization, 1989, p. 193-202</ref>).<ref name=\"book\">[https://books.google.com/books?id=NGmtmMhVe2sC&source=gbs_navlinks_s], a monograph of the subject.</ref> This interpolation is essentially a power law <math> E \\;=\\; E_0 \\,+\\, \\rho^p (E_1 - E_0) </math>. It interpolates the Young's modulus of the material to the scalar selection field. The value of the penalisation parameter <math>p</math> is generally taken between <math> [1,\\, 3]</math>.  This has been shown to confirm the micro-structure of the materials.<ref name=\"Paper Inverse Homogenisation\">[http://www.giref.ulaval.ca/~deteix/bois/documents_references/bendsoe1999.pdf], A reference that proved the validity of the interpolation scheme.</ref> In the SIMP method a lower bound on the Young's modulus is added, <math> E_0 </math>, to make sure the derivatives of the objective function are non-zero when the density becomes zero. The higher the penalisation factor, the more SIMP penalises the algorithm in the use of non-binary densities. Unfortunately, the penalisation parameter also introduces non-convexities<ref>van Dijk, NP. Langelaar, M. van Keulen, F. ''[http://www1.dem.ist.utl.pt/engopt2010/Book_and_CD/Papers_CD_Final_Version/pdf/03/01270-01.pdf Critical study of design parameterization in topology optimization; The influence of design parameterization on local minima].''. 2nd International Conference on Engineering Optimization, 2010</ref>).\n\n=== Shape derivatives ===\n\n=== Topological derivatives ===\n\n=== Level set ===\n\n=== Phase field ===\n\n=== Evolutionary structural optimization ===\n\n=== Commercial software ===\nThere are several commercial topology optimization software on the market. Most of them use topology optimization as a hint how the optimal design should look like, and manual geometry re-construction is required. There are a few solutions which produce optimal designs ready for Additive Manufacturing.\n\n== Examples ==\n[[File:Checkerboards in Topology Optimization.tif|thumb|Checker Board Patterns are shown in this result]]\n[[File:Topology Optimization with filtereing.tif|thumb|Topology optimization result when filtering is used]]\n[[File:Cantilvr 3d etaopt gsf 050.png|thumb|Topology optimization of a compliance problem]]\n\n=== Structural compliance ===\n{{unsourced|section|date=December 2018}}\nA stiff structure is one that has the least possible displacement when given certain set of boundary conditions. A global measure of the displacements is the strain energy (also called compliance) of the structure under the prescribed boundary conditions. The lower the strain energy the higher the stiffness of the structure. So, the problem statement involves the objective functional of the strain energy which has to be minimized.\n\nOn a broad level, one can visualize that the more the material, the less the deflection as there will be more material to resist the loads. So, the optimization requires an opposing constraint, the volume constraint. This is in reality a cost factor, as we would not want to spend a lot of money on the material. To obtain the total material utilized, an integration of the selection field over the volume can be done.\n\nFinally the elasticity governing differential equations are plugged in so as to get the final problem statement.\n:<math>\\min_{\\rho}\\; \\int_{\\Omega} \\frac{1}{2} \\mathbf{\\sigma}:\\mathbf{\\varepsilon} \\,\\mathrm{d}\\Omega</math>\n\nsubject to:\n*<math> \\rho \\,\\in\\, [0,\\, 1] </math>\n*<math> \\int_{\\Omega} \\rho\\, \\mathrm{d}\\Omega \\;\\leq\\; V^*</math>\n*<math> \\mathbf{\\nabla}\\cdot\\mathbf{\\sigma} \\,+\\, \\mathbf{F} \\;=\\; {\\mathbf{0}} </math>\n*<math> \\mathbf{\\sigma} \\;=\\; \\mathsf{C}:\\mathbf{\\varepsilon}</math>\n\nBut, a straightforward implementation in the Finite Element Framework of such a problem is still infeasible owing to issues such as:\n# Mesh dependency—Mesh Dependency means that the design obtained on one mesh is not the one that will be obtained on another mesh. The features of the design become more intricate as the mesh gets refined.\n# Numerical instabilities—The selection of region in the form of a chess board.\n\nSome techniques such as Filtering based on Image Processing are currently being used to alleviate some of these issues.\n\n=== Multiphysics problems ===\n\n==== Fluid-structure-interaction ====\n[[Fluid–structure_interaction|Fluid-structure-interaction]] is a strongly coupled phenomenon and concerns the interaction between a stationary or moving fluid and an elastic structure. Many engineering applications and natural phenomena are subject to fluid-structure-interaction and to take such effects into consideration is therefore critical in the design of many engineering applications. Topology optimisation for fluid structure interaction problems has been studied in e.g. references<ref> Yoon GH (2010) [https://onlinelibrary.wiley.com/doi/abs/10.1002/nme.2777 Topology optimization for stationary fluid–structure interaction problems using a new monolithic formulation]. Int J Numer Methods Eng 82(5):591–616 </ref>,<ref>Picelli R, Vicente WM, Pavanello R (2017) [https://www.sciencedirect.com/science/article/pii/S0168874X1730015X Evolutionary topology optimization for structural compliance minimization considering design-dependent FSI loads]. Fin Elem Anal Des 135:44–55. ISSN 0168-874X </ref>,<ref>Jenkins N, Maute K (2016) [https://link.springer.com/article/10.1007/s00158-016-1467-5 An immersed boundary approach for shape and topology optimization of stationary fluid-structure interaction problems]. Struct Multidiscip Optim</ref> and<ref name=Lundgaard_FSI>Lundgaard, Christian, et al. \"[https://www.researchgate.net/profile/Christian_Lundgaard/publication/323126930_Revisiting_density-based_topology_optimization_for_fluid-structure-interaction_problems/links/5c0e447092851c39ebe25542/Revisiting-density-based-topology-optimization-for-fluid-structure-interaction-problems.pdf Revisiting density-based topology optimization for fluid-structure-interaction problems].\" Structural and Multidisciplinary Optimization (2018): 1-27.</ref>. Design solutions solved for different Reynolds numbers are shown below. The design solutions depend on the fluid flow with indicate that the coupling between the fluid and the structure is resolved in the design problems.\n\n{{multiple image\n | align = left\n\n | image1 = Fluid-Structure-Interaction-Topology-Optimization-1.png\n | width1 = 300\n | alt1 = \n | link1 = \n | caption1 = Design solution and velocity field for Re=1\n\n | image2 = Fluid-Structure-Interaction-Topology-Optimization-2.png\n | width2 = 300\n | alt2 = \n | link2 = \n | caption2  = Design solution and velocity field for Re=5\n\n | image3 = Fluid-structure-interaction-pressure-field-topology-optimization.png\n | width3 = 300\n | alt3 = \n | caption3  = Design solution and pressure field for Re=10\n\n | image4 = Fluid-structure-interaction-pressure-field-topology-optimization-4.png\n | width4 = 300\n | alt4 = \n | caption4  = Design solution and pressure field for Re=40 \n\n | footer = Design solutions for different Reynolds number for a wall inserted in a channel with a moving fluid.\n}}\n\n[[File:Wall-flow-problem-topology-optimization-for-fluid-structure-interaction-problems.png|thumb|Sketch of the well-known wall problem. The objective of the design problem is to minimize the structural compliance.]]\n\n[[File:Fluid-structure-interaction-design-evolution.gif|thumb|Design evolution for a fluid-structure-interaction problem from reference<ref name=Lundgaard_FSI />. The objective of the design problem is to minimize the structural compliance. The fluid-structure-interaction problem is modelled with Navier-Cauchy and Navier-Stokes equations.]]\n\n==== Thermoelectric energy conversion ====\n\n[[File:Design-sketch.png|thumb|A sketch of the design problem. The aim of the design problem is to spatially distribute two materials, Material A and Material B, to maximise a performance measure such as cooling power or electric power output]]\n\n[[File:Topology-optimization-off-diagonal-design-evolution.gif|thumb|Design evolution for an off-diagonal thermoelectric generator. The design solution of an optimisation problem solved for electric power output. The performance of the device has been optimised by distributing [[Skutterudite]] (yellow) and [[bismuth telluride]] (blue) with a density-based topology optimisation methodology. The aim of the optimisation problem is to maximise the electric power output of the thermoelectric generator.]]\n\n[[File:Evolution-design solution.gif|thumb|Design evolution for a thermoelectric cooler. The aim of the design problem is to maximise the cooling power of the thermoelectric cooler. ]]\n\n[[Thermoelectric_effect|Thermoelectricity]] is a multi-physic problem which concerns the interaction and coupling between electric and thermal energy in semi conducting materials. Thermoelectric energy conversion can be described by two separately identified effects: The Seebeck effect and the Peltier effect. The Seebeck effect concerns the conversion of thermal energy into electric energy and the Peltier effect concerns the conversion of electric energy into thermal energy<ref>Rowe, David Michael. [https://books.google.com/books?id=VvCb_deT4kIC&printsec=frontcover#v=onepage&q=Seebeck&f=false Thermoelectrics handbook: macro to nano]. CRC press, 2005.</ref>. By spatially distributing two thermoelectric materials in a two dimensional design space with a topology optimisation methodology<ref>Lundgaard, Christian, and Ole Sigmund. \"[https://www.researchgate.net/profile/Christian_Lundgaard/publication/323126361_A_density-based_topology_optimization_methodology_for_thermoelectric_energy_conversion_problems/links/5c0e440aa6fdcc494fe90597/A-density-based-topology-optimization-methodology-for-thermoelectric-energy-conversion-problems.pdf A density-based topology optimization methodology for thermoelectric energy conversion problems].\" Structural and Multidisciplinary Optimization 57.4 (2018): 1427-1442.</ref>, it is possible to exceed performance of the constitutive thermoelectric materials for [[Thermoelectric_cooling|thermoelectric coolers]] and [[Thermoelectric_generator|thermoelectric generators]]<ref>Lundgaard, Christian, Ole Sigmund, and Rasmus Bjørk. \"[https://www.researchgate.net/profile/Christian_Lundgaard/publication/323143969_Topology_optimization_of_segmented_thermoelectric_generators/links/5c0e437a4585157ac1b735f3/Topology-optimization-of-segmented-thermoelectric-generators.pdf Topology Optimisation of Segmented Thermoelectric Generators].\" Journal of Electronic Materials 47.12 (2018): 6959-6971.</ref>.\n\n===3F3D Form Follows Force 3D Printing===\nThe current proliferation of 3D printer technology has allowed designers and engineers to use topology optimization techniques when designing new products. Topology optimization combined with 3D printing can result in lightweighting, improved structural performance and shortened design-to-manufacturing cycle. As the designs, while efficient, might not be realisable with more traditional manufacturing techniques.{{citation needed|date=November 2018}}\n\n==References==\n{{Reflist}}\n\n==Further reading==\n*Investigation into Structural Topology Optimization Problem Formulations, William Renold, lulu.com, 2007.\n*[http://www.springerlink.com/content/t5732j08vk143274/ Recent Developments in the Commercial Implementation of Topology Optimization]; Uwe Schramm, Ming Zhou; IUTAM Symposium on Topological Design Optimization of Structures, Machines and Materials: Status and Perspectives, 239–248; 2006 Springer.\n*[http://www.springerlink.com/content/l317544685kr4263/?p=86d69fac23964a0aaccc6c10e08701aa&pi=3/ Industrial Implementation and Applications of Topology Optimization and Future Needs]; Claus B.W. Pedersen; Peter Allinger; IUTAM Symposium on Topological Design Optimization of Structures, Machines and Materials, 229-238; 2006 Springer.\n*[http://www.springerlink.com/content/a7653p3h70116666/ Topology optimization of 2D continua for minimum compliance using parallel computing] Arash Mahdavi; Balaji Raghavan; Mary Frecker; Int Journal of Structural and Multidisciplinary Optimization, Volume 32, 121-132, 2006 Springer\n*[http://vrand.com/node/48 Modern Structural Optimization Concepts Applied to Topology Optimization] Juan Pablo Leiva; Brian C. Watson and Iku Kosaka ; 40th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Material Conference. St. Louis, MO, pp.&nbsp;1589–1596, 1999\n\n==External links==\n* [http://www.caess.eu/site/Software-Animations.html Topology optimization animations]\n\n{{DEFAULTSORT:Topology Optimization}}\n[[Category:Mathematical optimization]]\n[[Category:Topology]]\n[[Category:Construction]]\n[[Category:Structural engineering]]\n[[Category:3D printing]]"
    },
    {
      "title": "TOPSIS",
      "url": "https://en.wikipedia.org/wiki/TOPSIS",
      "text": "{{technical|date=April 2018}}\nThe '''Technique for Order of Preference by Similarity to Ideal Solution''' ('''TOPSIS''') is a [[multi-criteria decision analysis]] method, which was originally developed by Ching-Lai Hwang and Yoon in 1981<ref name='HwangandYoon1981'>{{cite book | last1 = Hwang | first1 = C.L. | last2 = Yoon | first2 = K. | title = Multiple Attribute Decision Making: Methods and Applications | publisher = Springer-Verlag | year = 1981 | location = New York }}</ref> with further developments by Yoon in 1987,<ref name='Yoon'>{{cite journal | last1 = Yoon | first1 = K. | title = A reconciliation among discrete compromise situations | journal = Journal of the Operational Research Society | year = 1987 | volume = 38 | issue = 3 | pages = 277–286 | doi=10.1057/jors.1987.44}}</ref> and Hwang, Lai and Liu in 1993.<ref name='HwangLaiLiu'>{{cite journal | last1 = Hwang | first1 = C.L. | last2 = Lai | first2 = Y.J. | last3 = Liu | first3 = T.Y. | title = A new approach for multiple objective decision making | journal = Computers and Operational Research | year = 1993 | volume = 20 | issue = 8 | pages = 889–899 | doi=10.1016/0305-0548(93)90109-v}}</ref> \nTOPSIS is based on the concept that the chosen alternative should have the shortest geometric distance from the positive ideal solution (PIS)<ref name=\"indjst.org\">Assari, A., Mahesh, T., & Assari, E. (2012b). [http://www.indjst.org/index.php/indjst/article/viewFile/30378/26306 Role of public participation in sustainability of historical city: usage of TOPSIS method]. Indian Journal of Science and Technology, 5(3), 2289-2294.</ref> and the longest geometric distance from the negative ideal solution (NIS).<ref name=\"indjst.org\"/>\n\n==Description==\nIt is a method of compensatory aggregation that compares a set of alternatives by identifying weights for each criterion, normalising scores for each criterion and calculating the geometric distance between each alternative and the ideal alternative, which is the best score in each criterion. An assumption of TOPSIS is that the criteria are [[Monotonic function|monotonically]] increasing or decreasing. \n[[Normalization (statistics)|Normalisation]] is usually required as the parameters or criteria are often of incongruous dimensions in multi-criteria problems.<ref name='YoonandHwang1995'>{{cite book | last1 = Yoon | first1 = K.P. | last2 = Hwang | first2 = C. | title = Multiple Attribute Decision Making: An Introduction | publisher = SAGE publications | year = 1995 | location = California }}</ref><ref name='Zavadskas'>{{cite journal | last1 = Zavadskas | first1 = E.K. | last2 = Zakarevicius | first2 = A. | last3 = Antucheviciene | first3 = J.| title = Evaluation of Ranking Accuracy in Multi-Criteria Decisions | journal = Informatica | year = 2006 | volume = 17 | number = 4 | pages = 601–618 }}</ref> Compensatory methods such as TOPSIS allow trade-offs between criteria, where a poor result in one criterion can be negated by a good result in another criterion. This provides a more realistic form of modelling than non-compensatory methods, which include or exclude alternative solutions based on hard cut-offs.<ref name='Greene'>{{cite journal | last1 = Greene | first1 = R. | last2 = Devillers | first2 = R. | last3 = Luther | first3 = J.E. | last4 = Eddy | first4 = B.G. | title = GIS-based multi-criteria analysis | journal = Geography Compass | year = 2011 | volume = 5/6 | issue = 6 | pages = 412–432 | doi = 10.1111/j.1749-8198.2011.00431.x }}</ref> An example of application on nuclear power plants is provided in.<ref>{{Cite journal|last=Locatelli|first=Giorgio|last2=Mancini|first2=Mauro|date=2012-09-01|title=A framework for the selection of the right nuclear power plant|journal=International Journal of Production Research|volume=50|issue=17|pages=4753–4766|doi=10.1080/00207543.2012.657965|issn=0020-7543}}</ref>\n\n==TOPSIS method==\n\nThe TOPSIS process is carried out as follows:\n\n;Step 1: Create an evaluation matrix consisting of m alternatives and n criteria, with the intersection of each alternative and criteria given as <math>x_{ij}</math>, we therefore have a matrix <math>( x_{ij} )_{m \\times n}</math>.\n\n;Step 2: The matrix <math>( x_{ij} )_{m \\times n}</math> is then normalised to form the matrix\n\n:: <math>R = ( r_{ij} )_{m \\times n}</math>, using the normalisation method \n:: <math> r_{ij} = \\frac  {x_{ij}} {\\sqrt{\\sum_{k=1}^m x_{kj}^2 }}, \\quad i = 1, 2, \\ldots, m, \\quad j = 1, 2, \\ldots, n</math>\n\n;Step 3: Calculate the weighted normalised decision matrix\n:: <math> t_{ij}= r_{ij}\\cdot w_j, \\quad i=1,2,\\ldots,m, \\quad j=1,2,\\ldots,n</math>\n\n:where <math>w_j = W_j \\Big/ \\sum_{k=1}^n W_k, j = 1, 2, \\ldots, n </math> so that <math> \\sum_{i=1}^n w_i = 1</math>, and <math>W_j</math> is the original weight given to the indicator <math>v_j, \\quad j = 1, 2, \\ldots, n.</math>\n\n;Step 4: Determine the worst alternative <math>(A_w)</math> and the best alternative <math>(A_b)</math>:\n\n:: <math> A_w = \\{ \\langle \\max(t_{ij} \\mid i = 1,2,\\ldots,m) \\mid j \\in J_- \\rangle, \\langle \\min(t_{ij} \\mid i = 1,2,\\ldots,m) \\mid j \\in J_+ \\rangle \\rbrace \\equiv \\{ t_{wj} \\mid j= 1,2,\\ldots,n \\rbrace, </math>\n\n:: <math> A_b = \\{ \\langle \\min(t_{ij} \\mid i = 1,2,\\ldots,m) \\mid j \\in J_- \\rangle, \\langle \\max(t_{ij} \\mid i = 1,2,\\ldots,m) \\mid j \\in J_+ \\rangle \\rbrace \\equiv \\{ t_{bj} \\mid j= 1,2,\\ldots,n \\rbrace, </math>\n\n:where,\n\n:: <math> J_+ = \\{ j = 1,2,\\ldots,n \\mid j\\}</math> associated with the criteria having a positive impact, and\n\n:: <math> J_- = \\{ j = 1,2,\\ldots,n \\mid j\\}</math> associated with the criteria having a negative impact.\n\n;Step 5: Calculate the L<sup>2</sup>-distance between the target alternative <math>i</math> and the worst condition <math>A_w</math>\n\n:: <math> d_{iw} = \\sqrt{\\sum_{j=1}^n (t_{ij} - t_{wj})^2}, \\quad i = 1, 2, \\ldots, m, </math>\n\n: and the distance between the alternative <math>i</math> and the best condition <math>A_b</math>\n\n:: <math> d_{ib} = \\sqrt{\\sum_{j=1}^n (t_{ij} - t_{bj})^2}, \\quad i = 1, 2, \\ldots , m </math>\n\n:where <math>d_{iw}</math> and <math>d_{ib}</math> are L<sup>2</sup>-norm distances from the target alternative <math>i</math> to the worst and best conditions, respectively.\n\n;Step 6: Calculate the similarity to the worst condition:\n:: <math> s_{iw}= d_{iw} / (d_{iw} + d_{ib}), \\quad 0 \\le s_{iw} \\le 1, \\quad i = 1, 2, \\ldots , m. </math>\n\n:: <math>s_{iw} = 1</math> if and only if the alternative solution has the best condition; and\n\n:: <math>s_{iw} = 0</math> if and only if the alternative solution has the worst condition.\n\n;  Step 7: Rank the alternatives according to <math>s_{iw} \\,\\, (i = 1, 2, \\ldots, m).</math>\n\n==Normalisation==\nTwo methods of normalisation that have been used to deal with incongruous criteria dimensions are linear normalisation and vector normalisation.\n\nLinear normalisation can be calculated as in Step 2 of the TOPSIS process above. Vector normalisation was incorporated with the original development of the TOPSIS method,<ref name='HwangandYoon1981' /> and is calculated using the following formula:\n\n: <math> r_{ij} = \\frac  {x_{ij}} {\\sqrt{\\sum_{k=1}^m x_{kj}^2 }}, \\quad i = 1, 2, \\ldots, m, \\quad j = 1, 2, \\ldots, n</math>\n\nIn using vector normalisation, the non-linear distances between single dimension scores and ratios should produce smoother trade-offs.<ref name='Huang2011'>{{cite journal | last1 = Huang | first1 = I.B. | last2 = Keisler | first2 = J. | last3 = Linkov | first3 = I. | title = Multi-criteria decision analysis in environmental science: ten years of applications and trends | journal = Science of the Total Environment | year = 2011 | volume = 409 | issue = 19 | pages = 3578–3594 | doi=10.1016/j.scitotenv.2011.06.022}}</ref>\n\n== Online tools ==\n* [https://decision-radar.com/ Decision Radar] : A free online TOPSIS calculator written in [[Python (programming language)|Python]].\n*{{cite journal |last1=Yadav |first1=Vinay |last2=Karmakar |first2=Subhankar |last3=Kalbar |first3=Pradip P. |last4=Dikshit |first4=A.K. |title=PyTOPS: A Python based tool for TOPSIS |journal=SoftwareX |date=January 2019 |volume=9 |pages=217–222 |doi=10.1016/j.softx.2019.02.004 }}\n\n==References==\n{{Reflist}}\n\n[[Category:Decision analysis]]\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis]]\n[[Category:Utility]]"
    },
    {
      "title": "Trajectory optimization",
      "url": "https://en.wikipedia.org/wiki/Trajectory_optimization",
      "text": "'''Trajectory optimization''' is the process of designing a [[trajectory]] that [[Mathematical optimization|minimizes]] (or maximizes) some measure of performance while satisfying a set of constraints. Generally speaking, trajectory optimization is a technique for computing an open-loop solution to an [[optimal control]] problem. It is often used for systems where computing the full closed-loop solution is either impossible or impractical.\n\nAlthough the idea of trajectory optimization has been around for hundreds of years ([[calculus of variations]], [[Brachistochrone curve|brachystochrone problem]]), it only became practical for real-world problems with the advent of the computer. Many of the original applications of trajectory optimization were in the aerospace industry, computing rocket and missile launch trajectories. More recently, trajectory optimization has also been used in a wide variety of industrial process and robotics applications.\n\n==History==\nTrajectory optimization first showed up in 1697, with the introduction of the Brachystochrone problem: find the shape of a wire such that a bead sliding along it will move between two points in the minimum time.<ref name = \"Willems1997\">''300 Years of Optimal Control: From The Brachystochrone to the Maximum Principle'', Hector J. Sussmann and Jan C. Willems. IEEE Control Systems, 1997.</ref> The interesting thing about this problem is that it is optimizing over a curve (the shape of the wire), rather than a single number. The most famous of the solutions was computed using [[calculus of variations]].\n\nIn the 1950s, the digital computer started to make trajectory optimization practical for solving real-world problems. The first optimal control approaches grew out of the [[calculus of variations]], based on the research of [[Gilbert Ames Bliss]] and Bryson<ref>Bryson, Ho,Applied Optimal Control, Blaisdell Publishing Company, 1969, p 246.</ref> in America, and [[Pontryagin]]<ref>L.S. Pontyragin, The Mathematical Theory of Optimal Processes, New York, Intersciences, 1962</ref> in Russia. [[Pontryagin's maximum principle]]<ref name = \"Ross\">[[I. Michael Ross|Ross, I. M.]] ''A Primer on Pontryagin's Principle in Optimal Control'', Collegiate Publishers, San Francisco, 2009.</ref> is of particular note. These early researchers created the foundation of what we now call indirect methods for trajectory optimization.\n\nMuch of the early work in trajectory optimization was focused on computing rocket thrust profiles, both in a vacuum and in the atmosphere. This early research discovered many basic principles that are still used today. \nAnother successful application was the climb to altitude trajectories for the early jet aircraft.  Because of the high drag associated with the transonic drag region and the low thrust of early jet aircraft, trajectory optimization was the key to maximizing climb to altitude performance.  Optimal control based trajectories were responsible for some of the world records.  In these situations, the pilot followed a Mach versus altitude schedule based on optimal control solutions.\n\nOne of the important early problems in trajectory optimization was that of the [[Singular control|singular arc]], where [[Pontryagin's maximum principle]] fails to yield a complete solution. An example of a problem with singular control is the optimization of the thrust of a missile flying at a constant altitude and which is launched at low speed.  Here the problem is one of a [[bang-bang control]] at maximum possible thrust until the singular arc is reached.  Then the solution to the singular control provides a lower variable thrust until burnout.  At that point bang-bang control provides that the control or thrust go to its minimum value of zero.  This solution is the foundation of the boost-sustain rocket motor profile widely used today to maximize missile performance.\n\n==Applications==\n\nThere are a wide variety of applications for trajectory optimization, primarily in robotics: industry, manipulation, walking, path-planning, and aerospace. It can also be used for modeling and estimation.\n\n===Quadrotor helicopters===\n\nTrajectory optimization is often used to compute trajectories for [[Quadcopter|quadrotor helicopters]]. These applications typically used highly specialized algorithms.\n<ref>Daniel Mellinger and Vijay Kumar, \"Minimum snap trajectory generation and control for quadrotors\" International Conference on Robotics and Automation, IEEE 2011\n</ref>\n<ref>Markus Hehn and Raffaello D'Andrea, \"Real-Time Trajectory Generation for Quadrocopters\" IEEE Transactions on Robotics, 2015.\n</ref>\nOne interesting application shown by the [http://www.kumarrobotics.org/research/ U.Penn GRASP Lab] is computing a trajectory that allows a quadrotor to fly through a hoop as it is thrown. Another, this time by the [http://flyingmachinearena.org/research/ ETH Zurich Flying Machine Arena],  involves two quadrotors tossing a pole back and forth between them, with it balanced like an inverted pendulum.\n\n===Manufacturing===\n\nTrajectory optimization is used in manufacturing, particularly for controlling chemical processes (such as in \n<ref>\nJohn W. Eaton and James B. Rawlings. \"Model-Predictive Control of Chemical Processes\" Chemical Engineering Science, Vol 47, No 4. 1992.\n</ref>\n) or computing the desired path for robotic manipulators (such as in\n<ref>T. Chettibi, H. Lehtihet, M. Haddad, S. Hanchi, \"Minimum cost trajectory planning for industrial robots\" European Journal of Mechanics, 2004.\n</ref>\n).\n\n===Walking robots===\n\nThere are a variety of different applications for trajectory optimization within the field of walking robotics. For example, one paper used trajectory optimization of bipedal gaits on a simple model to show that walking is energetically favorable for moving at a low speed and running is energetically favorable for moving at a high speed.\n<ref>Manoj Srinivasan and Andy Ruina. \"Computer optimization of a minimal biped model discovers walking and running\" Nature, 2006.\n</ref>\nLike in many other applications, trajectory optimization can be used to compute a nominal trajectory, around which a stabilizing controller is built.\n<ref>E.R. Westervelt, J.W. Grizzle, and D.E. Koditschek. \"Hybrid Zero Dynamics of PLanar Biped Walkers\" IEEE Transactions on Automatic Control, 2003.\n</ref>\nTrajectory optimization can be applied in detailed motion planning complex humanoid robots, such as [[Atlas (robot)|Atlas]].\n<ref>Michael Posa, Scott Kuindersma, and Russ Tedrake. \"Optimization and stabilization of trajectories for constrained dynamical systems.\" International Conference on Robotics and Automation, IEEE 2016.\n</ref>\nFinally, trajectory optimization can be used for path-planning of robots with complicated dynamics constraints, using reduced complexity models.\n<ref>Hongkai Dai, Andres Valenzuela, and Russ Tedrake. \"Whole-body motion planning with Centroidal Dynamics and Full Kinematics\" International Conference on Humanoid Robots, IEEE 2014.\n</ref>\n\n===Aerospace===\nFor [[tactical missile]]s, the flight profiles are determined by the thrust and [[load factor (aeronautics)|lift]] histories.  These histories can be controlled by a number of means including such techniques as using an [[angle of attack]] command history or an altitude/downrange schedule that the missile must follow.  Each combination of missile design factors, desired missile performance, and system constraints results in a new set of optimal control parameters.<ref>Phillips, C.A, \"Energy Management for a Multiple Pulse Missile\", AIAA Paper 88-0334, Jan., 1988</ref>\n\n==Terminology==\n\n;Decision variables\n: The set of unknowns to be found using optimization.\n\n;Trajectory optimization problem\n: A special type of optimization problem where the decision variables are functions, rather than real numbers.\n\n;[[Mathematical optimization|Parameter optimization]]\n: Any optimization problem where the decision variables are real numbers.\n\n;[[Nonlinear programming|Nonlinear program]]\n: A class of constrained parameter optimization where either the objective function or constraints are nonlinear.\n\n;Indirect method\n: An indirect method for solving a trajectory optimization problem proceeds in three steps: 1) Analytically construct the necessary and sufficient conditions for optimality, 2) Discretize these conditions, constructing a constrained parameter optimization problem, 3) Solve that optimization problem.<ref name=Betts2010>\nJohn T. Betts  \"Practical Methods for Optimal Control and Estimation Using Nonlinear Programming\" SIAM Advances in Design and Control, 2010.\n</ref>\n\n;Direct method\n: A direct method for solving a trajectory optimization problem consists of two steps: 1) Discretize the trajectory optimization problem directly, converting it into a constrained parameter optimization problem, 2) Solve that optimization problem.<ref name=Betts2010 />\n\n;Transcription\n: The process by which a trajectory optimization problem is converted into a parameter optimization problem. This is sometimes referred to as discretization. Transcription methods generally fall into two categories: shooting methods and collocation methods.\n\n;[[Shooting method]]\n: A transcription method that is based on simulation, typically using explicit Runge--Kutta schemes.\n\n;[[Collocation method]] (Simultaneous Method)\n: A transcription method that is based on function approximation, typically using implicit Runge--Kutta schemes.\n\n;[[Pseudo-spectral method|Pseudospectral method]] (Global Collocation)\n: A transcription method that represents the entire trajectory as a single high-order orthogonal polynomial.\n\n;Mesh (Grid)\n: After transcription, the formerly continuous trajectory is now represented by a discrete set of points, known as mesh points or grid points.\n\n;Mesh refinement\n: The process by which the discretization mesh is improved by solving a sequence of trajectory optimization problems. Mesh refinement is either performed by sub-dividing a trajectory segment or by increasing the order of the polynomial representing that segment.<ref>Christopher L. Darby, William W. Hager, and Anil V. Rao. \"An hp-adaptive pseudospectral method for solving optimal control problems.\" Optimal Control Applications and Methods, 2010.</ref>\n\n;Multi-phase trajectory optimization problem \n: Trajectory optimization over a system with [[Hybrid system|hybrid dynamics]] can be achieved by posing it as a multi-phase trajectory optimization problem. This is done by composing a sequence of standard trajectory optimization problems that are connected using constraints.<ref name=GPOPSII>{{Cite journal|title = GPOPS-II: A MATLAB Software for Solving Multiple-Phase Optimal Control Problems Using hp-Adaptive Gaussian Quadrature Collocation Methods and Sparse Nonlinear Programming|url = http://doi.acm.org/10.1145/2558904|journal = ACM Trans. Math. Softw.|date = 2014-10-01|issn = 0098-3500|pages = 1:1–1:37|volume = 41|issue = 1|doi = 10.1145/2558904|first = Michael A.|last = Patterson|first2 = Anil V.|last2 = Rao}}</ref>\n\n==Trajectory optimization techniques==\n\nThe techniques to any [[optimization (mathematics)|optimization problems]] can be divided into two categories: indirect and direct. An indirect method works by analytically constructing the necessary and sufficient conditions for optimality, which are then solved numerically. A direct method attempts a direct numerical solution by constructing a sequence of continually improving approximations to the optimal solution.<ref name=Betts2010 /> Direct and indirect methods can be blended by an application of the [[covector mapping principle]] of [[I. Michael Ross|Ross]] and [[Fariba Fahroo|Fahroo]].<ref name=\"ReviewPOC\">[[I. Michael Ross|I. M. Ross]] and M. Karpenko, \"A Review of Pseudospectral Optimal Control: From Theory to Flight,\" Annual Reviews in Control, Vol. 36, pp. 182-197, 2012.</ref>\n\nThe optimal control problem is an infinite-dimensional optimization problem, since the decision variables are functions, rather than real numbers. All solution techniques perform transcription, a process by which the trajectory optimization problem (optimizing over functions) is converted into a constrained parameter optimization problem (optimizing over real numbers). Generally, this constrained parameter optimization problem is a non-linear program, although in special cases it can be reduced to a [[Quadratic programming|quadratic program]] or [[Linear programming|linear program]].\n\n===Single shooting===\nSingle shooting is the simplest type of trajectory optimization technique. The basic idea is similar to how you would aim a cannon: pick a set of parameters for the trajectory, simulate the entire thing, and then check to see if you hit the target. The entire trajectory is represented as a single segment, with a single constraint, known as a defect constraint, requiring that the final state of the simulation match the desired final state of the system. Single shooting is effective for problems that are either simple or have an extremely good initialization. Both the indirect and direct formulation tend to have difficulties otherwise.<ref name=Betts2010 /><ref name=Betts1998>Survey of Numerical Methods for Trajectory Optimization; John T. Betts \nJournal of Guidance, Control, and Dynamics 1998; 0731-5090 vol.21 no.2 (193-207)\n</ref>\n<ref name=Rao2009>Anil V. Rao \"A survey of numerical methods for optimal control\" Advances in Astronautical Sciences, 2009.</ref>\n\n===Multiple shooting===\nMultiple shooting is a simple extension to single shooting that renders it far more effective. Rather than representing the entire trajectory as a single simulation (segment), the algorithm breaks the trajectory into many shorter segments, and a defect constraint is added between each. The result is large sparse non-linear program, which tends to be easier to solve than the small dense programs produced by single shooting.<ref name=Betts1998 /><ref name=Rao2009 />\n\n===Direct collocation===\nDirect collocation methods work by approximating the state and control trajectories using polynomial [[Spline (mathematics)|splines]]. These methods are sometimes referred to as direct transcription. '''Trapezoidal collocation''' is a commonly used low-order direct collocation method. The dynamics, path objective, and control are all represented using linear splines, and the dynamics are satisfied using [[Trapezoidal rule|trapezoidal quadrature]]. '''Hermite-Simpson Collocation''' is a common medium-order direct collocation method. The state is represented by a [[Cubic Hermite spline|cubic-Hermite spline]], and the dynamics are satisfied using [[Simpson's rule|Simpson quadrature]].<ref name=Betts2010 /><ref name=Rao2009 />\n\n===Orthogonal collocation===\nOrthogonal collocation is technically a subset of direct collocation, but the implementation details are so different that it can reasonably be considered its own set of methods. Orthogonal collocation differs from direct collocation in that it typically uses high-order splines, and each segment of the trajectory might be represented by a spline of a different order. The name comes from the use of orthogonal polynomials in the state and control splines.<ref name=Rao2009 /><ref name=Rao2014>Camila C. Francolin, David A. Benson, William W. Hager, Anil V. Rao. \"Costate Estimation in Optimal Control Using Integral Gaussian Quadrature Orthogonal Collocation Methods\" Optimal Control Applications and Methods, 2014.</ref>\n\n===Pseudospectral collocation===\nPseudospectral collocation, also known as global collocation, is a subset of orthogonal collocation in which the entire trajectory is represented by a single high-order orthogonal polynomial. As a side note: some authors use orthogonal collocation and pseudospectral collocation interchangeably. When used to solve a trajectory optimization problem whose solution is smooth, a pseudospectral method will achieve [http://www.scholarpedia.org/article/Spectral_methods spectral] (exponential) convergence.<ref name=ApprxTheoryApprxPractice>Lloyd N. Trefethen. \"Approximation Theory and Approximation Practice\", SIAM 2013</ref>\n\n===Differential dynamic programming===\n[[Differential dynamic programming]], is a bit different than the other techniques described here. In particular, it does not cleanly separate the transcription and the optimization. Instead, it does a sequence of iterative forward and backward passes along the trajectory. Each forward pass satisfies the system dynamics, and each backward pass satisfies the optimality conditions for control. Eventually, this iteration converges to a trajectory that is both feasible and optimal.<ref name=DDP>David H. Jacobson, \nDavid Q. Mayne. \"Differential Dynamic Programming\" Elsevier, 1970.</ref>\n\n==Comparison of techniques==\nThere are many techniques to choose from when solving a trajectory optimization problem. There is no best method, but some methods might do a better job on specific problems. This section provides a rough understanding of the trade-offs between methods.\n\n===Indirect vs. direct methods===\nWhen solving a trajectory optimization problem with an indirect method, you must explicitly construct the adjoint equations and their gradients. This is often difficult to do, but it gives an excellent accuracy metric for the solution. Direct methods are much easier to set up and solve, but do not have a built-in accuracy metric.<ref name=Betts2010 /> As a result, direct methods are more widely used, especially in non-critical applications. Indirect methods still have a place in specialized applications, particularly aerospace, where accuracy is critical.\n\nOne place where indirect methods have particular difficulty is on problems with path inequality constraints. These problems tend to have solutions for which the constraint is partially active. When constructing the adjoint equations for an indirect method, the user must explicitly write down when the constraint is active in the solution, which is difficult to know a priori. One solution is to use a direct method to compute an initial guess, which is then used to construct a multi-phase problem where the constraint is prescribed. The resulting problem can then be solved accurately using an indirect method.<ref name=Betts2010 />\n\n===Shooting vs. collocation===\nSingle shooting methods are best used for problems where the control is very simple (or there is an extremely good initial guess). For example, a satellite mission planning problem where the only control is the magnitude and direction of an initial impulse from the engines.<ref name=Betts1998 />\n\nMultiple shooting tends to be good for problems with relatively simple control, but complicated dynamics. Although path constraints can be used, they make the resulting nonlinear program relatively difficult to solve.\n\nDirect collocation methods are good for problems where the accuracy of the control and the state are similar. These methods tend to be less accurate then others (due to their low-order), but are particularly robust for problems with difficult path constraints.\n\nOrthogonal collocation methods are best for obtaining high-accuracy solutions to problems where the accuracy of the control trajectory is important. Some implementations have trouble with path constraints. These methods are particularly good when the solution is smooth.\n\n===Mesh refinement: h vs. p===\n\nIt is common to solve a trajectory optimization problem iteratively, each time using a discretization with more points. A '''h-method''' for mesh refinement works by increasing the number of trajectory segments along the trajectory, while a '''p-method''' increases the order of the transcription method within each segment.\n\nDirect collocation methods tend to exclusively use h-method type refinement, since each method is a fixed order. Shooting methods and orthogonal collocation methods can both use h-method and p-method mesh refinement, and some use a combination, known as hp-adaptive meshing. It is best to use h-method when the solution is non-smooth, while a p-method is best for smooth solutions.<ref name=GPOPSII />\n\n==Software==\nExamples of trajectory optimization programs include:\n* [http://apmonitor.com/wiki/ APMonitor]: Large-scale optimization software based on orthogonal collocation.\n* [https://www.astos.de/products/astos/ ASTOS]: Analysis, Simulation and Trajectory Optimization Software for Space Applications. The ASTOS software is a multi-purpose tool for space applications. Originally designed for trajectory optimization, it provides now modules for a variety of analysis, simulation and design capabilities\n* [http://bocop.org Bocop - The optimal control solver]: Open source toolbox for optimal control problems (user friendly and advanced GUI for efficient use).\n* [https://esa.github.io/pykep/ PyKEP], [https://esa.github.io/pygmo/ PyGMO] (Open Source, from the European Space Agency for interplanetary trajectory optimization)\n* Copernicus Trajectory Design and Optimization System [http://www.nasa.gov/centers/johnson/copernicus/]\n*[[DIDO (optimal control)|DIDO]]\n*[http://spaceworkssoftware.com/quickshot/ QuickShot]: A general-purpose, multi-threaded 3-DOF/4-DOF trajectory simulation tool for robust global optimization from [[SpaceWorks Enterprises|SpaceWorks Enterprises, Inc.]]<ref>{{Cite web|url=https://www.sbir.gov/sbirsearch/detail/873385|title=Innovative Aeropropulsion Technology for Future Military Assets {{!}} SBIR.gov|website=www.sbir.gov|language=en|access-date=2017-04-04}}</ref><ref>{{Cite web|url=http://www.phoenix-int.com/resources/webinars/2016/Analysis-and-Parametric-Assessment-of-Hypersonic-Research-Vehicle-Design-Reference-Missions-using-QuickShot.php|title=Analysis And Parametric Assessment Of Hypersonic Research Vehicle Design Reference Missions Using QuickShot {{!}} Phoenix Integration|website=www.phoenix-int.com|access-date=2017-04-04}}</ref><ref>{{Cite news|url=http://spaceworkseng.com/spaceworks-enterprises-inc-awarded-phase-2-sbir-from-afrl-to-further-the-development-of-quickshot-trajectory-tool/|title=SpaceWorks Enterprises Inc. Awarded Phase-2 SBIR from AFRL to Further the Development of QuickShot Trajectory Tool|date=2015-08-24|work=SpaceWorks|access-date=2017-04-04|language=en-US}}</ref>\n* [http://www.sim.informatik.tu-darmstadt.de/en/res/sw/dircol/ DIRCOL]: A general-purpose trajectory optimization software based on direct collocation.\n* [http://drake.mit.edu Drake]: A planning, control, and analysis toolbox for nonlinear dynamical systems. \n* [http://www.falcon-m.com FALCON.m]: The FSD Optimal Control Tool for Matlab, developed at the Institute of Flight System Dynamics of Technical University of Munich.\n* [[General Mission Analysis Tool]]\n* [[GPOPS-II]] ('''G'''eneral '''P'''urpose '''OP'''timal Control '''S'''oftware) Solves multi-phase trajectory optimization problems. (Matlab)<ref name=GPOPSII />\n* [http://hampath.org HamPath]: On solving optimal control problems by indirect and path following methods (Matlab and Python interfaces).\n* [[JModelica.org]] (Modelica-based open source platform for dynamic optimization)\n* [https://www.astos.de/products/lotos LOTOS] (Low-Thrust Orbit Transfer Trajectory Optimization Software) from Astos Solutions\n* [http://www.midaco-solver.com MIDACO] Optimization software particularly developed for interplanetary space trajectories. (Avail. in Matlab, Octave, Python, C/C++, R and Fortran)\n* [https://openocl.org OpenOCL] Open Optimal Control Library, optimal control modeling library, automatic differentiation, non-linear optimization, Matlab/Octave.  \n* OTIS (Optimal Trajectories by Implicit Simulation) [http://otis.grc.nasa.gov/background.html]\n* POST (Program to Optimize Simulated Trajectories) [https://post2.larc.nasa.gov/], [http://www.sierraengineering.com/Post3d/post3d.html]\n* [https://github.com/MatthewPeterKelly/OptimTraj OptimTraj]: An open-source trajectory optimization library for Matlab\n* ZOOM, Conceptual Design and Analysis of Rocket Configurations and Trajectories) [http://trajectorysolution.com/ZOOM%20Program.html]\n* PSOPT, an open source optimal control software package written in C++ that uses direct collocation methods [http://www.psopt.org/]\n* [https://github.com/istellartech/OpenGoddard OpenGoddard] An open source optimal control software package written in Python that uses pseudospectral methods.\n* [http://help.agi.com/stk/#gator/astrogator.htm Systems Tool Kit Astrogator (STK Astrogator)]: A specialized analysis module for orbit maneuver and space trajectory design. Astrogator offers orthogonal-collocation-based trajectory optimization using high-fidelity force models. \n* [https://github.com/Rapid-Design-of-Systems-Laboratory/beluga beluga]: An open source Python package for trajectory optimization using indirect methods.\n\nA collection of low thrust trajectory optimization tools, including members of the Low Thrust Trajectory Tool (LTTT) set, can be found here: [http://www.grc.nasa.gov/WWW/InSpace/LTTT LTTT Suite Optimization Tools].\n\n==References==\n<references/>\n\n[[Category:Ballistics]]\n[[Category:Mathematical optimization]]\n[[Category:Aerospace engineering]]\n[[Category:Aerodynamics]]"
    },
    {
      "title": "Variational Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Variational_Monte_Carlo",
      "text": "In [[computational physics]], '''variational Monte Carlo (VMC)''' is a [[quantum Monte Carlo]] method that applies the [[Variational method (quantum mechanics)|variational method]] to approximate the [[ground state]] of a quantum system.\n\nThe basic building block is a generic [[wave function]] <math>| \\Psi(a) \\rangle </math> depending on some parameters <math> a </math>.  \nThe optimal values of the parameters <math> a </math> is then found upon minimizing the total energy of the system.\n\nIn particular, given the [[Hamiltonian (quantum mechanics)|Hamiltonian]] <math> \\mathcal{H} </math>, and denoting with <math> X </math> a [[Many-body problem|many-body]] configuration,  the [[expectation value]] of the energy can be written as :\n\n<math> E(a) = \\frac{\\langle \\Psi(a) | \\mathcal{H} | \\Psi(a) \\rangle} {\\langle \\Psi(a) |  \\Psi(a) \\rangle } = \\frac{\\int | \\Psi(X,a) | ^2 \\frac{\\mathcal{H}\\Psi(X,a)}{\\Psi(X,a)} \\, dX} { \\int | \\Psi(X,a)|^2 \\, dX}. </math>\n\nFollowing the [[Monte Carlo method]] for evaluating [[integral]]s, we can interpret <math> \\frac{ | \\Psi(X,a) | ^2 } { \\int | \\Psi(X,a) | ^2 \\, dX } </math> as a [[probability distribution]] function, sample it, and evaluate the energy expectation value <math> E(a) </math> as the average of the so-called local energy <math>E_{\\textrm{loc}}(X)  = \\frac{\\mathcal{H}\\Psi(X,a)}{\\Psi(X,a)} </math>.  Once <math> E(a) </math> is known for a given set of variational parameters <math> a </math>, then optimization is performed in order to minimize the energy and obtain the best possible representation of the ground-state wave-function.\n\nVMC is no different from any other variational method, except that the many-dimensional integrals are evaluated numerically.  Monte Carlo integration is particularly crucial in this problem since the dimension of the many-body Hilbert space, comprising all the possible values of the configurations <math> X </math>, typically grows exponentially with the size of the physical system. Other approaches to the numerical evaluation of the energy expectation values would therefore, in general, limit applications to much smaller systems than those analyzable thanks to the Monte Carlo approach.\n\nThe accuracy of the method then largely depends on the choice of the variational state. The simplest choice typically corresponds to a [[Mean field theory|mean-field]] form, where the state <math> \\Psi </math> is written as a factorization over the Hilbert space. This particularly simple form is typically not very accurate since it neglects many-body effects.  \nOne of the largest gains in accuracy over writing the wave function separably comes from the introduction of the so-called Jastrow factor. In this case the wave function is written as <math> \\Psi(X) = \\exp(\\sum{u(r_{ij})})</math>, where <math> r_{ij} </math> is the distance between a pair of quantum particles and <math> u(r) </math> is a variational function to be determined.  \nWith this factor, we can explicitly account for particle-particle correlation, but the many-body integral becomes unseparable, so Monte Carlo is the only way to evaluate it efficiently.  In chemical systems, slightly more sophisticated versions of this factor can obtain 80&ndash;90% of the correlation energy (see [[electronic correlation]]) with less than 30 parameters.  In comparison, a configuration interaction calculation may require around 50,000 parameters to reach that accuracy, although it depends greatly on the particular case being considered.  In addition, VMC usually scales as a small power of the number of particles in the simulation, usually something like ''N''<sup>2&minus;4</sup> for calculation of the energy expectation value, depending on the form of the wave function.\n\n== Wave function optimization in VMC ==\n\nQMC calculations crucially depend on the quality of the trial-function, and so it is essential to have an optimized wave-function as close as possible to the ground state.\nThe problem of function [[Optimization (mathematics)|optimization]] is a very important research topic in numerical simulation. In QMC, in addition to the usual difficulties to find the minimum of multidimensional parametric function, the statistical noise is present in the estimate of the cost function (usually the energy), and its derivatives, required for an efficient optimization.\n\nDifferent cost functions and different strategies were used to optimize a many-body trial-function. Usually three cost functions were used in QMC optimization energy, variance or a linear combination of them.  The variance optimization method has the advantage that the exact wavefunction's variance is known.  (Because the exact wavefunction is an eigenfunction of the Hamiltonian, the variance of the local energy is zero).  This means that variance optimization is ideal in that it is bounded by below, it is positive defined and its minimum is known.  Energy minimization may ultimately prove more effective, however, as different authors recently showed that the energy optimization is more effective than the variance one.\n\nThere are different motivations for this: first, usually one is interested in the lowest energy rather than in the lowest variance in both variational and diffusion Monte Carlo; second, variance optimization takes many iterations to optimize determinant parameters and often the optimization can get stuck in multiple local minimum and it suffers of the \"false convergence\" problem; third energy-minimized wave functions on average yield more accurate values of other expectation values than variance minimized wave functions do.\n\nThe optimization strategies can be divided into three categories. The first strategy is based on correlated sampling together with deterministic optimization methods. Even if this idea yielded very accurate results for the first-row atoms, this procedure can have problems if parameters affect the nodes, and moreover density ratio of the current and initial trial-function increases exponentially with the size of the system. In the second strategy one use a large bin to evaluate the cost function and its derivatives in such way that the noise can be neglected and deterministic methods can be used.\n\nThe third approach, is based on an iterative technique to handle directly with noise functions. The first example of these methods is the so-called Stochastic Gradient Approximation (SGA), that was used also for structure optimization. Recently an improved and faster approach of this kind was proposed the so-called Stochastic Reconfiguration (SR) method.\n\n==See also==\n* [[Time-dependent variational Monte Carlo]] : an extension of the variational Monte Carlo to study the dynamics of [[pure quantum state]]s.\n\n== References ==\n* [http://prola.aps.org/abstract/PR/v138/i2A/pA442_1] W. L. McMillan, Phys. Rev. '''138''', A442 (1965)\n* [http://link.aps.org/abstract/PRB/v16/p3081] D. Ceperley, G. V. Chester and M. H. Kalos, Phys. Rev. B '''16''', 3081 (1977)\n* Wave-function optimization in VMC\n** [http://link.aip.org/link/%3FJCPSA6/115/1166/1] M. Snajdr. and S. M. Rothstein., J. Chem. Phys. '''112''', 4935 (2000) \n** [https://arxiv.org/abs/physics/0110003] D. Bressanini ''et al.'', J. Chem. Phys. '''116''', 5345 (2002)\n** [http://link.aps.org/doi/10.1103/PhysRevLett.60.1719] J. W. Wilkins C. J. Umrigar and K. G. Wilson, Phys. Rev. Lett. '''60''', 1719 (1988)\n** [http://prola.aps.org/abstract/PRB/v59/i19/p12344_1] P. R. C. Kent, R. J. Needs and G. Rajagopal, Phys. Rev. B, '''59''', 12344 (1999)\n** [https://arxiv.org/abs/physics/9911005] X. Lin, H. Zhang and A. M. Rappe, J. Chem. Phys., '''112''', 2650 (2000)\n** [http://prola.aps.org/abstract/PRL/v79/i7/p1173_1] A. Harju, B. Barbiellini, S. Siljamaki, R. M. Nieminen and G. Ortiz,  Phys. Rev. Lett. '''79''', 1173 (1997)\n** [https://aip.scitation.org/doi/10.1063/1.466885]<!--<ref>{{Cite journal|last=Tanaka|first=Shigenori|date=February 1994|title=Structural optimization in variational quantum Monte Carlo|url=https://aip.scitation.org/doi/10.1063/1.466885|journal=The Journal of Chemical Physics|volume=100|pages=7416|doi=10.1063/1.466885|via=}}</ref>--> S. Tanaka, J. Chem. Phys., '''100''', 7416 (1994)\n** [https://arxiv.org/abs/cond-mat/0409644] M. Casula, C. Attaccalite and S. Sorella,  J. Chem. Phys. '''121''', 7110 (2004)\n** [http://link.aps.org/doi/10.1103/PhysRevB.72.085124] N. D. Drummond and R. J. Needs, Phys. Rev. B '''72''', 085124 (2005).\n\n[[Category:Quantum chemistry]]\n[[Category:Quantum Monte Carlo]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Vector optimization",
      "url": "https://en.wikipedia.org/wiki/Vector_optimization",
      "text": "'''Vector optimization''' is a subarea of [[mathematical optimization]] where [[Optimization problem|optimization problems]] with a vector-valued [[objective function]]s are optimized with respect to a given [[partial ordering]] and subject to certain constraints.  A [[multi-objective optimization]] problem is a special case of a vector optimization problem: The objective space is the finite dimensional [[Euclidean space]] partially ordered by the component-wise \"less than or equal to\" ordering. \n\n== Problem formulation ==\nIn mathematical terms, a vector optimization problem can be written as:\n:<math>C\\operatorname{-}\\min_{x \\in S} f(x)</math>\nwhere <math>f: X \\to Z</math> for a partially ordered [[vector space]] <math>Z</math>. The partial ordering is induced by a cone <math>C \\subseteq Z</math>. <math>X</math> is an arbitrary set and <math>S \\subseteq X</math> is called the feasible set.\n\n== Solution concepts ==\nThere are different minimality notions, among them:\n* <math>\\bar{x} \\in S</math> is a ''weakly efficient point'' (weak minimizer) if for every <math>x \\in S</math> one has <math>f(x) - f(\\bar{x}) \\not\\in -\\operatorname{int} C</math>.\n* <math>\\bar{x} \\in S</math> is an ''efficient point'' (minimizer) if for every <math>x \\in S</math> one has <math>f(x) - f(\\bar{x}) \\not\\in -C \\backslash \\{0\\}</math>.\n* <math>\\bar{x} \\in S</math> is a ''properly efficient point'' (proper minimizer) if <math>\\bar{x}</math> is a weakly efficient point with respect to a [[closure (mathematics)|closed]] [[convex cone|pointed convex cone]] <math>\\tilde{C}</math> where <math>C \\backslash \\{0\\} \\subseteq \\operatorname{int} \\tilde{C}</math>.\n\nEvery proper minimizer is a minimizer.  And every minimizer is a weak minimizer.<ref name=\"scalar2vector\">{{Cite journal | last1 = Ginchev | first1 = I. | last2 = Guerraggio | first2 = A. | last3 = Rocca | first3 = M. | title = From Scalar to Vector Optimization | doi = 10.1007/s10492-006-0002-1 | journal = Applications of Mathematics | volume = 51 | pages = 5 | year = 2006 | pmid =  | pmc = | url = https://irinsubria.uninsubria.it/bitstream/11383/1500550/1/am51-5-GinI-GueA-RocM-06.pdf }}</ref>\n\nModern solution concepts not only consists of minimality notions but also take into account [[infimum]] attainment.<ref name=\"Lohne\">{{cite book|title=Vector Optimization with Infimum and Supremum|author=Andreas Löhne|publisher=Springer|year=2011|isbn=9783642183508}}</ref>\n\n== Solution methods ==\n* [[Benson's algorithm]] for ''linear'' vector optimization problems.<ref name=\"Lohne\">{{cite book|title=Vector Optimization with Infimum and Supremum|author=Andreas Löhne|publisher=Springer|year=2011|isbn=9783642183508}}</ref>\n\n== Relation to multi-objective optimization ==\nAny multi-objective optimization problem can be written as\n:<math>\\mathbb{R}^d_+\\operatorname{-}\\min_{x \\in M} f(x)</math>\nwhere <math>f: X \\to \\mathbb{R}^d</math> and <math>\\mathbb{R}^d_+</math> is the non-negative [[orthant]] of <math>\\mathbb{R}^d</math>.  Thus the minimizer of this vector optimization problem are the [[Pareto efficient]] points.\n\n== References ==\n{{Reflist}}\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "VIKOR method",
      "url": "https://en.wikipedia.org/wiki/VIKOR_method",
      "text": "{{multiple issues|\n{{cleanup reorganize|date=May 2016}}\n{{lead rewrite|date=May 2016}}\n{{manual|date=May 2016}}\n{{prose|date=May 2016}}\n{{technical|date=April 2018}}\n}}\nThe '''VIKOR method''' is a [[multi-criteria decision making]] (MCDM) or [[multi-criteria decision analysis]] method. It was originally developed by Serafim Opricovic to solve decision problems with conflicting and noncommensurable (different units) criteria, assuming that [[compromise]] is acceptable for conflict resolution, the decision maker wants a solution that is the closest to the ideal, and the alternatives are evaluated according to all established criteria.  VIKOR ranks alternatives and determines the solution named compromise that is the closest to the ideal.\n\nThe idea of compromise solution was introduced in MCDM by Po-Lung Yu in 1973,<ref>Po Lung Yu (1973) \"A Class of Solutions for Group Decision Problems\", Management Science, 19(8), 936–946.</ref> and by Milan Zeleny.<ref>Milan Zelrny (1973) \"Compromise Programming\", in Cochrane J.L. and M.Zeleny (Eds.), Multiple Criteria Decision Making, University of South Carolina Press, Columbia.</ref>\n\nS. Opricovic had developed the basic ideas of VIKOR in his Ph.D. dissertation in 1979, and an application was published in 1980.<ref>Lucien Duckstein and Serafim Opricovic (1980) \"Multiobjective Optimization in River  Basin Development\", Water Resources Research, 16(1), 14–20.</ref> The name VIKOR appeared in 1990 <ref>Serafim Opricović., (1990) \"Programski paket VIKOR za visekriterijumsko kompromisno rangiranje\", SYM-OP-IS</ref> from Serbian: VIseKriterijumska Optimizacija I Kompromisno Resenje, that means: Multicriteria Optimization and Compromise Solution, with pronunciation: vikor. The real applications were presented in 1998.<ref>Serafim Opricovic (1998) “Multicriteria Optimization in Civil Engineering\" (in Serbian), Faculty of Civil Engineering, Belgrade, 302 p. {{ISBN|86-80049-82-4}}.</ref> The paper in 2004 contributed to the international recognition of the VIKOR method.<ref>Serafim Opricovic and Gwo-Hshiung Tzeng (2004) \"The Compromise solution by MCDM methods: A comparative analysis of VIKOR and [[TOPSIS]]\", European Journal of Operational Research, 156(2), 445–455.</ref> (The most cited paper in the field of Economics, Science Watch, Apr.2009).\n\nThe MCDM problem is stated as follows: Determine the best (compromise) solution in multicriteria sense from the set of J feasible alternatives A1, A2, …AJ, evaluated according to the set of n criterion functions. The input data are the elements fij of the performance (decision) matrix, where fij is the value of the ''i''-th criterion function for the alternative Aj.\n\n==VIKOR method steps==\nThe VIKOR procedure has the following steps:\n\nStep 1. Determine the best fi* and the worst fi^ values of all criterion functions, i = 1,2,...,n;\nfi* = max (fij,j=1,…,J),   fi^ = min (fij,j=1,…,J), if the i-th function is benefit;\nfi* = min (fij,j=1,…,J),   fi^ = max (fij,j=1,…,J), if the i-th function is cost.\n\nStep 2. Compute the values  Sj  and  Rj, j=1,2,...,J, by the relations:\nSj=sum[wi(fi* - fij)/(fi*-fi^),i=1,…,n],  weighted and normalized [[Manhattan distance]];\nRj=max[wi(fi* - fij)/(fi*-fi^),i=1,…,n],, weighted and normalized [[Chebyshev distance]];\nwhere  wi are the weights of criteria, expressing the DM’s preference as the relative importance of the criteria.\n\nStep 3. Compute the values  Qj, j=1,2,…,J, by the relation\nQj = v(Sj – S*)/(S^ - S*) + (1-v)(Rj-R*)/(R^-R*)\nwhere S* = min (Sj, j=1,...,J),  S^ = max (Sj , j=1,…,J),  R* = min (Rj, j=1,...,J),  R^ = max (Rj , j=1,…,J),; and   is introduced as a weight for the strategy of maximum group utility, whereas 1-v is the weight of the individual regret. These strategies could be compromised by v = 0.5, and here v is modified as   = (n + 1)/ 2n (from v + 0.5(n-1)/n = 1) since the criterion (1 of n) related to R is included in S, too.\n\nStep 4.  Rank the alternatives, sorting by the values S, R and Q, from the minimum value. The results are three ranking lists.\n\nStep 5. Propose as a compromise solution the alternative A(1) which is the best ranked by the measure Q (minimum) if the following two conditions are satisfied:\nC1. “Acceptable Advantage”:  Q(A(2) – Q(A(1)) >= DQ\nwhere: A(2) is the alternative with second position in the ranking list by Q; \nDQ = 1/(J-1).\nC2. “Acceptable Stability in decision making”:\nThe alternative A(1) must also be the best ranked by S or/and R. This compromise solution is stable within a decision making process, which could be the strategy of maximum group utility (when v > 0.5 is needed), or “by consensus” v about 0.5, or  “with veto” v < 0.5).\nIf one of the conditions is not satisfied, then a set of compromise solutions is proposed, which consists of:\n- Alternatives A(1) and A(2) if only the condition C2 is not satisfied, or\n- Alternatives A(1), A(2),..., A(M) if the condition C1 is not satisfied; A(M) is determined by the relation Q(A(M)) – Q(A(1)) < DQ for maximum M (the positions of these alternatives are “in closeness”).\n\nThe obtained compromise solution could be accepted by the decision makers because it provides a maximum utility of the majority (represented by min S), and a minimum individual regret of the opponent (represented by min R). The measures S and R are integrated into Q for compromise solution, the base for an agreement established by mutual concessions.\n\n==Comparative analysis==\nA comparative analysis of MCDM methods VIKOR, [[TOPSIS]], [[ELECTRE]] and [[PROMETHEE]] is presented in the paper in 2007, through the discussion of their distinctive features and their application results.<ref>Serafim Opricovic and Gwo-Hshiung Tzeng (2007) \"Extended VIKOR Method in Comparison with Outranking Methods\", European Journal of Operational Research, Vol. 178, No 2, pp. 514–529.</ref>\nSayadi et. al. extended the VIKOR method for decision making with interval data.<ref>{{cite journal | url = http://www.sciencedirect.com/science/article/pii/S0307904X08001558 | doi=10.1016/j.apm.2008.06.002 | volume=33 | title=Extension of VIKOR method for decision making problem with interval numbers | journal=Applied Mathematical Modelling | pages=2257–2262}}</ref>\nHeydari et al. extende this method for solving  Multiple Objective Large-Scale Nonlinear Programming problems.<ref>http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=8114143&fileId=S0399055910000119</ref>\n\n==Fuzzy VIKOR method==\nThe Fuzzy VIKOR method has been developed to solve problem in a fuzzy environment where both criteria and weights could be [[fuzzy sets]]. The triangular fuzzy numbers are used to handle imprecise numerical quantities. Fuzzy VIKOR is based on the aggregating fuzzy merit that represents distance of an alternative to the ideal solution. The fuzzy operations and procedures for ranking fuzzy numbers are used in developing the fuzzy VIKOR algorithm.\n<ref>Serafim Opricovic (2011) \"Fuzzy VIKOR with an application to water resources planning\", Expert Systems with Applications 38, pp. 12983–12990.</ref>\n\n==See also==\n* [[Rank reversals in decision-making]]\n* [[Multi-criteria decision analysis]]\n* [[Pairwise comparison]]\n\n==References==\n{{reflist}}\n\n[[Category:1973 establishments]]\n[[Category:Decision analysis]]\n[[Category:Decision-making]]\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis]]"
    },
    {
      "title": "Wald's maximin model",
      "url": "https://en.wikipedia.org/wiki/Wald%27s_maximin_model",
      "text": "In [[decision theory]] and [[game theory]], '''[[Abraham Wald|Wald's]] [[Minimax#Maximin|maximin]] model''' is a non-probabilistic decision-making model according to which decisions are ranked on the basis of their worst-case outcomes – the optimal decision is one with the least worst outcome. It is one of the most important models in [[robust decision making]] in general and [[robust optimization]] in particular.\n\nIt is also known by a variety of other titles, such as Wald's maximin rule, Wald's maximin principle, Wald's maximin paradigm, and Wald's maximin criterion. Often '[[minimax]]' is used instead of 'maximin'.\n\n==Definition==\nWald's generic maximin model is as follows:\n\n:<math>v^{*}:= \\max_{d\\in D}\\min_{s\\in S(d)}f(d,s)</math>\nwhere <math>D</math> denotes the decision space; <math>S(d)</math> denotes the set of states associated with decision <math>d</math> and <math>f(d,s)</math> denotes the payoff (outcome) associated with decision <math>d</math> and state <math>s</math>.\n\nThis model represents a 2-person game in which the <math>\\max</math> player plays first. In response, the second player selects  the worst state in <math>S(d)</math>, namely a state in <math>S(d)</math> that minimizes the payoff <math>f(d,s)</math> over <math>s</math> in <math>S(d)</math>. In many applications the second player represents uncertainty. However, there are maximin models that are completely deterministic.\n\nThe above model is the ''classic'' format of Wald's maximin model. There is an equivalent [[Optimization (mathematics)|mathematical programming]] (MP) format:\n\n:<math>v^{*}:= \\max_{d\\in D,\\,z\\in \\mathbb{R}} \\{z: z \\le f(d,s),\\forall s\\in S(d)\\}</math>\n\nwhere <math>\\mathbb{R}</math> denotes the real line.\n\nAs in [[game theory]], the worst payoff associated with decision <math>d</math>, namely\n\n: <math>v(d):= \\min_{s\\in S(d)} f(d,s)\\ , \\ d \\in D</math>\n\nis called ''the security level'' of decision <math>d</math>.\n\nThe minimax version of the model is obtained by exchanging the positions of the <math>\\max</math> and <math>\\min</math>   operations in the classic format:\n\n:<math>v^{\\circ}:= \\min_{d\\in D}\\max_{s\\in S(d)}f(d,s).</math>\n\nThe equivalent MP format is as follows:\n\n:<math>v^{\\circ}:= \\min_{d\\in D,\\,z\\in \\mathbb{R}} \\{z: z \\ge f(d,s),\\forall s\\in S(d)\\}</math>\n\n==History==\nInspired by maximin models of game theory, [[Abraham Wald]] developed this model in the early 1940s <ref name=\"wald39\">Wald, A. (1939).  Contributions to the theory of statistical estimation and testing hypotheses. ''The Annals of Mathematics,'' 10(4), 299-326.</ref><ref name=\"wald45\">Wald, A. (1945).  Statistical decision functions which minimize the maximum risk. ''The Annals of Mathematics,'' 46(2), 265-280.</ref><ref name=\"wald50\">Wald, A.  (1950). ''Statistical Decision Functions,'' John Wiley, NY.</ref> as an approach to situations in which there is only one player (the decision maker). The second player represents a pessimistic (worst case) approach to uncertainty. In Wald's maximin model, player 1 (the <math>\\max</math> player) plays first and player 2 (the <math>\\min</math> player) knows player 1's decision when he selects his decision. This is a major simplification of the [[Two-person zero-sum game|classic 2-person zero-sum game]] in which the two players choose their strategies without knowing the other player's choice. The game of Wald's maximin model is also a 2-person [[zero-sum game]], but the players choose sequentially.\n\nWith the establishment of modern decision theory in the 1950s, the model became a key ingredient in the formulation of non-probabilistic decision-making models in the face of severe uncertainty.<ref name=\"resnik\">Resnik, M.D. (1987). ''Choices: an Introduction to Decision Theory,''   University of Minnesota Press, Minneapolis.</ref><ref name=\"french\">French, S. (1986). ''Decision Theory: An Introduction to the Mathematics of Rationality,'' Ellis Horwood, Chichester.</ref> It is widely used in diverse fields such as [[decision theory]], [[control theory]], [[economics]], [[statistics]], [[robust optimization]], [[operations research]], [[Maximin (philosophy)|philosophy]], etc.<ref name=\"ms07\">Sniedovich, M. (2007).  The art and science of modeling decision-making under severe uncertainty. ''Decision Making in Manufacturing and Services,''  1(1-2), 111-136.</ref><ref name=\"ms08\">Sniedovich, M. (2008). Wald's maximin model: a treasure in disguise! ''Journal of Risk Finance,'' 9(3), 287-91.</ref>\n\n==Example==\nOne of the most famous examples of a Maximin/Minimax model is\n\n: <math>\\min_{x\\in \\mathbb{R}} \\max_{y\\in \\mathbb{R}}\\ \\{x^{2} - y^{2}\\}</math>\n\nwhere <math>\\mathbb{R}</math> denotes the real line. Formally we can set <math>D=S(d)=\\mathbb{R}</math> and <math>f(d,s)=d^{2}-s^{2}</math>. The picture is this\n\n[[Image:Saddle point.png|400px]]\n\nThe optimal solution is the  (red) [[saddle point]]  <math>(x,y)=(0,0)</math>.\n\n==Decision tables==\nThere are many cases where it is convenient to 'organize' the Maximin/Minimax model as a 'table'. The convention is that the rows of the table represent the decisions, and the columns represent the states.\n\n===Example===\nHenri is going for a walk. The sun may shine, or it may rain. Should Henri carry an umbrella? Henri does not like carrying an umbrella, but he dislikes getting wet even more. His \"[[payoff matrix]]\", viewing this as a Maximin game pitting Henri against Nature, is as follows.\n\n{| class=\"wikitable\" align=\"left\"\n !\n ! &nbsp; &nbsp; Sun &nbsp; &nbsp;\n ! &nbsp;&nbsp; Rain &nbsp;&nbsp;\n |-\n ! No umbrella\n | <center>5</center>\n | <center>&minus;9</center>\n |-\n ! Umbrella\n | <center>1</center>\n | <center>&minus;5</center>\n |}\n\n{{Clear}}\nAppending a ''Worst Payoff''&nbsp;  column and a ''Best Worst Payoff''&nbsp; column to the payoff table, we obtain\n\n{| class=\"wikitable\" align=\"left\"\n !\n ! &nbsp; &nbsp; Sun &nbsp; &nbsp;\n ! &nbsp;&nbsp; Rain &nbsp;&nbsp;\n ! Worst Payoff\n ! Best Worst Payoff\n |-\n ! No umbrella\n | <center>5</center>\n | <center>&minus;9</center>\n | <center>&minus;9</center>\n | \n |-\n ! Umbrella\n | <center>1</center>\n | <center>&minus;5</center>\n | <center>&minus;5</center>\n | <center>&minus;5</center>\n |}\n{{Clear}}\nThe worst case, if Henri goes out without umbrella, is definitely worse than the (best) worst case when carrying an umbrella. Therefore, Henri takes his umbrella with him.\n\n==Variations on a theme==\nOver the years a variety of related models have been developed primarily to moderate the pessimistic approach dictated by the worst-case orientation of the model.<ref name=\"resnik\" /><ref name=\"french\" /><ref name=\"kouvelis\">Kouvelis P, and Yu G. (1997).  ''Robust Discrete Optimization and Its Applications,''  Kluwer, Boston.</ref><ref name=\"ben-tal09\">Ben-Tal, A,  El Gaoui, L, Nemirovski, A. (2009). ''Robust Optimization.''  Princeton University Press, Princeton.</ref><ref name=\"sim04\">Bertsimas D, and Sim, M. (2004). The price of robustness. ''Operations Research,''  52(1), 35-53.</ref> For example,\n\n===Savage's minimax regret===\n[[Leonard Jimmie Savage|Savage's]] [[Minimax regret|minimax regret model]]<ref name=\"savage51\">Savage, L. (1951). The theory of statistical decision. ''Journal of the American Statistical Association,'' 46, 55–67.</ref> is an application of Wald's minimax model to the 'regrets' associated with the payoffs. It can be formulated as follows:\n\n: <math>\\min_{d\\in D}\\max_{s\\in S} r(d,s)</math>\n\nwhere\n\n: <math>r(d,s):= \\max_{d\\,'\\in D} f(d\\,',s) - f(d,s)</math>\n\nis the regret of payoff <math>f(d,s)</math> associated with the (decision,state) pair <math>(d,s)</math>.\n\n==Deterministic models==\nThe sets of states <math>S(d),d\\in D,</math> need not represent uncertainty. They can represent (deterministic) variations in the value of a parameter.\n\n===Example===\nLet <math>D</math> be a finite set representing possible locations of an 'undesirable'  public facility (e.g. garbage dump), and let <math>S</math> denote a finite set of locations in the neighborhood of the planned facility, representing existing dwellings.\n\nIt might be desirable to build the facility so that its shortest distance from an existing dwelling is as large as possible. The maximin formulation of the problem is as follows:\n\n: <math>\\max_{d\\in D}\\min_{s\\in S} dist(d,s)</math>\n\nwhere <math>dist(d,s)</math> denotes the distance of <math>s</math> from <math>d</math>. Note that in this problem <math>S(d)</math> does not vary with <math>d</math>.\n\nIn cases where is it desirable to live close to the facility, the objective could be to minimize the maximum distance from the facility. This yields the following minimax problem:\n\n: <math>\\min_{d\\in D}\\max_{s\\in S} dist(d,s)</math>\n\nThese are generic [[facility location]] problems.\n\n==Maximin models in disguise==\nExperience has shown that the formulation of maximin models can be subtle in the sense that problems that 'do not look like' maximin problems can be formulated as such.\n\n===Example===\nConsider the following problem:\n <blockquote>\n Given a finite set <math>X</math> and a real valued function <math>g</math> on <math>X</math>, find the largest subset of <math>X</math> such that <math>g(x) \\le 0</math>&nbsp; for every <math>x</math> in this subset.\n </blockquote>\nThe maximin formulation of this problem, in the MP format, is as follows:\n\n:<math>\\max_{Y\\subseteq X} \\ \\{|Y|: g(x)\\le 0,\\forall x\\in Y\\}.</math>\n\nGeneric problems of this type appear in robustness analysis.<ref name=\"moffitt08\">L. Joe Moffitt, John K. Stranlund, and Craig D. Osteen (2008). Robust detection protocols for uncertain introductions of invasive species. ''Journal of Environmental Management,'' 89(4), 293–299.</ref><ref name=\"rosenhead72\">Jonathan Rosenhead, Martin Elton, Shiv K. Gupta. (1972). Robustness and Optimality as Criteria for Strategic Decisions. ''Operational Research Quarterly,'' 23(4), 413-431.</ref>\n\nIt has been shown that the [[Stability radius|radius of stability]] model and [[info-gap decision theory|info-gap's robustness]] model are simple instances of Wald's maximin model.<ref name=\"MS10\">Sniedovich, M. (2010). A bird's view of info-gap decision theory. ''Journal of Risk Finance,'' 11(3), 268-283.</ref>\n\n==Constrained maximin models==\nConstraints can be incorporated explicitly in the maximin models. For instance, the following is a constrained maximin problem stated in the classic format\n\n:<math>v^{*}:= \\max_{d\\in D}\\min_{s\\in S(d)}\\ \\{f(d,s): g(d,s) \\le 0, \\forall s\\in S(d)\\}.</math>\n\nIts equivalent MP format is as follows:\n\n:<math>v^{*}:= \\max_{d\\in D,\\,z\\in \\mathbb{R}} \\{z: z \\le f(d,s), g(d,s) \\le 0, \\forall s\\in S(d)\\}.</math>\n\nSuch models are very useful in [[robust optimization]].\n\n==The price of robustness==\nOne of the 'weaknesses' of the Maximin model is that the robustness that it provides comes with a ''price''.<ref name=\"sim04\" />  By playing it safe, the Maximin model tends to generate conservative decisions, whose price can be high. The following example illustrates this important feature of the model.\n\n===Example===\nConsider the simple case where there are two decisions, d'  and d\",  and where S(d')=S(d\")=[a,b]. The Maximin model is then as follows:\n\n: <math>\\max_{d\\in D}\\min_{s\\in S(d)} f(d,s) = \\max_{d\\,',d\\,''}\\ \\min_{a\\le s \\le b}f(d,s) = \\max\\ \\{\\min_{a\\le s \\le b}f(d\\,',s),\\min_{a\\le s\\le b}f(d\\,'',s)\\}</math>\n\nNow consider the instance shown by\n\n[[Image:Maximin price.png|600px]]\n\nNote that although the payoff associated with decision d'  is larger than the payoff associated with decision d\" over most of the state space S=[a,b], the best worst case according to Wald's model is provided by decision d\". Hence, according to Wald's model decision d\" is better than decision d'.\n\n==Algorithms==\nThere are no general-purpose algorithms for the solution of maximin problems. Some problems are very simple to solve, others are very difficult.<ref name=\"ben-tal09\" /><ref name=\"sim04\" /><ref name=\"reemstem98\">Reemstem, R. and R\\\"{u}ckmann, J. (1998). ''Semi-Infinite Programming,'' Kluwer, Boston.</ref><ref name=\"rustem02\">Rustem, B. and Howe, M. (2002). ''Algorithms for Worst-case Design and Applications to Risk Management,'' Princeton University Press, Princeton.</ref>\n\n===Example===\nConsider the case where the state variable is an \"index\", for instance  let <math>S(d)=\\{1,2,\\dots,k\\}</math> for  all <math>d \\in D</math>. The associated maximin problem is then as follows:\n\n: <math>\\begin{align}\\max_{d\\in D}\\min_{s\\in S(d)} f(d,s) &= \\max_{d\\in D}\\min_{1\\le s \\le k} \\{f_{1}(d),\\dots,f_{k}(d)\\}\\\\\n& = \\max_{d\\in D, z\\in \\mathbb{R}} \\{z: z\\le f_{s}(d),\\forall s=1,2,\\dots,k\\}\\end{align}</math>\nwhere <math>f_{s}(d) \\equiv f(d,s)</math>.\n\nIf <math>d\\in \\mathbb{R}^{n}</math>, all the functions <math>f_{s}, s=1,2,\\dots,k,</math>  are [[linear]], and <math>d\\in D</math> is specified by a system of [[linear]] constraints on <math>d</math>, then this problem is a [[linear programming]] problem that can be solved by [[linear programming]] algorithms such as the [[simplex algorithm]].\n\n==References==\n<references />\n\n{{DEFAULTSORT:Wald's Maximin Model}}\n[[Category:Mathematical optimization]]\n[[Category:Optimal decisions]]"
    },
    {
      "title": "Walrasian auction",
      "url": "https://en.wikipedia.org/wiki/Walrasian_auction",
      "text": "A '''Walrasian auction''', introduced by [[Léon Walras]], is a type of simultaneous [[auction]] where each [[Agent (economics)|agent]] calculates its demand for the good at every possible price and submits this to an auctioneer. The price is then set so that the total demand across all agents equals the total amount of the good. Thus, a Walrasian auction perfectly matches the supply and the demand.\n\nWalras suggests that [[General equilibrium|equilibrium]] will be achieved through a process of '''[[wikt:tâtonnement|tâtonnement]]'''{{anchor|tatonnement}} (French for \"trial and error\"), a form of [[hill climbing]].\n\n==Walrasian auctioneer==\nThe ''Walrasian auctioneer'' is the presumed auctioneer that matches [[supply and demand]] in a market of [[perfect competition]]. The auctioneer provides for the features of perfect competition: [[perfect information]] and no [[transaction cost]]s. The process is called ''tâtonnement'', or ''groping'', relating to finding the market clearing price for all commodities and giving rise to [[general equilibrium]].\n\nThe device is an attempt to avoid one of deepest conceptual problems of perfect competition, which may, essentially, be defined by the stipulation that no agent can affect prices. But if no one can affect prices no one can change them, so prices cannot change. However, involving as it does an artificial solution, the device is less than entirely satisfactory.\n\n==As a mistranslation==\nUntil Walker and van Daal's 2014 translation, William Jaffé's ''Elements of Pure Economics'' (1954) was for many years the only English translation of Walras's ''Éléments d’économie politique pure''. \n\nWalker and van Daal argue that the idea of the Walrasian auction and Walrasian auctioneer resulted from Jaffé's mistranslation of the French word ''crieurs'' (criers) into ''auctioneers''. Walker and van Daal call this \"a momentous error that has misled generations of readers into thinking that the markets in Walras's model are auction markets and that he assigned the function of changing prices in his model to an auctioneer.\"<ref>{{Cite book|url=https://books.google.com/books?id=9kilBAAAQBAJ&pg=PR35&lpg=PR35&dq=%22a+momentous+error+that+has+mislead+generations+of+readers+into+thinking+that+the+markets+in+Walras%E2%80%99s+model+are+auction+markets+and+that+he+assigned+the+function+of+changing+prices+in+his+model+to+an+auctioneer.%22|title=Leon Walras's Elements of Theoretical Economics|last=Walras|first=Léon|date=2014-10-23|publisher=Cambridge University Press|isbn=9781107064133|language=en}}</ref>\n\n==See also==\n* [[Double auction]]\n* [[Walras' law]]\n\n==References==\n<references />\n\n{{Authority control}}\n\n[[Category:Wholesale markets]]\n[[Category:General equilibrium theory]]\n[[Category:Mathematical optimization]]\n[[Category:Auction theory]]"
    },
    {
      "title": "Wing-shape optimization",
      "url": "https://en.wikipedia.org/wiki/Wing-shape_optimization",
      "text": "'''Wing-shape optimization''' is a software implementation of [[shape optimization]] primarily used for aircraft design.  This allows for engineers to produce more efficient and cheaper aircraft designs.\n\n==History==\nShape optimization, as a software process and tool, first appeared as an [[algorithm]] in 1995 and as commercial software for the [[automotive industry]] by 1998, as noted by F. Muyl.<ref>F. Muyl, L. Dumas, V. Herbert.  [http://www.ann.jussieu.fr/~dumas/Lisbon02.pdf “Hybrid Method for Aerodynamic Shape Optimization in Automotive Industry.”] {{webarchive |url=https://web.archive.org/web/20051018235247/http://www.ann.jussieu.fr/~dumas/Lisbon02.pdf |date=October 18, 2005 }}  Universite Pierre et Marie Curie.  1998.</ref>  Relative to the age of the automotive and aeronautical companies, this software is very new.  The difficulty was not with the science behind the process, but rather the capabilities of computer hardware.  In 1998, F. Muyl developed a compromise between exact accuracy and computational time to reduce drag of an automotive.  GA phases are the standard [[genetic algorithm]] iterations and the BFGS phases are the approximated calculations designed to save time.  However, he acknowledged that the [[computational time]] required on existing hardware, nearly two weeks for a moderate improvement on an oversimplified proof of concept model, made it unattractive for commercial purposes.  He also recognized that improving the modeling implementation to use automatic partial derivatives might improve the computational time, particularly with specialized hardware.\nIn 2000, after a couple years of computer hardware development, K. Maute <ref>Joaquim R. R. A. Martins and Juan J. Alonso. [http://aero-comlab.stanford.edu/Papers/ceas2001.pdf “AERO-STRUCTURAL WING DESIGN OPTIMIZATION USING HIGH-FIDELITY SENSITIVITY ANALYSIS.”] Confederation of European Aerospace Societies. 2001.</ref> introduced a more accurate system that could optimize an aircraft wing quickly enough for commercial use. \n\n==Method==\nWing-shape optimization is by nature an [[iterative]] process.  First, a baseline wing design is chosen to begin the process with; this is usually the wing created by [[aerospace engineer]]s.  This wing is assumed to be reasonably close to a best-fit design from the engineers.  The next step is to model the wing shape and structure.  Once those are mapped out, the software flies the model in a simulated air tunnel using well-developed [[computational fluid dynamics]] (CFD) equations.  The results of the test give the various [[performance characteristics]] of that design.  Once that completes, the software makes incremental changes to the structure and shape details, recreates the model, and flies the new model through a [[wind tunnel]].  If the changes result in a better performing wing, then the software commits the changes.  If not, the changes are thrown out and different changes are made.  The changes are then saved as the new working model and the cycle will loop.  This entire process is run until the changes observed appear to converge on a design&nbsp;– such as when the changes are under 1&nbsp;mm.<ref name=\"stanford.edu\">Jameson, A., Leoviriyakit, K., and Shankaran, S., [http://www.stanford.edu/~kasidit/publications/jameson.aiaa.07-764.pdf \"Multi-point Aero-Structural Optimization of Wings Including Planform Variations\"]{{dead link|date=June 2012}}, 45th Aerospace Sciences Meeting and Exhibit, AIAA-2007-764, Reno, NV, 8–11 Jan 2007</ref>\n\nUnfortunately, the resulting wing design can only be as good as the computational model.\n\n==Examples==\n===Traditional===\nAn example of an optimization proof of concept was done in 2003 by Leoviriyakit using the Boeing 747–200.<ref>K. Leoviriyakit and A. Jameson. [http://www.stanford.edu/~kasidit/publications/leoviriyakit.aiaa.03-0210.pdf “Aerodynamic shape optimization of wings including planform variations.”] {{webarchive|url=https://web.archive.org/web/20030804171702/http://www.stanford.edu/~kasidit/publications/leoviriyakit.aiaa.03-0210.pdf |date=2003-08-04 }} AIAA paper 2003-0210, 41 Aerospace Sciences Meeting & Exhibit, Reno, Nevada, January 2003.</ref>  Using the variable list above, he optimized for only a single point – a lift coefficient of 0.42 and a speed of [[Mach number|Mach]] 0.87, just above cruising.  With just those few variables, he was able to realize a 12% decrease in [[drag (physics)|drag]] and a 0.1% decrease in wing weight.  The code that was run produced a longer span but less sweep-back than the original wing planform.  While the reduction in sweep-back actually increases drag it also increases lift allowing a lower AoA and the extended wing span  decreases the induced drag (wing tip vortex) resulting in a net reduction of drag.  Unfortunately, his optimized design uses too simple of a model; he realized that had more variables, such as [[viscous]] effects, been taken into consideration, the resulting model would have been far different.  The other major limitation of the [[single point]] approach is that it only optimizes the wing for one speed and lift condition.  While the drag may have been reduced at cruising speed, it might have been drastically increased for take-off and landing, resulting in a net fuel loss for the airline.\n\n===Wing-body===\nThis process can also be extended to explore single wing-body aircraft designs.  Wing-body styled aircraft can scale up their cargo much easier than the traditional ‘tube and plank’ design.  Airbus utilized this approach to explore design choices in future large aircraft in 2002.<ref>M. Mialon, T. Fol, and C. Bonnand. [http://www.onera.fr/daap-en/flying-wings/aerodynamic-optimization-of-subsonic-flying-wing-configurations.pdf “AERODYNAMIC OPTIMIZATION OF SUBSONIC FLYING WING CONFIGURATIONS.”] {{webarchive|url=https://web.archive.org/web/20061206105003/http://www.onera.fr/daap-en/flying-wings/aerodynamic-optimization-of-subsonic-flying-wing-configurations.pdf |date=2006-12-06 }} AIAA paper 2002–2931.</ref>  Their objectives, however, were slightly more complex than the original design of the software: the aircraft needs a maximized [[lift to drag ratio]], to be longitudinally neutral (not wanting to pitch up or down while without a tail), to have a maximum [[angle of attack]], to have a minimum [[cabin (aircraft)|cabin]] volume and shape, and have a maximum thickness on the outboard wings.  Using three different components, they expanded their computational model to incorporate as many constraints as possible, including viscous effects.  This method involves significantly more computational power.\nTheir initial findings saved a lot of money in building and testing – since it causes supersonic flow of air, a [[shock wave]] forms on the aft part of the wing, drastically increasing drag and reducing lift.  After modifying their goals to only keep the lift to drag ratio high and even out the pressure, the simulation provided a better design – showing that this tool is very adaptable to the situation at hand. \nThe end result of this study was that Airbus had a set of airfoil designs that are suited to a very large wing-body aircraft.  This also proved that these methods are successful at adapting to any task that they would require.\n\n===Post-manufacturing changes===\nThis method of [[process optimization|optimization]] can also be used to develop a post-manufacture modification to an existing wing.  In 2006, Antony Jameson modified the code to increase the speed of a race [[P-51 Mustang]].<ref>A. Jameson. [http://www.stanford.edu/~kasidit/publications/jameson.aiaa.06-0048.pdf “Aerodynamic Shape Optimization for the World's Fastest P-51.”]{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }} 44th Aerospace Sciences Meeting and Exhibit, January 9–12, 2006, AIAA-0048, Reno, Nevada.</ref>  This goal is different still – the [[Reno Air Race]] is a straight drag from one point to another at a relatively low altitude.  The goal is to improve the top speed to reach a [[propeller (aircraft)|propeller]]-driven record.  Since the change must be glued onto the wing, this severely limits the changes possible.  The problem is similar to the previous example – shock wave buildup.  To accomplish this, the software was restricted to find a solution that could only distort the wing planform outwards, away from the control surfaces.  Using a [[lift coefficient]] of 0.1 and a speed of Mach 0.78, the software produced a bump near the front of the top of the wing.  The interruptions of air flow at that particular speed travel back the right distance to break up the shock, reducing the drag.  While the aircraft’s drag was increased below Mach 0.73, that was thrown out as being less important than a top speed. If these modifications perform as expected, then this validates the use of the software tool to improve on an existing production wing without remanufacture.\n\n==Multi-point optimization==\nStill, all of these methods have a weakness – they are tuned for one particular set of conditions and speed.  In 2007, Jameson introduced both an additional step and a new method of calculations.<ref name=\"stanford.edu\"/>  To account for additional conditions, such as take-off, landing, climbing, and cruising, the modeler calculates all of these simultaneously, rather than only one at a time.  Each gradient calculation g is assigned a weight β.  Higher priority items, such as cruising drag, are given more weight.  The gradient to determine an overall ‘loss’ or a ‘gain’ for the design is created by summing all the gradients times each respective weight.  What this allows for is if a change drastically improves takeoff performance but results in a slight hit on cruising performance, the cruising hit can override the takeoff gain due to weighting.  Setting the simulation up in this manner can significantly improve the designs produced by the software.  This version of the modeler, however, adds yet another complexity to the initial conditions, and a slight error on the designer’s behalf can have a significantly larger effect on the resulting design.  The calculation efficiency improvement takes advantage of the multiple variables.\nThis time, two different points were used for the [[Boeing 747-200]] – Mach 0.85 and 0.87.  Unfortunately, optimizing for the two points resulted in less than a 3% improvement over drag and almost no weight improvement on the base design.  To check his work, he used the same simulation on another aircraft wing and received similar results.  The problem observed is that changes that boosted one point of interest directly conflicted with the other, and the resulting compromise severely hampers the improvement gained.  His current research involves a better way to resolve the differences and achieve an improvement similar to the single-point optimizations.\n\n<!--[[WP:CRYSTAL BALL]]\n==Future==\nThe future of this technology lies in the accuracy of the models.  Computer hardware has followed [[Moore’s Law]] in computational power still to this day, and so the current limitation is the attention to detail on behalf of the programmers and engineers.  As more accurate models are produced, better aircraft wings can be produced.\nMuch farther in the future, when more advanced hardware structures are developed, it will be possible to have dynamically adapting wings based on current flight conditions.  As shown, the software portion of this problem is already solved: single-point calculations can be done on the fly for the particular speed and conditions, giving the possibility of achieving significant drag reduction throughout the entire flight.-->\n\n==References==\n<references/>\n\n[[Category:Mathematical optimization]]\n[[Category:Aircraft wing design]]"
    },
    {
      "title": "Wolfe conditions",
      "url": "https://en.wikipedia.org/wiki/Wolfe_conditions",
      "text": "In the unconstrained [[optimization (mathematics)|minimization]] problem, the '''Wolfe conditions''' are a set of inequalities for performing '''inexact''' [[line search]], especially in [[quasi-Newton methods]], first published by Philip Wolfe in 1969.<ref>{{Cite journal | last1 = Wolfe | first1 = P. | title = Convergence Conditions for Ascent Methods | doi = 10.1137/1011036 | journal = SIAM Review | volume = 11 | issue = 2 | pages = 226–000 | year = 1969 | jstor = 2028111| pmid =  | pmc = }}</ref><ref>{{Cite journal | last1 = Wolfe | first1 = P. | title = Convergence Conditions for Ascent Methods. II: Some Corrections | doi = 10.1137/1013035 | journal = SIAM Review | volume = 13 | issue = 2 | pages = 185–000 | year = 1971 | pmid =  | pmc = }}</ref>\n\nIn these methods the idea is to find\n\n::<math>\\min_x f(\\mathbf{x})</math>\n\nfor some [[smooth function|smooth]] <math>f:\\mathbb R^n\\to\\mathbb R</math>. Each step often involves approximately solving the subproblem\n\n::<math>\\min_{\\alpha} f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k)</math>\n\nwhere <math>\\mathbf{x}_k</math> is the current best guess, <math>\\mathbf{p}_k \\in \\mathbb R^n</math> is a search direction, and <math>\\alpha \\in \\mathbb R</math> is the step length.\n\nThe inexact line searches provide an efficient way of computing an acceptable step length <math>\\alpha</math> that reduces the [[objective function]] 'sufficiently', rather than minimizing the objective function over <math>\\alpha\\in\\mathbb R^+</math> exactly. A line search algorithm can use Wolfe conditions as a requirement for any guessed <math>\\alpha</math>, before finding a new search direction <math>\\mathbf{p}_k</math>.\n\n==Armijo rule and curvature==\nA step length <math>\\alpha_k</math> is said to satisfy the ''Wolfe conditions'', restricted to the direction <math>\\mathbf{p}_k</math>, if the following two inequalities hold:\n\n: <math>\n\\begin{align}\n\\textbf{i)} & \\quad f(\\mathbf{x}_k+\\alpha_k\\mathbf{p}_k)\\leq f(\\mathbf{x}_k) + c_1\\alpha_k \\mathbf{p}_k^{\\mathrm T} \\nabla f(\\mathbf{x}_k),\\\\[6pt]\n\\textbf{ii)} & \\quad {-\\mathbf{p}}_k^{\\mathrm T}\\nabla f(\\mathbf{x}_k+\\alpha_k\\mathbf{p}_k) \\leq -c_2\\mathbf{p}_k^{\\mathrm T}\\nabla f(\\mathbf{x}_k),\n\\end{align}\n</math>\n\nwith <math>0<c_1<c_2<1</math>. (In examining condition (ii), recall that to ensure that <math>\\mathbf{p}_k</math> is a descent direction, we have <math>\\mathbf{p}_k^{\\mathrm T}\\nabla f(\\mathbf{x}_k) < 0 </math>, as in the case of [[gradient descent]], where <math>\\mathbf{p}_k = -\\nabla f(\\mathbf{x}_k)</math>, or [[Newton–Raphson]], where <math>\\mathbf{p}_k = -\\mathbf{H}^{-1} \\nabla f(\\mathbf{x}_k)</math> with <math>\\mathbf{H}</math> positive definite.)\n\n<math>c_1</math> is usually chosen to be quite small while <math>c_2</math> is much larger; Nocedal<ref>{{cite book | title = Numerical Optimization | last1=Nocedal |first1=Jorge | last2=Wright |first2=Stephen | url = https://books.google.com/books?id=epc5fX0lqRIC&lpg=PP1&pg=PA38#v=onepage&q | year=1999}}</ref> gives example values of <math>c_1=10^{-4}</math>\nand <math>c_2=0.9</math> for Newton or quasi-Newton methods and <math>c_2=0.1</math> for the nonlinear [[conjugate gradient method]]. Inequality i) is known as the '''Armijo rule'''<ref>{{cite journal | last =  Armijo | first = Larry | year = 1966 | title = Minimization of functions having Lipschitz continuous first partial derivatives | journal = Pacific J. Math. | volume = 16 | issue = 1 | pages = 1–3 | url = http://projecteuclid.org/euclid.pjm/1102995080 | doi=10.2140/pjm.1966.16.1}}</ref> and ii) as the '''curvature condition'''; i) ensures that the step length <math>\\alpha_k</math> decreases <math>f</math>  'sufficiently', and ii) ensures that the slope has been reduced sufficiently. Conditions i) and ii) can be interpreted as respectively providing an upper and lower bound on the admissible step length values.\n\n==Strong Wolfe condition on curvature==\nDenote a univariate function <math>\\varphi</math> restricted to the direction <math>\\mathbf{p}_k</math> as <math>\\varphi(\\alpha)=f(\\mathbf{x}_k+\\alpha\\mathbf{p}_k)</math>. The Wolfe conditions can result in a value for the step length that is not close to a minimizer of <math>\\varphi</math>. If we modify the curvature condition to the following,\n\n: <math> \\textbf{iii)} \\quad \\big|\\mathbf{p}_k^{\\mathrm T}\\nabla f(\\mathbf{x}_k+\\alpha_k\\mathbf{p}_k)\\big|\\leq c_2\\big|\\mathbf{p}_k^{\\mathrm T}\\nabla f(\\mathbf{x}_k)\\big|</math>\n\nthen i) and iii) together form the so-called '''strong Wolfe conditions''', and force <math>\\alpha_k</math> to lie close to a [[critical point (mathematics)|critical point]] of <math>\\varphi</math>.\n\n==Rationale==\nThe principal reason for imposing the Wolfe conditions in an optimization algorithm where <math> \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha \\mathbf{p}_k </math> is to ensure convergence of the gradient to zero.  In particular, if the cosine of the angle between <math>\\mathbf{p}_k</math> and the gradient,\n\n:: <math> \\cos \\theta_k = \\frac {\\nabla f(\\mathbf{x}_k)^{\\mathrm T}\\mathbf{p}_k }{\\| \\nabla f(\\mathbf{x}_k)\\| \\|\\mathbf{p}_k\\| } </math>\n\nis bounded away from zero and the i) and ii) conditions hold, then <math> \\nabla f(\\mathbf{x}_k) \\rightarrow 0 </math>.\n\nAn additional motivation, in the case of a [[quasi-Newton method]], is that if <math> \\mathbf{p}_k = -B_k^{-1} \\nabla f(\\mathbf{x}_k) </math>, where the matrix <math> B_k </math> is updated by the [[BFGS]] or [[Davidon–Fletcher–Powell formula|DFP]] formula, then if <math> B_k </math> is positive definite ii) implies <math> B_{k+1} </math> is also positive definite.\n\n==References==\n<references />\n\n==Further reading==\n* {{Cite book | doi = 10.1007/978-0-387-40065-5_3 | chapter = Line Search Methods | title = Numerical Optimization | series = Springer Series in Operations Research and Financial Engineering | pages = 30–32 | year = 2006 | isbn = 978-0-387-30303-1 | pmid =  | pmc = }}\n* {{Cite book | doi = 10.1007/978-0-387-40065-5_6 | chapter = Quasi-Newton Methods | title = Numerical Optimization | series = Springer Series in Operations Research and Financial Engineering | pages = 135–163 | year = 2006 | isbn = 978-0-387-30303-1 | pmid =  | pmc = }}\n\n{{Optimization algorithms}}\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Berth allocation problem",
      "url": "https://en.wikipedia.org/wiki/Berth_allocation_problem",
      "text": "The '''berth allocation problem''' (also known as the berth scheduling problem) is a [[NP-complete]] problem in [[operations research]], regarding the allocation of berth space for [[Marine vessel|vessel]]s in [[container terminal]]s. Vessels arrive over time and the terminal operator needs to assign them to berths to be served (loading and unloading containers) as soon as possible. Different factors affect the berth and time assignment of each vessel.\n\nAmong models found in the literature, there are four most frequently observed cases: \n#a) discrete vs. continuous berthing space,\n#b) static vs. dynamic vessel arrivals, \n#c) static vs. dynamic vessel handling times, and \n#d) variable vessel arrivals.\n\nIn the discrete problem, the quay is viewed as a finite set of berths. In the continuous problem, vessels can berth anywhere along the quay and the majority of research deals with the former case. In the static arrival problem all vessels are already at the port whereas in the dynamic only a portion of the vessels to be scheduled are present. The majority of the published research in berth scheduling considers the latter case. In the static handling time problem, vessel handling times are considered as input, whereas in the dynamic they are decision variables. Finally, in the last case, the vessel arrival times are considered as variables and are optimized.\n\nTechnical restrictions such as berthing draft and inter-vessel and end-berth clearance distance are further assumptions that have been adopted in some of the studies dealing with the berth allocation problem, bringing the problem formulation closer to real world conditions. Introducing technical restrictions to existing berth allocation models is rather straightforward and it may increase the complexity of the problem but simplify the use of metaheuristics (decrease in the feasible space).\n\nSome of the most notable objectives addressed in the literature are: \n# Minimization of vessel total service times (waiting and handling times), \n# Minimization of early and delayed departures, \n# Optimization of vessel arrival times,\n# Optimization of emissions and fuel consumption.\n\nProblems have been formulated as single and multi-objective as well as single and bi-level.\n\n==See also==\n*[[List of NP-complete problems]]\n* [[Quay crane scheduling]]\n* [[Container terminals]]\n\n==Further reading==\n*{{cite journal |last=Golias |first=Mihalis M. |year=2009 |title=The berth allocation problem: Optimizing vessel arrival time |journal=Maritime Economics & Logistics |volume=11 |issue=4 |pages=358–377 |doi=10.1057/mel.2009.12 |display-authors=etal}}\n*{{cite journal |last=Guan |first=Yongpei |last2=Cheung |first2=Raymond K. |year=2004 |title=The berth allocation problem: models and solution methods |journal=OR Spectrum |volume=26 |issue=1 |pages=75–92 |doi=10.1007/s00291-003-0140-8 }}\n*{{cite book |last=Pinedo |first=Michael L. |year=2008 |title=Scheduling: Theory, Algorithms, and Systems |location=New York |publisher=Springer |isbn=978-0-387-78934-7 }}\n* Briano C, Briano E.,  Bruzzone A. G., Revetria R. (2005) Models for Support Maritime Logistics: A Case Study for Improving Terminal Planning. 19th European Conference on Modeling and Simulation. June 1–4, 2005 Riga, Latvia\n* Brown G.G., Cormican K.J., Lawphongpanich S., and Widdis, D.B. Optimizing submarine berthing with a persistence incentive. Naval Research Logistics. Vol. 44, 1997, pp.&nbsp;301–318.\n* Brown G.G., Lawphongpanich S., and Thurman K.P. Optimizing vessel berthing. Naval Research Logistics, Vol. 41, 1994, pp.&nbsp;1–15.\n* Canonaco, P., Legato, P., Mazza, R., Musmanno, R. A queuing network model for the management of berth crane operations. Computers and Operations Research, Vol. 35(8), 2008, pp.&nbsp;2432–2446.\n* Cordeau, J.-F., Laporte, G., Legato, P., Moccia, L. Models and tabu search heuristics for the berth-allocation problem. Transportation Science. Vol. 39, 2005, pp.&nbsp;526–538.\n* Dai, J., Liu, W., Moorthy, R. and Teo, C.-P. Berth Allocation Planning Optimization in Container Terminals.  [https://people.orie.cornell.edu/jdai/publications/daiLinMoorthyTeo08.pdf http://www.bschool.nus.edu.sg/staff/bizteocp/berthplanningjuly2004.pdf%5B%5D]\n* Dragović, B., Park N-K, Radmilović Z. Ship-berth link performance evaluation: simulation and analytical approaches. Maritime Policy & Management, Vol. 33 (3), 2006, pp.&nbsp;281–299.\n* Edmond E. D., and Maggs R. P., 1978. How useful are queue models in port investment decisions for container berths? Journal of the Operational Research Society, Vol. 29, 1978, pp.&nbsp;741–750.\n* Golias M.M. (2011) A bi-objective berth allocation formulation to account for vessel handling time uncertainty. Journal of Maritime Economics and Logistics. 13:419-441\n* Golias M.M., Haralambides H.E. Berth scheduling with variable cost functions. (2011) Journal of Maritime Economics and Logistics. 13:174-189\n* Golias M.M., Boilé M., Theofanis S., Efstathiou C. (2010) The berth scheduling problem: Maximizing berth productivity and minimizing fuel consumption and emissions production. Transportation Research Record: Journal of the Transportation Research Board, Marine Transportation and Port Operations, 2166, 20-27.\n* Golias M.M., Boilé M., Theofanis S. (2010) The discrete berth scheduling problem: Towards a unified mathematical formulation.  Transportation Research Record: Journal of the Transportation Research Board, Freight Transportation Modeling, Planning, and Logistics, 2168, 1-8.\n* Golias M.M.,  Boilé M., Theofanis S., Taboada A.H. (2010) A multi-objective decision and analysis approach for the berth scheduling problem. International Journal of Information Technology Project Management, 1(1), 54-73.\n* Saharidis G.K.D., Golias M.M., Boilé M., Theofanis S., Ierapetritou M. (2009) The berth scheduling problem with customer differentiation: A new methodological approach based on hierarchical optimization. International Journal of Advanced Manufacturing Technology, 46(1-4), 377-393.\n* Golias M.M., Boilé M., Theofanis S. (2009) Service time based customer differentiation berth scheduling. Transportation Research Part E: Logistics and Transportation Review, 45(6), 878-892.\n* Golias M.M., Boilé M., Theofanis S. (2009) A lambda-optimization based heuristic for the discrete berth scheduling problem. Transportation Research Pt. C, 18(5), 794-806.\n* Golias M.M., Boilé M., Theofanis S. (2009) An adaptive time window partitioning based algorithm for the discrete and dynamic berth scheduling problem. Transportation Research Record: Journal of the Transportation Research Board, Network Modeling, 2091, 21-30.\n* Boilé M., Golias M.M., Theofanis S. (2009) Scheduling of berthing resources at a marine container terminal via the use of Genetic Algorithms: Current and Future Research. In: Pinheiro dos Santos, Wellington et al. (Eds.), ''Evolutionary Computation''. Vukovar: In-Teh. {{ISBN|978-953-307-008-7}}, pp.&nbsp;61–76. \n* Guan Y, Xiao W-Q, Cheung R K, and Li C-L. A multiprocessor task scheduling model for berth allocation: heuristic and worst case analysis. Operations Research Letters, Vol. 30, 2002, pp.&nbsp;343–350.\n* Han M., Ping L., and Sun J.  “The Algorithm For Berth Scheduling Problem By The Hybrid Optimization Strategy GASA”, 9th International Conference on Control, Automation, Robotics and Vision, ICARCV, 2006.\n* Hansen P., and Oguz C. A note on formulations of static and dynamic berth allocation problems. Report, Les Cahiers du Gerad, G-2003-20, 2003. \n* Hansen, P., Oguz, C. and Mladenovic, N. Variable neighborhood search for minimum cost berth allocation.  European Journal of Operational Research, Vol. 131(3), 2008, pp.&nbsp;636–649.\n* Imai A., J-T. Zhang, E. Nishimura, and S. Papadimitriou. The Berth Allocation Problem with Service Time and Delay Time Objectives, Maritime Economics & Logistics, Vol. 9, 2007, pp.&nbsp;269–290.\n* Imai A., Nagaiwa K., Tat C-W. Efficient planning of berth allocation for container terminals in Asia. Journal of Advanced Transportation, Vol. 31, 1997, pp.&nbsp;75–94.\n* Imai A., Nishimura E., and Papadimitriou S. Berth allocation with service priority. Transportation Research Part B, Vol. 37, 2003, pp.&nbsp;437–457.\n* Imai A., Nishimura E., Hattori M., and Papadimitriou S. Berth allocation at indented berths for mega-containerships. European Journal of Operations Research, Vol. 179 (2), 2007, pp.&nbsp;579–593.\n* Imai A., Sun X., Nishimura E., and Papadimitriou S. Berth Allocation in a Container Port: Using Continuous Location Space Approach. Transportation Research Part B, Vol. 39, 2005, pp.&nbsp;199–221.\n* Imai, A., Nishimura, E. and Papadimitriou, S. Berthing ships at a multi-user container terminal with a limited quay capacity.  Transportation Research Part E, Vol. 44(1), 2007, pp.&nbsp;136–151.\n* Imai, A., Nishimura, E. and Papadimitriou, S. Corrigendum to “The dynamic berth allocation problem for a container port”. Transportation Research Part B, Vol. 39(3), 2005a, p.&nbsp;197.\n* Imai, A., Nishimura, E., Papadimitriou, S. The dynamic berth allocation problem for a container port. Transportation Research Part B, Vol. 35, 2001, pp.&nbsp;401–417.\n* Iris, C., Pacino, D., Ropke, S., Larsen, A.,  Integrated Berth Allocation and Quay Crane Assignment Problem: Set partitioning models and computational results. Transportation Research Part E, Vol. 81, 2015, pp.&nbsp;75–97.\n* Kim K.H., and Moon K.C. Berth scheduling by simulated annealing. Transportation Research Part B, Vol. 37, 2003, pp.&nbsp;541–560.\n* Lai K.K, and Shih K. A study of container berth allocation. Journal of Advanced Transportation, Vol. 26, 1992, pp.&nbsp;45–60.\n* Lee D-H, Song L., and Wang H.,. A genetic algorithm for a bi-level programming model of berth allocation and quay crane scheduling. Proceedings of the 2006 Annual Transportation Research Board Meeting. Washington D.C., 2006.\n* Lee, Y. and Chen, Y.-C. An Optimization Heuristic for the Berth Scheduling Problem. European Journal of Operational Research, 2008 (In Press).\n* Legato, P. and Mazza, R. Berth Planning and resources optimization at a container terminal via discrete event simulation. European Journal of Operational Research, Vol.133(3), 2001\n* Li C-L, Cai X, and Lee C-Y. Scheduling with multiple-job-on-one-processor pattern. IIE Transactions. Vol. 30, 1998, pp.&nbsp;433–445.\n* Lim A. The berth planning problem. Operations Research Letters .Vol. 22, 1998, pp.&nbsp;105–110.\n* Lokuge, P. and Alahakoon, P. Improving the adaptability in automated vessel scheduling in container ports using intelligent software agents. European Journal of Operational research, Vol. 177(3), 2007, pp.&nbsp;1985–2015.\n* Meersmans, P.J.M. and Dekker, R. Operations Research supports container handling. [[Econometric Institute]] Report EI 2001-22, Erasmus University, Netherlands, 2001. \n* Meisel F. and Bierwirth C., Integration of Berth Allocation and Crane Assignment to Improve the Resource Utilization at a Seaport Container Terminal. Operations Research Proceedings, Vol. 2005, Springer Berlin Heidelberg, 2006.\n* Meisel, F. (2009). Seaside operations planning in container terminals. Physica-Verlag Berlin Heidelberg.\n* Meisel, F., and Bierwirth, C. (2009) Heuristics for the integration of crane productivity in the berth allocation problem. Transportation Research Part E 45(1): 196-209.\n* Monaco, M.F. and Samara, M. The Berth Allocation Problem:  a Strong Formulation Solved by a Lagrangean Approach”, Transportation Science, Vol. 41, No.2, 2007, pp.&nbsp;265–280.\n* Moorthy R. and Teo C-P. Berth Management in Container Terminal: The Template Design Problem. OR Spectrum. Vol. 28(4), 2006, pp.&nbsp;495–518.\n* Nikolaou N.S. Berth planning by evaluation of congestion and cost. Journal of Waterways Highways Div. Proc. Am. Soc. Civ. Engrs., Vol. 93, 1967, pp.&nbsp;107–132.\n* Nishimura E., Imai A., Papadimitriou S. Berth allocation planning in the public berth system by genetic algorithms. European Journal of Operational Research, Vol. 131, 2001, pp.&nbsp;282–292.\n* Notteboom, T.E. The time factor in Liner Services. Maritime Economics and Logistics, Vol. 8(1), 2006, pp.&nbsp;19–39.\n* Park M.Y., and Kim H.K.A. Scheduling method for berth and quay cranes. OR Spectrum, Vol. 25, 2003, pp.&nbsp;1–23.\n* Park, K.T. and Kim, K.H. Berth scheduling for container terminals by using sub-gradient optimization techniques. Journal of Operational Research Society, Vol. 53, 2002, pp.&nbsp;1054–1062.\n* Stahlbock, R. and Voss, S. Operations research at container terminals: a literature update. OR Spectrum, Vol. 30, 2007, pp.&nbsp;1–52.\n* Steenken, D., Voss, S. and Stahlbock, R. Container terminal operation and operations research – a classification and literature review. OR Spectrum, Vol. 26, 2004, pp.&nbsp;3–49.\n* Theofanis S., Boilé M., Golias M.M (2009) Container terminal berth planning: critical review of research approaches and practical challenges. Transportation Research Record: Journal of the Transportation Research Board, Marine Transportation and Port Operations, 2100, 22-28.\n* Tong, C.J., Lau, H.C. and Lim, A. Ant Colony Optimization for the Ship Berthing Problem. Proceedings of the Asian Comp. Sci. Conf. (ASIAN), pp.&nbsp;359–370, 1999.\n* Umang, N., Bierlaire, M. and Vacca, I. Exact and heuristic methods to solve the berth allocation problem in bulk ports. Transportation Research Part E: Logistics and Transportation Review, Vol. 54, 2013, pp.&nbsp;14–31.\n* Vis, I.F.A. and de Koster, R. Transshipment of containers at a container terminal: An overview. European Journal of Operational Research, Vol.147, 2003, pp.&nbsp;1–16.\n* Wang F, Lim A (2007) A stochastic beam search for the berth allocation problem. Decision Support Systems, Vol. 42, 2007, pp.&nbsp;2186–2196.\n* Zhou P, Kang H., and Lin L. (2006) A Dynamic Berth Allocation Model Based on Stochastic Consideration. Proceedings of the 6th World Congress on Intelligent Control and Automation. Dalian, China.\n* Karam, A., and A. B. Eltawil. \"A new method for allocating berths, quay cranes and internal trucks in container terminals.\" Logistics, Informatics and Service Sciences (LISS), 2015 International Conference on. IEEE, 2015.\n* El-Boghdadly, T., Bader-El-Den, M., & Jones, D. (2016, July). Evolving local search heuristics for the integrated berth allocation and quay crane assignment problem. In Evolutionary Computation (CEC), 2016 IEEE Congress on (pp. 2880-2887). IEEE.\n\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Demand optimization",
      "url": "https://en.wikipedia.org/wiki/Demand_optimization",
      "text": "{{Unreferenced|date=December 2009}}\n'''Demand optimization''' is the application of processes and tools to maximize [[return on sales]]. This usually involves the application of mathematical modeling techniques using computer software.\n\nIt has particular '''applications''' in [[retail]], where merchants wish to identify the best combination of [[price]] and [[promotion (marketing)|promotion]] to achieve desired sales, [[gross margin]], inventory or [[market share]] objectives.\n\nThe '''methods used''' are similar to those applied in the related field of [[supply chain optimization]], where mathematical algorithms are applied to large databases of sales data to help [[Forecasting|predict future outcomes]]. In the case of demand optimization, as well as in house sales history, there may be competitive pricing information.\n\nBecause it is still a new field, authoritative data on the '''benefits of demand optimization''' is not widely available, although suppliers offer [[case studies]] of early adopters which claim rapid [[return on investment]], especially in the optimization of the timing and level of [[price markdown]]s.\n\n==See also==\n*[[Demand shortfall]]\n*[[Price]]\n*[[Profit maximization]]\n*[[Yield management]]\n*[[Price discrimination]]\n\n{{DEFAULTSORT:Demand Optimization}}\n[[Category:Pricing]]\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Facility location problem",
      "url": "https://en.wikipedia.org/wiki/Facility_location_problem",
      "text": "{{Refimprove|date=May 2009}}\nThe study of '''facility location problems''', also known as '''location analysis''', is a branch of [[operations research]] and [[computational geometry]] concerned with the optimal placement of facilities to minimize transportation costs while considering factors like avoiding placing hazardous materials near housing, and competitors' facilities. The techniques also apply to [[cluster analysis]].\n\n==Minimum facility location==\n\nA simple facility location problem is the [[Weber problem]], in which a single facility is to be placed, with the only optimization criterion being the minimization of the weighted sum of distances from a given set of point sites. More complex problems considered in this discipline include the placement of multiple facilities, constraints on the locations of facilities, and more complex optimization criteria.\n\nIn a basic formulation, the facility location problem consists of a set of potential facility sites ''L'' where a facility can be opened, and a set of demand points ''D'' that must be serviced. The goal is to pick a subset ''F'' of facilities to open, to minimize the sum of distances from each demand point to its nearest facility, plus the sum of opening costs of the facilities.\n\nThe facility location problem on general graphs is [[NP-hard]] to solve optimally, by reduction from (for example) the [[set cover problem]]. A number of approximation algorithms have been developed for the facility location problem and many of its variants.\n\nWithout assumptions on the set of distances between clients and sites (in particular, without assuming that the distances satisfy the [[triangle inequality]]), the problem is known as '''non-metric facility location''' and can be approximated to within a factor O(log&nbsp;''n'').<ref>{{Cite journal | last1 = Hochbaum | first1 = D. S. | authorlink = Dorit S. Hochbaum| doi = 10.1007/BF01581035 | title = Heuristics for the fixed cost median problem | journal = [[Mathematical Programming]] | volume = 22 | pages = 148–162 | year = 1982 | pmid =  | pmc = }}</ref> This factor is tight, via an [[approximation-preserving reduction]] from the set cover problem.\n\nIf we assume distances between clients and sites are undirected and satisfy the triangle inequality, we are talking about a '''metric facility location (MFL)''' problem. The MFL is still NP-hard and hard to approximate within factor better than 1.463.<ref>{{Cite journal | doi = 10.1006/jagm.1998.0993| title = Greedy Strikes Back: Improved Facility Location Algorithms| journal = Journal of Algorithms| volume = 31| pages = 228-248| year = 1999| last1 = Guha | first1 = S. | last2 = Khuller | first2 = S. | citeseerx = 10.1.1.47.2033}}</ref> The currently best known approximation algorithm achieves approximation ratio of 1.488.<ref>{{Cite book | last1 = Li | first1 = S. | chapter = A 1.488 Approximation Algorithm for the Uncapacitated Facility Location Problem | doi = 10.1007/978-3-642-22012-8_5 | title = Automata, Languages and Programming | series = [[Lecture Notes in Computer Science|LNCS]]| volume = 6756 | pages = 77–88 | year = 2011 | isbn = 978-3-642-22011-1 | url = http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.225.6387&rep=rep1&type=pdf| pmid =  | pmc = }}</ref>\n\n==Minimax facility location==\nThe '''minimax facility location''' problem seeks a location which minimizes the maximum distance to the sites, where the distance from one point to the sites is the distance from the point to its nearest site. A formal definition is as follows:\nGiven a point set '''''P'''''&nbsp;⊂&nbsp;ℝ<sup>''d''</sup>, find a point set '''''S'''''&nbsp;⊂&nbsp;ℝ<sup>''d''</sup>, |'''''S'''''|&nbsp;=&nbsp;''k'', so that max<sub>'''p'''&nbsp;∈&nbsp;'''''P'''''</sub>(min<sub>'''q'''&nbsp;∈&nbsp;'''''S'''''</sub>(d('''p''',&nbsp;'''q''')) ) is minimized.\n\nIn the case of the Euclidean metric for ''k''&nbsp;=&nbsp;1, it is known as the [[smallest enclosing sphere]] problem or [[1-center problem]]. Its study traced at least to the year of 1860. see [[smallest enclosing circle]] and [[bounding sphere]] for more details.\n\n===NP hardness===\nIt has been proved that exact solution of [[Vertex k-center problem|''k''-center]] problem is NP hard.<ref>{{citation\n | last1 = Fowler| first1 = R. J.\n | last2 = Paterson | first2 =M. S.\n | last3 = Tanimoto | first3 = S. L.\n | journal = Information Processing Letters\n | pages = 133–137\n | title = Optimal packing and covering in the plane are NP-complete\n | volume = 12\n | issue = 3\n | year = 1981 | doi=10.1016/0020-0190(81)90111-3}}.</ref>\n<ref>{{citation\n | last1 = Megiddo| first1 = Nimrod| authorlink = Nimrod Megiddo\n | last2 = Tamir| first2 =Arie \n | journal = Operations Research Letters\n | pages = 194–197\n | title = On the complexity of locating linear facilities in the plane \n | volume = 1\n | issue = 5\n | year = 1982 | url=http://theory.stanford.edu/~megiddo/pdf/complexity%20of%20locating%20linear%20facilities.pdf | doi=10.1016/0167-6377(82)90039-6}}.</ref>\n<ref name=\"Gonzalez1985\">{{citation\n |last        = Gonzalez\n |first       = Teofilo\n |authorlink  = Teofilo F. Gonzalez\n |journal     = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]\n |pages       = 293–306\n |title       = Clustering to minimize the maximum intercluster distance\n |volume      = 38\n |year        = 1985\n |url         = http://www.cs.ucsb.edu/~TEO/papers/Ktmm.pdf\n |doi         = 10.1016/0304-3975(85)90224-5\n |deadurl     = yes\n |archiveurl  = https://web.archive.org/web/20130124011012/http://www.cs.ucsb.edu/~TEO/papers/Ktmm.pdf\n |archivedate = 2013-01-24\n |df          = \n}}.</ref>\nApproximation to the problem was found to be also NP hard when the error is small. The error level in the [[approximation algorithm]] is measured as an approximation factor, which is defined as the ratio between the approximation and the optimum. It's proved that the ''k''-center problem approximation is NP hard when approximation factor is less than 1.822 (dimension&nbsp;=&nbsp;2)<ref name=\"Feder1988\">{{citation\n | last1 = Feder | first1 = Tomás\n | last2 = Greene| first2 =Daniel  \n | journal = Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing \n | pages = 434–444 \n | title = Optimal algorithms for approximate clustering \n | year = 1988\n | url=http://theory.stanford.edu/~tomas/clustering.ps}}</ref> or 2 (dimension&nbsp;>&nbsp;2).<ref name = Gonzalez1985/>\n\n===Algorithms===\n'''Exact solver'''\n\nThere exist algorithms to produce exact solutions to this problem. One exact solver runs in time <math>n^{O(\\sqrt{k})}</math>.<ref>{{citation\n | last1=HWang |first1=\tR. Z.\n | first2=R. C. T. | last2= Lee\n | first3=R. C. | last3= Chang\n | title = The slab dividing approach to solve the Euclidean p-center problem\n | journal = Algorithmica\n | year = 1993\n | volume = 9\n | issue = 1\n | pages = 1–22 | doi=10.1007/BF01185335}}</ref><ref>{{citation\n | last1=HWang |first1=\tR. Z.\n | first2=R. C. | last2= Chang\n | first3=R. C. T. | last3= Lee\n | title = The generalized searching over separators strategy to solve some NP-Hard problems in subexponential time\n | journal = Algorithmica\n | year = 1993\n | volume = 9\n | issue = 4\n | pages = 398–423 | doi=10.1007/bf01228511 }}</ref>\n\n'''1 + ''&epsilon;'' approximation'''\n\n1&nbsp;+&nbsp;''&epsilon;'' approximation is to find a solution with approximation factor no greater than&nbsp;1&nbsp;+&nbsp;''&epsilon;''. This approximation is NP hard as ''&epsilon;'' is arbitrary. One approach based on the [[coreset]] concept is proposed with execution complexity of  <math>O(2^{O(k \\log k/\\varepsilon^2)}dn)</math>.<ref>{{citation\n |first1=Mihai |last1= Bādoiu\n |first2=Sariel |last2=Har-Peled | author2-link = Sariel Har-Peled\n |first3=Piotr |last3= Indyk | author3-link = Piotr Indyk\n |title= Approximate clustering via core-sets\n |journal = Proceedings of the Thirty-fourth Annual ACM Symposium on Theory of Computing \n |pages = 250–257\n |year = 2002\n |url=http://www.cs.duke.edu/courses/spring07/cps296.2/papers/badoiu02approximate.pdf\n}}</ref>\nAs an alternative, another algorithm also based on coresets is available. It runs in <math>O(k^n)</math>.<ref>{{citation\n |first1=Pankaj |last1= Kumar\n |first2=Piyush |last2= Kumar\n |title= Almost optimal solutions to k-clustering problems\n |journal=International Journal of Computational Geometry & Applications\n |volume= 20\n |issue= 4\n |year= 2010\n |url=http://compgeom.com/~piyush/papers/kcenter.pdf\n}}</ref> The author claims that the running time is much less than the worst case and thus it's possible to solve some problems when ''k'' is small (say&nbsp;''k''&nbsp;<&nbsp;5).\n\n'''Farthest-point clustering'''\n\nFor the hardness of the problem, it's impractical to get an exact solution or precise approximation. Instead, an approximation with factor&nbsp;=&nbsp;2 is widely used for large ''k'' cases. The approximation is referred to as the farthest-point clustering (FPC) algorithm, or [[farthest-first traversal]].<ref name=Gonzalez1985/> The algorithm is quite simple: pick any point from the set as one center; search for the farthest point from remaining set as another center; repeat the process until ''k'' centers are found.\n\nIt is easy to see that this algorithm runs in linear time. As approximation with factor less than 2 is proved to be NP hard, FPC was regarded as the best approximation one can find.\n\nAs per the performance of execution, the time complexity is later improved to O(''n''&nbsp;log&nbsp;''k'') with box decomposition technique.<ref name=Feder1988/>\n\n==Maxmin facility location==\nThe '''maxmin facility location''' or '''obnoxious facility location''' problem seeks a location which maximizes the minimum distance to the sites. In the case of the Euclidean metric, it is known as the [[largest empty sphere]] problem. The planar case ([[largest empty circle]] problem) may be solved in  [[time complexity|optimal time]] &Theta;(''n''&nbsp;log&nbsp;n).<ref name=ps256>{{cite book\n|author = [[Franco P. Preparata]] and [[Michael Ian Shamos]] | title = Computational Geometry – An Introduction | publisher = Springer-Verlag| year = 1985 | id = 1st edition: ; 2nd printing, corrected and expanded, 1988: ; Russian translation, 1989: | isbn = 978-0-387-96131-6 }}, [https://books.google.com/books?id=gFtvRdUY09UC&pg=PA256&lpg=PA256&dq=%22minimax+facilities+location%22&source=bl&ots=dNgqxVw_fA&sig=l1wPWBd1PrIEMnVIMJbAb-a_OAg&hl=en&ei=tIo5S8zeOZGCswP6mJXQBA&sa=X&oi=book_result&ct=result&resnum=1&ved=0CAgQ6AEwAA#v=onepage&q=%22minimax%20facilities%20location%22&f=false p.&nbsp;256]</ref><ref>G. T. Toussaint, \"Computing largest empty circles with location constraints,\" ''International Journal of Computer and Information Sciences'', vol. 12, No. 5, October, 1983, pp. 347–358.</ref>\n\n== Dynamic facility location problems ==\n\nDynamic facility location problems allow considering a time-dependent plan for the optimal placement of facilities to minimize transportation costs, while serving customers in some area or region. This class of problems emerges as appropriate when changes in demands or transportation costs are known. As an extension to their static counterparts, a general mathematical programming framework for dynamic facility location problems has been recently introduced by Laporte et al.<ref>{{Cite book \n | last1= Nickel |first1= S.\n | first2= F. | last2= Saldanha-da-Gama\n | chapter = Multi-period facility location \n | doi = 10.1007/978-3-642-22012-8_5 \n | title = Location Science\n | year = 2015 \n | isbn = 978-3-319-13111-5\n }}</ref> \nEfficient approaches for solving large instances of those problems have been recently proposed by Castro et al.,<ref>{{Cite journal \n | last1= Castro |first1= J.\n | first2= S. | last2= Nasini\n | first3= F. | last3= Saldanha-da-Gama\n | title = A cutting-plane approach for large-scale capacitated multi-period facility location using a specialized interior-point method\n | journal = [[Mathematical Programming]]\n | year = 2017\n | volume = 163\n | issue = 1\n | pages = 411–444 | doi=10.1007/s10107-016-1067-6|hdl= 2117/80887\n }}</ref> based on a specialized application of the [[Benders decomposition]].\n\n== Integer programming formulations ==\nFacility location problems are often solved as [[Integer programming|integer programs]]. In this context, facility location problems are often posed as follows: suppose there are <math>n</math> facilities and <math>m</math> customers. We wish to choose (1) which of the <math>n</math> facilities to open, and (2) which (open) facilities to use to supply the <math>m</math> customers, in order to satisfy some fixed demand at minimum cost. We introduce the following notation: let <math>f_i</math> denote the (fixed) cost of opening facility <math>i</math>, for <math>i=1,\\dots,n</math>. Let <math>c_{ij}</math>denote the cost to ship a product from facility <math>i</math> to customer <math>j</math> for <math>i=1,\\dots,n</math> and <math>j=1,\\dots,m</math>. Let <math>d_j</math> denote the demand of customer <math>j</math> for <math>j=1,\\dots,m</math>. Further suppose that each facility has a maximum output. Let <math>u_i</math> denote the maximum amount of product that can be produced by facility <math>i</math>, that is, let <math>u_i</math> denote the ''capacity'' of facility <math>i</math>. The remainder of this section follows<ref name=\":0\">{{Cite book|title=Integer Programming {{!}} SpringerLink|volume = 271|last=Conforti|first=Michele|last2=Cornuéjols|first2=Gérard|last3=Zambelli|first3=Giacomo|language=en-gb|doi=10.1007/978-3-319-11008-0|series = Graduate Texts in Mathematics|year = 2014|isbn = 978-3-319-11007-3}}</ref>\n\n=== Capacitated facility location ===\nIn our initial formulation, introduce a binary variable <math>x_i</math> for <math>i=1,\\dots,n</math>, where <math>x_i=1</math> if facility <math>i</math> is open, and <math>x_i=0</math> otherwise. Further introduce the variable <math>y_{ij}</math> for <math>i=1,\\dots,n</math> and <math>j=1,\\dots,m</math> which represents the fraction of the demand <math>d_j</math> filled by facility <math>i</math>. The so-called '''capacitated facility location problem''' is then given by<math display=\"block\">\\begin{array}{rl}\n\\min & \\displaystyle\\sum_{i=1}^n\\sum_{j=1}^mc_{ij}y_{ij}+\\sum_{i=1}^nf_ix_i \\\\\n\\text{s.t.} & \\displaystyle\\sum_{i=1}^ny_{ij}=1 \\text{ for all }j=1,\\dots,m \\\\\n& \\displaystyle \\sum_{j=1}^md_jy_{ij}\\leqslant u_ix_i\\text{ for all }i=1\\dots,n \\\\\n&y_{ij}\\geqslant0\\text{ for all }i=1,\\dots,n \\text{ and }j=1,\\dots,m\\\\\n&x_i\\in\\{0,1\\}\\text{ for all } i=1,\\dots,n\n\\end{array}</math>\n\nNote that the second set of constraints ensure that if <math>x_i=0</math>, that is, facility <math>i</math> isn't open, then <math>y_{ij}=0</math> for all <math>j</math>, that is, no demand for any customer can be filled from facility <math>i</math>.\n\n=== Uncapacitated facility location ===\nA common case of the capacitated facility location problem above is the case when <math>u_i=+\\infty</math> for all <math>i=1,\\dots,n</math>. In this case, it is always optimal to satisfy all of the demand from customer <math>j</math> from the nearest open facility. Because of this, we may replace the continuous variables <math>y_{ij}</math> from above with the binary variables <math>z_{ij}</math>, where <math>z_{ij}=1</math> if customer <math>j</math> is supplied by facility <math>i</math>, and <math>z_{ij}=0</math> otherwise. The '''uncapacitated facility location problem''' is then given by<math display=\"block\">\\begin{array}{rl}\n\\min & \\displaystyle\\sum_{i=1}^n\\sum_{j=1}^mc_{ij}z_{ij}+\\sum_{i=1}^nf_ix_i \\\\\n\\text{s.t.} & \\displaystyle\\sum_{i=1}^nz_{ij}=1 \\text{ for all }j=1,\\dots,m \\\\\n& \\displaystyle \\sum_{j=1}^mz_{ij}\\leqslant Mx_i\\text{ for all }i=1\\dots,n \\\\\n&z_{ij}\\in\\{0,1\\}\\text{ for all }i=1,\\dots,n \\text{ and }j=1,\\dots,m\\\\\n&x_i\\in\\{0,1\\}\\text{ for all } i=1,\\dots,n\n\\end{array}</math>\n\nwhere <math>M</math> is a constant chosen to be suitably large. The choice of <math>M</math> can affect computation results--the best choice in this instance is obvious: take <math>M=m</math>. Then, if <math>x_i=1</math>, any choice of the <math>z_{ij}</math> will satisfy the second set of constraints.\n\nAnother formulation possibility for the uncapacitated facility location problem is to ''disaggregate'' the capacity constraints (the big-<math>M</math> constraints). That is, replace the constraints<math display=\"block\">\\sum_{j=1}^{m}z_{ij}\\leqslant Mx_i\\text{ for all }i=1,\\dots,n</math>with the constraints<math display=\"block\">z_{ij}\\leqslant x_i\\text{ for all }i=1,\\dots,n \\text{ and }j=1,\\dots,m</math>In practice, this new formulation performs significantly better, in the sense that it has a tighter [[Linear programming]] relaxation than the first formulation.<ref name=\":0\" /> Notice that summing the new constraints together yields the original big-<math>M</math> constraints. In the capacitated case, these formulations are not equivalent. More information about the uncapacitated facility location problem can be found in Chapter 3 of \"Discrete location theory\".<ref>{{Cite book|url=https://www.worldcat.org/oclc/19810449|title=Discrete location theory|date=1990|publisher=Wiley|others=Mirchandani, Pitu B., Francis, R. L.|isbn=9780471892335|location=New York|oclc=19810449}}</ref>\n\n== Free software for solving facility location problems ==\n{| class=\"wikitable\"\n|-\n!Name<br>(alphabetically)\n!License\n!API language\n!Brief info\n|-\n|FLP Spreadsheet Solver||Creative Commons Attribution 4.0 International License|||| Microsoft Excel and VBA based open source solver for facility location problems, with a link to public GIS for data retrieval. [http://verolog.deis.unibo.it/flp-spreadsheet-solver link] Video tutorial [https://www.youtube.com/watch?v=_a7MbzzG9Hg link] <ref name=csoke>{{cite thesis |degree=M.Sc. |last=Csoke |first=Meghan |date=2015 |title=The Facility Location Problem |publisher=Governors State University|url=http://opus.govst.edu/theses/63/}}</ref>\n|-\n|ODL Studio||LGPL|||| Capacitated clusterer component in ODL Studio solves the P-median site location problem. The software includes mapping, reporting and Excel load/save. [http://www.opendoorlogistics.com/tutorials/]\n|-\n|SITATION||freeware|||| Can solve five classes of location problems including: P-median, P-center, Set Covering, Maximal Covering, and Uncapacitated Fixed Charge Problems. [http://daskin.engin.umich.edu/software/]<ref name=csoke />\n|}\nhttp://www.opendoorlogistics.com/tutorials/tutorial-territory-design/step-3-automated-territory-design/\n\n==Healthcare facility location==\n{{Expand section|date=November 2017}}\n\nLocation problems have widely been used in placing healthcare facilities. The recent review paper <ref name=\"Ahmadi\">{{Cite journal | doi = 10.1016/j.cor.2016.05.018| title = A Survey of Healthcare Facility Location| year = 2017| last1 = Ahmadi-Javid | first1 = A. | last2 = Seyedi | first2 = P. | last3 = Syam | first3 = S. | journal = Computers & Operations Research| volume = 79| pages = 223–263}}</ref> surveys studies on this topic.\n\n==See also==\n*[[Graph center]]\n*[[Quadratic assignment problem]]\n*[[Location-allocation]]\n*[[Dijkstra's algorithm]]\n*[[List of spatial analysis software]]\n*[[Competitive facility location game]]\n*[[Vertex k-center problem]]\n\n\n\n==References==\n{{reflist}}\n\n== External links ==\n*[[EWGLA]] [https://www.euro-online.org/ewgla/ EURO Working Group on Locational Analysis].\n*[[INFORMS]] [http://location.section.informs.org/ section on location analysis], a professional society concerned with facility location.\n*[http://gator.uhd.edu/~halet/ Bibliography on facility location] collected by [[Trevor Hale]], containing over 3400 articles.\n*[http://www.mathematik.uni-kl.de/~lola/ Library of location algorithms]\n*[http://sporkforge.com/opt/facility_locate.php Web-based facility location utility (single facility)]\n*[http://www.project-flo.de Facility Location Optimizer], a MATLAB-based tool for solving facility location problems.\n\n{{DEFAULTSORT:Facility Location}}\n[[Category:Mathematical optimization in business]]\n[[Category:Computational problems in graph theory]]"
    },
    {
      "title": "Glove problem",
      "url": "https://en.wikipedia.org/wiki/Glove_problem",
      "text": "{{multiple issues|\n{{technical|date=December 2016}}\n{{Orphan|date=May 2012}}\n}}\n\nIn [[operations research]], the '''glove problem'''<ref>{{MathWorld|title=Glove Problem|id=GloveProblem}}</ref> (also known as the '''condom problem'''<ref>Vardi, I. The Condom Problem. Ch. 10 in ''Computational Recreations in Mathematica''. Redwood City, CA: Addison&ndash;Wesley, pp.&nbsp;203&ndash;222, 1991. {{ISBN|0-201-52989-0}}.</ref>) is an [[optimization problem]] used as an example that the cheapest capital cost often leads to dramatic increase in operational time, but that the shortest operational time need not be given by the most expensive capital cost.<ref>{{cite book |first=A. |last=Hajnal |authorlink=András Hajnal |first2=L. |last2=Lovász |authorlink2=László Lovász |chapter=An Algorithm to Prevent the Propagation of Certain Diseases at Minimum Cost |title=Interfaces between Computer Science and Operations Research |editor=[[J. K. Lenstra]] |editor2=[[Alexander Rinnooy Kan|A. H. G. Rinnooy Kan]] |editor3=P. van Emde Boas |publisher=[[Mathematisch Centrum]] |year=1978}}</ref>\n\n==Problem statement==\n''M'' doctors are each to examine each of ''N'' patients, wearing [[glove]]s to avoid contamination. Each glove can be used any number of times, but the same side of one glove cannot be exposed to more than one person. Gloves can be re-used any number of times, and more than one can be used simultaneously.\n\nGiven ''M'' doctors and ''N'' patients, the minimum number of gloves ''G''(''M''&nbsp;,''N'') required for all the doctors to examine all the patients is given by:\n\n* ''G''(''M'',&nbsp;''N'') = ''M'' + ''N'' &minus; 2 if both ''M'',&nbsp;''N''&nbsp;≥&nbsp;2\n* ''G''(''M'',&nbsp;1) = ''M''\n* ''G''(1,&nbsp;''N'') = ''N''\n* ''G''(1,&nbsp;1) = 1\n\n==Details==\nA naive approach would be to estimate the number of gloves as simply ''G''(''M'',&nbsp;''N'') =&nbsp;''MN''. But this number can be significantly reduced by exploiting the fact that each glove has two sides, and it is not necessary to use both sides simultaneously.\n\nA better solution can be found by assigning each person his or her own glove, which is to be used for the entire operation. Every pairwise encounter is then protected by a double layer. Note that the outer surface of the doctors's gloves meets only the inner surface of the patients's gloves. This gives an answer of ''M''&nbsp;+&nbsp;''N'' gloves, which is significantly lower than&nbsp;''MN''.\n\nThe [[makespan]] with this scheme is ''K''&nbsp;·&nbsp;max(''M'',&nbsp;''N''), where ''K'' is the duration of one pairwise encounter. Note that this is exactly the same makespan if MN gloves were used. Clearly in this case, increasing capital cost has not produced a shorter operation time.\n\nThe number ''G''(''M'',&nbsp;''N'') may be refined further by allowing asymmetry in the initial distribution of gloves. The best scheme is given by:\n\n*Doctor # 1 wears ''N'' gloves, layered one on top of another. He visits the ''N'' patients in turn, leaving the outermost glove behind with each.\n*Doctors # 2 to (''M''&nbsp;&minus;&nbsp;1) wear one glove each, and follow the double-layered protocol at each interaction, as described above.\n*Doctor # ''M'' doesn't wear one of his own, but he visits all the ''N'' patients, collecting their gloves in turn and turning it into a multilayered glove progressively. Note that in his first encounter, he uses only the untouched inside of Patient #&nbsp;1's glove, so it's still safe.\n\nThis scheme uses (1&nbsp;·&nbsp;''N'')&nbsp;+&nbsp;((''M''&nbsp;&minus;&nbsp;1&nbsp;&minus;&nbsp;1)&nbsp;·&nbsp;1) + (1&nbsp;·&nbsp;0) =&nbsp;''M''&nbsp;+&nbsp;''N''&nbsp;&minus;&nbsp;2 gloves. This number cannot be reduced further.\n\nThe makespan is then given by:\n* ''N'' serial interactions to plant the gloves.\n* max(''M''&nbsp;&minus;&nbsp;2,&nbsp;''N'') parallelized interactions for intermediate stage.\n* ''N'' serial interactions to collect the gloves.\n\nMakespan: ''K''&nbsp;·&nbsp;(2''N''&nbsp;+&nbsp;max(''M''&nbsp;&minus;&nbsp;2,&nbsp;''N'')).\n\nClearly, the minimum ''G''(''M'', ''N'') increases the makespan significantly, sometimes by a factor of&nbsp;3. Note that the benefit in the number of gloves is only 2 units.\n\nOne or the other solution may be preferred depending on the relative cost of a glove judged against the longer operation time. In theory, the intermediate solution with (''M''&nbsp;+&nbsp;''N''&nbsp;&minus;&nbsp;1) should also occur as a candidate solution, but this requires such narrow windows on ''M'',&nbsp;''N'' and the cost parameters to be optimal that it is often ignored.\n\n==Other factors==\nThe statement of the problem does not make it clear that the principle of contagion applies, i.e. if the inside of one glove has been touched by the outside of another that previously touched some person, then that inside also counts as touched by that person.\n\nAlso, [[medical glove]]s are reversible; therefore a better solution exists, which uses\n\n: <math>\\min\\left(\\lceil M/2\\rceil+N, M+\\lceil N/2\\rceil\\right) </math>\n\ngloves where the less numerous group are equipped with a glove each, the more numerous in pairs.  The first of each pair use a clean interface, the second reverse the glove.{{Or|section|date=May 2012}}\n\n==References==\n{{reflist}}\n\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Intertemporal budget constraint",
      "url": "https://en.wikipedia.org/wiki/Intertemporal_budget_constraint",
      "text": "{{Multiple issues|{{unreferenced|date=June 2015}}{{technical|date=April 2015}}}}\n\nIn [[economics]] and [[finance]], an '''intertemporal budget constraint''' is a [[constrained optimization|constraint]] faced by a [[decision theory|decision maker]] who is making choices for both the present and the future. In its general form it says that the [[present value]] of current and future cash outflows cannot exceed the present value of currently available funds and future cash inflows. Typically this is expressed as\n\n:<math>\\sum_{t=0}^T \\frac{x_t}{(1+r)^t}  \\le \\sum_{t=0}^T \\frac{w_t}{(1+r)^t} ,</math>\n\nwhere <math>x_t </math> is expenditure at time ''t'', <math>w_t</math> is the cash that becomes available at time ''t'', ''T'' is the most distant relevant time period, 0 is the current time period, and <math>\\frac{1}{1+r}</math> is the [[discount factor]] computed from the interest rate ''r''.\n\nComplications are possible in various circumstances. For example, the [[interest rate]] for discounting cash receipts might be greater than the interest rate for discounting expenditures, because future inflows may be borrowed against while currently available funds may be invested temporarily pending use for future expenditures, and borrowing rates may exceed [[investment return]]s.\n\n==Applications==\n\nIn most applications, the entire budget would be used up, because any unspent funds would represent unobtained potential utility. In these situations, the intertemporal budget constraint is effectively an equality constraint.\n\nIn an [[intertemporal consumption]]  model, the sum of utilities from expenditures made at various times in the future, these [[discounted utility|utilities discounted back to the present]] at the consumer's rate of [[time preference]], would be maximized with respect to the amounts ''x''<sub>''t''</sub> consumed in each period, subject to an intertemporal budget constraint.\n\nIn a model of [[intertemporal portfolio choice]], the objective would be to maximize the [[expected value]] or [[expected utility]] of final period wealth. Since investment returns in each period generally would not be known in advance, the constraint effectively imposes a limit on the amount that can be invested in the final period&mdash;namely, whatever the wealth accumulated as of the end of the next-to-last period is.\n\n==See also==\n*[[Intertemporal choice]]\n\n[[Category:Constraint programming]]\n[[Category:Intertemporal economics]]\n[[Category:Mathematical finance]]\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Operations research",
      "url": "https://en.wikipedia.org/wiki/Operations_research",
      "text": "{{For|the academic journal|Operations Research (journal){{!}}Operations Research}}\n{{Use dmy dates|date=November 2011}}\n'''Operations research''' ({{lang-en-GB|'''operational research'''}}) ('''OR''') is a discipline that deals with the application of advanced analytical methods to help make better decisions.<ref>{{cite web|url=http://www.informs.org/About-INFORMS/About-Operations-Research |title=About Operations Research |publisher=INFORMS.org |accessdate=7 January 2012}}</ref> Further, the term '''operational analysis''' is used in the British (and some British Commonwealth) military as an intrinsic part of capability development, management and assurance.  In particular, operational analysis forms part of the Combined Operational Effectiveness and Investment Appraisals, which support British defense capability acquisition decision-making.\n\nIt is often considered to be a sub-field of [[applied mathematics]].<ref>{{cite web|url=http://www.mathontheweb.org/mathweb/mi-mathbyclass.html |title=Mathematics Subject Classification |publisher=American Mathematical Society |date= 23 May 2011 |accessdate=7 January 2012}}</ref>  The terms [[management science]] and [[decision science]] are sometimes used as synonyms.<ref>{{citation|title=Systems analysis for computer-based information systems|series=West series in data processing and information systems|first=James C.|last=Wetherbe|publisher=West Pub. Co.|year=1979|isbn=9780829902280|quotation=A systems analyst who contributes in the area of DSS must be skilled in such areas as management science (synonymous with decision science and operation research), modeling, simulation, and advanced statistics.}}</ref>\n\nEmploying techniques from other mathematical sciences, such as [[mathematical model]]ing, [[statistics|statistical analysis]], and [[mathematical optimization]], operations research arrives at optimal or near-optimal solutions to complex decision-making problems. Because of its emphasis on human-technology interaction and because of its focus on practical applications, operations research has overlap with other disciplines, notably [[industrial engineering]] and [[operations management]], and draws on [[psychology]] and [[Organizational studies|organization science]]. Operations research is often concerned with determining the extreme values of some real-world objective: the [[Maxima and minima|maximum]] (of profit, performance, or yield) or minimum (of loss, risk, or cost). Originating in military efforts before World War II, its techniques have grown to concern problems in a variety of industries.<ref name=\"hsor.org\">{{cite web|url=http://www.hsor.org/what_is_or.cfm |title=What is OR |publisher=HSOR.org |accessdate=13 November 2011}}</ref>\n<!--[[File:Operation research study 01.svg|thumb|480px|Model of Operation research study, based on Stafford Beer (1959).<ref>Stafford Beer (1959). ''Cybernetic and Management''. English Universities Press.</ref>]] -->\n\n==Overview==\nOperational research (OR) encompasses a wide range of problem-solving techniques and methods applied in the pursuit of improved decision-making and efficiency, such as [[simulation]], [[mathematical optimization]], [[queueing theory]] and other [[Stochastic process|stochastic-process]] models, [[Markov Decision Process|Markov decision processes]], [[Econometrics|econometric methods]], [[data envelopment analysis]], [[neural networks]], [[Expert System|expert systems]], [[decision analysis]], and the [[analytic hierarchy process]].<ref>{{cite web|url=http://www.bls.gov/oco/ocos044.htm |title=Operations Research Analysts |publisher=Bls.gov |accessdate=27 January 2012}}</ref> Nearly all of these techniques involve the construction of mathematical models that attempt to describe the system. Because of the computational and statistical nature of most of these fields, OR also has strong ties to [[computer science]] and [[analytics]]. Operational researchers faced with a new problem must determine which of these techniques are most appropriate given the nature of the system, the goals for improvement, and constraints on time and computing power.\n\nThe major sub-disciplines in modern operational research, as identified by the journal ''Operations Research'',<ref>{{cite web|url=http://www3.informs.org/site/OperationsResearch/index.php?c=10&kat=Forthcoming+Papers |title=OR / Pubs / IOL Home |publisher=INFORMS.org |date=2 January 2009 |accessdate=13 November 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20090527093022/http://www.informs.org/site/OperationsResearch/index.php?c=10&kat=Forthcoming+Papers |archivedate=27 May 2009 }}</ref> are:\n* Computing and information technologies\n* [[Financial engineering]]\n* [[Manufacturing]], [[service science]]s, and [[supply chain management]]\n* Policy modeling and public sector work\n* Revenue management\n* [[Simulation]]\n* [[Stochastics|Stochastic models]]\n* Transportation\n\n==History==\nIn the decades after the two world wars, the tools of operations research were more widely applied to problems in business, industry and society. Since that time, operational research has expanded into a field widely used in industries ranging from petrochemicals to airlines, finance, logistics, and government, moving to a focus on the development of mathematical models that can be used to analyse and optimize complex systems, and has become an area of active academic and industrial research.<ref name=\"hsor.org\"/>\n\n===Historical origins===\nIn the 17th century, mathematicians like [[Christiaan Huygens]] and [[Blaise Pascal]] ([[problem of points]]) tried to solve problems involving complex decisions with [[probability]]. Others in the 18th and 19th centuries solved these types of problems with [[combinatorics]]. [[Charles Babbage]]'s research into the cost of transportation and sorting of mail led to England's [[Uniform Penny Post|universal \"Penny Post\"]] in 1840, and studies into the dynamical behaviour of railway vehicles in defence of the [[Great Western Railway|GWR]]'s broad gauge.<ref>M.S. Sodhi, \"What about the 'O' in O.R.?\" OR/MS Today, December, 2007, p. 12, http://www.lionhrtpub.com/orms/orms-12-07/frqed.html</ref> Beginning in the 20th century, study of inventory management could be considered the origin of modern operations research with [[Economic order quantity|economic order quantity]] developed by [[Ford W. Harris]] in 1913. Operational research may have originated in the efforts of military planners during World War I (convoy theory and [[Lanchester's laws]]). [[Percy Bridgman]] brought operational research to bear on problems in physics in the 1920s and would later attempt to extend these to the social sciences.<ref>P. W. Bridgman, The Logic of Modern Physics, The MacMillan Company, New York, 1927</ref> \n\nModern operational research originated at the [[Telecommunications Research Establishment|Bawdsey Research Station]] in the UK in 1937 and was the result of an initiative of the station's superintendent, [[Albert Percival Rowe|A. P. Rowe]]. Rowe conceived the idea as a means to analyse and improve the working of the UK's [[early warning radar]] system, [[Chain Home]] (CH). Initially, he analysed the operating of the radar equipment and its communication networks, expanding later to include the operating personnel's behaviour. This revealed unappreciated limitations of the CH network and allowed remedial action to be taken.<ref>{{cite encyclopedia|url=http://www.britannica.com/EBchecked/topic/682073/operations-research/68171/History#ref22348 |title=operations research (industrial engineering) :: History – Britannica Online Encyclopedia |encyclopedia=Britannica.com |accessdate=13 November 2011}}</ref>\n\nScientists in the United Kingdom including [[Patrick Maynard Stuart Blackett|Patrick Blackett]] (later Lord Blackett OM PRS), [[Cecil Gordon (scientist)|Cecil Gordon]], [[Solly Zuckerman, Baron Zuckerman|Solly Zuckerman]], (later Baron Zuckerman OM, KCB, FRS), [[Conrad Hal Waddington|C. H. Waddington]], [[Owen Wansbrough-Jones]], [[Frank Yates]], [[Jacob Bronowski]] and [[Freeman Dyson]], and in the United States with [[George Dantzig]] looked for ways to make better decisions in such areas as [[logistics]] and training schedules\n\n===Second World War===\n\nThe modern field of operational research arose during World War II.{{dubious||what about \"[[Bawdsey Research Station|Telecommunications Research Establishment]] in 1937\" above?|date=March 2019}} In the World War II era, operational research was defined as \"a scientific method of providing executive departments with a quantitative basis for decisions regarding the operations under their control\".<ref name=C67-3-4-48-para-1>\"Operational Research in the British Army 1939–1945, October 1947, Report C67/3/4/48, UK National Archives file WO291/1301<br />Quoted on the dust-jacket of: Morse, Philip M, and Kimball, George E, ''Methods of Operation Research'', 1st edition revised, MIT Press & J Wiley, 5th printing, 1954.</ref> Other names for it included operational analysis (UK Ministry of Defence from 1962)<ref name=PROCATWO291>[http://www.nationalarchives.gov.uk/catalogue/displaycataloguedetails.asp?CATID=109&CATLN=2&Highlight=&FullDetails=True UK National Archives Catalogue for WO291] lists a War Office organisation called [[Army Operational Research Group]] (AORG) that existed from 1946 to 1962. \"In January 1962 the name was changed to Army Operational Research Establishment (AORE). Following the creation of a unified Ministry of Defence, a tri-service operational research organisation was established: the [[Defence Operational Research Establishment]] (DOAE) which was formed in 1965, and it the Army Operational Research Establishment based at West Byfleet.\"</ref> and quantitative management.<ref>http://brochure.unisa.ac.za/myunisa/data/subjects/Quantitative%20Management.pdf</ref>\n\nDuring the [[World War II|Second World War]] close to 1,000 men and women in Britain were engaged in operational research. About 200 operational research scientists worked for the [[British Army]].<ref>Kirby, [https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA117 p. 117] {{webarchive |url=https://web.archive.org/web/20130827004623/https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA117 |date=27 August 2013 }}</ref>\n\n[[Patrick Blackett]] worked for several different organizations during the war. Early in the war while working for the [[Royal Aircraft Establishment]] (RAE) he set up a team known as the \"Circus\" which helped to reduce the number of [[anti-aircraft artillery]] rounds needed to shoot down an enemy aircraft from an average of over 20,000 at the start of the [[Battle of Britain]] to 4,000 in 1941.<ref>Kirby, [https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA94 pp. 91–94] {{webarchive |url=https://web.archive.org/web/20130827041022/https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA94 |date=27 August 2013 }}</ref>\n\n[[File:B 24 in raf service 23 03 05.jpg|thumb|A [[Consolidated B-24 Liberator|Liberator]] in standard RAF green/dark earth/black night bomber finish as originally used by Coastal Command]]\nIn 1941, Blackett moved from the RAE to the Navy, after first working with [[RAF Coastal Command]], in 1941 and then early in 1942 to the [[Admiralty]].<ref>Kirby, [https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA109 p. 96,109] {{webarchive |url=https://web.archive.org/web/20131002032938/https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA109 |date=2 October 2013 }}</ref> Blackett's team at Coastal Command's Operational Research Section (CC-ORS) included two future [[Nobel prize]] winners and many other people who went on to be pre-eminent in their fields.<ref>Kirby, [https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA96 p. 96] {{webarchive |url=https://web.archive.org/web/20140327234509/https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA96 |date=27 March 2014 }}</ref> They undertook a number of crucial analyses that aided the war effort. Britain introduced the [[convoy]] system to reduce shipping losses, but while the principle of using warships to accompany merchant ships was generally accepted, it was unclear whether it was better for convoys to be small or large. Convoys travel at the speed of the slowest member, so small convoys can travel faster. It was also argued that small convoys would be harder for German [[U-boat]]s to detect. On the other hand, large convoys could deploy more warships against an attacker. Blackett's staff showed that the losses suffered by convoys depended largely on the number of escort vessels present, rather than the size of the convoy. Their conclusion was that a few large convoys are more defensible than many small ones.<ref>{{cite web|url=http://www.familyheritage.ca/Articles/victory1943.html |title=\"Numbers are Essential\": Victory in the North Atlantic Reconsidered, March–May 1943 |publisher=Familyheritage.ca |date=24 May 1943 |accessdate=13 November 2011}}</ref>\n\n<!-- [[WP:NFCC]] violation: [[File:Vickers Warwick B ASR Mk1 - BV285.jpg|thumb|A [[Vickers Warwick|Warwick]] in the revised RAF Coastal Command green/dark grey/white finish]] -->\n{{anchor|RAF Coastal Command's Operational Research Section}}\nWhile performing an analysis of the methods used by [[RAF Coastal Command]] to hunt and destroy submarines, one of the analysts asked what colour the aircraft were. As most of them were from Bomber Command they were painted black for night-time operations. At the suggestion of CC-ORS a test was run to see if that was the best colour to camouflage the aircraft for daytime operations in the grey North Atlantic skies. Tests showed that aircraft painted white were on average not spotted until they were 20% closer than those painted black. This change indicated that 30% more submarines would be attacked and sunk for the same number of sightings.<ref>Kirby, [https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA101 p. 101]</ref> As a result of these findings Coastal Command changed their aircraft to using white undersurfaces.\n\nOther work by the CC-ORS indicated that on average if the trigger depth of aerial-delivered [[depth charge]]s (DCs) were changed from 100 feet to 25 feet, the kill ratios would go up. The reason was that if a U-boat saw an aircraft only shortly before it arrived over the target then at 100 feet the charges would do no damage (because the U-boat wouldn't have had time to descend as far as 100 feet), and if it saw the aircraft a long way from the target it had time to alter course under water so the chances of it being within the 20-foot kill zone of the charges was small. It was more efficient to attack those submarines close to the surface when the targets' locations were better known than to attempt their destruction at greater depths when their positions could only be guessed. Before the change of settings from 100 feet to 25 feet, 1% of submerged U-boats were sunk and 14% damaged. After the change, 7% were sunk and 11% damaged; if submarines were caught on the surface but had time to submerge just before being attacked, the numbers rose to 11% sunk and 15% damaged. Blackett observed \"there can be few cases where such a great operational gain had been obtained by such a small and simple change of tactics\".<ref>(Kirby, [https://books.google.com/books?id=DWITTpkFPEAC&lpg=PA141&pg=PA103 pp. 102,103])</ref>\n\n[[File:Kammhuber Line Map - Agent Tegal.png|thumb|upright|left|Map of ''[[Kammhuber Line]]'']]\n{{anchor|RAF Bomber Command's Operational Research Section}}\nBomber Command's Operational Research Section (BC-ORS), analyzed a report of a survey carried out by [[RAF Bomber Command]].{{Citation needed|date=February 2007}} For the survey, Bomber Command inspected all bombers returning from bombing raids over Germany over a particular period. All damage inflicted by German [[Anti-aircraft warfare|air defences]] was noted and the recommendation was given that armour be added in the most heavily damaged areas. This recommendation was not adopted because the fact that the aircraft were able to return with these areas damaged indicated the areas were not vital, and adding armour to non-vital areas where damage is acceptable reduces aircraft performance. Their suggestion to remove some of the crew so that an aircraft loss would result in fewer personnel losses, was also rejected by RAF command. Blackett's team made the logical recommendation that the armour be placed in the areas which were completely untouched by damage in the bombers which returned. They reasoned that the survey was biased, since it only included aircraft that returned to Britain. The areas untouched in returning aircraft were probably vital areas, which, if hit, would result in the loss of the aircraft.<ref>{{cite book | title=Dirty Little Secrets of the Twentieth Century | publisher=[[Harper Paperbacks]] | author=James F. Dunnigan | year=1999 | pages=215–217}}</ref> This story has been disputed,<ref>http://lesswrong.com/lw/bbv/examine_your_assumptions/</ref> with a similar damage assessment study completed in the US by the Statistical Research Group at Columbia University,<ref>{{Cite journal|doi = 10.1080/01621459.1980.10477469|title = The Statistical Research Group, 1942–1945|journal = Journal of the American Statistical Association|volume = 75|issue = 370|pages = 320–330|year = 1980|last1 = Wallis|first1 = W. Allen}}</ref> the result of work done by [[Abraham Wald]]<ref>{{Cite journal|jstor = 2288257|title = Abraham Wald's Work on Aircraft Survivability|journal = Journal of the American Statistical Association|volume = 79|issue = 386|pages = 259|last1 = Mangel|first1 = Marc|last2 = Samaniego|first2 = Francisco J|doi = 10.2307/2288257|year = 1984}}</ref>.\n\nWhen Germany organized its air defences into the [[Kammhuber Line]], it was realized by the British that if the RAF bombers were to fly in a [[bomber stream]] they could overwhelm the night fighters who flew in individual cells directed to their targets by ground controllers. It was then a matter of calculating the statistical loss from collisions against the statistical loss from night fighters to calculate how close the bombers should fly to minimize RAF losses.<ref>{{cite web|url=http://www.raf.mod.uk/bombercommand/thousands.html |title=RAF History – Bomber Command 60th Anniversary |publisher=Raf.mod.uk |accessdate=13 November 2011}}</ref>\n\nThe \"exchange rate\" ratio of output to input was a characteristic feature of operational research. By comparing the number of flying hours put in by Allied aircraft to the number of U-boat sightings in a given area, it was possible to redistribute aircraft to more productive patrol areas. Comparison of exchange rates established \"effectiveness ratios\" useful in planning. The ratio of 60 [[Mine (naval)|mines]] laid per ship sunk was common to several campaigns: German mines in British ports, British mines on German routes, and United States mines in Japanese routes.<ref name=\"Proceedings\">{{cite journal|author=Milkman, Raymond H. |title=Operation Research in World War II |publisher=[[United States Naval Institute]] Proceedings |date=May 1968}}</ref>\n\nOperational research doubled the on-target bomb rate of [[B-29]]s bombing Japan from the [[Marianas Islands]] by increasing the training ratio from 4 to 10 percent of flying hours; revealed that wolf-packs of three United States submarines were the most effective number to enable all members of the pack to engage targets discovered on their individual patrol stations; revealed that glossy enamel paint was more effective camouflage for night fighters than traditional dull camouflage paint finish, and the smooth paint finish increased airspeed by reducing skin friction.<ref name=\"Proceedings\"/>\n\nOn land, the operational research sections of the Army Operational Research Group (AORG) of the [[Ministry of Supply]] (MoS) were landed in [[Operation Overlord|Normandy in 1944]], and they followed British forces in the advance across Europe. They analyzed, among other topics, the effectiveness of artillery, aerial bombing and anti-tank shooting.\n\n===After World War II===\n{{Expand section|date=March 2010}}\nWith expanded techniques and growing awareness of the field at the close of the war, operational research was no longer limited to only operational, but was extended to encompass equipment procurement, training, logistics and infrastructure. Operations Research also grew in many areas other than the military once scientists learned to apply its principles to the civilian sector. With the development of the [[simplex algorithm]] for [[linear programming]] in 1947<ref name=\"pitt.edu\">{{cite book|title=PRINCIPLES AND APPLICATIONS OF OPERATIONS RESEARCH |contribution=1.2 A HISTORICAL PERSPECTIVE|url=http://www.pitt.edu/~jrclass/or/or-intro.html#history}}</ref> and the development of computers over the next three decades, Operations Research can now \"solve problems with hundreds of thousands of variables and constraints. Moreover, the large volumes of data required for such problems can be stored and manipulated very efficiently.\"<ref name=\"pitt.edu\"/>\n\n==Problems addressed==\n* [[Critical path analysis]] or [[project planning]]: identifying those processes in a complex project which affect the overall duration of the project\n* [[Floorplanning]]: designing the layout of equipment in a factory or components on a [[computer chip]] to reduce [[manufacturing]] time (therefore reducing cost)\n* [[Telecommunications network|Network optimization]]: for instance, setup of telecommunications or power system networks to maintain quality of service during outages\n* Allocation problems\n* [[Facility location (optimization problem)|Facility location]]\n* Assignment Problems:\n** [[Assignment problem]]\n** [[Generalized assignment problem]]\n** [[Quadratic assignment problem]]\n** [[Weapon target assignment problem]]\n* [[Bayesian search theory]]: looking for a target\n* [[Search theory|Optimal search]]\n* [[Routing]], such as determining the routes of buses so that as few buses are needed as possible\n* [[Supply chain management]]: managing the flow of raw materials and products based on uncertain demand for the finished products\n* Project production activities: managing the flow of work activities in a capital project in response to system variability through operations research tools for variability reduction and buffer allocation using a combination of allocation of capacity, inventory and time<ref>“Factory Physics for Managers”, E. S. Pound, J. H. Bell, and M. L. Spearman, McGraw-Hill, 2014, p 47</ref><ref>“New Era of Project Delivery – Project as Production System”, R. G. Shenoy and T. R. Zabelle, Journal of Project Production Management, Vol 1,  pp Nov 2016, pp 13-24\n\n<nowiki>https://www.researchgate.net/publication/312602707_New_Era_of_Project_Delivery_-_Project_as_Production_System</nowiki>\n</ref>\n* Efficient messaging and customer response tactics\n* [[Automation]]: automating or integrating robotic systems in human-driven operations processes\n* [[Globalization]]: globalizing operations processes in order to take advantage of cheaper materials, labor, land or other productivity inputs\n* Transportation: managing [[freight]] transportation and delivery systems (Examples: [[Less than truckload shipping|LTL shipping]], [[intermodal freight transport]], [[travelling salesman problem]])\n* [[Scheduling (computing)|Scheduling]]:\n** [[Nurse scheduling problem|Personnel staffing]]\n** Manufacturing steps\n** [[Project management|Project tasks]]\n** Network data traffic: these are known as [[queueing model]]s or queueing systems.\n** Sports events and their television coverage\n* Blending of raw materials in oil refineries\n* Determining optimal prices, in many retail and B2B settings, within the disciplines of [[pricing science]]\n* [[Cutting stock problem]]: Cutting small items out of bigger ones.\n\nOperational research is also used extensively in government where [[evidence-based policy]] is used.\n\n==Management science==\n{{main|Management science}}\nIn 1967 [[Stafford Beer]] characterized the field of management science as \"the business use of operations research\".<ref>[[Stafford Beer]] (1967) ''Management Science: The Business Use of Operations Research''</ref> However, in modern times the term management science may also be used to refer to the separate fields of [[organizational studies]] or [[corporate strategy]].{{Citation needed|date=December 2010}} Like operational research itself, management science (MS) is an interdisciplinary branch of applied mathematics devoted to optimal decision planning, with strong links with economics, business, engineering, and other [[science]]s. It uses various [[science|scientific]] [[research]]-based principles, [[Strategy|strategies]], and [[analytical method]]s including [[mathematical model]]ing, statistics and [[numerical algorithm]]s to improve an organization's ability to enact rational and meaningful management decisions by arriving at optimal or near optimal solutions to complex decision problems. Management scientists help businesses to achieve their goals using the scientific methods of operational research.\n\nThe management scientist's mandate is to use rational, systematic, science-based techniques to inform and improve decisions of all kinds. Of course, the techniques of management science are not restricted to business applications but may be applied to military, medical, public administration, charitable groups, political groups or community groups.\n\nManagement science is concerned with developing and applying [[scientific modeling|models]] and [[concept]]s that may prove useful in helping to illuminate management issues and solve managerial problems, as well as designing and developing new and better models of organizational excellence.<ref name=\"LS\">[http://www.lums.lancs.ac.uk/departments/ManSci/DeptProfile/WhatisManSci/ What is Management Science?] {{webarchive|url=https://web.archive.org/web/20080914101120/http://www.lums.lancs.ac.uk/departments/ManSci/DeptProfile/WhatisManSci/ |date=14 September 2008 }} Lancaster University, 2008. Retrieved 5 June 2008.</ref>\n\nThe application of these models within the corporate sector became known as management science.<ref name=\"UTK\">[http://bus.utk.edu/soms/information/whatis_msci.html What is Management Science?] The University of Tennessee, 2006. Retrieved 5 June 2008.</ref>\n\n===Related fields===\nSome of the fields that have considerable overlap with Operations Research and Management Science include<ref>{{Cite journal |last1=Merigó |first1=José M |last2=Yang |first2=Jian-Bo |date=2017|title=A bibliometric analysis of operations research and management science |url=https://www.sciencedirect.com/science/article/pii/S0305048316309379 |journal=Omega - International Journal of Management Science | volume=73 | pages=37–48 |doi=10.1016/j.omega.2016.12.004 |issn=0305-0483}}</ref>:\n{{div col|colwidth=20em}}\n* [[Business analytics]]\n* [[Data mining]]/[[Data science]]/[[Big data]]\n* [[Decision analysis]]\n* [[Decision intelligence]]\n* [[Engineering]]\n* [[Financial engineering]]\n* [[Forecasting]]\n* [[Game theory]]\n* [[Geography]]/[[Geographic information science]]\n* [[Graph theory]]\n* [[Industrial engineering]]\n* [[Logistics]]\n* [[Mathematical modeling]]\n* [[Mathematical optimization]]\n* [[Probability and statistics]]\n* [[Project management]]\n* [[Policy analysis]]\n* [[Simulation]]\n* [[Social network]]/[[Transportation forecasting]] models\n* [[Stochastic processes]]\n* [[Supply chain management]]\n{{div col end}}\n\n===Applications===\nApplications are abundant such as in airlines, manufacturing companies, [[service organization]]s, military branches, and government. The range of problems and issues to which it has contributed insights and solutions is vast. It includes:<ref name=\"LS\"/>\n* Scheduling (of airlines, trains, buses etc.)\n* Assignment (assigning crew to flights, trains or buses; employees to projects; commitment and dispatch of power generation facilities)\n* Facility location (deciding most appropriate location for new facilities such as warehouse; factory or fire station)\n* Hydraulics & Piping Engineering (managing flow of water from reservoirs)\n* Health Services (information and supply chain management)\n* Game Theory (identifying, understanding; developing strategies adopted by companies)\n* Urban Design\n* Computer Network Engineering (packet routing; timing; analysis)\n* Telecom & Data Communication Engineering (packet routing; timing; analysis)\n<ref>http://nak-architecture.com/index.php/en/services/blog/55-urban-operations-research-uor</ref>\n\nManagement is also concerned with so-called 'soft-operational analysis' which concerns methods for [[strategic planning]], strategic [[decision support]], [[problem structuring methods]]. \nIn dealing with these sorts of challenges, mathematical [[modeling and simulation]] may not be appropriate or may not suffice. Therefore, during the past 30 years{{vague|date=November 2017}}, a number of non-quantified modeling methods have been developed. These include:{{Citation needed|date=June 2016}}\n* stakeholder based approaches including [[metagame analysis]] and [[drama theory]]\n* [[Morphological analysis (problem-solving)|morphological analysis]] and various forms of [[influence diagram]]s\n* cognitive mapping\n* strategic choice \n* robustness analysis\n\n==Societies and journals==\n===Societies===\nThe [[International Federation of Operational Research Societies]] (IFORS)<ref>{{cite web|url=http://www.ifors.org/ |title=IFORS |publisher=IFORS |accessdate=13 November 2011}}</ref> is an [[umbrella organization]] for operational research societies worldwide, representing approximately 50 national societies including those in the US,<ref>{{cite web|last=Leszczynski |first=Mary |url=http://www.informs.org/ |title=Informs |publisher=Informs |date=8 November 2011 |accessdate=13 November 2011}}</ref> [[Operational Research Society|UK]],<ref>{{cite web |url=http://www.orsoc.org.uk |title=The OR Society |publisher=Orsoc.org.uk |accessdate=13 November 2011 |deadurl=yes |archiveurl=http://webarchive.loc.gov/all/20060424161729/http://www.orsoc.org.uk/ |archivedate=24 April 2006 |df=dmy-all }}</ref> France,<ref>{{cite web|url=http://www.roadef.org/content/index.htm |title=Société française de Recherche Opérationnelle et d'Aide à la Décision |publisher=ROADEF |accessdate=13 November 2011}}</ref> Germany, [[Italian Operations Research Society|Italy]],<ref>{{cite web|author=www.airo.org |url=http://www.airo.org |title=AIRO |publisher=airo.org |accessdate=31 March 2018}}</ref> Canada,<ref>{{cite web|author=www.cors.ca |url=http://www.cors.ca |title=CORS |publisher=Cors.ca |accessdate=13 November 2011}}</ref> Australia,<ref>{{cite web|url=http://www.asor.org.au |title=ASOR |publisher=ASOR |date=1 January 1972 |accessdate=13 November 2011}}</ref> New Zealand,<ref>{{cite web|url=http://www.orsnz.org.nz/ |title=ORSNZ |publisher=ORSNZ |accessdate=13 November 2011}}</ref> Philippines,<ref>{{cite web|url=http://www.orsp.org.ph/ |title=ORSP |publisher=ORSP |accessdate=13 November 2011}}</ref> India,<ref>{{cite web|url=http://www.orsi.in/ |title=ORSI |publisher=Orsi.in |accessdate=13 November 2011}}</ref> Japan and South Africa.<ref>{{cite web|url=http://www.orssa.org.za/ |title=ORSSA |publisher=ORSSA |date=23 September 2011 |accessdate=13 November 2011}}</ref> The constituent members of IFORS form regional groups, such as that in Europe, the [[Association of European Operational Research Societies]] (EURO).<ref>{{cite web|url=http://www.euro-online.org/ |title=EURO (EURO) |publisher=Euro-online.org |accessdate=13 November 2011}}</ref> Other important operational research organizations are [[Simulation Interoperability Standards Organization]] (SISO)<ref>{{cite web|url=http://www.sisostds.org/ |title=SISO |publisher=Sisostds.org |accessdate=13 November 2011}}</ref> and [[Interservice/Industry Training, Simulation and Education Conference]] (I/ITSEC)<ref>{{cite web|url=http://www.iitsec.org/ |title=I/Itsec |publisher=I/Itsec |accessdate=13 November 2011}}</ref>\n\nIn 2004 the US-based organization INFORMS began an initiative to market the OR profession better, including a website entitled ''The Science of Better''<ref>{{cite web|url=http://www.scienceofbetter.org/ |title=The Science of Better |publisher=The Science of Better |accessdate=13 November 2011}}</ref> which provides an introduction to OR and examples of successful applications of OR to industrial problems. This initiative has been adopted by the [[Operational Research Society]] in the UK, including a website entitled ''Learn about OR''.<ref>{{cite web|url=http://www.learnaboutor.co.uk/ |title=Learn about OR |publisher=Learn about OR |accessdate=13 November 2011}}</ref>\n\n===Journals of INFORMS===\nThe [[Institute for Operations Research and the Management Sciences]] (INFORMS) publishes thirteen scholarly journals about operations research, including the top two journals in their class, according to 2005 [[Journal Citation Reports]].<ref>{{cite web|url=http://www.informs.org/index.php?c=31&kat=-+INFORMS+Journals |title=INFORMS Journals |publisher=Informs.org |accessdate=13 November 2011}}</ref> They are:\n* ''Decision Analysis''<ref>{{cite web |url=http://pubsonline.informs.org/journal/deca |title=Decision Analysis |publisher=Informs.org |accessdate=19 March 2015}}</ref>\n* ''Information Systems Research''<ref>{{cite web |url=http://pubsonline.informs.org/journal/isre |title=Information Systems Research |publisher=Informs.org |accessdate=19 March 2015}}</ref>\n* ''INFORMS Journal on Computing''<ref>{{cite web |url=http://pubsonline.informs.org/journal/ijoc |title=INFORMS Journal on Computing |publisher=Informs.org |accessdate=19 March 2015}}</ref>\n* ''INFORMS Transactions on Education''<ref>{{cite web |url=http://pubsonline.informs.org/journal/ited |title=INFORMS Transactions on Education |publisher=Informs.org |accessdate=19 March 2015}}</ref> (an open access journal)\n* ''Interfaces''<ref>{{cite web |url=http://pubsonline.informs.org/journal/inte |title=Interfaces |publisher=Informs.org |accessdate=19 March 2015}}</ref>\n* ''[[Management Science (journal)|Management Science]]''\n* ''[[Manufacturing & Service Operations Management]]''\n* ''[[Marketing Science (journal)|Marketing Science]]''\n* ''[[Mathematics of Operations Research]]''\n* ''[[Operations Research (journal)|Operations Research]]''\n* ''Organization Science''<ref>{{cite web |url=http://pubsonline.informs.org/journal/orsc |title=Organization Science |publisher=Informs.org |accessdate=19 March 2015}}</ref>\n* ''Service Science''<ref>{{cite web |url=http://pubsonline.informs.org/journal/serv |title=Service Science |publisher=Informs.org |accessdate=19 March 2015}}</ref>\n* ''[[Transportation Science]]''\n\n===Other journals===\nThese are listed in alphabetical order of their titles.\n* ''[[4OR]]-A Quarterly Journal of Operations Research'': jointly published the Belgian, French and Italian Operations Research Societies (Springer);\n* ''[[Decision Sciences]]'' published by [[Wiley-Blackwell]] on behalf of the [[Decision Sciences Institute]]\n* ''[[European Journal of Operational Research]] (EJOR)'': Founded in 1975 and is presently{{when|date=March 2019}} by far the largest operational research journal in the world, with its around 9,000 pages of published papers per year. In 2004, its total number of citations was the second largest amongst Operational Research and Management Science journals;\n* ''INFOR Journal'': published and sponsored by the Canadian Operational Research Society;\n* ''International Journal of Operations Research and Information Systems'' (IJORIS):  an official publication of the Information Resources Management Association, published quarterly by IGI Global;<ref>{{cite web|url=http://www.igi-global.com/Bookstore/TitleDetails.aspx?TitleId=1141 |title=International Journal of Operations Research and Information Systems (IJORIS) (1947–9328)(1947–9336): John Wang: Journals |publisher=IGI Global |accessdate=13 November 2011}}</ref>\n* ''Journal of Defense Modeling and Simulation (JDMS): Applications, Methodology, Technology'': a quarterly journal devoted to advancing the science of modeling and simulation as it relates to the military and defense.<ref>{{cite web|author=[[The Society for Modeling & Simulation International]] |url=http://www.scs.org/pubs/jdms/jdms.html |title=JDMS |publisher=Scs.org |accessdate=13 November 2011}}</ref>\n* ''[[Journal of the Operational Research Society]] (JORS)'': an official journal of [[The OR Society]]; this is the oldest continuously published journal of OR in the world, published by [[Taylor & Francis]];\n* ''Military Operations Research (MOR)'': published by the [[Military Operations Research Society]];\n* ''Omega - The International Journal of Management Science'';\n* ''Operations Research Letters'';\n* ''Opsearch'': official journal of the Operational Research Society of India;\n* ''OR Insight'': a quarterly journal of The OR Society, published by Palgrave;<ref name=\"The OR Society\">[http://www.orsoc.org.uk The OR Society] {{webarchive|url=http://webarchive.loc.gov/all/20060424161729/http://www.orsoc.org.uk/ |date=24 April 2006 }};</ref>\n* ''[[Production and Operations Management]]'', the official journal of the Production and Operations Management Society\n* ''TOP'': the official journal of the [[Spanish Statistics and Operations Research Society]].<ref>{{cite web|url=https://www.springer.com/east/home/business/operations+research?SGWID=5-40521-70-173677307-detailsPage=journal%7Cdescription |title=TOP |publisher=Springer.com |accessdate=13 November 2011}}</ref>\n\n==See also==\n{{Col-begin}}\n{{Col-break}}\n;Operations research topics\n* [[Black box|Black box analysis]]\n* [[Dynamic programming]]\n* [[Inventory theory]]\n* [[Optimal maintenance]]\n* [[Real options valuation]]\n{{Col-break}}\n;Operations researchers\n* [[:Category:Operations researchers|Operations researchers]] (category)\n* [[George Dantzig]]\n* [[Leonid Kantorovich]]\n* [[Tjalling Koopmans]]\n* [[Russell L. Ackoff]]\n* [[Stafford Beer]]\n* [[Alfred Blumstein]]\n* [[C. West Churchman]]\n{{Col-break}}\n* [[William W. Cooper]]\n* [[Robert Dorfman]]\n* [[Richard M. Karp]]\n* [[Ramayya Krishnan]]\n* [[Frederick W. Lanchester]]\n* [[Thomas L. Magnanti]]\n* [[Alvin E. Roth]]\n* [[Peter Whittle (mathematician)|Peter Whittle]]\n{{Col-break}}\n;Related fields\n* [[Behavioral operations research]]\n* [[Big data]]\n* [[Business engineering]]\n* [[Business process management]]\n* [[Database normalization]]\n* [[Engineering management]]\n* [[Geographic information system]]s\n* [[Industrial engineering]]\n* [[Industrial organization]]\n{{Col-break}}\n* [[Managerial economics]]\n* [[Military simulation]]\n* [[Power system simulation]]\n* [[Project Production Management]]\n* [[Reliability engineering]]\n* [[Scientific management]]\n* [[Search-based software engineering]]\n* [[Simulation modeling]]\n* [[System safety]]\n* [[Wargaming]]\n{{col-end}}\n\n==References==\n{{Reflist}}\n\n==Further reading==\n\n===Classic books and articles===\n* R. E. Bellman, ''Dynamic Programming'', Princeton University Press, Princeton, 1957\n* Abraham Charnes, William W. Cooper, ''Management Models and Industrial Applications of Linear Programming'', Volumes I and II, New York, John Wiley & Sons, 1961\n* Abraham Charnes, William W. Cooper, A. Henderson, ''An Introduction to Linear Programming'', New York, John Wiley & Sons, 1953\n* C. West Churchman, Russell L. Ackoff & E. L. Arnoff, ''Introduction to Operations Research'', New York: J. Wiley and Sons, 1957\n* George B. Dantzig, ''Linear Programming and Extensions'', Princeton, Princeton University Press, 1963\n* Lester K. Ford, Jr., D. Ray Fulkerson, ''Flows in Networks'', Princeton, Princeton University Press, 1962\n* Jay W. Forrester, ''Industrial Dynamics'', Cambridge, MIT Press, 1961\n* L. V. Kantorovich, \"Mathematical Methods of Organizing and Planning Production\" ''Management Science'', 4, 1960, 266–422\n* Ralph Keeney, Howard Raiffa, ''Decisions with Multiple Objectives: Preferences and Value Tradeoffs'', New York, John Wiley & Sons, 1976\n* H. W. Kuhn, \"The Hungarian Method for the Assignment Problem,\" ''Naval Research Logistics Quarterly'', 1–2, 1955, 83–97\n* H. W. Kuhn, A. W. Tucker, \"Nonlinear Programming,\" pp.&nbsp;481–492 in ''Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability''\n* B. O. Koopman, ''Search and Screening: General Principles and Historical Applications'', New York, Pergamon Press, 1980\n* Tjalling C. Koopmans, editor, ''Activity Analysis of Production and Allocation'', New York, John Wiley & Sons, 1951\n* Charles C. Holt, Franco Modigliani, John F. Muth, Herbert A. Simon, ''Planning Production, Inventories, and Work Force'', Englewood Cliffs, NJ, Prentice-Hall, 1960\n* Philip M. Morse, George E. Kimball, ''Methods of Operations Research'', New York, MIT Press and John Wiley & Sons, 1951\n* Robert O. Schlaifer, Howard Raiffa, ''Applied Statistical Decision Theory'', Cambridge, Division of Research, Harvard Business School, 1961\n\n===Classic textbooks===\n* Frederick S. Hillier & Gerald J. Lieberman, ''Introduction to Operations Research'', McGraw-Hill: Boston MA; 10th Edition, 2014\n* Taha, Hamdy A., \"Operations Research: An Introduction\", Pearson, 10th Edition, 2016\n* Robert J. Thierauf & Richard A. Grosse, \"Decision Making Through Operations Research\", John Wiley & Sons, INC, 1970\n* Harvey M. Wagner, ''Principles of Operations Research'', Englewood Cliffs, Prentice-Hall, 1969\n\n===History===\n* Saul I. Gass,  Arjang A. Assad, ''An Annotated Timeline of Operations Research:  An Informal History''. New York, Kluwer Academic Publishers, 2005.\n* Saul I. Gass (Editor), Arjang A. Assad (Editor), ''Profiles in Operations Research: Pioneers and Innovators''. Springer, 2011\n* Maurice W. Kirby (Operational Research Society (Great Britain)). Operational Research in War and Peace: The British Experience from the 1930s to 1970, Imperial College Press, 2003. {{isbn|1-86094-366-7}}, {{isbn|978-1-86094-366-9}}\n* J. K. Lenstra, A. H. G. Rinnooy Kan, A. Schrijver (editors) ''History of Mathematical Programming: A Collection of Personal Reminiscences'', North-Holland, 1991\n* Charles W. McArthur, ''Operations Analysis in the U.S. Army Eighth Air Force in World War II'', History of Mathematics, Vol. 4, Providence, American Mathematical Society, 1990\n* C. H. Waddington, ''O. R. in World War 2: Operational Research Against the U-boat'', London, Elek Science, 1973.\n\n==External links==\n{{Commons category|Operations research}}\n{{Wikiquote}}\n* [https://www.informs.org/Build-Your-Career/Consider-an-Analytics-OR-Career What is Operations Research?]\n* [http://www.ifors.org/ International Federation of Operational Research Societies]\n* [http://www.informs.org/ The Institute for Operations Research and the Management Sciences (INFORMS)]\n* [https://web.archive.org/web/20080509183835/http://stats.bls.gov/oco/ocos044.htm Occupational Outlook Handbook, U.S. Department of Labor Bureau of Labor Statistics]\n<!-- ==============================({{NoMoreLinks}})============================== -->\n<!-- DO NOT ADD MORE LINKS TO THIS ARTICLE. WIKIPEDIA IS NOT A COLLECTION OF LINKS -->\n<!-- If you think that your link might be useful, instead of placing it here, put -->\n<!-- it on this article's discussion page first. Links that have not been verified -->\n<!-- WILL BE DELETED -->\n<!-- ============================================================================= -->\n\n{{Systems}}\n{{Areas of mathematics |collapsed}}\n{{Microeconomics}}\n{{Authority control}}\n\n[[Category:Operations research| ]]\n[[Category:Industrial engineering]]\n[[Category:Mathematical optimization in business]]\n[[Category:Management science]]\n[[Category:Applied statistics]]\n[[Category:Engineering disciplines]]\n[[Category:Mathematical and quantitative methods (economics)]]\n[[Category:Mathematical economics]]"
    },
    {
      "title": "Process optimization",
      "url": "https://en.wikipedia.org/wiki/Process_optimization",
      "text": "{{nofootnotes|date=December 2011}}\n\n'''Process optimization''' is the discipline of adjusting a process so as to optimize (make the best or most effective use of) some specified set of parameters without violating some constraint.  The most common goals are minimizing cost and maximizing throughput and/or efficiency.  This is one of the major [[quantitative property|quantitative]] tools in industrial [[decision theory|decision making]].\n\nWhen [[optimization|optimizing]] a process, the goal is to maximize one or more of the process specifications, while keeping all others within their constraints. This can be done by using a [[process mining]] tool, discovering the critical activities and bottlenecks, and acting only on them.\n\n== Areas ==\nFundamentally, there are three parameters that can be adjusted to affect optimal performance.  They are:\n* Equipment optimization\nThe first step is to verify that the existing equipment is being used to its fullest advantage by examining operating data to identify equipment bottlenecks.\n\n* Operating procedures\nOperating procedures may vary widely from person-to-person or from shift-to-shift.  Automation of the plant can help significantly.  But automation will be of no help if the operators take control and run the plant in manual.\n\n* Control optimization\nIn a typical processing plant, such as a [[chemical plant]] or [[oil refinery]], there are hundreds or even thousands of control loops.  Each control loop is responsible for controlling one part of the process, such as maintaining a temperature, level, or flow.\n\nIf the [[control loop]] is not properly designed and tuned, the process runs below its optimum.  The process will be more expensive to operate, and equipment will wear out prematurely.  For each control loop to run optimally, identification of sensor, valve, and tuning problems is important.  It has been well documented that over 35% of control loops typically have problems.{{Fact|date=June 2008}}\n\nThe process of continuously monitoring and optimizing the entire plant is sometimes called performance supervision.\n\n== See also ==\n* [[Calculation of glass properties]], optimization of several properties\n* [[Deficit irrigation]] to optimize water productivity\n* [[Process simulation]]\n* [[Taguchi methods]]\n\n==External links==\n* [http://Nutek-us.com/wp-txt.html Reference TEXTBOOKS on Taguchi Methods]\n* [http://rtime.felk.cvut.cz/scheduling-toolbox TORSCHE Scheduling Toolbox for Matlab] is a freely available toolbox of scheduling and graph algorithms.\n* [http://www.hillstormer.es HillStormer, a Tool for constrained Optimization by Nelder & Mead in Industry and Research.]\n[[Category:Business process management]]\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Reverse logistics network modelling",
      "url": "https://en.wikipedia.org/wiki/Reverse_logistics_network_modelling",
      "text": "{{Multiple issues|\n{{Orphan|date=June 2015}}\n{{cleanup|reason=Doesn't follow the Manuel of Style|date=June 2015}}\n}}\n\n'''Reverse logistics''' is for all operations related to the reuse of products and materials. It is \"the process of moving [[good (economics)|goods]] from their typical final destination for the purpose of capturing value, or proper disposal. [[Remanufacturing]] and [[Refurbishment (electronics)|refurbishing]] activities also may be included in the definition of reverse logistics.\"<ref>Hawks, Karen. [http://www.rlmagazine.com/edition01p12.php \"What is Reverse Logistics?\"], ''Reverse Logistics Magazine'', Winter/Spring 2006.</ref>\n \nIn order to model reverse logistics network from an economics point of view, the following simplified reverse logistics system has to be set.\n\nIn this model the products are gathered from the consumers and transferred back to the producers, hence the direction of the flow in the distribution supply chain is reversed and the model is expanded with the recovery center. First of all the used products are collected from the consumers and moved to the recovery center, where the condition of the products are examined according to their end of life cycle. If there is still recapture value, then the product is disassembled as preparation for further reprocessing, which means physical transformation to new customer. Otherwise the used product is disposed and transferred to the landfill site.<ref name=\"Moritz (2001)\">{{cite web|last1=Fleischmann|first1=Moritz|title=Reverse logistics network structures and design|url=http://www2.eur.nl/WebDOC/doc/erim/erimrs20010919163815.pdf|publisher=Journal of Economic  Literature|accessdate=3 June 2015}}{{dead link|date=April 2018 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>  According to the introduced model the main differences between forward and reverse logistics can be identified:\t\n* Uncertainty on the quantity, quality and timing \n* Complex system due to more participants and more interactions \n* Mismatch between demand and supply occurs \n* Unexplored market opportunities but the low value of return flow means a limit<ref name=\"Grabara et al (2009)\">{{cite web|last1=Grabara|first1=Janusz K|title=THEORETICAL FRAMES FOR DESIGNING REVERSE LOGISTICS  PROCESSES|url=http://www.managementgeneral.ro/pdf/1_2009_5.pdf|website=Review of General Management|accessdate=3 June 2015}}</ref>\n\n==Modeling techniques for optimizing in reverse logistics network==\nIn case of a reverse logistics network the nodes represent the different kind of facilities such as the manufacturers, distribution centers, recovery centers, ware houses. The opening of a facility is marked with a binary integer number. The links are acted for flow between facilities and the weights are continuous variables showing the quantity of flow. The two common way of designing reverse logistics network are the Mixed Integer Linear Programing (MILP) and Mixed Integer Non-Linear Programing (MINLP) methods, where the objective function, decision variables and constraint have to be defined\n\n=== Mixed Integer Linear Programing (MILP) ===\n\n==== Remanufacturing model ====\nThis model is a two-level location problem with three type of facilities, integrated forward and reverse flow of goods. It means that the used items are gathered from consumers, transported back to plants and after remanufacturing get into the logistics network of new products.\nObjective function: \n* minimizing linear cost function including fix and variable costs\nDecision variables: \n* location of manufacturer and distribution centeramount of production demand\n* quantity of returned used products\nConstraints: \n* satisfaction of the demand\n* opening of facilities\n\n==== Refurbishment model ====\nThis model take into account just reverse flow of goods.\nObjective function: \n* minimizing linear cost function incorporating fix cost of settling sites and transportation cost of returning goods\nDecision variables: \n* location of collector and refurbishing site\n* fraction of transported products to refurbishing site\nConstraints: \n* capacity\n* opening of facilities\n* maximum and minimum number of sites to be open in order uninterrupted flow\n\n==== Generic reverse logistics network model ====\nObjective function: \n* minimizing linear total cost function encompassing fix cost of facilities (plant, warehouse, disassembly locations), transportation cost and processing cost (recycling, disassembly, disposal, inventory)\nDecision variables:\t\n* identification of facilities to be opened\n* quantity of transported products between facilities\nConstraints:\n* number of facilities\n* opening of facilities\n* demand and capacity satisfaction\n* flow and inventory constraints\nThis model can be further developed by introducing penalty cost for not collecting returned items and a compulsory minimal disposal fraction as a feasibility technical constraints of reuse. Moreover, the static approach can be partly eliminated by multi-period programming, as a result trade-off between investment and operational cost and long run effect can be analyzed.\n\n=== Mixed Integer Non-Linear Programing (MINLP) ===\nThe most severe drawback of MILP is the static aspect, hence MINLP try to relieve these restriction and develop further the existing model with dynamic elements, such as integrating cycle time, time and inventory positions. By this way uncertainty appears stronger in the model. The main objective is to maximize profit by determining the optimal number of facilities in order to:\n* collection point be close to the consumers\n* returning process be simple\n* collection period be appropriate\n\n== Manage uncertainty in reverse logistics networks==\n* ''Sensitivity analysis:'' Through sensitivity analysis it can be tested how the output of the model will be changed if the decision variables such as the returned amount, number of disassembly and cost are varying.\n* ''Scenario analysis:'' The process is about generating scenarios for input parameters and calculate optimal solution at each case.\n* ''Robust optimization:'' This method is calibrating the model in that way to minimize the deviation of the values of the objective function at each scenario. Tis process is more elaborated, than scenario analysis and a good substitute of stochastic programming when there is lack of quality information\n* ''Stochastic programming:'' Mathematical programming technique. It applies probability distribution instead of deterministic number. It is a two-stage process, where at the first stage the decision binary variables, representing openness are determined, then happens the random events and finally at the second stage recourse (flow) actions ensures the justification of the formerly set constraints\n\n== Solution techniques of reverse logistics network models ==\n\n===Genetic algorithm===\nIt is applicable for large size complex problems\nMain steps of the algorithm: \n* objective function: minimize a combination of overall costs\n* identifying the number of facilities their locations, capacities, and topology of the network.\n* encoding scheme selected is a binary coded string reflecting one-gene-one facility correspondence on a linear string, whose substrings represent different types of facilities\n\n===Tabu search===\nThe algorithm pursues local search and if it finds a local optimum it is prevented to get back formerly visited solution, which were recorded in the so-called tabu list<ref name=\"Hamady et al (2007)\">{{cite web|last1=Elwany |first1=Hamdy |title=Reverse logistics network design: Review of models and solution techniques |url=https://www.academia.edu/725829/REVERSE_LOGISTICS_NETWORK_DESIGN_REVIEW_OF_MODELS_AND_SOLUTION_TECHNIQUES|website=academia.edu|accessdate=3 June 2015}}</ref>\n\n== Notes ==\n{{Reflist}}\n\n\n\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Secretary problem",
      "url": "https://en.wikipedia.org/wiki/Secretary_problem",
      "text": "The '''secretary problem''' is a problem that demonstrates a scenario involving [[optimal stopping]] theory.<ref name=\"Hill2009\">{{Cite journal | first1 = Theodore P. | last1 = Hill| authorlink1 = Theodore P. Hill | doi = 10.1511/2009.77.126 | title = Knowing When to Stop | journal = [[American Scientist]] | year = 2009 | volume = 97 | issue = 2| pages = 126–133 | issn = 1545-2786  | pmid =  | pmc = | via = (For French translation, see [https://web.archive.org/web/20110721020330/http://www.pourlascience.fr/ewb_pages/f/fiche-article-savoir-quand-s-arreter-22670.php cover story] in the July issue of ''Pour la Science'' (2009)) }}</ref> The problem has been studied extensively in the fields of [[applied probability]], [[statistics]], and [[decision theory]]. It is also known as the '''marriage problem''', the '''sultan's dowry problem''', the '''fussy suitor problem''', the '''googol game''', and the '''best choice problem'''.\n\nThe basic form of the problem is the following: imagine an administrator who wants to hire the best secretary out of <math>n</math> rankable applicants for a position. The applicants are interviewed one by one in random order. A decision about each particular applicant is to be made immediately after the interview. Once rejected, an applicant cannot be recalled. During the interview, the administrator gains information sufficient to rank the applicant among all applicants interviewed so far, but is unaware of the quality of yet unseen applicants. The question is about the optimal strategy ([[stopping rule]]) to maximize the probability of selecting the best applicant. If the decision can be deferred to the end, this can be solved by the simple maximum [[selection algorithm]] of tracking the running maximum (and who achieved it), and selecting the overall maximum at the end. The difficulty is that the decision must be made immediately.\n\nThe problem has an elegant solution, and the shortest rigorous proof known so far is provided by the [[odds algorithm]] (Bruss 2000). An easy analysis implies that the optimal win probability is always at least <math>1/e</math> (where ''[[e (mathematical constant)|e]]'' is the base of the [[natural logarithm]]), and that the latter holds even in a much greater generality (2003). The optimal stopping rule prescribes always rejecting the first <math> \\sim n/e</math> applicants that are interviewed and then stopping at the first applicant who is better than every applicant interviewed so far (or continuing to the last applicant if this never occurs).  Sometimes this strategy is called the <math>1/e</math> stopping rule, because the probability of stopping at the best applicant with this strategy is about <math>1/e</math> already for moderate values of <math>n</math>. One reason why the secretary problem has received so much attention is that the optimal policy for the problem (the stopping rule) is simple and selects the single best candidate about 37% of the time, irrespective of whether there are 100 or 100 million applicants. \n\n==Formulation==\nAlthough there are many variations, the basic problem can be stated as follows:\n\n* There is a single position to fill. \n* There are ''n'' applicants for the position, and the value of ''n'' is known.\n* The applicants, if seen altogether, can be ranked from best to worst unambiguously.\n* The applicants are interviewed sequentially in random order, with each order being equally likely.\n* Immediately after an interview, the interviewed applicant is either accepted or rejected, and the decision is irrevocable.\n* The decision to accept or reject an applicant can be based only on the relative ranks of the applicants interviewed so far.\n* The objective of the general solution is to have the highest probability of selecting the best applicant of the whole group.  This is the same as maximizing the expected payoff, with payoff defined to be one for the best applicant and zero otherwise.\n\nTerminology: A ''candidate'' is defined as an applicant who, when interviewed, is better than all the applicants interviewed previously. ''Skip'' is used to mean \"reject immediately after the interview\".\n\nClearly, since the objective in the problem is to select the single best applicant, only candidates will be considered for acceptance. The \"candidate\" in this context corresponds to the concept of record in permutation.\n\n==Deriving the optimal policy==\nThe optimal policy for the problem is a [[stopping rule]]. Under it, the interviewer rejects the first ''r''&nbsp;−&nbsp;1 applicants (let applicant ''M'' be the best applicant among these ''r''&nbsp;−&nbsp;1 applicants), and then selects the first subsequent applicant that is better than applicant ''M''. It can be shown that the optimal strategy lies in this class of strategies.{{citation needed|date=June 2016}} For an arbitrary  cutoff ''r'', the probability that the best applicant is selected is\n\n:<math>\n\\begin{align}\nP(r)\n&= \\sum_{i=1}^{n}\nP\\left(\\text{applicant } i \\text{ is selected} \\cap \\text{applicant } i \\text{ is the best}\\right)\n\\\\\n&= \\sum_{i=1}^{n}\nP\\left(\\text{applicant } i \\text{ is selected} | \\text{applicant } i \\text{ is the best}\\right) \\cdot\nP\\left(\\text{applicant } i \\text{ is the best}\\right)\n\\\\\n&= \\left[ \\sum_{i=1}^{r-1} 0\n+ \\sum_{i=r}^{n} P\\left( \\left.\n\\begin{array}{l}\n\\text{the best of the first } i - 1 \\text{ applicants} \\\\\n\\text{is in the first } r-1 \\text{ applicants}\n\\end{array} \\right|  \\text{applicant } i \\text{ is the best}\n\\right) \\right] \\cdot \\frac{1}{n}\n\\\\\n&= \\left[\\sum_{i=r}^{n} \\frac{r-1}{i-1}\\right] \\cdot \\frac{1}{n}\n\\quad=\\quad \\frac{r-1}{n} \\sum_{i=r}^{n} \\frac{1}{i-1}.\n\\end{align}\n</math>\n\nThe sum is not defined for ''r'' = 1, but in this case the only feasible policy is to select the first applicant, and hence ''P''(1) = 1/''n''.\n\nThis sum is obtained by noting that if applicant ''i'' is the best applicant, then it is selected if and only if the best applicant among the first ''i''&nbsp;−&nbsp;1 applicants is among the first ''r''&nbsp;−&nbsp;1 applicants that were rejected.\n\nLetting ''n'' tend to infinity, writing <math>x</math> as the limit of ''(r-1)''/''n'', using ''t'' for ''(i-1)''/''n'' and ''dt'' for 1/''n'', the sum can be approximated by the integral\n\n:<math>\nP(x)=x \\int_{x}^{1}\\frac{1}{t}\\,dt = -x \\ln(x)\\;.\n</math>\n:\n\nTaking the derivative of ''P''(''x'') with respect to <math>x</math>, setting it to 0, and solving for ''x'', we find that the optimal ''x'' is equal to 1/''e''.  Thus, the optimal cutoff tends to ''n''/''e'' as ''n'' increases, and the best applicant is selected with probability 1/''e''.\n\nFor small values of ''n'', the optimal ''r'' can also be obtained by standard [[dynamic programming]] methods. The optimal thresholds ''r'' and probability of selecting the best alternative ''P'' for several values of ''n'' are shown in the following table.\n\n{| class=\"wikitable\"\n|-\n! <math>n</math>\n! 1\n! 2\n! 3\n! 4\n! 5\n! 6\n! 7\n! 8\n! 9\n|-\n| <math>r</math>\n| 1\n| 1\n| 2\n| 2\n| 3\n| 3\n| 3\n| 4\n| 4\n|-\n| <math>P</math>\n| 1.000\n| 0.500\n| 0.500\n| 0.458\n| 0.433\n| 0.428\n| 0.414\n| 0.410\n| 0.406\n|}\n\nThe probability of selecting the best applicant in the classical secretary problem converges  toward <math>1/e\\approx 0.368</math>.\n\n==Alternative solution==\nThis problem and several modifications can be solved (including the proof of optimality) in a straightforward manner by the [[Odds algorithm]] (2000), which also has other applications. Modifications for the secretary problem that can be solved by this algorithm include random availabilities of applicants, more general hypotheses for applicants to be of interest to the decision maker, group interviews for applicants, as well as ''certain'' models for a random number of applicants. \n\n==Applicability in real life==\nThe solution of the secretary problem is of course only meaningful if it is justified to assume that the applicants have no knowledge of the decision strategy employed, because early applicants have no chance at all and may not show up otherwise. \n\nThere are also numerous other assumptions involved in the problem that restrict its applicability in modelling real employment decisions. For one, it is rarely the case that hiring the second-best applicant is as bad as hiring the worst. For another, it is also probably rare that interviewing an applicant gives us perfect information on how they rank with respect to the previous applicants, but leave us without a clue as to whether they are likely better than the remaining ones. \n\nOne important drawback for applications of the solution of the classical secretary problem is that the number of applicants <math> n </math> must be known in advance which is rarely the case.  One way to overcome this problem is to suppose that the number of applicants is a random variable <math>N </math> with a known distribution of  <math>P(N=k)_{k=1,2,\\cdots} </math> (Presman and Sonin, 1972). For this model, the optimal solution is in general much harder, however. Moreover, the optimal success probability is now no longer around 1/''e'' but typically lower. Indeed, it is intuitive that there should be a price to pay for not knowing the number of applicants. However, in this model the price is high. Depending on the choice of the distribution of <math>N</math>, the optimal win probability may even approach zero. Looking for ways to cope with this new problem led to a new model yielding the so-called 1/e-law of best choice.\n\n==1/e-law of best choice==\nThe essence of the model is based on the idea that life is sequential and that real-world problems pose themselves in real time. Also, it is easier to estimate times in which specific events (arrivals of applicants) should occur more likely (if they do) than to estimate the distribution of the number of specific events which will occur. This idea led to the following approach, the so-called '''unified approach''' (1984):\n\n'''The model''': An applicant must be selected on some time interval <math>[0,T]</math> from an unknown number <math> N</math> of rankable applicants. The goal is to maximize the probability of selecting only the best under the hypothesis that all arrival orders of different ranks are equally likely. Suppose that all applicants have the same, but independent to each other, arrival time density <math>f</math> on <math>[0,T]</math> and let  <math>F</math> denote the corresponding arrival time distribution function, that is\n\n: <math>F(t) = \\int_{0}^{t} f(s)ds </math>, <math>\\, 0\\le t\\le T</math>.\n\n'''1/e-law''':  Let <math>\\tau</math> be such that <math> F(\\tau)=1/e.</math> Consider the strategy to wait and observe all applicants up to time <math>\\tau </math> and then to select, if possible, the first candidate after time <math>\\tau </math> which is better than all preceding ones. Then this strategy, called ''1/e-strategy'', has the following properties:\n\nThe ''1/e-strategy''\n\n:(i)  yields for all <math>N</math> a success probability of at least 1/e,\n\n:(ii) is the unique strategy guaranteeing this lower success probability bound 1/e, and the bound is optimal,\n\n:(iii) selects, if there is at least one applicant, none at all with probability exactly 1/e.\n\nThe 1/e-law, proved in 1984 by [[F. Thomas Bruss]], came as a surprise. The reason was that a value of about 1/e had been considered before as being out of reach in a model for unknown <math> N </math>, whereas this value 1/e  was now achieved as a lower bound for the success probability, and this in a model with arguably much weaker hypotheses (see e.g. Math. Reviews 85:m).\n\nThe 1/e-law is sometimes confused with the solution for the classical secretary problem described above because of the similar role of the number 1/e. However, in the 1/e-law, this role is more general. The result is also stronger, since it holds for an '''unknown''' number of applicants and since the model based on an arrival time distribution F is more tractable for applications.\n\n==The game of googol==\nAccording to {{harvnb|Ferguson|1989}}, the secretary problem appeared for the first time in print when it was featured by [[Martin Gardner]] in his February 1960 [[Mathematical Games column]] in ''[[Scientific American]]''.<ref>[https://www.math.upenn.edu/~ted/210F10/References/Secretary.pdf Who Solved the Secretary Problem?] by Thomas S. Ferguson, [[Statistical Science]], 1989, Vol. 4, No. 3, 282-296</ref> Here is how Gardner formulated it: \"Ask someone to take as many slips of paper as he pleases, and on each slip write a different positive number. The numbers may range from small fractions of 1 to a number the size of a ''googol'' (1 followed by a hundred 0s) or even larger. These slips are turned face down and shuffled over the top of a table. One at a time you turn the slips face up. The aim is to stop turning when you come to the number that you guess to be the largest of the series. You cannot go back and pick a previously turned slip. If you turn over all the slips, then of course you must pick the last one turned.\"\n\nIn the article \"Who solved the Secretary problem?\" {{harvnb|Ferguson|1989}} pointed out that the secretary problem remained unsolved as it was stated by M. Gardner, that is as a two-person [[zero-sum game]] with two antagonistic players. In this game Alice, the informed player, writes secretly distinct numbers on <math>n</math> cards. Bob,  the stopping player, observes the actual values and can stop turning cards whenever he wants, winning if the last card turned has the overall maximal number. The difference with the basic secretary problem is that Bob observes the actual values written on the cards, which he can use in his decision procedures. The numbers on cards are analogous to the numerical qualities of applicants in some versions of the secretary problem. The [[joint probability distribution]] of the numbers is under the control of Alice.\n\nBob wants to guess the maximal number with the highest possible probability, while Alice's goal is to keep this probability as low as possible. It is not optimal for Alice to sample the numbers independently from some fixed distribution, and she can play better by choosing random numbers in some dependent way. For <math>n=2</math> Alice has no [[minimax]] strategy, which is closely related to a paradox of [[Thomas M. Cover|T. Cover]]. But for <math>n>2</math> the game has a solution: Alice can choose random numbers (which are dependent random variables) in such a way that Bob cannot play better than using the classical stopping strategy based on the relative ranks ({{harvnb|Gnedin|1994}}).\n\n==Heuristic performance==\nThe remainder of the article deals again with the secretary problem for a known number of applicants.\n\n[[Image:SecretaryProblemHeuristicPlot.png|thumb|Expected success probabilities for three heuristics.|300px|right|Expected success probabilities for three heuristics.]]\n\n{{harvnb|Stein|Seale|Rapoport|2003}} derived the expected success probabilities for several psychologically plausible heuristics that might be employed in the secretary problem. The heuristics they examined were:\n* '''The cutoff rule (CR):''' Do not accept any of the first ''y'' applicants; thereafter, select the first encountered candidate (i.e., an applicant with relative rank 1). This rule has as a special case the optimal policy for the classical secretary problem for which ''y''&nbsp;=&nbsp;''r''.\n* '''Candidate count rule (CCR):''' Select the ''y'' encountered candidate. Note, that this rule does not necessarily skip any applicants; it only considers how many candidates have been observed, not how deep the decision maker is in the applicant sequence.\n* '''Successive non-candidate rule (SNCR):''' Select the first encountered candidate after observing ''y'' non-candidates (i.e., applicants with relative rank&nbsp;>&nbsp;1).\n\nNote that each heuristic has a single parameter ''y''. The figure (shown on right) displays the expected success probabilities for each heuristic as a function of ''y'' for problems with ''n''&nbsp;=&nbsp;80.\n\n==Cardinal payoff variant==\nFinding the single best applicant might seem like a rather strict objective. One can imagine that the interviewer would rather hire a higher-valued applicant than a lower-valued one, and not only be concerned with getting the best. That is, the interviewer will derive some value from selecting an applicant that is not necessarily the best, and the derived value increases with the value of the one selected.\n\nTo model this problem, suppose that the <math>n</math> applicants have \"true\" values that are [[random variable]]s ''X'' drawn [[i.i.d.]] from a [[Uniform distribution (continuous)|uniform distribution]] on [0,&nbsp;1]. Similar to the classical problem described above, the interviewer only observes whether each applicant is the best so far (a candidate), must accept or reject each on the spot, and ''must'' accept the last one if he/she is reached. (To be clear, the interviewer does not learn the actual relative rank of ''each'' applicant. He/she learns only whether the applicant has relative rank 1.) However, in this version the ''payoff'' is given by the true value of the selected applicant. For example, if he/she selects an applicant whose true value is 0.8, then he/she will earn 0.8. The interviewer's objective is to maximize the expected value of the selected applicant.\n\nSince the applicant's values are i.i.d. draws from a uniform distribution on [0,&nbsp;1], the [[expected value]] of the ''t''th applicant given that <math>x_{t}=\\max\\left\\{x_1, x_2, \\ldots, x_t\\right\\}</math> is given by\n\n:<math>\nE_{t}=E\\left(X_{t}|I_{t}=1\\right)=\\frac{t}{t+1}.\n</math>\n\nAs in the classical problem, the optimal policy is given by a threshold, which for this problem we will denote by <math>c</math>, at which the interviewer should begin accepting candidates. {{harvnb|Bearden|2006}} showed that ''c'' is either <math>\\lfloor \\sqrt n \\rfloor</math> or <math>\\lceil \\sqrt n \\rceil</math>. (In fact, whichever is closest to <math> \\sqrt n </math>.) This follows from the fact that given a problem with <math>n</math> applicants, the expected payoff for some arbitrary threshold <math>1 \\le c \\le n</math> is\n\n:<math>\nV_{n}(c)=\\sum_{t=c}^{n-1}\\left[\\prod_{s=c}^{t-1}\\left(\\frac{s-1}{s}\\right)\\right]\\left(\\frac{1}{t+1}\\right)\n+\\left[\\prod_{s=c}^{n-1}\\left(\\frac{s-1}{s}\\right)\\right]\\frac{1}{2}={\\frac {2cn-{c}^{2}+c-n}{2cn}}.\n</math>\n\nDifferentiating <math> V_{n}(c)</math> with respect to ''c'', one gets\n\n: <math>\\frac{\\partial V}{\\partial c} = \\frac{ -{c}^{\\,2}+n }{ 2{c}^{\\,2}n }.</math>\n\nSince <math>\\partial^{\\,2}V / \\partial c^{\\,2}<0</math> for all permissible values of <math>c</math>, we find that <math>V</math> is maximized at <math>c=\\sqrt n</math>. Since ''V'' is convex in <math>c</math>, the optimal integer-valued threshold must be either <math>\\lfloor \\sqrt n \\rfloor</math> or <math>\\lceil \\sqrt n \\rceil</math>. Thus, for most values of <math>n</math> the interviewer will begin accepting applicants sooner in the cardinal payoff version than in the classical version where the objective is to select the single best applicant. Note that this is not an asymptotic result: It holds for all <math>n</math>. However it should also be noted that this is not the optimal policy to maximize expected value from a known distribution. In the case of a known distribution, optimal play can be calculated via dynamic programming.\n\n==Other modifications==\nThere are at least three variants of the secretary problem that also have simple and elegant solutions.\n\nOne variant replaces the desire to pick the best with the desire to pick the second-best.  [[Robert J. Vanderbei]] calls this the \"postdoc\" problem arguing that the \"best\" will go to Harvard.  For this problem, the probability of success for an even number of applicants is exactly <math> \\frac{0.25n^2}{n(n-1)} </math>. This probability tends to 1/4 as n tends to infinity illustrating the fact that it is easier to pick the best than the second-best.\n\nFor a second variant, the number of selections is specified to be greater than one.  In other words, the interviewer is not hiring just one secretary but\nrather is, say, admitting a class of students from an applicant pool.  Under the assumption that success is achieved if and only if all the selected candidates\nare superior to all of the not-selected candidates, it is again a problem that\ncan be solved.  It was shown in {{harvnb|Vanderbei|1980}} that when n is\neven and the desire is to select exactly half the candidates, the optimal strategy yields a success probability of <math>\\frac{1}{n/2+1}</math>.\n\nAnother variant is that of selecting the best <math>k</math> secretaries out of a pool of <math>n</math>, again in an on-line algorithm. This leads to a strategy related to the classic one and cutoff threshold of<math> \\frac{0.25n^2}{n(n-1)} </math> for which the classic problem is a special case {{harvnb|Ghirdar|2009}}.\n\n==Experimental studies==\nExperimental [[Experimental psychology|psychologists]] and [[experimental economics|economists]] have studied the [[Decision making|decision behavior]] of actual people in secretary problem situations.<ref>Bearden, Murphy, and Rapoport, 2006; Bearden, Rapoport, and Murphy, 2006; Seale and Rapoport, 1997</ref> In large part, this work has shown that people tend to stop searching too soon. This may be explained, at least in part, by the cost of evaluating candidates. In real world settings, this might suggest that people do not search enough whenever they are faced with problems where the decision alternatives are encountered sequentially. For example, when trying to decide at which gas station along a highway to stop for gas, people might not search enough before stopping. If true, then they would tend to pay more for gas than if they had searched longer. The same may be true when people search online for airline tickets. Experimental research on problems such as the secretary problem is sometimes referred to as [[behavioral operations research]].\n\n==Neural correlates==\nWhile there is a substantial body of [[neuroscience]] research on information integration, or the representation of belief, in perceptual decision-making tasks using both animal<ref>{{cite journal|last=Shadlen|first=M.|author2=Newsome, B. |title=Motion perception: seeing and deciding|journal=Proc Natl Acad Sci USA|year=1996|volume=93|issue=2|pages=628–633|doi=10.1073/pnas.93.2.628 |pmid=8570606|pmc=40102}}</ref><ref>{{cite journal|last=Roitman|first=J.D.|author2=Shadlen, M.N. |title=Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task|journal=J Neurosci|year=2002|volume=22|issue=21|pages=9475–9489|doi=10.1523/JNEUROSCI.22-21-09475.2002}}</ref> and human subjects,<ref>{{cite journal|last=Heekeren|first=H.R.|author2=Marrett, S |author3=Ungerleider, L.G. |title=The neural systems that mediate human perceptual decision making|journal=Nat Rev Neurosci|year=2008|volume=9|issue=6|pages=467–479|doi=10.1038/nrn2374|pmid=18464792}}</ref> there is relatively little known about how the decision to stop gathering information is arrived at.\n\nResearchers have studied the neural bases of solving the secretary problem in healthy volunteers using [[functional MRI]].<ref>{{cite journal|last=Costa|first=V.D.|author2=Averbeck, B.B. |title=Frontal–Parietal and Limbic-Striatal Activity Underlies Information Sampling in the Best Choice Problem|journal=Cerebral Cortex|year=2013|doi=10.1093/cercor/bht286|volume=25|issue=4|pages=972–982|pmid=24142842|pmc=4366612}}</ref> A [[Markov decision process]] (MDP) was used to quantify the value of continuing to search versus committing to the current option. Decisions to take versus decline an option engaged [[parietal cortex|parietal]] and [[dorsolateral prefrontal cortex|dorsolateral prefrontal]] cortices, as well [[ventral striatum]], [[Insular cortex|anterior insula]], and [[anterior cingulate]]. Therefore, brain regions previously implicated in evidence integration and [[Reward system|reward]] representation encode threshold crossings that trigger decisions to commit to a choice.\n\n==History==\nThe secretary problem was apparently introduced in 1949 by [[Merrill M. Flood]], who called it the fiancée problem in a lecture he gave that year. He referred to it several times during the 1950s, for example, in a conference talk at [[Purdue University|Purdue]] on 9 May 1958, and it eventually became widely known in the folklore although nothing was published at the time. In 1958 he sent a letter to [[Leonard Gillman]], with copies to a dozen friends including [[Samuel Karlin]] and J. Robbins, outlining a proof of the optimum strategy, with an appendix by R. Palermo who proved that all strategies are dominated by a strategy of the form \"reject the first ''p'' unconditionally, then accept the next candidate who is better\". (See Flood (1958).)\n\nThe first publication was apparently by [[Martin Gardner]] in Scientific American, February 1960. He had heard about it from John H. Fox, Jr., and L. Gerald Marnie, who had independently come up with an equivalent problem in 1958; they called it the \"game of googol\". Fox and Marnie did not know the optimum solution; Gardner asked for advice from [[Leo Moser]], who (together with J. R. Pounder) provided a correct analysis for publication in the magazine. Soon afterwards, several mathematicians wrote to Gardner to tell him about the equivalent problem they had heard via the grapevine, all of which can most likely be traced to Flood's original work.\n\nThe 1/''e''-law of best choice is due to [[F. Thomas Bruss]] (1984).\n\nFerguson (1989) has an extensive bibliography and points out that a similar (but different) problem had been considered by [[Arthur Cayley]] in 1875 and even by [[Johannes Kepler#Second marriage|Johannes Kepler]] long before that.\n\n==Combinatorial generalization==\nThe secretary problem can be generalized to the case where there are multiple different jobs. Again, there are <math>n</math> applicants coming in random order. When a candidate arrives, she reveals a set of nonnegative numbers. Each value specifies her qualification for one of the jobs. The administrator not only has to decide whether or not to take the applicant but, if so, also has to assign her permanently to one of the jobs. The objective is to find an assignment where the sum of qualifications is as big as possible. This problem is identical to finding a maximum-weight matching in an edge-weighted bipartite graph where the <math>n</math> nodes of one side arrive online in random order. Thus, it is a special case of the [[Matching (graph theory)#Online Bipartite Matching|online bipartite matching]] problem.\n\nBy a generalization of the classic algorithm for the secretary problem, it is possible to obtain an assignment where the expected sum of qualifications is only a factor of <math>e</math> less than an optimal (offline) assignment.<ref>{{Cite book|last1=Kesselheim|last2=Radke|last3=Tönnis|last4=Vöcking|chapter=An Optimal Online Algorithm for Weighted Bipartite Matching and Extensions to Combinatorial Auctions|volume=8125|pages=589–600|doi=10.1007/978-3-642-40450-4_50|title=Algorithms – ESA 2013|series=Lecture Notes in Computer Science|year=2013|isbn=978-3-642-40449-8}}</ref>\n\n==See also==\n* [[Assignment problem]]\n* [[Odds algorithm]]\n* [[Optimal stopping]]\n* [[Robbins' problem]]\n* [[Search theory]]\n* [[Stable marriage problem]]\n\n==Notes==\n{{Reflist|30em}}\n\n==References==\n* {{Cite journal|author=[[F. Thomas Bruss]] |title=Sum the odds to one and stop |journal=Annals of Probability |volume=28 |pages=1384–91 |year=2000 |doi=10.1214/aop/1019160340|issue=3 }}\n* {{Cite journal|author=[[F. Thomas Bruss]] |title=A Note on Bounds for the Odds Theorem |journal=Annals of Probability |volume=31 |issue=4 |pages=1859–1961 |year=2003 |doi=10.1214/aop/1068646368}}\n* {{Cite journal|last=Bearden |first=J.N. |title=A new secretary problem with rank-based selection and cardinal payoffs |journal=Journal of Mathematical Psychology |volume=50 |pages=58–9 |year=2006 |doi=10.1016/j.jmp.2005.11.003 |ref=harv}}\n* {{Cite journal|author=Bearden, J.N., Murphy, R.O. Rapoport, A. |title=A multi-attribute extension of the secretary problem: Theory and experiments |journal=Journal of Mathematical Psychology |volume=49 |pages=410–425 |year=2005 |doi=10.1016/j.jmp.2005.08.002|issue=5 |citeseerx=10.1.1.497.6468 }}\n* {{Cite journal|author=Bearden, J.N., Rapoport, A., Murphy R.O. |title=Sequential observation and selection with rank-dependent payoffs: An experimental test |journal=Management Science |volume=52 |pages=1437–49 |year=2006 |doi=10.1287/mnsc.1060.0535|issue=9 }}\n* {{Cite journal|author=F. Thomas Bruss |authorlink=F. Thomas Bruss |title=A unified Approach to a Class of Best Choice problems with an Unknown Number of Options |journal=Annals of Probability |volume=12 |pages=882–891 |year=1984 |doi=10.1214/aop/1176993237|issue=3 }}\n\n* {{Cite journal|last=Ferguson|first=T. S. |title=Who solved the secretary problem? |journal=Statistical Science |volume=4 |pages=282–296 |year=1989 |\ndoi=10.1214/ss/1177012493|issue=3| ref=harv}}\n*{{Cite book|author = Ghirdar, Y., Dudek G. |title = Optimal Online Data Sampling or How to Hire the Best Secretaries| journal = Proc. Computer and Robot Vision|  pages=292–298|year = 2009|ref = harv| doi=10.1109/CRV.2009.30|isbn = 978-1-4244-4211-9|citeseerx = 10.1.1.161.41}}\n* {{Cite journal|last=Gnedin|first=A.|title=A solution to the game of Googol  |journal=Annals of Probability |volume=22 |pages=1588–1595  |year=1994 |doi=10.1214/aop/1176988613|issue=3| ref=harv}}\n* {{Cite journal|doi=10.2307/1402748 |author=Freeman, P.R. |title=The secretary problem and its extensions: A review |journal=International Statistical Review / Revue Internationale de Statistique |volume=51 |issue=2 |pages=189–206 |year=1983 |jstor=1402748 }}\n* Hill, T.P. \"[http://www.americanscientist.org/issues/feature/2009/2/knowing-when-to-stop/1 Knowing When to Stop]\". ''American Scientist'', Vol. 97, 126-133 (2009). (For French translation, see [https://web.archive.org/web/20110721020330/http://www.pourlascience.fr/ewb_pages/f/fiche-article-savoir-quand-s-arreter-22670.php cover story] in the July issue of ''Pour la Science'' (2009))\n* {{Cite journal|author=Seale, D.A., Rapoport, A. |title=Sequential decision making with relative ranks: An experimental investigation of the 'secretary problem' |journal=Organizational Behavior and Human Decision Processes |volume=69 |pages=221–236 |year=1997 |doi=10.1006/obhd.1997.2683|issue=3 }}\n* {{Cite journal|last1=Stein |first1=W.E. |last2=Seale |first2=D.A. |last3=Rapoport |first3=A. |title=Analysis of heuristic solutions to the best choice problem |journal=European Journal of Operational Research |volume=151 |pages=140–152 |year= 2003|doi=10.1016/S0377-2217(02)00601-X |ref=harv}}\n* Merrill R. Flood, letter written in 1958, a copy of which can be found in the Martin Gardner papers at Stanford University Archives, series 1, box 5, folder 19.\n* [[Martin Gardner]], New Mathematical Diversions from Scientific American. Simon and Schuster, 1966, Chapter 3, Problem 3 [reprints his original column published in February 1960 with additional comments].\n* {{Cite book|author=Miller, Geoffrey F. |title=The mating mind: how sexual choice shaped the evolution of human nature |publisher=Anchor Books |year=2001 |isbn=978-0-385-49517-2 }}\n* ''Framing Our Thoughts: Ecological Rationality as Evolutionary Psychology's Answer to the Frame Problem'', Timothy Ketelaar and Peter M. Todd, Chapter 5 of ''Conceptual Challenges in Evolutionary Psychology'', p.&nbsp;187.\n* {{Cite journal|author=Sardelis, D., Valahas, T. |title=Decision Making: A Golden Rule |journal=American Mathematical Monthly |volume=106 |issue=2 |pages=215–226 |date=March 1999 | doi = 10.2307/2589677|jstor=2589677 }}\n*{{Cite journal|author1=Robert J. Vanderbei |title = The Optimal Choice of a Subset of a Population| journal = Mathematics of Operations Research| volume = 5 | issue = 4| pages=481–486|year = 1980|ref = harv| doi=10.1287/moor.5.4.481}}\n* [[Robert J. Vanderbei]] \"[http://www.princeton.edu/~rvdb/tex/PostdocProblem/PostdocProb.pdf The Postdoc Variant of the Secretary Problem]\"\n\n==External links==\n* {{OEIS el|1=A054404|2=Number of daughters to wait before picking in sultan's dowry problem with n daughters}} \n* {{MathWorld | urlname=SultansDowryProblem | title=Sultan's Dowry Problem}}\n* {{cite web|url=http://www.spotlightmind.com/optimal-search |author= Neil Bearden | title = Optimal Search (Secretary Problems)}}\n* [http://www.math.ucla.edu/~tom/Stopping/Contents.html Optimal Stopping and Applications book by Thomas S. Ferguson]\n{{Use dmy dates|date=September 2010}}\n\n{{DEFAULTSORT:Secretary Problem}}\n[[Category:Decision theory]]\n[[Category:Sequential methods]]\n[[Category:Matching]]\n[[Category:Optimal decisions]]\n[[Category:Probability problems]]\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Silver–Meal heuristic",
      "url": "https://en.wikipedia.org/wiki/Silver%E2%80%93Meal_heuristic",
      "text": "{{Use dmy dates|date=August 2012}}\nThe '''Silver–Meal heuristic''' method was composed in 1973<ref>EA Silver, HC Meal, A heuristic for selecting lot size quantities for the case of a deterministic time-varying demand rate and discrete opportunities for replenishment, Production and inventory management, 1973</ref> by Edward A. Silver and H.C. Meal. It refers to [[production planning]] in manufacturing and its purpose is to determine production quantities to meet the requirement of operations at minimum cost. \n\nThe method is an approximate heuristic for the [[dynamic lot-size model]], perceived as [[Computational complexity theory|computationally too complex]].\n\n==Definition==\nThe Silver–Meal heuristic is a forward method that requires determining the [[average cost]] per period as a function of the number of periods the current order is to span and stopping the computation when this function first increases.\n\n==Procedure==\nDefine :\n\n''K'': the setup cost per lot produced.\n\n''h'': [[holding cost]] per unit per period.\n \n''C(T)'' : the average holding and setup cost per period if the current order spans the next T periods.\nLet (r<sub>1</sub>, r<sub>2</sub>, r<sub>3</sub>, …….,r<sub>n</sub>) be the requirements over the n-period horizon.\n\nTo satisfy the demand for period 1\n* <math>C(1) = K</math>\nThe average cost = only the setup cost and there is no [[inventory]] holding cost.\n\nTo satisfy the demand for period 1, 2\nProducing lot 1 and 2 in one setup give us an average cost:\n* <math>C(2) = \\frac{K+hr_2}{2}</math>\nThe average cost = (the setup cost + the inventory holding cost of the lot required in period 2.) divided by 2 periods.\n\nTo satisfy the demand for period 1, 2, 3\nProducing lot 1, 2 and 3 in one setup give us an average cost:\n* <math>C(3) = \\frac{K+hr_2+2hr_3}{3}</math>\nThe average cost =( the setup cost + the inventory holding cost of the lot required in period 2+ the inventory holding cost of the lot required in period 3) divided by 3 periods.\n\nIn general,\n* <math>C(j) = \\frac{K + hr_2 + 2hr_3 + ... + (j-1)hr_j}{j}</math>\nThe search for the optimal T continues until C(T) > C(T − 1).\n\nOnce C(j) > C(j − 1), stop and produce r<sub>1</sub> + r<sub>2</sub> + r<sub>3</sub> + ... + r<sub>j − 1</sub> \nAnd, begin the process again starting from period j.\n\n==References==\n{{Reflist}}\n*Production and Operations Analysis by S. Nahmias, McGraw-Hill\n\n{{DEFAULTSORT:Silver-Meal heuristic}}\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Single-machine scheduling",
      "url": "https://en.wikipedia.org/wiki/Single-machine_scheduling",
      "text": "{{Unreferenced|date=December 2009}}\n'''Single-machine scheduling''' or '''single-resource scheduling''' is the process of assigning a group of tasks to a single machine or resource. The tasks are arranged so that one or many performance measures may be optimized.\n\n==Performance measures==\nThe performance measures of the tasks in the single machine scheduling problem include:\n*[[Tardiness (scheduling)|Tardiness]] – <math>max(0, receipt\\;date - due\\;date)</math> \n*[[Earliness (scheduling)|Earliness]] – <math>max(0, due\\;date - receipt\\;date)</math>\n*[[Lateness (scheduling)|Lateness]] – <math>receipt\\;date - due\\;date</math>\n*[[Flowtime]] – <math>end\\;date - start\\;date</math>\n\n==Solution techniques==\nMany solution techniques have been applied to solving single machine scheduling problems. Some of them are listed below.\n\n===Heuristics===\n*Shortest processing time (SPT)\n:The SPT schedule is optimal if the objective is to minimize the average flowtime.\n:SPT-order is an order based on processing time. The sequence of remaining jobs in sorted based on non-decreasing processing time.\n\n*Earliest due date (EDD)\n:The EDD schedule is optimal if the objective is to minimize the maximum tardiness.\n:EDD-order is an order based on due date. The sequence of remaining jobs in sorted based on non-decreasing due date.\nNote: \"Lateness\" is any deviation from the due date.  Positive lateness is \"tardiness,\" negative lateness is \"earliness\"\n\n*Hodgson's algorithm\n:Hodgson's algorithm gives an optimal solution if the objective is to minimize the number of jobs with tardiness greater than zero.\n\n\n===Computational===\n*[[Genetic algorithm]]s\n*[[Neural network]]s\n*[[Simulated annealing]]\n*[[Ant colonies]]\n*[[Tabu Search]]\n===References===\n{{Reflist}}\n\n{{DEFAULTSORT:Single-Machine Scheduling}}\n[[Category:Mathematical optimization in business]]\n[[Category:Manufacturing]]"
    },
    {
      "title": "Transportation theory (mathematics)",
      "url": "https://en.wikipedia.org/wiki/Transportation_theory_%28mathematics%29",
      "text": "{{Use dmy dates|date=April 2012}}\n{{Missing information|commonly used linear programming formulations|date=February 2015}}\nIn [[mathematics]] and economics, '''transportation theory''' or '''transport theory''' is a name given to the study of optimal [[transport]]ation and [[allocation of resources]]. The problem was formalized by the French [[mathematician]] [[Gaspard Monge]] in 1781.<ref name=Monge>G. Monge. ''Mémoire sur la théorie des déblais et des remblais. Histoire de l’Académie Royale des Sciences de Paris, avec les Mémoires de Mathématique et de Physique pour la même année'', pages 666–704, 1781.</ref>\n\nIn the 1920s A.N. Tolstoi was one of the first to study the transportation problem [[mathematical model|mathematically]]. In 1930, in the collection ''Transportation Planning Volume I'' for the National Commissariat of Transportation of the Soviet Union, he published a paper \"Methods of Finding the Minimal Kilometrage in Cargo-transportation in space\".<ref>[[Alexander Schrijver|Schrijver, Alexander]], [https://books.google.com/books?id=mqGeSQ6dJycC&printsec=frontcover ''Combinatorial Optimization''], Berlin ; New York : Springer, 2003. {{isbn|3540443894}}. Cf. [https://books.google.com/books?id=mqGeSQ6dJycC&pg=PA362&lpg=PA362&dq=a.n.+tolstoi+transportation+networks&source=bl&ots=xONQNWerQa&sig=LJl_9KbyS1FDp_wYuXNJ9ruEKes&hl=en&ei=bMujTLP6O4OClAfjoomQCw&sa=X&oi=book_result&ct=result&resnum=1&ved=0CBsQ6AEwAA#v=onepage&q=a.n.%20tolstoi%20transportation%20networks&f=false p.362]</ref><ref>Ivor Grattan-Guinness, Ivor,  [https://books.google.com/books?id=2hDvzITtfdAC&printsec=frontcover ''Companion encyclopedia of the history and philosophy of the mathematical sciences''], Volume 1, JHU Press, 2003. Cf. [https://books.google.com/books?id=2hDvzITtfdAC&pg=PA831&lpg=PA831&dq=%22a.n.+tolstoy%22+mathematics&source=bl&ots=pCwrnZWBwI&sig=QQz_1ng7mR6dmZWCmZ4L1Twar3U&hl=en&ei=w8SjTJeUDoT7lwe3nYT8Cw&sa=X&oi=book_result&ct=result&resnum=4&ved=0CCAQ6AEwAw#v=onepage&q=%22a.n.%20tolstoy%22%20mathematics&f=false p.831]</ref>\n\nMajor advances were made in the field during World War II by the [[Soviet Union|Soviet]] mathematician and economist [[Leonid Kantorovich]].<ref name=Kantorovich>L. Kantorovich. ''On the translocation of masses.'' C.R. (Doklady) Acad. Sci. URSS (N.S.), 37:199–201, 1942.</ref> Consequently, the problem as it is stated is sometimes known as the '''Monge–Kantorovich transportation problem'''.<ref name=\"Villani2003\">{{cite book|author=Cédric Villani|title=Topics in Optimal Transportation|year=2003|publisher=American Mathematical Soc.|isbn=978-0-8218-3312-4|page=66}}</ref> The [[linear programming]] formulation of the transportation problem is also known as the [[Frank Lauren Hitchcock|Hitchcock]]–[[Tjalling Koopmans|Koopmans]] transportation problem.<ref name=\"RaoRao2009\">{{cite book|author1=Singiresu S. Rao|title=Engineering Optimization: Theory and Practice|year=2009|publisher=John Wiley & Sons|isbn=978-0-470-18352-6|pages=221|edition=4th}}</ref>\n\n==Motivation==\n\n===Mines and factories===\nSuppose that we have a collection of ''n'' mines mining iron ore, and a collection of ''n'' factories which use the iron ore that the mines produce. Suppose for the sake of argument that these mines and factories form two [[Disjoint sets|disjoint]] [[subset]]s ''M'' and ''F'' of the [[Euclidean plane]] '''R'''<sup>2</sup>. Suppose also that we have a ''cost function'' ''c''&nbsp;:&nbsp;'''R'''<sup>2</sup>&nbsp;×&nbsp;'''R'''<sup>2</sup>&nbsp;→&nbsp;[0,&nbsp;∞), so that ''c''(''x'',&nbsp;''y'') is the cost of transporting one shipment of iron from ''x'' to ''y''. For simplicity, we ignore the time taken to do the transporting. We also assume that each mine can supply only one factory (no splitting of shipments) and that each factory requires precisely one shipment to be in operation (factories cannot work at half- or double-capacity). Having made the above assumptions, a ''transport plan'' is a [[bijection]] ''T'' : ''M'' → ''F''.\nIn other words, each mine ''m'' ∈ ''M'' supplies precisely one factory ''T''(''m'') ∈ ''F'' and each factory is supplied by precisely one mine. \nWe wish to find the ''optimal transport plan'', the plan ''T'' whose ''total cost''\n\n:<math>c(T) := \\sum_{m \\in M} c(m, T(m))</math>\n\nis the least of all possible transport plans from ''M'' to ''F''. This motivating special case of the transportation problem is an instance of the [[assignment problem]].\nMore specifically, it is equivalent to finding a minimum weight matching in a bipartite graph.\n\n===Moving books: the importance of the cost function===\nThe following simple example illustrates the importance of the [[Cost curve|cost function]] in determining the optimal transport plan. Suppose that we have ''n'' books of equal width on a shelf (the [[real line]]), arranged in a single contiguous block. We wish to rearrange them into another contiguous block, but shifted one book-width to the right. Two obvious candidates for the optimal transport plan present themselves:\n# move all ''n'' books one book-width to the right (\"many small moves\");\n# move the left-most book ''n'' book-widths to the right and leave all other books fixed (\"one big move\").\nIf the cost function is proportional to Euclidean distance (''c''(''x'',&nbsp;''y'')&nbsp;=&nbsp;α|''x''&nbsp;−&nbsp;''y''|) then these two candidates are ''both'' optimal. If, on the other hand, we choose the [[Convex function|strictly convex]] cost function proportional to the square of Euclidean distance (''c''(''x'',&nbsp;''y'')&nbsp;=&nbsp;α|''x''&nbsp;−&nbsp;''y''|<sup>2</sup>), then the \"many small moves\" option becomes the unique minimizer.\n\n==Hitchcock problem==\nThe following transportation problem formulation is credited to [[F. L. Hitchcock]]:<ref>Frank L. Hitchcock (1941) \"The distribution of a product from several sources to numerous localities\", [[MIT Journal of Mathematics and Physics]] 20:224–230 {{MR|id=0004469}}.\n</ref>\n:Suppose there are ''m'' sources <math>x_1, ... x_m</math> for a commodity, with <math>a(x_i)</math> units of supply at ''x''<sub>i</sub> and ''n'' sinks <math>y_1, ... y_n</math> for the commodity, with the demand <math>b(y_j)</math> at ''y''<sub>j</sub>. If <math>a(x_i,\\ y_j)</math> is the unit cost of shipment from ''x''<sub>i</sub> to ''y''<sub>j</sub>, find a flow that satisfies demand from supplies and minimizes the flow cost.\nThis challenge in logistics was taken up by [[D. R. Fulkerson]]<ref>D. R. Fulkerson (1956) [http://www.priorartdatabase.com/IPCOM/000128834/ Hitchcock Transportation Problem], RAND corporation.\n</ref> and in the book ''Flows in Networks'' (1962) written with [[L. R. Ford Jr.]].<ref>[[L. R. Ford Jr.]] & [[D. R. Fulkerson]] (1962) § 3.1 in ''Flows in Networks'', page 95,  [[Princeton University Press]]</ref>\n\n[[Tjalling Koopmans]] is also credited with formulations of [[transport economics]] and allocation of resources.\n\n==Abstract formulation of the problem==\n\n===Monge and Kantorovich formulations===\n\nThe transportation problem as it is stated in modern or more technical literature looks somewhat different because of the development of [[Riemannian geometry]] and [[measure theory]]. The mines-factories example, simple as it is, is a useful reference point when thinking of the abstract case. In this setting, we allow the possibility that we may not wish to keep all mines and factories open for business, and allow mines to supply more than one factory, and factories to accept iron from more than one mine.\n\nLet ''X'' and ''Y'' be two [[separable space|separable]] [[metric space]]s such that any [[probability measure]] on ''X'' (or ''Y'') is a [[Radon measure]] (i.e. they are [[Radon space]]s). Let ''c'' : ''X'' × ''Y'' → [0, ∞] be a Borel-[[measurable function]]. Given probability measures μ on ''X'' and ν on ''Y'', Monge's formulation of the optimal transportation problem is to find a transport map ''T'' : ''X'' → ''Y'' that realizes the [[infimum]]\n\n:<math>\\inf \\left\\{ \\left. \\int_{X} c(x, T(x)) \\, \\mathrm{d} \\mu (x) \\;\\right| \\; T_* (\\mu) = \\nu \\right\\},</math>\n\nwhere ''T''<sub>∗</sub>(μ) denotes the [[pushforward measure|push forward]] of μ by ''T''. A map ''T'' that attains this infimum (''i.e.'' makes it a [[minimum]] instead of an infimum) is called an \"optimal transport map\".\n\nMonge's formulation of the optimal transportation problem can be ill-posed, because sometimes there is no ''T'' satisfying ''T''<sub>∗</sub>(μ) = ν: this happens, for example, when μ is a [[Dirac measure]] but ν is not.\n\nWe can improve on this by adopting Kantorovich's formulation of the optimal transportation problem, which is to find a probability measure γ on ''X'' × ''Y'' that attains the infimum\n\n:<math>\\inf \\left\\{ \\left. \\int_{X \\times Y} c(x, y) \\, \\mathrm{d} \\gamma (x, y) \\right| \\gamma \\in \\Gamma (\\mu, \\nu) \\right\\},</math>\n\nwhere Γ(μ, ν) denotes the collection of all probability measures on ''X'' × ''Y'' with [[Conditional probability|marginals]] μ on ''X'' and ν on ''Y''. It can be shown<ref name=AGS>L. Ambrosio, N. Gigli & G. Savaré. ''Gradient Flows in Metric Spaces and in the Space of Probability Measures.'' Lectures in Mathematics ETH Zürich, Birkhäuser Verlag, Basel. (2005)</ref> that a minimizer for this problem always exists when the cost function ''c'' is lower semi-continuous and Γ(''μ'',&nbsp;''ν'') is a [[Tightness of measures|tight]] collection of measures (which is guaranteed for Radon spaces ''X'' and ''Y''). (Compare this formulation with the definition of the [[Wasserstein metric]] ''W''<sub>1</sub> on the space of probability measures.) A gradient descent formulation for the solution of the Monge–Kantorovich problem was given by [[Sigurd Angenent]], Steven Haker, and [[Allen Tannenbaum]].<ref name=AHT>{{cite journal |first=S. |last=Angenent |first2=S. |last2=Haker |first3=A. |last3=Tannenbaum |title=Minimizing flows for the Monge–Kantorovich problem |journal=SIAM J. Math. Anal. |volume=35 |issue=1 |pages=61–97 |year=2003 |doi=10.1137/S0036141002410927 |citeseerx=10.1.1.424.1064 }}</ref>\n\n===Duality formula===\nThe minimum of the Kantorovich problem is equal to\n\n:<math>\\sup \\left( \\int_X \\varphi (x) \\, \\mathrm{d} \\mu (x) + \\int_Y \\psi (y) \\, \\mathrm{d} \\nu (y) \\right),</math>\n\nwhere the [[supremum]] runs over all pairs of [[bounded function|bounded]] and [[continuous function]]s <math>\\varphi : X \\rightarrow \\mathbf{R}</math> and <math>\\psi : Y \\rightarrow \\mathbf{R}</math> such that\n\n:<math>\\varphi (x) + \\psi (y) \\leq c(x, y).</math>\n\n==Solution of the problem==\n\n===Optimal transportation on the real line===\n{{multiple image\n<!-- Layout parameters -->\n | align             = right\n | direction         = vertical\n | width             = 200\n<!--image 1-->\n | image1            = Optimal transport matrix.png\n | alt1              = Optimal transportation matrix\n | link1             = \n | caption1          =  Optimal transportation matrix\n<!--image 2-->\n | image2            = Continuous optimal transport.png\n | alt2              = Continuous optimal transport \n | link2             = \n | caption2          = Continuous optimal transport\n}}\nFor <math>1 \\leq p < \\infty</math>, let <math>\\mathcal{P}_p(\\mathbf{R})</math> denote the collection of [[probability measure]]s on '''<math>\\mathbf{R}</math>''' that have finite ''<math>p</math>''-th [[moment (mathematics)|moment]]. Let <math>\\mu, \\nu \\in \\mathcal{P}_p(\\mathbf{R})</math> and let <math>c(x, y) = h(x-y)</math>, where <math>h:\\mathbf{R} \\rightarrow [0,\\infty)</math> is a [[convex function]].\n# If <math>\\mu</math> has no [[atom (measure theory)|atom]], i.e., if the [[cumulative distribution function]] <math>F_\\mu = \\mathbf{R}\\rightarrow[0,1]</math> of <math>\\mu</math> is a [[continuous function]], then <math>F_{\\nu}^{-1} \\circ F_{\\mu} : \\mathbf{R} \\to \\mathbf{R}</math> is an optimal transport map. It is the unique optimal transport map if <math>h</math> is strictly convex.\n# We have\n::<math>\\min_{\\gamma \\in \\Gamma(\\mu, \\nu)} \\int_{\\mathbf{R}^2} c(x, y) \\, \\mathrm{d} \\gamma (x, y) = \\int_0^1 c \\left( F_{\\mu}^{-1} (s), F_{\\nu}^{-1} (s) \\right) \\, \\mathrm{d} s.</math>\n\nThe proof of this solution appears in.<ref name=RL_MTP>Rachev, Svetlozar T., and Ludger Rüschendorf. ''Mass Transportation Problems: Volume I: Theory''. Vol. 1. Springer, 1998.</ref>\n\n===Separable Hilbert spaces===\nLet ''<math>X</math>'' be a [[separable space|separable]] [[Hilbert space]]. Let <math>\\mathcal{P}_p(X)</math> denote the collection of probability measures on ''<math>X</math>'' such that have finite <math>p</math>-th moment; let <math>\\mathcal{P}_p^r(X)</math> denote those elements <math>\\mu \\in \\mathcal{P}_p(X)</math> that are '''Gaussian regular''': if <math>g</math> is any [[strictly positive measure|strictly positive]] [[Gaussian measure]] on <math>X</math> and <math>g(N) = 0</math>, then <math>\\mu(N) = 0</math> also.\n\nLet <math>\\mu \\in \\mathcal{P}_p^r (X)</math>, <math>\\nu \\in \\mathcal{P}_p(X)</math>, <math>c (x, y) = | x - y |^p/p</math> for <math>p\\in(1,\\infty), p^{-1} + q^{-1} = 1</math>. Then the Kantorovich problem has a unique solution <math>\\kappa</math>, and this solution is induced by an optimal transport map: i.e., there exists a Borel map <math>r\\in L^p(X, \\mu; X)</math> such that\n\n:<math>\\kappa = (\\mathrm{id}_X \\times r)_{*} (\\mu) \\in \\Gamma (\\mu, \\nu).</math>\n\nMoreover, if <math>\\nu</math> has [[bounded set|bounded]] [[support (measure theory)|support]], then\n\n:<math>r(x) = x -  | \\nabla \\varphi (x) |^{q - 2} \\nabla \\varphi (x)</math>\n\nfor <math>\\mu</math>-almost all ''<math>x\\in X</math>'' for some [[Lipschitz continuous|locally Lipschitz]], ''c''-concave and maximal Kantorovich potential <math>\\varphi</math>. (Here <math>\\nabla \\varphi</math> denotes the [[Gateaux derivative]] of <math>\\varphi</math>.)\n\n== Applications ==\nThe Monge–Kantorovich optimal transport has found applications in wide range in different fields. Among them are:\n* [[Image registration]] and warping <ref>{{Cite journal|last=Haker|first=Steven|last2=Zhu|first2=Lei|last3=Tannenbaum|first3=Allen|last4=Angenent|first4=Sigurd|date=2004-12-01|title=Optimal Mass Transport for Registration and Warping|journal=International Journal of Computer Vision|language=en|volume=60|issue=3|pages=225–240|doi=10.1023/B:VISI.0000036836.66311.97|issn=0920-5691|citeseerx=10.1.1.59.4082}}</ref>\n* Reflector design <ref>{{Cite journal|last=Glimm|first=T.|last2=Oliker|first2=V.|date=2003-09-01|title=Optical Design of Single Reflector Systems and the Monge–Kantorovich Mass Transfer Problem|journal=Journal of Mathematical Sciences|language=en|volume=117|issue=3|pages=4096–4108|doi=10.1023/A:1024856201493|issn=1072-3374}}</ref>\n* Retrieving information from [[shadowgraph]]y and proton radiography <ref>{{Cite journal|last=Kasim|first=Muhammad Firmansyah|last2=Ceurvorst|first2=Luke|last3=Ratan|first3=Naren|last4=Sadler|first4=James|last5=Chen|first5=Nicholas|last6=Sävert|first6=Alexander|last7=Trines|first7=Raoul|last8=Bingham|first8=Robert|last9=Burrows|first9=Philip N.|date=2017-02-16|title=Quantitative shadowgraphy and proton radiography for large intensity modulations|journal=Physical Review E|volume=95|issue=2|pages=023306|doi=10.1103/PhysRevE.95.023306|pmid=28297858|arxiv=1607.04179|bibcode=2017PhRvE..95b3306K}}</ref>\n* [[Seismic tomography]] and [[reflection seismology]] <ref>{{cite journal |last1=Metivier |first1=Ludovic |title=Measuring the misfit between seismograms using an optimal transport distance: application to full waveform inversion |journal=Geophysical Journal International |date=24 February 2016 |volume=205 |issue=1 |pages=345–377 |doi=10.1093/gji/ggw014 |url=https://academic.oup.com/gji/article-abstract/205/1/345/2594839}}</ref>\n\n==See also==\n{{Commons category|Transportation theory}}\n* [[Wasserstein metric]]\n* [[Transport function]]\n* [[Hungarian algorithm]]\n* [[Transportation planning]]\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n* {{cite book | last=Brualdi | first=Richard A. | title=Combinatorial matrix classes | series=Encyclopedia of Mathematics and Its Applications | volume=108 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2006 | isbn=978-0-521-86565-4 | zbl=1106.05001 }}\n\n{{DEFAULTSORT:Transportation Theory}}\n[[Category:Calculus of variations]]\n[[Category:Matching]]\n[[Category:Mathematical economics]]\n[[Category:Measure theory]]\n[[Category:Transport economics]]\n[[Category:Optimization in vector spaces]]\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Unit commitment problem in electrical power production",
      "url": "https://en.wikipedia.org/wiki/Unit_commitment_problem_in_electrical_power_production",
      "text": "The '''unit commitment problem''' ('''UC''') in electrical power production is a large family of [[mathematical optimization]] problems where the production of a set of electrical generators is coordinated in order to achieve some common target, usually either match the energy demand at minimum cost or maximize revenues from energy production. This is necessary because it is difficult to [[Energy storage#Storage for electricity|store electrical energy]] on a scale comparable with normal consumption; hence, each (substantial) variation in the consumption must be matched by a corresponding variation of the production.\n\nCoordinating generation units is a difficult task for a number of reasons:\n\n* the number of units can be large (hundreds or thousands);\n* there are [[Power station|several types of units]], with significantly different [[Cost of electricity by source|energy production costs]] and constraints about how power can be produced;\n* generation is distributed across a vast geographical area (e.g., a country), and therefore the response of the [[electrical grid]], itself a highly complex system, has to be taken into account: even if the production levels of all units are known, checking whether the load can be sustained and what the losses are requires highly complex [[Power-flow study|power flow computations]].\n\nBecause the relevant details of the electrical system vary greatly worldwide, there are many variants of the UC problem, which are often very difficult to solve. This is also because, since some units require quite a long time (many hours) to start up or shut down, the decisions need be taken well in advance (usually, the day before), which implies that these problems have to be solved within tight time limits (several minutes to a few hours). UC is therefore one of the fundamental problems in [[Power system simulation|power system management and simulation]]. It has been studied for many years,<ref name=\"BaDD59\">C.J. Baldwin, K.M. Dale, R.F. Dittrich. ''A study of the economic shutdown of generating units in daily dispatch''. '''Transactions of the American Institute of Electrical Engineers Power Apparatus and Systems''', Part III, 78(4):1272–1282, 1959.</ref><ref name=\"Ba88\">J.F. Bard. ''Short-term scheduling of thermal-electric generators using Lagrangian relaxation''. '''Operations Research''' 1338 36(5):765–766, 1988.</ref> and still is one of the most significant energy optimization problems. Recent surveys on the subject<ref name=\"Pa04\">N.P. Padhy. ''Unit commitment – a bibliographical survey'', '''IEEE Transactions On Power Systems''' 19(2):1196–1205, 2004.</ref><ref name=\"TvAFL15\">[https://dx.doi.org/10.1007/s10288-014-0279-y M. Tahanan, W. van Ackooij, A. Frangioni, F. Lacalandra. ''Large-scale Unit Commitment under uncertainty'', '''4OR''' 13(2), 115–171, 2015.]</ref> count many hundreds of scientific articles devoted to the problem. Furthermore, several commercial products comprise specific modules for solving UC,<ref name=\"Plexos\">[http://energyexemplar.com/software/plexos-desktop-edition PLEXOS® Integrated Energy Model]</ref> or are even entirely devoted to its solution.<ref name=\"PowerOp\">[http://www.powerop.co.uk Power optimization]</ref>\n\n== Elements of unit commitment problems ==\nThere are many different UC problems, as the electrical system is structured and governed differently across the world. Common elements are:\n\n* A ''time horizon'' along which the decisions have to be made, sampled at a finite number of ''time instants''. This is usually one or two days, up to a week, where instants are usually hours or half-hours; less frequently, 15 or 5 minutes. Hence, time instants are typically between 24 and around 2000.\n* A set of ''generating units'' with the corresponding energy production cost and/or emission curves, and (complex) technical constraints.\n* A representation of the significant part of the ''[[Electrical grid|grid network]]''.\n* A (forecasted) ''[[load profile]]'' to be satisfied, i.e., the net amount of energy to be delivered to each node of the grid network at each time instant.\n* Possibly, a set of ''reliability constraints''<ref name=\"ShYL02\">M. Shahidehpour, H. Yamin, and Z. Li. ''Market Operations in Electric Power Systems: Forecasting, Scheduling, and Risk Management'', Wiley-IEEE Press, 2002.</ref> ensuring that demand will be satisfied even if some unforeseen events occur. \n* Possibly, ''financial and/or regulatory conditions''<ref name=\"Ha11\">C. Harris. ''Electricity markets: Pricing, structures and Economics'', volume 565 of The Wiley Finance Series. John Wiley and Sons, 2011.</ref> (energy revenues, market operation constraints, financial instruments, ...).\n\nThe decisions that have to be taken usually comprise:\n\n* ''commitment decisions'': whether a unit is producing energy at any time instant;\n* ''production decisions'': how much energy a unit is producing at any time instant;\n* ''network decisions'': how much energy is flowing (and in which direction) on each branch of the transmission and/or distribution grid at any given time instant.\n\nWhile the above features are usually present, there are many combinations and many different cases. Among these we mention:\n\n* whether the units and the grid are all handled by a Monopolistic Operator (MO),<ref name=\"CoPr01\">A.J. Conejo and F.J. Prieto. ''Mathematical programming and electricity markets'', '''TOP''' 9(1):1–53, 2001.</ref> or a separate [[Transmission system operator|Transmission System Operator]] (TSO) manages the grid providing fair and not discriminatory access to [[Electric utility|Generating Companies]] (GenCos) that compete to satisfy the production on the (or, most often, several interconnected) [[Electricity market|energy market(s)]];\n* the [[Power station|different kinds of energy production units]], such as thermal/nuclear ones, hydro-electric ones, and renewable sources (wind, solar, ...);\n* which units can be [[Power station#Operations|''modulated'']], i.e., their produced energy can be decided by the operator (albeit subject to the technical constraints of the unit), as opposed to it being entirely dictated by external factors such as weather conditions;\n* the level of detail at which the working of the [[electrical grid]] must be considered, ranging from basically ignoring it to considering the possibility of dynamically opening (interrupting) a line in order to optimally change the energy routing on the grid.<ref name=\"FiOF08\" />\n\n=== Management objectives ===\nThe objectives of UC depend on the aims of the actor for which it is solved. For a MO, this is basically to ''minimize [[Cost of electricity by source|energy production costs]]'' while satisfying the demand; reliability and emissions are usually treated as constraints. In a free-market regime, the aim is rather to ''maximize energy production profits'', i.e., the difference between revenues (due to selling energy) and costs (due to producing it). If the GenCo is a ''price maker'', i.e., it has sufficient size to influence market prices, it may in principle perform ''strategic bidding''<ref name=\"DaW01\">A.K. David, F. Wen. ''Strategic bidding in competitive electricity markets: a literature survey'' In '''Proceedings IEEE PES Summer Meeting''' 4, 2168–2173, 2001.</ref> in order to improve its profits. This means bidding its production at high cost so as to raise market prices, losing market share but retaining some because, essentially, there is not enough generation capacity. For some regions this may be due to the fact that there is not enough [[Electric power transmission#Capacity|grid network capacity]] to import energy from nearby regions with available generation capacity.<ref name=\"PeTo03\">T. Peng and K. Tomsovic. ''Congestion influence on bidding strategies in an electricity market'', '''IEEE Transactions on Power Systems''' 18(3):1054–1061, August 2003.</ref> While the electrical markets are highly regulated in order to, among other things, rule out such behavior, large producers can still benefit from simultaneously optimizing the bids of all their units to take into account their combined effect on market prices.<ref name=\"CCAT02\">A.J. Conejo, J. Contreras, J.M. Arroyo, S. de la Torre. ''Optimal response of an oligopolistic generating company to a competitive pool-based electric power market'', '''IEEE Transactions on Power Systems''' 17(2):424–430, 2002.</ref> On the contrary, ''price takers'' can simply optimize each generator independently, as, not having a significant impact on prices, the corresponding decisions are not correlated.<ref name=\"ArC00\">J.M. Arroyo, A.J. Conejo. ''Optimal response of a thermal unit to an electricity spot market'', '''IEEE Transactions on Power Systems''' 15(3):1098–1104, 2000.</ref>\n\n=== Types of production units ===\nIn the context of UC, generating units are usually classified as:\n\n* [[Thermal power station|Thermal units]], which include [[Nuclear power plant|nuclear]] ones, that burn some sort of fuel to produce electricity. They are subject to numerous complex technical constraints, among which we mention ''minimum up/down time'', ''ramp up/down rate'', ''modulation/stability'' (a unit cannot change its production level too many times<ref name=\"BaRe02\">J. Batut and A. Renaud. ''Daily scheduling with transmission constraints: A new class of algorithms'', '''IEEE Transactions on Power Systems''' 7(3):982–989, 1992.</ref>), and ''start-up/shut-down ramp rate'' (when starting/stopping, a unit must follow a specific power curve which may depend on how long the plant has been offline/online<ref name=\"MELR13\">G. Morales-España, J.M. Latorre, A. Ramos. ''Tight and Compact MILP Formulation of Start-Up and Shut-Down Ramping in Unit Commitment'', '''IEEE Transactions on Power Systems''' 28(2), 1288–1296, 2013.</ref>). Therefore, optimizing even a single unit is in principle already a complex problem which requires specific techniques.<ref name=\"FrG06\">A. Frangioni, C. Gentile. ''Solving Nonlinear Single-Unit Commitment Problems with Ramping Constraints'', '''Operations Research''' 54(4), 767–775, 2006.</ref>\n* [[Hydroelectricity|Hydro units]], that generate energy by harvesting water potential energy, are often organized into systems of connected reservoirs called ''hydro valleys''. Because water released by an upstream reservoir reaches the downstream one (after some time), and therefore becomes available to generate energy there, decisions on the optimal production must be taken for all units simultaneously, which makes the problem rather difficult even if no (or little) thermal production is involved,<ref name=\"FiDS06\">E.C. Finardi and E.L. Da Silva. ''Solving the hydro unit commitment problem via dual decomposition and sequential quadratic programming'', '''IEEE Transactions on Power Systems''' 21(2):835–844, 2006.</ref> even more so if the complete electrical system is considered.<ref name=\"TDFR12\">F.Y.K. Takigawa, E.L. da Silva, E.C. Finardi, and R.N. Rodrigues. ''Solving the hydrothermal scheduling problem considering network constraints.'', '''Electric Power Systems Research''' 88:89–97, 2012.</ref> Hydro units may include [[Pumped-storage hydroelectricity|pumped-storage units]], where energy can be spent to pump water uphill. This is the only current technology capable of storing enough (potential) energy to be significant at the typical level of the UC problem. Hydro units are subject to complex technical constraints. The amount of energy generated by turbining some amount of water is not constant, but it depends on the [[Hydraulic head|water head]] which in turn depends on previous decisions. The relationship is nonlinear and nonconvex, making the problem particularly difficult to solve.<ref name=\"BDLM08\">[[Alberto Borghetti|A. Borghetti]], C. D’Ambrosio, A. Lodi, S. Martello. ''A MILP approach for short-term hydro scheduling and unit commitment with head-dependent reservoir'', '''IEEE Transactions on Power Systems''' 23(3):1115–1124, 2008.</ref>\n* Renewable generation units, such as [[Wind power|wind farms]], [[Solar power|solar plants]], [[Run-of-the-river hydroelectricity|run-of-river hydro units]] (without a dedicated reservoir, and therefore whose production is dictated by the flowing water), and [[Geothermal energy|geothermal units]]. Most of these cannot be ''modulated'', and several are also [[Intermittent energy source|''intermittent'']], i.e., their production is difficult to accurately forecast well in advance. In UC, these units do not really correspond to decisions, since they cannot be influenced. Rather, their production is considered fixed and added to that of the other sources. The substantial increase of intermittent renewable generation in recent years has significantly increased uncertainty in the ''net load'' (demand minus production that cannot be modulated), which has challenged the traditional view that the [[Energy forecasting|forecasted load]] in UC is accurate enough.<ref name=\"KeMD10\" />\n\n=== Electrical grid models ===\nThere are three different ways in which the energy grid is represented within a UC:\n\n* In the ''single bus approximation'' the grid is ignored: demand is considered to be satisfied whenever total production equals total demand, irrespective of their geographical location.\n* In the ''DC approximation'' only [[Kirchhoff's circuit laws#Kirchhoff.27s current law .28KCL.29|Kirchhoff's current law]] is modeled; this corresponds to [[AC power#Reactive power|reactive power]] flow being neglected, the [[Phase angle|voltage angles]] differences being considered small, and the angle voltage profile being assumed constant;\n* In the ''full AC model'' the complete [[Kirchhoff's circuit laws|Kirchhoff laws]] are used: this results in highly nonlinear and nonconvex constraints in the model.\n\nWhen the full AC model is used, UC actually incorporates the [[Power-flow study|optimal power flow problem]], which is already a nonconvex nonlinear problem.\n\nRecently, the traditional \"passive\" view of the energy grid in UC has been challenged. In a ''fixed'' electrical network currents cannot be routed, their behavior being entirely dictated by nodal power injection: the only way to modify the network load is therefore to change nodal demand or production, for which there is limited scope. However, a somewhat counter-intuitive consequence of Kirchhoff laws is that interrupting a line (maybe even a congested one) causes a global re-routing of electrical energy and may therefore ''improve'' grid performances. This has led to defining the ''Optimal Transmission Switching problem'',<ref name=\"FiOF08\">E.B. Fisher, R.P. O'Neill, M.C. Ferris. ''Optimal transmission switching'', '''IEEE Transactions on Power Systems''' 23(3):1346–1355, 2008.</ref> whereby some of the lines of the grid can be dynamically opened and closed across the time horizon. Incorporating this feature in the UC problem makes it difficult to solve even with the DC approximation, even more so with the full AC model.<ref name=\"Heta10\">K.W. Hedman, M.C. Ferris, R.P. O’Neill, E.B. Fisher, S.S. Oren. ''Co-optimization of generation unit commitment and transmission switching with ''n''&nbsp;−&nbsp;1 reliability'', '''IEEE Transactions on Power Systems''' 25(2):1052–1063, 2010.</ref>\n\n== Uncertainty in unit commitment problems ==\nA troubling consequence of the fact that UC needs be solved well in advance to the actual operations is that the future state of the system is not known exactly, and therefore needs be estimated. This used to be a relatively minor problem when the ''uncertainty'' in the system was only due to variation of users' demand, which on aggregate can be forecasted quite effectively,<ref name=\"FeGe05\">E.A. Feinberg, D. Genethliou. ''Load Forecasting'', in '''Applied Mathematics for Restructured Electric Power Systems''', J.H. Chow , F.F. Wu, and J. Momoh eds., Springer, 269–285, 2005</ref><ref name=\"HMNP09\">H. Hahn, S. Meyer-Nieberg, S. Pickl. ''Electric load forecasting methods: Tools for decision making'', '''European Journal of Operational Research''' 199(3), 902–907, 2009</ref> and occurrence of lines or generators faults, which can be dealt with by well established rules ([[Operating reserve|spinning reserve]]). However, in recent years the production from [[Intermittent energy source|intermittent renewable production sources]] has significantly increased. This has, in turn, very significantly increased the impact of uncertainty in the system, so that ignoring it (as traditionally done by taking average point estimates) risks significant cost increases.<ref name=\"KeMD10\">A. Keyhani, M.N. Marwali, and M. Dai. ''Integration of Green and Renewable Energy in Electric Power Systems'', Wiley, 2010.</ref> This had made it necessary to resort to appropriate mathematical modeling techniques to properly take uncertainty into account, such as:\n\n* [[Robust optimization]] approaches;\n* [[Scenario optimization]] approaches;\n* Chance-constrained optimization approaches.\n\nThe combination of the (already, many) traditional forms of UC problems with the several (old and) new forms of uncertainty gives rise to the even larger family of ''Uncertain Unit Commitment''<ref name=\"TvAFL15\" /> (UUC) problems, which are currently at the frontier of applied and methodological research.\n\n== See also ==\n\n* [[Electricity market]]\n\n== References ==\n\n{{reflist}}\n\n== External links ==\n*A description of the role of unit commitment problems in the overall context of power system management can be found in the  [http://www.energy-opt.eu/wiki Energy Optimization Wiki] developed by the COST TD1207 project.\n\n[[Category:Mathematical optimization in business]]"
    },
    {
      "title": "Weber problem",
      "url": "https://en.wikipedia.org/wiki/Weber_problem",
      "text": "In [[geometry]], the '''Weber problem''', named after [[Alfred Weber]], is one of the most famous problems in [[location theory]]. It requires finding a point in the plane that minimizes the sum of the transportation costs from this point to ''n'' destination points, where different destination points are associated with different costs per unit distance.\n\nThe Weber problem generalizes the [[geometric median]], which assumes transportation costs per unit distance are the same for all destination points, and the problem of computing the [[Fermat point]], the geometric median of three points. For this reason it is sometimes called the Fermat–Weber problem, although the same name has also been used for the unweighted geometric median problem. The Weber problem is in turn generalized by the [[attraction–repulsion problem]], which allows some of the costs to be negative, so that greater distance from some points is better.\n\n== Definition and history of the Fermat, Weber, and attraction-repulsion problems ==\n\n{| width=1000px class=\"wikitable\"\n!width=25% | \n!width=25% | The Fermat problem\n!width=25% | The Weber problem\n!width=25% | The attraction-repulsion problem\n|-\n|align=\"left\"| First formulated by\n|align=\"left\"| Fermat (before 1640)\n|align=\"left\"| Simpson (1750)\n|align=\"left\"| Tellier (1985)\n|-\n|align=\"left\"| Geometrical solution of the triangle problem\n|align=\"left\"| Torricelli (1645)\n|align=\"left\"| Simpson (1750)\n|align=\"left\"| Tellier (2013)\n|-\n|align=\"left\"| Direct numerical solution of the triangle problem\n|align=\"left\"| Tellier (1972)\n|align=\"left\"| Tellier (1972)\n|align=\"left\"| Tellier (1985)\n|-\n|align=\"left\"| Iterative numerical solution of the problem\n|align=\"left\"| Kuhn and Kuenne (1962)\n|align=\"left\"| Kuhn and Kuenne (1962)\n|align=\"left\"| Chen, Hansen, Jaumard and Tuy (1992)\n|}\n\nIn the triangle case, the Fermat problem consists in locating a point D with respect to three points A, B, and C in such a way that the sum of the distances between D and each of the three other points is minimized. It was formulated by the famous French mathematician [[Pierre de Fermat]] before 1640, and it can be seen as the true beginning of both location theory, and space-economy. Torricelli found a geometrical solution to this problem around 1645, but it still had no direct numerical solution more than 325 years later. Kuhn and Kuenne<ref>Kuhn, Harold W. and Robert E. Kuenne, 1962, \"An Efficient Algorithm for the Numerical Solution of the Generalized Weber Problem in Spatial Economics.\" ''Journal of Regional Science'' 4, 21–34.</ref> found an iterative solution for the general Fermat problem in 1962, and, in 1972, [[Luc-Normand Tellier|Tellier]]<ref>Tellier, Luc-Normand, 1972, “The Weber Problem: Solution and Interpretation”, ''Geographical Analysis'', vol. 4, no. 3, pp. 215–233.</ref>  found a direct numerical solution to the Fermat triangle problem, which is trigonometric. Kuhn and Kuenne's solution applies to the case of polygons having more than three sides, which is not the case with Tellier's solution for reasons explained further on.\n\nThe Weber problem consists, in the triangle case, in locating a point D with respect to three points A, B, and C in such a way that the sum of the transportation costs between D and each of the three other points is minimized. The Weber problem is a generalization of the Fermat problem since it involves both equal and unequal attractive forces (see below), while the Fermat problem only deals with equal attractive forces. It was first formulated, and solved geometrically in the triangle case, by [[Thomas Simpson]] in 1750.<ref>Simpson, Thomas, 1750, ''The Doctrine and Application of Fluxions'', London.</ref> It was later popularized by [[Alfred Weber]] in 1909.<ref>Weber, Alfred, 1909, ''Über den Standort der Industrien'', Tübingen, J.C.B. Mohr) — English translation: ''The Theory of the Location of Industries'', Chicago, Chicago University Press, 1929, 256 pages.</ref> Kuhn and Kuenne's iterative solution found in 1962, and Tellier's solution found in 1972 apply to the Weber triangle problem as well as to the Fermat one. Kuhn and Kuenne's solution applies also to the case of polygons having more than three sides.\n\nIn its simplest version, the attraction-repulsion problem consists in locating a point D with respect to three points A<sub>1</sub>, A<sub>2</sub> and R in such a way that the attractive forces exerted by points A<sub>1</sub> and A<sub>2</sub>, and the repulsive force exerted by point R cancel each other out as it must do at the optimum. It constitutes a generalization of both the Fermat and Weber problems. It was first formulated and solved, in the triangle case, in 1985 by [[Luc-Normand Tellier]].<ref>Tellier, Luc-Normand, 1985, ''Économie spatiale: rationalité économique de l'espace habité'', Chicoutimi, Gaëtan Morin éditeur, 280 pages.</ref> In 1992, Chen, Hansen, Jaumard and Tuy found a solution to the Tellier problem for the case of polygons having more than three sides.\n\n== Torricelli’s geometrical solution of the Fermat triangle problem ==\n[[File:Figaa.jpg|thumb|alt=Torricelli's solution|right|upright=1.5| Torricelli's geometrical solution of the Fermat triangle problem.]]\n\n[[Evangelista Torricelli]]’s geometrical solution of the Fermat triangle problem stems from two observations:\n\n1– point D is at its optimal location when any significant move out of that location induces a net increase of the total distance to reference points A, B, and C, which means that the optimal point is the only point where an infinitesimal movement towards one of the three reference points induces a reduction of the distance to that point that is equal to the sum of the induced changes in the distances to the two other points; in fact, in the Fermat problem, the advantage to reduce the distance from A by one kilometer is equal to the advantage to reduce the distance from B by one kilometer or the distance from C by the same length; in other words, the activity to be located at D is equally attracted by A, B, and C;\n\n2– according to an important theorem of Euclidean geometry, in a convex quadrilateral inscribed in a circle, the opposite angles are supplementary (that is their sum is equal to 180°); that theorem can also take the following form: if we cut a circle with a chord AB, we get two circle arcs, let us say AiB and AjB; on arc AiB, any ∠AiB angle is the same for any chosen point i, and, on arc AjB, all the ∠AjB angles are also equal for any chosen point j; moreover, the ∠AiB and ∠AjB angles are supplementary.\n\nIt can be proved that the first observation implies that, at the optimum, the angles between the AD, BD, and CD straight lines must be equal to 360° / 3 = 120°. Torricelli deduced from that conclusion that:\n\n1– if any triangle ABD, whose ∠ADB angle is equal to 120°, generates an ABDE convex quadrilateral inscribed in a circle, the ∠ABE angle of the ABE triangle must be equal to (180°&nbsp;&minus;&nbsp;120°)= 60°;\n\n2– one way to determine the set of locations of D for which the ∠ADB angle is equal to 120° is to draw an equilateral ABE triangle (because each angle of an equilateral triangle is equal to 60°), where E is located outside the ABC triangle, and draw a circle round that triangle; then all the D’ points of the circumference of that circle that lie within the ABC circle are such that the ∠AD’B angle is equal to 120°;\n\n3– the same reasoning can be made with respect to triangles ACD, and BCD;\n\n4– this leads to draw two other equilateral triangles ACF and BCG, where F and G are located outside the ABC triangle, as well as two other circles round these equilateral triangles, and to determine the location where the three circles intersect; at that location, the angles between the AD, BD, and CD straight lines is necessarily equal to 120°, which proves that it is the optimal location.\n\n== Simpson’s geometrical solution of the Weber triangle problem ==\n[[File:Figb.jpg|thumb|alt=Simpson's solution|right|upright=1.5| Simpson's geometrical solution of the Weber triangle problem.]]\n\nSimpson's geometrical solution of the so-called “Weber triangle problem” (which was first formulated by [[Thomas Simpson]] in 1750) directly derives from Torricelli's solution. Simpson and Weber stressed the fact that, in a total transportation minimization problem, the advantage to get closer to each attraction point A, B or C depends on what is carried and on its transportation cost. Consequently, the advantage of getting one kilometer closer to A, B or C varies, and the ∠ADB, ∠ADC and ∠BDC angles no more need to be equal to 120°.\n\nSimpson demonstrated that, in the same way as, in the Fermat triangle problem case, the constructed triangles ABE, ACF and BCG were equilateral because the three attractive forces were equal, in the Weber triangle problem case, the constructed triangles ABE, ACF and BCG, where E, F and G are located outside the ABC triangle, must be proportional to the attractive forces of the location system.\n\nThe solution is such that:\n\n1– in the constructed triangle ABE, the AB side is proportional to the attractive force <sub>C</sub>w pointing towards C, the AE side is proportional to the attractive force <sub>B</sub>w pointing towards B, and the BE side is proportional to the attractive force <sub>A</sub>w pointing towards A;\n\n2– in the constructed triangle BCG, the BC side is proportional to the attractive force <sub>A</sub>w pointing towards A, the BG side is proportional to the attractive force <sub>B</sub>w pointing towards B, and the CG side is proportional to the attractive force <sub>C</sub>w pointing towards C;\n\n3– the optimal point D is located at the intersection of the two circumferences drawn round the ABE and BCG constructed triangles.\n\nA third triangle of forces ACF, where F is located outside the ABC triangle, can be drawn based on the AC side, and a third circumference can be traced round that triangle. That third circumference crosses the two previous ones at the same point D.\n\n== Tellier’s geometrical solution of the attraction-repulsion triangle problem ==\n[[File:Figc.jpg|thumb|alt=Tellier's solution|right|upright=1.5| Tellier's geometrical solution of the attraction-repulsion triangle problem.]]\n\nA geometrical solution exists for the attraction-repulsion triangle problem. Its discovery is rather recent.<ref>Tellier, Luc-Normand, 2013, « Annexe 1 : Solution géométrique du cas triangulaire du problème d’attraction-répulsion », annex of the paper of Pierre Hansen, Christophe Meyer and Luc-Normand Tellier, « Modèles topodynamique et de la Nouvelle économie géographique : compatibilité, convergence et avantages comparés », in Marc-Urbain Proulx (ed.), 2013, ''Sciences du territoire II : méthodologies'', Québec, Presses de l’Université du Québec.</ref>  That geometrical solution differs from the two previous ones since, in this case, the two constructed force triangles overlap the A<sub>1</sub>A<sub>2</sub>R location triangle (where A<sub>1</sub> and A<sub>2</sub> are attraction points, and R, a repulsion one), while, in the preceding cases, they never did.\n\nThis solution is such that:\n\n1– in the constructed triangle RA<sub>2</sub>H, which partly overlaps the A<sub>1</sub>A<sub>2</sub>R location triangle, the RA<sub>2</sub> side is proportional to the attractive force <sub>A1</sub>w pointing towards A<sub>1</sub>, the RH side is proportional to the attractive force <sub>A2</sub>w pointing towards A<sub>2</sub>, and the A<sub>2</sub>H side is proportional to the repulsive force <sub>R</sub>w pushing away from point R;\n\n2– in the constructed triangle RA<sub>1</sub>I, which partly overlaps the A<sub>1</sub>A<sub>2</sub>R location triangle, the RA<sub>1</sub> side is proportional to the attractive force <sub>A2</sub>w pointing towards A<sub>2</sub>, the RI side is proportional to the attractive force <sub>A1</sub>w pointing towards A<sub>1</sub>, and the A<sub>1</sub>I side is proportional to the repulsive force <sub>R</sub>w pushing away from point R;\n\n3– the optimal point D is located at the intersection of the two circumferences drawn round the RA<sub>2</sub>H and RA<sub>1</sub>I constructed triangles.\nThis solution is useless if one of the forces is greater than the sum of the two other ones or if the angles are not compatible. In some cases, no force is larger than the two other ones, and the angles are not compatible; then, the optimal location lies at the point that exerts the greater attractive force.\n\n== Tellier’s trigonometric solution of the Fermat and Weber triangle problems ==\n[[File:Figd.jpg|thumb|alt=The Weber problem|right|upright=1.1| The angles of the Weber problem.]]\n[[File:Fige.jpg|thumb|alt=Non-coincidence of angles|right|upright=1.1| The case of non-coincidence of the vertices of the α angles.]]\n\nMore than 332 years separate the first formulation of the Fermat triangle problem and the discovery of its non-iterative numerical solution, while a geometrical solution existed for almost all that period of time. Is there an explanation for that? That explanation lies in the possibility of the origins of the three vectors oriented towards the three attraction points not coinciding. If those origins do coincide and lie at the optimum location P, the vectors oriented towards A, B and C, and the sides of the ABC location triangle form the six angles ∠1, ∠2, ∠3, ∠4, ∠5, and ∠6, and the three vectors form the ∠α<sub>A</sub>, ∠α<sub>B</sub> and ∠α<sub>C</sub> angles. It is easy to write the following six equations linking six unknowns (the angles ∠1, ∠2, ∠3, ∠4, ∠5, and ∠6) with six known values (angles ∠A, ∠B, and ∠C, whose values are given, and angles ∠α<sub>A</sub>, ∠α<sub>B</sub> and ∠α<sub>C</sub>, whose values depend only on the relative magnitude of the three attractive forces pointing towards the A, B and C attraction points):\n\n: ∠1 + ∠2 = ∠C ;\n: ∠3 + ∠4 = ∠A ;\n: ∠5 + ∠6 = ∠B ;\n: ∠1 + ∠6 + ∠α<sub>A</sub> = 180° ;\n: ∠2 + ∠3 + ∠α<sub>B</sub> = 180° ;\n: ∠4 + ∠5 + ∠α<sub>C</sub> = 180°.\n\nUnfortunately, this system of six simultaneous equations with six unknowns is undetermined, and the possibility of the origins of the three vectors oriented towards the three attraction points not coinciding explains why. In the case of non-coincidence, we observe that all the six equations are still valid. However, the optimal location P has disappeared because of the triangular hole that exists inside the triangle. In fact, as Tellier (1972)<ref>Tellier, Luc-Normand, 1972, “The Weber Problem: Solution and Interpretation”, ''Geographical Analysis'', vol. 4, no. 3, pp. 215–233.</ref> has shown, that triangular hole had exactly the same proportions as the “forces triangles” we drew in Simpson's geometrical solution.\n\nIn order to solve the problem, we must add to the six simultaneous equations a seventh requirement, which states that there should be no triangular hole in the middle of the location triangle. In other words, the origins of the three vectors must coincide.\n\nTellier's solution of the Fermat and Weber triangle problems involves three steps:\n\n1– Determine the angles ∠α<sub>A</sub>, ∠α<sub>B</sub> and ∠α<sub>C</sub> that are such that the three attractives forces <sub>A</sub>w, <sub>B</sub>w and <sub>C</sub>w cancel each other to ensure equilibrium. This is done by means of the following independent equations:\n\n: cos ∠α<sub>A</sub> = &minus;( <sub>B</sub>w<sup>2</sup> + <sub>C</sub>w<sup>2</sup> &minus; <sub>A</sub>w<sup>2</sup>) / (2 <sub>B</sub>w <sub>C</sub>w)  ;\n: cos ∠α<sub>B</sub> = &minus;( <sub>A</sub>w<sup>2</sup> + <sub>C</sub>w<sup>2</sup> &minus; <sub>B</sub>w<sup>2</sup>) / (2 <sub>A</sub>w <sub>C</sub>w)  ;\n: cos ∠α<sub>C</sub> = &minus;( <sub>A</sub>w<sup>2</sup> + <sub>B</sub>w<sup>2</sup> &minus; <sub>C</sub>w<sup>2</sup>) / (2 <sub>A</sub>w <sub>B</sub>w)  ;\n\n2– Determine the value of angle ∠3 (this equation derives from the requirement that point D must coincide with point E):\n\n: tan ∠3 = (k sin k’) / (1 + k cos k’) ;\n\nwhere k = (CB/CA) (sin ∠α<sub>B</sub> / sin ∠α<sub>A</sub>), and k’ = (∠A +∠B + ∠α<sub>C</sub>) &minus; 180° ;\n\n3– Solve the following system of simultaneous equations where ∠3 is now known:\n\n: ∠1 + ∠2 = ∠C ;\n: ∠3 + ∠4 = ∠A ;\n: ∠5 + ∠6 = ∠B ;\n: ∠1 + ∠6 + ∠α<sub>A</sub> = 180° ;\n: ∠2 + ∠3 + ∠α<sub>B</sub> = 180° ;\n: ∠4 + ∠5 + ∠α<sub>C</sub> = 180°.\n\n== Tellier’s trigonometric solution of the triangle attraction-repulsion problem ==\n[[File:Figf.jpg|thumb|alt= The attraction-repulsion triangle problem |right|upright=1.6| The angles of the attraction-repulsion triangle problem.]]\n[[File:Figg.jpg|thumb|alt= Non-coincidence of points D and E |right|upright=1.6| The case of non-coincidence of points D and E.]]\n\nTellier (1985)<ref>Tellier, Luc-Normand, 1985, ''Économie spatiale: rationalité économique de l'espace habité'', Chicoutimi, Gaëtan Morin éditeur, 280 pages.</ref> extended the Fermat–Weber problem to the case of repulsive forces. Let us examine the triangle case where there are two attractive forces <sub>A1</sub>w and <sub>A2</sub>w, and one repulsive force <sub>R</sub>w. Here as in the previous case, the possibility exists for the origins of the three vectors not to coincide. So the solution must require their coinciding. Tellier's trigonometric solution of this problem is the following:\n\n1– Determine angle ∠e :\n\n: cos ∠e = -( <sub>A1</sub>w<sup>2</sup> + <sub>A2</sub>w<sup>2</sup> &minus; <sub>R</sub>w<sup>2</sup>) / (2 <sub>A1</sub>w <sub>A2</sub>w)  ;\n\n2– Determine angle ∠p :\n: cos ∠p = -( <sub>A1</sub>w<sup>2</sup> + <sub>R</sub>w<sup>2</sup> &minus; <sub>A2</sub>w<sup>2</sup>) / (2 <sub>A1</sub>w <sub>R</sub>w)  ;\n\n3– Determine angle ∠c :\n: ∠c = 180° &minus; ∠p ;\n\n4– Determine angle ∠d :\n: ∠d = ∠e &minus; ∠c ;\n\n5– Determine the value of angle ∠3 (this equation derives from the requirement that point D must coincide with point E):\n: tan ∠3 = x / y ;\nwhere\tx = sin ∠f – (RA<sub>1</sub>/RA<sub>2</sub>)(sin ∠d sin [∠e &minus; ∠b] / sin ∠c) ; \nand\ty = (RA<sub>1</sub>/RA<sub>2</sub>)(sin ∠d cos [∠e &minus; ∠b] / sin ∠c) &minus; cos ∠f ;\n\n6– Determine ∠1 :\n: ∠1 = 180° &minus; ∠e &minus; ∠3 ;\n\n7– Determine ∠5 :\n: ∠5 = 180° &minus; ∠b &minus; ∠c &minus; ∠1 ;\n\n8– Determine ∠2 :\n: ∠2 = ∠a &minus; ∠5 .\n\n== Iterative solutions of the Fermat, Weber and attraction-repulsion problems ==\n\nWhen the number of forces is larger than three, it is no longer possible to determine the angles separating the various forces without taking into account the geometry of the location polygon. Geometric and trigonometric methods are then powerless. Iterative optimizing methods are used in such cases. Kuhn and Kuenne (1962)<ref>Kuhn, Harold W. and Robert E. Kuenne, 1962, \"An Efficient Algorithm for the Numerical Solution of the Generalized Weber Problem in Spatial Economics.\" ''Journal of Regional Science'' 4, 21–34.</ref> suggested an algorithm based on [[iteratively reweighted least squares]] generalizing [[Weiszfeld's algorithm]] for the [[geometric median|unweighted problem]]. Their method is valid for the Fermat and Weber problems involving many forces, but not for the attraction–repulsion problem. In this method, to find an approximation to the point ''y'' minimizing the weighted sum of distances\n:<math>\\sum_{i=1}^n w_i\\, \\|x_i-y\\|,</math>\nan initial approximation to the solution ''y''<sub>0</sub> is found, and then at each stage of the algorithm is moved closer to the optimal solution by setting ''y''<sub>''j''&nbsp;+&nbsp;1</sub> to be the point minimizing the sum of weighted squared distances\n:<math>\\sum_{i=1}^n \\frac{w_i}{\\|x_i-y_j\\|} \\|x_i-y\\|^2</math>\nwhere the initial weights ''w''<sub>''i''</sub> of the input points are divided by the distances from each point to the approximation from the previous stage.\nAs the unique optimal solution to a weighted least squares problem, each successive approximation may be found as a weighted average:\n:<math>\\left. y_{j+1}=\\left( \\sum_{i=1}^n \\frac{w_ix_i}{\\| x_i - y_j \\|} \\right) \\right/ \\left( \\sum_{i=1}^n \\frac{w_i}{\\| x_i - y_j \\|} \\right).</math>\n\nFor the attraction–repulsion problem one has instead to resort to the algorithm proposed by Chen, Hansen, Jaumard and Tuy (1992).<ref>Chen, Pey-Chun, Hansen, Pierre, Jaumard, Brigitte and Hoang Tuy, 1992, \"Weber's Problem with Attraction and Repulsion,\" ''Journal of Regional Science'' 32, 467–486.</ref>\n\n== Interpretation of the land rent theory in the light of the attraction–repulsion problem ==\n\nIn the world of [[location theory|spatial economics]], repulsive forces are omnipresent. Land values are the main illustration of them. In fact a substantial portion of [[Bid rent theory|land value theory]], both rural and urban, can be summed up in the following way.\n\nIn the case where everybody is attracted by a single attraction point (the rural market or the urban central business district), competition between the various bidders who all want to locate at the center will generate land values that will transform the unique attraction point of the system into a repulsion point from the land value point of view, and, at the equilibrium, each inhabitant and activity will be located at the point where the attractive and the repulsive forces exerted by the center on them will cancel out.\n\n== The attraction–repulsion problem and the New Economic Geography ==\n\nThe Tellier problem preceded the emergence of the [[Economic geography#New economic geography|New Economic Geography]]. It is seen by Ottaviano and Thisse (2005)<ref>Ottaviano, Gianmarco and Jacques-François Thisse, 2005, « New Economic Geography: what about the N? », ''Environment and Planning A'' 37, 1707–1725.</ref> as a prelude to the New Economic Geography (NEG) that developed in the 1990s, and earned [[Paul Krugman]] a [[Nobel Memorial Prize]] in Economic Sciences in 2008. The concept of attractive force is akin to the NEG concept of agglomeration or centripetal force, and the concept of repulsive force is akin to the NEG concept of dispersal or centrifugal force.\n\n== Notes ==\n{{reflist}}\n\n==References==\n* Chen, Pey-Chun, Hansen, Pierre, Jaumard, Brigitte and Hoang Tuy, 1992, \"Weber's Problem with Attraction and Repulsion,\" ''Journal of Regional Science'' 32, 467–486.\n* Kuhn, Harold W. and Robert E. Kuenne, 1962, \"An Efficient Algorithm for the Numerical Solution of the Generalized Weber Problem in Spatial Economics.\" ''Journal of Regional Science'' 4, 21–34.\n* Ottaviano, Gianmarco and Jacques-François Thisse, 2005, « New Economic Geography: what about the N? », ''Environment and Planning A'' 37, 1707–1725.\n* Simpson, Thomas, 1750, The Doctrine and Application of Fluxions, London.\n* Tellier, Luc-Normand and Boris Polanski, 1989, “The Weber Problem: Frequency of Different Solution Types and Extension to Repulsive Forces and Dynamic Processes”, ''Journal of Regional Science'', vol 29, no. 3, p.&nbsp;387–405.\n* Tellier, Luc-Normand, 1972, “The Weber Problem: Solution and Interpretation”, ''Geographical Analysis'', vol. 4, no. 3, pp.&nbsp;215–233.\n* Tellier, Luc-Normand, 1985, ''Économie spatiale: rationalité économique de l'espace habité'', Chicoutimi, Gaëtan Morin éditeur, 280 pages.\n* Tellier, Luc-Normand, 2013, « Annexe 1: Solution géométrique du cas triangulaire du problème d’attraction–répulsion », annex of the paper of Pierre Hansen, Christophe Meyer and Luc-Normand Tellier, « Modèles topodynamique et de la Nouvelle économie géographique : compatibilité, convergence et avantages comparés », in Marc-Urbain Proulx (ed.), 2013, ''Sciences du territoire II : méthodologies'', Québec, Presses de l’Université du Québec.\n* Weber, Alfred, 1909, ''Über den Standort der Industrien'', Tübingen, J.C.B. Mohr) — English translation: ''The Theory of the Location of Industries'', Chicago, Chicago University Press, 1929, 256 pages.\n* Wesolowski, Georges, 1993, «The Weber problem: History and perspective», ''Location Science'', Vol. 1, p.&nbsp;5–23.\n\n<!--- After listing your sources please cite them using inline citations and place them after the information they cite. Please see http://en.wikipedia.org/wiki/Wikipedia:REFB for instructions on how to add citations. --->\n\n==External links==\n* {{springer|title=Weber problem|id=p/w120040}}\n\n{{Portal|Mathematics|Business and economics}}\n\n[[Category:Applied mathematics]]\n[[Category:Economic geography]]\n[[Category:Mathematical optimization in business]]\n[[Category:Regional science]]"
    },
    {
      "title": "Inventory optimization",
      "url": "https://en.wikipedia.org/wiki/Inventory_optimization",
      "text": "'''Inventory optimization''' is a method of balancing capital investment constraints or objectives and service-level goals over a large assortment of stock-keeping units (SKUs) while  taking  demand and supply volatility  into account.\n\n== Inventory management challenges ==\nEvery company has the challenge of matching its supply volume to customer demand. How well the company manages this challenge has a major impact on its profitability.<ref>Yogesh Malik, Alex Niemeyer, and Brian Ruwadi, “[https://web.archive.org/web/20111106082811/http://www.mckinseyquarterly.com/Building_the_supply_chain_of_the_future_2729 Building the supply chain of the future],” ''McKinsey Quarterly'', January 2011.</ref> In contrast to the traditional \"binge and purge\" inventory cycle in which companies over-purchase product to prepare for possible demand spikes and then discards extra product, inventory optimization seeks to more efficiently match supply to expected customer demand.<ref>{{cite web|last1=King|first1=Bill|title=Inventory Optimization & Its Role in Businesses|url=https://www.avidxchange.com/inventory-optimization-role-businesses/|website=AvidXchange|accessdate=26 April 2017|date=11 January 2017}}</ref> APQC Open Standards data shows that the median company carries an inventory of 10.6 percent of annual revenues. The typical cost of carrying inventory is at least 10.0 percent of the inventory value. So the median company spends over 1 percent of revenues carrying inventory, although for some companies the number is much higher.<ref>Marisa Brown, “[http://www.scmr.com/article/inventory_optimization_show_me_the_money Inventory Optimization: Show Me the Money],” ''Supply Chain Management Review'', July 19, 2011.</ref>  \n\nAlso, the amount of inventory held has a major impact on available cash. With working capital at a premium, it’s important for companies to keep inventory levels as low possible and to sell inventory as quickly as possible.<ref>William Brandel, “[http://www.computerworld.com/s/article/341290/Free_Up_Cash_ Inventory Optimization Saves Working Capital in Tough Times],” ''Computerworld'', August 24, 2009.</ref> When Wall Street analysts look at a company’s performance to make earnings forecasts and buy and sell recommendations, inventory is always one of the top factors they consider.<ref>Dan Gilmore, “[http://www.scdigest.com/assets/FirstThoughts/08-08-28.php?cid=1885 Supply Chain News: What is Inventory Optimization?],” ''Supply Chain Digest'', August 28, 2008.</ref> Studies have shown a 77 percent correlation between overall manufacturing profitability and inventory turns.<ref>Vijay Sangam, “[http://vijaysangamworld.wordpress.com/2010/09/02/inventory-optimization/ Inventory Optimization],” ''Supply Chain World Blog'', September 2, 2010.</ref>  \n\nThe challenge of managing inventory is increased by the “[[Long Tail]]” phenomenon which is causing a greater percentage of total sales for many companies to come from a large number of products, each with low sales frequency.<ref>Dan Gilmore, “[http://www.scdigest.com/assets/FirstThoughts/08-08-28.php?cid=1885 Supply Chain News: What is Inventory Optimization?],” ''Supply Chain Digest'', August 28, 2008.</ref> Shorter and more frequent product cycles which are required to meet the needs of more sophisticated markets create the need to manage supply chains containing more products and parts.<ref>William Brandel, \"[http://www.computerworld.com/s/article/341290/Free_Up_Cash_ Inventory Optimization Saves Working Capital in Tough Times],” ''Computerworld'', August 24, 2009.</ref> Hence, businesses need to understand how this affects their inventory and how they can seize the opportunities presented by such products.<ref>{{Cite web|title = The Long Tail of Inventory... and 3 reasons why it's important|url = https://www.tradegecko.com/blog/the-long-tail-of-inventory-3-reasons|website = www.tradegecko.com|accessdate = 2015-11-24}}</ref>   \n\nAt the same time, planning frequencies and time-buckets are moving from monthly/weekly to daily and the number of managed stocking locations from dozens in distribution centers to hundreds or thousands at the points of sale (POS). This leads to a large number of time series with a high level of demand volatility.<ref>P.J. Jakovljevic, “A Modern Tale of Long (Supply Chain) Tails — Part I,” Technical Evaluation Centers Blog, July 2009.</ref> This explains one of the main challenges in managing modern supply chains, the so-called “[[bullwhip effect]]”, which often causes small changes in actual demand to cause a much larger change in perceived demand, which in turn can mislead companies to make bigger changes in inventory than are really necessary.<ref>“[http://wn.com/Bullwhip_Effect_in_Supply_Chain Bullwhip Effect in Supply Chain],” ''World News''.</ref>\n\n== Non-optimized approach ==\nWithout inventory optimization, companies commonly set inventory targets using rules of thumb or single stage calculations. Rules of thumb normally involve setting a number of days of supply as a coverage target. Single stage calculations look at a single item in a single location and calculate the amount of inventory required to meet demand.<ref>Sean P. Willems, “[http://www.scmr.com/article/how_inventory_optimization_opens_pathways_to_profitability/ How Inventory Optimization Opens Pathways to Profitability],” ''Supply Chain Management Review'', March/April 2011.</ref>\n\n== Deterministic vs. stochastic ==\nInventory optimization models can be either [[Deterministic system|deterministic]]—with every set of variable states uniquely determined by the parameters in the model – or [[Stochastic process|stochastic]]—with variable states described by probability distributions.<ref>Leslie Hansen Harps, “[http://www.inboundlogistics.com/cms/article/optimizing-your-supply-chain-a-model-approach/ Optimizing Your Supply Chain: A Model Approach],” ''Inbound Logistics'', April 2003.</ref> Stochastic optimization takes supply uncertainty into account that, for example, 6 percent of orders from an overseas supplier are 1–3 days late, 1 percent are 4–6 days late, 5 percent are 7–14 days late and 8 percent are more than 14 days late.<ref>“[http://www.uncg.edu/bae/isom/tisec/es_inventory.pdf Are Your Inventory Management Practices Outdated],” AberdeenGroup, March 1, 2005. {{webarchive|url=https://web.archive.org/web/20091229194219/http://www.uncg.edu/bae/isom/tisec/es_inventory.pdf |date=December 29, 2009 }}</ref>  \n\n[[Stochastic optimization]] also accounts for demand volatility which is a top priority among the challenges faced by supply chain professionals.<ref>Tim Payne, “Magic Quadrant for Supply Chain Planning for Process Automation,” Gartner Research, ID Number G00200934. September 3, 2010.</ref> For example, management predicts a 65 percent probability of selling 500 units, a 20 percent probability of selling 400 units and a 15 percent probability of selling 600 units. High service levels can be achieved with cost overruns, excessive inventory and firefighting, but higher profitability can be achieved by understanding the sources of volatility and planning appropriately. The result is a better understanding of the inventory requirements than with a deterministic approach.<ref>“Are Your Inventory Management Practices Outdated,” AberdeenGroup, March 1, 2005.</ref>\n\n== Single vs. multi-echelon ==\nSingle-echelon location problems are single-type problems such that either the material flow coming out or the material flow entering the facilities to be located is negligible. In multiple-echelon problems, both inbound and outbound commodities are relevant. This is the case, for example, when DCs have to be located taking into account both the transportation cost from plants to DCs and the transportation cost from DCs to customers. In multiple-echelon problems, constraints aiming at balancing inbound and outbound flows have to be considered.<ref>Introduction to Logistics Systems Planning and Control - Gianpaolo Ghiani, Gilbert Laporte, Roberto Musmanno\n\nhttp://onlinelibrary.wiley.com/book/10.1002/0470014040</ref>   \n\nA sequential single-echelon approach forecasts demand and determines required inventory for each echelon separately. Multi-echelon inventory optimization determines the correct levels of inventory across the network based on demand variability at the various nodes and the performance (lead time, delays, service level) at the higher echelons.<ref>Noha Tohamy, “A User Guide to Network Design and Inventory Optimization Solutions,” Gartner Research, Publication Number G00209211, December 8, 2010.</ref>   \n\nMulti-echelon inventory optimization looks at inventory levels holistically across the supply chain while taking into account the impact of inventories at any given level or echelon on other echelons. For example, if the product sold in a retailer’s outlet is received from one of its distribution centers, the distribution center represents one echelon of the supply chain and the outlet another one. It should be clear that the amount of stock needed at the outlets is a function of the service received from the distribution center. The better the service that is provided upstream, the smaller the protection that is needed downstream.  The goal of multi-echelon inventory optimization is to continually update and optimize safety stock levels across all of these echelons.<ref>Dan Gilmore, “[http://www.scdigest.com/assets/FirstThoughts/08-08-28.php?cid=1885 Supply Chain News: What is Inventory Optimization?],” ''Supply Chain Digest'', August 28, 2008.</ref>  \n\nMulti-echelon inventory optimization represents the state of the art approach to optimize inventory across the end to end supply chain. Modeling multiple stages allows other types of inventory, including cycle stock and prebuild along with safety stock due to time phased demands, to be accurately predicted. As part of inventory optimization, supplier performance, customer service and internal asset metrics should be continuously monitored to enable continuous improvement.<ref>“[http://www.apqc.org/knowledge-base/documents/inventory-optimization-balancing-asset-vs-service-tradeoff-report-overview Inventory Optimization: Balancing the Asset versus Service Tradeoff],” APQC Best Practices Report, 2011.</ref>\n\n== Benefits ==\nCompanies have achieved financial benefits by employing inventory optimization. A study by [[International Data Corporation|IDC]] Manufacturing Insights found that many organizations that utilized inventory optimization reduced inventory levels by up to 25 percent in one year and enjoyed a [[discounted cash flow]] above 50 percent in less than two years.<ref>William Brandel, \"[http://www.computerworld.com/s/article/341290/Free_Up_Cash_ Inventory Optimization Saves Working Capital in Tough Times],” ''Computerworld'', August 24, 2009.</ref>  \n\n[[Electrocomponents]], a United Kingdom based world’s largest distributor of electronics and maintenance products, increased profits by £36 million by using inventory optimization to achieve higher service levels while reducing inventory.<ref>Sarah Lafferty, “[http://content.yudu.com/A1v72o/scm1201EU/resources/index.htm?referrerUrl Handling Volatile Demand],” ''Supply Chain Movement'', Number 1, Quarter 1, 2012. Pages 36-38.</ref> [[Castrol]] used inventory optimization to reduce finished goods inventory by an average of 35 percent in two years while increasing service levels (defined as line fill rates) by 9 percent.<ref>Hallie Forcino, “[http://www.managingautomation.com/maonline/magazine/read/view/Break_on_Through_to_the_Other_Side_2326567 Break on Through to the Other Side],” ''Managing Automation'', February 2005. {{webarchive|url=https://web.archive.org/web/20130510022255/http://www.managingautomation.com/maonline/magazine/read/view/Break_on_Through_to_the_Other_Side_2326567 |date=2013-05-10 }}</ref> Smiths Medical, a division of [[Smiths Group]], used inventory optimization to better address demand volatility and supply variability, thus reducing the risk of both understocks and overstocks while smoothing out manufacturing cycles.<ref>Robert J. Bowman, “For Smiths Medical, Service Quality Is an Ever-Moving Goal,” ''Supply Chain Brain'', June 15, 2012.</ref>\n\n== See also ==\n* [[Inventory]]\n* [[Inventory theory]]\n* [[Supply chain management]]\n* [[Logistics]]\n* [[Mathematical optimization]]\n\n== References ==\n<!--- See [[Wikipedia:Footnotes]] on how to create references using <ref></ref> tags which will then appear here automatically -->\n{{Reflist}}\n\n<!-- Categories -->\n[[Category:Inventory optimization| ]]"
    },
    {
      "title": "Assemble-to-order system",
      "url": "https://en.wikipedia.org/wiki/Assemble-to-order_system",
      "text": "In [[applied probability]], an '''assemble-to-order system''' is a model of a warehouse operating a [[build to order]] policy where products are assembled from components only once an order has been made.\nThe time to assemble a product from components is negligible, but the time to create components is significant (for example, they must be ordered from a supplier).<ref name=\"song\">{{Cite book | last1 = Song | first1 = J. S. | last2 = Zipkin | first2 = P. | chapter = Supply Chain Operations: Assemble-to-Order Systems | doi = 10.1016/S0927-0507(03)11011-0 | title = Supply Chain Management: Design, Coordination and Operation | series = Handbooks in Operations Research and Management Science | volume = 11 | pages = 561–596| year = 2003 | isbn = 9780444513281 | url = https://faculty.fuqua.duke.edu/~jssong/bio/Publications/AtoctoSurvey28Jan03.pdf| pmid =  | pmc = }}</ref>\n\nResearch typically focuses on finding good policies for inventory levels and on the impact of different configurations (such as having more shared parts). The special case of only one product is an assembly system, the case of just once component is a distribution system.<ref name=\"song\" />\n\n==Model definition==\n\n===Single period model===\n\nThis case is a generalisation of the [[newsvendor model]] (which has only one component and one product). The problem involves three stages and we give one formation of the problem below<ref>{{Cite journal | last1 = Gerchak | first1 = Y. | last2 = Henig | first2 = M. | doi = 10.1016/0167-6377(86)90089-1 | title = An inventory model with component commonality | journal = Operations Research Letters | volume = 5 | issue = 3 | pages = 157 | year = 1986 | pmid =  | pmc = }}</ref>\n\n# components acquired\n# demand realized\n# components allocated, products produced\n\nWe use the following notation<ref name=\"song\" />\n{| class=\"wikitable\"\n|-\n! Symbol\n! Meaning\n|-\n| ''m''\n| total number of components\n|-\n| ''n''\n| total number of products\n|-\n| ''a''<sub>''i''</sub><sup>''j''</sup> \n| units of component ''i'' required to make one unit of product ''j''\n|-\n| ''d''<sub>''j''</sub>\n| demand for product ''j''\n|-\n| ''y''<sub>''i''</sub>\n| supply for component ''i''\n|-\n| ''p''<sub>''j''</sub>\n| penalty cost for unit shortage of product ''j''\n|-\n| ''h''<sub>''i''</sub>\n| cost for unit excess of component ''i''\n|-\n| ''z''<sub>''j''</sub>\n| production level of product ''j''\n|-\n| ''w''<sub>''j''</sub>\n| shortage of product ''j''\n|-\n| ''x''<sub>''i''</sub>\n| excess of component ''i''\n|}\n\nIn the final stage when demands are known the optimization problem faced is to \n\n:<math>\\begin{align}\n\\text{minimize } G(\\mathbf y, \\mathbf d) &= \\mathbf h' \\mathbf x+ \\mathbf p' \\mathbf w\\\\\n\\text{subject to } \nA \\mathbf z + \\mathbf x &= \\mathbf y\\\\\n\\mathbf z + \\mathbf w &= \\mathbf d\\\\\n\\mathbf w, \\mathbf x, \\mathbf z &\\geq 0,\\end{align}</math>\n\nand we can therefore write the optimization problem at the first stage as\n\n:<math>\\begin{align}\n\\text{minimize } & c(\\mathbf y - \\mathbf x_0) + \\mathbb E_{\\mathbf d} [ G(\\mathbf y, \\mathbf d) ] \\\\\n\\text{subject to } & \\mathbf y \\geq \\mathbf x_0,\\end{align}</math>\n\nwith '''x'''<sub>0</sub> representing the starting inventory vector and ''c'' the cost function for acquiring the components.\n\n===Continuous time===\n\nIn continuous time orders for products arrive according to a [[Poisson process]] and the time required to produce components are [[independent and identically distributed]] for each component. Two problems typically studied in this system are to minimize the expected backlog of orders subject to a constraint on the component inventory, and to minimize the expected component inventory subject to constraints on the rate at which orders must be completed.<ref>{{Cite journal | last1 = Song | first1 = J. S. | last2 = Yao | first2 = D. D. | doi = 10.1287/opre.50.5.889.372 | title = Performance Analysis and Optimization of Assemble-to-Order Systems with Random Lead Times | journal = [[Operations Research (journal)|Operations Research]]| volume = 50 | issue = 5 | pages = 889 | year = 2002 | jstor = 3088488| pmid =  | url = https://faculty.fuqua.duke.edu/~jssong/bio/Publications/SongYao_OR.pdf| pmc = }}</ref>\n\n==References==\n\n{{Reflist}}\n\n{{Production Approaches}}\n[[Category:Inventory optimization]]"
    },
    {
      "title": "Base stock model",
      "url": "https://en.wikipedia.org/wiki/Base_stock_model",
      "text": "The '''base stock model''' is a statistical model in [[inventory theory]].<ref name=\"FacPhy\">W.H. Hopp, M. L. Spearman, Factory Physics, Waveland Press 2008</ref> In this model inventory is refilled one unit at a time and demand is [[random]]. If there is only one replenishment, then the problem can be solved with the [[newsvendor model]].\n\n==Overview==\n\n===Assumptions===\n\n# Products can be analyzed individually\n# Demands occur one at a time (no batch orders)\n# Unfilled demand is back-ordered (no lost sales)\n# Replenishment lead times are fixed and known\n# Replenishments are ordered one at a time\n# Demand is modeled by a continuous probability distribution\n\n===Variables===\n\n*<math>L</math> = Replenishment lead time\n*<math>X</math> = Demand during replenishment lead time\n*<math>g(x)</math> = [[probability density function]] of demand during lead time\n*<math>G(x)</math> = [[cumulative distribution function]] of demand during lead time\n*<math>\\theta</math> = mean demand during lead time\n*<math>h</math> = cost to carry one unit of inventory for 1 year\n*<math>b</math> = cost to carry one unit of back-order for 1 year\n*<math>r</math> = [[reorder point]]\n*<math>SS=r-\\theta</math>, [[safety stock]] level\n*<math>S(r)</math> = fill rate\n*<math>B(r)</math> = average number of outstanding back-orders\n*<math>I(r)</math> = average on-hand inventory level\n\n==Fill rate, back-order level and inventory level==\n\nIn a base-stock system inventory position is given by on-hand inventory-backorders+orders and since inventory never goes negative, inventory position=r+1. Once an order is placed the base stock level is r+1 and if X≤r+1 there won't be a backorder. The probability that an order does not result in back-order is therefore:\n\n<math>P(X\\leq r+1)=G(r+1)</math>\n\nSince this holds for all orders, the fill rate is:\n\n<math>S(r)=G(r+1)</math>\n\nIf demand is normally distributed <math>\\mathcal{N}(\\theta,\\,\\sigma^2)</math>, the fill rate is given by:\n\n<math>S(r)=\\phi\\left( \\frac{r+1-\\theta}{\\sigma} \\right)</math>\n\nWhere <math>\\phi()</math> is [[cumulative distribution function]] for the [[standard normal]]. At any point in time, there are orders placed that are equal to the demand X that has occurred, therefore on-hand inventory-backorders=inventory position-orders=r+1-X. In expectation this means:\n\n<math>I(r)=r+1-\\theta+B(r)</math>\n\nIn general the number of outstanding orders is X=x and the number of back-orders is:\n\n<math>Backorders=\\begin{cases} 0, & x < r+1 \\\\ x-r-1, & x \\ge r+1 \\end{cases} </math>\n\nThe expected back order level is therefore given by:\n\n<math>B(r)=\\int_{r}^{+\\infty }\\left( x-r-1 \\right)g(x)dx=\\int_{r+1}^{+\\infty }\\left( x-r \\right)g(x)dx</math>\n\nAgain, if demand is normally distributed:<ref>Zipkin, Foundations of inventory management, McGrawHill 2000</ref>\n\n<math>B(r)=(\\theta-r)[1-\\phi(z)]+\\sigma\\phi(z)</math>\n\nWhere <math>z</math> is the [[Probit|inverse distribution function of a standard normal distribution]].\n\n==Total cost function and optimal reorder point==\n\nThe total cost is given by the sum of holdings costs and backorders costs:\n\n<math>TC=hI(r)+bB(r)</math>\n\nIt can be proven that:<ref name=\"FacPhy\"/>\n\n{{Equation box 1\n|indent =:\n|title=\n|equation = <math>G(r^{*}+1)=\\frac{b}{b+h}</math>\n|cellpadding\n|border\n|border colour = #50C878\n|background colour = #ECFCF4}}\n\nWhere r* is the optimal reorder point. If demand is normal then r* can be obtained by:\n\n<math>r^{*}+1=\\theta+z\\sigma</math>\n\n==See also==\n\n* Infinite fill rate for the part being produced: [[Economic order quantity]]\n* Constant fill rate for the part being produced: [[Economic production quantity]]\n* Demand is random: classical [[Newsvendor model]]\n* Demand varies deterministically over time: [[Dynamic lot size model]]\n* Several products produced on the same machine: [[Economic lot scheduling problem]]\n\n==References==\n\n{{reflist}}\n\n[[Category:Inventory optimization]]"
    },
    {
      "title": "Carrying cost",
      "url": "https://en.wikipedia.org/wiki/Carrying_cost",
      "text": "{{About|the marketing term|the financial term|Cost of carry}}\nIn marketing, '''carrying cost''', '''carrying cost of inventory''' or '''holding cost''' refers to the total cost of holding [[inventory]]. This includes warehousing costs such as rent, utilities and salaries, financial costs such as [[opportunity cost]], and inventory costs related to perishability, ''shrinkage'' ([[leakage (economics)|leakage]]) and insurance.<ref name=\"RussellTaylor\">{{Citation\n  | last1 = Russell | first1 = Roberta S.\n  | last2 = Taylor  | first2 = Bernard W.\n  | title = Operations Management: Quality and Competitiveness in a Global Environment, Fifth Edition\n  | publisher = [[John Wiley & Sons]]\n  | year = 2006\n  | isbn = 978-0-471-69209-6 }}</ref> Carrying cost also includes the [[opportunity cost]] of reduced responsiveness to customers' changing requirements, slowed introduction of improved items, and the inventory's value and direct expenses, since that money could be used for other purposes. When there are no transaction costs for shipment, carrying costs are minimized when no excess inventory is held at all, as in a [[Just In Time (business)|Just In Time]] production system.<ref name=\"RussellTaylor\" />\n\nExcess inventory can be held for one of three reasons. Cycle stock is held based on the [[Reorder point|re-order point]], and defines the inventory that must be held for production, sale or consumption during the time between re-order and delivery.{{citation needed|date=September 2018}} [[Safety stock]] is held to account for variability, either upstream in supplier lead time, or downstream in customer demand. Physical stock is held by consumer retailers to provide consumers with a perception of plenty. Carrying costs typically range between 20-30% of a company's inventory value.\n\n==Definitions==\nThe cost consists of four different factors:\n# The expenses of putting the inventory in storage\n#Salary and wages of workers\n#Maintenance in the long term\n#All utilities used in carrying the storage <ref>{{cite web|title=What is a Carrying Cost?|url=http://www.wisegeek.com/what-is-carrying-cost.htm|website=wisegeek|accessdate=31 October 2015}}</ref>\n\nMoreover, the carrying cost will mostly appear as a '''percentage''' number. It provides an idea of how long the inventory could be held before the company makes a loss, which also tells the manager how much to order.\n\n==Why do companies hold inventory==\nInventory is a property of a company that is ready for them to sell.<ref>{{cite web|title=‘Inventory Carrying Cost’|url=https://vijaysangamworld.wordpress.com/tag/inventory-carrying-cost/|website=Supply Chain World|publisher=Vijay Sangam|accessdate=1 November 2015}}</ref> There are five basic reasons that a company would need inventory.\n\n1. '''Safety inventory'''\n\nThis would act like a buffer to make sure that the company would have excess products for sale if consumer demands exceed their expectation.<ref name=\":3\">{{cite web|last1=Terwiesch|first1=Prof. Dr. Christian|title=Why do companies hold inventory?|url=https://lecturenotesblog.wordpress.com/2013/07/04/why-do-companies-hold-inventory/|website=THE LECTURE NOTES BLOG LECTURE NOTES FROM GREAT MOOCS|accessdate=1 November 2015}}</ref>\n\n2. '''Cater to Cyclical and Seasonal Demand'''\n\nThese kind of inventory are use for predicable events that would cause a change in people’s demand. For example, candy companies can start to produce extra sweets that have long duration period. Build up seasonal inventory gradually to match people’s sharply increasing demand before Halloween.<ref name=\":3\"/>\n\n3. '''Cycle inventory'''\n\nFirst of all, we need to go through the idea of [[economic order quantity]] (EOQ).<ref>{{cite web|last1=Bozarth|first1=Cecil|title=ECONOMIC ORDER QUANTITY (EOQ) MODEL: Inventory Management Models : A Tutorial|url=https://scm.ncsu.edu/scm-articles/article/economic-order-quantity-eoq-model-inventory-management-models-a-tutorial|website=NC STATE|accessdate=2 November 2015}}</ref> EOQ is an attempt to balance inventory holding or carrying costs with the costs incurred from ordering or setting up machinery. The total cost will minimized when the ordering cost and the carrying cost equal to each other. While customer order a significant quantities of products, cycle inventory would be able to save cost and act as a buffer for the company to purchase more supplies.<ref name=\":3\"/>\n\n4. '''In-transit Inventory'''<ref>{{cite web|title=What Is Transit Inventory?|url=http://smallbusiness.chron.com/transit-inventory-32831.html|website=Chron|publisher=Jared Lewis, Demand Media|accessdate=2 November 2015}}</ref>\n\nThis kind of inventory would save company a lot transportation cost and help the transition process become less time-consuming. For example, if the company request a particular raw material from overseas market. Purchase in bulk will save them a lot transportation cost from overseas shipment fees.{{citation needed|date=February 2016}}\n\n5. '''Dead Inventory'''\n\nDead inventory or dead stock is consisting of different kinds of products that was outdated or only a few consumer requests this kind of product. So manager pulled them from store shelves. \nTo reduce costs of holding this kinds of products, company could hold discount events or imply price reduction to attraction consumers attentions.<ref>{{cite web|title=How Does Dead Inventory Cost Money?|url=http://smallbusiness.chron.com/dead-inventory-cost-money-64935.html|website=Chron|publisher=Neil Kokemuller, Demand Media|accessdate=2 November 2015}}</ref>\n\n==Ways to reduce carrying cost==\nFor most firms they see profit maximizing, as their prior objectives. in order to reach higher profit here are some methods of reducing carrying cost.\n\n1. '''Base the number of stocks on the situation of Economics''':\nThe number of stocks should be changed with consumers demand, the situation of the industry also the [[exchange rate]] of the currency. When the economic is in [[recession]] or the currency depreciate residents’ purchasing power would decreased.<ref name=\":0\">{{cite web|title=25 Ways to Lower Inventory Costs|url=http://www.tompkinsinc.com/25-ways-lower-inventory-costs/|website=Tompkins International|accessdate=31 October 2015|archive-url=https://web.archive.org/web/20151107185844/http://www.tompkinsinc.com/25-ways-lower-inventory-costs/|archive-date=7 November 2015|dead-url=yes}}</ref>\n\n2. '''Improve the layout of warehouse''':\nInstead of renting a new place, the manager might consider about the idea of rearrange the layout of the warehouse that they owned.<ref>{{cite web|title=10 ways to reduce inventory cost|url=https://thesupplychainlab.wordpress.com/2008/10/21/10-ways-to-reduce-inventory-cost/|website=the supply chain lab|accessdate=31 October 2015}}</ref> An inefficient layout may increase the [[risk]] of shipping the wrong products to consumers this would both increase transportation cost and become time consuming. To improve the layout the company could either increase the reception area or apply [[market segmentation|segmentation]]. This will  reduce the cost as well as increase labour’s [[productivity]]!<ref>{{cite web |title=Improving the Layout of your Warehouse |url=http://www.aalhysterforklifts.com.au/index.php/about/blog-post/improving_the_layout_of_your_warehouse |website=adaptalift |accessdate=31 October 2015 |deadurl=yes |archiveurl=https://web.archive.org/web/20151107095940/http://www.aalhysterforklifts.com.au/index.php/about/blog-post/improving_the_layout_of_your_warehouse |archivedate=7 November 2015 |df= }}</ref>\n\n3.'''Build long-term agreements with suppliers''': Signing long-term contract with suppliers may increase the supplier’s financial security and the company may receive a lower price. This will become a win-win situation. Also the supplier might be willing to decrease the time period of delivery their products to the warehouse, for example from once a month to once a week. Hence, the company would be able to switch to a smaller warehouse, as they don’t need to stock that much products at a time. Furthermore, this would also reduce the risks of loss and depreciation of the products.<ref>{{cite web|title=FIVE WAYS TO LOWER INVENTORY COSTS|url=http://www.viconerubber.com/en/articles/five-ways-to-lower-inventory-costs|website=vicone|accessdate=31 October 2015}}</ref>\n\n4.''' Creating an effective database''':\nThe database should include things like retailer, date, quantity, quality, degree of advertising and the time taken until sold out. This will make sure that the future employees can learn from the past experience while making decisions. For example, if the manager want to hold a big discount event to clear the products that have been left in stock for a long time. Then he can go through the past data to find out if there is any event like this before and how was the result. The manager would be able to forecast the budget and make some improvements base on the past events’ record.<ref name=\":0\"/>\n\n==See also==\n* [[Inventory]]\n* [[Holding Cost]]\n* [[Inventory Turnover]]\n* [[Weighted average cost of capital]]\n* [[Theory of Constraints]]\n* [[Cost accounting]]\n* [[Throughput accounting]]\n* [[Is the Deadstock of inventory in the showroom, Number #1 problem?]]\n\n==Further reading==\n* [https://web.archive.org/web/20160304214511/http://web.applied.com/assets/attachments/B39518DE-AC6B-E3C2-7F966A30F041F783.pdf Applied Industrial Technologies.“Reducing Inventories and Cost of Operations While Improving Customer Support”]<ref>{{cite web |title=Reducing Inventories and Cost of Operations While Improving Customer Support |url=http://web.applied.com |website=web.applied.com |publisher=Applied Industrial Technologies |accessdate=31 October 2015 |deadurl=yes |archiveurl=https://web.archive.org/web/20151103000325/http://web.applied.com/ |archivedate=3 November 2015 |df= }}</ref>\n* [http://www.remassoc.com/portals/0/remprecc.pdf REM Associates.\"Methodology of Calculating Inventory Carrying Costs\"]<ref>{{cite web|title=Methodology of Calculating Inventory Carrying Costs|url=http://www.remassoc.com/portals/0/remprecc.pdf|website=www.remassoc.com|publisher=REM Associates|accessdate=31 October 2015}}</ref>\n* [http://www.diva-portal.org/smash/get/diva2:427755/FULLTEXT01.pdf Lower inventory levels and costs due to reduction of transportation time]<ref>{{cite web|last1=Multanen|first1=Hannu|title=Lower inventory levels and costs due to reduction of transportation time|url=http://www.diva-portal.org|website=diva-portal|accessdate=31 October 2015}}</ref>\n* [http://econpapers.repec.org/paper/redsed004/814.htm Why Do Firms Hold Inventories?]<ref>{{cite web|title=Why Do Firms Hold Inventories?|url=http://econpapers.repec.org/paper/redsed004/814.htm|website=Econpapers|publisher=Lawrence Christiano|accessdate=1 November 2015}}</ref>\n* [http://www.accaglobal.com/content/dam/acca/global/PDF-students/2012t/sa_mar10_inventory_cat10.pdf inventory]<ref>{{cite web|title=Inventory|url=http://www.accaglobal.com|website=ACCA|accessdate=1 November 2015}}</ref>\n* Anupindi, Ravi, et al. Managing Business Process Flows: Principles of Operations Management. 2nd ed. Upper Saddle River, NJ: Pearson Prentice Hall, 2004.\n* Cox, James F., III, and John H. Blackstone, Jr. APICS Dictionary. 9th ed. Falls Church VA: American Production and Inventory Control Society, 1998.\n* Meredith, Jack R., and Scott M. Shafer. Operations Management for MBAs. 2nd ed. New York: John Wiley & Sons Inc., 2002.\n* Stevenson, William J. Production/Operations Management. 8th ed. Boston: Irwin/McGraw-Hill, 2005.\n\n==References==\n\n{{Reflist}}\n\n[[Category:Inventory optimization]]\n[[Category:Costs]]"
    },
    {
      "title": "Dynamic lot-size model",
      "url": "https://en.wikipedia.org/wiki/Dynamic_lot-size_model",
      "text": "{{Use dmy dates|date=August 2012}}\nThe '''dynamic lot-size model''' in [[inventory theory]], is a generalization of the [[economic order quantity]] model that takes into account that demand for the product varies over time. The model was introduced by [[Harvey M. Wagner]] and [[Thomson M. Whitin]] in 1958.<ref name=\"WW1958\">[[Harvey M. Wagner]] and [[Thomson M. Whitin]], \"Dynamic version of the economic lot size model,\" Management Science, Vol. 5, pp.&nbsp;89–96, 1958</ref><ref>[[Albert Wagelmans|Wagelmans, Albert]], [[Stan Van Hoesel]], and [[Antoon Kolen]]. \"[http://repub.eur.nl/res/pub/2310/eur_wagelmans_22.pdf Economic lot sizing: an O (n log n) algorithm that runs in linear time in the Wagner-Whitin case].\" Operations Research 40.1-Supplement - 1 (1992): S145-S156.</ref>\n\n==Problem setup==\nWe have available a [[Demand forecasting|forecast of product demand]] \n{{math|<VAR >d</VAR ><SUB ><VAR >t</VAR ></sub>}} over a relevant time horizon t=1,2,...,N (for example we might know how many [[Widget (economics)|widget]]s will be needed each week for the next 52 weeks).  There is a [[setup cost]] {{math|<VAR >s</VAR ><SUB ><VAR >t</VAR ></sub>}} incurred for each order and there is an inventory [[holding cost]] {{math|<VAR >i</VAR ><SUB><VAR >t</VAR ></sub>}} per item per period ({{math|<VAR >s</VAR ><SUB><VAR >t</VAR ></sub>}} and {{math|<VAR >i</VAR ><SUB><VAR >t</VAR ></sub>}} can also vary with time if desired). The problem is how many units {{math|<VAR >x</VAR ><SUB><VAR >t</VAR ></sub>}} to order now to minimize the sum of setup cost and inventory cost. Let me denote [[inventory]]:\n\n<math>I=I_{0}+\\sum_{j=1}^{t-1}x_{j}-\\sum_{j=1}^{t-1}d_{j}\\geq0</math>\n\nThe functional equation representing minimal cost policy is:\n\n<math>f_{t}(I)=\\underset{x_{t}\\geq 0 \\atop I+x_{t}\\geq d_{t}}{min}\\left[ i_{t-1}I+H(x_{t})s_{t}+f_{t+1}\\left( I+x_{t}-d_{t} \\right) \\right]</math>\n\nWhere H() is the [[Heaviside step function]]. Wagner and Whitin<ref name=\"WW1958\"/> proved the following four theorems:\n\n* There exists an optimal program such that I{{math|<VAR >x</VAR ><SUB><VAR >t</VAR ></sub>}}=0; ∀t \n* There exists an optimal program such that ∀t: either {{math|<VAR >x</VAR ><SUB><VAR >t</VAR ></sub>}}=0 or <math>x_{t}=\\textstyle \\sum_{j=t}^{k} d_{j}</math> for some k (t≤k≤N)\n* There exists an optimal program such that if {{math|<VAR >d</VAR ><SUB ><VAR >t*</VAR ></sub>}} is satisfied by some {{math|<VAR >x</VAR ><SUB ><VAR >t**</VAR ></sub>}}, t**<t*, then {{math|<VAR >d</VAR ><SUB><VAR >t</VAR ></sub>}}, t=t**+1,...,t*-1, is also satisfied by {{math|<VAR >x</VAR ><SUB ><VAR >t**</VAR ></sub>}}\n*  Given that I = 0 for period t, it is optimal to consider periods 1 through t - 1 by themselves\n\n==Planning Horizon Theorem==\n\nThe precedent theorems are used in the proof of the Planning Horizon Theorem.<ref name=\"WW1958\"/> Let\n\n<math>F(t)= min\\left[ {\\underset{1\\leq j < t}{min}\\left[ s_{j}+ \\sum_{h=j}^{t-1}\\sum_{k=h+1}^{t}i_{h}d_{k}+F(j-1) \\right] \\atop s_{t}+F(t-1)} \\right]</math>\n\ndenote the minimal cost program for periods 1 to t. If at period t* the minimum in F(t) occurs for j = t** ≤ t*, then in periods t > t* it is sufficient to consider only t** ≤ j ≤ t. In particular, if t* = t**, then it is sufficient to consider programs such that {{math|<VAR >x</VAR ><SUB ><VAR >t*</VAR ></sub>}} > 0.\n\n==The algorithm==\n\nWagner and Whitin gave an [[algorithm]] for finding the optimal solution by [[dynamic programming]].<ref name=\"WW1958\"/> Start with t*=1:\n\n#  Consider the policies of ordering at period t**, t** = 1, 2, ... , t*, and filling demands {{math|<VAR >d</VAR ><SUB ><VAR >t</VAR ></sub>}} , t = t**, t** + 1, ... , t*, by this order\n# Add H({{math|<VAR >x</VAR ><SUB><VAR >t**</VAR ></sub>}}){{math|<VAR >s</VAR ><SUB><VAR >t**</VAR ></sub>}}+{{math|<VAR >i</VAR ><SUB><VAR >t**</VAR ></sub>}}{{math|<VAR >I</VAR ><SUB><VAR >t**</VAR ></sub>}} to the costs of acting optimally for periods 1 to t**-1 determined in the previous iteration of the algorithm\n# From these t* alternatives, select the minimum cost policy for periods 1 through t*\n# Proceed to period t*+1 (or stop if t*=N)\n\nBecause this method was perceived by some as [[Computational complexity theory|too complex]], a number of authors also developed approximate [[heuristics]] (e.g., the [[Silver-Meal heuristic]]<ref>EA Silver, HC Meal, A heuristic for selecting lot size quantities for the case of a deterministic time-varying demand rate and discrete opportunities for replenishment, Production and inventory management, 1973</ref>) for the problem. \n\n== See also ==\n\n* Infinite fill rate for the part being produced: [[Economic order quantity]]\n* Constant fill rate for the part being produced: [[Economic production quantity]]\n* Demand is random: classical [[Newsvendor model]]\n* Several products produced on the same machine: [[Economic lot scheduling problem]]\n* [[Reorder point]]\n\n==References==\n{{reflist}}\n\n== Further reading ==\n* Lee, Chung-Yee, Sila Çetinkaya, and [[Albert PM Wagelmans]]. \"[http://repub.eur.nl/res/pub/7707/1999-0954.pdf A dynamic lot-sizing model with demand time windows].\" ''[[Management Science (journal)|Management Science]]'' 47.10 (2001): 1384-1395.\n* Federgruen, Awi, and Michal Tzur. \"A simple forward algorithm to solve general dynamic lot sizing models with n periods in 0 (n log n) or 0 (n) time.\" ''[[Management Science (journal)|Management Science]]'' 37.8 (1991): 909-925.\n* Jans, Raf, and Zeger Degraeve. \"Meta-heuristics for dynamic lot sizing: a review and comparison of solution approaches.\" ''European Journal of Operational Research'' 177.3 (2007): 1855-1875.\n* [[H.M. Wagner]] and T. Whitin, \"Dynamic version of the economic lot size model,\" ''[[Management Science (journal)|Management Science]]'', Vol. 5, pp.&nbsp;89–96, 1958\n* [[H.M. Wagner]]: \"Comments on Dynamic version of the economic lot size model\", ''[[Management Science (journal)|Management Science]]'', Vol. 50 No. 12 Suppl., December 2004\n\n==External links==\n* [http://openresearch.wordpress.com/2009/09/03/solving-the-lot-sizing-problem-in-resolver-one-wagner-whitin-algorithm/ Solving the Lot Sizing Problem using the Wagner-Whitin Algorithm] \n* [http://eureka-operationresearch.blogspot.com/2011/09/dynamic-lot-size-model.html Dynamic lot size model]\n\n[[Category:Inventory optimization]]"
    },
    {
      "title": "Economic lot scheduling problem",
      "url": "https://en.wikipedia.org/wiki/Economic_lot_scheduling_problem",
      "text": "{{Use dmy dates|date=August 2012}}\nThe '''economic lot scheduling problem''' ('''ELSP''') is a problem in [[operations management]] and [[inventory theory]] that has been studied by a large number of researchers for more than 50 years. The term was first used in 1958 by professor [[Jack D. Rogers]] of Berkeley,<ref>[[Jack D. Rogers]]: A Computational Approach to the Economic Lot Scheduling Problem, Management Science, Vol. 4, No. 3, April 1958, pp. 264–291</ref> who extended the [[economic order quantity]] model to the case where there are several products to be produced on the same [[machine]], so that one must decide both the lot size for each product and when each lot should be produced. The method illustrated by Jack D. Rogers draws on a 1956 paper from Welch, W. Evert.<ref>Welch, W. Evert, A Case of Simple Linear Programming, Management Methods 1956 in [[Jack D. Rogers]]: A Computational Approach to the Economic Lot Scheduling Problem, Management Science, Vol. 4, No. 3, April 1958, pp. 264–291</ref> The ELSP is a mathematical model of a common issue for almost any company or industry: planning what to manufacture, when to manufacture and how much to manufacture.\n\n==Model formulation==\nThe classic ELSP is concerned with scheduling the production of several products on a single machine in order to minimize the total costs incurred (which include setup costs and inventory holding costs).\n\nWe assume a known, non-varying demand <math>d_j, j=1,\\cdots,m</math> for the m products (for example, there might be m=3 products and customers require 7 items a day of Product 1, 5 items a day of Product 2 and 2 items a day of Product 3). Customer [[demand]] is met from inventory and the inventory is replenished by our production facility.\n\nA single machine is available which can make all the products, but not in a perfectly interchangeable way.  Instead the machine needs to be [[Changeover#Set-up|set up]] to produce one product, incurring a setup cost and/or setup time, after which it will produce this product at a known rate <math>P_j</math>.  When it is desired to produce a different product, the machine is stopped and another costly setup is required to begin producing the next product. Let <math>S_{ij}</math> be the setup cost when switching from product i to product j and inventory cost <math>h_j</math> is charged based on average inventory level of each item. N is the number of runs made, U the use rate, L the lot size and T the planning period.\n\nTo give a very concrete example, the machine might be a [[bottling machine]] and the products could be cases of bottled [[apple juice]], [[orange juice]] and [[milk]].  The setup corresponds to the process of stopping the machine, cleaning it out and loading the tank of the machine with the desired fluid.  This product switching must not be done too often or the setup costs will be large, but equally too long a production run of apple juice would be undesirable because it would lead to a large inventory investment and carrying cost for unsold cases of apple juice and perhaps stock-outs in orange juice and milk.  The ELSP seeks the optimal trade off between these two extremes.\n\n==Rogers algorithm==\n\n1.Define:\n:<math>\\theta= T/N = L/U</math> = use period\n:c<sub>L</sub>=<math>\\frac{hL(P-U)}{2PU}+\\frac{S}{L}</math>, the unit cost for a lot of size L\n:<math>C_{N}=NLc_{L}=UT\\left[ \\frac{hL\\left( P-U \\right)}{2PU}+\\frac{S}{L} \\right]</math> the total cost for N lots. To obtain the [[optimum]] we impose:\n:<math>\\frac{d(C_{N})}{dL}=\\frac{hT\\left( P-U \\right)}{2P}-\\frac{SUT}{L^{2}}=0</math>\n:Which yields <math>L_{0}=\\sqrt{\\frac{2USP}{h(P-U)}}</math> as the optimum lot size. Now let:\n:<math>C_{N_{L\\pm a}}=UT\\left[ \\frac{h\\left( L\\pm a \\right)\\left( P-U \\right)}{2PU}+\\frac{S}{L\\pm a} \\right]</math> be the total cost for N<sub>L±a</sub>lots of size L±a\n:<math>+\\Delta=C_{N_{L+a}}-C_{N}=UT\\left[ \\frac{ha\\left( P-U \\right)}{2PU} - \\frac{S}{\\frac{L^{2}}{a}+L}\\right]</math> be the incremental cost of changing from size L to L+a\n:<math>-\\Delta=C_{N_{L-a}}-C_{N}=UT\\left[ -\\frac{ha\\left( P-U \\right)}{2PU} + \\frac{S}{\\frac{L^{2}}{a}-L} \\right]</math> be the incremental cost of changing from size L to L-a\n\n2.\n:Total quantity of an item required = UT\n:Total production time for an item = UT/P\n:Check that [[productive capacity]] is satisfied:\n:<math>\\sum_{i=1}^{m}\\frac{U_{i}T}{P_{i}}\\leq T</math>\n:<math>\\sum_{i=1}^{m}\\frac{U_{i}}{P_{i}}\\leq 1</math>\n\n3.Compute:\n:<math>\\theta_{0}=\\frac{L_{0}}{U}</math> as a whole number\n:If for a certain item, θ<sub>0</sub> is not an even number, calculate:\n:<math>L=U\\left( \\theta_{0}+1 \\right)</math>\n:<math>L=U\\left( \\theta_{0}-1 \\right)</math>\n:And change L<sub>0</sub> to L in the direction which incurs the least cost increase between +Δ and -Δ\n\n4.Compute t<sub>p</sub>=L/P for each item and list items in order of increasing θ=L/U\n\n5.For each pair of items ij check:\n:<math>\\theta_{i}-t_{p_{i}}\\geq t_{p_{j}}</math>\n:<math>\\theta_{j}-t_{p_{j}}\\geq t_{p_{i}}</math>\n:To forms pairs take the i<sup>th</sup> with the i+1th, i+2th, etc. If any of these inequalities is violated, calculate +Δ and -Δ for lot size increments of 2U and in order of size of cost change make step-by-step lot size changes. Repeat this step until both inequalities are satisfied.\n\n6.<math>e_{ij}=d-t_{p_{i}}\\leq\\theta_{i}-t_{p_{i}}-t_{p_{j}}</math>\n:# Form all possible pairs as in Step 5\n:# For each pair, select θ<sub>i</sub> < θ<sub>j</sub>\n:# Determine whether t<sub>p<sub>i</sub></sub> > t<sub>p<sub>j</sub></sub>, t<sub>p<sub>i</sub></sub> < t<sub>p<sub>j</sub></sub> or t<sub>p<sub>i</sub></sub> = t<sub>p<sub>j</sub></sub>\n:# Select a value for e<sub>ij</sub>(e<sub>ij</sub>=0,1,2,3,...,θ<sub>i</sub> - t<sub>p<sub>i</sub></sub> - t<sub>p<sub>j</sub></sub>) and calculate t<sub>pi</sub>+e and t<sub>pj</sub>+e \n:# Calculate M<sub>i</sub>θ<sub>i</sub>-M<sub>j</sub>θ<sub>j</sub> by setting M<sub>i</sub>=k and M<sub>j</sub>=1,2,3,...,T/θ<sub>j</sub>; ∀k∈(1,2,...,T/θ<sub>i</sub>). Then check if one of the following boundary conditions is satisfied: \n:::for <math>t_{p_{i}} > t_{p_{j}}</math> or <math>t_{p_{i}} < t_{p_{j}}</math><math>\\begin{cases} t_{p_{i}}+e \\geq M_{i}\\theta_{i} - M_{j}\\theta_{j} > e \\\\ t_{p_{i}}+e > M_{i}\\theta_{i} - M_{j}\\theta_{j} \\geq t_{p_{i}}+e \\\\  t_{p_{j}}+e \\geq M_{i}\\theta_{i} - M_{j}\\theta_{j} > t_{p_{i}}+e \\\\ t_{p_{i}}+t_{p_{j}}+e > M_{i}\\theta_{i} - M_{j}\\theta_{j} \\geq t_{p_{j}}+e \\end{cases}</math> \n:::for <math>t_{p_{i}} = t_{p_{j}}</math> <math>\\begin{cases} t_{p_{i}}+e > M_{i}\\theta_{i} - M_{j}\\theta_{j} > e \\\\ t_{p_{i}}+t_{p_{j}}+e > M_{i}\\theta_{i} - M_{j}\\theta_{j} > t_{p_{j}}+e \\\\ t_{p_{i}}+e= M_{i}\\theta_{i} - M_{j}\\theta_{j}=t_{p_{j}}+e \\end{cases}</math> \n:::If none of the boundary conditions is satisfied then e<sub>ij</sub> is non-interfering: if i=1 in e<sub>ij</sub>, pick the next larger e in sub-step 4, if i≠1 go back to sub-step 2. If some boundary condition is satisfied go to sub-step 4. If, for any pair, no non-interfering e appears, go back to Step 5.\n\n7.Enter items in schedule and check it's feasibility\n\n==Stochastic ELSP==\nOf great importance in practice is to design, plan and operate shared capacity across multiple products with changeover times and costs in an uncertain demand environment. Beyond the selection of  (expected) cycle times, with some amount of slack designed in (\"safety time\"), one has to also consider the amount of safety stock (buffer stock) that is needed to meet desired service level.<ref>{{Cite journal | last1 = Tayur | first1 = S. | title = Improving Operations and Quoting Accurate Lead Times in a Laminate Plant | doi = 10.1287/inte.30.5.1.11637 | journal = Interfaces | volume = 30 | issue = 5 | pages = 1–15| year = 2000 | pmid =  | pmc = }}</ref>\n\n==Problem status==\nThe problem is well known in the operations research community, and a large body of academic research work has been created to improve the model and to create new variations that solve specific issues.\n\nThe model is known as a [[NP-hard]] problem since it is not currently possible to find the optimal solution without checking nearly every possibility. What has been done follows two approaches: restricting the solution to be of a specific type (which makes it possible to find the optimal solution for the narrower problem), or approximate solution of the full problem using [[heuristics]] or [[genetic algorithms]].<ref>Zipkin Paul H., Foundations of Inventory Management, Boston: McGraw Hill, 2000, {{ISBN|0-256-11379-3}}</ref>\n\n==See also==\n\n* Infinite fill rate for the part being produced: [[Economic order quantity]]\n* Constant fill rate for the part being produced: [[Economic production quantity]]\n* Demand is random: classical [[Newsvendor model]]\n* Demand varies over time: [[Dynamic lot size model]]\n\n==References==\n{{reflist}}\n\n== Further reading ==\n* S E Elmaghraby: The Economic Lot Scheduling Problem (ELSP): Review and Extensions, Management Science, Vol. 24, No. 6, February 1978, pp.&nbsp;587–598\n* M A Lopez, B G Kingsman: The Economic Lot Scheduling Problem: Theory and Practice, International Journal of Production Economics, Vol. 23, October 1991, pp.&nbsp;147–164\n* Michael Pinedo, Planning and Scheduling in Manufacturing and Services, Springer, 2005. {{ISBN|0-387-22198-0}}\n\n==External links==\n* [http://www.columbia.edu/~gmg2/4000/pdf/lect_03.pdf Gallego: The ELSP, Columbia U.,2004]\n\n[[Category:Inventory optimization]]"
    },
    {
      "title": "Economic order quantity",
      "url": "https://en.wikipedia.org/wiki/Economic_order_quantity",
      "text": "In [[inventory management]], '''economic order quantity''' ('''EOQ''') is the order quantity that minimizes the total [[holding cost]]s and [[ordering cost]]s. It is one of the oldest classical [[Scheduling (production processes)|production scheduling]] models. The model was developed by [[Ford W. Harris]] in 1913, but R. H. Wilson, a consultant who applied it extensively, and K. Andler are given credit for their in-depth analysis.<ref name=\"Hax1984\">{{Citation\n | title = Production and Operations Management\n | url = http://catalogue.nla.gov.au/Record/772207\n | year = 1984\n |author1=Hax, AC  |author2=Candea, D.\n | publisher = Prentice-Hall |location=Englewood Cliffs, NJ\n | page = 135\n| isbn = 9780137248803\n }}</ref>\n\n==Overview==\nEOQ applies only when [[demand]] for a product is constant over the year and each new order is delivered in full when inventory reaches zero. There is a fixed cost for each order placed, regardless of the number of units ordered. There is also a cost for each unit held in storage, commonly known as [[holding cost]], sometimes expressed as a percentage of the purchase cost of the item.\n\nWe want to determine the optimal number of units to order so that we minimize the total cost associated with the purchase, delivery and storage of the product.\n\nThe required parameters to the solution are the total demand for the year, the purchase cost for each item, the fixed cost to place the order and the storage cost for each item per year. Note that the number of times an order is placed will also affect the total cost, though this number can be determined from the other parameters.\n\n===Variables===\n*<math>TC</math> = total annual inventory cost\n*<math>P</math> = purchase unit price, unit production cost\n*<math>Q</math> = order quantity.\n*<math>Q^*</math> = optimal order quantity.\n*<math>D</math> = annual demand quantity.\n*<math>K</math> = fixed cost per order, setup cost (''not'' per unit, typically cost of ordering and shipping and handling. This is not the cost of goods)\n*<math>h</math> = annual holding cost per unit, also known as carrying cost or storage cost (capital cost, warehouse space, refrigeration, insurance, etc. usually not related to the unit production cost)\n\n===The total cost function and derivation of EOQ formula===\n\nThe single-item EOQ formula finds the minimum point of the following cost function:\n\nTotal Cost = purchase cost or production cost + ordering cost + holding cost\n\nWhere:\n\n* Purchase cost: This is the variable cost of goods: purchase unit price &times; annual demand quantity. This is P &times; D\n* Ordering cost: This is the cost of placing orders: each order has a fixed cost K, and we need to order D/Q times per year. This is K &times; D/Q\n* Holding cost: the average quantity in stock (between fully replenished and empty) is Q/2, so this cost is h &times; Q/2\n\n<math>TC = PD + {\\frac{DK}{Q}} + {\\frac{hQ}{2}}</math>.\n\nTo determine the minimum point of the total cost curve, calculate the derivative of the total cost with respect to Q (assume all other variables are constant) and set it equal to 0:\n\n<math>{0} = -{\\frac{DK}{Q^2}}+{\\frac{h}{2}}</math>\n\nSolving for Q gives Q* (the optimal order quantity):\n\n<math>Q^{*2}={\\frac{2DK}{h}}</math>\n\nTherefore:\n\n{{Equation box 1\n|indent =:\n|title='''Economic Order Quantity'''\n|equation = <math>Q^* = \\sqrt{\\frac{2DK}{h}} </math>\n|cellpadding\n|border\n|border colour = #50C878\n|background colour = #ECFCF4}}\n\nQ* is independent of P; it is a function of only K, D, h.\n\nThe optimal value Q* may also be found by recognising that<ref>{{cite journal |doi=10.1016/0925-5273(95)00109-3 |title=Modelling production opportunities — an historical overview |journal=International Journal of Production Economics |volume=41 |issue=1–3 |pages=1–14 |year=1995 |last1=Grubbström |first1=Robert W. }}</ref>\n\n<math>TC = {\\frac{DK}{Q}} + {\\frac{hQ}{2}} + PD ={\\frac{h}{2Q}}(Q - \\sqrt{2DK/h})^2 +  \\sqrt{2hDK} +PD,  </math>\nwhere the non-negative quadratic term disappears for <math>Q = \\sqrt{2DK/h}, </math> which provides the cost minimum <math>TC_{min} =  \\sqrt{2hDK} + PD.  </math>\n\n=== Example ===\n\n*annual requirement quantity (D) = 10000 units\n*Cost per order (K) = 40\n*Cost per unit (P)= 50\n*Yearly carrying cost per unit (h) = 5\n\nEconomic order quantity = <math> \\sqrt{\\frac{2D*K}{h}} </math> <math> = \\sqrt{\\frac{2*10000*40}{5}} </math> = 400 units\n\nNumber of orders per year (based on EOQ) <math> = {\\frac{10000}{400}} = 25 </math>\n\nTotal cost <math> = P*D + K (D/EOQ) + h (EOQ/2) </math>\n\nTotal cost <math> = 50*10000 + 40*(10000/400) + 5*(400/2) = 502000 </math>\n\nIf we check the total cost for any order quantity other than 400(=EOQ), we will see that the cost is higher.  For instance, supposing 500 units per order, then\n\nTotal cost <math> = 50*10000 + 40*(10000/500) + 5*(500/2) = 502050 </math>\n\nSimilarly, if we choose 300 for the order quantity then\n\nTotal cost <math> = 50*10000 + 40*(10000/300) + 5*(300/2) = 502083.33 </math>\n\nThis illustrates that the economic order quantity is always in the best interests of the firm.\n\n==Extensions of the EOQ model==\n\n===Quantity discounts===\nAn important extension to the EOQ model is to accommodate quantity discounts. There are two main types of quantity discounts: (1) all-units and (2) incremental.<ref>{{Cite book | title = Production and operations analysis | last1 = Nahmias | first1 = Steven | year = 2005 | publisher = McGraw Hill Higher Education }}{{page needed|date=January 2017}}</ref><ref>Zipkin, Paul H, Foundations of Inventory Management, McGraw Hill 2000{{page needed|date=January 2017}}</ref> Here is a numerical example:\n\t\n* Incremental unit discount: Units 1–100 cost $30 each; Units 101–199 cost $28 each; Units 200 and up cost $26 each. So when 150 units are ordered, the total cost is $30*100 + $28*50.\n* All units discount: an order of 1–1000 units costs $50 each; an order of 1001–5000 units costs $45 each; an order of more than 5000 units costs $40 each. So when 1500 units are ordered, the total cost is $45*1500.\n\nIn order to find the optimal order quantity under different quantity discount schemes, one should use algorithms; these algorithms are developed under the assumption that the EOQ policy is still optimal with quantity discounts. Perera et al. (2017)<ref>{{cite journal |doi=10.1016/j.ijpe.2016.09.017 |title=Optimality of (s,S) policies in EOQ models with general cost structures |journal=International Journal of Production Economics |volume=187 |pages=216–228 |year=2017 |last1=Perera |first1=Sandun |last2=Janakiraman |first2=Ganesh |last3=Niu |first3=Shun-Chen }}</ref> establish this optimality and fully characterize the (s,S) optimality within the EOQ setting under general cost structures.\n\n===Design of optimal quantity discount schedules===\nIn presence of a strategic customer, who responds optimally to discount schedule,  the design of optimal quantity discount scheme by the supplier is complex and has to be done carefully.  This is particularly so when the demand at the customer is itself uncertain. An interesting effect called the \"reverse bullwhip\" takes place where an increase in consumer demand uncertainty actually reduces order quantity uncertainty at the supplier.<ref>{{cite journal |doi=10.1287/mnsc.1070.0829 |jstor=20122426 |title=Quantity Discounts Under Demand Uncertainty |journal=Management Science |volume=54 |issue=4 |pages=777–92 |year=2008 |last1=Altintas |first1=Nihat |last2=Erhun |first2=Feryal |last3=Tayur |first3=Sridhar }}</ref>\n\n===Backordering costs and multiple items===\nSeveral extensions can be made to the EOQ model, including backordering costs<ref>{{cite journal |doi=10.1016/j.ijpe.2016.09.017 |title=Optimality of (s,S) policies in EOQ models with general cost structures |journal=International Journal of Production Economics |volume=187 |pages=216–228 |year=2017 |last1=Perera |first1=Sandun |last2=Janakiraman |first2=Ganesh |last3=Niu |first3=Shun-Chen }}</ref> and multiple items.  Additionally, the [[economic order interval]]<ref>Engineering Costs and Production Economics\n[https://www.sciencedirect.com/journal/engineering-costs-and-production-economics/vol/11/issue/1 Volume 11, Issue 1], S.K. Goyal (April 1987), Pages 53-57.</ref> can be determined from the EOQ and the [[economic production quantity]] model (which determines the optimal production quantity) can be determined in a similar fashion.\n\nA version of the model, the [[Baumol-Tobin]] model, has also been used to determine the [[Money demand#Inventory models|money demand]] function, where a person's holdings of money balances can be seen in a way parallel to a firm's holdings of inventory.<ref name=jep>{{cite journal |doi=10.1257/jep.24.1.183 |first1=Andrew |last1=Caplin |first2=John |last2=Leahy |year=2010 |title=Economic Theory and the World of Practice: A Celebration of the (S, s) Model |journal=The Journal of Economic Perspectives |volume=24 |issue=1 |pages=183–201 |jstor=25703488 |citeseerx=10.1.1.730.8784 }}</ref>\n\n[[Behnam Malakooti|Malakooti]] (2013)<ref>{{cite book|last1=Malakooti|first1=B|title=Operations and Production Systems with Multiple Objectives|date=2013|publisher=John Wiley & Sons|isbn=978-1-118-58537-5}}{{page needed|date=January 2017}}</ref> has introduced the multi-criteria EOQ models where the criteria could be minimizing the total cost, Order quantity (inventory), and Shortages.\n\nA version taking the time-value of money into account was developed by Trippi and Lewin.<ref name=\"tri\">{{cite journal |doi=10.1111/j.1540-5915.1974.tb00592.x |title=A Present Value Formulation of the Classical Eoq Problem |journal=Decision Sciences |volume=5 |issue=1 |pages=30–35 |year=1974 |last1=Trippi |first1=Robert R. |last2=Lewin |first2=Donald E. }}</ref>\n\n=== Imperfect quality ===\nAnother important extension of EOQ model is to consider items with imperfect quality. Salameh and Jaber (2000) are the first to study the imperfect items in an EOQ model very thoroughly. They consider an inventory problem in which\n\nthe demand is deterministic and there is a fraction of imperfect items in the lot and are screened by the buyer and sold by them at the end of the circle at discount price.<ref>{{Cite journal|last=Salameh|first=M.K.|last2=Jaber|first2=M.Y.|date=March 2000|title=Economic production quantity model for items with imperfect quality|journal=International Journal of Production Economics|volume=64|issue=1–3|pages=59–64|doi=10.1016/s0925-5273(99)00044-4|issn=0925-5273}}</ref> Imperfect quality items have also been considered in a decentralized supply chain and the problem has also been studied with game theoretical models.<ref>{{Cite journal|last=Elyasi|first=Milad|last2=Khoshalhan|first2=Farid|last3=Khanmirzaee|first3=Mohammad|date=2014|title=Modified economic order quantity (EOQ) model for items with imperfect quality: Game-theoretical approaches|journal=International Journal of Industrial Engineering Computations|volume=5|issue=2|pages=211–222|doi=10.5267/j.ijiec.2014.1.003|issn=1923-2926}}</ref>\n\n== For improving fuel economy of internal combustion engines==\nRecently an interesting similarity between EOQ  of Melon picking and  fuel injection in Gasoline Direction Injection has been proposed.<ref>{{cite journal |doi=10.1016/j.applthermaleng.2016.02.024 |title=Optimization of fuel injection in GDI engine using economic order quantity and Lambert W function |journal=Applied Thermal Engineering |volume=101 |pages=112–20 |year=2016 |last1=Ventura |first1=Robert |last2=Samuel |first2=Stephen }}</ref>\n\n==See also==\n\n* Constant fill rate for the part being produced: [[Economic production quantity]]\n* Demand is random: classical [[Newsvendor model]]\n* Demand varies over time: [[Dynamic lot size model]]\n* Several products produced on the same machine: [[Economic lot scheduling problem]]\n* [[Reorder point]]\n* Revised Wilson Formula by Daniel CRETOIS [https://www.linkedin.com/pulse/revised-wilson-formula-daniel-cretois]\n* Renewal Demand and (s,S) Optimality by Perera, Janakiraman and Niu [https://onlinelibrary.wiley.com/doi/full/10.1111/poms.12795]\n\n==References==\n<references/>\n\n==Further reading==\n* Harris, Ford W. ''Operations Cost'' (Factory Management Series), Chicago:  Shaw (1915)\n*{{cite journal |last1=Harris |first1=Ford W. |title=How many parts to make at once |journal=Factory, the Magazine of Management |volume=10 |pages=135–136, 152 |year=1913 }}\n* Camp, W. E. \"Determining the production order quantity\", Management Engineering, 1922\n*{{cite journal |last1=Wilson |first1=R. H. |title=A Scientific Routine for Stock Control |journal=Harvard Business Review |volume=13 |pages=116–28 |year=1934 }}\n* Plossel, George. Orlicky's Material Requirement's Planning. Second Edition. McGraw Hill. 1984. (first edition 1975)\n*{{cite journal |doi=10.1016/j.ijpe.2014.01.013 |title=A century of evolution from Harris׳s basic lot size model: Survey and research agenda |journal=International Journal of Production Economics |volume=155 |pages=16–38 |year=2014 |last1=Andriolo |first1=Alessandro |last2=Battini |first2=Daria |last3=Grubbström |first3=Robert W. |last4=Persona |first4=Alessandro |last5=Sgarbossa |first5=Fabio |url=http://liu.diva-portal.org/smash/get/diva2:755589/FULLTEXT01 }}\n*{{cite journal |doi=10.1016/j.ijpe.2013.12.008 |title=Ford Whitman Harris's economical lot size model |journal=International Journal of Production Economics |volume=155 |pages=12–15 |year=2014 |last1=Erlenkotter |first1=Donald }}\n*{{cite journal |doi=10.1016/j.ijpe.2016.09.017 |title=Optimality of (s,S) policies in EOQ models with general cost structures |journal=International Journal of Production Economics |volume=187 |pages=216–228 |year=2017 |last1=Perera |first1=Sandun |last2=Janakiraman |first2=Ganesh |last3=Niu |first3=Shun-Chen }}\n*{{cite journal |doi=10.1111/poms.12795 |title=Optimality of (s, S) Inventory Policies under Renewal Demand and General Cost Structures |journal=Production and Operations Management |volume=27 |issue=2 |pages=368–383 |year=2018 |last1=Perera |first1=Sandun |last2=Janakiraman |first2=Ganesh |last3=Niu |first3=Shun-Chen }}     \n* Tsan-Ming Choi (Ed.)  Handbook of EOQ Inventory Problems: Stochastic and Deterministic Models and Applications, Springer's International Series in Operations Research and Management Science, 2014. {{doi|10.1007/978-1-4614-7639-9}}.\n* {{cite journal |doi=10.1016/j.applthermaleng.2016.02.024 |title=Optimization of fuel injection in GDI engine using economic order quantity and Lambert W function |journal=Applied Thermal Engineering |volume=101 |pages=112–20 |year=2016 |last1=Ventura |first1=Robert |last2=Samuel |first2=Stephen }}\n\n==External links==\n*[http://www.logisitik.com/learning-center/inventory-management/item/466-economic-order-quantity-eoq-model.html The EOQ Model]\n* http://www.inventoryops.com/economic_order_quantity.htm\n*http://www.scmfocus.com/supplyplanning/2014/04/10/economic-order-quantity-calculator/\n\n{{DEFAULTSORT:Economic Order Quantity}}\n[[Category:Inventory optimization]]\n\n[[de:Klassische Losformel]]"
    },
    {
      "title": "Economic production quantity",
      "url": "https://en.wikipedia.org/wiki/Economic_production_quantity",
      "text": "The '''economic production quantity''' model (also known as the '''EPQ model''') determines the quantity a company or retailer should order to minimize the total inventory costs by balancing the inventory [[holding cost]] and average fixed ordering cost. The EPQ model was developed by E.W. Taft in 1918. \nThis method is an extension of the [[economic order quantity]] model (also known as the EOQ model). The difference between these two methods is that the EPQ model assumes the company will produce its own quantity or the parts are going to be shipped to the company while they are being produced, therefore the orders are available or received in an incremental manner while the products are being produced. While the EOQ model assumes the order quantity arrives complete and immediately after ordering, meaning that the parts are produced by another company and are ready to be shipped when the order is placed. \n \nIn some literature, \"economic manufacturing quantity\" model (EMQ) is used for \"economic production quantity\" model (EPQ). Similar to the EOQ model, EPQ is a single product lot scheduling method. A multiproduct extension to these models is called ''product cycling problem''.\n\n==Overview==\nEPQ only applies where the demand for a product is constant over the year and that each new order is delivered/produced incrementally when the inventory reaches zero. There is a fixed cost charged for each order placed, regardless of the number of units ordered. There is also a holding or storage cost for each unit held in storage (sometimes expressed as a percentage of the purchase cost of the item).\n\nWe want to determine the optimal number of units of the product to order so that we minimize the total cost associated with the purchase, delivery and storage of the product\n\nThe required parameters to the solution are the total demand for the year, the purchase cost for each item, the fixed cost to place the order and the storage cost for each item per year. Note that the number of times an order is placed will also affect the total cost, however, this number can be determined from the other parameters\n\n=== Assumptions ===\n# Demand for items from inventory is continuous and at a constant rate\n# Production runs to replenish inventory are made at regular intervals\n# During a production run, the production of items is continuous and at a constant rate\n# Production set-up/ordering cost is fixed (independent of quantity produced)\n# The [[lead time]] is fixed\n# The purchase price of the item is constant, i.e. no discount is available\n# The replenishmeneet is made incrementally\n\n=== Variables ===\n* K = ordering/setup cost per production run\n* D = yearly demand rate\n* h = yearly holding cost per product\n* T = cycle length\n* P = yearly production rate\n* <math> x = \\frac {D}{P} </math>\n* Q = order quantity\n\n=== Total cost function and derivation of EPQ formula ===\n\n[[File:EPQ Graph.jpg|thumb|400px|right|This figure graphs the holding cost and ordering cost per year equations. The third line is the addition of these two equations, which generates the total inventory cost per year. This graph should give a better understanding of the derivation of the optimal ordering quantity equation, i.e., the EPQ equation]]\n\n* Holding Cost per Year  =  <math>\\frac{Q} {2} h(1-x)</math>\n\nWhere <math>\\frac{Q} {2}</math> is the average inventory level, and <math>h(1-x)</math> is the average holding cost. Therefore, multiplying these two results in the holding cost per year.\n\n* Ordering Cost per Year  =   <math>\\frac{D} {Q} K</math>\n\nWhere <math>\\frac{D} {Q} </math> are the orders placed in a year, multiplied by K results in the ordering cost per year.\n\nWe can notice from the equations above that the total ordering cost decreases as the production quantity increases. Inversely, the total holding cost increases as the production quantity increases. Therefore, in order to get the optimal production quantity we need to set holding cost per year equal to ordering cost per year and solve for quantity (Q), which is the EPQ formula mentioned below. Ordering this quantity will result in the lowest total inventory cost per year.\n\n{{Equation box 1\n|indent =:\n|title='''EPQ formula'''\n|equation = <math> Q = \\sqrt {\\frac {2KD}{h(1-x)}} </math>\n|cellpadding\n|border\n|border colour = #50C878\n|background colour = #ECFCF4}}\n\n=== Relevant formulas ===\n\n*Average holding cost per unit time:\n \n:<math>\\frac{1} {2} hD(1-x)t</math>\n\n*Average ordering and holding cost as a function of time:\n\n:<math>x(t) = \\frac {1} {2} hD(1-x)t+ \\frac {K} {t} </math>\n\n== See also ==\n\n* Infinite fill rate for the part being produced: [[Economic order quantity]]\n* Demand is random: classical [[Newsvendor model]]\n* Demand varies over time: [[Dynamic lot size model]]\n* Several products produced on the same machine: [[Economic lot scheduling problem]]\n* [[Reorder point]]\n\n== References ==\n* Taft, E. W. \"The most economical production lot.\" Iron Age 101.18 (1918): 1410-1412.\n* Gallego, G. \"IEOR4000: Production Management\" (Lecture 2), Columbia (2004). [http://www.columbia.edu/~gmg2/4000/pdf/lect_02.pdf]\n* Stevenson, W. J. \"Operations Management\" PowerPoint slide 19, The McGraw-Hill Companies (2005). [http://highered.mcgraw-hill.com/sites/0072869054/student_view0/chapter11/powerpoint_presentations.html]\n* Kroeger, D. R. \"Determining Economic Production in a Continuous Process\" IIE Process Industries Webinar, IIE (2009). [http://www.iienet2.org/uploadedFiles/Webcasts/Determining%20Economic%20Production%20Quantities%207-14-09.pdf]\n* Cárdenas-Barrón, L. E. \"The Economic Production Quantity derived Algebraically\" International Journal of Production Economics, Volume 77, Issue 1, (2002). \n* Blumenfeld, D. \"Inventory\" Operations Research Calculations Handbook, Florida (2001)\n*Harris, F.W. \"How Many Parts To Make At Once\" Factory, The Magazine of Management, 10(2), 135-136, 152 (1913).\n\n[[Category:Inventory optimization]]"
    },
    {
      "title": "Extended newsvendor model",
      "url": "https://en.wikipedia.org/wiki/Extended_newsvendor_model",
      "text": "'''Extended newsvendor models''' are variations of the classic [[newsvendor model]] involving production capacity constraints, multiple products, multiple production cycles, demand dependent selling price, etc. that appear in the [[Operations management]] literature.\n\n== Further reading ==\n* E. J. Lodree: [http://www.scs.org/getDoc.cfm?id=2178 A Simulation Optimization Approach for the Two-Product Newsvendor Problem]\n* P. Mileff, K. Nehez: [http://users.iit.uni-miskolc.hu/~mileff/pubs/2006h.pdf An Extended Newsvendor Model for Customized Mass Production], AOM  – Advanced modeling and Optimization. Electronic International Journal, Volume 8, Number 2. pp 169–186. (2006)\n* P. Mileff, K. Nehez: [http://users.iit.uni-miskolc.hu/~mileff/pubs/2007b.pdf Evaluating the Proper Service Level In a Cooperate Supply Chain Environment], MIM'07. IFAC workshop on manufacturing modelling, management and control. Budapest, Hungary. pp 123–126. (2007)\n\n[[Category:Inventory optimization]]\n\n{{tech-stub}}"
    },
    {
      "title": "Inventory",
      "url": "https://en.wikipedia.org/wiki/Inventory",
      "text": "{{Other uses}}\n[[File:Teenage Engineering Pocket Operators - PO-14 sub & stock cartons - 2015 NAMM Show.jpg|thumb|Electronics inventory]]\n'''Inventory''' ([[American English]]) or '''stock''' ([[British English]]) is the goods and materials that a [[business]] holds for the ultimate goal of resale (or repair).{{refn|group=nb|The word ''inventory'' is commonly used in [[American English]] and in business accounting. In the rest of the English-speaking world, ''stock'' is more commonly used, although ''inventory'' is recognised as a synonym.}}\n\n[[Stock management|Inventory management]] is a discipline primarily about specifying the shape and placement of stocked goods. It is required at different locations within a facility or within many locations of a supply network to precede the regular and planned course of production and stock of materials.\n\nThe concept of inventory, stock or work-in-process has been extended from manufacturing systems to service businesses<ref>\"Production and Operations Management: Manufacturing and Services\", R.B. Chase, N.J. Aquiline and F.R. Jacobs, Eighth Edition, 1998, pp 582-583\n</ref><ref>\"Operations and Supply Chain Management: The Core\", Third Edition, F. Robert Jacobs and Richard B. Chase, p 346</ref><ref>Maynard's Industrial Engineering Handbook, Fifth Edition, Kjell B. Landin (ed.), McGraw-Hill 2001, p G.8</ref> and projects,<ref>\"Factory Physics for Managers\", E.S. Pound, J.H. Bell, and M.L. Spearman, McGraw-Hill 2014, p 47</ref><ref>\"New Era of Project Delivery – Project as Production System\", R.G. Shiny and T.R. Zabelle, Journal of Project Production Management, Vol 1, pp Nov 2016, pp 13–24, [https://www.researchgate.net/publications/312602707_&nbsp;New_Era_of_Project_Delivery_-_Project_as_Production_System https://www.researchgate.net/publications/312602707]\n</ref> by generalizing the definition to be \"all work within the process of production- all work that is or has occurred prior to the completion of production.\" In the context of a manufacturing production system, inventory refers to all work that has occurred – raw materials, partially finished products, finished products prior to sale and departure from the manufacturing system. In the context of services, inventory refers to all work done prior to sale, including partially process information.\n\n==Definition==\n\nThe scope of inventory management concerns the balance between replenishment lead time, carrying costs of inventory, asset management, inventory forecasting, inventory valuation, inventory visibility, future inventory price forecasting, physical inventory, available physical space, quality management, replenishment, returns and defective goods, and demand forecasting. Balancing these competing requirements leads to optimal inventory levels, which is an ongoing process as the business needs shift and react to the wider environment.\n\nInventory management involves a retailer seeking to acquire and maintain a proper merchandise assortment while ordering, shipping, handling and related costs are kept in check. It also involves systems and processes that identify inventory requirements, set targets, provide replenishment techniques, report actual and projected inventory status and handle all functions related to the tracking and management of material. This would include the monitoring of material moved into and out of stockroom locations and the reconciling of the inventory balances. It also may include [[ABC analysis]], lot tracking, cycle counting support, etc. Management of the inventories, with the primary objective of determining/controlling stock levels within the physical distribution system, functions to balance the need for product availability against the need for minimizing stock holding and handling costs.\n\n==Business inventory==\n\n=== Reasons for keeping stock===\nThere are five basic reasons for keeping an inventory\n#Time – The time lags present in the supply chain, from supplier to user at every stage, requires that you maintain certain amounts of inventory to use in this [[lead time]]. However, in practice, inventory is to be maintained for consumption during 'variations in lead time'. Lead time itself can be addressed by ordering that many days in advance.\n#[[Seasonality|Seasonal Demand]]: demands varies periodically, but producers capacity is fixed. This can lead to stock accumulation, consider for example how goods consumed only in holidays can lead to accumulation of large stocks on the anticipation of future consumption. \n#Uncertainty – Inventories are maintained as buffers to meet uncertainties in demand, supply and movements of goods.\n#[[Economies of scale]] – Ideal condition of \"one unit at a time at a place where a user needs it, when he needs it\" principle tends to incur lots of costs in terms of logistics. So bulk buying, movement and storing brings in economies of scale, thus inventory.\n# Appreciation in Value – In some situations, some stock gains the required value when it is kept for some time to allow it reach the desired standard for consumption, or for production. For example; beer in the brewing industry\n\nAll these stock reasons can apply to any owner or product.\n\n=== Special terms used in dealing with inventory management ===\n* ''[[Stock Keeping Unit]]'' (SKU) SKUs are clear, internal identification numbers assigned to each of the products and their variants. SKUs can be any combination of letters and numbers chosen, just as long as the system is consistent and used for all the products in the inventory.<ref>{{Cite web|title = SKUs and UPCs: do your products have a unique identity?|url = https://www.tradegecko.com/blog/skus-and-upcs-do-your-products-have-an-identity|website = www.tradegecko.com|accessdate = 2015-11-23|deadurl = no|archiveurl = https://web.archive.org/web/20151123213941/https://www.tradegecko.com/blog/skus-and-upcs-do-your-products-have-an-identity|archivedate = 2015-11-23|df = }}</ref>\n* ''Stockout'' means running out of the inventory of an SKU.<ref>{{cite web|url=http://www.specialinvestor.com/terms/1072.html|title=Specialinvestor.com|author=|date=|website=www.specialinvestor.com|accessdate=8 May 2018|deadurl=no|archiveurl=https://web.archive.org/web/20061231032227/http://www.specialinvestor.com/terms/1072.html|archivedate=31 December 2006|df=}}</ref>\n* \"[[New old stock]]\" (sometimes abbreviated NOS) is a term used in business to refer to merchandise being offered for sale that was manufactured long ago but that has never been used. Such merchandise may not be produced anymore, and the new old stock may represent the only market source of a particular item at the present time.\n\n===Typology===\n#Buffer/[[safety stock]]\n#[[Reorder level]] \n#Cycle stock (Used in batch processes, it is the available inventory, excluding buffer stock)\n#De-coupling (Buffer stock held between the machines in a single process which serves as a buffer for the next one allowing smooth flow of work instead of waiting the previous or next machine in the same process)\n#Anticipation stock (Building up extra stock for periods of increased demand – e.g. ice cream for summer)\n#Pipeline stock (Goods still in transit or in the process of distribution – have left the factory but not arrived at the customer yet)\n\nAverage Daily/Weekly usage quantity X Lead time in days + Safety stock\n\n===Inventory examples===\nWhile [[accountant]]s often discuss inventory in terms of goods for sale, organizations –  [[manufacturer]]s, [[service provider|service-provider]]s and [[not-for-profit]]s – also have inventories (fixtures, furniture, supplies, etc.) that they do not intend to sell. Manufacturers', [[distribution (business)|distributor]]s', and wholesalers' inventory tends to cluster in [[warehouse]]s. [[Retailer]]s' inventory may exist in a warehouse or in a [[Retailing#Shops and stores|shop]] or store accessible to [[customers]]. Inventories not intended for sale to customers or to [[consumer|client]]s may be held in any premises an organization uses.  Stock ties up cash and, if uncontrolled, it will be impossible to know the actual level of stocks and therefore difficult to keep the costs associated with holding too much or too little inventory under control.\n\nWhile the reasons for holding stock were covered earlier, most manufacturing organizations usually divide their \"goods for sale\" inventory into:\n* [[Raw materials]] – materials and components scheduled for use in making a product.\n* [[Work in process]], WIP – materials and components that have begun their transformation to finished goods.\n* [[Finished goods]] – goods ready for sale to customers.\n* Goods for resale – returned goods that are salable.\n* Stocks in transit.\n* Consignment stocks.\n* Maintenance supply.\n\nFor example:\n\n====Manufacturing====\nA canned food manufacturer's materials inventory includes the ingredients to form the foods to be canned, empty cans and their lids (or coils of steel or aluminum for constructing those components), labels, and anything else (solder, glue, etc.) that will form part of a finished can. The firm's work in process includes those materials from the time of release to the work floor until they become complete and ready for sale to wholesale or retail customers. This may be vats of prepared food, filled cans not yet labeled or sub-assemblies of food components. It may also include finished cans that are not yet packaged into cartons or pallets. Its finished good inventory consists of all the filled and labeled cans of food in its warehouse that it has manufactured and wishes to sell to food distributors (wholesalers), to grocery stores (retailers), and even perhaps to consumers through arrangements like [[factory outlet|factory store]]s and outlet centers.\n\n==== Capital projects ====\nThe partially completed work (or work in process) is a measure of inventory built during the work execution of a capital project,<ref>“Construction: one type of Project Production System”, Proceedings of ''13th Annual Conference of the International Group for Lean Construction.'' Sydney, Australia, 19–21 Jul 2005. pp 29–35</ref><ref>“Strategic Positioning of Inventory to match demand in a capital projects supply chain”, K. D. Walsh, J. C. Hershauer, I.D. Tommelein and T. A. Walsh, Journal of Construction Engineerign and Manabement, Nov–Dec 2014, p 818</ref><ref>{{cite journal|title = New Era of Project Delivery – Project as Production System|first1=R. G. |last1=Shenoy |first2= T. R.|last2= Zabelle|work= Journal of Project Production Management|volume = 1 |date = Nov 2016|pages =13–24  |url=https://www.researchgate.net/publication/312602707_New_Era_of_Project_Delivery_-_Project_as_Production_System  |accessdate= |deadurl=no |archiveurl=https://web.archive.org/web/20170218063109/https://www.researchgate.net/publication/312602707_New_Era_of_Project_Delivery_-_Project_as_Production_System |archivedate=2017-02-18 |df= }}</ref> such as encountered in civilian infrastructure construction or oil and gas. Inventory may not only reflect physical items (such as materials, parts, partially-finished sub-assemblies) but also knowledge work-in-process (such as partially completed engineering designs of components and assemblies to be fabricated).\n\n====Virtual inventory====\nA \"virtual inventory\" (also known as a \"bank inventory\") enables a group of users to share common parts, especially where their availability at short notice may be critical but they are unlikely to required by more than a few bank members at any one time.<ref>''Inventory and Logistics Operations'', CIPS Study Materials, Profex Publishing, 2012, page 54</ref> Virtual inventory also allows distributors and fulfilment houses to ship goods to retailers direct from stock regardless of whether the stock is held in a retail store, stock room or warehouse.<ref>PLS Logistics,[http://info.plslogistics.com/blog/more-inventory-less-warehouse-space-how-virtual-inventory-works More Inventory, Less Warehouse Space: How Virtual Inventory Works] {{webarchive|url=https://web.archive.org/web/20180208123430/http://info.plslogistics.com/blog/more-inventory-less-warehouse-space-how-virtual-inventory-works |date=2018-02-08 }}, published 22 March 2016  accessed 7 February 2018</ref>\n\n=== Costs associated with inventory===\nThere are several costs associated with inventory:\n* [[Ordering cost]]\n* [[Setup cost]]\n* [[Holding Cost]]\n* [[Shortage Cost]]\n\n==Principle of inventory proportionality==\n\n===Purpose===\nInventory proportionality is the goal of demand-driven inventory management. The primary optimal outcome is to have the same number of days' (or hours', etc.) worth of inventory on hand across all products so that the time of runout of all products would be simultaneous. In such a case, there is no \"excess inventory,\" that is, inventory that would be left over of another product when the first product runs out. Excess inventory is sub-optimal because the money spent to obtain it could have been utilized better elsewhere, i.e. to the product that just ran out.\n\nThe secondary goal of inventory proportionality is inventory minimization. By integrating accurate [[demand forecasting]] with inventory management, rather than only looking at past averages, a much more accurate and optimal outcome is expected.\n\nIntegrating demand forecasting into inventory management in this way also allows for the prediction of the \"can fit\" point when inventory storage is limited on a per-product basis.\n\n===Applications===\nThe technique of inventory proportionality is most appropriate for inventories that remain unseen by the consumer, as opposed to \"keep full\" systems where a retail consumer would like to see full shelves of the product they are buying so as not to think they are buying something old, unwanted or stale; and differentiated from the \"trigger point\" systems where product is reordered when it hits a certain level; inventory proportionality is used effectively by just-in-time manufacturing processes and retail applications where the product is hidden from view.\n\nOne early example of inventory proportionality used in a retail application in the United States was for motor fuel. Motor fuel (e.g. gasoline) is generally stored in underground storage tanks. The motorists do not know whether they are buying gasoline off the top or bottom of the tank, nor need they care. Additionally, these storage tanks have a maximum capacity and cannot be overfilled. Finally, the product is expensive. Inventory proportionality is used to balance the inventories of the different grades of motor fuel, each stored in dedicated tanks, in proportion to the sales of each grade. Excess inventory is not seen or valued by the consumer, so it is simply cash sunk (literally) into the ground. Inventory proportionality minimizes the amount of excess inventory carried in underground storage tanks. This application for motor fuel was first developed and implemented by [[Petrolsoft Corporation]] in 1990 for [[Chevron Corporation|Chevron]] Products Company. Most major oil companies use such systems today.<ref name=aspentech>{{citation|url=http://www.aspentech.com/solutions/industry_solutions/refining_marketing/aspenone_supply_distribution.cfm|title=aspenONE Supply & Distribution for Refining & Marketing|deadurl=yes|archiveurl=https://web.archive.org/web/20100608125910/http://www.aspentech.com/solutions/industry_solutions/refining_marketing/aspenone_supply_distribution.cfm|archivedate=2010-06-08|df=}}</ref>\n\n===Roots===\nThe use of inventory proportionality in the United States is thought to have been inspired by Japanese [[just-in-time (business)|just-in-time]] parts inventory management made famous by [[Toyota]] Motors in the 1980s.<ref>{{cite web |url=http://www.bsu.edu/web/scfrazier2/jit/mainpage.htm |title=Archived copy |accessdate=2010-03-24 |deadurl=yes |archiveurl=https://web.archive.org/web/20100425054824/http://www.bsu.edu/web/scfrazier2/jit/mainpage.htm |archivedate=2010-04-25 |df= }}</ref>\n\n==High-level inventory management==\nIt seems that around 1880<ref>Relevance Lost, Johnson and Kaplan, Harvard Business School Press, 1987, p126</ref> there was a change in manufacturing practice from companies with relatively homogeneous lines of products to horizontally integrated companies with unprecedented diversity in processes and products. Those companies (especially in metalworking) attempted to achieve success through economies of scope - the gains of jointly producing two or more products in one facility. The managers now needed information on the effect of product-mix decisions on overall profits and therefore needed accurate product-cost information. A variety of attempts to achieve this were unsuccessful due to the huge overhead of the information processing of the time. However, the burgeoning need for financial reporting after 1900 created unavoidable pressure for [[financial accounting]] of stock and the management need to cost manage products became overshadowed. In particular, it was the need for audited accounts that sealed the fate of managerial cost accounting. The dominance of financial reporting accounting over [[management accounting]] remains to this day with few exceptions, and the financial reporting definitions of 'cost' have distorted effective management 'cost' accounting since that time. This is particularly true of inventory.\n\nHence, high-level financial inventory has these two basic formulas, which relate to the accounting period:\n\n#Cost of [[Beginning Inventory]] at the start of the period + inventory [[purchase]]s within the period + cost of [[Production, costs, and pricing|production]] within the period =  cost of goods available\n# Cost of goods available − cost of [[ending inventory]] at the end of the period = [[cost of goods sold]]\n\nThe benefit of these formulas is that the first absorbs all overheads of production and raw material costs into a value of inventory for reporting. The second formula then creates the new start point for the next period and gives a figure to be subtracted from the sales price to determine some form of sales-margin figure.\n\nManufacturing management is more interested in ''inventory turnover ratio'' or ''average days to sell inventory'' since it tells them something about relative inventory levels.\n\n:Inventory turnover ratio (also known as [[inventory turns]]) = cost of goods sold / Average Inventory = Cost of Goods Sold / ((Beginning Inventory + Ending Inventory) / 2)\n\nand its inverse\n\n:Average Days to Sell Inventory = Number of Days a Year / Inventory Turnover Ratio = 365 days a year / Inventory Turnover Ratio\n\nThis ratio estimates how many times the inventory turns over a year. This number tells how much cash/goods are tied up waiting for the process and is a critical measure of process reliability and effectiveness. So a factory with two inventory turns has six months stock on hand, which is generally not a good figure (depending upon the industry), whereas a factory that moves from six turns to twelve turns has probably improved effectiveness by 100%. This improvement will have some negative results in the financial reporting, since the 'value' now stored in the factory as inventory is reduced.\n\nWhile these accounting measures of inventory are very useful because of their simplicity, they are also fraught with the danger of their own assumptions. There are, in fact, so many things that can vary hidden under this appearance of simplicity that a variety of 'adjusting' assumptions may be used. These include:\n* [[Specific Identification]]\n* [[Lower of cost or market]]\n* [[Weighted Average Cost]]\n* [[Moving-Average Cost]]\n* [[FIFO and LIFO accounting|FIFO and LIFO]].\n* [[Queueing theory]]. <ref>{{Cite journal|url=https://www.sciencedirect.com/science/article/pii/S0278612510000397|title=A queueing approach to production-inventory planning for supply chain with uncertain demands: Case study of PAKSHOO Chemicals Company|author=Fathi, M.}}</ref>\n\n\nInventory Turn is a financial accounting tool for evaluating inventory and it is not necessarily a management tool. Inventory management should be forward looking. The methodology applied is based on historical cost of goods sold. The ratio may not be able to reflect the usability of future production demand, as well as customer demand.\n\nBusiness models, including Just in Time (JIT) Inventory, Vendor Managed Inventory (VMI) and Customer Managed Inventory (CMI), attempt to minimize on-hand inventory and increase inventory turns. VMI and CMI have gained considerable attention due to the success of third-party vendors who offer added expertise and knowledge that organizations may not possess.\n\nInventory management in modern days is online oriented and more viable in digital. This type of dynamics order management will require end-to-end visibility, collaboration across fulfillment processes, real-time data automation among different companies, and integration among multiple systems.<ref>{{Cite news|url=http://magentone.over-blog.com/2017/03/big-trends-for-inventory-management-in-2017.html|title=Big trends for Inventory Management in 2017 [Infographic] (UPDATED) - Magentone Developers Website|work=Magentone Developers Website|access-date=2017-07-19|language=en-US|deadurl=no|archiveurl=https://web.archive.org/web/20170718182930/http://magentone.over-blog.com/2017/03/big-trends-for-inventory-management-in-2017.html|archivedate=2017-07-18|df=}}</ref>\n\n==Accounting for inventory==\n{{Accounting}}\n\nEach country has its own rules about [[accounting]] for inventory that fit with their financial-reporting rules.\n\nFor example, organizations in the U.S. define '''inventory''' to suit their needs within [[US generally accepted accounting principles|US Generally Accepted Accounting Practices]] (GAAP), the rules defined by the [[Financial Accounting Standards Board]] (FASB) (and others) and enforced by the [[U.S. Securities and Exchange Commission]] (SEC) and other federal and state agencies. Other countries often have similar arrangements but with their own accounting standards and national agencies instead.\n\nIt is intentional that [[financial accounting]] uses standards that allow the public to compare firms' performance, [[cost accounting]] functions internally to an organization and potentially with much greater flexibility. A discussion of inventory from standard and [[Theory of Constraints]]-based ([[throughput]]) [[cost accounting]] perspective follows some examples and a discussion of inventory from a [[financial accounting]] perspective.\n\nThe internal costing/valuation of inventory can be complex. Whereas in the past most enterprises ran simple, one-process factories, such enterprises are quite probably in the minority in the 21st century. Where 'one process' factories exist, there is a market for the goods created, which establishes an independent market value for the good. Today, with multistage-process companies, there is much inventory that would once have been finished goods which is now held as 'work in process' (WIP). This needs to be valued in the accounts, but the valuation is a management decision since there is no market for the partially finished product. This somewhat arbitrary 'valuation' of WIP combined with the allocation of overheads to it has led to some unintended and undesirable results.\n\n===Financial accounting===\nAn organization's inventory can appear a mixed blessing, since it counts as an [[asset]] on the [[balance sheet]], but it also ties up money that could serve for other purposes and requires additional expense for its protection. Inventory may also cause significant tax expenses, depending on particular countries' laws regarding depreciation of inventory, as in [[Thor Power Tool Company v. Commissioner]].\n\nInventory appears as a [[current asset]] on an organization's balance sheet because the organization can, in principle, turn it into cash by selling it. Some organizations hold larger inventories than their operations require in order to inflate their apparent asset value and their perceived profitability.\n\nIn addition to the money tied up by acquiring inventory, inventory also brings associated costs for warehouse space, for utilities, and for [[insurance]] to cover staff to handle and protect it from fire and other disasters, obsolescence, shrinkage (theft and errors), and others. Such [[holding cost]]s can mount up: between a third and a half of its acquisition value per year. <!-- An organization that reduced its inventory by $1,000,000 would add that amount to its net income [huh???  Its net income would only increase by the income received minus the cost of the goods sold], an attractive prospect that helps to explain the popularity of programs like [[Just in time]] (JIT) inventory.   -->\n\nBusinesses that stock too little inventory cannot take advantage of large orders from customers if they cannot deliver. The conflicting objectives of cost control and customer service often put an organization's financial and operating managers against its [[sales]] and [[marketing]] departments. Salespeople, in particular, often receive sales-commission payments, so unavailable goods may reduce their potential personal income. This conflict can be minimised by reducing production time to being near or less than customers' expected delivery time. This effort, known as \"[[Lean production]]\" will significantly reduce [[working capital]] tied up in inventory and reduce manufacturing costs (See the [[Toyota Production System]]).\n\n===Role of inventory accounting===\nBy helping the organization to make better decisions, the accountants can help the public sector to change in a very positive way that delivers increased value for the taxpayer’s investment. It can also help to incentive's progress and to ensure that reforms are sustainable and effective in the long term, by ensuring that success is appropriately recognized in both the formal and informal reward systems of the organization.\n\nTo say that they have a key role to play is an understatement. Finance is connected to most, if not all, of the key business processes within the organization. It should be steering the stewardship and accountability systems that ensure that the organization is conducting its business in an appropriate, ethical manner. It is critical that these foundations are firmly laid. So often they are the litmus test by which public confidence in the institution is either won or lost.\n\nFinance should also be providing the information, analysis and advice to enable the organizations’ service managers to operate effectively. This goes beyond the traditional preoccupation with budgets – how much have we spent so far, how much do we have left to spend? It is about helping the organization to better understand its own performance. That means making the connections and understanding the relationships between given inputs – the resources brought to bear – and the outputs and outcomes that they achieve. It is also about understanding and actively managing risks within the organization and its activities.\n\n===FIFO vs. LIFO accounting===\n{{main article|FIFO and LIFO accounting}}\n\nWhen a merchant buys goods from inventory, the value of the inventory account is reduced by the [[cost of goods sold]] (COGS). This is simple where the cost has not varied across those held in stock; but where it has, then an agreed method must be derived to evaluate it. For [[commodity]] items that one cannot track individually, accountants must choose a method that fits the nature of the sale. Two popular methods in use are: FIFO (first in – first out) and LIFO (last in – first out).\n\nFIFO treats the first unit that arrived in inventory as the first one sold. LIFO considers the last unit arriving in inventory as the first one sold. Which method an accountant selects can have a significant effect on net income and [[book value]] and, in turn, on taxation. Using LIFO accounting for inventory, a company generally reports lower net income and lower book value, due to the effects of inflation. This generally results in lower taxation. Due to LIFO's potential to skew inventory value, [[UK GAAP]] and [[International Accounting Standards|IAS]] have effectively banned LIFO inventory accounting. LIFO accounting is permitted in the United States subject to section 472 of the [[Internal Revenue Code]].<ref>[https://www.gpo.gov/fdsys/pkg/USCODE-2011-title26/pdf/USCODE-2011-title26-subtitleA-chap1-subchapE-partII-subpartD-sec472.pdf Internal Revenue Code, § 472: Last-in, first-out inventories] {{webarchive|url=https://web.archive.org/web/20161223134628/https://www.gpo.gov/fdsys/pkg/USCODE-2011-title26/pdf/USCODE-2011-title26-subtitleA-chap1-subchapE-partII-subpartD-sec472.pdf |date=2016-12-23 }}, accessed 23 December 2016</ref>\n\n===Standard cost accounting===\n{{main article|Standard cost accounting}}\nStandard cost accounting uses [[ratio]]s called [[Efficiency (economics)|efficiencies]] that compare the labour and materials actually used to produce a good with those that the same goods would have required under \"standard\" conditions. As long as actual and standard conditions are similar, few problems arise. Unfortunately, standard cost accounting methods developed about 100 years ago, when labor comprised the most important cost in manufactured goods. Standard methods continue to emphasize labor efficiency even though that resource now constitutes a (very) small part of cost in most cases.\n\nStandard cost accounting can hurt managers, workers, and firms in several ways. For example, a policy decision to increase inventory can harm a manufacturing manager's [[performance evaluation]]. Increasing inventory requires increased production, which means that processes must operate at higher rates. When (not if) something goes wrong, the process takes longer and uses more than the standard labor time. The manager appears responsible for the excess, even though s/he has no control over the production requirement or the problem.\n\nIn adverse economic times, firms use the same efficiencies to downsize, rightsize, or otherwise reduce their labor force. Workers laid off under those circumstances have even less control over excess inventory and cost efficiencies than their managers.\n\nMany financial and cost accountants have agreed for many years on the desirability of replacing standard cost accounting. They have not, however, found a successor.\n\n===Theory of constraints cost accounting===\n[[Eliyahu M. Goldratt]] developed the [[Theory of Constraints]] in part to address the cost-accounting problems in what he calls the \"cost world.\" He offers a substitute, called [[throughput accounting]], that uses [[Throughput (business)|throughput]] (money for goods sold to customers) in place of output (goods produced that may sell or may boost inventory) and considers labor as a fixed rather than as a variable cost. He defines inventory simply as everything the organization owns that it plans to sell, including buildings, machinery, and many other things in addition to the categories listed here. Throughput accounting recognizes only one class of variable costs: the truly variable costs, like materials and components, which vary directly with the quantity produced\n\nFinished goods inventories remain [[balance sheet|balance-sheet]] assets, but labor-efficiency ratios no longer evaluate managers and workers. Instead of an incentive to reduce labor cost, throughput accounting focuses attention on the relationships between throughput (revenue or income) on one hand and controllable operating expenses and changes in inventory on the other.\n\n==National accounts==\nInventories also play an important role in [[national accounts]] and the analysis of the [[business cycle]]. Some short-term [[macroeconomic]] fluctuations are attributed to the [[Inventory investment#Inventory investment over the business cycle|inventory cycle]].\n\n==Distressed inventory==\nAlso known as distressed or expired stock, distressed inventory is inventory whose potential to be sold at a normal [[cost]] has passed or will soon pass. In certain industries it could also mean that the stock is or will soon be impossible to sell. Examples of distressed inventory include products which have reached their [[Shelf life|expiry date]], or have reached a date in advance of expiry at which the planned market will no longer purchase them (e.g. 3 months left to expiry), clothing which is out of [[fashion]], music which is no longer popular and old newspapers or magazines. It also includes computer or consumer-electronic equipment which is obsolete or discontinued and whose manufacturer is unable to support it, along with products which use that type of equipment e.g. [[VHS]] format equipment and videos.<ref name=\"SAXENA2009\">{{cite book|author=R. S. SAXENA|title=INVENTORY MANAGEMENT: Controlling in a Fluctuating Demand Environment|url=https://books.google.com/books?id=H6AM-vRhmoAC&pg=PA24|accessdate=7 April 2012|date=1 December 2009|publisher=Global India Publications|isbn=978-93-8022-821-1|pages=24–}}</ref>\n\nIn 2001, [[Cisco]] wrote off inventory worth US $2.25 billion due to duplicate orders.<ref>{{cite web|last=Armony |first=Mor\n |title=The Impact of Duplicate Orders on Demand Estimation and Capacity Investment |url=http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0371}}</ref> This is considered one of the biggest inventory write-offs in business history.{{citation needed|date=February 2017}}\n\n==Stock rotation==\n\nStock rotation is the practice of changing the way inventory is displayed on a regular basis. This is most commonly used in hospitality and retail - particularity where food products are sold. For example, in the case of supermarkets that a customer frequents on a regular basis, the customer may know exactly what they want and where it is. This results in many customers going straight to the product they seek and do not look at other items on sale. To discourage this practice, stores will rotate the location of stock to encourage customers to look through the entire store. This is in hopes the customer will pick up items they would not normally see.<ref>{{cite book|last=Lee|first=Perlitz|title=Retail Services|year=2012|publisher=McGraw HIll|location=Australia|isbn=9781743070741|pages=440|url=http://www.mcgraw-hill.com.au/html/9781743070741.html|deadurl=yes|archiveurl=https://web.archive.org/web/20130221050022/http://www.mcgraw-hill.com.au/html/9781743070741.html|archivedate=2013-02-21|df=}}</ref>\n\n==Inventory credit==\nInventory credit refers to the use of stock, or inventory, as [[collateral (finance)|collateral]] to raise finance. Where banks may be reluctant to accept traditional collateral, for example in [[developing countries]] where [[land registration|land title]] may be lacking, inventory credit is a potentially important way of overcoming financing constraints. This is not a new concept; archaeological evidence suggests that it was practiced in Ancient Rome. Obtaining finance against stocks of a wide range of products held in a [[bonded warehouse]] is common in much of the world. It is, for example, used with Parmesan cheese in Italy.<ref>{{cite web|url=http://www.italiannotebook.com/local-interest/parmigiano-hedge/|title=Who moved my Parmigiano?|work=italiannotebook.com|deadurl=no|archiveurl=https://archive.is/20130126133935/http://www.italiannotebook.com/local-interest/parmigiano-hedge/|archivedate=2013-01-26|df=}}</ref> Inventory credit on the basis of stored agricultural produce is widely used in Latin American countries and in some Asian countries.<ref>{{cite web|first1=Jonathan|last1=Coulter|first2=Andrew W.|last2=Shepherd|url=http://www.fao.org/docrep/v7470e/v7470e00.htm|title=Inventory Credit – An approach to developing agricultural markets|website=fao.org|location=Rome|year=1995|deadurl=no|archiveurl=https://web.archive.org/web/20090314040802/http://www.fao.org/DOCREP/V7470E/V7470E00.HTM|archivedate=2009-03-14|df=}}</ref> A precondition for such credit is that banks must be confident that the stored product will be available if they need to call on the collateral; this implies the existence of a reliable network of certified warehouses.<ref>{{cite web|last=CTA and EAGC|title=Structured grain trading systems in Africa|url=http://publications.cta.int/media/publications/downloads/1749_PDF.pdf|publisher=CTA|accessdate=27 February 2014|deadurl=no|archiveurl=https://web.archive.org/web/20141002180749/http://publications.cta.int/media/publications/downloads/1749_PDF.pdf|archivedate=2 October 2014|df=}}</ref> Banks also face problems in valuing the inventory. The possibility of sudden falls in commodity prices means that they are usually reluctant to lend more than about 60% of the value of the inventory at the time of the loan.\n\n==Journal ==\n* International Journal of Inventory Research\n\n==See also==\n* [[Cash conversion cycle]]\n* [[Consignment stock]]\n* [[Cost of goods sold]]\n* [[Economic order quantity]]\n* [[Inventory investment]]\n* [[Inventory management software]]\n* [[Operations research]]\n* [[Pinch point (economics)]]\n* [[Project production management]]\n* [[Service level]]\n* [[Spare part]]\n* [[Stock management]]\n\n==Notes==\n{{reflist|group=nb}}\n\n==References==\n{{Reflist}}\n\n{{Refimprove|date=March 2008}}\n\n==Further reading==\n{{wiktionary}}\n{{Library resources box \n|by=no \n|onlinebooks=no \n|others=no \n|about=yes \n|label=Inventory }}\n{{commons category|Inventories}}\n*{{Cite book | title = Intermediate Accounting 8th Canadian Edition | last = Kieso | first = , DE | isbn = 0-470-15313-X |author2=Warfield, TD |author3=Weygandt, JJ | publisher = [[John Wiley & Sons]] | location = Canada | year = 2007 }}\n* Cannella S., Ciancimino E. (2010) Up-to-date Supply Chain Management: the Coordinated (S,R). In \"Advanced Manufacturing and Sustainable Logistics\". Dangelmaier  W. et al. (Eds.) 175-185. Springer-Verlag  Berlin Heidelberg, Germany.\n{{Inventory types}}\n{{Supply chain Drivers}}\n\n[[Category:Inventory| ]]\n[[Category:Supply chain management]]\n[[Category:Inventory optimization]]\n[[Category:National accounts]]\n[[Category:Lean manufacturing]]\n\n[[fr:Stock]]"
    },
    {
      "title": "Inventory analysis",
      "url": "https://en.wikipedia.org/wiki/Inventory_analysis",
      "text": "'''Inventory analysis''' is the process of understanding the stock/[[product (business)|product]] mix combined with the knowledge of the demand for stock/[[Product (business)|product]]. It is the technique to determine the optimum level of inventory for a firm.<ref>{{Cite web|url=http://www.businessdictionary.com/definition/inventory-analysis.html|title=What is inventory analysis? definition and meaning|website=BusinessDictionary.com|language=en|access-date=2017-05-05}}</ref><ref>{{Cite web|url=http://www.accountingtools.com/questions-and-answers/what-is-inventory-analysis.html|title=What is inventory analysis? - Questions & Answers - AccountingTools|website=www.accountingtools.com|language=en|access-date=2017-05-05}}</ref>\n\n== Computing inventory balances ==\n* [[Average cost method|Average-cost method]]\n* [[FIFO and LIFO accounting|First in first out]] \n* [[FIFO and LIFO accounting|Last in first out]]\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Inventory Analysis}}\n[[Category:Inventory optimization]]\n\n\n{{Microeconomics-stub}}"
    },
    {
      "title": "Inventory control",
      "url": "https://en.wikipedia.org/wiki/Inventory_control",
      "text": "{{see also|Stock management}}\n\n'''Inventory control''' or '''stock control''' can be broadly defined as \"the activity of checking a shop’s stock.\"<ref name=\"MacDiction\">{{cite web |url=https://www.macmillandictionary.com/dictionary/british/stock-control |title=stock control |work=Macmillan Dictionary |publisher=Macmillan Publishers Limited |accessdate=21 June 2018}}</ref> However, a more focused definition takes into account the more science-based, methodical practice of not only verifying a business' inventory but also focusing on the many related facets of inventory management (such as forecasting future demand) \"within an organisation to meet the demand placed upon that business economically.\"<ref name=\"LewisDemand12\">{{cite book |url=https://books.google.com/books?id=NOOmR2D88Q0C |chapter=Chapter 1: Demand forecasting and inventory control |title=Demand Forecasting and Inventory Control |author=Lewis, C. |publisher=Routledge |page=3–20 |year=2012 |isbn=9781136346835}}</ref> Other facets of inventory control include [[supply chain management]], [[production control]], financial flexibility, and customer satisfaction.<ref name=\"AxsäterInventory15-1\">{{cite book |url=https://books.google.com/books?id=v9YjCgAAQBAJ&pg=PA1 |chapter=Chapter 1: Introduction |title=Inventory Control |author=Axsäter, S. |publisher=Springer |page=1–6 |year=2015 |isbn=9783319157290}}</ref> At the root of inventory control, however, is the [[inventory control problem]], which involves determining when to order, how much to order, and the logistics (where) of those decisions.<ref name=\"AxsäterInventory15-1\" />\n\nAn extension of inventory control is the inventory control system. This may come in the form of a technological system and its programmed software used for managing various aspects of inventory problems<ref name=\"AxsäterInventory15-2\">{{cite book |url=https://books.google.com/books?id=v9YjCgAAQBAJ&pg=PA7 |chapter=Chapter 2: Forecasting |title=Inventory Control |author=Axsäter, S. |publisher=Springer |page=7–35 |year=2015 |isbn=9783319157290}}</ref> , or it may refer to a methodology (which may include the use of technological barriers) for handling [[loss prevention]] in a business.<ref name=\"HayesRetail14\">{{cite book |url=https://books.google.com/books?id=MEGjBQAAQBAJ&pg=PA30 |title=Retail Security and Loss Prevention |author=Hayes, R. |publisher=Butterworth-Heinemann |page=30 |year=2014 |isbn=9781483296005}}</ref><ref name=\"WesleyAGuide16\">{{cite book |url=https://books.google.com/books?id=pA4SBQAAQBAJ&pg=PA81 |title=A Guide to Internal Loss Prevention |author=Wesley, R.L. |author2=Wanat, J.A. |publisher=Elsevier |pages=81–3 |year=2016 |isbn=9781483135731}}</ref>\n\n==Inventory control systems==\n[[Image:HDWR HD2000 Wireless Barcode Reader.png|thumb|Wireless barcoder reader with [[docking station]]]]An inventory control system is used to keep inventories in a desired state while continuing to adequately supply customers<ref name=\"ChorafasSystems65\">{{cite book |chapter=Chapter 13: Specifications for Inventory Control |title=Systems and Simulation |editor=Chorafas, D.N. |publisher=Elsevier |pages=233–52 |isbn=9780123749185 |doi=10.1016/S0076-5392(09)60019-9}}</ref><ref name=\"AxsäterInventory15-11\">{{cite book |url=https://books.google.com/books?id=v9YjCgAAQBAJ&pg=PA223 |chapter=Chapter 11: Implementation |title=Inventory Control |author=Axsäter, S. |publisher=Springer |page=223–34 |year=2015 |isbn=9783319157290}}</ref>, and its success depends on maintaining clear records on a periodic or perpetual basis.<ref name=\"AxsäterInventory15-11\" /><ref name=\"WildEssentials02\">{{cite book |url=https://books.google.com/books?id=B5j4D0U6QA0C&pg=PA333 |title=Essentials of Operations Management |author=Wild, R. |publisher=Cengage Learning |pages=332–3 |year=2002 |isbn=9781844800520}}</ref> \n\n[[Inventory management software]] often plays an important role in the modern inventory control system, providing timely and accurate analytical, optimization, and forecasting techniques for complex inventory management problems.<ref name=\"AzadivarOperations16\">{{cite book |url=https://books.google.com/books?id=JSCHFC9zaD4C&pg=SA10-PA34 |chapter=10.6 Inventory Management in Practice |title=Operations Research and Management Science Handbook |author=Azadivar, F. |author2=Rangarajan, A. |editor=Ravindran, A.R. |publisher=CRC Press |pages=10-34–10-35 |year=2016 |isbn=9781420009712}}</ref><ref name=\"DonathIOMA02\">{{cite book |url=https://books.google.com/books?id=G8E5bMwTrBQC&pg=PA505 |chapter=Part II Inventory Management - Chapter 4: Software and Technology |title=The IOMA Handbook of Logistics and Inventory Management |editor=Donath, B. |editor2=Mazel, J. |editor3=Dubin, C. |editor4=Patterson, P. |publisher=John Wiley & Sons |pages=504–38 |year=2002 |isbn=9780471209355}}</ref> Typical features of this type of software include<ref name=\"AxsäterInventory15-11\" /><ref name=\"DonathIOMA02\" />:\n\n* inventory tracking and forecasting tools that use selectable algorithms and review cycles to identify anomalies and other areas of concern\n* [[inventory optimization]]\n* purchase and replenishment tools that include automated and manual replenishment components, inventory calculations, and lot size optimization\n* lead time variability management\n* safety stock calculation and forecasting\n* inventory cost management\n* shelf-life and slow-mover logic\n* multiple location support\n\nThrough this functionality, a business may better detail what has sold, how quickly, and at what [[price]], for example. Reports could be used to predict when to stock up on extra products around a holiday or to make decisions about [[special offer]]s, discontinuing products, and so on. \n\nInventory control techniques often rely upon [[barcode]]s and [[radio-frequency identification]] (RFID) tags to provide automatic identification of inventory objects—including but not limited to [[merchandise]], [[consumable]]s, [[fixed asset]]s, circulating tools, library books, and [[capital equipment]]—which in turn can be processed with inventory management software.<ref name=\"GulatiMaint09\">{{cite book |url=https://books.google.com/books?id=igFCp-nz1n8C&pg=PA122 |title=Maintenance and Reliability Best Practices |author=Gulati, R. |author2=Smith, R. |publisher=Industrial Press, Inc |pages=122–4 |year=2009 |isbn=9780831133115}}</ref> A new trend in inventory management is to label inventory and assets with a [[QR Code]], which can then be read with [[smart-phone]]s to keep track of inventory count and movement.<ref name=\"PantanoInternet17\">{{cite book |url=https://books.google.com/books?id=kmyuDQAAQBAJ&pg=PT301 |title=Internet Retailing and Future Perspectives |author=Pantano, E. |author2=Nguyen, B. |author3=Dennis, C. |display-authors=et al |publisher=Routledge |page=PT301 |year=2017 |isbn=9781317378761}}</ref> These new systems are especially useful for field service operations, where an employee needs to record inventory transaction or look up inventory stock in the field, away from the computers and hand-held scanners.\n\n==Advantages and disadvantages==\nInventory control systems have advantages and disadvantages, based on what style of system is being run. A purely periodic (physical) inventory control system takes \"an actual physical count and valuation of all inventory on hand ... at the close of an accounting period,\"<ref name=\"DopsonFood15\">{{cite book |url=https://books.google.com/books?id=yxotCgAAQBAJ&pg=PA115 |title=Food and Beverage Cost Control |author=Dopson, L.R. |author2=Hayes, D.K. |publisher=John Wiley & Sons |pages=115–17 |year=2015 |isbn=9781118988497}}</ref> whereas a perpetual inventory control system takes an initial count of an entire inventory and then closely monitors any additions and deletions as they occur.<ref name=\"DopsonFood15\" /><ref name=\"WildEssentials02\" /> Various advantages and disadvantages, in comparison, include:\n\n* Periodic is technically the more accurate as it considers both counted and valued inventory.<ref name=\"DopsonFood15\" />\n* Periodic is more time-consuming than perpetual.<ref name=\"DopsonFood15\" />\n* Perpetual can lower the cost of carrying inventory vs. periodic.<ref name=\"WildEssentials02\" />\n* Perpetual is typically more costly to run than periodic.<ref name=\"WildEssentials02\" />\n* Perpetual needs to be verified from time to time against an actual physical count, due to scrap, human error, theft, and other variables.<ref name=\"DopsonFood15\" /><ref name=\"WallerTheDef14\">{{cite book |url=https://books.google.com/books?id=cq8_AwAAQBAJ&pg=150 |title=The Definitive Guide to Inventory Management: Principles and Strategies for the Efficient Flow of Inventory Across the Supply Chain |author=Waller, M.A. |author2=Esper, T.L. |publisher=Pearson Education |pages=150–1 |year=2014 |isbn=9780133448825}}</ref>\n\n== See also ==\n{{Col-begin}}\n{{Col-break}}\n\n* [[Supply chain management]]\n* [[Document automation]]\n* [[Warehouse management system]]\n* [[Storage management system]]\n* [[Automated identification and data capture]]\n\n{{Col-break}}\n* [[Economic order quantity]]\n* [[Economic lot scheduling problem]]\n* [[Newsvendor model]]\n* [[Vendor-managed inventory]]\n* [[Scan-based trading]]\n\n{{col-end}}\n\n== References ==\n{{Reflist|2}}\n\n{{DEFAULTSORT:Inventory Control}}\n[[Category:Inventory optimization]]\n[[Category:Freight transport]]\n[[Category:Lean manufacturing]]\n[[Category:Automatic identification and data capture]]"
    },
    {
      "title": "Inventory theory",
      "url": "https://en.wikipedia.org/wiki/Inventory_theory",
      "text": "'''Material theory''' (or more formally the [[mathematical]] theory of inventory and production) is the sub-specialty within [[operations research]] and [[operations management]] that is concerned with the design of production/[[inventory]] systems to minimize [[cost]]s: it studies the decisions faced by firms and the military in connection with [[manufacturing]], [[warehousing]], [[supply chain]]s, [[spare part]] allocation and so on and provides the mathematical foundation for [[logistics]]. The '''inventory control problem''' is the problem faced by a firm that must decide how much to order in each time period to meet demand for its products. The problem can be modeled using mathematical techniques of [[optimal control]], [[dynamic programming]] and [[flow network|network optimization]].  The study of such models is part of inventory theory.\n\n==Issues==\n{{Original research|section|date=March 2016}}\nOne issue is infrequent large orders vs. frequent small orders.  Large orders will increase the amount of inventory on hand, which is costly, but may benefit from volume discounts.  Frequent orders are costly to process, and the resulting small inventory levels may increase the probability of [[stockout]]s, leading to loss of [[customer]]s. In principle all these factors can be calculated mathematically and the [[optimum]] found.\n\nA second issue is related to changes in demand (predictable or random) for the product.  For example, having the needed merchandise on hand in order to make sales during the appropriate buying season(s).  A classic example is a [[toy store]] before [[Christmas]]: if the items are not on the shelves, they cannot be sold.  And the wholesale market is not perfect' there can be considerable delays, particularly with the most popular toys.  So, the entrepreneur or business manager will buy speculatively.  Another example is a [[furniture]] store.  If there is a six-week, or more, delay for customers to receive merchandise, some sales will be lost.  A further example is a restaurant, where a considerable percentage of the sales are the [[value-added]] aspects of food preparation and presentation, and so it is rational to buy and store somewhat more to reduce the chances of running out of key ingredients.  The situation often comes down to two key questions: confidence in the merchandise selling, and the benefits accruing if it does?\n\nA third issue comes from the view that inventory also serves the function of decoupling two separate operations.  For example, [[work in process]] inventory often accumulates between two departments because the consuming and the producing department do not coordinate their work.  With improved coordination this buffer inventory could be eliminated. This leads to the whole philosophy of [[Just In Time (business)|Just In Time]], which argues that the costs of carrying inventory have typically been underestimated, both the direct, obvious costs of storage space and insurance, but also the harder-to-measure costs of increased variables and complexity, and thus decreased flexibility, for the business enterprise.\n\n==Inventory models==\n\nThe mathematical approach is typically formulated as follows:\na store has, at time <math>k</math>, <math>x_k</math> items in stock. It then orders (and receives) <math>u_k</math> items, and sells <math>w_k</math> items, where <math>w</math> follows a given probability distribution. Thus:\n: <math> x_{k+1} = x_k + u_k - w_k</math>\n: <math> u_k \\ge 0 </math>\nWhether <math>x_k</math> is allowed to go negative, corresponding to back-ordered items, will depend on the specific situation; if allowed there will usually be a penalty for back orders. The store has costs that are related to the number of items in store and the number of items ordered: \n:<math>c_k = c(x_k, u_k)</math>. Often this will be in additive form: <math>c_k = p(x_k) + h(u_k)</math>\nThe store wants to select <math>u_k</math> in an optimal way, i.e. to minimize\n:<math> \\sum_{k=0}^T c_k. </math>\nMany other features can be added to the model, including multiple products (denoted <math>x_{ik}</math>), upper bounds on inventory and so on. Inventory models can be based on different assumptions:<ref>Zipkin Paul H., Foundations of Inventory Management, Boston: McGraw Hill, 2000, {{ISBN|0-256-11379-3}}</ref><ref>W. Hopp, M. Spearman, ''Factory Physics'', 3rd ed. Waveland Press, 2011</ref>\n*Nature of [[demand]]: constant, [[Deterministic system|deterministically]] time-varying or [[stochastic]]\n*[[Cost]]s: [[variable cost|variable]] versus [[fixed cost|fixed]]\n*Flow of [[time]]: [[Discrete time|discrete]] versus [[Continuity (mathematics)|continuous]]\n*[[Lead time]]: deterministic or stochastic\n*[[Time horizon]]: finite versus infinite (T=+∞)\n*Presence or absence of [[Scrum (development)#Product backlog|back-ordering]]\n*[[Production rate]]: infinite, deterministic or random\n*Presence or absence of quantity [[Discounts and allowances|discount]]s\n*Imperfect [[Quality (business)|quality]]\n*[[Productive capacity|Capacity]]: infinite or limited\n*[[Product (business)|Product]]s: one or many\n*[[Location (geography)|Location]]: one or many\n*Echelons: one or many\n\n===Classic models===\n\nAlthough the number of models described in the literature is immense, the following is a list of classics:\n* Infinite fill rate for the part being produced: [[Economic order quantity]] model, a.k.a. Wilson EOQ Model\n* Constant fill rate for the part being produced: [[Economic production quantity]] model\n* Demand is random, only one replenishment: classical [[Newsvendor model]]\n* Demand is random, continuous replenishment: [[Base stock model]]\n* Demand varies deterministically over time: [[Dynamic lot size model]] or Wagner-Whitin model\n* Demand varies deterministically over time: [[Silver–Meal heuristic]]\n* Several products produced on the same machine: [[Economic lot scheduling problem]]\n\n==See also==\n\n* [[Safety stock]]\n* [[Inventory optimization]]\n* [[Inventory management software]]\n* [[Supply chain management]]\n* [[Warehouse management system]]\n\n==References==\n{{Reflist}}\n\n==Further reading==\n* International Journal of Inventory Research is an [[academic journal]] on inventory theory publishing current research.\n\nClassic books that established the field are:\n\n* Kenneth J. Arrow, Samuel Karlin, and Herbert E. Scarf: Studies in the Mathematical Theory of Inventory and Production, Stanford University Press, 1958\n* Thomson M. Whitin, G. Hadley, Analysis of Inventory Systems, Englewood Cliffs: Prentice-Hall 1963\n\nMany university courses in inventory theory use one or more of the following current textbooks:\n\n* Axsaeter, Sven. Inventory Control. Norwell, MA: Kluwer, 2000. {{ISBN|0-387-33250-2}}\n* Porteus, Evan L. Foundations of Stochastic Inventory Theory. Stanford, CA: Stanford University Press, 2002. {{ISBN|0-8047-4399-1}}\n* Silver, Edward A., David F. Pyke, and Rein Peterson. Inventory Management and Production Planning and Scheduling, 3rd ed. Hoboken, NJ: Wiley, 1998. {{ISBN|0-471-11947-4}}\n* Simchi-Levi, David, Xin Chen, and Julien Bramel. The Logic of Logistics: Theory, Algorithms, and Applications for Logistics Management, 2nd ed. New York: Springer Verlag, 2004. {{ISBN|0-387-22199-9}}\n* Tempelmeier, Horst. Inventory Management in Supply Networks, 3rd. Edition, Norderstedt (Books on Demand) 2011, {{ISBN|3-8423-4677-8}}\n* Zipkin, Paul H. Foundations of Inventory Management. Boston: McGraw Hill, 2000. {{ISBN|0-256-11379-3}}\n\n[[Category:Inventory optimization]]"
    },
    {
      "title": "Newsvendor model",
      "url": "https://en.wikipedia.org/wiki/Newsvendor_model",
      "text": "The '''newsvendor''' (or '''newsboy''' or '''single-period'''<ref name=stevenson>William J. Stevenson, Operations Management. 10th edition, 2009; page 581</ref> or '''perishable''') '''model''' is a mathematical model in [[operations management]] and [[applied economics]] used to determine [[Inventory optimization|optimal inventory]] levels.  It is (typically) characterized by fixed prices and uncertain demand for a perishable product.  If the inventory level is <math>q</math>, each unit of demand above <math>q</math> is lost in potential sales. This model is also known as the ''newsvendor problem'' or ''newsboy problem'' by analogy with the situation faced by a newspaper vendor who must decide how many copies of the day's paper to stock in the face of uncertain demand and knowing that unsold copies will be worthless at the end of the day.\n\n== History ==\n\nThe mathematical problem appears to date from 1888<ref>{{cite journal | author = F. Y. Edgeworth | authorlink = Francis Ysidro Edgeworth | year = 1888 | title = The Mathematical Theory of Banking | journal = Journal of the Royal Statistical Society | volume = 51 | issue = 1 | pages = 113–127\n | url =  | format =  | accessdate =  | jstor = 2979084}}</ref> where [[Francis Ysidro Edgeworth|Edgeworth]] used the [[central limit theorem]] to determine the optimal cash reserves to satisfy random withdrawals from depositors.<ref>{{cite web|url=http://www.columbia.edu/~gmg2/4000/pdf/lect_07.pdf|title=IEOR 4000 Production Management Lecture 7|author=Guillermo Gallego|publisher=[[Columbia University]]|date=18 Jan 2005|accessdate=30 May 2012}}</ref>  \nAccording to Chen, Cheng, Choi and Wang (2016), the term \"newsboy\" was first mentioned in an example of the Morse and Kimball (1951)'s book/<ref>{{cite journal |author1=R. R. Chen |author2=T.C.E. Cheng |author3=T.M. Choi |author4=Y. Wang | title = Novel Advances in Applications of the Newsvendor Model| journal = Decision Sciences | volume = 47 | pages = 8–10 | year = 2016 }}</ref> The modern formulation relates to a paper in ''[[Econometrica]]'' by [[Kenneth Arrow]], T. Harris, and [[Jacob Marshak]].<ref>K. J. Arrow, T. Harris, Jacob Marshak, Optimal Inventory Policy, ''Econometrica'' 1951</ref>\n\n== Profit function and the critical fractile formula ==\nThe standard newsvendor [[Profit (economics)|profit]] function is\n\n: <math>\\operatorname{E}[\\text{profit}]=\\operatorname{E}\\left[p\\min (q,D)\\right]-cq</math>\n\nwhere <math>D</math> is a [[random variable]] with [[probability distribution]] <math>F</math> representing demand, each unit is sold for price <math>p</math> and purchased for price <math>c</math>, <math>q</math> is the number of units stocked, and <math>E</math> is the [[expectation operator]].  The solution to the optimal stocking quantity of the newsvendor which maximizes expected profit is:\n\n{{Equation box 1\n|indent =:\n|title='''Critical fractile formula'''\n|equation = <math>q=F^{-1}\\left( \\frac{p-c}{p}\\right)</math>\n|cellpadding\n|border\n|border colour = #50C878\n|background colour = #ECFCF4}}\n\nwhere <math>F^{-1}</math> denotes the [[Inverse function|inverse]] [[cumulative distribution function]] of <math>D</math>.\n\nIntuitively, this ratio, referred to as the '''critical fractile''', balances the cost of being understocked (a lost sale worth <math>(p-c)</math>) and the total costs of being either overstocked or understocked (where the cost of being overstocked is the inventory cost, or <math>c</math> so total cost is simply <math>p</math>).\n\nThe critical fractile formula is known as [[Littlewood's rule]] in the [[yield management]] literature.\n\n== Numerical examples ==\nIn the following cases, assume that the retail price, <math>p</math>, is $7 per unit and the purchase price is <math>c</math>, is $5 per unit. This gives a critical fractile of   <math>\\frac{p-c}{p} = \\frac{7-5}{7} = \\frac{2}{7}</math>\n\n=== Uniform distribution ===\nLet demand, <math>D</math>, follow a [[uniform distribution (continuous)]] between <math>D_\\min = 50</math> and <math>D_\\max = 80</math>.\n\n: <math>q_\\text{opt}=F^{-1}\\left( \\frac{7-5}{7}\\right)=F^{-1}\\left( 0.285 \\right) = D_\\min+(D_\\max-D_\\min) \\cdot 0.285 = 58.55\\approx59.</math>\n\nTherefore, optimal inventory level is approximately 59 units.\n\n=== Normal distribution ===\n\nLet demand, <math>D</math>, follow a [[normal distribution]] with a mean, <math>\\mu</math>, demand of 50 and a [[standard deviation]], <math>\\sigma</math>, of 20.\n\n: <math>q_\\text{opt}=F^{-1}\\left( \\frac{7-5}{7}\\right)=\\mu + \\sigma Z^{-1}\\left( 0.285 \\right) = 50 + 20 (-0.56595) = 38.68\\approx 39.</math>\n\nTherefore, optimal inventory level is approximately 39 units.\n\n=== Lognormal distribution ===\n\nLet demand, <math>D</math>, follow a [[lognormal distribution]] with a mean demand of 50, <math>\\mu</math>, and a [[standard deviation]], <math>\\sigma</math>, of 0.2.\n\n: <math>q_\\text{opt}=F^{-1}\\left(\\frac{7-5}{7}\\right)=\\mu e^{Z^{-1}\\left(0.285\\right) \\sigma} = 50 e^{\\left(0.2 \\cdot (-0.56595) \\right)} = 44.64\\approx 45.</math>\n\nTherefore, optimal inventory level is approximately 45 units.\n\n=== Extreme situation ===\nIf <math>p<c</math> (i.e. the retail price is less than the purchase price), the numerator becomes negative. In this situation, it isn't worth keeping any items in the inventory.\n\n== Derivation of optimal inventory level ==\nTo derive the critical fractile formula, start with <math>\\operatorname{E}\\left[{\\min\\{q,D\\}}\\right]</math> and condition on the event <math>D\\leq q</math>:\n\n: <math>\\operatorname{E}[\\min\\{q,D\\}]=\\operatorname{E}[\\min\\{q,D\\}\\mid D\\leq q]\\operatorname{P}(D\\leq q)+\\operatorname{E}[\\min\\{q,D\\}\\mid D>q]\\operatorname{P}(D>q)\n=\\operatorname{E}[D\\mid D\\leq q]F(q)+\\operatorname{E}[q\\mid D>q][1-F(q)]\n=\\operatorname{E}[D\\mid D\\leq q]F(q)+q[1-F(q)]\n</math>\n\nNow use <math>\\operatorname{E}[D\\mid D\\leq q]=\\frac{\\int\\limits_{x\\leq q} xf(x) \\, dx}{\\int\\limits_{x\\leq q} f(x) \\, dx}</math>, where <math>f(x)=F'(x)</math>. The denominator of this expression is <math>F(q)</math>, so now we can write:\n\n: <math>\\operatorname{E}[\\min\\{q,D\\}]=\\int\\limits_{x \\leq q}xf(x)\\,dx+q[1-F(q)]\n</math>\n\nSo <math>\\operatorname{E}[\\text{profit}]=p\\int\\limits_{x\\leq q} xf(x) \\, dx + pq[1-F(q)]-cq</math>\n\nTake the derivative with respect to <math>q</math>:\n\n: <math>\\frac{\\partial}{\\partial q}\\operatorname{E}[\\text{profit}]=pqf(q)+pq(-F'(q))+p[1-F(q)]-c=p[1-F(q)]-c</math>\n\nNow optimize: <math>p\\left[1-F(q^*)\\right]-c=0\\Rightarrow1-F(q^*)=\\frac{c}{p}\\Rightarrow F(q^*)=\\frac{p-c}{p}\\Rightarrow q^*=F^{-1}\\left(\\frac{p-c}{p}\\right)</math>\n\nTechnically, we should also check for convexity: <math>\\frac{\\partial^2}{\\partial q^2}\\operatorname{E}[\\text{profit}]=p[-F'(q)]</math>\n\nSince <math>F</math> is monotone non-decreasing, this second derivative is always non-positive, so the critical point determined above is a global maximum.\n\n== Alternative formulation ==\n\nThe problem above is cast as one of maximizing profit, although it can be cast slightly differently, with the same result. If the demand D exceeds the provided quantity q, then an opportunity cost of <math>(D-q)(p-c)</math> represents lost revenue not realized because of a shortage of inventory. On the other hand, if <math>D\\le q</math>, then (because the items being sold are perishable), there is an overage cost of <math>(q-D)c</math>. This problem can also be posed as one of minimizing the expectation of the sum of the opportunity cost and the overage cost, keeping in mind that only one of these is ever incurred for any particular realization of <math>D</math>. The derivation of this is as follows:\n\n: <math>\n\\begin{align}\n& \\operatorname{E}[\\text{opportunity cost}+\\text{overage cost}] \\\\[6pt]\n= {} & \\operatorname{E}[\\text{overage cost}\\mid D\\leq q]\\operatorname{P}(D\\leq q)+\\operatorname{E}[\\text{opportunity cost}\\mid D>q] \\operatorname{P}(D>q) \\\\[6pt]\n= {} & \\operatorname{E}[(q-D)c\\mid D\\leq q]F(q)+\\operatorname{E}[(D-q)(p-c)\\mid D>q][1-F(q)] \\\\[6pt]\n= {} & c\\operatorname{E}[q-D\\mid D\\leq q]F(q)+(p-c)\\operatorname{E}[D-q\\mid D>q][1-F(q)] \\\\[6pt]\n= {} & cqF(q)-c\\int\\limits_{x\\leq q} xf(x)\\,dx+(p-c)[\\int\\limits_{x>q}xf(x)\\,dx-q(1-F(q))] \\\\[6pt]\n= {} & p\\int\\limits_{x>q} xf(x)\\,dx-pq(1-F(q))-c\\int\\limits_{x>q}xf(x)\\,dx+cq(1-F(q))+cqF(q)-c\\int\\limits_{x\\le q}xf(x)\\,dx \\\\[6pt]\n= {} & p\\int\\limits_{x>q}xf(x)\\,dx-pq+pqF(q)+cq-c\\operatorname{E}[D]\n\\end{align}\n</math>\n\nThe derivative of this expression, with respect to <math>q</math>, is\n\n: <math>\\frac{\\partial}{\\partial q}\\operatorname{E}[\\text{opportunity cost}+\\text{overage cost}]=p(-qf(q))-p+pqF'(q)+pF(q)+c=pF(q)+c-p\n</math>\n\nThis is obviously the negative of the derivative arrived at above, and this is a minimization instead of a maximization formulation, so the critical point will be the same.\n\n== Cost based optimization of inventory level ==\nAssume that the 'newsvendor' is in fact a small company that wants to produce goods to an uncertain market. In this more general situation the cost function of the newsvendor (company) can be formulated in the following manner:\n\n: <math>K(q) = c_f + c_v (q-x) + p \\operatorname E\\left[\\max(D-q,0)\\right] + h \\operatorname E\\left[\\max(q-D,0) \\right] </math>\n\nwhere the individual parameters are the following:\n* <math>c_f</math> – fixed cost. This cost always exists when the production of a series is started. [$/production]\n* <math>c_v</math> – variable cost. This cost type expresses the production cost of one product. [$/product]\n* <math>q</math> – the product quantity in the inventory. The decision of the inventory control policy concerns the product quantity in the inventory after the product decision. This parameter includes the initial inventory as well. If nothing is produced, then this quantity is equal to the initial quantity, i.e. concerning the existing inventory.\n* <math>x</math> – initial inventory level. We assume that the supplier possesses <math>x</math> products in the inventory at the beginning of the demand of the delivery period.\n* <math>p</math> – penalty cost (or back order cost). If there is less raw material in the inventory than needed to satisfy the demands, this is the penalty cost of the unsatisfied orders. [$/product]\n* <math>D</math> – a random variable with cumulative distribution function <math>F</math> representing uncertain customer demand. [unit]\n* <math>E[D]</math> – expected value of random variable <math>D</math>.\n* <math>h</math> – inventory and stock holding cost. [$ / product]\n\nIn <math>K(q)</math>, the ''first order loss function'' <math>E\\left[\\max(D-q,0)\\right]</math> captures the expected shortage quantity; its complement, <math>E\\left[\\max(q-D,0)\\right]</math>, denotes the expected product quantity in stock at the end of the period.<ref>{{cite book | last = Axsäter | first = Sven | authorlink = Sven Axsäter | year = 2015 | title = Inventory Control | edition=3rd | publisher=Springer International Publishing | isbn = 978-3-319-15729-0 }}</ref>\n\nOn the basis of this cost function the determination of the optimal inventory level is a minimization problem. So in the long run the amount of cost-optimal end-product can be calculated on the basis of the following relation:<ref name=stevenson/>\n\n: <math>q_\\text{opt} = F^{-1}\\left( \\frac{p-c_v}{p+h}\\right)</math>\n\n== Data-driven models  ==\nThere are several data-driven models for the newsvendor problem. Among them, a deep learning model provides quite stable results in any kind of non-noisy or volatile data.<ref>{{cite arxiv|last=Oroojlooyjadid|first=Afshin|last2=Snyder|first2=Lawrence|last3=Takáč|first3=Martin|date=2016-07-07|title=Applying Deep Learning to the Newsvendor Problem|eprint=1607.02177|class=cs.LG}}</ref> More details can be found in a [https://oroojlooy.github.io/blog/newsvendor/ blog] explained the model<ref>{{Cite web|url=https://oroojlooy.github.io/blog/newsvendor|title=Deep Learning for Newsvendor Problem|last=Afshin|date=2017-04-11|website=Afshin|language=en|access-date=2019-03-10}}</ref>.\n\n== See also ==\n* Infinite fill rate for the part being produced: [[Economic order quantity]]\n* Constant fill rate for the part being produced: [[Economic production quantity]]\n* Demand varies over time: [[Dynamic lot size model]]\n* Several products produced on the same machine: [[Economic lot scheduling problem]]\n* [[Reorder point]]\n*[[Inventory control system]]\n*[[Extended newsvendor model]]\n\n== References ==\n<references/>\n\n== Further reading ==\n* Ayhan, Hayriye, Dai, Jim, Foley, R. D., Wu, Joe, 2004: Newsvendor Notes, ISyE 3232 Stochastic Manufacturing & Service Systems. [http://www2.isye.gatech.edu/people/faculty/Hayriye_Ayhan/newsvendor825.pdf]\n* Tsan-Ming Choi (Ed.)  Handbook of Newsvendor Problems: Models, Extensions and Applications, in Springer's International Series in Operations Research and Management Science, 2012.\n\n[[Category:Inventory optimization]]"
    },
    {
      "title": "Partnerized inventory management",
      "url": "https://en.wikipedia.org/wiki/Partnerized_inventory_management",
      "text": "{{Use dmy dates|date=May 2013}}\n{{Refimprove|date=March 2008}}\n\n'''Partner-optimized inventory management''', also known as '''partnerized inventory management''' or sometimes just the abbreviation '''PIM''' is an [[inventory]] management technique or model often used in [[Deterministic system|deterministic]] inventory systems in which a significant portion of the total inventory regularly becomes [[Stochastic process|stochastic]] in nature, due to slowing and/or low demand such as is typical in heavy machinery and construction equipment where the products themselves are extremely durable and have long lives in the field. Inventory in these cases needs to be maintained for an extended time to allow for repairs and product support perhaps as much as two or more decades after a manufacturer has ceased production.\n\nTraditional inventory management techniques break down in cases where a manufacturer maintains inventory to supply future maintenance of their in-service equipment. As demand for [[finished goods|goods]] approaches zero, liquidation of inventory is indicated in most [[revenue management]] models.<ref name=\"SAXENA2009\">{{cite book|author=R. S. SAXENA|title=INVENTORY MANAGEMENT: Controlling in a Fluctuating Demand Environment|date=1 December 2009|publisher=Global India Publications|isbn=978-93-8022-821-1}}</ref> Zero inventory to service products in the field, however, fails the organization in other business areas. Possible costs to manufacture replacement inventory and the harder-to-calculate costs of [[Customer experience|customer confidence]] erosion can be greater over time than the immediate financial concerns that are remedied by liquidating inventory entirely by [[scrap]]ping or discarding it as [[waste]].<ref>“Are Your Inventory Management Practices Outdated,” AberdeenGroup, 1 March 2005.</ref>\n\nWhile scrapping returns inventory to a state of raw materials, Partner-Optimized Inventory Management (PIM) returns inventory to the market as [[intermediate good]]s to be used in production of other goods or non-capital [[spare part]]s.<ref>{{cite book|title=PIM: A Dynamic Model for Inventory Management|year=2012|publisher=Lippert Enterprises|location=Ashland, Ohio|url=http://lippertent.com/free-whitepaper.html|pages=7}}</ref> An organization that uses the PIM model mitigates the immediate [[Pinch point (economics)|pinch point]] caused by inventory reduction by retaining as-needed mutual access to inventory through the marketplace for an indeterminate time rather than losing access immediately and irrevocably through scrapping or discarding the inventory as waste.\n\n==See also==\n* [[Inventory investment]]\n* [[Inventory management software]]\n* [[Operations research]]\n* [[Service level]]\n* [[Spare part]]\n* [[Stock management]]\n\n==References==\n{{reflist}}\n\n==Further reading==\n{{wiktionary}}\n* {{Cite book | title = Intermediate Accounting 8th Canadian Edition | last = Kieso | first = , DE | isbn = 0-470-15313-X |author2=Warfield, TD |author3=Weygandt, JJ | publisher = [[John Wiley & Sons]] | location = Canada | year = 2007 }}\n* Cannella S., Ciancimino E. (2010) Up-to-date Supply Chain Management: the Coordinated (S,R). In \"Advanced Manufacturing and Sustainable Logistics\". Dangelmaier  W. et al. (Eds.) 175–185. Springer-Verlag  Berlin Heidelberg, Germany.\n* [https://emergeapp.net/inventory-reports/inventory-management-techniques/ Inventory Management Techniques]\n\n[[Category:Inventory optimization]]\n[[Category:Freight transport]]\n[[Category:Lean manufacturing]]"
    },
    {
      "title": "Travelling salesman problem",
      "url": "https://en.wikipedia.org/wiki/Travelling_salesman_problem",
      "text": "{{Use British English Oxford spelling|date=August 2016}}\n{{Use dmy dates|date=July 2012}}\n[[File:GLPK solution of a travelling salesman problem.svg|thumb|Solution of a travelling salesman problem: the black line shows the shortest possible loop that connects every red dot]]\nThe '''travelling salesman problem ''' ('''TSP''') asks the following question: \"Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city and returns to the origin city?\" It is an [[NP-hardness|NP-hard]] problem in [[combinatorial optimization]], important in [[operations research]] and [[theoretical computer science]].\n\nThe [[Traveling purchaser problem|travelling purchaser problem]] and the [[vehicle routing problem]] are both generalizations of TSP.\n\nIn the [[Computational complexity theory|theory of computational complexity]], the decision version of the TSP (where, given a length ''L'', the task is to decide whether the graph has any tour shorter than ''L'') belongs to the class of [[NP-completeness|NP-complete]] problems. Thus, it is possible that the [[Best, worst and average case|worst-case]] [[Time complexity|running time]] for any algorithm for the TSP increases [[Time complexity#Superpolynomial time|superpolynomially]] (but no more than [[Exponential time hypothesis|exponentially]]) with the number of cities.\n\nThe problem was first formulated in 1930 and is one of the most intensively studied problems in optimization. It is used as a [[Benchmark (computing)|benchmark]] for many optimization methods. Even though the problem is computationally difficult, a large number of [[heuristic]]s and [[exact algorithm]]s are known, so that some instances with tens of thousands of cities can be solved completely and even problems with millions of cities can be approximated within a small fraction of 1%.<ref>See the TSP world tour problem which has already been solved to within 0.05% of the optimal solution. [http://www.math.uwaterloo.ca/tsp/world/]</ref>\n\nThe TSP has several applications even in its purest formulation, such as [[planning]], [[logistics]], and the manufacture of [[Integrated circuit|microchips]]. Slightly modified, it appears as a sub-problem in many areas, such as [[DNA sequencing]]. In these applications, the concept ''city'' represents, for example, customers, soldering points, or DNA fragments, and the concept ''distance'' represents travelling times or cost, or a [[similarity measure]] between DNA fragments. The TSP also appears in astronomy, as astronomers observing many sources will want to minimize the time spent moving the telescope between the sources. In many applications, additional constraints such as limited resources or time windows may be imposed.\n\n{{Toclimit|3}}\n\n== History ==\n\nThe origins of the travelling salesman problem are unclear. A handbook for travelling salesmen from 1832 mentions the problem and includes example tours through [[Germany]] and [[Switzerland]], but contains no mathematical treatment.<ref>[https://zs.thulb.uni-jena.de/receive/jportal_jparticle_00248075 \"Der Handlungsreisende – wie er sein soll und was er zu tun hat, um Aufträge zu erhalten und eines glücklichen Erfolgs in seinen Geschäften gewiß zu sein – von einem alten Commis-Voyageur\"] (The travelling salesman — how he must be and what he should do in order to get commissions and be sure of the happy success in his business — by an old ''commis-voyageur'')</ref>\n\n[[File:William Rowan Hamilton painting.jpg|thumb|William Rowan Hamilton]]\n\nThe travelling salesman problem was mathematically formulated in the 1800s by the Irish mathematician [[William Rowan Hamilton|W.R. Hamilton]] and by the British mathematician [[Thomas Kirkman]]. Hamilton’s [[Icosian game|Icosian Game]] was a recreational puzzle based on finding a [[Hamiltonian path|Hamiltonian cycle]].<ref>A discussion of the early work of Hamilton and Kirkman can be found in Graph Theory 1736–1936</ref> The general form of the TSP appears to have been first studied by mathematicians during the 1930s in Vienna and at Harvard, notably by [[Karl Menger]], who defines the problem, considers the obvious brute-force algorithm, and observes the non-optimality of the nearest neighbour heuristic:\n{{Quotation|\nWe denote by ''messenger problem'' (since in practice this question should be solved by each postman, anyway also by many travelers) the task to find, for finitely many points whose pairwise distances are known, the shortest route connecting the points. Of course, this problem is solvable by finitely many trials. Rules which would push the number of trials below the number of permutations of the given points, are not known. The rule that one first should go from the starting point to the closest point, then to the point closest to this, etc., in general does not yield the shortest route.\n<ref>Cited and English translation in {{harvtxt|Schrijver|2005}}. Original German: \"Wir bezeichnen als ''Botenproblem'' (weil diese Frage in der Praxis von jedem Postboten, übrigens auch von vielen Reisenden zu lösen ist) die Aufgabe, für endlich viele Punkte, deren paarweise Abstände bekannt sind, den kürzesten die Punkte verbindenden Weg zu finden. Dieses Problem ist natürlich stets durch endlich viele Versuche lösbar. Regeln, welche die Anzahl der Versuche unter die Anzahl der Permutationen der gegebenen Punkte herunterdrücken würden, sind nicht bekannt. Die Regel, man solle vom Ausgangspunkt erst zum nächstgelegenen Punkt, dann zu dem diesem nächstgelegenen Punkt gehen usw., liefert im allgemeinen nicht den kürzesten Weg.\"</ref>}}\n\nIt was first considered mathematically in the 1930s by [[Merrill M. Flood]] who was looking to solve a school bus routing problem.<ref name=\"Wiley\">{{Cite book|url={{google books |plainurl=y |id=qbFlMwEACAAJ}}|title=The Travelling Salesman Problem: A Guided Tour of Combinatorial Optimization|last=Lawler|first=E. L.|date=1985|publisher=John Wiley & sons|isbn=978-0471904137|edition=Repr. with corrections.}}</ref>\n[[Hassler Whitney]] at [[Princeton University]] introduced the name ''travelling salesman problem'' soon after.<ref>A detailed treatment of the connection between Menger and Whitney as well as the growth in the study of TSP can be found in [[Alexander Schrijver]]'s 2005 paper \"On the history of combinatorial optimization (till 1960). Handbook of Discrete Optimization ([[Karen Aardal|K. Aardal]], [[George Nemhauser|G.L. Nemhauser]], R. Weismantel, eds.), Elsevier, Amsterdam, 2005, pp. 1–68.[http://homepages.cwi.nl/~lex/files/histco.ps PS],[http://homepages.cwi.nl/~lex/files/histco.pdf PDF]</ref>\n\nIn the 1950s and 1960s, the problem became increasingly popular in scientific circles in Europe and the USA after the [[RAND Corporation]] in [[Santa Monica]] offered prizes for steps in solving the problem.<ref name=\"Wiley\"/> Notable contributions were made by [[George Dantzig]], [[Delbert Ray Fulkerson]] and [[Selmer M. Johnson]] from the RAND Corporation, who expressed the problem as an [[integer linear program]] and developed the [[Cutting-plane method|cutting plane]] method for its solution. They wrote what is considered the seminal paper on the subject in which with these new methods they solved an instance with 49 cities to optimality by constructing a tour and proving that no other tour could be shorter. Dantzig, Fulkerson and Johnson, however, speculated that given a near optimal solution we may be able to find optimality or prove optimality by adding a small number of extra inequalities (cuts). They used this idea to solve their initial 49 city problem using a string model. They found they only needed 26 cuts to come to a solution for their 49 city problem. While this paper did not give an algorithmic approach to TSP problems, the ideas that lay within it were indispensable to later creating exact solution methods for the TSP, though it would take 15 years to find an algorithmic approach in creating these cuts.<ref name=\"Wiley\"/> As well as cutting plane methods, Dantzig, Fulkerson and Johnson used [[branch and bound]] algorithms perhaps for the first time.<ref name=\"Wiley\"/>\n\nIn the following decades, the problem was studied by many researchers from [[mathematics]], [[computer science]], [[chemistry]], [[physics]], and other sciences. In the 1960s however a new approach was created, that instead of seeking optimal solutions, one would produce a solution whose length is provably bounded by a multiple of the optimal length, and in doing so create lower bounds for the problem; these may then be used with branch and bound approaches. One method of doing this was to create a [[minimum spanning tree]] of the graph and then double all its edges, which produces the bound that the length of an optimal tour is at most twice the weight of a minimum spanning tree.<ref name=\"Wiley\"/>\n\nChristofides made a big advance in this approach of giving an approach for which we know the worst-case scenario. [[Christofides algorithm]] given in 1976, at worst is 1.5 times longer than the optimal solution. As the algorithm was so simple and quick, many hoped it would give way to a near optimal solution method. This remains the method with the best worst-case scenario. However, for a fairly general special case of the problem it was beaten by a tiny margin in 2011.<ref>{{Cite journal|last1=Klarreich|first1=Erica|title=Computer Scientists Find New Shortcuts for Infamous Traveling Salesman Problem|url=https://www.wired.com/2013/01/traveling-salesman-problem/|journal=WIRED|accessdate=2015-06-14|date=2013-01-30}}</ref>\n\n[[Richard M. Karp]] showed in 1972 that the [[Hamiltonian cycle]] problem was [[NP-complete]], which implies the [[NP-hard]]ness of TSP. This supplied a mathematical explanation for the apparent computational difficulty of finding optimal tours.\n\nGreat progress was made in the late 1970s and 1980, when Grötschel, Padberg, Rinaldi and others managed to exactly solve instances with up to 2,392 cities, using cutting planes and [[branch and bound]].\n\nIn the 1990s, [[David Applegate|Applegate]],  [[Robert E. Bixby|Bixby]], [[Vašek Chvátal|Chvátal]], and [[William J. Cook|Cook]] developed the program ''Concorde'' that has been used in many recent record solutions. Gerhard Reinelt published the TSPLIB in 1991, a collection of benchmark instances of varying difficulty, which has been used by many research groups for comparing results. In 2006, Cook and others computed an optimal tour through an  85,900-city instance given by a microchip layout problem, currently the largest solved TSPLIB instance. For many other instances with millions of cities, solutions can be found that are guaranteed to be within 2-3% of an optimal tour.<ref name=\"rggo\">{{citation\n | last1 = Rego | first1 = César\n | last2 = Gamboa | first2 = Dorabela\n | last3 = Glover | first3 = Fred\n | last4 = Osterman | first4 = Colin\n | doi = 10.1016/j.ejor.2010.09.010\n | issue = 3\n | journal = European Journal of Operational Research\n | mr = 2774420\n | pages = 427–441\n | title = Traveling salesman problem heuristics: leading methods, implementations and latest advances\n | volume = 211\n | year = 2011}}.</ref>\n\n==Description==\n\n===As a graph problem===\n[[File:Weighted K4.svg|thumb|Symmetric TSP with four cities]]\nTSP can be modelled as an [[Graph (discrete mathematics)|undirected weighted graph]], such that cities are the graph's [[vertex (graph theory)|vertices]], paths are the graph's [[Glossary of graph theory terms|edges]], and a path's distance is the edge's weight. It is a minimization problem starting and finishing at a specified [[vertex (graph theory)|vertex]] after having visited each other [[vertex (graph theory)|vertex]] exactly once. Often, the model is a [[complete graph]] (''i.e.'' each pair of vertices is connected by an edge). If no path exists between two cities, adding an arbitrarily long edge will complete the graph without affecting the optimal tour.\n\n===Asymmetric and symmetric===\nIn the ''symmetric TSP'', the distance between two cities is the same in each opposite direction, forming an [[undirected graph]]. This symmetry halves the number of possible solutions. In the ''asymmetric TSP'', paths may not exist in both directions or the distances might be different, forming a [[directed graph]]. [[Traffic collision]]s, [[One-way traffic|one-way street]]s, and airfares for cities with different departure and arrival fees are examples of how this symmetry could break down.\n\n===Related problems===\n<!-- This belongs to somewhere else-->\n\n* An equivalent formulation in terms of [[graph theory]] is: Given a [[Glossary of graph theory|complete weighted graph]] (where the vertices would represent the cities, the edges would represent the roads, and the weights would be the cost or distance of that road), find a [[Hamiltonian cycle]] with the least weight.\n* The requirement of returning to the starting city does not change the [[Computational complexity theory|computational complexity]] of the problem, see [[Hamiltonian path problem]].\n* Another related problem is the [[Bottleneck traveling salesman problem]] (bottleneck TSP): Find a Hamiltonian cycle in a [[glossary of graph theory|weighted graph]] with the minimal weight of the weightiest [[edge (graph theory)|edge]]. For example, avoiding narrow streets with big buses.<ref>{{cite web|url=http://online.WSJ.com/public/resources/documents/print/WSJ_-A002-20170812.pdf|title=''How Do You Fix School Bus Routes? Call MIT'' in Wall street Journal}}</ref> The problem is of considerable practical importance, apart from evident transportation and logistics areas. A classic example is in [[Printed circuit board|printed circuit]] manufacturing: scheduling of a route of the [[drill]] machine to drill holes in a PCB. In robotic machining or drilling applications, the \"cities\" are parts to machine or holes (of different sizes) to drill, and the \"cost of travel\" includes time for retooling the robot (single machine job sequencing problem).<ref>{{Citation\n| last1 = Behzad| first1 = Arash| last2 = Modarres\n| first2 = Mohammad| year = 2002\n| title = New Efficient Transformation of the Generalized Traveling Salesman Problem into Traveling Salesman Problem\n| journal = Proceedings of the 15th International Conference of Systems Engineering (Las Vegas)}}</ref> \n* The [[Set TSP problem|generalized travelling salesman problem]], also known as the \"travelling politician problem\", deals with \"states\" that have (one or more) \"cities\" and the salesman has to visit exactly one \"city\" from each \"state\". One application is encountered in ordering a solution to the [[cutting stock problem]] in order to minimize knife changes. Another is concerned with drilling in [[semiconductor]] manufacturing, see e.g., {{US patent|7054798}}. Noon and Bean demonstrated that the generalized travelling salesman problem can be transformed into a standard travelling salesman problem with the same number of cities, but a modified [[distance matrix]].\n* The sequential ordering problem deals with the problem of visiting a set of cities where precedence relations between the cities exist.\n* A common interview question at Google is how to route data among data processing nodes; routes vary by time to transfer the data, but nodes also differ by their computing power and storage, compounding the problem of where to send data.\n* The [[Traveling purchaser problem|travelling purchaser problem]] deals with a purchaser who is charged with purchasing a set of products. He can purchase these products in several cities, but at different prices and not all cities offer the same products. The objective is to find a route between a subset of the cities, which minimizes total cost (travel cost + purchasing cost) and which enables the purchase of all required products.\n\n==Integer linear programming formulations==\nThe TSP can be formulated as an [[integer programming|integer linear program]].<ref>{{Citation|last=Papadimitriou|first=C.H.|last2=Steiglitz |first2=K. |title=Combinatorial optimization: algorithms and complexity|year=1998|publisher=Dover|location=Mineola, NY}}, pp.308-309.</ref><ref>Tucker, A. W. (1960), \"On Directed Graphs and Integer Programs\", IBM Mathematical research Project (Princeton University)</ref><ref>Dantzig, George B. (1963), ''Linear Programming and Extensions'', Princeton, NJ: PrincetonUP, pp. 545–7, {{isbn|0-691-08000-3}}, sixth printing, 1974.</ref> Several formulations are known. Two notable formulations are the Miller-Tucker-Zemlin (MTZ) formulation and the Dantzig-Fulkerson-Johnson (DFJ) formulation. The DFJ formulation is stronger, though the MTZ formulation is still useful in certain settings.<ref>{{cite journal |title=Short combinatorial proof that the DFJ polytope is contained in the MTZ polytope for the Asymmetric Traveling Salesman Problem |journal=Operations Research Letters|volume=45|issue=4|pages=323–324|doi=10.1016/j.orl.2017.04.010|year=2017|last1=Velednitsky|first1=Mark}}</ref><ref>{{cite journal |title=Requiem for the Miller–Tucker–Zemlin subtour elimination constraints? |journal=European Journal of Operational Research|volume=236|issue=3|pages=820–832|doi=10.1016/j.ejor.2013.07.038|year=2014|last1=Bektaş|first1=Tolga|last2=Gouveia|first2=Luis}}</ref>\n\n===Miller-Tucker-Zemlin formulation===\nLabel the cities with the numbers 1, &hellip;, ''n'' and define:\n\n:<math> x_{ij} = \\begin{cases} 1 & \\text{the path goes from city } i \\text{ to city } j \\\\ 0 & \\text{otherwise} \\end{cases}</math>\n\nFor ''i'' = 1, &hellip;, ''n'', let <math>u_i</math> be a dummy variable, and finally take <math>c_{ij}</math> to be the distance from city ''i'' to city ''j''. Then TSP can be written as the following integer linear programming problem:\n\n:<math>\\begin{align}\n\\min &\\sum_{i=1}^n \\sum_{j\\ne i,j=1}^nc_{ij}x_{ij}\\colon &&  \\\\\n     & x_{ij} \\in \\{0,1\\}  && i,j=1, \\ldots, n; \\\\\n     & u_{i} \\in \\mathbf{Z} && i=1, \\ldots, n; \\\\\n     & \\sum_{i=1,i\\ne j}^n x_{ij} = 1 && j=1, \\ldots, n; \\\\\n     & \\sum_{j=1,j\\ne i}^n x_{ij} = 1 && i=1, \\ldots, n; \\\\\n     & u_i-u_j +nx_{ij} \\le n-1 && 2 \\le i \\ne j \\le n;  \\\\\n     & 0 \\le u_i \\le n-1 && 2 \\le i \\le n.\n\\end{align}</math>\n\nThe first set of equalities requires that each city is arrived at from exactly one other city, and the second set of equalities requires that from each city there is a departure to exactly one other city. The last constraints enforce that there is only a single tour covering all cities, and not two or more disjointed tours that only collectively cover all cities. To prove this, it is shown below (1) that every feasible solution contains only one closed sequence of cities, and (2) that for every single tour covering all cities, there are values for the dummy variables <math>u_i</math> that satisfy the constraints.\n\nTo prove that every feasible solution contains only one closed sequence of cities, it suffices to show that every subtour in a feasible solution passes through city 1 (noting that the equalities ensure there can only be one such tour). For if we sum all the inequalities corresponding to <math>x_{ij}=1</math> for any subtour of ''k'' steps not passing through city 1, we obtain:\n\n:<math>nk \\leq (n-1)k,</math>\n\nwhich is a contradiction.\n\nIt now must be shown that for every single tour covering all cities, there are values for the dummy variables <math>u_i</math> that satisfy the constraints.\n\nWithout loss of generality, define the tour as originating (and ending) at city 1. Choose <math>u_{i}=t</math> if city ''i'' is visited in step ''t'' (''i'', ''t'' = 1, 2, ..., n). Then\n\n:<math>u_i-u_j\\le n-1,</math>\n\nsince <math>u_i</math> can be no greater than ''n'' and <math>u_j</math> can be no less than 1; hence the constraints are satisfied whenever <math>x_{ij}=0.</math> For <math>x_{ij}=1</math>, we have:\n\n:<math>  u_{i} - u_{j} + nx_{ij} = (t) - (t+1) + n = n-1,</math>\n\nsatisfying the constraint.\n\n===Dantzig-Fulkerson-Johnson formulation===\nLabel the cities with the numbers 1, &hellip;, ''n'' and define:\n\n:<math> x_{ij} = \\begin{cases} 1 & \\text{the path goes from city } i \\text{ to city } j \\\\ 0 & \\text{otherwise} \\end{cases}</math>\n\nTake <math>c_{ij}</math> to be the distance from city ''i'' to city ''j''. Then TSP can be written as the following integer linear programming problem:\n\n:<math>\\begin{align}\n\\min &\\sum_{i=1}^n \\sum_{j\\ne i,j=1}^nc_{ij}x_{ij}\\colon &&  \\\\\n     & 0 \\le x_{ij} \\le 1  && i,j=1, \\ldots, n; \\\\\n     & \\sum_{i=1,i\\ne j}^n x_{ij} = 1 && j=1, \\ldots, n; \\\\\n     & \\sum_{j=1,j\\ne i}^n x_{ij} = 1 && i=1, \\ldots, n; \\\\\n     & \\sum_{i \\in Q}{\\sum_{j \\in Q}{x_{ij}}} \\leq |Q| - 1 && \\forall Q \\subseteq \\{2, \\ldots, n\\} \\\\\n\\end{align}</math>\n\nThe last constraint of the DFJ formulation ensures that there are no sub-tours among the non-starting vertices, so the solution returned is a single tour and not the union of smaller tours. Because this leads to an exponential number of possible constraints, in practice it is solved with [[Column generation|delayed column generation]].\n\n==Computing a solution==\nThe traditional lines of attack for the NP-hard problems are the following:\n* Devising [[exact algorithm]]s, which work reasonably fast only for small problem sizes.\n* Devising \"suboptimal\" or [[Heuristic (computer science)|heuristic algorithm]]s, i.e., algorithms that deliver approximated solutions in a reasonable time.\n* Finding special cases for the problem (\"subproblems\") for which either better or exact heuristics are possible.\n\n===Exact algorithms===\n\nThe most direct solution would be to try all [[permutation]]s (ordered combinations) and see which one is cheapest (using [[brute-force search]]). The running time for this approach lies within a polynomial factor of <math>O(n!)</math>, the [[factorial]] of the number of cities, so this solution becomes impractical even for only 20 cities.\n\nOne of the earliest applications of [[dynamic programming]] is the [[Held&ndash;Karp algorithm]] that solves the problem in time <math>O(n^2 2^n)</math>.<ref>{{harvtxt|Bellman|1960}}, {{harvtxt|Bellman|1962}}, {{harvtxt|Held|Karp|1962}}</ref> This bound has also been reached by Exclusion-Inclusion in an attempt preceding the dynamic programming approach.\n[[File:Bruteforce.gif|framed|right|Solution to a symmetric TSP with 7 cities using brute force search. Note: Number of permutations: (7-1)!/2 = 360]]\n\nImproving these time bounds seems to be difficult. For example, it has not been determined whether an [[exact algorithm]] for TSP that runs in time <math>O(1.9999^n)</math> exists.<ref>{{harvtxt|Woeginger|2003}}</ref>\n\nOther approaches include:\n* Various [[Branch and bound|branch-and-bound]] algorithms, which can be used to process TSPs containing 40–60 cities.\n\n[[File:Branchbound.gif|framed|right|Solution of a TSP with 7 cities using a simple Branch and bound algorithm. Note: The number of permutations is much less than Brute force search]]\n\n* Progressive improvement algorithms which use techniques reminiscent of [[linear programming]]. Works well for up to 200 cities.\n* Implementations of [[Branch and bound|branch-and-bound]] and problem-specific cut generation ([[Branch and cut|branch-and-cut]]<ref>{{harvtxt|Padberg|Rinaldi|1991}}</ref>); this is the method of choice for solving large instances. This approach holds the current record, solving an instance with 85,900 cities, see {{harvtxt|Applegate|Bixby|Chvátal|Cook|2006}}.\n\nAn exact solution for 15,112 German towns from TSPLIB was found in 2001 using the [[cutting-plane method]] proposed by [[George Dantzig]], [[D. R. Fulkerson|Ray Fulkerson]], and [[Selmer M. Johnson]] in 1954, based on [[linear programming]]. The computations were performed on a network of 110 processors located at [[Rice University]] and [[Princeton University]]. The total computation time was equivalent to 22.6&nbsp;years on a single 500&nbsp;MHz [[Alpha processor]]. In May 2004, the travelling salesman problem of visiting all 24,978 towns in Sweden was solved: a tour of length approximately 72,500 kilometres was found and it was proven that no shorter tour exists.<ref>Work by David Applegate, AT&T Labs – Research, Robert Bixby, [[ILOG]] and Rice University, Vašek Chvátal, Concordia University, William Cook, University of Waterloo, and Keld Helsgaun, Roskilde University is discussed on their project web page hosted by the University of Waterloo and last updated in June 2004, here [http://www.math.uwaterloo.ca/tsp/sweden/]</ref> In March 2005, the travelling salesman problem of visiting all 33,810 points in a circuit board was solved using ''[[Concorde TSP Solver]]'': a tour of length 66,048,945 units was found and it was proven that no shorter tour exists. The computation took approximately 15.7 CPU-years<!-- Is this with a 500&nbsp;MHz processor. Please make clear what you mean by CPU year. --> (Cook et al. 2006). In April 2006 an instance with 85,900 points was solved using ''Concorde TSP Solver'', taking over 136 CPU-years, see {{harvtxt|Applegate|Bixby|Chvátal|Cook|2006}}.\n\n===Heuristic and approximation algorithms===\nVarious [[Heuristic (computer science)|heuristics]] and [[approximation algorithm]]s, which quickly yield good solutions have been devised. Modern methods can find solutions for extremely large problems (millions of cities) within a reasonable time which are with a high probability just 2–3% away from the optimal solution.<ref name=\"rggo\"/>\n\nSeveral categories of heuristics are recognized.\n\n====Constructive heuristics====\n[[File:Nearestneighbor.gif|393px|thumb|Nearest Neighbour algorithm for a TSP with 7 cities. The solution changes as the starting point is changed]]\nThe [[nearest neighbour algorithm|nearest neighbour (NN) algorithm]] (a [[greedy algorithm]]) lets the salesman choose the nearest unvisited city as his next move. This algorithm quickly yields an effectively short route. For N cities randomly distributed on a plane, the algorithm on average yields a path 25% longer than the shortest possible path.<ref name=johnson/> However, there exist many specially arranged city distributions which make the NN algorithm give the worst route.<ref>{{cite journal |last=Gutina |first=Gregory |last2=Yeob |first2=Anders |last3=Zverovich |first3=Alexey |date=15 March 2002 |title=Traveling salesman should not be greedy: domination analysis of greedy-type heuristics for the TSP |journal=Discrete Applied Mathematics |volume=117 |issue=1–3 |pages=81–86 |doi=10.1016/S0166-218X(01)00195-0}}></ref> This is true for both asymmetric and symmetric TSPs.<ref>{{Citation|last=Zverovitch|first=Alexei|title=Experimental Analysis of Heuristics for the ATSP|date=2007|work=The Traveling Salesman Problem and Its Variations|pages=445–487|series=Combinatorial Optimization|publisher=Springer, Boston, MA|doi=10.1007/0-306-48213-4_10|last2=Zhang|first2=Weixiong|last3=Yeo|first3=Anders|last4=McGeoch|first4=Lyle A.|last5=Gutin|first5=Gregory|last6=Johnson|first6=David S. |isbn=978-0-387-44459-8 |citeseerx=10.1.1.24.2386 }}</ref> Rosenkrantz et al.<ref>{{cite conference |first=D. J. |last=Rosenkrantz |first2=R. E. |last2=Stearns |first3=P. M. |last3=Lewis |title=Approximate algorithms for the traveling salesperson problem |conference=15th Annual Symposium on Switching and Automata Theory (swat 1974) |date=14–16 October 1974 |doi=10.1109/SWAT.1974.4}}</ref> showed that the NN algorithm has the approximation factor <math>\\Theta(\\log |V|)</math> for instances satisfying the triangle inequality. A variation of NN algorithm, called Nearest Fragment (NF) operator, which connects a group (fragment) of nearest unvisited cities, can find shorter route with successive iterations.<ref>{{cite journal | last1 = Ray | first1 = S. S. | last2 = Bandyopadhyay | first2 = S. | last3 = Pal | first3 = S. K. | year = 2007 | title = Genetic Operators for Combinatorial Optimization in TSP and Microarray Gene Ordering | url = | journal = Applied Intelligence | volume = 26 | issue = 3| pages = 183–195 | doi=10.1007/s10489-006-0018-y| citeseerx = 10.1.1.151.132 }}</ref> The NF operator can also be applied on an initial solution obtained by NN algorithm for further improvement in an elitist model, where only better solutions are accepted.\n\nThe [[bitonic tour]] of a set of points is the minimum-perimeter [[monotone polygon]] that has the points as its vertices; it can be computed efficiently by [[dynamic programming]].\n\nAnother [[constructive heuristic]], Match Twice and Stitch (MTS), performs two sequential [[Matching (graph theory)|matchings]], where the second matching is executed after deleting all the edges of the first matching, to yield a set of cycles. The cycles are then stitched to produce the final tour.<ref>{{cite journal | last1 = Kahng | first1 = A. B. | last2 = Reda | first2 = S. | year = 2004 | title = Match Twice and Stitch: A New TSP Tour Construction Heuristic | url = | journal = Operations Research Letters | volume = 32 | issue = 6| pages = 499–509 | doi = 10.1016/j.orl.2004.04.001 }}</ref>\n\n=====Christofides algorithm=====\nThe [[Christofides algorithm]] follows a similar outline but combines the minimum spanning tree with a solution of another problem, minimum-weight [[perfect matching]]. This gives a TSP tour which is at most 1.5 times the optimal.  The Christofides algorithm was one of the first [[approximation algorithm]]s, and was in part responsible for drawing attention to approximation algorithms as a practical approach to intractable problems. As a matter of fact, the term \"algorithm\" was not commonly extended to approximation algorithms until later; the Christofides algorithm was initially referred to as the Christofides heuristic.\n\nThis algorithm looks at things differently by using a result from graph theory which helps improve on the LB of the TSP which originated from doubling the cost of the minimum spanning tree. Given an [[Eulerian graph]] we can find an [[Eulerian tour]] in {{tmath|O(n)}} time.<ref name=\"Wiley\"/> So if we had an Eulerian graph with cities from a TSP as vertices then we can easily see that we could use such a method for finding an Eulerian tour to find a TSP solution. By [[triangular inequality]] we know that the TSP tour can be no longer than the Eulerian tour and as such we have a LB for the TSP. Such a method is described below.\n[[File:UbMjAyAmQrSwtP0gdeKe matchingshortcut.png|thumb|Using a shortcut heuristic on the graph created by the matching below]]\n#  Find a minimum spanning tree for the problem\n#  Create duplicates for every edge to create an Eulerian graph\n#  Find an Eulerian tour for this graph\n#  Convert to TSP: if a city is visited twice, create a shortcut from the city before this in the tour to the one after this.\n\nTo improve the lower bound, a better way of creating an Eulerian graph is needed. By triangular inequality, the best Eulerian graph must have the same cost as the best travelling salesman tour, hence finding optimal Eulerian graphs is at least as hard as TSP. One way of doing this is by minimum weight [[Matching (graph theory)|matching]] using algorithms of <math>O(n^3)</math>.<ref name=\"Wiley\"/>\n[[File:Creating a matching.png|thumb|Creating a matching]]\n\nMaking a graph into an Eulerian graph starts with the minimum spanning tree. Then all the vertices of odd order must be made even. So a matching for the odd degree vertices must be added which increases the order of every odd degree vertex by one.<ref name=\"Wiley\"/> This leaves us with a graph where every vertex is of even order which is thus Eulerian. Adapting the above method gives Christofides' algorithm,\n\n#  Find a minimum spanning tree for the problem\n# Create a matching for the problem with the set of cities of odd order. \n# Find an Eulerian tour for this graph\n# Convert to TSP using shortcuts.\n\n====Iterative improvement====\n[[File:Showing a step of the two-opt heuristic.png|thumb|right|An example of a 2-opt iteration]]\n\n===== Pairwise exchange =====\nThe pairwise exchange or ''[[2-opt]]'' technique involves iteratively removing two edges and replacing these with two different edges that reconnect the fragments created by edge removal into a new and shorter tour. Similarly, the [[3-opt]] technique removes 3 edges and reconnects them to form a shorter tour. These are special cases of the ''k''-opt method. Note that the label ''Lin–Kernighan'' is an often heard misnomer for 2-opt. Lin–Kernighan is actually the more general k-opt method.\n\nFor Euclidean instances, 2-opt heuristics give on average solutions that are about 5% better than Christofides' algorithm. If we start with an initial solution made with a [[greedy algorithm]], the average number of moves greatly decreases again and is {{tmath|O(n)}}. For random starts however, the average number of moves is {{tmath|O(n  \\log (n))}}. However whilst in order this is a small increase in size, the initial number of moves for small problems is 10 times as big for a random start compared to one made from a greedy heuristic. This is because such 2-opt heuristics exploit `bad' parts of a solution such as crossings. These types of heuristics are often used within [[Vehicle routing problem]] heuristics to reoptimize route solutions.<ref name=johnson>{{cite book |last1=Johnson|first1=D. S.|author1-link=David S. Johnson|last2=McGeoch|first2=L. A.|chapter=The Traveling Salesman Problem: A Case Study in Local Optimization|title=Local Search in Combinatorial Optimisation|editor1-first=E. H. L.|editor1-last=Aarts|editor2-first=J. K.|editor2-last=Lenstra|editor2-link=Jan Karel Lenstra|publisher=John Wiley and Sons Ltd.|date=1997 |location=London|pages=215–310 |chapter-url=https://www.cs.ubc.ca/~hutter/previous-earg/EmpAlgReadingGroup/TSP-JohMcg97.pdf}}</ref>\n\n===== ''k''-opt heuristic, or Lin–Kernighan heuristics =====\nThe Lin–Kernighan heuristic is a special case of the ''V''-opt or variable-opt technique. It involves the following steps:\n\n# Given a tour, delete ''k'' mutually disjoint edges. \n# Reassemble the remaining fragments into a tour, leaving no disjoint subtours (that is, don't connect a fragment's endpoints together). This in effect simplifies the TSP under consideration into a much simpler problem. \n# Each fragment endpoint can be connected to {{math|2''k''&nbsp;−&nbsp;2}} other possibilities: of 2''k'' total fragment endpoints available, the two endpoints of the fragment under consideration are disallowed. Such a constrained 2''k''-city TSP can then be solved with brute force methods to find the least-cost recombination of the original fragments.\n\nThe most popular of the ''k''-opt methods are 3-opt, as introduced by Shen Lin of [[Bell Labs]] in 1965. A special case of 3-opt is where the edges are not disjoint (two of the edges are adjacent to one another). In practice, it is often possible to achieve substantial improvement over 2-opt without the combinatorial cost of the general 3-opt by restricting the 3-changes to this special subset where two of the removed edges are adjacent. This so-called two-and-a-half-opt typically falls roughly midway between 2-opt and 3-opt, both in terms of the quality of tours achieved and the time required to achieve those tours.\n\n===== ''V''-opt heuristic =====\nThe variable-opt method is related to, and a generalization of the ''k''-opt method. Whereas the ''k''-opt methods remove a fixed number (''k'') of edges from the original tour, the variable-opt methods do not fix the size of the edge set to remove. Instead they grow the set as the search process continues. The best known method in this family is the Lin–Kernighan method (mentioned above as a misnomer for 2-opt). [[Shen Lin]] and [[Brian Kernighan]] first published their method in 1972, and it was the most reliable heuristic for solving travelling salesman problems for nearly two decades. More advanced variable-opt methods were developed at Bell Labs in the late 1980s by David Johnson and his research team. These methods (sometimes called [[Lin–Kernighan–Johnson]]) build on the Lin–Kernighan method, adding ideas from [[tabu search]] and [[evolutionary computing]]. The basic Lin–Kernighan technique gives results that are guaranteed to be at least 3-opt. The Lin–Kernighan–Johnson methods compute a Lin–Kernighan tour, and then perturb the tour by what has been described as a mutation that removes at least four edges and reconnecting the tour in a different way, then ''V''-opting the new tour. The mutation is often enough to move the tour from the [[local minimum]] identified by Lin–Kernighan. ''V''-opt methods are widely considered the most powerful heuristics for the problem, and are able to address special cases, such as the Hamilton Cycle Problem and other non-metric TSPs that other heuristics fail on. For many years Lin–Kernighan–Johnson had identified optimal solutions for all TSPs where an optimal solution was known and had identified the best known solutions for all other TSPs on which the method had been tried.\n\n====Randomized improvement====\nOptimized [[Markov chain]] algorithms which use local searching heuristic sub-algorithms can find a route extremely close to the optimal route for 700 to 800 cities.\n\nTSP is a touchstone for many general heuristics devised for combinatorial optimization such as [[genetic algorithm]]s, [[simulated annealing]], [[tabu search]], [[ant colony optimization]], [[river formation dynamics]] (see [[swarm intelligence]]) and the [[cross entropy method]].\n\n=====Ant colony optimization=====\n{{main|Ant colony optimization algorithms}}\n[[Artificial intelligence]] researcher [[Marco Dorigo]] described in 1993 a method of heuristically generating \"good solutions\" to the TSP using a [[Ant colony optimization|simulation of an ant colony]] called ''ACS'' (''ant colony system'').<ref>Marco Dorigo. \"Ant Colonies for the Traveling Salesman Problem. IRIDIA, Université Libre de Bruxelles. ''IEEE Transactions on Evolutionary Computation'', 1(1):53&ndash;66. 1997. http://citeseer.ist.psu.edu/86357.html</ref> It models behaviour observed in real ants to find short paths between food sources and their nest, an [[emergence|emergent]] behaviour resulting from each ant's preference to follow [[Pheromone#Trail|trail pheromones]] deposited by other ants.\n\nACS sends out a large number of virtual ant agents to explore many possible routes on the map. Each ant probabilistically chooses the next city to visit based on a heuristic combining the distance to the city and the amount of virtual pheromone deposited on the edge to the city. The ants explore, depositing pheromone on each edge that they cross, until they have all completed a tour. At this point the ant which completed the shortest tour deposits virtual pheromone along its complete tour route (''global trail updating''). The amount of pheromone deposited is inversely proportional to the tour length: the shorter the tour, the more it deposits.\n\n[[File:Aco TSP.svg|600px|center]]\n[[File:AntColony.gif|framed|center|Ant colony optimization algorithm for a TSP with 7 cities: Red and thick lines in the pheromone map indicate presence of more pheromone]]\n\n==Special cases==\n\n===Metric===\nIn the ''metric TSP'', also known as ''delta-TSP'' or Δ-TSP, the intercity distances satisfy the [[triangle inequality]].\n\nA very natural restriction of the TSP is to require that the distances between cities form a [[metric (mathematics)|metric]] to satisfy the [[triangle inequality]]; that is the direct connection from ''A'' to ''B'' is never farther than the route via intermediate ''C'':\n:<math>d_{AB} \\le d_{AC} + d_{CB}</math>.\n\nThe edge spans then build a [[metric space|metric]] on the set of vertices. When the cities are viewed as points in the plane, many natural [[distance function]]s are metrics, and so many natural instances of TSP satisfy this constraint.\n\nThe following are some examples of metric TSPs for various metrics.\n*In the Euclidean TSP (see below) the distance between two cities is the [[Euclidean distance]] between the corresponding points.\n*In the rectilinear TSP the distance between two cities is the sum of the absolute values of the differences of their ''x''- and ''y''-coordinates. This metric is often called the [[Manhattan distance]] or city-block metric.\n*In the [[maximum metric]], the distance between two points is the maximum of the absolute values of differences of their ''x''- and ''y''-coordinates.\n\nThe last two metrics appear, for example, in routing a machine that drills a given set of holes in a [[printed circuit board]]. The Manhattan metric corresponds to a machine that adjusts first one co-ordinate, and then the other, so the time to move to a new point is the sum of both movements. The maximum metric corresponds to a machine that adjusts both co-ordinates simultaneously, so the time to move to a new point is the slower of the two movements.\n\nIn its definition, the TSP does not allow cities to be visited twice, but many applications do not need this constraint. In such cases, a symmetric, non-metric instance can be reduced to a metric one. This replaces the original graph with a complete graph in which the inter-city distance <math>d_{AB}</math> is replaced by the [[shortest path]] between ''A'' and ''B'' in the original graph.\n\n===Euclidean===\nWhen the input numbers can be arbitrary real numbers, Euclidean TSP is a particular case of metric TSP, since distances in a plane obey the triangle inequality. When the input numbers must be integers, comparing lengths of tours involves comparing sums of square-roots.\n\nLike the general TSP, Euclidean TSP is NP-hard in either case. With rational coordinates and discretized metric (distances rounded up to an integer), the problem is NP-complete.{{sfnp|Papadimitriou|1977}} With rational coordinates and the actual Euclidean metric, Euclidean TSP is known to be in the Counting Hierarchy,<ref>{{harvtxt|Allender|Bürgisser|Kjeldgaard-Pedersen|Mitersen|2007}}</ref> a subclass of PSPACE. With arbitrary real coordinates, Euclidean TSP cannot be in such classes, since there are uncountably many possible inputs. However, Euclidean TSP is probably the easiest version for approximation.<ref>{{harvtxt|Larson|Odoni|1981}}</ref> For example, the minimum spanning tree of the graph associated with an instance of the Euclidean TSP is a [[Euclidean minimum spanning tree]], and so can be computed in expected O (''n'' log ''n'') time for ''n'' points (considerably less than the number of edges). This enables the simple 2-approximation algorithm for TSP with triangle inequality above to operate more quickly.\n\nIn general, for any ''c'' > 0, where ''d'' is the number of dimensions in the Euclidean space, there is a polynomial-time algorithm that finds a tour of length at most (1 + 1/''c'') times the optimal for geometric instances of TSP in\n\n:<math>O\\left(n (\\log n)^{(O(c \\sqrt{d}))^{d-1}}\\right),</math>\n\ntime; this is called a [[polynomial-time approximation scheme]] (PTAS).{{sfnp|Arora|1998}} [[Sanjeev Arora]] and [[Joseph S. B. Mitchell]] were awarded the [[Gödel Prize]] in 2010 for their concurrent discovery of a PTAS for the Euclidean TSP.\n\nIn practice, simpler heuristics with weaker guarantees continue to be used.\n\n===Asymmetric===\nIn most cases, the distance between two nodes in the TSP network is the same in both directions. The case where the distance from ''A'' to ''B'' is not equal to the distance from ''B'' to ''A'' is called asymmetric TSP. A practical application of an asymmetric TSP is route optimization using street-level routing (which is made asymmetric by one-way streets, slip-roads, motorways, etc.).\n\n====Conversion to symmetric====\nSolving an asymmetric TSP graph can be somewhat complex. The following is a 3×3 matrix containing all possible path weights between the nodes ''A'', ''B'' and ''C''. One option is to turn an asymmetric matrix of size ''N'' into a symmetric matrix of size 2''N''.<ref>{{cite journal | last1 = Jonker | first1 = Roy | last2 = Volgenant | first2 = Ton | title = Transforming asymmetric into symmetric traveling salesman problems | url = | journal = [[Operations Research Letters]] | volume = 2 | issue = 161–163| page = 1983 | doi = 10.1016/0167-6377(83)90048-2 | year = 1983 }}</ref>\n\n:{| class=\"wikitable\"\n|- style=\"text-align:center;\"\n|+ Asymmetric path weights\n! !! ''A'' !! ''B'' !! ''C''\n|- style=\"text-align:center;\"\n! ''A''\n| || 1 || 2\n|- style=\"text-align:center;\"\n! ''B''\n| 6 || || 3\n|- style=\"text-align:center;\"\n! ''C''\n| 5 || 4 ||\n|}\n\nTo double the size, each of the nodes in the graph is duplicated, creating a second ''ghost node'', linked to the original node with a \"ghost\" edge of very low (possibly negative) weight, here denoted −''w''. (Alternatively, the ghost edges have weight 0, and weight w is added to all other edges.)  The original 3×3 matrix shown above is visible in the bottom left and the transpose of the original in the top-right. Both copies of the matrix have had their diagonals replaced by the low-cost hop paths, represented by −''w''. In the new graph, no edge directly links original nodes and no edge directly links ghost nodes.\n\n:{| class=\"wikitable\"\n|- style=\"text-align:center;\" class=\"wikitable\"\n|+ Symmetric path weights\n! !! ''A'' !! ''B'' !! ''C'' !! ''A&prime;'' !! ''B&prime;'' !! ''C&prime;''\n|- style=\"text-align:center;\"\n! ''A''\n| || || || −''w'' || 6 || 5\n|- style=\"text-align:center;\"\n! ''B''\n| || || || 1 || −''w'' || 4\n|- style=\"text-align:center;\"\n! ''C''\n| || || || 2 || 3 || −''w''\n|- style=\"text-align:center;\"\n! ''A&prime;''\n| −''w'' || 1 || 2 || || ||\n|- style=\"text-align:center;\"\n! ''B&prime;''\n| 6 || −''w'' || 3 || || ||\n|- style=\"text-align:center;\"\n! ''C&prime;''\n| 5 || 4 || −''w'' || || ||\n|}\n\nThe weight −''w'' of the \"ghost\" edges linking the ghost nodes to the corresponding original nodes must be low enough to ensure that all ghost edges must belong to any optimal symmetric TSP solution on the new graph (w=0 is not always low enough). As a consequence, in the optimal symmetric tour, each original node appears next to its ghost node (e.g. a possible path is <math>\\mathrm{A \\to A' \\to C \\to C' \\to B \\to B' \\to A}</math>) and by merging the original and ghost nodes again we get an (optimal) solution of the original asymmetric problem (in our example, <math>\\mathrm{A \\to C \\to B \\to A}</math>).\n\n===Analyst's problem===\nThere is an analogous problem in [[geometric measure theory]] which asks the following: under what conditions may a subset ''E'' of [[Euclidean space]] be contained in a [[rectifiable curve]] (that is, when is there a curve with finite length that visits every point in ''E'')? This problem is known as the [[analyst's traveling salesman theorem|analyst's travelling salesman problem]]\n\n===Path length for random sets of points in a square===\nSuppose <math>X_1,\\ldots,X_n</math> are <math>n</math> independent random variables with uniform distribution in the square <math>[0,1]^2</math>, and let <math>L^\\ast_n</math> be the shortest path length (i.e. TSP solution) for this set of points, according to the usual [[Euclidean distance]]. It is known<ref name=\"Beardwood 1959\">{{harvtxt|Beardwood|Halton|Hammersley|1959}}</ref> that, almost surely,\n\n::<math>\\frac{L^*_n}{\\sqrt n}\\rightarrow \\beta\\qquad\\text{when }n\\to\\infty,</math>\n\nwhere <math>\\beta</math> is a positive constant that is not known explicitly. Since <math>L^*_n\\le2\\sqrt n+2</math> (see below), it follows from [[bounded convergence theorem]] that <math>\\beta=\\lim_{n\\to\\infty} \\mathbb E[L^*_n]/\\sqrt n</math>, hence lower and upper bounds on <math>\\beta</math> follow from bounds on <math>\\mathbb E[L^*_n]</math>.\n\nThe almost sure limit <math>\\frac{L^*_n}{\\sqrt n}\\rightarrow \\beta</math> as <math>n\\to\\infty</math> may not exist \nif the independent locations  <math>X_1,\\ldots,X_n</math> are replaced with observations from a stationary ergodic process with uniform marginals.<ref name=\"as2016\">{{citation\n | doi = 10.1214/15-AAP1142\n | last1 = Arlotto | first1 = Alessandro\n | last2 = Steele | first2 = J. Michael | author2-link = J._Michael_Steele\n | journal = The Annals of Applied Probability \n | pages = 2141–2168\n | title = Beardwood–Halton–Hammersley theorem for stationary ergodic sequences: a counterexample\n | volume = 26\n | issue = 4\n | year = 2016| arxiv = 1307.0221}}</ref>\n\n====Upper bound====\n*One has <math>L^*\\le 2\\sqrt{n}+2</math>, and therefore <math>\\beta\\leq 2</math>, by using a naive path which visits monotonically the points inside each of <math>\\sqrt n</math> slices of width <math>1/\\sqrt{n}</math> in the square.\n*Few <ref>{{cite journal|last1=Few|first1=L.|title=The shortest path and the shortest road through n points|journal=Mathematika|date=1955|volume=2|issue=2|pages=141–144|doi=10.1112/s0025579300000784 }}</ref> proved <math>L^*_n\\le\\sqrt{2n}+1.75</math>, hence <math>\\beta\\le\\sqrt 2</math>, later improved by Karloff (1987): <math>\\beta\\le0.984\\sqrt2</math>.\n* The current <ref name=\"ReferenceA\">{{cite journal|last1=Steinerberger|first1=S.|title=New bounds for the traveling salesman constant|journal=Advances in Applied Probability|date=2015|volume=47|issue=1}}</ref> best upper bound is  <math>\\beta\\le 0.92\\dots</math>.\n\n====Lower bound====\n*By observing that <math>\\mathbb E[L^*_n]</math> is greater than <math>n</math> times the distance between <math>X_0</math> and the closest point <math>X_i\\ne X_0</math>, one gets (after a short computation)\n\n::<math>\\mathbb E[L^*_n]\\ge\\tfrac{1}{2} \\sqrt{n}.</math>\n\n*A better lower bound is obtained<ref name=\"Beardwood 1959\"/> by observing that <math>\\mathbb E[L^*_n]</math> is greater than <math>\\tfrac12n</math> times the sum of the distances between <math>X_0</math> and the closest and second closest points <math>X_i,X_j\\ne X_0</math>, which gives\n\n::<math>\\mathbb E[L^*_n]\\ge \\left( \\tfrac{1}{4} + \\tfrac{3}{8} \\right)\\sqrt{n} = \\tfrac{5}{8}\\sqrt{n},</math>\n\n*The currently <ref name=\"ReferenceA\"/> best lower bound is\n::<math>\\mathbb E[L^*_n]\\ge (\\tfrac{5}{8} + \\tfrac{19}{5184})\\sqrt{n},</math>\n\n*Held and Karp<ref>{{cite journal|last1=Held|first1=M.|last2=Karp|first2=R.M.|title=The Traveling Salesman Problem and Minimum Spanning Trees|journal=Operations Research|date=1970|volume=18|issue=6|pages=1138–1162|doi=10.1287/opre.18.6.1138 }}</ref> gave a polynomial-time algorithm that provides numerical lower bounds for <math>L^*_n</math>, and thus for <math>\\beta(\\simeq L^*_n/{\\sqrt n})</math> which seem to be good up to more or less 1%.<ref>{{cite journal|last1=Goemans|first1=M.|last2=Bertsimas|first2=D.|title=Probabilistic analysis of the Held and Karp lower bound for the Euclidean traveling salesman problem|journal=Mathematics of Operations Research|date=1991|volume=16|issue=1|pages=72–89|doi=10.1287/moor.16.1.72}}</ref> In particular, David S. Johnson<ref>{{cite web|url=https://about.att.com/error.html|title=error|website=about.att.com}}</ref> obtained a lower bound by computer experiment:\n\n::<math>L^*_n\\gtrsim 0.7080\\sqrt{n}+0.522,</math>\n\nwhere 0.522 comes from the points near square boundary which have fewer neighbours,\nand Christine L. Valenzuela and Antonia J. Jones <ref>[http://users.cs.cf.ac.uk/Antonia.J.Jones/Papers/EJORHeldKarp/HeldKarp.pdf Christine L. Valenzuela and Antonia J. Jones] {{webarchive|url=https://web.archive.org/web/20071025205411/http://users.cs.cf.ac.uk/Antonia.J.Jones/Papers/EJORHeldKarp/HeldKarp.pdf |date=25 October 2007 }}</ref> obtained the following other numerical lower bound:\n::<math>L^*_n\\gtrsim 0.7078\\sqrt{n}+0.551</math>.\n\n==Computational complexity==\nThe problem has been shown to be [[NP-hard]] (more precisely, it is complete for the [[complexity class]] FP<sup>NP</sup>; see [[function problem]]), and the [[decision problem]] version (\"given the costs and a number ''x'', decide whether there is a round-trip route cheaper than ''x''\") is [[NP-complete]]. The [[bottleneck traveling salesman problem]] is also NP-hard. The problem remains NP-hard even for the case when the cities are in the plane with [[Euclidean distance]]s, as well as in a number of other restrictive cases. Removing the condition of visiting each city \"only once\" does not remove the NP-hardness, since it is easily seen that in the planar case there is an optimal tour that visits each city only once (otherwise, by the [[triangle inequality]], a shortcut that skips a repeated visit would not increase the tour length).\n\n===Complexity of approximation===\n\nIn the general case, finding a shortest travelling salesman tour is [[Optimization problem#NP optimization problem|NPO]]-complete.<ref>{{harvtxt|Orponen|1987}}</ref>  If the distance measure is a [[metric (mathematics)|metric]] (and thus symmetric), the problem becomes [[APX]]-complete<ref>{{harvtxt|Papadimitriou|1983}}</ref> and [[Christofides algorithm|Christofides’s algorithm]] approximates it within 1.5.<ref>{{harvtxt|Christofides|1976}}</ref>\nThe best known inapproximability bound is 123/122 .<ref name=\"KLS2015\">{{harvtxt|Karpinski|Lampis|Schmied|2015}}</ref>\n\nIf the distances are restricted to 1 and 2 (but still are a metric) the approximation ratio becomes 8/7.{{sfnp|Berman|Karpinski|2006}} In the asymmetric case with [[triangle inequality]], only logarithmic performance guarantees are known, the best current algorithm achieves performance ratio 0.814 log(''n'');<ref>{{harvtxt|Kaplan|2004}}</ref> it is an open question if a constant factor approximation exists.\nThe best known inapproximability bound is 75/74 .<ref name=\"KLS2015\" />\n\nThe corresponding maximization problem of finding the ''longest'' travelling salesman tour is approximable within 63/38.<ref>{{harvtxt|Kosaraju|1994}}</ref> If the distance function is symmetric, the longest tour can be approximated within 4/3 by a deterministic algorithm<ref>{{harvtxt|Serdyukov|1984}}</ref> and within <math>\\tfrac{1}{25}(33+\\varepsilon)</math> by a randomized algorithm.<ref>{{harvtxt|Hassin|2000}}</ref>\n\n==Human performance ==\nThe TSP, in particular the [[Euclidean distance|Euclidean]] variant of the problem, has attracted the attention of researchers in [[cognitive psychology]]. It has been observed that humans are able to produce near-optimal solutions quickly, in a close-to-linear fashion, with performance that ranges from 1% less efficient for graphs with 10-20 nodes, and 11% more efficient for graphs with 120 nodes.<ref>{{citation|title=Human performance on the traveling salesman problem|first1=J. N.|last1=Macgregor|first2=T.|last2=Ormerod|journal=Perception & Psychophysics|date=June 1996|volume=58|issue=4|pages=527–539|doi=10.3758/BF03213088}}.</ref><ref>{{Cite journal|last=Dry|first=Matthew|last2=Lee|first2=Michael D.|last3=Vickers|first3=Douglas|last4=Hughes|first4=Peter|date=2006|title=Human Performance on Visually Presented Traveling Salesperson Problems with Varying Numbers of Nodes|journal=The Journal of Problem Solving|volume=1|issue=1|doi=10.7771/1932-6246.1004|issn=1932-6246}}</ref> The apparent ease with which humans accurately generate near-optimal solutions to the problem has led researchers to hypothesize that humans use one or more heuristics, with the two most popular theories arguably being the convex-hull hypothesis and the crossing-avoidance heuristic.<ref>{{Cite journal|last=Rooij|first=Iris Van|last2=Stege|first2=Ulrike|last3=Schactman|first3=Alissa|date=2003-03-01|title=Convex hull and tour crossings in the Euclidean traveling salesperson problem: Implications for human performance studies|journal=Memory & Cognition|volume=31|issue=2|pages=215–220|doi=10.3758/bf03194380|issn=0090-502X|citeseerx=10.1.1.12.6117}}</ref><ref>{{Cite journal|last=MacGregor|first=James N.|last2=Chu|first2=Yun|date=2011|title=Human Performance on the Traveling Salesman and Related Problems: A Review|journal=The Journal of Problem Solving|volume=3|issue=2|doi=10.7771/1932-6246.1090|issn=1932-6246}}</ref><ref>{{Cite journal|last=MacGregor|first=James N.|last2=Chronicle|first2=Edward P.|last3=Ormerod|first3=Thomas C.|date=2004-03-01|title=Convex hull or crossing avoidance? Solution heuristics in the traveling salesperson problem|journal=Memory & Cognition|volume=32|issue=2|pages=260–270|doi=10.3758/bf03196857|issn=0090-502X}}</ref> However, additional evidence suggests that human performance is quite varied, and individual differences as well as graph geometry appear to impact performance in the task.<ref>{{Cite journal|last=Vickers|first=Douglas|last2=Mayo|first2=Therese|last3=Heitmann|first3=Megan|last4=Lee|first4=Michael D|last5=Hughes|first5=Peter|title=Intelligence and individual differences in performance on three types of visually presented optimisation problems|journal=Personality and Individual Differences|volume=36|issue=5|pages=1059–1071|doi=10.1016/s0191-8869(03)00200-9|year=2004}}</ref><ref>{{Cite journal|last=Kyritsis|first=Markos|last2=Gulliver|first2=Stephen R.|last3=Feredoes|first3=Eva|date=2017-06-12|title=Acknowledging crossing-avoidance heuristic violations when solving the Euclidean travelling salesperson problem|journal=Psychological Research|volume=82|issue=5|pages=997–1009|doi=10.1007/s00426-017-0881-7|pmid=28608230|issn=0340-0727}}</ref><ref>{{Cite journal|last=Kyritsis|first=Markos|last2=Blathras|first2=George|last3=Gulliver|first3=Stephen|last4=Varela|first4=Vasiliki-Alexia|title=Sense of direction and conscientiousness as predictors of performance in the Euclidean travelling salesman problem|journal=Heliyon|volume=3|issue=11|pages=e00461|doi=10.1016/j.heliyon.2017.e00461|pmid=29264418|pmc=5727545|date=2017-01-11}}</ref> Nevertheless, results suggest that computer performance on the TSP may be improved by understanding and emulating the methods used by humans for these problems,<ref>{{Cite journal|last=Kyritsis|first=Markos|last2=Gulliver|first2=Stephen R.|last3=Feredoes|first3=Eva|last4=Din|first4=Shahab Ud|date=December 2018|title=Human behaviour in the Euclidean Travelling Salesperson Problem: Computational modelling of heuristics and figural effects|url=https://linkinghub.elsevier.com/retrieve/pii/S1389041718300615|journal=Cognitive Systems Research|volume=52|pages=387–399|doi=10.1016/j.cogsys.2018.07.027}}</ref> and have also led to new insights into the mechanisms of human thought.<ref name=\"hptsp\">{{citation|title=Human performance on the traveling salesman and related problems: A review|first1=James N.|last1=MacGregor|first2=Yun|last2=Chu|journal=Journal of Problem Solving|volume=3|issue=2|year=2011|url=https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1090&context=jps|doi=10.7771/1932-6246.1090}}.</ref> The first issue of the ''Journal of Problem Solving'' was devoted to the topic of human performance on TSP,<ref>[https://docs.lib.purdue.edu/jps/vol1/iss1/ ''Journal of Problem Solving'' 1(1)], 2006, retrieved 2014-06-06.</ref> and a 2011 review listed dozens of papers on the subject.<ref name=\"hptsp\"/>\n\n==Natural computation==\n\nWhen presented with a spatial configuration of food sources, the [[Amoeba|amoeboid]] [[Physarum polycephalum]] adapts its morphology to create an efficient path between the food sources which can also be viewed as an approximate solution to TSP.<ref>{{citation|title=Computation of the travelling salesman problem by a shrinking blob|first1=Jeff|last1=Jones|first2=Andrew|last2=Adamatzky|journal=Natural Computing|date=2014|pages=2, 13|url=http://www.phychip.eu/wp-content/uploads/2013/03/Computation-of-the-travelling-salesman-problem-by-a-shrinking-blob.pdf}}</ref> It's considered to present interesting possibilities and it has been studied in the area of [[natural computing]].\n\n==Benchmarks==\nFor benchmarking of TSP algorithms, [http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/ '''TSPLIB'''] is a library of sample instances of the TSP and related problems is maintained, see the TSPLIB external reference. Many of them are lists of actual cities and layouts of actual [[Printed circuit board|printed circuits]].\n\n== Popular culture ==\n* ''[[Travelling Salesman (2012 film)|Travelling Salesman]]'', by director Timothy Lanzone, is the story of four mathematicians hired by the U.S. government to solve the most elusive problem in computer-science history: [[P vs. NP]].<ref>{{Cite journal|last=Geere|first=Duncan|title='Travelling Salesman' movie considers the repercussions if P equals NP|journal=Wired UK|url=https://www.wired.co.uk/news/archive/2012-04/26/travelling-salesman|accessdate=26 April 2012|date=2012-04-26}}</ref>\n\n==See also==\n\n* [[Canadian traveller problem]]\n* [[Exact algorithm]]\n* [[Route inspection problem]] (also known as \"Chinese postman problem\")\n* [[Set TSP problem]]\n* [[Seven Bridges of Königsberg]]\n* [[Steiner travelling salesman problem]]\n* [[Subway Challenge]]\n* [[Tube Challenge]]\n* [[Vehicle routing problem]]\n* [[Graph traversal#Graph exploration|Graph exploration]]\n\n==Notes==\n\n{{Reflist|30em}}\n\n==References==\n\n{{refbegin|2}}\n*{{Citation\n| last1 = Applegate\n| first1 = D. L.\n| last2 = Bixby\n| first2 = R. M.\n| last3 = Chvátal\n| first3 = V.\n| last4 = Cook|author4-link=William J. Cook\n| year = 2006\n| title = The Traveling Salesman Problem|first4 =W. J.\n| isbn = 978-0-691-12993-8}}.\n*{{Citation\n| last1 = Allender\n| first1 = Eric\n| last2 = Bürgisser\n| first2 = Peter\n| last3 = Kjeldgaard-Pedersen\n| first3 = Johan\n| last4 = Mitersen\n| first4 = Peter Bro\n| year = 2007\n| title = On the Complexity of Numerical Analysis\n| url = https://www3.math.tu-berlin.de/algebra/work/focs7.pdf\n| journal = [[SIAM J. Comput.]]\n| volume=38\n| issue=5\n| pages = 1987–2006\n| doi=10.1137/070697926\n| citeseerx = 10.1.1.167.5495\n}}.\n*{{Citation\n | last = Arora | first = Sanjeev | author-link = Sanjeev Arora\n | doi = 10.1145/290179.290180\n | issue = 5\n | journal = [[Journal of the ACM]]\n | mr = 1668147\n | pages = 753–782\n | title = Polynomial time approximation schemes for Euclidean traveling salesman and other geometric problems\n | volume = 45\n | year = 1998 }}.\n*{{Citation \n|last1= Beardwood\n|first1=J.\n|last2=Halton \n|first2=J.H. \n|last3=Hammersley\n|first3=J.M.\n|title=The Shortest Path Through Many Points\n|journal= Proceedings of the Cambridge Philosophical Society\n|volume =55\n|issue=4\n|pages= 299–327\n|year= 1959\n|doi=10.1017/s0305004100034095|bibcode=1959PCPS...55..299B\n}}.\n*{{Citation\n|last= Bellman\n|first= R.\n|contribution= Combinatorial Processes and Dynamic Programming\n|title=  Combinatorial Analysis, Proceedings of Symposia in Applied Mathematics 10\n|editor1= Bellman, R. |editor2=Hall, M. Jr. \n|pages= 217–249\n|publisher= American Mathematical Society\n|year=1960 }}.\n*{{Citation\n|last= Bellman\n|first= R.\n|title= Dynamic Programming Treatment of the Travelling Salesman Problem\n|journal= J. Assoc. Comput. Mach. |volume=9|pages= 61–63 |year=1962|doi=10.1145/321105.321111}}.\n*{{citation\n | last1 = Berman | first1 = Piotr\n | last2 = Karpinski | first2 = Marek | author2-link = Marek Karpinski\n | contribution = 8/7-approximation algorithm for (1,2)-TSP\n | doi = 10.1145/1109557.1109627\n | id = {{ECCC|2005|05|069}}\n | pages = 641–648\n | title = Proc. 17th ACM-SIAM Symposium on Discrete Algorithms (SODA '06)\n | year = 2006\n | isbn = 978-0898716054| url = http://eccc.hpi-web.de/report/2005/069/revision/2/download/| citeseerx = 10.1.1.430.2224\n }}.\n*{{Citation\n|last=Christofides|first=N.|year= 1976\n|title=Worst-case analysis of a new heuristic for the travelling salesman problem\n|series=Technical Report 388|publisher=Graduate School of Industrial Administration, Carnegie-Mellon University, Pittsburgh}}.\n*{{Citation|last1=Hassin|first1= R.|last2= Rubinstein|first2= S.|year=2000\n|title=Better approximations for max TSP\n|journal=Information Processing Letters|volume=75|pages=181–186|doi=10.1016/S0020-0190(00)00097-1|issue=4|citeseerx= 10.1.1.35.7209}}.\n*{{Citation\n| last1 = Held\n| first1 = M.\n| author1-link = Michael Held\n| last2 = Karp\n| first2 = R. M.\n| author2-link = Richard Karp\n| year = 1962\n| title = A Dynamic Programming Approach to Sequencing Problems\n| journal = Journal of the Society for Industrial and Applied Mathematics\n| volume = 10\n| issue = 1\n| pages = 196–210\n| doi = 10.1137/0110015}}.\n*{{Citation |last1= Kaplan|first1=H.|last2=Lewenstein |first2=L. | last3=Shafrir|first3=N. |last4= Sviridenko|first4=M.|contribution= Approximation Algorithms for Asymmetric TSP by Decomposing Directed Regular Multigraphs\n|title= In Proc. 44th IEEE Symp. on Foundations of Comput. Sci |pages= 56–65|year= 2004}}.\n*{{Citation\n|last1=Karpinski|first1=M.\n|last2=Lampis|first2=M.\n|last3=Schmied|first3=R.\n|journal=Journal of Computer and System Sciences\n|volume=81\n|issue=8\n|year=2015\n|title=New Inapproximability bounds for TSP\n|pages=1665–1677\n|doi=10.1016/j.jcss.2015.06.003\n|arxiv=1303.6437\n}}\n*{{Citation\n|last1= Kosaraju|first1= S. R.|last2= Park|first2=J. K.\n|last3= Stein|first3= C. |year=1994\n|contribution=Long tours and short superstrings'\n|title=Proc. 35th Ann. IEEE Symp. on Foundations of Comput. Sci\n|publisher= IEEE Computer Society|pages= 166–177}}.\n*{{Citation\n|last1= Orponen|first1= P. | last2=Mannila |first2= H. | author2-link = Heikki Mannila\n|year=1987\n|title=On approximation preserving reductions: Complete problems and robust measures'\n|journal= Technical Report C-1987–28, Department of Computer Science, University of Helsinki}}.\n*{{Citation\n| last1 = Larson\n| first1 = Richard C.\n| last2 = Odoni\n| first2 = Amedeo R.\n| year = 1981\n| title = Urban Operations Research\n| chapterurl = http://web.mit.edu/urban_or_book/www/book/chapter6/6.4.7.html\n| chapter=6.4.7: Applications of Network Models § Routing Problems §§ Euclidean TSP\n| publisher = Prentice-Hall\n| isbn = 9780139394478\n| oclc = 6331426\n}}.\n*{{Citation\n|last1=Padberg|first1=M.|last2=Rinaldi|first2=G.\n|title=A Branch-and-Cut Algorithm for the Resolution of Large-Scale Symmetric Traveling Salesman Problems\n|journal = SIAM Review\n|volume=33|year = 1991\n|pages = 60–100\n|doi = 10.1137/1033004}}.\n*{{citation\n | last = Papadimitriou | first = Christos H. | author-link = Christos Papadimitriou\n | issue = 3\n | journal = Theoretical Computer Science\n | mr = 0455550\n | pages = 237–244\n | title = The Euclidean traveling salesman problem is NP-complete\n | volume = 4\n | year = 1977\n | doi = 10.1016/0304-3975(77)90012-3}}.\n*{{Citation\n|last1=Papadimitriou|first1=C. H.|last2= Yannakakis|first2= M.\n|year=1993\n|title=The traveling salesman problem with distances one and two\n|journal= Math. Oper. Res.|volume= 18|pages= 1–11\n|doi=10.1287/moor.18.1.1}}.\n*{{Citation\n|last=Serdyukov|first= A. I.|year= 1984\n|title=An algorithm with an estimate for the traveling salesman problem of the maximum'\n|journal=Upravlyaemye Sistemy |volume= 25|pages= 80–86}}.\n*{{citation\n | last = Steinerberger | first = Stefan \n | journal = Advances in Applied Probability\n | title = New Bounds for the Traveling Salesman Constant\n | year = 2015\n | volume = 47\n| pages = 27–36 \n | doi = 10.1239/aap/1427814579 \n | arxiv = 1311.6338}}.\n*{{Citation\n| authorlink = Gerhard J. Woeginger |last= Woeginger|first= G.J.|contribution= Exact Algorithms for NP-Hard Problems: A Survey\n|title=Combinatorial Optimization – Eureka, You Shrink! Lecture notes in computer science, vol. 2570\n|pages= 185–207|publisher= Springer |year=2003 }}.\n{{refend}}\n\n==Further reading==\n*{{citation|first=Leonard|last=Adleman|authorlink=Leonard Adleman|url=http://www.usc.edu/dept/molecular-science/papers/fp-sci94.pdf|title=Molecular Computation of Solutions To Combinatorial Problems|year=1994|bibcode=1994Sci...266.1021A|volume=266|pages=1021–4|journal=Science|doi=10.1126/science.7973651|pmid=7973651|issue=5187|deadurl=yes|archiveurl=https://web.archive.org/web/20050206144827/http://www.usc.edu/dept/molecular-science/papers/fp-sci94.pdf|archivedate=6 February 2005|df=dmy-all|citeseerx=10.1.1.54.2565}}\n*{{citation|first=S.|last=Arora|authorlink=Sanjeev Arora|url=http://graphics.stanford.edu/courses/cs468-06-winter/Papers/arora-tsp.pdf|title=Polynomial time approximation schemes for Euclidean traveling salesman and other geometric problems|journal=Journal of the ACM|volume=45|year=1998|pages=753–782|issue=5|doi=10.1145/290179.290180}}\n*{{citation|first1=Gilbert|last1=Babin|first2=Stéphanie|last2=Deneault|first3=Gilbert|last3=Laportey|year=2005|title=Improvements to the Or-opt Heuristic for the Symmetric Traveling Salesman Problem|journal=The Journal of the Operational Research Society|series=Cahiers du GERAD|volume=G-2005-02|issue=3|pages=402–407|publisher=Group for Research in Decision Analysis|location=Montreal|citeseerx=10.1.1.89.9953|jstor=4622707}}\n*{{Cite book|url={{google books |plainurl=y |id=S3bxbr_-qhYC}}|title=In Pursuit of the Traveling Salesman: Mathematics at the Limits of Computation|last=Cook|first=William|date=2012|publisher=Princeton University Press|isbn=9780691152707|authorlink=William J. Cook}}\n*{{citation|first1=William|last1=Cook|author1-link=William J. Cook|first2=Daniel|last2=Espinoza|first3=Marcos|last3=Goycoolea|title=Computing with domino-parity inequalities for the TSP|journal=INFORMS Journal on Computing|volume=19|issue=3|year=2007|pages=356–365|doi=10.1287/ijoc.1060.0204}}\n*{{Cite book|url={{google books |plainurl=y |id=i-bUBQAAQBAJ}}|title=Introduction to Algorithms|last=Cormen|first=Thomas H.|last2=Leiserson|first2=Charles E.|last3=Rivest|first3=Ronald L.|last4=Stein|first4=Clifford|date=2009-07-31|publisher=MIT Press|isbn=9780262033848|author1-link=Thomas H. Cormen|author2-link=Charles E. Leiserson|author3-link=Ronald L. Rivest|author4-link=Clifford Stein|edition=2nd|contribution=35.2: The traveling-salesman problem|pages=1027–1033|title-link=Introduction to Algorithms}}\n*{{citation|first1=G. B.|last1=Dantzig|author1-link=George Dantzig|first2=R.|last2=Fulkerson|first3=S. M.|last3=Johnson|author3-link=Selmer M. Johnson|author2-link=D. R. Fulkerson|title=Solution of a large-scale traveling salesman problem|journal=Operations Research|volume=2|year=1954|pages=393–410|doi=10.1287/opre.2.4.393|jstor=166695|issue=4}}\n*{{Cite book|url={{google books |plainurl=y |id=fjxGAQAAIAAJ}}|title=Computers and Intractability: A Guide to the Theory of NP-completeness|last=Garey|first=Michael R.|last2=Johnson|first2=David S.|date=1979|publisher=W. H. Freeman|isbn=9780716710448|contribution=A2.3: ND22–24|pages=211–212}}\n*{{citation|first=D. E.|last=Goldberg|title=Genetic Algorithms in Search, Optimization & Machine Learning|publisher=Addison-Wesley|location=New York|year=1989|isbn=978-0-201-15767-3|bibcode=1989gaso.book.....G|journal=Reading: Addison-Wesley}}\n*{{Cite journal|date=2002-03-15|title=Traveling salesman should not be greedy: domination analysis of greedy-type heuristics for the TSP|journal=Discrete Applied Mathematics|volume=117|issue=1–3|pages=81–86|doi=10.1016/S0166-218X(01)00195-0|issn=0166-218X|first1=G.|last1=Gutin|first2=A.|last2=Yeo|first3=A.|last3=Zverovich}}\n*{{Cite book|url={{google books |plainurl=y |id=pfRSPwAACAAJ}}|title=The Traveling Salesman Problem and Its Variations|last=Gutin|first=G.|last2=Punnen|first2=A. P.|date=2007-05-18|publisher=Springer US|isbn=9780387444598}}</ref>{{citation|first1 = G.|last1=Gutin|first2=A. P.|last2=Punnen | title = The Traveling Salesman Problem and Its Variations | year = 2006 | publisher = Springer | isbn = 978-0-387-44459-8}}\n*{{citation|first1=D. S.|last1=Johnson|author1-link=David S. Johnson|first2=L. A.|last2=McGeoch|contribution=The Traveling Salesman Problem: A Case Study in Local Optimization|title=Local Search in Combinatorial Optimisation|editor1-first=E. H. L.|editor1-last=Aarts|editor2-first=J. K.|editor2-last=Lenstra|editor2-link=Jan Karel Lenstra|publisher=John Wiley and Sons Ltd.|year=1997|pages=215–310|url=https://www.cs.ubc.ca/~hutter/previous-earg/EmpAlgReadingGroup/TSP-JohMcg97.pdf}}\n*{{Cite book|url={{google books |plainurl=y |id=BXBGAAAAYAAJ}}|title=The Traveling Salesman Problem|last=Lawler|first=E. L.|last2=Shmoys|first2=D. B.|last3=Kan|first3=A. H. G. Rinnooy|last4=Lenstra|first4=J. K.|date=1985|publisher=John Wiley & Sons, Incorporated|isbn=9780471904137}}\n*{{citation|first1=J. N.|last1=MacGregor|first2=T.|last2=Ormerod|year=1996|title=Human performance on the traveling salesman problem|journal=Perception & Psychophysics|volume=58|issue=4|pages=527–539|url=http://www.psych.lancs.ac.uk/people/uploads/TomOrmerod20030716T112601.pdf|doi=10.3758/BF03213088|deadurl=yes|archiveurl=https://web.archive.org/web/20091229053516/http://www.psych.lancs.ac.uk/people/uploads/TomOrmerod20030716T112601.pdf|archivedate=29 December 2009|df=dmy-all}}\n*{{citation|first=J. S. B.|last=Mitchell|authorlink=Joseph S. B. Mitchell|year=1999|url=http://citeseer.ist.psu.edu/622594.html|title=Guillotine subdivisions approximate polygonal subdivisions: A simple polynomial-time approximation scheme for geometric TSP, ''k''-MST, and related problems|journal=SIAM Journal on Computing|volume=28 |pages=1298–1309 |doi=10.1137/S0097539796309764|issue=4}}\n*{{citation|first1=S.|last1=Rao |first2=W. |last2=Smith|contribution=Approximating geometrical graphs via 'spanners' and 'banyans' |title=Proceedings|conference= 30th Annual ACM Symposium on Theory of Computing |year=1998 |pages=540–550|title-link=Symposium on Theory of Computing |citeseerx=10.1.1.51.8676 }}\n*{{Cite journal|publisher=SIAM (Society for Industrial and Applied Mathematics)|first1=Daniel J. |last1=Rosenkrantz |first2=Richard E. |last2=Stearns |first3=Philip M., II |last3= Lewis |title=An Analysis of Several Heuristics for the Traveling Salesman Problem |journal=SIAM Journal on Computing |volume=6 |issue=5 |pages = 563–581 |year=1977 |doi=10.1137/0206041}}\n*{{Cite journal|last=Medvedev|first=Andrei|last2=Lee|first2=Michael|last3=Butavicius|first3=Marcus|last4=Vickers|first4=Douglas|date=2001-02-01|title=Human performance on visually presented Traveling Salesman problems|journal=Psychological Research|volume=65|issue=1|pages=34–45|doi=10.1007/s004260000031|issn=1430-2772|pmid=11505612 }}\n*{{citation |first1=Chris |last1=Walshaw |title=A Multilevel Approach to the Travelling Salesman Problem|publisher=CMS Press |year=2000}}\n*{{citation |url=http://dimacs.rutgers.edu/Challenges/TSP/WalshawTR8001.ps|first1=Chris |last1=Walshaw |title=A Multilevel Lin-Kernighan-Helsgaun Algorithm for the Travelling Salesman Problem |publisher=CMS Press |year=2001}}\n\n==External links==\n{{Commons category|Traveling salesman problem}}\n* {{webarchive |url=https://web.archive.org/web/20131217224319/http://www.math.uwaterloo.ca/tsp/index.html |date=* |title=Traveling Salesman Problem}} at [[University of Waterloo]]\n* [http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/ TSPLIB] at the [[University of Heidelberg]]\n* ''[http://demonstrations.wolfram.com/TravelingSalesmanProblem/ Traveling Salesman Problem]'' by Jon McLoone at the Wolfram Demonstrations Project\n\n{{DEFAULTSORT:Travelling Salesman Problem}}\n[[Category:Travelling salesman problem| ]]\n[[Category:NP-complete problems]]\n[[Category:NP-hard problems]]\n[[Category:Combinatorial optimization]]\n[[Category:Graph algorithms]]\n[[Category:Computational problems in graph theory]]\n[[Category:Hamiltonian paths and cycles]]"
    },
    {
      "title": "2-opt",
      "url": "https://en.wikipedia.org/wiki/2-opt",
      "text": "[[File:2-opt wiki.svg|thumb|2-opt]]\nIn [[Optimization (mathematics)|optimization]], '''2-opt''' is a simple local search algorithm first proposed by Croes in 1958 for solving the [[traveling salesman problem]]. The main idea behind it is to take a route that crosses over itself and reorder it so that it does not.\n\n  - A   B -             - A - B -\n      X         ==>     \n  - C   D -             - C - D -\n\nA complete 2-opt local search will compare every possible valid combination of the swapping mechanism. This technique can be applied to the travelling salesman problem as well as many related problems. These include the [[vehicle routing problem]] (VRP) as well as the capacitated VRP, which require minor modification of the algorithm. \n\nThis is the mechanism by which the 2-opt swap manipulates a given route:\n    2optSwap(route, i, k) {\n        1. take route[0] to route[i-1] and add them in order to new_route\n        2. take route[i] to route[k] and add them in reverse order to new_route\n        3. take route[k+1] to end and add them in order to new_route\n        return new_route;\n    }\n\nHere is an example of the above with arbitrary input:\n\n    example route: A ==> B ==> C ==> D ==> E ==> F ==> G ==> H ==> A\n    example i = 4, example k = 7 (starting index 1)\n    new_route:\n        1. (A ==> B ==> C)\n        2. A ==> B ==> C ==> (G ==> F ==> E ==> D)\n        3. A ==> B ==> C ==> G ==> F ==> E ==> D (==> H ==> A)\n\nThis is the complete 2-opt swap making use of the above mechanism:\n\n    repeat until no improvement is made {\n        start_again:\n        best_distance = calculateTotalDistance(existing_route)\n        for (i = 1; i < number of nodes eligible to be swapped - 1; i++) {\n            for (k = i + 1; k < number of nodes eligible to be swapped; k++) {\n                new_route = 2optSwap(existing_route, i, k)\n                new_distance = calculateTotalDistance(new_route)\n                if (new_distance < best_distance) {\n                    existing_route = new_route\n                    best_distance = new_distance\n                    goto start_again\n                }\n            }\n        }\n    }\n\nNote: If you start/end at a particular node or depot, then you must remove this from the search as an eligible candidate for swapping, as reversing the order will cause an invalid path.\n\nFor example, with depot at A:\n\n    A ==> B ==> C ==> D ==> A\n\nSwapping using node[0] and node[2] would yield \n\n    C ==> B ==> A ==> D ==> A \n\nwhich is not valid (does not leave from A, the depot).\n\t\n==References==\n\n* {{cite book|author = G. A. CROES | year = 1958 | title = A method for solving traveling salesman problems | publisher = Operations Res. 6 (1958) , pp., 791-812.}}\n\n==See also==\n*[[3-opt]]\n*[[local search (optimization)]]\n*[[Lin–Kernighan heuristic]]\n==External links==\n*[https://www.cs.ubc.ca/~hutter/previous-earg/EmpAlgReadingGroup/TSP-JohMcg97.pdf The Traveling Salesman Problem: A Case Study in Local Optimization]\n*[http://www-e.uni-magdeburg.de/mertens/TSP/node3.html Improving Solutions: 2-opt Exchanges]\n\n[[Category:Heuristic algorithms]]\n[[Category:Travelling salesman problem]]"
    },
    {
      "title": "3-opt",
      "url": "https://en.wikipedia.org/wiki/3-opt",
      "text": "{{Expert needed | reason=\"This page is very poor in terms of contents. No pseudo-code, scarce references. This algorithm deserves a lot better description and treatment.\"|date=September 2016}}\n\nIn optimization, '''3-opt''' is a simple local search algorithm for solving the [[travelling salesman problem]] and related [[network optimization]] problems.<ref>{{cite journal|last1=Munim|first1=Ziaul Haque|last2=Haralambides|first2= Hercules |title= Competition and cooperation for intermodal container transhipment: A network optimization approach|journal=Research in Transportation Business & Management|date=2018|pages=87–99|doi= 10.1016/j.rtbm.2018.03.004|url= https://www.sciencedirect.com/science/article/pii/S2210539517301001|volume=26}}</ref>\n\n3-opt analysis involves deleting 3 connections (or edges) in a [[Graph (discrete mathematics)|network]] (or tour), to create 3 sub-tours. Then the 7 different ways of reconnecting the network are analysed to find the optimum one. This process is then repeated for a different set of 3 connections, until all possible combinations have been tried in a network. A single execution of 3-opt has a time complexity of <math>O(n^3)</math>.<ref>{{Cite web|url=https://pdfs.semanticscholar.org/ab7c/c83bb513a91b06f6c8bc3b9da7f60cbbaee5.pdf|title=Combining 2-OPT, 3-OPT and 4-OPT with K-SWAP-KICK perturbations for the traveling salesman problem|last=Blazinskas|first=Andrius|last2=Misevicius|first2=Alfonsas|date=2011|website=|access-date=}}</ref> Iterated 3-opt has a higher time complexity.\n\nThis is the mechanism by which the 3-opt swap manipulates a given route:<syntaxhighlight lang=\"python3\">\ndef reverse_segment_if_better(tour, i, j, k):\n    \"If reversing tour[i:j] would make the tour shorter, then do it.\"\n    # Given tour [...A-B...C-D...E-F...]\n    A, B, C, D, E, F = tour[i-1], tour[i], tour[j-1], tour[j], tour[k-1], tour[k % len(tour)]\n    d0 = distance(A,B) + distance(C,D) + distance(E,F)\n    d1 = distance(A,C) + distance(B,D) + distance(E,F)\n    d2 = distance(A,B) + distance(C,E) + distance(D,F)\n    d3 = distance(A,D) + distance(E,B) + distance(C,F)\n    d4 = distance(F,B) + distance(C,D) + distance(E,A)\n\n    if d0 > d1:\n      tour[i:j] = reversed(tour[i:j])\n      return -d0 + d1\n    elif d0 > d2:\n      tour[j:k] = reversed(tour[j:k])\n      return -d0 + d2\n    elif d0 > d4:\n      tour[i:k] = reversed(tour[i:k])\n      return -d0 + d4\n    elif d0 > d3:\n      tmp = tour[j:k], tour[i:j]\n      tour[i:k] = tmp\n      return -d0 + d3\n    return 0\n\n</syntaxhighlight>The principle is pretty simple. You compute, the original distance <math>d_0</math> and you compute the cost of each modification. If you find a better cost, apply the modification and return <math>\\delta</math> (relative cost).\n\nThis is the complete 3-opt swap making use of the above mechanism:<syntaxhighlight lang=\"python3\">\ndef three_opt(tour):\n    \"Iterative improvement based on 3 exchange.\"\n    while True:\n        delta = 0\n        for (a,b,c) in all_segments(len(tour)):\n            delta += reverse_segment_if_better(tour, a, b, c)\n        if delta >= 0:\n            break\n    return tour\n\ndef all_segments(N):\n    \"Generate all segments combinations\"\n    return ((i, j, k)\n        for i in range(N)\n        for j in range(i+2, N)\n        for k in range(j+2, N+(i>0)))\n\n</syntaxhighlight>For the given tour, you generate all segments combinations and for each combinations, you try to improve the tour by reversing segments. While you find a better result, you restart the process, otherwise finish.\n\n==See also==\n*[[2-opt]]\n*[[local search (optimization)]]\n*[[Lin–Kernighan heuristic]]\n\n==References==\n{{Reflist}}\n* {{cite book|author = F. BOCK | year = 1965 | title = An algorithm for solving traveling-salesman and related network optimization problems | publisher = unpublished manuscript associated with talk presented at the 14th [[ORSA (OR)|ORSA]] National Meeting}}\n* {{cite book|author = S. LIN | year = 1965 | title = Computer solutions of the traveling salesman problem | publisher = Bell Syst. Tech. J. 44, 2245-2269.}} Available as [http://bstj.bell-labs.com/BSTJ/images/Vol44/bstj44-10-2245.pdf PDF]{{Dead link|date=April 2019 |bot=InternetArchiveBot |fix-attempted=yes }}\n* {{cite book|author = S. LIN AND B. W. KERNIGHAN | year = 1973 | title = An Effective Heuristic Algorithm for the Traveling-Salesman Problem | publisher = Operations Res. 21, 498-516.}} Available as [http://www.dti.unimi.it/~righini/Didattica/Algoritmi%20Euristici/MaterialeAE/Lin%20Kernighan%20TSP.pdf PDF]{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}\n* Local Search Heuristics. (n.d.) Retrieved June 16, 2008, from http://www.tmsk.uitm.edu.my/~naimah/csc751/slides/LS.pdf{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}\n\n==External links==\n\n[[Category:Heuristic algorithms]]\n[[Category:Travelling salesman problem]]"
    },
    {
      "title": "Arc routing",
      "url": "https://en.wikipedia.org/wiki/Arc_routing",
      "text": "{{refimprove|date=May 2014}}\n\n'''Arc Routing''' is the process of selecting the best path in a network based on the route. Contrary to normal routing problems, which usually involve mapping a [[routing|route]] between nodes, arc routing focuses more heavily on the route itself. The goal of many arc routing problems is to produce a route with the minimum amount of [[dead mileage]], while also fully encompassing the edges required. Examples of arc routing applications include garbage collection, road gritting, mail delivery, network maintenance, and [[snowplough]]ing.\n\n==Problem types==\nArc routing problems (ARPs) differ in their goal and heuristics. However, all of them are known to be [[NP-hard]].\n\n===Undirected rural postman problem===\nThis problem is named after the postman and his challenge to deliver mail in any order he may choose, but minimizing his costs such as time or travel distance. It is also sometimes called the ''undirected chinese postman problem''. The undirected rural postman problem (URPP) aims to minimize the total cost of a route that maps the entire network, or in more specific cases, a route that maps every edge that requires a service. If the whole network must be mapped, the route that maps the entire network is called a ''covering tour''. In the case where only certain edges need to be mapped, the problem aims to solve the route that optimizes the demands, crossing over into non-required routes a minimal number of times.\n<ref>{{cite journal |last1=H. A. |first1=Eiselt |last2=Michel |first2=Gendreau  |date=1995 |title=Arc Routing Problems, Part II: The Rural Postman Problem |url=https://doi.org/10.1287/opre.43.3.399 |journal=Operations Research |volume=43 |issue=3 |pages=399–414 |doi = 10.1287/opre.43.3.399 |access-date=2017-10-20 }}</ref>\n\n===Undirected capacitated arc routing problem===\nThe undirected capacitated arc routing problem consists of demands placed on the edges, and each edge must meet the demand. An example is garbage collection, where each route might require both a garbage collection and a recyclable collection. Problems in real life applications might arise if there are timing issues, such as the case in which certain routes cannot be serviced due to timing or scheduling conflicts, or constraints, such as a limited period of time. The heuristics described in this article ignore any such problems that arise due to application constraints.\n<ref>{{cite journal |last1=H. A. |first1=Eiselt |last2=Michel |first2=Gendreau  |date=1995 |title=Arc Routing Problems, Part II: The Rural Postman Problem |url=https://doi.org/10.1287/opre.43.3.399 |journal=Operations Research |volume=43 |issue=3 |pages=399–414 |doi = 10.1287/opre.43.3.399 |access-date=2017-10-20 }}</ref>\n\n==History==\nThe URPP was first introduced in 1974 and was proven to be an NP-hard problem by [[Jan Karel Lenstra|Lenstra]] and [[Alexander Rinnooy Kan|Kan]]. The UCARP can be derived from the URPP, and thus is NP-hard as well. In 1981, another pair of computer scientists, Golden and Wong, managed to prove that even deriving a .5 approximation to the URPP was NP-hard. In 2000, Dror published a book describing different arc routing problems.\n\n==Heuristics and algorithms==\nMost algorithms require a pre-processing of the graph, which simplifies the initial graph by removing all edges that are not in the shortest path between 2 required edges. Another simplification that the pre-processing adds is that it transforms the shortest path between 2 required edges into a single, non-required edge, regardless of the number of edges in the path, provided that there were no required edges in the path.\n\nOnce the pre-processing is done, the problem can be generalized into a [[convex hull]] problem, with the edges being the points of the hull. The convex hull problem can be solved through linear programming or through convex hull algorithms, but the process of finding the convex hull is an exponential problem.\n\nMethods of solving the URPP after the pre-processing is done consist of the [[Integer programming|''cutting plane algorithm'']] and the [[Branch and cut|''branch & cut methodology'']].\n<ref>http://www.gerad.ca/~alainh/Trends.pdf</ref>\n\n==External links==\n* [http://www.lancaster.ac.uk/lums/search/?q=arc+routing+problems Arc Routing Problems Search page at Lancaster University]\n* [http://www.gerad.ca/~alainh/Trends.pdf Trends in Arc Routing]\n\n==Notes==\n\n==Reference==\n{{reflist}}\n[[Category:Routing algorithms]]\n[[Category:Travelling salesman problem]]"
    },
    {
      "title": "Canadian traveller problem",
      "url": "https://en.wikipedia.org/wiki/Canadian_traveller_problem",
      "text": "In [[computer science]] and [[graph theory]], the '''Canadian traveller problem''' ('''CTP''') is a generalization of the [[shortest path problem]] to graphs that are ''partially observable''. In other words, the graph is revealed while it is being explored, and explorative edges are charged even if they do not contribute to the final path.\n\nThis [[optimization problem]] was introduced by  [[Christos Papadimitriou]] and [[Mihalis Yannakakis]] in 1989 and a number of variants of the problem have been studied since. The name supposedly originates from conversations of the authors who learned of the difficulty [[Canadian]] drivers had - traveling a network of cities with snowfall randomly blocking roads. The stochastic version, where each edge is associated with a probability of independently being in the graph, has been given considerable attention in [[operations research]] under the name \"the Stochastic Shortest Path Problem with Recourse\" (SSPPR).\n\n== Problem description ==\n\n{{expand section|date=February 2017}}\n\nFor a given instance, there are a number of possibilities, or ''realizations'', of how the hidden graph may look. Given an instance, a description of how to follow the instance in the best way is called a ''policy''. The CTP task is to compute the expected cost of the optimal policies. To compute an actual description of an optimal policy may be a harder problem.\n\nGiven an instance and policy for the instance, every realization produces its own (deterministic) walk in the graph. Note that the walk is not necessarily a [[glossary of graph theory|path]] since the best strategy may be to, e.g., visit every vertex of a cycle and return to the start. This differs from the [[shortest path problem]] (with strictly positive weights), where repetitions in a walk implies that a better solution exists.\n\n== Variants ==\nThere are primarily five parameters distinguishing the number of variants of the Canadian Traveller Problem. The first parameter is how to value the walk produced by a policy for a given instance and realization. In the Stochastic Shortest Path Problem with Recourse, the goal is simply to minimize the cost of the walk (defined as the sum over all edges of the cost of the edge times the number of times that edge was taken). For the Canadian Traveller Problem, the task is to minimize the [[competitive ratio]] of the walk; i.e., to minimize the number of times longer the produced walk is to the shortest path in the realization.\n\nThe second parameter is how to evaluate a policy with respect to different realizations consistent with the instance under consideration. In the Canadian Traveller Problem, one wishes to study the [[worst case]] and in SSPPR, the [[average case]]. For average case analysis, one must furthermore specify an [[a priori and a posteriori|a priori]] distribution over the realizations.\n\nThe third parameter is restricted to the stochastic versions and is about what assumptions we can make about the distribution of the realizations and how the distribution is represented in the input. In the Stochastic Canadian Traveller Problem and in the Edge-independent Stochastic Shortest Path Problem (i-SSPPR), each uncertain edge (or cost) has an associated probability of being in the realization and the event that an edge is in the graph is independent of which other edges are in the realization. Even though this is a considerable simplification, the problem is still [[sharp P|#P]]-hard. Another variant is to make no assumption on the distribution but require that each realization with non-zero probability be explicitly stated (such as “Probability 0.1 of edge set { {3,4},{1,2} }, probability 0.2 of...”). This is called the Distribution Stochastic Shortest Path Problem (d-SSPPR or R-SSPPR) and is NP-complete. The first variant is harder than the second because the former can represent in logarithmic space some distributions that the latter represents in linear space.\n\nThe fourth and final parameter is how the graph changes over time. In CTP and SSPPR, the realization is fixed but not known. In the Stochastic Shortest Path Problem with Recourse and Resets or the Expected Shortest Path problem, a new realization is chosen from the distribution after each step taken by the policy. This problem can be solved in polynomial time by reducing it to a Markov decision process with polynomial horizon. The Markov generalization, where the realization of the graph may influence the next realization, is known to be much harder.\n\nAn additional parameter is how new knowledge is being discovered on the realization. In traditional variants of CTP, the agent uncovers the exact weight (or status) of an edge upon reaching an adjacent vertex. A new variant was recently suggested where an agent also has the ability to perform remote sensing from any location on the realization. In this variant, the task is to minimize the travel cost plus the cost of sensing operations.\n\n==Formal definition==\nWe define the variant studied in the paper from 1989. That is, the goal is to minimize the competitive ratio in the worst case. It is necessary that we begin by introducing certain terms.\n\nConsider a given graph and the family of undirected graphs that can be constructed by adding one or more edges from a given set. Formally, let <math>\\mathcal{G}(V,E,F) = \\{(V,E+F') | F' \\subseteq F\\}, E \\cap F = \\emptyset</math> where we think of ''E'' as the edges that must be in the graph and of ''F'' as the edges that may be in the graph. We say that <math>G \\in \\mathcal{G}(V,E,F)</math> is a ''realization'' of the graph family. Furthermore, let W be an associated cost matrix where <math>w_{ij}</math> is the cost of going from vertex ''i'' to vertex ''j'', assuming that this edge is in the realization.\n\nFor any vertex ''v'' in ''V'', we call <math>E_B(v,V)</math> its incident edges with respect to the edge set ''B'' on ''V''. Furthermore, for a realization <math>G \\in \\mathcal{G}(V,E,F)</math>, let <math>d_B(s,t)</math> be the cost of the shortest path in the graph from ''s'' to ''t''. This is called the off-line problem because an algorithm for such a problem would have complete information of the graph.\n\nWe say that a strategy <math>\\pi</math> to navigate such a graph is a mapping from <math>(\\mathcal{P}(E),\\mathcal{P}(F),V)</math> to <math>V</math>, where <math>\\mathcal{P}(X)</math> denotes the [[powerset]] of ''X''. We define the cost <math>c(\\pi, B)</math> of a strategy <math>\\pi</math> with respect to a particular realization <math>G = (V,B)</math> as follows.\n* Let <math>v_0 = s, E_0 = E</math> and <math>F_0 = F</math>.\n* For <math>i = 0, 1, 2, ...</math>, define\n** <math>E_{i+1} = E_i \\cup E_B(v_i,V)</math>,\n** <math>F_{i+1} = F_i - E_F(v_i,V)</math>, and\n** <math>v_{i+1} = \\pi(E_{i+1}, F_{i+1}, v_i)</math>.\n* If there exists a ''T'' such that <math>v_T = t</math>, then <math>c(\\pi, B) = \\sum_{i=0}^{T-1} w_{v_i,v_{i+1}}</math>; otherwise let <math>c(\\pi, B) = \\infty</math>.\n\nIn other words, we evaluate the policy based on the edges we currently know are in the graph (<math>E_i</math>) and the edges we know might be in the graph (<math>F_i</math>). When we take a step in the graph, the edges incident to our new location become known to us. Those edges that are in the graph are added to <math>E_i</math>, and regardless of whether the edges are in the graph or not, they are removed from the set of unknown edges, <math>F_i</math>. If the goal is never reached, we say that we have an infinite cost. If the goal is reached, we define the cost of the walk as the sum of the costs of all of the edges traversed, with cardinality.\n\nFinally, we define the Canadian traveller problem.\n: Given a CTP instance <math>(V,E,F,s,t,r)</math>, decide whether there exists a policy <math>\\pi</math> such that for every realization <math>(V,B) \\in \\mathcal{G}(V,E,F)</math>, the cost <math>c(\\pi, B)</math> of the policy is no more than ''r'' times the off-line optimal, <math>d_B(s, t)</math>.\n\nPapadimitriou and Yannakakis noted that this defines a [[game theory|two-player game]], where the players compete over the cost of their respective paths and the edge set is chosen by the second player (nature).\n\n==Complexity==\nThe original paper analysed the complexity of the problem and reported it to be [[PSPACE-complete]]. It was also shown that finding an optimal path in the case where each edge has an associated probability of being in the graph (i-SSPPR) is a PSPACE-easy but [[sharp-P|♯P]]-hard problem.<ref>Papadimitriou and Yannakakis, 1989, p. 148</ref> It was an open problem to bridge this gap, but since then both the directed and undirected versions were shown to be PSPACE-hard.<ref>Fried, Shimony, Benbassat, and Wenner 2013</ref>\n\nThe directed version of the stochastic problem is known in [[operations research]] as the Stochastic Shortest Path Problem with Recourse.\n\n==Applications==\nThe problem is said to have applications in [[operations research]], transportation planning, [[artificial intelligence]], [[machine learning]], communication networks, and routing. A variant of the problem has been studied for robot navigation with probabilistic landmark recognition.<ref name=briggs04>{{cite journal |first1=Amy J. |last1=Briggs |first2=Carrick |last2=Detweiler |first3=Daniel |last3=Scharstein |title=Expected shortest paths for landmark-based robot navigation |journal=\"International Journal of Robotics Research\" |year=2004 |volume=23 |pages=717–718 |doi=10.1177/0278364904045467 |issue=7–8|citeseerx=10.1.1.648.3358 }}</ref>\n\n==Open problems==\nDespite the age of the problem and its many potential applications, many natural questions still remain open. Is there a constant-factor approximation or is the problem [[APX]]-hard? Is i-SSPPR #P-complete? An even more fundamental question has been left unanswered: is there a polynomial-size ''description'' of an optimal policy, setting aside for a moment the time necessary to compute the description?<ref>Karger and Nikolova, 2008, p. 1</ref>\n\n==See also==\n* [[Graph traversal]]\n* [[Hitting time]]\n* [[Shortest path problem]]\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{cite conference |author=C.H. Papadimitriou |author2=M. Yannakakis |title=Shortest paths without a map |conference=Proc. 16th ICALP |booktitle=Lecture Notes in Computer Science |volume=372 |publisher=[[Springer-Verlag]] |year=1989 |pages=610–620}}\n* {{cite paper |author=Dror Fried |author2=Solomon Eyal Shimony |author3=Amit Benbassat |author4=Cenny Wenner |title=Complexity of Canadian traveler problem variants |year=2013 |journal=Theoretical Computer Science |volume=487 |pages=1–16|doi=10.1016/j.tcs.2013.03.016 }}\n* {{cite paper |author=David Karger |author2=Evdokia Nikolova |title=Exact Algorithms for the Canadian Traveller Problem on Paths and Trees |year=2008}}\n* {{cite paper |author=Zahy Bnaya |author2=Ariel Felner |author3=Solomon Eyal Shimony |title=Canadian Traveller Problem with remote sensing |conference=International Joint Conference On Artificial Intelligence (IJCAI) |year=2009}}\n\n[[Category:PSPACE-complete problems]]\n[[Category:Travelling salesman problem]]\n[[Category:Computational problems in graph theory]]"
    },
    {
      "title": "Concorde TSP Solver",
      "url": "https://en.wikipedia.org/wiki/Concorde_TSP_Solver",
      "text": "The '''Concorde TSP Solver''' is a program for solving the [[travelling salesman problem]]. It was written by [[David Applegate]], [[Robert E. Bixby]], [[Vašek Chvátal]], and [[William J. Cook]], in [[ANSI C]], and is freely available for academic use.\n\nConcorde has been applied to problems of [[gene mapping]],<ref>{{harvtxt|Hitte|Lorentzen|Guyon|Kim|2003}}.</ref> [[protein function prediction]],<ref>{{harvtxt|Johnson|Liu|2006}}.</ref> [[Vehicle routing problem|vehicle routing]],<ref>{{harvtxt|Applegate|Cook|Dash|Rohe|2002}}.</ref> conversion of bitmap images to continuous line drawings,<ref>{{harvtxt|Bosch|Herman|2004}}.</ref> scheduling ship movements for seismic surveys,<ref>{{harvtxt|Gutin|Jakubowicz|Ronen|Zverovitch|2005}}</ref> and in studying the scaling properties of combinatorial optimization problems.<ref>{{harvtxt|Aldous|Percus|2003}}.</ref>\n\nAccording to {{harvtxt|Mulder|Wunsch|2003}}, Concorde “is widely regarded as the fastest TSP solver, for large instances, currently in existence.” In 2001, Concorde won a 5000 [[Dutch guilder|guilder]] prize from [[CMG (company)|CMG]] for solving a vehicle routing problem the company had posed in 1996.<ref>[http://www.tsp.gatech.edu/apps/whizzkids.html Whizzkids '96 vehicle routing], from the Concorde web site, retrieved August 26, 2008.</ref>\n\n==Notes==\n{{Reflist}}\n\n==References==\n{{refbegin|2}}\n*{{citation\n | last1 = Aldous | first1 = David\n | last2 = Percus | first2 = Allon G.\n | doi = 10.1073/pnas.1635191100\n | issue = 20\n | journal = Proc. Natl. Acad. Sci. USA\n | pages = 11211–11215\n | title = Scaling and universality in continuous length combinatorial optimization\n | volume = 100\n | year = 2003\n | pmid = 14504403\n | pmc = 208736| bibcode = 2003PNAS..10011211A\n | arxiv = cond-mat/0301035}}.\n*{{citation\n | last1 = Applegate | first1 = David\n | last2 = Cook | first2 = William\n | last3 = Dash | first3 = Sanjeeb\n | last4 = Rohe | first4 = André\n | doi = 10.1287/ijoc.14.2.132.118\n | issue = 2\n | journal = INFORMS Journal on Computing\n | pages = 132–143\n | title = Solution of a min-max vehicle routing problem\n | volume = 14\n | year = 2002}}.\n*{{citation\n | last1 = Bosch | first1 = Robert\n | last2 = Herman | first2 = Adrianne\n | doi = 10.1016/j.orl.2003.10.001\n | issue = 4\n | journal = Operations Research Letters\n | pages = 302–303\n | title = Continuous line drawings via the traveling salesman problem\n | url = http://www.oberlin.edu/math/faculty/bosch/cld.pdf\n | volume = 32\n | year = 2004}}.\n*{{citation\n | last1 = Gutin | first1 = Gregory\n | last2 = Jakubowicz | first2 = Helmut\n | last3 = Ronen | first3 = Shuki\n | last4 = Zverovitch | first4 = Alexei\n | journal = Communications in DQM\n | pages = 13–20\n | title = Seismic vessel problem\n | url = http://www.cs.rhul.ac.uk/home/gutin/paperstsp/svp5.pdf\n | volume = 8\n | year = 2005}}.\n*{{citation\n | last1 = Hitte | first1 = C.\n | last2 = Lorentzen | first2 = T. D.\n | last3 = Guyon | first3 = R.\n | last4 = Kim | first4 = L.\n | last5 = Cadieu | first5 = E.\n | last6 = Parker | first6 = H. G.\n | last7 = Quignon | first7 = P.\n | last8 = Lowe | first8 = J. K.\n | last9 = Gelfenbeyn | first9 = B.\n | last10 = Andre\n | first10 = C\n | last11 = Ostrander\n | first11 = E. A.\n | last12 = Galibert\n | first12 = F\n | doi = 10.1093/jhered/esg012\n | issue = 1\n | journal = Journal of Heredity\n | pages = 9–13\n | title = Comparison of MultiMap and TSP/CONCORDE for constructing radiation hybrid maps\n | volume = 94\n | year = 2003\n | pmid = 12692156| display-authors = 8\n }}.\n*{{citation\n | last1 = Johnson | first1 = Olin\n | last2 = Liu | first2 = Jing\n | doi = 10.1186/1751-0473-1-3\n | journal = Source Code for Biology and Medicine\n | page = 3\n | title = A traveling salesman approach for predicting protein functions\n | volume = 1\n | year = 2006\n | pmid = 17147783\n | pmc = 1636333}}.\n*{{citation\n | last1 = Mulder | first1 = Samuel A.\n | last2 = Wunsch | first2 = Donald C., II\n | doi = 10.1016/S0893-6080(03)00130-8\n | issue = 5–6\n | journal = Neural Networks\n | pages = 827–832\n | title = Million city traveling salesman problem solution by divide and conquer clustering with adaptive resonance neural networks\n | volume = 16\n | year = 2003\n | pmid = 12850040}}.\n{{refend}}\n\n==External links==\n*[http://www.math.uwaterloo.ca/tsp/concorde/ Concorde website]\n*[https://neos-server.org/neos/solvers/co:concorde/TSP.html Online access to Concorde solver] at [[Arizona State University]]\n\n[[Category:Travelling salesman problem]]\n[[Category:Mathematical optimization software]]"
    },
    {
      "title": "Lin–Kernighan heuristic",
      "url": "https://en.wikipedia.org/wiki/Lin%E2%80%93Kernighan_heuristic",
      "text": "{{about|the heuristic for the travelling salesman problem|a heuristic algorithm for the graph partitioning problem|Kernighan–Lin algorithm}}\nIn [[combinatorial optimization]], '''Lin–Kernighan''' is one of the best [[heuristic algorithm|heuristic]]s for solving the symmetric [[travelling salesman problem]]. Briefly, it involves swapping pairs of sub-tours to make a new tour. It is a generalization of [[2-opt]] and [[3-opt]]. 2-opt and 3-opt work by switching two or three edges to make the tour shorter. Lin–Kernighan is adaptive and at each step decides how many paths between cities need to be switched to find a shorter tour.\n\n==See also==\n*[[Local search (optimization)]]\n\n==References==\n* {{cite journal|doi=10.1287/opre.21.2.498|first1=Shen|last1=Lin|authorlink1=Shen Lin|first2=B. W.|last2=Kernighan|authorlink2=Brian Kernighan| year = 1973 | title = An Effective Heuristic Algorithm for the Traveling-Salesman Problem | journal = Operations Research | volume = 21|issue=2 | pages = 498–516}}\n* {{cite journal|doi = 10.1016/S0377-2217(99)00284-2|author = K. Helsgaun |title= An Effective Implementation of the Lin-Kernighan Traveling Salesman Heuristic |journal=European Journal of Operational Research |volume= 126 |issue= 1 |year=2000 |pages=106–130 |citeseerx = 10.1.1.180.1798 }}\n* {{cite book|chapter-url=http://www.research.att.com/~dsj/papers/TSPchapter.pdf|chapter=The Traveling Salesman Problem: A Case Study in Local Optimization|first1=David S.|last1=Johnson|first2=Lyle A.|last2=McGeoch|title=Local Search in Combinatorial Optimization|editors=E. H. L. Aarts and [[Jan Karel Lenstra|J. K. Lenstra]]|publisher=John Wiley and Sons|location=London|year=1997|pages=215–310}}\n\n==External links==\n* [http://akira.ruc.dk/~keld/research/LKH-3/ LKH implementation]\n* [http://www.math.uwaterloo.ca/tsp/concorde.html Concorde TSP implementation]\n\n{{DEFAULTSORT:Lin-Kernighan heuristic}}\n[[Category:Combinatorial optimization]]\n[[Category:Combinatorial algorithms]]\n[[Category:Heuristic algorithms]]\n[[Category:Travelling salesman problem]]\n\n\n{{algorithm-stub}}\n{{mathapplied-stub}}"
    },
    {
      "title": "Set TSP problem",
      "url": "https://en.wikipedia.org/wiki/Set_TSP_problem",
      "text": "In [[combinatorial optimization]], the '''set TSP''', also known as the '''generalized TSP''', '''group TSP''', '''One-of-a-Set TSP''', '''Multiple Choice TSP''' or '''Covering Salesman Problem''', is a generalization of the [[Traveling salesman problem]] (TSP), whereby it is required to find a shortest tour in a graph which visits all specified subsets of the vertices of a graph. The subsets of vertices must be disjoint. The ordinary TSP is a special case of the set TSP when all subsets to be visited are [[singleton (mathematics)|singleton]]s. Therefore, the set TSP is also [[NP-hard]].\n\nThere is a direct transformation for an instance of the set TSP to an instance of the standard asymmetric TSP.<ref name=\"Noon\">{{cite journal|author=Charles Noon, James Bean|title=An efficient transformation of the generalized traveling salesman problem|year=1993|url=https://www.researchgate.net/publication/265366022}}</ref>  The idea is to first create disjoint sets and then assign a directed cycle to each set.  The salesman, when visiting a vertex in some set, then walks around the cycle for free.  To not use the cycle would ultimately be very costly.\n\nThe Set TSP has a lot of interesting applications in several path planning problems. For example, a two vehicle cooperative routing problem could be transformed into a set TSP,<ref>{{cite journal|author=Satyanarayana G. Manyam, Sivakumar Rathinam, Swaroop Darbha, David Casbeer, Yongcan Cao, Phil Chandler|title=GPS Denied UAV Routing with Communication Constraints|journal=Journal of Intelligent & Robotic Systems|volume=84|pages=691–703|year=2016|doi=10.1007/s10846-016-0343-2}}</ref> tight lower bounds to the Dubins TSP and generalized Dubins path problem could be computed by solving a Set TSP,.<ref>{{cite journal|author=Satyanarayana G. Manyam, Sivakumar Rathinam|title=On Tightly Bounding the Dubins Traveling Salesman's Optimum|journal=Journal of Dynamic Systems, Measurement, and Control|volume=140|issue=7|pages=071013|year=2016|arxiv=1506.08752|doi=10.1115/1.4039099}}</ref><ref>{{cite journal|author=Satyanarayana G. Manyam, Sivakumar Rathinam, David Casbeer, Eloy Garcia|title=Tightly Bounding the Shortest Dubins Paths Through a Sequence of Points|year=2017|journal=Journal of Intelligent & Robotic Systems|volume=88|issue=2–4|pages=495–511|doi=10.1007/s10846-016-0459-4}}</ref>\n\n==Illustration from the cutting stock problem==\nThe one-dimensional [[cutting stock problem]] as applied in the paper / plastic film industries, involves cutting jumbo rolls into smaller ones. This is done by generating cutting patterns typically to minimise waste. Once such a solution has been produced, one may seek to minimise the knife changes, by re-sequencing the patterns (up and down in the figure), or moving rolls left or right within each pattern. These moves do not affect the waste of the solution.\n\n[[file:generalised TSP knife changes.png|500 px|border]]\n\nIn the above figure, patterns (width no more than 198) are rows; knife changes are indicated by the small white circles; for example, patterns 2-3-4 have a roll of size 42.5 on the left - the corresponding knife does not have to move. Each pattern represents a TSP set, one of whose permutations must be visited. For instance, for the last pattern, which contains two repeated sizes (twice each), there are 5! / (2! &times; 2!) = 30 permutations. The number of possible solutions to the above instance is 12! &times; (5!)<sup>6</sup> &times; (6!)<sup>4</sup> &times; (7!)<sup>2</sup> / ((2!)<sup>9</sup> &times; (3!)<sup>2</sup>) ≈ 5.3 &times; 10<sup>35</sup>. The above solution contains 39 knife changes, and has been obtained by a heuristic; it is not known whether this is optimal. Transformations into the regular TSP, as described in <ref name=\"Noon\" /> would involve a TSP with 5,520 nodes.\n\n==See also==\n*[[Fagnano's problem]] of finding the shortest tour that visits all three sides of a triangle\n\n==References==\n{{reflist}}\n\n[[Category:Travelling salesman problem]]\n[[Category:NP-complete problems]]\n[[Category:Computational problems in graph theory]]"
    },
    {
      "title": "Traveling purchaser problem",
      "url": "https://en.wikipedia.org/wiki/Traveling_purchaser_problem",
      "text": "The '''traveling purchaser problem''' ('''TPP''') is an [[NP-hard]] problem studied in [[theoretical computer science]]. Given a list of marketplaces, the cost of travelling between different marketplaces, and a list of available goods together with the price of each such good at each marketplace, the task is to find, for a given list of articles, the route with the minimum combined cost of purchases and traveling. The [[traveling salesman problem]] (TSP) is a [[special case]] of this problem.\n\n== Relation to traveling salesman problem (TSP) ==\nThe problem can be seen as a generalization of the traveling salesman problem, i.e. each article is available at one market only and each market sells only one item. Since TSP is NP-hard, TPP is NP-hard.<ref>[http://www.fsa.ulaval.ca/personnel/renaudj/pdf/Recherche/tpp(purchaser)%20COR.pdf Heuristics for the traveling purchaser problem]</ref>\n\n== Solving TPP ==\nApproaches for solving the traveling purchaser problem include [[dynamic programming]]<ref>[http://www.di.unipi.it/optimize/Events/proceedings/T/C/4/TC4-1.pdf A Dynamic Programming Approach for a Travelling Purchaser Problem With Additional Constraints]</ref> and [[tabu search]] algorithms.<ref>[http://infos2008.fci.cu.edu.eg/infos/DSS_04_P024-030.pdf A Tabu Search Approach for solving the Travelling Purchase Problem]</ref>\n\n==See also==\n* [[Vehicle routing problem]]\n\n== References ==\n<references />\n\n[[Category:NP-complete problems]]\n[[Category:Travelling salesman problem]]"
    },
    {
      "title": "Variable neighborhood search",
      "url": "https://en.wikipedia.org/wiki/Variable_neighborhood_search",
      "text": "'''Variable neighborhood search''' (VNS),<ref>{{cite journal |pages=367–407 |last1 = Hansen  |first1 = P.|last2 = Mladenovic|first2 = N.|last3 = Perez|first3 = J.A.M.|title=Variable neighbourhood search: methods and applications\n|volume=175 |journal= Annals of Operations Research |year=2010 |doi=10.1007/s10479-009-0657-6}}</ref> proposed by [[Mladenović, Hansen]], 1997,<ref name=\".....\">{{cite journal\n | author = Nenad Mladenovi´c, Pierre Hansen\n | year = 1997\n | title = Variable neighborhood search\n | journal = Computers and Operations Research\n | volume = 24\n | issue= 11\n | pages = 1097–1100\n | doi=10.1016/s0305-0548(97)00031-2\n }}\n</ref> is a [[metaheuristic]] method for solving a set of [[combinatorial optimization (mathematics)|combinatorial optimization]] and global optimization problems.\nIt explores distant neighborhoods of the current incumbent solution, and moves from there to a new one if and only if an improvement was made. The local search method is applied repeatedly to get from solutions in the neighborhood to local optima.\nVNS was designed for approximating solutions of discrete and continuous optimization problems and according to these, it is aimed for solving [[linear programming|linear program]] problems, [[linear programming|integer program]] problems, mixed integer program problems, [[nonlinear programming|nonlinear program]] problems, etc.\n\n== Introduction ==\nVNS systematically changes the neighborhood in two phases: firstly, descent to find a [[local optimum]] and finally, a perturbation phase to get out of the corresponding valley.\n\nApplications are rapidly increasing in number and pertain to many fields: [[location theory]], [[cluster analysis]], [[scheduling]], [[Vehicle routing problem|vehicle routing]], [[Network planning and design|network design]], lot-sizing, [[artificial intelligence]], engineering, pooling problems, biology, [[Phylogenetics|phylogeny]], [[wikt:reliability|reliability]], geometry, telecommunication design, etc.\n\nThere are several books important for understanding VNS, such as: ''Handbook of Metaheuristics'', 2010,<ref name=\"HoM2010\">{{cite journal |last1=Gendreau|  first1=M.|last2= Potvin|first2=J-Y.|title=Handbook of Metaheuristics|publisher =Springer|year=2010 }}</ref> Handbook of Metaheuristics, 2003<ref>{{cite journal|last1=Glover|  first1=F.|last2= Kochenberger|first2=G.A.|title=Handbook of Metaheuristics|publisher = Kluwer Academic Publishers |year=2003}}</ref> and Search methodologies, 2005.<ref>{{cite journal |last1=Burke|first1=EK.|last2= Kendall | first2=G.| title=Search methodologies. Introductory tutorials in optimization and decision support techniques |journal = Springer|year=2005}}</ref>\nEarlier work that motivated this approach can be found in\n# Davidson, W.C.<ref>{{cite journal |last1=Davidson  |first1=W.C.|title=Variable metric algorithm for minimization  |journal= Argonne National Laboratory Report ANL-5990 |year=1959 }}</ref>\n# Fletcher, R., Powell, M.J.D.<ref>{{cite journal |pages=163–168 |last1=Fletcher |first1=R. |last2=Powell |first2=M.J.D. |title=Rapidly convergent descent method for minimization|volume=6 |issue=2 |journal=Comput. J. |year=1963 |doi=10.1093/comjnl/6.2.163}}</ref>\n# Mladenović, N.<ref>{{cite journal |pages= 112 |last1=Mladenović |first1=N. |title=A variable neighborhood algorithm—a new metaheuristic for combinatorial optimization | journal=Abstracts of Papers Presented at Optimization Days, Montréal |year=1995 }}\n</ref> and\n# Brimberg, J., Mladenović, N.<ref>{{cite journal |pages=1–12 |last1=Brimberg |first1=J. |last2 = Mladenović |first2=N. |title=A variable neighborhood algorithm for solving the continuous location-allocation problem |volume=10 |journal=Stud. Locat. Anal. |year=1996}}</ref> \nRecent surveys on VNS  methodology as well as numerous applications can be found in 4OR, 2008<ref>{{cite journal |pages=319–360 |last1=Hansen |first1=P. |last2 = Mladenović |first2=N. |last3= Perez| first3=J.A.M|title=Variable neighbourhood search: methods and applications|volume=6 |issue=4 |journal=4OR |year=2008 |doi=10.1007/s10288-008-0089-1}}</ref> and Annals of OR, 2010.\n\n== Definition of the problem ==\nDefine one deterministic [[optimization problem]] with\n\n<math> \\min {\\{f (x)|x \\in X, X \\subseteq S\\}} </math>, (1)\n\nwhere ''S'', ''X'', ''x'', and ''f''  are the solution space, the feasible set, a feasible solution, and a real-valued [[mathematical optimization|objective function]], respectively. If ''S'' is a finite but large set, a combinatorial optimization problem is defined. If <math>{S = R^{n}}</math>, there is continuous optimization model.\n\nA solution <math>{x^* \\in X}</math> is optimal if\n\n<math> {f (x^{*}) \\leq f (x), \\qquad \\forall{x}\\, \\in X} </math>.\n\nExact algorithm for problem (1) is to be found an optimal solution ''x*'', with the validation of its optimal structure, or if it is unrealizable, in procedure have to be shown that there is no  achievable solution, i.e., <math>X =\\varnothing</math>, or the solution is unbounded. CPU time has to be finite and short. For continuous optimization, it is reasonable to allow for some degree of tolerance, i.e., to stop when a feasible solution <math>x^{*}</math> has been found such that\n\n<math> {f (x^{*}) \\leq f (x) + \\epsilon, \\qquad \\forall{x}\\, \\in X} </math> or\n<math> {(f (x^{*})- f (x))/ f (x^{*})  <  \\epsilon  , \\qquad \\forall{x}\\, \\in X} </math>\n\nSome heuristics speedily accept an approximate solution, or optimal solution but one with no validation of its optimality.\nSome of them have an incorrect certificate, i.e., the solution <math>x_h</math> obtained satisfies\n\n<math> {(f (x_{h})- f (x))/ f (x_{h})  \\leq  \\epsilon  , \\qquad \\forall{x}\\, \\in X} </math>\nfor some <math>\\epsilon</math>, though this is rarely small.\n\nHeuristics are faced with the problem of local optima as a result of avoiding boundless computing time.\nA local optimum <math>x_L</math> of problem is such that\n\n<math> {f (x_{L}) \\leq f (x), \\qquad \\forall{x}\\, \\in N(x_{L}) \\cap X} </math>\n\nwhere <math> N(x_{L})</math>  denotes a neighborhood of <math> x_{L} </math>\n\n== Description ==\nAccording to (Mladenovic, 1995), VNS is a metaheuristic which systematically performs the procedure of neighborhood change, both in descent to local minima and in escape from the valleys which contain them.\n\nVNS is built upon the following perceptions:\n\n# A local minimum with respect to one neighbourhood structure is not necessarily a local minimum for another neighbourhood structure.\n# A global minimum is a local minimum with respect to all possible neighborhood structures.\n# For many problems, local minima with respect to one or several neighborhoods are relatively close to each other.\n\nUnlike many other metaheuristics, the basic schemes of VNS and its extensions are simple and require few, and sometimes no parameters. Therefore, in addition to providing very good solutions, often in simpler ways than other methods, VNS gives insight into the reasons for such a performance, which, in turn, can lead to more efficient and sophisticated implementations.\n\nThere are several papers where it could be studied among recently mentioned, such as (Hansen and Mladenovi´c 1999, 2001a, 2003, 2005; Moreno-Pérez et al.;<ref>{{cite book|last1=Moreno-Pérez|first1=JA.|last2=Hansen|first2=P. |last3=Mladenovic|first3=N.| title = Parallel variable neighborhood search|journal=Alba e (ed) Parallel Metaheuristics: A New Class of Algorithms|pages=247–266|year=2005|doi=10.1002/0471739383.ch11|citeseerx=10.1.1.615.2796|isbn=9780471739388}}</ref>)\n\n==Local search==\n{{see also|Local search (optimization)}}\nA local search heuristic is performed through choosing an initial solution x, discovering a direction of descent from x, within a neighbourhood N(x), and proceeding to the minimum of f(x) within N(x) in the same direction. If there is no direction of descent, the heuristic stops; otherwise, it is iterated. Usually the highest direction of descent, also related to as best improvement, is used. This set of rules is summarized in Algorithm 1, where we assume that an initial solution x is given. The output consists of a local minimum, denoted by x', and its value. Observe that a neighbourhood structure N(x) is defined for all x ∈ X. At each step, the neighbourhood N(x) of x is explored completely. As this may be timeconsuming, an alternative is to use the first descent heuristic. Vectors <math>x^i \\in N(x)</math> are then enumerated systematically and a move is made as soon as a direction for the descent is found. This is summarized in Algorithm 2.\n\n=== Algorithm 1: Best improvement (highest descent) heuristic ===\n\n<pre>\nFunction BestImprovement(x)\n  1: repeat\n  2:     x' ← x\n  3:     x ← argmin_{f (y)}, y∈N(x)\n  4: until ( f (x) ≥ f (x'))\n  5: return x'\n</pre>\n\n=== Algorithm 2: First improvement (first descent) heuristic ===\n\n<pre>\nFunction FirstImprovement(x)\n  1: repeat\n  2:    x' ← x; i←0\n  3:    repeat\n  4:       i ← i+1\n  5:       x ← argmin{ f (x), f (x^i)}, x^i  ∈ N(x)\n  6:    until ( f (x) < f (x^i) or i = |N(x)|)\n  7: until ( f (x) ≥ f (x'))\n  8: return x'\n</pre>\n\nLet one denote <math> \\mathcal{ N}_k(k=1, . . . ,k_{max}) </math>, a finite set of pre-selected neighborhood structures, and with <math>\\mathcal{N}_k(x)</math> the set of solutions in the ''kth'' neighborhood of ''x''.\n\nOne will also use the notation <math>\\mathcal{N'}_k(x), k = 1, . . . , k'_{max} </math> when describing local descent. Neighborhoods <math>\\mathcal{N}_k(x)</math> or <math>\\mathcal{N'}_k(x)</math> may be induced from one or more [[metric (mathematics)|metric]] (or quasi-metric) functions introduced into a solution space ''S''.\nAn optimal solution <math>x_{opt}</math> (or [[maxima and minima|global minimum]]) is a feasible solution where a minimum of problem ( is reached. We call ''x' ∈ X'' a local minimum of problem with respect to <math>\\mathcal{N}_k(x) </math>, if there is no solution <math> x \\in \\mathcal{N'}_k(x) \\subseteq X </math> such that <math>f (x) < f (x')</math>.\n\nIn order to solve problem by using several neighbourhoods, facts 1–3 can be used in three different ways: (i) deterministic; (ii) [[stochastic]]; (iii) both deterministic and stochastic. We first give in Algorithm 3 the steps of the neighbourhood change function which will be used later. Function NeighbourhoodChange() compares the new value f(x') with the incumbent value f(x) obtained in the neighbourhood k (line 1). If an improvement is obtained, k is returned to its initial value and the new incumbent updated (line 2). Otherwise, the next neighbourhood is considered (line 3).\n\n=== Algorithm 3:&nbsp;– Neighborhood change ===\n\n<pre>\nFunction NeighborhoodChange (x, x', k)\n 1: if f (x') < f(x) then\n 2:    x ← x' // Make a move\n 3:    k ← 1 // Initial neighborhood\n 4: else\n 5:    k ← k+1 // Next neighborhood\n</pre>\n\nWhen VNS does not render a good solution, there are several steps which could be helped in process, such as comparing first and best improvement strategies in local search, reducing neighborhood, intensifying shaking, adopting VND, adopting FSS, and experimenting with parameter settings.\n\nThe Basic VNS (BVNS) method (''Handbook of Metaheuristics'', 2010)<ref name=\"HoM2010\" /> combines deterministic and stochastic changes of neighbourhood. Its steps are given in Algorithm 4. Often successive neighbourhoods <math> \\mathcal{N}_k</math> will be nested. Observe that point x' is generated at random in Step 4 in order to avoid cycling, which might occur if a deterministic rule were applied. In Step 5, the best improvement local search (Algorithm 1) is usually\nadopted. However, it can be replaced with first improvement (Algorithm 2).\n\n=== Algorithm 4: Basic VNS ===\n\n<pre>\nFunction VNS (x, kmax, tmax );\n 1: repeat\n 2:    k ← 1;\n 3:    repeat\n 4:       x' ← Shake(x, k) /* Shaking */;\n 5:       x'' ← BestImprovement(x' ) /* Local search */;\n 6:       x ← NeighbourhoodChange(x, x'', k) /* Change neighbourhood */;\n 7:    until k = k_max ;\n 8:    t ← CpuTime()\n 9: until t > t_max ;\n</pre>\n\n=== VNS variants ===\n\nThe basic VNS is a best improvement [[method of steepest descent|descent method]] with randomization.<ref name=\"HoM2010\" /> Without much additional effort, it can be transformed into a descent-ascent method: in NeighbourhoodChange() function, replace also x by x\" with some probability, even if the solution is worse than the incumbent. It can also be changed into a first improvement method.\nAnother variant of the basic VNS can be to find a solution x' in the “Shaking” step as the best among b (a parameter) randomly generated solutions from the ''k''th neighbourhood. There are two possible variants of this extension: (1) to perform only one local search from the best among b points; (2) to perform all b local searches and then choose the best. In paper (Fleszar and Hindi<ref>{{cite journal|last1=Fleszar|first1=K|last2=Hindi|first2=KS|title=Solving the resource-constrained project scheduling problem by a variable neighborhood search|journal=Eur J Oper Res|year=2004|volume=155|issue=2|pages=402–413|doi=10.1016/s0377-2217(02)00884-6}}</ref>) could be found algorithm.\n\n== Extensions ==\n* VND<ref>{{cite journal|last1=Brimberg|first1=J.|last2=Hansen|first2=P.|last3=Mladenovic|first3=N.|last4=Taillard |first4=E. |title=Improvements and comparison of heuristics for solving the multisource Weber problem|journal=Oper. Res.|year=2000|volume=48 |issue=3|pages=444–460 |doi=10.1287/opre.48.3.444.12431}}</ref>\n:The variable neighborhood descent (VND) method is obtained if a change of neighborhoods is performed in a deterministic way. In the descriptions of its algorithms, we assume that an initial solution x is given. Most local search heuristics in their descent phase use very few neighbourhoods. The final solution should be a local minimum with respect to all <math>k_{max}</math> neighbourhoods; hence the chances to reach a global one are larger when using VND than with a single neighbourhood structure.\n* RVNS<ref>{{cite journal|last1=Mladenovic|first1=N.|last2=Petrovic|first2=J.|last3=Kovacevic-Vujcic|first3=V.|last4=Cangalovic |first4=M. |title=Solving spread spectrum radar polyphase code design problem by tabu search and variable neighborhood search|journal=Eur. J. Oper. Res.|year=2003b|volume=151 |issue=2|pages=389–399 |doi=10.1016/s0377-2217(02)00833-0}}</ref>\n\n:The reduced VNS (RVNS) method is obtained if random points are selected from <math>\\mathcal{N}_k(x)</math> and no descent is made. Rather, the values of these new points are compared with that of the incumbent and an update takes place in case of improvement. It is assumed that a stopping condition has been chosen like the maximum [[CPU time]] allowed <math>t_{max}</math> or the maximum number of iterations between two improvements.\n:To simplify the description of the algorithms it is used <math>t_{max}</math> below. Therefore, RVNS uses two parameters: <math>t_{max}</math> and <math>k_{max}</math>. RVNS is useful in very large instances, for which local search is costly. It has been observed that the best value for the parameter k_max is often 2. In addition, the maximum number of iterations between two improvements is usually used as a stopping condition. :RVNS is akin to a [[Monte-Carlo method]], but is more systematic.\n* Skewed VNS\n:The skewed VNS (SVNS) method (Hansen et al.)<ref>{{cite journal|last1=Hansen|first1=P.|last2=Jaumard|first2=B|last3=Mladenovi´c|first3=N|last4=Parreira |first4=A |title=Variable neighborhood search :for weighted maximum satisfiability problem|journal=Les Cahiers du GERAD G–2000–62, HEC Montréal, Canada|year=2000}}</ref> addresses the :problem of exploring valleys far from the incumbent solution. Indeed, once the best solution in a large region has been found, it is necessary to :go some way to obtain an improved one. Solutions drawn at random in distant neighbourhoods may differ substantially from the incumbent and VNS :can then degenerate, to some extent, into the Multistart heuristic (in which descents are made iteratively from solutions generated at random, a :heuristic which is known not to be very efficient). Consequently, some compensation for distance from the incumbent must be made.\n* Variable Neighbourhood Decomposition Search\n:The variable neighbourhood decomposition search (VNDS) method (Hansen et al.)<ref>{{cite journal|last1=Hansen|first1=P|last2=Mladenovi´c|first2=N|last3=Pérez-Brito|first3=D |title=Variable neighborhood decomposition :search|journal=J Heuristics|year=2001|volume=7|issue=4|pages=335–350|doi=10.1023/A:1011336210885}}</ref> extends the basic VNS into a two-level VNS scheme based upon :decomposition of the problem. For ease of presentation, but without loss of generality, it is assumed that the solution x represents the set of :some elements.\n* Parallel VNS\n:Several ways of parallelizing VNS have recently been proposed for solving the p-Median problem. In García-López et al.:<ref>{{cite journal|last1=García-López|first1=F|last2=Melián-Batista|first2=B|last3= Moreno-Pérez|first3= JA|first4=JM :|title=The parallel :variable neighborhood search for the p-median problem|journal=J Heuristics|year=2002|volume=8|issue=3|pages=375–388|doi=10.1023/A:1015013919497}}</ref>&nbsp; three of them :are tested: (i) parallelize local search; (ii) augment the number of solutions drawn from the current neighbourhood and make a :local search in :parallel from each of them and (iii) do the same as (ii) but update the information about the best solution found. Three Parallel :VNS strategies :are also suggested for solving the [[Travelling purchaser problem]] in Ochi et al.<ref>{{cite journal|last1=Ochi|first1=LS|last2=Silva|first2=MB|last3= Drummond|first3= L|title=Metaheuristics based on GRASP and VNS for solving traveling purchaser :problem|journal=MIC'2001, Porto|year=2001|pages=489–494}}</ref>\n* Primal-dual VNS\n:For most modern heuristics, the difference in value between the optimal solution and the obtained one is completely unknown. Guaranteed :performance of the primal heuristic may be determined if a [[upper and lower bounds|lower bound]] on the objective function value is known. To :this end, the standard approach is to relax the integrality condition on the primal variables, based on a mathematical programming formulation of :the problem.\n:However, when the dimension of the problem is large, even the relaxed problem may be impossible to solve exactly by standard :commercial solvers. :Therefore, it seems a good idea to solve dual relaxed problems heuristically as well. It was obtained guaranteed bounds on :the primal heuristics :performance.  In Primal-dual VNS (PD-VNS) (Hansen et al.)<ref>{{cite journal|last1=Hansen|first1=P|last2=Brimberg|first2=J|last3=Uroševi´c|first3=D|last4=Mladenovi´c|first4=N|title=Primal-dual variable neighborhood search for the simple plant location problem|journal=INFORMS J Comput|year=2007a|volume=19|issue=4|pages=552–564|doi=10.1287/ijoc.1060.0196}}</ref> one :possible general way to attain both the guaranteed bounds and the exact solution is proposed.\n* Variable Neighborhood Branching.)<ref>{{cite journal|last1=Hansen|first1=P.|last2=Mladenovic|first2=N.|last3=Urosevic|first3=D.|title=Variable neighborhood search and local branching|journal=Computers and Operations Research|year=2006|volume=33|issue=10|pages=3034–3045|doi=10.1016/j.cor.2005.02.033|citeseerx=10.1.1.108.987}}</ref>\n:The mixed integer linear programming (MILP) problem consists of maximizing or minimizing a linear function, subject to equality or inequality :constraints, and integrality restrictions on some of the variables.\n* Variable Neighborhood Formulation Space Search .)<ref>{{cite journal|last1=Mladenovic|first1=N.|last2=Plastria|first2=F.|author2-link=Frank Plastria|last3=Urosevic|first3=D.|title=Reformulation descent applied to circle packing problems|journal=Computers and Operations Research|year=2006|volume=32|issue=9|pages=2419–2434|doi=10.1016/j.cor.2004.03.010}}</ref>\n:FSS is method which is very useful because, one problem could be defined in addition formulations and moving through formulations is legitimate. :It is proved that local search works within formulations, implying a final solution when started from some initial solution in first formulation. :Local search systematically alternates between different formulations which was investigated for [[Circle packing in a circle|circle packing]] :problem (CPP) where [[stationary point]] for a [[nonlinear programming]] formulation of CPP in [[Cartesian coordinate system|Cartesian coordinates]] is not strictly a stationary point in [[Polar coordinate system|polar coordinates]].\n\n== Applications ==\nApplications of VNS, or of varieties of VNS are very abundant and numerous. Some fields where it could be found collections of scientific papers:\n* Industrial applications\n* Design problems in communication\n* Location problems\n* [[Data mining]]\n* [[Graph theory|Graph problems]]\n* [[Knapsack problem|Knapsack]] and packing problems\n* Mixed integer problems\n* Time tabling\n* [[Scheduling]]\n* [[Vehicle routing problem]]s\n* [[Arc routing]] and waste collection\n* Fleet sheet problems\n* Extended vehicle routing problems\n* Problems in biosciences and chemistry\n* Continuous optimization\n* Other optimization problems\n* Discovery science\n\n== Conclusion ==\nVNS implies several features which are presented in Hansen and Mladenovic<ref>{{cite book|last1=Hansen|first1=P|last2=Mladenovi´c|first2=N|title=Variable neighborhood search|journal=Glover F, Kochenberger G (eds) Handbook of Metaheuristics|volume=57|year=2003|issue=Kluwer, Dordrecht|pages=145–184|doi=10.1007/0-306-48056-5_6|citeseerx=10.1.1.635.7056|series=International Series in Operations Research & Management Science|isbn=978-1-4020-7263-5}}</ref> and some are presented here:\n\n# Simplicity: VNS is simple, clear and universally applicable\n# Precision: VNS is formulated in precise mathematical definitions\n# Coherence: all actions of the heuristics for solving problems follow from the VNS principles\n# Effectiveness: VNS supplies optimal or near-optimal solutions for all or at least most realistic instances\n# Efficiency: VNS takes a moderate computing time to generate optimal or near-optimal solutions\n# Robustness: the functioning of the VNS is coherent over a variety of instances\n# User friendliness: VNS has no parameters, so it is easy for understanding, expressing and using\n# Innovation: VNS is generating new types of application\n# Generality: VNS is inducing to good results for a wide variety of problems\n# Interactivity: VNS allows the user to incorporate his knowledge to improve the resolution process\n# Multiplicity: VNS is able to produce a certain near-optimal solutions from which the user can choose;\n\nInterest in VNS is growing quickly, evidenced by the increasing number of papers published each year on this topic (10 years ago, only a few; 5 years ago, about a dozen; and about 50 in 2007).\nMoreover, the 18th EURO mini-conference held in Tenerife in November 2005 was entirely devoted to VNS. It led to special issues of [[Institute of Mathematics and its Applications|IMA Journal of Management Mathematics]] in 2007, European Journal of Operational Research (http://www.journals.elsevier.com/european-journal-of-operational-research/), and Journal of Heuristics (https://www.springer.com/mathematics/applications/journal/10732/) in 2008.\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* [http://toledo.mi.sanu.ac.rs/~grujicic/vnsconference EURO Mini Conference XXVIII on Variable Neighbourhood Search]\n\n[[Category:Search algorithms]]\n[[Category:Travelling salesman problem]]"
    },
    {
      "title": "Combinatorial optimization",
      "url": "https://en.wikipedia.org/wiki/Combinatorial_optimization",
      "text": "[[File:Minimum spanning tree.svg|thumb|300px|right|A [[minimum spanning tree]] of a weighted [[planar graph]]. Finding a minimum spanning tree is a common problem involving combinatorial optimization.]]\n\nIn [[Operations Research]], [[applied mathematics]] and [[theoretical computer science]], '''combinatorial optimization''' <!-- synonymous or subfield?: '''discrete optimization'''{{Citation needed|date=May 2012}}--> is a topic that consists of finding an optimal object from a [[finite set]] of objects.<ref>{{harvnb|Schrijver|2006|p=1}}.</ref> In many such problems, [[exhaustive search]] is not tractable. It operates on the domain of those optimization problems, in which the set of [[Candidate solution|feasible solutions]] is [[Discrete set|discrete]] or can be reduced to discrete, and in which the goal is to find the best solution.  Some common problems involving combinatorial optimization are the [[travelling salesman problem]] (\"TSP\"), the [[minimum spanning tree|minimum spanning tree problem]] (\"MST\"), and the [[knapsack problem]].\n\nCombinatorial optimization is a subset of [[mathematical optimization]] that is related to [[operations research]], [[algorithm|algorithm theory]], and [[computational complexity theory]]. It has important applications in several fields, including [[artificial intelligence]], [[machine learning]], [[auction theory]], and [[software engineering]].\n\nSome research literature<ref>{{cite web | title=Discrete Optimization | url=http://www.elsevier.com/locate/disopt | publisher=Elsevier |  accessdate=2009-06-08}}</ref> considers [[discrete optimization]] to consist of [[integer programming]] together with combinatorial optimization (which in turn is composed of [[optimization problem]]s dealing with [[Graph (discrete mathematics)|graph structures]]) although all of these topics have closely intertwined research literature. It often involves determining the way to efficiently allocate resources used to find solutions to mathematical problems.\n\n==Applications==\nApplications for combinatorial optimization include, but are not limited to:\n\n* Developing the best airline network of spokes and destinations\n* Deciding which taxis in a fleet to route to pick up fares\n* Determining the optimal way to deliver packages\n* Working out the best allocation of jobs to people\n* Determining the right attributes of concept elements prior to [[concept testing]]{{citation needed|date=October 2018}}\n* [[Logistics]]<ref>Sbihi, Abdelkader, and Richard W. Eglese. \"[https://hal.archives-ouvertes.fr/docs/00/64/40/76/PDF/COGL_4or.pdf Combinatorial optimization and green logistics].\" 4OR 5.2 (2007): 99-116.</ref>\n* [[Supply chain optimization]]<ref>Eskandarpour, Majid, et al. \"[https://hal.archives-ouvertes.fr/hal-01154605/document Sustainable supply chain network design: An optimization-oriented review].\" Omega 54 (2015): 11-32.</ref>\n\n==Methods==\nThere is a large amount of literature on [[polynomial-time algorithm]]s for certain special classes of discrete optimization, a considerable amount of it unified by the theory of [[linear programming]]. Some examples of combinatorial optimization problems that fall into this framework are [[shortest path]]s and [[shortest path tree]]s, [[flow network|flows and circulations]], [[spanning tree]]s, [[Matching (graph theory)|matching]], and [[matroid]] problems.\n\nFor [[NP-complete]] discrete optimization problems, current research literature includes the following topics:\n* polynomial-time exactly solvable special cases of the problem at hand (e.g. see [[fixed-parameter tractable]])\n* algorithms that perform well on \"random\" instances (e.g. for [[Traveling salesman problem#TSP path length for random pointset in a square|TSP]])\n* [[approximation algorithm]]s that run in polynomial time and find a solution that is \"close\" to optimal\n* solving real-world instances that arise in practice and do not necessarily exhibit the worst-case behavior inherent in NP-complete problems (e.g. TSP instances with tens of thousands of nodes<ref>{{harvnb|Cook|2016}}.</ref>).\n\nCombinatorial optimization problems can be viewed as searching for the best element of some set of discrete items; therefore, in principle, any sort of [[search algorithm]] or [[metaheuristic]] can be used to solve them. However, generic search algorithms are not guaranteed to find an optimal solution, nor are they guaranteed to run quickly (in polynomial time). Since some discrete optimization problems are [[NP-complete]], such as the traveling salesman problem{{cn|reason=TSP is NP-hard, not NP-complete|date=March 2019}}, this is expected unless [[P=NP]].\n\n== Formal definition ==\nFormally, a [[combinatorial optimization]] problem <math>A</math> is a quadruple{{Citation needed|date=January 2018}} <math>(I, f, m, g)</math>, where\n\n* <math>I</math> is a [[Set (mathematics)|set]] of instances;\n* given an instance <math>x \\in I</math>, <math>f(x)</math> is the set of feasible solutions;\n* given an instance <math>x</math> and a feasible solution <math>y</math> of <math>x</math>, <math>m(x, y)</math> denotes the [[Measure (mathematics)|measure]] of <math>y</math>, which is usually a [[Positive (mathematics)|positive]] [[Real number|real]].\n* <math>g</math> is the goal function, and is either <math>\\min</math> or <math>\\max</math>.\n\nThe goal is then to find for some instance <math>x</math> an ''optimal solution'', that is, a feasible solution <math>y</math> with\n\n: <math>\nm(x, y) = g \\{ m(x, y') \\mid y' \\in f(x) \\} .\n</math>\n\nFor each combinatorial optimization problem, there is a corresponding [[decision problem]] that asks whether there is a feasible solution for some particular measure <math>m_0</math>. For example, if there is a [[Graph (discrete mathematics)|graph]] <math>G</math> which contains vertices <math>u</math> and <math>v</math>, an optimization problem might be \"find a path from <math>u</math> to <math>v</math> that uses the fewest edges\". This problem might have an answer of, say, 4. A corresponding decision problem would be \"is there a path from <math>u</math> to <math>v</math> that uses 10 or fewer edges?\" This problem can be answered with a simple 'yes' or 'no'.\n\nIn the field of [[Approximation algorithm|approximation algorithms]], algorithms are designed to find near-optimal solutions to hard problems. The usual decision version is then an inadequate definition of the problem since it only specifies acceptable solutions. Even though we could introduce suitable decision problems, the problem is more naturally characterized as an optimization problem.<ref name=\"Ausiello03\">{{citation|last1=Ausiello|first1=Giorgio|title=Complexity and Approximation|year=2003|edition=Corrected|publisher=Springer|isbn=978-3-540-65431-5|display-authors=etal}}</ref>\n\n== NP optimization problem ==\nAn ''NP-optimization problem'' (NPO) is a combinatorial optimization problem with the following additional conditions.<ref name=\"Hromkovic02\">{{citation|last1=Hromkovic|first1=Juraj|title=Algorithmics for Hard Problems|year=2002|series=Texts in Theoretical Computer Science|edition=2nd|publisher=Springer|isbn=978-3-540-44134-2}}</ref> Note that the below referred [[Polynomial|polynomials]] are functions of the size of the respective functions' inputs, not the size of some implicit set of input instances.\n\n* the size of every feasible solution <math>y\\in f(x)</math> is polynomially [[Bounded set|bounded]] in the size of the given instance <math>x</math>,\n* the languages <math>\\{\\,x\\,\\mid\\, x \\in I \\,\\}</math> and <math>\\{\\,(x,y)\\, \\mid\\, y \\in f(x) \\,\\}</math> can be [[Decidable language|recognized]] in [[polynomial time]], and\n* <math>m</math> is [[Polynomial time|polynomial-time computable]].\n\nThis implies that the corresponding decision problem is in [[NP (complexity)|NP]]. In computer science, interesting optimization problems usually have the above properties and are therefore NPO problems. A problem is additionally called a P-optimization (PO) problem, if there exists an algorithm which finds optimal solutions in polynomial time. Often, when dealing with the class NPO, one is interested in optimization problems for which the decision versions are [[NP-completeness|NP-complete]]. Note that hardness relations are always with respect to some reduction. Due to the connection between approximation algorithms and computational optimization problems, reductions which preserve approximation in some respect are for this subject preferred than the usual [[Turing reduction|Turing]] and [[Karp reduction|Karp reductions]]. An example of such a reduction would be the [[L-reduction]]. For this reason, optimization problems with NP-complete decision versions are not necessarily called NPO-complete.<ref name=\"Kann92\">{{citation|last1=Kann|first1=Viggo|title=On the Approximability of NP-complete Optimization Problems|year=1992|publisher=Royal Institute of Technology, Sweden|isbn=91-7170-082-X}}</ref>\n\nNPO is divided into the following subclasses according to their approximability:<ref name=\"Hromkovic02\" />\n\n* ''NPO(I)'': Equals [[FPTAS]]. Contains the [[Knapsack problem]].\n* ''NPO(II)'': Equals [[Polynomial-time approximation scheme|PTAS]]. Contains the [[Makespan]] scheduling problem.\n* ''NPO(III)'': :The class of NPO problems that have polynomial-time algorithms which computes solutions with a cost at most ''c'' times the optimal cost (for minimization problems) or a cost at least <math>1/c</math> of the optimal cost (for maximization problems). In [[Juraj Hromkovič|Hromkovič]]'s book, excluded from this class are all NPO(II)-problems save if P=NP. Without the exclusion, equals APX. Contains [[MAX-SAT]] and metric [[Travelling salesman problem|TSP]].\n* ''NPO(IV)'': :The class of NPO problems with polynomial-time algorithms approximating the optimal solution by a ratio that is polynomial in a logarithm of the size of the input. In Hromkovic's book, all NPO(III)-problems are excluded from this class unless P=NP. Contains the [[set cover]] problem.\n* ''NPO(V)'': :The class of NPO problems with polynomial-time algorithms approximating the optimal solution by a ratio bounded by some function on n. In Hromkovic's book, all NPO(IV)-problems  are excluded from this class unless P=NP. Contains the [[Travelling salesman problem|TSP]] and [[Clique problem|Max Clique problems]].\n\nAn NPO problem is called ''polynomially bounded'' (PB) if, for every instance <math>x</math> and for every solution <math>y\\in f(x)</math>, the measure <math>\nm(x, y)\n</math>is bounded by a polynomial function of the size of <math>x</math>. The class NPOPB is the class of NPO problems that are polynomially-bounded.\n\n<br />\n==Specific problems==\n[[Image:TSP Deutschland 3.png|thumb|200px|An optimal traveling salesperson tour through [[Germany]]’s 15 largest cities. It is the shortest among 43,589,145,600<ref>Take one city, and take all possible orders of the other 14 cities. Then divide by two because it does not matter in which direction in time they come after each other: 14!/2 = 43,589,145,600.</ref> possible tours visiting each city exactly once.]]\n* [[Assignment problem]]\n* [[Closure problem]]\n* [[Constraint satisfaction problem]]\n* [[Cutting stock problem]]\n*[[Dominating set]] problem\n* [[Integer programming]]\n* [[Knapsack problem]]\n*[[Minimum relevant variables in linear system]]\n*[[Minimum spanning tree]]\n* [[Nurse scheduling problem]]\n*[[Set cover problem]]\n* [[Traveling salesman problem]]\n* [[Vehicle rescheduling problem]]\n* [[Vehicle routing problem]]\n* [[Weapon target assignment problem]]\n\n==See also==\n*[[Constraint Composite Graph]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*{{Cite web\n | url = http://people.brunel.ac.uk/~mastjjb/jeb/or/ip.html\n | title = Integer programming\n | last = Beasley\n | first = J. E.\n | type = lecture notes\n | ref = harv\n}}\n\n*{{Cite book\n | first1 = William J.\n | last1 = Cook\n | author1-link = William J. Cook\n | first2 = William H.\n | last2 = Cunningham\n | first3 = William R.\n | last3 = Pulleyblank\n | author3-link = William R. Pulleyblank\n | last4 = Schrijver\n | first4 = Alexander\n | author4-link = Alexander Schrijver\n | title = Combinatorial Optimization\n | publisher = Wiley\n | year = 1997\n | isbn = 0-471-55894-X\n | ref = harv\n}}\n\n*{{Cite web\n | title = Optimal TSP Tours\n | url = http://www.tsp.gatech.edu/optimal/index.html\n | last = Cook\n | first = William\n | publisher = [[University of Waterloo]]\n | year = 2016\n | ref = harv\n}} ''(Information on the largest TSP instances solved to date.)''\n\n*{{Cite web\n | editor-last1 = Crescenzi\n | editor-first1 = Pierluigi\n | editor-last2 = Kann\n | editor-first2 = Viggo\n | editor-last3 = Halldórsson\n | editor-first3 = Magnús\n | editor-last4 = Karpinski\n | editor-first4 = Marek\n | editor4-link = Marek Karpinski\n | editor-last5 = Woeginger\n | editor-first5 = Gerhard\n | editor5-link = Gerhard J. Woeginger\n | url = http://www.nada.kth.se/%7Eviggo/wwwcompendium/\n | title = A Compendium of NP Optimization Problems\n | ref = harv\n}} ''(This is a continuously updated catalog of approximability results for NP optimization problems.)''\n\n*{{Cite book\n | editor-last1 = Das\n | editor-first1 = Arnab\n | editor-last2 = Chakrabarti\n | editor-first2 = Bikas K\n | editor2-link = Bikas K Chakrabarti\n | title = Quantum Annealing and Related Optimization Methods\n | series = Lecture Notes in Physics\n | volume = 679\n | publisher = Springer\n | year = 2005\n | ref = harv\n}}\n\n*{{Cite journal\n | last1 = Das\n | first1 = Arnab\n | last2 = Chakrabarti\n | first2 = Bikas K\n | title = Colloquium: Quantum annealing and analog quantum computation\n | journal = Rev. Mod. Phys.\n | volume = 80\n | page = 1061\n | year = 2008\n | doi = 10.1103/RevModPhys.80.1061\n | ref = harv\n| citeseerx = 10.1.1.563.9990\n }}\n\n*{{Cite book\n | last = Lawler\n | first = Eugene\n | author-link = Eugene Lawler\n | title = Combinatorial Optimization: Networks and Matroids\n | year = 2001\n | publisher = Dover\n | isbn = 0-486-41453-1\n | <!-- pages = 117–120 -->\n | ref = harv\n}}\n\n*{{Cite book\n | first = Jon\n | last = Lee\n | author-link = Jon Lee (mathematician)\n | url = https://books.google.com/books?id=3pL1B7WVYnAC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false\n | title = A First Course in Combinatorial Optimization\n | publisher = Cambridge University Press\n | year = 2004\n | isbn = 0-521-01012-8\n | ref = harv\n}}\n\n*{{Cite book\n | last1 = Papadimitriou\n | first1 = Christos H.\n | last2 = Steiglitz\n | first2 = Kenneth\n | author2-link = Kenneth Steiglitz\n | title = Combinatorial Optimization : Algorithms and Complexity\n | publisher = Dover\n | date = July 1998\n | isbn = 0-486-40258-4\n | ref = harv\n}}\n\n*{{Cite book\n | last = Schrijver\n | first = Alexander\n | title = Combinatorial Optimization: Polyhedra and Efficiency\n | publisher = Springer\n | series = Algorithms and Combinatorics\n | volume = 24\n | year = 2003\n | ref = harv\n | url = https://books.google.com/books?id=mqGeSQ6dJycC&printsec=frontcover#v=onepage&q&f=false\n}}\n\n*{{Cite book\n | last = Schrijver\n | first = Alexander\n | chapter = On the history of combinatorial optimization (till 1960)\n | title = Handbook of Discrete Optimization\n | editor-last1 = Aardal\n | editor-first1 = K.|editor1-link=Karen Aardal\n | editor-last2 = Nemhauser\n | editor-first2 = G.L.\n | editor-last3 = Weismantel\n | editor-first3 = R.\n | publisher = Elsevier\n | year = 2005\n | pages = 1–68\n | url = http://homepages.cwi.nl/~lex/files/histco.pdf\n | ref = harv\n}}\n\n*{{Cite book\n | last = Schrijver\n | first = Alexander\n | title = A Course in Combinatorial Optimization\n | url = http://homepages.cwi.nl/~lex/files/dict.pdf\n | date = February 1, 2006\n | ref = harv\n}}\n\n*{{Cite book\n | last1 = Sierksma\n | first1 = Gerard\n | last2 = Ghosh\n | first2 = Diptesh\n | author1-link = Gerard Sierksma\n | title = Networks in Action; Text and Computer Exercises in Network Optimization\n | publisher = Springer\n | date = 2010\n | isbn = 978-1-4419-5512-8\n | ref = harv\n}}\n\n*{{Cite book\n | author1=Gerard Sierksma\n | author2=Yori Zwols\n | title=Linear and Integer Optimization: Theory and Practice\n | year=2015\n | publisher=CRC Press\n | isbn=978-1-498-71016-9\n}}\n\n*{{Cite book\n | last = Pintea\n | first = C-M.\n | title = Advances in Bio-inspired Computing for Combinatorial Optimization Problem\n | url = https://www.springer.com/la/book/9783642401787\n | publisher = Springer\n | year = 2014\n | ISBN = 978-3-642-40178-7\n | ref = harv\n}}\n\n==External links==\n{{Commonscat}}\n*[https://www.springer.com/mathematics/journal/10878 Journal of Combinatorial Optimization]\n*[http://www.iasi.cnr.it/aussois The Aussois Combinatorial Optimization Workshop]\n*[http://sourceforge.net/projects/jcop/ Java Combinatorial Optimization Platform] (open source code)\n*[https://www.mjc2.com/staff-planning-complexity.htm Why is scheduling people hard?]\n*[https://www7.in.tum.de/~kugele/files/jobsis.pdf Complexity classes for optimization problems / Stefan Kugele]\n\n{{DEFAULTSORT:Combinatorial Optimization}}\n[[Category:Combinatorial optimization| ]]\n[[Category:Computational complexity theory]]\n[[Category:Theoretical computer science]]\n\n[[eo:Diskreta optimumigo]]"
    },
    {
      "title": "Symmetry-breaking constraints",
      "url": "https://en.wikipedia.org/wiki/Symmetry-breaking_constraints",
      "text": "In the field of mathematics called [[combinatorial optimization]], the method of '''symmetry-breaking constraints''' can be used to take advantage of [[symmetry|symmetries]] in many [[constraint satisfaction]] and optimization problems, by adding constraints that eliminate symmetries and reduce the search space size.\n\nSymmetries in a combinatorial problem increase the size of the search space and therefore, time is wasted in visiting new solutions which are symmetric to the already visited solutions. The solution time of a combinatorial problem can be reduced by adding new constraints, referred as symmetry breaking constraints, such that some of the symmetric solutions are eliminated from the search space while preserving the existence of at least one solution.<ref>{{cite journal|title=Published key research papers on Symmetry Breaking Constraints|url=https://scholar.google.com.hk/scholar?as_q=&as_epq=symmetry+breaking+constraints&as_oq=&as_eq=&as_occt=title&as_sauthors=&as_publication=&as_ylo=&as_yhi=&btnG=&hl=en&as_sdt=0%2C5}}</ref><ref>{{cite book|last1=Walsh|first1=Toby|title=General symmetry breaking constraints|journal=Principles and Practice of Constraint Programming-CP|date=2006|volume=Springer Berlin Heidelberg|pages=650–664|doi=10.1007/11889205_46|series=Lecture Notes in Computer Science|isbn=978-3-540-46267-5|citeseerx=10.1.1.131.2959}}</ref>\n\nSymmetry is common in many real-life combinatorial problems. For example, certain vehicles in the [[vehicle routing problem]] might be identical. For a valid routing plan, every permutation of such identical vehicles yields another valid routing plan with the same objective function value.\n\n==References==\n{{Reflist}}\n\n[[Category:Constraint programming|*]]\n[[Category:Combinatorial optimization| ]]"
    },
    {
      "title": "1-center problem",
      "url": "https://en.wikipedia.org/wiki/1-center_problem",
      "text": "The '''1-center problem''' or '''minimax''' or '''minmax location problem''' is a classical [[combinatorial optimization]] problem in [[operations research]] of [[facilities location]] type. In its most general case the problem is stated as follows: given a set of n demand points, a space of feasible locations of a facility and a function to calculate the transportation cost between a facility and any demand point, find a location of the facility which minimizes the maximum facility-demand point transportation cost.\n\nThere are numerous particular cases of the problem, depending on the choice of the locations both of demand points and facilities, as well as the distance function.\n\nA simple special case is when the feasible locations and demand points are in the plane with Euclidean distance as transportation cost ('''planar minmax Euclidean facility location problem, Euclidean 1-center problem in the plane,''' etc.). It is also known as the [[smallest circle problem]]. Its generalization to n-dimensional Euclidean spaces is known as the [[smallest enclosing ball]] problem. A further generalization ('''weighted Euclidean facility location''') is when the set of weights is assigned to demand points and the transportation cost is the sum of the products of distances by the corresponding weights. Another special case, the [[closest string]] problem, arises when the inputs are [[String (computer science)|strings]] and their distance is measured using [[Hamming distance]].\n\n==References==\n* {{cite journal | last = Megiddo | first = Nimrod | title = The weighted Euclidean 1-center problem | journal = Mathematics of Operations Research | volume = 8 | issue = 4 | pages = 498–504 | publisher = Institute for Operations Research and the Management Sciences | location = [[Hanover (disambiguation)]] | date = November 1983 | url = http://theory.stanford.edu/~megiddo/pdf/weight1.pdf | doi=10.1287/moor.8.4.498}}\n* {{cite journal | last = Foul | first = Abdelaziz | title = A 1-center problem on the plane with uniformly distributed demand points | journal = Operations Research Letters | volume = 34 | issue = 3 | pages = 264–268 | publisher = Elsevier | date = May 2006 | url = http://www.sciencedirect.com/science/article/pii/S016763770500060X | doi = 10.1016/j.orl.2005.04.011}}\n* {{cite journal | last = Chandrasekaran | first = R. | title = The weighted euclidean 1-center problem | journal = Operations Research Letters | volume = 1 | issue = 3 | pages = 111–112 | publisher = Elsevier | date = July 1982 | url = http://www.sciencedirect.com/science/article/pii/0167637782900098 | doi = 10.1016/0167-6377(82)90009-8}}\n* {{cite journal | last = Colebrook | first = M. |author2= J. Gutiérrez, S. Alonso|author3= J. Sicilia | title = A New Algorithm for the Undesirable 1-Center Problem on Networks | journal = [[Journal of the Operational Research Society]] | volume = 53 | issue = 12 | pages = 1357–1366 | publisher = Palgrave Macmillan Journals | date = December 2002 | jstor = 822725 | doi = 10.1057/palgrave.jors.2601468}}\n* {{cite journal | last = Burkard | first = Rainer E. |author2= Helidon Dollani | title = A Note on the Robust 1-Center Problem on Trees | journal = Annals of Operations Research | volume = 110 | issue = 1–4 | pages = 69–82 | publisher = Kluwer Academic Publishers | date = February 2002 | issn = 1572-9338 | doi = 10.1023/A:1020711416254}}\n\n==See also==\n*[[Minsum facility location]] ([[1-median problem]]), with [[geometric median]] being a special case\n*[[Maxmin facility location]] ([[obnoxious facility location]])\n*[[k-center problem]]\n*[[k-median problem]]\n\n[[Category:Combinatorial optimization]]"
    },
    {
      "title": "A* search algorithm",
      "url": "https://en.wikipedia.org/wiki/A%2A_search_algorithm",
      "text": "{{Infobox algorithm\n|name= <!-- Defaults to article name -->\n|class= [[Search algorithm]]\n|image=\n|caption=\n|data= [[Graph (data structure)|Graph]]\n|time= <math>O(|E|) = O(b^d)</math>\n|best-time=\n|average-time=\n|space= <math>O(|V|) = O(b^d)</math>\n}}\n\n{{Tree search algorithm}}\nIn [[computer science]], '''A*''' (pronounced \"A star\") is a [[computer algorithm]] that is widely used in [[pathfinding]] and [[graph traversal]], which is the process of finding a path between multiple points, called \"nodes\". It enjoys widespread use due to its [[Computer performance|performance]] and accuracy. However, in practical travel-routing systems, it is generally outperformed by algorithms which can pre-process the graph to attain better performance,<ref>{{cite book\n | last1 = Delling | first1 = D.\n | last2 = Sanders | first2 = P. | author2-link = Peter Sanders (computer scientist)\n | last3 = Schultes | first3 = D.\n | last4 = Wagner | first4 = D. | author4-link = Dorothea Wagner\n | doi = 10.1007/978-3-642-02094-0_7\n | pages = 11个$7–139\n | publisher = Springer\n | title= Algorithmics of Large and Complex Networks: Design, Analysis, and Simulation\n | volume = 5515\n | year = 2009| chapter = Engineering Route Planning Algorithms\n | series = Lecture Notes in Computer Science\n | isbn = 978-3-642-02093-3\n | citeseerx = 10.1.1.164.8916\n }}</ref> although other work has found A* to be superior to other approaches.<ref name=\"Zeng\">{{cite journal\n | first = W.\n | last = Zeng\n |author2= Church, R. L.\n | title = Finding shortest paths on real road networks: the case for A*\n | journal = International Journal of Geographical Information Science\n | issue = 4\n | pages = 531–543\n | year = 2009\n | doi = 10.1080/13658810801949850 | volume = 23\n }}\n</ref>\n\n[[Peter E. Hart|Peter Hart]], [[Nils Nilsson (researcher)|Nils Nilsson]] and [[Bertram Raphael]] of Stanford Research Institute (now [[SRI International]]) first published the algorithm in 1968.<ref name=\"nilsson\">{{cite journal\n | first = P. E.\n | last = Hart\n |author2= Nilsson, N. J.|author3= Raphael, B.\n | title = A Formal Basis for the Heuristic Determination of Minimum Cost Paths\n | journal = IEEE Transactions on Systems Science and Cybernetics SSC4\n | issue = 2\n | pages = 100–107\n | year = 1968\n | doi = 10.1109/TSSC.1968.300136\n | volume = 4\n }}\n</ref> It can be seen as an extension of [[Edsger Dijkstra|Edsger Dijkstra's]] [[Dijkstra's algorithm|1959 algorithm]]. A* achieves better performance by using [[Heuristic (computer science)|heuristics]] to guide its search.\n\n==History==\n[[File:SRI Shakey with callouts.jpg|thumb|right|A* was invented by researchers working on Shakey the Robot's path planning.]]\nA* was created as part of [[Shakey the robot|the Shakey project]], which had the aim of building a mobile robot that could plan its own actions.&nbsp; Nils Nilsson originally proposed using the Graph Traverser algorithm<ref>{{Cite journal|last=Doran|first=J. E.|last2=Michie|first2=D.|date=1966-09-20|title=Experiments with the Graph Traverser program|url=http://rspa.royalsocietypublishing.org/content/294/1437/235|journal=Proc. R. Soc. Lond. A|language=en|volume=294|issue=1437|pages=235–259|doi=10.1098/rspa.1966.0205|issn=0080-4630}}</ref> for Shakey's path planning.<ref name=\":0\">{{Cite book|url=https://ai.stanford.edu/~nilsson/QAI/qai.pdf|title=The Quest for Artificial Intelligence|last=Nilsson|first=Nils J.|date=2009-10-30|publisher=Cambridge University Press|isbn=9780521122931|location=Cambridge|pages=|language=English}}</ref>   Graph Traverser is guided by a heuristic function <math>h(n),</math> the estimated distance from node <math>n</math> to the goal node, it entirely ignores <math>g(n),</math> the distance from the start node to <math>n.</math> Bertram Raphael suggested using the sum, <math>g(n) + h(n)</math>.<ref name=\":0\" /> Peter Hart invented the concepts we now call admissibility and consistency of heuristic functions.&nbsp; A* was originally designed for finding least-cost paths when the cost of a path is the sum of its edge costs, but it has been shown that A* can be used to find optimal paths for any problem satisfying the conditions of a cost algebra.<ref>{{Cite journal|last=Edelkamp|first=Stefan|last2=Jabbar|first2=Shahid|last3=Lluch-Lafuente|first3=Alberto|date=2005|title=Cost-Algebraic Heuristic Search|url=http://www.aaai.org/Papers/AAAI/2005/AAAI05-216.pdf|journal=Proceedings of the Twentieth National Conference on Artificial Intelligence (AAAI)|volume=|pages=1362–1367|via=}}</ref>\n\nThe original 1968 A* paper<ref name=\"nilsson\" /> contained a theorem that no A*-like algorithm<ref>“A*-like” means the algorithm searches by extending paths originating at the start node one edge at a time, just as A* does. This excludes, for example, algorithms that search backward from the goal or in both directions simultaneously. In addition, the algorithms covered by this theorem must be admissible and “not more informed” than A*.</ref> could expand fewer nodes than A* if the heuristic function is consistent and A*’s tie-breaking rule is suitably chosen. A correction was published a few years later<ref>{{Cite journal|last=Hart|first=Peter E.|last2=Nilsson|first2=Nils J.|last3=Raphael|first3=Bertram|date=1972-12-01|title=Correction to 'A Formal Basis for the Heuristic Determination of Minimum Cost Paths'|url=https://www.ics.uci.edu/~dechter/publications/r0.pdf|journal=ACM SIGART Bulletin|volume=|issue=37|pages=28–29|doi=10.1145/1056777.1056779|issn=0163-5719|via=}}</ref> showing that consistency was not required, just admissibility.  However, what was really shown was that no (such) algorithm can be ''strictly'' more efficient than A* with respect to the set of expanded nodes.  As shown in Dechter and Pearl’s definitive study of A*'s optimality (optimal efficiency as it is now called), it is possible for a different correct algorithm to outperform A* on some graphs while losing to A* on other graphs, or to expand a set of nodes that neither contains the set of nodes expanded by A*, nor is contained in it.<ref name=\":1\" />\n\n==Description==\nA* is an [[informed search algorithm]], or a [[best-first search]], meaning that it is formulated in terms of [[weighted graph]]s: starting from a specific starting [[node (graph theory)|node]] of a graph, it aims to find a path to the given goal node having the smallest cost (least distance travelled, shortest time, etc.).  It does this by maintaining a [[tree (data structure)|tree]] of paths originating at the start node and extending those paths one edge at a time until its termination criterion is satisfied.\n\nAt each iteration of its main loop, A* needs to determine which of its paths to extend. It does so based on the cost of the path and an estimate of the cost required to extend the path all the way to the goal. Specifically, A* selects the path that minimizes\n\n:<math>f(n) = g(n) + h(n)</math>\n\nwhere {{mvar|n}} is the next node on the path, {{math|''g''(''n'')}} is the cost of the path from the start node to {{mvar|n}}, and {{math|''h''(''n'')}} is a [[heuristic]] function that estimates the cost of the cheapest path from {{mvar|n}} to the goal. A* terminates when the path it chooses to extend is a path from start to goal or if there are no paths eligible to be extended. The heuristic function is problem-specific. If the heuristic function is [[admissible heuristic|admissible]], meaning that it never overestimates the actual cost to get to the goal, A* is guaranteed to return a least-cost path from start to goal.\n\nTypical implementations of A* use a [[priority queue]] to perform the repeated selection of minimum (estimated) cost nodes to expand. This priority queue is known as the ''[[open set (Computer science)|open set]]'' or ''[[fringe (Computer science)|fringe]]''. At each step of the algorithm, the node with the lowest {{math|''f''(''x'')}} value is removed from the queue, the {{mvar|f}} and {{mvar|g}} values of its neighbors are updated accordingly, and these neighbors are added to the queue. The algorithm continues until a goal node has a lower {{mvar|f}} value than any node in the queue (or until the queue is empty).{{efn|Goal nodes may be passed over multiple times if there remain other nodes with lower {{mvar|f}} values, as they may lead to a shorter path to a goal.}} The {{mvar|f}} value of the goal is then the cost of the shortest path, since {{mvar|h}} at the goal is zero in an admissible heuristic.\n\nThe algorithm described so far gives us only the length of the shortest path. To find the actual sequence of steps, the algorithm can be easily revised so that each node on the path keeps track of its predecessor. After this algorithm is run, the ending node will point to its predecessor, and so on, until some node's predecessor is the start node.\n\nAs an example, when searching for the shortest route on a map, {{math|''h''(''x'')}} might represent the [[Euclidean distance|straight-line distance]] to the goal, since that is physically the smallest possible distance between any two points.\n\nIf the [[heuristic]] {{mvar|h}} satisfies the additional condition {{math|''h''(''x'') ≤ ''d''(''x'', ''y'') + ''h''(''y'')}} for every edge {{math|(''x'', ''y'')}} of the graph (where {{mvar|d}} denotes the length of that edge), then {{mvar|h}} is called [[Consistent heuristic|monotone, or consistent]]. In such a case, A* can be implemented more efficiently—roughly speaking, no node needs to be processed more than once (see ''closed set'' below)—and A* is equivalent to running [[Dijkstra's algorithm]] with the [[reduced cost]] {{math|''d'''(''x'', ''y'') {{=}} ''d''(''x'', ''y'') + ''h''(''y'') − ''h''(''x'')}}.\n\n===Pseudocode===\nThe following [[pseudocode]] describes the algorithm:\n\n<source lang=\"pascal\" start=\"1\">\nfunction reconstruct_path(cameFrom, current)\n    total_path := {current}\n    while current in cameFrom.Keys:\n        current := cameFrom[current]\n        total_path.append(current)\n    return total_path\n\nfunction A_Star(start, goal)\n    // The set of nodes already evaluated\n    closedSet := {}\n\n    // The set of currently discovered nodes that are not evaluated yet.\n    // Initially, only the start node is known.\n    openSet := {start}\n\n    // For each node, which node it can most efficiently be reached from.\n    // If a node can be reached from many nodes, cameFrom will eventually contain the\n    // most efficient previous step.\n    cameFrom := an empty map\n\n    // For each node, the cost of getting from the start node to that node.\n    gScore := map with default value of Infinity\n\n    // The cost of going from start to start is zero.\n    gScore[start] := 0\n\n    // For each node, the total cost of getting from the start node to the goal\n    // by passing by that node. That value is partly known, partly heuristic.\n    fScore := map with default value of Infinity\n\n    // For the first node, that value is completely heuristic.\n    fScore[start] := heuristic_cost_estimate(start, goal)\n\n    while openSet is not empty\n        current := the node in openSet having the lowest fScore[] value\n        if current = goal\n            return reconstruct_path(cameFrom, current)\n\n        openSet.Remove(current)\n        closedSet.Add(current)\n\n        for each neighbor of current\n            if neighbor in closedSet\n                continue\t\t// Ignore the neighbor which is already evaluated.\n\n            // The distance from start to a neighbor\n            tentative_gScore := gScore[current] + dist_between(current, neighbor)\n\n            if neighbor not in openSet\t// Discover a new node\n                openSet.Add(neighbor)\n            else if tentative_gScore >= gScore[neighbor]\n                continue\n\n            // This path is the best until now. Record it!\n            cameFrom[neighbor] := current\n            gScore[neighbor] := tentative_gScore\n            fScore[neighbor] := gScore[neighbor] + heuristic_cost_estimate(neighbor, goal) \n</source>\n\n'''Remark:''' the above pseudocode assumes that the heuristic function is  ''monotonic'' (or [[Consistent heuristic|consistent]], see below), which is a frequent case in many practical problems, such as the Shortest Distance Path in road networks. However, if the assumption is not true, nodes in the '''closed''' set may be rediscovered and their cost improved.  \nIn other words, the closed set can be omitted (yielding a tree search algorithm) if a solution is guaranteed to exist, or if the algorithm is adapted so that new nodes are added to the open set only if they have a lower ''f'' value than at any previous iteration.\n\n[[Image:Astar progress animation.gif|thumb|Illustration of A* search for finding path from a start node to a goal node in a [[robotics|robot]] [[motion planning]] problem. The empty circles represent the nodes in the ''open set'', i.e., those that remain to be explored, and the filled ones are in the closed set. Color on each closed node indicates the distance from the start: the greener, the farther. One can first see the A* moving in a straight line in the direction of the goal, then when hitting the obstacle, it explores alternative routes through the nodes from the open set. {{see also|Dijkstra's algorithm}}]]\n\n===Example===\nAn example of an A* algorithm in action where nodes are cities connected with roads and h(x) is the     straight-line distance to target point:\n\n[[File:AstarExampleEn.gif|An example of A* algorithm in action (nodes are cities connected with roads, h(x) is the straight-line distance to target point) Green: Start, Blue: Target, Orange: Visited]]\n\n'''Key:''' green: start; blue: goal; orange: visited\n\nThe A* algorithm also has real-world applications. In this example, edges are railroads and h(x) is the great-circle distance (the shortest possible distance on a sphere) to the target. The algorithm is searching for a path between Washington, D.C. and Los Angeles.\n\n[[File:A* Search Example on North American Freight Train Network.gif|The A* algorithm finding a path of railroads between Washington, D.C. and Los Angeles.]]\n\n==Properties==\nLike [[breadth-first search]], A* is ''complete'' and will always find a solution if one exists provided <math display=\"inline\">d(x,y)>\\varepsilon>0</math> for fixed <math>\\varepsilon</math>.\n\nIf the heuristic function ''h'' is [[admissible heuristic|admissible]], meaning that it never overestimates the actual minimal cost of reaching the goal, then A* is itself admissible (or ''optimal'') if we do not use a closed set. If a closed set is used, then ''h'' must also be ''monotonic'' (or [[consistent heuristic|consistent]]) for A* to be optimal. This means that for any pair of adjacent nodes ''x'' and ''y'', where {{tmath|d(x,y)}} denotes the length of the edge between them, we must have:\n\n:<math>h(x) \\le d(x,y) + h(y)</math>\n\nThis ensures that for any path ''X'' from the initial node to ''x'':\n\n:<math>L(X) + h(x) \\le L(X) + d(x,y) + h(y) = L(Y) + h(y)</math>\n\nwhere ''L'' is a function that denotes the length of a path, and ''Y'' is the path ''X'' extended to include ''y''. In other words, it is impossible to decrease (total distance so far + estimated remaining distance) by extending a path to include a neighboring node. (This is analogous to the restriction to nonnegative edge weights in [[Dijkstra's algorithm]].) Monotonicity implies admissibility when the heuristic estimate at any goal node itself is zero, since (letting ''P'' = (''f'',''v''<sub>1</sub>,''v''<sub>2</sub>,...,''v<sub>n</sub>'',''g'') be a shortest path from any node ''f'' to the nearest goal ''g''):\n\n:<math>h(f) \\le d(f,v_1) + h(v_1) \\le d(f,v_1) + d(v_1,v_2) + h(v_2) \\le \\ldots \\le L(P) + h(g) = L(P)</math>\n\nA* is also optimally efficient for any heuristic ''h'', meaning that no optimal algorithm employing the same heuristic will expand fewer nodes than A*, except when there are multiple partial solutions where ''h'' exactly predicts the cost of the optimal path. Even in this case, for each graph there exists some order of breaking ties in the priority queue such that A* examines the fewest possible nodes.\n\n===Special cases===\n[[Dijkstra's algorithm]], as another example of a uniform-cost search algorithm, can be viewed as a special case of A* where {{tmath|1=h(x) = 0}} for all ''x''.<ref name=\"geospatial\">{{citation|title=Geospatial Analysis: A Comprehensive Guide to Principles, Techniques and Software Tools|first1=Michael John|last1=De Smith|first2=Michael F.|last2=Goodchild|first3=Paul|last3=Longley|publisher=Troubadour Publishing Ltd|year=2007|isbn=9781905886609|page=344|url=https://books.google.com/books?id=SULMdT8qPwEC&pg=PA344}}.</ref><ref name=\"pythalgs\">{{citation|title=Python Algorithms: Mastering Basic Algorithms in the Python Language|first=Magnus Lie|last=Hetland|publisher=Apress|year=2010|isbn=9781430232377|page=214|url=https://books.google.com/books?id=9_AXCmGDiz8C&pg=PA214}}.</ref> General [[depth-first search]] can be implemented using A* by considering that there is a global counter ''C'' initialized with a very large value. Every time we process a node we assign ''C'' to all of its newly discovered neighbors. After each single assignment, we decrease the counter ''C'' by one. Thus the earlier a node is discovered, the higher its {{tmath|h(x)}} value. Both Dijkstra's algorithm and depth-first search can be implemented more efficiently without including an {{tmath|h(x)}} value at each node.\n\n===Implementation details===\nThere are a number of simple optimizations or implementation details that can significantly affect the performance of an A* implementation.  The first detail to note is that the way the priority queue handles ties can have a significant effect on performance in some situations.  If ties are broken so the queue behaves in a [[LIFO (computing)|LIFO]] manner, A* will behave like [[depth-first search]] among equal cost paths (avoiding exploring more than one equally optimal solution).\n\nWhen a path is required at the end of the search, it is common to keep with each node a reference to that node's parent.  At the end of the search these references can be used to recover the optimal path.  If these references are being kept then it can be important that the same node doesn't appear in the priority queue more than once (each entry corresponding to a different path to the node, and each with a different cost).  A standard approach here is to check if a node about to be added already appears in the priority queue.  If it does, then the priority and parent pointers are changed to correspond to the lower cost path. A standard [[binary heap]] based priority queue does not directly support the operation of searching for one of its elements, but it can be augmented with a [[hash table]] that maps elements to their position in the heap, allowing this decrease-priority operation to be performed in logarithmic time. Alternatively, a [[Fibonacci heap]] can perform the same decrease-priority operations in constant [[amortized time]].\n\n==Admissibility and optimality{{anchor|Admissibility and Optimality}}==\nA* is [[admissible heuristic|admissible]] and, in some circumstances, considers fewer nodes than any other admissible search algorithm with the same heuristic. This is because A* uses an \"optimistic\" estimate of the cost of a path through every node that it considers—optimistic in that the true cost of a path through that node to the goal will be at least as great as the estimate. But, critically, as far as A* \"knows\", that optimistic estimate might be achievable.\n\nTo prove the admissibility of A*, the solution path returned by the algorithm is used as follows:\n\nWhen A* terminates its search, it has found a path whose actual cost is lower than the estimated cost of any path through any open node. But since those estimates are optimistic, A* can safely ignore those nodes. In other words, A* will never overlook the possibility of a lower-cost path and so is admissible.\n\nSuppose now that some other search algorithm B terminates its search with a path whose actual cost is ''not'' less than the estimated cost of a path through some open node. Based on the heuristic information it has, Algorithm B cannot rule out the possibility that a path through that node has a lower cost. So while B might consider fewer nodes than A*, it cannot be admissible. Accordingly, A* considers the fewest nodes of any admissible search algorithm.\n\nThis is only true if both:\n\n* A* uses an [[admissible heuristic]]. Otherwise, A* is not guaranteed to expand fewer nodes than another search algorithm with the same heuristic.<ref name=\":1\">{{cite journal\n | first = Rina\n | last = Dechter\n |author2= Judea Pearl\n | title = Generalized best-first search strategies and the optimality of A*\n | journal = [[Journal of the ACM]]\n | volume = 32\n | issue = 3\n | pages = 505–536\n | year = 1985\n | doi = 10.1145/3828.3830\n | url=http://portal.acm.org/citation.cfm?id=3830&coll=portal&dl=ACM\n }}\n</ref>\n\n* A* solves only one search problem rather than a series of similar search problems. Otherwise, A* is not guaranteed to expand fewer nodes than [[incremental heuristic search]] algorithms.<ref>{{cite journal\n | first = Sven\n | last = Koenig\n |author2=Maxim Likhachev|author3=Yaxin Liu|author4=David Furcy\n | title = Incremental heuristic search in AI\n | journal = [[AI Magazine]]\n | volume = 25\n | issue = 2\n | pages = 99–112\n | year = 2004\n | url=http://portal.acm.org/citation.cfm?id=1017140\n }}\n</ref>\n\n[[Image:Weighted A star with eps 5.gif|thumb|A* search that uses a heuristic that is 5.0(=ε) times a [[consistent heuristic]], and obtains a suboptimal path.]]\n\n===Bounded relaxation===\nWhile the admissibility criterion guarantees an optimal solution path, it also means that A* must examine all equally meritorious paths to find the optimal path. To compute approximate shortest paths, it is possible to speed up the search at the expense of optimality by relaxing the admissibility criterion. Oftentimes we want to bound this relaxation, so that we can guarantee that the solution path is no worse than (1 + ''ε'') times the optimal solution path. This new guarantee is referred to as ''ε''-admissible.\n\nThere are a number of ''ε''-admissible algorithms:\n\n* Weighted A*/Static Weighting.<ref>{{cite journal\n | first = Ira\n | last = Pohl\n | title = First results on the effect of error in heuristic search\n | journal = Machine Intelligence\n | volume = 5\n | pages = 219–236\n | year = 1970\n}}</ref> If ''h<sub>a</sub>''(''n'') is an admissible heuristic function, in the weighted version of the A* search one uses {{math|1=''h<sub>w</sub>''(''n'') = ''ε h<sub>a</sub>''(''n'')}}, {{math|1=''ε'' > 1}} as the heuristic function, and perform the A* search as usual (which eventually happens faster than using ''h<sub>a</sub>'' since fewer nodes are expanded). The path hence found by the search algorithm can have a cost of at most ''ε'' times that of the least cost path in the graph.<ref name=\"pearl84\"/>\n\n* Dynamic Weighting<ref>{{cite conference\n | first = Ira\n | last = Pohl\n | title = The avoidance of (relative) catastrophe, heuristic competence, genuine dynamic weighting and computational issues in heuristic problem solving\n | booktitle = Proceedings of the Third International Joint Conference on Artificial Intelligence (IJCAI-73)\n | volume = 3\n | pages = 11–17\n | place = California, USA\n | date = August 1973\n | url = https://www.cs.auckland.ac.nz/courses/compsci709s2c/resources/Mike.d/Pohl1973WeightedAStar.pdf\n}}</ref> uses the cost function {{tmath|1=f(n) = g(n) + (1 + \\varepsilon w(n))h(n)}}, where <math>w(n) = \\begin{cases} 1 - \\frac{d(n)}{N} & d(n) \\le N \\\\ 0 & \\text{otherwise} \\end{cases}</math>, and where {{tmath|d(n)}} is the depth of the search and ''N'' is the anticipated length of the solution path.\n\n* Sampled Dynamic Weighting<ref>{{cite conference\n | first = Andreas\n | last = Köll\n |author2= Hermann Kaindl\n | title = A new approach to dynamic weighting\n | booktitle = Proceedings of the Tenth European Conference on Artificial Intelligence (ECAI-92)\n | pages = 16–17\n | place = Vienna, Austria\n | date = August 1992\n}}</ref> uses sampling of nodes to better estimate and debias the heuristic error.\n\n* <math>A^*_\\varepsilon</math>.<ref>{{cite journal\n | first = Judea\n | last = Pearl\n |author2= Jin H. Kim\n | title = Studies in semi-admissible heuristics\n | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)\n | volume = 4\n | issue = 4\n | pages = 392–399\n | year = 1982\n| doi = 10.1109/TPAMI.1982.4767270\n }}</ref> uses two heuristic functions. The first is the FOCAL list, which is used to select candidate nodes, and the second ''h<sub>F</sub>'' is used to select the most promising node from the FOCAL list.\n\n* ''A<sub>ε</sub>''<ref>{{cite conference\n |first=Malik \n |last=Ghallab \n |author2=Dennis Allard \n |title=''A<sub>ε</sub>'' – an efficient near admissible heuristic search algorithm \n |booktitle=Proceedings of the Eighth International Joint Conference on Artificial Intelligence (IJCAI-83) \n |volume=2 \n |pages=789–791 \n |place=Karlsruhe, Germany \n |date=August 1983 \n |url=http://ijcai.org/Past%20Proceedings/IJCAI-83-VOL-2/PDF/048.pdf \n |deadurl=yes \n |archiveurl=https://web.archive.org/web/20140806200328/http://ijcai.org/Past%20Proceedings/IJCAI-83-VOL-2/PDF/048.pdf \n |archivedate=2014-08-06 \n}}</ref> selects nodes with the function {{tmath|A f(n) + B h_F(n)}}, where ''A'' and ''B'' are constants. If no nodes can be selected, the algorithm will backtrack with the function {{tmath|C f(n) + D h_F(n)}}, where ''C'' and ''D'' are constants.\n\n* AlphA*<ref>{{cite journal\n |first        = Bjørn\n |last         = Reese\n |title        = AlphA*: An ''ε''-admissible heuristic search algorithm\n |year         = 1999\n |url          = http://home1.stofanet.dk/breese/astaralpha-submitted.pdf.gz\n |journal      = \n |access-date  = 2014-11-05\n |archive-url  = https://web.archive.org/web/20160131214618/http://home1.stofanet.dk/breese/astaralpha-submitted.pdf.gz\n |archive-date = 2016-01-31\n |dead-url     = yes\n |df           = \n}}</ref> attempts to promote depth-first exploitation by preferring recently expanded nodes. AlphA* uses the cost function <math>f_\\alpha(n) = (1 + w_\\alpha(n)) f(n)</math>, where <math>w_\\alpha(n) = \\begin{cases} \\lambda & g(\\pi(n)) \\le g(\\tilde{n}) \\\\ \\Lambda & \\text{otherwise} \\end{cases}</math>, where ''λ'' and ''Λ'' are constants with <math>\\lambda \\le \\Lambda</math>, ''π''(''n'') is the parent of ''n'', and ''ñ'' is the most recently expanded node.\n\n==Complexity==\nThe [[computational complexity theory|time complexity]] of A* depends on the heuristic. In the worst case of an unbounded search space, the number of nodes expanded is [[exponential time|exponential]] in the depth of the solution (the shortest path) {{mvar|d}}: {{math|''O''(''b<sup>d</sup>'')}}, where {{mvar|b}} is the [[branching factor]] (the average number of successors per state).<ref name=\"aima\"/> This assumes that a goal state exists at all, and is [[reachability|reachable]] from the start state; if it is not, and the state space is infinite, the algorithm will not terminate.\n\nThe heuristic function has a major effect on the practical performance of A* search, since a good heuristic allows A* to prune away many of the {{mvar|b<sup>d</sup>}} nodes that an uninformed search would expand. Its quality can be expressed in terms of the ''effective'' branching factor {{math|''b''*}}, which can be determined empirically for a problem instance by measuring the number of nodes expanded, {{mvar|N}}, and the depth of the solution, then solving<ref name=\"aima3\">{{cite AIMA |edition=3 |pages=103}}</ref>\n\n:<math>N + 1 = 1 + b^* + (b^*)^2 + \\dots + (b^*)^d.</math>\n\nGood heuristics are those with low effective branching factor (the optimal being {{math|''b''* {{=}} 1}}).\n\nThe time complexity is [[polynomial time|polynomial]] when the search space is a tree, there is a single goal state, and the heuristic function ''h'' meets the following condition:\n\n:<math>|h(x) - h^*(x)| = O(\\log h^*(x))</math>\n\nwhere {{math|''h''<sup>*</sup>}} is the optimal heuristic, the exact cost to get from {{mvar|x}} to the goal. In other words, the error of {{mvar|h}} will not grow faster than the [[logarithm]] of the \"perfect heuristic\" {{math|''h''<sup>*</sup>}} that returns the true distance from {{mvar|x}} to the goal.<ref name=\"pearl84\">{{cite book\n | first = Judea\n | last = Pearl\n | title = Heuristics: Intelligent Search Strategies for Computer Problem Solving\n | publisher = Addison-Wesley\n | year = 1984\n | isbn = 978-0-201-05594-8\n }}</ref><ref name=\"aima\">{{cite AIMA |edition=2 |pages = 97–104}}</ref>\n\n==Applications==\nA* is commonly used for the common pathfinding problem in applications such as video games, but was originally designed as a general graph traversal algorithm.<ref name=\"nilsson\"/>\nIt finds applications to diverse problems, including the problem of [[parsing]] using [[Stochastic context-free grammar|stochastic grammars]] in [[Natural language processing|NLP]].<ref>{{cite conference\n|last1=Klein\n|first1=Dan\n|last2=Manning\n|first2=Christopher D.\n|title=A* parsing: fast exact Viterbi parse selection\n|conference=Proc. NAACL-HLT\n|year=2003\n}}</ref>\nOther cases include an Informational search with online learning.<ref name=\"WPCleanerAuto1\">{{cite journal\n|url= http://www.eng.tau.ac.il/~bengal/GTA.pdf\n|title=A Group-Testing Algorithm with Online Informational Learning\n|author= Kagan E. and Ben-Gal I. \n|publisher= IIE Transactions, 46:2, 164-184\n|year=2014\n}}</ref>\n\n==Relations to other algorithms==\nWhat sets A* apart from a [[greedy algorithm|greedy]] best-first search algorithm is that it takes the cost/distance already traveled, {{math|''g''(''n'')}}, into account.\n\nSome common variants of [[Dijkstra's algorithm]] can be viewed as a special case of A* where the heuristic <math>h(n) = 0</math> for all nodes;<ref name=\"geospatial\"/><ref name=\"pythalgs\"/> in turn, both Dijkstra and A* are special cases of [[dynamic programming]].<ref>{{cite conference |first1=Dave |last1=Ferguson |first2=Maxim |last2=Likhachev |first3=Anthony |last3=Stentz |title=A Guide to Heuristic-based Path Planning |conference=Proc. ICAPS Workshop on Planning under Uncertainty for Autonomous Systems |year=2005 |url=https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/maxim/files/hsplanguide_icaps05ws.pdf}}</ref>\nA* itself is a special case of a generalization of [[branch and bound]]<ref>{{cite journal |last1=Nau |first1=Dana S. |first2=Vipin |last2=Kumar |first3=Laveen |last3=Kanal |title=General branch and bound, and its relation to A∗ and AO∗ |journal=Artificial Intelligence |volume=23 |issue=1 |year=1984 |pages=29–58 |url=https://www.cs.umd.edu/~nau/papers/nau1984general.pdf |doi=10.1016/0004-3702(84)90004-3}}</ref>\nand can be derived from the primal-dual algorithm for [[linear programming]].<ref>{{cite journal |title=A Note on the Connection Between the Primal-Dual and the A* Algorithm |first1=Xugang |last1=Ye |first2=Shih-Ping |last2=Han |first3=Anhua |last3=Lin |journal=International Journal of Operations Research and Information Systems |volume=1 |issue=1 |pages=73–85 |year=2010|doi=10.4018/joris.2010101305 }}</ref>\n\n==Variants==\n*[[Anytime A*]]<ref>Hansen, Eric A., and Rong Zhou. \"[http://www.jair.org/media/2096/live-2096-3136-jair.pdf?q=anytime: Anytime Heuristic Search.]\" J. Artif. Intell. Res.(JAIR) 28 (2007): 267-297.</ref> or Anytime Repairing A* (ARA*)<ref>Likhachev, Maxim; Gordon, Geoff; Thrun, Sebastian. \"[http://robots.stanford.edu/papers/Likhachev03b.pdf ARA*: Anytime A* search with provable bounds on sub-optimality]\". In S. Thrun, L. Saul, and B. Schölkopf, editors, ''Proceedings of Conference on Neural Information Processing Systems (NIPS)'', Cambridge, MA, 2003. MIT Press.</ref>\n*[[Anytime Dynamic A*]]\n*[[Any-angle path planning#A*-based|Block A*]]\n*[[D*]]\n*[[Any-angle path planning|Field D*]]\n*[[Fringe search|Fringe]]\n*[[Incremental heuristic search|Fringe Saving A* (FSA*)]]\n*[[Incremental heuristic search|Generalized Adaptive A* (GAA*)]]\n*[[Incremental heuristic search]]\n*[[Informational search]]<ref name=\"WPCleanerAuto1\" /> \n*[[Iterative deepening A*|Iterative deepening A* (IDA*)]]\n*[[Jump point search]]\n*[[Lifelong Planning A*|Lifelong Planning A* (LPA*)]]\n*[[New Bidirectional A*|New Bidirectional A* (NBA*)]]<ref>Pijls, Wim; Post, Henk \"[https://repub.eur.nl/pub/16100/ei2009-10.pdf Yet another bidirectional algorithm for shortest paths]\" In ''Econometric Institute Report EI 2009-10/Econometric Institute, Erasmus University Rotterdam. Erasmus School of Economics.''</ref>\n*[[SMA*|Simplified Memory bounded A* (SMA*)]]\n*[[Realtime A*]]<ref>Korf, Richard E. \"[https://pdfs.semanticscholar.org/2fda/10f6079156c4621fefc8b7cad72c1829ee94.pdf Real-time heuristic search.]\" Artificial intelligence 42.2-3 (1990): 189-211.</ref> \n*[[Theta*]]\n*[[Time-Bounded A*|Time-Bounded A* (TBA*)]]<ref>{{cite conference | url = http://web.cs.du.edu/~sturtevant/papers/TBA.pdf | title = TBA*: time-bounded A* | first1 = Yngvi | last1 = Björnsson | first2 = Vadim | last2 = Bulitko | first3 = Nathan | last3 = Sturtevant | date = July 11–17, 2009 | conference =  IJCAI 2009, Proceedings of the 21st International Joint Conference on Artificial Intelligence | publisher = Morgan Kaufmann Publishers Inc. | location = Pasadena, California, USA | pages = 431–436}}</ref>\n\nA* can also be adapted to a [[bidirectional search]] algorithm. Special care needs to be taken for the stopping criterion.<ref>{{cite journal\n | title = Efficient Point-to-Point Shortest Path Algorithms\n | url = http://www.cs.princeton.edu/courses/archive/spr06/cos423/Handouts/EPP%20shortest%20path%20algorithms.pdf\n}} from [[Princeton University]]</ref>\n\n==See also==\n*[[Breadth-first search]]\n*[[Depth-first search]]\n*[[Any-angle path planning]], search for paths that are not limited to move along graph edges but rather can take on any angle\n\n==Notes==\n{{notelist}}\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n* {{cite journal\n | first = P. E.\n | last = Hart\n |author2= Nilsson, N. J.|author3= Raphael, B.\n | title = Correction to \"A Formal Basis for the Heuristic Determination of Minimum Cost Paths\"\n | journal = SIGART Newsletter\n | volume = 37\n | issue = 37\n | pages = 28–29\n | year = 1972\n | doi=10.1145/1056777.1056779\n }}\n* {{cite book\n | first = N. J.\n | last = Nilsson\n | title = Principles of Artificial Intelligence\n | publisher = Tioga Publishing Company\n | location = Palo Alto, California\n | year = 1980\n | isbn = 978-0-935382-01-3\n }}\n\n==External links==\n* [http://theory.stanford.edu/~amitp/GameProgramming/ Clear visual A* explanation, with advice and thoughts on path-finding]\n* Variation on A* called [http://www.cs.ualberta.ca/~mmueller/ps/hpastar.pdf Hierarchical Path-Finding A* (HPA*)]\n\n{{DEFAULTSORT:A Search Algorithm}}\n[[Category:Graph algorithms]]\n[[Category:Routing algorithms]]\n[[Category:Search algorithms]]\n[[Category:Combinatorial optimization]]\n[[Category:Game artificial intelligence]]\n[[Category:Articles with example pseudocode]]"
    },
    {
      "title": "B*",
      "url": "https://en.wikipedia.org/wiki/B%2A",
      "text": "{{about|a graph search algorithm|variant of [[B-Tree]]|B*-tree}}\n{{graph search algorithm}}\nIn [[computer science]], '''B*''' (pronounced \"B star\") is a [[best-first search|best-first]] [[graph search algorithm]] that finds the least-cost path from a given initial [[node (graph theory)|node]] to any [[goal node]] (out of one or more possible goals). First published by [[Hans Berliner]] in 1979, it is related to the [[A* search algorithm]].\n\n==Summary==\nThe algorithm stores intervals for nodes of the [[tree (graph theory)|tree]] as opposed to single point-valued estimates. Then, leaf nodes of the tree can be searched until one of the top level nodes has an interval which is clearly \"best.\"\n\n==Details==\n\n===Interval evaluations rather than estimates===\nLeaf nodes of a B*-tree are given evaluations that are intervals rather than single numbers. The interval is supposed to contain the true value of that node. If all intervals attached to leaf nodes satisfy this property, then B* will identify an optimal path to the goal state.\n\n===Backup process===\nTo back up the intervals within the tree, a parent's upper bound is set to the maximum of the upper bounds of the children. A parent's lower bound is set to the maximum of the lower bound of the children. Note that different children might supply these bounds.\n\n===Termination of search===\nB* systematically expands nodes in order to create \"separation,\" which occurs when the lower bound of a direct child of the root is at least as large as the upper bound of any other direct child of the root. A tree that creates separation at the root contains a proof that the best child is at least as good as any other child.\n\nIn practice, complex searches might not terminate within practical resource limits. So the algorithm is normally augmented with artificial termination criteria such as time or memory limits. When an artificial limit is hit, then you must make a heuristic judgment about which move to select. Normally, the tree would supply you with extensive evidence, like the intervals of root nodes.\n\n===Expansion===\nB* is a best-first process, which means that it is very efficient to traverse the tree, repeatedly descending to find a leaf to expand. This section describes how to choose the node to expand.  (Note: Whether or not the tree is memory-resident, is a function of the overall implementation efficiency, including how it may be mapped and/or managed via real or virtual memory.) \n\nAt the root of the tree, the algorithm applies one of two strategies, called prove-best and disprove-rest. In the prove-best strategy, the algorithm selects the node associated with the highest upper bound. The hope is that expanding that node will raise its lower bound higher than any other node's upper bound.\n\nThe disprove-rest strategy selects the child of the root that has the second-highest upper bound. The hope is that by expanding that node you might be able to reduce the upper bound to less than the lower bound of the best child.\n\n====Strategy selection====\nNote that applying the disprove-rest strategy is pointless until the lower bound of the child node that has the highest upper bound is the highest among all lower bounds.\n\nThe original algorithm description did not give any further guidance on which strategy to select. There are several reasonable alternatives, such as expanding the choice that has the smaller tree.\n\n====Strategy selection at non-root nodes====\nOnce a child of the root has been selected (using prove-best or disprove-best) then the algorithm descends to a leaf node by repeatedly selecting the child that has the highest upper bound.\n\nWhen a leaf node is reached, the algorithm generates all successor nodes and assigns intervals to them using the evaluation function. Then the intervals of all nodes have to be backed up using the backup operation.\n\nWhen transpositions are possible, then the back-up operation might need to alter the values of nodes that did not lie on the selection path. In this case, the algorithm needs pointers from children to all parents so that changes can be propagated. Note that propagation can cease when a backup operation does not change the interval associated with a node.\n\n===Robustness===\nIf intervals are incorrect (in the sense that the game-theoretic value of the node is not contained within the interval), then B* might not be able to identify the correct path. However, the algorithm is fairly robust to errors in practice.\n\nThe [[Maven (Scrabble)]] program has an innovation that improves the robustness of B* when evaluation errors are possible. If a search terminates due to separation then Maven restarts the search after widening all of the evaluation intervals by a small amount. This policy progressively widens the tree, eventually erasing all errors.\n\n===Extension to two-player games===\nThe B* algorithm applies to two-player deterministic zero-sum games. In fact, the only change is to interpret \"best\" with respect to the side moving in that node. So you would take the maximum if your side is moving, and the minimum if the opponent is moving. Equivalently, you can represent all intervals from the perspective of the side to move, and then negate the values during the back-up operation.\n\n===Applications===\nAndrew Palay applied B* to chess. Endpoint evaluations were assigned by performing null-move searches. There is no report of how well this system performed compared to [[alpha-beta pruning]] search engines running on the same hardware.\n\nThe [[Maven (Scrabble)]] program applied B* search to endgames. Endpoint evaluations were assigned using a heuristic planning system. \n\nThe B* search algorithm has been used to compute optimal strategy in a sum game of a set of combinatorial games.\n\n==See also==\n* [[Branch and bound]]\n\n==References==\n* {{cite journal\n | first = Hans\n | last = Berliner\n | title = The B* Tree Search Algorithm. A Best-First Proof Procedure.\n | journal = [[Artificial Intelligence (journal)|Artificial Intelligence]]\n | volume = 12\n | issue = 1\n | pages = 23–40\n | year = 1979\n | doi=10.1016/0004-3702(79)90003-1\n | url = http://www.dtic.mil/get-tr-doc/pdf?AD=ADA059391\n }}\n* {{cite book\n | first = S. J.\n | last = Russell\n |author2=Norvig, P.\n | title = [[Artificial Intelligence: A Modern Approach]]\n | year = 2003\n | pages = 188\n | isbn = 0-13-790395-2\n | publisher = Prentice Hall\n | location = Upper Saddle River, N.J.\n }}\n* {{cite journal\n | first = Brian\n | last = Sheppard\n | title = World-championship-caliber Scrabble.\n | journal = [[Artificial Intelligence (journal)|Artificial Intelligence]]\n | volume = 134\n | issue = 1-2\n | pages = 241–275\n | year = 2002\n | doi=10.1016/S0004-3702(01)00166-7\n }}\n\n{{DEFAULTSORT:B star Search Algorithm}}\n[[Category:Graph algorithms]]\n[[Category:Routing algorithms]]\n[[Category:Search algorithms]]\n[[Category:Combinatorial optimization]]\n[[Category:Game artificial intelligence]]"
    },
    {
      "title": "Bottleneck traveling salesman problem",
      "url": "https://en.wikipedia.org/wiki/Bottleneck_traveling_salesman_problem",
      "text": "The '''Bottleneck traveling salesman problem''' ('''bottleneck TSP''') is a problem in [[discrete optimization|discrete]] or [[combinatorial optimization]].  The problem is to find the [[Hamiltonian path|Hamiltonian cycle]] in a [[weighted graph]] which minimizes the weight of the most weighty [[Edge (graph theory)|edge]] of the cycle.<ref name=\"kp07\">{{citation\n | last1 = Kabadi | first1 = Santosh N.\n | last2 = Punnen | first2 = Abraham P.\n | editor1-last = Gutin | editor1-first = Gregory\n | editor2-last = Punnen | editor2-first = Abraham P.\n | contribution = The bottleneck TSP\n | doi = 10.1007/0-306-48213-4_15\n | pages = 697–735\n | publisher = Springer\n | series = Combinatorial Optimization\n | title = The Traveling Salesman Problem and Its Variations\n | year = 2007}}.</ref> It was first formulated by {{harvtxt|Gilmore|Gomory|1964}} with some additional constraints, and in its full generality by {{harvtxt|Garfinkel|Gilbert|1978}}.<ref name=\"kp07\"/><ref>{{citation\n | last1 = Gilmore | first1 = P. C.\n | last2 = Gomory | first2 = R. E. | author2-link = Ralph E. Gomory\n | doi = 10.1287/opre.12.5.655\n | journal = Oper. Res.\n | jstor = 167772\n | pages = 655–679\n | title = Sequencing a one state-variable machine: A solvable case of the traveling salesman problem\n | volume = 12\n | year = 1964}}.</ref><ref>{{citation\n | last1 = Garfinkel | first1 = R. S.\n | last2 = Gilbert | first2 = K. C.\n | doi = 10.1145/322077.322086\n | issue = 3\n | journal = [[Journal of the ACM]]\n | pages = 435–448\n | title = The bottleneck traveling salesman problem: Algorithms and probabilistic analysis\n | volume = 25\n | year = 1978}}.</ref>\n\n==Complexity==\nThe problem is known to be [[NP-hard]]. The [[decision problem]] version of this, \"for a given length {{mvar|x}} is there a Hamiltonian cycle in a graph {{mvar|G}} with no edge longer than {{mvar|x}}?\", is [[NP-complete]]. NP-completeness follows immediately by a [[Reduction (complexity)|reduction]] from the problem of finding a Hamiltonian cycle.<ref name=gj>{{citation\n | last1 = Garey | first1 = Michael R. | author1-link = Michael R. Garey\n | last2 = Johnson | first2 = David S. | author2-link = David S. Johnson\n | isbn = 0-7167-1045-5\n | publisher = W.H. Freeman\n | title = [[Computers and Intractability: A Guide to the Theory of NP-Completeness]]\n | year = 1979\n | at = A2.3: ND24, p.&nbsp;212}}.</ref>\n\n==Algorithms==\nAnother reduction, from the bottleneck TSP to the usual TSP (where the goal is to minimize the sum of edge lengths), allows any algorithm for the usual TSP to also be used to solve the bottleneck TSP.\nIf the edge weights of  the bottleneck TSP are replaced by any other numbers that have the same relative order, then the bottleneck solution remains unchanged.\nIf, in addition, each number in the sequence exceeds the sum of all smaller numbers, then the bottleneck solution will also equal the usual TSP solution.\nFor instance, such a result may be attained by resetting each weight to {{math|''n''<sup>''i''</sup>}} where {{mvar|n}} is the number of vertices in the graph and {{mvar|i}} is the rank of the original weight of the edge in the sorted sequence of weights. For instance, following this transformation, the [[Held–Karp algorithm]] could be used to solve the bottleneck TSP in time {{math|''O''(''n''<sup>2</sup>2<sup>''n''</sup>)}}.<ref name=\"kp07\"/>\n\nAlternatively, the problem can be solved by performing a [[binary search]] or [[sequential search]] for the smallest {{mvar|x}} such that the subgraph of edges of weight at most {{mvar|x}} has a Hamiltonian cycle. This method leads to solutions whose running time is only a logarithmic factor larger than the time to find a Hamiltonian cycle.<ref name=\"kp07\"/>\n\n==Variations==\n\nIn an '''asymmetric bottleneck TSP''', there are cases where the weight from node ''A'' to ''B'' is different from the weight from B to A (e. g. travel time between two cities with a traffic jam in one direction).\n\nThe '''Euclidean bottleneck TSP''', or planar bottleneck TSP, is the bottleneck TSP with the distance being the ordinary [[Euclidean distance]]. The problem still remains NP-hard. However, many heuristics work better for it than for other distance functions.\n\nThe '''maximum scatter traveling salesman problem''' is another variation of the traveling salesman problem in which the goal is to find a Hamiltonian cycle that maximizes the minimum edge length rather than minimizing the maximum length. Its applications include the analysis of medical images, and the scheduling of metalworking steps in aircraft manufacture to avoid heat buildup from steps that are nearby in both time and space. It can be translated into an instance of the bottleneck TSP problem by negating all edge lengths (or, to keep the results positive, subtracting them all from a large enough constant). However, although this transformation preserves the optimal solution, it does not preserve the quality of approximations to that solution.<ref name=\"kp07\"/>\n\n==Metric approximation algorithm==\nIf the graph is a [[metric space]] then there is an efficient [[approximation algorithm]] that finds a Hamiltonian cycle with maximum edge weight being no more than twice the optimum.\nThis result follows by [[Fleischner's theorem]], that the [[Graph power|square]] of a [[k-vertex-connected graph|2-vertex-connected graph]] always contains a Hamiltonian cycle. It is easy to find a threshold value {{mvar|&theta;}}, the smallest value such that the edges of weight {{mvar|&theta;}} form a 2-connected graph. Then {{mvar|&theta;}} provides a valid lower bound on the bottleneck TSP weight, for the bottleneck TSP is itself a 2-connected graph and necessarily contains an edge of weight at least {{mvar|&theta;}}. However, the square of the subgraph of edges of weight at most {{mvar|&theta;}} is Hamiltonian. By the [[triangle inequality]] for metric spaces, its Hamiltonian cycle has edges of weight at most {{math|2''&theta;''}}.<ref>{{citation\n | last1 = Parker | first1 = R. Garey\n | last2 = Rardin | first2 = Ronald L.\n | doi = 10.1016/0167-6377(84)90077-4\n | issue = 6\n | journal = Operations Research Letters\n | pages = 269–272\n | title = Guaranteed performance heuristics for the bottleneck traveling salesman problem\n | volume = 2\n | year = 1984}}.</ref><ref name=\"hs\">{{citation\n | last1 = Hochbaum | first1 = Dorit S. | author1-link = Dorit S. Hochbaum\n | last2 = Shmoys | first2 = David B. | author2-link = David Shmoys\n | date = May 1986\n | doi = 10.1145/5925.5933\n | issue = 3\n | journal = Journal of the ACM\n | location = New York, NY, USA\n | pages = 533–550\n | publisher = ACM\n | title = A unified approach to approximation algorithms for bottleneck problems\n | url = https://www.researchgate.net/profile/David_Shmoys/publication/220430962_A_unified_approach_to_approximation_algorithms_for_bottleneck_problems/links/57dc685508ae4e6f1846abde.pdf\n | volume = 33}}.</ref>\n\nThis approximation ratio is best possible. For, any unweighted graph can be transformed into a metric space by setting its edge weights to {{math|1}} and setting the distance between all nonadjacent pairs of vertices to {{math|2}}. An approximation with ratio better than {{math|2}} in this metric space could be used to determine whether the original graph contains a Hamiltonian cycle, an NP-complete problem.<ref name=\"hs\"/>\n\nWithout the assumption that the input is a metric space, no finite approximation ratio is possible.<ref name=\"kp07\"/>\n\n==See also==\n*[[Travelling salesman problem]] \n\n== References ==\n{{reflist}}\n\n[[Category:Combinatorial optimization]]\n[[Category:Graph algorithms]]\n[[Category:Hamiltonian paths and cycles]]"
    },
    {
      "title": "Bridge and torch problem",
      "url": "https://en.wikipedia.org/wiki/Bridge_and_torch_problem",
      "text": "The '''bridge and torch problem''' (also known as ''The Midnight Train''<ref name=\"mm\">{{cite web|title=MURDEROUS MATHS BRAINBENDERS|url=http://www.murderousmaths.co.uk/books/BKMMPxbb.htm|accessdate=2008-02-08}}</ref> and ''Dangerous crossing''<ref name=\"webam\">{{cite web|title=Some simple and not so simple maths problems|author=Gleb Gribakin|url=http://web.am.qub.ac.uk/users/g.gribakin/problems.html|accessdate=2008-02-08}}</ref>) is a [[logic puzzle]] that deals with four people, a bridge and a torch.  It is one of the category of [[river crossing puzzle]]s, where a number of objects must move across a river, with some constraints.<ref name=a>[http://www.sciencenews.org/articles/20031213/mathtrek.asp Tricky Crossings], Ivars Peterson, ''Science News'', '''164''', #24 (December 13, 2003); accessed on line February 7, 2008.</ref>\n\n==Story==\nFour people come to a river in the night. There is a narrow bridge, but it can only hold two people at a time. They have one torch and, because it's night, the torch has to be used when crossing the bridge. Person A can cross the bridge in 1 minute, B in 2 minutes, C in 5 minutes, and D in 8 minutes. When two people cross the bridge together, they must move at the slower person's pace. The question is, can they all get across the bridge if the torch lasts only 15 minutes?<ref name=webam />\n\n==Solution==\n\nAn obvious first idea is that the cost of returning the torch to the people waiting to cross is an unavoidable expense which should be minimized. This strategy makes A the torch bearer, shuttling each person across the bridge:<ref name=eatcs />\n\n{| class=\"wikitable\"\n|-\n! Elapsed Time\n! Starting Side\n! Action\n! Ending Side\n|-\n| 0 minutes\n| A B C D\n|\n|\n|-\n| 2 minutes\n| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C D\n| A and B cross forward, taking 2 minutes\n| A B\n|-\n| 3 minutes\n| A &nbsp;&nbsp;&nbsp;C D\n| A returns, taking 1 minute\n| &nbsp;&nbsp;&nbsp;B\n|-\n| 8 minutes\n| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D\n| A and C cross forward, taking 5 minutes\n| A B C\n|-\n| 9 minutes\n| A&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D\n| A returns, taking 1 minute\n| &nbsp;&nbsp;&nbsp;B C\n|-\n| 17 minutes\n|\n| A and D cross forward, taking 8 minutes\n| A B C D\n|}\n\nThis strategy does not permit a crossing in 15 minutes.  To find the correct solution, one must realize that forcing the two slowest people to cross individually wastes time which can be saved if they both cross together:<ref name=eatcs />\n\n{| class=\"wikitable\"\n|-\n! Elapsed Time\n! Starting Side\n! Action\n! Ending Side\n|-\n| 0 minutes\n| A B C D\n|\n|\n|-\n| 2 minutes\n| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C D\n| A and B cross forward, taking 2 minutes\n| A B\n|-\n| 3 minutes\n| A &nbsp;&nbsp;&nbsp;C D\n| A returns, taking 1 minute\n| &nbsp;&nbsp;&nbsp;B\n|-\n| 11 minutes\n| A\n| C and D cross forward, taking 8 minutes\n| &nbsp;&nbsp; B C D\n|-\n| 13 minutes\n| A B\n| B returns, taking 2 minutes\n| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; C D\n|-\n| 15 minutes\n|\n| A and B cross forward, taking 2 minutes\n| A B C D\n|}\n\nA second equivalent solution swaps the return trips.  Basically, the two fastest people cross together on the 1st and 5th trips, the two slowest people cross together on the 3rd trip, and EITHER of the fastest people returns on the 2nd trip, and the other fastest person returns on the 4th trip.\n\n==A semi-formal approach==\n{{Unreferenced section|date=July 2014}}\n\nAssume that a solution minimizes the total number of crossings. This gives a total of five crossings - three pair crossings and two solo-crossings. Also, assume we always choose the fastest for the solo-cross. First, we show that if the two slowest persons (C and D) cross separately, they accumulate a total crossing time of 15. This is done by taking persons A, C, & D: C+A+D+A = 5+1+8+1=15. (Here we use A because we know that using A to cross both C and D separately is the most efficient.) But, the time has elapsed and person A and B are still on the starting side of the bridge and must cross. So it is not possible for the two slowest (C & D) to cross separately. Second, we show that in order for C and D to cross together that they need to cross on the second pair-cross: i.e. not C or D, so A and B, must cross together first. Remember our assumption at the beginning states that we should minimize crossings and so we have five crossings - 3 pair-crossings and 2 single crossings. Assume that C and D cross first. But then C or D must cross back to bring the torch to the other side, and so whoever solo-crossed must cross again. Hence, they will cross separately. Also, it is impossible for them to cross together last, since this implies that one of them must have crossed previously, otherwise there would be three persons total on the start side. So, since there are only three choices for the pair-crossings and C and D cannot cross first or last, they must cross together on the second, or middle, pair-crossing. Putting all this together, A and B must cross first, since we know C and D cannot and we are minimizing crossings. Then, A must cross next, since we assume we should choose the fastest to make the solo-cross. Then we are at the second, or middle, pair-crossing so C and D must go. Then we choose to send the fastest back, which is B. A and B are now on the start side and must cross for the last pair-crossing. This gives us, B+A+D+B+B = 2+1+8+2+2 = 15.\n\n==Variations and history==\nSeveral variations exist, with cosmetic variations such as differently named people, or variation in the crossing times or time limit.<ref name=\"visi\">{{cite web|title=The Bridge Crossing Puzzle|url=http://www.visi.com/cgi-bin/cgiwrap/~heyyousir/bridge.cgi|deadurl=yes|archiveurl=https://web.archive.org/web/20080531013610/http://www.visi.com/cgi-bin/cgiwrap/~heyyousir/bridge.cgi|archivedate=2008-05-31|df=}}</ref>  The torch itself may expire in a short time and so serve as the time limit.  In a variation called ''The Midnight Train'', for example, person D needs 10 minutes instead of 8 to cross the bridge, and persons A, B, C and D, now called the four Gabrianni brothers, have 17 minutes to catch the midnight train.<ref name=\"mm\" />\n\nThe puzzle is known to have appeared as early as 1981, in the book ''Super Strategies For Puzzles and Games''.  In this version of the puzzle, A, B, C and D take 5, 10, 20, and 25 minutes, respectively, to cross, and the time limit is 60 minutes.<ref name=\"sillke\">{{cite web|url=http://www.mathematik.uni-bielefeld.de/~sillke/PUZZLES/crossing-bridge|title=Crossing the bridge in an hour|author=Torsten Sillke|date=September 2001|accessdate=2008-02-09}}</ref><ref>{{Cite book | last1 = Levmore | first1 = Saul X. | last2 = Cook | first2 = Elizabeth Early | title = Super strategies for puzzles and games | publisher = Doubleday & Company | place = Garden City, New York | year = 1981 | isbn = 0-385-17165-X | postscript = <!--None-->}}</ref>  In all these variations, the structure and solution of the puzzle remain the same.\n\nIn the case where there are an arbitrary number of people with arbitrary crossing times, and the capacity of the bridge remains equal to two people, the problem has been completely analyzed by [[graph-theoretic]] methods.<ref name=eatcs>{{Cite news | last = Rote | first = Günter | year = 2002 | title = Crossing the bridge at night | periodical = Bulletin of the European Association for Theoretical Computer Science | volume = 78 | pages = 241–246 |url=http://page.mi.fu-berlin.de/%7Erote/Papers/pdf/Crossing+the+bridge+at+night.pdf | postscript = <!--None-->}}</ref>\n\nMartin Erwig from Oregon State University has used a variation of the problem to argue for the usability of the Haskell programming language over Prolog for solving [[ search problem | search problems]].<ref name=ezurg>{{Cite web | last = Erwig | first = Martin | title = Escape from Zurg | url=http://web.engr.oregonstate.edu/~erwig/papers/Zurg_JFP04.pdf | year = 2004 | publisher = Journal of Functional Programming, Vol. 14, No. 3| pages = 253–261  | postscript = <!--None-->}}</ref>\n\nThe puzzle is also mentioned in Daniel Dennett's book ''[[From Bacteria to Bach and Back]]'' as his favorite example of a solution that is counter-intuitive.\n\n==See also==\n* [[River crossing puzzle]]\n\n<!-- * This puzzle has been updated to a U2 Concert, e.g. [http://groups.google.com/group/rec.puzzles/browse_thread/thread/cc40ad2904f58da0/5b1fa80d34e704c9?lnk=gst&q=concert#5b1fa80d34e704c9 rec.puzzles thread (Google Groups)] -->\n\n==References==\n{{reflist}}\n\n==External links==\n* Slides of the Capacity C Torch Problem [https://web.archive.org/web/20110811160332/http://aps.cs.nott.ac.uk/wp-content/uploads/2008/05/capacity-c-torch-problem-aps-club.pdf]\n* Paper discussing the Capacity C Torch Problem [http://www.cs.nott.ac.uk/~rcb/MPC/GeneralTorchProblem.ps]\n* Ted Ed Video and Exercise Based on Bridge and Torch Problem [https://ed.ted.com/lessons/can-you-solve-the-bridge-riddle-alex-gendler]\n* Paper discussing A Systematic Solution to the Bridge Riddle using Combinatorics [https://doi.org/10.21256/zhaw-4057]\n\n{{DEFAULTSORT:Bridge And Torch Problem}}\n[[Category:Combinatorial optimization]]\n[[Category:Logic puzzles]]"
    },
    {
      "title": "Change-making problem",
      "url": "https://en.wikipedia.org/wiki/Change-making_problem",
      "text": "The '''change-making problem''' addresses the question of finding the minimum number of coins (of certain denominations) that add up to a given amount of money. It is a special case of the integer [[knapsack problem]], and has applications wider than just currency.\n\nIt is also the most common variation of the ''coin change problem'', a general case of [[partition problem|partition]] in which, given the available denominations of an infinite set of coins, the objective is to find out the number of possible ways of making a change for a specific amount of money, without considering the order of the coins.\n\nIt is [[Weak NP-completeness|weakly NP-hard]], but may be solved optimally in [[pseudo-polynomial time]] by [[dynamic programming]].<ref>{{cite book\n | last1 = Cormen | first1 = Thomas H.\n | last2 = Leiserson | first2 = Charles E.\n | last3 = Rivest | first3 = Ronald L.\n | last4 = Stein | first4 = Clifford\n | at = Problem 16-1, p. 446\n | publisher = MIT Press\n | title = [[Introduction to Algorithms]]\n | year = 2009}}</ref><ref>{{cite book\n | last1 = Goodrich | first1 = Michael T.\n | last2 = Tamassia | first2 = Roberto\n | at = Exercise A-12.1, p. 349\n | publisher = Wiley\n | title = Algorithm Design and Applications\n | year = 2015}}</ref>\n\n==Mathematical definition==\nCoin values can be modeled by a set of {{mvar|n}} distinct positive [[integer]] values (whole numbers), arranged in increasing order as {{math|''w''<sub>1</sub> {{=}} 1}} through {{math|''w''<sub>''n''</sub>}}. The problem is: given an amount {{mvar|W}}, also a positive integer, to find a set of non-negative (positive or zero) integers {{math|{''x''<sub>1</sub>, ''x''<sub>2</sub>, ..., ''x''<sub>''n''</sub>}}}, with each {{math|''x''<sub>''j''</sub>}} representing how often the coin with value {{math|''w''<sub>''j''</sub>}} is used, which minimize the total number of coins {{math|''f''(''W'')}}\n\n: <math>f(W)=\\sum_{j=1}^n x_j</math>\n\nsubject to\n\n: <math>\\sum_{j=1}^n w_j x_j = W.</math>\n\n==Non-currency examples==\nAn application of change-making problem can be found in computing the ways one can make a [[nine dart finish]] in a game of darts.\n\nAnother application is computing the possible atomic (or isotopic) composition of a given mass/charge peak in mass spectrometry.\n\n==Methods of solving==\n\n===Simple dynamic programming===\nA classic [[dynamic programming]] strategy works upward by finding the combinations of all smaller values that would sum to the current threshold.<ref>* {{cite journal |author=J.W.Wright |title=The Change-Making Problem |journal=Journal of the Association for Computing Machinery |volume=22 |issue=1 |year=1975 |pages=125-128 |doi=10.1145/321864.321874 }}</ref> Thus, at each threshold, all previous thresholds are potentially considered to work upward to the goal amount ''W''. For this reason, this dynamic programming approach may require a number of steps that is at least quadratic in the goal amount ''W''.\n\n==== Optimal substructure ====\n\nSince the problem exhibits [[optimal substructure]], a dynamic programming strategy can be applied to reach a solution as follows:\n\nFirstly, given that <math>S</math> is the optimal solution that contains exactly <math>n</math> coins, hence <math>S' = S - c</math>. It may seem as if <math>c \\in S</math>, is the optimal solution for the sub-problem that contains exactly <math>n - c</math> coins.\n\nHowever, <math>S'</math> does not contain <math>n - c</math> coins, and is not optimal, therefore the solution is known as <math>X \\neq S'</math>, hence <math>X</math> becomes the optimal solution, since it must contain fewer coins than <math>S'</math>.\n\nFinally, combining <math>X</math> with <math>c</math> achieves the optimal solution that contains exactly <math>n</math> coins, while contradicting any assumptions that <math>S</math> is the optimal solution for the original problem.\n\n==== Implementation ====\n\nThe following is a dynamic programming implementation (with Python 3) which uses a matrix to keep track of the optimal solutions to sub-problems, and returns the minimum number of coins. A second matrix may be used to obtain the set of coins for the optimal solution.\n\n<syntaxhighlight lang=\"Python\" line>\ndef _get_change_making_matrix(set_of_coins, r):\n    m = [[0 for _ in range(r + 1)] for _ in range(len(set_of_coins) + 1)]\n    for i in range(r + 1):\n        m[0][i] = i\n    return m\n\ndef change_making(coins, n):\n    \"\"\"This function assumes that all coins are available infinitely.\n    n is the number to obtain with the fewest coins.\n    coins is a list or tuple with the available denominations.\"\"\"\n    m = _get_change_making_matrix(coins, n)\n    for c in range(1, len(coins) + 1):\n        for r in range(1, n + 1):\n            # Just use the coin coins[c - 1].\n            if coins[c - 1] == r:\n                m[c][r] = 1\n            # coins[c - 1] cannot be included.\n            # Use the previous solution for making r,\n            # excluding coins[c - 1].\n            elif coins[c - 1] > r:\n                m[c][r] = m[c - 1][r]\n            # coins[c - 1] can be used.\n            # Decide which one of the following solutions is the best:\n            # 1. Using the previous solution for making r (without using coins[c - 1]).\n            # 2. Using the previous solution for making r - coins[c - 1] (without\n            #      using coins[c - 1]) plus this 1 extra coin.\n            else:\n                m[c][r] = min(m[c - 1][r], 1 + m[c][r - coins[c - 1]])\n    return m[-1][-1]\n</syntaxhighlight>\n\n===Dynamic programming with the probabilistic convolution tree===\nThe probabilistic convolution tree<ref name=\"Serang\" >{{cite journal|last=Serang|first=O.|title=The Probabilistic Convolution Tree: Efficient Exact Bayesian Inference for Faster LC-MS/MS Protein Inference\n|journal=PLOS ONE|volume=9|year=2012|doi=10.1371/journal.pone.0091507|ref=harv|issue=3|pages=e91507|pmid=24626234|pmc=3953406|bibcode=2014PLoSO...991507S}}</ref> can also be used as a more efficient dynamic programming approach. The probabilistic convolution tree merges pairs of coins to produce all amounts which can be created by that pair of coins (with neither coin present, only the first coin present, only the second coin present, and both coins present), and then subsequently merging pairs of these merged outcomes in the same manner. This process is repeated until the final two collections of outcomes are merged into one, leading to a balanced binary tree with ''W log(W)'' such merge operations. Furthermore, by discretizing the coin values, each of these merge operations can be performed via convolution, which can often be performed more efficiently with the [[fast Fourier transform]] (FFT). In this manner, the probabilistic convolution tree may be used to achieve a solution in sub-quadratic number of steps: each convolution can be performed in ''n log(n)'', and the initial (more numerous) merge operations use a smaller ''n'', while the later (less numerous) operations require ''n'' on the order of ''W''.\n\nThe probabilistic convolution tree-based dynamic programming method also efficiently solves the probabilistic generalization of the change-making problem, where uncertainty or fuzziness in the goal amount ''W'' makes it a discrete distribution rather than a fixed quantity, where the value of each coin is likewise permitted to be fuzzy (for instance, when an exchange rate is considered), and where different coins may be used with particular frequencies.\n\n===Greedy method===\nFor the so-called canonical coin systems, like those used in the US and many other countries, a [[greedy algorithm]] of picking the largest denomination of coin which is not greater than the remaining amount to be made will produce the optimal result.<ref>\n{{cite journal |author=Xuan Cai |title=Canonical Coin Systems for CHANGE-MAKING Problems |journal=Proceedings of the Ninth International Conference on Hybrid Intelligent Systems |volume=1 |pages=499–504 |year=2009 |doi=10.1109/HIS.2009.103 |arxiv=0809.0400 }}\n</ref> This is not the case for arbitrary coin systems, though: if the coin denominations were 1, 3 and 4, then to make 6, the greedy algorithm would choose three coins (4,1,1) whereas the optimal solution is two coins (3,3).\n\nHowever, there is a modified version of greedy algorithm to solve this question. In our case, we have \n:<math>W=x_1+3x_2+4x_3</math>\nwhere <math>0 \\leq x_1 \\leq 2</math> and <math>0 \\leq x_2 \\leq 2</math> \nsince <math>3w_1=w_2</math> and <math>3w_2=w_1+2w_3</math>.\n\nNow let <math>y=x_1+3x_2</math>. We can write\n:<math>W=y+4x_3</math> \nwhere <math>0 \\leq y \\leq 8</math>.\n\nFor example, given <math>W=2018</math>, we have <math>2018=6+4 \\times 503</math>.\nHence <math>f(2018)=f(6)+503=505</math>.\n\nTherefore \n:<math>f(W)=[W/4]-1+f(4+W\\%4)</math>\nwhere <math>[W/4]</math> denotes the largest integer less than or equal to <math>W/4</math>\nand <math>W\\%4</math> denotes the remainder of <math>W</math> divided by 4.\n\n== Related problems ==\nThe \"optimal [[denomination (currency)|denomination]] problem\"<ref>\n{{cite journal |author=J. Shallit |title=What this country needs is an 18c piece |journal=[[Mathematical Intelligencer]] |volume=25 |issue=2| year=2003 |pages=20–23 |doi=10.1007/BF02984830 |url=http://www.cs.uwaterloo.ca/~shallit/Papers/change2.pdf}}\n</ref> is a problem for people who design entirely new currencies. It asks what denominations should be chosen for the coins in order to minimize the average cost of making change, that is, the average number of coins needed to make change? The version of this problem assumed that the people making change will use the minimum number of coins (from the denominations available). One variation of this problem assumes that the people making change will use the \"greedy algorithm\" for making change, even when that requires more than the minimum number of coins. Most current currencies use a [[1-2-5 series]], but some other set of denominations would require fewer denominations of coins or a smaller average number of coins to make change or both.\n\n==See also==\n* [[List of knapsack problems]]\n* [[Coin problem]]\n* [[package-merge algorithm#The coin collector's problem|The coin collector's problem]]\n\n==References==\n{{reflist}}\n\n== Further reading ==\n* {{cite journal |author=X. Cai |title=Canonical Coin Systems for Change-Making Problems |journal=Proceedings of the Ninth International Conference on Hybrid Intelligent Systems |year=2009 |pages=499–504 |doi=10.1109/HIS.2009.103 |arxiv=0809.0400|ref=Cai}}\n* {{cite journal |author=M. Adamaszek, A. Niewiarowska |title=Combinatorics of the change-making problem |journal=European Journal of Combinatorics |volume=31 |issue=1 |year=2010 |pages=47–63 |doi=10.1016/j.ejc.2009.05.002 |arxiv=0801.0120}}\n* {{cite journal |author=J.W.Wright |title=The Change-Making Problem |journal=Journal of the Association for Computing Machinery |volume=22 |issue=1 |year=1975 |pages=125-128 |doi=10.1145/321864.321874 }}\n\n[[Category:Number theory]]\n[[Category:Recreational mathematics]]\n[[Category:Combinatorial optimization]]\n[[Category:Articles with example Python code]]"
    },
    {
      "title": "Closure problem",
      "url": "https://en.wikipedia.org/wiki/Closure_problem",
      "text": "In [[graph theory]] and [[combinatorial optimization]], a '''closure''' of a [[directed graph]] is a set of vertices with no outgoing edges.\nThat is, the graph should have no edges that start within the closure and end outside the closure.\nThe '''closure problem''' is the task of finding the maximum-weight or minimum-weight closure in a vertex-weighted directed graph.<ref name=\"amo\">{{citation\n | last1 = Ahuja | first1 = Ravindra K. | author1-link = Ravindra K. Ahuja\n | last2 = Magnanti | first2 = Thomas L. | author2-link = Thomas L. Magnanti\n | last3 = Orlin | first3 = James B. | author3-link = James B. Orlin\n | contribution = 19.2 Maximum weight closure of a graph\n | isbn = 0-13-617549-X\n | location = Englewood Cliffs, NJ\n | mr = 1205775\n | pages = 719–724\n | publisher = Prentice Hall Inc.\n | title = Network flows\n | year = 1993}}.</ref><ref name=\"ccps\">{{citation\n | last1 = Cook | first1 = William J. | author1-link = William J. Cook\n | last2 = Cunningham | first2 = William H.\n | last3 = Pulleyblank | first3 = William R. | author3-link = William R. Pulleyblank\n | last4 = Schrijver | first4 = Alexander | author4-link = Alexander Schrijver\n | contribution = Optimal closure in a digraph\n | isbn = 9781118031391\n | pages = 49–50\n | publisher = John Wiley & Sons\n | series = Wiley Series in Discrete Mathematics and Optimization\n | title = Combinatorial Optimization\n | url = https://books.google.com/books?id=tarLTNwM3gEC&pg=PA49\n | volume = 33\n | year = 2011}}.</ref>\nIt may be solved in polynomial time using a reduction to the [[maximum flow problem]]. It may be used to model various application problems of choosing an optimal subset of tasks to perform, with dependencies between pairs of tasks, one example being in [[open pit mining]].\n\n==Algorithms==\n\n===Condensation===\nThe maximum-weight closure of a given graph ''G'' is the same as the [[Complement (set theory)|complement]] of the minimum-weight closure on the [[transpose graph]] of ''G'', so the two problems are equivalent in computational complexity.\nIf two vertices of the graph belong to the same [[strongly connected component]], they must behave the same as each other with respect to all closures: it is not possible for a closure to contain one vertex without containing the other. For this reason, the input graph to a closure problem may be replaced by its [[condensation (graph theory)|condensation]], in which every strongly connected component is replaced by a single vertex.\nThe condensation is always a [[directed acyclic graph]].\n\n===Reduction to maximum flow===\n[[Image:closure.png|thumb|420px|Reduction from closure to maximum flow]]\nAs {{harvtxt|Picard|1976}} showed,<ref name=\"ccps\"/><ref>{{citation\n | last = Picard | first = Jean-Claude\n | doi = 10.1287/mnsc.22.11.1268\n | issue = 11\n | journal = [[Management Science (journal)|Management Science]]\n | mr = 0403596\n | pages = 1268–1272\n | title = Maximal closure of a graph and applications to combinatorial problems\n | volume = 22\n | year = 1976}}.</ref>\na maximum-weight closure may be obtained from ''G'' by solving a [[maximum flow problem]] on a graph ''H'' constructed from ''G'' by adding to it two additional vertices ''s'' and ''t''. For each vertex ''v'' with positive weight in ''G'', the augmented graph ''H'' contains an edge from ''s'' to ''v'' with capacity equal to the weight of ''v'',\nand for each vertex ''v'' with negative weight in ''G'', the augmented graph ''H'' contains an edge from ''v'' to ''t'' whose capacity is the negation of the weight of ''v''. All of the edges in ''G'' are given infinite capacity in ''H''.<ref name=\"amo\"/>\n\nA [[minimum cut]] separating ''s'' from ''t'' in this graph cannot have any edges of ''G'' passing in the forward direction across the cut: a cut with such an edge would have infinite capacity and would not be minimum. Therefore, the set of vertices on the same side of the cut as ''s'' automatically forms a closure ''C''. The capacity of the cut equals the weight of all positive-weight vertices minus the weight of the vertices in ''C'', which is minimized when the weight of ''C'' is maximized. By the [[max-flow min-cut theorem]], a minimum cut, and the optimal closure derived from it, can be found by solving a maximum flow problem.<ref name=\"amo\"/>\n\n===Alternative algorithms===\nAlternative algorithms for the maximum closure problem that do not compute flows have also been studied.<ref name=\"new-old\">{{citation\n | last = Hochbaum | first = Dorit S. | authorlink = Dorit S. Hochbaum\n | doi = 10.1002/net.1012\n | issue = 4\n | journal = Networks\n | mr = 1837196\n | pages = 171–193\n | title = A new-old algorithm for minimum-cut and maximum-flow in closure graphs\n | volume = 37\n | year = 2001}}.</ref><ref name=\"lg65\">{{citation|first1=H.|last1=Lerchs|first2=I. F.|last2=Grossmann|title=Optimum design of open-pit mines|journal=Transactions of the Canadian Institute of Mining and Metallurgy|volume=68|year=1965|pages=17–24}}. As cited by {{harvtxt|Hochbaum|2001}}.</ref><ref>{{citation|title=A new algorithm for computing the maximal closure of a graph|first1=Bruce|last1=Faaland|first2=Kiseog|last2=Kim|first3=Tom|last3=Schmitt|journal=[[Management Science (journal)|Management Science]]|volume=36|issue=3|year=1990|doi=10.1287/mnsc.36.3.315|pages=315–331}}.</ref> Their running time is similar to that of the fastest known flow algorithms.<ref name=\"new-old\"/>\n\n==Applications==\n\n===Open pit mining===\nAn open pit mine may be modeled as a set of blocks of material which may be removed by mining it once all the blocks directly above it have been removed. A block has a total value, equal to the value of the minerals that can be extracted from it minus the cost of removal and extraction; in some cases, a block has no extraction value but must still be removed to reach other blocks, giving it a negative value.\nOne may define an acyclic network that has as its vertices the blocks of a mine, with an edge from each block to the blocks above it that must be removed earlier than it. The weight of each vertex in this network is the total value of its block, and the most profitable plan for mining can be determined by finding a maximum weight closure, and then forming a [[topological ordering]] of the blocks in this closure.<ref name=\"amo\"/><ref name=\"lg65\"/><ref>{{citation|first=T. B.|last=Johnson|title=Optimum pit mine production scheduling|series=Technical Report|publisher=University of California, Berkeley, CA|year=1968}}. As cited by {{harvtxt|Ahuja|Magnanti|Orlin|1993}}.</ref>\n\n===Military targeting===\nIn military operations, high-value targets such as command centers are frequently protected by layers of defense systems, which may in turn be protected by other systems. In order to reach a target, all of its defenses must be taken down, making it into a secondary target. Each target needs a certain amount of resources to be allocated to it in order to perform a successful attack. The optimal set of targets to attack, to obtain the most value for the resources expended, can be modeled as a closure problem.<ref name=\"amo\"/><ref>{{citation|first=D.|last=Orlin|title=Optimal weapons allocation against layered defenses|journal=Naval Research Logistics Quarterly|volume=34|pages=605–617|year=1987|doi=10.1002/1520-6750(198710)34:5<605::aid-nav3220340502>3.0.co;2-l}}. As cited by {{harvtxt|Ahuja|Magnanti|Orlin|1993}}.</ref>\n\n===Transportation network design===\nThe problem of planning a freight delivery system may be modeled by a network in which the vertices represent cities and the (undirected) edges represent potential freight delivery routes between pairs of cities. Each route can achieve a certain profit, but can only be used if freight depots are constructed at both its ends, with a certain cost. The problem of designing a network that maximizes the difference between the profits and the costs can be solved as a closure problem, by subdividing each undirected edge into two directed edges, both directed outwards from the subdivision point. The weight of each subdivision point is a positive number, the profit of the corresponding route, and the weight of each original graph vertex is a negative number, the cost of building a depot in that city.<ref name=\"amo\"/><ref name=\"h04\">{{citation\n | last = Hochbaum | first = Dorit | authorlink = Dorit S. Hochbaum\n | doi = 10.1287/mnsc.1040.0242\n | issue = 6\n | journal = [[Management Science (journal)|Management Science]]\n | pages = 709–723\n | title = 50th Anniversary Article: Selection, Provisioning, Shared Fixed Costs, Maximum Closure, and Implications on Algorithmic Methods Today\n | volume = 50\n | year = 2004}}.</ref> Together with open pit mining, this was one of the original motivating applications for studying the closure problem; it was originally studied in 1970, in two independent papers published in the same issue of the same journal by J. M. W. Rhys and [[Michel Balinski]].<ref name=\"h04\"/><ref>{{citation|last=Rhys|first=J. M. W.|year=1970|title=A selection problem of shared fixed costs and network ﬂows|journal = [[Management Science (journal)|Management Science]]|volume=17|issue=3|pages=200–207|doi=10.1287/mnsc.17.3.200}}.</ref><ref>{{citation|last=Balinski|first=M. L.|authorlink=Michel Balinski|year=1970|title=On a selection problem|journal = [[Management Science (journal)|Management Science]]|volume=17|issue=3|pages=230–231|doi=10.1287/mnsc.17.3.230}}.</ref>\n\n===Job scheduling===\n{{harvtxt|Sidney|1975}} and {{harvtxt|Lawler|1978}} describe an application of the closure problem to a version of [[job shop scheduling]] in which one is given a collection of tasks to be scheduled to be performed, one at a time. Each task has two numbers associated with it: a weight or priority, and a processing time, the amount of time that it takes to perform that task. In addition the tasks have precedence constraints: certain tasks must be performed before others. These precedence constraints can be described by a directed acyclic graph ''G'' in which an edge from one task to another indicates that the first task must be performed earlier than the second one.  The goal is to choose an ordering that is consistent with these constraints (a [[topological ordering]] of ''G'') that minimizes the total weighted completion time of the tasks.<ref name=\"sidney75\">{{citation\n | last = Sidney | first = Jeffrey B.\n | doi = 10.1287/opre.23.2.283\n | issue = 2\n | journal = [[Operations Research (journal)|Operations Research]]\n | pages = 283–298\n | title = Decomposition algorithms for single-machine sequencing with precedence relations and deferral costs\n | volume = 23\n | year = 1975}}.</ref><ref name=\"lawler78\">{{citation\n | last = Lawler | first = E. L. | author-link = Eugene Lawler\n | doi = 10.1016/S0167-5060(08)70323-6\n | journal = Ann. Discrete Math.\n | mr = 0495156\n | pages = 75–90\n | title = Sequencing jobs to minimize total weighted completion time subject to precedence constraints\n | url = https://books.google.com/books?id=YvdjzQxSMLMC&pg=PA75\n | volume = 2\n | year = 1978}}.</ref>\n\nAlthough (as Lawler shows) this scheduling problem is [[NP-complete]] in general, Sidney describes a decomposition method that can help solve the problem by reducing it to several smaller problems of the same type. In particular, if ''S'' is a subset of the tasks that (among all subsets) has the largest possible ratio of its total weight to its total processing time, and in addition ''S'' is minimal among all sets with the same ratio, then there exists an optimal schedule in which all tasks in ''S'' are performed before all other tasks. As long as ''S'' is not the whole set of tasks, this partition of the tasks splits the scheduling problem into two smaller problems, one of scheduling ''S'' and one of scheduling the remaining tasks.<ref name=\"sidney75\"/> Although ''S'' is a closure (for a graph with reversed edges from ''G'') the problem of finding ''S'' is not exactly a maximum weight closure problem, because the value of ''S'' is a ratio rather than a sum of weights. Nevertheless, Lawler shows that ''S'' may be found in polynomial time by a [[binary search]] algorithm in which each step of the search uses an instance of the closure problem as a subroutine.<ref name=\"lawler78\"/>\n\n==References==\n{{reflist}}\n\n[[Category:Mineral economics]]\n[[Category:Combinatorial optimization]]\n[[Category:Graph algorithms]]"
    },
    {
      "title": "Combinatorial data analysis",
      "url": "https://en.wikipedia.org/wiki/Combinatorial_data_analysis",
      "text": "In statistics, '''combinatorial data analysis''' ('''CDA''') is the study of data sets where the order in which objects are arranged is important. CDA can be used either to determine how well a given [[combinatorial]] construct reflects the observed data, or to search for a suitable combinatorial construct that does fit the data.<ref>{{cite book | author=Lawrence J. Hubert | title=Assignment Methods in Combinatorial Data Analysis | publisher=Marcel Dekker | year=1987 | isbn=978-0824776176}}</ref><ref>{{cite book | author=Lawrence J. Hubert, Phipps Arabie, [[Jacqueline Meulman]] | title=Combinatorial Data Analysis: Optimization by Dynamic Programming | publisher=SIAM | year=2001 | isbn=978-0898714784}}</ref><ref>{{cite book |author1=Michael J Brusco |author2=Stephanie Stahl | title=Branch-and-bound Applications in Combinatorial Data Analysis | publisher=Springer | year=2005 | isbn=978-0387250373}}</ref>\n\n==See also==\n*[[Cluster analysis]]\n*[[Geometric data analysis]]\n*[[Structured data analysis (statistics)]]\n*[[Seriation (statistics)]]\n\n==References==\n{{reflist}}\n\n[[Category:Combinatorics]]\n[[Category:Data analysis]]\n[[Category:Combinatorial optimization]]\n\n\n{{statistics-stub}}"
    },
    {
      "title": "Combinatorial search",
      "url": "https://en.wikipedia.org/wiki/Combinatorial_search",
      "text": "{{no footnotes|date=January 2013}}\nIn [[computer science]] and [[artificial intelligence]], '''combinatorial search''' studies [[search algorithms]] for solving instances of problems that are believed to be hard in general, by efficiently exploring the usually large solution space of these instances. Combinatorial search algorithms achieve this efficiency by reducing the effective size of the search space or employing heuristics. Some algorithms are guaranteed to find the optimal solution, while others may only return the best solution found in the part of the state space that was explored.\n\nClassic combinatorial search problems include solving the [[eight queens puzzle]] or evaluating moves in games with a large [[game tree]], such as [[reversi]] or [[chess]].\n\nA study of [[computational complexity theory]] helps to motivate combinatorial search.  Combinatorial search algorithms are typically concerned with problems that are [[NP-hard]].  Such problems are not believed to be efficiently solvable in general.  However, the various approximations of complexity theory suggest that some instances (e.g. \"small\" instances) of these problems could be efficiently solved.  This is indeed the case, and such instances often have important practical ramifications.\n\n== Examples ==\nCommon algorithms for solving combinatorial search problems include:\n* [[A* search algorithm]]\n* [[Alpha-beta pruning]]\n* [[Branch-and-bound]]\n* [[Minimax]]\n\n== Lookahead ==\nLookahead is an important component of combinatorial search, which specifies, roughly, how deeply the [[graph (data structure)|graph]] representing the problem is explored. The need for a specific limit on lookahead comes from the large problem graphs in many applications, such as [[computer chess]] and [[computer Go]]. A naive [[breadth-first search]] of these graphs would quickly consume all the memory of any modern computer. By setting a specific lookahead limit, the algorithm's time can be carefully controlled; its time [[exponential growth|increases exponentially]] as the lookahead limit increases.\n\nMore sophisticated search techniques such as [[alpha-beta pruning]] are able to eliminate entire subtrees of the search tree from consideration. When these techniques are used, lookahead is not a precisely defined quantity, but instead either the maximum depth searched or some type of average.\n\n==See also==\n* [[Brute-force search]]\n* [[Combinatorial explosion]]\n* [[Combinatorial optimization]]\n* [[Search algorithm]]\n* [[State space search]]\n\n== References ==\n* Russell and Norvig. ''[[Artificial Intelligence: A Modern Approach]]''.\n\n[[Category:Analysis of algorithms]]\n[[Category:Combinatorial optimization]]\n[[Category:Computational complexity theory]]\n[[Category:Game artificial intelligence]]\n[[Category:Search algorithms| ]]"
    },
    {
      "title": "Continuous knapsack problem",
      "url": "https://en.wikipedia.org/wiki/Continuous_knapsack_problem",
      "text": "In [[theoretical computer science]], the '''continuous knapsack problem''' (also known as the '''fractional knapsack problem''') is an [[algorithm]]ic problem in [[combinatorial optimization]] in which the goal is to fill a container (the \"knapsack\") with fractional amounts of different materials chosen to maximize the value of the selected materials.<ref name=\"gt\">{{citation|title=Algorithm Design: Foundations, Analysis, and Internet Examples|first1=Michael T.|last1=Goodrich|author1-link=Michael T. Goodrich|first2=Roberto|last2=Tamassia|author2-link=Roberto Tamassia|publisher=John Wiley & Sons|year=2002|contribution=5.1.1 The Fractional Knapsack Problem|pages=259–260}}.</ref><ref name=\"co\">{{citation|title=Combinatorial Optimization: Theory and Algorithms|volume=21|series=Algorithms and Combinatorics|first1=Bernhard|last1=Korte|author1-link=Bernhard Korte|first2=Jens|last2=Vygen|publisher=Springer|year=2012|isbn=9783642244889|contribution=17.1 Fractional Knapsack and Weighted Median|pages=459–461|url=https://books.google.com/books?id=8535vmYbLGYC&pg=PA459}}.</ref> It resembles the classic [[knapsack problem]], in which the items to be placed in the container are indivisible; however, the continuous knapsack problem may be solved in [[polynomial time]] whereas the classic knapsack problem is [[NP-hard]].<ref name=\"gt\"/>  It is a classic example of how a seemingly small change in the formulation of a problem can have a large impact on its [[Analysis of algorithms|computational complexity]].\n\n==Problem definition==\nAn instance of either the continuous or classic knapsack problems may be specified by the numerical capacity ''W'' of the knapsack, together with a collection of materials, each of which has two numbers associated with it: the weight ''w<sub>i</sub>'' of material that is available to be selected and the value per unit weight ''v<sub>i</sub>'' of that material. The goal is to choose an amount ''x<sub>i</sub>''&nbsp;≤&nbsp;''w<sub>i</sub>'' of each material, subject to the capacity constraint\n:<math>\\sum_i x_i w_i\\le W</math>\nand maximizing the total benefit\n:<math>\\sum_i x_i v_i</math>.\nIn the classic knapsack problem, each of the amounts ''x<sub>i</sub>'' must be either zero or ''w<sub>i</sub>''; the continuous knapsack problem differs by allowing ''x<sub>i</sub>'' to range continuously from zero to ''w<sub>i</sub>''.<ref name=\"gt\"/>\nSome formulations of this problem rescale the variables ''x<sub>i</sub>'' to be in the range from 0 to 1\n\n==Solution technique==\nThe continuous knapsack problem may be solved by a [[greedy algorithm]], first published in 1957 by [[George Dantzig]],<ref name=\"co\"/><ref>{{citation\n | last = Dantzig | first = George B. | authorlink = George Dantzig\n | doi = 10.1287/opre.5.2.266\n | journal = Operations Research\n | mr = 0089098\n | pages = 266–277\n | title = Discrete-variable extremum problems\n | volume = 5\n | year = 1957}}.</ref> that considers the materials in sorted order by their values per unit weight. For each material, the amount ''x<sub>i</sub>'' is chosen to be as large as possible:\n*If the sum of the choices made so far equals the capacity ''W'', then the algorithm sets ''x<sub>i</sub>''&nbsp;=&nbsp;0.\n*If the difference ''d'' between the sum of the choices made so far and ''W'' is smaller than ''w<sub>i</sub>'', then the algorithm sets ''x<sub>i</sub>''&nbsp;=&nbsp;''d''.\n*In the remaining case, the algorithm chooses ''x<sub>i</sub>''&nbsp;=&nbsp;''w<sub>i</sub>''.\nBecause of the need to sort the materials, this algorithm takes time ''O''(''n''&nbsp;log&nbsp;''n'') on inputs with ''n'' materials.<ref name=\"gt\"/><ref name=\"co\"/> However, by adapting an algorithm for finding [[weighted median]]s, it is possible to solve the problem in time ''O''(''n'').<ref name=\"co\"/>\n\n==References==\n{{reflist}}\n\n[[Category:Combinatorial optimization]]"
    },
    {
      "title": "Cut (graph theory)",
      "url": "https://en.wikipedia.org/wiki/Cut_%28graph_theory%29",
      "text": "In [[graph theory]], a '''cut''' is a [[Partition of a set|partition]] of the [[Vertex (graph theory)|vertices]] of a graph into two [[Disjoint set|disjoint subsets]]. Any cut determines a '''cut-set''', the set of edges that have one endpoint in each subset of the partition. These edges are said to '''cross''' the cut. In a [[connected graph]], each cut-set determines a unique cut, and in some cases cuts are identified with their cut-sets rather than with their vertex partitions.\n\nIn a [[flow network]], an '''s–t cut''' is a cut that requires the [[Glossary of graph theory#Direction|''source'']] and the [[Glossary of graph theory#Direction|''sink'']] to be in different subsets, and its ''cut-set'' only consists of edges going from the source's side to the sink's side. The ''capacity'' of an s–t cut is defined as the sum of the capacity of each edge in the ''cut-set''.\n\n==Definition==\nA '''cut''' <math>C=(S,T)</math> is a partition of <math>V</math> of a graph <math>G=(V,E)</math> into two subsets ''S'' and ''T''.\nThe '''cut-set''' of a cut <math>C=(S,T)</math> is the set <math>\\{(u,v)\\in E \\mid u\\in S, v \\in T\\}</math> of edges that have one endpoint in ''S'' and the other endpoint in ''T''.\nIf ''s'' and ''t'' are specified vertices of the graph ''G'',  then an '''''s''–''t'' cut''' is a cut in which ''s'' belongs to the set ''S'' and ''t'' belongs to the set ''T''.\n\nIn an unweighted undirected graph, the ''size'' or ''weight'' of a cut is the number of edges crossing the cut. In a [[Graph (discrete mathematics)#Weighted graph|weighted graph]], the '''value''' or '''weight''' is defined by the sum of the weights of the edges crossing the cut.\n\nA '''bond''' is a cut-set that does not have any other cut-set as a proper subset.\n\n==Minimum cut==\n[[File:Min-cut.svg|thumb|right|A minimum cut.]]\n{{main|Minimum cut}}\n\nA cut is ''minimum'' if the size or weight of the cut is not larger than the size of any other cut. The illustration on the right shows a minimum cut: the size of this cut is 2, and there is no cut of size 1 because the graph is [[Bridge (graph theory)|bridgeless]].\n\nThe [[max-flow min-cut theorem]] proves that the maximum [[flow network|network flow]] and the sum of the cut-edge weights of any minimum cut that separates the source and the sink are equal. There are [[polynomial time|polynomial-time]] methods to solve the min-cut problem, notably the [[Edmonds–Karp algorithm]].<ref>{{citation\n | last1 = Cormen | first1 = Thomas H. | author1-link = Thomas H. Cormen\n | last2 = Leiserson | first2 = Charles E. | author2-link = Charles E. Leiserson\n | last3 = Rivest | first3 = Ronald L. | author3-link = Ronald L. Rivest\n | last4 = Stein | first4 = Clifford | author4-link = Clifford Stein\n | edition = 2nd\n | isbn = 0-262-03293-7\n | page = 563,655,1043\n | publisher = MIT Press and McGraw-Hill\n | title = [[Introduction to Algorithms]]\n | year = 2001}}.</ref>\n\n==Maximum cut==\n[[File:Max-cut.svg|thumb|right|A maximum cut.]]\n{{main|Maximum cut}}\n\nA cut is ''maximum'' if the size of the cut is not smaller than the size of any other cut. The illustration on the right shows a maximum cut: the size of the cut is equal to 5, and there is no cut of size 6, or |''E''| (the number of edges), because the graph is not [[Bipartite graph|bipartite]] (there is an [[Cycle graph#Terminology|odd cycle]]).\n\nIn general, finding a maximum cut is computationally hard.<ref>{{citation\n | last1 = Garey | first1 = Michael R. | author1-link = Michael R. Garey\n | last2 = Johnson | first2 = David S. | author2-link = David S. Johnson\n | isbn = 0-7167-1045-5\n | at = A2.2: ND16, p.&nbsp;210\n | publisher = W.H. Freeman\n | title = [[Computers and Intractability: A Guide to the Theory of NP-Completeness]]\n | year = 1979}}.</ref>\nThe max-cut problem is one of [[Karp's 21 NP-complete problems]].<ref>{{citation\n | last = Karp | first = R. M. | author-link = Richard Karp\n | editor1-last = Miller | editor1-first = R. E.\n | editor2-last = Thacher | editor2-first = J. W.\n | contribution = Reducibility among combinatorial problems\n | location = New York\n | pages = 85–103\n | publisher = Plenum Press\n | title = Complexity of Computer Computation\n | year = 1972}}.</ref>\nThe max-cut problem is also [[Constant-factor approximation algorithm|APX-hard]], meaning that there is no polynomial-time approximation scheme for it unless P&nbsp;=&nbsp;NP.<ref>{{citation\n | last1 = Khot | first1 = S. | author1-link = Subhash Khot\n | last2 = Kindler | first2 = G.\n | last3 = Mossel | first3 = E.\n | last4 = O’Donnell | first4 = R.\n | contribution = Optimal inapproximability results for MAX-CUT and other two-variable CSPs?\n | pages = 146–154\n | title = Proceedings of the 45th IEEE Symposium on Foundations of Computer Science\n | contribution-url = http://www.cs.cmu.edu/~odonnell/papers/maxcut.pdf\n | year = 2004}}.</ref>\nHowever, it can be approximated to within a constant [[approximation ratio]] using [[semidefinite programming]].<ref>{{citation\n | last1 = Goemans | first1 = M. X. | author1-link = Michel Goemans\n | last2 = Williamson | first2 = D. P. | author2-link = David P. Williamson\n | doi = 10.1145/227683.227684\n | issue = 6\n | journal = [[Journal of the ACM]]\n | pages = 1115–1145\n | title = Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming\n | volume = 42\n | year = 1995}}.</ref>\n\nNote that min-cut and max-cut are ''not'' [[Linear programming#Duality|dual]] problems in the [[linear programming]] sense, even though one gets from one problem to other by changing min to max in the [[objective function]]. The max-flow problem is the dual of the min-cut problem.<ref>{{citation\n | last = Vazirani | first = Vijay V. | author-link = Vijay Vazirani\n | isbn = 3-540-65367-8\n | pages = 97–98\n | publisher = Springer\n | title = Approximation Algorithms\n | year = 2004}}.</ref>\n\n== Sparsest cut ==\nThe '''sparsest cut problem''' is to bipartition the vertices so as to minimize the ratio of the number of edges across the cut divided by the number of vertices in the smaller half of the partition.  This objective function favors solutions that are both sparse (few edges crossing the cut) and balanced (close to a bisection). The problem is known to be NP-hard, and the best known approximation algorithm is an <math>O(\\sqrt{\\log n})</math> approximation due to {{Harvtxt|Arora|Rao|Vazirani|2009}}.<ref>{{citation\n | last1 = Arora | first1 = Sanjeev | author1-link = Sanjeev Arora\n | last2 = Rao | first2 = Satish\n | last3 = Vazirani | first3 = Umesh | author3-link = Umesh Vazirani\n | doi = 10.1145/1502793.1502794\n | issue = 2\n | journal = J. ACM\n | pages = 1–37\n | publisher = ACM\n | title = Expander flows, geometric embeddings and graph partitioning\n | volume = 56\n | year = 2009}}.</ref>\n\n== Cut space==\nThe family of all cut sets of an undirected graph is known as the '''cut space''' of the graph. It forms a [[vector space]] over the two-element [[finite field]] of arithmetic modulo two, with the [[symmetric difference]] of two cut sets as the vector addition operation, and is the [[orthogonal complement]] of the [[cycle space]].<ref name=\"gy\">{{citation\n | last1 = Gross | first1 = Jonathan L.\n | last2 = Yellen | first2 = Jay\n | contribution = 4.6 Graphs and Vector Spaces\n | edition = 2nd\n | isbn = 9781584885054\n | pages = 197–207\n | publisher = CRC Press\n | title = Graph Theory and Its Applications\n | url = https://books.google.com/books?id=-7Q_POGh-2cC&pg=PA197\n | year = 2005}}.</ref><ref name=\"diestel\">{{citation\n | last = Diestel | first = Reinhard\n | contribution = 1.9 Some linear algebra\n | pages = 23–28\n | publisher = Springer\n | series = Graduate Texts in Mathematics\n | title = Graph Theory\n | url = https://books.google.com/books?id=eZi8AAAAQBAJ&pg=PA23\n | volume = 173\n | year = 2012}}.</ref> If the edges of the graph are given positive weights, the minimum weight [[Basis (linear algebra)|basis]] of the cut space can be described by a [[tree (graph theory)|tree]] on the same vertex set as the graph, called the [[Gomory–Hu tree]].<ref>{{citation\n | last1 = Korte | first1 = B. H. | author1-link = Bernhard Korte\n | last2 = Vygen | first2 = Jens\n | contribution = 8.6 Gomory–Hu Trees\n | isbn = 978-3-540-71844-4\n | pages = 180–186\n | publisher = Springer\n | series = Algorithms and Combinatorics\n | title = Combinatorial Optimization: Theory and Algorithms\n | volume = 21\n | year = 2008}}.</ref> Each edge of this tree is associated with a bond in the original graph, and the minimum cut between two nodes ''s'' and ''t'' is the minimum weight bond among the ones associated with the path from ''s'' to ''t'' in the tree.\n\n== See also ==\n* [[Connectivity (graph theory)]]\n* [[Graph cuts in computer vision]]\n* [[Split (graph theory)]]\n* [[Vertex separator]]\n\n== References ==\n{{reflist|30em}}\n\n[[Category:Graph connectivity]]\n[[Category:Combinatorial optimization]]"
    },
    {
      "title": "Dijkstra's algorithm",
      "url": "https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm",
      "text": "{{Distinguish|Dykstra's projection algorithm}}\n\n{{Infobox algorithm\n|class=[[Search algorithm]]\n|image=Dijkstra Animation.gif\n|caption = Dijkstra's algorithm to find the shortest path between ''a'' and ''b''.  It picks the unvisited vertex with the lowest distance, calculates the distance through it to each unvisited neighbor, and updates the neighbor's distance if smaller. Mark visited (set to red) when done with neighbors.\n|data=[[Graph (data structure)|Graph]]\n|time= <math>O(|E| + |V| \\log|V|)</math>\n|best-time=\n|average-time=\n|space=\n|optimal=\n|complete=\n}}\n{{graph search algorithm}}\n\n'''Dijkstra's algorithm''' (or '''Dijkstra's Shortest Path First algorithm''', '''SPF algorithm''')<ref>{{Cite web|url=https://www.cisco.com/c/en/us/td/docs/ios/12_0s/feature/guide/ospfispf.html|title=OSPF Incremental SPF|website=Cisco}}</ref> is an [[algorithm]] for finding the [[shortest path problem|shortest paths]] between [[vertex (graph theory)|node]]s in a [[Graph (abstract data type)|graph]], which may represent, for example, [[Road network|road networks]].  It was conceived by [[computer scientist]] [[Edsger W. Dijkstra]] in 1956 and published three years later.<ref>{{cite web |url=http://amturing.acm.org/award_winners/dijkstra_1053701.cfm |title=Edsger Wybe Dijkstra |last=Richards |first=Hamilton |website=A.M. Turing Award |publisher=Association for Computing Machinery |access-date=October 16, 2017 |quote=At the Mathematical Centre a major project was building the ARMAC computer. For its official inauguration in 1956, Dijkstra devised a program to solve a problem interesting to a nontechnical audience: Given a network of roads connecting cities, what is the shortest route between two designated cities?}}</ref><ref name=\"Dijkstra Interview\">{{cite journal|first=Phil |last=Frana |title=An Interview with Edsger W. Dijkstra|journal=Communications of the ACM|date=August 2010|volume=53|issue=8|pages=41–47 |doi=10.1145/1787234.1787249}}</ref><ref name=\"Dijkstra1959\">{{cite journal | authorlink = Edsger W. Dijkstra | first1 = E. W. | last1 = Dijkstra | url= http://www-m3.ma.tum.de/twiki/pub/MN0506/WebHome/dijkstra.pdf | title = A note on two problems in connexion with graphs | journal = Numerische Mathematik | volume = 1 | year = 1959 | pages = 269–271 | ref = harv | doi = 10.1007/BF01386390}}</ref>\n\nThe algorithm exists in many variants; Dijkstra's original variant found the shortest path between two nodes,{{r|Dijkstra1959}} but a more common variant fixes a single node as the \"source\" node and finds shortest paths from the source to all other nodes in the graph, producing a [[shortest-path tree]].\n\nFor a given source node in the graph, the algorithm finds the shortest path between that node and every other.<ref name=\"mehlhorn\"/>{{rp|196–206}} It can also be used for finding the shortest paths from a single node to a single destination node by stopping the algorithm once the shortest path to the destination node has been determined. For example, if the nodes of the graph represent cities and edge path costs represent driving distances between pairs of cities connected by a direct road (for simplicity, ignore red lights, stop signs, toll roads and other obstructions), Dijkstra's algorithm can be used to find the shortest route between one city and all other cities. A widely used application of shortest path algorithm is network [[routing protocol]]s, most notably [[IS-IS]] (Intermediate System to Intermediate System) and Open Shortest Path First ([[OSPF]]). It is also employed as a [[subroutine]] in other algorithms such as [[Johnson's algorithm|Johnson's]].\n\nThe Dijkstra algorithm uses labels that are positive integer or real numbers, which have the strict weak ordering defined.  Interestingly, Dijkstra can be generalized to use labels defined in any way, provided they have the strict partial order defined, and provided the subsequent labels (a subsequent label is produced when traversing an edge) are monotonically non-decreasing.  This generalization is called the Generic Dijkstra shortest-path algorithm <ref name = \"Generic Dijkstra\">{{cite web | url = https://arxiv.org/pdf/1810.04481 | title = Generic Dijkstra for Optical Networks | last1 = Szcześniak | first1 = Ireneusz | last2 = Jajszczyk | first2 = Andrzej | last3 = Woźna-Szcześniak | first3 = Bożena | access-date = October 10, 2018}}</ref>.\n\nDijkstra's original algorithm does not use a [[min-priority queue]] and runs in [[time complexity|time]] <math>O(|V|^2)</math> (where <math>|V|</math> is the number of nodes). The idea of this algorithm is also given in {{harvnb|Leyzorek|Gray|Johnson|Ladew|1957}}. The implementation based on a [[min-priority queue]] implemented by a [[Fibonacci heap]] and running in <math>O(|E|+|V|\\log|V|)</math> (where <math>|E|</math> is the number of edges) is due to {{harvnb|Fredman|Tarjan|1984}}.\nThis is [[Asymptotic computational complexity|asymptotically]] the fastest known single-source [[shortest path problem|shortest-path algorithm]] for arbitrary [[directed graph]]s with unbounded non-negative weights. However, specialized cases (such as bounded/integer weights, directed acyclic graphs etc.) can indeed be improved further as detailed in {{slink||Specialized variants}}.\n\nIn some fields, [[artificial intelligence]] in particular, Dijkstra's algorithm or a variant of it is known as '''uniform cost search''' and formulated as an instance of the more general idea of [[best-first search]].{{r|felner}}\n\n== History ==\n{{quote|What is the shortest way to travel from [[Rotterdam]] to [[Groningen]], in general: from given city to given city. [[Shortest path problem|It is the algorithm for the shortest path]], which I designed in about twenty minutes. One morning I was shopping in [[Amsterdam]] with my young fiancée, and tired, we sat down on the café terrace to drink a cup of coffee and I was just thinking about whether I could do this, and I then designed the algorithm for the shortest path. As I said, it was a twenty-minute invention. In fact, it was published in ’59, three years later. The publication is still readable, it is, in fact, quite nice. One of the reasons that it is so nice was that I designed it without pencil and paper. I learned later that one of the advantages of designing without pencil and paper is that you are almost forced to avoid all avoidable complexities. Eventually that algorithm became, to my great amazement, one of the cornerstones of my fame.|Edsger Dijkstra, in an interview with Philip L. Frana, Communications of the ACM, 2001<ref name=\"Dijkstra Interview\"/>}}\nDijkstra thought about the shortest path problem when working at the [[Centrum Wiskunde & Informatica|Mathematical Center in Amsterdam]] in 1956 as a programmer to demonstrate the capabilities of a new computer called ARMAC.<ref>{{cite web|title=ARMAC|url=http://www-set.win.tue.nl/UnsungHeroes/machines/armac.html|website=Unsung Heroes in Dutch Computing History|date=2007|archiveurl=https://web.archive.org/web/20131113021126/http://www-set.win.tue.nl/UnsungHeroes/machines/armac.html|archivedate=13 November 2013|deadurl=yes|df=dmy-all}}</ref> His objective was to choose both a problem and a solution (that would be produced by computer) that non-computing people could understand. He designed the shortest path algorithm and later implemented it for ARMAC for a slightly simplified transportation map of 64 cities in the Netherlands (64, so that 6 bits would be sufficient to encode the city number).<ref name=\"Dijkstra Interview\"/> A year later, he came across another problem from hardware engineers working on the institute's next computer: minimize the amount of wire needed to connect the pins on the back panel of the machine. As a solution, he re-discovered the algorithm known as [[Prim's algorithm|Prim's minimal spanning tree algorithm]] (known earlier to [[Vojtěch Jarník|Jarník]], and also rediscovered by [[Robert C. Prim|Prim]]).<ref name=\"EWD841a\">{{citation | last1 = Dijkstra | first1 =Edsger W. | title = Reflections on \"A note on two problems in connexion with graphs | url = https://www.cs.utexas.edu/users/EWD/ewd08xx/EWD841a.PDF}}</ref><ref>{{citation|first=Robert Endre|last=Tarjan|authorlink=Robert Endre Tarjan|title=Data Structures and Network Algorithms|series=CBMS_NSF Regional Conference Series in Applied Mathematics|volume=44|year=1983|publisher=Society for Industrial and Applied Mathematics|page=75|quote=The third classical minimum spanning tree algorithm was discovered by Jarník and rediscovered by Prim and Dikstra; it is commonly known as Prim's algorithm.}}</ref> Dijkstra published the algorithm in 1959, two years after Prim and 29 years after Jarník.<ref>{{cite journal|last1=Prim|first1=R.C.|title=Shortest connection networks and some generalizations|journal=Bell System Technical Journal|date=1957|volume=36|pages=1389–1401|doi=10.1002/j.1538-7305.1957.tb01515.x|url=http://bioinfo.ict.ac.cn/~dbu/AlgorithmCourses/Lectures/Prim1957.pdf|archiveurl=https://web.archive.org/web/20170718230207/http://bioinfo.ict.ac.cn/~dbu/AlgorithmCourses/Lectures/Prim1957.pdf|archivedate=18 July 2017|deadurl=no|df=dmy-all}}</ref><ref>V. Jarník: ''O jistém problému minimálním'' [About a certain minimal problem], Práce Moravské Přírodovědecké Společnosti, 6, 1930, pp.&nbsp;57–63. (in Czech)</ref>\n\n== Algorithm ==\n[[Image:Dijkstras progress animation.gif|thumb|Illustration of Dijkstra's algorithm finding a path from a start node (lower left, red) to a goal node (upper right, green) in a [[robotics|robot]] [[motion planning]] problem. Open nodes represent the \"tentative\" set (aka set of \"unvisited\" nodes). Filled nodes are visited ones, with color representing the distance: the greener, the closer. Nodes in all the different directions are explored uniformly, appearing more-or-less as a circular [[wavefront]] as Dijkstra's algorithm uses a [[consistent heuristic|heuristic]] identically equal to 0.]]\n\nLet the node at which we are starting be called the '''initial node'''. Let the '''distance of node ''Y''''' be the distance from the '''initial node''' to ''Y''. Dijkstra's algorithm will assign some initial distance values and will try to improve them step by step.\n\n# Mark all nodes unvisited. Create a set of all the unvisited nodes called the ''unvisited set''.\n# Assign to every node a tentative distance value: set it to zero for our initial node and to infinity for all other nodes. Set the initial node as current.<ref>{{Cite journal|last=Gass|first=Saul|last2=Fu|first2=Michael|date=2013|title=Dijkstra’s Algorithm|url=|journal=Encyclopedia of Operations Research and Management Science|publisher=Springer|volume=1|pages=|doi=10.1007/978-1-4419-1153-7|via=Springer Link}}</ref>\n# For the current node, consider all of its unvisited neighbours and calculate their ''tentative'' distances through the current node. Compare the newly calculated ''tentative'' distance to the current assigned value and assign the smaller one. For example, if the current node ''A'' is marked with a <!--tentative ((commented out because the distance is NOT tentative.. it cannot change while visiting the neighbors.. so calling it tentative implies that it can still change, which is confusing))--> distance of 6, and the edge connecting it with a neighbour ''B'' has length 2, then the distance to ''B'' through ''A'' will be 6 + 2 = 8. If B was previously marked with a distance greater than 8 then change it to 8. Otherwise, keep the current value.\n# When we are done considering all of the unvisited neighbours of the current node, mark the current node as visited and remove it from the ''unvisited set''. A visited node will never be checked again. \n<!-- its distance recorded now is final and minimal. ((commented out because the distance is final for the current-node at the point it is taken from the queue.. the distance cannot be dropped while visiting the neighbours.. yet, the current-node remains unvisited until this step.  This is inconsistent and confusing.)) --> \n<!-- # Move to the next unvisited node with the smallest tentative distance and repeat the above steps which check neighbours and mark visited. ((I think that if this line exist, then we cannot terminate the algorithm)) -->\n# If the destination node has been marked visited (when planning a route between two specific nodes) or if the smallest tentative distance among the nodes in the ''unvisited set'' is infinity (when planning a complete traversal; occurs when there is no connection between the initial node and remaining unvisited nodes), then stop. The algorithm has finished.\n# Otherwise, select the unvisited node that is marked with the smallest tentative distance, set it as the new \"current node\", and go back to step 3.\n\nWhen planning a route, it is actually not necessary to wait until the destination node is \"visited\" as above: the algorithm can stop once the destination node has the smallest tentative distance among all \"unvisited\" nodes (and thus could be selected as the next \"current\").\n\n== Description ==\n{{Hatnote|'''Note:''' For ease of understanding, this discussion uses the terms '''intersection''', '''road''' and '''map''' &mdash; however, in formal terminology these terms are '''vertex''', '''edge''' and '''graph''', respectively.}}\n\nSuppose you would like to find the ''shortest path'' between two [[Intersection (road)|intersections]] on a city map: a ''starting point'' and a ''destination''. Dijkstra's algorithm initially marks the distance (from the starting point) to every other intersection on the map with ''infinity''. This is done not to imply that there is an infinite distance, but to note that those intersections have not been visited yet. Some variants of this method leave the intersections' distances ''unlabeled''. Now select the ''current intersection'' at each iteration.  For the first iteration, the current intersection will be the starting point, and the distance to it (the intersection's label) will be ''zero''. For subsequent iterations (after the first), the current intersection will be a ''closest unvisited intersection'' to the starting point (this will be easy to find).\n\nFrom the current intersection, ''update'' the distance to every unvisited intersection that is directly connected to it. This is done by determining the ''sum'' of the distance between an unvisited intersection and the value of the current intersection and then [[Graph labeling|relabeling]] the unvisited intersection with this value (the sum) if it is less than the unvisited intersection's current value. In effect, the intersection is relabeled if the path to it through the current intersection is shorter than the previously known paths.  To facilitate shortest path identification, in pencil, mark the road with an arrow pointing to the relabeled intersection if you label/relabel it, and erase all others pointing to it.  After you have updated the distances to each [[Neighbourhood (graph theory)|neighboring intersection]], mark the current intersection as ''visited'' and select an unvisited intersection with minimal distance (from the starting point) – or the lowest label—as the current intersection. Intersections marked as visited are labeled with the shortest path from the starting point to it and will not be revisited or returned to.\n\nContinue this process of updating the neighboring intersections with the shortest distances, marking the current intersection as visited, and moving onto a closest unvisited intersection until you have marked the destination as visited. Once you have marked the destination as visited (as is the case with any visited intersection), you have determined the shortest path to it from the starting point and can ''trace your way back following the arrows in reverse''. In the algorithm's implementations, this is usually done (after the algorithm has reached the destination node) by following the nodes' parents from the destination node up to the starting node; that's why we also keep track of each node's parent.\n\nThis algorithm makes no attempt of direct \"exploration\" towards the destination as one might expect. Rather, the sole consideration in determining the next \"current\" intersection is its distance from the starting point. This algorithm therefore expands outward from the starting point, interactively considering every node that is closer in terms of shortest path distance until it reaches the destination. When understood in this way, it is clear how the algorithm necessarily finds the shortest path. However, it may also reveal one of the algorithm's weaknesses: its relative slowness in some topologies.\n\n== Pseudocode ==\n\nIn the following algorithm, the code {{mono|u ← vertex in ''Q'' with min dist[u]}}, searches for the vertex {{mono|<var>u</var>}} in the vertex set {{mono|<var>Q</var>}} that has the least {{mono|dist[<var>u</var>]}} value. {{mono|length(<var>u</var>, <var>v</var>)}} returns the length of the edge joining (i.e. the distance between) the two neighbor-nodes {{mono|<var>u</var>}} and {{mono|<var>v</var>}}. The variable {{mono|<var>alt</var>}} on line 18 is the length of the path from the root node to the neighbor node {{mono|<var>v</var>}} if it were to go through {{mono|<var>u</var>}}. If this path is shorter than the current shortest path recorded for {{mono|<var>v</var>}}, that current path is replaced with this {{mono|<var>alt</var>}} path. The {{mono|prev}} array is populated with a pointer to the \"next-hop\" node on the source graph to get the shortest route to the source.\n[[File:DijkstraDemo.gif|thumb|A demo of Dijkstra's algorithm based on Euclidean distance. Red lines are the shortest path covering, i.e., connecting ''u'' and prev[''u'']. Blue lines indicate where relaxing happens, i.e., connecting ''v'' with a node ''u'' in ''Q'', which gives a shorter path from the source to ''v''.]]\n\n  1  '''function''' Dijkstra(''Graph'', ''source''):\n  2\n  3      create vertex set Q\n  4\n  5      '''for each''' vertex ''v'' in ''Graph'':             \n  6          dist[''v''] ← INFINITY                  \n  7          prev[''v''] ← UNDEFINED                 \n  8          add ''v'' to ''Q''                      \n 10      dist[''source''] ← 0                        \n 11      \n 12      '''while''' ''Q'' is not empty:\n 13          ''u'' ← vertex in ''Q'' with min dist[u]    \n 14                                              \n 15          remove ''u'' from ''Q'' \n 16          \n 17          '''for each''' neighbor ''v'' of ''u'':           ''// only v that are still in Q''\n 18              ''alt'' ← dist[''u''] + length(''u'', ''v'')\n 19              '''if''' ''alt'' < dist[''v'']:               \n 20                  dist[''v''] ← ''alt'' \n 21                  prev[''v''] ← ''u'' \n 22\n 23      '''return''' dist[], prev[]\n\nIf we are only interested in a shortest path between vertices {{mono|<var>source</var>}} and {{mono|<var>target</var>}}, we can terminate the search after line 15 if {{mono|<var>u</var> {{=}} <var>target</var>}}.\nNow we can read the shortest path from {{mono|<var>source</var>}} to {{mono|<var>target</var>}} by reverse iteration:\n\n 1  ''S'' ← empty sequence\n 2  ''u'' ← ''target''\n 3  '''if''' prev[''u''] is defined '''or''' ''u'' = ''source'':          ''// Do something only if the vertex is reachable''\n 4      '''while''' ''u'' is defined:                       ''// Construct the shortest path with a stack S''\n 5          insert ''u'' at the beginning of ''S''        ''// Push the vertex onto the stack''\n 6          ''u'' ← prev[''u'']                           ''// Traverse from target to source''\n\nNow sequence {{mono|<var>S</var>}} is the list of vertices constituting one of the shortest paths from {{mono|<var>source</var>}} to {{mono|<var>target</var>}}, or the empty sequence if no path exists.\n\nA more general problem would be to find all the shortest paths between {{mono|<var>source</var>}} and {{mono|<var>target</var>}} (there might be several different ones of the same length). Then instead of storing only a single node in each entry of {{mono|prev[]}} we would store all nodes satisfying the relaxation condition. For example, if both {{mono|<var>r</var>}} and {{mono|<var>source</var>}} connect to {{mono|<var>target</var>}} and both of them lie on different shortest paths through {{mono|<var>target</var>}} (because the edge cost is the same in both cases), then we would add both {{mono|<var>r</var>}} and {{mono|<var>source</var>}} to {{mono|prev[<var>target</var>]}}. When the algorithm completes, {{mono|prev[]}} data structure will actually describe a graph that is a subset of the original graph with some edges removed. Its key property will be that if the algorithm was run with some starting node, then every path from that node to any other node in the new graph will be the shortest path between those nodes in the original graph, and all paths of that length from the original graph will be present in the new graph. Then to actually find all these shortest paths between two given nodes we would use a path finding algorithm on the new graph, such as [[depth-first search]].\n\n===Using a priority queue===\n\nA min-priority queue is an abstract data type that provides 3 basic operations : {{mono|add_with_priority()}}, {{mono|decrease_priority()}} and {{mono|extract_min()}}. As mentioned earlier, using such a data structure can lead to faster computing times than using a basic queue. Notably, [[Fibonacci heap]] {{harv|Fredman|Tarjan|1984}} or [[Brodal queue]] offer optimal implementations for those 3 operations. As the algorithm is slightly different, we mention it here, in pseudo-code as well :\n\n 1  '''function''' Dijkstra(''Graph'', ''source''):\n 2      dist[''source''] ← 0                           ''// Initialization''\n 3\n 4      create vertex set Q\n 5\n 6      '''for each''' vertex ''v'' in ''Graph'':           \n 7          '''if''' ''v'' ≠ ''source''\n 8              dist[''v''] ← INFINITY                 ''// Unknown distance from source to v''\n 9          prev[''v''] ← UNDEFINED                    ''// Predecessor of v''\n 10\n 11         ''Q''.add_with_priority(''v'', dist[''v''])\n 12\n 13\n 14     '''while''' ''Q'' is not empty:                      ''// The main loop''\n 15         ''u'' ← ''Q''.extract_min()                    ''// Remove and return best vertex''\n 16         '''for each''' neighbor ''v'' of ''u'':              ''// only v that are still in Q''\n 17             ''alt'' ← dist[''u''] + length(''u'', ''v'') \n 18             '''if''' ''alt'' < dist[''v'']\n 19                 dist[''v''] ← ''alt''\n 20                 prev[''v''] ← ''u''\n 21                 ''Q''.decrease_priority(''v'', ''alt'')\n 22\n 23     '''return''' dist, prev\n\nInstead of filling the priority queue with all nodes in the initialization phase, it is also possible to initialize it to contain only ''source''; then, inside the {{mono|'''if''' ''alt'' < dist[''v'']}} block, the node must be inserted if not already in the queue (instead of performing a <var>decrease_priority</var> operation).<ref name=\"mehlhorn\"/>{{rp|198}}\n\nOther data structures can be used to achieve even faster computing times in practice.<ref name=chen_07>{{cite book|first1=M.|last1=Chen|first2=R. A.|last2=Chowdhury|first3=V.|last3=Ramachandran|first4=D. L.|last4=Roche|first5=L.|last5=Tong|title=Priority Queues and Dijkstra’s Algorithm &mdash; UTCS Technical Report TR-07-54 &mdash; 12 October 2007|publisher=The University of Texas at Austin, Department of Computer Sciences|location=Austin, Texas|year=2007|url=http://www.cs.sunysb.edu/~rezaul/papers/TR-07-54.pdf|ref=chen}}</ref>\n\n== Proof of correctness ==\n''Proof of Dijkstra's algorithm is constructed by induction on the number of visited nodes.''\n\n''Invariant hypothesis'': For each visited node {{mono|v}}, {{mono|dist[v]}} is considered the shortest distance from {{mono|source}} to {{mono|v}}; and for each unvisited node {{mono|u}}, {{mono|dist[u]}} is assumed the shortest distance when traveling via visited nodes only, from {{mono|source}} to {{mono|u}}. This assumption is only considered if a path exists, otherwise the distance is set to infinity. (Note : we do not assume {{mono|dist[u]}} is the actual shortest distance for unvisited nodes)\n\nThe base case is when there is just one visited node, namely the initial node {{mono|source}}, in which case the hypothesis is [[triviality (mathematics)|trivial]].\n\nOtherwise, assume the hypothesis for ''n-1'' visited nodes. In which case, we choose an edge {{mono|vu}} where {{mono|u}} has the least {{mono|dist[u]}} of any unvisited nodes and the edge {{mono|vu}} is such that {{mono|1=dist[u] = dist[v] + length[v,u]}}. {{mono|dist[u]}} is considered to be the shortest distance from {{mono|source}} to {{mono|u}} because if there were a shorter path, and if {{mono|w}} was the first unvisited node on that path then by the original hypothesis {{mono|dist[w]}} > {{mono|dist[u]}} which creates a contradiction. Similarly if there was a shorter path to {{mono|u}} without using unvisited nodes, and if the last but one node on that path were {{mono|w}}, then we would have had {{mono|1=dist[u] = dist[w] + length[w,u]}}, also a contradiction.\n\nAfter processing {{mono|u}} it will still be true that for each unvisited nodes {{mono|w}}, {{mono|dist[w]}} will be the shortest distance from {{mono|source}} to {{mono|w}} using visited nodes only, because if there were a shorter path that doesn't go by {{mono|u}} we would have found it previously, and if there were a shorter path using {{mono|u}} we would have updated it when processing {{mono|u}}.\n\n== Running time ==\n\nBounds of the running time of Dijkstra's algorithm on a graph with edges {{mvar|E}} and vertices {{mvar|V}} can be expressed as a function of the number of edges, denoted <math>|E|</math>, and the number of vertices, denoted <math>|V|</math>, using [[big-O notation]]. How tight a bound is possible depends on the way the vertex set {{mvar|Q}} is implemented. In the following, upper bounds can be simplified because <math>|E|</math> is <math>O(|V|^2)</math> for any graph, but that simplification disregards the fact that in some problems, other upper bounds on <math>|E|</math> may hold.\n\nFor any implementation of the vertex set {{mvar|Q}}, the running time is in\n:<math>O(|E| \\cdot T_\\mathrm{dk} + |V| \\cdot T_\\mathrm{em}),</math>\nwhere <math>T_\\mathrm{dk}</math> and <math>T_\\mathrm{em}</math> are the complexities of the ''decrease-key'' and ''extract-minimum'' operations in {{mvar|Q}}, respectively. The simplest implementation of Dijkstra's algorithm stores the vertex set {{mvar|Q}} as an ordinary linked list or array, and extract-minimum is simply a linear search through all vertices in {{mvar|Q}}. In this case, the running time is <math>O(|E| + |V|^2) = O(|V|^2)</math>.\n\nIt must be noted that if the implementation stores the graph as an adjacency list, the running time for a dense graph i.e. <math>|E|</math> = <math>O(|V|^2)</math> is\n:<math>\\Theta((|V|^2) \\log |V|)</math>.\n\nFor [[sparse graph]]s, that is, graphs with far fewer than <math>|V|^2</math> edges, Dijkstra's algorithm can be implemented more efficiently by storing the graph in the form of [[adjacency list]]s and using a [[self-balancing binary search tree]], [[binary heap]], [[pairing heap]], or [[Fibonacci heap]] as a [[priority queue]] to implement extracting minimum efficiently. To perform decrease-key steps in a binary heap efficiently, it is necessary to use an auxiliary data structure that maps each vertex to its position in the heap, and to keep this structure up to date as the priority queue {{mvar|Q}} changes. With a self-balancing binary search tree or binary heap, the algorithm requires\n:<math>\\Theta((|E| + |V|) \\log |V|)</math>\ntime in the worst case (where <math>\\log</math> denotes the binary logarithm <math>\\log_2</math>); for connected graphs this time bound can be simplified to <math>\\Theta( | E | \\log | V | )</math>.  The [[Fibonacci heap]] improves this to\n:<math>O(|E| + |V| \\log|V|).</math>\n\nWhen using binary heaps, the [[Best, worst and average case|average case]] time complexity is lower than the worst-case: assuming edge costs are drawn independently from a common [[probability distribution]], the expected number of ''decrease-key'' operations is bounded by <math>O(|V| \\log (|E|/|V|))</math>, giving a total running time of<ref name=\"mehlhorn\">{{cite book |last1=Mehlhorn |first1=Kurt |author1-link=Kurt Mehlhorn|first2=Peter |last2=Sanders|author2-link=Peter Sanders (computer scientist) |title=Algorithms and Data Structures: The Basic Toolbox |publisher=Springer |year=2008 |chapter=Chapter 10. Shortest Paths |chapterurl=http://people.mpi-inf.mpg.de/~mehlhorn/ftp/Toolbox/ShortestPaths.pdf |isbn=978-3-540-77977-3 |doi=10.1007/978-3-540-77978-0}}</ref>{{rp|199–200}}\n:<math>O\\left(|E| + |V| \\log \\frac{|E|}{|V|} \\log |V|\\right).</math>\n\n===Practical optimizations and infinite graphs===\nIn common presentations of Dijkstra's algorithm, initially all nodes are entered into the priority queue. This is, however, not necessary: the algorithm can start with a priority queue that contains only one item, and insert new items as they are discovered (instead of doing a decrease-key, check whether the key is in the queue; if it is, decrease its key, otherwise insert it).{{r|mehlhorn}}{{rp|198}} This variant has the same worst-case bounds as the common variant, but maintains a smaller priority queue in practice, speeding up the queue operations.<ref name=\"felner\">{{cite conference |first=Ariel |last=Felner |title=Position Paper: Dijkstra's Algorithm versus Uniform Cost Search or a Case Against Dijkstra's Algorithm |conference=Proc. 4th Int'l Symp. on Combinatorial Search |year=2011 |url=http://www.aaai.org/ocs/index.php/SOCS/SOCS11/paper/view/4017/4357}} In a route-finding problem, Felner finds that the queue can be a factor 500–600 smaller, taking some 40% of the running time.</ref>\n\nMoreover, not inserting all nodes in a graph makes it possible to extend the algorithm to find the shortest path from a single source to the closest of a set of target nodes on infinite graphs or those too large to represent in memory. The resulting algorithm is called ''uniform-cost search'' (UCS) in the artificial intelligence literature{{r|felner}}<ref name=\"aima\">{{Cite AIMA|3|pages=75, 81}}</ref><ref>Sometimes also ''least-cost-first search'': {{cite journal |last=Nau |first=Dana S. |title=Expert computer systems |journal=Computer |publisher=IEEE |volume=16 |issue=2 |year=1983 |pages=63–85 |url=https://www.cs.umd.edu/~nau/papers/nau1983expert.pdf |doi=10.1109/mc.1983.1654302}}</ref> and can be expressed in pseudocode as\n \n  '''procedure''' ''UniformCostSearch''(Graph, start, goal)\n   node ← start\n   cost ← 0\n   frontier ← priority queue containing node only\n   explored ← empty set\n   '''do'''\n     '''if''' frontier is empty\n       '''return''' failure\n     node ← frontier.pop()\n     '''if''' node is goal\n       '''return''' solution\n     explored.add(node)\n     '''for each''' of node's neighbors n\n       '''if''' n is not in explored\n           frontier.add(n)\n\nThe complexity of this algorithm can be expressed in an alternative way for very large graphs: when {{math|''C''<sup>*</sup>}} is the length of the shortest path from the start node to any node satisfying the \"goal\" predicate, each edge has cost at least {{mvar|ε}}, and the number of neighbors per node is bounded by {{mvar|b}}, then the algorithm's worst-case time and space complexity are both in {{math|''O''(''b''<sup>1+⌊''C''<sup>*</sup> {{frac}} ''ε''⌋</sup>)}}.{{r|aima}}\n\nFurther optimizations of Dijkstra's algorithm for the single-target case include [[bidirectional search|bidirectional]] variants, goal-directed variants such as the [[A* algorithm]] (see {{slink||Related problems and algorithms}}), graph pruning to determine which nodes are likely to form the middle segment of shortest paths (reach-based routing), and hierarchical decompositions of the input graph that reduce {{math|''s''–''t''}} routing to connecting {{mvar|s}} and {{mvar|t}} to their respective \"transit nodes\" followed by shortest-path computation between these transit nodes using a \"highway\".<ref name=\"speedup\">{{cite conference |last1=Wagner |first1=Dorothea |first2=Thomas |last2=Willhalm |title=Speed-up techniques for shortest-path computations |conference=STACS |pages=23–36 |year=2007}}</ref>\nCombinations of such techniques may be needed for optimal practical performance on specific problems.<ref>{{cite journal |last1=Bauer |first1=Reinhard |first2=Daniel |last2=Delling |first3=Peter |last3=Sanders |first4=Dennis |last4=Schieferdecker |first5=Dominik |last5=Schultes |first6=Dorothea |last6=Wagner |title=Combining hierarchical and goal-directed speed-up techniques for Dijkstra's algorithm |journal=J. Experimental Algorithmics |volume=15 |year=2010}}</ref>\n\n<span id=\"specialized variants\">\n\n===Specialized variants===\nWhen arc weights are small integers (bounded by a parameter ''C''), a [[monotone priority queue]] can be used to speed up Dijkstra's algorithm. The first algorithm of this type was '''Dial's algorithm''', which used a [[bucket queue]] to obtain a running time <math>O(|E|+\\operatorname{diam}(G))</math> that depends on the weighted [[Distance (graph theory)|diameter]] of a graph with integer edge weights {{harv|Dial|1969}}. The use of a [[Van Emde Boas tree]] as the priority queue brings the complexity to <math>O(|E|\\log\\log C)</math> {{harv|Ahuja|Mehlhorn|Orlin|Tarjan|1990}}. Another interesting implementation based on a combination of a new [[radix heap]] and the well-known Fibonacci heap runs in time <math>O(|E|+|V|\\sqrt{\\log C})</math> {{harv|Ahuja|Mehlhorn|Orlin|Tarjan|1990}}. Finally, the best algorithms in this special case are as follows. The algorithm given by {{harv|Thorup|2000}} runs in <math>O(|E|\\log\\log|V|)</math> time and the algorithm given by {{harv|Raman|1997}} runs in <math>O(|E| + |V|\\min\\{(\\log|V|)^{1/3+\\varepsilon}, (\\log C)^{1/4+\\varepsilon}\\})</math> time.\n\nAlso, for [[directed acyclic graph]]s, it is possible to find shortest paths from a given starting vertex in linear <math>O(|E|+|V|)</math> time, by processing the vertices in a [[Topological sorting|topological order]], and calculating the path length for each vertex to be the minimum length obtained via any of its incoming edges.<ref>{{Cite web|url=https://www.boost.org/doc/libs/1_44_0/libs/graph/doc/dag_shortest_paths.html|title=Boost Graph Library: Directed Acyclic Graph Shortest Paths - 1.44.0|website=www.boost.org}}</ref><ref>{{harvnb|Cormen|Leiserson|Rivest|Stein|2001|p=655}}</ref>\n\nIn the special case of integer weights and undirected connected graphs, Dijkstra's algorithm can be completely countered with a linear <math>O(|E|)</math> complexity algorithm, given by {{harv|Thorup|1999}}.\n</span>\n\n== Related problems and algorithms ==\n\nThe functionality of Dijkstra's original algorithm can be extended with a variety of modifications. For example, sometimes it is desirable to present solutions which are less than mathematically optimal. To obtain a ranked list of less-than-optimal solutions, the optimal solution is first calculated. A single edge appearing in the optimal solution is removed from the graph, and the optimum solution to this new graph is calculated. Each edge of the original solution is suppressed in turn and a new shortest-path calculated. The secondary solutions are then ranked and presented after the first optimal solution.\n\nDijkstra's algorithm is usually the working principle behind [[link-state routing protocol]]s, [[OSPF]] and [[IS-IS]] being the most common ones.\n\nUnlike Dijkstra's algorithm, the [[Bellman–Ford algorithm]] can be used on graphs with negative edge weights, as long as the graph contains no [[negative cycle]] reachable from the source vertex ''s''. The presence of such cycles means there is no shortest path, since the total weight becomes lower each time the cycle is traversed. It is possible to adapt Dijkstra's algorithm to handle negative weight edges by combining it with the Bellman-Ford algorithm (to remove negative edges and detect negative cycles), such an algorithm is called [[Johnson's algorithm]].\n\nThe [[A-star algorithm|A* algorithm]] is a generalization of Dijkstra's algorithm that cuts down on the size of the subgraph that must be explored, if additional information is available that provides a lower bound on the \"distance\" to the target. This approach can be viewed from the perspective of [[linear programming]]: there is a natural [[Shortest path problem#Linear programming formulation|linear program for computing shortest paths]], and solutions to its [[dual linear program]] are feasible if and only if they form a [[consistent heuristic]] (speaking roughly, since the sign conventions differ from place to place in the literature). This feasible dual / consistent heuristic defines a non-negative [[reduced cost]] and A* is essentially running Dijkstra's algorithm with these reduced costs. If the dual satisfies the weaker condition of [[Admissible heuristic|admissibility]], then A* is instead more akin to the Bellman–Ford algorithm.\n\nThe process that underlies Dijkstra's algorithm is similar to the [[Greedy algorithm|greedy]] process used in [[Prim's algorithm]].  Prim's purpose is to find a [[minimum spanning tree]] that connects all nodes in the graph; Dijkstra is concerned with only two nodes. Prim's does not evaluate the total weight of the path from the starting node, only the individual edges.\n\n[[Breadth-first search]] can be viewed as a special-case of Dijkstra's algorithm on unweighted graphs, where the priority queue degenerates into a FIFO queue.\n\nThe [[fast marching method]] can be viewed as a continuous version of Dijkstra's algorithm which computes the geodesic distance on a triangle mesh.\n\n=== Dynamic programming perspective ===\n\nFrom a [[dynamic programming]] point of view, Dijkstra's algorithm is a successive approximation scheme that solves the dynamic programming functional equation for the shortest path problem by the '''Reaching''' method.<ref name=sniedovich_06>{{cite journal | last = Sniedovich | first = M. | title = Dijkstra’s algorithm revisited: the dynamic programming connexion | journal = Journal of Control and Cybernetics | volume = 35 | issue = 3 | pages = 599–620 | year = 2006 | url = http://matwbn.icm.edu.pl/ksiazki/cc/cc35/cc3536.pdf | format = [[PDF]]}} [http://www.ifors.ms.unimelb.edu.au/tutorial/dijkstra_new/index.html Online version of the paper with interactive computational modules.]</ref><ref name=denardo_03>{{cite book | last = Denardo | first = E.V. | title = Dynamic Programming: Models and Applications | publisher = [[Dover Publications]] | location = Mineola, NY | year = 2003 | isbn = 978-0-486-42810-9}}</ref><ref name=sniedovich_10>{{cite book | last = Sniedovich | first = M. | title = Dynamic Programming: Foundations and Principles | publisher = [[Francis & Taylor]] | year = 2010 | isbn = 978-0-8247-4099-3  }}</ref>\n\nIn fact, Dijkstra's explanation of the logic behind the algorithm,<ref>{{harvnb|Dijkstra|1959|p=270}}</ref> namely\n{{quote|\n'''Problem 2.''' Find the path of minimum total length between two given nodes <math>P</math> and <math>Q</math>.\n\nWe use the fact that, if <math>R</math> is a node on the minimal path from <math>P</math> to <math>Q</math>, knowledge of the latter implies the knowledge of the minimal path from <math>P</math> to <math>R</math>.\n}}\n\nis a paraphrasing of [[Richard Bellman|Bellman's]] famous [[Principle of Optimality]] in the context of the shortest path problem.\n\n== See also ==\n{{portal|Computer science}}\n* [[A* search algorithm]]\n* [[Bellman–Ford algorithm]]\n* [[Euclidean shortest path]]\n* [[Flood fill]]\n* [[Floyd–Warshall algorithm]]\n* [[Johnson's algorithm]]\n* [[Longest path problem]]\n* [[Parallel all-pairs shortest path algorithm]]\n\n==Notes==\n{{reflist}}\n\n== References ==\n* {{cite book | author1-link = Thomas H. Cormen | first1 = Thomas H. | last1 = Cormen | author2-link = Charles E. Leiserson | first2 = Charles E. | last2 = Leiserson | author3-link = Ronald L. Rivest | first3 = Ronald L. | last3 = Rivest | author4-link = Clifford Stein | first4 = Clifford | last4 = Stein | title = [[Introduction to Algorithms]] | edition = Second | publisher = [[MIT Press]] and [[McGraw–Hill]] | year = 2001 | isbn = 0-262-03293-7 | chapter = Section 24.3: Dijkstra's algorithm | pages = 595–601 | ref = harv}}\n* {{cite journal\n | last = Dial | first = Robert B.\n | doi = 10.1145/363269.363610\n | issue = 11\n | journal = [[Communications of the ACM]]\n | pages = 632–633\n | title = Algorithm 360: Shortest-path forest with topological ordering [H]\n | volume = 12\n | year = 1969\n | ref = harv}}\n* {{cite conference|first1=Michael Lawrence|last1=Fredman|authorlink1=Michael Fredman|first2=Robert E.|last2=Tarjan|authorlink2=Robert Tarjan|title=Fibonacci heaps and their uses in improved network optimization algorithms|conference=25th Annual Symposium on Foundations of Computer Science|year=1984|publisher=[[IEEE]]|pages=338&ndash;346|ref=harv|doi=10.1109/SFCS.1984.715934}}\n* {{cite journal|first1=Michael Lawrence|last1=Fredman|authorlink1=Michael Fredman|first2=Robert E.|last2=Tarjan|authorlink2=Robert Tarjan|title=Fibonacci heaps and their uses in improved network optimization algorithms|journal=Journal of the Association for Computing Machinery|volume=34|year=1987|pages=596&ndash;615|url=http://portal.acm.org/citation.cfm?id=28874|ref=harv|doi=10.1145/28869.28874|issue=3}}\n* {{cite journal | first1 = F. Benjamin | last1 = Zhan | first2 = Charles E. | last2 = Noon |date=February 1998 | title = Shortest Path Algorithms: An Evaluation Using Real Road Networks | journal = [[Transportation Science]] | volume = 32 | issue = 1 | pages = 65–73 | doi = 10.1287/trsc.32.1.65}}\n* {{cite book|first1=M.|last1=Leyzorek|first2=R. S.|last2=Gray|first3=A. A.|last3=Johnson|first4=W. C.|last4=Ladew|first5=S. R.|last5=Meaker, Jr.|first6=R. M.|last6=Petry|first7=R. N.|last7=Seitz|title=Investigation of Model Techniques &mdash; First Annual Report &mdash; 6 June 1956 &mdash; 1 July 1957 &mdash; A Study of Model Techniques for Communication Systems|publisher=Case Institute of Technology|location=Cleveland, Ohio|year=1957|ref=harv}}\n* {{cite journal|first1=D.E.|last1=Knuth|title=A Generalization of Dijkstra's Algorithm|journal=[[Information Processing Letters]]|volume=6|number=1|pages=1–5|year=1977|authorlink1=Donald Knuth|doi=10.1016/0020-0190(77)90002-3}}\n* {{cite journal|first1=Ravindra K.|last1=Ahuja|first2=Kurt|last2=Mehlhorn|first3=James B.|last3=Orlin|first4=Robert E.|last4=Tarjan|title=Faster Algorithms for the Shortest Path Problem|journal=Journal of the ACM|volume=37|number=2|pages=213–223| date=April 1990 |doi=10.1145/77600.77615|ref=harv}}\n* {{cite journal|first1=Rajeev|last1=Raman|title=Recent results on the single-source shortest paths problem|journal=SIGACT News|volume=28|issue=2|pages=81–87|year=1997|ref=harv|doi=10.1145/261342.261352}}\n* {{cite journal|first1=Mikkel|last1=Thorup|title=On RAM priority Queues|journal=SIAM Journal on Computing|volume=30|issue=1|pages=86–109|year=2000|doi=10.1137/S0097539795288246|ref=harv}}\n* {{cite journal|first1=Mikkel|last1=Thorup|title=Undirected single-source shortest paths with positive integer weights in linear time|journal=journal of the ACM|volume=46|issue=3|pages=362–394|year=1999|doi=10.1145/316542.316548|ref=harv|url=http://www.diku.dk/~mthorup/PAPERS/sssp.ps.gz}}\n\n== External links ==\n{{Commons category|Dijkstra's algorithm}}\n* [http://purl.umn.edu/107247 Oral history interview with Edsger W. Dijkstra],  [[Charles Babbage Institute]] University of Minnesota, Minneapolis.\n{{Use dmy dates|date=February 2011}}\n* [http://blog.cleancoder.com/uncle-bob/2016/10/26/DijkstrasAlg.html Implementation of Dijkstra's algorithm using TDD], [[Robert Cecil Martin]], The Clean Code Blog\n* [http://www.gilles-bertrand.com/2014/03/disjkstra-algorithm-description-shortest-path-pseudo-code-data-structure-example-image.html Graphical explanation of Dijkstra's algorithm step-by-step on an example], [[Gilles Bertrand]], A step by step graphical explanation of Dijkstra's algorithm operations\n\n{{Edsger Dijkstra}}\n\n[[Category:Edsger W. Dijkstra|Algorithm]]\n[[Category:1959 in computer science]]\n[[Category:Graph algorithms]]\n[[Category:Search algorithms]]\n[[Category:Routing algorithms]]\n[[Category:Combinatorial optimization]]\n[[Category:Articles with example pseudocode]]"
    },
    {
      "title": "Edge cycle cover",
      "url": "https://en.wikipedia.org/wiki/Edge_cycle_cover",
      "text": "In [[mathematics]], an '''edge cycle cover''' (sometimes called simply '''cycle cover'''<ref>Cun-Quan Zhang, Integer flows and cycle covers of graphs, Marcel Dekker,1997.</ref>) of a [[Graph (discrete mathematics)|graph]] is a family of [[cycle (graph theory)|cycle]]s which are [[Glossary of graph theory#Subgraphs|subgraphs]] of ''G'' and contain all edges of ''G''. \n\nIf the cycles of the cover have no vertices in common, the cover is called '''vertex-disjoint''' or sometimes simply '''disjoint cycle cover'''. In this case the set of the cycles constitutes a [[spanning subgraph]] of ''G''.\n\nIf the cycles of the cover have no edges in common, the cover is called '''edge-disjoint''' or simply '''disjoint cycle cover'''.\n\n==Properties and applications==\n\n===Minimum-Weight Cycle Cover===\nFor a [[weighted graph]], the Minimum-Weight Cycle Cover Problem (MWCCP) is the problem to find a cycle cover with minimal sum of weights of edges in all cycles of the cover.\n\nFor [[bridge (graph theory)|bridge]]less [[planar graph]]s the MWCCP can be solved in [[polynomial time]]. <ref>\"Handbook in Graph Theory\" (2004) {{isbn|1-58488-090-2}}, [https://books.google.com/books?id=mKkIGIea_BkC&pg=PA225&lpg=PA225&dq=%22minimum+weight+cycle+cover%22&source=web&ots=VV2JRTVXzz&sig=RPtrYtXXqDFPfXv0OrX0gqLs8GE&hl=en&sa=X&oi=book_result&resnum=8&ct=result#PPA225,M1 p. 225]</ref>\n\n==Cycle k-cover==\nA '''cycle ''k''-cover''' of a graph is a family of cycles which cover every edge of ''G'' exactly ''k'' times. It has been proven that every bridgeless graph has cycle ''k''-cover for any integer even integer ''k≥4''. For ''k=2'', it is the well-known [[cycle double cover conjecture]] is an open problem in graph theory. The [[cycle double cover conjecture]]  states that in every [[Bridge (graph theory)|bridgeless]] graph there exists a set of cycles that together cover every edge of the graph twice.<ref>[http://www.cems.uvm.edu/%7Earchdeac/problems/cyclecov.htm \"The Cycle Double Cover Conjecture\"]</ref>\n\n==See also==\n*[[Alspach's conjecture]]\n*[[Vertex cycle cover]]\n\n==References==\n{{reflist}}\n\n[[Category:Graph theory objects]]\n[[Category:Combinatorial optimization]]"
    },
    {
      "title": "Jack Edmonds",
      "url": "https://en.wikipedia.org/wiki/Jack_Edmonds",
      "text": "'''Jack R. Edmonds''' (born April 5, 1934) is an American [[computer scientist]], regarded as one of the most important contributors to the field of [[combinatorial optimization]].\n\n==Research==\nA breakthrough contribution of Edmonds is the [[Cobham–Edmonds thesis]], defining the concept of polynomial time characterising the difference between a practical and an impractical algorithm (in modern terms, a [[tractable problem]] or intractable problem). Today, problems solvable in polynomial time are called the [[complexity class]] '''[[PTIME]]''', or simply '''[[P (complexity)|P]]'''. Another of Edmonds' earliest and most notable contributions is the [[blossom algorithm]] for constructing [[maximum matching]]s on graphs, discovered in 1961<ref name = \"glimpse\">{{Citation\n | last = Edmonds\n | first = Jack \n | contribution = A glimpse of heaven\n | year = 1991\n | title = History of Mathematical Programming – A Collection of Personal Reminiscences\n | editor = J.K. Lenstra |editor2=A.H.G. Rinnooy Kan |editor3=A. Schrijver\n | pages = 32–54\n | publisher = CWI, Amsterdam and North-Holland, Amsterdam }}</ref> and published in 1965.<ref name = \"algorithm\">\n{{cite journal\n  | doi = 10.4153/CJM-1965-045-4\n  | author = Edmonds, Jack\n  | title = Paths, trees, and flowers\n  | journal = Can. J. Math.\n  | volume = 17\n  | year = 1965\n  | pages = 449&ndash;467\n}}</ref> This was the first polynomial-time algorithm for maximum matching in graphs. Its generalization to weighted graphs<ref name = \"weighted\">\n{{cite journal\n  | author = Edmonds, Jack\n  | title = Maximum matching and a polyhedron with 0,1-vertices\n  | journal = Journal of Research of the National Bureau of Standards Section B\n  | volume = 69\n  | year = 1965\n  | pages = 125&ndash;130\n}}</ref> was a conceptual breakthrough in the use of [[linear programming]] ideas in [[combinatorial optimization]]. It sealed in the importance of there being proofs, or \"witnesses\", that the answer for an instance is yes and there being proofs, or \"witnesses\", that the answer for an instance is no. In this blossom algorithm paper, Edmonds also characterizes feasible problems as those solvable in polynomial time; this is one of the origins of the [[Cobham–Edmonds thesis]].<ref>{{cite book |title=Algorithms and Complexity |first=Gerard |last=Meurant |year=2014 |isbn=978-0-08093391-7 |page=[https://books.google.com/books?id=6WriBQAAQBAJ&pg=PA4&dq=Edmonds p. 4] |quote=A problem is said to be ''feasible'' if it can be solved in polynomial time (as stated for the first time in Edmonds [26] [1965, Paths, trees, and flowers])).}}</ref>\n\nAdditional landmark work of Edmonds is in the area of [[matroids]]. He found a polyhedral description for all [[spanning tree]]s of a graph, and more generally for all independent sets of a matroid.<ref name = \"matroid\">\n{{cite journal\n  | author = Edmonds, Jack\n  | title = Matroids and the greedy algorithm\n  | journal = Math. Programming (Princeton Symposium Math. Prog. 1967)\n  | volume = 1\n  | year = 1971\n  | pages = 127&ndash;136\n}}</ref> Building on this, as a novel application of linear programming to discrete mathematics, he proved the [[matroid intersection]] theorem, a very general combinatorial min-max theorem<ref name=\"intersection\">{{citation\n | last = Edmonds\n | first = Jack\n | contribution = Submodular functions, matroids, and certain polyhedra\n | editor = R. Guy |editor2=H. Hanam |editor3=N. Sauer |editor4=J. Schonheim\n | title = Combinatorial structures and their applications (Proc. 1969 Calgary Conference)\n | pages = 69&ndash;87\n | publisher = Gordon and Breach, New York\n | year = 1970\n}}.</ref><ref name=\"eureka\" /> which, in modern terms, showed that the matroid intersection problem lay in both [[NP (complexity)|NP]] and [[co-NP]].\n\nEdmonds is well known for his theorems on [[Chu–Liu/Edmonds algorithm|max-weight branching algorithms]]<ref name = \"wbranchings\">\n{{cite journal\n  | author = Edmonds, Jack\n  | title = Optimum Branchings\n  | journal = J. Res. Nat. Bur. Standards\n  | year = 1967\n  | volume = 71B\n  | pages = 233&ndash;240\n}}</ref> and packing edge-disjoint branchings<ref name = \"branchings\">\n{{citation \n  | author = Edmonds, Jack\n  | title = Edge-disjoint branchings\n  | journal = Combinatorial Algorithms |conference=Courant Computer Science Symposium 9, 1972 |location= Monterey, California, 1972  |editor=R. Rustin\n  | publisher = Algorithmics Press, New York\n  | year = 1973\n  | pages = 91&ndash;96\n}}</ref> and his work with [[Richard Karp]] on [[Edmonds–Karp algorithm|faster flow algorithms]]. The [[Gallai–Edmonds decomposition|Edmonds–Gallai decomposition theorem]] describes finite graphs from the point of view of matchings. He introduced [[polymatroid]]s,<ref name=\"intersection\" /> [[submodular]] flows with Richard Giles,<ref name = \"subflows\">\n{{citation \n  |author1=Edmonds, Jack  |author2=Giles, Richard\n  | title = A min-max relation for submodular functions on graphs\n  | journal = Studies in Integer Programming |conference=Proceedings Workshop on Integer Programming, Bonn, 1975  |editor=P.L. Hammer |editor2=E.L. Johnson |editor3=B.H. Korte |editor4=G.L. Nemhauser\n  | volume = 1\n  | series = Annals of Discrete Mathematics\n  | publisher = North-Holland, Amsterdam\n  | year = 1977\n  | pages = 185&ndash;204\n}}</ref> and the terms [[clutter (mathematics)|clutter]] and blocker in the study of [[hypergraph]]s.<ref name = \"glimpse\" /> A recurring theme in his work<ref name=\"Witzgall\">\n{{citation \n  | author = Christoph Witzgall\n  | contribution = Paths, Trees, and Flowers\n  | title = A Century of Excellence in Measurements, Standards, and Technology\n  | publisher = National Institute of Standards and Technology \n  | year = 2001\n  | pages = 140&ndash;144\n  | url = http://nvl.nist.gov/pub/nistpubs/sp958-lide/140-144.pdf\n}}</ref> is to seek algorithms whose time complexity is polynomially bounded by their input size and bit-complexity.<ref name = \"glimpse\" />\n\n==Career==\nEdmonds graduated with a baccalaureate degree from [[George Washington University]] in 1958, and obtained a master's degree from the [[University of Maryland, College Park|University of Maryland]] in 1959, with a thesis on the problem of embedding graphs\ninto surfaces.\n\nFrom 1959 to 1969 he worked at the [[National Institute of Standards and Technology]] (then the National Bureau of Standards), and was a founding member of [[Alan J. Goldman|Alan Goldman]]’s newly created Operations Research Section in 1961.\n\nFrom 1969 on, with the exception of 1991–1993, he held a faculty position at the Department of Combinatorics and Optimization at the [[University of Waterloo]]'s [[University of Waterloo Faculty of Mathematics|Faculty of Mathematics]]. He supervised the doctoral work of a dozen students in this time.\n\nFrom 1991 to 1993, he was involved in a dispute (\"the Edmonds affair\") with the University of Waterloo,<ref>[https://web.archive.org/web/20120605150100/http://www.communications.uwaterloo.ca/Gazette/1992/Gazette,%20October%207,%201992/CAUT%20called%20in%20on%20Jack%20Edmonds%20case UW Gazette, October 7, 1992: CAUT called in on Jack Edmonds case]</ref><ref>[http://arts.uwaterloo.ca/~kwesthue/workplmobintro Editor's introduction], in: Kenneth Westhues, ed., Workplace Mobbing in Academe: Reports from Twenty Universities, Lewiston: NY: The Edwin Mellen Press, 2004</ref> wherein the university claimed that a letter submitted constituted a letter of resignation, which Edmonds denied.<ref>[http://www.bulletin.uwaterloo.ca/2001/mar/05mo.html University of Waterloo Daily Bulletin, March 5 2001: Conference honours Jack Edmonds]</ref> The conflict was resolved in 1993, and he returned to the university.\n\nEdmonds retired in 1999. The fifth [[Aussois]] Workshop on Combinatorial Optimization in 2001 was dedicated to him.<ref name = \"eureka\">\n{{citation |editor1=Jünger, Michael |editor2=Reinelt, Gerhard |editor3=Rinaldi, Giovanni | title = Combinatorial Optimization – Eureka, You Shrink! | journal = Lecture Notes in Computer Science |volume=2570 | publisher = Springer | year = 2003}}</ref>\n\n==Personal life==\nJack's son Jeff Edmonds is a professor of computer science at [[York University]], and his wife Kathie Cameron is a professor of mathematics at [[Laurier University]].\n\n== See also ==\n* [[Edmonds matrix]]\n\n==References==\n<references/>\n\n==External links==\n* {{MathGenealogy |id=44142}}\n* [https://www.informs.org/content/view/full/271949 Biography of Jack Edmonds] from the Institute for Operations Research and the Management Sciences\n\n{{John von Neumann Theory Prize recipients}}\n{{Authority control}}\n\n{{DEFAULTSORT:Edmonds, Jack}}\n[[Category:Combinatorialists]]\n[[Category:John von Neumann Theory Prize winners]]\n[[Category:Canadian mathematicians]]\n[[Category:20th-century mathematicians]]\n[[Category:University of Waterloo faculty]]\n[[Category:1934 births]]\n[[Category:Living people]]\n[[Category:Combinatorial optimization]]\n[[Category:Canadian computer scientists]]"
    },
    {
      "title": "European Chapter on Combinatorial Optimization",
      "url": "https://en.wikipedia.org/wiki/European_Chapter_on_Combinatorial_Optimization",
      "text": "{{Infobox organization\n| name = ECCO, European Chapter on Combinatorial Optimization\n| image =EWG_ECCO.png\n| formation     = 1987\n| status        = Working group\n| purpose       = To promote combinatorial optimization\n| region        = Europe\n| parent_organization = [[Association of European Operational Research Societies]] \n| website       = {{url|http://ecco.grenoble-inp.fr/}}\n}}\n\nThe '''European Chapter on Combinatorial Optimization (also, EURO Working Group on Combinatorial Optimization, or EWG ECCO)''' \nis a [[working group]] whose objective is to promote original research in the field of [[combinatorial optimization]] at the \nEuropean level. \n<ref>{{Cite web | url=http://www.euro-online.org/web/ewg/9/ewg-ecco-european-chapter-on-combinatorial-optimization | title=EURO - the Association of European Operational Research Societies - EWG ECCO, EURO working group on Combinatorial Optimization}}</ref> \n<ref>{{Cite web | url=http://ecco.grenoble-inp.fr | title=European Chapter on Combinatorial Optimization - Welcome}}</ref>\n\n== History ==\nECCO is one of the working groups of EURO, the [[Association of European Operational Research Societies]]. \nThe Group was founded in 1987 by Catherine Roucairol, [[Alexander Rinnooy Kan]], and Dominique de Werra.\t\t\n\t\t\t\t\t\t\t\t\n== Governance ==\nThe group is managed by a Coordinator and an Advisory Board of 4 members. The current coordinator is Silvano Martello. \n<ref>[http://www.or.deis.unibo.it/staff_pages/martello/cvitae.html]</ref>\n\n== Membership ==\nThe group is suitable for people who are presently engaged in Combinatorial Optimization, either in theoretical aspects or in business, \nindustry or public administration applications. Currently (2015), the group has about 1,400 members from 77 countries.\n\n== Conferences ==\n\nECCO holds conferences on a regular basis (once a year during Spring). An abstract booklet is distributed to the participants at each \nmeeting.\n\n== Publications ==\nIn most cases, the annual conference is followed by a peer reviewed special issue of an international journal, presenting a selection \nof the contributions presented at the meeting. Recent special issues appeared on ''Annals of Operations Research'' \n,<ref>[https://link.springer.com/journal/10479/207/1/page/1]</ref> \n''Optimization'',<ref>{{Cite journal | doi=10.1080/02331934.2013.850255|title = An overview of advances in combinatorial optimization related topics| journal=Optimization| volume=62| issue=10| pages=1291–1295|year = 2013|last1 = Martello|first1 = Silvano| last2=Weber| first2=Gerhard-Wilhelm| last3=Kasimbeyli| first3=Refail}}</ref>   \n''Journal of Scheduling'',<ref>{{Cite journal | doi=10.1007/s10951-010-0170-4|title = Combinatorial optimization issues in scheduling| journal=Journal of Scheduling| volume=14| issue=3| pages=221–223|year = 2011|last1 = Blazewicz|first1 = Jacek| last2=Boljunčić| first2=Valter| last3=Martello| first3=Silvano| last4=Skorin-Kapov| first4=Jadranka}}</ref> and\n''Discrete Applied Mathematics''.<ref>[http://www.sciencedirect.com/science/journal/0166218X/196]</ref>\n\nA newsletter is emailed to all members every three months.\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{url|http://ifors.org/newsletter/june2012_web.pdf}}\n* {{url|http://ifors.org/newsletter/september-2013.pdf}}\n* {{url|http://ifors.org/newsletter/sept2014-newsletter.pdf}}\n* {{url|http://ifors.org/newsletter/ifors-news-sept2015.pdf}}\n\n[[Category:Combinatorial optimization]]\n[[Category:Working groups]]\n[[Category:Organizations established in 1987]]"
    },
    {
      "title": "Extremal combinatorics",
      "url": "https://en.wikipedia.org/wiki/Extremal_combinatorics",
      "text": "'''Extremal combinatorics''' is a field of [[combinatorics]], which is itself a part of [[mathematics]]. Extremal combinatorics studies how large or how small a collection of finite objects ([[number]]s, [[Graph (discrete mathematics)|graph]]s, [[vector space|vector]]s, [[Set (mathematics)|sets]], etc.) can be, if it has to satisfy certain restrictions.\n\nMuch of extremal combinatorics concerns [[class (set theory)|class]]es of sets; this is called '''extremal set theory'''.  For instance, in an ''n''-element set, what is the largest number of ''k''-element [[subset]]s that can pairwise intersect one another?  What is the largest number of subsets of which none contains any other?  The latter question is answered by [[Sperner family#Sperner's theorem|Sperner's theorem]], which gave rise to much of extremal set theory.\n\nAnother kind of example:  How many people can we invite to a party where among each three people there are two who know each other and two who don't know each other? [[Ramsey theory]] shows that at most five persons can attend such a party. Or, suppose we are given a finite set of nonzero integers, and are asked to mark as large a subset as possible of this set under the restriction that the sum of any two marked integers cannot be marked. It appears that (independent of what the given integers actually are!) we can always mark at least one-third of them.\n\n==See also==\n*[[Extremal graph theory]]\n*[[Sauer–Shelah lemma]]\n*[[Erdős–Ko–Rado theorem]]\n*[[Kruskal&ndash;Katona theorem]]\n*[[Fisher's inequality]]\n*[[Union-closed_sets_conjecture]]\n\n==References==\n\n*{{citation\n | last = Jukna | first1 = Stasys \n | publisher = Birkhäuser Verlag\n | title = Extremal Combinatorics, With Applications in Computer Science\n | url = http://lovelace.thi.informatik.uni-frankfurt.de/~jukna/EC_Book/preface.html\n | isbn = 3-540-66313-4\n | year = 2011}}.\n\n*{{Citation\n | last1 = Alon | first1 = Noga | author1-link = Noga Alon\n | last2 = Krivelevich | first2 = Michael | author2-link = Michael Krivelevich\n | url = http://www.math.tau.ac.il/~nogaa/PDFS/epc7.pdf \n | title = Extremal and Probabilistic Combinatorics\n | year = 2006}}.\n\n*{{Citation\n | last1 = Frankl | first1 = Peter | author1-link = Péter Frankl\n | last2 = Rödl | first2 = Vojtěch | author2-link = Vojtěch Rödl\n | title = Forbidden intersections\n | journal = Transactions of the American Mathematical Society \n | volume = 300\n | issue = 1\n | pages = 259–286\n | year = 1987 | doi=10.2307/2000598}}.\n\n[[Category:Combinatorics|*]]\n[[Category:Combinatorial optimization]]"
    },
    {
      "title": "Floorplan (microelectronics)",
      "url": "https://en.wikipedia.org/wiki/Floorplan_%28microelectronics%29",
      "text": "{{Use American English|date = April 2019}}\n{{Short description|electronic circuit schematic showing major functional blocks}}\n[[File:floorplan.png|thumb|right|300px|Mock floorplan in an [[IC layout editor]] [[window (computing)|window]] ]]\nIn [[electronic design automation]], a '''floorplan''' of an [[integrated circuit]] is a schematic representation of tentative [[placement (EDA)|placement]] of its major functional blocks.\n\nIn modern electronic design process floorplans are created during the '''floorplanning''' design stage, an early stage in the hierarchical approach to [[integrated circuit design]].\n\nDepending on the design methodology being followed, the actual definition of a floorplan may differ.\n\n==Floorplanning==\nFloorplanning takes in some of the geometrical constraints in a design. Examples of this are:\n\n* [[bonding pad]]s for off-chip connections (often using [[wire bonding]]) are normally located at the circumference of the chip;\n* [[line driver]]s often have to be located as close to bonding pads as possible;\n* chip area is therefore in some cases given a minimum area in order to fit in the required number of pads;\n* areas are clustered in order to limit data paths thus frequently featuring defined structures such as [[CPU cache|cache]] [[Random-access memory|RAM]], [[Multiplication|multiplier]], [[barrel shifter]], [[line driver]] and [[arithmetic logic unit]];\n* purchased intellectual property blocks ([[Semiconductor intellectual property core|IP-blocks]]), such as a [[processor core]], come in predefined area blocks;\n* some IP-blocks come with legal limitations such as permitting no routing of signals directly above the block.\n\n==Mathematical models and optimization problems==\n\nIn some approaches the floorplan may be a partition of the whole chip area into [[axis aligned rectangle]]s to be occupied by IC blocks. This partition is subject to various constraints and requirements of optimization: block area, [[aspect ratio]]s, estimated total measure of interconnects, etc.\n\nFinding good floorplans has been a research area in [[combinatorial optimization]]. Most of the problems related to finding optimal floorplans are [[NP-hard]], i.e., require vast computational resources. Therefore, the most common approach is to use various optimization heuristics for finding good solutions.\n\nAnother approach is to restrict design methodology to certain classes of floorplans, such as sliceable floorplans. \n\n===Sliceable floorplans===\n[[File:Flo-01.png|thumb|right|200px|A sliceable floorplan, with a slicing order indicated]]\n[[File:Flo-02.png|thumb|right|200px|The simplest non-sliceable floorplan]]\nA '''sliceable  floorplan''' is a floorplan that may be defined recursively as described below. <ref name=dorf>\"The Electrical Engineering Handbook\", Richard C. Dorf (1997) {{ISBN|0-8493-8574-1}}</ref>\n*A floorplan that consists of a single rectangular block is sliceable.\n*If a block from a sliceable floorplan is cut (\"sliced\") in two by a vertical or horizontal line, the resulting floorplan is sliceable.\n\nSliceable floorplans have been used in a number of  early [[Electronic Design Automation]] tools<ref name=dorf/> for a number of reasons. Sliceable floorplans may be conveniently represented by [[binary tree]]s (more specifically, [[k-d tree|''k''-d trees]]), which correspond to the order of slicing. More importantly, a number of NP-hard problems with floorplans have [[polynomial time]] algorithms when restricted to sliceable floorplans.<ref>Sarrafzadeh, M, \"Transforming an arbitrary floorplan into a sliceable one\", Proc. 1993 IEEE/ACM International Conference on Computer-Aided Design (ICCAD-93), pp. 386-389. </ref>\n\n==Further reading==\n* [http://www.schoelzke.info/mirror/galway/projects/ChipPlanner-Description.htm The Chip Planner of the PLAYOUT System]\n\n==References==\n{{reflist}}\n\n[[Category:Electronic design automation]]\n[[Category:Electronics optimization]]\n[[Category:Combinatorial optimization]]"
    },
    {
      "title": "Generalized assignment problem",
      "url": "https://en.wikipedia.org/wiki/Generalized_assignment_problem",
      "text": "{{short description|combinatorial optimization problem}}\nIn [[applied mathematics]], the maximum '''generalized assignment problem''' is a problem in [[combinatorial optimization]].  This problem is a [[generalization]] of the [[assignment problem]] in which both tasks and [[Agent-based model|agents]] have a size. Moreover, the size of each task might vary from one agent to the other.\n\nThis problem in its most general form is as follows:\n\nThere are a number of agents and a number of tasks. Any agent can be assigned to perform any task, incurring some cost and profit that may vary depending on the agent-task assignment. Moreover, each agent has a budget and the sum of the costs of tasks assigned to it cannot exceed this budget. It is required to find an assignment in which all agents do not exceed their budget and total profit of the assignment is maximized.\n\n==In special cases==\nIn the special case in which all the agents' budgets and all tasks' costs are equal to 1, this problem reduces to the [[assignment problem]]. When the costs and profits of all tasks do not vary between different agents, this problem reduces to the multiple knapsack problem. If there is a single agent, then, this problem reduces to the [[knapsack problem]].\n\n==Explanation of definition==\nIn the following, we have ''n'' kinds of items, <math>a_1</math> through <math>a_n</math> and ''m'' kinds of bins <math>b_1</math> through <math>b_m</math>. Each bin <math>b_i</math> is associated with a budget <math>t_i</math>. For a bin <math>b_i</math>, each item <math>a_j</math> has a profit <math>p_{ij}</math> and a weight <math>w_{ij}</math>.  A solution is an assignment from items to bins. A feasible solution is a solution in which for each bin <math>b_i</math> the total weight of assigned items is at most <math>t_i</math>. The solution's profit is the sum of profits for each item-bin assignment. The goal is to find a maximum profit feasible solution.\n\nMathematically the generalized assignment problem can be formulated as an [[Integer programming|integer program]]:\n\n: <math>\n\\begin{align}\n\\text{maximize } & \\sum_{i=1}^m\\sum_{j=1}^n p_{ij} x_{ij}. \\\\\n\\text{subject to } & \\sum_{j=1}^n w_{ij} x_{ij} \\le t_i & & i=1, \\ldots, m; \\\\\n& \\sum_{i=1}^m x_{ij} = 1 & & j=1, \\ldots, n; \\\\\n& x_{ij} \\in \\{0,1\\} & & i=1, \\ldots, m, \\quad j=1, \\ldots, n;\n\\end{align}\n</math>\n\n== Complexity ==\nThe generalized assignment problem is [[NP-hard]],<ref>{{citation\n | last1 = Özbakir | first1 = Lale\n | last2 = Baykasoğlu | first2 =  Adil\n | last3 = Tapkan | first3 =  Pınar\n | pages = 3782–3795\n | publisher = Elsevier\n | series = Applied Mathematics and Computation\n | title = Bees algorithm for generalized assignment problem\n | url = http://www.sciencedirect.com/science/article/pii/S0096300309010078\n | volume = 215\n | year = 2010}}.</ref> and it is even [[APX-hard]] to approximate it. Recently it was shown that an extension of it is <math>e/(e-1) - \\varepsilon</math> hard to approximate for every <math>\\varepsilon</math>.{{Citation needed|date=November 2012}}\n\n==Greedy approximation algorithm==\nUsing any <math> \\alpha</math>-approximation algorithm ALG for the [[knapsack problem]], it is possible to construct a (<math> \\alpha+1</math>)-approximation for the generalized assignment problem in a greedy manner using a residual profit concept.\nThe algorithm constructs a schedule in iterations, where during iteration <math>j</math> a tentative selection of items to bin <math>b_j</math> is selected.\nThe selection for bin <math>b_j</math> might change as items might be reselected in a later iteration for other bins.\nThe residual profit of an item <math>x_i</math> for bin <math>b_j</math> is <math>p_{ij}</math> if <math>x_i</math> is not selected for any other bin or <math> p_{ij}</math> – <math>p_{ik} </math> if <math>x_i</math> is selected for bin <math>b_k</math>.\n\nFormally: We use a vector <math>T</math> to indicate the tentative schedule during the algorithm. Specifically, <math>T[i]=j</math> means the item <math>x_i</math> is scheduled on bin <math>b_j</math> and <math>T[i]=-1</math> means that item <math>x_i</math> is not scheduled. The residual profit in iteration <math>j</math> is denoted by <math>P_j</math>, where <math>P_j[i]=p_{ij}</math> if item <math>x_i</math> is not scheduled (i.e. <math>T[i]=-1</math>) and <math>P_j[i]=p_{ij}-p_{ik}</math> if item <math>x_i</math> is scheduled on bin <math>b_k</math> (i.e. <math>T[i]=k</math>).\n\nFormally:\n: Set <math>T[i]=-1 \\text{ for } i = 1\\ldots n</math>\n: For <math>j=1,\\ldots,m</math> do:\n:: Call ALG to find a solution to bin <math>b_j</math> using the residual profit function <math>P_j</math>. Denote the selected items by <math>S_j</math>.\n:: Update <math>T</math> using <math>S_j</math>, i.e., <math>T[i]=j</math> for all <math>i \\in S_j</math>.\n\n==See also==\n*[[Assignment problem]]\n\n== References ==\n{{Reflist}}\n* Reuven Cohen, Liran Katzir, and Danny Raz, [http://www.cs.technion.ac.il/~lirank/pubs/2006-IPL-Generalized-Assignment-Problem.pdf \"An Efficient Approximation for the Generalized Assignment Problem\"], Information Processing Letters, Vol. 100, Issue 4, pp.&nbsp;162–166, November 2006.  \n* Lisa Fleischer, Michel X. Goemans, Vahab S. Mirrokni, and Maxim Sviridenko, [http://www-math.mit.edu/~goemans/PAPERS/ga-soda06.pdf \"Tight Approximation Algorithms for Maximum General Assignment Problems\"], SODA 2006, pp.&nbsp;611–620.\n* Hans Kellerer, Ulrich Pferschy, David Pisinger, ''Knapsack Problems '', 2005. Springer Verlag {{ISBN|3-540-40286-1}}\n\n== External links ==\n\n[[Category:NP-complete problems]]\n[[Category:Combinatorial optimization]]"
    }
  ]
}