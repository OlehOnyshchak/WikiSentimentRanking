{
  "pages": [
    {
      "title": "Ekeland's variational principle",
      "url": "https://en.wikipedia.org/wiki/Ekeland%27s_variational_principle",
      "text": "In [[mathematical analysis]], '''Ekeland's variational principle''', discovered by [[Ivar Ekeland]],<ref name=\"Eke74\">{{cite journal\n|     doi = 10.1016/0022-247X(74)90025-0\n|     last = Ekeland\n|    first = Ivar\n|    title = On the variational principle\n|  journal = J. Math. Anal. Appl.\n|   volume = 47\n|     year = 1974\n|    pages = 324&ndash;353\n|     issn = 0022-247X\n}}</ref><ref>{{cite journal|last=Ekeland|first=Ivar|<!-- authorlink=Ivar Ekeland -->|title=Nonconvex minimization problems|journal=Bulletin of the American Mathematical Society|series=New Series|volume=1|year=1979|number=3|pages=443–474|doi=10.1090/S0273-0979-1979-14595-6|mr=526967|ref=harv}}</ref><ref>{{cite book|last1=Ekeland|first1=Ivar|last2=Temam|first2=Roger|authorlink=Roger Temam|title=Convex analysis and variational problems|edition=Corrected reprinting of the (1976) North-Holland|series=Classics in applied mathematics|volume=28 |publisher=Society for Industrial and Applied Mathematics&nbsp;(SIAM)|location=Philadelphia,&nbsp;PA|year=1999|pages=357–373|isbn=0-89871-450-8|mr=1727362|ref=harv}}</ref> is a theorem that asserts that there exists nearly optimal solutions to some [[optimization problem]]s.\n\nEkeland's variational principle can be used when the lower [[level set]] of a minimization problems is not [[compactness (topology)|compact]], so that the [[Bolzano&ndash;Weierstrass theorem]] cannot be applied. Ekeland's principle relies on the [[complete metric space|completeness]] of the [[metric space]].<ref name=\"KG90\"/>\n\nEkeland's principle leads to a quick proof of the [[Caristi fixed point theorem]].<ref name=\"KG90\">{{cite book\n |author1=Kirk, William A. |author2=Goebel, Kazimierz | title      = Topics in Metric Fixed Point Theory\n | year       = 1990\n | publisher  = Cambridge University Press\n | isbn         = 0-521-38289-0\n}}</ref><ref name=\"realanalysisok\">{{cite book|last=Ok|first=Efe|title=Real Analysis with Economic Applications|publisher=Princeton University Press|year=2007|pages=664|chapter=D: Continuity I|isbn=978-0-691-11768-3|url=http://homepages.nyu.edu/~eo1/Book-PDF/Ekeland.pdf|accessdate=January 31, 2009}}</ref>\n\nEkeland's principle has been shown by F. Sullivan to be equivalent to completeness of metric spaces.\n\nEkeland was associated with the [[Paris Dauphine University]] when he proposed this theorem.<ref name=\"Eke74\"/>\n\n==Statement of the theorem==\n\nLet (''X'',&nbsp;''d'') be a [[complete metric space]], and let ''F'':&nbsp;''X''&nbsp;→&nbsp;'''R'''&nbsp;∪&nbsp;{+∞} be a [[lower semicontinuous]] functional on ''X'' that is bounded below and not identically equal to +∞.  Fix ''&epsilon;''&nbsp;&gt;&nbsp;0 and a point ''u''&nbsp;∈&nbsp;''X'' such that\n:<math>F(u) \\leq \\varepsilon + \\inf_{x \\in X} F(x).</math>\nThen, for every ''&lambda;''&nbsp;&gt;&nbsp;0, there exists a point ''v''&nbsp;∈&nbsp;''X'' such that\n:<math>F(v) \\leq F(u),</math>\n:<math>d(u, v) \\leq \\lambda,</math>\nand, for all ''w''&nbsp;≠&nbsp;''v'',\n:<math>F(w) > F(v) - \\frac{\\varepsilon}{\\lambda} d(v, w).</math>\n\n== References ==\n<references />\n\n==Further reading==\n* {{cite journal|last=Ekeland|first=Ivar|authorlink=Ivar Ekeland|title=Nonconvex minimization problems|journal=Bulletin of the American Mathematical Society|series=New Series|volume=1|year=1979|number=3|pages=443–474|doi=10.1090/S0273-0979-1979-14595-6|mr=526967|ref=harv}}\n*{{cite book\n |author1=Kirk, William A. |author2=Goebel, Kazimierz | title      = Topics in Metric Fixed Point Theory\n | year       = 1990\n | publisher  = Cambridge University Press\n | isbn         = 0-521-38289-0\n}}\n\n[[Category:Convex analysis]]\n[[Category:Theorems in functional analysis]]\n[[Category:Variational principles]]"
    },
    {
      "title": "Fenchel–Moreau theorem",
      "url": "https://en.wikipedia.org/wiki/Fenchel%E2%80%93Moreau_theorem",
      "text": "[[Image:Upper semi.svg|thumb|right|A function that is not [[lower semi-continuous]]. By the Fenchel-Moreau theorem, this function is not equal to its [[biconjugate]].]]\n\nIn [[convex analysis]], the '''Fenchel–Moreau theorem''' (named after [[Werner Fenchel]] and [[Jean Jacques Moreau]]) or '''Fenchel biconjugation theorem''' (or just '''biconjugation theorem''') is a [[theorem]] which gives [[necessary and sufficient conditions]] for a function to be equal to its [[biconjugate]].  This is in contrast to the general property that for any function <math>f^{**} \\leq f</math>.<ref name=\"BorweinLewis\">{{cite book |last1=Borwein |first1=Jonathan |authorlink1=Jonathan Borwein|last2=Lewis |first2=Adrian |title=Convex Analysis and Nonlinear Optimization: Theory and Examples| edition=2 |year=2006 |publisher=Springer |isbn=9780387295701|pages=76–77}}</ref><ref name=\"Zalinescu\">{{cite book |last=Zălinescu |first=Constantin |title=Convex analysis in general vector spaces |publisher=World Scientific Publishing&nbsp;Co.,&nbsp;Inc. |isbn=981-238-067-1 |mr=1921556 |issue=J |year=2002 |location=River Edge, NJ |pages=75–79}}</ref>  This can be seen as a generalization of the [[bipolar theorem]].<ref name=\"BorweinLewis\"/>  It is used in [[duality (optimization)|duality theory]] to prove [[strong duality]] (via the [[perturbation function]]).\n\n== Statement of theorem ==\nLet <math>(X,\\tau)</math> be a [[Hausdorff space|Hausdorff]] [[locally convex space]], for any [[extended real]] valued function <math>f: X \\to \\mathbb{R} \\cup \\{\\pm \\infty\\}</math> it follows that <math>f = f^{**}</math> if and only if one of the following is true\n# <math>f</math> is a [[proper convex function|proper]], [[lower semi-continuous]], and [[convex function]],\n# <math>f \\equiv +\\infty</math>, or\n# <math>f \\equiv -\\infty</math>.<ref name=\"BorweinLewis\"/><ref>{{cite journal | author = Hang-Chin Lai  | author2 = Lai-Jui Lin | date=May 1988 | title = The Fenchel-Moreau Theorem for Set Functions | journal = Proceedings of the American Mathematical Society | publisher = American Mathematical Society | volume = 103 | issue = 1 | pages = 85–90 | doi = 10.2307/2047532 | url =  | format =  | accessdate = }}</ref><ref>{{cite journal|title=A generalization of the Fenchel–Moreau theorem|author=Shozo Koshi|author2=Naoto Komuro|journal=<abbr title=\"Proceedings of the Japan Academy, Series A Mathematical Sciences\">Proc. Japan Acad. Ser. A Math. Sci.</abbr>|volume=59|issue=5|year=1983|pages=178–181}}</ref>\n\n== References ==\n{{Reflist}}\n\n{{DEFAULTSORT:Fenchel-Moreau theorem}}\n[[Category:Convex analysis]]\n[[Category:Theorems in analysis]]"
    },
    {
      "title": "Gauss–Lucas theorem",
      "url": "https://en.wikipedia.org/wiki/Gauss%E2%80%93Lucas_theorem",
      "text": "In [[complex analysis]], a branch of mathematics, the '''Gauss–Lucas theorem''' gives a [[geometry|geometrical]] relation between the [[root of a function|root]]s of a [[polynomial]] ''P'' and the roots of its [[derivative]] ''P′''. The set of roots of a real or complex polynomial is a set of [[point (geometry)|points]] in the [[complex plane]]. The theorem states that the roots of ''P′'' all lie within the [[convex hull]] of the roots of ''P'', that is the smallest [[convex polygon]] containing the roots of ''P''. When ''P'' has a single root then this convex hull is a single point and when the roots lie on a [[line (geometry)|line]] then the convex hull is a [[line segment|segment]] of this line. The Gauss–Lucas theorem, named after [[Carl Friedrich Gauss]] and Félix Lucas, is similar in spirit to [[Rolle's theorem]].\n\n==Formal statement==\nIf ''P'' is a (nonconstant) polynomial with complex coefficients, all [[root of a function|zeros]] of ''P′'' belong to the convex hull of the set of zeros of&nbsp;''P''.<ref>Marden (1966), Theorem (6,1).</ref>\n\n==Special cases ==\nIt is easy to see that if ''P''(''x'') = ''ax''<sup>2</sup> + ''bx'' + ''c'' is a [[second degree polynomial]], the zero of ''P′''(''x'') = 2''ax'' + ''b'' is the [[average]] of the roots of ''P''. In that case, the convex hull is the line segment with the two roots as endpoints and it is clear that the average of the roots is the middle point of the segment. \n\nFor a third degree complex polynomial ''P'' ([[cubic function]]) with three distinct zeros, [[Marden's theorem]] states that the zeros of ''P′'' are the foci of the [[Steiner inellipse]] which is the unique ellipse tangent to the midpoints of the triangle formed by the zeros of ''P''. \n\nFor a fourth degree complex polynomial ''P'' ([[quartic function]]) with four distinct zeros forming a concave [[quadrilateral]], one of the zeros of ''P'' lies within the convex hull of the other three; all three zeros of ''P′'' lie in two of the three triangles formed by the interior zero of ''P'' and two others zeros of ''P''.<ref>{{cite journal |first=A. |last=Rüdinger |year=2014 |title= Strengthening the Gauss–Lucas theorem for polynomials with Zeros in the interior of the convex hull |work=[[Preprint]] |arxiv= 1405.0689 |bibcode=2014arXiv1405.0689R }}</ref>\n\nIn addition, if a polynomial of degree ''n'' of [[real number|real coefficients]] has ''n'' distinct real zeros <math>x_1<x_2<\\cdots <x_n,</math> we see, using [[Rolle's theorem]], that the zeros of the derivative polynomial are in the interval <math>[x_1,x_n]</math> which is the convex hull of the set of roots.\n\nThe convex hull of the roots of the polynomial \n\n:<math> p_n x^n+p_{n-1}x^{n-1}+\\cdots +p_0 </math> \n\nparticularly includes the point \n\n:<math>-\\frac{p_{n-1}}{n\\cdot p_n}.</math>\n\n== Proof ==\nOver the complex numbers, ''P'' is a product of prime factors \n\n:<math> P(z)= \\alpha \\prod_{i=1}^n (z-a_i) </math>\n\nwhere the complex numbers <math>a_1, a_2, \\ldots, a_n</math> are the – not necessary distinct – zeros of the polynomial ''P'', the complex number <math>\\alpha</math> is the leading coefficient of ''P'' and ''n'' is the degree of ''P''. Let ''z'' be any complex number for which <math>P(z) \\neq 0.</math> Then we have for the [[logarithmic derivative]]\n\n:<math> \\frac{P^\\prime(z)}{P(z)}= \\sum_{i=1}^n \\frac{1}{z-a_i}. </math>\n\nIn particular, if ''z'' is a zero of <math>P'</math> and <math>P(z) \\neq 0</math>, then\n\n:<math>\\sum_{i=1}^n \\frac{1}{z-a_i}=0</math>\n\nor \n\n:<math>\\sum_{i=1}^n \\frac{\\overline{z}-\\overline{a_i}} {|z-a_i|^2}=0. </math>\n\nThis may also be written as\n \n:<math>\\left(\\sum_{i=1}^n \\frac{1}{|z-a_i|^2}\\right)\\overline{z}= \\left(\\sum_{i=1}^n\\frac{1}{|z-a_i|^2}\\overline{a_i}\\right).</math>\n\nTaking their conjugates, we see that <math>z</math> is a weighted sum with positive coefficients that sum to one, or the [[Barycentric coordinates (astronomy)|barycenter on affine coordinates]], of the complex numbers <math>a_i</math> (with different mass assigned on each root whose weights collectively sum to 1).\n\nIf <math>P(z)=P'(z)=0,</math> then \n\n:<math>z=1\\cdot a_i +\\left(\\sum_{j=1, j\\neq i}^n 0\\cdot{a_j}\\right)</math> \n\nfor some ''i'', and is still a [[convex combination]] of the roots of <math>P</math>.\n\n== See also ==\n{{Div col|colwidth=25em}}\n* [[Marden's theorem]]\n* [[Bôcher's theorem]]\n* [[Sendov's conjecture]]\n* [[Routh–Hurwitz theorem]]\n* [[Hurwitz's theorem (complex analysis)]]\n* [[Descartes' rule of signs]]\n* [[Rouché's theorem]]\n* [[Properties of polynomial roots]]\n{{div col end}}\n\n== Notes ==\n{{reflist}}\n\n== References ==\n* Morris Marden, ''Geometry of Polynomials'', AMS, 1966.\n\n== External links ==\n* [http://demonstrations.wolfram.com/LucasGaussTheorem/ Lucas–Gauss Theorem] by Bruce Torrence, the [[Wolfram Demonstrations Project]].\n\n{{DEFAULTSORT:Gauss-Lucas Theorem}}\n[[Category:Convex analysis]]\n[[Category:Articles containing proofs]]\n[[Category:Theorems in complex analysis]]\n[[Category:Polynomials]]"
    },
    {
      "title": "Hilbert projection theorem",
      "url": "https://en.wikipedia.org/wiki/Hilbert_projection_theorem",
      "text": "In mathematics, the '''Hilbert projection theorem''' is a famous result of [[convex analysis]] that says that for every point <math>x</math> in a [[Hilbert space]] <math>H</math> and every nonempty closed convex <math>C \\subset H</math>, there exists a unique point <math>y \\in C</math> for which <math>\\lVert x - y \\rVert</math> is minimized over <math>C</math>.  \n\nThis is, in particular, true for any closed subspace <math>M</math> of <math>H</math>. In that case, a necessary and sufficient condition for <math>y</math> is that the vector <math> x-y</math> be orthogonal to <math>M</math>.\n\n==Proof==\n:* ''Let us show the existence of ''y'':''\nLet δ be the distance between ''x'' and ''C'', (''y''<sub>''n''</sub>) a sequence in ''C'' such that the distance squared between ''x'' and ''y''<sub>''n''</sub> is below or equal to δ<sup>2</sup> + 1/''n''. Let ''n'' and ''m'' be two integers, then the following equalities are true:\n\n: <math>\\| y_n - y_m \\|^2 = \\|y_n -x\\|^2 + \\|y_m -x\\|^2 - 2 \\langle y_n - x \\, , \\, y_m - x\\rangle</math>\n\nand\n\n: <math>4 \\left\\| \\frac{y_n + y_m}2 -x \\right\\|^2 = \\|y_n -x\\|^2 + \\|y_m -x\\|^2 + 2 \\langle y_n - x \\, , \\, y_m - x\\rangle</math>\n\nWe have therefore:\n\n: <math>\\| y_n - y_m \\|^2 = 2\\|y_n -x\\|^2 + 2\\|y_m -x\\|^2 - 4\\left\\| \\frac{y_n + y_m}2 -x \\right\\|^2</math>\n(Recall the formula for the median in a triangle - [[Median_(geometry)#Formulas_involving_the_medians'_lengths]])\nBy giving an upper bound to the first two terms of the equality and by noticing that the middle of ''y''<sub>''n''</sub> and ''y''<sub>''m''</sub> belong to ''C'' and has therefore  a distance greater than or equal to ''δ''  from ''x'', one gets :\n\n: <math>\\| y_n - y_m \\|^2 \\; \\le \\; 2\\left(\\delta^2 + \\frac 1n\\right) + 2\\left(\\delta^2 + \\frac 1m\\right) - 4\\delta^2=2\\left( \\frac 1n + \\frac 1m\\right)</math>\n\nThe last inequality proves that (''y''<sub>''n''</sub>) is a [[Cauchy sequence]]. Since ''C'' is complete, the sequence is therefore convergent to a point ''y'' in ''C'', whose distance from ''x'' is minimal.\n\n:* ''Let us show the uniqueness of ''y'' :''\nLet ''y''<sub>1</sub> and ''y''<sub>2</sub> be two minimizers. Then:\n\n: <math>\\| y_2 - y_1 \\|^2 = 2\\|y_1 -x\\|^2 + 2\\|y_2 -x\\|^2 - 4\\left\\| \\frac{y_1 + y_2}2 -x \\right\\|^2</math>\n\nSince <math>\\frac{y_1 + y_2}2</math> belongs to ''C'', we have <math>\\left\\| \\frac{y_1 + y_2}2 -x \\right\\|^2\\geq \\delta^2</math> and therefore\n\n: <math>\\| y_2 - y_1 \\|^2 \\leq 2\\delta^2 + 2\\delta^2 - 4\\delta^2=0 \\, </math>\n\nHence <math>y_1=y_2</math>, which proves uniqueness.\n\n:* ''Let us show the equivalent condition on'' ''y'' ''when'' ''C''&nbsp;=&nbsp;''M'' ''is a closed subspace.''\n\nThe condition is sufficient:\nLet <math>z\\in M</math> such that <math>\\langle z-x, a \\rangle=0</math> for all <math>a\\in M</math>.\n<math>\\|x-a\\|^2=\\|z-x\\|^2+\\|a-z\\|^2+2\\langle z-x, a-z \\rangle=\\|z-x\\|^2+\\|a-z\\|^2</math> which proves that <math>z</math> is a minimizer.\n\nThe condition is necessary:\nLet <math>y\\in M</math> be the minimizer. Let <math>a\\in M</math> and <math>t\\in\\mathbb R</math>.\n\n: <math>\\|(y+t a)-x\\|^2-\\|y-x\\|^2=2t\\langle y-x,a\\rangle+t^2 \\|a\\|^2=2t\\langle y-x,a\\rangle+O(t^2)</math>\n\nis always non-negative. Therefore, <math>\\langle y-x,a\\rangle=0.</math>\n\nQED\n\n==References==\n* [[Walter Rudin]], ''Real and Complex Analysis. Third Edition'', '''1987'''.\n\n==See also==\n*[[Orthogonality principle]]\n\n{{DEFAULTSORT:Hilbert Projection Theorem}}\n[[Category:Convex analysis]]\n[[Category:Theorems in functional analysis]]"
    },
    {
      "title": "Hypograph (mathematics)",
      "url": "https://en.wikipedia.org/wiki/Hypograph_%28mathematics%29",
      "text": "{{refimprove|date=August 2014}}\nIn [[mathematics]], the '''hypograph''' or '''subgraph''' of a [[function (mathematics)|function]] ''f''&nbsp;:&nbsp;'''R'''<sup>''n''</sup>&nbsp;→&nbsp;'''R''' is the [[Set (mathematics)|set]] of points lying on or below its [[graph of a function|graph]]:\n\n: <math>\\mbox{hyp} f = \\{ (x, \\mu) \\, : \\, x \\in \\mathbb{R}^n,\\, \\mu \\in \\mathbb{R},\\, \\mu \\le f(x) \\} \\subseteq \\mathbb{R}^{n+1}</math>\n\nand the strict hypograph of the function is:\n\n: <math>\\mbox{hyp}_S f = \\{ (x, \\mu) \\, : \\, x \\in \\mathbb{R}^n,\\, \\mu \\in \\mathbb{R},\\,  \\mu <  f(x) \\} \\subseteq \\mathbb{R}^{n+1}.</math>\n\nThe set is empty if <math>f \\equiv -\\infty</math>.\n\nThe domain (rather than the co-domain) of the function is not particularly important for this definition; it can be an arbitrary set<ref name=\"AliprantisBorder2007\">{{cite book|author1=Charalambos D. Aliprantis|author2=Kim C. Border|title=Infinite Dimensional Analysis: A Hitchhiker's Guide|url=https://books.google.com/books?id=4hIq6ExH7NoC&pg=PA8|year=2007|publisher=Springer Science & Business Media|isbn=978-3-540-32696-0|pages=8–9|edition=3rd}}</ref> instead of <math>\\mathbb{R}^n</math>.\n\nSimilarly, the set of points on or above the function's graph is its [[Epigraph (mathematics)|epigraph]].\n\n==Properties==\nA function is [[concave function|concave]] if and only if its hypograph is a [[convex set]]. The hypograph of a real [[affine function]] ''g''&nbsp;:&nbsp;'''R'''<sup>''n''</sup>&nbsp;→&nbsp;'''R''' is a [[Half-space (geometry)|halfspace]] in '''R'''<sup>''n''+1</sup>.\n\nA function is [[Semi-continuity|upper semicontinuous]] if and only if its hypograph is [[Closed set|closed]].\n\n==See also==\n* [[Epigraph (mathematics)]]\n\n==References==\n{{reflist}}\n\n[[Category:Mathematical analysis]]\n[[Category:Convex analysis]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Invex function",
      "url": "https://en.wikipedia.org/wiki/Invex_function",
      "text": "In [[vector calculus]], an '''invex function''' is a [[differentiable function]] <math>f</math> from <math>\\mathbb{R}^n</math> to <math>\\mathbb{R}</math> for which there exists a vector valued function <math>\\eta</math> such that\n\n:<math>f(x) - f(u) \\geq \\eta(x, u) \\cdot \\nabla f(u), \\, </math>\n\nfor all ''x'' and ''u''.\n\nInvex functions were introduced by Hanson<ref>{{Cite journal|last=Hanson|first=Morgan A.|date=1981|title=On sufficiency of the Kuhn-Tucker conditions|url=http://www.sciencedirect.com/science/article/pii/0022247X81901232|journal=Journal of Mathematical Analysis and Applications|volume=80|issue=2|pages=545–550|doi=10.1016/0022-247X(81)90123-2|issn=0022-247X|via=}}</ref> as a generalization of [[convex function]]s.  Ben-Israel and Mond<ref>{{Cite journal|last=Ben-Israel|first=A.|last2=Mond|first2=B.|date=1986|title=What is invexity?|url=https://www.cambridge.org/core/journals/anziam-journal/article/what-is-invexity/82C3938EDF3585B2AC5C27093E23814F|journal=The ANZIAM Journal|language=en|volume=28|issue=1|pages=1–9|doi=10.1017/S0334270000005142|issn=1839-4078|via=}}</ref> provided a simple proof that a function is invex if and only if every [[stationary point]] is a [[global minimum]], a theorem first stated by Craven and Glover.<ref>{{Cite journal|last=Craven|first=B. D.|last2=Glover|first2=B. M.|date=1985|title=Invex functions and duality|url=https://www.cambridge.org/core/journals/journal-of-the-australian-mathematical-society/article/invex-functions-and-duality/17C4993C6394B695564E58C522F99101|journal=Journal of the Australian Mathematical Society|language=en|volume=39|issue=1|pages=1–20|doi=10.1017/S1446788700022126|issn=0263-6115|via=}}</ref>\n\nHanson also showed that if the objective and the constraints of an [[optimization problem]] are invex with respect to the same function <math>\\eta(x,u) </math>, then the [[Karush–Kuhn–Tucker conditions]] are sufficient for a global minimum.\n\n== Type I invex functions ==\nA slight generalization of invex functions called '''Type I invex functions''' are the most general class of functions for which the [[Karush–Kuhn–Tucker conditions]] are necessary and sufficient for a global minimum.<ref name=\":0\">{{Cite journal|last=Hanson|first=Morgan A.|date=1999|title=Invexity and the Kuhn–Tucker Theorem|url=http://www.sciencedirect.com/science/article/pii/S0022247X99964843|journal=Journal of Mathematical Analysis and Applications|volume=236|issue=2|pages=594–604|doi=10.1006/jmaa.1999.6484|issn=0022-247X|via=}}</ref> Consider a mathematical program of the form\n\n<math>\\begin{array}{rl}\n\\min & f(x)\\\\\n\\text{s.t.} & g(x)\\leq0\n\\end{array}</math>\n\nwhere <math>f:\\mathbb{R}^n\\to\\mathbb{R}</math> and <math>g:\\mathbb{R}^n\\to\\mathbb{R}^m</math>are differentiable functions. Let <math>F=\\{x\\in\\mathbb{R}^n\\;|\\;g(x)\\leq0\\}</math>denote the feasible region of this program. The function <math>f</math> is a '''Type I''' '''objective function''' and the function <math>g</math> is a '''Type I constraint function''' at <math>x_0</math>with respect to <math>\\eta</math> if there exists a vector-valued function <math>\\eta</math> defined on <math>F</math>such that \n\n<math>f(x)-f(x_0)\\geq\\eta(x)\\cdot\\nabla{f(x_0)}</math>\n\nand\n\n<math>-g(x_0)\\geq\\eta(x)\\cdot\\nabla{g(x_0)}</math>\n\nfor all <math>x\\in{F}</math>.<ref>{{Cite journal|last=Hanson|first=M. A.|last2=Mond|first2=B.|date=1987|title=Necessary and sufficient conditions in constrained optimization|journal=Mathematical Programming|language=en|volume=37|issue=1|pages=51–58|doi=10.1007/BF02591683|issn=1436-4646}}</ref> Note that, unlike invexity, Type I invexity is defined relative to a point <math>x_0</math>.\n\n'''Theorem (Theorem 2.1 in'''<ref name=\":0\" />'''):''' If <math>f </math> and <math>g </math> are Type I invex at a point <math>x^* </math>with respect to <math>\\eta </math>, and the [[Karush–Kuhn–Tucker conditions]] are satisfied at <math>x^* </math>, then <math>x^* </math>is a global minimizer of <math>f </math> over <math>F </math>.\n\n==See also==\n* [[Convex function]]\n* [[Pseudoconvex function]]\n* [[Quasiconvex function]]\n\n==References==\n\n<references/>\n\n==Further reading==\n\nS. K. Mishra and G. Giorgi, Invexity and optimization, Nonconvex optimization and Its Applications, Vol. 88, Springer-Verlag, Berlin, 2008.\n\nS. K. Mishra, S.-Y. Wang and K. K. Lai, Generalized Convexity and Vector Optimization, Springer, New York, 2009.\n[[Category:Real analysis]]\n[[Category:Types of functions]]\n[[Category:Convex analysis]]\n[[Category:Generalized convexity]]"
    },
    {
      "title": "K-convex function",
      "url": "https://en.wikipedia.org/wiki/K-convex_function",
      "text": "'''''K''-convex functions''', first introduced by [[Herbert Scarf|Scarf]],<ref name=Scarf>{{cite book|last1=Scarf|first1=H.|title=The Optimality of (S, s) Policies in the Dynamic Inventory Problem|date=1960|publisher=Stanford University Press|location=Stanford, CA|page=Chapter 13}}</ref> are a special weakening of the concept of [[convex function]] which is crucial in the proof of the [[optimality]] of the <math>(s,S)</math> policy in [[Inventory theory|inventory control theory]]. The policy is characterized by two numbers {{mvar|s}} and {{mvar|S}}, <math>S \\geq s</math>, such that when the inventory level falls below level {{mvar|s}}, an order is issued for a quantity that brings the inventory up to level {{mvar|S}}, and nothing is ordered otherwise.\n\n== Definition ==\nTwo equivalent definitions are as follows:\n\n=== Definition 1 (The original definition) ===\nA function <math>g: \\mathbb{R}\\rightarrow\\mathbb{R}</math> is ''K''-convex if\n:<math>g(u)+z\\left[\\frac{g(u)-g(u-b)}{b}\\right] \\leq g(u+z) + K</math>\nfor any <math>u, z\\geq 0,</math> and <math>b>0</math>.\n\n=== Definition 2  (Definition with geometric interpretation) ===\nA function <math>g: \\mathbb{R}\\rightarrow\\mathbb{R}</math> is ''K''-convex if\n:<math>g(\\lambda x+\\bar{\\lambda} y) \\leq \\lambda g(x) + \\bar{\\lambda} [g(y)+K]</math>\nfor all <math>x\\leq y, \\lambda \\in [0,1]</math>, where <math>\\bar{\\lambda}=1-\\lambda</math>.\n\nThis definition admits a simple geometric interpretation related to the concept of visibility.<ref name=Kolmogorov>{{cite book|last1=Kolmogorov|first1=A. N.|last2=Fomin|first2=S. V.|title=Introduction to Real Analysis|date=1970|publisher=Dover Publications Inc.|location=New York}}</ref> Let <math>a \\geq 0</math>. A point <math>(x,f(x))</math> is said to be visible from <math>(y,f(y)+a)</math> if all intermediate points <math>(\\lambda x+\\bar{\\lambda} y, f(\\lambda x+\\bar{\\lambda} y)), 0\\leq \\lambda \\leq 1</math> lie below the line segment joining these two points. Then the geometric characterization of ''K''-convexity can be obtain as:\n\n:A function <math>g</math> is ''K''-convex if and only if <math>(x,g(x))</math> is visible from <math>(y,g(y)+K)</math> for all <math>y\\geq x</math>.\n\n=== Proof of Equivalence ===\nIt is sufficient to prove that the above definitions can be transformed to each other. This can be seen by using the transformation\n:<math> \\lambda = z/(b+z),\\quad x=u-b,\\quad y=u+z.</math>\n\n== Properties == \n<ref>Sethi S P, Cheng F. Optimality of (s, S) Policies in Inventory Models with Markovian Demand. INFORMS, 1997.</ref>\n\n=== Property 1 ===\nIf <math>g: \\mathbb{R}\\rightarrow\\mathbb{R}</math> is ''K''-convex, then it is ''L''-convex for any <math>L\\geq K</math>. In particular, if <math>g</math> is convex, then it is also ''K''-convex for any <math>K\\geq 0</math>.\n\n=== Property 2 ===\nIf <math>g_1</math> is ''K''-convex and <math>g_2</math> is ''L''-convex, then for <math>\\alpha \\geq 0, \\beta \\geq 0,\\; g=\\alpha g_1 +\\beta g_2</math> is <math>(\\alpha K+\\beta L)</math>-convex.\n\n=== Property 3 ===\nIf <math>g</math> is ''K''-convex and <math>\\xi</math> is a random variable such that <math>E|g(x-\\xi)|<\\infty</math> for all <math>x</math>, then <math>Eg(x-\\xi)</math> is also ''K''-convex.\n\n=== Property 4 ===\nIf <math>g: \\mathbb{R}\\rightarrow\\mathbb{R}</math> is ''K''-convex, restriction of <math>g</math> on any convex set <math>\\mathbb{D}\\subset\\mathbb{R}</math> is ''K''-convex.\n\n=== Property 5 ===\nIf <math>g: \\mathbb{R}\\rightarrow\\mathbb{R}</math> is a continuous ''K''-convex function and <math>g(y)\\rightarrow \\infty</math> as <math>|y|\\rightarrow \\infty</math>, then there exit scalars <math>s</math> and <math>S</math> with <math>s\\leq S</math> such that\n* <math>g(S)\\leq g(y)</math>, for all <math>y\\in \\mathbb{R}</math>;\n* <math>g(S)+K=g(s)<g(y)</math>, for all <math>y<s</math>;\n* <math>g(y)</math> is a decreasing function on <math>(-\\infty, s)</math>;\n* <math>g(y)\\leq g(z)+K</math> for all <math>y, z</math> with <math>s\\leq y\\leq z</math>.\n\n==References==\n{{reflist}}\n\n==External links==\n* {{cite journal |last1=Gallego |first1=Guillermo|last2=Sethi |first2=Suresh |date=16 September 2004 |title=K-CONVEXITY IN ℜ<sup>n</sup> |url=https://www.utdallas.edu/~sethi/Postscript/Kconvexity091504.pdf |format=PDF |pages=21 |access-date=January 21, 2016}}\n\n[[Category:Types of functions]]\n[[Category:Convex analysis]]"
    },
    {
      "title": "Kachurovskii's theorem",
      "url": "https://en.wikipedia.org/wiki/Kachurovskii%27s_theorem",
      "text": "In [[mathematics]], '''Kachurovskii's theorem''' is a theorem relating the [[convex function|convexity]] of a function on a [[Banach space]] to the [[monotone operator|monotonicity]] of its [[Fréchet derivative]].\n\n==Statement of the theorem==\nLet ''K'' be a [[convex set|convex subset]] of a Banach space ''V'' and let ''f''&nbsp;:&nbsp;''K''&nbsp;&rarr;&nbsp;'''R'''&nbsp;&cup;&nbsp;{+&infin;} be an [[extended real number line|extended real-valued function]] that is Fréchet differentiable with derivative d''f''(''x'')&nbsp;:&nbsp;''V''&nbsp;&rarr;&nbsp;'''R''' at each point ''x'' in ''K''. (In fact, d''f''(''x'') is an element of the [[continuous dual space]] ''V''<sup>&lowast;</sup>.) Then the following are equivalent:\n\n* ''f'' is a convex function;\n* for all ''x'' and ''y'' in ''K'',\n\n::<math>\\mathrm{d} f(x) (y - x) \\leq f(y) - f(x);</math>\n\n* d''f'' is an (increasing) monotone operator, i.e., for all ''x'' and ''y'' in ''K'',\n\n::<math>\\big( \\mathrm{d} f(x) - \\mathrm{d} f(y) \\big) (x - y) \\geq 0.</math>\n\n==References==\n\n* {{cite journal\n| last = Kachurovskii\n| first = I. R.\n| title = On monotone operators and convex functionals\n| journal = Uspekhi Mat. Nauk\n| volume = 15\n| number = 4\n| year = 1960\n| pages = 213&ndash;215\n}}\n* {{cite book\n| last = Showalter\n| first = Ralph E.\n| title = Monotone operators in Banach space and nonlinear partial differential equations\n| series = Mathematical Surveys and Monographs 49\n| publisher = American Mathematical Society\n| location = Providence, RI\n| year = 1997\n| pages = 80\n| isbn = 0-8218-0500-2\n}} {{MathSciNet|id=1422252}} (Proposition 7.4)\n\n[[Category:Convex analysis]]\n[[Category:Theorems in functional analysis]]"
    },
    {
      "title": "Legendre transformation",
      "url": "https://en.wikipedia.org/wiki/Legendre_transformation",
      "text": "{{about|an involution transform commonly used in classical mechanics and thermodynamics|the integral transform using Legendre polynomials as kernels|Legendre transform}}\n[[Image:Legendre transformation.png|thumb|256px|right|The function {{math|''f''(''x'')}} is defined on the interval {{math|[''a'', ''b'']}}. The difference {{math|''px'' − ''f''(''x'')}} takes a maximum at {{math|''x'''}}. Thus, {{math|''f''*(''p'') {{=}} ''px' − f(x')''}}.]]\nIn [[mathematics]] and [[physics]], the '''Legendre transformation''', named after [[Adrien-Marie Legendre]], is an [[involution (mathematics)|involutive]] [[List of transforms|transformation]] on the [[real number|real]]-valued [[convex function]]s of one real variable. It is commonly used in [[classical mechanics]] to derive the [[Hamiltonian mechanics|Hamiltonian]] formalism out of the [[Lagrangian mechanics|Lagrangian]] formalism and in [[thermodynamics]] to derive the [[thermodynamic potential]]s, as well as in the solution of [[differential equation]]s of several variables.\n\nFor sufficiently smooth functions on the real line, the Legendre transform {{mvar|''f*''}} of a function {{mvar|f}} can be specified, up to an additive constant, by the condition that the functions' first derivatives are inverse functions of each other.  This can be expressed in [[Notation for differentiation#Euler.27s notation|Euler's derivative notation]] as\n:<math>Df = \\left( D f^* \\right)^{-1}~,</math>\nor, equivalently, as <math>f'(f^{*\\prime}(x^*)) = x^*</math> and <math>f^{*\\prime}(f'(x)) = x</math> in [[Notation for differentiation#Lagrange.27s notation|Lagrange's notation]].\n\nThe generalization of the Legendre transformation to affine spaces and non-convex functions is known as the [[convex conjugate]] (also called the Legendre–Fenchel transformation), which can be used to construct a function's [[convex hull]].\n\n==Definition==\n\nLet {{math|''I'' ⊂ ℝ}} be an [[Interval (mathematics)|interval]], and {{math|''f'' : ''I'' → ℝ}} a [[convex function]]; then its ''Legendre transform'' is the function {{math|''f*'' : ''I*'' → ℝ}} defined by\n:<math>f^*(x^*) = \\sup_{x\\in I}(x^*x-f(x)),\\quad x^*\\in I^*</math>\nwhere <math>\\sup</math> is the [[Infimum and supremum|supremum]], and the [[Domain of a function|domain]] <math>I^*</math> is\n:<math>I^*= \\left \\{x^*\\in \\R:\\sup_{x\\in I}(x^*x-f(x))<\\infty \\right \\} ~.</math>\n\nThe transform is always well-defined when {{math|''f''(''x'')}} is [[convex function|convex]].\n\nThe generalization to convex functions {{math|''f'' : ''X'' → ℝ}} on a convex set {{math|''X'' ⊂ ℝ<sup>''n''</sup>}} is straightforward: {{math|''f *'' : ''X*'' → ℝ}} has domain\n:<math>X^*= \\left \\{x^* \\in \\R^n:\\sup_{x\\in X}(\\langle x^*,x\\rangle-f(x))<\\infty \\right \\}</math>\nand is defined by\n:<math>f^*(x^*) = \\sup_{x\\in X}(\\langle x^*,x\\rangle-f(x)),\\quad x^*\\in X^*   ~,</math>\nwhere <math>\\langle x^*,x \\rangle</math> denotes the [[dot product]] of {{math|''x''*}} and {{mvar|x}}.\n\nThe function {{math|''f'' *}} is called the [[convex conjugate]] function of {{mvar|f}}. For historical reasons (rooted in analytic mechanics), the conjugate variable is often denoted {{mvar|p}}, instead of {{math|''x''*}}.  If the convex function {{mvar|f}} is defined on the whole line and is everywhere [[Differentiable function|differentiable]], then\n:<math>f^*(p)=\\sup_{x\\in I}(px-f(x)) = \\left( p x - f(x) \\right)|_{x = (f')^{-1}(p)} </math>\ncan be interpreted as the negative of the [[y-intercept|{{math|''y''}}-intercept]] of the [[tangent line]] to the [[Graph of a function|graph]] of {{mvar|f}} that has slope {{mvar|p}}.\n\nThe Legendre transformation is an application of the [[Duality (projective geometry)|duality]] relationship between points and lines. The functional relationship specified by {{mvar|f}} can be represented equally well as a set of {{math|(''x'', ''y'')}} points, or as a set of tangent lines specified by their slope and intercept values.\n\n===Understanding the transform in terms of derivatives===\n\nFor differentiable convex functions <math> f</math>\non the real line with an invertible first derivative, the Legendre transform <math> f^*</math>\ncan be specified, up to an additive constant, by the condition that the functions' first \nderivatives are inverse functions of each other.\n\nTo see this, first note that if  <math> f</math> is differentiable and <math> \\overline{x} </math> is a critical point\nof the function of <math> x \\mapsto p \\cdot x -f(x) </math>, then the\nsupremum is achieved at <math> \\overline{x}</math> (by convexity). \nTherefore, <math> f^*(p)= p \\cdot \\overline{x} - f(\\overline{x})</math>.\n\nSuppose that <math>f'</math> is invertible and let <math> h </math> denote its inverse.\nThen for each <math> p</math>, the point <math> h(p)</math>  is the unique critical point of\n<math> x \\mapsto px -f(x) </math>.  Indeed,  <math> f'(h(p))=p </math> and so <math> p-f'(h(p))=0 </math>.\nHence we have <math> f^*(p) = p \\cdot h(p) - f(h(p))</math> for each <math> p</math>. \nBy differentiating with respect to <math> p</math> we find \n:<math>(f^*)'(p) =  h(p)+ p \\cdot h'(p) - f'(h(p)) \\cdot h'(p).</math>\nSince <math> f'(h(p))=p</math> this simplifies to  <math>(f^*)'(p) =  h(p)</math>.\nIn other words,  <math>(f^*)'</math> and <math>f'</math> are inverses.\n\nIn general, if <math> g' </math> is an inverse of <math> f' </math>, then <math> g' = (f^*)' </math> \nand so integration provides a constant <math> c </math> so that  <math> f^* = g +c </math>.\n\nIn practical terms, given {{math|''f''(''x'')}}, the parametric plot of {{math|''xf'' '(''x'') − ''f''(''x'')}} versus {{math|''f'' '(''x'')}} amounts to the graph of  {{math| ''g''(''p'')}} versus {{mvar|p}}.\n\nIn some cases (e.g. thermodynamic potentials, below), a non-standard requirement is used, amounting to an alternative definition of {{math|''f'' *}} with a ''minus sign'',\n:<math>f(x) - f^*(p) = xp.</math>\n\n==Properties==\n*The Legendre transform of a convex function is convex.\n\n: Let us show this for the case of a doubly differentiable {{mvar|f}} with a non zero (and hence positive, due to convexity) double derivative.\n\n: For a fixed {{mvar|p}}, let {{mvar|x}} maximize {{math|''px'' − ''f''(''x'')}}. Then {{math|''f'' *(''p'') {{=}} ''px'' − ''f''(''x'')}}, noting that {{mvar|x}} depends on {{mvar|p}}.  Thus,\n\n:: <math>f^\\prime(x) = p ~.</math>\n\n: The derivative of {{mvar|f}} is itself differentiable with a positive derivative and hence strictly monotonic and invertible.\n\n: Thus {{math|''x'' {{=}} ''g''(''p'')}} where <math>g \\equiv (f^{\\prime})^{-1}</math>, meaning that {{math|''g''}} is defined so that <math>f'(g(p))= p</math>.\n\n: Note that {{mvar|g}} is also differentiable with the following derivative,\n\n:: <math>\\frac{dg(p)}{dp} = \\frac{1}{f''(g(p))} ~.</math>\n\n: Thus {{math|''f'' *(''p'') {{=}} ''pg''(''p'') − ''f''(''g''(''p''))}} is the composition of differentiable functions, hence differentiable.\n\n: Applying the [[product rule]] and the [[chain rule]] yields\n\n:: <math>\\begin{align}\n\\frac{d(f^{*})}{dp} &= g(p) +  \\left(p - f'(g(p))\\right)\\cdot \\frac{dg(p)}{dp}\\\\[4pt]\n& =  g(p),\n\\end{align} </math>\n\n: giving\n\n:: <math>\n\\frac{d^2(f^{*})}{dp^2} = \\frac{dg(p)}{dp} = \\frac{1}{f''(g(p))} > 0,\n</math>\n\n: so {{math|''f'' *}} is convex.\n\n*It follows that the Legendre transformation is an [[Involution (mathematics)|involution]], i.e., {{math|''f'' ** {{=}} ''f''}}:\n\n: By using the above equalities for {{math|''g''(''p'')}}, {{math|''f'' *(''p'')}} and its derivative,\n\n:: <math>\\begin{align}\nf^{**}(x) &{} = \\left(x\\cdot p_s - f^{*}(p_s)\\right)_{|\\frac{d}{dp}f^{*}(p=p_s) = x} \\\\[5pt]\n&{} = g(p_s)\\cdot p_s - f^{*}(p_s) \\\\[5pt]\n&{} = f(g(p_s)) \\\\[5pt]\n&{} =  f(x)~.\n\\end{align}  </math>\n\n==Examples==\n\n===Example 1===\n[[Image:LegendreExample.svg|right|thumb|200px|e<sup>''x''</sup> is plotted in red and its Legendre transform in dashed blue.]]\nThe [[exponential function]]\n:<math> f(x) = e^x </math> &nbsp;  has <math>\\qquad  f^*(p) = p ( \\ln p - 1 ) </math>\nas a Legendre transform, since their respective first derivatives {{math|''e<sup>x''</sup>}} and {{math|ln ''p''}} are inverse functions of each other.\n\nThis example illustrates how the respective [[domain (mathematics)|domain]]s of a function and its Legendre transform need not agree.\n\n===Example 2===\nLet {{math|''f''(''x'') {{=}} ''cx''<sup>2</sup>}} defined on ℝ, where {{math|''c'' > 0}} is a fixed constant.\n\nFor {{math|''x''*}} fixed, the function of {{mvar|x}}, {{math|''x''*''x'' – ''f''(''x'') {{=}} ''x''*''x'' – ''cx''<sup>2</sup>}} has the first derivative {{math|''x''* – 2''cx''}} and second derivative {{math|−2''c''}}; there is one stationary point at {{math|''x'' {{=}} ''x''*/2''c''}}, which is always a maximum.\n\nThus, {{math|''I''* {{=}} ℝ}} and\n:<math>f^*(x^*)=\\frac{{x^*}^2}{4c}  ~.</math>\n\nThe first derivatives of  {{math|''f''}},  2{{math|''cx''}}, and of {{math|''f'' *}},  {{math|''x''*/(2''c'')}}, are inverse functions to each other. Clearly, furthermore,\n:<math>f^{**}(x)=\\frac{1}{4 (1/4c)}x^2=cx^2~,</math>\nnamely {{math|''f'' ** {{=}} ''f''}}.\n\n===Example 3===\nLet {{math|''f''(''x'') {{=}} ''x''<sup>2</sup>}} for {{math|''x'' ∈ ''I'' {{=}} [2, 3]}}.\n\nFor {{math|''x''*}} fixed, {{math|''x''*''x'' − ''f''(''x'')}} is continuous on {{mvar|I}} [[compact space|compact]], hence it always takes a finite maximum on it; it follows that {{math|''I''* {{=}} ℝ}}.\n\nThe stationary point at {{math|''x'' {{=}} ''x''*/2}} is in the domain {{math|[2, 3]}} if and only if {{math|4 ≤ ''x''* ≤ 6}}, otherwise the maximum is taken either at {{math|''x'' {{=}} 2}}, or {{math|''x'' {{=}} 3}}. It follows that\n:<math>f^*(x^*)=\\begin{cases}2x^*-4, & x^*<4\\\\ \\frac{{x^*}^2}{4}, & 4\\leqslant x^*\\leqslant 6,\\\\3x^*-9, & x^*>6.\\end{cases}</math>\n\n===Example 4===\nThe function {{math|''f''(''x'') {{=}} ''cx''}} is convex, for every {{mvar|x}} (strict convexity is not required for the Legendre transformation to be well defined). Clearly {{math|''x''*''x'' − ''f''(''x'') {{=}} (''x''* − ''c'')''x''}} is never bounded from above as a function of {{mvar|x}}, unless {{math|''x''* − ''c'' {{=}} 0}}. Hence {{math|''f''*}} is defined on {{math|''I''* {{=}} {''c''}}} and {{math|''f''*(''c'') {{=}} 0}}.\n\nOne may check involutivity: of course {{math|''x''*''x'' − ''f''*(''x''*)}} is always bounded as a function of {{math|''x''* ∈ {''c''}}}, hence  {{math|''I'' ** {{=}} ℝ}}. Then, for all {{mvar|x}} one has\n:<math>\\sup_{x^*\\in\\{c\\}}(xx^*-f^*(x^*))=xc,</math>\nand hence {{math|''f'' **(''x'') {{=}} ''cx'' {{=}} ''f''(''x'')}}.\n\n===Example 5: several variables===\nLet\n:<math>f(x)=\\langle x,Ax\\rangle+c</math>\nbe defined on {{math|''X'' {{=}} ℝ<sup>''n''</sup>}}, where {{mvar|A}} is a real, positive definite matrix.\n\nThen {{mvar|f}} is convex, and\n:<math>\\langle p,x\\rangle-f(x)=\\langle p,x \\rangle-\\langle x,Ax\\rangle-c,</math>\nhas gradient {{math|''p'' − 2''Ax''}} and [[Hessian matrix|Hessian]] {{math|−2''A''}}, which is negative; hence the stationary point {{math|''x'' {{=}} ''A''<sup>−1</sup>''p''/2}} is a maximum.\n\nWe have {{math|''X''* {{=}} ℝ<sup>''n''</sup>}}, and\n:<math>f^*(p)=\\frac14\\langle p,A^{-1}p\\rangle-c.</math>\n\n==Behavior of differentials under Legendre transforms==\nThe Legendre transform is linked to [[integration by parts]], &nbsp;  {{math|''pdx'' {{=}} ''d''(''px'') − ''xdp''}}.\n\nLet {{mvar|f}} be a function of two independent variables {{mvar|x}} and {{mvar|y}}, with the differential\n:<math>df = {\\partial f \\over \\partial x}\\,dx + {\\partial f \\over \\partial y}\\,dy = p\\,dx + v\\,dy.</math>\n\nAssume that it is convex in {{mvar|x}} for all {{mvar|y}}, so that one may perform the Legendre transform in {{mvar|x}}, with {{mvar|p}} the variable conjugate to {{mvar|x}}. Since the new independent variable is {{mvar|p}}, the differentials {{math|''dx''}} and {{math|''dy''}}  devolve to {{math|''dp''}} and {{math|''dy''}}, i.e., we build another function with its differential expressed in terms of the new basis {{math|''dp''}} and {{math|''dy''}}.\n\nWe thus consider the function {{math|''g''(''p'', ''y'') {{=}} ''f'' − ''px''}}  so that\n:<math>dg = df - p\\,dx - x\\,dp = -x\\,dp + v\\,dy</math>\n:<math>x = -\\frac{\\partial g}{\\partial p}</math>\n:<math>v = \\frac{\\partial g}{\\partial y}.</math>\n\nThe function {{math|''-g''(''p'', ''y'')}} is the Legendre transform of {{math|''f''(''x'', ''y'')}}, where only the independent variable {{mvar|x}} has been supplanted by {{mvar|p}}. This is widely used in thermodynamics, as illustrated below.\n\n==Applications==\n\n===Hamilton–Lagrange mechanics===\nA Legendre transform is used in [[classical mechanics]] to derive the [[Hamiltonian mechanics|Hamiltonian formulation]] from the [[Lagrangian mechanics|Lagrangian formulation]], and conversely. A typical Lagrangian has the form\n\n:<math>L(v,q)=\\tfrac{1}2\\langle v,Mv\\rangle-V(q),</math>\n\nwhere <math>(v,q)</math>  are coordinates on {{math|'''R'''<sup>''n''</sup> × '''R'''<sup>''n''</sup>}}, {{mvar|M}} is a positive real matrix, and\n\n:<math>\\langle x,y\\rangle=\\sum_jx_jy_j.</math>\n\nFor every {{mvar|q}} fixed, <math>L(v, q)</math> is a convex function of <math>v</math>, while <math>V(q)</math> plays the role of a constant.\n\nHence the Legendre transform of <math>L(v, q)</math> as a function of {{mvar|v}}  is the Hamiltonian function,\n\n:<math>H(p,q)=\\tfrac 12\\langle p,M^{-1}p\\rangle+V(q)</math>.\n\nIn a more general setting, <math>(v, q)</math> are local coordinates on the [[tangent bundle]]<math>T\\mathcal M</math> of a manifold <math>\\mathcal M</math>. For each {{mvar|q}}, <math>L(v, q)</math> is a convex function of the tangent space {{math|''V<sub>q</sub>''}}. The Legendre transform gives the Hamiltonian <math>H(p, q)</math> as a function of the coordinates {{math|(''p'', ''q'')}} of the [[cotangent bundle]] <math>T^*\\mathcal M</math>; the inner product used to define the Legendre transform is inherited from the pertinent canonical [[symplectic vector space|symplectic structure]]. In this abstract setting, the Legendre transformation corresponds to the [[tautological one-form]].\n\n===Thermodynamics===\nThe strategy behind the use of Legendre transforms in thermodynamics is to shift from a function that depends on a variable to a new (conjugate) function that depends on a new variable, the conjugate of the original one. The new variable is the partial derivative of the original function with respect to the original variable. The new function is the difference between the original function and the product of the old and new variables. Typically, this transformation is useful because it shifts the dependence of, e.g., the energy from an [[Intensive and extensive properties|extensive variable]] to its conjugate intensive variable, which can usually be controlled more easily in a physical experiment.\n\nFor example, the [[internal energy]] is an explicit function of the ''[[extensive quantity|extensive variables]]'' [[entropy]], [[volume]], and [[chemical composition]]\n\n:<math> U = U \\left (S,V,\\{N_i\\} \\right ),</math>\n\nwhich has a total differential\n\n:<math> dU = T\\,dS - P\\,dV + \\sum \\mu_i \\,dN _i.</math>\n\nBy using the (non-standard) Legendre transform of the internal energy, {{mvar|U}}, with respect to volume, {{mvar|V}}, it is possible to define the [[enthalpy]] as\n\n:<math> H = U + PV \\, = H \\left (S,P,\\{N_i\\} \\right ),</math>\n\nwhich is an explicit function of the pressure, {{mvar|P}}. The enthalpy contains all of the same information as the internal energy, but is often easier to work with in situations where the pressure is constant.\n\nIt is likewise possible to shift the dependence of the energy from the extensive variable of entropy, {{mvar|S}}, to the (often more convenient) intensive variable {{mvar|T}}, resulting in the [[Helmholtz energy|Helmholtz]] and [[Gibbs energy|Gibbs]] [[thermodynamic free energy|free energies]]. The Helmholtz free energy, {{mvar|A}}, and Gibbs energy, {{mvar|G}}, are obtained by performing Legendre transforms of the internal energy and enthalpy, respectively,\n\n:<math> A = U - TS ~,</math>\n:<math> G = H - TS = U + PV - TS ~.</math>\n\nThe Helmholtz free energy is often the most useful thermodynamic potential when temperature and volume are held constant, while the Gibbs energy is often the most useful when temperature and pressure are held constant.\n\n===An example – variable capacitor===\nAs another example from [[physics]], consider a parallel-plate [[capacitor]], in which the plates can move relative to one another. Such a capacitor would allow transfer of the electric energy which is stored in the capacitor into external mechanical work, done by the [[force]] acting on the plates. One may think of the electric charge as analogous to the \"charge\" of a [[gas]] in a [[cylinder (engine)|cylinder]], with the resulting mechanical [[force]] exerted on a [[piston]].\n\nCompute the force on the plates as a function of {{math|'''x'''}}, the distance which separates them. To find the force, compute the potential energy, and then apply the definition of force as the gradient of the potential energy function.\n\nThe energy stored in a capacitor of [[capacitance]] {{math|''C''('''x''')}} and charge {{math|''Q''}} is\n\n:<math> U (Q, \\mathbf{x}) = \\frac{1}{2} QV = \\frac{1}{2} \\frac{Q^2}{C(\\mathbf{x})},~</math>\n\nwhere the dependence on the area of the plates, the dielectric constant of the material between the plates, and the separation {{math|'''x'''}} are abstracted away as the [[capacitance]] {{math|''C''('''x''')}}. (For a parallel plate capacitor, this is proportional to the area of the plates and inversely proportional to the separation.)\n\nThe force {{math|'''F'''}} between the plates due to the electric field is then\n\n:<math> \\mathbf{F}(\\mathbf{x}) = -\\frac{dU}{d\\mathbf{x}} ~. </math>\n\nIf the capacitor is not connected to any circuit, then the ''[[electric charge|charges]]'' on the plates remain constant as they move, and the force is the negative [[gradient]] of the [[electrostatics|electrostatic]] energy\n\n:<math> \\mathbf{F}(\\mathbf{x}) = \\frac{1}{2} \\frac{dC}{d\\mathbf{x}} \\frac{Q^2}{C^2}. </math>\n\nHowever, suppose, instead, that the ''[[volt]]age'' between the plates {{math|''V''}} is maintained constant by connection to a [[battery (electricity)|battery]], which is a reservoir for charge at constant potential difference; now the ''charge is variable'' instead of the voltage, its Legendre conjugate. To find the force, first compute the non-standard Legendre transform,\n\n:<math>U^*  = U - \\left(\\frac{\\partial U}{\\partial Q} \\right)\\bigg|_\\mathbf{x} \\cdot Q =U - \\frac{1}{2C(\\mathbf{x})} \\left( \\frac{\\partial Q^2}{\\partial Q} \\right)\\bigg|_\\mathbf{x} \\cdot Q = U - QV = \\frac{1}{2} QV - QV = -\\frac{1}{2} QV= - \\tfrac{1}{2} V^2 C(\\mathbf{x}).</math>\n\nThe force now becomes the negative gradient of this Legendre transform, still pointing in the same direction,\n\n:<math>  \\mathbf{F}(\\mathbf{x}) = -\\frac{dU^*}{d\\mathbf{x}}~.</math>\n\nThe two conjugate energies happen to stand opposite to each other, only because of the [[linear]]ity of the [[capacitance]]—except now {{math|''Q''}} is no longer a constant. They reflect the two different pathways of storing energy into the capacitor, resulting in, for instance, the same \"pull\" between a capacitor's plates.\n\n===Probability theory===\nIn [[large deviations theory]], the ''rate function'' is defined as the Legendre transformation of the logarithm of the [[moment generating function]] of a random variable. An important application of the rate function is in the calculation of tail probabilities of sums of i.i.d. random variables.\n\n===Microeconomics===\nLegendre transformation arises naturally in [[microeconomics]] in the process of finding the ''[[supply (economics)|supply]]'' {{math|''S''(''P'')}} of some product given a fixed price {{math|''P''}} on the market knowing the [[cost curve|cost function]] {{math|''C''(''Q'')}}, i.e. the cost for the producer to make/mine/etc. {{math|''Q''}} units of the given product.\n\nA simple theory explains the shape of the supply curve based solely on the cost function. Let us suppose the market price for a one unit of our product is {{math|''P''}}. For a company selling this good, the best strategy is to adjust the production {{math|''Q''}} so that its profit is maximized. We can maximize the profit\n\n:<math>\\text{profit} = \\text{revenue} - \\text{costs} =  PQ - C(Q)</math>\n\nby differentiating with respect to {{math|''Q''}} and solving\n\n:<math>P - C'(Q_{opt}) = 0.</math>\n\n{{math|''Q''<sub>''opt''</sub>}} represents the optimal quantity {{math|''Q''}} of goods that the producer is willing to supply, which is indeed the supply itself:\n:<math>S(P) = Q_{opt}(P) = (C^')^{-1}(P)</math>.\n\nIf we consider the maximal profit as a function of price, <math>\\text{profit}_\\text{max}(P)</math>, we see that it is the Legendre transform of the cost function <math>C(Q)</math>.\n\n==Geometric interpretation==\nFor a [[strictly convex function]], the Legendre transformation can be interpreted as a mapping between the [[graph of a function|graph]] of the function and the family of [[tangent]]s of the graph. (For a function of one variable, the tangents are well-defined at all but at most [[countable set|countably many]] points, since a convex function is [[derivative|differentiable]] at all but at most countably many points.)\n\nThe equation of a line with [[slope]] {{math|''p''}} and [[y-intercept|{{math|''y''}}-intercept]] {{math|''b''}} is given by {{math|''y'' {{=}} ''px'' + ''b''}}. For this line to be tangent to the graph of a function {{mvar|f}} at the point {{math|(''x''<sub>0</sub>, ''f''(''x''<sub>0</sub>))}} requires\n:<math>f\\left(x_0\\right) = p x_0 + b</math>\nand\n:<math>p = f'(x_0).</math>\n\nThe function <math>f'</math>is strictly monotone as the derivative of a strictly convex function. The second equation can be solved for <math>x_0 = f^{\\prime-1}(p)</math>, allowing elimination of {{math|''x''<sub>0</sub>}} from the first, and solving for the {{math|''y''}}-intercept {{math|''b''}} of the tangent as a function of its slope {{math|''p''}},\n:<math>b = f\\left(f^{\\prime-1}\\left(p\\right)\\right) - p \\cdot f^{\\prime-1}\\left(p\\right) = -f^\\star(p).</math>\n\nHere, <math>f^\\star</math> denotes the Legendre transform of {{mvar|f}}.\n\nThe [[indexed family|family]] of tangents of the graph of {{mvar|f}} parameterized by {{mvar|p}} is therefore given by\n:<math>y = px - f^\\star(p),</math>\nor, written implicitly, by the solutions of the equation\n:<math>F(x,y,p) = y + f^\\star(p) - px = 0~.</math>\n\nThe graph of the original function can be reconstructed from this family of lines as the [[envelope (mathematics)|envelope]] of this family by demanding\n: <math>{\\partial F(x,y,p)\\over\\partial p} = f^{\\star\\prime}(p) - x = 0.</math>\n\nEliminating {{math|''p''}} from these two equations gives\n: <math>y = x \\cdot f^{\\star\\prime-1}(x) - f^\\star\\left(f^{\\star\\prime-1}(x)\\right).</math>\n\nIdentifying {{math|''y''}} with {{math|''f''(''x'')}} and recognizing the right side of the preceding equation as the Legendre transform of {{math|''f''*}},  yields\n: <math>f(x) = f^{\\star\\star}(x) ~.</math>\n\n==Legendre transformation in more than one dimension==\nFor a differentiable real-valued function on an [[open set|open]] subset {{mvar|U}} of {{math|'''R'''<sup>''n''</sup>}} the Legendre conjugate of the pair {{math|(''U'', ''f'')}} is defined to be the pair {{math|(''V'', ''g'')}}, where {{mvar|V}} is the image of {{mvar|U}} under the [[gradient]] mapping {{math|''Df''}}, and {{mvar|g}} is the function on {{mvar|V}} given by the formula\n:<math>g(y) = \\left\\langle y, x \\right\\rangle - f(x), \\qquad x = \\left(Df\\right)^{-1}(y)</math>\nwhere\n:<math>\\left\\langle u,v\\right\\rangle = \\sum_{k=1}^n u_k \\cdot v_k</math>\n\nis the [[scalar product]] on {{math|'''R'''<sup>''n''</sup>}}. The multidimensional transform can be interpreted as an encoding of the [[convex hull]] of the function's [[epigraph (mathematics)|epigraph]] in terms of its [[supporting hyperplane]]s.<ref>http://maze5.net/?page_id=733</ref>\n\nAlternatively, if {{mvar|X}} is a [[vector space]] and {{math|''Y''}} is its [[dual space|dual vector space]], then for each point {{mvar|x}} of {{math|''X''}} and {{math|''y''}} of {{math|''Y''}}, there is a natural identification of the [[cotangent space]]s {{math|T*''X<sub>x</sub>''}} with {{math|''Y''}} and {{math|T*''Y<sub>y</sub>''}} with {{math|''X''}}. If {{mvar|f}} is a real differentiable function over {{math|''X''}}, then its [[exterior derivative]], {{math|''df''}}, is a section of the [[cotangent bundle]] {{math|T*''X''}} and as such, we can construct a map from {{math|''X''}} to {{math|''Y''}}. Similarly, if {{mvar|g}} is a real differentiable function over {{math|''Y''}}, then {{math|''dg''}} defines a map from {{math|''Y''}} to {{math|''X''}}. If both maps happen to be inverses of each other, we say we have a Legendre transform. The notion of the [[tautological one-form]] is commonly used in this setting.\n\nWhen the function is not differentiable, the Legendre transform can still be extended, and is known as the [[Legendre-Fenchel transformation]]. In this more general setting, a few properties are lost: for example, the Legendre transform is no longer its own inverse (unless there are extra assumptions, like [[convex function|convexity]]).\n\n==Further properties==\n\n===Scaling properties===\nThe Legendre transformation has the following scaling properties: For {{math|''a'' > 0}},\n\n:<math>f(x) = a \\cdot g(x) \\Rightarrow f^\\star(p) = a \\cdot g^\\star\\left(\\frac{p}{a}\\right) </math>\n:<math>f(x) = g(a \\cdot x) \\Rightarrow f^\\star(p) = g^\\star\\left(\\frac{p}{a}\\right).</math>\n\nIt follows that if a function is [[homogeneous function|homogeneous of degree {{mvar|r}}]] then its image under the Legendre transformation is a homogeneous function of degree {{mvar|s}}, where {{math|1/''r'' + 1/''s'' {{=}} 1}}. (Since {{math|''f''(''x'') {{=}} ''x<sup>r</sup>''/''r''}}, with {{math|''r'' > 1}}, implies {{math|''f''*(''p'') {{=}} ''p<sup>s</sup>''/''s''}}.)  Thus, the only monomial whose degree is invariant under Legendre transform is the quadratic.\n\n===Behavior under translation===\n:<math> f(x) = g(x) + b \\Rightarrow f^\\star(p) = g^\\star(p) - b</math>\n:<math> f(x) = g(x + y) \\Rightarrow f^\\star(p) = g^\\star(p) - p \\cdot y </math>\n\n===Behavior under inversion===\n:<math> f(x) = g^{-1}(x) \\Rightarrow f^\\star(p) = - p \\cdot g^\\star\\left(\\frac{1}{p} \\right) </math>\n\n===Behavior under linear transformations===\nLet {{math|''A'' : '''R'''<sup>''n''</sup> → '''R'''<sup>''m''</sup>}} be a [[linear transformation]]. For any convex function {{mvar|f}} on {{math|'''R'''<sup>''n''</sup>}}, one has\n\n:<math> (A f)^\\star = f^\\star A^\\star </math>\n\nwhere {{math|''A''*}} is the [[adjoint operator]] of {{mvar|A}} defined by\n\n:<math> \\left \\langle Ax, y^\\star \\right \\rangle = \\left \\langle x, A^\\star y^\\star \\right \\rangle, </math>\n\nand {{math|''Af''}} is the ''push-forward'' of {{mvar|f}} along {{mvar|A}}\n\n:<math> (A f)(y) = \\inf\\{ f(x) : x \\in X , A x = y \\}. </math>\n\nA closed convex function {{mvar|f}} is symmetric with respect to a given set {{mvar|G}} of [[orthogonal matrix|orthogonal linear transformation]]s,\n:<math>f(A x) = f(x), \\; \\forall x, \\; \\forall A \\in G </math>\n[[if and only if]] {{math|''f''*}} is symmetric with respect to {{mvar|G}}.\n\n===Infimal convolution===\nThe '''infimal convolution''' of two functions {{mvar|f}} and {{mvar|g}} is defined as\n\n:<math> \\left(f \\star_\\inf  g\\right)(x) = \\inf \\left \\{ f(x-y) + g(y) \\, | \\, y \\in \\mathbf{R}^n \\right \\}. </math>\n\nLet {{math|''f''<sub>1</sub>, ..., ''f<sub>m</sub>''}} be proper convex functions on {{math|'''R'''<sup>''n''</sup>}}. Then\n\n:<math> \\left( f_1 \\star_\\inf \\cdots \\star_\\inf f_m \\right)^\\star = f_1^\\star + \\cdots + f_m^\\star. </math>\n\n===Fenchel's inequality===\nFor any function {{mvar|f}} and its convex conjugate {{math|''f'' *}} ''Fenchel's inequality'' (also known as the ''Fenchel–Young inequality'') holds for every {{math|''x'' ∈ ''X''}}  and {{math|''p'' ∈ ''X''*}}, i.e., ''independent'' {{math|''x'', ''p''}} pairs,\n:<math>\\left\\langle p,x \\right\\rangle \\le f(x) + f^\\star(p).</math>\n\n==See also==\n* [[Dual curve]]\n* [[Projective duality]]\n* [[Young's inequality for products]]\n* [[Convex conjugate]]\n* [[Moreau's theorem]]\n* [[Integration by parts]]\n* [[Fenchel's duality theorem]]\n\n==References==\n{{reflist}}\n* {{cite book | last1=Courant |first1=Richard |authorlink1=Richard Courant |last2=Hilbert |first2=David |authorlink2=David Hilbert | title=Methods of Mathematical Physics |volume=2 |year=2008 | publisher=John Wiley & Sons |isbn=0471504394}}\n* {{cite book | last=Arnol'd |first=Vladimir Igorevich |authorlink=Vladimir Igorevich Arnol'd | title=Mathematical Methods of Classical Mechanics |edition=2nd | publisher=Springer | year=1989 | isbn=0-387-96890-3}}\n* Fenchel, W. (1949). \"On conjugate convex functions\", ''Can. J. Math''  '''1''': 73-77.\n* {{cite book | last=Rockafellar |first=R. Tyrrell | authorlink=R. Tyrrell Rockafellar |title=Convex Analysis |publisher=Princeton University Press |year=1996 |origyear=1970 |isbn=0-691-01586-4}}\n* {{Cite journal| last1   = Zia    | first1 = R. K. P.| last2   = Redish | first2 = E. F.| last3   = McKay  | first3 = S. R.| doi     = 10.1119/1.3119512| title   = Making sense of the Legendre transform| journal = American Journal of Physics| volume  = 77| issue   = 7| pages   = 614| year    = 2009| pmid    = | pmc     = | arxiv   = 0806.1147| bibcode= 2009AmJPh..77..614Z}}\n\n==Further reading==\n*{{cite web\n|url = https://www.lix.polytechnique.fr/~nielsen/Note-LegendreTransformation.pdf\n|title = Legendre transformation and information geometry\n|accessdate = 2016-01-24\n|last = Nielsen\n|first = Frank\n|date = 2010-09-01\n|format = PDF\n}}\n*{{cite web\n|url = http://www.physics.sun.ac.za/~htouchette/archive/notes/lfth2.pdf\n|title = Legendre-Fenchel transforms in a nutshell\n|accessdate = 2016-01-24\n|last = Touchette\n|first = Hugo\n|date = 2005-07-27\n|format = PDF\n}}\n*{{cite web\n|url = http://www.physics.sun.ac.za/~htouchette/archive/pnotes/convex1.pdf\n|title = Elements of convex analysis\n|accessdate = 2016-01-24\n|last = Touchette\n|first = Hugo\n|date = 2006-11-21\n|format = PDF\n}}\n\n==External links==\n{{Commons category|Legendre transformation}}\n*[http://maze5.net/?page_id=733 Legendre transform with figures] at maze5.net\n*[http://www.onmyphd.com/?p=legendre.fenchel.transform Legendre and Legendre-Fenchel transforms in a step-by-step explanation] at onmyphd.com\n\n[[Category:Transforms]]\n[[Category:Duality theories]]\n[[Category:Concepts in physics]]\n[[Category:Convex analysis]]\n[[Category:Mathematical physics]]"
    },
    {
      "title": "Linear separability",
      "url": "https://en.wikipedia.org/wiki/Linear_separability",
      "text": "In [[Euclidean geometry]], '''linear separability''' is a property of two sets of [[point (geometry)|points]]. This is most easily visualized in two dimensions (the [[Euclidean plane]]) by thinking of one set of points as being colored blue and the other set of points as being colored red. These two sets are ''linearly separable'' if there exists at least one [[line (geometry)|line]] in the plane with all of the blue points on one side of the line and all the red points on the other side. This idea immediately generalizes to higher-dimensional Euclidean spaces if line is replaced by [[hyperplane]].\n\nThe problem of determining if a pair of sets is linearly separable and finding a separating hyperplane if they are arises in several areas.  In [[statistics]] and [[machine learning]], classifying certain types of data is a problem for which good algorithms exist that are based on this concept.\n\n==Mathematical definition==\n\nLet <math>X_{0}</math> and <math>X_{1}</math> be two sets of points in an ''n''-dimensional Euclidean space. Then <math>X_{0}</math> and <math>X_{1}</math> are ''linearly separable'' if there exist ''n'' + 1 real numbers <math>w_{1}, w_{2},..,w_{n}, k</math>, such that every point <math>x \\in X_{0}</math> satisfies <math>\\sum^{n}_{i=1} w_{i}x_{i} > k</math> and every point <math>x \\in X_{1}</math> satisfies <math>\\sum^{n}_{i=1} w_{i}x_{i} < k</math>, where <math>x_{i}</math> is the <math>i</math>-th component of <math>x</math>.\n\nEquivalently, two sets are linearly separable precisely when their respective [[convex hull]]s are [[disjoint sets|disjoint]] (colloquially, do not overlap).{{Citation needed|reason=It is unclear that this is equivalent|date=September 2017}}\n\n== Examples ==\n\nThree non-[[collinear]] points in two classes ('+' and '-') are always linearly separable in two dimensions. This is illustrated by the three examples in the following figure (the all '+' case is not shown, but is similar to the all '-' case):\n\n{| align=\"center\" border=\"0\" cellpadding=\"4\" cellspacing=\"10\"\n| align=\"center\" | [[File:VC1.svg]]\n| align=\"center\" | [[File:VC2.svg]]\n| align=\"center\" | [[File:VC3.svg]]\n|}\n\nHowever, not all sets of four points, no three collinear, are linearly separable in two dimensions. The following example would need ''two'' straight lines and thus is not linearly separable:\n\n{| align=\"center\" border=\"0\" cellpadding=\"4\" cellspacing=\"0\"\n| [[File:VC4.svg]]\n|}\n\nNotice that three points which are collinear and of the form \"+ ⋅⋅⋅ &mdash; ⋅⋅⋅ +\" are also not linearly separable.\n\n== Linear separability of Boolean functions in ''n'' variables ==\n\nA [[Boolean function]] in ''n'' variables can be thought of as an assignment of ''0'' or ''1'' to each vertex of a Boolean [[hypercube]] in ''n'' dimensions. This gives a natural division of the vertices into two sets. The Boolean function is said to be ''linearly separable'' provided these two sets of points are linearly separable. The number of distinct Boolean functions is <math>2^{2^{n}}</math>where ''n'' is the number of variables passed into the function.<ref>{{Cite book|url=https://www.worldcat.org/oclc/945899984|title=Artificial intelligence a modern approach|last=1962-|first=Russell, Stuart J.|publisher=|others=Norvig, Peter 1956-|year=|isbn=1292153962|edition= Third|location=Boston|pages=766|oclc=945899984}}</ref>\n\n{| class=\"wikitable\"\n|+<small>Number of linearly separable Boolean functions in each dimension</small><ref>\n{{cite paper\n| last=Gruzling\n| first=Nicolle\n| title=Linear separability of the vertices of an n-dimensional hypercube. M.Sc Thesis\n| publisher= University of Northern British Columbia\n| year=2006\n}}</ref> {{OEIS|id=A000609}}\n!Number of variables\n!Boolean functions\n!Linearly separable Boolean functions\n|-\n|  2 \n|16|| 14\n|-\n|  3 \n|256|| 104\n|-\n|  4 \n|65536|| 1882\n|-\n|  5 \n|4294967296|| 94572\n|-\n|  6 \n|18446744073709552000|| 15028134\n|-\n|  7 \n|3.402823669 ×10^38\n| 8378070864\n|-\n|  8 \n|1.157920892 ×10^77|| 17561539552946\n|-\n|  9 \n|1.340780792 ×10^154|| 144130531453121108\n|}\n\n== Support vector machines==\n{{main|Support vector machine}}\n\n[[Image:Svm separating hyperplanes (SVG).svg|thumb|right|H<sub>1</sub> does not separate the sets. H<sub>2</sub> does, but only with a small margin.  H<sub>3</sub> separates them with the maximum margin.]]\n[[Statistical classification|Classifying data]] is a common task in [[machine learning]].\nSuppose some data points, each belonging to one of two sets, are given and we wish to create a model that will decide which set a ''new'' data point will be in. In the case of [[support vector machine]]s, a data point is viewed as a ''p''-dimensional vector (a list of ''p'' numbers), and we want to know whether we can separate such points with a (''p''&nbsp;&minus;&nbsp;1)-dimensional [[hyperplane]]. This is called a [[linear classifier]]. There are many hyperplanes that might classify (separate) the data. One reasonable choice as the best hyperplane is the one that represents the largest separation, or margin, between the two sets. So we choose the hyperplane so that the distance from it to the nearest data point on each side is maximized. If such a hyperplane exists, it is known as the ''[[maximum-margin hyperplane]]'' and the linear classifier it defines is known as a ''maximum [[margin classifier]]''.\n\nMore formally, given some training data <math>\\mathcal{D}</math>, a set of ''n'' points of the form\n\n:<math>\\mathcal{D} = \\left\\{ (\\mathbf{x}_i, y_i)\\mid\\mathbf{x}_i \\in \\mathbb{R}^p,\\, y_i \\in \\{-1,1\\}\\right\\}_{i=1}^n</math>\n\nwhere the ''y''<sub>''i''</sub> is either 1 or −1, indicating the set to which the point <math>\\mathbf{x}_i </math> belongs. Each <math> \\mathbf{x}_i </math> is a ''p''-dimensional [[real number|real]] vector. We want to find the maximum-margin hyperplane that divides the points having <math>y_i=1</math> from those having <math>y_i=-1</math>. Any hyperplane can be written as the set of points <math>\\mathbf{x}</math> satisfying\n\n: <math>\\mathbf{w}\\cdot\\mathbf{x} - b=0,</math>\n\nwhere <math>\\cdot</math> denotes the [[dot product]] and <math>{\\mathbf{w}}</math> the (not necessarily normalized) [[Normal (geometry)|normal vector]] to the hyperplane. The parameter <math>\\tfrac{b}{\\|\\mathbf{w}\\|}</math> determines the offset of the hyperplane from the origin along the normal vector <math>{\\mathbf{w}}</math>.\n\nIf the training data are linearly separable, we can select two hyperplanes in such a way that they separate the data and there are no points between them, and then try to maximize their distance.\n\n== See also ==\n\n* [[Perceptron]]\n* [[Vapnik–Chervonenkis dimension]]\n\n== References ==\n{{reflist}}\n\n[[Category:Geometry]]\n[[Category:Convex analysis]]\n[[Category:Machine learning]]"
    },
    {
      "title": "Logarithmically concave function",
      "url": "https://en.wikipedia.org/wiki/Logarithmically_concave_function",
      "text": "In [[convex analysis]], a [[non-negative]] function {{math|''f'' : '''R'''<sup>''n''</sup> → '''R'''<sub>+</sub>}} is '''logarithmically concave''' (or '''log-concave''' for short) if its [[domain of a function|domain]] is a [[convex set]], and if it satisfies the inequality\n: <math>\n    f(\\theta x + (1 - \\theta) y) \\geq f(x)^{\\theta} f(y)^{1 - \\theta}\n  </math>\nfor all {{math|''x'',''y'' ∈ dom ''f''}} and {{math|0&nbsp;<&nbsp;''&theta;''&nbsp;<&nbsp;1}}. If {{math|''f''}} is strictly positive, this is equivalent to saying that the [[logarithm]] of the function, {{math|log ∘ ''f''}}, is [[concave function|concave]]; that is,\n: <math>\n    \\log  f(\\theta x + (1 - \\theta) y) \\geq \\theta \\log f(x) + (1-\\theta) \\log f(y)\n  </math>\nfor all {{math|''x'',''y'' ∈ dom ''f''}} and {{math|0&nbsp;<&nbsp;''&theta;''&nbsp;<&nbsp;1}}.\n\nExamples of log-concave functions are the 0-1 [[indicator function]]s of convex sets (which requires the more flexible definition), and the [[Gaussian function]].\n\nSimilarly, a function is '''[[log-convex]]''' if it satisfies the reverse inequality\n: <math>\n    f(\\theta x + (1 - \\theta) y) \\leq f(x)^{\\theta} f(y)^{1 - \\theta}\n  </math>\nfor all {{math|''x'',''y'' ∈ dom ''f''}} and {{math|0&nbsp;<&nbsp;''&theta;''&nbsp;<&nbsp;1}}.\n\n==Properties==\n* A log-concave function is also [[Quasi-concave function|quasi-concave]]. This follows from the fact that the logarithm is monotone implying that the superlevel sets of this function are convex.<ref name=\":0\" />\n* Every concave function that is nonnegative on its domain is log-concave. However, the reverse does not necessarily hold. An example is the [[Gaussian function]] {{math|''f''(''x'')}}&nbsp;=&nbsp;{{math|exp(&minus;x<sup>2</sup>/2)}} which is log-concave since {{math|log ''f''(''x'')}}&nbsp;=&nbsp;{{math|&minus;''x''<sup>2</sup>/2}} is a concave function of {{math|''x''}}. But {{math|''f''}} is not concave since the second derivative is positive for |{{math|''x''}}|&nbsp;>&nbsp;1:\n\n::<math>f''(x)=e^{-\\frac{x^2}{2}} (x^2-1) \\nleq 0</math>\n* From above two points, [[Concave function|concavity]] <math>\\Rightarrow</math> log-concavity <math>\\Rightarrow</math> [[Quasiconcave function|quasiconcavity]].\n* A twice differentiable, nonnegative function with a convex domain is log-concave if and only if for all {{math|''x''}} satisfying {{math|''f''(''x'')&nbsp;>&nbsp;0}},\n\n::<math>f(x)\\nabla^2f(x) \\preceq \\nabla f(x)\\nabla f(x)^T</math>,<ref name=\":0\">{{cite book |first=Stephen |last=Boyd |authorlink=Stephen P. Boyd |first2=Lieven |last2=Vandenberghe |chapter=Log-concave and log-convex functions |title=Convex Optimization |location= |publisher=Cambridge University Press |year=2004 |isbn=0-521-83378-7 |url=https://web.stanford.edu/~boyd/cvxbook/ |pages=104–108 }}</ref>\n\n:i.e.\n\n::<math>f(x)\\nabla^2f(x) - \\nabla f(x)\\nabla f(x)^T</math> is\n\n:[[positive-definite matrix|negative semi-definite]]. For functions of one variable, this condition simplifies to\n\n::<math>f(x)f''(x) \\leq (f'(x))^2</math>\n\n==Operations preserving log-concavity==\n\n* Products: The product of log-concave functions is also log-concave. Indeed, if {{math|''f''}} and {{math|''g''}} are log-concave functions, then {{math|log&nbsp;''f''}} and {{math|log&nbsp;''g''}} are concave by definition. Therefore\n\n::<math>\\log\\,f(x) + \\log\\,g(x) = \\log(f(x)g(x))</math>\n\n:is concave, and hence also {{math|''f''&nbsp;''g''}} is log-concave.\n\n* [[marginal distribution|Marginals]]: if {{math|''f''(''x'',''y'')}}&nbsp;:&nbsp;{{math|'''R'''<sup>''n''+''m''</sup>&nbsp;&rarr;&nbsp;'''R'''}} is log-concave, then\n\n::<math>g(x)=\\int f(x,y) dy</math>\n\n:is log-concave (see [[Prékopa–Leindler inequality]]).\n\n* This implies that [[convolution]] preserves log-concavity, since {{math|''h''(''x'',''y'')}}&nbsp;=&nbsp;{{math|''f''(''x''-''y'')&nbsp;''g''(''y'')}} is log-concave if {{math|''f''}} and {{math|''g''}} are log-concave, and therefore\n\n::<math>(f*g)(x)=\\int f(x-y)g(y) dy = \\int h(x,y) dy</math>\n\n:is log-concave.\n\n==Log-concave distributions==\nLog-concave distributions are necessary for a number of algorithms, e.g. [[adaptive rejection sampling]]. Every distribution with  log-concave density is a [[maximum entropy probability distribution]] with specified mean ''μ'' and [[Deviation risk measure]] ''D''.<ref name=\"Grechuk1\">{{cite journal |last=Grechuk |first=B. |last2=Molyboha |first2=A. |last3=Zabarankin |first3=M. |year=2009 |title=Maximum Entropy Principle with General Deviation Measures |journal=Mathematics of Operations Research |volume=34 |issue=2 |pages=445–467 |doi=10.1287/moor.1090.0377 }}</ref> \nAs it happens, many common [[probability distribution]]s are log-concave.  Some examples:<ref>See {{cite journal |first=Mark |last=Bagnoli |first2=Ted |last2=Bergstrom |year=2005 |title=Log-Concave Probability and Its Applications |journal=Economic Theory |volume=26 |issue=2 |pages=445–469 |doi=10.1007/s00199-004-0514-4 }}</ref>\n*The [[normal distribution]] and [[multivariate normal distribution]]s.\n*The [[exponential distribution]].\n*The [[uniform distribution (continuous)|uniform distribution]] over any [[convex set]].\n*The [[logistic distribution]].\n*The [[extreme value distribution]].\n*The [[Laplace distribution]].\n*The [[chi distribution]].\n*The [[Wishart distribution]], where ''n'' >= ''p'' + 1.<ref name=\"prekopa\">{{cite journal | last1 = Prékopa | first1 = András | year = 1971 | title = Logarithmic concave measures with application to stochastic programming | url = | journal = Acta Scientiarum Mathematicarum | volume = 32 | issue = | pages = 301–316 }}</ref>\n*The [[Dirichlet distribution]], where all parameters are >= 1.<ref name=\"prekopa\"/>\n*The [[gamma distribution]] if the shape parameter is >= 1.\n*The [[chi-square distribution]] if the number of degrees of freedom is >= 2.\n*The [[beta distribution]] if both shape parameters are >= 1.\n*The [[Weibull distribution]] if the shape parameter is >= 1.\n\nNote that all of the parameter restrictions have the same basic source: The exponent of non-negative quantity must be non-negative in order for the function to be log-concave.\n\nThe following distributions are non-log-concave for all parameters:\n*The [[Student's t-distribution]].\n*The [[Cauchy distribution]].\n*The [[Pareto distribution]].\n*The [[log-normal distribution]].\n*The [[F-distribution]].\n\nNote that the [[cumulative distribution function]] (CDF) of all log-concave distributions is also log-concave.  However, some non-log-concave distributions also have log-concave CDF's:\n*The [[log-normal distribution]].\n*The [[Pareto distribution]].\n*The [[Weibull distribution]] when the shape parameter < 1.\n*The [[gamma distribution]] when the shape parameter < 1.\n\nThe following are among the properties of log-concave distributions:\n*If a density is log-concave, so is its [[cumulative distribution function]] (CDF).\n*If a multivariate density is log-concave, so is the [[marginal density]] over any subset of variables.\n*The sum of two independent log-concave [[random variable]]s is log-concave.  This follows from the fact that the convolution of two log-concave functions is log-concave.\n*The product of two log-concave functions is log-concave.  This means that [[joint distribution|joint]] densities formed by multiplying two probability densities (e.g. the [[normal-gamma distribution]], which always has a shape parameter >= 1) will be log-concave.  This property is heavily used in general-purpose [[Gibbs sampling]] programs such as [[Bayesian inference using Gibbs sampling|BUGS]] and [[Just another Gibbs sampler|JAGS]], which are thereby able to use [[adaptive rejection sampling]] over a wide variety of [[conditional distribution]]s derived from the product of other distributions.\n\n==See also==\n*[[logarithmically concave sequence]]\n*[[logarithmically concave measure]]\n*[[logarithmically convex function]]\n*[[convex function]]\n\n==Notes==\n{{Reflist}}\n\n==References==\n* {{cite book|authorlink=Ole Barndorff-Nielsen|last=Barndorff-Nielsen|first=Ole|title=Information and exponential families in statistical theory|series=Wiley Series in Probability and Mathematical Statistics|publisher=John Wiley \\& Sons, Ltd.|location=Chichester|year=1978|pages=ix+238 pp.|isbn=0-471-99545-2|mr=489333}}\n* {{cite book|title=Unimodality, convexity, and applications \n|last1=Dharmadhikari|first1=Sudhakar\n|last2=Joag-Dev\n|first2=Kumar|series=Probability and Mathematical Statistics\n|publisher=Academic Press, Inc.\n|location=Boston, MA\n|year=1988\n|pages=xiv+278\n|isbn=0-12-214690-5|mr=954608}}\n\n* {{cite book|title=Parametric Statistical Theory | last1=Pfanzagl | first1=Johann \n|authorlink= <!-- Johann Pfanzagl --> \n|last2=with the assistance of R. Hamböker \n|year=1994|publisher=Walter de Gruyter\n|isbn=3-11-013863-8\n|mr=1291393}}\n\n* {{cite book|title=Convex functions, partial orderings, and statistical applications|last1=Pečarić|first1=Josip E.|last2=Proschan|first2=Frank|last3=Tong|first3=Y. L.|<!-- authorlink2=Frank Proschan -->\n|series=Mathematics in Science and Engineering|volume=187\n|publisher=Academic Press, Inc.\n|location=Boston, MA\n|year=1992|pages=xiv+467 pp.\n|isbn=0-12-549250-2\n|mr=1162312}}\n\n{{DEFAULTSORT:Logarithmically Concave Function}}\n[[Category:Mathematical analysis]]\n[[Category:Convex analysis]]"
    },
    {
      "title": "Lower convex envelope",
      "url": "https://en.wikipedia.org/wiki/Lower_convex_envelope",
      "text": "In [[mathematics]], the '''lower convex envelope''' <math>\\breve f</math> of a [[function (mathematics)|function]] <math>f</math> defined on an [[interval (mathematics)|interval]] <math>[a,b]</math> is defined at each point of the interval as the [[supremum]] of all [[convex function]]s that lie under that function, i.e.\n\n: <math>\n\\breve f (x) = \\sup\\{ g(x) \\mid g \\text{ is convex and } g \\leq f \\text{ over } [a,b] \\}.\n</math>\n\n== See also ==\n* [[Convex hull]]\n\n[[Category:Convex analysis]]\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Minkowski functional",
      "url": "https://en.wikipedia.org/wiki/Minkowski_functional",
      "text": "In [[mathematics]], in the field of [[functional analysis]], a '''Minkowski functional''' is a function that recovers a notion of distance on a linear space.\n\nLet ''K'' be a symmetric (i.e. if it contains ''x'' it also contains -''x'') convex body in a linear space ''V''.  We define a function ''p'' on ''V'' as\n\n:<math>p(x) = \\inf \\{ \\lambda \\in \\mathbb{R}_{> 0} : x \\in \\lambda K \\} </math>\n\nThis is the Minkowski functional of ''K''.<ref>Thompson (1996) p.17</ref> Usually it is assumed that ''K'' is such that the set of <math>\\lambda</math> is never empty, but sometimes the set is allowed to be empty and then ''p(x)'' is defined as infinity.\n\n== Examples ==\n\n===Example 1===\n\nConsider a [[normed vector space]] <math>X</math>, with the norm ||·||. Let <math>K</math> be the unit ball in <math>X</math>. Define a function <math>p:X\\rightarrow \\mathbb{R}</math> by \n\n:<math>p(x) = \\inf \\left\\{r > 0: x \\in r K \\right\\}. </math>\n\nOne can see that <math>p(x) = \\|x\\|</math>, i.e. <math>p</math> is just the norm on <math>X</math>. The function ''p'' is a special case of a Minkowski functional.\n\n=== Example 2===\n\nLet ''X'' be a vector space without topology with underlying scalar field <math>\\mathbb{K}</math>. Take <math>\\phi \\in X'</math>, the algebraic dual of <math>X</math>, i.e. <math>\\phi: X \\rightarrow \\mathbb{K}</math> is a linear functional on <math>X</math>. Fix <math>a>0</math>. Let the set <math>K</math> be given by\n\n:<math>K = \\{ x \\in X : | \\phi(x) | \\leq a \\}. </math>\n\nAgain we define\n\n:<math>p(x) = \\inf \\left\\{r > 0: x \\in r K \\right\\}. </math>\n\nThen\n\n:<math>p(x) = \\frac{1}{a} | \\phi(x) |.</math>\n\nThe function ''p''(''x'') is another instance of a Minkowski functional. It has the following properties:\n\n#It is ''subadditive'': <math>p(x + y) \\leqslant p(x) + p(y)</math>,\n#It is ''homogeneous'': for all <math>\\alpha \\in \\mathbb{K}, p(\\alpha x) = \\left\\vert \\alpha \\right\\vert p(x)</math>,\n#It is nonnegative.\n\nTherefore, <math>p</math> is a [[seminorm]] on <math>X</math>, with an induced topology. This is characteristic of Minkowski functionals defined via \"nice\" sets. There is a one-to-one correspondence between seminorms and the Minkowski functional given by such sets. What is meant precisely by \"nice\" is discussed in the section below.\n\nNotice that, in contrast to a stronger requirement for a norm, <math>p(x) = 0</math> need not imply <math>x=0</math>. In the above example, one can take a nonzero <math>x</math> from the kernel of <math>\\phi</math>. Consequently, the resulting topology need not be [[Hausdorff space|Hausdorff]].\n\n== Definition ==\n\nThe above examples suggest that, given a (complex or real) vector space ''X'' and a subset ''K'', one can define a corresponding Minkowski functional\n\n:<math>p_K:X \\rightarrow [0, \\infty)</math>\n\nby\n\n:<math>p_K (x) = \\inf \\left\\{r > 0: x \\in r K \\right\\},</math>\n\nwhich is often called the gauge of <math>K</math>.\n\nIt is implicitly assumed in this definition that 0 ∈ ''K'' and the set {''r'' > 0: ''x'' ∈ ''r K''} is nonempty for every x. In order for ''p<sub>K</sub>'' to have the properties of a seminorm, additional restrictions must be imposed on ''K''. These conditions are listed below.\n\n#The set ''K'' being [[convex set|convex]] implies the subadditivity of ''p<sub>K</sub>''.\n#[[Homogeneous function|Homogeneity]], i.e. ''p<sub>K</sub>''(''α x'') = |''α''| ''p<sub>K</sub>''(''x'') for all ''α'', is ensured if ''K'' is ''balanced'', meaning ''α K'' ⊂ ''K'' for all |''α''| ≤ 1.\n\nA set ''K'' with these properties is said to be [[absolutely convex set|absolutely convex]].\n\n=== Convexity of ''K'' ===\n\nA simple geometric argument that shows convexity of ''K'' implies subadditivity is as follows. Suppose for the moment that ''p<sub>K</sub>''(''x'') = ''p<sub>K</sub>''(''y'') = ''r''. Then for all ''ε'' > 0, we have ''x'', ''y'' ∈ (''r + ε'') ''K'' = '' K' ''. The assumption that ''K'' is convex means '' K' '' is also. Therefore, ½ ''x'' + ½ ''y'' is in '' K' ''. By definition of the Minkowski functional ''p<sub>K</sub>'', one has\n\n:<math>p_K\\left( \\frac{1}{2} x + \\frac{1}{2} y\\right) \\le r + \\epsilon = \\frac{1}{2} p_K(x) + \\frac{1}{2} p_K(y) + \\epsilon .</math>\n\nBut the left hand side is ½ ''p<sub>K</sub>''(''x'' + ''y''), i.e. the above becomes\n\n:<math>p_K(x + y) \\le  p_K(x) + p_K(y) + \\epsilon, \\quad \\mbox{for all} \\quad \\epsilon > 0.</math>\n\nThis is the desired inequality. The general case ''p<sub>K</sub>''(''x'') > ''p<sub>K</sub>''(''y'') is obtained after the obvious modification.\n\n'''Note''' Convexity of ''K'', together with the initial assumption that the set {''r'' > 0: ''x'' ∈ ''r K''} is nonempty, implies that ''K'' is [[absorbing set|absorbing]].\n\n=== Balancedness of ''K'' ===\n\nNotice that ''K'' being balanced implies that\n\n:<math>\\lambda x \\in r K \\quad \\mbox{if and only if} \\quad x \\in \\frac{r}{|\\lambda|} K.</math>\n\nTherefore\n\n:<math>p_K (\\lambda x) = \\inf \\left\\{r > 0:  \\lambda x \\in r K \\right\\} \n=  \\inf \\left\\{r > 0:  x \\in \\frac{r}{|\\lambda|} K \\right\\}\n= \\inf \\left\\{ | \\lambda | \\frac{r}{ | \\lambda | } > 0:  x \\in \\frac{r}{|\\lambda|} K \\right\\}\n= |\\lambda| p_K(x).\n</math>\n\n== See also ==\n\n* [[Hadwiger's theorem]]\n* [[Hugo Hadwiger]]\n* [[Morphological image processing]]\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{cite book | title=Minkowski Geometry | series=Encyclopedia of Mathematics and Its Applications | first=Anthony C. | last=Thompson | publisher=[[Cambridge University Press]] | year=1996 | isbn=0-521-40472-X }}\n\n{{Functional Analysis}}\n\n[[Category:Functional analysis]]\n[[Category:Convex analysis]]\n[[Category:Hermann Minkowski]]"
    },
    {
      "title": "Minkowski's theorem",
      "url": "https://en.wikipedia.org/wiki/Minkowski%27s_theorem",
      "text": "{{multiple issues|{{no footnotes|date=February 2017}}{{Page numbers needed|date=September 2010}}}}\n[[File:Mconvexe.png|thumb|A set in {{math|ℝ<sup>2</sup>}} satisfying the hypotheses of Minkowski's theorem.]]\n\nIn [[mathematics]], '''Minkowski's theorem''' is the statement that every [[convex set]] in <math>\\mathbb{R}^n</math> which is symmetric with respect to the origin and which has [[volume]] greater than <math>2^n</math> contains a non-zero [[integer point]]. The theorem was proved by [[Hermann Minkowski]] in 1889 and became the foundation of the branch of [[number theory]] called the [[geometry of numbers]]. It can be extended from the integers to any [[Lattice (group)|lattice]] <math>L</math> and to any symmetric convex set with volume greater than <math>2^n\\,d(L)</math>, where <math>d(L)</math> denotes the covolume of the lattice (the absolute value of the [[determinant]] of any of its bases).\n\n==Formulation==\nSuppose that {{math|''L''}} is a [[lattice (group)|lattice]] of [[Lattice (group)#Dividing_space_according_to_a_lattice|determinant]] {{math|d(''L'')}} in the {{math|''n''}}-dimensional real [[vector space]] {{math|ℝ<sup>''n''</sup>}} and {{math|''S''}} is a [[convex set|convex subset]] of {{math|ℝ<sup>''n''</sup>}} that is symmetric with respect to the origin, meaning that if {{math|''x''}} is in {{math|''S''}} then {{math|−''x''}} is also in {{math|''S''}}. Minkowski's theorem states that if the volume of {{math|''S''}} is strictly greater than {{math|2<sup>''n''</sup> d(''L'')}}, then {{math|''S''}} must contain at least one lattice point other than the origin. (Since the set {{math|''S''}} is symmetric, it would then contain at least three lattice points: the origin 0 and a pair of points {{math|±''x''}}, where {{math|''x'' ∈ ''L'' \\ 0}}.)\n\n==Example==\nThe simplest example of a lattice is the [[integer lattice]] {{math|ℤ<sup>''n''</sup>}} of all points with [[integer]] coefficients; its determinant is 1. For {{math|''n'' {{=}} 2}}, the theorem claims that a convex figure in the [[Euclidean plane]] symmetric about the [[Origin (mathematics)|origin]] and with [[area]] greater than 4 encloses at least one lattice point in addition to the origin. The area bound is [[Mathematical jargon#sharp|sharp]]: if {{math|''S''}} is the interior of the square with vertices {{math|(±1, ±1)}} then {{math|''S''}} is symmetric and convex, and has area 4, but the only lattice point it contains is the origin. This example, showing that the bound of the theorem is sharp, generalizes to [[hypercube]]s in every dimension {{math|''n''}}.\n\n==Proof==\nThe following argument proves Minkowski's theorem for the specific case of {{math|''L'' {{=}} ℤ<sup>''2''</sup>}}. It can be generalized to arbitrary lattices in arbitrary dimensions.\n\nConsider the map\n:<math>f: S \\to \\mathbb{R}^2/2L, \\qquad (x,y) \\mapsto (x \\bmod 2, y \\bmod 2)</math>\nIntuitively, this map cuts the plane into 2 by 2 squares, then stacks the squares on top of each other. Clearly {{math|''f''(''S'')}} has area less than or equal to 4, because this set lies within a 2 by 2 square. Assume for a contradiction that {{math|''f''}} could be [[injective]], which means the pieces of {{math|''S''}} cut out by the squares stack up in a non-overlapping way. Because {{math|''f''}} is locally area-preserving, this non-overlapping property would make it area-preserving for all of {{math|''S''}}, so the area of {{math|''f''(''S'')}} would be the same as that of {{math|''S''}}, which is greater than 4. That is not the case, so the assumption must be false: {{math|''f''}} is not injective, meaning that there exist at least two distinct points {{math|''p''<sub>1</sub>, ''p''<sub>2</sub>}} in {{math|''S''}} that are mapped by {{math|''f''}} to the same point: {{math|''f''(''p''<sub>1</sub>) {{=}} ''f''(''p''<sub>2</sub>)}}.\n\nBecause of the way {{math|''f''}} was defined,\nthe only way that {{math|''f''(''p''<sub>1</sub>)}} can equal {{math|''f''(''p''<sub>2</sub>)}} is for {{math|''p''<sub>2</sub>}}\nto equal {{math|''p''<sub>1</sub> + (2''i'', 2''j'')}} for some integers {{math|''i''}} and {{math|''j''}}, not both zero.\nThat is, the coordinates of the two points differ by two even integers. \nSince {{math|''S''}} is symmetric about the origin, {{math|−''p''<sub>1</sub>}} is also a point in {{math|''S''}}. Since {{math|''S''}} is convex, the line segment between {{math|−''p''<sub>1</sub>}} and {{math|''p''<sub>2</sub>}} lies entirely in {{math|''S''}}, and in particular the midpoint of that segment lies in {{math|''S''}}. In other words,\n:<math>\\tfrac{1}{2}\\left(-p_1 + p_2\\right) = \\tfrac{1}{2}\\left(-p_1 + p_1 + (2i, 2j)\\right) = (i, j)</math>\nis a point in {{math|''S''}}. But this point {{math|(''i'',''j'')}} is an integer point, and is not the origin since {{math|''i''}} and {{math|''j''}} are not both zero.\nTherefore, {{math|''S''}} contains a nonzero integer point.\n\n==Applications==\nAn application of this theorem is the result that every class in the [[ideal class group]] of a [[number field]] {{math|''K''}} contains an [[integral ideal]] of [[field norm|norm]] not exceeding a certain bound, depending on {{math|''K''}}, called [[Minkowski's bound]]: the finiteness of the [[Class number (number theory)|class number]] of an algebraic number field follows immediately.\n\nMinkowski's theorem is also useful to prove [[Lagrange's four-square theorem]], which states that every natural number can be written as the sum of the squares of four natural numbers.\n\n==See also==\n* [[Danzer set]]\n* [[Pick's theorem]]\n* [[Dirichlet's unit theorem]]\n* [[Minkowski's second theorem]]\n\n==Further reading==\n*{{Cite book|\nauthor=[[Enrico Bombieri]] and Walter Gubler\n|title=Heights in Diophantine Geometry\n|publisher=Cambridge U. P.\n|year=2006}}\n* [[J. W. S. Cassels]]. ''An Introduction to the Geometry of Numbers''. Springer Classics in Mathematics, Springer-Verlag 1997 (reprint of 1959 and 1971 Springer-Verlag editions).\n* [[John Horton Conway]] and [[N. J. A. Sloane]], ''Sphere Packings, Lattices and Groups'', Springer-Verlag, NY, 3rd ed., 1998.\n<!-- *R. J. Gardner, ''Geometric tomography,'' Cambridge University Press, New York, 1995. Second edition: 2006. -->\n*{{Cite book\n  | author = Hancock, Harris\n  | title = Development of the Minkowski Geometry of Numbers\n  | year = 1939\n  | publisher = Macmillan}} (Republished in 1964 by Dover.)\n* [[Edmund Hlawka]], Johannes Schoißengeier, Rudolf Taschner. ''Geometric and Analytic Number Theory''. Universitext. Springer-Verlag, 1991.\n* [[C. G. Lekkerkerker]]. ''Geometry of Numbers''. Wolters-Noordhoff, North Holland, Wiley. 1969.\n* [[Wolfgang M. Schmidt]]. ''Diophantine approximation''. Lecture Notes in Mathematics 785. Springer. (1980 [1996 with minor corrections])\n* [[Wolfgang M. Schmidt]].''Diophantine approximations and Diophantine equations'', Lecture Notes in Mathematics, Springer Verlag 2000.\n*{{Cite book\n  | author = Siegel, Carl Ludwig\n  | authorlink = Carl Ludwig Siegel\n  | title = Lectures on the Geometry of Numbers\n  | year = 1989\n  | publisher = Springer-Verlag}}\n* Rolf Schneider, ''Convex bodies: the Brunn-Minkowski theory,'' Cambridge University Press, Cambridge, 1993.\n\n==External links==\n* {{planetmath_reference|id=4601|title=Minkowski's theorem}}\n*Stevenhagen, Peter. [http://websites.math.leidenuniv.nl/algebra/ant.pdf ''Number Rings''.]\n*{{springer|title=Minkowski theorem|id=M/m064090|last=Malyshev|first=A.V.}}\n*{{Springer|id=G/g044350|title=Geometry of numbers}} <!-- Hazewinkel -->\n\n{{DEFAULTSORT:Minkowski's Theorem}}\n[[Category:Geometry of numbers]]\n[[Category:Convex analysis]]\n[[Category:Theorems in number theory]]\n[[Category:Articles containing proofs]]\n[[Category:Hermann Minkowski]]"
    },
    {
      "title": "Modulus and characteristic of convexity",
      "url": "https://en.wikipedia.org/wiki/Modulus_and_characteristic_of_convexity",
      "text": "In [[mathematics]], the '''modulus of convexity''' and the '''characteristic of convexity''' are measures of \"how [[convex set|convex]]\" the [[unit ball]] in a [[Banach space]] is. In some sense, the modulus of convexity has the same relationship to the ''ε''-''δ'' definition of [[uniformly convex space|uniform convexity]] as the [[modulus of continuity]] does to the ''ε''-''δ'' definition of [[continuous function|continuity]].\n\n==Definitions==\n\nThe '''modulus of convexity''' of a Banach space (''X'',&nbsp;||&middot;||) is the function {{nowrap|''δ'' : [0, 2] → [0, 1]}} defined by\n\n:<math>\\delta (\\varepsilon) = \\inf \\left\\{ 1 - \\left\\| \\frac{x + y}{2} \\right\\| \\,:\\,  x, y \\in S, \\| x - y \\| \\geq \\varepsilon \\right\\},</math>\n\nwhere ''S'' denotes the unit sphere of (''X'',&nbsp;||&nbsp;||).  In the definition of&nbsp;''δ''(''ε''), one can as well take the infimum over all vectors ''x'', ''y'' in&nbsp;''X'' such that {{nowrap|ǁ''x''ǁ, ǁ''y''ǁ &le; 1}} and {{nowrap|ǁ''x'' &minus; ''y''ǁ &ge; ''ε''}}.<ref>p.&nbsp;60 in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref>\n\nThe '''characteristic of convexity''' of the space (''X'',&nbsp;||&nbsp;||) is the number ''ε''<sub>0</sub> defined by\n\n:<math>\\varepsilon_{0} = \\sup \\{ \\varepsilon \\,:\\, \\delta(\\varepsilon) = 0 \\}.</math>\n\nThese notions are implicit in the general study of uniform convexity by J.&nbsp;A.&nbsp;Clarkson ({{harvtxt|Clarkson|1936}}; this is the same paper containing the statements of [[Clarkson's inequalities]]).  The term \"modulus of convexity\" appears to be due to M.&nbsp;M.&nbsp;Day.<ref>{{citation\n| last = Day\n| first = Mahlon\n| title = Uniform convexity in factor and conjugate spaces\n| journal = Ann. of Math. |series =  2\n| volume = 45\n| year = 1944\n| pages = 375&ndash;385\n| doi = 10.2307/1969275\n| issue = 2\n| publisher = Annals of Mathematics\n| jstor = 1969275\n}}</ref>\n\n==Properties==\n* The modulus of convexity, ''δ''(''ε''), is a [[monotonic function|non-decreasing]] function of ''ε'', and the quotient {{nowrap|''δ''(''ε'')&thinsp;/&thinsp;''ε''}} is also non-decreasing on&nbsp;{{nowrap|(0, 2]}}.<ref>Lemma 1.e.8, p.&nbsp;66 in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref>  The modulus of convexity need not itself be a [[convex function]] of&nbsp;''ε''.<ref>see Remarks, p.&nbsp;67 in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref>  However, the modulus of convexity is equivalent to a convex function in the following sense:<ref>see Proposition 1.e.6, p.&nbsp;65 and Lemma 1.e.7, 1.e.8, p.&nbsp;66  in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref> there exists a convex function ''δ''<sub>1</sub>(''ε'') such that\n::<math>\\delta(\\varepsilon / 2) \\le \\delta_1(\\varepsilon) \\le \\delta(\\varepsilon), \\quad \\varepsilon \\in [0, 2].</math>\n\n* The normed space {{nowrap|(''X'', ǁ&thinsp;&sdot;&thinsp;ǁ)}} is [[uniformly convex space|uniformly convex]] [[if and only if]] its characteristic of convexity ''ε''<sub>0</sub> is equal to&nbsp;0, ''i.e.'', if and only if {{nowrap|''δ''(''ε'') > 0}} for every&nbsp;{{nowrap|''ε'' > 0}}.\n* The Banach space {{nowrap|(''X'', ǁ&thinsp;&sdot;&thinsp;ǁ)}} is a [[strictly convex space]] (i.e., the boundary of the unit ball ''B'' contains no line segments) if and only if ''δ''(2)&nbsp;=&nbsp;1, ''i.e.'', if only [[antipodal point]]s (of the form ''x'' and ''y''&nbsp;=&nbsp;&minus;''x'') of the unit sphere can have distance equal to&nbsp;2.\n* When ''X'' is uniformly convex, it admits an equivalent norm with power type modulus of convexity.<ref>see {{citation\n | last=Pisier |first=Gilles |authorlink=Gilles Pisier\n | title= Martingales with values in uniformly convex spaces | journal=Israel J. Math. | volume=20 | year=1975 | issue=3–4 | pages=326–350 | doi = 10.1007/BF02760337 | url=http://www.springerlink.com/content/pwh1126545520581/ | mr=394135}}\n.</ref> Namely, there exists {{nowrap|''q'' &ge; 2}} and a constant&nbsp;{{nowrap|''c'' &gt; 0}} such that\n::<math>\\delta(\\varepsilon) \\ge c \\, \\varepsilon^q, \\quad \\varepsilon \\in [0, 2].</math>\n\n==Modulus of convexity of the <math>L^p</math> spaces==\n\nThe modulus of convexity is known for the L^p spaces.<ref>{{citation\n| last = Hanner\n| first = Olof\n| title = On the uniform convexity of <math>L^p</math> and <math>\\ell^p</math>\n| journal = Arkiv för Mathematik\n| volume = 3\n| year = 1955\n| pages = 239-244\n}}</ref> If <math>1<p\\le2</math>, then it satisfies the following implicit equation:\n\n:<math>\\left(1-\\delta_p(\\varepsilon)+\\frac{\\varepsilon}{2}\\right)^p+\\left(1-\\delta_p(\\varepsilon)-\\frac{\\varepsilon}{2}\\right)^p=2.\n</math>\nKnowing that <math>\\delta_p(\\varepsilon+)=0,</math> one can suppose that <math>\\delta_p(\\varepsilon)=a_0\\varepsilon+a_1\\varepsilon^2+\\cdots</math>. Substituting this into the above, and expanding the left-hand-side as a Taylor series around <math>\\varepsilon=0</math>, one can calculate the <math>a_i</math> coefficients:\n:<math>\\delta_p(\\varepsilon)=\\frac{p-1}{8}\\varepsilon^2+\\frac{1}{384}(3-10p+9p^2-2p^3)\\varepsilon^4+\\cdots.\n</math>\n\nFor <math>2<p<\\infty</math>, one has the explicit expression\n:<math>\\delta_p(\\varepsilon)=1-\\left(1-\\left(\\frac{\\varepsilon}{2}\\right)^p\\right)^{\\frac1p}.\n</math>\nTherefore, <math>\\delta_p(\\varepsilon)=\\frac{1}{p2^p}\\varepsilon^p+\\cdots</math>.\n\n== See also ==\n*[[Uniformly smooth space]]\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{cite book|author=Beauzamy, Bernard|title=Introduction to Banach Spaces and their Geometry|year=1985 |origyear=1982|edition=Second revised|publisher=North-Holland|mr=889253|isbn=0-444-86416-4}}\n*{{citation\n| last = Clarkson\n| first = James\n| title = Uniformly convex spaces\n| journal = Trans. Amer. Math. Soc.\n| volume = 40\n| year = 1936\n| pages = 396&ndash;414\n| doi = 10.2307/1989630\n| issue = 3\n| publisher = American Mathematical Society\n| jstor = 1989630\n}}\n* Fuster, Enrique Llorens. Some moduli and constants related to metric fixed point theory. ''Handbook of metric fixed point theory'', 133-175, Kluwer Acad. Publ., Dordrecht, 2001. {{MR|1904276}}\n* [[Joram Lindenstrauss|Lindenstrauss, Joram]] and Benyamini, Yoav. ''Geometric nonlinear functional analysis'' Colloquium publications, 48. American Mathematical Society.\n*{{citation\n | last1 = Lindenstrauss\n | first1 = Joram | author1-link = Joram Lindenstrauss\n | last2 = Tzafriri | first2 = Lior\n | title = Classical Banach spaces. II. Function spaces\n | series = Ergebnisse der Mathematik und ihrer Grenzgebiete [Results in Mathematics and Related Areas]\n | volume = 97 \n | publisher = Springer-Verlag\n | location = Berlin-New York\n | year = 1979\n | pages = x+243\n | isbn = 3-540-08888-1 \n}}.\n* [[Vitali Milman|Vitali D. Milman]]. Geometric theory of Banach spaces II. Geometry of the unit sphere. ''Uspechi Mat. Nauk,'' vol. 26, no. 6, 73-149, 1971; ''Russian Math. Surveys'', v. 26 6, 80-159.\n\n[[Category:Banach spaces]]\n[[Category:Convex analysis]]"
    },
    {
      "title": "Moreau's theorem",
      "url": "https://en.wikipedia.org/wiki/Moreau%27s_theorem",
      "text": "In [[mathematics]], '''Moreau's theorem''' is a result in [[convex analysis]]. It shows that sufficiently [[well-behaved]] [[convex function]]als on [[Hilbert space]]s are differentiable and the derivative is well-approximated by the so-called [[Yosida approximation]], which is defined in terms of the [[resolvent operator]].\n\n==Statement of the theorem==\nLet ''H'' be a Hilbert space and let ''&phi;''&nbsp;:&nbsp;''H''&nbsp;&rarr;&nbsp;'''R'''&nbsp;&cup;&nbsp;{+&infin;} be a [[proper function|proper]], convex and [[semi-continuity|lower semi-continuous]] [[extended real number line|extended real-valued functional]] on ''H''. Let ''A'' stand for &part;''&phi;'', the [[subderivative]] of ''&phi;''; for ''&alpha;''&nbsp;&gt;&nbsp;0 let ''J''<sub>''&alpha;''</sub> denote the resolvent:\n\n:<math>J_{\\alpha} = (\\mathrm{id} + \\alpha A)^{-1};</math>\n\nand let ''A''<sub>''&alpha;''</sub> denote the '''Yosida approximation''' to ''A'':\n\n:<math>A_{\\alpha} = \\frac1{\\alpha} ( \\mathrm{id} - J_{\\alpha} ).</math>\n\nFor each ''&alpha;''&nbsp;&gt;&nbsp;0 and ''x''&nbsp;&isin;&nbsp;''H'', let\n\n:<math>\\varphi_{\\alpha} (x) = \\inf_{y \\in H} \\frac1{2 \\alpha} \\| y - x \\|^{2} + \\varphi (y).</math>\n\nThen\n\n:<math>\\varphi_{\\alpha} (x) = \\frac{\\alpha}{2} \\| A_{\\alpha} x \\|^{2} + \\varphi (J_{\\alpha} (x))</math>\n\nand ''&phi;''<sub>''&alpha;''</sub> is convex and [[Fréchet derivative|Fréchet differentiable]] with derivative d''&phi;''<sub>''&alpha;''</sub>&nbsp;=&nbsp;''A''<sub>''&alpha;''</sub>. Also, for each ''x''&nbsp;&isin;&nbsp;''H'' (pointwise), ''&phi;''<sub>''&alpha;''</sub>(''x'') converges upwards to ''&phi;''(''x'') as ''&alpha;''&nbsp;&rarr;&nbsp;0.\n\n==References==\n* {{cite book\n| last = Showalter\n| first = Ralph E.\n| title = Monotone operators in Banach space and nonlinear partial differential equations\n| series = Mathematical Surveys and Monographs 49\n| publisher = American Mathematical Society\n| location = Providence, RI\n| year = 1997\n| pages = 162&ndash;163\n| isbn = 0-8218-0500-2\n}} {{MathSciNet|id=1422252}} (Proposition IV.1.8)\n\n[[Category:Convex analysis]]\n[[Category:Theorems in functional analysis]]"
    },
    {
      "title": "Polyconvex function",
      "url": "https://en.wikipedia.org/wiki/Polyconvex_function",
      "text": "In [[mathematics]], the notion of '''polyconvexity''' is a generalization of the notion of [[convex function|convexity]] for [[function (mathematics)|functions]] defined on spaces of [[matrix (mathematics)|matrices]]. Let ''M''<sub>''m''&times;''n''</sub>(''K'') denote the space of all ''m''&nbsp;&times;&nbsp;''n'' matrices over the [[field (algebra)|field]] ''K'', which may be either the [[real number]]s '''R''', or the [[complex number]]s '''C'''. A function ''f''&nbsp;:&nbsp;''M''<sub>''m''&times;''n''</sub>(''K'')&nbsp;&rarr;&nbsp;'''R'''&nbsp;&cup;&nbsp;{&plusmn;&infin;} is said to be '''polyconvex''' if\n\n:<math>A \\mapsto f(A)</math>\n\ncan be written as a convex function of the ''p''&nbsp;&times;&nbsp;''p'' sub[[determinant]]s of ''A'', for 1&nbsp;&le;&nbsp;''p''&nbsp;&le;&nbsp;min{''m'',&nbsp;''n''}.\n\nPolyconvexity is a weaker property than convexity. For example, the function ''f'' given by\n\n:<math>f(A) = \\begin{cases} \\frac1{\\det (A)}, & \\det (A) > 0; \\\\ + \\infty, & \\det (A) \\leq 0; \\end{cases}</math>\n\nis polyconvex but not convex.\n\n==References==\n\n* {{cite book\n|author1=Renardy, Michael  |author2=Rogers, Robert C.\n |lastauthoramp=yes |    title = An introduction to partial differential equations\n|   series = Texts in Applied Mathematics 13\n|  edition = Second\n|publisher = Springer-Verlag\n| location = New York\n|     year = 2004\n|    pages = 353\n|       isbn = 0-387-00444-0\n}} (Definition 10.25)\n\n[[Category:Convex analysis]]\n[[Category:Matrices]]\n[[Category:Types of functions]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Proper convex function",
      "url": "https://en.wikipedia.org/wiki/Proper_convex_function",
      "text": "{{About|the concept in [[convex analysis]]|the concept of properness in [[topology]]|proper map}}\n\nIn [[mathematical analysis]] (in particular [[convex analysis]]) and [[optimization (mathematics)|optimization]], a '''proper convex function''' is a [[convex function]] ''f'' taking values in the [[extended real number line]] such that\n\n:<math>f(x) < +\\infty</math>\n\nfor at least one ''x'' and \n\n:<math>f(x) > -\\infty</math>\n\nfor every ''x''.  That is, a convex function is ''proper'' if its [[effective domain]] is nonempty and it never attains <math>-\\infty</math>.<ref name=\"AB\">{{cite book|last1=Aliprantis|first1=C.D.|last2=Border|first2=K.C.|title=Infinite Dimensional Analysis: A Hitchhiker's Guide|edition=3|publisher=Springer|year=2007|isbn=978-3-540-32696-0|doi=10.1007/3-540-29587-9|page=254}}</ref> Convex functions that are not proper are called ''improper convex functions''.<ref>{{cite book|author=[[Rockafellar, R. Tyrrell]]|title=Convex Analysis|publisher=Princeton University Press|location=Princeton, NJ|year=1997|origyear=1970|isbn=978-0-691-01586-6|page=24}}</ref>\n\nA ''proper concave function'' is any function ''g'' such that <math>f = -g</math> is a proper convex function.\n\n== Properties ==\n\nFor every proper convex function ''f'' on '''R'''<sup>n</sup> there exist some ''b'' in '''R'''<sup>n</sup> and β in '''R''' such that \n\n:<math>f(x) \\ge x \\cdot b - \\beta</math>\n\nfor every ''x''.\n\nThe sum of two proper convex functions is convex, but not necessarily proper.<ref>{{Cite book|title=Convex Optimization|last=Boyd|first=Stephen|publisher=Cambridge University Press|year=2004|isbn=978-0-521-83378-3|location=Cambridge, UK|pages=79}}</ref>  For instance if the sets <math>A \\subset X</math> and <math>B \\subset X</math> are non-empty [[convex set]]s in the [[vector space]] ''X'', then the [[Characteristic function (convex analysis)|characteristic function]]s <math>I_A</math> and <math>I_B</math> are proper convex functions, but if <math>A \\cap B = \\emptyset</math> then <math>I_A + I_B</math> is identically equal to <math>+\\infty</math>.\n\nThe [[infimal convolute|infimal convolution]] of two proper convex functions is convex but not necessarily proper convex.<ref>{{citation|title=Theory of extremal problems|volume=6|series=Studies in Mathematics and its Applications|first1=Aleksandr Davidovich|last1=Ioffe|first2=Vladimir Mikhaĭlovich|last2=Tikhomirov|publisher=North-Holland|year=2009|isbn=9780080875279|page=168|url=https://books.google.com/books?id=iDRVxznSxUsC&pg=PA168}}.</ref>\n\n== References ==\n{{reflist|30em}}\n\n[[Category:Convex analysis]]\n[[Category:Types of functions]]"
    },
    {
      "title": "Recession cone",
      "url": "https://en.wikipedia.org/wiki/Recession_cone",
      "text": "In [[mathematics]], especially [[convex analysis]], the '''recession cone''' of a set <math>A</math> is a [[cone (linear algebra)|cone]] containing all [[vector (mathematics)|vector]]s such that <math>A</math> ''recedes'' in that direction.  That is, the set extends outward in all the directions given by the recession cone.<ref name=\"Rockafellar\">{{cite book|author=[[Rockafellar, R. Tyrrell]]|title=Convex Analysis|publisher=Princeton University Press|location=Princeton, NJ|year=1997|origyear=1970|isbn=978-0-691-01586-6|pages=60–76}}</ref>\n\n== Mathematical definition ==\nGiven a nonempty set <math>A \\subset X</math> for some [[vector space]] <math>X</math>, then the recession cone <math>\\operatorname{recc}(A)</math> is given by\n:<math>\\operatorname{recc}(A) = \\{y \\in X: \\forall x \\in A, \\forall \\lambda \\geq 0: x + \\lambda y \\in A\\}.</math><ref>{{cite book |last1=Borwein |first1=Jonathan |last2=Lewis |first2=Adrian |title=Convex Analysis and Nonlinear Optimization: Theory and Examples| edition=2 |year=2006 |publisher=Springer |isbn=978-0-387-29570-1}}</ref>\n\nIf <math>A</math> is additionally a [[convex set]] then the recession cone can equivalently be defined by\n:<math>\\operatorname{recc}(A) = \\{y \\in X: \\forall x \\in A: x + y \\in A\\}.</math><ref name=\"Zalinescu\">{{cite book |last=Zălinescu |first=Constantin |title=Convex analysis in general vector spaces |publisher=World Scientific Publishing&nbsp;Co.,&nbsp;Inc. |isbn=981-238-067-1 |mr=1921556 |issue=J |year=2002 |location=River Edge, NJ |pages=6–7}}</ref>\n\nIf <math>A</math> is a nonempty [[closed set|closed]] convex set then the recession cone can equivalently be defined as\n:<math>\\operatorname{recc}(A) = \\bigcap_{t > 0} t(A - a)</math> for any choice of <math>a \\in A.</math><ref name=\"Zalinescu\"/>\n\n== Properties ==\n* If <math>A</math> is a nonempty set then <math>0 \\in \\operatorname{recc}(A)</math>.\n* If <math>A</math> is a nonempty convex set then <math>\\operatorname{recc}(A)</math> is a [[convex cone]].<ref name=\"Zalinescu\"/>\n* If <math>A</math> is a nonempty closed convex subset of a finite-dimensional [[Hausdorff space]] (e.g. <math>\\mathbb{R}^d</math>), then <math>\\operatorname{recc}(A) = \\{0\\}</math> if and only if <math>A</math> is bounded.<ref name=\"Rockafellar\"/><ref name=\"Zalinescu\"/>\n* If <math>A</math> is a nonempty set then <math>A + \\operatorname{recc}(A) = A</math> where the sum denotes [[Minkowski addition]].\n\n== Relation to asymptotic cone ==\nThe [[asymptotic cone]] for <math>C \\subseteq X</math> is defined by\n: <math>C_{\\infty} = \\{x \\in X: \\exists (t_i)_{i \\in I} \\subset (0,\\infty), \\exists (x_i)_{i \\in I} \\subset C: t_i \\to 0, t_i x_i \\to x\\}.</math><ref name=\"Border\">{{cite web|url=http://www.hss.caltech.edu/~kcb/Notes/AsymptoticCones.pdf|format=pdf|title=Sums of sets, etc.|author=Kim C. Border|accessdate=March 7, 2012}}</ref><ref name=\"Asymptotic\">{{cite book|title=Asymptotic cones and functions in optimization and variational inequalities|author=Alfred Auslender|author2=M. Teboulle|publisher=Springer|year=2003|isbn=978-0-387-95520-9|pages=25–80}}</ref>\n\nBy the definition it can easily be shown that <math>\\operatorname{recc}(C) \\subseteq C_\\infty.</math><ref name=\"Border\"/>\n\nIn a finite-dimensional space, then it can be shown that <math>C_{\\infty} = \\operatorname{recc}(C)</math> if <math>C</math> is nonempty, closed and convex.<ref name=\"Asymptotic\"/>  In infinite-dimensional spaces, then the relation between asymptotic cones and recession cones is more complicated, with properties for their equivalence summarized in.<ref>{{cite journal|title=Recession cones and asymptotically compact sets|last=Zălinescu |first=Constantin|journal=Journal of Optimization Theory and Applications|publisher=Springer Netherlands|issn=0022-3239|pages=209–220|volume=77|issue=1|year=1993|doi=10.1007/bf00940787}}</ref>\n\n== Sum of closed sets ==\n* [[Dieudonné's theorem]]: Let nonempty closed convex sets <math>A,B \\subset X</math> a [[locally convex space]], if either <math>A</math> or <math>B</math> is [[locally compact]] and <math>\\operatorname{recc}(A) \\cap \\operatorname{recc}(B)</math> is a [[linear subspace]], then <math>A - B</math> is closed.<ref>{{cite journal|title=Sur la séparation des ensembles convexes|author=J. Dieudonné|year=1966|journal=<abbr title=\"Mathematische Annalen\">Math. Ann.</abbr>|volume=163}}</ref><ref name=\"Zalinescu\"/>\n*  Let nonempty closed convex sets <math>A,B \\subset \\mathbb{R}^d</math> such that for any <math>y \\in \\operatorname{recc}(A) \\backslash \\{0\\}</math> then <math>-y \\not\\in \\operatorname{recc}(B)</math>, then <math>A + B</math> is closed.<ref name=\"Rockafellar\"/><ref name=\"Border\"/>\n\n== See also ==\n* [[Barrier cone]]\n\n== References ==\n{{Reflist}}\n\n[[Category:Convex analysis]]"
    },
    {
      "title": "Shephard's problem",
      "url": "https://en.wikipedia.org/wiki/Shephard%27s_problem",
      "text": "In [[mathematics]], '''Shephard's problem''', is the following geometrical question asked by {{harvs|txt|first=Geoffrey Colin |last=Shephard|authorlink=Geoffrey Colin Shephard|year=1964}}: if ''K'' and ''L'' are centrally symmetric [[convex body|convex bodies]] in ''n''-[[dimension]]al [[Euclidean space]] such that whenever ''K'' and ''L'' are [[projection (mathematics)|projected]] onto a [[hyperplane]], the [[volume]] of the projection of ''K'' is smaller than the volume of the projection of ''L'', then does it follow that the volume of ''K'' is smaller than that of ''L''?\n\nIn this case, \"centrally symmetric\" means that the [[Reflection symmetry|reflection]] of ''K'' in the origin, ''&minus;K'', is a translate of ''K'', and similarly for ''L''. If {{pi}}<sub>''k''</sub>&nbsp;:&nbsp;'''R'''<sup>''n''</sup>&nbsp;→&nbsp;Π<sub>''k''</sub> is a [[projection (mathematics)|projection]] of '''R'''<sup>''n''</sup> onto some ''k''-dimensional [[hyperplane]] Π<sub>''k''</sub> (not necessarily a coordinate hyperplane) and ''V''<sub>''k''</sub> denotes ''k''-dimensional volume, Shephard's problem is to determine the truth or falsity of the implication\n\n:<math>V_{k} (\\pi_{k} (K)) \\leq V_{k} (\\pi_{k} (L)) \\mbox{ for all } 1 \\leq k < n \\implies V_{n} (K) \\leq V_{n} (L).</math>\n\n''V''<sub>''k''</sub>({{pi}}<sub>''k''</sub>(''K'')) is sometimes known as the '''brightness''' of ''K'' and the function ''V''<sub>''k''</sub>&nbsp;<small>o</small>&nbsp;{{pi}}<sub>''k''</sub> as a (''k''-dimensional) '''brightness function'''.\n\nIn dimensions ''n''&nbsp;=&nbsp;1 and 2, the answer to Shephard's problem is \"yes\". In 1967, however, Petty and Schneider showed that the answer is \"no\" for every ''n''&nbsp;≥&nbsp;3. The solution of Shephard's problem requires [[Minkowski's first inequality for convex bodies]] and the notion of [[projection body| projection bodies]] of convex bodies.\n\n==See also==\n\n*[[Busemann–Petty problem]]\n\n==References==\n\n* {{cite journal\n| last=Gardner \n| first=Richard J. \n| title=The Brunn-Minkowski inequality \n| journal=Bull. Amer. Math. Soc. (N.S.) \n| volume=39 \n| issue=3 \n| year=2002 \n| pages=355&ndash;405 (electronic) \n| doi=10.1090/S0273-0979-02-00941-2 \n}}\n* {{cite journal\n|     last = Petty\n|    first = C.M.\n|    title = Projection bodies\n|  journal = Proc. Colloquium on Convexity (Copenhagen, 1965)\n|    pages = 234&ndash;241\n|     year = 1967\n}}\n* {{cite journal\n|     last = Schneider\n|    first = Rolf\n| authorlink = Rolf Schneider\n|    title = Zur einem Problem von Shephard über die Projektionen konvexer Körper\n|  journal = Math. Z.\n|   volume = 101\n|     year = 1967\n|    pages = 71&ndash;82\n| language = German\n|    doi = 10.1007/BF01135693\n}}\n*{{Citation | last1=Shephard | first1=G. C. | title=Shadow systems of convex sets | doi=10.1007/BF02759738 |mr=0179686 | year=1964 | journal=Israel Journal of Mathematics | issn=0021-2172 | volume=2 | issue=4 | pages=229–236}}\n\n[[Category:Convex geometry]]\n[[Category:Convex analysis]]"
    },
    {
      "title": "Strictly convex space",
      "url": "https://en.wikipedia.org/wiki/Strictly_convex_space",
      "text": "[[Image:Vector norms.svg|frame|right|The unit ball in the middle figure is strictly convex, while the other two balls are not (they contain a line segment as part of their boundary).]]\nIn [[mathematics]], a '''strictly convex space''' is a [[normed vector space]] (''X'',&nbsp;||&nbsp;||) for which the closed unit [[Ball (mathematics)|ball]] is a strictly [[convex set]]. Put another way, a strictly convex space is one for which, given any two distinct points ''x'' and ''y'' on the [[unit sphere]] ∂''B'' (i.e. the [[Boundary (topology)|boundary]] of the unit ball ''B'' of ''X''), the segment joining ''x'' and ''y'' meets ∂''B'' ''only'' at ''x'' and ''y''.  Strict convexity is somewhere between an [[inner product space]] (all inner product spaces being strictly convex) and a general [[normed space]] in terms of structure. It also guarantees the uniqueness of a best approximation to an element in ''X'' (strictly convex) out of a convex subspace ''Y'', provided that such an approximation exists.\n\nIf the normed space ''X'' is [[Banach space|complete]] and satisfies the slightly stronger property of being [[Uniformly convex space|uniformly convex]] (which implies strict convexity), then it is also reflexive by [[Milman-Pettis theorem]].\n\n==Properties==\n\nThe following properties are equivalent to strict convexity.\n* A [[normed vector space]] (''X'',&nbsp;||&nbsp;||) is strictly convex if and only if ''x''&nbsp;≠&nbsp;''y'' and ||&nbsp;''x''&nbsp;||&nbsp;=&nbsp;||&nbsp;''y''&nbsp;||&nbsp;=&nbsp;1 together imply that ||&nbsp;''x''&nbsp;+&nbsp;''y''&nbsp;||&nbsp;<&nbsp;2.\n* A [[normed vector space]] (''X'',&nbsp;||&nbsp;||) is strictly convex if and only if ''x''&nbsp;≠&nbsp;''y'' and ||&nbsp;''x''&nbsp;||&nbsp;=&nbsp;||&nbsp;''y''&nbsp;||&nbsp;=&nbsp;1 together imply that ||&nbsp;''αx''&nbsp;+&nbsp;(1&nbsp;&minus;&nbsp;''α'')''y''&nbsp;||&nbsp;&lt;&nbsp;1 for all 0&nbsp;&lt;&nbsp;''α''&nbsp;&lt;&nbsp;1.\n* A [[normed vector space]] (''X'',&nbsp;||&nbsp;||) is strictly convex if and only if  ''x''&nbsp;≠&nbsp;''0'' and  ''y''&nbsp;≠&nbsp;''0'' and ||&nbsp;''x''&nbsp;+&nbsp;''y''&nbsp;||&nbsp;=&nbsp;||&nbsp;''x''&nbsp;||&nbsp;+&nbsp;||&nbsp;''y''&nbsp;|| together imply that ''x'' = ''cy'' for some constant ''c&nbsp;>&nbsp;0'';\n* A [[normed vector space]] (''X'',&nbsp;||&nbsp;||) is strictly convex [[if and only if]] the [[modulus of convexity]] ''δ'' for (''X'',&nbsp;||&nbsp;||) satisfies ''δ''(2)&nbsp;=&nbsp;1.\n\n==See also==\n\n* [[Uniformly convex space]]\n* [[Modulus and characteristic of convexity]]\n\n==References==\n\n* {{cite journal\n| last = Goebel\n| first = Kazimierz\n| title = Convexity of balls and fixed-point theorems for mappings with nonexpansive square\n| journal = Compositio Mathematica\n| volume = 22\n| issue = 3\n| year = 1970\n| pages = 269&ndash;274\n}}\n\n{{Functional analysis}}\n\n[[Category:Convex analysis]]\n[[Category:Normed spaces]]"
    },
    {
      "title": "Uniformly convex space",
      "url": "https://en.wikipedia.org/wiki/Uniformly_convex_space",
      "text": "In [[mathematics]], '''uniformly convex spaces''' (or '''uniformly rotund spaces''') are common examples of  [[reflexive space|reflexive]] [[Banach space]]s. The concept of uniform convexity was first introduced by [[James A. Clarkson]] in 1936.\n\n== Definition ==\nA '''uniformly convex space''' is a [[normed vector space]] so that, for every <math>0<\\epsilon \\leq 2</math> there is some <math>\\delta>0</math> so that for any two vectors with <math>\\|x\\| = 1</math> and <math>\\|y\\| = 1,</math> the condition\n\n:<math>\\|x-y\\|\\geq\\varepsilon</math>\n\nimplies that:\n\n:<math>\\left\\|\\frac{x+y}{2}\\right\\|\\leq 1-\\delta.</math>\n\nIntuitively, the center of a line segment inside the [[unit ball]] must lie deep inside the unit ball unless the segment is short.\n\n== Properties ==\n* The [[unit sphere]] can be replaced with the closed unit [[Ball (mathematics)|ball]] in the definition. Namely, a [[normed vector space]] <math> X </math> is uniformly convex [[if and only if]] for every <math> 0<\\epsilon\\le 2 </math> there is some <math> \\delta>0 </math> so that, for any two vectors <math> x </math> and <math> y </math> in the closed unit ball (i.e. <math> \\|x\\| \\le 1 </math> and <math> \\|y\\| \\le 1 </math>) with <math> \\|x-y\\| \\ge \\varepsilon </math>, one has <math> \\left\\|{\\frac{x+y}{2}}\\right\\| \\le 1-\\delta </math> (note that, given <math> \\epsilon </math>, the corresponding value of <math> \\delta </math> could be smaller than the one provided by the original weaker definition).\n{{Collapsed top|Proof}}\nThe \"if\" part is trivial. Conversely, assume now that <math> X </math> is uniformly convex and that <math> x,y </math> are as in the statement, for some fixed <math> 0<\\epsilon\\le 2 </math>. Let <math> \\delta_1\\le 1 </math> be the value of <math> \\delta </math> corresponding to <math> \\frac{\\epsilon}{3} </math> in the definition of uniform convexity. We will show that <math> \\left\\|\\frac{x+y}{2}\\right\\|\\le 1-\\delta </math>, with <math> \\delta=\\min\\left\\{\\frac{\\epsilon}{6},\\frac{\\delta_1}{3}\\right\\} </math>.\n\nIf <math> \\|x\\|\\le 1-2\\delta </math> then <math> \\left\\|\\frac{x+y}{2}\\right\\|\\le\\frac{1}{2}(1-2\\delta)+\\frac{1}{2}=1-\\delta </math> and the claim is proved. A similar argument applies for the case <math> \\|y\\|\\le 1-2\\delta </math>, so we can assume that <math> 1-2\\delta<\\|x\\|,\\|y\\|\\le 1 </math>. In this case, since <math> \\delta\\le\\frac{1}{3} </math>, both vectors are nonzero, so we can let <math> x'=\\frac{x}{\\|x\\|} </math> and <math> y'=\\frac{y}{\\|y\\|} </math>. We have <math> \\|x'-x\\|=1-\\|x\\|\\le 2\\delta</math>  and similarly <math> \\|y'-y\\|\\le 2\\delta </math>, so <math> x' </math> and <math> y' </math> belong to the unit sphere and have distance <math> \\|x'-y'\\|\\ge\\|x-y\\|-4\\delta\\ge\\epsilon-\\frac{4\\epsilon}{6}=\\frac{\\epsilon}{3} </math>. Hence, by our choice of <math> \\delta_1 </math>, we have <math> \\left\\|\\frac{x'+y'}{2}\\right\\|\\le 1-\\delta_1 </math>. It follows that <math> \\left\\|\\frac{x+y}{2}\\right\\|\\le\\left\\|\\frac{x'+y'}{2}\\right\\|+\\frac{\\|x'-x\\|+\\|y'-y\\|}{2}\\le 1-\\delta_1+2\\delta\\le 1-\\frac{\\delta_1}{3}\\le 1-\\delta </math> and the claim is proved.\n{{Collapsed bottom}}\n* The [[Milman–Pettis theorem]] states that every uniformly convex [[Banach space]] is [[reflexive space|reflexive]], while the converse is not true.\n* Every uniformly convex [[Banach space]] is a Radon-Riesz space, that is, if <math> \\{f_n\\}_{n=1}^{\\infty} </math> is a sequence in a uniformly convex Banach space which converges weakly to <math> f </math> and satisfies <math> \\|f_n\\| \\to \\|f\\|,</math> then <math> f_n </math> converges strongly to <math> f </math>, that is, <math> \\|f_n - f\\| \\to 0 </math>.\n* A [[Banach space]] <math> X </math> is uniformly convex if and only if its dual <math> X^* </math> is [[uniformly smooth space|uniformly smooth]].\n* Every uniformly convex space is [[strictly convex space|strictly convex]]. Intuitively, the strict convexity means a stronger [[triangle inequality]]  <math> \\|x+y\\| < \\|x\\|+\\|y\\|</math> whenever <math>x,y</math> are linearly independent, while the uniform convexity requires this inequality to be true uniformly.\n\n== Examples ==\n\n* Every Hilbert space is uniformly convex.\n* Every closed subspace of a uniformly convex Banach space is uniformly convex.\n* [[Hanner's inequalities]] imply that [[lp space|L<sup>''p''</sup> spaces]] <math>(1<p<\\infty)</math> are uniformly convex.\n* Conversely, <math>L^\\infty</math> is not uniformly convex.\n\n==See also==\n\n* [[Modulus and characteristic of convexity]]\n* [[Convex function#Uniformly convex functions|Uniformly convex function]]\n* [[Uniformly smooth space]]\n\n== References ==\n* {{Cite journal|first=J. A.|last=Clarkson|title=Uniformly convex spaces|journal=Trans. Amer. Math. Soc.|volume=40|year=1936|pages=396–414|doi=10.2307/1989630|jstor=1989630|issue=3|publisher=American Mathematical Society|postscript=<!--None-->}}.\n* {{Cite journal|first=O.|last=Hanner|authorlink=Olof Hanner|title=On the uniform convexity of <math>L^p</math> and  <math>l^p</math>|journal=Ark. Mat.|volume=3|year=1956|pages=239–244|postscript=<!--None-->|doi=10.1007/BF02589410}}.\n*{{cite book\n|author=Beauzamy, Bernard\n|title=Introduction to Banach Spaces and their Geometry\n|year=1985 |origyear=1982\n|edition=Second revised\n|publisher=North-Holland\n|isbn=0-444-86416-4\n}}\n* {{cite journal\n|doi=10.1007/BF02762802\n|author=[[Per Enflo]]\n|title=Banach spaces which can be given an equivalent uniformly convex norm\n|journal=Israel Journal of Mathematics\n|volume=13\n|issue=3–4\n|year=1972\n|pages=281–288}}\n* [[Joram Lindenstrauss|Lindenstrauss, Joram]] and Benyamini, Yoav. ''Geometric nonlinear functional analysis'' Colloquium publications, 48. American Mathematical Society.\n\n[[Category:Convex analysis]]\n[[Category:Banach spaces]]"
    },
    {
      "title": "Uniformly smooth space",
      "url": "https://en.wikipedia.org/wiki/Uniformly_smooth_space",
      "text": "In [[mathematics]], a '''uniformly smooth space''' is a [[normed vector space]] <math>X</math> satisfying the property that for every <math>\\epsilon>0</math> there exists <math>\\delta>0</math> such that if <math>x,y\\in X</math> with <math>\\|x\\|=1</math> and <math>\\|y\\|\\leq\\delta</math> then\n\n:<math>\\|x+y\\|+\\|x-y\\| \\le 2 + \\epsilon\\|y\\|.</math>\n\nThe '''modulus of smoothness''' of a normed space ''X'' is the function &rho;<sub>''X''</sub> defined for every {{nowrap|''t'' &gt; 0}} by the formula<ref>see Definition&nbsp;1.e.1, p.&nbsp;59 in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref>\n\n:<math> \\rho_X(t) = \\sup \\Bigl\\{ \\frac{\\|x + y \\| + \\|x - y\\|}{2} - 1 \\,:\\, \\|x\\| = 1, \\; \\|y\\| = t \\Bigr\\}. </math>\n\nThe triangle inequality yields that {{nowrap|&rho;<sub>''X''</sub>(''t''&thinsp;) &le; ''t''}}.  The normed space ''X'' is uniformly smooth if and only if {{nowrap|&rho;<sub>''X''</sub>(''t''&thinsp;) / ''t''}} tends to 0 as ''t'' tends to&nbsp;0.\n\n==Properties==\n* Every uniformly smooth [[Banach space]] is [[reflexive space|reflexive]].<ref>Proposition 1.e.3, p.&nbsp;61 in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref>\n* A Banach space <math>X</math> is uniformly smooth if and only if its [[Dual space#Continuous dual space|continuous dual]] <math>X^*</math> is [[uniformly convex space|uniformly convex]] (and vice versa, via reflexivity).<ref>Proposition 1.e.2, p.&nbsp;61 in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref> The moduli of convexity and smoothness are linked by\n::<math>\\rho_{X^*}(t) = \\sup \\{ t \\varepsilon / 2 - \\delta_X(\\varepsilon) : \\varepsilon \\in [0, 2]\\}, \\quad t \\ge 0,</math>\n:and the maximal convex function majorated by the modulus of convexity &delta;<sub>''X''</sub> is given by<ref>Proposition 1.e.6, p.&nbsp;65 in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref> \n::<math>\\tilde \\delta_X(\\varepsilon) = \\sup \\{ \\varepsilon t / 2 - \\rho_{X^*}(t) : t \\ge 0\\}.</math>\n:Furthermore,<ref>Lemma 1.e.7 and 1.e.8, p.&nbsp;66 in {{harvtxt|Lindenstrauss|Tzafriri|1979}}.</ref>\n::<math>\\delta_X(\\varepsilon / 2) \\le \\tilde \\delta_X(\\varepsilon) \\le \\delta_X(\\varepsilon), \\quad \\varepsilon \\in [0, 2].</math>\n* A Banach space is uniformly smooth if and only if the limit\n\n::<math>\\lim_{t\\to 0}\\frac{\\|x+ty\\|-\\|x\\|}{t}</math>\n\n:exists uniformly for all <math>x, y\\in S_X</math> (where <math>S_X</math> denotes the [[unit sphere#Unit balls in normed vector spaces|unit sphere]] of <math>X</math>).\n*When {{nowrap| 1 &lt; ''p'' &lt; &infin;}}, the [[Lp space|''L''<sup>''p''</sup>-spaces]] are uniformly smooth (and uniformly convex).\n\n[[Per Enflo|Enflo]] proved<ref>Enflo, Per (1973), \"Banach spaces which can be given an equivalent uniformly convex norm\", Israel J. Math. '''13''':281&ndash;288.</ref> \nthat the class of Banach spaces that admit an equivalent uniformly convex norm coincides with the class of [[Reflexive space#Super-reflexive space|super-reflexive]] Banach spaces, introduced by Robert C. James.<ref>James, Robert C. (1972), \"Super-reflexive Banach spaces\", Can. J. Math. '''24''':896&ndash;904.</ref>  \nAs a space is super-reflexive if and only if its dual is super-reflexive, it follows that the class of Banach spaces that admit an equivalent uniformly convex norm coincides with the class of spaces that admit an equivalent uniformly smooth norm.  The [[Gilles Pisier|Pisier]] renorming theorem<ref>Pisier, Gilles (1975),\n\"Martingales with values in uniformly convex spaces\",\nIsrael J. Math. '''20''':326&ndash;350.</ref> \nstates that a super-reflexive space&nbsp;''X'' admits an equivalent uniformly smooth norm for which the modulus of smoothness &rho;<sub>''X''</sub> satisfies, for some constant&nbsp;''C'' and some&nbsp;{{nowrap|''p'' &gt; 1}}\n\n:<math> \\rho_X(t) \\le C \\, t^p, \\quad t > 0.</math>\n\nIt follows that every super-reflexive space ''Y'' admits an equivalent uniformly convex norm for which the [[Modulus and characteristic of convexity|modulus of convexity]] satisfies, for some constant&nbsp;{{nowrap|''c'' &gt; 0}} and some positive real ''q''\n\n:<math> \\delta_Y(\\varepsilon) \\ge c \\, \\varepsilon^q, \\quad \\varepsilon \\in [0, 2].</math>\n\nIf a normed space admits two equivalent norms, one uniformly convex and one uniformly smooth, the Asplund averaging technique<ref>Asplund, Edgar (1967), \"Averaged norms\", Israel J. Math. '''5''':227&ndash;233.</ref> \nproduces another equivalent norm that is both uniformly convex and uniformly smooth.\n\n==See also==\n\n* [[Uniformly convex space]]\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n*{{cite book\n | last = Diestel\n | first = Joseph\n | title = Sequences and series in Banach spaces\n | series = Graduate Texts in Mathematics \n | volume = 92 \n | publisher = Springer-Verlag \n | location = New York \n | year = 1984 \n | pages = xii+261\n | isbn = 0-387-90859-5\n}}\n*{{cite book\n|author=Itō, Kiyoshi\n|title=Encyclopedic Dictionary of Mathematics, Volume 1\n|year=1993\n|publisher=MIT Press\n|isbn=0-262-59020-4\n}}  [https://books.google.com/books?id=WHjO9K6xEm4C]\n*{{citation\n | last1 = Lindenstrauss\n | first1 = Joram | author1-link = Joram Lindenstrauss\n | last2 = Tzafriri | first2 = Lior\n | title = Classical Banach spaces. II. Function spaces\n | series = Ergebnisse der Mathematik und ihrer Grenzgebiete [Results in Mathematics and Related Areas]\n | volume = 97 \n | publisher = Springer-Verlag\n | location = Berlin-New York\n | year = 1979\n | pages = x+243\n | isbn = 3-540-08888-1 \n}}.\n\n[[Category:Convex analysis]]\n[[Category:Banach spaces]]"
    },
    {
      "title": "Generalizations of the derivative",
      "url": "https://en.wikipedia.org/wiki/Generalizations_of_the_derivative",
      "text": "{{about|the term as used in mathematics|other uses|derivative (disambiguation)}}\n{{Calculus |Differential}}\n{{cleanup|reason=too much bold; see [[WP:MOSBOLD]]|date=April 2015}}\nIn [[mathematics]], the [[derivative]] is a fundamental construction of [[differential calculus]] and admits many possible generalizations within the fields of [[mathematical analysis]], [[combinatorics]], [[algebra]], and [[geometry]].\n\n== Derivatives in analysis ==\nIn real, complex, and functional analysis, derivatives are generalized to functions of several real or complex variables and functions between [[topological vector spaces]]. An important case is the [[functional derivative|variational derivative]] in the [[calculus of variations]]. Repeated application of differentiation leads to derivatives of higher order and differential operators. \n\n=== Multivariable calculus ===\n{{main|Fréchet derivative}}\nThe derivative is often met for the first time as an operation on a single real function of a single real variable.  One of the simplest settings for generalizations is to vector valued functions of several variables (most often the domain forms a vector space as well).  This is the field of [[multivariable calculus]].\n\nIn one-variable calculus, we say that a function <math>f: \\R \\to \\R</math> is differentiable at a point ''x'' if the limit\n:<math>\\lim_{h \\to 0}\\frac{f(x+h) - f(x)}{h}</math>\nexists. Its value is then the derivative ƒ'(''x'').  A function is differentiable on an [[Interval (mathematics)|interval]] if it is differentiable at every point within the interval. Since the line <math>L(z) = f'(x)z - f'(x)x + f(x)</math> is tangent to the original function at the point <math>(x, f(x)),</math> the derivative can be seen as a way to find the ''best linear approximation'' of a function. If one ignores the constant term, setting <math>L(z) = f'(x)z</math>, ''L''(''z'') becomes an actual [[linear operator]] on '''R''' considered as a vector space over itself.\n\nThis motivates the following generalization to functions mapping '''R'''<sup>''m''</sup> to '''R'''<sup>''n''</sup>: ƒ is differentiable at ''x'' if there exists a [[linear operator]] ''A''(''x'') (depending on ''x'') such that\n:<math>\\lim_{\\|h\\| \\to 0}\\frac{\\|f(x+h) - f(x) - A(x)h\\|}{\\|h\\|} = 0.</math>\nAlthough this definition is perhaps not as explicit as the above, if such an operator exists, then it is unique, and in the one-dimensional case coincides with the original definition. (In this case the derivative is represented by a 1-by-1 matrix consisting of the sole entry ''f'''(''x'').) Note that, in general, we concern ourselves mostly with functions being differentiable in some open [[neighbourhood (mathematics)|neighbourhood]]  of <math>x</math>  rather than at individual points, as not doing so tends to lead to many [[Pathological (mathematics)|pathological]] [[counterexamples]].\n\nAn ''n'' by ''m'' [[matrix (mathematics)|matrix]], of the [[linear operator]] ''A''(''x'') is known as [[Jacobian matrix and determinant|Jacobian]] matrix J<sub>''x''</sub>(ƒ) of the mapping ƒ at point ''x''. Each entry of this matrix represents a [[partial derivative]], specifying the rate of change of one range coordinate with respect to a change in a domain coordinate. Of course, the Jacobian\nmatrix of the composition ''g<sub>°</sub>f'' is a product of corresponding Jacobian matrices:    \nJ<sub>''x''</sub>(''g<sub>°</sub>f'') =J<sub>ƒ(''x'')</sub>(''g'')J<sub>''x''</sub>(ƒ). This is a higher-dimensional statement of the [[chain rule]].\n\nFor real valued functions from '''R'''<sup>''n''</sup> to '''R''' ([[scalar field]]s), the total derivative can be interpreted as a [[vector field]] called the [[gradient]]. An intuitive interpretation of the gradient is that it points \"up\": in other words, it points in the direction of fastest increase of the function.  It can be used to calculate [[directional derivative]]s of [[Scalar (mathematics)|scalar]] functions or normal directions.\n\nSeveral linear combinations of partial derivatives are especially useful in the context of differential equations defined by a vector valued function '''R'''<sup>''n''</sup> to '''R'''<sup>''n''</sup>. The [[divergence]] gives a measure of how much \"source\" or \"sink\" near a point there is.  It can be used to calculate [[flux]] by [[divergence theorem]]. The [[curl (mathematics)|curl]] measures how much \"[[rotation]]\" a vector field has near a point.\n\nFor [[vector-valued functions]] from '''R''' to '''R'''<sup>''n''</sup> (i.e., [[parametric curve]]s), one can take the derivative of each component separately. The resulting derivative is another vector valued function. This is useful, for example, if the vector-valued function is the position vector of a particle through time, then the derivative is the velocity vector of the particle through time.\n\nThe [[convective derivative]] takes into account changes due to time dependence and motion through space along vector field.\n\n=== Convex analysis ===\n\nThe [[subderivative]] and [[subgradient]] are generalizations of the derivative to [[convex function]]s.\n\n=== Higher-order derivatives and differential operators ===\nOne can iterate the differentiation process, that is, apply derivatives more than once, obtaining derivatives of second and higher order. A more sophisticated idea is to combine several derivatives, possibly of different orders, in one algebraic expression, a [[differential operator]]. This is especially useful in considering ordinary [[linear differential equation]]s with constant coefficients. For example, if ''f''(''x'') is a twice differentiable function of one variable, the differential equation\n\n: <math>f''+2f'-3f=4x-1\\,</math>\n\nmay be rewritten in the form \n\n: <math>L(f)=4x-1,\\,</math> &ensp;&ensp; where &ensp;&ensp; <math> L=\\frac{d^2}{dx^2}+2\\frac{d}{dx}-3</math>\n\nis a ''second order linear constant coefficient differential operator'' acting on functions of ''x''. The key idea here is that we consider a particular [[linear combination]] of zeroth, first and second order derivatives \"all at once\". This allows us to think of the set of solutions of this differential equation as a \"generalized antiderivative\" of its right hand side 4''x''&nbsp;&minus;&nbsp;1, by analogy with ordinary [[Integral|integration]], and formally write \n\n: <math>f(x)=L^{-1}(4x-1).\\, </math>\n\nHigher derivatives can also be defined for functions of several variables, studied in [[multivariable calculus]]. In this case, instead of repeatedly applying the derivative, one repeatedly applies [[partial derivative]]s with respect to different variables. For example, the second order partial derivatives of a scalar function of ''n'' variables can be organized into an ''n'' by ''n'' matrix, the [[Hessian matrix]].  One of the subtle points is that the higher derivatives are not intrinsically defined, and depend on the choice of the coordinates in a complicated fashion (in particular, the Hessian matrix of a function is not a [[tensor]]). Nevertheless, higher derivatives have important applications to analysis of [[maxima and minima|local extrema]] of a function at its [[critical point (mathematics)|critical points]]. For an advanced application of this analysis to topology of [[manifold]]s, see  [[Morse theory]].\n\nAs in the case of functions of one variable, we can combine first and higher order partial derivatives to arrive at a notion of a [[partial differential operator]]. Some of these operators are so important that they have their own names: \n\n*The [[Laplace operator]] or '''Laplacian''' on '''R'''<sup>3</sup> is a second-order partial differential operator ''Δ'' given by the  [[divergence]] of the [[gradient]] of a scalar function of three variables, or explicitly as\n\n:: <math> \\Delta=\\frac{\\partial^2}{\\partial x^2}+\\frac{\\partial^2}{\\partial y^2}+\\frac{\\partial^2}{\\partial z^2}. </math>\nAnalogous operators can be defined for functions of any number of variables.\n\n*The [[d'Alembertian]] or '''wave operator''' is similar to the Laplacian, but acts on functions of four variables. Its definition uses the indefinite [[metric tensor]] of [[Minkowski space]], instead of the [[Euclidean space|Euclidean]] [[dot product]] of '''R'''<sup>''3''</sup>:\n\n:: <math> \\square=\\frac{\\partial^2}{\\partial x^2}+\\frac{\\partial^2}{\\partial y^2}+\\frac{\\partial^2}{\\partial z^2}-\\frac{1}{c^2}\\frac{\\partial^2}{\\partial t^2}. </math>\n\n=== Analysis on fractals ===\nLaplacians and differential equations can be defined on [[analysis on fractals|fractals]].\n\n=== Fractional derivatives ===\nIn addition to ''n''-th derivatives for any natural number ''n'', there are various ways to define derivatives of fractional or negative orders, which are studied in [[fractional calculus]].  The -1 order derivative corresponds to the integral, whence the term [[differintegral]].\n\n=== Complex analysis ===\n\nIn [[complex analysis]], the central objects of study are [[holomorphic function]]s, which are complex-valued functions on the [[complex numbers]] satisfying a [[Fréchet derivative|suitably extended definition of differentiability]].\n\nThe [[Schwarzian derivative]] describes how a complex function is approximated by a [[fractional-linear map]], in much the same way that a normal derivative describes how a function is approximated by a linear map.\n\nThe [[Wirtinger derivatives]] are a set of differential operators that permit the construction of a differential calculus for complex functions that is entirely analogous to the ordinary differential calculus for functions of real variables.\n\n=== Quaternionic analysis ===\n\nIn [[quaternionic analysis]], derivatives can be defined in a similar way to real and complex functions. Being the [[Quaternion|quaternions]] <math>\\mathbb{H}</math> non-commutative the limit of the difference quotient yield two different derivatives. Left derivative\n\n:<math>\\lim_{h\\to0}[h^{-1}(f(a+h)-f(a))]</math>\n\nand right derivative\n\n:<math>\\lim_{h\\to0}[(f(a+h)-f(a))h^{-1}].</math>\n\nThe existence of these limits are very restrictive conditions. For example, if <math>f:\\mathbb{H}\\to\\mathbb{H}</math> has left-derivatives at every point on an open connected set <math>U\\subset\\mathbb{H}</math>, then <math>f(q)=a+qb</math> for <math>a,b\\in\\mathbb{H}</math>.\n\n=== Functional analysis ===\n\nIn [[functional analysis]], the [[functional derivative]] defines the derivative with respect to a function of a functional on a space of functions.  This is an extension of the directional derivative to an infinite [[dimension]]al vector space.  \n\nThe [[Fréchet derivative]] allows the extension of the directional derivative to a general [[Banach space]].  The [[Gateaux derivative]] extends the concept to [[locally convex]] [[topological vector space]]s.  Fréchet differentiability is a strictly stronger condition than Gateaux differentiability, even in finite dimensions.  Between the two extremes is the [[quasi-derivative]].\n\nIn [[measure theory]], the [[Radon–Nikodym derivative]] generalizes the [[Jacobian matrix and determinant|Jacobian]], used for changing variables, to measures. It expresses one measure μ in terms of another measure ν (under certain conditions).\n\nIn the theory of [[abstract Wiener space]]s, the [[H-derivative|''H''-derivative]] defines a derivative in certain directions corresponding to the Cameron-Martin [[Hilbert space]].\n\nThe derivative also admits a generalization to the space of [[distribution (mathematics)|distributions]] on a space of functions using [[integration by parts]] against a suitably well-behaved subspace.\n\nOn a [[function space]], the [[linear operator]] which assigns to each function its derivative is an example of a [[differential operator]].  General differential operators include higher order derivatives.  By means of the [[Fourier transform]], [[pseudo-differential operator]]s can be defined which allow for fractional calculus.\n\n===Analogues of derivatives in fields of positive characteristic===\nThe [[Carlitz derivative]] is an operation similar to usual differentiation have been devised with the usual context of real or complex numbers changed to [[local fields]] of positive [[Characteristic_(algebra)|characteristic]] in the form of [[formal Laurent series]] with coefficients in some [[finite field]] F<sub>''q''</sub> (it is known that any local field of positive characteristic is isomorphic to a Laurent series field).\n\nAlong with suitably defined analogs to the [[exponential function]], [[logarithms]] and others the derivative can be used to develop notions of smoothness, analycity, integration, Taylor series as well as a theory of differential equations.<ref>{{cite book |title=Analysis in Positive Characteristic |last=Kochubei |first= Anatoly N.|year=2009 |publisher= Cambridge University Press |location= New York |isbn= 978-0-521-50977-0}}</ref>\n\n==Difference operator, q-analogues and time scales==\n\n* The [[q-derivative]]  of a function is defined by the formula\n\n: <math> D_q f(x)=\\frac{f(qx)-f(x)}{(q-1)x}.</math>\n\nFor ''x'' nonzero, if ''f'' is a differentiable function of ''x'' then in the limit as ''q''&ensp;→ 1 we obtain the ordinary derivative, thus the ''q''-derivative may be viewed as its [[q-deformation]]. A large body of results from ordinary differential calculus, such as [[binomial formula]] and [[Taylor expansion]], have natural ''q''-analogues that were discovered in the 19th century, but remained relatively obscure for a big part of the 20th century, outside of the theory of [[special functions]]. The progress of [[combinatorics]] and the discovery of [[quantum group]]s have changed the situation dramatically, and the popularity of ''q''-analogues is on the rise.\n\n* The [[difference operator]] of [[difference equations]] is another discrete analog of the standard derivative.\n:<math>\\Delta f(x)=f(x+1)-f(x)\\,</math>\n\n* The '''q-derivative''', the '''difference operator''' and the '''standard derivative''' can all be viewed as the same thing on different [[time scale calculus|time scales]]. For example, taking <math>\\epsilon = (q-1)x </math>, we may have\n\n: <math> \\frac{f(qx)-f(x)}{(q-1)x} = \\frac{f(x+\\epsilon)-f(x)}{\\epsilon}.</math>\nThe q-derivative is a special case of [[Wolfgang Hahn| Hahn]] difference (see {{harvtxt|Hahn|1949}}),\n: <math> \\frac{f(qx+\\omega)-f(x)}{qx+\\omega-x}.</math>\nHahn difference is not only a generalization of q-derivative but also an extension of forward difference.\n* Also note that the q-derivative is nothing but a special case of the familiar derivative. Take <math> z = qx </math>. Then we have,\n\n:<math>\\lim_{z \\to x}\\frac{f(z) - f(x)}{z - x} = \\lim_{q \\to 1}\\frac{f(qx) - f(x)}{qx - x} = \\lim_{q \\to 1}\\frac{f(qx)-f(x)}{(q-1)x}.</math>\n\n== Derivatives in algebra ==\nIn algebra, generalizations of the derivative can be obtained by imposing the [[product rule|Leibniz rule of differentiation]] in an algebraic structure, such as a [[ring (mathematics)|ring]] or a [[Lie algebra]].\n\n=== Derivations ===\n\nA [[derivation (abstract algebra)|derivation]] is a linear map on a  ring or [[algebra over a field|algebra]] which satisfies the Leibniz law (the product rule).  Higher derivatives and [[algebraic differential equation|algebraic differential operators]] can also be defined. They are studied in a purely algebraic setting in [[differential Galois theory]] and the theory of [[D-module]]s, but also turn up in many other areas, where they often agree with less algebraic definitions of derivatives.\n\nFor example, the [[differential algebra|formal derivative]] of a [[polynomial]] over a commutative ring ''R'' is defined by\n:<math>(a_dx^d + a_{d-1}x^{d-1} + \\cdots+a_1x+a_0)' = da_dx^{d-1}+(d-1)a_{d-1}x^{d-2} + \\cdots+a_1.</math>\nThe mapping <math>f\\mapsto f'</math> is then a derivation on the [[polynomial ring]] ''R''[''X''].  This definition can be extended to [[rational function]]s as well.\n\nThe notion of derivation applies to noncommutative as well as commutative rings, and even to non-associative algebraic structures, such as Lie algebras.\n\nSee also [[Pincherle derivative]] and [[Arithmetic derivative]].\n\n=== Commutative algebra ===\n\nIn [[commutative algebra]], [[Kähler differential]]s are universal derivations of a [[commutative ring]] or [[module (algebra)|module]]. They can be used to define an analogue of exterior derivative from differential geometry that applies to arbitrary [[algebraic varieties]], instead of just smooth manifolds.\n\n=== Number theory ===\n\nIn [[p-adic analysis]], the usual definition of derivative is not quite strong enough, and one requires [[strictly differentiable|strict differentiability]] instead.\n\nAlso see [[arithmetic derivative]] and [[Hasse derivative]].\n\n=== Type theory ===\nMany [[abstract data type]]s in mathematics and [[computer science]] can be described as the [[universal algebra|algebra]] generated by a transformation that maps structures based on the type back into the type. For example, the type T of [[binary tree]]s containing values of type A can be represented as the algebra generated by the transformation 1+A&times;T<sup>2</sup>→T. The \"1\" represents the construction of an empty tree, and the second term represents the construction of a tree from a value and two subtrees. The \"+\" indicates that a tree can be constructed either way.\n\nThe derivative of such a type is the type that describes the context of a particular substructure with respect to its next outer containing structure. Put another way, it is the type representing the \"difference\" between the two. In the tree example, the derivative is a type that describes the information needed, given a particular subtree, to construct its parent tree. This information is a tuple that contains a binary indicator of whether the child is on the left or right, the value at the parent, and the sibling subtree. This type can be represented as 2&times;A&times;T, which looks very much like the derivative of the transformation that generated the tree type.\n\nThis concept of a derivative of a type has practical applications, such as the [[zipper (data structure)|zipper]] technique used in [[functional programming language]]s.\n\n== Derivatives in geometry ==\nMain types of derivatives in geometry is Lie derivatives along a vector field, exterior differential, and covariant derivatives.\n\n=== Differential topology ===\n\nIn [[differential topology]], a [[vector field]] may be defined as a derivation on the ring of [[smooth function]]s on a [[manifold]], and a [[tangent vector]] may be defined as a derivation at a point.  This allows the abstraction of the notion of a [[directional derivative]] of a scalar function to general manifolds.  For manifolds that are [[subset]]s of '''R'''<sup>''n''</sup>, this tangent vector will agree with the directional derivative defined above.\n\nThe [[pushforward (differential)|differential or pushforward]] of a map between manifolds is the induced map between tangent spaces of those maps.  It abstracts the [[Jacobian matrix]].\n\nOn the [[exterior algebra]] of [[differential forms]] over a [[smooth manifold]], the [[exterior derivative]] is the unique linear map which satisfies a [[Graded Leibniz rule|graded version of the Leibniz law]] and squares to zero.  It is a grade 1 derivation on the exterior algebra.\n\nThe [[Lie derivative]] is the rate of change of a vector or tensor field along the flow of another vector field.  On vector fields, it is an example of a [[Lie bracket]] (vector fields form the [[Lie algebra]] of the [[diffeomorphism group]] of the manifold).  It is a grade 0 derivation on the algebra.\n\nTogether with the [[interior product]] (a degree -1 derivation on the exterior algebra defined by contraction with a vector field), the exterior derivative and the Lie derivative form a [[Lie superalgebra]].\n\n=== Differential geometry ===\n\nIn [[differential geometry]], the [[covariant derivative]] makes a choice for taking directional derivatives of vector fields along [[curve]]s.  This extends the directional derivative of scalar functions to sections of [[vector bundle]]s or [[principal bundle]]s.  In [[Riemannian geometry]], the existence of a metric chooses a unique preferred [[Torsion tensor|torsion]]-free covariant derivative, known as the [[Levi-Civita connection]].  See also [[gauge covariant derivative]] for a treatment oriented to physics.\n\nThe [[exterior covariant derivative]] extends the exterior derivative to vector valued forms.\n\n=== Geometric calculus ===\n\nIn [[geometric calculus]], the [[Geometric_calculus#Differentiation|geometric derivative]] satisfies a weaker form of the Leibniz rule. It specializes the Frechet derivative to the objects of geometric algebra. Geometric calculus is a powerful formalism that has been shown to encompass the similar frameworks of differential forms and differential geometry.<ref>[[David Hestenes]], Garrett Sobczyk: Clifford Algebra to Geometric Calculus, a Unified Language for mathematics and Physics (Dordrecht/Boston:G.Reidel Publ.Co., 1984, {{ISBN|90-277-2561-6}}</ref>\n\n== Other generalizations ==\n\nIt may be possible to combine two or more of the above different notions of extension or abstraction of the original derivative.  For example, in [[Finsler geometry]], one studies spaces which look [[locally]] like [[Banach space]]s.  Thus one might want a derivative with some of the features of a [[functional derivative]] and the [[covariant derivative]].\n\nThe study of [[stochastic processes]] requires a form of calculus known as the [[Malliavin calculus]]. One notion of derivative in this setting is the [[H-derivative|''H''-derivative]] of a function on an [[abstract Wiener space]].\n\n[[Multiplicative calculus]] replaces addition with multiplication, and hence rather than dealing with the limit of a ratio of differences, it deals with the limit of an exponentiation of ratios. This allows the development of the [[Multiplicative calculus |geometric derivative]] and [[multiplicative calculus | bigeometric derivative]]. Moreover, just like the classical differential operator has a discrete analog, the difference operator, there are also [[List of derivatives and integrals in alternative calculi|discrete analogs of these multiplicative derivatives]].\n\n== See also ==\n*[[Arithmetic derivative]]\n*[[Dini derivative]]\n*[[Multiplicative calculus#History|Non-Newtonian calculus]]\n*[[Non-classical analysis]]\n*[[Semi-differentiability]]\n*[[Symmetric derivative]]\n\n== Notes ==\n\n{{reflist}}\n\n[[Category:Generalizations of the derivative| ]]"
    },
    {
      "title": "Arithmetic derivative",
      "url": "https://en.wikipedia.org/wiki/Arithmetic_derivative",
      "text": "In [[number theory]], the '''Lagarias arithmetic derivative''', or '''number derivative''', is a function defined for [[integer]]s, based on [[prime factorization]], by analogy with the [[product rule]] for the [[derivative|derivative of a function]] that is used in [[mathematical analysis]].\n\nThere are many versions of \"arithmetic derivatives\", including the one discussed in this article (the Lagarias arithmetic derivative), such as Ihara's arithmetic derivative and Buium's arithmetic derivatives.\n\n==Definition==\nFor [[natural numbers]] the arithmetic derivative is defined as follows:\n\n* <math>p' \\;=\\; 1 </math> for any prime <math>p </math>.\n* <math>(pq)'\\;=\\;p'q\\,+\\,p q' </math> for any <math>p \\textrm{,}\\, q \\;\\in\\; \\mathbb{N}</math> ([[product rule|Leibniz rule]]).\n\n[[E. J. Barbeau]] was most likely the first person to formalize this definition. He also extended it to all integers by proving that <math>(-x)' \\;=\\; -(x')</math> uniquely defines the derivative over the integers. Barbeau also further extended it to rational numbers, showing that the familiar [[quotient rule]] gives a well-defined derivative on '''Q''':\n\n:<math>\\left(\\frac{p}{q}\\right)' = \\frac{p'q-p q'}{q^2} \\ .</math>\n\n[[Victor Ufnarovski]] and [[Bo Åhlander]] expanded it to certain irrationals. In these extensions, the formula above still applies, but the exponents <math>e_i</math> are allowed to be arbitrary rational numbers.\n\n==Elementary properties==\nThe Leibniz rule implies that <math>0'=0</math> (take <math>p = q = 0</math>) and <math>1'=0</math> (take <math>p = q = 1</math>).\n\nThe ''power rule'' is also valid for the arithmetic derivative. For any integers {{mvar|p}} and {{math|''n'' &ge; 0}}:\n\n:<math>(p^n)' = np^{n-1} p'.</math>\n\nThis allows one to compute the derivative from the prime factorisation of an integer, <math>x = p_1^{n_1}\\cdots p_k^{n_k}</math>:\n\n:<math>x' = \\sum_{i=1}^k n_i p_1^{n_1} \\cdots p_{i-1}^{n_{i-1}} p_i^{n_i-1} p_{i+1}^{n_{i+1}}\\cdots p_k^{n_k} = \\sum_{i=1}^k \\frac {n_i} {p_i}x.</math>\n\nFor example: \n\n:<math>60' = (2^2 \\cdot 3 \\cdot 5)' = \\left(\\frac{2}{2} + \\frac{1}{3} + \\frac{1}{5}\\right) \\cdot 60 = 92,</math>\n\nor\n\n:<math>81' = (3^4)' = 4\\cdot 3^3\\cdot 3' = 4\\cdot 27\\cdot 1 = 108.</math>\n\nThe sequence of number derivatives for {{math|1=''k'' = 0, 1, 2, ...}} begins {{OEIS|id=A003415}}:\n\n:<math>0, 0, 1, 1, 4, 1, 5, 1, 12, 6, 7, 1, 16, 1, 9, \\ldots </math>\n\n== Related function==\nThe ''logarithmic derivative'' <math>\\operatorname{ld}(x)=\\frac{x'}{x}</math> is a [[totally additive function]]: <math>\\operatorname{ld}(x \\cdot y) = \\operatorname{ld}(x)+\\operatorname{ld}(y).</math>\n\n==Inequalities and bounds==\nE. J. Barbeau examined bounds of the arithmetic derivative. He found that the arithmetic derivative of natural numbers is bounded by\n: <math>\nn' \\leq \\frac{n \\log_p n}{k}\n</math>\nwhere '''''p''''' is the least prime in ''n'' and \n\n: <math>\nn' \\geq sn^{\\frac{s-1}{s}}\n</math>\nwhere '''''s''''' is the number of prime factors in ''n''.\nIn both bounds above, equality always occurs when ''n'' is a perfect power of 2, that is <math>n=2^m</math> for some ''m''.\n\n[[Alexander Loiko]], [[Jonas Ernst Olsson|Jonas Olsson]] and [[Niklas Dahl]] found that it is impossible to find similar bounds for the arithmetic derivative extended to rational numbers by proving that between any two rational numbers there are other rationals with arbitrary large or small derivatives.\n\n==Order of the average==\nWe have \n\n:<math> \\sum_{n \\le x} \\frac{n'}{n} = T_0 x + O(\\log x \\log\\log x) </math>\n\nand\n\n:<math> \\sum_{n \\le x} n' = (1/2)T_0 x^2 + O(x^{1+\\delta}) </math>\n\nfor any δ>0, where \n\n:<math>T_0 = \\sum_p \\frac{1}{p(p-1)}. </math>\n\n==Relevance to number theory==\n\n[[Victor Ufnarovski]] and [[Bo Åhlander]] have detailed the function's connection to famous number-theoretic conjectures like the [[twin prime conjecture]], the prime triples conjecture, and [[Goldbach's conjecture]]. For example, Goldbach's conjecture would imply, for each ''k''&nbsp;>&nbsp;1 the existence of an ''n'' so that ''n''<nowiki>'</nowiki> = 2''k''. The twin prime conjecture would imply that there are infinitely many ''k'' for which ''k''<nowiki>''</nowiki> = 1.\n\n==References==\n{{reflist}}\n* {{cite journal | first=E. J. | last=Barbeau | title=Remarks on an arithmetic derivative | journal=[[Canadian Mathematical Bulletin]] | volume=4 | year=1961 | pages=117–122 | doi=10.4153/CMB-1961-013-0 | zbl=0101.03702 }}\n* {{cite journal | first1=Victor | last1=Ufnarovski | first2=Bo | last2=Åhlander | url=http://www.cs.uwaterloo.ca/journals/JIS/VOL6/Ufnarovski/ufnarovski.html | title=How to Differentiate a Number | journal=[[Journal of Integer Sequences]] | volume=6 | year=2003 | at=Article 03.3.4 | zbl=1142.11305 | issn=1530-7638 }}\n* [https://web.archive.org/web/20071018000709/http://planetmath.org/encyclopedia/ArithmeticDerivative.html Arithmetic Derivative]'', [[Planet Math]]'', accessed 04:15, 9 April 2008 (UTC)\n* L. Westrick (2003). ''[https://web.archive.org/web/20050426071741/http://web.mit.edu/lwest/www/intmain.pdf Investigations of the Number Derivative]''.\n* Peterson, I. ''[http://www.maa.org/mathland/mathtrek_03_22_04.html Math Trek: Deriving the Structure of Numbers]''.\n* {{cite journal | first=Michael | last=Stay | journal=[[Journal of Integer Sequences]] | volume=8 | year=2005 | at=Article 05.1.4 | title=Generalized Number Derivatives | url=https://cs.uwaterloo.ca/journals/JIS/VOL8/Stay/stay44.html | zbl=1065.05019 | issn=1530-7638 }}\n* Dahl N., Olsson J., Loiko A., ''[https://arxiv.org/abs/1108.4762 Investigation of the properties of the arithmetic derivative]''.\n*{{cite book | last1 = Balzarotti| first1 = Giorgio| last2 = Lava| first2 = Paolo Pietro| title = La derivata aritmetica. Alla scoperta di un nuovo approccio alla teoria dei numeri | publisher= Hoepli| location = Milan | date = 2013| isbn = 978-88-203-5864-8 }}\n\n[[Category:Number theory]]\n[[Category:Generalizations of the derivative]]"
    },
    {
      "title": "Differential of a function",
      "url": "https://en.wikipedia.org/wiki/Differential_of_a_function",
      "text": "{{for|other uses of \"differential\" in mathematics|Differential (mathematics)}}\n{{Calculus |Differential}}\n\nIn [[calculus]], the '''differential''' represents the [[principal part#Calculus|principal part]] of the change in a function ''y''&nbsp;=&nbsp;''f''(''x'') with respect to changes in the independent variable. The differential ''dy'' is defined by\n:<math>dy = f'(x)\\,dx,</math>\nwhere <math>f'(x)</math> is the [[derivative]] of ''f'' with respect to ''x'', and ''dx'' is an additional real [[variable (mathematics)|variable]] (so that ''dy'' is a function of ''x'' and ''dx'').  The notation is such that the equation\n\n:<math>dy = \\frac{dy}{dx}\\, dx</math>\n\nholds, where the derivative is represented in the [[Leibniz notation]] ''dy''/''dx'', and this is consistent with regarding the derivative as the quotient of the differentials. One also writes\n\n:<math>df(x) = f'(x)\\,dx.</math>\n\nThe precise meaning of the variables ''dy'' and ''dx'' depends on the context of the application and the required level of mathematical rigor. The domain of these variables may take on a particular geometrical significance if the differential is regarded as a particular [[differential form]], or analytical significance if the differential is regarded as a [[linear approximation]] to the increment of a function.  Traditionally, the variables ''dx'' and ''dy'' are considered to be very small ([[infinitesimal]]), and this interpretation is made rigorous in [[non-standard analysis]].\n\n==History and usage==\nThe differential was first introduced via an intuitive or heuristic definition by [[Gottfried Wilhelm Leibniz]], who thought of the differential&nbsp;''dy'' as an infinitely small (or [[infinitesimal]]) change in the value&nbsp;''y'' of the function, corresponding to an infinitely small change&nbsp;''dx'' in the function's argument&nbsp;''x''.  For that reason, the instantaneous rate of change of ''y'' with respect to ''x'', which is the value of the [[derivative]] of the function, is denoted by the fraction\n\n: <math> \\frac{dy}{dx} </math>\n\nin what is called the [[Leibniz notation]] for derivatives. The quotient ''dy''/''dx'' is not infinitely small; rather it is a [[real number]].\n\nThe use of infinitesimals in this form was widely criticized, for instance by the famous pamphlet [[The Analyst]] by Bishop Berkeley.  [[Augustin-Louis Cauchy]] ([[#CITEREFCauchy1823|1823]]) defined the differential without appeal to the atomism of Leibniz's infinitesimals.<ref>For a detailed historical account of the differential, see {{harvnb|Boyer|1959}}, especially page 275 for Cauchy's contribution on the subject.  An abbreviated account appears in {{harvnb|Kline|1972|loc=Chapter 40}}.</ref><ref>Cauchy explicitly denied the possibility of actual infinitesimal and infinite quantities {{harv|Boyer|1959|pp=273–275}}, and took the radically different point of view that \"a variable quantity becomes infinitely small when its numerical value decreases indefinitely in such a way as to converge to zero\" ({{harvnb|Cauchy|1823|p=12}};  translation from {{harvnb|Boyer|1959|p=273}}).</ref> Instead, Cauchy, following [[Jean le Rond d'Alembert|d'Alembert]], inverted the logical order of Leibniz and his successors: the derivative itself became the fundamental object, defined as a [[limit (mathematics)|limit]] of difference quotients, and the differentials were then defined in terms of it.  That is, one was free to ''define'' the differential ''dy'' by an expression\n:<math>dy = f'(x)\\,dx</math>\nin which ''dy'' and ''dx''  are simply new variables taking finite real values,<ref>{{harvnb|Boyer|1959|p=275}}</ref> not fixed infinitesimals as they had been for Leibniz.<ref>{{harvnb|Boyer|1959|p=12}}: \"The differentials as thus defined are only new ''variables'', and not fixed infinitesimals...\"</ref>\n\nAccording to {{harvtxt|Boyer|1959|p=12}}, Cauchy's approach was a significant logical improvement over the infinitesimal approach of Leibniz because, instead of invoking the metaphysical notion of infinitesimals, the quantities ''dy'' and ''dx'' could now be manipulated in exactly the same manner as any other real quantities\nin a meaningful way.  Cauchy's overall conceptual approach to differentials remains the standard one in modern analytical treatments,<ref>{{harvnb|Courant|1937a|loc=II, §9}}: \"Here we remark merely in passing that it is possible to use this approximate representation of the increment &Delta;''y'' by the linear expression ''h&fnof;''(''x'') to construct a logically satisfactory definition of a \"differential\", as was done by Cauchy in particular.\"</ref> although the final word on rigor, a fully modern notion of the limit, was ultimately due to [[Karl Weierstrass]].<ref>{{harvnb|Boyer|1959|p=284}}</ref>\n\nIn physical treatments, such as those applied to the theory of [[thermodynamics]], the infinitesimal view still prevails.  {{harvtxt|Courant|John|1999|p=184}} reconcile the physical use of infinitesimal differentials with the mathematical impossibility of them as follows.  The differentials represent finite non-zero values that are smaller than the degree of accuracy required for the particular purpose for which they are intended.  Thus \"physical infinitesimals\" need not appeal to a corresponding mathematical infinitesimal in order to have a precise sense.\n\nFollowing twentieth-century developments in [[mathematical analysis]] and [[differential geometry]], it became clear that the notion of the differential of a function could be extended in a variety of ways.  In [[real analysis]], it is more desirable to deal directly with the differential as the principal part of the increment of a function.  This leads directly to the notion that the differential of a function at a point is a [[linear functional]] of an increment Δ''x''.  This approach allows the differential (as a linear map) to be developed for a variety of more sophisticated spaces, ultimately giving rise to such notions as the [[Fréchet derivative|Fréchet]] or [[Gateaux derivative]].  Likewise, in [[differential geometry]], the differential of a function at a point is a linear function of a [[tangent vector]] (an \"infinitely small displacement\"), which exhibits it as a kind of one-form: the [[exterior derivative]] of the function.  In [[non-standard calculus]], differentials are regarded as infinitesimals, which can themselves be put on a rigorous footing (see [[differential (infinitesimal)]]).\n\n==Definition==\n\n[[File:Sentido geometrico del diferencial de una funcion.png|thumb|The differential of a function ''&fnof;''(''x'') at a point&nbsp;''x''<sub>0</sub>.]]\nThe differential is defined in modern treatments of differential calculus as follows.<ref>See, for instance, the influential treatises of {{harvnb|Courant|1937a}}, {{harvnb|Kline|1977}}, {{harvnb|Goursat|1904}}, and {{harvnb|Hardy|1905}}.  Tertiary sources for this definition include also {{harvnb|Tolstov|2001}} and {{harvnb|Ito|1993|loc=§106}}.</ref>  The differential of a function ''f''(''x'') of a single real variable ''x'' is the function ''df'' of two independent real variables ''x'' and ''Δx'' given by\n\n:<math>df(x, \\Delta x) \\stackrel{\\mathrm{def}}{=} f'(x)\\,\\Delta x.</math>\n\nOne or both of the arguments may be suppressed, i.e., one may see ''df''(''x'') or simply ''df''. If ''y''&nbsp;=&nbsp;''f''(''x''), the differential may also be written as ''dy''.  Since ''dx''(''x'',&nbsp;Δ''x'')&nbsp;=&nbsp;Δ''x'' it is conventional to write ''dx''&nbsp;=&nbsp;Δ''x'', so that the following equality holds:\n\n:<math>df(x) = f'(x) \\, dx</math>\n \nThis notion of differential is broadly applicable when a [[linear approximation]] to a function is sought, in which the value of the increment Δ''x'' is small enough.  More precisely, if ''f'' is a [[differentiable function]] at ''x'', then the difference in ''y''-values\n\n:<math>\\Delta y \\stackrel{\\rm{def}}{=} f(x+\\Delta x) - f(x)</math>\n\nsatisfies\n\n:<math>\\Delta y = f'(x)\\,\\Delta x + \\varepsilon = df(x) + \\varepsilon\\,</math>\n\nwhere the error ε in the approximation satisfies ε/Δ''x''&nbsp;→&nbsp;0 as Δ''x''&nbsp;→&nbsp;0.  In other words, one has the approximate identity\n\n:<math>\\Delta y \\approx dy</math>\n\nin which the error can be made as small as desired relative to Δ''x'' by constraining ''Δx'' to be sufficiently small; that is to say,\n:<math>\\frac{\\Delta y - dy}{\\Delta x}\\to 0</math>\nas Δ''x''&nbsp;→&nbsp;0.  For this reason, the differential of a function is known as the [[principal part|principal (linear) part]] in the increment of a function: the differential is a [[linear function]] of the increment Δ''x'', and although the error ε may be nonlinear, it tends to zero rapidly as Δ''x'' tends to zero.\n\n==Differentials in several variables==\nFollowing {{harvtxt|Goursat|1904|loc=I, §15}}, for functions of more than one independent variable,\n\n: <math> y = f(x_1,\\dots,x_n), \\, </math>\n\nthe '''partial differential''' of ''y'' with respect to any one of the variables&nbsp;''x''<sub>1</sub> is the principal part of the change in ''y'' resulting from a change&nbsp;''dx''<sub>1</sub> in that one variable.  The partial differential is therefore\n\n: <math> \\frac{\\partial y}{\\partial x_1} dx_1 </math>\n\ninvolving the [[partial derivative]] of ''y'' with respect to&nbsp;''x''<sub>1</sub>.  The sum of the partial differentials with respect to all of the independent variables is the '''total differential'''\n\n: <math> dy = \\frac{\\partial y}{\\partial x_1} dx_1 + \\cdots + \\frac{\\partial y}{\\partial x_n} dx_n, </math>\n\nwhich is the principal part of the change in ''y'' resulting from changes in the independent variables&nbsp;''x''<sub>''i''</sub>.\n\nMore precisely, in the context of multivariable calculus, following {{harvtxt|Courant|1937b}}, if ''f'' is a differentiable function, then by the [[Fréchet derivative|definition of the differentiability]], the increment\n\n:<math>\\begin{align}\n\\Delta y &{}\\stackrel{\\mathrm{def}}{=} f(x_1+\\Delta x_1, \\dots, x_n+\\Delta x_n) - f(x_1,\\dots,x_n)\\\\\n&{}= \\frac{\\partial y}{\\partial x_1} \\Delta x_1 + \\cdots + \\frac{\\partial y}{\\partial x_n} \\Delta x_n + \\varepsilon_1\\Delta x_1 +\\cdots+\\varepsilon_n\\Delta x_n\n\\end{align}</math>\n\nwhere the error terms ε<sub>&nbsp;''i''</sub> tend to zero as the increments Δ''x''<sub>''i''</sub> jointly tend to zero.  The total differential is then rigorously defined as\n\n:<math>dy = \\frac{\\partial y}{\\partial x_1} \\Delta x_1 + \\cdots + \\frac{\\partial y}{\\partial x_n} \\Delta x_n.</math>\n\nSince, with this definition,\n:<math>dx_i(\\Delta x_1,\\dots,\\Delta x_n) = \\Delta x_i,</math>\none has\n:<math>dy = \\frac{\\partial y}{\\partial x_1}\\,d x_1 + \\cdots + \\frac{\\partial y}{\\partial x_n}\\,d x_n.</math>\n\nAs in the case of one variable, the approximate identity holds\n\n:<math>dy \\approx \\Delta y</math>\n\nin which the total error can be made as small as desired relative to <math>\\sqrt{\\Delta x_1^2+\\cdots +\\Delta x_n^2}</math> by confining attention to sufficiently small increments.\n\n=== Application of the total differential to error estimation ===\nIn measurement, the total differential is used in [[Experimental uncertainty analysis|estimating the error]] Δ''f'' of a function ''f'' based on the errors Δ''x'', Δ''y'', ... of the parameters ''x, y, ...''. Assuming that the interval is short enough for the change to be approximately linear:\n\n:Δ''f''(''x'') = ''f'''(''x'') × Δ''x''\n\nand that all variables are independent, then for all variables,\n\n:<math>\\Delta f = f_x \\Delta x + f_y \\Delta y + \\cdots</math>\n\nThis is because the derivative ''f''<sub>x</sub>  with respect to the particular parameter ''x'' gives the sensitivity of the function ''f'' to a change in ''x'', in particular the error Δ''x''. As they are assumed to be independent, the analysis describes the worst-case scenario. The absolute values of the component errors are used, because after simple computation, the derivative may have a negative sign. From this principle the error rules of summation, multiplication etc. are derived, e.g.:\n\n:Let f(''a'', ''b'') = ''a'' × ''b'';\n\n:Δ''f'' = ''f''<sub>''a''</sub>Δ''a'' + ''f''<sub>''b''</sub>Δ''b''; evaluating the derivatives\n\n:Δ''f'' = ''b''Δ''a'' + ''a''Δ''b''; dividing by ''f'', which is ''a'' × ''b''\n\n:Δ''f''/''f'' = Δ''a''/''a'' + Δ''b''/''b''\n\nThat is to say, in multiplication, the total [[relative error]] is the sum of the relative errors of the parameters.\n\nTo illustrate how this depends on the function considered, consider the case where the function is ''f(a, b) = a ln b'' instead. Then, it can be computed that the error estimate is\n:Δ''f''/''f'' = Δ''a''/''a'' + Δ''b''/(''b'' ln ''b'')\nwith an extra 'ln ''b''' factor not found in the case of a simple product. This additional factor tends to make the error smaller, as ln ''b'' is not as large as a bare ''b''.\n\n==Higher-order differentials==\nHigher-order differentials of a function ''y''&nbsp;=&nbsp;''f''(''x'') of a single variable ''x'' can be defined via:<ref>{{harvnb|Cauchy|1823}}. See also, for instance,  {{harvnb|Goursat|1904|loc=I, §14}}.</ref>\n:<math>d^2y = d(dy) = d(f'(x)dx) = (df'(x))dx = f''(x)\\,(dx)^2,</math>\nand, in general,\n:<math>d^ny = f^{(n)}(x)\\,(dx)^n.</math>\nInformally, this justifies Leibniz's notation for higher-order derivatives\n:<math>f^{(n)}(x) = \\frac{d^n f}{dx^n}.</math>\nWhen the independent variable ''x'' itself is permitted to depend on other variables, then the expression becomes more complicated, as it must include also higher order differentials in ''x'' itself.  Thus, for instance,\n:<math>\n\\begin{align}\nd^2 y &= f''(x)\\,(dx)^2 + f'(x)d^2x\\\\\nd^3 y &= f'''(x)\\, (dx)^3 + 3f''(x)dx\\,d^2x + f'(x)d^3x \n\\end{align}</math>\nand so forth.\n\nSimilar considerations apply to defining higher order differentials of functions of several variables.  For example, if ''f'' is a function of two variables ''x'' and ''y'', then\n:<math>d^nf = \\sum_{k=0}^n \\binom{n}{k}\\frac{\\partial^n f}{\\partial x^k \\partial y^{n-k}}(dx)^k(dy)^{n-k},</math>\nwhere <math>\\scriptstyle{\\binom{n}{k}}</math> is a [[binomial coefficient]].  In more variables, an analogous expression holds, but with an appropriate [[multinomial coefficient|multinomial]] expansion rather than binomial expansion.<ref>{{harvnb|Goursat|1904|loc=I, §14}}</ref>\n\nHigher order differentials in several variables also become more complicated when the independent variables are themselves allowed to depend on other variables.  For instance, for a function ''f'' of ''x'' and ''y'' which are allowed to depend on auxiliary variables, one has\n:<math>d^2f = \\left(\\frac{\\partial^2f}{\\partial x^2}(dx)^2+2\\frac{\\partial^2f}{\\partial x\\partial y}dx\\,dy + \\frac{\\partial^2f}{\\partial y^2}(dy)^2\\right) + \\frac{\\partial f}{\\partial x}d^2x + \\frac{\\partial f}{\\partial y}d^2y.</math>\n\nBecause of this notational infelicity, the use of higher order differentials was roundly criticized by {{harvnb|Hadamard|1935}}, who concluded:\n:Enfin, que signifie ou que représente l'égalité\n::<math>d^2z = r\\,dx^2 + 2s\\,dx\\,dy + t\\,dy^2\\,?</math>\n:A mon avis, rien du tout.\n\nThat is: ''Finally, what is meant, or represented, by the equality [...]? In my opinion, nothing at all.'' In spite of this skepticism, higher order differentials did emerge as an important tool in analysis<ref>In particular to [[infinite dimensional holomorphy]] {{harv|Hille|Phillips|1974}} and [[numerical analysis]] via the calculus of [[finite differences]].</ref>\n\nIn these contexts, the ''n''th order differential of the function ''f'' applied to an increment Δ''x'' is defined by\n:<math>d^nf(x,\\Delta x) = \\left.\\frac{d^n}{dt^n} f(x+t\\Delta x)\\right|_{t=0}</math>\nor an equivalent expression, such as\n:<math>\\lim_{t\\to 0}\\frac{\\Delta^n_{t\\Delta x} f}{t^n}</math>\nwhere <math>\\Delta^n_{t\\Delta x} f</math> is an ''n''th [[forward difference]] with increment ''t''Δ''x''.\n\nThis definition makes sense as well if ''f'' is a function of several variables (for simplicity taken here as a vector argument). Then the ''n''th differential defined in this way is a [[homogeneous function]] of degree ''n'' in the vector increment Δ''x''.  Furthermore, the [[Taylor series]] of ''f'' at the point ''x'' is given by\n:<math>f(x+\\Delta x)\\sim f(x) + df(x,\\Delta x) + \\frac{1}{2}d^2f(x,\\Delta x) + \\cdots + \\frac{1}{n!}d^nf(x,\\Delta x) + \\cdots</math>\nThe higher order [[Gateaux derivative]] generalizes these considerations to infinite dimensional spaces.\n\n==Properties==\nA number of properties of the differential follow in a straightforward manner from the corresponding properties of the derivative, partial derivative, and total derivative.  These include:<ref>{{harvnb|Goursat|1904|loc=I, §17}}</ref>\n\n* [[Linearity]]:  For constants ''a'' and ''b'' and differentiable functions ''f'' and ''g'',\n::<math>d(af+bg) = a\\,df + b\\,dg.</math>\n* [[Product rule]]:  For two differentiable functions ''f'' and ''g'',\n::<math>d(fg) = f\\,dg+g\\,df.</math>\n\nAn operation ''d'' with these two properties is known in [[abstract algebra]] as a [[derivation (abstract algebra)|derivation]].  They imply the Power rule\n::<math> d( f^n ) = n f^{n-1} df </math>\nIn addition, various forms of the [[chain rule]] hold, in increasing level of generality:<ref>{{harvnb|Goursat|1904|loc=I, §§14,16}}</ref>\n\n* If ''y''&nbsp;=&nbsp;''f''(''u'') is a differentiable function of the variable ''u'' and ''u''&nbsp;=&nbsp;''g''(''x'') is a differentiable function of ''x'', then\n::<math>dy = f'(u)\\,du = f'(g(x))g'(x)\\,dx.</math>\n\n* If ''y''&nbsp;=&nbsp;''f''(''x''<sub>1</sub>,&nbsp;...,&nbsp;''x''<sub>''n''</sub>) and all of the variables&nbsp;''x''<sub>1</sub>,&nbsp;...,&nbsp;''x''<sub>''n''</sub> depend on another variable&nbsp;''t'', then by the [[Chain rule#Chain rule for several variables|chain rule for partial derivatives]], one has\n\n:: <math>\\begin{align}\ndy &= \\frac{dy}{dt}dt \\\\\n&= \\frac{\\partial y}{\\partial x_1} dx_1 + \\cdots + \\frac{\\partial y}{\\partial x_n} dx_n\\\\\n&= \\frac{\\partial y}{\\partial x_1} \\frac{dx_1}{dt}\\,dt + \\cdots + \\frac{\\partial y}{\\partial x_n} \\frac{dx_n}{dt}\\,dt.\n\\end{align}</math>\n\n:Heuristically, the chain rule for several variables can itself be understood by dividing through both sides of this equation by the infinitely small quantity ''dt''.\n\n* More general analogous expressions hold, in which the intermediate variables ''x''<sub>&nbsp;''i''</sub> depend on more than one variable.\n\n==General formulation==\n{{See also|Fréchet derivative|Gateaux derivative}}\nA consistent notion of differential can be developed for a function ''f''&nbsp;:&nbsp;'''R'''<sup>''n''</sup>&nbsp;→&nbsp;'''R'''<sup>''m''</sup> between two [[Euclidean space]]s.  Let '''x''',Δ'''x'''&nbsp;∈&nbsp;'''R'''<sup>''n''</sup> be a pair of [[Euclidean vector]]s.  The increment in the function ''f'' is\n:<math>\\Delta f = f(\\mathbf{x}+\\Delta\\mathbf{x}) - f(\\mathbf{x}).</math>\nIf there exists an ''m''&nbsp;&times;&nbsp;''n'' [[matrix (mathematics)|matrix]] ''A'' such that\n:<math>\\Delta f = A\\Delta\\mathbf{x} + \\|\\Delta\\mathbf{x}\\|\\boldsymbol{\\varepsilon}</math>\nin which the vector '''''ε'''''&nbsp;→&nbsp;0 as Δ'''x'''&nbsp;→&nbsp;0, then ''f'' is by definition differentiable at the point '''x'''.  The matrix ''A'' is sometimes known as the [[Jacobian matrix]], and the [[linear transformation]] that associates to the increment Δ'''x'''&nbsp;∈&nbsp;'''R'''<sup>''n''</sup> the vector ''A''Δ'''x'''&nbsp;∈&nbsp;'''R'''<sup>''m''</sup> is, in this general setting, known as the differential ''df''(''x'') of ''f'' at the point ''x''.  This is precisely the [[Fréchet derivative]], and the same construction can be made to work for a function between any [[Banach space]]s.\n\nAnother fruitful point of view is to define the differential directly as a kind of [[directional derivative]]:\n\n:<math>df(\\mathbf{x},\\mathbf{h}) = \\lim_{t\\to 0}\\frac{f(\\mathbf{x}+t\\mathbf{h})-f(\\mathbf{x})}{t} = \\left.\\frac{d}{dt}f(\\mathbf{x}+t\\mathbf{h})\\right|_{t=0},</math>\n\nwhich is the approach already taken for defining higher order differentials (and is most nearly the definition set forth by Cauchy).  If ''t'' represents time and '''x''' position, then '''h''' represents a velocity instead of a displacement as we have heretofore regarded it.  This yields yet another refinement of the notion of differential: that it should be a linear function of a kinematic velocity.  The set of all velocities through a given point of space is known as the [[tangent space]], and so ''df'' gives a linear function on the tangent space: a [[differential form]].  With this interpretation, the differential of ''f'' is known as the [[exterior derivative]], and has broad application in [[differential geometry]] because the notion of velocities and the tangent space makes sense on any [[differentiable manifold]].  If, in addition, the output value of ''f'' also represents a position (in a Euclidean space), then a dimensional analysis confirms that the output value of ''df'' must be a velocity.  If one treats the differential in this manner, then it is known as the [[pushforward (differential)|pushforward]] since it \"pushes\" velocities from a source space into velocities in a target space.\n\n==Other approaches==\n{{Main|Differential (infinitesimal)}}\nAlthough the notion of having an infinitesimal increment ''dx'' is not well-defined in modern [[mathematical analysis]], a variety of techniques exist for defining the [[differential (infinitesimal)|infinitesimal differential]] so that the differential of a function can be handled in a manner that does not clash with the [[Leibniz notation]].  These include:\n\n* Defining the differential as a kind of [[differential form]], specifically the [[exterior derivative]] of a function.  The infinitesimal increments are then identified with vectors in the [[tangent space]] at a point.  This approach is popular in [[differential geometry]] and related fields, because it readily generalizes to mappings between [[differentiable manifold]]s.\n* Differentials as [[nilpotent]] elements of [[commutative ring]]s. This approach is popular in [[algebraic geometry]].<ref>{{Harvnb|Eisenbud|Harris|1998}}.</ref>\n* Differentials in smooth models of set theory. This approach is known as [[synthetic differential geometry]] or [[smooth infinitesimal analysis]] and is closely related to the algebraic geometric approach, except that ideas from [[topos theory]] are used to ''hide'' the mechanisms by which nilpotent infinitesimals are introduced.<ref>See {{Harvnb|Kock|2006}} and {{Harvnb|Moerdijk|Reyes|1991}}.</ref>\n* Differentials as infinitesimals in [[hyperreal number]] systems, which are extensions of the real numbers which contain invertible infinitesimals and infinitely large numbers. This is the approach of [[nonstandard analysis]] pioneered by [[Abraham Robinson]].<ref name=\"nonstd\">See {{Harvnb|Robinson|1996}} and {{Harvnb|Keisler|1986}}.</ref>\n\n== Examples and applications ==\nDifferentials may be effectively used in [[numerical analysis]] to study the propagation of experimental errors in a calculation, and thus the overall [[numerical stability]] of a problem {{harv|Courant|1937a}}.  Suppose that the variable ''x'' represents the outcome of an experiment and ''y'' is the result of a numerical computation applied to ''x''.  The question is to what extent errors in the measurement of ''x'' influence the outcome of the computation of ''y''.  If the ''x'' is known to within Δ''x'' of its true value, then [[Taylor's theorem]] gives the following estimate on the error Δ''y'' in the computation of ''y'':\n:<math>\\Delta y = f'(x)\\Delta x + \\frac{(\\Delta x)^2}{2}f''(\\xi)</math>\nwhere ξ&nbsp;=&nbsp;''x''&nbsp;+&nbsp;θΔ''x'' for some 0&nbsp;<&nbsp;θ&nbsp;<&nbsp;1.  If Δ''x'' is small, then the second order term is negligible, so that Δ''y'' is, for practical purposes, well-approximated by ''dy''&nbsp;=&nbsp;''f'''(''x'')Δ''x''.\n\nThe differential is often useful to rewrite a [[differential equation]]\n\n: <math> \\frac{dy}{dx} = g(x) </math>\n\nin the form\n\n: <math> dy = g(x)\\,dx, </math>\n\nin particular when one wants to [[separation of variables|separate the variables]].\n\n==Notes==\n<references/>\n\n== References ==\n*{{Citation | last1=Boyer | first1=Carl B. | author1-link=Carl Benjamin Boyer | title=The history of the calculus and its conceptual development | publisher=[[Dover Publications]] | location=New York | mr=0124178  | year=1959}}.\n*{{citation|first=Augustin-Louis|last=Cauchy|authorlink=Augustin-Louis Cauchy|chapter=<!--Quatrième leçon: Différentialles des fonctions d'une seule variable-->|title=Résumé des Leçons données à l'Ecole royale polytechnique sur les applications du calcul infinitésimal|year=1823|url=http://math-doc.ujf-grenoble.fr/cgi-bin/oeitem?id=OE_CAUCHY_2_4_9_0}}.\n*{{Citation | last1=Courant | first1=Richard |authorlink=Richard Courant | title=Differential and integral calculus. Vol. I | publisher=[[John Wiley & Sons]] | location=New York | series=Wiley Classics Library | isbn=978-0-471-60842-4 | mr=1009558  | year=1937a|publication-date=1988}}.\n*{{Citation | last1=Courant | first1=Richard | authorlink=Richard Courant |title=Differential and integral calculus. Vol. II | publisher=[[John Wiley & Sons]] | location=New York | series=Wiley Classics Library | isbn=978-0-471-60840-0 | mr=1009559  | year=1937b|publication-date=1988}}.\n*{{Citation | last1=Courant | first1=Richard | authorlink1=Richard Courant| last2=John | first2=Fritz |authorlink2=Fritz John| title=Introduction to Calculus and Analysis Volume 1|series=Classics in Mathematics| publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=3-540-65058-X | year=1999 | mr=1746554  }}\n* {{Citation| author1-link=David Eisenbud|first1=David|last1=Eisenbud|author2-link=Joe Harris (mathematician)|first2=Joe|last2=Harris| year = 1998 |title = The Geometry of Schemes| publisher = Springer-Verlag| isbn = 0-387-98637-5}}.\n*{{Citation | last1=Fréchet | first1=Maurice | author1-link= Maurice Fréchet | title=La notion de différentielle dans l'analyse générale | mr=1509268  | year=1925 | journal=Annales Scientifiques de l'École Normale Supérieure |series=Série 3 | issn=0012-9593 | volume=42 | pages=293–323}}.\n*{{Citation | last1=Goursat | first1=Édouard | authorlink=Édouard Goursat|title=A course in mathematical analysis: Vol 1: Derivatives and differentials, definite integrals, expansion in series, applications to geometry| publisher=[[Dover Publications]] | location=New York | others= E. R. Hedrick | mr=0106155  | year=1904 | publication-date=1959|url=https://archive.org/details/coursemathanalys01gourrich}}.\n*{{citation|last=Hadamard|first=Jacques|authorlink=Jacques Hadamard|title=La notion de différentiel dans l'enseignement|journal=Mathematical Gazette|volume=XIX|year=1935|issue=236|pages=341–342|jstor=3606323}}.\n*{{Citation | last1=Hardy | first1=Godfrey Harold | author1-link=G. H. Hardy | title=A Course of Pure Mathematics | publisher=[[Cambridge University Press]] | isbn=978-0-521-09227-2 | year=1908}}.\n*{{Citation | last1=Hille | first1=Einar | authorlink1=Einar Hille | last2=Phillips | first2=Ralph S. | authorlink2=Ralph Phillips (mathematician) | title=Functional analysis and semi-groups | publisher=[[American Mathematical Society]] | location=Providence, R.I. | mr=0423094  | year=1974}}.\n*{{Citation | last1=Ito | first1=Kiyosi | title=Encyclopedic Dictionary of Mathematics | publisher=[[MIT Press]] | edition=2nd | isbn=978-0-262-59020-4 | year=1993}}.\n*{{citation|chapter=Chapter 13: Differentials and the law of the mean|title=Calculus: An intuitive and physical approach|first=Morris|last=Kline|authorlink=Morris Kline|publisher=John Wiley and Sons|year=1977}}.\n*{{Citation | last1=Kline | first1=Morris | author1-link=Morris Kline | title=Mathematical thought from ancient to modern times | year=1972 | publisher=[[Oxford University Press]] | edition=3rd | isbn=978-0-19-506136-9 | publication-date=1990}}\n* {{Citation |author-link=Howard Jerome Keisler|first=H. Jerome|last=Keisler|title=Elementary Calculus: An Infinitesimal Approach|edition=2nd|year=1986|url=http://www.math.wisc.edu/~keisler/calc.html}}.\n* {{Citation | first=Anders|last= Kock|url=http://home.imf.au.dk/kock/sdg99.pdf|title= Synthetic Differential Geometry|publisher= Cambridge University Press|edition= 2nd|year=2006}}.\n* {{Citation | last1=Moerdijk|first1= I.|authorlink1=Ieke Moerdijk|last2=Reyes|first2=G.E.|title=Models for Smooth Infinitesimal Analysis|publisher= Springer-Verlag|year= 1991}}.\n* {{Citation | last1=Robinson | first1=Abraham | author1-link=Abraham Robinson | title=Non-standard analysis | publisher=[[Princeton University Press]] | isbn=978-0-691-04490-3 | year=1996}}.\n*{{springer|id=D/d031810|title=Differential|first=G.P.|last=Tolstov}}.\n\n==External links==\n*[http://demonstrations.wolfram.com/DifferentialOfAFunction/ Differential Of A Function] at Wolfram Demonstrations Project\n\n{{DEFAULTSORT:Differential Of A Function}}\n[[Category:Differential calculus]]\n[[Category:Generalizations of the derivative]]\n[[Category:Linear operators in calculus]]"
    },
    {
      "title": "Differentiation in Fréchet spaces",
      "url": "https://en.wikipedia.org/wiki/Differentiation_in_Fr%C3%A9chet_spaces",
      "text": "In [[mathematics]], in particular in [[functional analysis]] and [[nonlinear analysis]], it is possible to define the [[derivative (generalizations)|derivative]] of a function between two [[Fréchet space]]s.  This notion of differentiation, as it is [[Gateaux derivative]] between Fréchet spaces, is significantly weaker than the [[Fréchet derivative|derivative in a Banach space]], even between general [[topological vector space]]s.  Nevertheless, it is the weakest notion of differentiation for which many of the familiar theorems from [[calculus]] hold.  In particular, the [[chain rule]] is true.  With some additional constraints on the Fréchet spaces and functions involved, there is an analog of the [[inverse function theorem]] called the [[Nash–Moser inverse function theorem]], having wide applications in nonlinear analysis and [[differential geometry]].\n\n== Mathematical details ==\nFormally, the definition of differentiation is identical to the [[Gateaux derivative]].  Specifically, let ''X'' and ''Y'' be Fréchet spaces, ''U'' ⊂ ''X'' be an [[open set]], and ''F'' : ''U'' → ''Y'' be a function.  The directional derivative of ''F'' in the direction ''v'' ∈ ''X'' is defined by\n:<math>\nDF(u)v=\\lim_{\\tau\\rightarrow 0}\\frac{F(u+v \\tau)-F(u)}{\\tau}\n</math>\nif the limit exists.  One says that ''F'' is continuously differentiable, or ''C''<sup>1</sup> if the limit exists for all ''v''&nbsp;∈&nbsp;''X'' and the mapping\n:''DF'':''U'' x ''X'' &rarr; ''Y''\nis a [[continuous (topology)|continuous]] map.\n\nHigher order derivatives are defined inductively via\n:<math>D^{k+1}F(u)\\{v_1,v_2,\\dots,v_{k+1}\\} = \\lim_{\\tau\\rightarrow 0}\\frac{D^kF(u+\\tau v_{k+1})\\{v_1,\\dots,v_k\\}-D^kF(u)\\{v_1,\\dots,v_k\\}}{\\tau}.</math>\nA function is said to be ''C''<sup>k</sup> if ''D''<sup>k</sup>''F'' : ''U'' x ''X'' x ''X''x ... x ''X'' → ''Y'' is continuous.  It is ''C''<sup>∞</sup>, or '''smooth''' if it is ''C''<sup>k</sup> for every ''k''.\n\n== Properties ==\n\nLet ''X'', ''Y'', and ''Z'' be Fréchet spaces.  Suppose that ''U'' is an open subset of ''X'', ''V'' is an open subset of ''Y'', and ''F'' : ''U'' → ''V'', ''G'' : ''V'' → ''Z'' are a pair of ''C''<sup>1</sup> functions.  Then the following properties hold:\n\n* ('''Fundamental theorem of calculus'''.)  \n::If the line segment from ''a'' to ''b'' lies entirely within ''U'', then\n::<math> F(b)-F(a) = \\int_0^1 DF(a+(b-a)t)\\cdot (b-a) dt</math>.\n\n* ('''The chain rule'''.)\n::''D''(''G'' o ''F'')(''u'')''x'' = ''DG''(''F''(''u''))''DF''(''u'')''x''  for all ''u'' &epsilon; ''U'' and ''x'' &epsilon; ''X''.\n\n* ('''Linearity'''.)  \n::''DF''(''u'')''x'' is linear in ''x''.{{citation needed|date=March 2013}}  More generally, if ''F'' is ''C''<sup>k</sup>, then ''DF''(''u''){''x''<sub>1</sub>,...,''x''<sub>k</sub>} is multilinear in the x's.\n\n* ('''Taylor's theorem with remainder.''')\n::Suppose that the line segment between ''u'' &epsilon; ''U'' and ''u+h'' lies entirely within ''U''.  If ''F'' is ''C''<sup>k</sup> then\n::<math>F(u+h)=F(u)+DF(u)h+\\frac{1}{2!}D^2F(u)\\{h,h\\}+\\dots+\\frac{1}{(k-1)!}D^{k-1}F(u)\\{h,h,\\dots,h\\}+R_k</math>\n::where the remainder term is given by\n::<math>R_k(u,h)=\\frac{1}{(k-1)!}\\int_0^1(1-t)^{k-1}D^kF(u+th)\\{h,h,\\dots,h\\}dt</math>\n\n* ('''Commutativity of directional derivatives.''')  If ''F'' is ''C''<sup>k</sup>, then\n::<math>D^kF(u)\\{h_1,...,h_k\\}=D^kF(u)\\{h_{\\sigma(1)},\\dots,h_{\\sigma(k)}\\}</math> for every [[permutation]] &sigma; of {1,2,...,k}.\n\nThe proofs of many of these properties rely fundamentally on the fact that it is possible to define the [[Riemann integral]] of continuous curves in a Fréchet space.\n\n==Smooth mappings==\nSurprisingly, a mapping between open subset of Fréchet spaces is smooth (infinitely often differentiable) if it maps smooth curves to smooth curves; see [[Convenient analysis]].\nMoreover, smooth curves in spaces of smooth functions are just smooth functions of one variable more.\n\n==Consequences in differential geometry==\nThe existence of a chain rule allows for the definition of a [[manifold (mathematics)|manifold]] modeled on a Frèchet space: a [[Fréchet manifold]].  Furthermore, the linearity of the derivative implies that there is an analog of the [[tangent bundle]] for Fréchet manifolds.\n\n==Tame Fréchet spaces==\nFrequently the Fréchet spaces that arise in practical applications of the derivative enjoy an additional property: they are '''tame'''.  Roughly speaking, a tame Fréchet space is one which is almost a [[Banach space]].  On tame spaces, it is possible to define a preferred class of mappings, known as tame maps.  On the category of tame spaces under tame maps, the underlying topology is strong enough to support a fully fledged theory of [[differential topology]].  Within this context, many more techniques from calculus hold.  In particular, there are versions of the inverse and implicit function theorems.\n\n==References==\n# {{cite journal|author=Hamilton, R. S.|authorlink=Richard S. Hamilton|title=The inverse function theorem of Nash and Moser|url=http://projecteuclid.org/euclid.bams/1183549049|\njournal=Bull. Amer. Math. Soc.|issue=1|year=1982|pages=65–222|doi=10.1090/S0273-0979-1982-15004-2|volume=7|mr=656198}}\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Differentiation in Frechet spaces}}\n[[Category:Differential calculus]]\n[[Category:Generalizations of the derivative]]\n[[Category:Topological vector spaces]]"
    },
    {
      "title": "Dini derivative",
      "url": "https://en.wikipedia.org/wiki/Dini_derivative",
      "text": "\n\nIn [[mathematics]] and, specifically, [[real analysis]], the '''Dini derivatives''' (or '''Dini derivates''') are a class of generalizations of the [[derivative]]. They were introduced by [[Ulisse Dini]] who studied continuous but nondifferentiable functions, for which he defined the so-called Dini derivatives.\n\nThe '''upper Dini derivative''', which is also called an '''upper right-hand derivative''',<ref name=\"Khalil02\">{{cite book | last = Khalil | first = Hassan K. | year = 2002 | edition = 3rd | url = http://www.egr.msu.edu/~khalil/NonlinearSystems/ | isbn = 0-13-067389-7 | title = Nonlinear Systems | publisher = [[Prentice Hall]] | location = Upper Saddle River, NJ}}</ref> of a [[continuous function]]\n\n:<math>f:{\\mathbb R} \\rightarrow {\\mathbb R},</math>\n\nis denoted by {{math|''f''{{underset|+|′}}}} and defined by\n\n:<math>f'_+(t) \\triangleq \\limsup_{h \\to {0+}} \\frac{f(t + h) - f(t)}{h},</math>\n\nwhere {{math|lim sup}} is the [[supremum limit]] and the limit is a [[one-sided limit]]. The '''lower Dini derivative''', {{math|''f''{{underset|−|′}}}}, is defined by\n\n:<math>f'_-(t) \\triangleq \\liminf_{h \\to {0+}} \\frac{f(t + h) - f(t)}{h},</math>\n\nwhere {{math|lim inf}} is the [[infimum limit]].\n\nIf {{math|''f''}} is defined on a [[vector space]], then the upper Dini derivative at {{math|''t''}} in the direction {{math|''d''}} is defined by\n\n:<math>f'_+ (t,d) \\triangleq \\limsup_{h \\to {0+}} \\frac{f(t + hd) - f(t)}{h}.</math>\n\nIf {{math|''f''}} is [[locally]] [[Lipschitz continuity|Lipschitz]], then {{math|''f''{{underset|+|′}}}} is finite. If {{math|''f''}} is [[differentiable function|differentiable]] at {{math|''t''}}, then the Dini derivative at {{math|''t''}} is the usual [[derivative]] at {{math|''t''}}.\n\n==Remarks==\n* Sometimes the notation {{math|''D''<sup>+</sup> ''f''(''t'')}} is used instead of {{math|''f''{{underset|+|′}}(''t'')}} and {{math|''D''<sub>−</sub> ''f''(''t'')}} is used instead of {{math|''f''{{underset|−|′}}(''t'')}}.<ref name=\"Khalil02\"/>\n* Also,\n:<math>D^+f(t) \\triangleq \\limsup_{h \\to {0+}} \\frac{f(t) - f(t - h)}{h}</math>\n\nand\n\n:<math>D_-f(t) \\triangleq \\liminf_{h \\to {0-}} \\frac{f(t) - f(t - h)}{h}</math>.\n\n* So when using the {{math|''D''}} notation of the Dini derivatives, the plus or minus sign indicates the left- or right-hand limit, and the placement of the sign indicates the infimum or supremum limit.\n* On the [[extended real number line|extended reals]], each of the Dini derivatives always exist; however, they may take on the values {{math|+∞}} or {{math|−∞}} at times (i.e., the Dini derivatives always exist in the [[extended real number line|extended]] sense).\n\n==See also==\n\n* [[Denjoy–Young–Saks theorem]]\n* [[Derivative (generalizations)]]\n\n==References==\n{{reflist}}\n{{refbegin}}\n* {{springer|id=d/d032530|title=Dini derivative|first=T.P.|last=Lukashenko|year=2001}}.\n* {{Cite book |first=H. L. |last=Royden |title=Real Analysis |publisher=MacMillan |year=1968 |edition=2nd |isbn=978-0-02-404150-0}}\n* {{cite book|first1=Brian S. |last1=Thomson|first2=Judith B. |last2=Bruckner|first3=Andrew M. |last3=Bruckner|title=Elementary Real Analysis|year=2008|publisher=ClassicalRealAnalysis.com [first edition published by Prentice Hall in 2001]|isbn=978-1-4348-4161-2|pages=301–302}}\n{{refend}}\n\n{{PlanetMath attribution|id=4714|title=Dini derivative}}{{failed verification|date=April 2015}}\n\n[[Category:Generalizations of the derivative]]\n[[Category:Real analysis]]"
    },
    {
      "title": "Directional derivative",
      "url": "https://en.wikipedia.org/wiki/Directional_derivative",
      "text": "{{refimprove section|date=October 2012|talk=Verifiability of definition}}\n{{Calculus |Vector}}\n\nIn [[mathematics]], the '''directional derivative''' of a multivariate [[differentiable function]] along a given [[vector (mathematics)|vector]] '''v''' at a given point '''x''' intuitively represents the instantaneous rate of change of the function, moving through '''x''' with a velocity specified by '''v'''.  It therefore generalizes the notion of a [[partial derivative]], in which the rate of change is taken along one of the [[Curvilinear coordinates|curvilinear]] [[coordinate curves]], all other coordinates being constant.\n\nThe directional derivative is a special case of the [[Gateaux derivative]].\n\n== Notation ==\nLet ''&tau;'' be a curve whose tangent vector at some chosen point is '''v'''.  The directional derivative of a function ''f'' with respect to '''v''' may be denoted by any of the following\n*<math>\\nabla_{\\mathbf{v}}{f}(\\mathbf{x}),</math>\n*<math>f'_\\mathbf{v}(\\mathbf{x}),</math>\n*<math>D_\\mathbf{v}f(\\mathbf{x}),</math>\n*<math>Df(\\mathbf{x})(\\mathbf{v}),</math>\n*<math>\\partial_\\mathbf{v}f(\\mathbf{x}),</math>\n*<math>\\frac{\\partial{f(\\mathbf{x})}}{\\partial{\\mathbf{v}}},</math>\n*<math>\\mathbf{v}\\cdot{\\nabla f(\\mathbf{x})},</math>\n*<math>\\mathbf{v}\\cdot \\frac{\\partial f(\\mathbf{x})}{\\partial\\mathbf{x}}.</math>\n\n== Definition ==\n[[File:Directional derivative contour plot.svg|thumb|275px|A [[contour plot]] of <math>f(x, y)=x^2 + y^2</math>, showing the gradient vector in black, and the unit vector <math>\\mathbf{u}</math> scaled by the directional derivative in the direction of <math>\\mathbf{u}</math> in orange. The gradient vector is longer because the gradient points in the direction of greatest rate of increase of a function.]]\n\nThe ''directional derivative'' of a [[scalar function]] \n:<math>f(\\mathbf{x}) = f(x_1, x_2, \\ldots, x_n)</math>\nalong a vector\n:<math>\\mathbf{v} = (v_1, \\ldots, v_n)</math>\nis the [[function (mathematics)|function]] <math>\\nabla_{\\mathbf{v}}{f}</math> defined by the [[limit (mathematics)|limit]]<ref>{{cite book |author1=R. Wrede |author2=M.R. Spiegel | title=Advanced Calculus|edition=3rd| publisher=Schaum's Outline Series| year=2010 | isbn=978-0-07-162366-7}}</ref>\n:<math>\\nabla_{\\mathbf{v}}{f}(\\mathbf{x}) = \\lim_{h \\rightarrow 0}{\\frac{f(\\mathbf{x} + h\\mathbf{v}) - f(\\mathbf{x})}{h}}.</math>\n\nThis definition is valid in a broad range of contexts, for example where the [[Euclidean norm|norm]] of a vector (and hence a unit vector) is undefined.<ref>The applicability extends to functions over spaces without a [[metric (mathematics)|metric]] and to [[differentiable manifold]]s, such as in [[general relativity]].</ref>\n\nIf the function ''f'' is [[Differentiable function#Differentiability in higher dimensions|differentiable]] at '''x''', then the directional derivative exists along any vector '''v''', and one has\n\n:<math>\\nabla_{\\mathbf{v}}{f}(\\mathbf{x}) = \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}</math>\n\nwhere the <math>\\nabla</math> on the right denotes the gradient and <math>\\cdot</math> is the [[dot product]].<ref>If the dot product is undefined, the [[gradient]] is also undefined; however, for differentiable ''f'', the directional derivative is still defined, and a similar relation exists with the exterior derivative.</ref> This follows from defining a path <math>h(t)=x+tv</math> and using the definition of the derivative as a limit which can be calculated along this path to get:\n\n:<math>\n\\begin{align}\n0=\\lim_{t\\rightarrow 0}\\frac {f(x+tv)-f(x)-t*D_f(x)(v)} t =\\lim_{t\\rightarrow 0}\\frac {f(x+tv)-f(x)} t - D_f(x)(v)=\\nabla_v f(x)-D_f(x)(v) \\\\\n \\rightarrow \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}=D_f(x)(v)=\\nabla_{\\mathbf{v}}{f}(\\mathbf{x})\n\\end{align}\n</math>\n\nIntuitively, the directional derivative of ''f'' at a point '''x''' represents the [[derivative|rate of change]] of ''f'', in the direction of '''v''' with respect to time, when moving past '''x'''.\n\n=== Using only direction of vector ===\n[[image:Geometrical interpretation of a directional derivative.svg|thumb|The angle ''α'' between the tangent ''A'' and the horizontal will be maximum if the cutting plane contains the direction of the gradient ''A''.]]\nIn a [[Euclidean space]], some authors<ref>Thomas, George B. Jr.; and Finney, Ross L. (1979) ''Calculus and Analytic Geometry'', Addison-Wesley Publ. Co., fifth edition, p. 593.</ref> define the directional derivative to be with respect to an arbitrary nonzero vector '''v''' after [[Normalized vector|normalization]], thus being independent of its magnitude and depending only on its direction.<ref>This typically assumes a [[Euclidean space]] – for example, a function of several variables typically has no definition of the magnitude of a vector, and hence of a unit vector.</ref>\n\nThis definition gives the rate of increase of ''f'' per unit of distance moved in the direction given by '''v'''. In this case, one has\n:<math>\\nabla_{\\mathbf{v}}{f}(\\mathbf{x}) = \\lim_{h \\rightarrow 0}{\\frac{f(\\mathbf{x} + h\\mathbf{v}) - f(\\mathbf{x})}{h|\\mathbf{v}|}},</math>\nor in case ''f'' is differentiable at '''x''',\n:<math>\\nabla_{\\mathbf{v}}{f}(\\mathbf{x}) = \\nabla f(\\mathbf{x}) \\cdot \\frac{\\mathbf{v}}{|\\mathbf{v}|} .</math>\n\n=== Restriction to a unit vector ===\n\nIn the context of a function on a [[Euclidean space]], some texts restrict the vector '''v''' to being a [[unit vector]].  With this restriction, both the above definitions are equivalent.<ref>{{Cite book|url=https://www.worldcat.org/oclc/828768012|title=Calculus : Single and multivariable.|last=Hughes-Hallet|first=Deborah|last2=McCallum|first2=William G.|last3=Gleason|first3=Andrew M.|date=2012-01-01|publisher=John wiley|year=|isbn=9780470888612|location=|pages=780|oclc=828768012}}</ref>\n\n== Properties ==\nMany of the familiar properties of the ordinary [[derivative]] hold for the directional derivative.  These include, for any functions ''f'' and ''g'' defined in a [[neighborhood (mathematics)|neighborhood]] of, and [[total derivative|differentiable]] at, '''p''': \n{{ordered list\n|1=  '''[[Sum rule in differentiation|sum rule]]''':\n:<math>\\nabla_{\\mathbf{v}} (f + g) = \\nabla_{\\mathbf{v}} f + \\nabla_{\\mathbf{v}} g.</math>\n|2=  '''[[Constant factor rule in differentiation|constant factor rule]]''': For any constant ''c'', \n:<math>\\nabla_{\\mathbf{v}} (cf) = c\\nabla_{\\mathbf{v}} f.</math>\n|3=  '''[[product rule]]''' (or '''Leibniz's rule'''):\n:<math>\\nabla_{\\mathbf{v}} (fg) = g\\nabla_{\\mathbf{v}} f + f\\nabla_{\\mathbf{v}} g.</math>\n|4=  '''[[chain rule]]''': If ''g'' is differentiable at '''p''' and ''h'' is differentiable at ''g''('''p'''), then\n:<math>\\nabla_{\\mathbf{v}}(h\\circ g)(\\mathbf{p}) = h'(g(\\mathbf{p})) \\nabla_{\\mathbf{v}} g (\\mathbf{p}).</math>\n}}\n\n== In differential geometry ==\n{{see also|Tangent space#Tangent vectors as directional derivatives}}\n\nLet {{math|''M''}} be a [[differentiable manifold]] and {{math|'''p'''}} a point of {{math|''M''}}.  Suppose that {{math|''f''}} is a function defined in a neighborhood of {{math|'''p'''}}, and [[total derivative|differentiable]] at {{math|'''p'''}}.  If {{math|'''v'''}} is a [[tangent vector]] to {{math|''M''}} at {{math|'''p'''}}, then the '''directional derivative''' of {{math|''f''}} along {{math|'''v'''}}, denoted variously as {{math|''df''('''v''')}} (see [[Exterior derivative]]), <math>\\nabla_{\\mathbf{v}} f(\\mathbf{p})</math> (see [[Covariant derivative]]), <math>L_{\\mathbf{v}} f(\\mathbf{p})</math> (see [[Lie derivative]]), or <math>{\\mathbf{v}}_{\\mathbf{p}}(f)</math> (see {{section link|Tangent space|Definition via derivations}}), can be defined as follows.  Let {{math|''γ'' : [−1, 1] → ''M''}} be a differentiable curve with {{math|1=''γ''(0) = '''p'''}} and {{math|1=''γ''′(0) = '''v'''}}.  Then the directional derivative is defined by\n:<math>\\nabla_{\\mathbf{v}} f(\\mathbf{p}) = \\left.\\frac{d}{d\\tau} f\\circ\\gamma(\\tau)\\right|_{\\tau=0}.</math>\nThis definition can be proven independent of the choice of {{math|''γ''}}, provided {{math|''γ''}} is selected in the prescribed manner so that {{math|1=''γ''′(0) = '''v'''}}.\n\n===The Lie derivative===\nThe [[Lie derivative]] of a vector field <math>\\scriptstyle W^\\mu(x)</math> along a vector field <math>\\scriptstyle V^\\mu(x)</math> is given by the difference of two directional derivatives (with vanishing torsion):\n:<math>\\mathcal{L}_V W^\\mu=(V\\cdot\\nabla) W^\\mu-(W\\cdot\\nabla) V^\\mu.</math>\nIn particular, for a scalar field <math>\\scriptstyle \\phi(x)</math>, the Lie derivative reduces to the standard directional derivative:\n:<math>\\mathcal{L}_V \\phi=(V\\cdot\\nabla) \\phi.</math>\n\n===The Riemann tensor===\nDirectional derivatives are often used in introductory derivations of the [[Riemann curvature tensor]]. Consider a curved rectangle with an infinitesimal vector ''δ'' along one edge and ''δ''′ along the other. We translate a covector ''S'' along ''δ'' then ''δ''′ and then subtract the translation along ''δ''′ and then ''δ''. Instead of building the directional derivative using partial derivatives, we use the [[covariant derivative]]. The translation operator for ''δ'' is thus\n:<math>1+\\sum_\\nu \\delta^\\nu D_\\nu=1+\\delta\\cdot D,</math>\nand for ''δ''′,\n:<math>1+\\sum_\\mu \\delta'^\\mu D_\\mu=1+\\delta'\\cdot D.</math>\nThe difference between the two paths is then\n:<math>(1+\\delta'\\cdot D)(1+\\delta\\cdot D)S^\\rho-(1+\\delta\\cdot D)(1+\\delta'\\cdot D)S^\\rho=\\sum_{\\mu,\\nu}\\delta'^\\mu \\delta^\\nu[D_\\mu,D_\\nu]S_\\rho.</math>\nIt can be argued<ref>{{cite book|last1=Zee|first1=A.|title=Einstein gravity in a nutshell|date=2013|publisher=Princeton University Press|location=Princeton|isbn=9780691145587|page=341}}</ref> that the noncommutativity of the covariant derivatives measures the curvature of the manifold:\n:<math>[D_\\mu,D_\\nu]S_\\rho=\\pm \\sum_\\sigma R^\\sigma{}_{\\rho\\mu\\nu}S_\\sigma,</math>\nwhere ''R'' is the Riemann curvature tensor and the sign depends on the [[sign convention]] of the author.\n\n== In group theory ==\n\n===Translations===\nIn the [[Poincaré algebra]], we can define an infinitesimal translation operator '''P''' as\n:<math>\\mathbf{P}=i\\nabla.</math>\n(the i ensures that '''P''' is a [[self-adjoint operator]]) For a finite displacement '''λ''', the [[Unitary operator|unitary]] [[Hilbert space]] [[Group representation|representation]] for translations is<ref>{{cite book|last1=Weinberg|first1=Steven|title=The quantum theory of fields|date=1999|publisher=Cambridge Univ. Press|location=Cambridge [u.a.]|isbn=9780521550017|edition=Reprinted (with corr.).}}</ref> \n:<math>U(\\mathbf{\\lambda})=\\exp\\left(-i\\mathbf{\\lambda}\\cdot\\mathbf{P}\\right).</math>\nBy using the above definition of the infinitesimal translation operator, we see that the finite translation operator is an exponentiated directional derivative:\n:<math>U(\\mathbf{\\lambda})=\\exp\\left(\\mathbf{\\lambda}\\cdot\\nabla\\right).</math>\nThis is a translation operator in the sense that it acts on multivariable functions f('''x''') as\n:<math>U(\\mathbf{\\lambda}) f(\\mathbf{x})=\\exp\\left(\\mathbf{\\lambda}\\cdot\\nabla\\right) f(\\mathbf{x})=f(\\mathbf{x}+\\mathbf{\\lambda}).</math>\n\n{| class=\"toccolours collapsible collapsed\" width=\"80%\" style=\"text-align:left\"\n!Proof of the last equation\n|-\n|\nIn standard single-variable calculus, the derivative of a smooth function f(x) is defined by (for small ε)\n:<math>\\frac{df}{dx}=\\frac{f(x+\\epsilon)-f(x)}{\\epsilon}.</math>\nThis can be rearranged to find f(x+ε):\n:<math>f(x+\\epsilon)=f(x)+\\epsilon \\,\\frac{df}{dx}=\\left(1+\\epsilon\\,\\frac{d}{dx}\\right)f(x).</math>\nIt follows that <math>[1+\\epsilon\\,(d/dx)] </math> is a translation operator. This is instantly generalized<ref>{{cite book|last1=Zee|first1=A.|title=Einstein gravity in a nutshell|date=2013|publisher=Princeton University Press|location=Princeton|isbn=9780691145587}}</ref> to multivariable functions f('''x''')\n:<math>f(\\mathbf{x}+\\mathbf{\\epsilon})=\\left(1+\\mathbf{\\epsilon}\\cdot\\nabla\\right)f(\\mathbf{x}).</math>\nHere <math> \\mathbf{\\epsilon}\\cdot\\nabla</math> is the directional derivative along the infinitesimal displacement '''ε'''. We have found the infinitesimal version of the translation operator:\n:<math>U(\\mathbf{\\epsilon})=1+\\mathbf{\\epsilon}\\cdot\\nabla.</math>\nIt is evident that the group multiplication law<ref>{{cite book|last1=Mexico|first1=Kevin Cahill, University of New|title=Physical mathematics|date=2013|publisher=Cambridge University Press|location=Cambridge|isbn=978-1107005211|edition=Repr.}}</ref> U(g)U(f)=U(gf) takes the form\n:<math>U(\\mathbf{a})U(\\mathbf{b})=U(\\mathbf{a+b}).</math>\nSo suppose that we take the finite displacement '''λ''' and divide it into N parts (N→∞ is implied everywhere), so that '''λ'''/N='''ε'''. In other words,\n:<math>\\mathbf{\\lambda}=N\\mathbf{\\epsilon}.</math>\nThen by applying U('''ε''') N times, we can construct U('''λ'''):\n:<math>[U(\\mathbf{\\epsilon})]^N=U(N\\mathbf{\\epsilon})=U(\\mathbf{\\lambda}).</math>\nWe can now plug in our above expression for U('''ε'''):\n:<math>[U(\\mathbf{\\epsilon})]^N=\\left[1+\\mathbf{\\epsilon}\\cdot\\nabla\\right]^N=\\left[1+\\frac{\\mathbf{\\lambda}\\cdot\\nabla}{N}\\right]^N.</math>\nUsing the identity<ref>{{cite book|last1=Edwards|first1=Ron Larson, Robert, Bruce H.|title=Calculus of a single variable|date=2010|publisher=Brooks/Cole|location=Belmont|isbn=9780547209982|edition=9th}}</ref>\n:<math>\\exp(x)=\\left[1+\\frac{x}{N}\\right]^N,</math>\nwe have\n:<math>U(\\mathbf{\\lambda})=\\exp\\left(\\mathbf{\\lambda}\\cdot\\nabla\\right).</math>\nAnd since U('''ε''')f('''x''')=f('''x'''+'''ε''') we have\n:<math>[U(\\mathbf{\\epsilon})]^Nf(\\mathbf{x})=f(\\mathbf{x}+N\\mathbf{\\epsilon})=f(\\mathbf{x}+\\mathbf{\\lambda})=U(\\mathbf{\\lambda})f(\\mathbf{x})=\\exp\\left(\\mathbf{\\lambda}\\cdot\\nabla\\right)f(\\mathbf{x}),</math>\nQ.E.D.\n\nAs a technical note, this procedure is only possible because the translation group forms an [[abelian group|Abelian]] [[subgroup]] ([[Cartan subalgebra]]) in the Poincaré algebra. In particular, the group multiplication law U('''a''')U('''b''')=U('''a'''+'''b''') should not be taken for granted. We also note that Poincaré is a connected Lie group. It is a group of transformations  T(ξ) that are described by a continuous set of real parameters <math>\\scriptstyle \\xi^a</math>. The group multiplication law takes the form\n:<math>T(\\bar{\\xi})T(\\xi)=T(f(\\bar{\\xi},\\xi)).</math>\nTaking <math>\\scriptstyle \\xi^a</math>=0 as the coordinates of the identity, we must have\n:<math>f^a(\\xi,0)=f^a(0,\\xi)=\\xi^a.</math>\nThe actual operators on the Hilbert space are represented by unitary operators U(T(ξ)). In the above notation we suppressed the T; we now write U('''λ''') as U('''P'''('''λ''')). For a small neighborhood around the identity, the power series representation \n:<math>U(T(\\xi))=1+i\\sum_a\\xi^a t_a+\\frac{1}{2}\\sum_{b,c}\\xi^b\\xi^c t_{bc}+\\cdots</math>\nis quite good. Suppose that U(T(ξ)) form a non-projective representation, i.e. that\n:<math>U(T(\\bar{\\xi}))U(T(\\xi))=U(T(f(\\bar{\\xi},\\xi))).</math>\nThe expansion of f to second power is\n:<math>f^a(\\bar{\\xi},\\xi)=\\xi^a+\\bar{\\xi}^a+\\sum_{b,c}f^{abc}\\bar{\\xi}^b\\xi^c.</math>\nAfter expanding the representation multiplication equation and equating coefficients, we have the nontrivial condition\n:<math>t_{bc}=-t_b t_c-i\\sum_a f^{abc}t_a.</math>\nSince <math>\\scriptstyle t_{ab}</math> is by definition symmetric in its indices, we have the standard [[Lie algebra]] commutator:\n:<math>[t_b, t_c]=i\\sum_a(-f^{abc}+f^{acb})t_a=i\\sum_a C^{abc}t_a,</math>\nwith C the [[structure constant]]. The generators for translations are partial derivative operators, which commute:\n:<math>\\left[\\frac{\\partial}{\\partial x^b},\\frac{\\partial }{\\partial x^c}\\right]=0.</math>\nThis implies that the structure constants vanish and thus the quadratic coefficients in the f expansion vanish as well. This means that f is simply additive:\n:<math>f^a_\\text{abelian}(\\bar{\\xi},\\xi)=\\xi^a+\\bar{\\xi}^a,</math>\nand thus for abelian groups,\n:<math>U(T(\\bar{\\xi}))U(T(\\xi))=U(T(\\bar{\\xi}+\\xi)).</math>\nQ.E.D.\n|}\n\n===Rotations===\nThe [[rotation operator (quantum mechanics)|rotation operator]] also contains a directional derivative. The rotation operator for an angle '''θ''', i.e. by an amount θ=|'''θ'''| about an axis parallel to <math>\\scriptstyle \\hat{\\theta}</math>='''θ'''/θ is\n:<math>U(R(\\mathbf{\\theta}))=\\exp(-i\\mathbf{\\theta}\\cdot\\mathbf{L}).</math>\nHere '''L''' is the vector operator that generates [[SO(3)]]:\n:<math>\\mathbf{L}=\\begin{pmatrix}\n 0& 0 & 0\\\\ \n 0& 0 & 1\\\\ \n 0& -1 & 0\n\\end{pmatrix}\\mathbf{i}+\\begin{pmatrix}\n0 &0  & -1\\\\ \n 0& 0 &0 \\\\ \n1 & 0 & 0\n\\end{pmatrix}\\mathbf{j}+\\begin{pmatrix}\n 0&1  &0 \\\\ \n -1&0  &0 \\\\ \n0 & 0 & 0\n\\end{pmatrix}\\mathbf{k}.</math>\nIt may be shown geometrically that an infinitesimal right-handed rotation changes the position vector '''x''' by\n:<math>\\mathbf{x}\\rightarrow \\mathbf{x}-\\delta\\mathbf{\\theta}\\times\\mathbf{x}.</math>\nSo we would expect under infinitesimal rotation:\n:<math>U(R(\\delta\\mathbf{\\theta}))f(\\mathbf{x})=f(\\mathbf{x}-\\delta\\mathbf{\\theta}\\times\\mathbf{x})=f(\\mathbf{x})-(\\delta\\mathbf{\\theta}\\times\\mathbf{x})\\cdot\\nabla f.</math>\nIt follows that \n:<math>U(R(\\delta\\mathbf{\\theta}))=1-(\\delta\\mathbf{\\theta}\\times\\mathbf{x})\\cdot\\nabla.</math>\nFollowing the same exponentiation procedure as above, we arrive at the rotation operator in the position basis, which is an exponentiated directional derivative:<ref>{{cite book|last1=Shankar|first1=R.|title=Principles of quantum mechanics|date=1994|publisher=Kluwer Academic / Plenum|location=New York|isbn=9780306447907|page=318|edition=2nd}}</ref>\n:<math>U(R(\\mathbf{\\theta}))=\\exp(-(\\mathbf{\\theta}\\times\\mathbf{x})\\cdot\\nabla).</math>\n\n== Normal derivative ==\n\nA '''normal derivative''' is a directional derivative taken in the direction normal (that is, [[orthogonal]]) to some surface in space, or more generally along a [[normal vector]] field orthogonal to some [[hypersurface]]. See for example [[Neumann boundary condition]].  If the normal direction is denoted by <math>\\mathbf{n}</math>, then the directional derivative of a function ''f'' is sometimes denoted as <math>\\frac{ \\partial f}{\\partial n}</math>.  In other notations,\n:<math>\\frac{ \\partial f}{\\partial \\mathbf{n}} = \\nabla f(\\mathbf{x}) \\cdot \\mathbf{n} = \\nabla_{\\mathbf{n}}{f}(\\mathbf{x}) = \\frac{\\partial f}{\\partial \\mathbf{x}}\\cdot\\mathbf{n} = Df(\\mathbf{x})[\\mathbf{n}].</math>\n\n== In the continuum mechanics of solids ==\n\nSeveral important results in continuum mechanics require the derivatives of vectors with respect to vectors and of [[tensors]] with respect to vectors and tensors.<ref name=Marsden00>J. E. Marsden and T. J. R. Hughes, 2000, ''Mathematical Foundations of Elasticity'', Dover.</ref>  The '''directional directive''' provides a systematic way of finding these derivatives.\n\nThe definitions of directional derivatives for various situations are given below.  It is assumed that the functions are sufficiently smooth that derivatives can be taken.\n\n===Derivatives of scalar-valued functions of vectors===\nLet <math>f(\\mathbf{v})</math> be a real-valued function of the vector <math>\\mathbf{v}</math>.  Then the derivative of <math>f(\\mathbf{v})</math> with respect to <math>\\mathbf{v}</math> (or at <math>\\mathbf{v}</math>) in the direction <math>\\mathbf{u}</math> is defined as\n:<math>\n  \\frac{\\partial f}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} = Df(\\mathbf{v})[\\mathbf{u}] \n     = \\left[\\frac{d }{d \\alpha}~f(\\mathbf{v} + \\alpha~\\mathbf{u})\\right]_{\\alpha = 0}\n</math>\nfor all vectors <math>\\mathbf{u}</math>.\n\n''Properties:''\n{{ordered list\n|1= If <math>f(\\mathbf{v}) = f_1(\\mathbf{v}) + f_2(\\mathbf{v})</math> then <math>\n   \\frac{\\partial f}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} =  \\left(\\frac{\\partial f_1}{\\partial \\mathbf{v}} + \\frac{\\partial f_2}{\\partial \\mathbf{v}}\\right)\\cdot\\mathbf{u}.\n </math>\n\n|2= If <math>f(\\mathbf{v}) = f_1(\\mathbf{v})~ f_2(\\mathbf{v})</math> then <math>\n   \\frac{\\partial f}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} =  \\left(\\frac{\\partial f_1}{\\partial \\mathbf{v}}\\cdot\\mathbf{u}\\right)~f_2(\\mathbf{v}) + f_1(\\mathbf{v})~\\left(\\frac{\\partial f_2}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} \\right).\n </math>\n\n|3= If <math>f(\\mathbf{v}) = f_1(f_2(\\mathbf{v}))</math> then <math>\n   \\frac{\\partial f}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} =  \\frac{\\partial f_1}{\\partial f_2}~\\frac{\\partial f_2}{\\partial \\mathbf{v}}\\cdot\\mathbf{u}.\n </math>\n}}\n\n===Derivatives of vector-valued functions of vectors===\nLet <math>\\mathbf{f}(\\mathbf{v})</math> be a vector-valued function of the vector <math>\\mathbf{v}</math>.  Then the derivative of <math>\\mathbf{f}(\\mathbf{v})</math> with respect to <math>\\mathbf{v}</math> (or at <math>\\mathbf{v}</math>) in the direction <math>\\mathbf{u}</math> is the '''second-order tensor''' defined as\n:<math>\n  \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} = D\\mathbf{f}(\\mathbf{v})[\\mathbf{u}] \n     = \\left[\\frac{d }{d \\alpha}~\\mathbf{f}(\\mathbf{v} + \\alpha~\\mathbf{u})\\right]_{\\alpha = 0}\n</math>\nfor all vectors <math>\\mathbf{u}</math>.\n\n''Properties:''\n{{ordered list\n|1= If <math>\\mathbf{f}(\\mathbf{v}) = \\mathbf{f}_1(\\mathbf{v}) + \\mathbf{f}_2(\\mathbf{v})</math> then <math>\n   \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} =  \\left(\\frac{\\partial \\mathbf{f}_1}{\\partial \\mathbf{v}} + \\frac{\\partial \\mathbf{f}_2}{\\partial \\mathbf{v}}\\right)\\cdot\\mathbf{u} .\n </math>\n\n|2= If <math>\\mathbf{f}(\\mathbf{v}) = \\mathbf{f}_1(\\mathbf{v})\\times\\mathbf{f}_2(\\mathbf{v})</math> then <math>\n   \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} =  \\left(\\frac{\\partial \\mathbf{f}_1}{\\partial \\mathbf{v}}\\cdot\\mathbf{u}\\right)\\times\\mathbf{f}_2(\\mathbf{v}) + \\mathbf{f}_1(\\mathbf{v})\\times\\left(\\frac{\\partial \\mathbf{f}_2}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} \\right).\n </math>\n\n|3= If <math>\\mathbf{f}(\\mathbf{v}) = \\mathbf{f}_1(\\mathbf{f}_2(\\mathbf{v}))</math> then <math>\n   \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} =  \\frac{\\partial \\mathbf{f}_1}{\\partial \\mathbf{f}_2}\\cdot\\left(\\frac{\\partial \\mathbf{f}_2}{\\partial \\mathbf{v}}\\cdot\\mathbf{u} \\right).\n </math>\n}}\n\n===Derivatives of scalar-valued functions of second-order tensors===\nLet <math>f(\\mathbf{S})</math> be a real-valued function of the second order tensor <math>\\mathbf{S}</math>.  Then the derivative of <math>f(\\mathbf{S})</math> with respect to <math>\\mathbf{S}</math> (or at <math>\\mathbf{S}</math>) in the direction\n<math>\\mathbf{T}</math> is the ''' second order tensor''' defined as\n:<math>\n  \\frac{\\partial f}{\\partial \\mathbf{S}}:\\mathbf{T} = Df(\\mathbf{S})[\\mathbf{T}] \n     = \\left[\\frac{d }{d \\alpha}~f(\\mathbf{S} + \\alpha\\mathbf{T})\\right]_{\\alpha = 0}\n</math>\nfor all second order tensors <math>\\mathbf{T}</math>.\n\n''Properties:''\n{{ordered list\n|1=  If <math>f(\\mathbf{S}) = f_1(\\mathbf{S}) + f_2(\\mathbf{S})</math> then <math> \\frac{\\partial f}{\\partial \\mathbf{S}}:\\mathbf{T} =  \\left(\\frac{\\partial f_1}{\\partial \\mathbf{S}} + \\frac{\\partial f_2}{\\partial \\mathbf{S}}\\right):\\mathbf{T}.</math>\n\n|2= If <math>f(\\mathbf{S}) = f_1(\\mathbf{S})~ f_2(\\mathbf{S})</math> then <math> \\frac{\\partial f}{\\partial \\mathbf{S}}:\\mathbf{T} =  \\left(\\frac{\\partial f_1}{\\partial \\mathbf{S}}:\\mathbf{T}\\right)~f_2(\\mathbf{S}) + f_1(\\mathbf{S})~\\left(\\frac{\\partial f_2}{\\partial \\mathbf{S}}:\\mathbf{T} \\right).</math>\n\n|3= If <math>f(\\mathbf{S}) = f_1(f_2(\\mathbf{S}))</math> then <math> \\frac{\\partial f}{\\partial \\mathbf{S}}:\\mathbf{T} =  \\frac{\\partial f_1}{\\partial f_2}~\\left(\\frac{\\partial f_2}{\\partial \\mathbf{S}}:\\mathbf{T} \\right).</math>\n}}\n\n===Derivatives of tensor-valued functions of second-order tensors===\nLet <math>\\mathbf{F}(\\mathbf{S})</math> be a second order tensor-valued function of the second order tensor <math>\\mathbf{S}</math>.  Then the derivative of <math>\\mathbf{F}(\\mathbf{S})</math> with respect to <math>\\mathbf{S}</math> \n(or at <math>\\mathbf{S}</math>) in the direction <math>\\mathbf{T}</math> is the ''' fourth order tensor''' defined as\n:<math>\n  \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{S}}:\\mathbf{T} = D\\mathbf{F}(\\mathbf{S})[\\mathbf{T}] \n     = \\left[\\frac{d }{d \\alpha}~\\mathbf{F}(\\mathbf{S} + \\alpha\\mathbf{T})\\right]_{\\alpha = 0}\n</math>\nfor all second order tensors <math>\\mathbf{T}</math>.\n\n''Properties:''\n{{ordered list\n|1= If <math>\\mathbf{F}(\\mathbf{S}) = \\mathbf{F}_1(\\mathbf{S}) + \\mathbf{F}_2(\\mathbf{S})</math> then <math> \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{S}}:\\mathbf{T} =  \\left(\\frac{\\partial \\mathbf{F}_1}{\\partial \\mathbf{S}} + \\frac{\\partial \\mathbf{F}_2}{\\partial \\mathbf{S}}\\right):\\mathbf{T}.</math>\n\n|2= If <math>\\mathbf{F}(\\mathbf{S}) = \\mathbf{F}_1(\\mathbf{S})\\cdot\\mathbf{F}_2(\\mathbf{S})</math> then <math> \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{S}}:\\mathbf{T} =  \\left(\\frac{\\partial \\mathbf{F}_1}{\\partial \\mathbf{S}}:\\mathbf{T}\\right)\\cdot\\mathbf{F}_2(\\mathbf{S}) + \\mathbf{F}_1(\\mathbf{S})\\cdot\\left(\\frac{\\partial \\mathbf{F}_2}{\\partial \\mathbf{S}}:\\mathbf{T} \\right).</math>\n\n|3= If <math>\\mathbf{F}(\\mathbf{S}) = \\mathbf{F}_1(\\mathbf{F}_2(\\mathbf{S}))</math> then <math> \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{S}}:\\mathbf{T} =  \\frac{\\partial \\mathbf{F}_1}{\\partial \\mathbf{F}_2}:\\left(\\frac{\\partial \\mathbf{F}_2}{\\partial \\mathbf{S}}:\\mathbf{T} \\right).</math>\n\n|4= If <math>f(\\mathbf{S}) = f_1(\\mathbf{F}_2(\\mathbf{S}))</math> then <math> \\frac{\\partial f}{\\partial \\mathbf{S}}:\\mathbf{T} =  \\frac{\\partial f_1}{\\partial \\mathbf{F}_2}:\\left(\\frac{\\partial \\mathbf{F}_2}{\\partial \\mathbf{S}}:\\mathbf{T} \\right).</math>\n}}\n\n== See also ==\n* [[Fréchet derivative]]\n* [[Gateaux derivative]]\n* [[Derivative (generalizations)]]\n* [[Lie derivative]]\n* [[Differential form]]\n* [[Structure tensor]]\n* [[Tensor derivative (continuum mechanics)]]\n* [[Del in cylindrical and spherical coordinates]]\n\n== Notes ==\n{{reflist|2}}\n\n== References ==\n*{{cite book | first=F. B. | last=Hildebrand | title=Advanced Calculus for Applications| publisher=Prentice Hall | year=1976 | isbn=0-13-011189-9 }}\n*{{cite book |author1=K.F. Riley |author2=M.P. Hobson |author3=S.J. Bence | title=Mathematical methods for physics and engineering| publisher=Cambridge University Press| year=2010 | isbn=978-0-521-86153-3}}\n\n== External links ==\n*[http://mathworld.wolfram.com/DirectionalDerivative.html Directional derivatives] at [[MathWorld]].\n*[http://planetmath.org/directionalderivative Directional derivative] at [[PlanetMath]].\n\n[[Category:Differential calculus]]\n[[Category:Differential geometry]]\n[[Category:Generalizations of the derivative]]\n[[Category:Multivariable calculus]]"
    },
    {
      "title": "Distribution (mathematics)",
      "url": "https://en.wikipedia.org/wiki/Distribution_%28mathematics%29",
      "text": "{{about|generalized functions in mathematical analysis|the concept of distributions in probability theory|Probability distribution|artificial landscapes|Test functions for optimization|other uses|Distribution (disambiguation)#In mathematics{{!}}Distribution § Mathematics}}\n\n'''Distributions''' (or '''[[generalized functions]]''') are objects that generalize the classical notion of functions in [[mathematical analysis]].  Distributions make it possible to [[derivative|differentiate]] functions whose derivatives do not exist in the classical sense.  In particular, any [[locally integrable]] function has a distributional derivative.  Distributions are widely used in the theory of [[partial differential equation]]s, where it may be easier to establish the existence of distributional solutions than classical solutions, or appropriate classical solutions may not exist. Distributions are also important in [[physics]] and [[engineering]] where many problems naturally lead to differential equations whose solutions or initial conditions are distributions, such as the [[Dirac delta]] function (which is a distribution, not a function as its historical name might suggest).\n\nThe practical use of distributions can be traced back to the use of [[Green's function|Green functions]] in the 1830s to solve\nordinary differential equations, but was not formalized until much later.  According to {{harvtxt|Kolmogorov|Fomin|1957}}, generalized functions originated in the work of {{harvs|txt|authorlink=Sergei Lvovich Sobolev|first=Sergei|last= Sobolev|year=1936}} on second-order hyperbolic partial differential equations, and the ideas were developed in somewhat extended form  by [[Laurent Schwartz]] in the late 1940s. According to his autobiography, Schwartz introduced the term \"distribution\" by analogy with a distribution of electrical charge, possibly including not only point charges but also dipoles and so on. {{harvtxt|Gårding|1997}} comments that although the ideas in the transformative book by {{harvtxt|Schwartz|1951}} were not entirely new, it was Schwartz's broad attack and conviction that distributions would be useful almost everywhere in analysis that made the difference.\n\nDistribution theory reinterprets functions as linear functionals acting on a space of '''test functions'''. Standard functions act by integration against a test function, but many other linear functionals do not arise in this way, and these are the \"generalized functions\". There are different possible choices for the space of test functions, leading to different spaces of distributions. The basic space of test function consists of smooth functions with [[compact support]], leading to standard distributions. Use of the space of smooth, rapidly (faster than any polynomial increases) decreasing test functions (these functions are called [[Schwartz space|Schwartz functions]]) gives instead the tempered distributions, which are important because they have a well-defined distributional Fourier transform.  Every tempered distribution is a distribution in the normal sense, but the converse is not true: in general the larger the space of test functions, the more restrictive the notion of distribution.  On the other hand, the use of spaces of analytic test functions leads to Sato's theory of [[hyperfunction]]s; this theory has a different character from the previous ones because there are no analytic functions with non-empty compact support.\n\n== Basic idea ==\n\n[[File:Mollifier Illustration.svg|right|thumb|280px|A typical test function, the [[bump function]] ''Ψ''(''x''). It is [[smooth function|smooth]] (infinitely differentiable) and has [[compact support]] (is zero outside an interval, in this case the interval [−1, 1]).]]\n\nDistributions are a class of [[linear functional]]s that map a set of ''test functions'' (conventional and [[well-behaved]] functions) into the set of real numbers. In the simplest case, the set of test functions considered is D('''R'''), which is the set of functions ''φ'' : '''R''' → '''R''' having two properties:\n* ''φ'' is [[smooth function|smooth]] (infinitely differentiable);\n* ''φ'' has [[compact support]] (is identically zero outside some bounded interval).\nA distribution ''T'' is a linear mapping ''T'' : D('''R''') → '''R'''. Instead of writing ''T''(''<math>\\varphi</math>''), it is conventional to write <math>\\langle T,\\varphi \\rangle</math> for the value of ''T'' acting on a  test function ''<math>\\varphi</math>''. A simple example of a distribution is the [[Dirac delta]] ''δ'', defined by\n\n: <math>\\left\\langle \\delta, \\varphi \\right\\rangle = \\varphi(0),</math>\n\nmeaning that ''δ'' evaluates a test function at 0. Its physical interpretation is as the density of a point source.\n \nAs described next, there are straightforward mappings from both [[locally integrable function]]s and [[Radon measure]]s to corresponding distributions, but not all distributions can be formed in this manner.\n\n===Functions and measures as distributions===\nSuppose that ''f'' : '''R''' → '''R''' is a locally integrable function. Then a corresponding distribution ''T<sub>f</sub>'' may be defined by\n\n: <math>\\left\\langle T_{f}, \\varphi \\right\\rangle = \\int_\\mathbf{R} f(x) \\varphi(x) \\,dx\\qquad \\text{for} \\quad \\varphi\\in D(\\mathbf{R}).</math>\n\nThis integral is a [[real number]] which depends [[linear operator|linearly]] and [[Continuous function|continuously]] on <math>\\varphi</math>.  Conversely, the values of the distribution ''T<sub>f</sub>'' on test functions in D('''R''') determine the pointwise almost everywhere values of the function ''f'' on '''R'''.   In a conventional [[abuse of notation]], ''f'' is often used to represent both the original function ''f'' and the corresponding distribution ''T<sub>f</sub>''. This example suggests the definition of a distribution as a linear and, in an appropriate sense, continuous [[functional (mathematics)|functional]] on the space of test functions D('''R''').\n\nSimilarly, if μ is a [[Radon measure]] on '''R''', then a corresponding distribution ''R''<sub>μ</sub> may be defined by\n\n: <math>\\left\\langle R_\\mu, \\varphi \\right\\rangle = \\int_{\\mathbf{R}} \\varphi\\, d\\mu\\qquad \\text{for} \\quad \\varphi\\in D(\\mathbf{R}). </math>\n\nThis integral also depends linearly and continuously on <math>\\varphi</math>, so that ''R''<sub>μ</sub> is a distribution. If μ is [[absolute continuity|absolutely continuous]] with respect to Lebesgue measure with density ''f'' and ''d''μ = ''f'' ''dx'', then this definition for ''R''<sub>μ</sub> is the same as the previous one for ''T<sub>f</sub>'', but if μ is not absolutely continuous, then ''R''<sub>μ</sub> is a distribution that is not associated with a function. For example, if ''P'' is the point-mass measure on '''R''' that assigns measure one to the singleton set {0} and measure zero to sets that do not contain zero, then\n\n: <math>\\int_{\\mathbf{R}} \\varphi\\, dP = \\varphi(0), </math>\n\nso that ''R''<sub>''P''</sub> = ''δ'' is the Dirac delta.\n\n===Adding and multiplying distributions===\nDistributions may be multiplied by real numbers and added together, so they form a real [[vector space]].\nDistributions may also be multiplied by infinitely differentiable functions, but \n[[Distribution_(mathematics)#Problem of multiplication|it is not possible to define a product of general distributions]] that extends the usual pointwise product of functions and has the same algebraic properties. This result was shown by {{harvtxt|Schwartz|1954}}, and is usually referred to as the \n''Schwartz Impossibility Theorem''.\n\n===Derivatives of distributions===\nIt is desirable to choose a definition for the derivative of a distribution which, at least for distributions derived from smooth functions, has the property that <math>T'_f = T_{f'}</math>. If <math>\\varphi</math> is a test function, we can use [[integration by parts]] to see that\n\n:<math>\\left\\langle f', \\varphi\\right\\rangle = \\int_{\\mathbf{R}} f'\\varphi \\,dx = \\Big[ f(x) \\varphi(x) \\Big]_{-\\infty}^\\infty - \\int_{\\mathbf{R}} f\\varphi' \\,dx = -\\left\\langle f, \\varphi' \\right\\rangle</math>\n\nwhere the last equality follows from the fact that <math>\\varphi</math> has compact support, so is zero outside of a bounded set. This suggests that if <math>T</math> is a ''distribution'', we should define its derivative <math>T'</math> by\n\n: <math>\\left\\langle T', \\varphi \\right\\rangle = - \\left\\langle T, \\varphi' \\right\\rangle.</math>\n\nIt turns out that this is the proper definition; it extends the ordinary definition of derivative, every distribution becomes infinitely differentiable and the usual properties of derivatives hold.\n\n'''Example:''' Recall that the [[Dirac delta]] (so-called Dirac delta function) is the distribution defined by the equation\n\n: <math>\\left\\langle \\delta, \\varphi \\right\\rangle = \\varphi(0).</math>\n\nIt is the derivative of the distribution corresponding to the [[Heaviside step function]] ''H'': For any test function&nbsp;''φ'',\n\n: <math>\\left\\langle H', \\varphi \\right\\rangle = - \\int_{-\\infty}^\\infty H(x) \\varphi'(x) \\, dx = - \\varphi(\\infty) +\\varphi(0) = \\left\\langle \\delta, \\varphi \\right\\rangle,</math>\n\nso ''H''′ = ''δ''. Note, <math>\\varphi</math>(∞) = 0 because <math>\\varphi</math> has compact support by our definition of a test function. Similarly, the derivative of the Dirac delta is the distribution defined by the equation\n\n:<math>\\langle\\delta',\\varphi\\rangle= -\\varphi'(0).</math>\n\nThis latter distribution is an example of a distribution that is not derived from a function or a measure. Its physical interpretation is the density of a dipole source. Just as the Dirac impulse can be realized in the weak limit as a sequence of various kinds of constant norm bump functions of ever increasing amplitude and narrowing support, its derivative can by definition be realized as the weak limit of the negative derivatives of said functions, which are now antisymmetric about the eventual distribution's point of singular support.\n\n== Test functions and distributions ==\n\nIn the following, real-valued distributions on an [[open set|open subset]] ''U'' of '''R'''<sup>''n''</sup> will be formally defined. With minor modifications, one can also define complex-valued distributions, and one can replace '''R'''<sup>''n''</sup> by any ([[paracompactness|paracompact]]) [[smooth manifold]].\n\nThe first object to define is the space D(''U'') of test functions on ''U''.  Once this is defined, it is then necessary to equip it with a [[topology]] by defining the [[limit of a sequence]] of elements of D(''U'').  The space of distributions will then be given as the space of [[continuous linear functional]]s on D(''U'').\n\n=== Test function space ===\n\nThe space D(''U'') of '''test functions''' on ''U'' is defined as follows. A function ''φ'' : ''U'' → '''R''' is said to have [[Compact support#Compact support|compact support]] if there exists a [[compact space|compact]] subset ''K'' of ''U'' such that ''φ''(''x'') = 0 for all ''x'' in ''U'' \\ ''K''. The elements of D(''U'') are the infinitely differentiable functions ''φ'' : ''U'' → '''R''' with compact support – also known as [[bump function]]s. This is a real [[vector space]].  It can be given a [[topology]] by defining the [[limit of a sequence]] of elements of D(''U'').  A sequence (''φ''<sub>''k''</sub>) in D(''U'') is said to converge to ''φ''&nbsp;∈&nbsp;D(''U'') if the following two conditions hold:<ref>According to {{harv|Gel'fand|Shilov|1966–1968|loc=v. 1, §1.2}}</ref>\n\n* There is a compact set ''K''&nbsp;⊂&nbsp;''U'' containing the supports of all ''φ''<sub>''k''</sub>:\n\n::<math>\\bigcup\\nolimits_k \\operatorname{supp}(\\varphi_k)\\subset K.</math>\n\n* For each [[multi-index]] α, the sequence of partial derivatives <math>\\partial^\\alpha \\varphi_k</math> tends [[uniform convergence|uniformly]] to <math>\\partial^\\alpha\\varphi</math>.\n\nWith this definition, D(''U'') becomes a [[completeness (topology)|complete]] [[locally convex]] [[topological vector space]] satisfying the [[Heine–Borel theorem|Heine–Borel property]].<ref>See for example {{harv|Rudin|1991|loc=§6.4–5}}.</ref>\n\nThis topology can be placed in the context of the following general construction: let\n\n:<math>X = \\bigcup\\nolimits_i X_i</math>\n\nbe a countable increasing union of locally convex topological vector spaces and ι<sub>''i''</sub> : ''X<sub>i</sub>'' → ''X'' be the inclusion maps. In this context, the [[inductive limit]] topology, or [[final topology]], τ on ''X'' is the finest locally convex vector space topology making all the inclusion maps <math>\\iota_i</math> continuous. The topology τ can be explicitly described as follows: let ''β'' be the collection of convex balanced subsets ''W'' of ''X'' such that ''W'' ∩ ''X<sub>i</sub>'' is open for all ''i''. A base for the inductive limit topology τ then consists of the sets of the form ''x'' + ''W'', where ''x'' in ''X'' and ''W'' in ''β''.\n\nThe proof that τ is a vector space topology makes use of the assumption that each ''X<sub>i</sub>'' is locally convex. By construction, ''β'' is a local base for ''τ''. That any locally convex vector space topology on ''X'' must necessarily contain ''τ'' means it is the weakest one. One can also show that, for each ''i'', the subspace topology ''X<sub>i</sub>'' inherits from τ coincides with its original topology. When each ''X<sub>i</sub>'' is a [[Fréchet space]], (''X'', τ) is called an [[LF space]].\n\nNow let ''U'' be the union of ''U<sub>i</sub>'' where {''U<sub>i</sub>''} is a countable nested family of open subsets of ''U'' with compact closures ''K<sub>i</sub>'' = {{overline|''U''}}<sub>''i''</sub>. Then we have the countable increasing union\n\n:<math>\\mathrm{D}(U) = \\bigcup\\nolimits_i \\mathrm{D}_{K_i} </math>\n\nwhere D<sub>''K<sub>i</sub>''</sub> is the set of all smooth functions on ''U'' with support lying in ''K<sub>i</sub>''. On each D<sub>''K<sub>i</sub>''</sub>, consider the topology given by the seminorms\n\n:<math>\\| \\varphi \\|_{\\alpha} = \\max_{x \\in K_i} \\left |\\partial^{\\alpha} \\varphi \\right | ,</math>\n\ni.e. the topology of uniform convergence of derivatives of arbitrary order. This makes each D<sub>''K<sub>i</sub>''</sub> a [[Fréchet space]]. The resulting [[LF space]] structure on D(''U'') is the topology described in the beginning of the section.\n\nOn D(''U''), one can also consider the topology given by the [[seminorm]]s\n\n:<math>\\| \\varphi \\|_{\\alpha, K_i} = \\max_{x \\in K_i} \\left |\\partial^{\\alpha} \\varphi \\right | .</math>\n\nHowever, this topology has the disadvantage of not being complete. On the other hand, because of the particular features of D<sub>''K<sub>i</sub>''</sub>'s, a set this bounded with respect to τ if and only if it lies in some D<sub>''K<sub>i</sub>''</sub>'s. The completeness of (''D''(''U''), τ) then follow from that of D<sub>''K<sub>i</sub>''</sub>'s.\n\nThe topology τ is not [[metrizable]] by the [[Baire category theorem]], since D(''U'') is the union of subspaces of the [[first category]] in D(''U'').<ref>See for example {{harv|Rudin|1991|loc=§6.9}}</ref>\n\n=== Distributions ===\n\nA '''distribution''' on ''U'' is a [[continuous linear functional]] ''T''&nbsp;:&nbsp;D(''U'')&nbsp;→&nbsp;'''R''' (or ''T''&nbsp;:&nbsp;D(''U'')&nbsp;→&nbsp;'''C'''). That is, a distribution ''T'' assigns to each test function ''φ'' a real (or complex) scalar ''T''(''φ'') such that\n\n:<math> T(c_1\\varphi_1 + c_2\\varphi_2) = c_1 T(\\varphi_1) + c_2 T(\\varphi_2)</math>\n\nfor all test functions ''φ''<sub>1</sub>, ''φ''<sub>2</sub> and scalars c<sub>1</sub>, c<sub>2</sub>.\nMoreover, ''T'' is continuous if and only if\n\n:<math>\\lim_{k\\to\\infty}T(\\varphi_k)= T\\left(\\lim_{k\\to\\infty}\\varphi_k\\right)</math>\n\nfor every convergent sequence ''φ''<sub>''k''</sub> in D(''U''). (Even though the topology of D(''U'') is not metrizable, a linear functional on D(''U'') is continuous if and only if it is sequentially continuous.)  Equivalently, ''T'' is continuous if and only if for every compact subset ''K'' of ''U'' there exists a positive constant ''C<sub>K</sub>'' and a non-negative integer ''N<sub>K</sub>'' such that\n\n:<math> |T(\\varphi)| \\le C_K \\sup \\{ |\\partial^\\alpha\\varphi(x)| \\mid x\\in K, |\\alpha|\\leq N_K \\}</math>\n\nfor all test functions ''φ'' with support contained in ''K''.<ref>See for example {{harv|Grubb|2009|page=14}}.</ref>\n\nThe space of distributions on ''U'' is denoted by D′(''U'') and it is the [[continuous dual space]] of D(''U''). No matter what dual topology is placed on D′(''U''), a ''sequence'' of distributions converges in this topology if and only if it converges pointwise (although this need not be true of a [[Net (mathematics)|net]]), which is why the topology is sometimes defined to be the [[weak-* topology]]. But often the [[Strong topology (polar topology)|topology of bounded convergence]], which in this case is the same as the topology of uniform convergence on compact sets, is placed on D′(''U'') since it is with this topology that D′(''U'') becomes a [[nuclear space|nuclear]] [[Montel space]] and it is with this topology that the [[Schwartz kernel theorem|kernels theorem of Schwartz]] holds.<ref>See for example {{harv|Schaefer|Wolff|1999|p=173}}.</ref> No matter which topology is chosen, D′(''U'') will be a non-metrizable, [[locally convex]] topological vector space.\n\nThe duality pairing between a distribution ''T'' in D′(''U'') and a test function ''φ'' in D(''U'') is denoted using [[angle brackets]] by\n\n:<math>\\begin{cases}\n\\mathrm{D}'(U) \\times \\mathrm{D}(U) \\to \\mathbf{R} \\\\\n(T, \\varphi) \\mapsto \\langle T, \\varphi \\rangle,\n\\end{cases}</math>\n\nso that {{langle}}''T'',''φ''{{rangle}} = ''T''(''φ''). One interprets this notation as the distribution ''T'' acting on the test function ''φ'' to give a scalar, or symmetrically as the test function ''φ'' acting on the distribution ''T''.\n\nA sequence of distributions (''T<sub>k</sub>'') converges with respect to the weak-* topology on D′(''U'') to a distribution ''T'' if and only if\n\n:<math>\\langle T_k, \\varphi\\rangle \\to \\langle T, \\varphi\\rangle</math>\n\nfor every test function ''φ'' in D(''U''). For example, if ''f<sub>k</sub>'' : '''R''' →  '''R''' is the function\n\n:<math> f_k(x) = \\begin{cases} k & \\text{if}\\ 0\\le x \\le  1/k \\\\ 0 & \\text{otherwise} \\end{cases}</math>\n\nand ''T<sub>k</sub>'' is the distribution corresponding to ''f<sub>k</sub>'', then\n\n:<math> \\langle T_k, \\varphi\\rangle = k\\int_0^{1/k} \\varphi(x)\\, dx \\to \\varphi(0) = \\langle \\delta, \\varphi\\rangle</math>\n\nas ''k'' → ∞, so ''T''<sub>''k''</sub> → ''δ'' in  D′('''R'''). Thus,  for large ''k'', the function ''f''<sub>''k''</sub> can be regarded as an approximation of the Dirac delta distribution.\n\n=== Functions as distributions ===\n\nThe function ''f''&nbsp;:&nbsp;''U''&nbsp;→&nbsp;'''R''' is called '''locally integrable''' if it is [[Lebesgue integration|Lebesgue integrable]] over every compact subset ''K'' of ''U''.<ref>For more information on such class of functions, see the [[Locally integrable|entry on locally integrable functions]].</ref> This is a large class of functions which includes all continuous functions and all [[Lp space|''L<sup>p</sup>'' functions]]. The topology on D(''U'') is defined in such a fashion that any locally integrable function ''f'' yields a continuous linear functional on D(''U'') – that is, an element of D′(''U'') – denoted here by ''T<sub>f</sub>'', whose value on the test function ''φ'' is given by the Lebesgue integral:\n\n:<math>\\langle T_f,\\varphi \\rangle = \\int_U f\\varphi\\,dx.</math>\n\nConventionally, one [[abuse of notation|abuses notation]] by identifying ''T<sub>f</sub>'' with ''f'', provided no confusion can arise, and thus the pairing between ''T<sub>f</sub>'' and ''φ'' is often written\n\n:<math>\\langle f, \\varphi\\rangle = \\langle T_f,\\varphi\\rangle.</math>\n\nIf ''f'' and ''g'' are two locally integrable functions, then the associated distributions ''T<sub>f</sub>'' and ''T<sub>g</sub>'' are equal to the same element of D′(''U'') if and only if ''f'' and ''g'' are equal [[almost everywhere]] (see, for instance, {{harvtxt|Hörmander|1983|loc=Theorem 1.2.5}}). In a similar manner, every [[Radon measure]] μ on ''U'' defines an element of D′(''U'') whose value on the test function ''φ'' is ∫''φ''&nbsp;''dμ''.  As above, it is conventional to abuse notation and write the pairing between a Radon measure ''μ'' and a test function ''φ'' as <math>\\langle \\mu, \\varphi \\rangle</math>.  Conversely, as shown in a theorem by Schwartz (similar to the [[Riesz representation theorem]]), every distribution which is non-negative on non-negative functions is of this form for some (positive) Radon measure.\n\nThe  test functions are themselves locally integrable, and so define distributions.  As such they are [[dense (topology)|dense]] in D′(''U'') with respect to the topology on D′(''U'') in the sense that for any distribution ''T''&nbsp;∈&nbsp;D′(''U''), there is a sequence ''φ''<sub>''n''</sub>&nbsp;∈&nbsp;D(''U'') such that\n\n:<math>\\langle\\varphi_n,\\psi\\rangle\\to \\langle T,\\psi\\rangle</math>\n\nfor all ''Ψ''&nbsp;∈&nbsp;D(''U'').  This fact follows from the [[Hahn–Banach theorem]], since the dual of D′(''U'') with its weak-* topology is the space D(''U''),<ref>See for example {{harv|Rudin|1991|loc=Theorem 3.10}}.</ref> and it can also be proven more constructively by a convolution argument.\n\n== Operations on distributions ==\n\nMany operations which are defined on smooth functions with compact support can also be defined for distributions.  In general, if ''A'' : D(''U'') → D(''U'') is a linear mapping of vector spaces which is continuous with respect to the weak-* topology, then it is possible to extend ''A'' to a mapping ''A'' : D′(''U'') → D′(''U'') by passing to the limit.  (This approach works for non-linear mappings as well, provided they are assumed to be [[uniformly continuous]].)\n\nIn practice, however, it is more convenient to define operations on distributions by means of the [[adjoint of an operator|transpose]].<ref>{{harv|Strichartz|1994|loc=§2.3}}; {{harv|Trèves|1967}}.</ref> If ''A''&nbsp;:&nbsp;D(''U'')&nbsp;→&nbsp;D(''U'') is a continuous linear operator, then the transpose is an operator ''A<sup>t</sup>''&nbsp;:&nbsp;D(''U'')&nbsp;→&nbsp;D(''U'') such that\n\n:<math>\\int_U A\\varphi(x)\\cdot \\psi(x) \\,dx = \\int_U \\varphi(x) \\cdot A^t\\psi(x)\\, dx\\qquad \\text{for all}\\ \\varphi,\\psi\\in D(U).</math>\n\n(For operators acting on spaces of complex-valued test functions, the transpose ''A<sup>t</sup>'' differs from the adjoint ''A<sup>*</sup>'' in that it does not include a complex conjugate.)\n\nIf such an operator ''A<sup>t</sup>'' exists and is continuous on D(''U''), then the original operator ''A'' may be extended to D′(''U'') by defining ''AT'' for a distribution ''T'' as\n\n:<math>\\langle AT, \\varphi\\rangle = \\langle T, A^t\\varphi\\rangle\\qquad \\text{for all}\\ \\varphi\\in D(U).</math>\n\n=== Differentiation ===\n\nSuppose ''A''&nbsp;:&nbsp;D(''U'')&nbsp;→&nbsp;D(''U'') is the partial derivative operator\n\n:<math>A\\varphi = \\frac{\\partial\\varphi}{\\partial x_k}.</math>\n\nIf ''φ'' and ''ψ'' are in D(''U''), then an integration by parts gives\n\n:<math>\\int_U \\frac{\\partial\\varphi}{\\partial x_k} \\psi \\, dx = -\\int_U\\varphi \\frac{\\partial\\psi}{\\partial x_k}\\, dx,</math>\n\nso that ''A<sup>t</sup>''&nbsp;=&nbsp;−''A''.  This operator is a continuous linear transformation on D(''U'').  So, if ''T''&nbsp;∈&nbsp;D′(''U'') is a distribution, then the partial derivative of ''T'' with respect to the coordinate ''x<sub>k</sub>'' is defined by the formula\n\n:<math>\\left\\langle \\frac{\\partial T}{\\partial x_{k}}, \\varphi \\right\\rangle = - \\left\\langle T, \\frac{\\partial \\varphi}{\\partial x_{k}} \\right\\rangle\n\\qquad \\text{for all}\\ \\varphi\\in D(U).</math>\n\nWith this definition, every distribution is infinitely differentiable, and the derivative in the direction ''x<sub>k</sub>'' is a [[linear operator]] on D′(''U'').\n\nMore generally, if α = (α<sub>1</sub>, ..., α<sub>''n''</sub>) is an arbitrary [[multi-index]] and ∂<sup>α</sup> is the associated partial derivative operator, then the partial derivative ∂<sup>α</sup>''T'' of the distribution ''T'' ∈ D′(''U'') is defined by\n\n:<math>\\left\\langle \\partial^{\\alpha} T, \\varphi \\right\\rangle = (-1)^{| \\alpha |} \\left\\langle T, \\partial^{\\alpha} \\varphi \\right\\rangle \\mbox{ for all } \\varphi \\in \\mathrm{D}(U).</math>\n\nDifferentiation of distributions is a continuous operator on D′(''U''); this is an important and desirable property that is not shared by most other notions of differentiation.\n\n=== Multiplication by a smooth function ===\n\nIf ''m'' : ''U'' → '''R''' is an infinitely differentiable function and ''T'' is a distribution on ''U'', then the product m''T'' is defined by\n\n:<math>\\langle mT, \\varphi\\rangle = \\langle T, m\\varphi \\rangle\\qquad \\text{for all}\\ \\varphi\\in D(U).</math>\n\nThis definition coincides with the transpose definition since if ''M''&nbsp;:&nbsp;D(''U'')&nbsp;→&nbsp;D(''U'') is the operator of multiplication by the function ''m'' (i.e., ''Mφ'' = ''m'' ''φ''), then\n\n:<math>\\int_U M\\varphi(x)\\cdot \\psi(x)\\,dx  = \\int_U m(x)\\varphi(x)\\cdot \\psi(x)\\,dx = \\int_U \\varphi(x)\\cdot m(x)\\psi(x)\\,dx = \\int_U \\varphi(x)\\cdot M\\psi(x)\\,dx,</math>\n\nso that ''M<sup>t</sup>''&nbsp;=&nbsp;''M''.\n\nUnder multiplication by smooth functions, D′(''U'') is a [[module (mathematics)|module]] over the [[ring (mathematics)|ring]] C<sup>∞</sup>(''U'').  With this definition of multiplication by a smooth function, the ordinary product rule of calculus remains valid. However, a number of unusual identities also arise. For example, if ''δ'' is the Dirac delta distribution on '''R''', then ''mδ''&nbsp;=&nbsp;''m''(0)''δ'', and if ''δ''′ is the derivative of the delta distribution, then\n\n:<math>m\\delta' = m(0)\\delta' - m'\\delta = m(0)\\delta' - m'(0)\\delta.\\,</math>\n\nThese definitions of differentiation and multiplication also make it possible to define the operation of a linear [[differential operator]] with smooth coefficients on a distribution.  A linear differential operator ''P'' takes a distribution ''T''&nbsp;∈&nbsp;D′(''U'') to another distribution ''PT'' given by a sum of the form\n\n:<math>PT = \\sum\\nolimits_{|\\alpha|\\le k} p_\\alpha \\partial^\\alpha T,</math>\n\nwhere the coefficients ''p''<sub>α</sub> are smooth functions on ''U''. The action of the distribution ''PT'' on a test function ''φ'' is given by\n\n:<math>\\left\\langle \\sum\\nolimits_{|\\alpha|\\le k} p_\\alpha \\partial^\\alpha T,\\varphi\\right\\rangle = \\left\\langle T,\\sum\\nolimits_{|\\alpha|\\le k} (-1)^{|\\alpha|} \\partial^\\alpha(p_\\alpha\\varphi)\\right\\rangle.</math>\n\nThe minimum integer ''k'' for which such an expansion holds for every distribution ''T'' is called the '''order''' of ''P''.\nThe space D′(''U'') is a [[D-module]] with respect to the action of the ring of linear differential operators.\n\n=== Composition with a smooth function ===\n\nLet ''T'' be a distribution on an open set ''U''&nbsp;⊂&nbsp;'''R'''<sup>''n''</sup>. Let ''V'' be an open set in '''R'''<sup>''n''</sup>, and ''F''&nbsp;:&nbsp;''V''&nbsp;→&nbsp;''U''.  Then provided ''F'' is a [[submersion (mathematics)|submersion]], it is possible to define\n\n:<math>T\\circ F \\in \\mathrm{D}'(V).</math>\n\nThis is the '''composition''' of the distribution ''T'' with ''F'', and is also called the '''[[pullback (differential geometry)|pullback]]''' of ''T'' along ''F'', sometimes written\n\n:<math>F^\\sharp : T\\mapsto F^\\sharp T = T\\circ F.</math>\n\nThe pullback is often denoted ''F*'', although this notation should not be confused with the use of '*' to denote the adjoint of a linear mapping.\n\nThe condition that ''F'' be a submersion is equivalent to the requirement that the [[Jacobian matrix and determinant|Jacobian]] derivative ''dF''(''x'') of ''F'' is a [[surjective]] linear map for every ''x''&nbsp;∈&nbsp;''V''.  A necessary (but not sufficient) condition for extending ''F''<sup>#</sup> to distributions is that ''F'' be an [[open mapping]].<ref>See for example {{harv|Hörmander|1983|loc=Theorem 6.1.1}}.</ref>  The [[inverse function theorem]] ensures that a submersion satisfies this condition.\n\nIf ''F'' is a submersion, then ''F''<sup>#</sup> is defined on distributions by finding the transpose map.  Uniqueness of this extension is guaranteed since ''F''<sup>#</sup> is a continuous linear operator on D(''U'').  Existence, however, requires using the [[integration by substitution|change of variables]] formula, the inverse function theorem (locally) and a [[partition of unity]] argument.<ref>See {{harv|Hörmander|1983|loc=Theorem 6.1.2}}.</ref>\n\nIn the special case when ''F'' is a [[diffeomorphism]] from an open subset ''V'' of '''R'''<sup>''n''</sup> onto an open subset ''U'' of '''R'''<sup>''n''</sup> change of variables under the integral gives\n\n:<math>\\int_V\\varphi\\circ F(x) \\psi(x)\\,dx = \\int_U\\varphi(x) \\psi \\left (F^{-1}(x) \\right ) \\left |\\det dF^{-1}(x) \\right |\\,dx.</math>\n\nIn this particular case, then, ''F''<sup>#</sup> is defined by the transpose formula:\n\n:<math>\\left \\langle F^\\sharp T,\\varphi \\right \\rangle = \\left \\langle T, \\left |\\det d(F^{-1}) \\right | \\varphi\\circ F^{-1} \\right \\rangle.</math>\n\n==Localization of distributions==\nThere is no way to define the value of a distribution in D′(''U'') at a particular point of ''U''.  However, as is the case with functions, distributions on ''U'' restrict to give distributions on open subsets of ''U''.  Furthermore, distributions are ''locally determined'' in the sense that a distribution on all of ''U'' can be assembled from a distribution on an open cover of ''U'' satisfying some compatibility conditions on the overlap.  Such a structure is known as a [[sheaf (mathematics)|sheaf]].\n\n===Restriction===\nLet ''U'' and ''V'' be open subsets of '''R'''<sup>''n''</sup> with ''V''&nbsp;⊂&nbsp;''U''.  Let ''E<sub>VU</sub>''&nbsp;:&nbsp;D(''V'')&nbsp;→&nbsp;D(''U'') be the operator which ''extends by zero'' a given smooth function compactly supported in ''V'' to a smooth function compactly supported in the larger set ''U''.  Then the restriction mapping ρ<sub>''VU''</sub> is defined to be the transpose of ''E<sub>VU</sub>''.  Thus for any distribution ''T''&nbsp;∈&nbsp;D′(''U''), the restriction ρ<sub>''VU''</sub>''T'' is a distribution in the dual space D′(''V'') defined by\n\n:<math>\\langle \\rho_{VU}T,\\varphi\\rangle = \\langle T, E_{VU}\\varphi\\rangle</math>\n\nfor all test functions ''φ''&nbsp;∈&nbsp;D(''V'').\n\nUnless ''U''&nbsp;=&nbsp;''V'', the restriction to ''V'' is neither [[injective]] nor [[surjective]].  Lack of surjectivity follows since distributions can blow up towards the boundary of ''V''.  For instance, if ''U''&nbsp;=&nbsp;'''R''' and ''V''&nbsp;=&nbsp;(0, 2), then the distribution\n\n:<math>T(x) = \\sum_{n=1}^\\infty n\\,\\delta\\left(x-\\frac{1}{n}\\right)</math>\n\nis in D′(''V'') but admits no extension to D′(''U'').\n\n=== Support of a distribution ===\n\nLet ''T''&nbsp;∈ D′(''U'') be a distribution on an open set ''U''.  Then ''T'' is said to vanish on an open set ''V'' of ''U'' if ''T'' lies in the [[kernel (algebra)|kernel]] of the restriction map ρ<sub>''VU''</sub>.  Explicitly ''T'' vanishes on ''V'' if\n\n:<math>\\langle T,\\varphi\\rangle = 0</math>\n\nfor all test functions ''φ''&nbsp;∈ C<sup>∞</sup>(''U'') with support in ''V''.  Let ''V'' be a maximal open set on which the distribution ''T'' vanishes; i.e., ''V'' is the union of every open set on which ''T'' vanishes.  The '''support''' of ''T'' is the complement of ''V'' in ''U''.  Thus\n\n:<math>\\operatorname{supp}\\,T = U \\setminus \\bigcup\\left\\{V \\mid \\rho_{VU}T = 0\\right\\}.</math>\n\nThe distribution ''T'' has '''compact support''' if its support is  a compact set.  Explicitly, ''T'' has compact support if there is a compact subset ''K'' of ''U'' such that for every test function ''φ'' whose support is completely outside of ''K'', we have ''T''(''φ'') = 0.  Compactly supported distributions define continuous linear functionals on the space C<sup>∞</sup>(''U''); the topology on C<sup>∞</sup>(''U'') is defined such that a sequence of test functions ''φ''<sub>''k''</sub> converges to 0 if and only if all derivatives of ''φ''<sub>''k''</sub> converge uniformly to 0 on every compact subset of ''U''.  Conversely, it can be shown that every continuous linear functional on this space defines a distribution of compact support. The embedding of  C<sub>c</sub><sup>∞</sup>(''U'') into C<sup>∞</sup>(''U''), where the spaces are given their respective topologies, is continuous and has dense image. Thus compactly supported distributions can be identified with those distributions that can be extended from  C<sub>c</sub><sup>∞</sup>(''U'') to  C<sup>∞</sup>(''U'').\n\n== Tempered distributions and Fourier transform {{anchor|Tempered distribution}} ==\nBy using a larger space of test functions ''S''('''R'''<sup>''n''</sup>), \none can define the space of '''tempered distributions''' \nS′('''R'''<sup>''n''</sup>), a subspace of D′('''R'''<sup>''n''</sup>). These distributions are useful if one studies the [[Fourier transform]]: all tempered distributions have a Fourier transform, but not all distributions in D′('''R'''<sup>''n''</sup>) have one.\n\nThe space of test functions employed here, the so-called [[Schwartz space]] ''S''('''R'''<sup>''n''</sup>), is the function space of all infinitely differentiable functions that are [[rapidly decreasing]] at infinity along with all partial derivatives.  Thus {{nowrap|''φ'' : '''R'''<sup>''n''</sup> → '''R'''}} is in the Schwartz space provided that any derivative of ''φ'', multiplied with any power of&nbsp;|''x''|, converges towards 0 for |''x''|&nbsp;→&nbsp;∞.  These functions form a complete [[topological vector space]] with a suitably defined family of [[seminorm]]s.  More precisely, let\n\n:<math> p_{\\alpha , \\beta} (\\varphi) = \\sup_{x \\in \\mathbf{R}^n} | x^\\alpha D^\\beta \\varphi(x)| </math>\n\nfor ''α'', ''β'' [[multi-indices]] of size ''n''.  Then ''φ'' is a Schwartz function if all the values satisfy\n\n:<math> p_{\\alpha, \\beta} (\\varphi) < \\infty.</math>\n\nThe family of seminorms ''p''<sub>''α'', ''β''</sub> defines a [[locally convex]] topology on the Schwartz space. The seminorms are, in fact, [[norm (mathematics)|norms]] on the Schwartz space.  The Schwartz space is [[metrizable]] and [[complete space|complete]]. Because the Fourier transform changes differentiation by ''x''<sup>''α''</sup> into multiplication by ''x''<sup>''α''</sup> and vice versa, this symmetry implies that the Fourier transform of a Schwartz function is also a Schwartz function.\n\nThe space of '''tempered distributions''' is defined as the (continuous) [[dual space|dual]] of the Schwartz space. In other words, a distribution ''T'' is a tempered distribution if and only if\n\n:  <math> \\lim_{m\\to\\infty} T(\\varphi_m)=0. </math>\n\nis true whenever\n\n: <math> \\lim_{m\\to\\infty} p_{\\alpha , \\beta} (\\varphi_m) = 0 </math>\n\nholds for all [[multi-indices]] ''α'', ''β''.\n\nThe derivative of a tempered distribution is again a tempered distribution.  Tempered distributions generalize the bounded (or slow-growing) locally integrable functions; all distributions with compact support and all [[square-integrable]] functions are tempered distributions. More generally, all functions that are products of polynomials with elements of [[Lp space|''L<sup>p</sup>''('''R'''<sup>''n''</sup>)]] for ''p''&nbsp;≥&nbsp;1 are tempered distributions.\n\nThe ''tempered distributions'' can also be characterized as ''slowly growing'', meaning that each derivative of ''T'' grows at most as fast as some [[polynomial]]. This characterization is dual to the ''rapidly falling'' behaviour of the derivatives of a function in the Schwartz space, where each derivative of ''Φ'' decays faster than every inverse power of ''|x|''. An example of a rapidly falling function is <math>|x|^n \\cdot \\exp (- \\lambda |x|^\\beta)</math> for any positive  ''n'', ''λ'', ''β''.\n\nTo study the Fourier transform, it is best to consider ''complex''-valued test functions and complex-linear distributions. The ordinary [[continuous Fourier transform]] ''F'' yields then an [[automorphism]] of Schwartz function space, and we can define the '''Fourier transform''' of the tempered distribution ''T'' by (''FT'')(''Ψ'') = ''T''(''Fψ'') for every Schwartz function ''Ψ''. ''FT'' is thus again a tempered distribution. The Fourier transform is a continuous, linear, bijective operator from the space of tempered distributions to itself. This operation is compatible with differentiation in the sense that\n\n:<math>F\\dfrac{dT}{dx}=ixFT</math>\n\nand also with convolution: if ''T'' is a tempered distribution and ''Ψ'' is a ''slowly increasing'' infinitely differentiable function on '''R'''<sup>''n''</sup>, then ''ψT'' is again a tempered distribution and\n\n:<math>F(\\psi T)=F\\psi*FT\\,</math>\nis the convolution of ''FT'' and ''Fψ''. In particular, the Fourier transform of the  constant function equal to 1 is the ''δ'' distribution.\n\n==Convolution==\n\nUnder some circumstances, it is possible to define the [[convolution]] of a function with a distribution, or even the convolution of two distributions.\n\n;Convolution of a test function with a distribution\n\nIf ''f''&nbsp;∈&nbsp;D('''R'''<sup>''n''</sup>) is a compactly supported smooth test function, then convolution with ''f'',\n\n:<math>\\begin{cases}\nC_f : \\mathrm{D}(\\mathbf{R}^n)\\to \\mathrm{D}(\\mathbf{R}^n) \\\\\nC_f : g \\mapsto f * g\n\\end{cases}</math>\n\ndefines a linear operator which is  [[continuous function|continuous]] with respect to the [[LF space]] topology on D('''R'''<sup>''n''</sup>).\n\nConvolution of ''f'' with a distribution ''T''&nbsp;∈&nbsp;D′('''R'''<sup>''n''</sup>) can be defined by taking the transpose of ''C<sub>f</sub>'' relative to the duality pairing of D('''R'''<sup>''n''</sup>) with the space D′('''R'''<sup>''n''</sup>) of distributions {{harv|Trèves|1967|loc=Chapter 27}}. If ''f'',&nbsp;''g'',&nbsp;''φ''&nbsp;∈&nbsp;D('''R'''<sup>''n''</sup>), then by [[Fubini's theorem]]\n\n:<math>\\left \\langle C_fg, \\varphi \\right \\rangle = \\int_{\\mathbf{R}^n}\\varphi(x)\\int_{\\mathbf{R}^n}f(x-y) g(y) \\, dy \\, dx = \\left \\langle g, C_{\\widetilde{f}}\\varphi \\right \\rangle</math>\n\nwhere <math>\\scriptstyle{\\widetilde{f}(x) = f(-x)}</math>.  Extending by continuity, the convolution of ''f'' with a distribution ''T'' is defined by\n\n:<math>\\langle f*T, \\varphi\\rangle = \\left \\langle T, \\widetilde{f}*\\varphi \\right \\rangle</math>\n\nfor all test functions ''φ''&nbsp;∈&nbsp;D('''R'''<sup>''n''</sup>).\n\nAn alternative way to define the convolution of a function ''f'' and a distribution ''T'' is to use the translation operator τ<sub>''x''</sub> defined on test functions by\n\n:<math>\\tau_x \\varphi(y) = \\varphi(y-x)</math>\n\nand extended by the transpose to distributions in the obvious way.<ref>See for example {{harv|Rudin|1991|loc=§6.29}}.</ref>  The convolution of the compactly supported function ''f'' and the distribution ''T'' is then the function defined for each ''x''&nbsp;∈&nbsp;'''R'''<sup>''n''</sup> by\n\n:<math>(f*T)(x) = \\left \\langle T, \\tau_x\\widetilde{f} \\right \\rangle.</math>\n\nIt can be shown that the convolution of a smooth, compactly supported function and a distribution is a smooth function.  If the distribution ''T'' has compact support as well, then ''f''∗''T'' is a compactly supported function, and the [[Titchmarsh convolution theorem]] {{harv|Hörmander|1983|loc=Theorem 4.3.3}} implies that\n\n:<math>\\operatorname{ch}(\\operatorname{supp}(f*T)) = \\operatorname{ch}\\operatorname{supp}f + \\operatorname{ch} \\operatorname{supp} T</math>\n\nwhere ''ch'' denotes the [[convex hull]] and supp denotes the support.\n\n;Distribution of compact support\n\nIt is also possible to define the convolution of two distributions ''S'' and ''T'' on '''R'''<sup>''n''</sup>, provided one of them has compact support.  Informally, in order to define ''S''∗''T'' where ''T'' has compact support, the idea is to extend the definition of the convolution ∗ to a linear operation on distributions so that the associativity formula\n\n:<math>S*(T*\\varphi) = (S*T)*\\varphi</math>\n\ncontinues to hold for all test functions ''φ''.<ref>{{harvtxt|Hörmander|1983|loc=§IV.2}} proves the uniqueness of such an extension.</ref>\n\nIt is also possible to provide a more explicit characterization of the convolution of distributions {{harv|Trèves|1967|loc=Chapter 27}}.  Suppose that it is ''T'' that has compact support.  For any test function ''φ'' in D('''R'''<sup>''n''</sup>), consider the function\n\n:<math>\\psi(x) = \\langle T, \\tau_{-x} \\varphi\\rangle.</math>\n\nIt can be readily shown that this defines a smooth function of ''x'', which moreover has compact support.  The convolution of ''S'' and ''T'' is defined by\n\n:<math>\\langle S * T,\\varphi\\rangle = \\langle S, \\psi\\rangle.</math>\n\nThis generalizes the classical notion of [[convolution]] of functions and is compatible with differentiation in the following sense:\n\n:<math>\\partial^\\alpha(S*T)=(\\partial^\\alpha S)*T=S*(\\partial^\\alpha T).</math>\n\nThis definition of convolution remains valid under less restrictive assumptions about ''S'' and ''T''.<ref>See for instance {{harvtxt|Gel'fand|Shilov|1966–1968|loc=v. 1, pp. 103–104}} and {{harvtxt|Benedetto|1997|loc=Definition 2.5.8}}.</ref>\n\n==Distributions as derivatives of continuous functions==\n\nThe formal definition of distributions exhibits them as a subspace of a very large space, namely the topological dual of D(''U'') (or S('''R'''<sup>''d''</sup>) for tempered distributions). It is not immediately clear from the definition how exotic a distribution might be. To answer this question, it is instructive to see distributions built up from a smaller space, namely the space of continuous functions. Roughly, any distribution is locally a (multiple) derivative of a continuous function. A precise version of this result, given below, holds for distributions of compact support, tempered distributions, and general distributions. Generally speaking, no proper subset of the space of distributions contains all continuous functions and is closed under differentiation. This says that distributions are not particularly exotic objects; they are only as complicated as necessary.\n\n===Tempered distributions===\n\nIf ''f''&nbsp;∈&nbsp;''S''′('''R'''<sup>''n''</sup>) is a tempered distribution, then there exists a constant ''C''&nbsp;>&nbsp;0, and positive integers ''M'' and ''N'' such that for all [[Schwartz function]]s ''<math>\\varphi</math>''&nbsp;∈&nbsp;''S''('''R'''<sup>''n''</sup>)\n\n:<math>\\langle f, \\varphi\\rangle \\le C\\sum\\nolimits_{|\\alpha|\\le N, |\\beta|\\le M}\\sup_{x\\in\\mathbf{R}^n} \\left |x^\\alpha D^\\beta \\varphi(x) \\right |=C\\sum\\nolimits_{|\\alpha|\\le N, |\\beta|\\le M}p_{\\alpha,\\beta}(\\varphi).</math>\n\nThis estimate along with some techniques from functional analysis can be used to show that there is a continuous slowly increasing function ''F'' and a multi-index ''α'' such that\n\n:<math>f=D^\\alpha F.\\,</math>\n\n===Restriction of distributions to compact sets===\n\nIf ''f''&nbsp;∈&nbsp;D′('''R'''<sup>''n''</sup>), then for any compact set ''K''&nbsp;⊂&nbsp;'''R'''<sup>''n''</sup>, there exists a continuous function ''F '' compactly supported \nin '''R'''<sup>''n''</sup> (possibly on a larger set than ''K'' itself) and a multi-index ''α'' such that ''f''&nbsp;=&nbsp;''D''<sup>''α''</sup>''F'' on C<sub>c</sub><sup>∞</sup>(''K'').\nThis follows from the previously quoted result on tempered distributions by means of a localization argument.\n\n===Distributions with point support===\n\nIf ''f'' has support at a single point {''P''}, then ''f'' is in fact a finite linear combination of distributional derivatives of the ''δ'' function at ''P''.  That is, there exists an integer ''m'' and complex constants ''a''<sub>''α''</sub> for [[multi-index|multi-indices]] |''α''|&nbsp;≤&nbsp;''m'' such that\n\n:<math> f = \\sum\\nolimits_{|\\alpha|\\le m} a_\\alpha D^\\alpha(\\tau_P\\delta)</math>\n\nwhere τ<sub>''P''</sub> is the translation operator.\n\n===General distributions===\n\nA version of the above theorem holds locally in the following sense {{harv|Rudin|1991}}. Let ''T'' be a distribution on ''U'', then one can find for every multi-index ''α'' a continuous function ''g''<sub>''α''</sub> such that\n\n: <math>\\displaystyle T = \\sum\\nolimits_\\alpha D^\\alpha g_\\alpha</math>\n\nand that any compact subset ''K'' of ''U'' intersects the supports of only finitely many ''g''<sub>''α''</sub>; therefore, to evaluate the value of ''T'' for a given smooth function ''f'' compactly supported in ''U'', we only need finitely many ''g''<sub>''α''</sub>; hence the infinite sum above is well-defined as a distribution. If the distribution ''T'' is of finite order, then one can choose ''g''<sub>''α''</sub> in such a way that only finitely many of them are nonzero.\n\n== Using holomorphic functions as test functions ==\n\nThe success of the theory led to investigation of the idea of [[hyperfunction]], in which spaces of [[holomorphic function]]s are used as test functions. A refined theory has been developed, in particular [[Mikio Sato]]'s [[algebraic analysis]], using [[sheaf theory]] and [[several complex variables]]. This extends the range of symbolic methods that can be made into rigorous mathematics, for example [[Path integral formulation|Feynman integrals]].\n\n== Problem of multiplication ==\n\nIt is easy to define the product of a distribution with a smooth function, or more generally the product of two distributions whose singular supports are disjoint. With more effort it is possible to define a well-behaved product of several distributions provided their [[wave front set]]s at each point are compatible.  \nA limitation of the theory of distributions (and hyperfunctions) is that there is no associative product of two distributions extending the product of a distribution by a smooth function, as has been proved by [[Laurent Schwartz]] in the 1950s.  For example, if p.v. 1/''x'' is the distribution obtained by the [[Cauchy principal value]]\n\n:<math>\\left(\\operatorname{p.v.}\\frac{1}{x}\\right)[\\varphi] = \\lim_{\\varepsilon\\to 0^+} \\int_{|x|\\ge\\varepsilon} \\frac{\\varphi(x)}{x}\\, dx</math>\n\nfor all ''φ''&nbsp;∈&nbsp;''S''('''R'''), and ''δ'' is the Dirac delta distribution then\n\n: <math>\\left(\\delta \\times x \\right) \\times \\operatorname{p.v.} \\frac{1}{x} = 0</math>\n\nbut\n\n: <math>\\delta \\times \\left( x \\times \\operatorname{p.v.} \\frac{1}{x} \\right) = \\delta</math>\n\nso the product of a distribution by a smooth function (which is always well defined) cannot be extended to an [[associativity|associative]] product on the space of distributions.\n\nThus, nonlinear problems cannot be posed in general and thus not solved within distribution theory alone. In the context of [[quantum field theory]], however, solutions can be found. In more than two spacetime dimensions the problem is related to the [[Regularization (physics)|regularization]] of [[Ultraviolet divergence|divergences]]. Here [[Henri Epstein]] and [[Vladimir Glaser]] developed the mathematically rigorous (but extremely technical) ''[[causal perturbation theory]]''. This does not solve the problem in other situations. Many other interesting theories are non linear, like for example the [[Navier–Stokes equations]] of [[fluid dynamics]].\n\nSeveral not entirely satisfactory theories of [[algebra (ring theory)|algebra]]s of [[generalized function]]s have been developed, among which [[Colombeau algebra|Colombeau's (simplified) algebra]] is maybe the most popular in use today.\n\nInspired by Lyons' [[rough path]] theory,<ref>{{Cite journal | last1 = Lyons | first1 = T. | title = Differential equations driven by rough signals | doi = 10.4171/RMI/240 | journal = Revista Matemática Iberoamericana | pages = 215–310 | year = 1998 | pmid =  | pmc = }}</ref> [[Martin Hairer]] proposed a consistent way of multiplying distributions with certain structure ([[regularity structures]] <ref>{{cite journal|last1=Hairer|first1=Martin|title=A theory of regularity structures|journal=Inventiones Mathematicae|date=2014|doi=10.1007/s00222-014-0505-4|volume=198|issue=2|pages=269–504|bibcode=2014InMat.198..269H|arxiv=1303.5113}}</ref>), available in many examples from stochastic analysis, notably stochastic partial differential equations. See also Gubinelli–Imkeller–Perkowski (2015) for a related development based on [[Jean-Michel Bony|Bony]]'s [[paraproduct]] from Fourier analysis.\n\n==See also==\n*[[Current (mathematics)]]\n*[[Distribution (number theory)]]\n*[[Colombeau algebra]]\n*[[Gelfand triple]]\n*[[Generalized function]]\n*[[Homogeneous distribution]]\n*[[Hyperfunction]]\n*[[Laplacian of the indicator]]\n*[[Linear form]]\n*[[Malgrange–Ehrenpreis theorem]]\n*[[Pseudodifferential operator]]\n*[[Riesz representation theorem]]\n*[[Vague topology]]\n*[[Weak solution]]\n*[[Distribution on a linear algebraic group]]\n\n==Notes==\n{{Reflist|29em}}\n\n==References==\n*{{citation|first=J.J.|last=Benedetto|title=Harmonic Analysis and Applications|publisher=CRC Press|year=1997}}.\n*{{citation|first=L.|last=Gårding|title=Some Points of Analysis and their History|publisher=American Mathematical Society|year=1997}}.\n*{{citation|first1=I.M.|last1=Gel'fand|author1-link=Israel Gelfand|first2=G.E.|last2=Shilov|title=Generalized functions|volume=1–5|publisher=Academic Press|year=1966–1968}}.\n* {{citation | first=G. | last=Grubb| title=Distributions and Operators | publisher=Springer | year=2009}}.\n*{{citation|mr=0717035|first=L.|last= Hörmander|authorlink=Lars Hörmander|title=The analysis of linear partial differential operators I|series= Grundl. Math. Wissenschaft. |volume= 256 |publisher= Springer  |year=1983|isbn=3-540-12104-8 |doi=10.1007/978-3-642-96750-4}}.\n*{{citation|first1=A. N.|last1=Kolmogorov|author1-link=Andrey Kolmogorov|first2=S. V.|last2=Fomin|author2-link=Sergei Fomin|year=1957|title=Elements of the Theory of Functions and Functional Analysis|publisher=Dover Books}}.\n* {{citation|first=W.|last=Rudin|authorlink=Walter Rudin|title=Functional Analysis|edition=2nd|publisher=McGraw–Hill|year=1991|isbn=0-07-054236-8}}.\n* {{citation | isbn = 9780387987262 | title = Topological Vector Spaces | last1 = Schaefer | first1 = Helmuth H. | year = 1999 | publisher = [[Springer-Verlag]] | location = New York | last2 = Wolff | first2 = M.P. | series = [[Graduate Texts in Mathematics|GTM]] | volume = 3  | pages =  }} <!-- Schaefer, H.H. (1999) Topological Vector Spaces -->\n* {{citation|first=L.|last=Schwartz|year=1954|authorlink=Laurent Schwartz|title=Sur l'impossibilité de la multiplications des distributions|journal=C. R. Acad. Sci. Paris|volume=239|pages=847–848}}.\n* {{citation|first=L.|last=Schwartz|authorlink=Laurent Schwartz|title=Théorie des distributions|volume=1–2|publisher=Hermann|year=1951}}.\n*{{citation|first=S.L. |last=Sobolev|authorlink=Sergei Sobolev|title=Méthode nouvelle à résoudre le problème de Cauchy pour les équations linéaires hyperboliques normales|journal= Mat. Sbornik |volume= 1 |year=1936|pages= 39–72|url=http://mi.mathnet.ru/msb5358}}\t\n* {{citation|first1=Elias|last1=Stein|authorlink1=Elias Stein|first2=Guido|last2=Weiss|title=Introduction to Fourier Analysis on Euclidean Spaces|publisher=Princeton University Press|year=1971|isbn=0-691-08078-X}}.\n* {{citation|first=R.|last=Strichartz|year=1994|title=A Guide to Distribution Theory and Fourier Transforms|publisher=CRC Press|isbn=0-8493-8273-4}}.\n*{{citation|first=François|last=Trèves|authorlink=François Trèves|title=Topological Vector Spaces, Distributions and Kernels|publisher=Academic Press|year=1967|pages=126 ff}}.\n\n==Further reading==\n* M. J. Lighthill (1959). ''Introduction to Fourier Analysis and Generalised Functions''. Cambridge University Press. {{ISBN|0-521-09128-4}} (requires very little knowledge of analysis; defines distributions as limits of sequences of functions under integrals)\n* [[Vasily Vladimirov|V.S. Vladimirov]] (2002). ''Methods of the theory of generalized functions''. Taylor & Francis. {{ISBN|0-415-27356-0}}\n* {{springer|id=G/g043810|title=Generalized function|first=V.S.|last=Vladimirov| author-link= Vasilii Sergeevich Vladimirov|year=2001}}.\n* {{springer|id=G/g043840|title=Generalized functions, space of|first=V.S.|last=Vladimirov| author-link= Vasilii Sergeevich Vladimirov|year=2001}}.\n* {{springer|id=G/g043820|title=Generalized function, derivative of a|first=V.S.|last=Vladimirov| author-link= Vasilii Sergeevich Vladimirov|year=2001}}.\n* {{springer|id=G/g043830|title=Generalized functions, product of|first=V.S.|last=Vladimirov| author-link= Vasilii Sergeevich Vladimirov|year=2001}}.\n* {{springer|id=G/g130030|title=Generalized function algebras|first=Michael|last=Oberguggenberger|year=2001}}.\n\n[[Category:Generalized functions]]\n[[Category:Functional analysis]]\n[[Category:Smooth functions]]\n[[Category:Generalizations of the derivative]]"
    },
    {
      "title": "Exterior derivative",
      "url": "https://en.wikipedia.org/wiki/Exterior_derivative",
      "text": "{{Short description|operation of differentiation in differential geometry}}\n{{Calculus |Multivariable}}\n\nOn a [[differentiable manifold]], the '''exterior derivative''' extends the concept of the [[pushforward (differential)|differential]] of a function to [[differential form]]s of higher degree. The exterior derivative was first described in its current form by [[Élie Cartan]] in 1899; it allows for a natural, metric-independent generalization of [[Stokes' theorem]], [[Gauss's theorem]], and [[Green's theorem]] from vector calculus.\n\nIf a {{math|''k''}}-form is thought of as measuring the flux through an infinitesimal {{math|''k''}}-[[Parallelepiped#Parallelotope|parallelotope]], then its exterior derivative can be thought of as measuring the net flux through the boundary of a {{math|(''k'' + 1)}}-parallelotope.\n\n== Definition ==\nThe exterior derivative of a [[differential form]] of degree {{math|''k''}} is a differential form of degree {{math|''k'' + 1.}}\n\nIf {{math|&thinsp;''f''&thinsp;}} is a [[Smoothness|smooth function]] (a {{math|0}}-form), then the exterior derivative of {{math|&thinsp;''f''&thinsp;}} is the [[Pushforward (differential)|differential]] of {{math|&thinsp;''f''&thinsp;}}. That is, {{math|''df''&thinsp;}} is the unique [[1-form|{{math|1}}-form]] such that for every smooth [[vector field]] {{math|''X''}}, {{math|1=''df''&thinsp;(''X'') = ''d''<sub>''X''</sub>&thinsp;''f''&thinsp;}}, where {{math|''d''<sub>''X''</sub>&thinsp;''f''&thinsp;}} is the [[directional derivative]] of {{math|&thinsp;''f''&thinsp;}} in the direction of {{math|''X''}}.\n\nThere are a variety of equivalent definitions of the exterior derivative of a general {{math|''k''}}-form.\n\n===In terms of axioms===\nThe exterior derivative is defined to be the unique {{math|ℝ}}-linear mapping from {{math|''k''}}-forms to {{math|(''k'' + 1)}}-forms satisfying the following properties:\n\n# {{math|''df''&thinsp;}} is the [[Differential_of_a_function|differential]] of {{math|&thinsp;''f''&thinsp;}}, for {{math|0}}-forms  ([[Smoothness|smooth functions]]) {{math|&thinsp;''f''&thinsp;}}.\n# {{math|1=''d''(''df''&thinsp;) = 0}} for any {{math|0}}-form (smooth function) {{math|&thinsp;''f''&thinsp;}}.\n# {{math|1=''d''(''α'' ∧ ''β'') = ''dα'' ∧ ''β'' + (−1){{sup|''p''}} (''α'' ∧ ''dβ'')}} where {{mvar|α}} is a {{math|''p''}}-form. That is to say, {{math|''d''}} is an [[derivation (algebra)|antiderivation]] of degree {{math|1}} on the [[exterior algebra]] of differential forms.\n\nThe second defining property holds in more generality: in fact, {{math|1=''d''(''dα'') = 0}} for any {{math|''k''}}-form {{mvar|α}}; more succinctly, {{math|1=''d''{{i sup|2}} = 0}}. The third defining property implies as a special case that if {{math|&thinsp;''f''&thinsp;}} is a function and {{mvar|α}} a {{math|''k''}}-form, then {{math|1=''d''(&thinsp;''fα'') = ''d''(&thinsp;''f'' ∧ ''α'') = ''df''&thinsp; ∧ ''α'' + &thinsp;''f''&thinsp; ∧ ''dα''}} because functions are {{math|0}}-forms, and scalar multiplication and the exterior product are equivalent when one of the arguments is a scalar.\n\n===In terms of local coordinates===\nAlternatively, one can work entirely in a [[local coordinate system]] {{math|(''x''{{sup|1}}, ..., ''x''{{i sup|''n''}})}}. The coordinate differentials {{math|''dx''{{sup|1}}, ..., ''dx''{{i sup|''n''}}}} form a basis of the space of one-forms, each associated with a coordinate. Given a [[multi-index]] {{math|1=''I'' = (''i''{{sub|1}}, ..., ''i''{{sub|''k''}})}} with {{math|1 ≤ ''i''{{sub|''p''}} ≤ ''n''}} for {{math|1 ≤ ''p'' ≤ ''k''}} (and denoting {{math|''dx''{{i sup|''i''{{sub|1}}}} ∧ ... ∧ ''dx''{{i sup|''i''{{sub|''k''}}}}}} with an [[abuse of notation]] {{math|1=''dx''{{i sup|''I''}}}}), the exterior derivative of a (simple) {{math|''k''}}-form\n\n:<math>\\varphi = g\\,dx^I = g\\,dx^{i_1}\\wedge dx^{i_2}\\wedge\\cdots\\wedge dx^{i_k}</math>\n\nover {{math|ℝ{{sup|''n''}}}} is defined as\n\n:<math>d{\\varphi} =  \\frac{\\partial g}{\\partial x^i} dx^i \\wedge dx^I</math>\n\n(using [[Einstein notation]]).  The definition of the exterior derivative is extended [[linear]]ly to a general {{math|''k''}}-form\n\n:<math>\\omega = f_I dx^I,</math>\n\nwhere each of the components of the multi-index {{math|''I''}} run over all the values in {{math|{1, ..., ''n''}<nowiki/>}}. Note that whenever {{math|''i''}} equals one of the components of the multi-index {{math|''I''}} then {{math|1=''dx''{{i sup|''i''}} ∧ ''dx''{{i sup|''I''}} = 0}} (see [[Exterior product]]).\n\nThe definition of the exterior derivative in local coordinates follows from the preceding [[#In terms of axioms|definition in terms of axioms]]. Indeed, with the {{math|''k''}}-form {{math|''φ''}} as defined above,\n\n:<math>\\begin{align}\nd{\\varphi} &= d\\left (g\\,dx^{i_1} \\wedge \\cdots \\wedge dx^{i_k} \\right ) \\\\\n                   &= dg  \\wedge \\left (dx^{i_1} \\wedge \\cdots \\wedge dx^{i_k} \\right ) + g\\,d\\left (\n                      dx^{i_1}\\wedge \\cdots \\wedge dx^{i_k} \\right ) \\\\\n                   &= dg \\wedge dx^{i_1} \\wedge \\cdots \\wedge dx^{i_k} + g \\sum_{p=1}^k (-1)^{p-1} dx^{i_1}\n                      \\wedge \\cdots \\wedge dx^{i_{p-1}} \\wedge d^2x^{i_p} \\wedge dx^{i_{p+1}} \\wedge \\cdots \\wedge d\n                      x^{i_k} \\\\\n                     &= dg \\wedge dx^{i_1} \\wedge \\cdots \\wedge dx^{i_k} \\\\\n                     &= \\frac{\\partial g}{\\partial x^i} dx^i \\wedge dx^{i_1} \\wedge \\cdots \\wedge dx^{i_k} \\\\\n\\end{align}</math>\n\nHere, we have interpreted {{math|''g''}} as a {{math|0}}-form, and then applied the properties of the exterior derivative.\n\nThis result extends directly to the general {{math|''k''}}-form {{math|''ω''}} as\n\n:<math>d{\\omega} = \\frac{\\partial f_I}{\\partial x^i} dx^i \\wedge dx^I .</math>\n\nIn particular, for a {{math|1}}-form {{math|''ω''}}, the components of {{math|''dω''}} in [[Local coordinate system|local coordinates]] are\n:<math>(d\\omega)_{ij} = \\partial_i \\omega_j - \\partial_j \\omega_i. </math>\n\n===In terms of invariant formula===\nAlternatively, an explicit formula can be given for the exterior derivative of a {{math|''k''}}-form {{math|''ω''}}, when paired with {{math|''k'' + 1}} arbitrary smooth [[vector field]]s {{math|''V''<sub>0</sub>,''V''<sub>1</sub>, ..., ''V''<sub>''k''</sub>}}:\n\n:<math>d\\omega(V_0,...,V_k) = \\sum_i(-1)^{i} V_i \\left( \\omega \\left (V_0, \\ldots, \\hat V_i, \\ldots,V_k \\right )\\right) +\\sum_{i<j}(-1)^{i+j}\\omega \\left (\\left [V_i, V_j \\right ], V_0, \\ldots, \\hat V_i, \\ldots, \\hat V_j, \\ldots, V_k \\right )</math>\n\nwhere {{math|[''V<sub>i</sub>'', ''V<sub>j</sub>'']}} denotes the [[Lie bracket of vector fields|Lie bracket]] and a hat denotes the omission of that element:\n\n:<math>\\omega \\left (V_0, \\ldots, \\hat V_i, \\ldots,V_k \\right ) = \\omega \\left (V_0, \\ldots, V_{i-1}, V_{i+1}, \\ldots, V_k \\right ).</math>\n\nIn particular, for {{math|1}}-forms we have: {{math|1=''dω''(''X'', ''Y'') = ''X''(''ω''(''Y'')) − ''Y''(''ω''(''X'')) − ''ω''([''X'', ''Y''])}}, where {{math|''X''}} and {{math|''Y''}} are vector fields, {{math|''X''(''ω''(''Y''))}} is the scalar field defined by the vector field {{math|''X'' ∈ Γ(''TM'')}} applied as a differential operator (\"directional derivative along ''X''\") to the scalar field defined by applying {{math|''ω'' ∈ Γ{{sup|∗}}(''TM'')}} as a covector field to the vector field {{math|''Y'' ∈ Γ(''TM'')}} and likewise for {{math|''Y''(''ω''(''X''))}}.\n\n'''Note:''' Some authors (e.g., Kobayashi–Nomizu and Helgason) use a formula that differs by a factor of {{math|{{sfrac|''k'' + 1}}}}:\n:<math>\\begin{align}d\\omega(V_0,...,V_k) &= {1 \\over k+1} \\sum_i(-1)^{i} V_i \\left( \\omega \\left (V_0, \\ldots, \\hat V_i, \\ldots,V_k \\right )\\right) \\\\\n&+ {1 \\over k+1}  \\sum_{i<j}(-1)^{i+j}\\omega \\left (\\left [V_i, V_j \\right ], V_0, \\ldots, \\hat V_i, \\ldots, \\hat V_j, \\ldots, V_k \\right ).\\end{align}</math>\n\n== Examples ==\n'''Example 1.''' Consider {{math|1=''σ'' = ''u''&thinsp;''dx''{{i sup|1}} ∧ ''dx''{{i sup|2}}}} over a {{math|1}}-form basis {{math|''dx''{{i sup|1}}, ..., ''dx''{{i sup|''n''}}}} for a scalar field {{math|''u''}}. The exterior derivative is:\n\n:<math>\\begin{align}\n  d\\sigma &= du \\wedge dx^1 \\wedge dx^2 \\\\\n                    &= \\left(\\sum_{i=1}^n \\frac{\\partial u}{\\partial x^i} dx^i\\right) \\wedge dx^1 \\wedge dx^2 \\\\\n                    &= \\sum_{i=3}^n \\left( \\frac{\\partial u}{\\partial x^i} dx^i \\wedge dx^1 \\wedge dx^2 \\right )\n\\end{align}</math>\n\nThe last formula follows easily from the properties of the [[exterior product]]. Namely, {{math|1=''dx''{{i sup|''i''}} ∧ ''dx''{{i sup|''i''}} = 0}}.\n\n'''Example 2.''' Let {{math|1=''σ'' = ''u''&thinsp;''dx'' + ''v''&thinsp;''dy''}} be a {{math|1}}-form defined over {{math|ℝ{{sup|2}}}}. By applying the above formula to each term (consider {{math|1=''x''{{i sup|1}} = ''x''}} and {{math|1=''x''{{i sup|2}} = ''y''}}) we have the following sum,\n\n:<math>\\begin{align}\nd\\sigma \n    &= \\left( \\sum_{i=1}^2 \\frac{\\partial u}{\\partial x^i} dx^i \\wedge dx \\right) + \\left( \\sum_{i=1}^2 \\frac{\\partial v}{\\partial x^i} dx^i \\wedge dy \\right) \\\\\n    &= \\left(\\frac{\\partial{u}}{\\partial{x}} dx \\wedge dx + \\frac{\\partial{u}}{\\partial{y}} dy \\wedge dx\\right) + \\left(\\frac{\\partial{v}}{\\partial{x}} dx \\wedge dy + \\frac{\\partial{v}}{\\partial{y}} dy \\wedge dy\\right) \\\\\n    &= 0 - \\frac{\\partial{u}}{\\partial{y}} dx \\wedge dy + \\frac{\\partial{v}}{\\partial{x}} dx \\wedge dy + 0 \\\\\n    &= \\left(\\frac{\\partial{v}}{\\partial{x}} - \\frac{\\partial{u}}{\\partial{y}}\\right) dx \\wedge dy\n\\end{align}</math>\n\n== Stokes' theorem on manifolds ==\n{{main|Stokes' theorem}}\n\nIf {{math|''M''}} is a compact smooth orientable {{math|''n''}}-dimensional manifold with boundary, and {{math|''ω''}} is an {{math|(''n'' − 1)}}-form on {{math|''M''}}, then the generalized form of [[Stokes' theorem]] states that:\n\n:<math>\\int_M d\\omega = \\int_{\\partial{M}} \\omega</math>\n\nIntuitively, if one thinks of {{math|''M''}} as being divided into infinitesimal regions, and one adds the flux through the boundaries of all the regions, the interior boundaries all cancel out, leaving the total flux through the boundary of {{math|''M''}}.\n\n== Further properties ==\n\n===Closed and exact forms===\n{{main article|Closed and exact forms}}\nA {{math|''k''}}-form {{math|''ω''}} is called ''closed'' if {{math|1=''dω'' = 0}}; closed forms are the [[Kernel (algebra)|kernel]] of {{math|''d''}}. {{math|''ω''}} is called ''exact'' if {{math|1=''ω'' = ''dα''}} for some {{math|(''k'' − 1)}}-form {{math|''α''}}; exact forms are the [[Image (mathematics)|image]] of {{math|''d''}}. Because {{math|1=''d''{{i sup|2}} = 0}}, every exact form is closed. The [[Poincaré lemma]] states that in a contractible region, the converse is true.\n\n===de Rham cohomology===\nBecause the exterior derivative {{math|''d''}} has the property that {{math|1=''d''{{i sup|2}} = 0}}, it can be used as the [[Cochain complex|differential]] (coboundary) to define [[de Rham cohomology]] on a manifold. The {{math|''k''}}-th de Rham cohomology (group) is the vector space of closed {{math|''k''}}-forms modulo the exact {{math|''k''}}-forms; as noted in the previous section, the Poincaré lemma states that these vector spaces are trivial for a contractible region, for {{math|''k'' > 0}}. For [[smooth manifold]]s, integration of forms gives a natural homomorphism from the de Rham cohomology to the singular cohomology over {{math|ℝ}}. The theorem of de Rham shows that this map is actually an isomorphism, a far-reaching generalization of the Poincaré lemma. As suggested by the generalized Stokes' theorem, the exterior derivative is the \"dual\" of the [[Chain complex#Formal definition|boundary map]] on singular simplices.\n\n===Naturality===\nThe exterior derivative is natural in the technical sense: if {{math|&thinsp;''f'' : ''M'' → ''N''}} is a smooth map and {{math|Ω{{sup|''k''}}}} is the contravariant smooth [[functor]] that assigns to each manifold the space of {{math|''k''}}-forms on the manifold, then the following diagram commutes\n\n:[[Image:Exteriorderivnatural.png|none]]\n\nso {{math|1=''d''(&thinsp;''f''{{i sup|∗}}''ω'') = &thinsp;''f''{{i sup|∗}}''dω''}}, where {{math|&thinsp;''f''{{i sup|∗}}}} denotes the [[pullback (differential geometry)|pullback]] of {{math|&thinsp;''f''&thinsp;}}. This follows from that {{math|&thinsp;''f''{{i sup|∗}}''ω''(·)}}, by definition, is {{math|''ω''(&thinsp;''f''<sub>∗</sub>(·))}}, {{math|&thinsp;''f''<sub>∗</sub>}} being the [[Pushforward (differential)|pushforward]] of {{math|&thinsp;''f''&thinsp;}}. Thus {{math|''d''}} is a [[natural transformation]] from {{math|Ω{{sup|''k''}}}} to {{math|Ω{{sup|''k''+1}}}}.\n\n== Exterior derivative in vector calculus ==\nMost [[vector calculus]] operators are special cases of, or have close relationships to, the notion of exterior differentiation.\n\n===Gradient===\nA [[smooth function]] {{math|&thinsp;''f'' : ''M'' → ℝ}} on a real differentiable manifold {{math|''M''}} is a {{math|0}}-form. The exterior derivative of this {{math|0}}-form is the {{math|1}}-form {{math|''df''}}.\n\nWhen an inner product {{math|{{langle}}·,·{{rangle}}}} is defined, the [[gradient]] {{math|∇''f''&thinsp;}} of a function {{math|&thinsp;''f''&thinsp;}} is defined as the unique vector in {{math|''V''}} such that its inner product with any element of {{math|''V''}} is the directional derivative of {{math|&thinsp;''f''&thinsp;}} along the vector, that is such that\n\n:<math>\\langle \\nabla f, \\cdot \\rangle = df = \\sum_{i=1}^n \\frac{\\partial f}{\\partial x^i}\\, dx^i .</math>\n\nThat is,\n:<math>\\nabla f = (df)^\\sharp = \\sum_{i=1}^n \\frac{\\partial f}{\\partial x^i}\\, (dx^i)^\\sharp ,</math>\nwhere {{math|{{music|sharp}}}} denotes the [[musical isomorphism]] {{math|{{music|sharp}} : ''V''{{sup|∗}} → ''V''}} mentioned earlier that is induced by the inner product.\n\nThe {{math|1}}-form {{math|''df''&thinsp;}} is a section of the [[cotangent bundle]], that gives a local linear approximation to {{math|&thinsp;''f''&thinsp;}} in the cotangent space at each point.\n\n===Divergence===\nA vector field {{math|1=''V'' = (''v''<sub>1</sub>, ''v''<sub>2</sub>, ... ''v<sub>n</sub>'')}} on {{math|ℝ{{sup|''n''}}}} has a corresponding {{math|(''n'' − 1)}}-form\n\n:<math>\\begin{align}\n\\omega_V &= v_1 \\left (dx^2 \\wedge \\cdots \\wedge dx^n \\right) - v_2 \\left (dx^1 \\wedge dx^3  \\wedge \\cdots \\wedge dx^n \\right ) + \\cdots + (-1)^{n-1}v_n \\left (dx^1 \\wedge \\cdots \\wedge dx^{n-1} \\right) \\\\\n&=\\sum_{i=1}^n (-1)^{(i-1)}v_i \\left (dx^1 \\wedge \\cdots \\wedge dx^{i-1} \\wedge \\widehat{dx^{i}} \\wedge dx^{i+1} \\wedge \\cdots \\wedge dx^n \\right )\n\\end{align}</math>\n\nwhere <math>\\widehat{dx^{i}}</math> denotes the omission of that element.\n\n(For instance, when {{math|1=''n'' = 3}}, i.e. in three-dimensional space, the {{math|2}}-form {{math|''ω<sub>V</sub>''}} is locally the [[scalar triple product]] with {{math|''V''}}.)  The integral of {{math|''ω<sub>V</sub>''}} over a hypersurface is the [[flux]] of {{math|''V''}} over that hypersurface.\n\nThe exterior derivative of this {{math|(''n'' − 1)}}-form is the {{math|''n''}}-form\n\n:<math>d\\omega _V = \\operatorname{div} V \\left (dx^1 \\wedge dx^2 \\wedge \\cdots \\wedge dx^n \\right ).</math>\n\n===Curl===\nA vector field {{math|''V''}} on {{math|ℝ{{sup|''n''}}}} also has a corresponding {{math|1}}-form\n\n:<math>\\eta_V = v_1  dx^1 + v_2 dx^2 + \\cdots + v_n dx^n.</math>,\n\nLocally, {{math|''η<sub>V</sub>''}} is the dot product with {{math|''V''}}. The integral of {{math|''η<sub>V</sub>''}} along a path is the [[Mechanical work|work]] done against {{math|−''V''}} along that path.\n\nWhen {{math|1=''n'' = 3}}, in three-dimensional space, the exterior derivative of the {{math|1}}-form {{math|''η<sub>V</sub>''}} is the {{math|2}}-form\n\n:<math>d\\eta_V = \\omega_{\\operatorname{curl} V}.</math>\n\n===Invariant formulations of operators in vector calculus===\nThe standard [[vector calculus]] operators can be generalized for any [[pseudo-Riemannian manifold]], and written in coordinate-free notation as follows:\n\n:<math>\n\\begin{array}{rcccl}\n      \\operatorname{grad} f &\\equiv& \\nabla f        &=& \\left( d f \\right)^\\sharp \\\\\n      \\operatorname{div} F  &\\equiv& \\nabla \\cdot F  &=& {\\star d {\\star} ( F^\\flat )} \\\\\n      \\operatorname{curl} F &\\equiv& \\nabla \\times F &=& \\left( {\\star} d ( F^\\flat ) \\right)^\\sharp \\\\\n      \\Delta f              &\\equiv& \\nabla^2 f      &=& {\\star} d {\\star} d f \\\\\n                            &      & \\nabla^2 F      &=& \\left(d{\\star}d{\\star}(F^{\\flat}) - {\\star}d{\\star}d(F^{\\flat})\\right)^{\\sharp} , \\\\\n\\end{array}\n</math>\n\nwhere {{math|⋆}} is the [[Hodge dual|Hodge star operator]], {{music|flat}} and {{music|sharp}} are the [[musical isomorphism]]s, {{mvar|&thinsp;f&thinsp;}} is a [[scalar field]] and {{mvar|F}} is a [[vector field]].\n\nNote that the expression for <math>\\operatorname{curl}</math> makes sense only in three dimensions, since it requires <math>\\sharp</math> to act on <math>{\\star} d( F^\\flat )</math>, which is a form of degree <math>n-2</math>.\n\n== See also ==\n*[[Exterior covariant derivative]]\n*[[de Rham complex]]\n*[[Discrete exterior calculus]]\n*[[Green's theorem]]\n*[[Lie derivative]]\n*[[Stokes' theorem]]\n*[[Fractal derivative]]\n\n== Notes ==\n{{reflist}}\n\n== References ==\n* {{cite journal | last =Cartan | first =Élie | author-link =Élie Cartan\n | title =Sur certaines expressions différentielles et le problème de Pfaff\n | journal =Annales Scientifiques de l'École Normale Supérieure |series=Série 3\n | volume =16 | pages =239–332 | publisher =Gauthier-Villars | location =Paris | date =1899 | language =French\n | url =http://www.numdam.org/item?id=ASENS_1899_3_16__239_0\n | issn =0012-9593 | jfm =30.0313.04 | access-date = 2 Feb 2016}}\n* {{cite book |author=Conlon, Lawrence |title=Differentiable manifolds |publisher=Birkhäuser |location=Basel, Switzerland |year=2001 |pages= 239 |isbn=0-8176-4134-3 |oclc= |doi=}}\n* {{cite book |author=Darling, R. W. R. |title=Differential forms and connections |publisher=Cambridge University Press |location=Cambridge, UK |year=1994 |pages=35 |isbn=0-521-46800-0 |oclc= |doi=}}\n* {{cite book |author=Flanders, Harley |title=Differential forms with applications to the physical sciences |publisher=Dover Publications |location=New York |year=1989 |pages=20 |isbn=0-486-66169-5 |oclc= |doi=}}\n* {{cite book|url=https://archive.org/details/LoomisL.H.SternbergS.AdvancedCalculusRevisedEditionJonesAndBartlett|title=Advanced Calculus|first=Lynn H.|last2=Sternberg|first2=Shlomo|publisher=Jones and Bartlett|year=1989|isbn=0-486-66169-5|location=Boston|pages=304–473 (ch. 7–11)|chapter=|doi=|oclc=|author=Loomis}}\n* {{cite book |author=Ramanan, S. |title=Global calculus |publisher=American Mathematical Society |location=Providence, Rhode Island |year=2005 |pages=54 |isbn=0-8218-3702-8 |oclc= |doi=}}\n* {{cite book | last =Spivak | first =Michael | author-link =Michael Spivak | title =[[Calculus on Manifolds (book)|Calculus on Manifolds]]\n | publisher =Westview Press | date =1971 | location =Boulder, Colorado | url = | doi = | isbn =9780805390216 }}\n* {{citation|last=Warner|first= Frank W.|title= Foundations of differentiable manifolds and Lie groups|series= Graduate Texts in Mathematics|volume= 94|publisher= Springer|year=1983|isbn= 0-387-90894-3}}\n\n{{Tensors}}\n\n[[Category:Differential forms]]\n[[Category:Differential operators]]\n[[Category:Generalizations of the derivative]]"
    },
    {
      "title": "Fréchet derivative",
      "url": "https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative",
      "text": "{{distinguish|Differentiation in Fréchet spaces}}\n\nIn [[mathematics]], the '''Fréchet derivative''' is a [[derivative]] defined on [[Banach space]]s. Named after [[Maurice René Fréchet|Maurice Fréchet]], it is commonly used to generalize the derivative of a [[real-valued function]] of a single real variable to the case of a [[vector-valued function]] of multiple real variables, and to define the [[functional derivative]] used widely in the [[calculus of variations]].\n\nGenerally, it extends the idea of the derivative from real-valued [[function (mathematics)|functions]] of one real variable to functions on Banach spaces. The Fréchet derivative should be contrasted to the more general [[Gateaux derivative]] which is a generalization of the classical [[directional derivative]].\n\nThe Fréchet derivative has applications to nonlinear problems throughout [[mathematical analysis]] and physical sciences, particularly to the calculus of variations and much of nonlinear analysis and [[nonlinear functional analysis]].\n\n== Definition ==\nLet ''V'' and ''W'' be [[normed vector space]]s, and <math>U\\subset V</math> be an [[open subset]] of ''V''. A function ''f'' : ''U'' → ''W'' is called ''Fréchet differentiable'' at <math>x \\in U</math> if there exists a [[bounded linear operator]] <math>A:V\\to W</math> such that\n\n:<math>\\lim_{\\|h\\| \\to 0} \\frac{ \\| f(x + h) - f(x) - Ah \\|_{W} }{ \\|h\\|_{V} } = 0.</math>\n\nThe [[limit (mathematics)|limit]] here is meant in the usual sense of a [[limit of a function]] defined on a metric space (see [[Limit of a function#Functions on metric spaces|Functions on metric spaces]]), using ''V'' and ''W'' as the two metric spaces, and the above expression as the function of argument ''h'' in ''V''. As a consequence, it must exist for all [[sequence]]s <math>\\langle h_n\\rangle_{n=1}^{\\infty}</math> of non-zero elements of ''V'' which converge to the zero vector <math>h_n \\to 0.</math> Equivalently, the first-order expansion holds, in [[Landau notation]]\n\n:<math> f(x + h) = f(x) + Ah +o(h).</math>\n\nIf there exists such an operator ''A'', it is unique, so we write <math>Df(x)=A </math> and call it the ''Fréchet derivative'' of ''f'' at ''x''.\nA function ''f'' that is Fréchet differentiable for any point of ''U'' is said to be C<sup>1</sup> if the function\n\n:<math>Df:U\\to B(V,W) ; x \\mapsto Df(x)</math>\n\nis continuous. Note that this is not the same as requiring that the map <math>Df(x) : V \\to W</math> be continuous for each value of <math>x</math> (which is assumed; bounded and continuous are equivalent).\n\nThis notion of derivative is a generalization of the ordinary derivative of a function on the [[real number]]s <math>f:\\R\\to\\R</math> since the linear maps from <math>\\R</math> to <math>\\R</math> are just multiplication by a real number. In this case, ''Df''(''x'') is the function <math>t \\mapsto f'(x)t </math>.\n\n== Properties ==\nA function differentiable at a point is continuous at that point.\n\nDifferentiation is a linear operation in the following sense: if ''f'' and ''g'' are two maps ''V'' → ''W'' which are differentiable at ''x'', and ''r'' and ''s'' are scalars (two real or [[complex number]]s), then ''rf'' + ''sg'' is differentiable at ''x'' with D(''rf'' + ''sg'')(''x'') = ''r''D''f''(''x'') + ''s''D''g''(''x'').\n\nThe [[chain rule]] is also valid in this context: if ''f'' : ''U'' → ''Y'' is differentiable at ''x'' in ''U'', and ''g'' : ''Y'' → ''W'' is differentiable at ''y'' = ''f''(''x''), then the composition ''g'' o ''f'' is differentiable in ''x'' and the derivative is the [[Function composition|composition]] of the derivatives:\n\n:<math>D(g \\circ f)(x) = Dg(f(x))\\circ Df(x).</math>\n\n== Finite dimensions ==\n\nThe Fréchet derivative in finite-dimensional spaces is the usual derivative. In particular, it is represented in coordinates by the [[Jacobian matrix and determinant|Jacobian matrix]].\n\nSuppose that ''f'' is a map, <math>f:U\\sub\\R^n\\to\\R^m</math> with ''U'' an open set. If ''f'' is Fréchet differentiable at a point ''a'' ∈ ''U'', then its derivative is\n\n:<math>\\begin{cases} Df(a): \\R^n \\to \\R^m \\\\ Df(a)(v) = J_f(a) v \\end{cases}</math>\n\nwhere ''J''<sub>''f''</sub>(''a'') denotes the Jacobian matrix of ''f'' at ''a''.\n\nFurthermore, the partial derivatives of ''f'' are given by\n\n:<math> \\frac{\\partial f}{\\partial x_i}(a) = Df(a)(e_i) = J_f(a) e_i, </math>\n\nwhere {''e''<sub>''i''</sub>} is the canonical basis of <math>\\R^n.</math> Since the derivative is a linear function, we have for all vectors <math>h \\in \\R^n</math> that the [[directional derivative]] of ''f'' along ''h'' is given by\n\n:<math> Df(a)(h) = \\sum_{i=1}^{n} h_i \\frac{\\partial f}{\\partial x_i}(a). </math>\n\nIf all partial derivatives of ''f'' exist and are continuous, then ''f'' is Fréchet differentiable (and, in fact, C<sup>1</sup>). The converse is not true: the function\n\n:<math> f(x, y)= \\begin{cases} (x^2+y^2)\\sin \\left ((x^2+y^2)^{-1/2} \\right ) & (x, y)\\ne (0, 0)\\\\ 0 & (x, y)=(0, 0) \\end{cases}</math>\n\nis Fréchet differentiable and yet fails to have continuous partial derivatives at <math>(0,0)</math>.\n\n== Example in infinite dimensions == \nOne of the simplest (nontrivial) examples in infinite dimensions, is the one where the domain is a Hilbert space (<math>H</math>) and the function in interest is the norm. So consider <math>\\|\\cdot\\|:H\\to\\mathbb{R}</math>.\n\nFirst assume that <math>x\\ne 0</math>. Then we claim that the Frechet derivative of <math>\\|\\cdot\\|</math> at <math>x</math> is the linear functional <math>D</math>, defined by <math>\\displaystyle Dv:=\\left\\langle v,\\frac{x}{\\|x\\|}\\right\\rangle </math>. Indeed, <math>\\frac{|\\|x+h\\|-\\|x\\|-Dh|}{\\|h\\|}=\\frac{|\\|x\\|\\|x+h\\|-\\langle x,x\\rangle-\\langle x,h\\rangle|}{\\|x\\|\\|h\\|}=\\frac{|\\|x\\|\\|x+h\\|-\\langle x,x+h\\rangle|}{\\|x\\|\\|h\\|}=\\frac{|\\langle x,x\\rangle \\langle x+h,x+h\\rangle-\\langle x,x+h\\rangle^2|}{\\|x\\|\\|h\\|(|\\|x\\|\\|x+h\\|+\\langle x,x+h\\rangle|)}</math>\nAfter expanding the numerator it simplifies to <math>\\langle x,x \\rangle \\langle h,h \\rangle-\\langle x,h \\rangle^2</math>. Thus, using continuity of the norm and inner product we obtain <math>\\lim_{h\\to 0}\\frac{|\\|x+h\\|-\\|x\\|-Dh|}{\\|h\\|}=\\frac{1}{2\\|x\\|^3}\\lim_{h\\to 0}\\frac{\\langle x,x \\rangle \\langle h,h \\rangle-\\langle x,h \\rangle^2}{\\|h\\|}=\\frac{1}{2\\|x\\|^3}\\lim_{h\\to 0}\\left(\\langle x,x\\rangle\\|h\\|-\\langle x,h\\rangle \\left\\langle x,\\frac{h}{\\|h\\|}\\right\\rangle\\right)</math>.\nThe first summand obviously tends to <math>0</math> as <math>h\\to 0</math>. For the second, <math>\\langle x,h\\rangle</math> also tends to zero and <math>\\displaystyle\\left\\langle x,\\frac{h}{\\|h\\|}\\right\\rangle</math> is bounded by <math>\\|x\\|</math> (because of the Cauchy-Bunyakovsky-Schwarz inequality). Thus the whole limit is <math>0</math>.\n\nNow we show that at <math>x=0</math> the norm is not differentiable, i.e. there does not exist bounded linear functional <math>D</math> such that the limit in question to be <math>0</math>. Let <math>D</math> be any linear functional. [[Riesz representation theorem]] tells us that <math>D</math> could be defined by <math>Dv=\\langle a,v\\rangle</math> for some <math>a\\in H</math>.\nConsider <math>A(h)=\\frac{|\\|0+h\\|-\\|0\\|-Dh|}{\\|h\\|}=\\left|1-\\left\\langle a,\\frac{h}{\\|h\\|}\\right\\rangle\\right|</math>. In order for the norm to be differentiable at <math>0</math> we must have <math>\\displaystyle \\lim_{h\\to 0}A(h)=0</math>. We will show that this is not true for any <math>a</math>. If <math>a=0</math> obviously <math>A(h)=1</math> independently of <math>h</math>, hence this is not the derivative. Assume <math>a\\ne 0</math>. If we take <math>h</math> tending to zero in the direction of <math>-a</math> (i.e. <math>h=t\\cdot(-a)</math>, where <math>t \\to 0 ^{+}</math>) then <math>A(h)=|1+\\|a\\||>1>0</math>, hence <math>\\displaystyle \\lim_{h\\to 0} A(h)\\ne 0</math> (If we take <math>h</math> tending to zero in the direction of <math>a</math> we would even see this limit does not exists since in this case we will obtain <math>|1-\\|a\\||</math>).\n\nThe result just obtained agrees with the results in finite dimensions.\n\n== Relation to the Gateaux derivative ==\nA function ''f'' : ''U'' ⊂ ''V'' → ''W'' is called ''[[Gateaux derivative|Gateaux differentiable]]'' at ''x''&nbsp;∈ ''U'' if ''f'' has a directional derivative along all directions at&nbsp;''x''. This means that there exists a function {{nowrap|''g'' : ''V'' → ''W''}} such that\n\n:<math>g(h)=\\lim_{t \\to 0} \\frac{ f(x + th) - f(x) }{ t } </math>\n\nfor any chosen vector ''h'' in ''V'', and where ''t'' is from the scalar field associated with ''V'' (usually, ''t'' is [[real numbers|real]]).<ref>It is common to include in the definition that the resulting map ''g'' must be a [[continuous linear operator]]. We avoid adopting this convention here to allow examination of the widest possible class of pathologies.</ref>\n\nIf ''f'' is Fréchet differentiable at ''x'', it is also Gateaux differentiable there, and ''g'' is just the linear operator ''A''&nbsp;= ''Df''(''x'').\n\nHowever, not every Gateaux differentiable function is Fréchet differentiable. This is analogous to the fact that the existence of all directional derivatives at a point does not guarantee total differentiability (or even continuity) at that point.{{Clarify|date=February 2017}}\nFor example, the real-valued function ''f'' of two real variables defined by\n\n:<math>f(x, y)= \\begin{cases} \\frac{x^3}{x^2+y^2} & (x, y)\\ne (0, 0)\\\\ 0 & (x, y)=(0, 0) \\end{cases}</math>\n\nis continuous and Gateaux differentiable at (0, 0), with its derivative being\n\n:<math>g(a, b)=\\begin{cases} \\frac{a^3}{a^2+b^2}& (a, b)\\ne (0, 0)\\\\ 0 & (a, b)=(0, 0) \\end{cases}</math>\n\nThe function ''g'' is not a linear operator, so this function is not Fréchet differentiable.\n\nMore generally, any function of the form <math>f(x,y) = g (r) h (\\phi)</math>, where ''r'' and φ are the [[polar coordinates]] of (''x'',''y''), is continuous and Gateaux differentiable at (0,0) if ''g'' is differentiable at 0 and <math>h(\\phi + \\pi) = -h(\\phi)</math>, but the Gateaux derivative is only linear and the Fréchet derivative only exists if ''h'' is [[sinusoidal]].\n\nIn another situation, the function ''f'' given by\n\n:<math>f(x, y)= \\begin{cases} \\frac{x^3y}{x^6+y^2} & (x, y)\\ne (0, 0)\\\\ 0 & (x, y)=(0, 0) \\end{cases}</math>\n\nis Gateaux differentiable at (0,&nbsp;0), with its derivative there being ''g''(''a'',&nbsp;''b'')&nbsp;= 0 for all (''a'',&nbsp;''b''), which ''is'' a linear operator. However, ''f'' is not continuous at (0, 0) (one can see by approaching the origin along the curve (''t'', ''t''<sup>3</sup>)) and therefore ''f'' cannot be Fréchet differentiable at the origin.\n\nA more subtle example is\n\n:<math>f(x, y)= \\begin{cases} \\frac{x^2y}{x^4+y^2}\\sqrt{x^2+y^2} & (x, y)\\ne (0, 0)\\\\ 0 & (x, y)=(0, 0) \\end{cases}</math>\n\nwhich is a continuous function that is Gateaux differentiable at (0,&nbsp;0), with its derivative being ''g''(''a'',&nbsp;''b'')&nbsp;= 0 there, which is again linear. However, ''f'' is not Fréchet differentiable. If it were, its Fréchet derivative would coincide with its Gateaux derivative, and hence would be the zero operator; hence the limit\n\n:<math>\\lim_{(x,y)\\to(0,0)}\\left|\\frac{x^2y}{x^4+y^2}\\right|</math>\n\nwould have to be zero, whereas approaching the origin along the curve (''t'', ''t''<sup>2</sup>) shows that this limit does not exist.\n\nThese cases can occur because the definition of the Gateaux derivative only requires that the [[difference quotient]]s converge along each direction individually, without making requirements about the rates of convergence for different directions. Thus, for a given ε, although for each direction the difference quotient is within ε of its limit in some neighborhood of the given point, these neighborhoods may be different for different directions, and there may be a sequence of directions for which these neighborhoods become arbitrarily small. If a sequence of points is chosen along these directions, the quotient in the definition of the Fréchet derivative, which considers all directions at once, may not converge. Thus, in order for a linear Gateaux derivative to imply the existence of the Fréchet derivative, the difference quotients have to [[uniform convergence|converge uniformly]] for all directions.\n\nThe following example only works in infinite dimensions. Let ''X'' be a Banach space, and φ a [[linear functional]] on ''X'' that is ''discontinuous'' at ''x''&nbsp;= 0 (a [[discontinuous linear functional]]). Let\n\n:<math>f(x) = \\|x\\|\\varphi(x).</math>\n\nThen ''f''(''x'') is Gateaux differentiable at ''x''&nbsp;= 0 with derivative&nbsp;0. However, ''f''(''x'') is not Fréchet differentiable since the limit\n\n:<math>\\lim_{x\\to 0}\\varphi(x)</math>\n\ndoes not exist.\n\n== Higher derivatives ==\nIf {{nowrap|''f'' : ''U'' → ''W''}} is a differentiable function at all points in an open subset ''U'' of ''V'', it follows that its derivative\n\n:<math>D f : U \\to L(V, W)</math>\n\nis a function from ''U'' to the space {{nowrap|''L''(''V'', ''W'')}} of all bounded linear operators from ''V'' to ''W''. This function may also have a derivative, the ''second order derivative'' of ''f'', which, by the definition of derivative, will be a map\n\n:<math>D^2 f : U \\to L\\big(V, L(V, W)\\big). </math>\n\nTo make it easier to work with second-order derivatives, the space on the right-hand side is identified with the Banach space {{nowrap|''L''<sup>2</sup>(''V'' × ''V'', ''W'')}} of all continuous [[bilinear map]]s from ''V'' to ''W''. An element ''φ'' in {{nowrap|''L''(''V'', ''L''(''V'', ''W''))}} is thus identified with ''ψ'' in {{nowrap|''L''<sup>2</sup>(''V'' × ''V'', ''W'')}} such that for all ''x'' and ''y'' in ''V'',\n\n:<math>\\varphi(x)(y)=\\psi(x, y).</math>\n\n(Intuitively: a function ''φ'' linear in ''x'' with ''φ''(''x'') linear in ''y'' is the same as a bilinear function ''ψ'' in ''x'' and ''y'').\n\nOne may differentiate\n\n:<math>D^2 f : U \\to L^2(V\\times V, W) </math>\n\nagain, to obtain the ''third order derivative'', which at each point will be a ''trilinear map'', and so on. The ''n''-th derivative will be a function\n\n:<math>D^n f : U \\to L^n(V\\times V\\times \\cdots \\times V, W),</math>\n\ntaking values in the Banach space of continuous [[multilinear map]]s in ''n'' arguments from ''V'' to ''W''. Recursively, a function ''f'' is {{nowrap|''n'' + 1}} times differentiable on ''U'' if it is ''n'' times differentiable on ''U'' and for each ''x'' in ''U'' there exists a continuous multilinear map ''A'' of {{nowrap|''n'' + 1}} arguments such that the limit\n\n:<math>\\lim_{h_{n+1} \\to 0} \\frac{ \\left \\| D^nf \\left(x + h_{n+1} \\right )(h_1, h_2, \\ldots, h_n) - D^nf(x)(h_1, h_2, \\ldots, h_n) - A \\left (h_1, h_2, \\ldots, h_n, h_{n+1} \\right ) \\right \\| }{ \\|h_{n+1}\\| } = 0</math>\n\nexists [[uniform convergence|uniformly]] for ''h''<sub>1</sub>, ''h''<sub>2</sub>, ..., ''h''<sub>''n''</sub> in bounded sets in ''V''. In that case, ''A'' is the {{nowrap|(''n'' + 1)}}st derivative of ''f'' at ''x''.\n\nMoreover, we may obviously identify a member of the space <math> L^n(V\\times V\\times \\cdots \\times V, W) </math> with a linear map <math> L(\\bigotimes_{j=1}^n V_j, W) </math> through the identification <math> f(x_1,x_2, \\ldots, x_n) = f(x_1 \\otimes x_2 \\otimes \\cdots \\otimes x_n) </math>, thus viewing the derivative as a linear map.\n\n== Generalization to topological vector spaces ==\nThe notion of the Fréchet derivative can be generalized to arbitrary [[topological vector space]]s (TVS) ''X'' and ''Y''. Letting ''U'' be an open subset of ''X'' that contains the origin and given a function <math>f: U \\to Y</math> such that <math>f(0) = 0,</math> we first define what it means for this function to have 0 as its derivative. We say that this function ''f'' is tangent to 0 if for every open neighborhood of 0, <math>W \\sub Y</math> there exists an open neighborhood of 0, <math>V\\sub X</math> and a function <math>o: \\R \\to \\R</math> such that\n\n:<math>\\lim_{t\\to 0} \\frac{o(t)}{t} = 0,</math>\n\nand for all ''t'' in some neighborhood of the origin, <math>f(tV) \\sub o(t) W.</math>\n\nWe can now remove the constraint that <math>f(0) = 0</math> by defining ''f'' to be Fréchet differentiable at a point <math>x_0 \\in U</math> if there exists a continuous linear operator <math>\\lambda : X \\to Y</math> such that <math>f(x_0 + h) - f(x_0) - \\lambda h</math>, considered as a function of ''h'', is tangent to 0. (Lang p.&nbsp;6)\n\nIf the Fréchet derivative exists then it is unique. Furthermore, the Gateaux derivative must also exist and be equal the Fréchet derivative in that for all <math> v \\in X</math>,\n\n:<math> \\lim_{\\tau \\to 0}\\frac{f(x_0 + \\tau v) - f(x_0)}{\\tau} = f'(x_0) v,</math>\n\nwhere <math>f'(x_0)</math> is the Fréchet derivative. A function that is Fréchet differentiable at a point is necessarily continuous there and sums and scalar multiples of Fréchet differentiable functions are differentiable so that the space of functions that are Fréchet differentiable at a point form a subspace of the functions that are continuous at that point. The chain rule also holds as does the Leibniz rule whenever ''Y'' is an algebra and a TVS in which multiplication is continuous.\n\n== See also ==\n* [[Generalizations of the derivative]]\n* [[Infinite-dimensional holomorphy]]\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n*{{Citation | last=Cartan | first=Henri | authorlink=Henri Cartan| title=Calcul différentiel | publisher=Hermann | location=Paris | mr=0223194 | year=1967}}.\n*{{Citation | last=Dieudonné | first=Jean |authorlink= Jean Dieudonné| title=Foundations of modern analysis | publisher=[[Academic Press]] | location=Boston, MA | mr=0349288 | year=1969}}.\n*{{Citation | last=Lang | first=Serge | authorlink=Serge Lang| title=Differential and Riemannian Manifolds | publisher=[[Springer Science+Business Media|Springer]] | isbn=0-387-94338-2 | year=1995}}.\n*{{Citation | last=Munkres | first=James R. | authorlink=James Munkres| title=Analysis on manifolds | publisher=[[Addison-Wesley]] | isbn=978-0-201-51035-5 | mr=1079066 | year=1991}}.\n*{{Citation | editor1-last=Previato | editor1-first=Emma |editor1-link=Emma Previato| title=Dictionary of applied math for engineers and scientists | publisher=[[CRC Press]] | location=London | series=Comprehensive Dictionary of Mathematics | isbn=978-1-58488-053-0 | mr=1966695 | year=2003}}.\n*{{Citation | editor1-last=Coleman | editor1-first=Rodney | title=Calculus on Normed Vector Spaces | publisher=[[Springer Science+Business Media|Springer]] | series=Universitext | isbn=978-1-4614-3894-6 | year=2012}}.\n\n== External links ==\n* B. A. Frigyik, S. Srivastava and M. R. Gupta, ''[http://www.ee.washington.edu/techsite/papers/documents/UWEETR-2008-0001.pdf Introduction to Functional Derivatives]'', UWEE Tech Report 2008-0001.\n* http://www.probability.net. This webpage is mostly about basic probability and measure theory, but there is nice chapter about Frechet derivative in Banach spaces (chapter about Jacobian formula). All the results are given with proof.\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Frechet derivative}}\n[[Category:Banach spaces]]\n[[Category:Generalizations of the derivative]]"
    },
    {
      "title": "Gateaux derivative",
      "url": "https://en.wikipedia.org/wiki/Gateaux_derivative",
      "text": "{{Use dmy dates|date=July 2013}}\nIn [[mathematics]], the '''Gateaux differential''' or '''Gateaux derivative''' is a generalization of the concept of [[directional derivative]] in [[differential calculus]]. Named after [[René Gateaux]], a French mathematician who died young in [[World War I]], it is defined for functions between [[locally convex]] [[topological vector space]]s such as [[Banach space]]s.  Like the [[Fréchet derivative]] on a Banach space, the Gateaux differential is often used to formalize the [[functional derivative]] commonly used in the [[calculus of variations]] and [[physics]].\n\nUnlike other forms of derivatives, the Gateaux differential of a function may be [[nonlinear]]. However, often the definition of the Gateaux differential also requires that it be a [[continuous linear transformation]].  Some authors, such as {{harvtxt|Tikhomirov|2001}}, draw a further distinction between the Gateaux differential (which may be nonlinear) and the Gateaux derivative (which they take to be linear).  In most applications, continuous linearity follows from some more primitive condition which is natural to the particular setting, such as imposing [[holomorphic function|complex differentiability]] in the context of [[infinite dimensional holomorphy]] or [[continuously differentiable|continuous differentiability]] in nonlinear analysis.\n\n==Definition==\nSuppose <math>X</math> and <math>Y</math> are [[locally convex]] [[topological vector space]]s (for example,  [[Banach space]]s), <math>U \\subset X</math> is open, and <math>F : X \\to Y</math>.  The Gateaux differential <math>dF(u; \\psi)</math> of <math>F</math> at <math>u \\in U</math> in the direction <math>\\psi \\in X</math> is defined as\n\n{{NumBlk|:|<math>\ndF(u;\\psi)=\\lim_{\\tau\\rightarrow 0}\\frac{F(u+\\tau \\psi)-F(u)}{\\tau}=\\left.\\frac{d}{d\\tau}F(u+\\tau \\psi)\\right|_{\\tau=0} \n</math>|{{EquationRef|1}}}}\n\nIf the limit exists for all <math>\\psi \\in X</math>, then one says that <math>F</math> is Gateaux differentiable at <math>u</math>.\n\nThe limit appearing in ({{EquationNote|1}}) is taken relative to the topology of <math>Y</math>.  If <math>X</math> and <math>Y</math> are [[real numbers|real]] topological vector spaces, then the limit is taken for real <math>\\tau</math>. On the other hand, if <math>X</math> and <math>Y</math> are [[complex numbers|complex]] topological vector spaces, then the limit above is usually taken as <math>\\tau \\to 0</math> in the [[complex plane]] as in the definition of [[holomorphic function|complex differentiability]].  In some cases, a [[weak topology|weak limit]] is taken instead of a strong limit, which leads to the notion of a weak Gateaux derivative.\n\n==Linearity and continuity==\nAt each point <math>u \\in U</math>, the Gateaux differential defines a function\n\n:<math>dF(u;\\cdot) : X \\rightarrow Y.</math>\n\nThis function is homogeneous in the sense that for all scalars <math>\\alpha</math>,\n\n:<math>dF(u;\\alpha\\psi)=\\alpha dF(u;\\psi).\\,</math>\n\nHowever, this function need not be additive, so that the Gateaux differential may fail to be linear, unlike the [[Fréchet derivative]].  Even if linear, it may fail to depend continuously on <math>\\psi</math> if <math>X</math> and <math>Y</math> are infinite dimensional.  Furthermore, for Gateaux differentials that ''are'' linear and continuous in <math>\\psi</math>, there are several inequivalent ways to formulate their [[continuously differentiable|continuous differentiability]].\n\nFor example, consider the real-valued function <math>F</math> of two real variables defined by\n:<math>\nF(x, y)=\n\\begin{cases}\n\\dfrac{x^3}{x^2+y^2} & \\text{if } (x, y)\\ne (0, 0), \\\\\n0 & \\text{if } (x, y)=(0, 0).\n\\end{cases}</math>\nThis is Gateaux differentiable at {{nowrap|(0, 0)}}, with its differential there being\n:<math>dF(0,0; a, b)=\\begin{cases}\n\\dfrac{a^3}{a^2+b^2} & (a,b)\\not=(0,0), \\\\\n0 & (a,b)=(0,0).\n\\end{cases}\n</math>\nHowever this is continuous but not linear in the arguments <math>(a, b)</math>.  In infinite dimensions, any [[discontinuous linear functional]] on <math>X</math> is Gateaux differentiable, but its Gateaux differential at <math>0</math> is linear but not continuous.\n\n;Relation with the Fréchet derivative\n\nIf <math>F</math> is Fréchet differentiable, then it is also Gateaux differentiable, and its Fréchet and Gateaux derivatives agree.  The converse is clearly not true, since the Gateaux derivative may fail to be linear or continuous.  In fact, it is even possible for the Gateaux derivative to be linear and continuous but for the Fréchet derivative to fail to exist.\n\nNevertheless, for functions <math>F</math> from a <math>complex</math> Banach space <math>X</math> to another complex Banach space <math>Y</math>, the Gateaux derivative (where the limit is taken over complex <math>\\tau</math> tending to zero as in the definition of [[holomorphic function|complex differentiability]]) is automatically linear, a theorem of {{harvtxt|Zorn|1945}}.  Furthermore, if <math>F</math> is (complex) Gateaux differentiable at each <math>u \\in U</math> with derivative\n\n:<math>DF(u) : \\psi\\mapsto dF(u;\\psi)</math>\n\nthen <math>F</math> is Fréchet differentiable on <math>U</math> with Fréchet derivative <math>DF</math> {{harv|Zorn|1946}}. This is analogous to the result from basic [[complex analysis]] that a function is [[Analytic function|analytic]] if it is complex differentiable in an open set, and is a fundamental result in the study of [[infinite dimensional holomorphy]].\n\n;Continuous differentiability\n\nContinuous Gateaux differentiability may be defined in two inequivalent ways. Suppose that <math>F : U \\to Y</math> is Gateaux differentiable at each point of the open set <math>U</math>.  One notion of continuous differentiability in <math>U</math> requires that the mapping on the [[product space]]\n\n:<math>dF:U\\times X \\rightarrow Y \\,</math>\n\nbe [[continuous (topology)|continuous]].  Linearity need not be assumed: if <math>X</math> and <math>Y</math> are Fréchet spaces, then <math>dF(u; \\cdot)</math> is automatically bounded and linear for all <math>u</math> {{harv|Hamilton|1982}}.\n\nA stronger notion of continuous differentiability requires that\n\n:<math>u\\mapsto DF(u) \\,</math>\n\nbe a continuous mapping\n\n:<math>U\\to L(X,Y) \\,</math>\n\nfrom <math>U</math> to the space of continuous linear functions from <math>X</math> to <math>Y</math>.  Note that this already presupposes the linearity of <math>DF(u)</math>.\n\nAs a matter of technical convenience, this latter notion of continuous differentiability is typical (but not universal) when the spaces <math>X</math> and <math>Y</math> are Banach, since <math>L(X, Y)</math> is also Banach and standard results from functional analysis can then be employed.  The former is the more common definition in areas of nonlinear analysis where the function spaces involved are not necessarily Banach spaces.  For instance, [[differentiation in Fréchet spaces]] has applications such as the [[Nash–Moser inverse function theorem]] in which the function spaces of interest often consist of [[smooth function]]s on a [[differentiable manifold|manifold]].\n\n==Higher derivatives==\nWhereas higher order Fréchet derivatives are naturally defined as [[multilinear function]]s by iteration, using the isomorphisms <math>L^n(X, Y) = L(X, L^{n - 1}(X, Y))</math>, higher order Gateaux derivative cannot be defined in this way.  Instead the <math>n</math>th order Gateaux derivative of a function <math>F : U \\subset X \\to Y</math> in the direction <math>h</math> is defined by\n{{NumBlk|:|<math>d^nF(u;h) = \\left.\\frac{d^n}{d\\tau^n}F(u+\\tau h)\\right|_{\\tau=0}.</math>|{{EquationRef|2}}}}\nRather than a multilinear function, this is instead a [[homogeneous function]] of degree <math>n</math> in <math>h</math>.\n\nThere is another candidate for the definition of the higher order derivative, the function\n{{NumBlk|:|<math>D^2F(u)\\{h,k\\} = \\lim_{\\tau\\to 0} \\frac{DF(u+\\tau k)h - DF(u)h}{\\tau} = \\left.\\frac{\\partial^2}{\\partial\\tau \\, \\partial\\sigma}F(u+\\sigma h + \\tau k)\\right|_{\\tau=\\sigma=0}</math>|{{EquationRef|3}}}}\nthat arises naturally in the calculus of variations as the [[second variation]] of <math>F</math>, at least in the special case where <math>F</math> is scalar-valued.  However, this may fail to have any reasonable properties at all, aside from being separately homogeneous in <math>h</math> and <math>k</math>.  It is desirable to have sufficient conditions in place to ensure that <math>D^2 F(u)\\{h, k\\}</math> is a symmetric bilinear function of <math>h</math> and <math>k</math>, and that it agrees with the [[polarization of an algebraic form|polarization]] of <math>d^n F</math>.\n\nFor instance, the following sufficient condition holds {{harv|Hamilton|1982}}.  Suppose that <math>F</math> is <math>C^1</math> in the sense that the mapping\n:<math>DF : U\\times X\\to Y</math>\nis continuous in the product topology, and moreover that the second derivative defined by ({{EquationNote|3}}) is also continuous in the sense that\n:<math>D^2F : U\\times X\\times X\\to Y</math>\nis continuous.  Then <math>D^2 F(u)\\{h, k\\}</math> is bilinear and symmetric in <math>h</math> and <math>k</math>.  By virtue of the bilinearity, the polarization identity holds\n:<math>D^2F(u)\\{h,k\\} = \\frac{1}{2}d^2F(u;h+k)-d^2F(u;h)-d^2F(u;k)</math>\nrelating the second order derivative <math>D^2 F(u)</math> with the differential <math>d^2 F(u; -)</math>.  Similar conclusions hold for higher order derivatives.\n\n==Properties==\nA version of the [[fundamental theorem of calculus]] holds for the Gateaux derivative of <math>F</math>, provided <math>F</math> is assumed to be sufficiently continuously differentiable.  Specifically:\n\n* Suppose that <math>F : X \\to Y</math> is <math>C^1</math> in the sense that the Gateaux derivative is a continuous function <math>dF : U \\times X \\to Y</math>.  Then for any <math>u \\in U</math> and <math>h \\in X</math>,\n::<math>F(u+h) - F(u) = \\int_0^1 dF(u+th;h)\\,dt</math>\n:where the integral is the [[Pettis integral|Gelfand–Pettis integral]] (the weak integral).\n\nMany of the other familiar properties of the derivative follow from this, such as multilinearity and commutativity of the higher-order derivatives.  Further properties, also consequences of the fundamental theorem, include:\n\n* ('''The [[chain rule]]''')\n:::<math>d(G\\circ F)(u;x) = dG(F(u); dF(u;x))</math>\n::for all <math>u \\in U</math> and <math>x \\in X</math>.  (Note well that, as with simple [[partial derivative]]s, the Gateaux derivative does ''not'' satisfy the chain rule if the derivative is permitted to be discontinuous.)\n\n* ('''[[Taylor's theorem]] with remainder''')\n::Suppose that the line segment between <math>u \\in U</math> and <math>u + h</math> lies entirely within <math>U</math>.  If <math>F</math> is <math>C^k</math> then\n:::<math>F(u+h)=F(u)+dF(u;h)+\\frac{1}{2!}d^2F(u;h)+\\dots+\\frac{1}{(k-1)!}d^{k-1}F(u;h)+R_k</math>\n::where the remainder term is given by\n:::<math>R_k(u;h)=\\frac{1}{(k-1)!}\\int_0^1(1-t)^{k-1}d^kF(u+th;h)\\,dt</math>\n\n==Example==\nLet <math>X</math> be the [[Hilbert space]] of [[square-integrable function]]s on a [[Lebesgue measure|Lebesgue measurable set]] <math>\\Omega</math> in the [[Euclidean space]] <math>\\mathbb{R}^n</math>. The functional\n\n:<math>E:X\\rightarrow \\mathbb{R}</math>\n:<math> E(u)=\\int_\\Omega F(u(x)) \\, dx </math>\n\nwhere <math>F</math> is a [[real number|real]]-valued function of a real variable and <math>u</math> is defined on <math>\\Omega</math> with real values, has Gateaux derivative\n:<math>\ndE(u,\\psi)=\\langle F'(u),\\psi \\rangle := \\int_\\Omega F'(u(x))\\,\\psi(x) \\,dx.\n</math>\n\nIndeed, the above is the limit <math>\\tau \\to 0</math> of\n\n:<math>\n\\begin{align}\n\\frac{E(u+\\tau\\psi) - E(u)}{\\tau} & = \\frac{1}{\\tau} \\left( \\int_\\Omega F(u+\\tau\\,\\psi)\\,dx - \\int_\\Omega F(u)\\,dx \\right) \\\\[6pt]\n& =\\frac{1}{\\tau} \\left( \\int_\\Omega\\int_0^1 \\frac{d}{ds} F(u+s\\,\\tau\\,\\psi) \\,ds\\,dx \\right) \\\\[6pt]\n& =\\int_\\Omega\\int_0^1 F'(u+s\\tau\\psi)\\,\\psi \\,ds\\,dx.\n\\end{align}\n</math>\n\n==See also==\n* [[Derivative (generalizations)]]\n* [[Differentiation in Fréchet spaces]]\n* [[Fractal derivative]]\n* [[Quasi-derivative]]\n* [[Quaternionic analysis]]\n\n==References==\n* {{Citation | first = R|last=Gateaux |authorlink= René Gateaux| title =Sur les fonctionnelles continues et les fonctionnelles analytiques | pages = 325–327| url =  http://gallica.bnf.fr/ark:/12148/bpt6k31103/f325.image | journal = Comptes rendus hebdomadaires des séances de l'Académie des sciences |publication-place=Paris|volume=157|year=1913 | accessdate=2 September 2012}}.\n* {{Citation | first = R|last=Gateaux|authorlink= René Gateaux|title=Fonctions d'une infinité de variables indépendantes|journal=Bulletin de la Société Mathématique de France|volume=47|year=1919|pages=70–96|url=http://www.numdam.org:80/numdam-bin/item?id=BSMF_1919__47__70_1}}.\n* {{Citation|author=Hamilton, R. S.|authorlink=Richard S. Hamilton |title=The inverse function theorem of Nash and Moser|url=http://projecteuclid.org/euclid.bams/1183549049|\njournal=Bull. Amer. Math. Soc.|issue=1|year=1982|pages=65–222|doi=10.1090/S0273-0979-1982-15004-2|volume=7|mr=656198}}\n* {{Citation | last1=Hille | first1=Einar | authorlink1=Einar Hille | last2=Phillips | first2=Ralph S. | authorlink2=Ralph Phillips (mathematician) | title=Functional analysis and semi-groups | publisher=[[American Mathematical Society]] | location=Providence, R.I. | mr=0423094  | year=1974}}.\n* {{springer|first=V.M.|last=Tikhomirov|title=Gâteaux variation|id=G/g043390|year=2001}}.\n* {{Citation | doi=10.2307/1969198 | last1=Zorn | first1=Max |authorlink=Max Zorn| title=Characterization of analytic functions in Banach spaces | mr=0014190  | jstor=1969198 | year=1945 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=46 | issue=4 | pages=585–593}}.\n* {{Citation| first=Max|last=Zorn|authorlink=Max Zorn|title=Derivatives and Frechet differentials|journal=Bulletin of the American Mathematical Society|year=1946|volume=52|pages=133–137|url=http://www.ams.org/bull/1946-52-02/S0002-9904-1946-08524-9/home.html|doi=10.1090/S0002-9904-1946-08524-9|issue=2| mr=0014595}}.\n\n{{Functional Analysis}}\n\n{{DEFAULTSORT:Gateaux Derivative}}\n[[Category:Generalizations of the derivative]]\n[[Category:Topological vector spaces]]"
    },
    {
      "title": "Gradient",
      "url": "https://en.wikipedia.org/wiki/Gradient",
      "text": "{{about|the gradient of a multivariate function|direction and steepness of a line on a graph|Slope|the slope of a road or other physical feature|Grade (slope)|the similarly spelled unit of angle also known as gon|Gradian|other uses|Gradient (disambiguation)}}\n\n{{more footnotes|date=January 2018}}\n{{short description|Multi-variable generalization of the derivative of a function}}\n[[File:Gradient2.svg|thumb|300px|In the above two images, the values of the function are represented in black and white, black representing higher values, and its corresponding gradient is represented by blue arrows.]]\n\nIn [[vector calculus]], the '''gradient''' is a multi-variable generalization of the [[derivative]].<ref>{{harvtxt|Beauregard|Fraleigh|1973|p=84}}</ref> Whereas the ordinary derivative of a function of a single variable is a [[scalar-valued function]], the gradient of a function of several variables is a [[vector-valued function]].  Specifically, the gradient of a [[differentiable function]] <math>f</math> of [[Function of several variables|several variables]], at a point <math>P</math>, is the [[Vector (mathematics and physics)|vector]] whose components are the [[partial derivative]]s of <math>f</math> at <math>P</math>.<ref>{{harvtxt|Bachman|2007|p=76}}</ref><ref>{{harvtxt|Beauregard|Fraleigh|1973|p=84}}</ref><ref>{{harvtxt|Downing|2010|p=316}}</ref><ref>{{harvtxt|Harper|1976|p=15}}</ref><ref>{{harvtxt|Kreyszig|1972|p=307}}</ref><ref>{{harvtxt|McGraw-Hill|2007|p=196}}</ref><ref>{{harvtxt|Moise|1967|p=683}}</ref><ref>{{harvtxt|Protter|Morrey, Jr.|1970|p=714}}</ref><ref>{{harvtxt|Swokowski et al.|1994|p=1038}}</ref>\n\nMuch as the derivative of a function of a single variable represents the [[slope]] of the [[tangent]] to the [[graph of a function|graph]] of the function,<ref>{{harvtxt|Protter|Morrey, Jr.|1970|pp=21,88}}</ref> if at a point <math>P</math>, the gradient of a function of several variables is not the zero vector, it has the direction of greatest increase of the function at <math>P</math>, and its [[magnitude (mathematics)|magnitude]] is the rate of increase in that direction.<ref>{{harvtxt|Bachman|2007|p=77}}</ref><ref>{{harvtxt|Downing|2010|pp=316–317}}</ref><ref>{{harvtxt|Kreyszig|1972|p=309}}</ref><ref>{{harvtxt|McGraw-Hill|2007|p=196}}</ref><ref>{{harvtxt|Moise|1967|p=684}}</ref><ref>{{harvtxt|Protter|Morrey, Jr.|1970|p=715}}</ref><ref>{{harvtxt|Swokowski et al.|1994|pp=1036,1038–1039}}</ref>\n\nThe magnitude and direction of the gradient vector are [[Invariant (mathematics)|independent]] of the particular [[Coordinate system|coordinate representation]].<ref>{{harvtxt|Kreyszig|1972|pp=308–309}}</ref><ref>{{harvtxt|Stoker|1969|p=292}}</ref>\n\nThe [[Jacobian matrix and determinant|Jacobian]] is the generalization of the gradient for vector-valued functions of several variables and [[differentiable map]]s between [[Euclidean space]]s or, more generally, [[manifold]]s.<ref>{{harvtxt|Beauregard|Fraleigh|1973|pp=87,248}}</ref><ref>{{harvtxt|Kreyszig|1972|pp=333,353,496}}</ref>  A further generalization for a function between [[Banach space]]s is the [[Fréchet derivative]].\n\n==Motivation==\n[[File:Gradient of a Function.tif|thumb|350px|Gradient of the 2D function {{math|1=''f''(''x'', ''y'') = ''xe''<sup>−(''x''<sup>2</sup> + ''y''<sup>2</sup>)</sup>}} is plotted as blue arrows over the pseudocolor plot of the function.]]\n\nConsider a room in which the temperature is given by a [[scalar field]], {{math|''T''}}, so at each point {{math|(''x'', ''y'', ''z'')}} the temperature is {{math|''T''(''x'', ''y'', ''z'')}}. (Assume that the temperature does not change over time.) At each point in the room, the gradient of {{math|''T''}} at that point will show the direction in which the temperature rises most quickly. The magnitude of the gradient will determine how fast the temperature rises in that direction.\n\nConsider a surface whose height above sea level at point {{math|(''x'', ''y'')}} is {{math|''H''(''x'', ''y'')}}. The gradient of {{math|''H''}} at a point is a vector pointing in the direction of the steepest slope or [[Grade (slope)|grade]] at that point. The steepness of the slope at that point is given by the magnitude of the gradient vector.\n\nThe gradient can also be used to measure how a scalar field changes in other directions, rather than just the direction of greatest change, by taking a [[dot product]]. Suppose that the steepest slope on a hill is 40%. If a road goes directly up the hill, then the steepest slope on the road will also be 40%. If, instead, the road goes around the hill at an angle, then it will have a shallower slope. For example, if the angle between the road and the uphill direction, projected onto the horizontal plane, is 60°, then the steepest slope along the road will be 20%, which is 40% times the [[cosine]] of 60°.\n\nThis observation can be mathematically stated as follows. If the hill height function {{math|''H''}} is [[differentiable function|differentiable]], then the gradient of {{math|''H''}} [[dot product|dotted]] with a [[unit vector]] gives the slope of the hill in the direction of the vector. More precisely, when {{math|''H''}} is differentiable, the dot product of the gradient of {{math|''H''}} with a given unit vector is equal to the [[directional derivative]] of {{math|''H''}} in the direction of that unit vector.\n\n==Definition==\n[[File:3d-gradient-cos.svg|thumb|350px|The gradient of the function {{math|''f''(''x'',''y'') {{=}} −(cos<sup>2</sup>''x'' + cos<sup>2</sup>''y'')<sup>2</sup>}} depicted as a projected [[vector field]] on the bottom plane.]]\n\nThe gradient (or gradient vector field) of a scalar function {{math|''f''(''x''<sub>1</sub>, ''x''<sub>2</sub>, ''x''<sub>3</sub>, ..., ''x<sub>n</sub>'')}} is denoted {{math|∇''f''}} or {{math|{{vec|∇}}''f''}}  where {{math|∇}} (the [[nabla symbol]]) denotes the vector [[differential operator]], [[del]]. The notation {{math|grad ''f''}} is also commonly used for the gradient. The gradient of {{math|''f''}} is defined as the unique vector field whose dot product with any unit [[Euclidean vector|vector]] {{math|'''v'''}} at each point {{math|''x''}} is the directional derivative of {{math|''f''}} along {{math|'''v'''}}. That is,\n\n:<math>\\big(\\nabla f(x)\\big)\\cdot \\mathbf{v} = D_{\\mathbf v}f(x).</math>\n\nWhen a function also depends on a parameter such as time, the gradient often refers simply to the vector of its spatial derivatives only (see [[Spatial gradient]]).\n\n===Cartesian coordinates===\nIn the three-dimensional [[Cartesian coordinate system]] with a [[Euclidean metric]], the gradient, if it exists, is given by:\n\n:<math>\\nabla f = \\frac{\\partial f}{\\partial x} \\mathbf{i} + \\frac{\\partial f}{\\partial y} \\mathbf{j} + \\frac{\\partial f}{\\partial z} \\mathbf{k},</math>\n\nwhere {{math|'''i'''}}, {{math|'''j'''}}, {{math|'''k'''}} are the [[standard basis|standard]] unit vectors in the directions of the {{math|''x''}}, {{math|''y''}} and {{math|''z''}} coordinates, respectively. For example, the gradient of the function\n:<math>f(x,y,z)= 2x+3y^2-\\sin(z)</math>\nis\n:<math>\\nabla f = 2\\mathbf{i}+ 6y\\mathbf{j} -\\cos(z)\\mathbf{k}.</math>\n\nIn some applications it is customary to represent the gradient as a [[row vector]] or [[column vector]] of its components in a rectangular coordinate system.\n\n===Cylindrical and spherical coordinates===\n{{main|Del in cylindrical and spherical coordinates}}\n\nIn [[cylindrical coordinate system#Definition|cylindrical coordinates]] with a Euclidean metric, the gradient is given by:<ref name=\"Schey-1992\">{{harvnb|Schey|1992|pp=139–142}}.</ref>\n\n:<math>\\nabla f(\\rho, \\varphi, z) = \\frac{\\partial f}{\\partial \\rho}\\mathbf{e}_\\rho + \\frac{1}{\\rho}\\frac{\\partial f}{\\partial \\varphi}\\mathbf{e}_\\varphi + \\frac{\\partial f}{\\partial z}\\mathbf{e}_z,</math>\n\nwhere {{math|''ρ''}} is the axial distance, {{math|''φ''}} is the azimuthal or azimuth angle, {{math|''z''}} is the axial coordinate, and {{math|'''e'''<sub>''ρ''</sub>}}, {{math|'''e'''<sub>''φ''</sub>}} and {{math|'''e'''<sub>''z''</sub>}} are unit vectors pointing along the coordinate directions.\n\nIn [[spherical coordinate system#Definition|spherical coordinates]], the gradient is given by:<ref name=\"Schey-1992\" />\n\n:<math>\\nabla f(r, \\theta, \\varphi) = \\frac{\\partial f}{\\partial r}\\mathbf{e}_r + \\frac{1}{r}\\frac{\\partial f}{\\partial \\theta}\\mathbf{e}_\\theta + \\frac{1}{r \\sin\\theta}\\frac{\\partial f}{\\partial \\varphi}\\mathbf{e}_\\varphi,</math>\n\nwhere {{math|''r''}} is the radial distance, {{math|''φ''}} is the azimuthal angle and {{math|''θ''}} is the polar angle, and {{math|'''e'''<sub>''r''</sub>}}, {{math|'''e'''<sub>''θ''</sub>}} and {{math|'''e'''<sub>''φ''</sub>}} are again local unit vectors pointing in the coordinate directions (i.e. the normalized  [[Curvilinear coordinates#Covariant and contravariant bases|covariant basis]]).\n\nFor the gradient in other [[orthogonal coordinate system]]s, see [[Orthogonal coordinates#Differential operators in three dimensions|Orthogonal coordinates (Differential operators in three dimensions)]].\n\n===General coordinates===\nWe consider [[Curvilinear coordinates|general coordinates]], which we write as {{math|''x''<sup>1</sup>, ..., ''x''<sup>''i''</sup>, ..., ''x''<sup>''n''</sup>}}, where {{mvar|n}} is the number of dimensions of the domain. Here, the upper index refers to the position in the list of the coordinate or component, so {{math|''x''<sup>2</sup>}} refers to the second component—not the quantity {{math|''x''}} squared. The index variable {{math|''i''}} refers to an arbitrary element {{math|''x''<sup>''i''</sup>}}. Using [[Einstein notation]], the gradient can then be written as:\n\n:<math>\\nabla f = \\frac{\\partial f}{\\partial x^{i}}g^{ij} \\mathbf{e}_j</math>  ( Note that its [[Dual space|dual]] is <math>\\mathrm{d}f= \\frac{\\partial f}{\\partial x^{i}}\\mathbf{e}^i</math> ),\n\nwhere <math>\\mathbf{e}_i = \\partial \\mathbf{x}/\\partial x^i</math> and <math>\\mathbf{e}^i = \\mathrm{d}x^i</math> refer to the unnormalized local [[Curvilinear coordinates#Covariant and contravariant bases|covariant and contravariant bases]] respectively, <math>g^{ij}</math> is the [[Metric tensor#Inverse metric|inverse metric tensor]], and the Einstein summation convention implies summation over ''i''  and ''j''. \n\nIf the coordinates are orthogonal we can easily express the gradient (and the [[Differential form|differential]]) in terms of the normalized bases, which we refer to as  <math>\\hat{\\mathbf{e}}_i</math> and  <math>\\hat{\\mathbf{e}}^i</math>, using the scale factors (also known as [https://www.encyclopediaofmath.org/index.php/Lam%C3%A9_coefficients Lamé coefficients])  <math>h_i= \\lVert \\mathbf{e}_i \\rVert = 1\\, / \\lVert \\mathbf{e}^i  \\,\\rVert</math> :\n\n:<math>\\nabla f = \\sum_{i=1}^n \\, \\frac{\\partial f}{\\partial x^{i}}\\frac{1}{h_i}\\mathbf{\\hat{e}}_i</math>  ( and <math>\\mathrm{d}f = \\sum_{i=1}^n \\, \\frac{\\partial f}{\\partial x^{i}}\\frac{1}{h_i}\\mathbf{\\hat{e}}^i</math> ),\n\nwhere we cannot use Einstein notation, since it is impossible to avoid the repetition of more than two indices. Despite the use of upper and lower indices, <math>\\mathbf{\\hat{e}}_i</math>, <math>\\mathbf{\\hat{e}}^i</math>, and <math>h_i</math> are neither contravariant nor covariant.\n\nThe latter expression evaluates to the expressions given above for cylindrical and spherical coordinates.\n\n==Gradient and the derivative or differential==\n{{Calculus |Vector}}\n\n===Linear approximation to a function===\nThe gradient of a [[function (mathematics)|function]] {{math|''f''}} from the Euclidean space {{math|'''R'''<sup>''n''</sup>}} to {{math|'''R'''}} at any particular point {{math|''x''<sub>0</sub>}} in {{math|'''R'''<sup>''n''</sup>}} characterizes the best [[linear approximation]] to {{math|''f''}} at {{math|''x''<sub>0</sub>}}. The approximation is as follows:\n\n:<math>f(x) \\approx f(x_0) + (\\nabla f)_{x_0}\\cdot(x-x_0)</math>\n\nfor {{math|''x''}} close to {{math|''x''<sub>0</sub>}}, where {{math|(∇''f''&thinsp;)<sub>''x''<sub>0</sub></sub>}} is the gradient of {{math|''f''}} computed at {{math|''x''<sub>0</sub>}}, and the dot denotes the dot product on {{math|'''R'''<sup>''n''</sup>}}. This equation is equivalent to the first two terms in the [[Taylor series#Taylor series in several variables|multivariable Taylor series]] expansion of {{math|''f''}} at {{math|''x''<sub>0</sub>}}.\n\n===Differential or (exterior) derivative===\nThe best linear approximation to a differentiable function\n:<math>f \\colon \\mathbf{R}^n \\to \\mathbf{R}</math>\nat a point {{math|''x''}} in {{math|'''R'''<sup>''n''</sup>}} is a linear map from {{math|'''R'''<sup>''n''</sup>}} to {{math|'''R'''}} which is often denoted by {{math|''df<sub>x</sub>''}} or {{math|''Df''(''x'')}} and called the '''[[differential (calculus)|differential]]''' or [[total derivative|('''total''') '''derivative''']] of {{math|''f''}} at {{math|''x''}}. The gradient is therefore related to the differential by the formula\n:<math>(\\nabla f)_x\\cdot v = df_x(v)</math>\nfor any {{math|''v'' ∈ '''R'''<sup>''n''</sup>}}. The function {{math|''df''}}, which maps {{math|''x''}} to {{math|''df''<sub>''x''</sub>}}, is called the differential or [[exterior derivative]] of {{math|''f''}} and is an example of a [[differential 1-form]].\n\nIf {{math|'''R'''<sup>''n''</sup>}} is viewed as the space of (dimension {{math|''n''}}) column vectors (of real numbers), then one can regard {{math|''df''}} as the row vector with components\n:<math>\\left( \\frac{\\partial f}{\\partial x_1}, \\dots, \\frac{\\partial f}{\\partial x_n}\\right),</math>\nso that {{math|''df''<sub>''x''</sub>(''v'')}} is given by matrix multiplication.  Assuming the standard Euclidean metric on {{math|'''R'''<sup>''n''</sup>}}, the gradient is then the corresponding column vector, i.e.,\n:<math>(\\nabla f)_i = df^\\mathsf{T}_i.</math>\n\n===Gradient as a derivative===\nLet {{math|''U''}} be an [[open set]] in {{math|'''R'''<sup>''n''</sup>}}. If the function {{math|''f'' : ''U'' → '''R'''}} is [[Fréchet derivative|differentiable]], then the differential of {{math|''f''}} is the (Fréchet) derivative of {{math|''f''}}. Thus {{math|∇''f''}} is a function from {{math|''U''}} to the space {{math|'''R'''<sup>''n''</sup>}} such that\n:<math>\\lim_{h\\to 0} \\frac{|f(x+h)-f(x) -\\nabla f(x)\\cdot h|}{\\|h\\|} = 0,</math>\nwhere · is the dot product.\n\nAs a consequence, the usual properties of the derivative hold for the gradient:\n\n====[[Linearity]]====\nThe gradient is linear in the sense that if {{math|''f''}} and {{math|''g''}} are two real-valued functions differentiable at the point {{math|''a'' ∈ '''R'''<sup>''n''</sup>}}, and {{mvar|α}} and {{mvar|β}} are two constants, then {{math|''αf'' + ''βg''}} is differentiable at {{math|''a''}}, and moreover\n:<math>\\nabla\\left(\\alpha f+\\beta g\\right)(a) = \\alpha \\nabla f(a) + \\beta\\nabla g (a).</math>\n\n====[[Product rule]]====\nIf {{math|''f''}} and {{math|''g''}} are real-valued functions differentiable at a point {{math|''a'' ∈ '''R'''<sup>''n''</sup>}}, then the product rule asserts that the product {{math|''fg''}} is differentiable at {{math|''a''}}, and\n:<math>\\nabla (fg)(a) = f(a)\\nabla g(a) + g(a)\\nabla f(a).</math>\n\n====[[Chain rule]]====\nSuppose that {{math|''f'' : ''A'' → '''R'''}} is a real-valued function defined on a subset {{math|''A''}} of {{math|'''R'''<sup>''n''</sup>}}, and that {{math|''f''}} is differentiable at a point {{math|''a''}}. There are two forms of the chain rule applying to the gradient. First, suppose that the function {{math|''g''}} is a [[parametric curve]]; that is, a function {{math|''g'' : ''I'' → '''R'''<sup>''n''</sup>}} maps a subset {{math|''I'' ⊂ '''R'''}} into {{math|'''R'''<sup>''n''</sup>}}. If {{math|''g''}} is differentiable at a point {{math|''c'' ∈ ''I''}} such that {{math|''g''(''c'') {{=}} ''a''}}, then\n:<math>(f\\circ g)'(c) = \\nabla f(a)\\cdot g'(c),</math>\nwhere ∘ is the [[composition operator]]: {{math|(&thinsp;''f'' ∘ ''g'')(''x'') {{=}} ''f''(''g''(''x''))}}.\n\nMore generally, if instead {{math|''I'' ⊂ '''R'''<sup>''k''</sup>}}, then the following holds:\n:<math>\\nabla (f\\circ g)(c) = \\big(Dg(c)\\big)^\\mathsf{T} \\big(\\nabla f(a)\\big),</math>\nwhere {{math|(''Dg'')}}<sup>T</sup> denotes the transpose [[Jacobian matrix]].\n\nFor the second form of the chain rule, suppose that {{math|''h'' : ''I'' → '''R'''}} is a real valued function on a subset {{math|''I''}} of {{math|'''R'''}}, and that {{math|''h''}} is differentiable at the point {{math|''f''(''a'') ∈ ''I''}}. Then\n:<math>\\nabla (h\\circ f)(a) = h'\\big(f(a)\\big)\\nabla f(a).</math>\n\n==Further properties and applications==\n\n===Level sets===\n{{see also|Level set#Level sets versus the gradient}}\nA level surface, or [[isosurface]], is the set of all points where some function has a given value.\n\nIf {{math|''f''}} is differentiable, then the dot product {{math|(∇''f''&thinsp;)<sub>''x''</sub> ⋅ ''v''}} of the gradient at a point {{math|''x''}} with a vector {{math|''v''}} gives the directional derivative of {{math|''f''}} at {{math|''x''}} in the direction {{math|''v''}}. It follows that in this case the gradient of {{math|''f''}} is [[orthogonal]] to the [[level set]]s of {{math|''f''}}. For example, a level surface in three-dimensional space is defined by an equation of the form {{math|1=''F''(''x'', ''y'', ''z'') = ''c''}}. The gradient of {{math|''F''}} is then normal to the surface.\n\nMore generally, any [[embedded submanifold|embedded]] [[hypersurface]] in a Riemannian manifold can be cut out by an equation of the form {{math|1=''F''(''P'') = 0}} such that {{math|''dF''}} is nowhere zero. The gradient of {{math|''F''}} is then normal to the hypersurface.\n\nSimilarly, an [[affine algebraic variety|affine algebraic hypersurface]] may be defined by an equation {{math|1=''F''(''x''<sub>1</sub>, ..., ''x''<sub>''n''</sub>) = 0}}, where {{math|''F''}} is a polynomial. The gradient of {{math|''F''}} is zero at a singular point of the hypersurface (this is the definition of a singular point). At a non-singular point, it is a nonzero normal vector.\n\n===Conservative vector fields and the gradient theorem===\n{{main|Gradient theorem}}\n\nThe gradient of a function is called a gradient field. A (continuous) gradient field is always a [[conservative vector field]]: its [[line integral]] along any path depends only on the endpoints of the path, and can be evaluated by the gradient theorem (the fundamental theorem of calculus for line integrals). Conversely, a (continuous) conservative vector field is always the gradient of a function.\n\n==Generalizations==\n\n===Gradient of a vector===\n{{see also|Covariant derivative}}\nSince the total derivative of a vector field is a [[linear mapping]] from vectors to vectors, it is a [[tensor]] quantity.\n\nIn rectangular coordinates, the gradient of a vector field {{math|1='''f''' = (&thinsp;''f''{{i sup|1}}, ''f''{{i sup|2}}, ''f''{{i sup|3}})}} is defined by:\n\n:<math>\\nabla \\mathbf{f}=g^{jk}\\frac{\\partial f^i}{\\partial x^j} \\mathbf{e}_i \\otimes \\mathbf{e}_k,</math>\n\n(where the [[Einstein summation notation]] is used and the [[tensor product]] of the vectors {{math|'''e'''<sub>''i''</sub>}} and {{math|'''e'''<sub>''k''</sub>}} is a [[dyadic tensor]] of type (2,0)). Overall, this expression equals the transpose of the Jacobian matrix:\n\n:<math>\\frac{\\partial f^i}{\\partial x^j} = \\frac{\\partial (f^1,f^2,f^3)}{\\partial (x^1,x^2,x^3)}.</math>\n\nIn curvilinear coordinates, or more generally on a curved [[Riemannian manifold|manifold]], the gradient involves [[Christoffel symbols]]:\n\n:<math>\\nabla \\mathbf{f}=g^{jk}\\left(\\frac{\\partial f^i}{\\partial x^j}+{\\Gamma^i}_{jl}f^l\\right) \\mathbf{e}_i \\otimes \\mathbf{e}_k,</math>\n\nwhere {{math|''g''{{i sup|''jk''}}}} are the components of the inverse [[metric tensor]] and the {{math|'''e'''<sub>''i''</sub>}} are the coordinate basis vectors.\n\nExpressed more invariantly, the gradient of a vector field {{math|'''f'''}} can be defined by the [[Levi-Civita connection]] and metric tensor:<ref>{{harvnb|Dubrovin|Fomenko|Novikov|1991|pages=348–349}}.</ref>\n\n:<math>\\nabla^a f^b = g^{ac} \\nabla_c f^b ,</math>\n\nwhere {{math|∇<sub>''c''</sub>}} is the connection.\n\n===Riemannian manifolds===\nFor any smooth function {{mvar|f}} on a Riemannian manifold {{math|(''M'', ''g'')}}, the gradient of {{math|''f''}} is the vector field {{math|∇''f''}} such that for any vector field {{math|''X''}},\n:<math>g(\\nabla f, X) = \\partial_X f,</math>\ni.e.,\n:<math>g_x\\big((\\nabla f)_x, X_x \\big) = (\\partial_X f) (x),</math>\nwhere {{math|''g''<sub>''x''</sub>( , )}} denotes the [[inner product]] of tangent vectors at {{math|''x''}} defined by the metric {{math|''g''}} and {{math|∂<sub>''X''</sub>&thinsp;''f''}} is the function that takes any point {{math|''x'' ∈ ''M''}} to the directional derivative of {{math|''f''}} in the direction {{math|''X''}}, evaluated at {{math|''x''}}. In other words, in a [[coordinate chart]] {{math|''φ''}} from an open subset of {{math|''M''}} to an open subset of {{math|'''R'''<sup>''n''</sup>}}, {{math|(∂<sub>''X''</sub>&thinsp;''f''&thinsp;)(''x'')}} is given by:\n:<math>\\sum_{j=1}^n X^{j} \\big(\\varphi(x)\\big) \\frac{\\partial}{\\partial x_{j}}(f \\circ \\varphi^{-1}) \\Bigg|_{\\varphi(x)},</math>\nwhere {{math|''X''{{isup|''j''}}}} denotes the {{math|''j''}}th component of {{math|''X''}} in this coordinate chart.\n\nSo, the local form of the gradient takes the form:\n\n:<math>\\nabla f = g^{ik} \\frac{\\partial f}{\\partial x^k} {\\textbf e}_i .</math>\n\nGeneralizing the case {{math|1=''M'' = '''R'''<sup>''n''</sup>}}, the gradient of a function is related to its exterior derivative, since\n:<math>(\\partial_X f) (x) = (df)_x(X_x) .</math>\nMore precisely, the gradient {{math|∇''f''}} is the vector field associated to the differential 1-form {{math|''df''}} using the [[musical isomorphism]]\n:<math>\\sharp=\\sharp^g\\colon T^*M\\to TM</math>\n(called \"sharp\") defined by the metric {{math|''g''}}. The relation between the exterior derivative and the gradient of a function on {{math|'''R'''<sup>''n''</sup>}} is a special case of this in which the metric is the flat metric given by the dot product.\n\n==See also==\n* [[Curl (mathematics)|Curl]]\n* [[Divergence]]\n* [[Four-gradient]]\n* [[Hessian matrix]]\n* [[Skew gradient]]\n\n== Notes ==\n{{reflist}}\n\n== References ==\n* {{ citation | last1 = Bachman | first1 = David | title = Advanced Calculus Demystified | location = New York | publisher = [[McGraw-Hill]] | year = 2007 | isbn = 0-07-148121-4 }}\n* {{ citation | last1 = Beauregard | first1 = Raymond A. | last2 = Fraleigh | first2 = John B. | title = A First Course In Linear Algebra: with Optional Introduction to Groups, Rings, and Fields | location = Boston | publisher = [[Houghton Mifflin Company]] | year = 1973 | isbn = 0-395-14017-X }}\n* {{ citation | last1 = Downing | first1 = Douglas, Ph.D. | title = Barron's E-Z Calculus | location = New York | publisher = [[B.E.S. Publishing|Barron's]] | year = 2010 | isbn = 978-0-7641-4461-5 }}\n* {{cite book\n | first1 = B. A.\n | last1 = Dubrovin\n | first2 = A. T.\n | last2 = Fomenko\n | first3 = S. P.\n | last3 = Novikov\n | title = Modern Geometry—Methods and Applications: Part I: The Geometry of Surfaces, Transformation Groups, and Fields\n | series = [[Graduate Texts in Mathematics]]\n | publisher = Springer\n | edition = 2nd\n | year = 1991\n | isbn = 978-0-387-97663-1\n | ref = harv\n}}\n* {{ citation | last1 = Harper | first1 = Charlie | title = Introduction to Mathematical Physics | location = New Jersey | publisher = [[Prentice-Hall]] | year = 1976 | isbn = 0-13-487538-9 }}\n* {{ citation | last1 = Kreyszig | first1 = Erwin | authorlink = Erwin Kreyszig | title = Advanced Engineering Mathematics | edition = 3rd | location = New York | publisher = [[John Wiley & Sons|Wiley]] | year = 1972 | isbn = 0-471-50728-8 }}\n* {{ cite encyclopedia | encyclopedia = McGraw-Hill Encyclopedia of Science & Technology | edition = 10th | location = New York | publisher = [[McGraw-Hill]] | year = 2007 | isbn = 0-07-144143-3 | ref = {{harvid|McGraw-Hill|2007}} }}\n* {{ citation | last1 = Moise | first1 = Edwin E. | title = Calculus:  Complete | location = Reading | publisher = [[Addison-Wesley]] | year = 1967 }}\n* {{ citation | last1 = Protter | first1 = Murray H. | last2 = Morrey, Jr. | first2 = Charles B. | title = College Calculus with Analytic Geometry | edition = 2nd | location = Reading | publisher = [[Addison-Wesley]] | year = 1970 | lccn = 76087042 }}\n* {{cite book\n | first = H. M.\n | last = Schey\n | title = Div, Grad, Curl, and All That\n | publisher = W. W. Norton\n | edition = 2nd\n | year = 1992\n | isbn = 0-393-96251-2\n | oclc = 25048561\n | ref = harv\n}}\n* {{ citation | last1 = Stoker | first1 = J. J. | title = Differential Geometry | location = New York | publisher = [[John Wiley & Sons|Wiley]] | year = 1969 | isbn = 0-471-82825-4 }}\n* {{ citation | last1 = Swokowski | first1 = Earl W. | last2 = Olinick | first2 = Michael | last3 = Pence | first3 = Dennis | last4 = Cole | first4 = Jeffery A. | title = Calculus | edition = 6th | location = Boston | publisher = PWS Publishing Company | year = 1994 | isbn = 0-534-93624-5 | ref = {{harvid|Swokowski et al.|1994}} }}\n\n==Further reading==\n* {{cite book\n | first1 = Theresa M.\n | last1 = Korn\n | first2 = Granino Arthur\n | last2 = Korn\n | title = Mathematical Handbook for Scientists and Engineers: Definitions, Theorems, and Formulas for Reference and Review\n | publisher = Dover Publications\n | year = 2000\n | pages = 157–160\n | isbn = 0-486-41147-8\n | oclc = 43864234\n | ref = harv\n}}\n\n==External links==\n{{wiktionary}}\n* {{cite web\n | url = https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient\n | title = Gradient\n | publisher = [[Khan Academy]]\n}}\n* {{springer\n | title = Gradient\n | id = G/g044680\n | last = Kuptsov\n | first = L.P.\n}}.\n* {{MathWorld\n | title = Gradient\n | urlname = Gradient\n}}\n\n[[Category:Differential operators]]\n[[Category:Differential calculus]]\n[[Category:Generalizations of the derivative]]\n[[Category:Linear operators in calculus]]\n[[Category:Vector calculus]]\n[[Category:Rates]]"
    },
    {
      "title": "H-derivative",
      "url": "https://en.wikipedia.org/wiki/H-derivative",
      "text": "{{technical|date=June 2012}}\nIn [[mathematics]], the '''''H''-derivative''' is a notion of [[derivative]] in the study of [[abstract Wiener space]]s and the [[Malliavin calculus]].\n\n==Definition==\n\nLet <math>i : H \\to E</math> be an abstract Wiener space, and suppose that <math>F : E \\to \\mathbb{R}</math> is [[Fréchet_derivative|differentiable]]. Then the [[Fréchet derivative]] is a map\n:<math>\\mathrm{D} F : E \\to \\mathrm{Lin} (E; \\mathbb{R})</math>;\ni.e., for <math>x \\in E</math>, <math>\\mathrm{D} F (x)</math> is an element of <math>E^{*}</math>, the [[dual space]] to <math>E</math>.\n\nTherefore, define the '''<math>H</math>-derivative''' <math>\\mathrm{D}_{H} F</math> at <math>x \\in E</math> by\n:<math>\\mathrm{D}_{H} F (x) := \\mathrm{D} F (x) \\circ i : H \\to \\R</math>,\na [[continuous function|continuous]] [[linear map]] on <math>H</math>.\n\nDefine the '''<math>H</math>-gradient''' <math>\\nabla_{H} F : E \\to H</math> by\n:<math>\\langle \\nabla_{H} F (x), h \\rangle_{H} = \\left( \\mathrm{D}_{H} F \\right) (x) (h) = \\lim_{t \\to 0} \\frac{F (x + t i(h)) - F(x)}{t}</math>.\nThat is, if <math>j : E^{*} \\to H</math> denotes the [[adjoint]] of <math>i : H \\to E</math>, we have <math>\\nabla_{H} F (x) := j \\left( \\mathrm{D} F (x) \\right)</math>.\n\n==See also==\n\n* [[Malliavin derivative]]\n\n==References==\n{{unreferenced|date=June 2008}}\n\n[[Category:Generalizations of the derivative]]\n[[Category:Measure theory]]\n[[Category:Stochastic calculus]]\n{{probability-stub}}"
    },
    {
      "title": "Jacobian matrix and determinant",
      "url": "https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant",
      "text": "{{Calculus |Multivariable}}\n\nIn [[vector calculus]], the '''Jacobian matrix''' ({{IPAc-en|dʒ|ə|ˈ|k|əʊ|b|i|ə|n}},<ref>{{cite web|url=https://en.oxforddictionaries.com/definition/jacobian|title=Jacobian - Definition of Jacobian in English by Oxford Dictionaries|author=|date=|website=Oxford Dictionaries - English|accessdate=2 May 2018|deadurl=no|archiveurl=https://web.archive.org/web/20171201043633/https://en.oxforddictionaries.com/definition/jacobian|archivedate=1 December 2017|df=}}</ref><ref>{{cite web|url=http://www.dictionary.com/browse/jacobian|title=the definition of jacobian|author=|date=|website=Dictionary.com|accessdate=2 May 2018|deadurl=no|archiveurl=https://web.archive.org/web/20171201040801/http://www.dictionary.com/browse/jacobian|archivedate=1 December 2017|df=}}</ref><ref>{{cite web|url=https://forvo.com/word/jacobian/|title=Jacobian pronunciation: How to pronounce Jacobian in English|first=Forvo|last=Team|date=|website=forvo.com|accessdate=2 May 2018}}</ref> {{IPAc-en|dʒ|ᵻ|-|,_|j|ᵻ|-}}) is the [[matrix (mathematics)|matrix]] of all first-order [[partial derivative]]s of a [[vector-valued function]]. When the matrix is a [[square matrix]], both the matrix and its [[determinant]] are referred to as the '''Jacobian''' in literature.<ref>{{cite web|url=http://mathworld.wolfram.com/Jacobian.html|title=Jacobian|first=Weisstein, Eric|last=W.|date=|website=mathworld.wolfram.com|accessdate=2 May 2018|deadurl=no|archiveurl=https://web.archive.org/web/20171103144419/http://mathworld.wolfram.com/Jacobian.html|archivedate=3 November 2017|df=}}</ref>\n\nSuppose {{math|'''f''' : ℝ<sup>''n''</sup> → ℝ<sup>''m''</sup>}} is a function which takes as input the vector {{math|'''x''' ∈ ℝ<sup>''n''</sup>}} and produces as output the vector {{math|'''f'''('''x''') ∈ ℝ<sup>''m''</sup>}}. Then the Jacobian matrix {{math|'''J'''}} of {{math|'''f'''}} is an {{math|''m''×''n''}} matrix, usually defined and arranged as follows:\n\n:<math>\\mathbf J = \\begin{bmatrix}\n    \\dfrac{\\partial \\mathbf{f}}{\\partial x_1} & \\cdots & \\dfrac{\\partial \\mathbf{f}}{\\partial x_n} \\end{bmatrix}\n= \\begin{bmatrix}\n    \\dfrac{\\partial f_1}{\\partial x_1} & \\cdots & \\dfrac{\\partial f_1}{\\partial x_n}\\\\\n    \\vdots & \\ddots & \\vdots\\\\\n    \\dfrac{\\partial f_m}{\\partial x_1} & \\cdots & \\dfrac{\\partial f_m}{\\partial x_n} \\end{bmatrix}</math>\n\nor, component-wise:\n\n:<math>\\mathbf J_{ij} = \\frac{\\partial f_i}{\\partial x_j} .</math>\n\nThis matrix, whose entries are functions of {{math|'''x'''}}, is also denoted by {{math|D'''f'''}}, {{math|'''J'''<sub>'''f'''</sub>}}, and {{sfrac|''∂''(''f''<sub>1</sub>,...,''f''<sub>''m''</sub>)|''∂''(''x''<sub>1</sub>,...,''x''<sub>''n''</sub>)}}. (Note that some literature defines the Jacobian as the [[transpose]] of the matrix given above.)\n\nThe Jacobian matrix is important because if the function {{math|'''f'''}} is [[Differentiable function|differentiable]] at a point {{math|'''x'''}} (this is a slightly stronger condition than merely requiring that all partial derivatives exist at {{math|'''x'''}}), then the Jacobian matrix defines a [[linear map]] {{math|ℝ<sup>''n''</sup> → ℝ<sup>''m''</sup>}}, which is the best (pointwise) [[linear approximation]] of the function {{math|'''f'''}} near the point {{math|'''x'''}}. This linear map is thus the generalization of the usual notion of derivative, and is called the ''derivative'' or the ''differential'' of {{math|'''f'''}} at {{math|'''x'''}}.\n\nIf {{math|''m''}} = {{math|''n''}}, the Jacobian matrix is a square matrix, and its [[determinant]], a function of {{math|''x''<sub>1</sub>, …, ''x''<sub>''n''</sub>}}, is the '''Jacobian determinant''' of {{math|'''f'''}}. It carries important information about the local behavior of {{math|'''f'''}}. In particular, the function {{math|'''f'''}} has locally in the neighborhood of a point {{math|'''x'''}} an [[inverse function]] that is differentiable if and only if the Jacobian determinant is nonzero at {{math|'''x'''}} (see [[Jacobian conjecture]]). The Jacobian determinant also appears when changing the variables in [[multiple integral]]s (see [[Integration_by_substitution#Substitution_for_multiple_variables|substitution rule for multiple variables]]).\n\nIf {{math|''m''}} = 1, {{math|'''f'''}} is a [[scalar field]] and the Jacobian matrix is reduced to a [[row vector]] of partial derivatives of {{math|'''f'''}}—i.e. the [[transpose]] of the [[gradient]] of {{math|'''f'''}}, when denoted as column vector with respect to the ordered basis <math>\\{\\hat{\\mathbf{x}}_1,\\cdots,\\hat{\\mathbf{x}}_n\\}</math>.\n\nThese concepts are named after the [[mathematician]] [[Carl Gustav Jacob Jacobi]] (1804–1851).\n\n== Jacobian matrix ==\n\nThe Jacobian generalizes the [[gradient]] of a [[scalar (mathematics)|scalar]]-valued function of multiple variables, which itself generalizes the derivative of a scalar-valued function of a single variable. In other words, the Jacobian for a scalar-valued [[multivariate function]] is the gradient and that of a scalar-valued function of single variable is simply its derivative. The Jacobian can also be thought of as describing the amount of \"stretching\", \"rotating\" or \"transforming\" that a transformation imposes locally. For example, if {{math|(''x''′, ''y''′) {{=}} '''f'''(''x'', ''y'')}} is used to transform an image, the Jacobian {{math|'''J'''<sub>'''f'''</sub>(''x'', ''y'')}}, describes how the image in the neighborhood of {{math|(''x'', ''y'')}} is transformed.\n\nIf a function is differentiable at a point, its derivative is given in coordinates by the Jacobian, but a function does not need to be differentiable for the Jacobian to be defined, since only the [[partial derivative]]s are required to exist.\n\nIf {{math|'''p'''}} is a point in {{math|ℝ<sup>''n''</sup>}} and {{math|'''f'''}} is [[derivative|differentiable]] at {{math|'''p'''}}, then its derivative is given by {{math|'''J'''<sub>'''f'''</sub>('''p''')}}. In this case, the [[linear map]] described by {{math|'''J'''<sub>'''f'''</sub>('''p''')}} is the best [[linear approximation]] of {{math|'''f'''}} near the point {{math|'''p'''}}, in the sense that\n\n:<math>\\mathbf f(\\mathbf x) = \\mathbf f(\\mathbf p) + \\mathbf J_{\\mathbf f}(\\mathbf p)(\\mathbf x - \\mathbf p) + o(\\|\\mathbf x - \\mathbf p\\|)</math>\n\nfor {{math|'''x'''}} close to {{math|'''p'''}} and where {{math|''o''}} is the [[Big_O_notation#Little-o_notation|little o-notation]] (for {{math|'''x''' → '''p'''}}) and {{math|‖'''x''' − '''p'''‖}} is the [[Euclidean distance|distance]] between {{math|'''x'''}} and {{math|'''p'''}}. (See [[Total derivative#The total derivative as a linear map]].)\n\nCompare this to a [[Taylor series]] for a scalar function of a scalar argument, truncated to first order:\n\n:<math>f(x) = f(p) + f'(p) (x - p) + o(x - p) .</math>\n\nIn a sense, both the [[gradient]] and Jacobian are \"[[derivative|first derivatives]]\"—the former the first derivative of a ''scalar function'' of several variables, the latter the first derivative of a ''vector function'' of several variables.\n\nThe Jacobian of the gradient of a scalar function of several variables has a special name: the [[Hessian matrix]], which in a sense is the \"[[second derivative]]\" of the function in question.\n\n== Jacobian determinant ==\n\n[[File:Jacobian_determinant_and_distortion.svg|thumb|400px|A nonlinear map <math>f \\colon \\mathbb{R}^{2} \\to \\mathbb{R}^{2}</math> sends a small square (left, in red) to a distorted parallelogram (right, in red). The Jacobian at a point gives the best linear approximation of the distorted parallelogram near that point (right, in translucent white), and the Jacobian determinant gives the ratio of the area of the approximating parallelogram to that of the original square.]]\n\nIf {{math|1=''m'' = ''n''}}, then {{math|'''f'''}} is a function from {{math|ℝ<sup>''n''</sup>}} to itself and the Jacobian matrix is a [[square matrix]]. We can then form its [[determinant]], known as the '''Jacobian determinant'''. The Jacobian determinant is sometimes referred to as \"the Jacobian\".\n\nThe Jacobian determinant at a given point gives important information about the behavior of {{math|'''f'''}} near that point. For instance, the [[continuously differentiable function]] {{math|'''f'''}} is [[invertible]] near a point {{math|'''p''' ∈ ℝ<sup>''n''</sup>}} if the Jacobian determinant at {{math|'''p'''}} is non-zero. This is the [[inverse function theorem]]. Furthermore, if the Jacobian determinant at {{math|'''p'''}} is [[positive number|positive]], then {{math|'''f'''}} preserves orientation near {{math|'''p'''}}; if it is [[negative number|negative]], {{math|'''f'''}} reverses orientation. The [[absolute value]] of the Jacobian determinant at {{math|'''p'''}} gives us the factor by which the function {{math|'''f'''}} expands or shrinks [[volume]]s near {{math|'''p'''}}; this is why it occurs in the general [[substitution rule]].\n\nThe Jacobian determinant is used when making a [[Integration by substitution#Substitution for multiple variables|change of variables]] when evaluating a [[multiple integral]] of a function over a region within its domain. To accommodate for the change of coordinates the magnitude of the Jacobian determinant arises as a multiplicative factor within the integral. This is because the {{math|''n''}}-dimensional {{math|''dV''}} element is in general a [[parallelepiped]] in the new coordinate system, and the {{math|''n''}}-volume of a parallelepiped is the determinant of its edge vectors.\n\nThe Jacobian can also be used to solve [[matrix differential equation|systems of differential equations]] at an [[equilibrium point]] or approximate solutions near an equilibrium point. Its applications include determining the stability of the disease-free equilibrium in disease modelling.<ref>{{cite journal |vauthors=((Smith? RJ)) |title=The Joys of the Jacobian |journal=Chalkdust |volume=2 |pages=10–17 |year=2015 |url=http://chalkdustmagazine.com/features/the-joys-of-the-jacobian/}}</ref>\n\n== Inverse ==\n\nAccording to the [[inverse function theorem]], the [[Invertible matrix|matrix inverse]] of the Jacobian matrix of an [[invertible function]] is the Jacobian matrix of the ''inverse'' function.  That is, if the Jacobian of the function {{math|'''f''' : ℝ<sup>''n''</sup> → ℝ<sup>''n''</sup>}} is continuous and nonsingular at the point {{math|'''p'''}} in {{math|ℝ<sup>''n''</sup>}}, then {{math|'''f'''}} is invertible when restricted to some neighborhood of {{math|'''p'''}} and\n\n:<math>\\mathbf J_{\\mathbf f^{-1}} \\circ \\mathbf f = {\\mathbf J_{\\mathbf f}}^{-1} .</math>\n\nConversely, if the Jacobian determinant is not zero at a point, then the function is ''locally invertible'' near this point, that is, there is a [[neighbourhood]] of this point in which the function is invertible.\n\nThe (unproved) [[Jacobian conjecture]] is related to global invertibility in the case of a polynomial function, that is a function defined by ''n'' [[polynomial]]s in ''n'' variables. It asserts that, if the Jacobian determinant is a non-zero constant (or, equivalently, that it does not have any complex zero), then the function is invertible and its inverse is a polynomial function.\n\n== Critical points ==\n\n{{main|Critical point (mathematics)|l1=Critical point}}\n\nIf {{math|'''f''' : ℝ<sup>''n''</sup> → ℝ<sup>''m''</sup>}} is a [[differentiable function]], a ''critical point'' of {{math|'''f'''}} is a point where the [[rank (linear algebra)|rank]] of the Jacobian matrix is not maximal. This means that the rank at the critical point is lower than the rank at some neighbour point. In other words, let {{math|''k''}} be the maximal dimension of the [[open ball]]s contained in the image of {{math|'''f'''}}; then a point is critical if all [[minor (linear algebra)|minor]]s of rank {{math|''k''}} of {{math|'''f'''}} are zero.\n\nIn the case where {{math|1=1 = ''m'' = ''n'' = ''k''}}, a point is critical if the Jacobian determinant is zero.\n\n== Examples ==\n\n=== Example 1 ===\n\nConsider the function {{math|'''f''' : ℝ<sup>2</sup> → ℝ<sup>2</sup>,}} with  {{math|(''x'', ''y'') ↦ (''f''<sub>1</sub>(''x'', ''y''), ''f''<sub>2</sub>(''x'', ''y'')),}} given by\n:<math> \\mathbf f\\left(\\begin{bmatrix} x\\\\y\\end{bmatrix}\\right) = \\begin{bmatrix} f_1(x,y)\\\\f_2(x,y)\\end{bmatrix} =\n  \\begin{bmatrix}  x^2 y \\\\5 x + \\sin y \n  \\end{bmatrix}.</math>\n\nThen we have\n:<math>f_1(x, y) = x^2 y</math>\nand\n:<math>f_2(x, y) = 5 x + \\sin y</math>\nand the Jacobian matrix of {{math|'''f'''}} is\n:<math>\\mathbf J_{\\mathbf f}(x, y) = \\begin{bmatrix}\n  \\dfrac{\\partial f_1}{\\partial x} & \\dfrac{\\partial f_1}{\\partial y}\\\\[1em]\n  \\dfrac{\\partial f_2}{\\partial x} & \\dfrac{\\partial f_2}{\\partial y} \\end{bmatrix}\n= \\begin{bmatrix}\n  2 x y & x^2    \\\\\n  5     & \\cos y \\end{bmatrix}</math>\nand the Jacobian determinant is\n:<math>\\det(\\mathbf J_{\\mathbf f}(x, y)) = 2 x y \\cos y - 5 x^2 .</math>\n\n=== Example 2: polar-Cartesian transformation ===\n\nThe transformation from [[polar coordinate system|polar coordinates]] {{math|(''r'', ''φ'')}} to [[Cartesian coordinate system|Cartesian coordinates]] (''x'', ''y''), is given by the function {{math|'''F''': ℝ<sup>+</sup> × [0, 2{{pi}}) → ℝ<sup>2</sup>}} with components:\n\n:<math>\\begin{align}\nx &= r \\cos \\varphi ; \\\\\ny &= r \\sin \\varphi .\n\\end{align}</math>\n:<math>\\mathbf J_{\\mathbf F}(r, \\varphi) = \\begin{bmatrix}\n  \\dfrac{\\partial x}{\\partial r} & \\dfrac{\\partial x}{\\partial\\varphi}\\\\[1em]\n  \\dfrac{\\partial y}{\\partial r} & \\dfrac{\\partial y}{\\partial\\varphi} \\end{bmatrix}\n= \\begin{bmatrix}\n  \\cos\\varphi & - r\\sin \\varphi \\\\\n  \\sin\\varphi &   r\\cos \\varphi \\end{bmatrix}</math>\n\nThe Jacobian determinant is equal to {{math|''r''}}.  This can be used to transform integrals between the two coordinate systems:\n:<math>\\iint_{\\mathbf F(A)} f(x, y) \\,dx \\,dy = \\iint_A f(r \\cos \\varphi, r \\sin \\varphi) \\, r \\, dr \\, d\\varphi .</math>\n\n=== Example 3: spherical-Cartesian transformation ===\n\nThe transformation from [[spherical coordinate system|spherical coordinates]] {{math|(''r'', ''θ'', ''φ'')}} to [[Cartesian coordinate system|Cartesian coordinates]] (''x'', ''y'', ''z''), is given by the function {{math|'''F''': ℝ<sup>+</sup> × [0, ''π''] × [0, 2 ''π'') → ℝ<sup>3</sup>}} with components:\n\n:<math>\\begin{align}\nx &= r \\sin \\theta \\cos \\varphi ; \\\\\ny &= r \\sin \\theta \\sin \\varphi ; \\\\\nz &= r \\cos \\theta .\n\\end{align}</math>\n\nThe Jacobian matrix for this coordinate change is\n\n:<math>\\mathbf J_{\\mathbf F}(r, \\theta, \\varphi) = \\begin{bmatrix}\n  \\dfrac{\\partial x}{\\partial r} & \\dfrac{\\partial x}{\\partial \\theta} & \\dfrac{\\partial x}{\\partial \\varphi} \\\\[1em]\n  \\dfrac{\\partial y}{\\partial r} & \\dfrac{\\partial y}{\\partial \\theta} & \\dfrac{\\partial y}{\\partial \\varphi} \\\\[1em]\n  \\dfrac{\\partial z}{\\partial r} & \\dfrac{\\partial z}{\\partial \\theta} & \\dfrac{\\partial z}{\\partial \\varphi}\\end{bmatrix}\n= \\begin{bmatrix}\n      \\sin \\theta \\cos \\varphi & r \\cos \\theta \\cos \\varphi & - r \\sin \\theta \\sin \\varphi \\\\\n      \\sin \\theta \\sin \\varphi & r \\cos \\theta \\sin \\varphi & r \\sin \\theta \\cos \\varphi \\\\\n      \\cos \\theta & - r \\sin \\theta & 0 \\end{bmatrix}.</math>\n\nThe [[determinant]] is {{math|''r''<sup>2</sup> sin ''θ''}}.  As an example, since {{math|''dV'' {{=}} ''dx'' ''dy'' ''dz''}} this determinant implies that the [[differential volume element]] {{math|''dV'' {{=}} ''r''<sup>2</sup> sin ''θ'' ''dr'' ''dθ'' ''dφ''}}. Unlike for a change of [[Cartesian coordinates]], this determinant is not a constant, and varies with coordinates ({{math|''r''}} and {{math|''θ''}}).\n\n=== Example 4 ===\n\nThe Jacobian matrix of the function {{math|'''F''' : ℝ<sup>3</sup> → ℝ<sup>4</sup>}} with components\n\n:<math>\\begin{align}\ny_1 &= x_1 \\\\\ny_2 &= 5 x_3 \\\\\ny_3 &= 4 x_2^2 - 2 x_3 \\\\\ny_4 &= x_3 \\sin x_1\n\\end{align}</math>\n\nis\n\n:<math>\\mathbf J_{\\mathbf F}(x_1, x_2, x_3) = \\begin{bmatrix}\n  \\dfrac{\\partial y_1}{\\partial x_1} & \\dfrac{\\partial y_1}{\\partial x_2} & \\dfrac{\\partial y_1}{\\partial x_3} \\\\[1em]\n  \\dfrac{\\partial y_2}{\\partial x_1} & \\dfrac{\\partial y_2}{\\partial x_2} & \\dfrac{\\partial y_2}{\\partial x_3} \\\\[1em]\n  \\dfrac{\\partial y_3}{\\partial x_1} & \\dfrac{\\partial y_3}{\\partial x_2} & \\dfrac{\\partial y_3}{\\partial x_3} \\\\[1em]\n  \\dfrac{\\partial y_4}{\\partial x_1} & \\dfrac{\\partial y_4}{\\partial x_2} & \\dfrac{\\partial y_4}{\\partial x_3} \\end{bmatrix}\n= \\begin{bmatrix}\n  1 & 0 & 0 \\\\\n  0 & 0 & 5 \\\\\n  0 & 8 x_2 & -2 \\\\\n  x_3\\cos x_1 & 0 & \\sin x_1 \\end{bmatrix}.</math>\n\nThis example shows that the Jacobian need not be a square matrix.\n\n=== Example 5 ===\n\nThe Jacobian determinant of the function {{math|'''F''' : ℝ<sup>3</sup> → ℝ<sup>3</sup>}} with components\n\n:<math>\\begin{align}\n  y_1 &= 5x_2 \\\\\n  y_2 &= 4x_1^2 - 2 \\sin (x_2x_3) \\\\\n  y_3 &= x_2 x_3\n\\end{align}</math>\n\nis\n\n:<math>\\begin{vmatrix}\n  0 & 5 & 0 \\\\\n  8 x_1 & -2 x_3 \\cos(x_2 x_3) & -2 x_2 \\cos (x_2 x_3) \\\\\n  0 & x_3 & x_2\n\\end{vmatrix} = -8 x_1 \\begin{vmatrix}\n  5 & 0 \\\\\n  x_3 & x_2\n\\end{vmatrix} = -40 x_1 x_2.</math>\n\nFrom this we see that {{math|'''F'''}} reverses orientation near those points where {{math|''x''<sub>1</sub>}} and {{math|''x''<sub>2</sub>}} have the same sign; the function is [[locally]] invertible everywhere except near points where {{math|''x''<sub>1</sub> {{=}} 0}} or {{math|''x''<sub>2</sub> {{=}} 0}}. Intuitively, if one starts with a tiny object around the point {{math|(1, 2, 3)}} and apply {{math|'''F'''}} to that object, one will get a resulting object with approximately {{math|40 × 1 × 2 {{=}} 80}} times the volume of the original one, with orientation reversed.\n\n== Other uses ==\n\nThe Jacobian serves as a linearized [[design matrix]] in statistical [[regression analysis|regression]] and [[curve fitting]]; see [[non-linear least squares]].\n\n=== Dynamical systems ===\n\nConsider a [[dynamical system]] of the form <math>\\dot{\\mathbf{x}} = F(\\mathbf{x})</math>, where <math>\\dot{\\mathbf{x}}</math> is the (component-wise) derivative of <math>\\mathbf{x}</math> with respect to the [[evolution parameter]] <math>t</math> (time), and <math>F \\colon \\mathbb{R}^{n} \\to \\mathbb{R}^{n}</math> is differentiable.  If <math>F(\\mathbf{x}_{0}) = 0</math>, then <math>\\mathbf{x}_{0}</math> is a [[stationary point]] (also called a [[steady state]]). By the [[Hartman–Grobman theorem]], the behavior of the system near a stationary point is related to the [[eigenvalue]]s of <math>\\mathbf{J}_{F} \\left( \\mathbf{x}_{0} \\right)</math>, the Jacobian of <math>F</math> at the stationary point.<ref>{{cite book |first=D. K. |last=Arrowsmith |first2=C. M. |last2=Place |title=Dynamical Systems: Differential Equations, Maps, and Chaotic Behaviour |chapter=The Linearization Theorem |publisher=Chapman & Hall |location=London |year=1992 |isbn=0-412-39080-9 |pages=77–81 |chapterurl=https://books.google.com/books?id=8qCcP7KNaZ0C&pg=PA77 }} </ref> Specifically, if the eigenvalues all have real parts that are negative, then the system is stable near the stationary point, if any eigenvalue has a real part that is positive, then the point is unstable. If the largest real part of the eigenvalues is zero, the Jacobian matrix does not allow for an evaluation of the stability.<ref>{{cite book |first=Morris |last=Hirsch |first2=Stephen |last2=Smale |title=Differential equations, dynamical systems and linear algebra |year=1974}}</ref>\n\n=== Newton's method ===\n\nA square system of coupled nonlinear equations can be solved iteratively by [[Newton's method#Nonlinear systems of equations|Newton's method]].  This method uses the Jacobian matrix of the system of equations.\n\n===Surface analysis===\nLet ''n'' = 2 so the Jacobian is a [[2 × 2 real matrix]]. Suppose a [[surface (differential geometry)|surface]] [[diffeomorphism]] f: ''U'' → ''V'' in the neighborhood of ''p'' in ''U'' is written <math>(u(x,y),\\ v(x,y)) .</math> The matrix <math>\\mathbf J_{\\mathbf f}(\\mathbf p)</math> can be interpreted as a complex number: ordinary, split, or dual. Furthermore, since <math>\\mathbf J_{\\mathbf f}(\\mathbf p)</math> is invertible, the complex number has a [[polar decomposition]] or an [[polar decomposition#Alternative planar decompositions|alternative planar decomposition]].\n\nAnd again, each such complex number represents a [[Group action (mathematics)|group action]] on the tangent plane at ''p''. The action is dilation by the norm of the complex number, and rotation respecting [[angle]], [[hyperbolic angle]], or [[slope]], according to the case of <math>\\mathbf J_{\\mathbf f}(\\mathbf p) .</math> Such action corresponds to a [[conformal mapping#Pseudo-Riemannian geometry|conformal mapping]].\n\n== See also ==\n* [[Center manifold]]\n* [[Hessian matrix]]\n* [[Pushforward (differential)]]\n\n== References ==\n{{Reflist}}\n\n== Further reading ==\n* {{cite book |last=Gandolfo |first=Giancarlo |authorlink=Giancarlo Gandolfo |title=Economic Dynamics |location=Berlin |publisher=Springer |edition=Third |year=1996 |isbn=3-540-60988-1 |pages=305–330 }}\n\n== External links ==\n\n* {{springer|title=Jacobian|id=p/j054080}}\n* [http://mathworld.wolfram.com/Jacobian.html Mathworld] A more technical explanation of Jacobians\n\n{{Matrix classes}}\n\n[[Category:Multivariable calculus]]\n[[Category:Differential calculus]]\n[[Category:Generalizations of the derivative]]\n[[Category:Determinants]]\n[[Category:Matrices]]"
    },
    {
      "title": "Lie derivative",
      "url": "https://en.wikipedia.org/wiki/Lie_derivative",
      "text": "{{Use dmy dates|date=September 2013}}\nIn [[differential geometry]], the '''Lie derivative''' {{IPAc-en|ˈ|l|iː}}, named after [[Sophus Lie]] by [[Władysław Ślebodziński]],<ref>{{cite book |first=A. |last=Trautman |authorlink=Andrzej Trautman |year=2008 |chapter=Remarks on the history of the notion of Lie differentiation |title=Variations, Geometry and Physics: In honour of Demeter Krupka’s sixty-fifth birthday |editor1-first=O. |editor1-last=Krupková |editor2-first=D. J. |editor2-last=Saunders |location=New York |publisher=Nova Science |isbn=978-1-60456-920-9 |pages=297–302 }}</ref><ref>{{cite journal |last=Ślebodziński |first=W. |year=1931 |title=Sur les équations de Hamilton |journal=Bull. Acad. Roy. d. Belg. |volume=17 |issue=5 |pages=864–870 |doi= }}</ref> evaluates the change of a [[tensor field]] (including scalar function, [[vector field]] and [[one-form]]), along the [[flow (mathematics)|flow]] defined by another vector field. This change is coordinate invariant and therefore the Lie derivative is defined on any  [[differentiable manifold]].\n\nFunctions, tensor fields and forms can be differentiated with respect to a vector field. If ''T'' is a tensor field and ''X'' is a vector field, then the Lie derivative of ''T'' with respect to ''X'' is denoted <math> \\mathcal{L}_X(T)</math>. The [[differential operator]] <math> T \\mapsto \\mathcal{L}_X(T)</math> is a [[derivation (differential algebra)|derivation]] of the algebra of [[tensor fields]] of the underlying manifold.\n\nThe Lie derivative commutes with [[Tensor contraction|contraction]] and the [[exterior derivative]] on [[differential forms]].\n\nAlthough there are many concepts of taking a derivative in differential geometry, they all agree when the expression being differentiated is a function or [[scalar field]]. Thus in this case the word \"Lie\" is dropped, and one simply speaks of the derivative of a function.\n\nThe Lie derivative of a vector field ''Y'' with respect to another vector field ''X'' is known as the \"[[Lie bracket of vector fields|Lie bracket]]\"  of ''X'' and ''Y'', and is often denoted [''X'',''Y''] instead of <math> \\mathcal{L}_X(Y)</math>. The space of vector fields forms a [[Lie algebra]] with respect to this Lie bracket. The Lie derivative constitutes an infinite-dimensional [[Lie algebra representation]] of this Lie algebra, due to the identity\n\n:<math> \\mathcal{L}_{[X,Y]} T = \\mathcal{L}_X \\mathcal{L}_{Y} T - \\mathcal{L}_Y \\mathcal{L}_X T,</math>\n\nvalid for any vector fields ''X'' and ''Y'' and any tensor field ''T''.\n\nConsidering vector fields as [[Lie algebra|infinitesimal generator]]s of [[Flow (mathematics)|flows]] (i.e. one-dimensional [[Group (mathematics)|groups]] of [[diffeomorphism]]s) on ''M'', the Lie derivative is the [[Lie_algebra_representation#Infinitesimal_Lie_group_representations|differential]] of the representation of the [[Diffeomorphism#Diffeomorphism group|diffeomorphism group]] on tensor fields, analogous to Lie algebra representations as [[Lie algebra representation#Infinitesimal Lie group representations|infinitesimal representations]] associated to [[group representation]] in [[Lie group]] theory.\n\nGeneralisations exist for [[spinor]] fields, [[fibre bundle]]s with [[Connection (mathematics)|connection]] and vector-valued [[differential forms]].\n\n==Motivation==\nA \"naive\" attempt to define the derivative of a [[tensor field]] with respect to a [[vector field]] would be to take the [[Tensor#As multidimensional arrays|components]] of the tensor field and take the [[directional derivative]] with respect to the vector field of each component. However, this definition is undesirable because it is not invariant under [[Manifold#Transition map|changes of coordinate system]] and e.g. the naive derivative expressed in polar or spherical coordinates differs from the naive derivative of the components in polar or spherical coordinates. On an abstract [[manifold]] such a definition is meaningless and ill defined. In [[differential geometry]], there are  three main coordinate independent notions of differentiation of tensor fields: Lie derivatives, derivatives with respect to [[Connection_(differential_geometry)|connections]], and the [[exterior derivative]] of completely anti symmetric (covariant) tensors or [[differential forms]]. The main difference between the Lie derivative and a derivative with respect to a connection is that the latter derivative of a tensor field with respect to a [[tangent space|tangent vector]] is well-defined even if it is not specified how to extend that tangent vector to a vector field. However a connection requires the choice of an additional geometric structure (e.g. a [[Riemannian manifold|Riemannian metric]] or just an abstract [[Connection_(differential_geometry)|connection]]) on the manifold. In contrast, when taking a Lie derivative, no additional structure on the manifold is needed, but it is impossible to talk about the Lie derivative of a tensor field with respect to a single tangent vector, since the value of the Lie derivative of a tensor field with respect to a vector field ''X'' at a point ''p'' depends on the value of ''X'' in a neighborhood of ''p'', not just at ''p'' itself. Finally, the exterior derivative of differential forms does not require any additional choices, but is only a well defined derivative of differential forms (including functions).\n\n==Definition==\nThe Lie derivative may be defined in several equivalent ways. To keep things simple, we begin by defining the Lie derivative acting on scalar functions and vector fields, before moving on to the definition for general tensors.\n\n===The (Lie) derivative of a function===\nThe problem with generalizing the derivative of a function when we consider functions over manifolds is that the usual [[difference quotient]] requires we define addition on the function's inputs but it is meaningless to add points on a manifold which is not a vector space.  The critical issue, however, is to consider how the function changes relative to smooth displacements of the points.  The Lie derivative of a scalar function can be thought of as a definition of the derivative where we are using the flows defined by vector fields to displace the points:\n\n:The Lie derivative of a function ''f'' with respect to a [[vector field]] ''X'' at a point ''p'' of the manifold ''M'' is the value\n::<math>\\mathcal{L}_X f (p) = \\lim_{t\\to 0} \\frac{f(P(t;p)) - f(p)}{t}</math>\nwhere <math>P(t; p)</math> is the point to which the [[flow (mathematics)|flow]] defined by the vector field <math>X</math> maps the point <math>p</math> as follows: in a coordinate neighbourhood with coordinates <math> x^1,..., x^n</math>we can express the vector field (which we consider as a first order differential operator) as <math>X = X^\\mu(x)\\partial_\\mu = X^\\mu \\frac\\partial{\\partial x^\\mu}</math>. Locally, the flow is then defined by <math> x^\\mu(P(t; p)) = P^\\mu(t, p^1,..., p^n)</math> where <math>p^\\mu = x^\\mu(p)</math> and <math>P^\\mu(t;0)</math> is the solution to the partial differential equation  \n::<math> \\partial_t P^\\mu(t; p^1, ..., p^n) = X^\\mu(P^1(t; p^1,..., p^n),..., P^n(t, p^1, ..., p^n))) </math>\nwith <math>P^\\mu(0; p^1,...,p^n) = p^\\mu</math>.\n \nWe can then identify the Lie derivative of a function at ''p'' with the [[directional derivative]]:\n::<math>(\\mathcal{L}_X f)(p) = (X f)(p) = X^\\mu \\partial_\\mu(f(p(x^1,...,x^n))) = \\partial_t (f(P(t; p)))</math>\n\n===The Lie derivative of a vector field===\nIf ''X'' and ''Y'' are both vector fields, then the Lie derivative of ''Y'' with respect to ''X'' is also known as the [[Lie bracket of vector fields|Lie bracket]] of ''X'' and ''Y'', and is sometimes denoted <math>[X,Y]</math>. There are several approaches to defining the Lie bracket, all of which are equivalent. We list two definitions here, corresponding to the two definitions of a vector field given above:\n\n* The Lie bracket of ''X'' and ''Y'' at ''p'' is given in local coordinates by the formula\n\n<math>\\mathcal{L}_X Y (p) = [X,Y](p) = \\partial_X Y(p) - \\partial_Y X(p),</math>\n\nwhere <math>\\partial_X</math> and <math>\\partial_Y</math> denote the operations of taking the [[directional derivative]]s with respect to ''X'' and ''Y'', respectively. Here we are treating a vector in ''n''-dimensional space as an ''n''-[[tuple]], so that its directional derivative is simply the tuple consisting of the directional derivatives of its coordinates. Note that although the final expression <math>\\partial_X Y(p) - \\partial_Y X(p)</math> appearing in this definition does not depend on the choice of local coordinates, the individual terms <math>\\partial_X Y(p)</math> and <math>\\partial_Y X(p)</math> do depend on the choice of coordinates.\n\n* If ''X'' and ''Y'' are vector fields on a manifold ''M'' according to the second definition, then the operator <math>\\mathcal{L}_X Y = [X,Y]</math> defined by the formula\n::<math>[X,Y]: C^\\infty(M) \\rightarrow C^\\infty(M)</math>\n::<math>[X,Y](f) = X(Y(f)) - Y(X(f))</math>\nis a derivation of order zero of the algebra of smooth functions of ''M'', i.e. this operator is a vector field according to the second definition.\n\n===The Lie derivative of a tensor field===\nMore generally, if we have a [[Differentiable function|differentiable]] [[tensor field]] ''T'' of [[Tensor order|rank]] <math>(q,r)</math> and a differentiable [[vector field]] ''Y'' (i.e. a differentiable section of the [[tangent bundle]] ''TM''), then we can define the Lie derivative of ''T'' along ''Y''. Let, for some open interval ''I'' around 0, {{nowrap|''φ'' : ''M'' × ''I'' → ''M''}} be the one-parameter semigroup of local diffeomorphisms of ''M'' induced by the [[vector flow]] of ''Y'' and denote {{nowrap|1=''φ''<sub>''t''</sub>(''p'') := ''φ''(''p'', ''t'')}}. For each sufficiently small ''t'', ''φ''<sub>''t''</sub> is a diffeomorphism from a [[neighborhood (mathematics)|neighborhood]] in ''M'' to another neighborhood in ''M'', and ''φ''<sub>0</sub> is the identity diffeomorphism. The Lie derivative of ''T'' is defined at a point ''p'' by\n\n:<math>(\\mathcal{L}_Y T)_p=\\left.\\frac{d}{dt}\\right|_{t=0}\\left((\\varphi_{-t})_*T_{\\varphi_{t}(p)}\\right)=\\left.\\frac{d}{dt}\\right|_{t=0}\\left((\\varphi_{t})^*T_{p}\\right).</math>\n\nwhere <math>(\\varphi_t)_*</math> is the [[pushforward (differential)|pushforward]] along the diffeomorphism and <math>(\\varphi_t)^*</math> is the [[Pullback (differential geometry)|pullback]] along the diffeomorphism. Intuitively, if you have a tensor field <math>T</math> and a vector field ''Y'', then <math>\\mathcal{L}_{Y} T</math> is the infinitesimal change you would see when you flow <math>T</math> using the vector field −''Y'', which is the same thing as the infinitesimal change you would see in <math>T</math> if you yourself flowed along the vector field  ''Y''.\n\nWe now give an algebraic definition. The algebraic definition for the Lie derivative of a tensor field follows from the following four axioms:\n\n:'''Axiom 1.''' The Lie derivative of a function is equal to the directional derivative of the function. This fact is often expressed by the formula\n::<math>\\mathcal{L}_Yf=Y(f)</math>\n\n:'''Axiom 2.''' The Lie derivative obeys the following version of Leibniz's rule: For any tensor fields ''S'' and ''T'', we have\n::<math>\\mathcal{L}_Y(S\\otimes T)=(\\mathcal{L}_YS)\\otimes T+S\\otimes (\\mathcal{L}_YT).</math>\n\n:'''Axiom 3.''' The Lie derivative obeys the Leibniz rule with respect to [[Tensor contraction|contraction]]:\n::<math> \\mathcal{L}_X (T(Y_1, \\ldots, Y_n)) = (\\mathcal{L}_X T)(Y_1,\\ldots, Y_n) + T((\\mathcal{L}_X Y_1), \\ldots, Y_n) + \\cdots + T(Y_1, \\ldots, (\\mathcal{L}_X Y_n)) </math>\n\n:'''Axiom 4.''' The Lie derivative commutes with exterior derivative on functions:\n::<math> [\\mathcal{L}_X, d] = 0 </math>\n\nIf these axioms hold, then applying the Lie derivative <math>\\mathcal{L}_X</math> to the relation <math> df(Y) = Y(f) </math> shows that\n::<math>\\mathcal{L}_X Y (f) = X(Y(f)) - Y(X(f)),</math>\nwhich is one of the standard definitions for the [[Lie bracket of vector fields|Lie bracket]].\n\nThe Lie derivative of a differential form is the [[Commutator#Ring theory|anticommutator]] of the [[interior product]] with the exterior derivative. So if α is a differential form,\n::<math>\\mathcal{L}_Y\\alpha=i_Yd\\alpha+di_Y\\alpha.</math>\nThis follows easily by checking that the expression commutes with exterior derivative, is a derivation (being an anticommutator of graded derivations) and does the right thing on functions.\n\nExplicitly, let ''T'' be a tensor field of type {{nowrap|(''p'', ''q'')}}. Consider ''T'' to be a differentiable [[multilinear map]] of [[smooth function|smooth]] [[section (fiber bundle)|sections]] ''α''<sup>1</sup>, ''α''<sup>2</sup>, ..., ''α''<sup>''q''</sup> of the cotangent bundle ''T''<sup>∗</sup>''M'' and of sections ''X''<sub>1</sub>, ''X''<sub>2</sub>, ..., ''X''<sub>p</sub> of the [[tangent bundle]] ''TM'', written ''T''(''α''<sup>1</sup>, ''α''<sup>2</sup>, ..., ''X''<sub>1</sub>, ''X''<sub>2</sub>, ...) into '''R'''. Define the Lie derivative of ''T'' along ''Y'' by the formula\n\n:<math>(\\mathcal{L}_Y T)(\\alpha_1, \\alpha_2, \\ldots, X_1, X_2, \\ldots) =Y(T(\\alpha_1,\\alpha_2,\\ldots,X_1,X_2,\\ldots))</math>\n::<math>- T(\\mathcal{L}_Y\\alpha_1, \\alpha_2, \\ldots, X_1, X_2, \\ldots)\n- T(\\alpha_1, \\mathcal{L}_Y\\alpha_2, \\ldots, X_1, X_2, \\ldots) -\\ldots </math>\n::<math>- T(\\alpha_1, \\alpha_2, \\ldots, \\mathcal{L}_YX_1, X_2, \\ldots)\n-  T(\\alpha_1, \\alpha_2, \\ldots, X_1, \\mathcal{L}_YX_2, \\ldots) - \\ldots\n</math>\n\nThe analytic and algebraic definitions can be proven to be equivalent using the properties of the pushforward and the [[General Leibniz rule|Leibniz rule]] for differentiation. Note also that the Lie derivative commutes with the contraction.\n\n===The Lie derivative of a differential form===\n{{see also|Interior product}}\nA particularly important class of tensor fields is the class of [[differential forms]]. The restriction of the Lie derivative to the space of differential forms is closely related to the [[exterior derivative]]. Both the Lie derivative and the exterior derivative attempt to capture the idea of a derivative in different ways. These differences can be bridged by introducing the idea of an [[interior product]], after which the relationships falls out as an identity known as '''Cartan's formula'''. Note that Cartan's formula can also be used as a definition of the Lie derivative on the space of differential forms.\n\nLet ''M'' be a manifold and ''X'' a vector field on ''M''. Let <math>\\omega \\in \\Lambda^{k+1}(M)</math> be a {{nowrap|(''k'' + 1)}}-[[Differential form|form]], i.e. for each <math>p \\in M</math>, <math>\\omega(p)</math> is an [[Alternating form|alternating]] [[multilinear map]] from <math>(T_p M)^{k + 1}</math> to the real numbers. The [[interior product]] of ''X'' and ''ω'' is the ''k''-form <math>i_X\\omega</math> defined as\n\n:<math>(i_X\\omega) (X_1, \\ldots, X_k) = \\omega (X,X_1, \\ldots, X_k)\\,</math>\n\nThe differential form <math>i_X\\omega</math> is also called the '''contraction''' of ''ω'' with ''X''. Note that\n\n:<math>i_X:\\Lambda^{k+1}(M) \\rightarrow \\Lambda^k(M)</math>\n\nand that <math>i_X</math> is a <math>\\wedge</math>-[[derivation (abstract algebra)|antiderivation]]. That is, <math>i_X</math> is '''R'''-linear, and\n\n:<math>i_X (\\omega \\wedge \\eta) = \n(i_X \\omega) \\wedge \\eta + (-1)^k \\omega \\wedge (i_X \\eta)</math>\n\nfor <math>\\omega \\in \\Lambda^k(M)</math> and η another differential form. Also, for a function <math>f \\in \\Lambda^0(M)</math>, that is, a real- or complex-valued function on ''M'', one has\n\n:<math>i_{fX} \\omega = f\\,i_X\\omega</math>\n\nwhere <math>f X</math> denotes the product of ''f'' and ''X''.\nThe relationship between [[exterior derivative]]s and Lie derivatives can then be summarized as follows. First, since the Lie derivative of a function ''f'' with respect to a vector field ''X'' is the same as the directional derivative ''X''(''f''), it is also the same as the [[Differential form#Operations on forms|contraction]] of the exterior derivative of ''f'' with ''X'':\n\n:<math>\\mathcal{L}_Xf = i_X \\, df</math>\n\nFor a general differential form, the Lie derivative is likewise a contraction, taking into account the variation in ''X'':\n\n:<math>\\mathcal{L}_X\\omega = i_Xd\\omega + d(i_X \\omega).</math>\n\nThis identity is known variously as '''Cartan formula''', '''Cartan homotopy formula''' or '''Cartan's magic formula'''. See [[interior product]] for details. The Cartan formula can be used as a definition of the Lie derivative of a differential form. Cartan's formula shows in particular that\n\n:<math>d\\mathcal{L}_X\\omega = \\mathcal{L}_X(d\\omega).</math>\n\nThe Lie derivative also satisfies the relation\n\n:<math>\\mathcal{L}_{fX}\\omega = f\\mathcal{L}_X\\omega + df \\wedge i_X \\omega .</math>\n\n==Coordinate expressions==\n{{Einstein summation convention}}\n\nIn local [[coordinate]] notation, for a type {{nowrap|(''r'', ''s'')}} tensor field <math>T</math>, the Lie derivative along <math>X</math> is\n:<math> \\begin{align}\n(\\mathcal{L}_X T) ^{a_1 \\ldots a_r}{}_{b_1 \\ldots b_s} = & X^c(\\partial_c T^{a_1 \\ldots a_r}{}_{b_1 \\ldots b_s}) \\\\ & - (\\partial_c X ^{a_1}) T ^{c a_2 \\ldots a_r}{}_{b_1 \\ldots b_s} - \\ldots - (\\partial_c X^{a_r}) T ^{a_1 \\ldots a_{r-1}c}{}_{b_1 \\ldots b_s} \\\\ & + (\\partial_{b_1} X^c) T ^{a_1 \\ldots a_r}{}_{c b_2 \\ldots b_s} + \\ldots + (\\partial_{b_s}X^c) T ^{a_1 \\ldots a_r}{}_{b_1 \\ldots b_{s-1} c}\n\\end{align}</math>\nhere, the notation <math>\\partial_a = \\frac{\\partial}{\\partial x^a}</math> means taking the partial derivative with respect to the coordinate <math> x^a</math>. Alternatively, if we are using a [[torsion (differential geometry)|torsion-free]] [[connection (mathematics)|connection]] (e.g., the [[Levi Civita connection]]), then the partial derivative <math>\\partial_a</math> can be replaced with the [[covariant derivative]] which means replacing <math>\\partial_a X^b</math>   with (by abuse of notation) <math>\\nabla_a X^b = X^b_{;a} := (\\nabla X)_a^{\\ b} = \\partial_a X^b  + \\Gamma^b_{ac}X^c</math> where the <math>\\Gamma^a_{bc} = \\Gamma^a_{cb}</math> are the [[Christoffel coefficients]].\n\nThe Lie derivative of a tensor is another tensor of the same type, i.e., even though the individual terms in the expression depend on the choice of coordinate system, the expression as a whole results in a tensor <math>(\\mathcal{L}_X T) ^{a_1 \\ldots a_r}{}_{b_1 \\ldots b_s}\\partial_{a_1}\\otimes\\cdots\\otimes\\partial_{a_r}\\otimes dx^{b_1}\\otimes\\cdots\\otimes dx^{b_s}</math>\nwhich is independent of any coordinate system and of the same type as <math>T</math>.\n\nThe definition can be extended further to tensor densities.  If ''T'' is a tensor density of some real number valued weight ''w'' (e.g. the volume density of weight 1), then its Lie derivative is a tensor density of the same type and weight.\n:<math> (\\mathcal {L}_X T) ^{a_1 \\ldots a_r}{}_{b_1 \\ldots b_s} = X^c(\\partial_c T^{a_1 \\ldots a_r}{}_{b_1 \\ldots b_s}) - (\\partial_c X ^{a_1}) T ^{c a_2 \\ldots a_r}{}_{b_1 \\ldots b_s} - \\ldots - (\\partial_c X^{a_r}) T ^{a_1 \\ldots a_{r-1}c}{}_{b_1 \\ldots b_s} +</math>\n::<math>+  (\\partial_{b_1} X^c) T ^{a_1 \\ldots a_r}{}_{c b_2 \\ldots b_s} + \\ldots + (\\partial_{b_s} X^c) T ^{a_1 \\ldots a_r}{}_{b_1 \\ldots b_{s-1} c} + w (\\partial_{c} X^c) T ^{a_1 \\ldots a_r}{}_{b_1 \\ldots b_{s}}\n</math>\nNotice the new term at the end of the expression.\n\nFor a [[Affine connection|linear connection]] <math>\\Gamma =( \\Gamma^{a}_{bc} )</math>, the Lie derivative along <math>X</math> is<ref>{{cite book|authorlink=Kentaro Yano (mathematician) |last=Yano |first=K. |title=The Theory of Lie Derivatives and its Applications\n|url=https://archive.org/details/theoryofliederiv029601mbp|publisher=North-Holland|year=1957|page=8|isbn=978-0-7204-2104-0}}</ref>\n:<math>\n(\\mathcal{L}_X \\Gamma)^{a}_{bc} =  X^d\\partial_d \\Gamma^{a}_{bc} + \\partial_b\\partial_c X^a - \\Gamma^{d}_{bc}\\partial_d X^a \n+ \\Gamma^{a}_{dc}\\partial_b X^d + \\Gamma^{a}_{bd}\\partial_c X^d\n</math>\n\n===Examples===\nFor clarity we now show the following examples in local [[coordinate]] notation.\n\nFor a [[scalar field]] <math>\\phi(x^c)\\in\\mathcal{F}(M)</math> we have:\n:<math> (\\mathcal {L}_X \\phi)=X(\\phi) = X^a \\partial_a \\phi</math>.\nHence for the scalar field <math>\\phi(x,y) = x^2 - \\sin(y)</math> and the vector field <math>X = \\sin(x)\\partial_y - y^2\\partial_x</math> the corresponding Lie derivative becomes \n<math display=\"block\">\n\\begin{alignat}{4}\n\\mathcal{L}_X\\phi &= (\\sin(x)\\partial_y - y^2\\partial_x)(x^2 - \\sin(y))\\\\\n                  & = -\\sin(x)\\cos(y) - 2xy^2\n\\end{alignat}\n</math>\n\nFor an example of higher rank differential form, \nconsider the 2-form <math>\\omega = (x^2 + y^2)dx\\wedge dz</math> and the vector field <math>X</math> from the previous example. Then,\n<math display=\"block\">\n\\begin{align}\n\\mathcal{L}_X\\omega & = d(i_{\\sin(x)\\partial_y - y^2\\partial_x}((x^2 + y^2)dx\\wedge dz)) + i_{\\sin(x)\\partial_y - y^2\\partial_x}(d((x^2 + y^2)dx\\wedge dz)) \\\\\n& = d(-y^2(x^2 + y^2) dz) + i_{\\sin(x)\\partial_y - y^2\\partial_x}(2ydy\\wedge dx\\wedge dz) \\\\\n& = \\left(- 2xy^2 dx + (-2yx^2  - 4y^3) dy\\right) \\wedge dz + (2y\\sin(x)dx \\wedge dz + 2y^3dy \\wedge dz)\\\\ \n& = \\left(-2xy^2 + 2y\\sin(x)\\right)dx\\wedge dz + (-2yx^2 - 2y^3)dy\\wedge dz\n\\end{align}\n</math>\n\nSome more abstract examples.\nNote that\n:<math>\\mathcal{L}_X (dx^b) = d i_X (dx^b) = d X^b = \\partial_a X^b dx^a </math>.\nHence For a [[One-form|covector field]], i.e., a [[differential form]], <math>A=A_a(x^b)dx^a</math> we have:\n:<math>\n\\mathcal{L}_X A =  X (A_a) dx^a +  A_b \\mathcal{L}_X (dx^b) = (X^b \\partial_b A_a + A_b\\partial_a (X^b))dx^a\n</math>\nNote that the coefficient of the last expression is the local coordinate expression of the Lie derivative. \n\nFor a covariant rank 2 tensor field <math>T=T_{ab}(x^c)dx^a\\otimes dx^b</math> we have:\n<math display = \"block\">\n\\begin{align} \n(\\mathcal {L}_X T) &= (\\mathcal {L}_X T)_{ab} dx^a\\otimes dx^b\\\\\n                   &= X(T_{ab})dx^a\\otimes dx^b + T_{cb} \\mathcal{L}_X (dx^c) \\otimes dx^b + T_{ac}  dx^a \\otimes \\mathcal{L}_X (dx^c)\\\\  \n                   &= (X^c \\partial_c T_{ab}+T_{cb}\\partial_a X^c+T_{ac}\\partial_b X^c)dx^a\\otimes dx^b\\\\\n\\end{align}\n</math>\nIf <math>T = g</math> is the symmetric metric tensor, it is parallel with respect to the Levi Civita connection (aka covariant derivative), and it becomes fruitful to use the connection. This has the effect of replacing all derivatives with covariant derivatives, giving\n:<math> (\\mathcal {L}_X g) = (X^c g_{ab; c}+g_{cb}X^c_{;a}+g_{ac}X^c_{; b})dx^a\\otimes dx^b = (X_{b;a} + X_{a;b}) dx^a\\otimes dx^b</math>\n\n==Properties==\nThe Lie derivative has a number of properties. Let <math>\\mathcal{F}(M)</math> be the [[algebra]] of functions defined on the [[manifold]] ''M''. Then\n\n:<math>\\mathcal{L}_X : \\mathcal{F}(M) \\rightarrow \\mathcal{F}(M)</math>\n\nis a [[derivation (abstract algebra)|derivation]] on the algebra <math>\\mathcal{F}(M)</math>. That is,\n<math>\\mathcal{L}_X</math> is '''R'''-linear and\n\n:<math>\\mathcal{L}_X(fg)=(\\mathcal{L}_Xf) g + f\\mathcal{L}_Xg.</math>\n\nSimilarly, it is a derivation on <math>\\mathcal{F}(M) \\times \\mathcal{X}(M)</math> where <math>\\mathcal{X}(M)</math> is the set of vector fields on ''M'':\n\n:<math>\\mathcal{L}_X(fY)=(\\mathcal{L}_Xf) Y + f\\mathcal{L}_X Y</math>\n\nwhich may also be written in the equivalent notation\n\n:<math>\\mathcal{L}_X(f\\otimes Y)=\n(\\mathcal{L}_Xf) \\otimes Y + f\\otimes \\mathcal{L}_X Y</math>\n\nwhere the [[tensor product]] symbol <math>\\otimes</math> is used to emphasize the fact that the product of a function times a vector field is being taken over the entire manifold.\n\nAdditional properties are consistent with that of the [[Lie bracket of vector fields|Lie bracket]]. Thus, for example, considered as a derivation on a vector field,\n\n:<math>\\mathcal{L}_X [Y,Z] = [\\mathcal{L}_X Y,Z] + [Y,\\mathcal{L}_X Z]</math>\n\none finds the above to be just the [[Jacobi identity]]. Thus, one has the important result that the space of vector fields over ''M'', equipped with the Lie bracket, forms a [[Lie algebra]].\n\nThe Lie derivative also has important properties when acting on differential forms. Let α and β be two differential forms on ''M'', and let ''X'' and ''Y'' be two vector fields. Then\n* <math>\\mathcal{L}_X(\\alpha\\wedge\\beta) = (\\mathcal{L}_X\\alpha) \\wedge\\beta + \\alpha\\wedge (\\mathcal{L}_X\\beta)</math>\n* <math>[\\mathcal{L}_X,\\mathcal{L}_Y]\\alpha:= \\mathcal{L}_X\\mathcal{L}_Y\\alpha-\\mathcal{L}_Y\\mathcal{L}_X\\alpha=\\mathcal{L}_{[X,Y]}\\alpha</math>\n* <math>[\\mathcal{L}_X,i_Y]\\alpha=[i_X,\\mathcal{L}_Y]\\alpha=i_{[X,Y]}\\alpha,</math> where ''i'' denotes interior product defined above and it's clear whether [·,·] denotes the [[commutator]] or the [[Lie bracket of vector fields]].\n\n==Generalizations==\nVarious generalizations of the Lie derivative play an important role in differential geometry.\n\n===The Lie derivative of a spinor field===\nA definition for Lie derivatives of [[spinors]] along generic spacetime vector fields, not necessarily [[Killing vector field|Killing]] ones, on a general (pseudo) [[Riemannian manifold]] was already proposed in 1972 by [[Yvette Kosmann-Schwarzbach|Yvette Kosmann]].<ref name=\"autogenerated317\">{{cite journal |last=Kosmann |first=Y. |authorlink=Yvette Kosmann-Schwarzbach |year=1972 |title=Dérivées de Lie des spineurs |journal=[[Annali di Matematica Pura ed Applicata|Ann. Mat. Pura Appl.]] |volume=91 |issue=4 |pages=317–395 |doi=10.1007/BF02428822 }}</ref> Later, it was provided a geometric framework which justifies her ''ad hoc'' prescription within the general framework of Lie derivatives on [[fiber bundles]]<ref>{{cite book |last=Trautman |first=A. |year=1972 |chapter=Invariance of Lagrangian Systems |editor-first=L. |editor-last=O'Raifeartaigh |editor-link=Lochlainn O'Raifeartaigh |title=General Relativity: Papers in honour of J. L. Synge |publisher=Clarenden Press |location=Oxford |isbn=0-19-851126-4 |page=85 }}</ref> in the explicit context of gauge natural bundles which turn out to be the most appropriate arena for (gauge-covariant) field theories.<ref>{{cite book |last=Fatibene |first=L. |last2=Francaviglia |first2=M. |authorlink2=Mauro Francaviglia |year=2003 |title=Natural and Gauge Natural Formalism for Classical Field Theories |publisher=Kluwer Academic |location=Dordrecht |isbn= }}</ref>\n\nIn a given [[spin manifold]], that is in a Riemannian manifold <math>(M,g)</math> admitting a [[spin structure]], the Lie derivative of a [[spinor]] [[Field (mathematics)|field]] <math>\\psi</math> can be defined by first defining it with respect to infinitesimal isometries (Killing vector fields) via the [[André Lichnerowicz]]'s local expression given in 1963:<ref>{{cite journal |last=Lichnerowicz |first=A. |year=1963 |title=Spineurs harmoniques |journal=C. R. Acad. Sci. Paris |volume=257 |issue= |pages=7–9 }}</ref>\n\n:<math>\\mathcal{L}_X \\psi := X^{a}\\nabla_{a}\\psi\n-\\frac14\\nabla_{a}X_{b} \\gamma^{a}\\,\\gamma^{b}\\psi\\, ,</math>\n\nwhere <math>\\nabla_{a}X_{b}=\\nabla_{[a}X_{b]}</math>, as <math>X=X^{a}\\partial_{a}</math> is assumed to be a [[Killing vector field]], and <math>\\gamma^{a}</math> are [[Dirac matrices]].\n\nIt is then possible to extend Lichnerowicz's definition to all vector fields (generic infinitesimal transformations) by retaining Lichnerowicz's local expression for a ''generic'' vector field <math>X</math>, but explicitly taking the antisymmetric part of <math>\\nabla_{a}X_{b}</math> only.<ref name=\"autogenerated317\" /> More explicitly, Kosmann's local expression given in 1972 is:<ref name=\"autogenerated317\"/>\n\n:<math>\\mathcal{L}_X \\psi := X^{a}\\nabla_{a}\\psi\n-\\frac18\\nabla_{[a}X_{b]}\n[\\gamma^{a},\\gamma^{b}]\\psi\\, = \\nabla_X \\psi - \\frac14 (d X^\\flat)\\cdot \\psi\\, ,</math>\n\nwhere <math>[\\gamma^{a},\\gamma^{b}]= \\gamma^a\\gamma^b - \\gamma^b\\gamma^a</math> is the commutator, <math>d</math> is [[exterior derivative]], <math>X^\\flat = g(X, -)</math> is the dual 1 form corresponding to <math>X</math> under the metric (i.e. with lowered indices) and <math> \\cdot </math> is Clifford multiplication.\nIt is worth noting that the spinor Lie derivative is independent of the metric, and hence also of the [[Connection (differential geometry)|connection]]. This is not obvious from the right-hand side of Kosmann's local expression, as the right-hand side seems to depend on the metric through the spin connection (covariant derivative), the dualisation of vector fields (lowering of the indices) and the Clifford multiplication on the [[spinor bundle]]. Such is not the case: the quantities on the right-hand side of Kosmann's local expression combine so as to make all metric and connection dependent terms cancel.\n\nTo gain a better understanding of the long-debated concept of Lie derivative of spinor fields one may refer to the original article,<ref>{{cite book |last=Fatibene |first=L. |last2=Ferraris |first2=M. |last3=Francaviglia |first3=M. |last4=Godina |first4=M. |year=1996 |chapter=A geometric definition of Lie derivative for Spinor Fields |title=Proceedings of the 6th International Conference on Differential Geometry and Applications, August 28th–September 1st 1995 (Brno, Czech Republic) |editor-last=Janyska |editor-first=J. |editor2-last=Kolář |editor2-first=I. |editor3-last=Slovák |editor3-first=J. |publisher=Masaryk University |location=Brno |pages=549–558 |isbn=80-210-1369-9 |arxiv=gr-qc/9608003v1 |bibcode=1996gr.qc.....8003F }}</ref><ref>{{cite journal |last=Godina |first=M. |last2=Matteucci |first2=P. |year=2003 |title=Reductive G-structures and Lie derivatives |journal=[[Journal of Geometry and Physics]] |volume=47 |issue= |pages=66–86 |doi=10.1016/S0393-0440(02)00174-2 |arxiv=math/0201235 |bibcode=2003JGP....47...66G }}</ref> where the definition of a Lie derivative of spinor fields is placed in the more general framework of the theory of Lie derivatives of sections of fiber bundles and the direct approach by Y. Kosmann to the spinor case is generalized to gauge natural bundles in the form of a new geometric concept called the [[Kosmann lift]].\n\n===Covariant Lie derivative===\nIf we have a principal bundle over the manifold M with G as the structure group, and we pick X to be a covariant vector field as section of the tangent space of the principal bundle (i.e. it has horizontal and vertical components), then the covariant Lie derivative is just the Lie derivative with respect to X over the principal bundle.\n\nNow, if we're given a vector field ''Y'' over ''M'' (but not the principal bundle) but we also have a [[Connection (mathematics)|connection]] over the principal bundle, we can define a vector field X over the principal bundle such that its horizontal component matches ''Y'' and its vertical component agrees with the connection. This is the covariant Lie derivative.\n\nSee [[connection form]] for more details.\n\n===Nijenhuis–Lie derivative===\n\nAnother generalization, due to [[Albert Nijenhuis]], allows one to define the Lie derivative of a differential form along any section of the bundle Ω<sup>''k''</sup>(''M'', T''M'') of differential forms with values in the tangent bundle. If ''K''&nbsp;∈&nbsp;Ω<sup>''k''</sup>(''M'', T''M'') and α is a differential ''p''-form, then it is possible to define the interior product ''i''<sub>''K''</sub>α of ''K'' and α. The Nijenhuis–Lie derivative is then the anticommutator of the interior product and the exterior derivative:\n:<math>\\mathcal{L}_K\\alpha=[d,i_K]\\alpha = di_K\\alpha-(-1)^{k-1}i_K \\, d\\alpha.</math>\n\n==History==\nIn 1931, [[Władysław Ślebodziński]] introduced a new differential operator, later called by [[David van Dantzig]] that of Lie derivation, which can be applied to scalars, vectors, tensors and affine connections and which proved to be a powerful instrument in the study of groups of automorphisms.\n\nThe Lie derivatives of general geometric objects (i.e., sections of [[natural bundle|natural fiber bundle]]s) were studied by [[Albert Nijenhuis|A. Nijenhuis]], Y. Tashiro and [[Kentaro Yano (mathematician)|K. Yano]].\n\nFor a quite long time, physicists had been using Lie derivatives, without reference to the work of mathematicians. In 1940, [[Léon Rosenfeld]]<ref>{{cite journal |last=Rosenfeld |first=L. |year=1940 |title=Sur le tenseur d’impulsion-énergie |journal=Mémoires Acad. Roy. d. Belg. |volume=18 |issue=6 |pages=1–30 }}</ref>—and before him (in 1921<ref>Pauli's book on relativity.</ref>) [[Wolfgang Pauli]]<ref>{{cite book |last=Pauli |first=W. |title=Theory of Relativity |edition=First |year=1981 |publisher=Dover |location=New York |origyear=1921 |isbn=978-0-486-64152-2 }} ''See section 23''</ref>—introduced what he called a ‘local variation’ <math>\\delta^{\\ast}A</math> of a geometric object <math>A\\,</math> induced by an infinitesimal transformation of coordinates generated by a vector field <math>X\\,</math>. One can easily prove that his <math>\\delta^{\\ast}A</math> is <math> - \\mathcal{L}_X(A)\\,</math>.\n\n==See also==\n* [[Covariant derivative]]\n* [[Connection (mathematics)]]\n* [[Frölicher–Nijenhuis bracket]]\n* [[Geodesic]]\n* [[Killing vector field|Killing field]]\n* [[Derivative of the exponential map]]\n\n==Notes==\n{{Reflist|30em}}\n\n==References==\n* {{cite book |first=Ralph |last=Abraham |authorlink=Ralph Abraham (mathematician) |first2=Jerrold E. |last2=Marsden |authorlink2=Jerrold E. Marsden |title=Foundations of Mechanics |year=1978 |publisher=Benjamin-Cummings |location=London |isbn=0-8053-0102-X }} ''See section 2.2''.\n* {{cite book |first=David |last=Bleecker |title=Gauge Theory and Variational Principles |year=1981 |location= |publisher=Addison-Wesley |isbn=0-201-10096-7 }} ''See Chapter 0''.\n* {{cite book |first=Jürgen |last=Jost |authorlink=Jürgen Jost |title=Riemannian Geometry and Geometric Analysis |year=2002 |publisher=Springer |location=Berlin |isbn=3-540-42627-2 }} ''See section 1.6''.\n* {{cite book |last=Kolář |first=I. |last2=Michor |first2=P. |last3=Slovák |first3=J. |title=Natural operations in differential geometry|url=http://www.emis.de/monographs/KSM/index.html|publisher=Springer-Verlag|year=1993}} Extensive discussion of Lie brackets, and the general theory of Lie derivatives.\n* {{cite book|authorlink=Serge Lang |last=Lang |first=S.|title=Differential and Riemannian manifolds|publisher=Springer-Verlag|year=1995|isbn=978-0-387-94338-1}} For generalizations to infinite dimensions.\n* {{cite book|authorlink=Serge Lang |last=Lang |first=S.|title=Fundamentals of Differential Geometry|publisher=Springer-Verlag|year=1999|isbn=978-0-387-98593-0}} For generalizations to infinite dimensions.\n* {{cite book|authorlink=Kentaro Yano (mathematician) |last=Yano |first=K. |title=The Theory of Lie Derivatives and its Applications\n|url=https://archive.org/details/theoryofliederiv029601mbp|publisher=North-Holland|year=1957|isbn=978-0-7204-2104-0}} Classical approach using coordinates.\n\n==External links==\n* {{springer|title=Lie derivative|id=p/l058560}}\n\n{{Tensors}}\n\n{{DEFAULTSORT:Lie Derivative}}\n[[Category:Differential geometry]]\n[[Category:Differential topology]]\n[[Category:Differential operators]]\n[[Category:Generalizations of the derivative]]"
    },
    {
      "title": "Malliavin derivative",
      "url": "https://en.wikipedia.org/wiki/Malliavin_derivative",
      "text": "{{Multiple issues|\n{{unreferenced|date=August 2009}}\n{{Expert-subject|Mathematics|date=February 2009}}\n}}\n\nIn [[mathematics]], the '''Malliavin derivative''' is a notion of [[derivative]] in the [[Malliavin calculus]]. Intuitively, it is the notion of derivative appropriate to paths in [[classical Wiener space]], which are \"usually\" not differentiable in the usual sense. {{Citation Needed|date=August 2011}}\n\n==Definition==\nLet <math>H</math> be the [[Cameron–Martin space]], and <math>C_{0}</math> denote [[classical Wiener space]]:\n\n:<math>H := \\{ f \\in W^{1,2} ([0, T]; \\mathbb{R}^{n}) \\;|\\; f(0) = 0 \\} := \\{ \\text{paths starting at 0 with first derivative in } L^{2} \\}</math>;\n\n:<math>C_{0} := C_{0} ([0, T]; \\mathbb{R}^{n}) := \\{ \\text{continuous  paths starting at 0} \\};</math>\n\nBy the [[Sobolev_inequality#Sobolev_embedding_theorem|Sobolev embedding theorem]], <math>H \\subset C_0</math>. Let\n:<math>i : H \\to C_{0}</math>\ndenote the [[inclusion map]].\n\nSuppose that <math>F : C_{0} \\to \\mathbb{R}</math> is [[Fréchet derivative|Fréchet differentiable]]. Then the [[Fréchet derivative]] is a map\n\n:<math>\\mathrm{D} F : C_{0} \\to \\mathrm{Lin} (C_{0}; \\mathbb{R});</math>\n\ni.e., for paths <math>\\sigma \\in C_{0}</math>, <math>\\mathrm{D} F (\\sigma)\\;</math> is an element of <math>C_{0}^{*}</math>, the [[dual space]] to <math>C_{0}\\;</math>. Denote by <math>\\mathrm{D}_{H} F(\\sigma)\\;</math> the [[continuous function|continuous]] [[linear map]] <math>H \\to \\mathbb{R}</math> defined by\n\n:<math>\\mathrm{D}_{H} F (\\sigma) := \\mathrm{D} F (\\sigma) \\circ i : H \\to \\mathbb{R}, </math>\n\nsometimes known as the [[H-derivative|''H''-derivative]]. Now define <math>\\nabla_{H} F : C_{0} \\to H</math> to be the [[adjoint]] of <math>\\mathrm{D}_{H} F\\;</math> in the sense that\n\n:<math>\\int_0^T \\left(\\partial_t \\nabla_H F(\\sigma)\\right) \\cdot \\partial_t h := \\langle \\nabla_{H} F (\\sigma), h \\rangle_{H} = \\left( \\mathrm{D}_{H} F \\right) (\\sigma) (h) = \\lim_{t \\to 0} \\frac{F (\\sigma + t i(h)) - F(\\sigma)}{t}.</math>\n\nThen the '''Malliavin derivative''' <math>\\mathrm{D}_{t}</math> is defined by\n\n:<math>\\left( \\mathrm{D}_{t} F \\right) (\\sigma) := \\frac{\\partial}{\\partial t} \\left( \\left( \\nabla_{H} F \\right) (\\sigma) \\right).</math>\n\nThe [[domain (mathematics)|domain]] of <math>\\mathrm{D}_{t}</math> is the set <math>\\mathbf{F}</math> of all Fréchet differentiable real-valued functions on <math>C_{0}\\;</math>; the [[codomain]] is <math>L^{2} ([0, T]; \\mathbb{R}^{n})</math>.\n\nThe '''Skorokhod integral''' <math>\\delta\\;</math> is defined to be the [[adjoint]] of the Malliavin derivative:\n\n:<math>\\delta := \\left( \\mathrm{D}_{t} \\right)^{*} : \\operatorname{image} \\left( \\mathrm{D}_{t} \\right) \\subseteq L^{2} ([0, T]; \\mathbb{R}^{n}) \\to \\mathbf{F}^{*} = \\mathrm{Lin} (\\mathbf{F}; \\mathbb{R}).</math>\n\n==See also==\n*[[H-derivative]]\n\n==References==\n{{reflist}}\n\n[[Category:Generalizations of the derivative]]\n[[Category:Stochastic calculus]]"
    },
    {
      "title": "P-derivation",
      "url": "https://en.wikipedia.org/wiki/P-derivation",
      "text": "{{DISPLAYTITLE:''p''-derivation}}\nIn [[mathematics]], more specifically [[differential algebra]], a '''''p''-derivation''' (for ''p'' a prime number) on a [[Ring (mathematics)|ring]] ''R'', is a mapping from ''R'' to ''R'' that satisfies certain conditions outlined directly below. The notion of a '''''p''-derivation''' is related to that of a [[Differential algebra|derivation]] in differential algebra. \n\n==Definition==\nLet ''p'' be a prime number. A '''''p''-derivation''' or Buium derivative on a ring <math> R </math> is a map of sets <math> \\delta:R\\to R </math> that satisfies the following \"[[product rule]]\":\n\n:<math> \\delta_p(ab) = \\delta_p (a)b^p + a^p\\delta_p (b) + p\\delta_p (a)\\delta_p (b) </math>\n\nand \"sum rule\":\n\n:<math> \\delta_p(a+b) = \\delta_p (a) + \\delta_p(b) + \\frac{a^p +b^p - (a+b)^p }{p} </math>.\n\nas well as \n\n:<math> \\delta_p(1) =0 </math>.\n\nNote that in the \"sum rule\" we are not really dividing by ''p'', since all the relevant [[binomial coefficients]] in the numerator are divisible by ''p'', so this definition applies in the case when <math> R </math> has ''p''-[[Torsion (algebra)|torsion]].\n\n==Relation to Frobenius Endomorphisms==\nA map <math> \\sigma: R\\to R </math> is a lift of the [[Frobenius endomorphism]] provided <math> \\sigma(x) = x^p \\mod pR </math>. An example such lift could come from the [[Artin map]].\n\nIf <math> (R,\\delta) </math> is a ring with a ''p''-derivation, then the map\n<math> \\sigma(x) := x^p + p\\delta(x) </math> defines a ring endomorphism which is a lift of the Frobenius endomorphism. When the ring ''R'' is ''p''-torsion free the correspondence is a bijection.\n\n==Examples==\n* For <math> R = \\mathbb Z </math> the unique ''p''-derivation is the map\n:<math> \\delta(x) = \\frac{x-x^p}{p}. </math>\nThe quotient is well-defined because of [[Fermat's Little Theorem]].\n* If ''R'' is any ''p''-torsion free ring  and <math>\\sigma:R \\to R</math> is a lift of the Frobenius endomorphism then \n:<math> \\delta(x) = \\frac{\\sigma(x)-x^p}{p} </math>\ndefines a ''p''-derivation.\n\n==See also==\n*[[Arithmetic derivative]]\n*[[Derivation (abstract algebra)|Derivation]]\n*[[Fermat quotient]]\n\n==References==\n* {{Citation|first=Alex|last=Buium|title=Arithmetic Differential Equations|year=1989|publisher=Springer-Verlag|isbn=0-8218-3862-8|series=Mathematical Surveys and Monographs}}.\n\n==External links==\n*[http://projecteuclid.org/DPubS?verb=Display&version=1.0&service=UI&handle=euclid.dmj/1077245037&page=record Project Euclid] \n\n[[Category:Differential algebra]]\n[[Category:Generalizations of the derivative]]"
    },
    {
      "title": "Pushforward (differential)",
      "url": "https://en.wikipedia.org/wiki/Pushforward_%28differential%29",
      "text": "{{Use American English|date = March 2019}}\n{{Short description|Linear approximation of smooth maps on tangent spaces}}\n{{About|pushforward operations in [[differential geometry]], which are associated with the '''differential''' of a [[smooth map]] between [[smooth manifold]]s|other uses of this term in [[mathematics]]|Pushforward (disambiguation){{!}}Pushforward}}\n[[File:pushforward.svg|thumb|upright=1.5|alt=\"If a map, φ, carries every point on manifold M to manifold N then the pushforward of φ carries vectors in the tangent space at every point in M to a tangent space at every point in N.\"|If a map, ''φ'', carries every point on manifold ''M'' to manifold ''N'' then the pushforward of ''φ'' carries vectors in the tangent space at every point in ''M'' to a tangent space at every point in ''N''.]]\n\nSuppose that {{nowrap|''φ'' : ''M'' → ''N''}} is a [[smooth map]] between [[smooth manifold]]s; then the '''differential''' of ''φ'' at a point ''x'' is, in some sense, the best [[linear approximation]] of ''φ'' near ''x''. It can be viewed as a generalization of the [[total derivative]] of ordinary calculus. Explicitly, it is a [[linear map]] from the [[tangent space]] of ''M'' at ''x'' to the tangent space of ''N'' at ''φ''(''x''). Hence it can be used to ''push'' tangent vectors on ''M'' ''forward'' to tangent vectors on ''N''.\n\nThe differential of a map ''φ'' is also called, by various authors, the '''derivative''' or '''total derivative''' of ''φ'', and is sometimes itself called the '''pushforward'''.\n\n== Motivation ==\nLet {{nowrap|''φ'' : ''U'' → ''V''}} be a [[Smooth function#Smooth functions between manifolds|smooth map]] from an [[Open subset#Euclidean space|open subset]] ''U'' of '''R'''<sup>''m''</sup> to an open subset ''V'' of '''R'''<sup>''n''</sup>. For any point ''x'' in ''U'', the [[Jacobian matrix and determinant|Jacobian]] of ''φ'' at ''x'' (with respect to the standard coordinates) is the [[matrix (mathematics)|matrix]] representation of the [[total derivative]] of ''φ'' at ''x'', which is a [[linear map]]\n:<math>d\\varphi_x:\\mathbf R^m\\to\\mathbf R^n\\ .</math>\n\nWe wish to generalize this to the case that ''φ'' is a smooth function between ''any'' [[Manifold#Differentiable manifolds|smooth manifolds]] ''M'' and ''N''.\n\n== The differential of a smooth map ==\nLet {{nowrap|''φ'' : ''M'' → ''N''}} be a smooth map of smooth manifolds. Given some {{nowrap|''x'' ∈ ''M''}}, the '''differential''' of ''φ'' at ''x'' is a linear map\n:<math>d\\varphi_x:T_xM\\to T_{\\varphi(x)}N\\,</math>\nfrom the [[tangent space]] of ''M'' at ''x'' to the tangent space of ''N'' at ''φ''(''x''). The application of ''dφ''<sub>''x''</sub> to a tangent vector ''X'' is sometimes called the '''pushforward''' of ''X'' by ''φ''. The exact definition of this pushforward depends on the definition one uses for tangent vectors (for the various definitions see [[tangent space]]).\n\nIf one defines tangent vectors as equivalence classes of curves through ''x'' then the differential is given by\n:<math>d\\varphi_x(\\gamma^\\prime(0)) = (\\varphi \\circ \\gamma)^\\prime(0).</math>\nHere ''γ'' is a curve in ''M'' with {{nowrap|1=''γ''(0) = ''x''}}. In other words, the pushforward of the tangent vector to the curve ''γ'' at 0 is just the tangent vector to the curve {{nowrap|''φ'' ∘ ''γ''}} at 0.\n\nAlternatively, if tangent vectors are defined as [[derivation (abstract algebra)|derivations]] acting on smooth real-valued functions, then the differential is given by\n:<math>d\\varphi_x(X)(f) = X(f \\circ \\varphi).</math>\nHere {{nowrap|''X'' ∈ ''T<sub>x</sub>M''}}, therefore ''X'' is a derivation defined on ''M'' and ''f'' is a smooth real-valued function on ''N''. By definition, the pushforward of ''X'' at a given ''x'' in ''M'' is in ''T''<sub>''φ''(''x'')</sub>''N'' and therefore itself is a derivation.\n\nAfter choosing [[manifold (mathematics)|charts]] around ''x'' and ''φ''(''x''), ''φ'' is locally determined by a smooth map\n\n:<math>\\widehat{\\varphi} : U \\to V</math>\n\nbetween open sets of '''R'''<sup>''m''</sup> and '''R'''<sup>''n''</sup>, and ''dφ''<sub>''x''</sub> has representation (at ''x'')\n\n:<math>d\\varphi_x\\left(\\frac{ \\partial }{\\partial u^a}\\right)  = \\frac{\\partial \\widehat{\\varphi}^b}{\\partial u^a} \\frac{ \\partial }{\\partial v^b},</math>\n\nin the [[Einstein summation notation]], where the partial derivatives are evaluated at the point in ''U'' corresponding to ''x'' in the given chart.\n\nExtending by linearity gives the following matrix\n\n:<math>(d\\varphi_x)_a^{\\;b}= \\frac{\\partial \\widehat{\\varphi}^b}{\\partial u^a}.</math>\n\nThus the differential is a linear transformation, between tangent spaces, associated to the smooth map ''φ'' at each point. Therefore, in some chosen local coordinates, it is represented by the [[Jacobian matrix]] of the corresponding smooth map from '''R'''<sup>''m''</sup> to '''R'''<sup>''n''</sup>. In general the differential need not be invertible. If ''φ'' is a [[local diffeomorphism]], then the pushforward at ''x'' is invertible and its inverse gives the [[pullback (differential geometry)|pullback]] of ''T''<sub>''φ''(''x'')</sub>''N''.\n\nThe differential is frequently expressed using a variety of other notations such as\n:<math>D\\varphi_x,\\; (\\varphi_*)_x, \\;\\varphi'(x),\\; T_x\\varphi.</math>\n\nIt follows from the definition that the differential of a [[function composition|composite]] is the composite of the differentials (i.e., [[functor]]ial behaviour). This is the ''chain rule'' for smooth maps.\n\nAlso, the differential of a [[local diffeomorphism]] is a [[linear isomorphism]] of tangent spaces.\n\n==The differential on the tangent bundle ==\nThe differential of a smooth map ''φ'' induces, in an obvious manner, a [[bundle map]] (in fact a [[vector bundle homomorphism]]) from the [[tangent bundle]] of ''M'' to the tangent bundle of ''N'', denoted by ''dφ'' or ''φ''<sub>∗</sub>, which fits into the following [[commutative diagram]]:\n[[Image:SmoothPushforward-01.svg|center]]\nwhere ''π''<sub>''M''</sub> and ''π''<sub>''N''</sub> denote the bundle projections of the tangent bundles of ''M'' and ''N'' respectively.\n\nEquivalently (see [[bundle map]]), {{nowrap|1=''φ''<sub>∗</sub> = ''dφ''}} is a bundle map from ''TM'' to the [[pullback bundle]] ''φ''<sup>∗</sup>''TN'' over ''M'', which may in turn be viewed as a [[section (fiber bundle)|section]] of the [[vector bundle]] {{nowrap|Hom(''TM'', ''φ''<sup>∗</sup>''TN'')}} over ''M''. The bundle map ''dφ'' is also denoted by ''Tφ'' and called the '''tangent map'''. In this way, ''T'' is a [[functor]].\n\n== Pushforward of vector fields ==\nGiven a smooth map {{nowrap|''φ'' : ''M'' → ''N''}} and a [[vector field]] ''X'' on ''M'', it is not usually possible to identify a pushforward of ''X'' by φ with some vector field ''Y'' on ''N''. For example, if the map ''φ'' is not surjective, there is no natural way to define such a pushforward outside of the image of ''φ''. Also, if ''φ'' is not injective there may be more than one choice of pushforward at a given point. Nevertheless, one can make this difficulty precise, using the notion of a vector field along a map.\n\nA [[vector bundle|section]] of ''φ''<sup>∗</sup>''TN'' over ''M'' is called a '''vector field along ''φ'''''. For example, if ''M'' is a submanifold of ''N'' and ''φ'' is the inclusion, then a vector field along ''φ'' is just a section of the tangent bundle of ''N'' along ''M''; in particular, a vector field on ''M'' defines such a section via the inclusion of ''TM'' inside ''TN''. This idea generalizes to arbitrary smooth maps.\n\nSuppose that ''X'' is a vector field on ''M'', i.e., a section of ''TM''. Then, applying the differential pointwise to ''X'' yields the '''pushforward''' ''φ''<sub>∗</sub>''X'', which is a vector field along ''φ'', i.e., a section of ''φ''<sup>∗</sup>''TN'' over ''M''.\n\nAny vector field ''Y'' on ''N'' defines a [[pullback bundle|pullback section]] ''φ''<sup>∗</sup>''Y'' of ''φ''<sup>∗</sup>''TN'' with {{nowrap|1=(''φ''<sup>∗</sup>''Y'')<sub>''x''</sub> = ''Y''<sub>''φ''(''x'')</sub>}}. A vector field ''X'' on ''M'' and a vector field ''Y'' on ''N'' are said to be '''''φ''-related''' if {{nowrap|1=''φ''<sub>∗</sub>''X'' = ''φ''<sup>∗</sup>''Y''}} as vector fields along ''φ''. In other words, for all ''x'' in ''M'', {{nowrap|1=''dφ''<sub>''x''</sub>(''X'') = ''Y''<sub>''φ''(''x'')</sub>}}.\n\nIn some situations, given a ''X'' vector field on ''M'', there is a unique vector field ''Y'' on ''N'' which is ''φ''-related to ''X''. This is true in particular when ''φ'' is a [[diffeomorphism]]. In this case, the pushforward defines a vector field ''Y'' on ''N'', given by\n:<math>Y_y=\\varphi_*(X_{\\varphi^{-1}(y)}).</math>\n\nA more general situation arises when ''φ'' is surjective (for example the [[fiber bundle|bundle projection]] of a fiber bundle). Then a vector field ''X'' on ''M'' is said to be '''projectable''' if for all ''y'' in ''N'', ''dφ''<sub>''x''</sub>(''X<sub>x</sub>'') is independent of the choice of ''x'' in ''φ''<sup>−1</sup>({''y''}). This is precisely the condition that guarantees that a pushforward of ''X'', as a vector field on ''N'', is well defined.\n\n==See also==\n*[[Pullback (differential geometry)|Pullback]]\n\n==References==\n*{{cite book |first=John M. |last=Lee |title=Introduction to Smooth Manifolds |year=2003 |series=Springer Graduate Texts in Mathematics |volume=218 }}\n*{{cite book |first=Jürgen |last=Jost |title=Riemannian Geometry and Geometric Analysis |year=2002 |publisher=Springer-Verlag |location=Berlin |isbn=3-540-42627-2 }} ''See section 1.6''.\n*{{cite book |authorlink=Ralph Abraham (mathematician) |first=Ralph |last=Abraham |first2=Jerrold E. |last2=Marsden |authorlink2=Jerrold E. Marsden |title=Foundations of Mechanics |year=1978 |publisher=Benjamin-Cummings |location=London |isbn=0-8053-0102-X }} ''See section 1.7 and 2.3''.\n\n[[Category:Generalizations of the derivative]]\n[[Category:Differential geometry]]\n[[Category:Smooth functions]]"
    },
    {
      "title": "Quasi-derivative",
      "url": "https://en.wikipedia.org/wiki/Quasi-derivative",
      "text": "In [[mathematics]], the '''quasi-derivative''' is one of several generalizations of the [[derivative]] of a [[function (mathematics)|function]] between two [[Banach space]]s.  The quasi-derivative is a slightly stronger version of the [[Gateaux derivative]], though weaker than the [[Fréchet derivative]].\n\nLet ''f'' : ''A'' &rarr; ''F'' be a [[continuous function]] from an [[open set]] ''A'' in a Banach space ''E'' to another Banach space ''F''.  Then the '''quasi-derivative''' of ''f'' at ''x''<sub>0</sub> &isin; ''A'' is a [[linear transformation]] ''u'' : ''E'' &rarr; ''F'' with the following property: for every continuous function ''g'' : [0,1] &rarr; ''A'' with ''g''(0)=''x''<sub>0</sub> such that ''g''&prime;(0) &isin; ''E'' exists,\n\n:<math>\\lim_{t\\to 0^+}\\frac{f(g(t))-f(x_0)}{t} = u(g'(0)).</math>\n\nIf such a linear map ''u'' exists, then ''f'' is said to be ''quasi-differentiable'' at ''x''<sub>0</sub>.\n\nContinuity of ''u'' need not be assumed, but it follows instead from the definition of the quasi-derivative.  If ''f'' is Fréchet differentiable at ''x''<sub>0</sub>, then by the [[chain rule]], ''f'' is also quasi-differentiable and its quasi-derivative is equal to its Fréchet derivative at ''x''<sub>0</sub>.  The converse is true provided ''E'' is finite-dimensional.  Finally, if ''f'' is quasi-differentiable, then it is Gateaux differentiable and its Gateaux derivative is equal to its quasi-derivative.\n\n==References==\n*{{cite book|author=Dieudonné, J|title=Foundations of modern analysis|publisher=Academic Press|year=1969}}\n\n[[Category:Banach spaces]]\n[[Category:Generalizations of the derivative]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Skew gradient",
      "url": "https://en.wikipedia.org/wiki/Skew_gradient",
      "text": "In [[mathematics]], a '''skew gradient''' of a [[harmonic function]] over a [[simply connected domain]] with two real dimensions is a [[vector field]] that is everywhere [[orthogonal]] to the [[gradient]] of the function and that has the same [[Magnitude (mathematics)|magnitude]] as the gradient.\n\n==Definition==\nThe skew gradient can be defined using complex analysis and the [[Cauchy–Riemann equations]].\n\nLet <math> f(z(x,y))=u(x,y)+iv(x,y) </math> be a complex-valued analytic function, where ''u'',''v'' are real-valued scalar functions of the real variables&nbsp;''x'',&nbsp;''y''.\n\nA skew gradient is defined as:\n\n: <math>\\nabla^\\perp u(x,y)=\\nabla v(x,y)</math>\n\nand from the [[Cauchy–Riemann equations]], it is derived that\n\n: <math>\\nabla^\\perp u(x,y)=(-\\frac{\\partial u}{\\partial y},\\frac{\\partial u}{\\partial x})</math>\n\n==Properties==\nThe skew gradient has two interesting properties. It is everywhere orthogonal to the gradient of u, and of the same length:\n\n: <math>\\nabla u(x,y) \\cdot \\nabla^\\perp u(x,y)=0 ,  \\rVert \\nabla u\\rVert =\\rVert \\nabla^\\perp u\\rVert</math>\n\n==References==\n\n{{Refbegin}}\n* [[Peter J. Olver|Peter Olver]], [http://www.math.umn.edu/~olver/pdn.html Introduction to Partial Differential Equations, ch. 7, p. 232] \n{{Refend}}\n\n[[Category:Differential calculus]]\n[[Category:Generalizations of the derivative]]\n[[Category:Linear operators in calculus]]\n[[Category:Vector calculus]]"
    },
    {
      "title": "Weak derivative",
      "url": "https://en.wikipedia.org/wiki/Weak_derivative",
      "text": "{{no footnotes|date=May 2014}}\n\nIn [[mathematics]], a '''weak derivative''' is a generalization of the concept of the [[derivative]] of a [[function (mathematics)|function]] (''strong derivative'') for functions not assumed [[Differentiable function|differentiable]], but only [[Integrable function|integrable]], i.e., to lie in the [[Lp space|L<sup>''p''</sup> space]] <math>L^1([a,b])</math>.  See [[distribution (mathematics)|distribution]]s for a more general definition.\n\n== Definition ==\n\nLet <math>u</math> be a function in the [[Lp space|Lebesgue space]] <math>L^1([a,b])</math>. We say that <math>v</math>   in <math>L^1([a,b])</math> is a ''weak derivative'' of <math>u</math> if,\n\n:<math>\\int_a^b u(t)\\varphi'(t)dt=-\\int_a^b v(t)\\varphi(t)dt</math>\n\nfor '''all''' infinitely [[differentiable function]]s <math> \\varphi </math> with <math>\\varphi(a)=\\varphi(b)=0</math>. This definition is motivated by the integration technique of [[Integration by parts]].\n\nGeneralizing to <math>n</math> dimensions, if <math>u</math> and <math>v</math> are in the space <math>L_{loc}^1(U)</math> of [[locally integrable function]]s for some [[open set]] <math>U \\subset \\mathbb{R}^n</math>, and if <math>\\alpha</math> is a [[multi-index]], we say that <math>v</math> is the <math>\\alpha^{th}</math>-weak derivative of <math>u</math> if\n\n:<math>\\int_U u D^{\\alpha} \\varphi=(-1)^{|\\alpha|} \\int_U v\\varphi,</math>\n\nfor all <math>\\varphi \\in C^{\\infty}_c (U)</math>, that is, for all infinitely differentiable functions <math>\\varphi</math> with [[compact support]] in <math>U</math>. Here <math> D^{\\alpha}\\varphi</math> is defined as\n\n:<math> \\qquad D^{\\alpha}\\varphi = \\frac{\\partial^{| \\alpha |} \\varphi }{\\partial x_{1}^{\\alpha_{1}} \\dots \\partial x_{n}^{\\alpha_{n}}}.</math>\n\nIf <math>u</math> has a weak derivative, it is often written <math>D^{\\alpha}u</math> since weak derivatives are unique (at least, up to a set of [[measure zero]], see below).\n\n== Examples ==\n*The [[absolute value]] function ''u''&nbsp;:&nbsp;[&minus;1,&nbsp;1]&nbsp;→&nbsp;[0,&nbsp;1], ''u''(''t'')&nbsp;=&nbsp;|''t''|, which is not differentiable at ''t''&nbsp;=&nbsp;0, has a weak derivative ''v'' known as the [[sign function]] given by\n\n:<math>v \\colon [-1,1]\\to [-1,1] ; \\quad t \\mapsto v(t) = \\begin{cases} 1, & \\mbox{if } t > 0; \\\\ 0, & \\mbox{if } t = 0; \\\\ -1, & \\mbox{if } t < 0. \\end{cases} </math>\n\n:This is not the only weak derivative for ''u'': any ''w'' that is equal to ''v'' [[almost everywhere]] is also a weak derivative for ''u''.  Usually, this is not a problem, since in the theory of [[Lp space|''L''<sup>''p''</sup> spaces]] and [[Sobolev space]]s, functions that are equal almost everywhere are identified.\n\n*The [[indicator function|characteristic function]] of the rational numbers <math> 1_{\\mathbb{Q}} </math> is nowhere differentiable yet has a weak derivative.  Since the [[Lebesgue measure]] of the rational numbers is zero,\n\n::<math> \\int 1_{\\mathbb{Q}}(t) \\varphi(t) dt = 0.</math>\n\n:Thus <math> v(t)=0 </math> is the weak derivative of <math> 1_{\\mathbb{Q}} </math>.  Note that this does agree with our intuition since when considered as a member of an Lp space, <math> 1_{\\mathbb{Q}} </math> is identified with the zero function.\n\n*The [[Cantor function]] ''c'' does not have a weak derivative, despite being differentiable almost everywhere. This is because any weak derivative of ''c'' would have to be equal almost everywhere to the classical derivative of ''c'', which is zero almost everywhere. But the zero function is not a weak derivative of ''c'', as can be seen by comparing against an appropriate test function <math>\\varphi</math>. More theoretically, ''c'' does not have a weak derivative because its [[distributional derivative]], namely the [[Cantor distribution]], is a [[singular measure]] and therefore cannot be represented by a function.\n\n== Properties ==\n\nIf two functions are weak derivatives of the same function, they are equal except on a set with [[Lebesgue measure]] zero, i.e., they are equal [[almost everywhere]].  If we consider [[equivalence classes]] of functions such that two functions are equivalent if they are equal almost everywhere, then the weak derivative is unique.\n\nAlso, if ''u'' is differentiable in the conventional sense then its weak derivative is identical (in the sense given above) to its conventional (strong) derivative.  Thus the weak derivative is a generalization of the strong one.  Furthermore, the classical rules for derivatives of sums and products of functions also hold for the weak derivative.\n\n== Extensions ==\n\nThis concept gives rise to the definition of [[weak solution]]s in [[Sobolev space]]s, which are useful for problems of [[differential equations]] and in [[functional analysis]].\n\n==See also==\n*[[Subderivative]]\n\n==References==\n* {{Cite book | author2-link=Neil Trudinger|first1=D.|last1=Gilbarg|first2=N.|last2=Trudinger| title=Elliptic partial differential equations of second order | year=2001 | publisher=Springer | location=Berlin  | isbn=3-540-41160-7 | page=149}}\n*{{Cite book | author=Evans, Lawrence C. | title=Partial differential equations | year=1998 | publisher=American Mathematical Society | location=Providence, R.I.  | isbn=0-8218-0772-2 | page=242}}\n* {{Cite book |author1=Knabner, Peter |author2=Angermann, Lutz | title=Numerical methods for elliptic and parabolic partial differential equations | year=2003 | publisher=Springer | location=New York  | isbn=0-387-95449-X | page=53}}\n\n[[Category:Generalized functions]]\n[[Category:Functional analysis]]\n[[Category:Generalizations of the derivative]]\n[[Category:Generalizations]]"
    },
    {
      "title": "Spatial gradient",
      "url": "https://en.wikipedia.org/wiki/Spatial_gradient",
      "text": "{{unreferenced|date=July 2016}}\nA '''spatial gradient''' is a [[gradient]] whose components are spatial [[partial derivatives|derivatives]], i.e., [[rate of change (mathematics)|rate of change]] of a given [[scalar (physics)|scalar]] [[physical quantity]] with respect to the [[position coordinate]]s. \nHomogeneous regions have spatial gradient [[vector norm]] equal to zero.\nWhen evaluated over altitude or depth, it is called '''vertical gradient'''.\n\nExamples:\n;Biology\n* [[diffusion|Concentration gradient]], the ratio of solute concentration between two adjoining regions\n* [[Potential gradient]], the difference in electric charge between two adjoining regions\n;Fluid dynamics and earth science\n*  [[Density gradient]]\n*  [[Pressure gradient]]\n*  [[Temperature gradient]]\n** [[Geothermal gradient]]\n** [[Sound speed gradient]]\n*  [[Wind gradient]]\n* [[Lapse rate]]\n\n==See also==\n*[[Time derivative]]\n*[[Material derivative]]\n\n[[Category:Spatial gradient| ]]"
    },
    {
      "title": "Density gradient",
      "url": "https://en.wikipedia.org/wiki/Density_gradient",
      "text": "'''Density gradient''' is a spatial variation in [[density]] over an area. The term is used in the [[natural sciences]] to describe varying density of [[matter]], but can apply to any [[quantity]] whose density can be [[measured]].<ref>{{cite web\n  | title = Non-Destructive Testing Resource Center - Glossary   | url = http://www.ndt-ed.org/GeneralResources/Glossary/letter/d.htm\n}}</ref>\n<ref>{{cite web\n  | title = Chicago Wilderness Journal, Volume 1 - Number 1 - November, 2003 | url = http://www.chicagowilderness.org/pubprod/cwjournal/docs/CWJournal1003.pdf\n}}</ref>\n\n==Aerodynamics==\nIn the study of [[supersonic]] flight, [[Schlieren photography]] observes the density gradient of air as it interacts with aircraft.\n<ref>{{cite web\n  | title = CFI-Shadowgraph/Schliren Photography for Aerodynamic Applications | url = http://pdf.aiaa.org/preview/1994/PV1994_2616.pdf\n}}</ref>\n\nAlso in the field of Computational Fluid Dynamics, Density gradient is used to observe the acoustic waves, shock waves or expansion waves in the flow field.\n\n==Water==\nA steep density gradient in a body of water can have the effect of trapping energy and preventing [[convection]], such a gradient is employed in [[solar pond]]s. In the case of salt water, sharp gradients can lead to [[Stratification (water)|stratification]] of different concentrations of [[salinity]]. This is called a [[Halocline]]. \n<ref>{{cite web\n  | title = Effects of sill processes and tidal forcing on exchange in eastern Long Island Sound | url = http://www.agu.org/pubs/crossref/1994/94JC00721.shtml\n}}</ref>\n\n==Biology==\nIn the life sciences, a special technique called density gradient separation is used for isolating and purifying cells, viruses and subcellular particles.<ref>{{cite web\n  | title = GE Healthcare Density Gradient Separation\n  | url = http://www6.amershambiosciences.com/aptrix/upp00919.nsf/Content/CellSep_EduC~dgs\n}}</ref> Variations of this include [[Isopycnic centrifugation]], [[Differential centrifugation]], and [[Sucrose gradient centrifugation]]. A blood donation technique called [[Pheresis]] involves density gradient separation.\n\n==Geophysics==\n\nThe understanding of what is at the centre of the earth, the [[earth core]], requires the framework of density gradients in which elements and compounds then interact. [[Fast breeder nuclear reactor]] at the core of the earth is one theory by reason of density gradient and supported and espoused by [http://www.pnas.org/cgi/content/abstract/93/2/646 J. Marvin Herndon] (7 & 8).\n\n==Urban Economics==\nIn the study of population, the density gradient can refer to the change in density in an urban area from the center to the periphery.\n<ref>{{cite web\n  | title = The Spatial Distribution of Population in 48 World Cities: Implications for Economies in Transition\n  | url = http://www.bus.wisc.edu/realestate/pdf/pdf/Complete%20Spatial%20Distribution%20of%20Population%20in%2050%20World%20Ci.pdf\n}}</ref>\n\n==References==\n<references/>\n\n*7. Herndon, J. Marvin (1994) Planetary and Protostellar Nuclear Fission: Implications for Planetary Change, Stellar Ignition and Dark Matter Proceedings: Mathematical and Physical Sciences, Vol. 445, No. 1924 (May 9, 1994), pp.&nbsp;453–461\n*8. Herndon, J. Marvin (1996) Substructure of the inner core of the Earth Vol. 93, Issue 2, 646-648, January 23, 1996, PNAS\n\n[[Category:Density]]\n[[Category:Spatial gradient]]"
    },
    {
      "title": "Flow velocity",
      "url": "https://en.wikipedia.org/wiki/Flow_velocity",
      "text": "In [[continuum mechanics]] the '''macroscopic velocity''',<ref>{{cite book |author1=Duderstadt, James J. |author2=Martin, William R. | title= Transport theory | editor=Wiley-Interscience Publications | location= New York| year= 1979 | ed= | ISBN=978-0471044925|chapter=Chapter 4:The derivation of continuum description from transport equations|page=218}}</ref><ref>{{cite book | author=Freidberg, Jeffrey P.|title=Plasma Physics and Fusion Energy|edition=1|editor=Cambridge University Press|location=Cambridge|year=2008| ISBN=978-0521733175|chapter=Chapter 10:A self-consistent two-fluid model|page=225}}</ref> also '''flow velocity''' in [[fluid dynamics]] or '''drift velocity''' in [[electromagnetism]], is a [[vector field]] used to mathematically describe the motion of a continuum. The length of the flow velocity vector is the '''flow speed''' and is a scalar.\nIt is also called '''velocity field'''; when evaluated along a [[line (geometry)|line]], it is called a '''velocity profile''' (as in, e.g., [[law of the wall]]).\n\n==Definition==\n\nThe flow velocity '''''u''''' of a fluid is a vector field\n\n:<math> \\mathbf{u}=\\mathbf{u}(\\mathbf{x},t),</math>\n\nwhich gives the [[velocity]] of an ''[[fluid parcel|element of fluid]]'' at a position <math>\\mathbf{x}\\,</math> and time <math> t.\\,</math>\n\nThe flow speed ''q'' is the length of the flow velocity vector<ref>{{cite book| first1=R. | last1=Courant | author1-link=Richard Courant | first2=K.O. | last2=Friedrichs | author2-link=Kurt Otto Friedrichs | edition=5th | origyear=unabridged republication of the original edition of 1948 | isbn=0387902325 | pages=24 | title=Supersonic Flow and Shock Waves | oclc=44071435 | publisher=Springer-Verlag New York Inc | year=1999 | series=Applied mathematical sciences}}</ref>\n\n:<math>q = || \\mathbf{u} ||</math>\n\nand is a scalar field.\n\n==Uses==\n\nThe flow velocity of a fluid effectively describes everything about the motion of a fluid.  Many physical properties of a fluid can be expressed mathematically in terms of the flow velocity.  Some common examples follow:\n\n===Steady flow===\n\n{{Main article|Steady flow}}\n\nThe flow of a fluid is said to be ''steady'' if <math> \\mathbf{u}</math> does not vary with time.  That is if\n\n:<math> \\frac{\\partial \\mathbf{u}}{\\partial t}=0.</math>\n\n===Incompressible flow===\n\n{{Main article|Incompressible flow}}\n\nIf a fluid is incompressible the [[divergence]] of <math>\\mathbf{u}</math> is zero:\n\n:<math> \\nabla\\cdot\\mathbf{u}=0.</math>\n\nThat is, if <math>\\mathbf{u}</math> is a [[solenoidal vector field]].\n\n===Irrotational flow===\n{{main article|Irrotational flow}}\n\nA flow is ''irrotational'' if the [[Curl (mathematics)|curl]] of <math>\\mathbf{u}</math> is zero:\n\n:<math> \\nabla\\times\\mathbf{u}=0. </math>\n\nThat is, if <math>\\mathbf{u}</math> is an [[irrotational vector field]].\n\nA flow in a [[simply-connected domain]] which is irrotational can be described as a [[potential flow]], through the use of a [[velocity potential]] <math>\\Phi,</math> with <math>\\mathbf{u}=\\nabla\\Phi.</math> If the flow is both irrotational and incompressible, the [[Laplacian]] of the velocity potential must be zero: <math>\\Delta\\Phi=0.</math>\n\n===Vorticity===\n\n{{Main article| Vorticity}}\n\nThe ''vorticity'', <math>\\omega</math>, of a flow can be defined in terms of its flow velocity by\n\n:<math> \\omega=\\nabla\\times\\mathbf{u}.</math>\n\nThus in irrotational flow the vorticity is zero.\n\n==The velocity potential==\n{{main article|Potential flow}}\nIf an irrotational flow occupies a [[simply-connected]] fluid region then there exists a [[scalar field]] <math> \\phi </math> such that\n\n:<math> \\mathbf{u}=\\nabla\\mathbf{\\phi}. </math>\n\nThe scalar field <math>\\phi</math> is called the [[velocity potential]] for the flow. (See [[Irrotational vector field]].)\n\n==See also==\n{{div col||colwidth=20em}}\n*[[Velocity gradient]]\n*[[Velocity potential]]\n*[[Drift velocity]]\n*[[Group velocity]]\n*[[Particle velocity]]\n*[[Vorticity]]\n*[[Enstrophy]] \n*[[Strain rate]] \n*[[Stream function]]\n*[[Pressure gradient]]\n{{Div col end}}\n\n==References==\n{{reflist}}\n\n[[Category:Fluid dynamics]]\n[[Category:Continuum mechanics]]\n[[Category:Vector calculus]]\n[[Category:Velocity]]\n[[Category:Spatial gradient]]"
    },
    {
      "title": "Geothermal gradient",
      "url": "https://en.wikipedia.org/wiki/Geothermal_gradient",
      "text": "{{redirects here|Geothermal}}\n[[Image:Temperature schematic of inner Earth.jpg|thumb|275px|right|Temperature profile of the inner Earth, schematic view ([[Estimation|estimated]]). ]]\n\n'''Geothermal gradient''' is the rate of increasing temperature with respect to increasing depth in the [[Earth]]'s interior. Away from tectonic plate boundaries, it is about 25–30&nbsp;°C/km (72-87&nbsp;°F/mi)  of depth near the surface in most of the world.<ref name=\"IPCC\" /> Strictly speaking, ''geo''-thermal necessarily refers to the Earth but the concept may be applied to other planets.\n\nThe [[Earth's internal heat budget|Earth's internal heat]] comes from a combination of residual heat from [[planetary accretion]], heat produced through [[radioactive decay]], latent heat from core crystallization, and possibly heat from other sources. The major heat-producing isotopes in the Earth are [[Potassium|potassium-40]], [[Uranium|uranium-238]], [[uranium-235]], and [[Thorium|thorium-232]].<ref>{{cite news\n | first=Robert | last=Sanders\n | title=Radioactive potassium may be major heat source in Earth's core | publisher=UC Berkeley News | date=2003-12-10 | url=http://www.berkeley.edu/news/media/releases/2003/12/10_heat.shtml\n | accessdate=2007-02-28 }}</ref> At the center of the planet, the temperature may be up to 7,000&nbsp;K and the pressure could reach 360&nbsp;[[GPa]] (3.6 million atm).<ref>{{cite journal\n |author1=Alfè, D. |author2=Gillan, M. J. |author3=Vocadlo, L. |author4=Brodholt, J. |author5=Price, G. D. | title=The ''ab initio'' simulation of the Earth's core\n | journal= Philosophical Transactions of the Royal Society\n | date=2002 | volume=360 | issue=1795 | pages=1227–44 | url=http://chianti.geol.ucl.ac.uk/~dario/pubblicazioni/PTRSA2002.pdf\n | format=PDF | accessdate=2007-02-28 | doi=10.1098/rsta.2002.0992|bibcode = 2002RSPTA.360.1227A }}</ref> Because much of the heat is provided by radioactive decay, scientists believe that early in Earth history, before isotopes with short [[Half-life|half-lives]] had been depleted, Earth's heat production would have been much higher. Heat production was twice that of present-day at approximately 3&nbsp;billion&nbsp;years ago,<ref name= \"turcotte\" /> resulting in larger temperature gradients within the Earth, larger rates of [[mantle convection]] and [[plate tectonics]], allowing the production of igneous rocks such as [[komatiites]] that are no longer formed.<ref>{{cite journal\n | last=Vlaar | first=N | title=Cooling of the earth in the Archaean: Consequences of pressure-release melting in a hotter mantle | date=1994 |journal=Earth and Planetary Science Letters\n | volume=121\n | issue=1–2 | doi=10.1016/0012-821X(94)90028-0\n | page=1\n | last2=Vankeken\n | first2=P\n | last3=Vandenberg\n | first3=A | bibcode=1994E&PSL.121....1V}}</ref>\n\n== Heat sources ==\n[[Image:Earth-crust-cutaway-english.svg|thumb|275px|right|Earth cutaway from core to exosphere]]\n[[File:Geothermaldrilling.jpg|275px|thumb|Geothermal drill machine in Wisconsin, USA]]\nTemperature within the Earth increases with depth. Highly viscous or partially molten rock at temperatures between {{convert|650|to|1200|C|F|sigfig=2}}  are found at the margins of tectonic plates, increasing the geothermal gradient in the vicinity, but only the outer core is postulated to exist in a molten or fluid state, and the temperature at the Earth's inner core/outer core boundary, around {{convert|3500|km|mi}} deep, is estimated to be 5650 ± 600 K[[kelvin|elvin]].<ref name='Alfe2003'>{{cite journal |title=Thermodynamics from first principles: temperature and composition of the Earth's core |url=http://www.es.ucl.ac.uk/people/d-price/papers/153.pdf |format=PDF |accessdate=2007-03-01 |date=2003-02-01 |first=D. |last=Alfe |author2=M. J. Gillan |author3=G. D. Price |volume=67 |issue=1 |pages=113–123 |doi=10.1180/0026461026610089 |journal=Mineralogical Magazine |deadurl=yes |archiveurl=https://web.archive.org/web/20070316082958/http://www.es.ucl.ac.uk/people/d-price/papers/153.pdf |archivedate=2007-03-16 |df= |bibcode=2003MinM...67..113A }}</ref><ref name='Gerd2001'>{{cite news | first=Gerd | last=Steinle-Neumann |author2=Lars Stixrude |author3=Ronald Cohen  | title=New Understanding of Earth’s Inner Core | date=2001-09-05 | publisher=[[Carnegie Institution of Washington]] | url =http://www.carnegieinstitution.org/news_010905.html | work = | pages = | accessdate = 2007-03-01 | language = |archiveurl = https://web.archive.org/web/20061214151031/http://www.carnegieinstitution.org/news_010905.html |archivedate = 2006-12-14}}</ref> The heat content of the Earth is [[1 E31 J|10<sup>31</sup> joules]].<ref name=\"IPCC\">{{cite journal| first1=Ingvar B. | last1=Fridleifsson, | first2=Ruggero | last2=Bertani | first3=Ernst | last3=Huenges | first4=John W. | last4=Lund | first5=Arni | last5=Ragnarsson | first6=Ladislaus | last6=Rybach | date=2008-02-11 | title=The possible role and contribution of geothermal energy to the mitigation of climate change | conference =IPCC Scoping Meeting on Renewable Energy Sources | editor = O. Hohmeyer and T. Trittin | location = Luebeck, Germany | pages = 59–80 | url = http://www.ipcc.ch/pdf/supporting-material/proc-renewables-lubeck.pdf | format = pdf | accessdate = 2013-11-03}}</ref>\n* Much of the heat is created by [[radioactive decay|decay]] of naturally radioactive elements. An estimated 45 to 90 percent of the heat escaping from the Earth originates from radioactive decay of elements mainly located in the mantle.<ref name=\"turcotte\">{{cite book\n | last=Turcotte | first=DL |author2=Schubert, G\n | title=Geodynamics | publisher=Cambridge University Press\n | location=Cambridge, England, UK| date=2002 | edition=2nd\n | pages=136–7 | chapter=4 | isbn=978-0-521-66624-4 }}</ref><ref name='Anuta2006'>{{cite news | first=Joe | last=Anuta | title=Probing Question: What heats the earth's core? | date=2006-03-30 | publisher=physorg.com | url=http://www.physorg.com/news62952904.html | accessdate = 2007-09-19 }}</ref><ref name=physicsworld>{{cite web|last=Johnston|first=Hamish|title=Radioactive decay accounts for half of Earth's heat|url=http://physicsworld.com/cws/article/news/2011/jul/19/radioactive-decay-accounts-for-half-of-earths-heat|work=PhysicsWorld.com|publisher=Institute of Physics|accessdate=18 June 2013|date=19 July 2011}}</ref> \n* Gravitational potential energy released during the [[Accretion (astrophysics)|accretion]] of the Earth.\n* Heat released during [[Planetary differentiation|differentiation]], as abundant [[heavy metals]] ([[iron]], [[nickel]], [[copper]]) descended to the Earth's core.\n* Latent heat released as the liquid [[outer core]] [[crystallization|crystallizes]] at the [[inner core]] boundary. \n* Heat may be generated by [[tidal force]]<nowiki/>s on the Earth as it rotates. The resulting [[earth tide|earth tid]]<nowiki/>[[earth tide|e]]<nowiki/>s dissipate energy in Earth's interior as heat.\n* There is no reputable science to suggest that any significant heat may be created by the [[Earth's magnetic field]], as suggested by some contemporary folk theories.\n[[File:Evolution of Earth's radiogenic heat.svg|thumb|275px|The [[radiogenic heat]] from the decay of <sup>238</sup>U and <sup>232</sup>Th are now the major contributors to the [[earth's internal heat budget]].]]\n\nIn Earth's continental crust, the decay of natural radioactive isotopes makes a significant contribution to geothermal heat production. The continental crust is abundant in lower density minerals but also contains significant concentrations of heavier [[Goldschmidt classification#Lithophile elements|lithophilic]] minerals such as uranium. Because of this, it holds the most concentrated global reservoir of radioactive elements found in the Earth.<ref name=\"Geothermal\">William, G. E. (2010). ''Geothermal Energy: Renewable Energy and the Environment'' (pp. 1-176). Boca Raton, FL: CRC Press.</ref> Especially in layers closer to Earth's surface, naturally occurring isotopes are enriched in the granite and basaltic rocks.<ref>Wengenmayr, R., & Buhrke, T. (Eds.). (2008). ''Renewable Energy: Sustainable Energy Concepts for the future'' (pp. 54-60). Weinheim, Germany: WILEY-VCH Verlag GmbH & Co. KGaA.</ref> These high levels of radioactive elements are largely excluded from the Earth's mantle due to their inability to substitute in mantle minerals and consequent enrichment in melts during mantle melting processes. The mantle is mostly made up of high density minerals with higher concentrations of elements that have relatively small atomic radii such as magnesium (Mg), titanium (Ti), and calcium (Ca).<ref name=\"Geothermal\" />\n\n{| class=\"wikitable\" border=\"1\" style=\"text-align: center;\"\n|+ Present-day major heat-producing isotopes<ref name=\"T&S 137\">{{cite book|last=Turcotte|first=D. L.|author2=Schubert, G.|title=Geodynamics|publisher=Cambridge University Press|location=Cambridge, England, UK|date=2002|edition=2nd|page=137|chapter=4|isbn=978-0-521-66624-4}}</ref>\n|-\n! Isotope\n! Heat release\n[W/kg isotope]\n! Half-life\n[years]\n! Mean mantle concentration\n[kg isotope/kg mantle]\n! Heat release\n[W/kg mantle]\n|-\n| <sup>238</sup>U\n| {{nowrap|9.46 × 10<sup>−5</sup>}}\n| {{nowrap|4.47 × 10<sup>9</sup>}}\n| {{nowrap|30.8 × 10<sup>−9</sup>}}\n| {{nowrap|2.91 × 10<sup>−12</sup>}}\n|-\n| <sup>235</sup>U\n| {{nowrap|5.69 × 10<sup>−4</sup>}}\n| {{nowrap|7.04 × 10<sup>8</sup>}}\n| {{nowrap|0.22 × 10<sup>−9</sup>}}\n| {{nowrap|1.25 × 10<sup>−13</sup>}}\n|-\n| <sup>232</sup>Th\n| {{nowrap|2.64 × 10<sup>−5</sup>}}\n| {{nowrap|1.40 × 10<sup>10</sup>}}\n| {{nowrap|124 × 10<sup>−9</sup>}}\n| {{nowrap|3.27 × 10<sup>−12</sup>}}\n|-\n| <sup>40</sup>K\n| {{nowrap|2.92 × 10<sup>−5</sup>}}\n| {{nowrap|1.25 × 10<sup>9</sup>}}\n| {{nowrap|36.9 × 10<sup>−9</sup>}}\n| {{nowrap|1.08 × 10<sup>−12</sup>}}\n|}\n\nThe geothermal gradient is steeper in the lithosphere than in the mantle because the mantle transports heat primarily by convection, leading to a geothermal gradient that is determined by the mantle adiabat, rather than by the conductive heat transfer processes that predominate in the lithosphere, which acts as a [[Thermal boundary layer thickness and shape|thermal boundary layer]] of the convecting mantle.{{Citation needed|sate=August 2018|date=August 2018}}\n\n==Heat flow ==\n\n{{main|Earth's internal heat budget}}\n\nHeat flows constantly from its sources within the Earth to the surface. Total heat loss from the Earth is estimated at 44.2 TW ({{nowrap|4.42 × 10<sup>13</sup> Watts}}).<ref name=Pollack>[http://anquetil.colorado.edu/EPP3/readings/Pollack_etal_1993_Rev_Geophys.pdf Pollack, Henry N., et.al.,''Heat flow from the Earth's interior: Analysis of the global data set,'' Reviews of Geophysics, 31, 3 / August 1993, p. 273 ] {{webarchive|url=https://web.archive.org/web/20110811133919/http://anquetil.colorado.edu/EPP3/readings/Pollack_etal_1993_Rev_Geophys.pdf |date=2011-08-11 }} {{doi|10.1029/93RG01249}}</ref> Mean heat flow is 65&nbsp;mW/m<sup>2</sup> over [[continental crust]] and 101&nbsp;mW/m<sup>2</sup> over [[oceanic crust]].<ref name=Pollack/> This is 0.087 watt/square meter on average (0.03 percent of solar power absorbed by the Earth<ref>{{cite web|title=Climate and Earth’s Energy Budget|url=http://earthobservatory.nasa.gov/Features/EnergyBalance/page1.php|publisher=NASA}}</ref> ), but is much more concentrated in areas where the lithosphere is thin, such as along [[mid-ocean ridge]]s (where new oceanic lithosphere is created) and near [[mantle plume]]s.<ref>{{cite journal|author1=Richards, M. A.|author2=Duncan, R. A.|author3=Courtillot, V. E.|date=1989|title=Flood Basalts and Hot-Spot Tracks: Plume Heads and Tails|journal=Science|volume=246|issue=4926|pages=103–107|bibcode=1989Sci...246..103R|doi=10.1126/science.246.4926.103|pmid=17837768}}<!--| accessdate=2007-04-21--></ref>\nThe [[Earth's crust]] effectively acts as a thick insulating blanket which must be pierced by fluid conduits (of magma, water or other) in order to release the heat underneath. More of the heat in the Earth is lost through plate tectonics, by mantle upwelling associated with mid-ocean ridges. The final major mode of heat loss is by [[Heat conduction|conduction]] through the [[lithosphere]], the majority of which occurs in the oceans due to the crust there being much thinner and younger than under the continents.<ref name=Pollack/><ref name=\"heat loss\">{{cite journal\n | doi=10.1029/JB086iB12p11535 | title=Oceans and Continents: Similarities and Differences in the Mechanisms of Heat Loss\n | date=1981 | last=Sclater | first=John G\n | journal=Journal of Geophysical Research | volume=86\n | issue=B12 |pages=11535\n | last2=Parsons\n | first2=Barry\n | last3=Jaupart\n | first3=Claude | bibcode=1981JGR....8611535S\n}}</ref>\n\nThe heat of the Earth is replenished by radioactive decay at a rate of 30 TW.<ref name=\"sustainability\">{{Cite news | last = Rybach | first = Ladislaus | date =September 2007 | title =Geothermal Sustainability | periodical =Geo-Heat Centre Quarterly Bulletin | publication-place =Klamath Falls, Oregon | publisher =Oregon Institute of Technology | volume =28 | issue =3 | pages = 2–7 | url =http://www.oit.edu/docs/default-source/geoheat-center-documents/quarterly-bulletin/vol-28/28-3/28-3-art2.pdf | issn =0276-1084 | accessdate =2018-03-07}}</ref> The global geothermal flow rates are more than twice the rate of human energy consumption from all primary sources.\n\n== Direct application ==\nHeat from Earth's interior can be used as an energy source, known as [[geothermal energy]]. The geothermal gradient has been used for space heating and bathing since ancient Roman times, and more recently for generating electricity. As the human population continues to grow, so does energy use and the correlating environmental impacts that are consistent with global primary sources of energy. This has caused a growing interest in finding sources of energy that are renewable and have reduced greenhouse gas emissions. In areas of high geothermal energy density, current technology allows for the generation of electrical power because of the corresponding high temperatures. Generating electrical power from geothermal resources requires no fuel while providing true baseload energy at a reliability rate that constantly exceeds 90%.<ref name=\"Geothermal\" /> In order to extract geothermal energy, it is necessary to efficiently transfer heat from a geothermal reservoir to a power plant, where electrical energy is converted from heat by passing steam through a [[turbine]] connected to a generator.<ref name=\"Geothermal\" /> On a worldwide scale, the heat stored in Earth's interior provides an energy that is still seen as an exotic source. About 10 GW of [[geothermal electric]] capacity is installed around the world as of 2007, generating 0.3% of global electricity demand. An additional 28 GW of direct [[geothermal heating]] capacity is installed for district heating, space heating, spas, industrial processes, desalination and agricultural applications.<ref name=\"IPCC\" />\n\n== Variations ==\nThe geothermal gradient varies with location and is typically measured by determining the bottom open-hole [[temperature]] after borehole drilling. To achieve accuracy the drilling fluid needs time to reach the [[ambient temperature]]. This is not always achievable for practical reasons.\n\nIn stable [[tectonic]] areas in the [[tropics]] a temperature-[[:wikt:depth|depth]] plot will converge to the annual average surface temperature. However, in areas where deep [[permafrost]] developed during the [[Pleistocene]] a low temperature anomaly can be observed that persists down to several hundred metres.<ref>[http://www.pgi.gov.pl/pgi_en/index.php?option=news&task=viewarticle&sid=107 The Frozen Time, from the Polish Geological Institute] {{webarchive|url=https://web.archive.org/web/20101027200436/http://www.pgi.gov.pl/pgi_en/index.php?option=news&task=viewarticle&sid=107 |date=2010-10-27 }}</ref> The [[Suwałki]] cold anomaly in [[Poland]] has led to the recognition that similar thermal disturbances related to Pleistocene-[[Holocene]] [[climatic]] changes are recorded in boreholes throughout Poland, as well as in [[Alaska]], [[northern Canada]], and [[Siberia]].\n[[Image:300px-Geothermgradients.png|right|thumb|500px]]\n\nIn areas of Holocene [[Tectonic uplift|uplift]] and [[erosion]] (Fig. 1) the shallow gradient will be high until it reaches an inflection point where it reaches the stabilized heat-flow regime. If the gradient of the stabilized regime is projected above the inflection point to its intersect with present-day annual average temperature, the height of this intersect above present-day surface level gives a measure of the extent of Holocene uplift and erosion. In areas of Holocene [[subsidence]] and [[Deposition (sediment)|deposition]] (Fig. 2) the initial gradient will be lower than the average until it reaches an inflection point where it joins the stabilized heat-flow regime.\n\nA long time before anything was known about the floors of the oceans a certain notable from the University of Sydney had been reporting a thermal gradient of about 30&nbsp;°C per vertical mile in the mines<ref>K. E. Bullen (University of Sydney) in D. R. Bates ''The Earth and Its Atmosphere'' (1957) New York: Basic Books, page 46.</ref> (ca 0.01864 Kelvin per meter) and an estimate of the underworld combining such a gradient with the Stephens measurement on Basalt<ref>Basalt in ''List of Thermal conductivities'' here in Wikipedia.</ref> would find a rate of about (1.7 ⋅ 0.01864) 0.03 watts per square meter instead of the 0.06 W ⋅ m<sup>−2</sup> like the one found in a 1971 Encyclopedia.<ref>Mitton, Simon, ''Editor-in Chief'', Cambridge Encyclopædia of Astronomy (1977) New York: Crown Publishers Inc. 1978, page 174.</ref>  Before then it was actually measured like that three times over from a drilled hole at the Oak Ridge National Laboratory in Tennessee and it was 1963 when they reported it as 0.73±0.04/μcal/cm<sup>−2</sup> sec.<ref>Diment, W.H., and Robertson, E.C., ''Temperature, thermal conductivity, and heat flow in a drilled hole near Oak Ridge, Tennessee'' Journal of Geophysical Research '''68''' (17), September 1, 1963 pages 5035 — 5047 and at least the abstract is free at  https://agupubs.onlinelibrary.wiley.com/doi/10.1029/JZ068i017p05035 retrieved January 27, 2019 at 8:30AM EST.</ref> That is 0.0305 ± 0.0017 W/m<sup>2</sup>.  Now more recently most any unauthorized person may notice that the ice on top of Lake Vostok would have to have a very high thermal conductivity (for ice) to be conducting heat at the estimated planetary average of 0.06 watts per meter<sup>2</sup> (1971 Encyclopedia) or 0.087 W ⋅ m<sup>2</sup> (this article) through any temperature gradient that could be reconciled with the Wiki articles on Lake Vostok and Vostok Station where we find that the ice is about three and a half or four kilometers thick and the temperatures on the top where the station is have been getting around from about -31.9&nbsp;°C to about -68&nbsp;°C and the heat does not seem to be up to standard at that location either.<ref>Wikipedia, ''Lake Vostok'', ''Vostok Station'' and ''Ice'' in Analytical List of Thermal Conductivities in  ''List of Thermal Conductivities.''</ref>\n\nThe more recent estimates would more nearly fit a 1980 study of about 500 American wells showing most typical values of less than 30&nbsp;°C/km and also commonplace values substantially higher than that throughout much of the country [Kron and Heiken 1980].  One extreme location in Oregon was found with a gradient as high as 145&nbsp;°C/km, ± 20%, some other very high values were found in various places both in Oregon and Idaho [the map with much extrapolation between the dots was published by Andrea Kron and Grant Heiken of the U of CA Los Alamos Scientific Laboratory in 1980 and right now it is on line for free from the digital library of the University of North Texas],<ref>https://digital.library.unt.edu/ark:/67531/metadc100962/m1/2/zoom/?resolution=6&lat=4267.312494870114&lon=11206.080463525464 retrieved February 8, 2019 at 2:19 AM EST.</ref> some geothermal power levels could be extrapolated, and for short term purposes and for power plants a continental power level of whatever hundredths of a watt per square meter would seem to be entirely incidental since there is hot rock down in there.  Some large part of its accumulated thermal energy came from the rock itself, which has power levels of about 3.22 ⋅ 10<sup>−13</sup> Watts/gram (whole continental), or about 6.7 ⋅ 10<sup>−13</sup> W/gm (upper continental), but the much smaller amount of radioactivity in the floors of the oceans would be fine pickings by comparison (Peridotite, 3.35 ⋅ 10<sup>−15</sup>, Dunite, 1.25 ⋅ 10<sup>−16</sup>, Eclogite, 4.6 ⋅ 10<sup>−14</sup> W/gm) and the geothermal power of oceanic regions and the migration of continents could not have come from that cause [Taylor and McLennan(1985) in Robertson p.&nbsp;97].<ref name=\"Robertson\">Robertson, Eugene C., ''Thermal Properties of Rocks, '', United States Department of the Interior Geological Survey, Open-File Report 88-441, 1988 at https://pubs.usgs.gov/of/1988/0441/report.pdf  Retrieved January 24, 2019 at 12:08 AM EST.</ref>\n\nA variation in surface temperature induced by [[climate change]]s and the [[Milankovitch cycle]] can penetrate below the Earth's surface and produce an oscillation in the geothermal gradient with periods varying from daily to tens of thousands of years and an amplitude which decreases with depth and having a scale depth of several kilometers.<ref name=\"Stacey\">{{cite book|last=Stacey|first=Frank D.|title=Physics of the Earth|edition=2nd|date=1977|publisher=John Wiley & Sons|location=New York|isbn=0-471-81956-5}} pp. 183-4</ref><ref name=\"Sleep\">{{cite book|last=Sleep|first=Norman H.|author2=Kazuya Fujita|title=Principles of Geophysics|date=1997|publisher=Blackwell Science|isbn=0-86542-076-9}} pp. 187-9</ref> Melt water from the [[polar ice caps]] flowing along ocean bottoms tends to maintain a constant geothermal gradient throughout the Earth's surface.<ref name=\"Stacey\"/>\n\nIf the rate of temperature increase with depth observed in shallow boreholes were to persist at greater depths, temperatures deep within the Earth would soon reach the point where rocks would melt. We know, however, that the Earth's [[Mantle (geology)|mantle]] is solid because of the transmission of [[S-waves]]. The temperature gradient dramatically decreases with depth for two reasons. First, the mechanism of thermal transport changes from [[Heat conduction|conduction]], as within the rigid tectonic plates, to [[convection]], in the portion of [[Earth's mantle]] that convects. Despite its [[solid]]ity, most of the Earth's mantle behaves over long time-scales as a [[fluid]], and heat is transported by [[advection]], or material transport. Second, [[Decay heat|radioactive heat]] production is concentrated within the crust of the Earth, and particularly within the upper part of the crust, as concentrations of [[uranium]], [[thorium]], and [[potassium]] are highest there: these three elements are the main producers of radioactive heat within the Earth. Thus, the geothermal gradient within the bulk of Earth's mantle is of the order of 0.5 kelvin per kilometer, and is determined by the [[adiabatic]] gradient associated with mantle material ([[peridotite]] in the upper mantle).<ref name=\"T&S 187\">{{cite book|last=Turcotte|first=D. L.|author2=Schubert, G.|title=Geodynamics|publisher=Cambridge University Press|location=Cambridge, England, UK|date=2002|edition=2nd|page=187|chapter=4|isbn=978-0-521-66624-4}}</ref>\n\n== See also ==\n{{Portal|Sustainable development}}\n* [[Temperature gradient]]\n* [[Earth's internal heat budget]]\n* [[Geothermal power]]\n* [[Hydrothermal circulation]]\n* [[TauTona Mine]] The world's deepest mining operation at 3.9&nbsp;km (2.4&nbsp;mi), where the rock face temperature reaches 60&nbsp;°C (140&nbsp;°F).\n\n==References==\n{{Reflist|2}}\n{{Refbegin}}\n{{cite web | title=Geothermal Resources | work=DOE/EIA-0603(95) Background Information and 1990 Baseline Data Initially Published in the Renewable Energy Annual 1995 | url=http://www.eia.doe.gov/cneaf/solar.renewables/renewable.energy.annual/backgrnd/chap9b.htm | accessdate=May 4, 2005 }}\n{{Refend}}\n\n{{Magmatic processes}}\n{{Geology}}\n{{Geophysics navbox}}\n{{Geothermal power}}\n\n{{DEFAULTSORT:Geothermal Gradient}}\n[[Category:Geological processes]]\n[[Category:Geodynamics]]\n[[Category:Structure of the Earth]]\n[[Category:Geothermal energy]]\n[[Category:Spatial gradient]]"
    },
    {
      "title": "Lapse rate",
      "url": "https://en.wikipedia.org/wiki/Lapse_rate",
      "text": "The '''lapse rate''' is the rate at which an atmospheric variable, normally [[temperature]] in [[Earth's atmosphere]], changes with [[altitude]].<ref>{{cite book |first=Mark Zachary |last=Jacobson |title=Fundamentals of Atmospheric Modeling |publisher=[[Cambridge University Press]] |edition=2nd |year=2005 |isbn=978-0-521-83970-9}}</ref><ref>{{cite book |first=C. Donald |last=Ahrens |title=Meteorology Today |publisher=Brooks/Cole Publishing |edition=8th |year=2006 |isbn=978-0-495-01162-0}}</ref> ''Lapse rate'' arises from the word ''lapse'', in the sense of a gradual change.\nIt corresponds to the vertical component of the [[spatial gradient]] of [[temperature gradient|temperature]].\nAlthough this concept is most often applied to the Earth's [[troposphere]], it can be extended to any gravitationally supported [[fluid parcel|parcel of gas]].\n\n== Definition ==\nA formal definition from the ''Glossary of Meteorology''<ref name=\"Glossary of Meteorology\">{{cite book|author=Todd S. Glickman|title=Glossary of Meteorology|edition=2nd|publisher=[[American Meteorological Society]], [[Boston]]|date=June 2000|isbn=978-1-878220-34-9}} [http://www.ametsoc.org/pubs/glossary_index.html (Glossary of Meteorology)]</ref> is:\n:The decrease of an atmospheric variable with height, the variable being temperature unless otherwise specified.\n\nIn general, a lapse rate is the negative of the rate of temperature change with altitude change, thus:\n\n:<math>\\Gamma = -\\frac{\\mathrm{d}T}{\\mathrm{d}z}</math>\n\nwhere <math>\\Gamma</math> (sometimes <math>L</math>) is the lapse rate given in [[physical unit|unit]]s of temperature divided by units of altitude, ''T'' is temperature, and ''z'' is altitude.{{efn|Note: <math>\\Gamma</math> and <math>\\gamma</math> are both used in this article but with very distinct meanings.<ref>{{cite book | author=Salomons, Erik M. | title=Computational Atmospheric Acoustics | edition=1st | publisher=Kluwer Academic Publishers| year=2001 | isbn=978-1-4020-0390-5}}</ref><ref>{{cite book | author=Stull, Roland B. | title=An Introduction to Boundary Layer Meteorology | edition=1st | publisher=Kluwer Academic Publishers| year=2001 | isbn=978-90-277-2769-5}}</ref>}}\n\n== Convection and adiabatic expansion ==\n[[File:Emagram.GIF|thumb|350px|right|[[Emagram]] diagram showing variation of dry adiabats (bold lines) and moist adiabats (dash lines) according to pressure and temperature]]\n\nThe temperature profile of the atmosphere is a result of an interaction between [[radiation]] and [[convection]]. Sunlight hits the ground and heats it. The ground then heats the air at the surface. If [[radiation]] were the only way to transfer heat from the ground to space, the [[greenhouse effect]] of gases in the atmosphere would keep the ground at roughly {{convert|333|K|C F}}, and the temperature would decay exponentially with height.<ref name=goodywilson>{{cite book|first1=Richard M.|last1=Goody|first2=James C.G.|last2=Walker|title=Atmospheres|chapter=Atmospheric Temperatures|chapterurl=http://lasp.colorado.edu/~bagenal/3720/GoodyWalker/AtmosCh3sm.pdf|publisher=Prentice-Hall|year=1972}}</ref>\n\nHowever, when air is hot, it tends to expand, which lowers its density. Thus, hot air tends to rise and transfer heat upward. This is the process of [[convection]]. Convection comes to equilibrium when a parcel of air at a given altitude has the same density as the other air at the same elevation.\n\nWhen a parcel of air expands, it pushes on the air around it, doing [[Work (thermodynamics)|work]] (thermodynamics). Since the parcel does work but gains no heat, it loses [[internal energy]] so that its temperature decreases. The process of expanding and contracting without exchanging heat is an [[adiabatic process]]. The term ''adiabatic'' means that no heat transfer occurs into or out of the parcel. Air has low [[thermal conductivity]], and the bodies of air involved are very large, so transfer of heat by [[heat conduction|conduction]] is negligibly small.\n\nThe adiabatic process for air has a characteristic temperature-pressure curve, so the process determines the lapse rate. When the air contains little water, this lapse rate is known as the dry adiabatic lapse rate: the rate of temperature decrease is {{nowrap|9.8&nbsp;°C/km}} ({{nowrap|5.38&nbsp;°F}} per 1,000&nbsp;ft) (3.0&nbsp;°C/1,000&nbsp;ft). The reverse occurs for a sinking parcel of air.<ref name=\"DLA\">Danielson, Levin, and Abrams, ''Meteorology'', McGraw Hill, 2003</ref>\n\nOnly the [[troposphere]] (up to approximately {{convert|12|km|ft}} of altitude) in the Earth's atmosphere undergoes [[convection]]: the [[stratosphere]] does not generally convect.<ref>{{cite web|url=http://scied.ucar.edu/shortcontent/stratosphere-overview|title=The stratosphere: overview|publisher=UCAR|accessdate=2016-05-02}}</ref> However, some exceptionally energetic convection processes—notably volcanic [[eruption column]]s and [[overshooting top]]s associated with severe [[supercell thunderstorms]]—may ''locally'' and ''temporarily'' inject convection through the [[tropopause]] and into the stratosphere.\n\n== Mathematics of the adiabatic lapse rate==\nThese calculation use a very simple model of an atmosphere, either dry or moist, within a still vertical column at equilibrium.\n\n===Dry adiabatic lapse rate===\nThermodynamics defines an adiabatic process as:\n:<math>P \\mathrm{d}V = -\\frac{V \\mathrm{d}P}{\\gamma}</math>\n\nthe [[first law of thermodynamics]] can be written as\n:<math>m c_\\text{v} \\mathrm{d}T - \\frac{V \\mathrm{d}P}{\\gamma} = 0</math>\n\nAlso, since <math>\\alpha = V/m</math> and <math>\\gamma = c_\\text{p}/c_\\text{v}</math>, we can show that:\n:<math>c_\\text{p} \\mathrm{d}T - \\alpha \\mathrm{d}P = 0</math>\n\nwhere <math>c_\\text{p}</math> is the [[specific heat]] at constant pressure and <math>\\alpha</math> is the [[specific volume]].\n\nAssuming an atmosphere in [[hydrostatic equilibrium]]:<ref name=\"LL\">Landau and Lifshitz, ''Fluid Mechanics'', Pergamon, 1979</ref>\n:<math>\\mathrm{d}P = -\\rho g \\mathrm{d}z</math>\n\nwhere ''g'' is the [[standard gravity]] and ''<math>\\rho</math>'' is the density. Combining these two equations to eliminate the pressure, one arrives at the result for the dry adiabatic lapse rate (DALR),<ref>{{cite book|last1=Kittel|last2=Kroemer|title=Thermal Physics|publisher=W. H. Freeman|year=1980|chapter-url=https://books.google.com/books?id=c0R79nyOoNMC&pg=PA179|chapter=6|isbn=978-0-7167-1088-2|page=179}} problem 11</ref>\n:<math>\\Gamma_\\text{d} = -\\frac{\\mathrm{d}T}{\\mathrm{d}z} = \\frac{g}{c_\\text{p}} = 9.8\\ ^{\\circ}\\text{C}/\\text{km}</math>\n\n=== Moist adiabatic lapse rate  ===\n\nThe presence of water within the atmosphere (usually the troposphere) complicates the process of convection. Water vapor contains latent [[heat of vaporization]]. As a parcel of air rises and cools, it eventually becomes [[Dew point|saturated]]; that is, the vapor pressure of water in equilibrium with liquid water has decreased (as temperature has decreased) to the point where it is equal to the actual vapor pressure of water. With further decrease in temperature the water vapor in excess of the equilibrium amount condenses, forming [[cloud]], and releasing heat (latent heat of condensation). Before saturation, the rising air follows the dry adiabatic lapse rate. After saturation, the rising air follows the moist adiabatic lapse rate.<ref>{{cite web|url=http://meteorologytraining.tpub.com/14312/css/14312_47.htm |title=Dry Adiabatic Lapse Rate |publisher=tpub.com |accessdate=2016-05-02 |deadurl=yes |archiveurl=https://web.archive.org/web/20160603041448/http://meteorologytraining.tpub.com/14312/css/14312_47.htm |archivedate=2016-06-03 |df= }}</ref> The release of latent heat is an important source of energy in the development of thunderstorms.\n\nWhile the dry adiabatic lapse rate is a constant {{nowrap|9.8&nbsp;°C/km}} ({{nowrap|5.38&nbsp;°F}} per 1,000&nbsp;ft, {{nowrap|3&nbsp;°C/1,000&nbsp;ft}}), the moist adiabatic lapse rate varies strongly with temperature. A typical value is around {{nowrap|5&nbsp;°C/km}}, ({{nowrap|9&nbsp;°F/km}}, {{nowrap|2.7&nbsp;°F/1,000&nbsp;ft}}, {{nowrap|1.5&nbsp;°C/1,000&nbsp;ft}}).<ref name=\"MLM\">{{cite journal|last1=Minder|first1=JR|first2=PW|last2=Mote|first3=JD|last3=Lundquist|year=2010|title=Surface temperature lapse rates over complex terrain: Lessons from the Cascade Mountains|journal=J. Geophys. Res.|volume=115|issue=D14|page=D14122|doi=10.1029/2009JD013493|bibcode = 2010JGRD..11514122M }}</ref> The formula for the moist adiabatic lapse rate is given by:<ref>{{cite web|url=http://glossary.ametsoc.org/wiki/Saturation-adiabatic_lapse_rate|publisher=American Meteorological Society|title=Saturation adiabatic lapse rate|work=Glossary}}</ref>\n\n:<math>\\Gamma_\\text{w}\n  = g\\, \\frac{\\left(1 + \\dfrac{H_\\text{v}\\, r}{R_\\text{sd}\\, T}\\right)}{\\left(c_\\text{pd} + \\dfrac{H_\\text{v}^2\\, r}{R_\\text{sw}\\, T^2}\\right)}\n  = g\\, \\dfrac{R_\\text{sd}\\,T^2 + H_\\text{v}\\, r\\, T}{c_\\text{pd}\\, R_\\text{sd}\\, T^2 + H_\\text{v}^2\\, r\\, \\epsilon}\n</math>\n\nwhere:\n:{| border=\"0\" cellpadding=\"2\"\n|-\n| style=\"text-align:right;\" | <math>\\Gamma_\\text{w}</math>,\n| wet adiabatic lapse rate, K/m\n|-\n| style=\"text-align:right;\" | <math>g</math>,\n| Earth's [[Standard gravity|gravitational acceleration]] = 9.8076&nbsp;m/s<sup>2</sup>\n|-\n| style=\"text-align:right;\" | <math>H_v</math>,\n| [[heat of vaporization]] of water = {{val|2501000|u=J/kg}} \n|-\n| style=\"text-align:right;\" | <math>R_\\text{sd}</math>,\n| [[specific gas constant]] of dry air = 287&nbsp;J/kg·K \n|-\n| style=\"text-align:right;\" | <math>R_\\text{sw}</math>,\n| specific gas constant of water vapour = 461.5&nbsp;J/kg·K\n|-\n| style=\"text-align:right;\" | <math>\\epsilon = \\frac{R_\\text{sd}}{R_\\text{sw}}</math>,\n| the dimensionless ratio of the specific gas constant of dry air to the specific gas constant for water vapour = 0.622\n|-\n| style=\"text-align:right;\" | <math>e</math>,\n| the water [[vapour pressure]] of the saturated air\n|-\n| style=\"text-align:right;\" | <math>r = \\frac{\\epsilon e}{p - e}</math>,\n| the [[mixing ratio]] of the mass of water vapour to the mass of dry air<ref>{{cite web|url=http://glossary.ametsoc.org/wiki/Mixing_ratio|publisher=American Meteorological Society|title=Mixing ratio|work=Glossary}}</ref>\n|-\n| style=\"text-align:right;\" | <math>p</math>,\n| the pressure of the saturated air\n|-\n|-\n| style=\"text-align:right;\" | <math>T</math>,\n| temperature of the saturated air, K\n|-\n| style=\"text-align:right;\" | <math>c_\\text{pd}</math>,\n| the [[specific heat]] of dry air at constant pressure, = 1003.5{{nbsp}}J/kg·K \n|}\n\n== Environmental lapse rate ==\nThe environmental lapse rate (ELR), is the rate of decrease of temperature with altitude in the stationary atmosphere at a given time and location. As an average, the [[International Civil Aviation Organization]] (ICAO) defines an [[international standard atmosphere]] (ISA) with a temperature lapse rate of {{nowrap|6.49&nbsp;K/km}}<ref name=\"ICAO 1993\">{{cite book|publisher=[[International Civil Aviation Organization]]|title=Manual of the ICAO Standard Atmosphere (extended to 80 kilometres (262 500 feet))|id=Doc 7488-CD|edition=Third|year=1993|isbn=978-92-9194-004-2}}</ref> {{nowrap|(3.56&nbsp;°F}} or {{nowrap|1.98&nbsp;°C/1,000 ft)}} from sea level to 11&nbsp;km {{nowrap|(36,090 ft}} or {{nowrap|6.8&nbsp;mi)}}. From 11&nbsp;km up to 20&nbsp;km {{nowrap|(65,620 ft}} or {{nowrap|12.4&nbsp;mi)}}, the constant temperature is {{nowrap|−56.5&nbsp;°C}} {{nowrap|(−69.7&nbsp;°F)}}, which is the lowest assumed temperature in the ISA. The [[ICAO Standard Atmosphere|standard atmosphere]] contains no moisture. Unlike the idealized ISA, the temperature of the actual atmosphere does not always fall at a uniform rate with height. For example, there can be an [[Temperature inversion|inversion]] layer in which the temperature increases with altitude.\n\n== Effect on weather ==\n[[File:Anvil shaped cumulus panorama edit crop.jpg|thumb|right|x150px|The latent heat of vaporization adds energy to clouds and storms.]]\nThe varying environmental lapse rates throughout the Earth's atmosphere are of critical importance in [[meteorology]], particularly within the [[troposphere]]. They are used to determine if the [[air parcel|parcel]] of rising air will rise high enough for its water to condense to form [[cloud]]s, and, having formed clouds, whether the air will continue to rise and form bigger shower clouds, and whether these clouds will get even bigger and form [[cumulonimbus cloud]]s (thunder clouds).\n\nAs unsaturated air rises, its temperature drops at the dry adiabatic rate.  The [[dew point]] also drops (as a result of decreasing air pressure) but much more slowly, typically about {{nowrap|−2&nbsp;°C}} per 1,000&nbsp;m. If unsaturated air rises far enough, eventually its temperature will reach its [[dew point]], and condensation will begin to form. This altitude is known as the [[lifting condensation level]] (LCL) when mechanical lift is present and the [[convective condensation level]] (CCL) when mechanical lift is absent, in which case, the parcel must be heated from below to its [[convective temperature]]. The [[cloud base]] will be somewhere within the layer bounded by these parameters.\n\nThe difference between the dry adiabatic lapse rate and the rate at which the [[dew point]] drops is around {{nowrap|8&nbsp;°C}} per 1,000&nbsp;m. Given a difference in temperature and [[dew point]] readings on the ground, one can easily find the LCL by multiplying the difference by 125 m/°C.\n\nIf the environmental lapse rate is less than the moist adiabatic lapse rate, the air is absolutely stable — rising air will cool faster than the surrounding air and lose [[buoyancy]]. This often happens in the early morning, when the air near the ground has cooled overnight. Cloud formation in stable air is unlikely.\n\nIf the environmental lapse rate is between the moist and dry adiabatic lapse rates, the air is conditionally unstable — an unsaturated parcel of air does not have sufficient buoyancy to rise to the LCL or CCL, and it is stable to weak vertical displacements in either direction. If the parcel is saturated it is unstable and will rise to the LCL or CCL, and either be halted due to an [[Inversion (meteorology)|inversion layer]] of [[convective inhibition]], or if lifting continues, deep, moist convection (DMC) may ensue, as a parcel rises to the [[level of free convection]] (LFC), after which it enters the [[free convective layer]] (FCL) and usually rises to the [[equilibrium level]] (EL).\n\nIf the environmental lapse rate is larger than the dry adiabatic lapse rate, it has a superadiabatic lapse rate, the air is absolutely unstable — a parcel of air will gain buoyancy as it rises both below and above the lifting condensation level or convective condensation level. This often happens in the afternoon mainly over land masses. In these conditions, the likelihood of [[cumulus cloud]]s, showers or even [[thunderstorm]]s is increased.\n\nMeteorologists use [[radiosonde]]s to measure the environmental lapse rate and compare it to the predicted adiabatic lapse rate to forecast the likelihood that air will rise. Charts of the environmental lapse rate are known as [[thermodynamic diagrams]], examples of which include [[Skew-T log-P diagram]]s and [[tephigram]]s. (See also [[Thermals]]).\n\nThe difference in moist adiabatic lapse rate and the dry rate is the cause of [[foehn wind]] phenomenon (also known as \"[[Chinook wind]]s\" in parts of North America). The phenomenon exists because warm moist air rises through [[orographic lifting]] up and over the top of a mountain range or large mountain. The temperature decreases with the dry adiabatic lapse rate, until it hits the dew point, where water vapor in the air begins to condense. Above that altitude, the adiabatic lapse rate decreases to the moist adiabatic lapse rate as the air continues to rise. Condensation is also commonly followed by [[precipitation (meteorology)|precipitation]] on the top and [[windward]] sides of the mountain. As the air descends on the leeward side, it is warmed by [[adiabatic compression]] at the dry adiabatic lapse rate. Thus, the foehn wind at a certain altitude is warmer than the corresponding altitude on the windward side of the mountain range. In addition, because the air has lost much of its original water vapor content, the descending air creates an [[arid]] region on the leeward side of the mountain.<ref name=\"Whiteman\">{{cite book|last=Whiteman|first= C. David|title=Mountain Meteorology: Fundamentals and Applications |publisher=Oxford University Press|year=2000|isbn=978-0-19-513271-7}}</ref>\n\n== See also ==\n* [[Adiabatic process]]\n* [[Atmospheric thermodynamics]]\n* [[Fluid dynamics]]\n* [[Foehn wind]]\n\n==Notes==\n{{notelist}}\n\n== References ==\n{{reflist|2}}\n\n== Further reading ==\n* {{cite book | author=Beychok, Milton R. | title=Fundamentals Of Stack Gas Dispersion | edition=4th | publisher=author-published | year=2005 | isbn=978-0-9644588-0-2| title-link=Fundamentals Of Stack Gas Dispersion }} [http://www.air-dispersion.com www.air-dispersion.com]\n* {{cite book | author=R. R. Rogers and M. K. Yau | title=Short Course in Cloud Physics | edition=3rd | publisher=Butterworth-Heinemann | year=1989 | isbn=978-0-7506-3215-7}}\n\n== External links ==\n* [http://pds-atmospheres.nmsu.edu/education_and_outreach/encyclopedia/adiabatic_lapse_rate.htm Definition, equations and tables of lapse rate] from the Planetary Data system.\n* National Science Digital Library glossary:\n** [https://web.archive.org/web/20050420085336/http://www.nsdl.arm.gov/Library/glossary.shtml#lapse_rate Lapse Rate]\n** [https://web.archive.org/web/20050420085336/http://www.nsdl.arm.gov/Library/glossary.shtml#environmental_lapse_rate Environmental lapse rate]\n** [https://web.archive.org/web/20050420085336/http://www.nsdl.arm.gov/Library/glossary.shtml#absolute_stable_air Absolute stable air]\n* An introduction to [http://farside.ph.utexas.edu/teaching/sm1/lectures/node56.html lapse rate calculation from first principles] from U. Texas\n\n{{Meteorological variables}}\n\n{{DEFAULTSORT:Lapse Rate}}\n[[Category:Atmospheric thermodynamics]]\n[[Category:Climate feedbacks]]\n[[Category:Fluid mechanics]]\n[[Category:Spatial gradient]]\n[[Category:Temperature]]\n[[Category:Vertical position]]"
    },
    {
      "title": "Potential gradient",
      "url": "https://en.wikipedia.org/wiki/Potential_gradient",
      "text": "In [[physics]], [[chemistry]] and [[biology]], a '''potential gradient''' is the local [[derivative|rate of change]] of the [[potential]] with respect to displacement, i.e. spatial derivative, or gradient. This quantity frequently occurs in equations of physical processes because it leads to some form of [[flux]].\n\n==Definition==\n\n===One dimension===\n\nThe simplest definition for a potential gradient ''F'' in one dimension is the following:<ref>Essential Principles of Physics, P.M. Whelan, M.J. Hodgeson, 2nd Edition, 1978, John Murray, {{ISBN|0-7195-3382-1}}</ref>\n\n:<math> F = \\frac{\\phi_2-\\phi_1}{x_2-x_1} = \\frac{\\Delta \\phi}{\\Delta x}\\,\\!</math>\n\nwhere {{math|''ϕ''(''x'')}} is some type of [[scalar potential]] and {{math|''x''}} is [[Displacement (vector)|displacement]] (not [[distance]]) in the {{math|''x''}} direction, the subscripts label two different positions {{math|''x''<sub>1</sub>, ''x''<sub>2</sub>}}, and potentials at those points, {{math|''ϕ''<sub>1</sub> {{=}} ''ϕ''(''x''<sub>1</sub>), ''ϕ''<sub>2</sub> {{=}} ''ϕ''(''x''<sub>2</sub>)}}. In the limit of [[infinitesimal]] displacements, the ratio of differences becomes a ratio of [[differential of a function|differentials]]:\n\n:<math> F = \\frac{{\\rm d} \\phi}{{\\rm d} x}.\\,\\!</math>\n\nThe direction of the electric potential gradient is from x1 to x2.\n\n===Three dimensions===\n\nIn [[three dimensional space|three dimensions]], [[Cartesian coordinates]] make it clear that the resultant potential gradient is the sum of the potential gradients in each direction:\n\n:<math> \\mathbf{F} = \\mathbf{e}_x\\frac{\\partial \\phi}{\\partial x} + \\mathbf{e}_y\\frac{\\partial \\phi}{\\partial y} + \\mathbf{e}_z\\frac{\\partial \\phi}{\\partial z}\\,\\!</math> \n\nwhere {{math|'''e'''<sub>x</sub>, '''e'''<sub>y</sub>, '''e'''<sub>z</sub>}} are [[unit vector]]s in the {{math|''x, y, z''}} directions. This can be compactly written in terms of the [[gradient]] [[operator (mathematics)|operator]] {{math|∇}},\n\n:<math> \\mathbf{F} = \\nabla \\phi.\\,\\!</math>\n\nalthough this final form holds in any [[curvilinear coordinate system]], not just Cartesian.\n\nThis expression represents a significant feature of any [[conservative vector field]] {{math|'''F'''}}, namely {{math|'''F'''}} has a corresponding potential {{math|''ϕ''}}.<ref>Vector Analysis (2nd Edition), M.R. Spiegel, S. Lipcshutz, D. Spellman, Schaum’s Outlines, McGraw Hill (USA), 2009, {{ISBN|978-0-07-161545-7}}</ref>\n\nUsing [[Stokes' theorem]], this is equivalently stated as\n\n:<math> \\nabla\\times\\mathbf{F} = \\boldsymbol{0} \\,\\!</math>\n\nmeaning the [[Curl (mathematics)|curl]], denoted ∇×, of the vector field vanishes.\n\n==Physics==\n\n===Newtonian gravitation===\n\nIn the case of the [[gravitational field#classical mechanics|gravitational field]] {{math|'''g'''}}, which can be shown to be conservative,<ref>Dynamics and Relativity, J.R. Forshaw, A.G. Smith, Wiley, 2009, {{ISBN|978-0-470-01460-8}}</ref> it is equal to the gradient in [[gravitational potential]] {{math|Φ}}:\n\n:<math>\\mathbf{g} = - \\nabla \\Phi. \\,\\!</math>\n\nThere are opposite signs between gravitational field and potential, because the potential gradient and field are opposite in direction: as the potential increases, the gravitational field strength decreases and vice versa.\n\n===Electromagnetism===\n{{main|Maxwell's equations|Mathematical descriptions of the electromagnetic field}}\nIn [[electrostatics]], the [[electric field]] {{math|'''E'''}} is independent of time {{math|''t''}}, so there is no induction of a time-dependent [[magnetic field]] {{math|'''B'''}} by [[Faraday's law of induction]]:\n\n:<math>\\nabla\\times\\mathbf{E} = -\\frac{\\partial\\mathbf{B}}{\\partial t} = \\boldsymbol{0} \\,,</math>\n\nwhich implies {{math|'''E'''}} is the gradient of the electric potential {{math|''V''}}, identical to the classical gravitational field:<ref>Electromagnetism (2nd Edition), I.S. Grant, W.R. Phillips, Manchester Physics, John Wiley & Sons, 2008, {{ISBN|978-0-471-92712-9}}</ref>\n\n:<math>- \\mathbf{E} = \\nabla V. \\,\\!</math>\n\nIn [[electrodynamics]], the {{math|'''E'''}} field is time dependent and induces a time-dependent {{math|'''B'''}} field also (again by Faraday's law), so the curl of {{math|'''E'''}} is not zero like before, which implies the electric field is no longer the gradient of electric potential. A time-dependent term must be added:<ref>Introduction to Electrodynamics (3rd Edition), D.J. Griffiths, Pearson Education, Dorling Kindersley, 2007, {{ISBN|81-7758-293-3}}</ref> \n\n:<math>- \\mathbf{E} = \\nabla V + \\frac{\\partial \\mathbf{A}}{\\partial t}\\,\\!</math>\n\nwhere {{math|'''A'''}} is the electromagnetic [[vector potential]]. This last potential expression in fact reduces Faraday's law to an identity.\n\n===Fluid mechanics===\n\nIn [[fluid mechanics]], the [[velocity field]] {{math|'''v'''}} describes the fluid motion. An [[irrotational flow]] means the velocity field is conservative, or equivalently the [[vorticity]] [[pseudovector]] field {{math|'''ω'''}} is zero: \n\n:<math> \\boldsymbol{\\omega} = \\nabla\\times\\mathbf{v} = \\boldsymbol{0}.</math>\n\nThis allows the [[velocity potential]] to be defined simply as:\n\n:<math> \\mathbf{v} = \\nabla\\phi</math>\n\n==Chemistry==\n\n{{main|Electrode potentials}}\n\nIn an [[Electrochemistry|electrochemical]] [[half-cell]], at the interface between the [[electrolyte]] (an [[ion]]ic [[solution]]) and the [[metal]] [[electrode]], the standard [[electric potential difference]] is:<ref>Physical chemistry, P.W. Atkins, Oxford University Press, 1978, {{ISBN|0-19-855148-7}}</ref>\n\n:<math>\\Delta \\phi_{(M,M^{+z})} = \\Delta \\phi_{(M,M^{+z})}^{\\ominus} + \\frac{RT}{zeN_\\text{A}}\\ln a_{M^{+z}} \\,\\!</math>\n\nwhere ''R'' = [[gas constant]], ''T'' = [[temperature]] of solution, ''z'' = [[Valence (chemistry)|valency]] of the metal, ''e'' = [[elementary charge]], ''N''<sub>A</sub> = [[Avogadro constant]], and ''a''<sub>M<sup>+z</sup></sub> is the [[Activity (chemistry)|activity]] of the ions in solution. Quantities with superscript ⊖ denote the measurement is taken under [[Standard conditions for temperature and pressure|standard conditions]]. The potential gradient is relatively abrupt, since there is an almost definite boundary between the metal and solution, hence the interface term.<!---What is this sentence trying to say!??--->{{clarify|date=March 2013}}\n\n==Biology==\n\nIn [[biology]], a potential gradient is the net difference in [[electric charge]] across a [[cell membrane]].\n\n==Non-uniqueness of potentials==\n\nSince gradients in potentials correspond to [[Field (physics)|physical field]]s, it makes no difference if a constant is added on (it is erased by the gradient operator {{math|&nabla;}} which includes [[partial differentiation]]). This means there is no way to tell what the \"absolute value\" of the potential \"is\" – the zero value of potential is completely arbitrary and can be chosen anywhere by convenience (even \"at infinity\"). This idea also applies to vector potentials, and is exploited in [[classical field theory]] and also [[gauge field theory]].\n\nAbsolute values of potentials are not physically observable, only gradients and path-dependent potential differences are. However, the [[Aharonov–Bohm effect]] is a [[quantum mechanics|quantum mechanical]] effect which illustrates that non-zero [[electromagnetic potential]]s along a closed loop (even when the {{math|'''E'''}} and {{math|'''B'''}} fields are zero everywhere in the region) lead to changes in the phase of the [[wave function]] of an electrically [[charged particle]] in the region, so the potentials appear to have measurable significance.\n\n==Potential theory==\n\n[[Field equation]]s, such as Gauss's laws [[Gauss's law|for electricity]], [[Gauss's law for magnetism|for magnetism]], and [[Gauss's law for gravity|for gravity]], can be written in the form:\n\n:<math>\\nabla\\cdot\\mathbf{F}= X \\rho</math>\n\nwhere {{math|''ρ''}} is the electric [[charge density]], [[magnetic monopole|monopole]] density (should they exist), or [[mass density]] and {{math|''X''}} is a constant (in terms of [[physical constant]]s [[Gravitational constant|{{math|''G''}}]], [[Vacuum permittivity|{{math|''ε''<sub>0</sub>}}]], [[Vacuum permeability|{{math|''μ''<sub>0</sub>}}]] and other numerical factors).\n\nScalar potential gradients lead to [[Poisson's equation]]:\n\n:<math>\\nabla\\cdot (\\nabla\\phi)= X \\rho \\quad \\Rightarrow \\quad \\nabla^2 \\phi = X \\rho</math>\n\nA general [[potential theory|theory of potentials]] has been developed to solve this equation for the potential. The gradient of that solution gives the physical field, solving the field equation.\n\n==See also==\n*[[Tensors in curvilinear coordinates]]\n\n==References==\n\n{{reflist}}\n\n[[Category:Concepts in physics]]\n[[Category:Spatial gradient]]\n\n[[pl:Gradient potencjału]]"
    },
    {
      "title": "Pressure gradient",
      "url": "https://en.wikipedia.org/wiki/Pressure_gradient",
      "text": "In [[atmospheric science]], the '''pressure gradient''' (typically of [[Earth's atmosphere|air]] but more generally of any [[fluid]]) is a physical quantity that describes in which direction and at what rate the [[pressure]] increases the most rapidly around a particular location. The pressure gradient is a dimensional quantity expressed in units of [[pascal (unit)|pascals]] per [[metre]] (Pa/m). Mathematically, it is obtained by applying the [[del operator]] to a pressure function of position. The negative gradient of pressure is known as the [[force density]].\n\nIn [[petroleum geology]] and the petrochemical sciences pertaining to [[oil well]]s, and more specifically within [[hydrostatics]], pressure gradients refer to the [[gradient]] of vertical pressure in a column of fluid within a [[wellbore]] and are generally expressed in [[pounds per square inch]] per [[foot (unit)|foot]] (psi/ft). This column of fluid is subject to the compound pressure gradient of the overlying fluids. The path and geometry of the column is totally irrelevant; only the vertical depth of the column has any relevance to the vertical pressure of any point within its column and the pressure gradient for any given [[true vertical depth]].\n\n==Physical interpretation==\n\nThe concept of a pressure gradient is a ''local'' characterisation of the air (more generally of the fluid under investigation). The pressure gradient is defined only at those spatial scales at which pressure (more generally [[fluid dynamics]]) itself is defined.\n\nWithin [[planet]]ary [[atmosphere]]s (including the [[Earth's atmosphere|Earth's]]), the pressure gradient is a vector pointing roughly downwards, because the pressure changes most rapidly vertically, increasing downwards (see [[vertical pressure variation]]). The value of the strength (or [[Norm (mathematics)|norm]]) of the pressure gradient in the [[troposphere]] is typically of the order of 9 Pa/m (or 90 hPa/km).\n\nThe pressure gradient often has a small but critical horizontal component, which is largely responsible for [[wind]] circulation in the atmosphere. The '''horizontal pressure gradient''' is a two-dimensional vector resulting from the projection of the pressure gradient onto a local horizontal plane. Near the [[Earth's surface]], this horizontal pressure gradient force is directed from higher toward lower pressure. Its particular orientation at any one time and place depends strongly on the weather situation. At mid-[[latitude]]s, the typical horizontal pressure gradient may take on values of the order of 10<sup>−2</sup> Pa/m (or 10 Pa/km), although rather higher values occur within [[Surface weather analysis|meteorological fronts]].\n\n==Weather and climate relevance==\n\nInterpreting differences in air pressure between different locations is a fundamental component of many [[meteorology|meteorological]] and [[climatology|climatological]] disciplines, including [[weather forecasting]]. As indicated above, the pressure gradient constitutes one of the main forces acting on the air to make it move as wind. Note that the [[pressure gradient force]] points from high towards low pressure zones. It is thus oriented in the opposite direction from the pressure gradient itself.\n\n==In acoustics==\n\n\nIn [[acoustics]], the pressure gradient is proportional to the sound particle acceleration according to [[Euler's equation]]. [[Sound]] waves and [[shock wave]]s can induce very large pressure gradients, but these are oscillatory, and often transitory disturbances.\n\n==See also==\n\n*[[Adverse pressure gradient]]\n*[[Force density]]\n*[[Isobar (meteorology)|Isobar]]\n*[[Geopotential height]]\n*[[Geostrophic wind]]\n*[[Primitive equations]]\n*[[Temperature gradient]]\n\n==References==\n\n*Conner A. Perrine (1967) ''The nature and theory of the general circulation of atmosphere'', World Meteorological Organization, Publication No. 218, Geneva, Switzerland.\n*Robert G. Fleagle and [[Joost A. Businger]] (1980) ''An Introduction to Atmospheric Physics'', Second Edition, Academic Press, International Geophysics Series, Volume '''25''', {{ISBN|0-12-260355-9}}.\n*John S. Wallace and Peter V. Hobbs (2006) ''Atmospheric Science: An Introductory Survey'', Second Edition, Academic Press, International Geophysics Series, {{ISBN|0-12-732951-X}}.\n\n==External links==\n\n*[http://www.grida.no/climate/ipcc_tar/wg1/index.htm IPCC Third Assessment Report]\n\n{{Meteorological variables}}\n\n[[Category:Atmospheric dynamics]]\n[[Category:Pressure]]\n[[Category:Spatial gradient]]"
    },
    {
      "title": "Sound speed gradient",
      "url": "https://en.wikipedia.org/wiki/Sound_speed_gradient",
      "text": "In [[acoustics]], the '''sound speed gradient''' is the rate of change of the [[speed of sound]] with distance, for example with depth in the [[ocean]],<ref name=\"NTRP 1-02\">{{cite book\n |title     = Navy Supplement to the DOD Dictionary of Military and Associated Terms\n |date      = August 2006\n |publisher = [[United States Navy|Department Of The Navy]]\n |url       = https://www.nwdc.navy.mil/Documents/NTRP_1-02.pdf\n |id        = NTRP 1-02\n}}{{dead link|date=May 2018 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>\nor height in the [[Earth's atmosphere]]. A sound speed gradient leads to [[refraction of sound]] [[wavefront]]s in the direction of lower sound speed, causing the sound rays to follow a curved path. The [[Radius of curvature (mathematics)|radius of curvature]] of the sound path is inversely proportional to the gradient.<ref>{{cite book\n|title=Noise Control\n|chapter=10. Outdoor sound propagation\n|series=ME 458: Engineering Noise Control\n|year=2000\n|first=J. S. \n|last=Lamancusa\n|url=http://www.mne.psu.edu/lamancusa/me458/10_osp.pdf\n|publisher=[[Penn State University]]\n|location=State College, PA\n|format=pdf\n|pages=10.6–10.7\n}}</ref>\n\nWhen the sun warms the Earth's surface, there is a negative [[temperature gradient]] in atmosphere. The [[speed of sound]] decreases with decreasing temperature, so this also creates a negative sound speed gradient.<ref name=Ahnert>{{cite book\n|title=Sound Reinforcement Engineering\n|first=Wolfgang |last=Ahnert\n|author2=Steffen, Frank\n |publisher=Taylor and Francis\n|place = London\n|year=1999\n|pages=40\n|isbn= 0-415-23870-6\n}}</ref> The sound wave front travels faster near the ground, so the sound is [[refraction|refracted]] upward, away from listeners on the ground, creating an [[acoustic shadow]] at some distance from the source.<ref>\n{{cite book \n| last = Everest | first = F. \n| title = The Master Handbook of Acoustics \n| publisher = McGraw-Hill \n| location = New York \n| year = 2001 \n| isbn = 0-07-136097-2 \n| pages = 262–263 }}</ref> The opposite effect happens when the ground is covered with snow, or in the morning over water, when the sound speed gradient is positive. In this case, sound waves can be refracted from the upper levels down to the surface.<ref name=Ahnert/>\n\nIn [[underwater acoustics]], speed of sound [[speed of sound#Seawater|depends]] on pressure (hence depth), temperature, and salinity of [[seawater]], thus leading to vertical speed gradients similar to those that exist in atmospheric acoustics. However, when there is a zero sound speed gradient, values of sound speed have the same \"isospeed\" in all parts of a given water column (there is no change in sound speed with depth).<ref name=\"NTRP 1-02\"/> The same effect happens in an [[isothermal atmosphere]] with the [[ideal gas]] assumption.\n\n==References==\n{{Reflist}}\n\n==See also==\n* [[SOFAR channel]]\n* [[Wind gradient]]\n\n{{science-stub}}\n{{hydroacoustics}}\n\n[[Category:Acoustics]]\n[[Category:Spatial gradient]]"
    },
    {
      "title": "Temperature gradient",
      "url": "https://en.wikipedia.org/wiki/Temperature_gradient",
      "text": "A '''temperature gradient''' is a [[physical quantity]] that describes in which direction and at what rate the [[temperature]] changes the most rapidly around a particular location. The temperature gradient is a [[Dimensional analysis|dimensional quantity]] expressed in [[Units of measurement|units]] of degrees (on a particular temperature scale) per unit [[length]]. The [[International System of Units|SI]] unit is [[kelvin]] per [[meter]] (K/m). It can be found in the formula for dQ/dt, the rate of heat transfer per second.\n\nTemperature gradients in the [[Earth's atmosphere|atmosphere]] are important in the atmospheric sciences ([[meteorology]], [[climatology]] and related fields).\n\n== Mathematical description ==\nAssuming that the temperature ''T'' is an [[intensive quantity]], i.e., a single-valued, [[Continuous function|continuous]] and [[Derivative|differentiable]] [[Function (mathematics)|function]] of three-dimensional space (often called a [[scalar field]]), i.e., that\n\n:<math>T=T(x,y,z)</math>\n\nwhere ''x'', ''y'' and ''z'' are the [[Cartesian coordinate system|coordinates]] of the location of interest, then the temperature gradient is the [[vector (geometric)|vector]] quantity defined as\n\n:<math>\n\\nabla T = \\begin{pmatrix}\n{\\frac{\\partial T}{\\partial x}},  \n{\\frac{\\partial T}{\\partial y}}, \n{\\frac{\\partial T}{\\partial z}}\n\\end{pmatrix}</math>\n...\n\n== Physical processes ==\n\n=== Climatology ===\nOn a global and annual basis, the dynamics of the atmosphere (and the oceans) can be understood as attempting to reduce the large difference of temperature between the [[Geographical pole|poles]] and the equator by redistributing warm and cold air and water, known as Earth's heat engine.\n\n=== Meteorology ===\nDifferences in air temperature between different locations are critical in weather forecasting and climate. The absorption of solar light at or near the planetary surface increases the temperature gradient and may result in [[convection]] (a major process of [[cloud]] formation, often associated with [[Precipitation (meteorology)|precipitation]]). \n[[Surface weather analysis|Meteorological fronts]] are regions where the horizontal temperature gradient may reach relatively high values, as these are boundaries between [[air mass]]es with rather distinct properties.\n\nClearly, the temperature gradient may change substantially in time, as a result of diurnal or seasonal heating and cooling for instance. This most likely happens during an [[Inversion (meteorology)|inversion]]. For instance, during the day the temperature at [[Lithosphere|ground level]] may be cold while it's warmer up in the atmosphere. As the day shifts over to night the temperature might drop rapidly while at other places on the land stay warmer or cooler at the same [[elevation]]. This happens on the [[West Coast of the United States]] sometimes due to geography.\n\n=== Weathering ===\nExpansion and contraction of rock, caused by temperature changes during a [[wildfire]], through [[Weathering#Thermal stress|thermal stress weathering]], may result in [[thermal shock]] and subsequent structure failure.\n\n== Indoor temperature ==\n{{Main|Thermal destratification in buildings}}\n\n== See also ==\n* [[Atmospheric temperature]] for gradient of earth's atmosphere\n* [[Geothermal gradient]]\n* [[Gradient]]\n* [[Lapse rate]]\n\n== References ==\n* {{cite book|author=Edward N. Lorenz|title=The Nature and Theory of the General Circulation of the Atmosphere|url=https://books.google.com/books?id=RaMJAQAAIAAJ|series=Publication No. 218|year=1967|publisher=World Meteorological Organization|location=Geneva, Switzerland}}\n* {{cite book|author=M. I. Budyko|year=1978|title=Climate and Life|url=https://www.elsevier.com/books/climate-and-life/budyko/978-0-12-139450-9|publisher=Academic Press|series=International Geophysics Series|volume=18|isbn=0-12-139450-6}}\n* {{cite book|title=An introduction to atmospheric physics|url=https://books.google.com/books?id=6oIuAAAAIAAJ|author1=Robert G. Fleagle|author2=[[Joost A. Businger]]|date=1980|publisher=Academic Press|series=International Geophysics Series|volume=25|isbn=0-12-260355-9}}\n* {{cite book|author=David Miller|title=Energy at the surface of the earth : an introduction to the energetics of ecosystems|url=https://books.google.com/books?id=GhkGo9ZztAcC|year=1981|publisher=Academic Press|isbn=978-0-08-095460-8}}\n* {{cite book|author1=John M. Wallace|author2=Peter V. Hobbs|title=Atmospheric Science: An Introductory Survey|url=https://books.google.com/books?id=HZ2wNtDOU0oC|year=2006|publisher=Elsevier|isbn=978-0-08-049953-6}}\n<references />\n\n==External links==\n* [http://www.grida.no/climate/ipcc_tar/wg1/index.htm IPCC Third Assessment Report]\n* [http://visualdaq.com/DaqPlaner/ Pictorial Representation of Temperature Gradient (Tools)].\n\n[[Category:Atmospheric dynamics]]\n[[Category:Climatology]]\n[[Category:Spatial gradient]]\n[[Category:Temperature]]\n\n[[fr:Gradient#Gradient de température]]"
    },
    {
      "title": "Velocity gradient",
      "url": "https://en.wikipedia.org/wiki/Velocity_gradient",
      "text": "#REDIRECT [[Strain-rate tensor]] {{R from merge}}\n\n[[Category:Fluid mechanics]]\n[[Category:Continuum mechanics]]\n[[Category:Spatial gradient]]"
    },
    {
      "title": "Wind gradient",
      "url": "https://en.wikipedia.org/wiki/Wind_gradient",
      "text": "{{distinguish|gradient wind}}\n{{about|the interaction of horizontal wind with the earth's surface|a more general treatment of related phenomena|wind shear}}\n\nIn common usage, '''wind gradient''', more specifically '''wind speed gradient'''<ref name=Hadlock>{{cite book | last = Hadlock | first =  Charles | title = Mathematical Modeling in the Environment | publisher = Mathematical Association of America | location = Washington | year = 1998 | isbn = 978-0-88385-709-0 |pages= |quote=Thus we have a “wind-speed gradient” as we move vertically, and this has a tendency to encourage mixing between the air at one level and the air at those levels immediately above and below it.}}</ref>\nor '''wind velocity gradient''',<ref name=Gorder1996>{{cite conference\n | author = Gorder, P.J. |author2=Kaufman, K. |author3=Greif, R.\n | year = 1996\n | title = Effect of wind gradient on the trajectory synthesis algorithms of the Center-TRACON Automation System (CTAS)\n | booktitle = AIAA, Guidance, Navigation and Control Conference, San Diego, CA\n | publisher = [[American Institute of Aeronautics and Astronautics]]\n | url = http://pdf.aiaa.org/GetFileGoogle.cfm?gID=10404&gTable=mtgpaper\n | quote=...the effect of a change in mean wind velocity with altitude, the wind velocity gradient...}}</ref>\nor alternatively '''shear wind''',<ref>{{cite journal\n|journal=Ibis\n|volume=147 \n|issue=1 \n|pages=1–10\n|date=2005-01-10\n|year= 2004 \n|title=Minimum shear wind strength required for dynamic soaring of albatrosses\n|author=Sachs, Gottfried\n|doi=10.1111/j.1474-919x.2004.00295.x\n|quote=...the shear wind gradient is rather weak....the energy gain...is due to a mechanism other than the wind gradient effect.}}</ref>\nis the vertical [[gradient]] of the mean horizontal [[wind]] speed in the lower [[Earth's atmosphere|atmosphere]].<ref name=Oke>{{cite book | last = Oke | first = T. | title = Boundary Layer Climates | publisher = Methuen | location = London | year = 1987 | isbn = 978-0-415-04319-9 |pages = 54 | quote = Therefore the vertical gradient of mean wind speed (dū/dz) is greatest over smooth terrain, and least over rough surfaces.}}</ref> It is the rate of increase of wind strength with unit increase in height above ground level.<ref>{{cite book | last = Crocker | first = David | title = Dictionary of Aeronautical English | publisher = Routledge | location = New York | year = 2000 | isbn = 978-1-57958-201-2 | pages = 104 | quote=wind gradient = rate of increase of wind strength with unit increase in height above ground level;}}</ref><ref name=Wizelius/> In metric units, it is often measured in units of meters per second of speed, per kilometer of height&nbsp;(m/s/km), which reduces to the standard unit of [[shear rate]], inverse seconds&nbsp;(s<sup>−1</sup>).\n\n==Simple explanation==\n\n[[Surface friction]] forces the surface [[wind]] to slow and turn near the surface of the [[Earth]], blowing directly towards the low pressure, when compared to the winds in the nearly frictionless flow well above the Earth's surface.<ref>{{cite web | title=AMS Glossary of Meteorology, Ekman layer | publisher = [[American Meteorological Association]] | url=http://glossary.ametsoc.org/wiki/Ekman_layer | accessdate=2015-02-15}}</ref>  This layer, where surface friction slows the wind and changes the wind direction, is known as the [[planetary boundary layer]]. Daytime solar heating due to [[insolation]] thickens the boundary layer as winds warmed by contact with the earth's hot surface rise up and become increasingly mixed with winds aloft. Radiative cooling overnight gradually decouples the winds at the surface from the winds above the boundary layer, increasing vertical wind shear near the surface, also known as wind gradient.\n\n==Background==\n{{see also|Ekman layer|Ekman spiral|Planetary boundary layer|Surface layer}}\nTypically, due to [[aerodynamic]] [[drag (force)|drag]], there is a wind gradient in the wind flow, especially in the first few hundred meters above the Earth's surface—the [[surface layer]] of the [[planetary boundary layer]]. Wind speed increases with increasing height above the ground, starting from zero<ref name=Wizelius>{{cite book | last = Wizelius | first = Tore | title = Developing Wind Power Projects | publisher = Earthscan Publications Ltd | location = London | year = 2007 | isbn = 978-1-84407-262-0 | pages = 40 | quote = The relation between wind speed and height is called the wind profile or wind gradient.}}</ref> due to the [[no-slip condition]].<ref name=Brown>{{cite book | last = Brown | first = G. | title = Sun, Wind & Light | publisher = Wiley | location = New York | year = 2001 | pages = 18 | isbn = 978-0-471-34877-1 }}</ref> Flow near the surface encounters obstacles that reduce the wind speed, and introduce random vertical and horizontal velocity components at right angles to the main direction of flow.<ref>{{cite journal\n|title=CBD-28. Wind on Buildings\n|author=Dalgliesh, W. A. and D. W. Boyd\n|journal=Canadian Building Digest\n|url=http://irc.nrc-cnrc.gc.ca/pubs/cbd/cbd028_e.html\n|date=1962-04-01\n|quote=Flow near the surface encounters small obstacles that change the wind speed and introduce random vertical and horizontal velocity components at right angles to the main direction of flow.}}</ref>\nThis [[turbulence]] causes vertical [[Mixing (physics)|mixing]] between the air moving horizontally at various levels, which has an effect on the dispersion of [[pollutants]]<ref name=Hadlock/>, dust and airborne sand and [[soil]] particles.<ref name=Lal/>\n\nThe reduction in velocity near the surface is a function of surface roughness. Wind velocity profiles are quite different for different terrain types.<ref name=Brown/> Rough, irregular ground, and man-made obstructions on the ground, retard movement of the air near the surface, reducing wind velocity.<ref name=Oke/><ref name=Crawley>{{cite book | last = Crawley | first = Stanley | title = Steel Buildings | publisher = Wiley | location = New York | year = 1993 | isbn = 978-0-471-84298-9 | pages = 272 }}</ref> Because of the relatively smooth water surface, wind speeds do not decrease as much close to the sea as they do on land.<ref name=Lubosny>{{cite book | last = Lubosny | first = Zbigniew | title = Wind Turbine Operation in Electric Power Systems: Advanced Modeling | publisher = Springer | location = Berlin | year = 2003 | isbn = 978-3-540-40340-1 | pages = 17}}</ref> Over a city or rough terrain, the wind gradient effect could cause a reduction of 40% to 50% of the [[geostrophic wind]] speed aloft; while over open water or ice, the reduction may be only 20% to 30%.<ref>{{cite book | last = Harrison | first = Roy | title = Understanding Our Environment | publisher = Royal Society of Chemistry | location = Cambridge | year = 1999 | isbn = 978-0-85404-584-6 | pages = 11}}</ref><ref name=Russell>{{cite book | last = Thompson | first = Russell | title = Atmospheric Processes and Systems | publisher = Routledge | location = New York | year = 1998 | isbn = 978-0-415-17145-8 | pages = 102–103 }}</ref>\n\nFor [[engineering]] purposes, the wind gradient is modeled as a [[simple shear]] exhibiting a vertical velocity profile varying according to a [[power law]] with a constant [[exponent]]ial coefficient based on surface type. The height above ground where surface friction has a negligible effect on wind speed is called the \"gradient height\" and the wind speed above this height is assumed to be a constant called the \"gradient wind speed\".<ref name=Crawley/><ref name=Gupta>{{cite book | last = Gupta | first = Ajaya | title = Guidelines for Design of Low-Rise Buildings Subjected to Lateral Forces | publisher = CRC Press | location = Boca Raton | year = 1993 | isbn = 978-0-8493-8969-6 | pages = 49}}</ref><ref>{{cite book | last = Stoltman | first = Joseph | title = International Perspectives on Natural Disasters: Occurrence, Mitigation, and Consequences | publisher = Springer | location = Berlin | year = 2005 | isbn = 978-1-4020-2850-2 | pages = 73 }}</ref> For example, typical values for the predicted gradient height are 457 m for large cities, 366 m for suburbs, 274 m for open terrain, and 213 m for open sea.<ref>{{cite book | last = Chen | first = Wai-Fah | title = Handbook of Structural Engineering | publisher = CRC Press | location = Boca Raton | year = 1997 | isbn = 978-0-8493-2674-5 | pages = 12–50}}</ref>\n\nAlthough the power law exponent approximation is convenient, it has no theoretical basis.<ref>{{cite book | last = Ghosal | first = M. | title = Renewable Energy Resources | chapter = 7.8.5 Vertical Wind Speed Gradient | publisher = Alpha Science International, Ltd | location = City | year = 2005 | isbn = 978-1-84265-125-4 | pages = 378–379}}</ref> When the temperature profile is adiabatic, the wind speed should vary [[logarithm]]ically with height,<ref>{{cite book | last = Stull | first = Roland | title = An Introduction to Boundary Layer Meteorology | publisher = Kluwer Academic Publishers | location = Boston | year = 1997 | isbn = 978-90-277-2768-8 | pages = 442 | quote = ...both the wind gradient and the mean wind profile itself can usually be described diagnostically by the log wind profile.}}</ref> Measurements over open terrain in 1961 showed good agreement with the logarithmic fit up to 100 m or so, with near constant average wind speed up through 1000 m.<ref name=Thuillier>{{cite journal\n | author = Thuillier, R.H.\n |author2=Lappe, U.O.\n  | year = 1964\n | title = Wind and Temperature Profile Characteristics from Observations on a 1400 ft Tower\n | journal = [[Journal of Applied Meteorology]]\n | volume = 3\n | issue = 3\n | pages = 299–306\n | doi = 10.1175/1520-0450(1964)003<0299:WATPCF>2.0.CO;2\n |bibcode = 1964JApMe...3..299T }}</ref>\n\nThe [[shearing (physics)|shearing]] of the wind is usually three-dimensional,<ref>{{cite book | last = Mcilveen | first = J. | title = Fundamentals of Weather and Climate | publisher = Chapman & Hall | location = London | year = 1992 | isbn = 978-0-412-41160-1 | pages = 184}}</ref> that is, there is also a change in direction between the 'free' pressure-driven geostrophic wind and the wind close to the ground.<ref>{{cite book | last = Burton | first = Tony | title = Wind Energy Handbook | publisher = J. Wiley | location = London | year = 2001 | pages = 20 | isbn = 978-0-471-48997-9 }}</ref> This is related to the [[Ekman spiral]] effect. \nThe cross-isobar angle of the diverted ageostrophic flow near the surface ranges from 10° over open water, to 30° over rough hilly terrain, and can increase to 40°-50° over land at night when the wind speed is very low.<ref name=Russell/>\n\nAfter sundown the wind gradient near the surface increases, with the increasing stability.<ref name=K>{{cite journal\n | author = Köpp, F. |author2=Schwiesow, R.L. |author3=Werner, C.\n |date=January 1984\n | title = Remote Measurements of Boundary-Layer Wind Profiles Using a CW Doppler Lidar\n | journal = [[Journal of Applied Meteorology and Climatology]]\n | volume = 23\n | issue = 1\n | pages = 153\n | doi = 10.1175/1520-0450(1984)023<0148:RMOBLW>2.0.CO;2\n |bibcode = 1984JApMe..23..148K  }}</ref>\nAtmospheric stability occurring at night with [[radiative cooling]] tends to contain turbulent eddies vertically, increasing the wind gradient.<ref name=Lal>{{cite book | last = Lal | first = R. | title = Encyclopedia of Soil Science | publisher = Marcel Dekker | location = New York | year = 2005 | isbn = 978-0-8493-5053-5 | pages= 618}}</ref> The magnitude of the wind gradient is largely influenced by the height of the convective boundary layer and this effect is even larger over the sea, where there is no diurnal variation of the height of the boundary layer as there is over land.<ref name=Johansson2002>{{cite conference\n | author = Johansson, C. |author2=Uppsala, S. |author3=Smedman, A.S.\n | year = 2002\n | title = Does the height of the boundary layer influence the turbulence structure near the surface over the Baltic Sea?\n | booktitle = 15th Conference on Boundary Layer and Turbulence\n | publisher = [[American Meteorological Society]]\n | url = http://ams.confex.com/ams/BLT/techprogram/paper_43332.htm\n | conferenceurl = http://ams.confex.com/ams/BLT/techprogram/program_117.htm\n }}</ref>\nIn the convective boundary layer, strong mixing diminishes vertical wind gradient.<ref>{{cite book | last = Shao | first = Yaping | title = Physics and Modelling of Wind Erosion | publisher = Kluwer Academic | location = City | year = 2000 | isbn = 978-0-7923-6657-7 |pages = 69 |quote = In the bulk of the convective boundary layer, strong mixing diminishes vertical wind gradient...}}</ref>\n\n==Engineering==\n\nThe design of buildings must account for wind loads, and these are affected by wind gradient. The respective gradient levels, usually assumed in the Building Codes, are 500 meters for cities, 400 meters for suburbs, and 300 m for flat open terrain.<ref>{{cite book | last = Augusti | first = Giuliano | title = Probabilistic Methods in Structural Engineering | publisher = Chapman and Hall | location = London | year = 1984 | isbn = 978-0-412-22230-6 |pages = 85}}</ref>  For engineering purposes, a power law wind speed profile may be defined as follows:<ref name=Crawley/><ref name=Gupta/>\n\n:<math>\\ v_z = v_g \\cdot \\left(  \\frac {z} {z_g} \\right)^ \\frac {1} {\\alpha},  0 < z < z_g\n</math>\n\nwhere:\n\n:<math>\\ v_z</math> = speed of the wind at height <math>\\ z</math>\n:<math>\\ v_g</math> = gradient wind at gradient height <math>\\ z_g </math>\n:<math>\\ \\alpha</math> = exponential coefficient\n\n{{further information|Wind engineering}}\n\n===Wind turbines===\n\n[[Wind turbine]] operation is affected by wind gradient. Vertical wind-speed profiles result in different wind speeds at the blades nearest to the ground level compared to those at the top of blade travel which results in asymmetric load.<ref name=Heier>{{cite book | last = Heier | first = Siegfried | title = Grid Integration of Wind Energy Conversion Systems | publisher = John Wiley & Sons | location = Chichester | year = 2005 | isbn = 978-0-470-86899-7 | pages = 45}}</ref> The wind gradient can create a large bending moment in the shaft of a two bladed turbine when the blades are vertical.<ref>{{cite book | last = Harrison | first = Robert | title = Large Wind Turbines | publisher = John Wiley & Sons | location = Chichester | year = 2001 | isbn = 978-0-471-49456-0 | pages = 30}}</ref> The reduced wind gradient over water means shorter and less expensive wind turbine towers can be used in windparks which are placed in (shallow) seas.<ref name=Lubosny/> It would be preferable for wind turbines to be tested in a [[wind tunnel]] simulating the wind gradient that they will eventually see, but this is rarely done.<ref>{{cite book | last = Barlow | first = Jewel | title = Low-Speed Wind Tunnel Testing | publisher = Wiley | location = New York | year = 1999 | isbn = 978-0-471-55774-6 | pages= 42 | quote=It would be preferable to evaluate windmills in the wind gradient that they will eventually see, but this is rarely done.}}</ref>\n\nFor wind turbine engineering, a polynomial variation in wind speed with height can be defined relative to wind measured at a reference height of 10 meters as:<ref name=Heier/>\n\n:<math>\\ v_w(h) = v_{10} \\cdot \\left(  \\frac {h} {h_{10}} \\right)^ a\n</math>\n\nwhere:\n\n:<math>\\ v_w(h)</math> = velocity of the wind <nowiki>[m/s]</nowiki>, at height <math> h</math>\n:<math>\\ v_{10}</math> = velocity of the wind <nowiki>[m/s]</nowiki>, at height <math> h_{10} </math> = 10 meters\n:<math>\\ a</math> = Hellmann exponent\n\nThe [[Gustav Hellmann|Hellmann]] exponent depends upon the coastal location and the shape of the terrain on the ground, and the stability of the air. Examples of values of the Hellmann exponent are given in the table below:\n\n{| class=\"wikitable\" border=\"1\"\n|-\n!  location\n!  α\n|-\n|Unstable air above open water surface: \n|0.06\n|-\n|Neutral air above open water surface: \n|0.10\n|-\n|Unstable air above flat open coast: \n|0.11\n|-\n|Neutral air above flat open coast: \n|0.16\n|-\n|Stable air above open water surface: \n|0.27\n|-\n|Unstable air above human inhabited areas: \n|0.27\n|-\n|Neutral air above human inhabited areas: \n|0.34\n|-\n|Stable air above flat open coast: \n|0.40\n|-\n|Stable air above human inhabited areas: \n|0.60\n|}\n\nSource:\n\"Renewable energy: technology, economics, and environment\" by\nMartin Kaltschmitt, Wolfgang Streicher, Andreas Wiese, (Springer, 2007, {{ISBN|3-540-70947-9}}, {{ISBN|978-3-540-70947-3}}), page 55\n\n==Gliding==\n\n[[File:FAA-8083-13 Fig 7-20.PNG|thumb|right|Glider ground launch wind gradient effect.]]\nIn gliding, wind gradient affects the takeoff and landing phases of flight of a [[Glider (sailplane)|glider]].\nWind gradient can have a noticeable effect on [[ground launch]]es. If the wind gradient is significant or sudden,\nor both, and the pilot maintains the same pitch attitude, the indicated airspeed will increase, possibly exceeding\nthe maximum ground launch tow speed. The pilot must adjust the airspeed to deal with the effect of the\ngradient.<ref>{{cite book\n | title = Glider Flying Handbook\n | year = 2003\n | publisher = U.S. Federal Aviation Administration\n | location = U.S. Government Printing Office, Washington D.C.\n | id = FAA-8083-13_GFH\n | pages = 7–16\n | url=http://www.faa.gov/library/manuals/aircraft/glider_handbook/\n }}</ref>\n\nWhen landing, wind gradient is also a hazard, particularly when the winds are strong.<ref>{{cite book | last = Longland | first = Steven | title = Gliding | publisher = Crowood Press, Limited, The | location = City | year = 2001 | isbn = 978-1-86126-414-5 | pages= 125 | quote=The reason for making the increase is because the wind speed increases with height (a `wind gradient')}}</ref> As the glider descends through the wind gradient on final approach to landing, airspeed decreases while sink rate increases, and there is insufficient time to accelerate prior to ground contact. The pilot must anticipate the wind gradient and use a higher approach speed to compensate for it.<ref name=Piggott>{{cite book | last = Piggott | first = Derek | title = Gliding: a Handbook on Soaring Flight | publisher = Knauff & Grove | location =  | year = 1997 | isbn = 978-0-9605676-4-5 | pages = 85–86, 130–132 | quote= The wind gradient is said to be steep or pronounced when the change in wind speed with height is very rapid, and it is in these conditions that extra care must be used when taking off or landing in a glider}}</ref>\n\nWind gradient is also a hazard for aircraft making steep turns near the ground. It is a particular problem for gliders which have a relatively long [[wingspan]], which exposes them to a greater wind speed difference for a given [[Roll (flight)|bank]] angle. The different airspeed experienced by each wing tip can result in an aerodynamic stall on one wing, causing a loss of control accident.<ref name=Piggott/><ref>{{cite book | last = Knauff | first = Thomas | title = Glider Basics from First Flight to Solo | publisher = Thomas Knauff | location =  | year = 1984 | isbn = 978-0-9605676-3-8 }}</ref> The rolling moment generated by the different airflow over each wing can exceed the [[aileron]] control authority, causing the glider to continue rolling into a steeper bank angle.<ref name=Conway>{{cite book | last = Conway | first = Carle | title = Joy of Soaring | publisher = Soaring Society of America, Incorporated | location = City | year = 1989 | isbn = 978-1-883813-02-4 }} If the pilot runs into the wind gradient as he is turning into the wind, there will obviously be less wind across the lower than the higher wing.</ref>\n\n{{Further information|Gliding}}\n\n==Sailing==\nIn [[sailing]], wind gradient affects [[sailboats]] by presenting a different wind speed to the [[sail]] at different heights along the [[mast (sailing)|mast]]. The direction also varies with height, but sailors refer to this as \"wind shear.\"<ref>{{cite book | last = Jobson | first = Gary | title = Gary Jobson's Championship Sailing | publisher = International Marine/Ragged Mountain Press | location = City | year = 2004 | isbn = 978-0-07-142381-6 | pages = 180 | quote=Wind shear is the difference in direction at varying heights above the water; wind gradient is the difference in wind strength at varying heights above the water.}}</ref>\n\nThe mast head instruments indication of apparent wind speed and direction is different from what the sailor sees and feels near the surface.<ref name=Jobson>{{cite book | last = Jobson | first = Gary | title = Championship Tactics: How Anyone Can Sail Faster, Smarter, and Win Races | publisher = St. Martin's Press | location = New York | year = 1990 | isbn = 978-0-312-04278-3 | pages = 323 | quote = You'll not recognize wind shear if your apparent wind angle is smaller on one tack than on the other because the apparent wind direction is a combination of boat speed and wind speed - and the sailing speed may be more determined by water conditions in one direction rather than another. This means that the faster a boat goes the more 'ahead' the apparent wind becomes. That is why the 'close reach' direction is the fastest direction of sailing – simply because as the boat speeds up the apparent wind direct goes further and further forward without stalling the sails and the apparent wind speed also increases – so increasing the boat's speed even further. This particular factor is exploited to the full in sand-yachting in which it is common for a sand yacht to exceed the wind speed as measured by a stationary observer. Wind shear is certainly felt because the wind speed at the masthead will be higher than at deck level. Thus gusts of wind can capsize a small sailing boat easily if the crew are not sufficiently wary.}}</ref><ref name=Garrett/> [[Sailmaker]]s may introduce [[sail twist]] in the design of the sail, where the head of the sail is set at a different angle of attack from the foot of the sail in order to change the [[lift distribution]] with height. The effect of wind gradient can be factored into the selection of twist in the sail design, but this can be difficult to predict since the wind gradient may vary widely in different weather conditions.<ref name=Garrett/> [[Sailors]] may also adjust the trim of the sail to account for wind gradient, for example using a [[boom vang]].<ref name=Garrett>{{cite book | last = Garrett | first = Ross | title = The Symmetry of Sailing | publisher = Sheridan House | location = Dobbs Ferry | year = 1996 | pages = 97–99, 108 | isbn = 978-1-57409-000-0 | quote = Wind speed and direction are normally measured at the top of the mast, and the wind gradient must therefore be known in order to determine the mean wind speed incident on the sail.}}</ref>\n\nAccording to one source,<ref>{{cite book\n  |last = Bethwaite\n  |first = Frank\n  |title = High Performance Sailing\n  |publisher = Waterline (1993), Thomas Reed Publications (1996, 1998, and 2001), and Adlard Coles Nautical (2003 and 2007)\n  |year = first published in 1993; new edition in 1996, reprinted in 2007\n  |isbn = 978-0-7136-6704-2}} See sections 3.2 and 3.3.</ref> the wind gradient is not significant for sailboats when the wind is over 6 knots (because a wind speed of 10 knots at the surface corresponds to 15 knots at 300 meters, so the change in speed is negligible over the height of a sailboat's mast).  According to the same source, the wind increases steadily with height up to about 10 meters in 5 knot winds but less if there is less wind. That source states that in winds with average speeds of six knots or more, the change of speed with height is confined almost entirely to the one or two meters closest to the surface.<ref>See p. 11 of the cited book by Bethwaite</ref>  This is consistent with another source, which shows that the change in wind speed is very small for heights over 2 meters<ref>http://www.onemetre.net/Design/Gradient/Gradient.htm concerning design of radio-controlled model yachts</ref> and with a statement by the Australian Government Bureau of Meteorology<ref>http://www.bom.gov.au/weather/nsw/amfs/Wind%20Shear.shtml</ref> according to which differences can be as little as 5% in unstable air.<ref>As explained in Bethwaite's book, the air is turbulent near the surface if the wind speed is greater than 6 knots</ref>\n\nIn [[kitesurfing]], the wind gradient is even more important, because the [[power kite]] is flown on 20-30m lines,<ref>{{cite book | last = Currer | first = Ian | title = Kitesurfing | publisher = Lakes Paragliding | location = City | year = 2002 | isbn = 978-0-9542896-0-7 | pages = 27}}</ref> and the kitesurfer can use the kite to jump off the water, bringing the kite to even greater heights above the sea surface.\n\n==Sound propagation==\n\nWind gradient can have a pronounced effect upon sound propagation in the lower atmosphere. This effect is important in understanding sound propagation from distant sources, such as [[foghorn]]s, [[thunder]], [[sonic boom]]s, [[gunshot]]s or other phenomena like [[mistpouffers]]. It is also important in studying [[noise pollution]], for example from [[roadway noise]] and [[aircraft noise]], and must be considered in the design of [[noise barrier]]s.<ref>{{cite journal \n| publisher = Washington State Department of Transportation. \n| url = http://www.wsdot.wa.gov/Research/Reports/000/033.1.htm \n| title = Ground Plane Wind Shear Interaction on Acoustic Transmission\n| accessdate = 2007-05-30\n| version = WA-RD 033.1\n| author = Foss, Rene N. \n| date = June 1978 \n}}</ref>\nWhen wind speed increases with altitude, wind blowing towards the listener from the source will refract sound waves downwards, resulting in increased noise levels downwind of the barrier.<ref name=Bies>{{cite book | last = Bies | first = David | title = Engineering Noise Control; Theory and Practice | publisher = Spon Press | location = London | year = 2003 | isbn = 978-0-415-26713-7 | pages = 235 | quote = As wind speed generally increases with altitude, wind blowing towards the listener from the source will refract sound waves downwards, resulting in increased noise levels.}}</ref>  These effects were first quantified in the field of highway engineering to address variations of noise barrier efficacy in the 1960s.<ref>[http://www.springerlink.com/content/x1707075n815g604/  C.Michael Hogan, '' Analysis of Highway Noise'', Journal of Water, Air, & Soil Pollution, Vol. 2, No. 3, Biomedical and Life Sciences and Earth and Environmental Science Issue, Pages 387–392, September 1973, Springer Verlag, Netherlands {{ISSN|0049-6979}}]</ref>\n\nWhen the sun warms the Earth's surface, there is a negative [[temperature gradient]] in atmosphere. The [[speed of sound]] decreases with decreasing temperature, so this also creates a negative [[sound speed gradient]].<ref>{{cite book\n|title=Sound Reinforcement Engineering\n|first=Wolfgang\n|last=Ahnert\n|publisher=Taylor & Francis\n|year=1999\n|pages=40\n|isbn=978-0-419-21810-4}}</ref> The sound wave front travels faster near the ground, so the sound is [[refraction (sound)|refracted]] upward, away from listeners on the ground, creating an [[acoustic shadow]] at some distance from the source.<ref>{{cite book | last = Everest | first = F. | title = The Master Handbook of Acoustics | publisher = McGraw-Hill | location = New York | year = 2001 | isbn = 978-0-07-136097-5 | pages = 262–263 }}</ref> The radius of curvature of the sound path is inversely proportional to the velocity gradient.<ref>{{cite book\n|title=Noise Control\n|chapter=10. Outdoor sound propagation\n|series=ME 458: Engineering Noise Control\n|year=2000\n|first=J. S. \n|last=Lamancusa\n|url=http://www.mne.psu.edu/lamancusa/me458/10_osp.pdf\n|publisher=[[Penn State University]]\n|location=State College, PA\n|format=pdf\n|pages=10.6–10.7\n}}</ref>\n\nA wind speed gradient of 4 (m/s)/km can produce refraction equal to a typical temperature [[lapse rate]] of 7.5&nbsp;°C/km.<ref>{{cite book | last = Uman | first = Martin | title = Lightning | publisher = Dover Publications | location = New York | year = 1984 | isbn = 978-0-486-64575-9 | pages = 196 }}</ref> Higher values of wind gradient will refract sound downward toward the surface in the downwind direction,<ref>{{cite book | last = Volland | first = Hans | title = Handbook of Atmospheric Electrodynamics | publisher = CRC Press | location = Boca Raton | year = 1995 | isbn = 978-0-8493-8647-3 | pages = 22}}</ref> eliminating the acoustic shadow on the downwind side. This will increase the audibility of sounds downwind. This downwind refraction effect occurs because there is a wind gradient; the sound is not being carried along by the wind.<ref>{{cite book | last = Singal | first = S. | title = Noise Pollution and Control Strategy | publisher = Alpha Science International, Ltd | location =  | year = 2005 | isbn = 978-1-84265-237-4 | pages = 7 | quote = It may be seen that refraction effects occur only because there is a wind gradient and it is not due to the result of sound being convected along by the wind.}}</ref>\n\nThere will usually be both a wind gradient and a temperature gradient. In that case, the effects of both might add together or subtract depending on the situation and the location of the observer.<ref>{{cite book\n|publisher=Royal School Of Artillery\n|series=Basic Science & Technology Section\n|title=N01-N07 Sound Ranging\n|date=2002-12-19\n|pages=N–12\n|url=http://www.army.mod.uk/linkedfiles/royalartillery/units/royal_school_of_artillery/bst_handout_n01.pdf\n|quote=...there will usually be both a wind gradient and a temperature gradient.}}</ref>\nThe wind gradient and the temperature gradient can also have complex interactions. For example, a foghorn can be audible at a place near the source, and a distant place, but not in a sound shadow between them.<ref>{{cite journal\n|title=Fog Signals: Areas of Silence and Greatest Range of Sound\n|author=Mallock, A.\n|journal=Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character\n|volume= 91 \n|date=1914-11-02\n|pages= 71–75|doi=10.1098/rspa.1914.0103\n|issue= 623\n|bibcode = 1914RSPSA..91...71M }}</ref>\nIn the case of transverse sound propagation, wind gradients do not sensibly modify sound propagation relative to the windless condition; the gradient effect appears to be important only in upwind and downwind configurations.<ref name=Malbequi1993>{{cite journal\n | author = Malbequi, P. |author2=Delrieux, Y. |author3=Canard-caruana, S.\n | year = 1993\n | title = Wind tunnel study of 3D sound propagation in presence of a hill and of a wind gradient\n | journal = ONERA, TP No\n | volume = 111\n | pages = 5\n | bibcode = 1993ONERA....R....M\n }}</ref>\n\nFor sound propagation, the exponential variation of wind speed with height can be defined as follows:<ref name=Bies/>\n\n:<math>\\ U(h) = U(0) h ^ \\zeta\n</math>\n\n:<math>\\ \\frac {dU} {dH} = \\zeta \\frac {U(h)} {h}\n</math>\n\nwhere:\n\n:<math> \\ U(h)</math> = speed of the wind at height <math> \\ h</math>, and <math> \\ U(0)</math> is a constant\n:<math> \\ \\zeta</math> = exponential coefficient based on ground surface roughness, typically between 0.08 and 0.52\n:<math> \\ \\frac {dU} {dH}</math> = expected wind gradient at height <math> h</math>\n\nIn the 1862 [[American Civil War]] [[Battle of Iuka]], an [[acoustic shadow]], believed to have been enhanced by a northeast wind, kept two divisions of Union soldiers out of the battle,<ref>{{cite book | last = Cornwall | first = Sir | title = Grant as Military Commander | publisher = Barnes & Noble Inc | location =  | year = 1996 | isbn = 978-1-56619-913-1 |page =  92}}</ref> because they could not hear the sounds of battle only six miles downwind.<ref>{{cite book | last = Cozzens | first = Peter | title = The Darkest Days of the War: the Battles of Iuka and Corinth | publisher = The University of North Carolina Press | location = Chapel Hill | year = 2006 | isbn = 978-0-8078-5783-0 }}</ref>\n\nScientists have understood the effect of wind gradient upon [[refraction]] of sound since the mid-1900s; however, with the advent of the U.S. [[Noise Control Act]], the application of this refractive phenomena became applied widely beginning in the early 1970s, chiefly in the application to noise propagation from [[highway]]s and resultant design of transportation facilities.<ref>Hogan, C. Michael and Gary L. Latshaw, [http://www.worldcatlibraries.org/wcpa/top3mset/2930880 \"The Relationship between Highway Planning and Urban Noise\"], Proceedings of the ASCE, Urban Transportation Division specialty conference, May 21/23, 1973, Chicago, Ill., [[American Society of Civil Engineers]]</ref>\n\n{{further information|Sound}}\n\n==Wind gradient soaring==\n[[File:Black-browed albatross.jpg|thumb|left|This [[albatross]] is an expert in [[dynamic soaring]] using the wind gradient.]]\nWind gradient soaring, also called [[dynamic soaring]], is a technique used by [[soaring birds]] including [[albatross]]es. If the wind gradient is of sufficient magnitude, a bird can climb into the wind gradient, trading ground speed for height, while maintaining airspeed.<ref>{{cite book | last = Alexander | first = R. | title = Principles of Animal Locomotion | publisher = Princeton University Press | location = Princeton | year = 2002 | pages = 206 | isbn = 978-0-691-08678-1 }}</ref> By then turning downwind, and diving through the wind gradient, they can also gain energy.<ref>{{cite book | last = Alerstam | first = Thomas | title = Bird Migration | publisher = Cambridge University Press | location = Cambridge | year = 1990 | pages = 275 | isbn = 978-0-521-44822-2 }}</ref>\n\n==See also==\n*[[Wind shear]]\n{{clear}}\n\n==References==\n{{reflist|2}}\n\n{{DEFAULTSORT:Wind Gradient}}\n[[Category:Wind]]\n[[Category:Weather hazards to aircraft]]\n[[Category:Microscale meteorology]]\n[[Category:Spatial gradient]]\n\n[[pt:Gradiente de vento]]"
    },
    {
      "title": "Chandrasekhar's variational principle",
      "url": "https://en.wikipedia.org/wiki/Chandrasekhar%27s_variational_principle",
      "text": "In [[astrophysics]], '''Chandrasekhar's variational principle''' provides the stability criterion for a static [[barotropic]] [[star]], subjected to radial perturbation, named after the [[Indian American]] [[astrophysicist]] [[Subrahmanyan Chandrasekhar]].\n\n==Statement<ref>Chandrasekhar, S. \"A general variational principle governing the radial and the non-radial oscillations of gaseous masses.\" VI. Ellipsoidal Figures of Equilibrium 1.2 (1960).</ref><ref>Chandrasekhar, Subrahmanyan. Hydrodynamic and hydromagnetic stability. Courier Corporation, 2013.</ref><ref>Binney, James, and Scott Tremaine. Galactic dynamics. Princeton university press, 2011.</ref>==\n\n''A baratropic star with <math>\\frac{d\\rho}{dr}<0</math> and <math>\\rho(R)=0</math> is stable if the quantity''\n\n:<math>\\mathcal{E}(\\rho') = \\int_V \\left| \\frac{d\\Phi}{d\\rho}\\right|_0 \\rho'^2 d \\mathbf{x} - G \\int_V\\int_V \\frac{\\rho'(\\mathbf{x})\\rho'(\\mathbf{x'})}{|\\mathbf{x}-\\mathbf{x'}|} d\\mathbf{x}d\\mathbf{x'} \\quad \\text{where} \\quad \\Phi = -G\\int_V \\frac{\\rho(\\mathbf{x'})}{|\\mathbf{x}-\\mathbf{x'}|}d\\mathbf{x},</math>\n\n''is non-negative for all real functions <math>\\rho'(\\mathbf{x})</math> that conserve the total mass of the star <math>\\int_V \\rho' d\\mathbf{x} = 0</math>.''\n\nwhere\n*<math>\\mathbf{x}</math> is the coordinate system fixed to the center of the star\n*<math>R</math> is the radius of the star\n*<math>V</math> is the volume of the star\n*<math>\\rho(\\mathbf{x})</math> is the unperturbed [[density]]\n*<math>\\rho'(\\mathbf{x})</math> is the small perturbed density such that in the perturbed state, the total density is <math>\\rho+\\rho'</math>\n*<math>\\Phi</math> is the self-gravitating potential from [[Newton's law of gravity]]\n*<math>G</math> is the [[Gravitational constant]]\n\n\n==References==\n{{Reflist}}\n\n[[Category:Variational principles]]\n[[Category:Stellar dynamics]]\n[[Category:Astrophysics]]\n[[Category:Fluid dynamics]]"
    },
    {
      "title": "Fermat Prize",
      "url": "https://en.wikipedia.org/wiki/Fermat_Prize",
      "text": "The '''Fermat prize''' of [[mathematics|mathematical]] [[research]] bi-annually rewards research works in fields where the contributions of [[Pierre de Fermat]] have been decisive:\n\n* Statements of [[variational principle]]s\n* Foundations of [[probability]] and [[analytic geometry]]\n* [[Number theory]]. \n\nThe spirit of the prize is focused on rewarding the results of research accessible to the greatest number of professional [[mathematicians]] within these fields. The Fermat prize was created in 1989 and is awarded once every two years in [[Toulouse]] by the [[Institut de Mathématiques de Toulouse]]. The amount of the Fermat prize has been fixed at 20,000 Euros for the twelfth edition (2011).\n\n== Previous prize winners ==\n\n*'''1989''' Awarded jointly to '''[[Abbas Bahri]]''' for the introduction of new methods in the [[calculus of variations]] and to '''[[Kenneth Ribet]]''' for his contribution to [[number theory]] and [[Fermat's Last Theorem]].\n*'''1991''' Awarded to '''[[Jean-Louis Colliot-Thélène]]''' for his work on [[number theory]] and rational manifolds the research for which was undertaken to a large extent with [[Jean-Jacques Sansuc]].\n*'''1993''' Awarded to '''[[Jean-Michel Coron]]''' for his contributions to the study of [[calculus of variations|variational problems]] and [[control theory]].\n*'''1995''' Awarded to '''[[Andrew Wiles]]''' for his works on the [[Modularity theorem|Taniyama–Shimura–Weil conjecture]] which resulted in the demonstration of the proof of [[Fermat's Last Theorem]].\n*'''1997''' Awarded to '''[[Michel Talagrand]]''' for his fundamental contributions in various domains of [[probability theory|probability]].\n*'''1999''' Awarded jointly to '''[[Fabrice Béthuel]]''' and '''[[Frédéric Hélein]]''' for several important contributions to the [[variational calculus|theory of variational calculus]], which have consequences in Physics and Geometry.\n*'''2001''' Awarded jointly to '''[[Richard Taylor (mathematician)|Richard Taylor]]''' for his various contributions to the study of links between [[Galois representations]] and [[automorphic form]]s and to '''[[Wendelin Werner]]''' for his works on the intersection exponents of [[Brownian motion]] and their impact in theoretical Physics.\n*'''2003''' Awarded to '''[[Luigi Ambrosio]]''' for his impressive contributions to the [[calculus of variations]] and [[geometric measure theory]], and their link with [[partial differential equation]]s.\n*'''2005''' Awarded jointly to '''[[Pierre Colmez]]''' for his contributions to the study of [[L-function]]s and p-adic [[Galois representations]] and to '''[[Jean-François Le Gall]]''' for his contributions to the fine analysis of planar [[Brownian motion]]s, his invention of the Brownian snake and its applications to the study of non-linear [[partial differential equations]].\n*'''2007''' Awarded to '''[[Chandrashekhar Khare]]''' for his proof (with [[Jean-Pierre Wintenberger]]) of the [[Serre conjecture (number theory)|Serre modularity conjecture in number theory]]. \n*'''2009''' Awarded jointly to '''[[Elon Lindenstrauss]]''' for his contributions to ergodic theory and their applications in number theory;  and to '''[[Cédric Villani]]''' for his contributions to the theory of optimal transport and his studies of non-linear evolution equations.\n*'''2011''' Awarded jointly to '''[[Manjul Bhargava]]''' for his work on various generalizations of the Davenport-Heilbronn estimates and for his recent startling results (with [[Arul Shankar]]) on the average rank of elliptic curves;  and to '''[[Igor Rodnianski]]''' for his fundamental contributions to the studies of the equations of general relativity and to the propagation of the light on the space-time curves (in collaboration with [[Mihalis Dafermos]], [[Sergiu Klainerman]], and [[Hans Lindblad]]).\n*'''2013''' Awarded jointly to '''[[Camillo De Lellis]]''' for his fundamental contributions (in collaboration with László Székelyhidi) to the conjecture of Onsager about dissipative solutions of the Euler-equations and for his work to the regularity of minimal surfaces; and to '''[[Martin Hairer ]]''' for his contributions to the analysis of stochastic partial differential equations, especially for the regularity of their solutions and convergence to the equilibrium.\n*'''2015''' Awarded jointly to '''[[Laure Saint-Raymond]]''' for the development of asymptotic theories of partial differential equations, including the fluid limits of rarefied flows, multiscale analysis in plasma physics equations and ocean modeling, and the derivation of the Boltzmann equation from interacting particle systems; and to '''[[Peter Scholze]]''' for his invention of perfectoid spaces and their application to fundamental problems in algebraic geometry and in the theory of automorphic forms.<ref>[https://www.math.univ-toulouse.fr/spip.php?article648&lang=en Fermat Prize 2015]</ref>\n*'''2017''' Awarded jointly to '''[[Simon Brendle]]''' for his numerous and profound results in geometric analysis, involving partial differential equations of elliptic, parabolic and hyperbolic type; in particular for his elegant proof of Lawson's conjecture, for his characterization of soliton solutions of Ricci flows and mean curvature in dimension 3 as well as for his remarkable contributions, in collaboration with Gerhard Huisken, to the analysis of mean curvature flow of mean convex surfaces in manifolds of dimension 3; and to '''{{ill|Nader Masmoudi|fr}}''' for his remarkable work of depth and creativity in the analysis of nonlinear partial differential equations and in particular for his recent contributions to the rigorous and complete resolution of hydrodynamic stability problems raised at the end of the 19th century by the founding fathers of modern fluid mechanics.<ref>[https://www.math.univ-toulouse.fr/spip.php?article736 Fermat Prize 2017]</ref>\n\n==Pierre Fermat medal==\nThere has also been a ''Pierre Fermat medal'', which has been awarded for example to [[Linus Pauling]] (1957)<ref>{{cite web|url=http://scarc.library.oregonstate.edu/coll/pauling/awards///1957h.4.html |title=Linus Pauling: Awards, Honors and Medals |publisher=Oregon State University Libraries |accessdate=January 24, 2017}}</ref> and [[Ernst Peschl]] (1965).\n\n== Junior Fermat Prize ==\n\nThe Junior Fermat Prize is a mathematical prize, awarded every two years to a student in the first four years of university for a contribution to mathematics. The amount of the prize is 2000 [[Euro]]s.\n\n== References ==\n<references />\n\n== External links ==\n* [http://www.math.univ-toulouse.fr/spip.php?article240&lang=fr Fermat Prize official web site]\n* [http://www.math.univ-toulouse.fr/spip.php?article246 Junior Fermat Prize official web site] \n* [http://www.numdam.org/numdam-bin/feuilleter?j=AFST&sl=0 Annales de la faculté des sciences de Toulouse]\n\n{{DEFAULTSORT:Fermat, Prize}}\n[[Category:Mathematics awards]]\n[[Category:Awards established in 1989]]\n[[Category:Variational principles]]\n[[Category:Number theory|.]]"
    },
    {
      "title": "Fermat’s and energy variation principles in field theory",
      "url": "https://en.wikipedia.org/wiki/Fermat%E2%80%99s_and_energy_variation_principles_in_field_theory",
      "text": "In [[general relativity]], light is assumed to propagate in a [[vacuum]] along a [[null geodesic]] in a [[pseudo-Riemannian manifold]]. Besides the geodesics principle in a [[classical field theory]] there exists [[Fermat's principle]] for [[stationary spacetime|stationary gravity fields]].<ref name = \"Land\">{{Citation|author=Landau, Lev D.|authorlink=Lev Landau|author2= Lifshitz, Evgeny F.| author2-link=Evgeny Lifshitz|title=The Classical Theory of Fields (4th ed.)|location=London|publisher=[[Butterworth-Heinemann]]|date=1980|isbn=9780750627689| page = 273}}</ref>\n\n== Fermat's principle ==\n\nIn the general case of [[Conformal manifold|conformally]] [[stationary spacetime]] <ref name = \"Perl\">{{Citation|author= Perlik, Volker |title=Gravitational Lensing from a Spacetime Perspective|journal= Living Rev. Relativ.| volume=7| date=2004| issue=9|at=Chapter 4.2}}</ref>  with [[coordinates]] <math>(t,x^1,x^2,x^3) </math> a Fermat [[Metric tensor|metric]] takes the form\n\n:<math>g=e^{2f(t,x)}[(dt+\\phi_{\\alpha}(x)dx^{\\alpha})^{2}-\\hat{g}_{\\alpha\\beta} dx^{\\alpha} dx^{\\beta}]</math>,\n\nwhere the conformal factor <math>f(t,x)</math> depends on time <math>t</math> and [[space]] coordinates <math>x^{\\alpha}</math> and does not affect the [[lightlike]] geodesics apart from their parametrization.\n\nFermat's principle for a pseudo-Riemannian manifold states that the light ray path between points <math>x_a=(x^1_a,x^2_a,x^3_a) </math> and <math>x_b=(x^1_b,x^2_b,x^3_b) </math> corresponds to stationary [[Action (physics)|action]].\n\n:<math>S=\\int^{\\mu_a}_{\\mu_b}\\left(\\sqrt{\\hat{g}_{\\alpha\\beta} \\frac{dx^{\\alpha}}{d\\mu} \\frac{dx^{\\beta}}{d\\mu}}+\\phi_{\\alpha}(x)\\frac{dx^{\\alpha}}{d\\mu} \\right) d\\mu</math>,\n\nwhere  <math>\\mu</math> is any parameter ranging over an [[Interval (mathematics)|interval]] <math>[\\mu_a, \\mu_b] </math>  and varying along [[curve]] with fixed endpoints <math>x_a=x(\\mu_a) </math>  and <math>x_b=x(\\mu_b)</math>.\n\n==Principle of stationary integral of energy ==\n\nIn principle of stationary integral of energy for a light-like particle's motion <ref name = \"Ext\">{{Citation| last1=D. Yu. | first1= Tsipenyuk|last2=W. B. | first2=Belayev | title=Extended space model is consistent with the photon dynamics in the gravitational field|journal= J. Phys.: Conf. Ser.| volume=1251| date=2019| issue=012048 | url=https://iopscience.iop.org/article/10.1088/1742-6596/1251/1/012048/pdf }}</ref>, the pseudo-Riemannian metric with coefficients <math>\\tilde{g}_{ij}</math> is defined by a transformation\n\n:<math> \\tilde{g}_{00} =\\rho ^{2}{g}_{00} ,\\,\\,\\,\\, \\tilde{g}_{0k}=\\rho{g}_{0k} ,\\,\\,\\,\\, \\tilde{g}_{kq} ={g}_{kq} .</math>\n\nWith time coordinate <math>x^0</math> and space coordinates with indexes ''k,q=1,2,3'' the [[line element]] is written in form\n\n:<math> ds^2=\\rho^2 g_{00}(dx^{0})^{2}+ 2\\rho g_{0k}dx^{0}dx^{k}+g_{kq}dx^{k}dx^{q},</math>\n       \nwhere <math>\\rho </math>  is some quantity, which is assumed equal 1 and regarded as the energy of the light-like particle with <math>ds=0</math>. Solving this equation for <math>\\rho </math> under condition <math>g_{00} \\ne 0</math>  gives two solutions\n\n:<math>\\rho =\\frac{-g_{0k} v^{k} \\pm \\sqrt{(g_{0k} g_{0q} -g_{00} g_{kq})v^{k} v^{q} } }{g_{00} v^{0} },</math>\n           \nwhere <math>v^{i}=dx^i/d\\mu</math> are elements of the [[four-velocity]]. Even if one solution, in accordance with making definitions, is <math>\\rho=1 </math>.\n\nWith <math>g_{00}=0</math>  and <math>g_{0k} \\ne 0</math> even if for one ''k'' the energy takes form\n\n:<math>\\rho =-\\frac{g_{kq} v^{k} v^{q} }{2v_{0} v^{0}}.</math>\n\nIn both cases for the [[Free motion equation|free moving]] particle the [[Lagrangian mechanics|Lagrangian]] is\n\n:<math>L= -\\rho.</math>\n                                                                       \nIts [[partial derivatives]] give the [[Momentum|canonical momenta]]\n\n:<math>p_{\\lambda}=\\frac{\\partial L}{\\partial v^{\\lambda}}=\\frac{v_{\\lambda}}{v^{0}v_{0}}</math>\n                                                      \nand the [[forces]]\n\n: <math>F_{\\lambda}=\\frac{\\partial L }{\\partial x^{\\lambda}}=\\frac{1}{2v^{0}v_{0}}\\frac{\\partial g_{ij}}{\\partial x^{\\lambda}}v^{i}v^{j}.</math>\n\nMomenta satisfy energy condition <ref name = \"Land2\">{{Citation|author=Landau, Lev D.|authorlink=Lev Landau|author2= Lifshitz, Evgeny F.| author2-link=Evgeny Lifshitz|title= Mechanics Vol. 1 (3rd ed.)|location=London|publisher=Butterworth-Heinemann|date=1976|isbn=9780750628969| page = 14}}</ref>\nfor [[closed system]]  \n             \n:<math>\\rho=v^{\\lambda}p_{\\lambda}-L,</math>\n\nand thus <math>\\rho</math> is [[Hamiltonian mechanics|Hamiltonian]].\n\nStandard [[variational method|variational procedure]] according to [[Hamilton's principle]] is applied to action\n\n:<math> S=\\int^{\\mu_a}_{\\mu_b}L d\\mu=-\\int^{\\mu_a}_{\\mu_b}\\rho d\\mu, </math>\n \nwhich is integral of energy. Stationary action is conditional upon zero variational derivatives {{math|''δS''/''δx''<sup>λ</sup> }}\nand leads to [[Euler–Lagrange equations]]\n\n:<math>\\frac{d}{d\\mu}\\frac{\\partial \\rho }{\\partial v^{\\lambda}}-\\frac{\\partial \\rho }{\\partial x^{\\lambda}}=0,</math>\n\nwhich is rewritten in form\n\n:<math>\\frac{d}{d\\mu} p_{\\lambda}-F_{\\lambda}=0.</math>\n\nAfter substitution of canonical momentum and forces they give motion equations of lightlike particle in a [[free space]]\n\n:<math>\\frac{dv^{0}}{d\\mu}+\\frac{v^{0}}{2v_{0}}\\frac{\\partial g_{ij}}{\\partial x^{0}}v^{i}v^{j}=0</math>\n\nand\n\n:<math> (g_{k\\lambda} v_{0}-g_{0k}v_{\\lambda})\\frac{dv^{k}}{d\\mu}+\\left[\\frac{1}{2v_{0}}\\frac{\\partial g_{ij}}{\\partial x^{0}}(g_{00}v^{0}v_{\\lambda}+ g_{k\\lambda}v^{k}v_{0})-\\frac{1}{2}\\frac{\\partial g_{ij}}{\\partial x^{\\lambda}}v_{0} +\\frac{\\partial g_{i\\lambda}}{\\partial x^{j}}v_0- \\frac{\\partial g_{0i}}{\\partial x^{j}}v_{\\lambda}\\right]v^i v^j=0.</math>\n\n== Static spacetime ==\nFor the [[Isotropic_line|isotropic paths]] a transformation to metric <math> \\overline{g}_{ij}=g_{ij}/{g_{00}}</math> is equivalent to replacement of parameter <math>\\mu</math>  on <math>d\\overline{\\mu}=d\\mu/\\sqrt{g_{00}}</math> to which the four-velocities <math>\\overline{v}^{i}=dx^i/d\\overline{\\mu}</math> correspond. The curve of motion of lightlike particle in [[four-dimensional space]]time and value of energy <math>\\rho </math>  are [[invariant (physics)|invariant]] under this reparametrization. \nFor the [[static spacetime]] the first equation of motion with appropriate parameter <math>\\overline \\mu</math>  gives <math>\\overline v^0=1</math> . Canonical momentum and forces take form\n\n:<math>\\overline{p}_{\\lambda}=\\overline v_{\\lambda}; \\qquad \\overline{F}_{\\lambda}=\\frac{1}{2}\\frac{\\partial \\overline{g}_{ij}}{\\partial x^{\\lambda}}\\overline{v}^{i}\\overline{v}^{j}.</math>\n\nSubstitution of them in Euler–Lagrange equations gives\n\n:<math>\\frac{d}{d\\mu}\\left(\\overline{g}_{\\lambda k} \\overline{v}^k\\right)=\\frac{1}{2}\\frac{\\partial \\overline{g}_{ij}}{\\partial x^{\\lambda}}\\overline{v}^{i}\\overline{v}^{j}</math>.\n\nAfter differentiation on the left side and multiplying by <math>\\overline{g}^{l \\lambda}</math> this expression, after the summation over the repeated index <math>\\lambda</math>, becomes null geodesic equations\n\n:<math>\\frac{d^2 x^l}{d\\overline{\\mu}^2}+\\Gamma^l_{ij} \\frac{dx^i}{d\\overline{\\mu}}\\frac{dx^j}{d\\overline{\\mu}}=0,</math>\n\nwhere <math>\\Gamma^l_{ij}</math> are the second kind [[Christoffel symbols]] with respect to the [[metric tensor]] <math> \\overline{g}_{ij}</math>.\n\nSo in case of the static spacetime the geodesic principle and the energy variational method as well as Fermat's principle give the same solution for the light propagation.\n\n==See also==\n*[[Fermat's principle]]\n\n== References ==\n\n{{reflist}}\n\n==Further reading==\n\n*{{Cite journal\n|last=Belayev\n|first=W. B.\n|title=Application of Lagrange mechanics for analysis of the light-like particle motion in pseudo-Riemann space\n|arxiv=0911.0614\n|date=2011\n|ref=harv\n|postscript=.\n|bibcode=2009arXiv0911.0614B\n}}\n\n{{DEFAULTSORT:Fermat's and energy variation principles in field theory}}\n[[Category:Theories of gravitation]]\n[[Category:Variational principles]]"
    },
    {
      "title": "Geometric mechanics",
      "url": "https://en.wikipedia.org/wiki/Geometric_mechanics",
      "text": "'''Geometric mechanics''' is a branch of mathematics applying particular geometric methods to many areas of mechanics, from mechanics of particles and [[rigid body mechanics|rigid bodies]] to [[fluid mechanics]] to [[control theory]].\n\nGeometric mechanics applies principally to systems for which the [[Configuration space (mathematics)|configuration space]] is a [[Lie group]], or a group of [[diffeomorphism]]s, or more generally where some aspect of the configuration space has this group structure. For example, the configuration space of a rigid body such as a satellite is the group of Euclidean motions (translations and rotations in space), while the configuration space for a liquid crystal is the group of diffeomorphisms coupled with an internal state (gauge symmetry or order parameter).\n\n== Momentum map and reduction ==\nOne of the principal ideas of geometric mechanics is ''reduction'', which goes back to Jacobi's elimination of the node in the 3-body problem, but in its modern form is due to K. Meyer (1973) and independently J.E. Marsden and A. Weinstein (1974), both inspired by the work of Smale (1970).  Symmetry of a Hamiltonian or Lagrangian system gives rise to conserved quantities, by [[Noether's theorem]], and these conserved quantities are the components of the [[momentum map]] '''J'''.  If ''P'' is the phase space and ''G'' the symmetry group, the momentum map is a map <math>\\mathbf{J}:P\\to\\mathfrak{g}^*</math>, and the reduced spaces are quotients of the level sets of '''J''' by the subgroup of ''G'' preserving the level set in question: for <math>\\mu\\in\\mathfrak{g}^*</math> one defines <math>P_\\mu=\\mathbf{J}^{-1}(\\mu)/G_\\mu</math>, and this reduced space is a symplectic manifold if <math>\\mu</math> is a regular value of ''J''.\n\n==Variational principles ==\n\n* Euler–Lagrange\n* D'Alembert\n* Maupertuis \n* Euler–Poincaré\n* Vakonomic\n*\n\n{{Empty section|date=January 2014}}\n\n== Geometric integrators ==\nOne of the important developments arising from the geometric approach to mechanics is the incorporation of the geometry into numerical methods.\nIn particular symplectic and variational integrators are proving particularly accurate for long-term integration of Hamiltonian and Lagrangian systems.\n\n== History ==\nAs a modern subject, geometric mechanics has its roots in four works written in the 1960s. These were by [[Vladimir Arnold]] (1966),  [[Stephen Smale]] (1970) and [[Jean-Marie Souriau]] (1970), and the first edition of Abraham and Marsden's ''Foundation of Mechanics'' (1967). Arnold's fundamental work showed that Euler's equations for the free rigid body are the equations for geodesic flow on the rotation group SO(3) and carried this geometric insight over to the dynamics of ideal fluids, where the rotation group is replaced by the group of volume preserving diffeomorphisms.  Smale's paper on Topology and Mechanics investigates the conserved quantities arising from Noether's theorem when a Lie group of symmetries acts on a mechanical system, and defines what is now called the momentum map (which Smale calls angular momentum), and he raises questions about the topology of the energy-momentum level surfaces and the effect on the dynamics.  In his book, Souriau also considers the conserved quantities arising from the action of a group of symmetries, but he concentrates more on the geometric structures involved (for example the equivariance properties of this momentum for a wide class of symmetries), and less on questions of dynamics.\n\nThese ideas, and particularly those of Smale were central in the second edition of ''Foundations of Mechanics'' (Abraham and Marsden, 1978).\n\n== Applications ==\n* Computer graphics \n* Control theory &mdash; see Bloch (2003)\n* Liquid Crystals &mdash; see Gay-Balmaz, Ratiu, Tronci (2013)\n* Magnetohydrodynamics\n* Molecular oscillations\n* Nonholonomic constraints &mdash; see Bloch (2003)\n* Nonlinear stability\n* Plasmas &mdash; see Holm, Marsden, Weinstein (1985)\n* Quantum mechanics\n* Superfluids\n* Trajectory planning for space exploration\n* Underwater vehicles\n* Variational integrators\n\n== References ==\n*{{Citation | last1=Abraham | first1=Ralph| author1-link=Ralph Abraham (mathematician) | last2=Marsden | first2=Jerrold E.| author2-link=Jerrold E. Marsden | title=Foundations of Mechanics| year=1978 | edition=2nd| publisher=Addison-Wesley}}\n*{{Citation | last=Arnold | first=Vladimir | author-link=Vladimir Arnold | title=Sur la géométrie différentielle des groupes de Lie de dimension infine et ses applications a l'hydrodynamique des fluides parfaits | journal=Annales de l'Institut Fourier | volume=16| pages=319–361 | year=1966 | doi=10.5802/aif.233| url=http://www.numdam.org/article/AIF_1966__16_1_319_0.pdf }}\n*{{Citation | last=Arnold | first=Vladimir | author-link=Vladimir Arnold | title=Mathematical Methods for Classical Mechanics | publisher=Springer-Verlag | year=1978}}\n*{{cite book | last=Bloch | first=Anthony | title=Nonholonomic Mechanics and Control | publisher=Springer-Verlag | year=2003 }}\n*{{cite journal|last1=Gay-Balmaz|first1=Francois|last2=Ratiu|first2=Tudor|author2-link=Tudor Ratiu| last3=Tronci|first3=Cesare|title=Equivalent Theories of Liquid Crystal Dynamics| journal=Arch. Ration. Mech. Anal. |volume=210|year=2013|pages= 773–811|doi=10.1007/s00205-013-0673-1|arxiv=1102.2918|bibcode=2013ArRMA.210..773G}}\n*{{cite journal| last1=Holm|first1=Darryl D.|last2=Marsden|first2=Jerrold E.|author2-link=Jerrold E. Marsden|last3=Ratiu|first3=Tudor S.|author3-link=Tudor Ratiu|last4=Weinstein|first4=Alan| author4-link=Alan Weinstein|title=Nonlinear stability of fluid and plasma equilibria|journal=Physics Reports|volume=123|year=1985|pages=1–116|doi=10.1016/0370-1573(85)90028-6|bibcode=1985PhR...123....1H}}\n*{{cite book|last1=Libermann | first1=Paulette|author1-link= Paulette Libermann | last2=Marle | first2=Charles-Michel | title=Symplectic geometry and analytical mechanics | series=Mathematics and its Applications | volume=35| publisher=D. Reidel| location=Dordrecht| year=1987| isbn=90-277-2438-5| doi=10.1007/978-94-009-3807-6}}\n*{{Citation | last1=Marsden | first1=Jerrold | author1-link=Jerrold E. Marsden| last2=Weinstein| first2=Alan | author2-link=Alan Weinstein|  title=Reduction of Symplectic Manifolds with Symmetry | journal=Reports on Mathematical Physics | year=1974 | pages=121–130 | volume=5 | doi=10.1016/0034-4877(74)90021-4| bibcode=1974RpMP....5..121M}}\n*{{cite book| last1=Marsden | first1=Jerrold | author1-link=Jerrold E. Marsden| last2=Ratiu | first2=Tudor S. | author2-link=Tudor Ratiu| title=Introduction to mechanics and symmetry | publisher=Springer-Verlag | location=New York | series=Texts in Applied Mathematics | year=1999 | edition=2| isbn=0-387-98643-X}}\n*{{Citation | last=Meyer|first=Kenneth|title=Symmetries and integrals in mechanics|booktitle=Dynamical systems (Proc. Sympos., Univ. Bahia, Salvador, 1971)|year=1973|pages=259–272|publisher=Academic Press|location=New York}}\n*{{cite book| last1=Ortega| first1=Juan-Pablo|last2=Ratiu| first2=Tudor S.| author2-link=Tudor Ratiu| title=Momentum maps and Hamiltonian reduction|publisher = Birkhauser Boston|series=Progress in Mathematics|volume = 222|year = 2004|isbn = 0-8176-4307-9}}\n*{{Citation | last=Smale | first=Stephen | author-link=Stephen Smale| title=Topology and Mechanics I | journal=Inventiones Mathematicae | year=1970 | pages=305–331 | doi= 10.1007/bf01418778| volume=10| bibcode=1970InMat..10..305S}}\n*{{Citation | last=Souriau | first=Jean-Marie | author-link=Jean-Marie Souriau | title=Structure des Systemes Dynamiques | publisher=Dunod | year=1970}}\n\n[[Category:Classical mechanics]]\n[[Category:Hamiltonian mechanics]]\n[[Category:Dynamical systems]]\n[[Category:Symplectic geometry]]\n[[Category:Lagrangian mechanics]]\n[[Category:Variational principles]]"
    },
    {
      "title": "Geodesic",
      "url": "https://en.wikipedia.org/wiki/Geodesic",
      "text": "{{about||geodesics on the [[Earth]]|Geodesics on an ellipsoid|geodesics in [[general relativity]]|Geodesics in general relativity|other uses|Geodesic (disambiguation)}}\n[[File:Spherical triangle.svg|thumb|right|150px|A geodesic triangle on the sphere.\nThe geodesics are [[great circle]] arcs.]]\n\n{{Geodesy}}\n\nIn [[differential geometry]], a '''geodesic''' ({{IPAc-en|ˌ|dʒ|iː|ə|ˈ|d|ɛ|s|ɪ|k|,_|ˌ|dʒ|iː|oʊ|-|,_|-|ˈ|d|iː|-|,_|-|z|ɪ|k}}{{refn|{{cite web |url=https://www.oxforddictionaries.com/definition/english/geodesic |title=geodesic – definition of geodesic in English from the Oxford dictionary |publisher=[[OxfordDictionaries.com]] |access-date=2016-01-20 }}}}{{refn|{{MerriamWebsterDictionary|geodesic}}}}) is a [[curve]] representing in some sense the [[shortest path]] between two points in a [[Differential geometry of surfaces|surface]], or more generally in a [[Riemannian manifold]]. It is a generalization of the notion of a \"[[Line (mathematics)|straight line]]\" to a more general setting. \n\nThe term \"geodesic\" comes from ''[[geodesy]]'', the science of measuring the size and shape of [[Earth]]. In the original sense, a geodesic was the shortest route between two points on the Earth's [[Planetary surface|surface]]. For a [[spherical Earth]], it is a [[line segment|segment]] of a [[great circle]].  The term has been generalized to include measurements in much more general mathematical spaces; for example, in [[graph theory]], one might consider a [[Distance (graph theory)|geodesic]] between two [[vertex (graph theory)|vertices]]/nodes of a [[Graph (discrete mathematics)|graph]].\n\nIn a Riemannian manifold or submanifold geodesics are characterised by the property of having vanishing [[geodesic curvature]]. More generally, in the presence of an [[affine connection]], a geodesic is defined to be a curve whose [[Tangent space|tangent vector]]s remain parallel if they are [[parallel transport|transported]] along it. Applying this to the [[Levi-Civita connection]] of a [[Riemannian metric]] recovers the previous notion.\n\nGeodesics are of particular importance in [[general relativity]].  Timelike [[geodesics in general relativity]] describe the motion of [[free fall]]ing [[test particles]].\n\n==Introduction==\nThe shortest path between two given points in a curved space, assumed to be a [[differential manifold]], can be defined by using the [[equation]] for the [[Arc length|length]] of a [[curve]] (a function ''f'' from an [[open interval]] of '''[[Real number line|R]]''' to the space), and then minimizing this length between the points using the [[calculus of variations]]. This has some minor technical problems, because there is an infinite dimensional space of different ways to parameterize the shortest path. It is simpler to restrict the set of curves to those that are parameterized \"with constant speed\" 1, meaning that  the distance from ''f''(''s'') to ''f''(''t'') along the curve equals |''s''&minus;''t''|. Equivalently, a different quantity may be used, termed the energy of the curve; minimizing the energy leads to the same equations for a geodesic (here \"constant velocity\" is a consequence of minimization).{{citation needed|date=May 2018}} Intuitively, one can understand this second formulation by noting that an [[elastic band]] stretched between two points will contract its length, and in so doing will minimize its energy.  The resulting shape of the band is a geodesic.\n\nIt is possible that several different curves between two points minimize the distance, as is the case for two diametrically opposite points on a sphere. In such a case, any of these curves is a geodesic.\n\nA contiguous segment of a geodesic is again a geodesic.\n\nIn general, geodesics are not the same as \"shortest curves\" between two points, though the two concepts are closely related. The difference is that geodesics are only ''locally'' the shortest distance between points, and are parameterized with \"constant speed\". Going the \"long way round\" on a [[great circle]] between two points on a sphere is a geodesic but not the shortest path between the points. The map ''t''&nbsp;→&nbsp;''t''<sup>2</sup> from the unit interval on the real number line to itself gives the shortest path between 0 and 1, but is not a geodesic because the velocity of the corresponding motion of a point is not constant.\n\nGeodesics are commonly seen in the study of [[Riemannian geometry]] and more generally [[metric geometry]]. In [[general relativity]], geodesics in [[spacetime]] describe the motion of [[point particle]]s under the influence of gravity alone. In particular, the path taken by a falling rock, an orbiting [[satellite]], or the shape of a [[planetary orbit]] are all geodesics in curved spacetime. More generally, the topic of [[sub-Riemannian geometry]] deals with the paths that objects may take when they are not free, and their movement is constrained in various ways.\n\nThis article presents the mathematical formalism involved in defining, finding, and proving the existence of geodesics, in the case of [[Riemannian manifold|Riemannian]] and [[pseudo-Riemannian manifold]]s.  The article [[geodesic (general relativity)]] discusses the special case of general relativity in greater detail.\n\n===Examples===\n[[File:Transpolar geodesic on a triaxial ellipsoid case A.svg|thumb|right|200px|\nA [[geodesics on a triaxial ellipsoid|geodesic on a triaxial ellipsoid]].]]\n[[File:Insect on a torus tracing out a non-trivial geodesic.gif|thumb|right|If an insect is placed on a surface and continually walks \"forward\", by definition it will trace out a geodesic.]]\nThe most familiar examples are the straight lines in [[Euclidean geometry]]. On a  [[sphere]], the images of geodesics are the  [[great circle]]s. The shortest path from point ''A'' to point ''B'' on a sphere is given by the shorter [[arc (geometry)|arc]] of the great circle passing through ''A'' and ''B''. If ''A'' and ''B'' are [[antipodal point]]s, then there are ''infinitely many'' shortest paths between them.  [[Geodesics on an ellipsoid]] behave in a more complicated way than on a sphere; in particular, they are not closed in general (see figure).\n\n==Metric geometry==\nIn [[metric geometry]], a geodesic is a curve which is everywhere [[locally]] a [[distance]] minimizer. More precisely, a [[curve]] {{nowrap|''γ'' : ''I'' → ''M''}} from an interval ''I'' of the reals to the [[metric space]] ''M'' is a '''geodesic''' if there is a [[mathematical constant|constant]] {{nowrap|''v'' ≥ 0}} such that for any {{nowrap|''t'' ∈ ''I''}} there is a neighborhood ''J'' of ''t'' in ''I'' such that for any {{nowrap|''t''<sub>1</sub>, ''t''<sub>2</sub> ∈ ''J''}} we have\n\n:<math>d(\\gamma(t_1),\\gamma(t_2)) = v \\left| t_1 - t_2 \\right| .</math>\n\nThis generalizes the notion of geodesic for Riemannian manifolds. However, in metric geometry the geodesic considered is often equipped with [[Curve#Lengths of curves|natural parameterization]], i.e. in the above identity ''v''&nbsp;=&nbsp;1 and\n\n:<math>d(\\gamma(t_1),\\gamma(t_2)) = \\left| t_1 - t_2 \\right| .</math>\n\nIf the last equality is satisfied for all {{nowrap|''t''<sub>1</sub>, ''t''<sub>2</sub> ∈ ''I''}}, the geodesic is called a '''minimizing geodesic''' or '''shortest path'''.\n\nIn general, a metric space may have no geodesics, except constant curves. At the other extreme, any two points in a [[length metric space]] are joined by a minimizing sequence of [[rectifiable path]]s, although this minimizing sequence need not converge to a geodesic.\n\n==Riemannian geometry==\nIn a [[Riemannian manifold]] ''M'' with [[metric tensor]] ''g'', the length of a continuously differentiable curve γ&nbsp;:&nbsp;[''a'',''b'']&nbsp;→&nbsp;''M'' is defined by\n:<math>L(\\gamma)=\\int_a^b \\sqrt{  g_{\\gamma(t)}(\\dot\\gamma(t),\\dot\\gamma(t)) }\\,dt.</math>\nThe distance ''d''(''p'', ''q'') between two points ''p'' and ''q'' of ''M'' is defined as the [[infimum]] of the length taken over all continuous, piecewise continuously differentiable curves γ&nbsp;:&nbsp;[''a'',''b'']&nbsp;→&nbsp;''M'' such that γ(''a'')&nbsp;=&nbsp;''p'' and γ(''b'')&nbsp;=&nbsp;''q''. In Riemannian geometry, all geodesics are locally distance-minimizing paths, but the converse is not true. In fact, only paths that are both locally distance minimizing and parameterized proportionately to arc-length are geodesics. Another equivalent way of defining geodesics on a Riemannian manifold, is to define them as the minima of the following [[action (physics)|action]] or [[energy functional]]\n:<math>E(\\gamma)=\\frac{1}{2}\\int_a^b g_{\\gamma(t)}(\\dot\\gamma(t),\\dot\\gamma(t))\\,dt.</math>\nNote that all minima of ''E'' are also minima of ''L'', but ''L'' is a bigger set since paths that are minima of ''L'' can be arbitrarily re-parameterized, while minima of ''E'' cannot.\nFor a piecewise <math>C^1</math> curve (more generally, a <math>W^{1,2}</math> curve), the [[Cauchy–Schwarz inequality]] gives\n:<math>L(\\gamma)^2 \\le 2(b-a)E(\\gamma)</math>\nwith equality if and only if <math>g(\\gamma',\\gamma')</math> is equal to a constant a.e.  It happens that minimizers of <math>E(\\gamma)</math> also minimize <math>L(\\gamma)</math>, because they turn out to be affinely parameterized, and the inequality is an equality.  The usefulness of this approach is that the problem of seeking minimizers of ''E'' is a more robust variational problem.  Indeed, ''E'' is a \"convex function\" of <math>\\gamma</math>, so that within each isotopy class of \"reasonable functions\", one ought to expect existence, uniqueness, and regularity of minimizers.  In contrast, \"minimizers\" of the functional <math>L(\\gamma)</math> are generally not very regular, because arbitrary reparameterizations are allowed.\n\nThe [[Euler–Lagrange equation]]s of motion for the functional ''E'' are then given in local coordinates by\n:<math>\\frac{d^2x^\\lambda }{dt^2} + \\Gamma^{\\lambda}_{\\mu \\nu }\\frac{dx^\\mu }{dt}\\frac{dx^\\nu }{dt} = 0,</math>\nwhere <math>\\Gamma^\\lambda_{\\mu\\nu}</math> are the [[Christoffel symbols]] of the metric.  This is the '''geodesic equation''', discussed [[#Affine geodesics|below]].\n\n===Calculus of variations===\n\nTechniques of the classical [[calculus of variations]] can be applied to examine the energy functional ''E''.  The [[first variation]] of energy is defined in local coordinates by\n\n:<math>\\delta E(\\gamma)(\\varphi) = \\left.\\frac{\\partial}{\\partial t}\\right|_{t=0} E(\\gamma + t\\varphi).</math>\n\nThe [[critical point (mathematics)|critical point]]s of the first variation are precisely the geodesics.  The [[second variation]] is defined by\n\n:<math>\\delta^2 E(\\gamma)(\\varphi,\\psi) = \\left.\\frac{\\partial^2}{\\partial s \\, \\partial t} \\right|_{s=t=0} E(\\gamma + t\\varphi + s\\psi).</math>\n\nIn an appropriate sense, zeros of the second variation along a geodesic γ arise along [[Jacobi field]]s.  Jacobi fields are thus regarded as variations through geodesics.\n\nBy applying variational techniques from [[classical mechanics]], one can also regard [[geodesics as Hamiltonian flows]].  They are solutions of the associated [[Hamilton equation]]s, with (pseudo-)Riemannian metric taken as [[Hamiltonian mechanics|Hamiltonian]].\n\n==Affine geodesics==\n{{See also|Geodesics in general relativity}}\nA '''geodesic''' on a [[Differentiable manifold|smooth manifold]]  ''M'' with an [[affine connection]]  ∇ is defined as a [[curve]] γ(''t'') such that [[parallel transport]] along the curve preserves the tangent vector to the curve, so\n{{NumBlk|:|<math> \\nabla_{\\dot\\gamma} \\dot\\gamma= 0</math>|{{EquationRef|1}}}}\nat each point along the curve,  where <math>\\dot\\gamma</math> is the derivative with respect to <math>t</math>.  More precisely, in order to define the covariant derivative of <math>\\dot\\gamma</math> it is necessary first to extend <math>\\dot\\gamma</math> to a continuously differentiable [[vector field]] in an [[open set]].  However, the resulting value of ({{EquationNote|1}}) is independent of the choice of extension.\n\nUsing [[local coordinates]] on ''M'', we can write the '''geodesic equation''' (using the [[summation convention]]) as\n:<math>\\frac{d^2\\gamma^\\lambda }{dt^2} + \\Gamma^{\\lambda}_{\\mu \\nu }\\frac{d\\gamma^\\mu }{dt}\\frac{d\\gamma^\\nu }{dt} = 0\\ ,</math>\nwhere <math>\\gamma^\\mu = x^\\mu \\circ \\gamma (t)</math> are the coordinates of the curve γ(''t'') and <math>\\Gamma^{\\lambda }_{\\mu \\nu }</math> are the [[Christoffel symbol]]s of the connection ∇.  This is an [[ordinary differential equation]] for the coordinates.  It has a unique solution, given an initial position and an initial velocity.  Therefore, from the point of view of [[classical mechanics]], geodesics can be thought of as trajectories of [[free particle]]s in a manifold. Indeed, the equation <math> \\nabla_{\\dot\\gamma} \\dot\\gamma= 0</math> means that the [[Acceleration (differential geometry)|acceleration vector]] of the curve has no components in the direction of the surface (and therefore it is perpendicular to the tangent plane of the surface at each point of the curve). So, the motion is completely determined by the bending of the surface. This is also the idea of general relativity where particles move on geodesics and the bending is caused by the gravity.\n\n===Existence and uniqueness===\nThe ''local existence and uniqueness theorem'' for geodesics states that geodesics on a smooth manifold with an [[affine connection]] exist, and are unique.  More precisely:\n\n:For any point ''p'' in ''M'' and for any vector ''V'' in ''T<sub>p</sub>M'' (the [[tangent space]] to ''M'' at ''p'') there exists a unique geodesic <math>\\gamma \\,</math> : ''I'' &rarr; ''M'' such that\n::<math>\\gamma(0) = p \\,</math> and\n::<math>\\dot\\gamma(0) = V,</math>\n:where ''I'' is a maximal [[open interval]] in '''R''' containing 0.\n\nThe proof of this theorem follows from the theory of  [[ordinary differential equation]]s, by noticing that the geodesic equation is a second-order ODE. Existence and uniqueness then follow from the [[Picard&ndash;Lindelöf theorem]] for the solutions of ODEs with prescribed initial conditions. γ depends [[smooth function|smoothly]] on both ''p'' and&nbsp;''V''.  \n\nIn general, ''I'' may not be all of '''R''' as for example for an open disc in '''R'''<sup>2</sup>. Any {{mvar|γ}} extends to all of {{mvar|&#x0211D;}} if and only if {{mvar|M}} is [[geodesic manifold|geodesically complete]].\n\n===Geodesic flow===\nGeodesic [[Flow (mathematics)|flow]] is a local '''R'''-[[Group action (mathematics)|action]] on the [[tangent bundle]] ''TM'' of a manifold ''M'' defined in the following way\n\n:<math>G^t(V)=\\dot\\gamma_V(t)</math>\n\nwhere ''t''&nbsp;∈&nbsp;'''R''', ''V''&nbsp;∈&nbsp;''TM'' and <math>\\gamma_V</math> denotes the geodesic with initial data <math>\\dot\\gamma_V(0)=V</math>. Thus,  ''<math>G^t</math>''(''V'')&nbsp;=&nbsp;exp(''tV'') is the [[exponential map (Riemannian geometry)|exponential map]] of the vector ''tV''.  A closed orbit of the geodesic flow corresponds to a [[closed geodesic]] on&nbsp;''M''.\n\nOn a (pseudo-)Riemannian manifold, the geodesic flow is identified with a [[Hamiltonian flow]] on the cotangent bundle.  The [[Hamiltonian mechanics|Hamiltonian]] is then given by the inverse of the (pseudo-)Riemannian metric, evaluated against the [[canonical one-form]]. In particular the flow preserves the (pseudo-)Riemannian metric <math>g</math>, i.e.\n\n: <math>g(G^t(V),G^t(V))=g(V,V). \\, </math>\n\nIn particular, when ''V'' is a unit vector, <math>\\gamma_V</math> remains unit speed throughout, so the geodesic flow is tangent to the [[unit tangent bundle]].  [[Liouville's theorem (Hamiltonian)|Liouville's theorem]] implies invariance of a kinematic measure on the unit tangent bundle.\n\n===Geodesic spray===\nThe geodesic flow defines a family of curves in the [[tangent bundle]]. The derivatives of these curves define a [[vector field]]  on the [[total space]] of the tangent bundle, known as the [[spray (mathematics)|geodesic spray]].\n\nMore precisely, an affine connection gives rise to a splitting of the [[double tangent bundle]] TT''M'' into [[horizontal bundle|horizontal]] and [[vertical bundle]]s:\n:<math>TTM = H\\oplus V.</math>\nThe geodesic spray is the unique horizontal vector field ''W'' satisfying\n:<math>\\pi_* W_v = v\\,</math>\nat each point ''v''&nbsp;∈&nbsp;T''M''; here π<sub>∗</sub>&nbsp;:&nbsp;TT''M''&nbsp;→&nbsp;T''M'' denotes the [[pushforward (differential)]] along the projection π&nbsp;:&nbsp;T''M''&nbsp;→&nbsp;''M'' associated to the tangent bundle.\n\nMore generally, the same construction allows one to construct a vector field for any [[Ehresmann connection]] on the tangent bundle.  For the resulting vector field to be a spray (on the deleted tangent bundle T''M''&nbsp;\\&nbsp;{0}) it is enough that the connection be equivariant under positive rescalings: it need not be linear.  That is, (cf. [[Ehresmann connection#Vector bundles and covariant derivatives]]) it is enough that the horizontal distribution satisfy\n:<math>H_{\\lambda X} = d(S_\\lambda)_X H_X\\,</math>\nfor every ''X''&nbsp;∈&nbsp;T''M''&nbsp;\\&nbsp;{0} and λ&nbsp;>&nbsp;0.  Here ''d''(''S''<sub>λ</sub>) is the [[pushforward (differential)|pushforward]] along the scalar homothety <math>S_\\lambda: X\\mapsto \\lambda X.</math>  A particular case of a non-linear connection arising in this manner is that associated to a [[Finsler manifold]].\n\n===Affine and projective geodesics===\nEquation ({{EquationNote|1}}) is invariant under affine reparameterizations; that is, parameterizations of the form\n:<math>t\\mapsto at+b</math>\nwhere ''a'' and ''b'' are constant real numbers. Thus apart from specifying a certain class of embedded curves, the geodesic equation also determines a preferred class of parameterizations on each of the curves. Accordingly, solutions of ({{EquationNote|1}}) are called geodesics with '''affine parameter'''.\n\nAn affine connection is ''determined by'' its family of affinely parameterized geodesics, up to [[torsion tensor|torsion]] {{harv|Spivak|1999|loc=Chapter 6, Addendum I}}.  The torsion itself does not, in fact, affect the family of geodesics, since the geodesic equation depends only on the symmetric part of the connection.  More precisely, if <math>\\nabla, \\bar{\\nabla}</math> are two connections such that the difference tensor\n:<math>D(X,Y) = \\nabla_XY-\\bar{\\nabla}_XY</math>\nis [[skew-symmetric matrix|skew-symmetric]], then <math>\\nabla</math> and <math>\\bar{\\nabla}</math> have the same geodesics, with the same affine parameterizations. Furthermore, there is a unique connection having the same geodesics as  <math>\\nabla</math>, but with vanishing torsion.\n\nGeodesics without a particular parameterization are described by a [[projective connection]].\n\n==Computational methods==\nEfficient solvers for the minimal geodesic problem on surfaces posed as [[Eikonal equations]] can be found in\n<ref>R. Kimmel, A. Amir, and A. M. Bruckstein. [http://www.cs.technion.ac.il/~ron/PAPERS/geodesics_pami1995.pdf  Finding shortest paths on surfaces using level sets propagation]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(6):635–640, 1995.</ref>\n<ref>R. Kimmel and J. A. Sethian. [http://www.cs.technion.ac.il/~ron/PAPERS/KimSet_PNAS1998.pdf Computing Geodesic Paths on Manifolds] in the Proceedings of National Academy of Sciences, 95(15):8431–8435, July, 1998.</ref>\n\n==Applications==\n{{expand section|date=June 2014}}\nGeodesics serve as the basis to calculate:\n* geodesic airframes; see [[geodesic airframe]] or [[geodetic airframe]]\n* geodesic structures – for example [[geodesic domes]]\n* horizontal distances on or near Earth; see [[Earth geodesics]]\n* mapping images on surfaces, for rendering; see [[UV mapping]]\n* robot [[motion planning]] (e.g., when painting car parts); see [[Shortest path problem]]\n\n==See also==\n{{div col|colwidth=25em}}\n* [[Basic introduction to the mathematics of curved spacetime]]\n* [[Clairaut's relation]]\n* [[Differential geometry of curves]]\n* [[Hopf&ndash;Rinow theorem]]\n* [[Intrinsic metric]]\n* [[Isotropic line]]\n* [[Jacobi field]]\n* [[Zoll surface]]\n* [[The spider and the fly problem]]\n{{div col end}}\n\n==References==\n{{Reflist}}\n*{{Citation | last1=Spivak | first1=Michael | author1-link=Michael Spivak | title=A Comprehensive introduction to differential geometry (Volume 2) | publisher=Publish or Perish | location=Houston, TX | isbn=978-0-914098-71-3 | year=1999}}\n{{Commons category|Geodesic (mathematics)}}\n\n==Further reading==\n{{more footnotes|date=July 2014}}\n*{{Citation | last1=Adler | first1=Ronald | last2=Bazin | first2=Maurice | last3=Schiffer | first3=Menahem | title=Introduction to General Relativity | publisher=[[McGraw-Hill]] | location=New York | edition=2nd | isbn=978-0-07-000423-8 | year=1975}}. ''See chapter 2''.\n*{{Citation | last1=Abraham | first1=Ralph H. | author1-link=Ralph Abraham (mathematician) | last2=Marsden | first2=Jerrold E. | author2-link=Jerrold E. Marsden | title=Foundations of mechanics | publisher=Benjamin-Cummings | location=London | isbn=978-0-8053-0102-1 | year=1978}}. ''See section 2.7''.\n*{{Citation | last1=Jost | first1=Jürgen | title=Riemannian Geometry and Geometric Analysis | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-42627-1 | year=2002}}. ''See section 1.4''.\n*{{citation | last1=Kobayashi|first1=Shoshichi|last2=Nomizu|first2=Katsumi | title = Foundations of Differential Geometry|volume=Vol. 1| publisher=Wiley-Interscience | year=1996|edition=New|isbn=0-471-15733-3}}.\n*{{Citation | last1=Landau | first1=L. D. | author1-link=Lev Landau | last2=Lifshitz | first2=E. M. | author2-link=Evgeny Lifshitz | title=Classical Theory of Fields | publisher=Pergamon | location=Oxford | isbn=978-0-08-018176-9 | year=1975}}. ''See section 87''.\n*{{Citation | last1=Misner | first1=Charles W. | author1-link=Charles W. Misner | last2=Thorne | first2=Kip | author2-link=Kip Thorne | last3=Wheeler | first3=John Archibald | author3-link=John Archibald Wheeler | title=[[Gravitation (book)|Gravitation]] | publisher=W. H. Freeman | isbn=978-0-7167-0344-0 | year=1973}}\n*{{Citation | last1=Ortín | first1=Tomás | title=Gravity and strings | publisher=[[Cambridge University Press]] | isbn=978-0-521-82475-0 | year=2004}}.  Note especially pages 7 and 10.\n*{{springer|first=Yu.A.|last=Volkov|title=Geodesic line|id=G/g044120}}.\n*{{Citation | last1=Weinberg | first1=Steven | author1-link=Steven Weinberg | title=Gravitation and Cosmology: Principles and Applications of the General Theory of Relativity | publisher=[[John Wiley & Sons]] | location=New York | isbn=978-0-471-92567-5 | year=1972}}. ''See chapter 3''.\n\n== External links ==\n* [http://www.cmsim.eu/papers_pdf/january_2012_papers/25_CMSIM_2012_Pokorny_1_281-298.pdf Geodesics Revisited] &mdash; Introduction to geodesics including two ways of derivation of the equation of geodesic with applications in geometry (geodesic on a sphere and on a [[torus]]), mechanics ([[brachistochrone]]) and optics (light beam in inhomogeneous medium).\n* [http://wiki.sagemath.org/interact/geometry#Geodesics_on_a_parametric_surface Geodesics on a parametric surface -- sage interact] &mdash; Interactive [[SageMath]] worksheet to calculate and illustrate geodesics on parametric surfaces.\n* [http://www.map.mpim-bonn.mpg.de/Totally_geodesic_submanifold Totally geodesic submanifold] at the Manifold Atlas\n\n{{Tensors}}\n\n[[Category:Geodesic (mathematics)| ]]"
    },
    {
      "title": "Geodesics in general relativity",
      "url": "https://en.wikipedia.org/wiki/Geodesics_in_general_relativity",
      "text": "{{about|the use of geodesics in general relativity|the general concept in geometry|geodesic}}\n{{General relativity sidebar |equations}}\n\nIn [[general relativity]], a '''geodesic''' generalizes the notion of a \"straight line\" to curved [[spacetime]]. Importantly, the [[world line]] of a particle free from all external, non-gravitational force is a particular type of geodesic. In other words, a freely moving or falling particle always moves along a geodesic.\n\nIn general relativity, gravity can be regarded as not a force but a consequence of a [[Spacetime curvature|curved spacetime]] geometry where the source of curvature is the [[stress–energy tensor]] (representing matter, for instance).  Thus, for example, the path of a planet orbiting a star is the projection of a geodesic of the curved 4-D spacetime geometry around the star onto 3-D space.\n\n==Mathematical expression==\nThe full '''geodesic equation''' is this:\n:<math> {d^2 x^\\mu \\over ds^2}+\\Gamma^\\mu {}_{\\alpha \\beta}{d x^\\alpha \\over ds}{d x^\\beta \\over ds}=0\\ .</math>\nwhere ''s'' is a scalar parameter of motion (e.g. the [[proper time]]), and <math> \\Gamma^\\mu {}_{\\alpha \\beta}</math> are [[Christoffel symbols]] (sometimes called the [[affine connection]] coefficients or [[Levi-Civita connection]] coefficients) which is symmetric in the two lower indices.  Greek indices may take the values: 0, 1, 2, 3 and the [[summation convention]] is used for repeated indices <math>\\alpha</math> and <math>\\beta</math>.  The quantity on the left-hand-side of this equation is the acceleration of a particle, and so this equation is analogous to [[Newton's laws of motion]] which likewise provide formulae for the acceleration of a particle.  This equation of motion employs the [[Einstein notation]], meaning that repeated indices are summed (i.e. from zero to three).  The Christoffel symbols are functions of the four space-time coordinates, and so are independent of the velocity or acceleration or other characteristics of a [[test particle]] whose motion is described by the geodesic equation.\n\n==Equivalent mathematical expression using coordinate time as parameter==\nSo far the geodesic equation of motion has been written in terms of a scalar parameter ''s''. It can alternatively be written in terms of the time coordinate, <math>t \\equiv x^0</math> (here we have used the [[triple bar]] to signify a definition). The geodesic equation of motion then becomes:\n:<math> {d^2 x^\\mu \\over dt^2} =- \\Gamma^\\mu {}_{\\alpha \\beta}{d x^\\alpha \\over dt}{d x^\\beta \\over dt}+ \\Gamma^0 {}_{\\alpha \\beta}{d x^\\alpha \\over dt}{d x^\\beta \\over dt}{d x^\\mu \\over dt}\\ .</math>\n\nThis formulation of the geodesic equation of motion can be useful for computer calculations and to compare General Relativity with Newtonian Gravity.<ref>Will, Clifford.  ''Theory and Experiment in Gravitational Physics'', p. 143 (Cambridge University Press 1993).</ref>  It is straightforward to derive this form of the geodesic equation of motion from the form which uses proper time as a parameter, using the [[chain rule]].  Notice that both sides of this last equation vanish when the mu index is set to zero.  If the particle's velocity is small enough, then the geodesic equation reduces to this:\n\n:<math> {d^2 x^n \\over dt^2} =- \\Gamma^n {}_{00}.</math>\n\nHere the Latin index ''n'' takes the values [1,2,3].  This equation simply means that all test particles at a particular place and time will have the same acceleration, which is a well-known feature of Newtonian gravity.  For example, everything floating around in the [[international space station]] will undergo roughly the same acceleration due to gravity.\n\n==Derivation directly from the equivalence principle==\nPhysicist [[Steven Weinberg]] has presented a derivation of the geodesic equation of motion directly from the [[equivalence principle]].<ref name=Weinberg>Weinberg, Steven.  ''Gravitation and Cosmology: Principles and Applications of the General Theory of Relativity'' (Wiley 1972).</ref>\nThe first step in such a derivation is to suppose that no particles are accelerating in the neighborhood of a [[point-event]] with respect to a freely falling coordinate system (<math>X^\\mu</math>).  Setting <math>T \\equiv X^0</math>, we have the following equation that is locally applicable in free fall:\n:<math> {d^2 X^\\mu \\over dT^2} = 0 .</math>\nThe next step is to employ the multi-dimensional [[chain rule]].  We have:\n\n:<math> {d X^\\mu \\over dT}={d x^\\nu \\over dT} {\\partial X^\\mu \\over \\partial x^\\nu} </math>\n\nDifferentiating once more with respect to the time, we have:\n\n:<math> {d^2 X^\\mu \\over dT^2}={d^2 x^\\nu \\over dT^2} {\\partial X^\\mu \\over \\partial x^\\nu} + {d x^\\nu \\over dT} {d x^\\alpha \\over dT} {\\partial^2 X^\\mu \\over \\partial x^\\nu\\partial x^\\alpha}</math>\n\nTherefore:\n\n:<math> {d^2 x^\\nu \\over dT^2} {\\partial X^\\mu \\over \\partial x^\\nu} =- {d x^\\nu \\over dT} {d x^\\alpha \\over dT} {\\partial^2 X^\\mu \\over \\partial x^\\nu\\partial x^\\alpha}</math>\n\nMultiply both sides of this last equation by the following quantity:\n\n:<math> {\\partial x^\\lambda \\over \\partial X^\\mu}</math>\n\nConsequently, we have this:\n\n:<math> {d^2 x^\\lambda \\over dT^2} = - {d x^\\nu \\over dT} {d x^\\alpha \\over dT} \\left[{\\partial^2 X^\\mu \\over \\partial x^\\nu\\partial x^\\alpha} {\\partial x^\\lambda \\over \\partial X^\\mu}\\right] .</math>\n\nUsing (from [[Christoffel symbols#Change of variable]] and the fact that the Christoffel symbols vanish in an inertial frame of reference)\n:<math>\\Gamma^\\lambda {}_{\\nu \\alpha} = \\left[{\\partial^2 X^\\mu \\over \\partial x^\\nu\\partial x^\\alpha} {\\partial x^\\lambda \\over \\partial X^\\mu}\\right]</math>\n\nit becomes\n:<math> {d^2 x^\\lambda \\over dT^2} = - \\Gamma^{\\lambda}_{\\nu \\alpha} {d x^\\nu \\over dT} {d x^\\alpha \\over dT} .</math>\n\nApplying the one-dimensional [[chain rule]] gives\n:<math> {d^2 x^\\lambda \\over d t^2} \\left( \\frac{d t}{d T} \\right)^2 + {d x^\\lambda \\over d t} \\frac{d^2 t}{d T^2} = - \\Gamma^{\\lambda}_{\\nu \\alpha} {d x^\\nu \\over d t} {d x^\\alpha \\over d t} \\left( \\frac{d t}{d T} \\right)^2 .</math>\n\n:<math> {d^2 x^\\lambda \\over d t^2} + {d x^\\lambda \\over d t} \\frac{d^2 t}{d T^2} \\left( \\frac{d T}{d t} \\right)^2 = - \\Gamma^{\\lambda}_{\\nu \\alpha} {d x^\\nu \\over d t} {d x^\\alpha \\over d t} .</math>\n\nAs before, we can set <math>t \\equiv x^0</math>. Then the first derivative of ''x''<sup>0</sup> with respect to ''t'' is one and the second derivative is zero. Replacing ''&lambda;'' with zero gives:\n:<math> \\frac{d^2 t}{d T^2} \\left( \\frac{d T}{d t} \\right)^2 = - \\Gamma^{0}_{\\nu \\alpha} {d x^\\nu \\over d t} {d x^\\alpha \\over d t} .</math>\n\nSubtracting d ''x''<sup>''&lambda;''</sup> / d ''t'' times this from the previous equation gives:\n:<math> {d^2 x^\\lambda \\over dt^2} = - \\Gamma^{\\lambda}_{\\nu \\alpha} {d x^\\nu \\over dt} {d x^\\alpha \\over dt} + \\Gamma^{0}_{\\nu \\alpha} {d x^\\nu \\over dt} {d x^\\alpha \\over dt}{d x^\\lambda \\over dt} </math>\n\nwhich is a form of the geodesic equation of motion (using the coordinate time as parameter).\n\nThe geodesic equation of motion can alternatively be derived using the concept of [[parallel transport]].<ref>Plebański, Jerzy and Krasiński, Andrzej. ''An Introduction to General Relativity and Cosmology'', p. 34 (Cambridge University Press, 2006).</ref>\n\n==Deriving the geodesic equation via an action==\n\nWe can (and this is the most common technique) derive the geodesic equation via the [[action (physics)|action]] principle. Consider the case of trying to find a geodesic between two timelike-separated events.\n\nLet the action be \n:<math>S=\\int ds</math>\n\nwhere <math>ds=\\sqrt{-g_{\\mu\\nu}(x)dx^{\\mu}dx^{\\nu}}</math> is the [[line element]]. There is a negative sign inside the square root because the curve must be timelike. To get the geodesic equation we must vary this action. To do this let us parameterize this action with respect to a parameter <math>\\lambda</math>. Doing this we get:\n \n:<math>S=\\int\\sqrt{-g_{\\mu\\nu}\\frac{dx^{\\mu}}{d\\lambda}\\frac{dx^{\\nu}}{d\\lambda}}d\\lambda</math>\n\nWe can now go ahead and vary this action with respect to the curve <math>x^{\\mu}</math>. By the [[principle of least action]] we get:\n\n:<math>0=\\delta S=\\int\\delta\\left(\\sqrt{-g_{\\mu\\nu}\\frac{dx^{\\mu}}{d\\lambda}\\frac{dx^{\\nu}}{d\\lambda}}\\right)d\\lambda =\\int\\frac{\\delta\\left(-g_{\\mu\\nu}\\frac{dx^{\\mu}}{d\\lambda}\\frac{dx^{\\nu}}{d\\lambda}\\right)}{2\\sqrt{-g_{\\mu\\nu}\\frac{dx^{\\mu}}{d\\lambda}\\frac{dx^{\\nu}}{d\\lambda}}}d\\lambda</math>\n\nUsing the product rule we get:\n\n:<math>0=\\int\\left(\\frac{dx^{\\mu}}{d\\lambda}\\frac{dx^{\\nu}}{d\\tau}\\delta g_{\\mu\\nu}+g_{\\mu\\nu}\\frac{d\\delta x^{\\mu}}{d\\lambda}\\frac{dx^{\\nu}}{d\\tau}+g_{\\mu\\nu}\\frac{dx^{\\mu}}{d\\tau}\\frac{d\\delta x^{\\nu}}{d\\lambda}\\right)d\\lambda = \\int\\left(\\frac{dx^{\\mu}}{d\\lambda}\\frac{dx^{\\nu}}{d\\tau}\\partial_{\\alpha}g_{\\mu\\nu}\\delta x^{\\alpha}+2g_{\\mu\\nu}\\frac{d\\delta x^{\\mu}}{d\\lambda}\\frac{dx^{\\nu}}{d\\tau}\\right)d\\lambda </math>\n\nIntegrating by-parts the last term and dropping the total derivative (which equals to zero at the boundaries) we get that:\n\n:<math>0=\\int \\left(\\frac{dx^{\\mu}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}\\partial_{\\alpha}g_{\\mu\\nu}\\delta x^{\\alpha}-2\\delta x^{\\mu}\\frac{d}{d\\tau}\\left(g_{\\mu\\nu}\\frac{dx^{\\nu}}{d\\tau}\\right)\\right) d\\tau = \\int \\left(\\frac{dx^{\\mu}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}\\partial_{\\alpha}g_{\\mu\\nu}\\delta x^{\\alpha}-2\\delta x^{\\mu}\\partial_{\\alpha}g_{\\mu\\nu}\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}-2\\delta x^{\\mu}g_{\\mu\\nu}\\frac{d^{2}x^{\\nu}}{d\\tau^{2}}\\right) d\\tau </math>\n\nSimplifying a bit we see that:\n\n:<math>0=\\int \\left(-2g_{\\mu\\nu}\\frac{d^{2}x^{\\nu}}{d\\tau^{2}}+\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}\\partial_{\\mu}g_{\\alpha\\nu}-2\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}\\partial_{\\alpha}g_{\\mu\\nu}\\right) \\delta x^{\\mu}d\\tau </math>\n\nso,\n\n:<math>0=\\int \\left(-2g_{\\mu\\nu}\\frac{d^{2}x^{\\nu}}{d\\tau^{2}}+\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}\\partial_{\\mu}g_{\\alpha\\nu}-\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}\\partial_{\\alpha}g_{\\mu\\nu}-\\frac{dx^{\\nu}}{d\\tau}\\frac{dx^{\\alpha}}{d\\tau}\\partial_{\\nu}g_{\\mu\\alpha}\\right) \\delta x^{\\mu}d\\tau </math>\n\nmultiplying this equation by <math>-\\frac{1}{2}</math> we get:\n\n:<math>0=\\int \\left(g_{\\mu\\nu}\\frac{d^{2}x^{\\nu}}{d\\tau^{2}}+\\frac{1}{2}\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}\\left(\\partial_{\\alpha}g_{\\mu\\nu}+\\partial_{\\nu}g_{\\mu\\alpha}-\\partial_{\\mu}g_{\\alpha\\nu}\\right)\\right) \\delta x^{\\mu}d\\tau </math>\n\nSo by [[Hamilton's principle]] we find that the [[Euler–Lagrange equation]] is\n\n:<math>g_{\\mu\\nu}\\frac{d^{2}x^{\\nu}}{d\\tau^{2}}+\\frac{1}{2}\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}\\left(\\partial_{\\alpha}g_{\\mu\\nu}+\\partial_{\\nu}g_{\\mu\\alpha}-\\partial_{\\mu}g_{\\alpha\\nu}\\right)=0</math>\n\nMultiplying by the inverse [[metric tensor]] <math>g^{\\mu\\beta}</math> we get that\n\n:<math>\\frac{d^{2}x^{\\beta}}{d\\tau^{2}}+\\frac{1}{2}g^{\\mu\\beta}\\left(\\partial_{\\alpha}g_{\\mu\\nu}+\\partial_{\\nu}g_{\\mu\\alpha}-\\partial_{\\mu}g_{\\alpha\\nu}\\right)\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}=0</math>\n\nThus we get the geodesic equation:\n\n:<math>\\frac{d^{2}x^{\\beta}}{d\\tau^{2}}+\\Gamma^{\\beta}{}_{\\alpha\\nu}\\frac{dx^{\\alpha}}{d\\tau}\\frac{dx^{\\nu}}{d\\tau}=0</math>\n\nwith the [[Christoffel symbol]] defined in terms of the metric tensor as\n\n:<math>\\Gamma^{\\beta}{}_{\\alpha\\nu}=\\frac{1}{2}g^{\\mu\\beta}\\left(\\partial_{\\alpha}g_{\\mu\\nu}+\\partial_{\\nu}g_{\\mu\\alpha}-\\partial_{\\mu}g_{\\alpha\\nu}\\right)</math>\n\n(NOTE: Similar derivations, with minor amendments, can be used to produce analogous results for geodesics between light-like{{cn|date=July 2018}} or space-like separated pairs of points.)\n\n==Equation of motion may follow from the field equations for empty space==\n[[Albert Einstein]] believed that the geodesic equation of motion can be derived from the [[Einstein Field Equations#Vacuum field equations|field equations for empty space]], i.e. from the fact that the [[Ricci curvature]] vanishes.  He wrote:<ref>Einstein, Albert.  ''The Meaning of Relativity'', p. 113 (Psychology Press 2003).</ref>\n<blockquote>It has been shown that this law of motion — generalized to the case of arbitrarily large gravitating masses — can be derived from the field equations of empty space alone.  According to this derivation the law of motion is implied by the condition that the field be singular nowhere outside its generating mass points.</blockquote>\nand <ref>{{cite journal|last1=Einstein|first1=A.|last2=Rosen|first2=N.|title=The Particle Problem in the General Theory of Relativity|journal=Physical Review|date=1 July 1935|volume=48|issue=1|pages=76|doi=10.1103/PhysRev.48.73|bibcode = 1935PhRv...48...73E }} and ER - Einstein Rosen paper [[ER=EPR]] </ref>\n<blockquote>One of the imperfections of the original relativistic theory of gravitation was that as a field theory it was not complete; it introduced the independent postulate that the law of motion of a particle is given by the equation of the geodesic. \nA complete field theory knows only fields and not the concepts of particle and motion. For these must not exist independently from the field but are to be treated as part of it.\n On the basis of the description of a particle without singularity, one has the possibility of a logically more satisfactory treatment of the combined problem: The problem of the field and that of the motion coincide.</blockquote>\nBoth physicists and philosophers have often repeated the assertion that the geodesic equation can be obtained from the field equations to describe the motion of a [[gravitational singularity]], but this claim remains disputed.<ref>Tamir, M. \"[http://philsci-archive.pitt.edu/9158/1/Tamir_-_Proving_the_Principle.pdf Proving the principle: Taking geodesic dynamics too seriously in Einstein’s theory]\", ''Studies In History and Philosophy of Modern Physics'' 43(2), 137–154 (2012).</ref>  Less controversial is the notion that the field equations determine the motion of a fluid or dust, as distinguished from the motion of a point-singularity.<ref>Plebański, Jerzy and Krasiński, Andrzej. ''An Introduction to General Relativity and Cosmology'', p. 143 (Cambridge University Press, 2006).</ref>\n\n==Extension to the case of a charged particle==\nIn deriving the geodesic equation from the equivalence principle, it was assumed that particles in a local inertial coordinate system are not accelerating.  However, in real life, the particles may be charged, and therefore may be accelerating locally in accordance with the [[Lorentz force]].  That is:\n:<math> {d^2 X^\\mu \\over ds^2} = {q \\over m} {F^{\\mu \\beta}} {d X^\\alpha \\over ds}{\\eta_{\\alpha \\beta}}.</math>\n\nwith\n\n:<math> {\\eta_{\\alpha \\beta}}{d X^\\alpha \\over ds}{d X^\\beta \\over ds}=-1.</math>\n\nThe [[Minkowski space|Minkowski tensor]] <math>\\eta_{\\alpha \\beta}</math> is given by:\n:<math>\\eta_{\\alpha \\beta} = \\begin{pmatrix}-1&0&0&0\\\\0&1&0&0\\\\0&0&1&0\\\\0&0&0&1\\end{pmatrix}</math>\n\nThese last three equations can be used as the starting point for the derivation of an equation of motion in General Relativity, instead of assuming that acceleration is zero in free fall.<ref name=Weinberg />  Because the Minkowski tensor is involved here, it becomes necessary to introduce something called the ''[[metric tensor]]'' in General Relativity.  The metric tensor ''g'' is symmetric, and locally reduces to the Minkowski tensor in free fall.  The resulting equation of motion is as follows:<ref>{{cite book|last=Wald|first=R.M.|title=General Relativity|location=Eq. 4.3.2|isbn=978-0-226-87033-5|publisher=[[University of Chicago Press]]|year=1984}}</ref>\n\n:<math> {d^2 x^\\mu \\over ds^2} =- \\Gamma^\\mu {}_{\\alpha \\beta}{d x^\\alpha \\over ds}{d x^\\beta \\over ds}\\ +{q \\over m} {F^{\\mu \\beta}} {d x^\\alpha \\over ds}{g_{\\alpha \\beta}}.</math>\n\nwith\n\n:<math> {g_{\\alpha \\beta}}{d x^\\alpha \\over ds}{d x^\\beta \\over ds}=-1.</math>\n\nThis last equation signifies that the particle is moving along a timelike geodesic; massless particles like the [[photon]] instead follow null geodesics (replace −1 with zero on the right-hand side of the last equation).  It is important that the last two equations are consistent with each other, when the latter is differentiated with respect to proper time, and the following formula for the Christoffel symbols ensures that consistency:\n\n:<math>\\Gamma^{\\lambda}{}_{\\alpha\\beta}=\\frac{1}{2}g^{\\lambda \\tau} \\left(\\frac{\\partial g_{\\tau\\alpha}}{\\partial x^\\beta} + \\frac{\\partial g_{\\tau\\beta}}{\\partial x^{\\alpha}} - \\frac{\\partial g_{\\alpha\\beta}}{\\partial x^{\\tau}} \\right) </math>\n\nThis last equation does not involve the electromagnetic fields, and it is applicable even in the limit as the electromagnetic fields vanish.  The letter ''g'' with superscripts refers to the [[Invertible matrix|inverse]] of the metric tensor.  In General Relativity, indices of tensors are lowered and raised by [[Tensor contraction|contraction]] with the metric tensor or its inverse, respectively.\n\n==Geodesics as curves of stationary interval==\nA geodesic between two events can also be described as the curve joining those two events which has a stationary [[Spacetime#Spacetime intervals|interval]] (4-dimensional \"length\"). ''Stationary'' here is used in the sense in which that term is used in the [[calculus of variations]], namely, that the interval along the curve varies minimally among curves that are nearby to the geodesic.\n\nIn Minkowski space there is only one time-like geodesic that connects any given pair of time-like separated events, and that geodesic is the curve with the longest [[proper time]] between the two events.  But in curved spacetime, it's possible for a pair of widely separated events to have more than one time-like geodesic that connects them.  In such instances, the proper times along the various geodesics will not in general be the same.  And for some geodesics in such instances, it's possible for a curve that connects the two events and is nearby to the geodesic to have either a longer or a shorter proper time than the geodesic.<ref>{{cite book | author = [[Charles W. Misner]] |author2=[[Kip Thorne]] |author3=[[John Archibald Wheeler]] | title = [[Gravitation (book)|Gravitation]] | publisher = [[W. H. Freeman]] | year = 1973 | isbn = 0-7167-0344-0 | pages = 316, 318–319 }}</ref>\n\nFor a space-like geodesic through two events, there are always nearby curves which go through the two events that have either a longer or a shorter [[proper length]] than the geodesic, even in Minkowski space.  In Minkowski space, in an inertial frame of reference in which the two events are simultaneous, the geodesic will be the straight line between the two events at the time at which the events occur.  Any curve that differs from the geodesic purely spatially (''i.e.'' does not change the time coordinate) in that frame of reference will have a longer proper length than the geodesic, but a curve that differs from the geodesic purely temporally (''i.e.'' does not change the space coordinate) in that frame of reference will have a shorter proper length.\n\nThe interval of a curve in spacetime is\n:<math> l = \\int \\sqrt{\\left|g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu \\right|} \\, ds\\ .</math>\nThen, the [[Euler–Lagrange equation]],\n:<math> {d \\over ds} {\\partial \\over \\partial \\dot x^\\alpha} \\sqrt{\\left| g_{\\mu \\nu} \\dot \nx^\\mu \\dot x^\\nu \\right|} = {\\partial \\over \\partial x^\\alpha} \\sqrt{\\left| g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu \\right|} \\ ,</math>\nbecomes, after some calculation, \n:<math> 2(\\Gamma^\\lambda {}_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu + \\ddot x^\\lambda) = U^\\lambda {d \\over ds} \\ln |U_\\nu U^\\nu| \\ ,</math>\nwhere <math> U^\\mu = \\dot x^\\mu .</math>\n{{hidden begin|title=Proof}}\nThe goal being to find a curve for which the value of\n:<math> l = \\int d\\tau = \\int {d\\tau \\over d\\phi} \\, d\\phi = \\int \\sqrt{{(d\\tau)^2 \\over (d\\phi)^2}} \\, d\\phi = \\int \\sqrt{{-g_{\\mu \\nu} dx^\\mu dx^\\nu \\over d\\phi \\, d\\phi}} \\, d\\phi = \\int f \\, d\\phi</math>\nis stationary, where\n: <math> f = \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu} </math>\nsuch goal can be accomplished by calculating the Euler–Lagrange equation for ''f'', which is \n: <math> {d \\over d\\tau} {\\partial f \\over \\partial \\dot x^\\lambda} = {\\partial f \\over \\partial x^\\lambda} </math>.\n\nSubstituting the expression of ''f'' into the Euler–Lagrange equation (which makes the value of the integral ''l'' stationary), gives\n:<math> {d \\over d\\tau} {\\partial \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu} \\over \\partial \\dot x^\\lambda} = {\\partial \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu} \\over \\partial x^\\lambda} </math>\n\nNow calculate the derivatives:\n<math> {d \\over d\\tau} \\left( {-g_{\\mu \\nu} {\\partial \\dot x^\\mu \\over \\partial \\dot x^\\lambda} \\dot x^\\nu - g_{\\mu \\nu} \\dot x^\\mu {\\partial \\dot x^\\nu \\over \\partial \\dot x^\\lambda} \\over 2 \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu}} \\right) = {-g_{\\mu \\nu, \\lambda} \\dot x^\\mu \\dot x^\\nu \\over 2 \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu}} \\qquad \\qquad (1)</math>\n\n<math> {d \\over d\\tau} \\left( {g_{\\mu \\nu} \\delta^\\mu {}_\\lambda \\dot x^\\nu + g_{\\mu \\nu} \\dot x^\\mu \\delta^\\nu {}_\\lambda \\over 2 \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu}} \\right) = {g_{\\mu \\nu , \\lambda} \\dot x^\\mu \\dot x^\\nu \\over 2 \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu}} \\qquad \\qquad (2) </math>\n\n<math> {d \\over d\\tau} \\left( {g_{\\lambda \\nu} \\dot x^\\nu + g_{\\mu \\lambda} \\dot x^\\mu \\over \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu}} \\right) = {g_{\\mu \\nu , \\lambda} \\dot x^\\mu \\dot x^\\nu \\over \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu}} \\qquad \\qquad (3) </math>\n\n<math> {\\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu} {d \\over d\\tau} (g_{\\lambda \\nu} \\dot x^\\nu + g_{\\mu \\lambda} \\dot x^\\mu) - (g_{\\lambda \\nu} \\dot x^\\nu + g_{\\mu \\lambda} \\dot x^\\mu) {d \\over d\\tau} \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu} \\over -g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu} = {g_{\\mu \\nu , \\lambda} \\dot x^\\mu \\dot x^\\nu \\over \\sqrt{-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu}} \\qquad \\qquad (4) </math>\n\n<math> {(-g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu) {d \\over d\\tau} (g_{\\lambda \\nu} \\dot x^\\nu + g_{\\mu \\lambda} \\dot x^\\mu) + {1 \\over 2} (g_{\\lambda \\nu} \\dot x^\\nu + g_{\\mu \\lambda} \\dot x^\\mu) {d \\over d\\tau} (g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu) \\over -g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu} = g_{\\mu \\nu ,\\lambda} \\dot x^\\mu \\dot x^\\nu \\qquad \\qquad (5) </math>\n\n<math> (g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu) (g_{\\lambda \\nu ,\\mu} \\dot x^\\nu \\dot x^\\mu + g_{\\mu \\lambda ,\\nu} \\dot x^\\mu \\dot x^\\nu + g_{\\lambda \\nu} \\ddot x^\\nu + g_{\\lambda \\mu} \\ddot x^\\mu) </math>\n:<math>= (g_{\\mu \\nu ,\\lambda} \\dot x^\\mu \\dot x^\\nu) (g_{\\alpha \\beta} \\dot x^\\alpha \\dot x^\\beta) + {1 \\over 2} (g_{\\lambda \\nu} \\dot x^\\nu + g_{\\lambda \\mu} \\dot x^\\mu) {d \\over d\\tau} (g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu) \\qquad \\qquad (6) </math>\n\n<math> g_{\\lambda \\nu ,\\mu} \\dot x^\\mu \\dot x^\\nu + g_{\\lambda \\mu ,\\nu} \\dot x^\\mu \\dot x^\\nu - g_{\\mu \\nu ,\\lambda} \\dot x^\\mu \\dot x^\\nu +  2 g_{\\lambda \\mu} \\ddot x^\\mu = {\\dot x_\\lambda {d \\over d\\tau} (g_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu) \\over g_{\\alpha \\beta} \\dot x^\\alpha \\dot x^\\beta} \\qquad \\qquad (7) </math>\n\n<math> 2(\\Gamma_{\\lambda \\mu \\nu} \\dot x^\\mu \\dot x^\\nu + \\ddot x_\\lambda) = {\\dot x_\\lambda {d \\over d\\tau} (\\dot x_\\nu \\dot x^\\nu) \\over \\dot x_\\beta \\dot x^\\beta} = {U_\\lambda {d \\over d\\tau} (U_\\nu U^\\nu) \\over U_\\beta U^\\beta} = U_\\lambda {d \\over d\\tau} \\ln |U_\\nu U^\\nu| \\qquad \\qquad (8) </math>\n\nThis is just one step away from the geodesic equation.\n{{hidden end}}\nIf the parameter ''s'' is chosen to be affine, then the right side of the above equation vanishes (because <math>U_\\nu U^\\nu</math> is constant).  Finally, we have the geodesic equation\n:<math> \\Gamma^\\lambda {}_{\\mu \\nu} \\dot x^\\mu \\dot x^\\nu + \\ddot x^\\lambda = 0\\ .</math>\n\n==See also==\n* [[Geodesic]]\n* [[Schwarzschild geodesics]]\n* [[Geodesics as Hamiltonian flows]]\n\n==Bibliography==\n* [[Steven Weinberg]], ''Gravitation and Cosmology: Principles and Applications of the General Theory of Relativity'', (1972) John Wiley & Sons, New York {{ISBN|0-471-92567-5}}. ''See chapter 3''.\n* [[Lev D. Landau]] and [[Evgenii M. Lifschitz]], ''The Classical Theory of Fields'', (1973) Pergammon Press, Oxford {{ISBN|0-08-018176-7}} ''See section 87''.\n* [[Charles W. Misner]], [[Kip S. Thorne]], [[John Archibald Wheeler]], ''[[Gravitation (book)|Gravitation]]'', (1970) W.H. Freeman, New York; {{ISBN|0-7167-0344-0}}.\n* [[Bernard F. Schutz]], ''A first course in general relativity'', (1985; 2002) Cambridge University Press: Cambridge, UK; {{ISBN|0-521-27703-5}}.  ''See chapter 6''.\n* [[Robert M. Wald]], ''[[General Relativity (book)|General Relativity]]'', (1984)  The University of Chicago Press, Chicago.  ''See Section 3.3''.\n\n==References==\n{{reflist}}\n\n{{Relativity}}\n\n[[Category:General relativity]]\n[[Category:Geodesic (mathematics)| ]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Alexandrov's uniqueness theorem",
      "url": "https://en.wikipedia.org/wiki/Alexandrov%27s_uniqueness_theorem",
      "text": "{{short description|rigidity theorem in mathematics}}\n{{good article}}\nThe '''Alexandrov uniqueness theorem''' is a [[rigidity (mathematics)|rigidity theorem]] in mathematics, describing three-dimensional [[convex polyhedron|convex polyhedra]] in terms of the distances between points on their surfaces. It implies that convex polyhedra with distinct shapes from each other also have distinct [[metric space]]s of surface distances, and it characterizes the metric spaces that come from the surface distances on polyhedra.  It is named after Soviet mathematician [[Aleksandr Danilovich Aleksandrov]], who published it in the 1940s.{{r|senechal|alexandrov|connelly}}\n\n==Statement of the theorem==\nThe surface of any convex polyhedron in [[Euclidean space]] forms a [[metric space]], in which the distance between two points is measured by the length of the [[shortest path]] from one point to the other along the surface. These paths are known as [[geodesic]]s, and are [[Isometry|isometric]] to [[line segment]]s.\nA space in which every pair of points is connected by a geodesic is called a \"geodesic space\". The metric space formed in this way from a polyhedron is called its [[development (differential geometry)|development]].{{r|connelly}}\n\n[[File:4-hex octahedron.svg|thumb|upright=1.8|Four regular hexagons can be folded and glued to form the surface of a regular octahedron.{{r|kl}} Note that the edges of the hexagons and the edges of the octahedron are not in the same locations.]]\nThe polyhedron can be thought of as being folded from a sheet of paper (a [[net (polyhedron)|net]] for the polyhedron) and it inherits the same geometry as the paper: for every point ''p'' within a face of the polyhedron, a sufficiently small [[neighbourhood (mathematics)|open neighborhood]] of ''p'' will [[isometry|have the same distances]] as a subset of the [[Euclidean plane]]. The same thing is true even for points on the edges of the polyhedron: they can be modeled locally as a Euclidean plane folded along a line and embedded into three-dimensional space, but the fold does not change the structure of shortest paths along the surface. However, the vertices of the polyhedron have a different distance structure: the local geometry of a polyhedron vertex is the same as the local geometry at the apex of a [[cone]]. Any cone can be formed from a flat sheet of paper with a wedge removed from it by gluing together the cut edges where the wedge was removed. The angle of the wedge that was removed is called the [[angular defect]] of the vertex; it is a positive number in the open interval from 0 to&nbsp;2{{pi}}. The defect of a polyhedron vertex can be measured by subtracting the face angles at that vertex from 2{{pi}}. For instance, in a regular tetrahedron, each face angle is {{pi}}/3, and there are three of them at each vertex, so subtracting them from 2{{pi}} leaves a defect of {{pi}} at each of the four vertices.\nSimilarly, a cube has a defect of {{pi}}/2 at each of its eight vertices. [[Descartes' theorem on total angular defect]] (a form of the [[Gauss–Bonnet theorem]]) states that the sum of the angular defects of all the vertices is always exactly&nbsp;4{{pi}}. In summary, the development of a convex polyhedron is geodesic, [[homeomorphism|homeomorphic]] (topologically equivalent) to a sphere, and locally Euclidean except for a finite number of cone points whose angular defect sums to&nbsp;4{{pi}}.{{r|connelly}}\n\nAlexandrov's theorem gives a converse to this description. It states that if a metric space (''X'',''d'') is geodesic, homeomorphic to a sphere, and locally Euclidean except for a finite number of cone points of positive angular defect summing to&nbsp;4{{pi}}, then there exists a convex polyhedron whose development is (''X'',''d''). Moreover, this polyhedron is uniquely defined from the metric: any two convex polyhedra with the same surface metric must be [[congruence (geometry)|congruent]] to each other as three-dimensional sets.{{r|connelly}}\n\n==Limitations==\nThe polyhedron representing the given metric space may be [[degeneracy (mathematics)|degenerate]]: it may form a doubly-covered two-dimensional convex polygon (a [[dihedron]]) rather than a fully three-dimensional polyhedron. In this case, its surface metric consists of two copies of the polygon (its two sides) glued together along corresponding edges.{{r|connelly|o'rourke}}\n\n[[File:Icosahedron.svg|thumb|The regular icosahedron has the same surface metric as a non-convex [[deltahedron]] in which one of its five-triangle pyramids is pushed in rather than protruding]]\nAlthough Alexandrov's theorem states that there is a unique convex polyhedron whose surface has a given metric, it may also be possible for there to exist non-convex polyhedra with the same metric. An example is given by the [[regular icosahedron]]: if five of its triangles are removed, and are replaced by five congruent triangles forming an indentation into the polyhedron, the resulting surface metric stays unchanged.{{r|hartshorne}}\n\nThe development of any polyhedron can be described concretely by a collection of two-dimensional polygons together with instructions for gluing them together along their edges to form a metric space, and the conditions of Alexandrov's theorem for spaces described in this way are easily checked. However, the edges where two polygons are glued together could become flat and lie in the interior of faces of the resulting polyhedron,\nrather than becoming polyhedron edges. Therefore, even when the development is described in this way, it may not be clear what shape the resulting polyhedron has, what shapes its faces have, or even how many faces it has. Alexandrov's original proof does not lead to an [[algorithm]] for constructing the polyhedron (for instance by giving coordinates for its vertices) realizing the given metric space. In 2008, Bobenko and Izmestiev provided such an algorithm.{{r|bobenko}} Their algorithm can approximate the coordinates arbitrarily accurately, in [[pseudo-polynomial time]].{{r|pseudopolynomial}}\n\n==Related results==\nOne of the first existence and uniqueness theorems for convex polyhedra is [[Cauchy's theorem (geometry)|Cauchy's theorem]], which states that a convex polyhedron is uniquely determined by the shape and connectivity of its faces. Alexandrov's theorem strengthens this, showing that even if the faces are allowed to bend or fold, without stretching or shrinking, then their connectivity still determines the shape of the polyhedron. In turn, Alexandrov's proof of the existence part of his theorem uses a strengthening of Cauchy's theorem by [[Max Dehn]] to [[structural rigidity|infinitesimal rigidity]].{{r|connelly}}\n\nAn analogous result to Alexandrov's holds for smooth convex surfaces: a two-dimensional [[smooth manifold]] whose total [[Gaussian curvature]] is&nbsp;4{{pi}} can be represented uniquely as the surface of a smooth convex body in three dimensions. This is a result of [[Stephan Cohn-Vossen]] from 1927. [[Aleksei Pogorelov]] generalized both these results, characterizing the developments of arbitrary convex bodies in three dimensions.{{r|connelly}}\n\nAnother result of Pogorelov on the geodesic metric spaces derived from convex polyhedra is a version of the [[theorem of the three geodesics]]: every convex polyhedron has at least three simple closed quasigeodesics. These are curves that are locally straight lines except when they pass through a vertex, where they are required to have angles of less than {{pi}} on both sides of them.{{r|pogorelov}}\n\n==References==\n{{reflist|refs=\n\n<ref name= alexandrov>{{citation |title=Convex Polyhedra|series=Springer Monographs in Mathematics|first=A. D.|last=Alexandrov|authorlink= Aleksandr Danilovich Aleksandrov |publisher=Springer|year=2006|isbn=9783540263401}}. Translated into English by N. S. Dairbekov, S. S. Kutateladze, and A. B. Sossinsky. The uniqueness part of the theorem is covered in Chapter 3, and the existence part is covered in Chapter 4.</ref>\n\n<ref name=bobenko>{{citation |first1=Alexander I. |last1=Bobenko |first2=Ivan |last2=Izmestiev |title=Alexandrov's theorem, weighted Delaunay triangulations, and mixed volumes |mr=2410380 |journal=Université de Grenoble. Annales de l'Institut Fourier |year=2008 |volume=58 |issue=2 |pages=447–505 |url=http://aif.cedram.org/item?id=AIF_2008__58_2_447_0}}</ref>\n\n<ref name=connelly>{{citation |title=''Convex Polyhedra'' by A. D. Alexandrov|first=Robert|last=Connelly|authorlink=Robert Connelly|journal=SIAM Review|volume=48|issue=1|date=March 2006|pages=157–160|jstor=204537|doi=10.1137/SIREAD000048000001000149000001|url=http://www.math.cornell.edu/~connelly/alexandrov.pdf}}</ref>\n\n<ref name=hartshorne>{{citation\n | last = Hartshorne | first = Robin | authorlink = Robin Hartshorne\n | contribution = Example 44.2.3, the \"punched-in icosahedron\"\n | doi = 10.1007/978-0-387-22676-7\n | isbn = 0-387-98650-2\n | mr = 1761093\n | page = 442\n | publisher = Springer-Verlag, New York\n | series = Undergraduate Texts in Mathematics\n | title = Geometry: Euclid and beyond\n | year = 2000}}.</ref>\n\n<ref name=kl>{{citation|first1=Elena|last1=Khramtcova|first2=Stefan|last2=Langerman|author2-link=Stefan Langerman|contribution=Which convex polyhedra can be made by gluing regular hexagons?|url=http://www.jcdcgg.u-tokai.ac.jp/JCDCG3_2017_abstracts.pdf|title=Abstracts of the 20th Japan Conference on Discrete and Computational Geometry, Graphs, and Games|year=2017|pages=63–64}}</ref>\n\n<ref name=\"o'rourke\">{{citation|arxiv=1007.2016|title=On flat polyhedra deriving from Alexandrov's theorem|first=Joseph|last=O'Rourke|year=2010|authorlink=Joseph O'Rourke (professor)|bibcode=2010arXiv1007.2016O}}</ref>\n\n<ref name=pogorelov>{{citation |last= Pogorelov |first= Aleksei V. |authorlink= Aleksei Pogorelov |journal= [[Matematicheskii Sbornik]] |mr= 0031767 |pages= 275–306 |title= Quasi-geodesic lines on a convex surface |volume= 25 |issue= 62 |year= 1949 |language= ru}}</ref>\n\n<ref name=pseudopolynomial>{{citation |contribution=A pseudopolynomial algorithm for Alexandrov’s theorem|title=Algorithms and data structures. [[SWAT and WADS conferences|11th International Symposium, WADS 2009]], Banff, Canada, August 21–23, 2009, Proceedings|doi=10.1007/978-3-642-03367-4_38|series=Lecture Notes in Computer Science|year=2009|volume=5664|pages=435–446|first1=Daniel|last1=Kane|author1-link=Daniel Kane (mathematician)|first2=Gregory N.|last2=Price|first3=Erik D.|last3=Demaine|author3-link=Erik Demaine|mr=2550627|isbn=978-3-642-03366-7|publisher=Springer|location=Berlin|editor1-first=Frank|editor1-last=Dehne|editor2-first=Marina|editor2-last=Gavrilova|editor3-first=Jörg-Rüdiger|editor3-last=Sack|editor3-link=Jörg-Rüdiger Sack|editor4-last=Tóth|editor4-first= Csaba D.|arxiv=0812.5030|contribution-url=http://erikdemaine.org/papers/Alexandrov_WADS2009/}}</ref>\n\n<ref name=senechal>Senechal gives a date of 1941, while O'Rourke lists 1948. See: {{citation |title=Shaping Space: Exploring Polyhedra in Nature, Art, and the Geometrical Imagination|first=Marjorie|last=Senechal|authorlink=Marjorie Senechal|publisher=Springer|year=2013|isbn=9780387927145|page=62|url=https://books.google.com/books?id=kZtCAAAAQBAJ&pg=PA62}}. {{citation |title=How to Fold It: The Mathematics of Linkages, Origami and Polyhedra|first=Joseph|last=O’Rourke|authorlink=Joseph O'Rourke (professor)|publisher=Cambridge University Press|year=2011|isbn=9781139498548|page=134|url=https://books.google.com/books?id=EbwNKD0xkUwC&pg=PA134}}.</ref>\n\n}}\n\n[[Category:Geodesic (mathematics)]]\n[[Category:Mathematics of rigidity]]\n[[Category:Theorems in convex geometry]]\n[[Category:Theorems in discrete geometry]]"
    },
    {
      "title": "Closed geodesic",
      "url": "https://en.wikipedia.org/wiki/Closed_geodesic",
      "text": "In [[differential geometry]] and [[dynamical systems]], a '''closed geodesic''' on a [[Riemannian manifold]] is a [[geodesic]] that returns to its starting point with the same tangent direction. It may be formalized as the projection of a closed orbit of the [[geodesic|geodesic flow]] on the [[tangent space]] of the manifold.\n\n==Definition==\nIn a [[Riemannian manifold]] (''M'',''g''), a closed geodesic is a curve <math>\\gamma:\\mathbb R\\rightarrow M</math> that is a [[geodesic]] for the metric ''g'' and is periodic.\n\nClosed geodesics can be characterized by means of a variational principle. Denoting by <math>\\Lambda M</math> the space of smooth 1-periodic curves on ''M'', closed geodesics of period 1 are precisely the [[critical point (mathematics)|critical points]] of the energy function <math>E:\\Lambda M\\rightarrow\\mathbb R</math>, defined by\n\n: <math>E(\\gamma)=\\int_0^1 g_{\\gamma(t)}(\\dot\\gamma(t),\\dot\\gamma(t))\\,\\mathrm{d}t.</math>\n\nIf <math>\\gamma</math> is a closed geodesic of period ''p'', the reparametrized curve <math>t\\mapsto\\gamma(pt)</math> is a closed geodesic of period 1, and therefore it is a critical point of ''E''. If <math>\\gamma</math> is a critical point of ''E'', so are the reparametrized curves <math>\\gamma^m</math>, for each <math>m\\in\\mathbb N</math>, defined by <math>\\gamma^m(t):=\\gamma(mt)</math>. Thus every closed geodesic on ''M'' gives rise to an infinite sequence of critical points of the energy ''E''.\n\n==Examples==\nOn the [[unit sphere]] <math>S^n\\subset\\mathbb R^{n+1}</math> with the standard round Riemannian metric, every [[great circle]] is an example of a closed geodesic. Thus, on the sphere, all geodesics are closed. On a smooth surface topologically equivalent to the sphere, this may not be true, but there are always at least three simple closed geodesics; this is the [[theorem of the three geodesics]].<ref>{{citation\n | last = Grayson | first = Matthew A.\n | doi = 10.2307/1971486\n | issue = 1\n | journal = [[Annals of Mathematics]]\n | mr = 979601\n | pages = 71–111\n | series = Second Series\n | title = Shortening embedded curves\n | url = http://wwwmath.uni-muenster.de/u/janmark/Grayson_CurveInSurface.pdf\n | volume = 129\n | year = 1989}}.</ref> Manifolds all of whose geodesics are closed have been thoroughly investigated in the mathematical literature. On a compact hyperbolic [[surface (differential geometry)|surface]], whose fundamental group has no torsion, closed geodesics are in one-to-one correspondence with non-trivial [[conjugacy class]]es of elements in the [[Fuchsian group]] of the surface.\n\n==See also==\n*[[Lyusternik–Fet theorem]]\n*[[Curve-shortening flow]]\n*[[Selberg trace formula]]\n*[[Selberg zeta function]]\n*[[Zoll surface]]\n\n==References==\n{{Reflist}}\n\n*[[Arthur Besse|Besse, A.]]: \"Manifolds all of whose geodesics are closed\", ''Ergebisse Grenzgeb. Math.'', no. 93, Springer, Berlin, 1978.\n*[[Wilhelm Klingenberg|Klingenberg, W.]]: \"Lectures on closed geodesics\", Grundlehren der Mathematischen Wissenschaften, Vol. 230. Springer-Verlag, Berlin-New York, 1978. x+227 pp. {{ISBN|3-540-08393-6}}\n\n[[Category:Differential geometry]]\n[[Category:Dynamical systems]]\n[[Category:Geodesic (mathematics)]]"
    },
    {
      "title": "Geodesic manifold",
      "url": "https://en.wikipedia.org/wiki/Geodesic_manifold",
      "text": "{{context|date=January 2013}}\nIn [[mathematics]], a '''complete manifold''' (or '''geodesically complete manifold''') {{Mvar|M}} is a ([[Pseudo-Riemannian manifold|pseudo]]-) [[Riemannian manifold]] for which {{Math|exp{{sub|''p''}}}}, the [[Exponential map (Riemannian geometry)|exponential map]] at a point {{Mvar|p}}, is defined on {{Math|''TM''{{sub|''p''}}}}, the entire tangent space at {{Mvar|p}}.  \n\nEquivalently, consider a maximal [[geodesic]] {{Math|''l'':''I''&rarr;''M''}}.  {{Mvar|I}} is an open interval of {{Mvar|&#x0211D;}}, and, because geodesics travel at fixed speed, uniquely defined up to translation.  Because {{Mvar|l}} is maximal, {{Mvar|l}} maps the [[End (topology)|ends]] of {{Mvar|I}} to points of {{Math|&part;''M''}}, and the length of {{Mvar|I}} measures the distance between those points.  A manifold is geodesically complete if for any such {{Mvar|l}}, {{Math|1=''I''=(-&infin;,&infin;)}}.  \n\n==Examples and non-examples==\nAll [[compact space|compact]] Riemannian manifolds and all [[homogeneous space|homogeneous]] manifolds are geodesically complete.\n\n[[Euclidean space]] {{Math|&#x0211D;{{sup|n}}}}, the [[sphere]]s {{Math|&#x1D54A;{{sup|n}}}}, and the [[torus|tori]] {{Math|&#x1D54B;{{sup|n}}}} (with their natural [[Riemannian metric]]s) are all complete manifolds.\n\n=== Non-examples ===\nA simple example of a non-complete manifold is given by the punctured plane {{Math|&#x0211D;{{sup|2}}\\{0} }} (with its induced metric). Geodesics going to the origin cannot be defined on the entire real line.\n\nThere exist non-geodesically complete compact pseudo-Riemannian (but not Riemannian) manifolds. It is the case for example of the [[Clifton–Pohl torus]].\n\n==Path-connectedness, completeness and geodesic completeness==\nIt can be shown that a finite-dimensional [[Connected space#Path connectedness|path-connected]] Riemannian manifold is a [[complete metric space]] (with respect to the [[Riemannian manifold#Riemannian manifolds as metric spaces 2|Riemannian distance]]) if and only if it is geodesically complete. This is the [[Hopf–Rinow theorem]]. This theorem does not hold for infinite-dimensional manifolds. The example of a non-complete manifold (the punctured plane) given above fails to be geodesically complete because, although it is path-connected, it is not a complete metric space: any sequence in the plane converging to the origin is a non-converging Cauchy sequence in the punctured plane.\n\n==References==\n* {{Cite book|title=Semi-Riemannian Geometry|last=O'Neill|first=Barrett|publisher=[[Academic Press]]|year=1983|isbn=0-12-526740-1|location=|pages=|at=Chapter 3}}\n\n{{DEFAULTSORT:Complete Manifold}}\n[[Category:Riemannian geometry]]\n[[Category:Manifolds]]\n[[Category:Geodesic (mathematics)]]"
    },
    {
      "title": "Geodesic curvature",
      "url": "https://en.wikipedia.org/wiki/Geodesic_curvature",
      "text": "In [[Riemannian geometry]], the '''geodesic curvature''' <math>k_g</math> of a curve <math>\\gamma</math> measures how far the curve is from being a [[geodesic]]. For example, for [[Curvature of curves on surfaces|1D curves on a 2D surface embedded in 3D space]], it is the curvature of the curve projected onto the surface's tangent plane. More generally, in a given manifold <math>\\bar{M}</math>, the '''geodesic curvature''' is just the usual '''curvature''' of <math>\\gamma</math> (see below). However, when the curve <math>\\gamma</math> is restricted to lie on a submanifold <math>M</math> of <math>\\bar{M}</math> (e.g. for [[Curvature#Curves on surfaces|curves on surfaces]]), geodesic curvature refers to the curvature of <math>\\gamma</math> in <math>M</math> and it is different in general from the curvature of <math>\\gamma</math> in the ambient manifold  <math>\\bar{M}</math>. The (ambient) curvature <math>k</math> of <math>\\gamma</math> depends on two factors: the curvature of the submanifold <math>M</math> in the direction of <math>\\gamma</math> (the [[normal curvature]] <math>k_n</math>), which depends only on the direction of the curve, and the curvature of <math>\\gamma</math> seen in <math>M</math> (the geodesic curvature <math>k_g</math>), which is a second order quantity. The relation between these is <math>k = \\sqrt{k_g^2+k_n^2}</math>. In particular geodesics on <math>M</math> have zero geodesic curvature (they are \"straight\"), so that <math>k=k_n</math>, which explains why they appear to be curved in ambient space whenever the submanifold is.\n\n==Definition==\nConsider a curve <math>\\gamma</math> in a manifold <math>\\bar{M}</math>, parametrized by [[arclength]], with unit tangent vector <math>T=d\\gamma/ds</math>. Its curvature is the norm of the [[Covariant derivative#Derivative along curve|covariant derivative]] of <math>T</math>: <math>k = \\|DT/ds \\|</math>. If <math>\\gamma</math> lies on <math>M</math>, the '''geodesic curvature''' is the norm of the projection of the covariant derivative <math>DT/ds</math> on the tangent space to the submanifold. Conversely the '''normal curvature''' is the norm of the projection of <math>DT/ds</math> on the normal bundle to the submanifold at the point considered.\n\nIf the ambient manifold is the euclidean space <math>\\mathbb{R}^n</math>, then the covariant derivative <math>DT/ds</math> is just the usual derivative <math>dT/ds</math>.\n\n==Example==\nLet <math>M</math> be the unit sphere <math>S^2</math> in three-dimensional Euclidean space. The normal curvature of <math>S^2</math> is identically 1, independently of the direction considered. Great circles have curvature <math>k=1</math>, so they have zero geodesic curvature, and are therefore geodesics. Smaller circles of radius <math>r</math> will have curvature <math>1/r</math> and geodesic curvature <math>k_g = \\frac{\\sqrt{1-r^2}}{r}</math>.\n\n==Some results involving geodesic curvature==\n\n*The geodesic curvature is none other than the usual curvature of the curve when computed intrinsically in the submanifold <math>M</math>. It does not depend on the way the submanifold <math>M</math> sits in <math>\\bar{M}</math>.\n* Geodesics of <math>M</math> have zero geodesic curvature, which is equivalent to saying that <math>DT/ds</math> is orthogonal to the tangent space to <math>M</math>.\n*On the other hand the normal curvature depends strongly on how the submanifold lies in the ambient space, but marginally on the curve: <math>k_n</math> only depends on the point on the submanifold and the direction <math>T</math>, but not on <math>DT/ds</math>.\n*In general Riemannian geometry, the derivative is computed using the [[Levi-Civita connection]] <math>\\bar{\\nabla}</math> of the ambient manifold: <math>DT/ds = \\bar{\\nabla}_T T</math>. It splits into a tangent part and a normal part to the submanifold: <math>\\bar{\\nabla}_T T = \\nabla_T T + (\\bar{\\nabla}_T T)^\\perp</math>. The tangent part is the usual derivative <math>\\nabla_T T</math> in <math>M</math> (it is a particular case of Gauss equation in the [[Gauss-Codazzi equations]]), while the normal part is <math>\\mathrm{I\\!I}(T,T)</math>, where <math>\\mathrm{I\\!I}</math> denotes the [[second fundamental form]].\n*The [[Gauss–Bonnet theorem]].\n\n==See also==\n* [[Curvature]]\n* [[Darboux frame]]\n* [[Gauss–Codazzi equations]]\n\n== References ==\n*{{citation | last = do Carmo|first =Manfredo P. |authorlink=Manfredo do Carmo | title=Differential Geometry of Curves and Surfaces | publisher=Prentice-Hall | year=1976 | isbn = 0-13-212589-7}}\n* {{citation|first=Heinrich|last=Guggenheimer|author-link=Heinrich Guggenheimer|title=Differential Geometry|year=1977|publisher=Dover|chapter=Surfaces|isbn=0-486-63433-7}}.\n* {{springer|id=G/g044070|title=Geodesic curvature|first=Yu.S.|last=Slobodyan|year=2001}}.\n\n==External links==\n* {{Mathworld|urlname=GeodesicCurvature|title=Geodesic curvature}}\n\n[[Category:Geodesic (mathematics)]]\n[[Category:Manifolds]]"
    },
    {
      "title": "Geodesic deviation",
      "url": "https://en.wikipedia.org/wiki/Geodesic_deviation",
      "text": "In [[general relativity]], '''geodesic deviation''' describes the tendency of objects to approach or recede from one another while moving under the influence of a spatially varying [[gravitational field]]. Put another way, if two objects are set in motion along two initially parallel trajectories, the presence of a [[tidal force|tidal gravitational force]] will cause the trajectories to bend towards or away from each other, producing a relative [[acceleration]] between the objects.<ref name=\"ohanian\">{{cite book|last1=Ohanian|first1=Hans|title=Gravitation and Spacetime|edition=1st|year=1976|pages=271&ndash;6}}</ref>\n\nMathematically, the tidal force in general relativity is described by the [[Riemann curvature tensor]],<ref name=\"ohanian\" /> and the trajectory of an object solely under the influence of gravity is called a ''[[geodesic]]''. The ''geodesic deviation equation'' relates the Riemann curvature tensor to the relative acceleration of two neighboring geodesics. In [[differential geometry]], the geodesic deviation equation is more commonly known as the [[Jacobi field|Jacobi equation]].\n\n== Mathematical definition ==\n\nTo quantify geodesic deviation, one begins by setting up a family of closely spaced geodesics indexed by a continuous variable ''s'' and parametrized by an [[affine parameter]] τ. That is, for each fixed ''s'', the curve swept out by γ<sub>''s''</sub>(τ) as τ varies is a geodesic. When considering the geodesic of a massive object, it is often convenient to choose τ to be the object's [[proper time]]. If ''x''<sup>μ</sup>(''s'',&nbsp;τ) are the coordinates of the geodesic  γ<sub>''s''</sub>(τ), then the [[tangent vector]] of this geodesic is\n\n:<math>T^\\mu = \\frac{\\partial x^\\mu(s, \\tau)}{\\partial \\tau}.</math>\n\nIf τ is the proper time, then ''T''<sup>μ</sup> is the [[four velocity]] of the object traveling along the geodesic.\n\nOne can also define a ''deviation vector'', which is the displacement of two objects travelling along two infinitesimally separated geodesics:\n\n:<math>X^\\mu = \\frac{\\partial x^\\mu(s, \\tau)}{\\partial s}.</math>\n\nThe ''relative acceleration'' ''A''<sup>μ</sup> of the two objects is defined, roughly, as the second derivative of the separation vector ''X''<sup>μ</sup> as the objects advance along their respective geodesics. Specifically, ''A''<sup>μ</sup> is found by taking the directional [[covariant derivative]] of ''X'' along ''T'' twice:\n:<math> A^\\mu = T^\\alpha \\nabla_\\alpha (T^\\beta \\nabla_\\beta X^\\mu).</math>\n\nThe geodesic deviation equation relates ''A''<sup>μ</sup>, ''T''<sup>μ</sup>, ''X''<sup>μ</sup>, and the Riemann tensor ''R''<sup>μ</sup><sub>νρσ</sub>:<ref name=\"carroll\">{{cite book|last=Carroll|first=Sean|title=Spacetime and Geometry|year=2004|pages=144&ndash;6}}</ref>\n:<math> A^\\mu = {R^\\mu}_{\\nu\\rho\\sigma} T^\\nu T^\\rho X^\\sigma.</math>\n\nAn alternate notation for the directional covariant derivative <math>T^\\alpha \\nabla_\\alpha</math> is <math>D/d\\tau</math>, so the geodesic deviation equation may also be written as\n:<math>\\frac{D^2 X^\\mu}{d\\tau^2} = {R^\\mu}_{\\nu\\rho\\sigma} T^\\nu T^\\rho X^\\sigma.</math>\n\nThe geodesic deviation equation can be derived from the [[second variation]] of the point particle [[Lagrangian mechanics|Lagrangian]] along geodesics, or from the first variation of a combined Lagrangian.{{Clarify|date=September 2009}} The Lagrangian approach has two advantages. First it allows various formal approaches of [[Quantization (physics)|quantization]] to be applied to the geodesic deviation system. Second it allows deviation to be formulated for much more general objects than geodesics (any [[dynamical system]] which has a one [[spacetime]] indexed momentum appears to have a corresponding generalization of geodesic deviation).{{Citation needed|date=September 2009}}\n\n==Weak field limit==\n\nThe connection between geodesic deviation and tidal acceleration can be seen more explicitly by examining geodesic deviation in the [[Linearized gravity|weak-field limit]], where the metric is approximately Minkowski, and the velocities of test particles are assumed to be much less than ''c''. Then the tangent vector ''T''<sup>μ</sup> is approximately (1, 0, 0, 0); i.e., only the timelike component is nonzero.\n\nThe spatial components of the relative acceleration are then given by\n:<math> A^i = -{R^i}_{0j0} X^j,</math>\nwhere ''i'' and ''j'' run only over the spatial indices 1, 2, and 3.\n\nIn the particular case of a metric corresponding to the Newtonian potential Φ(''x'', ''y'', ''z'') of a massive object at ''x'' = ''y'' = ''z'' = 0, we have\n:<math> {R^i}_{0j0} = -\\frac{\\partial^2\\Phi}{\\partial x^i \\partial x^j},</math>\nwhich is the [[tidal tensor]] of the Newtonian potential.\n\n==See also==\n*[[Bernhard Riemann]]\n*[[Curvature]]\n*[[Glossary of Riemannian and metric geometry]]\n\n==References==\n{{reflist}}\n\n*{{Citation|title=General relativity - an introduction to the theory of the gravitation field|first=Hans|last=Stephani|publisher=Cambridge University Press|year=1982|isbn=0-521-37066-3}}.\n*{{Citation | last1=Wald | first1=Robert M. | author1-link=Robert Wald | title=[[General Relativity (book)|General Relativity]] | isbn=978-0-226-87033-5 | year=1984}}.\n\n==External links==\n*[http://www.arXiv.org/abs/gr-qc/0404094 General Relativity and Quantum Cosmology]\n*[http://www.mth.uct.ac.za/omei/gr/chap6/node11.html Tensors and Relativity: Geodesic deviation]\n\n{{DEFAULTSORT:Geodesic Deviation Equation}}\n[[Category:Geodesic (mathematics)]]\n[[Category:Riemannian geometry]]\n[[Category:Equations]]"
    },
    {
      "title": "Geodesics as Hamiltonian flows",
      "url": "https://en.wikipedia.org/wiki/Geodesics_as_Hamiltonian_flows",
      "text": "In [[mathematics]], the [[geodesic equation]]s are second-order non-linear [[differential equation]]s, and are commonly presented in the form of [[Euler–Lagrange]] equations of motion. However, they can also be presented as a set of coupled first-order equations, in the form of [[Hamilton's equations]]. This latter formulation is developed in this article.\n\n==Overview==\nIt is frequently said that [[geodesics]] are \"straight lines in curved space\". By using the Hamilton–Jacobi approach to the [[geodesic equation]], this statement can be given a very intuitive meaning: geodesics describe the motions of particles that are not experiencing any forces. In flat space, it is well known that a particle moving in a straight line will continue to move in a straight line if it experiences no external forces; this is [[Newton's first law]]. The Hamiltonian describing such motion is well known to be <math>H=mv^2/2=p^2/2m</math> with ''p'' being the [[momentum]]. It is the [[conservation of momentum]] that leads to the straight motion of a particle. On a curved surface, exactly the same ideas are at play, except that, in order to measure distances correctly, one must use the [[Metric (mathematics)|metric]]. To measure momenta correctly, one must use the inverse of the metric. The motion of a free particle on a curved surface still has exactly the same form as above, i.e. consisting entirely of a [[kinetic term]]. The resulting motion is still, in a sense, a \"straight line\", which is why it is sometimes said that geodesics are \"straight lines in curved space\". This idea is developed in greater detail below.\n\n==Geodesics as an application of the principle of least action==\nGiven a ([[pseudo-Riemannian manifold|pseudo]]-)[[Riemannian manifold]] ''M'', a [[geodesic]] may be defined as the curve that results from the application of the [[principle of least action]]. A differential equation describing their shape may be derived, using [[variational principle]]s, by minimizing (or finding the extremum) of the [[energy]] of a curve. Given a [[smooth curve]]\n \n:<math>\\gamma:I\\to M</math>\n\nthat maps an interval ''I'' of the [[real number line]] to the manifold ''M'', one writes the energy\n\n:<math>E(\\gamma)=\\frac{1}{2}\\int_I g(\\dot\\gamma(t),\\dot\\gamma(t))\\,dt,</math>\n\nwhere <math>\\dot\\gamma(t)</math> is the [[tangent vector]] to the curve <math>\\gamma</math> at point <math>t \\in I</math>.\nHere, <math>g(\\cdot,\\cdot)</math> is the [[metric tensor]] on the manifold ''M''. \n  \nUsing the energy given above as the action, one may choose to solve either the [[Euler–Lagrange equations]] or the [[Hamilton–Jacobi equations]]. Both methods give the [[geodesic equation]] as the solution; however, the Hamilton–Jacobi equations provide greater insight into the structure of the manifold, as shown below. In terms of the [[local coordinates]] on ''M'', the (Euler–Lagrange) geodesic equation is  \n\n:<math>\\frac{d^2x^a}{dt^2} + \\Gamma^{a}_{bc}\\frac{dx^b}{dt}\\frac{dx^c}{dt} = 0</math>\n\nwhere the ''x''<sup>''a''</sup>(''t'') are the coordinates of the curve γ(''t''), <math>\\Gamma^{a}_{bc}</math> are the [[Christoffel symbol]]s, and repeated indices imply the use of the [[summation convention]].\n\n==Hamiltonian approach to the geodesic equations==\nGeodesics can be understood to be the [[Hamiltonian flow]]s of a special [[Hamiltonian vector field]] defined on the [[cotangent space]] of the manifold. The Hamiltonian is constructed from the metric on the manifold, and is thus a [[quadratic form]] consisting entirely of the [[kinetic term]]. \n\nThe geodesic equations are second-order differential equations; they can be re-expressed as first-order equations by introducing additional independent variables, as shown below.  Note that a coordinate neighborhood ''U'' with coordinates ''x''<sub>''a''</sub> induces a ''[[local trivialization]]'' of \n:<math>T^*M|_{U}\\simeq U \\times \\mathbb{R}^n</math>\nby the map which sends a point \n:<math>\\eta \\in T_x^*M|_{U}</math>\nof the form \n<math>\\eta = p_a dx^a</math> to the point <math>(x,p_a) \\in U\\times\\mathbb{R}^n</math>.\nThen introduce the [[Hamiltonian vector field|Hamiltonian]] as\n\n:<math>H(x,p)=\\frac{1}{2}g^{ab}(x)p_a p_b.</math>\n\nHere, ''g''<sup>''ab''</sup>(''x'') is the inverse of the [[metric tensor]]: ''g''<sup>''ab''</sup>(''x'')''g''<sub>''bc''</sub>(''x'') = <math>\\delta^a_c</math>.  The behavior of the metric tensor under coordinate transformations implies that ''H'' is [[invariant (mathematics)|invariant]] under a change of variable. The geodesic equations can then be written as\n\n:<math>\\dot{x}^a = \\frac{\\partial H}{\\partial p_a} = g^{ab}(x) p_b</math>\n\nand\n\n:<math>\\dot{p}_a = - \\frac {\\partial H}{\\partial x^a} = \n-\\frac{1}{2} \\frac {\\partial g^{bc}(x)}{\\partial x^a} p_b p_c.</math>\n\nThe [[flow (mathematics)|flow]] determined by these equations is called the '''cogeodesic flow'''; a simple substitution of one into the other obtains the Euler–Lagrange equations, which give the '''geodesic flow''' on the tangent bundle ''TM''.  The geodesic lines are the projections of integral curves of the geodesic flow onto the manifold ''M''.  This is a [[Hamiltonian flow]], and the Hamiltonian is constant along the geodesics:\n\n:<math>\\frac{dH}{dt} = \\frac {\\partial H}{\\partial x^a} \\dot{x}^a +\n\\frac{\\partial H}{\\partial p_a} \\dot{p}_a = \n- \\dot{p}_a \\dot{x}^a + \\dot{x}^a \\dot{p}_a = 0.</math>\n\nThus, the geodesic flow splits the cotangent bundle into [[level set]]s of constant energy \n\n:<math>M_E = \\{ (x,p) \\in T^*M : H(x,p)=E \\}</math> \n\nfor each energy ''E'' ≥ 0, so that \n\n:<math>T^*M=\\bigcup_{E \\ge 0} M_E</math>.\n\n==References==\n* Terence Tao, ''The Euler-Arnold Equation'', 2010:  http://terrytao.wordpress.com/2010/06/07/the-euler-arnold-equation/ ''See the discussion at the beginning''\n* Ralph Abraham and Jerrold E. Marsden, ''Foundations of Mechanics'', (1978) Benjamin-Cummings, London {{ISBN|0-8053-0102-X}} ''See section 2.7''.\n* B.A. Dubrovin, A.T. Fomenko, and S.P. Novikov, ''Modern Geometry: Methods and Applications, Part I'', (1984) Springer-Verlag, Berlin {{ISBN|0-387-90872-2}} ''See chapter 5, in particular section 33''.\n\n[[Category:Symplectic geometry]]\n[[Category:Hamiltonian mechanics]]\n[[Category:Geodesic (mathematics)]]"
    },
    {
      "title": "Lyusternik–Fet theorem",
      "url": "https://en.wikipedia.org/wiki/Lyusternik%E2%80%93Fet_theorem",
      "text": "In [[mathematics]], the '''Lyusternik–Fet theorem''' states that  on every compact [[Riemannian manifold]] there exists a [[closed geodesic]]. It is named after [[Lazar Lyusternik]] and [[Abram Ilyich Fet]].\n\n== References ==\n* https://www.encyclopediaofmath.org/index.php/Closed_geodesic\n* L.A. Lyusternik, A.I. Fet, \"Variational problems on closed manifolds\" Dokl. Akad. Nauk. SSSR, 81 (1951) pp. 17–18 (In Russian)\n\n\n[[Category:Differential geometry]]\n[[Category:Geodesic (mathematics)]]"
    },
    {
      "title": "Prime geodesic",
      "url": "https://en.wikipedia.org/wiki/Prime_geodesic",
      "text": "{{Unreferenced|date=December 2009}}\nIn [[mathematics]], a '''prime geodesic''' on a [[hyperbolic geometry|hyperbolic]] [[Surface (topology)|surface]] is a '''primitive''' [[closed geodesic]], i.e. a geodesic which is a [[curve|closed curve]] that traces out its image exactly once. Such geodesics are called prime geodesics because, among other things, they obey an [[asymptotic analysis|asymptotic distribution law]] similar to the [[prime number theorem]].\n\n==Technical background==\nWe briefly present some facts from [[hyperbolic geometry]] which are helpful in understanding prime geodesics.\n\n===Hyperbolic isometries===\nConsider the [[Poincaré half-plane model]] ''H'' of 2-dimensional [[hyperbolic geometry]]. Given a [[Fuchsian group]], that is, a [[discrete subgroup]] Γ of [[projective linear group|PSL(2, '''R''')]], Γ [[Group action (mathematics)|acts]] on ''H'' via [[linear fractional transformation]]. Each element of PSL(2, '''R''') in fact defines an [[isometry]] of ''H'', so Γ is a group of isometries of ''H''.\n\nThere are then 3 types of transformation: hyperbolic, elliptic, and parabolic. (The loxodromic transformations are not present because we are working with [[real number]]s.) Then an element γ of Γ has 2 distinct real fixed points if and only if γ is hyperbolic. See [[Möbius transformation#Classification|Classification of isometries]] and [[Möbius transformation#Fixed points|Fixed points of isometries]] for more details.\n\n===Closed geodesics===\nNow consider the [[Quotient space (topology)|quotient surface]] ''M''=Γ\\''H''.  The following description refers to the upper half-plane [[Models of the hyperbolic plane|model of the hyperbolic plane]].  This is a hyperbolic surface, in fact, a [[Riemann surface]]. Each hyperbolic element ''h'' of Γ determines a [[closed geodesic]] of Γ\\''H'': first, by connecting the geodesic semicircle joining the fixed points of ''h'', we get a geodesic on ''H'' called the axis of ''h'', and by projecting this geodesic to ''M'', we get a geodesic on Γ\\''H''.\n\nThis geodesic is closed because 2 points which are in the same orbit under the action of Γ project to the same point on the quotient, by definition.\n\nIt can be shown that this gives a [[bijection|1-1 correspondence]] between closed geodesics on Γ\\''H'' and hyperbolic [[conjugacy class]]es in Γ. The prime geodesics are then those geodesics that trace out their image exactly once &mdash; algebraically, they correspond to primitive hyperbolic conjugacy classes, that is, conjugacy classes {γ} such that γ cannot be written as a nontrivial power of another element of Γ.\n\n==Applications of prime geodesics==\nThe importance of prime geodesics comes from their relationship to other branches of mathematics, especially [[dynamical systems]], [[ergodic theory]], and [[number theory]], as well as [[Riemann surface]]s themselves. These applications often overlap among several different research fields.\n\n===Dynamical systems and ergodic theory===\nIn dynamical systems, the [[closed geodesic]]s represent the [[Periodic function|periodic]] [[Group action (mathematics)|orbits]] of the [[Geodesic#Geodesic flow|geodesic flow]].\n\n===Number theory===\nIn number theory, various \"prime geodesic theorems\" have been proved which are very similar in spirit to the [[prime number theorem]]. To be specific, we let π(''x'') denote the number of closed geodesics whose norm (a function related to length) is less than or equal to ''x''; then π(''x'') ∼ ''x''/ln(''x''). This result is usually credited to [[Atle Selberg]]. In his 1970 Ph.D. thesis, [[Grigory Margulis]] proved a similar result for surfaces of variable negative curvature, while in his 1980 Ph.D. thesis, [[Peter Sarnak]] proved an analogue of [[Chebotarev's density theorem]].\n\nThere are other similarities to number theory &mdash; error estimates are improved upon, in much the same way that error estimates of the prime number theorem are improved upon. Also, there is a [[Selberg zeta function]] which is formally similar to the usual [[Riemann zeta function]] and shares many of its properties.\n\nAlgebraically, prime geodesics can be lifted to higher surfaces in much the same way that [[prime ideal]]s in the [[ring of integers]] of a [[number field]] can be split (factored) in a [[Galois extension]]. See [[Covering map]] and [[Splitting of prime ideals in Galois extensions]] for more details.\n\n===Riemann surface theory===\nClosed geodesics have been used to study Riemann surfaces; indeed, one of [[Riemann]]'s original definitions of the [[genus (mathematics)|genus]] of a surface was in terms of simple closed curves. Closed geodesics have been instrumental in studying the [[eigenvalue]]s of [[Laplacian]] [[operator (mathematics)|operator]]s, [[arithmetic group|arithmetic Fuchsian group]]s, and [[Teichmüller space]]s.\n\n==See also==\n*[[Fuchsian group]]\n*[[Modular group Gamma]]\n*[[Riemann surface]]\n*[[Fuchsian model]]\n*[[Analytic number theory]]\n*[[Zoll surface]]\n\n{{DEFAULTSORT:Prime Geodesic}}\n[[Category:Riemann surfaces]]\n[[Category:Differential geometry]]\n[[Category:Dynamical systems]]\n[[Category:Number theory]]\n[[Category:Geodesic (mathematics)]]\n[[Category:Hyperbolic geometry]]"
    },
    {
      "title": "Theorem of the three geodesics",
      "url": "https://en.wikipedia.org/wiki/Theorem_of_the_three_geodesics",
      "text": "In [[differential geometry]] the '''theorem of the three geodesics''' states that every [[Riemannian manifold]] with the topology of a [[sphere]] has at least three [[closed geodesic]]s that form [[simple closed curve]]s without self-intersections.<ref name=\"k\">{{citation\n | last = Klingenberg | first = Wilhelm\n | authorlink = Wilhelm Klingenberg\n | contribution = The existence of three short closed geodesics\n | mr = 780043\n | pages = 169–179\n | publisher = Springer, Berlin\n | title = Differential geometry and complex analysis\n | contribution-url = https://books.google.com/books?id=IpbzCAAAQBAJ&pg=PA169\n | year = 1985}}.<!-- The MR review claims that the main result of this reference is dubious, so use only for historical purposes. --></ref><ref name=\"grayson\"/> The result can also be extended to quasigeodesics on a convex polyhedron.\n\n==History and proof==\n[[File:Ellipsoid tri-axial abc.svg|thumb|A triaxial ellipsoid and its three geodesics]]\nThis result stems from the mathematics of ocean navigation, where the surface of the earth can be modeled accurately by an [[ellipsoid]], and from the study of the [[geodesics on an ellipsoid]], the shortest paths for ships to travel. In particular, a nearly-spherical triaxial ellipsoid has only three simple closed geodesics, its equators.<ref name=\"galperin\">{{citation\n | last = Galperin | first = G.\n | doi = 10.1070/RD2003v008n01ABEH000231\n | issue = 1\n | journal = Regular & Chaotic Dynamics\n | mr = 1963967\n | pages = 45–58\n | title = Convex polyhedra without simple closed geodesics\n | url = http://www.ux1.eiu.edu/~cfgg/papers/GeodesRCD.pdf\n | volume = 8\n | year = 2003| bibcode = 2003RCD.....8...45G\n }}.</ref> In 1905, [[Henri Poincaré]] conjectured that every smooth surface topologically equivalent to a sphere likewise contains at least three simple closed geodesics,<ref>{{citation\n | last = Poincaré | first = H. | author-link = Henri Poincaré\n | doi = 10.2307/1986219\n | issue = 3\n | journal = Transactions of the American Mathematical Society\n | jstor = 1986219\n | language = French\n | pages = 237–274\n | title = Sur les lignes géodésiques des surfaces convexes\n |trans-title=Geodesics lines on convex surfaces\n | url = https://books.google.com/books?id=o0MLAAAAYAAJ&pg=PA237\n | volume = 6\n | year = 1905}}.</ref> and in 1929 [[Lazar Lyusternik]] and [[Lev Schnirelmann]] published a proof of the conjecture, which was later found to be flawed.<ref>{{citation\n | last1 = Lyusternik | first1 = L. | author1-link = Lazar Lyusternik\n | last2 = Schnirelmann | first2 = L. | author2-link = Lev Schnirelmann\n | journal = Comptes Rendus de l'Académie des Sciences de Paris\n | language = French\n | pages = 269–271\n | title = Sur le problème de trois géodésiques fermées sur les surfaces de genre 0\n |trans-title=The problem of three closed geodesics on surfaces of genus 0\n | url = http://gallica.bnf.fr/ark:/12148/bpt6k3142j/f269\n | volume = 189\n | year = 1929}}.</ref>\nThe proof was repaired by [[Hans Werner Ballmann]] in 1978.<ref>{{citation\n| last1 = Ballmann | first1 = Werner\n| title = Der Satz von Lusternik und Schnirelmann\n| journal = Math. Shriften \n| volume = 102\n| pages = 1–25\n| year = 1978}}.</ref>\n\nOne proof of this conjecture examines the [[Homology (mathematics)|homology]] of the space of smooth curves on the sphere, and uses the [[curve-shortening flow]] to find a simple closed geodesic that represents each of the three nontrivial homology classes of this space.<ref name=\"grayson\">{{citation\n | last = Grayson | first = Matthew A.\n | doi = 10.2307/1971486\n | issue = 1\n | journal = [[Annals of Mathematics]]\n | mr = 979601\n | pages = 71–111\n | series = Second Series\n | title = Shortening embedded curves\n | url = http://wwwmath.uni-muenster.de/u/janmark/Grayson_CurveInSurface.pdf\n | volume = 129\n | year = 1989| jstor = 1971486\n }}.</ref>\n\n==Generalizations==\nMore strongly, there necessarily exist three simple closed geodesics whose length is at most proportional to the diameter of the surface.<ref>{{citation\n | last1 = Liokumovich | first1 = Yevgeny\n | last2 = Nabutovsky | first2 = Alexander\n | last3 = Rotman | first3 = Regina\n | arxiv = 1410.8456\n | title = Lengths of three simple periodic geodesics on a Riemannian 2-sphere\n | year = 2014| bibcode = 2014arXiv1410.8456L}}.</ref>\n\nThe number of closed geodesics of length at most ''L'' on a smooth topological sphere grows in proportion to ''L''/log&nbsp;''L'', but not all such geodesics can be guaranteed to be simple.<ref>{{citation\n | last = Hingston | first = Nancy | authorlink = Nancy Hingston\n | doi = 10.1155/S1073792893000285\n | issue = 9\n | journal = International Mathematics Research Notices\n | volume = 1993 | mr = 1240637\n | pages = 253–262\n | title = On the growth of the number of closed geodesics on the two-sphere\n | year = 1993}}.</ref>\n\nOn compact [[hyperbolic geometry|hyperbolic]] [[Riemann surface]]s, there are infinitely many simple closed geodesics, but only finitely many with a given length bound. They are encoded analytically by the [[Selberg zeta function]]. The growth rate of the number of simple closed geodesics, as a function of their length, was investigated by [[Maryam Mirzakhani]].<ref>{{citation|last1=Mirzakhani|first1=Maryam |title=Growth of the number of simple closed geodesics on hyperbolic surfaces|journal=[[Annals of Mathematics]]|year=2008 |doi=10.4007/annals.2008.168.97|volume=168|issue=1|pages=97–125|mr=2415399|zbl=1177.37036}},</ref>\n\n==Non-smooth metrics==\n{{unsolved|computer science|Is there an algorithm that can find a simple closed quasigeodesic on a convex polyhedron in polynomial time?}}\nIt is also possible to define geodesics on some surfaces that are not smooth everywhere, such as [[convex polyhedron|convex polyhedra]]. Although some polyhedra have simple closed geodesics (for instance, the [[regular tetrahedron]] and [[disphenoid]]s have infinitely many closed geodesics, all simple)<ref name=\"fuchs2\">{{citation\n | last1 = Fuchs | first1 = Dmitry\n | authorlink1= :de:Dmitry Fuchs\n | last2 = Fuchs | first2 = Ekaterina\n | issue = 2\n | journal = Moscow Mathematical Journal\n | mr = 2337883\n | pages = 265–279, 350\n | title = Closed geodesics on regular polyhedra\n | url = http://www.ams.org/distribution/mmj/vol7-2-2007/fuchs.pdf\n | volume = 7\n | year = 2007| doi = 10.17323/1609-4514-2007-7-2-265-279\n }}.</ref><ref>{{citation\n | last1 = Cotton | first1 = Andrew\n | last2 = Freeman | first2 = David\n | last3 = Gnepp | first3 = Andrei\n | last4 = Ng | first4 = Ting\n | last5 = Spivack | first5 = John\n | last6 = Yoder | first6 = Cara\n | doi = 10.1017/S1446788700008016\n | issue = 2\n | journal = Journal of the Australian Mathematical Society\n | mr = 2141875\n | pages = 167–197\n | title = The isoperimetric problem on some singular surfaces\n | volume = 78\n | year = 2005}}.</ref> others do not. In particular, a simple closed geodesic of a convex polyhedron would necessarily bisect the total [[angular defect]] of the vertices, and [[almost all]] polyhedra do not have such bisectors.<ref name=\"galperin\"/><ref name=\"fuchs2\"/>\n\nNevertheless, the theorem of the three geodesics can be extended to convex polyhedra by considering quasigeodesics, curves that are geodesic except at the vertices of the polyhedra and that have angles less than {{pi}} on both sides at each vertex they cross. A version of the theorem of the three geodesics for convex polyhedra states that all polyhedra have at least three simple closed quasigeodesics; this can be proved by approximating the polyhedron by a smooth surface and applying the theorem of the three geodesics to this surface.<ref>{{citation\n | last = Pogorelov | first = A. V. | authorlink = Aleksei Pogorelov\n | journal = [[Matematicheskii Sbornik]] | series = N.S.\n | mr = 0031767\n | pages = 275–306\n | title = Quasi-geodesic lines on a convex surface\n | volume = 25 | issue = 67\n | year = 1949\n | url        =http://www.mathnet.ru/php/getFT.phtml?jrnid=sm&paperid=6003&what=fullt&option_lang=rus}}.</ref> It is an [[open problem]] whether any of these quasigeodesics can be constructed in [[polynomial time]].<ref>{{citation\n | last1 = Demaine | first1 = Erik D. | author1-link = Erik Demaine\n | last2 = O'Rourke | first2 = Joseph | author2-link = Joseph O'Rourke (professor)\n | contribution = 24 Geodesics: Lyusternik–Schnirelmann\n | doi = 10.1017/CBO9780511735172\n | isbn = 978-0-521-71522-5\n | location = Cambridge\n | mr = 2354878\n | pages = 372–375\n | publisher = Cambridge University Press\n | title = Geometric folding algorithms: Linkages, origami, polyhedra\n | year = 2007}}.</ref><ref>{{citation\n | last1 = Itoh | first1 = Jin-ichi\n | last2 = O'Rourke | first2 = Joseph | author2-link = Joseph O'Rourke (professor)\n | last3 = Vîlcu | first3 = Costin\n | arxiv = 0707.4258\n | doi = 10.1007/s00454-009-9223-x\n | issue = 1\n | journal = [[Discrete and Computational Geometry]]\n | mr = 2639817\n | pages = 35–54\n | title = Star unfolding convex polyhedra via quasigeodesic loops\n | volume = 44\n | year = 2010}}.</ref>\n\n==References==\n{{reflist|30em}}\n\n[[Category:Theorems in differential geometry]]\n[[Category:Geodesic (mathematics)]]"
    },
    {
      "title": "Geometric flow",
      "url": "https://en.wikipedia.org/wiki/Geometric_flow",
      "text": "In [[mathematics]], specifically [[differential geometry]], a '''geometric flow''' is the [[gradient flow]] associated to a functional on a [[manifold]] which has a geometric interpretation, usually associated with some [[curvature|extrinsic or intrinsic curvature]]. They can be interpreted as flows on a [[moduli space]] (for intrinsic flows) or a [[parameter space]] (for extrinsic flows).\n\nThese are of fundamental interest in the [[calculus of variations]], and include several famous problems and theories.\nParticularly interesting are their [[critical point (mathematics)|critical point]]s.\n\nA geometric flow is also called a '''geometric evolution equation'''.\n\n==Examples==\n\n===Extrinsic===\nExtrinsic geometric flows are flows on [[embedded submanifold]]s, or more generally\n[[immersed submanifold]]s. In general they change both the Riemannian metric and the immersion.\n* [[Mean curvature flow]], as in [[soap film]]s; critical points are [[minimal surface]]s\n* [[Curve-shortening flow]], the one-dimensional case of the mean curvature flow\n* [[Willmore flow]], as in [[minimax eversion]]s of spheres\n* [[Inverse mean curvature flow]]\n\n===Intrinsic===\nIntrinsic geometric flows are flows on the [[Riemannian metric]], independent of any embedding or immersion.\n* [[Ricci flow]], as in the [[solution of the Poincaré conjecture]], and [[Richard S. Hamilton]]'s proof of the [[uniformization theorem]]\n* [[Calabi flow]], two dimensional and for [[string theory]]\n* [[Yamabe flow]], be some special case of the Ricci flow\n\n==Classes of flows==\nImportant classes of flows are '''curvature flows''', '''variational flows''' (which extremize some functional), and flows arising as solutions to [[parabolic partial differential equation]]s. A given flow frequently admits all of these interpretations, as follows.\n\nGiven an [[elliptic operator]] ''L'', the parabolic PDE <math>u_t = Lu</math> yields a flow, and stationary states for the flow are solutions to the [[elliptic partial differential equation]] <math>Lu=0</math>.\n\nIf the equation <math>Lu=0</math> is the [[Euler–Lagrange equation]] for some functional ''F'', then the flow has a variational interpretation as the gradient flow of ''F'', and stationary states of the flow correspond to critical points of the functional.\n\nIn the context of geometric flows, the functional is often the [[L2 norm|''L''<sup>2</sup>]] norm of some curvature.\n\nThus, given a curvature ''K'', one can define the functional <math>F(K)=\\|K\\|_2 := \\left(\\int_M K^2\\right)^{1/2}</math>, which has Euler–Lagrange equation <math>Lu=0</math> for some elliptic operator ''L'', and associated parabolic PDE <math>u_t=Lu</math>.\n\nThe [[Ricci flow]], [[Calabi flow]], and [[Yamabe flow]] arise in this way (in some cases with normalizations).\n\nCurvature flows may or may not ''preserve volume'' (the Calabi flow does, while the Ricci flow does not), and if not, the flow may simply shrink or grow the manifold, rather than regularizing the metric. Thus one often normalizes the flow, for instance, by fixing the volume.\n\n==References==\n* {{cite journal\n| last = Bakas | first = Ioannis\n| title = The algebraic structure of geometric flows in two dimensions\n| origyear = 28 Jul 2005 (v1)\n| arxiv = hep-th/0507284\n| journal = [[Journal of High Energy Physics]]\n| volume = 2005 | issue = 10 | page = 038| date = 14 October 2005\n| doi = 10.1088/1126-6708/2005/10/038\n| bibcode = 2005JHEP...10..038B}}\n\n* {{cite journal\n| last = Bakas | first = Ioannis\n| title = Renormalization group equations and geometric flows\n| date = 5 Feb 2007\n| arxiv = hep-th/0702034\n| bibcode = 2007hep.th....2034B\n}}\n\n{{DEFAULTSORT:Geometric Flow}}\n[[Category:Geometric flow|*]]"
    },
    {
      "title": "Calabi flow",
      "url": "https://en.wikipedia.org/wiki/Calabi_flow",
      "text": "In [[differential geometry]], the '''Calabi flow''' is an intrinsic [[geometric flow]]—a process which deforms the [[metric tensor|metric]] of a [[Riemannian manifold]]—in a manner formally analogous to the way that [[oscillation|vibration]]s are [[damping|damped]] and [[dissipation|dissipated]] in a hypothetical curved ''n''-dimensional [[structural element]].\n\n==Introduction==\nThe Calabi flow is an intrinsic curvature flow, like the [[Ricci flow]].\nIt tends to smooth out deviations from roundness in a manner formally analogous to the way that the two-dimensional '''vibration equation''' damps and propagates away transverse mechanical vibrations in a thin plate, and it extremizes a certain intrinsic curvature functional.  \n\n==Formal statement==\nIf Σ is a closed Riemannian surface, then the Calabi flow is given by:<ref>S.-C. Chang ''The two-dimensional Calabi flow''\nNagoya Math. J., Vol. 181 (2006), 63–73</ref>\n\n:<math>\\frac{\\partial g_{ij}}{\\partial t}=(\\Delta R)g_{ij}</math>,\nwhere the <math>g_{ij}</math> are the coordinates of the metric, <math>\\Delta</math> is the [[Laplace-Beltrami operator]] and R is the [[scalar curvature]].\n\n==Use==\nThe Calabi flow is important in the study of  [[Kähler manifold]]s, particularly [[Calabi–Yau manifold]]s and also in the study of [[Robinson–Trautman spacetime]]s in [[general relativity]].  An intriguing observation is that the underlying '''Calabi equation''' appears to be '''completely integrable''', which would give a direct link with the [[soliton|theory of solitons]].\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{citation | author=Bakas, I. | title=The algebraic structure of geometric flows in two dimensions| arxiv=hep-th/0507284| bibcode=2005JHEP...10..038B}}\n\n{{DEFAULTSORT:Calabi Flow}}\n[[Category:Geometric flow]]\n[[Category:Partial differential equations]]\n[[Category:String theory]]"
    },
    {
      "title": "Curve-shortening flow",
      "url": "https://en.wikipedia.org/wiki/Curve-shortening_flow",
      "text": "{{good article}}\n[[File:Convex curve shortening.png|thumb|upright=1.3|Convergence of a convex curve to a circle under the curve-shortening flow. Inner curves (lighter color) are flowed versions of the outer curves. Time steps between curves are not uniform.]]\nIn mathematics, the '''curve-shortening flow''' is a process that modifies a [[smooth curve]] in the [[Euclidean plane]] by moving its points perpendicularly to the curve at a speed proportional to the [[curvature]]. The curve-shortening flow is an example of a [[geometric flow]], and is the one-dimensional case of the [[mean curvature flow]]. Other names for the same process include the '''Euclidean shortening flow''', '''geometric heat flow''',<ref>The phrase \"geometric heat flow\" has also been used for flows on other kinds of object than curves, such as [[differential form]]s.</ref> and '''arc length evolution'''.\n\nAs the points of any smooth [[simple closed curve]] move in this way, the curve remains simple and smooth. It loses area at a constant rate, and its perimeter decreases as quickly as possible for any continuous curve evolution. If the curve is non-convex, its [[total absolute curvature]] decreases monotonically, until it becomes convex. Once convex, the [[isoperimetric ratio]] of the curve decreases as the curve converges to a circular shape, before collapsing to a single point of singularity. If two disjoint simple smooth closed curves evolve, they remain disjoint until one of them collapses to a point.\nThe circle is the only simple closed curve that maintains its shape under the curve-shortening flow, but some curves that cross themselves or have infinite length keep their shape, including the grim reaper curve, an infinite curve that translates upwards, and [[spiral]]s that rotate while remaining the same size and shape.\n\nAn approximation to the curve-shortening flow can be computed numerically, by approximating the curve as a [[polygon]] and using the [[finite difference method]] to calculate the motion of each polygon vertex. Alternative methods include computing a [[convolution]] of polygon vertices and then resampling vertices on the resulting curve, or repeatedly applying a [[median filter]] to a [[digital image]] whose black and white pixels represent the inside and outside of the curve.\n\nThe curve-shortening flow was originally studied as a model for [[Annealing (metallurgy)|annealing]] of metal sheets. Later, it was applied in image analysis to give a multi-scale representation of shapes. It can also model [[reaction–diffusion system]]s, and the behavior of [[cellular automaton|cellular automata]]. In pure mathematics, the curve-shortening flow can be used to find [[closed geodesic]]s on [[Riemannian manifold]]s, and as a model for the behavior of higher-dimensional flows.\n\n==Definitions==\nA [[Flow (mathematics)|flow]] is a process in which the points of a mathematical space continuously change their locations or properties over time. More specifically, in a one-dimensional [[geometric flow]] such as the curve-shortening flow, the points undergoing the flow belong to a [[curve]], and what changes is the shape of the curve, its [[embedding]] into the Euclidean plane determined by the locations of each of its points.<ref>{{harvtxt|Devadoss|O'Rourke|2011}}, p.140: \"a geometric flow [is] an evolution of the geometry of {{mvar|C}} over time {{mvar|t}}.\"</ref>\nIn the curve-shortening flow, each point of a curve moves in the direction of a [[Normal (geometry)|normal vector]] to the curve, at a rate proportional to the [[curvature]]. For an evolving curve represented by a two-parameter function {{math|''C''(''s'',''t'')}} where {{mvar|s}} parameterizes the arc length along the curve and {{mvar|t}} parameterizes a time in the evolution of the curve, the curve-shortening flow can be described by the [[parabolic partial differential equation]]\n:<math>\\frac{\\partial C}{\\partial t} = \\frac{\\partial^2 C}{\\partial s^2} = \\kappa n,</math>\na form of the [[heat equation]], where {{math|''κ''}} is the curvature and {{mvar|n}} is the unit normal vector.{{sfnp|Devadoss|O'Rourke|2011|page=140}}\n\nBecause the ingredients of this equation, the arc length, curvature, and time, are all unaffected by translations and rotations of the Euclidean plane, it follows that the flow defined by this equation is invariant under translations and rotations (or more precisely, [[Equivariant map|equivariant]]). If the plane is scaled by a constant dilation factor, the flow remains essentially unchanged, but is slowed down or sped up by the same factor.{{sfnp|Grayson|1989a}}\n\n===Non-smooth curves===\nIn order for the flow to be well defined, the given curve must be sufficiently smooth that it has a continuous curvature. However, once the flow starts, the curve becomes [[differentiable manifold|analytic]], and remains so until reaching a singularity at which the curvature blows up. For a smooth curve without crossings, the only possible singularity happens when the curve collapses to a point, but [[Immersion (mathematics)|immersed curves]] can have other types of singularity.<ref>{{harvtxt|Grayson|1989a}}; {{harvtxt|White|2002}}.</ref>\nIn such cases, with some care it is possible to continue the flow past these singularities until the whole curve shrinks to a single point.<ref>{{harvtxt|Angenent|1991a}}; {{harvtxt|Altschuler|Grayson|1992}}.</ref>\n\nFor a simple closed curve, using an extension of the flow to non-smooth curves based on the [[level-set method]], there are only two possibilities. Curves with zero [[Lebesgue measure]] (including all [[polygon]]s and piecewise-smooth curves) instantly evolve into smooth curves, after which they evolve as any smooth curve would. However, [[Osgood curve]]s with nonzero measure instead immediately evolve into a topological [[Annulus (mathematics)|annulus]] with nonzero area and smooth boundaries.{{sfnp|Lauer|2013}} The [[topologist's sine curve]] is an example that instantly becomes smooth, despite not even being [[Locally connected space|locally connected]]; examples such as this show that the reverse evolution of the curve-shortening flow can take well-behaved curves to complicated singularities in a finite amount of time.{{sfnp|Lam|Lauer|2016}}\n\n===Non-Euclidean surfaces===\nThe curve-shortening flow, and many of the results about the curve-shortening flow, can be generalized from the Euclidean plane to any two-dimensional [[Riemannian manifold]]. In order to avoid additional types of singularity, it is important for the manifold to be ''convex at infinity''; this is defined to mean that every [[compact set]] has a compact [[convex hull]], as defined using [[geodesic convexity]]. The curve-shortening flow cannot cause a curve to depart from its convex hull, so this condition prevents parts of the curve from reaching the boundary of the manifold.{{sfnp|Ritoré|Sinestrari|2010|p=72}}\n\n===Space curves===\nThe curve-shortening flow has also been studied for curves in three-dimensional [[Euclidean space]]. The normal vector in this case can be defined (as in the plane) as the derivative of the tangent vector with respect to arc length, normalized to be a unit vector; it is one of the components of the [[Frenet–Serret formulas|Frenet–Serret frame]]. It is not well defined at points of zero curvature, but the product of the curvature and the normal vector remains well defined at those points, allowing the curve-shortening flow to be defined. Curves in space may cross each other or themselves according to this flow, and the flow may lead to singularities in the curves; every singularity is asymptotic to a plane.{{sfnp|Altschuler|1991}} The curve shortening flow for space curves has been used as a way to define flow past singularities in plane curves.{{sfnp|Altschuler|Grayson|1992}}\n\n===Beyond curves===\nIt is possible to extend the definition of the flow to more general inputs than curves, for instance by using [[Varifold|rectifiable varifolds]] or the [[level-set method]]. However, these extended definitions may allow parts of curves to vanish instantaneously or fatten into sets of nonzero area.<ref>{{harvtxt|Brakke|1978}}; {{harvtxt|White|1989}}; {{harvtxt|Cao|2003}}, \"4.7.1 Brakke's varifold solution\", p.&nbsp;100. {{harvtxt|Lauer|2013}}.</ref>\n\n[[File:Curve-shortening ambiguity.svg|thumb|upright=1.3|For networks of curves, extending the curve-shortening flow past a singularity may result in ambiguity or fattening.]]\nA commonly studied variation of the problem involves networks of interior-disjoint smooth curves, with junctions where three or more of the curves meet. When the junctions all have exactly three curves meeting at angles of 2{{pi}}/3 (the same conditions seen in an optimal [[Steiner tree]] or two-dimensional [[foam]] of [[soap bubble]]s) the flow is well-defined for the short term. However, it may eventually reach a singular state with four or more curves meeting at a junction, and there may be more than one way to continue the flow past such a singularity.{{sfnp|Ilmanen|Neves|Schulze|2014}}\n\n==Behavior==\n\n===Avoidance principle, radius, and stretch factor===\nIf two disjoint smooth [[Jordan curve theorem|simple closed curves]] undergo the curve-shortening flow simultaneously, they remain disjoint as the flow progresses. The reason is that, if two smooth curves move in a way that creates a crossing, then at the time of first crossing the curves would necessarily be tangent to each other, without crossing. But, in such a situation, the two curves' curvatures at the point of tangency would necessarily pull them apart rather than pushing them together into a crossing. For the same reason, a single simple closed curve can never evolve to cross itself. This phenomenon is known as the avoidance principle.{{sfnp|White|2002|page=526}}\n\nThe avoidance principle implies that any smooth curve eventually either reaches a singularity (such as a point of infinite curvature) or collapses to a point. For, if a given smooth curve {{mvar|C}} is surrounded by a circle, both will remain disjoint until one or the other collapses or reaches a singularity. But the enclosing circle shrinks under the curvature flow, remaining circular, until it collapses, and by the avoidance principle {{mvar|C}} must remain contained within it. By the same reasoning, the radius of the [[Smallest-circle problem|smallest circle that encloses {{mvar|C}}]] must decrease at a rate that is at least as fast as the decrease in radius of a circle undergoing the same flow.{{sfnp|White|2002|page=527}}\n\n{{harvtxt|Huisken|1998}} quantifies the avoidance principle for a single curve in terms of the ratio between the arc length (of the shorter of two arcs) and Euclidean distance between pairs of points, sometimes called the [[stretch factor]]. He shows that the stretch factor is strictly decreasing at each of its local maxima, except for the case of the two ends of a diameter of a circle in which case the stretch factor is constant at {{pi}}. This monotonicity property implies the avoidance principle, for if the curve would ever touch itself the stretch factor would become infinite at the two touching points.\n\n===Length===\nAs a curve undergoes the curve-shortening flow, its [[length]] {{mvar|L}} decreases at a rate given by the formula\n:<math>\\frac{dL}{dt} = -\\int \\kappa^2 \\, ds,</math>\nwhere the interval is taken over the curve, {{mvar|κ}} is the curvature, and {{mvar|s}} is arc length along the curve.\nThe integrand is always non-negative, and for any smooth closed curve there exist arcs within which it is strictly positive, so the length decreases monotonically.\nMore generally, for any evolution of curves whose normal speed is {{mvar|f}},\nthe rate of change in length is\n:<math>\\frac{dL}{dt} = -\\int f\\kappa \\, ds,</math>\nwhich can be interpreted as a negated [[inner product]] between the given evolution and the curve-shortening flow.\nThus, the curve-shortening flow can be described as the  [[gradient flow]] for length, the flow that (locally) decreases the length of the curve as quickly as possible relative to the [[Lp space|{{math|''L''<sup>2</sup>}} norm]] of the flow. This property is the one that gives the curve-shortening flow its name.<ref>{{harvtxt|Chou|Zhu|2001}}, p.&nbsp; vii; {{harvtxt|White|2002}}, p. 526.</ref>\n\n===Area===\nFor a simple closed curve, the [[area]] enclosed by the curve shrinks, at the constant rate of 2{{pi}} units of area per unit of time, independent of the curve. Therefore, the total time for a curve to shrink to a point is proportional to its area, regardless of its initial shape.<ref>{{harvtxt|Brakke|1978}}, Appendix B, Proposition 1, p.&nbsp;230; {{harvtxt|Chou|Zhu|2001}}, p.&nbsp; vii; {{harvtxt|White|2002}}, Theorem 1, p.&nbsp;527.</ref>\nBecause the area of a curve is reduced at a constant rate, and (by the [[isoperimetric inequality]]) a circle has the greatest possible area among simple closed curves of a given length, it follows that circles are the slowest curves to collapse to a point under the curve-shortening flow. All other curves take less time to collapse than a circle of the same length.{{sfnp|White|1989}}\n\nThe constant rate of area reduction is the only [[conservation law]] satisfied by the curve-shortening flow. This implies that it is not possible to express the \"vanishing point\" where the curve eventually collapses as an integral over the curve of any function of its points and their derivatives, because such an expression would lead to a forbidden second conservation law.{{sfnp|Bryant|Griffiths|1995}} However, by combining the constant rate of area loss with the avoidance principle, it is possible to prove that the vanishing point always lies within a circle, concentric with the minimum enclosing circle, whose area is the difference in areas between the enclosing circle and the given curve.{{sfnp|Kimmel|2004|pages=182–183}}\n\n===Total absolute curvature===\nThe [[total absolute curvature]] of a smooth curve is the integral of the [[absolute value]] of the curvature along the arc length of the curve,\n:<math>K=\\int|\\kappa| \\,ds.</math>\nIt can also be expressed as a sum of the angles between the normal vectors at consecutive pairs of [[inflection point]]s. It is 2{{pi}} for convex curves and larger for non-convex curves, serving as a measure of non-convexity of a curve.{{sfnp|Brook|Bruckstein|Kimmel|2005}}\n\nNew inflection points cannot be created by the curve-shortening flow.<ref>{{harvtxt|Cao|2003}}, p.&nbsp;143.</ref>\nEach of the angles in the representation of the total absolute curvature as a sum decreases monotonically, except at the instants when two consecutive inflection points reach the same angle or position as each other and are both eliminated.\nTherefore, the total absolute curvature can never increase as the curve evolves. For convex curves it is constant at 2{{pi}} and for non-convex curves it decreases monotonically.<ref>{{harvtxt|Brakke|1978}}, Appendix B, Proposition 2, p. 230; {{harvtxt|Chou|Zhu|2001}}, Lemma 5.5, p.&nbsp;130; \"6.1 The decrease in total absolute curvature\", pp.&nbsp;144–147.</ref>\n\n===Gage–Hamilton–Grayson theorem===\nIf a smooth simple closed curve undergoes the curve-shortening flow, it remains smoothly embedded without self-intersections. It will eventually become [[convex curve|convex]], and once it does so it will remain convex. After this time, all points of the curve will move inwards, and the shape of the curve will converge to a [[circle]] as the whole curve shrinks to a single point. This behavior is sometimes summarized by saying that every simple closed curve shrinks to a \"round point\".<ref>{{harvtxt|Chou|Zhu|2001}}, p.&nbsp; vii; {{harvtxt|White|2002}}, Theorems 2 and 3, pp.&nbsp;527–528; {{harvtxt|Cao|2003}}, Theorem 3.26, p.&nbsp;47; {{harvtxt|Devadoss|O'Rourke|2011}}, p.&nbsp;141.</ref>\n\nThis result is due to [[Michael Gage]], [[Richard S. Hamilton]], and Matthew Grayson. {{harvs|last=Gage|year=1983|year2=1984|txt}} proved convergence to a circle for convex curves that contract to a point. More specifically Gage showed that the [[isoperimetric ratio]] (the ratio of squared curve length to area, a number that is 4{{pi}} for a circle and larger for any other convex curve) decreases monotonically and quickly. {{harvtxt|Gage|Hamilton|1986}} proved that all smooth convex curves eventually contract to a point without forming any other singularities, and {{harvtxt|Grayson|1987}} proved that every non-convex curve will eventually become convex.<ref>{{harvtxt|Chou|Zhu|2001}}, p.&nbsp; vii; {{harvtxt|Cao|2003}}, p.&nbsp;47; {{harvtxt|Devadoss|O'Rourke|2011}}, p.&nbsp;141.</ref> {{harvtxt|Andrews|Bryan|2011}} provide a simpler proof of Grayson's result, based on the monotonicity of the stretch factor.\n\n[[File:Curve-shortening self-similar lens.svg|thumb|upright=1.4|The limiting shape for all networks of two collinear rays and two curves connecting the endpoints of the two rays. The central [[lens (geometry)|lens]] has the shape of a [[vesica piscis]].]]\nSimilar results can be extended from closed curves to unbounded curves satisfying a local [[Lipschitz continuity|Lipschitz condition]]. For such curves, if both sides of the curve have infinite area, then the evolved curve remains smooth and singularity-free for all time. However, if one side of an unbounded curve has finite area, and the curve has finite total absolute curvature, then its evolution reaches a singularity in time proportional to the area on the finite-area side of the curve, with unbounded curvature near the singularity.{{sfnp|Chou|Zhu|1998}} For curves that are graphs of sufficiently well-behaved functions, asymptotic to a ray in each direction, the solution converges in shape to a unique shape that is asymptotic to the same rays.{{sfnp|Ishimura|1995}}\nFor networks formed by two disjoint rays on the same line, together with two smooth curves connecting the endpoints of the two rays, an analogue of the Gage–Hamilton–Grayson theorem holds, under which the region between the two curves becomes convex and then converges to a [[vesica piscis]] shape.<ref>{{harvtxt|Schnürer|Azouani|Georgi|Hell|2011}}; {{harvtxt|Bellettini|Novaga|2011}}.</ref>\n\n===Singularities of self-crossing curves===\nCurves that have self-crossings may reach singularities before contracting to a point. For instance, if a [[lemniscate]] (any smooth [[Immersion (mathematics)|immersed curve]] with a single crossing, resembling a figure 8 or [[infinity symbol]]) has unequal areas in its two lobes, then eventually the smaller lobe will collapse to a point. However, if the two lobes have equal areas, then they will remain equal throughout the evolution of the curve, and the isoperimetric ratio will diverge as the curve collapses to a singularity.{{sfnp|Grayson|1989a}}\n\nWhen a locally convex self-crossing curve approaches a singularity as one of its loops shrinks, it either shrinks in a self-similar way or asymptotically approaches the grim reaper curve (described below) as it shrinks. When a loop collapses to a singularity, the amount of total absolute curvature that is lost is either at least 2{{pi}} or exactly {{pi}}.{{sfnp|Angenent|1991b}}\n\n===On Riemannian manifolds===\nOn a Riemannian manifold, any smooth simple closed curve will remain smooth and simple as it evolves, just as in the Euclidean case. It will either collapse to a point in a finite amount of time, or remain smooth and simple forever. In the latter case, the curve necessarily converges to a [[closed geodesic]] of the surface.<ref>{{harvtxt|Grayson|1989b}}; {{harvtxt|White|2002}}, p.&nbsp;528; {{harvtxt|Ritoré|Sinestrari|2010}}, Theorem 2.2.1, p.&nbsp;73. This result was already stated as a [[conjecture]] by {{harvtxt|Gage|Hamilton|1986}}.</ref>\n\nImmersed curves on Riemannian manifolds, with finitely many self-crossings, become self-tangent only at a discrete set of times, at each of which they lose a crossing. As a consequence the number of self-crossing points is non-decreasing.{{sfnp|Angenent|1991a}}\n\n[[File:PelotaTenis.jpg|thumb|upright=0.75|A [[tennis ball]]]]\nCurve shortening on a [[sphere]] can be used as part of a proof of the [[tennis ball theorem]]. This theorem states that every smooth simple closed curve on the sphere that divides the sphere's surface into two equal areas (like the seam of a [[tennis ball]]) must have at least four [[inflection point]]s. The proof comes from the observation that curve shortening preserves the smoothness and area-bisection properties of the curve, and does not increase its number of inflection points. Therefore, it allows the problem to be reduced to the problem for curves near the limiting shape of curve shortening, a [[great circle]].{{sfnp|Angenent|1999}}\n\n===Huisken's monotonicity formula===\n{{main article|Huisken's monotonicity formula}}\nAccording to [[Huisken's monotonicity formula]], the convolution of an evolving curve with a time-reversed [[heat kernel]] is non-increasing. This result can be used to analyze the singularities of the evolution.{{sfnp|Huisken|1990}}\n\n==Specific curves==\n\n===Curves with self-similar evolution===\n[[File:Grim reaper curve.svg|thumb|upright=1.2|The grim reaper curve and translated copies of it produced by the curve-shortening flow]]\nBecause every other simple closed curve converges to a circle, the circle is the only simple closed curve that keeps its shape under the curve-shortening flow. However, there are many other examples of curves that are either non-simple (they include self-crossings) or non-closed (they extend to infinity) and keep their shape. In particular,<ref name=\"stable\">{{harvtxt|Mullins|1956}}; {{harvtxt|Abresch|Langer|1986}}; {{harvtxt|Epstein|Weinstein|1987}}; {{harvtxt|Chou|Zhu|2001}}, \"2. Invariant solutions for the curve-shortening flow\", pp. 27–44; {{harvtxt|Halldórsson |2012}}; {{harvtxt|Altschuler|Altschuler|Angenent|Wu|2013}}.</ref>\n* Every [[Line (geometry)|line]] stays unchanged by the curve-shortening flow. Lines are the only curves that are unaffected by the curve-shortening flow,<ref name=\"stable\"/> although there exist more complex stable networks of curves, such as the [[hexagonal tiling]] of the plane.\n* The [[grim reaper curve]] {{math|1=''y'' = − log cos ''x''}} moves upwards without changing its shape. In the same way, any curve [[Similarity (geometry)|similar]] to the grim reaper is [[translation (geometry)|translated]] by the curve-shortening flow, shifted in the direction of the [[Reflection symmetry|symmetry axis]] of the curve without changing its shape or orientation. The grim reaper is the only curve with this property.<ref name=\"stable\"/> It is also called the ''hairpin model'' in the physics literature.<ref name=\"physics curve names\"/>\n* A family of self-crossing closed curves, derived from projections of [[torus knot]]s, shrink [[Homothetic transformation|homothetically]] but remain self-similar under the curve-shortening flow.<ref name=\"stable\"/> These have come to be known as the [[Abresch–Langer curves]], after the work of {{harvtxt|Abresch|Langer|1986}},{{sfnp|Au|2010}} although they were mentioned earlier by {{harvtxt|Mullins|1956}} and rediscovered independently by {{harvtxt|Epstein|Weinstein|1987}}. These curves are locally convex, and therefore can be described by their [[support function]]s. Suitably scaled versions of these support functions obey the [[differential equation]]\n*: <math>h''+h=\\frac{1}{h},</math>\n:which has positive periodic solutions (corresponding to curves with self-similar evolution) for any period that is strictly between {{pi}} and <math>\\pi\\sqrt{2}</math>.{{sfnp|Au|2010}}\n* Other curves, including some infinite [[spiral]]s, remain self-similar with more complicated motions including rotation or combinations of rotation, shrinking or expansion, and translation.<ref name=\"stable\"/>\n* For networks of smooth curves, meeting in threes at junctions with angles of 2{{pi}}/3, the self-similar shrinking solutions include a [[double bubble conjecture|double bubble]] surrounding two equal areas, a [[Lens (geometry)|lens]] shape ([[vesica piscis]]) bounded by two congruent arcs of circles together with two collinear rays having their apexes at the corners of the lens, and a \"fish-shaped\" network bounded by a line segment, two rays, and a convex curve. Any other self-similar shrinking networks involve a larger number of curves.{{sfnp|Schnürer|Azouani|Georgi|Hell|2011}} Another family of networks grows homothetically and remains self-similar; these are tree-like networks of curves, meeting at angles of 2{{pi}}/3 at triple junctions, [[Asymptotic curve|asymptotic]] to a fan of two or more [[Ray (geometry)|rays]] that meet at a common endpoint. The two-ray case of these shapes is an unbounded smooth curve; for three or more rays the evolution of these shapes may be defined using generalized variants of the curve-shortening flow such as the one for varifolds. A given fan of four or more rays may be asymptotic to more than one different solution of this type, so these solutions do not provide a unique definition for the curve-shortening flow starting from a fan of rays.<ref>The two-ray case was already described by {{harvtxt|Mullins|1956}}. For the generalization to two or more rays and issues of non-uniqueness see {{harvtxt|Brakke|1978}}, Appendix C, pp. 235–237 and {{harvtxt|Ilmanen|Neves|Schulze|2014}}.</ref>\n\n===Ancient solutions===\nAn [[ancient solution]] to a flow problem is a curve whose evolution can be extrapolated backwards for all time, without singularities. All of the self-similar solutions that shrink or stay the same size rather than growing are ancient solutions in this sense; they can be extrapolated backwards by reversing the [[self-similarity]] transformation that they would undergo by the forwards curve-shortening flow. Thus, for instance, the circle, grim reaper, and Abresch–Langer curves are all ancient solutions.{{sfnp|Daskalopoulos|Hamilton|Sesum|2010}}\n\nThe only closed curves other than the circle and Abresch–Langer curves that form ancient solutions are a class of curves called the [[Angenent oval]]s after the work of {{harvtxt|Angenent|1992}}.{{sfnp|Daskalopoulos|Hamilton|Sesum|2010}} These curves may be parameterized by specifying their curvature as a function of the tangent angle using the formula\n:<math>k(\\theta,t)=\\sqrt{\\cos 2\\theta-\\operatorname{coth} 2t}</math>\nand have as their limiting shape under reverse evolution a pair of grim reaper curves approaching each other from opposite directions.{{sfnp|Angenent|1992}}\nIn the [[Cartesian coordinate system]], they may be given by the [[implicit curve]] equation{{sfnp|Broadbridge|Vassiliou|2011}}\n:<math>\\cosh y - e^{-t}\\cos x = 0.</math>\nIn the physics literature, the same shapes are known as the ''paperclip model''.<ref name=\"physics curve names\">{{harvtxt|Lukyanov|Vitchev|Zamolodchikov|2004}}; {{harvtxt|Huisken|Sinestrari|2015}}.</ref>\n\nFor more general classes of curves, such as the graphs of functions,\na more diverse collection of ancient solutions is known.{{sfnp|You|2014}}\n\n==Numerical approximations==\nIn order to compute the curve-shortening flow efficiently, both a continuous curve and the continuous evolution of the curve need to be replaced by a discrete approximation.\n\n===Front tracking===\n[[Front tracking]] methods have long been used in [[fluid dynamics]] to model and track the motion of boundaries between different materials, of steep gradients in material properties such as [[weather front]]s, or of shock waves within a single material. These methods involve deriving the equations of motion of the boundary, and using them to directly simulate the motion of the boundary, rather than simulating the underlying fluid and treating the boundary as an emergent property of the fluid.<ref>See, e.g., {{harvtxt|Scriven|1960}}; {{harvtxt|Holden|Risebro|2015}}.</ref> The same methods can also be used to simulate the curve-shortening flow, even when the curve undergoing the flow is not a boundary or shock.\n\nIn front tracking methods for curve shortening, the curve undergoing the evolution is discretized as a polygon. The [[finite difference method]] is used to derive formulas for the approximate normal vector and curvature at each vertex of the polygon, and these values are used to determine how to move each vertex in each time step.<ref>{{harvtxt|Merriman|Bence|Osher|1992}}; {{harvtxt|Mikula|Ševčovič|1999}}; {{harvtxt|Cao|2003}}, \"5.1.1 Finite difference methods\", pp.&nbsp;107–108.</ref> Although the curve-shortening flow is defined by the motion of a curve perpendicularly to itself, some parameterizations of the curve-shortening flow may allow the vertices that approximate the curve to move non-perpendicularly. In effect, this allows the vertices to move along the curve, as the curve evolves. Choosing a careful reparameterization can help redistribute the vertices more evenly along the curve in situations where perpendicular motion would cause them to bunch up.<ref>{{harvtxt|Kimura|1994}}; {{harvtxt|Deckelnick|Dziuk|1995}}; {{harvtxt|Mikula|Ševčovič|2001}}; {{harvtxt|Barrett|Garcke|Nürnberg|2011}}; {{harvtxt|Elliott|Fritz|2017}}.</ref> {{harvtxt|Merriman|Bence|Osher|1992}} write that these methods are fast and accurate but that it is much more complicated to extend them to versions of the curve-shortening flow that apply to more complicated inputs than simple closed curves, where it is necessary to deal with singularities and changes of topology.\n\nFor most such methods, {{harvtxt|Cao|2003}} warns that \"The conditions of stability cannot be determined easily and the time step must be chosen ad hoc.\"<ref>{{harvtxt|Cao|2003}}, \"5.1.1 Finite difference methods\", pp.&nbsp;107–108.</ref> Another finite differencing method by {{harvtxt|Crandall|Lions|1996}} modifies the formula for the curvature at each vertex by adding to it a small term based on the [[Laplace operator]]. This modification is called [[elliptic regularization]], and it can be used to help prove the existence of generalized flows as well as in their numerical simulation.<ref>{{harvtxt|Ilmanen|1994}}, [https://books.google.com/books?id=dInUCQAAQBAJ&pg=PA1 p.&nbsp;1].</ref> Using it, the method of Crandall and Lions can be proven to converge and is the only numerical method listed by Cao that is equipped with bounds on its convergence rate.<ref>{{harvtxt|Crandall|Lions|1996}}; {{harvtxt|Deckelnick|2000}}; {{harvtxt|Cao|2003}}, \"5.2.3 A monotone and convergent finite difference schemes\", p.&nbsp;109.</ref> For an empirical comparison of the [[Euler method|forward Euler]], [[backward Euler method|backward Euler]], and more accurate [[Crank–Nicolson method|Crank–Nicolson]] finite difference methods, see {{harvtxt|Balažovjech|Mikula|2009}}.\n\n===Resampled convolution===\n{{harvtxt|Mokhtarian|Mackworth|1992}} suggest a numerical method for computing an approximation to the curve-shortening flow that maintains a discrete approximation to the curve and alternates between two steps:\n* Resample the current curve by placing new sample points at a uniform spacing, as measured by normalized arc length.\n* [[Convolution|Convolve]] the locations of the points with a [[Gaussian function]] with small standard deviation, in effect replacing each point's location with a [[Weighted arithmetic mean|weighted average]] of the locations of nearby points along the curve, with Gaussian weights. The standard deviation of the Gaussian should be chosen to be small enough that, after this step, the sample points still have nearly-uniform spacing.\nAs they show, this method converges to the curve-shortening distribution in the limit as the number of sample points grows and the normalized arc length of the convolution radius shrinks.<ref>{{harvtxt|Mokhtarian|Mackworth|1992}}, pp.&nbsp;796–797; {{harvtxt|Cao|2003}}, pp.&nbsp;10–11.</ref>\n\n===Median filtering===\n{{harvtxt|Merriman|Bence|Osher|1992}} describe a scheme operating on a two-dimensional square grid – effectively an array of [[pixel]]s.\nThe curve to be evolved is represented by assigning the value 0 (black) to pixels exterior to the curve, and 1 (white) to pixels interior to the curve, giving the [[indicator function]] for the interior of the curve. This representation is updated by alternating two steps:\n* Convolve the pixelated image with a [[heat kernel]] to simulate its evolution under the [[heat equation]] for a short time step. The result is a [[Gaussian blur]] of the image, or equivalently the [[Weierstrass transform]] of the indicator function, with radius proportional to the square root of the time step.\n* Set every pixel with numerical value less than 1/2 to 0, and every pixel with numerical value greater than 1/2 to 1, [[Thresholding (image processing)|thresholding]] the image back to its original values in new positions.\nIn order for this scheme to be accurate, the time step must be large enough to cause the curve to move by at least one pixel even at points of low curvature, but small enough to cause the radius of blurring to be less than the minimum radius of curvature. Therefore, the size of a pixel must be {{math|''O''(min ''κ''/max ''κ''<sup>2</sup>)}}, small enough to allow a suitable intermediate time step to be chosen.\n\nThe method can be generalized to the evolution of networks of curves, meeting at junctions and dividing the plane into more than three regions, by applying the same method simultaneously to each region.{{sfnp|Merriman|Bence|Osher|1992}}\nInstead of blurring and thresholding, this method can alternatively be described as applying a [[median filter]] with [[Gaussian function|Gaussian]] [[Weighted median|weights]] to each pixel. It is possible to use kernels other than the heat kernel, or to adaptively refine the grid so that it has high resolution near the curve but does not waste time and memory on pixels far from the curve that do not contribute to the outcome.<ref>{{harvtxt|Cao|2003}}, \"5.2.4 Bence, Merriman and Osher scheme for mean curvature motion\", pp. 109–110. For the correctness of median filtering with other isotropic kernels, see section 4.4.1, pp. 90–92.</ref> Instead of using only the two values in the pixelated image, a version of this method that uses an image whose pixel values represent the signed distance to the curve can achieve subpixel accuracy and require lower resolution.{{sfnp|Esedoḡlu|Ruuth|Tsai|2010}}\n\n==Applications==\n\n===Annealing metal sheets===\nAn early reference to the curve-shortening flow by {{harvs|first=William W.|last=Mullins|authorlink=William W. Mullins|year=1956|txt}} motivates it as a model for the physical process of [[Annealing (metallurgy)|annealing]], in which heat treatment causes the boundaries between grains of crystallized metal to shift. Unlike [[soap film]]s, which are forced by differences in [[air pressure]] to become surfaces of constant [[mean curvature]], the grain boundaries in annealing are subject only to local effects, which cause them to move according to the mean curvature flow. The one-dimensional case of this flow, the curve-shortening flow, corresponds to annealing sheets of metal that are thin enough for the grains to become effectively two-dimensional and their boundaries to become one-dimensional.<ref>{{harvtxt|Mullins|1956}}; {{harvtxt|Rhines|Craig|DeHoff|1974}}; {{harvtxt|Brakke|1978}}, Appendix A, pp. 224–228.</ref>\n\n===Shape analysis===\nIn [[image processing]] and [[computer vision]], {{harvtxt|Mokhtarian|Mackworth|1992}} suggest applying the curve-shortening flow to the outline of a shape derived from a digital image, in order to remove noise from the shape and provide a [[scale space]] that provides a simplified description of the shape at different levels of resolution.\nThe method of Mokhtarian and Mackworth involves computing the curve-shortening flow, tracking the [[inflection point]]s of the curve as they progress through the flow, and drawing a graph that plots the positions of the inflection points around the curve against the time parameter. The inflection points will typically be removed from the curve in pairs as the curve becomes convex (according to the Gage–Hamilton–Grayson theorem) and the lifetime of a pair of points corresponds to the salience of a feature of the shape.\nBecause of the resampled convolution method that they describe for computing a numerical approximation of the curve-shortening flow, they call their method the ''resampled curvature scale space''. They observe that this scale space is invariant under Euclidean transformations of the given shape, and assert that it uniquely determines the shape and is robust against small variations in the shape. They compare it experimentally against several related alternative definitions of a scale space for shapes, and find that the resampled curvature scale space is less computationally intensive, more robust against nonuniform noise, and less strongly influenced by small-scale shape differences.\n\n===Reaction–diffusion===\nIn [[reaction–diffusion system]]s modeled by the [[Allen–Cahn equation]], the limiting behavior for fast reaction, slow diffusion, and two or more local minima of energy with the same energy level as each other is for the system to settle into regions of different local minima, with the fronts delimiting boundaries between these regions evolving according to the curve-shortening flow.{{sfnp|Rubinstein|Sternberg|Keller|1989}}\n\n===Cellular automata===\n[[File:Anneal CA.png|thumb|upright=1.2|The Anneal cellular automaton, 1600 steps after a random start]]\nIn a [[cellular automaton]], each cell in an infinite grid of cells may have one of a finite set of states, and all cells update their states simultaneously based only on the configuration of a small set of neighboring cells.\nA [[Life-like cellular automaton]] rule is one in which the grid is the infinite square lattice, there are exactly two cell states, the set of neighbors of each cell are the eight neighbors of the [[Moore neighborhood]],\nand the update rule depends only on the number of neighbors with each of the two states rather than on any more complicated function of those states.\nIn one particular life-like rule, introduced by Gerard Vichniac and called the twisted majority rule or annealing rule, the update rule sets the new value for each cell to be the majority among the nine cells given by it and its eight neighbors, except\nwhen these cells are split among four with one state and five with the other state, in which case the new value of the cell is the minority rather than the majority.\nThe detailed dynamics of this rule are complicated, including the existence of small stable structures.{{sfnp|Pickover|1993}} However, in the aggregate (when started with all cells in random states) it tends to form large regions of cells that are all in the same state as each other, with the boundaries between these regions evolving according to the curve-shortening flow.<ref>{{harvtxt|Vichniac|1986}}; {{harvtxt|Chopard|Droz|1998}}.</ref>\n\n===Construction of closed geodesics===\nThe curve-shortening flow can be used to prove an [[isoperimetric inequality]] for surfaces whose [[Gaussian curvature]] is a non-increasing function of the distance from the [[Origin (mathematics)|origin]], such as the [[paraboloid]]. On such a surface, the smooth compact set that has any given area and minimum perimeter for that area is necessarily a circle centered at the origin. The proof applies the curve-shortening flow to two curves, a metric circle and the boundary of any other compact set, and compares the change in perimeter of the two curves as they are both reduced to a point by the flow.<ref>{{harvtxt|Benjamini|Cao|1996}}; {{harvtxt|Ritoré|Sinestrari|2010}}, Theorem 2.3.1, p.&nbsp;75.</ref>\nThe curve-shortening flow can also be used to prove the [[theorem of the three geodesics]], that every smooth Riemannian manifold topologically equivalent to a sphere has three geodesics that form [[simple closed curve]]s.{{sfnp|Grayson|1989b}}\n\n==Related flows==\nOther [[geometric flow]]s related to the curve-shortening flow include the following ones.\n* For simulating the behavior of [[crystal]]s or other [[Anisotropy|anisotropic]] materials, it is important to have variants of the curve-shortening flow for which the speed of flow depends on the orientation of a curve as well as on its curvature. One way of doing this is to define the energy of a curve to be the integral of a [[smooth function]] {{mvar|γ}} of its normal vectors, and form the gradient flow of this energy, according to which the normal speed at which the curve flows is proportional to an anisotropic analog of the curvature. This flow can be simulated by discretizing the curve as a polygon. In numerical experiments, initial curves appear to converge to the [[Wulff construction|Wulff shape]] for {{mvar|γ}} before shrinking to a point.<ref>{{harvtxt|Dziuk|1999}}; {{harvtxt|Haußer|Voigt|2006}}.</ref> Alternatively, one can let the curve flow with speed {{math|''a''(''θ'')''κ'' + ''b''(''θ'')}} where {{mvar|κ}} is the (usual) curvature and {{mvar|a}} and {{mvar|b}} are smooth functions of the orientation {{mvar|θ}}. When {{math|1=''a''(''θ'' + {{pi}}) = ''a''(''θ'')}} and {{math|1=''b''(''θ'' + {{pi}}) = −''b''(''θ'')}} (so that the flow is invariant under [[point reflection]]), the resulting flow can be shown to obey the avoidance principle and an analog of the Gage–Hamilton–Grayson theorem.<ref>{{harvtxt|Chou|Zhu|2001}}, Chapter 6: A Class of Non-convex Anisotropic Flows, pp. 143–177.</ref>\n* The [[affine curve-shortening flow]] was first investigated by {{harvtxt|Alvarez|Guichard|Lions|Morel|1993}} and {{harvtxt|Sapiro|Tannenbaum|1993}}. In this flow, the normal speed of the curve is proportional to the cube root of the curvature.<ref>{{harvtxt|Cao|2003}}, \"3.2.3 The affine invariant flow: the simplest affine invariant curve flow\", pp. 42–46.</ref> The resulting flow is invariant (with a corresponding time scaling) under the [[affine transformation]]s of the Euclidean plane, a larger [[symmetry group]] than the [[Similarity (geometry)|similarity transformations]] under which the curve-shortening flow is invariant. Under this flow, an analogue of the Gage–Hamilton–Grayson theorem applies, under which any simple closed curve eventually becomes convex and then converges to an [[ellipse]] as it collapses to a point.<ref>{{harvtxt|Angenent|Sapiro|Tannenbaum|1998}}; {{harvtxt|Cao|2003}}, Theorem 3.28, p.&nbsp;47.</ref>\n* Transforming a curve with equal normal speeds at all points has been called the [[grassfire transform]]. Curves evolved in this way will in general develop sharp corners, the trace of which forms the [[medial axis]] of the curve.{{sfnp||Sapiro|Tannenbaum|1993}} A closely related curve evolution which moves straight segments of a polygonal curve at equal speeds but allows concave corners to move more quickly than unit speed instead forms a different type of [[topological skeleton]] of the given curve, its [[straight skeleton]].{{sfnp|Aichholzer|Aurenhammer|Alberts|Gärtner|1995}}\n* For surfaces in higher dimensions, there is more than one definition of curvature, including extrinsic (embedding-dependent) measures such as the [[mean curvature]] and intrinsic measures such as the [[Gaussian curvature]] and [[Ricci curvature]]. Correspondingly, there are several ways of defining geometric flows based on curvature, including the [[mean curvature flow]] (in which the normal speed of an embedded surface is its mean curvature), the [[Ricci flow]] (an intrinsic flow on the metric of a space based on its Ricci curvature) and the [[Willmore flow]] (the gradient flow for an energy functional combining the mean curvature and Gaussian curvature). The curve-shortening flow is a special case of the mean curvature flow for one-dimensional curves.{{sfnp|White|1989}}\n* Inspired by the curve-shortening flow on smooth curves, researchers have studied methods for flowing [[polygon]]s so that they stay polygonal, with applications including pattern formation and synchronization in distributed systems of robots.{{sfnp|Smith|Broucke|Francis|2007}} Length-preserving polygonal flows can be used to solve the [[carpenter's rule problem]].{{sfnp|Cantarella|Demaine|Iben|O'Brien|2004}}\n* In [[computer vision]], the [[active contour model]] for [[edge detection]] and [[image segmentation]] is based on curve shortening, and evolves curves based on a combination of their curvature and the features of an image.{{sfnp|Kichenassamy|Kumar|Olver|Tannenbaum|1995}}\n\n==Notes==\n{{reflist|30em}}\n\n==References==\n{{refbegin|30em}}\n* {{citation\n | last1 = Abresch | first1 = U.\n | last2 = Langer | first2 = J.\n | issue = 2\n | journal = [[Journal of Differential Geometry]]\n | mr = 845704\n | pages = 175–196\n | title = The normalized curve shortening flow and homothetic solutions\n | url = http://projecteuclid.org/euclid.jdg/1214440025\n | volume = 23\n | year = 1986\n | doi=10.4310/jdg/1214440025}}.\n* {{citation\n | last1 = Aichholzer | first1 = Oswin\n | last2 = Aurenhammer | first2 = Franz | author2-link = Franz Aurenhammer\n | last3 = Alberts | first3 = David\n | last4 = Gärtner | first4 = Bernd\n | doi = 10.1007/978-3-642-80350-5_65\n | issue = 12\n | journal = Journal of Universal Computer Science\n | mr = 1392429\n | pages = 752–761\n | title = A novel type of skeleton for polygons\n | url = http://www.jucs.org/jucs_1_12/a_novel_type_of\n | volume = 1\n | year = 1995}}.\n* {{citation\n | last = Altschuler | first = Steven J.\n | issue = 2\n | journal = [[Journal of Differential Geometry]]\n | mr = 1131441\n | pages = 491–514\n | title = Singularities of the curve shrinking flow for space curves\n | url = http://projecteuclid.org/euclid.jdg/1214447218\n | volume = 34\n | year = 1991\n | doi=10.4310/jdg/1214447218}}.\n* {{citation\n | last1 = Altschuler | first1 = Dylan J.\n | last2 = Altschuler | first2 = Steven J.\n | last3 = Angenent | first3 = Sigurd B. | author3-link = Sigurd Angenent\n | last4 = Wu | first4 = Lani F.\n | arxiv = 1207.4051\n | doi = 10.1088/0951-7715/26/5/1189\n | issue = 5\n | journal = [[Nonlinearity (journal)|Nonlinearity]]\n | mr = 3043378\n | pages = 1189–1226\n | title = The zoo of solitons for curve shortening in <math>\\mathbb{R}^n</math>\n | volume = 26\n | year = 2013| bibcode = 2013Nonli..26.1189A}}.\n* {{citation\n | last1 = Altschuler | first1 = Steven J.\n | last2 = Grayson | first2 = Matthew A.\n | issue = 2\n | journal = [[Journal of Differential Geometry]]\n | mr = 1158337\n | pages = 283–298\n | title = Shortening space curves and flow through singularities\n | url = http://projecteuclid.org/euclid.jdg/1214448076\n | volume = 35\n | year = 1992\n | doi=10.4310/jdg/1214448076}}.\n* {{citation\n | last1 = Alvarez | first1 = Luis\n | last2 = Guichard | first2 = Frédéric\n | last3 = Lions | first3 = Pierre-Louis\n | last4 = Morel | first4 = Jean-Michel\n | doi = 10.1007/BF00375127\n | issue = 3\n | journal = [[Archive for Rational Mechanics and Analysis]]\n | mr = 1225209\n | pages = 199–257\n | title = Axioms and fundamental equations of image processing\n | volume = 123\n | year = 1993 | bibcode=1993ArRMA.123..199A}}.\n* {{citation\n | last1 = Andrews | first1 = Ben\n | last2 = Bryan | first2 = Paul\n | arxiv = 0908.2682\n | doi = 10.1515/CRELLE.2011.026\n | journal = [[Crelle's Journal|Journal für die Reine und Angewandte Mathematik]]\n | mr = 2794630\n | pages = 179–187\n | title = Curvature bound for curve shortening flow via distance comparison and a direct proof of Grayson's theorem\n | volume = 653\n | year = 2011}}.\n* {{citation\n | last = Angenent | first = Sigurd | authorlink = Sigurd Angenent\n | doi = 10.2307/2944327\n | issue = 1\n | journal = [[Annals of Mathematics]]\n | mr = 1087347\n | pages = 171–215\n | series = Second Series\n | title = Parabolic equations for curves on surfaces. II. Intersections, blow-up and generalized solutions\n | volume = 133\n | year = 1991a}}.\n* {{citation\n | last = Angenent | first = Sigurd | authorlink = Sigurd Angenent\n | issue = 3\n | journal = [[Journal of Differential Geometry]]\n | mr = 1100205\n | pages = 601–633\n | title = On the formation of singularities in the curve shortening flow\n | url = http://projecteuclid.org/euclid.jdg/1214446558\n | volume = 33\n | year = 1991b\n | doi=10.4310/jdg/1214446558}}.\n* {{citation\n | last = Angenent | first = Sigurd B. | authorlink = Sigurd Angenent\n | contribution = Shrinking doughnuts\n | contribution-url = http://www.math.wisc.edu/~angenent/preprints/1989Gregynog/Gregynog.pdf\n | mr = 1167827\n | pages = 21–38\n | publisher = Birkhäuser | location = Boston, MA\n | series = Progress in Nonlinear Differential Equations and their Applications\n | title = Nonlinear diffusion equations and their equilibrium states, 3 (Gregynog, 1989)\n | volume = 7\n | year = 1992}}.\n*{{citation\n | last = Angenent | first = S. | authorlink = Sigurd Angenent\n | contribution = Inflection points, extatic points and curve shortening\n | contribution-url = https://www.math.wisc.edu/~angenent/preprints/proceedings/S'AGARRO%20'95/extatic.pdf\n | mr = 1720878\n | pages = 3–10\n | publisher = Kluwer Acad. Publ. | location = Dordrecht\n | series = NATO Adv. Sci. Inst. Ser. C Math. Phys. Sci.\n | title = Hamiltonian systems with three or more degrees of freedom (S'Agaró, 1995)\n | volume = 533\n | year = 1999}}\n* {{citation\n | last1 = Angenent | first1 = Sigurd | authorlink = Sigurd Angenent\n | last2 = Sapiro | first2 = Guillermo | author2-link = Guillermo Sapiro\n | last3 = Tannenbaum | first3 = Allen | author3-link = Allen Tannenbaum\n | doi = 10.1090/S0894-0347-98-00262-8\n | issue = 3\n | journal = [[Journal of the American Mathematical Society]]\n | mr = 1491538\n | pages = 601–634\n | title = On the affine heat equation for non-convex curves\n | volume = 11\n | year = 1998}}.\n* {{citation\n | last = Au | first = Thomas Kwok-Keung\n | arxiv = math/0102088\n | doi = 10.4310/CAG.2010.v18.n1.a1\n | issue = 1\n | journal = Communications in Analysis and Geometry\n | mr = 2660456\n | pages = 1–21\n | title = On the saddle point property of Abresch-Langer curves under the curve shortening flow\n | volume = 18\n | year = 2010}}.\n* {{citation\n | last1 = Balažovjech | first1 = Martin\n | last2 = Mikula | first2 = Karol\n | contribution = A higher order scheme for the curve shortening flow of plane curves\n | contribution-url = https://www.math.sk/mikula/balazovjech_mikula_alg2009.pdf\n | pages = 165–175\n | title = Algoritmy 2009\n | year = 2009}}.\n* {{citation\n | last1 = Barrett | first1 = John W.\n | last2 = Garcke | first2 = Harald\n | last3 = Nürnberg | first3 = Robert\n | doi = 10.1002/num.20637\n | journal = Numerical Methods for Partial Differential Equations\n | mr = 2743598\n | page = 1–30\n | title = The approximation of planar curve evolutions by stable fully implicit finite element schemes that equidistribute\n | volume = 27\n | year = 2011}}.\n* {{citation\n | last1 = Bellettini | first1 = Giovanni\n | last2 = Novaga | first2 = Matteo\n | doi = 10.1515/CRELLE.2011.041\n | journal = [[Crelle's Journal|Journal für die Reine und Angewandte Mathematik]]\n | mr = 2818854\n | pages = 17–46\n | title = Curvature evolution of nonconvex lens-shaped domains\n | volume = 656\n | year = 2011| arxiv = 0906.0166}}.\n* {{citation\n | last1 = Benjamini | first1 = Itai | author1-link = Itai Benjamini\n | last2 = Cao | first2 = Jianguo\n | doi = 10.1215/S0012-7094-96-08515-4\n | issue = 2\n | journal = [[Duke Mathematical Journal]]\n | mr = 1417620\n | pages = 359–396\n | title = A new isoperimetric comparison theorem for surfaces of variable curvature\n | volume = 85\n | year = 1996}}.\n* {{citation\n | last = Brakke | first = Kenneth A.\n | isbn = 0-691-08204-9\n | mr = 485012\n | publisher = Princeton University Press, Princeton, N.J.\n | series = Mathematical Notes\n | title = The motion of a surface by its mean curvature\n | url = http://facstaff.susqu.edu/brakke/aux/downloads/papers/motionbook.pdf\n | volume = 20\n | year = 1978}}.\n* {{citation\n | last1 = Broadbridge | first1 = Philip\n | last2 = Vassiliou | first2 = Peter\n | arxiv = 1106.0092\n | doi = 10.3842/SIGMA.2011.052\n | journal = SIGMA\n | mr = 2804584\n | page = Paper 052, 19\n | title = The role of symmetry and separation in surface evolution and curve shortening\n | volume = 7\n | year = 2011| bibcode = 2011SIGMA...7..052B\n }}.\n* {{citation\n | last1 = Brook | first1 = Alexander\n | last2 = Bruckstein | first2 = Alfred M.\n | last3 = Kimmel | first3 = Ron | author3-link = Ron Kimmel\n | editor1-last = Kimmel | editor1-first = Ron | editor1-link = Ron Kimmel\n | editor2-last = Sochen | editor2-first = Nir A.\n | editor3-last = Weickert | editor3-first = Joachim\n | contribution = On similarity-invariant fairness measures\n | doi = 10.1007/11408031_39\n | pages = 456–467\n | publisher = Springer-Verlag\n | series = Lecture Notes in Computer Science\n | title = Scale Space and PDE Methods in Computer Vision: 5th International Conference, Scale-Space 2005, Hofgeismar, Germany, April 7–9, 2005, Proceedings\n | volume = 3459\n | year = 2005}}.\n* {{citation\n | last1 = Bryant | first1 = Robert L. | author1-link = Robert Bryant (mathematician)\n | last2 = Griffiths | first2 = Phillip A. | author2-link = Phillip Griffiths\n | doi = 10.1215/S0012-7094-95-07824-7\n | issue = 3\n | journal = [[Duke Mathematical Journal]]\n | mr = 1334205\n | pages = 531–676\n | title = Characteristic cohomology of differential systems. II. Conservation laws for a class of parabolic equations\n | volume = 78\n | year = 1995}}. See in particular Example 1, pp.&nbsp;542–544 and 601–604.\n* {{citation\n | last1 = Cantarella | first1 = Jason H.\n | last2 = Demaine | first2 = Erik D. | author2-link = Erik Demaine\n | last3 = Iben | first3 = Hayley N.\n | last4 = O'Brien | first4 = James F.\n | contribution = An energy-driven approach to linkage unfolding\n | doi = 10.1145/997817.997840\n | isbn = 1-58113-885-7\n | location = New York, NY, USA\n | pages = 134–143\n | publisher = ACM\n | title = [[Symposium on Computational Geometry|Proceedings of the Twentieth Annual Symposium on Computational Geometry (SCG '04)]]\n | year = 2004}}.\n* {{citation\n | last = Cao | first = Frédéric\n | doi = 10.1007/b10404\n | isbn = 3-540-00402-5\n | location = Berlin\n | mr = 1976551\n | publisher = Springer-Verlag\n | series = Lecture Notes in Mathematics\n | title = Geometric Curve Evolution and Image Processing\n | volume = 1805\n | year = 2003}}.\n* {{citation\n | last1 = Chopard | first1 = Bastien\n | last2 = Droz | first2 = Michel\n | contribution = 2.2.4 The annealing rule\n | doi = 10.1017/CBO9780511549755\n | isbn = 0-521-46168-5\n | mr = 1669736\n | pages = 37–38\n | publisher = Cambridge University Press, Cambridge\n | series = Collection Aléa-Saclay: Monographs and Texts in Statistical Physics\n | title = Cellular automata modeling of physical systems\n | year = 1998}}.\n* {{citation\n | last1 = Chou | first1 = Kai-Seng\n | last2 = Zhu | first2 = Xi-Ping\n | issue = 3\n | journal = [[Journal of Differential Geometry]]\n | mr = 1690737\n | pages = 471–504\n | title = Shortening complete plane curves\n | url = http://projecteuclid.org/euclid.jdg/1214424967\n | volume = 50\n | year = 1998\n | doi=10.4310/jdg/1214424967}}.\n* {{citation\n | last1 = Chou | first1 = Kai-Seng\n | last2 = Zhu | first2 = Xi-Ping\n | doi = 10.1201/9781420035704\n | isbn = 1-58488-213-1\n | location = Boca Raton, FL\n | mr = 1888641\n | publisher = Chapman & Hall/CRC\n | title = The Curve Shortening Problem\n | year = 2001}}.\n* {{citation\n | last1 = Crandall | first1 = Michael G.\n | last2 = Lions | first2 = Pierre-Louis\n | doi = 10.1007/s002110050228\n | issue = 1\n | journal = [[Numerische Mathematik]]\n | mr = 1417861\n | pages = 17–41\n | title = Convergent difference schemes for nonlinear parabolic equations and mean curvature motion\n | volume = 75\n | year = 1996}}.\n* {{citation\n | last1 = Daskalopoulos | first1 = Panagiota | author1-link = Panagiota Daskalopoulos\n | last2 = Hamilton | first2 = Richard | author2-link = Richard S. Hamilton\n | last3 = Sesum | first3 = Natasa | author3-link = Nataša Šešum\n | arxiv = 0806.1757\n | issue = 3\n | journal = [[Journal of Differential Geometry]]\n | mr = 2669361\n | pages = 455–464\n | title = Classification of compact ancient solutions to the curve shortening flow\n | url = http://projecteuclid.org/euclid.jdg/1279114297\n | volume = 84\n | year = 2010 | doi=10.4310/jdg/1279114297}}.\n* {{citation\n | last = Deckelnick | first = Klaus\n | doi = 10.4171/IFB/15\n | issue = 2\n | journal = Interfaces and Free Boundaries\n | mr = 1760409\n | pages = 117–142\n | title = Error bounds for a difference scheme approximating viscosity solutions of mean curvature flow\n | volume = 2\n | year = 2000}}.\n*{{citation\n | last1 = Deckelnick | first1 = K.\n | last2 = Dziuk | first2 = G.\n | contribution = On the approximation of the curve shortening flow\n | mr = 1419337\n | pages = 100–108\n | publisher = Longman Sci. Tech., Harlow\n | series = Pitman Res. Notes Math. Ser.\n | title = Calculus of variations, applications and computations (Pont-à-Mousson, 1994)\n | volume = 326\n | year = 1995}}.\n* {{citation\n | last1 = Devadoss | first1 = Satyan L. | author1-link = Satyan Devadoss\n | last2 = O'Rourke | first2 = Joseph | author2-link = Joseph O'Rourke (professor)\n | chapter = 5.5 Curve Shortening\n | isbn = 978-0-691-14553-2\n | mr = 2790764\n | pages = 138–144\n | publisher = Princeton University Press | location = Princeton, NJ\n | title = Discrete and Computational Geometry\n | year = 2011}}.\n* {{citation\n | last = Dziuk | first = Gerhard\n | doi = 10.1137/S0036142998337533\n | issue = 6\n | journal = [[SIAM Journal on Numerical Analysis]]\n | mr = 1712165\n | pages = 1808–1830\n | title = Discrete anisotropic curve shortening flow\n | volume = 36\n | year = 1999}}.\n* {{citation\n | last1 = Elliott | first1 = Charles M.\n | last2 = Fritz | first2 = Hans\n | arxiv = 1602.07143\n | doi = 10.1093/imanum/drw020\n | issue = 2\n | journal = IMA Journal of Numerical Analysis\n | mr = 3649420\n | pages = 543–603\n | title = On approximations of the curve shortening flow and of the mean curvature flow based on the DeTurck trick\n | volume = 37\n | year = 2017}}.\n* {{citation\n | last1 = Epstein | first1 = C. L. | author1-link = Charles Epstein\n | last2 = Weinstein | first2 = M. I.\n | doi = 10.1002/cpa.3160400106\n | issue = 1\n | journal = [[Communications on Pure and Applied Mathematics]]\n | mr = 865360\n | pages = 119–139\n | title = A stable manifold theorem for the curve shortening equation\n | volume = 40\n | year = 1987}}.\n* {{citation\n | last1 = Esedoḡlu | first1 = Selim\n | last2 = Ruuth | first2 = Steven\n | last3 = Tsai | first3 = Richard\n | doi = 10.1016/j.jcp.2009.10.002\n | issue = 4\n | journal = [[Journal of Computational Physics]]\n | mr = 2576237\n | pages = 1017–1042\n | title = Diffusion generated motion using signed distance functions\n | url = http://www.math.sfu.ca/~sruuth/ert.pdf\n | volume = 229\n | year = 2010| bibcode = 2010JCoPh.229.1017E}}.\n* {{citation\n | last = Gage | first = Michael E. | authorlink = Michael Gage\n | doi = 10.1215/S0012-7094-83-05052-4\n | issue = 4\n | journal = [[Duke Mathematical Journal]]\n | mr = 726325\n | pages = 1225–1229\n | title = An isoperimetric inequality with applications to curve shortening\n | volume = 50\n | year = 1983}}.\n* {{citation\n | last = Gage | first = M. E. | authorlink = Michael Gage\n | doi = 10.1007/BF01388602\n | issue = 2\n | journal = [[Inventiones Mathematicae]]\n | mr = 742856\n | pages = 357–364\n | title = Curve shortening makes convex curves circular\n | volume = 76\n | year = 1984| bibcode = 1984InMat..76..357G}}.\n* {{citation\n | last1 = Gage | first1 = M. | author1-link = Michael Gage\n | last2 = Hamilton | first2 = R. S. | author2-link = Richard S. Hamilton\n | issue = 1\n | journal = [[Journal of Differential Geometry]]\n | mr = 840401\n | pages = 69–96\n | title = The heat equation shrinking convex plane curves\n | url = http://projecteuclid.org/euclid.jdg/1214439902\n | volume = 23\n | year = 1986 | doi=10.4310/jdg/1214439902}}.\n* {{citation\n | last = Grayson | first = Matthew A.\n | issue = 2\n | journal = [[Journal of Differential Geometry]]\n | mr = 906392\n | pages = 285–314\n | title = The heat equation shrinks embedded plane curves to round points\n | url = http://projecteuclid.org/euclid.jdg/1214441371\n | volume = 26\n | year = 1987\n | doi=10.4310/jdg/1214441371}}.\n* {{citation\n | last = Grayson | first = Matthew A.\n | doi = 10.1007/BF01393973\n | issue = 1\n | journal = [[Inventiones Mathematicae]]\n | mr = 981740\n | pages = 177–180\n | title = The shape of a figure-eight under the curve shortening flow\n | url = https://eudml.org/doc/143675\n | volume = 96\n | year = 1989a| bibcode = 1989InMat..96..177G\n }}.\n* {{citation\n | last = Grayson | first = Matthew A.\n | doi = 10.2307/1971486\n | issue = 1\n | journal = [[Annals of Mathematics]]\n | mr = 979601\n | pages = 71–111\n | series = Second Series\n | title = Shortening embedded curves\n | url = http://wwwmath.uni-muenster.de/u/janmark/Grayson_CurveInSurface.pdf\n | volume = 129\n | year = 1989b}}.\n* {{citation\n | last = Halldórsson | first = Höskuldur P.\n | arxiv = 1007.1617\n | doi = 10.1090/S0002-9947-2012-05632-7\n | issue = 10\n | journal = [[Transactions of the American Mathematical Society]]\n | mr = 2931330\n | pages = 5285–5309\n | title = Self-similar solutions to the curve shortening flow\n | volume = 364\n | year = 2012}}.\n* {{citation\n | last1 = Haußer | first1 = Frank\n | last2 = Voigt | first2 = Axel\n | doi = 10.1016/j.aml.2005.05.011\n | issue = 8\n | journal = Applied Mathematics Letters\n | mr = 2232241\n | pages = 691–698\n | title = A numerical scheme for regularized anisotropic curve shortening flow\n | volume = 19\n | year = 2006}}.\n* {{citation\n | last1 = Holden | first1 = Helge\n | last2 = Risebro | first2 = Nils Henrik\n | edition = 2nd\n | isbn = 978-3-662-47507-2\n | publisher = Springer\n | series = Applied Mathematical Sciences\n | title = Front Tracking for Hyperbolic Conservation Laws\n | volume = 152\n | year = 2015}}.\n* {{citation\n | last = Huisken | first = Gerhard | authorlink = Gerhard Huisken\n | issue = 1\n | journal = [[Journal of Differential Geometry]]\n | mr = 1030675\n | pages = 285–299\n | title = Asymptotic behavior for singularities of the mean curvature flow\n | url = http://projecteuclid.org/euclid.jdg/1214444099\n | volume = 31\n | year = 1990\n | doi=10.4310/jdg/1214444099}}.\n* {{citation\n | last = Huisken | first = Gerhard | authorlink = Gerhard Huisken\n | issue = 1\n | journal = The Asian Journal of Mathematics\n | mr = 1656553\n | pages = 127–133\n | title = A distance comparison principle for evolving curves\n | volume = 2\n | year = 1998\n | doi=10.4310/ajm.1998.v2.n1.a2}}.\n* {{citation\n | last1 = Huisken | first1 = Gerhard | author1-link = Gerhard Huisken\n | last2 = Sinestrari | first2 = Carlo\n | arxiv = 1405.7509\n | issue = 2\n | journal = [[Journal of Differential Geometry]]\n | mr = 3399098\n | pages = 267–287\n | title = Convex ancient solutions of the mean curvature flow\n | url = http://projecteuclid.org/euclid.jdg/1442364652\n | volume = 101\n | year = 2015 | doi=10.4310/jdg/1442364652}}.\n* {{citation\n | last = Ilmanen | first = Tom\n | doi = 10.1090/memo/0520\n | issue = 520\n | journal = Memoirs of the American Mathematical Society\n | mr = 1196160\n | title = Elliptic regularization and partial regularity for motion by mean curvature\n | volume = 108\n | year = 1994}}.\n* {{citation\n | last1 = Ilmanen | first1 = Tom\n | last2 = Neves | first2 = André | author2-link = André Neves\n | last3 = Schulze | first3 = Felix\n | arxiv = 1407.4756\n | title = On short time existence for the planar network flow\n | year = 2014| bibcode = 2014arXiv1407.4756I}}.\n* {{citation\n | last = Ishimura | first = Naoyuki\n | doi = 10.1017/S0004972700014714\n | issue = 2\n | journal = Bulletin of the Australian Mathematical Society\n | mr = 1348488\n | pages = 287–296\n | title = Curvature evolution of plane curves with prescribed opening angle\n | volume = 52\n | year = 1995}}.\n* {{citation\n | last1 = Kichenassamy | first1 = S.\n | last2 = Kumar | first2 = A.\n | last3 = Olver | first3 = P. | author3-link=Peter J. Olver\n | last4 = Tannenbaum | first4 = A. | author4-link = Allen Tannenbaum\n | last5 = Yezzi | first5 = A.\n | contribution = Gradient flows and geometric active contour models\n | doi = 10.1109/iccv.1995.466855\n | pages = 810–815\n | title = Proceedings of IEEE International Conference on Computer Vision\n | year = 1995}}.\n* {{citation\n | last = Kimmel | first = Ron | author-link = Ron Kimmel\n | isbn = 978-0-387-21637-9\n | mr = 2028182\n | publisher = Springer-Verlag\n | title = Numerical Geometry of Images: Theory, Algorithms, and Applications\n | year = 2004}}.\n* {{citation\n | last = Kimura | first = M.\n | doi = 10.1016/0893-9659(94)90056-6\n | issue = 1\n | journal = Applied Mathematics Letters\n | mr = 1349897\n | pages = 69–73\n | title = Accurate numerical scheme for the flow by curvature\n | volume = 7\n | year = 1994}}.\n* {{citation\n | last1 = Lam | first1 = Casey\n | last2 = Lauer | first2 = Joseph\n | arxiv = 1601.02442\n | title = The level-set flow of the topologist's sine curve is smooth\n | year = 2016| bibcode = 2016arXiv160102442L}}\n* {{citation\n | last = Lauer | first = Joseph\n | arxiv = 1102.5110\n | doi = 10.1007/s00039-013-0248-1\n | issue = 6\n | journal = [[Geometric and Functional Analysis (journal)|Geometric and Functional Analysis]]\n | mr = 3132906\n | pages = 1934–1961\n | title = A new length estimate for curve shortening flow and low regularity initial data\n | volume = 23\n | year = 2013}}.\n* {{citation\n | last1 = Lukyanov | first1 = S.L\n | last2 = Vitchev | first2 = E.S\n | last3 = Zamolodchikov | first3 = A.B\n | arxiv = hep-th/0312168\n | doi = 10.1016/j.nuclphysb.2004.02.010\n | issue = 3\n | journal = Nuclear Physics B\n | pages = 423–454\n | title = Integrable model of boundary interaction: the paperclip\n | volume = 683\n | year = 2004| bibcode = 2004NuPhB.683..423L}}.\n* {{citation\n | last1 = Merriman | first1 = Barry\n | last2 = Bence | first2 = James\n | last3 = Osher | first3 = Stanley | author3-link = Stanley Osher\n | date = April 1992\n | publisher = Department of Mathematics, University of California, Los Angeles\n | series = CAM Report 92-18\n | title = Diffusion generated motion by mean curvature\n | url = ftp://ftp.math.ucla.edu/pub/camreport/cam92-18.pdf}}. Also published in {{citation\n | last = Taylor | first = Jean E.\n | isbn = 0-8218-8072-1\n | location = Providence, RI\n | mr = 1224451\n | pages = 73–83\n | publisher = American Mathematical Society\n | series = Selected Lectures in Mathematics\n | title = Computational Crystal Growers Workshop: Proceedings of the Geometry Center Workshop held in Minneapolis, Minnesota, February 22–28, 1992\n | year = 1992}}.\n* {{citation\n | last1 = Mikula | first1 = Karol\n | last2 = Ševčovič | first2 = Daniel\n | doi = 10.1016/S0168-9274(98)00130-5\n | issue = 2\n | journal = Applied Numerical Mathematics\n | mr = 1708959\n | pages = 191–207\n | title = Solution of nonlinearly curvature driven evolution of plane curves\n | volume = 31\n | year = 1999}}.\n* {{citation\n | last1 = Mikula | first1 = Karol\n | last2 = Ševčovič | first2 = Daniel\n | doi = 10.1137/S0036139999359288\n | issue = 5\n | journal = SIAM Journal on Applied Mathematics\n | mr = 1824511\n | pages = 1473–1501 (electronic)\n | title = Evolution of plane curves driven by a nonlinear function of curvature and anisotropy\n | volume = 61\n | year = 2001}}.\n* {{citation\n | last1 = Mokhtarian | first1 = F.\n | last2 = Mackworth | first2 = A. K. | author2-link = Alan Mackworth\n | doi = 10.1109/34.149591\n | issue = 8\n | journal = [[IEEE Transactions on Pattern Analysis and Machine Intelligence]]\n | pages = 789–805\n | title = A theory of multiscale, curvature-based shape representation for planar curves\n | url = http://www.cs.ubc.ca/~mack/Publications/IEEE-PAMI92.pdf\n | volume = 14\n | year = 1992}}.\n* {{citation\n | last = Mullins | first = W. W. | authorlink = William W. Mullins\n | doi = 10.1063/1.1722511\n | issue = 8\n | journal = [[Journal of Applied Physics]]\n | pages = 900–904\n | title = Two-dimensional motion of idealized grain boundaries\n | volume = 27\n | year = 1956| bibcode = 1956JAP....27..900M}}. Reprinted in {{citation\n | editor1-last = Ball | editor1-first = John M. | editor1-link = John M. Ball\n | editor2-last = Kinderlehrer | editor2-first = David | editor2-link = David Kinderlehrer\n | editor3-last = Podio-Guidugli | editor3-first = Paulo\n | editor4-last = Slemrod | editor4-first = Marshall\n\n | doi = 10.1007/978-3-642-59938-5_3\n | isbn = 978-3-642-59938-5\n | pages = 70–74\n | publisher = Springer-Verlag\n | title = Fundamental Contributions to the Continuum Theory of Evolving Phase Interfaces in Solids: A Collection of Reprints of 14 Seminal Papers\n | year = 1999}}.\n* {{citation\n | last = Pickover | first = Clifford A. | authorlink = Clifford A. Pickover\n | doi = 10.1007/bf01900906\n | issue = 3\n | journal = The Visual Computer\n | pages = 173–177\n | title = Lava lamps in the 21st century\n | volume = 10\n | year = 1993}}.\n* {{citation\n | last1 = Rhines | first1 = Frederick N.\n | last2 = Craig | first2 = Kenneth R.\n | last3 = DeHoff | first3 = Robert T.\n | doi = 10.1007/bf02644109\n | issue = 2\n | journal = Metallurgical Transactions\n | pages = 413–425\n | title = Mechanism of steady-state grain growth in aluminum\n | volume = 5\n | year = 1974| bibcode = 1974MT......5..413R}}.\n* {{citation\n | last1 = Ritoré | first1 = Manuel\n | last2 = Sinestrari | first2 = Carlo\n | contribution = 2.2 Curve shortening flow\n | contribution-url = https://books.google.com/books?id=0IPBBAAAQBAJ&pg=PA72\n | doi = 10.1007/978-3-0346-0213-6_13\n | isbn = 978-3-0346-0213-6\n | pages = 72–75\n | publisher = Birkhäuser\n | series = Advanced Courses in Mathematics – CRM Barcelona\n | title = Mean Curvature Flow and Isoperimetric Inequalities\n | year = 2010}}.\n* {{citation\n | last1 = Rubinstein | first1 = Jacob\n | last2 = Sternberg | first2 = Peter\n | last3 = Keller | first3 = Joseph B. | author3-link = Joseph Keller\n | doi = 10.1137/0149007\n | issue = 1\n | journal = SIAM Journal on Applied Mathematics\n | mr = 978829\n | pages = 116–133\n | title = Fast reaction, slow diffusion, and curve shortening\n | volume = 49\n | year = 1989}}.\n* {{citation\n | last1 = Sapiro | first1 = Guillermo | author1-link = Guillermo Sapiro\n | last2 = Tannenbaum | first2 = Allen | author2-link = Allen Tannenbaum\n | doi = 10.1007/bf01420591\n | issue = 1\n | journal = International Journal of Computer Vision\n | pages = 25–44\n | title = Affine invariant scale-space\n | volume = 11\n | year = 1993}}.\n* {{citation\n | last1 = Schnürer | first1 = Oliver C.\n | last2 = Azouani | first2 = Abderrahim\n | last3 = Georgi | first3 = Marc\n | last4 = Hell | first4 = Juliette\n | last5 = Jangle | first5 = Nihar\n | last6 = Koeller | first6 = Amos\n | last7 = Marxen | first7 = Tobias\n | last8 = Ritthaler | first8 = Sandra\n | last9 = Sáez | first9 = Mariel\n | last10 = Schulze | first10 = Felix\n | last11 = Smith | first11 = Brian\n | arxiv = 0711.1108\n | doi = 10.1090/S0002-9947-2010-04820-2\n | issue = 5\n | journal = [[Transactions of the American Mathematical Society]]\n | mr = 2763716\n | pages = 2265–2294\n | title = Evolution of convex lens-shaped networks under the curve shortening flow\n | volume = 363\n | year = 2011}}.\n* {{citation\n | last = Scriven | first = L.E.\n | doi = 10.1016/0009-2509(60)87003-0\n | issue = 2\n | journal = Chemical Engineering Science\n | pages = 98–108\n | title = Dynamics of a fluid interface Equation of motion for Newtonian surface fluids\n | volume = 12\n | year = 1960}}.\n* {{citation\n | last1 = Smith | first1 = Stephen L.\n | last2 = Broucke | first2 = Mireille E. | author2-link = Mireille Broucke\n | last3 = Francis | first3 = Bruce A.\n | doi = 10.1109/tac.2007.899024\n | issue = 6\n | journal = IEEE Transactions on Automatic Control\n | pages = 1154–1159\n | title = Curve shortening and the rendezvous problem for mobile autonomous robots\n | volume = 52\n | year = 2007| arxiv = cs/0605070}}.\n* {{citation\n | last = Vichniac | first = Gérard Y.\n | editor1-last = Bienenstock | editor1-first = E.\n | editor2-last = Fogelman Soulié | editor2-first = F.\n | editor3-last = Weisbuch | editor3-first = G.\n | contribution = Cellular automata models of disorder and organization\n | doi = 10.1007/978-3-642-82657-3_1\n | pages = 3–20\n | publisher = Springer-Verlag\n | series = NATO ASI Series\n | title = Disordered Systems and Biological Organization\n | volume = 20\n | year = 1986}}.\n* {{citation\n | last = White | first = Brian | authorlink = Brian White (mathematician)\n | doi = 10.1007/BF03025885\n | issue = 4\n | journal = [[The Mathematical Intelligencer]]\n | mr = 1016106\n | pages = 41–47\n | title = Some recent developments in differential geometry\n | volume = 11\n | year = 1989}}.\n* {{citation\n | last = White | first = Brian | authorlink = Brian White (mathematician)\n | arxiv = math/0212407\n | contribution = Evolution of curves and surfaces by mean curvature\n | mr = 1989203\n | pages = 525–538\n | publisher = Higher Ed. Press, Beijing\n | title = Proceedings of the International Congress of Mathematicians, Vol. I (Beijing, 2002)\n | year = 2002| bibcode = 2002math.....12407W}}.\n* {{citation\n | last = You | first = Qian\n | publisher = The University of Wisconsin – Madison\n | series = Ph.D. thesis\n | title = Some Ancient Solutions of Curve Shortening\n | url = http://search.proquest.com/docview/1641120538\n | year = 2014}}.\n{{refend}}\n\n[[Category:Geometric flow]]"
    },
    {
      "title": "Inverse mean curvature flow",
      "url": "https://en.wikipedia.org/wiki/Inverse_mean_curvature_flow",
      "text": "{{Use American English|date = March 2019}}\n{{Short description|Geometric flow}}\nIn the field of [[differential geometry]] in [[mathematics]], '''inverse mean curvature flow (IMCF)''' is an example of a geometric flow of [[hypersurface]]s of a [[Riemannian manifold]] (for example, smooth surfaces in 3-dimensional Euclidean space).  Intuitively, a family of surfaces evolves under IMCF if the outward normal speed at which a point on the surface moves is given by the reciprocal of the [[mean curvature]] of the surface.  For example, a round sphere evolves under IMCF by expanding outward uniformly at an exponentially growing rate (see below).  In general, this flow does not exist (for example, if a point on the surface has zero mean curvature), and even if it does, it generally develops singularities.  Nevertheless, it has recently been an important tool in differential geometry and mathematical problems in [[general relativity]].\n\n== Example: a round sphere ==\nConsider a two-dimensional [[sphere]] of radius <math>R(t)</math> evolving under IMCF in 3-dimensional [[Euclidean space]], where <math>t</math> is the time parameter of the flow.  (By symmetry considerations, a round sphere will remain round under this flow, so that the radius at time <math>t</math> determines the surface at time <math>t</math>.)  The outward speed under the flow is the derivative, <math>R'(t)</math>, and the mean curvature equals <math>\\frac{2}{R(t)}</math>.  (This may be computed from the [[first variation of area formula]].)  Setting the speed equal to the reciprocal of the mean curvature, we have the [[ordinary differential equation]]\n\n:<math>\\frac{dR}{dt}=\\frac{R(t)}{2},</math>\n\nwhich possesses a unique, smooth solution given by\n\n:<math>R(t) = R_0 e^{t/2},</math>\n\nwhere <math>R_0</math> is the radius of the sphere at time <math>t=0</math>.  Thus, in this case we see that a round sphere evolves under IMCF by uniformly expanding outward with an exponentially increasing radius.\n\n== Generalization: weak IMCF ==\nIn 1997 [[Gerhard Huisken]] and T. Ilmanen showed that it makes sense to define a [[weak solution]] to IMCF.  Geometrically, this means that the flow can be continued past singularities if the surface is allowed to \"jump\" outward at certain times.\n\n== Monotonicity of the Hawking mass ==\nIt was observed by Geroch, Jang, and Wald that if a closed, connected surface evolves smoothly under IMCF in a 3-manifold with nonnegative [[scalar curvature]], then a certain geometric quantity associated to the surface, the [[Hawking mass]], is non-decreasing under the flow.  Amazingly, the Hawking mass is non-decreasing even under IMCF in the sense of Huisken and Ilmanen.  This fact is at the heart of the geometric applications of IMCF.\n\n== Applications ==\nIn the late 1990s and early 2000s, weak IMCF has been used to\n* prove the [[Riemannian Penrose inequality]] for the case of a single black hole (due to Huisken and Ilmanen)\n* compute the [[Yamabe invariant]] of three-dimensional [[real projective space]] (due to H. Bray and A. Neves)\n\n== See also ==\n* [[mean curvature flow]]\n\n==References==\n* Huisken, G., and Ilmanen, T. \"The inverse mean curvature flow and the Riemannian Penrose inequality\", ''Journal of Differential Geometry'', '''59''', (2001), 353-437.\n* Bray, H., and Neves A. \"Classification of prime 3-manifolds with Yamabe invariant greater than RP3.\" ''Annals of Mathematics'','''159''', (2004), 407-424.\n\n\n[[Category:Geometric flow]]\n[[Category:Differential geometry]]"
    },
    {
      "title": "Mean curvature flow",
      "url": "https://en.wikipedia.org/wiki/Mean_curvature_flow",
      "text": "{{Use mdy dates|date = March 2019}}\n{{Short description|Parabolic partial differential equation}}\n{{Use American English|date = March 2019}}\n\nIn the field of [[differential geometry]] in [[mathematics]], '''mean curvature flow''' is an example of a [[geometric flow]] of [[Glossary of differential geometry and topology#H|hypersurfaces]] in a [[Riemannian manifold]] (for example, smooth surfaces in 3-dimensional [[Euclidean space]]). Intuitively, a family of surfaces evolves under mean curvature flow if the normal component of the velocity of which a point on the surface moves is given by the [[mean curvature]] of the surface.  For example, a round [[sphere]] evolves under mean curvature flow by shrinking inward uniformly (since the mean curvature vector of a sphere points inward).  Except in special cases, the mean curvature flow develops [[Mathematical singularity|singularities]].\n\nUnder the constraint that volume enclosed is constant, this is called [[surface tension]] flow.\n\nIt is a [[parabolic partial differential equation]], and can be interpreted as \"smoothing\".\n\n==Physical examples==\nThe most familiar example of mean curvature flow is in the evolution of [[soap film]]s. A similar 2-dimensional phenomenon is oil drops on the surface of water, which evolve into disks (circular boundary).\n\nMean curvature flow was originally proposed as a model for the formation of grain boundaries in the annealing of pure metal.\n\n==Properties==\nThe mean curvature flow [[extremalization|extremalizes]] surface area, and [[minimal surface]]s are the critical points for the mean curvature flow; minima solve the [[isoperimetric]] problem.\n\nFor manifolds embedded in a [[Kähler–Einstein metric|Kähler–Einstein manifold]], if the surface is a [[Lagrangian submanifold]], the mean curvature flow is of Lagrangian type, so the surface evolves within the class of Lagrangian submanifolds.\n\n[[Huisken's monotonicity formula]] gives a monotonicity property of the [[convolution]] of a time-reversed [[heat kernel]] with a surface undergoing the mean curvature flow.\n\nRelated flows are:\n* [[Curve-shortening flow]], the one-dimensional case of mean curvature flow\n* the surface tension flow\n* the Lagrangian mean curvature flow\n* the [[inverse mean curvature flow]]\n\n==Mean curvature flow of a three-dimensional surface==\nThe differential equation for mean-curvature flow of a surface given by <math>z=S(x,y)</math> is given by\n\n:<math>\\frac{\\partial S}{\\partial t} = 2D\\ H(x,y) \\sqrt{1 + \\left(\\frac{\\partial S}{\\partial x}\\right)^2 + \\left(\\frac{\\partial S}{\\partial y}\\right)^2}\n</math>\n\nwith <math>D</math> being a constant relating the curvature and the speed of the surface normal, and\nthe mean curvature being\n\n:<math>\n\\begin{align}\nH(x,y) & = \n\\frac{1}{2}\\frac{\n\\left(1 + \\left(\\frac{\\partial S}{\\partial x}\\right)^2\\right) \\frac{\\partial^2 S}{\\partial y^2} - \n2 \\frac{\\partial S}{\\partial x} \\frac{\\partial S}{\\partial y} \\frac{\\partial^2 S}{\\partial x \\partial y} + \n\\left(1 + \\left(\\frac{\\partial S}{\\partial y}\\right)^2\\right) \\frac{\\partial^2 S}{\\partial x^2}\n}{\\left(1 + \\left(\\frac{\\partial S}{\\partial x}\\right)^2 + \\left(\\frac{\\partial S}{\\partial y}\\right)^2\\right)^{3/2}}.\n\\end{align}\n</math>\n\nIn the limits <math> |\\frac{\\partial S}{\\partial x}| \\ll 1 </math> and \n<math> |\\frac{\\partial S}{\\partial y}| \\ll 1 </math>, so that the surface is nearly planar with its normal nearly\nparallel to the z axis, this reduces to a [[diffusion equation]]\n\n:<math>\\frac{\\partial S}{\\partial t} = D\\ \\nabla^2 S\n</math>\n\nWhile the conventional diffusion equation is a linear parabolic partial differential equation and does not develop\nsingularities (when run forward in time), mean curvature flow may develop singularities because it is a nonlinear parabolic equation.  In general additional constraints need to be put on a surface to prevent singularities under \nmean curvature flows.\n\nEvery smooth convex surface collapses to a point under the mean-curvature flow, without other singularities, and converges to the shape of a sphere as it does so. For surfaces of dimension two or more this is a theorem of [[Gerhard Huisken]];<ref>{{citation\n | last = Huisken | first = Gerhard | authorlink = Gerhard Huisken\n | issue = 1\n | journal = Journal of Differential Geometry\n | mr = 1030675\n | pages = 285–299\n | title = Asymptotic behavior for singularities of the mean curvature flow\n | url = http://projecteuclid.org/euclid.jdg/1214444099\n | volume = 31\n | year = 1990}}.</ref> for the one-dimensional [[curve-shortening flow]] it is the Gage–Hamilton–Grayson theorem. However, there exist embedded surfaces of two or more dimensions other than the sphere that stay self-similar as they contract to a point under the mean-curvature flow, including the [[Angenent torus]].<ref>{{citation\n | last = Angenent | first = Sigurd B. | authorlink = Sigurd Angenent\n | contribution = Shrinking doughnuts\n | contribution-url = http://www.math.wisc.edu/~angenent/preprints/1989Gregynog/Gregynog.pdf\n | mr = 1167827\n | pages = 21–38\n | publisher = Birkhäuser | location = Boston, MA\n | series = Progress in Nonlinear Differential Equations and their Applications\n | title = Nonlinear diffusion equations and their equilibrium states, 3 (Gregynog, 1989)\n | volume = 7\n | year = 1992}}.</ref>\n\n==References==\n{{Reflist}}\n*{{citation\n | last = Ecker | first = Klaus\n | doi = 10.1007/978-0-8176-8210-1\n | isbn = 0-8176-3243-3\n | location = Boston, MA\n | mr = 2024995\n | publisher = Birkhäuser\n | series = Progress in Nonlinear Differential Equations and their Applications\n | title = Regularity Theory for Mean Curvature Flow\n | volume = 57\n | year = 2004}}.\n*{{citation\n | last = Mantegazza | first = Carlo\n | doi = 10.1007/978-3-0348-0145-4\n | isbn = 978-3-0348-0144-7\n | location = Basel\n | mr = 2815949\n | publisher = Birkhäuser/Springer\n | series = Progress in Mathematics\n | title = Lecture Notes on Mean Curvature Flow\n | volume = 290\n | year = 2011}}.\n*{{citation\n | last1 = Lu | first1 = Conglin\n | last2 = Cao | first2 = Yan\n | last3 = Mumford | first3 = David | author3-link = David Mumford\n | doi = 10.1006/jvci.2001.0476\n | issue = 1–2\n | journal = [[Journal of Visual Communication and Image Representation]]\n | pages = 65–81\n | title = Surface evolution under curvature flows\n | volume = 13\n | year = 2002}}. See in particular Equations 3a and 3b.\n\n[[Category:Geometric flow]]\n[[Category:Differential geometry]]"
    },
    {
      "title": "Ricci flow",
      "url": "https://en.wikipedia.org/wiki/Ricci_flow",
      "text": "[[Image:Ricci flow.png|thumb|right|upright|200px|Several stages of Ricci flow on a 2D manifold.]]\n\nIn [[differential geometry]], the '''Ricci flow''' ({{IPAc-en|ˈ|r|iː|tʃ|i}}, {{IPA-it|ˈrittʃi|lang}}) is an intrinsic [[geometric flow]]. It is a process that deforms the [[Metric tensor|metric]] of a [[Riemannian manifold]] in a way formally analogous to the [[diffusion]] of heat. Heuristically speaking, at every point of the manifold the Ricci flow shrinks directions of positive curvature and expands directions of negative curvature, while simultaneously smoothing out irregularities in the metric. The latter is analogous to the smoothing behavior of the [[heat equation]].\n\nThe Ricci flow, named after [[Gregorio Ricci-Curbastro]], was first introduced by [[Richard S. Hamilton]] in 1981 and is also referred to as the '''Ricci–Hamilton flow'''. It is the primary tool used in [[Grigori Perelman]]'s [[Poincaré conjecture#Solution|solution of the Poincaré conjecture]],<ref>{{Cite arxiv<!-- Deny Citation bot-->  |arxiv=math/0211159 |title=The entropy formula for the Ricci flow and its geometric applications |last1=Perelman |first1=Grisha |year=2002}}</ref> as well as in the proof of the [[differentiable sphere theorem]] by [[Simon Brendle]] and [[Richard Schoen]].<ref>{{Cite journal | doi = 10.1090/s0273-0979-2010-01312-4| title = Curvature, Sphere Theorems, and the Ricci flow| journal = Bulletin of the American Mathematical Society| volume = 48| pages = 1| year = 2011| last1 = Brendle | first1 = S. | last2 = Schoen | first2 = R. | arxiv = 1001.2278| bibcode = 1994BAMaS..30..205W}}</ref>\n\n== Mathematical definition ==\n\nGiven a Riemannian manifold with [[metric tensor]] <math>g_{ij}</math>, we can compute the [[Ricci tensor]] <math>R_{ij}</math>, which collects averages of sectional curvatures into a kind of \"[[trace (linear algebra)|trace]]\" of the [[Riemann curvature tensor]].  If we consider the metric tensor (and the associated Ricci tensor) to be functions of a variable which is usually called \"time\" (but which may have nothing to do with any physical time), then the Ricci flow may be defined by the '''geometric evolution equation'''<ref>{{cite journal|last=Friedan|first=D.|authorlink=Daniel Friedan|title=Nonlinear models in 2+ε dimensions | journal = PRL | volume = 45 | issue = 13| pages = 1057–1060 | year = 1980 |doi= 10.1103/PhysRevLett.45.1057 | bibcode=1980PhRvL..45.1057F|url=https://digital.library.unt.edu/ark:/67531/metadc841801/|type=Submitted manuscript}}</ref>\n:<math>\\partial_t g_{ij}=-2 R_{ij}.</math>\n\nThe normalized Ricci flow makes sense for [[Compact space|compact]] manifolds and is given by the equation\n:<math>\\partial_t g_{ij}=-2 R_{ij} +\\frac{2}{n} R_\\mathrm{avg} g_{ij}</math>\nwhere <math>R_\\mathrm{avg}</math> is the average (mean) of the scalar curvature (which is obtained from the Ricci tensor by taking the trace) and <math>n</math> is the dimension of the manifold. This normalized equation preserves the volume of the metric.\n\nThe factor of −2 is of little significance, since it can be changed to any nonzero real number by rescaling ''t''. However, the minus sign ensures that the Ricci flow is well defined for sufficiently small positive times; if the sign is changed, then the Ricci flow would usually only be defined for small negative times. (This is similar to the way in which the [[heat equation]] can be run forwards in time, but not usually backwards in time.)\n\nInformally, the Ricci flow tends to expand negatively curved regions of the manifold, and contract positively curved regions.\n\n==Examples==\n\n===Einstein metrics===\n*If the manifold is [[Euclidean space]], or more generally [[Ricci-flat manifold|Ricci-flat]], then Ricci flow leaves the metric unchanged.  Conversely, any metric unchanged by Ricci flow is [[Ricci-flat manifold|Ricci-flat]].\n*If the manifold is a [[sphere]] (with the usual metric), or more generally an [[Einstein metric]] (where Ricci tensor = constant × metric tensor) with positive curvature, then Ricci flow collapses the manifold to a point in finite time. For example, the metric of the ''n''-dimensional sphere of radius 1, after time <math>t</math>,  will be multiplied by <math> (1-2t(n-1))</math>, so the manifold will collapse after time <math>1/2(n-1)</math>. This shows that the Ricci flow sometimes cannot be continued for all time, instead producing singularities.\n* If the manifold is an [[Einstein manifold]] with negative curvature, then Ricci flow will expand it.\n\n===Ricci solitons===\n\n{{anchor|cigar_soliton_solution}}\n[[Ricci soliton | Ricci solitons]] are Ricci flows that may change their size but not their shape up to diffeomorphisms.\n* Cylinders '''S'''<sup>k</sup> × '''R'''<sup>l</sup> (for ''k ≥ 2'') shrink self similarly under the Ricci flow up to diffeomorphisms\n*A significant 2-dimensional example is the '''cigar soliton''', which is given by the metric (''dx''<sup>2</sup>&nbsp;+&nbsp;''dy''<sup>2</sup>)/(''e''<sup>4''t''</sup>&nbsp;+&nbsp;''x''<sup>2</sup>&nbsp;+&nbsp;''y''<sup>2</sup>) on the Euclidean plane. Although this metric shrinks under the Ricci flow, its geometry remains the same. Such solutions are called steady Ricci solitons.\n* An example of a 3-dimensional steady Ricci soliton is the '''[[Robert Bryant (mathematician)|Bryant]] soliton''', which is rotationally symmetric, has positive curvature, and is obtained by solving a system of ordinary differential equations.  A similar construction works in arbitrary dimension.\n* There exist numerous families of Kähler manifolds, invariant under a ''U(n)'' action and birational to ''C<sup>n</sup>'', which are Ricci solitons. These examples were constructed by Cao and Feldman-Ilmanen-Knopf.<ref>B. Chow and D. Knopf, ''The Ricci Flow: An Introduction'', ser. ''Mathematical Surveys and Monographs''. American Mathematical Society, 2004.[https://doi.org/10.1090/surv/110 doi:10.1090/surv/110]</ref>\n\n== Relationship to uniformization and geometrization ==\n\nThe Ricci flow was utilized by [[Richard S. Hamilton]] (1981) to gain insight into the [[geometrization conjecture]] of [[William Thurston]], which concerns the [[homeomorphism|topological classification]] of three-dimensional smooth manifolds.<ref>{{cite book | author=[[Jeffrey Weeks (mathematician)|Weeks, Jeffrey R.]] | title=The Shape of Space: how to visualize surfaces and three-dimensional manifolds| location=New York | publisher=Marcel Dekker | year=1985 | isbn=978-0-8247-7437-0}}.  A popular book that explains the background for the Thurston classification program.</ref> Hamilton's idea was to define a kind of nonlinear [[heat equation|diffusion equation]] which would tend to smooth out irregularities in the metric.  Then, by placing an ''arbitrary'' metric ''g'' on a given smooth manifold ''M'' and evolving the metric by the Ricci flow, the metric should approach a particularly nice metric, which might constitute a [[canonical form]] for ''M''.  Suitable canonical forms had already been identified by Thurston; the possibilities, called '''Thurston model geometries''', include the three-sphere '''S'''<sup>3</sup>, three-dimensional Euclidean space '''E'''<sup>3</sup>, three-dimensional hyperbolic space '''H'''<sup>3</sup>, which are [[homogeneous space|homogeneous]] and [[isotropic]], and five slightly more exotic Riemannian manifolds, which are homogeneous but not isotropic.  (This list is closely related to, but not identical with, the [[Bianchi classification]] of the three-dimensional real [[Lie algebra]]s into nine classes.) Hamilton's idea was that these special metrics should behave like [[Fixed point (mathematics)|fixed point]]s of the Ricci flow, and that if, for a given manifold, globally only one Thurston geometry was admissible, this might even act like an [[attractor]] under the flow.\n\nHamilton succeeded in proving that any smooth closed three-manifold which admits a metric of ''positive'' Ricci curvature also admits a unique Thurston geometry, namely a spherical metric, which does indeed act like an attracting fixed point under the Ricci flow, renormalized to preserve volume. (Under the unrenormalized Ricci flow, the manifold collapses to a point in finite time.)  This doesn't prove the full geometrization conjecture, because the most difficult case turns out to concern manifolds with ''negative'' Ricci curvature and more specifically those with negative sectional curvature.\n\nIndeed, a triumph of nineteenth century geometry was the proof of the [[uniformization theorem]], the analogous topological classification of smooth two-manifolds, where Hamilton showed that the Ricci flow does indeed evolve a negatively curved two-manifold into a two-dimensional multi-holed torus which is locally isometric to the hyperbolic plane.  This topic is closely related to important topics in analysis, number theory, dynamical systems, mathematical physics, and even cosmology.\n\nNote that the term \"uniformization\" suggests a kind of smoothing away of irregularities in the geometry, while the term \"geometrization\" suggests placing a geometry on a smooth manifold.  ''Geometry'' is being used here in a precise manner akin to [[Felix Klein|Klein]]'s [[Erlangen program|notion of geometry]] (see [[Geometrization conjecture]] for further details).  In particular, the result of geometrization may be a geometry that is not [[isotropic]].  In most cases including the cases of constant curvature, the geometry is unique.  An important theme in this area is the interplay between real and complex formulations.  In particular, many discussions of uniformization speak of complex curves rather than real two-manifolds.\n\nThe Ricci flow does not preserve volume, so to be more careful, in applying the Ricci flow to uniformization and geometrization one needs to ''normalize'' the Ricci flow to obtain a flow which preserves volume.  If one fails to do this, the problem is that (for example) instead of evolving a given three-dimensional manifold into one of Thurston's canonical forms, we might just shrink its size.\n\nIt is possible to construct a kind of [[moduli space]] of n-dimensional Riemannian manifolds, and then the Ricci flow really does give a ''[[geometric flow]]'' (in the intuitive sense of particles flowing along flowlines) in this moduli space.\n\n==Singularities==\n[[Richard_S._Hamilton | Hamilton]] showed that a compact Riemannian manifold always admits a short-time Ricci flow solution. Later Shi generalized the short-time existence result to complete manifolds of bounded curvature.<ref>{{cite journal |first=W.-X. |last=Shi |title=Deforming the metric on complete Riemannian manifolds |journal=J. Differential Geometry |volume=30 |year=1989 |pages=223–301 |doi=10.4310/jdg/1214443292 }}</ref> In general, however, due to the highly non-linear nature of the Ricci flow equation, singularities form in finite time. These singularities are curvature singularities, which means that as one approaches the singular time the norm of the [[Riemann curvature tensor | curvature tensor]] <math>|\\operatorname{Rm}|</math> blows up to infinity in the region of the singularity. A fundamental problem in Ricci flow is to understand all the possible geometries of singularities. When successful, this can lead to insights into the topology of manifolds. For instance, analyzing the geometry of singular regions that may develop in 3d Ricci flow, is the crucial ingredient in Perelman's proof the Poincare and Geometrization Conjectures. \n\n===Blow-up limits of singularities===\n\nTo study the formation of singularities it is useful, as in the study of other non-linear differential equations, to consider blow-ups limits. Intuitively speaking, one zooms into the singular region of the Ricci flow by rescaling time and space. Under certain assumptions, the zoomed in flow tends to a limiting Ricci flow <math> (M_\\infty, g_\\infty(t)), t \\in (-\\infty, 0] </math>, called a '''singularity model'''. Singularity models are ancient Ricci flows, i.e. they can be extended infinitely into the past. Understanding the possible singularity models in Ricci flow is an active research endeavor.\n\nBelow, we sketch the blow-up procedure in more detail: Let <math> (M, g_t), \\, t \\in [0,T), </math> be a Ricci flow that develops a singularity as <math>t \\rightarrow T</math>. Let <math>(p_i, t_i) \\in M \\times [0,T) </math> be a sequence of points in spacetime such that \n:<math>K_i := |\\operatorname{Rm}(g_{t_i})|(p_i) \\rightarrow \\infty  </math>\nas <math>i \\rightarrow \\infty</math>. Then one considers the parabolically rescaled metrics\n:<math>g_i(t) = K_i g\\left(t_i + \\frac{t}{K_i}\\right), \\quad t\\in[-K_i t_i, 0]</math>\nDue to the symmetry of the Ricci flow equation under parabolic dilations, the metrics <math>g_i(t)</math> are also solutions to the Ricci flow equation. In the case that \n:<math> |Rm| \\leq K_i  \\text{ on } M \\times [0,t_i]</math>,\ni.e. up to time <math>t_i</math> the maximum of the curvature is attained at <math>p_i</math>, then the pointed sequence of Ricci flows <math>(M, g_i(t), p_i)</math> subsequentially converges smoothly to a limiting ancient Ricci flow <math> (M_{\\infty}, g_{\\infty}(t), p_{\\infty})</math>. Note that in general <math> M_\\infty </math> is not diffeomorphic to <math>M</math>.\n\n===Type I and Type II singularities===\nHamilton distinguishes between '''Type I and Type II singularities''' in Ricci flow.<ref>{{cite journal |first=R. S. |last=Hamilton |title=The formation of singularities in the Ricci flow |journal=Surveys in Differential Geometry |volume=2 |issue= |pages=7136 |year=1995 |doi= }}</ref> In particular, one says a Ricci flow <math> (M, g_t), \\, t \\in [0,T) </math>, encountering a singularity a time <math>T</math> is of Type I if\n:<math> \\sup_{t < T} (T-t)|Rm| < \\infty </math>.\nOtherwise the singularity is of Type II. It is known that the blow-up limits of Type I singularities are gradient shrinking [[Ricci soliton|Ricci solitons]].<ref>{{cite journal |first=J. |last=Enders |first2=R. |last2=Mueller |first3=P. |last3=Topping |title=On Type I Singularities in Ricci flow |journal=Communications in Analysis and Geometry |volume=19 |issue=5 |year=2011 |pages=905–922 |doi=10.4310/CAG.2011.v19.n5.a4 }}</ref> In the Type II case it is an open question whether the singularity model must be a steady Ricci soliton—so far all known examples are.\n\n===Singularities in 3d Ricci flow===\nIn 3d the possible blow-up limits of Ricci flow singularities are well-understood. By Hamilton, Perelman and recent work by Brendle, blowing up at points of maximum curvature leads to one of the following three singularity models:\n* The shrinking round spherical space form <math> S^3/\\Gamma </math>\n* The shrinking round cylinder <math> S^2 \\times \\mathbb{R} </math> \n* The Bryant soliton\nThe first two singularity models arise from Type I singularities, whereas the last one arises from a Type II singularity.  \n\n===Singularities in 4d Ricci flow===\nIn four dimensions very little is known about the possible singularities, other than that the possibilities are far more numerous than in three dimensions. To date the following singularity models are known\n*<math>S^3 \\times \\mathbb{R} </math>\n*<math>S^2 \\times \\mathbb{R}^2 </math>\n*The 4d Bryant soliton\n*Compact Einstein manifold of positive scalar curvature\n*Compact gradient Kahler-Ricci shrinking soliton\n*The FIK shrinker <ref>{{cite journal |first=D. |last=Maximo |title=On the blow-up of four-dimensional Ricci flow singularities |journal=J. Reine Angew. Math. |volume=692 |year=2014 |pages=153171 |doi=10.1515/crelle-2012-0080 }}</ref>\n*The [[Eguchi–Hanson space]] <ref>{{cite arXiv |last=Appleton |first=Alexander |eprint=1903.09936 |title=Eguchi-Hanson singularities in U(2)-invariant Ricci flow\n |date= 2019}}</ref>\nNote that the first three examples are generalizations of 3d singularity models. The FIK shrinker models the collapse of an embedded sphere with [[Intersection number|self-intersection number]] -1.\n\n== Relation to diffusion ==\nTo see why the evolution equation defining the Ricci flow is indeed a kind of nonlinear diffusion equation, we can consider the special case of (real) two-manifolds in more detail.  Any metric tensor on a two-manifold can be written with respect to an '''exponential isothermal coordinate chart''' in the form\n:<math> ds^2 = \\exp(2 \\, p(x,y)) \\, \\left( dx^2 + dy^2 \\right). </math>\n(These coordinates provide an example of a [[conformal map|conformal]] coordinate chart, because angles, but not distances, are correctly represented.)\n\nThe easiest way to compute the [[Ricci tensor]] and [[Laplace-Beltrami operator]] for our Riemannian two-manifold is to use the differential forms method of [[Élie Cartan]].  Take the '''[[coframe field]]'''\n:<math> \\sigma^1 = \\exp (p) \\, dx, \\; \\; \\sigma^2 = \\exp (p) \\, dy</math>\nso that [[metric tensor]] becomes\n:<math> \\sigma^1 \\otimes \\sigma^1 + \\sigma^2 \\otimes \\sigma^2 = \\exp(2 p) \\, \\left( dx \\otimes dx + dy \\otimes dy \\right). </math>\n\nNext, given an arbitrary smooth function <math>h(x,y)</math>, compute the [[exterior derivative]]\n:<math> d h = h_x dx + h_y dy = \\exp(-p) h_x \\, \\sigma^1 + \\exp(-p) h_y \\, \\sigma^2.</math>\nTake the [[Hodge dual]]\n:<math> \\star d h = -\\exp(-p) h_y \\, \\sigma^1 + \\exp(-p) h_x \\, \\sigma^2 = -h_y \\, dx + h_x \\, dy.</math>\nTake another exterior derivative\n:<math> d \\star d h = -h_{yy} \\, dy \\wedge dx + h_{xx} \\, dx \\wedge dy = \\left( h_{xx} + h_{yy} \\right) \\, dx \\wedge dy </math>\n(where we used the '''anti-commutative property''' of the [[exterior product]]).  That is,\n:<math> d \\star d h = \\exp(-2 p) \\, \\left( h_{xx} + h_{yy} \\right) \\, \\sigma^1 \\wedge \\sigma^2. </math>\nTaking another Hodge dual gives\n:<math> \\Delta h = \\star d \\star d h = \\exp(-2 p) \\, \\left( h_{xx} + h_{yy} \\right)</math>\nwhich gives the desired expression for the Laplace/Beltrami operator\n:<math> \\Delta = \\exp(-2 \\, p(x,y)) \\left( D_x^2 + D_y^2 \\right). </math>\n\nTo compute the curvature tensor, we take the exterior derivative of the covector fields making up our coframe:\n:<math> d \\sigma^1 = p_y \\exp(p) dy \\wedge dx = -\\left( p_y dx \\right) \\wedge \\sigma^2 = -{\\omega^1}_2 \\wedge \\sigma^2</math>\n:<math> d \\sigma^2 = p_x \\exp(p) dx \\wedge dy = -\\left( p_x dy \\right) \\wedge \\sigma^1 = -{\\omega^2}_1 \\wedge \\sigma^1.</math>\nFrom these expressions, we can read off the only independent '''[[Spin connection]] one-form'''\n:<math> {\\omega^1}_2 = p_y dx - p_x dy,</math>\nwhere we have taken advantage of the anti-symmetric property of the connection (<math>{\\omega^2}_1=-{\\omega^1}_2</math>). Take another exterior derivative\n:<math> d {\\omega^1}_2 = p_{yy} dy \\wedge dx - p_{xx} dx \\wedge dy = -\\left( p_{xx} + p_{yy} \\right) \\, dx \\wedge dy.</math>\nThis gives the '''curvature two-form'''\n:<math> {\\Omega^1}_2 = -\\exp(-2p) \\left( p_{xx} + p_{yy} \\right) \\, \\sigma^1 \\wedge \\sigma^2 = -\\Delta p \\, \\sigma^1 \\wedge \\sigma^2</math>\nfrom which we can read off the only linearly independent component of the [[Riemann tensor]] using\n:<math> {\\Omega^1}_2 = {R^1}_{212} \\, \\sigma^1 \\wedge \\sigma^2.</math>\nNamely\n:<math> {R^1}_{212} = -\\Delta p</math>\nfrom which the only nonzero components of the [[Ricci tensor]] are\n:<math> R_{22} = R_{11} = -\\Delta p.</math>\nFrom this, we find components with respect to the '''coordinate cobasis''', namely\n:<math> R_{xx} = R_{yy} = -\\left( p_{xx} + p_{yy} \\right). </math>\n\nBut the metric tensor is also diagonal, with\n:<math> g_{xx} = g_{yy} = \\exp (2 p)</math>\nand after some elementary manipulation, we obtain an elegant expression for the Ricci flow:\n:<math> \\frac{\\partial p}{\\partial t} = \\Delta p. </math>\nThis is manifestly analogous to the best known of all diffusion equations, the [[heat equation]]\n:<math> \\frac{\\partial u}{\\partial t} = \\Delta u </math>\nwhere now <math>\\Delta = D_x^2 + D_y^2</math> is the usual [[Laplacian]] on the Euclidean plane.\nThe reader may object that the heat equation is of course a [[linear]] [[partial differential equation]]—where is the promised ''nonlinearity'' in the p.d.e. defining the Ricci flow?\n\nThe answer is that nonlinearity enters because the Laplace-Beltrami operator depends upon the same function p which we used to define the metric.  But notice that the flat Euclidean plane is given by taking <math> p(x,y) = 0</math>.  So if <math>p</math> is small in magnitude, we can consider it to define small deviations from the geometry of a flat plane, and if we retain only first order terms in computing the exponential, the Ricci flow on our two-dimensional almost flat Riemannian manifold becomes the usual two dimensional heat equation.  This computation suggests that, just as (according to the heat equation) an irregular temperature distribution in a hot plate tends to become more homogeneous over time, so too (according to the Ricci flow) an almost flat Riemannian manifold will tend to flatten out the same way that heat can be carried off \"to infinity\" in an infinite flat plate.  But if our hot plate is finite in size, and has no boundary where heat can be carried off, we can expect to ''homogenize'' the temperature, but clearly we cannot expect to reduce it to zero.  In the same way, we expect that the Ricci flow, applied to a distorted round sphere, will tend to round out the geometry over time, but not to turn it into a flat Euclidean geometry.\n\n==Recent developments==\n\nThe Ricci flow has been intensively studied since 1981. Some recent work has focused on the question of precisely how higher-dimensional Riemannian manifolds evolve under the Ricci flow, and in particular, what types of parametric [[Mathematical singularity|singularities]] may form.  For instance, a certain class of solutions to the Ricci flow demonstrates that '''neckpinch singularities''' will form on an evolving ''n''-dimensional metric Riemannian manifold having a certain topological property (positive [[Euler characteristic]]), as the flow approaches some characteristic time <math>t_{0}</math>.  In certain cases, such neckpinches will produce manifolds called [[Ricci soliton]]s.\n\nFor a 3-dimensional manifold, Perelman showed how to continue past the singularities using [[Poincare conjecture#Ricci flow with surgery|surgery on the manifold]].\n\nKähler metrics remain Kähler under Ricci flow, and so Ricci flow has applications  to the construction of [[Kähler–Einstein metric]]s.<ref>https://arxiv.org/find/all/1/all:+AND+flow+AND+ricci+AND+Einstein+metric/0/1/0/all/0/1</ref>\n\n== See also ==\n\n===Applications===\n* [[Uniformization theorem]]\n* [[Geometrization conjecture]]\n* [[Solution of the Poincaré conjecture]]\n* [[Differentiable sphere theorem]]\n\n===General context===\n* [[Ricci curvature]]\n* [[Calculus of variations]]\n* [[Geometric flow]]\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n*{{cite book | author=[[Simon Brendle|Brendle, Simon]] | title =Ricci Flow and the Sphere Theorem| publisher=American Mathematical Society | year=2010| isbn=978-0-8218-4938-5 | url=http://www.ams.org/bookstore-getitem/item=GSM-111}}.\n*{{cite journal |arxiv=math.DG/0605667 |author1=[[Bruce Kleiner]] |author2=[[John Lott (mathematician)|John Lott]] |title=Notes on Perelman's papers |year=2008 |doi=10.2140/gt.2008.12.2587 |volume=12 |issue=5 |journal=Geometry |pages=2587–2855}}\n*{{cite journal | first = Huai-Dong | last = Cao | authorlink = Huai-Dong Cao |author2=[[Xi-Ping Zhu]]  | title = A Complete Proof of the Poincaré and Geometrization Conjectures&nbsp;— application of the Hamilton-Perelman theory of the Ricci flow | url = http://www.ims.cuhk.edu.hk/~ajm/vol10/10_2.pdf | format = PDF | journal = Asian Journal of Mathematics | volume = 10 |date=June 2006 | issue =2}}    [https://web.archive.org/web/20120514194801/http://www.intlpress.com/AJM/p/2006/10_2/AJM-10-2-Erratum.pdf Erratum].\n** Revised version: {{cite arXiv | eprint=math.DG/0612069 |title=Hamilton-Perelman's Proof of the Poincaré Conjecture and the Geometrization Conjecture | author1=Huai-Dong Cao | author2=Xi-Ping Zhu | year=2006}}\n*{{Citation | editor-last1 = Cao | editor-first1 = H. D. | editor1-link = Huai-Dong Cao | editor-last2 = Chow | editor-first2 = B. | editor-last3 = Chu | editor-first3 = S. C. | editor-last4 = Yau | editor-first4 = S.-T. | editor4-link = Shing-Tung Yau | title = Collected Papers on Ricci Flow | place = Somerville, MA | publisher = International Press | series = Series in Geometry and Topology | volume = 37 | year = 2003 | isbn = 978-1-57146-110-0 | mr = 2145154 | zbl = 1108.53002 }}\n*[[Michael T. Anderson|Anderson, Michael T.]] ''Geometrization of 3-manifolds via the Ricci flow'', Notices of the AMS 51 (2004) 184–193.\n*[[John Milnor]], ''Towards the Poincaré Conjecture and the classification of 3-manifolds'', Notices of the AMS. 50 (2003) 1226–1233.\n*[[John Morgan (mathematician)|John Morgan]],  ''Recent progress on the Poincaré conjecture and the classification of 3-manifolds'', Bull. AMS 42 (2005) 57–78.\n*[[Richard S. Hamilton]], ''Three-manifolds with positive Ricci curvature'', J. Diff. Geom 17 (1982), 255–306.\n* {{cite book |author=Peter Topping|title=Lectures on the Ricci flow\n|url=http://www.maths.warwick.ac.uk/~topping/RFnotes.html| location=| publisher=C.U.P.| year=2006| isbn=978-0-521-68947-2}}\n*{{Cite book|last=Tao|first=T.|authorlink=Terence Tao|chapter=Ricci flow|pages=279–281|chapter-url=http://terrytao.files.wordpress.com/2008/03/ricci.pdf|title=The Princeton Companion to Mathematics|editor1-first=Timothy|editor1-last=Gowers|editor1-link=Timothy Gowers|editor2-first=June|editor2-last=Barrow-Green|editor3-first=Imre|editor3-last=Leader|editor3-link=Imre Leader|year=2008|publisher=Princeton University Press|isbn=978-0-691-11880-2|title-link=The Princeton Companion to Mathematics}}\n\n==External links==\n* {{cite web|last=Isenberg|first=James A|authorlink=James A. Isenberg|title=Ricci Flow|url=https://www.youtube.com/watch?v=hwOCqA9Xw6A|publisher=[[Brady Haran]]|accessdate=23 April 2014|format=video}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Ricci Flow}}\n[[Category:Geometric flow]]\n[[Category:Partial differential equations]]\n[[Category:3-manifolds]]\n[[Category:1981 introductions]]"
    },
    {
      "title": "Willmore energy",
      "url": "https://en.wikipedia.org/wiki/Willmore_energy",
      "text": "[[File:Willmore Surface sculpture Durham.jpg|thumb|right|\"Willmore Surface\" sculpture at Durham University in memory of Thomas Willmore]]\nIn [[differential geometry]], the '''Willmore energy''' is a quantitative measure of how much a given [[Surface (topology)|surface]] deviates from a round [[sphere]].  Mathematically, the Willmore energy of a [[Smooth manifold|smooth]] [[closed surface]] [[Embedding|embedded]] in three-dimensional [[Euclidean space]] is defined to be the [[integral]] of the square of the [[mean curvature]] minus the [[Gaussian curvature]].  It is named after the English geometer [[Thomas Willmore]].\n\n==Definition==\nExpressed symbolically, the Willmore energy of ''S'' is:\n\n:<math> \\mathcal{W} = \\int_S H^2 \\, dA - \\int_S K \\, dA</math>\n\nwhere <math>H</math> is the [[mean curvature]], <math>K</math> is the [[Gaussian curvature]], and ''dA'' is the area form of ''S''.  For a closed surface, by the [[Gauss–Bonnet theorem]], the integral of the Gaussian curvature may be computed in terms of the [[Euler characteristic]] <math>\\chi(S)</math> of the surface, so\n\n:<math> \\int_S K \\, dA = 2 \\pi \\chi(S), </math>\n\nwhich is a [[topological property|topological invariant]] and thus independent of the particular embedding in <math>\\mathbb{R}^3</math> that was chosen.  Thus the Willmore energy can be expressed as\n:<math> \\mathcal{W} = \\int_S H^2 \\, dA - 2 \\pi \\chi(S)</math>\n\nAn alternative, but equivalent, formula is\n\n:<math> \\mathcal{W} = {1 \\over 4} \\int_S (k_1 - k_2)^2 \\, dA</math>\n\nwhere <math>k_1</math> and <math>k_2</math> are the [[principal curvatures]] of the surface.\n\n===Properties===\nThe Willmore energy is always greater than or equal to zero.  A round [[sphere]] has zero Willmore energy.\n\nThe Willmore energy can be considered a functional on the space of embeddings of a given surface, in the sense of the [[calculus of variations]], and one can vary the embedding of a surface, while leaving it topologically unaltered.\n\n==Critical points==\nA basic problem in the [[calculus of variations]] is to find the [[critical point (mathematics)|critical points]] and minima of a functional.\n\nFor a given topological space, this is equivalent to finding the critical points of the function\n:<math>\\int_S H^2 \\, dA </math>\nsince the Euler characteristic is constant.\n\nOne can find (local) minima for the Willmore energy by [[gradient descent]], which in this context is called [[#Willmore_flow|Willmore flow]].\n\nFor embeddings of the sphere in 3-space, the critical points have been classified:<ref>{{citation\n | last = Bryant | first = Robert L. | authorlink = Robert Bryant (mathematician)\n | issue = 1\n | journal = [[Journal of Differential Geometry]]\n | mr = 772125\n | pages = 23–53\n | title = A duality theorem for Willmore surfaces\n | url = http://projecteuclid.org/euclid.jdg/1214438991\n | volume = 20\n | year = 1984}}.</ref> they are all [[conformal transform]]s of [[minimal surface]]s, the round sphere is the minimum, and all other critical values are integers greater than or equal to 4<math>\\pi</math>. They are called Willmore surfaces.\n\n==Willmore flow==\nThe '''Willmore flow''' is the [[geometric flow]] corresponding to the Willmore energy;\nit is an <math>L^2</math>-[[gradient flow]].\n\n:<math>e[{\\mathcal{M}}]=\\frac{1}{2} \\int_{\\mathcal{M}} H^2\\, \\mathrm{d}A</math>\n\nwhere ''H'' stands for the [[mean curvature]] of the [[manifold]] <math>\\mathcal{M}</math>.\n\nFlow lines satisfy the differential equation:\n:<math> \\partial_t x(t) = -\\nabla \\mathcal{W}[x(t)] \\, </math>\nwhere <math>x</math> is a point belonging to the surface.\n\nThis flow leads to an evolution problem in [[differential geometry]]: the surface <math>\\mathcal{M}</math> is evolving \nin time to follow variations of steepest descent of the energy. Like [[surface diffusion (mathematics)|surface diffusion]] it is a fourth-order \nflow, since the variation of the energy contains fourth derivatives.\n\n==Applications==\n* [[Cell membrane]]s tend to position themselves so as to minimize Willmore energy.\n* Willmore energy is used in constructing a class of optimal [[sphere eversion]]s, the [[minimax eversion]]s.\n\n==See also==\n* [[Willmore conjecture]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*{{citation\n | last = Willmore | first = T. J. | authorlink = Thomas Willmore\n | contribution = A survey on Willmore immersions\n | mr = 1185712\n | pages = 11–16\n | publisher = World Scientific | location = River Edge, NJ\n | title = Geometry and Topology of Submanifolds, IV (Leuven, 1991)\n | year = 1992}}.\n\n[[Category:Geometric flow]]\n[[Category:Differential geometry]]\n[[Category:Surfaces]]"
    },
    {
      "title": "Yamabe flow",
      "url": "https://en.wikipedia.org/wiki/Yamabe_flow",
      "text": "{{Refimprove|date=October 2016}}\nIn [[differential geometry]], the '''Yamabe flow''' is an intrinsic [[geometric flow]]—a process which [[deformation theory|deforms]] the [[metric tensor|metric]] of a [[Riemannian manifold]].  First introduced by [[Richard S. Hamilton]],{{cn|date=February 2018}} Yamabe flow is for noncompact manifolds, and is the \nnegative [[L2 norm|''L''<sup>2</sup>]]-[[gradient flow]] of the (normalized) total [[scalar curvature]], restricted to a given [[conformal class]]: it can be interpreted as deforming a Riemannian metric to a conformal metric of constant scalar curvature, when this flow converges.\n\nThe Yamabe flow was introduced in response to  [[Richard S. Hamilton]]'s own work on the [[Ricci flow]] and [[Richard Schoen|Rick Schoen's]] solution of the [[Yamabe problem]] on manifolds of positive conformal [[Yamabe invariant]].\n\n==Main results==\nThe fixed points of the Yamabe flow are metrics of constant scalar curvature in the given conformal class. The flow was first studied in the 1980s in unpublished notes of Richard Hamilton. Hamilton conjectured that, for every initial metric, the flow converges to a conformal metric of constant scalar curvature. This was verified by Rugang Ye in the locally conformally flat case.<ref>{{cite journal |first=Rugang |last=Ye |title=Global existence and convergence of Yamabe flow |journal=J. Differential Geom. |volume=39 |year=1994 |issue=1 |pages=35–50 |doi=10.4310/jdg/1214454674 }}</ref> Later, [[Simon Brendle|Brendle]], proved convergence of the flow for all conformal classes and arbitrary initial metrics.<ref>{{cite journal |first=Simon |last=Brendle |title=Convergence of the Yamabe flow for arbitrary initial energy |journal=J. Differential Geom. |volume=69 |year=2005 |issue=2 |pages=217–278 |doi=10.4310/jdg/1121449107 }}</ref> The limiting constant-scalar-curvature metic is typically no longer a Yamabe minimizer in this context. While the compact case is settled, the flow on complete, non-compact manifolds is not completely understood, and remains a topic of current research.\n\n== Notes ==\n{{reflist}}\n\n[[Category:Geometric flow]]"
    },
    {
      "title": "Minimal surface",
      "url": "https://en.wikipedia.org/wiki/Minimal_surface",
      "text": "[[Image:Bulle de savon hélicoïde.PNG|thumb|180px|right|A [[helicoid]] minimal surface formed by a soap film on a helical frame]]\nIn [[mathematics]], a '''minimal surface''' is a surface that locally minimizes its area. This is equivalent to having zero [[mean curvature]] (see definitions below).\n\nThe term \"minimal surface\" is used because these surfaces originally arose as surfaces that minimized total surface area subject to some constraint. Physical models of area-minimizing minimal surfaces can be made by dipping a wire frame into a soap solution, forming a [[soap film]], which is a minimal surface whose boundary is the wire frame. However, the term is used for more general surfaces that may [[Immersed submanifold#Immersed submanifolds|self-intersect]] or do not have constraints. For a given constraint there may also exist several minimal surfaces with different areas (for example, see [[minimal surface of revolution]]): the standard definitions only relate to a [[local optimum]], not a [[global optimum]].\n\n==Definitions==\n[[File:Saddle Tower Minimal Surfaces.png|thumb|[[Saddle tower]] minimal surface. While any small change of the surface increases its area, there exist other surfaces with the same boundary with a smaller total area.]]\n\nMinimal surfaces can be defined in several equivalent ways in '''R'''<sup>3</sup>. The fact that they are equivalent serves to demonstrate how minimal surface theory lies at the crossroads of several mathematical disciplines, especially [[differential geometry]], [[calculus of variations]], [[potential theory]], [[complex analysis]] and [[mathematical physics]].<ref>{{cite journal\n | first1 = William H., III\n | last1 = Meeks\n | first2 = Joaquín\n | last2 = Pérez\n | year = 2011\n | title = The classical theory of minimal surfaces\n | journal =  [[Bull. Amer. Math. Soc.]]\n | volume = 48\n | issue = 3\n | pages = 325–407\n | doi = 10.1090/s0273-0979-2011-01334-9\n | mr = 2801776 \n}}</ref>\n\n:'''Local least area definition''': A surface ''M'' ⊂ '''R'''<sup>3</sup> is minimal if and only if every point ''p'' ∈ ''M'' has a [[neighbourhood (topology)|neighbourhood]] with least-area relative to its boundary.\n\nNote that this property is local: there might exist other surfaces that minimize area better with the same global boundary.\n\n:'''Variational definition''': A surface ''M'' ⊂ '''R'''<sup>3</sup> is minimal if and only if it is a [[Critical point (mathematics)|critical point]] of the area [[Functional (mathematics)|functional]] for all compactly supported [[Calculus of variations|variations]].\n\nThis definition makes minimal surfaces a 2-dimensional analogue to [[geodesics]].\n\n:'''Soap film definition''': A surface ''M'' ⊂ '''R'''<sup>3</sup> is minimal if and only if every point ''p'' ∈ ''M'' has a neighbourhood ''D<sub>p</sub>'' which is equal to the unique idealized soap film with boundary ∂''D<sub>p</sub>''\n\nBy the [[Young–Laplace equation]] the [[curvature]] of a soap film is proportional to the difference in pressure between the sides: if it is zero, the membrane has zero mean curvature. Note that spherical [[Soap bubble|bubbles]] are ''not'' minimal surfaces as per this definition: while they minimize total area subject to a constraint on internal volume, they have a positive pressure.\n\n[[File:Minimal surface curvature planes-en.svg|thumb|Minimal surface curvature planes.  On a minimal surface, the curvature along the principal curvature planes are equal and opposite at every point. This makes the mean curvature zero.]]\n\n:'''Mean curvature definition''': A surface ''M'' ⊂ '''R'''<sup>3</sup> is minimal if and only if its [[mean curvature]] vanishes identically.\n\nA direct implication of this definition is that every point on the surface is a [[saddle point]] with equal and opposite [[principal curvatures]].\n\n:'''Differential equation definition''': A surface ''M'' ⊂ '''R'''<sup>3</sup> is minimal if and only if it can be locally expressed as the graph of a solution of\n\n::<math>(1+u_x^2)u_{yy} - 2u_xu_yu_{xy} + (1+u_y^2)u_{xx}=0</math>\n\nThe partial differential equation in this definition was originally found in 1762 by [[Lagrange]],<ref name=\"Lagrange1760\">J. L. Lagrange. Essai d'une nouvelle methode pour determiner les maxima et les minima des formules integrales indefinies. Miscellanea Taurinensia 2, 325(1):173{199, 1760.</ref> and [[Jean Baptiste Meusnier]] discovered in 1776 that it implied a vanishing mean curvature.<ref name=\"Meusnier1785\">J. B. Meusnier. Mémoire sur la courbure des surfaces. Mém. Mathém. Phys. Acad. Sci. Paris, prés. par div. Savans, 10:477–510, 1785. Presented in 1776.</ref>\n\n:'''Energy definition''': A [[Conformal map|conformal]] immersion ''X'': ''M'' → '''R'''<sup>3</sup> is minimal if and only if it is a critical point of the [[Dirichlet energy]] for all compactly supported variations, or equivalently if any point ''p'' ∈ ''M'' has a neighbourhood with least energy relative to its boundary.\n\nThis definition ties minimal surfaces to [[harmonic functions]] and [[potential theory]].\n\n:'''Harmonic definition''': If ''X'' = (''x''<sub>1</sub>, ''x''<sub>2</sub>, ''x''<sub>3</sub>): ''M'' → '''R'''<sup>3</sup> is an [[Isometry|isometric]] [[Immersion (mathematics)|immersion]] of a [[Riemann surface]] into 3-space, then ''X'' is said to be minimal whenever ''x<sub>i</sub>'' is a [[harmonic function]] on ''M'' for each ''i''.\n\nA direct implication of this definition and the [[Harmonic functions#Maximum principle|maximum principle for harmonic functions]] is that there are no [[compact space|compact]] [[Complete metric space|complete]] minimal surfaces in '''R'''<sup>3</sup>.\n\n:'''Gauss map definition''': A surface ''M'' ⊂ '''R'''<sup>3</sup> is minimal if and only if its [[Stereographic projection|stereographically]] projected [[Gauss map]] ''g'': ''M'' → '''C''' ∪ {∞} is [[meromorphic]] with respect to the underlying [[Riemann surface]] structure, and ''M'' is not a piece of a sphere.\n\nThis definition uses that the mean curvature is half of the [[Trace (linear algebra)|trace]] of the [[Shape operator#Shape operator|shape operator]], which is linked to the derivatives of the Gauss map. If the projected Gauss map obeys the [[Cauchy–Riemann equations]] then either the trace vanishes or every point of ''M'' is [[Umbilical point|umbilic]], in which case it is a piece of a sphere.\n\n:'''Mean curvature flow definition''': Minimal surfaces are the critical points for the [[mean curvature flow]].<ref>{{cite journal | first1=Tobias H. | last1=Colding | first2=William P., II | last2=Minicozzi | title=The Space of Embedded Minimal Surfaces of Fixed Genus in a 3-manifold. II. Multi-valued Graphs in Disks | journal=[[Ann. of Math.]] | volume=160 | year=2004 | issue=1 | pages=69–92 | mr=2119718 | doi=10.4007/annals.2004.160.69}}</ref>\n\nThe local least area and variational definitions allow extending minimal surfaces to other [[Riemannian manifolds]] than '''R'''<sup>3</sup>.\n\n==History==\nMinimal surface theory originates with [[Lagrange]] who in 1762 considered the variational problem of finding the surface ''z'' = ''z''(''x'', ''y'') of least area stretched across a given closed contour. He derived the [[Euler–Lagrange equation]] for the solution\n\n:<math>\\frac{d}{dx}\\left(\\frac{z_x}{\\sqrt{1+z_x^2+z_y^2}}\\right ) + \\frac{d}{dy}\\left(\\frac{z_y}{\\sqrt{1+z_x^2+z_y^2}}\\right )=0</math>\n\nHe did not succeed in finding any solution beyond the plane. In 1776 [[Jean Baptiste Marie Meusnier]] discovered that the [[helicoid]] and [[catenoid]] satisfy the equation and that the differential expression corresponds to twice the [[mean curvature]] of the surface, concluding that surfaces with zero mean curvature are area-minimizing.\n\nBy expanding Lagrange's equation to\n\n:<math>\\left(1 + z_x^2\\right)z_{yy} - 2z_xz_yz_{xy} + \\left(1 + z_y^2\\right)z_{xx} = 0</math>\n\n[[Gaspard Monge]] and [[Adrien-Marie Legendre|Legendre]] in 1795 derived representation formulas for the solution surfaces. While these were successfully used by [[Heinrich Scherk]] in 1830 to derive his [[Scherk surface|surfaces]], they were generally regarded as practically unusable. [[Eugène Charles Catalan|Catalan]] proved in 1842/43 that the helicoid is the only [[ruled surface|ruled]] minimal surface.\n\nProgress had been fairly slow until the middle of the century when the [[Björling problem]] was solved using complex methods. The \"first golden age\" of minimal surfaces began. [[Hermann Schwarz|Schwarz]] found the solution of the [[Plateau problem]] for a regular quadrilateral in 1865 and for a general quadrilateral in 1867 (allowing the construction of his periodic [[Schwarz minimal surface|surface families]]) using complex methods. [[Weierstrass]] and [[Alfred Enneper|Enneper]] developed more useful [[Weierstrass–Enneper parameterization|representation formulas]], firmly linking minimal surfaces to [[complex analysis]] and [[harmonic functions]]. Other important contributions came from Beltrami, Bonnet, Darboux, Lie, Riemann, Serret and Weingarten.\n\nBetween 1925 and 1950 minimal surface theory revived, now mainly aimed at nonparametric minimal surfaces. The complete solution of the Plateau problem by [[Jesse Douglas]] and [[Tibor Radó]] was a major milestone. [[Bernstein's problem]] and [[Robert Osserman]]'s work on complete minimal surfaces of finite total curvature were also important.\n\nAnother revival began in the 1980s. One cause was the discovery in 1982 by Celso Costa of [[Costa's minimal surface|a surface]] that disproved the conjecture that the plane, the catenoid, and the helicoid are the only complete embedded minimal surfaces in '''R'''<sup>3</sup> of finite topological type. This not only stimulated new work on using the old parametric methods, but also demonstrated the importance of computer graphics to visualise the studied surfaces and numerical methods to solve the \"period problem\" (when using the [[Associate family|conjugate surface method]] to determine surface patches that can be assembled into a larger symmetric surface, certain parameters need to be numerically matched to produce an embedded surface). Another cause was the verification by H. Karcher that the [[triply periodic minimal surface]]s originally described empirically by Alan Schoen in 1970 actually exist. This has led to a rich menagerie of surface families and methods of deriving new surfaces from old, for example by adding handles or distorting them.\n\nCurrently the theory of minimal surfaces has diversified to minimal submanifolds in other ambient geometries, becoming relevant to mathematical physics (e.g. the [[positive mass conjecture]], the [[Riemannian Penrose inequality|Penrose conjecture]]) and three-manifold geometry (e.g. the [[Smith conjecture]], the [[Poincaré conjecture]], the [[Thurston Geometrization Conjecture]]).\n\n==Examples==\n[[File:Costa's Minimal Surface.png|thumb|[[Costa's Minimal Surface]]]]\n\nClassical examples of minimal surfaces include:\n* the [[plane (geometry)|plane]], which is a [[trivial (mathematics)|trivial]] case\n* [[catenoid]]s: minimal surfaces made by rotating a [[catenary]] once around its directrix\n* [[helicoid]]s: A surface swept out by a line rotating with uniform velocity around an axis perpendicular to the line and simultaneously moving along the axis with uniform velocity\n\nSurfaces from the 19th century golden age include:\n* [[Schwarz minimal surface]]s: [[Triply periodic minimal surface|triply periodic surfaces]] that fill '''R'''<sup>3</sup>\n* [[Riemann's minimal surface]]: A posthumously described periodic surface\n* the [[Enneper surface]]\n* the [[Henneberg surface]]: the first non-orientable minimal surface\n* [[Bour's minimal surface]]\n\nModern surfaces include:\n* the [[Gyroid]]: One of Schoen's 1970 surfaces, a triply periodic surface of particular interest for liquid crystal structure\n* the [[Saddle tower]] family: generalisations of [[Scherk surface|Scherk's second surface]]\n* [[Costa's minimal surface]]: Famous conjecture disproof. Described in 1982 by [[Celso Costa]] and later visualized by [[Jim Hoffman]]. Jim Hoffman, David Hoffman and William Meeks III then extended the definition to produce a family of surfaces with different rotational symmetries.\n* the [[Chen–Gackstatter surface]] family, adding handles to the Enneper surface.\n\n==Generalisations and links to other fields==\nMinimal surfaces can be defined in other [[manifolds]] than '''R'''<sup>3</sup>, such as [[hyperbolic space]], higher-dimensional spaces or [[Riemannian manifolds]].\n\nThe definition of minimal surfaces can be generalized/extended to cover [[constant-mean-curvature surface]]s: surfaces with a constant mean curvature, which need not equal zero.\n\nIn [[discrete differential geometry]] discrete minimal surfaces are studied: [[simplicial complex]]es of triangles that minimize their area under small perturbations of their vertex positions.<ref>{{cite journal | first1=Ulrich | last1=Pinkall | first2=Konrad | last2=Polthier | title=Computing Discrete Minimal Surfaces and Their Conjugates | journal=[[Experimental Mathematics (journal)|Experimental Mathematics]] | volume=2 | issue=1 | pages=15–36 | year=1993 | mr=1246481 | url=http://projecteuclid.org/euclid.em/1062620735| doi=10.1080/10586458.1993.10504266 }}</ref> Such discretizations are often used to approximate minimal surfaces numerically, even if no closed form expressions are known.\n\n[[Wiener process|Brownian motion]] on a minimal surface leads to probabilistic proofs of several theorems on minimal surfaces.<ref>{{cite journal | first=Robert | last=Neel | year=2009 | arxiv=0805.0556 | title=A martingale approach to minimal surfaces | journal=Journal of Functional Analysis | volume=256 | issue=8 | pages=2440–2472 | doi=10.1016/j.jfa.2008.06.033 | mr=2502522}}</ref>\n\nMinimal surfaces have become an area of intense scientific study, especially in the areas of [[molecular engineering]] and [[materials science]], due to their anticipated applications in [[self-assembly]] of complex materials.{{Citation needed|date=March 2019}} The [[Endoplasmic reticulum|endoplasmic reticulum]], an important structure in cell biology, is proposed to be under evolutionary pressure to conform to a nontrivial minimal surface<ref>{{Cite journal|last=Terasaki|first=Mark|last2=Shemesh|first2=Tom|last3=Kasthuri|first3=Narayanan|last4=Klemm|first4=Robin W.|last5=Schalek|first5=Richard|last6=Hayworth|first6=Kenneth J.|last7=Hand|first7=Arthur R.|last8=Yankova|first8=Maya|last9=Huber|first9=Greg|date=2013-07-18|title=Stacked endoplasmic reticulum sheets are connected by helicoidal membrane motifs|journal=Cell|volume=154|issue=2|pages=285–296|doi=10.1016/j.cell.2013.06.031|issn=0092-8674|pmc=3767119|pmid=23870120}}</ref>.\n\nMinimal surfaces play a role in [[general relativity]]. The [[apparent horizon]] (marginally outer trapped surface) is a minimal hypersurface, linking the theory of [[black holes]] to minimal surfaces and the [[Plateau problem]].<ref>{{cite journal | first1=Piotr T. | last1=Chruściel | first2=Gregory J. | last2=Galloway | first3=Daniel | last3=Pollack | title=Mathematical general relativity: a sampler | journal=[[Bull. Amer. Math. Soc.]] | volume=47 | issue=4 | year=2010 | pages=567–638 | arxiv=1004.1016 | mr=2721040 | doi=10.1090/S0273-0979-2010-01304-5| bibcode=2010arXiv1004.1016C }}</ref><ref>{{cite journal | first=Michael | last=Eichmair | title=The Plateau problem for marginally outer trapped surfaces | journal=[[Journal of Differential Geometry]] | volume=83 | issue=3 | year=2009 | pages=551–584 | arxiv=0711.4139 | mr=2581357 | url=http://projecteuclid.org/euclid.jdg/1264601035| bibcode=2007arXiv0711.4139E | doi=10.4310/jdg/1264601035 }}</ref>\n\nMinimal surfaces are part of the [[Generative Design|generative design]] toolbox used by modern designers. In architecture there has been much interest in [[tensile structure]]s, which are closely related to minimal surfaces. A famous example is the [[Olympiapark, Munich|Olympiapark in Münich]] by [[Frei Otto]], inspired by soap surfaces.\n\nIn the art world, minimal surfaces have been extensively explored in the sculpture of [[Robert Engman]] (1927– ), [[Robert Longhurst]] (1949– ), and [[Charles O. Perry]] (1929–2011), among others.\n\n==See also==\n* [[Bernstein's problem]]\n* [[Bilinear interpolation]]\n* [[Bryant surface]]\n* [[Curvature]]\n* [[Enneper–Weierstrass parameterization]]\n* [[Harmonic map]]\n* [[Harmonic morphism]]\n* [[Plateau's problem]]\n* [[Schwarz minimal surface]]\n* [[Soap bubble]]\n* [[Surface Evolver]]\n* [[Stretched grid method]]\n* [[Tensile structure]]\n* [[Triply periodic minimal surface]]\n* [[Weaire–Phelan structure]]\n\n==References==\n{{reflist}}\n\n==Further reading==\n* {{cite book\n | first = Robert\n | last = Osserman\n | title = A Survey of Minimal Surfaces\n | year = 1986\n | edition = Second\n | publisher = Dover Publications, Inc. | location = New York\n | isbn = 978-0-486-64998-6\n | mr = 0852409\n }} ''(Introductory text for surfaces in ''n''-dimensions, including ''n''=3; requires strong calculus abilities but no knowledge of differential geometry.)''\n* {{cite web\n | first1 = Hermann\n | last1 = Karcher\n | first2 = Konrad\n | last2 = Polthier\n | url = http://page.mi.fu-berlin.de/polthier/booklet/intro.html\n | title= Touching Soap Films - An introduction to minimal surfaces\n | year  = 1995\n | accessdate = December 27, 2006 }} ''(graphical introduction to minimal surfaces and soap films.)''\n* {{cite web\n | author = Various\n | url = http://www.eg-models.de/models.html\n | title= EG-Models\n | year  = 2000–\n | accessdate = September 28, 2004 }} ''(Online journal with several published models of minimal surfaces)''\n* {{cite web\n | author = Stewart Dickson\n | url = http://www.eg-models.de/models.html\n | title= Scientific Concretization; Relevance to the Visually Impaired Student\n | year  = 1996\n | work = VR in the School, Volume 1, Number 4\n | accessdate = April 15, 2006 }} ''(Describes the discovery of [[Costa's surface]])''\n* {{cite web\n | title=Grape Minimal Surface Library\n | url=http://numod.ins.uni-bonn.de/grape/EXAMPLES/AMANDUS/amandus.html\n | author = Martin Steffens and Christian Teitzel\n | accessdate = October 27, 2008 }} ''(A collection of minimal surfaces)''\n* {{cite web\n |title           = Scientific Graphics Project\n |url             = http://www.msri.org/about/sgp/jim/geom/minimal/index.html\n |author          = David Hoffman, [[Jim Hoffman]]\n |accessdate      = April 24, 2006\n |display-authors = etal\n |deadurl         = yes\n |archiveurl      = https://web.archive.org/web/20060703193416/http://www.msri.org/about/sgp/jim/geom/minimal/index.html\n |archivedate     = July 3, 2006\n |df              = \n}} ''(An collection of minimal surfaces with classical and modern examples)''\n* {{cite web\n | title=Periodic Minimal Surfaces Gallery\n | url=http://www-klinowski.ch.cam.ac.uk/pmsgal1.html\n| author = Jacek Klinowski\n| accessdate = February 2, 2009 }} ''(An collection of minimal surfaces with classical and modern examples)''\n* {{cite book\n | first1 = Ulrich\n | last1 = Dierkes\n | first2 = Stefan\n | last2 = Hildebrandt\n | first3 = Friedrich\n | last3 = Sauvigny\n | title = Minimal Surfaces\n | year = 2010\n | edition = Second\n | volume = 339\n | series = Grundlehren der Mathematischen Wissenschaften\n | others = With assistance and contributions by A. Küster and R. Jakob\n | publisher = Springer | location = Heidelberg\n | isbn = 978-3-642-11697-1\n | mr = 2566897\n | doi = 10.1007/978-3-642-11698-8\n }} ''(Review of minimal surface theory, in particularly boundary value problems. Contains extensive references to the literature.)''\n\n== External links==\n* {{springer|title=Minimal surface|id=p/m063920}}\n* [http://3d-xplormath.org/j/index.html 3D-XplorMath-J Homepage &mdash; Java program and applets for interactive mathematical visualisation]\n* [http://xahlee.org/surface/gallery_m.html Gallery of rotatable minimal surfaces]\n* [http://www.princeton.edu/~rvdb/WebGL/minsurf.html WebGL-based Gallery of rotatable/zoomable minimal surfaces]\n\n{{Minimal surfaces}}\n\n[[Category:Differential geometry]]\n[[Category:Differential geometry of surfaces]]\n[[Category:Minimal surfaces| ]]"
    },
    {
      "title": "Associate family",
      "url": "https://en.wikipedia.org/wiki/Associate_family",
      "text": "[[Image:helicatenoid.gif|thumb|right|256px|Animation showing the deformation of a helicoid into a catenoid as ''θ'' changes.]]\n\nIn [[differential geometry]], the '''associate family''' (or [[Pierre Ossian Bonnet|Bonnet]] family) of a [[minimal surface]] is a one-parameter family of minimal surfaces which share the same [[Weierstrass–Enneper parameterization|Weierstrass data]]. That is, if the surface has the representation \n:<math>x_k(\\zeta) = \\Re \\left\\{ \\int_{0}^{\\zeta} \\varphi_{k}(z) \\, dz \\right\\} + c_k , \\qquad k=1,2,3</math>\nthe family is described by\n\n:<math>x_k(\\zeta,\\theta) = \\Re \\left\\{ e^{i \\theta} \\int_0^\\zeta \\varphi_{k}(z) \\, dz \\right\\} + c_k , \\qquad \\theta \\in [0,2\\pi] </math>\n\nFor ''θ''&nbsp;=&nbsp;''π''/2 the surface is called the conjugate of the ''θ''&nbsp;=&nbsp;0 surface.<ref>Matthias Weber, Classical Minimal Surfaces in Euclidean Space by Examples, in Global Theory of Minimal Surfaces:\nProceedings of the Clay Mathematics Institute 2001 Summer School, Mathematical Sciences Research Institute, Berkeley, California, June 25–July 27, 2001. American Mathematical Soc., 2005 [http://www.indiana.edu/~minimal/research/claynotes.pdf]</ref>\n\nThe transformation can be viewed as locally rotating the [[principal curvature]] directions. The surface normals of a point with a fixed ''ζ'' remains unchanged as ''θ'' changes; the point itself moves along an ellipse.\n\nSome examples of associate surface families are: the [[catenoid]] and [[helicoid]] family, the [[Schwarz minimal surface#Schwarz P .28.22Primitive.22.29|Schwarz P]], [[Schwarz minimal surface#Schwarz D .28.22Diamond.22.29|Schwarz D]] and [[gyroid]] family, and the [[Scherk surface|Scherk's first and second surface]] family. The [[Enneper surface]] is conjugate to itself: it is left invariant as ''θ'' changes.\n\nConjugate surfaces have the property that any straight line on a surface maps to a planar geodesic on its conjugate surface and vice versa. If a patch of one surface is bounded by a straight line, then the conjugate patch is bounded by a planar symmetry line. This is useful for constructing minimal surfaces by going to the conjugate space: being bound by planes is equivalent to being bound by a polygon.<ref>Hermann Karcher, Konrad Polthier, \"Construction of Triply Periodic Minimal Surfaces\", Phil. Trans. R. Soc. Lond. A 16 September 1996 vol. 354 no. 1715 2077–2104 [http://www.polthier.info/articles/triply/triply_withoutApp.pdf]</ref>\n\nThere are counterparts to the associate families of minimal surfaces in higher-dimensional spaces and manifolds.<ref>J.-H. Eschenburg, The Associated Family, Matematica Contemporanea, Vol 31, 1–12 2006 [http://www.mat.unb.br/matcont/31_1.pdf]</ref>\n\n==References==\n{{reflist}}\n\n{{Minimal surfaces}}\n\n[[Category:Differential geometry]]\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Björling problem",
      "url": "https://en.wikipedia.org/wiki/Bj%C3%B6rling_problem",
      "text": "[[File:Catalan's Minimal Surface.png|thumb|Catalan's minimal surface. It can be defined as the minimal surface symmetrically passing through a cycloid.]]\n\nIn [[differential geometry]], the '''Björling problem''' is the problem of finding a [[minimal surface]] passing through a given curve with prescribed normal (or tangent planes). The problem was posed and solved by Swedish mathematician [[Emanuel Björling|Emanuel Gabriel Björling]],<ref>E.G. Björling, Arch. Grunert , IV (1844) pp. 290</ref> with further refinement by [[Hermann Schwarz]].<ref>H.A. Schwarz, J. reine angew. Math. 80 280-300 1875</ref>\n\nThe problem can be solved by extending the surface from the curve using complex [[analytic continuation]]. If <math>c(s)</math> is a real analytic curve in ℝ<sup>3</sup> defined over an interval ''I'', with <math>c'(s)\\neq 0</math> and a vector field <math>n(s)</math> along ''c'' such that <math>||n(t)||=1</math> and <math>c'(t)\\cdot n(t)=0</math>, then the following surface is minimal:\n\n:<math>X(u,v) = \\Re \\left ( c(w) - i \\int_{w_0}^w n(w) \\wedge c'(w) \\, dw \\right)</math>\n\nwhere <math>w = u+iv \\in \\Omega</math>, <math>u_0\\in I</math>, and <math>I \\subset \\Omega</math> is a simply connected domain where the interval is included and the power series expansions of <math>c(s)</math> and <math>n(s)</math> are convergent.<ref>Kai-Wing Fung, Minimal Surfaces as Isotropic Curves in '''C'''<sup>3</sup>: Associated minimal surfaces and the Björling's problem. MIT BA Thesis. 2004 http://ocw.mit.edu/courses/mathematics/18-994-seminar-in-geometry-fall-2004/projects/main1.pdf</ref>\n\nA classic example is [[Catalan's minimal surface]], which passes through a [[cycloid]] curve. Applying the method to a [[semicubical parabola]] produces the [[Henneberg surface]], and to a circle (with a suitably twisted normal field) a minimal [[Möbius strip]].<ref>{{cite journal |author=W.H. Meeks III |title=The classification of complete minimal surfaces in '''R'''<sup>3</sup> with total curvature greater than <math>-8\\pi</math> |journal=Duke Math. J. |volume=48 |year=1981 |pages=523–535 |issue=3 |doi=10.1215/S0012-7094-81-04829-8 |mr=630583 |zbl=0472.53010}}</ref>\n\nA unique solution always exists. It can be viewed as a [[Cauchy problem]] for minimal surfaces, allowing one to find a surface if a geodesic, asymptote or lines of curvature is known. In particular, if the curve is planar and geodesic, then the plane of the curve will be a symmetry plane of the surface.<ref>Björling problem. Encyclopedia of Mathematics. URL: http://www.encyclopediaofmath.org/index.php?title=Bj%C3%B6rling_problem&oldid=23196</ref>\n\n==References==\n\n{{reflist|30em}}\n\n==External image galleries==\n\n* Björling Surfaces, at the Indiana Minimal Surface Archive: http://www.indiana.edu/~minimal/archive/Bjoerling/index.html\n\n{{DEFAULTSORT:Bjorling problem}}\n[[Category:Minimal surfaces]]\n[[Category:Differential geometry]]"
    },
    {
      "title": "Bour's minimal surface",
      "url": "https://en.wikipedia.org/wiki/Bour%27s_minimal_surface",
      "text": "[[File:Bour's Surface 01.jpg|thumb|Bour's surface.]]\n[[File:Bour's Surface annulus.jpg|thumb|Bour's surface, leaving out the points with ''r''&nbsp;<&nbsp;0.5 to show the self-crossings more clearly.]]\n\nIn mathematics, '''Bour's minimal surface''' is a two-dimensional [[minimal surface]],  embedded with self-crossings into three-dimensional [[Euclidean space]]. It is named after [[Edmond Bour]], whose work on minimal surfaces won him the 1861 mathematics prize of the French Academy of Sciences.<ref>{{MacTutor|id=Bour|title=Edmond Bour}}.</ref>\n\n==Description==\nBour's surface crosses itself on three coplanar rays, meeting at equal angles at the origin of the space. The rays partition the surface into six sheets, topologically equivalent to half-planes; three sheets lie in the halfspace above the plane of the rays, and three below. Four of the sheets are mutually tangent along each ray.\n\n==Equation==\nThe points on the surface may be parameterized in [[polar coordinates]] by a pair of numbers (''r'',&theta;). Each such pair corresponds to a point in three dimensions according to the [[parametric equation]]s<ref>Weisstein, Eric W. \"Bour's Minimal Surface.\" From MathWorld--A Wolfram Web Resource. http://mathworld.wolfram.com/BoursMinimalSurface.html</ref> \n:<math>x(r,\\theta) = r\\cos(\\theta) - (1/2)r^2 \\cos(2\\theta)</math>\n:<math>y(r,\\theta) = -r\\sin(\\theta)(r \\cos(\\theta) + 1)</math>\n:<math>z(r,\\theta) = (4/3)r^{3/2} \\cos(3\\theta/2).</math>\nThe surface can also be expressed as the solution to a polynomial equation of order 16 in the [[Cartesian coordinate]]s of the three-dimensional space.\n\n==Properties==\nThe [[Weierstrass–Enneper parameterization]], a method for turning certain pairs of functions over the [[complex number]]s into minimal surfaces, produces this surface for the two functions <math>f(z)=1, g(z)=\\sqrt{z}</math>. It was proved by Bour that surfaces in this family are [[Developable surface|developable]] onto a [[surface of revolution]].<ref>Ulrich Dierkes, Stefan Hildebrandt, Friedrich Sauvigny, Minimal Surfaces, Volume 1. Springer 2010</ref>\n\n== References ==\n{{reflist}}\n\n{{Minimal surfaces}}\n\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Bryant surface",
      "url": "https://en.wikipedia.org/wiki/Bryant_surface",
      "text": "In [[Riemannian geometry]], a '''Bryant surface''' is a 2-dimensional surface embedded in 3-dimensional [[hyperbolic space]] with constant [[mean curvature]] equal to 1.<ref>{{citation\n | last1 = Collin | first1 = Pascal\n | last2 = Hauswirth | first2 = Laurent\n | last3 = Rosenberg | first3 = Harold\n | arxiv = math/0105265\n | doi = 10.2307/2661364\n | issue = 3\n | journal = Annals of Mathematics\n | mr = 1836284\n | pages = 623–659\n | series = Second Series\n | title = The geometry of finite topology Bryant surfaces\n | volume = 153\n | year = 2001}}.</ref><ref>{{citation\n | last = Rosenberg | first = Harold\n | contribution = Bryant surfaces\n | doi = 10.1007/978-3-540-45609-4_3\n | location = Berlin\n | mr = 1901614\n | pages = 67–111\n | publisher = Springer\n | series = Lecture Notes in Math.\n | title = The global theory of minimal surfaces in flat spaces (Martina Franca, 1999)\n | volume = 1775\n | year = 2002}}.</ref>  These surfaces take their name from the geometer [[Robert Bryant (mathematician)|Robert Bryant]], who proved that every [[simply-connected]] [[minimal surface]] in 3-dimensional [[Euclidean space]] is [[Isometry|isometric]] to a Bryant surface by a [[Holomorphic function|holomorphic]] parameterization analogous to the (Euclidean) [[Weierstrass–Enneper parameterization]].<ref>{{citation\n | last = Bryant | first = Robert L.\n | issue = 154-155\n | journal = Astérisque\n | mr = 955072\n | pages = 12, 321–347, 353 (1988)\n | title = Surfaces of mean curvature one in hyperbolic space\n | year = 1987}}.</ref>\n\n==References==\n{{reflist}}\n\n[[Category:Hyperbolic geometry]]\n[[Category:Riemannian geometry]]\n[[Category:Minimal surfaces]]\n\n\n{{differential-geometry-stub}}"
    },
    {
      "title": "Catalan's minimal surface",
      "url": "https://en.wikipedia.org/wiki/Catalan%27s_minimal_surface",
      "text": "{{About|the minimal surface|the ruled surfaces|Catalan surface}}\n\n[[File:Catalan's Minimal Surface.png|thumb|Catalan's minimal surface.]]\n\nIn [[differential geometry]], '''Catalan's minimal surface''' is a [[minimal surface]] originally studied by [[Eugène Charles Catalan]] in 1855.<ref>Catalan, E. \"Mémoire sur les surfaces dont les rayons de courbures en chaque point, sont égaux et les signes contraires.\" Comptes rendus de l'Académie des Sciences de Paris 41, 1019–1023, 1855.</ref>\n\nIt has the special property of being the minimal surface that contains a [[cycloid]] as a [[geodesic]]. It is also swept out by a family of parabolae.<ref>Ulrich Dierkes, Stefan Hildebrandt, Friedrich Sauvigny, Minimal Surfaces, Volume 1. Springer 2010</ref>\n\nThe surface has parametric equation:<ref>Gray, A. \"Catalan's Minimal Surface.\" Modern Differential Geometry of Curves and Surfaces with Mathematica, 2nd ed. Boca Raton, Florida: CRC Press, pp. 692–693, 1997</ref>\n:<math>\\begin{align}\nx(u,v) &= u - \\sin(u)\\cosh(v)\\\\\ny(u,v) &= 1 - \\cos(u)\\cosh(v)\\\\\nz(u,v) &= 4 \\sin(u/2) \\sinh(v/2)\n\\end{align}</math>\n\n== External links ==\n*  Weisstein, Eric W. \"Catalan's Surface.\" From MathWorld—A Wolfram Web Resource. http://mathworld.wolfram.com/CatalansSurface.html\n*  Weiqing Gu, The Library of Surfaces. http://www.math.hmc.edu/~gu/curves_and_surfaces/surfaces/catalan.html\n\n==References==\n{{reflist}}\n\n{{Minimal surfaces}}\n\n{{DEFAULTSORT:Catalans minimal surface}}\n[[Category:Minimal surfaces]]\n[[Category:Differential geometry]]"
    },
    {
      "title": "Catenoid",
      "url": "https://en.wikipedia.org/wiki/Catenoid",
      "text": "[[Image:Catenoid.svg|thumb|right|alt=three-dimensional diagram of a catenoid|A catenoid]]\n[[Image:Catenoid.gif|thumb|right|alt=animation of a catenary sweeping out the shape of a catenoid as it rotates about a central point|A catenoid obtained from the rotation of a catenary]]\n\nA '''catenoid''' is a type of surface, arising by rotating a [[catenary]] curve about an axis.<ref>{{cite book|last1=Dierkes|first1=Ulrich|last2=Hildebrandt|first2=Stefan|last3=Sauvigny|first3=Friedrich|title=Minimal Surfaces|date=2010|publisher=[[Springer Science & Business Media]]|isbn=9783642116988|page=141|url=https://books.google.com/books?id=9YhBOg6vO-EC&pg=PA141|language=en}}</ref> It is a [[minimal surface]], meaning that it occupies the least area when bounded by a closed space.<ref name=Gullberg>{{cite book|last1=Gullberg|first1=Jan|title=Mathematics: From the Birth of Numbers|date=1997|publisher=[[W. W. Norton & Company]]|isbn=9780393040029|page=538|url=https://books.google.com/books?id=E09fBi9StpQC&pg=PA538|language=en}}</ref> It was formally described in 1744 by the mathematician [[Leonhard Euler]].\n\n[[Soap film]] attached to twin circular rings will take the shape of a catenoid.<ref name=Gullberg/> Because they are members of the same [[associate family]] of surfaces, a catenoid can be bent into a portion of a [[helicoid]], and vice versa.\n\n==Geometry==\nThe catenoid was the first non-trivial minimal [[surface (topology)|surface]] in 3-dimensional Euclidean space to be discovered apart from the [[plane (geometry)|plane]]. The catenoid is obtained by rotating a catenary about its [[Directrix (conic section)|directrix]].<ref name=Gullberg/> It was found and proved to be minimal by [[Leonhard Euler]] in 1744.<ref>{{cite book|last1=Helveticae|first1=Euler, Leonhard |editor= Carathëodory Constantin |title=Methodus inveniendi lineas curvas: maximi minimive proprietate gaudentes sive solutio problematis isoperimetrici latissimo sensu accepti |date=1952 |orig-year=reprint of 1744 edition |publisher=Springer Science & Business Media  |isbn=3-76431-424-9 |language=Latin |url=https://books.google.com/books/about/Methodus_inveniendi_lineas_curvas_maximi.html?id=zNDdVFZalSAC}}</ref><ref name=Colding06>{{cite journal|last1=Colding|first1=T. H.|last2=Minicozzi|first2=W. P.|title=Shapes of embedded minimal surfaces|journal=Proceedings of the National Academy of Sciences|date=17 July 2006|volume=103|issue=30|pages=11106–11111|doi=10.1073/pnas.0510379103|pmc=1544050}}</ref>\n\nEarly work on the subject was published also by [[Jean Baptiste Meusnier]].<ref name=salvert>{{cite book|url=https://archive.org/details/mmoiresurlathor00salvgoog|format=PDF|last1=Meusnier|first1=J. B|title=Mémoire sur la courbure des surfaces|trans-title=Memory on the curvature of surfaces.|date=1881|publisher=F. Hayez, Imprimeur De L'Acdemie Royale De Belgique|location=Bruxelles|language=French|isbn=9781147341744|pages=477–510}}</ref><ref name=Colding06/>{{rp|11106}} There are only two [[minimal surfaces of revolution]] ([[surfaces of revolution]] which are also minimal surfaces): the [[plane (geometry)|plane]] and the catenoid.<ref>{{cite web|title=Catenoid|url=http://mathworld.wolfram.com/Catenoid.html|website=Wolfram MathWorld|accessdate=15 January 2017|language=en}}</ref>\n\nThe catenoid may be defined by the following parametric equations:\n\n:<math>x=c \\cosh \\frac{v}{c} \\cos u</math>\n\n:<math>y=c \\cosh \\frac{v}{c} \\sin u</math>\n\n:<math>z=v</math>\n\n:where <math>u \\in [-\\pi, \\pi)</math> and <math>v \\in \\mathbb{R}</math> and <math>c</math> is a non-zero real constant.\n\nIn cylindrical coordinates:\n\n:<math>\\rho =c \\cosh \\frac{z}{c}</math>\n\n:where <math>c</math> is a real constant.\n\nA physical model of a catenoid can be formed by dipping two [[circle|circular]] rings into a soap solution and slowly drawing the circles apart.\n\nThe catenoid may be also defined approximately by the [[Stretched grid method]] as a facet 3D model.\n\n== Helicoid transformation ==\n\n[[Image:helicatenoid.gif|thumb|right|256px|alt=Continuous animation showing a helicoid deforming into a catenoid and back to a helicoid|Deformation of a [[helicoid]] into a catenoid]]\n\nBecause they are members of the same [[associate family]] of surfaces, one can bend a catenoid into a portion of a [[helicoid]] without stretching.  In other words, one can make a (mostly) [[continuous function|continuous]] and [[Isometry|isometric]] deformation of a catenoid to a portion of the [[helicoid]] such that every member of the deformation family is [[Minimal surface|minimal]] (having a [[mean curvature]] of zero).  A [[Parametric equation|parametrization]] of such a deformation is given by the system\n\n:<math>x(u,v) = \\cos \\theta \\,\\sinh v \\,\\sin u + \\sin \\theta \\,\\cosh v \\,\\cos u</math>\n\n:<math>y(u,v) = -\\cos \\theta \\,\\sinh v \\,\\cos u + \\sin \\theta \\,\\cosh v \\,\\sin u</math>\n\n:<math>z(u,v) = u \\cos \\theta + v \\sin \\theta </math>\n\n:for <math>(u,v) \\in (-\\pi, \\pi] \\times (-\\infty, \\infty)</math>, with deformation parameter <math>-\\pi < \\theta \\le \\pi</math>,\n\nwhere \n<math>\\theta = \\pi</math> corresponds to a right-handed helicoid, \n<math>\\theta = \\pm \\pi / 2</math> corresponds to a catenoid, and\n<math>\\theta = 0</math> corresponds to a left-handed helicoid.\n\n==References==\n{{reflist}}\n\n==Further reading==\n* {{cite book |last1=Krivoshapko |first1=Sergey |last2=Ivanov |first2=V. N. |title=Encyclopedia of Analytical Surfaces |date=2015 |publisher=Springer |isbn=9783319117737 |chapter=Minimal Surfaces |chapter-url=https://books.google.com/books?id=cXTdBgAAQBAJ&pg=PA427 |language=en}}\n\n==External links==\n* {{springer|title=Catenoid|id=p/c020800}}\n* [http://www.princeton.edu/~rvdb/WebGL/catenoid.html Catenoid - WebGL model]\n* [http://posner.library.cmu.edu/Posner/books/book.cgi?call=517.4_E88M_1744 Euler's text describing the catenoid] at Carnegie Mellon University\n\n{{Minimal surfaces}}\n\n[[Category:Geometry]]\n[[Category:Minimal surfaces]]\n\n[[de:Minimalfläche#Das Katenoid]]"
    },
    {
      "title": "Chen–Gackstatter surface",
      "url": "https://en.wikipedia.org/wiki/Chen%E2%80%93Gackstatter_surface",
      "text": "[[File:Chen-Gackstatter-Thayer surfaces.png|thumb|The first nine Chen–Gackstatter surfaces.]]\n\nIn [[differential geometry]], the '''Chen–Gackstatter surface family''' (or the '''Chen–Gackstatter–Thayer''' surface family) is a family of [[minimal surfaces]] that generalize the [[Enneper surface]] by adding handles, giving it nonzero [[Genus (mathematics)|topological genus]].<ref>{{citation|last1=Chen|first1=Chi Cheng|last2=Gackstatter|first2=Fritz|title=Elliptische und hyperelliptische Funktionen und vollständige Minimalflächen vom Enneperschen Typ|journal=Math. Ann.|volume=259|pages=359–369|year=1982|url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=GDZPPN002321963&IDDOC=129137|doi=10.1007/bf01456948}}</ref><ref name=\"thayer\">{{citation|first=Edward C.|last=Thayer|title=Higher-genus Chen–Gackstatter surfaces and the Weierstrass representation for surfaces of infinite genus|journal=Experiment. Math.|volume=4|issue=1|year=1995|pages=19–39|url=http://projecteuclid.org/euclid.em/1062621140|doi=10.1080/10586458.1995.10504305}}</ref>\n\nThey are not [[Topological embedding|embedded]], and have Enneper-like [[End (topology)|ends]]. The members <math>M_{ij}</math> of the family are indexed by the number of extra handles ''i'' and the winding number of the Enneper end; the total genus is ''ij'' and the total [[Gaussian curvature]] is <math>-4\\pi(i+1)j</math>.<ref>{{mathworld|author=Barile, Margherita|title=Chen–Gackstatter Surfaces|urlname=Chen-GackstatterSurfaces}}</ref> It has been shown that <math>M_{11}</math> is the only  genus one orientable complete minimal surface of total curvature <math>-8\\pi</math>.<ref>{{citation|last=López|first=F. J.|title=The classification of complete minimal surfaces with total curvature greater than &minus;12''π''|journal=Trans. Amer. Math. Soc.|volume=334|pages=49–73|year=1992|doi=10.1090/s0002-9947-1992-1058433-9}}.</ref>\n\nIt has been conjectured that continuing to add handles to the surfaces will in the limit converge to the [[Scherk_surface#Scherk.27s_second_surface|Scherk's second surface]] (for ''j''&nbsp;=&nbsp;1) or the [[saddle tower]] family for ''j''&nbsp;>&nbsp;1.<ref name=\"thayer\" />\n\n==References==\n\n{{reflist}}\n\n==External links==\n* The Chen–Gackstatter Thayer Surfaces at the Scientific Graphics Project [https://web.archive.org/web/20160304054125/https://secure.msri.org/about/sgp/jim/geom/minimal/library/chengack/index.html]\n* Chen–Gackstatter Surface in the Minimal Surface Archive [http://www.indiana.edu/~minimal/archive/Tori/Tori/Chen-Gackstatter/web/index.html]\n* Xah Lee's page on Chen–Gackstatter [http://xahlee.info/surface/chen_gackstatter/chen_gackstatter.html]\n\n{{Minimal surfaces}}\n\n{{DEFAULTSORT:Chen-Gackstatter surface}}\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Costa's minimal surface",
      "url": "https://en.wikipedia.org/wiki/Costa%27s_minimal_surface",
      "text": "[[File:Costa's minimal surface (200x150).ogv|thumbtime=0 |thumb |200px |alt=Computer rendering of Costa's minimal surface.|Costa's minimal surface, cropped by a sphere. [[:File:Costa's minimal surface.ogv|Higher resolution video]]]]\n\nIn [[mathematics]], '''Costa's minimal surface,''' is an embedded [[minimal surface]] discovered in 1982 by the [[Brazil]]ian [[mathematician]] [[Celso Costa|Celso José da Costa]]. It is also a surface of finite topology, which means that it can be formed by puncturing a [[compact space|compact]] surface. Topologically, it is a thrice-punctured [[torus]].\n\nUntil its discovery, the [[plane (geometry)|plane]], [[helicoid]] and the [[catenoid]] were believed to be the only embedded minimal surfaces that could be formed by puncturing a compact surface. The Costa surface evolves from a torus, which is deformed until the planar [[End (topology)|end]] becomes catenoidal. Defining these surfaces on rectangular tori of arbitrary dimensions yields the Costa surface. Its discovery triggered research and discovery into several new surfaces and open [[conjectures]] in topology.\n\nThe Costa surface can be described using the [[Weierstrass zeta function|Weierstrass zeta]] and the [[Weierstrass elliptic function|Weierstrass elliptic]] [[function (mathematics)|functions]].\n\n==References==\n* {{cite book\n | author = Costa, Celso José da\n | title = Imersões mínimas completas em <math>\\mathbb{R}^3</math> de gênero um e curvatura total finita\n | year = 1982\n }} ''Ph.D. Thesis, IMPA, Rio de Janeiro, Brazil.''\n* {{cite book\n | author = Costa, Celso José da\n | title = Example of a complete minimal immersion in <math>\\mathbb{R}^3</math> of genus one and three embedded ends\n | year = 1984\n }} ''Bol. Soc. Bras. Mat. 15, 47–54.''\n* {{cite web\n | author = Weisstein, Eric W.\n | title = Costa Minimal Surface.\n | url=http://mathworld.wolfram.com/CostaMinimalSurface.html\n | accessdate=2006-11-19\n }} ''From MathWorld--A Wolfram Web Resource.''\n\n{{Minimal surfaces}}\n\n[[Category:Differential geometry]]\n[[Category:Minimal surfaces]]\n[[Category:Articles containing video clips]]\n\n\n{{topology-stub}}"
    },
    {
      "title": "Double bubble conjecture",
      "url": "https://en.wikipedia.org/wiki/Double_bubble_conjecture",
      "text": "[[File:Ggb in soap bubble 1.jpg|thumb|upright=1.35|A double bubble. Note that the surface separating the small lower bubble from the large bubble bulges into the large bubble.]]\nIn the mathematical theory of [[minimal surfaces]], the '''double bubble conjecture''' states that the shape that encloses and separates two given [[volume]]s and has the minimum possible [[surface area]] is a ''standard double bubble'' — three spherical surfaces meeting at angles of 2{{pi}}/3 on a common circle. It is now a [[theorem]], as a proof of it was published in 2002.<ref name=\"hmrr02\"/><ref>{{citation\n | last = Morgan | first = Frank | authorlink = Frank Morgan (mathematician)\n | contribution = Chapter 14. Proof of Double Bubble Conjecture\n | edition = 4th\n | publisher = Academic Press\n | title = Geometric Measure Theory: A Beginner's Guide\n | year = 2009}}.</ref>\n\n==The conjecture==\nAccording to [[Plateau's laws]], the minimum area shape that encloses any volume or set of volumes must take a form commonly seen in [[soap bubble]]s in which surfaces of constant [[mean curvature]] meet in threes, forming [[dihedral angle]]s of 2{{pi}}/3.<ref>{{citation\n | last = Taylor | first = Jean E. | authorlink = Jean Taylor\n | issue = 3\n | journal = [[Annals of Mathematics]] | series = 2nd Ser.\n | mr = 0428181\n | pages = 489–539\n | title = The structure of singularities in soap-bubble-like and soap-film-like minimal surfaces\n | volume = 103\n | year = 1976 | doi=10.2307/1970949| jstor = 1970949 }}.</ref> In a ''standard double bubble'', these surfaces are patches of [[sphere]]s, and the curve where they meet is a circle. When the two enclosed volumes are different from each other, there are three spherical surfaces, two on the outside of the double bubble and one in the interior, separating the two volumes from each other; the radii of the spheres is inversely proportional to the pressure differences between the volumes they separate, according to the [[Young–Laplace equation]].<ref>{{citation\n | last = Isenberg | first = Cyril | authorlink = Cyril Isenberg\n | contribution = Chapter 5. The Laplace–Young Equation\n | publisher = Dover\n | title = The Science of Soap Films and Soap Bubbles\n | year = 1978}}.</ref> When the two volumes are equal, the middle surface is instead a flat [[Disk (mathematics)|disk]], which can be interpreted as a patch of an infinite-radius sphere.\n\nThe double bubble conjecture states that, for any two volumes, the standard double bubble is the minimum area shape that encloses them; no other set of surfaces encloses the same amount of space with less total area.\n\nThe same fact is also true for the minimum-length set of curves in the [[Euclidean plane]] that encloses a given pair of areas,<ref name=\"abfhz93\">{{citation\n | last1 = Alfaro | first1 = M.\n | last2 = Brock | first2 = J.\n | last3 = Foisy | first3 = J.\n | last4 = Hodges | first4 = N.\n | last5 = Zimba | first5 = J.\n | issue = 1\n | journal = [[Pacific Journal of Mathematics]]\n | mr = 1211384\n | pages = 47–59\n | title = The standard double soap bubble in '''R'''<sup>2</sup> uniquely minimizes perimeter\n | url = http://projecteuclid.org/euclid.pjm/1102634378\n | volume = 159\n | year = 1993 | doi=10.2140/pjm.1993.159.47}}.</ref> and it can be generalized to any higher dimension.<ref>{{citation\n | last = Reichardt | first = Ben W.\n | arxiv = 0705.1601\n | doi = 10.1007/s12220-007-9002-y\n | issue = 1\n | journal = Journal of Geometric Analysis\n | mr = 2365672\n | pages = 172–191\n | title = Proof of the double bubble conjecture in R<sup>n</sup>\n | volume = 18\n | year = 2008}}.</ref>\n\n==History==\nThe [[isoperimetric inequality]] for three dimensions states that the shape enclosing the minimum single volume for its surface area is the sphere; it was formulated by [[Archimedes]] but not proven rigorously until the 19th century, by [[Hermann Schwarz]].\nIn the 19th century, [[Joseph Plateau]] studied the double bubble, and the truth of the double bubble conjecture was assumed without proof by [[C. V. Boys]] in his 1896 book on soap bubbles.<ref name=\"m04\">{{citation\n | last = Morgan | first = Frank | authorlink = Frank Morgan (mathematician)\n | editor-last = Hardt | editor-first = Robert\n | contribution = Proof of the double bubble conjecture\n | mr = 2108996\n | pages = 59–77\n | publisher = American Mathematical Society\n | series = Student Mathematical Library\n | title = Six Themes on Variation\n | volume = 26\n | year = 2004}}. Revised version of an article initially appearing in the ''[[American Mathematical Monthly]]'' (2001), {{doi|10.2307/2695380}}, {{MR|1834699}}.</ref><ref>{{citation\n | last = Boys | first = C. V. | authorlink = C. V. Boys\n | publisher = Society for Promoting Christian Knowledge\n | title = Soap-Bubbles And The Forces Which Mould Them\n | url = http://www.gutenberg.org/ebooks/33370\n | year = 1896}}.</ref>\n\nIn 1991, Joel Foisy, an undergraduate student at [[Williams College]], was the leader of a team of undergraduates that proved the two-dimensional analogue of the double bubble conjecture.<ref name=\"abfhz93\"/><ref name=\"m04\"/> In his undergraduate thesis, Foisy was the first to provide a precise statement of the three-dimensional double bubble conjecture, but he was unable to prove it.<ref name=\"guardian\"/>\n\nA proof for the restricted case of the double bubble conjecture, for two equal volumes, was announced by [[Joel Hass]] and Roger Schlafly in 1995, and published in 2000.<ref>{{citation|title=Toil and trouble over double bubbles|journal=[[Science News]]|date=August 12, 1995|volume=148|issue=7|pages=101–102|first=Ivars|last=Peterson|url=http://www.sciencenews.org/pages/pdfs/data/1995/148-07/14807-04.pdf|authorlink=Ivars Peterson|doi=10.2307/3979333|jstor=3979333}}.</ref><ref name=\"hs00\">{{citation\n | last1 = Hass | first1 = Joel | author1-link = Joel Hass\n | last2 = Schlafly | first2 = Roger\n | doi = 10.2307/121042\n | issue = 2\n | journal = [[Annals of Mathematics]] | series = 2nd Ser.\n | mr = 1765704\n | pages = 459–515\n | title = Double bubbles minimize\n | volume = 151\n | year = 2000| arxiv = math/0003157| jstor = 121042 | bibcode = 2000math......3157H }}. Previously announced in ''Electronic Research Announcements of the American Mathematical Society'', 1995, {{doi|10.1090/S1079-6762-95-03001-0}}.</ref> The proof of the full conjecture by [[Michael Hutchings (mathematician)|Hutchings]], [[Frank Morgan (mathematician)|Morgan]], Ritoré, and Ros was announced in 2000 and published in 2002.<ref name=\"hmrr02\">{{citation\n | last1 = Hutchings | first1 = Michael | author1-link = Michael Hutchings (mathematician)\n | last2 = Morgan | first2 = Frank | author2-link = Frank Morgan (mathematician)\n | last3 = Ritoré | first3 = Manuel\n | last4 = Ros | first4 = Antonio\n | doi = 10.2307/3062123\n | issue = 2\n | journal = [[Annals of Mathematics]] | series = 2nd Ser.\n | mr = 1906593\n| pages = 459–489\n | title = Proof of the double bubble conjecture\n | volume = 155\n | year = 2002| arxiv = math/0406017| jstor = 3062123 }}.</ref><ref name=\"guardian\">{{citation|title=Blowing out the bubble reputation: Four mathematicians have just cleaned up a long-standing conundrum set by soapy water, writes Keith Devlin|url=https://www.theguardian.com/science/2000/mar/23/technology1|date=22 March 2000|periodical=[[The Guardian]]}}.</ref><ref>{{citation|title=Mathematics: Why Double Bubbles Form the Way They Do|last= Cipra  |first= Barry A.  |author-link = Barry A. Cipra |url=http://math.berkeley.edu/~hutching/pub/db2ann/science_article.html|journal=[[Science (journal)|Science]]|volume=287|issue=5460|date=March 17, 2000|pages=1910–1912|doi=10.1126/science.287.5460.1910a}}</ref>\n\n==The proof==\nA lemma of [[Brian White (mathematician)|Brian White]] shows that the minimum area double bubble must be a [[surface of revolution]]. For, if not, it would be possible to find two orthogonal planes that bisect both volumes, replace surfaces in two of the four quadrants by the reflections of the surfaces in the other quadrants, and then smooth the singularities at the reflection planes, reducing the total area.<ref name=\"m04\"/> Based on this lemma, Michael Hutchings was able to restrict the possible shapes of non-standard optimal double bubbles, to consist of layers of toroidal tubes.<ref>{{citation\n | last = Hutchings | first = Michael | authorlink = Michael Hutchings (mathematician)\n | doi = 10.1007/BF02921724\n | issue = 2\n | journal = Journal of Geometric Analysis\n | mr = 1646776\n | pages = 285–304\n | title = The structure of area-minimizing double bubbles\n | volume = 7\n | year = 1997}}.</ref>\n\nAdditionally, Hutchings showed that the number of toroids in a non-standard but minimizing double bubble could be bounded by a function of the two volumes. In particular, for two equal volumes, the only possible nonstandard double bubble consists of a single central bubble with a single toroid around its equator. Based on this simplification of the problem, [[Joel Hass]] and Roger Schlafly were able to reduce the proof of this case of the double bubble conjecture to a large computerized case analysis, taking 20 minutes on a 1995 PC.<ref name=\"m04\"/><ref name=\"hs00\"/>\n\nThe eventual proof of the full double bubble conjecture also uses Hutchings' method to reduce the problem to a finite case analysis, but it avoids the use of computer calculations, and instead works by showing that all possible nonstandard double bubbles are unstable: they can be perturbed by arbitrarily small amounts to produce another solution with lower cost. The perturbations needed to prove this result are a carefully chosen set of rotations.<ref name=\"m04\"/>\n\n==Related problems==\n[[John M. Sullivan (mathematician)|John M. Sullivan]] has conjectured that, for any dimension ''d'', the minimum enclosure of up to ''d''&nbsp;+&nbsp;1 volumes has the form of a [[stereographic projection]] of a [[simplex]].<ref name=\"s99\">{{citation\n | last = Sullivan | first = John M. | authorlink = John M. Sullivan (mathematician)\n | editor1-last = Sadoc | editor1-first = Jean-François\n | editor2-last = Rivier | editor2-first = Nicolas\n | contribution = The geometry of bubbles and foams\n | location = Dordrecht\n | mr = 1688327\n | pages = 379–402\n | publisher = Kluwer Acad. Publ.\n | series = NATO Adv. Sci. Inst. Ser. E Appl. Sci.\n | title = Foams and Emulsions: Proc. NATO Advanced Study Inst. on Foams and Emulsions, Emulsions and Cellular Materials, Cargèse, Corsica, 12–24 May, 1997\n | volume = 354\n | year = 1999}}.</ref> In particular, in this case, all boundaries between bubbles would be patches of spheres. The special case of this conjecture for three bubbles in two dimensions has been proven; in this case, the three bubbles are formed by six circular arcs and straight line segments, meeting in the same combinatorial pattern as the edges of a [[tetrahedron]].<ref>{{citation\n | last = Wichiramala | first = Wacharin\n | doi = 10.1515/crll.2004.011\n | journal = [[Journal für die Reine und Angewandte Mathematik]]\n | mr = 2038304\n | pages = 1–49\n | title = Proof of the planar triple bubble conjecture\n | volume = 567\n | issue = 567\n | year = 2004}}.</ref> However, numerical experiments have shown that for six or more volumes in three dimensions, some of the boundaries between bubbles may be non-spherical.<ref name=\"s99\"/>\n\nFor an infinite number of equal areas in the plane, the minimum-length set of curves separating these areas is the [[hexagonal tiling]], familiar from its use by bees to form [[honeycomb]]s.<ref>{{citation\n | last = Hales | first = Thomas C. | authorlink = Thomas Callister Hales\n | arxiv = math.MG/9906042\n | issue = 1\n | journal = [[Discrete and Computational Geometry]]\n | mr = 1797293\n | pages = 1–22\n | title = The honeycomb conjecture\n | volume = 25\n | year = 2001\n | doi=10.1007/s004540010071}}.</ref> For the same problem in three dimensions, the optimal solution is not known; [[William Thomson, 1st Baron Kelvin|Lord Kelvin]] conjectured that it was given by a structure combinatorially equivalent to the [[bitruncated cubic honeycomb]], but this conjecture was disproved by the discovery of the [[Weaire–Phelan structure]], a partition of space into equal volume cells of two different shapes using a smaller average amount of surface area per cell.<ref>{{citation\n | last1 = Weaire | first1 = Denis | author1-link = Denis Weaire\n | last2 = Phelan | first2 = Robert\n | doi = 10.1080/09500839408241577\n | journal = Philosophical Magazine Letters\n | pages = 107–110\n | title = A counter-example to Kelvin's conjecture on minimal surfaces\n | volume = 69\n | issue = 2 | year = 1994| bibcode = 1994PMagL..69..107W }}.</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n*{{mathworld|title=Double Bubble|urlname=DoubleBubble}}\n\n[[Category:Minimal surfaces]]\n[[Category:Theorems]]\n[[Category:Bubbles (physics)]]"
    },
    {
      "title": "Enneper surface",
      "url": "https://en.wikipedia.org/wiki/Enneper_surface",
      "text": "[[File:EnneperSurfaceAnimated.gif|frame|''Figure 1. A portion of the Enneper surface'']]\n\nIn [[mathematics]], in the fields of [[differential geometry]] and [[algebraic geometry]], the '''Enneper surface''' is a self-intersecting surface that can be described [[parameter|parametrically]] by:\n: <math> x = u(1 - u^2/3 + v^2)/3,\\ </math> \n: <math> y = -v(1 - v^2/3 + u^2)/3,\\ </math> \n: <math> z = (u^2 - v^2)/3.\\ </math> \nIt was introduced by [[Alfred Enneper]] 1864 in connection with [[minimal surface]] theory.<ref>J.C.C. Nitsche, \"Vorlesungen über Minimalflächen\" , Springer (1975)</ref><ref>[http://www.ugr.es/~fmartin/dvi/survey.pdf Francisco J. López, Francisco Martín, Complete minimal surfaces in R3]</ref><ref name=\"dierkes\">Ulrich Dierkes, Stefan Hildebrandt, Friedrich Sauvigny (2010). Minimal Surfaces. Berlin Heidelberg: Springer. {{ISBN|978-3-642-11697-1}}.</ref><ref>{{MathWorld|title=Enneper's Minimal Surface|urlname=EnnepersMinimalSurface}}</ref>\n\nThe [[Weierstrass–Enneper parameterization]] is very simple, <math>f(z)=1, g(z)=z</math>, and the real parametric form can easily be calculated from it. The surface is [[Associate family|conjugate]] to itself.\n\nImplicitization methods of [[algebraic geometry]] can be used to find out that the points in the Enneper surface given above satisfy the degree-9 [[polynomial]] equation\n: <math>64 z^9 - 128 z^7 + 64 z^5 - 702 x^2 y^2 z^3 - 18 x^2 y^2 z + 144 (y^2 z^6 - x^2 z^6)\\ </math> \n: <math>{} + 162 (y^4 z^2 - x^4 z^2) + 27 (y^6 - x^6) + 9 (x^4 z + y^4 z) + 48 (x^2 z^3 + y^2 z^3)\\ </math> \n: <math>{} - 432 (x^2 z^5 + y^2 z^5) + 81 (x^4 y^2 - x^2 y^4) + 240 (y^2 z^4 - x^2 z^4) - 135 (x^4 z^3 + y^4 z^3) = 0.\\ </math>\n\nDually, the [[tangent plane]] at the point with given parameters is <math>a + b x + c y + d z = 0,\\ </math> where\n: <math>a = -(u^2 - v^2) (1 + u^2/3 + v^2/3),\\ </math>\n: <math>b = 6 u,\\ </math> \n: <math>c = 6 v,\\ </math> \n: <math>d = -3(1 - u^2 - v^2).\\ </math> \nIts coefficients satisfy the implicit degree-6 polynomial equation\n: <math>162 a^2 b^2 c^2 + 6 b^2 c^2 d^2 - 4 (b^6 + c^6) + 54 (a b^4 d - a c^4 d) + 81 (a^2 b^4 + a^2 c^4)\\ </math> \n: <math>{} + 4 (b^4 c^2 + b^2 c^4) - 3 (b^4 d^2 + c^4 d^2) + 36 (a b^2 d^3 - a c^2 d^3) = 0.\\ </math>\n\nThe [[Jacobian matrix and determinant|Jacobian]], [[Gaussian curvature]] and [[mean curvature]] are\n: <math> J = (1 + u^2 + v^2)^4/81,\\ </math> \n: <math> K = -(4/9)/J,\\ </math> \n: <math> H = 0.\\ </math>\nThe total curvature is <math>-4\\pi</math>. Osserman proved that a complete minimal surface in <math>\\R^3</math> with total curvature <math>-4\\pi</math> is either the [[catenoid]] or the Enneper surface.<ref>R. Osserman, A survey of Minimal Surfaces. Vol. 1, Cambridge Univ. Press, New York (1989).</ref>\n\nAnother property is that all bicubical minimal [[Bézier surface|Bézier surfaces]] are, up to an [[affine transformation]], pieces of the surface.<ref>Cosín, C., Monterde, Bézier surfaces of minimal area. In Computational Science — ICCS 2002, eds. J., Sloot, Peter, Hoekstra, Alfons, Tan, C., Dongarra, Jack. Lecture Notes in Computer Science 2330, Springer Berlin / Heidelberg, 2002. pp. 72-81 {{ISBN|978-3-540-43593-8}}</ref>\n\nIt can be generalized to higher order rotational symmetries by using the Weierstrass–Enneper parameterization <math>f(z)=1, g(z)=z^k</math> for integer  k>1.<ref name=\"dierkes\" /> It can also be generalized to higher dimensions; Enneper-like surfaces are known to exist in <math>\\R^n</math> for n up to 7.<ref>Jaigyoung Choe, On the existence of higher dimensional Enneper's surface, Commentarii Mathematici Helvetici 1996, Volume 71, Issue 1, pp 556-569</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n* {{springer|title=Enneper surface|id=p/e035710}}\n* http://www.math.hmc.edu/~gu/curves_and_surfaces/surfaces/enneper.html\n* https://secure.msri.org/about/sgp/jim/geom/minimal/library/ennepern/index.html\n\n{{DEFAULTSORT:Enneper Surface}}\n{{Minimal surfaces}}\n[[Category:Algebraic surfaces]]\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Gyroid",
      "url": "https://en.wikipedia.org/wiki/Gyroid",
      "text": "{{Other uses|Gyroid (crystallography)}}\n{{For|the creature|Animal Crossing (video game)}}\n[[Image:Gyroid surface with Gaussian curvature.png|thumb|right|A gyroid minimal surface, coloured to show the [[Gaussian curvature]] at each point]]\n[[File:Gyroid.GIF|thumb|right|Gyroid]]\n\nA '''gyroid''' is an infinitely connected [[Triply periodic minimal surface|triply periodic]] [[minimal surface]] discovered by [[Alan Schoen]] in 1970.<ref>{{cite web|first=Alan H. |last=Schoen |title=Infinite periodic minimal surfaces without self-intersections |year=1970 |url=https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19700020472_1970020472.pdf}}</ref><ref name=\"hoffman\">{{cite book|first=David |last=Hoffman |chapter=Computing Minimal Surfaces |title=Global Theory of Minimal Surfaces|series= Proceedings of the Clay Mathematics Institute |publisher=Mathematical Sciences Research Institute |location=Berkeley, California |date=June 25 – July 27, 2001 }}</ref>\n\n==History and properties==\n\nThe gyroid is the unique non-trivial embedded member of the [[associate family]] of the [[Schwarz minimal surface#Schwarz P .28.22Primitive.22.29|Schwarz P]] and [[Schwarz minimal surface#Schwarz D .28.22Diamond.22.29|D]] surfaces with angle of association approximately 38.01°.  The gyroid is similar to the [[Lidinoid]].  The gyroid was discovered in 1970 by NASA scientist [[Alan Schoen]].  He calculated the angle of association and gave a convincing demonstration pictures of intricate plastic models, but did not provide a proof of embeddedness. Schoen noted that the gyroid contains neither straight lines nor planar symmetries. Karcher<ref>{{Cite journal|last=Karcher|first=Hermann|title=The triply periodic minimal surfaces of Alan Schoen and their constant mean curvature companions|journal=Manuscripta Mathematica|language=en|volume=64|issue=3|pages=291–357|doi=10.1007/BF01165824|issn=0025-2611|year=1989}}</ref> gave a different, more contemporary treatment of the surface in 1989 using conjugate surface construction. In 1996 Große-Brauckmann and Wohlgemuth<ref>{{Cite journal|last=Große-Brauckmann|first=Karsten|last2=Meinhard|first2=Wohlgemuth|title=The gyroid is embedded and has constant mean curvature companions|journal=Calculus of Variations and Partial Differential Equations|language=en|volume=4|issue=6|pages=499–523|doi=10.1007/BF01261761|issn=0944-2669|year=1996}}</ref> proved that it is embedded, and in 1997 Große-Brauckmann provided CMC variants of the gyroid and made further numerical investigations about the volume fractions of the minimal and CMC gyroids.\n\nThe gyroid separates space into two oppositely congruent labyrinths of passages. The gyroid has [[space group]] ''Ia''{{overline|3}}''d''. Channels run through the gyroid labyrinths in the (100) and (111) directions; passages emerge at 70.5 degree angles to any given channel as it is traversed, the direction at which they do so gyrating down the channel, giving rise to the name \"gyroid\". One way to visualize the surface is to picture the “square catenoids” of the P surface (formed by two squares in parallel planes, with a nearly circular waist); rotation about the edges of the square generate the P surface. In the associate family, these square catenoids “open up” (similar to the way the catenoid “opens up” to a helicoid) to form gyrating ribbons, then finally become the [[Schwarzian derivative|Schwarz D]] surface.  For one value of the associate family parameter the gyrating ribbons lie in precisely the locations required to have an embedded surface.\n\nThe gyroid refers to the member that is in the associate family of the Schwarz P surface, but in fact the gyroid exists in several families that preserve various symmetries of the surface; a more complete discussion of families of these minimal surfaces appears in [[triply periodic minimal surface]]s.\n\nCuriously, like some other triply periodic minimal surfaces, the gyroid surface can be trigonometrically approximated by a short equation:\n:<math>\\sin x\\cos y+\\sin y\\cos z+\\sin z\\cos x=0</math>\n\nThe gyroid structure is closely related to the [[Laves graph|K<sub>4</sub> crystal (Laves' graph of girth ten)]].<ref>[[Toshikazu Sunada|T. Sunada]], Crystals that nature might miss creating, Notices of the AMS, 55(2008), 208-215</ref>\n\n==Applications==\nIn nature, self-assembled gyroid structures are found in certain surfactant or lipid [[mesophase]]s<ref>Longley, W. & McIntosh, T. J. 1983 A bicontinuous tetrahedral structure in a liquid crystalline lipid. Nature 303, 612–614.</ref> and block [[copolymer]]s. In the polymer phase diagram, the gyroid phase is between the lamellar and cylindrical phases. Such self-assembled polymer structures have found applications in experimental [[supercapacitors]],<ref>Wei D, Scherer MR, Bower C, Andrew P, Ryhänen T, Steiner U. A nanostructured electrochromic supercapacitor. Nano Lett. 2012 Apr 11;12(4):1857-62.</ref> solar cells<ref>Crossland EJ, Kamperman M, Nedelcu M, Ducati C, Wiesner U, Smilgies DM, Toombes GE, Hillmyer MA, Ludwigs S, Steiner U, Snaith HJ. A bicontinuous double gyroid hybrid solar cell. Nano Lett. 2009 Aug;9(8):2807-12.</ref> and nanoporous membranes.<ref>Li L, Schulte L, Clausen LD, Hansen KM, Jonsson GE, Ndoni S. Gyroid nanoporous membranes with tunable permeability. ACS Nano. 2011 Oct 25;5(10):7754-66. Epub 2011 Sep 14.</ref>\n\nGyroid membrane structures are occasionally found inside cells.<ref>S. Hyde, Z. Blum, T. Landh, S. Lidin, B.W. Ninham, S. Andersson, K. Larsson, The Language of Shape: The Role of Curvature in Condensed Matter: Physics, Chemistry and Biology, Elsevier, 1996</ref>\n\nGyroid structures have photonic [[band gap]]s that make them potential [[photonic crystals]].<ref>Martin-Moreno, L., Garcia-Vidal, F. J. & Somoza, A. M. Self-assembled triply periodic minimal surfaces as molds for photonic band gap materials. Phys. Rev. Lett. 83, 73–75. 1999</ref> Gyroid structures have been observed in biological [[structural coloration]] such as butterfly wing scales, inspiring work on [[Biomimicry|biomimetic materials]].<ref>Saranathan V, Osuji CO, Mochrie SG, Noh H, Narayanan S, Sandy A, Dufresne ER, Prum RO. Structure, function, and self-assembly of single network gyroid (I4132) photonic crystals in butterfly wing scales. Proc Natl Acad Sci U S A. 2010 Jun 29;107(26):11676-81.</ref><ref>Michielsen K, Stavenga DG. Jun 14. J R Soc Interface. 2008 Jan 6;5(18):85-94. Gyroid cuticular structures in butterfly wing scales: biological photonic crystals.</ref> The gyroid mitochondrial membranes in [[tree shrew]] cones might have an optical function.<ref>Zakaria Almsherqi, Felix Margadant and Yuru Deng. A look through ‘lens’ cubic mitochondria. Interface Focus (2012) 2, 539–545</ref>\n\nIn 2017, MIT researchers studied the possibility of using the gyroid shape to turn bi-dimensional materials, such as [[graphene]], into a three-dimensional structural material with low density yet high [[tensile strength]].<ref>[http://news.mit.edu/2017/3-d-graphene-strongest-lightest-materials-0106 Researchers design one of the strongest, lightest materials known], MIT news</ref>\n\nResearchers from [[Cambridge University]] have shown the controlled [[chemical vapor deposition]] of sub-60 nm graphene gyroids. These interwoven structures are one of the smallest free standing graphene 3D structures. They are conductive, mechanically stable and easily transferable, and of interest for a wide range of applications.<ref>{{cite journal|doi=10.1063/1.4997774|title=Chemical vapour deposition of freestanding sub-60 nm graphene gyroids|journal=Appl. Phys. Let.|volume=111|issue=25|pages=253103|year=2017|last1=Cebo|first1=T.|last2=Aria|first2=A. I.|last3=Dolan|first3=J.A.|last4=Weatherup|first4=R. S.|last5=Nakanishi|first5=K.|last6=Kidambi|first6=P. R. |last7=Divitini|first7=G.|last8=Ducati|first8=C.|last9=Steiner|first9=U.|last10=Hofmann|first10=S.|url=http://dspace.lib.cranfield.ac.uk/handle/1826/13396}}</ref>\n\nThe gyroid pattern has also found use in [[3D printing]] due to its high strength for lightweight internal structures and ease to print on a [[Fused deposition modeling|FDM 3d printer]].<ref>{{Cite web|url=https://mattshub.com/2018/03/15/gyroid-infill/|title=Introducing Gyroid Infill|last=Matt|first=~|date=2018-03-15|website=Matt's Hub|language=en|access-date=2019-01-05}}</ref>\n\n==References==\n\n{{reflist|30em}}\n\n==External links==\n* [http://schoengeometry.com/e-tpms.html Triply Periodic Minimal Surfaces at schoengeometry.com]\n* [http://mathworld.wolfram.com/Gyroid.html Gyroid] at [[MathWorld]]\n* [http://www.bathsheba.com/math/gyroid  Rotatable picture of a gyroid's period]\n* [http://www.indiana.edu/~minimal/archive/Triply/genus3/Gyroid%20small/web/index.html The gyroid at loomington's Virtual Minimal Surface Museum]\n* [https://books.google.com/books?id=eLBR7ONRzUMC&pg=PA92]\n\n{{Minimal surfaces}}\n\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Heegaard splitting",
      "url": "https://en.wikipedia.org/wiki/Heegaard_splitting",
      "text": "In the [[mathematics|mathematical]] field of [[geometric topology]], a '''Heegaard splitting''' {{IPAc-en|audio=En-heegaard.ogg|}} is a decomposition of a compact oriented [[3-manifold]] that results from dividing it into two [[handlebody|handlebodies]].\n\n==Definitions==\nLet ''V'' and ''W'' be [[handlebody|handlebodies]] of genus ''g'', and let ƒ be an orientation reversing [[homeomorphism]] from the [[Boundary (topology)|boundary]] of ''V'' to the boundary of ''W''.  By gluing ''V'' to ''W'' along ƒ we obtain the compact oriented [[3-manifold]]\n\n:<math> M = V \\cup_f W. </math>\n\nEvery closed, [[orientable]] three-manifold may be so obtained; this follows from deep results on the triangulability of three-manifolds due to [[Edwin E. Moise|Moise]].  This contrasts strongly with higher-dimensional manifolds which need not admit smooth or piecewise linear structures. Assuming smoothness the existence of a Heegaard splitting also follows from the work of [[Smale]] about handle decompositions from Morse theory.\n\nThe decomposition of ''M'' into two handlebodies is called a '''Heegaard splitting''', and their common boundary ''H'' is called the '''Heegaard surface''' of the splitting.  Splittings are considered up to [[Homotopy#Isotopy|isotopy]].\n\nThe gluing map ƒ need only be specified up to taking a double [[coset]] in the [[mapping class group]] of ''H''.  This connection with the mapping class group was first made by [[W. B. R. Lickorish]].\n\nHeegaard splittings can also be defined for compact 3-manifolds with boundary by replacing handlebodies with [[compression body|compression bodies]].  The gluing map is between the positive boundaries of the compression bodies.\n\nA closed curve is called '''essential''' if it is not homotopic to a point, a puncture, or a boundary component.<ref>{{cite book |last1= Farb |first1= B. |last2 = Margalit |first2 = D. |title=A Primer on Mapping Class Groups |publisher=Princeton University Press| page=22}}</ref>\n\nA Heegaard splitting is '''reducible''' if there is an essential simple closed curve <math>\\alpha</math> on ''H'' which bounds a disk in both ''V'' and in ''W''.  A splitting is '''irreducible''' if it is not reducible.  It follows from [[Heegaard splitting#Theorems|Haken's Lemma]] that in a [[irreducible manifold|reducible manifold]] every splitting is reducible.\n\nA Heegaard splitting is '''stabilized''' if there are essential simple closed curves <math>\\alpha</math> and <math>\\beta</math> on ''H'' where <math>\\alpha</math> bounds a disk in ''V'', <math>\\beta</math> bounds a disk in ''W'', and <math>\\alpha</math> and <math>\\beta</math> intersect exactly once.  It follows from [[Heegaard splitting#Theorems|Waldhausen's Theorem]] that every reducible splitting of an [[irreducible manifold]] is stabilized.\n\nA Heegaard splitting is '''weakly reducible''' if there are disjoint essential simple closed curves <math>\\alpha</math> and <math>\\beta</math> on ''H'' where <math>\\alpha</math> bounds a disk in ''V'' and <math>\\beta</math> bounds a disk in ''W''.  A splitting is '''strongly irreducible''' if it is not weakly reducible.\n\nA Heegaard splitting is '''minimal''' or '''minimal genus''' if there is no other splitting of the ambient three-manifold of lower [[genus]]. The minimal value ''g'' of the splitting surface is the '''Heegaard genus''' of ''M''.\n\n===Generalized Heegaard splittings===\n\nA '''generalized Heegaard splitting''' of ''M'' is a decomposition into  [[compression body|compression bodies]] <math>V_i, W_i, i=1,\\dots,n</math> and surfaces <math>H_i, i=1,\\dots, n</math> such that <math>\\partial_+ V_i = \\partial_+ W_i = H_i</math> and <math>\\partial_- W_i = \\partial_- V_{i+1}</math>. The interiors of the compression bodies must be pairwise disjoint and their union must be all of <math>M</math>.  The surface <math>H_i</math> forms a Heegaard surface for the submanifold <math>V_i \\cup W_i</math> of <math>M</math>.  (Note that here each ''V<sub>i</sub>'' and ''W<sub>i</sub>'' is allowed to have more than one component.)\n\nA generalized Heegaard splitting is called '''strongly irreducible''' if each <math>V_i \\cup W_i</math> is strongly irreducible.\n\nThere is an analogous notion of [[thin position]], defined for knots, for Heegaard splittings.  The complexity of a connected surface ''S'', ''c(S)'', is defined to be <math>\\operatorname{max}\\{0, 1 - \\chi(S)\\}</math>; the complexity of a disconnected surface is the sum of complexities of its components.  The complexity of a generalized Heegaard splitting is the multi-set ''{c(S_i)}'', where the index runs over the Heegaard surfaces in the generalized splitting.  These multi-sets can be well-ordered by [[lexicographical order]]ing (monotonically decreasing).  A generalized Heegaard splitting is '''thin''' if its complexity is minimal.\n\n==Examples==\n\n'''[[Three-sphere]]''': The three-sphere <math>S^3</math> is the set of vectors in <math>\\mathbb{R}^4</math> with length one.  Intersecting this with the <math>xyz</math> hyperplane gives a [[two-sphere]].  This is the '''standard''' genus zero splitting of <math>S^3</math>.  Conversely, by [[Alexander's Trick]], all manifolds admitting a genus zero splitting are [[homeomorphic]] to <math>S^3</math>.\n\nUnder the usual identification of <math>\\mathbb{R}^4</math> with <math>\\mathbb{C}^2</math> we may view <math>S^3</math> as living in <math>\\mathbb{C}^2</math>.  Then the set of points where each coordinate has norm <math>1/\\sqrt{2}</math> forms a [[Clifford torus]], <math>T^2</math>.  This is the standard genus one splitting of <math>S^3</math>.  (See also the discussion at [[Hopf bundle]].)\n\n'''Stabilization''': Given a Heegaard splitting ''H'' in ''M'' the '''stabilization''' of ''H'' is formed by taking the [[connected sum]] of the pair <math>(M, H)</math> with the pair <math>(S^3, T^2)</math>.  It is easy to show that the stabilization procedure yields stabilized splittings.  Inductively, a splitting is '''standard''' if it is the stabilization of a standard splitting.\n\n'''[[Lens space]]s''': All have a standard splitting of genus one.  This is the image of the Clifford torus in <math>S^3</math> under the quotient map used to define the lens space in question.  It follows from the structure of the [[mapping class group]] of the [[torus|two-torus]] that only lens spaces have splittings of genus one.\n\n'''[[Three-torus]]''': Recall that the three-torus <math>T^3</math> is the [[Cartesian product]] of three copies of <math>S^1</math> ([[circle]]s).  Let <math>x_0</math> be a point of <math>S^1</math> and consider the graph\n<math> \\Gamma = \nS^1 \\times \\{x_0\\} \\times \\{x_0\\} \\cup\n\\{x_0\\} \\times S^1 \\times \\{x_0\\} \\cup\n\\{x_0\\} \\times \\{x_0\\} \\times S^1\n</math>.  It is an easy exercise to show that ''V'', a [[regular neighborhood]] of <math>\\Gamma</math>, is a handlebody as is <math>T^3 - V</math>.  Thus the boundary of ''V'' in <math>T^3</math> is a Heegaard splitting and this is the standard splitting of <math>T^3</math>. It was proved by Charles Frohman and [[Joel Hass]] that any other genus 3 Heegaard splitting of the three-torus is topologically\nequivalent to this one. Michel Boileau and Jean-Pierre Otal proved that in general any Heegaard splitting of the three-torus is equivalent to the result of stabilizing this example.\n\n==Theorems==\n'''Alexander's Lemma''': Up to isotopy, there is a unique ([[piecewise linear homeomorphism|piecewise linear]]) embedding of the two-sphere into the three-sphere.  (In higher dimensions this is known as the [[Jordan–Schönflies theorem|Schoenflies theorem]].  In dimension two this is the [[Jordan curve theorem]].)  This may be restated as follows: the genus zero splitting of <math>S^3</math> is unique.\n\n'''Waldhausen's Theorem''': Every splitting of <math>S^3</math> is obtained by stabilizing the unique splitting of genus zero.\n\nSuppose now that ''M'' is a closed orientable three-manifold.\n\n'''Reidemeister–Singer Theorem''': For any pair of splittings <math>H_1</math> and <math>H_2</math> in ''M'' there is a third splitting <math>H</math> in ''M'' which is a stabilization of both.\n\n'''Haken's Lemma''':  Suppose that <math>S_1</math> is an essential two-sphere in ''M'' and ''H'' is a Heegaard splitting.  Then there is an essential  two-sphere <math>S_2</math> in ''M'' meeting ''H'' in a single curve.\n\n==Classifications==\n\nThere are several classes of three-manifolds where the set of Heegaard splittings is completely known.  For example, Waldhausen's Theorem shows that all splittings of <math>S^3</math> are standard.  The same holds for [[lens space]]s (as proved by Francis Bonahon and Otal).\n\nSplittings of [[Seifert fiber space]]s are more subtle.  Here, all splittings may be isotoped to be '''vertical''' or '''horizontal''' (as proved by Yoav Moriah and Jennifer Schultens).\n\n{{harvtxt|Cooper|Scharlemann|1999}} classified splittings of [[torus bundle]]s (which includes all three-manifolds with [[Sol geometry]]).  It follows from their work that all torus bundles have a unique splitting of minimal genus.  All other splittings of the torus bundle are stabilizations of the minimal genus one.\n\nAs of 2008, the only [[Geometrization conjecture|hyperbolic]] three-manifolds whose Heegaard splittings are classified are two-bridge knot complements, in a paper of Tsuyoshi Kobayashi.\n\n==Applications and connections==\n\n===Minimal surfaces===\n\nHeegaard splittings appeared in the theory of [[minimal surface]]s first in the work of [[Blaine Lawson]] who proved that embedded minimal surfaces in compact manifolds of positive sectional curvature are Heegaard splittings. This result was extended by William Meeks to flat manifolds, except he proves that an embedded minimal surface in a flat three-manifold is either a Heegaard surface or [[totally geodesic]].\n  \nMeeks and [[Shing-Tung Yau]] went on to use results of Waldhausen to prove results about the topological uniqueness of minimal surfaces of finite genus in <math>\\R^3</math>. The final topological classification of embedded minimal surfaces in <math>\\R^3</math> was given by Meeks and Frohman. The result relied heavily on techniques developed for studying the topology of Heegaard splittings.\n\n===Heegaard Floer homology===\nHeegaard diagrams, which are simple combinatorial descriptions of Heegaard splittings, have been used extensively to construct invariants of three-manifolds. The most recent example of this is the [[Floer homology#Heegaard Floer homology|Heegaard Floer homology]] of [[Peter Ozsvath]] and [[Zoltán Szabó (mathematician)|Zoltán Szabó]]. The theory uses the <math>g^{th}</math> symmetric product of a Heegaard surface as the ambient space, and tori built from the boundaries of meridian disks for the two handlebodies as the [[Lagrangian submanifold]]s.\n\n==History==\n\nThe idea of a Heegaard splitting was introduced by {{harvs|txt|authorlink=Poul Heegaard|last=Heegaard|first=Poul|year=1898}}.  While Heegaard splittings were studied extensively by mathematicians such as [[Wolfgang Haken]] and [[Friedhelm Waldhausen]] in the 1960s, it was not until a few decades later that the field was rejuvenated by {{harvs|txt|last1=Casson | first1=Andrew | author1-link=Andrew Casson| last2=Gordon | first2=Cameron | author2-link=Cameron Gordon (mathematician)|year=1987}}, primarily through their concept of '''strong irreducibility'''.\n\n==See also==\n*[[Manifold decomposition]]\n*[[Handle decompositions of 3-manifolds]]\n*[[Compression body]]\n\n==References==\n{{reflist}}\n*{{Citation|last1= Farb |first1= Benson |author1-link=Benson Farb|last2 = Margalit |first2 = Dan |title=A Primer on Mapping Class Groups |publisher=Princeton University Press}}\n*{{Citation | last1=Casson | first1=Andrew J. | author1-link=Andrew Casson| last2=Gordon | first2=Cameron McA. | author2-link=Cameron Gordon (mathematician)| title=Reducing Heegaard splittings | doi=10.1016/0166-8641(87)90092-7 | mr=918537 | year=1987 | journal=[[Topology and Its Applications]] | issn=0166-8641 | volume=27 | issue=3 | pages=275–283}}\n*{{Citation | last1=Cooper | first1=Daryl | last2=Scharlemann | first2=Martin | url=http://mistug.tubitak.gov.tr/bdyim/toc.php?dergi=mat&yilsayi=1999/1 | mr=1701636 | year=1999 | journal=Turkish Journal of Mathematics | issn=1300-0098 | volume=23 | issue=1 | title=The structure of a solvmanifold's Heegaard splittings | pages=1–18}}\n*{{Citation | last1=Heegaard | first1=Poul | title=Forstudier til en topologisk Teori for de algebraiske Fladers Sammenhang | url=http://www.maths.ed.ac.uk/~aar/papers/heegaardthesis.pdf | language=Danish | series=Thesis | jfm=29.0417.02 | year=1898}}\n*{{Citation | last1=Hempel | first1=John | title=3-manifolds | publisher=[[Princeton University Press]] | series=Annals of Mathematics Studies | isbn=978-0-8218-3695-8 | mr=0415619 | year=1976 | volume=86}}\n\n[[Category:3-manifolds]]\n[[Category:Minimal surfaces]]\n[[Category:Geometric topology]]"
    },
    {
      "title": "Helicoid",
      "url": "https://en.wikipedia.org/wiki/Helicoid",
      "text": "[[Image:Helicoid.svg|right|thumb|350px|A helicoid with ''α''&nbsp;=&nbsp;1, −1&nbsp;≤&nbsp;''ρ''&nbsp;≤&nbsp;1 and −{{pi}}&nbsp;≤&nbsp;''θ''&nbsp;≤&nbsp;{{pi}}.]]\n{{for|the circular building in Caracas, Venezuela|El Helicoide}}\nThe '''helicoid''', after the [[Plane (geometry)|plane]] and the [[catenoid]], is the third [[minimal surface]] to be known. \n\n==Description==\nIt was described by [[Euler]] in 1774 and by [[Jean Baptiste Meusnier]] in 1776. Its [[Nomenclature|name]] derives from its similarity to the [[helix]]: for every [[Point (geometry)|point]] on the helicoid, there is a helix contained in the helicoid which passes through that point. Since it is considered that the planar range extends through negative and positive infinity, close observation shows the appearance of two parallel or mirror planes in the sense that if the slope of one plane is traced, the co-plane can be seen to be bypassed or skipped, though in actuality the co-plane is also traced from the opposite perspective.\n\nThe helicoid is also a [[ruled surface]] (and a [[right conoid]]), meaning that it is a trace of a line. Alternatively, for any point on the surface, there is a line on the surface passing through it. Indeed, [[Eugène Charles Catalan|Catalan]] proved in 1842 that the helicoid and the plane were the only ruled [[minimal surface]]s.<ref>''Elements of the Geometry and Topology of Minimal Surfaces in Three-dimensional Space''\nBy [[A. T. Fomenko]], A. A. Tuzhilin\nContributor A. A. Tuzhilin\nPublished by AMS Bookstore, 1991\n{{ISBN|0-8218-4552-7}}, {{ISBN|978-0-8218-4552-3}}, p. 33</ref>. \n\nA helicoid is also a [[Translation surface (differential geometry)|translation surface]] in the sense of differential geometry.\n\nThe helicoid and the [[catenoid]] are parts of a family of helicoid-catenoid minimal surfaces.\n\nThe helicoid is shaped like [[Archimedes screw]], but extends infinitely in all directions.  It can be described by the following [[parametric equation]]s in [[Cartesian coordinates]]:\n:<math> x = \\rho \\cos (\\alpha \\theta), \\ </math>\n:<math> y = \\rho \\sin (\\alpha \\theta), \\ </math>\n:<math> z = \\theta, \\ </math>\nwhere ''ρ'' and ''θ'' range from negative [[infinity]] to [[positive number|positive]] infinity, while ''α'' is a constant. If ''α'' is positive, then the helicoid is right-handed as shown in the figure; if negative then left-handed.\n\nThe helicoid has [[principal curvature]]s <math>\\pm \\alpha /(1+ \\alpha^2 \\rho ^2) \\ </math>.  The sum of these quantities gives the [[mean curvature]] (zero since the helicoid is a minimal surface) and the product gives the [[Gaussian curvature]].\n\nThe helicoid is [[homeomorphism|homeomorphic]] to the plane <math> \\mathbb{R}^2 </math>.  To see this, let alpha decrease [[continuous function|continuous]]ly from its given value down to [[0 (number)|zero]].  Each intermediate value of ''α'' will describe a different helicoid, until ''α''&nbsp;=&nbsp;0 is reached and the helicoid becomes a vertical [[plane (mathematics)|plane]].\n\nConversely, a plane can be turned into a helicoid by choosing a line, or ''axis'', on the plane, then twisting the plane around that axis.\n\nFor example, if one takes ''h'' as the maximum value at ''z'' and ''R'' the radius, the area of the surface is\n\n: <math>\\pi \\left[R \\sqrt{R^2+h^2}+h^2 \\ln \\left( R + \\frac{\\sqrt{R^2+h^2}} h\\right) \\right].</math>\n\n==Helicoid and catenoid==\n[[File:Helicatenoid.gif|thumb|256px|Animation showing the transformation of a helicoid into a catenoid.]]\nThe helicoid and the [[catenoid]] are locally isometric surfaces; see [[Catenoid#Helicoid transformation]].\n\n==See also==\n*[[Generalized helicoid]]\n*[[Dini's surface]]\n*[[Right conoid]]\n*[[Ruled surface]]\n\n==Notes==\n<references />\n\n==External links==\n{{commonscat|Helicoids}}\n* {{springer|title=Helicoid|id=p/h046880}}\n* [http://www.princeton.edu/~rvdb/WebGL/helicoid.html WebGL-based Interactive 3D Helicoid]\n\n{{Minimal surfaces}}\n\n[[Category:Geometric shapes]]\n[[Category:Minimal surfaces]]\n[[Category:Surfaces]]"
    },
    {
      "title": "Henneberg surface",
      "url": "https://en.wikipedia.org/wiki/Henneberg_surface",
      "text": "[[File:Henneberg surface.jpg|thumb|Henneberg surface.]]\n\nIn [[differential geometry]], the '''Henneberg surface''' is a [[non-orientable]] [[minimal surface]]<ref>L. Henneberg, Über salche minimalfläche, welche eine vorgeschriebene ebene curve sur geodätishen line haben, Doctoral Dissertation, Eidgenössisches Polythechikum, Zürich, 1875</ref> named after Lebrecht Henneberg.<ref>[[:de:Lebrecht Henneberg|Lebrecht Henneberg]] from the German-language Wikipedia. Retrieved on September 25, 2012.</ref>\n\nIt has parametric equation\n:<math>\\begin{align}\nx(u,v) &= 2\\cos(v)\\sinh(u) - (2/3)\\cos(3v)\\sinh(3u)\\\\\ny(u,v) &= 2\\sin(v)\\sinh(u) + (2/3)\\sin(3v)\\sinh(3u)\\\\\nz(u,v) &= 2\\cos(2v)\\cosh(2u)\n\\end{align}</math>\nand can be expressed as an order-15 algebraic surface.<ref>Weisstein, Eric W. \"Henneberg's Minimal Surface.\" From MathWorld—A Wolfram Web Resource. http://mathworld.wolfram.com/HennebergsMinimalSurface.html</ref> It can be viewed as an [[immersion (mathematics)|immersion]] of a punctured [[projective plane]].<ref>Ulrich Dierkes, Stefan Hildebrandt, Friedrich Sauvigny, Minimal Surfaces, Volume 1. Springer 2010</ref> Up until 1981 it was the only known non-orientable minimal surface.<ref>M. Elisa G. G. de Oliveira, Some New Examples of Nonorientable Minimal Surfaces, Proceedings of the American Mathematical Society, Vol. 98, No. 4, Dec., 1986</ref>\n\nThe surface contains a [[semicubical parabola]] (\"Neile's parabola\") and can be derived from solving the corresponding [[Björling problem]].<ref>L. Henneberg, Über diejenige minimalfläche, welche die Neil'sche Paralee zur ebenen geodätischen line hat, Vierteljschr Natuforsch, Ges. Zürich 21 (1876), 66–70.</ref><ref>Kai-Wing Fung, Minimal Surfaces as Isotropic Curves in C3: Associated minimal surfaces and the Björling's problem. MIT BA Thesis. 2004 http://ocw.mit.edu/courses/mathematics/18-994-seminar-in-geometry-fall-2004/projects/main1.pdf</ref>\n\n== References ==\n{{reflist}}\n\n{{Minimal surfaces}}\n\n[[Category:Minimal surfaces]]\n[[Category:Differential geometry]]"
    },
    {
      "title": "K-noid",
      "url": "https://en.wikipedia.org/wiki/K-noid",
      "text": "{{DISPLAYTITLE:''k''-noid}}\n{{Redirect|Trinoid|the entities from the television show Bakuryū Sentai Abaranger|Wicked Lifeforms Evolien#Trinoids}}\n[[File:Trinoid.png|thumb|Trinoid]]\n[[File:7-noid.png|thumb|7-noid]]\nIn [[differential geometry]], a '''''k''-noid''' is a [[minimal surface]] with ''k'' [[catenoid]] openings. In particular, the 3-noid is often called trinoid. The first ''k''-noid minimal surfaces were described by Jorge and Meeks in 1983.<ref>L. P. Jorge and W. H. Meeks III,  The topology of complete minimal surfaces of finite total Gaussian  curvature,  Topology  22 (1983)</ref>\n\nThe term ''k''-noid and trinoid is also sometimes used for [[constant mean curvature surface]]s, especially branched versions of the [[unduloid]] (\"triunduloids\").<ref>{{cite arxiv|author=N Schmitt|title=Constant Mean Curvature ''n''-noids with Platonic Symmetries|eprint=math/0702469|year=2007}}</ref>\n\n''k''-noids are topologically equivalent to ''k''-punctured spheres (spheres with ''k'' points removed). ''k''-noids with symmetric openings can be generated using the [[Weierstrass–Enneper parameterization]] <math>f(z) = 1/(z^k-1)^2, g(z) = z^{k-1}\\,\\!</math>.<ref>{{cite web|author=Matthias Weber|title=Classical Minimal Surfaces in Euclidean Space by Examples|year=2001|url=http://www.indiana.edu/~minimal/research/claynotes.pdf|publisher=Indiana.edu|accessdate=2012-10-05}}</ref> This produces the explicit formula\n\n: <math>\\begin{align}\nX(z) = \\frac{1}{2} \\Re \\Bigg\\{ \\Big(\\frac{-1}{kz(z^k-1)} \\Big)  \\Big[ &(k-1)(z^k-1)_2F_1(1,-1/k;(k-1)/k;z^k)\\\\\n& {}-(k-1)z^2(z^k-1)_2F_1(1,1/k;1+1/k;z^k) \\\\\n&{}-kz^k +k+z^2-1  \\Big] \\Bigg\\}\n\\end{align}</math>\n\n: <math>\\begin{align}\nY(z) = \\frac{1}{2} \\Re  \\Bigg\\{ \\Big(\\frac{i}{kz(z^k-1)}\\Big) \\Big[ &(k-1)(z^k-1)_2F_1(1,-1/k;(k-1)/k;z^k) \\\\\n&{}+(k-1)z^2(z^k-1)_2F_1(1,1/k;1+1/k;z^k)\\\\\n& {}-kz^k+k-z^2-1 )  \\Big] \\Bigg\\}\n\\end{align}</math>\n\n: <math>\nZ(z) =\\Re \\left \\{ \\frac{1}{k-kz^k} \\right\\}\n</math>\n\nwhere <math>_2F_1(a,b;c;z)</math> is the Gaussian [[hypergeometric function]] and <math>\\Re \\{z\\}</math> denotes the real part of <math>z</math>.\n\nIt is also possible to create k-noids with openings in different directions and sizes,<ref>{{cite web|author=H. Karcher|title=Construction of minimal surfaces, in \"Surveys in Geometry\", University of Tokyo, 1989, and Lecture Notes No. 12, SFB 256, Bonn, 1989, pp. 1-96|url= http://www.math.uni-bonn.de/people/karcher/karcherTokyo.pdf|publisher=Math.uni-bonn-de|accessdate=2012-10-05}}</ref> k-noids corresponding to the [[platonic solids]] and k-noids with handles.<ref>{{cite journal|author=Jorgen Berglund, Wayne Rossman|title= Minimal Surfaces with Catenoid Ends |journal=Pacific J. Math. |volume=171 |issue=2 |year=1995 |pages=353–371|arxiv=0804.4203|bibcode= 2008arXiv0804.4203B |doi=10.2140/pjm.1995.171.353}}</ref>\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://www.indiana.edu/~minimal/archive/Spheres/Noids/Jorge-Meeks/web/index.html Indiana.edu]\n* [http://page.mi.fu-berlin.de/polthier/booklet/alteration.html Page.mi.fu-berlin.de]\n\n{{Minimal surfaces}}\n\n[[Category:Differential geometry]]\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Lidinoid",
      "url": "https://en.wikipedia.org/wiki/Lidinoid",
      "text": "{{technical|date=October 2012}}\n\n[[File:Lidinoid surface.jpg|thumb|Lidinoid in a unit cell.]]\n\nIn [[differential geometry]], the '''lidinoid''' is a [[Triply periodic minimal surface|triply periodic]] [[minimal surface]]. The name comes from its Swedish discoverer Sven Lidin (who called it the HG surface).<ref>{{cite journal |first1=Sven |last1=Lidin |first2=Stefan |last2=Larsson |title=Bonnet Transformation of Infinite Periodic Minimal Surfaces with Hexagonal Symmetry |journal=J. Chem. Soc. Faraday Trans. |year=1990 |volume=86 |issue=5 |pages=769–775 |doi=10.1039/FT9908600769}}</ref>\n\nIt has many similarities to the [[gyroid]], and just as the gyroid is the unique embedded member of the [[associate family]] of the [[Schwarz minimal surface#Schwarz P .28.22Primitive.22.29|Schwarz P surface]] the lidinoid is the unique embedded member of the associate family of the [[Schwarz minimal surface#Schwarz H .28.22Hexagonal.22.29|Schwarz H surface]].<ref>{{cite journal |author=Adam G. Weyhaupt |title=Deformations of the gyroid and lidinoid minimal surfaces |journal=Pacific Journal of Mathematics |volume=235 |year=2008 |issue=1 |pages=137–171 |doi=10.2140/pjm.2008.235.137}}</ref> It belongs to [[space group]] 230(Ia3d).\n\nThe Lidinoid can be expressed as a [[level set]]:<ref>[https://secure.msri.org/about/sgp/jim/papers/morphbysymmetry/lidinoid/index.html The lidionoid in the Scientific Graphic Project]</ref>\n:<math>\\begin{align}\n(1/2)[&\\sin(2x) \\cos(y)\\sin(z)\\\\\n  + &\\sin(2y)\\cos(z) \\sin(x)\\\\\n  + &\\sin(2z)\\cos(x) \\sin(y)]\\\\ \n  -& (1/2)[\\cos(2x)\\cos(2y)\\\\\n  + &\\cos(2y)\\cos(2z)\\\\\n  + &\\cos(2z)\\cos(2x)]  + 0.15 = 0\n\\end{align}\n</math>\n\n==References==\n\n{{reflist}}\n\n==External images==\n\n* [http://www.indiana.edu/~minimal/archive/Triply/genus3/Lidinoid/web/index.html The lidinoid at the minimal surface archive]\n* [https://secure.msri.org/about/sgp/jim/papers/morphbysymmetry/lidinoid/index.html The lidionoid in the Scientific Graphic Project]\n\n{{Minimal surfaces}}\n\n[[Category:Minimal surfaces]]\n[[Category:Differential geometry of surfaces]]\n\n\n{{differential-geometry-stub}}"
    },
    {
      "title": "Minimal surface of revolution",
      "url": "https://en.wikipedia.org/wiki/Minimal_surface_of_revolution",
      "text": "[[File:Bulle caténoïde.png|thumb|240px|Stretching a soap film between two parallel circular wire loops generates a [[catenoid]]al minimal surface of revolution]]\nIn [[mathematics]], a '''minimal surface of revolution''' or '''minimum surface of revolution''' is a [[surface of revolution]] defined from two [[point (geometry)|points]] in a [[half-plane]], whose boundary is the axis of revolution of the surface. It is generated by a [[curve]] that lies in the half-plane and connects the two points; among all the surfaces that can be generated in this way, it is the one that [[mathematical optimization|minimizes]] the [[surface area]].<ref name=\"Mathworld: Minimal Surface of Revolution\">{{cite web | url=http://mathworld.wolfram.com/MinimalSurfaceofRevolution.html | title=Minimal Surface of Revolution | last=Weisstein | first=Eric W. | authorlink=Eric W. Weisstein | work=[[Mathworld]] | publisher=[[Wolfram Research]] | accessdate=2012-08-29}}</ref> A basic problem in the [[calculus of variations]] is finding the curve between two points that produces this minimal surface of revolution.<ref name=\"Mathworld: Minimal Surface of Revolution\"/>\n\n==Relation to minimal surfaces==\nA minimal surface of revolution is a subtype of [[minimal surface]].<ref name=\"Mathworld: Minimal Surface of Revolution\"/> A minimal surface is defined not as a surface of minimal area, but as a surface with a [[mean curvature]] of 0.<ref name=\"Mathworld: Minimal Surface\">{{cite web | url=http://mathworld.wolfram.com/MinimalSurface.html | title=Minimal Surface | last=Weisstein | first=Eric W. | authorlink=Eric W. Weisstein | work=[[Mathworld]] | publisher=[[Wolfram Research]] | accessdate=2012-08-29}}</ref> Since a mean curvature of 0 is a [[necessary condition]] of a surface of minimal area, all minimal surfaces of revolution are minimal surfaces, but not all minimal surfaces are minimal surfaces of revolution. As a point forms a [[circle]] when [[rotation around a fixed axis|rotated about an axis]], finding the minimal surface of revolution is equivalent to finding the minimal surface passing through two circular [[wireframe model|wireframes]].<ref name=\"Mathworld: Minimal Surface of Revolution\"/> A physical realization of a minimal surface of revolution is [[soap film]] stretched between two parallel circular [[wire]]s: the soap film naturally takes on the shape with least surface area.<ref name=\"Peter J. Olver\">{{cite book | title=Applied Mathematics Lecture Notes | last=Olver | first=Peter J. |author-link=Peter J. Olver | chapter=Chapter 21: The Calculus of Variations | year=2012 | url=http://www.math.umn.edu/~olver/am_/cvz.pdf | format=PDF | accessdate=2012-08-29}}</ref><ref name=\"When Least Is Best-Soap and Solution\">\n{{cite book | title=When Least Is Best: How Mathematicians Discovered Many Clever Ways to Make Things as Small (or as Large) as Possible | last=Nahin | first=Paul J. | publisher=[[Princeton University Press]] | year=2011 | pages=265–6 | quote=So what happens to the soap film after it breaks [...]? This discontinuous behavior is called the ''Goldschmidt solution'', after the German mathematician [[C. W. B. Goldschmidt]] (1807-51) who discovered it (on paper) in 1831.}}</ref>\n\n==Catenoid solution==\n[[File:Catenoid.svg|thumb|A [[catenoid]]]]\nIf the half-plane containing the two points and the axis of revolution is given [[Cartesian coordinate]]s, making the axis of revolution into the ''x''-axis of the coordinate system, then the curve connecting the points may be interpreted as the [[graph of a function]]. If the Cartesian coordinates of the two given points are <math>(x_1,y_1)</math>, <math>(x_2,y_2)</math>, then the area of the surface generated by a [[continuous function]] <math>f</math> may be expressed mathematically as\n:<math>2\\pi\\int_{x_1}^{x_2} f(x) \\sqrt{1+f'(x)^2} dx</math>\nand the problem of finding the minimal surface of revolution becomes one of finding the function that minimizes this integral, subject to the [[boundary conditions]] that <math>f(x_1)=y_1</math> and <math>f(x_2)=y_2</math>.<ref name=\"sagan\"/> In this case, the optimal curve will necessarily be a [[catenary]].<ref name=\"Mathworld: Minimal Surface of Revolution\"/><ref name=\"sagan\"/> The axis of revolution is the directrix of the catenary, and the minimal surface of revolution will thus be a [[catenoid]].<ref name=\"Mathworld: Minimal Surface of Revolution\"/><ref name=\"Colding and Minicozzi\">{{cite book | title=A Course in Minimal Surfaces | series=Graduate Studies in Mathematics | last1=Colding | first1=Tobias Holck | authorlink1=Tobias Colding | last2=Minicozzi II | first2=William P. | chapter=Chapter 1: The Beginning of the Theory | publisher=[[American Mathematical Society]] | year=2011 | url=http://www.ams.org/bookstore/pspdf/gsm-121-prev.pdf | format=PDF | accessdate=2012-08-29}}</ref><ref name=\"Meeks and Perez\">{{cite book | title=A Survey on Classical Minimal Surface Theory | series=University Lectures Series | volume=60 | last1=Meeks III | first1=William H. | last2=Pérez | first2=Joaquín | chapter=Chapter 2.5: Some interesting examples of complete minimal surfaces. | publisher=[[American Mathematical Society]] | year=2012 | url=http://www.ugr.es/~jperez/papers/monograph-book2.pdf | format=PDF | accessdate=2012-08-29}}</ref>\n\n==Goldschmidt solution==\nSolutions based on discontinuous functions may also be defined. In particular, for some placements of the two points the optimal solution is generated by a discontinuous function that is nonzero at the two points and zero everywhere else. This function leads to a surface of revolution consisting of two circular disks, one for each point, connected by a degenerate line segment along the axis of revolution. This is known as a '''Goldschmidt solution'''<ref name=\"sagan\">{{citation|contribution=2.6 The problem of minimal surfaces of revolution|title=Introduction to the Calculus of Variations|first=Hans|last=Sagan|publisher=Courier Dover Publications|year=1992|isbn=9780486673660|url=https://books.google.com/books?id=abhS8PgpBskC&pg=PA62|pages=62–66}}</ref><ref name=\"Mathworld: Goldschmidt Solution\">{{cite web | url=http://mathworld.wolfram.com/GoldschmidtSolution.html | title=Goldschmidt Solution | last=Weisstein | first=Eric W. | authorlink=Eric W. Weisstein | work=[[Mathworld]] | publisher=[[Wolfram Research]] | accessdate=2012-08-29}}</ref> after [[German people|German]] mathematician [[Carl Wolfgang Benjamin Goldschmidt]],<ref name=\"When Least Is Best-Soap and Solution\"/> who announced his discovery of it in his 1831 paper \"Determinatio superficiei minimae rotatione curvae data duo puncta jungentis circa datum axem ortae\" (\"Determination of the surface-minimal rotation curve given two joined points about a given axis of origin\").<ref>{{cite web | url=https://books.google.com/books/about/Determinatio_superficiei_minimae_rotatio.html?id=bPs-AAAAYAAJ | title=Bibliographic Information: Determinatio superficiei minimae rotatione curvae data duo puncta jungentis circa datum axem ortae | publisher=[[Google Books]] | accessdate=2012-08-27}}</ref>\n\nTo continue the physical analogy of soap film given above, these Goldschmidt solutions can be visualized as instances in which the soap film breaks as the circular wires are stretched apart.<ref name=\"When Least Is Best-Soap and Solution\"/> However, in a physical soap film, the connecting line segment would not be present. Additionally, if a soap film is stretched in this way, there is a range of distances within which the catenoid solution is still feasible but has greater area than the Goldschmidt solution, so the soap film may stretch into a configuration in which the area is a [[local minimum]] but not a global minimum. For distances greater than this range, the catenary that defines the catenoid crosses the ''x''-axis and leads to a self-intersecting surface, so only the Goldschmidt solution is feasible.<ref>{{citation|title=The Science of Soap Films and Soap Bubbles|first=Cyril|last=Isenberg|authorlink=Cyril Isenberg|publisher=Courier Dover Publications|year=1992|isbn=9780486269603|page=165|url=https://books.google.com/books?id=PdsVME_LXTYC&pg=PA165}}.</ref>\n\n==References==\n\n{{reflist}}\n\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Neovius surface",
      "url": "https://en.wikipedia.org/wiki/Neovius_surface",
      "text": "[[File:Neovius' minimal surface.png|thumb|Neovius' minimal surface in a unit cell.]]\n\nIn [[differential geometry]], the '''Neovius surface''' is a [[Triply periodic minimal surface|triply periodic]] [[minimal surface]] originally discovered by Finnish mathematician Edvard Rudolf Neovius (the uncle of [[Rolf Nevanlinna]]).<ref>E. R. Neovius, \"Bestimmung zweier spezieller periodischer Minimalflächen\", Akad. Abhandlungen, Helsingfors, 1883. http://resolver.sub.uni-goettingen.de/purl?PPN591417707</ref><ref>Eric A. Lord, and Alan L. Mackay, Periodic minimal surfaces of cubic symmetry, Current science, vol. 85, no. 3, 10 August 2003</ref>\n\nThe surface has [[genus (mathematics)|genus]] 9, dividing space into two infinite non-equivalent labyrinths. Like many other triply periodic minimal surfaces it has been studied in relation to the microstructure of [[block copolymers]], [[surfactant]]-water mixtures,<ref>S. T. Hyde, Interfacial architecture in surfactant-water mixtures: Beyond spheres, cylinders and planes. Pure and Applied Chemistry, vol. 64, no. 11, pp. 1617–1622, 1992</ref> and crystallography of soft materials.<ref>AL Mackay, Flexicrystallography: curved surfaces in chemical structures, Current Science, 69:2 25 July 1995</ref>\n\nIt can be approximated with the level set surface<ref>Meinhard Wohlgemuth, Nataliya Yufa, James Hoffman, and Edwin L. Thomas. Triply Periodic Bicontinuous Cubic Microdomain Morphologies by Symmetries. Macromolecules, 2001, 34 (17), pp 6083–6089</ref>\n:<math>3[\\cos(x) + \\cos(y) + \\cos(z)] +  4 \\cos(x)\\cos(y)\\cos(z) = 0</math>\n\nIn [[Alan Schoen|Schoen's]] categorisation it is called the C(P) surface, since it is the \"complement\" of the [[Schwarz_minimal_surface#Schwarz_P_.28.22Primitive.22.29|Schwarz P surface]].  It can be extended with further handles, converging towards the expanded regular octahedron (in Schoen's categorisation)<ref>Alan H. Schoen, Triply Periodic Minimal Surfaces (TPMS), http://schoengeometry.com/e-tpms.html</ref><ref>Ken Brakke, C-P Family of Triply Periodic Minimal Surfaces, http://www.susqu.edu/brakke/evolver/examples/periodic/cpfamily.html</ref>\n\n==References==\n{{reflist}}\n\n{{Minimal surfaces}}\n\n[[Category:Differential geometry]]\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Plateau's laws",
      "url": "https://en.wikipedia.org/wiki/Plateau%27s_laws",
      "text": "[[File:Foam - big.jpg|thumb|250px|Bubbles in a foam of soapy water obey Plateau's laws. At every vertex the angle is close to 109.47 degrees, the [[tetrahedral angle]]]]\n\n'''Plateau's laws''' describe the structure of [[soap film]]s. These laws were formulated in the 19th century by the Belgian physicist [[Joseph Plateau]] from his experimental observations. Many [[patterns in nature]] are based on foams obeying these laws.<ref>Ball, 2009. pp. 66–71, 97–98, 291–292</ref>\n\n==Laws for soap films==\n\nPlateau's laws describe the shape and configuration of soap films as follows:<ref>Ball, 2009. p. 68</ref>\n\n# Soap films are made of entire (unbroken) smooth surfaces.\n# The [[mean curvature]] of a portion of a soap film is everywhere constant on any point on the same piece of soap film.\n# Soap films always meet in threes along an edge called a '''Plateau border''', and they do so at an angle of arccos(−{{sfrac|1|2}})&nbsp;= 120°.\n# These Plateau borders meet in fours at a vertex, and they do so at an angle of arccos(−{{sfrac|1|3}})&nbsp;≈ 109.47° (the [[tetrahedral angle]]).\n\nConfigurations other than those of Plateau's laws are unstable, and the film will quickly tend to rearrange itself to conform to these laws.<ref>Ball, 2009. pp. 66–67</ref>\n\nThat these laws hold for [[minimal surface]]s was proved mathematically by [[Jean Taylor]] using [[geometric measure theory]].<ref>{{citation | last = Taylor | first = Jean E. | authorlink = Jean Taylor | doi = 10.2307/1970949\n | issue = 3 | journal = [[Annals of Mathematics]] | mr = 0428181 | pages = 489–539 | series = Second Series | title = The structure of singularities in soap-bubble-like and soap-film-like minimal surfaces | volume = 103 | year = 1976}}.</ref><ref>{{citation|first1=Frederick  J., Jr.|last1=Almgren|author1-link=Frederick J. Almgren, Jr.|first2=Jean E.|last2=Taylor|author2-link=Jean Taylor|title=The geometry of soap films and soap bubbles|journal=[[Scientific American]]|volume=235|pages=82–93|date=July 1976|doi=10.1038/scientificamerican0776-82}}.</ref>\n\n==See also==\n\n* [[Young–Laplace equation]], governing the curvature of surfaces in a soap film\n\n==Notes==\n\n{{reflist}}\n\n== Sources ==\n\n* {{cite book | title=Shapes. Nature's Patterns: a tapestry in three parts | publisher=Oxford University Press | author=Ball, Philip | year=2009 | pages=66–71, 97–98, 291–292 | isbn=978-0-19-960486-9}}\n\n==External links==\n\n* {{mathworld|title=Plateau's Laws|urlname=PlateausLaws}}\n\n{{Patterns in nature}}\n\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Richmond surface",
      "url": "https://en.wikipedia.org/wiki/Richmond_surface",
      "text": "[[File:Richmond Surface.png|thumb|Richmond surface for m=2.]]\n\nIn [[differential geometry]], a '''Richmond surface''' is a [[minimal surface]] first described by [[Herbert William Richmond]] in 1904. <ref> [[Jesse Douglas]], Tibor Radó, The Problem of Plateau: A Tribute to Jesse Douglas & Tibor Radó, World Scientific, 1992 (p. 239-240)</ref> It is a family of surfaces with one planar [[End (topology)|end]] and one [[Enneper surface]]-like self-intersecting end.\n\nIt has [[Weierstrass–Enneper parameterization]] <math>f(z)=1/z^2, g(z)=z^m</math>. This allows a parametrization based on a complex parameter as\n:<math>\\begin{align}\nX(z) &=  \\Re[(-1/2z) - z^{2m+1}/(4m+2)]\\\\\nY(z) &=  \\Re[(-i/2z) + i z^{2m+1}/(4m+2)]\\\\\nZ(z) &=  \\Re[z^m / m]\n\\end{align}\n</math>\nThe [[associate family]] of the surface is just the surface rotated around the z-axis.\n\nTaking ''m''&nbsp;=&nbsp;2 a real parametric expression becomes:<ref>John Oprea, The Mathematics of Soap Films: Explorations With Maple, American Mathematical Soc., 2000 </ref>\n:<math>\\begin{align}\nX(u,v) &= (1/3)u^3 - uv^2 + \\frac{u}{u^2+v^2}\\\\\nY(u,v) &= -u^2v + (1/3)v^3 - \\frac{v}{u^2+v^2}\\\\\nZ(u,v) &= 2u\n\\end{align}\n</math>\n\n== References ==\n\n{{reflist}}\n\n{{Minimal surfaces}}\n\n[[Category:Minimal surfaces]]"
    },
    {
      "title": "Riemann's minimal surface",
      "url": "https://en.wikipedia.org/wiki/Riemann%27s_minimal_surface",
      "text": "[[File:Riemann Minimal Surface.png|thumb|Section of Riemann's minimal surface.]]\n\nIn [[differential geometry]], '''Riemann's minimal surface''' is a one-parameter family of [[minimal surface]]s described by [[Bernhard Riemann]] in a posthumous paper published in 1867.<ref>B. Riemann, Oeuvres mathématiques de Riemann, Gauthiers-Villards, Paris 1898.</ref> Surfaces in the family are singly periodic minimal surfaces with an infinite number of [[End (topology)|ends]] asymptotic to parallel planes, each plane \"shelf\" connected with [[catenoid]]-like bridges to the neighbouring ones. Their intersections with horizontal planes are circles or lines; Riemann proved that they were the only minimal surfaces fibered by circles in parallel planes besides the [[catenoid]], [[helicoid]] and plane. They are also the only nontrivial embedded minimal surfaces in Euclidean 3-space invariant under the [[group (mathematics)|group]] generated by a nontrivial translation.<ref>{{cite journal |first1=Francisco J. |last1=López |first2=Manuel |last2=Ritoré |first3=Fusheng |last3=Wei |title=A characterization of Riemann's minimal surfaces |journal=J. Differential Geom. |volume=47 |issue=2 |year=1997 |pages=376–397 |mr=1601620 |zbl=0938.53004 |url=http://projecteuclid.org/euclid.jdg/1214460115}}</ref> It is possible to attach extra handles to the surfaces, producing higher-[[Genus (mathematics)|genus]] minimal surface families.<ref>{{cite journal |first1=Laurent |last1=Hauswirth |first2=Frank |last2=Pacard |title=Higher-genus Riemann minimal surfaces |journal=Invent. Math. |date=September 2007 |volume=169 |issue=3 |pages=569–620 |arxiv=math/0511438 |doi=10.1007/s00222-007-0056-z|bibcode=2007InMat.169..569H }}</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n* http://www.math.indiana.edu/gallery/minimalSurface.phtml\n* http://www.indiana.edu/~minimal/essays/riemann/index.html\n* http://virtualmathmuseum.org/Surface/riemann/riemann.html\n\n{{Minimal surfaces}}\n\n[[Category:Differential geometry]]\n[[Category:Minimal surfaces]]\n[[Category:Bernhard Riemann]]"
    },
    {
      "title": "Saddle tower",
      "url": "https://en.wikipedia.org/wiki/Saddle_tower",
      "text": "[[File:Saddle Tower Minimal Surfaces.png|thumb|Two periods of a 3-fold saddle tower.]]\n\nIn [[differential geometry]], a '''saddle tower''' is a [[minimal surface]] family generalizing the singly periodic [[Scherk surface|Scherk's second surface]] so that it has ''N''-fold (''N''&nbsp;>&nbsp;2) symmetry around one axis.<ref>H. Karcher, Embedded minimal surfaces derived from Scherk's examples, Manuscripta Math. 62 (1988) pp. 83–114.</ref><ref>H. Karcher, Construction of minimal surfaces, in \"Surveys in Geometry\", Univ. of Tokyo, 1989, and Lecture Notes No. 12, SFB 256, Bonn, 1989, pp. 1–96.</ref>\n\nThese surfaces are the only properly embedded singly periodic minimal surfaces in '''R'''<sup>3</sup> with [[genus (mathematics)|genus]] zero and finitely many Scherk-type [[End (topology)|ends]] in the quotient.<ref>Joaquın Perez and Martin Traize, The classification of singly periodic minimal surfaces with genus zero and Scherk-type ends, Transactions of the American Mathematical Society, Volume 359, Number 3, March 2007, Pages 965–990</ref>\n\n== Images ==\n\n* [http://www.msri.org/publications/sgp/jim/geom/minimal/library/saddletower/index.html The Saddle Tower Surface Families]\n\n== References ==\n{{reflist}}\n\n{{Minimal surfaces}}\n\n[[Category:Minimal surfaces]]"
    }
  ]
}