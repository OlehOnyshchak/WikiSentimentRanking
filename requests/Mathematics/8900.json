{
  "pages": [
    {
      "title": "Planetary boundary layer",
      "url": "https://en.wikipedia.org/wiki/Planetary_boundary_layer",
      "text": "{{short description|The lowest part of the atmosphere directly influenced by contact with the planetary surface}}\n{{distinguish|planetary boundaries}}\n[[File:The air over Los Angeles.ogv|thumb|300px|This movie is a combined visualization of the PBL and wind dynamics over the Los Angeles basin for a one-month period. Vertical motion of the PBL is represented by the gray \"blanket\". The height of the PBL is largely driven by [[convection]] associated with the changing surface temperature of the Earth (for example, rising during the day and sinking at night). The colored arrows represent the strength and direction of winds at different altitudes.]]\n[[File:PBLimage.jpg|thumb|right|Depiction of where the planetary boundary layer lies on a sunny day.]]\n\nIn meteorology the '''planetary boundary layer''' ('''PBL'''), also known as the '''atmospheric boundary layer''' ('''ABL''') or ''peplosphere'', is the lowest part of the [[atmosphere]] and its behaviour is directly influenced by its contact with a [[planetary surface]].<ref> https://www.sciencedaily.com/terms/troposphere.htm  Retrieved on 2018-09-20.</ref> On Earth it usually responds to changes in surface [[radiative forcing]] in an hour or less. In this layer physical quantities such as [[flow velocity]], temperature, and moisture display rapid fluctuations ([[turbulence]]) and vertical mixing is strong. Above the PBL is the \"free atmosphere\",<ref>[http://glossary.ametsoc.org/wiki/Free_atmosphere]</ref> where the wind is approximately [[geostrophic wind|geostrophic]] (parallel to the isobars),<ref> http://glossary.ametsoc.org/wiki/Geostrophic_wind_level  Retrieved on 2018-09-20.</ref> while within the PBL the wind is affected by surface [[Drag (physics)|drag]] and turns across the [[Contour line#Barometric pressure|isobar]]s.\n\n==Cause of surface wind gradient==\n[[File:Light pollution and the planetary boundary layer over Berlin.jpg|thumb|The difference in the amount of aerosols below and above the boundary layer is easy to see in this aerial photograph. Light pollution from the city of Berlin is strongly scattered below the layer, but above the layer it mostly propagates out into space.]]\n\n{{see also|Wind shear|Wind gradient|Wind engineering|Ekman layer}}\nTypically, due to [[aerodynamic]] [[drag (force)|drag]], there is a wind gradient in the wind flow just a few hundred meters above the Earth's surface—the [[surface layer]] of the planetary boundary layer. Wind speed increases with increasing height above the ground, starting from zero<ref name=Wizelius>{{cite book | last = Wizelius | first = Tore | title = Developing Wind Power Projects | publisher = Earthscan Publications Ltd | location = London | year = 2007 | isbn = 1-84407-262-2 | quote = The relation between wind speed and height is called the wind profile or wind gradient. | page = 40}}</ref> due to the [[no-slip condition]].<ref name=Brown>{{cite book | last = Brown | first = G. | title = Sun, Wind & Light | publisher = Wiley | location = New York | year = 2001 | isbn = 0-471-34877-5 | page = 18 }}</ref> Flow near the surface encounters obstacles that reduce the wind speed, and introduce random vertical and horizontal velocity components at right angles to the main direction of flow.<ref>{{cite journal\n|title=CBD-28. Wind on Buildings\n|author1=Dalgliesh, W. A.  |author2=D. W. Boyd\n |lastauthoramp=yes |work=Canadian Building Digest\n|url=http://irc.nrc-cnrc.gc.ca/pubs/cbd/cbd028_e.html\n|date=1962-04-01\n|quote=Flow near the surface encounters small obstacles that change the wind speed and introduce random vertical and horizontal velocity components at right angles to the main direction of flow.}}</ref>\nThis [[turbulence]] causes vertical [[Mixing (physics)|mixing]] between the air moving horizontally at one level and the air at those levels immediately above and below it, which is important in dispersion of [[pollutants]]<ref name=Hadlock>{{cite book | last = Hadlock | first = Charles | title = Mathematical Modeling in the Environment | publisher = Mathematical Association of America | location = Washington | year = 1998 | isbn = 0-88385-709-X |pages=}}</ref> and in [[soil erosion]].<ref name=Lal/>\n\nThe reduction in velocity near the surface is a function of surface roughness, so wind velocity profiles are quite different for different terrain types.<ref name=Brown/> Rough, irregular ground, and man-made obstructions on the ground can reduce the [[geostrophic wind]] speed by 40% to 50%.<ref name=Oke>{{cite book | last = Oke | first = T. | title = Boundary Layer Climates | publisher = Methuen | location = London | year = 1987 | isbn = 0-415-04319-0 | quote = Therefore the vertical gradient of mean wind speed (dū/dz) is greatest over smooth terrain, and least over rough surfaces. |page = 54}}</ref><ref name=Crawley>{{cite book | last = Crawley | first = Stanley | title = Steel Buildings | publisher = Wiley | location = New York | year = 1993 | isbn = 0-471-84298-2 | page = 272 }}</ref> Over open water or ice, the reduction may be only 20% to 30%.<ref>{{cite book | last = Harrison | first = Roy | title = Understanding Our Environment | publisher = Royal Society of Chemistry | location = Cambridge | year = 1999 | isbn = 0-85404-584-8 | page = 11}}</ref><ref name=Russell>{{cite book | last = Thompson | first = Russell | title = Atmospheric Processes and Systems | publisher = Routledge | location = New York | year = 1998 | isbn = 0-415-17145-8 | pages = 102–103 }}</ref>  These effects are taken into account when siting [[wind turbine]]s.<ref>Maeda, Takao, Shuichiro Homma, and Yoshiki Ito. [http://www.ingentaconnect.com/content/mscp/wind/2004/00000028/00000006/art00004 Effect of Complex Terrain on Vertical Wind Profile Measured by SODAR Technique.] Retrieved on 2008-07-04.</ref><ref name=Lubosny>{{cite book | last = Lubosny | first = Zbigniew | title = Wind Turbine Operation in Electric Power Systems: Advanced Modeling | publisher = Springer | location = Berlin | year = 2003 | isbn = 3-540-40340-X | page = 17}}</ref>\n\nFor [[engineering]] purposes, the wind gradient is modeled as a [[simple shear]] exhibiting a vertical velocity profile varying according to a [[power law]] with a constant [[exponent]]ial coefficient based on surface type. The height above ground where surface friction has a negligible effect on wind speed is called the \"gradient height\" and the wind speed above this height is assumed to be a constant called the \"gradient wind speed\".<ref name=Crawley/><ref name=Gupta>{{cite book | last = Gupta | first = Ajaya | title = Guidelines for Design of Low-Rise Buildings Subjected to Lateral Forces | publisher = CRC Press | location = Boca Raton | year = 1993 | isbn = 0-8493-8969-0 | page = 49}}</ref><ref>{{cite book | last = Stoltman | first = Joseph | title = International Perspectives on Natural Disasters: Occurrence, Mitigation, and Consequences | publisher = Springer | location = Berlin | year = 2005 | isbn = 1-4020-2850-4 | page = 73 }}</ref> For example, typical values for the predicted gradient height are 457 m for large cities, 366 m for suburbs, 274 m for open terrain, and 213 m for open sea.<ref>{{cite book | last = Chen | first = Wai-Fah | title = Handbook of Structural Engineering | publisher = CRC Press | location = Boca Raton | year = 1997 | isbn = 0-8493-2674-5 | pages = 12–50}}</ref>\n\nAlthough the power law exponent approximation is convenient, it has no theoretical basis.<ref>{{cite book | last = Ghosal | first = M. | title = Renewable Energy Resources | chapter = 7.8.5 Vertical Wind Speed Gradient | publisher = Alpha Science International, Ltd | location = City | year = 2005 | isbn = 978-1-84265-125-4 | pages = 378–379}}</ref> When the temperature profile is adiabatic, the wind speed should vary [[logarithm]]ically with height.<ref>{{cite book | last = Stull | first = Roland | title = An Introduction to Boundary Layer Meteorology | publisher = Kluwer Academic Publishers | location = Boston | year = 1997 | isbn = 90-277-2768-6 | quote = ...both the wind gradient and the mean wind profile itself can usually be described diagnostically by the log wind profile. | page = 442}}</ref> Measurements over open terrain in 1961 showed good agreement with the [[log wind profile|logarithmic fit]] up to 100 m or so (within the [[surface layer]]), with near constant average wind speed up through 1000 m.<ref name=Thuillier>{{cite journal\n | author = Thuillier, R.H.\n | author2 = Lappe, U.O.\n | year = 1964\n | title = Wind and Temperature Profile Characteristics from Observations on a 1400 ft Tower\n | journal = [[Journal of Applied Meteorology]]\n | publisher= [[American Meteorological Society]]\n | volume = 3\n | issue = 3\n | pages = 299–306\n | doi = 10.1175/1520-0450(1964)003<0299:WATPCF>2.0.CO;2\n | url = http://ams.allenpress.com/perlserv/?request=get-abstract&doi=10.1175%2F1520-0450(1964)003%3C0299%3AWATPCF%3E2.0.CO%3B2\n | accessdate = 2007-06-10\n | issn = 1520-0450\n | bibcode=1964JApMe...3..299T\n }}</ref>\n\nThe [[shearing (physics)|shearing]] of the wind is usually three-dimensional,<ref>{{cite book | last = Mcilveen | first = J. | title = Fundamentals of Weather and Climate | publisher = Chapman & Hall | location = London | year = 1992 | isbn = 0-412-41160-1 | page = 184}}</ref> that is, there is also a change in direction between the 'free' pressure-driven geostrophic wind and the wind close to the ground.<ref>{{cite book | last = Burton | first = Tony | title = Wind Energy Handbook | publisher = J. Wiley | location = London | year = 2001 | isbn = 0-471-48997-2 | page = 20 }}</ref> This is related to the [[Ekman spiral]] effect. \nThe cross-isobar angle of the diverted ageostrophic flow near the surface ranges from 10° over open water, to 30° over rough hilly terrain, and can increase to 40°-50° over land at night when the wind speed is very low.<ref name=Russell/>\n\nAfter sundown the wind gradient near the surface increases, with the increasing stability.<ref name=\"Köpp\">{{cite journal\n | author = Köpp, F.\n | author2 = Schwiesow, R.L.; Werner, C.\n |date=January 1984\n | title = Remote Measurements of Boundary-Layer Wind Profiles Using a CW Doppler Lidar\n | journal = [[Journal of Applied Meteorology and Climatology]]\n | publisher = [[American Meteorological Society]]\n | volume = 23\n | issue = 1\n | pages = 153\n | doi = 10.1175/1520-0450(1984)023<0148:RMOBLW>2.0.CO;2\n | url = http://ams.allenpress.com/amsonline/?request=get-abstract&doi=10.1175%2F1520-0450(1984)023%3C0148:RMOBLW%3E2.0.CO%3B2\n | accessdate = 2007-06-09\n | issn = 1520-0450\n | bibcode=1984JApMe..23..148K\n }}</ref>\n[[Atmospheric instability|Atmospheric stability]] occurring at night with [[radiative cooling]] tends to contain turbulent eddies vertically, increasing the wind gradient.<ref name=Lal>{{cite book | last = Lal | first = R. | title = Encyclopedia of Soil Science | publisher = Marcel Dekker | location = New York | year = 2005 | isbn = 0-8493-5053-0 | page= 618}}</ref> The magnitude of the wind gradient is largely influenced by the [[weather]], principally atmospheric stability and the height of any convective boundary layer or [[Capping inversion]]. This effect is even larger over the sea, where there is no diurnal variation of the height of the boundary layer as there is over land.<ref name=Johansson2002>{{cite conference\n | author = Johansson, C. |author2=Uppsala, S. |author3=Smedman, A.S.\n | year = 2002\n | title = Does the height of the boundary layer influence the turbulence structure near the surface over the Baltic Sea?\n | booktitle = 15th Conference on Boundary Layer and Turbulence\n | publisher = [[American Meteorological Society]]\n | url = http://ams.confex.com/ams/BLT/techprogram/paper_43332.htm\n | conferenceurl = http://ams.confex.com/ams/BLT/techprogram/program_117.htm\n }}</ref>\nIn the convective boundary layer, strong mixing diminishes vertical wind gradient.<ref>{{cite book | last = Shao | first = Yaping | title = Physics and Modelling of Wind Erosion | publisher = Kluwer Academic | location = City | year = 2000 | isbn = 978-0-7923-6657-7 |page = 69 | quote = In the bulk of the convective boundary layer, strong mixing diminishes vertical wind gradient...}}</ref>\n\n==Constituent layers==\n[[File:20120629 atmospheric thermocline.JPG|thumb|A [[shelf cloud]] at the leading edge of a thunderstorm complex on the [[South Side (Chicago)|South Side of Chicago]] that extends from the [[Hyde Park, Chicago|Hyde Park]] [[Community areas of Chicago|community area]] to over the [[Regents Park (Chicago)|Regents Park]] twin towers and out over [[Lake Michigan]]]]\nAs [[Navier–Stokes equations]] suggest, the planetary boundary layer turbulence is produced in the layer with the largest velocity gradients that is at the very surface proximity. This layer – conventionally called a [[surface layer]] – constitutes about 10% of the total PBL depth. Above the surface layer the PBL turbulence gradually dissipates, losing its kinetic energy to friction as well as converting the kinetic to potential energy in a density stratified flow. The balance between the rate of the turbulent kinetic energy production and its dissipation determines the planetary boundary layer depth. The PBL depth varies broadly. At a given wind speed, e.g. 8&nbsp;m/s, and so at a given rate of the turbulence production, a PBL in wintertime Arctic could be as shallow as 50&nbsp;m, a nocturnal PBL in mid-latitudes could be typically 300&nbsp;m in thickness, and a tropical PBL in the trade-wind zone could grow to its full theoretical depth of 2000&nbsp;m.\n\nIn addition to the surface layer, the planetary boundary layer also comprises the PBL ''core'' (between 0.1 and 0.7 of the PBL depth) and the PBL top or ''entrainment layer'' or ''capping inversion layer'' (between 0.7 and 1 of the PBL depth). Four main external factors determine the PBL depth and its mean vertical structure: \n# the free atmosphere wind speed;\n# the surface heat (more exactly buoyancy) balance;\n# the free atmosphere density stratification;\n# the free atmosphere vertical wind shear or [[baroclinicity]].\n\n==Principal types==\n[[File:Atmospheric boundary layer.svg|thumbnail]]\n\n===Convective planetary boundary layer (CBL)===\n{{main|Convective Planetary Boundary Layer}}\nThe CBL is a PBL when positive buoyancy flux at the surface creates a thermal instability and thus generates additional or even major turbulence, (also known as having CAPE  or [[Convective available potential energy]]); see [[Atmospheric convection]]. A CBL is typical in tropical and mid-latitudes during daytime. Solar heating assisted by the heat released from the water vapor condensation could create so strong convective turbulence that the [[Free convective layer]] comprises the entire troposphere up to the [[tropopause]] (the boundary in the Earth's atmosphere between the [[troposphere]] and the [[stratosphere]]), which is at 10&nbsp;km to 18&nbsp;km in the [[Intertropical convergence zone]].  \n\n===Stably stratified planetary boundary layer (SBL)===\nThe SBL is a PBL when negative buoyancy flux at the surface damps the turbulence; see [[Convective inhibition]]. An SBL is solely driven by the wind shear turbulence and hence the SBL cannot exist without the free atmosphere wind. An SBL is typical in nighttime at all locations and even in daytime in places where the Earth's surface is colder than the air above. An SBL plays a particularly important role in high latitudes where it is often prolonged (days to months), resulting in very cold air temperatures.\n\nPhysical laws and equations of motions, which govern the planetary boundary layer dynamics and microphysics, are strongly non-linear and considerably influenced by properties of the Earth's surface and evolution of the processes in the free atmosphere. To deal with this complicity, the whole array of [[turbulence models|turbulence modelling]] has been proposed. However, they are often not accurate enough to meet practical requests. Significant improvements are expected from application of a [[large eddy simulation]] technique to problems related to the PBL.\n\nPerhaps the most important processes, which are critically dependent on the correct representation of the PBL in the atmospheric models ([[Atmospheric Model Intercomparison Project]]), are turbulent transport of moisture ([[evapotranspiration]]) and pollutants ([[Air pollution|air pollutants]]). [[Cloud]]s in the boundary layer influence [[trade wind]]s, the [[hydrological cycle]], and energy exchange.\n\n==See also==\n*[[Boundary layer]]\n*[[Turbulence]]\n*[[Wind shear]]\n*[[Microburst]]\n*[[Atmospheric physics]]\n*[[Atmospheric sciences]]\n*[[Atmospheric electricity]]\n*[[Astronomical seeing]]\n*[[Mixed layer]]\n*[[Remote sensing atmospheric boundary layer]]\n*[[Representations of the atmospheric boundary layer in global climate models]]\n*[[Atmospheric dispersion modeling]]\n\n==References==\n{{reflist|2}}\n\n==External links==\n*[http://www.theweatherprediction.com/basic/pbl/ Description of the planetary boundary layer] at [http://www.theweatherprediction.com/ theweatherprediction.com]\n*[http://amsglossary.allenpress.com/glossary/search?id=atmospheric-boundary-layer1 American Meteorological Society glossary entry]\n\n{{DEFAULTSORT:Planetary Boundary Layer}}\n[[Category:Boundary layer meteorology]]\n[[Category:Articles containing video clips]]\n\n[[fr:Couche limite#Météorologie]]"
    },
    {
      "title": "Remote sensing atmospheric boundary layer",
      "url": "https://en.wikipedia.org/wiki/Remote_sensing_atmospheric_boundary_layer",
      "text": "[[Remote sensing]] of the [[planetary boundary layer]] refers to the utilization of ground-based, flight-based, or satellite-based remote sensing instruments to measure properties of the planetary boundary layer including boundary layer height, aerosols and clouds. Satellite remote sensing of the atmosphere has the advantage of being able to provide global coverage of atmospheric planetary boundary layer properties while simultaneously providing relatively high temporal sampling rates. Advancements in satellite remote sensing have provided greater vertical resolution which enables higher accuracy for planetary boundary layer measurements.\n\nThe [[radiative forcing]] for marine boundary layer (MBL) clouds is imperative for understanding any global warming changes. Low-level clouds, including MBL clouds, have the largest net radiative forcing of all clouds.\n<ref>{{cite journal |journal=Journal of Climate |year=2008 |volume=21|issue=19 |pages=4955–4973|doi=10.1175/2008JCLI1974.1 |title=Investigation of Regional and Seasonal Variations in Marine Boundary Properties from MODIS Observations |last=Jensen |first=Michael|citeseerx=10.1.1.556.9408 }}</ref>\nThe albedo of these low level clouds is much higher than the albedo of the underlying ocean surface and correctly modeling these clouds is needed to limit the uncertainty in climate model predictions. The remote sensing of the planetary boundary layer, especially clouds and aerosols within the planetary boundary layer can help verify and improve climate models.\n\n==Planetary boundary layer==\nThe planetary boundary layer is the portion of the troposphere that is influenced by the interaction with the surface of the earth and will adjust to surface forcings within a timescale of 1 hour.<ref>{{cite book|last=Stull|first=Rolald B.|title=An Introduction to Boundary Layer Meteorology|date=1988|publisher=Kluwer Academic Publishers|page=3}}</ref> The planetary boundary layer is characterized by turbulence during the daytime and by stability during the night. At the top of the planetary boundary layer, there is a stable layer that is frequently termed the inversion layer as temperature tends to increase with height in contrast to much of the troposphere. The planetary boundary layer can have lower level clouds located around the capping inversion top. The two main types of clouds within the planetary boundary layer are fair-weather cumulus clouds and stratocumulus clouds. The underlying surface primarily determines the type of cloud produced within the planetary boundary layer. The presence of the capping inversion can also trap  aerosols within the planetary boundary layer. The increase of anthropogenic aerosols from burning fossil fuels can have significant impacts on precipitation and climate.<ref>{{cite journal |journal=Science |year=1989 |volume=245 |issue=4923 |pages=1227–30 |doi=10.1126/science.245.4923.1227 |title=Aerosols, Cloud Microphysics, and Fractional Cloudiness |last=Albrecht |first=B.A. |pmid=17747885}}</ref>\n\n==Satellite Remote Sensing==\nSatellite measurements have the advantage of being able to sample meteorological variables in regions that have little measurement systems. Many instruments have been created to help observe the atmosphere for both research and weather prediction. One of the first successful satellite missions for weather radar observations was the [[Television Infrared Observation Satellite]] (TIROS). This instrument paved the way for more weather satellite systems that utilize the visible, infrared and microwave radiation spectrum. Current remote sensing instruments that can help detect planetary boundary layer phenomenon include the [[Moderate-Resolution Imaging Spectroradiometer]] (MODIS) aboard [[Terra (satellite)|Terra]] and [[Aqua (satellite)|Aqua]] as well as CALIOP (Cloud-Aerosol Lidar with Orthogonal Polarization) aboard [[CALIPSO]]. While MODIS and many other satellites are passive remote sensors, active remote sensors such as CALIPSO provide greater accuracy for height retrievals. Satellite measurements have been used to determine the dynamical conditions that produce planetary boundary layer clouds and the climatological regions of where these clouds occur.<ref name=\"Anderson\">{{Cite report |author=Anderson, Ralph |author2=Farr, G. |date=1974 |title=Application of Meteorological Satellite Data in Analysis and Forecasting |url=http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=AD0786137 |publisher=National Environmental Satellite Center |accessdate=12 May 2014}}</ref>\n\n==Planetary boundary layer clouds==\n\n===Remote sensing of mesoscale cellular convection ===\nMesoscale cellular convection (MCC) is a form of buoyantly driven convection that can provide the planetary boundary layer with cumulus clouds at the top of the boundary layer. MCC generally occurs over ocean regions and is primarily found off the coasts of major continents particularly in North and South America.<ref name = \"Agee\">{{cite journal |last=Agee |first=Ernest|date=1984 |title=Observations from Space and Thermal Convection: A Historical Prospective|journal=Bulletin of the American Meteorological Society |volume=65 |issue=9|pages=938–949 |doi=10.1175/1520-0477(1984)065<0938:OFSATC>2.0.CO;2 }}</ref>\nMCC is a form of the [[Rayleigh–Bénard convection|Bénard]] cell where the fluid will rise or fall in hexagonal cells creating hexagonal cloud structure. The capping inversion of the planetary boundary layer acts as a lid for the convection creating a horizontal plane for the hexagonal cloud structures. Satellite observations have been imperative for understanding the horizontal scale and the vertical scale of these cloud formations. MCC is generally too small for synoptic scale measurements, but too large for single point measurements. However, satellite observations are able to monitor the development of the cloud patterns because of their large field of view.<ref>{{cite journal |last=Agee |first=Ernest |date=1973 |title=A Review of Mesoscale Cellular Convection |journal=Bulletin of the American Meteorological Society |volume=54 |issue=10 |pages=1004–1012 |doi=10.1175/1520-0477(1973)054<1004:AROMCC>2.0.CO;2 }}</ref> Satellites images from TIROS helped to highlight one of the main differences between laboratory convection cells and those that occur in the atmosphere. The ratio of the diameter of the hexagon compared to the depth of the cloud was much larger in the atmosphere compared to the same ratio calculated in controlled experiments. This difference showed that viscosity and heat conduction were important for the laboratory measurements, but eddy diffusion of heat and momentum dominated the atmospheric cells.<ref name=\"Agee\"/> Wind shear must be low to form MCC cells otherwise cloud streaks will form in the direction of the wind shear. The cloud formations that occur as part of MCC can be placed into two categories: open cells and closed cells.\n\n===Open cells===\n[[File:Open Cellular Convection.JPG|thumb|150px|right|MODIS image of open cellular convection taken southeast of South Africa]]\nOpen cells are characterized by a cloud free region in the middle of the hexagonal formation with cloudy regions in the outer edge of the hexagon. The open cell will have slow descending motion in the middle with faster rising motion on the edges forming the hexagonal cloud shape. They tend to form over colder water such as those that exist off the Californian coast.\n\nWhile places such as the Californian coast regularly produce open cellular convection, atmospheric storm systems can also spur the production of open cellular clouds in regions of low climatological production. Open cellular patterns can often be found behind cold fronts in the cold unstable air, and produce multiple cloud types including cumulus congenstus, cumulonimbus, and stratocumulus clouds.<ref name=\"Anderson\"/> However, the open cells formed in subtropical regions are not normally associated with synoptic storms.\n\n===Closed cells===\n[[File:Closed Cellular Convection Cloud.png|thumb|200px|right|MODIS image of closed cellular convection taken southeast of South Africa]]\nClosed cells contain cloud filled regions in the center of the hexagon formation with cloud free regions on the edge of the hexagon. The closed cell has slow rising motion in the middle and faster descending motion at the edges. Closed cells tend to occur over warmer waters such as those associated with the Kuroshio Current and the Gulf Stream.\n\nClosed cellular patterns are generally formed under weak convective mixing in the lower levels with an inversion layer cap. They commonly occur in the eastern sections of subtropical high pressure regions or in the southeastern quadrant of polar highs.\n\n==Aerosols from Satellites==\n[[File:CALIPSO.png|thumb|CALIPSO satellite image showing lidar backscatter and aerosol classification based on the backscatter data.]]\nThe CALIOP on board CALIPSO allows for the measurements of different aerosol particles by measuring the backscatter at wavelengths of 1064 and 532 nanometers with the ability to receive two orthogonal components in the 532&nbsp;nm wavelength.<ref>{{cite web|title=CALIPSO Payload|url=http://www-calipso.larc.nasa.gov/about/payload.php#CALIOP|publisher=NASA|accessdate=14 May 2014}}</ref> Without the presence of optically thick clouds, aerosol layers within the planetary boundary layer may be measured and provides a great technique for measuring aerosol pollution. Ground-based [[lidar]] have shown agreement with CALIOP in measuring isolated aerosol layers above the Seoul metropolitan area.<ref>{{cite journal |last=Kim |first=W. |date=2008 |title=Validation of aerosol and cloud layer structures from the space-borne lidar CALIOP using a ground-based lidar in Seoul, Korea |journal=Atmospheric Chemistry and Physics |volume=8 |issue=13 |pages=3705–3720 |doi=10.5194/acp-8-3705-2008 }}</ref>\n\nCALIPSO has also been used in conjunction with the MODIS data to determine how aerosols within the planetary boundary layer might alter low planetary boundary layer stratus clouds. The detection of biomass burning aerosols were shown to decrease the cloud droplet radius within these warm layer clouds in agreement with the [[Albrecht effect]], while simultaneously decreasing [[liquid water path]] in contrast to the Albrecht effect.<ref>{{cite journal |last=Constantino |first=L. |date=2012 |title=Aerosol indirect effect on warm clouds over South-East Atlantic,from co-located MODIS and CALIPSO observations|journal=Atmospheric Chemistry and Physics |volume=13 |pages=69–88 |doi=10.5194/acp-13-69-2013}}</ref>\n\n==Boundary layer height==\nThe boundary layer tends to have higher moisture values and greater aerosol amounts which results in higher scattering of light within the boundary layer. With remote sensing instruments, the boundary layer height can be detected based on these principles. Using the lidar on board CALIPSO, boundary layer height estimates have been made and compared with [[radiosonde]] and [[ECMWF re-analysis]] data and have shown high correlations between the remote sensing estimated value and the measured radiosonde values.<ref>\n{{cite journal |last=Leventidou |first=E |date=August 2013 |title=Factors affecting the comparisons of boundary layer height retrievals from CALIPSO, ECMWF and radiosondes over Thessaloniki, Greece |journal=Atmospheric Environment |volume=74 |pages=360–366 |doi=10.1016/j.atmosenv.2013.04.007 }}</ref>\n\nThe boundary layer height can be derived in a few different ways from lidar data including the maximum variance technique, which states that the maximum in the variance of the backscatter occurs at the top of the boundary layer. Within the entrainment zone, cleaner free troposphere eddies will mix with more polluted boundary layer eddies resulting in high variances at the height of the entrainment layer.<ref>{{cite journal |last=Jordan |first=N |date=2010 |title=Validation of Goddard Earth Observing System‐version 5 MERRA boundary layer heights using CALIPSO |journal=Journal of Geophysical Research: Atmospheres |volume=115|issue=D24 |pages=D24218 |doi=10.1029/2009JD013777 |bibcode=2010JGRD..11524218J}}</ref> The use of satellite derived boundary layer heights provides another method for verifying climate model output. Some remote sensing instruments have limitations. Since CALIOP relies on the use of backscattered light, daytime retrievals can contain high signal to noise ratios as sunlight can add background noise. Nighttime retrievals\n\n== Boundary layer composition ==\nUnder suitable conditions, specialized lidar techniques can be used to determine the boundary layer composition. Lidar pulses used for remote sensing get pulse echoes off the ground and off clouds. When there is a layer of broken clouds at the top of the boundary layer, [[Lidar|IPDA lidar]] techniques used for atmospheric composition remote sensing can obtain the boundary layer composition.<ref>{{Cite journal|last = Ramanathan|first = Anand K.|last2 = Mao|first2 = Jianping|last3 = Abshire|first3 = James B.|last4 = Allan|first4 = Graham R.|date = 2015-03-28|title = Remote sensing measurements of the CO2 mixing ratio in the planetary boundary layer using cloud slicing with airborne lidar|journal = Geophysical Research Letters|language = en|volume = 42|issue = 6|pages = 2014GL062749|doi = 10.1002/2014GL062749|issn = 1944-8007}}</ref>\n\n==References==\n{{reflist}}\n\n[[Category:Boundary layer meteorology]]"
    },
    {
      "title": "Representations of the atmospheric boundary layer in global climate models",
      "url": "https://en.wikipedia.org/wiki/Representations_of_the_atmospheric_boundary_layer_in_global_climate_models",
      "text": "{{multiple issues|\n{{essay-like|date=July 2014}}\n{{overly detailed|date=July 2014}}\n{{technical|date=July 2014}}\n}}\n'''Representations of the atmospheric boundary layer in global climate models'''\nplay a role in simulations of past, present, and future [[climate]]s.  Representing the [[planetary boundary layer|atmospheric boundary layer]] (ABL) within [[Global circulation model|global climate models]] (GCMs) are difficult due to differences in surface type, scale mismatch between physical processes affecting the ABL and scales at which GCMs are run, and difficulties in measuring different physical processes within the ABL.  Various parameterization techniques described below attempt to address the difficulty in ABL representations within GCMs.\n\n== What is the ABL? ==\n[[File:Atmospheric boundary layer.svg|thumbnail|right|Idealized ABL structure]]The ABL is the lowest part of the Earth's [[troposphere]], loosely about the altitude zone 0 km to 1.5 km.  The ABL is the only part of the troposphere directly affected by daily cycled contact with the Earth's surface, so the ABL is directly affected by forcings originating at the surface.<ref name=\"Stull\">{{Cite book|editor=Roland B. Stull|title=An introduction to boundary layer meteorology|volume=13|publisher=Springer|date=1988|pp=2, 200, 204, 208, 261–269}}</ref>  Such forcings include: heat flux, moisture flux, convection, friction, pollutant emission, and topographically modified flow. Response times to these forcings typically are an hour or less.<ref name=\"Stull\"/>\n\n== Why is modeling of the ABL so difficult? ==\nSurface forcings must be accounted for in [[Global circulation model|GCMs]] in order to have accurate simulations of the Earth's climate.  Unfortunately, difficulty in simulating these forcings arise for a number of reasons.  First, the Earth's surface is not uniform.  It consists (broadly) of land, water, and ice, and each surface interacts differently with the atmosphere.  Secondly, the time and spatial scales for forcings between the Earth's surface and atmosphere occur on scales much less than the scales at which GCMs are run.  Third, many of these processes are difficult to measure directly.  So, these forcings need to be [[Parametrization (atmospheric modeling)|parameterized]] as a result.<ref name=\"Hartmann\">{{Cite book|last=Hartmann|first=Dennis L.|title=Global physical climatology|volume=56|publisher=Academic press|date=1994|pp=257–258, 260–263}}</ref>\n\nIn general, the Earth is divided into a 3-D grid.  Prognostic equations for each relevant physical process are run for each grid point.  From there, grid point values for each variable are interpolated into each grid cell, which can then be analyzed.<ref name=\"Hartmann\"/>\n[[File:AtmosphericModelSchematic.png|thumbnail|left|Schematic describing GCMs]]\n\nGrid resolution for GCMs varies considerably, on the order of 1 to 5 degrees (approximately 110 to 550&nbsp;km for latitude, up to 110&nbsp;km for longitude) in the horizontal, and 10 levels in the vertical.  As grid resolution is made finer, the amount of computational time needed to run the model increases exponentially, because there are many more grid points comprising the model.  Furthermore, even with the highest resolution of 1 degree, the spatial scales of many of the physical processes incorporated in the model are still far smaller than the model resolution.<ref name=\"Hartmann\"/>\n\n==GCM cloud parameterizations==\n[[Cloud]]s and [[Convection (meteorology)|convection]] often arise from small-scale processes that occur within the ABL.  Additionally, clouds and convection help tie together the ABL with the free atmosphere, as convection helps grow the ABL.  Furthermore, when the environment is sufficiently unstable, convection may help wash away the temperature inversion that caps the ABL.  Also, \"the convective motions associated with clouds produce important fluxes of mass, momentum, heat, and moisture\".<ref name=\"Hartmann\"/>  The scales at which these fluxes are set come about are usually much smaller than GCM grids.  However, these fluxes are often greater than those of the synoptic flow.  Parameterizations of clouds and convection aim to address the scaling differences between GCM grids and cloud/convective scales.<ref name=\"Hartmann\"/>\n\nGCM cloud parameterizations account for at least two cloud types: convective clouds and large-scale supersaturation clouds. \"Large-scale supersaturation clouds occur when the relative humidity in a grid box at some model level exceeds a critical value\".<ref name=\"Hartmann\"/>  One way of accounting for large-scale supersaturation clouds is by setting the critical relative humidity value to 80%, assigning grid boxes with relative humidity values at or above 80% as cloud covered.  Another way to account for large-scale supersaturation clouds is to benchmark clouds via temperature variability, in that wherever the temperature \"causes the relative humidity to reach 100% is cloud covered\".<ref name=\"Hartmann\"/>\n\n===Moist adiabatic adjustment scheme===\nConvective clouds follow one of three general parameterization schemes.  The first scheme is moist adiabatic adjustment.  The main advantage of this method is that it is simple, in that if the moist adiabatic [[lapse rate]] is exceeded, moisture and heat within the vertical layer are adjusted so that air within the layer is saturated.<ref name=\"Hartmann\"/><ref name=\"Kalnay\">{{Cite book|last=Kalnay|first=Eugenia|title=Atmospheric modeling, data assimilation and predictability|publisher=[[Cambridge University Press]]|date=2003|pp=130–135|author-link=Eugenia Kalnay}}</ref> In turn the lapse rate is then adjusted to the moist adiabatic lapse rate, conserving energy, raining out excess moisture while not transporting momentum.  The disadvantage of this scheme is that it over-estimates convection, as constrains an entire grid box to act in a convective manner, unrealistic in the real atmosphere.<ref name=\"Hartmann\"/>\n\n===Kuo scheme===\nThe second scheme is the Kuo parameterization, and is more complex than the moist adiabatic adjustment scheme.<ref name=\"Hartmann\"/><ref name=\"Kalnay\"/>  This scheme is concerned with large-scale moisture convergence as the moisture source for convection.  A weakness of this scheme is convective heating, in that this parameterization scheme assumes that convection heats by mixing cloud and environmental air, instead of heating produced by subsidence between clouds.<ref name=\"Hartmann\"/>\n\n===Arakawa-Schubert scheme===\nThe Arakawa-Schubert scheme is the third scheme, and is the most comprehensive.<ref name=\"Hartmann\"/><ref name=\"Kalnay\"/>  This scheme models cumulus cloud/environment interactions, entrainment and detrainment of air/moisture, cloud downdrafts, and subsidence outside of clouds. Additionally, this scheme assumes quasi-equilibrium, with cloud dissipation at a \"rate sufficient to keep the atmosphere near equilibrium in the face of large-scale destabilization.\"<ref name=\"Hartmann\"/>\n\n== Turbulence closure ==\nMost atmospheric [[turbulence]] occurs within the ABL, whereas the free atmosphere is largely non-turbulent.  So, in order to have a proper accounting for motions within the ABL, GCMs must properly account for turbulence within the ABL.  To do this, GCMs must have some way of achieving turbulence closure.\n\nTurbulent processes can be roughly combined into three categories:  heat flux, moisture flux, and momentum flux.<ref name=\"Hartmann\"/> When calculating these fluxes, one ends up with more unknowns than equations, which means those equations cannot be solved directly.  In order to calculate turbulent fluxes and close the equations, one must make parameterizations for the higher order terms.  The sections below describe methods for parameterizing turbulent fluxes and turbulence closure.\n\n===Parameterizations===\n\n===Local and non-local closure===\nThere are two methods of parameterizing turbulent fluxes.  The first is local closure.  Local closure ties the unknown turbulent quantity at a specific point in space to values and gradients of known quantities at the same point.  Additionally, local closure likens turbulent transport to molecular diffusion, and is usually first or second order.<ref name=\"Stull\"/>\n\nThe second method of parameterizing turbulent fluxes is nonlocal closure.  Turbulence does not just depend on local values and gradients due to the superposition of many individual eddies.  Unlike local closure, nonlocal closure links unknown turbulent quantities to known quantities at many points in space.<ref name=\"Stull\"/>\n\n===K-theory===\nK-theory (eddy diffusivity/viscosity theory) is a form of local closure, and is the main first order closure scheme within the surface layer. K-theory follows a similar concept as molecular viscosity, in that the turbulent flux of a quantity is proportional to its spatial gradient, with K as the eddy viscosity/diffusivity. K-theory is powerful because the flux of quantities can be directly tied into the gradient of the mean quantities with height, multiplied by a value K. The idea behind K-theory is that turbulence eliminates gradients, creating a net flow of quantities down their gradients.<ref name=\"Stull\"/>  So K is positive.  \n\n{| class=\"wikitable\"\n|-\n! !! Turbulent flux !! Gradient\n|-\n| <math>\\tau_x =</math> || <math>-\\rho\\overline{u'w'}=</math> || <math>\\rho K_m \\mathrm{d}\\overline{u}/\\mathrm{d}z</math>\n|-\n| <math>\\tau_y =</math> || <math>-\\rho\\overline{v'w'}=</math> || <math>\\rho K_m \\mathrm{d}\\overline{v}/\\mathrm{d}z</math>\n|-\n| <math>H_v =</math> || <math>\\rho\\,C_p\\overline{w'\\theta'} =</math> || <math>-\\rho K_H \\mathrm{d}\\overline{\\theta}/\\mathrm{d}z</math>\n|-\n| <math>E =</math> || <math>\\rho\\overline{w'q'} =</math> || <math>-\\rho K_w \\mathrm{d}\\overline{q}/\\mathrm{d}z</math>\n|}\nThe eddy diffusivity/viscosity equations are shown in the table above.  K<sub>m</sub> represents eddy viscosity, while K<sub>H</sub> and K<sub>W</sub> represent eddy diffusivity of heat and moisture, respectively.  τ<sub>x</sub> and τ<sub>y</sub> represent Reynolds stress (momentum flux) in the x and y directions, H<sub>v</sub> represents the turbulent heat flux, and E represents the turbulent moisture flux.  ρ is the density of air, u', v', and w' are velocity perturbations, and θ' and q' are potential temperature and moisture perturbations. Other key points regarding K:<ref name=\"Stull\"/>\n* K = 0 when flow is laminar\n* K = 0 at the surface\n* K increases as TKE (turbulent kinetic energy) increases\n* K varies with static stability\n* K is non-negative, with turbulent fluxes flowing down-gradient\n\n[[File:Diagram of eddy diffusivity.jpg|thumbnail|right|Diagram of eddy diffusivity]]\nK-theory is best applied in statically neutral environments, with predominantly mechanically-generated turbulence, though it has been applied to statically stable environments.<ref name=\"Stull\"/>  The figure to the right demonstrates how temperature flux works in a stable environment.  If a parcel is displaced upward in a stable environment, w' is positive 0, and θ' is greater than the mean θ.  So w'θ' is greater than zero.  Conversely, when a parcel is displaced downward, w' is negative, and θ' is negative.\n\nDepending on the vertical resolution of the model, K-theory may be used to account for the various fluxes within the ABL.<ref name=\"Hartmann\"/><ref name=\"Kalnay\"/>  Additionally, K-theory can be applied in unstable conditions within the mixed layer if a counter-gradient term is applied, which accounts for buoyancy-driven turbulence.\n\n===Bulk aerodynamic formulae===\n[[File:Bulk aerodynamic formulas.jpg|thumb|center|Bulk aerodynamic formulae]]\nAs an alternative to K-theory, ABL fluxes can be accounted for through the use of bulk aerodynamic formulae.<ref name=\"Hartmann\"/>\n\nThe bulk aerodynamic formulae use C<sub>d</sub>, C<sub>h</sub>, and C<sub>q</sub>, where C<sub>d</sub> is the drag coefficient, C<sub>h</sub> is the heat exchange (transfer) coefficient, and C<sub>q</sub> is the moisture exchange (transfer) coefficient.<ref name=\"Kalnay\"/>  Each of these coefficients are functions of the known variables, such as the average wind speed at 10m, and average potential temperature and moisture at the surface and 10m.  Additionally, each of these coefficients varies based on stability. From the known variables the exchange coefficients can be easily calculated, and thus, the fluxes can be easily calculated as well.  The image below shows the equations used for calculating the exchange coefficients and fluxes, with u<sub>*</sub> as the frictional velocity.<ref name=\"Stull\"/>\n\n== References ==\n{{reflist}}\n\n[[Category:Boundary layer meteorology]]"
    },
    {
      "title": "Surface layer",
      "url": "https://en.wikipedia.org/wiki/Surface_layer",
      "text": "{{short description|The layer of a turbulent fluid most affected by interaction with a solid surface or the surface separating a gas and a liquid where the characteristics of the turbulence depend on distance from the interface}}\n[[Image:Surface layer.jpg|thumb|400px|The surface layer is the layer in a fluid where the scale of turbulent [[eddies|eddy]] is limited by the eddies' proximity to an interface. The objects highlighted in white above are turbulent eddies whose size is constrained by the proximity of the center of each eddy to the surface.]]\n\nThe '''surface layer''' is the layer of a turbulent fluid most affected by interaction with a solid surface or the surface separating a gas and a liquid where the characteristics of the [[turbulence]] depend on distance from the interface. Surface layers are characterized by large normal [[gradient]]s of [[tangential]] [[velocity]] and large concentration gradients of any substances ([[temperature]], [[moisture]], [[sediments]] et cetera) [[transport]]ed to or from the interface.\n\nThe term '''[[boundary layer]]''' is used in [[meteorology]] and in [[oceanography|physical oceanography]]. The atmospheric surface layer is the lowest part of the [[atmospheric boundary layer]] (typically the bottom 10% where the [[log wind profile]] is valid). The ocean has two surface layers: the [[benthic]], found immediately above the [[sea floor]] and the [[marine (ocean)|marine]] surface layer, at the air-sea [[Interface (chemistry)|interface]].\n\n==Mathematical Formulation==\nA simple [[Mathematical model|model]] of the surface layer can be derived by first examining the turbulent momentum flux through a surface.<ref name=\"Holton\">{{cite book |last=Holton |first=James R. |url=https://books.google.com/books?hl=en&id=fhW5oDv3EPsC |title=Dynamic Meteorology |edition=4th |series=International Geophysics Series |volume=88 |year=2004 |publisher=Elsevier Academic Press |location=Burlington, MA |pages=129–130 |chapter=Chapter 5 - The Planetary Boundary Layer }}</ref>\nUsing Reynolds Decomposition to express the horizontal flow in the <math>x</math> direction as the sum of a slowly varying component,<math>\\overline{u}</math>, and a turbulent component,<math>\\ u'</math>,:\n\n<math> u = \\overline{u} + u'</math> <ref name=\"reynolds\">{{cite news|url=http://www.eng.fsu.edu/~dommelen/courses/flm/flm00/topics/turb/node2.html |title=Reynolds Decomposition | publisher=[[Florida State University]] | date=6 December 2008 | accessdate=2008-12-06}}</ref>\n\nand the vertical flow, <math>\\ w</math>, in an analogous fashion:\n\n<math> w = \\overline{w} + w' </math>\n\nwe can express the flux of turbulent momentum through a surface, <math>\\ u_*</math> as the time averaged magnitude of vertical turbulent transport of horizontal turbulent momentum, <math>\\ u'w'</math>:\n\n<math> u_*^2  = \\left|\\overline{(u'w')_s} \\right|</math>.\n\nIf the flow is homogeneous within the region, we can set the product of the vertical gradient of the mean horizontal flow and the eddy viscosity coefficient <math>\\ K_m</math> equal to <math>\\ u_*^2</math>:\n\n<math>\\ K_m\\frac{\\partial \\overline{u}}{\\partial z} = u_*^2 </math>,\n\nwhere <math>\\ K_m</math> is defined in terms of [[Ludwig Prandtl|Prandtl]]'s mixing length hypothesis:\n\n<math>\\ K_m = \\overline{\\xi'^2}\\left |\\frac{\\partial\\overline{u}}{\\partial z}\\right |</math>\n\nwhere <math>\\ \\xi'</math> is the mixing length.\n\nWe can then express <math>\\ u_*</math> as:\n\n<math>\\frac{\\partial \\overline{u}}{\\partial z} = \\frac{u_*}{\\overline{\\xi'}}</math>.\n\n==Assumptions about the mixing length==\nFrom the figure above, we can see that the size of a turbulent eddy near the surface is constrained by its proximity to the surface; turbulent eddies centered near the surface cannot be as large as those centered further from the surface. From this consideration, and in neutral conditions, it is reasonable to assume that the [[Mixing length theory|mixing length]], <math>\\ \\xi'</math> is proportional to the eddy's depth in the surface:\n\n<math>\\ \\xi' = kz</math>,\n\nwhere <math>\\ z</math> is the depth and <math>\\ k</math> is known as the [[Theodore von Kármán|von Kármán]] constant. Thus the gradient can be integrated to solve for <math>\\ \\overline{u}</math>:\n\n<math>\\overline{u} = \\frac{u_*}{k}\\ln\\frac{z}{z_o}</math>.\n\nSo we see that the mean flow in the surface layer has a [[logarithm]]ic relationship with depth. In non-neutral conditions the mixing length is also affected by buoyancy forces and [[Monin-Obukhov similarity theory]] is required to describe the horizontal-wind profile.\n\n==The Surface layer in oceanography==\nThe surface layer is studied in oceanography,<ref name=\"whoi\">{{cite news|url=http://cofdl.whoi.edu/ |title=Coastal & Ocean Fluid Dynamics Laboratory | publisher=[[Woods Hole Oceanographic Institution|WHOI]] | date=10 December 2008 | accessdate=2008-12-10}}</ref> as both the [[wind stress]] and action of surface waves can cause turbulent mixing necessary for the formation of a surface layer.\n\nThe world's oceans are made up of many different [[water mass]]es. Each have particular temperature and salinity characteristics as a result of the location in which they formed. Once formed at a particular source, a water mass will travel some distance via large-scale ocean circulation. Typically, the flow of water in the ocean is described as turbulent (i.e. it doesn't follow straight lines). Water masses can travel across the ocean as turbulent eddies, or parcels of water usually along constant density (isopycnic) surfaces where the expenditure of energy is smallest. When these turbulent eddies of different water masses interact, they will mix together. With enough mixing, some stable equilibrium is reached and a mixed layer is formed.<ref name=\"Ocean Circulation\">{{cite web |url=http://www.sciencedirect.com/science/book/9780750652780 |title=Ocean Circulation | publisher=[[Open University]] | date=2001}}</ref> Turbulent eddies can also be produced from wind stress by the atmosphere on the ocean. This kind of interaction and mixing through buoyancy at the surface of the ocean also plays a role in the formation of a surface mixed layer.\n\n===Discrepancies with traditional theory===\nThe logarithmic flow profile has long been observed in the ocean, but recent, highly sensitive measurements reveal a sublayer within the surface layer in which turbulent eddies are enhanced by the action of surface waves.<ref name = \"craig\">{{cite journal | doi = 10.1175/1520-0485(1994)024<2546:MWETIT>2.0.CO;2 | last = Craig | first = Peter D. |author2=Michael L. Banner  | title = Modeling Wave-Enhanced Turbulence in the Ocean Surface Layer | journal = Journal of Physical Oceanography | volume = 24 | issue = 12 | pages = 2546–2559 | year = 1994 |bibcode = 1994JPO....24.2546C }}</ref>\nIt is becoming clear that the surface layer of the ocean is only poorly modeled as being up against the \"wall\" of the air-sea interaction.<ref name = \"Agrawal\">{{cite journal|last1=Agrawal|first1=Y. C.|last2=Terray|first2=E. A.|last3=Donelan|first3=M. A.|last4=Hwang|first4=P. A.|last5=Williams|first5=A. J.|last6=Drennan|first6=W. M.|last7=Kahma|first7=K. K.|last8=Krtaigorodskii|first8=S. A.|title=Enhanced dissipation of kinetic energy beneath surface waves|journal=Nature|volume=359|issue=6392|year=1992|pages=219–220|issn=0028-0836|doi=10.1038/359219a0|bibcode=1992Natur.359..219A}}</ref>\nObservations of turbulence in Lake Ontario reveal under wave-breaking conditions the traditional theory significantly underestimates the production of turbulent kinetic energy within the surface layer.<ref name=\"Agrawal\"/>\n\n===Diurnal cycle===\nThe depth of the surface mixed layer is affected by solar insolation and thus is related to the diurnal cycle. After nighttime convection over the ocean, the turbulent surface layer is found to completely decay and restratify. The decay is caused by the decrease in solar [[insolation]], divergence of turbulent flux and relaxation of lateral gradients.<ref name = \"Caldwell\">{{cite journal|last1=Caldwell|first1=D. R.|last2=Lien|first2=R-C.|last3=Moum|first3=J. N.|last4=Gregg|first4=M. C.|title=Turbulence Decay and Restratification in the Equatorial Ocean Surface Layer following Nighttime Convection|journal=Journal of Physical Oceanography|volume=27|issue=6|year=1997|pages=1120–1132|issn=0022-3670|doi=10.1175/1520-0485(1997)027<1120:TDARIT>2.0.CO;2|bibcode=1997JPO....27.1120C}}</ref>\nDuring the nighttime, the surface ocean cools because the atmospheric circulation is reduced due to the change in heat with the setting of the sun each day. Cooler water is less buoyant and will sink. This buoyancy effect causes water masses to be transported to lower depths even lower those reached during daytime. During the following daytime, water at depth is restratified or un-mixed because of the warming of the sea surface and buoyancy driving the warmed water upward. The entire cycle will be repeated and the water will be mixed during the following nighttime.<ref name=\"Talley\">{{cite book |last=Talley |first=Lynne |authorlink=|title=Descriptive Physical Oceanography: An Introduction |edition=6th |year=2011 |publisher=Elsevier Academic Press |location=Burlington, MA |pages=74–76 |chapter=Chapter 4 - Typical Distributions of Water Characteristics }}</ref>\n\nIn general, the surface mixed layer only occupies the first 100 meters of the ocean but can reach 150 m in the end of winter. The diurnal cycle does not change the depth of the mixed layer significantly relative to the seasonal cycle which produces much larger changes in sea surface temperature and buoyancy. With several vertical profiles, one can estimate the depth of the mixed layer by assigning a set temperature or density difference in water between surface and deep ocean observations – this is known as the “threshold method”.<ref name=\"Talley\">{{cite book |last=Talley |first=Lynne |authorlink=|title=Descriptive Physical Oceanography: An Introduction |edition=6th |year=2011 |publisher=Elsevier Academic Press |location=Burlington, MA |pages=74–76 |chapter=Chapter 4 - Typical Distributions of Water Characteristics }}</ref>\n\nHowever, this diurnal cycle does not have the same effect in midlatitudes as it does at tropical latitudes. Tropical regions are less likely than midlatitude regions to have a mixed layer dependent on diurnal temperature changes. One study explored diurnal variability of the mixed layer depth in the Western Equatorial Pacific Ocean. Results suggested no appreciable change in the mixed layer depth with the time of day. The significant precipitation in this tropical area would lead to further stratification of the mixed layer.<ref name = \"Lukas\">{{cite journal | last = Lukas | first = Roger |author2=Lindstrom, Eric  | title = The Mixed Layer of the Western Equatorial Pacific Ocean | journal = Journal of Geophysical Research | volume = 96 | pages = 3343–3357 | year = 1991 | doi=10.1029/90jc01951|bibcode = 1991JGR....96.3343L }}</ref> Another study which instead focused on the Central Equatorial Pacific Ocean found a tendency for increased depths of the mixed layer during nighttime.<ref name = \"Gregg\">{{cite journal | last = Gregg | first = M. C. |author2=PETERS H. |author3=WESSON J. C. |author4=OAKEY N. S. |author5=SHAY T. J.  | title = Intensive measurements of turbulence and shear in the equatorial undercurrent | journal = Nature | volume = 318 | pages = 140–144 | year = 1985 | doi=10.1038/318140a0|bibcode = 1985Natur.318..140G }}</ref> The extratropical or midlatitude mixed layer was shown in one study to be more affected by diurnal variability than the results of the two tropical ocean studies. Over a 15-day study period in Australia, the diurnal mixed layer cycle repeated in a consistent manner with decaying turbulence throughout the day.<ref name = \"Caldwell\"/>\n\n== See also ==\n*[[Boundary layer]]\n*[[Mixed layer]]\n*[[Density]]\n*[[Salinity]]\n\n==References==\n<!-- this 'empty' section displays references defined elsewhere -->\n{{reflist}}\n\n{{DEFAULTSORT:Surface Layer}}\n[[Category:Boundary layer meteorology]]\n[[Category:Oceanography]]"
    },
    {
      "title": "Valley exit jet",
      "url": "https://en.wikipedia.org/wiki/Valley_exit_jet",
      "text": "A '''valley exit jet''' is a strong, down-valley, elevated air current that emerges above the intersection of the valley and its adjacent plain. These winds frequently reach a maximum of {{convert|20|m/s|mph|abbr=on}} at a height of {{convert|40-200|m|abbr=on}} above the ground. Surface winds below the jet may sway vegetation but are significantly weaker.\n\nThe presence of these strong nighttime down-valley air flows has been documented at the mouth of many Alpine valleys that merge with basins, such as the Inn Valley of Austria, where the jet is strong enough to be heard at the ground. In the United States, exit jet signatures have been observed at the [[North Fork Gunnison River]] at [[Paonia, Colorado]]; the exit of [[South Boulder Creek (Colorado)|South Boulder Creek]] south of [[Boulder, Colorado]]; [[Albuquerque, New Mexico]] at the mouth of [[Tijeras Canyon]]; and the mouth of [[Spanish Fork River|Spanish Fork Canyon]] in [[Utah]].\n\n==Theory==\n \nExit jets are likely to be found in valley regions that exhibit diurnal mountain wind systems, such as those of the dry mountain ranges of the US. These diurnal wind systems are driven by horizontal pressure gradients. Due to the abrupt transition over a short distance between the valley high pressure and the basin low pressure, the gradients are strongest near the valley exit, producing a jet.\n\nOther meteorological factors acting to increase exit wind speeds are the acceleration of winds originating inside the valley as they travel to lower elevations downvalley, and the process of [[Katabatic wind|cold valley air sinking]] and ejecting into the plain. Deep valleys that terminate abruptly at a plain are more impacted by these factors than are those that gradually become shallower as downvalley distance increases.<ref>Whiteman, C. David (2000). ''Mountain Meteorology'', p. 193. Oxford University Press, New York. {{ISBN|978-0-19-513271-7}}, pp. 191–193.</ref>\n\n== Impacts ==\n \nValley exit jets can play a major role in the mitigation of [[air pollution]]:                   \n* Airflow emerging into the basin is cleaner due to lower aerosol content\n* Vertical mixing resulting from directional shear and from the convergence of the jet with basin scale flows reduces ozone and other pollutants.\n* Surface eddies created near canyon mouths inhibit the transport of pollution.<ref>Darby, L.S., and R.M. Banta (2006) ''The modulation of canyon flows by larger-scale influences''. Preprints, 12th Conf. on Mountain Meteorology. Amer. Meteor. Soc., 14-4.</ref>\n\nMethods of examining exit jets include remote sensing and direct observation. [[SODAR]] and [[Doppler effect|Doppler]] [[LIDAR]] have been used in numerous studies to identify, quantify and relate the jets to atmospheric transport of hazardous materials.<ref>Banta, R.M., L.D. Olivier, P.H. Gudiksen, and R. Lange, (1996). ''Implications of small-scale flow features to modeling dispersion over complex terrain''. J. Appl. Meteorol., 35:3, 330-342.</ref>  Detailed profiles of winds at canyon exits can be directly observed and calculated using a single or double [[theodolite]] and [[tethersonde]]s.\n\nThe identification and measurement of valley exit jets can also significantly aid in fire control, as fire often rides valley jets, as well as the development of wind energy.\n\n== References ==\n\n<references/>\n\n[[Category:Atmospheric dynamics]]\n[[Category:Mountain meteorology]]\n[[Category:Boundary layer meteorology]]"
    },
    {
      "title": "Von Kármán constant",
      "url": "https://en.wikipedia.org/wiki/Von_K%C3%A1rm%C3%A1n_constant",
      "text": "In [[fluid dynamics]], the '''von Kármán constant''' (or '''Kármán's constant'''), named for [[Theodore von Kármán]], is a [[dimensionless]] constant involved in the [[logarithm]]ic law describing the distribution of the longitudinal velocity in the wall-normal direction of a turbulent [[fluid flow]] near a boundary with a [[no-slip condition]].  The equation for such [[boundary layer]] flow profiles is:\n\n:<math>u=\\frac{u_{\\star}}{\\kappa}\\ln\\frac{z}{z_0},</math>\n\nwhere ''u'' is the mean [[flow velocity]] at height ''z'' above the boundary. The roughness height (also known as [[roughness length]]) ''z<sub>0</sub>'' is where <math>u</math> appears to go to zero. Further ''κ'' is the von Kármán constant being typically 0.41, and <math>u_\\star</math> is the [[friction velocity]] which depends on the [[shear stress]] ''τ<sub>w</sub>'' at the boundary of the flow:\n\n:<math>u_\\star = \\sqrt{\\frac{\\tau_w}{\\rho}},</math>\n\nwith ''ρ'' the fluid [[density]].\n\nThe Kármán constant is often used in [[turbulence modeling]], for instance in boundary-layer [[meteorology]] to calculate [[flux]]es of [[momentum]], heat and moisture from the atmosphere to the land surface. It is considered to be a universal (''κ'' ≈ 0.40).\n\nGaudio, Miglio and [[Subhasish Dey|Dey]] argued that the Kármán constant is however nonuniversal in flows over mobile sediment beds.\n\nIn recent years the von Kármán constant has been subject to periodic scrutiny. Reviews (Foken, 2006; Hogstrom, 1988; Hogstrom, 1996) report values of ''κ'' between 0.35 and 0.42. The overall conclusion of over 18 studies is that ''κ'' is constant, close to 0.40.\n\n==See also==\n*[[Law of the wall]]\n*[[Log wind profile]]\n\n==References==\n*Bonan, G. B. (2005). ''\"Land Surface Model (LSM 1.0) for Ecological, Hydrological, Atmospheric Studies. Model product\"''. Available on-line [http://daac.ornl.gov] from Oak Ridge National Laboratory Distributed Active Archive Center, Oak Ridge, Tennessee, U.S.A.\n*Foken T. (2006). \"50 years of the Monin-Obukhov similarity theory\". ''Boundary-Layer Meteorology'', Vol. 119, 431-447.\n*Gaudio, R. Miglio, R. and Dey, S. (2010). \"Nonuniversality of von Kármán’s κ in fluvial streams\". ''Journal of Hydraulic Research'', International Association for Hydraulic Research (IAHR), Vol. 48, No. 5, 658-663\n*Hogstrom U (1996). \"Review of some basic characteristics of the atmospheric surface layer\". ''Boundary-Layer Meteorology'', Vol. 78, 215-246.\n*Hogstrom U (1988). \"Non-dimensional wind and temperature profiles in the atmospheric surface layer-a re-evaluation\". ''Boundary Layer Meteorology'', Vol. 42, 55-78.\n\n==External links==\n* http://www.ccsm.ucar.edu/models/ccsm3.0/cpl6/users_guide/node21.html a list of physical constants used in the NCAR Community Climate System Model\n\n{{DEFAULTSORT:Von Karman constant}}\n[[Category:Boundary layer meteorology]]\n[[Category:Turbulence]]"
    },
    {
      "title": "Wind profile power law",
      "url": "https://en.wikipedia.org/wiki/Wind_profile_power_law",
      "text": "The '''wind profile power law''' is a relationship between the wind speeds at one height, and those at another.\n\n==Definition==\n\nThe wind profile power law relationship is :\n\n:<math>\\frac{u}{u_r} = \\bigg(\\frac{z}{z_r} \\bigg)^\\alpha</math>\n\nwhere <math>u</math> is the wind speed (in metres per second) at height <math>z</math> (in metres), and <math>u_r</math> is the known wind speed at a reference height <math>z_r</math>. The exponent (<math>\\alpha</math>) is an empirically derived coefficient that varies dependent upon the stability of the atmosphere.  For [[Air pollution dispersion terminology|neutral stability]] conditions, <math>\\alpha</math> is approximately 1/7, or 0.143.\n\nIn order to estimate the wind speed at a certain height ''z'', the relationship would be rearranged to:\n\n:<math>u = u_r\\bigg(\\frac{z}{z_r} \\bigg)^\\alpha</math>\n\nThe value of 1/7 for α is commonly assumed to be constant in wind resource assessments, because the differences between the two levels are not usually so great as to introduce substantial errors into the estimates (usually < 50 m).  However, when a constant exponent is used, it does not account for the roughness of the surface, the displacement of calm winds from the surface due to the presence of obstacles (i.e., zero-plane displacement), or the stability of the atmosphere.<ref>Touma, J.S., 1977, ''Dependence of the wind profile power law on stability for various locations'', J. Air Pollution Control Association, Vol. 27, pp. 863-866</ref><ref>Counihan, J., 1975, ''Adiabatic atmospheric boundary layers: A review and analysis of data from the period 1880-1972'', Atmospheric Environment, Vol.79, pp. 871-905</ref> In places where trees or structures impede the near-surface wind, the use of a constant 1/7 exponent may yield quite erroneous estimates, and the [[log wind profile]] is preferred. Even under neutral stability conditions, an exponent of 0.11 is more appropriate over open water (e.g., for offshore wind farms), than 0.143,<ref>Hsu, S.A., E.A. Meindl, and D.B. Gilhousen, 1994, ''Determining the power-law wind-profile exponent under near-neutral stability conditions at sea'', J. Appl. Meteorol., Vol. 33,  pp. 757-765</ref> which is more applicable over open land surfaces.\n\n==Limits==\n\nThe wind profile of the atmospheric [[boundary layer]] (surface to around 2000 metres) is generally logarithmic in nature and is best approximated using the [[log wind profile]] equation that accounts for surface roughness and atmospheric [[Air pollution dispersion terminology|stability]]. The relationships between surface power and wind are often used as an alternative to logarithmic wind features when surface roughness or stability information is not available.\n\n==Applications==\n\nThe power law is often used in [[wind power]] assessments<ref>Elliott, D.L., C.G. Holladay, W.R. Barchet, H.P. Foote, and W.F. Sandusky, 1986, Pacific Northwest Laboratory, Richland, WA. [http://rredc.nrel.gov/wind/pubs/atlas/ Wind Energy Resource Atlas of the United States]</ref><ref>Peterson, E.W. and J.P. Hennessey, Jr., 1978, ''On the use of power laws for estimates of wind power potential'', J. Appl. Meteorology, Vol. 17, pp. 390-394</ref> where wind speeds at the height of a turbine (\n<math>\\ge </math> 50 metres) must be estimated from near surface wind observations (~10 metres), or where wind speed data at various heights must be adjusted to a standard height<ref>Robeson, S.M., and Shein, K.A., 1997, ''Spatial coherence and decay of wind speed and power in the north-central United States'', Physical Geography, Vol. 18, pp. 479-495</ref> prior to use. Wind profiles are generated and used in a number of [[List of atmospheric dispersion models|atmospheric pollution dispersion models]].<ref>{{cite book|author=Beychok, Milton R.|title=[[Fundamentals Of Stack Gas Dispersion]]|edition=4th|publisher=author-published|year=2005|isbn=0-9644588-0-2}}</ref>\n\n===Wind power density===\n\nEstimates of wind power density are presented as wind class, ranging from 1 to 7. The speeds are average wind speeds over the course of a year,<ref>[http://rredc.nrel.gov/wind/pubs/atlas/tables/A-8T.html Classes of wind power density at 10 m and 50 m]</ref> although the frequency distribution of wind speed can provide different power densities for the same average wind speed.<ref>[http://rredc.nrel.gov/wind/pubs/atlas/tables/1-2T.html Comparison of annual average wind power at three sites with identical wind speeds.]</ref>\n\n{| class=\"wikitable\" border=\"1\"\n|-\n! rowspan=2|Class\n! colspan=2|10&nbsp;m (33&nbsp;ft)\n! colspan=2|30&nbsp;m (98&nbsp;ft)\n! colspan=2|50&nbsp;m (164&nbsp;ft)\n|-\n! Wind power density (W/m<sup>2</sup>)\n! Speed m/s (mph)\n! Wind power density (W/m<sup>2</sup>)\n! Speed m/s (mph)\n! Wind power density (W/m<sup>2</sup>)\n! Speed m/s (mph)\n|-\n| 1\n| 0 - 100\n| 0 - 4.4<br>(0 - 9.8)\n| 0 - 160\n| 0 - 5.1<br>(0 - 11.4)\n| 0 - 200\n| 0 - 5.6<br>(0 - 12.5)\n|-\n| 2\n| 100 - 150\n| 4.4 - 5.1<br>(9.8 - 11.5)\n| 160 - 240\n| 5.1 - 5.9<br>(11.4 - 13.2)\n| 200 - 300\n| 5.6 - 6.4<br>(12.5 - 14.3)\n|-\n| 3\n| 150 - 200\n| 5.1 - 5.6<br>(11.5 - 12.5)\n| 240 - 320\n| 5.9 - 6.5<br>(13.2 - 14.6)\n| 300 - 400\n| 6.4 - 7.0<br>(14.3 - 15.7)\n|-\n| 4\n| 200 - 250\n| 5.6 - 6.0<br>(12.5 - 13.4)\n| 320 - 400\n| 6.5 - 7.0<br>(14.6 - 15.7)\n| 400 - 500\n| 7.0 - 7.5<br>(15.7 - 16.8)\n|-\n| 5\n| 250 - 300\n| 6.0 - 6.4<br>(13.4 - 14.3)\n| 400 - 480\n| 7.0 - 7.4<br>(15.7 - 16.6)\n| 500 - 600\n| 7.5 - 8.0<br>(16.8 - 17.9)\n|-\n| 6\n| 300 - 400\n| 6.4 - 7.0<br>(14.3 - 15.7)\n| 480 - 640\n| 7.4 - 8.2<br>(16.6 - 18.3)\n| 600 - 800\n| 8.0 - 8.8<br>(17.9 - 19.7)\n|-\n| 7\n| 400 - 1000\n| 7.0 - 9.4<br>(15.7 - 21.1)\n| 640 - 1600\n| 8.2 - 11.0<br>(18.3 - 24.7)\n| 800 - 2000\n| 8.8 - 11.9<br>(19.7 - 26.6)\n|}\n\n==See also==\n* [[Log wind profile]]\n\n==References==\n{{reflist}}\n\n{{Wind power}}\n\n[[Category:Atmospheric dispersion modeling]]\n[[Category:Boundary layer meteorology]]\n[[Category:Wind power]]"
    },
    {
      "title": "Yamartino method",
      "url": "https://en.wikipedia.org/wiki/Yamartino_method",
      "text": "The '''Yamartino method''' is an algorithm for calculating an approximation of [[wind direction]] during a single pass through the incoming data.<ref>\n{{cite journal\n | author = Yamartino, R.J.\n | year = 1984\n | title = A Comparison of Several \"Single-Pass\" Estimators of the Standard Deviation of Wind Direction\n | journal = Journal of Climate and Applied Meteorology\n | volume = 23 | issue = 9 | pages = 1362–1366\n | bibcode = 1984JApMe..23.1362Y\n | doi = 10.1175/1520-0450(1984)023<1362:ACOSPE>2.0.CO;2\n}}</ref> \n\n==Background==\nThe standard deviation of wind direction is a measure of lateral [[turbulence]] and is used in a method for estimating the [[Air pollution dispersion terminology#The Pasquill atmospheric stability classes|Pasquill stability category]] in air pollution dispersion.\n\nThe simple method for calculating standard deviation requires two passes through the list of values. The first pass determines the average of those values; the second pass determines the sum of the squares of the differences between the values and the average. This double-pass method requires access to all values. A [[Standard deviation#Rapid calculation methods|single-pass method]] can be used for normal data but is unsuitable for [[Polar coordinate system|angular]] data such as wind direction where the 0°/360° (or ±180°) discontinuity forces special consideration. For example, the directions 1°, 0°, and 359° (or −1°) should not average to the direction 180°.\n\nThe Yamartino method, introduced by Robert J. Yamartino in 1984, solves both problems. The [[United States Environmental Protection Agency]] (EPA) has chosen it as the preferred way to compute the standard deviation of wind direction.<ref>[http://www.epa.gov/scram001/guidance/met/mmgrma.pdf Meteorological Monitoring Guidance for Regulatory Modeling Applications (section 6.2.1)]</ref>\nA further discussion of the Yamartino method, along with other methods of estimating the standard deviation of wind direction can be found in Farrugia & Micallef.\n\nIt is possible to calculate the exact standard deviation in one pass. However, that method needs slightly more calculation effort.\n\n==Algorithm==\nOver the time interval to be averaged across, ''n'' measurements of wind direction (''θ'') will be made and two totals are accumulated without storage of the ''n'' individual values. At the end of the interval the calculations are as follows: with the average values of sin&nbsp;''θ'' and cos&nbsp;''θ'' defined as\n\n:<math>s_a = \\frac 1 n \\sum_{i=1}^n \\sin \\theta_i,</math>\n\n:<math>c_a = \\frac 1 n \\sum_{i=1}^n \\cos \\theta_i.</math>\n\nThen the average wind direction is given via the four-quadrant arctan(x,y) function as\n\n:<math>\\theta_a=\\arctan(c_a,s_a).</math>\n\nFrom twenty different functions for ''σ''<sub>''θ''</sub> using variables obtained in a single-pass of the wind direction data, Yamartino found the best function to be\n\n: <math>\\sigma_\\theta = \\arcsin (\\varepsilon) \\left[1+\\left(\\tfrac 2 {\\sqrt 3} -1\\right) \\varepsilon^3\\right], </math>\n\nwhere\n\n:<math>\\varepsilon=\\sqrt{1-(s^2_a+c^2_a)}.</math>\n\nThe key here is to remember that sin<sup>2</sup>''θ'' + cos<sup>2</sup>''θ'' = 1 so that for example, with a constant wind direction at any value of ''θ'', the value of <math>\\varepsilon</math> will be zero, leading to a zero value for the standard deviation.\n \nThe use of <math>\\varepsilon</math> alone produces a result close to that produced with a double-pass when the dispersion of angles is small (not crossing the discontinuity), but by construction it is always between 0 and 1.  Taking the [[arcsine]] then produces the double-pass answer when there are just two equally common angles: in the extreme case of an oscillating wind blowing backwards and forwards, it produces a result of <math>\\tfrac{\\pi}{2}</math> radians, i.e. a [[right angle]].  The final factor adjusts this figure upwards so that it produces the double-pass result of <math>\\tfrac{\\pi}{\\sqrt{3}}</math> radians for an almost uniform distribution of angles across all directions, while making minimal change to results for small dispersions.\n\nThe theoretical maximum error against the correct double-pass ''σ''<sub>''θ''</sub> is therefore about 15% with an oscillating wind. Comparisons against Monte Carlo generated cases indicate that Yamartino's algorithm is within 2% for more realistic distributions.\n\nA variant might be to weight each wind direction observation by the wind speed at that time.\n\n==See also==\n* [[Algorithms for calculating variance]]\n* [[Directional statistics]]\n\n==References==\n{{reflist}}\n\n==Further reading==\n{{cite journal\n | author = P. S. Farrugia and A. Micallef\n | year = 2006\n | title = Comparative analysis of estimators for wind direction standard deviation\n | journal = [[Meteorological Applications]]\n | volume = 13 | issue = 1 | pages = 29–41\n | doi = 10.1017/S1350482705001982\n|bibcode = 2006MeApp..13...29F }}\n\n[[Category:Statistical algorithms]]\n[[Category:Boundary layer meteorology]]\n[[Category:Atmospheric dispersion modeling]]\n[[Category:Directional statistics]]"
    },
    {
      "title": "Perturbation (astronomy)",
      "url": "https://en.wikipedia.org/wiki/Perturbation_%28astronomy%29",
      "text": "{{merge from|Orbital_perturbation_analysis|discuss=Talk:Perturbation_(astronomy)#Merge_from_https://en.wikipedia.org/wiki/Orbital_perturbation_analysis|date=August 2018}}\n\n[[File:Moon perturbation diagram.svg|thumb|300px|alt=Vector diagram of the Sun's perturbations on the Moon. When the gravitational force of the Sun common to both the Earth and the Moon is subtracted, what is left is the perturbations.|The perturbing forces of the [[Sun]] on the [[Moon]] at two places in its [[orbit]]. The blue arrows represent the [[Euclidean vector|direction and magnitude]] of the gravitational force on the [[Earth]]. Applying this to both the Earth's and the Moon's position does not disturb the positions relative to each other. When it is subtracted from the force on the Moon (black arrows), what is left is the perturbing force (red arrows) on the Moon relative to the Earth. Because the perturbing force is different in direction and magnitude on opposite sides of the orbit, it produces a change in the shape of the orbit.]]\n\nIn [[astronomy]], '''perturbation''' is the complex motion of a [[astronomical object|massive body]] subject to forces other than the [[gravity|gravitational]] attraction of a single other [[mass]]ive [[physical body|body]].<ref>Bate, Mueller, White (1971): ch. 9, p. 385.</ref> The other forces can include a third (fourth, fifth, etc.) body, [[drag (physics)|resistance]], as from an [[atmosphere]], and the off-center attraction of an [[oblate spheroid|oblate]] or otherwise misshapen body.<ref name=\"moulton\"/>\n\n== Introduction ==\nThe study of perturbations began with the first attempts to predict planetary motions in the sky. In ancient times the causes were a mystery. [[Isaac Newton|Newton]], at the time he formulated his laws of [[Newton's laws of motion|motion]] and of [[Newton's law of universal gravitation|gravitation]], applied them to the first analysis of perturbations,<ref name=\"moulton\"/> recognizing the complex difficulties of their calculation.<ref>Newton in 1684 wrote: \"By reason of the deviation of the Sun from the center of gravity, the centripetal force does not always tend to that immobile center, and hence the planets neither move exactly in ellipses nor revolve twice in the same orbit. Each time a planet revolves it traces a fresh orbit, as in the motion of the Moon, and each orbit depends on the combined motions of all the planets, not to mention the action of all these on each other. But to consider simultaneously all these causes of motion and to define these motions by exact laws admitting of easy calculation exceeds, if I am not mistaken, the force of any human mind.\" (quoted by Prof G E Smith (Tufts University), in [http://google.com/search?q=cache:8RItNNOcJJoJ:www.stanford.edu/dept/cisst/SmithPowerpointTalk1.ppt \"Three Lectures on the Role of Theory in Science\"] 1. Closing the loop: Testing Newtonian Gravity, Then and Now); and Prof R F Egerton (Portland State University, Oregon) after quoting the same passage from Newton concluded: [http://physics.pdx.edu/~egertonr/ph311-12/newton.htm \"Here, Newton identifies the \"many body problem\" which remains unsolved analytically.\"] {{webarchive |url=https://web.archive.org/web/20050310192531/http://physics.pdx.edu/~egertonr/ph311-12/newton.htm |date=2005-03-10}}</ref> Many of the great mathematicians since then have given attention to the various problems involved; throughout the 18th and 19th centuries there was demand for accurate tables of the position of the [[Moon]] and [[planet]]s for [[marine navigation]].\n\nThe complex motions of gravitational perturbations can be broken down. The hypothetical motion that the body follows under the gravitational effect of one other body only is typically a [[conic section]], and can be readily described with the methods of [[geometry]]. This is called a [[two-body problem]], or an unperturbed [[Kepler orbit|Keplerian orbit]]. The differences between that and the actual motion of the body are '''perturbations''' due to the additional gravitational effects of the remaining body or bodies. If there is only one other significant body then the perturbed motion is a [[three-body problem]]; if there are multiple other bodies it is an [[n-body problem|''n''-body problem]]. A general analytical solution (a mathematical expression to predict the positions and motions at any future time) exists for the two-body problem; when more than two bodies are considered analytic solutions exist only for special cases. Even the two-body problem becomes insoluble if one of the bodies is irregular in shape.<ref name=\"roy\">Roy (1988): ch. 6, 7.</ref>\n\n[[File:Mercury perturbation comparison.png|thumb|300px|alt=Plot of Mercury's position in its orbit, with and without perturbations from various planets. The perturbations cause Mercury to move in looping paths around its unperturbed position.|[[Mercury (planet)|Mercury]]'s orbital longitude and latitude, as perturbed by [[Venus]], [[Jupiter]] and all of the planets of the [[Solar System]], at intervals of 2.5 days. Mercury would remain centered on the crosshairs if there were no perturbations.]]\n\nMost systems that involve multiple gravitational attractions present one primary body which is dominant in its effects (for example, a [[star]], in the case of the star and its planet, or a planet, in the case of the planet and its satellite). The gravitational effects of the other bodies can be treated as perturbations of the hypothetical unperturbed motion of the planet or [[satellite]] around its primary body.\n\n== Mathematical analysis ==\n\n=== General perturbations ===\nIn methods of '''general perturbations''', general differential equations, either of motion or of change in the [[orbital elements]], are solved analytically, usually by [[series expansion]]s. The result is usually expressed in terms of algebraic and trigonometric functions of the orbital elements of the body in question and the perturbing bodies. This can be applied generally to many different sets of conditions, and is not specific to any particular set of gravitating objects.<ref>Bate, Mueller, White (1971): p. 387; sec. 9.4.3, p. 410.</ref> Historically, general perturbations were investigated first. The classical methods are known as ''variation of the elements'', ''[[variation of parameters]]'' or ''variation of the constants of integration''. In these methods, it is considered that the body is always moving in a [[conic section]], however the conic section is constantly changing due to the perturbations. If all perturbations were to cease at any particular instant, the body would continue in this (now unchanging) conic section indefinitely; this conic is known as the [[osculating orbit]] and its [[orbital elements]] at any particular time are what are sought by the methods of general perturbations.<ref name=\"moulton\"/>\n\nGeneral perturbations takes advantage of the fact that in many problems of [[celestial mechanics]], the two-body orbit changes rather slowly due to the perturbations; the two-body orbit is a good first approximation. General perturbations is applicable only if the perturbing forces are about one order of magnitude smaller, or less, than the gravitational force of the primary body.<ref name=\"roy\"/> In the [[Solar System]], this is usually the case; [[Jupiter]], the second largest body, has a mass of about 1/1000 that of the [[Sun]].\n\nGeneral perturbation methods are preferred for some types of problems, as the source of certain observed motions are readily found. This is not necessarily so for special perturbations; the motions would be predicted with similar accuracy, but no information on the configurations of the perturbing bodies (for instance, an [[orbital resonance]]) which caused them would be available.<ref name=\"roy\"/>\n\n=== Special perturbations ===\nIn methods of '''special perturbations''', numerical datasets, representing values for the positions, velocities and accelerative forces on the bodies of interest, are made the basis of [[numerical integration]] of the differential [[equations of motion]].<ref>Bate, Mueller, White (1971), pp. 387–409.</ref> In effect, the positions and velocities are perturbed directly, and no attempt is made to calculate the curves of the orbits or the [[orbital elements]].<ref name=moulton>Moulton (1914): ch. IX</ref>\n\nSpecial perturbations can be applied to any problem in [[celestial mechanics]], as it is not limited to cases where the perturbing forces are small.<ref name=\"roy\"/> Once applied only to comets and minor planets, special perturbation methods are now the basis of the most accurate machine-generated [[Fundamental ephemeris|planetary ephemerides]] of the great astronomical almanacs.<ref name=\"moulton\"/><ref>See, for instance, [[Jet Propulsion Laboratory Development Ephemeris]].</ref> Special perturbations are also used for [[Orbit Modeling|modeling]] an orbit with computers.\n\n==== Cowell's formulation ====\n[[File:Cowells method.png|thumb|Cowell's method. Forces from all perturbing bodies (black and gray) are summed to form the total force on body ''i'' (red), and this is numerically integrated starting from the initial position (the ''epoch of osculation'').]]\n\nCowell's formulation (so named for [[Philip Herbert Cowell|Philip H. Cowell]], who, with A.C.D. Cromellin, used a similar method to predict the return of Halley's comet) is perhaps the simplest of the special perturbation methods.<ref>{{cite web |url=http://adsabs.harvard.edu/full/1911GOAMM..71O...1C |last1=Cowell |first1=P. H. |last2=Crommelin |first2=A. C. D. |title=Investigation of the Motion of Halley's Comet from 1759 to 1910 |publisher=Neill & Co. |location=Bellevue, for His Majesty's Stationery Office |date=1910 |bibcode=1911GOAMM..71O...1C}}</ref> In a system of <math>n</math> mutually interacting bodies, this method mathematically solves for the [[Newton's law of universal gravitation|Newtonian]] forces on body <math>i</math> by summing the individual interactions from the other <math>j</math> bodies:\n:<math>\\mathbf{\\ddot{r}}_i = \\sum_{\\underset{j \\ne i}{j=1}}^n {Gm_j (\\mathbf{r}_j-\\mathbf{r}_i) \\over r_{ij}^3}</math>\n\nwhere <math>\\mathbf{\\ddot{r}}_i</math> is the [[acceleration]] vector of body <math>i</math>, <math>G</math> is the [[gravitational constant]], <math>m_j</math> is the [[mass]] of body <math>j</math>, <math>\\mathbf{r}_i</math> and <math>\\mathbf{r}_j</math> are the [[position vector]]s of objects <math>i</math> and <math>j</math> respectively, and <math>r_{ij}</math> is the distance from object <math>i</math> to object <math>j</math>. All [[Euclidean vector#Physics|vectors]] being referred to the [[Center of mass#Astronomy|barycenter]] of the system. This equation is resolved into components in <math>x</math>, <math>y</math>, and <math>z</math> and these are integrated numerically to form the new velocity and position vectors. This process is repeated as many times as necessary. The advantage of Cowell's method is ease of application and programming. A disadvantage is that when perturbations become large in magnitude (as when an object makes a close approach to another) the errors of the method also become large.<ref name=\"danby\">\n{{cite book \n|last = Danby \n|first = J.M.A. \n| title = Fundamentals of Celestial Mechanics \n|publisher = Willmann-Bell, Inc. \n|edition = second |isbn = 0-943396-20-4 \n|date=1988}}, chapter 11.</ref> \nHowever, for many problems in [[celestial mechanics]], this is never the case. Another disadvantage is that in systems with a dominant central body, such as the [[Sun]], it is necessary to carry many [[Significant figures|significant digits]] in the [[arithmetic]] because of the large difference in the forces of the central body and the perturbing bodies, although with modern [[computer]]s this is not nearly the limitation it once was.<ref>\n{{cite book \n|last = Herget\n|first = Paul \n|title = The Computation of Orbits\n|publisher = privately published by the author\n|date=1948}}, p. 91 ff.</ref>\n\n==== Encke's method ====\n[[File:Enckes method-vector.svg|thumb|Encke's method. Greatly exaggerated here, the small difference  δ'''r''' (blue) between the osculating, unperturbed orbit (black) and the perturbed orbit (red), is numerically integrated starting from the initial position (the ''epoch of osculation'').]]\n\nEncke's method begins with the [[osculating orbit]] as a reference and integrates numerically to solve for the variation from the reference as a function of time.<ref>\n{{cite book \n|url=https://books.google.com/books?id=t5VCAQAAMAAJ&source=gbs_navlinks_s\n|last = Encke\n|first = J. F.\n|title = Über die allgemeinen Störungen der Planeten \n|work=Berliner Astronomisches Jahrbuch für 1857\n|date=1854\n|pages=319–397}}</ref> \nIts advantages are that perturbations are generally small in magnitude, so the integration can proceed in larger steps (with resulting lesser errors), and the method is much less affected by extreme perturbations. Its disadvantage is complexity; it cannot be used indefinitely without occasionally updating the osculating orbit and continuing from there, a process known as ''rectification''.<ref name=\"danby\"/> Encke's method is similar to the general perturbation method of variation of the elements, except the rectification is performed at discrete intervals rather than continuously.<ref>\nBattin (1999), sec. 10.2.</ref>\n\nLetting <math>\\boldsymbol{\\rho}</math> be the [[Position vector|radius vector]] of the [[osculating orbit]], <math>\\mathbf{r}</math> the radius vector of the perturbed orbit, and <math>\\delta \\mathbf{r}</math> the variation from the osculating orbit,\n\n{{NumBlk|:|<math>\\delta \\mathbf{r} = \\mathbf{r} - \\boldsymbol{\\rho}</math>, and the [[Equations of motion|equation of motion]] of <math>\\delta \\mathbf{r}</math> is simply|{{EquationRef|1}}}}\n\n{{NumBlk|:|<math>\\ddot{\\delta \\mathbf{r}} = \\mathbf{\\ddot{r}} - \\boldsymbol{\\ddot{\\rho}}</math>.|{{EquationRef|2}}}}\n\n<math>\\mathbf{\\ddot{r}}</math> and <math>\\boldsymbol{\\ddot{\\rho}}</math> are just the equations of motion of <math>\\mathbf{r}</math> and <math>\\boldsymbol{\\rho},</math>\n\n{{NumBlk|:|<math>\\mathbf{\\ddot{r}} = \\mathbf{a}_{\\text{per}} - {\\mu \\over r^3} \\mathbf{r}</math> for the perturbed orbit and |{{EquationRef|3}}}}\n\n{{NumBlk|:|<math>\\boldsymbol{\\ddot{\\rho}} = - {\\mu \\over \\rho^3} \\boldsymbol{\\rho}</math> for the unperturbed orbit,|{{EquationRef|4}}}}\n\nwhere <math>\\mu = G(M+m)</math> is the [[Standard gravitational parameter|gravitational parameter]] with <math>M</math> and <math>m</math> the [[mass]]es of the central body and the perturbed body, <math>\\mathbf{a}_{\\text{per}}</math> is the perturbing [[acceleration]], and <math>r</math> and <math>\\rho</math> are the magnitudes of <math>\\mathbf{r}</math> and <math>\\boldsymbol{\\rho}</math>.\n\nSubstituting from equations ({{EquationNote|3}}) and ({{EquationNote|4}}) into equation ({{EquationNote|2}}),\n\n{{NumBlk|:|<math>\\ddot{\\delta \\mathbf{r}} = \\mathbf{a}_{\\text{per}} + \\mu \\left( {\\boldsymbol{\\rho} \\over \\rho^3} - {\\mathbf{r} \\over r^3} \\right),</math> |{{EquationRef|5}}}}\n\nwhich, in theory, could be integrated twice to find <math>\\delta \\mathbf{r}</math>. Since the osculating orbit is easily calculated by two-body methods, <math>\\boldsymbol{\\rho}</math> and <math>\\delta \\mathbf{r}</math> are accounted for and <math>\\mathbf{r}</math> can be solved. In practice, the quantity in the brackets, <math> {\\boldsymbol{\\rho} \\over \\rho^3} - {\\mathbf{r} \\over r^3} </math>, is the difference of two nearly equal vectors, and further manipulation is necessary to avoid the need for extra [[Significant figures|significant digits]].<ref>\nBate, Mueller, White (1971), sec. 9.3.</ref><ref>\nRoy (1988), sec. 7.4.</ref> \nEncke's method was more widely used before the advent of modern [[computer]]s, when much orbit computation was performed on [[Calculating machine|mechanical calculating machines]].\n\n== Periodic nature ==\n[[File:Eccentricity rocky planets.jpg|thumb|300px|[http://www.orbitsimulator.com/gravity/articles/what.html Gravity Simulator] plot of the changing [[orbital eccentricity]] of [[Mercury (planet)|Mercury]], [[Venus]], [[Earth]], and [[Mars]] over the next 50,000 years. The 0 point on this plot is the year 2007.]]\n\nIn the Solar System, many of the disturbances of one planet by another are periodic, consisting of small impulses each time a planet passes another in its orbit. This causes the bodies to follow motions that are periodic or quasi-periodic &ndash; such as the Moon in its [[Lunar theory|strongly perturbed]] [[Orbit of the Moon|orbit]], which is the subject of [[lunar theory]]. This periodic nature led to the [[discovery of Neptune]] in 1846 as a result of its perturbations of the orbit of [[Uranus]].\n\nOn-going mutual perturbations of the planets cause long-term quasi-periodic variations in their [[orbital element]]s, most apparent when two planets' orbital periods are nearly in sync. For instance, five orbits of [[Jupiter]] (59.31 years) is nearly equal to two of [[Saturn]] (58.91 years). This causes large perturbations of both, with a period of 918 years, the time required for the small difference in their positions at [[Conjunction (astronomy and astrology)|conjunction]] to make one complete circle, first discovered by [[Pierre-Simon Laplace|Laplace]].<ref name=\"moulton\"/> [[Venus]] currently has the orbit with the least [[Orbital eccentricity|eccentricity]], i.e. it is the closest to [[Circle|circular]], of all the planetary orbits. In 25,000 years' time, [[Earth]] will have a more circular (less eccentric) orbit than Venus. It has been shown that long-term periodic disturbances within the [[Solar System]] can become chaotic over very long time scales; under some circumstances one or more [[planet]]s can cross the orbit of another, leading to collisions.<ref>see references at [[Stability of the Solar System]]</ref>\n\nThe orbits of many of the minor bodies of the Solar System, such as [[comet]]s, are often heavily perturbed, particularly by the gravitational fields of the [[gas giant]]s. While many of these perturbations are periodic, others are not, and these in particular may represent aspects of [[chaotic motion]]. For example, in April 1996, [[Jupiter]]'s gravitational influence caused the [[Orbital period|period]] of [[Comet Hale–Bopp]]'s orbit to decrease from 4,206 to 2,380 years, a change that will not revert on any periodic basis.<ref name=perturb>{{cite web |date=1997-04-10 |title=Comet Hale–Bopp Orbit and Ephemeris Information |publisher=JPL/NASA |author=Don Yeomans |url=http://www2.jpl.nasa.gov/comet/ephemjpl8.html |access-date=2008-10-23}}</ref>\n\n== See also ==\n* [[Nereid (moon)|Nereid]] one of the outer moons of Neptune with a high [[orbital eccentricity]] of ~0.75 and is frequently perturbed\n* [[Osculating orbit]]\n* [[Orbital resonance]]\n* [[Stability of the Solar System]]\n* [[Formation and evolution of the Solar System]]\n* [[Orbit modeling]]\n* [[Proper orbital elements]]\n\n== References ==\n;Bibliography\n*{{cite book |last1=Bate |first1=Roger R. |last2=Mueller |first2=Donald D. |last3=White |first3=Jerry E. |title=Fundamentals of Astrodynamics |publisher=[[Dover Publications]] |location=New York |isbn=0-486-60061-0 |date=1971}}\n*{{cite book |url=https://books.google.com/books?id=jqM5AAAAMAAJ&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false |title=An Introduction to Celestial Mechanics |edition=2nd revised |last=Moulton |first=Forest Ray |date=1914}}\n*{{cite book |last=Roy |first=A. E. |title=Orbital Motion |publisher=Institute of Physics Publishing |edition=3rd |isbn=0-85274-229-0 |date=1988}}\n\n;Footnotes\n{{Reflist}}\n\n== External links ==\n*[https://web.archive.org/web/20070907013516/http://main.chemistry.unina.it/~alvitagl/solex/MarsDist.html Solex] (by Aldo Vitagliano) predictions for the position/orbit/close approaches of Mars\n*[https://books.google.com/books?id=snK4AAAAIAAJ&source=gbs_navlinks_s Gravitation] Sir George Biddell Airy's 1884 book on gravitational motion and perturbations, using little or no math.(at [https://books.google.com/books Google books])\n\n{{Orbits}}\n\n[[Category:Orbital perturbations|*]]\n[[Category:Dynamical systems]]\n[[Category:Dynamics of the Solar System]]\n[[Category:Celestial mechanics]]"
    },
    {
      "title": "Variation (astronomy)",
      "url": "https://en.wikipedia.org/wiki/Variation_%28astronomy%29",
      "text": "{{See also|Lunar theory|Orbit of the Moon}}\nIn [[astronomy]], the '''variation of the Moon''' is one of the principal [[perturbation (astronomy)|perturbation]]s in the motion of the Moon.\n\n==Discovery==\nThe variation was discovered by [[Tycho Brahe]], who noticed that, starting from a [[lunar eclipse]] in December 1590, at the times of [[Syzygy (astronomy)|syzygy]] (new or full moon), the apparent velocity of motion of the Moon (along its orbit as seen against the background of stars) was faster than expected. On the other hand, at the times of first and last quarter, its velocity was correspondingly slower than expected.  (Those expectations were based on the lunar tables widely used up to Tycho's time.  They took some account of the two largest irregularities in the Moon's motion, i.e. those now known as the [[equation of the center]] and the [[evection]], see also [[Lunar theory#History|Lunar theory - History]].)<ref>V E Thoren, [http://articles.adsabs.harvard.edu/full/1967PASP...79..482T \"Tycho and Kepler on the Lunar theory\"], Publications of the Astronomical Society of the Pacific, vol.79 (1967), pp. 482-489, especially at p.485.  The discovery of the variation was made accidentally, after Tycho planned to observe the lunar eclipse of December 1590, and checked the Moon's position a day or two beforehand, to determine more exactly, as he thought, the starting time. But when he went out to observe just before the expected time, he found that he had missed the start of the eclipse.  The Moon was earlier by about an hour, the eclipse already in progress. Tycho's subsequent investigations pinned down the cause, a previously unrecognized inequality, since then called the variation.</ref>\n\n==Variation==\nThe main visible effect (in longitude) of the variation of the Moon is that during the course of every month, at the octants of the Moon's phase that follow the syzygies (i.e. halfway between the new or the full moon and the next-following quarter), the Moon is about two thirds of a degree farther ahead than would be expected on the basis of its mean motion (as modified by the equation of the centre and by the evection).  But at the octants that precede the syzygies, it is about two thirds of a degree behind.  At the syzygies and quarters themselves, the main effect is on the Moon's velocity rather than its position.\n\n[[image:Variation (astronomy).gif|frame|right|Variational orbit: nearly an ellipse, with the Earth at the center. The diagram illustrates the perturbing effect of the Sun on the Moon's orbit, using some simplifying approximations, e.g. that in the absence of the Sun, the Moon's orbit would be circular with the Earth at its center]]\nIn 1687 Newton published, in the '[[Philosophiæ Naturalis Principia Mathematica|Principia]]', his first steps in the gravitational analysis of the motion of [[Lunar theory#Newton|three mutually-attracting bodies]].  This included a proof that the Variation is one of the results of the perturbation of the motion of the Moon caused by the action of the Sun, and that one of the effects is to distort the Moon's orbit in a practically elliptical manner (ignoring at this point the eccentricity of the Moon's orbit), with the centre of the ellipse occupied by the Earth, and the major axis perpendicular to a line drawn between the Earth and Sun.\n\nThe Variation has a period of half a [[synodic month]] and causes the Moon's [[ecliptic longitude]] to vary by nearly two-thirds of a  [[degree (angle)|degree]], more exactly by +2370\"sin(2D) where D is the mean elongation of the Moon from the Sun.<ref>See [[Lunar theory#Delaunay arguments|Lunar theory - Delaunay arguments]].</ref>\n\nThe variational distortion of the Moon's orbit is a different effect from the eccentric elliptical motion of a body in an unperturbed orbit. The Variation effect would still occur if the undisturbed motion of the Moon had an [[eccentricity (orbit)|eccentricity]] of zero (i.e. [[circle|circular]]).  The eccentric [[Kepler orbit|Keplerian ellipse]] is another and separate approximation for the Moon's orbit, different from the approximation represented by the (central) variational ellipse.  The Moon's line of apses, i.e. the long axis of the Moon's orbit when approximated as an eccentric ellipse, rotates once in about nine years, so that it can be oriented at any angle whatever relative to the direction of the Sun at any season. (The angular difference between these two directions used to be referred to, in much older literature, as the \"annual argument of the Moon's apogee\".) Twice in every period of just over a year, the direction of the Sun coincides with the direction of the long axis of the eccentric elliptical approximation of the Moon's orbit (as projected on to the ecliptic).\n\n==Elliptical distortion==\nThus the (central) elliptical distortion of the Moon's orbit caused by the variation should not be confused with an undisturbed eccentric elliptical motion of an orbiting body. The variational effects due to the Sun would still occur even if the hypothetical undisturbed motion of the Moon had an eccentricity of zero (i.e. even if the orbit would be circular in the absence of the Sun).\n\nNewton expressed an approximate recognition that the real orbit of the Moon is not exactly an eccentric Keplerian ellipse, nor exactly a central ellipse due to the variation, but \"an oval of another kind\".<ref>D T Whiteside (ed.) (1973), ''The Mathematical papers of Isaac Newton, Volume VI: 1684-1691'', Cambridge University Press, [https://books.google.com/books?id=lIZ0v23iqRgC&pg=PA533&lpg=PA533 at page 533].</ref> Newton did not give an explicit expression for the form of this \"oval of another kind\"; to an approximation, it combines the two effects of the central-elliptical variational orbit and the Keplerian eccentric ellipse. Their combination also continually changes its shape as the annual argument changes, and also as the evection shows itself in libratory changes in the eccentricity, and in the direction, of the long axis of the eccentric ellipse.\n\nThe Variation is the second-largest solar perturbation of the Moon's orbit after the Evection, and the third-largest inequality in the motion of the Moon altogether; (the first and largest of the lunar inequalities is the [[equation of the centre]], a result of the eccentricity &ndash; which is not an effect of solar perturbation).\n\n==See also==\n*[[Evection]]\n\n==References==\n{{Reflist}}\n\n==Bibliography==\n*[[Ernest William Brown|Brown, E.W.]] ''An Introductory Treatise on the Lunar Theory.'' Cambridge University Press, 1896 (republished by Dover, 1960).\n*\n\n[[Category:Celestial mechanics]]\n[[Category:Orbital perturbations|*]]"
    },
    {
      "title": "Kozai mechanism",
      "url": "https://en.wikipedia.org/wiki/Kozai_mechanism",
      "text": "In [[celestial mechanics]], the '''Kozai mechanism''' or '''Lidov–Kozai mechanism''' or '''Kozai–Lidov mechanism''', also known as the '''Kozai''', '''Lidov–Kozai''' or '''Kozai–Lidov''' '''effect''', '''oscillations''', '''cycles''' or '''resonance''', is a dynamical phenomenon affecting the orbit of a [[binary system]] perturbed by a distant third body under certain conditions, causing the orbit's [[argument of pericenter]] to [[libration|oscillate about a constant value]], which in turn leads to a periodic exchange between its [[Orbital eccentricity|eccentricity]] and [[inclination]]. The process occurs on timescales much longer than the orbital periods. It can drive an initially near-circular orbit to arbitrarily high eccentricity, and ''flip'' an initially moderately inclined orbit between a [[Retrograde and prograde motion|prograde and a retrograde motion]].\n\nThe effect has been found to be an important factor shaping the orbits of [[irregular satellite]]s of the planets, [[trans-Neptunian object]]s, [[extrasolar planets]], and [[multiple star system]]s.<ref>Shevchenko 2017, p. v</ref> It is hypothesized to enable [[black hole merger]]s.<ref name=\"Tremaine2014\">Tremaine and Yavetz 2014</ref> It was first described in 1961 by [[Mikhail Lidov]] while analyzing the orbits of artificial and natural satellites of planets.<ref name=\"Lidov1961/62\">Lidov 1961, 1962</ref> In 1962, [[Yoshihide Kozai]] published this same result in application to the orbits of [[asteroid]]s perturbed by [[Jupiter]].<ref name=\"Kozai1962Paper\">Kozai 1962</ref> The citations of the initial papers by Kozai and Lidov have risen sharply in the 21st century. As of 2017, the mechanism is among the most studied astrophysical phenomena.<ref name=\"ShevchenkoCitations\">Shevchenko 2016, p. vi</ref>\n\n==Background==\n===Hamiltonian mechanics===\n{{main|Hamiltonian mechanics}}\nIn Hamiltonian mechanics, a physical system is specified by a function, called ''Hamiltonian'' and denoted <math display=\"inline\">\\mathcal{H}</math>, of [[canonical coordinates]] in [[phase space]]. The canonical coordinates consist of the [[generalized coordinates]] <math display=\"inline\">x_i</math> in [[Configuration space (physics)|configuration space]] and their [[conjugate momentum|conjugate momenta]] <math display=\"inline\">p_i</math>. The number of <math display=\"inline\">(x_i, p_i)</math> pairs required to describe a given system is the number of its [[degree of freedom|degrees of freedom]]. The coordinates are usually chosen in such a way as to simplify the calculations involved in solving a particular problem. One set of canonical coordinates can be changed to another by a [[canonical transformation]]. The [[equations of motion]] for the system are obtained from the Hamiltonian through ''Hamilton's canonical equations'', which relate time derivatives of the coordinates to partial derivatives of the Hamiltonian with respect to the conjugate momenta.\n\n===Orbital elements===\n{{main|Orbital elements}}\n[[Image:Orbit1.svg|thumb|200px|right|The Keplerian orbital elements]]\nAn elliptical orbit in three dimensions is uniquely described by a set of six coordinates, called [[orbital elements]]. The traditional choice are the [[Keplerian elements]], which consist of the [[orbital eccentricity|eccentricity]], [[semimajor axis]], [[inclination]], [[longitude of the ascending node]], [[argument of periapsis]], and [[true anomaly]]. In celestial mechanics calculations, it is common to use a set of orbital elements introduced in nineteenth century by [[Charles-Eugène Delaunay]].<ref>Shevchenko 2017, p. 17</ref> The Delaunay elements form a canonical set of [[action-angle coordinates]] and consist of the [[mean anomaly]] <math display=\"inline\">l</math>, the [[argument of periapsis]] <math display=\"inline\">g</math> and the longitude of the ascending node <math display=\"inline\">h</math>, along with their conjugate momenta denoted by <math display=\"inline\">L</math>, <math display=\"inline\">G</math>, and <math display=\"inline\">H</math>, respectively.<ref>Shevchenko 2017, pp. 68-69</ref>\n\n===The three-body problem===\n{{main|Three-body problem|Perturbation theory}}\n<!-- Insert illustration of a hierarchical setup showing the notation -->\nThe dynamics of a system composed of three bodies system acting under their mutual gravitational attraction is complex. In general, the behaviour of a three-body system [[Chaos theory|depends sensitively on the initial conditions]]. Thus, the [[three-body problem]], the problem of determining the motions of the three bodies, cannot be solved analytically except in special cases.<ref name=\"Valtonen221\">Valtonen 2005, p. 221</ref> Instead, [[numerical methods]] are used.<ref>Musielak and Quarles 2014, p. 2,10</ref>\n\nThe Lidov-Kozai mechanism is a feature of ''hierarchical'' triple systems,<ref>Li et al. 2014, p. 86</ref> that is systems in which one of the bodies, called the \"perturber\", is located far from the other two, which are said to comprise the '''inner binary'''. The perturber and the centre of mass of the inner binary comprise the '''outer binary'''.<ref>Naoz et al. 2013, sec. I</ref> Such systems are often studied by using the methods of [[perturbation theory]] to write the Hamiltonian of a hierarchical three-body system as a sum of two terms responsible for the isolated evolution of the inner and the outer binary, and a third term [[Coupling (physics)|coupling]] the two orbits,<ref name=\"Naoz2013\" />\n\n:<math> \\mathcal{H} = \\mathcal{H}_{\\rm in} + \\mathcal{H}_{\\rm out} + \\mathcal{H}_{\\rm pert}.</math>\n\nThe coupling term is then expanded in the orders of parameter <math display=\"inline\">\\alpha</math>, defined as the ratio of the [[semi-major axis|semi-major axes]] of the inner and the outer binary and hence small in a hierarchical system.<ref name=\"Naoz2013\" /> Since the perturbative series [[Convergent series|converges]] rapidly, the qualitative behaviour of a hierarchical three-body system is determined by the initial terms in the expansion, referred to as the ''quadrupole''\n(<math display=\"inline\">\\propto\\alpha^2</math>), ''octupole'' (<math display=\"inline\">\\propto\\alpha^3</math>) and ''hexadecapole'' (<math display=\"inline\">\\propto\\alpha^4</math>) order terms,<ref>Naoz 2016, pp. 4-5</ref>\n\n:<math> \\mathcal{H}_{\\rm pert} = \\mathcal{H}_{\\rm quad} + \\mathcal{H}_{\\rm oct} + \\mathcal{H}_{\\rm hex} + O(\\alpha^5).</math>\n\n<!-- Plot with octupole turned off -->\nFor many systems, a satisfactory description is found already at the lowest, quadrupole order in the perturbative expansion. The octupole term becomes dominant in certain regimes and is responsible for a long-term variation in the amplitude of the Lidov-Kozai oscillations.<ref name=\"Katz2011\">Katz et al. 2011</ref> <!-- summarize the hex term -->\n\n====Secular approximation====\nThe Lidov-Kozai mechanism is a ''secular'' effect, that is, it occurs on timescales much longer compared to the orbital periods of the inner and the outer binary. In order to simplify the problem and make it more tractable computationally, the hierarchical three-body Hamiltonian can be ''secularised'', that is averaged over the rapidly varying mean anomalies of the two orbits. Through this process, the problem is reduced to that of two interacting massive wires.<ref>Naoz 2016, p. 4</ref>\n\n==Overview of the mechanism==\n\n===Test particle limit===\nThe simplest treatment of the Lidov-Kozai mechanism assumes that one of the inner binary's components, the ''secondary'', is a [[test particle]] - an idealized point-like object with negligible mass compared to the other two bodies, the ''primary'' and the distant perturber. These assumptions are valid, for instance, in the case of an artificial satellite in a [[low-Earth orbit]] that is perturbed by the [[Moon]], or a [[short-period comet]] that is perturbed by [[Jupiter]].\n\nUnder these approximations, the orbit-averaged equations of motion for the secondary have a [[integral of motion|conserved quantity]]: the component of the secondary's orbital angular momentum parallel to the angular momentum of the primary/perturber angular momentum. This conserved quantity can be expressed in terms of the secondary's [[Orbital eccentricity|eccentricity]] ''e'' and  [[inclination]] ''i'' relative to the plane of the outer binary:\n\n:<math> L_z = \\sqrt{(1-e^2)} \\cos i = \\mathrm{const} .</math>\n\nConservation of ''L''<sub>z</sub> means that orbital eccentricity can be \"traded for\" inclination. Thus, near-circular, highly inclined orbits can become very eccentric. Since increasing eccentricity while keeping the [[semimajor axis]] constant reduces the distance between the objects at [[periapsis]], this mechanism can cause comets (perturbed by [[Jupiter]]) to become [[Sungrazing comet|sungrazing]].\n\nLidov-Kozai oscillations will be present if ''L''<sub>z</sub> is lower than a certain value. At the critical value of ''L''<sub>z</sub>, a \"fixed-point\" orbit appears, with constant inclination given by\n\n:<math>i_{crit} = \\arccos\\left(\\sqrt\\frac{3}{5}\\right) \\approx 39.2^{o}</math>\n\nFor values of ''L''<sub>z</sub> less than this critical value, there is a one-parameter family of orbital solutions having the same ''L''<sub>z</sub> but different amounts of variation in ''e'' or ''i''.  Remarkably, the degree of possible variation in ''i'' is independent of the masses involved, which only set the timescale of the oscillations.<ref>Merritt 2013</ref>\n\n====Timescale====\nThe basic timescale associated with Kozai oscillations is<ref>Merritt 2013, p. 575</ref>\n:<math>\nT_\\mathrm{Kozai} = 2\\pi\\frac{\\sqrt{GM}}{Gm_2}\\frac{a_2^3}{a^{3/2}}\\left(1-e_2^2\\right)^{3/2} = \\frac{M}{m_2}\\frac{P_2^2}{P}\\left(1-e_2^2\\right)^{3/2}\n</math>\nwhere ''a'' indicates semimajor axis, ''P'' is orbital period, ''e'' is eccentricity and ''m'' is mass; variables with subscript \"2\" refer to the outer (perturber) orbit and variables lacking subscripts refer to the inner orbit; ''M'' is the mass of the primary.\nThe period of oscillation of all three variables (''e'', ''i'', ω – the last being the [[argument of periapsis]]) is the same, but depends on how \"far\" the orbit is from the fixed-point orbit, becoming very long for the [[separatrix (dynamical systems)|separatrix]] orbit that separates librating  orbits from oscillating orbits.\n\n==Astrophysical implications==\n\n===Solar System===\nThe Lidov-Kozai mechanism causes the [[argument of pericenter]] (ω) to librate about either 90° or 270°, which is to say that its [[periapse]] occurs when the body is farthest from the equatorial plane. This effect is part of the reason that [[Pluto]] is dynamically protected from close encounters with [[Neptune]].\n\nThe Lidov-Kozai mechanism places restrictions on the orbits possible within a system, for example\n* for a regular moon: if the orbit of a planet's moon is highly inclined to the planet's orbit, the eccentricity of the moon's orbit will increase until, at closest approach, the moon is destroyed by tidal forces.\n* for irregular satellites: the growing eccentricity will result in a collision with a regular moon, the planet, or alternatively, the growing apocenter may push the satellite outside the [[Hill sphere]]. Recently, the Hill-stability radius has been found as a function of satellite inclination, also explains the non-uniform distribution of irregular satellite inclinations.<ref>Grishin et al. 2017</ref>\n\nThe mechanism has been invoked in searches for [[Planet X]], hypothetical planets orbiting the Sun beyond the orbit of Neptune.<ref>de la Fuente Marcos et al. 2014</ref>\n\nA number of moons have been found to be in the Lidov-Kozai resonance with their planet, including Jupiter's [[Carpo (moon)|Carpo]] and [[Euporie (moon)|Euporie]],<ref>Brozović and Jacobson 2017</ref> Saturn's [[Kiviuq (moon)|Kiviuq]] and [[Ijiraq (moon)|Ijiraq]],<ref>Shevchenko 2017, p. 100</ref> Uranus's [[Margaret (moon)|Margaret]],<ref>Brozović and Jacobson 2009</ref> and Neptune's [[Sao (moon)|Sao]] and [[Neso (moon)|Neso]].<ref>Brozović et al. 2011</ref>\n\nSome sources identify the Soviet space probe [[Luna 3]] as the first example of an artificial satellite undergoing Lidov-Kozai oscillations. Launched in 1959 into a highly inclined, eccentric, geocentric orbit, it was the first mission to photograph the [[far side of the Moon]]. It burned in the Earth's atmosphere after completing eleven revolutions.<ref>Shevchenko 2017, pp. 9-10</ref> However, according to Gkolias et al., a different mechanism must have driven the decay of the probe's orbit since the Lidov-Kozai oscillations would have been thwarted by effects due to the [[oblateness]] of the Earth's figure.<ref>Gkolias et al. 2016</ref>\n\n===Extrasolar planets===\nThe Lidov-Kozai mechanism, in combination with [[tidal friction]], is able to produce [[Hot Jupiter]]s, which are [[gas giant]] exoplanets orbiting their stars on tight orbits.<ref name=\"FabryckyTremaine\">Fabrycky and Tremaine 2007</ref><ref>Naoz et al. 2011</ref>\n\n===Black holes===\nThe mechanism is thought to affect the growth of central [[black holes]] in dense [[star cluster]]s. It also drives the evolution of certain classes of [[binary black hole]]s<ref name=\"Naoz2013\">Naoz et al. 2013</ref> and may play a role in enabling [[black hole merger]]s.<ref name=\"Blaes2002\">Blaes et al. 2002</ref>\n\n==History and development==\n<!-- Insert image -->\nThe effect was first described in 1961 by the Soviet space scientist [[Mikhail Lidov]] while analyzing the orbits of artificial and natural satellites of planets. Originally published in Russian, the result was translated into English in 1962.<ref name=\"Lidov1961/62\" /><ref name=\"Nakamura\">Nakamura and Orchiston 2017, p. 88</ref> Lidov presented his work at the ''Conference on General and Applied Problems of Theoretical Astronomy'' held in Moscow on November 20–25, 1961.<ref name=\"Grebnikov1962\">Grebnikov 1962</ref> Among the participants of that conference was a Japanese astronomer [[Yoshihide Kozai]]<ref name=\"Grebnikov1962\" /> who soon published this same result, in application to the orbits of the [[asteroid]]s perturbed by [[Jupiter]].<ref name=\"Kozai1962Paper\" /> Since Lidov was the first to discover it, many authors use the term Lidov–Kozai mechanism. Many, however, name it Kozai–Lidov or just Kozai mechanism.\n\n<!-- Insert image -->\nThe number of citations of the 1961 and 1962 papers by Lidov and Kozai has risen sharply in the 21st century. As of 2017, the Kozai mechanism is among the most studied astrophysical phenomena.<ref name=\"ShevchenkoCitations\" />\n\n==Notes==\n{{reflist|30em}}\n\n==References==\n{{refbegin|30em}}\n*{{cite journal | last = Lidov | first = Mikhail L. | year = 1961 | title=Эволюция орбит искусственных спутников под воздействием гравитационных возмущений внешних тел | journal = Iskusstvennye Sputniki Zemli | volume = 8 | pages = 5–45 | language = ru }}\n*{{cite journal |last= Lidov|first= Mikhail L. | year=1962 |title= The evolution of orbits of artificial satellites of planets under the action of gravitational perturbations of external bodies|journal= [[Planetary and Space Science]]|volume=9 |issue=10 |pages=719–759 |doi=10.1016/0032-0633(62)90129-0 |bibcode = 1962P&SS....9..719L }} (translation of the 1961 paper)\n*{{cite journal |last= Lidov|first= Mikhail L.|title= On approximate analysis of the evolution of orbits of artificial satellites | journal = Problems of Motion of Artificial Celestial Bodies. Proceedings of the Conference on General and Practical Topics of Theoretical Astronomy, Held in Moscow on 20–25 November 1961. |  year=1963| publisher = Publication of the Academy of Sciences of the USSR, Moscow 1963}}\n*{{cite journal | last = Kozai | first = Yoshihide | year=1962 | title = Secular perturbations of asteroids with high inclination and eccentricity  | journal = [[The Astronomical Journal]] | volume = 67 |issue= |page=591 |publisher= |doi=  10.1086/108790| bibcode = 1962AJ.....67..591K }}\n*{{cite book | last=Shevchenko | first=Ivan I. | title=Astrophysics and Space Science Library | volume=441 | chapter=The Lidov-Kozai Effect - Applications in Exoplanet Research and Dynamical Astronomy | publisher=Springer International Publishing | location=Cham | year=2017 | isbn=978-3-319-43520-6 | issn=0067-0057 | doi=10.1007/978-3-319-43522-0 | page=}}\n*{{cite journal | last=Li | first=Gongjie | last2=Naoz | first2=Smadar | last3=Holman | first3=Matt | last4=Loeb | first4=Abraham | title=CHAOS IN THE TEST PARTICLE ECCENTRIC KOZAI-LIDOV MECHANISM | journal=The Astrophysical Journal | publisher=IOP Publishing | volume=791 | issue=2 | pages=86 | year=2014 | issn=1538-4357 | doi=10.1088/0004-637x/791/2/86 | arxiv=1405.0494 | bibcode=2014ApJ...791...86L }}\n*{{cite book | last = Merritt | first = David | authorlink = David Merritt | title = Dynamics and Evolution of Galactic Nuclei | year = 2013 | publisher = Princeton University Press | location = Princeton, NJ | page = | url = http://openlibrary.org/works/OL16802359W/Dynamics_and_Evolution_of_Galactic_Nuclei | isbn = 978-0-691-12101-7 | oclc = 863632625 | series = Princeton Series in Astrophysics }}\n*{{cite journal |last1=Brozović |first1=Marina |last2=Jacobson |first2=Robert A. | year=2017 |title=The Orbits of Jupiter's Irregular Satellites |journal=The Astronomical Journal |volume=153:147 |issue=4 |pages=147 |doi=10.3847/1538-3881/aa5e4d|bibcode = 2017AJ....153..147B }}\n*{{cite journal |last1=Brozovic |first1=M. |last2=Jacobson |first2=R. A. | year=2009 |title=The Orbits of the Outer Uranian Satellites |journal=The Astronomical Journal |volume=137 |issue=4 |doi=10.1088/0004-6256/137/4/3834 |bibcode = 2009AJ....137.3834B | pages=3834–42 }}\n*{{cite journal |last1=Brozović |first1=Marina |last2=Jacobson |first2=Robert A. |last3=Sheppard |first3=Scott S. | year=2011 |title=The Orbits of Neptune's Outer Sallites |journal=The Astronomical Journal |volume=141 |issue=4 |pages=135 |doi=10.1088/0004-6256/141/4/135 |bibcode = 2011AJ....141..135B }}\n*{{cite journal | url = http://mnrasl.oxfordjournals.org/content/443/1/L59.short | last1 = de la Fuente Marcos | first1 = Carlos | first2 = Raul | last2 = de la Fuente Marcos | title = Extreme trans-Neptunian objects and the Kozai mechanism: signalling the presence of trans-Plutonian planets | journal = [[Monthly Notices of the Royal Astronomical Society: Letters]] | volume = 443 | issue = 1 | year=2014 | pages = L59–L63 | arxiv = 1406.0715 |bibcode = 2014MNRAS.443L..59D |doi = 10.1093/mnrasl/slu084 }}\n*{{cite journal | last=Katz | first=Boaz | last2=Dong | first2=Subo | last3=Malhotra | first3=Renu | title=Long-Term Cycling of Kozai-Lidov Cycles: Extreme Eccentricities and Inclinations Excited by a Distant Eccentric Perturber | journal=Physical Review Letters | publisher=American Physical Society | volume=107 | issue=18 | year=2011 | issn=0031-9007 | doi=10.1103/PhysRevLett.107.181101 | pmid=22107620 | page=181101 | ref=harv| arxiv=1106.3340 | bibcode=2011PhRvL.107r1101K }}\n*{{cite journal | last=Lithwick | first=Yoram | last2=Naoz | first2=Smadar | title=THE ECCENTRIC KOZAI MECHANISM FOR A TEST PARTICLE | journal=The Astrophysical Journal | publisher=IOP Publishing | volume=742 | issue=2 | year=2011 | issn=0004-637X | doi=10.1088/0004-637x/742/2/94 | page=94 | ref=harv| arxiv=1106.3329 | bibcode=2011ApJ...742...94L }}\n*{{cite journal | last=Naoz | first=Smadar | last2=Farr | first2=Will M. | last3=Lithwick | first3=Yoram | last4=Rasio | first4=Frederic A. | last5=Teyssandier | first5=Jean | title=Hot Jupiters from secular planet–planet interactions | journal=Nature | publisher=Springer Nature | volume=473 | issue=7346 | year=2011 | issn=0028-0836 | doi=10.1038/nature10076 | pmid=21562558 | pages=187–189 | ref=harv| arxiv=1011.2501 | bibcode=2011Natur.473..187N }}\n*{{cite journal | last=Naoz | first=Smadar | last2=Farr | first2=Will M. | last3=Lithwick | first3=Yoram | last4=Rasio | first4=Frederic A. | last5=Teyssandier | first5=Jean | title=Secular dynamics in hierarchical three-body systems | journal=Monthly Notices of the Royal Astronomical Society | publisher=Oxford University Press (OUP) | volume=431 | issue=3 | year=2013 | issn=1365-2966 | doi=10.1093/mnras/stt302 | pages=2155–2171 | ref=harv| arxiv=1107.2414 | bibcode=2013MNRAS.431.2155N }}\n*{{cite book | last=Valtonen | first=M. J. | title=The three-body problem | publisher=Cambridge University Press | location=Cambridge, UK New York | year=2005 | isbn=978-0-521-85224-1 | ref=harv}}\n*{{cite journal | last=Musielak | first=Z E | last2=Quarles | first2=B | title=The three-body problem | journal=Reports on Progress in Physics | publisher=IOP Publishing | volume=77 | issue=6 | pages=065901 | year=2014 | issn=0034-4885 | doi=10.1088/0034-4885/77/6/065901 | pmid=24913140 | ref=harv| arxiv=1508.02312 | bibcode=2014RPPh...77f5901M }}\n*{{cite journal | last=Fabrycky | first=Daniel | last2=Tremaine | first2=Scott | title=Shrinking Binary and Planetary Orbits by Kozai Cycles with Tidal Friction | journal=The Astrophysical Journal | volume=669 | issue=2 | year=2007 | issn=0004-637X | doi=10.1086/521702 | pages=1298–1315 | ref=harv| arxiv=0705.4285 | bibcode=2007ApJ...669.1298F }}\n*{{cite journal | last=Blaes | first=Omer | last2=Lee | first2=Man Hoi | last3=Socrates | first3=Aristotle | title=The Kozai Mechanism and the Evolution of Binary Supermassive Black Holes | journal=The Astrophysical Journal | volume=578 | issue=2 | year=2002 | issn=0004-637X | doi=10.1086/342655 | pages=775–786| arxiv=astro-ph/0203370 | bibcode=2002ApJ...578..775B }}\n*{{cite book | editor-last=Nakamura | editor-first=Tsuko | editor-last2=Orchiston | editor-first2=Wayne | title=Historical & Cultural Astronomy | chapter=The Emergence of Astrophysics in Asia | publisher=Springer International Publishing | location=Cham | year=2017 | isbn=978-3-319-62080-0 | issn=2509-310X | doi=10.1007/978-3-319-62082-4 | ref={{sfnref | Springer International Publishing }}}}\n*{{cite journal | last=Grebnikov | first=E. A. | title=Conference on General and Applied Problems of Theoretical Astronomy | journal=Soviet Astronomy | volume=6 | issn=0038-5301 | pages=440– | bibcode=1962SvA.....6..440G | ref=harv | year=1962 }}\n*{{cite journal | last=Tremaine | first=Scott | last2=Yavetz | first2=Tomer D. | title=Why do Earth satellites stay up? | journal=American Journal of Physics | publisher=American Association of Physics Teachers (AAPT) | volume=82 | issue=8 | year=2014 | issn=0002-9505 | doi=10.1119/1.4874853 | pages=769–777 | ref=harv| arxiv=1309.5244 | bibcode=2014AmJPh..82..769T }}\n*{{cite journal | last=Verrier | first=P. E. | last2=Evans | first2=N. W. | title=High-inclination planets and asteroids in multistellar systems | journal=Monthly Notices of the Royal Astronomical Society | publisher=Oxford University Press (OUP) | volume=394 | issue=4 | year=2009 | issn=0035-8711 | doi=10.1111/j.1365-2966.2009.14446.x | pages=1721–1726 | ref=harv| arxiv=0812.4528 | bibcode=2009MNRAS.394.1721V }}\n*{{cite journal | last=Naoz | first=Smadar | title=The Eccentric Kozai-Lidov Effect and Its Applications | journal=Annual Review of Astronomy and Astrophysics | publisher=Annual Reviews | volume=54 | issue=1 | year=2016 | issn=0066-4146 | doi=10.1146/annurev-astro-081915-023315 | pages=441–489 | ref=harv| arxiv=1601.07175 | bibcode=2016ARA&A..54..441N }}\n*{{cite journal | last=Gkolias | first=Ioannis | last2=Daquin | first2=Jérôme | last3=Gachet | first3=Fabien | last4=Rosengren | first4=Aaron J. | title=FROM ORDER TO CHAOS IN EARTH SATELLITE ORBITS | journal=The Astronomical Journal | publisher=American Astronomical Society | volume=152 | issue=5 | year=2016 | issn=1538-3881 | doi=10.3847/0004-6256/152/5/119 | page=119 | ref=harv| arxiv=1606.04180 | bibcode=2016AJ....152..119G }}\n*{{cite journal | last=Grishin | first=Evgeni | last2=Perets | first2=Hagai B. | last3=Zenati | first3=Yossef | last4=Michaely | first4=Erez | title=Generalized Hill-Stability Criteria for Hierarchical Three-Body Systems at Arbitrary Inclinations | journal=Monthly Notices of the Royal Astronomical Society | publisher=Oxford University Press (OUP) | volume=466 | issue=1 | year=2017 | issn=1365-2966 | doi=10.1093/mnras/stw3096 | pages=276–285 | ref=harv| arxiv=1609.05912 | bibcode=2017MNRAS.466..276G }}\n{{refend}}\n\n[[Category:Orbital perturbations]]"
    },
    {
      "title": "Lindblad resonance",
      "url": "https://en.wikipedia.org/wiki/Lindblad_resonance",
      "text": "A '''Lindblad resonance''', named for the Swedish galactic astronomer [[Bertil Lindblad]],<ref>{{cite book\n|title=Galactic dynamics (Princeton series in astrophysics)\n|first1=James\n|last1=Binney\n|first2=Scott\n|last2=Tremaine\n|publisher=[[Princeton University Press]]\n|date=1988\n|isbn=978-0-691-08445-9\n|page=149\n|url=https://books.google.com/books?id=01yNf7mipb0C&pg=PA149}}\n</ref> is an [[orbital resonance]] in which an object's [[epicyclic frequency]] (the rate at which one [[periapse]] follows another) is a simple multiple of some [[Harmonic oscillator|forcing frequency]].  Resonances of this kind tend to increase the object's [[orbital eccentricity]]<ref>{{cite book\n|title=Numerical astrophysics: proceedings of the International Conference on Numerical Astrophysics 1998 (NAP98)\n|first1=Shoken M.\n|last1=Miyama\n|first2=Kohji\n|last2=Tomisaka\n|first3=Tomoyuki\n|last3=Hanawa\n|publisher=Springer\n|date=1999\n|isbn=978-0-7923-5566-3\n|page=162\n|url=https://books.google.com/books?id=9mvhdGS8nCAC&pg=PA162}}\n</ref> and to cause its [[longitude of periapse]] to line up in phase with the forcing.  Lindblad resonances drive [[Density wave theory|spiral density waves]]<ref>{{cite book\n|title=Star formation in the interstellar medium: in honor of David Hollenbach, Chris McKee, and Frank Shu\n|first1=D.\n|last1=Johnstone\n|publisher=Astronomical Society of the Pa\n|date=2004\n|isbn=978-1-58381-185-6\n|page=73\n|url=https://books.google.com/books?id=RpDvAAAAMAAJ}}</ref> both in [[galaxies]] (where stars are subject to forcing by the spiral arms themselves) and in [[Rings of Saturn|Saturn's rings]] (where ring particles are subject to forcing by [[Moons of Saturn|Saturn's moons]]).\n\nLindblad resonances affect stars at such distances from a [[disc galaxy]]'s centre where the natural frequency of the radial component of a star's orbital velocity is close to the frequency of the gravitational potential maxima encountered during its course through the spiral arms.  If a star's orbital speed around the galactic centre is greater than that of the part of the spiral arm through which it is passing, then an inner Lindblad resonance occurs - if smaller, then an outer Lindblad resonance.<ref>{{cite book\n|title=The Physics of Astrophysics: Gas dynamics\n|first1=Frank H.\n|last1=Shu\n|publisher=University Science Books\n|date=1992\n|isbn=978-0-935702-65-1\n|page=147\n|url=https://books.google.com/books?id=50VYSc56URUC&pg=PA147}}\n</ref> At an inner resonance, a star's orbital speed is increased, moving the star outwards, and decreased for an outer resonance causing inward movement.\n\n==References==\n{{reflist}}\n\n==Further reading==\n* Murray, C.D., and S.F. Dermott 1999, ''Solar System Dynamics'' (Cambridge: Cambridge University Press).\n\n==External links==\n* [http://iopscience.iop.org/0004-637X/504/2/983/pdf/0004-637X_504_2_983.pdf Three-Dimensional Waves Generated At Lindblad Resonances In Thermally Stratified Disks - Lubow & Ogilvie]\n\n{{DEFAULTSORT:Lindblad Resonance}}\n[[Category:Astrophysics]]\n[[Category:Stellar dynamics]]\n[[Category:Orbital perturbations]]"
    },
    {
      "title": "Orbit modeling",
      "url": "https://en.wikipedia.org/wiki/Orbit_modeling",
      "text": "'''Orbit modeling''' is the process of creating mathematical models to simulate motion of a massive body as it moves in [[orbit]] around another massive body due to [[gravity]]. Other forces such as gravitational attraction from tertiary bodies, [[Drag (physics)|air resistance]], [[Solar wind|solar pressure]], or thrust from a [[propulsion]] system are typically modeled as secondary effects. Directly modeling an orbit can push the limits of [[machine precision]] due to the need to model small perturbations to very large orbits. Because of this, [[Perturbation (astronomy)|perturbation]] methods are often used to model the orbit in order to achieve better accuracy.\n\n== Background ==\nThe study of orbital motion and mathematical modeling of orbits began with the first attempts to predict planetary motions in the sky, although in ancient times the causes remained a mystery. [[Isaac Newton|Newton]], at the time he formulated his laws of [[Newton's laws of motion|motion]] and of [[Newton's law of universal gravitation|gravitation]], applied them to the first analysis of perturbations,<ref name=\"moulton\"/> recognizing the complex difficulties of their calculation.<ref name=moulton>\n{{cite book\n|chapter-url=https://books.google.com/books?id=jqM5AAAAMAAJ\n|title=An Introduction to Celestial Mechanics\n|edition=Second Revised\n|last=Moulton\n|first=Forest Ray\n|date=1914\n|chapter=Chapter IX}}</ref>\nMany of the great mathematicians since then have given attention to the various problems involved; throughout the 18th and 19th centuries there was demand for accurate tables of the position of the Moon and planets for purposes of navigation at sea.\n\nThe complex motions of orbits can be broken down. The hypothetical motion that the body follows under the gravitational effect of one other body only is typically a [[conic section]], and can be readily modeled with the methods of [[geometry]]. This is called a [[two-body problem]], or an unperturbed [[Kepler orbit|Keplerian orbit]]. The differences between the Keplerian orbit and the actual motion of the body are caused by [[Perturbation (astronomy)|perturbations]]. These perturbations are caused by forces other than the gravitational effect between the primary and secondary body and must be modeled to create an accurate orbit simulation. Most orbit modeling approaches model the two-body problem and then add models of these perturbing forces and simulate these models over time. Perturbing forces may include gravitational attraction from other bodies besides the primary, solar wind, drag, magnetic fields, and propulsive forces.\n\nAnalytical solutions (mathematical expressions to predict the positions and motions at any future time) for simple two-body and [[three-body problem]]s exist; none have been found for the [[n-body problem|''n''-body problem]] except for certain special cases. Even the two-body problem becomes insoluble if one of the bodies is irregular in shape.<ref name=\"roy\">{{cite book |last = Roy |first = A.E. | title = Orbital Motion |publisher = [[Institute of Physics Publishing]] |edition = third |isbn = 978-0-85274-229-7 |date=1988 |chapter=Chapters 6 and 7}}</ref>\n\nDue to the difficulty in finding analytic solutions to most problems of interest, computer [[modeling and simulation]] is typically used to analyze orbital motion. Commercial software applications such as [[Satellite Tool Kit]] have been created for the specific purpose of simulating orbits and trajectories of spacecraft.\n\n== Keplerian orbit model ==\n{{main|Kepler orbit}}\nIn its simplest form, an orbit model can be created by assuming that only two bodies are involved, both behave as spherical point-masses, and that no other forces act on the bodies. For this case the model is simplified to a [[Kepler orbit]].\n\nKeplerian orbits follow [[conic sections]]. The mathematical model of the orbit which gives the distance between a central body and an orbiting body can be expressed as:\n\n:<math> r(\\nu) = \\frac{a(1-e^2)}{1+e\\cos(\\nu)} </math>\n\nWhere:\n:<math>r</math> is the distance\n:<math>a</math> is the [[semi-major axis]], which defines the size of the orbit\n:<math>e</math> is the [[orbital eccentricity|eccentricity]], which defines the shape of the orbit\n:<math>\\nu</math> is the [[true anomaly]], which is the angle between the current position of the orbiting object and the location in the orbit at it is closest to the central body (called the [[periapsis]])\nAlternately, the equation can be expressed as:\n\n:<math> r(\\nu) = \\frac{p}{1+e\\cos(\\nu)} </math>\n\nWhere <math>p</math> is called the [[conic section#Features|semi-latus rectum]] of the curve. This form of the equation is particularly useful when dealing with parabolic trajectories, for which the semi-major axis is infinite.\n\nAn alternate approach uses [[Isaac Newton]]'s [[Newton's law of universal gravitation|law of universal gravitation]] as defined below:\n\n:<math>F = G \\frac{m_1 m_2}{r^2}</math>\n\nwhere:\n\n:<math>F</math> is the magnitude of the gravitational force between the two point masses\n:<math>G</math> is the [[gravitational constant]]\n:<math>m_1</math> is the mass of the first point mass\n:<math>m_2</math> is the mass of the second point mass\n:<math>r</math> is the distance between the two point masses\n\nMaking an additional assumption that the mass of the primary body is much greater than the mass of the secondary body and substituting in Newton's [[Newton's laws of motion|second law of motion]], results in the following differential equation\n:<math> \\ddot{\\mathbf{r}} = \\frac{G m_1}{r^2} \\mathbf{\\hat{r}}</math>\n\nSolving this differential equation results in Keplerian motion for an orbit.\nIn practice, Keplerian orbits are typically only useful for first-order approximations, special cases, or as the base model for a perturbed orbit.\n\n== Orbit simulation methods ==\n{{main|Perturbation (astronomy)}}\nOrbit models are typically propagated in time and space using special [[Perturbation (astronomy)|perturbation]] methods. This is performed by first modeling the orbit as a Keplerian orbit. Then perturbations are added to the model to account for the various perturbations that affect the orbit.<ref name=\"moulton\"/>\nSpecial perturbations can be applied to any problem in [[celestial mechanics]], as it is not limited to cases where the perturbing forces are small.<ref name=\"roy\"/> Special perturbation methods are the basis of the most accurate machine-generated [[Fundamental ephemeris|planetary ephemerides]].<ref name=\"moulton\"/>\nsee, for instance, [[Jet Propulsion Laboratory Development Ephemeris]]\n\n=== Cowell's method ===\n[[File:Cowells method.png|thumb|Cowell's method. Forces from all perturbing bodies (black and gray) are summed to form the total force on body ''i'' (red), and this is numerically integrated starting from the initial position (the ''epoch of osculation'').]]\n\nCowell's method is perhaps the simplest of the special perturbation methods;<ref>\nSo named for [[Philip Herbert Cowell|Philip H. Cowell]], who, with A.C.D. Cromellin, used a similar method to predict the return of Halley's comet.\n{{cite book\n|last1 = Brouwer\n|first1 = Dirk\n|last2 = Clemence\n|first2 = Gerald M.\n| title = Methods of Celestial Mechanics\n|publisher = Academic Press, New York and London\n|date=1961\n|page=186\n}}</ref>\nmathematically, for <math>n</math> mutually interacting bodies, [[Newton's law of universal gravitation|Newtonian]] forces on body <math>i</math> from the other bodies <math>j</math> are simply summed thus,\n\n: <math>\\mathbf{\\ddot{r}}_i = \\sum_{\\underset{j \\ne i}{j=1}}^n {Gm_j (\\mathbf{r}_j-\\mathbf{r}_i) \\over r_{ij}^3}</math>\n\nwhere\n:<math>\\mathbf{\\ddot{r}}_i</math> is the [[acceleration]] vector of body <math>i</math>\n:<math>G</math> is the [[gravitational constant]]\n:<math>m_j</math> is the [[mass]] of body <math>j</math>\n:<math>\\mathbf{r}_i</math> and <math>\\mathbf{r}_j</math> are the [[position vector]]s of objects <math>i</math> and <math>j</math>\n:<math>r_{ij}</math> is the distance from object <math>i</math> to object <math>j</math>\nwith all [[Euclidean vector#Physics|vectors]] being referred to the [[Center of mass#Astronomy|barycenter]] of the system. This equation is resolved into components in <math>x</math>, <math>y</math>, <math>z</math> and these are integrated numerically to form the new velocity and position vectors as the simulation moves forward in time. The advantage of Cowell's method is ease of application and programming. A disadvantage is that when perturbations become large in magnitude (as when an object makes a close approach to another) the errors of the method also become large.<ref name=\"danby\">\n{{cite book\n|last = Danby\n|first = J.M.A.\n| title = Fundamentals of Celestial Mechanics\n|publisher = Willmann-Bell, Inc.\n|edition = second |isbn = 978-0-943396-20-0\n|date=1988\n|chapter=Chapter 11}}</ref>\nAnother disadvantage is that in systems with a dominant central body, such as the [[Sun]], it is necessary to carry many [[Significant figures|significant digits]] in the [[arithmetic]] because of the large difference in the forces of the central body and the perturbing bodies.<ref>\n{{cite book\n|last = Herget\n|first = Paul\n|title = The Computation of Orbits\n|publisher = privately published by the author\n|date=1948\n|page=91 ff}}</ref>\n\n=== Encke's method ===\n\n[[File:Enckes method.PNG|thumb|Encke's method. Greatly exaggerated here, the small difference  δ'''r''' (blue) between the osculating, unperturbed orbit (black) and the perturbed orbit (red), is numerically integrated starting from the initial position (the ''epoch of osculation'').]]\n\nEncke's method begins with the [[osculating orbit]] as a reference and integrates numerically to solve for the variation from the reference as a function of time.<ref>\nSo named for [[Johann Franz Encke]];\n{{cite book\n|last = Battin\n|first = Richard H.\n|title = An Introduction to the Mathematics and Methods of Astrodynamics, Revised Edition\n|publisher = American Institute of Aeronautics and Astronautics, Inc.\n|isbn = 978-1-56347-342-5\n|date=1999\n|page=448}}</ref>\nIts advantages are that perturbations are generally small in magnitude, so the integration can proceed in larger steps (with resulting lesser errors), and the method is much less affected by extreme perturbations than Cowell's method. Its disadvantage is complexity; it cannot be used indefinitely without occasionally updating the osculating orbit and continuing from there, a process known as ''rectification''.<ref name=\"danby\"/>\n<ref>Battin (1999), sec. 10.2.</ref>\n\nLetting <math>\\boldsymbol{\\rho}</math> be the [[Position vector|radius vector]] of the [[osculating orbit]], <math>\\mathbf{r}</math> the radius vector of the perturbed orbit, and <math>\\delta \\mathbf{r}</math> the variation from the osculating orbit,\n\n{{NumBlk|:|<math>\\delta \\mathbf{r} = \\mathbf{r} - \\boldsymbol{\\rho},</math> and the [[Equations of motion|equation of motion]] of <math>\\delta \\mathbf{r}</math> is simply|{{EquationRef|1}}}}\n\n{{NumBlk|:|<math>\\ddot{\\delta \\mathbf{r}} = \\mathbf{\\ddot{r}} - \\boldsymbol{\\ddot{\\rho}}.</math>|{{EquationRef|2}}}}\n\n<math>\\mathbf{\\ddot{r}}</math> and <math>\\boldsymbol{\\ddot{\\rho}}</math> are just the equations of motion of <math>\\mathbf{r}</math> and <math>\\boldsymbol{\\rho}</math>,\n\n{{NumBlk|:|<math>\\mathbf{\\ddot{r}} = \\mathbf{a}_{\\text{per}} - {\\mu \\over r^3} \\mathbf{r}</math> for the perturbed orbit and |{{EquationRef|3}}}}\n\n{{NumBlk|:|<math>\\boldsymbol{\\ddot{\\rho}} = - {\\mu \\over \\rho^3} \\boldsymbol{\\rho}</math> for the unperturbed orbit,|{{EquationRef|4}}}}\n\nwhere <math>\\mu = G(M+m)</math> is the [[Standard gravitational parameter|gravitational parameter]] with <math>M</math> and <math>m</math> the [[mass]]es of the central body and the perturbed body, <math>\\mathbf{a}_{\\text{per}}</math> is the perturbing [[acceleration]], and <math>r</math> and <math>\\rho</math> are the magnitudes of <math>\\mathbf{r}</math> and <math>\\boldsymbol{\\rho}</math>.\n\nSubstituting from equations ({{EquationNote|3}}) and ({{EquationNote|4}}) into equation ({{EquationNote|2}}),\n\n{{NumBlk|:|<math>\\ddot{\\delta \\mathbf{r}} = \\mathbf{a}_{\\text{per}} + \\mu \\left( {\\boldsymbol{\\rho} \\over \\rho^3} - {\\mathbf{r} \\over r^3} \\right),</math> |{{EquationRef|5}}}}\n\nwhich, in theory, could be integrated twice to find <math>\\delta \\mathbf{r}</math>. Since the osculating orbit is easily calculated by two-body methods, <math>\\boldsymbol{\\rho}</math> and <math>\\delta \\mathbf{r}</math> are accounted for and <math>\\mathbf{r}</math> can be solved. In practice, the quantity in the brackets, <math> {\\boldsymbol{\\rho} \\over \\rho^3} - {\\mathbf{r} \\over r^3} </math>, is the difference of two nearly equal vectors, and further manipulation is necessary to avoid the need for extra [[Significant figures|significant digits]].<ref>\nBate, Mueller, White (1971), sec. 9.3.</ref><ref>\nRoy (1988), sec. 7.4.</ref>\n\n=== Sperling–Burdet method ===\nIn 1991 Victor R. Bond and Michael F. Fraietta created an efficient and highly accurate method for solving the two-body perturbed problem.<ref name=\"Peláez\">{{cite journal|last=Peláez|first=Jesús|author2=José Manuel Hedo |author3=Pedro Rodríguez de Andrés |title=A special perturbation method in orbital dynamics|journal=Celest. Mech. Dyn. Astron.|date=13 October 2006|volume=97|issue=2|pages=131–150|doi =10.1007/s10569-006-9056-3|bibcode = 2007CeMDA..97..131P }}</ref> This method uses the linearized and regularized differential equations of motion derived by Hans Sperling and a perturbation theory based on these equations developed by C.A. Burdet in the year 1864. In 1973, Bond and Hanssen improved Burdet's set of differential equations by using the total energy of the perturbed system as a parameter instead of the two-body energy and by reducing the number of elements to 13. In 1989 Bond and Gottlieb embedded the Jacobian integral, which is a constant when the potential function is explicitly dependent upon time as well as position in the Newtonian equations. The Jacobian constant was used as an element to replace the total energy in a reformulation of the differential equations of motion. In this process, another element which is proportional to a component of the angular momentum is introduced. This brought the total number of elements back to 14. In 1991, Bond and Fraietta made further revisions by replacing the Laplace vector with another vector integral as well as another scalar integral which removed small secular terms which appeared in the differential equations for some of the elements.<ref name=Bond>{{cite journal|last=Bond|first=Victor|author2=Michael F. Fraietta|title=Elimination Of Secular Terms From The Differential Equations For The Elements of Perturbed Two-Body Motion|journal=Flight Mechanics and Estimation Theory Symposium|date=1991}}</ref>\n\nThe Sperling–Burdet method is executed in a 5 step process as follows:<ref name=\"Bond\"/>\n:'''Step 1: Initialization'''\n::Given an initial position, <math>\\mathbf{r}_0</math>, an initial velocity, <math>\\mathbf{v}_0</math>, and an initial time, <math>t_0</math>, the following variables are initialized:\n::<math>s=0</math>\n::<math>r_0=(\\mathbf{r}_0\\cdot\\mathbf{r}_0)^{1/2}</math>\n::<math>a=r_0</math>\n::<math>b=\\mathbf{r}_0\\cdot\\mathbf{v}_0</math>\n::<math>\\tau=t_0</math>\n::<math>\\boldsymbol{\\alpha}=\\mathbf{r}_0</math>\n::<math>\\boldsymbol{\\beta}=a\\mathbf{v}_0</math>\n::Perturbations due to perturbing masses, defined as <math>V_0</math> and <math>\\Bigg[{\\partial{V}\\over{\\partial{\\mathbf{r}}}}\\Bigg]_0</math>, are evaluated\n::Perturbations due to other accelerations, defined as <math>\\mathbf{P}_0</math>, are evaluated\n::<math>\\alpha_J=\\frac{2\\mu}{r_0}-\\mathbf{v}_0\\cdot\\mathbf{v}_0-2V_0</math>\n::<math>\\gamma=\\mu-\\alpha_Ja</math>\n::<math>\\boldsymbol{\\delta}=-(\\mathbf{v}_0\\cdot\\mathbf{v}_0)\\mathbf{r}_0+(\\mathbf{r}_0\\cdot\\mathbf{v}_0)\\mathbf{v}_0+\\frac{\\mu}{r_0}\\mathbf{r}_0-\\alpha_J\\mathbf{r}_0</math>\n::<math>\\sigma=0</math>\n:'''Step 2: Transform elements to coordinates'''\n::<math>\\mathbf{r}=\\boldsymbol{\\alpha}+\\boldsymbol{\\beta}sc_1+\\boldsymbol{\\delta}s^2c_2</math>\n::<math>\\mathbf{r'}=\\boldsymbol{\\beta}c_0+\\boldsymbol{\\delta}sc_1</math>\n::<math>\\mathbf{x}_3=\\alpha_J(\\boldsymbol{\\alpha}-\\mathbf{r})+\\boldsymbol{\\delta}</math>\n::<math>\\gamma=\\mu-\\alpha_Ja</math>\n::<math>r=a+bsc_1+\\gamma s^2c_2</math>\n::<math>\\mathbf{v}=\\mathbf{r'}/r</math>\n::<math>r'=bc_0+\\gamma sc_1</math>\n::<math>t=\\tau+as+bs^2c_2+\\gamma s^3c_3</math>\n::where <math>c_0, c_1, c_2, c_3</math> are [[Stumpff function]]s\n:'''Step 3: Evaluate differential equations for the elements'''\n::<math>\\mathbf{F}=\\mathbf{P}-{\\partial{V}\\over\\partial{\\mathbf{r}}}</math>\n::<math>\\mathbf{Q}=r^2\\mathbf{F}+2\\mathbf{r}(-V+\\sigma)</math>\n::<math>\\alpha'_J=2(-\\mathbf{r'}+r\\boldsymbol{\\omega}\\times\\mathbf{r})\\cdot\\mathbf{P}</math>\n::<math>\\mu\\boldsymbol{\\epsilon}'=2(\\mathbf{r'}\\cdot\\mathbf{F})\\mathbf{r}-(\\mathbf{r}\\cdot\\mathbf{F})\\mathbf{r'}-(\\mathbf{r}\\cdot\\mathbf{r'})\\mathbf{F}</math>\n::<math>\\boldsymbol{\\alpha}'=-\\mathbf{Q}sc_1-\\mu\\boldsymbol{\\epsilon}'s^2c_2-\\alpha'_J\\big[\\boldsymbol{\\alpha}s^2c_2+2\\boldsymbol{\\beta}s^3\\bar{c}_3+\\frac{1}{2}\\boldsymbol{\\delta}s^4c^2_2\\big]</math>\n::<math>\\boldsymbol{\\beta}'=\\mathbf{Q}c_0+\\mu\\boldsymbol{\\epsilon}'sc_1+\\alpha'_J\\big[\\boldsymbol{\\alpha}sc_1+\\boldsymbol{\\beta}s^2\\bar{c}_2-\\boldsymbol{\\delta}s^3(2\\bar{c}_3-c_1c_2)\\big]</math>\n::<math>\\boldsymbol{\\delta}'=\\mathbf{Q}\\alpha_Jsc_1-\\mu\\boldsymbol{\\epsilon}'c_0+\\alpha'_J\\big[-\\boldsymbol{\\alpha}c_0+2\\alpha_J\\boldsymbol{\\beta}s^3\\bar{c}_3+\\frac{1}{2}\\boldsymbol{\\delta}\\alpha_Js^4c^2_2\\big]</math>\n::<math>\\sigma'=r\\boldsymbol{\\omega}\\cdot\\mathbf{r}\\times\\mathbf{F}</math>\n::<math>a'=-\\frac{1}{r}\\mathbf{r}\\cdot\\mathbf{Q}sc_1-\\alpha_J'\\big[as^2c_2+2bs^3\\bar{c}_3+\\frac{1}{2}\\gamma s^4c^2_2\\big]</math>\n::<math>b'=\\frac{1}{r}\\mathbf{r}\\cdot\\mathbf{Q}c_0+\\alpha_J'\\big[asc_1+bs^2\\bar{c}_2-\\gamma s^3(2\\bar{c}_3-c_1c_2)\\big]</math>\n::<math>\\gamma'=-\\frac{1}{r}\\mathbf{r}\\cdot\\mathbf{Q}\\alpha_Jsc_1+\\alpha_J'\\big[-ac_0+2b\\alpha_Js^3\\bar{c}_3+\\frac{1}{2}\\gamma \\alpha_J s^4c^2_2\\big]</math>\n::<math>\\tau'=\\frac{1}{r}\\mathbf{r}\\cdot\\mathbf{Q}s^2c_2+\\alpha_J'\\big[as^3c_3+\\frac{1}{2}bs^4c^2_2-2\\gamma s^5(c_5-4\\bar{c}_5)\\big]</math>\n:'''Step 4: Integration'''\n::Here the differential equations are integrated over a period <math>\\Delta s</math> to obtain the element value at <math>s+\\Delta s</math>\n:'''Step 5: Advance'''\n::Set <math>s=s+\\Delta s</math> and return to step 2 until simulation stopping conditions are met.\n\n== Models of perturbing forces ==\nPerturbing forces cause orbits to become perturbed from a perfect Keplerian orbit. Models for each of these forces are created and executed during the orbit simulation so their effects on the orbit can be determined.\n\n=== Non-spherical gravity ===\nThe Earth is not a perfect sphere nor is mass evenly distributed within the Earth. This results in the point-mass gravity model being inaccurate for orbits around the Earth, particularly [[Low Earth Orbit|Low Earth orbits]]. To account for variations in gravitational potential around the surface of the Earth, the gravitational field of the Earth is modeled with spherical harmonics<ref name=Roithmayr>{{cite journal|last=Roithmayr|first=Carlos|title=Contributions of Spherical Harmonics to Magnetic and Gravitational Fields|journal=Nasa/tm–2004–213007|date=March 2004}}</ref> which are expressed through the equation:\n:<math>{\\mathbf{f}}=-\\frac{\\mu}{R^2}\\mathbf{\\hat{r}}+\\sum_{n=2}^\\infty \\sum_{m=0}^n {\\mathbf{f}}_{n,m}</math>\nwhere\n:<math>{\\mu}</math> is the gravitational parameter defined as the product of G, the [[universal gravitational constant]], and the mass of the primary body.\n:<math>\\mathbf{\\hat{r}}</math> is the unit vector defining the distance between the primary and secondary bodies, with <math>{R}</math> being the magnitude of the distance.\n:<math>{\\mathbf{f}}_{n,m}</math> represents the contribution to <math>{\\mathbf{f}}</math> of the spherical harmonic of degree ''n'' and order ''m'', which is defined as:<ref name=\"Roithmayr\"/>\n\n: <math>\n\\begin{align}\n\\mathbf{f}_{n,m} & = \\frac{\\mu R_O^2}{R^{n+m+1}} \\left(\\frac{C_{n,m}\\mathcal{C}_m+S_{n,m}\\mathcal{S}_m}{R}(A_{n,m+1}\\mathbf{\\hat{e}}_3 -  \\left(s_{\\lambda} A_{n,m+1}+(n+m+1)A_{n,m}\\right)\\mathbf{\\hat{r}}\\right) \\\\[10pt]\n& {}\\quad {}+ mA_{n,m}  ((C_{n,m}\\mathcal{C}_{m-1} + S_{n,m}\\mathcal{S}_{m-1})\\mathbf{\\hat{e}}_1+(S_{n,m}\\mathcal{C}_{m-1}-C_{n,m}\\mathcal{S}_{m-1})\\mathbf{\\hat{e}}_2))\n\\end{align}\n</math>\n\nwhere:\n:<math>R_O</math> is the mean equatorial radius of the primary body.\n:<math>R</math> is the magnitude of the position vector from the center of the primary body to the center of the secondary body.\n:<math> C_{n,m}</math> and <math>S_{n,m}</math> are gravitational coefficients of degree ''n'' and order ''m''. These are typically found through [[gravimetry]] measurements.\n:The unit vectors <math>\\mathbf{\\hat{e}}_1, \\mathbf{\\hat{e}}_2, \\mathbf{\\hat{e}}_3</math> define a coordinate system fixed on the primary body. For the Earth, <math>\\mathbf{\\hat{e}}_1</math> lies in the equatorial plane parallel to a line intersecting Earth's geometric center and the [[Greenwich meridian]],<math>\\mathbf{\\hat{e}}_3</math> points in the direction of the North polar axis, and <math>\\mathbf{\\hat{e}}_2=\\mathbf{\\hat{e}}_3\\times\\mathbf{\\hat{e}}_1</math>\n:<math>A_{n,m}</math> is referred to as a derived [[Legendre polynomial]] of degree ''n'' and order ''m''. They are solved through the [[recurrence relation]]: <math>A_{n,m}(u)=\\frac{1}{n-m}((2n-1)uA_{n-1,m}(u)-(n+m-1)A_{n-2,m}(u))</math>\n:<math>s_\\lambda</math> is sine of the geographic latitude of the secondary body, which is <math>\\mathbf{\\hat{r}}\\cdot\\mathbf{\\hat{e}}_3</math>.\n:<math>\\mathcal{C}_m, \\mathcal{S}_{m}</math> are defined with the following recurrence relation and initial conditions:<math>\\mathcal{C}_m=\\mathcal{C}_1\\mathcal{C}_{m-1}-\\mathcal{S}_1\\mathcal{S}_{m-1}, \\mathcal{S}_m=\\mathcal{S}_1\\mathcal{C}_{m-1}+\\mathcal{C}_1\\mathcal{S}_{m-1}, \\mathcal{S}_0=0, \\mathcal{S}_1=\\mathbf{R}\\cdot\\mathbf{\\hat{e}}_2, \\mathcal{C}_{0}=1, \\mathcal{C}_1=\\mathbf{R}\\cdot\\mathbf{\\hat{e}}_1</math>\nWhen modeling perturbations of an orbit around a primary body only the sum of the <math>{\\mathbf{f}}_{n,m}</math> terms need to be included in the perturbation since the point-mass gravity model is accounted for in the <math>-\\frac{\\mu}{R^2}\\mathbf{\\hat{r}}</math> term\n\n=== Third-body perturbations ===\nGravitational forces from third bodies can cause perturbations to an orbit. For example, the [[Sun]] and [[Moon]] cause perturbations to Orbits around the Earth.<ref name=SMAD>{{cite book|last=Larson|first=Wiley|title=Space Mission Analysis and Design|date=1999|publisher=Microcosm Press|location=California|isbn=978-1-881883-10-4}}</ref> These forces are modeled in the same way that gravity is modeled for the primary body by means of [[N-body simulation|Direct gravitational N-body simulations]]. Typically, only a spherical point-mass gravity model is used for modeling effects from these third bodies.<ref name=Delgado>{{cite web|last=Delgado|first=Manuel|title=Third Body Perturbation Modeling the Space Environment|url=http://ocw.upm.es/ingenieria-aeroespacial/modeling-the-space-environment/contenidos/material-de-clase/mse05_3rdbody.pdf|work=European Masters in Aeronautics and Space|publisher=Universidad Polit ´ecnica de Madrid|accessdate=27 November 2012}}</ref>\nSome special cases of third-body perturbations have approximate analytic solutions. For example, perturbations for the right ascension of the ascending node and argument of perigee for a circular Earth orbit are:<ref name=\"SMAD\"/>\n:<math>\\dot{\\Omega}_\\mathrm{MOON}=-0.00338(\\cos(i))/n</math>\n:<math>\\dot{\\omega}_\\mathrm{MOON}=-0.00169(4-5\\sin^2(i))/n</math>\n:where:\n:<math>\\dot{\\Omega}</math> is the change to the right ascension of the ascending node in degrees per day.\n:<math>\\dot{\\omega}</math> is the change to the argument of perigee in degrees per day.\n:<math>i</math> is the orbital inclination.\n:<math>n</math> is the number of orbital revolutions per day.\n\n=== Solar radiation ===\n{{main|Radiation pressure}}\nSolar radiation pressure causes perturbations to orbits. The magnitude of acceleration it imparts to a spacecraft in Earth orbit is modeled using the equation below:<ref name=\"SMAD\"/>\n:<math>a_R\\approx -4.5 \\times 10^{-6}(1+r)A/m</math>\nwhere:\n:<math>a_R</math> is the magnitude of acceleration in meters per second-squared.\n:<math>A</math> is the cross-sectional area exposed to the [[Sun]] in meters-squared.\n:<math>m</math> is the spacecraft mass in [[kilograms]].\n:<math>r</math> is the reflection factor which depends on material properties. <math>r=0</math> for absorption, <math>r=1</math> for specular reflection, and <math>r\\approx0.4</math> for diffuse reflection.\n\nFor orbits around the Earth, solar radiation pressure becomes a stronger force than drag above 800&nbsp;km altitude.<ref name=\"SMAD\"/>\n\n=== Propulsion ===\n{{main|Spacecraft propulsion}}\nThere are many different types of spacecraft propulsion. Rocket engines are one of the most widely used. The force of a rocket engine is modeled by the equation:<ref>{{cite book|author=George P. Sutton|author2=Oscar Biblarz|last-author-amp=yes|title=Rocket Propulsion Elements|edition=7th|publisher=[[Wiley Interscience]]|date=2001|isbn=978-0-471-32642-7}} See Equation 2-14.</ref>\n:<math>F_n = \\dot{m}\\;v_\\text{e} = \\dot{m}\\;v_\\text{e-act} + A_\\text{e}(p_\\text{e} - p_\\text{amb})</math>\n\n:{| border=\"0\" cellpadding=\"2\"\n|-\n|align=right|where:\n|&nbsp;\n|-\n!align=right|<math>\\dot{m}</math>\n|align=left|=&nbsp; exhaust gas mass flow\n|-\n!align=right|<math>v_\\text{e}</math>\n|align=left|=&nbsp; effective exhaust velocity\n|-\n!align=right|<math>v_\\text{e-act}</math>\n|align=left|=&nbsp; actual jet velocity at nozzle exit plane\n|-\n!align=right|<math>A_\\text{e}</math>\n|align=left|=&nbsp; flow area at nozzle exit plane (or the plane where the jet leaves the nozzle if separated flow)\n|-\n!align=right|<math>p_\\text{e}</math>\n|align=left|=&nbsp; static pressure at nozzle exit plane\n|-\n!align=right|<math>p_\\text{amb}</math>\n|align=left|=&nbsp; ambient (or atmospheric) pressure\n|}\n\nAnother possible method is a [[solar sail]]. Solar sails use [[radiation pressure]] in a way to achieve a desired propulsive force.<ref>{{cite web |url=http://messenger.jhuapl.edu/news_room/details.php?id=102 |title=MESSENGER Sails on Sun's Fire for Second Flyby of Mercury |date=2008-09-05 |quote=On September 4, the MESSENGER team announced that it would not need to implement a scheduled maneuver to adjust the probe's trajectory. This is the fourth time this year that such a maneuver has been called off. The reason? A recently implemented navigational technique that makes use of solar-radiation pressure (SRP) to guide the probe has been extremely successful at maintaining MESSENGER on a trajectory that will carry it over the cratered surface of Mercury for a second time on October 6. |postscript=<!--None--> |deadurl=yes |archiveurl=https://web.archive.org/web/20130514095117/http://messenger.jhuapl.edu/news_room/details.php?id=102 |archivedate=2013-05-14 |df= }}</ref> The perturbation model due to the solar wind can be used as a model of propulsive force from a solar sail.\n\n=== Drag ===\n{{main|Drag (physics)}}\nThe primary non-gravitational force acting on satellites in low Earth orbit is atmospheric drag.<ref name=\"SMAD\"/> Drag will act in opposition to the direction of velocity and remove energy from an orbit. The force due to drag is modeled by the following equation:\n\n:<math>F_D\\, =\\, \\tfrac12\\, \\rho\\, v^2\\, C_d\\, A,</math>\n\nwhere\n:<math> \\mathbf{F}_D </math> is the [[force]] of drag,\n:<math> \\mathbf{} \\rho </math> is the [[density]] of the fluid,<ref>Note that for the [[Earth's atmosphere]], the air density can be found using the [[barometric formula]]. It is 1.293 kg/m<sup>3</sup> at 0 °C and 1 [[atmosphere (unit)|atmosphere]].</ref>\n:<math> \\mathbf{} v </math> is the [[velocity]] of the object relative to the fluid,\n:<math> \\mathbf{} C_d </math> is the [[drag coefficient]] (a [[dimensionless number|dimensionless]] [[parameter]], e.g. 2 to 4 for most satellites<ref name=\"SMAD\"/>)\n:<math> \\mathbf{} A </math> is the reference [[area]].\n\nOrbits with an altitude below 120&nbsp;km generally have such high drag that the orbits decay too rapidly to give a satellite a sufficient lifetime to accomplish any practical mission. On the other hand, orbits with an altitude above 600&nbsp;km have relatively small drag so that the orbit decays slow enough that it has no real impact on the satellite over its useful life.<ref name=\"SMAD\"/> [[Density of air]] can vary significantly in the [[thermosphere]] where most low Earth orbiting satellites reside. The variation is primarily due to solar activity, and thus solar activity can greatly influence the force of drag on a spacecraft and complicate long-term orbit simulation.<ref name=\"SMAD\"/>\n\n=== Magnetic fields ===\nMagnetic fields can play a significant role as a source of orbit perturbation as was seen in the [[Long Duration Exposure Facility]].<ref name=\"Roithmayr\"/> Like gravity, the magnetic field of the Earth can be expressed through spherical harmonics as shown below:<ref name=\"Roithmayr\"/>\n\n:<math>{\\mathbf{B}}=\\sum_{n=1}^\\infty \\sum_{m=0}^n {\\mathbf{B}}_{n,m}</math>\nwhere\n:<math>{\\mathbf{B}}</math> is the magnetic field vector at a point above the Earth's surface.\n:<math>{\\mathbf{B}}_{n,m}</math> represents the contribution to <math>{\\mathbf{B}}</math> of the spherical harmonic of degree ''n'' and order ''m'', defined as:<ref name=\"Roithmayr\"/>\n\n:<math>\n\\begin{align}\n\\mathbf{B}_{n,m} = {} & \\frac{K_{n,m}a^{n+2}}{R^{n+m+1}}\\left[\\frac{g_{n,m}\\mathcal{C}_m+h_{n,m}\\mathcal{S}_m}{R}((s_{\\lambda} A_{n,m+1}+(n+m+1)A_{n,m})\\mathbf{\\hat{r}})-A_{n,m+1}\\mathbf{\\hat{e}}_3\\right] \\\\[10pt]\n& {}-mA_{n,m}((g_{n,m}\\mathcal{C}_{m-1}+h_{n,m}\\mathcal{S}_{m-1})\\mathbf{\\hat{e}}_1+(h_{n,m}\\mathcal{C}_{m-1}-g_{n,m}\\mathcal{S}_{m-1})\\mathbf{\\hat{e}}_2))\n\\end{align}\n</math>\n\nwhere:\n:<math>a</math> is the mean equatorial radius of the primary body.\n:<math>R</math> is the magnitude of the position vector from the center of the primary body to the center of the secondary body.\n:<math>\\mathbf{\\hat{r}}</math> is a unit vector in the direction of the secondary body with its origin at the center of the primary body.\n:<math> g_{n,m}</math> and <math>h_{n,m}</math> are Gauss coefficients of degree ''n'' and order ''m''. These are typically found through [[magnetic field]] measurements.\n:The unit vectors <math>\\mathbf{\\hat{e}}_1, \\mathbf{\\hat{e}}_2, \\mathbf{\\hat{e}}_3</math> define a coordinate system fixed on the primary body. For the Earth, <math>\\mathbf{\\hat{e}}_1</math> lies in the equatorial plane parallel to a line intersecting Earth's geometric center and the [[Greenwich meridian]],<math>\\mathbf{\\hat{e}}_3</math> points in the direction of the North polar axis, and <math>\\mathbf{\\hat{e}}_2=\\mathbf{\\hat{e}}_3\\times\\mathbf{\\hat{e}}_1</math>\n:<math>A_{n,m}</math> is referred to as a derived [[Legendre polynomial]] of degree ''n'' and order ''m''. They are solved through the recurrence relation: <math>A_{n,m}(u)=\\frac{1}{n-m}((2n-1)uA_{n-1,m}(u)-(n+m-1)A_{n-2,m}(u))</math>\n:<math>K_{n,m}</math> is defined as: 1 if ''m''&nbsp;=&nbsp;0, <math>\\big[\\frac{n-m}{n+m}\\big]^{0.5}K_{n-1,m}</math> for <math> n\\ge (m+1)</math> and <math> m=[1\\ldots\\infty]</math> , and <math>[(n+m)(n-m+1)]^{-0.5}K_{n,m-1}</math> for <math> n\\ge m</math> and <math>m=[2\\ldots\\infty]</math>\n:<math>s_{\\lambda}</math> is sine of the geographic latitude of the secondary body, which is <math>\\mathbf{\\hat{r}}\\cdot\\mathbf{\\hat{e}}_3</math>.\n:<math>\\mathcal{C}_{m}, \\mathcal{S}_{m}</math> are defined with the following recurrence relation and initial conditions:<math>\\mathcal{C}_{m}=\\mathcal{C}_{1}\\mathcal{C}_{m-1}-\\mathcal{S}_{1}\\mathcal{S}_{m-1}, \\mathcal{S}_{m}=\\mathcal{S}_{1}\\mathcal{C}_{m-1}+\\mathcal{C}_{1}\\mathcal{S}_{m-1}, \\mathcal{S}_{0}=0, \\mathcal{S}_{1}=\\mathbf{R}\\cdot\\mathbf{\\hat{e}}_2, \\mathcal{C}_{0}=1, \\mathcal{C}_{1}=\\mathbf{R}\\cdot\\mathbf{\\hat{e}}_1</math>\n\n== See also ==\n* [[n-body problem]]\n* [[Orbital resonance]]\n* [[Osculating orbit]]\n* [[Perturbation (astronomy)]]\n* [[Sphere of influence (astrodynamics)]]\n* [[Two-body problem]]\n\n== Notes and references ==\n{{Reflist}}\n\n==External links==\n* [http://www.fas.org/irp/imint/docs/rst/Intro/Part2_1b.html] Gravity maps of the Earth\n\n[[Category:Orbital perturbations]]\n[[Category:Dynamical systems]]\n[[Category:Dynamics of the Solar System]]"
    },
    {
      "title": "Orbital perturbation analysis",
      "url": "https://en.wikipedia.org/wiki/Orbital_perturbation_analysis",
      "text": "{{Multiple issues|\n{{mergeto|Perturbation_(astronomy)|discuss=Talk:Perturbation_(astronomy)#Merge_from_Orbital_perturbation_analysis|date=August 2018}}\n{{technical|date=December 2011}}\n{{one source|date=December 2011}}\n{{more footnotes|date=December 2011}}\n}}\n\n'''Orbital perturbation analysis''' is the activity of determining why a [[satellite|satellite's]] orbit differs from the mathematical ideal orbit.  A satellite's [[Kepler orbit|orbit]] in an ideal two-body system describes a conic section, usually an ellipse.  In reality, there are several factors that cause the conic section to continually change.  These deviations from the ideal Kepler's orbit are called [[Perturbation (astronomy)|perturbations]].\n\n==History, for example, of the lunar orbit==\nIt has long been recognized that the [[Lunar theory|Moon]] does not follow a perfect orbit, and many theories and models have been examined over the millennia to explain it. [[Isaac Newton]] determined the primary contributing factor to orbital perturbation of the moon was that the shape of the Earth is actually an [[oblate spheroid]] due to its spin, and he used the perturbations of the lunar orbit to estimate the oblateness of the Earth.{{dubious|date=April 2017}}{{citation needed|date=April 2017}}\n\nIn Newton's [[Philosophiæ Naturalis Principia Mathematica]], he demonstrated that the gravitational force between two mass points is inversely proportional to the square of the distance between the points, and he fully solved the corresponding [[Kepler orbit|\"two-body problem\"]] demonstrating that the radius vector between the two points would describe an ellipse. But no exact closed analytical form could be found for the [[three-body problem]].  Instead, mathematical models called \"orbital perturbation analysis\" have been developed. With these techniques a quite accurate mathematical description of the trajectories of all the planets could be obtained.  Newton recognized that the Moon's perturbations could not entirely be accounted for using just the solution to the three-body problem, as the deviations from a pure Kepler orbit around the Earth are much larger than deviations of the orbits of the planets from their own Sun-centered Kepler orbits, caused by the gravitational attraction between the planets. With the availability of digital computers and the ease with which we can now compute orbits, this problem has partly disappeared, as the motion of all celestial bodies including planets, satellites, asteroids and comets can be modeled and predicted with almost perfect accuracy using the method of the numerical propagation of the trajectories. Nevertheless, several analytical closed form expressions for the effect of such additional \"perturbing forces\" are still very useful.\n\nThe precise modeling of the motion of the Moon has been a difficult task. The best and most accurate modeling for the lunar orbit before the availability of digital computers was obtained with the complicated [[Charles-Eugène Delaunay|Delaunay]] and [[Ernest William Brown|Brown]]'s [[lunar theory|lunar theories]].\n\n==In general==\nAll celestial bodies of the [[Solar System]] follow in first approximation a [[Kepler orbit]] around a central body. For a satellite (artificial or natural) this central body is a planet. But both due to gravitational forces caused by the Sun and other celestial bodies and due to the flattening of its planet (caused by its rotation which makes the planet slightly oblate and therefore the result of the [[Shell theorem]] not fully applicable) the satellite will follow an orbit around the Earth that deviates more than the Kepler orbits observed for the planets.\n\n==Perturbation of spacecraft orbits==\nFor man-made spacecraft orbiting the Earth at comparatively low altitudes the deviations from a Kepler orbit are much larger than for the Moon. The approximation of the gravitational force of the Earth to be that of a homogeneous sphere gets worse the closer one gets to the Earth surface and the majority of the artificial Earth satellites are in orbits that are only a few hundred kilometers over the Earth surface.  Furthermore, they are (as opposed to the Moon) significantly affected by the [[solar radiation pressure]] because of their large cross-section-to-mass ratio; this applies in particular to [[3-axis stabilized spacecraft]] with large [[solar arrays]] and is allowed for in calculation of [[graveyard orbit]]s. In addition they are significantly affected by rarefied air below 800–1000&nbsp;km. The air drag at high altitudes is also dependent on [[Space weather|solar activity]].\n\n==Mathematical approach==\n\nConsider any function \n:<math>g(x_1,x_2,x_3,v_1,v_2,v_3)\\,</math>\n\nof the position\n:<math>x_1,x_2,x_3\\,</math>\n\nand the velocity\n:<math>v_1,v_2,v_3\\,</math>\n\nFrom the chain rule of differentiation one gets that the time derivative of <math>g</math> is\n\n:<math>\\dot{g}\\ =\\ \\frac{\\partial g }{\\partial x_1}\\ v_1\\ + \\ \\frac{\\partial g }{\\partial x_2}\\ v_2\\ + \\frac{\\partial g }{\\partial x_3}\\ v_3\\ + \\ \\frac{\\partial g }{\\partial v_1}\\ f_1\\ + \\ \\frac{\\partial g }{\\partial v_2}\\ f_2\\ + \\ \\frac{\\partial g }{\\partial v_3}\\ f_3</math>\n\nwhere <math>f_1\\ ,\\ f_2\\ ,\\ f_3</math> are the components of the force per unit mass acting on the body.\n\nIf now <math>g</math> is a \"constant of motion\" for a [[Kepler orbit]] like for example an [[orbital element]] and the force is corresponding \"Kepler force\"\n:<math>\n(f_1\\ ,\\ f_2\\ ,\\ f_3)\\  = \\ - \\frac {\\mu} {r^3}\\ (x_1\\ ,\\ x_2\\ ,\\ x_3)\n</math>\none has that <math>\\dot{g}\\ =\\ 0\\,</math>.\n\nIf the force is the sum of the \"Kepler force\" and an additional force (force per unit mass)\n\n:<math>(h_1\\ ,\\ h_2\\ ,\\ h_3)</math>\n\ni.e.\n\n:<math>\n(f_1\\ ,\\ f_2\\ ,\\ f_3)\\  = \\ - \\frac {\\mu} {r^3}\\ (x_1\\ ,\\ x_2\\ ,\\ x_3)\\ +\\ (h_1\\ ,\\ h_2\\ ,\\ h_3)\n</math>\n\none therefore has\n\n:<math>\\dot{g}\\ =\\frac{\\partial g }{\\partial v_1}\\ h_1\\ + \\ \\frac{\\partial g }{\\partial v_2}\\ h_2\\ + \\ \\frac{\\partial g }{\\partial v_3}\\ h_3</math>\n\nand that the change of <math>g\\,</math> in the time from <math>t=t_1\\,</math> to  <math>t=t_2\\,</math> is\n:<math>\n\\Delta g\\ =\\ \\int\\limits_{t_1}^{t_2}\\left(\\frac{\\partial g }{\\partial v_1}\\ h_1\\ + \\ \\frac{\\partial g }{\\partial v_2}\\ h_2\\ + \\ \\frac{\\partial g }{\\partial v_3}\\ h_3 \\right)dt\n</math>\n\nIf now the additional force <math>(h_1\\ ,\\ h_2\\ ,\\ h_3)\\,</math> is sufficiently small that the motion will be close to that of a [[Kepler orbit]] one gets an approximate value for <math>\\Delta g\\,</math> by evaluating this integral assuming \n<math>x_1(t),x_2(t),x_3(t)\\,</math> to precisely follow this [[Kepler orbit]].\n\nIn general one wants to find an approximate expression for the change  <math>\\Delta g\\,</math> over one orbital revolution using the true anomaly <math>\\theta\\,</math> as integration variable, i.e. as\n{{NumBlk|:|<math>\n\\Delta g\\ =\\ \\int\\limits_{0}^{2\\pi}\\left(\\frac{\\partial g }{\\partial v_1}\\ h_1\\ + \\ \\frac{\\partial g }{\\partial v_2}\\ h_2\\ + \\ \\frac{\\partial g }{\\partial v_3}\\ h_3 \\right)\\frac{r^2}{\\sqrt{\\mu p}}d\\theta\n</math>|{{EquationRef|1}}}}\n\nThis integral is evaluated setting <math>r(\\theta)=\\frac {p}{1+e\\cos \\theta}\\,</math>, the elliptical Kepler orbit in polar angles.\nFor the transformation of integration variable from time to [[true anomaly]] it was used that the angular momentum <math>H\\ =\\ r^2\\ \\dot{\\theta}\\ =\\ \\sqrt{\\mu p} \\,</math> by definition of the parameter <math>p\\,</math> for a Kepler orbit (see equation (13) of the [[Kepler orbit]] article).\n\nFor the special case where the Kepler orbit is circular or almost circular\n:<math>r\\ =\\ p</math> and ({{EquationNote|1}}) takes the simpler form\n{{NumBlk|:|<math>\n\\Delta g\\ =\\ \\frac{P}{2\\pi}\\ \\int\\limits_{0}^{2\\pi}\\left(\\frac{\\partial g }{\\partial v_1}\\ h_1\\ + \\ \\frac{\\partial g }{\\partial v_2}\\ h_2\\ + \\ \\frac{\\partial g }{\\partial v_3}\\ h_3 \\right)d\\theta\n</math>|{{EquationRef|2}}}}\n\nwhere <math>P\\ =\\ 2\\pi\\ r\\ \\sqrt{\\frac{r}{\\mu}}\\,</math> is the orbital period\n\n===Perturbation of the semi-major axis/orbital period===\n\nFor an elliptic [[Kepler orbit]], the sum of the kinetic and the potential energy\n\n:<math>g = \\frac{V^2}{2}-\\frac {\\mu} {r}</math>,\n\nwhere <math>V\\,</math> is the orbital velocity, is a constant and equal to\n\n:<math>g\\ =\\ -\\frac {\\mu} {2 \\cdot a}</math> (Equation ([[Kepler orbit#equation 44|44]]) of the Kepler orbit article)\n\nIf <math>\\bar{h}\\,</math> is the perturbing force and <math>\\bar{V}\\,</math>is the velocity vector of the Kepler orbit the equation ({{EquationNote|1}}) takes the form:\n\n{{NumBlk|:|<math>\n\\Delta g\\ =\\ \\int\\limits_{0}^{2\\pi}\\bar{V} \\bar{h}\\frac{r^2}{\\sqrt{\\mu p}}d\\theta\n</math>|{{EquationRef|3}}}}\n\nand for a circular or almost circular orbit\n\n{{NumBlk|:|<math>\n\\Delta g\\ =\\ \\frac{P}{2\\pi}\\ \\int\\limits_{0}^{2\\pi} \\bar{V} \\bar{h}d\\theta\n</math>|{{EquationRef|4}}}}\n\nFrom the change <math>\\Delta g\\,</math> of the parameter <math>g\\,</math> the new semi-major axis <math>a\\,</math> and the new period <math>P\\ =\\ 2\\pi\\ a\\ \\sqrt{\\frac{a}{\\mu}}\\,</math> are computed (relations (43) and (44) of the [[Kepler orbit]] article).\n\n===Perturbation of the orbital plane===\n\nLet <math>\\hat{g}\\,</math> and <math>\\hat{h}\\,</math> make up a rectangular coordinate system in the plane of the reference Kepler orbit. If <math>\\omega\\,</math> is the argument of perigee relative the <math>\\hat{g}\\,</math> and <math>\\hat{h}\\,</math> coordinate system the true anomaly <math>\\theta\\,</math> is given by <math>\\theta=u-\\omega\\,</math> and the approximate change <math> \\Delta \\hat{z}\\,</math> of the orbital pole <math> \\hat{z}\\,</math> (defined as the unit vector in the direction of the angular momentum) is\n{{NumBlk|:|<math>\n\\Delta \\hat{z}\\ =\\ \\int\\limits_{0}^{2\\pi}\\frac{f_z }{V_t} (\\hat{g} \\cos u  + \\hat{h} \\sin u)\\frac{r^2}{\\sqrt{\\mu p}}du \\quad \\times \\ \\hat{z}\n=\\ \\frac{1}{\\mu p}\\left[\\hat{g}\\int\\limits_{0}^{2\\pi}f_z r^3 \\cos u \\ du\n+\\ \\hat{h}\\int\\limits_{0}^{2\\pi}f_z r^3 \\sin u \\ du \\right]\\quad \\times \\ \\hat{z}\n</math>|{{EquationRef|5}}}}\n\nwhere <math>f_z\\,</math> is the component of the perturbing force in the <math> \\hat{z}\\,</math> direction, <math>V_t=\\sqrt{\\frac{\\mu}{p}}\\ (1+e\\ \\cos\\theta)\\,</math> is the velocity component of the Kepler orbit orthogonal to radius vector and <math>r=\\frac{p}{1+e\\ \\cos\\theta}\\,</math> is the distance to the center of the Earth.\n \nFor a circular or almost circular orbit ({{EquationNote|5}}) simplifies to\n\n{{NumBlk|:|<math>\n\\Delta \\hat{z}\\ =\\ \\frac{r^2}{\\mu}\\left[\\hat{g}\\int\\limits_{0}^{2\\pi}f_z \\cos u \\ du\n+\\ \\hat{h}\\int\\limits_{0}^{2\\pi}f_z \\sin u \\ du \\right]\\quad \\times \\ \\hat{z}\n</math>|{{EquationRef|6}}}}\n\n'''Example'''\n\nIn a circular orbit a low-force propulsion system ([[Ion thruster]]) generates a thrust (force per unit mass) of <math>F\\  \\hat{z}\\,</math> in the direction of the orbital pole in the half of the orbit for which <math>\\sin u\\,</math> is positive and in the opposite direction in the other half. The resulting change of orbit pole after one orbital revolution of duration <math>P\\ =\\ 2\\pi\\ r\\ \\sqrt{\\frac{r}{\\mu}}\\,</math> is\n\n{{NumBlk|:|<math>\n\\Delta \\hat{z}\\ =\\ \\frac{r^2}{\\mu}\\left[\\ 2\\ F\\int\\limits_{0}^{\\pi}\\sin u \\ du \\right]\\quad \\hat{h}\\times \\hat{z} =\n\\ \\frac{r^2}{\\mu}\\ 4\\ F\\ \\quad \\hat{g}\n</math>|{{EquationRef|7}}}}\n\nThe average change rate <math>\\frac{\\Delta \\hat{z}}{P}\\,</math> is therefore\n\n{{NumBlk|:|<math>\n\\frac{\\Delta \\hat{z}}{P} =\\ \\frac{2}{\\pi}\\ \\frac{F}{V}\\ \\hat{g}\n</math>|{{EquationRef|8}}}}\nwhere <math>V\\ =\\ \\sqrt{\\frac{\\mu}{r}},</math> is the orbital velocity in the circular Kepler orbit.\n\n===Perturbation of the eccentricity vector===\n\nRather than applying (1) and (2) on the partial derivatives of the orbital elements '''eccentricity''' and '''argument of perigee''' directly one should apply these relations for the [[eccentricity vector]]. First of all the typical application is a near-circular orbit. But there are also mathematical advantages working with the partial derivatives of the components of this vector also for orbits with a significant eccentricity.\n\nEquations (60), (55) and (52) of the [[Kepler orbit]] article say that the eccentricity vector is\n \n{{NumBlk|:|<math>\\bar{e}=\\frac{(V_t-V_0) \\cdot \\hat{r} - V_r \\cdot \\hat{t}}{V_0}</math>|{{EquationRef|9}}}}\n\nwhere\n\n{{NumBlk|:|<math>V_0 = \\sqrt{\\frac{\\mu}{p}}</math>|{{EquationRef|10}}}}\n{{NumBlk|:|<math>p = \\frac{{(r \\cdot V_t)}^2}{\\mu }</math>|{{EquationRef|11}}}}\n\nfrom which follows that\n\n{{NumBlk|:|<math>\\frac{\\partial\\bar{e}}{\\partial V_r} = -\\frac {1}{V_0} \\hat{t}</math>|{{EquationRef|12}}}}\n{{NumBlk|:|<math>\\frac{\\partial\\bar{e}}{\\partial V_t} = \\frac {1}{V_0} \\left(2\\ \\hat{r}-\\frac{V_r}{V_t}\\ \\hat{t}\\right)</math>|{{EquationRef|13}}}}\n\nwhere\n\n{{NumBlk|:|<math>V_r = \\sqrt{\\frac {\\mu}{p}} \\cdot e \\cdot \\sin \\theta</math>|{{EquationRef|14}}}}\n{{NumBlk|:|<math>V_t = \\sqrt{\\frac {\\mu}{p}} \\cdot (1 + e \\cdot \\cos \\theta)</math>|{{EquationRef|15}}}}\n\n(Equations (18) and (19) of the [[Kepler orbit]] article)\n\nThe eccentricity vector is by definition always in the [[Osculating orbit|osculating]] orbital plane spanned by <math>\\hat{r}</math> and <math>\\hat{t}</math> and formally there is also a derivative \n:<math>\\frac{\\partial\\bar{e}}{\\partial V_z} = -\\frac {V_r}{V_0}\\  \\frac{\\partial\\hat{t}}{\\partial V_z}</math>\n\nwith\n:<math>\\frac{\\partial\\hat{t}}{\\partial V_z} =  \\frac {1}{V_t}\\ \\hat{z}</math>\n\ncorresponding to the rotation of the orbital plane\n\nBut in practice the in-plane change of the eccentricity vector is computed as\n\n{{NumBlk|:|<math>\n\\begin{align}\n\\Delta \\bar{e}\\ = &\\frac {1}{V_0}\\ \\int\\limits_{0}^{2\\pi}\\left(-\\hat{t}\\ f_r\\ + \\ \\left(2\\ \\hat{r}-\\frac{V_r}{V_t}\\ \\hat{t}\\right)\\ f_t\\right)\\frac{r^2}{\\sqrt{\\mu p}}du\\ = \\\\\n&\\frac {1}{\\mu}\\ \\int\\limits_{0}^{2\\pi}\\left(-\\hat{t}\\ f_r\\ + \\ \\left(2\\ \\hat{r}-\\frac{V_r}{V_t}\\ \\hat{t}\\right)\\ f_t\\right) r^2 du \\end{align}\n</math>|{{EquationRef|16}}}}\n\nignoring the out-of-plane force and the new eccentricity vector \n:<math>\\bar{e} + \\Delta \\bar{e}</math>\nis subsequently projected to the new orbital plane orthogonal to the new orbit normal\n:<math>\\hat{z} + \\Delta \\hat{z}</math>\ncomputed as described above.\n\n'''Example'''\n\nThe Sun is in the orbital plane of a spacecraft in a circular orbit with radius <math>r\\,</math> and consequently with a constant orbital velocity <math>V_0\\ =\\ \\sqrt{\\frac{\\mu}{r}}</math> . If <math>\\hat{k}\\,</math> and <math>\\hat{l}\\,</math> make up a rectangular coordinate system in the orbital plane such that <math>\\hat{k}\\,</math> points to the Sun and assuming that the solar radiation pressure force per unit mass <math>F\\,</math> is constant  one gets that \n:<math>\\hat{r}=\\cos(u)\\ \\hat{k}\\ +\\ \\sin(u)\\ \\hat{l}\\,</math>\n:<math>\\hat{t}=-\\sin(u)\\ \\hat{k}\\ +\\ \\cos(u)\\ \\hat{l}\\,</math>\n:<math>F_r=-\\cos(u)\\ F\\,</math>\n:<math>F_t= \\sin(u)\\ F\\,</math>\n\nwhere <math>u\\,</math> is the polar angle of <math>\\hat{r}\\,</math> in the <math>\\hat{k}\\,</math>, <math>\\hat{l}\\,</math> system. Applying ({{EquationNote|2}}) one gets that\n\n{{NumBlk|:|<math>\n\\begin{align}\n\\Delta \\hat{e}\\ & =\\ \\frac{P}{2\\pi}\\ \\frac {1}{V_0}\\ \\int\\limits_{0}^{2\\pi}\\left( (-\\sin(u)\\ \\hat{k}\\ +\\ \\cos(u)\\ \\hat{l}) \\ F\\  \\cos(u)\\ + \\ 2\\ (\\cos(u)\\ \\hat{k}\\ +\\ \\sin(u)\\ \\hat{l})\\ F\\ \\sin(u)\\right)\\ du \\\\\n& = P\\ \\frac{3}{2}\\ \\frac {1}{V_0}\\ \\ F\\ \\hat{l} \n\\end{align}\n</math>|{{EquationRef|17}}}}\n\nThis means the eccentricity vector will gradually increase in the direction <math>\\hat{l}\\,</math> orthogonal to the Sun direction. This is true for any orbit with a small eccentricity, the direction of the small eccentricity vector does not matter.  As <math>P\\,</math> is the orbital period this means that the average rate of this increase will be \n<math>\\frac{3}{2}\\ \\frac {F}{V_0}\\,</math>\n\n==The effect of the Earth flattening==\n[[File:Spherical coordinates unit vectors.svg|thumb|right|Figure 1: The unit vectors <math>\\hat{\\phi}\\ ,\\ \\hat{\\lambda}\\ ,\\ \\hat{r}</math>]]\nIn the article [[Geopotential model]] the modeling of the gravitational field as a sum of spherical harmonics is discussed. By far, the dominating term is the \"J2-term\". This is a \"zonal term\" and corresponding force is therefore completely in a longitudinal plane with one component <math>F_r\\ \\hat{r}\\,</math> in the radial direction and one component <math>F_\\lambda\\ \\hat{\\lambda}\\,</math>  with the unit vector <math>\\hat{\\lambda}\\,</math> orthogonal to the radial direction towards north. These directions <math>\\hat{r}\\,</math> and <math>\\hat{\\lambda}\\,</math> are illustrated in Figure 1.\n\n[[File:Zonal term force components.svg|thumb|right|Figure 2: The unit vector <math>\\hat{t}\\,</math> orthogonal to <math>\\hat{r}\\,</math> in the direction of motion and the orbital pole <math>\\hat{z}\\,</math>. The force component <math>F_\\lambda</math> is marked as \"F\"]]\n\nTo be able to apply relations derived in the previous section the force component <math>F_\\lambda\\ \\hat{\\lambda}\\,</math> must be split into two orthogonal components <math>F_t\\ \\hat{t}</math> and <math>F_z\\ \\hat{z}</math> as illustrated in figure 2\n\nLet <math>\\hat{a}\\ ,\\ \\hat{b}\\ ,\\ \\hat{n}\\,</math> make up a rectangular coordinate system with origin in the center of the Earth (in the center of the [[Reference ellipsoid]])  such that <math>\\hat{n}\\,</math> points in the direction north and such that <math>\\hat{a}\\ ,\\ \\hat{b}\\,</math> are in the equatorial plane of the Earth with <math>\\hat{a}\\,</math> pointing towards the [[Orbital node|ascending node]], i.e. towards the blue point of Figure 2.\n\nThe components of the unit vectors\n:<math>\\hat{r}\\ ,\\ \\hat{t}\\ ,\\ \\hat{z}\\,</math>\n\nmaking up the local coordinate system (of which <math>\\hat{t}\\ ,\\ \\hat{z},</math> are illustrated in figure 2) relative the <math>\\hat{a}\\ ,\\ \\hat{b}\\ ,\\ \\hat{n}\\,</math> are\n\n:<math>r_a= \\cos u\\,</math>\n:<math>r_b= \\cos i \\ \\sin u\\,</math>\n:<math>r_n= \\sin i \\ \\sin u\\,</math>\n:<math>t_a=-\\sin u\\,</math>\n:<math>t_b= \\cos i \\ \\cos u\\,</math>\n:<math>t_n= \\sin i \\ \\cos u\\,</math>\n:<math>z_a= 0\\,</math>\n:<math>z_b=-\\sin i\\,</math>\n:<math>z_n= \\cos i\\,</math>\n\nwhere <math>u\\,</math> is the polar argument of <math>\\hat{r}\\,</math> relative the orthogonal unit vectors <math>\\hat{g}=\\hat{a}\\,</math> and <math>\\hat{h}=\\cos i\\ \\hat{b}\\ +\\ \\sin i\\ \\hat{n}\\,</math> in the orbital plane\n\nFirstly\n\n:<math>\\sin \\lambda =\\ r_n\\ =\\ \\sin i \\ \\sin u\\,</math>\n\nwhere  <math>\\lambda\\,</math> is the angle between the equator plane and <math>\\hat{r}\\,</math> (between the green points of figure 2) and from equation (12) of the article [[Geopotential model]] one therefore gets that\n{{NumBlk|:|<math>\nf_r = J_2\\ \\frac{1}{r^4}\\ \\frac{3}{2}\\ \\left(3\\ \\sin^2 i\\ \\sin^2 u\\ -\\ 1\\right)\n</math>|{{EquationRef|18}}}}\n\nSecondly the projection of direction north, <math>\\hat{n}\\,</math>, on the plane spanned by <math>\\hat{t}\\ ,\\ \\hat{z},</math> is\n\n:<math>\\sin i \\ \\cos u \\ \\hat{t}\\ +\\ \\cos i \\ \\hat{z}\\,</math>\n\nand this projection is \n:<math>\\cos \\lambda \\ \\hat{\\lambda}\\,</math>\n\nwhere <math>\\hat{\\lambda}\\,</math> is the unit vector <math>\\hat{\\lambda}</math> orthogonal to the radial direction towards north illustrated in figure 1.\n\nFrom equation (12) of the article [[Geopotential model]] one therefore gets that\n\n:<math>f_\\lambda \\ \\hat{\\lambda}\\ =\\ -J_2\\ \\frac{1}{r^4}\\ 3\\ \\sin\\lambda\\ (\\sin i \\ \\cos u \\ \\hat{t}\\ +\\ \\cos i \\ \\hat{z}) =\\ -J_2\\ \\frac{1}{r^4}\\ 3\\ \\sin i \\ \\sin u\\ (\\sin i \\ \\cos u \\ \\hat{t}\\ +\\ \\cos i \\ \\hat{z})\\,</math>\n\nand therefore:\n{{NumBlk|:|<math>\nf_t  =\\ -J_2\\ \\frac{1}{r^4}\\ 3\\ \\sin^2 i\\ \\sin u\\ \\cos u\n</math>|{{EquationRef|19}}}}\n{{NumBlk|:|<math>\nf_z =\\ -J_2\\ \\frac{1}{r^4}\\ 3\\ \\sin i\\ \\cos i\\ \\sin u\n</math>|{{EquationRef|20}}}}\n\n===Perturbation of the orbital plane===\nFrom ({{EquationNote|5}}) and ({{EquationNote|20}}) one gets that\n\n{{NumBlk|:|<math>\n\\Delta \\hat{z}\\ =\\ -J_2\\ \\frac{3\\ \\sin i\\ \\cos i}{\\mu p^2}\\left[\\hat{g}\\int\\limits_{0}^{2\\pi}\\frac{p}{r}\\ \\sin u\\ \\cos u \\ du\n+\\ \\hat{h}\\int\\limits_{0}^{2\\pi}\\frac{p}{r}\\ \\sin^2 u\\ du \\right]\\quad \\times \\ \\hat{z}\n</math>|{{EquationRef|21}}}}\n\nThe fraction <math>\\frac{p}{r}\\,</math> is\n:<math>\\frac{p}{r}\\ =\\ 1\\ +\\ e\\ \\cos (u-\\omega)\\ =\\ 1\\ +\\ e\\ \\cos u\\ \\cos\\omega\\ +\\ e\\ \\sin u\\ \\sin\\omega\\,</math>\nwhere <math>e\\,</math> is the eccentricity\nand <math>\\omega\\,</math> is the argument of perigee \nof the reference [[Kepler orbit]]\n\nAs all integrals of type\n:<math>\\int\\limits_{0}^{2\\pi} \\cos^m u \\ \\sin^n u\\ du\\,</math>\nare zero if not both <math>n\\,</math> and <math>m\\,</math> are even one gets from ({{EquationNote|21}}) that\n\n:<math>\n\\Delta \\hat{z}\\ =\\ -2\\pi\\ \\frac{J_2}{\\mu\\ p^2}\\ \\frac{3}{2}\\ \\sin i\\ \\cos i\\ \\quad \\hat{h} \\times \\hat{z}\n</math>\n\nAs\n:<math>\n\\hat{n}\\ =\\ \\cos i\\ \\hat{z}\\ + \\sin i\\ \\hat{h}\n</math>\n\nthis can be written\n{{NumBlk|:|<math>\n\\Delta \\hat{z}\\ =\\ -2\\pi\\ \\frac{J_2}{\\mu\\ p^2}\\ \\frac{3}{2}\\ \\cos i\\ \\quad \\hat{n} \\times \\hat{z}\n</math>|{{EquationRef|22}}}}\n\nAs  <math>\\hat{n}</math> is an inertially fixed vector (the direction of the spin axis of the Earth) relation ({{EquationNote|22}}) is the equation of motion for a unit vector <math>\\hat{z}\\,</math> describing a cone around <math>\\hat{n}</math> with a precession rate (radians per orbit) of <math>-2\\pi\\ \\frac{J_2}{\\mu\\ p^2}\\ \\frac{3}{2}\\ \\cos i\\,</math>\n\nIn terms of orbital elements this is expressed as\n\n{{NumBlk|:|<math>\n\\Delta i\\ =\\ 0\n</math>|{{EquationRef|23}}}}\n{{NumBlk|:|<math>\n\\Delta \\Omega\\ =\\ -2\\pi\\ \\frac{J_2}{\\mu\\ p^2}\\ \\frac{3}{2}\\ \\cos i\n</math>|{{EquationRef|24}}}}\n\nwhere\n:<math>i\\,</math> is the inclination of the orbit to the equatorial plane of the Earth\n\n:<math>\\Omega\\,</math> is the right ascension of the ascending node\n\n===Perturbation of the eccentricity vector===\n\nFrom ({{EquationNote|16}}), ({{EquationNote|18}}) and ({{EquationNote|19}}) follows that in-plane perturbation of the eccentricity vector is\n\n{{NumBlk|:|<math>\n\\Delta \\bar{e}\\ =\\ \\frac {J_2}{\\mu\\ p^2}\\ \\int\\limits_{0}^{2\\pi}\\left(-\\hat{t}\\ \\left(\\frac{p}{r}\\right)^2\\ \\frac{3}{2}\\ \\left(3\\ \\sin^2 i\\ \\sin^2 u\\ -\\ 1\\right)\\ - \\ \\left(2\\ \\hat{r}-\\frac{V_r}{V_t}\\ \\hat{t}\\right)\\ \\left(\\frac{p}{r}\\right)^2\\ 3\\ \\sin^2 i \\cos u\\ \\sin u\\right)du \n</math>|{{EquationRef|25}}}}\n\nthe new eccentricity vector being the projection of \n:<math>\\bar{e}+\\Delta \\bar{e}</math>\n\non the new orbital plane orthogonal to\n:<math>\\hat{z}+\\Delta \\hat{z}</math>\nwhere <math>\\Delta \\hat{z}\\,</math> is given by ({{EquationNote|22}})\n\nRelative the coordinate system\n:<math>\\hat{g}=\\hat{a}\\,</math>\n:<math>\\hat{h}=\\cos i\\ \\hat{b}\\ +\\ \\sin i\\ \\hat{n}\\,</math>\n\none has that\n\n:<math>\\hat{r}=\\cos u\\ \\hat{g}\\ +\\ \\sin u\\ \\hat{h}\\,</math>\n:<math>\\hat{t}=-\\sin u\\ \\hat{g}\\ +\\ \\cos u\\ \\hat{h}\\,</math>\n\nUsing that\n\n:<math>\\frac {p}{r}\\ =\\ 1 + e \\cdot \\cos \\theta\\ =\\ 1 + e_g \\cdot \\cos u + e_h \\cdot \\sin u</math>\nand that\n\n:<math>\\frac {V_r}{V_t} = \\frac {e_g \\cdot \\sin u\\ -\\ e_h \\cdot \\cos u}{\\frac {p}{r}}</math>\n\nwhere\n\n:<math>e_g =\\ e\\ \\cos \\omega</math>\n:<math>e_h =\\ e\\ \\sin \\omega</math>\n\nare the components of the eccentricity vector in the <math>\\hat{g}\\ ,\\ \\hat{h}\\,</math> coordinate system this integral ({{EquationNote|25}}) can be evaluated analytically, the result is\n\n{{NumBlk|:|<math>\n\\Delta \\bar{e}\\ =\\ -2\\pi\\ \\frac {J_2}{\\mu\\ p^2}\\ \\frac{3}{2} \\left(\\frac{3}{2}\\ \\sin^2 i\\ -\\ 1\\right)\\ \\left(-e_h \\hat{g}\\ +\\ e_g \\hat{h}\\right)\\ =\\ -2\\pi\\ \\frac {J_2}{\\mu\\ p^2} \\frac{3}{2} \\left(\\frac{3}{2}\\ \\sin^2 i\\ -\\ 1\\right)\\ \\hat{z}\\ \\times \\  \\bar{e}\n</math>|{{EquationRef|26}}}}\n\nThis the difference equation of motion for the eccentricity vector <math>\\bar{e}\\,</math> to form a circle, the magnitude of the eccentricity <math>e\\,</math> staying constant.\n\nTranslating this to orbital elements it must be remembered that the new eccentricity vector obtained by adding <math>\\Delta \\bar{e}\\ \\,</math> to the old <math>\\bar{e}\\ \\,</math> must be projected to the new orbital plane obtained by applying ({{EquationNote|23}}) and ({{EquationNote|24}})\n\n[[File:J2-perturbation.svg|thumb|right|Figure 3: The change <math>\\Delta\\omega\\,</math> in \"argument of perigee\" after one orbit is the sum of a contribution <math>\\Delta \\omega_1\\,</math> caused by the in-plane force components and a contribution <math>\\Delta \\omega_2\\,</math> caused by the use of the ascending node as reference]]\nThis is illustrated  in figure 3:\n\nTo the change in argument of the eccentricity vector\n\n:<math>\\Delta \\omega_1\\ =\\ -2\\pi\\ \\frac {J_2}{\\mu\\ p^2}\\ \\frac{3}{2} \\left(\\frac{3}{2}\\ \\sin^2 i\\ -\\ 1\\right)\\,</math>\n\nmust be added an increment due to the precession of the orbital plane (caused by the out-of-plane force component) amounting to\n\n:<math>\\Delta \\omega_2\\ =\\ -\\cos i\\ \\Delta\\Omega \\ =\\ 2\\pi\\ \\frac {J_2}{\\mu\\ p^2}\\ \\frac{3}{2}\\ \\cos^2 i\\,</math>\n\nOne therefore gets that\n\n{{NumBlk|:|<math>\n\\Delta e\\ =0\n</math>|{{EquationRef|27}}}}\n\n{{NumBlk|:|<math>\n\\Delta \\omega\\ =\\Delta \\omega_1\\ +\\ \\Delta \\omega_2\\ =\\ \\ -2\\pi\\ \\frac {J_2}{\\mu\\ p^2}\\ 3 \\left(\\frac{5}{4}\\ \\sin^2 i\\ -\\ 1\\right)</math>|{{EquationRef|28}}}}\n\nIn terms of the components of the eccentricity vector <math>e_g,e_h\\,</math> relative the coordinate system <math>\\hat{g} ,\\hat{h}\\,</math> that precesses around the polar axis of the Earth the same is expressed as follows\n\n{{NumBlk|:|<math>\n\\begin{align}\n&(\\Delta e_g,\\Delta e_h)\\ = \\\\\n&-2\\pi\\ \\frac {J_2}{\\mu\\ p^2}\\ \\frac{3}{2} \\left(\\frac{3}{2}\\ \\sin^2 i\\ -\\ 1\\right)\\ (-e_h ,e_g)\\ + \\ 2\\pi\\ \\frac {J_2}{\\mu\\ p^2}\\ \\frac{3}{2}\\ \\cos^2 i\\ (-e_h ,e_g ) = \\\\\n&-2\\pi\\ \\frac {J_2}{\\mu\\ p^2}\\ 3 \\left(\\frac{5}{4}\\ \\sin^2 i\\ -\\ 1\\right)\\ (-e_h ,e_g) \n\\end{align}\n</math>|{{EquationRef|29}}}}\n\nwhere the first term is the in-plane perturbation of the eccentricity vector and the second is the effect of the new position of the ascending node in the new plane\n\nFrom ({{EquationNote|28}}) follows that <math>\\Delta \\omega\\,</math> is zero if <math>\\sin^2 i\\ =\\frac{4}{5}\\,</math>. This fact is used for [[Molniya orbit]]s having an inclination of 63.4 deg. An orbit with an inclination of 180 - 63.4 deg = 116.6 deg would in the same way have a constant argument of perigee.\n\n====Proof====\n\nProof that the integral\n\n{{NumBlk|:|<math>\n\\int\\limits_{0}^{2\\pi}\\left(-\\hat{t}\\ \\left(\\frac{p}{r}\\right)^2\\ \\frac{3}{2}\\ \\left(3\\ \\sin^2 i\\ \\sin^2 u\\ -\\ 1\\right)\\ - \\ \\left(2\\ \\hat{r}-\\frac{V_r}{V_t}\\ \\hat{t}\\right)\\ \\left(\\frac{p}{r}\\right)^2\\ 3\\ \\sin^2 i \\cos u\\ \\sin u\\right)du \n</math>|{{EquationRef|30}}}}\n\nwhere:\n:<math>\\hat{r}=\\cos u\\ \\hat{G}\\ +\\ \\sin u\\ \\hat{H}\\,</math>\n:<math>\\hat{t}=-\\sin u\\ \\hat{G}\\ +\\ \\cos u\\ \\hat{H}\\,</math>\n:<math>\\frac{p}{r}\\ =\\ 1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u</math>\n:<math>\\frac{V_r}{V_t}\\ =\\ \\frac{e_g\\ \\sin u\\ -\\ e_h\\ \\cos u}{\\frac{p}{r}}</math>\n\nhas the value \n{{NumBlk|:|<math>\n-2\\pi\\  \\frac{3}{2} \\left(\\frac{3}{2}\\ \\sin^2 i\\ -\\ 1\\right)\\ \\left(-e_h \\hat{G}\\ +\\ e_g \\hat{H}\\right)\n</math>|{{EquationRef|31}}}}\n\nIntegrating the first term of the integrand one gets:\n\n{{NumBlk|:|<math>\n\\begin{align}\n&\\int\\limits_{0}^{2\\pi}-t_g\\ \\left(\\frac{p}{r}\\right)^2\\ \\frac{3}{2}\\ 3\\ \\sin^2 i\\ \\sin^2 u\\ du\\  =\\  \n\\frac{9}{2}\\ \\sin^2 i\\ \\int\\limits_{0}^{2\\pi}\\ \\left(1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u\\right)^2\\ \\ \\sin^3 u\\ du\\  = \\\\   \n&9\\ \\sin^2 i\\ e_h\\ \\int\\limits_{0}^{2\\pi}\\sin^4 u\\ du\\ =\\ 2\\pi \\frac{27}{8}\\ \\sin^2 i\\ e_h \n\\end{align}\n</math>|{{EquationRef|32}}}}\n\nand\n\n{{NumBlk|:|<math>\n\\begin{align}\n&\\int\\limits_{0}^{2\\pi}-t_h\\ \\left(\\frac{p}{r}\\right)^2\\ \\frac{3}{2}\\ 3\\ \\sin^2 i\\ \\sin^2 u\\ du\\  =\\  \n-\\frac{9}{2}\\ \\sin^2 i\\ \\int\\limits_{0}^{2\\pi}\\ \\left(1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u\\right)^2\\ \\ \\sin^2 u\\ \\cos u\\ du\\  = \\\\   \n&-9\\ \\sin^2 i\\ e_g\\ \\int\\limits_{0}^{2\\pi}\\sin^2 u\\ \\cos^2 u\\ du\\ =\\ -2\\pi \\frac{9}{8}\\ \\sin^2 i\\ e_g \n\\end{align}\n</math>|{{EquationRef|33}}}}\n\nFor the second term one gets:\n\n{{NumBlk|:|<math>\n\\int\\limits_{0}^{2\\pi} t_g\\ \\left(\\frac{p}{r}\\right)^2\\ \\frac{3}{2}\\ du\\  =\\  \n-\\frac{3}{2}\\ \\int\\limits_{0}^{2\\pi}\\ \\left(1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u\\right)^2\\ \\ \\sin u\\ du\\  =\\     \n-3\\ e_h\\ \\int\\limits_{0}^{2\\pi}\\sin^2 u\\ du\\ =\\ -2\\pi \\frac{3}{2}\\ e_h\n</math>|{{EquationRef|34}}}}\n\nand\n\n{{NumBlk|:|<math>\n\\int\\limits_{0}^{2\\pi} t_h\\ \\left(\\frac{p}{r}\\right)^2\\ \\frac{3}{2}\\ du\\  =\\  \n\\frac{3}{2}\\ \\int\\limits_{0}^{2\\pi}\\ \\left(1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u\\right)^2\\ \\ \\cos u\\ du\\  =\\     \n3\\ e_g\\ \\int\\limits_{0}^{2\\pi}\\cos^2 u\\ du\\ =\\ 2\\pi \\frac{3}{2}\\ e_g\n</math>|{{EquationRef|35}}}}\n\nFor the third term one gets:\n{{NumBlk|:|<math>\n\\begin{align}\n&-\\int\\limits_{0}^{2\\pi}\\ 2\\ r_g \\ \\left(\\frac{p}{r}\\right)^2\\ 3\\ \\sin^2 i \\cos u\\ \\sin u\\ du\\ =\\ \n-6\\ \\sin^2 i \\int\\limits_{0}^{2\\pi}\\ \\left(1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u\\right)^2\\ \\cos^2 u\\ \\sin u\\ du\\ =\\  \\\\\n&-12\\ \\sin^2 i\\ e_h \\int\\limits_{0}^{2\\pi}\\ \\cos^2 u\\ \\sin^2 u\\ du\\ =\\ -2\\pi \\frac{3}{2}\\ \\sin^2 i\\ e_h\n\\end{align}\n</math>|{{EquationRef|36}}}}\n\nand\n\n{{NumBlk|:|<math>\n\\begin{align}\n&-\\int\\limits_{0}^{2\\pi}\\ 2\\ r_h \\ \\left(\\frac{p}{r}\\right)^2\\ 3\\ \\sin^2 i \\cos u\\ \\sin u\\ du\\ =\\ \n-6\\ \\sin^2 i \\int\\limits_{0}^{2\\pi}\\ \\left(1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u\\right)^2\\ \\cos u\\ \\sin^2 u\\ du\\ =\\  \\\\\n&-12\\ \\sin^2 i\\ e_g \\int\\limits_{0}^{2\\pi}\\ \\sin^2 u \\cos^2 u\\ du\\ =\\ -2\\pi \\ \\frac{3}{2}\\ \\sin^2 i\\ e_g\n\\end{align}\n</math>|{{EquationRef|37}}}}\n\nFor the fourth term one gets:\n\n{{NumBlk|:|<math>\n\\begin{align}\n&\\int\\limits_{0}^{2\\pi}t_g\\ \\frac{V_r}{V_t}\\ \\left(\\frac{p}{r}\\right)^2\\ 3\\ \\sin i \\cos^2 u\\ \\sin u\\ du\\ =\n-3\\ \\sin^2 i \\int\\limits_{0}^{2\\pi}(e_g\\ \\sin u\\ -\\ e_h\\ \\cos u)\\ \\frac{p}{r}\\ \\cos u\\ \\sin^2 u\\ du \\ = \\\\ \n&-3\\ \\sin^2 i \\int\\limits_{0}^{2\\pi}(e_g\\ \\sin u\\ -\\ e_h\\ \\cos u)\\ (1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u)\\ \\cos u\\ \\sin^2 u\\ du\\ = \\\\\n&3\\ \\sin^2 i \\ e_h\\int\\limits_{0}^{2\\pi}\\ \\ \\cos^2 u\\ \\sin^2 u\\ du\\ =\\ 2\\pi \\frac{3}{8} \\sin^2 i \\ e_h\n\\end{align}\n</math>|{{EquationRef|38}}}}\n\nand\n\n{{NumBlk|:|<math>\n\\begin{align}\n&\\int\\limits_{0}^{2\\pi}t_h\\ \\frac{V_r}{V_t}\\ \\left(\\frac{p}{r}\\right)^2\\ 3\\ \\sin^2 i \\cos u\\ \\sin u\\ du\\ =\n3\\ \\sin^2 i \\int\\limits_{0}^{2\\pi}(e_g\\ \\sin u\\ -\\ e_h\\ \\cos u)\\ \\frac{p}{r}\\ \\cos^2 u\\ \\sin u\\ du \\ = \\\\ \n&3\\ \\sin^2 i \\int\\limits_{0}^{2\\pi}(e_g\\ \\sin u\\ -\\ e_h\\ \\cos u)\\ (1\\ +\\ e_g\\ \\cos u\\ +\\ e_h\\ \\sin u)\\ \\cos^2 u\\ \\sin u\\ du\\ = \\\\\n&3\\ \\sin^2 i \\ e_g\\int\\limits_{0}^{2\\pi}\\ \\ \\cos^2 u\\ \\sin^2 u\\ du\\ =\\ 2\\pi \\frac{3}{8} \\sin^2 i \\ e_g\n\\end{align}\n</math>|{{EquationRef|39}}}}\n\nAdding the right hand sides of ({{EquationNote|32}}), ({{EquationNote|34}}), ({{EquationNote|36}}) and ({{EquationNote|38}}) one gets\n<math>\n2\\pi \\frac{27}{8}\\ \\sin^2 i\\ e_h\\ -\\ 2\\pi \\frac{3}{2}\\ e_h\\ -\\ 2\\pi \\frac{3}{2}\\ \\sin^2 i\\ e_h\\ +\\ 2\\pi \\frac{3}{8} \\sin^2 i \\ e_h\n\\ =\\ 2\\pi\\  \\frac{3}{2} \\left(\\frac{3}{2}\\ \\sin^2 i\\ -\\ 1\\right)\\ e_h\n</math>\n\nAdding the right hand sides of ({{EquationNote|33}}), ({{EquationNote|35}}), ({{EquationNote|37}}) and ({{EquationNote|39}}) one gets\n<math>\n-2\\pi \\frac{9}{8}\\ \\sin^2 i\\ e_g\\ +\\ 2\\pi \\frac{3}{2}\\ e_g\\ -\\ 2\\pi \\ \\frac{3}{2}\\ \\sin^2 i\\ e_g\\ +\\ 2\\pi \\frac{3}{8} \\sin^2 i \\ e_g\\ =\\ -2\\pi\\  \\frac{3}{2} \\left(\\frac{3}{2}\\ \\sin^2 i\\ -\\ 1\\right)\\ e_g\n</math>\n\n==References==\n\n* P.E. El'Yasberg: [https://archive.org/details/nasa_techdoc_19670020827 Introduction to the Theory of Flight of Artificial Earth Satellites]\n\n==See also==\n* [[Frozen orbit]]\n* [[Molniya orbit]]\n\n[[Category:Orbital perturbations]]\n[[Category:Spaceflight concepts]]"
    },
    {
      "title": "Osculating orbit",
      "url": "https://en.wikipedia.org/wiki/Osculating_orbit",
      "text": "[[File:Enckes method-vector.svg|thumb|Osculating orbit (inner, black) and perturbed orbit (red)]]\n\nIn [[astronomy]], and in particular in [[astrodynamics]], the '''osculating orbit''' of an object in space at a given moment in time is the gravitational [[Kepler orbit]] (i.e. an [[elliptic orbit|elliptic]] or other conic one) that it would have around its [[primary (astronomy)|central body]] if [[perturbation (astronomy)|perturbations]] were absent.<ref>{{cite book |first=Forest R. |last=Moulton |title=Introduction to Celestial Mechanics |orig-year=1902 |publisher=Dover |year=1970 |pages=322-23 |isbn=0486646874 |edition=2nd revised |location=[[Mineola, New York]]}}</ref> That is, it is the orbit that coincides with the current [[orbital state vectors]] (position and [[velocity]]).\n\n==Etymology==\nThe word ''[[wikt:en:osculate|osculate]]'' is [[Latin (language)|Latin]] for “kiss”. In mathematics, two curves osculate when they just touch, without (necessarily) crossing, at a point, where both have the same position and slope, i.e. the two curves “kiss”.\n\n== Kepler elements ==\nAn osculating orbit and the object's position upon it can be fully described by the six standard Kepler [[orbital elements]] (osculating elements), which are easy to calculate as long as one knows the object's position and velocity relative to the central body. The osculating elements would remain constant in the absence of [[perturbation (astronomy)|perturbations]]. Real astronomical orbits experience perturbations that cause the osculating elements to evolve, sometimes very quickly. In cases where general celestial mechanical analyses of the motion have been carried out (as they have been for the major planets, the Moon, and other [[planetary satellite]]s), the orbit can be described by a set of mean elements with secular and periodic terms. In the case of [[minor planet]]s, a system of [[proper orbital elements]] has been devised to enable representation of the most important aspects of their orbits.\n\n== Perturbations ==\n\n[[Perturbation (astronomy)|Perturbations]] that cause an object's osculating orbit to change can arise from:\n* A non-spherical component to the central body (when the central body can be modeled neither with a [[point mass]] nor with a spherically symmetrical mass distribution, e.g. when it is an [[oblate spheroid]]).\n* A third body or multiple other bodies whose gravity perturbs the object's orbit, for example the effect of the [[Moon]]'s gravity on objects orbiting Earth.\n* A relativistic correction.\n* A non-[[gravitational force]] acting on the body, for example force arising from:\n** Thrust from a [[rocket engine]]\n** Releasing, leaking, venting or [[ablation]] of a material\n** Collisions with other objects\n** [[Atmospheric drag]]\n** [[Radiation pressure]]\n** [[Solar wind]] pressure\n** Switch to a non-inertial reference frame (e.g. when a satellite's orbit is described in a reference frame associated with the [[precession|precessing]] equator of the planet).\n\n== Parameters ==\n\nAn object's orbital parameters will be different if they are expressed with respect to a [[non-inertial reference frame]] (for example, a frame co-precessing with the primary's equator), than if it is expressed with respect to a (non-rotating) [[inertial reference frame]].\n\nPut in more general terms, a perturbed trajectory can be analysed as if assembled of points, each of which is contributed by a curve out of a sequence of curves. Variables parameterising the curves within this family can be called ''[[orbital elements]]''. Typically (though not necessarily), these curves are chosen as Keplerian conics, all of which share one focus. In most situations, it is convenient to set each of these curves tangent to the trajectory at the point of intersection. Curves that obey this condition (and also the further condition that they have the same curvature at the point of tangency as would be produced by the object's gravity towards the central body in the absence of perturbing forces) are called osculating, while the variables parameterising these curves are called osculating elements. In some situations, description of orbital motion can be simplified and approximated by choosing orbital elements that are not osculating. Also, in some situations, the standard (Lagrange-type or Delaunay-type) equations furnish orbital elements that turn out to be non-osculating.<ref>For details see: {{Cite journal|arxiv=astro-ph/0603092|postscript=|doi=10.1196/annals.1370.016|pmid=16510420|title=Gauge Freedom in Orbital Mechanics|journal=Annals of the New York Academy of Sciences|volume=1065|pages=346–74|year=2005|last1=Efroimsky|first1=M.|bibcode=2005NYASA1065..346E}};\n{{Cite journal|arxiv=astro-ph/0305344|doi=10.1063/1.1622447|title=Gauge symmetry of the N-body problem in the Hamilton–Jacobi approach|journal=Journal of Mathematical Physics|volume=44|issue=12|pages=5958–5977|year=2003|last1=Efroimsky|first1=Michael|last2=Goldreich|first2=Peter|bibcode=2003JMP....44.5958E}}</ref>\n\n==See also==\n* [[Kepler orbit]]\n* [[Eccentricity vector]]\n* [[Orbital elements]]\n* [[Contact (mathematics)]]\n* [[Osculating circle]]\n* [[List of orbits]]\n\n==References==\n{{Reflist}}\n\n== External links ==\n* Diagram of a sequence of osculating orbits for the escape from Earth orbit by the ion-driven [[SMART-1]] spacecraft: http://sci.esa.int/science-e/www/object/index.cfm?fobjectid=35722\n* A sequence of osculating orbits for the approach to the Moon by the [[SMART-1]] spacecraft: http://sci.esa.int/science-e/www/object/index.cfm?fobjectid=36359\n\n; Videos\n\n* {{YouTube|id=qIVe_xEv6zQ|title=Osculating orbits: ''restricted 3-Body problem''}} {{small|(min. 4:26)}}\n* {{YouTube|id=m689l0sjMmE|title=Osculating orbits: ''3-Body Lagrange problem''}} {{small|(min. 4:00)}}\n* {{YouTube|id=BG0Oi1muq_0|title=Osculating orbits: ''4-Body Lagrange problem''}} {{small|(min. 1:05)}}\n* {{YouTube|id=rr0JpgKPKgg|title=Osculating orbits: in: ''the Pythagorean 3-Body problem''}} {{small|(min. 4:26)}}\n* {{YouTube|id=8M_27st1ZCI|title=Minor Planet Center: ''Asteroid Hazards, Part 3: Finding the Path''}} {{small|(min. 5:38)}}\n\n{{orbits|state=expanded}}\n\n[[Category:Astrodynamics]]\n[[Category:Orbital perturbations]]"
    },
    {
      "title": "Poynting–Robertson effect",
      "url": "https://en.wikipedia.org/wiki/Poynting%E2%80%93Robertson_effect",
      "text": "The '''Poynting–Robertson effect''', also known as '''Poynting–Robertson drag''', named after [[John Henry Poynting]] and [[Howard P. Robertson]], is a process by which [[solar radiation]] causes a dust grain orbiting a star to lose angular momentum relative to its orbit around the star.  This is related to [[radiation pressure]] tangential to the grain's motion.\n\nThis causes dust that is small enough to be affected by this drag, but too large to be blown away from the star by radiation pressure, to spiral slowly into the star.  In the case of the Solar System, this can be thought of as affecting dust grains from {{Val|1|ul=um}} to {{val|1|ul=mm}} in diameter.  Larger dust is likely to collide with another object long before such drag can have an effect.\n\nPoynting initially gave a description of the effect in 1903 based on the [[luminiferous aether]] theory, which was superseded by the [[theory of relativity|theories of relativity]] in 1905–1915. In 1937 Robertson described the effect in terms of [[general relativity]].\n\n== History ==\n\nRobertson considered dust motion in a beam of radiation emanating from a point source. A. W. Guess later considered the problem for a spherical source of radiation and found that for particles far from the source the resultant forces are in agreement with those concluded by Poynting.<ref>{{cite journal |last=Guess |first=A. W. |year=1962 |title=Poynting-Robertson Effect for a Spherical Source of Radiation |journal=[[Astrophysical Journal]] |volume=135 |issue= |pages=855–866 |doi=10.1086/147329 |bibcode=1962ApJ...135..855G}}</ref>\n\n== Source of the effect ==\n\nThe effect can be understood in two ways, depending on the [[Frame of reference|reference frame]] chosen.\n\n[[Image:Poynting-Robertson effect.png|thumb|312px|Radiation from a star (S) and thermal radiation from a particle seen (a) from an observer moving with the particle and (b) from an observer at rest with respect to the star.]]\nFrom the perspective of the grain of dust circling a star (panel (a) of the figure), the star's radiation appears to be coming from a slightly forward direction ([[aberration of light]]). Therefore the absorption of this radiation leads to a [[radiation pressure|force]] with a component against the direction of movement. The angle of aberration is extremely small since the radiation is moving at the [[speed of light]] while the dust grain is moving many orders of magnitude slower than that.\n\nFrom the perspective of the star (panel (b) of the figure), the dust grain absorbs sunlight entirely in a radial direction, thus the grain's angular momentum is not affected by it.  But the ''re-emission'' of photons, which is isotropic in the frame of the grain (a), is no longer isotropic in the frame of the star (b).  This [[anisotropic]] emission causes the photons to carry away angular momentum from the dust grain.\n\nThe Poynting–Robertson drag can be understood as an effective force opposite the direction of the dust grain's orbital motion, leading to a drop in the grain's angular momentum. While the dust grain thus spirals slowly into the star, its [[orbital speed]] increases continuously.\n\nThe Poynting–Robertson force is equal to:\n\n:<math>F_{\\rm PR} = \\frac{v}{c^2}W = \\frac{r^2 L_{\\rm s}}{4 c^2}\\sqrt{\\frac{G M_{\\rm s}}{R^5}}</math>\n\nwhere ''v'' is the grain's velocity, ''c'' is the [[speed of light]], ''W'' is the power of the incoming radiation, ''r'' the grain's radius, ''G'' is the universal [[gravitational constant]], ''M''<sub>s</sub> the [[Sun]]'s mass, ''L''<sub>s</sub> is the solar luminosity and ''R'' the grain's orbital radius.\n\n== Relation to other forces ==\n\nThe Poynting–Robertson effect is more pronounced for smaller objects.  Gravitational force varies with mass, which is <math> \\propto r^3 </math> (where <math>r</math> is the radius of the dust), while the power it receives and radiates varies with surface area (<math> \\propto r^2 </math>).  So for large objects the effect is negligible.\n\nThe effect is also stronger closer to the sun.  Gravity varies as <math>\\frac{1}{R^2}</math> (where R is the radius of the orbit) whereas the Poynting–Robertson force varies as <math>\\frac{1}{R^{2.5}}</math>, so the effect also gets relatively stronger as the object approaches the Sun.  This tends to reduce the [[eccentricity (orbit)|eccentricity]] of the object's orbit in addition to dragging it in.\n\nIn addition, as the size of the particle increases, the surface temperature is no longer approximately constant, and the radiation pressure is no longer isotropic in the particle's reference frame.  If the particle rotates slowly, the radiation pressure may contribute to the change in angular momentum, either positively or negatively.\n\n[[Radiation pressure]] affects the effective force of gravity on the particle: it is felt more strongly by smaller particles, and blows very small particles away from the Sun.  It is characterized by the dimensionless dust parameter <math> \\beta </math>, the ratio of the force due to [[radiation pressure]] to the force of gravity on the particle:\n\n:<math>\n\\beta = { F_{\\rm r} \\over F_{\\rm g} }  \n=  { 3L  Q_{\\rm PR}  \\over { 16 \\pi GMc \\rho s }  }\n</math>\n\nwhere <math>Q_{\\rm PR} </math> is the [[Mie scattering]] coefficient, and <math> \\rho </math> is the density and <math>s</math> is the size (the radius) of the dust grain.<ref>{{cite journal |last=Burns |last2=Lamy |last3=Soter |year=1979 |title=Radiation Forces on Small Particles in the Solar System |journal=[[Icarus (journal)|Icarus]] |volume=40 |issue=1 |pages=1–48 |doi=10.1016/0019-1035(79)90050-2 |bibcode=1979Icar...40....1B}}</ref>\n\n=== Impact of the effect on dust orbits ===\n\nParticles with <math>\\beta \\geq 0.5 </math> have [[radiation pressure]] at least half as strong as gravity, and will pass out of the Solar System on hyperbolic orbits if their initial velocities were Keplerian.<ref name=\"wyatt\">{{Cite web | url = http://www.ast.cam.ac.uk/~wyatt/wyat06b.pdf | title = Theoretical Modeling of Debris Disk Structure | first = Mark | last = Wyatt | publisher = University of Cambridge | date = 2006 }}</ref> \nFor rocky dust particles, this corresponds to a diameter of less than 1 [[1 E-6 m|µm]].<ref>{{Cite encyclopedia |title=Interplanetary dust particle (IDP) |encyclopedia=[[Britannica Online]] |url=https://www.britannica.com/topic/interplanetary-dust-particle |accessdate=2017-02-17 |last=Flynn |first=George J.  |date=2005-06-16}}</ref>\n\nParticles with <math>0.1 < \\beta < 0.5</math> may spiral inwards or outwards depending on their size and initial velocity vector; they tend to stay in eccentric orbits.\n\nParticles with <math>\\beta \\approx 0.1</math> take around 10,000 years to spiral into the sun from a circular orbit at 1 [[Astronomical unit|AU]].  In this regime, inspiraling time and particle diameter are both roughly <math>\\propto {1 \\over \\beta}</math>.<ref name=\"inspiral\">{{Cite journal |last=Klačka |first=J. |last2=Kocifaj |first2=M. |title=Times of inspiralling for interplanetary dust grains |url=http://mnras.oxfordjournals.org/content/390/4/1491.full |journal=[[Monthly Notices of the Royal Astronomical Society]]|location=Oxford |date=27 October 2008 |volume=390 |issue=4 |pages=1491–1495 |quote=Sec. 4, Numerical results |doi=10.1111/j.1365-2966.2008.13801.x|bibcode=2008MNRAS.390.1491K }}</ref>\n\nNote that, if the initial grain velocity was not Keplerian, then circular or any confined orbit is possible for <math>\\beta < 1 </math>.\n\nIt has been theorized that the slowing down of the sun's outer layer may be caused by a similar effect.<ref>{{Cite news|url=http://www.hawaii.edu/news/2016/12/12/giving-the-sun-a-brake/|title=Giving the Sun a brake|date=2016-12-12|newspaper=University of Hawaiʻi System News|access-date=2017-02-17|language=en-US}}</ref><ref>{{cite paper | arxiv = 1612.00873 | title = Poynting-Robertson-like Drag at the Sun's Surface | first1 = Ian | last1 = Cunnyngham | first2 = Marcelo | last2 = Emilio | first3 = Jeff | last3 = Kuhn | first4 = Isabelle | last4 = Scholl | first5 = Rock | last5 = Bush | year = 2017 | journal = [[Physical Review Letters]] | volume = 118 | issue = 5 | page = 051102 | doi = 10.1103/PhysRevLett.118.051102 | pmid = 28211737 | bibcode = 2017PhRvL.118e1102C }}</ref><ref>{{Cite journal|last=Wright|first=Katherine|date=2017-02-03|title=Focus: Photons Brake the Sun|url=https://physics.aps.org/articles/v10/13|journal=Physics|language=en-US|volume=10}}</ref>\n\n==See also==\n\n* [[Differential Doppler effect]]\n* [[Radiation pressure]]\n* [[Yarkovsky effect]]\n* [[Speed of gravity]]\n\n== References ==\n{{Reflist}}\n\n=== Additional sources ===\n\n* {{cite journal| last = Poynting\n  | first = J. H.\n  | authorlink = John Henry Poynting\n  | title = Radiation in the Solar System: its Effect on Temperature and its Pressure on Small Bodies\n  | journal = [[Philosophical Transactions of the Royal Society A|Philosophical Transactions of the Royal Society of London A]]\n  | volume = 202| issue = 346–358\n  | pages = 525–552\n  | publisher = Royal Society of London\n  | year = 1904\n  | url=http://rsta.royalsocietypublishing.org/content/202/346-358/525.full.pdf\n  | doi = 10.1098/rsta.1904.0012 |bibcode = 1904RSPTA.202..525P }}\n\n* {{cite journal| last = Poynting\n  | first = J. H.\n  | authorlink = John Henry Poynting\n  | title = Radiation in the solar system: its Effect on Temperature and its Pressure on Small Bodies\n  | journal = [[Monthly Notices of the Royal Astronomical Society]]\n  | volume = 64\n  | issue = Appendix\n  | pages = 1a–5a\n  | publisher = Royal Astronomical Society\n  |date=November 1903\n  | bibcode=1903MNRAS..64A...1P\n  | doi=10.1093/mnras/64.1.1a}} (Abstract of Philosophical Transactions paper)\n\n* {{cite journal| last = Robertson\n  | first = H. P.\n  | authorlink = Howard Percy Robertson\n  | title = Dynamical effects of radiation in the solar system\n  | journal = [[Monthly Notices of the Royal Astronomical Society]]\n  | volume = 97\n  | issue = 6\n | pages = 423–438\n  | publisher = Royal Astronomical Society\n  |date=April 1937\n  | bibcode=1937MNRAS..97..423R\n  | doi=10.1093/mnras/97.6.423}}\n\n{{DEFAULTSORT:Poynting-Robertson Effect}}\n[[Category:Orbital perturbations]]"
    },
    {
      "title": "Secular resonance",
      "url": "https://en.wikipedia.org/wiki/Secular_resonance",
      "text": "A '''secular resonance''' is a type of [[orbital resonance]] of two bodies with a synchronized [[Precession#precession of planetary orbits|precession]]. Secular resonances are used to study the long-time orbital evolution of [[asteroid]]s and their [[Asteroid family|families]] within the [[asteroid belt]], where &nu;<sub>6</sub> denotes such a resonance with respect to Saturn. \n\n== Description ==\n\nSecular resonances occur when the [[Precession#precession of planetary orbits|precession]] of two orbits is synchronised (a precession of the [[perihelion]], with frequency g, or the [[ascending node]], with frequency s, or both). A small [[Astronomical body|body]] (such as a [[small Solar System body]]) in secular resonance with a much larger one (e.g. a [[planet]]) will precess at the same rate as the large body. Over relatively short time periods (a million years, or so) a secular resonance will change the [[Eccentricity (orbit)|eccentricity]] and [[inclination]] of the small body.\n\nOne can distinguish between:\n*''linear secular resonances'' between a body (no subscript) and a single other large perturbing body (e.g. a planet, subscript as numbered from the Sun), such as the ''&nu;<sub>6</sub> = g − g<sub>6</sub> secular resonance'' between [[asteroid]]s and [[Saturn]]; and\n*''nonlinear secular resonances'', which are higher-order resonances, usually combination of linear resonances such as the z<sub>1</sub> = (g − g<sub>6</sub>) + (s − s<sub>6</sub>), or the ν<sub>6</sub> + ν<sub>5</sub> = 2g − g<sub>6</sub> − g<sub>5</sub> resonances.<ref>{{cite journal | author= V. Carruba| title= ''On the V-type asteroids outside the Vesta family''| journal= Astronomy & Astrophysics| date= 2005| volume= 441| pages= 819 | doi= 10.1051/0004-6361:20053355| bibcode=2005A&A...441..819C|arxiv = astro-ph/0506656 | name-list-format= vanc | display-authors= 1 | last2= Michtchenko | first2= T. A. | last3= Roig | first3= F. | last4= Ferraz-Mello | first4= S. | last5= Nesvorný | first5= D. | issue= 2 }}</ref>\n\n=== &nu;<sub>6</sub> resonance ===\nA prominent example of a linear resonance is the ''&nu;<sub>6</sub> secular resonance'' between [[asteroid]]s and [[Saturn]]. Asteroids which approach it have their eccentricity slowly increased until they become [[mars-crossing asteroid|Mars-crossers]], at which point they are usually ejected from the [[asteroid belt]] due to a close encounter with [[Mars]]. This resonance forms the inner and \"side\" boundaries of the asteroid belt around 2 [[astronomical unit|AU]], and at [[inclination]]s of about 20°.\n\n==See also==\n*[[Orbital resonance]]\n*[[Asteroid belt]]\n\n==References==\n{{reflist}}\n\n[[Category:Orbital perturbations]]"
    },
    {
      "title": "Simplified perturbations models",
      "url": "https://en.wikipedia.org/wiki/Simplified_perturbations_models",
      "text": "{{short description|Models used to calculate the orbital state of a satellite}}\n'''Simplified perturbations models''' are a set of five mathematical models (SGP, SGP4, SDP4, SGP8 and SDP8) used to calculate [[orbital state vectors]] of [[satellites]] and [[space debris]] relative to the [[Earth-centered inertial]] coordinate system. This set of models is often referred to collectively as SGP4 due to the frequency of use of that model particularly with [[two-line element set]]s produced by [[NORAD]] and [[NASA]].\n\nThese models predict the effect of [[perturbation (astronomy)|perturbations]] caused by the Earth’s shape, drag, radiation, and gravitation effects from other bodies such as the sun and moon.<ref name=\"Zwiep \">{{cite journal|last=Miura|first=Nicholas Zwiep |title=COMPARISON AND DESIGN OF SIMPLIFIED GENERAL PERTURBATION MODELS|journal=California Polytechnic State University, San Luis Obispo|year=2009|url=http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1094&context=theses}}</ref><ref name=\"spacetrackreport\">{{cite journal|last= Hoots |first=Felix R.|author2=Ronald L. Roehrich |title=Models for Propagation of NORAD Element Sets|journal=United States Department of Defense Spacetrack Report|date=31 December 1988|issue=3|url=http://www.celestrak.com/NORAD/documentation/spacetrk.pdf|accessdate=16 June 2010}}</ref>   Simplified General Perturbations (SGP) models apply to near earth objects with an [[orbital period]] of less than 225 minutes. Simplified Deep Space Perturbations (SDP) models apply to objects with an orbital period greater than 225 minutes, which corresponds to an altitude of 5,877.5&nbsp;km, assuming a circular orbit.<ref name=\"revisiting\" />\n\nThe SGP4 and SDP4 models were published along with sample code in [[FORTRAN IV]] in 1988 with refinements over the original model to handle the larger number of objects in orbit since.   SGP8/SDP8 introduced additional improvements for handling [[orbital decay]].<ref name=\"revisiting\">{{cite journal|last= Vallado|first=David A.|author2=Paul Crawford |author3=Richard Hujsak |author4=T. S. Kelso |title=Revisiting Spacetrack Report #3|journal=Astrodynamics Specialist Conference|date=August 2006|url=http://celestrak.com/publications/AIAA/2006-6753/AIAA-2006-6753-Rev2.pdf|accessdate=29 April 2017}}</ref>\n\nThe SGP4 model has an error ~1&nbsp;km at [[Epoch (astronomy)|epoch]] and grows at ~1–3&nbsp;km per day.<ref name=revisiting /> This data is updated frequently in NASA and NORAD sources due to this error. The original SGP model was developed by [[Yoshihide Kozai|Kozai]] in 1959, refined by Hilton & Kuhlman in 1966 and was originally used by the National Space Surveillance Control Center (and later the [[United States Space Surveillance Network]]) for tracking of objects in orbit.  The SDP4 model has an error of 10&nbsp;km at epoch.<ref name=Zwiep />\n\nDeep space models SDP4 and SDP8 use only 'simplified drag' equations. Accuracy is not a great concern here as high drag satellite cases do not remain in \"deep space\" for very long as the orbit quickly becomes lower and near circular.  SDP4 also adds Lunar–Solar gravity perturbations to all orbits, and Earth resonance terms specifically for 24-hour [[geostationary]] and 12-hour [[Molniya orbit]]s.<ref name=spacetrackreport />\n\nAdditional revisions of the model were developed and published by 2010 by the NASA [[Goddard Space Flight Center]] in support of tracking of the [[SeaWiFS]] mission and the [[Navigation and Ancillary Information Facility]] at the [[Jet Propulsion Laboratory]] in support of Planetary Data System for navigational purposes of numerous, mostly deep space, missions.<ref name=Zwiep /><ref>{{cite web|url=http://pds.jpl.nasa.gov/|title=Planetary Data System|publisher= NASA Science Mission Directorate|accessdate=16 June 2010}}</ref>  Current code libraries<ref name=\"Kelso\">{{cite web |last1=Kelso |first1=Dr. T. S. |title=CelesTrak: Publications [AIAA 2006-6753] |url=https://www.celestrak.com/publications/AIAA/2006-6753/ |website=www.celestrak.com |publisher=Celestrak |accessdate=15 April 2019}}</ref><ref name=\"Gray2019\">{{cite web |last1=Gray |first1=Bill |title=sat_code: Code for the SGP4/SDP4 satellite motion model |url=https://github.com/Bill-Gray/sat_code |website=Github |accessdate=15 April 2019 |date=30 March 2019}}</ref> use SGP4 and SDP4 algorithms merged into a single codebase in 1990<ref name=\"Vallado\">{{cite web |last1=Vallado |first1=David A |last2=Crawford |first2=Paul |last3=Hujsak |first3=Richard |title=Revisiting Spacetrack Report #3: Rev 1 |url=https://www.celestrak.com/publications/AIAA/2006-6753/AIAA-2006-6753-Rev1.pdf |website=Celestrak |publisher=AIAA |accessdate=15 April 2019}}</ref> handling the range of orbital periods which are usually referred to generically as SGP4.<ref name=\"Vallado\" />\n\n==References==\n{{reflist}}\n\n==External links==\nSource code for algorithm implementations, and TLE interpretation in some cases:\n* [https://github.com/brandon-rhodes/python-sgp4 python-sgp4] A Python Implementation of the sgp4 model with automatic downloading of TLE Elements from NORAD database.\n* [https://github.com/shupp/Predict PHP5] based on [http://gpredict.oz9aec.net/ Gpredict]\n* Java: [http://www.chiandh.eu/soft/Sputnik/ReadMe.html Sputnik] and [https://code.google.com/p/predict4java/ predict4java]\n* [http://celestrak.com/publications/AIAA/2006-6753/AIAA-2006-6753.zip C++, FORTRAN, Pascal, and MATLAB].\n* [https://github.com/joshuaferrara/go-satellite go-satellite] GoLang implementation of SGP4 model and helper utilities.\n\n[[Category:Orbital perturbations]]\n[[Category:North American Aerospace Defense Command]]\n[[Category:Computational physics]]"
    },
    {
      "title": "Stability of the Solar System",
      "url": "https://en.wikipedia.org/wiki/Stability_of_the_Solar_System",
      "text": "The '''stability of the Solar System''' is a subject of much inquiry in [[astronomy]]. Though the planets have been stable when historically observed, and will be in the short term, their weak gravitational effects on one another can add up in unpredictable ways.\nFor this reason (among others) the [[Solar System]] is chaotic in the technical sense of mathematical [[chaos theory]],<ref name=laskar94>{{cite journal\n|title=Large-scale chaos in the Solar System\n|author=J. Laskar\n|journal=[[Astronomy and Astrophysics]]\n|volume=287\n|pages=L9–L12\n|date=1994\n|bibcode=1994A&A...287L...9L}}</ref>  \nand even the most precise long-term models for the orbital motion of the Solar System are not valid over more than a few tens of millions of years.<ref>{{cite journal|author2=P. Robutel|author3=F. Joutel|author4=M. Gastineau|author5=A. C. M. Correia|author6=B. Levrard|last-author-amp=yes |title=A long-term numerical solution for the insolation quantities of the Earth |doi=10.1051/0004-6361:20041335|date=2004|display-authors=4|last1=Laskar|first1=J.|journal=Astronomy and Astrophysics|volume=428|issue=1|page=261|bibcode=2004A&A...428..261L}}</ref>\n\nThe Solar System is stable in human terms, and far beyond, given that it is unlikely any of the planets will collide with each other or be ejected from the system in the next few billion years,<ref name=hayes07/> and the [[Earth's orbit]] will be relatively stable.<ref>Gribbin, John. Deep Simplicity. Random House 2004.</ref>\n\nSince [[Newton's law of universal gravitation|Newton's law of gravitation]] (1687), mathematicians and astronomers (such as [[Pierre-Simon Laplace|Laplace]], [[Joseph Louis Lagrange|Lagrange]], [[Carl Friedrich Gauss|Gauss]], [[Henri Poincaré|Poincaré]], [[Andrey Kolmogorov|Kolmogorov]], [[Vladimir Arnold]] and [[Jürgen Moser]]) have searched for evidence for the stability of the planetary motions, and this quest led to many mathematical developments, and several successive 'proofs' of stability of the Solar System.<ref>[http://adsabs.harvard.edu/abs/2000eaa..bookE2198L Laskar, J. Solar System: Stability]</ref>\n\n==Overview and challenges==\n{{Main|n-body problem}}\nThe orbits of the planets are open to long-term variations. Modeling the Solar System is a case of the [[n-body problem|''n''-body problem]] of physics, which is generally unsolvable except by numerical simulation.\n\n===Resonance===\n[[File:Semimajorhistogramofkbos.svg|thumb|401 px|Graph showing the numbers of [[Kuiper belt]] objects for a given distance (in [[astronomical unit|AU]]) from the Sun]]\n \n[[Orbital resonance]] happens when any two periods have a simple numerical ratio. The most fundamental period for an object in the Solar System is its [[orbital period]], and orbital resonances pervade the Solar System. In 1867, the American astronomer [[Daniel Kirkwood]] noticed that asteroids in the [[asteroid belt]] are not randomly distributed.<ref>{{cite book|last=Hall|first=Nina|title=Exploring Chaos|pages=110|isbn=9780393312263|url=https://books.google.com/books?id=xhm3m-ka0XUC&dq=C.+J.+Cohen+astronomer|date=1994-09-01}}</ref> There were distinct gaps in the belt at locations that corresponded to resonances with [[Jupiter]]. For example, there were no asteroids at the 3:1 resonance – a distance of 2.5&nbsp;AU – or at the 2:1 resonance at 3.3&nbsp;AU (AU is the [[astronomical unit]], or essentially the distance from the Sun to Earth). These are now known as the [[Kirkwood gap]]s. Some asteroids were later discovered to orbit in these gaps, but their orbits are unstable and they will eventually break out of the resonance due to close encounters with a major planet.\n\nAnother common form of resonance in the Solar System is spin–orbit resonance, where the period of spin (the time it takes the planet or moon to rotate once about its axis) has a simple numerical relationship with its orbital period. An example is our own [[Moon]], which is in a 1:1 spin–orbit resonance that keeps the [[far side of the Moon]] away from the [[Earth]]. [[Mercury (planet)|Mercury]] is in a 3:2 spin–orbit resonance.\n\n===Predictability===\nThe planets' orbits are chaotic over longer timescales, in such a way that the whole Solar System possesses a [[Lyapunov time]] in the range of 2–230&nbsp;million years.<ref name=hayes07>{{cite journal | author=Wayne B. Hayes | title=Is the outer Solar System chaotic? | journal=Nature Physics | date=2007 | volume=3 | issue=10 | pages=689–691 | doi=10.1038/nphys728 | bibcode=2007NatPh...3..689H|arxiv = astro-ph/0702179 }}</ref> In all cases this means that the position of a planet along its orbit ultimately becomes impossible to predict with any certainty (so, for example, the timing of winter and summer become uncertain), but in some cases the orbits themselves may change dramatically. Such chaos manifests most strongly as changes in [[Orbital eccentricity|eccentricity]], with some planets' orbits becoming significantly more—or less—[[ellipse|elliptical]].<ref>{{cite book\n|author=Ian Stewart\n|title=Does God Play Dice?\n|publisher=[[Penguin Books]]\n|edition=2nd\n|pages=246–249\n|date=1997\n|isbn=978-0-14-025602-4}}</ref>\n\nIn calculation, the unknowns include [[asteroid]]s, the solar [[quadrupole moment]], mass loss from the [[Sun]] through radiation and [[solar wind]], drag of solar wind on planetary [[magnetosphere]]s, galactic [[tidal forces]], and effects from passing [[star]]s.<ref>{{Cite news|url=http://www.slideserve.com/shina/the-stability-of-the-solar-system|title=The stability of the solar system|last=shina|date=2012-09-17|work=SlideServe|access-date=2017-10-26|language=en}}</ref>\n\nFurthermore, the equations of motion describe a process that is inherently [[Single threading|serial]], so there is little to be gained from using [[massively parallel computer]]s.{{Citation needed|date=July 2010}}\n\n==Scenarios==\n\n===Neptune–Pluto resonance===\nThe [[Neptune]]–[[Pluto]] system lies in a 3:2 [[orbital resonance]]. [[C.J. Cohen]] and [[E.C. Hubbard]] at the [[Naval Surface Warfare Center Dahlgren Division]] discovered this in 1965. Although the resonance itself will remain stable in the short term, it becomes impossible to predict the position of Pluto with any degree of accuracy, as the uncertainty in the position grows by a factor ''e'' with each [[Lyapunov time]], which for Pluto is 10–20&nbsp;million years into the future.<ref name=SW88>{{cite journal | title = Numerical evidence that the motion of Pluto is chaotic | author = Gerald Jay Sussman | author2 = Jack Wisdom | journal = Science | volume = 241 | pages = 433–437 | date = 1988 | bibcode = 1988Sci...241..433S | doi = 10.1126/science.241.4864.433 | pmid = 17792606 | issue = 4864 | url=http://groups.csail.mit.edu/mac/users/wisdom/pluto-chaos.pdf\n}}</ref>\nThus, on the time scale of hundreds of millions of years Pluto's orbital phase becomes impossible to determine, even if Pluto's orbit appears to be perfectly stable on 10 [[myr|MYR]] time scales (Ito and Tanikawa 2002, MNRAS).\n\n===Jovian moon resonance===\nJupiter's moon [[Io (moon)|Io]] has an orbital period of 1.769 days, nearly half that of the next satellite [[Europa (moon)|Europa]] (3.551 days). They are in a 2:1 orbit/orbit resonance. This particular resonance has important consequences because Europa's gravity [[Perturbation (astronomy)|perturbs]] the orbit of Io. As Io moves closer to Jupiter and then further away in the course of an orbit, it experiences significant tidal stresses resulting in active volcanoes. Europa is also in a 2:1 resonance with the next satellite [[Ganymede (moon)|Ganymede]].\n\n===Mercury–Jupiter 1:1 perihelion-precession resonance===\nThe planet [[Mercury (planet)|Mercury]] is especially susceptible to [[Jupiter]]'s influence because of a small celestial coincidence: Mercury's [[perihelion]], the point where it gets closest to the Sun, precesses at a rate of about 1.5 degrees every 1000 years, and Jupiter's perihelion precesses only a little slower. At one point, the two may fall into sync, at which time Jupiter's constant gravitational tugs could accumulate and pull Mercury off course with 1–2% probability, 3–4 billion years into the future.\nThis could eject it from the Solar System altogether<ref name=laskar94/> or send it on a collision course with [[Venus]], the Sun, or Earth.<ref>{{cite news|title=The Solar System could go haywire before the Sun dies|url=https://www.newscientist.com/article/dn13757-solar-system-could-go-haywire-before-the-sun-dies.html | author=David Shiga | work=NewScientist.com News Service | date=23 April 2008 | accessdate=2015-03-31 | dead-url=no | archive-url=https://web.archive.org/web/20141231165529/http://www.newscientist.com/article/dn13757-solar-system-could-go-haywire-before-the-sun-dies.html| archive-date=2014-12-31}}</ref>\n\n===Asteroid influence===\n\n{{expand section|date=November 2013}}\n\n===Chaos from geological processes===\nAnother example is Earth's [[axial tilt]] which, due to friction raised within Earth's [[mantle (geology)|mantle]] by tidal interactions with the [[Moon]] ([[#Moon-ring systems|see below]]), will be rendered chaotic at some point between 1.5 and 4.5 billion years from now.<ref>{{cite journal|title=On the long term evolution of the spin of the Earth|author=O. Neron de Surgy|author2=J. Laskar|journal=Astronomy and Astrophysics|date=February 1997|volume=318|pages=975–989|bibcode=1997A&A...318..975N}}</ref>\n{{See also|Pole shift hypothesis}}\n\n===External influences===\nObjects coming from outside the Solar System can also affect it. Though they are not technically part of the solar system for the purposes of studying the system's intrinsic stability, they nevertheless can change the system. Unfortunately predicting the potential influences of these [[extrasolar objects]] is even more difficult than predicting the influences of objects within the system simply because of the sheer distances involved. Among the known objects with a potential to significantly impact the Solar System is the star [[Gliese 710]], which is expected to pass near the system in approximately 1.35 million years. Though the star is not expected to substantially affect the orbits of the major planets, it could substantially disrupt the Oort cloud which could cause major comet activity throughout the solar system. There are at least a dozen other stars that have a potential to make a close approach in the next few million years.<ref>{{cite magazine | title=A star is hurtling towards our Solar System and could knock millions of comets straight towards Earth | author=Dodgson, Lindsay | date=January 8, 2017 | magazine=Business Insider | url=http://www.businessinsider.com/star-hurting-towards-solar-system-2016-12}}</ref>\n\n==Studies==\n\n===LONGSTOP===\nProject LONGSTOP (Long-term Gravitational Study of the Outer Planets) was a 1982 international consortium of Solar System dynamicists led by [[Archie Roy]]. It involved creation of a model on a supercomputer, integrating the orbits of (only) the outer planets. Its results revealed several curious exchanges of energy between the outer planets, but no signs of gross instability.\n\n===Digital Orrery===\nAnother project involved constructing the Digital Orrery by [[Gerry Sussman]] and his MIT group in 1988. The group used a supercomputer to integrate the orbits of the outer planets over 845 million years (some 20 per cent of the age of the Solar System). In 1988, Sussman and Wisdom found data using the Orrery which revealed that Pluto's orbit shows signs of chaos, due in part to its peculiar [[resonance]] with [[Neptune]].<ref name=SW88 />\n\nIf Pluto's orbit is chaotic, then technically the whole Solar System is chaotic, because each body, even one as small as Pluto, affects the others to some extent through gravitational interactions.<ref>[http://www.fortunecity.com/emachines/e11/86/solarsys.html Is the Solar System Stable?<!-- Bot generated title -->] {{webarchive|url=https://web.archive.org/web/20080625235601/http://www.fortunecity.com/emachines/e11/86/solarsys.html |date=2008-06-25 }}</ref>\n\n===Laskar #1===\nIn 1989, [[Jacques Laskar]] of the [[Bureau des Longitudes]] in Paris published the results of his numerical integration of the Solar System over 200 million years. These were not the full equations of motion, but rather averaged equations along the lines of those used by [[Pierre-Simon Laplace|Laplace]]. Laskar's work showed that the Earth's orbit (as well as the orbits of all the inner planets) is chaotic and that an error as small as 15 metres in measuring the position of the Earth today would make it impossible to predict where the Earth would be in its orbit in just over 100 million years' time.\n\n===Laskar and Gastineau===\nJacques Laskar and his colleague Mickaël Gastineau in 2008 took a more thorough approach by directly simulating 2500 possible futures. Each of the 2500 cases has slightly different initial conditions: Mercury's position varies by about 1 metre between one simulation and the next.<ref>{{cite web|url=https://www.newscientist.com/article/mg20227125.000-solar-systems-planets-could-spin-out-of-control.html|title=Solar System's planets could spin out of control|publisher=newscientist|accessdate=2009-06-11}}</ref> In 20 cases, Mercury goes into a dangerous orbit and often ends up colliding with Venus or plunging into the Sun. Moving in such a warped orbit, Mercury's gravity is more likely to shake other planets out of their settled paths: in one simulated case its perturbations sent Mars heading towards Earth.<ref name=\"las2\">{{cite journal|url=http://www.nature.com/nature/journal/v459/n7248/full/nature08096.html|title=Existence of collisional trajectories of Mercury, Mars and Venus with the Earth|author=J. Laskar|author2=M. Gastineau|accessdate=2009-06-11|volume=459|issue=7248|doi=10.1038/nature08096|journal=Nature|pages=817–819|bibcode = 2009Natur.459..817L |year=2009}}</ref>\n\n=== Batygin and Laughlin ===\nIndependently of Laskar and Gastineau, Batygin  and Laughlin, were also directly simulating the Solar System 20 Gyr into the future. Their results reached the same basic conclusions of Laskar and Gastineau while additionally providing a lower bound of a billion (1e^9) years on the dynamical lifespan of the Solar System.<ref>{{Cite journal|last=Batygin|first=Konstantin|date=2008|title=n the Dynamical Stability of the Solar System|journal=The Astrophysical Journal|volume=Volume 683, Issue 2|issue=2|pages=1207–1216|doi=10.1086/589232|arxiv=0804.1946}}</ref>\n\n==See also==\n*[[Clearing the neighbourhood]]\n*[[Future of the Earth]]\n*[[Global catastrophic risk]]\n*[[Resonant trans-Neptunian object]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*{{cite web |first=Jacques |last=Laskar |authorlink=Jacques Laskar |date=2009 |title=Stability of the Solar System |publisher=[[Scholarpedia]] |url=http://www.scholarpedia.org/article/Stability_of_the_solar_system |accessdate=2009-12-18}}\n*[http://www.space.com/scienceastronomy/090610-planets-colllide.html Long Shot: Planet Could Hit Earth in Distant Future] Space.com.\n*[http://adsabs.harvard.edu/abs/1988VA.....32...95R Project LONGSTOP] - Long-term Gravitational Study of the Outer Planets\n\n[[Category:Chaos theory]]\n[[Category:Dynamics of the Solar System]]\n[[Category:Orbital perturbations]]"
    },
    {
      "title": "Yarkovsky effect",
      "url": "https://en.wikipedia.org/wiki/Yarkovsky_effect",
      "text": "[[Image:YarkovskyEffect.svg|thumb|300px|'''Yarkovsky effect:'''<br />1. Radiation from asteroid's surface <br />2. Prograde rotating asteroid <br />2.1 Location with \"Afternoon\" <br />3. Asteroid's orbit <br />4. Radiation from Sun]]\n\nThe '''Yarkovsky effect''' is a [[Force (physics)|force]] acting on a rotating body in space caused by the [[anisotropic]] emission of [[heat|thermal]] [[photon]]s, which carry [[momentum]]. It is usually considered in relation to [[meteoroid]]s or small [[asteroid]]s (about 10&nbsp;cm to 10&nbsp;km in diameter), as its influence is most significant for these bodies.\n\n==History of discovery==\nThe effect was discovered by the [[Poland|Polish]]<ref>{{cite journal |first=George |last=Beekman |title=The nearly forgotten scientist Ivan Osipovich Yarkovsky |journal=Journal of the British Astronomical Association |volume=115 |issue=4 |pages=207 |year=2005 |url=http://adsabs.harvard.edu/full/2005JBAA..115..207B }}</ref> civil engineer [[Ivan Osipovich Yarkovsky]] (1844&ndash;1902), who worked on scientific problems in his spare time. Writing in a pamphlet around the year 1900, Yarkovsky noted that the daily heating of a rotating object in space would cause it to experience a force that, while tiny, could lead to large long-term effects in the orbits of small bodies, especially [[meteoroid]]s and small [[asteroid]]s. Yarkovsky's insight would have been forgotten had it not been for the [[Estonia]]n astronomer [[Ernst J. Öpik]] (1893&ndash;1985), who read Yarkovsky's pamphlet sometime around 1909. Decades later, Öpik, recalling the pamphlet from memory, discussed the possible importance of the Yarkovsky effect on movement of meteoroids about the [[Solar System]].<ref>{{cite journal |first=E. J. |last=Öpik |title=Collision probabilities with the planets and the distribution of interplanetary matter |journal=Proceedings of the Royal Irish Academy |volume=54A |issue= |pages=165–199 |year=1951 |jstor=20488532 }}</ref>\n\n==Mechanism==\nThe Yarkovsky effect is a consequence of the fact that change in the temperature of an object warmed by radiation (and therefore the intensity of thermal radiation from the object) lags behind changes in the incoming radiation. That is, the surface of the object takes time to become warm when first illuminated, and takes time to cool down when illumination stops. In general there are two components to the effect:\n\n* '''Diurnal''' effect: On a rotating body illuminated by the Sun (e.g. an asteroid or the Earth), the surface is warmed by solar radiation during the day, and cools at night. Due to the thermal properties of the surface, there is a lag between the absorption of radiation from the Sun, and the emission of that same radiation as heat, so the warmest point on a rotating body occurs around the \"2 PM\" site on the surface, or slightly after noon. This results in a difference between the directions of absorption and re-emission of radiation, which yields a net force along the direction of motion of the orbit. If the object is a [[direct motion|prograde]] rotator, the force is in the direction of motion of the orbit, and causes the [[semi-major axis]] of the orbit to increase steadily; the object spirals away from the Sun. A [[retrograde motion|retrograde]] rotator spirals inward. The diurnal effect is the dominant component for bodies with diameter greater than about 100 m.<ref name=Bottke06review>{{cite journal |last=Bottke, Jr. |first=William F. |title=The Yarkovsky and YORP Effects: Implications for Asteroid Dynamics |journal=[[Annual Review of Earth and Planetary Sciences|Annu. Rev. Earth Planet. Sci.]] |volume=34 |pages=157–191 |year=2006 |doi=10.1146/annurev.earth.34.031405.125154 |bibcode = 2006AREPS..34..157B |display-authors=etal}}</ref>\n* '''Seasonal''' effect: This is easiest to understand for the idealised case of a non-rotating body orbiting the Sun, for which each \"year\" consists of exactly one \"day\". As it travels around its orbit, the \"dusk\" hemisphere which has been heated over a long preceding time period is invariably in the direction of orbital motion. The excess of thermal radiation in this direction causes a braking force that always causes spiraling inward toward the Sun. In practice, for rotating bodies, this seasonal effect increases along with the [[axial tilt]]. It dominates only if the diurnal effect is small enough. This may occur because of very rapid rotation (no time to cool off on the night side, hence an almost uniform [[longitude|longitudinal]] temperature distribution), small size (the whole body is heated throughout) or an axial tilt close to 90°. The seasonal effect is more important for smaller asteroid fragments (from a few metres up to about 100 m), provided their surfaces are not covered by an insulating [[regolith]] layer and they do not have exceedingly slow rotations. Additionally, on very long timescales over which the spin axis of the body may be repeatedly changed due to collisions (and hence also the direction of the diurnal effect changes), the seasonal effect will also tend to dominate.<ref name=Bottke06review />\n\nIn general, the effect is size-dependent, and will affect the semi-major axis of smaller asteroids, while leaving large asteroids practically unaffected. For kilometre-sized asteroids, the Yarkovsky effect is minuscule over short periods: the force on asteroid [[6489 Golevka]] has been estimated at about 0.25 [[newton (unit)|newton]], for a net acceleration of 10<sup>&minus;10</sup>&nbsp;m/s². But it is steady; over millions of years an asteroid's orbit can be perturbed enough to transport it from the [[asteroid belt]] to the inner Solar System.\n\nThe above details can become more complicated for bodies in strongly [[eccentricity (orbit)|eccentric]] orbits.\n\n==Measurement==\nThe effect was first measured in 1991–2003 on the asteroid [[6489 Golevka]]. The asteroid drifted 15&nbsp;km from its predicted position over twelve years (the orbit was established with great precision by a series of radar observations in 1991, 1995 and 1999 from the [[Arecibo Observatory|Arecibo]] radio telescope).<ref>{{cite journal |last=Chesley |first=Steven R. |title=Direct Detection of the Yarkovsky Effect via Radar Ranging to Asteroid 6489 Golevka |journal=[[Science (journal)|Science]] |volume=302 |issue=5651 |pages=1739–1742 |year=2003 |doi=10.1126/science.1091452 |bibcode = 2003Sci...302.1739C |display-authors=etal}}</ref>\n\nWithout direct measurement, it is very hard to predict the exact result of the Yarkovsky effect on a given asteroid's orbit. This is because the magnitude of the effect depends on many variables that are hard to determine from the limited observational information that is available. These include the exact shape of the asteroid, its orientation, and its [[albedo]]. Calculations are further complicated by the effects of shadowing and thermal \"reillumination\", whether caused by local craters or a possible overall concave shape. The Yarkovsky effect also competes with [[radiation pressure]], whose net effect may cause similar small long-term forces for bodies with albedo variations or non-spherical shapes.\n\nAs an example, even for the simple case of the pure seasonal Yarkovsky effect on a spherical body in a circular orbit with 90° [[obliquity]], semi-major axis changes could differ by as much as a factor of two between the case of a uniform albedo and the case of a strong north/south albedo asymmetry. Depending on the object's orbit and [[Rotation|spin axis]], the Yarkovsky change of the semi-major axis may be reversed simply by changing from a spherical to a non-spherical shape.\n\nDespite these difficulties, utilizing the Yarkovsky effect is one scenario under investigation to alter the course of potentially Earth-impacting [[near-Earth object|near-Earth asteroid]]s. Possible [[asteroid deflection strategies]] include \"painting\" the surface of the asteroid or focusing solar radiation onto the asteroid to alter the intensity of the Yarkovsky effect and so alter the orbit of the asteroid away from a collision with Earth.<ref>http://tamutimes.tamu.edu/2013/02/21/asteroids-no-match-for-paint-gun-says-prof/</ref>  The [[OSIRIS-REx]] mission, launched in September 2016, will study the Yarkovsky effect on [[101955 Bennu|asteroid Bennu]].<ref>[http://www.asteroidmission.org/qa/ OSIRIS-REx - Q & A]</ref>\n\n==See also==\n\n* [[Asteroid]]\n* [[Poynting–Robertson effect]]\n* [[Radiation pressure]]\n* [[Yarkovsky–O'Keefe–Radzievskii–Paddack effect|YORP effect]]\n\n==References==\n{{Reflist}}\n\n== External links ==\n* [https://arxiv.org/abs/1204.5990 Detection of Semi-Major Axis Drifts in 54 Near-Earth Asteroids: New Measurements of the Yarkovsky Effect] – ([[Arxiv]]: 1204.5990) \n* [https://www.sciencedaily.com/releases/2012/05/120524215341.htm Asteroid Nudged by Sunlight: Most Precise Measurement of Yarkovsky Effect] – ([[ScienceDaily]] 2012-05-24)\n\n{{DEFAULTSORT:Yarkovsky Effect}}\n[[Category:Orbital perturbations]]"
    },
    {
      "title": "Yarkovsky–O'Keefe–Radzievskii–Paddack effect",
      "url": "https://en.wikipedia.org/wiki/Yarkovsky%E2%80%93O%27Keefe%E2%80%93Radzievskii%E2%80%93Paddack_effect",
      "text": "{{short description|Second-order variation on the Yarkovsky effect that changes the rotation rate of a small body}}\n[[File:YORP effect - wedged sphere.svg|thumb|A spherical asteroid with two wedge-shaped projections. Re-radiated light from the \"B\" fin has the same magnitude as the \"A\" fin, but is not parallel to the incoming light. This produces a torque on the object.]]\n\nThe '''Yarkovsky–O'Keefe–Radzievskii–Paddack effect''', or '''YORP effect''' for short, changes the rotation state of a small [[astronomical body]] – that is, the body's [[rotation period|spin rate]] and the [[Axial tilt|obliquity]] of its [[Poles of astronomical bodies|pole]](s) – due to the [[scattering]] of [[solar radiation]] off its surface and the [[Emission (electromagnetic radiation)|emission]] of its own [[thermal radiation]].\n\nThe YORP effect is typically considered for [[asteroid]]s with their [[heliocentric orbit]] in the [[Solar System]]. The effect is responsible for the creation of [[Binary asteroid|binary]] and [[tumbling asteroids]] as well as for changing an asteroid's pole towards 0[[Degree (angle)|°]], 90°, or 180° relative to the [[ecliptic plane]] and so modifying its heliocentric radial drift rate due to the [[Yarkovsky effect]].\n\n== Term ==\n\nThe term was coined by [[David P. Rubincam]] in 2000<ref>{{Cite journal |last=Rubincam |first=D |title=Radiative Spin-up and Spin-down of Small Asteroids |url=http://linkinghub.elsevier.com/retrieve/doi/10.1006/icar.2000.6485 |journal=Icarus |language=en |volume=148 |issue=1 |pages=2–11 |doi=10.1006/icar.2000.6485 |bibcode=2000Icar..148....2R}}</ref> to honor four important contributors to the concepts behind the so-named YORP effect. In the 19th century, [[Ivan Osipovich Yarkovsky|Ivan Yarkovsky]] realized that the [[thermal radiation]] escaping from a body warmed by the Sun carries off [[momentum]] as well as [[heat]]. Translated into modern physics, each emitted [[photon]] possesses a momentum ''p'' = ''E/c'' where ''E'' is its [[energy]] and ''c'' is the [[speed of light]]. Vladimir Radzievskii applied the idea to rotation based on changes in [[astronomical albedo|albedo]]<ref>Radzievskii (1954)</ref> and Stephen Paddack realized that shape was a much more effective means of altering a body's spin rate.<ref>{{Cite journal|last=Paddack|first=S. J.|date=1969-01-01|title=Rotational bursting of small celestial bodies: Effects of radiation pressure.|journal=Journal of Geophysical Research|volume=74|pages=4379–4381|doi=10.1029/JB074i017p04379|issn=0148-0227|bibcode=1969JGR....74.4379P}}</ref> Stephen Paddack and [[John A. O'Keefe (astronomer)|John O'Keefe]] suggested that the YORP effect leads to rotational bursting and by repeatedly undergoing this process, small asymmetric bodies are eventually reduced to dust.<ref>S. J. Paddack, J. W. Rhee, ''Geophys. Res. Lett'' '''2''', 365 (1975)</ref><ref>{{Cite journal|last=Okeefe|first=J. A.|date=1975-04-01|title=Tektites and their origin|journal=NASA STI/Recon Technical Report N|volume=75|bibcode=1975STIN...7523444O}}</ref>\n\n== Physical mechanism ==\n\nIn principle, [[electromagnetic radiation]] interacts with the surface of an asteroid in three significant ways: radiation from the [[Sun]] is (1) [[Absorption (electromagnetic radiation)|absorbed]] and (2) [[Diffuse reflection|diffusively reflected]] by the surface of the body and the body's internal energy is (3) [[Emission (electromagnetic radiation)|emitted]] as [[thermal radiation]]. Since [[photon]]s possess [[momentum]], each of these interactions leads to changes in the [[angular momentum]] of the body relative to its [[center of mass]]. If considered for only a short period of time, these changes are very small, but over longer periods of time, these changes may [[Integration (mathematics)|integrate]] to significant changes in the angular momentum of the body. For bodies in a [[heliocentric orbit]], the relevant long periods of time is the [[orbital period]] (i.e. year), since most asteroids have [[rotation period]]s (i.e. days) shorter than their orbital periods. Thus, for most asteroids, the YORP effect is the secular change in the rotation state of the asteroid after averaging the [[Solar Radiation|solar radiation]] torques over first the rotational period and then the orbital period.\n\n== Observations ==\n\nIn 2007 there was direct observational confirmation of the YORP effect on the small asteroids [[54509 YORP]] (then designated {{mpl|2000 PH|5}})<ref name=\"LowryFitzsimmons2007\">{{cite journal|last1=Lowry|first1=S. C.|last2=Fitzsimmons|first2=A.|last3=Pravec|first3=P.|last4=Vokrouhlicky|first4=D.|last5=Boehnhardt|first5=H.|last6=Taylor|first6=P. A.|last7=Margot|first7=J.-L.|last8=Galad|first8=A.|last9=Irwin|first9=M.|last10=Irwin|first10=J.|last11=Kusnirak|first11=P.|title=Direct Detection of the Asteroidal YORP Effect|journal=Science|volume=316|issue=5822|year=2007|pages=272–274|issn=0036-8075|doi=10.1126/science.1139040|bibcode=2007Sci...316..272L|pmid=17347414}}</ref><ref name=\"TaylorMargot2007\">{{cite journal|last1=Taylor|first1=P. A.|last2=Margot|first2=J.-L.|last3=Vokrouhlicky|first3=D.|last4=Scheeres|first4=D. J.|last5=Pravec|first5=P.|last6=Lowry|first6=S. C.|last7=Fitzsimmons|first7=A.|last8=Nolan|first8=M. C.|last9=Ostro|first9=S. J.|last10=Benner|first10=L. A. M.|last11=Giorgini|first11=J. D.|last12=Magri|first12=C.|title=Spin Rate of Asteroid (54509) 2000 PH5 Increasing Due to the YORP Effect|journal=Science|volume=316|issue=5822|year=2007|pages=274–277|issn=0036-8075|doi=10.1126/science.1139038|bibcode=2007Sci...316..274T|pmid=17347415}}</ref> and [[1862 Apollo]].<ref>{{cite journal |author=Kaasalainen, Mikko |author2=Ďurech, Josef |author3=Warner, Brian D. |author4=Krugly, Yurij N. |author5=Gaftonyuk, Ninel M. | date = 2007 | title = Acceleration of the rotation of asteroid 1862 Apollo by radiation torques | journal = Nature | volume = 446 | issue = 7134 | pages = 420–422 | doi = 10.1038/nature05614 | bibcode=2007Natur.446..420K | pmid=17344861}}</ref> The spin rate of 54509 YORP will double in just 600,000 years, and the YORP effect can also alter the axial tilt and [[precession]] rate, so that the entire suite of YORP phenomena can send asteroids into interesting resonant spin states, and helps explain the existence of [[binary asteroid]]s.<ref>{{cite journal | last1 = Rubincam | first1 = D. P. | last2 = Paddack | first2 = S. J. | date = 2007 | title = As Tiny Worlds Turn | journal = Science | volume = 316 | issue = 5822 | pages = 211–212 | doi = 10.1126/science.1141930 }}</ref>\n\nObservations show that asteroids larger than 125&nbsp;km in diameter have rotation rates that follow a [[Maxwell–Boltzmann distribution|Maxwellian frequency distribution]], while smaller asteroids (in the 50 to 125&nbsp;km size range) show a small excess of fast rotators. The smallest asteroids (size less than 50&nbsp;km) show a clear excess of very fast and slow rotators, and this becomes even more pronounced as smaller populations are measured. These results suggest that one or more size-dependent mechanisms are depopulating the centre of the spin rate distribution in favour of the extremes. The YORP effect is a prime candidate. It is not capable of significantly modifying the spin rates of large asteroids by itself, so a different explanation must be sought for objects such as [[253 Mathilde]].\n\nIn late 2013 asteroid [[P/2013 R3]] was observed breaking apart, likely because of a high rotation speed from the YORP effect.<ref>{{cite web\n|url=http://www.spacetelescope.org/news/heic1405/\n|title=Hubble witnesses an asteroid mysteriously disintegrating}}</ref>\n\n== Example ==\n\nAssume a rotating spherical asteroid has two wedge-shaped fins attached to its equator, irradiated by parallel rays of sunlight. The [[Reaction (physics)|reaction]] force from photons departing from any given surface element of the spherical core will be normal to the surface, such that no [[torque]] is produced (the force vectors all pass through the centre of mass).\n\nThermally-emitted photons [[wiktionary:reradiate|reradiated]] from the sides of the wedges, however, can produce a torque, as the normal vectors do not pass through the centre of mass. Both fins present the same cross section to the incoming light (they have the same height and width), and so absorb and reflect the same amount of energy each and produce an equal force. Due to the fin surfaces being oblique, however, the normal forces from the reradiated photons do not cancel out. In the diagram, Fin A's outgoing radiation produces an equatorial force parallel to the incoming light and no vertical force, but Fin B's force has a smaller equatorial component and a vertical component. The unbalanced forces on the two fins lead to torque and the object spins. The torque from the outgoing light does not average out, even over a full rotation, so the spin accelerates over time.<ref name=\"Rubincam 2000 pp. 2–11\">{{cite journal | last=Rubincam | first=D | title=Radiative Spin-up and Spin-down of Small Asteroids | journal=Icarus | publisher=Elsevier BV | volume=148 | issue=1 | year=2000 | pages=2–11 | url=https://doi.org/10.1006%2Ficar.2000.6485 | doi=10.1006/icar.2000.6485 | accessdate=2017-04-11 | bibcode=2000Icar..148....2R}}</ref>\n\nAn object with some \"windmill\" asymmetry can therefore be subjected to minuscule torque forces that will tend to spin it up or down as well as make its axis of rotation [[precession|precess]]. The YORP effect is zero for a rotating [[ellipsoid]] ''if'' there are no irregularities in surface temperature or [[albedo]].\n\nIn the long term, the object's changing [[obliquity]] and rotation rate may wander randomly, chaotically or regularly, depending on several factors. For example, assuming the [[Sun]] remains on its [[equator]], asteroid [[951 Gaspra]], with a radius of 6&nbsp;km and a [[semi-major axis]] of 2.21 [[astronomical unit|AU]], would in 240 Ma (240 million years) go from a rotation period of 12 h to 6 h and vice versa. If [[243 Ida]] were given the same radius and orbit values as Gaspra, it would spin up or down twice as fast, while a body with [[Phobos (moon)|Phobos']] shape would take several [[1000000000 (number)|billion]] years to change its spin by the same amount.\n\nSize as well as shape affects the amount of the effect. Smaller objects will spin up or down much more quickly. If Gaspra were smaller by a factor of 10 (to a radius of 500 m), its spin will halve or double in just a few million years. Similarly, the YORP effect intensifies for objects closer to the Sun. At 1 AU, Gaspra would double/halve its spin rate in a mere 100,000 years. After one million years, its period may shrink to ~2 h, at which point it could start to break apart.\n\nThis is one mechanism through which [[binary asteroid]]s may form, and it may be more common than collisions and planetary near-encounter tidal disruption as the primary means of binary formation.\n\nAsteroid {{mp|2000 PH|5}} was later named [[54509 YORP]] to honor its part in the confirmation of this phenomenon.\n\n== See also ==\n* {{annotated link|54509 YORP}}, asteroid\n* {{annotated link|Radiation pressure}}\n* {{annotated link|Radiometer}}\n* {{annotated link|Yarkovsky effect}}\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n* {{Cite book | title = Tektites and Their Origin | last=O'Keefe | first=John A. | authorlink=John A. O'Keefe (astronomer) | year = 1976 | publisher = Elsevier}}\n* {{cite journal | last1 = Paddack | first1 = Stephen J | year = 1969 | title = Rotational bursting of small celestial bodies: Effects of radiation pressure | url = | journal = J. Geophys. Res. | volume = 74 | issue = | pages = 4379–4381 | doi=10.1029/jb074i017p04379 | bibcode=1969JGR....74.4379P}}\n* {{cite journal| last=Radzievskii | first=V. V. | year=1954 | title=A mechanism for the disintegration of asteroids and meteorites | journal=[[Doklady Akademii Nauk SSSR]] | volume=97 | pages=49–52}}\n* {{cite journal | last1 = Rubincam | first1 = David P | year = 2000 | title = Radiative spin-up and spin-down of small asteroids | url = | journal = Icarus | volume = 148 | issue = | pages = 2–11 | doi=10.1006/icar.2000.6485 | bibcode=2000Icar..148....2R}}\n\n== Further reading ==\n* {{Cite journal | title = Extreme Sensitivity of the YORP Effect to Small-Scale Topography | last = Statler | first = Thomas S. | date = 2009-03-05 |arxiv = 0903.1119 | doi=10.1016/j.icarus.2009.03.003 | bibcode=2009Icar..202..502S | volume=202 | journal=Icarus | pages=502–513}}\n* {{cite journal | last1 = Vokrouhlicky | first1 = David | authorlink2 = William F. Bottke | last2 = Bottke | first2 = William F. | year = | title = Yarkovsky and YORP effects| url = | journal = [[Scholarpedia]] | volume = 7 | issue = 5| page = 10599 | doi = 10.4249/scholarpedia.10599 |bibcode = 2012SchpJ...710599B | arxiv = 1502.01249 }}\n\n== External links ==\n* {{Cite news | title = Asteroid Spin Changed by Sunlight | first = Irene | last = Klotz | date = 2007-03-07 | publisher = [[Discovery Communications|Discovery Communications, LLC.]] | url = http://dsc.discovery.com/news/2007/03/07/asteroidspin_spa.html?category=space&guid=20070307130000&dcitc=w19-502-ak-0000 | archive-url = https://web.archive.org/web/20080426041544/http://dsc.discovery.com/news/2007/03/07/asteroidspin_spa.html?category=space&guid=20070307130000&dcitc=w19-502-ak-0000 | dead-url = yes | archive-date = 2008-04-26}}\n* [http://skytonight.com/news/wires?id=104027525&c=y Asteroid rotation discovery reported]\n\n{{DEFAULTSORT:Yarkovsky-O'keefe-Radzievskii-Paddack Effect}}\n[[Category:Orbital perturbations]]"
    },
    {
      "title": "Variational methods in general relativity",
      "url": "https://en.wikipedia.org/wiki/Variational_methods_in_general_relativity",
      "text": "{{Unreferenced|date=May 2018}}\n'''Variational methods in general relativity''' refers to various mathematical techniques that employ the use of [[variational calculus]] in [[Albert Einstein|Einstein]]'s theory of [[general relativity]]. The most commonly used tools are [[Lagrangian (field theory)|Lagrangian]]s and [[Hamiltonian mechanics#Mathematical formalism|Hamiltonian]]s and are used to derive the [[Einstein field equations]].\n\n==Lagrangian methods==\n{{Main|Einstein–Hilbert action}}\n\nThe [[equations of motion]] in physical theories can often be derived from an object called the [[Lagrangian (field theory)|Lagrangian]]. In [[classical mechanics]], this object is usually of the form, 'kinetic energy &minus; potential energy'. In general, the Lagrangian is that function which when integrated over produces the Action functional.\n\n[[David Hilbert]] gave an early and classic formulation of the equations in Einstein's general relativity. This used the functional now called the [[Einstein-Hilbert action]].\n\n==See also==\n*[[Palatini action]]\n*[[Plebanski action]]\n*[[MacDowell–Mansouri action]]\n*[[Freidel–Starodubtsev action]]\n*[[Mathematics of general relativity]]\n\n==References==\n<references/>\n\n{{DEFAULTSORT:Variational Methods In General Relativity}}\n[[Category:Variational formalism of general relativity| ]]\n\n\n{{Relativity-stub}}"
    },
    {
      "title": "Einstein–Hilbert action",
      "url": "https://en.wikipedia.org/wiki/Einstein%E2%80%93Hilbert_action",
      "text": "{{General relativity sidebar}}\nThe '''Einstein–Hilbert action''' (also referred to as [[Relativity priority dispute|Hilbert action]]<ref>{{Citation\n|author-first=David\n|author-last=Hilbert\n|author-link =David Hilbert\n|title = Die Grundlagen der Physik\n|trans-title= Foundations of Physics\n|journal = Nachrichten von der Gesellschaft der Wissenschaften zu Göttingen – Mathematisch-Physikalische Klasse\n|volume =3\n|issue=\n|pages =395-407\n|year =1915\n|language =German\n|url =\n|doi =\n|jfm = \n}}</ref>) in [[general relativity]] is the [[action (physics)|action]] that yields the [[Einstein field equations]] through the [[principle of least action]]. With the [[Sign_convention#Relativity|{{nowrap|(− + + +)}} metric signature]], the gravitational part of the action is given as<ref>{{cite book |first=Richard P. |last=Feynman |title=Feynman Lectures on Gravitation |publisher=Addison-Wesley |year=1995 |isbn=0-201-62734-5 |at=p. 136, eq. (10.1.2) }}</ref>\n\n:<math>S = {1 \\over 2\\kappa} \\int R \\sqrt{-g} \\, \\mathrm{d}^4x,</math>\n\nwhere <math>g=\\det(g_{\\mu\\nu})</math> is the determinant of the [[metric tensor]] matrix, <math>R</math> is the [[Ricci scalar]], and <math>\\kappa = 8\\pi Gc^{-4}</math> is [[Einstein's constant]] (<math>G</math> is the [[gravitational constant]] and <math>c</math> is the [[speed of light]] in vacuum). If it converges, the integral is taken over the whole [[spacetime]]. If it does not converge, <math>S</math> is no longer well-defined, but a modified definition where one integrates over arbitrarily large, relatively compact domains, still yields the Einstein equation as the [[Euler–Lagrange equation]] of the Einstein–Hilbert action.\n\nThe action was first proposed by [[David Hilbert]] in 1915.\n\n== Discussion ==\nThe derivation of equations from an action has several advantages. First of all, it allows for easy unification of general relativity with other classical field theories (such as [[Maxwell theory]]), which are also formulated in terms of an action. In the process the derivation from an action identifies a natural candidate for the source term coupling the metric to matter fields. Moreover, the action allows for the easy identification of conserved quantities through [[Noether's theorem]] by studying symmetries of the action.\n\nIn general relativity, the action is usually assumed to be a [[functional (mathematics)|functional]] of the metric (and matter fields), and the [[connection (mathematics)|connection]] is given by the [[Levi-Civita connection]]. The [[Palatini action|Palatini formulation]] of general relativity assumes the metric and connection to be independent, and varies with respect to both independently, which makes it possible to include fermionic matter fields with non-integral spin.\n\nThe Einstein equations in the presence of matter are given by adding the matter action to the Einstein-Hilbert action.\n\n==Derivation of Einstein's field equations==\nSuppose that the full action of the theory is given by the Einstein–Hilbert term plus a term <math>\\mathcal{L}_\\mathrm{M}</math> describing any matter fields appearing in the theory.\n\n:<math>S = \\int \\left[ \\frac{1}{2\\kappa} R + \\mathcal{L}_\\mathrm{M} \\right] \\sqrt{-g} \\, \\mathrm{d}^4 x. </math>\n\nThe [[action principle]] then tells us that the variation of this action with respect to the inverse metric is zero, yielding\n\n:<math>\\begin{align}\n0 &= \\delta S \\\\\n  &= \\int \\left[ \\frac{1}{2\\kappa} \\frac{\\delta (\\sqrt{-g}R)}{\\delta g^{\\mu\\nu}} + \\frac{\\delta (\\sqrt{-g} \\mathcal{L}_\\mathrm{M})}{\\delta g^{\\mu\\nu}}\n \\right] \\delta g^{\\mu\\nu} \\, \\mathrm{d}^4x \\\\\n  &= \\int \\left[ \\frac{1}{2\\kappa} \\left( \\frac{\\delta R}{\\delta g^{\\mu\\nu}} + \\frac{R}{\\sqrt{-g}} \\frac{\\delta \\sqrt{-g}}{\\delta g^{\\mu\\nu} } \n \\right) + \\frac{1}{\\sqrt{-g}} \\frac{\\delta (\\sqrt{-g} \\mathcal{L}_\\mathrm{M})}{\\delta g^{\\mu\\nu}} \\right] \\delta g^{\\mu\\nu} \\sqrt{-g}\\, \\mathrm{d}^4x.\n\\end{align}</math>\n\nSince this equation should hold for any variation <math>\\delta g^{\\mu\\nu}</math>, it implies that\n\n:<math>\\frac{\\delta R}{\\delta g^{\\mu\\nu}} + \\frac{R}{\\sqrt{-g}} \\frac{\\delta \\sqrt{-g}}{\\delta g^{\\mu\\nu}} = -2\\kappa \\frac{1}{\\sqrt{-g}}\\frac{\\delta (\\sqrt{-g} \\mathcal{L}_\\mathrm{M})}{\\delta g^{\\mu\\nu}},</math>\n\nis the [[equation of motion]] for the metric field. The right hand side of this equation is (by definition) proportional to the [[stress–energy tensor]],\n\n:<math>T_{\\mu\\nu}:= \\frac{-2}{\\sqrt{-g}}\\frac{\\delta (\\sqrt{-g} \\mathcal{L}_\\mathrm{M})}{\\delta g^{\\mu\\nu}} = -2 \\frac{\\delta \\mathcal{L}_\\mathrm{M}}{\\delta g^{\\mu\\nu}} + g_{\\mu\\nu} \\mathcal{L}_\\mathrm{M}.</math>\n\nTo calculate the left hand side of the equation we need the variations of the Ricci scalar ''R'' and the determinant of the metric. These can be obtained by standard text book calculations such as the one given below, which is strongly based on the one given in {{Harvnb|Carroll|2004}}.\n\n===Variation of the Riemann tensor, the Ricci tensor, and the Ricci scalar===\nTo calculate the variation of the [[Ricci scalar]] we calculate first the variation of the [[Riemann curvature tensor]], and then the variation of the Ricci tensor. So, the Riemann curvature tensor is defined as,\n\n:<math>{R^\\rho}_{\\sigma\\mu\\nu} = \\partial_\\mu\\Gamma^\\rho_{\\nu\\sigma}- \\partial_\\nu\\Gamma^\\rho_{\\mu\\sigma} + \\Gamma^\\rho_{\\mu\\lambda} \\Gamma^\\lambda_{\\nu\\sigma} - \\Gamma^\\rho_{\\nu\\lambda}\\Gamma^\\lambda_{\\mu\\sigma}.</math>\n\nSince the Riemann curvature depends only on the [[Levi-Civita connection]] <math>\\Gamma^\\lambda_{\\mu\\nu}</math>, the variation of the Riemann tensor can be calculated as,\n\n:<math>\\delta{R^\\rho}_{\\sigma\\mu\\nu} = \\partial_\\mu \\delta \\Gamma^\\rho_{\\nu\\sigma} - \\partial_\\nu\\delta\\Gamma^\\rho_{\\mu\\sigma} + \\delta \\Gamma^\\rho_{\\mu\\lambda} \\Gamma^\\lambda_{\\nu\\sigma} + \\Gamma^\\rho_{\\mu\\lambda} \\delta\\Gamma^\\lambda_{\\nu\\sigma}-\\delta\\Gamma^\\rho_{\\nu\\lambda} \\Gamma^\\lambda_{\\mu\\sigma} -\\Gamma^\\rho_{\\nu\\lambda} \\delta\\Gamma^\\lambda_{\\mu\\sigma}.</math>\n\nNow, since <math>\\delta\\Gamma^\\rho_{\\nu\\sigma}</math> is the difference of two connections, it is a tensor and we can thus calculate its [[covariant derivative]], \n\n:<math>\\nabla_\\mu \\left( \\delta \\Gamma^\\rho_{\\nu\\sigma} \\right ) = \\partial_\\mu (\\delta \\Gamma^\\rho_{\\nu\\sigma}) + \\Gamma^\\rho_{\\mu\\lambda} \\delta \\Gamma^\\lambda_{\\nu\\sigma} -\\Gamma^\\lambda_{\\mu\\nu} \\delta \\Gamma^\\rho_{\\lambda\\sigma} - \\Gamma^\\lambda_{\\mu\\sigma} \\delta \\Gamma^\\rho_{\\nu\\lambda}. </math>\n\nWe can now observe that the expression for the variation of Riemann curvature tensor above is equal to the difference of two such terms, \n\n:<math>\\delta{R^\\rho}_{\\sigma\\mu\\nu} =\\nabla_\\mu \\left (\\delta \\Gamma^\\rho_{\\nu\\sigma} \\right ) -\\nabla_\\nu \\left (\\delta \\Gamma^\\rho_{\\mu\\sigma} \\right ).</math>\n\nWe may now obtain the variation of the [[Ricci curvature tensor]] simply by contracting two indices of the variation of the Riemann tensor, and get the [[Palatini identity]]:\n\n:<math>\\delta R_{\\sigma\\nu} \\equiv \\delta {R^\\rho}_{\\sigma\\rho\\nu} = \\nabla_\\rho \\left (\\delta \\Gamma^\\rho_{\\nu\\sigma} \\right ) - \\nabla_\\nu \\left (\\delta \\Gamma^\\rho_{\\rho\\sigma} \\right ).</math>\n\nThe [[Ricci scalar]] is defined as\n\n:<math> R = g^{\\sigma\\nu} R_{\\sigma\\nu}.</math>\n\nTherefore, its variation with respect to the inverse metric <math>g^{\\sigma\\nu}</math> is given by\n\n:<math>\\begin{align}\n\\delta R &= R_{\\sigma\\nu} \\delta g^{\\sigma\\nu} + g^{\\sigma\\nu} \\delta R_{\\sigma\\nu}\\\\\n         &= R_{\\sigma\\nu} \\delta g^{\\sigma\\nu} + \\nabla_\\rho \\left( g^{\\sigma\\nu} \\delta\\Gamma^\\rho_{\\nu\\sigma} - g^{\\sigma\\rho} \\delta \\Gamma^\\mu_{\\mu\\sigma} \\right)\n\\end{align}</math>\n\nIn the second line we used the metric compatibility of the covariant derivative, <math>\\nabla_\\sigma g^{\\mu\\nu} = 0,</math> and the previously obtained result for the variation of the Ricci curvature (in the second term, renaming the dummy indices <math>\\rho</math> and <math>\\nu</math> to <math>\\mu</math> and <math>\\rho</math> respectively).\n\nThe last term, \n:<math>\\nabla_\\rho \\left ( g^{\\sigma\\nu} \\delta\\Gamma^\\rho_{\\nu\\sigma} - g^{\\sigma\\rho}\\delta\\Gamma^\\mu_{\\mu\\sigma} \\right )\\quad \\text{i.e.,}\\quad \\nabla_\\rho A^{\\rho} \\equiv A^{\\lambda}{}_{;\\lambda}\\quad \\text{with}\\quad A^{\\rho}=g^{\\sigma\\nu} \\delta\\Gamma^\\rho_{\\nu\\sigma} - g^{\\sigma\\rho}\\delta\\Gamma^\\mu_{\\mu\\sigma},</math>\n\nmultiplied by <math>\\sqrt{-g}</math>, becomes a [[total derivative]], since for any [[Ricci calculus|vector]] <math>A^{\\lambda}</math> and any [[tensor density]] <math>\\sqrt{-g}\\,A^{\\lambda}</math> we have:\n\n:<math>\\sqrt{-g}\\,A^\\lambda_{;\\lambda} = (\\sqrt{-g}\\,A^{\\lambda})_{;\\lambda}= (\\sqrt{-g}\\,A^\\lambda)_{,\\lambda} \\quad \\text{or}\\quad \\sqrt{-g}\\,\\nabla_\\mu A^\\mu = \\nabla_\\mu\\left(\\sqrt{-g}\\,A^\\mu\\right)= \\partial_\\mu\\left(\\sqrt{-g}\\,A^\\mu\\right)</math>\n\nand thus by [[Stokes' theorem]] only yields a boundary term when integrated. The boundary term is in general non-zero, because the integrand depends not only on <math>\\delta g^{\\mu\\nu},</math> but also on its partial derivatives <math>\\partial_\\lambda \\, \\delta g^{\\mu\\nu} \\equiv \\delta\\, \\partial_\\lambda g^{\\mu\\nu};</math> see the article [[Gibbons–Hawking–York boundary term]] for details. However when the variation of the metric <math>\\delta g^{\\mu\\nu}</math> vanishes in a neighbourhood of the boundary or when there is no boundary, this term does not contribute to the variation of the action. And we thus obtain,\n\n:<math>\\frac{\\delta R}{\\delta g^{\\mu\\nu}} = R_{\\mu\\nu}</math>\n\nat events not in the closure of the boundary.\n\n===Variation of the determinant===\n[[Jacobi's formula]], the rule for differentiating a [[determinant#Derivative|determinant]], gives:\n\n:<math>\\delta g = \\delta \\det(g_{\\mu\\nu}) = g g^{\\mu\\nu} \\delta g_{\\mu\\nu}</math>\n\nor one could transform to a coordinate system where <math>g_{\\mu\\nu}</math> is diagonal and then apply the product rule to differentiate the product of factors on the main diagonal. Using this we get\n\n:<math>\\delta \\sqrt{-g} = -\\frac{1}{2\\sqrt{-g}}\\delta g = \\frac{1}{2} \\sqrt{-g} \\left (g^{\\mu\\nu} \\delta g_{\\mu\\nu} \\right ) = -\\frac{1}{2} \\sqrt{-g} \\left (g_{\\mu\\nu} \\delta g^{\\mu\\nu} \\right )</math>\n\nIn the last equality we used the fact that\n\n:<math>g_{\\mu\\nu}\\delta g^{\\mu\\nu}=-g^{\\mu\\nu}\\delta g_{\\mu\\nu}</math>\n\nwhich follows from the rule for differentiating the inverse of a matrix\n\n:<math>\\delta g^{\\mu\\nu} = - g^{\\mu\\alpha} \\left ( \\delta g_{\\alpha\\beta} \\right  ) g^{\\beta\\nu}.</math>\n\nThus we conclude that\n\n:<math>\\frac{1}{\\sqrt{-g}} \\frac{\\delta \\sqrt{-g}}{\\delta g^{\\mu\\nu} } = -\\frac{1}{2} g_{\\mu\\nu}.</math>\n\n===Equation of motion===\nNow that we have all the necessary variations at our disposal, we can insert them into the equation of motion for the metric field to obtain,\n\n:<math>R_{\\mu\\nu} - \\frac{1}{2} g_{\\mu\\nu} R = \\frac{8 \\pi G}{c^4} T_{\\mu\\nu},</math>\n\nwhich is [[Einstein's field equation]] and\n\n:<math>\\kappa = \\frac{8\\pi G}{c^4}</math>\n\nhas been chosen such that the non-relativistic limit yields [[Newton's law of universal gravitation|the usual form of Newton's gravity law]], where ''G'' is the [[gravitational constant]] (see [[Einstein_field_equations#The_correspondence_principle|here]] for details).\n\n== Cosmological constant ==\nWhen a [[cosmological constant]] Λ is included in the [[Lagrangian (field theory)|Lagrangian]], the action\n\n:<math>S = \\int \\left[ \\frac{1}{2\\kappa} (R-2 \\Lambda ) + \\mathcal{L}_\\mathrm{M} \\right] \\sqrt{-g} \\, \\mathrm{d}^4 x </math>\n\nyields the field equations:\n\n:<math>R_{\\mu \\nu} - \\frac{1}{2} g_{\\mu \\nu} R + \\Lambda g_{\\mu \\nu} = \\frac{8 \\pi G}{c^4} T_{\\mu \\nu}.</math>\n\n==See also==\n*[[Belinfante–Rosenfeld stress–energy tensor|Belinfante–Rosenfeld tensor]]\n*[[Brans–Dicke theory]] (in which the constant ''k'' is replaced by a scalar field).\n*[[Einstein–Cartan theory]]\n*[[Einstein–Maxwell–Dirac equations]]\n*[[f(R) gravity]] (in which the Ricci scalar is replaced by a function of the Ricci curvature)\n*[[Gibbons–Hawking–York boundary term]]\n*[[Kaluza–Klein theory]]\n*[[Komar superpotential]]\n*[[Palatini action]]\n*[[Teleparallelism]]\n*[[Tetradic Palatini action]]\n*[[Variational methods in general relativity]]\n*[[Vermeil's theorem]]\n\n==Notes==\n{{reflist}}\n\n==Bibliography==\n* {{Citation|first=Charles W.|last=Misner|authorlink=Charles W. Misner|first2=Kip. S.|last2=Thorne|author2-link=Kip Thorne|first3=John A.|last3=Wheeler|author3-link=John A. Wheeler|title=Gravitation|publisher= W. H. Freeman|date=1973|isbn=978-0-7167-0344-0|title-link=Gravitation (book)}}\n* {{Citation|last=Wald|first=Robert M.|authorlink=Robert Wald|title=General Relativity|publisher=University of Chicago Press|date=1984|isbn=978-0-226-87033-5|title-link=General Relativity (book)}}\n* {{Citation|author=Carroll, Sean M. |authorlink=Sean M. Carroll |title=Spacetime and Geometry: An Introduction to General Relativity |location=San Francisco |publisher=Addison-Wesley |date=2004 |isbn=978-0-8053-8732-2}}\n*[[David Hilbert|Hilbert, D.]] (1915) [http://einstein-annalen.mpiwg-berlin.mpg.de/related_texts/relativity_rev/hilbert'' Die Grundlagen der Physik'' (German original for free)] [http://www.springerlink.com/content/t2681418480nq841 (English translation for $25)], Konigl. Gesell. d. Wiss. Göttingen, Nachr. Math.-Phys. Kl. 395-407\n*{{springer|id=C/c026670|last=Sokolov |first=D.D. |title=Cosmological constant}}\n*{{Citation| last = Feynman | first = Richard P. | year = 1995 | authorlink= Richard Feynman | title = Feynman Lectures on Gravitation | publisher = Addison-Wesley | isbn = 0-201-62734-5 | url = }}\n*Christopher M. Hirata [http://www.tapir.caltech.edu/~chirata/ph236/2011-12/lec33.pdf Lecture 33: Lagrangian formulation of GR] (27 April 2012).\n\n{{DEFAULTSORT:Einstein-Hilbert action}}\n[[Category:Variational formalism of general relativity]]\n[[Category:General relativity]]\n[[Category:Albert Einstein]]\n[[Category:Gravity]]\n[[Category:David Hilbert]]"
    },
    {
      "title": "Gibbons–Hawking–York boundary term",
      "url": "https://en.wikipedia.org/wiki/Gibbons%E2%80%93Hawking%E2%80%93York_boundary_term",
      "text": "{{Technical|date=December 2012}}\nIn [[general relativity]], the '''Gibbons–Hawking–York boundary term''' is a term that needs to be added to the [[Einstein–Hilbert action]] when the underlying [[spacetime]] [[manifold]] has a boundary.\n\nThe Einstein–Hilbert action is the basis for the most elementary [[variational principle]] from which the [[Einstein field equations|field equations of general relativity]] can be defined. However, the use of the Einstein–Hilbert action is appropriate only when the underlying spacetime manifold <math>\\mathcal{M}</math> is [[Closed manifold|closed]], i.e., a manifold which is both [[compact manifold|compact]] and without boundary. In the event that the manifold has a boundary <math>\\partial\\mathcal{M}</math>, the action should be supplemented by a boundary term so that the variational principle is well-defined.\n\nThe necessity of such a boundary term was first realised by [[James W. York|York]] and later refined in a minor way by [[Gary Gibbons|Gibbons]] and [[Stephen Hawking|Hawking]].\n\nFor a manifold that is not closed, the appropriate action is\n\n:<math>\\mathcal{S}_\\mathrm{EH} + \\mathcal{S}_\\mathrm{GHY} = \\frac{1}{16 \\pi} \\int_\\mathcal{M} \\mathrm{d}^4 x \\, \\sqrt{-g} R + \\frac{1}{8 \\pi} \\int_{\\partial \\mathcal{M}} \\mathrm{d}^3 y \\, \\epsilon \\sqrt{h}K,</math>\n\nwhere <math>\\mathcal{S}_\\mathrm{EH}</math> is the Einstein–Hilbert action, <math>\\mathcal{S}_\\mathrm{GHY}</math> is the Gibbons–Hawking–York boundary term, <math>h_{ab}</math> is the [[induced metric]] (see section below on definitions) on the boundary, <math>h</math> its determinant, <math>K</math> is the trace of the [[second fundamental form]], <math>\\epsilon</math> is equal to <math>+1</math> where <math>\\partial \\mathcal{M}</math> is timelike and <math>-1</math> where <math>\\partial \\mathcal{M}</math> is spacelike, and <math>y^a</math> are the coordinates on the boundary. Varying the action with respect to the metric <math>g_{\\alpha\\beta}</math>, subject to the condition\n\n:<math>\\delta g_{\\alpha \\beta} \\big|_{\\partial \\mathcal{M}} = 0,</math>\n\ngives the [[Einstein field equations|Einstein equations]]; the addition of the boundary term means that in performing the variation, the geometry of the boundary encoded in the transverse metric <math>h_{ab}</math> is fixed (see section below). There remains ambiguity in the action up to an arbitrary functional of the induced metric <math>h_{ab}</math>.\n\nThat a boundary term is needed in the gravitational case is because <math>R</math>, the gravitational Lagrangian density, contains second derivatives of the metric tensor. This is a non-typical feature of field theories, which are usually formulated in terms of Lagrangians that involve first derivatives of fields to be varied over only.\n\nThe GHY term is desirable, as it possesses a number of other key features. When passing to the Hamiltonian formalism, it is necessary to include the GHY term in order to reproduce the correct Arnowitt–Deser–Misner energy ([[ADM energy]]). The term is required to ensure the path integral (a la Hawking) for [[quantum gravity]] has the correct composition properties. When calculating black hole entropy using the Euclidean semiclassical approach, the entire contribution comes from the GHY term. This term has had more recent applications in [[loop quantum gravity]] in calculating transition amplitudes and background-independent scattering amplitudes.\n\nIn order to determine a finite value for the action, one may have to subtract off a surface term for flat spacetime:\n\n:<math>S_{EH} + S_{GHY,0} = \\frac{1}{16 \\pi} \\int_\\mathcal{M} \\mathrm{d}^4 x \\, \\sqrt{-g} R + \\frac{1}{8 \\pi} \\int_{\\partial \\mathcal{M}} \\mathrm{d}^3 y \\, \\epsilon \\sqrt{h} K - {1 \\over 8 \\pi} \\int_{\\partial \\mathcal{M}} \\mathrm{d}^3 y \\, \\epsilon \\sqrt{h} K_0,</math>\n\nwhere <math>K_0</math> is the extrinsic curvature of the boundary imbedded flat spacetime. As <math>\\sqrt{h}</math> is invariant under variations of <math>g_{\\alpha \\beta}</math>, this addition term does not affect the field equations; as such, this is referred to as the non-dynamical term.\n\n== Introduction to hyper-surfaces ==\n\n=== Defining hyper-surfaces ===\n\nIn a four-dimensional spacetime manifold, a hypersurface is a three-dimensional [[submanifold]] that can be either timelike, spacelike, or null.\n\nA particular hyper-surface <math>\\Sigma</math> can be selected either by imposing a constraint on the coordinates\n\n:<math>f (x^\\alpha) = 0,</math>\n\nor by giving parametric equations,\n\n:<math>x^\\alpha = x^\\alpha (y^a),</math>\n\nwhere <math>y^a (a=1,2,3)</math> are coordinates intrinsic to the hyper-surface.\n\nFor example, a two-sphere in three-dimensional Euclidean space can be described either by\n\n:<math>f (x^\\alpha) = x^2 + y^2 + z^2 - r^2 = 0,</math>\n\nwhere <math>r</math> is the radius of the sphere, or by\n\n:<math>x = r \\sin \\theta \\cos \\phi, \\quad y = r \\sin \\theta \\sin \\phi, \\quad z = r \\cos \\theta,</math>\n\nwhere <math>\\theta</math> and <math>\\phi</math> are intrinsic coordinates.\n\n=== Hyper-surface orthogonal vector fields ===\n\nWe take the metric convention (-,+,...,+). We start with the family of hyper-surfaces given by\n\n:<math>f (x^\\alpha) = C</math>\n\nwhere different members of the family correspond to different values of the constant <math>C</math>. Consider two neighbouring points <math>P</math> and <math>Q</math> with coordinates <math>x^\\alpha</math> and <math>x^\\alpha + d x^\\alpha</math>, respectively, lying in the same hyper-surface. We then have to first order\n\n:<math>C = f (x^\\alpha + d x^\\alpha) = f (x^\\alpha) + {\\partial f \\over \\partial x^\\alpha} d x^\\alpha. </math>\n\nSubtracting off <math>C = f (x^\\alpha)</math> from this equation gives\n\n:<math>{\\partial f \\over \\partial x^\\alpha} d x^\\alpha = 0</math>\n\nat <math>P</math>. This implies that <math>f_{, \\alpha}</math> is normal to the hyper-surface. A unit normal <math>n_\\alpha</math> can be introduced in the case where the hyper-surface is not null. This is defined by\n\n:<math>n^\\alpha n_\\alpha \\equiv \\epsilon =\\begin{cases} -1 & \\text{if } \\Sigma \\text{ is spacelike} \\\\ +1 & \\text{if } \\Sigma \\text{ is timelike} \\end{cases}</math>\n\nand we require that <math>n^\\alpha</math> point in the direction of increasing <math>f : n^\\alpha f_{, \\alpha} > 0</math>. It can then easily be checked that <math>n_\\alpha</math> is given by\n\n:<math>n_\\alpha = {\\epsilon f_{, \\alpha} \\over |g^{\\alpha \\beta} f_{, \\alpha} f_{, \\beta}|^{1 \\over 2}}</math>\n\nif the hyper-surface either spacelike or timelike.\n\n=== Induced and transverse metric ===\n\nThe three vectors\n\n:<math>e^\\alpha_a = \\left( {\\partial x^\\alpha \\over \\partial y^a} \\right)_{\\partial \\mathcal{M}} \\quad a=1,2,3</math>\n\nare tangential to the hyper-surface.\n\nThe induced metric is the three-tensor <math>h_{ab}</math> defined by\n\n:<math>h_{ab} = g_{\\alpha \\beta} e^\\alpha_a e^\\beta_b .</math>\n\nThis acts as a metric tensor on the hyper-surface in the <math>y^a</math> coordinates. For displacements confined to the hyper-surface (so that <math>x^\\alpha = x^\\alpha (y^a)</math>)\n\n:<math>\\begin{align}\nds^2 &= g_{\\alpha \\beta} dx^\\alpha dx^\\beta \\\\\n &= g_{\\alpha \\beta} \\left(\\frac{\\partial x^\\alpha}{\\partial y^a} dy^a \\right) \\left(\\frac{\\partial x^\\beta}{\\partial y^b} dy^b \\right) \\\\\n &= \\left( g_{\\alpha \\beta} e^\\alpha_a e^\\beta_b \\right) dy^a dy^b \\\\\n &= h_{ab} dy^a dy^b\n\\end{align}</math>\n\nBecause the three vectors <math>e^\\alpha_1, e^\\alpha_2, e^\\alpha_3</math> are tangential to the hyper-surface,\n\n:<math>n_\\alpha e^\\alpha_a = 0</math>\n\nwhere <math>n_\\alpha</math> is the unit vector (<math>n_\\alpha n^\\alpha = \\pm 1</math>) normal to the hyper-surface.\n\nWe introduce what is called the transverse metric\n\n:<math>h_{\\alpha \\beta} = g_{\\alpha \\beta} - \\epsilon n_\\alpha n_\\beta.</math>\n\nIt isolates the part of the metric that is transverse to the normal <math>n^\\alpha</math>.\n\nIt is easily seen that this four-tensor\n\n:<math>{h^\\alpha}_{\\beta} = {\\delta^\\alpha}_{\\beta} - \\epsilon n^\\alpha n_\\beta</math>\n\nprojects out the part of a four-vector transverse to the normal <math>n^\\alpha</math> as\n\n:<math>{h^\\alpha}_{\\beta} n^\\beta = ({\\delta^\\alpha}_{\\beta} - \\epsilon n^\\alpha n_\\beta) n^\\beta = (n^\\alpha - \\epsilon^2 n^\\alpha) = 0 \\quad \\text{and } \\; \\mathrm{if} \\quad w^\\alpha n_\\alpha = 0 \\quad \\mathrm{then} \\quad {h^\\alpha}_{\\beta} w^\\beta = w^\\alpha.</math>\n\nWe have\n\n:<math> h_{ab} = h_{\\alpha \\beta} e^\\alpha_a e^\\beta_b.</math>\n\nIf we define <math>h^{ab}</math> to be the inverse of <math>h_{ab}</math>, it is easy to check\n\n:<math>h^{\\alpha \\beta} = h^{ab} e^\\alpha_a e^\\beta_b</math>\n\nwhere\n\n:<math>h^{\\alpha \\beta} = g^{\\alpha \\beta} - \\epsilon n^\\alpha n^\\beta.</math>\n\nNote that variation subject to the condition\n\n:<math>\\delta g_{\\alpha \\beta} \\big|_{\\partial \\mathcal{M}} = 0,</math>\n\nimplies that <math>h_{ab} = g_{\\alpha \\beta} e^\\alpha_a e^\\beta_b</math>, the induced metric on <math>\\partial \\mathcal{M}</math>, is held fixed during the variation.\n\n== On proving the main result ==\n\nIn the following subsections we will first compute the variation of the Einstein-Hilbert term and then the variation of the boundary term, and show that their sum results in\n\n:<math>\\delta S_{TOTAL} = \\delta S_{EH} + \\delta S_{GHY} = \\frac{1}{16 \\pi} \\int_\\mathcal{M} G_{\\alpha \\beta} \\delta g^{\\alpha \\beta} \\sqrt{-g} d^4x</math>\n\nwhere <math>G_{\\alpha \\beta} = R_{\\alpha \\beta} - {1 \\over 2} g_{\\alpha \\beta} R</math> is the [[Einstein tensor]], which produces the correct left-hand side to the [[Einstein field equations]], without the [[cosmological term]], which however is trivial to include by replacing <math>S_{EH}</math> with\n\n:<math>{1 \\over 16 \\pi} \\int_\\mathcal{M} (R - 2 \\Lambda) \\sqrt{-g} d^4x</math>\n\nwhere <math>\\Lambda</math> is the [[cosmological constant]].\n\nIn the third subsection we elaborate on the meaning of the non-dynamical term.\n\n=== Variation of the Einstein–Hilbert term ===\n\nWe will use the identity\n\n:<math> \\delta \\sqrt{-g} \\equiv - {1 \\over 2}\\sqrt{-g} g_{\\alpha \\beta} \\delta g^{\\alpha \\beta},</math>\n\nand the [[Palatini identity]]:\n\n:<math> \\delta R_{\\alpha \\beta} \\equiv \\nabla_\\mu (\\delta \\Gamma^\\mu_{\\alpha \\beta}) - \\nabla_\\beta (\\delta \\Gamma^\\mu_{\\alpha \\mu}),\n</math>\n\nwhich are both obtained in the article [[Einstein–Hilbert action]].\n\nWe consider the variation of the Einstein–Hilbert term:\n\n:<math>\\begin{align}\n(16 \\pi) \\delta S_{EH} & = \\int_\\mathcal{M} \\delta \\left ( g^{\\alpha \\beta} R_{\\alpha \\beta} \\sqrt{-g} \\right ) d^4x \\\\\n& = \\int_\\mathcal{M} \\left( R_{\\alpha \\beta} \\sqrt{-g} \\delta g^{\\alpha \\beta} + g^{\\alpha \\beta} R_{\\alpha \\beta} \\delta \\sqrt{-g} + \\sqrt{-g} g^{\\alpha \\beta} \\delta R_{\\alpha \\beta} \\right) d^4x \\\\\n& = \\int_\\mathcal{M} \\left( R_{\\alpha \\beta} - {1 \\over 2} g_{\\alpha \\beta} R \\right ) \\delta g^{\\alpha \\beta} \\sqrt{-g} d^4x + \\int_\\mathcal{M} g^{\\alpha \\beta} \\delta R_{\\alpha \\beta} \\sqrt{-g} d^4x .\n\\end{align}</math>\n\nThe first term gives us what we need for the left-hand side of the Einstein field equations. We must account for the second term.\n\nBy the Palatini identity\n\n:<math> g^{\\alpha \\beta} \\delta R_{\\alpha \\beta} = \\delta {V^\\mu}_{; \\mu}, \\qquad \\delta V^\\mu = g^{\\alpha \\beta} \\delta \\Gamma^\\mu_{\\alpha \\beta} - g^{\\alpha \\mu} \\delta \\Gamma^\\beta_{\\alpha \\beta} . \n</math>\n\nWe will need [[Stokes theorem]] in the form:\n\n:<math>\\begin{align}\n \\int_\\mathcal{M} {A^\\mu}_{; \\mu} \\sqrt{-g} d^4x & = \\int_\\mathcal{M} (\\sqrt{-g} A^\\mu)_{, \\mu} d^4x \\\\\n& = \\oint_{\\partial \\mathcal{M}} A^\\mu d \\Sigma_\\mu \\\\\n& = \\oint_{\\partial \\mathcal{M}} \\epsilon A^\\mu n_\\mu \\sqrt{|h|} d^3y\n\\end{align}</math>\n\nwhere <math>n_\\mu</math> is the unit normal to <math>\\partial_\\mathcal{M}</math> and <math>\\epsilon \\equiv n^\\mu n_\\mu = \\pm 1</math>, and <math>y^a</math> are coordinates on the boundary. And <math>d \\Sigma_\\mu = \\epsilon n_\\mu d \\Sigma</math> where <math>d \\Sigma = |h|^{1 \\over 2} d^3 y</math> where <math>h = \\det [h_{ab}]</math>, is an invariant three-dimensional volume element on the hyper-surface. In our particular case we take <math>A^\\mu = \\delta V^\\mu</math>.\n\nWe now evaluate <math>\\delta V^\\mu n_\\mu</math> on the boundary <math>\\partial \\mathcal{M}</math>, keeping in mind that on <math>\\partial \\mathcal{M}, \\delta g_{\\alpha \\beta} = 0 = \\delta g^{\\alpha \\beta}</math>. Taking this into account we have\n\n:<math>\\delta \\Gamma^\\mu_{\\alpha \\beta} \\big|_{\\partial \\mathcal{M}} = \\frac{1}{2} g^{\\mu \\nu} (\\delta g_{\\nu \\alpha, \\beta} + \\delta g_{\\nu \\beta, \\alpha} - \\delta g_{\\alpha \\beta, \\nu}).</math>\n \nIt is useful to note that\n\n:<math>\\begin{align}\ng^{\\alpha \\mu} \\delta \\Gamma^\\beta_{\\alpha \\beta} \\big|_{\\partial \\mathcal{M}} & = {1 \\over 2} g^{\\alpha \\mu} g^{\\beta \\nu} (\\delta g_{\\nu \\alpha, \\beta} + \\delta g_{\\nu \\beta, \\alpha} - \\delta g_{\\alpha \\beta, \\nu}) \\\\\n& = {1 \\over 2} g^{\\mu \\nu} g^{\\alpha \\beta} (\\delta g_{\\nu \\alpha, \\beta} + \\delta g_{\\alpha \\beta, \\nu} - \\delta g_{\\nu \\beta, \\alpha})\n\\end{align}</math>\n\nwhere in the second line we have swapped around <math>\\alpha</math> and <math>\\nu</math> and used that the metric is symmetric. It is then not difficult to work out <math>\\delta V^\\mu = g^{\\mu \\nu} g^{\\alpha \\beta} (\\delta g_{\\nu \\beta, \\alpha} - \\delta g_{\\alpha \\beta, \\nu})</math>.\n\nSo now\n\n:<math>\\begin{align}\n\\delta V^\\mu n_\\mu \\big|_{\\partial \\mathcal{M}} & = n^\\mu g^{\\alpha \\beta} (\\delta g_{\\mu \\beta, \\alpha} - \\delta g_{\\alpha \\beta, \\mu}) \\\\\n& = n^\\mu (\\epsilon n^\\alpha n^\\beta + h^{\\alpha \\beta}) (\\delta g_{\\mu \\beta, \\alpha} - \\delta g_{\\alpha \\beta, \\mu}) \\\\\n& = n^\\mu h^{\\alpha \\beta} (\\delta g_{\\mu \\beta, \\alpha} - \\delta g_{\\alpha \\beta, \\mu})\n\\end{align}</math>\n\nwhere in the second line we used the identity <math>g^{\\alpha \\beta} = \\epsilon n^\\alpha n^\\beta + h^{\\alpha \\beta}</math>, and in the third line we have used the anti-symmetry in <math>\\alpha</math> and <math>\\mu</math>. As <math>\\delta g_{\\alpha \\beta}</math> vanishes everywhere on the boundary <math>\\partial \\mathcal{M}</math>, its tangential derivatives must also vanish: <math>\\delta g_{\\alpha \\beta, \\gamma} e^\\gamma_c = 0</math>. It follows that <math>h^{\\alpha \\beta} \\delta g_{\\mu \\beta, \\alpha} = h^{ab} e^\\alpha_a e^\\beta_b \\delta g_{\\mu \\beta, \\alpha} = 0</math>. So finally we have\n\n:<math>n^\\mu \\delta V_\\mu \\big|_{\\partial \\mathcal{M}} = - h^{\\alpha \\beta} \\delta g_{\\alpha \\beta, \\mu} n^\\mu.</math>\n\nGathering the results we obtain\n\n:<math>(16 \\pi) \\delta S_{EH} = \\int_\\mathcal{M} G_{\\alpha \\beta} \\delta g^{\\alpha \\beta} \\sqrt{-g} d^4x - \\oint_{\\partial \\mathcal{M}} \\epsilon h^{\\alpha \\beta} \\delta g_{\\alpha \\beta, \\mu} n^\\mu \\sqrt{h} d^3 y \\quad Eq 1.</math>\n\nWe next show that the above boundary term will be cancelled by the variation of <math>S_{GHY}</math>.\n\n=== Variation of the boundary term ===\n\nWe now turn to the variation of the <math>S_{GHY}</math> term. Because the induced metric is fixed on <math>\\partial \\mathcal{M},</math> the only quantity to be varied is <math>K</math> is the trace of the [[extrinsic curvature]].\n\nWe have\n\n:<math>\\begin{align}\nK & = {n^\\alpha}_{; \\alpha} \\\\\n  & = g^{\\alpha \\beta} n_{\\alpha ; \\beta} \\\\\n  & = \\left (\\epsilon n^\\alpha n^\\beta + h^{\\alpha \\beta} \\right ) n_{\\alpha ; \\beta} \\\\\n  & = h^{\\alpha \\beta} n_{\\alpha ; \\beta} \\\\\n  & = h^{\\alpha \\beta} (n_{\\alpha, \\beta} - \\Gamma^\\gamma_{\\alpha \\beta} n_\\gamma)\n\\end{align}</math>\n\nwhere we have used that <math>0 = (n^\\alpha n_\\alpha)_{; \\beta}</math> implies <math>n^\\alpha n_{\\alpha; \\beta} = 0.</math> So the variation of <math>K</math> is\n\n:<math>\\begin{align}\n\\delta K &= -h^{\\alpha \\beta} \\delta \\Gamma^\\gamma_{\\alpha \\beta} n_\\gamma \\\\\n&= -h^{\\alpha \\beta} n^\\mu g_{\\mu \\gamma} \\delta \\Gamma^\\gamma_{\\alpha \\beta} \\\\\n&= -h^{\\alpha \\beta} n^\\mu g_{\\mu \\gamma} \\frac{1}{2} g^{\\gamma \\sigma} \\left (\\delta g_{\\sigma \\alpha, \\beta} + \\delta g_{\\sigma \\beta, \\alpha} - \\delta g_{\\alpha \\beta, \\sigma} \\right ) \\\\\n&= -{1 \\over 2} h^{\\alpha \\beta} \\left( \\delta g_{\\mu \\alpha, \\beta} + \\delta g_{\\mu \\beta, \\alpha} - \\delta g_{\\alpha \\beta, \\mu} \\right ) n^\\mu \\\\\n&= \\frac{1}{2} h^{\\alpha \\beta} \\delta g_{\\alpha \\beta, \\mu} n^\\mu\n\\end{align}</math>\n\nwhere we have use the fact that the tangential derivatives of <math>\\delta g_{\\alpha \\beta}</math> vanish on <math>\\partial \\mathcal{M}.</math> We have obtained\n\n:<math>(16 \\pi) \\delta S_{GHY} = \\oint_{\\partial \\mathcal{M}} \\epsilon h^{\\alpha \\beta} \\delta g_{\\alpha \\beta, \\mu} n^\\mu \\sqrt{h} d^3 y</math>\n\nwhich cancels the second integral on the right-hand side of Eq. 1. The total variation of the gravitational action is:\n\n:<math>\\delta S_{TOTAL} = {1 \\over 16 \\pi} \\int_\\mathcal{M} G_{\\alpha \\beta} \\delta g^{\\alpha \\beta} \\sqrt{-g} d^4x .</math>\n\nThis produces the correct left-hand side of the Einstein equations. This proves the main result.\n\nThis result was generalized to fourth order theories of gravity on manifolds with boundaries in 1983<ref>{{Cite web| url= https://www.researchgate.net/publication/34874539_Second_and_fourth_order_gravitational_actions_on_manifolds_with_boundaries |title=Second and fourth order gravitational actions on manifolds with boundaries|website=ResearchGate |language=en| access-date=2017-05-08}}</ref> and published in 1985.<ref>{{Cite web| url=https://www.researchgate.net/publication/230911526_The_fourth-order_gravitational_action_for_manifolds_with_boundaries |title=The Fourth-order Gravitational Action for Manifolds with Boundaries| last=Barth| first=Norman|date=|year=1985|website=Research Gate|series=Classical and Quantum Gravity 2 (4)| page=497 |archive-url=| archive-date=|dead-url=|access-date=April 17, 2017}}</ref>\n\n=== The non-dynamical term ===\n\nWe elaborate on the role of\n\n:<math>S_0 = {1 \\over 8 \\pi} \\oint_{\\partial \\mathcal{M}} \\epsilon K_0 |h|^{1 \\over 2} d^3y</math>\n\nin the gravitational action. As already mentioned above, because this term only depends on <math>h_{ab}</math>, its variation with respect to <math>g_{\\alpha \\beta}</math> gives zero and so does not effect the field equations, its purpose is to change the numerical value of the action. As such we will refer to it as the non-dynamical term.\n\nLet us assume that <math>g_{\\alpha \\beta}</math> is a solution of the vacuum field equations, in which case the Ricci scalar <math>R</math> vanishes. The numerical value of the gravitational action is then\n\n:<math>S = {1 \\over 8 \\pi} \\oint_{\\partial \\mathcal{M}} \\epsilon K |h|^{1 \\over 2} d^3y ,</math>\n\nwhere we are ignoring the non-dynamical term for the moment. Let us evaluate this for flat spacetime. Choose the boundary <math>\\partial \\mathcal{M}</math> to consist of two hyper-surfaces of constant time value <math>t= t_1, t_2</math> and a large three-cylinder at <math>r=r_0</math> (that is, the product of a finite interval and a three-sphere of radius <math>r_0</math>). We have <math>K=0</math> on the hyper-surfaces of constant time. On the three cylinder, in coordinates intrinsic to the hyper-surface, the line element is\n\n:<math>\\begin{align}\nds^2 & = - dt^2 + r_0^2 d \\Omega^2 \\\\\n& = - dt^2 + r_0^2 (d \\theta^2 + \\sin^2 \\theta d \\phi^2)\n\\end{align}</math>\n\nmeaning the induced metric is\n\n:<math>h_{ab} = \\begin{bmatrix} -1 & 0 & 0 \\\\ 0 & r_0^2 & 0 \\\\ 0 & 0 & r_0^2 \\sin^2 \\theta \\end{bmatrix}. </math>\n\nso that <math>|h|^{1 \\over 2} = r_0^2 \\sin \\theta</math>. The unit normal is <math>n_\\alpha = \\partial_\\alpha r</math>, so <math>K = {n^\\alpha}_{; \\alpha} = 2/r_0</math>. Then\n\n:<math>\\oint_{\\partial \\mathcal{M}} \\epsilon K |h|^{1 \\over 2} d^3y = \\int_{t_1}^{t_2} dt \\int_0^{2 \\pi} d \\varphi \\int_0^\\pi d \\theta \\left( {2 \\over r_0} \\right) (r_0^2 \\sin \\theta) = 8 \\pi r_0 (t_2 - t_1)</math>\n\nand diverges as <math>r_0 \\to \\infty</math>, that is, when the spatial boundary is pushed to infinity, even when the <math>\\mathcal{M}</math> is bounded by two hyper-surfaces of constant time. One would expect the same problem for curved spacetimes that are [[asymptotically flat]] (there is no problem if the spacetime is compact). This problem is remedied by the non-dynamical term. The difference <math>S_{GHY} - S_0</math> will be well defined in the limit <math>r_0 \\to \\infty</math>.\n\n===Variation of modified gravity terms===\n{{Main|Alternatives to general relativity}}\nThere are many theories which attempt to modify General Relativity in different ways, for example [[f(R) gravity]] replaces R, the Ricci scalar in the Einstein-Hilbert action with a function f(R). Guarnizo et al. found the boundary term for a general f(R) theory.<ref>{{Cite journal|arxiv=1002.0617|title=Boundary Term in Metric f(R) Gravity: Field Equations in the Metric Formalism| journal=General Relativity and Gravitation |volume=42|issue=11|pages=2713–2728| last1=Guarnizo |first1=Alejandro | last2=Castaneda|first2=Leonardo|last3= Tejeiro|first3=Juan M.|year=2010|doi=10.1007/s10714-010-1012-6|bibcode=2010GReGr..42.2713G}}</ref> \nThey found that \"the modified action in the metric formalism of f(R) gravity plus a Gibbons- York-Hawking like boundary term must be written as:\n\n:<math>S_{mod} = \\frac{1}{2\\kappa} \\int_V d^4x\\sqrt{-g} f(R) +2 \\int_{\\partial V} d^3y \\epsilon |h| f'(R) K </math>\n\nwhere <math>f'(R) \\equiv \\frac{d f(R)}{d R}</math>.\n\nBy using the [[ADM formalism|ADM decomposition]] and introducing extra auxiliary fields, in 2009 Deruelle et al. found a method to find the boundary term for \"gravity theories whose Lagrangian is an arbitrary function of the Riemann tensor.\"<ref>{{Cite journal|arxiv=0908.0679|title=Hamiltonian formulation of f(Riemann) theories of gravity|journal=Progress of Theoretical Physics|volume=123|pages=169–185| last1=Deruelle| first1=Nathalie| last2=Sasaki|first2=Misao |last3=Sendouda| first3=Yuuiti| last4=Yamauchi|first4=Daisuke|year=2009|doi=10.1143/PTP.123.169|bibcode=2010PThPh.123..169D}}</ref> This method can be used to find the GHY boundary terms for [[Infinite derivative gravity]].<ref>{{Cite journal| arxiv=1606.01911 |last1=Teimouri |first1=Ali |title=Generalised Boundary Terms for Higher Derivative Theories of Gravity|journal=Journal of High Energy Physics| volume=2016 |issue=8 |last2=Talaganis| first2=Spyridon|last3=Edholm |first3=James| last4=Mazumdar |first4=Anupam| year=2016| doi=10.1007/JHEP08(2016)144|bibcode=2016JHEP...08..144T}}</ref>\n\n== Arnowitt–Deser–Misner (ADM) energy ==\n\n{{Empty section|date=November 2015}}\n\n== A path integral approach to quantum gravity ==\n\nAs mentioned at the beginning, the GHY term is required to ensure the path integral (a la Hawking et al.) for quantum gravity has the correct composition properties.\n\nThis older approach to path-integral quantum gravity had a number of difficulties and unsolved problems. The starting point in this approach is Feynman's idea that one can represent the amplitude\n\n:<math>\\langle g_2, \\phi_2, \\Sigma_2 | g_1, \\phi_1, \\Sigma_1 \\rangle</math>\n\nto go from the state with metric <math>g_1</math> and matter fields <math>\\phi_1</math> on a surface <math>\\Sigma_1</math> to a state with metric <math>g_2</math> and matter fields <math>\\phi_2</math> on a surface <math>\\Sigma_2</math>, as a sum over all field configurations <math>g</math> and <math>\\phi</math> which take the boundary values of the fields on the surfaces <math>\\Sigma_1</math> and <math>\\Sigma_2</math>. We write\n\n:<math>\\langle g_2, \\phi_2, \\Sigma_2 | g_1, \\phi_1, \\Sigma_1 \\rangle = \\int \\mathcal{D} [g,\\phi] \\exp (i S [g,\\phi])</math>\n\nwhere <math>\\mathcal{D} [g,\\phi]</math> is a measure on the space of all field configurations <math>g</math> and <math>\\phi</math>, <math>S [g,\\phi]</math> is the action of the fields, and the integral is taken over all fields which have the given values on <math>\\Sigma_1</math> and <math>\\Sigma_2</math>.\n\nIt is argued that one need only specify the three-dimensional induced metric <math>h</math> on the boundary.\n\nNow consider the situation where one makes the transition from metric <math>h_1</math>, on a surface <math>\\Sigma_1</math>, to a metric <math>h_2</math>, on a surface <math>\\Sigma_2</math> and then on to a metric <math>h_3</math> on a later surface <math>\\Sigma_3</math>\n\nOne would like to have the usual composition rule\n\n:<math>\\langle h_3, \\Sigma_3 | h_1, \\Sigma_1 \\rangle = \\sum_{h_2} \\langle h_3, \\Sigma_3 | h_2, \\Sigma_2 \\rangle \\langle h_2, \\Sigma_2 | h_1, \\Sigma_1 \\rangle</math>\n\nexpressing that the amplitude to go from the initial to final state to be obtained by summing over all states on the intermediate surface <math>\\Sigma_2</math>.\n\nLet <math>g_1</math> be the metric between <math>\\Sigma_1</math> and <math>\\Sigma_2</math> and <math>g_2</math> be the metric between <math>\\Sigma_2</math> and <math>\\Sigma_3</math>. Although the induced metric of <math>g_1</math> and <math>g_2</math> will agree on <math>\\Sigma_2</math>, the normal derivative of <math>g_1</math> at <math>\\Sigma_2</math> will not in general be equal to that of <math>g_2</math> at <math>\\Sigma_2</math>. Taking the implications of this into account, it can then be shown that the composition rule will hold if and only if we include the GHY boundary term.<ref>For example see the book \"Hawking on the big bang and black holes\" by Stephen Hawking, chapter 15.</ref>\n\nIn the next section it is demonstrated how this path integral approach to quantum gravity leads to the concept of black hole temperature and intrinsic quantum mechanical entropy.\n\n== Calculating black hole entropy using the euclidean semiclassical approach ==\n{{main| Euclidean quantum gravity}}\n\n{{Empty section|date=November 2015}}\n\n== Application in loop quantum gravity ==\n{{main| Loop quantum gravity}}\n\n=== Transition amplitudes and the Hamilton's principal function ===\n\nIn the quantum theory, the object that corresponds to the [[Hamilton's principal function]] is the [[transition amplitude]]. Consider gravity defined on a compact region of spacetime, with the topology of a four dimensional ball. The boundary of this region is a three-dimensional space with the topology of a three-sphere, which we call <math>\\Sigma</math>. In pure gravity without cosmological constant, since the Ricci scalar vanishes on solutions of Einstein's equations, the bulk action vanishes and the Hamilton's principal function is given entirely in terms of the boundary term,\n\n:<math>S [q] = \\int_\\Sigma K^{ab} [q] q_{ab} \\sqrt{q} \\; d^3 \\sigma</math>\n\nwhere <math>K^{ab}</math> is the extrinsic curvature of the boundary, <math>q_{ab}</math> is the three-metric induced on the boundary, and <math>\\sigma</math> are coordinates on the boundary.\n\nThe functional <math>S [q]</math> is a highly non-trivial functional to compute; this is because the extrinsic curvature <math>K^{ab} [q]</math> is determined by the bulk solution singled out by the boundary intrinsic geometry. As such <math>K^{ab} [q]</math> is non-local. Knowing the general dependence of <math>K^{ab}</math> from <math>q_{ab}</math> is equivalent to knowing the general solution of the Einstein equations.\n\n=== Background-independent scattering amplitudes ===\n\n[[Loop quantum gravity]] is formulated in a background-independent language. No spacetime is assumed a priori, but rather it is built up by the states of theory themselves - however scattering amplitudes are derived from <math>n</math>-point functions ([[Correlation function (quantum field theory)]]) and these, formulated in conventional quantum field theory, are functions of points of a background space-time. The relation between the background-independent formalism and the conventional formalism of quantum field theory on a given spacetime is far from obvious, and it is far from obvious how to recover low-energy quantities from the full background-independent theory. One would like to derive the <math>n</math>-point functions of the theory from the background-independent formalism, in order to compare them with the standard perturbative expansion of quantum general relativity and therefore check that loop quantum gravity yields the correct low-energy limit.\n\nA strategy for addressing this problem has been suggested;<ref>L. Modesto, C. Rovelli:''Particle scattering in loop quantum gravity'', Phys Rev Lett 95 (2005) 191301</ref> the idea is to study the boundary amplitude, or transition amplitude of a compact region of spacetime, namely a path integral over a finite space-time region, seen as a function of the boundary value of the field.<ref>R Oeckl, ''A ‘general boundary’ formulation for quantum mechanics and quantum gravity'', Phys Lett B575 (2003) 318-324 ; ''Schrodinger's cat and the clock: lessons for quantum gravity'', Class Quant Grav 20 (2003) 5371-5380l</ref> In conventional quantum field theory, this boundary amplitude is well–defined<ref>F. Conrady, C. Rovelli ''Generalized Schrodinger equation in Euclidean field theory\", Int J Mod Phys A 19, (2004) 1-32.</ref><ref>L Doplicher, ''Generalized Tomonaga-Schwinger equation from the Hadamard formula'', Phys Rev D70 (2004) 064037</ref> and codes the physical information of the theory; it does so in quantum gravity as well, but in a fully background–independent manner.<ref>F. Conrady, L. Doplicher, R. Oeckl, C. Rovelli, M. Testa, ''Minkowski vacuum in background independent quantum gravity'', Phys Rev D69 (2004) 064019.</ref> A generally covariant definition of <math>n</math>-point functions can then be based on the idea that the distance between physical points –arguments of the <math>n</math>-point function is determined by the state of the gravitational field on the boundary of the spacetime region considered.\n\nThe key observation is that in gravity the boundary data include the gravitational field, hence the geometry of the boundary, hence all relevant relative distances and time separations. In other words, the boundary formulation realizes very elegantly in the quantum context the complete identification between spacetime geometry and dynamical fields.\n\n==Notes==\n{{Reflist}}\n\n==References==\n*{{cite journal|last=York |first=J. W. |authorlink=James W. York |year=1972|title=Role of conformal three-geometry in the dynamics of gravitation |journal=[[Physical Review Letters]] |volume=28 |issue=16 |doi=10.1103/PhysRevLett.28.1082 |bibcode=1972PhRvL..28.1082Y |page=1082}}\n*{{cite journal |last1=Gibbons |first1=G. W. |authorlink1=Gary Gibbons |last2=Hawking |first2=S. W. |authorlink2=Stephen Hawking |title=Action integrals and partition functions in quantum gravity |year=1977 |journal=[[Physical Review D]] |volume=15 |issue=10 |doi=10.1103/PhysRevD.15.2752 |bibcode=1977PhRvD..15.2752G |page=2752}}\n*S. W. Hawking and G. T. Horowitz, \"The Gravitational Hamiltonian, action, entropy and surface terms,\" ''Class. Quantum Grav.'' 13 (1996) 1487 [arXiv:gr-qc/9501014].\n*J. D. Brown and J. W. York, `\"The Microcanonical functional integral. 1. The Gravitational field,\" ''Phys. Rev.'' D47, 1420 (1993) [arXiv:gr-qc/9209014].\n\n{{Stephen Hawking}}\n\n{{DEFAULTSORT:Gibbons-Hawking-York boundary term}}\n[[Category:Variational formalism of general relativity]]\n[[Category:General relativity]]\n[[Category:Lagrangian mechanics]]\n[[Category:Stephen Hawking]]"
    },
    {
      "title": "Plebanski action",
      "url": "https://en.wikipedia.org/wiki/Plebanski_action",
      "text": "{{More citations needed|date=February 2015}}\n[[General relativity]] and [[supergravity]] in all dimensions meet each other at a common assumption:\n\n:''Any [[Configuration space (physics)|configuration space]] can be coordinatized by [[gauge field]]s <math>A^i_a</math>, where the index <math>i</math> is a [[Lie algebra]] index and <math>a</math> is a [[Three-dimensional space|spatial]] [[manifold]] index.''\n\nUsing these assumptions one can construct an [[effective field theory]] in low energies for both. In this form the action of general relativity can be written in the form of the '''Plebanski action''' which can be constructed using the [[Palatini action]] to derive [[Einstein's field equations]] of [[general relativity]].\n\nThe form of the action introduced by [[Jerzy Plebański|Plebanski]] is:\n\n:<math>S_{Plebanski} = \\int_{\\Sigma \\times R} \\epsilon_{ijkl} B^{ij} \\wedge F^{kl} (A^i_a) + \\phi_{ijkl} B^{ij} \\wedge B^{kl} </math>\n\nwhere\n\n:<math>i, j, l, k</math>\n\nare internal indices,\n\n:<math>F</math>\n\nis a curvature on the orthogonal group <math>SO(3, 1)</math> and the [[Connection (mathematics)|connection]] variables (the gauge fields) are denoted by\n\n:<math>A^i_a</math>.\n\nThe symbol\n\n:<math>\\phi_{ijkl}</math>\n\nis the  [[Lagrangian multiplier]] and\n\n:<math>\\epsilon_{ijkl}</math>\n\nis the [[antisymmetric symbol]] valued over <math>SO(3, 1)</math>.\n\nThe specific definition\n\n:<math>B^{ij} = e^i \\wedge e^j</math>,\n\nwhich formally satisfies the [[Einstein's field equation]] of [[general relativity]].\n\nApplication is to the [[Barrett–Crane model]].<ref name=Barrett1998>{{citation\n | author = Barrett, John W.\n | author2 = Louis Crane\n | title = Relativistic spin networks and quantum gravity\n | journal = J. Math. Phys. \n | volume = 39\n | issue = 6\n | pages = 3296–3302\n | doi = 10.1063/1.532254\n | date = 1998\n|arxiv = gr-qc/9709028 |bibcode = 1998JMP....39.3296B }}</ref><ref name=Barrett>{{citation\n | author = Barrett, John W.\n | author2 = Louis, Crane\n | title = A Lorentzian signature model for quantum general relativity\n | journal = Classical and Quantum Gravity\n | volume = 17\n | issue = 16\n | pages = 3101\n | doi = 10.1088/0264-9381/17/16/302\n|arxiv = gr-qc/9904025 |bibcode = 2000CQGra..17.3101B | year = 2000\n }}</ref>\n\n==See also==\n\n* [[tetradic Palatini action]]\n* [[Barrett–Crane model]]\n* [[BF model]]\n\n==References==\n{{reflist}}\n\n* {{cite journal  |last1=Celada |first1=Mariano |last2=Gonzalez|first2=Diego |last3=Montesinos |first3=Merced |year=2016  |title=BF gravity |journal=Classical and Quantum Gravity |volume=33 |issue=21 |pages=213001 |arxiv=1610.02020  |bibcode=2016CQGra..33u3001C |doi=10.1088/0264-9381/33/21/213001}}\n\n{{DEFAULTSORT:Plebanski Action}}\n[[Category:Theories of gravitation]]\n[[Category:Variational formalism of general relativity]]"
    },
    {
      "title": "Antithetic variates",
      "url": "https://en.wikipedia.org/wiki/Antithetic_variates",
      "text": "In [[statistics]], the '''antithetic variates''' method is a [[variance reduction]] technique used in [[Monte Carlo methods]]. Considering that the error reduction in the simulated signal (using [[Monte Carlo methods]]) has a [[square root]] [[limit of a sequence|convergence]], a very large number of [[Sample (statistics)|sample]] paths is required to obtain an accurate result. The antithetic variates method reduces the variance of the simulation results.<ref>{{cite book|last1=Kroese|first1=D. P.|last2=Taimre|first2=T.|last3=Botev|first3=Z. I.|title=Handbook of Monte Carlo methods|year=2011 |publisher=John Wiley & Sons}}(Chapter 9.3)</ref>\n\n==Underlying principle==\n\nThe antithetic variates technique consists, for every sample path obtained, in taking its antithetic path &mdash; that is given a path <math>\\{\\varepsilon_1,\\dots,\\varepsilon_M\\}</math> to also take <math>\\{-\\varepsilon_1,\\dots,-\\varepsilon_M\\}</math>. The advantage of this technique is twofold: it reduces the number of [[Normal distribution|normal]] samples to be taken to generate ''N'' paths, and it reduces the [[variance]] of the sample paths, improving the accuracy.\n\nSuppose that we would like to estimate \n:<math>\\theta = \\mathrm{E}( h(X) ) = \\mathrm{E}( Y ) \\, </math>\n\nFor that we have generated two samples\n\n:<math>Y_1\\text{ and }Y_2 \\, </math>\n\nAn unbiased estimate of <math>{\\theta}</math> is given by\n\n:<math>\\hat \\theta = \\frac{\\hat \\theta_1 + \\hat \\theta_2}{2}. </math>\n\nAnd \n:<math>\\text{Var}(\\hat \\theta) = \\frac{\\text{Var}(Y_1) + \\text{Var}(Y_2) + 2\\text{Cov}(Y_1,Y_2)}{4} </math>\n\nso variance is reduced if <math>Cov(Y_1,Y_2)</math> is negative.\n\n==Example 1==\n\nIf the law of the variable ''X'' follows a [[uniform distribution (continuous)|uniform distribution]] along [0,&nbsp;1], the first sample will be   <math>u_1, \\ldots, u_n</math>,  where, for any given ''i'', <math>u_i</math> is obtained from ''U''(0,&nbsp;1). The second sample is built from   <math>u'_1, \\ldots, u'_n</math>,  where, for any given ''i'': <math>u'_i = 1-u_i</math>.   If the set <math>u_i</math> is uniform along [0,&nbsp;1], so are <math>u'_i</math>.  Furthermore, covariance is negative, allowing for initial variance reduction.\n\n==Example 2: integral calculation==\n\nWe would like to estimate\n:<math>I = \\int_0^1 \\frac{1}{1+x} \\, \\mathrm{d}x.</math>\n\nThe exact result is   <math>I=\\ln 2 \\approx 0.69314718</math>.  This integral can be seen as the expected value of  <math>f(U)</math>,  where\n\n:<math>f(x) = \\frac{1}{1+x}</math>\n\nand ''U'' follows a [[uniform distribution (continuous)|uniform distribution]]&nbsp;[0,&nbsp;1].\n\nThe following table compares the classical Monte Carlo estimate (sample size: 2''n'', where ''n''&nbsp;=&nbsp;1500) to  the antithetic variates estimate (sample size: ''n'', completed with the transformed sample 1&nbsp;&minus;&nbsp;''u''<sub>''i''</sub>):\n\n:{| cellspacing=\"1\" border=\"1\"\n|\n| align=\"right\" | '''Estimate'''\n| align=\"right\" | '''Variance'''\n|-\n| ''Classical Estimate''\n| align=\"right\" | 0.69365\n| align=\"right\" | 0.002005\n|-\n| ''Antithetic Variates ''\n| align=\"right\" | 0.69399\n| align=\"right\" | 0.00063\n|}\n\nThe use of the antithetic variates method to estimate the result shows an important variance reduction.\n\n==References==\n{{Reflist}}\n\n[[Category:Variance reduction]]\n[[Category:Computational statistics]]\n[[Category:Monte Carlo methods]]"
    },
    {
      "title": "Auxiliary-field Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Auxiliary-field_Monte_Carlo",
      "text": "{{One source|date=September 2010}}\n\n'''Auxiliary-field Monte Carlo''' is a method that allows the calculation, by use of [[Monte Carlo method|Monte Carlo techniques]], of averages of operators in many-body [[quantum mechanics|quantum mechanical]] (Blankenbecler 1981, Ceperley 1977) or classical problems (Baeurle 2004, Baeurle 2003, Baeurle 2002a).\n\n==Reweighting procedure and numerical sign problem==\nThe distinctive ingredient of \"auxiliary-field Monte Carlo\" is the fact that the interactions are decoupled by means of the application of the [[Hubbard–Stratonovich transformation]], which permits the reformulation of [[many-body theory]] in terms of a scalar auxiliary-[[Field (physics)|field]] representation. This reduces the [[many-body problem]] to the calculation of a sum or integral over all possible [[auxiliary-field]] configurations. In this sense, there is a trade-off: instead of dealing with one very complicated many-body problem, one faces the calculation of an infinite number of simple external-field problems.\n\nIt is here, as in other related methods, that Monte Carlo enters the game in the guise of [[importance sampling]]: the large sum over auxiliary-field configurations is performed by sampling over the most important ones, with a certain [[probability]]. In classical [[statistical physics]], this probability is usually given by the (positive semi-definite) [[Boltzmann factor]]. Similar factors arise also in quantum field theories; however, these can have indefinite sign (especially in the case of Fermions) or even be complex-valued, which precludes their direct interpretation as probabilities. In these cases, one has to resort to a reweighting procedure (i.e., interpret the absolute value as probability and multiply the sign or phase to the observable) to get a strictly positive reference distribution suitable for Monte Carlo sampling. However, it is well known that, in specific parameter ranges of the model under consideration, the oscillatory nature of the weight function can lead to a bad [[convergence of random variables|statistical convergence]] of the [[numerical integration]] procedure. The problem is known as the [[numerical sign problem]] and can be alleviated with analytical and numerical [[convergence acceleration]] procedures (Baeurle 2002, Baeurle 2003a).\n\n==See also==\n* [[Quantum Monte Carlo]]\n\n{{No footnotes|date=November 2010}}\n\n==References==\n* {{Cite journal\n    |last = Blankenbecler\n    |first = R. |author2=Scalapino, D. J. |author3=Sugar, R. L.\n    |title = Monte Carlo calculations of coupled boson-fermion systems. I\n    |year = 1981\n    |journal = [[Physical Review D]]\n    |volume = 24\n    |issue = 8\n    |page = 2278\n    |doi = 10.1103/PhysRevD.24.2278|bibcode = 1981PhRvD..24.2278B }}\n\n* {{Cite journal\n    |last = Ceperley\n    |first = D. |author2=Chester, G.V. |author3=Kalos, M.H.\n    |title = Monte Carlo simulation of a many-fermion study\n    |journal = [[Physical Review B]]\n    |volume = 16\n    |pages = 3081\n    |year = 1977\n    |doi = 10.1103/PhysRevB.16.3081|bibcode = 1977PhRvB..16.3081C\n    |issue = 7 }}\n\n* {{Cite journal\n    |last = Baeurle\n    |first = S.A.\n    |title = Grand canonical auxiliary field Monte Carlo: a new technique for simulating open systems at high density\n    |journal = Comput. Phys. Commun.\n    |volume = 157\n    |pages = 201\n    |year = 2004\n    |doi = 10.1016/j.comphy.2003.11.001|bibcode = 2004CoPhC.157..201B\n    |issue = 3 }}\n\n* {{Cite journal\n    |last = Baeurle\n    |first = S.A.\n    |title = Computation within the auxiliary field approach\n    |journal = J. Comput. Phys.\n    |volume = 184\n    |pages = 540\n    |year = 2003\n    |doi = 10.1016/S0021-9991(02)00036-0\n|bibcode=2003JCoPh.184..540B\n    |issue = 2}}\n\n* {{Cite journal\n    |last = Baeurle\n    |first = S.A.\n    |author2= Martonak, R.|author3= Parrinello, M.\n    |title = A field-theoretical approach to simulation in the classical canonical and grand canonical ensemble\n    |journal = J. Chem. Phys.\n    |volume = 117\n    |pages = 3027\n    |year = 2002a\n    |doi = 10.1063/1.1488587|bibcode = 2002JChPh.117.3027B\n    |issue = 7 }}\n\n* {{Cite journal\n    |last = Baeurle\n    |first = S.A.\n    |title = Method of Gaussian Equivalent Representation: A New Technique for Reducing the Sign Problem of Functional Integral Methods\n    |journal = Phys. Rev. Lett.\n    |volume = 89\n    |page = 080602\n    |year = 2002\n    |doi = 10.1103/PhysRevLett.89.080602\n    |pmid = 12190451\n    |issue = 8\n|bibcode=2002PhRvL..89h0602B}}\n\n* {{Cite journal\n    |last = Baeurle\n    |first = S.A.\n    |title = The stationary phase auxiliary field Monte Carlo method: a new strategy for reducing the sign problem of auxiliary field methodologies\n    |journal = Comput. Phys. Commun.\n    |volume = 154\n    |pages = 111\n    |year = 2003a\n    |doi = 10.1016/S0010-4655(03)00284-4\n|bibcode=2003CoPhC.154..111B\n    |issue = 2}}\n* {{Cite journal\n    |last = Baer\n    |first = R. |author2=Head-Gordon, M. |author3=Neuhauser, D.\n    |title = Shifted-contour auxiliary field Monte Carlo for ab initio electronic structure: Straddling the sign problem\n    |journal = Journal of Chemical Physics\n    |volume = 109\n    |pages = 6219\n    |year = 1998\n    |issue = 15\n    |doi = 10.1063/1.477300\n    |bibcode=1998JChPh.109.6219B}}\n\n==Implementations==\n* [https://alf.physik.uni-wuerzburg.de ALF]\n* [http://quest.ucdavis.edu/ QUEST]\n\n==External links==\n*[https://archive.is/20130708123512/http://homepages-nw.uni-regensburg.de/~bas16706/index.html Theory and Computation of Advanced Materials and Sensors Group]\n\n{{DEFAULTSORT:Auxiliary Field Monte Carlo}}\n[[Category:Quantum mechanics]]\n[[Category:Monte Carlo methods]]\n[[Category:Quantum Monte Carlo]]"
    },
    {
      "title": "Auxiliary particle filter",
      "url": "https://en.wikipedia.org/wiki/Auxiliary_particle_filter",
      "text": "{{technical|date=May 2016}}\nThe '''auxiliary particle filter''' is a [[particle filter]]ing algorithm introduced by Pitt and Shephard in 1999 to improve some deficiencies of the [[particle filter#Sequential importance resampling .28SIR.29|sequential importance resampling]] (SIR) algorithm when dealing with tailed observation densities.\n\nAssume that the filtered [[Posterior probability|posterior]] is described by the following ''M'' weighted samples:\n\n: <math>\np(x_t|z_{1:t}) \\approx \\sum_{i=1}^M \\omega^{(i)}_t \\delta \\left( x_t - x^{(i)}_t \\right).\n</math>\n\nThen, each step in the [[algorithm]] consists of first drawing a sample of the particle index <math>k</math> which will be propagated from <math>t-1</math> into the new step <math>t</math>. These indexes are auxiliary [[variable (mathematics)|variables]] only used as an intermediary step, hence the name of the algorithm. The indexes are drawn according to the likelihood of some reference point <math>\\mu^{(i)}_t</math> which in some way is related to the transition model <math>x_t|x_{t-1}</math> (for example, the mean, a sample, etc.):\n\n: <math>\nk^{(i)} \\sim P(i=k|z_t) \\propto \\omega^{(i)}_t p( z_t | \\mu^{(i)}_t )\n</math>\n\nThis is repeated for <math>i=1,2,\\dots,M</math>, and using these indexes we can now draw the conditional samples:\n\n: <math>\nx_t^{(i)} \\sim p( x | x^{k^{(i)}}_{t-1}).\n</math>\n\nFinally, the weights are updated to account for the mismatch between the likelihood at the actual sample and the predicted point <math>\\mu_t^{k^{(i)}}</math>:\n\n: <math>\n\\omega_t^{(i)} \\propto \\frac{p( z_t | x^{(i)}_t) } { p( z_t | \\mu^{k^{(i)}}_t) }.\n</math>\n\n==References==\n* {{cite journal\n |author       = Pitt, M.K.\n |author2      = Shephard, N.\n |year         = 1999\n |title        = Filtering Via Simulation: Auxiliary Particle Filters\n |journal      = Journal of the American Statistical Association\n |volume       = 94\n |issue        = 446\n |pages        = 590&ndash;591\n |url          = https://www.questia.com/PM.qst?a=o&se=gglsc&d=5002321997\n |accessdate   = 2008-05-06\n |doi          = 10.2307/2670179\n |jstor        = 2670179\n |publisher    = American Statistical Association\n |archive-url  = https://web.archive.org/web/20071016200646/http://www.questia.com/PM.qst?a=o\n |archive-date = 2007-10-16\n |dead-url     = yes\n |df           = \n}}\n\n[[Category:Monte Carlo methods]]\n[[Category:Computational statistics]]\n[[Category:Nonlinear filters]]\n\n\n{{Mathapplied-stub}}\n{{statistics-stub}}"
    },
    {
      "title": "Biology Monte Carlo method",
      "url": "https://en.wikipedia.org/wiki/Biology_Monte_Carlo_method",
      "text": "'''Biology [[Monte Carlo methods]] (BioMOCA)''' have been developed at the [[University of Illinois at Urbana-Champaign]] to simulate ion transport in an electrolyte environment through ion channels or nano-pores embedded in membranes.<ref name=\"Straaten\">T.A. van der Straaten, G. Kathawala, A. Trellakis, R.S. Eisenberg, and U. Ravaioli, Molecular Simulation, 31, 151 (2005)</ref> It is a 3-D particle-based [[Monte Carlo]] simulator for analyzing and studying the ion transport problem in ion channel systems or similar nanopores in wet/biological environments. The system simulated consists of a protein forming an ion channel (or an artificial nanopores like a Carbon Nano Tube, CNT), with a membrane (i.e. lipid bilayer) that separates two ion baths on either side. BioMOCA is based on two methodologies, namely the [[Boltzmann equation|Boltzmann transport]] Monte Carlo (BTMC)<ref name=\"Jacoboni\">C. Jacoboni, P. Lugli, The Monte Carlo Method for Semiconductor Device Simulation, Springer Verlag, New York (1989)</ref> and particle-particle-particle-mesh (P<sup>3</sup>M).<ref name=\"Hockney\">R. Hockney, J. Eastwood, Computer Simulation Using Particles, McGraw-Hill, New York (1981)</ref> The first one uses Monte Carlo method to solve the Boltzmann equation, while the later splits the electrostatic forces into short-range and long-range components.\n\n==Backgrounds==\nIn full-atomic [[molecular dynamics]] simulations of [[ion channel]]s, most of the computational cost is for following the trajectory of water molecules in the system. However, in BioMOCA the water is treated as a continuum dielectric background media. In addition to that, the [[protein]] atoms of the ion channel are also modeled as static point charges embedded in a finite volume with a given dielectric coefficient. So is the [[lipid membrane]], which is treated as a static dielectric region inaccessible to ions. In fact the only non-static particles in the system are ions. Their motion is assumed classical, interacting with other ions through electrostatic interactions and pairwise [[Lennard-Jones potential]]. They also interact with the water background media, which is modeled using a scattering mechanism.\n\nThe ensemble of ions in the simulation region, are propagated synchronously in time and 3-D space by integrating the equations of motion using the second-order accurate leap-frog scheme. Ion positions ''r'' and forces ''F'' are defined at time steps ''t'', and ''t''&nbsp;+&nbsp;''dt''. The ion velocities are defined at ''t''&nbsp;–&nbsp;''dt''/2, ''t''&nbsp;+&nbsp;''dt''/2. The governing finite difference equations of motion are\n\n:<math>\n\\vec{v}(t+\\frac{dt}{2})\n= \\vec{v}(t-\\frac{dt}{2}) + \\vec{F}(t) \\, dt\n</math>\n\n:<math>\n\\vec{r}(t+dt)= \\vec{r}(t-dt) + \\vec{v}(t+\\frac{dt}{2}) \\, dt\n</math>\n\nwhere ''F'' is the sum of electrostatic and pairwise ion-ion interaction forces.\n\n===Electrostatic field solution===\nThe [[electrostatic potential]] is computed at regular time intervals by solving the [[Poisson’s equation]]\n\n:<math>\n\\nabla (\\varepsilon (r)\\nabla \\phi (r,t))\n= -(\\rho_\\text{ions}(r,t) + \\rho_\\text{perm}(r))\n</math>\n\nwhere <math>\\rho_\\text{ions}(r,t)</math> and <math>\\rho_\\text{perm}(r)</math> are the charge density of ions and permanent charges on the protein, respectively. <math>\\epsilon (r)</math> is the local [[dielectric constant]] or [[permittivity]], and <math>\\phi (r,t)</math> is the local electrostatic potential. Solving this equation provides a self-consistent way to include applied bias and the effects of image charges induced at dielectric boundaries.\n\nThe ion and partial charges on protein residues are assigned to a finite rectangular grid using the cloud-in-cell (CIC) scheme.<ref name=\"Hockney\"/> Solving the Poisson equation on the grid counts for the particlemesh component of the P<sup>3</sup>M scheme. However, this discretization leads to an unavoidable truncation of the short-range component of electrostatic force, which can be corrected by computing the short-range charge-charge [[Coulomb's law|Coulombic interactions]].\n\n===Dielectric coefficient===\nAssigning the appropriate values for dielectric permittivity of the protein, membrane, and aqueous regions is of great importance. The dielectric coefficient determines the strength of the interactions between charged particles and also the [[dielectric|dielectric boundary forces]] (DBF) on ions approaching a boundary between two regions of different permittivity. However, in nano scales the task of assigning specific permittivity is problematic and not straightforward.\n\nThe protein or membrane environment could respond to an external field in a number of different ways.<ref name=\"Straaten\"/><ref name=\"Reza\"/><ref name=\"Warshel\">A. Warshel, S.T. Russell, Q. Rev. Biol., 17, 283 (1984)</ref><ref name=\"Schutz\">C.N. Schutz, A. Warshel, Proteins, 44, 400 (2001)</ref><ref name=\"Warshel2\">A. Warshel, A. Papazyan, Curr Opin Struct Biol., 8, 211 (1998)</ref> Field induced dipoles, reorientation of permanent dipoles, protonation and deprotonation of protein residues, larger scale reorganization of ionized side-chains and water [[molecules]], both within the interior and on the surface of the protein, are all examples of how complicated the assignment of permittivity is. In MD simulations, where all the charges, [[dipoles]], and field induced atomic dipoles are treated explicitly then it is suggested that a dielectric value of 1 is appropriate. However, in reduced-particle ion simulation programs, such as ours, where the protein, membrane, and water are continuum backgrounds and treated implicitly, and on top of that, the ion motion takes place on the same time-scale as the protein’s response to its presence, it is very difficult to assign the dielectric coefficients. In fact, changing the dielectric coefficients could easily alter the channel characteristics, such as ion permeation and selectivity The assignment of dielectric coefficient for water is another key issue. The water molecules inside ion channels could be very ordered due to tapered size of the pore, which is often lined with highly charged residues, or hydrogen bond formation between water molecules and protein.<ref name=\"Roux\">B. Roux, T. Allen, S. Berneche, W. Im, Q. Rev. Biophys., 37, 15 (2004)</ref> As a result, the dielectric constant of water inside an ion channel could be quite different from the value under bulk conditions. To make the matter even more complicated, the dielectric coefficients of water inside [[nanopore]]s is not necessarily an isotropic scalar value, but an [[anisotropic]] tensor having different values in different directions.\n\n===Anisotropic permittivity===\nIt has become evident that the [[macroscopic]] properties of a system do not necessarily extend to the molecular length scales.  In a recent research study carried by Reza Toghraee, R. Jay Mashl, and Eric Jakobsson at the University of Illinois, Urbana-Champaign,<ref name=\"Reza\">Reza Toghraee, J. R. Mashl, K.I. Lee, E. Jakobsson, U. Ravaioli,  Journal of Computational Electronics, 8, 98, (2009)</ref> they used Molecular Dynamics simulations to study the properties of water in featureless hydrophobic cylinders with diameters ranging from 1 to 12&nbsp;nm. This study showed that water undergoes distinct transitions in structure, dielectric properties, and [[Electrical mobility|mobility]] as the tube diameter is varied. In particular they found that the dielectric properties in the range of 1 to 10&nbsp;nm is quite different from bulk water and is in fact anisotropic in nature.\nThough, such featureless [[hydrophobic]] channels do not represent actual ion channels and more research has to be done in this area before one could use such data for ion channels, it is evident that water properties like [[permittivity]] inside an ion channel or nano-pore could be much more\ncomplicated that it has been thought before. While a high axial dielectric constant shields ion’s electrostatic charges in the axial direction (along the channel), low radial dielectric constant increases the interaction between the mobile ion and the partial charges, or the dielectric charge images on the channel, conveying stronger selectivity in ion channels.\n\nSolving the [[Poisson equation]] based on an anisotropic permittivity has been incorporated into BioMOCA using the box integration discretization method,<ref name=\"Selberherr\">[[Siegfried Selberherr|S. Selberherr]], Analysis and Simulation of Semiconductor Devices, New York, Springer-Verlag Wien, (1984). {{ISBN|3-211-81800-6}}</ref> which has been briefly described below.\n\n==Calculations==\n\n===Box integration discretization===\nIn order to use box integration for discretizing a D-dimensional Poisson equation\n:<math>\n\\nabla (\\varepsilon \\nabla \\varphi) = \\rho\n</math>\nwith <math>\\varepsilon</math> being a diagonal ''D''&nbsp;×&nbsp;''D'' tensor, this differential equation is reformulated as an integral equation. Integration the above equation over a D-dimensional region <math>\\Omega</math>, and using Gauss theorem, then the integral formulation is obtained\n:<math>\n\\oint_{\\partial \\Omega} \\hat{n} (\\varepsilon \\nabla \\varphi)\n= - \\int_\\Omega \\rho\n</math>\n\nIn this appendix it is assumed to be a two-dimensional case. Upgrading to a three-dimensional system would be straightforward and legitimate as the Gauss theorem is also valid for the one and three dimensions. <math>\\epsilon</math> is assumed to be given on the rectangular regions between nodes, while <math>\\varphi</math> is defined on the grid nodes (as illustrated on figure at the right).\n\n[[File:F1.gif|thumb|Box integration for a two-dimensional tensor product grid. The integration region is indicated by the dashed rectangle. Charges are assumed to be given on the same nodes as potential]]\n\nThe integration regions <math>\\Omega</math> are then chosen as rectangles centered around node and extending to the 4 nearest neighbor nodes. The gradient <math>\\nabla \\varphi</math> is then approximated using centered difference normal to the boundary of the integration region <math>\\Omega</math>, and average <math>\\epsilon</math> over the integration surface <math>\\partial \\Omega</math> . This approach allows us to approximate the left hand side of the Poisson equation above in first order as\n:<math>\n\\oint_{\\partial \\Omega} \\hat{n}(\\varepsilon \\nabla \\varphi)\n= \\frac{\\varphi_{i+1,j} - \\varphi_{i,j}}{h_i^x}\n\\left ( \\frac{h^y_j}{2} \\epsilon^x_{i,j} + \\frac{h^y_{j-1}}{2} \\varepsilon^x_{i,j-1} \\right )\n</math>\n\n:<math>\n{} - \\frac{\\varphi_{i,j} - \\varphi_{i-1,j}}{h_{i-1}^x}\n\\left ( \\frac{h^y_j}{2} \\epsilon^x_{i-1,j} + \\frac{h^y_{j-1}}{2} \\varepsilon^x_{i-1,j-1} \\right )\n</math>\n\n:<math>\n{} + \\frac{\\varphi_{i,j+1} - \\varphi_{i,j}}{h_{j}^y}\n\\left ( \\frac{h^x_i}{2} \\varepsilon^y_{i,j} + \\frac{h^x_{i-1}}{2} \\varepsilon^y_{i-1,j} \\right )\n</math>\n\n:<math>\n{} - \\frac{\\varphi_{i,j} - \\varphi_{i,j-1}}{h_{j-1}^y}\n\\left ( \\frac{h^x_i}{2} \\varepsilon^y_{i,j-1} + \\frac{h^x_{i-1}}{2} \\varepsilon^y_{i-1,j-1} \\right )\n</math>\n\nwhere <math>\\varepsilon^x</math> and <math>\\varepsilon^y</math> are the two components of the diagonal of the tensor <math>\\epsilon</math>.\nDiscretizing the right-hand side of the Poisson equation is fairly simple. <math>\\rho</math> is discretized on the same grid nodes, as it's been done for <math>\\varphi</math>.\n:<math>\n\\int_{\\Omega_i} \\rho = \\text{Volume}(\\Omega_i) \\rho_i\n</math>\n\n===Ion size===\nThe finite size of ions is accounted for in BioMOCA using pairwise [[Coulomb's law|repulsive forces]] derived from the 6–12 [[Lennard-Jones potential]]. A truncated-shifted form of the Lennard-Jones potential is used in the simulator to mimic ionic core repulsion. The modified form of the Lennard-Jones pairwise potential that retains only the repulsive component is given by\n\n:<math>\nU_{LJ}(r_{ij}) =\n\\begin{cases}\n4\\epsilon_{LJ} \\left (\\left (\\frac{\\sigma_{ij}}{r_{ij}}\\right )^{12} - \\left (\\frac{\\sigma_{ij}}{r_{ij}}\\right )^6 \\right ) + \\epsilon_{LJ}\n& r_{ij} < 2^{1/6} \\sigma_{ij} \\\\\n0 &  r_{ij} > 2^{1/6} \\sigma_{ij}\n\\end{cases}\n</math>\n\nHere, <math>\\epsilon_{LJ}</math> is the Lennard-Jones energy parameter and <math>\\sigma_{ij}=(\\sigma_i + \\sigma_j)/2</math> is the average of the individual Lennard-Jones distance parameters for particles ''i'' and ''j''. Using a truncated form of the potential is computationally efficient while preventing the ions from overlapping or coalescing, something that would be clearly unphysical.\n\n===Ion-protein interaction===\nAvailability of high-resolution X-ray crystallographic measurements of complete [[molecular structures]] provides information about the type and location of all atoms that forms the protein. In BioMOCA the protein atoms are modeled as static point charges embedded in a finite volume inaccessible to the ions and associated with a user-defined dielectric coefficient. Moreover, a number of force-field parameters are available that provide information about the charge and radii of atoms in different amino-acid groups. The conjunction of the molecular structure and force fields provide the coordinates, radii, and charge of each atom in the protein channel. BioMOCA uses such information in the standard PQR (Position-Charge-Radius) format to map the protein system onto a rectangular grid.\n\nIdeally, the steric interactions between protein atoms and the ions in the aqueous medium are to use a repulsive potential like [[Lennard-Jones]] to prevent ions from penetrating the protein. As this approach could add a significant load to the amount of calculations, a simpler approach is chosen that treats the protein surfaces as predetermined hard wall boundaries. Many recent open source molecular biology packages have built-in facilities that determine the volume accessible to ions in a protein system. The Adaptive Poisson Boltzmann Solver (APBS) scheme<ref name=\"Baker\">N.A. Baker, D. Sept, M.J. Holst, J.A. McCammon, IBM J. Res. Dev., 45, 427 (2001)</ref> has been incorporated to BioMOCA to obtain the accessible volume region and therefore partition the simulation domain into continuous regions.\n\nIons are deemed to have access to protein and lipid regions and if any point within the finite-size of ionic sphere crosses the protein or membrane boundary, a collision is assumed and the ion is reflected diffusively.\n\n===Ion-water interactions===\nAs a reduced particle approach, BioMOCA replaces the explicit water molecules with continuum background and handles the ion-water interactions using BTMC method, in which, appropriate scattering rates should be chosen. In other words, ion trajectories are randomly interrupted by scattering events that account for the ions’ [[Molecular diffusion|diffusive motion]] in water.<ref name=\"Straaten\"/> In between these scattering events, ions follow the Newtonian forces. The free flight times, ''T<sub>f</sub>'', are generated statistically from the total scattering rate according to\n\n:<math>\n-\\ln(r) = \\int^{T_f}_0 \\lambda (\\vec{p}(t)) \\, dt\n</math>\n\nwhere ''r'' is a random number uniformly distributed on the unit interval. <math>\\lambda</math>, a function of [[momentum]], is the total [[scattering]] rate for all [[collision]] mechanisms. At the end of each free flight, the ion’s velocity is reselected randomly from a Maxwellian distribution. As the correct scattering mechanism for ion-water interactions in nonbulk electrolyte solutions has yet to be developed, a position dependent scattering rate linked to the local diffusivity is used in our model. This dependency on position comes from the fact that water molecules can have different order of organization in different regions, which will affect the [[scattering rate]].\n\n===Position-dependent diffusivity===\nIt is widely accepted that the ions and water molecules do not have the same mobility or diffusivity in confined regions as in bulk.<ref name=\"Jacoboni\"/><ref name=\"Schutz\"/> In fact, it is more likely to have a lessening in the [[electron mobility|effective mobility]] of ions in ion channels.<ref name=\"Warshel\"/> In reduced particle methods where the channel water is assumed as implicit continuum background, a mean ion mobility is needed to reveal how ions could diffuse due to local [[electrostatic forces]] and random events. In Transport Monte Carlo simulations, the total scattering rate (<math>\\lambda</math>), is assumed to only result from ion-water interactions; it is related to ion diffusivity with the expression\n\n:<math>\\lambda = \\frac{kT}{mD}</math>\n\nwhere ''m'' is the mass of the ion and ''D'' is its diffusion constant. As the equation indicates, reduced diffusivity of ions inside the lumen of the channel renders to increased incidence of scattering events.\n\n===Hydration shells===\nIn addition to having a diffusive effect on [[ion transport]], water molecules also form hydration shells around individual ions due to their polar nature. The hydration shell not only shields the charge on ions from other ions but also modulates the ion radial distribution function causing the formation of peaks and troughs. The average minimum distance between two ions is increased as there is always at least one layer of water molecules present between them, acting as a physical deterrent preventing two ions from getting too close to each other, in a manner that is similar to the short-range repulsive component of the Lennard-Jones potential.\n\nThe theory of hydration shells is well developed in the physical chemistry literature however a simple model is required that captures the essential effects with as little computational overhead as possible. For this purpose the same pairwise potential discussed by Im and Roux<ref name=\"Im\">W. Im, B. Roux, J. Mol. Biol., 322, 851 (2002)</ref> is implemented to include the effect of hydration shells.\n\n:<math>\nU_{hy} = c_0 \\exp \\left (\\frac{c_1 - r}{c_2} \\right )\ncos(c_3(c_1 - r)\\pi ) + c_4 \\left (\\frac{c_1}{r} \\right )^6\n</math>\n\nThe coefficients ''c<sub>i</sub>'' were determined empirically for a 1 M [[KCl]] solution, using MD simulations to benchmark the ion radial distribution functions against Equilibrium [[Monte Carlo simulations]]. The effect of hydration shells was found to be important in simulations at higher salt concentrations where the conductance of many ion channels, porin among them, is observed to saturate as the salt concentration in the electrolyte baths is further increased. Earlier simulations that did not include a model of hydration shells did not reproduce the conductance saturation behavior. This suggests an additional repulsive potential acting to prevent ion crowding, and hence limiting the concentration of ions and current density in the confined space of the pore even at high bath salt concentration. When the repulsive potential was included moderate channel [[Electrical conductance|conductance]] was observed.\n\n==Conditions and methods==\n\n===Boundary conditions===\nThe electrical and physiological properties of ion channels are experimentally measured by inserting the channel into a lipid membrane separating two baths containing solutions of specific concentrations. A constant electrostatic bias is applied across the channel by immersing the electrodes in the two baths. Formulating [[boundary conditions]] that accurately represent these contact regions may require enormously large bath regions and is a challenging task. Beyond a Debye length from the membrane the electrostatic potential and ion densities do not vary appreciably. This assumption has been supported by the results of continuum results presented earlier.<ref name=\"Straaten37\">T. A. van der Straaten, J. M. Tang, U. Ravaioli, R. S. Eisenberg and N. Aluru, J. Comp. Elect. 2, 29 (2003)</ref> For typical salt concentrations used in ion channel simulations, the [[Debye length]] is of the order of 10 Å. Using the assumption, [[Dirichlet boundary conditions]] are imposed on the potential at the two domain boundary planes that are transverse to the channel, taking care that these planes are sufficiently far from the membrane.\n\nThe other problem in duplicating the experimental conditions is the problem of maintaining fixed charge density in the two baths. This problem is treated by maintaining the specified density in two buffer regions extending from the boundary plane toward the membrane. The number of ions needed to maintain the density in the two buffer regions is calculated at the start of the simulations. The count of the ions in these buffers is sampled throughout the simulation and an ion is injected whenever a deficit is observed. The initial velocity of the injected particle is decided according to Maxwellian distribution. It should be noted that the ions can leave the system only by exiting through the two Dirichlet boundary planes and an ion is not removed artificially from these buffer regions. The reflections from the [[Neumann boundary condition|Neumann boundary planes]] are treated as [[Reflection seismology|elastic reflections]].\n\n===Multi-grids and grid focusing method===\n{{inappropriate person|section|we|date=April 2011}}\nIn all most any of the methods in simulation of ion channels, the major computational cost comes from the calculation of electrostatic forces acting on the ions. In continuum models, for instance, where [[Charge density|ionic density]] exist rather than explicit ions, the electrostatic potential is calculated in a self-consistent manner by solving the Poisson equation. In MD simulations, on the other hand, the [[electrostatic forces]] acting on the particles are calculated by explicit evaluation of the Coulombic force term, often splitting the short-range and long-range electrostatic forces so they could be computed with different methods. In our model as a reduced particle method, the longrange electrostatic forces are evaluated by solving the [[Poisson equation]] and augmenting the forces so obtained with a short-range component. By solving the Poisson equation it is possible to self-consistently include the forces arising from the bias to the system, while this is a difficult issue to be addressed in MD simulations.\n\nCurrently there are two Poisson solvers implemented in BioMOCA based on the [[finite difference method]]. One uses the pre-conditioned [[conjugate gradient method|Conjugate Gradient scheme]] (pCG) and is used by default. The later is borrowed from an APBS solver, which uses a V-multi-grid scheme. Other than the numerical approach to solve the Poisson equation, the main difference between the two solvers is on how they address the [[permittivity]] in the system. In the first solver, a dielectric value is assigned to each cell in the grid, while in the APBS solver the dielectric coefficients are defined on the grid nodes. As discussed earlier box integration method is used in the pCG solver, which allows us to treat the Poisson equation in the most accurate way. Even though a full multigrid solver based on box-integration method has been under development, there is a neat way to reuse the already exiting code and treat the ion channel systems.\n\nIon channel simulations require the presence of large bath regions for accurate treatment of screening.<ref name=\"Straaten\"/> There being of such bath regions make the mesh domain of Poisson equation large and leads to either a large number of grid points with fine mesh resolution or a small number of grid points with very coarse discretization. From bulk simulations a coarse mesh is sufficient for describing the baths using the P<sup>3</sup>M scheme. However, a fine resolution is required in the channel domain because of the highly charged nature of these regions and the presence of spatially varying dielectric regions. Besides the ultimate interest is to study the channel behavior in terms of ion [[Semipermeable membrane|permeability]], selectivity, gating, density, etc.… In other words, it is better off to put more computational resources in the channel region, and bare minimum in the baths to reduce the overall computational cost and speed up our simulations from weeks to perhaps days instead.\nA scheme based on the grid focusing method has been developed that makes it possible to satisfy the requirement of large bath region and a fine grid resolution in channel at the same time in a computationally effective way. This methodology also allows us to have multiple fine mesh domains, which may be needed to describe multiple pore channels like OmpF porin, or an array of ion channels sharing the same bath regions or even having yet finer meshes inside a fine mesh for relatively large channels with narrow ion passages like [[Nicotinic acetylcholine receptor|Nicotine receptor channel]].<ref name=\"Hai-Long\">Hai-Long Wang, Reza Toghraee, D. Papke, X. L. Cheng, J. A. McCammons, U. Ravaioli, and S. M. Sine, Biophysical Journal, 96, 3582, (2009)</ref>\n\nThe first grid is coarse mesh spanning the entire problem domain including the bath regions and the channel region. The second grid (and so on for any other grids, 3rd, 4th, etc.) is a relatively much finer mesh that spans a sub-domain of the system containing the region that requires fine resolution like the channel pore. The Poisson equation is first solved on the coarse mesh with all the Dirichlet and Neumann boundary conditions, taking into account the applied bias. Next the [[boundary conditions]] for the secondary meshes are obtained by interpolating from the first or previous solutions of the Poisson equation. The Poisson equation is solved again for the finer meshes using the new boundary conditions. In this way, electrostatic fields with different mesh discretization for different regions can be generated.\n\n===EMF and DBF===\nThe [[Electromotive force|electro-motive-force]] (EMF) is the measurement of the energy needed for a charged particle like ion to cross the ion channel embedded in a membrane. Part of this potential energy barrier is due the interaction between the crossing ion and the permanent/partial charges on the protein residues. The other part comes from the induced dipoles in the protein/membrane dielectric medium, and is referred as dielectric-boundary-force (DBF). To compute the DBF alone, one may turn off all the static charges on the protein residues and drag the ion through the pore and compute the energy barrier using\n:<math>\nP_{DBF} = \\int -d \\hat{z}. \\vec{E}\n</math>\n\nIt is important to note that EMF or DBF measurements are just qualitative measurements, as an ion does not necessarily cross the channel through the center of its lumen in a straight line and it is often accompanied by other ions moving in the same or opposite directions, which dramatically changes the dynamics of the system. Moreover, unlike steered MD calculations where the protein residues dynamically reposition themselves as an ion or ions are bouncing across the channel, in our EMF or DBF calculations protein is modeled as a static continuum, which further affects the energy calculations in a more quantitative way. Another issue that additionally impacts the measurements is absence of water hydration molecules, which move with the ion and shield part of its charge. Having said all of above, still computing EMF or DBF is valuable to address channel selectivity or gating. Computing either of these two energy barriers is available as an option in BioMOCA.\n\n===Visualization using VMD===\n[[File:Visual Molecular Dynamics visualization.jpg|thumb|VMD visualization of Gramicidin 1MAG molecule along with the structure generated by BioMOCA, where green represents protein, red addresses the membrane (i.e. lipid), and purple is the channel and left and right baths]]\n[[Visual Molecular Dynamics|VMD]]<ref name=\"ks\">http://www.ks.uiuc.edu/Research/vmd</ref> was equipped with the option of loading BioMOCA structures. This is a very useful feature as one could load both the protein  structure (i.e. PDB or PQR file) along with the structures generated by BioMOCA to make comparisons. Figure at the right shows how BioMOCA has generated a structure for [[Gramicidin|Gramicidin channel]] with a membrane wrapped around it. Furthermore, BioMOCA also dumps the ion trajectories in standard formats so they could be later loaded to molecular visualization tools such as VMD and watched frame by frame in a movie format.\n\n===Recording trajectories in binary===\nOther than counting the number of ions crossing the channel, sometimes it is desirable to study their behavior at different regions of the channel. Such examples would be the average occupancy of ions or their average moving velocity inside the channel or a nanopore. BioMOCA has been equipped with the option of dumping every ions position, average and instantaneous velocities, [[potential energy|potential]] and [[kinetic energy|kinetic energies]], average and instantaneous displacements and other info at every step (or few steps) of the simulations in ASCII format, so such trajectory information could be studied later on to gather further statistics. From a technical point of view however, dumping such information for tens of ions, even at every few hundreds of time steps, could slow down the simulations and end up with huge files accumulating to tens of gigabytes. Loading such files later on from disk storage is also a very time consuming and computationally inefficient procedure. Over and above that, recoding the numerical information in [[ASCII]] format does not hold its machine precision and has loss of accuracy.\n\nSolving such problems is actually an easy task and it is simply to avoid using [[ASCII]] format and use binary format instead. Not only it preserves the machine accuracy but also writing and reading to file system is a lot faster. The computational overhead to dump the trajectories becomes negligible and the trajectory files become about two orders of magnitude smaller in size. The downside might be that programming and decoding the data could become very tricky, but once it’s done correctly and with care, the advantages of using binary format are well worth the extra effort. BioMOCA is now equipped with the tools to record the trajectory information in [[binary format]].\n\n==See also==\n*[[Monte Carlo method]]\n*[[Biology]]\n*[[Computational biology]]\n\n== References ==\n<!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using<ref></ref> tags which will then appear here automatically -->\n{{Reflist}}\n\n[[Category:University of Illinois at Urbana–Champaign]]\n[[Category:Monte Carlo methods]]\n[[Category:Statistical mechanics]]\n[[Category:Computational physics]]\n[[Category:Randomized algorithms]]"
    },
    {
      "title": "Control variates",
      "url": "https://en.wikipedia.org/wiki/Control_variates",
      "text": "The '''control variates''' method is a [[variance reduction]] technique used in [[Monte Carlo methods]]. It exploits information about the errors in estimates of known quantities to reduce the error of an estimate of an unknown quantity.<ref name=\"lemieux17\">{{cite journal|last1= Lemieux |first1=C.|title=Control Variates|journal= Wiley StatsRef: Statistics Reference Online|date=2017|pages=1--8|doi= 10.1002/9781118445112.stat07947 }}</ref>\n<ref>Glasserman, P. (2004). ''Monte Carlo Methods in Financial Engineering''. New York: Springer. {{ISBN|0-387-00451-3}} (p. 185)</ref> <ref name=\"varred17\">{{cite journal|last1=Botev|first1=Z.|last2=Ridder|first2=A.|title=Variance Reduction|journal= Wiley StatsRef: Statistics Reference Online|date=2017|pages=1--6|doi=10.1002/9781118445112.stat07975}}</ref>\n\n==Underlying principle==\nLet the unknown [[Parameter#Statistics and econometrics|parameter]] of interest be <math>\\mu</math>, and assume we have a [[statistic]] <math>m</math> such that the [[expected value]] of ''m'' is &mu;: <math>\\mathbb{E}\\left[m\\right]=\\mu</math>, i.e. ''m'' is an [[bias of an estimator|unbiased estimator]] for &mu;. Suppose we calculate another statistic <math>t</math> such that <math>\\mathbb{E}\\left[t\\right]=\\tau</math> is a known value. Then\n\n:<math>m^\\star = m + c\\left(t-\\tau\\right) \\, </math>\n\nis also an unbiased estimator for <math>\\mu</math> for any choice of the coefficient <math>c</math>. \nThe [[variance]] of the resulting estimator <math>m^{\\star}</math> is\n\n:<math>\\textrm{Var}\\left(m^{\\star}\\right)=\\textrm{Var}\\left(m\\right) + c^2\\,\\textrm{Var}\\left(t\\right) + 2c\\,\\textrm{Cov}\\left(m,t\\right).</math>\n\nIt can be shown that choosing the optimal coefficient\n\n:<math>c^\\star = - \\frac{\\textrm{Cov}\\left(m,t\\right)}{\\textrm{Var}\\left(t\\right)} </math>\n\nminimizes the variance of <math>m^{\\star}</math>, and that with this choice,\n\n:<math>\\begin{align}\n\\textrm{Var}\\left(m^{\\star}\\right) & =\\textrm{Var}\\left(m\\right) - \\frac{\\left[\\textrm{Cov}\\left(m,t\\right)\\right]^2}{\\textrm{Var}\\left(t\\right)} \\\\\n& = \\left(1-\\rho_{m,t}^2\\right)\\textrm{Var}\\left(m\\right)\n\\end{align} </math>\n\nwhere\n        \n:<math>\\rho_{m,t}=\\textrm{Corr}\\left(m,t\\right) \\, </math>\n\nis the [[Pearson product-moment correlation coefficient|correlation coefficient]] of <math>m</math> and <math>t</math>. The greater the value of <math>\\vert\\rho_{m,t}\\vert</math>, the greater the [[variance reduction]] achieved.\n\nIn the case that <math>\\textrm{Cov}\\left(m,t\\right)</math>, <math>\\textrm{Var}\\left(t\\right)</math>, and/or <math>\\rho_{m,t}\\;</math> are unknown, they can be estimated across the Monte Carlo replicates. This is equivalent to solving a certain [[least squares]] system; therefore this technique is also known as '''regression sampling'''.\n\nWhen the expectation of the control variable, <math>\\mathbb{E}\\left[t\\right]=\\tau</math>, is not known analytically, it is still possible to increase the precision in estimating <math>\\mu</math> (for a given fixed simulation budget), provided that the two conditions are met: 1) evaluating <math>t</math> is significantly cheaper than computing <math>m</math>; 2) the magnitude of the correlation coefficient <math>|\\rho_{m,t}| </math> is close to unity. <ref name=\"varred17\"/>\n\n==Example==\n\nWe would like to estimate\n:<math>I = \\int_0^1 \\frac{1}{1+x} \\, \\mathrm{d}x</math>\nusing [[Monte Carlo integration]]. This integral is the expected value of  <math>f(U)</math>,  where\n:<math>f(U) = \\frac{1}{1+U}</math>\nand ''U'' follows a [[uniform distribution (continuous)|uniform distribution]]&nbsp;[0,&nbsp;1].\nUsing a sample of size ''n'' denote the points in the sample as <math>u_1, \\cdots, u_n</math>. Then the estimate is given by\n:<math>I \\approx \\frac{1}{n} \\sum_i f(u_i). </math>\n\nNow we introduce <math>g(U) = 1+U</math> as a control variate with a known expected value <math>\\mathbb{E}\\left[g\\left(U\\right)\\right]=\\int_0^1 (1+x) \\, \\mathrm{d}x=\\tfrac{3}{2} </math> and combine the two into a new estimate\n:<math>I \\approx \\frac{1}{n} \\sum_i f(u_i)+c\\left(\\frac{1}{n}\\sum_i g(u_i) -3/2\\right). </math>\n\nUsing <math>n=1500</math> realizations and an estimated optimal coefficient <math> c^\\star \\approx 0.4773 </math> we obtain the following results\n\n{| class=\"wikitable\"\n|\n| align=\"right\" | '''Estimate'''\n| align=\"right\" | '''Variance'''\n|-\n| ''Classical estimate''\n| align=\"right\" | 0.69475\n| align=\"right\" | 0.01947\n|-\n| ''Control variates ''\n| align=\"right\" | 0.69295\n| align=\"right\" | 0.00060\n|}\n\nThe variance was significantly reduced after using the control variates technique. (The exact result is   <math>I=\\ln 2 \\approx 0.69314718</math>.)\n\n==See also==\n:* [[Antithetic variates]]\n:* [[Importance sampling]]\n\n{{refimprove|date=August 2011}}\n\n==Notes==\n<references/>\n\n==References==\n* Ross, Sheldon M. (2002) ''Simulation'' 3rd edition {{ISBN|978-0-12-598053-1}}\n* Averill M. Law & W. David Kelton (2000), ''Simulation Modeling and Analysis'', 3rd edition. {{ISBN|0-07-116537-1}}\n* S. P. Meyn (2007) ''Control Techniques for Complex Networks'', Cambridge University Press. {{ISBN|978-0-521-88441-9}}.  [https://web.archive.org/web/20100619011046/https://netfiles.uiuc.edu/meyn/www/spm_files/CTCN/CTCN.html  Downloadable draft] (Section 11.4: Control variates and shadow functions)\n\n[[Category:Monte Carlo methods]]\n[[Category:Statistical randomness]]\n[[Category:Computational statistics]]\n[[Category:Variance reduction]]"
    },
    {
      "title": "Coupling from the past",
      "url": "https://en.wikipedia.org/wiki/Coupling_from_the_past",
      "text": "Among [[Markov chain Monte Carlo]] (MCMC) [[algorithms]], '''coupling from the past''' is a method for [[sampling (statistics)|sampling]] from the stationary distribution of a [[Markov chain]]. Contrary to many MCMC algorithms, coupling from the past gives in principle a perfect sample from the [[stationary distribution]]. It was invented by [[James Propp]] and [[David Bruce Wilson|David Wilson]] in 1996.\n\n==The basic idea==\nConsider a finite state [[Markov chain|irreducible]] [[Markov chain|aperiodic]] Markov chain <math>M</math> with state space <math>S</math> and (unique) stationary distribution <math>\\pi</math> (<math>\\pi</math> is a probability vector). Suppose that we come up with a probability distribution <math>\\mu</math> on the set of maps <math>f:S\\to S</math> with the property that for every fixed <math>s\\in S</math>, its image <math>f(s)</math> is distributed according to the transition probability of <math>M</math> from state <math>s</math>. An example of such a probability distribution is the one where <math>f(s)</math> is [[independent (probability)|independent]] from <math>f(s')</math> whenever <math>s\\ne s'</math>, but it is often worthwhile to consider other distributions. Now let <math>f_j</math> for <math>j\\in\\mathbb Z</math> be independent samples from <math>\\mu</math>.\n\nSuppose that <math>x</math> is chosen randomly according to <math>\\pi</math> and is independent from the sequence <math>f_j</math>. (We do not worry for now where this <math>x</math> is coming from.) Then <math>f_{-1}(x)</math> is also distributed according to <math>\\pi</math>, because <math>\\pi</math> is <math>M</math>-stationary and our assumption on the law of <math>f</math>. Define \n:<math>F_j:= f_{-1}\\circ f_{-2}\\circ\\cdots\\circ f_{-j}.</math>\nThen it follows by induction that <math>F_j(x)</math> is also distributed according to <math>\\pi</math> for every <math>j\\in\\mathbb{N}</math>. Now here is the main point. It may happen that for some <math>n\\in\\mathbb{N}</math> the image of the map <math>F_n</math> is a single element of <math>S</math>.\nIn other words, <math>F_n(x)=F_n(y)</math> for each <math>y\\in S</math>. Therefore, we do not need to have access to <math>x</math> in order to compute <math>F_n(x)</math>. The algorithm then involves finding some <math>n\\in \\mathbb N</math> such that <math>F_n(S)</math> is a [[singleton (mathematics)|singleton]], and outputting the element of that singleton. The design of a good distribution <math>\\mu</math> for which the task of finding such an <math>n</math> and computing <math>F_n</math> is not too costly is not always obvious, but has been accomplished successfully in several important instances{{Citation needed|date=May 2008}}.\n\n==The monotone case==\nThere is a special class of Markov chains in which there are particularly good choices\nfor <math>\\mu</math> and a tool for determining if <math>|F_n(S)|=1</math>. (Here <math>|\\cdot|</math> denotes [[cardinal number|cardinality]].) Suppose that <math>S</math> is a [[partially ordered set]] with order <math>\\le</math>, which has a unique minimal element <math>s_0</math> and a unique maximal element <math>s_1</math>; that is, every <math>s\\in S</math> satisfies <math>s_0\\le s\\le s_1</math>. Also, suppose that <math>\\mu</math> may be chosen to be supported on the set of [[monotone function|monotone]] maps <math>f:S\\to S</math>. Then it is easy to see that <math>|F_n(S)|=1</math> if and only if <math>F_n(s_0)=F_n(s_1)</math>, since <math>F_n</math> is monotone. Thus, checking this becomes rather easy. The algorithm can proceed by choosing <math>n:=n_0</math> for some constant <math>n_0</math>, sampling the maps <math>f_{-1},\\dots,f_{-n}</math>, and outputting <math>F_n(s_0)</math> if <math>F_n(s_0)=F_n(s_1)</math>. If <math>F_n(s_0)\\ne F_n(s_1)</math> the algorithm proceeds by doubling <math>n</math> and repeating as necessary until an output is obtained. (But the algorithm does not resample the maps <math>f_{-j}</math> which were already sampled; it uses the previously sampled maps when needed.)\n\n== References ==\n*{{cite conference |mode=cs2 |last1=Propp |first1=James Gary |last2=Wilson |first2=David Bruce |book-title=Proceedings of the Seventh International Conference on Random Structures and Algorithms (Atlanta, GA, 1995) |mr=1611693 |year=1996 |chapter=Exact sampling with coupled Markov chains and applications to statistical mechanics |pages=223–252}}\n*{{Citation | last1=Propp | first1=James | last2=Wilson | first2=David | title=Microsurveys in discrete probability (Princeton, NJ, 1997) | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=DIMACS Ser. Discrete Math. Theoret. Comput. Sci. | mr=1630414 | year=1998 | volume=41 | chapter=Coupling from the past: a user's guide | pages=181–192 |chapter-url=https://pdfs.semanticscholar.org/622e/a9c9c665002670ff26119d1aad5c3c5e0be8.pdf}}\n\n[[Category:Monte Carlo methods]]\n[[Category:Markov chain Monte Carlo]]"
    },
    {
      "title": "Demon algorithm",
      "url": "https://en.wikipedia.org/wiki/Demon_algorithm",
      "text": "The '''demon algorithm''' is a [[Monte Carlo method]] for efficiently sampling members of a [[microcanonical ensemble]] with a given energy. An additional degree of freedom, called 'the demon', is added to the system and is able to store and provide energy. If a drawn microscopic state has lower energy than the original state, the excess energy is transferred to the demon. For a sampled state that has higher energy than desired, the demon provides the missing energy if it is available. The demon can not have negative energy and it does not interact with the particles beyond exchanging energy. Note that the additional degree of freedom of the demon does not alter a system with many particles significantly on a macroscopic level.\n\n== Motivation ==\nIn [[thermodynamical system]]s, equal macroscopic properties (e. g. temperature) can result from different microscopic properties (e. g. velocities of individual particles). Computer simulations of the full equations of motion for every individual particle to simulate microscopic properties is computationally very expensive. [[Monte Carlo methods]] can overcome this problem by sampling microscopic states according to stochastic rules instead of modeling the complete microphysics.\n\nThe [[microcanonical ensemble]] is a collection of microscopic states which have fixed energy, volume and number of particles. In an enclosed system with a certain number of particles, energy is the only macroscopic variable affected by the microphysics. The Monte Carlo simulation of a microcanonical ensemble thus requires sampling different microscopic states with the same energy. When the number of possible microscopic states of thermodynamical systems is very large, it is inefficient to randomly draw a state from all possible states and accept it for the simulation if it has the right energy, since many drawn states would be rejected.\n\n== The demon algorithm ==\n\nThe full procedure can be summarized by the following steps:\n\n1. Perform a random change in the state of a randomly chosen particle (e. g. change velocity or position).\n\n2. Calculate the change in energy <math>\\Delta E</math> of the thermal system.\n\n3. Negative <math>\\Delta E</math>, i. e. excess energy, is given to the demon by adding <math>|\\Delta E|</math> to the demon. This case (<math>\\Delta E < 0</math>) is always accepted.\n\n4. The demon provides positive <math>\\Delta E</math> to keep the total energy constant only if it has sufficient energy, i. e. <math>E_d > \\Delta E</math>. In this case the change is accepted, otherwise the randomly chosen change in velocity is rejected and the algorithm is restarted from the original microscopic state.\n\n5. If the change is accepted, repeat the algorithm for the new configuration.\n\nSince energy fluctuations per degree of freedom are only of order 1/''N'', the presence of the demon has little effect on macroscopic properties of systems with high numbers of particles. After many iterations of the algorithm, the interplay of demon and random energy changes equilibrates the system. Assuming that a particular system approaches all possible states over very long times ([[ergodic theory|quasi-ergodicity]]), the resulting Monte Carlo dynamics realistically sample microscopic states that correspond to the given energy value. This is only true if macroscopic quantities are stable over many Monte Carlo steps, i. e. if the system is at equilibrium.\n\n== See also ==\n\n* [[Monte Carlo methods]]\n* [[Metropolis algorithm]] to sample microscopic states at a fixed temperature\n\n{{no footnotes|date=January 2011}}\n\n== References ==\n\n* {{cite book\n|  author = Harvey Gould and Jan Tobochnik and Wolfgang Christian\n|  title = An Introduction to Computer Simulation Methods: Applications to Physical Systems (3rd Edition)\n|  publisher = Addison Wesley\n|  year = 2006\n|  isbn = 978-0-8053-7758-3\n|  chapter= Chapter 15: Monte Carlo Simulations of Thermal Systems\n}}\n* {{cite journal\n| title = Microcanonical Monte Carlo Simulation\n|  author = Creutz, Michael\n|  journal = Phys. Rev. Lett.\n|  volume = 50\n|  issue = 19\n|  pages = 1411–1414\n|date=May 1983\n|  doi = 10.1103/PhysRevLett.50.1411\n|  publisher = American Physical Society\n| bibcode=1983PhRvL..50.1411C\n}}\n\n[[Category:Monte Carlo methods]]\n[[Category:Computational physics]]\n[[Category:Sampling techniques]]"
    },
    {
      "title": "Diagrammatic Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Diagrammatic_Monte_Carlo",
      "text": "{{Multiple issues|\n{{Orphan|date=May 2019}}\n{{context|date=November 2018}}\n}}\n\nIn mathematical physics, the '''diagrammatic Monte Carlo method''' is based on  stochastic summation of [[Feynman diagram]]s with controllable error bars.<ref>{{Cite journal|last=Van Houcke|first=K.|last2=Werner|first2=F.|last3=Kozik|first3=E.|last4=Prokof’ev|first4=N.|last5=Svistunov|first5=B.|last6=Ku|first6=M. J. H.|last7=Sommer|first7=A. T.|last8=Cheuk|first8=L. W.|last9=Schirotzek|first9=A.|date=2012-03-18|title=Feynman diagrams versus Fermi-gas Feynman emulator|journal=Nature Physics|language=En|volume=8|issue=5|pages=366–370|doi=10.1038/nphys2273|issn=1745-2473}}</ref><ref>{{Cite journal|last=Prokof’ev|first=Nikolay|last2=Svistunov|first2=Boris|date=2007-12-18|title=Bold Diagrammatic Monte Carlo Technique: When the Sign Problem Is Welcome|journal=Physical Review Letters|volume=99|issue=25|pages=250201|doi=10.1103/PhysRevLett.99.250201|pmid=18233498|arxiv=cond-mat/0702555}}</ref> It was developed by [[Boris Svistunov]] and [[Nikolay Prokof'ev]]. It was proposed as a generic approach to overcome the [[numerical sign problem]] that  precludes simulations of many-body fermionic problems.<ref>{{Cite journal |last=Rossi |first=R. |last2=Prokof'ev |first2=N. |last3=Svistunov |first3=B. |last4=Van Houcke |first4=K. |last5=Werner |first5=F. |date=2017-04-01 |title=Polynomial complexity despite the fermionic sign |journal=EPL (Europhysics Letters) |volume=118 |issue=1 |pages=10004 |doi=10.1209/0295-5075/118/10004 |issn=0295-5075|arxiv=1703.10141 }}</ref>\n\n==References==\n{{Reflist}}\n\n[[Category:Monte Carlo methods]]\n\n\n{{math-stub}}"
    },
    {
      "title": "Direct simulation Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Direct_simulation_Monte_Carlo",
      "text": "'''Direct Simulation Monte Carlo''' ('''DSMC''') method uses probabilistic ([[Monte Carlo method|Monte Carlo]]) [[simulation]] to solve the [[Boltzmann equation]] for finite [[Knudsen number]]  [[fluid]] flows.\n\nThe DSMC method was proposed by Prof. Graeme Bird,<ref>{{cite journal |doi=10.1063/1.1710976 |title=Approach to Translational Equilibrium in a Rigid Sphere Gas |journal=Physics of Fluids |volume=6 |issue=10 |pages=1518 |year=1963 |last1=Bird |first1=G. A }}</ref><ref>G. A. Bird, ''Molecular Gas Dynamics'', Clarendon, Oxford (1976){{pn|date=March 2018}}</ref><ref>G. A. Bird, ''Molecular Gas Dynamics and the Direct Simulation of Gas Flows'', Claredon, Oxford (1994){{pn|date=March 2018}}</ref> Emeritus Professor of Aeronautics, University of Sydney. DSMC is a numerical method for modeling rarefied gas flows, in which the [[mean free path]] of a molecule is of the same order (or greater) than a representative physical length scale (i.e. the [[Knudsen number]] Kn is greater than 1).  In supersonic and hypersonic flows rarefaction is characterized by Tsien's parameter, which is equivalent to the product of Knudsen number and Mach number (KnM) or M<math>^2</math>/Re, where Re is the Reynolds number.<ref>{{cite journal |doi=10.2514/8.11476 |title=Superaerodynamics, Mechanics of Rarefied Gases |journal=Journal of the Aeronautical Sciences |volume=13 |issue=12 |pages=653–64 |year=1946 }}</ref><ref>M. N. Macrossan, \n[http://espace.library.uq.edu.au/view.php?pid=UQ:7959 'Scaling Parameters for Hypersonic Flow: Correlation of Sphere Drag Data']. In: M. S. Ivanov and A. K. Rebrov,  ''25th International Symposium on Rarefied Gas Dynamics'', Siberian Division of the Russian Academy of Sciences, p.759 (2007).</ref> In these rarefied flows, the [[Navier-Stokes equations]] can be inaccurate. The DSMC method has been extended to model continuum flows (Kn < 1) and the results can be compared with Navier Stokes solutions.\n\nThe DSMC method models fluid flows using simulation [[molecule]]s which represent a large number of real molecules in a probabilistic simulation to solve the [[Boltzmann equation]].  Molecules are moved through a simulation of physical space in a realistic manner that is directly coupled to physical time such that unsteady flow characteristics can be modeled.  Intermolecular collisions and molecule-surface collisions are calculated using probabilistic, [[phenomenological model]]s.  Common molecular models include the Hard Sphere model, the Variable Hard Sphere (VHS) model, and the Variable Soft Sphere (VSS) model.  The fundamental assumption of the DSMC method is that the molecular movement and collision phases can be decoupled over time periods that are smaller than the mean collision time. Various collision models are presented in.<ref>{{cite journal |doi=10.1016/j.physrep.2016.08.002 |title= Collision partner selection schemes in DSMC: From micro/nano flows to hypersonic flows |journal=Physics Reports |volume=656 |issue=1 |pages=1–38 |year=2016 |last1=Roohi |first1=E. |last2=Stefanov |first2=S. }}</ref> \n\nCurrently, the DSMC method has been applied to the solution of flows ranging from estimation of the [[Space Shuttle]] re-entry aerodynamics, to the modeling micro-electro-mechanical systems ([[Microelectromechanical systems|MEMS]]).\n\n==DSMC Software==\nMultiple implementations of the DSMC method exist:\n* '''DS1V''', '''DS2V''' and '''DS3V''' are the original DSMC programs written by Prof. Bird. These programs have a visual user interface that can be used for configuration and post processing.\n* '''dsmcFoam''' is a DSMC solver for 2D and 3D flows. dsmcFoam is part of the open source CFD package [[OpenFOAM]].<ref>{{cite journal |doi=10.1016/j.compfluid.2010.07.014 |title=An open source, parallel DSMC code for rarefied gas flows in arbitrary geometries |journal=Computers & Fluids |volume=39 |issue=10 |pages=2078–89 |year=2010 |last1=Scanlon |first1=T.J |last2=Roohi |first2=E |last3=White |first3=C |last4=Darbandi |first4=M |last5=Reese |first5=J.M }}</ref>\n* '''dsmcFoam+''' is the updated release of dsmcFoam. For further information, please go to the reference article.<ref>{{cite journal |doi=10.1016/j.cpc.2017.09.030 |title=dsmcFoam+: An OpenFOAM based direct simulation Monte Carlo solver |journal=Computer Physics Communications |volume=224 |pages=22-43 |year=2010 |last1=White |first1=C. |last2=Borg |first2=M.K. |last3=Scanlon |first3=T.J. |last4=Longshaw |first4=S.M. |last5=John |first5=B |last6=Emerson |first6=D.R. |last7=Reese |first7=J.M.}}</ref>\n* '''MONACO''' is a DSMC solver devised at [[Cornell University]] by Dr. Stefan Dietrich and Prof. Iain Boyd's [[Nonequilibrium Gas and Plasma Dynamics Laboratory]] at the [[University of Michigan]].<ref>{{cite journal |doi=10.1006/jcph.1996.0141 |title=Scalar and Parallel Optimized Implementation of the Direct Simulation Monte Carlo Method |journal=Journal of Computational Physics |volume=126 |issue=2 |pages=328–42 |year=1996 |last1=Dietrich |first1=Stefan |last2=Boyd |first2=Iain D }}</ref>\n* '''PI-DSMC''' is a commercial DSMC software package for 2D and 3D flows.\n* '''SMILE''' ('''S'''tatistical '''M'''odeling '''i'''n '''L'''ow-density '''E'''nvironment) is a general purpose 2D/3D parallel DSMC software system developed since 1998 by Computational Aerodynamics Laboratory (L7) at the  Khristianovich Institute of Theoretical and Applied Mechanics, Siberian Division of the Russian Academy of Sciences. SMILE has been the principal aerodynamic analysis tool for high-altitude stages of reentry of the [[Mir Space Station]] as well as many other Russian and European space vehicle projects.\n* '''DAC''' is a general purpose DSMC code developed by NASA at the Johnson Space and Langley Research Centers. It employs a two level mesh using Cartesian volumes and employs the cut cell algorithm developed by Prof. Tom Schwartzentruber's group at the [[University of Minnesota]]. Both scalar and parallel versions exist with the parallel version using the Message Passing Interface (MPI) and domain decomposition. DAC was designed to handle difficult problems such as complex geometries (for example, the International Space Station) and the plume impingement which may occur during the rendezvous of two spacecraft. DAC is classified as ITAR and distribution is restricted to United States users. Requests for DAC should be directed to the Technology Transfer Office at the NASA Johnson Space Center.\n*'''MAP''' ('''M'''ultiphysics '''A'''lgorithm with '''P'''articles) is another general purpose DSMC code developed by NASA at the Langley Research Center.  It is an Octree-based 0D/2D/Axi/3D implementation of DSMC derived from DAC with emphasis placed on the high energy physics encountered upon re-entry flows.  The cut cell algorithm used in MAP is derived from the algorithm used in SPARTA, which is based on the work done by Prof. Schwartzentruber's group at the [[University of Minnesota]].  MAP is classified as EAR99 and is freely available to US citizens and foreign entities upon request at [[software.nasa.gov]].\n* '''MGDS''' is a fully 3D DSMC solver incorporating three level adaptive mesh refinement and a cut cell algorithm developed by Prof. Tom Schwartzentruber's group at the [[University of Minnesota]].\n* '''Molflow''' is a 3D DSMC simulator currently developed at [[CERN]] for the simulation of free molecular flow (vacuum) systems.\n* '''SAMADII/SCiV''' ('''S'''tatistical '''C'''ontact '''i'''n '''V'''acuum) is general purpose 3D DSMC software system based on '''multi-GPUs'''.\n* '''HAP''' ('''H'''ypersonic '''A'''erothermodynamics '''P'''article code) is a DSMC code developed at the U.S. [[Air Force Research Laboratory]] for high speed flight and space applications.\n* '''SPARTA''' ('''S'''tochastic '''PA'''rallel '''R'''arefied-gas '''T'''ime-accurate '''A'''nalyzer), an [[Open Source]] 2 & 3D DSMC simulator optimized for parallel computing and developed at [[Sandia National Laboratories]]. Written in [[C++]], '''SPARTA''' is designed to be easy to modify or extend with new functionality. Code is distributed under [[GPL]], and available from the [http://sparta.sandia.gov/ project website]\n* '''PICLas''' is a parallel, three-dimensional [[Particle-in-cell|PIC]]-DSMC solver developed cooperatively by the [http://www.irs.uni-stuttgart.de/forschung/numerische_modellierung_und_simulation/PICLas.en.html Institute of Space Systems] and [https://nrg.iag.uni-stuttgart.de/ Institute of Aerodynamics and Gas Dynamics] at the [[University of Stuttgart]].<ref>{{cite journal |doi=10.1016/j.crme.2014.07.005 |title=Coupled Particle-In-Cell and Direct Simulation Monte Carlo method for simulating reactive plasma flows |journal=Comptes Rendus Mécanique |volume=342 |issue=10–11 |pages=662–70 |year=2014 |last1=Munz |first1=Claus-Dieter |last2=Auweter-Kurtz |first2=Monika |last3=Fasoulas |first3=Stefanos |last4=Mirza |first4=Asim |last5=Ortwein |first5=Philip |last6=Pfeiffer |first6=Marcel |last7=Stindl |first7=Torsten }}</ref> It is a flexible simulation suite for the computation of reactive plasma flows, where the [[Particle-in-cell|PIC]], DSMC and several other particle methods can be coupled or utilized separately. Application areas include the simulation of [[Electrically powered spacecraft propulsion|electric propulsion systems]], [[Atmospheric entry|atmospheric entry manoeuvres]], [[Gyrotron|gyrotons]], [[Traveling-wave tube|travelling wave tubes]] and laser-plasma interaction. The [[Free and open-source software|free and open-source code]] is available under the GNU General Public License v3.0 at [https://github.com/piclas-framework/piclas GitHub].\n*'''ultraSPARTS''' ('''ultra'''-fast '''S'''tatistical '''PART'''icle '''S'''imulation Package), owned by [http://www.plasmati.tw/ Plasma Taiwan Innovative Corp.], is a commercial general-purpose DSMC package, evolved from PDSC++ that was developed by Prof. Jong-Shinn Wu's [http://www.me.nctu.edu.tw/appl/ APPL] (Aerothermal & Plasma Physics Laboratory), [[National Chiao Tung University]], Taiwan. It is written in [[C++]] with important features including 2D/2D-axisymmetric/3D hybrid unstructured grid with parallel computing (MPI) using dynamic domain decomposition. A truly free of particle cloning technique is developed for handling 2D-axisymmetric flow. It has been applied to model many important science and engineering problems such as hypersonic non-reacting and reacting flow, turbo-vacuum pump flow, materials processing chamber design, large vacuum chamber design, materials processing (e.g., OLED, CIG deposition, PVD), RCS plume impingement of a spacecraft, and recently comet gas/dust plumes, among others. It also has been successfully hybridized with an unstructured-grid NS solver. Details can be found at [http://plasmati.com.tw/ultrasparts.html Plasma Taiwan Innovative Corp.]\n* '''VizGrain''' is a commercial, parallel, 1D/2D/3D, multi-species PIC-DSMC code developed by [http://esgeetech.com/products/vizgrain-particle-modeling Esgee Technologies]. '''VizGrain''' is designed to run standalone or coupled with fluid simulation for hybrid [[plasma modeling]]. Applications include semiconductor processing, reactive flows, electric propulsion, and material processing.\n* '''NFS''' ('''N'''onequilibrium '''F'''low '''S'''olver) is a 3D, multi-species, parallel DSMC code<ref>{{Cite journal|last=Kumar|first=Rakesh|last2=Chinnappan|first2=Arun Kumar|date=2017-12-15|title=Development of a multi-species, parallel, 3D Direct Simulation Monte-Carlo solver for rarefied gas flows|url=https://www.sciencedirect.com/science/article/pii/S0045793017303638|journal=Computers & Fluids|language=en|volume=159|pages=204–216|doi=10.1016/j.compfluid.2017.10.006|issn=0045-7930|via=}}</ref> with adaptive mesh refinement, developed at [http://home.iitk.ac.in/~rkm/index.html Non-equilibrium Flow Simulation Lab] (NFSL) headed by Prof. Rakesh Kumar at [https://www.iitk.ac.in/ Indian Institute of Technology Kanpur].\n\n==References==\n{{reflist}}\n\n==External links ==\n* [http://gab.com.au/ Direct Simulation Monte Carlo Method: Visual Simulation Programs created by GA Bird].\n* [http://www.simba.us/misc/dsmc/dsmca.html DSMC Demo Applet] by Greg Khanlarov\n* [http://homepage.univie.ac.at/franz.vesely/cp_tut/nol2h/new/c8hd_s4dsm.html Course material on DSMC] (part of Computational Physics tutorial by Franz J. Vesely, University of Vienna)\n* [https://web.archive.org/web/20110717092648/https://www.ipam.ucla.edu/schedule.aspx?pc=kttut Course material on DSMC and recent developments] (given at IPAM UCLA by Lorenzo Pareschi, University of Ferrara)\n* [http://www.pi-dsmc.com PI-DSMC homepage]\n* [http://cern.ch/test-molflow Molflow homepage]\n* [http://metariver.kr SAMADII/SCiV homepage]\n* [http://plasmati.com.tw/ultrasparts.html ultraSPARTS homepage]\n\n[[Category:Monte Carlo methods]]\n[[Category:Statistical mechanics]]"
    },
    {
      "title": "Dynamic Monte Carlo method",
      "url": "https://en.wikipedia.org/wiki/Dynamic_Monte_Carlo_method",
      "text": "In [[chemistry]], '''dynamic Monte Carlo (DMC)''' is a [[Monte Carlo method]] for modeling the dynamic behaviors of [[molecule]]s by comparing the rates of individual steps with [[random number generation|random number]]s. It is essentially the same as [[Kinetic Monte Carlo]]. Unlike the [[Metropolis Monte Carlo]] method, which has been employed to study systems at [[Chemical equilibrium|equilibrium]], the DMC method is used to investigate non-equilibrium systems such as a [[chemical reaction|reaction]], [[diffusion]], and so-forth (Meng and Weinberg 1994). This method is mainly applied to analyze adsorbates' behavior on surfaces. The DMC method is very similar to the [[kinetic Monte Carlo]] method.\n\nThere are several well-known methods for performing DMC simulations, including the First Reaction Method (FRM) and Random Selection Method (RSM). Although the FRM and RSM give the same results from a given model, the [[Computational resource|computer resource]]s are different depending on the applied system.\n\nIn the FRM, the reaction whose time is minimum on the event list is advanced. In the event list, the tentative times for all possible reactions are stored. After the selection of one event, the system time is advanced to the reaction time, and the event list is recalculated. This method is efficient in [[computation time]] because the reaction always occurs in one event. On the other hand, it consumes a lot of [[computer memory]] because of the event list. Therefore, it is difficult to apply to large-scale systems.\n\nThe RSM decides whether the reaction of the selected molecule proceeds or not by comparing the transition probability with a [[Random number generator|random number]]. In this method, the reaction does not necessarily proceed in one event, so it needs significantly more computation time than FRM. However, this method saves computer memory because it does not use an event list. Large-scale systems are able to be calculated by this method.\n\n==See also==\n* [[Hybrid Monte Carlo]]\n\n== References ==\n\n* (Meng and Weinberg 1994): B. Meng and W. H. Weinberg, J. Chem. Phys. 100, 5280 (1994)\n* (Meng and Weinberg 1996): B. Meng, W.H. Weinberg, Surface Science 364 (1996) 151-163.\n\n{{DEFAULTSORT:Dynamic Monte Carlo Method}}\n[[Category:Monte Carlo methods]]\n[[Category:Computational chemistry]]"
    },
    {
      "title": "Ensemble forecasting",
      "url": "https://en.wikipedia.org/wiki/Ensemble_forecasting",
      "text": "[[File:WRF rita spread2.jpg|thumb|right|''Top'': ''[[Weather Research and Forecasting model]]'' simulation of Hurricane Rita tracks. ''Bottom'': The spread of [[National Hurricane Center]] multi-model ensemble forecast.]]\n\n'''Ensemble forecasting''' is a method used in [[numerical weather prediction]]. Instead of making a single forecast of the most likely weather, a set (or ensemble) of forecasts is produced. This set of forecasts aims to give an indication of the range of possible future states of the atmosphere. Ensemble forecasting is a form of [[Monte Carlo method|Monte Carlo analysis]]. The multiple simulations are conducted to account for the two usual sources of [[uncertainty]] in forecast models: (1) the errors introduced by the use of imperfect initial conditions, amplified by the [[Chaos theory|chaotic]] nature of the evolution equations of the atmosphere, which is often referred to as [[sensitive dependence on initial conditions]]; and (2) errors introduced because of imperfections in the model formulation, such as the approximate mathematical methods to solve the equations.  Ideally, the verified future atmospheric state should fall within the predicted ensemble [[Standard deviation|spread]], and the amount of spread should be related to the uncertainty (error) of the forecast. In general, this approach can be used to make probabilistic forecasts of any [[dynamical system]], and not just for weather prediction.\n\nToday ensemble predictions are commonly made at most of the major operational weather prediction facilities worldwide, including:\n* [[National Centers for Environmental Prediction]] (NCEP of the US)\n* [[European Centre for Medium-Range Weather Forecasts]] (ECMWF)\n* United Kingdom [[Met Office]]\n* [[Météo-France]]\n* [[Environment Canada]]\n* [[Japan Meteorological Agency]]\n* [[Bureau of Meteorology]] (Australia)\n* [[China Meteorological Administration]] (CMA)\n* [[Korea Meteorological Administration]]\n* [[CPTEC]] (Brazil)\n*[[Ministry of Earth Sciences]] (IMD, IITM & NCMRWF) (India)\nExperimental ensemble forecasts are made at a number of universities, such as the University of Washington, and ensemble forecasts in the US are also generated by the [[US Navy]] and [[US Air Force|Air Force]].  There are various ways of viewing the data such as [[spaghetti plot]]s, ''ensemble means'' or ''Postage Stamps'' where a number of different results from the models run can be compared.\n\n==History==\n{{See also|History of numerical weather prediction}}\n<!-- [[WP:NFCC]] violation: [[File:Edward lorenz.jpg|thumb|[[Edward Norton Lorenz|Ed Lorenz]], father of chaos theory]] -->\nAs proposed by [[Edward Lorenz]] in 1963, it is impossible for long-range forecasts—those made more than two weeks in advance—to predict the state of the atmosphere with any degree of [[forecast skill|skill]] owing to the [[chaos theory|chaotic nature]] of the [[fluid dynamics]] equations involved.<ref name=\"Cox\">{{cite book|title=Storm Watchers|pages=222–224|year=2002|author=Cox, John D.|publisher=John Wiley & Sons, Inc.|isbn=978-0-471-38108-2}}</ref>  Furthermore, existing observation networks have limited spatial and temporal resolution (for example, over large bodies of water such as the Pacific Ocean), which introduces uncertainty into the true initial state of the atmosphere.  While a set of equations, known as the [[Liouville's theorem (Hamiltonian)|Liouville equations]], exists to determine the initial uncertainty in the model initialization, the equations are too complex to run in real-time, even with the use of supercomputers.<ref name=\"HPCens\">{{cite web|url=http://www.wpc.ncep.noaa.gov/ensembletraining|title=Ensemble Prediction Systems|date=2006-07-19|publisher=[[Hydrometeorological Prediction Center]]|author=Manousos, Peter|accessdate=2010-12-31}}</ref> The practical importance of ensemble forecasts derives from the fact that in a chaotic and hence nonlinear system, the rate of growth of forecast error is dependent on starting conditions. An ensemble forecast therefore provides a prior estimate of state-dependent predictability, i.e. an estimate of the types of weather that might occur, given inevitable uncertainties in the forecast initial conditions and in the accuracy of the computational representation of the equations. These uncertainties limit forecast model accuracy to about six days into the future.<ref name=\"Klaus\">Weickmann, Klaus, Jeff Whitaker, Andres Roubicek and Catherine Smith (2001-12-01). [http://www.cdc.noaa.gov/spotlight/12012001/ The Use of Ensemble Forecasts to Produce Improved Medium Range (3–15&nbsp;days) Weather Forecasts.] [[Climate Diagnostics Center]]. Retrieved 2007-02-16.</ref> The first operational ensemble forecasts were produced for sub-seasonal timescales in 1985 <ref>{{Cite journal|last=Palmer|first=Tim|title=The ECMWF ensemble prediction system: Looking back (more than) 25 years and projecting forward 25 years|journal=Quarterly Journal of the Royal Meteorological Society|language=en|volume=0|doi=10.1002/qj.3383|issn=1477-870X|year=2018}}</ref>. However, it was realised that the philosophy underpinning such forecasts was also relevant on shorter timescales – timescales where predictions had previously been made by purely deterministic means. \n\n[[Edward Epstein (meteorologist)|Edward Epstein]] recognized in 1969 that the atmosphere could not be completely described with a single forecast run due to inherent uncertainty, and proposed a [[stochastic process|stochastic]] dynamic model that produced [[arithmetic mean|means]] and [[variance]]s for the state of the atmosphere.<ref>{{cite journal|last=Epstein|first=E.S.|title=Stochastic dynamic prediction|journal=[[Tellus A]]|date=December 1969|volume=21|issue=6|pages=739–759|doi=10.1111/j.2153-3490.1969.tb00483.x|bibcode=1969Tell...21..739E}}</ref>  Although these [[Monte Carlo method|Monte Carlo simulations]] showed skill, in 1974 [[Cecil Leith]] revealed that they produced adequate forecasts only when the ensemble [[probability distribution]] was a representative sample of the probability distribution in the atmosphere.<ref>{{cite journal|last=Leith|first=C.E.|title=Theoretical Skill of Monte Carlo Forecasts|journal=[[Monthly Weather Review]]|date=June 1974|volume=102|issue=6|pages=409–418|doi=10.1175/1520-0493(1974)102<0409:TSOMCF>2.0.CO;2|issn=1520-0493|bibcode=1974MWRv..102..409L}}</ref>  It was not until 1992 that ensemble forecasts began being prepared by the [[European Centre for Medium-Range Weather Forecasts]] (ECMWF) and the [[National Centers for Environmental Prediction]] (NCEP).\n\n==Methods for representing uncertainty==\nThere are two main sources of uncertainty that must be accounted for when making an ensemble weather forecast: initial condition uncertainty and model uncertainty.<ref>{{Cite journal|last=Slingo|first=Julia|last2=Palmer|first2=Tim|date=2011-12-13|title=Uncertainty in weather and climate prediction|journal=Phil. Trans. R. Soc. A|language=en|volume=369|issue=1956|pages=4751–4767|doi=10.1098/rsta.2011.0161|issn=1364-503X|pmc=3270390|pmid=22042896|bibcode=2011RSPTA.369.4751S}}</ref>\n\n=== Initial condition uncertainty ===\nInitial condition uncertainty arises due to errors in the estimate of the starting conditions for the forecast, both due to limited observations of the atmosphere, and uncertainties involved in using indirect measurements, such as [[Satellite temperature measurements|satellite data]], to measure the state of atmospheric variables. Initial condition uncertainty is represented by perturbing the starting conditions between the different ensemble members. This explores the range of starting conditions consistent with our knowledge of the current state of the atmosphere, together with its past evolution. There are a number of ways to generate these initial condition perturbations. The ECMWF model, the Ensemble Prediction System,<ref name=\"ECens\">{{cite web|url=http://www.ecmwf.int/products/forecasts/guide/The_Ensemble_Prediction_System_EPS_1.html |title=The Ensemble Prediction System (EPS) |publisher=[[ECMWF]] |accessdate=2011-01-05 |deadurl=yes |archiveurl=https://web.archive.org/web/20101030055238/http://ecmwf.int/products/forecasts/guide/The_Ensemble_Prediction_System_EPS_1.html |archivedate=2010-10-30 |df= }}</ref> uses a combination of [[Singular value decomposition|singular vectors]] and an ensemble of [[data assimilation]]s (EDA) to simulate the initial [[probability density function|probability density]].<ref>{{Cite web|url=http://www.ecmwf.int/en/research/modelling-and-prediction/quantifying-forecast-uncertainty|title=Quantifying forecast uncertainty {{!}} ECMWF|website=www.ecmwf.int|access-date=2016-11-20|date=2013-11-29}}</ref> The singular vector perturbations are more active in the extra-tropics, while the EDA perturbations are more active in the tropics. The NCEP ensemble, the Global Ensemble Forecasting System, uses a technique known as [[Bred vector|vector breeding]].<ref name=\"Toth\">{{cite journal|last=Toth|first=Zoltan|date=December 1997|title=Ensemble Forecasting at NCEP and the Breeding Method|journal=[[Monthly Weather Review]]|volume=125|issue=12|pages=3297–3319|bibcode=1997MWRv..125.3297T|doi=10.1175/1520-0493(1997)125<3297:EFANAT>2.0.CO;2|issn=1520-0493|author2=Kalnay, Eugenia|author-link2=Eugenia Kalnay|citeseerx=10.1.1.324.3941}}</ref><ref name=\"RMS\">{{cite journal|last2=Buizza|first2=R.|last3=Palmer|first3=T.N.|last4=Petroliagis|first4=T.|date=January 1996|title=The ECMWF Ensemble Prediction System: Methodology and validation|journal=Quarterly Journal of the Royal Meteorological Society|volume=122|issue=529|pages=73–119|bibcode=1996QJRMS.122...73M|doi=10.1002/qj.49712252905|last1=Molteni|first1=F.|authorlink3=Tim Palmer (physicist)}}</ref>\n\n=== Model uncertainty ===\nModel uncertainty arises due to the limitations of the forecast model. The process of representing the atmosphere in a computer model involves many simplifications such as the development of [[Parametrization (atmospheric modeling)|parametrisation]] schemes, which introduce errors into the forecast. Several techniques to represent model uncertainty have been proposed.\n\n==== Perturbed parameter schemes ====\nWhen developing a [[Parametrization (atmospheric modeling)|parametrisation]] scheme, many new parameters are introduced to represent simplified physical processes. These parameters may be very uncertain. For example, the '[[Entrainment (meteorology)|entrainment]] coefficient' represents the [[Turbulence|turbulent]] mixing of dry environmental air into a [[Thunderstorm|convective cloud]], and so represents a complex physical process using a single number. In a perturbed parameter approach, uncertain parameters in the model's parametrisation schemes are identified and their value changed between ensemble members. While in probabilistic climate modelling, such as [[climateprediction.net]], these parameters are often held constant globally and throughout the integration,<ref>{{Cite web|url=http://www.climateprediction.net/climate-science/climate-ensembles/perturbed-physics-ensembles/|title=Perturbed Physics Ensembles {{!}} climateprediction.net|website=www.climateprediction.net|access-date=2016-11-20}}</ref> in modern numerical weather prediction it is more common to stochastically vary the value of the parameters in time and space.<ref>{{Cite journal|last=McCabe|first=Anne|last2=Swinbank|first2=Richard|last3=Tennant|first3=Warren|last4=Lock|first4=Adrian|date=2016-10-01|title=Representing model uncertainty in the Met Office convection-permitting ensemble prediction system and its impact on fog forecasting|journal=Quarterly Journal of the Royal Meteorological Society|language=en|volume=142|issue=700|pages=2897–2910|doi=10.1002/qj.2876|issn=1477-870X|bibcode=2016QJRMS.142.2897M}}</ref> The degree of parameter perturbation can be guided using expert judgement,<ref>{{Cite journal|last=Ollinaho|first=Pirkka|last2=Lock|first2=Sarah-Jane|last3=Leutbecher|first3=Martin|last4=Bechtold|first4=Peter|last5=Beljaars|first5=Anton|last6=Bozzo|first6=Alessio|last7=Forbes|first7=Richard M.|last8=Haiden|first8=Thomas|last9=Hogan|first9=Robin J.|date=2016-10-01|title=Towards process-level representation of model uncertainties: Stochastically perturbed parametrisations in the ECMWF ensemble|journal=Quarterly Journal of the Royal Meteorological Society|volume=143|issue=702|language=en|pages=408–422|doi=10.1002/qj.2931|issn=1477-870X|bibcode=2017QJRMS.143..408O}}</ref> or by directly estimating the degree of parameter uncertainty for a given model.<ref>{{Cite journal|last=Christensen|first=H. M.|last2=Moroz|first2=I. M.|last3=Palmer|first3=T. N.|date=2015-02-04|title=Stochastic and Perturbed Parameter Representations of Model Uncertainty in Convection Parameterization|journal=Journal of the Atmospheric Sciences|volume=72|issue=6|pages=2525–2544|doi=10.1175/JAS-D-14-0250.1|issn=0022-4928|bibcode=2015JAtS...72.2525C}}</ref>\n\n==== Stochastic parametrisations ====\nA traditional [[Parametrization (atmospheric modeling)|parametrisation]] scheme seeks to represent the average effect of the sub grid-scale motion (e.g. convective clouds) on the resolved scale state (e.g. the large scale temperature and wind fields). A stochastic parametrisation scheme recognises that there may be many sub-grid scale states consistent with a particular resolved scale state. Instead of predicting the most likely sub-grid scale motion, a stochastic parametrisation scheme represents one possible realisation of the sub-grid. It does this through including [[Statistical randomness|random numbers]] into the equations of motion. This samples from the [[probability distribution]] assigned to uncertain processes. Stochastic parametrisations have significantly improved the skill of weather forecasting models, and are now used in operational forecasting centres worldwide.<ref>{{Cite journal|last=Berner|first=Judith|last2=Achatz|first2=Ulrich|last3=Batté|first3=Lauriane|last4=Bengtsson|first4=Lisa|last5=De La Cámara|first5=Alvaro|last6=Christensen|first6=Hannah M.|last7=Colangeli|first7=Matteo|last8=Coleman|first8=Danielle R. B.|last9=Crommelin|first9=Daan|date=2016-07-19|title=Stochastic Parameterization: Towards a new view of Weather and Climate Models|journal=Bulletin of the American Meteorological Society|volume=98|issue=3|pages=565|doi=10.1175/BAMS-D-15-00268.1|issn=0003-0007|bibcode=2017BAMS...98..565B|arxiv=1510.08682}}</ref> Stochastic parametrisations were first developed at the [[European Centre for Medium-Range Weather Forecasts|European Centre for Medium Range Weather Forecasts]].<ref>{{Cite journal|last=Buizza|first=R.|last2=Milleer|first2=M.|last3=Palmer|first3=T. N.|date=1999-10-01|title=Stochastic representation of model uncertainties in the ECMWF ensemble prediction system|journal=Quarterly Journal of the Royal Meteorological Society|language=en|volume=125|issue=560|pages=2887–2908|doi=10.1002/qj.49712556006|issn=1477-870X|bibcode=1999QJRMS.125.2887B}}</ref>\n\n==== Multi model ensembles ====\nWhen many different forecast models are used to try to generate a forecast, the approach is termed multi-model ensemble forecasting.  This method of forecasting can improve forecasts when compared to a single model-based approach.<ref>{{cite journal|date=February 2010|title=Fog Prediction From a Multimodel Mesoscale Ensemble Prediction System|url=http://www.emc.ncep.noaa.gov/mmb/SREF/2222289_WAF_Feb-2010.official.PDF|journal=[[Weather and Forecasting]]|volume=25|issue=1|page=303|bibcode=2010WtFor..25..303Z|doi=10.1175/2009WAF2222289.1|author=Zhou, Binbin and Jun Du|accessdate=2011-01-02}}</ref>  When the models within a multi-model ensemble are adjusted for their various biases, this process is known as \"superensemble forecasting\".  This type of a forecast significantly reduces errors in model output.<ref>{{cite journal|date=2010-02-12|title=Multimodel SuperEnsemble technique for quantitative precipitation forecasts in Piemonte region|journal=Natural Hazards and Earth System Sciences|volume=10|issue=2|page=265|bibcode=2010NHESS..10..265C|doi=10.5194/nhess-10-265-2010|author=Cane, D. and M. Milelli}}</ref> When models of different physical processes are combined, such as combinations of atmospheric, ocean and wave models, the multi-model ensemble is called hyper-ensemble.<ref>{{cite journal|year=2009|title=Super-Ensemble techniques: application to surface drift prediction|url=http://orbi.ulg.ac.be/request-copy/2268/16406/33151/Super-ensemble%20techniques.pdf|journal=Progress in Oceanography|volume=82|issue=3|pages=149–167|bibcode=2009PrOce..82..149V|doi=10.1016/j.pocean.2009.06.002|author=Vandenbulcke, L.|display-authors=etal}}</ref>\n\n==Probability assessment==\nThe ensemble forecast is usually evaluated by comparing the average of the individual forecasts for one forecast variable to the observed value of that variable (the \"error\"). This is combined with consideration of the degree of agreement between various forecasts within the ensemble system, as represented by their overall [[standard deviation]] or \"spread\". Ensemble spread can be visualised through tools such as spaghetti diagrams, which show the dispersion of one quantity on prognostic charts for specific time steps in the future.  Another tool where ensemble spread is used is a [[meteogram]], which shows the dispersion in the forecast of one quantity for one specific location.  It is common for the ensemble spread to be too small, such that the observed atmospheric state falls outside of the ensemble forecast. This can lead the forecaster to be overconfident in their forecast.<ref name=\"ensbook\" /> This problem becomes particularly severe for forecasts of the weather about 10 days in advance,<ref>{{cite journal|last=Palmer|first=T.N.|date=May 2005|title=Representing Model Uncertainty in Weather and Climate Prediction|journal=[[Annual Review of Earth and Planetary Sciences]]|volume=33|pages=163–193|bibcode=2005AREPS..33..163P|doi=10.1146/annurev.earth.33.092203.122552|author2=G.J. Shutts|author3=R. Hagedorn|author4=F.J. Doblas-Reyes|author5=T. Jung|author6=M. Leutbecher}}</ref> particularly if model uncertainty is not accounted for in the forecast.\n\n=== Reliability and resolution (calibration and sharpness) ===\nThe spread of the ensemble forecast indicates how confident the forecaster can be in his or her prediction. When ensemble spread is small and the forecast solutions are consistent within multiple model runs, forecasters perceive more confidence in the forecast in general.<ref name=\"ensbook\">{{cite book|url=https://books.google.com/books?id=6RQ3dnjE8lgC&pg=PA261|title=Numerical Weather and Climate Prediction|author=Warner, Thomas Tomkins |publisher=[[Cambridge University Press]]|year=2010|isbn=978-0-521-51389-0|pages=266–275}}</ref> When the spread is large, this indicates more uncertainty in the prediction. Ideally, a ''spread-skill relationship'' should exist, whereby the spread of the ensemble is a good predictor of the expected error in the ensemble mean. If the forecast is ''[[Reliability (statistics)|reliable]],'' the observed state will behave as if it is drawn from the forecast probability distribution. Reliability (or ''calibration'') can be evaluated by comparing the standard deviation of the error in the ensemble mean with the forecast spread: for a reliable forecast, the two should match, both at different forecast lead times and for different locations.<ref>{{Cite journal|last=Leutbecher|first=M.|last2=Palmer|first2=T. N.|date=2008-03-20|title=Ensemble forecasting|journal=Journal of Computational Physics|series=Predicting weather, climate and extreme events|volume=227|issue=7|pages=3515–3539|doi=10.1016/j.jcp.2007.02.014|bibcode=2008JCoPh.227.3515L}}</ref>\n\nThe reliability of forecasts of a specific weather event can also be assessed. For example, if 30 of 50 members indicated greater than 1&nbsp;cm rainfall during the next 24 h, the [[probability of exceedance|probability of exceeding]] 1&nbsp;cm could be estimated to be 60%. The forecast would be considered reliable if, considering all the situations in the past when a 60% probability was forecast, on 60% of those occasions did the rainfall actually exceed 1&nbsp;cm. In practice, the probabilities generated from operational weather ensemble forecasts are not highly reliable, though with a set of past forecasts (''reforecasts'' or ''hindcasts'') and observations, the probability estimates from the ensemble can be adjusted to ensure greater reliability.\n\nAnother desirable property of ensemble forecasts is ''resolution.'' This is an indication of how much the forecast deviates from the climatological event frequency – provided that the ensemble is reliable, increasing this deviation will increase the usefulness of the forecast. This forecast quality can also be considered in terms of ''sharpness'', or how small the spread of the forecast is. The key aim of a forecaster should be to maximise sharpness, while maintaining reliability.<ref>{{Cite journal|last=Gneiting|first=Tilmann|last2=Balabdaoui|first2=Fadoua|last3=Raftery|first3=Adrian E.|date=2007-04-01|title=Probabilistic forecasts, calibration and sharpness|url=http://www.ingentaconnect.com/content/bpl/rssb/2007/00000069/00000002/art00008|journal=Journal of the Royal Statistical Society, Series B|volume=69|issue=2|pages=243–268|doi=10.1111/j.1467-9868.2007.00587.x|citeseerx=10.1.1.142.9002}}</ref> Forecasts at long leads will inevitably not be particularly sharp (have particularly high resolution), for the inevitable (albeit usually small) errors in the initial condition will grow with increasing forecast lead until the expected difference between two model states is as large as the difference between two random states from the forecast model's climatology.\n\n==Co-ordinated research==\n{{main|THORPEX Interactive Grand Global Ensemble}}\n[[THORPEX|The Observing System Research and Predictability Experiment]] (THORPEX) is a 10-year international research and development programme to accelerate improvements in the accuracy of one-day to two-week high impact weather forecasts for the benefit of society, the economy and the environment. It establishes an organizational framework that addresses weather research and forecast problems whose solutions will be accelerated through international collaboration among academic institutions, operational forecast centres and users of forecast products.\n\nOne of its key components is [[THORPEX Interactive Grand Global Ensemble]] (TIGGE), a World Weather Research Programme to accelerate the improvements in the accuracy of 1-day to 2 week high-impact weather forecasts for the benefit of humanity. Centralized archives of ensemble model forecast data, from many international centers, are used to enable extensive data sharing and research.\n\n==See also==\n*[[Chaos theory]]\n*[[Climate ensemble]]\n*[[Ensemble Kalman filter]]\n*[[Ensemble (fluid mechanics)]]\n*[[Forecasting]]\n*[[Probabilistic forecasting]]\n*[[THORPEX Interactive Grand Global Ensemble]]\n*[[North American Ensemble Forecast System]]\n\n==References==\n{{reflist|2}}\n\n==Further reading==\n* {{cite book |author= Ian Roulstone and John Norbury |title=Invisible in the Storm: the role of mathematics in understanding weather |url=https://books.google.com/?id=qnMrFEHMrWwC|year=2013 |publisher=Princeton University Press|isbn=978-0691152721 }}\n\n==External links==\n*[http://tigge.ecmwf.int TIGGE Research Page]\n*[http://dss.ucar.edu/datasets/ds330.3 TIGGE Tropical Cyclone Track data Archive at NCAR]\n*[http://www.wmo.int/pages/prog/arep/wwrp/new/thorpex_new.html THORPEX Research Page]\n\n{{Atmospheric, Oceanographic and Climate Models}}\n{{Computer modeling}}\n\n{{DEFAULTSORT:Ensemble Forecasting}}\n[[Category:Climate modeling]]\n[[Category:Climate and weather statistics]]\n[[Category:Monte Carlo methods]]\n[[Category:Numerical climate and weather models]]\n[[Category:Statistical forecasting]]"
    },
    {
      "title": "Ensemble Kalman filter",
      "url": "https://en.wikipedia.org/wiki/Ensemble_Kalman_filter",
      "text": "The '''ensemble Kalman filter''' ('''EnKF''') is a [[recursive filter]] suitable for problems with a large number of variables, such as [[discretization]]s of [[partial differential equation]]s in geophysical models. The EnKF originated as a version of the [[Kalman filter]] for large problems (essentially, the [[covariance matrix]] is replaced by the [[sample covariance matrix|sample covariance]]), and it is now an important [[data assimilation]] component of [[ensemble forecasting]]. EnKF is related to the [[particle filter]] (in this context, a particle is the same thing as ensemble member) but the EnKF makes the assumption that all probability distributions involved are [[Normal distribution|Gaussian]];  when it is applicable, it is much more efficient than the [[particle filter]].\n<!-- The original version of this page was converted from LaTeX by [[User:Jmath666/latex2wiki.pl]] -->\n<!-- first version written by [[User:Oleg Alexandrov]], now developed and maintained by [[User:Jmath666]] -->\n<!-- NOTE: this page is using references by [[Wikipedia:Footnote]] -->\n<!-- NOTE: please follow this reference scheme and leave these comments in. -->\n\n==Introduction==\n\nThe ensemble Kalman filter (EnKF) is a [[Monte Carlo method|Monte Carlo]] implementation of the [[Bayesian inference|Bayesian update]] problem: given a [[probability density function]] (pdf) of the state of the modeled system (the ''[[Prior probability|prior]]'', called often the forecast in geosciences) and the data likelihood, [[Bayes' theorem]] is used to obtain the pdf after the data likelihood has been taken into account (the ''[[Posterior probability|posterior]]'', often called the analysis). This is called a Bayesian update. The Bayesian update is combined with advancing the model in time, incorporating new data from time to time. The original [[Kalman filter]], introduced in 1960,<ref name=\"Kalman-1960-NAL\">{{cite journal |first=R. E. |last=Kalman |title=A new approach to linear filtering and prediction problems |journal=Transactions of the ASME – Journal of Basic Engineering |series=Series D |volume=82 |year=1960 |issue=1 |pages=35–45 |doi=10.1115/1.3662552 }}</ref> assumes that all pdfs are [[normal distribution|Gaussian]] (the Gaussian assumption) and provides algebraic formulas for the change of the [[mean]] and the [[covariance matrix]] by the Bayesian update, as well as a formula for advancing the covariance matrix in time provided the system is linear. However, maintaining the covariance matrix is not feasible computationally for high-dimensional systems. For this reason, EnKFs were developed.<ref name=\"Evensen-1994-SDA\">{{cite journal |first=G. |last=Evensen |title=Sequential data assimilation with nonlinear quasi-geostrophic model using Monte Carlo methods to forecast error statistics |journal=Journal of Geophysical Research |volume=99 |issue=C5 |year=1994 |pages=143–162 |doi=10.1029/94JC00572  |hdl=1956/3035 }}</ref><ref name=\"Houtekamer-1998-DAE\">{{cite journal |first=P. |last=Houtekamer |first2=H. L. |last2=Mitchell |title=Data assimilation using an ensemble Kalman filter technique |journal=[[Monthly Weather Review]] |volume=126 |year=1998 |issue= 3|pages=796–811 |doi=10.1175/1520-0493(1998)126<0796:DAUAEK>2.0.CO;2 |citeseerx=10.1.1.3.1706 }}</ref> EnKFs represent the distribution of the system state using a collection of state vectors, called an [[Numerical weather prediction#Ensembles|ensemble]], and replace the covariance matrix by the [[sample covariance]] computed from the ensemble. The ensemble is operated with as if it were a [[random sample]], but the ensemble members are really not [[Statistical independence|independent]] – the EnKF ties them together. One advantage of EnKFs is that advancing the pdf in time is achieved by simply advancing each member of the ensemble.<ref name=\"Evensen-2007-DAE\">For a survey of EnKF and related data assimilation techniques, see {{cite book |first=G. |last=Evensen |title=Data Assimilation : The Ensemble Kalman Filter |publisher=Springer |location=Berlin |year=2007 |isbn=978-3-540-38300-0 }}</ref>\n\n==Derivation==\n\n===Kalman filter===\n\nLet us review first the [[Kalman filter]]. Let <math>\\mathbf{x}</math> denote the <math>n</math>-dimensional [[State space representation|state vector]] of a model, and assume that it has [[normal distribution|Gaussian probability distribution]] with mean <math>\\mathbf{\\mu}</math> and covariance <math>Q</math>, i.e., its pdf is\n\n:<math> p(\\mathbf{x})\\propto\\exp\\left(  -\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu })^{\\mathrm{T}}Q^{-1}(\\mathbf{x}-\\mathbf{\\mu})\\right)  . </math>\n\nHere and below, <math>\\propto</math> means proportional; a pdf is always scaled so that its integral over the whole space is one. This <math>p(\\mathbf{x})</math>, called the ''[[prior probability|prior]]'', was evolved in time by running the model and now is to be updated to account for new data. It is natural to assume that the error distribution of the data is known; data have to come with an error estimate, otherwise they are meaningless. Here, the data <math>\\mathbf{d}</math> is assumed to have Gaussian pdf with covariance <math>R</math> and mean <math>H\\mathbf{x}</math>, where <math>H</math> is the so-called [[Hat matrix|observation matrix]]. The covariance matrix <math>R</math> describes the estimate of the error of the data; if the random errors in the entries of the data vector <math>\\mathbf{d}</math> are independent, <math>R</math> is diagonal and its diagonal entries are the squares of the [[standard deviation]] (“error size”) of the error of the corresponding entries of the data vector <math>\\mathbf{d}</math>. The value <math>H\\mathbf{x}</math> is what the value of the data would be for the state <math>\\mathbf{x}</math> in the absence of data errors. Then the probability density <math>p(\\mathbf{d}|\\mathbf{x})</math> of the data <math>\\mathbf{d}</math> conditional of the system state <math>\\mathbf{x}</math>, called the [[Likelihood function|data likelihood]], is\n\n:<math> p\\left(  \\mathbf{d}|\\mathbf{x}\\right)  \\propto\\exp\\left(  -\\frac{1}{2}(\\mathbf{d}-H\\mathbf{x})^{\\mathrm{T}}R^{-1}(\\mathbf{d}-H\\mathbf{x})\\right) . </math>\n\nThe pdf of the state and the [[Likelihood function|data likelihood]] are combined to give the new probability density of the system state <math>\\mathbf{x}</math> conditional on the value of the data <math>\\mathbf{d}</math> (the ''[[posterior probability|posterior]]'') by the [[Bayes theorem#Bayes' theorem for probability densities|Bayes theorem]],\n\n:<math> p\\left(  \\mathbf{x}|\\mathbf{d}\\right)  \\propto p\\left(  \\mathbf{d}|\\mathbf{x}\\right)  p(\\mathbf{x}). </math>\n\nThe data <math>\\mathbf{d}</math> is fixed once it is received, so denote the posterior state by <math>\\mathbf{\\hat{x}}</math> instead of <math>\\mathbf{x}|\\mathbf{d}</math> and the posterior pdf by <math>p\\left(  \\mathbf{\\hat{x}}\\right)  </math>. It can be shown by algebraic manipulations<ref name=\"Anderson-1979-OF\">{{cite book |first=B. D. O. |last=Anderson |first2=J. B. |last2=Moore |title=Optimal Filtering |publisher=Prentice-Hall |location=Englewood Cliffs, NJ |year=1979 |isbn=978-0-13-638122-8 }}</ref> that the posterior pdf is also Gaussian,\n\n:<math> p\\left(  \\mathbf{\\hat{x}}\\right)  \\propto\\exp\\left(  -\\frac{1}{2}(\\mathbf{\\hat{x}}-\\mathbf{\\hat{\\mu}})^{\\mathrm{T}}\\hat{Q}^{-1}(\\mathbf{\\hat{x}}-\\mathbf{\\hat{\\mu}})\\right)  , </math>\n\nwith the posterior mean <math>\\mathbf{\\hat{\\mu}}</math> and covariance <math>\\hat{Q}</math> given by the Kalman update formulas\n\n:<math> \\mathbf{\\hat{\\mu}}=\\mathbf{\\mu}+K\\left(  \\mathbf{d}-H\\mathbf{\\mu}\\right) ,\\quad\\hat{Q}=\\left(  I-KH\\right)  Q, </math>\n\nwhere\n\n:<math> K=QH^{\\mathrm{T}}\\left(  HQH^{\\mathrm{T}}+R\\right)  ^{-1}</math>\n\nis the so-called [[Kalman filter#Kalman gain derivation|Kalman gain]] matrix.\n\n===Ensemble Kalman Filter===\n\nThe EnKF is a Monte Carlo approximation of the Kalman filter, which avoids evolving the covariance matrix of the pdf of the state vector <math>\\mathbf{x}</math>. Instead, the pdf is represented by an ensemble\n\n:<math> X=\\left[  \\mathbf{x}_{1},\\ldots,\\mathbf{x}_{N}\\right]  =\\left[  \\mathbf{x}_{i}\\right]. </math>\n\n<math>X</math> is an <math>n\\times N</math> matrix whose columns are the ensemble members, and it is called the ''prior ensemble''. Ideally, ensemble members would form a [[Random sample|sample]] from the prior distribution. However, the ensemble members are not in general [[Statistical independence|independent]] except in the initial ensemble, since every EnKF  step ties them together. They are deemed to be approximately independent, and all calculations proceed as if they actually were independent.\n\nReplicate the data <math>\\mathbf{d}</math> into an <math>m\\times N</math> matrix\n\n:<math> D=\\left[  \\mathbf{d}_{1},\\ldots,\\mathbf{d}_{N}\\right]  =\\left[  \\mathbf{d}_{i}\\right], \\quad \\mathbf{d}_{i}=\\mathbf{d}+\\mathbf{\\epsilon_{i}}, \\quad \\mathbf{\\epsilon_{i}} =N(0,R), </math>\n\nso that each column <math>\\mathbf{d}_{i}</math> consists of the data vector <math>\\mathbf{d}</math> plus a random vector from the <math>m</math>-dimensional normal distribution <math>N(0,R)</math>. If, in addition, the columns of <math>X</math> are a sample from the [[prior probability]] distribution, then the columns of\n\n:<math> \\hat{X}=X+K(D-HX) </math>\n\nform a sample from the [[posterior probability]] distribution. To see this in the scalar case with <math>H=1</math>: Let <math>x_i = \\mu + \\xi_i, \\; \\xi_i \\sim N(0, \\sigma_x^2)</math>, and <math>d_i = d + \\epsilon_i, \\; \\epsilon_i \\sim N(0, \\sigma_d^2).</math>  Then\n\n:<math>\\hat{x}_i = \\left(\\frac{1/\\sigma_x^2}{1/\\sigma_x^2 + 1/\\sigma_d^2} \\mu + \\frac{1/\\sigma_d^2}{1/\\sigma_x^2 + 1/\\sigma_d^2} d \\right)+ \\left(\\frac{1/\\sigma_x^2}{1/\\sigma_x^2 + 1/\\sigma_d^2} \\xi_i + \\frac{1/\\sigma_d^2}{1/\\sigma_x^2 + 1/\\sigma_d^2} \\epsilon_i \\right) </math>.\n\nThe first sum is the posterior mean, and the second sum, in view of the independence, has a variance\n\n:<math>\\left(\\frac{1/\\sigma_x^2}{1/\\sigma_x^2 + 1/\\sigma_d^2}\\right)^2 \\sigma_x^2 + \\left(\\frac{1/\\sigma_d^2}{1/\\sigma_x^2 + 1/\\sigma_d^2}\\right)^2 \\sigma_d^2 =  \\frac{1}{1/\\sigma_x^2 + 1/\\sigma_d^2}</math>,\n\nwhich is the posterior variance.\n\nThe EnKF is now obtained simply by replacing the state covariance <math>Q</math> in Kalman gain matrix <math>K</math> by the sample covariance <math>C</math> computed from the ensemble members (called the ''ensemble covariance''),<ref name=\"Johns-2005-CEK\">{{cite journal |first=C. J. |last=Johns |first2=J. |last2=Mandel |title=A Two-Stage Ensemble Kalman Filter for Smooth Data Assimilation |journal=Environmental and Ecological Statistics |year=2008 |volume=15 |issue=1 |pages=101–110 |doi=10.1007/s10651-007-0033-0 |citeseerx=10.1.1.67.4916 }}</ref> that is: <math>K=CH^{\\mathrm{T}}\\left(  HCH^{\\mathrm{T}}+R\\right)  ^{-1}</math>\n\n==Implementation==\n\n===Basic formulation===\n\nHere we follow.<ref name=\"Burgers-1998-ASE\">{{cite journal |first=G. |last=Burgers |first2=P. J. |last2=van Leeuwen |first3=G. |last3=Evensen |title=Analysis Scheme in the Ensemble Kalman Filter |journal=Monthly Weather Review |volume=126 |issue= 6|year=1998 |pages=1719–1724 |doi=10.1175/1520-0493(1998)126<1719:ASITEK>2.0.CO;2 |citeseerx=10.1.1.41.5827 }}</ref><ref name=\"Evensen-2003-EKF\">{{cite journal |first=G. |last=Evensen |title=The Ensemble Kalman Filter: Theoretical Formulation and Practical Implementation |journal=Ocean Dynamics |volume=53 |year=2003 |issue=4 |pages=343–367 |doi=10.1007/s10236-003-0036-9 |citeseerx=10.1.1.5.6990 }}</ref> Suppose the ensemble matrix <math>X</math> and the data matrix <math>D</math> are as above. The ensemble mean and the covariance are\n\n:<math> E\\left(  X\\right)  =\\frac{1}{N}\\sum_{k=1}^{N}\\mathbf{x}_{k},\\quad C=\\frac{AA^{T}}{N-1}, </math>\n\nwhere\n\n:<math> A=X-E\\left(  X\\right) \\mathbf{e}_{1\\times N}  =X-\\frac{1}{N}\\left(  X\\mathbf{e}_{N\\times1}\\right) \\mathbf{e}_{1\\times N}, </math>\n\nand <math>\\mathbf{e}</math> denotes the matrix of all ones of the indicated size.\n\nThe posterior ensemble <math>X^{p}</math> is then given by\n\n:<math> X^{p}=X+CH^{T}\\left(  HCH^{T}+R\\right)  ^{-1}(D-HX), </math>\n\nwhere the perturbed data matrix <math>D</math> is as above.\n\nNote that since <math>R</math> is a covariance matrix, it is always [[positive semidefinite matrix|positive semidefinite]] and usually [[positive semidefinite matrix|positive definite]], so the inverse above exists and the formula can be implemented by the  [[Cholesky decomposition]].<ref name=\"Mandel-2006-EIE\">{{cite paper |first=J. |last=Mandel |title=Efficient Implementation of the Ensemble Kalman Filter |work=CCM Report 231 |publisher=University of Colorado at Denver and Health Sciences Center |url=http://www.math.ucdenver.edu/ccm/reports/rep231.pdf |date=June 2006 }}</ref> In,<ref name=\"Burgers-1998-ASE\"/><ref name=\"Evensen-2003-EKF\"/> <math>R</math> is replaced by the sample covariance <math>\\tilde{D} \\tilde{D}^{T}/\\left(  N-1\\right)  </math> where <math>\\tilde{D} = D - \\frac{1}{N} d \\, \\mathbf{e}_{1\\times N}</math>and the inverse is replaced by a [[pseudoinverse]], computed using the [[singular-value decomposition]] (SVD) .\n\nSince these formulas are matrix operations with dominant [[BLAS#Level 3|Level 3]] operations,<ref name=\"Golub-1989-MAC\">{{cite book |first=G. H. |last=Golub |authorlink=Gene H. Golub |first2=C. F. V. |last2=Loan |title=Matrix Computations |publisher=Johns Hopkins Univ. Press |location=Baltimore |year=1989 |edition=Second |isbn=978-0-8018-3772-2 }}</ref> they are suitable for efficient implementation using software packages such as [[LAPACK]] (on serial and [[Shared memory architecture|shared memory]] computers) and [[ScaLAPACK]] (on [[distributed memory]] computers).<ref name=\"Mandel-2006-EIE\"/> Instead of computing the [[inverse matrix|inverse]] of a matrix and multiplying by it, it is much better (several times cheaper and also more accurate) to compute the [[Cholesky decomposition]] of the matrix and treat the multiplication by the inverse as solution of a linear system with many simultaneous right-hand sides.<ref name=\"Golub-1989-MAC\"/>\n\n===Observation matrix-free implementation===\n\nSince we have replaced the covariance matrix with ensemble covariance, this leads to a simpler formula where ensemble observations are directly used without explicitly specifying the matrix <math>H</math>. More specifically, define a function <math>h(\\mathbf{x})</math> of the form\n\n:<math> h(\\mathbf{x})=H\\mathbf{x}. </math>\n\nThe function <math>h</math> is called the ''[[observation function]]'' or, in the [[inverse problem]]s context, the ''[[Inverse problem#Probabilistic formulation of inverse problems|forward operator]]''. The value of <math>h(\\mathbf{x})</math> is what the value of the data would be for the state <math>\\mathbf{x}</math> assuming the measurement is exact. Then the posterior ensemble can be rewritten as\n\n:<math> X^{p}=X+\\frac{1}{N-1}A\\left(  HA\\right)  ^{T}P^{-1}(D-HX) </math>\n\nwhere\n\n:<math> HA=HX-\\frac{1}{N}\\left(  \\left(  HX\\right)  \\mathbf{e}_{N\\times1}\\right) \\mathbf{e}_{1\\times N}, </math>\n\nand\n\n:<math> P=\\frac{1}{N-1}HA\\left(  HA\\right)  ^{T}+R, </math>\n\nwith\n\n:<math>\\left[  HA\\right]  _{i}    =H\\mathbf{x}_{i}-H\\frac{1}{N}\\sum_{j=1}^{N}\\mathbf{x}_{j}\\   =h\\left(  \\mathbf{x}_{i}\\right)  -\\frac{1}{N}\\sum_{j=1}^{N}h\\left( \\mathbf{x}_{j}\\right)  . </math>\n\nConsequently, the ensemble update can be computed by evaluating the observation function <math>h</math> on each ensemble member once and the matrix <math>H</math> does not need to be known explicitly. This formula holds also<ref name=\"Mandel-2006-EIE\"/> for an observation function <math>h(\\mathbf{x})=H\\mathbf{x+f}</math> with a fixed offset <math>\\mathbf{f}</math>, which also does not need to be known explicitly. The above formula has been commonly used for a nonlinear observation function <math>h</math>, such as the position of a [[hurricane]] [[vortex]].<ref name=\"Chen-2006-AVP\">{{cite journal |first=Y. |last=Chen |first2=C. |last2=Snyder |title=Assimilating Vortex Position with an Ensemble Kalman Filter |journal=Monthly Weather Review |volume=135 |year=2007 |issue=5 |pages=1828–1845 |doi=10.1175/MWR3351.1 }}</ref> In that case, the observation function is essentially approximated by a linear function from its values at ensemble members.\n\n===Implementation for a large number of data points===\n\nFor a large number <math>m</math> of data points, the multiplication by <math>P^{-1}</math> becomes a bottleneck. The following alternative formula is advantageous when the number of data points <math>m</math> is large (such as when assimilating gridded or pixel data) and the data error [[covariance matrix]] <math>R</math> is diagonal (which is the case when the data errors are uncorrelated), or cheap to decompose (such as banded due to limited covariance distance). Using the [[Sherman–Morrison–Woodbury formula]]<ref name=\"Hager-1989-UIM\">{{cite journal |first=W. W. |last=Hager |title=Updating the inverse of a matrix |journal=[[SIAM Review]] |volume=31 |issue=2 |year=1989 |pages=221–239 |doi=10.1137/1031049 }}</ref>\n\n:<math> (R+UV^{T})^{-1}=R^{-1}-R^{-1}U(I+V^{T}R^{-1}U)^{-1}V^{T}R^{-1}, </math>\n\nwith\n\n:<math> U=\\frac{1}{N-1}HA,\\quad V=HA, </math>\n\ngives\n\n:<math>\\begin{align} P^{-1}  &  =\\left(  R+\\frac{1}{N-1}HA\\left(  HA\\right)  ^{T}\\right)  ^{-1}\\ =  \\\\\n&  =R^{-1}\\left[  I-\\frac{1}{N-1}\\left(  HA\\right)  \\left(  I+\\left( HA\\right)  ^{T}R^{-1}\\frac{1}{N-1}\\left(  HA\\right)  \\right)  ^{-1}\\left( HA\\right)  ^{T}R^{-1}\\right]  , \\end{align}</math>\n\nwhich requires only the solution of systems with the matrix <math>R</math> (assumed to be cheap) and of a system of size <math>N</math> with <math>m</math> right-hand sides. See<ref name=\"Mandel-2006-EIE\"/> for operation counts.\n\n==Further extensions==\n\nThe EnKF version described here involves randomization of data. For filters without randomization of data, see.<ref name=\"Anderson-2001-EAK\">{{cite journal |first=J. L. |last=Anderson |title=An ensemble adjustment Kalman filter for data assimilation |journal=Monthly Weather Review |volume=129 |year=2001 |issue=12 |pages=2884–2903 |doi=10.1175/1520-0493(2001)129<2884:AEAKFF>2.0.CO;2 |citeseerx=10.1.1.5.9952 }}</ref><ref name=\"Evensen-2004-SSR\">{{cite journal |first=G. |last=Evensen |title=Sampling strategies and square root analysis schemes for the EnKF |journal=Ocean Dynamics |volume=54 |year=2004 |issue=6 |pages=539–560 |doi=10.1007/s10236-004-0099-2 |citeseerx=10.1.1.3.6213 }}</ref><ref name=\"Tippett-2003-ESR\">{{cite journal |first=M. K. |last=Tippett |first2=J. L. |last2=Anderson |first3=C. H. |last3=Bishop |first4=T. M. |last4=Hamill |first5=J. S. |last5=Whitaker |title=Ensemble square root filters |journal=Monthly Weather Review |volume=131 |year=2003 |issue=7 |pages=1485–1490 |doi=10.1175/1520-0493(2003)131<1485:ESRF>2.0.CO;2 |citeseerx=10.1.1.332.775 }}</ref>\n\nSince the ensemble covariance is [[rank deficient]] (there are many more state variables, typically millions, than the ensemble members, typically less than a hundred), it has large terms for pairs of points that are spatially distant. Since in reality the values of physical fields at distant locations are not that much [[correlated]], the covariance matrix is tapered off artificially based on the distance, which gives rise to [[Localized ensemble Kalman filters|localized EnKF]] algorithms.<ref name=\"Anderson-2003-LLS\">{{cite journal |first=J. L. |last=Anderson |title=A local least squares framework for ensemble filtering |journal=Monthly Weather Review |volume=131 |year=2003 |issue=4 |pages=634–642 |doi=10.1175/1520-0493(2003)131<0634:ALLSFF>2.0.CO;2 |citeseerx=10.1.1.10.6543 }}</ref><ref name=\"Ott-2003-LEK\">{{cite journal |authorlink1=Edward Ott |first1=E. |last1=Ott |first2=B. R. |last2=Hunt |first3=I. |last3=Szunyogh |first4=A. V. |last4=Zimin |first5=E. J. |last5=Kostelich |first6=M. |last6=Corazza |authorlink7=Eugenia Kalnay |first7=E. |last7=Kalnay |first8=D. |last8=Patil |authorlink9=James A. Yorke |first9=J. A. |last9=Yorke |title=A local ensemble Kalman filter for atmospheric data assimilation |journal=[[Tellus A]] |series= |volume=56 |year=2004 |issue=5 |pages=415–428 |doi=10.3402/tellusa.v56i5.14462 |arxiv=physics/0203058 }}</ref> These methods modify the covariance matrix used in the computations and, consequently, the posterior ensemble is no longer made only of linear combinations of the prior ensemble.\n\nFor nonlinear problems, EnKF can create posterior ensemble with non-physical states. This can be alleviated by [[Tikhonov regularization|regularization]], such as [[Penalty method|penalization]] of states with large spatial [[gradient]]s.<ref name=\"Johns-2005-CEK\"/>\n\nFor problems with [[coherent feature]]s, such as [[hurricane]]s, [[thunderstorm]]s, [[fireline]]s, [[squall line]]s, and [[rain front]]s, there is a need to adjust the numerical model state by deforming the state in space (its grid) as well as by  correcting the state amplitudes additively. In 2007, Ravela et al. introduce the joint position-amplitude adjustment model using ensembles, and systematically derive a sequential approximation which can be applied to both EnKF and other formulations.<ref name =\"Ravela-2007\">{{cite journal |first=S. |last=Ravela |first2=K. |last2=Emanuel |authorlink2=Kerry Emanuel |first3=D. |last3=McLaughlin |title=Data Assimilation by Field Alignment |journal=[[Physica (journal)|Physica]] |series=D: Nonlinear Phenomena |volume=230 |issue=1–2 |year=2007 |pages=127–145 |doi=10.1016/j.physd.2006.09.035 }}</ref> Their method does not make the assumption that amplitudes and position errors are independent or jointly Gaussian, as others do. The morphing EnKF employs intermediate states, obtained by techniques borrowed from [[image registration]] and [[morphing]], instead of linear combinations of states.<ref name=\"Beezley-2007-MEK\">{{cite journal |first=J. D. |last=Beezley |first2=J. |last2=Mandel |title=Morphing ensemble Kalman filters |journal=Tellus A |year=2008 |volume=60 |issue=1 |pages=131–140 |doi=10.1111/j.1600-0870.2007.00275.x }}</ref><ref name=\"Mandel-2006-PME\">{{cite conference |first=J. |last=Mandel |first2=J. D. |last2=Beezley |title=Predictor-corrector and morphing ensemble filters for the assimilation of sparse data into high dimensional nonlinear systems |work=CCM Report 239 |publisher=University of Colorado at Denver and Health Sciences Center |url=http://www.math.ucdenver.edu/ccm/reports/rep239.pdf |date=November 2006 |conference=11th Symposium on Integrated Observing and Assimilation Systems for the Atmosphere, Oceans, and Land Surface (IOAS-AOLS), CD-ROM, Paper 4.12, 87th American Meteorological Society Annual Meeting, San Antonio, TX, January 2007 }}</ref>\n\nEnKFs rely on the Gaussian assumption, although they in practice are used for nonlinear problems, where the Gaussian assumption may not be satisfied. Related filters attempting to relax the Gaussian assumption in EnKF while preserving its advantages include filters that fit the state pdf with multiple Gaussian kernels,<ref name=\"Anderson-1999-MCI\">{{cite journal |first=J. L. |last=Anderson |first2=S. L. |last2=Anderson |title=A Monte Carlo implementation of the nonlinear filtering problem to produce ensemble assimilations and forecasts |journal=Monthly Weather Review |volume=127 |issue=12 |year=1999 |pages=2741–2758 |doi=10.1175/1520-0493(1999)127<2741:AMCIOT>2.0.CO;2 }}</ref> filters that approximate the state pdf by [[Gaussian mixture]]s,<ref name=\"Bengtsson-2003-NFE\">{{cite journal |first=T. |last=Bengtsson |first2=C. |last2=Snyder |first3=D. |last3=Nychka |title=Toward a nonlinear ensemble filter for high dimensional systems |journal=Journal of Geophysical Research: Atmospheres |volume=108 |issue=D24 |year=2003 |pages=STS 2–1–10 |doi=10.1029/2002JD002900 }}</ref> a variant of the [[particle filter]] with computation of particle weights by [[density estimation]],<ref name=\"Mandel-2006-PME\"/> and a variant of the particle filter with [[Cauchy distribution|thick tailed]] data pdf to alleviate [[Particle filter#Sampling Importance Resampling (SIR)|particle filter degeneracy]].<ref name=\"vanLeeuwen-2003-VMF\">{{cite journal |first=P. |last=van Leeuwen |title=A variance-minimizing filter for large-scale applications |journal=Monthly Weather Review |volume=131 |year=2003 |issue=9 |pages=2071–2084 |doi=10.1175/1520-0493(2003)131<2071:AVFFLA>2.0.CO;2 |citeseerx=10.1.1.7.3719 }}</ref>\n\n==See also==\n* [[Data assimilation]]\n* [[Numerical weather prediction#Ensembles]]\n* [[Particle filter]]\n* [[Recursive Bayesian estimation]]\n\n==References==\n{{reflist|2}}\n\n==External links==\n* [http://enkf.nersc.no EnKF webpage]\n* [http://topaz.nersc.no TOPAZ, real-time forecasting of the North Atlantic ocean and Arctic sea-ice with the EnKF]\n* [https://github.com/sakov/enkf-c EnKF-C, a light-weight framework for data assimilation into large-scale layered geophysical models with the EnKF]\n* [http://pdaf.awi.de PDAF] – [[Parallel Data Assimilation Framework]] – an open-source software for data assimilation providing different variants of the EnKF\n\n{{DEFAULTSORT:Ensemble Kalman Filter}}\n[[Category:Linear filters]]\n[[Category:Nonlinear filters]]\n[[Category:Bayesian statistics]]\n[[Category:Signal estimation]]\n[[Category:Monte Carlo methods]]"
    },
    {
      "title": "Equation of State Calculations by Fast Computing Machines",
      "url": "https://en.wikipedia.org/wiki/Equation_of_State_Calculations_by_Fast_Computing_Machines",
      "text": "'''Equation of State Calculations by Fast Computing Machines''' is an article published by [[Nicholas Metropolis]], [[Arianna W. Rosenbluth]], [[Marshall N. Rosenbluth]], [[Augusta H. Teller]], and [[Edward Teller]] in the [[Journal of Chemical Physics]] in 1953.<ref name=metropolis>{{cite journal\n |first1=N. |last1=Metropolis |authorlink1=Nicholas Metropolis\n |first2=A.W. |last2=Rosenbluth |authorlink2= Arianna W. Rosenbluth\n |first3=M.N. |last3=Rosenbluth |authorlink3=Marshall N. Rosenbluth\n |first4=A.H. |last4=Teller | authorlink4=Augusta H. Teller \n |first5=E. |last5=Teller |authorlink5=Edward Teller\n |title=Equation of State Calculations by Fast Computing Machines\n |journal=[[Journal of Chemical Physics]]\n |volume=21 |issue=6 |pages=1087&ndash;1092 |year=1953\n |doi=10.1063/1.1699114\n|bibcode = 1953JChPh..21.1087M |title-link=Equation of State Calculations by Fast Computing Machines }}</ref> This paper proposed what became known as the [[Metropolis Monte Carlo]] algorithm, which forms the basis for Monte Carlo [[statistical mechanics]] simulations of atomic and molecular systems.<ref name=jorgensen>{{cite journal |title=Perspective on \"Equation of state calculations by fast computing machines |author=William L. Jorgensen |volume=103 |issue=3–4 |year=2000 |doi=10.1007/s002149900053 |pages=225–227 |journal=Theoretical Chemistry Accounts: Theory, Computation, and Modeling (Theoretica Chimica Acta)}}</ref> \n\n==Development==\nSome controversy exists with regard to credit for development of the algorithm.  Prior to 2003, there was no detailed account of the algorithm's development.  Then, shortly before his death, [[Marshall Rosenbluth]] attended a 2003 conference at LANL marking the 50th anniversary of the 1953 publication.  At this conference, Rosenbluth described the algorithm and its development in a presentation titled \"Genesis of the Monte Carlo Algorithm for Statistical Mechanics\".<ref>{{cite journal |title=Genesis of the Monte Carlo Algorithm for Statistical Mechanics|author=M.N. Rosenbluth |journal=[[AIP Conference Proceedings]] | volume=690 | pages=22–30 | year=2003 | doi=10.1063/1.1632112 \n}}</ref>  Further historical clarification is made by Gubernatis in a 2005 journal article<ref>{{cite journal |title=Marshall Rosenbluth and the Metropolis Algorithm |author=J.E. Gubernatis |journal=[[Physics of Plasmas]] | volume=12| pages=057303| year=2005| doi=10.1063/1.1887186 | bibcode=2005PhPl...12e7303G |issue=5\n|url=https://zenodo.org/record/1231899 }}</ref> recounting the 50th anniversary conference. Rosenbluth makes it clear that he and his wife Arianna did the work, and that Metropolis played no role in the development other than providing computer time.\nRosenbluth credits Teller with a crucial but early suggestion to \"take advantage of statistical mechanics and take ensemble averages instead of following detailed kinematics\".  Additional clarification of attribution is given in connection with the [[Metropolis–Hastings algorithm]].  The Rosenbluths would subsequently publish two additional, lesser-known papers using the Monte Carlo method <ref>{{cite journal|last1=Rosenbluth|first1=Marshall|last2=Rosenbluth|first2=Arianna|title=Further Results on Monte Carlo Equations of State|journal=The Journal of Chemical Physics|volume=22|issue=5|pages=881–884|year=1954|doi=10.1063/1.1740207|bibcode=1954JChPh..22..881R}}</ref><ref>{{cite journal|last1=Rosenbluth|first1=Marshall|last2=Rosenbluth|first2=Arianna|title=Monte Carlo Calculation of the Average Extension of Molecular Chains|journal=The Journal of Chemical Physics|volume=23|issue=2|pages=356–359|year=1955|doi=10.1063/1.1741967|bibcode=1955JChPh..23..356R}}</ref>, while the other authors would not continue to work on the topic.  Already in 1953, however, Marshall was recruited to work on [[Project Sherwood]] and thereafter turned his attention to [[plasma physics]].  Here he laid the foundation for much of modern plasma fluid and kinetic theory, and particularly the theory of plasma instabilities. \n\n==Algorithm==\n[[Monte Carlo methods]] are a class of computational algorithms that rely on repeated random sampling to compute their results. In [[statistical mechanics]] applications prior to the introduction of the Metropolis algorithm, the method consisted of generating a large number of random configurations of the system, computing the properties of interest (such as energy or density) for each configuration, and then producing a [[weighted average]] where the weight of each configuration is its [[Boltzmann factor]], exp(−''E''/''kT''), where ''E'' is the [[energy]], ''T'' is the [[temperature]], and ''k'' is [[Boltzmann's constant]]. The key contribution of the Metropolis paper was the idea that\n\n{{quotation|Instead of choosing configurations randomly, then weighting them with exp(−''E''/''kT''), we choose configurations with a probability  exp(−''E''/''kT'') and weight them evenly.|Metropolis et al.|<ref name=metropolis/>}}\n\n[[Image:Limiteperiodicite.svg|thumb|Periodic boundary conditions. When the green particle moves through the top of the central sphere, it reenters through the bottom.]]This change makes the sampling focus on the low-energy configurations, which contribute the most to the Boltzmann average, resulting in improved [[limit of a sequence|convergence]]. To choose configurations with a probability exp(−''E''/''kT'') that can be weighed evenly, the authors devised the following algorithm: 1) each configuration is generated by a random move on the previous configuration and the new energy is computed; 2) if the new energy is lower, the move is always accepted; otherwise the move is accepted with a probability of exp(−Δ''E''/''kT''). When a move is rejected, the last accepted configuration is counted again for the statistical averages and is used as a base for the next attempted move.\n\nThe main topic of the article was the numerical calculation of the [[equation of state]] for a system of [[rigid sphere]]s in two dimensions. Subsequent work generalized the method to three dimensions and to fluids using the [[Lennard-Jones potential]]. The simulations were done for a system of 224 particles; each simulation consisted of up to 48 cycles, where each cycle consisted of moving each particle once and took about three minutes of computer time using the [[MANIAC]] computer at [[Los Alamos National Lab]].\n\nTo minimize surface effects, the authors introduced the use of [[periodic boundary conditions]]. This means that the simulated system is treated as a [[unit cell]] in a lattice, and when a particle moves out of the cell, it automatically comes in through the other side (making the system a topological [[torus]]).\n\nAccording to a perspective published nearly fifty years later by [[William L. Jorgensen]], \"Metropolis et al. introduced the samplic method and periodic boundary conditions that remain at the heart of Monte Carlo statistical mechanics simulations of fluids. This was one of the major contributions to theoretical chemistry of the twentieth century.\"<ref name=jorgensen/> As of 2011, the article has been cited over 18,000 times.<ref>[[ISI Web of Knowledge]] Cited Reference Search. Accessed 2010-09-22.</ref>\n\nIn another perspective, it was said that although \"the Metropolis algorithm began as a technique for attacking specific problems in numerical simulations of physical systems [...] later, the subject exploded as the scope of applications broadened in many surprising directions, including function minimization, computational geometry, and combinatorial counting. Today, topics related to the Metropolis algorithm constitute an entire field of computational science supported by a deep theory and having applications ranging from physical simulations to the foundations of computational complexity.\"<ref>{{cite journal |author=I. Beichl and F. Sullivan |title=The Metropolis Algorithm |journal=Computing in Science and Engineering |volume=2 |issue=1 |year=2000 |pages=65–69 |doi=10.1109/5992.814660|url=https://zenodo.org/record/1232185 }}</ref>\n\n==See also==\n* [[Timeline of scientific computing]]\n\n==References==\n{{reflist}}\n\n==External links==\n* {{cite journal | last1 = Metropolis| first1 = Nicholas| last2 = Rosenbluth| first2 = Arianna W.| last3 = Rosenbluth| first3 = Marshall N.| last4 = Teller| first4 = Augusta H.| last5 = Teller| first5 = Edward| year = 1953 | title = Equation of State Calculations by Fast Computing Machines | url = http://jcp.aip.org/resource/1/jcpsa6/v21/i6/p1087_s1 | journal = [[J. Chem. Phys.]] | volume = 21 | issue = 6| page = 1087 | doi = 10.1063/1.1699114 | bibcode=1953JChPh..21.1087M}}\n* [[Nicholas Metropolis]] (1987).  [http://lib-www.lanl.gov/la-pubs/00326866.pdf \"The Beginning of the Monte Carlo Method\"]. ''[[Los Alamos Science]]'', No. 15, Page 125.\n* [[Herbert L. Anderson|Herbert Anderson]] (1986). [http://lib-www.lanl.gov/la-pubs/00326886.pdf \"Metropolis, Monte Carlo and the MANIAC\"]. ''Los Alamos Science'' No. 14, Page 69.\n\n[[Category:Monte Carlo methods]]\n[[Category:1953 documents]]\n[[Category:History of physics]]\n[[Category:1953 in science]]\n[[Category:Computer science papers]]\n[[Category:Works originally published in American magazines]]\n[[Category:Works originally published in science and technology magazines]]"
    },
    {
      "title": "Event generator",
      "url": "https://en.wikipedia.org/wiki/Event_generator",
      "text": "'''Event generators''' are [[software]] [[library (computer science)|libraries]] that generate simulated high-energy [[particle physics]] [[event (particle physics)|events]].<ref>[http://arjournals.annualreviews.org/doi/abs/10.1146/annurev.nucl.55.090704.151505 M. L. Mangano & T. J. Stelzer, Annu. Rev. Nucl. Part. Sci. 55, 555 (2005).]</ref><ref>[https://arxiv.org/abs/hep-ph/0403045 M. A. Dobbs ''et al.'', hep-ph/0403045.]</ref>\nThey randomly generate events as those produced in [[particle accelerators]], [[collider]] experiments or the early universe.\nEvents come in different types called ''processes'' as discussed in the [[Automatic calculation of particle interaction or decay]] article.\n\nDespite the simple structure of the tree-level [[perturbation theory|perturbative]] [[quantum field theory]] description of the [[collision]] and [[radioactive decay|decay]] processes in an event, the observed high-energy process usually contains significant amount of modifications, like [[photon]] and [[gluon]] ''[[bremsstrahlung]]'' or loop [[Feynman diagram|diagram]] corrections, that usually are too complex to be easily evaluated in real calculations directly on the diagrammatic level. Furthermore, the non-perturbative nature of [[Quantum chromodynamics|QCD]] [[bound state]]s makes it necessary to include information that is well beyond the reach of perturbative quantum field theory, and also beyond present ability of computation in [[lattice QCD]]. And in collisional systems more complex than a few [[lepton]]s and [[hadron]]s (e.g. heavy-ion collisions), the collective behavior of the system would involve a [[phenomenology (particle physics)|phenomenological]] description that also cannot be easily obtained from the fundamental field theory by a simple calculus.\n\n==Use in simulations==\nAs said above, the experimental calibration involves processes that usually are too complicated to be easily evaluated in calculations directly, so any realistic test of the underlying physical process in a [[particle accelerator]] [[experiment]], therefore, requires an adequate inclusion of these complex behaviors surrounding the actual process. Based on the fact that in most processes a [[factorization]] of the full process into individual problems is possible (which means a negligible effect from [[Interference (wave propagation)|interference]]), these individual processes are calculated separately, and the [[probability|probabilistic]] branching between them are performed using [[Monte Carlo method]]s.\n\nThe final-state particles generated by event generators can be fed into the detector simulation, allowing a precise prediction and verification for the entire system of experimental setup. However, as the detector simulation is usually a complex and computationally expensive task, simple event analysis techniques are also performed directly on event generator results.\n\nSome automatic software packages exist, that help in constructing event generators and are sometimes viewed as ''generators of event generators'' or ''meta-generators''.\n\nPartly due to historic reasons, most event generators are written in [[FORTRAN 77]], with a few [[C++]] generators slowly emerging in recent years. The [[Particle Data Group]] maintains a [[Standardization|standard]] for designating [[Standard Model]] particles and [[Resonance#Quantum field theory|resonances]] with [[integer]] [[code]]s in event generators (also known as the \"PDG code\").\n\n===Processes===\nA typical hadronic event generator simulates the following subprocesses:\n\n* Initial-state composition and substructure\n* Initial-state [[particle shower|shower]]s\n* The hard process\n* [[Resonance]] decay\n* Final-state showers\n* Accompanying semi-hard processes\n* [[Hadronization]] and further decay\n\nA typical heavy-ion event generator usually can be less strict in simulating the rare and rather negligible processes found in a hadronic generator, but would need to simulate the following subprocesses, in addition to those in a hadronic generator:\n\n* [[atomic nucleus|Nuclear]] initial-state\n* High multiplicity, soft processes\n* In-medium energy loss\n* Collective behavior of the medium ''(not handled properly by any generators so far)''\n\n== List of event generators ==\nThe major event generators that are used by current experiments are:\n\n'''Hadronic event generators'''<ref>[http://indico.cern.ch/conferenceDisplay.py?confId=a042790 T. Sjöstrand, \"Monte Carlo generators for the LHC (1/4)\", CERN Lecture (2005)], p. 22</ref>\n* [[PYTHIA]] (formerly Pythia/Jetset)\n* [http://www.hep.phy.cam.ac.uk/theory/webber/Herwig/ HERWIG]\n* [http://www.nhn.ou.edu/~isajet/ ISAJET]\n* [https://sherpa.hepforge.org/ SHERPA]\n\n'''Multi-purpose parton level generators'''\n*[http://madgraph.hep.uiuc.edu/ MadGraph5] (able to run directly on the web site after registration and an email to the author)\n*[http://whizard.hepforge.org/ Whizard]\n\n'''Heavy ion event generators'''\n* [http://gibuu.hepforge.org GiBUU]\n* [http://www-nsdth.lbl.gov/~xnwang/hijing/ HIJING]\n\n'''Neutrino event generators'''\n* [http://www.genie-mc.org GENIE]\n* [http://gibuu.hepforge.org GiBUU]\n* [http://borg.ift.uni.wroc.pl/nuwro/ NuWro]\n\n'''Specialized event generators'''\n* [http://borut.home.cern.ch/borut/ AcerMC] &ndash; [[Large Hadron Collider|LHC]] background processes\n* [http://mlm.home.cern.ch/mlm/alpgen/ ALPGEN] &ndash; multiple [[Parton (particle physics)|parton]] processes\n* [http://www.thep.lu.se/~leif/ariadne/ Ariadne] &ndash; QCD cascade with Color Dipole Model\n* [http://www.hep.phy.cam.ac.uk/theory/webber/MCatNLO/ MC@NLO] &ndash; next-to-leading-order QCD matrix elements, using HERWIG for parton shower\n* [http://hepforge.cedar.ac.uk/jimmy/ JIMMY] &ndash; multiple parton processes\n* [http://starlight.hepforge.org/ [[STARlight]] ] &ndash; Photonuclear and two-photon processes in ultra-peripheral collisions of heavy ions <ref>[https://arxiv.org/abs/1607.03838 S. Klein, J. Nystrand, J. Seger, Y. Gorbunov and J. Butterworth, arXiv:1607.03838]</ref>\n* [https://www.mv.helsinki.fi/home/mmieskol/ GRANIITTI] &ndash; Diffractive QCD and two-photon processes\n\n'''\"Meta-generator\"'''\n* [[CompHEP]] &ndash; automatic evaluation of tree level matrix elements for event generation or export into other event generators\n\n'''\"A repository with public Monte Carlo samples\"'''\n* [https://atlaswww.hep.anl.gov/hepsim/  HepSim] Public repository with event samples from Monte Carlo generators for particle collisions\n\n==References==\n\n{{reflist}}\n\n==External links ==\n* [http://pdg.lbl.gov/2006/mcdata/mc_particle_id_contents.html 2006 Monte Carlo Number Scheme], from the 2006 [[Review of Particle Physics]].\n* [http://www.desy.de/~heramc/mclist.html List of Monte Carlo Programs] &ndash; from [[DESY]]\n\n[[Category:Particle physics]]\n[[Category:Monte Carlo methods]]\n[[Category:Computational particle physics]]"
    },
    {
      "title": "Fisher–Yates shuffle",
      "url": "https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle",
      "text": "The '''Fisher–Yates shuffle''' is an [[algorithm]] for generating a [[random permutation]] of a finite [[sequence]]—in plain terms, the algorithm [[shuffling|shuffles]] the sequence.  The algorithm effectively puts all the elements into a hat; it continually determines the next element by randomly drawing an element from the hat until no elements remain. The algorithm produces an [[Biased sample|unbiased]] permutation: every permutation is equally likely.  The modern version of the algorithm is efficient: it takes time proportional to the number of items being shuffled and shuffles them [[In-place algorithm|in place]].\n\nThe Fisher–Yates shuffle is named after [[Ronald Fisher]] and [[Frank Yates]], who first described it, and is also known as the '''Knuth shuffle''' after [[Donald Knuth]]. A variant of the Fisher–Yates shuffle, known as '''Sattolo's algorithm''', may be used to generate random [[cyclic permutation]]s of length ''n'' instead of random permutations.\n\n== Fisher and Yates' original method ==\n\nThe Fisher–Yates shuffle, in its original form, was described in 1938 by [[Ronald Fisher]] and [[Frank Yates]] in their book ''Statistical tables for biological, agricultural and medical research''.<ref name=\"fisheryates\">\n{{cite book\n| last=Fisher |first=Ronald A. |author1link=Ronald A. Fisher |last2=Yates |first2=Frank |author2link=Frank Yates\n| title = Statistical tables for biological, agricultural and medical research\n| origyear = 1938\n| edition = 3rd\n| year = 1948\n| pages = 26–27\n| publisher = Oliver & Boyd\n| location = London\n| oclc = 14222135\n}} <!-- TODO: should cite 1st ed., if I could just find it -->\nNote: the 6th edition, {{ISBN|0-02-844720-4}}, is [http://hdl.handle.net/2440/10701 available on the web], but gives a different shuffling algorithm by [[C. R. Rao]].\n</ref>  Their description of the algorithm used pencil and paper; a table of random numbers provided the randomness.  The basic method given for generating a random permutation of the numbers 1 through ''N'' goes as follows:\n\n# Write down the numbers from 1 through ''N''.\n# Pick a random number ''k'' between one and the number of unstruck numbers remaining (inclusive).\n# Counting from the low end, strike out the ''k''th number not yet struck out, and write it down at the end of a separate list.\n# Repeat from step 2 until all the numbers have been struck out.\n# The sequence of numbers written down in step 3 is now a random permutation of the original numbers.\n\nProvided that the random numbers picked in step 2 above are truly random and unbiased, so will the resulting permutation be.  Fisher and Yates took care to describe how to obtain such random numbers in any desired range from the supplied tables in a manner which avoids any bias.  They also suggested the possibility of using a simpler method — picking random numbers from one to ''N'' and discarding any duplicates—to generate the first half of the permutation, and only applying the more complex algorithm to the remaining half, where picking a duplicate number would otherwise become frustratingly common.\n\n== The modern algorithm ==\nThe modern version of the Fisher–Yates shuffle, designed for computer use, was introduced by [[Richard Durstenfeld]] in 1964<ref name=\"cacm\">{{Cite journal | last1 = Durstenfeld |first1 = R. | title = Algorithm 235: Random permutation | doi = 10.1145/364520.364540 | journal = Communications of the ACM | volume = 7 | issue = 7 | pages = 420 | date=July 1964 | pmid =  | pmc = }}</ref> and popularized by [[Donald E. Knuth]] in ''[[The Art of Computer Programming]]'' as \"Algorithm P (Shuffling)\".<ref name=\"knuth\">\n{{cite book\n| series=The Art of Computer Programming |volume=2 |title=Seminumerical algorithms\n| first = Donald E.\n| last = Knuth\n| pages = 139–140\n| year = 1969\n| publisher = Addison–Wesley\n| location = Reading, MA\n| oclc = 85975465\n}}\n</ref> Neither Durstenfeld's article nor Knuth's first edition of ''The Art of Computer Programming'' acknowledged the work of Fisher and Yates; they may not have been aware of it.  Subsequent editions of Knuth's ''The Art of Computer Programming'' mention Fisher and Yates' contribution.<ref name=\"knuth3\">\n{{cite book\n| series=The Art of Computer Programming |volume=2 |title=Seminumerical algorithms\n| last = Knuth\n| edition = 3rd\n| year = 1998\n| pages = 12–15, 145–146\n| isbn = 0-201-89684-2\n| oclc = 38207978\n| publisher = Addison–Wesley\n| location = Boston\n}}\n</ref>\n\nThe algorithm described by Durstenfeld differs from that given by Fisher and Yates in a small but significant way.  Whereas a naive computer implementation of Fisher and Yates' method would spend needless time counting the remaining numbers in step 3 above, Durstenfeld's solution is to move the \"struck\" numbers to the end of the list by swapping them with the last unstruck number at each iteration.  This reduces the algorithm's [[time complexity]] to ''O''(''n''), compared to ''O''(''n''<sup>2</sup>) for the naïve implementation.<ref name=\"nist\">\n{{cite web\n| first = Paul E.\n| last = Black\n| work = Dictionary of Algorithms and Data Structures\n| title = Fisher–Yates shuffle\n| publisher = [[National Institute of Standards and Technology]]\n| url = https://xlinux.nist.gov/dads/HTML/fisherYatesShuffle.html\n| date = 2005-12-19\n| accessdate = 2007-08-09\n}}\n</ref>  This change gives the following algorithm (for a zero-based [[Array data structure|array]]).\n\n -- To shuffle an array ''a'' of ''n'' elements (indices 0..''n''-1):\n '''for''' ''i'' '''from''' ''n''−1 '''downto''' 1 '''do'''\n      ''j'' ← random integer such that 0 ≤ ''j'' ≤ ''i''\n      exchange ''a''[''j''] and ''a''[''i'']\n\nAn equivalent version which shuffles the array in the opposite direction (from lowest index to highest) is:\n -- To shuffle an array ''a'' of ''n'' elements (indices 0..''n''-1):\n '''for''' ''i'' '''from''' 0 '''to''' ''n''−2 '''do'''\n      ''j'' ← random integer such that ''i'' ≤ ''j'' < ''n''\n      exchange ''a''[''i''] and ''a''[''j'']\n\n== Examples ==\n\n=== Pencil-and-paper method ===\n\nAs an example, we'll permute the numbers from 1 to 8 using [[#Fisher and Yates' original method|Fisher and Yates' original method]].  We'll start by writing the numbers out on a piece of scratch paper:\n\n{| class=\"wikitable\"\n|-\n! Range !! Roll !! Scratch !! Result\n|-\n| &nbsp; || &nbsp; || 1 2 3 4 5 6 7 8 || &nbsp;\n|}\n\nNow we roll a random number ''k'' from 1 to 8—let's make it 3—and strike out the ''k''th (i.e. third) number (3, of course) on the scratch pad and write it down as the result:\n\n{| class=\"wikitable\"\n|-\n! Range !! Roll !! Scratch !! Result\n|-\n| 1–8 || 3 || 1 2 <s><span style=\"color:gray;\">3</span></s> 4 5 6 7 8 || 3\n|}\n\nNow we pick a second random number, this time from 1 to 7: it turns out to be 4.  Now we strike out the fourth number ''not yet struck'' off the scratch pad—that's number 5—and add it to the result:\n\n{| class=\"wikitable\"\n|-\n! Range !! Roll !! Scratch !! Result\n|-\n| 1–7 || 4 || 1 2 <s><span style=\"color:gray;\">3</span></s> 4 <s><span style=\"color:gray;\">5</span></s> 6 7 8 || 3 5\n|}\n\nNow we pick the next random number from 1 to 6, and then from 1 to 5, and so on, always repeating the strike-out process as above:\n\n{| class=\"wikitable\"\n|-\n! Range !! Roll !! Scratch !! Result\n|-\n| 1–6 || 5 || 1 2 <s><span style=\"color:gray;\">3</span></s> 4 <s><span style=\"color:gray;\">5</span></s> 6 <s><span style=\"color:gray;\">7</span></s> 8 || 3 5 7\n|-\n| 1–5 || 3 || 1 2 <s><span style=\"color:gray;\">3</span></s> <s><span style=\"color:gray;\">4</span></s> <s><span style=\"color:gray;\">5</span></s> 6 <s><span style=\"color:gray;\">7</span></s> 8 || 3 5 7 4\n|-\n| 1–4 || 4 || 1 2 <s><span style=\"color:gray;\">3</span></s> <s><span style=\"color:gray;\">4</span></s> <s><span style=\"color:gray;\">5</span></s> 6 <s><span style=\"color:gray;\">7</span></s> <s><span style=\"color:gray;\">8</span></s> || 3 5 7 4 8\n|-\n| 1–3 || 1 || <s><span style=\"color:gray;\">1</span></s> 2 <s><span style=\"color:gray;\">3</span></s> <s><span style=\"color:gray;\">4</span></s> <s><span style=\"color:gray;\">5</span></s> 6 <s><span style=\"color:gray;\">7</span></s> <s><span style=\"color:gray;\">8</span></s> || 3 5 7 4 8 1\n|-\n| 1–2 || 2 || <s><span style=\"color:gray;\">1</span></s> 2 <s><span style=\"color:gray;\">3</span></s> <s><span style=\"color:gray;\">4</span></s> <s><span style=\"color:gray;\">5</span></s> <s><span style=\"color:gray;\">6</span></s> <s><span style=\"color:gray;\">7</span></s> <s><span style=\"color:gray;\">8</span></s> || 3 5 7 4 8 1 6\n|-\n| &nbsp; || &nbsp; || <s><span style=\"color:gray;\">1</span></s> <s><span style=\"color:gray;\">2</span></s> <s><span style=\"color:gray;\">3</span></s> <s><span style=\"color:gray;\">4</span></s> <s><span style=\"color:gray;\">5</span></s> <s><span style=\"color:gray;\">6</span></s> <s><span style=\"color:gray;\">7</span></s> <s><span style=\"color:gray;\">8</span></s> || 3 5 7 4 8 1 6 2\n|}\n\n=== Modern method ===\n\nWe'll now do the same thing using [[#The modern algorithm|Durstenfeld's version]] of the algorithm: this time, instead of striking out the chosen numbers and copying them elsewhere, we'll swap them with the last number not yet chosen.  We'll start by writing out the numbers from 1 to 8 as before:\n\n{| class=\"wikitable\"\n|-\n! Range !! Roll !! Scratch !! Result\n|-\n| &nbsp; || &nbsp; || 1 2 3 4 5 6 7 8 || &nbsp;\n|}\n\nFor our first roll, we roll a random number from 1 to 8: this time it is 6, so we swap the 6th and 8th numbers in the list:\n\n{| class=\"wikitable\"\n|-\n! Range !! Roll !! Scratch !! Result\n|-\n| 1–8 || 6 || 1 2 3 4 5 '''8''' 7 || '''6'''\n|}\n\nThe next random number we roll from 1 to 7, and turns out to be 2.  Thus, we swap the 2nd and 7th numbers and move on:\n\n{| class=\"wikitable\"\n|-\n! Range !! Roll !! Scratch !! Result\n|-\n| 1–7 || 2 || 1 '''7''' 3 4 5 8 || '''2''' 6\n|}\n\nThe next random number we roll is from 1 to 6, and just happens to be 6, which means we leave the 6th number in the list (which, after the swap above, is now number 8) in place and just move to the next step.  Again, we proceed the same way until the permutation is complete:\n\n{| class=\"wikitable\"\n|-\n! Range !! Roll !! Scratch !! Result\n|-\n| 1–6 || 6 || 1 7 3 4 5 || '''8''' 2 6\n|-\n| 1–5 || 1 || align=\"right\" | '''5''' 7 3 4 || '''1''' 8 2 6\n|-\n| 1–4 || 3 || align=\"right\" | 5 7 '''4''' || '''3''' 1 8 2 6\n|-\n| 1–3 || 3 || align=\"right\" | 5 7 || '''4''' 3 1 8 2 6\n|-\n| 1–2 || 1 || align=\"right\" | '''7''' || '''5''' 4 3 1 8 2 6\n|}\n\nAt this point there's nothing more that can be done, so the resulting permutation is 7 5 4 3 1 8 2 6.\n\n== Variants ==\n\n=== The \"inside-out\" algorithm ===\n{{original research|section|date=April 2017}}\nThe Fisher–Yates shuffle, as implemented by Durstenfeld, is an ''in-place shuffle''. That is, given a preinitialized array, it shuffles the elements of the array in place, rather than producing a shuffled copy of the array. This can be an advantage if the array to be shuffled is large.\n\nTo simultaneously initialize and shuffle an array, a bit more efficiency can be attained by doing an \"inside-out\" version of the shuffle.  In this version, one successively places element number ''i'' into a random position among the first ''i'' positions in the array, after moving the element previously occupying that position to position ''i''.  In case the random position happens to be number ''i'', this \"move\" (to the same place) involves an uninitialised value, but that does not matter, as the value is then immediately overwritten. No separate initialization is needed, and no exchange is performed. In the common case where ''source'' is defined by some simple function, such as the integers from 0 to ''n''&nbsp;−&nbsp;1, ''source'' can simply be replaced with the function since ''source'' is never altered during execution.\n\n To initialize an array ''a'' of ''n'' elements to a randomly shuffled copy of ''source'', both 0-based:\n   '''for''' ''i'' '''from''' 0 '''to''' ''n'' − 1 '''do'''\n       ''j'' ← random integer such that 0 ≤ ''j'' ≤ ''i''\n       '''if''' ''j'' ≠ ''i''\n           ''a''[''i''] ← ''a''[''j'']\n       ''a''[''j''] ← ''source''[''i'']\n\nThe inside-out shuffle can be seen to be correct by [[Mathematical induction|induction]]. Assuming a perfect random number generator, every one of the ''n''! different sequences of random numbers that could be obtained from the calls of ''random'' will produce a different permutation of the values, so all of these are obtained exactly once. The condition that checks if ''j'' ≠ ''i'' may be omitted in languages that have no problems accessing uninitialized array values, and for which assigning is cheaper than comparing.\n\nAnother advantage of this technique is that the algorithm can be modified so that even when we do not know \"n\", the number of elements in ''source'', we can still generate a uniformly distributed random permutation of the ''source'' data. Below the array ''a'' is built iteratively starting from empty, and ''a''.length represents the current number of elements seen.\n\n To initialize an empty array ''a'' to a randomly shuffled copy of ''source'' whose length is not known:\n   '''while''' ''source''.moreDataAvailable\n       ''j'' ← random integer such that 0 ≤ ''j'' ≤ ''a''.length\n       '''if''' j = ''a''.length\n           ''a''.append(''source''.next)\n       '''else'''\n           ''a''.append(''a''[''j''])\n           ''a''[''j''] ← ''source''.next\n\n=== Sattolo's algorithm ===\n\nA very similar algorithm was published in 1986 by [[Sandra Sattolo]] for generating uniformly distributed [[cyclic permutation|cycle]]s of (maximal) length ''n''.<ref name=\"sattolo\">\n{{cite journal\n| last = Sattolo\n| first = Sandra\n| date = 1986-05-30\n| title =  An algorithm to generate a random cyclic permutation| journal = Information Processing Letters|  volume = 22\n| issue = 6\n| pages = 315–3017\n| doi=10.1016/0020-0190(86)90073-6\n}}\n</ref><ref name=\"wilson\">\n{{cite conference\n| last = Wilson\n| first = Mark C.\n| date = 2004-06-21\n| title = Overview of Sattolo's Algorithm\n| url = http://algo.inria.fr/seminars/summary/Wilson2004b.pdf\n| conference = Algorithms Seminar 2002–2004\n| conferenceurl = http://algo.inria.fr/seminars/allyears.html\n| editor = F. Chyzak\n| others = summary by Éric Fusy.\n| booktitle = INRIA Research Report\n| volume = 5542\n| pages = 105–108\n|issn=0249-6399\n}}\n</ref> The only difference between Durstenfeld's and Sattolo's algorithms is that in the latter, in step 2 above, the random number ''j'' is chosen from the range between 1 and ''i''−1 (rather than between 1 and ''i'') inclusive.  This simple change modifies the algorithm so that the resulting permutation always consists of a single cycle.\n\nIn fact, as described below, it is quite easy to ''accidentally'' implement Sattolo's algorithm when the ordinary Fisher–Yates shuffle is intended.  This will bias the results by causing the permutations to be picked from the smaller set of (''n''−1)! cycles of length ''N'', instead of from the full set of all ''n''! possible permutations.\n\nThe fact that Sattolo's algorithm always produces a cycle of length ''n'' can be shown by [[Mathematical induction|induction]]. Assume by induction that after the initial iteration of the loop, the remaining iterations permute the first ''n''&nbsp;−&nbsp;1 elements according to a cycle of length ''n''&nbsp;−&nbsp;1 (those remaining iterations are just Sattolo's algorithm applied to those first ''n''&nbsp;−&nbsp;1 elements). This means that tracing the initial element to its new position ''p'', then the element originally at position ''p'' to its new position, and so forth, one only gets back to the initial position after having visited all other positions. Suppose the initial iteration swapped the final element with the one at (non-final) position ''k'', and that the subsequent permutation of first ''n''&nbsp;−&nbsp;1 elements then moved it to position&nbsp;''l''; we compare the permutation&nbsp;''π'' of all ''n'' elements with that remaining permutation&nbsp;''σ'' of the first ''n''&nbsp;−&nbsp;1 elements. Tracing successive positions as just mentioned, there is no difference between ''π'' and ''σ'' until arriving at position&nbsp;''k''. But then, under&nbsp;''π'' the element originally at position&nbsp;''k'' is moved to the final position rather than to position&nbsp;''l'', and the element originally at the final position is moved to position&nbsp;''l''. From there on, the sequence of positions for&nbsp;''π'' again follows the sequence for&nbsp;''σ'', and all positions will have been visited before getting back to the initial position, as required.\n\nAs for the equal probability of the permutations, it suffices to observe that the modified algorithm involves (''n''−1)! distinct possible sequences of random numbers produced, each of which clearly produces a different permutation, and each of which occurs—assuming the random number source is unbiased—with equal probability.  The (''n''−1)! different permutations so produced precisely exhaust the set of cycles of length ''n'': each such cycle has a unique [[cycle notation]] with the value ''n'' in the final position, which allows for (''n''−1)! permutations of the remaining values to fill the other positions of the cycle notation.\n\nA sample implementation of Sattolo's algorithm in [[Python (programming language)|Python]] is:\n\n<source lang=\"python\">\nfrom random import randrange\n\ndef sattoloCycle(items):\n    i = len(items)\n    while i > 1:\n        i = i - 1\n        j = randrange(i)  # 0 <= j <= i-1\n        items[j], items[i] = items[i], items[j]\n</source>\n\n== Comparison with other shuffling algorithms ==\n\nThe asymptotic time and space complexity of the Fisher–Yates shuffle are optimal.  Combined with a high-quality unbiased random number source, it is also guaranteed to produce unbiased results.  Compared to some other solutions, it also has the advantage that, if only part of the resulting permutation is needed, it can be stopped halfway through, or even stopped and restarted repeatedly, generating the permutation incrementally as needed.\n\nAn alternative method assigns a random number to each element of the set to be shuffled and then sorts the set according to the assigned numbers. The sorting method has the same asymptotic time complexity as Fisher–Yates: although general sorting is ''O''(''n''&nbsp;log&nbsp;''n''), numbers are efficiently sorted using [[Radix sort]] in ''O''(''n'') time. Like the Fisher–Yates shuffle, the sorting method produces unbiased results.  However, care must be taken to ensure that the assigned random numbers are never duplicated, since sorting algorithms typically don't order elements randomly in case of a tie.<ref>{{cite web |work=Oleg Kiselyov |title=Provably perfect shuffle algorithms |url=http://okmij.org/ftp/Haskell/perfect-shuffle.txt |date=3 Sep 2001 |accessdate=2013-07-09}}</ref>  Additionally, this method requires asymptotically larger space: ''O''(''n'') additional storage space for the random numbers, versus ''O''(1) space for the Fisher–Yates shuffle.  Finally, we note that the sorting method has a simple parallel implementation, unlike the Fisher–Yates shuffle, which is sequential.\n\nA variant of the above method that has seen some use in languages that support sorting with user-specified comparison functions is to shuffle a list by sorting it with a comparison function that returns random values.  However, ''this is an extremely bad method'': it is very likely to produce highly non-uniform distributions, which in addition depends heavily on the sorting algorithm used.<ref>\n{{cite web\n| work = require ‘brain’\n| title = A simple shuffle that proved not so simple after all\n| url = http://szeryf.wordpress.com/2007/06/19/a-simple-shuffle-that-proved-not-so-simple-after-all/\n| date = 2007-06-19\n| accessdate = 2007-08-09\n}} <!-- TODO: could use a more authoritative reference, although this ought to suffice to demonstrate the point -->\n</ref><ref>\n{{cite web\n| work = Rob Weir: An Antic Disposition\n| title = Doing the Microsoft Shuffle: Algorithm Fail in Browser Ballot\n| url = http://www.robweir.com/blog/2010/02/microsoft-random-browser-ballot.html\n| date = 2010-02-27\n| accessdate = 2010-02-28\n}}\n</ref>\nFor instance suppose [[quicksort]] is used as sorting algorithm, with a fixed element selected as first [[pivot element]]. The algorithm starts comparing the pivot with all other elements to separate them into those less and those greater than it, and the relative sizes of those groups will determine the final place of the pivot element. For a uniformly distributed [[random permutation]], each possible final position should be equally likely for the pivot element, but if each of the initial comparisons returns \"less\" or \"greater\" with equal probability, then that position will have a [[binomial distribution]] for ''p''&nbsp;=&nbsp;1/2, which gives positions near the middle of the sequence with a much higher probability for than positions near the ends. Randomized comparison functions applied to other sorting methods like [[merge sort]] may produce results that appear more uniform, but are not quite so either, since merging two sequences by repeatedly choosing one of them with equal probability (until the choice is forced by the exhaustion of one sequence) does not produce results with a uniform distribution; instead the probability to choose a sequence should be proportional to the number of elements left in it{{Citation needed|date=February 2019}}. In fact no method that uses only two-way random events with equal probability ([[Bernoulli process|\"coin flipping\"]]), repeated a bounded number of times, can produce permutations of a sequence (of more than two elements) with a uniform distribution, because every execution path will have as probability a rational number with as denominator a [[power of 2]], while the required probability 1/''n''! for each possible permutation is not of that form{{Citation needed|date=February 2019}}.\n\nIn principle this shuffling method can even result in program failures like endless loops or access violations, because the correctness of a sorting algorithm may depend on properties of the order relation (like [[transitive relation|transitivity]]) that a comparison producing random values will certainly not have.<ref>\n{{cite web\n| work = require ‘brain’\n| title = Writing a sort comparison function, redux\n| url = http://blogs.msdn.com/oldnewthing/archive/2009/05/08/9595334.aspx\n| date = 2009-05-08\n| accessdate = 2009-05-08\n}}\n</ref>\nWhile this kind of behaviour should not occur with sorting routines that never perform a comparison whose outcome can be predicted with certainty (based on previous comparisons), there can be valid reasons for deliberately making such comparisons. For instance the fact that any element should compare equal to itself allows using them as [[sentinel value]] for efficiency reasons, and if this is the case, a random comparison function would break the sorting algorithm.\n\n== Potential sources of bias ==\n\nCare must be taken when implementing the Fisher–Yates shuffle, both in the implementation of the algorithm itself and in the generation of the random numbers it is built on, otherwise the results may show detectable bias.  A number of common sources of bias have been listed below.\n\n=== Implementation errors ===\n\nA common error when implementing the Fisher–Yates shuffle is to pick the random numbers from the wrong range. The flawed algorithm may appear to work correctly, but it will not produce each possible permutation with equal probability, and it may not produce certain permutations at all.  For example, a common [[off-by-one error]] would be choosing the index ''j'' of the entry to swap in [[#The modern algorithm|the example above]] to be always strictly less than the index ''i'' of the entry it will be swapped with. This turns the Fisher–Yates shuffle into [[#Sattolo's algorithm|Sattolo's algorithm]], which produces only permutations consisting of a single cycle involving all elements: in particular, with this modification, no element of the array can ever end up in its original position.\n\n[[Image:Probabilities7.svg|thumb|Order bias from incorrect implementation]]\n[[Image:Orderbias.png|thumb|Order bias from incorrect implementation - n = 1000]]\nSimilarly, always selecting ''j'' from the entire range of valid array indices on ''every'' iteration also produces a result which is biased, albeit less obviously so.  This can be seen from the fact that doing so yields ''n''<sup>''n''</sup> distinct possible sequences of swaps, whereas there are only [[factorial|''n''!]] possible permutations of an ''n''-element array.  Since ''n''<sup>''n''</sup> can never be evenly divisible by ''n''!  when ''n'' &gt; 2 (as the latter is divisible by ''n''−1, which shares no [[prime factor]]s with ''n''), some permutations must be produced by more of the ''n''<sup>''n''</sup> sequences of swaps than others.  As a concrete example of this bias, observe the distribution of possible outcomes of shuffling a three-element array [1, 2, 3].  There are 6 possible permutations of this array (3! = 6), but the algorithm produces 27 possible shuffles (3<sup>3</sup> = 27).  In this case, [1, 2, 3], [3, 1, 2], and [3, 2, 1] each result from 4 of the 27 shuffles, while each of the remaining 3 permutations occurs in 5 of the 27 shuffles.\n\nThe matrix to the right shows the probability of each element in a list of length 7 ending up in any other position.  Observe that for most elements, ending up in their original position (the matrix's main diagonal) has lowest probability, and moving one slot backwards has highest probability.\n\n=== Modulo bias ===\n{{unreferenced section|date=April 2017}}\nDoing a Fisher–Yates shuffle involves picking [[uniform distribution (discrete)|uniformly distributed]] random integers from various ranges.  Most [[random number generator]]s, however — whether true or [[pseudorandom]] — will only directly provide numbers in a fixed range from 0 to RAND_MAX, and in some libraries, RAND_MAX may be as low as 32767.<ref>''[https://www.gnu.org/software/libc/manual/html_node/ISO-Random.html The GNU C Library: ISO Random]''</ref>  A simple and commonly used way to force such numbers into a desired range is to apply the [[modulo operator]]; that is, to divide them by the size of the range and take the remainder.  However, the need in a Fisher–Yates shuffle to generate random numbers in every range from 0–1 to 0–''n'' pretty much guarantees that some of these ranges will not evenly divide the natural range of the random number generator.  Thus, the remainders will not always be evenly distributed and, worse yet, the bias will be systematically in favor of small remainders.\n\nFor example, assume that your random number source gives numbers from 0 to 99 (as was the case for Fisher and Yates' original tables), and that you wish to obtain an unbiased random number from 0 to 15.  If you simply divide the numbers by 16 and take the remainder, you'll find that the numbers 0–3 occur about 17% more often than others.  This is because 16 does not evenly divide 100: the largest multiple of 16 less than or equal to 100 is 6×16 = 96, and it is the numbers in the incomplete range 96–99 that cause the bias.  The simplest way to fix the problem is to discard those numbers before taking the remainder and to keep trying again until a number in the suitable range comes up.  While in principle this could, in the worst case, take forever, the [[expected value|expected number]] of retries will always be less than one.\n\nA related problem occurs with implementations that first generate a random [[floating-point]] number—usually in the range [0,1)—and then multiply it by the size of the desired range and round down.  The problem here is that random floating-point numbers, however carefully generated, always have only finite precision.  This means that there are only a finite number of possible floating point values in any given range, and if the range is divided into a number of segments that doesn't divide this number evenly, some segments will end up with more possible values than others.  While the resulting bias will not show the same systematic downward trend as in the previous case, it will still be there.\n\n=== Pseudorandom generators ===\n{{unreferenced section|date=April 2017}}\n{| class=\"wikitable\" style=\"margin:0 0 0 1em; text-align:right; float:right;\"\n|+ Size of PRNG seeds and the largest list where every permutation could be reached\n|-\n! seed bits\n! maximum list length\n|-\n| 0 || 1\n|-\n| 1 || 2\n|-\n| 3 || 3\n|-\n| 5 || 4\n|-\n| 7 || 5\n|-\n| 10 || 6\n|-\n| 13 || 7\n|-\n| 16 || 8\n|-\n| 22 || 10\n|-\n| 24 || 10\n|-\n| <!--numerous--> 32 || 12\n|-\n| <!--java.util.Random--> 48 || 16\n|-\n| 64 || 20\n|-\n| 128 || 34\n|-\n| <!--SHA-1--> 160 || 40\n|-\n| 226 || <!--deck of cards--> 52\n|-\n| <!--SHA-256--> 256 || 57\n|-\n| <!--SHA-512--> 512 || 98\n|-\n| 1024 || 170\n|-\n| <!--SHA-3--> 1600 || 245\n|-\n| <!--MT19937--> 19937 || 2080\n|-\n| <!--WELL44497--> 44497 || 4199\n|}\n\nAn additional problem occurs when the Fisher–Yates shuffle is used with a [[pseudorandom number generator]] or PRNG: as the sequence of numbers output by such a generator is entirely determined by its internal state at the start of a sequence, a shuffle driven by such a generator cannot possibly produce more distinct permutations than the generator has distinct possible states.<ref>{{cite book|last1=Arndt|first1=Jörg|title=Generating Random Permutations (PhD Thesis)|date=2009|publisher=Australian National University|page=9|url=https://maths-people.anu.edu.au/~brent/pd/Arndt-thesis.pdf|accessdate=25 April 2018}}</ref>  Even when the number of possible states exceeds the number of permutations, the irregular nature of the mapping from sequences of numbers to permutations means that some permutations will occur more often than others.  Thus, to minimize bias, the number of states of the PRNG should exceed the number of permutations by at least several orders of magnitude.\n\nFor example, the built-in pseudorandom number generator provided by many programming languages and/or libraries may often have only 32 bits of internal state, which means it can only produce 2<sup>32</sup> different sequences of numbers.  If such a generator is used to shuffle a deck of 52 [[playing card]]s, it can only ever produce a very small fraction of the [[factorial|52!]] ≈ 2<sup>225.6</sup> possible permutations.  It is impossible for a generator with less than 226 bits of internal state to produce all the possible permutations of a 52-card deck.\n\nNo pseudorandom number generator can produce more distinct sequences, starting from the point of initialization, than there are distinct seed values it may be initialized with.  Thus, a generator that has 1024 bits of internal state but which is initialized with a 32-bit seed can still only produce 2<sup>32</sup> different permutations right after initialization. It can produce more permutations if one exercises the generator a great many times before starting to use it for generating permutations, but this is a very inefficient way of increasing randomness: supposing one can arrange to use the generator a random number of up to a billion, say 2<sup>30</sup> for simplicity, times between initialization and generating permutations, then the number of possible permutations is still only 2<sup>62</sup>.\n\nA further problem occurs when a simple [[linear congruential generator|linear congruential]] PRNG is used with the divide-and-take-remainder method of range reduction described above.  The problem here is that the low-order bits of a linear congruential PRNG with modulo 2<sup>''e''</sup> are less random than the high-order ones:<ref name=\"knuth3\" /> the low ''n'' bits of the generator themselves have a period of at most 2<sup>''n''</sup>.  When the divisor is a power of two, taking the remainder essentially means throwing away the high-order bits, such that one ends up with a significantly less random value. Different rules apply if the [[linear congruential generator|LCG]] has prime modulo, but such generators are uncommon. This is an example of the general rule that a poor-quality RNG or PRNG will produce poor-quality shuffles.\n\n== See also ==\n* [[RC4]], a stream cipher based on shuffling an array\n* [[Reservoir sampling]], in particular Algorithm R which is a specialization of the Fisher–Yates shuffle\n\n== References ==\n{{reflist|30em}}\n\n==External links==\n* [http://bost.ocks.org/mike/shuffle/ An interactive example]\n\n{{Donald Knuth navbox}}\n\n{{DEFAULTSORT:Fisher-Yates shuffle}}\n[[Category:Combinatorial algorithms]]\n[[Category:Randomized algorithms]]\n[[Category:Permutations]]\n[[Category:Monte Carlo methods]]\n[[Category:Articles with example pseudocode]]"
    },
    {
      "title": "Gillespie algorithm",
      "url": "https://en.wikipedia.org/wiki/Gillespie_algorithm",
      "text": "In [[probability theory]], the '''Gillespie algorithm''' (or occasionally the '''Doob-Gillespie algorithm''') generates a statistically correct trajectory (possible solution) of a [[stochastic]] equation. It was created by [[Joseph L. Doob]] and others (circa 1945), presented by [[Dan Gillespie]] in 1976, and popularized in 1977 in a paper where he uses it to simulate chemical or biochemical systems of reactions efficiently and accurately using limited computational power (see [[stochastic simulation]]){{citation needed|date=June 2016}}. As computers have become faster, the algorithm has been used to simulate increasingly complex systems. The algorithm is particularly useful for simulating reactions within cells, where the number of [[reagent]]s is low and keeping track of the position and behaviour of individual molecules is computationally feasible. Mathematically, it is a variant of a [[dynamic Monte Carlo method]] and similar to the [[kinetic Monte Carlo]] methods. It is used heavily in [[computational systems biology]].{{citation needed|date=June 2012}}\n\n==History==\nThe process that led to the algorithm recognizes several important steps. In 1931, [[Andrei Kolmogorov]] introduced the differential equations corresponding to the time-evolution of stochastic processes that proceed by jumps, today known as [[Kolmogorov equations (Markov jump process)]] (a simplified version is known as [[master equation]] in the natural sciences). It was [[William Feller]], in 1940, who found the conditions under which the Kolmogorov equations admitted (proper) probabilities as solutions. In his Theorem I (1940 work) he establishes that the time-to-the-next-jump was exponentially distributed and the probability of the next event is proportional to the rate. As such, he established the relation of Kolmogorov's equations with [[stochastic process]]es.\nLater, Doob (1942, 1945) extended Feller's solutions beyond the case of pure-jump processes. The method was implemented in computers by [[David George Kendall]] (1950) using the [[Manchester Mark 1]] computer and later used by [[Maurice S. Bartlett]] (1953) in his studies of epidemics outbreaks. Gillespie (1977) obtains the algorithm in a different manner by making use of a physical argument.\n\n==Idea behind the algorithm==\nTraditional continuous and deterministic biochemical rate equations do not accurately predict cellular reactions since they rely on bulk reactions that require the interactions of millions of molecules. They are typically modeled as a set of coupled ordinary differential equations. In contrast, the Gillespie algorithm allows a discrete and stochastic simulation of a system with few reactants because every reaction is explicitly simulated. A trajectory corresponding to a single Gillespie simulation represents an exact sample from the probability mass function that is the solution of the [[master equation]].\n\nThe physical basis of the algorithm is the collision of molecules within a reaction vessel. It is assumed that collisions are frequent, but collisions with the proper orientation and energy are infrequent. Therefore, all reactions within the Gillespie framework must involve at most two molecules. Reactions involving three molecules are assumed to be extremely rare and are modeled as a sequence of binary reactions. It is also assumed that the reaction environment is well mixed.\n\n\n==Algorithm==\nGillespie developed two different, but equivalent formulations; the direct method and the first reaction method. Below is a summary of the steps to run the algorithm (math omitted):\n\n# '''Initialization''': Initialize the number of molecules in the system, reaction constants, and random number generators.\n# '''Monte Carlo step''': Generate random numbers to determine the next reaction to occur as well as the time interval. The probability of a given reaction to be chosen is proportional to the number of substrate molecules, the time interval is exponentially distributed with mean <math>1/R_\\mathrm{TOT}</math>.\n# '''Update''': Increase the time by the randomly generated time in Step 2. Update the molecule count based on the reaction that occurred.\n# '''Iterate''': Go back to Step 2 unless the number of reactants is zero or the simulation time has been exceeded.\n\nThe algorithm is computationally expensive and thus many modifications and adaptations exist, including the next reaction method (Gibson & Bruck), [[tau-leaping]], as well as hybrid techniques where abundant reactants are modeled with deterministic behavior. Adapted techniques generally compromise the exactitude of the theory behind the algorithm as it connects to the Master equation, but offer reasonable realizations for greatly improved timescales. The computational cost of exact versions of the algorithm is determined by the coupling class of the reaction network. In weakly coupled networks, the number of reactions that is influenced by any other reaction is bounded by a small constant. In strongly coupled networks, a single reaction firing can in principle affect all other reactions. An exact version of the algorithm with constant-time scaling for weakly coupled networks has been developed, enabling efficient simulation of systems with very large numbers of reaction channels (Slepoy Thompson Plimpton 2008). The generalized Gillespie algorithm that accounts for the non-Markovian properties of random biochemical events with delay has been developed by Bratsun et al. 2005 and independently Barrio et al. 2006, as well as (Cai 2007). See the articles cited below for details.\n\nPartial-propensity formulations, as developed independently by both Ramaswamy et al. (2009, 2010) and Indurkhya and Beal (2010), are available to construct a family of exact versions of the algorithm whose computational cost is proportional to the number of chemical species in the network, rather than the (larger) number of reactions. These formulations can reduce the computational cost to constant-time scaling for weakly coupled networks and to scale at most linearly with the number of species for strongly coupled networks. A partial-propensity variant of the generalized Gillespie algorithm for reactions with delays has also been proposed (Ramaswamy Sbalzarini 2011). The use of partial-propensity methods is limited to elementary chemical reactions, i.e., reactions with at most two different reactants. Every non-elementary chemical reaction can be equivalently decomposed into a set of elementary ones, at the expense of a linear (in the order of the reaction) increase in network size.\n\n===Simple example: Reversible binding of A and B to form AB dimers===\nA simple example may help to explain how the Gillespie algorithm works. Consider a system of molecules of two types: {{math|A}} and {{math|B}}. In the system {{math|A}} and {{math|B}} reversibly bind together to form {{math|AB}} dimers. So there are two reactions. The first is where one molecule of {{math|A}} reacts reversibly with one B molecule to form an {{math|AB}} dimer, and the second is where an {{math|AB}} dimer dissociates into an {{math|A}} and a {{math|B}} molecule. The reaction rate constant for a given single A molecule reacting with a given single {{math|B}} molecule is <math>k_\\mathrm{D}</math>, and the reaction rate for an {{math|AB}} dimer breaking up is <math>k_\\mathrm{B}</math>.\n\nSo, for example if at time ''t'' there is one molecule of each type then the rate of dimer formation is <math>k_\\mathrm{D}</math>, while if there are <math>n_\\mathrm{A}</math> molecules of type {{math|A}} and <math>n_\\mathrm{B}</math> molecules of type {{math|B}}, the rate of dimer formation is <math>k_\\mathrm{D}n_\\mathrm{A}n_\\mathrm{B}</math>. If there are <math>n_\\mathrm{AB}</math> dimers then the rate of dimer dissociation is <math>k_\\mathrm{B}n_\\mathrm{AB}</math>.\n\nThe total reaction rate, <math>R_\\mathrm{TOT}</math>, at time ''t'' is then given by\n\n<math>R_\\mathrm{TOT}=k_\\mathrm{D}n_\\mathrm{A}n_\\mathrm{B}+k_\\mathrm{B}n_\\mathrm{AB}</math>\n\nSo, we have now described a simple model with two reactions. This definition is independent of the Gillespie algorithm. We will now describe how to apply the Gillespie algorithm to this system.\n\nIn the algorithm, we advance forward in time in two steps: calculating the time to the next reaction, and determining which of the possible reactions the next reaction is. Reactions are assumed to be completely random, so if the reaction rate at a time ''t'' is <math>R_\\mathrm{TOT}</math>, then the time, &delta;''t'', until the next reaction occurs is a random number drawn from exponential distribution function with mean <math>1/R_\\mathrm{TOT}</math>. Thus, we advance time from ''t'' to ''t'' + &delta;''t''.\n\n[[File:Example calculation illustrating the Gillespie algorithm for reversible dimerising molecules.png|thumb|Plot of the number {{math|A}} molecules (black curve) and {{math|AB}} dimers as a function of time. As we started with 10 {{math|A}} and {{math|B}} molecules at time ''t''=0, the number of {{math|B}} molecules is always equal to the number of {{math|A}} molecules and so it is not shown.]]\n\nThe probability that this reaction is an {{math|A}} molecule binding to a {{math|B}} molecule is simply the fraction of total rate due to this type of reaction, i.e.,\n\nthe probability that reaction is <math chem>P(\\ce{{A} + B -> AB}) = k_Dn_An_B/R_\\ce{TOT}</math>\n\nThe probability that the next reaction is an {{math|AB}} dimer dissociating is just 1 minus that. So with these two probabilities we either form a dimer by reducing <math>n_\\mathrm{A}</math> and <math>n_\\mathrm{B}</math> by one, and increase <math>n_\\mathrm{AB}</math> by one, or we dissociate a dimer and increase <math>n_\\mathrm{A}</math> and <math>n_\\mathrm{B}</math> by one and decrease <math>n_\\mathrm{AB}</math> by one.\n\nNow we have both advanced time to ''t'' + &delta;''t'', and performed a single reaction. The Gillespie algorithm just repeats these two steps as many times as needed to simulate the system for however long we want (i.e., for as many reactions). The result of a Gillespie simulation that starts with <math>n_\\mathrm{A}=n_\\mathrm{B}=10</math> and <math>n_\\mathrm{AB}=0</math> at ''t''=0, and where <math>k_\\mathrm{D}=2</math> and <math>k_\\mathrm{B}=1</math>, is shown at the right. For these parameter values, on average there are 8 <math>n_\\mathrm{AB}</math> dimers and 2 of {{math|A}} and {{math|B}} but due to the small numbers of molecules fluctuations around these values are large. The Gillespie algorithm is often used to study systems where these fluctuations are important.\n\nThat was just a simple example, with two reactions. More complex systems with more reactions are handled in the same way. All reaction rates must be calculated at each time step, and one chosen with probability equal to its fractional contribution to the rate. Time is then advanced as in this example.\n\n===Another example: The SIR epidemic without vital dynamics===\nThe [[SIR model]] is a classic biological description of how certain diseases permeate through a fixed-size population. In its simplest form there are <math>N</math> members of the population, whereby each member may be in one of three states -- susceptible, infected, or recovered -- at any instant in time, and each such member transitions irreversibly through these states according to the directed graph below. We can denote the number of susceptible members as <math>n_{S}</math>, the number of infected members as <math>n_{I}</math>, and the number of recovered members as <math>n_{R}</math>. Therefore we may also conclude that <math>N = n_{S} + n_{I} + n_{R}</math> for any point in time.\n\n[[File:SIR graph.png|400px|center]]\n\nFurther, a given susceptible member will transition to the infected state by coming into contact with any of the <math>n_{I}</math> infected members, and so infection occurs with rate <math>\\alpha n_{I}</math> (dimensions of inverse time).  A given member of the infected state recovers without dependence on any of the three states, which is specified by rate {{mvar|&beta;}} (also with dimensions of inverse time).  Given this basic scheme, it possible to construct the following non-linear system.\n\n[[File:SIR trajectory.png|thumb|A single realization of the SIR epidemic as produced with an implementation of the Gillespie algorithm.]]\n\n:<math> \\frac{dn_{S}}{dt} = - \\frac{\\alpha n_{S}}{V} n_{I}</math>,\n\n:<math> \\frac{d n_{I}}{dt} = \\left(\\frac{\\alpha n_{S}}{V}- \\beta\\right)n_{I}</math>,\n\n:<math> \\frac{d n_{R}}{dt} = \\beta n_{I} </math>.\n\nThis system has no analytical solution.  However, with the Gillespie algorithm, it can be simulated many times, and a regression technique such as least-squares may be applied to fit a polynomial over all of the trajectories.  As the number of trajectories increases, such polynomial regression will asymptotically behave like an analytic solution.  In addition to estimating the solution to an intractable problem like the SIR epidemic, the stochastic nature of each trajectory allows one to compute statistics other than <math>\\mathrm{E}[n|t]</math>.\n\nThe trajectory presented in the above figure was simulated with the following Python implementation of the Gillespie algorithm.\n\n<source lang=\"numpy\">\nimport math\nimport random\n\n### input parameters ####################\n\n# int; total population\nN = 350\n\n# float; maximum elapsed time\nT = 100.0\n\n# float; start time\nt = 0.0\n\n# float; spatial parameter\nV = 100.0\n\n# float; rate of infection after contact\n_alpha = 10.0 \n\n# float; rate of cure\n_beta = 0.5\n\n# int; initial infected population\nn_I = 1\n\n#########################################\n\n# compute susceptible population, set recovered to zero\nn_S = N - n_I\nn_R = 0\n\n# initialize results list\nSIR_data = []\nSIR_data.append((t, n_S, n_I, n_R))\n\n# main loop\nwhile t < T:\n\n\tif n_I == 0:\n\t\tbreak\n\n\tw1 = _alpha * n_S * n_I / V\n\tw2 = _beta * n_I\n\tW = w1 + w2\n\n\tdt = -math.log(random.uniform(0.0,1.0)) / W\n\tt = t + dt\n\t\n\tif random.uniform(0.0,1.0) < w1 / W:\n\t\tn_S = n_S - 1\n\t\tn_I = n_I + 1\n\n\telse:\n\t\tn_I = n_I - 1\n\t\tn_R = n_R + 1\n\n\tSIR_data.append((t, n_S, n_I, n_R))\n\nwith open('SIR_data.txt', 'w+') as fp:\n    fp.write('\\n'.join('%f %i %i %i' % x for x in SIR_data))\n</source>\n\n==Further reading==\n<!-- *[http://www.caam.rice.edu/~caam210/reac/lec.html Summary of Gillespie Algorithm with [[MATLAB]] examples] -->\n* {{cite journal |author=Gillespie, Daniel T. |title=Exact Stochastic Simulation of Coupled Chemical Reactions |journal=The Journal of Physical Chemistry |volume=81 |issue=25 |pages=2340&ndash;2361 |year=1977 |doi=10.1021/j100540a008 |citeseerx=10.1.1.704.7634 }}\n* {{cite journal |author=Gillespie, Daniel T. |title=A General Method for Numerically Simulating the Stochastic Time Evolution of Coupled Chemical Reactions |journal=Journal of Computational Physics |volume=22 |issue=4 |pages=403&ndash;434 |year=1976 |doi=10.1016/0021-9991(76)90041-3 |bibcode=1976JCoPh..22..403G }}\n* {{cite journal |author1=Gibson, Michael A. |author2=Bruck, Jehoshua |title=Efficient Exact Stochastic Simulation of Chemical Systems with Many Species and Many Channels |journal= Journal of Physical Chemistry A |volume=104 |pages=1876&ndash;1889 |year=2000 |doi=10.1021/jp993732q |issue=9 |bibcode=2000JPCA..104.1876G }}\n* {{cite journal |author=Doob, Jacob L. |title=Topics in the Theory of Markoff Chains |journal=Transactions of the American Mathematical Society |volume=52 |pages=37&ndash;64 |year=1942 |issue=1 |jstor=1990152 |doi=10.1090/S0002-9947-1942-0006633-7 }}\n* {{cite journal |author=Doob, Jacob L. |title=Markoff chains – Denumerable case |journal=Transactions of the American Mathematical Society |volume=58 |pages=455&ndash;473 |year=1945 |doi=10.2307/1990339 |issue=3 |jstor=1990339 }}\n* {{Cite book |last1=Press |first1=William H. |last2=Teukolsky |first2=Saul A. |last3=Vetterling |first3=William T. |last4=Flannery |first4=Brian P. |year=2007 |title=Numerical Recipes: The Art of Scientific Computing |edition=3rd |publisher=Cambridge University Press |location=New York, NY |isbn=978-0-521-88068-8 |chapter=Section 17.7. Stochastic Simulation of Chemical Reaction Networks |chapter-url=http://apps.nrbook.com/empanel/index.html#pg=946 }}\n* {{cite journal |author=Kolmogorov, Andrey N. |title=Über die analytischen Methoden in der Wahrscheinlichkeitsrechnung |trans-title=On Analytical Methods in the Theory of Probability |journal=Mathematische Annalen |volume=104 |pages=415–458 |year=1931 |doi=10.1007/BF01457949 }}\n* {{cite journal |author=Feller, Willy |title=On the Integro-Differential Equations of Purely Discontinuous Markoff Processes |journal=Transactions of the American Mathematical Society |volume= 48 |pages=4885&ndash;15 |year=1940 |jstor=1970064 |issue=3 |doi=10.2307/1990095}}\n* {{cite journal |author=Kendall, David G. |title=An Artificial Realization of a Simple \"Birth-and-Death\" Process |journal=Journal of the Royal Statistical Society, Series B |volume=12 |pages=116&ndash;119 |year=1950 |issue=1 |jstor=2983837 }}\n* {{cite journal |author=Bartlett, Maurice S. |title=Stochastic Processes or the Statistics of Change |journal=Journal of the Royal Statistical Society, Series C |volume=2 |pages=44&ndash;64 |year=1953 |issue=1 |jstor=2985327 }}\n* {{cite journal |author1=Rathinam, Muruhan |author2=[[Linda Petzold|Petzold, Linda R.]] |author3=Cao, Yang |author4=Gillespie, Daniel T.  |title=Stiffness in stochastic chemically reacting systems: The implicit tau-leaping method |journal=Journal of Chemical Physics |volume=119 |issue=24 |pages=12784&ndash;12794 |year=2003 |doi=10.1063/1.1627296 |bibcode=2003JChPh.11912784R }}\n* {{cite journal|last1=Sinitsyn |first1=Nikolai A. |last2=Hengartner |first2=Nicolas |last3=Nemenman |first3=Ilya |title=Adiabatic coarse-graining and simulations of stochastic biochemical networks |journal=Proceedings of the National Academy of Sciences of the United States of America |volume=106 |issue=20 |pages=10546&ndash;10551 |year=2009 |url=http://www.menem.com/~ilya/wiki/images/1/18/Sinitsyn-etal-09.pdf |doi=10.1073/pnas.0809340106 |pmid=19525397 |pmc=2705573 |deadurl=yes |archiveurl=https://web.archive.org/web/20110714072216/http://www.menem.com/~ilya/wiki/images/1/18/Sinitsyn-etal-09.pdf |archivedate=2011-07-14 |df= |bibcode=2009PNAS..10610546S }}\n* {{cite journal |last1=Salis |first1=Howard |last2=Kaznessis |first2=Yiannis N. |title=Accurate hybrid stochastic simulation of a system of coupled chemical or biochemical reactions |journal=Journal of Chemical Physics |volume=122 |pages=054103 |year=2005 |doi=10.1063/1.1835951 |pmid=15740306 |issue=5 |bibcode=2005JChPh.122e4103S }}\n* (Slepoy Thompson Plimpton 2008): {{cite journal |last1=Slepoy |first1=Alexander |last2=Thompson |first2=Aidan P. |last3=Plimpton |first3=Steven J. |title=A constant-time kinetic Monte Carlo algorithm for simulation of large biochemical reaction networks |journal=Journal of Chemical Physics |volume=128 |issue=20 |pages=205101 |year=2008 |doi=10.1063/1.2919546 |pmid=18513044 |bibcode=2008JChPh.128t5101S }}\n* (Bratsun et al. 2005): {{cite journal |author1=Bratsun, Dmitri |author2=Volfson, Dmitri |author3=Hasty, Jeff |author4=Tsimring, Lev S. |title=Delay-induced stochastic oscillations in gene regulation |journal=Proceedings of the National Academy of Sciences of the United States of America |volume=102 |issue=41 |pages=14593–8 |year=2005 |doi=10.1073/pnas.0503858102 |pmid=16199522 |pmc=1253555 |bibcode=2005PNAS..10214593B }}\n* (Barrio et al. 2006): {{cite journal |author1=Barrio, Manuel |author2=Burrage, Kevin |author3=Leier, André |author4=Tian, Tianhai |title=Oscillatory Regulation of ''hes1'': Discrete Stochastic Delay Modelling and Simulation |journal=PLoS Computational Biology |volume=2 |pages=1017 |year=2006 |doi=10.1371/journal.pcbi.0020117 |pmid=16965175 |issue=9 |pmc=1560403 |bibcode=2006PLSCB...2..117B }}\n* (Cai 2007): {{cite journal |author=Cai, Xiaodong |title=Exact stochastic simulation of coupled chemical reactions with delays |journal=Journal of Chemical Physics |volume=126 |pages=124108 |year=2007 |doi=10.1063/1.2710253 |issue=12 |pmid=17411109 |bibcode=2007JChPh.126l4108C }}\n* (Barnes Chu 2010): {{cite book |author1=Barnes, David J. |author2=Chu, Dominique |title=Introduction to Modeling for Biosciences |publisher=Springer Verlag |year=2010 }}\n* (Ramaswamy González-Segredo Sbalzarini 2009): {{cite journal |author1=Ramaswamy, Rajesh |author2=González-Segredo, Nélido |author3=Sbalzarini, Ivo F. |title=A new class of highly efficient exact stochastic simulation algorithms for chemical reaction networks |journal=Journal of Chemical Physics |volume=130 |pages=244104 |year=2009 |doi=10.1063/1.3154624 |issue=24 |pmid=19566139 |arxiv=0906.1992 |bibcode=2009JChPh.130x4104R }}\n* (Ramaswamy Sbalzarini 2010): {{cite journal |author1=Ramaswamy, Rajesh |author2=Sbalzarini, Ivo F. |title=A partial-propensity variant of the composition-rejection stochastic simulation algorithm for chemical reaction networks |journal=Journal of Chemical Physics |volume=132 |pages=044102 |year=2010 |doi=10.1063/1.3297948 |issue=4 |pmid=20113014 |bibcode=2010JChPh.132d4102R }}\n* (Indurkhya Beal 2010): {{cite journal |author1=Indurkhya, Sagar |author2=Beal, Jacob S.  |title=Reaction Factoring and Bipartite Update Graphs Accelerate the Gillespie Algorithm for Large-Scale Biochemical Systems |journal=PLoS ONE |volume=5 |issue=1 |pages=e8125 |year=2005 |doi=10.1371/journal.pone.0008125 |editor1-last=Isalan |editor1-first=Mark |pmid=20066048 |pmc=2798956 |bibcode=2010PLoSO...5.8125I }}\n* (Ramaswamy Sbalzarini 2011): {{cite journal |author1=Ramaswamy, Rajesh |author2=Sbalzarini, Ivo F. |title=A partial-propensity formulation of the stochastic simulation algorithm for chemical reaction networks with delays |journal=Journal of Chemical Physics |volume=134 |pages=014106 |year=2011 |doi=10.1063/1.3521496 |pmid=21218996 |issue=1 |bibcode=2011JChPh.134a4106R }}\n* (Yates Klingbeil 2013): {{cite journal |author1=Yates, Christian A. |author2=Klingbeil, Guido |title=Recycling random numbers in the stochastic simulation algorithm |journal=Journal of Chemical Physics |volume=138 |pages=094103 |year=2013 |doi=10.1063/1.4792207 |pmid=23485273 |issue=9 |bibcode=2013JChPh.138i4103Y }}\n\n==External links==\n;Software\n* [http://www.stochss.org/ StochSS] – a cloud computing framework for modeling and simulation of stochastic biochemical systems\n* [http://www.engineering.ucsb.edu/~cse/StochKit/ StochKit2] – stochastic simulation kit\n* [http://cain.sourceforge.net/ Cain] – stochastic simulation of chemical kinetics. Direct, next reaction, tau-leaping, hybrid, etc.\n* [http://stochpy.sourceforge.net/ StochPy] – stochastic modelling in Python\n* [http://synbioss.sourceforge.net/ SynBioSS] – Stochastic simulation of chemical kinetics using the exact SSA as well as an SSA/Langevin hybrid (Both MPI-parallel (supercomputer) and GUI (desktop) versions are provided.)\n* [https://cran.r-project.org/web/packages/GillespieSSA/index.html GillespieSSA] – R package for Gillespie algorithm\n* [http://demonstrations.wolfram.com/DeterministicVersusStochasticChemicalKinetics/] – Mathematica code and applet for stochastic simulation of chemical kinetics\n* [http://mosaic.mpi-cbg.de/?q=downloads/stochastic_chemical_net pSSAlib] – C++ implementations of all partial-propensity methods\n* [https://github.com/sdwfrost/Gillespie.jl Gillespie.jl] – Julia implementation of Gillespie's direct method\n\n[[Category:Chemical kinetics]]\n[[Category:Computational chemistry]]\n[[Category:Monte Carlo methods]]\n[[Category:Stochastic simulation]]"
    },
    {
      "title": "Hamiltonian Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo",
      "text": "In [[mathematics]] and [[physics]], '''Hamiltonian Monte Carlo''' algorithm (originally known as '''hybrid Monte Carlo'''), is a [[Markov chain Monte Carlo]] method for obtaining a sequence of [[Sampling (statistics)|random samples]] from a [[probability distribution]] for which direct sampling is difficult. This sequence can be used to approximate the distribution (i.e., to generate a [[histogram]]), or to compute an [[integral]] (such as an [[expected value]]).\n\nIt differs from the [[Metropolis–Hastings algorithm]] by reducing the correlation between successive sampled states by using a [[Hamiltonian mechanics|Hamiltonian]] evolution between states and additionally by targeting states with a higher acceptance criteria than the observed probability distribution. This causes it to converge more quickly to the absolute probability distribution. It was devised by Simon Duane, A.D. Kennedy, Brian Pendleton and Duncan Roweth in 1987,<ref>{{cite journal|last=Duane|first=Simon|author2=Kennedy, A.D.|author3=Pendleton, Brian J.|author4=Roweth, Duncan|title=Hybrid Monte Carlo|journal=Physics Letters B|date=3 September 1987|volume=195|issue=2|pages=216–222|doi=10.1016/0370-2693(87)91197-X |bibcode=1987PhLB..195..216D}}</ref> for calculations in [[lattice QCD|lattice quantum chromodynamics]].\n\n==See also==\n* [[Dynamic Monte Carlo method]]\n* [[List of software for Monte Carlo molecular modeling|Software for Monte Carlo molecular modeling]]\n* [[Stan (software)|Stan]]\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n* {{cite book\n    |last=Neal\n    |first=Radford M\n    |title=Handbook of Markov Chain Monte Carlo\n    |year=2011\n    |publisher=Chapman and Hall/CRC\n    |isbn=9781420079418\n    |editor=Steve Brooks |editor2=Andrew Gelman |editor3=Galin L. Jones |editor4=Xiao-Li Meng\n    |chapter=MCMC Using Hamiltonian Dynamics\n    |chapter-url=http://www.mcmchandbook.net/HandbookChapter5.pdf}}\n* {{Cite paper |title=A Conceptual Introduction to Hamiltonian Monte Carlo |first=Michael |last=Betancourt |year=2018 |arxiv=1701.02434 |bibcode=2017arXiv170102434B }}\n\n== External links ==\n* {{Cite web |title=Efficient Bayesian inference with Hamiltonian Monte Carlo |first=Michael |last=Betancourt |work=MLSS Iceland 2014 |via=[[YouTube]] |url=https://www.youtube.com/watch?v=pHsuIaPbNbY&list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF&index=11 }}\n\n[[Category:Monte Carlo methods]]  \n[[Category:Markov chain Monte Carlo]]"
    },
    {
      "title": "Importance sampling",
      "url": "https://en.wikipedia.org/wiki/Importance_sampling",
      "text": "{{short description|distribution estimation technique}}\nIn [[statistics]], '''importance sampling''' is a general technique for estimating properties of a particular [[probability distribution|distribution]], while only having samples generated from a different distribution than the distribution of interest.  It is related to [[umbrella sampling]] in [[computational physics]]. Depending on the application, the term may refer to the process of sampling from this alternative distribution, the process of inference, or both.\n\n== Basic theory ==\n<!-- '''E'''[''X;P''] / \\mathbf{E}[X;P] represents the expectation of ''X''. -->\n\nLet <math>X:\\Omega\\to \\mathbb{R}</math> be a [[random variable]] in some [[probability space]] <math>(\\Omega,\\mathcal{F},P)</math>. We wish to estimate the [[expected value]] of ''X'' under ''P'', denoted '''E'''[''X;P'']. If we have statistically independent random samples <math>x_1, \\ldots, x_n</math>, generated according to ''P'', then an empirical estimate of '''E'''[''X;P''] is\n\n: <math>\n  \\widehat{\\mathbf{E}}_{n}[X;P] = \\frac{1}{n} \\sum_{i=1}^n x_i\n</math>\n\nand the precision of this estimate depends on the variance of ''X'':\n\n: <math>\n   \\operatorname{var}[\\widehat{\\mathbf{E}}_{n};P] = \\frac{\\operatorname{var}[X;P]} n.\n</math>\n\nThe basic idea of importance sampling is to sample the states from a different distribution to lower the variance of the estimation of '''E'''[''X;P''], or when sampling from P is difficult.\nThis is accomplished by first choosing a random variable <math>L\\geq 0</math> such that '''E'''[''L'';''P'']&nbsp;=&nbsp;1 and that ''P''-[[almost everywhere]] <math>L(\\omega)\\neq 0</math>.\nWith the variate ''L'' we define a probability <math>P^{(L)}</math> that satisfies\n: <math>\n  \\mathbf{E}[X;P] = \\mathbf{E}\\left[\\frac{X}{L};P^{(L)}\\right].\n</math>\n\nThe variable ''X''/''L'' will thus be sampled under ''P''<sup>(''L'')</sup> to estimate '''E'''[''X;P''] as above and this estimation is improved when\n<math>\\operatorname{var}\\left[\\frac{X}{L};P^{(L)}\\right] < \\operatorname{var}[X;P]</math>.\n\nWhen ''X'' is of constant sign over Ω, the best variable ''L'' would clearly be <math>L^*=\\frac{X}{\\mathbf{E}[X;P]}\\geq 0</math>, so that ''X''/''L''* is the searched constant '''E'''[''X;P''] and a single sample under ''P''<sup>(''L''*)</sup> suffices to give its value. Unfortunately we cannot take that choice, because '''E'''[''X;P''] is precisely the value we are looking for! However this theoretical best case ''L*'' gives us an insight into what importance sampling does:\n\n: <math>\n\\begin{align}\\forall a\\in\\mathbb{R}, \\; P^{(L^*)}(X\\in[a;a+da]) &= \\int_{\\omega\\in\\{X\\in[a;a+da]\\}} \\frac{X(\\omega)}{E[X;P]} \\, dP(\\omega) \\\\[6pt] &= \\frac{1}{E[X;P]}\\; a\\,P(X\\in[a;a+da]) \n\\end{align}</math>\nto the right, <math>a\\,P(X\\in[a;a+da])</math> is one of the infinitesimal elements that sum up to '''E'''[''X'';''P'']:\n\n: <math>E[X;P] = \\int_{a=-\\infty}^{+\\infty} a\\,P(X\\in[a;a+da]) </math>\ntherefore, '''a good probability change ''P''<sup>(''L'')</sup> in importance sampling will redistribute the law of ''X'' so that its samples' frequencies are sorted directly according to their weights in''' '''E'''[''X'';''P'']. Hence the name \"importance sampling.\"\n\nImportance sampling is often used as a [[Monte Carlo integration|Monte Carlo integrator]].\nWhen <math>P</math> is the uniform distribution and <math>\\Omega =\\mathbb{R}</math>, '''E'''[''X;P''] corresponds to the integral of the real function <math>X:\\mathbb{R}\\to\\mathbb{R}</math>.\n\n== Application to probabilistic inference ==\n\nSuch methods are frequently used to estimate posterior densities or expectations in state and/or parameter estimation problems in probabilistic models that are too hard to treat analytically, for example in [[Bayesian network]]s.\n\n== Application to simulation ==\n'''Importance sampling''' is a [[variance reduction]] technique that can be used in the [[Monte Carlo method]]. The idea behind importance sampling is that certain values of the input [[random variables]] in a [[simulation]] have more impact on the parameter being estimated than others. If these \"important\" values are emphasized by sampling more frequently, then the [[estimator]] variance can be reduced. Hence, the basic methodology in importance sampling is to choose a distribution which \"encourages\" the important values. This use of \"biased\" distributions will result in a biased estimator if it is applied directly in the simulation. However, the simulation outputs are weighted to correct for the use of the biased distribution, and this ensures that the new importance sampling estimator is unbiased. The weight is given by the [[Likelihood-ratio test|likelihood ratio]], that is, the [[Radon–Nikodym derivative]] of the true underlying distribution with respect to the biased simulation distribution.\n\nThe fundamental issue in implementing importance sampling simulation is the choice of the biased distribution which encourages the important regions of the input variables. Choosing or designing a good biased distribution is the \"art\" of importance sampling. The rewards for a good distribution can be huge run-time savings; the penalty for a bad distribution can be longer run times than for a general Monte Carlo simulation without importance sampling.\n\nConsider <math>X</math> to be the sample and <math>\\frac{f(X)}{g(X)}</math> to be the likelihood ratio, where <math>f</math> is the probability density (mass) function of the desired distribution and <math>g</math> is the probability density (mass) function of the biased/proposal/sample distribution. Then the problem can be characterized by choosing the sample distribution <math>g</math> that minimizes the variance of the scaled sample:\n\n:<math>g^* = \\min_g \\operatorname{var}_g \\left( X \\frac{f(X)}{g(X)} \\right).</math>\n\nIt can be shown that the following distribution minimizes the above variance:<ref>Rubinstein, R. Y., & Kroese, D. P. (2011). Simulation and the Monte Carlo method (Vol. 707). John Wiley & Sons.</ref>\n\n:<math> \ng^*(X) = \\frac{|X| f(X)}{ \\int |x| f(x) \\, dx}.\n</math>\n\nIt is easy to see that when <math>X\\ge 0</math>, this variance becomes 0.\n\n=== Mathematical approach ===\n\nConsider estimating by simulation the probability <math>p_t\\,</math> of an event <math>X \\ge t</math>, where <math>X</math> is a random variable with [[probability distribution|distribution]] <math>F</math> and [[probability density function]] <math>f(x)= F'(x)\\,</math>, where prime denotes [[derivative]]. A <math>K</math>-length [[independent and identically distributed]] (i.i.d.) sequence <math>X_i\\,</math> is generated from the distribution <math>F</math>, and the number <math>k_t</math> of random variables that lie above the threshold <math>t</math> are counted. The random variable <math>k_t</math> is characterized by the [[Binomial distribution]]\n\n:<math>P(k_t = k)={K\\choose k}p_t^k(1-p_t)^{K-k},\\,\\quad \\quad k=0,1,\\dots,K.</math>\n\nOne can show that <math>\\operatorname{E} [k_t/K] = p_t</math>, and <math>\\operatorname{var} [k_t/K] = p_t(1-p_t)/K</math>, so in the limit <math>K \\to \\infty</math> we are able to obtain <math>p_t</math>.  Note that the variance is low if <math>p_t \\approx 1</math>.  Importance sampling is concerned with the determination and use of an alternate density function <math>f_*\\,</math>(for <math>X</math>), usually referred to as a biasing density, for the simulation experiment. This density allows the event <math>{ X \\ge t\\ }</math> to occur more frequently, so the sequence lengths <math>K</math> gets smaller for a given [[estimator]] variance. Alternatively, for a given <math>K</math>, use of the biasing density results in a variance smaller than that of the conventional Monte Carlo estimate. From the definition of <math>p_t\\,</math>, we can introduce <math>f_*\\,</math> as below.\n\n:<math>\n\\begin{align}\np_t & = {E} [1(X \\ge t)] \\\\[6pt]\n& = \\int 1(x \\ge t) \\frac{f(x)}{f_*(x)} f_*(x) \\,dx \\\\[6pt]\n& = E_* [1(X \\ge t) W(X)]\n\\end{align}\n</math>\n\nwhere\n\n:<math>W(\\cdot) \\equiv \\frac{f(\\cdot)}{f_*(\\cdot)} </math>\n\nis a likelihood ratio and is referred to as the weighting function. The last equality in the above equation motivates the estimator\n\n:<math> \\hat p_t = \\frac{1}{K}\\,\\sum_{i=1}^K 1(X_i \\ge t) W(X_i),\\,\\quad \\quad X_i \\sim  f_*</math>\n\nThis is the importance sampling estimator of <math>p_t\\,</math> and is unbiased. That is, the estimation procedure is to generate i.i.d. samples from <math>f_*\\,</math> and for each sample which exceeds <math>t\\,</math>, the estimate is incremented by the weight <math>W\\,</math> evaluated at the sample value. The results are averaged over <math>K\\,</math> trials. The variance of the importance sampling estimator is easily shown to be\n\n:<math>\n\\begin{align}\n\\operatorname{var}_*\\widehat p_t & = \\frac{1}{K}\\operatorname{var}_* [1(X \\ge t)W(X)] \\\\[5pt]\n& = \\frac{1}{K}\\left\\{{E_*}[1(X \\ge t)^2 W^2(X)] - p_t^2\\right\\} \\\\[5pt]\n& = \\frac{1}{K}\\left\\{{E}[1(X \\ge t) W(X)] - p_t^2\\right\\}\n\\end{align}\n</math>\n\nNow, the importance sampling problem then focuses on finding a biasing density <math>f_*\\,</math> such that the variance of the importance sampling estimator is less than the variance of the general Monte Carlo estimate. For some biasing density function, which minimizes the variance, and under certain conditions reduces it to zero, it is called an optimal biasing density function.\n\n=== Conventional biasing methods ===\n\nAlthough there are many kinds of biasing methods, the following two methods are most widely used in the applications of importance sampling.\n\n==== Scaling ====\n\nShifting probability mass into the event region <math>{ X \\ge t\\ }</math> by positive scaling of the random variable <math>X\\,</math> with a number greater than unity has the effect of increasing the variance (mean also) of the density function. This results in a heavier tail of the density, leading to an increase in the event probability. Scaling is probably one of the earliest biasing methods known and has been extensively used in practice. It is simple to implement and usually provides conservative simulation gains as compared to other methods.\n\nIn importance sampling by scaling, the simulation density is chosen as the density function of the scaled random variable <math>aX\\,</math>, where usually <math>a>1</math> for tail probability estimation. By transformation,\n\n:<math> f_*(x)=\\frac{1}{a} f \\bigg( \\frac{x}{a} \\bigg)\\,</math>\n\nand the weighting function is\n\n:<math> W(x)= a \\frac{f(x)}{f(x/a)} \\,</math>\n\nWhile scaling shifts probability mass into the desired event region, it also pushes mass into the complementary region <math>X<t\\,</math> which is undesirable. If <math>X\\,</math> is a sum of <math>n\\,</math> random variables, the spreading of mass takes place in an <math>n\\,</math> dimensional space. The consequence of this is a decreasing importance sampling gain for increasing <math>n\\,</math>, and is called the dimensionality effect.\nA modern version of importance sampling by scaling is e.g. so-called sigma-scaled sampling (SSS) which is running multiple MC analysis with different scaling factors. In opposite to many other high yield estimation methods (like worst-case distances WCD) SSS does not suffer much from the dimensionality problem. Also addressing multiple MC outputs causes no degradation in efficiency. On the other hand, as WCD, SSS is only designed for Gaussian statistical variables, and in opposite to WCD, the SSS method is not designed to provide accurate statistical corners. Another SSS disadvantage is that the MC runs with large scale factors may become difficult, e. g. due to model and simulator convergence problems. In addition, in SSS we face a strong bias-variance trade-off: Using large scale factors, we obtain quite stable yield results, but the larger the scale factors, the larger the bias error. If the advantages of SSS does not matter much in the application of interest, then often other methods are more efficient.\n\n==== Translation ====\n\nAnother simple and effective biasing technique employs translation of the density function (and hence random variable) to place much of its probability mass in the rare event region. Translation does not suffer from a dimensionality effect and has been successfully used in several applications relating to simulation of [[digital communication]] systems. It often provides better simulation gains than scaling. In biasing by translation, the simulation density is given by\n\n:<math> f_*(x)= f(x-c), \\quad c>0 \\,</math>\n\nwhere <math>c\\,</math> is the amount of shift and is to be chosen to minimize the variance of the importance sampling estimator.\n\n=== Effects of system complexity  ===\n\nThe fundamental problem with importance sampling is that designing good biased distributions becomes more complicated as the system complexity increases. Complex systems are the systems with long memory since complex processing of a few inputs is much easier to handle. This dimensionality or memory can cause problems in three ways:\n\n* long memory (severe [[intersymbol interference]] (ISI))\n* unknown memory ([[Viterbi decoder]]s)\n* possibly infinite memory (adaptive equalizers)\n\nIn principle, the importance sampling ideas remain the same in these situations, but the design becomes much harder. A successful approach to combat this problem is essentially breaking down a simulation into several smaller, more sharply defined subproblems. Then importance sampling strategies are used to target each of the simpler subproblems. Examples of techniques to break the simulation down are conditioning and error-event simulation (EES) and regenerative simulation.\n\n=== Evaluation of importance sampling ===\n\nIn order to identify successful importance sampling techniques, it is useful to be able to quantify the run-time savings due to the use of the importance sampling approach. The performance measure commonly used is <math>\\sigma^2_{MC} / \\sigma^2_{IS} \\,</math>, and this can be interpreted as the speed-up factor by which the importance sampling estimator achieves the same precision as the MC estimator. This has to be computed empirically since the estimator variances are not likely to be analytically possible when their mean is intractable. Other useful concepts in quantifying an importance sampling estimator are the variance bounds and the notion of asymptotic efficiency. One related measure is the so-called '''Effective Sample Size''' '''(ESS)'''.<ref>{{Cite journal|last=Martino|first=Luca|last2=Elvira|first2=Víctor|last3=Louzada|first3=Francisco|title=Effective sample size for importance sampling based on discrepancy measures|journal=Signal Processing|volume=131|pages=386–401|doi=10.1016/j.sigpro.2016.08.025|arxiv=1602.03572|year=2017}}</ref>\n\n=== Variance cost function ===\n\nVariance is not the only possible [[Loss function|cost function]] for a simulation, and other cost functions, such as the mean absolute deviation, are used in various statistical applications. Nevertheless, the variance is the primary cost function addressed in the literature, probably due to the use of variances in [[confidence interval]]s and in the performance measure <math>\\sigma^2_{MC} / \\sigma^2_{IS} \\,</math>.\n\nAn associated issue is the fact that the ratio <math>\\sigma^2_{MC} / \\sigma^2_{IS} \\,</math> overestimates the run-time savings due to importance sampling since it does not include the extra computing time required to compute the weight function. Hence, some people evaluate the net run-time improvement by various means. Perhaps a more serious overhead to importance sampling is the time taken to devise and program the technique and analytically derive the desired weight function.\n\n===Multiple and adaptive importance sampling ===\nWhen different proposal distributions, <math>g_n(x)</math> , <math>n=1,\\ldots,N,</math> are jointly used for drawing the samples <math>x_1, \\ldots, x_N, </math> different proper weighting functions can be employed (e.g., see <ref>{{Cite book|title = Optimally Combining Sampling Techniques for Monte Carlo Rendering|publisher = ACM|journal = Proceedings of the 22Nd Annual Conference on Computer Graphics and Interactive Techniques|date = 1995-01-01|location = New York, NY, USA|isbn = 978-0-89791-701-8|pages = 419–428|series = SIGGRAPH '95|doi = 10.1145/218380.218498|first = Eric|last = Veach|first2 = Leonidas J.|last2 = Guibas|citeseerx = 10.1.1.127.8105}}</ref><ref>{{Cite journal|title = Safe and Effective Importance Sampling|journal = Journal of the American Statistical Association|date = 2000-03-01|issn = 0162-1459|pages = 135–143|volume = 95|issue = 449|doi = 10.1080/01621459.2000.10473909|first = Art|last = Owen|first2 = Yi Zhou|last2 = Associate|citeseerx = 10.1.1.36.4536}}</ref><ref>{{Cite journal|title = Efficient Multiple Importance Sampling Estimators|url = http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7105865|journal = IEEE Signal Processing Letters|date = 2015-10-01|issn = 1070-9908|pages = 1757–1761|volume = 22|issue = 10|doi = 10.1109/LSP.2015.2432078|first = V.|last = Elvira|first2 = L.|last2 = Martino|first3 = D.|last3 = Luengo|first4 = M.F.|last4 = Bugallo|arxiv = 1505.05391|bibcode = 2015ISPL...22.1757E}}</ref><ref>{{Cite journal|last=Elvira|first=Víctor|last2=Martino|first2=Luca|last3=Luengo|first3=David|last4=Bugallo|first4=Mónica F.|title=Improving population Monte Carlo: Alternative weighting and resampling schemes|journal=Signal Processing|volume=131|pages=77–91|doi=10.1016/j.sigpro.2016.07.012|arxiv=1607.02758|year=2017}}</ref>). In an adaptive setting, the proposal distributions, <math>g_{n,t}(x)</math> , <math>n=1,\\ldots,N,</math> and <math>t=1,\\ldots,T,</math> are updated each iteration <math>t</math> of the adaptive importance sampling algorithm. Hence, since a population of proposal densities is used, several suitable combinations of sampling and weighting schemes can be employed.<ref>{{Cite journal|title = Population Monte Carlo|journal = Journal of Computational and Graphical Statistics|date = 2004-12-01|issn = 1061-8600|pages = 907–929|volume = 13|issue = 4|doi = 10.1198/106186004X12803|first = O.|last = Cappé|first2 = A.|last2 = Guillin|first3 = J. M.|last3 = Marin|first4 = C. P.|last4 = Robert}}</ref><ref>{{Cite journal|last=Martino|first=L.|last2=Elvira|first2=V.|last3=Luengo|first3=D.|last4=Corander|first4=J.|date=2017-05-01|title=Layered adaptive importance sampling|journal=Statistics and Computing|language=en|volume=27|issue=3|pages=599–623|doi=10.1007/s11222-016-9642-5|issn=0960-3174|arxiv=1505.04732}}</ref><ref>{{Cite journal|title = Adaptive importance sampling in general mixture classes|journal = Statistics and Computing|date = 2008-04-25|issn = 0960-3174|pages = 447–459|volume = 18|issue = 4|doi = 10.1007/s11222-008-9059-x|first = Olivier|last = Cappé|first2 = Randal|last2 = Douc|first3 = Arnaud|last3 = Guillin|first4 = Jean-Michel|last4 = Marin|first5 = Christian P.|last5 = Robert|arxiv = 0710.4242}}</ref><ref>{{Cite journal|title = Adaptive Multiple Importance Sampling|journal = Scandinavian Journal of Statistics|date = 2012-12-01|issn = 1467-9469|pages = 798–812|volume = 39|issue = 4|doi = 10.1111/j.1467-9469.2011.00756.x|first = Jean-Marie|last = Cornuet|first2 = Jean-Michel|last2 = Marin|first3 = Antonietta|last3 = Mira|first4 = Christian P.|last4 = Robert|arxiv = 0907.1254}}</ref><ref>{{Cite journal|title = An Adaptive Population Importance Sampler: Learning From Uncertainty|url = http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7117437|journal = IEEE Transactions on Signal Processing|date = 2015-08-01|issn = 1053-587X|pages = 4422–4437|volume = 63|issue = 16|doi = 10.1109/TSP.2015.2440215|first = L.|last = Martino|first2 = V.|last2 = Elvira|first3 = D.|last3 = Luengo|first4 = J.|last4 = Corander|bibcode = 2015ITSP...63.4422M|citeseerx = 10.1.1.464.9395}}</ref><ref>{{Cite journal|title = Adaptive importance sampling in signal processing|url = http://www.sciencedirect.com/science/article/pii/S1051200415001864|journal = Digital Signal Processing|date = 2015-12-01|pages = 36–49|volume = 47|series = Special Issue in Honour of William J. (Bill) Fitzgerald|doi = 10.1016/j.dsp.2015.05.014|first = Mónica F.|last = Bugallo|first2 = Luca|last2 = Martino|first3 = Jukka|last3 = Corander}}</ref><ref>{{Cite journal|last=Bugallo|first=M. F.|last2=Elvira|first2=V.|last3=Martino|first3=L.|last4=Luengo|first4=D.|last5=Miguez|first5=J.|last6=Djuric|first6=P. M.|date=July 2017|title=Adaptive Importance Sampling: The past, the present, and the future|url=http://ieeexplore.ieee.org/document/7974876/|journal=IEEE Signal Processing Magazine|volume=34|issue=4|pages=60–79|doi=10.1109/msp.2017.2699226|issn=1053-5888|bibcode=2017ISPM...34...60B}}</ref>\n\n== See also ==\n* [[Monte Carlo method]]\n* [[Variance reduction]]\n* [[Stratified sampling]]\n* [[Monte Carlo integration#Recursive stratified sampling|Recursive stratified sampling]]\n* [[VEGAS algorithm]]\n* [[Particle filter]] &mdash; a sequential Monte Carlo method, which uses importance sampling\n* [[Auxiliary field Monte Carlo]]\n* [[Rejection sampling]]\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n*{{cite journal |last=Arouna |first=Bouhari |title=Adaptative Monte Carlo Method, A Variance Reduction Technique |journal=Monte Carlo Methods and Their Applications |year=2004 |volume=10 |issue=1 |pages=1–24 |doi=10.1515/156939604323091180 }}\n*{{cite book |title=Introduction to Rare Event Simulation |first=James Antonio |last=Bucklew |publisher=Springer-Verlag |location=New York |year=2004 }}\n*{{cite book |title=Sequential Monte Carlo Methods in Practice |first=A. |last=Doucet |first2=N. |last2=de Freitas |first3=N. |last3=Gordon |publisher=Springer |year=2001 |isbn=978-0-387-95146-1 }}\n*{{cite book |first=M. |last=Ferrari |first2=S. |last2=Bellini |title=Importance Sampling simulation of turbo product codes |journal=The IEEE International Conference on Communications |volume=9 |pages=2773–2777 |year=2001 |doi=10.1109/ICC.2001.936655 |isbn=978-0-7803-7097-5 }}\n*{{cite journal |first=Oleg |last=Mazonka |title=Easy as Pi: The Importance Sampling Method |journal=Journal of Reference |volume=16 |year=2016 |url=http://jrxv.net/x/16/ism.pdf}}\n*{{cite book |first=Tommy |last=Oberg |title=Modulation, Detection, and Coding |publisher=John Wiley & Sons |location=New York |year=2001 }}\n*{{Cite book | last1=Press | first1=WH | last2=Teukolsky | first2=SA | last3=Vetterling | first3=WT | last4=Flannery | first4=BP | year=2007 | title=Numerical Recipes: The Art of Scientific Computing | edition=3rd | publisher=Cambridge University Press |  location=New York | isbn=978-0-521-88068-8 | chapter=Section 7.9.1 Importance Sampling | chapter-url=http://apps.nrbook.com/empanel/index.html#pg=411}}\n*{{cite book |first=B. D. |last=Ripley |title=Stochastic Simulation |year=1987 |publisher=Wiley & Sons |location= |isbn= }}\n*{{cite journal |first=P. J. |last=Smith |first2=M. |last2=Shafi |first3=H. |last3=Gao |title=Quick simulation: A review of importance sampling techniques in communication systems |journal= IEEE Journal on Selected Areas in Communications |volume=15 |issue=4 |pages=597–613 |year=1997 |doi=10.1109/49.585771 }}\n*{{cite book |first=R. |last=Srinivasan |title=Importance sampling – Applications in communications and detection |publisher=Springer-Verlag |location=Berlin |year=2002 |isbn= }}\n\n==External links==\n* [http://www-sigproc.eng.cam.ac.uk/smc/ Sequential Monte Carlo Methods (Particle Filtering)] homepage on University of Cambridge\n* [http://www.iop.org/EJ/abstract/0143-0807/22/4/315 Introduction to importance sampling in rare-event simulations] European journal of Physics. PDF document.\n* [http://portal.acm.org/citation.cfm?id=1030470 Adaptive monte carlo methods for rare event simulation: adaptive monte carlo methods for rare event simulations] Winter Simulation Conference\n\n[[Category:Monte Carlo methods]]\n[[Category:Variance reduction]]\n[[Category:Stochastic simulation]]"
    },
    {
      "title": "Inverse transform sampling",
      "url": "https://en.wikipedia.org/wiki/Inverse_transform_sampling",
      "text": "'''Inverse transform sampling''' (also known as '''inversion sampling''', the '''inverse probability integral transform''', the '''inverse transformation method''', '''[[Nikolai Smirnov (mathematician)|Smirnov]] transform''', '''universality of the uniform''', or the '''golden rule'''<ref name=aalto>Aalto University, N. Hyvönen, Computational methods in inverse problems. Twelfth lecture https://noppa.tkk.fi/noppa/kurssi/mat-1.3626/luennot/Mat-1_3626_lecture12.pdf{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>) is a basic method for [[pseudo-random number sampling]], i.e. for generating sample numbers at [[random]] from any [[probability distribution]] given its [[cumulative distribution function]].\n\nInverse transformation sampling takes [[Continuous uniform distribution|uniform samples]] of a number <math>u</math> between 0 and 1, interpreted as a probability, and then returns the largest number <math>x</math> from the domain of the distribution <math>P(X)</math> such that <math>P(-\\infty < X < x) \\le u</math>.  For example, imagine that <math>P(X)</math> is the standard [[normal distribution]] with mean zero and standard deviation one. The table below shows samples taken from the uniform distribution and their representation on the standard normal distribution.\n\n{| class=\"wikitable floatright\"\n|+ Transformation from uniform sample to normal\n|-\n! <math>u</math> !! <math>F^{-1}(u)</math>\n|-\n| .5 || 0\n|-\n| .975 || 1.95996\n|-\n| .995 || 2.5758\n|-\n| .999999 || 4.75342\n|-\n| 1-2^{-52} || 8.12589\n|}\n\n[[File:Inverse transform sampling.png|thumbnail|right|Inverse transform sampling for normal distribution]]\n\nWe are randomly choosing a proportion of the area under the curve and returning the number in the domain such that exactly this proportion of the area occurs to the left of that number.  Intuitively, we are unlikely to choose a number in the far end of tails because there is very little area in them which would require choosing a number very close to zero or one.\n\nComputationally, this method involves computing the [[quantile function]] of the distribution — in other words, computing the [[cumulative distribution function]] (CDF) of the distribution (which maps a number in the domain to a probability between 0 and 1) and then inverting that function. This is the source of the term \"inverse\" or \"inversion\" in most of the names for this method. Note that for a [[discrete distribution]], computing the CDF is not in general too difficult: we simply add up the individual probabilities for the various points of the distribution. For a [[continuous distribution]], however, we need to integrate the [[probability density function]] (PDF) of the distribution, which is impossible to do analytically for most distributions (including the [[normal distribution]]). As a result, this method may be computationally inefficient for many distributions and other methods are preferred; however, it is a useful method for building more generally applicable samplers such as those based on [[rejection sampling]].\n\nFor the [[normal distribution]], the lack of an analytical expression for the corresponding quantile function means that other methods (e.g. the [[Box–Muller transform]]) may be preferred computationally. It is often the case that, even for simple distributions, the inverse transform sampling method can be improved on:<ref>{{cite book |author=Luc Devroye |url=http://www.eirene.de/Devroye.pdf |title=Non-Uniform Random Variate Generation |publisher=Springer-Verlag |place=New York |year=1986}}</ref> see, for example, the [[ziggurat algorithm]] and [[rejection sampling]]. On the other hand, it is possible to approximate the quantile function of the normal distribution extremely accurately using moderate-degree polynomials, and in fact the method of doing this is fast enough that inversion sampling is now the default method for sampling from a normal distribution in the statistical package [[R (programming language)|R]].<ref>https://stat.ethz.ch/R-manual/R-devel/library/base/html/Random.html</ref>\n\n==Definition==\n\nThe [[probability integral transform]] states that if <math>X</math> is a [[continuous random variable]] with [[cumulative distribution function]] <math>F_X</math>, then the random variable <math>Y=F_X(X)</math> has a [[uniform distribution (continuous)|uniform distribution]] on [0,&nbsp;1]. The inverse probability integral transform is just the inverse of this: specifically, if  <math>Y</math> has a uniform distribution on [0,&nbsp;1] and if  <math>X</math> has a cumulative distribution  <math>F_X</math>, then the random variable <math>F_X^{-1}(Y)</math>  has the same distribution as  <math>X</math> .\n\n[[File:InverseFunc.png|thumb|Graph of the inversion technique from <math>x</math> to <math>F(x)</math>. On the bottom right we see the regular function and in the top left its inversion.]]\n\n== Intuitions ==\nFrom <math>U \\sim \\mathrm{Unif}[0,1]</math>, we want to generate <math>X</math> with [[Cumulative distribution function|CDF]] <math>F_X(x).</math> We assume <math>F_X(x)</math> to be a strictly increasing function, which provides good intuition but is not true in general. \n\nWe want to see if we can find some strictly monotone transformation <math>T:[0,1]\\mapsto \\mathbb{R}</math>, such that <math>T(U)\\overset{d}{=}X</math>. Still, the condition of strict monotonicity may not be true for general situations. We will have\n\n<math>F_X(x)=\\Pr(X\\leq x)=\\Pr(T(U)\\leq x) = \\Pr(U\\leq T^{-1}(x))=T^{-1}(x), \\text{ for } x\\in \\mathbb{R}. </math>\n\nSo we got <math>F_X</math> to be the inverse function of <math>T </math>, or, equivalently <math>T(u)=F_X^{-1}(u), u\\in [0,1]. </math>\n\nTherefore, we can generate <math>X </math> from <math>F_X^{-1}(U). </math>\n\n==The method==\n[[File:Generalized inversion method.svg|thumb|300px|Schematic of the inverse transform sampling. The inverse function of <math>y=F_X(x)</math> can be defined by <math>F_X^{-1}(y)=\\mathrm{inf}\\{x| F_X(x)\\geq y\\}</math>.]]\nThe problem that the inverse transform sampling method solves is as follows:\n\n*Let <math>X</math> be a [[random variable]] whose distribution can be described by the [[cumulative distribution function]] <math>F_X</math>.\n*We want to generate values of <math>X</math> which are distributed according to this distribution.\n\nThe inverse transform sampling method works as follows:\n#[[pseudorandom number generator|Generate a random number]] <math>u</math> from the standard uniform distribution in the interval <math>[0,1]</math>, e.g. from <math>U \\sim \\mathrm{Unif}[0,1].</math>\n#Find the inverse of the desired CDF, e.g. <math>F_X^{-1}(x)</math>.\n# Compute <math>X=F_X^{-1}(u)</math>. The computed random variable <math>X</math> has distribution <math>F_X(x)</math>.\n\nExpressed differently, given a continuous uniform variable <math>U</math> in <math>[0,1]</math> and an [[Inverse function|invertible]] cumulative distribution function <math>F_X</math>, the random variable <math>X = F_X^{-1}(U)</math> has distribution <math>F_X</math> (or, <math>X</math> is distributed <math>F_X</math>).\n\nA treatment of such inverse functions as objects satisfying differential equations can be given.<ref>Steinbrecher, G., Shaw, W.T. (2008). Quantile mechanics. ''European Journal of Applied Mathematics'' 19 (2): 87–112.</ref> Some such differential equations admit explicit power series solutions, despite their non-linearity.{{Citation needed|date=July 2017}}\n\n== Examples ==\n* As an example, suppose we have a random variable <math> U \\sim \\mathrm{Unif}(0,1)</math> and a [[cumulative distribution function]]\n: <math>\n\\begin{align}\n F(x)=1-\\exp(-\\sqrt{x})\n\\end{align}\n</math>\n: In order to perform an inversion we want to solve for <math>F(F^{-1}(u))=u</math>\n: <math>\n\\begin{align}\n F(F^{-1}(u))&=u \\\\\n 1-\\exp\\left(-\\sqrt{F^{-1}(u)}\\right) &= u \\\\\n F^{-1}(u) &= (-\\log(1-u))^2 \\\\\n&= (\\log(1-u))^2\n\\end{align}\n</math>\n: From here we would perform steps one, two and three.\n\n* As another example, we use the [[exponential distribution]] with <math>F_X(x)=1-e^{-\\lambda x}</math> for x ≥ 0 (and 0 otherwise). By solving y=F(x) we obtain the inverse function\n: <math>x = F^{-1}(y) = -\\frac{1}{\\lambda}\\ln(1-y).</math>\n:It means that if we draw some <math>y_0</math>from a <math> U \\sim Unif(0,1)</math>and compute <math>x_0 = F_X^{-1}(y_0) = -\\frac{1}{\\lambda}\\ln(1-y_0),</math>This <math>x_0</math>has exponential distribution.\n: The idea is illustrated in the following graph:\n\n: [[File:Inverse transformation method for exponential distribution.jpg|thumb|none|400px|Random numbers y<sub>i</sub> are generated from a uniform distribution between 0 and 1, i.e. Y ~ U(0, 1). They are sketched as colored points on the y-axis. Each of the points is mapped according to x=F<sup>−1</sup>(y), which is shown with gray arrows for two example points. In this example, we have used an exponential distribution. Hence, for x ≥ 0, the probability density is <math>\\varrho_X(x) = \\lambda e^{-\\lambda \\, x}</math> and the cumulated distribution function is <math>F(x) = 1 - e^{-\\lambda \\, x}</math>. Therefore, <math>x = F^{-1}(y) = - \\frac{\\ln(1-y)}{\\lambda}</math>. We can see that using this method, many points end up close to 0 and only few points end up having high x-values - just as it is expected for an exponential distribution.]]\n: Note that the distribution does not change if we start with 1-y instead of y. For computational purposes, it therefore suffices to generate random numbers y in [0, 1] and then simply calculate\n: <math>x = F^{-1}(y) = -\\frac{1}{\\lambda}\\ln(y).</math>\n\n==Proof of correctness==\nLet ''F'' be a continuous [[cumulative distribution function]], and let ''F''<sup>&minus;1</sup> be its inverse function (using the [[infimum]] because CDFs are weakly monotonic and [[Càdlàg|right-continuous]]):<ref>{{cite book |author=Luc Devroye |title=Non-Uniform Random Variate Generation |publisher=Springer-Verlag |place=New York |year=1986 |chapter=Section 2.2. Inversion by numerical solution of ''F''(''X'')&nbsp;=&nbsp;''U'' |url=http://luc.devroye.org/chapter_two.pdf}}</ref>\n\n:<math>F^{-1}(u) = \\inf\\;\\{x \\mid F(x)\\geq u\\} \\qquad (0<u<1).</math>\n\n''Claim:'' If ''U'' is a [[uniform distribution (continuous)|uniform]] random variable on (0,&nbsp;1) then <math>F^{-1}(U)</math> has ''F'' as its CDF.\n\n''Proof:''\n\n:<math>\n\\begin{align}\n& \\Pr(F^{-1}(U) \\leq x) \\\\\n& {} = \\Pr(U \\leq F(x)) \\quad &(\\text{applying }F,\\text{ to both sides}) \\\\\n& {} = F(x)\\quad &(\\text{because }\\Pr(U \\leq y) = y,\\text{ when U is uniform on}(0,1)) \\\\\n\\end{align}\n</math>\n\n== Truncated distribution ==\n\nInverse transform sampling can be simply extended to cases of [[truncated distribution]]s on the interval <math>(a,b]</math> without the cost of rejection sampling: the same algorithm can be followed, but instead of  generating a random number <math>u</math> uniformly distributed between 0 and 1, generate <math>u</math> uniformly distributed between <math>F(a)</math> and <math>F(b)</math>, and then again take <math>F^{-1}(u)</math>.\n\n== Reduction of the number of inversions ==\nIn order to obtain a large number of samples, one needs to perform the same number of inversions of the distribution. \nOne possible way to reduce the number of inversions while obtaining a large number of samples is the application of the so-called Stochastic Collocation Monte Carlo sampler (SCMC sampler) within a [[polynomial chaos]] expansion framework. This allows us to generate any number of Monte Carlo samples with only a few inversions of the original distribution with independent samples of a variable for which the inversions are analytically available, for example the standard normal variable.<ref>L.A. Grzelak, J.A.S. Witteveen, M. Suarez, and C.W. Oosterlee. The stochastic collocation Monte Carlo sampler: Highly efficient sampling from “expensive” distributions. http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2529691</ref>\n\n== See also ==\n* [[Probability integral transform]]\n* [[Copula (statistics)|Copula]], defined by means of probability integral transform.\n* [[Quantile function]], for the explicit construction of inverse CDFs.\n* [[Cumulative distribution function#Inverse|Inverse distribution function]] for a precise mathematical definition for distributions with discrete components.\n\n==References==\n\n<references/>\n\n{{DEFAULTSORT:Inverse Transform Sampling}}\n[[Category:Monte Carlo methods]]\n[[Category:Non-uniform random numbers]]"
    },
    {
      "title": "Iterated filtering",
      "url": "https://en.wikipedia.org/wiki/Iterated_filtering",
      "text": "'''Iterated filtering''' algorithms are a tool for [[maximum likelihood]] inference on partially observed [[dynamical system]]s.  [[Stochastic]] [[perturbation theory|perturbations]] to the unknown parameters are used to explore the parameter space.  Applying sequential Monte Carlo (the [[particle filter]]) to this extended model results in the selection of the parameter values that are more consistent with the data.  Appropriately constructed procedures, iterating with successively diminished perturbations, converge to the maximum likelihood estimate.<ref name=ionides06 /><ref name=ionides11 /><ref name=ionides15 />  Iterated filtering methods have so far been used most extensively to study infectious disease transmission dynamics.  Case studies include [[cholera]],<ref name=king08 /><ref name=breto09 /> [[Ebola virus]],<ref name=king15prsb /> [[influenza]],<ref name=he11 /><ref name=camacho11 /><ref name=earn12 /><ref name=shrestha13 /> [[malaria]],<ref name=laneri10 /><ref name=bhadra11 /><ref name=roy13 /> [[HIV]],<ref name=zhou13 /> [[pertussis]],<ref name=lavine12 /><ref name=blackwood13 /> [[poliovirus]]<ref name=blake14 />  and [[measles]].<ref name=breto09 /><ref name=he10 />  Other areas which have been proposed to be suitable for these methods include ecological dynamics<ref name=ionides11-statSci>{{cite journal|last = Ionides|first = E. L..|title = Discussion on \"Feature Matching in Time Series Modeling\" by Y. Xia and H. Tong.|journal = Statistical Science |year = 2011|doi=10.1214/11-STS345C|volume=26|pages=49–52|arxiv=1201.1376}}</ref><ref name=blackwood13b /> and [[finance]].<ref name=bhadra10 /><ref name=breto14 /> \n\nThe perturbations to the [[parameter]] space play several different roles. Firstly, they smooth out the likelihood surface, enabling the algorithm to overcome small-scale features of the likelihood during early stages of the global search. Secondly, Monte Carlo variation allows the search to escape from local minima. Thirdly, the iterated filtering update uses the perturbed parameter values to construct an approximation to the derivative of the log likelihood even though this quantity is not typically available in closed form. Fourthly, the parameter perturbations help to overcome numerical difficulties that can arise during sequential Monte Carlo.\n\n==Overview==\nThe data are a time series <math>y_1,\\dots,y_N</math> collected at times <math> t_1 < t_2 < \\dots < t_N</math>. The dynamic system is modeled by a [[Markov process]] <math> X(t)</math> which is generated by a function <math>f(x,s,t,\\theta,W)</math> in the sense that\n\n: <math>X(t^{}_n)=f(X(t^{}_{n-1}),t^{}_{n-1},t^{}_n,\\theta,W) </math>\n\nwhere <math>\\theta</math> is a vector of unknown parameters and <math>W</math> is some random quantity that is drawn independently each time <math>f(.)</math> is evaluated.  An initial condition <math>X(t_0)</math> at some time <math>t_0<t_1</math> is specified by an initialization function, <math>X(t_0)=h(\\theta)</math>. A measurement density <math> g(y_n|X_n,t_n,\\theta)</math> completes the specification of a partially observed Markov process. We present a basic iterated filtering algorithm (IF1)<ref name=ionides06 /><ref name=ionides11 /> followed by an iterated filtering algorithm implementing an iterated, perturbed Bayes map (IF2).<ref name=ionides15 /><ref name=lindstrom12 />\n\n==Procedure: Iterated filtering (IF1)==\n:Input: A partially observed Markov model specified as above; Monte Carlo sample size <math>J</math>; number of iterations <math>M</math>; cooling parameters <math>0<a<1</math> and  <math>b</math>; covariance matrix <math>\\Phi</math>; initial parameter vector <math>\\theta^{(1)}</math>\n\n:for <math>m^{}_{}=1</math> to <math>M^{}_{}</math>\n::draw <math>\\Theta_F(t^{}_0,j)\\sim \\mathrm{Normal}(\\theta^{(m)},b a^{m-1} \\Phi)</math>  for  <math>j=1,\\dots, J</math>\n::set <math>X_F(t^{}_0,j)=h\\big(\\Theta_F(t^{}_0,j)\\big)</math> for  <math>j=1,\\dots, J</math>\n::set <math>\\bar\\theta(t^{}_0)=\\theta^{(m)}</math>\n::for <math>n^{}_{}=1</math> to <math>N^{}_{}</math>\n:::draw <math>\\Theta_P(t^{}_n,j)\\sim \\mathrm{Normal}(\\Theta_F(t^{}_{n-1},j), a^{m-1} \\Phi)</math>  for  <math>j=1,\\dots, J</math>\n:::set <math>X_P(t^{}_n,j)=f(X_F(t^{}_{n-1},j),t^{}_{n-1},t_n,\\Theta_P(t_{n},j),W)</math> for  <math>j=1,\\dots, J</math>\n:::set <math>w(n,j) = g(y_n|X_P(t^{}_n,j),t^{}_n,\\Theta_P(t_{n},j))</math> for  <math>j=1,\\dots, J</math>\n:::draw <math>k^{}_1,\\dots,k^{}_J</math> such that <math>P(k^{}_j=i)=w(n,i)\\big/{\\sum}_\\ell w(n,\\ell)</math>\n:::set <math>X_F(t^{}_n,j)=X_P(t^{}_n,k^{}_j)</math> and <math>\\Theta_F(t^{}_n,j)=\\Theta_P(t^{}_n,k^{}_j)</math> for  <math>j=1,\\dots, J</math>\n:::set <math>\\bar\\theta_i^{}(t_n^{})</math> to the sample mean of <math>\\{\\Theta_{F,i}^{}(t^{}_{n},j),j=1,\\dots,J\\}</math>, where the vector <math>\\Theta^{}_F</math> has components <math>\\{\\Theta^{}_{F,i}\\}</math>\n:::set <math>V_i^{}(t_n^{})</math> to the sample variance of <math>\\{\\Theta_{P,i}^{}(t^{}_{n},j),j=1,\\dots,J\\}</math>\n::set <math>\\theta_i^{(m+1)}= \\theta_i^{(m)}+V_i(t_{1})\\sum_{n=1}^N V_i^{-1}(t_{n})(\\bar\\theta_i(t_n)-\\bar\\theta_i(t_{n-1}))</math>\n\n:Output: Maximum likelihood estimate <math>\\hat\\theta=\\theta^{(M+1)}</math>\n\n==Variations==\n# For IF1, parameters which enter the model only in the specification of the initial condition, <math>X(t_0)</math>, warrant some special algorithmic attention since information about them in the data may be concentrated in a small part of the time series.<ref name=ionides06 />\n# Theoretically, any distribution with the requisite mean and variance could be used in place of the [[normal distribution]]. It is standard to use the normal distribution and to reparameterise to remove constraints on the possible values of the parameters.\n# Modifications to the IF1 algorithm have been proposed to give superior asymptotic performance.<ref name=lindstrom13 /><ref name=doucet13 />\n\n==Procedure: Iterated filtering (IF2)==\n:Input: A partially observed Markov model specified as above; Monte Carlo sample size <math>J</math>; number of iterations <math>M</math>; cooling parameter <math>0<a<1</math>; covariance matrix <math>\\Phi</math>; initial parameter vectors <math>\\{\\Theta_j, j=1,\\dots,J\\}</math>\n\n:for <math>m^{}_{}=1</math> to <math>M^{}_{}</math>\n::set <math>\\Theta_F(t^{}_0,j) \\sim \\mathrm{Normal}(\\Theta_j, a^{m-1} \\Phi)</math>  for  <math>j=1,\\dots, J</math>\n::set <math>X_F(t^{}_0,j)=h\\big(\\Theta_F(t^{}_0,j)\\big)</math> for  <math>j=1,\\dots, J</math>\n::for <math>n^{}_{}=1</math> to <math>N^{}_{}</math>\n:::draw <math>\\Theta_P(t^{}_n,j)\\sim \\mathrm{Normal}(\\Theta_F(t^{}_{n-1},k^{}_j), a^{m-1} \\Phi)</math>  for  <math>j=1,\\dots, J</math>\n:::set <math>X_P(t^{}_n,j)=f(X_F(t^{}_{n-1},j),t^{}_{n-1},t_n,\\Theta_P(t_{n},j),W)</math> for  <math>j=1,\\dots, J</math>\n:::set <math>w(n,j) = g(y_n|X_P(t^{}_n,j),t^{}_n,\\Theta_P(t_{n},j))</math> for  <math>j=1,\\dots, J</math>\n:::draw <math>k^{}_1,\\dots,k^{}_J</math> such that <math>P(k^{}_j=i)=w(n,i)\\big/{\\sum}_\\ell w(n,\\ell)</math>\n:::set <math>X_F(t^{}_n,j)=X_P(t^{}_n,k^{}_j)</math>  and <math>\\Theta_F(t^{}_n,j)=\\Theta_P(t^{}_n,k^{}_j)</math> for  <math>j=1,\\dots, J</math>\n::set <math>\\Theta_j=\\Theta_F(t^{}_N,j)</math>  for  <math>j=1,\\dots, J</math>\n\n:Output: Parameter vectors approximating the maximum likelihood estimate, <math>\\{\\Theta_j, j=1,\\dots, J \\}</math>\n\n==Software==\n[https://kingaa.github.io/pomp/ \"pomp: statistical inference for {{sic|hide=y|partially|-}}observed Markov processes\"] : R package.\n\n==References==\n{{Reflist|refs=\n<ref name=bhadra10>{{cite journal|last = Bhadra|first = A.|title = Discussion of \"Particle Markov chain Monte Carlo methods\" by C. Andrieu, A. Doucet and R. Holenstein|journal = Journal of the Royal Statistical Society, Series B|volume =72 |year = 2010|pages = 314–315|doi=10.1111/j.1467-9868.2009.00736.x|issue = 3}}</ref>\n\n<ref name=breto09>{{cite journal|last = Breto|first = C. |author2=He, D. |author3=Ionides, E. L. |author4=King, A. A.|title = Time series analysis via mechanistic models|journal = Annals of Applied Statistics|volume = 3|year = 2009|pages = 319–348|doi=10.1214/08-AOAS201|arxiv=0802.0021}}</ref>\n\n<ref name=camacho11>{{cite journal|last = Camacho|first = A. |author2=S. Ballesteros |author3=A. L. Graham |author4=R. Carrat |author5=O. Ratmann |author6=B. Cazelles|title = Explaining rapid reinfections in multiple-wave influenza outbreaks: Tristan da Cunha 1971 epidemic as a case study|journal = Proceedings of the Royal Society B|year = 2011|doi=10.1098/rspb.2011.0300|volume = 278|issue = 1725|pages = 3635–3643 |pmid=21525058 |pmc=3203494}}</ref>\n\n<ref name=he10>{{cite journal|last = He|first = D. |author2=Ionides,E. L. |author3=King, A. A.|title = Plug-and-play inference for disease dynamics: measles in large and small towns as a case study|journal = Journal of the Royal Society Interface|volume = 7|year = 2010|pages = 271–283|pmc = 2842609|doi=10.1098/rsif.2009.0151|pmid=19535416|issue = 43}}</ref>\n\n<ref name=he11>{{cite journal|last = He|first = D. |author2=J. Dushoff |author3=T. Day |author4=J. Ma |author5=D. Earn |title = Mechanistic modelling of the three waves of the 1918 influenza pandemic|journal = Theoretical Ecology|volume = 4|year = 2011|pages = 1–6|doi=10.1007/s12080-011-0123-3|issue = 2}}</ref>\n\n<ref name=ionides06>{{cite journal|last = Ionides|first = E. L. |author2=Breto, C. |author3=King, A. A.|title = Inference for nonlinear dynamical systems|journal = Proceedings of the National Academy of Sciences of the USA|volume = 103|year = 2006|pages = 18438–18443|pmid = 17121996|doi=10.1073/pnas.0603181103|issue = 49|pmc = 3020138|bibcode = 2006PNAS..10318438I}}</ref>\n\n<ref name=ionides11>{{cite journal|last = Ionides|first = E. L. |author2=Bhadra, A. |author3=Atchade, Y. |author4=King, A. A.|title = Iterated filtering|journal = Annals of Statistics|volume = 39|pages = 1776–1802|year = 2011| doi=10.1214/11-AOS886|issue = 3|arxiv=0902.0347}}</ref>\n\n<ref name=lavine12>{{cite journal|last = Lavine|first = J.|author2=Rohani, P.|title = Resolving pertussis immunity and vaccine effectiveness using incidence time series|journal = Expert Review of Vaccines|pmc = 3595187 |volume = 11|year = 2012|pages = 1319–1329|doi=10.1586/ERV.12.109|pmid=23249232}}</ref>\n\n<ref name=lindstrom12>{{cite journal|last = Lindstrom|first = E. |author2=Ionides, E. L. |author3=Frydendall, J. |author4=Madsen, H.|title = Efficient Iterated Filtering|journal = System Identification|volume = 16|year = 2012|pages = 1785–1790|doi=10.3182/20120711-3-BE-2027.00300}}</ref>\n\n<ref name=earn12>{{cite journal|last = Earn|first = D. |author2=He, D. |author3=Loeb, M. B. |author4=Fonseca, K. |author5=Lee, B. E. |author6=Dushoff, J.|title = Effects of School Closure on Incidence of Pandemic Influenza in Alberta, Canada| journal = Annals of Internal Medicine | year=2012|volume=156|pages=173–181|doi=10.7326/0003-4819-156-3-201202070-00005}}</ref>\n\n<ref name=lindstrom13>{{cite journal|last = Lindstrom|first = E.|journal = Statistics and Probability Letters|title = Tuned iterated filtering|volume = 83|issue=9|year = 2013|pages = 2077–2080|doi=10.1016/j.spl.2013.05.019}}</ref>\n\n<ref name=roy13>{{cite journal|last = Roy|first = M. |author2=Bouma, M. J. |author3=Ionides, E. L. |author4=Dhiman, R. C. |author5=Pascual, M.|journal= PLoS Neglected Tropical Diseases | title=The potential elimination of Plasmodium vivax malaria by relapse treatment: Insights from a transmission model and surveillance data from NW India |year=2013|volume=7|pages= e1979|doi=10.1371/journal.pntd.0001979}}</ref>\n\n<ref name=zhou13>{{cite journal|last = Zhou|first = J. |author2=Han, L. |author3=Liu, S. |journal = Statistics and Probability Letters|volume = 83|year = 2013|pages = 1448–1456|title = Nonlinear mixed-effects state space models with applications to HIV dynamics|doi  = 10.1016/j.spl.2013.01.032}}</ref>\n\n<ref name=doucet13>{{cite arXiv |last= Doucet|first= A. |author2=Jacob, P. E. |author3=Rubenthaler, S.|eprint= 1304.5768|title= Derivative-Free Estimation of the Score Vector and Observed Information Matrix with Application to State-Space Models |class= stat.ME|year= 2013}}</ref>\n\n<ref name=king08>{{cite journal|last = King|first = A. A. |author2=Ionides, E. L. |author3=Pascual, M. |author4=Bouma, M. J.|title = Inapparent infections and cholera dynamics|journal = Nature|volume = 454|year = 2008|pages = 877–880|pmid = 18704085 |doi=10.1038/nature07084|issue=7206|bibcode=2008Natur.454..877K}}</ref>\n\n<ref name=laneri10>{{cite journal|last = Laneri|first = K. |author2=A. Bhadra |author3=E. L. Ionides |author4=M. Bouma |author5=R. C. Dhiman |author6=R. S. Yadav |author7=M. Pascual|title = Forcing versus feedback: Epidemic malaria and monsoon rains in NW India|journal = PLoS Computational Biology|volume = 6|year = 2010|pages = e1000898|pmc = 2932675 |doi=10.1371/journal.pcbi.1000898|pmid=20824122|issue = 9|bibcode=2010PLSCB...6E0898L}}</ref>\n\n<ref name=bhadra11>{{cite journal|last=Bhadra|first=A. |author2=E. L. Ionides |author3=K. Laneri |author4=M. Bouma |author5=R. C. Dhiman |author6=M. Pascual|title=Malaria in Northwest India: Data analysis via partially observed stochastic differential equation models driven by Lévy noise|journal = Journal of the American Statistical Association|year=2011|doi=10.1198/jasa.2011.ap10323|volume=106|issue=494|pages=440–451}}</ref>\n\n<ref name=ionides15>{{cite journal|last = Ionides|first = E. L. |author2=Nguyen, D. |author3=Atchadé, Y. |author4=Stoev, S. |author5=King, A. A.|title = Inference for dynamic and latent variable models via iterated, perturbed Bayes maps|journal = Proceedings of the National Academy of Sciences of the USA|volume = 112 |year = 2015|pages = 719–724|pmc = 4311819|doi=10.1073/pnas.1410597112|issue = 3 |pmid=25568084|bibcode=2015PNAS..112..719I}}</ref>\n\n<ref name=blake14>{{cite journal|last = Blake|first= I. M. |author2=Martin, R. |author3=Goel, A. |author4=Khetsuriani, N. |author5=Everts, J. |author6=Wolff, C. |author7=Wassilak, S. |author8=Aylward, R. B. |author9=Grassly, N. C.|title=The role of older children and adults in wild poliovirus transmission|journal = Proceedings of the National Academy of Sciences of the USA|volume = 111 |year = 2014|pages = 10604–10609|pmc = 4115498|doi=10.1073/pnas.1323688111|issue = 29 |pmid=25002465|bibcode=2014PNAS..11110604B}}</ref>\n \n<ref name=breto14>{{cite journal|last = Breto|first = C.|title = On idiosyncratic stochasticity of financial leverage effects|journal = Statistics and Probability Letters|volume = 91|year = 2014|pages = 20–26|doi=10.1016/j.spl.2014.04.003|arxiv = 1312.5496}}</ref>\n\n<ref name=king15prsb>{{cite journal|vauthors = King AA, Domenech de Celles M, Magpantay FM, Rohani P|title = Avoidable errors in the modelling of outbreaks of emerging pathogens, with special reference to Ebola|journal = Proceedings of the Royal Society B|volume = 282|year = 2015|pages = 20150347|doi=10.1098/rspb.2015.0347|pmid=25833863|pmc=4426634}}</ref>\n\n<ref name=shrestha13>{{cite journal|last = Shrestha|first = S. |author2=Foxman, B. |author3=Weinberger, D. M. |author4=Steiner, C. |author5=Viboud, C. |author6=Rohani, P.|title = Identifying the interaction between influenza and pneumococcal pneumonia using incidence data|journal = Science Translational Medicine|volume = 5|year = 2013|pages = 191ra84|pmc = 4178309|doi=10.1126/scitranslmed.3005982|issue = 191 |pmid=23803706}}</ref>\n\n<ref name=blackwood13>{{cite journal|last = Blackwood|first = J. C. |author2=Cummings, D. A. T. |author3=Broutin, H. |author4=Iamsirithaworn, S. |author5=Rohani, P.|title = Deciphering the impacts of vaccination and immunity on pertussis epidemiology in Thailand|journal = Proceedings of the National Academy of Sciences of the USA|volume = 110|year = 2013|pages = 9595–9600|pmc = 3677483|doi=10.1073/pnas.1220908110|issue = 23 |pmid=23690587|bibcode=2013PNAS..110.9595B}}</ref>\n\n<ref name=blackwood13b>{{cite journal|last = Blackwood|first = J. C. |author2=Streicker, D. G. |author3=Altizer, S. |author4=Rohani, P.|title = Resolving the roles of immunity, pathogenesis, and immigration for rabies persistence in vampire bat|journal = Proceedings of the National Academy of Sciences of the USA|volume = 110|year = 2013|pages = 20837–-20842|pmc = 3870737|doi=10.1073/pnas.1308817110|issue = 51 |pmid=24297874|bibcode=2013PNAS..11020837B}}</ref>\n\n}}\n\n[[Category:Dynamical systems]]\n[[Category:Monte Carlo methods]]\n[[Category:Nonlinear filters]]"
    },
    {
      "title": "Kinetic Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Kinetic_Monte_Carlo",
      "text": "{{use dmy dates|date=September 2010}}\n\nThe '''kinetic Monte Carlo (KMC)''' method is a [[Monte Carlo method]] computer simulation intended to simulate the time evolution of some processes occurring in nature.  Typically these are processes that occur with known transition rates among states.  It is important to understand that these rates are inputs to the KMC algorithm, the method itself cannot predict them.\n\nThe KMC method is essentially the same as the [[dynamic Monte Carlo method]] and the [[Gillespie algorithm]].\n\n== Algorithms ==\nOne possible classification of KMC algorithms is as rejection-KMC (rKMC) and rejection-free-KMC (rfKMC).\n\n=== Rejection-free KMC ===\n[[File:Transfer_rates.svg|thumb|240px|alt=Transfer rates between one initial and four final states|At each step, the system can jump into several ending states, the transfer rates between the initial state and all the possible ending states are supposed to be known.]]\n\n[[File:State decision in KMC.svg|thumb|240px|Choice of the final state : a random var is chosen between 0 and Γ<sub>tot</sub>; the probability that the system jumps into state ''i'' is proportional to Γ<sub>i</sub>.]]\n\nA rfKMC algorithm, often only called KMC, for simulating the time evolution of a system, where some processes can occur with known rates r, can be written for instance as follows:\n# Set the time <math>t = 0</math>.\n# Choose an initial state  ''k''.\n# Form the list of all <math>N_k</math> possible transition rates in the system <math>r_{ki}</math>, from state ''k'' into a generic state ''i''. States that do not communicate with ''k'' will have <math>r_{ki}=0</math>.\n# Calculate the cumulative function <math>R_{ki}=\\sum_{j=1}^i r_{kj}</math> for <math>i=1,\\ldots,N_k</math>. The total rate is <math>Q_k =  R_{k,N_k}</math>.\n# Get a uniform random number <math>u \\in (0, 1]</math>.\n# Find the event to carry out ''i'' by finding the ''i'' for which <math>R_{k,i-1} < u Q_k \\le R_{ki}</math> (this can be achieved efficiently using [[binary search]]).\n# Carry out event ''i'' (update the current state <math>k \\rightarrow i</math>).\n# Get a new uniform random number <math>u^\\prime \\in (0, 1]</math>.\n# Update the time with <math>t = t + \\Delta t</math>, where <math>\\Delta t =  Q_k^{-1} \\ln(1/u^\\prime)</math>.\n# Return to step 3.\n\n(Note: because the average value of <math>\\ln(1/u^\\prime)</math> is equal to unity, the same ''average'' time scale can be obtained by instead using <math>\\Delta t = Q_k^{-1} </math> in step 9. In this case, however, the delay associated with transition ''i'' will not be drawn from the [[Poisson distribution]] described by the rate <math>Q_k</math>, but will instead be the mean of that distribution.)\n\nThis algorithm is known in different sources variously as the '''residence-time algorithm''' or the '''''n''-fold way''' or the '''Bortz-Kalos-Lebowitz  (BKL)''' algorithm. It is important to note that the timestep involved is a function of the probability that all events ''i'', did not occur.\n\n===Rejection KMC===\nRejection KMC has typically the advantage of an easier data handling, and faster computations for each attempted step, since the time consuming action of getting all <math>r_{ki}</math> is not needed.\nOn the other hand, the time evolved at each step is smaller than for rfKMC. The relative weight of pros and cons varies with the case at hand, and with available resources.\n\nAn rKMC associated with the same transition rates as above can be written as follows:\n# Set the time <math>t = 0</math>.\n# Choose an initial state  ''k''.\n# Get the number <math>N_k</math> of all possible transition rates, from state ''k'' into a generic state ''i''.\n# Find the ''candidate'' event to carry out ''i'' by uniformly sampling from the <math>N_k</math> transitions above.\n# Accept the event with probability <math>f_{ki} = r_{ki} / r_0</math>, where <math>r_0</math> is a suitable upper bound for <math>r_{ki}</math>. It is often easy to find <math>r_0</math> without having to compute all  <math>r_{ki}</math> (e.g., for Metropolis transition rate probabilities).\n# If accepted, carry out event ''i'' (update the current state <math>k \\rightarrow i</math>).\n# Get a new uniform random number <math>u^\\prime \\in (0, 1]</math>.\n# Update the time with <math>t = t + \\Delta t</math>, where <math>\\Delta t =  (N_k r_0)^{-1} \\ln(1/u^\\prime)</math>.\n# Return to step 3.\n\n(Note: <math>r_0</math> can change from one MC step to another.)\nThis algorithm is usually called a '''standard algorithm'''.\n\nTheoretical<ref name=\"Serebrinsky2011\">S.A. Serebrinsky, Physical time scale in kinetic Monte Carlo simulations of continuous-time Markov chains, Phys. Rev. E '''83''', 037701 (2011) [http://journals.aps.org/pre/abstract/10.1103/PhysRevE.83.037701] [https://www.ncbi.nlm.nih.gov/pubmed/21517635].</ref> and numerical<ref name=\"Bortz1975\">A. B. Bortz and M. H. Kalos and J. L. Lebowitz, Journal of Computational Physics 17 (1975) 10 [https://dx.doi.org/10.1016/0021-9991%2875%2990060-1 Journal of Computational Physics 17 (1975) 10] (needs subscription).</ref><ref name=\"Sadiq1984\">A. Sadiq, A new algorithm for the Monte Carlo simulation of spin-exchange kinetics of Ising systems, J. Comput. Phys. '''55''' (3), 387–396 (1984) [http://www.sciencedirect.com/science/article/pii/0021999184900287].</ref> comparisons between the algorithms were provided.\n\n==Time-dependent Algorithms==\nIf the rates <math>r_{ki}(t)</math> are time dependent, step 9 in the rfKMC must be modified by:<ref>A. Prados, J. J. Brey and B. Sanchez-Rey, Journal of Statistical Physics 89, 709-734 (1997)</ref>\n: <math>\\int_{0}^{\\Delta t} Q_k(t') dt' =  \\ln(1/u^\\prime)</math>.\nThe reaction (step 6) has to be chosen after this by\n: <math>R_{k,i-1}(\\Delta t)  <  u  Q_k( \\Delta t ) \\leq R_{ki}(\\Delta t)</math>\n\nAnother very similar algorithm is called the First Reaction Method (FRM). It consists of choosing the first-occurring reaction, meaning to choose the smallest time <math>\\Delta t_i</math>, and the corresponding reaction number ''i'', from the formula\n: <math>\\int_{0}^{\\Delta t_i} r_{ki}(t') dt' =  \\ln(1/u_i) </math>,\nwhere the <math>u_i \\in (0, 1]</math> are N random numbers.\n\n==Comments on the algorithm==\nThe key property of the KMC algorithm (and of the FRM one) is that if the rates are correct, if the processes associated with the rates are of the [[Poisson process]] type, and if different processes are independent (i.e. not correlated) then the KMC algorithm gives the correct time scale for the evolution of the simulated system. There was some debate about the correctness of the time scale for rKMC algorithms, but this was also rigorously shown to be correct.<ref name=\"Serebrinsky2011\" />\n\nIf furthermore the transitions follow [[detailed balance]], the KMC algorithm can be used to simulate thermodynamic equilibrium. However, KMC is widely used to simulate non-equilibrium processes,<ref>B. Meng and W. H. Weinberg, J. Chem. Phys. '''100''', 5280 (1994).</ref> in which case detailed balance need not be obeyed.\n\nThe rfKMC algorithm is efficient in the sense that every iteration is guaranteed to produce a transition. However, in the form presented above it requires <math>N</math> operations for each transition, which is not too efficient. In many cases this can be much improved on by binning the same kinds of transitions into bins, and/or forming a tree data structure of the events. A constant-time scaling algorithm of this type has recently been developed and tested.<ref>A. Slepoy, A. P. Thompson, and S. J. Plimpton, A constant-time kinetic Monte Carlo \nalgorithm for simulation of large biochemical reaction networks, Journal of Chemical Physics, Volume 128, Issue 20, December 2007, Page 205101</ref>\n\nThe major disadvantage with rfKMC is that all possible rates <math>r_{ki}</math> and reactions have to be known in advance. The method itself can do nothing about predicting them. The rates and reactions must be obtained from other methods, such as [[diffusion]] (or other) experiments, [[molecular dynamics]] or [[density-functional theory]] simulations.\n\n==Examples of use==\nKMC has been used in simulations of the following physical systems:\n# Surface diffusion\n# Dislocation mobility<ref>{{cite journal|last1=Cai|first1=W.|last2=Bulatov|first2=V. V.|last3=Justo|first3=J. F.|last4=Argon|first4=A.S|last5=Yip|first5=S.|title=Intrinsic mobility of a dissociated Dislocation in silicon|journal=Phys. Rev. Lett.|date=2000|volume=84|issue=15|pages=3346–9|doi=10.1103/PhysRevLett.84.3346|pmid=11019086|bibcode=2000PhRvL..84.3346C}}</ref> <ref>{{cite journal |last1=Cai |first1=W. |last2=Bulatov |first2=V. V. |last3=Justo |first3=J. F. |last4=Argon |first4=A. S. |last5=Yip |first5=S. |title=Kinetic Monte Carlo approach to modeling dislocation mobility |journal=Comput. Mater. Sci. |date=2002 |volume=23 |issue=1–4 |page=124–130 |doi=10.1016/S0927-0256(01)00223-3}}</ref>\n# Surface growth<ref>B. Meng, W.H. Weinberg, Surface Science '''364''' (1996) 151-163.</ref>\n# [[Vacancy defect|Vacancy]] diffusion in alloys (this was the original use<ref name=\":0\">W. M. Young and E. W. Elcock, Proceedings of the Physical Society  89 (1966) 735.</ref>)\n# Coarsening of domain evolution\n# Defect mobility and clustering in ion or neutron irradiated solids including, but not limited to, damage accumulation and amorphization/recrystallization models.\n# Viscoelasticity of physically crosslinked networks<ref>S.A. Baeurle, T. Usami and A.A. Gusev, Polymer 47 (2006) 8604 .</ref>\n\nTo give an idea what the \"objects\" and \"events\" may be in practice, here is one concrete simple example, corresponding to example 2 above.\n\nConsider a system where individual atoms are deposited on a surface one at a time (typical of [[physical vapor deposition]]), but also may migrate on the surface with some known jump rate <math>w</math>. In this case the \"objects\" of the KMC algorithm are simply the individual atoms.\n\nIf two atoms come right next to each other, they become immobile. Then the flux of incoming atoms determines a rate ''r''<sub>deposit</sub>, and the system can be simulated with KMC considering all deposited mobile atoms which have not (yet) met a counterpart and become immobile. This way there are the following events possible at each KMC step:\n* A new atom comes in with rate 'r''<sub>deposit</sub>\n* An already deposited atom jumps one step with rate ''w''.\n\nAfter an event has been selected and carried out with the KMC algorithm, one then needs to check whether the new or just jumped atom has become immediately adjacent to some other atom. If this has happened, the atom(s) which are now adjacent needs to be moved away from the list of mobile atoms, and correspondingly their jump events removed from the list of possible events.\n\nNaturally in applying KMC to problems in physics and chemistry, one has to first consider whether the real system follows the assumptions underlying KMC well enough.\nReal processes do not necessarily have well-defined rates, the\ntransition processes may be correlated, in case of atom or particle jumps\nthe jumps may not occur in random directions, and so on. When simulating\nwidely disparate time scales one also needs to consider whether\nnew processes may be present at longer time scales. If any of these\nissues are valid, the time scale and system evolution predicted by KMC\nmay be skewed or even completely wrong.\n\n==History==\nThe first  publication which described the basic features of the KMC method (namely using a cumulative function to select an event and a time scale calculation of the form 1/''R'') was by Young and Elcock in 1966.<ref name=\":0\" /> The residence-time algorithm was also published at about the same time.<ref>D.R. Cox and H.D. Miller, The Theory of Stochastic Processes (Methuen, London), 1965, pp.&nbsp;6–7.</ref>\n\nApparently independent of the work of Young and Elcock, Bortz, Kalos and Lebowitz<ref name=\"Bortz1975\" /> developed a KMC algorithm for simulating the [[Ising model]], which they called the ''n-fold way''. The basics of their algorithm is the same as that of Young,<ref name=\":0\" /> but they do provide much greater detail on the method.\n\nThe following year [[Dan Gillespie]] published what is now known as the [[Gillespie algorithm]] to describe chemical reactions.<ref>D. T. Gillespie, Journal of Computational Physics 22 (1976) 403</ref> The algorithm is similar and the time advancement scheme essentially the same as in KMC.\n\nThere is as of the writing of this (June 2006) no definitive treatise of the theory of KMC, but Fichthorn and Weinberg have discussed the theory for thermodynamic equilibrium KMC simulations in detail.<ref>K. A. Fichthorn and W. H. Weinberg, [https://dx.doi.org/10.1063/1.461138 Journal of Chemical Physics '''95''' (1991) 1090] (needs subscription)</ref> A good introduction is given also by Art Voter,<ref>A. F. Voter, Introduction to the Kinetic Monte Carlo Method, in Radiation Effects in Solids, edited by K. E. Sickafus and E. A. Kotomin (Springer, NATO Publishing Unit, Dordrecht, The Netherlands, 2005).</ref>[https://web.archive.org/web/20081010112418/http://www.ipam.ucla.edu/publications/matut/matut_5898_preprint.pdf] and by A.P.J. Jansen,<ref>A.P.J. Jansen, An Introduction To Monte Carlo Simulations Of Surface Reactions, Condensed Matter, abstract [https://arxiv.org/abs/cond-mat/0303028 cond-mat/0303028].</ref>[https://arxiv.org/abs/cond-mat/0303028],\nand a recent review is (Chatterjee 2007)<ref>A. Chatterjee and D. G. Vlachos, An overview of spatial microscopic and accelerated kinetic Monte Carlo methods, J. Computer-Aided Mater. Des. '''14''', 253 (2007).</ref> or (Chotia 2008).<ref>A. Chotia, M.\n Viteau, T. Vogt, D. Comparat and P. Pillet, Kinetic Monte Carlo \nmodelling of dipole blockade in Rydberg excitation experiment, New \nJournal of Physics '''10''' pages 045031 (2008)</ref>\n\nIn March, 2006 the, probably, first commercial software using Kinetic Monte Carlo to simulate the diffusion and activation/deactivation of dopants in Silicon and Silicon-like materials is released by [[Synopsys]], reported by Martin-Bragado et al.<ref>I. \nMartin-Bragado, S. Tian, M. Johnson, P. Castrillo, R. Pinacho, J. Rubio \nand M. Jaraiz, Modeling charged defects, dopant diffusion and activation\n mechanisms for TCAD simulations using kinetic Monte Carlo. [https://dx.doi.org/10.1016/j.nimb.2006.10.035 Nuclear Instruments and Methods in Physics Research B, '''253''' (2006) 63-67 (needs subscription).]</ref>\n\n==Varieties of KMC==\nThe KMC method can be subdivided by how the objects are moving or reactions\noccurring. At least the following subdivisions are used:\n\n* Lattice KMC ('''LKMC''') signifies KMC carried out on an atomic [[crystal structure|lattice]]. Often this variety is also called atomistic KMC, ('''AKMC'''). A typical example is simulation of [[vacancy (chemistry)|vacancy]] [[diffusion]] in [[alloy]]s, where a [[vacancy (chemistry)|vacancy]] is allowed to jump around the lattice with rates that depend on the local elemental composition.<ref>{{cite journal|last1=Mason|first1=D.R.|last2=Hudson|first2=T.S.|last3=Sutton|first3=A.P.|title=Fast recall of state-history in kinetic Monte Carlo simulations utilizing the Zobrist key|journal=Computer Physics Communications|date=January 2005|volume=165|issue=1|pages=37–48|doi=10.1016/j.cpc.2004.09.007|bibcode = 2005CoPhC.165...37M }}</ref>\n* Object KMC ('''OKMC''') means KMC carried out for [[crystallographic defect|defects]] or [[impurity|impurities]], which are jumping either in random or lattice-specific directions. Only the positions of the jumping objects are included in the simulation, not those of the 'background' lattice atoms. The basic KMC step is one object jump.\n* Event KMC ('''EKMC''') or First-passage KMC ('''FPKMC''') signifies an OKMC variety where the following reaction between objects (e.g. clustering of two [[impurity|impurities]] or [[vacancy (chemistry)|vacancy]]-[[interstitial defect|interstitial]] annihilation) is chosen with the KMC algorithm, taking the object positions into account, and this event is then immediately carried out.<ref>J. Dalla Torre, J.-L. Bocquet, N.V. Doan, E. Adam and A. Barbu, Phil. Mag. '''85''' (2005), p.&nbsp;549.</ref><ref>T. Opplestrup, V. V. Bulatov, G. H. Gilmer, M. H. Kalos, and B. Sadigh, First-Passage Monte Carlo Algorithm: Diffusion without All the Hops, \nPhysical Review Letters 97, 230602 (2006)</ref>\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://www.roentzsch.org/RealBit/ 3D lattice kinetic Monte Carlo simulation in 'bit language']\n* [http://www.roentzsch.org/Rayleigh/ KMC simulation of the Plateau-Rayleigh instability]\n* [http://www.roentzsch.org/SurfDiff/ KMC simulation of f.c.c. vicinal (100)-surface diffusion]\n* [http://skmf.eu '''Stochastic Kinetic Mean Field Model'''  (gives similar results as lattice kinetic Monte Carlo, however, far more cost-effective and easier to realise — open source program code is provided)]\n\n[[Category:Monte Carlo methods]]\n[[Category:Statistical mechanics]]\n[[Category:Stochastic simulation]]"
    },
    {
      "title": "Markov chain Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo",
      "text": "<math></math>{{Bayesian statistics}}\n\nIn [[statistics]], '''Markov chain Monte Carlo''' ('''MCMC''') methods comprise a class of [[algorithm]]s for sampling from a [[probability distribution]]. By constructing a [[Markov chain]] that has the desired distribution as its [[Markov chain#Steady-state analysis and limiting distributions|equilibrium distribution]], one can obtain a sample of the desired distribution by observing{{clarify|reason=What does it mean to observe a Markov chain?|date=May 2019}} the chain after a number of steps. The more steps there are, the more closely the distribution of the sample matches the actual desired distribution.\n\n== Application domains ==\nMarkov chain Monte Carlo methods are primarily used for calculating [[Numerical analysis|numerical approximations]] of [[Multiple integral|multi-dimensional integrals]], for example in [[Bayesian statistics]], [[computational physics]], [[computational biology]],<ref>{{Cite journal|last=Gupta|first=Ankur|last2=Rawlings|first2=James B. | date = April 2014 |title=Comparison of Parameter Estimation Methods in Stochastic Chemical Kinetic Models: Examples in Systems Biology |journal=AIChE Journal|volume=60|issue=4|pages=1253–1268|doi=10.1002/aic.14409 |pmc=4946376|pmid=27429455}}</ref> and [[computational linguistics]].<ref>See Gill 2008.</ref><ref>See Robert & Casella 2004.</ref>\n\nIn Bayesian statistics, the recent development of Markov chain Monte Carlo methods has been a key step in making it possible to compute large [[Bayesian network#Hierarchical models|hierarchical models]] that require integrations over hundreds or even thousands of unknown parameters.<ref>{{cite book|last1=Banerjee|first1=Sudipto|last2=Carlin|first2=Bradley P.|last3=Gelfand|first3=Alan P.|title=Hierarchical Modeling and Analysis for Spatial Data|publisher=CRC Press|isbn=978-1-4398-1917-3|page=xix|edition=Second|date=2014-09-12}}</ref>\n\nIn [[rare event sampling]], they are also used for generating samples that gradually populate the rare failure region.\n\n== General explanation ==\n[[File:Metropolis algorithm convergence example.png|thumbnail|upright=1.25|Convergence of the [[Metropolis–Hastings algorithm]]. Markov chain Monte Carlo attempts to approximate the blue distribution with the orange distribution.]]\n\nMarkov chain Monte Carlo methods create samples from a possibly multi-dimensional continuous [[random variable]], with [[probability density]] proportional to a known function. These samples can be used to evaluate an integral over that variable, as its [[expected value]] or [[variance]].\n\nPractically, an [[Statistical ensemble|ensemble]] of chains is generally developed, starting from a set of points arbitrarily chosen and sufficiently distant from each other. These chains are [[stochastic processes]] of \"walkers\" which move around randomly according to an algorithm which looks for places with a reasonably high contribution to the integral to move into next, assigning them higher probabilities.\n\nRandom walk Monte Carlo methods are a kind of random [[Computer simulation|simulation]] or [[Monte Carlo method]]. However, whereas the random samples of the integrand used in a conventional [[Monte Carlo integration]] are [[statistically independent]], those used in Markov chain Monte Carlo methods are [[autocorrelation|autocorrelated]].\n\nThese algorithms create [[Markov chains]] such that they have an [[Markov chain#Steady-state analysis and limiting distributions|equilibrium distribution]] which is proportional to the function given.\n\n==Reducing correlation==\nWhile MCMC methods were created to address multi-dimensional problems better than simple Monte Carlo algorithms, when the number of dimensions rises they too tend to suffer the [[curse of dimensionality]]: the regions of higher probability tend to stretch and get lost in a increasing volume of space that gives little contribution to the desired integral. One way to address this problem could be shortening the steps of the walker, so that it doesn't continuously try to exit the highest probability region, though this way the process would be highly autocorrelated and quite ineffective (i.e. many steps would be required for an accurate result). More sophisticated methods{{Which?|date=April 2019}} use various ways of reducing the autocorrelation, while managing to keep the process in the regions that give a higher contribution to the integral. These algorithms{{Which?|date=April 2019}} usually rely on a more complicated theory, and may be harder to implement, but they usually exhibit faster convergence (fewer steps required).\n\n== Examples ==\nExamples of random walk Monte Carlo methods include the following:\n* [[Metropolis–Hastings algorithm]]: This method generates a Markov chain using a proposal density for new steps and a method for rejecting some of the proposed moves. It is actually a general framework which includes as special cases the very first and simpler MCMC (Metropolis algorithm) and many more recent alternatives listed below.\n**[[Gibbs sampling]]: This method requires all the [[conditional distribution]]s of the target distribution to be sampled exactly. When drawing from the full-conditional distributions is not straightforward other samplers-within-Gibbs are used (e.g., see <ref>{{Cite journal|title = Adaptive Rejection Sampling for Gibbs Sampling|journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1992-01-01|pages = 337–348|volume = 41|issue = 2|doi = 10.2307/2347565|first = W. R.|last = Gilks|first2 = P.|last2 = Wild|jstor=2347565}}</ref><ref>{{Cite journal|title = Adaptive Rejection Metropolis Sampling within Gibbs Sampling|journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1995-01-01|pages = 455–472|volume = 44|issue = 4|doi = 10.2307/2986138|first = W. R.|last = Gilks|first2 = N. G.|last2 = Best|first3 = K. K. C.|last3 = Tan|jstor=2986138}}</ref><ref>{{Cite journal|title = Independent Doubly Adaptive Rejection Metropolis Sampling Within Gibbs Sampling|journal = IEEE Transactions on Signal Processing|date = 2015-06-01|issn = 1053-587X|pages = 3123–3138|volume = 63|issue = 12|doi = 10.1109/TSP.2015.2420537|first = L.|last = Martino|first2 = J.|last2 = Read|first3 = D.|last3 = Luengo|arxiv = 1205.5494|bibcode = 2015ITSP...63.3123M |ref=harv}}</ref>). Gibbs sampling is popular partly because it does not require any 'tuning'.\n** [[Metropolis-adjusted Langevin algorithm]] and other methods that rely on the gradient (and possibly second derivative) of the log target density to propose steps that are more likely to be in the direction of higher probability density.<ref>See Stramer 1999.</ref>\n**[[Pseudo-Marginal Metropolis-Hastings algorithm|Pseudo-marginal Metropolis–Hastings]]: This method replaces the evaluation of the density of the target distribution with an unbiased estimate and is useful when the target density is not available analytically, e.g. [[Latent variable model|latent variable models]].\n\n* [[Slice sampling]]: This method depends on the principle that one can sample from a distribution by sampling uniformly from the region under the plot of its density function.  It alternates uniform sampling in the vertical direction with uniform sampling from the horizontal 'slice' defined by the current vertical position.\n* [[Multiple-try Metropolis]]: This method is a variation of the Metropolis–Hastings algorithm that allows multiple trials at each point. By making it possible to take larger steps at each iteration, it helps address the curse of dimensionality.<ref>{{Cite journal|title = The Multiple-Try Method and Local Optimization in Metropolis Sampling|journal = Journal of the American Statistical Association|date = 2000-03-01|issn = 0162-1459|pages = 121–134|volume = 95|issue = 449|doi = 10.1080/01621459.2000.10473908|first = Jun S.|last = Liu|first2 = Faming|last2 = Liang|first3 = Wing Hung|last3 = Wong}}</ref><ref>{{Cite journal|title = On the flexibility of the design of multiple try Metropolis schemes|journal = Computational Statistics|date = 2013-07-11|issn = 0943-4062|pages = 2797–2823|volume = 28|issue = 6|doi = 10.1007/s00180-013-0429-2|first = Luca|last = Martino|first2 = Jesse|last2 = Read|arxiv = 1201.0646}}</ref>\n* [[Reversible-jump]]: This method is a variant of the Metropolis–Hastings algorithm that allows proposals that change the dimensionality of the space.<ref>See Green 1995.</ref>  Markov chain Monte Carlo methods that change dimensionality have long been used in [[statistical physics]] applications, where for some problems a distribution that is a [[grand canonical ensemble]] is used (e.g., when the number of molecules in a box is variable).  But the reversible-jump variant is useful when doing Markov chain Monte Carlo or Gibbs sampling over [[nonparametric]] Bayesian models such as those involving the [[Dirichlet process]] or [[Chinese restaurant process]], where the number of mixing components/clusters/etc. is automatically inferred from the data.\n* [[Hamiltonian Monte Carlo|Hamiltonian (or Hybrid) Monte Carlo]] (HMC): Tries to avoid random walk behaviour by introducing an auxiliary [[momentum]] vector and implementing [[Hamiltonian dynamics]], so the potential energy function is the target density. The momentum samples are discarded after sampling. The end result of Hybrid Monte Carlo is that proposals move across the sample space in larger steps; they are therefore less correlated and converge to the target distribution more rapidly.\n\n===Training-based Markov chain Monte Carlo===\nUnlike most of the current Markov chain Monte Carlo methods that ignore the previous trials, using a new algorithm the Markov chain Monte Carlo algorithm is able to use the previous steps and generate the next candidate. This training-based algorithm is able to speed-up the Markov chain Monte Carlo algorithm by an order of magnitude.<ref>{{cite journal|last1=Tahmasebi|first1=Pejman|last2=Javadpour|first2=Farzam|last3=Sahimi|first3=Muhammad|title=Stochastic shale permeability matching: Three-dimensional characterization and modeling|journal=International Journal of Coal Geology|date=August 2016|volume=165|pages=231–242|doi=10.1016/j.coal.2016.08.024|url=https://www.researchgate.net/publication/307626119}}</ref>\n\nInteracting Markov chain Monte Carlo methodologies are a class of [[mean field particle methods]] for obtaining [[Pseudo-random number sampling|random samples]] from a sequence of probability distributions with an increasing level of sampling complexity.<ref name=\"dp13\">{{cite book|last = Del Moral|first = Pierre|title = Mean field simulation for Monte Carlo integration|year = 2013|publisher = Chapman & Hall/CRC Press|quote = Monographs on Statistics & Applied Probability|url = http://www.crcpress.com/product/isbn/9781466504059|pages = 626}}</ref> These probabilistic models include path space state models with increasing time horizon, posterior distributions w.r.t. sequence of partial observations, increasing constraint level sets for conditional distributions, decreasing temperature schedules associated with some Boltzmann-Gibbs distributions, and many others. In principle, any Markov chain Monte Carlo sampler can be turned into an interacting Markov chain Monte Carlo sampler. These interacting Markov chain Monte Carlo samplers can be interpreted as a way to run in parallel a sequence of Markov chain Monte Carlo samplers. For instance, interacting [[simulated annealing]] algorithms are based on independent Metropolis-Hastings moves interacting sequentially with a selection-resampling type mechanism. In contrast to traditional Markov chain Monte Carlo methods, the precision parameter of this class of interacting Markov chain Monte Carlo samplers is ''only'' related to the number of interacting Markov chain Monte Carlo samplers. These advanced particle methodologies belong to the class of Feynman-Kac particle models,<ref name=\"dp04\">{{cite book|last = Del Moral|first = Pierre|title = Feynman-Kac formulae. Genealogical and interacting particle approximations|year = 2004|publisher = Springer|quote = Series: Probability and Applications|url = https://www.springer.com/mathematics/probability/book/978-0-387-20268-6|pages = 575}}</ref><ref name=\"dmm002\">{{cite book|last1 = Del Moral|first1 = Pierre|last2 = Miclo|first2 = Laurent|title = Branching and Interacting Particle Systems Approximations of Feynman-Kac Formulae with Applications to Non-Linear Filtering.|journal = Lecture Notes in Mathematics|date = 2000|volume = 1729|pages = 1–145|url = http://archive.numdam.org/ARCHIVE/SPS/SPS_2000__34_/SPS_2000__34__1_0/SPS_2000__34__1_0.pdf|doi = 10.1007/bfb0103798|isbn = 978-3-540-67314-9}}</ref>  also called Sequential Monte Carlo or [[particle filter]] methods in [[Bayesian inference]] and [[signal processing]] communities.<ref name=\":3\">{{Cite journal|title = Sequential Monte Carlo samplers - P. Del Moral - A. Doucet - A. Jasra - 2006 - Journal of the Royal Statistical Society: Series B (Statistical Methodology) - Wiley Online Library| doi=10.1111/j.1467-9868.2006.00553.x|volume=68|issue = 3|year=2006|journal=Journal of the Royal Statistical Society. Series B (Statistical Methodology)|pages=411–436 | last1 = Del Moral | first1 = Pierre|arxiv=cond-mat/0212648}}</ref> Interacting Markov chain Monte Carlo methods can also be interpreted as a mutation-selection [[Genetic algorithm|genetic particle algorithm]] with Markov chain Monte Carlo mutations.\n\nMarkov Chain quasi-Monte Carlo (MCQMC)<ref>Chen, S., Josef Dick, and Art B. Owen. \"Consistency of Markov chain quasi-Monte Carlo on continuous state spaces.\" The Annals of Statistics 39.2 (2011): 673-701.</ref><ref>Tribble, Seth D. Markov chain Monte Carlo algorithms using completely uniformly distributed driving sequences. Diss. Stanford University, 2007.</ref>\nThe advantage of [[low-discrepancy sequence]]s in lieu of random numbers for simple independent Monte Carlo sampling is well known.<ref>Papageorgiou, Anargyros, and J. F. Traub. \"Beating Monte Carlo.\" Risk 9.6 (1996): 63-65.</ref> This procedure, known as [[Quasi-Monte Carlo method]] (QMC),<ref>{{cite journal | last1 = Sobol | first1 = Ilya M | year = 1998 | title = On quasi-monte carlo integrations | url = | journal = Mathematics and Computers in Simulation | volume = 47 | issue = 2| pages = 103–112 | doi=10.1016/s0378-4754(98)00096-2}}</ref> yields an integration error that decays at a superior rate to that obtained by IID sampling, by the [[Koksma-Hlawka inequality]]. Empirically it allows the reduction of both estimation error and convergence time by an order of magnitude {{Citation needed|date=April 2015}}.  \nThe Array-RQMC method<ref>L'Ecuyer, P., C. Lécot, and B. Tuffin. \"A Randomized Quasi-Monte Carlo Simulation Method for Markov Chains.\" Operations Research 56, 4 (2008): 958-975.</ref>  combines randomized quasi-Monte Carlo and Markov chain simulation by simulating <math>n</math> chains simultaneously in a way that the empirical distribution of the <math>n</math> states at any given step is a better approximation of the true distribution of the chain than with ordinary MCMC. In empirical experiments, the variance of the average of a function of the state sometimes converges at rate <math>O(n^{-2})</math> or even faster, instead of the <math>O(n^{-1})</math> Monte Carlo rate.<ref>L'Ecuyer, P., D. Munger, C. Lécot, and B. Tuffin. \"Sorting Methods and Convergence Rates for Array-RQMC: Some Empirical Comparisons.\" Mathematics and Computers in Simulation 143 (2018), 191-201.</ref> \n\n==Convergence==\n\nUsually it is not hard to construct a Markov chain with the desired properties. The more difficult problem is to determine how many steps are needed to converge to the stationary distribution within an acceptable error.<ref name=\"Gelman and Rubin, 1992\">{{cite journal|last1=Gelman|first1=A.|last2=Rubin|first2=D.B.|title=Inference from iterative simulation using multiple sequences (with discussion)|journal=Statistical Science|date=1992|volume=7|issue=4|pages=457–511|doi=10.1214/ss/1177011136|bibcode=1992StaSc...7..457G}}</ref> A good chain will have [[Markov chain mixing time|rapid mixing]]: the stationary distribution is reached quickly starting from an arbitrary position. A standard empirical method to assess convergence is to run several independent simulated Markov chains and check that the ratio of inter-chain to intra-chain variances for all the parameters sampled is close to 1.<ref name=\"Gelman and Rubin, 1992\" /><ref name=\"Colwes and Carlin, 1996\">{{cite journal|last1=Cowles|first1=M.K.|last2=Carlin|first2=B.P.|title=Markov chain Monte Carlo convergence diagnostics: a comparative review|journal=Journal of the American Statistical Association|date=1996|volume=91|issue=434|pages=883–904|doi=10.1080/01621459.1996.10476956|citeseerx=10.1.1.53.3445}}</ref>\n\nTypically, Markov chain Monte Carlo sampling can only approximate the target distribution, as there is always some residual effect of the starting position. More sophisticated Markov chain Monte Carlo-based algorithms such as [[coupling from the past]] can produce exact samples, at the cost of additional computation and an unbounded (though finite in expectation) [[running time]].\n\nMany random walk Monte Carlo methods move around the equilibrium distribution in relatively small steps, with no tendency for the steps to proceed in the same direction. These methods are easy to implement and analyze, but unfortunately it can take a long time for the walker to explore all of the space. The walker will often double back and cover ground already covered.\n\nSee also [[Markov chain central limit theorem]]. A relatively accessible treatment of the theory related to convergence and stationarity of Metropolis-Hastings is given in <ref>Hill, S. D. and Spall, J. C. (2019), “Stationarity and Convergence of the Metropolis-Hastings Algorithm: Insights into Theoretical Aspects,” IEEE Control Systems Magazine, vol. 39(1), pp. 56–67. https://doi.org/10.1109/MCS.2018.2876959</ref>.\n\n== Software ==\nSeveral software programs provide MCMC sampling capabilities, for example:\n*Packages that use dialects of the [[Bayesian inference using Gibbs sampling|BUGS]] model language:\n**[[WinBUGS]] / [[OpenBUGS]]/ [https://www.multibugs.org/ MultiBUGS]\n**[[Just another Gibbs sampler|JAGS]]\n**[https://r-nimble.org/ NIMBLE]\n*[https://greta-dev.github.io/greta/ greta], a Bayesian statistical modeling language / R package which uses TensorFlow behind the scenes,<ref>{{Cite web|url=https://greta-dev.github.io/greta/software.html|title=greta's software dependencies and inspirations|last=|first=|date=|website=greta-dev.github.io|archive-url=|archive-date=|dead-url=|access-date=2018-10-02}}</ref> similar to PyMC3's use of Theano as the computational back-end\n*[[MCSim]]\n*[[PyMC3]]\n*[https://github.com/prmiles/pymcmcstat/wiki pymcmcstat]\n* [[R (programming language)]] with the packages adaptMCMC, atmcmc, BRugs, mcmc, MCMCpack, ramcmc, rjags, rstan, etc.\n*[[Stan (software)|Stan]]\n*[https://www.tensorflow.org/probability/ TensorFlow Probability] ([[Probabilistic programming language|probabilistic programming]] library built on [[TensorFlow]])\n*[http://micans.org/mcl/ MCL] (a cluster algorithm for graphs)<ref>{{cite journal|last1=Enright|first1=AJ|last2=Van Dongen|first2=S|last3=Ouzounis|first3=CA|title=An efficient algorithm for large-scale detection of protein families.|journal=Nucleic Acids Research|date=1 April 2002|volume=30|issue=7|pages=1575–84|pmid=11917018|pmc=101833|doi=10.1093/nar/30.7.1575}}</ref> and [https://bitbucket.org/azadcse/hipmcl/wiki/Home HipMCL] (a parallelized version)<ref>{{cite journal|last1=Azad|first1=A|last2=Pavlopoulos|first2=GA|last3=Ouzounis|first3=CA|last4=Kyrpides|first4=NC|last5=Buluç|first5=A|title=HipMCL: a high-performance parallel implementation of the Markov clustering algorithm for large-scale networks.|journal=Nucleic Acids Research|date=6 April 2018|volume=46|issue=6|pages=e33|doi=10.1093/nar/gkx1313|pmid=29315405|pmc=5888241}}</ref>\n* [http://dfm.io/emcee/current/ emcee] (MIT licensed pure-Python implementation of Goodman & Weare's Affine Invariant Markov chain Monte Carlo Ensemble sampler)\n* [https://www.causascientia.org/software/MacMCMC/MacMCMC.html MacMCMC] (Standalone, full-featured MCMC application for Mac OS)\n\n== See also ==\n*[[Coupling from the past]]\n*[[Metropolis-adjusted Langevin algorithm]]\n\n== References ==\n=== Citations ===\n{{Reflist}}\n\n=== Sources ===\n{{refbegin|40em}}\n* Christophe Andrieu, Nando De Freitas, Arnaud Doucet and Michael I. Jordan [http://www.cs.princeton.edu/courses/archive/spr06/cos598C/papers/AndrieuFreitasDoucetJordan2003.pdf ''An Introduction to MCMC for Machine Learning''], 2003\n* {{cite book\n | last1 = Asmussen\n | first1 = Søren\n | last2 = Glynn\n | first2 = Peter W.\n | title = Stochastic Simulation: Algorithms and Analysis\n | publisher = Springer\n | series = Stochastic Modelling and Applied Probability\n | volume = 57\n | year = 2007\n}}\n*{{cite web\n | first = P.\n | last = Atzberger\n | url = http://www.math.ucsb.edu/~atzberg/spring2006/monteCarloMethod.pdf\n | title = An Introduction to Monte-Carlo Methods\n}}\n*{{cite book\n | first = Bernd A.\n | last = Berg\n | author1link = Bernd A. Berg\n | title = Markov Chain Monte Carlo Simulations and Their Statistical Analysis\n | publisher = [[World Scientific]]\n | year = 2004\n}}\n*{{cite book\n | last = Bolstad\n | first = William M.\n | year = 2010\n | title = Understanding Computational Bayesian Statistics\n | publisher = Wiley\n | isbn = 978-0-470-04609-8\n}}\n*{{cite journal\n | first1 = George\n | last1 = Casella\n | first2 = Edward I.\n | last2 = George\n | title = Explaining the Gibbs sampler\n | journal = [[The American Statistician]]\n | volume = 46\n | issue = 3\n | pages = 167–174\n | year = 1992\n | doi=10.2307/2685208\n| jstor = 2685208\n | citeseerx = 10.1.1.554.3993\n }} \n*{{cite journal\n | first1 = A.E.\n | last1 = Gelfand\n | first2 = A.F.M.\n | last2 = Smith\n | title = Sampling-Based Approaches to Calculating Marginal Densities\n | journal = [[Journal of the American Statistical Association]]\n | volume = 85\n | issue = 410\n | pages = 398–409\n | year = 1990\n | doi=10.1080/01621459.1990.10476213\n| citeseerx = 10.1.1.512.2330\n }}\n*{{cite book\n | first1 = Andrew\n | last1 = Gelman\n | author1link = Andrew Gelman\n | first2 = John B.\n | last2 = Carlin\n | first3 = Hal S.\n | last3 = Stern\n | first4 = Donald B.\n | last4 = Rubin\n | author4link = Donald B. Rubin\n | title = Bayesian Data Analysis\n | publisher = [[Chapman and Hall]]\n | edition = 1st\n | year = 1995\n}} ''(See Chapter 11.)''\n*{{cite journal\n | first1 = S.\n | last1 = Geman\n | first2 = D.\n | last2 = Geman\n | author2link = Donald Geman\n | title = Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images\n | journal = [[IEEE Transactions on Pattern Analysis and Machine Intelligence]]\n | volume = 6\n | issue = 6\n | pages = 721–741\n | year = 1984\n| doi = 10.1109/TPAMI.1984.4767596\n }}\n*{{cite book\n | last1 = Gilks\n | first1 = W.R.\n | last2 = Richardson\n | first2 = S.\n | first3 = D.J.\n | last3 = Spiegelhalter\n | author3link = David Spiegelhalter\n | title = Markov Chain Monte Carlo in Practice\n | publisher = [[Chapman and Hall]]/CRC\n | year = 1996\n}}\n*{{cite book\n | first = Jeff\n | last = Gill\n | title = Bayesian methods: a social and behavioral sciences approach\n | edition = 2nd\n | year = 2008\n | publisher = [[Chapman and Hall]]/CRC\n | isbn = 978-1-58488-562-7\n}}\n*{{cite journal\n | first = P.J.\n | last = Green\n | title = Reversible-jump Markov chain Monte Carlo computation and Bayesian model determination\n | journal = [[Biometrika]]\n | volume=82\n | issue = 4\n | pages = 711–732\n | year = 1995\n | doi = 10.1093/biomet/82.4.711\n| citeseerx = 10.1.1.407.8942\n }}\n*{{cite journal\n | first = Radford M.\n | last = Neal\n | title = Slice Sampling\n | journal = [[Annals of Statistics]]\n | volume = 31\n | issue = 3\n | pages = 705–767\n | year = 2003\n | jstor = 3448413\n | doi=10.1214/aos/1056562461\n}}\n*{{cite web\n | last = Neal\n | first = Radford M.\n | url = http://www.cs.utoronto.ca/~radford/review.abstract.html\n | title = ''Probabilistic Inference Using Markov Chain Monte Carlo Methods''\n | year = 1993\n}}\n*{{cite book\n |first = Christian P.\n |last = Robert\n |last2 = Casella\n |first2 = G.\n |title = Monte Carlo Statistical Methods\n |edition = 2nd\n |year = 2004\n |publisher = Springer\n |isbn = 978-0-387-21239-5\n}}\n*{{cite book\n | first1 = R.Y.\n | last1 = Rubinstein\n | first2 = D.P.\n | last2 = Kroese\n | title = Simulation and the Monte Carlo Method\n | edition = 2nd\n | publisher = [[John Wiley & Sons|Wiley]]\n | year = 2007\n | isbn = 978-0-470-17794-5\n}}\n*{{cite journal\n | first = R.L.\n | last = Smith\n | title = Efficient Monte Carlo Procedures for Generating Points Uniformly Distributed Over Bounded Regions\n | journal = [[Operations Research: A Journal of the Institute for Operations Research and the Management Sciences|Operations Research]]\n | volume = 32\n | issue = 6\n | pages = 1296–1308\n | year = 1984\n | doi = 10.1287/opre.32.6.1296\n}}\n* {{cite journal\n | first = J.C.\n | last = Spall\n | title = Estimation via Markov Chain Monte Carlo\n | journal = [[IEEE Control Systems Magazine]]\n | volume = 23\n | issue = 2\n | pages = 34–45\n |date=April 2003\n | doi=10.1109/mcs.2003.1188770\n}}\n*{{cite journal\n | last1 = Stramer\n | first1 = O.\n | last2 = Tweedie\n | first2 = R.\n | year = 1999\n | title = Langevin-Type Models II: Self-Targeting Candidates for MCMC Algorithms\n | journal = Methodology and Computing in Applied Probability\n | volume = 1\n | issue = 3\n | pages = 307–328\n | doi = 10.1023/A:1010090512027\n}}\n{{refend}}\n\n== Further reading ==\n\n{{refbegin}}\n*{{cite journal\n | first = Persi\n | last = Diaconis\n | author1link = Persi Diaconis\n | url = http://www.ams.org/bull/2009-46-02/S0273-0979-08-01238-X/S0273-0979-08-01238-X.pdf\n | title = The Markov chain Monte Carlo revolution\n | journal = [[Bull. Amer. Math. Soc.]]\n | volume = 46\n | issue = 2\n |date=April 2009\n | pages = 179–205\n | id = S 0273-0979(08)01238-X\n | doi=10.1090/s0273-0979-08-01238-x\n}}\n*{{Citation\n | last1 = Press\n | first1 = W.H.\n | author1link = William H. Press\n | last2 = Teukolsky\n | first2 = S.A.\n | author2link = Saul Teukolsky\n | last3 = Vetterling\n | first3 = W.T.\n | last4 = Flannery\n | first4 = B.P.\n | year = 2007\n | title = Numerical Recipes: The Art of Scientific Computing\n | edition = 3rd\n | publisher = [[Cambridge University Press]]\n | isbn = 978-0-521-88068-8\n | chapter = Section 15.8. Markov Chain Monte Carlo\n | chapter-url = http://apps.nrbook.com/empanel/index.html#pg=824\n}}\n*{{cite journal\n | last = Richey\n | first = Matthew\n | url = http://stat.wharton.upenn.edu/~stjensen/stat542/lecture14.mcmchistory.pdf\n | title = The Evolution of Markov Chain Monte Carlo Methods\n | journal = [[The American Mathematical Monthly]]\n | volume = 117\n | issue = 5\n |date=May 2010\n | pages = 383–413\n | doi=10.4169/000298910x485923\n| citeseerx = 10.1.1.295.4478\n }}\n{{refend}}\n\n== External links ==\n*[https://web.archive.org/web/20110531150413/http://www.bioss.ac.uk/students/alexm/MCMCintroPresentation.pdf MCMC sampling and other methods in a basic overview], by Alexander Mantzaris ([http://www.bioss.ac.uk/students/alexm/MCMCintroPresentation.pdf original link - now broken])\n*[https://pymc-devs.github.io/pymc/ PyMC] - Python module implementing Bayesian statistical models and fitting algorithms, including Markov chain Monte Carlo.\n*[http://a2rms.sourceforge.net IA2RMS] is a Matlab code of the \"Independent Doubly Adaptive Rejection Metropolis Sampling\" method, {{harvtxt |Martino |Read |Luengo |2015}}, for drawing from the full-conditional densities within a Gibbs sampler.\n\n{{DEFAULTSORT:Markov Chain Monte Carlo}}\n[[Category:Monte Carlo methods]]\n[[Category:Markov chain Monte Carlo| ]]\n[[Category:Computational statistics]]\n[[Category:Markov models]]\n[[Category:Bayesian estimation]]"
    },
    {
      "title": "Marsaglia polar method",
      "url": "https://en.wikipedia.org/wiki/Marsaglia_polar_method",
      "text": "{{More citations needed|date=December 2011}}\n\nThe '''polar method''' (attributed to [[George Marsaglia]], 1964<ref>{{Cite journal |jstor = 2027592|title = A Convenient Method for Generating Normal Variables|journal = SIAM Review|volume = 6|issue = 3|pages = 260–264|last1 = Marsaglia|first1 = G.|last2 = Bray|first2 = T. A.|year = 1964|doi = 10.1137/1006063}}</ref>) is a [[pseudo-random number sampling]] method for generating a pair of independent [[standard normal random variable]]s.<ref>Peter E. Kloeden Eckhard Platen Henri Schurz, Numerical Solution of SDE Through Computer Experiments, Springer, 1994.</ref> While it is superior to the [[Box–Muller transform]],<ref>{{Cite journal|title = Efficient sampling from truncated bivariate Gaussians via Box–Muller transformation|journal = Electronics Letters|pages = 1533–1534|volume = 48|issue = 24|doi = 10.1049/el.2012.2816|first = L.|last = Martino|first2 = D.|last2 = Luengo|first3 = J.|last3 = Míguez|year = 2012|citeseerx = 10.1.1.716.8683}}</ref><ref>{{citation|title=Monte Carlo Methods in Financial Engineering|volume=53|series=Applications of Mathematics: Stochastic Modelling and Applied Probability|first=Paul|last=Glasserman|publisher=Springer|year=2004|isbn=9780387004518|page=66|url=https://books.google.com/books?id=e9GWUsQkPNMC&pg=PA66}}.</ref> the [[Ziggurat algorithm]] is even more efficient.<ref>{{Cite journal | doi=10.1145/1287620.1287622|title = Gaussian random number generators| journal=ACM Computing Surveys| volume=39| issue=4| pages=11–es|year = 2007|last1 = Thomas|first1 = David B.| last2=Luk| first2=Wayne| last3=Leong| first3=Philip H.W.| last4=Villasenor| first4=John D.| citeseerx=10.1.1.127.5773}}</ref>\n\nStandard normal random variables are frequently used in [[computer science]], [[computational statistics]], and in particular, in applications of the [[Monte Carlo method]].\n\nThe polar method works by choosing random points (''x'',&nbsp;''y'') in the square &minus;1&nbsp;<&nbsp;''x''&nbsp;<&nbsp;1, &minus;1&nbsp;<&nbsp;''y''&nbsp;<&nbsp;1 until\n\n:<math> 0 < s=x^2+y^2 < 1, \\,</math>\n\nand then returning the required pair of normal [[random variable]]s as\n\n:<math> x\\sqrt{\\frac{-2\\ln(s)}{s}}\\,,\\ \\ y\\sqrt{\\frac{-2\\ln(s)}{s}},</math>\n\nor, equivalently,\n\n:<math> \\frac{x}{\\sqrt{s}} \\sqrt{-2\\ln(s)}\\,,\\ \\ \\frac{y}{\\sqrt{s}} \\sqrt{-2\\ln(s)},</math>\n\nwhere <math>x/\\sqrt{s}</math> and <math>y/\\sqrt{s}</math> represent the [[cosine]] and [[sine]] of the angle that the vector (''x'', ''y'') makes with ''x'' axis.\n\n==Theoretical basis==\nThe underlying theory may be summarized as follows:\n\nIf  ''u'' is uniformly distributed in the interval\n0&nbsp;≤&nbsp;''u''&nbsp;<&nbsp;1, then the point\n(cos(2π''u''),&nbsp;sin(2π''u''))\nis uniformly distributed on the unit circumference\n''x''<sup>2</sup>&nbsp;+&nbsp;''y''<sup>2</sup>&nbsp;=&nbsp;1, and multiplying that point by an independent\nrandom variable ρ whose distribution is\n\n:<math>\\Pr(\\rho<a)=\\int_0^a re^{-r^2/2}\\,dr </math>\n\nwill produce a point\n\n:<math> \\left(\\rho\\cos(2\\pi u),\\rho\\sin(2\\pi u)\\right) </math>\n\nwhose coordinates are jointly distributed as two independent standard\nnormal random variables.\n\n==History==\nThis idea dates back to [[Pierre-Simon Laplace|Laplace]], whom [[Carl Friedrich Gauss|Gauss]] credits with finding the above\n\n:<math>I=\\int_{-\\infty}^\\infty e^{-x^2/2}\\,dx </math>\n\nby taking the square root of\n\n:<math>I^2 = \\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty e^{-(x^2+y^2)/2}\\,dx\\,dy\n    =\\int_0^{2\\pi}\\int_0^\\infty re^{-r^2/2} \\, dr \\, d\\theta.</math>\n\nThe transformation to polar coordinates makes evident that θ is\nuniformly distributed (constant density) from 0 to 2π, and that the\nradial distance ''r'' has density\n\n:<math>re^{-r^2/2}. \\, </math>\n\n(''r''<sup>2</sup> has the appropriate [[chi square]] distribution.)\n\nThis method of producing a pair of independent standard normal variates by radially projecting a random point on the unit circumference to a distance given by the square root of a chi-square-2 variate is called the polar method for generating a pair of normal random variables,\n\n==Practical considerations==\nA direct application of this idea,\n\n:<math>x=\\sqrt{-2\\ln(u_1)}\\cos(2\\pi u_2),\\quad  y=\\sqrt{-2\\ln(u_1)}\\sin(2\\pi u_2)</math>\n\nis called the [[Box–Muller transform]], in which the chi variate is usually\ngenerated as\n\n:<math>\\sqrt{-2\\ln(u_1)},</math>\n\nbut that transform requires logarithm, square root, sine and cosine functions. On some processors, the cosine and sine of the same argument can be calculated in parallel using a single instruction.<ref>{{cite web|last=Kanter|first=David|title=Intel's Ivy Bridge Graphics Architecture|url=http://www.realworldtech.com/ivy-bridge-gpu/5/|work=Real World Tech|accessdate=8 April 2013}}</ref>  Notably for Intel-based machines, one can use fsincos assembler instruction or the expi instruction (available e.g. in D), to calculate  complex\n\n: <math>\\operatorname{expi}(z) = e^{i z} = \\cos(z) + i \\sin(z), \\, </math>\n\nand just separate the real and imaginary parts.\n\n'''Note:''' \nTo explicitly calculate the complex-polar form use the following substitutions in the general form,\n\nLet <math> r = \\sqrt{-2 \\ln(u_1)} </math> and <math> z = 2 \\pi u_2. </math> Then\n\n: <math> \\ re^{i z} = \\sqrt{-2 \\ln(u_1)} e^{i 2 \\pi u_2} =\\sqrt{-2 \\ln(u_1)}\\left[ \\cos(2 \\pi u_2) + i \\sin(2 \\pi u_2)\\right].</math>\n\nIn contrast, the polar method here removes the need to calculate a cosine and sine. Instead, by solving for a point on the unit circle, these two functions can be replaced with the ''x'' and ''y'' coordinates normalized to the <math>\\sqrt{x^2 + y^2}</math> radius. In particular, a random point (''x'',&nbsp;''y'') inside the unit circle is projected onto the unit circumference by setting <math>s=x^2+y^2</math> and forming the point\n\n:<math>\\left( \\frac{x}{\\sqrt{s}}, \\frac{y}{\\sqrt{s}} \\right), \\, </math>\n\nwhich is a faster procedure than calculating the cosine and sine. Some researchers argue that the conditional if instruction (for rejecting a point outside of the unit circle), can make programs slower on modern processors equipped with pipelining and branch prediction.<ref>This effect can be heightened in a GPU generating many variates in parallel, where a rejection on one processor can slow down many other processors. See section 7 of {{citation\n | last1 = Thomas | first1 = David B.\n | last2 = Howes | first2 = Lee W.\n | last3 = Luk | first3 = Wayne\n | editor1-last = Chow | editor1-first = Paul\n | editor2-last = Cheung | editor2-first = Peter Y. K.\n | contribution = A comparison of CPUs, GPUs, FPGAs, and massively parallel processor arrays for random number generation\n | doi = 10.1145/1508128.1508139\n | pages = 63–72\n | publisher = [[Association for Computing Machinery]]\n | title = Proceedings of the ACM/SIGDA 17th International Symposium on Field Programmable Gate Arrays, FPGA 2009, Monterey, California, USA, February 22–24, 2009\n | year = 2009| isbn = 9781605584102\n | citeseerx = 10.1.1.149.6066\n }}.</ref> Also this procedure requires about 27% more evaluations of the underlying random number generator (only <math>\\pi/4 \\approx 79\\%</math> of generated points lie inside of unit circle).\n\nThat random point on the circumference is then radially projected the required random distance by means of\n\n:<math>\\sqrt{-2\\ln(s)}, \\, </math>\n\nusing the same ''s'' because that ''s'' is independent of the random point on the circumference and is itself uniformly distributed from 0 to&nbsp;1.\n\n== Implementation ==\nSimple implementation in [[Java (programming language)|Java]] using the mean and standard deviation:\n<source lang=\"java\">\nprivate static double spare;\nprivate static boolean isSpareReady = false;\n\npublic static synchronized double getGaussian(double mean, double stdDev) {\n    if (isSpareReady) {\n        isSpareReady = false;\n        return spare * stdDev + mean;\n    } else {\n        double u, v, s;\n        do {\n            u = Math.random() * 2 - 1;\n            v = Math.random() * 2 - 1;\n            s = u * u + v * v;\n        } while (s >= 1 || s == 0);\n        double mul = Math.sqrt(-2.0 * Math.log(s) / s);\n        spare = v * mul;\n        isSpareReady = true;\n        return mean + stdDev * u * mul;\n    }\n}\n</source>\n\nAn implementation, not [[thread safe]], in [[C++]] using the mean and standard deviation:\n<source lang=\"c\" line=\"1\">\ndouble generateGaussianNoise(const double& mean, const double &stdDev) {\n\n\tstatic bool hasSpare = false;\n\tstatic double spare;\n\n\tif(hasSpare) {\n\t\thasSpare = false;\n\t\treturn mean + stdDev * spare;\n\t}\n\n\thasSpare = true;\n\tstatic double u, v, s;\n\tdo {\n\t\tu = (rand() / ((double) RAND_MAX)) * 2.0 - 1.0;\n\t\tv = (rand() / ((double) RAND_MAX)) * 2.0 - 1.0;\n\t\ts = u * u + v * v;\n\t}\n\twhile( (s >= 1.0) || (s == 0.0) );\n\n\ts = sqrt(-2.0 * log(s) / s);\n\tspare = v * s;\n\treturn mean + stdDev * u * s;\n}\n</source>\n\n[[C++11]] GNU GCC [[libstdc++]]'s implementation of std::normal_distribution [https://stackoverflow.com/a/25684539/3393574 uses] the Marsaglia polar method, as quoted from [https://gcc.gnu.org/onlinedocs/gcc-4.6.0/libstdc++/api/a01001_source.html#l01649 herein.]\n\n<source lang=\"c\" line=\"1\">\nif (_M_saved_available)\n{\n    _M_saved_available = false;\n    ret = _M_saved;\n}\nelse\n{\n    result_type x, y, r2;\n    do\n    {\n        x = result_type(2.0) * aurng() - 1.0;\n        y = result_type(2.0) * aurng() - 1.0;\n        r2 = x * x + y * y;\n    }\n    while (r2 > 1.0 || r2 == 0.0);\n\n    const result_type mult = std::sqrt(-2 * std::log(r2) / r2);\n    _M_saved = x * mult;\n    _M_saved_available = true;\n    ret = y * mult;\n}\n</source>\n\n== References ==\n{{Reflist}}\n\n[[Category:Monte Carlo methods]]\n[[Category:Pseudorandom number generators]]\n[[Category:Non-uniform random numbers]]"
    },
    {
      "title": "Mean field particle methods",
      "url": "https://en.wikipedia.org/wiki/Mean_field_particle_methods",
      "text": "'''Mean field particle methods''' are a broad class of ''interacting type'' [[Monte Carlo method|Monte Carlo]] algorithms for simulating from a sequence of probability distributions satisfying a nonlinear evolution equation<ref name=\"kol10\"/><ref name=\"dp13\">{{cite journal|last=Del Moral|first=Pierre|title=Mean field simulation for Monte Carlo integration|journal=Annales de l'Institut Henri Poincare Section (B) Probability and Statistics|volume=37|issue=2|year=2013 |quote=Monographs on Statistics & Applied Probability|url=http://www.crcpress.com/product/isbn/9781466504059|pages=626}}</ref><ref name=\"dp04\" /><ref name=\"dmm00\" /> These flows of probability measures can always be interpreted as the distributions of the random states of a Markov process whose transition probabilities depends on the distributions of the current random states.<ref name=\"kol10\">{{cite book|last=Kolokoltsov|first=Vassili|title=Nonlinear Markov processes|year=2010|publisher=Cambridge Univ. Press |pages=375}}</ref><ref name=\"dp13\"/> A natural way to simulate these sophisticated nonlinear Markov processes is to sample a large number of copies of the process, replacing in the evolution equation the unknown distributions of the random states by the sampled [[empirical measure]]s.  In contrast with traditional Monte Carlo and [[Markov chain Monte Carlo]] methods these mean field particle techniques rely on '''sequential interacting samples'''. The terminology mean field reflects the fact that each of the ''samples (a.k.a. particles, individuals, walkers, agents, creatures, or phenotypes)'' interacts with the empirical measures of the process. When the size of the system tends to infinity, these random empirical measures converge to the deterministic distribution of the random states of the nonlinear Markov chain, so that the statistical interaction between particles vanishes. In other words, starting with a chaotic configuration based on independent copies of initial state of the nonlinear Markov chain model, the chaos propagates at any time horizon as the size the system tends to infinity; that is, finite blocks of particles reduces to independent copies of the nonlinear Markov process. This result is called the propagation of chaos property.<ref name=\"mck67\"/><ref name=\"mr87\"/><ref name=\"as91\"/> The terminology \"propagation of chaos\" originated with  the work of Mark Kac in 1976 on a colliding mean field kinetic gas model<ref>{{cite book|last1=Kac|first1=Mark|title=Probability and Related Topics in Physical Sciences|date=1976|publisher=Topics in Physical Sciences. American Mathematical Society, Providence, Rhode Island}}</ref>\n\n==History==\nThe theory of mean field interacting particle models had certainly started by the mid-1960s, with the work of  [[Henry McKean|Henry P. McKean Jr.]] on Markov interpretations of a class of nonlinear parabolic partial differential equations arising in  fluid mechanics.<ref name=\"mck67\">{{cite journal|last1=McKean|first1=Henry, P.|title=Propagation of chaos for a class of non-linear parabolic equations|journal=Lecture Series in Differential Equations, Catholic Univ.|date=1967|volume=7|pages=41–57}}</ref><ref>{{cite journal|last1=McKean|first1=Henry, P.|title=A class of Markov processes associated with nonlinear parabolic equations|journal=Proc. Natl. Acad. Sci. USA|date=1966|volume=56|issue=6|pages=1907–1911|doi=10.1073/pnas.56.6.1907|pmid=16591437|pmc=220210|bibcode = 1966PNAS...56.1907M }}</ref> The mathematical foundations of these classes of models were developed from the mid-1980s to the mid-1990s  by several mathematicians, including Werner Braun, Klaus Hepp,<ref>{{cite journal|last1=Braun|first1=Werner|last2=Hepp|first2=Klaus|title=The Vlasov dynamics and its fluctuations in the 1 limit of interacting classical particles.|journal=Communications in Mathematical Physics|date=1977|volume=56|issue=2|pages=101–113|doi=10.1007/bf01611497|bibcode = 1977CMaPh..56..101B }}</ref> Karl Oelschläger,<ref name=\"o84\">{{cite journal |title=A martingale approach to the law of large numbers for weakly interacting stochastic processes|first=Karl |last=Oelschläger|journal=Ann. Probab.|year=1984 |volume=12 |issue=2 |pages=458–479 |doi=10.1214/aop/1176993301}}</ref><ref name=\"o89\">{{cite journal |title=On the derivation of reaction-diffusion equations as limit of dynamics of systems of moderately interacting stochastic processes|first=Karl |last=Oelschläger|journal=Prob. Th. Rel. Fields |year=1989 |volume=82 |pages=565–586}}</ref><ref name=\"o90\">{{cite journal |title=Large systems of interacting particles and porous medium equation|first=Karl |last=Oelschläger|journal=J. Differential Equations |year=1990 |volume=88 |issue=2 |pages=294–346 |doi=10.1016/0022-0396(90)90101-t|bibcode = 1990JDE....88..294O }}</ref> Gérard Ben Arous and Marc Brunaud,<ref>{{cite journal|last1=Ben Arous|first1=Gérard|last2=Brunaud|first2=Marc|title=Méthode de Laplace: Etude variationnelle des fluctuations de diffusions de type \"champ moyen\"|journal=Stochastics 31, 79–144, (1990)|date=1990|volume=31|pages=79–144|doi=10.1080/03610919008833649}}</ref> Donald Dawson, Jean Vaillancourt<ref>{{cite journal|last1=Dawson|first1=Donald|last2=Vaillancourt|first2=Jean|title=Nonlinear Differential Equations and Applications|journal=Nonlinear Differential Equations and Applications|date=1995|volume=2|issue=2|pages=199–229|doi=10.1007/bf01295311}}</ref> and Jürgen Gärtner,<ref>{{cite journal| last1=Dawson |first1=Donald|last2=Gartner|first2=Jurgen|title=Large deviations from the McKean-Vlasov limit for weakly interacting diffusions|journal=Stochastics|date=1987|volume=20|issue=4|pages=247–308|doi=10.1080/17442508708833446}}</ref><ref>{{cite journal|last1=Gartner|first1=Jurgen|title=J. GÄRTNER, On the McKean-Vlasov limit for interacting diffusions|journal=Math. Nachr.|date=1988|volume=137|pages=197–248|doi=10.1002/mana.19881370116}}</ref> Christian Léonard,<ref>{{cite journal|last1=Léonard|first1=Christian|title=Une loi des grands nombres pour des systèmes de diffusions avec interaction et à coefficients non bornés|journal=Ann. I.H.P.|date=1986|volume=22|pages=237–262}}</ref> [[Sylvie Méléard]], Sylvie Roelly,<ref name=\"mr87\">{{cite journal|last1=Méléard|first1=Sylvie|author1-link=Sylvie Méléard|last2=Roelly|first2=Sylvie|title=A propagation of chaos result for a system of particles with moderate interaction|journal=Stoch. Proc. And Appl.|date=1987|url=http://ac.els-cdn.com/0304414987901840/1-s2.0-0304414987901840-main.pdf?_tid=96542162-33af-11e4-b3b6-00000aab0f6b&acdnat=1409779176_83da63437a171aac657c89ba2fb9e5cb|volume=26|pages=317–332|doi=10.1016/0304-4149(87)90184-0}}</ref> [[Alain-Sol Sznitman]]<ref name=\"as91\">{{cite book|last1=Sznitman|first1=Alain-Sol|author1-link=Alain-Sol Sznitman|title=Topics in propagation of chaos|date=1991|publisher=Springer, Berlin|pages=164–251|quote=Saint-Flour Probability Summer School, 1989}}</ref><ref>{{cite journal|last1=Sznitman|first1=Alain-Sol|title=Nonlinear reflecting diffusion process, and the propagation of chaos and fluctuations associated|journal=J. Funct. Anal.|date=1984|volume=36|pages=311–336}}</ref> and Hiroshi Tanaka<ref>{{cite journal|last1=Tanaka|first1=Hiroshi|title=Tanaka, H.: Limit theorems for certain diffusion processes with interaction|journal=Proceedings of the Taniguchi International Symposium on Stochastic Analysis|date=1984|pages=469–488}}</ref> for diffusion type models;  F. Alberto Grünbaum,<ref>{{cite journal|last1=Grunbaum.|first1=F. Alberto|title=Propagation of chaos for the Boltzmann equation|journal=Archive for Rational Mechanics and Analysis|date=1971|volume=42|issue=5|pages=323–345|bibcode = 1971ArRMA..42..323G |doi = 10.1007/BF00250440 }}</ref> Tokuzo Shiga, Hiroshi Tanaka,<ref>{{cite journal|last1=Shiga|first1=Tokuzo|last2=Tanaka|first2=Hiroshi|title=Central limit theorem for a system of Markovian particles with mean field interactions|journal=Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete|date=1985|volume=69|issue=3}}</ref>  \nSylvie Méléard and Carl Graham<ref name=\"gm92\">{{cite journal|last1=Graham|first1=Carl|title=Non linear diffusions with jumps|journal=Ann. I.H.P.|volume=28|issue=3|pages=393–402|year=1992}}</ref><ref name=\"m96\">{{cite book |title=Asymptotic behaviour of some interacting particle systems; McKean-Vlasov and Boltzmann models|first=Sylvie |last=Méléard|authorlink=Sylvie Méléard|journal=Lecture Notes in Mathematics, Springer |year=1996 |volume=1627 |pages=42–95 |doi=10.1007/bfb0093177|series=Lecture Notes in Mathematics |isbn=978-3-540-61397-8 }}</ref><ref name=\"gm97\">{{cite journal|last1=Graham|first1=Carl|last2=Méléard|first2=Sylvie|author2-link=Sylvie Méléard|title=Stochastic particle approximations for generalized Boltzmann models and convergence estimates.|journal=Annals of Probability|date=1997|volume=25|issue=1|pages=115–132|doi=10.1214/aop/1024404281|url=http://projecteuclid.org/euclid.aop/1024404281}}</ref> for general classes of interacting jump-diffusion processes.\n\nWe also quote an earlier pioneering article by [[Ted Harris (mathematician)|Theodore E. Harris]] and Herman Kahn, published in 1951, using mean field but heuristic-like genetic methods for estimating particle transmission energies.<ref>{{cite journal|last1=Herman|first1=Kahn|last2=Harris|first2=Theodore, E.|title=Estimation of particle transmission by random sampling| journal=Natl. Bur. Stand. Appl. Math. Ser.|date=1951|volume=12|pages=27–30| url=https://dornsifecms.usc.edu/assets/sites/520/docs/kahnharris.pdf}}</ref> Mean field genetic type particle methods are also used as heuristic natural search algorithms (a.k.a. [[metaheuristic]]) in evolutionary computing. The origins of these mean field computational techniques can be traced to 1950 and 1954 with the work of [[Alan Turing]] on genetic type mutation-selection learning machines<ref>{{cite journal|last1=Turing|first1=Alan M.|title=Computing machinery and intelligence|journal=Mind|volume=LIX|issue=238|pages=433–460|doi=10.1093/mind/LIX.236.433|url=http://mind.oxfordjournals.org/content/LIX/236/433|date=October 1950}}</ref>\nand the articles by [[Nils Aall Barricelli]] at the [[Institute for Advanced Study]] in [[Princeton, New Jersey]].<ref>{{cite journal|last=Barricelli|first=Nils Aall|year=1954|authorlink=Nils Aall Barricelli|title=Esempi numerici di processi di evoluzione|journal=Methodos|pages=45–68}}</ref><ref>{{cite journal|last=Barricelli|first=Nils Aall|year=1957|authorlink=Nils Aall Barricelli|title=Symbiogenetic evolution processes realized by artificial methods|journal=Methodos|pages=143–182}}</ref> The Australian geneticist [[Alex Fraser (scientist)|Alex Fraser]] also published in 1957 a series of papers on the genetic type simulation of [[artificial selection]] of organisms.<ref>{{cite journal|last=Fraser|first=Alex|authorlink=Alex Fraser (scientist)|year=1957|title=Simulation of genetic systems by automatic digital computers. I. Introduction|journal=Aust. J. Biol. Sci.|volume=10|pages=484–491}}</ref>\n\n[[Quantum Monte Carlo]], and more specifically [[Diffusion Monte Carlo|Diffusion Monte Carlo methods]] can also be interpreted as a mean field particle approximation of Feynman-Kac path integrals.<ref name=\"dp04\"/><ref name=\"dmm00\"/><ref name=\"dmm00m\"/><ref name=\"dm-esaim03\">{{cite journal|last1=Del Moral|first1=Pierre|title=Particle approximations of Lyapunov exponents connected to Schrödinger operators and Feynman-Kac semigroups|journal=ESAIM Probability & Statistics|date=2003|volume=7|pages=171–208|url=http://journals.cambridge.org/download.php?file=%2FPSS%2FPSS7%2FS1292810003000016a.pdf&code=a0dbaa7ffca871126dc05fe2f918880a|doi=10.1051/ps:2003001}}</ref><ref name=\"caffarel1\">{{cite journal|last1=Assaraf|first1=Roland|last2=Caffarel|first2=Michel|last3=Khelif|first3=Anatole|title=Diffusion Monte Carlo Methods with a fixed number of walkers|journal=Phys. Rev. E|url=http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|date=2000|volume=61|issue=4|pages=4566–4575|doi=10.1103/physreve.61.4566|bibcode=2000PhRvE..61.4566A|deadurl=yes|archiveurl=https://web.archive.org/web/20141107015724/http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|archivedate=2014-11-07|df=}}</ref><ref name=\"caffarel2\">{{cite journal|last1=Caffarel|first1=Michel|last2=Ceperley|first2=David|last3=Kalos|first3=Malvin|title=Comment on Feynman-Kac Path-Integral Calculation of the Ground-State Energies of Atoms|journal=Phys. Rev. Lett.|date=1993|volume=71|issue=13|doi=10.1103/physrevlett.71.2159 |bibcode = 1993PhRvL..71.2159C|pages=2159|pmid=10054598}}</ref><ref name=\"h84\">{{cite journal|last1=Hetherington|first1=Jack, H.|title=Observations on the statistical iteration of matrices|journal=Phys. Rev. A| date=1984|volume=30|issue=2713|doi=10.1103/PhysRevA.30.2713|pages=2713–2719|bibcode = 1984PhRvA..30.2713H }}</ref> The origins of Quantum Monte Carlo methods are often attributed to Enrico Fermi and Robert Richtmyer who developed in 1948 a mean field particle interpretation of neutron-chain reactions,<ref>{{cite journal|last1=Fermi|first1=Enrique|last2=Richtmyer|first2=Robert, D.|title=Note on census-taking in Monte Carlo calculations|journal=LAM|date=1948|volume=805|issue=A|url=http://scienze-como.uninsubria.it/bressanini/montecarlo-history/fermi-1948.pdf|quote=Declassified report Los Alamos Archive}}</ref> but the first heuristic-like and genetic type particle algorithm (a.k.a. Resampled or Reconfiguration Monte Carlo methods) for estimating ground state energies of quantum systems (in reduced matrix models) is due to Jack H. Hetherington in 1984<ref name=\"h84\"/>\nIn molecular chemistry, the use of genetic heuristic-like particle methods (a.k.a. pruning and enrichment strategies) can be traced back to 1955 with the seminal work of Marshall. N. Rosenbluth and Arianna. W. Rosenbluth.<ref>{{cite journal|last1=Rosenbluth|first1=Marshall, N.|last2=Rosenbluth|first2=Arianna, W.|title=Monte-Carlo calculations of the average extension of macromolecular chains|journal=J. Chem. Phys.|date=1955|volume=23|issue=2|pages=356–359|bibcode = 1955JChPh..23..356R |doi = 10.1063/1.1741967 }}</ref>\n\nThe first pioneering articles on the applications of these heuristic-like particle methods in nonlinear filtering problems were the independent studies of Neil Gordon, David Salmon and Adrian Smith (bootstrap filter),<ref>{{cite journal\n | last = Gordon | first = N. J.\n | last2 = Salmond | first2 = D. J. | last3 = Smith | first3 = A. F. M.\n | year = 1993\n | title = Novel approach to nonlinear/non-Gaussian Bayesian state estimation\n | journal = IEE Proceedings F on Radar and Signal Processing\n | volume = 140\n | issue = 2\n | pages = 107–113\n | url = http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=210672 \n | accessdate = 2009-09-19\n | doi = 10.1049/ip-f-2.1993.0015\n}}\n</ref> Genshiro Kitagawa (Monte Carlo filter)\n,<ref>{{cite journal\n | last = Kitagawa | first = G.\n | year = 1996\n | title =Monte carlo filter and smoother for non-Gaussian nonlinear state space models\n | volume = 5\n | issue = 1\n | journal = Journal of Computational and Graphical Statistics\n | pages = 1–25\n | doi = 10.2307/1390750\n | jstor = 1390750\n}}\n</ref> and the one by Himilcon Carvalho, Pierre Del Moral, André Monin and Gérard Salut<ref>{{cite journal|last1=Carvalho|first1=Himilcon|last2=Del Moral| first2=Pierre|last3=Monin|first3=André|last4=Salut|first4=Gérard|title=Optimal Non-linear Filtering in GPS/INS Integration.|journal=IEEE Transactions on Aerospace and Electronic Systems|date=July 1997|volume=33|issue=3|url=http://homepages.laas.fr/monin/Version_anglaise/Publications_files/GPS.pdf}}</ref> published in the 1990s. The term interacting \"particle filters\" was first coined in 1996 by Del Moral.<ref name=\"dm962\">{{cite journal|last1 = Del Moral|first1 = Pierre|title = Non Linear Filtering: Interacting Particle Solution.|journal = Markov Processes and Related Fields|date = 1996|volume = 2|issue = 4|pages = 555–580|url = http://web.maths.unsw.edu.au/~peterdel-moral/mprfs.pdf}}</ref>  Particle filters were also developed in signal processing in the early 1989-1992 by P. Del Moral, J.C. Noyer, G. Rigal, and G. Salut in the LAAS-CNRS  in a series of restricted and classified research reports with STCAN (Service Technique des Constructions et Armes Navales), the IT company DIGILOG, and the [https://www.laas.fr/public/en LAAS-CNRS] (the Laboratory for Analysis and Architecture of Systems) on RADAR/SONAR and GPS signal processing problems.<ref>P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : An unified framework for particle solutions <br>\nLAAS-CNRS, Toulouse, Research Report no. 91137, DRET-DIGILOG- LAAS/CNRS contract, April (1991).</ref><ref>P. Del Moral, G. Rigal, and G. Salut. Nonlinear and non Gaussian particle filters applied to inertial platform repositioning.<br>\nLAAS-CNRS, Toulouse, Research Report no. 92207, STCAN/DIGILOG-LAAS/CNRS Convention STCAN no. A.91.77.013, (94p.) September (1991).</ref><ref>P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Experimental results.<br>\nConvention DRET no. 89.34.553.00.470.75.01, Research report no.2 (54p.), January (1992).</ref><ref>P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Theoretical results <br>\nConvention DRET no. 89.34.553.00.470.75.01, Research report no.3 (123p.), October (1992).</ref><ref>P. Del Moral, J.-Ch. Noyer, G. Rigal, and G. Salut. Particle filters in radar signal processing : detection, estimation and air targets recognition.<br>\nLAAS-CNRS, Toulouse, Research report no. 92495, December (1992).</ref><ref>P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. <br>\nStudies on: Filtering, optimal control, and maximum likelihood estimation. Convention DRET no. 89.34.553.00.470.75.01. Research report no.4 (210p.), January (1993).</ref>\n\nThe foundations and the first rigorous analysis on the convergence of genetic type models and mean field Feynman-Kac particle methods are due to Pierre Del Moral<ref name=\"dm96\"/><ref>{{cite journal|last1=Del Moral|first1=Pierre|title=Measure Valued Processes and Interacting Particle Systems. Application to Non Linear Filtering Problems|journal=Annals of Applied Probability|date=1998|edition=Publications du Laboratoire de Statistique et Probabilités, 96-15 (1996)|volume=8|issue=2|pages=438–495| url=http://projecteuclid.org/download/pdf_1/euclid.aoap/1028903535|doi=10.1214/aoap/1028903535}}</ref> in 1996. Branching type particle methods with varying population sizes were also developed in the end of the 1990s by Dan Crisan, Jessica Gaines and Terry Lyons,<ref>{{cite journal| last1=Crisan|first1=Dan|last2=Gaines |first2=Jessica|last3=Lyons|first3=Terry|title=Convergence of a branching particle method to the solution of the Zakai|journal=SIAM Journal on Applied Mathematics|date=1998|volume=58|issue=5|pages=1568–1590|doi=10.1137/s0036139996307371}}</ref><ref>{{cite journal| last1=Crisan| first1=Dan| last2=Lyons|first2=Terry|title=Nonlinear filtering and measure-valued processes|journal=Probability Theory and Related Fields| date=1997 |volume=109 |issue=2| pages=217–244|doi=10.1007/s004400050131}}</ref><ref>{{cite journal|last1=Crisan|first1=Dan|last2=Lyons|first2=Terry|title=A particle approximation of the solution of the Kushner–Stratonovitch equation|journal=Probability Theory and Related Fields|date=1999|volume=115|issue=4|pages=549–578|doi=10.1007/s004400050249}}</ref> and by Dan Crisan,  Pierre Del Moral and Terry Lyons.<ref>{{cite journal|last1=Crisan|first1=Dan|last2=Del Moral|first2=Pierre|last3=Lyons|first3=Terry|title=Discrete filtering using branching and interacting particle systems|journal=Markov Processes and Related Fields|date=1999|volume=5|issue=3|pages=293–318|url=http://web.maths.unsw.edu.au/~peterdel-moral/crisan98discrete.pdf}}</ref> The first uniform convergence results with respect to the time parameter for mean field particle models were developed in the end of the 1990s by Pierre Del Moral and Alice Guionnet<ref name=\"dg01\">{{cite journal|last1=Del Moral|first1=Pierre|last2=Guionnet|first2=Alice|title=On the stability of interacting processes with applications to filtering and genetic algorithms|journal=Annales de l'Institut Henri Poincaré|date=2001|volume=37|issue=2|pages=155–194|url=http://web.maths.unsw.edu.au/~peterdel-moral/ihp.ps|doi=10.1016/s0246-0203(00)01064-5|bibcode = 2001AnIHP..37..155D }}</ref><ref name=\"dg99\">{{cite journal|last1=Del Moral|first1=Pierre|last2=Guionnet|first2=Alice|title=On the stability of Measure Valued Processes with Applications to filtering|journal=C. R. Acad. Sci. Paris|date=1999|volume=39|issue=1|pages=429–434}}</ref> for interacting jump type processes, and by Florent Malrieu for nonlinear diffusion type processes.<ref>{{cite journal|last1=Malrieu|first1=Florent|title=Logarithmic Sobolev inequalities for some nonlinear PDE's|journal=Stochastic Process. Appl|date=2001|volume=95|issue=1|pages=109–132|doi=10.1016/s0304-4149(01)00095-3}}</ref>\n\nNew classes of mean field particle simulation techniques for Feynman-Kac path-integration problems includes genealogical tree based models,<ref name=\"dp13\"/><ref name=\"dp04\"/><ref>{{cite journal|last1=Del Moral|first1=Pierre|last2=Miclo|first2=Laurent|title=Genealogies and Increasing Propagations of Chaos for Feynman-Kac and Genetic Models|journal=Annals of Applied Probability|date=2001|volume=11|issue=4|pages=1166–1198|url=http://web.maths.unsw.edu.au/~peterdel-moral/spc.ps}}</ref> backward particle models,<ref name=\"dp13\"/><ref>{{cite journal|last1=Del Moral|first1=Pierre|last2=Doucet|first2=Arnaud|last3=Singh|first3=Sumeetpal, S.|title=A Backward Particle Interpretation of Feynman-Kac Formulae |journal=M2AN|date=2010|volume=44|issue=5|pages=947–976|url=http://hal.inria.fr/docs/00/42/13/56/PDF/RR-7019.pdf|doi=10.1051/m2an/2010048|arxiv=0908.2556}}</ref> adaptive mean field particle models,<ref>{{cite journal|last1=Del Moral|first1=Pierre|last2=Doucet|first2=Arnaud|last3=Jasra|first3=Ajay|title=On Adaptive Resampling Procedures for Sequential Monte Carlo Methods|journal=Bernoulli|date=2012|volume=18|issue=1|pages=252–278|url=http://hal.inria.fr/docs/00/33/25/83/PDF/RR-6700.pdf|doi=10.3150/10-bej335|arxiv=1203.0464}}</ref> island type particle models,<ref>{{cite journal|last1=Vergé|first1=Christelle|last2=Dubarry|first2=Cyrille|last3=Del Moral|first3=Pierre|last4=Moulines|first4=Eric|title=On parallel implementation of Sequential Monte Carlo methods: the island particle model|journal=Statistics and Computing|date=2013|doi=10.1007/s11222-013-9429-x|volume=25|issue=2|pages=243–260|arxiv=1306.3911}}</ref><ref>{{cite arXiv|last1=Chopin|first1=Nicolas|last2=Jacob|first2=Pierre, E.|last3=Papaspiliopoulos|first3=Omiros|title=SMC^2: an efficient algorithm for sequential analysis of state-space models|eprint=1101.1528v3|class=stat.CO|year=2011}}</ref> and particle Markov chain Monte Carlo methods<ref>{{cite journal| last1=Andrieu| first1=Christophe|last2=Doucet|first2=Arnaud|last3=Holenstein|first3=Roman|title=Particle Markov chain Monte Carlo methods|journal=Journal of the Royal Statistical Society, Series B| date=2010|volume=72|issue=3|pages=269–342|doi=10.1111/j.1467-9868.2009.00736.x}}</ref><ref>{{cite arXiv|last1=Del Moral| first1=Pierre |last2=Patras |first2=Frédéric| last3=Kohn|first3=Robert|title=On Feynman-Kac and particle Markov chain Monte Carlo models|eprint=1404.5733|date=2014| class=math.PR }}</ref>\n\n==Applications==\n\nIn [[physics]], and more particularly in [[statistical mechanics]], these nonlinear evolution equations are often used to describe the statistical behavior of microscopic interacting  particles in a fluid or in some condensed matter. In this context, the random evolution of a virtual fluid or a gas particle is represented by [[McKean–Vlasov process|McKean-Vlasov diffusion processes]], [[reaction–diffusion system]]s, or [[Boltzmann equation|Boltzmann type collision processes]].<ref name=\"o84\"/><ref name=\"o89\"/><ref name=\"o90\"/><ref name=\"gm97\"/><ref>{{cite journal|last1=Cercignani|first1=Carlo|last2=Illner|first2= Reinhard|last3=Pulvirenti|first3= Mario|title=The Mathematical Theory of Dilute Gases.|journal=Springer|date=1994}}</ref> As its name indicates, the mean field particle model represents the collective behavior of microscopic particles weakly interacting with their occupation measures. The macroscopic behavior of these many-body particle systems is encapsulated in the limiting model obtained when the size of the population tends to infinity. Boltzmann equations represent the macroscopic evolution of colliding particles in rarefied gases, while McKean Vlasov diffusions represent the macroscopic behavior of fluid particles and granular gases.\n\nIn [[computational physics]] and more specifically in [[quantum mechanics]], the ground state energies of quantum systems is associated with the top of the spectrum of Schrödinger's operators. The [[Schrödinger equation]] is the quantum mechanics version of the Newton's second law of motion of classical mechanics (the mass times the acceleration is the sum of the forces). This equation represents the wave function (a.k.a. the quantum state) evolution of some physical system, including molecular, atomic of subatomic systems, as well as macroscopic systems like the universe.<ref>{{cite journal|last1=Schrodinger|first1=Erwin|title=An Undulatory Theory of the Mechanics of Atoms and Molecules|journal=Physical Review| date=1926| volume=28|issue=6|pages=1049–1070|doi=10.1103/physrev.28.1049|bibcode = 1926PhRv...28.1049S }}</ref> The solution of the imaginary time Schrödinger equation (a.k.a. the heat equation) is given by a Feynman-Kac distribution associated with a free evolution  Markov process (often represented by Brownian motions) in the set of electronic or macromolecular configurations and some potential energy function. The long time behavior of these nonlinear semigroups is related to top eigenvalues and ground state energies of  Schrödinger's operators.<ref name=\"dp04\"/><ref name=\"dm-esaim03\"/><ref name=\"caffarel1\"/><ref name=\"caffarel2\"/><ref name=\"h84\"/><ref name=\"dd-soft04\"/>  The genetic type mean field interpretation of these Feynman-Kac models are termed Resample Monte Carlo, or Diffusion Monte Carlo methods. These branching type evolutionary algorithms are based on mutation and selection transitions. During the mutation transition, the walkers evolve randomly and independently in a potential energy landscape on particle configurations.  The mean field selection process (a.k.a. quantum teleportation, population reconfiguration, resampled transition) is associated with a fitness function that  reflects the particle absorption in an energy well. Configurations with low relative energy are more likely to duplicate. In molecular chemistry, and statistical physics Mean field particle methods are also used to sample [[Boltzmann distribution|Boltzmann-Gibbs measures]] associated with some cooling schedule, and to compute their normalizing constants (a.k.a. free energies, or partition functions).<ref name=\"dp13\"/><ref name=\"ddj06\"/><ref>{{cite journal| last1=Lelièvre|first1=Tony|last2=Rousset|first2=Mathias|last3=Stoltz|first3=Gabriel|title=Computation of free energy differences through nonequilibrium stochastic dynamics: the reaction coordinate case. |journal=J. Comput. Phys.|date=2007|volume=222|issue=2|pages=624–643|doi=10.1016/j.jcp.2006.08.003|arxiv = cond-mat/0603426 |bibcode = 2007JCoPh.222..624L }}</ref><ref>{{cite journal|last1=Lelièvre|first1=Tony|last2=Rousset|first2=Mathias|last3=Stoltz|first3=Gabriel|title=Free energy computations: A mathematical perspective|journal=Imperial College Press|date=2010|pages=472}}</ref>\n\nIn [[computational biology]], and more specifically in [[population genetics]], spatial [[branching process]]es  with competitive selection and migration mechanisms can also represented by mean field genetic type [[Population dynamics|population dynamics models]].<ref name=\"dmm00\">{{cite book|last1=Del Moral|first1=Pierre|last2=Miclo|first2=Laurent|title=Branching and Interacting Particle Systems Approximations of Feynman-Kac Formulae with Applications to Non-Linear Filtering. |journal=Lecture Notes in Mathematics|date=2000|volume=1729|pages=1–145|url=http://archive.numdam.org/ARCHIVE/SPS/SPS_2000__34_/SPS_2000__34__1_0/SPS_2000__34__1_0.pdf|doi=10.1007/bfb0103798|isbn=978-3-540-67314-9}}</ref><ref name=\"CaronDel Moral2011\">{{cite journal|last1=Caron|first1=F.|last2=Del Moral|first2=P.|last3=Pace|first3=M.|last4=Vo|first4=B.-N.|title=On the Stability and the Approximation of Branching Distribution Flows, with Applications to Nonlinear Multiple Target Filtering|journal=Stochastic Analysis and Applications|volume=29|issue=6|year=2011|pages=951–997|issn=0736-2994|doi=10.1080/07362994.2011.598797|arxiv=1009.1845}}</ref>\nThe first moments of the occupation measures of a spatial branching process are given by Feynman-Kac distribution flows.<ref>{{cite book|last1=Dynkin|first1=Eugène, B.|title=An Introduction to Branching Measure-Valued Processes|date=1994|publisher=CRM Monograph Series|isbn=978-0-8218-0269-4|pages=134}}</ref><ref>{{cite journal|last1=Zoia|first1=Andrea|last2=Dumonteil|first2=Eric|last3=Mazzolo|first3=Alain|title=Discrete Feynman-Kac formulas for branching random walks|journal=EPL|volume=98|issue=40012|pages=40012|doi=10.1209/0295-5075/98/40012|url=http://iopscience.iop.org/0295-5075/98/4/40012/pdf/0295-5075_98_4_40012.pdf|arxiv = 1202.2811 |bibcode = 2012EL.....9840012Z |year=2012}}</ref> The mean field genetic type approximation of these flows offers a fixed population size interpretation of these branching processes.<ref name=\"dp13\"/><ref name=\"dp04\"/><ref name=\"cddm11\"/>   Extinction probabilities can be interpreted as absorption probabilities of some Markov process evolving in some absorbing environment. These absorption models are represented by Feynman-Kac models.<ref>{{cite journal|last1=Pitman|first1=Jim|last2=Fitzsimmons|first2=Patrick, J.|title=Kac's moment formula and the Feynman–Kac formula for additive functionals of a Markov process|journal=Stochastic Processes and Their Applications|date=1999|volume=79|issue=1|pages=117–134|doi=10.1016/S0304-4149(98)00081-7|url=http://math.ucsd.edu/~pfitz/downloads/kac/kac.html}}</ref><ref>{{cite journal|last1=Arendt|first1=Wolfgang|last2=Batty|first2=Charles, J.K.|title=Absorption semigroups and Dirichlet boundary conditions|journal=Math. Ann.|date=1993|volume=295|pages=427–448|url=https://www.uni-ulm.de/fileadmin/website_uni_ulm/mawi.inst.020/arendt/downloads/pubbib/short/1993-AreBat-AbsSmgDrcBndCnd.pdf|doi=10.1007/bf01444895}}</ref><ref>{{cite journal| last1=Lant|first1=Timothy|last2=Thieme|first2=Horst|title=Perturbation of Transition Functions and a Feynman-Kac Formula for the Incorporation of Mortality| journal=Positivity|date=2007|volume=11|issue=2|pages=299–318|doi=10.1007/s11117-006-2044-8}}</ref><ref>{{cite journal|last1=Takeda|first1=Masayoshi|title=Some Topics connected with Gaugeability for Feynman-Kac Functionals|journal=RIMS Kokyuroku Bessatsu|date=2008|volume=B6|pages=221–236|url=http://www.kurims.kyoto-u.ac.jp/~kenkyubu/bessatsu/open/B6/pdf/B6-18.pdf}}</ref> The long time behavior of these processes conditioned on non-extinction can be expressed in an equivalent way by [[quasi-invariant measure]]s,  [[Yaglom]] limits,<ref>{{cite journal|last1=Yaglom|first1=Isaak|title=Certain limit theorems of the theory of branching processes|journal=Dokl. Akad. Nauk SSSR|date=1947|volume=56|pages=795–798}}</ref> or invariant measures of nonlinear normalized Feynman-Kac flows.<ref name=\"dp13\"/><ref name=\"dp04\"/><ref name=\"dg01\"/><ref name=\"dg99\"/><ref name=\"dd-soft04\">{{cite journal|last1=Del Moral|first1=Pierre|last2=Doucet|first2=Arnaud|title=Particle Motions in Absorbing Medium with Hard and Soft Obstacles|journal=Stochastic Analysis and Applications|date=2004|volume=22|issue=5|pages=1175–1207|doi=10.1081/SAP-200026444|url=http://web.maths.unsw.edu.au/~peterdel-moral/obstacle.ps}}</ref><ref>{{cite journal|last1=Del Moral|first1=Pierre|last2=Miclo|first2=Laurent|title=On the Stability of Non Linear Semigroup of Feynman-Kac Type|journal=Annales de la Faculté des Sciences de Toulouse|date=2002|volume=11|issue=2|pages=135–175| url=http://archive.numdam.org/ARCHIVE/AFST/AFST_2002_6_11_2/AFST_2002_6_11_2_135_0/AFST_2002_6_11_2_135_0.pdf|doi=10.5802/afst.1021}}</ref>\n\nIn [[computer science]]s, and more particularly in [[artificial intelligence]] these mean field type [[genetic algorithm]]s are used as random search heuristics that mimic the process of evolution to generate useful solutions to complex optimization problems.<ref>{{cite book|last1=Kallel|first1=Leila|last2=Naudts|first2=Bart|last3=Rogers|first3=Alex|title=Theoretical Aspects of Evolutionary Computing|publisher=Springer, Berlin, New York; Natural computing series.|isbn=978-3540673965|pages=497|date=2001-05-08}}</ref><ref>{{cite journal|last1=Del Moral| first1=Pierre|last2=Kallel|first2=Leila|last3=Rowe|first3=John|title=Modeling genetic algorithms with interacting particle systems|journal=Revista de Matematica: Teoria y Aplicaciones|date=2001|volume=8|issue=2|pages=19–77|citeseerx = 10.1.1.87.7330|doi=10.15517/rmta.v8i2.201}}</ref><ref>{{cite journal|last1=Del Moral|first1=Pierre|last2=Guionnet|first2=Alice|title=On the stability of interacting processes with applications to filtering and genetic algorithms|journal=Annales de l'Institut Henri Poincaré|date=2001|volume=37|issue=2|pages=155–194|doi=10.1016/S0246-0203(00)01064-5|url=http://www.sciencedirect.com/science/article/pii/S0246020300010645|bibcode = 2001AnIHP..37..155D }}</ref> These stochastic search algorithms belongs to the class of [[Evolutionary algorithm|Evolutionary models]]. The idea is to propagate a population of feasible candidate solutions using mutation and selection mechanisms. The mean field interaction between the individuals is encapsulated in the selection and the cross-over mechanisms.\n\nIn [[Mean field game theory|mean field games]] and [[Multi-agent system|multi-agent interacting systems]] theories, mean field particle processes are used to represent the collective behavior of complex systems with interacting individuals.<ref>{{cite journal|last=Aumann|first=Robert John|title=Markets with a continuum of traders| journal=Econometrica|date=1964|volume=32|issue=1–2|pages=39–50|doi=10.2307/1913732|jstor=1913732}}</ref><ref>{{cite journal|last1=Jovanovic|first1=Boyan|last2=Rosenthal|first2=Robert W.|title=Anonymous sequential games|journal= Journal of Mathematical Economics|date=1988|volume=17|issue=1|pages=77–87|doi=10.1016/0304-4068(88)90029-8}}</ref><ref>{{cite journal|last1=Huang|first1=Minyi.Y|last2=Malhame|first2=Roland P.|last3=Caines|first3= Peter E.|title=Large Population Stochastic Dynamic Games: Closed-Loop McKean–Vlasov Systems and the Nash Certainty Equivalence Principle|journal=Special Issue in Honor of the 65th Birthday of Tyrone Duncan, Communications in Information and Systems|date=2006|volume=6|pages=221–252}}</ref><ref>{{cite book|last=Maynard Smith|first=John|title=Evolution and the Theory of Games|publisher=Cambridge University Press, Cambridge|date=1982}}</ref><ref>{{cite arXiv|last1=Kolokoltsov|first1=Vassili|last2=Li|first2=Jiajie|last3=Yang|first3=Wei|title=Mean field games and nonlinear Markov processes|eprint=1112.3744v2|class=math.PR|year=2011}}</ref><ref>{{cite journal|last1=Lasry|first1=Jean Michel|last2=Lions|first2=Pierre Louis|title=Mean field games|journal=Japanese J. Math|date=2007|volume=2|issue=1|pages=229–260|doi=10.1007/s11537-007-0657-8}}</ref><ref>{{cite journal|first1=René|last1=Carmona|first2=Jean Pierre|last2=Fouque|first3= Li-Hsien|last3=Sun|title= Mean Field Games and Systemic Risk|journal=Communications in Mathematical Sciences|date=2014}}</ref><ref>{{cite journal|last1=Budhiraja|first1=Amarjit|last2=Del Moral|first2=Pierre|last3=Rubenthaler|first3=Sylvain|title=Discrete time Markovian agents interacting through a potential|journal=ESAIM Probability & Statistics|date=2013|volume=17|pages=614–634|doi=10.1051/ps/2012014}}</ref> In this context, the mean field interaction is encapsulated in the decision process of interacting agents. The limiting model as the number of agents tends to infinity is sometimes called the continuum model of agents<ref>{{cite journal|last1=Aumann|first1=Robert|title=Markets with a continuum of traders|journal=Econometrica|date=1964|volume=32|issue=1–2|pages=39–50|url=http://www.u.arizona.edu/~mwalker/501BReadings/Aumann1964.pdf|doi=10.2307/1913732|jstor=1913732}}</ref>\n\nIn [[information theory]], and more specifically in statistical [[machine learning]] and [[signal processing]], mean field particle methods are used to sample sequentially from the conditional distributions of some random process with respect to a sequence of observations or a cascade of [[Rare Event Sampling|rare events]].<ref name=\"dp13\"/><ref name=\"dp04\">{{cite book|last=Del Moral|first=Pierre|title=Feynman-Kac formulae. Genealogical and interacting particle approximations|year=2004 |publisher=Springer|quote=Series: Probability and Applications|url=https://www.springer.com/mathematics/probability/book/978-0-387-20268-6|pages=575|isbn=9780387202686|series=Probability and its Applications}}</ref><ref name=\"cddm11\"/><ref>{{cite book|last1=Del Moral|first1=Pierre|last2=Lézaud|first2=Pascal|title=Branching and interacting particle interpretation of rare event probabilities.|date=2006|publisher=Springer, Berlin|pages=277–323|edition=stochastic Hybrid Systems: Theory and Safety Critical Applications, eds. H. Blom and J. Lygeros.|url=http://web.maths.unsw.edu.au/~peterdel-moral/Del-Moral-Lezaud-rare-events.pdf}}</ref> In discrete time [[Nonlinear filter|nonlinear filtering problems]], the conditional distributions of the random states of a signal given partial and noisy observations satisfy a nonlinear updating-prediction evolution equation. The updating step is given by [[Bayes' rule]], and the prediction step is a [[Chapman–Kolmogorov equation|Chapman-Kolmogorov transport equation]]. The mean field particle interpretation of these nonlinear filtering equations is a genetic type selection-mutation particle algorithm<ref name=\"dm96\">{{cite journal|last1=Del Moral|first1=Pierre|title=Non Linear Filtering: Interacting Particle Solution.|journal=Markov Processes and Related Fields|date=1996|volume=2|issue=4|pages=555–580|url=http://web.maths.unsw.edu.au/~peterdel-moral/mprfs.pdf}}</ref>\nDuring the mutation step, the particles evolve independently of one another according to the Markov transitions of the signal . During the selection stage, particles with small relative likelihood values are killed, while the ones with high relative values are multiplied.<ref>{{cite journal|last1=Crisan|first1=Dan|last2=Del Moral|first2=Pierre|last3=Lyons|first3=Terry|title=Discrete Filtering Using Branching and Interacting Particle Systems.|journal=Markov Processes and Related Fields|date=1998|volume=5|issue=3|pages=293–318|url=http://web.maths.unsw.edu.au/~peterdel-moral/crisan98discrete.pdf}}</ref><ref name=\"cdl98s\">{{cite journal|last1=Crisan|first1=Dan|last2=Del Moral|first2=Pierre|last3=Lyons|first3=Terry|title=Interacting Particle Systems Approximations of the Kushner Stratonovitch Equation|journal=Advances in Applied Probability|date=1998|volume=31|issue=3|pages=819–838|url=http://web.maths.unsw.edu.au/~peterdel-moral/ks-approx.pdf|doi=10.1239/aap/1029955206}}</ref> These mean field particle techniques are also used to solve multiple-object tracking problems, and more specifically to estimate association measures<ref name=\"dp13\"/><ref name=\"cddm11\">{{cite journal|last1=Caron|first1=François|last2=Del Moral| first2=Pierre|last3=Doucet|first3=Arnaud|last4=Pace|first4=Michele|title=Particle approximations of a class of branching distribution flows arising in multi-target tracking|journal=SIAM J. Control Optim.|date=2011|pages=1766–1792|url=http://hal.archives-ouvertes.fr/docs/00/46/41/30/PDF/RR-7233.pdf}}</ref><ref name=\"cddm11\"/><ref>{{cite journal|last1=Pace|first1=Michele|last2=Del Moral|first2=Pierre|title=Mean-Field PHD Filters Based on Generalized Feynman-Kac Flow|journal=IEEE Journal of Selected Topics in Signal Processing|date=2013|volume=Special Issue on Multi-target tracking|issue=7–3|pages=484–495|doi=10.1109/JSTSP.2013.2250909|url=http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6472732|bibcode = 2013ISTSP...7..484P }}</ref>\n\nThe continuous time version of these particle models are mean field Moran type particle interpretations of the robust optimal filter evolution equations or the Kushner-Stratonotich stochastic partial differential equation.<ref name=\"dmm00\"/><ref name=\"dmm00m\">{{cite journal|last1=Del Moral|first1=Pierre|last2=Miclo|first2=Laurent|title=A Moran particle system approximation of Feynman-Kac formulae.|journal=Stochastic Processes and Their Applications|date=2000|volume=86|issue=2|pages=193–216|doi=10.1016/S0304-4149(99)00094-0|url=http://www.sciencedirect.com/science/article/pii/S0304414999000940}}</ref><ref name=\"cdl98s\"/> These genetic type mean field particle algorithms also termed [[particle filters|Particle Filters]] and [[Sequential Monte Carlo methods]] are extensively and routinely used in operation research and statistical inference\n.<ref>\n{{cite book\n | last1 = Cappe | first1 = O.\n | last2 = Moulines | first2 = E. | last3 = Ryden | first3 = T.\n | year = 2005\n | title = Inference in Hidden Markov Models\n | publisher = Springer\n | isbn = \n}}</ref><ref>\n {{cite book\n | last = Liu | first = J.\n | year = 2001\n | title = Monte Carlo strategies in Scientific Computing\n | publisher = Springer\n | isbn = \n}}</ref><ref>\n{{cite book\n | last1 = Doucet | first1 = A.\n | editor1-last = de Freitas | editor1-first = J. F. G. | editor2-first = J. | editor2-last = Gordon\n | year = 2001\n | title = Sequential Monte Carlo Methods in Practice\n | publisher = Springer\n | isbn = \n}}\n</ref>  The term \"particle filters\" was first coined in 1996 by Del Moral,<ref name=\"dm962\">{{cite journal|last1 = Del Moral|first1 = Pierre|title = Non Linear Filtering: Interacting Particle Solution.|journal = Markov Processes and Related Fields|date = 1996|volume = 2|issue = 4|pages = 555–580|url = http://web.maths.unsw.edu.au/~peterdel-moral/mprfs.pdf}}</ref> and the term \"sequential Monte Carlo\" by Liu and Chen in 1998. [[Subset simulation]] and Monte Carlo splitting<ref>{{cite journal|last1=Botev|first1=Z. I. |last2=Kroese|first2=D. P.|title=Efficient Monte Carlo simulation via the generalized splitting method|journal=Methodology and Computing in Applied Probability|date=2008|volume=10|issue=4|pages=471–505|doi=10.1007/s11009-008-9073-7|citeseerx=10.1.1.399.7912 }}</ref> techniques are particular instances of genetic particle schemes and Feynman-Kac particle models equipped with [[Markov chain Monte Carlo]] mutation transitions<ref name=\"ddj06\">{{cite journal|last1=Del Moral|first1=Pierre|last2=Doucet|first2=Arnaud|last3=Jasra|first3=Ajay|title=Sequential Monte Carlo samplers|journal=J. Royal Statist. Soc. B|date=2006|volume=68|issue=3|pages=411–436|url=http://web.maths.unsw.edu.au/~peterdel-moral/smc_samplers_try.pdf|doi=10.1111/j.1467-9868.2006.00553.x|arxiv=cond-mat/0212648}}</ref><ref>{{cite journal|last1=Botev|first1=Z. I. |last2=Kroese|first2=D. P.|title=Efficient Monte Carlo simulation via the generalized splitting method|journal=Statistics and Computing|date=2012|volume=22|issue=1|pages=1–16|doi=10.1007/s11222-010-9201-4}}</ref><ref>{{cite journal|last1=Cérou|first1=Frédéric|last2=Del Moral|first2=Pierre|last3=Furon|first3=Teddy|last4=Guyader|first4=Arnaud|title=Sequential Monte Carlo for Rare event estimation|journal=Statistics and Computing|date=2012|volume=22|issue=3|pages=795–808|doi=10.1007/s11222-011-9231-6|url=https://hal.inria.fr/inria-00584352/file/cdfg.pdf}}</ref>\n\n==Illustrations of the Mean field simulation method==\n\n===Countable state space models===\nTo motivate the mean field simulation algorithm we start with ''S'' a [[Finite set|finite]] or [[countable set|countable state]] space and let ''P''(''S'') denote the set of all probability measures on ''S''. Consider a sequence of [[probability distributions]] <math>(\\eta_0, \\eta_1, \\cdots)</math> on ''S'' satisfying an evolution equation:\n\n{{NumBlk|:| <math>\\eta_{n+1}=\\Phi(\\eta_n)</math>|{{EquationRef|1}}}}\n\nfor some, possibly nonlinear, mapping <math>\\Phi: P(S) \\to P(S).</math> These distributions are given by vectors\n\n:<math>\\eta_n=(\\eta_n(x))_{x\\in S},</math>\n\nthat satisfy:\n\n:<math>0 \\leqslant \\eta_n(x) \\leqslant 1,  \\qquad \\sum\\nolimits_{x\\in S}\\eta_n(x)=1.</math>\n\nTherefore, <math>\\Phi</math> is a mapping from the <math>(s-1)</math>-[[unit simplex]] into itself, where ''s'' stands for the [[cardinality]] of the set ''S''. When ''s'' is too large, solving equation ({{EquationNote|1}}) is [[Intractability (complexity)|intractable]] or computationally very costly. One natural way to approximate these evolution equations is to reduce sequentially the state space using a mean field particle model. One of the simplest mean field simulation scheme is defined by the Markov chain\n\n:<math>\\xi^{(N)}_n=\\left(\\xi^{(N,1)}_n, \\cdots, \\xi^{(N,N)}_n \\right)</math>\n\non the product space <math>S^N</math>, starting with ''N'' independent random variables with probability distribution <math>\\eta_0</math> and elementary transitions\n\n:<math>\\mathbf{P} \\left( \\left. \\xi^{(N,1)}_{n+1}=y^1,\\cdots,\\xi^{(N,N)}_{n+1}=y^N \\right |\\xi^{(N)}_n\\right)=\\prod_{i=1}^N \\Phi\\left(\\eta_n^N\\right)\\left(y^i\\right),</math>\n\nwith the [[empirical measure]]\n\n:<math>\\eta^N_n=\\frac{1}{N}\\sum_{j=1}^N1_{\\xi^{(N,j)}_n} </math>\n\nwhere <math>1_x</math> is the [[indicator function]] of the state ''x''.\n\nIn other words, given <math>\\xi^{(N)}_n</math> the samples <math>\\xi^{(N)}_{n+1}</math> are independent random variables with probability distribution <math> \\Phi\\left(\\eta_n^N\\right)</math>. The rationale behind this mean field simulation technique is the following: We expect that when <math>\\eta_{n}^N</math> is a good approximation of <math>\\eta_n</math>, then <math>\\Phi\\left(\\eta_n^N\\right)</math> is an approximation of <math>\\Phi\\left(\\eta_n\\right)=\\eta_{n+1}</math>. Thus, since <math>\\eta_{n+1}^N</math> is the empirical measure of ''N'' conditionally independent random variables with common probability distribution <math>\\Phi\\left(\\eta_n^N\\right)</math>, we expect <math>\\eta_{n+1}^N</math> to be a good approximation of <math>\\eta_{n+1}</math>.\n\nAnother strategy is to find a collection\n\n:<math>K_{\\eta_n}=\\left(K_{\\eta_n}(x,y)\\right)_{x,y\\in S}</math>\n\nof [[stochastic matrix|stochastic matrices]] indexed by <math>\\eta_n\\in P(S)</math> such that\n\n{{NumBlk|:| <math>\\sum_{x\\in S}\\eta_n(x)K_{\\eta_n}(x,y)=\\Phi(\\eta_n)(y)=\\eta_{n+1}(y)</math>|{{EquationRef|2}}}}\n\nThis formula allows us to interpret the sequence <math>(\\eta_0, \\eta_1, \\cdots)</math> as the probability distributions of the random states <math>\\left(\\overline{X}_0, \\overline{X}_1, \\cdots \\right)</math> of the nonlinear Markov chain model with elementary transitions\n\n:<math>\\mathbf{P} \\left ( \\left.\\overline{X}_{n+1}=y \\right|  \\overline{X}_n=x \\right )=K_{\\eta_n}(x,y), \\qquad \\text{Law}(\\overline{X}_n)=\\eta_n.</math>\n\nA collection of Markov transitions <math>K_{\\eta_n}</math> satisfying the equation  ({{EquationNote|1}})  is called a McKean interpretation of the sequence of measures <math>\\eta_n</math>.\nThe mean field particle interpretation of ({{EquationNote|2}})  is now defined by the Markov chain\n\n:<math>\\xi^{(N)}_n=\\left(\\xi^{(N,1)}_n, \\cdots, \\xi^{(N,N)}_n \\right)</math>\n\non the product space <math>S^N</math>, starting with ''N'' independent random copies of <math>X_0</math> and elementary transitions\n\n:<math>\\mathbf{P}\\left( \\left. \\xi^{(N,1)}_{n+1}=y^1,\\cdots,\\xi^{(N,N)}_{n+1}=y^N \\right |\\xi^{(N)}_n\\right)=\\prod_{i=1}^N K_{n+1,\\eta_n^N}\\left(\\xi^{(N,i)}_n,y^i\\right),</math>\n\nwith the empirical measure\n\n:<math>\\eta^N_n=\\frac{1}{N}\\sum_{j=1}^N1_{\\xi^{(N,j)}_n}</math>\n\nUnder some weak regularity conditions<ref name=\"dp13\"/> on the mapping <math>\\Phi</math> for any function <math>f: S\\to \\mathbf{R}</math>, we have the almost sure convergence\n\n:<math> \\frac{1}{N}\\sum_{j=1}^N f\\left(\\xi^{(N,j)}_n\\right)\\to_{N\\uparrow\\infty}E\\left(f(\\overline{X}_n)\\right)=\\sum_{x\\in S}\\eta_n(x)f(x)</math>\n\nThese nonlinear Markov processes and their mean field particle interpretation can be extended to time non homogeneous models on general [[measurable space|measurable]] state spaces.<ref name=\"dp13\"/>\n\n===Feynman-Kac models===\nTo illustrate the abstract models presented above, we consider a stochastic matrix <math>M=(M(x,y))_{x,y\\in S}</math> and some function <math>G : S \\to (0,1)</math>. We associate with these two objects the mapping\n\n:<math>\\begin{cases} \\Phi : P(S) \\to P(S) \\\\ (\\eta_n(x))_{x\\in S} \\mapsto \\left(\\Phi(\\eta_n)(y)\\right)_{y\\in S} \\end{cases} \\qquad \\Phi(\\eta_n)(y)=\\sum_{x\\in S} \\Psi_{G}(\\eta_n)(x)M(x,y)</math>\n\nand the Boltzmann-Gibbs measures  <math>\\Psi_{G}(\\eta_n)(x)</math> defined by\n\n:<math>\\Psi_{G}(\\eta_n)(x)=\\frac{\\eta_n(x)G(x)}{\\sum_{z\\in S}\\eta_n(z)G(z)}.</math>\n\nWe denote by <math>K_{\\eta_n}=\\left(K_{\\eta_n}(x,y)\\right)_{x,y\\in S}</math> the collection of stochastic matrices indexed by <math> \\eta_n\\in P(S)</math> given by\n\n:<math>K_{\\eta_n}(x,y)=\\epsilon G(x) M(x,y)+(1-\\epsilon G(x)) \\Phi(\\eta_n)(y)</math>\n\nfor some parameter <math>\\epsilon \\in [0,1]</math>. It is readily checked that the equation ({{EquationNote|2}}) is satisfied. In addition, we can also show (cf. for instance<ref name=\"dp04\"/>) that the solution of ({{EquationNote|1}}) is given by the Feynman-Kac formula\n\n:<math>\\eta_n(x) =\\frac{E\\left(1_x(X_n)\\prod_{p=0}^{n-1} G(X_p)\\right)}{E\\left(\\prod_{p=0}^{n-1} G(X_p) \\right)},</math>\n\nwith a Markov chain <math>X_n</math> with initial distribution <math>\\eta_0</math> and Markov transition ''M''.\n\nFor any function <math>f : S\\to \\mathbf{R}</math> we have\n\n:<math>\\eta_n(f):=\\sum_{x\\in S}\\eta_n(x)f(x) =\\frac{E\\left(f(X_n)\\prod_{p=0}^{n-1}G(X_p)\\right)}{E\\left(\\prod_{p=0}^{n-1} G(X_p)\\right)}</math>\n\nIf <math>G(x)=1</math> is the unit function and <math>\\epsilon=1</math>, then we have\n\n:<math>K_{\\eta_n}(x,y)=M(x,y)=\\mathbf{P} \\left( \\left. X_{n+1}=y \\right | X_n=x\\right), \\qquad \\eta_n(x) =E\\left(1_x(X_n)\\right)=\\mathbf{P}(X_n=x).</math>\n\nAnd the equation ({{EquationNote|2}}) reduces to the [[Chapman-Kolmogorov equation]]\n\n:<math>\\eta_{n+1}(y)=\\sum_{x\\in S}\\eta_n(x)M(x,y) \\qquad \\Leftrightarrow \\qquad \\mathbf{P}\\left(X_{n+1}=y\\right) =\\sum_{x\\in S} \\mathbf{P}(X_{n+1}=y|X_n=x) \\mathbf{P}\\left(X_n=x\\right)</math>\n\nThe mean field particle interpretation of this Feynman-Kac model is defined by sampling sequentially ''N'' conditionally independent random variables <math>\\xi^{(N,i)}_{n+1}</math> with probability distribution\n\n:<math>K_{n+1,\\eta_n^N}\\left(\\xi^{(N,i)}_n,y\\right)=\\epsilon G\\left(\\xi^{(N,i)}_n\\right) M\\left(\\xi^{(N,i)}_n,y\\right)+\\left(1-\\epsilon G\\left(\\xi^{(N,i)}_n\\right)\\right) \\sum_{j=1}^N \\frac{G\\left(\\xi^{(N,j)}_n\\right)}{\\sum_{k=1}^N G\\left(\\xi^{(N,k)}_n\\right)} M\\left(\\xi^{(N,j)}_n,y\\right)</math>\n\nIn other words, with a probability <math>\\epsilon G\\left(\\xi^{(N,i)}_n\\right)</math> the particle <math>\\xi^{(N,i)}_n</math> evolves to a new state <math>\\xi^{(N,i)}_{n+1}=y</math> randomly chosen with the probability distribution <math>M\\left(\\xi^{(N,i)}_n,y\\right)</math>; otherwise, <math>\\xi^{(N,i)}_n</math> jumps to a new location <math>\\xi^{(N,j)}_{n}</math> randomly chosen with a probability proportional to <math>G\\left(\\xi^{(N,j)}_n\\right)</math> and evolves to a new state <math>\\xi^{(N,i)}_{n+1}=y </math> randomly chosen with the probability distribution <math>M\\left(\\xi^{(N,j)}_n, y\\right).</math> If <math>G(x)=1</math> is the unit function and <math>\\epsilon=1</math>, the interaction between the particle vanishes and the particle model reduces to a sequence of independent copies of the Markov chain <math>X_n</math>. When <math>\\epsilon=0</math> the mean field particle model described above reduces to a simple [[mutation-selection]] genetic algorithm with fitness function ''G'' and mutation transition ''M''. These nonlinear Markov chain models and their mean field particle interpretation can be extended to  time non homogeneous models on general measurable state spaces (including transition states, path spaces and random excursion spaces) and continuous time models.<ref name=\"kol10\"/><ref name=\"dp13\"/><ref name=\"dp04\"/>\n\n===Gaussian nonlinear state space models===\nWe consider a sequence of real valued random variables <math>\\left (\\overline{X}_0, \\overline{X}_1, \\cdots \\right)</math> defined sequentially by the equations\n\n{{NumBlk|:| <math>\\overline{X}_{n+1}=E\\left(a\\left(\\overline{X}_n\\right)\\right) b \\left (\\overline{X}_n \\right )+c \\left (\\overline{X}_n \\right )+\\sigma W_n</math>|{{EquationRef|3}}}}\n\nwith a collection <math>W_n</math> of independent [[Normal distribution|standard Gaussian]] random variables, a positive parameter ''σ'', some functions <math>a,b,c: \\mathbf{R} \\to \\mathbf{R},</math> and some standard Gaussian initial random state <math>\\overline{X}_0</math>. We let <math>\\eta_n</math> be the probability distribution of the random state <math>\\overline{X}_n</math>; that is, for any bounded [[measurable function]] ''f'', we have\n\n:<math>E\\left(f(\\overline{X}_n)\\right)=\\int_{\\mathbf{R}} f(x) \\eta_n(dx),</math>\n\nwith\n\n:<math>\\mathbf{P} \\left (\\overline{X}_n\\in dx \\right )=\\eta_n(dx)</math>\n\nThe integral is the [[Lebesgue integral]], and ''dx'' stands for an infinitesimal neighborhood of the state ''x''. The [[Markov process|Markov transition]] of the chain is given for any bounded measurable functions ''f'' by the formula\n\n:<math>E\\left( \\left. f \\left (\\overline{X}_{n+1} \\right ) \\right |\\overline{X}_n=x\\right)=\\int_{\\mathbf{R}} K_{\\eta_n}(x,dy) f(y),</math>\n\nwith\n\n:<math>K_{\\eta_n}(x,dy)=\\mathbf{P} \\left ( \\left.\\overline{X}_{n+1}\\in dy\\right | \\overline{X}_n=x \\right )=\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp{\\left\\{-\\frac{1}{2\\sigma^2}\\left(y-\\left[b(x)\\int_{\\mathbf{R}} a(z) \\eta_n(dz)+c(x)\\right]\\right)^2\\right\\}} dy</math>\n\nUsing the tower property of [[conditional expectation]]s we prove that the probability distributions <math>\\eta_n</math> satisfy the nonlinear equation\n\n:<math>\\int_{\\mathbf{R}} \\eta_{n+1}(dy) f(y)=\\int_{\\mathbf{R}}\\left[\\int_{\\mathbf{R}} \\eta_n(dx)K_{\\eta_n}(x,dy)\\right] f(y)</math>\n\nfor any bounded measurable functions ''f''. This equation is sometimes written in the more synthetic form\n\n:<math>\\eta_{n+1} =\\Phi\\left(\\eta_n\\right)= \\eta_nK_{\\eta_n}\\quad\\Leftrightarrow\\quad\\eta_{n+1}(dy)= \\left(\\eta_nK_{\\eta_n}\\right)(dy) =\\int_{x\\in \\mathbf{R}}\\eta_n(dx)K_{\\eta_n}(x,dy)</math>\n\nThe mean field particle interpretation of this model is defined by the Markov chain\n\n:<math>\\xi^{(N)}_n=\\left(\\xi^{(N,1)}_n, \\cdots, \\xi^{(N,N)}_n \\right)</math>\n\non the product space <math>\\mathbf{R}^N</math> by\n\n:<math>\\xi^{(N,i)}_{n+1}=\\left(\\frac{1}{N}\\sum_{j=1}^N a\\left(\\xi^{(N,i)}_n\\right)\\right) b\\left(\\xi^{(N,i)}_n\\right)+c\\left(\\xi^{(N,i)}_n\\right)+\\sigma W^i_n\\qquad 1\\leqslant i\\leqslant N\n</math>\n\nwhere\n\n:<math>\\xi^{(N)}_0= \\left(\\xi^{(N,1)}_0, \\cdots, \\xi^{(N,N)}_0\\right), \\qquad \\left( W^1_n, \\cdots, W^N_n\\right)</math>\n\nstand for ''N'' independent copies of <math>\\overline{X}_0</math> and <math>W_n; n \\geqslant 1,</math> respectively. For regular models (for instance for bounded Lipschitz functions ''a'', ''b'', ''c'') we have the almost sure convergence\n\n:<math> \\frac{1}{N}\\sum_{j=1}^N f\\left(\\xi^{(N,i)}_n\\right)=\\int_{\\mathbf{R}} f(y) \\eta^N_n(dy) \\to_{N\\uparrow\\infty} E\\left(f(\\overline{X}_n)\\right) = \\int_{\\mathbf{R}}f(y)\\eta_n(dy),</math>\n\nwith the empirical measure\n\n:<math> \\eta^N_n=\\frac{1}{N}\\sum_{j=1}^N \\delta_{\\xi^{(N,i)}_n}</math>\n\nfor any bounded measurable functions ''f'' (cf. for instance <ref name=\"dp13\"/>). In the above display, <math>\\delta_x</math> stands for the [[Dirac measure]] at the state ''x''.\n\n===Continuous time mean field models===\n\nWe consider a [[standard Brownian motion]] <math>\\overline{W}_{t_n}</math> (a.k.a. [[Wiener Process]]) evaluated on a time mesh sequence <math>t_0=0<t_1<\\cdots<t_n<\\cdots</math> with a given time step <math>t_n-t_{n-1}=h</math>. We choose <math>c(x)=x</math> in equation ({{EquationNote|1}}), we replace <math>b(x)</math> and ''σ'' by <math>b(x) \\times h</math> and <math>\\sigma \\times \\sqrt{h}</math>, and we write <math>\\overline{X}_{t_n}</math> instead of <math>\\overline{X}_n</math> the values of the random states evaluated at the time step <math>t_n.</math> Recalling that <math>\\left(\\overline{W}_{t_{n+1}}-\\overline{W}_{t_n}\\right)</math> are independent centered Gaussian random variables with variance  <math>t_n-t_{n-1} = h,</math> the resulting equation can be rewritten in the following form\n\n{{NumBlk|:| <math>\\overline{X}_{t_{n+1}}-\\overline{X}_{t_n}=E\\left(a\\left(\\overline{X}_{t_n}\\right)\\right)b(\\overline{X}_{t_n})h+\\sigma\\left(\\overline{W}_{t_{n+1}}-\\overline{W}_{t_n}\\right)</math>|{{EquationRef|4}}}}\n\nWhen ''h'' → 0, the above equation converge to the nonlinear diffusion process\n\n:<math>d\\overline{X}_{t}=E\\left(a\\left(\\overline{X}_{t}\\right)\\right)b(\\overline{X}_{t})dt+\\sigma d\\overline{W}_{t}</math>\n\nThe mean field continuous time model associated with these nonlinear diffusions is the (interacting) diffusion process <math>\\xi^{(N)}_t=\\left(\\xi^{(N,i)}_t\\right)_{1\\leqslant i\\leqslant N}</math> on the product space <math>\\mathbf{R}^N</math> defined by\n\n:<math>d\\xi^{(N,i)}_{t}=\\left(\\frac{1}{N}\\sum_{j=1}^N a\\left(\\xi^{(N,i)}_t\\right)\\right)b\\left(\\xi^{(N,i)}_t\\right)+\\sigma d\\overline{W}_{t}^i\\qquad 1\\leqslant i\\leqslant N</math>\n\nwhere\n\n:<math>\\xi^{(N)}_0= \\left(\\xi^{(N,1)}_0, \\cdots, \\xi^{(N,N)}_0\\right), \\qquad \\left( \\overline{W}_{t}^1, \\cdots, \\overline{W}_t^N\\right)</math>\n\nare ''N'' independent copies of <math>\\overline{X}_0</math> and <math>\\overline{W}_t.</math> For regular models (for instance for bounded Lipschitz functions ''a'', ''b'') we have the almost sure convergence\n\n:<math>\\frac{1}{N}\\sum_{j=1}^N f\\left(\\xi^{(N,i)}_t\\right)=\\int_{\\mathbf{R}} f(y) \\eta^N_t(dy)\\to_{N\\uparrow\\infty} E\\left(f(\\overline{X}_t)\\right)=\\int_{\\mathbf{R}} f(y) \\eta_t(dy)</math>,\n\nwith <math>\\eta_t=\\text{Law}\\left(\\overline{X}_{t}\\right),</math> and the empirical measure\n\n:<math> \\eta^N_t=\\frac{1}{N}\\sum_{j=1}^N \\delta_{\\xi^{(N,i)}_t}</math>\n\nfor any bounded measurable functions ''f'' (cf. for instance.<ref name=\"as91\"/>). These nonlinear Markov processes and their mean field particle interpretation can be extended to interacting jump-diffusion processes<ref name=\"kol10\"/><ref name=\"dp13\"/><ref name=\"gm92\"/><ref name=\"gm97\"/>\n\n==References==\n{{Reflist}}\n\n==External links==\n{{refbegin}}\n* [http://web.maths.unsw.edu.au/~peterdel-moral/simulinks.html Feynman-Kac models and interacting particle systems] Theoretical aspects and a list of application domains of Feynman-Kac particle methods.\n* [http://www.stats.ox.ac.uk/~doucet/smc_resources.html Sequential Monte Carlo method and particle filters resources] \n* [http://vserver1.cscs.lsa.umich.edu/~crshalizi/notabene/interacting-particle-systems.html Interacting Particle Systems resources] \n* [http://vallico.net/casinoqmc/ QMC in Cambridge and around the world] General information about Quantum Monte Carlo.\n* [[Evolver (software)|EVOLVER Software package for stochastic optimisation using genetic algorithms]]\n* [[CASINO|CASINO Quantum Monte Carlo program developed by the Theory of Condensed Matter group at the Cavendish Laboratory in Cambridge.]]\n* [https://alea.bordeaux.inria.fr/biips/doku.php Biips is a probabilistic programming software for Bayesian inference with interacting particle systems.]\n{{refend}}\n\n{{Stochastic processes}}\n\n{{Statistics}}\n\n[[Category:Telecommunication theory]]\n[[Category:Statistical data types]]\n[[Category:Monte Carlo methods]]\n[[Category:Statistical mechanics]]\n[[Category:Sampling techniques]]\n[[Category:Stochastic simulation]]\n[[Category:Randomized algorithms]]\n[[Category:Risk analysis methodologies]]"
    },
    {
      "title": "Metropolis light transport",
      "url": "https://en.wikipedia.org/wiki/Metropolis_light_transport",
      "text": "{{More footnotes|date=February 2014}}\nThe '''Metropolis light transport''' ('''MLT''') is an application of a variant of the [[Monte Carlo method]] called the [[Metropolis–Hastings algorithm]] to the [[rendering equation]] for generating images from detailed physical descriptions of [[3D computer graphics|three-dimensional]] scenes.<ref>{{Cite book | last1 = Veach | first1 = E. | last2 = Guibas | first2 = L. J. | doi = 10.1145/258734.258775 | chapter = Metropolis light transport | title = Proceedings of the 24th annual conference on Computer graphics and interactive techniques  - SIGGRAPH '97 | pages = 65 | year = 1997 | isbn = 978-0897918961 | pmid =  | pmc = | citeseerx = 10.1.1.40.2090 }}</ref><ref>{{cite web|author1=[[Eric Veach]]|author2=[[Leonidas J. Guibas]]|title=Metropolis Light Transport|url=http://graphics.stanford.edu/papers/metro/metro.pdf|publisher=[[Stanford University]]}}</ref>\n\nThe procedure constructs paths from the eye to a light source using [[path tracing#Bidirectional path tracing|bidirectional path tracing]], then constructs slight modifications to the path.  Some careful statistical calculation (the Metropolis algorithm) is used to compute the appropriate distribution of brightness over the image.  This procedure has the advantage, relative to bidirectional path tracing, that once a path has been found from light to eye, the algorithm can then explore nearby paths; thus difficult-to-find light paths can be explored more thoroughly with the same number of simulated photons.  In short, the algorithm generates a path and stores the path's 'nodes' in a list. It can then modify the path by adding extra nodes and creating a new light path. While creating this new path, the algorithm decides how many new 'nodes' to add and whether or not these new nodes will actually create a new path.\n\nMetropolis light transport is an unbiased method that, in some cases (but not always), converges to a solution of the rendering equation faster than other unbiased algorithms such as path tracing or bidirectional path tracing.{{Citation needed|date=July 2010}}\n\n==See also==\n* [[Nicholas Metropolis]]  &ndash; The physicist after whom the algorithm is named\n''Renderers using MLT:''\n* [[Arion (software)|Arion]] &ndash; A commercial unbiased renderer based on path tracing and providing an MLT sampler\n* [[Indigo Renderer]] &ndash; A commercial unbiased 3D renderer that uses MLT\n* [[Iray]] ([http://www.nvidia-arc.com/iray.html external link]) &ndash; An unbiased renderer that has an option for MLT<ref>{{cite web|url=http://www.nvidia-arc.com/products/iray/features.html |title=NVIDIA Advanced Rendering: NVIDIA Iray |publisher=Nvidia-arc.com |date= |accessdate=2014-02-03}}</ref><ref>{{cite web|author= |url=http://blog.irayrender.com/post/51722647664/the-architectural-and-caustic-samplers |title=The Architectural and Caustic samplers - iray dev blog |publisher=Blog.irayrender.com |date=2013-05-30 |accessdate=2014-02-03}}</ref><ref>{{cite arxiv |eprint= 1705.01263 |title=The Iray Light Transport Simulation and Rendering System |last1= Keller |first1=Alexander |last2=Wächter |first2=Carsten |last3=Raab |first3=Matthias |last4=Seibert |first4=Daniel |author5=Dietger van Antwerpen |last6=Korndörfer |first6=Johann |last7=Kettner |first7=Lutz |class=cs.GR |date=2017 }}</ref>\n* [[Kerkythea]] &ndash; A free unbiased 3D renderer that uses MLT\n* [[LuxRender]] &ndash; An open source unbiased renderer that uses MLT\n* [[Mitsuba Renderer]] ([http://www.mitsuba-renderer.org web site])  A research-oriented renderer which implements several MLT variants\n* [[Unicorn Render]] ([http://www.unicornrender.com web site]) &ndash; A commercial unbiased render providing MTL sampler and Caustic sampler\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://graphics.stanford.edu/papers/metro/ Metropolis project at Stanford]\n* [http://www.mitsuba-renderer.org Homepage of the Mitsuba renderer]\n* [http://www.luxrender.net/ LuxRender - an open source render engine that supports MLT]\n* [http://www.kerkythea.net/ Kerkythea 2008 - a freeware rendering system that uses MLT]\n* [https://web.archive.org/web/20061202194353/http://rivit.cs.byu.edu/a3dg/publications/metropolisTutorial.pdf A Practical Introduction to Metropolis Light Transport]\n* [http://repository.tudelft.nl/view/ir/uuid%3A4a5be464-dc52-4bd0-9ede-faefdaff8be6/ Unbiased physically based rendering on the GPU]\n\n[[Category:Monte Carlo methods]]\n[[Category:Global illumination algorithms]]\n\n\n{{compu-stub}}"
    },
    {
      "title": "Metropolis-adjusted Langevin algorithm",
      "url": "https://en.wikipedia.org/wiki/Metropolis-adjusted_Langevin_algorithm",
      "text": "In [[computational statistics]], the '''Metropolis-adjusted Langevin algorithm (MALA)''' is a [[Markov chain Monte Carlo]] (MCMC) method for obtaining [[pseudo-random number sampling|random samples]] – sequences of random observations – from a [[probability distribution]] for which direct sampling is difficult.  As the name suggests, MALA uses a combination of two mechanisms to generate the states of a [[random walk]] that has the target probability distribution as an [[invariant measure]]:\n* new states are proposed using ([[overdamped]]) '''[[Langevin dynamics]]''', which use evaluations of the [[gradient]] of the target [[probability density function]];\n* these proposals are accepted or rejected using the '''[[Metropolis–Hastings algorithm]]''', which uses evaluations of the target probability density (but not its gradient).\nInformally, the Langevin dynamics drive the random walk towards regions of high probability in the manner of a gradient flow, while the Metropolis–Hastings accept/reject mechanism improves the mixing and convergence properties of this random walk.  MALA was originally proposed by [[Julian Besag]] in 1994,<ref name=\"Besag1994\">{{cite journal\n| author = J. Besag\n| title = Comments on \"Representations of knowledge in complex systems\" by U. Grenander and MI Miller\n| journal = Journal of the Royal Statistical Society, Series B\n| year = 1994\n| volume = 56\n| pages = 591&ndash;592\n}}</ref> and its properties were examined in detail by  [[Gareth Roberts (statistician)|Gareth Roberts]] together with [[Richard Tweedie]]<ref name=\"RobertsTweedie1996\">{{cite journal\n| author = G. O. Roberts and R. L. Tweedie\n| title = Exponential convergence of Langevin distributions and their discrete approximations\n| journal = Bernoulli\n| year = 1996\n| volume = 2\n| number = 4\n| pages = 341&ndash;363\n| doi = 10.2307/3318418\n| jstor = 3318418\n}}</ref> and [[Jeff Rosenthal]].<ref name=\"RobertsRosenthal1998\">{{cite journal\n| author = G. O. Roberts and J. S. Rosenthal\n| title = Optimal scaling of discrete approximations to Langevin diffusions\n| journal = Journal of the Royal Statistical Society, Series B\n| year = 1998\n| volume = 60\n| number = 1\n| pages = 255&ndash;268\n| doi = 10.1111/1467-9868.00123\n}}</ref>  Many variations and refinements have been introduced since then, e.g. the [[manifold]] variant of Girolami and Calderhead (2011).<ref name=\"GirolamiCalderhead2011\">{{cite journal\n| author = M. Girolami and B. Calderhead\n| title = Riemann manifold Langevin and Hamiltonian Monte Carlo methods\n| journal = Journal of the Royal Statistical Society, Series B\n| year = 2011\n| volume = 73\n| number = 2\n| pages = 123&ndash;214\n| doi = 10.1111/j.1467-9868.2010.00765.x\n| citeseerx = 10.1.1.190.580\n}}</ref>\n\n==Further details==\n\nLet <math>\\pi</math> denote a probability density function on <math>\\mathbb{R}^{d}</math>, one from which it is desired to draw an ensemble of [[independent and identically distributed]] samples.  We consider the overdamped Langevin  [[Itô diffusion]]\n\n: <math>\\dot{X} = \\nabla \\log \\pi(X) + \\sqrt{2} \\dot{W}</math>\n\ndriven by the time derivative of a standard [[Brownian motion]] <math>W</math>.  (Note that another commonly-used normalisation for this diffusion is\n\n: <math>\\dot{X} = \\frac{1}{2} \\nabla \\log \\pi(X) + \\dot{W},</math>\n\nwhich generates the same dynamics.)  In the limit as <math>t \\to \\infty</math>, this probability distribution <math>\\rho(t)</math> of <math>X(t)</math> approaches a stationary distribution, which is also invariant under the diffusion, which we denote <math>\\rho_\\infty</math>.  It turns out that, in fact, <math>\\rho_\\infty = \\pi</math>.\n\nApproximate sample paths of the Langevin diffusion can be generated by many discrete-time methods.  One of the simplest is the [[Euler–Maruyama method]] with a fixed time step <math>\\tau > 0</math>.  We set <math>X_0 := x_0</math> and then recursively define an approximation <math>X_k</math> to the true solution <math>X(k \\tau)</math> by\n\n:<math>X_{k + 1} := X_k + \\tau \\nabla \\log \\pi(X_k) + \\sqrt{2 \\tau} \\xi_k,</math>\n\nwhere each <math>\\xi_{k}</math> is an independent draw from a [[multivariate normal distribution]] on <math>\\mathbb{R}^{d}</math> with [[expected value|mean]] 0 and [[covariance matrix]] equal to the <math>d \\times d</math> [[identity matrix]].  Note that <math>X_{k + 1}</math> is normally distributed with mean <math>X_k + \\tau \\nabla \\log \\pi(X_k)</math> and covariance equal to <math>2 \\tau</math> times the <math>d \\times d</math> identity matrix.\n\nIn contrast to the Euler–Maruyama method for simulating the Langevin diffusion, which always updates <math>X_k</math> according to the update rule\n\n:<math>X_{k + 1} := X_k + \\tau \\nabla \\log \\pi(X_k) + \\sqrt{2 \\tau} \\xi_k,</math>\n\nMALA incorporates an additional step.  We consider the above update rule as defining a ''proposal'' <math>\\tilde{X}_{k + 1}</math> for a new state,\n\n:<math>\\tilde{X}_{k + 1} := X_k + \\tau \\nabla \\log \\pi(X_k) + \\sqrt{2 \\tau} \\xi_k.</math>\n\nThis proposal is accepted or rejected according to the Metropolis–Hastings algorithm:  set\n\n:<math>\\alpha := \\min \\left\\{ 1 , \\frac{\\pi(\\tilde{X}_{k + 1}) q(X_{k}\\mid\\tilde{X}_{k + 1})}{\\pi({X}_{k}) q(\\tilde{X}_{k + 1}\\mid X_k)} \\right\\},</math>\n\nwhere\n\n:<math>q(x'\\mid x) \\propto \\exp \\left( - \\frac{1}{4 \\tau} \\| x' - x - \\tau \\nabla \\log \\pi(x) \\|_2^2 \\right)</math>\n\nis the transition probability density from <math>x</math> to <math>x'</math> (note that, in general <math>q(x'\\mid x) \\neq q(x\\mid x')</math>).  Let <math>u</math> be drawn from the [[continuous uniform distribution]] on the interval <math>[0, 1]</math>.  If <math>u \\leq \\alpha</math>, then the proposal is accepted, and we set <math>X_{k + 1} := \\tilde{X}_{k + 1}</math>;  otherwise, the proposal is rejected, and we set <math>X_{k + 1} := X_k</math>.\n\nThe combined dynamics of the Langevin diffusion and the Metropolis–Hastings algorithm satisfy the [[detailed balance]] conditions necessary for the existence of a unique, invariant, stationary distribution <math>\\rho_{\\infty} = \\pi</math>.  Compared to naive Metropolis–Hastings, MALA has the advantage that it usually proposes moves into regions of higher <math>\\pi</math> probability, which are then more likely to be accepted.  On the other hand, when <math>\\pi</math> is strongly [[isotropy|anisotropic]] (i.e. it varies much more quickly in some directions than others), it is necessary to take <math>0 < \\tau \\ll 1</math> in order to properly capture the Langevin dynamics;  the use of a positive-definite [[preconditioning]] matrix <math>A \\in \\mathbb{R}^{d \\times d}</math> can help to alleviate this problem, by generating proposals according to\n:<math>\\tilde{X}_{k + 1} := X_k + \\tau A \\nabla \\log \\pi(X_k) + \\sqrt{2 \\tau A} \\xi_k,</math>\nso that <math>\\tilde{X}_{k + 1}</math> has mean <math>X_k + \\tau A \\nabla \\log \\pi(X_k)</math> and covariance <math>2 \\tau A</math>.\n\nIn practical applications, the optimal acceptance rate for this algorithm is <math>0.574</math>; if it is discovered to be substantially different, <math>\\tau</math> should be modified accordingly.<ref name=\"RobertsRosenthal1998\" />\n\n==References==\n<references />\n\n[[Category:Monte Carlo methods]]\n[[Category:Markov chain Monte Carlo]]\n[[Category:Sampling techniques]]"
    },
    {
      "title": "Metropolis–Hastings algorithm",
      "url": "https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm",
      "text": "[[Image:Metropolis hastings algorithm.png|thumb|450px|The proposal [[probability distribution|distribution]] ''Q'' proposes the next point to which the [[random walk]] might move.]]\n\nIn [[statistics]] and [[statistical physics]], the '''Metropolis–Hastings algorithm''' is a [[Markov chain Monte Carlo]] (MCMC) method for obtaining a sequence of [[pseudo-random number sampling|random samples]] from a [[probability distribution]] from which direct sampling is difficult. This sequence can be used to approximate the distribution (e.g. to generate a [[histogram]]) or to [[Monte Carlo integration|compute an integral]] (e.g. an [[expected value]]).  Metropolis–Hastings and other MCMC algorithms are generally used for sampling from multi-dimensional distributions, especially when the number of dimensions is high.  For single-dimensional distributions, there are usually other methods (e.g. [[adaptive rejection sampling]]) that can directly return independent samples from the distribution, and these are free from the problem of [[autocorrelation|autocorrelated]] samples that is inherent in MCMC methods.\n\n==History==\nThe algorithm was named after [[Nicholas Metropolis]], who authored the 1953 paper ''[[Equation of State Calculations by Fast Computing Machines]]'' together with [[Arianna W. Rosenbluth]], [[Marshall Rosenbluth]], [[Augusta H. Teller]] and [[Edward Teller]].  This paper proposed the algorithm for the case of symmetrical proposal distributions, and [[W. K. Hastings]] extended it to the more general case in 1970.<ref name=Hastings/>\n\nSome controversy exists with regard to credit for development of the algorithm.  Metropolis had coined the term \"Monte Carlo\" in an earlier paper with [[Stanislav Ulam]], was familiar with the computational aspects of the method, and led the group in the Theoretical Division that designed and built the [[MANIAC I]] computer used in the experiments in 1952.  However, prior to 2003, there was no detailed account of the algorithm's development.  Then, shortly before his death, [[Marshall Rosenbluth]] attended a 2003 conference at LANL marking the 50th anniversary of the 1953 publication.    At this conference, Rosenbluth described the algorithm and its development in a presentation titled \"Genesis of the Monte Carlo Algorithm for Statistical Mechanics\".<ref name=Rosenbluth/>.  Further historical clarification is made by Gubernatis in a 2005 journal article<ref name=Gubernatis/> recounting the 50th anniversary conference. Rosenbluth makes it clear that he and his wife Arianna did the work, and that Metropolis played no role in the development other than providing computer time.\n\nThis contradicts an account by Edward Teller, who states in his memoirs that the five authors of the 1953 paper worked together for \"days (and nights).\"<ref name=Teller/> In contrast, the detailed account by Rosenbluth credits Teller with a crucial but early suggestion to \"take advantage of statistical mechanics and take ensemble averages instead of following detailed kinematics\".  This, says Rosenbluth, started him thinking about the generalized Monte Carlo approach -- a topic which he says he had discussed often with Von Neumann.  Arianna recounted (to Gubernatis in 2003) that Augusta Teller started the computer work, but that Arianna herself took it over and wrote the code from scratch.  In an oral history recorded shortly before his death<ref name=Barth/>, Rosenbluth again credits Teller with posing the original problem, himself with solving it, and Arianna with programming the computer.  In terms of reputation there is little reason to question Rosenbluth's account.  In a biographical memoir of Rosenbluth, [[Freeman Dyson]] writes\n\n{{Quote\n|text=Many times I came to Rosenbluth, asking him a question [...] and receiving an answer in two minutes.  Then it would usually take me a week of hard work to understand in detail why Rosenbluth's answer was right.  He had an amazing ability to see through a complicated physical situation and reach the right answer by physical arguments.  Enrico Fermi was the only other physicist I have known who was equal to Rosenbluth in his intuitive grasp of physics.<ref name=Dyson/>\n}} \n\n==Intuition==\nThe Metropolis–Hastings algorithm can draw samples from any [[probability distribution]] <math>P(x)</math>, provided that the value of a function <math>f(x)</math> proportional to the density of <math>P</math> can be calculated{{clarify|reason=What exactly is f(x)? How do we determine it? How is it related to the P(x)?|date=May 2019}}. The requirement that <math>f(x)</math> must only be proportional to the density, rather than exactly equal to it, makes the Metropolis–Hastings algorithm particularly useful, because calculating the necessary normalization factor is often extremely difficult in practice{{citation needed|date=May 2019}}.\n\nThe Metropolis–Hastings algorithm works by generating a sequence of sample values in such a way that, as more and more sample values are produced, the distribution of values more closely approximates the desired distribution <math>P(x)</math>. These sample values are produced iteratively, with the distribution of the next sample being dependent only on the current sample value (thus making the sequence of samples into a [[Markov chain]]). Specifically, at each iteration, the algorithm picks a candidate for the next sample value based on the current sample value. Then, with some probability, the candidate is either accepted (in which case the candidate value is used in the next iteration) or rejected (in which case the candidate value is discarded, and current value is reused in the next iteration)—the probability of acceptance is determined by comparing the values of the function <math>f(x)</math> of the current and candidate sample values with respect to the desired distribution <math>P(x)</math>.\n\nFor the purpose of illustration, the Metropolis algorithm, a special case of the Metropolis–Hastings algorithm where the proposal function is symmetric, is described below.\n<!---The sample values are linked in a [[Markov chain]], which means that the probability of each sample is conditionally independent of any earlier sample, given the sample immediately before it. In other words, \ngeneral idea is to generate a sequence of samples which are linked in a [[Markov chain]]; in other words, where each sample in the sequence is conditionally independent of any earlier sample, given the sample immediately before it. The procedure for choosing successive samples guarantees that the distribution of sample values will match the desired distribution ''P''(''x'') after a long time.!-->\n\n'''Metropolis algorithm (symmetric proposal distribution)'''\n\nLet <math>f(x)</math> be a function that is proportional to the desired probability distribution <math>P(x)</math> (a.k.a. a target distribution).\n\n# Initialization: Choose an arbitrary point <math>x_0</math> to be the first sample, and choose an arbitrary probability density <math>g(x|y)</math> (sometimes written <math>Q(x|y)</math>) that suggests a candidate for the next sample value <math>x</math>, given the previous sample value <math>y</math>. For the Metropolis algorithm, <math>g</math> must be symmetric; in other words, it must satisfy <math>g(x|y) = g(y|x)</math>. A usual choice is to let <math>g(x|y)</math> be a [[Gaussian distribution]] centered at <math>y</math>, so that points closer to <math>y</math> are more likely to be visited next—making the sequence of samples into a [[random walk]].   The function <math>g</math> is referred to as the ''proposal density'' or ''jumping distribution''. \n# For each iteration ''t'':\n#* '''Generate''' : Generate a candidate <math>x'</math> for the next sample by picking from the distribution <math>g(x'|x_t)</math>.\n#* '''Calculate''' : Calculate the ''acceptance ratio'' <math display=\"inline\">\\alpha = f(x')/f(x_t)</math>, which will be used to decide whether to accept or reject the candidate. Because ''f'' is proportional to the density of ''P'', we have that <math>\\alpha = f(x')/f(x_t) = P(x')/P(x_t)</math>.\n#* '''Accept or Reject''' : \n#** Generate a uniform random number <math>u</math> on [0,1].\n#** If <math>u \\le \\alpha</math> ''accept'' the candidate by setting <math>x_{t+1} = x'</math>,\n#** If <math>u > \\alpha</math> ''reject'' the candidate and set <math>x_{t+1}=x_t</math>, instead.\n\nThis algorithm proceeds by randomly attempting to move about the sample space, sometimes accepting the moves and sometimes remaining in place.  Note that the acceptance ratio <math>\\alpha</math> indicates how probable the new proposed sample is with respect to the current sample, according to the distribution <math>\\displaystyle P(x)</math>.  If we attempt to move to a point that is more probable than the existing point (i.e. a point in a higher-density region of <math>\\displaystyle P(x)</math>), we will always accept the move.  However, if we attempt to move to a less probable point, we will sometimes reject the move, and the more the relative drop in probability, the more likely we are to reject the new point.  Thus, we will tend to stay in (and return large numbers of samples from) high-density regions of <math>\\displaystyle P(x)</math>, while only occasionally visiting low-density regions.  Intuitively, this is why this algorithm works, and returns samples that follow the desired distribution <math>\\displaystyle P(x)</math>.\n\nCompared with an algorithm like [[adaptive rejection sampling]]<ref name=\":0\">{{Cite journal|title = Adaptive Rejection Sampling for Gibbs Sampling|jstor = 2347565|journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1992-01-01|pages = 337–348|volume = 41|issue = 2|doi = 10.2307/2347565|first = W. R.|last = Gilks|first2 = P.|last2 = Wild}}</ref> that directly generates independent samples from a distribution, Metropolis–Hastings and other MCMC algorithms have a number of disadvantages:\n*The samples are correlated.  Even though over the long term they do correctly follow <math>\\displaystyle P(x)</math>, a set of nearby samples will be correlated with each other and not correctly reflect the distribution.  This means that if we want a set of independent samples, we have to throw away the majority of samples and only take every ''n''th sample, for some value of ''n'' (typically determined by examining the [[autocorrelation]] between adjacent samples).  Autocorrelation can be reduced by increasing the ''jumping width'' (the average size of a jump, which is related to the variance of the jumping distribution), but this will also increase the likelihood of rejection of the proposed jump.  Too large or too small a jumping size will lead to a ''slow-mixing'' Markov chain, i.e. a highly correlated set of samples, so that a very large number of samples will be needed to get a reasonable estimate of any desired property of the distribution.\n*Although the Markov chain eventually converges to the desired distribution, the initial samples may follow a very different distribution, especially if the starting point is in a region of low density.  As a result, a ''burn-in'' period is typically necessary,<ref>{{Cite book|title=Bayesian data analysis|date=2004|publisher=Chapman & Hall/CRC|others=Gelman, Andrew.|isbn=978-1584883883|edition= 2nd|location=Boca Raton, Fla.|oclc=51991499}}</ref> where an initial number of samples (e.g. the first 1,000 or so) are thrown away.\nOn the other hand, most simple [[rejection sampling]] methods suffer from the \"[[curse of dimensionality]]\", where the probability of rejection increases exponentially as a function of the number of dimensions.  Metropolis–Hastings, along with other MCMC methods, do not have this problem to such a degree, and thus are often the only solutions available when the number of dimensions of the distribution to be sampled is high.  As a result, MCMC methods are often the methods of choice for producing samples from [[hierarchical Bayesian model]]s and other high-dimensional statistical models used nowadays in many disciplines.\n\nIn [[multivariate distribution|multivariate]] distributions, the classic Metropolis–Hastings algorithm as described above involves choosing a new multi-dimensional sample point.  When the number of dimensions is high, finding the right jumping distribution to use can be difficult, as the different individual dimensions behave in very different ways, and the jumping width (see above) must be \"just right\" for all dimensions at once to avoid excessively slow mixing.  An alternative approach that often works better in such situations, known as [[Gibbs sampling]], involves choosing a new sample for each dimension separately from the others, rather than choosing a sample for all dimensions at once.  This is especially applicable when the multivariate distribution is composed out of a set of individual [[random variable]]s in which each variable is conditioned on only a small number of other variables, as is the case in most typical [[hierarchical Bayesian model|hierarchical model]]s.  The individual variables are then sampled one at a time, with each variable conditioned on the most recent values of all the others.  Various algorithms can be used to choose these individual samples, depending on the exact form of the multivariate distribution: some possibilities are the [[adaptive rejection sampling]] methods,<ref name=\":0\" /><ref>{{Cite journal|title = Concave-Convex Adaptive Rejection Sampling|journal = Journal of Computational and Graphical Statistics|date = 2011-01-01|issn = 1061-8600|pages = 670–691|volume = 20|issue = 3|doi = 10.1198/jcgs.2011.09058|first = Dilan|last = Görür|first2 = Yee Whye|last2 = Teh}}</ref><ref>{{Cite journal|title = A Rejection Technique for Sampling from T-concave Distributions|journal = ACM Trans. Math. Softw.|date = 1995-06-01|issn = 0098-3500|pages = 182–193|volume = 21|issue = 2|doi = 10.1145/203082.203089|first = Wolfgang|last = Hörmann|citeseerx = 10.1.1.56.6055}}</ref><ref>{{Cite journal|title = A generalization of the adaptive rejection sampling algorithm|journal = Statistics and Computing|date = 2010-08-25|issn = 0960-3174|pages = 633–647|volume = 21|issue = 4|doi = 10.1007/s11222-010-9197-9|first = Luca|last = Martino|first2 = Joaquín|last2 = Míguez|hdl = 10016/16624}}</ref> the  adaptive rejection Metropolis sampling algorithm<ref>{{Cite journal|title = Adaptive Rejection Metropolis Sampling within Gibbs Sampling|jstor = 2986138|journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1995-01-01|pages = 455–472|volume = 44|issue = 4|doi = 10.2307/2986138|first = W. R.|last = Gilks|first2 = N. G.|last2 = Best|first3 = K. K. C.|last3 = Tan}}</ref> or its improvements<ref>{{Cite journal|title = Independent Doubly Adaptive Rejection Metropolis Sampling Within Gibbs Sampling|journal = IEEE Transactions on Signal Processing|date = 2015-06-01|issn = 1053-587X|pages = 3123–3138|volume = 63|issue = 12|doi = 10.1109/TSP.2015.2420537|first = L.|last = Martino|first2 = J.|last2 = Read|first3 = D.|last3 = Luengo|arxiv = 1205.5494|bibcode = 2015ITSP...63.3123M}}</ref><ref>{{Cite journal|title = Adaptive rejection Metropolis sampling using Lagrange interpolation polynomials of degree 2|journal = Computational Statistics & Data Analysis|date = 2008-03-15|pages = 3408–3423|volume = 52|issue = 7|doi = 10.1016/j.csda.2008.01.005|first = Renate|last = Meyer|first2 = Bo|last2 = Cai|first3 = François|last3 = Perron}}</ref> (see [http://a2rms.sourceforge.net matlab code]), a simple one-dimensional Metropolis–Hastings step, or [[slice sampling]].\n\n==Formal derivation==\nThe purpose of the Metropolis–Hastings algorithm is to generate a collection of states according to a desired distribution <math>P(x)</math>. To accomplish this, the algorithm uses a [[Markov process]] which asymptotically reaches a unique [[Markov chain#Steady-state analysis and limiting distributions|stationary distribution]] <math>\\pi(x)</math> such that <math>\\pi(x)=P(x)</math> .<ref name=Roberts_Casella/>\n\nA Markov process is uniquely defined by its transition probabilities, <math>P(x' | x)</math>, the probability of transitioning from any given state, <math>x</math>, to any other given state, <math>x'</math>. It has a unique stationary distribution <math>\\pi(x)</math> when the following two conditions are met:<ref name=Roberts_Casella/>\n# '''existence of stationary distribution''': there must exist a stationary distribution <math>\\pi(x)</math>. A sufficient but not necessary condition is [[Markov chain#Reversible Markov chain|detailed balance]] which requires that each transition <math>x\\rightarrow x'</math> is reversible: for every pair of states <math>x, x'</math>, the probability of being in state <math>x</math> and transitioning to state <math>x'</math> must be equal to the probability of being in state <math>x'</math> and transitioning to state <math>x</math>, <math>\\pi(x)P(x' | x) = \\pi(x')P(x | x')</math>.\n# '''uniqueness of stationary distribution''': the stationary distribution <math>\\pi(x)</math> must be unique. This is guaranteed by [[Markov Chain#Ergodicity|ergodicity]] of the Markov process, which requires that every state must (1) be aperiodic—the system does not return to the same state at fixed intervals; and (2) be positive recurrent—the expected number of steps for returning to the same state is finite.\n\nThe Metropolis–Hastings algorithm involves designing a Markov process (by constructing transition probabilities) which fulfills the two above conditions, such that its stationary distribution <math>\\pi(x)</math> is chosen to be <math>P(x)</math>. The derivation of the algorithm starts with the condition of detailed balance:\n\n<math>P(x' | x)P(x) = P(x', x) = P(x | x')P(x')</math>\n\nwhich is re-written as\n\n<math>\\frac{P(x' | x)}{P(x | x')} = \\frac{P(x')}{P(x)}</math>.\n\nThe approach is to separate the transition in two sub-steps; the proposal and the acceptance-rejection. The '''proposal distribution''' <math>\\displaystyle g(x' | x)</math> is the conditional probability of proposing a state <math>x'</math> given <math>x</math>, and the '''acceptance ratio''' <math>\\displaystyle A(x' , x)</math> the probability to accept the proposed state <math>x'</math>. The transition probability can be written as the product of them:\n\n<math>P(x'|x) = g(x' | x) A(x' , x)</math>  .\n\nInserting this relation in the previous equation, we have\n\n<math>\\frac{A(x' , x)}{A(x , x')} = \\frac{P(x')}{P(x)}\\frac{g(x | x')}{g(x' | x)}</math>  .\n\nThe next step in the derivation is to choose an acceptance ratio that fulfils the condition above. One common choice is the Metropolis choice:\n\n<math>A(x' , x) = \\min\\left(1,\\frac{P(x')}{P(x)}\\frac{g(x | x')}{g(x' | x)}\\right)</math>\n\nFor this Metropolis acceptance ratio <math>A</math>, either <math>A(x',x)=1</math> or <math>A(x,x')=1</math> and, either way, the condition is satisfied.\n\nThe Metropolis–Hastings algorithm thus consists in the following:\n\n# Initialise \n## Pick an initial state <math>x_0</math>;\n## Set <math>t=0</math>;\n# Iterate\n## '''Generate:''' randomly generate a candidate state x' according to <math>g(x' | x_t)</math>;\n## '''Calculate:''' calculate the acceptance probability <math display=\"inline\">A(x' , x_t) = \\min\\left(1,\\frac{P(x')}{P(x_t)}\\frac{g(x_t | x')}{g(x' | x_t)}\\right)</math>; \n## '''Accept or Reject:''' \n### generate a uniform random number <math>u \\in [0,1]</math>;\n### if <math>u \\le A(x' , x_t)</math>, ''accept'' the new state and set <math>x_{t+1} = x'</math>;\n### if <math>u >   A(x' , x_t)</math>, ''reject'' the new state, and copy the old state forward <math>x_{t+1} = x_{t}</math>;\n## '''Increment:'''  set <math display=\"inline\">t=t+1</math>;\n\nProvided that specified conditions are met, the empirical distribution of saved states <math>x_0, \\ldots, x_T</math> will approach <math>P(x)</math>. The number of iterations (<math>T</math>) required to effectively estimate <math>P(x)</math> depends on the number of factors, including the relationship between <math>P(x)</math> and the proposal distribution and the desired accuracy of estimation.<ref>Raftery, Adrian E., and Steven Lewis. \"How Many Iterations in the Gibbs Sampler?.\" ''In Bayesian Statistics 4''. 1992.</ref>  For distribution on discrete state spaces, it has to be of the order of the [[autocorrelation]] time of the Markov process.<ref name=Newman_Barkema/>\n\nIt is important to notice that it is not clear, in a general problem, which distribution <math>\\displaystyle g(x' | x)</math> one should use or the number of iterations necessary for proper estimation; both are free parameters of the method which must be adjusted to the particular problem in hand.\n\n== Use in numerical integration ==\n\n{{main|Monte Carlo integration}}\n\nA common use of Metropolis–Hastings algorithm is to compute an integral. Specifically, consider a space <math>\\Omega \\subset \\mathbb{R}</math> and a probability distribution P(x) over <math>\\Omega</math>, <math>x \\in \\Omega</math>. Metropolis-Hastings can estimate an integral of the form of\n\n:<math>\nP(E) = \\int_\\Omega A(x) P(x) dx\n</math>\nwhere A(x) is an arbitrary function of interest. \nFor example, consider a [[statistic]] E(x) and its probability distribution P(E), which is a [[marginal distribution]]. Suppose that the goal is to estimate P(E) for E on the tail of P(E). Formally, P(E) can be written as\n\n:<math>\nP(E) = \\int_\\Omega P(E|x) P(x) dx = \\int_\\Omega \\delta(E - E(x)) P(x) dx=E_X(P(E|X))\n</math>\nand, thus, estimating P(E) can be accomplished by estimating the expected value of the [[indicator function]] <math>A_E(x) \\equiv \\mathbf{1}_E(x)</math>, which is 1 when <math>E(x) \\in [E, E + \\Delta E]</math> and zero otherwise.\nBecause E is on the tail of P(E), the probability to draw a state x with E(x) on the tail of P(E) is proportional to P(E), which is small by definition. Metropolis-Hastings can be used here to sample (rare) states more likely and thus increase the number of samples used to estimate P(E) on the tails. This can be done e.g. by using a sampling distribution <math>\\pi(x)</math> to favor those states (e.g. <math>\\pi(x) \\propto e^{a E}</math> with a>0).\n\n==Step-by-step instructions==\n\nSuppose the most recent value sampled is <math>x_t\\,</math>. To follow the Metropolis–Hastings algorithm, we next draw a new proposal state <math>x'\\,</math> with probability density <math>g(x' | x_t)\\,</math>, and calculate a value\n\n:<math>\na = a_1 a_2\\,\n</math>\n\nwhere\n\n:<math>\na_1 = \\frac{P(x')}{P(x_t)} \\,\\!\n</math>\n\nis the probability (e.g., Bayesian posterior) ratio between the proposed sample <math>x'\\,</math> and the previous sample <math>x_t\\,</math>, and\n\n:<math>\na_2 = \\frac{g(x_t | x')}{g(x' | x_t)}\n</math>\n\nis the ratio of the proposal density in two directions (from <math>x_t\\,</math> to <math>x'\\,</math> and ''vice versa'').\nThis is equal to 1 if the proposal density is symmetric.\nThen the new state <math>\\displaystyle x_{t+1}</math> is chosen according to the following rules.\n\n:<math>\n\\begin{matrix}\n\\mbox{If } a \\geq 1: &  \\\\\n& x_{t+1} = x',\n\\end{matrix}\n</math>\n:<math>\n\\begin{matrix}\n\\mbox{else} & \\\\\n& x_{t+1} = \\left\\{\n                   \\begin{array}{lr}\n                       x' & \\mbox{ with probability }a \\\\\n                       x_t & \\mbox{ with probability }1-a.\n                   \\end{array}\n            \\right.\n\\end{matrix}\n</math>\n\nThe Markov chain is started from an arbitrary initial value <math>\\displaystyle x_0</math> and the algorithm is run for many iterations until this initial state is \"forgotten\".  \nThese samples, which are discarded, are known as ''burn-in''. The remaining set of accepted values of <math>x</math> represent a [[Sample (statistics)|sample]] from the distribution <math>P(x)</math>.\n\nThe algorithm works best if the proposal density matches the shape of the target distribution <math>\\displaystyle P(x)</math> from which direct sampling is difficult, that is <math>g(x' | x_t) \\approx P(x') \\,\\!</math>.\nIf a Gaussian proposal density <math>\\displaystyle g</math> is used the variance parameter <math>\\displaystyle \\sigma^2</math> has to be tuned during the burn-in period.\nThis is usually done by calculating the ''acceptance rate'', which is the fraction of proposed samples that is accepted in a window of the last <math>\\displaystyle N</math> samples.\nThe desired acceptance rate depends on the target distribution, however it has been shown theoretically that the ideal acceptance rate for a one-dimensional Gaussian distribution is approx 50%, decreasing to approx 23% for an <math>\\displaystyle N</math>-dimensional Gaussian target distribution.<ref name=Roberts/>\n\nIf <math>\\displaystyle \\sigma^2</math> is too small the chain will ''mix slowly'' (i.e., the acceptance rate will be high but successive samples will move around the space slowly and the chain will converge only slowly to <math>\\displaystyle P(x)</math>).  On the other hand,\nif <math>\\displaystyle \\sigma^2</math> is too large the acceptance rate will be very low because the proposals are likely to land in regions of much lower probability density, so <math>\\displaystyle a_1</math> will be very small and again the chain will converge very slowly. One typically tunes the proposal distribution so that the algorithms accepts on the order of 30% of all samples -- in line with the theoretical estimates mentioned in the previous paragraph.\n\n[[Image:3dRosenbrock.png|thumb|350px|The result of three [[Markov chain]]s running on the 3D [[Rosenbrock function]] using the Metropolis-Hastings algorithm. The algorithm samples from regions where the [[posterior probability]] is high and the chains begin to mix in these regions. The approximate position of the maximum has been illuminated. Note that the red points are the ones that remain after the burn-in process. The earlier ones have been discarded.]]\n\n==See also==\n* [[Detailed balance]]\n* [[Genetic algorithm]]s\n* [[Gibbs sampling]]\n* [[Mean field particle methods]]\n* [[Metropolis-adjusted Langevin algorithm]]\n* [[Metropolis light transport]]\n* [[Multiple-try Metropolis]]\n* [[Parallel tempering]]\n* [[Preconditioned Crank–Nicolson algorithm]]\n* [[Particle filter|Sequential Monte Carlo]]\n* [[Simulated annealing]]\n\n{{clear}}\n\n==References==\n{{Reflist|\nrefs=\n<ref name=Hastings>{{cite journal\n |first=W.K. |last=Hastings\n |title=Monte Carlo Sampling Methods Using Markov Chains and Their Applications\n |journal=[[Biometrika]]\n |volume=57 |issue=1 |pages=97&ndash;109 |year=1970 \n |jstor=2334940 | zbl = 0219.65008 |doi=10.1093/biomet/57.1.97\n|bibcode=1970Bimka..57...97H}}</ref>\n<ref name=Teller>Teller, Edward. ''Memoirs: A Twentieth-Century Journey in Science and Politics''. [[Perseus Publishing]], 2001, p. 328</ref>\n<ref name=Barth>Rosenbluth, Marshall. [https://www.aip.org/history-programs/niels-bohr-library/oral-histories/28636-1 \"Oral History Transcript\"]. American Institute of Physics</ref>\n<ref name=Gubernatis>{{cite journal |title=Marshall Rosenbluth and the Metropolis Algorithm |author=J.E. Gubernatis |journal=[[Physics of Plasmas]] | volume=12| pages=057303| year=2005| doi=10.1063/1.1887186 | bibcode=2005PhPl...12e7303G |issue=5\n}}</ref>\n<ref name=Rosenbluth>{{cite journal |title=Genesis of the Monte Carlo Algorithm for Statistical Mechanics|author=M.N. Rosenbluth |journal=[[AIP Conference Proceedings]] | volume=690 | pages=22 | year=2003 | doi=10.1063/1.1632112 \n}}</ref>\n<ref name=Dyson>{{cite journal |title=Marshall N. Rosenbluth|author=F. Dyson |journal=[[Proceedings of the American Philosophical Society]] | volume=250 | pages=404 | year=2006 \n}}</ref>\n<ref name=Roberts>{{cite journal\n |first1=G.O. |last1=Roberts\n |first2=A. |last2=Gelman\n |first3=W.R. |last3=Gilks\n |title=Weak convergence and optimal scaling of random walk Metropolis algorithms\n |journal=[[Ann. Appl. Probab.]]\n |volume=7 |issue=1 |pages=110&ndash;120 |year=1997\n |doi=10.1214/aoap/1034625254\n|url=http://www.stat.columbia.edu/~gelman/research/published/theory7.ps|citeseerx=10.1.1.717.2582}}</ref>\n<ref name=\"Roberts_Casella\">{{cite book |title=Monte Carlo Statistical Methods |last1=Robert |first1=Christian |last2=Casella |first2=George |year= 2004 |publisher=Springer |isbn=978-0387212395 }}</ref>\n<ref name=\"Newman_Barkema\">{{cite book |title=Monte Carlo Methods in Statistical Physics |last1=Newman |first1=M. E. J. |last2=Barkema |first2=G. T. |year= 1999 |publisher=Oxford University Press |location=USA |isbn=978-0198517979 }}</ref>\n}}\n\n== Further reading ==\n* [[Bernd A. Berg]]. ''Markov Chain Monte Carlo Simulations and Their Statistical Analysis''. Singapore, [[World Scientific]], 2004.\n* Siddhartha Chib and Edward Greenberg: \"Understanding the Metropolis&ndash;Hastings Algorithm\". ''[[American Statistician]]'', 49(4), 327&ndash;335, 1995\n* [http://www.tandfonline.com/doi/abs/10.1080/03610918.2013.777455#.VOk8J1PF9_c David D. L. Minh and Do Le Minh. \"Understanding the Hastings Algorithm.\" Communications in Statistics - Simulation and Computation, 44:2 332-349, 2015]\n* Bolstad, William M. (2010) ''Understanding Computational Bayesian Statistics'', [[John Wiley & Sons]] {{ISBN|0-470-04609-0}}\n\n== External links ==\n* [http://xbeta.org/wiki/show/Metropolis-Hastings+algorithm Metropolis-Hastings algorithm on xβ]\n* [https://web.archive.org/web/20110405024000/http://www.quantiphile.com/2010/11/01/metropolis-hastings/ Matlab implementation of Random-Walk Metropolis]\n* [http://blog.abhranil.net/2014/02/08/r-code-for-multivariate-random-walk-metropolis-hastings-sampling/ R implementation of Random-Walk Metropolis]\n* [http://a2rms.sourceforge.net IA2RMS] is a Matlab code of the ''Independent Doubly Adaptive Rejection Metropolis Sampling'' method for drawing from the full-conditional densities within a Gibbs sampler.\n* [https://github.com/kirill77/SimpleMetropolisCheck unbiased Metropolis sampling] Simple Visual C++ project which showcases numerical integration using Metropolis sampling without burn-in samples and without bias. Uses idea from Ph.D. thesis of Eric Veach \"ROBUST MONTE CARLO METHODS FOR LIGHT TRANSPORT SIMULATION\"\n\n{{DEFAULTSORT:Metropolis-Hastings Algorithm}}\n[[Category:Monte Carlo methods]]\n[[Category:Markov chain Monte Carlo]]\n[[Category:Statistical algorithms]]"
    },
    {
      "title": "Monte Carlo integration",
      "url": "https://en.wikipedia.org/wiki/Monte_Carlo_integration",
      "text": "[[Image:MonteCarloIntegrationCircle.svg|thumb|An illustration of Monte Carlo integration. In this example, the domain ''D'' is the inner circle and the domain E is the square. Because the square's area (4) can be easily calculated, the area of the circle (π*1.0<sup>2</sup>) can be estimated by the ratio (0.8) of the points inside the circle (40) to the total number of points (50), yielding an approximation for the circle's area of 4*0.8 = 3.2 ≈ π.]]\n\nIn [[mathematics]], '''Monte Carlo integration''' is a technique for [[numerical quadrature|numerical integration]] using [[pseudorandomness|random numbers]]. It is a particular [[Monte Carlo method]] that numerically computes a [[definite integral]]. While other algorithms usually evaluate the integrand at a regular grid,<ref>Press et al, 2007, Chap. 4.</ref> Monte Carlo randomly choose points at which the integrand is evaluated.<ref>Press et al, 2007, Chap. 7.</ref> This method is particularly useful for higher-dimensional integrals.<ref name=newman1999ch2/>\n\nThere are different methods to perform a Monte Carlo integration, such as [[Uniform distribution (continuous)|uniform sampling]], [[stratified sampling]], [[importance sampling]], [[Particle filter|sequential Monte Carlo]] (also known as a particle filter), and [[mean field particle methods]].\n\n== Overview ==\nIn numerical integration, methods such as the [[trapezoidal rule]] use a [[Deterministic algorithm|deterministic approach]]. Monte Carlo integration, on the other hand, employs a [[Stochastic|non-deterministic]] approach: each realization provides a different outcome. In Monte Carlo, the final outcome is an approximation of the correct value with respective error bars, and the correct value is likely to be within those error bars.\n\nThe problem Monte Carlo integration addresses is the computation of a [[Multiple integral|multidimensional definite integral]]\n\n:<math>I = \\int_{\\Omega}f(\\overline{\\mathbf{x}}) \\, d\\overline{\\mathbf{x}}</math>\n\nwhere Ω, a subset of '''R'''<sup>''m''</sup>, has volume\n\n:<math>V = \\int_{\\Omega}d\\overline{\\mathbf{x}}</math>\n\nThe naive Monte Carlo approach is to sample points uniformly on Ω:<ref name=newman1999ch1>Newman, 1999, Chap. 1.</ref> given ''N'' uniform samples,\n\n:<math>\\overline{\\mathbf{x}}_1, \\cdots, \\overline{\\mathbf{x}}_N\\in \\Omega,</math>\n\n''I'' can be approximated by\n\n:<math> I \\approx Q_N \\equiv V \\frac{1}{N} \\sum_{i=1}^N f(\\overline{\\mathbf{x}}_i) = V \\langle f\\rangle</math>.\n\nThis is because the [[law of large numbers]] ensures that\n\n:<math> \\lim_{N \\to \\infty} Q_N = I</math>.\n\nGiven the estimation of ''I'' from ''Q<sub>N</sub>'', the error bars of ''Q<sub>N</sub>'' can be estimated by the  [[Sample variance#Population variance and sample variance|sample variance]] using the [[Bias of an estimator#Sample variance|unbiased estimate of the variance]].\n\n:<math> \\mathrm{Var}(f)\\equiv\\sigma_N^2 = \\frac{1}{N-1} \\sum_{i=1}^N \\left (f(\\overline{\\mathbf{x}}_i) - \\langle f \\rangle \\right )^2. </math>\n\nwhich leads to\n\n:<math> \\mathrm{Var}(Q_N) =  \\frac{V^2}{N^2} \\sum_{i=1}^N \\mathrm{Var}(f) = V^2\\frac{\\mathrm{Var}(f)}{N} = V^2\\frac{\\sigma_N^2}{N}</math>.\n\nAs long as the sequence\n\n:<math> \\left \\{ \\sigma_1^2, \\sigma_2^2, \\sigma_3^2, \\ldots \\right \\} </math>\n\nis bounded, this variance decreases asymptotically to zero as 1/''N''. The estimation of the error of ''Q<sub>N</sub>'' is thus\n\n:<math>\\delta Q_N\\approx\\sqrt{\\mathrm{Var}(Q_N)}=V\\frac{\\sigma_N}{\\sqrt{N}},</math>\nwhich decreases as <math>\\tfrac{1}{\\sqrt{N}}</math>. This is [[standard error of the mean]] multiplied with <math>V</math>. \nThis result does not depend on the number of dimensions of the integral, which is the promised advantage of Monte Carlo integration against most deterministic methods that depend exponentially on the dimension.<ref>Press et al, 2007</ref> \nIt is important to notice that, unlike in deterministic methods, the estimate of the error is not a strict error bound; random sampling may not uncover all the important features of the integrand that can result in an underestimate of the error.\n\nWhile the naive Monte Carlo works for simple examples, an improvement over deterministic algorithms only can be accomplished with algorithms that use problem specific sampling distributions.\nWith an appropriate sample distribution it is possible to exploit the fact that almost all higher-dimensional integrands are very localized and only small subspace notably contributes to the integral<ref>{{Cite book|url=http://www.inference.phy.cam.ac.uk/mackay/itila/book.html|title=Information Theory, Inference and Learning Algorithms|last=MacKay|first=David|publisher=Cambridge University Press|year=2003|isbn=978-0-521-64298-9|pages=284&ndash;292|chapter=chapter 4.4 Typicality & chapter 29.1|mr=2012999|ref=mackay2003|authorlink=David MacKay (scientist)|chapterurl=http://www.inference.org.uk/itprnn/book.pdf}}</ref>.\nA large part of the Monte Carlo literature is dedicated in developing strategies to improve the error estimates. In particular, stratified sampling—dividing the region in sub-domains—, and importance sampling—sampling from non-uniform distributions—are two of such techniques.\n\n=== Example ===\n[[File:Relative error of a Monte Carlo integration to calculate pi.svg|thumb|right|350px|Relative error as a function of the number of samples, showing the scaling <math>\\tfrac{1}{\\sqrt{N}}</math>]]\n\nA paradigmatic example of a Monte Carlo integration is the estimation of π. Consider the function\n\n:<math>H\\left(x,y\\right)=\\begin{cases}\n1 & \\text{if }x^{2}+y^{2}\\leq1\\\\\n0 & \\text{else}\n\\end{cases}</math>\n\nand the set Ω = [−1,1] × [−1,1] with ''V'' = 4. Notice that\n\n:<math>I_\\pi = \\int_\\Omega H(x,y) dx dy = \\pi.</math>\n\nThus, a crude way of calculating the value of π with Monte Carlo integration is to pick ''N'' random numbers on Ω and compute\n\n:<math>Q_N = 4 \\frac{1}{N}\\sum_{i=1}^N H(x_{i},y_{i})</math>\n\nIn the figure on the right, the relative error <math>\\tfrac{Q_N-\\pi}{\\pi}</math>  is measured as a function of ''N'', confirming the <math>\\tfrac{1}{\\sqrt{N}}</math>.\n\n=== C example ===\nKeep in mind that a true random number generator should be used.\n<syntaxhighlight lang=\"c\">\nint i, throws = 99999, circleDarts = 0;\nlong double randX, randY, pi;\n\nsrand(time(NULL));\n\nfor (i = 0; i < throws; ++i) {\n  randX = rand() / (double)RAND_MAX;\n  randY = rand() / (double)RAND_MAX;\n  if (1 > ((randX*randX) + (randY*randY))) ++circleDarts;\n}\n\npi = 4 * (circleDarts/throws);\n</syntaxhighlight>\n\n=== Wolfram Mathematica example ===\nThe code below describes a process of integrating the function\n:<math>f(x) = \\frac{1}{1+\\sinh(2x)\\log(x)^2}</math>\nfrom <math>0.8<x<3</math> using the Monte-Carlo method in [[Mathematica]]:\n\n<source lang=\"Mathematica\">\nfunc[x_] := 1/(1 + Sinh[2*x]*(Log[x])^2);\n\n(*Sample from truncated normal distribution to speed up convergence*)\nDistrib[x_, average_, var_] :=   PDF[NormalDistribution[average, var], 1.1*x - 0.1];\nn = 10;\nRV = RandomVariate[TruncatedDistribution[{0.8, 3}, NormalDistribution[1, 0.399]], n];\nInt = 1/n Total[func[RV]/Distrib[RV, 1, 0.399]]*Integrate[Distrib[x, 1, 0.399], {x, 0.8, 3}]\n\nNIntegrate[func[x], {x, 0.8, 3}] (*Compare with real answer*)\n</source>\n\n=== C++ example ===\nBoost.Math (version 1.67 and later) provides a multithreaded Monte-Carlo integration routine.\n<syntaxhighlight lang=\"c++\">\n# include <boost/math/quadrature/naive_monte_carlo.hpp>\n// Define a function to integrate:\nauto g = [](std::vector<double> const & x)\n{\n  constexpr const double A = 1.0 / (M_PI * M_PI * M_PI);\n  return A / (1.0 - cos(x[0])*cos(x[1])*cos(x[2]));\n};\nstd::vector<std::pair<double, double>> bounds{{0, M_PI}, {0, M_PI}, {0, M_PI}};\ndouble error_goal = 0.001;\nnaive_monte_carlo<double, decltype(g)> mc(g, bounds, error_goal);\n\nstd::future<double> task = mc.integrate();\nwhile (task.wait_for(std::chrono::seconds(1)) != std::future_status::ready) {\n    display_progress(mc);\n}\ndouble I = task.get();\n</syntaxhighlight>\n\n== Recursive stratified sampling ==\n[[Image:Strata.png|thumb|right|An illustration of Recursive Stratified Sampling. In this example, the function:\n<math>f(x,y) = \\begin{cases}1 & x^2+y^2<1 \\\\0 & x^2+y^2 \\ge 1 \\end{cases}</math> <br>\nfrom the above illustration was integrated within a unit square using the suggested algorithm. The sampled points were recorded and plotted. Clearly stratified sampling algorithm concentrates the points in the regions where the variation of the function is largest.]]\n\n'''Recursive stratified sampling''' is a generalization of one-dimensional [[adaptive quadrature]]s to multi-dimensional integrals. On each recursion step the integral and the error are estimated using a plain Monte Carlo algorithm. If the error estimate is larger than the required accuracy the integration volume is divided into sub-volumes and the procedure is recursively applied to sub-volumes.\n\nThe ordinary 'dividing by two' strategy does not work for multi-dimensions as the number of sub-volumes grows far too quickly to keep track. Instead one estimates along which dimension a subdivision should bring the most dividends and only subdivides the volume along this dimension.\n\nThe stratified sampling algorithm concentrates the sampling points in the regions where the variance of the function is largest thus reducing the grand variance and making the sampling more effective, as shown on the illustration.\n\nThe popular MISER routine implements a similar algorithm.\n\n=== MISER Monte Carlo ===\nThe MISER algorithm is based on recursive [[stratified sampling]]. This technique aims to reduce the overall integration error by concentrating integration points in the regions of highest variance.<ref>Press, 1990, pp 190-195.</ref>\n\nThe idea of stratified sampling begins with the observation that for two [[Disjoint sets|disjoint]] regions ''a'' and ''b'' with Monte Carlo estimates of the integral <math>E_a(f)</math> and <math>E_b(f)</math> and variances <math>\\sigma_a^2(f)</math> and <math>\\sigma_b^2(f)</math>, the variance Var(''f'') of the combined estimate\n:<math>E(f) = \\tfrac{1}{2} \\left (E_a(f) + E_b(f) \\right )</math>\nis given by,\n\n:<math>\\mathrm{Var}(f) = \\frac{\\sigma_a^2(f)}{4 N_a} + \\frac{\\sigma_b^2(f)}{4 N_b}</math>\n\nIt can be shown that this variance is minimized by distributing the points such that,\n\n:<math>\\frac{N_a}{N_a + N_b} = \\frac{\\sigma_a}{\\sigma_a + \\sigma_b}</math>\n\nHence the smallest error estimate is obtained by allocating sample points in proportion to the standard deviation of the function in each sub-region.\n\nThe MISER algorithm proceeds by bisecting the integration region along one coordinate axis to give two sub-regions at each step. The direction is chosen by examining all ''d'' possible bisections and selecting the one which will minimize the combined variance of the two sub-regions. The variance in the sub-regions is estimated by sampling with a fraction of the total number of points available to the current step. The same procedure is then repeated recursively for each of the two half-spaces from the best bisection. The remaining sample points are allocated to the sub-regions using the formula for ''N<sub>a</sub>'' and ''N<sub>b</sub>''. This recursive allocation of integration points continues down to a user-specified depth where each sub-region is integrated using a plain Monte Carlo estimate. These individual values and their error estimates are then combined upwards to give an overall result and an estimate of its error.\n\n== Importance sampling ==\n{{Main|Importance sampling}}\n\n=== VEGAS Monte Carlo ===\n{{Main|VEGAS algorithm}}\n\nThe VEGAS algorithm takes advantage of the information stored during the sampling, and uses it and importance sampling to efficiently estimate the integral ''I''. It samples points from the probability distribution described by the function |''f''| so that the points are concentrated in the regions that make the largest contribution to the integral.\n\nIn general, if the Monte Carlo integral of ''f'' is sampled with points distributed according to a probability distribution described by the function ''g'', we obtain an estimate:\n\n:<math>E_g(f; N) = E \\left (\\tfrac{f}{g}; N \\right )</math>\n\nwith a corresponding variance,\n\n:<math>\\mathrm{Var}_g(f; N) = \\mathrm{Var} \\left (\\tfrac{f}{g}; N \\right )</math>\n\nIf the probability distribution is chosen as\n\n:<math>g = \\tfrac{|f|}{I(|f|)}</math>\n\nthen it can be shown that the variance <math>V_g(f; N)</math> vanishes, and the error in the estimate will be zero. {{Citation needed|date=August 2017}} In practice it is not possible to sample from the exact distribution ''g'' for an arbitrary function, so importance sampling algorithms aim to produce efficient approximations to the desired distribution.\n\nThe VEGAS algorithm approximates the exact distribution by making a number of passes over the integration region which creates the histogram of the function ''f''. Each histogram is used to define a sampling distribution for the next pass. Asymptotically this procedure converges to the desired distribution.<ref name=\"Lepage, 1978\">Lepage, 1978</ref> In order to avoid the number of histogram bins growing like ''K<sup>d</sup>'', the probability distribution is approximated by a separable function:\n\n:<math>g(x_1, x_2, \\ldots) = g_1(x_1) g_2(x_2) \\ldots </math>\n\nso that the number of bins required is only ''Kd''. This is equivalent to locating the peaks of the function from the projections of the integrand onto the coordinate axes. The efficiency of VEGAS depends on the validity of this assumption. It is most efficient when the peaks of the integrand are well-localized. If an integrand can be rewritten in a form which is approximately separable this will increase the efficiency of integration with VEGAS.\n\nVEGAS incorporates a number of additional features, and combines both stratified sampling and importance sampling.<ref name=\"Lepage, 1978\"/> The integration region is divided into a number of \"boxes\", with each box getting a fixed number of points (the goal is 2). Each box can then have a fractional number of bins, but if bins/box is less than two, Vegas switches to a kind variance reduction (rather than importance sampling).\n\nThis routines uses the VEGAS Monte Carlo algorithm to integrate the function ''f'' over the ''dim''-dimensional hypercubic region defined by the lower and upper limits in the arrays ''xl'' and ''xu'', each of size ''dim''. The integration uses a fixed number of function calls. The result and its error estimate are based on a weighted average of independent samples.\n\nThe VEGAS algorithm computes a number of independent estimates of the integral internally, according to the iterations parameter described below, and returns their weighted average. Random sampling of the integrand can occasionally produce an estimate where the error is zero, particularly if the function is constant in some regions. An estimate with zero error causes the weighted average to break down and must be handled separately.\n\n=== Importance sampling algorithm ===\n\nImportance sampling provides a very important tool to perform Monte-Carlo integration.<ref name=newman1999ch2>Newman, 1999, Chap. 2.</ref><ref name=\"kr11\">{{cite book|last1 = Kroese|first1 = D. P.|last2 = Taimre|first2 = T.|last3 = Botev|first3 = Z. I. |title = Handbook of Monte Carlo Methods|year = 2011|publisher = John Wiley & Sons}}</ref> The main result of importance sampling to this method is that the uniform sampling of <math>\\overline{\\mathbf{x}}</math> is a particular case of a more generic choice, on which the samples are drawn from any distribution <math>p(\\overline{\\mathbf{x}})</math>. The idea is that <math>p(\\overline{\\mathbf{x}})</math> can be chosen to decrease the variance of the measurement ''Q<sub>N</sub>''.\n\nConsider the following example where one would like to numerically integrate a gaussian function, centered at 0, with σ = 1, from −1000 to 1000. Naturally, if the samples are drawn uniformly on the interval [−1000, 1000], only a very small part of them would be significant to the integral. This can be improved by choosing a different distribution from where the samples are chosen, for instance by sampling according to a gaussian distribution centered at 0, with σ = 1. Of course the \"right\" choice strongly depends on the integrand.\n\nFormally, given a set of samples chosen from a distribution\n:<math>p(\\overline{\\mathbf{x}}) : \\qquad \\overline{\\mathbf{x}}_1, \\cdots, \\overline{\\mathbf{x}}_N \\in V, </math>\nthe estimator for ''I'' is given by<ref name=newman1999ch2/>\n\n:<math> Q_N \\equiv \\frac{1}{N} \\sum_{i=1}^N \\frac{f(\\overline{\\mathbf{x}}_i)}{p(\\overline{\\mathbf{x}}_i)}</math>\n\nIntuitively, this says that if we pick a particular sample twice as much as other samples, we weight it half as much as the other samples. This estimator is naturally valid for uniform sampling, the case where <math>p(\\overline{\\mathbf{x}})</math> is constant.\n\nThe [[Metropolis-Hastings algorithm]] is one of the most used algorithms to generate <math>\\overline{\\mathbf{x}}</math> from <math>p(\\overline{\\mathbf{x}})</math>,<ref name=newman1999ch2/> thus providing an efficient way of computing integrals.\n\n=== Multiple and adaptive importance sampling ===\nWhen different proposal distributions, <math>p_n(\\overline{\\mathbf{x}})</math> , <math>n=1,\\ldots,N,</math> are jointly used for drawing the samples <math>\\overline{\\mathbf{x}}_1, \\cdots, \\overline{\\mathbf{x}}_N \\in V, </math> different proper weighting functions can be employed (e.g., see <ref>{{Cite book|title = Optimally Combining Sampling Techniques for Monte Carlo Rendering10.1145/218380.218498|journal = Proceedings of the 22Nd Annual Conference on Computer Graphics and Interactive Techniques|date = 1995-01-01|location = New York, NY, USA|isbn = 978-0-89791-701-8|pages = 419–428|series = SIGGRAPH '95|doi = 10.1145/218380.218498|first = Eric|last = Veach|first2 = Leonidas J.|last2 = Guibas|url = http://www.cs.rpi.edu/~cutler/classes/advancedgraphics/S07/lectures/veach_95.pdf|citeseerx = 10.1.1.127.8105}}</ref><ref>{{Cite journal|title = Safe and Effective Importance Sampling|journal = Journal of the American Statistical Association|date = 2000-03-01|issn = 0162-1459|pages = 135–143|volume = 95|issue = 449|doi = 10.1080/01621459.2000.10473909|first = Art|last = Owen|first2 = Yi Zhou|last2 = Associate|citeseerx = 10.1.1.36.4536}}</ref><ref>{{Cite journal|title = Efficient Multiple Importance Sampling Estimators|journal = IEEE Signal Processing Letters|date = 2015-10-01|issn = 1070-9908|pages = 1757–1761|volume = 22|issue = 10|doi = 10.1109/LSP.2015.2432078|first = V.|last = Elvira|first2 = L.|last2 = Martino|first3 = D.|last3 = Luengo|first4 = M.F.|last4 = Bugallo|arxiv = 1505.05391|bibcode = 2015ISPL...22.1757E}}</ref>). In an adaptive setting, the proposal distributions, <math>p_{n,t}(\\overline{\\mathbf{x}})</math> , <math>n=1,\\ldots,N,</math> and <math>t=1,\\ldots,T,</math> are updated each iteration <math>t</math> of the adaptive importance sampling algorithm. Hence, since a population of proposal densities is used, several suitable combinations of sampling and weighting schemes can be employed.<ref>{{Cite journal|title = Population Monte Carlo|journal = Journal of Computational and Graphical Statistics|date = 2004-12-01|issn = 1061-8600|pages = 907–929|volume = 13|issue = 4|doi = 10.1198/106186004X12803|first = O.|last = Cappé|first2 = A.|last2 = Guillin|first3 = J. M.|last3 = Marin|first4 = C. P.|last4 = Robert}}</ref><ref>{{Cite journal|title = Adaptive importance sampling in general mixture classes|journal = Statistics and Computing|date = 2008-04-25|issn = 0960-3174|pages = 447–459|volume = 18|issue = 4|doi = 10.1007/s11222-008-9059-x|first = Olivier|last = Cappé|first2 = Randal|last2 = Douc|first3 = Arnaud|last3 = Guillin|first4 = Jean-Michel|last4 = Marin|first5 = Christian P.|last5 = Robert|arxiv = 0710.4242}}</ref><ref>{{Cite journal|title = Adaptive Multiple Importance Sampling|journal = Scandinavian Journal of Statistics|date = 2012-12-01|issn = 1467-9469|pages = 798–812|volume = 39|issue = 4|doi = 10.1111/j.1467-9469.2011.00756.x|first = Jean-Marie|last = Cornuet|first2 = Jean-Michel|last2 = Marin|first3 = Antonietta|last3 = Mira|first4 = Christian P.|last4 = Robert|arxiv = 0907.1254}}</ref><ref>{{Cite journal|title = An Adaptive Population Importance Sampler: Learning From Uncertainty|journal = IEEE Transactions on Signal Processing|date = 2015-08-01|issn = 1053-587X|pages = 4422–4437|volume = 63|issue = 16|doi = 10.1109/TSP.2015.2440215|first = L.|last = Martino|first2 = V.|last2 = Elvira|first3 = D.|last3 = Luengo|first4 = J.|last4 = Corander|bibcode = 2015ITSP...63.4422M|citeseerx = 10.1.1.464.9395}}</ref><ref>{{Cite journal|title = Adaptive importance sampling in signal processing|journal = Digital Signal Processing|date = 2015-12-01|pages = 36–49|volume = 47|series = Special Issue in Honour of William J. (Bill) Fitzgerald|doi = 10.1016/j.dsp.2015.05.014|first = Mónica F.|last = Bugallo|first2 = Luca|last2 = Martino|first3 = Jukka|last3 = Corander}}</ref>\n\n== See also ==\n* [[Auxiliary field Monte Carlo]]\n* [[Monte Carlo method in statistical physics]]\n* [[Monte Carlo method]]\n* [[Variance reduction]]\n\n== Notes ==\n{{reflist|30em}}\n\n== References ==\n* {{cite journal |first=R. E. |last=Caflisch |authorlink=Russel E. Caflisch |title=Monte Carlo and quasi-Monte Carlo methods |journal=[[Acta Numerica]] |volume=7 |year=1998 |pages=1–49 |doi=10.1017/S0962492900002804 |bibcode=1998AcNum...7....1C }}\n* {{cite arxiv |first=S. |last=Weinzierl |title=Introduction to Monte Carlo methods |eprint=hep-ph/0006269 |year=2000}}\n* {{cite journal |first=W. H. |last=Press |first2=G. R. |last2=Farrar |title=Recursive Stratified Sampling for Multidimensional Monte Carlo Integration |journal=Computers in Physics |volume=4 |issue=2 |pages=190 |year=1990 |doi=10.1063/1.4822899 |bibcode=1990ComPh...4..190P }}\n* {{cite journal |first=G. P. |last=Lepage |title=A New Algorithm for Adaptive Multidimensional Integration |journal=[[Journal of Computational Physics]] |volume=27 |issue=2 |pages=192–203 |year=1978 |doi=10.1016/0021-9991(78)90004-9 |bibcode=1978JCoPh..27..192L }}\n* {{cite journal |first=G. P. |last=Lepage |title=VEGAS: An Adaptive Multi-dimensional Integration Program |journal=Cornell Preprint CLNS 80-447 |year=1980 }}\n* {{cite book |first=J. M. |last=Hammersley |first2=D. C. |last2=Handscomb |year=1964 |title=Monte Carlo Methods |location= |publisher=Methuen |isbn=978-0-416-52340-9 }}\n* {{Cite book | last1=Press | first1=WH | last2=Teukolsky | first2=SA | last3=Vetterling | first3=WT | last4=Flannery | first4=BP | year=2007 | title=Numerical Recipes: The Art of Scientific Computing | edition=3rd | publisher=Cambridge University Press |  location=New York | isbn=978-0-521-88068-8}}\n* {{Cite book | last1=Newman | first1=MEJ | last2=Barkema | first2=GT | year=1999 | title=Monte Carlo Methods in Statistical Physics | publisher=Clarendon Press}}\n* {{Cite book | last1=Robert | first1=CP | last2=Casella | first2=G | year=2004 | title=Monte Carlo Statistical Methods | publisher=Springer | edition=2nd | isbn=978-1-4419-1939-7}}\n\n== External links ==\n* [http://www.cafemath.fr/mathblog/article.php?page=MonteCarlo.php Café math : Monte Carlo Integration] : A blog article describing Monte Carlo integration (principle, hypothesis, confidence interval)\n* [http://www.boost.org/doc/libs/release/libs/math/doc/html/math_toolkit/naive_monte_carlo.html Boost.Math : Naive Monte Carlo integration: Documentation for the C++ naive Monte-Carlo routines]\n* [https://sites.google.com/view/chremos-group/applets/monte-carlo: Monte Carlo applet applied in statistical physics problems] \n\n[[Category:Monte Carlo methods]]\n[[Category:Articles with example code]]"
    },
    {
      "title": "Monte Carlo localization",
      "url": "https://en.wikipedia.org/wiki/Monte_Carlo_localization",
      "text": "[[File:Corridorbot localization.svg|thumb|right|A robot in a one-dimensional corridor containing doors. The goal of Monte Carlo localization is to let a robot determine its position based on its sensor observations.]]\n\n'''Monte Carlo localization (MCL)''', also known as '''particle filter localization''',<ref name=\"Rekleitis\">Ioannis M. Rekleitis. \"A Particle Filter Tutorial for Mobile Robot Localization.\" ''Centre for Intelligent Machines, McGill University, Tech. Rep. TR-CIM-04-02'' (2004).</ref> is an algorithm for robots to [[robot localization|localize]] using a [[particle filter]].<ref name=\"icra1999\">\n[[Frank Dellaert]], Dieter Fox, [[Wolfram Burgard]], [[Sebastian Thrun]]. \"[http://www.ri.cmu.edu/pubs/pub_533.html Monte Carlo Localization for Mobile Robots] {{webarchive|url=https://web.archive.org/web/20070917170430/http://www.ri.cmu.edu/pubs/pub_533.html |date=2007-09-17 }}.\" ''Proc. of the IEEE International Conference on Robotics and Automation'' Vol. 2. IEEE, 1999.</ref><ref name=\"aaai1999\">\nDieter Fox, Wolfram Burgard, Frank Dellaert, and Sebastian Thrun, \"[http://www.cs.washington.edu/ai/Mobile_Robotics/abstracts/sampling-aaai-99.abstract.html Monte Carlo Localization: Efficient Position Estimation for Mobile Robots].\" ''Proc. of the Sixteenth National Conference on Artificial Intelligence'' John Wiley & Sons Ltd, 1999.</ref><ref name=\"pr\">\nSebastian Thrun, Wolfram Burgard, Dieter Fox. [http://www.probabilistic-robotics.org/ ''Probabilistic Robotics''] MIT Press, 2005. Ch. 8.3 {{ISBN|9780262201629}}.</ref><ref name=\"robust\">Sebastian Thrun, Dieter Fox, Wolfram Burgard, Frank Dellaert. \"[http://robots.stanford.edu/papers/thrun.robust-mcl.html Robust monte carlo localization for mobile robots].\" ''Artificial Intelligence'' 128.1 (2001): 99–141.\n</ref> Given a map of the environment, the algorithm estimates the [[pose (computer vision)|position and orientation]] of a robot as it moves and senses the environment.<ref name=\"pr\" /> The algorithm uses a [[particle filter]] to represent the [[probability density function|distribution]] of likely states, with each particle representing a possible state, i.e., a hypothesis of where the robot is.<ref name=\"pr\" /> The algorithm typically starts with a uniform random distribution of particles over the [[Configuration space (physics)|configuration space]], meaning the robot has no information about where it is and assumes it is equally likely to be at any point in space.<ref name=\"pr\" /> Whenever the robot moves, it shifts the particles to predict its new state after the movement. Whenever the robot senses something, the particles are resampled based on [[recursive Bayesian estimation]], i.e., how well the actual sensed data correlate with the predicted state. Ultimately, the particles should converge towards the actual position of the robot.<ref name=\"pr\" />\n\n==Basic description==\nConsider a robot with an internal map of its environment. When the robot moves around, it needs to know where it is within this map. Determining its location and rotation (more generally, the [[pose (computer vision)|pose]]) by using its sensor observations is known as [[robot localization]]. \n\nBecause the robot may not always behave in a perfectly predictable way, it generates many random guesses of where it is going to be next. These guesses are known as particles. Each particle contains a full description of a possible future state. When the robot observes the environment, it discards particles inconsistent with this observation, and generates more particles close to those that appear consistent. In the end, hopefully most particles converge to where the robot actually is.\n\n==State representation==\nThe state of the robot depends on the application and design. For example, the state of a typical 2D robot may consist of a tuple <math>(x, y, \\theta)</math> for position <math>x, y</math> and orientation <math>\\theta</math>. For a robotic arm with 10 joints, it may be a tuple containing the angle at each joint: <math>(\\theta_1, \\theta_2, ..., \\theta_{10})</math>.\n\nThe ''belief'', which is the robot's estimate of its current state, is a [[probability density function]] distributed over the state space.<ref name=\"Rekleitis\" /><ref name=\"pr\" /> In the MCL algorithm, the belief at a time <math>t</math> is represented by a set of <math>M</math> [[Particle filter|particles]] <math>X_t = \\lbrace x_t^{[1]}, x_t^{[2]}, \\ldots , x_t^{[M]} \\rbrace</math>.<ref name=\"pr\" /> Each particle contains a state, and can thus be considered a hypothesis of the robot's state. Regions in the state space with many particles correspond to a greater probability that the robot will be there—and regions with few particles are unlikely to be where the robot is.\n\nThe algorithm assumes the [[Markov property]] that the current state's probability distribution depends only on the previous state (and not any ones before that), i.e., <math>X_t</math> depends ''only'' on <math>X_{t-1}</math>.<ref name=\"pr\" /> This only works if the environment is static and [[Time-invariant system|does not change with time]].<ref name=\"pr\" /> Typically, on start up, the robot has no information on its current pose so the particles are uniformly distributed over the [[Configuration space (physics)|configuration space]].<ref name=\"pr\" />\n\n==Overview==\nGiven a map of the environment, the goal of the algorithm is for the robot to determine its [[Pose (computer vision)|pose]] within the environment.\n\nAt every time <math>t</math> the algorithm takes as input the previous belief <math>X_{t-1} = \\lbrace x_{t-1}^{[1]}, x_{t-1}^{[2]}, \\ldots, x_{t-1}^{[M]} \\rbrace</math>, an actuation command <math>u_t</math>, and data received from sensors <math>z_t</math>; and the algorithm outputs the new belief <math>X_t</math>.<ref name=\"pr\" />\n\n    '''Algorithm MCL'''<math>(X_{t-1}, u_t, z_t)</math>:\n        <math>\\bar{X_t} = X_t = \\emptyset</math>\n        for <math>m = 1</math> to <math>M</math>:\n            <math>x_t^{[m]} = </math> '''motion_update'''<math>(u_t, x_{t-1}^{[m]})</math>\n            <math>w_t^{[m]} = </math> '''sensor_update'''<math>(z_t, x_t^{[m]})</math>\n            <math>\\bar{X_t} = \\bar{X_t} + \\langle x_t^{[m]}, w_t^{[m]} \\rangle</math>\n        endfor\n        for <math>m = 1</math> to <math>M</math>:\n            draw <math>x_t^{[m]}</math> from <math>\\bar{X_t}</math> with probability <math>\\propto w_t^{[m]}</math>\n            <math>X_t = X_t + x_t^{[m]}</math>\n        endfor\n        return <math>X_t</math>\n\n===Example for 1D robot===\n{{multiple image\n| footer    = A robot travels along a one-dimensional corridor, armed with a sensor that can only tell if there is a door (left) or there is no door (right).\n| width     = 120\n\n| image1    = Corridorbot door.png\n| alt1      = Robot detects a door.\n\n| image2    = Corridorbot wall.png\n| alt2      = Robot detects a wall.\n}}\nConsider a robot in a one-dimensional [[periodic boundary conditions|circular]] corridor with three identical doors, using a sensor that returns [[Boolean value|either true or false]] depending on whether there is a door.\n\n{|style=\"border:1px #AAAAAA solid;\"\n! colspan=3 style=\"background-color:#F2F2F2;\"|<math>t=0</math>\n|-\n|[[File:Mcl t 0 1.svg|thumb|320px|center|The algorithm initializes with a uniform distribution of particles. The robot considers itself equally likely to be at any point in space along the corridor, even though it is physically at the first door.]]\n|[[File:Mcl t 0 2.svg|thumb|320px|center|'''Sensor update''': the robot detects '''a door'''. It assigns a weight to each of the particles. The particles which are likely to give this sensor reading receive a higher weight.]]\n|[[File:Mcl t 0 3.svg|thumb|320px|center|'''Resampling''': the robot generates a set of new particles, with most of them generated around the previous particles with more weight. It now believes it is at one of the three doors.]]\n|}\n\n<br>\n{|style=\"border:1px #AAAAAA solid;\"\n! colspan=3 style=\"background-color:#F2F2F2;\"|<math>t=1</math>\n|-\n|[[File:Mcl t 1 1.svg|thumb|320px|center|'''Motion update''': the robot moves some distance to the right. All particles also move right, and some noise is applied. The robot is physically between the second and third doors.]]\n|[[File:Mcl t 1 2.svg|thumb|320px|center|'''Sensor update''': the robot detects '''no door'''. It assigns a weight to each of the particles. The particles likely to give this sensor reading receive a higher weight.]]\n|[[File:Mcl t 1 3.svg|thumb|320px|center|'''Resampling''': the robot generates a set of new particles, with most of them generated around the previous particles with more weight. It now believes it is at one of two locations.]]\n|}\n\n<br>\n{|style=\"border:1px #AAAAAA solid;\"\n! colspan=3 style=\"background-color:#F2F2F2;\"|<math>t=2</math>\n|-\n|[[File:Mcl t 2 1.svg|thumb|320px|center|'''Motion update''': the robot moves some distance to the left. All particles also move left, and some noise is applied. The robot is physically at the second door.]]\n|[[File:Mcl t 2 2.svg|thumb|320px|center|'''Sensor update''': the robot detects '''a door'''. It assigns a weight to each of the particles. The particles likely to give this sensor reading receive a higher weight.]]\n|[[File:Mcl t 2 3.svg|thumb|320px|center|'''Resampling''': the robot generates a set of new particles, with most of them generated around the previous particles with more weight. The robot has successfully localized itself.]]\n|}\nAt the end of the three iterations, most of the particles are converged on the actual position of the robot as desired.\n\n==Motion update==\n[[File:Particle2dmotion.svg|thumb|right|Belief after moving several steps for a 2D robot [[dead reckoning|using a typical motion model without sensing]].]]\nDuring the motion update, the robot predicts its new location based on the actuation command given, by applying the simulated motion to each of the particles.<ref name=\"Rekleitis\" /> For example, if a robot moves forward, all particles move forward in their own directions no matter which way they point. If a robot rotates 90 degrees clockwise, all particles rotate 90 degrees clockwise, regardless of where they are. However, in the real world, no actuator is perfect: they may overshoot or undershoot the desired amount of motion. When a robot tries to drive in a straight line, it inevitably curves to one side or the other due to minute differences in wheel radius.<ref name=\"Rekleitis\" /> Hence, the motion model must compensate for noise. Inevitably, the particles diverge during the motion update as a consequence. This is expected since a robot becomes less sure of its position if it moves blindly without sensing the environment.\n\n==Sensor update==\nWhen the robot senses its environment, it updates its particles to more accurately reflect where it is. For each particle, the robot computes the probability that, had it been at the state of the particle, it would perceive what its sensors have actually sensed. It assigns a weight <math>w_t^{[i]}</math> for each particle proportional to the said probability. Then, it randomly draws <math>M</math> new particles from the previous belief, with probability proportional to <math>w_t^{[i]}</math>. Particles consistent with sensor readings are more likely to be chosen (possibly more than once) and particles inconsistent with sensor readings are rarely picked. As such, particles converge towards a better estimate of the robot's state. This is expected since a robot becomes increasingly sure of its position as it senses its environment.\n\n==Properties==\n\n=== Non-parametricity ===\nThe [[particle filter]] central to MCL can approximate multiple different kinds of [[probability distributions]], since it is a [[Non-parametric statistics|non-parametric representation]].<ref name=\"pr\" /> Some other Bayesian localization algorithms, such as the [[Kalman filter]] (and variants, the [[extended Kalman filter]] and the [[unscented Kalman filter]]), assume the belief of the robot is close to being a [[Normal distribution|Gaussian distribution]] and do not perform well for situations where the belief is [[Multimodal distribution|multimodal]].<ref name=\"pr\" /> For example, a robot in a long corridor with many similar-looking doors may arrive at a belief that has a peak for each door, but the robot is unable to distinguish ''which'' door it is at. In such situations, the particle filter can give better performance than parametric filters.<ref name=\"pr\" />\n\nAnother non-parametric approach to Markov localization is the grid-based localization, which uses a [[histogram]] to represent the belief distribution. Compared with the grid-based approach, the Monte Carlo localization is more accurate because the state represented in samples is not discretized.<ref name=\"icra1999\"/>\n\n=== Computational requirements ===\nThe particle filter's [[time complexity]] is [[linear time|linear]] with respect to the number of particles. Naturally, the more particles, the better the accuracy, so there is a compromise between speed and accuracy and it is desired to find an optimal value of <math>M</math>. One strategy to select <math>M</math> is to continuously generate additional particles until the next pair of command <math>u_t</math> and sensor reading <math>z_t</math> has arrived.<ref name=\"pr\" /> This way, the greatest possible number of particles is obtained while not impeding the function of the rest of the robot. As such, the implementation is adaptive to available computational resources: the faster the processor, the more particles can be generated and therefore the more accurate the algorithm is.<ref name=\"pr\" />\n\nCompared to grid-based Markov localization, Monte Carlo localization has reduced memory usage since memory usage only depends on number of particles and does not scale with size of the map,<ref name=\"icra1999\" /> and can integrate measurements at a much higher frequency.<ref name=\"icra1999\"/>\n\nThe algorithm can be improved using [[#KLD sampling|KLD sampling]], as described below, which adapts the number of particles to use based on how sure the robot is of its position.\n\n=== Particle deprivation ===\nA drawback of the naive implementation of Monte Carlo localization occurs in a scenario where a robot sits at one spot and repeatedly senses the environment without moving.<ref name=\"pr\" /> Suppose that the particles all converge towards an erroneous state, or if [[kidnapped robot problem|an occult hand picks up the robot and moves it to a new location]] after particles have already converged. As particles far away from the converged state are rarely selected for the next iteration, they become scarcer on each iteration until they disappear altogether. At this point, the algorithm is unable to recover.<ref name=\"pr\" /> This problem is more likely to occur for small number of particles, e.g., <math>M \\leq 50</math>, and when the particles are spread over a large state space.<ref name=\"pr\" /> In fact, any [[particle filter]] algorithm may accidentally discard all particles near the correct state during the resampling step.<ref name=\"pr\" />\n\nOne way to mitigate this issue is to randomly add extra particles on every iteration.<ref name=\"pr\" /> This is equivalent to assuming that, at any point in time, the robot has some small probability of being [[kidnapped robot problem|kidnapped]] to a random position in the map, thus causing a fraction of random states in the motion model.<ref name=\"pr\" /> By guaranteeing that no area in the map is totally deprived of particles, the algorithm is now robust against particle deprivation.\n\n== Variants ==\n\nThe original Monte Carlo localization algorithm is fairly simple. Several variants of the algorithm have been proposed, which address its shortcomings or adapt it to be more effective in certain situations.\n\n=== KLD sampling ===\n\nMonte Carlo localization may be improved by sampling the particles in an adaptive manner based on an error estimate using the [[Kullback–Leibler divergence]] (KLD). Initially, it is necessary to use a large <math>M</math> due to the need to cover the entire map with a uniformly random distribution of particles. However, when the particles have converged around the same location, maintaining such a large sample size is computationally wasteful. <ref name=\"kldpaper\">Dieter Fox. \"KLD–Sampling: Adaptive Particle Filters.\" ''Department of Computer Science and Engineering, University of Washington.'' NIPS, 2001.</ref>\n\nKLD–sampling is a variant of Monte Carlo Localization where at each iteration, a sample size <math>M_x</math> is calculated. The sample size <math>M_x</math> is calculated such that, with probability <math>1-\\delta</math>, the error between the true posterior and the sample-based approximation is less than <math>\\epsilon</math>. The variables <math>\\delta</math> and <math>\\epsilon</math> are fixed parameters.<ref name=\"pr\" />\n\nThe main idea is to create a grid (a histogram) overlaid on the state space. Each bin in the histogram is initially empty. At each iteration, a new particle is drawn from the previous (weighted) particle set with probability proportional to its weight. Instead of the resampling done in classic MCL, the KLD–sampling algorithm draws particles from the previous, weighted, particle set and applies the motion and sensor updates before placing the particle into its bin. The algorithm keeps track of the number of non-empty bins, <math>k</math>. If a particle is inserted in a previously empty bin, the value of <math>M_x</math> is recalculated, which increases mostly linear in <math>k</math>. This is repeated until the sample size <math>M</math> is the same as <math>M_x</math>. <ref name=\"pr\" />\n\nIt is easy to see KLD–sampling culls redundant particles from the particle set, by only increasing <math>M_x</math> when a new location (bin) has been filled. In practice, KLD–sampling consistently outperforms and converges faster than classic MCL.<ref name=\"pr\" />\n\n== References ==\n{{reflist}}\n\n[[Category:Robot navigation]]\n[[Category:Monte Carlo methods]]"
    },
    {
      "title": "Monte Carlo method for photon transport",
      "url": "https://en.wikipedia.org/wiki/Monte_Carlo_method_for_photon_transport",
      "text": "Modeling photon propagation with [[Monte Carlo method]]s is a flexible yet rigorous approach to simulate photon transport. In the method, local rules of photon transport are expressed as probability distributions which describe the step size of photon movement between sites of photon-tissue interaction and the angles of deflection in a photon's trajectory when a scattering event occurs.  This is equivalent to modeling photon transport analytically by the [[Radiative transfer equation and diffusion theory for photon transport in biological tissue|radiative transfer equation]] (RTE), which describes the motion of photons using a differential equation.  However, closed-form solutions of the RTE are often not possible; for some geometries, the [[Radiative transfer equation and diffusion theory for photon transport in biological tissue|diffusion approximation]] can be used to simplify the RTE, although this, in turn, introduces many inaccuracies, especially near sources and boundaries.  In contrast, Monte Carlo simulations can be made arbitrarily accurate by increasing the number of photons traced.  For example, see the movie, where a Monte Carlo simulation of a [[pencil beam]] incident on a [[semi-infinite]] medium models both the initial ballistic photon flow and the later diffuse propagation.\n\nThe Monte Carlo method is necessarily statistical and therefore requires significant computation time to achieve precision.  In addition Monte Carlo simulations can keep track of multiple physical quantities simultaneously, with any desired spatial and temporal resolution.  This flexibility makes Monte Carlo modeling a powerful tool.  Thus, while computationally inefficient, Monte Carlo methods are often considered the standard for simulated measurements of photon transport for many biomedical applications. [[Image:MonteCarloSemiInf.gif|thumb|right|Monte Carlo simulation of a pencil beam incident on a semi-infinite scattering medium.]]\n\n==Biomedical applications of Monte Carlo methods==\n\n===Biomedical imaging===\nThe optical properties of biological tissue offer an exciting approach to biomedical imaging.  There are many interesting endogenous contrasts, including absorption from blood and melanin and scattering from nerve cells and cancer cell nuclei.  In addition, fluorescent probes can be targeted to many different tissues.  Microscopy techniques (including [[Confocal microscopy|confocal]], [[Two-photon excitation microscopy|two-photon]], and [[optical coherence tomography]]) have the ability to image these properties with high spatial resolution, but, since they rely on ballistic photons, their depth penetration is limited to a few millimeters.  Imaging deeper into tissues, where photons have been multiply scattered, requires a deeper understanding of the statistical behavior of large numbers of photons in such an environment.  Monte Carlo methods provide a flexible framework that has been used by different techniques to reconstruct optical properties deep within tissue.  A brief introduction to a few of these techniques is presented here.\n*[[Photoacoustic imaging in biomedicine|Photoacoustic tomography]] In PAT, diffuse laser light is absorbed which generates a local temperature rise.  This local temperature variation in turn generates ultrasound waves via thermoelastic expansion which are detected via an ultrasonic transducer.  In practice, a variety of setup parameters are varied (i.e. light wavelength, transducer numerical aperture) and as a result Monte Carlo modeling is a valuable tool for predicting tissue response prior to experimental methods.\n*[[Diffuse optical imaging|Diffuse optical tomography]] DOT is an imaging technique that uses an array of near-infrared light sources and detectors to measure optical properties of biological tissues.  A variety of contrasts can be measured including the absorption due to oxy- and deoxy-hemoglobin (for functional neuro-imaging or cancer detection) and the concentration of fluorescent probes.  In order to reconstruct an image, one must know the manner in which light traveled from a given source to a given detector and how the measurement depends on the distribution and changes in the optical properties (known as the forward model).  Due to the highly scattering nature of biological tissue, such paths are complicated and the sensitivity functions are diffuse.  The forward model is often generated using Monte Carlo methods.\n\n===Radiation therapy===\nThe goal of [[radiation therapy]] is to deliver energy, generally in the form of ionizing radiation, to cancerous tissue while sparing the surrounding normal tissue. Monte Carlo modeling is commonly employed in radiation therapy to determine the peripheral dose the patient will experience due to scattering, both from the patient tissue as well as scattering from collimation upstream in the linear accelerator.\n\n===Photodynamic therapy===\nIn [[Photodynamic therapy]] (PDT) light is used to activate chemotherapy agents.  Due to the nature of PDT, it is useful to use Monte Carlo methods for modeling scattering and absorption in the tissue in order to ensure appropriate levels of light are delivered to activate chemotherapy agents.\n\n==Implementation of photon transport in a scattering medium==\nPresented here is a model of a photon Monte Carlo method in a homogeneous infinite medium. The model is easily extended for multi-layered media, however.  For an inhomogeneous medium, boundaries must be considered.  In addition for a semi-infinite medium (in which photons are considered lost if they exit the top boundary), special consideration must be taken. For more information, please visit the links at the bottom of the page.  We will solve the problem using an infinitely small point source (represented analytically as a [[Dirac delta function]] in space and time).  Responses to arbitrary source geometries can be constructed using the method of [[Green's functions]] (or [[convolution]], if enough spatial symmetry exists).  The required parameters are the [[absorption coefficient]], the scattering coefficient, and the scattering phase function.  (If boundaries are considered the index of refraction for each medium must also be provided.)  Time-resolved responses are found by keeping track of the total elapsed time of the photon's flight using the [[optical path length]].  Responses to sources with arbitrary time profiles can then be modeled through convolution in time.\n\nIn our simplified model we use the following variance reduction technique to reduce computational time.  Instead of propagating photons individually, we create a photon packet with a specific weight (generally initialized as unity).  As the photon interacts in the turbid medium, it will deposit weight due to absorption and the remaining weight will be scattered to other parts of the medium.  Any number of variables can be logged along the way, depending on the interest of a particular application.  Each photon packet will repeatedly undergo the following numbered steps until it is either terminated, reflected, or transmitted.  The process is diagrammed in the schematic to the right.  Any number of photon packets can be launched and modeled, until the resulting simulated measurements have the desired signal-to-noise ratio.  Note that as Monte Carlo modeling is a statistical process involving random numbers, we will be using the variable ξ throughout as a [[Pseudorandom number generator|pseudo-random number]] for many calculations.[[Image:MonteCarlo.png|thumb|right|Schematic for modeling photon flow in an infinite scattering and absorbing medium with Monte Carlo simulations.]]\n\n===Step 1: Launching a photon packet===\nIn our model, we are ignoring initial specular reflectance associated with entering a medium that is not refractive index matched.  With this in mind, we simply need to set the initial position of the photon packet as well as the initial direction.  It is convenient to use a global coordinate system.  We will use three [[Cartesian coordinate system|Cartesian coordinates]] to determine position, along with three [[Unit vector|direction cosines]] to determine the direction of propagation. The initial start conditions will vary based on application, however for a pencil beam initialized at the origin, we can set the initial position and direction cosines as follows (isotropic sources can easily be modeled by randomizing the initial direction of each packet):\n\n: <math>\n\\begin{align}\n x & = 0 \\\\\n\\text{Position: }y & = 0 \\\\\n z & = 0 \\\\  \\\\\n \\mu_x & = 0 \\\\\n\\text{Direction cosines: } \\mu_y & = 0 \\\\\n \\mu_z & = 1\n\\end{align}\n</math>\n\n===Step 2: Step size selection and photon packet movement===\nThe step size, ''s'', is the distance the photon packet travels between interaction sites. There are a variety of methods for step size selection. Below is a basic form of photon step size selection (derived using the [[Inverse transform sampling|inverse distribution method]] and the [[Beer&ndash;Lambert law]]) from  which we use for our homogeneous model:\n\n: <math>s = -\\frac{\\ln\\xi}{\\mu_t}</math>\n\nwhere <math>\\xi</math> is a random number and <math>{\\mu_t}</math> is the total interaction coefficient (i.e., the sum of the absorption and scattering coefficients).\n\nOnce a step size is selected, the photon packet is propagated by a distance ''s'' in a direction defined by the direction cosines.  This is easily accomplished by simply updating the coordinates as follows:\n\n: <math>\n\\begin{align}\nx & \\leftarrow x + \\mu_x s \\\\\ny & \\leftarrow y + \\mu_y s \\\\\nz & \\leftarrow z + \\mu_z s\n\\end{align}\n</math>\n\n===Step 3: Absorption and scattering===\nA portion of the photon weight is absorbed at each interaction site.  This fraction of the weight is determined as follows:\n\n: <math>\\Delta W = \\frac{\\mu_a}{\\mu_t} W</math>\n\nwhere <math>{\\mu_a}</math> is the absorption coefficient.\n\nThe weight fraction can then be recorded in an array if an absorption distribution is of interest for the particular study.  The weight of the photon packet must then be updated as follows:\n\n: <math>W \\leftarrow W - \\Delta W \\, </math>\n\nFollowing absorption, the photon packet is scattered.  The weighted average of the cosine of the photon scattering angle is known as scattering anisotropy (''g''), which has a value between &minus;1 and 1.  If the optical anisotropy is 0, this generally indicates that the scattering is isotropic. If ''g'' approaches a value of 1 this indicates that the scattering is primarily in the forward direction.  In order to determine the new direction of the photon packet (and hence the photon direction cosines), we need to know the scattering phase function. Often the Henyey-Greenstein phase function is used. Then the scattering angle, θ, is determined using the following formula.\n\n: <math>\\cos\\theta = \n\\begin{cases}\n\\frac{1}{2g} \\left[ 1 + g^2 - \\left(\\frac{1-g^2}{1-g+2g\\xi}\\right)^2\\right]&\\text{ if }g\\ne 0 \\\\\n1-2\\xi&\\text{ if }g= 0\n\\end{cases}\n</math>\n\nAnd, the polar angle ''&phi;'' is generally assumed to be uniformly distributed between 0 and <math> 2\\pi </math>.  Based on this assumption, we can set:\n\n: <math>\n\\varphi = 2\\pi\\xi\\frac{}{}\n</math>\n\nBased on these angles and the original direction cosines, we can find a new set of direction cosines.  The new propagation direction can be represented in the global coordinate system as follows:\n\n: <math>\n\\begin{align}\n\\mu'_x & = \\frac{\\sin\\theta(\\mu_x \\mu_z \\cos\\varphi - \\mu_y \\sin\\varphi)}{\\sqrt{1-\\mu_z^2}}+ \\mu_x \\cos\\theta \\\\\n\\mu'_y & = \\frac{\\sin\\theta(\\mu_y \\mu_z \\cos\\varphi + \\mu_x \\sin\\varphi)}{\\sqrt{1-\\mu_z^2}}+ \\mu_y \\cos\\theta \\\\\n\\mu'_z & = -\\sqrt{1-\\mu_z^2}\\sin\\theta\\cos\\varphi + \\mu_z\\cos\\theta \\\\\n\\end{align}\n</math>\n\nFor a special case \n: <math>\n\\begin{align}\n\\mu_z=1\n\\end{align}\n</math>\n\nuse\n\n: <math>\n\\begin{align}\n\\mu'_x & = \\sin\\theta\\cos\\varphi \\\\\n\\mu'_y & = \\sin\\theta\\sin\\varphi \\\\\n\\mu'_z & = \\cos\\theta \\\\\n\\end{align}\n</math>\n\nor\n\n: <math>\n\\begin{align}\n\\mu_z=-1\n\\end{align}\n</math>\n\nuse\n\n: <math>\n\\begin{align}\n\\mu'_x & = \\sin\\theta\\cos\\varphi \\\\\n\\mu'_y & = -\\sin\\theta\\sin\\varphi \\\\\n\\mu'_z & = -\\cos\\theta \\\\\n\\end{align}\n</math>\nC-code:\n\n /*********************** Indicatrix *********************\n *New direction cosines after scattering by angle theta, fi.\n * mux new=(sin(theta)*(mux*muz*cos(fi)-muy*sin(fi)))/sqrt(1-muz^2)+mux*cos(theta)\n * muy new=(sin(theta)*(muy*muz*cos(fi)+mux*sin(fi)))/sqrt(1-muz^2)+muy*cos(theta)\n * muz new= - sqrt(1-muz^2)*sin(theta)*cos(fi)+muz*cos(theta)\n *---------------------------------------------------------\n *Input:\n * muxs,muys,muzs - direction cosine before collision\n * mutheta, fi - cosine of polar angle and the azimuthal angle\n *---------------------------------------------------------\n *Output:\n *  muxd,muyd,muzd - direction cosine after collision\n *---------------------------------------------------------\n */\n void Indicatrix(double muxs, double muys, double muzs, double mutheta, double fi, double *muxd, double *muyd, double *muzd)\n {\n  double costheta = mutheta;\n  double sintheta = sqrt(1.0-costheta*costheta); // sin(theta)\n  double sinfi = sin(fi);\n  double cosfi = cos(fi);\n  if (muzs == 1.0) {\n    *muxd = sintheta*cosfi;\n    *muyd = sintheta*sinfi;\n    *muzd = costheta;\n  } elseif (muzs == -1.0) {\n    *muxd = sintheta*cosfi;\n    *muyd = -sintheta*sinfi;\n    *muzd = -costheta;\n  } else {\n    double denom = sqrt(1.0-muzs*muzs);\n    double muzcosfi = muzs*cosfi;\n    *muxd = sintheta*(muxs*muzcosfi-muys*sinfi)/denom + muxs*costheta;\n    *muyd = sintheta*(muys*muzcosfi+muxs*sinfi)/denom + muys*costheta;\n    *muzd = -denom*sintheta*cosfi + muzs*costheta;\n  }\n }\n\n===Step 4: Photon termination===\nIf a photon packet has experienced many interactions, for most applications the weight left in the packet is of little consequence.  As a result, it is necessary to determine a means for terminating photon packets of sufficiently small weight.  A simple method would use a threshold, and if the weight of the photon packet is below the threshold, the packet is considered dead.  The aforementioned method is limited as it does not conserve energy.  To keep total energy constant, a [[Russian roulette]] technique is often employed for photons below a certain weight threshold.  This technique uses a roulette constant ''m'' to determine whether or not the photon will survive.  The photon packet has one chance in ''m'' to survive, in which case it will be given a new weight of ''mW'' where ''W'' is the initial weight (this new weight, on average, conserves energy).  All other times, the photon weight is set to 0 and the photon is terminated.  This is expressed mathematically below:\n\n: <math> \nW = \\begin{cases}\nmW&\\xi \\leq  1/m \\\\\n0&\\xi > 1/m\n\\end{cases}\n</math>\n\n== Graphics Processing Units (GPU) and fast Monte Carlo simulations of photon transport ==\n\nMonte Carlo simulation of photon migration in turbid media is a highly parallelizable problem, where a large number of photons are propagated independently, but according to identical rules and different random number sequences. The parallel nature of this special type of Monte Carlo simulation renders it highly suitable for execution on a graphics processing unit (GPU). The release of programmable GPUs started such a development, and since 2008 there have been a few reports on the use of GPU for high-speed Monte Carlo simulation of photon migration.<ref name=Alerstam2008_JBiomedOpt/><ref name=Fang2009_OptExpress/><ref name=Ren2010_OptExpress/><ref name=Dor2011_JBiomedOptExp/>\n\nThis basic approach can itself be parallelized by using multiple GPUs linked together. One example is the \"GPU Cluster MCML,\" which can be downloaded from the authors' website (Monte Carlo Simulation of Light Transport in Multi-layered Turbid Media Based on GPU Clusters):\nhttp://bmp.hust.edu.cn/GPU_Cluster/GPU_Cluster_MCML.HTM\n\n==See also==\n*[[Radiative transfer equation and diffusion theory for photon transport in biological tissue]]\n*[[Monte Carlo method]]\n*[[Convolution for optical broad-beam responses in scattering media]]\n*[[Monte Carlo methods for electron transport]]\n\n==Links to other Monte Carlo resources==\n*[http://labs.seas.wustl.edu/bme/Wang/mc.html Optical Imaging Laboratory at Washington University in St. Louis (MCML)]\n*[http://omlc.ogi.edu/software/mc/ Oregon Medical Laser Center]\n*[https://web.archive.org/web/20101031052710/http://www.atomic.physics.lu.se/biophotonics/our_research/monte_carlo_simulations/ Photon migration Monte Carlo research at Lund University, Sweden] GPU acceleration of Monte Carlo simulations and scalable Monte Carlo. Open source code for download.\n*[http://www.lighttransport.net/ Cloud-based Monte Carlo for light transport in turbid scattering medium] The tool is free to use in research and non-commercial activities.\n*[http://scratchapixel.com/old/lessons/3d-basic-lessons/lesson-17-monte-carlo-methods-in-practice/monte-carlo-simulation-2/ Light Transport in Tissue as an Example of Monte Carlo Simulation (with C++ source code).]\n\n==References==\n*{{Cite book|author1=Wang, L-H  |author2=Wu Hsin-I|title=Biomedical Optics: Principles and Imaging|publisher=Wiley|year=2007}}\n*{{Cite journal|author1=L.-H. Wang |author2=S. L. Jacques |author3=L.-Q. Zheng |title=MCML—Monte Carlo modeling of light transport in multi-layered tissues|journal=Computer Methods and Programs in Biomedicine|volume=47|issue=2|pages=131&ndash;146|year=1995|doi=10.1016/0169-2607(95)01640-F}}\n*{{Cite journal|author1=L.-H. Wang |author2=S. L. Jacques |author3=L.-Q. Zheng |title=Conv—convolution for responses to a finite diameter photon beam incident on multi-layered tissues|journal=Computer Methods and Programs in Biomedicine|volume=54|issue=3 |pages=141&ndash;150|year=1997|doi=10.1016/S0169-2607(97)00021-7|url=http://labs.seas.wustl.edu/bme/Wang/epub/1997LWCMPBConv.pdf}}\n*{{Cite book|author1=S. L. Jacques |author2=L.-H. Wang |chapter=Monte Carlo modeling of light transport in tissues|title=Optical Thermal Response of Laser Irradiated Tissue|editor=A. J. Welch |editor2=M. J. C. van Gemert|publisher=Plenum Press|place=New York|year=1995|pages=&nbsp;73&ndash;100|chapter-url=http://labs.seas.wustl.edu/bme/Wang/epub/1995LWCMPBMcml.pdf}}\n*{{Cite journal|author1=L.-H. Wang |author2=S. L. Jacques |title=Optimized radial and angular positions in Monte Carlo modeling|journal=Medical Physics|volume=21|issue=7 |pages=1081&ndash;1083|year=1994|url=http://labs.seas.wustl.edu/bme/Wang/epub/1994LWMPOpt.pdf|doi=10.1118/1.597351|pmid=7968840 |bibcode = 1994MedPh..21.1081W }}\n\n==Inline references==\n{{reflist|refs=\n\n<ref name=Alerstam2008_JBiomedOpt>{{Cite journal|author1=E. Alerstam |author2=T. Svensson |author3=S. Andersson-Engels |title=Parallel computing with graphics processing units for high-speed Monte Carlo simulation of photon migration|journal=J. Biomed. Opt.|volume=13|issue=6 |pages=060504 |year=2008|doi=10.1117/1.3041496|pmid=19123645 |url=http://www.atomic.physics.lu.se/fileadmin/atomfysik/Biophotonics/Publications/Alerstam2008_JBOLetters.pdf|bibcode = 2008JBO....13f0504A }}</ref>\n<ref name=Fang2009_OptExpress>{{Cite journal|author1=Q. Fang |author2=D.A. Boas |title=Monte Carlo Simulation of Photon Migration in 3D Turbid Media Accelerated by Graphics Processing Units|journal=Opt. Express|volume=17|issue=22 |pages=20178–20190|year=2009|doi=10.1364/oe.17.020178|pmid=19997242 |pmc=2863034 |bibcode = 2009OExpr..1720178F }}</ref>\n\n<ref name=Ren2010_OptExpress>{{Cite journal|author1=N. Ren |author2=J. Liang |author3=X. Qu |author4=J. Li |author5=B. Lu |author6=J. Tian |title=GPU-based Monte Carlo simulation for light propagation in complex heterogeneous tissues|journal=Opt. Express |volume=18 |issue=7 |pages=6811–6823 |year=2010 |doi=10.1364/oe.18.006811|pmid=20389700 |bibcode=2010OExpr..18.6811R }}</ref>\n\n<ref name=Dor2011_JBiomedOptExp>{{Cite journal|author1=A. Doronin |author2=I. Meglinski |title=Online object oriented Monte Carlo computational tool for the needs of biomedical optics|journal=Biomed. Opt. Express |volume=2 |issue=9 |pages=2461–2469 |year=2011 |doi=10.1364/boe.2.002461|pmid=21991540 |pmc=3184856 }}</ref>\n\n}}\n\n[[Category:Monte Carlo methods]]\n[[Category:Photonics]]"
    },
    {
      "title": "Monte Carlo methods for electron transport",
      "url": "https://en.wikipedia.org/wiki/Monte_Carlo_methods_for_electron_transport",
      "text": "The '''Monte Carlo method for electron transport ''' is a semiclassical [[Monte Carlo]](MC) approach of modeling [[semiconductor]] transport. Assuming the carrier motion consists of free flights interrupted by scattering mechanisms, a computer is utilized to simulate the trajectories of particles as they move across the device under the influence of an [[electric field]] using [[classical mechanics]]. The scattering events and the duration of particle flight is determined through the use of random numbers.\n\n== Background ==\n\n=== Boltzmann transport equation ===\nThe [[Boltzmann transport equation]] model has been the main tool used in the analysis of transport in semiconductors. The BTE equation is given by:\n\n:<math>\n\\frac{\\partial f}{\\partial t}\n+ \\frac{1}{\\hbar} \\nabla_k E(k) \\nabla_r f \n+ \\frac{qF(r)}{\\hbar} \\nabla_k f\n= \\left[\\frac{\\partial f}{\\partial t}\\right]_\\mathrm{collision}\n</math>\n\n:<math>\nv = \\frac{1}{\\hbar} \\nabla_k E(k)\n</math>\n<!-- Used to be \\nalba_r F (force), should be \\nabla_r f (the distribution instead). -->\n\nThe [[Distribution function (physics)|distribution function]], ''f'', is a dimensionless function which is used to extract all observable of interest and gives a full depiction of electron distribution in both real and [[momentum space|k-space]]. Further, it physically represents the probability of particle occupation of energy ''k'' at position ''r'' and time&nbsp;''t''. In addition, due to being a seven-dimensional integro-differential equation (six dimensions in the phase space and one in time) the solution to the BTE is cumbersome and can be solved in closed analytical form under very special restrictions. Numerically, solution to the BTE is employed using either a deterministic method or a stochastic method. Deterministic method solution is based on a grid-based numerical method such as the spherical harmonics approach, whereas the Monte Carlo is the stochastic approach used to solve the BTE.\n\n=== Monte Carlo method ===\nThe semiclassical Monte Carlo method is a statistical method used to yield exact solution to the Boltzmann transport equation which includes complex [[band structure]] and [[scattering]] processes. This approach is semiclassical for the reason that scattering mechanisms are treated quantum mechanically using the [[Fermi's Golden Rule]], whereas the transport between scattering events is treated using the classical particle notion. The Monte Carlo model in essence tracks the particle trajectory at each free flight and chooses a corresponding scattering mechanism stochastically. Two of the great advantages of semiclassical Monte Carlo are its capability to provide accurate quantum mechanical treatment of various distinct scattering mechanisms within the scattering terms, and the absence of assumption about the form of carrier distribution in energy or k-space. The semiclassical equation describing the motion of an electron is\n\n:<math> \\frac{dr}{dt} = \\frac{1}{\\hbar} \\nabla_k E(k) </math>\n\n:<math> \\frac{dk}{dt} = \\frac{qF(r)}{\\hbar} </math>\n\nwhere F is the electric field, E(k) is the energy dispersion relation, and k is the momentum wave vector. To solve the above equation, one needs strong knowledge of the band structure (E(k)). The E(k) relation describes how the particle moves inside the device, in addition to depicting useful information necessary for transport such as the [[density of states]] (DOS) and the particle velocity. A Full-band E(K) relation can be obtained using the semi-empirical pseudopotential method.<ref name=\"Hess\">{{cite book|editor=Karl Hess|title=Monte Carlo Device Simulation: Full Band and Beyond|year=1991|isbn=978-1-4615-4026-7|doi=10.1007/978-1-4615-4026-7|publisher=Springer US}}</ref>\n\n=== Hydrodynamic and drift diffusion method ===\nBoth [[drift-diffusion equation|drift diffusion]] (DD) and the hydrodynamic (HD) models can be derived from the moments of the Boltzmann transport equation (BTE) using simplified approximation valid for long channel devices. The DD scheme is the most classical approach and usually solves the [[Poisson equation]] and the continuity equations for carriers considering the drift and diffusion components. In this approach, the charge transit time is assumed to be very large in comparison to the energy relaxation time.<ref name=\"Sze\">{{cite book|author1=S. M. Sze|author2=Kwok K. Ng|title=Physics of Semiconductor Devices|publisher=John Wiley and Sons, Inc|year=2007|edition=third|url=https://archive.org/details/PhysicsOfSemiconductorDevices_855/|isbn=978-0-471-14323-9}}</ref> On the other hand, the HD method solves\nthe DD scheme with the energy balance equations obtained from the moments of BTE.<ref name=\"Choi\">W.S. Choi, J.-K. Ahn, Y.-J. Park, H.-S. Min, and C.-G. Hwang., “A time dependent hydrodynamic device simula- tor snu-2d with new discretization scheme and algorithm.,” IEEE Trans. on CAD, vol. 13, pp. 898 (1994)</ref><ref name=\"Forghieri\">A. Forghieri, R. Guerrieri, P. Ciampolini, A. Gnudi, M. Rudan, and G. Baccarani., “A new discretization strategy of the semiconductor equations comprising momentum and energy balance,” IEEE Trans. on CAD, vol.7, pp. 231 (1988)</ref> Thus, one may capture and calculate physical details such as carrier heating and the [[velocity overshoot]] effect. Needless to say, an accurate discretization method is required in HD simulation, since the governing equations are strongly coupled and one has to deal with larger number of variables compared to the DD scheme.\n\n=== Comparison of semiclassical models ===\n[[File:Wiki mc fig3.PNG|thumb|Average carrier velocity for an 80nm nmos comparing the various semiclassical simulation model (a) Vds= 0.3V (b) Vds= 0.6V]]\nThe accuracy of semiclassical models are compared based on the BTE by investigating how they treat the classical velocity overshoot problem, a key [[short channel effect]] (SCE) in transistor structures. Essentially, velocity overshoot is a nonlocal effects of scaled devices, which is related to the experimentally observed increase in current drive and transconductance.<ref name=\"Sai\">G. A. Sai-Halasz, M. R. Wordeman, D. P. Kern, S. Rishton, and E. Ganin, “High transconductance and velocity overshoot in NMOS devices at the 0.1 μ gate-length level,” IEEE Electron Device Letter, vol. 9, pp. 464-66 (1998)</ref> As the channel length becomes smaller, the velocity is no longer saturated in the high field region, but it overshoots the predicted saturation velocity. The cause of this phenomenon is that the carrier transit time becomes comparable to the energy relaxation time, and therefore the mobile carriers do not have enough time to reach equilibrium with the applied electric field by scattering in the short channel devices.<ref name=\"Song\">J.H. Song, Y.J. Park, and H.S. Min, “Drain current enhancement due to velocity overshoot effects and its analytic modeling,” IEEE Trans. Electron Devices, 43, pp. 1870-5 (1996)</ref> The summary of simulation results (Illinois Tool: MOCA) with DD and HD model is shown in figure beside. In the figure (a), the case when the field is not high enough to cause the velocity overshoot effect in the whole channel region is shown. Note that at such limit, the data from the DD model fit well to the MC model in the non-overshoot region, but the HD model overestimate the velocity in that region. The velocity overshoot is observed only near the drain junction in the MC data and the HD model fits well in that region. From the MC data, it can be noticed that the velocity overshoot effect is abrupt in the high-field region, which is not properly included in the HD model. For high field conditions as shown in the figure (b) the velocity overshoot effect almost all over the channel and the HD results and the MC results are very close in the channel region.\n\n== Monte Carlo for semiconductor transport ==\n\n=== Band structure ===\n[[Band structure]] describes the relationship between energy(E) and [[wave vector]](k). The band structure is used to compute the movement of carriers under the action of the electric field, scattering rate, and final state after the collision. Silicon band structure and its Brillouin zone are shown in figure below, but there is no analytical expression which satisfies entire [[Brillouin zone]]. By using some approximation, there are two analytical models for band structure, namely the parabolic and the non-parabolic modes.\n\n[[File:Wiki mc fig45 new.PNG|Silicon band structure and its Brillouin Zone]]\n\n==== Parabolic band structure ====\nFor the concept of band structure, parabolic energy bands are generally assumed for simplicity. Electrons reside, at least when close to equilibrium, close to the minima of the E(k) relation. Then the E(k) relation can be extended in a Taylor series as\n\n:<math> E(k) =  E(0) + \\left. \\frac{\\partial E(k)}{\\partial k} \\right|_{\\mathrm{k=0}}\n\\cdot k + \\frac{1}{2} \\frac{\\partial^2 E(k)}{\\partial k^2} \n\\cdot k^2 </math>\n\nBecause the first derivative vanishes at the band minimum, so the gradient of E(k) is zero at k = 0. Thus,\n\n:<math> E(k) = \\frac{\\hbar^2 k^2}{2m^*} </math>\n\nwhich yields the definition of the effective mass tensor\n\n:<math> \\frac{1}{m^*} = \\frac{1}{\\hbar^2} \\frac{\\partial^2 E(k)}{\\partial k^2} </math>\n\nThis expression is true for semiconductor which has isotropic effective mass, for instance GaAs. In case of silicon, conduction band minima does not lie at ''k''&nbsp;=&nbsp;0 and the effective mass depends on the crystallographic orientation of the minimum as\n\n:<math> E(k) = \\frac{\\hbar^2}{2} \\left(\\frac{k^2_l}{m^*_l} + \\frac{2k^2_t}{m^*_t}\\right) </math>\n\nwhere <math>m^*_l , m^*_t </math> describe longitudinal and transverse effective mass, respectively.\n\n==== Non-parabolic band structure ====\nFor higher applied fields, carriers reside above the minimum and the dispersion relation, E(k), does not satisfy the simple parabolic expression described above. This non-parabolicity is generally described by\n\n:<math> E(1+\\alpha E) = \\frac{\\hbar^2 k^2}{2m^*} </math>\n\nwhere <math>\\alpha</math> is a coefficient of non-parabolicity given by\n\n:<math> \\alpha = \\frac{(1-m^* / m_0)^2}{E_g} </math>\n\nwhere <math>m_0</math> is the electron mass in vacuum, and {{Not a typo|Eg}} is the energy gap.<ref name = 'iue'>{{cite web|url=http://www.iue.tuwien.ac.at/phd/wessner/node31.html|title=6.3 Silicon Band Structure Models|publisher=}}</ref>\n\n==== Full band structure ====\nFor many applications, non-parabolic band structure provides reasonable approximation. However, in case of very high field transport, which requires the better physical model of the full band structure. For full band approach, numerically generated table of E(k) is used. Full band approach for Monte Carlo simulation was first used by Karl Hess at the University of Illinois at Urbana-Champaign. This approach is based on empirical pseudopotential method suggested by Cohen and Bergstresser [18]. Full band approach is computationally expensive, however, following the advancement of the computational power, it can be used as a more general approach.<ref name = 'Cohen'>Marvin L. Cohen, T. K. Bergstresser, “Band Structures and Pseudopotential Form Factors for Fourteen Semiconductors of the Diamond and Zinc-blende Structures”, Phys. Rev., vol. 141, pp. 789–796 (1966)</ref>\n\n=== Types of Monte Carlo simulation ===\n\n==== One-particle Monte Carlo ====\nFor this type of simulation, one carrier is injected and the motion is tracked in the domain, until it exits through contact. Another carrier is then injected and the process repeated to simulate an ensemble of trajectories. This approach is mostly useful to study bulk properties, like the steady state drift velocity as a function of field.\n\n==== Ensemble Monte Carlo ====\nInstead of single carrier, a large ensemble of carriers is simulated at the same time. This procedure is obviously a good candidate for super-computation, since one may apply parallelization and vectorization. Also, it is now possible to perform ensemble averages directly. This approach is suitable for transient simulations.\n\n==== Self-consistent ensemble Monte Carlo ====\nThis method couples the ensemble Monte Carlo procedure to Poisson's equation, and is the most suitable for device simulation. Typically, Poisson's equation is solved at fixed intervals to update the internal field, to reflect the internal redistribution of charge, due to the movement of carriers.\n\n=== Random flight selection ===\nThe probability that the electron will suffer its next collision during dt around t is given by\n\n:<math> p(t) \\, dt = P[k(t)] \\exp[-\\int^t_0 P[k(t')] \\, dt' ] \\, dt </math>\n\nwhere P[k(t)]dt is the probability that an electron in the state k suffers a collision during the time dt. Because of the complexity of the integral at the exponent, it is impractical to generate stochastic free flights with the distribution of the equation above. In order to overcome this difficulty, people use a fictitious “self-scattering” scheme. By doing this, the total scattering rate, including this self-scattering, is constant and equal to, say, <math>\\Gamma</math>. By random selection, if self-scattering is selected, k′ after the collision is the same as k and the carrier continues its flight without perturbation. Introducing a constant <math>P(k) = \\tau_0^{-1}</math>, the above equation reduces to\n\n:<math> p(t) = \\frac{1}{\\tau_0} \\exp(-t/ \\tau_0). </math>\n\nRandom numbers ''r'' can be used very simply to generate stochastic free flights, which duration will then be given by <math> t_r = - \\tau_0 \\ln(r) </math>. The computer time used for self-scattering is more than compensated for by the simplification of the calculation of the free-flight duration.<ref name = 'Jacoboni'>C. Jacoboni, L. Reggiani, “The Monte Carlo Method for Solution of Charge Transport in Semiconductor with Application to Covalent Materials” Rev. Modern Physics, vol.55, 3, pp. 645–705 (1983)</ref> To enhance the speed of free flight time calculation, several schemes such as “Constant Technique”, and “Piecewise Technique” are used to minimize the self-scattering events.\n\n== Scattering mechanisms ==\n\n=== General background in solid-state physics ===\nImportant charge transport properties of semiconductor devices such as the deviance from Ohm's law and the saturation of carriers mobility are a direct consequence of scattering mechanisms. It is thus of great importance for a semiconductor device simulation to capture the physics of such mechanisms. The semiconductor Monte Carlo simulation, in this scope, is a very powerful tool for the ease and the precision with which an almost exhaustive array of scattering mechanisms can be included. The duration of the free flights is determined from the scattering rates. At the end of each flight, the appropriate scattering mechanism must be chosen in order to determine the final energy of the scattered carrier, or equivalently, its new momentum and scattering angle. In this sense, one will distinguish two broad types of scattering mechanisms which naturally derive form the classic\nkinetic theory of collision between two bodies:\n\n''Elastic scattering'', where the energy of the particle is conserved after being scattered. Elastic scattering will hence only change the direction of the particle's momentum. Impurity scattering and surface scattering are, with a fair approximation, two good examples of elastic scattering processes.\n\n''Inelastic scattering'', where energy is transferred between the scattered particle and the scattering center. Electronphonon interactions are essentially inelastic since a phonon of definite energy is either emitted or absorbed by the scattered particle.\nBefore characterizing scattering mechanisms in greater mathematical details, it is important to note that when running semiconductor Monte Carlo simulations, one has to deal mainly with the following types of scattering events:<ref name=\"Jacoboni\"/>\n\n''Acoustic Phonon:'' The charge carrier exchanges energy with an acoustic mode of the vibration of atoms in the crystal lattice. Acoustic Phonons mainly arise from thermal excitation of the crystal lattice.\n\n''Polar Optical:'' The charge carrier exchanges energy with one of the polar optical modes of the crystal lattice. These modes are not present in covalent semiconductors. Optical phonons arise from the vibration against each other of atoms of different types when there is more than one atom in the smallest unit cell, and are usually excited by light.\n\n''Non-Polar Optical:'' Energy is exchanged with an optical mode. Non-polar optical phonons must generally be considered in covalent semiconductors and the L-valley of GaAs.\n\n''Equivalent Intervalley Phonon:'' Due to the interaction with a phonon, the charge carrier transitions from initial states to final states which belong to different but equivalent valleys. Typically, this type of scattering mechanism describes the transition of an electron from one X-valley to another X-valley, or from one L-valley to another L-valley.<ref name = 'iue55'>{{cite web|url=http://www.iue.tuwien.ac.at/phd/smirnov/node55.html|title=2.5.2.4 Intervalley Phonon Scattering|publisher=}}</ref>\n\n''Non Equivalent Intervalley Phonon:'' Involves the transition of a charge carrier between valleys of different types.\n\n''Piezoelectric Phonon:'' For low temperatures.\n\n''Ionized Impurity:'' Reflects the deviation of a particle from it ballistic trajectory due to Coulomb interaction with an ionized impurity in the crystal lattice. Because the mass of an electron is relatively small in comparison to the one of an impurity, the Coulomb cross section decreases rapidly with the difference of the modulus of momentum between the initial and final state.<ref name = 'Jacoboni' /> Therefore, impurity scattering events are mostly considered for intravalley scattering, intraband scattering and, to a minor extent, interband scattering.\n\n''Carrier-Carrier:'' (electron-electron, hole-hole and electron-hole interactions). When carrier concentration is high, this type of scattering reflects the electrostatic interaction between charge carriers. This problem becomes very quickly computationally intensive with an increasing number of particles in an ensemble simulation. In this scope, Particle-Particle–Particle-Mesh (P3M) algorithms, which distinguish short range and long range interaction of a particle with its surrounding charge gas, have proved efficient in including carrier-carrier interaction in the semiconductor Monte Carlo simulation.<ref name = 'Hockney'>R. Hockney, J. Eastwood, “Computer Simulations Using Particles”\nMcGraw Hill, Ch. 10 (1981)</ref> Very often, the charge of the carriers is assigned to a grid using a Cloud-in-Cell method, where part of the charge of a given particle is assigned to a given number of closest grid points with a certain weight factor.\n\n''Plasmon:'' Reflects the effect of the collective oscillation of the charge carriers on a given particle.\n\n=== Inclusion of scattering mechanisms in Monte Carlo ===\nA computationally efficient approach to including scattering in Monte Carlo simulation consists in storing the scattering rates of the individual mechanisms in tables. Given the different scattering rates for a precise particle state, one may then randomly select the scattering process at the end of the free flight. These scattering rates are very often derived using the [[Born approximation]], in which a scattering event is merely a transition between two momentum states of the carrier involved. As discussed in section II-I, the quantum many-body problem arising from the interaction of a carrier with its surrounding environment (phonons, electrons, holes, plasmons, impurities,...) can be reduced to a two-body problem using the quasiparticle approximation, which separates the carrier of interest from the rest of the crystal.<ref name = 'Jacoboni' /> Within these approximations,\n[[Fermi's Golden Rule]] gives, to the first order, the transition probability per unit time for a scattering mechanism from a state <math> |k \\rangle</math> to a state <math> |k' \\rangle</math>:\n\n:<math> S(k,k') = \\frac{2\\pi}{\\hbar}\n\\left | \\langle k|H'|k' \\rangle \\right |^2 \\cdot\n\\delta(E - E') </math>\n\nwhere H' is the perturbation Hamiltonian representing the collision and E and E′ are respectively the initial and final energies of the system constituted of both the carrier and the electron and phonon gas. The Dirac <math>\\delta</math>-function stands for the conservation of energy. In addition, the term <math>\\langle k|H'|k' \\rangle</math>, generally referred to as the matrix element, mathematically represents an inner product of the initial and final wave functions of the carrier:<ref name = 'Ferry'>D.K. Ferry, “Quantum Mechanics: An Introduction for Device Physicist and Electrical Engineer” Institute of Physics,ed. 1, p.186 (1995)</ref>\n\n:<math> \\langle k|H'|k' \\rangle = \\frac{1}{Vol} \\int_\\mathrm{Vol}\n\\psi_k (r) H' \\psi^*_{k'} (r) \\, dr </math>\n\nIn a crystal lattice, the wavefunctions  <math>\\psi_k (r)</math> and  <math>\\psi_{k'} (r)</math> are simply [[Bloch waves]]. When it is possible, analytic expression of the Matrix elements are commonly found by Fourier expanding the [[Hamiltonian mechanics#Mathematical formalism|Hamiltonian]] H', as in the case of Impurity scattering <ref name = 'Hess94'>K. Hess, “Advanced Theory of Semiconductor Devices” Wiley,ed. 1, pp.94–95 (1999)</ref> or acoustic phonon scattering.<ref name = 'Hess97'>K. Hess, “Advanced Theory of Semiconductor Devices” Wiley, ed. 1, pp.97–99(1999)</ref> In the important case of a transition from an energy state E to an energy state E' due to a phonon of wave vector q and frequency <math>\\omega_q</math>, the energy and momentum change is:\n\n:<math> E' - E = E(k') - E(k) \\pm \\hbar \\omega_q \\,  </math>\n\n:<math>k' - k \\pm q = \\begin{cases} 0 & \\text{ } \\\\ R  & \\text{Umklapp-process} \\end{cases} </math>\n\nwhere ''R'' is a [[reciprocal lattice]] vector. Umklapp processes (or U-processes) change the momentum of the particle after scattering and are therefore limiting the conduction in semiconductor crystals. Physically, U-processes occur when the final momentum of the particle points out of the first Brillouin zone.  Once one knows the scattering probability per unit time from a state k to a state k', it is interesting to determine the scattering rate for a given scattering process. The scattering rate gives the probability per unit time to scatter from a state ''k'' to any other state in the reciprocal space. Therefore, the scattering rate is\n\n:<math> \\lambda (k) = \\sum_{k'} S(k,k')</math>\n\nwhich can be readily used to determine the free flight time and the scattering process as discussed in section 3-3. It is important to note that this scattering rate will be dependent on the band structure of the material (the dependence arises from the matrix elements).\n\n=== Selection of scattering mode and scattered trajectory ===\nAt the end of a free flight, a scattering mode and angle must be randomly chosen. In order to determine the scattering mechanism, one has to consider all the scattering rates <math> \\lambda_1, \\lambda_2, ..., \\lambda_n</math> of the mechanisms relevant to the simulation as well as the total scattering rate at the time of scattering <math> \\lambda_{tot} (t_{sc}) = \\sum_i \\lambda_i. </math> Selecting a scattering mechanism then simply results in generating a uniformly distributed random number 0 < r < 1 and referring to the following rules\n\n:<math>\n\\begin{align}\nr & < \\frac{\\lambda_1}{\\lambda_\\mathrm{tot}} \\rightarrow \\text{scattering-mechanism-}1 \\\\\nr & < \\frac{\\lambda_1 + \\lambda_2}{\\lambda_\\mathrm{tot}} \\rightarrow \\text{scattering-mechanism-}2 \\\\\n& {} \\  \\vdots \\\\\nr & < \\frac{\\sum_{i=0}^n \\lambda_i}{\\lambda_\\mathrm{tot}} \\rightarrow \\text{scattering-mechanism-}n\n\\end{align}\n</math>\n\nA computationally efficient approach to selecting the scattering mechanism consists in adding a “void” scattering mechanism so that <math>\\lambda_\\mathrm{tot}</math> remains constant over time. If a particle is scattered according to this mechanism, it will keep its ballistic trajectory after scattering takes place. In order to choose a new trajectory, one must first derive the [[energy]] (or [[momentum]]) of the particle after scattering\n\n:<math> E(k') = E(k) \\pm \\hbar \\omega_q \\pm \\Delta E_C \\, </math>\n\nwhere the term <math>\\hbar \\omega_q</math> accounts for phonon emission or absorption and the term <math> \\Delta E_C </math> is non-null for inter-valley scattering. The final energy (and the band structure) directly yield the modulus of the new momentum k'. At this point one only needs to choose a new direction (or angle) for the scattered particle. In some simple cases as [[phonon scattering]] and a parabolic dispersion relation, the scattering angle is random and evenly distributed on the sphere of radius k'. Using spherical coordinates, the process of choosing the angle is equivalent to randomly picking two angles <math>\\theta</math>and <math>\\psi</math>. If the angle is distributed with a distribution <math>p(\\theta, \\psi)</math>, then for a uniform distribution of angles, the [[probability]] to pick a point of the sphere is\n\n:<math> p(\\theta, \\psi) \\, d \\theta d \\psi = \\frac{\\sin \\theta \\, d \\theta \\, d \\psi}{4 \\pi} </math>\n\nIt is possible, in this case, to separate the two variables. Integrating over <math>\\psi</math> then over <math>\\theta</math>, one finds\n:<math> p(\\theta) = \\frac{\\sin \\theta}{2}</math>\n:<math> p(\\psi) = \\frac{1}{2 \\pi}</math>\n\nThe two spherical angles can then be chosen, in the uniform case, by generating two random numbers 0 < r<sub>1</sub>, r<sub>2</sub> < 1 such that\n\n:<math> r_1 = \\int_0^\\psi p(\\psi ') \\, d \\psi ' = \\frac{\\psi}{2 \\pi} </math>\n:<math> r_2 = \\int_0^\\theta p(\\theta ') \\, d \\theta ' = \\frac{1 - \\cos \\theta}{2} </math>\n\n== Quantum corrections for Monte Carlo simulation ==\n[[File:Wiki mc fig6.PNG|thumb|Effects Quantum Correction]]\n \nThe current trend of scaling down [[semiconductor devices]] has forced physicists to incorporate quantum mechanical issues in order to acquire a thorough understanding of device behavior. Simulating the behavior of nano-scale devices necessitates the use of a full [[quantum mechanics|quantum transport]] model especially for cases when the quantum effects cannot be ignored. This complication, however, can be avoided in the case of practical devices like the modern day [[MOSFET]], by employing quantum corrections within a semi-classical framework. The semi-classical Monte Carlo model can then be employed to simulate the device characteristics. The quantum corrections can be incorporated into a Monte Carlo simulator by simply introducing a quantum potential term which is superimposed onto the classical electrostatic potential seen by the simulated particles. Figure beside pictorially depicts the essential features of this technique. The various quantum approaches available for implementation are described in the following subsections.\n\n=== Wigner-based correction ===\nThe Wigner transport equation forms the bases for the Wigner-based quantum correction.\n\n:<math> \\frac{\\partial f}{\\partial t} + r \\cdot \\nabla_r f\n- \\frac{1}{\\hbar} \\nabla_r V \\cdot \\nabla_k f\n+ \\sum_{\\alpha = 1}^{\\infty} \\frac{(-1)^{\\alpha +1}}{\\hbar 4^{\\alpha} (2 \\alpha +1)!}\n\\times (\\nabla_r \\nabla_k)^{2 \\alpha +1} V f = \\left(\\frac{\\partial f}{\\partial t}\\right)_c\n</math>\n\nwhere, ''k'' is the crystal momentum, V is the classical potential, the term on the RHS is the effect of collision,the fourth term on the LHS represents non-local quantum mechanical effects. The standard Boltzmann Transport Equation is obtained when the non-local terms on the LHS disappear in the limit of slow spatial variations. The simplified (for <math>\\alpha=0</math>) quantum corrected BTE then becomes\n\n:<math> \\frac{\\partial f}{\\partial t} + r \\cdot \\nabla_r f\n- \\frac{1}{\\hbar} \\nabla_r V \\cdot \\nabla_k f = \\left(\\frac{\\partial f}{\\partial t}\\right)_c\n</math>\n\nwhere the quantum potential is contained in the term <math>V_{\\omega}</math> (must be an error: <math>V_{\\omega}</math> was never mentioned).\n\n=== Effective potential correction ===\nThis method for quantum correction was developed by Feynman and Hibbs in 1965. In this method the effective potential is derived by calculating the contribution to the path integral of a particle's quantum fluctuations around its classical path. This calculation is undertaken by a variational method using a trial potential to first order. The effective classical potential in the average point on each path then becomes\n\n:<math> V_\\mathrm{eff} (x) = \\frac{1}{\\sqrt{2 \\pi a}} \\int^\\infty_{- \\infty} V(x') \ne^{-\\frac{(x'-x)^2}{2a^2}} dx' </math>\n\n:<math> a^2 = \\frac{\\hbar^2}{12m^*k_BT} </math>\n\n=== Schrödinger-based correction ===\nThis approach involves periodical solving of a [[Schrödinger equation]] in a simulation with the input being the self-consistent electrostatic potential. The exact energy levels and wavefunctions relating to the electrostatic potential solution are employed to calculate the quantum potential. The quantum correction obtained on the bases of this method can be visualised by the following equation\n\n:<math> V_\\mathrm{schr}(z) = -k_BT \\cdot \\log(n_q(z)) - V_p(z) + V_0 </math>\n\nwhere V<sub>schr</sub> is the quantum correction potential, ''z'' is the direction perpendicular to the interface, ''n''<sub>''q''</sub> is the quantum density from the Schrödinger equation which is equivalent to the converged Monte Carlo concentration, ''V''<sub>''p''</sub> is the potential from the Poisson solution, ''V''<sub>0</sub> is the arbitrary reference potential far away from the quantum region such that the correction goes to null in the region of semi-classical behavior. Even though the above-mentioned potentials for quantum correction differ in their method of calculation and their basic assumptions, yet when it comes to their inclusion into Monte Carlo simulation they are all incorporated the same way.\n\n==See also==\n*[[Monte Carlo method]]\n*[[Semiconductor device]]\n*[[Monte Carlo method for photon transport]]\n*[[Band structure]]\n*[[Method of quantum characteristics]]\n*[[Quantum Monte Carlo]]\n*[[Quasi-Monte Carlo method]]\n\n==References==\n<!--- See [[Wikipedia:Footnotes]] on how to create references using  tags which will then appear here automatically -->\n{{Reflist|2}}\n\n{{Statistics}}\n\n{{DEFAULTSORT:Monte Carlo Methods For Electron Transport}}\n[[Category:Monte Carlo methods]]\n[[Category:Quantum mechanics]]\n[[Category:Semiconductor analysis]]"
    },
    {
      "title": "Monte Carlo molecular modeling",
      "url": "https://en.wikipedia.org/wiki/Monte_Carlo_molecular_modeling",
      "text": "'''Monte Carlo molecular modeling''' is the application of [[Monte Carlo method]]s to molecular problems. These problems can also be modeled by the [[molecular dynamics]] method. The difference is that this approach relies on [[equilibrium statistical mechanics]] rather than molecular dynamics. Instead of trying to reproduce the dynamics of a system, it generates states according to appropriate [[Boltzmann distribution|Boltzmann probabilities]]. Thus, it is the application of the '''Metropolis Monte Carlo simulation''' to molecular systems. It is therefore also a particular subset of the more\ngeneral [[Monte Carlo method in statistical physics]].\n\nIt employs a [[Markov chain]] procedure in order to determine a '''new state''' for a system from a previous one. According to its stochastic nature, this new state is accepted at random. Each trial usually counts as\na '''move'''. The avoidance of dynamics restricts the method to studies of static quantities only, but the freedom to choose moves makes the method very flexible. These moves must only satisfy a basic condition of\n'''balance''' in order equilibrium be properly described, but '''[[detailed balance]]''', a stronger condition,\nis usually imposed when designing new algorithms. An additional advantage is that some systems, such as the [[Ising model]], lack a dynamical description and are only defined by an energy prescription; for these the Monte Carlo approach is the only one feasible.\n\nThe great success of this method in statistical mechanics has led to various generalizations such as the method of [[simulated annealing]] for optimization, in which a fictitious temperature is introduced and then gradually lowered.\n\nA range of software packages have been developed specifically for the use of the Metropolis Monte Carlo method on molecular simulations. These include:\n* BOSS<ref>[http://www.cemcomco.com/BOSS_and_MCPRO_Distribution125.html BOSS & MCPro Distribution]</ref>\n* MCPro<ref>[http://www.cemcomco.com/BOSS_and_MCPRO_Distribution125.html BOSS & MCPro Distribution]</ref>\n* Sire<ref>[http://siremol.org/Sire/Home.html Sire website] {{webarchive|url=https://web.archive.org/web/20160415055514/http://siremol.org/Sire/Home.html |date=2016-04-15 }}</ref>\n* ProtoMS<ref>[http://protoms.org ProtoMS website]</ref>\n\n==See also==\n* [[Quantum Monte Carlo]]\n* [[Monte Carlo method in statistical physics]]\n* [[List of software for Monte Carlo molecular modeling]]\n* [[List of software for molecular mechanics modeling|Software for molecular mechanics modeling]]\n* [[Bond fluctuation model]]\n\n==External links==\n* http://cmm.cit.nih.gov/intro_simulation/node25.html\n\n==References==\n{{Reflist}}\n\n* {{cite book |author1=Allen, M.P.  |author2=Tildesley, D.J.  |lastauthoramp=yes | title=Computer Simulation of Liquids | publisher=Oxford University Press | year=1987 | isbn=0-19-855645-4}}\n* {{cite book |author1=Frenkel, D.  |author2=Smit, B.  |lastauthoramp=yes | title=Understanding Molecular Simulation | publisher=Academic Press | year=2001 | isbn=0-12-267351-4}}\n* {{cite book |author1=Binder, K.  |author2=Heermann, D.W.  |lastauthoramp=yes | title=Monte Carlo Simulation in Statistical Physics. An Introduction (4th edition) | publisher= Springer | year=2002 | isbn=3-540-43221-3}}\n\n[[Category:Molecular modelling]]\n[[Category:Theoretical chemistry]]\n[[Category:Monte Carlo methods]]\n[[Category:Stochastic models]]"
    },
    {
      "title": "Monte Carlo tree search",
      "url": "https://en.wikipedia.org/wiki/Monte_Carlo_tree_search",
      "text": "{{Infobox algorithm\n|class=[[Search algorithm]]\n|image=\n|data=\n|time=\n|best-time=\n|average-time=\n|space=\n|optimal=\n|complete=\n}}\n\n{{Tree search algorithm}}\n\nIn [[computer science]], '''Monte Carlo tree search''' ('''MCTS''') is a [[heuristic (computer science)|heuristic]] [[search algorithm]] for some kinds of [[decision process]]es, most notably those employed in game play. MCTS was introduced in 2006 for [[computer Go]].<ref name=\"alphago\">{{Cite journal|title = Mastering the game of Go with deep neural networks and tree search|journal = [[Nature (journal)|Nature]]| issn= 0028-0836|pages = 484–489|volume = 529|issue = 7587|doi = 10.1038/nature16961|pmid = 26819042|first1 = David|last1 = Silver|author-link1=David Silver (programmer)|first2 = Aja|last2 = Huang|author-link2=Aja Huang|first3 = Chris J.|last3 = Maddison|first4 = Arthur|last4 = Guez|first5 = Laurent|last5 = Sifre|first6 = George van den|last6 = Driessche|first7 = Julian|last7 = Schrittwieser|first8 = Ioannis|last8 = Antonoglou|first9 = Veda|last9 = Panneershelvam|first10= Marc|last10= Lanctot|first11= Sander|last11= Dieleman|first12=Dominik|last12= Grewe|first13= John|last13= Nham|first14= Nal|last14= Kalchbrenner|first15= Ilya|last15= Sutskever|author-link15=Ilya Sutskever|first16= Timothy|last16= Lillicrap|first17= Madeleine|last17= Leach|first18= Koray|last18= Kavukcuoglu|first19= Thore|last19= Graepel|first20= Demis |last20=Hassabis|author-link20=Demis Hassabis|date= 28 January 2016|bibcode = 2016Natur.529..484S}}{{closed access}}</ref> It has been used in other board games like [[chess]] and [[shogi]],<ref name=\":0\">{{cite arXiv |last=Silver|first=David |date=2017 |title=Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm|eprint=1712.01815v1|class=cs.AI }}</ref> games with incomplete information such as [[contract bridge|bridge]]<ref>{{cite book |authors=[[Stuart J. Russell]], [[Peter Norvig]] |title= Artificial Intelligence: A Modern Approach |edition= 3rd |publisher= [[Prentice Hall]] |year= 2009|title-link= Artificial Intelligence: A Modern Approach }}</ref> and [[poker]],<ref name=\"cpr\"/> as well as in real-time video games (such as [[Total War: Rome II]]'s implementation in the high level campaign AI<ref>{{cite web|title=Monte-Carlo Tree Search in TOTAL WAR: ROME II's Campaign AI|url=http://aigamedev.com/open/coverage/mcts-rome-ii/|website=AI Game Dev|accessdate=25 February 2017}}</ref>).\n\n== History ==\n=== Monte Carlo Method ===\nThe [[Monte Carlo method]], which uses randomness for deterministic problems difficult or impossible to solve using other approaches, dates back to the 1940s. In his 1987 PhD thesis, Bruce Abramson combined [[minimax|minimax search]] with an ''expected-outcome model'' based on random game playouts to the end, instead of the usual [[evaluation function|static evaluation function]]. Abramson said the expected-outcome model \"is shown to be precise, accurate, easily estimable, efficiently calculable, and domain-independent.\"<ref name=Abramson>{{cite book|last=Abramson|first=Bruce|title=The Expected-Outcome Model of Two-Player Games|publisher=Technical report, Department of Computer Science, Columbia University|year=1987|url=http://academiccommons.columbia.edu/download/fedora_content/download/ac:142327/CONTENT/CUCS-315-87.pdf|accessdate=23 December 2013}}</ref>  He experimented in-depth with [[Tic-tac-toe]] and then with machine-generated evaluation functions for [[Reversi|Othello]] and [[Chess]].\n\nSuch methods were then explored and successfully applied to heuristic search in the field of [[automated theorem proving]] by W. Ertel, J. Schumann and C. Suttner in 1989,<ref>{{cite book|editor1=J. Retti|editor2=K. Leidlmair|title=5. Österreichische Artificial-Intelligence-Tagung. Informatik-Fachberichte 208,pp. 87-95.|chapter=Learning Heuristics for a Theorem Prover using Back Propagation. |author2= Johann Schumann| author3=Christian Suttner |author1= Wolfgang Ertel |publisher=Springer |year=1989|chapter-url=http://www.hs-weingarten.de/~ertel/veroeff_bib.html#ESS89}}</ref><ref>{{cite book|title=CADE90, 10th Int. Conf. on Automated Deduction.pp. 470-484. LNAI 449.|chapter=Automatic Acquisition of Search Guiding Heuristics. | author1=Christian Suttner |author2= Wolfgang Ertel |publisher=Springer |year=1990|chapter-url=http://www.hs-weingarten.de/~ertel/veroeff_bib.html#ES90:CADE}}</ref><ref>{{cite journal|author1=Christian Suttner |author2= Wolfgang Ertel |title=Using Back-Propagation Networks for Guiding the Search of a Theorem Prover.|journal=Journal of Neural Networks Research & Applications|volume= 2|issue=1|pages=3–16|date=1991|url=http://www.hs-weingarten.de/~ertel/veroeff_bib.html#ES90:IJNN}}</ref> thus improving the exponential search times of uninformed search algorithms such as e.g. breadth-first search, depth-first search or [[iterative deepening]].\n\nIn 1992, B. Brügmann employed it for the first time in a [[Computer Go|Go-playing program]].<ref name=\"Bruegmann\"/> Chang et al.<ref name=\"Chang2005\" /> proposed the idea of \"recursive rolling out and backtracking\" with \"adaptive\" sampling choices in their Adaptive Multi-stage Sampling (AMS) algorithm for the model of Markov decision processes. AMS was the first work to explore the idea of [[Thompson sampling#Upper-Confidence-Bound (UCB) Algorithms|UCB]]-based exploration and exploitation in constructing sampled/simulated (Monte Carlo) trees and was the main seed for UCT (Upper Confidence Trees).<ref name=\"changORMStoday\"/>\n\n=== Monte Carlo Tree Search ===\n\n[[File:Computer-go-ratings-English.svg|thumb|The rating of best Go-playing programs on the KGS server since 2007. Since 2006, all the best programs use Monte Carlo tree search.<ref>{{cite web|url=http://senseis.xmp.net/?KGSBotRatings|title=Sensei's Library: KGSBotRatings|accessdate=2012-05-03}}</ref>]]\nIn 2006, inspired by these predecessors,<ref>{{cite book|author=[[Rémi Coulom]]|chapter=The Monte-Carlo Revolution in Go|title=Japanese-French Frontiers of Science Symposium|year=2008|chapter-url=http://remi.coulom.free.fr/JFFoS/JFFoS.pdf}}</ref> [[Rémi Coulom]] described the application of the Monte Carlo method to game-tree search and coined the name Monte Carlo tree search,<ref>{{cite book|author=[[Rémi Coulom]]|chapter=Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search|pages=72–83|others=H. Jaap van den Herik, Paolo Ciancarini, H. H. L. M. Donkers (eds.)|title=Computers and Games, 5th International Conference, CG 2006, Turin, Italy, May 29–31, 2006. Revised Papers |publisher=Springer|year=2007|isbn=978-3-540-75537-1|doi=|citeseerx=10.1.1.81.6817}}</ref> L. Kocsis and Cs. Szepesvári developed the UCT algorithm,<ref name=\"Kocsis-Szepesvari\"/> and S. Gelly et al. implemented UCT in their program MoGo.<ref name=\"Gelly-et-al\"/> In 2008, MoGo achieved [[dan (rank)|dan]] (master) level in 9×9 Go,<ref>{{cite journal|author1=Chang-Shing Lee |author2=Mei-Hui Wang |author3=Guillaume Chaslot |author4=Jean-Baptiste Hoock |author5=Arpad Rimmel |author6=Olivier Teytaud |author7=Shang-Rong Tsai |author8=Shun-Chin Hsu |author9=Tzung-Pei Hong |title=The Computational Intelligence of MoGo Revealed in Taiwan's Computer Go Tournaments|journal=IEEE Transactions on Computational Intelligence and AI in Games|pages=73–89|volume=1|issue=1|year=2009|url=http://hal.inria.fr/docs/00/36/97/86/PDF/TCIAIG-2008-0010_Accepted_.pdf |doi=10.1109/tciaig.2009.2018703|citeseerx=10.1.1.470.6018 }}</ref> and the Fuego program began to win against strong amateur players in 9×9 Go.<ref>{{cite book|url=http://pug.raph.free.fr/files/Fuego.pdf|title=Fuego – An Open-Source Framework for Board Games and Go Engine Based on Monte Carlo Tree Search|publisher=Technical report, University of Alberta|year=2008|isbn=|location=|pages=|quote=|via=|author1=Markus Enzenberger|author2=Martin Mūller}}</ref>\n\nIn January 2012, the Zen program won 3:1 in a Go match on a 19×19 board with an [[Go ranks and ratings|amateur 2 dan]] player.<ref>{{cite web|url=http://dcook.org/gobet/|title=The Shodan Go Bet|accessdate=2012-05-02}}</ref> [[Google DeepMind|Google Deepmind]] developed the program [[AlphaGo]], which in October 2015 became the first Computer Go program to beat a professional human Go player without [[Go handicaps|handicaps]] on a full-sized 19x19 board.<ref name=\"alphago\"/><ref>{{Cite web|url=http://googleresearch.blogspot.com/2016/01/alphago-mastering-ancient-game-of-go.html|title=Research Blog: AlphaGo: Mastering the ancient game of Go with Machine Learning|last=|first=|date=27 January 2016|website=Google Research Blog|access-date=}}</ref><ref>{{Cite web|url=https://www.bbc.com/news/technology-35420579|title=Google achieves AI 'breakthrough' by beating Go champion|last=|first=|date=27 January 2016|website=BBC News|access-date=}}</ref> In March 2016, AlphaGo was awarded an honorary 9-dan (master) level in 19×19 Go for defeating Lee Sedol in [[AlphaGo versus Lee Sedol|a five-game match]] with a final score of four games to one.<ref>{{Cite web|url=https://www.youtube.com/watch?v=vFr3K2DORc8&t=1h57m|title=Match 1 - Google DeepMind Challenge Match: Lee Sedol vs AlphaGo|last=|first=|date=9 March 2016|website=Youtube|access-date=}}</ref> AlphaGo represents a significant improvement over previous Go programs as well as a milestone in [[machine learning]] as it uses Monte Carlo tree search with [[artificial neural network]]s (a [[deep learning]] method) for policy (move selection) and value, giving it efficiency far surpassing previous programs.<ref>{{Cite web|url=http://www.zdnet.com/article/google-alphago-ai-clean-sweeps-european-go-champion/|title=Google AlphaGo AI clean sweeps European Go champion|last=|first=|date=28 January 2016|website=ZDNet|access-date=}}</ref>\n\nMonte Carlo tree search has also been used in programs that play other [[board game]]s (for example [[Hex (board game)|Hex]],<ref>{{cite journal|author1=Broderick Arneson |author2=Ryan Hayward |author3=Philip Henderson |title=MoHex Wins Hex Tournament|journal=ICGA Journal|volume=32|issue=2|pages=114–116|date=June 2009|url=http://webdocs.cs.ualberta.ca/~hayward/papers/rptPamplona.pdf|doi=10.3233/ICG-2009-32218 }}</ref> [[Havannah]],<ref>{{cite book|author=Timo Ewalds|title=Playing and Solving Havannah|publisher=Master's thesis, University of Alberta|year=2011|url=http://havannah.ewalds.ca/static/thesis.pdf}}</ref> [[Game of the Amazons]],<ref>{{cite book|author=Richard J. Lorentz|chapter=Amazons Discover Monte-Carlo|pages=13–24|others=H. Jaap van den Herik, Xinhe Xu, Zongmin Ma, Mark H. M. Winands (eds.)|title=Computers and Games, 6th International Conference, CG 2008, Beijing, China, September 29 – October 1, 2008. Proceedings|publisher=Springer|year=2008|isbn=978-3-540-87607-6}}</ref> and [[Arimaa]]<ref>{{cite book|author=Tomáš Kozelek|title=Methods of MCTS and the game Arimaa|publisher=Master's thesis, Charles University in Prague|year=2009|url=http://arimaa.com/arimaa/papers/TomasKozelekThesis/mt.pdf}}</ref>), real-time video games (for instance [[Ms. Pac-Man]]<ref>{{cite journal|author1=Xiaocong Gan |author2=Yun Bao |author3=Zhangang Han |title=Real-Time Search Method in Nondeterministic Game – Ms. Pac-Man|pages=209–222|journal=ICGA Journal|volume=34|issue=4|date=December 2011|doi=10.3233/ICG-2011-34404 }}</ref><ref>{{cite journal|author1=Tom Pepels |author2=Mark H. M. Winands |author3=Marc Lanctot |title=Real-Time Monte Carlo Tree Search in Ms Pac-Man|pages=245–257|journal=IEEE Transactions on Computational Intelligence and AI in Games|volume=6|issue=3|date=September 2014 |doi=10.1109/tciaig.2013.2291577}}</ref> and [[Fable Legends]]<ref>{{cite web|url=https://archives.nucl.ai/recording/tactical-planning-and-real-time-mcts-in-fable-legends/|title= Tactical Planning and Real-time MCTS in Fable Legends|last= Mountain|first=Gwaredd  |date= 2015|access-date= 2019-06-08|quote=..&nbsp;we implemented a simulation based approach, which involved modelling the game play and using MCTS to search the potential plan space. Overall this worked well,&nbsp;...}}</ref>), and nondeterministic games (such as [[skat (card game)|skat]],<ref>{{cite book|author1=Michael Buro |author2=Jeffrey Richard Long |author3=Timothy Furtak |author4=Nathan R. Sturtevant |chapter=Improving State Evaluation, Inference, and Search in Trick-Based Card Games|pages=1407–1413 |others=Craig Boutilier (ed.)|title=IJCAI 2009, Proceedings of the 21st International Joint Conference on Artificial Intelligence, Pasadena, California, USA, July 11–17, 2009 |year=2009 |doi=|citeseerx=10.1.1.150.3077 }}</ref> [[poker]],<ref name=\"cpr\">{{cite journal|author1=Jonathan Rubin |author2=Ian Watson |title=Computer poker: A review|journal=Artificial Intelligence |volume=175|issue=5–6|date=April 2011|doi=10.1016/j.artint.2010.12.005|url=https://web.archive.org/web/20120813081731/https://www.cs.auckland.ac.nz/~jrub001/files/CPReviewPreprintAIJ.pdf|pages=958–987}}</ref> [[Magic: The Gathering]],<ref>{{cite book|author1=C.D. Ward |author2=P.I. Cowling |chapter=Monte Carlo Search Applied to Card Selection in Magic: The Gathering|title=CIG'09 Proceedings of the 5th international conference on Computational Intelligence and Games|publisher=IEEE Press |year=2009 |chapter-url=http://scim.brad.ac.uk/staff/pdf/picowlin/CIG2009.pdf |archiveurl=https://web.archive.org/web/20160528074031/http://scim.brad.ac.uk/staff/pdf/picowlin/CIG2009.pdf |archivedate=2016-05-28}}</ref> or [[Settlers of Catan]]<ref>{{cite book|author1=István Szita |author2=Guillaume Chaslot |author3=Pieter Spronck |chapter=Monte-Carlo Tree Search in Settlers of Catan |pages=21–32 |editor1=Jaap Van Den Herik |editor2=Pieter Spronck |title=Advances in Computer Games, 12th International Conference, ACG 2009, Pamplona, Spain, May 11–13, 2009. Revised Papers |publisher=Springer |year=2010 |isbn=978-3-642-12992-6 |chapter-url=http://ticc.uvt.nl/icga/acg12/proceedings/Contribution100.pdf}}</ref>).\n\n== Principle of operation ==\nThe focus of Monte Carlo tree search is on the analysis of the most promising moves, expanding the [[search tree]] based on [[Monte Carlo method|random sampling]] of the search space.\nThe application of Monte Carlo tree search in games is based on many ''playouts''. In each playout, the game is played out to the very end by selecting moves at random. The final game result of each playout is then used to weight the nodes in the game tree so that better nodes are more likely to be chosen in future playouts.\n\nThe most basic way to use playouts is to apply the same number of playouts after each legal move of the current player, then choose the move which led to the most victories.<ref name=\"Bruegmann\">{{cite book|last=Brügmann|first=Bernd|title=Monte Carlo Go|url=http://www.ideanest.com/vegos/MonteCarloGo.pdf|publisher=Technical report, Department of Physics, Syracuse University|year=1993}}</ref> The efficiency of this method—called ''Pure Monte Carlo Game Search''—often increases with time as more playouts are assigned to the moves that have frequently resulted in the current player's victory according to previous playouts. Each round of Monte Carlo tree search consists of four steps:<ref name=\"chaslot2008\">{{cite journal|author1=G.M.J.B. Chaslot |author2=M.H.M. Winands |author3=J.W.H.M. Uiterwijk |author4=H.J. van den Herik |author5=B. Bouzy |title=Progressive Strategies for Monte-Carlo Tree Search|journal=New Mathematics and Natural Computation|volume=4|issue=3|pages=343–359|year=2008|url=https://dke.maastrichtuniversity.nl/m.winands/documents/pMCTS.pdf|doi=10.1142/s1793005708001094}}</ref>\n* ''Selection'': start from root {{math|''R''}} and select successive child nodes until a leaf node {{math|''L''}} is reached. The root is the current game state and a leaf is any node from which no simulation (playout) has yet been initiated. The section below says more about a way of biasing choice of child nodes that lets the game tree expand towards the most promising moves, which is the essence of Monte Carlo tree search.\n* ''Expansion'': unless {{math|''L''}} ends the game decisively (e.g. win/loss/draw) for either player, create one (or more) child nodes and choose node {{math|''C''}} from one of them. Child nodes are any valid moves from the game position defined by {{math|''L''}}.\n* ''Simulation'': complete one random playout from node {{math|''C''}}. This step is sometimes also called playout or rollout. A playout may be as simple as choosing [[Discrete uniform distribution|uniform random]] moves until the game is decided (for example in chess, the game is won, lost, or drawn).\n* ''Backpropagation'': use the result of the playout to update information in the nodes on the path from {{math|''C''}} to {{math|''R''}}.\n\n[[File:MCTS (English) - Updated 2017-11-19.svg|center|frame|Steps of Monte Carlo tree search]]\n\nThis graph shows the steps involved in one decision, with each node showing the ratio of wins to total playouts from that point in the game tree for the player that node represents.<ref>{{Cite web|url=http://jeffbradberry.com/posts/2015/09/intro-to-monte-carlo-tree-search/|title=Introduction to Monte Carlo Tree Search|last=Bradberry|first=Jeff|date=2015-09-07|website=|access-date=}}</ref> In the Selection diagram, black is about to move. The root node shows there are 11 wins out of 21 playouts for white from this position so far. It complements the total of 10/21 black wins shown along the three black nodes under it, each of which represents a possible black move.\n\nIf white loses the simulation, all nodes along the selection incremented their simulation count (the denominator), but among them only the black nodes were credited with wins (the numerator). If instead white wins, all nodes along the selection would still increment their simulation count, but among them only the white nodes would be credited with wins. In games where draws are possible, a draw causes the numerator for both black and white to be incremented by 0.5 and the denominator by 1. This ensures that during selection, each player's choices expand towards the most promising moves for that player, which mirrors the goal of each player to maximize the value of their move.\n\nRounds of search are repeated as long as the time allotted to a move remains. Then the move with the most simulations made (i.e. the highest denominator) is chosen as the final answer.\n\n== Pure Monte Carlo game search ==\nThis basic procedure can be applied to any game whose positions necessarily have a finite number of moves and finite length. For each position, all feasible moves are determined: ''k'' random games are played out to the very end, and the scores are recorded. The move leading to the best score is chosen. Ties are broken by fair coin flips. Pure Monte Carlo Game Search results in strong play in several games with random elements, as in the game ''[[EinStein würfelt nicht!]]''. It converges to optimal play (as ''k'' tends to infinity) in board filling games with random turn order, for instance in [[Hex (board game)|Hex]] with random turn order.<ref>{{cite arXiv |last1=Peres |first1= Yuval| last2=Schramm| first2=Oded| last3= Sheffield| first3 =Scott | last4 = Wilson | first4=David B. |eprint=math/0508580 |title=Random-Turn Hex and other selection games |date=2006 }}</ref> DeepMind's AlphaZero replaces the simulation step with an evaluation based on a neural network.<ref name=\":0\" />\n\n== Exploration and exploitation ==\nThe main difficulty in selecting child nodes is maintaining some balance between the ''exploitation'' of deep variants after moves with high average win rate and the ''exploration'' of moves with few simulations. The first formula for balancing exploitation and exploration in games, called UCT (''Upper Confidence Bound'' 1 ''applied to trees''), was introduced by [[Levente Kocsis]] and [[Csaba Szepesvári]].<ref name=\"Kocsis-Szepesvari\">{{cite conference |last=Kocsis|first=Levente|last2=Szepesvári|first2=Csaba|title=Bandit based Monte-Carlo Planning|editor-first=Johannes|editor-last=Fürnkranz|editor2-first=Tobias|editor2-last=Scheffer|editor3-first=Myra|editor3-last=Spiliopoulou |booktitle=Machine Learning: ECML 2006, 17th European Conference on Machine Learning, Berlin, Germany, September 18–22, 2006, Proceedings|series=Lecture Notes in Computer Science |volume=4212|publisher=Springer|isbn=3-540-45375-X |pages=282–293|year=2006|doi=10.1007/11871842_29|citeseerx=10.1.1.102.1296}}</ref> UCT is based on the UCB1 formula derived by Auer, Cesa-Bianchi, and Fischer<ref>{{cite journal |last=Auer |first=Peter|last2=Cesa-Bianchi|first2=Nicolò|last3=Fischer|first3=Paul|title=Finite-time Analysis of the Multiarmed Bandit Problem|journal=Machine Learning|volume=47|issue=2/3|pages=235–256 |year=2002 |url=http://moodle.technion.ac.il/pluginfile.php/192340/mod_resource/content/0/UCB.pdf|doi=10.1023/a:1013689704352}}{{dead link|date=February 2018 |bot=InternetArchiveBot |fix-attempted=yes }}</ref> and the provably convergent AMS (Adaptive Multi-stage Sampling) algorithm first applied to multi-stage decision making models (specifically, [[Markov Decision Processes]]) by Chang, Fu, Hu, and Marcus.<ref name=\"Chang2005\">{{cite journal |last=Chang|first=Hyeong Soo |last2=Fu|first2=Michael C.|last3=Hu|first3=Jiaqiao|last4=Marcus|first4=Steven I.|title=An Adaptive Sampling Algorithm for Solving Markov Decision Processes|journal=Operations Research |volume=53|pages=126–139 |year=2005 |url=http://scholar.rhsmith.umd.edu/sites/default/files/mfu/files/cfhm05.pdf?m=1449834091|doi=10.1287/opre.1040.0145}}</ref> Kocsis and Szepesvári recommend to choose in each node of the game tree the move for which the expression <math>\\frac{w_i}{n_i} + c\\sqrt{\\frac{\\ln N_i}{n_i}}</math> has the highest value. In this formula:\n* {{math|''w''<sub>''i''</sub>}} stands for the number of wins for the node considered after the {{math|''i''}}-th move\n* {{math|''n''<sub>''i''</sub>}} stands for the number of simulations for the node considered after the {{math|''i''}}-th move\n* {{math|''N''<sub>''i''</sub>}} stands for the total number of simulations after the {{math|''i''}}-th move ran by the parent node of the one considered\n* {{math|''c''}} is the exploration parameter—theoretically equal to {{math|{{radic|2}}}}; in practice usually chosen empirically\n\nThe first component of the formula above corresponds to exploitation; it is high for moves with high average win ratio. The second component corresponds to exploration; it is high for moves with few simulations.\n\nMost contemporary implementations of Monte Carlo tree search are based on some variant of UCT that traces its roots back to the AMS simulation optimization algorithm for estimating the value function in finite-horizon [[Markov Decision Processes]] (MDPs) introduced by Chang et al.<ref name=\"Chang2005\" /> (2005) in [[Operations Research]]. (AMS was the first work to explore the idea of UCB-based exploration and exploitation in constructing sampled/simulated (Monte Carlo) trees and was the main seed for UCT.<ref name=\"changORMStoday\">{{cite journal|author1=Hyeong Soo Chang |author2=Michael Fu |author3=Jiaqiao Hu|author4=Steven I. Marcus |title=Google DeepMind's Alphago: O.R.'s unheralded role in the path-breaking achievement|journal=ORMS Today|volume=45|issue=5|pages=24–29|year=2016|url=https://www.informs.org/ORMS-Today/Public-Articles/October-Volume-43-Number-5}}</ref>)\n\n== Advantages and disadvantages ==\nAlthough it has been proven that the evaluation of moves in Monte Carlo tree search converges to [[minimax]],<ref>{{cite book|last=Bouzy|first=Bruno|chapter=Old-fashioned Computer Go vs Monte-Carlo Go|title=IEEE Symposium on Computational Intelligence and Games, April 1–5, 2007, Hilton Hawaiian Village, Honolulu, Hawaii|chapter-url=http://ewh.ieee.org/cmte/cis/mtsc/ieeecis/tutorial2007/Bruno_Bouzy_2007.pdf}}</ref> the basic version of Monte Carlo tree search converges very slowly. However Monte Carlo tree search does offer significant advantages over [[alpha–beta pruning]] and similar algorithms that minimize the search space.\n\nIn particular, pure Monte Carlo tree search does not need an explicit [[evaluation function]]. Simply implementing the game's mechanics is sufficient to explore the search space (i.e. the generating of allowed moves in a given position and the game-end conditions). As such, Monte Carlo tree search can be employed in games without a developed theory or in [[general game playing]].\n\nThe game tree in Monte Carlo tree search grows asymmetrically as the method concentrates on the more promising subtrees. Thus{{dubious|date=June 2019}} it achieves better results than classical algorithms in games with a high [[branching factor]].\n\nMoreover, Monte Carlo tree search can be interrupted at [[Anytime algorithm|any time]] yielding the most promising move already found.\n\nA disadvantage is that, in a critical position against an expert player, there may be a single branch which leads to a loss. Because this is not easily found at random, the search may not \"see\" it and will not take it into account. It is believed that this may have been part of the reason for [[AlphaGo versus Lee Sedol|AlphaGo's loss in its fourth game against Lee Sedol]]. In essence, the search attempts to prune sequences which are less relevant. In some cases, a play can lead to a very specific line of play which is significant, but which is overlooked when the tree is pruned, and this outcome is therefore \"off the search radar\".<ref>{{cite web|url=https://gogameguru.com/lee-sedol-defeats-alphago-masterful-comeback-game-4/|title=Lee Sedol defeats AlphaGo in masterful comeback - Game 4|publisher=Go Game Guru|access-date=2017-07-04|archive-url=https://web.archive.org/web/20161116082508/https://gogameguru.com/lee-sedol-defeats-alphago-masterful-comeback-game-4/|archive-date=2016-11-16|dead-url=yes}}</ref>\n\n== Improvements ==\nVarious modifications of the basic Monte Carlo tree search method have been proposed to shorten the search time. Some employ domain-specific expert knowledge, others do not.\n\nMonte Carlo tree search can use either ''light'' or ''heavy'' playouts. Light playouts consist of random moves while heavy playouts apply various heuristics to influence the choice of moves.<ref>Swiechowski, M.; Mandziuk, J., \"Self-Adaptation of Playing Strategies in General Game Playing\" (2010), ''IEEE Transactions on Computational Intelligence and AI in Games'', doi: 10.1109/TCIAIG.2013.2275163, http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6571225&isnumber=4804729</ref> These heuristics may employ the results of previous playouts (e.g. the Last Good Reply heuristic<ref>{{cite journal|last=Drake|first=Peter|title=The Last-Good-Reply Policy for Monte-Carlo Go|journal=ICGA Journal|volume=32|issue=4|pages=221–227|date=December 2009|doi=10.3233/ICG-2009-32404}}</ref>) or expert knowledge of a given game. For instance, in many Go-playing programs certain stone patterns in a portion of the board influence the probability of moving into that area.<ref name=\"Gelly-et-al\">{{cite book|author1=Sylvain Gelly |author2=Yizao Wang |author3=Rémi Munos |author4=Olivier Teytaud |title=Modification of UCT with Patterns in Monte-Carlo Go|date=November 2006|publisher=Technical report, INRIA|url=http://hal.inria.fr/docs/00/11/72/66/PDF/MoGoReport.pdf}}</ref> Paradoxically, playing suboptimally in simulations sometimes makes a Monte Carlo tree search program play stronger overall.<ref>{{cite book|author1=Seth Pellegrino |author2=Peter Drake |chapter=Investigating the Effects of Playout Strength in Monte-Carlo Go|pages=1015–1018|others=Hamid R. Arabnia, David de la Fuente, Elena B. Kozerenko, José Angel Olivas, Rui Chang, Peter M. LaMonica, Raymond A. Liuzzi, Ashu M. G. Solo (eds.)|title=Proceedings of the 2010 International Conference on Artificial Intelligence, ICAI 2010, July 12–15, 2010, Las Vegas Nevada, USA|publisher=CSREA Press|year=2010|isbn=978-1-60132-148-0}}</ref>\n\n[[File:Mogo-hane.svg|frame|center|Patterns of ''hane'' (surrounding opponent stones) used in playouts by the MoGo program. It is advantageous for both black and white to put a stone on the middle square, except the rightmost pattern where it favors black only.<ref name=\"Gelly-et-al\"/>]]\n\nDomain-specific knowledge may be employed when building the game tree to help the exploitation of some variants. One such method assigns nonzero ''priors'' to the number of won and played simulations when creating each child node, leading to artificially raised or lowered average win rates that cause the node to be chosen more or less frequently, respectively, in the selection step.<ref name=\"Gelly-Silver\">{{cite book|author1=Sylvain Gelly |author2=David Silver |chapter=Combining Online and Offline Knowledge in UCT|pages=273–280|others=Zoubin Ghahramani (ed.)|title=Machine Learning, Proceedings of the Twenty-Fourth International Conference (ICML 2007), Corvallis, Oregon, USA, June 20–24, 2007|publisher=ACM|year=2007|isbn=978-1-59593-793-3|chapter-url=http://www.machinelearning.org/proceedings/icml2007/papers/387.pdf}}</ref> A related method, called ''progressive bias'', consists in adding to the UCB1 formula a <math>\\frac{b_i}{n_i}</math> element, where {{math|''b''<sub>''i''</sub>}} is a heuristic score of the  {{math|''i''}}-th move.<ref name=\"chaslot2008\"/>\n\nThe basic Monte Carlo tree search collects enough information to find the most promising moves only after many rounds; until then its moves are essentially random. This exploratory phase may be reduced significantly in a certain class of games using RAVE (''Rapid Action Value Estimation'').<ref name=\"Gelly-Silver\"/> In these games, permutations of a sequence of moves lead to the same position. Typically, they are board games in which a move involves placement of a piece or a stone on the board. In such games the value of each move is often only slightly influenced by other moves.\n\nIn RAVE, for a given game tree node {{math|''N''}}, its child nodes {{math|''C''<sub>''i''</sub>}} store not only the statistics of wins in playouts started in node {{math|''N''}} but also the statistics of wins in all playouts started in node {{math|''N''}} and below it, if they contain move {{math|''i''}} (also when the move was played in the tree, between node {{math|''N''}} and a playout). This way the contents of tree nodes are influenced not only by moves played immediately in a given position but also by the same moves played later.\n\n[[File:Tic-tac-toe-RAVE-English.svg|frame|center|RAVE on the example of tic-tac-toe. In red nodes, the RAVE statistics will be updated after the b1-a2-b3 simulation.]]\n\nWhen using RAVE, the selection step selects the node, for which the modified UCB1 formula <math>(1-\\beta(n_i, \\tilde{n}_i))\\frac{w_i}{n_i} + \\beta(n_i, \\tilde{n}_i)\\frac{\\tilde{w}_i}{\\tilde{n}_i} + c\\sqrt{\\frac{\\ln t}{n_i}}</math> has the highest value. In this formula, <math>\\tilde{w}_i</math> and <math>\\tilde{n}_i</math> stand for the number of won playouts containing move {{math|''i''}} and the number of all playouts containing move {{math|''i''}}, and the <math>\\beta(n_i, \\tilde{n}_i)</math> function should be close to one and to zero for relatively small and relatively big {{math|''n''<sub>''i''</sub>}} and <math>\\tilde{n}_i</math>, respectively. One of many formulas for <math>\\beta(n_i, \\tilde{n}_i)</math>, proposed by D. Silver,<ref>{{cite book|author=David Silver|title=Reinforcement Learning and Simulation-Based Search in Computer Go|publisher=PhD thesis, University of Alberta |year=2009 |url=http://papersdb.cs.ualberta.ca/~papersdb/uploaded_files/1029/paper_thesis.pdf}}</ref> says that in balanced positions one can take <math>\\beta(n_i, \\tilde{n}_i)=\\frac{\\tilde{n}_i}{n_i+\\tilde{n}_i+4b^2 n_i\\tilde{n}_i}</math>, where {{math|''b''}} is an empirically chosen constant.\n\nHeuristics used in Monte Carlo tree search often require many parameters. There are automated methods to tune the parameters to maximize the win rate.<ref>{{cite book|author=[[Rémi Coulom]]|chapter=CLOP: Confident Local Optimization for Noisy Black-Box Parameter Tuning|title=ACG 2011: Advances in Computer Games 13 Conference, Tilburg, the Netherlands, November 20–22|chapter-url=http://remi.coulom.free.fr/CLOP/}}</ref>\n\nMonte Carlo tree search can be concurrently executed by many [[thread (computing)|threads]] or [[process (computing)|processes]]. There are several fundamentally different methods of its [[parallel computing|parallel]] execution:<ref>{{cite book|author=Guillaume M.J-B. Chaslot, Mark H.M. Winands, [[Jaap van den Herik]]|chapter=Parallel Monte-Carlo Tree Search|pages=60–71|others=H. Jaap van den Herik, Xinhe Xu, Zongmin Ma, Mark H. M. Winands (eds.)|title=Computers and Games, 6th International Conference, CG 2008, Beijing, China, September 29 – October 1, 2008. Proceedings|publisher=Springer|year=2008|isbn=978-3-540-87607-6|chapter-url=https://dke.maastrichtuniversity.nl/m.winands/documents/multithreadedMCTS2.pdf}}</ref>\n* ''Leaf parallelization'', i.e. parallel execution of many playouts from one leaf of the game tree.\n* ''Root parallelization'', i.e. building independent game trees in parallel and making the move basing on the root-level branches of all these trees.\n* ''Tree parallelization'', i.e. parallel building of the same game tree, protecting data from simultaneous writes either with one, global [[mutex]], with more mutexes, or with [[non-blocking algorithm|non-blocking synchronization]].<ref>{{cite book|author1=Markus Enzenberger |author2=Martin Müller |chapter=A Lock-free Multithreaded Monte-Carlo Tree Search Algorithm |pages=14–20 |editor1=Jaap Van Den Herik |editor2=Pieter Spronck |title=Advances in Computer Games: 12th International Conference, ACG 2009, Pamplona, Spain, May 11–13, 2009, Revised Papers |publisher=Springer |year=2010 |chapter-url=http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=02CC0F88A12A3CCE44F0CD139ADA7AF5?doi=10.1.1.161.1984&rep=rep1&type=pdf |isbn=978-3-642-12992-6}}</ref>\n\n== See also ==\n* [[AlphaGo]], a Go program using Monte Carlo tree search, [[reinforcement learning]] and [[deep learning]].\n* [[AlphaGo Zero]], an updated Go program using Monte Carlo tree search, [[reinforcement learning]] and [[deep learning]].\n* [[AlphaZero]], a generalized version of AlphaGo Zero using Monte Carlo tree search, [[reinforcement learning]] and [[deep learning]].\n* [[Leela Chess Zero]], a [[free software]] implementation of AlphaZero's methods to chess, which is currently among the leading chess playing programs.\n\n== References ==\n{{Reflist|30em}}\n\n== Bibliography ==\n* {{cite journal|author1=Cameron Browne |author2=Edward Powley |author3=Daniel Whitehouse |author4=Simon Lucas |author5=Peter I. Cowling |author6=Philipp Rohlfshagen |author7=Stephen Tavener |author8=Diego Perez |author9=Spyridon Samothrakis |author10=Simon Colton |title=A Survey of Monte Carlo Tree Search Methods|journal=IEEE Transactions on Computational Intelligence and AI in Games|volume=4|issue=1|pages=1–43 |date=March 2012|doi=10.1109/tciaig.2012.2186810|citeseerx=10.1.1.297.3086 }}\n\n[[Category:Combinatorial game theory]]\n[[Category:Heuristic algorithms]]\n[[Category:Monte Carlo methods]]\n[[Category:Optimal decisions]]"
    },
    {
      "title": "MPMC",
      "url": "https://en.wikipedia.org/wiki/MPMC",
      "text": "{{Infobox software\n| name                  = Massively Parallel Monte Carlo\n| logo                  = File:MPMC logo.png| logo alt              = | logo caption          = MPMC logo\n| screenshot            =\n| caption               =\n| collapsible           =\n| author                = Jon Belof (currently at [[Lawrence Livermore National Laboratory]]),<br/>MPMC development team, [[University of South Florida]]\n| developer             = University of South Florida\n| released              = {{Start date and age|2007}}\n| latest release version= \n| latest release date   = {{Start date and age|2012}}\n| latest preview version= \n| latest preview date   = \n| frequently updated    =\n| programming language  = [[C (programming language)|C]], [[C++]]\n| operating system      = [[Linux]], [[macOS]], all [[Unix]]\n| platform              = [[IA-32]], [[x86-64]], [[NVidia]] [[CUDA]]\n| size                  =\n| language              = English\n| status                = Active\n| genre                 = [[Monte Carlo method|Monte Carlo]] simulation\n| license               = [[GNU General Public License|GPL]] 3\n| website               = {{URL|github.com/mpmccode}}\n}}\n\n'''Massively Parallel Monte Carlo''' ('''MPMC''') is a [[Monte Carlo method]] package primarily designed to simulate liquids, molecular interfaces, and functionalized [[nanoscale]] materials.  It was developed originally by Jon Belof and is now maintained by a group of researchers in the Department of Chemistry<ref>[http://chemistry.usf.edu/ University of South Florida, Department of Chemistry]</ref> and SMMARTT Materials Research Center<ref>[http://chemistry.usf.edu/smmartt/ University of South Florida, SMMARTT Materials Research Center]</ref> at the [[University of South Florida]].<ref name=mpmcwww>{{cite web |url= https://github.com/mpmccode/mpmc |title= MPMC |publisher= GitHub |date= 9 April 2015 |accessdate= 9 April 2015}}</ref>  MPMC has been applied to the scientific research challenges of [[nanomaterials]] for [[clean energy]], [[carbon sequestration]], and molecular detection.  Developed to run efficiently on the most powerful supercomputing platforms, MPMC can scale to extremely large numbers of CPUs or GPUs (with support provided for [[NVidia]]'s [[CUDA]] architecture<ref name=mpmccuda>{{cite journal |author1=Brant Tudor |author2=Brian Space |title= Solving the Many-Body Polarization Problem on GPUs: Application to MOFs |journal= Journal of Computational Science Education |year= 2013 |volume= 4 |issue= 1 |pages= 30–34 |doi=10.22369/issn.2153-4136/4/1/5}}</ref>).  Since 2012, MPMC has been released as an [[open-source software]] project under the [[GNU General Public License]] (GPL) version 3, and the [https://github.com/mpmccode/mpmc repository] is hosted on [[GitHub]].\n\n==History==\nMPMC was originally written by Jon Belof (then at the University of South Florida) in 2007 for applications toward the development of [[nanomaterials]] for hydrogen storage.<ref name=h2jacs>{{cite journal |author= Belof, Jonathan L., Abraham C. Stern, Mohamed Eddaoudi and Brian Space |title= On the mechanism of hydrogen storage in a metal-organic framework material |journal= Journal of the American Chemical Society |year= 2007 |volume= 129 |issue= 49 |pages= 15202–15210 |doi= 10.1021/ja0737164 |pmid=17999501}}</ref>  Since then MPMC has been released as an open source project and been extended to include a number of simulation methods relevant to statistical physics. The code is now further maintained by a group of researchers (Christian Cioce, Keith McLaughlin, Brant Tudor, Adam Hogan and Brian Space) in the Department of Chemistry and SMMARTT Materials Research Center at the [[University of South Florida]].\n\n==Features==\nMPMC is optimized for the study of nanoscale interfaces. MPMC supports simulation of Coulomb and Lennard-Jones systems, many-body polarization,<ref name=mpmcmb>{{cite journal |author1=Keith McLaughlin |author2=Christian R. Cioce |author3=Tony Pham |author4=Jonathan L. Belof |author5=Brian Space |title= Efficient calculation of many-body induced electrostatics in molecular systems |journal= The Journal of Chemical Physics |year= 2013 |volume= 139 |pages= 184112 |doi= 10.1063/1.4829144|bibcode=2013JChPh.139r4112M }}</ref> coupled-dipole van der Waals,<ref name=mpmcvdw>{{cite journal |author1=Keith McLaughlin |author2=Christian R. Cioce |author3=Jonathan L. Belof |author4=Brian Space |title= A Molecular H2 Potential for Heterogeneous Simulations including Polarization and Many-Body van der Waals Interactions |journal= Journal of Chemical Physics |year= 2012 |volume= 136 |pages= 194302 |doi= 10.1063/1.4717705|bibcode=2012JChPh.136s4302M }}</ref> quantum rotational statistics,<ref name=qmrot>{{cite journal |author1=Tony Pham |author2=Katherine A. Forrest |author3=Adam Hogan |author4=Keith McLaughlin |author5=Jonathan L. Belof |author6=Juergen Eckert |author7=Brian Space |title= Simulations of Hydrogen Sorption in rht-MOF-1: Identifying the Binding Sites Through Explicit Polarization and Quantum Rotation Calculations |journal= Journal of Materials Chemistry A |year= 2014 |volume= 2 |pages= 2088–2100 |doi= 10.1039/C3TA14591C}}</ref> semi-classical quantum effects, advanced [[importance sampling]] methods relevant to fluids, and numerous tools for the development of intermolecular potentials.<ref name=belofh2potential>{{cite journal |author1=Jonathan L. Belof |author2=Abraham C. Stern |author3=Brian Space |last-author-amp=yes |title= An Accurate and Transferable Intermolecular Diatomic Hydrogen Potential for Condensed Phase Simulation |journal= Journal of Chemical Theory and Computation |year= 2008 |volume= 4 |issue= 8 |pages= 1332–1337 |doi= 10.1021/ct800155q}}</ref><ref name=mclaughlinh2potential>{{cite journal |author1=Keith McLaughlin |author2=Christian R. Cioce |author3=Jonathan L. Belof |author4=Brian Space |last-author-amp=yes |title= A molecular H2 potential for heterogeneous simulations including polarization and many-body van der Waals interactions |journal= The Journal of Chemical Physics |year= 2012 |volume= 136 |pages= 194302 |doi= 10.1063/1.4717705|bibcode=2012JChPh.136s4302M }}</ref><ref name=ciocen2potential>{{cite journal |author1=Christian R. Cioce |author2=Keith McLaughlin |author3=Jonathan L. Belof |author4=Brian Space |last-author-amp=yes |title= A Polarizable and Transferable PHAST N2 Potential for Use in Materials Simulation |journal= Journal of Chemical Theory and Computation |year= 2013 |volume= 9 |issue= 12 |pages= 5550–5557 |doi= 10.1021/ct400526a}}</ref><ref name=mullenco2potential>{{cite journal |author1=Ashley L. Mullen |author2=Tony Pham |author3=Katherine A. Forrest |author4=Christian R. Cioce |author5=Keith McLaughlin |author6=Brian Space |last-author-amp=yes |title= A Polarizable and Transferable PHAST CO2 Potential for Materials Simulation |journal= Journal of Chemical Theory and Computation |year= 2013 |volume= 9 |issue= 12 |pages= 5421–5429 |doi= 10.1021/ct400549q}}</ref> The code is designed to efficiently run on [[high-performance computing]] resources, including the network of some of the most powerful supercomputers in the world made available through the [[National Science Foundation]] supported project [[Extreme Science and Engineering Discovery Environment]] (XSEDE).<ref>[https://www.xsede.org/ XSEDE]</ref><ref>https://www.xsede.org/documents/10157/169907/X13_highlights.pdf</ref>\n\n==Applications==\nMPMC has been applied to the scientific challenges of discovering nanomaterials for clean energy applications,<ref name= mpmch2pred>{{cite journal |author= Jonathan L. Belof, Abraham C. Stern and Brian Space |title= A Predictive Model of Hydrogen Sorption for Metal−Organic Materials |journal= The Journal of Physical Chemistry C |year= 2009 |volume= 113 |issue= 21 |pages= 9316–9320 |doi= 10.1021/jp901988e}}</ref> capturing and sequestering carbon dioxide,<ref name=mpmcco2>{{cite journal |author1=Tony Pham |author2=Katherine A. Forrest |author3=Keith McLaughlin |author4=Brant Tudor |author5=Patrick Nugent |author6=Adam Hogan |author7=Ashley Mullen |author8=Christian R. Cioce |author9=Michael J. Zaworotko |author10=Brian Space |title= Theoretical Investigations of CO2 and H2 Sorption in an Interpenetrated Square-Pillared Metal–Organic Material |journal= The Journal of Physical Chemistry C |year= 2013 |volume= 117 |issue= 19 |pages= 9970–9982 |doi= 10.1021/jp402764s}}</ref> designing tailored organometallic materials for chemical weapons detection,<ref name= dimp>{{cite journal |author1=William A. Maza |author2=Carissa M. Vetromile |author3=Chungsik Kim |author4=Xue Xu |author5=X. Peter Zhang |author6=Randy W. Larsen |last-author-amp=yes |title= Spectroscopic Investigation of the Noncovalent Association of the Nerve Agent Simulant Diisopropyl Methylphosphonate (DIMP) with Zinc(II) Porphyrins |journal= Journal of Physical Chemistry A |year= 2013 |volume= 117 |issue= 44 |pages= 11308–11315 |doi=10.1021/jp405976h|bibcode=2013JPCA..11711308M }}</ref> and quantum effects in cryogenic hydrogen for spacecraft propulsion.<ref name=nasareport>{{cite report |author1=David L. Block |author2=Ali T-Raissi |lastauthoramp=yes |date= February 2009 |title= NASA Report: Hydrogen Research at Florida Universities |url= https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090021319.pdf |publisher= NASA |page= |docket= NASA/CR2009-215441 |accessdate= }}</ref>  Also simulated and published have been the solid, liquid, supercritical, and gaseous states of matter of [[nitrogen]] (N<sub>2</sub>)<ref name=\"ciocen2potential\"/> and [[carbon dioxide]] (CO<sub>2</sub>).<ref name=\"mullenco2potential\"/>\n\n==See also==\n{{Portal|Free and open-source software}}\n{{Columns-list|colwidth=30em|\n* [[Statistical physics]]\n* [[Monte Carlo method in statistical physics]]\n* [[Metropolis–Hastings algorithm]]\n* [[Simulated annealing]]\n* [[Direct simulation Monte Carlo]]\n* [[Dynamic Monte Carlo method]]\n* [[Kinetic Monte Carlo]]\n* [[List of software for Monte Carlo molecular modeling]]\n* [[Comparison of software for molecular mechanics modeling]]\n}}\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{Official website|github.com/mpmccode}}\n\n[[Category:Monte Carlo particle physics software]]\n[[Category:Science software for Linux]]\n[[Category:Computational physics]]\n[[Category:Monte Carlo methods]]\n[[Category:Theoretical chemistry]]\n[[Category:Stochastic models]]\n[[Category:Molecular modelling]]\n[[Category:Free software programmed in C]]"
    },
    {
      "title": "Multicanonical ensemble",
      "url": "https://en.wikipedia.org/wiki/Multicanonical_ensemble",
      "text": "In [[statistics]] and [[physics]], '''multicanonical ensemble''' (also called '''multicanonical sampling''' or '''flat histogram''') is a [[ Markov chain Monte Carlo]] sampling technique that uses the [[Metropolis–Hastings algorithm]] to compute [[integral]]s where the integrand has a rough landscape with multiple [[Local minimum|local minima]]. It samples states according to the inverse of the [[density of states]],<ref name=Berg/> which has to be known a priori or be computed using other techniques like the [[Wang and Landau algorithm]].<ref name=Landau/> Multicanonical sampling is an important technique for [[spin (physics)|spin]] systems like the [[Ising model]] or [[spin glass]]es.<ref name=Berg/><ref name=Newmann/><ref name=Dayal/>\n\n==Motivation==\n\nIn systems with a large number of degrees of freedom, like [[spin (physics)|spin]] systems, [[Monte Carlo integration]] is required. In this integration, [[importance sampling]] and in particular the [[Metropolis algorithm]], is a very important technique.<ref name=Newmann/> However, the Metropolis algorithm samples states according to <math>\\exp(-\\beta E)</math> where beta is the inverse of the temperature. This means that an [[energy barrier]] of <math>\\Delta E</math> on the energy spectrum is exponentially difficult to overcome.<ref name=Berg/> Systems with multiple local energy minima like the [[Potts model]] become hard to sample as the algorithm gets stuck in the system's local minima.<ref name=Newmann/> This motivates other approaches, namely, other sampling distributions.\n\n==Overview==\n\nMulticanonical ensemble uses the Metropolis–Hastings algorithm with a sampling distribution given by the inverse of the density of states of the system, contrary to the sampling distribution <math>\\exp(-\\beta E)</math> of the Metropolis algorithm.<ref name=Berg/> With this choice, on average, the number of states sampled at each energy is constant, i.e. it is a simulation with a \"flat histogram\" on energy. This leads to an algorithm for which the energy barriers are no longer difficult to overcome. Another advantage over the Metropolis algorithm is that the sampling is independent of the temperature of the system, which means that one simulation allows the estimation of thermodynamical variables for all temperatures (thus the name \"multicanonical\": several temperatures). This is a great improvement in the study of first order [[phase transition]]s.<ref name=Berg/>\n\nThe biggest problem in performing a multicanonical ensemble is that the density of states has to be known ''a priori''.<ref name=Landau/><ref name=Newmann/> One important contribution to multicanonical sampling was the [[Wang and Landau algorithm]], which asymptotically converges to a multicanonical ensemble while calculating the density of states during the convergence.<ref name=Landau/>\n\nThe multicanonical ensemble is not restricted to physical systems. It can be employed on abstract systems which have a cost function ''F''. By using the density of states with respect to F, the method becomes general for computing higher-dimensional integrals or finding local minima.<ref name=Lee/>\n\n==Motivation==\n\nConsider a system and its phase-space <math>\\Omega</math> characterized by a configuration <math>\\boldsymbol{r}</math> in <math>\\Omega</math> and a \"cost\" function ''F'' from the system's phase-space to a one-dimensional space <math>\\Gamma</math>: <math>F(\\Omega) = \\Gamma = [\\Gamma_\\min, \\Gamma_\\max]</math>, the spectrum of ''F''.\n\n{| class=\"wikitable1\" width=300px\n|-\n|\n{{show\n|example:\n|\nThe [[Ising model]] with ''N'' sites is an example of such a system; the phase-space is a discrete phase-space defined by all possible configurations of ''N'' spins <math>\\boldsymbol{r} = (\\sigma_1, \\ldots, \\sigma_i, \\ldots, \\sigma_N)</math> where <math>\\sigma_i\\in\\{-1,1\\}</math>. The cost function is the [[Hamiltonian (quantum mechanics)|Hamiltonian]] of the system:\n\n: <math>H(\\boldsymbol{r}) = - \\sum_{\\langle i~j\\rangle} J_{ij} (1 - \\sigma_i \\sigma_j),</math>\n\nwhere <math><i,j></math> is the sum over neighborhoods and <math>J_{ij}</math> is the interaction matrix.\n\nThe energy spectrum is <math>\\Gamma = [E_\\min, E_\\max]</math> which, in this case, depends on the particular <math>J_{ij}</math> used. If all <math>J_{ij}</math> are 1 (the ferromagnetic Ising model), <math>E_\\min = 0</math> (e.g. all spins are 1.) and <math>E_\\max = 2 D N </math> (half spins are up, half spins are down). Also notice that in this system, <math>\\Gamma \\in \\mathbb{Z}</math>\n\n}}\n|}\n\nThe computation of an average quantity <math>\\langle Q\\rangle</math> over the phase-space requires the evaluation of an integral:\n\n: <math>\\langle Q\\rangle = \\int_\\Omega Q(\\boldsymbol{r}) P_r(\\boldsymbol{r}) \\,d\\boldsymbol{r}</math>\n\nwhere <math>P_r(\\boldsymbol{r})</math> is the weight of each state (e.g. <math>P_r(\\boldsymbol{r})=1/V</math> correspond to uniformly distributed states).\n\nWhen ''Q'' does not depend on the particular state but only on the particular F's value of the state <math>F(\\boldsymbol{r}) = F_\\boldsymbol{r}</math>,\nthe formula for <math>\\langle Q\\rangle</math> can be integrated over ''f'' by adding a [[dirac delta function]] and be written as\n\n: <math>\n\\begin{align}\n \\langle Q\\rangle & = \\int_{\\Gamma_\\min}^{\\Gamma_\\max} \\int_\\Omega  Q(F_\\boldsymbol{r}) P_r(F_\\boldsymbol{r}) \\delta(f - F_\\boldsymbol{r}) \\,d\\boldsymbol{r} \\,df \\\\\n & = \\int_{\\Gamma_\\min}^{\\Gamma_\\max} Q(f) \\int_\\Omega \\delta(f - F_\\boldsymbol{r}) P_r(F_\\boldsymbol{r}) \\,d\\boldsymbol{r} \\, df \\\\\n & = \\int_{\\Gamma_\\min}^{\\Gamma_\\max} Q(f) P(f) \\, df \\\\\n\\end{align}\n</math>\n\nwhere\n\n: <math>P(f) = \\int_\\Omega P_r(r)\\delta(f - F(\\boldsymbol{r})) \\,d\\boldsymbol{r}</math>\n\nis the marginal distribution of F.\n\n{| class=\"wikitable1\" width=300px\n|-\n|\n{{show\n|example:\n|\nA system in contact with a heat bath at inverse temperature <math>\\beta</math> is an example for computing this kind of integral. For instance, the mean energy of the system is weighted by the [[Boltzmann factor]]:\n\n:<math>\\langle E\\rangle = \\frac{1}{V}\\int_\\Omega H_\\boldsymbol{r} \\frac{e^{-\\beta H_\\boldsymbol{r}}}{Z} d\\boldsymbol{r}</math>\n\nwhere\n\n: <math>Z = \\frac{1}{V}\\int_\\Omega e^{-\\beta H_\\boldsymbol{r}} d\\boldsymbol{r}.</math>\n\nThe marginal distribution <math>P(E)</math> is given by \n\n: <math>P(E) = \\frac{1}{V}\\int_\\Omega e^{-\\beta H_\\boldsymbol{r}} \\delta(E - H_\\boldsymbol{r}) d\\boldsymbol{r} = \n                         e^{-\\beta E} \\frac{1}{V}\\int_\\Omega \\delta(E - H_\\boldsymbol{r}) d\\boldsymbol{r} = \n                         e^{-\\beta E} \\rho(E)</math>\n\nwhere <math> \\rho(E) </math> is the density of states.\n\nThe average energy <math>\\langle E\\rangle</math> is then given by\n\n: <math>\\langle E\\rangle = \\int_{E_\\min}^{E_\\max} E P(E) \\, dE </math>\n\n}}\n|}\n\nWhen the system has a large number of degrees of freedom, an analytical expression for <math>\\langle Q\\rangle</math> is often hard to obtain, and [[Monte Carlo integration]] is typically employed in the computation of <math>\\langle Q\\rangle</math>. On the simplest formulation, the method chooses ''N'' uniformly distributed states <math>\\boldsymbol{r}_i\\in \\Omega</math>, and uses the [[estimator]]\n\n:<math>\\overline{Q}_N = \\sum_{i = 1}^N Q(\\boldsymbol{r}_i) V P_r(\\boldsymbol{r}_i)</math>\n\nfor computing <math>\\langle Q\\rangle</math> because <math>\\overline{Q}_N</math> converges almost surely to <math>\\langle Q\\rangle</math> by the [[Law_of_large_numbers#Strong_law|strong law of large numbers]]:\n\n:<math>\\lim_{N\\rightarrow\\infty} \\overline{Q}_N = \\langle Q\\rangle.</math>\n\nOne typical problem of this convergence is that the variance of ''Q'' can be very high, which leads to a high computational effort to achieve reasonable results.\n\n{| class=\"wikitable1\" width=300px\n|-\n|\n{{show\n|example\n|\nOn the previous example, the states that mostly contribute to the integral are the ones with low energy. If the states are sampled uniformly, on average, the number of states which are sampled with energy ''E'' is given by the density of states. This density of states can be centered far away from the energy's minima and thus the average can be difficult to obtain.\n\n}}\n|}\n\nTo improve this convergence, the [[Metropolis–Hastings algorithm]] was proposed. Generally, Monte Carlo methods' idea is to use [[importance sampling]] to improve the convergence of the estimator <math>\\overline{Q}_N</math> by sampling states according to an ''arbitrary'' distribution <math>\\pi(\\boldsymbol{r})</math>, and use the appropriate estimator:\n\n: <math>\\overline{Q}_N = \\sum_{i = 1}^N Q(\\boldsymbol{r}_i) \\pi^{-1}(\\boldsymbol{r}_i) P_r(\\boldsymbol{r}_i)</math>.\n\nThis estimator generalizes the estimator of the mean for samples drawn from an arbitrary distribution. Therefore, when <math>\\pi(\\boldsymbol{r})</math> is a uniform distribution, it corresponds the one used on a uniform sampling above.\n\nWhen the system is a physical system in contact with a heat bath, each state <math>\\boldsymbol{r}</math> is weighted according to the [[Boltzmann factor]], <math>P_r(\\boldsymbol{r}_i) \\propto \\exp(-\\beta F_\\boldsymbol{r})</math>.\nIn Monte Carlo, the [[canonical ensemble]] is defined by choosing <math>\\pi(\\boldsymbol{r})</math> to be proportional to <math>P_r(\\boldsymbol{r}_i)</math>. In this situation, the estimator corresponds to a simple arithmetic average:\n:<math>\\overline{Q}_N = \\frac{1}{N} \\sum_{i = 1}^N Q(\\boldsymbol{r}_i)</math>\n\nHistorically, this occurred because the [[Equation of State Calculations by Fast Computing Machines|original idea]]<ref name=Metropolis/> was to use [[Metropolis–Hastings algorithm]] to compute averages on a system in contact with a heat bath where the weight is given by the Boltzmann factor, <math>P(\\boldsymbol{x}) \\propto \\exp(-\\beta E(\\boldsymbol{r}))</math>.<ref name=Newmann/>\n\nWhile the it is often the case that the sampling distribution <math>\\pi</math> is chosen to be the weight distribution <math>P_r</math>, this does not need to be the case.\nOne situation where the canonical ensemble is not an efficient choice is when it takes an arbitrarily long time to converge.<ref name=Berg/>\nOne situation where this happens is when the function F has multiple local minima.\nThe computational cost for the algorithm to leave a specific region with a local minimum exponentially increases with the cost function's value of the minimum. That is, the deeper the minimum, the more time the algorithm spends there, and the harder it will be to leave (exponentially growing with the depth of the local minimum).\n\nOne way to avoid becoming stuck in local minima of the cost function is to make the sampling technique \"invisible\" to local minima. This is the basis of the multicanonical ensemble.\n\n==Multicanonical ensemble==\n\nThe multicanonical ensemble is defined by choosing the sampling distribution to be\n\n: <math>\\pi(\\boldsymbol{r}) \\propto \\frac{1}{P(F_\\boldsymbol{r})}</math>\n\nwhere <math> P(f)</math> is the marginal distribution of F defined above.\nThe consequence of this choice is that the average number of samples with a given value of ''f'', m(f), is given by\n\n: <math> m(f) = \\int_\\Omega \\delta(f - F_\\boldsymbol{r}) \\pi(\\boldsymbol{r}) P_r(\\boldsymbol{r})\\,d\\boldsymbol{r} \\propto \\int_\\Omega \\delta(f - F_\\boldsymbol{r}) P_r(\\boldsymbol{r}) \\frac{1}{P(F_\\boldsymbol{r})} d\\boldsymbol{r} = \\frac{1}{P(f)} \\int_\\Omega \\delta(f - F_\\boldsymbol{r}) P_r(\\boldsymbol{r}) d\\boldsymbol{r} = 1</math>\n\nthat is, the average number of samples ''does not'' depend on ''f'': all costs ''f'' are equally sampled regardless of whether they are more or less probable. \nThis motivates the name \"flat-histogram\". For systems in contact with a heat bath, the sampling is independent of the temperature and one simulation allows to study all temperatures.\n\n{| class=\"wikitable1\" width=300px\n|-\n|\n{{show\n|example:\n|\nOn the ferromagnetic [[Ising model]] with ''N'' sites (exemplified on previous section), the density of states can be analytically computed. In this case, a multicanonical ensemble can be used to compute any other quantity ''Q'' by sampling the system according to <math>P(\\boldsymbol{r})</math> and using the proper estimator <math>\\overline{Q}</math> defined on the previous section.\n\n}}\n|}\n\n==Tunneling time and critical slowing down==\n\nLike in any other Monte Carlo method, there are correlations of the samples being drawn from <math>P(\\boldsymbol{r})</math>. A typical measurement of the correlation is the ''tunneling time''. The tunneling time is defined by the number of Markov steps (of the Markov chain) the simulation needs to perform a round-trip between the minimum and maximum of the spectrum of ''F''. One motivation to use the tunneling time is that when it crosses the spectra, it passes through the region of the maximum of the density of states, thus de-correlating the process. On the other hand using round-trips ensures that the system visits all the spectrum.\n\nBecause the histogram is flat on the variable ''F'', a multicanonic ensemble can be seen as a diffusion process (i.e. a [[random walk]]) on the one-dimensional line of ''F'' values. [[Detailed balance]] of the process dictates that there is no [[stochastic drift|drift]] on the process.<ref name=Robert/> This implies that the tunneling time, in local dynamics, should scale as a diffusion process, and thus the tunneling time should scale quadratically with the size of the spectrum, ''N'':\n\n:<math>\\tau_{tt} \\propto N^2</math>\n\nHowever, in some systems (the Ising model being the most paradigmatic), the scaling suffers from critical slowing down: it is <math>N^{2+z}</math> where <math>z>0</math> depends on the particular system.<ref name=Dayal/>\n\nNon-local dynamics were developed to improve the scaling to a quadratic scaling<ref name=Wolff/> (see the [[Wolff algorithm]]), beating the critical slowing down. However, it is still an open question whether there is a local dynamics that does not suffer from critical slowing down in spin systems like the Ising model.\n\n==References==\n\n{{Reflist|\nrefs=\n<ref name=Berg>{{Cite journal | last1 = Berg | first1 = B. | last2 = Neuhaus | first2 = T. | doi = 10.1103/PhysRevLett.68.9 | title = Multicanonical ensemble: A new approach to simulate first-order phase transitions | journal = Physical Review Letters | volume = 68 | issue = 1 | pages = 9–12 | year = 1992 | pmid =  10045099| pmc = |arxiv = hep-lat/9202004 |bibcode = 1992PhRvL..68....9B }}</ref>\n<ref name=Landau>{{Cite journal | last1 = Wang | first1 = F. | last2 = Landau | first2 = D. | doi = 10.1103/PhysRevLett.86.2050 | title = Efficient, Multiple-Range Random Walk Algorithm to Calculate the Density of States | journal = Physical Review Letters | volume = 86 | issue = 10 | pages = 2050–2053 | year = 2001 | pmid =  11289852| pmc = |arxiv = cond-mat/0011174 |bibcode = 2001PhRvL..86.2050W }}</ref>\n<ref name=Newmann>{{cite book\n |title= Monte Carlo Methods in Statistical Physics\n |last1=Newmann |first1=M E J\n |last2=Barkema |first2=G T\n |year= 2002 \n |publisher= Oxford University Press\n |location=USA\n |isbn=0198517971\n |url=\n |page=\n |pages=\n |ref=\n}}\n</ref>\n<ref name=Lee>{{Cite journal | last1 = Lee | first1 = J. | last2 = Choi | first2 = M. | doi = 10.1103/PhysRevE.50.R651 | title = Optimization by multicanonical annealing and the traveling salesman problem | journal = Physical Review E | volume = 50 | issue = 2 | pages = R651 | year = 1994 | pmid =  | pmc = |bibcode = 1994PhRvE..50..651L }}</ref>\n<ref name=Metropolis>{{Cite journal | last1 = Metropolis | first1 = N. | last2 = Rosenbluth | first2 = A. W. | last3 = Rosenbluth | first3 = M. N. | last4 = Teller | first4 = A. H. | last5 = Teller | first5 = E. | title = Equation of State Calculations by Fast Computing Machines | doi = 10.1063/1.1699114 | journal = The Journal of Chemical Physics | volume = 21 | issue = 6 | pages = 1087 | year = 1953 | pmid =  | pmc = |bibcode = 1953JChPh..21.1087M }}</ref>\n<ref name=Robert>{{cite book\n |title=Monte Carlo statistical methods\n |last1=Robert |first1=Christian |authorlink1=\n |last2=Casella |first2=George |authorlink2=\n |year= 2004 \n |publisher=Springer\n |location=\n |isbn=978-0-387-21239-5\n |url=https://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-21239-5\n}}\n</ref>\n<ref name=Dayal>{{Cite journal | last1 = Dayal | first1 = P. | last2 = Trebst | first2 = S. | last3 = Wessel | first3 = S. | last4 = Würtz | first4 = D. | last5 = Troyer | first5 = M. | last6 = Sabhapandit | first6 = S. | last7 = Coppersmith | first7 = S. |author7-link= Susan Coppersmith | title = Performance Limitations of Flat-Histogram Methods | doi = 10.1103/PhysRevLett.92.097201 | journal = Physical Review Letters | volume = 92 | issue = 9 | year = 2004 | pmid =  | pmc = |arxiv = cond-mat/0306108 |bibcode = 2004PhRvL..92i7201D }}</ref>\n<ref name=Wolff>{{Cite journal | last1 = Wolff | first1 = U. | title = Collective Monte Carlo Updating for Spin Systems | doi = 10.1103/PhysRevLett.62.361 | journal = Physical Review Letters | volume = 62 | issue = 4 | pages = 361–364 | year = 1989 | pmid =  10040213| pmc = |bibcode = 1989PhRvL..62..361W }}</ref>\n}}\n\n[[Category:Monte Carlo methods]]\n[[Category:Computational physics]]"
    },
    {
      "title": "Multiple-try Metropolis",
      "url": "https://en.wikipedia.org/wiki/Multiple-try_Metropolis",
      "text": "'''Multiple-try Metropolis (MTM)''' is a [[sampling method]] that is a modified form of the [[Metropolis–Hastings]] method, first presented by Liu, Liang, and Wong in 2000.\nIt is designed to help the sampling trajectory converge faster,\nby increasing both the step size and the acceptance rate.   \n\n==Background==\n\n===Problems with Metropolis–Hastings===\nIn [[Markov chain Monte Carlo]], the [[Metropolis–Hastings algorithm]] (MH) can be used to sample from a [[probability distribution]] which is difficult to sample from directly. However, the MH algorithm requires the user to supply a proposal distribution, which can be relatively arbitrary. In many cases, one uses a Gaussian distribution centered on the current point in the probability space, of the form <math>Q(x'; x^t)=\\mathcal{N}(x^t;\\sigma^2 I) \\,</math>. This proposal distribution is convenient to sample from and may be the best choice if one has little knowledge about the target distribution, <math>\\pi(x) \\,</math>. If desired, one can use the more general [[multivariate normal distribution]], <math>Q(x'; x^t)=\\mathcal{N}(x^t;\\mathbf{\\Sigma})</math>, where <math>\\mathbf{\\Sigma}</math> is the covariance matrix which the user believes is similar to the target distribution.\n\nAlthough this method must converge to the stationary distribution in the limit of infinite sample size, in practice the progress can be exceedingly slow. If <math>\\sigma^2 \\,</math> is too large, almost all steps under the MH algorithm will be rejected. On the other hand, if <math>\\sigma^2 \\,</math> is too small, almost all steps will be accepted, and the Markov chain will be similar to a random walk through the probability space. In the simpler case of <math>Q(x'; x^t)=\\mathcal{N}(x^t;I) \\,</math>, we see that <math>N \\,</math> steps only takes us a distance of <math>\\sqrt{N} \\,</math>. In this event, the Markov Chain will not fully explore the probability space in any reasonable amount of time. Thus the MH algorithm requires reasonable tuning of the scale parameter (<math>\\sigma^2 \\,</math> or <math>\\mathbf{\\Sigma}</math>).\n\n===Problems with high dimensionality===\nEven if the scale parameter is well-tuned, as the dimensionality of the problem increases, progress can still remain exceedingly slow. To see this, again consider <math>Q(x'; x^t)=\\mathcal{N}(x^t;I) \\,</math>. In one dimension, this corresponds to a Gaussian distribution with mean 0 and variance 1. For one dimension, this distribution has a mean step of zero, however the mean squared step size is given by\n\n:<math>\\langle x^2 \\rangle =\\int_{-\\infty}^\\infty x^2\\frac{1}{\\sqrt{2 \\pi}}e^{-\\frac{x^2}{2}}=1</math>\n\nAs the number of dimensions increases, the expected step size becomes larger and larger. In <math>N \\,</math> dimensions, the probability of moving a radial distance <math>r \\,</math> is related to the [[Chi distribution]], and is given by\n\n:<math>P_n(r) \\propto r^{n-1}e^{-r^2/2}</math>\n\nThis distribution is peaked at <math>r=\\sqrt{N-1} \\,</math> which is <math>\\approx\\sqrt{N} \\,</math> for large <math>N \\,</math>. This means that the step size will increase as the roughly the square root of the number of dimensions. For the MH algorithm, large steps will almost always land in regions of low probability, and therefore be rejected.\n\nIf we now add the scale parameter <math>\\sigma^2 \\,</math> back in, we find that to retain a reasonable acceptance rate, we must make the transformation <math>\\sigma^2 \\rightarrow \\sigma^2/N</math>. In this situation, the acceptance rate can now be made reasonable, but the exploration of the probability space becomes increasingly slow. To see this, consider a slice along any one dimension of the problem. By making the scale transformation above, the expected step size is any one dimension is not <math>\\sigma \\,</math> but instead is <math>\\sigma/\\sqrt{N}</math>. As this step size is much smaller than the \"true\" scale of the probability distribution (assuming that <math>\\sigma \\,</math> is somehow known a priori, which is the best possible case), the algorithm executes a random walk along every parameter.\n\n==The multiple-try Metropolis algorithm==\n\nSuppose <math>Q(\\mathbf{x},\\mathbf{y})</math> is an arbitrary [[proposal function]]. We require that <math>Q(\\mathbf{x},\\mathbf{y})>0</math> only if <math>Q(\\mathbf{y},\\mathbf{x})>0</math>. Additionally, <math>\\pi(\\mathbf{x})</math> is the likelihood function.\n\nDefine <math>w(\\mathbf{x},\\mathbf{y})=\\pi(\\mathbf{x})Q(\\mathbf{x},\\mathbf{y})\\lambda(\\mathbf{x},\\mathbf{y})</math> where <math>\\lambda(\\mathbf{x},\\mathbf{y})</math> is a non-negative symmetric function in <math>\\mathbf{x}</math> and <math>\\mathbf{y}</math> that can be chosen by the user.\n\nNow suppose the current state is <math>\\mathbf{x}</math>. The MTM algorithm is as follows:\n\n1) Draw ''k'' independent trial proposals <math>\\mathbf{y}_1,\\ldots,\\mathbf{y}_k</math> from <math>Q(\\mathbf{x},.)</math>. Compute the weights <math>w(\\mathbf{y}_j,\\mathbf{x})</math> for each of these.\n\n2) Select <math>\\mathbf{y}</math> from the <math>\\mathbf{y}_i</math> with probability proportional to the weights.\n\n3) Now produce a reference set by drawing <math>\\mathbf{x}_1,\\ldots,\\mathbf{x}_{k-1}</math> from the distribution <math>Q(\\mathbf{y},.)</math>. Set <math>\\mathbf{x}_k=\\mathbf{x}</math> (the current point).\n\n4) Accept <math>\\mathbf{y}</math> with probability\n:<math>r=\\text{min} \\left(1, \\frac{ w(\\mathbf{y}_1,\\mathbf{x} )+ \\ldots+ w(\\mathbf{y}_k,\\mathbf{x}) }{ w(\\mathbf{x}_1,\\mathbf{y})+ \\ldots+ w(\\mathbf{x}_k,\\mathbf{y}) } \\right)</math>\n\nIt can be shown that this method satisfies the [[detailed balance]] property and therefore produces a reversible Markov chain with <math>\\pi(\\mathbf{x})</math> as the stationary distribution.\n\nIf <math>Q(\\mathbf{x},\\mathbf{y})</math> is symmetric (as is the case for the [[multivariate normal distribution]]), then one can choose <math>\\lambda(\\mathbf{x},\\mathbf{y})=\\frac{1}{Q(\\mathbf{x},\\mathbf{y})}</math>  which gives <math>w(\\mathbf{x},\\mathbf{y})=\\pi(\\mathbf{x})</math>.\n\nSeveral further theoretical studies, variants and extensions can be found in literature.<ref>{{Cite journal|title = Scaling analysis of multiple-try MCMC methods|url = http://www.sciencedirect.com/science/article/pii/S0304414911002791|journal = Stochastic Processes and Their Applications|date = 2012-03-01|pages = 758–786|volume = 122|issue = 3|doi = 10.1016/j.spa.2011.11.004|first = Mylène|last = Bédard|first2 = Randal|last2 = Douc|first3 = Eric|last3 = Moulines}}</ref><ref>{{Cite journal|title = On the flexibility of the design of multiple try Metropolis schemes|journal = Computational Statistics|date = 2013-07-11|issn = 0943-4062|pages = 2797–2823|volume = 28|issue = 6|doi = 10.1007/s00180-013-0429-2|first = Luca|last = Martino|first2 = Jesse|last2 = Read|arxiv = 1201.0646}}</ref><ref>{{Cite journal|title = Acceleration of the Multiple-Try Metropolis algorithm using antithetic and stratified sampling|journal = Statistics and Computing|date = 2007-01-30|issn = 0960-3174|pages = 109–120|volume = 17|issue = 2|doi = 10.1007/s11222-006-9009-4|first = Radu V.|last = Craiu|first2 = Christiane|last2 = Lemieux}}</ref><ref>{{Cite journal|title = A multi-point Metropolis scheme with generic weight functions|url = http://www.sciencedirect.com/science/article/pii/S0167715212001514|journal = Statistics & Probability Letters|date = 2012-07-01|pages = 1445–1453|volume = 82|issue = 7|doi = 10.1016/j.spl.2012.04.008|first = Luca|last = Martino|first2 = Victor Pascual|last2 = Del Olmo|first3 = Jesse|last3 = Read|arxiv = 1112.4048}}</ref><ref>{{Cite journal|title = A generalized multiple-try version of the Reversible Jump algorithm|url = http://www.sciencedirect.com/science/article/pii/S0167947313003605|journal = Computational Statistics & Data Analysis|date = 2014-04-01|pages = 298–314|volume = 72|doi = 10.1016/j.csda.2013.10.007|first = Silvia|last = Pandolfi|first2 = Francesco|last2 = Bartolucci|first3 = Nial|last3 = Friel|arxiv = 1006.0621|hdl = 10197/8372}}</ref><ref>{{Cite journal|last=Casarin|first=Roberto|last2=Craiu|first2=Radu|last3=Leisen|first3=Fabrizio|date=2011-12-07|title=Interacting multiple try algorithms with different proposal distributions|journal=Statistics and Computing|language=en|volume=23|issue=2|pages=185–200|doi=10.1007/s11222-011-9301-9|issn=0960-3174|arxiv=1011.1170}}</ref> A review of MTM schemes and related techniques is given in <ref>{{Cite journal|last=Martino|first=Luca|title=A review of multiple try MCMC algorithms for signal processing|url=http://linkinghub.elsevier.com/retrieve/pii/S1051200418300149|journal=Digital Signal Processing|volume=75|pages=134–152|doi=10.1016/j.dsp.2018.01.004|year=2018|arxiv=1801.09065}}</ref>.\n\n===Disadvantages===\nMultiple-try Metropolis needs to compute the energy of <math>2k-1</math> other states at every step.\nIf the slow part of the process is calculating the energy, then this method can be slower.\nIf the slow part of the process is finding neighbors of a given point, or generating random numbers, then again this method can be slower.\nIt can be argued that this method only appears faster because it puts much more computation into a \"single step\" than Metropolis-Hastings does.\n\n==See also==\n* [[Markov chain Monte Carlo]]\n* [[Metropolis–Hastings algorithm]]\n* [[Detailed balance]]\n\n==References==\n{{Reflist}}\n* <ref>{{Cite journal|last=Casarin|first=Roberto|last2=Craiu|first2=Radu|last3=Leisen|first3=Fabrizio|date=2011-12-07|title=Interacting multiple try algorithms with different proposal distributions|journal=Statistics and Computing|language=en|volume=23|issue=2|pages=185–200|doi=10.1007/s11222-011-9301-9|issn=0960-3174|arxiv=1011.1170}}</ref>Liu, J. S., Liang, F. and Wong, W. H. (2000). The multiple-try method and local optimization in Metropolis sampling, ''Journal of the American Statistical Association'', '''95'''(449): 121–134 [https://www.jstor.org/stable/2669532 JSTOR]\n\n[[Category:Monte Carlo methods]]\n[[Category:Markov chain Monte Carlo]]"
    },
    {
      "title": "Particle filter",
      "url": "https://en.wikipedia.org/wiki/Particle_filter",
      "text": "{{About|mathematical algorithms|devices to filter particles from air|Air filter}}\n{{Use American English|date=January 2019}}{{Short desc|Type of Monte Carlo algorithms for signal processing and statistical inference}}\n\n'''Particle filters''' or '''Sequential Monte Carlo''' (SMC) methods are a set of [[Monte Carlo algorithm|Monte Carlo]] algorithms used to solve [[Filtering problem (stochastic processes)|filtering problems]] arising in [[signal processing]] and [[Bayesian inference|Bayesian statistical inference]]. The '''[[Filtering problem (stochastic processes)|filtering problem]]''' consists of estimating the internal states in [[dynamical systems]] when partial observations are made, and random perturbations are present in the sensors as well as in the dynamical system. The objective is to compute the posterior distributions of the states of some [[Markov process]], given some noisy and partial observations.  The term \"particle filters\" was first coined in 1996 by Del Moral<ref name=\"dm962\">{{cite journal|last1 = Del Moral|first1 = Pierre|title = Non Linear Filtering: Interacting Particle Solution.|journal = Markov Processes and Related Fields|date = 1996|volume = 2|issue = 4|pages = 555–580|url = http://people.bordeaux.inria.fr/pierre.delmoral/delmoral96nonlinear.pdf}}</ref> in reference to [[mean field particle methods|mean field interacting particle methods]] used in fluid mechanics since the beginning of the 1960s. The terminology \"sequential Monte Carlo\" was proposed by Liu and Chen in 1998.\n\nParticle filtering uses a set of particles (also called samples) to represent the [[posterior distribution]] of some [[stochastic process]] given noisy and/or partial observations. The state-space model can be nonlinear and the initial state and noise distributions can take any form required. Particle filter techniques provide a well-established methodology<ref name=\"dm962\" /><ref name=\":22\">{{cite journal|last1 = Del Moral|first1 = Pierre|title = Measure Valued Processes and Interacting Particle Systems. Application to Non Linear Filtering Problems|journal = Annals of Applied Probability|date = 1998|edition = Publications du Laboratoire de Statistique et Probabilités, 96-15 (1996)|volume = 8|issue = 2|pages = 438–495|url = http://projecteuclid.org/download/pdf_1/euclid.aoap/1028903535|doi = 10.1214/aoap/1028903535}}</ref><ref name=\":1\">{{Cite book|title = Feynman-Kac formulae. Genealogical and interacting particle approximations.|last = Del Moral|first = Pierre|publisher = Springer. Series: Probability and Applications|year = 2004|isbn = 978-0-387-20268-6|location = https://www.springer.com/gp/book/9780387202686|pages = 556}}</ref> for generating samples from the required distribution without requiring assumptions about the state-space model or the state distributions. However, these methods do not perform well when applied to very high-dimensional systems.\n\nParticle filters implement the '''prediction-updating''' updates in an approximate manner. The samples from the distribution are represented by a set of particles; each particle has a likelihood weight assigned to it that represents the probability of that particle being sampled from the probability density function. Weight disparity leading to weight collapse is a common issue encountered in these filtering algorithms; however it can be mitigated by including a resampling step before the weights become too uneven. Several adaptive resampling criteria can be used, including the variance of the weights and the relative entropy with respect to the uniform distribution.<ref name=\":0\">{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Doucet|first2 = Arnaud|last3 = Jasra|first3 = Ajay|title = On Adaptive Resampling Procedures for Sequential Monte Carlo Methods|journal = Bernoulli|date = 2012|volume = 18|issue = 1|pages = 252–278|url = http://hal.inria.fr/docs/00/33/25/83/PDF/RR-6700.pdf|doi = 10.3150/10-bej335}}</ref> In the resampling step, the particles with negligible weights are replaced by new particles in the proximity of the particles with higher weights.\n\nFrom the statistical and probabilistic point of view, particle filters can be interpreted as [[Mean field particle methods|mean field particle]] interpretations of [[Feynman–Kac formula|Feynman-Kac]] probability measures.<ref name=\"dp042\">{{cite book|last = Del Moral|first = Pierre|title = Feynman-Kac formulae. Genealogical and interacting particle approximations|year = 2004|publisher = Springer|quote = Series: Probability and Applications|url = https://www.springer.com/mathematics/probability/book/978-0-387-20268-6|pages = 575|isbn = 9780387202686|series = Probability and its Applications}}</ref><ref name=\"dmm002\">{{cite book|last1 = Del Moral|first1 = Pierre|last2 = Miclo|first2 = Laurent|title = Branching and Interacting Particle Systems Approximations of Feynman-Kac Formulae with Applications to Non-Linear Filtering.|journal = Lecture Notes in Mathematics|date = 2000|volume = 1729|pages = 1–145|url = http://archive.numdam.org/ARCHIVE/SPS/SPS_2000__34_/SPS_2000__34__1_0/SPS_2000__34__1_0.pdf|doi = 10.1007/bfb0103798|isbn = 978-3-540-67314-9}}</ref><ref name=\"dmm00m2\">{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Miclo|first2 = Laurent|title = A Moran particle system approximation of Feynman-Kac formulae.|journal = Stochastic Processes and Their Applications|date = 2000|volume = 86|issue = 2|pages = 193–216|doi = 10.1016/S0304-4149(99)00094-0}}</ref><ref name=\"dp13\" /><ref>{{Cite journal|title = Particle methods: An introduction with applications | journal= ESAIM: Proc.| doi = 10.1051/proc/201444001 | volume=44| pages=1–46| year= 2014| last1= Moral| first1= Piere Del| last2= Doucet| first2= Arnaud}}</ref> These particle integration techniques were developed in [[molecular chemistry]] and computational physics by [[Ted Harris (mathematician)|Theodore E. Harris]] and Herman Kahn in 1951, Marshall N. Rosenbluth and Arianna W. Rosenbluth in 1955<ref name=\":5\">{{cite journal|last1 = Rosenbluth|first1 = Marshall, N.|last2 = Rosenbluth|first2 = Arianna, W.|title = Monte-Carlo calculations of the average extension of macromolecular chains|journal = J. Chem. Phys.|date = 1955|volume = 23|issue = 2|pages = 356–359|doi=10.1063/1.1741967|bibcode = 1955JChPh..23..356R}}</ref>  and more recently by Jack H. Hetherington in 1984.<ref name=\"h84\" /> In computational physics, these Feynman-Kac type path particle integration methods are also used in [[Quantum Monte Carlo]], and more specifically [[Diffusion Monte Carlo|Diffusion Monte Carlo methods]].<ref name=\"dm-esaim032\">{{cite journal|last1 = Del Moral|first1 = Pierre|title = Particle approximations of Lyapunov exponents connected to Schrödinger operators and Feynman-Kac semigroups|journal = ESAIM Probability & Statistics|date = 2003|volume = 7|pages = 171–208|url = http://journals.cambridge.org/download.php?file=%2FPSS%2FPSS7%2FS1292810003000016a.pdf&code=a0dbaa7ffca871126dc05fe2f918880a|doi = 10.1051/ps:2003001}}</ref><ref name=\"caffarel12\">{{cite journal|last1 = Assaraf|first1 = Roland|last2 = Caffarel|first2 = Michel|last3 = Khelif|first3 = Anatole|title = Diffusion Monte Carlo Methods with a fixed number of walkers|journal = Phys. Rev. E|url = http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|date = 2000|volume = 61|issue = 4|pages = 4566–4575|doi = 10.1103/physreve.61.4566|bibcode = 2000PhRvE..61.4566A|deadurl = yes|archiveurl = https://web.archive.org/web/20141107015724/http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|archivedate = 2014-11-07|df = }}</ref><ref name=\"caffarel22\">{{cite journal|last1 = Caffarel|first1 = Michel|last2 = Ceperley|first2 = David|last3 = Kalos|first3 = Malvin|title = Comment on Feynman-Kac Path-Integral Calculation of the Ground-State Energies of Atoms|journal = Phys. Rev. Lett.|date = 1993|volume = 71|issue = 13|doi = 10.1103/physrevlett.71.2159|bibcode = 1993PhRvL..71.2159C|pages=2159|pmid=10054598}}</ref> Feynman-Kac interacting particle methods are also strongly related to [[Genetic algorithm|mutation-selection genetic algorithms]] currently used in [[Evolutionary computation|evolutionary computing]] to solve complex optimization problems.\n\nThe particle filter methodology is used to solve [[Hidden Markov model|Hidden Markov Model]] (HMM) and [[nonlinear filter]]ing problems.  With the notable exception of linear-Gaussian signal-observation models ([[Kalman filter]]) or wider classes of models (Benes filter<ref>{{Cite journal|title = Asymptotic stability of beneš filters|journal = Stochastic Analysis and Applications|date = January 1, 1999|issn = 0736-2994|pages = 1053–1074|volume = 17|issue = 6|doi = 10.1080/07362999908809648|first = D. L.|last = Ocone}}</ref>) Mireille Chaleyat-Maurel and Dominique Michel proved in 1984 that the sequence of posterior distributions of the random states of the signal given the observations (a.k.a. optimal filter)  have no finitely recursive recursion.<ref>{{Cite journal|title = Des resultats de non existence de filtre de dimension finie|journal = Stochastics|date = January 1, 1984|issn = 0090-9491|pages = 83–102|volume = 13|issue = 1–2|doi = 10.1080/17442508408833312|first = Mireille Chaleyat|last = Maurel|first2 = Dominique|last2 = Michel}}</ref> Various numerical methods based on fixed grid approximations, [[Markov chain Monte Carlo|Markov Chain Monte Carlo]] techniques (MCMC), conventional linearization, [[extended Kalman filter]]s, or determining the best linear system (in expect cost-error sense) have never really coped with large scale systems, unstable processes or when the nonlinearities are not sufficiently smooth.\n\nParticle filters and Feynman-Kac particle methodologies find application in [[signal processing|signal and image processing]], [[Bayesian inference]], [[machine learning]], [[Rare Event Sampling|risk analysis and rare event sampling]], [[engineering]] [[robotics|and robotics]], [[artificial intelligence]], [[bioinformatics]],<ref name=\":PFOBC\">Hajiramezanali, E. & Imani, M. & Braga-Neto, U. & Qian, X & Dougherty, E. R., \"Scalable Optimal Bayesian Classification of Single-Cell Trajectories under Regulatory Model Uncertainty\", Proceedings of the 2018 ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics, Washington, DC, USA. https://arxiv.org/pdf/1902.03188.pdf</ref> [[phylogenetics]], [[computational science]], [[Economics]] [[financial mathematics|and]] [[mathematical finance]], [[molecular chemistry]], [[computational physics]], [[Pharmacokinetics|pharmacokinetic]] and other fields.\n\nIn non-technical language all this means that in order to solve an estimation problem we could use particle filters to estimate the state of a system without knowing so much of their operation and only taking advantage of the chance of the measurements that we can obtain.\n\n==History==\n\n=== Heuristic like algorithms ===\nFrom the statistical and probabilistic viewpoint, particle filters belong to the class of [[Branching process|branching]]/[[genetic algorithms|genetic type algorithms]], and [[Mean field particle methods|mean field type interacting particle methodologies.]] The interpretation of these particle methods depends on the scientific discipline. In [[Evolutionary computation|Evolutionary Computing]], [[Mean field particle methods|mean field genetic type particle]] methodologies are often used as a heuristic and natural search algorithms (a.k.a. [[Metaheuristic]]). In [[computational physics]] and [[molecular chemistry]] they are used to solve Feynman-Kac path integration problems, or they compute Boltzmann-Gibbs measures, top eigenvalues and ground states of [[Schrödinger equation|Schrödinger]] operators. In [[Biology]] and [[Genetics]] they also represent the evolution of a population of individuals or genes in some environment.\n\nThe origins of mean field type evolutionary computational techniques can be traced to 1950 and 1954 with the seminal work of [[Alan Turing]] on genetic type mutation-selection learning machines<ref>{{cite journal|last1 = Turing|first1 = Alan M.|title = Computing machinery and intelligence|journal = Mind|volume = LIX|issue = 238|pages = 433–460|doi = 10.1093/mind/LIX.236.433 |url = http://mind.oxfordjournals.org/content/LIX/236/433|date = October 1950}}</ref> and the articles by [[Nils Aall Barricelli]] at the [[Institute for Advanced Study]] in [[Princeton, New Jersey]].<ref>{{cite journal|last = Barricelli|first = Nils Aall|year = 1954|authorlink = Nils Aall Barricelli|title = Esempi numerici di processi di evoluzione|journal = Methodos|pages = 45–68}}</ref><ref>{{cite journal|last = Barricelli|first = Nils Aall|year = 1957|authorlink = Nils Aall Barricelli|title = Symbiogenetic evolution processes realized by artificial methods|journal = Methodos|pages = 143–182}}</ref> The first trace of particle filters in [[Statistics|statistical methodology]] dates back to the mid-50's; the 'Poor Man's Monte Carlo',<ref>{{Cite journal|title = Poor Man's Monte Carlo |journal = Journal of the Royal Statistical Society. Series B (Methodological) |jstor = 2984008 | volume=16 |issue = 1 | pages=23–38|last1 = Hammersley |first1 = J. M. |last2 = Morton |first2 = K. W. |year = 1954 |doi = 10.1111/j.2517-6161.1954.tb00145.x }}</ref> that was proposed by Hammersley et al., in 1954, contained hints of the genetic type particle filtering methods used today.  In 1963, [[Nils Aall Barricelli]] simulated a genetic type algorithm to mimic the ability of individuals to play a simple game.<ref>{{cite journal|last = Barricelli|first = Nils Aall|year = 1963|title = Numerical testing of evolution theories. Part II. Preliminary tests of performance, symbiogenesis and terrestrial life|journal = Acta Biotheoretica|volume = 16|issue = 16|pages = 99–126|doi = 10.1007/BF01556602}}</ref> In [[Evolutionary computation|evolutionary computing]] literature, genetic type mutation-selection algorithms became popular through the seminal work of John Holland in the early 1970s, and particularly his book<ref>{{Cite web|title = Adaptation in Natural and Artificial Systems {{!}} The MIT Press|url = https://mitpress.mit.edu/index.php?q=books/adaptation-natural-and-artificial-systems|website = mitpress.mit.edu|accessdate = 2015-06-06}}</ref> published in 1975.\n\nIn Biology and [[Genetics]], the Australian geneticist [[Alex Fraser (scientist)|Alex Fraser]] also published in 1957 a series of papers on the genetic type simulation of [[artificial selection]] of organisms.<ref>{{cite journal|last = Fraser|first = Alex|authorlink = Alex Fraser (scientist)|year = 1957|title = Simulation of genetic systems by automatic digital computers. I. Introduction|journal = Aust. J. Biol. Sci.|volume = 10|issue = 4|pages = 484–491|doi = 10.1071/BI9570484}}</ref> The computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970)<ref>{{cite book|last = Fraser|first = Alex|authorlink = Alex Fraser (scientist)|first2 = Donald|last2 = Burnell|year = 1970|title = Computer Models in Genetics|publisher = McGraw-Hill|location = New York|isbn = 978-0-07-021904-5}}</ref> and Crosby (1973).<ref>{{cite book|last = Crosby|first = Jack L.|year = 1973|title = Computer Simulation in Genetics|publisher = John Wiley & Sons|location = London|isbn = 978-0-471-18880-3}}</ref> Fraser's simulations included all of the essential elements of modern mutation-selection genetic particle algorithms.\n\nFrom the mathematical viewpoint, the conditional distribution of the random states of a signal given some partial and noisy observations is described by a Feynman-Kac probability on the random trajectories of the signal weighted by a sequence of likelihood potential functions.<ref name=\"dp042\" /><ref name=\"dmm002\" /> [[Quantum Monte Carlo]], and more specifically [[Diffusion Monte Carlo|Diffusion Monte Carlo methods]] can also be interpreted as a mean field genetic type particle approximation of Feynman-Kac path integrals.<ref name=\"dp042\" /><ref name=\"dmm002\" /><ref name=\"dmm00m2\" /><ref name=\"h84\">{{cite journal|last1 = Hetherington|first1 = Jack, H.|title = Observations on the statistical iteration of matrices|journal = Phys. Rev. A|date = 1984|volume = 30|issue = 2713|doi = 10.1103/PhysRevA.30.2713|pages = 2713–2719|bibcode=1984PhRvA..30.2713H}}</ref><ref name=\"dm-esaim032\" /><ref name=\"caffarel1\">{{cite journal|last1 = Assaraf|first1 = Roland|last2 = Caffarel|first2 = Michel|last3 = Khelif|first3 = Anatole|title = Diffusion Monte Carlo Methods with a fixed number of walkers|journal = Phys. Rev. E|url = http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|date = 2000|volume = 61|issue = 4|pages = 4566–4575|doi = 10.1103/physreve.61.4566|bibcode = 2000PhRvE..61.4566A|deadurl = yes|archiveurl = https://web.archive.org/web/20141107015724/http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|archivedate = 2014-11-07|df = }}</ref><ref name=\"caffarel2\">{{cite journal|last1 = Caffarel|first1 = Michel|last2 = Ceperley|first2 = David|last3 = Kalos|first3 = Malvin|title = Comment on Feynman-Kac Path-Integral Calculation of the Ground-State Energies of Atoms|journal = Phys. Rev. Lett.|date = 1993|volume = 71|issue = 13|doi = 10.1103/physrevlett.71.2159|bibcode=1993PhRvL..71.2159C|pages=2159|pmid=10054598}}</ref> The origins of Quantum Monte Carlo methods are often attributed to Enrico Fermi and Robert Richtmyer who developed in 1948 a mean field particle interpretation of neutron-chain reactions,<ref>{{cite journal|last1 = Fermi|first1 = Enrique|last2 = Richtmyer|first2 = Robert, D.|title = Note on census-taking in Monte Carlo calculations|journal = LAM|date = 1948|volume = 805|issue = A|url = http://scienze-como.uninsubria.it/bressanini/montecarlo-history/fermi-1948.pdf|quote = Declassified report Los Alamos Archive}}</ref> but the first heuristic-like and genetic type particle algorithm (a.k.a. Resampled or Reconfiguration Monte Carlo methods) for estimating ground state energies of quantum systems (in reduced matrix models) is due to Jack H. Hetherington in 1984.<ref name=\"h84\" /> We also quote an earlier seminal works of [[Ted Harris (mathematician)|Theodore E. Harris]] and Herman Kahn in particle physics, published in 1951, using mean field but heuristic-like genetic methods for estimating particle transmission energies.<ref>{{cite journal|last1 = Herman|first1 = Kahn|last2 = Harris|first2 = Theodore, E.|title = Estimation of particle transmission by random sampling|journal = Natl. Bur. Stand. Appl. Math. Ser.|date = 1951|volume = 12|pages = 27–30|url = https://dornsifecms.usc.edu/assets/sites/520/docs/kahnharris.pdf}}</ref> In molecular chemistry, the use of genetic heuristic-like particle methodologies (a.k.a. pruning and enrichment strategies) can be traced back to 1955 with the seminal work of Marshall. N. Rosenbluth and Arianna. W. Rosenbluth.<ref name=\":5\" />\n\nThe use of [[Genetic algorithm|genetic particle algorithms]] in advanced [[signal processing]] and [[Bayesian inference]] is more recent. It was in 1993, that Gordon et al., published in their seminal work<ref>{{Cite journal|title = Novel approach to nonlinear/non-Gaussian Bayesian state estimation|url = http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=210672&url=http%25253A%25252F%25252Fieeexplore.ieee.org%25252Fxpls%25252Fabs_all.jsp%25253Farnumber%25253D210672| journal = Radar and Signal Processing, IEE Proceedings F|date = April 1993|issn = 0956-375X|pages = 107–113|volume = 140|issue = 2|first = N.J.|last = Gordon|first2 = D.J.|last2 = Salmond|first3 = A.F.M.|last3 = Smith|doi=10.1049/ip-f-2.1993.0015}}</ref> the first application of genetic type algorithm in Bayesian statistical inference. The authors named their algorithm 'the bootstrap filter', and demonstrated that compared to other filtering methods, their bootstrap algorithm does not require any assumption about that state-space or the noise of the system. Independently, Genshiro Kitagawa developed a similar \"Monte Carlo filter\" in 1993,<ref>{{cite journal|last = Kitagawa|first = G.|year = 1993|title=A Monte Carlo Filtering and Smoothing Method for Non-Gaussian Nonlinear State Space Models|journal =Proceedings of the 2nd U.S.-Japan Joint Seminar on Statistical Time Series Analysis|pages = 110–131}}</ref> a slightly modified version of this article appearing in 1996<ref>{{cite journal|last = Kitagawa|first = G.|year = 1996|title = Monte carlo filter and smoother for non-Gaussian nonlinear state space models|volume = 5|issue = 1|journal = Journal of Computational and Graphical Statistics|pages = 1–25|doi = 10.2307/1390750|jstor = 1390750}}\n</ref> and the ones by Pierre Del Moral<ref name=\"dm962\" /> and Himilcon Carvalho, Pierre Del Moral, André Monin and Gérard Salut<ref>{{cite journal|last1 = Carvalho|first1 = Himilcon|last2 = Del Moral|first2 = Pierre|last3 = Monin|first3 = André|last4 = Salut|first4 = Gérard|title = Optimal Non-linear Filtering in GPS/INS Integration.|journal = IEEE Transactions on Aerospace and Electronic Systems|date = July 1997|volume = 33|issue = 3|url = http://homepages.laas.fr/monin/Version_anglaise/Publications_files/GPS.pdf}}</ref> on particle filters published in the mid-1990s. Particle filters were also developed in signal processing in the early 1989-1992 by P. Del Moral, J.C. Noyer, G. Rigal, and G. Salut in the LAAS-CNRS in a series of restricted and classified research reports with STCAN (Service Technique des Constructions et Armes Navales), the IT company DIGILOG, and the [https://www.laas.fr/public/en LAAS-CNRS] (the Laboratory for Analysis and Architecture of Systems) on RADAR/SONAR and GPS signal processing problems.<ref>P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : An unified framework for particle solutions <br>\nLAAS-CNRS, Toulouse, Research Report no. 91137, DRET-DIGILOG- LAAS/CNRS contract, April (1991).</ref><ref>P. Del Moral, G. Rigal, and G. Salut. Nonlinear and non Gaussian particle filters applied to inertial platform repositioning.<br>\nLAAS-CNRS, Toulouse, Research Report no. 92207, STCAN/DIGILOG-LAAS/CNRS Convention STCAN no. A.91.77.013, (94p.) September (1991).</ref><ref>P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Experimental results.<br>\nConvention DRET no. 89.34.553.00.470.75.01, Research report no.2 (54p.), January (1992).</ref><ref>P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Theoretical results <br>\nConvention DRET no. 89.34.553.00.470.75.01, Research report no.3 (123p.), October (1992).</ref><ref>P. Del Moral, J.-Ch. Noyer, G. Rigal, and G. Salut. Particle filters in radar signal processing : detection, estimation and air targets recognition.<br>\nLAAS-CNRS, Toulouse, Research report no. 92495, December (1992).</ref><ref>P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. <br>\nStudies on: Filtering, optimal control, and maximum likelihood estimation. Convention DRET no. 89.34.553.00.470.75.01. Research report no.4 (210p.), January (1993).</ref>\n\n=== Mathematical foundations ===\nFrom 1950 to 1996, all the publications on particle filters, genetic algorithms, including the pruning and resample Monte Carlo methods introduced in computational physics and molecular chemistry, present natural and heuristic-like algorithms applied to different situations without a single proof of their consistency, nor a discussion on the bias of the estimates and on genealogical and ancestral tree based algorithms.\n\nThe mathematical foundations and the first rigorous analysis of these particle algorithms are due to Pierre Del Moral<ref name=\"dm962\" /><ref name=\":22\" /> in 1996. The article<ref name=\"dm962\" /> also contains a proof of the unbiased properties of a particle approximations of likelihood functions and unnormalized conditional probability measures. The unbiased particle estimator of the likelihood functions presented in this article is used today in Bayesian statistical inference.\n\nBranching type particle methodologies with varying population sizes were also developed toward the end of the 1990s by Dan Crisan, Jessica Gaines and Terry Lyons,<ref name=\":42\">{{cite journal|last1 = Crisan|first1 = Dan|last2 = Gaines|first2 = Jessica|last3 = Lyons|first3 = Terry|title = Convergence of a branching particle method to the solution of the Zakai|journal = SIAM Journal on Applied Mathematics|date = 1998|volume = 58|issue = 5|pages = 1568–1590|doi = 10.1137/s0036139996307371}}</ref><ref>{{cite journal|last1 = Crisan|first1 = Dan|last2 = Lyons|first2 = Terry|title = Nonlinear filtering and measure-valued processes|journal = Probability Theory and Related Fields|date = 1997|volume = 109|issue = 2|pages = 217–244|doi = 10.1007/s004400050131}}</ref><ref>{{cite journal|last1 = Crisan|first1 = Dan|last2 = Lyons|first2 = Terry|title = A particle approximation of the solution of the Kushner–Stratonovitch equation|journal = Probability Theory and Related Fields|date = 1999|volume = 115|issue = 4|pages = 549–578|doi = 10.1007/s004400050249}}</ref> and by Dan Crisan, Pierre Del Moral and Terry Lyons.<ref name=\":52\">{{cite journal|last1 = Crisan|first1 = Dan|last2 = Del Moral|first2 = Pierre|last3 = Lyons|first3 = Terry|title = Discrete filtering using branching and interacting particle systems|journal = Markov Processes and Related Fields|date = 1999|volume = 5|issue = 3|pages = 293–318|url = http://web.maths.unsw.edu.au/~peterdel-moral/crisan98discrete.pdf}}</ref> Further developments in this field were developed in 2000 by P. Del Moral, A. Guionnet and L. Miclo.<ref name=\"dmm002\" /><ref name=\"dg99\" /><ref name=\"dg01\" /> The first central limit theorems are due to Pierre Del Moral and Alice Guionnet<ref name=\":2\">{{Cite journal|title = Central limit theorem for nonlinear filtering and interacting particle systems|journal = The Annals of Applied Probability|date = 1999|issn = 1050-5164|pages = 275–297|volume = 9|issue = 2|doi = 10.1214/aoap/1029962742|first = P.|last = Del Moral|first2 = A.|last2 = Guionnet}}</ref> in 1999 and Pierre Del Moral and Laurent Miclo<ref name=\"dmm002\" /> in 2000. The first uniform convergence results with respect to the time parameter for particle filters were developed in the end of the 1990s by Pierre Del Moral and Alice Guionnet.<ref name=\"dg99\">{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Guionnet|first2 = Alice|title = On the stability of Measure Valued Processes with Applications to filtering|journal = C. R. Acad. Sci. Paris|date = 1999|volume = 39|issue = 1|pages = 429–434}}</ref><ref name=\"dg01\">{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Guionnet|first2 = Alice|title = On the stability of interacting processes with applications to filtering and genetic algorithms|journal = Annales de l'Institut Henri Poincaré|date = 2001|volume = 37|issue = 2|pages = 155–194|url = http://web.maths.unsw.edu.au/~peterdel-moral/ihp.ps|doi = 10.1016/s0246-0203(00)01064-5|bibcode=2001AnIHP..37..155D}}</ref> The first rigorous analysis of genealogical tree based particle filter smoothers is due to P. Del Moral and L. Miclo in 2001<ref name=\":4\">{{Cite journal|title = Genealogies and Increasing Propagation of Chaos For Feynman-Kac and Genetic Models|journal = The Annals of Applied Probability|date = 2001|issn = 1050-5164|pages = 1166–1198|volume = 11|issue = 4|doi = 10.1214/aoap/1015345399|first = Pierre|last = Del Moral|first2 = Laurent|last2 = Miclo}}</ref>\n\nThe theory on Feynman-Kac particle methodologies and related particle filters algorithms has been developed in 2000 and 2004 in the books.<ref name=\"dmm002\"/><ref name=\":1\" /> These abstract probabilistic models encapsulate genetic type algorithms, particle and bootstrap filters, interacting Kalman filters (a.k.a. Rao–Blackwellized particle filter<ref name=\"rbpf1999\">{{cite conference| citeseerx = 10.1.1.137.5199| title = Rao–Blackwellised particle filtering for dynamic Bayesian networks\n| author = Doucet, A.\n |author2=De Freitas, N. |author3=Murphy, K. |author4=Russell, S.\n| year          = 2000\n| conference    = Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence\n| pages         = 176–183\n| accessdate    = }}\n</ref>), importance sampling and resampling style particle filter techniques, including genealogical tree based and particle backward methodologies for solving filtering and smoothing problems. Other classes of particle filtering methodologies includes genealogical tree based models,<ref name=\"dp13\">{{cite book|last = Del Moral|first = Pierre|title = Mean field simulation for Monte Carlo integration|year = 2013|publisher = Chapman & Hall/CRC Press|quote = Monographs on Statistics & Applied Probability|url = http://www.crcpress.com/product/isbn/9781466504059|pages = 626}}</ref><ref name=\":1\" /><ref name=\":3\">{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Miclo|first2 = Laurent|title = Genealogies and Increasing Propagations of Chaos for Feynman-Kac and Genetic Models|journal = Annals of Applied Probability|date = 2001|volume = 11|issue = 4|pages = 1166–1198|url = http://web.maths.unsw.edu.au/~peterdel-moral/spc.ps}}</ref> backward Markov particle models,<ref name=\"dp13\" /><ref name=\":6\">{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Doucet|first2 = Arnaud|last3 = Singh|first3 = Sumeetpal, S.|title = A Backward Particle Interpretation of Feynman-Kac Formulae|journal = M2AN|date = 2010|volume = 44|issue = 5|pages = 947–976|url = http://hal.inria.fr/docs/00/42/13/56/PDF/RR-7019.pdf|doi = 10.1051/m2an/2010048}}</ref> adaptive mean field particle models,<ref name=\":0\" /> island type particle models,<ref>{{cite journal|last1 = Vergé|first1 = Christelle|last2 = Dubarry|first2 = Cyrille|last3 = Del Moral|first3 = Pierre|last4 = Moulines|first4 = Eric|title = On parallel implementation of Sequential Monte Carlo methods: the island particle model|journal = Statistics and Computing|date = 2013|doi = 10.1007/s11222-013-9429-x|volume = 25|issue = 2|pages = 243–260|arxiv = 1306.3911}}</ref><ref>{{cite arXiv|last1 = Chopin|first1 = Nicolas|last2 = Jacob|first2 = Pierre, E.|last3 = Papaspiliopoulos|first3 = Omiros|title = SMC^2: an efficient algorithm for sequential analysis of state-space models|eprint=1101.1528v3|class = stat.CO|year = 2011}}</ref> and particle Markov chain Monte Carlo methodologies.<ref>{{cite journal|last1 = Andrieu|first1 = Christophe|last2 = Doucet|first2 = Arnaud|last3 = Holenstein|first3 = Roman|title = Particle Markov chain Monte Carlo methods|journal = Journal of the Royal Statistical Society, Series B|date = 2010|volume = 72|issue = 3|pages = 269–342|doi = 10.1111/j.1467-9868.2009.00736.x}}</ref><ref>{{cite arXiv|last1 = Del Moral|first1 = Pierre|last2 = Patras|first2 = Frédéric|last3 = Kohn|first3 = Robert|title = On Feynman-Kac and particle Markov chain Monte Carlo models|eprint=1404.5733|date = 2014|class = math.PR}}</ref>\n\n== The filtering problem ==\n\n===Objective===\nThe objective of a particle filter is to estimate the posterior density of the state variables given the observation variables. The particle filter is designed for a [[hidden Markov Model]], where the system consists of hidden and observable variables. The observable variables (observation process) are related to the hidden variables (state-process) by some functional form that is known. Similarly the dynamical system describing the evolution of the state variables is also known probabilistically.\n\nA generic particle filter estimates the posterior distribution of the hidden states using the observation measurement process. Consider a state-space shown in the diagram below.\n\n:<math>\\begin{array}{cccccccccc}\nX_0&\\to &X_1&\\to &X_2&\\to&X_3&\\to &\\cdots&\\text{signal}\\\\\n\\downarrow&&\\downarrow&&\\downarrow&&\\downarrow&&\\cdots&\\\\\nY_0&&Y_1&&Y_2&&Y_3&&\\cdots&\\text{observation}\n\\end{array}</math>\n \nThe filtering problem is to estimate '''sequentially''' the values of the hidden states <math>X_k</math>, given the values of the observation process <math>Y_0,\\cdots,Y_k,</math> at any time step ''k''.\n\nAll Bayesian estimates of <math>X_k</math> follow from the [[Posterior probability|posterior density]]  ''p''(''x''<sub>''k''</sub>&nbsp;|&nbsp;''y''<sub>0</sub>,''y''<sub>1</sub>,…,''y''<sub>''k''</sub>). The particle filter methodology provides an approximation of these conditional probabilities using the empirical measure associated with a genetic type particle algorithm.  In contrast, the [[Markov chain Monte Carlo|MCMC]] or [[importance sampling]] approach would model the full posterior ''p''(''x''<sub>0</sub>,''x''<sub>1</sub>,…,''x''<sub>''k''</sub>&nbsp;|&nbsp;''y''<sub>0</sub>,''y''<sub>1</sub>,…,''y''<sub>''k''</sub>).\n\n===The Signal-Observation Model===\nParticle methods often assume <math>X_k</math> and the observations <math>Y_k</math> can be modeled in this form:\n\n*<math>X_0, X_1, \\cdots</math> is a [[Markov process]] on <math>\\mathbb R^{d_x}</math> (for some <math>d_x\\geqslant 1</math>) that evolves according to the transition probability density <math>p(x_k|x_{k-1})</math>. This model is also often written in a synthetic way as \n*:<math>X_k|X_{k-1}=x_k \\sim p(x_k|x_{k-1})</math>\n:with an initial probability density <math>p(x_0)</math>.\n*The observations <math>Y_0, Y_1, \\cdots</math>  take values in some state space on <math>\\mathbb{R}^{d_y}</math> (for some <math>d_y\\geqslant 1</math>) and are conditionally independent provided that <math>X_0, X_1, \\cdots</math> are known. In other words, each <math>Y_k</math> only depends on <math>X_k</math>. In addition, we assume conditional distribution for <math>Y_k</math> given <math>X_k=x_k</math> are absolutely continuous, and in a synthetic way we have\n*:<math>Y_k|X_k=y_k \\sim p(y_k|x_k)</math>\nAn example of system with these properties is:\n\n:<math>X_k = g(X_{k-1}) + W_{k-1}</math>\n:<math>Y_k = h(X_k) + V_k</math>\n\nwhere both <math>W_k</math> and <math>V_k</math> are mutually independent sequences with known [[probability density function]]s and ''g'' and ''h'' are known functions. These two equations can be viewed as [[state space (controls)|state space]] equations and look similar to the state space equations for the Kalman filter. If the functions ''g'' and ''h'' in the above example are linear, and if both <math>W_k</math> and <math>V_k</math> are [[Gaussian]], the Kalman filter finds the exact Bayesian filtering distribution.  If not, Kalman filter based methods are a first-order approximation ([[Extended Kalman filter|EKF]]) or a second-order approximation (UKF in general, but if probability distribution is Gaussian a third-order approximation is possible).\n\nThe assumption that the initial distribution and the transitions of the Markov chain are absolutely continuous with respect to the Lebesgue measure can be relaxed. To design a particle filter we simply need to assume that we can sample the transitions <math>X_{k-1} \\to X_k</math> of the Markov chain <math>X_k,</math> and to compute the likelihood function <math>x_k\\mapsto p(y_k|x_k)</math> (see for instance the genetic selection mutation description of the particle filter given below). The absolutely continuous assumption on the Markov transitions of <math>X_k</math> are only used to derive in an informal (and rather abusive) way different formulae between posterior distributions using the Bayes' rule for conditional densities.\n\n=== [[Approximate Bayesian computation|Approximate Bayesian Computation models]] ===\nIn some important problems, the conditional distribution of the observations given the random states of the signal may fail to have a density or may be impossible or too complex to compute.<ref name=\":PFOBC\"/> In this situation, we need to resort to an additional level of approximation. One strategy is to replace the signal <math>X_k</math> by the Markov chain <math>\\mathcal X_k=\\left(X_k,Y_k\\right)</math> and to introduce a virtual observation of the form\n\n:<math>\\mathcal Y_k=Y_k+\\epsilon \\mathcal V_k\\quad\\mbox{for some parameter}\\quad\\epsilon\\in [0,1]</math>\n\nfor some sequence of independent sequences with known [[probability density function]]s. The central idea is to observe that\n\n:<math>\\text{Law}\\left(X_k|\\mathcal Y_0=y_0,\\cdots, \\mathcal Y_k=y_k\\right)\\approx_{\\epsilon\\downarrow 0} \\text{Law}\\left(X_k|Y_0=y_0,\\cdots, Y_k=y_k\\right)</math>\n\nThe particle filter associated with the Markov process <math>\\mathcal X_k=\\left(X_k,Y_k\\right)</math> given the partial observations <math>\\mathcal Y_0=y_0,\\cdots, \\mathcal Y_k=y_k,</math> is defined in terms of particles evolving in <math>\\mathbb R^{d_x+d_y}</math> with a likelihood function given with some obvious abusive notation by <math>p(\\mathcal Y_k|\\mathcal X_k)</math>. These probabilistic techniques are closely related to [[Approximate Bayesian Computation]] (ABC). In the context of particle filters, these ABC particle filtering techniques were introduced in 1998 by P. Del Moral, J. Jacod and P. Protter.<ref>{{Cite journal|title = The Monte-Carlo method for filtering with discrete-time observations|journal = Probability Theory and Related Fields|date = 2001-07-01|issn = 0178-8051|pages = 346–368|volume = 120|issue = 3|doi = 10.1007/PL00008786|first = Pierre|last = Del Moral|first2 = Jean|last2 = Jacod|first3 = Philip|last3 = Protter|hdl = 1813/9179}}</ref> They were further developed by P. Del Moral, A. Doucet and A. Jasra.<ref>{{Cite journal|title = An adaptive sequential Monte Carlo method for approximate Bayesian computation|journal = Statistics and Computing|date = 2011|issn = 0960-3174|pages = 1009–1020|volume = 22|issue = 5|doi = 10.1007/s11222-011-9271-y|first = Pierre|last = Del Moral|first2 = Arnaud|last2 = Doucet|first3 = Ajay|last3 = Jasra|citeseerx = 10.1.1.218.9800}}</ref><ref>{{Cite journal|title = Approximate Bayesian Computation for Smoothing|journal = Stochastic Analysis and Applications|date = May 4, 2014|issn = 0736-2994|pages = 397–420|volume = 32|issue = 3|doi = 10.1080/07362994.2013.879262|first = James S.|last = Martin|first2 = Ajay|last2 = Jasra|first3 = Sumeetpal S.|last3 = Singh|first4 = Nick|last4 = Whiteley|first5 = Pierre|last5 = Del Moral|first6 = Emma|last6 = McCoy|arxiv = 1206.5208}}</ref>\n\n=== The nonlinear filtering equation ===\nBayes' rule for conditional probability gives:\n\n:<math>p(x_0, \\cdots, x_k|y_0,\\cdots,y_k) =\\frac{p(y_0,\\cdots,y_k|x_0, \\cdots, x_k)  p(x_0,\\cdots,x_k)}{p(y_0,\\cdots,y_k)}</math>\n\nwhere\n\n:<math>\\begin{align}\np(y_0,\\cdots,y_k) &=\\int p(y_0,\\cdots,y_k|x_0,\\cdots, x_k) p(x_0,\\cdots,x_k) dx_0\\cdots dx_k \\\\\np(y_0,\\cdots, y_k|x_0,\\cdots ,x_k) &=\\prod_{l=0}^{k} p(y_l|x_l) \\\\\np(x_0,\\cdots, x_k) &=p_0(x_0)\\prod_{l=1}^{k} p(x_l|x_{l-1})\n\\end{align}</math>\n\nParticle filters are also an approximation, but with enough particles they can be much more accurate.<ref name=\"dm962\" /><ref name=\":22\" /><ref name=\":1\" /><ref name=\"dg99\" /><ref name=\"dg01\" /> The nonlinear filtering equation is given by the recursion\n\n{{NumBlk|:|\n<math>\\begin{align} \np(x_k|y_0,\\cdots,y_{k-1}) &\\stackrel{\\text{updating}}{\\longrightarrow} p(x_k|y_0,\\cdots,y_k)=\\frac{p(y_k|x_k)p(x_k|y_0,\\cdots,y_{k-1})}{\\int p(y_k|x'_k)p(x'_k|y_0,\\cdots,y_{k-1})dx'_k}  \\\\\n&\\stackrel{\\text{prediction}}{\\longrightarrow}p(x_{k+1}|y_0,\\cdots,y_k)=\\int p(x_{k+1}|x_k) p(x_k|y_0,\\cdots,y_k) dx_k\n\\end{align}</math>\n|Eq. 1}}\n\nwith the convention <math>p(x_0|y_0,\\cdots,y_{k-1})=p(x_0)</math> for ''k'' = 0. The nonlinear filtering problem consists in computing these conditional distributions sequentially.\n\n=== [[Feynman–Kac formula|Feynman-Kac formulation]] ===\nWe fix a time horizon n and a sequence of observations <math>Y_0=y_0,\\cdots,Y_n=y_n</math>, and for each ''k'' = 0, ..., ''n'' we set:\n\n:<math>G_k(x_k)=p(y_k|x_k).</math>\n\nIn this notation, for any bounded function ''F'' on the set of trajectories of <math>X_k</math> from the origin ''k'' = 0 up to time ''k'' = ''n'', we have the Feynman-Kac formula\n\n:<math>\\begin{align}\n\\int F(x_0,\\cdots,x_n) p(x_0,\\cdots,x_n|y_0,\\cdots,y_n) dx_0\\cdots dx_n &= \\frac{\\int F(x_0,\\cdots,x_n) \\left\\{\\prod\\limits_{k=0}^{n} p(y_k|x_k)\\right\\}p(x_0,\\cdots,x_n) dx_0\\cdots dx_n}{\\int \\left\\{\\prod\\limits_{k=0}^{n} p(y_k|x_k)\\right\\}p(x_0,\\cdots,x_n) dx_0\\cdots dx_n}\\\\\n&=\\frac{E\\left(F(X_0,\\cdots,X_n)\\prod\\limits_{k=0}^{n} G_k(X_k)\\right)}{E\\left(\\prod\\limits_{k=0}^{n} G_k(X_k)\\right)}\n\\end{align}</math>\n\nThese Feynman-Kac path integration models arise in a variety of scientific disciplines, including in computational physics, biology, information theory and computer sciences.<ref name=\"dmm002\" /><ref name=\"dp13\" /><ref name=\":1\" /> Their interpretations depend on the application domain. For instance, if we choose the indicator function <math>G_n(x_n)=1_A(x_n)</math> of some subset of the state space, they represent the conditional distribution of a Markov chain given it stays in a given tube; that is, we have:\n\n:<math>E\\left(F(X_0,\\cdots,X_n) | X_0\\in A, \\cdots, X_n\\in A\\right) =\\frac{E\\left(F(X_0,\\cdots,X_n)\\prod\\limits_{k=0}^{n} G_k(X_k)\\right)}{E\\left(\\prod\\limits_{k=0}^{n} G_k(X_k)\\right)}</math>\nand\n:<math>P\\left(X_0\\in A,\\cdots, X_n\\in A\\right)=E\\left(\\prod\\limits_{k=0}^{n} G_k(X_k)\\right)</math>\n\nas soon as the normalizing constant is strictly positive.\n\n== Particle filters ==\n\n=== A Genetic type particle algorithm===\nInitially we start with ''N'' independent random variables <math>\\left(\\xi^i_0\\right)_{1\\leqslant i\\leqslant N}</math> with common probability density <math>p(x_0)</math>. The genetic algorithm selection-mutation transitions\n\n:<math>\\xi_k:=\\left(\\xi^i_{k}\\right)_{1\\leqslant i\\leqslant N}\\stackrel{\\text{selection}}{\\longrightarrow} \\widehat{\\xi}_k:=\\left(\\widehat{\\xi}^i_{k}\\right)_{1\\leqslant i\\leqslant N}\\stackrel{\\text{mutation}}{\\longrightarrow} \\xi_{k+1}:=\\left(\\xi^i_{k+1}\\right)_{1\\leqslant i\\leqslant N}</math>\n\nmimic/approximate the updating-prediction transitions of the optimal filter evolution ({{EquationNote|Eq. 1}}):\n\n* '''During the selection-updating transition''' we sample ''N'' (conditionally) independent random variables <math>\\widehat{\\xi}_k:=\\left(\\widehat{\\xi}^i_{k}\\right)_{1\\leqslant i\\leqslant N}</math> with common (conditional) distribution\n::<math>\\sum_{i=1}^N \\frac{p(y_k|\\xi^i_k)}{\\sum_{j=1}^Np(y_k|\\xi^j_k)} \\delta_{\\xi^i_k}(dx_k)</math>\n\n* '''During the mutation-prediction transition,''' from each selected particle <math>\\widehat{\\xi}^i_k</math> we sample independently a transition \n::<math>\\widehat{\\xi}^i_k \\longrightarrow\\xi^i_{k+1} \\sim p(x_{k+1}|\\widehat{\\xi}^i_k), \\qquad i=1,\\cdots,N.</math>\nIn the above displayed formulae  <math>p(y_k|\\xi^i_k)</math> stands for the likelihood function <math>x_k\\mapsto p(y_k|x_k)</math> evaluated at <math>x_k=\\xi^i_k</math>, and <math>p(x_{k+1}|\\widehat{\\xi}^i_k)</math> stands for the conditional density <math>p(x_{k+1}|x_k)</math> evaluated at <math>x_k=\\widehat{\\xi}^i_k</math>.\n\nAt each time ''k'', we have the particle approximations\n\n:<math>\\widehat{p}(dx_k|y_0,\\cdots,y_k):=\\frac{1}{N} \\sum_{i=1}^N \\delta_{\\widehat{\\xi}^i_k} (dx_k) \\approx_{N\\uparrow\\infty} p(dx_k|y_0,\\cdots,y_k) \\approx_{N\\uparrow\\infty} \n\\sum_{i=1}^N \\frac{p(y_k|\\xi^i_k)}{\\sum_{i=1}^N p(y_k|\\xi^j_k)} \\delta_{\\xi^i_k}(dx_k)</math>\n\nand\n\n:<math>\\widehat{p}(dx_k|y_0,\\cdots,y_{k-1}):=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^i_k}(dx_k) \\approx_{N\\uparrow\\infty} p(dx_k|y_0,\\cdots,y_{k-1})</math>\n\nA detailed proof of these convergence results can be found in,<ref name=\"dm962\" /><ref name=\":22\" /> see also the more recent developments provided in the books.<ref name=\"dp13\" /><ref name=\":1\" /> In Genetic algorithms and [[Evolutionary computing]] community, the mutation-selection Markov chain described above is often called the genetic algorithm with proportional selection. Several branching variants, including with random population sizes have also been proposed in the articles.<ref name=\":1\" /><ref name=\":42\" /><ref name=\":52\" />\n\n===[[Monte Carlo method|Monte Carlo principles]]===\nParticle methods, like all sampling-based approaches (e.g., [[Markov chain Monte Carlo|MCMC]]), generate a set of samples that approximate the filtering density\n\n:<math>p(x_k|y_0, \\cdots, y_k).</math>\n\nFor example, we may have ''N'' samples from the approximate posterior distribution of <math>X_k</math>, where the samples are labeled with superscripts as\n\n:<math>\\widehat{\\xi}_k^1, \\cdots, \\widehat{\\xi}_k^{N}.</math>\n\nThen, expectations with respect to the filtering distribution are approximated by\n\n{{NumBlk|:| <math>\\int f(x_k)p(x_k|y_0,\\cdots,y_k) \\, dx_k\\approx_{N\\uparrow\\infty}\\frac{1}{N} \\sum_{i=1}^Nf\\left(\\widehat{\\xi}_k^{i}\\right)=\\int f(x_k) \\widehat{p}(dx_k|y_0,\\cdots,y_k)</math>\n|Eq. 2}}\n\nwith\n\n:<math>\\widehat{p}(dx_k|y_0,\\cdots,y_k)=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\widehat{\\xi}^i_k}(dx_k)</math>\n\nwhere <math>\\delta_a</math> stands for the '''[[Dirac measure]]''' at a given state a. The function ''f'', in the usual way for Monte Carlo, can give all the [[moment (mathematics)|moments]] etc. of the distribution up to some approximation error. When the approximation equation  ({{EquationNote|Eq. 2}}) is satisfied for any bounded function ''f'' we write\n\n:<math>p(dx_k|y_0,\\cdots,y_k):=p(x_k|y_0,\\cdots,y_k) dx_k \\approx_{N\\uparrow\\infty} \\widehat{p}(dx_k|y_0,\\cdots,y_k)=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\widehat{\\xi}^{i}_k}(dx_k)</math>\n\nParticle filters can be interpreted as a genetic type particle algorithm evolving with mutation and selection transitions. We can keep track of the ancestral lines\n\n:<math>\\left(\\widehat{\\xi}^{i}_{0,k}, \\widehat{\\xi}^{i}_{1,k},\\cdots,\\widehat{\\xi}^{i}_{k-1,k},\\widehat{\\xi}^i_{k,k}\\right)</math>\n\nof the particles <math>i=1,\\cdots,N</math>. The random states <math>\\widehat{\\xi}^{i}_{l,k}</math>, with the lower indices l=0,...,k, stands for the ancestor of the individual <math>\\widehat{\\xi}^{i}_{k,k}=\\widehat{\\xi}^i_k</math> at level l=0,...,k. In this situation, we have the approximation formula\n\n{{NumBlk|:| <math>\\begin{align}\n\\int F(x_0, \\cdots,x_k) p(x_0,\\cdots, x_k|y_0,\\cdots,y_k) \\, dx_0 \\cdots dx_k &\\approx_{N\\uparrow\\infty} \\frac{1}{N} \\sum_{i=1}^NF\\left( \\widehat{\\xi}_{0,k}^{i}, \\widehat{\\xi}_{1,k}^{i}, \\cdots, \\widehat{\\xi}_{k,k}^{i}\\right) \\\\\n& =\\int F(x_0, \\cdots, x_k)\\widehat{p}(d(x_0, \\cdots,x_k)|y_0,\\cdots,y_k)\n\\end{align}</math> |Eq. 3}}\n\nwith the [[empirical measure]]\n\n:<math>\\widehat{p}(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_k):=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\left(\\widehat{\\xi}^{i}_{0,k},\\widehat{\\xi}^{i}_{1,k},\\cdots,\\widehat{\\xi}^{i}_{k,k}\\right)}(d(x_0,\\cdots,x_k))</math>\n\nHere ''F'' stands for any founded function on the path space of the signal. In a more synthetic form ({{EquationNote|Eq. 3}}) is equivalent to\n\n:<math>\\begin{align}\np(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_k)&:=p(x_0,\\cdots,x_k|y_0,\\cdots,y_k) \\, dx_0\\cdots dx_k \\\\\n&\\approx_{N\\uparrow\\infty} \\widehat{p}(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_k) \\\\\n&:=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\left(\\widehat{\\xi}^{i}_{0,k}, \\cdots,\\widehat{\\xi}^{i}_{k,k}\\right)}(d(x_0,\\cdots,x_k))\n\\end{align}</math>\n\nParticle filters can be interpreted in many different ways. From the probabilistic point of view they coincide with a [[Mean field particle methods|mean field particle]] interpretation of the nonlinear filtering equation. The updating-prediction transitions of the optimal filter evolution can also be interpreted as the classical genetic type selection-mutation transitions of individuals. The sequential importance resampling technique provides another interpretation of the filtering transitions coupling importance sampling with the bootstrap resampling step. Last, but not least, particle filters can be seen as an acceptance-rejection methodology equipped with a recycling mechanism.<ref name=\"dp13\" /><ref name=\":1\" />\n\n=== [[Mean field particle methods|Mean field particle simulation]] ===\n{{Technical|section|date=June 2017}}\n\n==== The general probabilistic principle ====\nThe nonlinear filtering evolution can be interpreted as a dynamical system in the set of probability measures of the following form <math>\\eta_{n+1}=\\Phi_{n+1}\\left(\\eta_{n}\\right)</math> where <math>\\Phi_{n+1}</math> stands for some mapping from the set of probability distribution into itself. For instance, the evolution of the one-step optimal predictor <math> \\eta_n(dx_n) =p(x_n|y_0,\\cdots,y_{n-1})dx_n</math>\n\nsatisfies a nonlinear evolution starting with the probability distribution <math>\\eta_0(dx_0)=p(x_0)dx_0</math>. One of the simplest ways to approximate these probability measures is to start with ''N'' independent random variables <math>\\left(\\xi^i_0\\right)_{1\\leqslant i\\leqslant N}</math> with common probability distribution  <math>\\eta_0(dx_0)=p(x_0)dx_0</math> . Suppose we have defined a sequence of ''N'' random variables <math>\\left(\\xi^i_n\\right)_{1\\leqslant i\\leqslant N}</math> such that\n\n:<math>\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^i_n}(dx_n) \\approx_{N\\uparrow\\infty} \\eta_n(dx_n)</math>\n\nAt the next step we sample ''N'' (conditionally) independent random variables <math>\\xi_{n+1}:=\\left(\\xi^i_{n+1}\\right)_{1\\leqslant i\\leqslant N}</math> with common law .\n\n:<math>\\Phi_{n+1}\\left(\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^i_n}\\right) \\approx_{N\\uparrow\\infty} \\Phi_{n+1}\\left(\\eta_{n}\\right)=\\eta_{n+1}</math>\n\n==== A particle interpretation of the filtering equation ====\nWe illustrate this mean field particle principle in the context of the evolution of the one step optimal predictors\n\n{{NumBlk|:|\n<math>p(x_{k}|y_0,\\cdots,y_{k-1}) dx_k \\to  p(x_{k+1}|y_0,\\cdots,y_k)=\\int p(x_{k+1}|x'_{k}) \\frac{p(y_k|x_k') p(x'_k|y_0,\\cdots,y_{k-1}) dx'_k}{\\int p(y_k|x''_k) p(x''_k|y_0,\\cdots,y_{k-1}) dx''_{k}}</math>\n|Eq. 4}}\n\nFor ''k'' = 0 we use the convention <math>p(x_0|y_0,\\cdots,y_{-1}):=p(x_0)</math>.\n\nBy the law of large numbers, we have\n\n:<math>\\widehat{p}(dx_0)=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^{i}_0}(dx_0)\\approx_{N\\uparrow\\infty} p(x_0)dx_0</math>\n\nin the sense that\n\n:<math>\\int f(x_0)\\widehat{p}(dx_0)=\\frac{1}{N}\\sum_{i=1}^N f(\\xi^i_0)\\approx_{N\\uparrow\\infty} \\int f(x_0)p(dx_0)dx_0</math>\n\nfor any bounded function <math>f</math>. We further assume that we have constructed a sequence of particles <math>\\left(\\xi^i_k\\right)_{1\\leqslant i\\leqslant N}</math> at some rank ''k'' such that\n\n:<math>\\widehat{p}(dx_k|y_0,\\cdots,y_{k-1}):=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^{i}_k}(dx_k)\\approx_{N\\uparrow\\infty}~p(x_k~|~y_0,\\cdots,y_{k-1})dx_k</math>\n\nin the sense that for any bounded function <math>f</math> we have\n\n:<math>\\int f(x_k)\\widehat{p}(dx_k|y_0,\\cdots,y_{k-1})=\\frac{1}{N}\\sum_{i=1}^N f(\\xi^i_k)\\approx_{N\\uparrow\\infty} \\int f(x_k)p(dx_k|y_0,\\cdots,y_{k-1})dx_k</math>\n\nIn this situation, replacing <math id=\"{{EquationRef|1}}\">p(x_k|y_0,\\cdots,y_{k-1}) dx_k</math> by the [[empirical measure]] <math id=\"{{EquationRef|1}}\">\\widehat{p}(dx_k|y_0,\\cdots,y_{k-1})</math> in the evolution equation of the one-step optimal filter stated in ({{EquationNote|Eq. 4}}) we find that\n\n:<math>p(x_{k+1}|y_0,\\cdots,y_k)\\approx_{N\\uparrow\\infty} \\int p(x_{k+1}|x'_{k}) \\frac{p(y_k|x_k') \\widehat{p}(dx'_k|y_0,\\cdots,y_{k-1})}{ \\int p(y_k|x''_k) \\widehat{p}(dx''_k|y_0,\\cdots,y_{k-1})}</math>\n\nNotice that the right hand side in the above formula is a weighted probability mixture\n\n:<math>\\int p(x_{k+1}|x'_{k}) \\frac{p(y_k|x_k') \\widehat{p}(dx'_k|y_0,\\cdots,y_{k-1})}{\\int p(y_k|x''_k) \\widehat{p}(dx''_k|y_0,\\cdots,y_{k-1})}=\\sum_{i=1}^N \\frac{p(y_k|\\xi^i_k)}{\\sum_{i=1}^N p(y_k|\\xi^j_k)} p(x_{k+1}|\\xi^i_k)=:\\widehat{q}(x_{k+1}|y_0,\\cdots,y_k)</math>\n\nwhere <math>p(y_k|\\xi^i_k)</math> stands for the density <math>p(y_k|x_k)</math> evaluated at <math>x_k=\\xi^i_k</math>, and <math>p(x_{k+1}|\\xi^i_k)</math> stands for the density <math>p(x_{k+1}|x_k)</math> evaluated at <math>x_k=\\xi^i_k</math> for <math>i=1,\\cdots,N.</math>\n\nThen, we sample ''N'' independent random variable <math>\\left(\\xi^i_{k+1}\\right)_{1\\leqslant i\\leqslant N}</math> with common probability density <math>\\widehat{q}(x_{k+1}|y_0,\\cdots,y_k)</math>  so that\n\n:<math>\\widehat{p}(dx_{k+1}|y_0,\\cdots,y_{k}):=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^{i}_{k+1}}(dx_{k+1})\\approx_{N\\uparrow\\infty} \\widehat{q}(x_{k+1}|y_0,\\cdots,y_{k}) dx_{k+1} \\approx_{N\\uparrow\\infty} p(x_{k+1}|y_0,\\cdots,y_{k})dx_{k+1}</math>\n\nIterating this procedure, we design a Markov chain such that\n\n:<math>\\widehat{p}(dx_k|y_0,\\cdots,y_{k-1}):=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^i_k}(dx_k) \\approx_{N\\uparrow\\infty} p(dx_k|y_0,\\cdots,y_{k-1}):=p(x_k|y_0,\\cdots,y_{k-1}) dx_k</math>\n\nNotice that the optimal filter is approximated at each time step k using the Bayes' formulae\n\n:<math>p(dx_{k}|y_0,\\cdots,y_{k}) \\approx_{N\\uparrow\\infty} \\frac{p(y_{k}|x_{k}) \\widehat{p}(dx_{k}|y_0,\\cdots,y_{k-1})}{\\int p(y_{k}|x'_{k})\\widehat{p}(dx'_{k}|y_0,\\cdots,y_{k-1})}=\\sum_{i=1}^N \\frac{p(y_k|\\xi^i_k)}{\\sum_{j=1}^Np(y_k|\\xi^j_k)}~\\delta_{\\xi^i_k}(dx_k)</math>\n\nThe terminology \"mean field approximation\" comes from the fact that we replace at each time step the probability measure <math>p(dx_k|y_0,\\cdots,y_{k-1})</math> by the empirical approximation <math>\\widehat{p}(dx_k|y_0,\\cdots,y_{k-1})</math>. The mean field particle approximation of the filtering problem is far from being unique. Several strategies are developed in the books.<ref name=\"dp13\" /><ref name=\":1\" />\n\n=== Some convergence results ===\nThe analysis of the convergence of particle filters was started in 1996<ref name=\"dm962\" /><ref name=\":22\" /> and in 2000 in the book<ref name=\"dmm002\" /> and the series of articles.<ref name=\":52\" /><ref name=\"dg99\" /><ref name=\"dg01\" /><ref name=\":2\" /><ref name=\":4\" /><ref>{{Cite journal|title = Concentration inequalities for mean field particle models|journal = The Annals of Applied Probability|date = 2011|issn = 1050-5164|pages = 1017–1052|volume = 21|issue = 3|doi = 10.1214/10-AAP716|first = Pierre|last = Del Moral|first2 = Emmanuel|last2 = Rio|arxiv = 1211.1837}}</ref><ref>{{Cite book|title = On the Concentration Properties of Interacting Particle Processes|url = http://dl.acm.org/citation.cfm?id=2222549|publisher = Now Publishers Inc.|date = 2012|location = Hanover, MA, USA|isbn = 978-1601985125|first = Pierre|last = Del Moral|first2 = Peng|last2 = Hu|first3 = Liming|last3 = Wu}}</ref> More recent developments can be found in the books,<ref name=\"dp13\" /><ref name=\":1\" /> When the filtering equation is stable (in the sense that it corrects any erroneous initial condition), the bias and the variance of the particle particle estimates\n\n:<math>I_k(f):=\\int f(x_k) p(dx_k|y_0,\\cdots,y_{k-1}) \\approx_{N\\uparrow\\infty} \\widehat{I}_k(f):=\\int f(x_k) \\widehat{p}(dx_k|y_0,\\cdots,y_{k-1})</math>\n\nare controlled by the non asymptotic uniform estimates\n\n:<math>\\sup_{k\\geqslant 0}\\left\\vert E\\left(\\widehat{I}_k(f)\\right)-I_k(f)\\right\\vert\\leqslant \\frac{c_1}{N}</math>\n:<math>\\sup_{k\\geqslant 0}E\\left(\\left[\\widehat{I}_k(f)-I_k(f)\\right]^2\\right)\\leqslant \\frac{c_2}{N}</math>\n\nfor any function ''f'' bounded by 1, and for some finite constants <math>c_1,c_2.</math>  In addition, for any <math>x\\geqslant 0</math>:\n\n:<math>\\mathbf{P} \\left ( \\left| \\widehat{I}_k(f)-I_k(f)\\right|\\leqslant c_1 \\frac{x}{N}+c_2 \\sqrt{\\frac{x}{N}}\\land \\sup_{0\\leqslant k\\leqslant n}\\left| \\widehat{I}_k(f)-I_k(f)\\right|\\leqslant c \\sqrt{\\frac{x\\log(n)}{N}} \\right ) > 1-e^{-x}</math>\n\nfor some finite constants <math>c_1, c_2</math> related to the asymptotic bias and variance of the particle estimate, and some finite constant ''c''. The same results are satisfied if we replace the one step optimal predictor by the optimal filter approximation.\n\n== Genealogical trees and Unbiasedness properties ==\n{{Technical|section|date=June 2017}}\n\n=== Genealogical tree based particle smoothing ===\n\nTracing back in time the ancestral lines\n\n:<math>\\left(\\widehat{\\xi}^i_{0,k},\\widehat{\\xi}^i_{1,k},\\cdots,\\widehat{\\xi}^i_{k-1,k},\\widehat{\\xi}^i_{k,k}\\right), \\quad \\left(\\xi^i_{0,k},\\xi^i_{1,k},\\cdots,\\xi^i_{k-1,k},\\xi_{k,k}\\right)</math>\n\nof the individuals <math>\\widehat{\\xi}^i_{k}\\left(=\\widehat{\\xi}^i_{k,k}\\right)</math> and <math>\\xi^i_{k}\\left(={\\xi}^i_{k,k}\\right)</math> at every time step ''k'', we also have the particle approximations\n\n:<math>\\begin{align}\n\\widehat{p}(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_k) &:=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\left(\\widehat{\\xi}^i_{0,k},\\cdots,\\widehat{\\xi}^i_{0,k}\\right)}(d(x_0,\\cdots,x_k)) \\\\\n&\\approx_{N\\uparrow\\infty} p(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_k) \\\\\n&\\approx_{N\\uparrow\\infty} \\sum_{i=1}^N \\frac{p(y_k|\\xi^i_{k,k})}{\\sum_{j=1}^Np(y_k|\\xi^j_{k,k})} \\delta_{\\left(\\xi^i_{0,k},\\cdots,\\xi^i_{0,k}\\right)}(d(x_0,\\cdots,x_k)) \\\\\n& \\ \\\\\n\\widehat{p}(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_{k-1}) &:=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\left(\\xi^i_{0,k},\\cdots,\\xi^i_{k,k}\\right)}(d(x_0,\\cdots,x_k)) \\\\\n&\\approx_{N\\uparrow\\infty} p(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_{k-1}) \\\\\n&:=p(x_0,\\cdots,x_k|y_0,\\cdots,y_{k-1}) dx_0,\\cdots,dx_k\n\\end{align}</math>\n\nThese empirical approximations are equivalent to the particle integral approximations\n\n:<math>\\begin{align}\n\\int F(x_0,\\cdots,x_n) \\widehat{p}(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_k) &:=\\frac{1}{N}\\sum_{i=1}^N F\\left(\\widehat{\\xi}^i_{0,k},\\cdots,\\widehat{\\xi}^i_{0,k}\\right) \\\\\n&\\approx_{N\\uparrow\\infty} \\int F(x_0,\\cdots,x_n) p(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_k) \\\\\n&\\approx_{N\\uparrow\\infty} \\sum_{i=1}^N \\frac{p(y_k|\\xi^i_{k,k})}{\\sum_{j=1}^N p(y_k|\\xi^j_{k,k})} F\\left(\\xi^i_{0,k}, \\cdots,\\xi^i_{k,k} \\right) \\\\\n& \\ \\\\\n\\int F(x_0,\\cdots,x_n) \\widehat{p}(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_{k-1}) &:=\\frac{1}{N} \\sum_{i=1}^N F\\left(\\xi^i_{0,k},\\cdots,\\xi^i_{k,k}\\right) \\\\\n&\\approx_{N\\uparrow\\infty} \\int F(x_0,\\cdots,x_n) p(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_{k-1})\n\\end{align}</math>\n\nfor any bounded function ''F'' on the random trajectories of the signal. As shown in<ref name=\":3\" /> the evolution of the genealogical tree coincides with a mean field particle interpretation of the evolution equations associated with the posterior densities of the signal trajectories. For more details on these path space models, we refer to the books.<ref name=\"dp13\" /><ref name=\":1\" />\n\n=== Unbiased particle estimates of likelihood functions ===\n\nWe use the product formula\n\n:<math>p(y_0,\\cdots,y_n)=\\prod_{k=0}^n p(y_k|y_0,\\cdots,y_{k-1})</math>\n\nwith\n\n:<math>p(y_k|y_0,\\cdots,y_{k-1})=\\int p(y_k|x_k) p(dx_k|y_0,\\cdots,y_{k-1})</math>\n\nand  the conventions <math>p(y_0|y_0,\\cdots,y_{-1})=p(y_0)</math> and <math>p(x_0|y_0,\\cdots,y_{-1})=p(x_0),</math> for ''k'' = 0. Replacing <math>p(x_k|y_0,\\cdots,y_{k-1})dx_k</math> by the [[empirical measure|empirical]] approximation\n\n:<math>\\widehat{p}(dx_k|y_0,\\cdots,y_{k-1}):=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^i_k}(dx_k) \\approx_{N\\uparrow\\infty} p(dx_k|y_0,\\cdots,y_{k-1})</math>\n\nin the above displayed formula, we design the following unbiased particle approximation of the likelihood function\n\n:<math>p(y_0,\\cdots,y_n) \\approx_{N\\uparrow\\infty} \\widehat{p}(y_0,\\cdots,y_n)=\\prod_{k=0}^n \\widehat{p}(y_k|y_0,\\cdots,y_{k-1}) </math>\n\nwith\n\n:<math>\\widehat{p}(y_k|y_0,\\cdots,y_{k-1})=\\int p(y_k|x_k) \\widehat{p}(dx_k|y_0,\\cdots,y_{k-1})=\\frac{1}{N}\\sum_{i=1}^N p(y_k|\\xi^i_k)</math>\n\nwhere <math>p(y_k|\\xi^i_k)</math> stands for the density <math>p(y_k|x_k)</math> evaluated at <math>x_k=\\xi^i_k</math>. The design of this particle estimate and the unbiasedness property has been proved in 1996 in the article.<ref name=\"dm962\"/> Refined variance estimates can be found in<ref name=\":1\" /> and.<ref name=\"dp13\" />\n\n=== Backward particle smoothers ===\nUsing Bayes' rule, we have the formula\n\n:<math>p(x_0,\\cdots,x_n|y_0,\\cdots,y_{n-1}) = p(x_n | y_0,\\cdots,y_{n-1}) p(x_{n-1}|x_n, y_0,\\cdots,y_{n-1} ) \\cdots p(x_1|x_2,y_0,y_1) p(x_0|x_1,y_0)</math>\n\nNotice that\n\n:<math> \\begin{align} \np(x_{k-1}|x_{k},(y_0,\\cdots,y_{k-1})) &\\propto p(x_{k}|x_{k-1})p(x_{k-1}|(y_0,\\cdots,y_{k-1})) \\\\\np(x_{k-1}|(y_0,\\cdots,y_{k-1}) &\\propto p(y_{k-1}|x_{k-1})p(x_{k-1}|(y_0,\\cdots,y_{k-2})\n\\end{align}</math>\n\nThis implies that\n\n:<math>p(x_{k-1}|x_k, (y_0,\\cdots,y_{k-1}))=\\frac{p(y_{k-1}|x_{k-1})p(x_{k}|x_{k-1})p(x_{k-1}|y_0,\\cdots,y_{k-2})}{\\int p(y_{k-1}|x'_{k-1})p(x_{k}|x'_{k-1})p(x'_{k-1}|y_0,\\cdots,y_{k-2}) dx'_{k-1}}</math>\n\nReplacing the one-step optimal predictors <math>p(x_{k-1}|(y_0,\\cdots,y_{k-2}))dx_{k-1}</math> by the particle [[empirical measure]]s\n\n:<math>\\widehat{p}(dx_{k-1}|(y_0,\\cdots,y_{k-2}))=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^i_{k-1}}(dx_{k-1}) \\left(\\approx_{N\\uparrow\\infty} p(dx_{k-1}|(y_0,\\cdots,y_{k-2})):={p}(x_{k-1}|(y_0,\\cdots,y_{k-2})) dx_{k-1}\\right)</math>\n\nwe find that\n\n:<math>\\begin{align}\np(dx_{k-1}| x_{k},(y_0,\\cdots,y_{k-1})) &\\approx_{N\\uparrow\\infty} \\widehat{p}(dx_{k-1}|x_{k},(y_0,\\cdots,y_{k-1})) \\\\\n&:= \\frac{p(y_{k-1}|x_{k-1}) p(x_{k}|x_{k-1}) \\widehat{p}(dx_{k-1}|y_0,\\cdots,y_{k-2})}{\\int p(y_{k-1}|x'_{k-1})~p(x_{k}| x'_{k-1}) \\widehat{p}(dx'_{k-1}|y_0,\\cdots,y_{k-2})}\\\\\n&= \\sum_{i=1}^{N} \\frac{p(y_{k-1}|\\xi^i_{k-1}) p(x_{k}|\\xi^i_{k-1})}{\\sum_{j=1}^{N} p(y_{k-1}|\\xi^j_{k-1}) p(x_{k}|\\xi^j_{k-1})} \\delta_{\\xi^i_{k-1}}(dx_{k-1})\n\\end{align}</math>\n\nWe conclude that\n\n:<math>p(d(x_0,\\cdots,x_n)|(y_0,\\cdots,y_{n-1})) \\approx_{N\\uparrow\\infty} \\widehat{p}_{backward}(d(x_0,\\cdots,x_n)|(y_0,\\cdots,y_{n-1}))</math>\n\nwith the backward particle approximation\n\n:<math>\\begin{align}\n\\widehat{p}_{backward} (d(x_0,\\cdots,x_n)|(y_0,\\cdots,y_{n-1})) = \\widehat{p}(dx_n|(y_0,\\cdots,y_{n-1})) \\widehat{p}(dx_{n-1}|x_n,(y_0,\\cdots,y_{n-1})) \\cdots \\widehat{p}(dx_1|x_2,(y_0,y_1)) \\widehat{p}(dx_0|x_1,y_0)\n\\end{align}</math>\n\nThe probability measure\n\n:<math>\\widehat{p}_{backward}(d(x_0,\\cdots,x_n)|(y_0,\\cdots,y_{n-1}))</math>\n\nis the probability of the random paths of a Markov chain <math>\\left(\\mathbb X^{\\flat}_{k,n}\\right)_{0\\leqslant k\\leqslant n}</math>running backward in time from time k=n to time k=0, and evolving at each time step k in the state space associated with the population of particles <math>\\xi^i_k,  i=1,\\cdots,N.</math>\n* Initially (at time k=n) the chain <math>\\mathbb X^{\\flat}_{n,n}</math> chooses randomly a state with the distribution\n::<math>\\widehat{p}(dx_{n}|(y_0,\\cdots,y_{n-1}))=\\frac{1}{N}\\sum_{i=1}^N \\delta_{\\xi^i_{n}}(dx_{n})</math>\n* From time k to the time (k-1), the chain starting at some state <math>\\mathbb X^{\\flat}_{k,n}=\\xi^i_k</math> for some <math> i=1,\\cdots,N</math> at time k moves at time (k-1) to a random state <math>\\mathbb{X}^{\\flat}_{k-1,n}</math> chosen with the discrete weighted probability\n\n:<math>\\widehat{p}(dx_{k-1}|\\xi^i_{k},(y_0,\\cdots,y_{k-1}))= \\sum_{j=1}^N\\frac{p(y_{k-1}|\\xi^j_{k-1}) p(\\xi^i_{k}|\\xi^j_{k-1})}{\\sum_{l=1}^Np(y_{k-1}|\\xi^l_{k-1}) p(\\xi^i_{k}|\\xi^l_{k-1})}~\\delta_{\\xi^j_{k-1}}(dx_{k-1})</math>\n\nIn the above displayed formula, <math>\\widehat{p}(dx_{k-1}|\\xi^i_{k},(y_0,\\cdots,y_{k-1}))</math>  stands for the conditional distribution <math>\\widehat{p}(dx_{k-1}|x_k, (y_0,\\cdots,y_{k-1}))</math> evaluated at <math>x_k=\\xi^i_{k}</math>. In the same vein, <math>p(y_{k-1}|\\xi^j_{k-1})</math> and <math>p(\\xi^i_k|\\xi^j_{k-1})</math> stand for the conditional densities <math>p(y_{k-1}|x_{k-1})</math> and <math>p(x_k|x_{k-1})</math> evaluated at <math>x_k=\\xi^i_{k}</math> and <math>x_{k-1}=\\xi^j_{k-1}.</math> These models allows to reduce integration with respect to the densities <math>p((x_0,\\cdots,x_n)|(y_0,\\cdots,y_{n-1}))</math> in terms of matrix operations with respect to the Markov transitions of the chain described above.<ref name=\":6\" /> For instance, for any function <math>f_k</math> we have the particle estimates\n\n:<math>\\begin{align}\n\\int p(d(x_0,\\cdots,x_n)&|(y_0,\\cdots,y_{n-1}))f_k(x_k) \\\\\n&\\approx_{N\\uparrow\\infty} \\int \\widehat{p}_{backward}(d(x_0,\\cdots,x_n)| (y_0,\\cdots,y_{n-1})) f_k(x_k) \\\\\n&=\\int \\widehat{p}(dx_n| (y_0,\\cdots,y_{n-1})) \\widehat{p}(dx_{n-1}|x_n,(y_0,\\cdots,y_{n-1})) \\cdots \\widehat{p}(dx_k| x_{k+1},(y_0,\\cdots,y_k)) f_k(x_k) \\\\\n&=\\underbrace{\\left[\\tfrac{1}{N},\\cdots,\\tfrac{1}{N}\\right]}_{N \\text{ times}}\\mathbb{M}_{n-1} \\cdots\\mathbb M_{k} \\begin{bmatrix} f_k(\\xi^1_k)\\\\\n\\vdots\\\\ f_k(\\xi^N_k) \\end{bmatrix}\n\\end{align}</math>\n\nwhere\n\n:<math>\\mathbb M_k= (\\mathbb M_k(i,j))_{1\\leqslant i,j\\leqslant N}: \\qquad \\mathbb M_k(i,j)=\\frac{p(\\xi^i_{k}|\\xi^j_{k-1})~p(y_{k-1}|\\xi^j_{k-1})}{\\sum\\limits_{l=1}^{N} p(\\xi^i_{k}|\\xi^l_{k-1}) p(y_{k-1}|\\xi^l_{k-1})}</math>\n\nThis also shows that if\n\n:<math>\\overline{F}(x_0,\\cdots,x_n):=\\frac{1}{n+1}\\sum_{k=0}^n f_k(x_k)</math>\n\nthen\n\n:<math>\\begin{align} \n\\int \\overline{F}(x_0,\\cdots,x_n) p(d(x_0,\\cdots,x_n)|(y_0,\\cdots,y_{n-1})) &\\approx_{N\\uparrow\\infty} \\int \\overline{F}(x_0,\\cdots,x_n) \\widehat{p}_{backward}(d(x_0,\\cdots,x_n)|(y_0,\\cdots,y_{n-1})) \\\\\n&=\\frac{1}{n+1} \\sum_{k=0}^n \\underbrace{\\left[\\tfrac{1}{N},\\cdots,\\tfrac{1}{N}\\right]}_{N \\text{ times}}\\mathbb M_{n-1}\\mathbb M_{n-2}\\cdots\\mathbb{M}_k \\begin{bmatrix} f_k(\\xi^1_k)\\\\ \\vdots\\\\ f_k(\\xi^N_k) \\end{bmatrix}\n\\end{align}</math>\n\n=== Some convergence results ===\nWe shall assume that filtering equation is stable, in the sense that it corrects any erroneous initial condition.\n\nIn this situation, the '''particle approximations of the likelihood functions''' are unbiased and the relative variance is controlled by\n\n:<math>E\\left(\\widehat{p}(y_0,\\cdots,y_n)\\right)= p(y_0,\\cdots,y_n), \\qquad E\\left(\\left[\\frac{\\widehat{p}(y_0,\\cdots,y_n)}{p(y_0,\\cdots,y_n)}-1\\right]^2\\right)\\leqslant \\frac{cn}{N},</math>\n\nfor some finite constant ''c''. In addition, for any <math>x\\geqslant 0</math>:\n\n:<math>\\mathbf{P} \\left ( \\left\\vert \\frac{1}{n}\\log{\\widehat{p}(y_0,\\cdots,y_n)}-\\frac{1}{n}\\log{p(y_0,\\cdots,y_n)}\\right\\vert \\leqslant c_1 \\frac{x}{N}+c_2 \\sqrt{\\frac{x}{N}} \\right ) > 1-e^{-x} </math>\n\nfor some finite constants <math>c_1, c_2</math> related to the asymptotic bias and variance of the particle estimate, and for some finite constant ''c''.\n\nThe bias and the variance of  '''the particle particle estimates based on the ancestral lines of the genealogical trees'''\n\n:<math>\\begin{align}\nI^{path}_k(F) &:=\\int F(x_0,\\cdots,x_k) p(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_{k-1}) \\\\\n&\\approx_{N\\uparrow\\infty} \\widehat{I}^{path}_k(F) \\\\\n&:=\\int F(x_0,\\cdots,x_k) \\widehat{p}(d(x_0,\\cdots,x_k)|y_0,\\cdots,y_{k-1}) \\\\\n&=\\frac{1}{N}\\sum_{i=1}^N F\\left(\\xi^i_{0,k},\\cdots,\\xi^i_{k,k}\\right)\n\\end{align}</math>\n\nare controlled by the non asymptotic uniform estimates\n\n:<math>\\left| E\\left(\\widehat{I}^{path}_k(F)\\right)-I_k^{path}(F)\\right|\\leqslant \\frac{c_1 k}{N}, \\qquad E\\left(\\left[\\widehat{I}^{path}_k(F)-I_k^{path}(F)\\right]^2\\right)\\leqslant \\frac{c_2 k}{N},</math>\n\nfor any function ''F'' bounded by 1, and for some finite constants <math>c_1, c_2.</math> In addition, for any <math>x\\geqslant 0</math>:\n\n:<math>\\mathbf{P} \\left ( \\left|  \\widehat{I}^{path}_k(F)-I_k^{path}(F)\\right | \\leqslant c_1 \\frac{kx}{N}+c_2 \\sqrt{\\frac{kx}{N}} \\land \\sup_{0\\leqslant k\\leqslant n}\\left| \\widehat{I}_k^{path}(F)-I^{path}_k(F)\\right| \\leqslant c \\sqrt{\\frac{xn\\log(n)}{N}} \\right ) > 1-e^{-x}</math>\n\nfor some finite constants <math>c_1, c_2</math> related to the asymptotic bias and variance of the particle estimate, and for some finite constant ''c''. The same type of bias and variance estimates hold for the backward particle smoothers. For additive functionals of the form\n\n:<math>\\overline{F}(x_0,\\cdots,x_n):=\\frac{1}{n+1}\\sum_{0\\leqslant k\\leqslant n}f_k(x_k)</math>\n\nwith\n\n:<math>I^{path}_n(\\overline{F}) \\approx_{N\\uparrow\\infty} I^{\\flat, path}_n(\\overline{F}):=\\int \\overline{F}(x_0,\\cdots,x_n) \\widehat{p}_{backward}(d(x_0,\\cdots,x_n)|(y_0,\\cdots,y_{n-1}))</math>\n\nwith functions <math>f_k</math> bounded by 1, we have\n\n:<math>\\sup_{n\\geqslant 0}{\\left\\vert E\\left(\\widehat{I}^{\\flat,path}_n(\\overline{F})\\right)-I_n^{path}(\\overline{F})\\right\\vert} \\leqslant \\frac{c_1}{N}</math>\n\nand\n\n:<math>E\\left(\\left[\\widehat{I}^{\\flat,path}_n(F)-I_n^{path}(F)\\right]^2\\right)\\leqslant \\frac{c_2}{nN}+ \\frac{c_3}{N^2}</math>\n\nfor some finite constants <math>c_1,c_2,c_3.</math> More refined estimates including exponentially small probability of errors are developed in.<ref name=\"dp13\" />\n\n== Sequential Importance Resampling (SIR) ==\n\n=== The bootstrap filter ===\n''Sequential importance [[Resampling (statistics)|Resampling]] (SIR)'', the original bootstrap filtering algorithm (Gordon et al. 1993), is also a very commonly used filtering algorithm, which approximates the filtering probability density <math>p(x_k|y_0,\\cdots,y_k)</math> by a weighted set of ''N'' samples\n\n: <math> \\left \\{ \\left (w^{(i)}_k,x^{(i)}_k \\right ) \\ : \\ i\\in\\{1,\\cdots,N\\} \\right \\}.</math>\n\nThe ''importance weights'' <math>w^{(i)}_k</math> are approximations to the relative posterior probabilities (or densities) of the samples such that\n\n:<math>\\sum_{i=1}^N w^{(i)}_k = 1.</math>\n\nSequential importance sampling (SIS) is a sequential (i.e., recursive) version of [[importance sampling]]. As in importance sampling, the expectation of a function ''f'' can be approximated as a weighted average\n\n: <math> \\int f(x_k) p(x_k|y_0,\\dots,y_k) dx_k \\approx \\sum_{i=1}^N w_k^{(i)} f(x_k^{(i)}).</math>\n\nFor a finite set of samples, the algorithm performance is dependent on the choice of the ''proposal distribution''\n\n: <math>\\pi(x_k|x_{0:k-1},y_{0:k})\\, </math>.\n\nThe \"''optimal\" proposal distribution'' is given as the ''target distribution''\n: <math>\\pi(x_k|x_{0:k-1},y_{0:k}) = p(x_k|x_{k-1},y_{k})=\\frac{p(y_k|x_k)}{\\int p(y_k|x_k)p(x_k|x_{k-1})dx_k}~p(x_k|x_{k-1}).</math>\n\nThis particular choice of proposal transition has been proposed by P. Del Moral in 1996 and 1998.<ref name=\":22\"/> When it is difficult to sample transitions according to the distribution  <math> p(x_k|x_{k-1},y_{k})</math> one natural strategy is to use the following particle approximation\n\n:<math>\\begin{align} \n\\frac{p(y_k|x_k)}{\\int p(y_k|x_k)p(x_k|x_{k-1})dx_k} p(x_k|x_{k-1})dx_k &\\simeq_{N\\uparrow\\infty} \\frac{p(y_k|x_k)}{\\int p(y_k|x_k)\\widehat{p}(dx_k|x_{k-1})} \\widehat{p}(dx_k|x_{k-1}) \\\\\n&= \\sum_{i=1}^N \\frac{p(y_k|X^i_k(x_{k-1}))}{\\sum_{j=1}^N p(y_k|X^j_k(x_{k-1}))} \\delta_{X^i_k(x_{k-1})}(dx_k)\n\\end{align}</math>\n\nwith the empirical approximation\n\n:<math> \\widehat{p}(dx_k|x_{k-1})= \\frac{1}{N}\\sum_{i=1}^{N} \\delta_{X^i_k(x_{k-1})}(dx_k)~\\simeq_{N\\uparrow\\infty} p(x_k|x_{k-1})dx_k </math>\n\nassociated with ''N'' (or any other large number of samples) independent random samples <math>X^i_k(x_{k-1}), i=1,\\cdots,N </math>with the conditional distribution of the random state <math>X_k</math> given <math>X_{k-1}=x_{k-1}</math>. The consistency of the resulting particle filter of this approximation and other extensions are developed in.<ref name=\":22\"/> In the above display <math>\\delta_a</math> stands for the '''[[Dirac measure]]''' at a given state a.\n\nHowever, the transition prior probability distribution is often used as importance function, since it is easier to draw particles (or samples) and perform subsequent importance weight calculations:\n: <math>\\pi(x_k|x_{0:k-1},y_{0:k}) = p(x_k|x_{k-1}).</math>\n''Sequential Importance Resampling'' (SIR) filters with transition prior probability distribution as importance function are commonly known as [[Resampling (statistics)#Bootstrap|bootstrap filter]] and [[condensation algorithm]].\n\n''Resampling'' is used to avoid the problem of degeneracy of the algorithm, that is, avoiding the situation that all but one of the importance weights are close to zero. The performance of the algorithm can be also affected by proper choice of resampling method. The ''[[stratified sampling]]'' proposed by Kitagawa (1996) is optimal in terms of variance.\n\nA single step of sequential importance resampling is as follows:\n\n:1) For <math>i=1,\\cdots,N</math> draw samples from the ''proposal distribution''\n:: <math>x^{(i)}_k \\sim \\pi(x_k|x^{(i)}_{0:k-1},y_{0:k})</math>\n\n:2) For <math>i=1,\\cdots,N</math> update the importance weights up to a normalizing constant:\n::<math>\\hat{w}^{(i)}_k = w^{(i)}_{k-1} \\frac{p(y_k|x^{(i)}_k) p(x^{(i)}_k|x^{(i)}_{k-1})} {\\pi(x_k^{(i)}|x^{(i)}_{0:k-1},y_{0:k})}.</math>\n: Note that when we use the transition prior probability distribution as the importance function, \n::<math> \\pi(x_k^{(i)}|x^{(i)}_{0:k-1},y_{0:k}) = p(x^{(i)}_k|x^{(i)}_{k-1}),</math>\n:this simplifies to the following :\n::<math> \\hat{w}^{(i)}_k = w^{(i)}_{k-1} p(y_k|x^{(i)}_k), </math>\n\n:3) For <math>i=1,\\cdots,N</math> compute the normalized importance weights:\n:: <math>w^{(i)}_k = \\frac{\\hat{w}^{(i)}_k}{\\sum_{j=1}^N \\hat{w}^{(j)}_k}</math>\n\n:4) Compute an estimate of the effective number of particles as\n:: <math>\\hat{N}_\\mathit{eff} = \\frac{1}{\\sum_{i=1}^N\\left(w^{(i)}_k\\right)^2} </math>\n:This criterion reflects the variance of the weights, other criteria can be found in the article,<ref name=\":0\"/> including their rigorous analysis and central limit theorems.\n\n:5) If the effective number of particles is less than a given threshold <math>\\hat{N}_\\mathit{eff} < N_{thr}</math>, then perform resampling:\n::a) Draw ''N'' particles from the current particle set with probabilities proportional to their weights. Replace the current particle set with this new one.\n::b) For <math>i=1,\\cdots,N</math> set <math>w^{(i)}_k = 1/N.</math>\n\nThe term ''Sampling Importance Resampling'' is also sometimes used when referring to SIR filters.\n\n=== Sequential importance sampling (SIS) ===\n* Is the same as sequential importance resampling, but without the resampling stage.\n\n=== \"direct version\" algorithm ===\n{{confusing section|date=October 2011}}\nThe \"direct version\" algorithm {{citation needed|date=October 2011}} is rather simple (compared to other particle filtering algorithms) and it uses composition and rejection. To generate a single sample ''x'' at ''k'' from <math>p_{x_k|y_{1:k}}(x|y_{1:k})</math>:\n\n:1) Set n=0 (This will count the number of particles generated so far)\n\n:2) [[Uniform distribution (discrete)|Uniformly]] choose an index i from the range <math>\\{1,..., N\\}</math>\n\n:3) Generate a test <math>\\hat{x}</math> from the distribution <math>p(x_k|x_{k-1})</math> with <math> x_{k-1}=x_{k-1|k-1}^{(i)}</math>\n\n:4) Generate the probability of <math>\\hat{y}</math> using <math>\\hat{x}</math> from <math>p(y_k|x_k),~\\mbox{with}~x_k=\\hat{x}</math> where <math>y_k</math> is the measured value\n\n:5) Generate another [[Uniform distribution (continuous)|uniform]] u from <math>[0, m_k]</math> where <math>m_k = \\sup_{x_k} p(y_k|x_k) </math>\n\n:6) Compare u and <math>p\\left(\\hat{y}\\right)</math>\n\n::6a) If u is larger then repeat from step 2\n\n::6b) If u is smaller then save <math>\\hat{x}</math> as <math>x_{k|k}^{(i)}</math> and increment n\n\n:7) If n == N then quit\n\nThe goal is to generate P \"particles\" at ''k'' using only the particles from <math>k-1</math>. This requires that a Markov equation can be written (and computed) to generate a <math>x_k</math> based only upon <math>x_{k-1}</math>. This algorithm uses composition of the P particles from <math>k-1</math> to generate a particle at ''k'' and repeats (steps 2–6) until P particles are generated at ''k''.\n\nThis can be more easily visualized if ''x'' is viewed as a two-dimensional array. One dimension is ''k'' and the other dimensions is the particle number. For example, <math>x(k,i)</math> would be the i<sup>th</sup> particle at <math>k</math> and can also be written <math>x_k^{(i)}</math> (as done above in the algorithm). Step 3 generates a ''potential'' <math>x_k</math> based on a randomly chosen particle (<math>x_{k-1}^{(i)}</math>) at time <math>k-1</math> and rejects or accepts it in step 6. In other words, the <math>x_k</math> values are generated using the previously generated <math>x_{k-1}</math>.\n\n==Other particle filters==\n* [[Exponential Natural Particle Filter]]<ref name=\"xnpf2015\">{{cite arXiv\n | author = Zand, G.\n | author2= Taherkhani, M. |author3=Safabakhsh, R. \n | year = 2015\n | title = Exponential Natural Particle Filter\n | eprint = 1511.06603\n| class= cs.LG }}</ref>\n* [[Auxiliary particle filter]]<ref name=\"apf1999\">{{cite journal\n | author = Pitt, M.K.\n |author2=Shephard, N.\n | year = 1999\n | title = Filtering Via Simulation: Auxiliary Particle Filters\n | journal = Journal of the American Statistical Association\n | volume = 94\n | issue = 446\n | pages = 590–591\n | url = https://www.questia.com/PM.qst?a=o&se=gglsc&d=5002321997 \n | accessdate = 2008-05-06\n | doi = 10.2307/2670179\n | jstor = 2670179\n }}</ref>\n* [[Regularized auxiliary particle filter]]<ref name=\"jliu2011\">{{cite journal\n | author = Liu, J.\n |author2=Wang, W. |author3=Ma, F. \n | year = 2011\n | title = A Regularized Auxiliary Particle Filtering Approach for System State Estimation and Battery Life Prediction\n | journal = Smart Materials and Structures\n | volume = 20\n | issue = 7\n | pages = 1–9\n | doi = 10.1088/0964-1726/20/7/075021\n| bibcode = 2011SMaS...20g5021L}}</ref>\n* Gaussian particle filter\n* Unscented particle filter\n* Gauss–Hermite particle filter\n* Cost Reference particle filter\n* Hierarchical/Scalable particle filter<ref name=\"Canton2011\">{{cite journal\n | author = Canton-Ferrer, C.\n |author2=Casas, J.R. |author3=Pardàs, M. \n | year = 2011\n | title = Human Motion Capture Using Scalable Body Models\n | journal = Computer Vision and Image Understanding\n | volume = 115\n | issue = 10\n | pages = 1363–1374\n | doi = 10.1016/j.cviu.2011.06.001\n }}</ref>\n* Rao–Blackwellized particle filter<ref name=\"rbpf1999\"/>\n* [[Rejection sampling|Rejection-sampling]] based optimal particle filter<ref name=\"optrj2008\">{{cite conference\n| citeseerx           = 10.1.1.190.7092\n| title         = An Optimal Filtering Algorithm for Non-Parametric Observation Models in Robot Localization\n| author        = Blanco, J.L. |author2=Gonzalez, J. |author3=Fernandez-Madrigal, J.A.\n| year          = 2008\n| conference    = IEEE International Conference on Robotics and Automation (ICRA'08)\n| pages         = 461–466\n}}\n</ref><ref name=\"optrj2010\">{{cite journal\n| url           = http://ijr.sagepub.com/content/29/14/1726.full.pdf\n| title         = Optimal Filtering for Non-Parametric Observation Models: Applications to Localization and SLAM\n| author        = Blanco, J.L. |author2=Gonzalez, J. |author3=Fernandez-Madrigal, J.A.\n| year          = 2010\n| journal       = The International Journal of Robotics Research (IJRR)\n| volume        = 29\n| number        = 14\n| pages         = 1726–1742\n| doi           = 10.1177/0278364910364165\n| citeseerx         = 10.1.1.1031.4931\n}}\n</ref>\n* Feynman-Kac and mean field particle methodologies<ref name=\"dm962\"/><ref name=\"dp13\" /><ref name=\":1\" />\n* Particle Markov-Chain Monte-Carlo, see e.g. [[Pseudo-Marginal Metropolis-Hastings algorithm]].\n\n==See also==\n* [[Mean field particle methods]]\n* [[Genetic algorithm]]\n* [[Ensemble Kalman filter]]\n* [[Generalized filtering]]\n* [[Moving horizon estimation]]\n* [[Recursive Bayesian estimation]]\n* [[Monte Carlo localization]]\n\n==References==\n{{Reflist}}\n\n== Bibliography ==\n* {{cite journal | last1 = Del Moral | first1 = Pierre | year = 1996 | title = Non Linear Filtering: Interacting Particle Solution | url = http://web.maths.unsw.edu.au/~peterdel-moral/mprfs.pdf | journal = Markov Processes and Related Fields | volume = 2 | issue = 4| pages = 555–580 }}\n* Del Moral, Pierre (2004). ''[https://www.springer.com/us/book/9780387202686#reviews Feynman-Kac formulae. Genealogical and interacting particle approximations]''. Springer. p.&nbsp;575. \"Series: Probability and Applications\"\n* Del Moral, Pierre (2013). ''[https://www.crcpress.com/product/isbn/9781466504059 Mean field simulation for Monte Carlo integration]''[https://www.crcpress.com/product/isbn/9781466504059 .] Chapman & Hall/CRC Press. p.&nbsp;626. \"Monographs on Statistics & Applied Probability\"\n* {{cite book\n | author = Cappe, O. |author2=Moulines, E. |author3=Ryden, T.\n | year = 2005\n | title = Inference in Hidden Markov Models\n | publisher = Springer\n | isbn = \n}}\n*{{cite journal\n | author = Liu, J.S.\n |author2=Chen, R.\n | year = 1998\n | title = Sequential Monte Carlo methods for dynamic systems\n | journal = Journal of the American Statistical Association\n | volume = 93\n | issue = 443\n | pages = 1032–1044\n | url = http://www.people.fas.harvard.edu/~junliu/TechRept/98folder/liu&chen98_2.pdf\n | doi = 10.1080/01621459.1998.10473765\n}}\n* {{cite book\n | author = Liu, J.S.\n | year = 2001\n | title = Monte Carlo strategies in Scientific Computing\n | publisher = Springer\n | isbn = \n}}\n*{{cite journal\n | author = Kong, A.\n |author2=Liu, J.S. |author3=Wong, W.H. \n | year = 1994\n | title = Sequential imputations and Bayesian missing data problems\n | journal = Journal of the American Statistical Association\n | volume = 89\n | issue = 425\n | pages = 278–288\n | url = http://www.people.fas.harvard.edu/~junliu/TechRept/94folder/klw94.pdf\n | doi = 10.1080/01621459.1994.10476469\n}}\n*{{cite journal\n | author = Liu, J.S.\n |author2=Chen, R.\n | year = 1995\n | title = Blind deconvolution via sequential imputations\n | journal = Journal of the American Statistical Association\n | volume = 90\n | issue = 430\n | pages = 567–576\n | url = http://www.people.fas.harvard.edu/~junliu/TechRept/95folder/liu&chen95_s.pdf\n | doi = 10.2307/2291068\n|jstor=2291068\n }}\n* {{cite book\n | author = Ristic, B. |author2=Arulampalam, S. |author3=Gordon, N.\n | year = 2004\n | title = Beyond the Kalman Filter: Particle Filters for Tracking Applications\n | publisher = Artech House\n | isbn = \n}}\n* {{cite journal\n | author = Doucet, A.\n |author2=Johansen, A.M.\n | year = December 2008\n | title = A tutorial on particle filtering and smoothing: fifteen years later\n | journal = Technical Report\n | volume = \n | issue = \n | pages = \n | url = http://www.cs.ubc.ca/%7Earnaud/doucet_johansen_tutorialPF.pdf\n | doi = \n}}\n* {{cite journal\n | author = Doucet, A. |author2=Godsill, S. |author3=Andrieu, C.\n | year = 2000\n | title = On sequential Monte Carlo sampling methods for Bayesian filtering\n | journal = Statistics and Computing\n | volume = 10\n | issue = 3\n | pages = 197–208\n | doi = 10.1023/A:1008935410038\n}}\n* {{cite journal\n | author = Arulampalam, M.S. |author2=Maskell, S. |author3=Gordon, N. |author4=Clapp, T.\n | year = 2002\n | title = A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking\n | journal = IEEE Transactions on Signal Processing\n | volume = 50\n | issue = 2\n | pages = 174–188\n | doi = 10.1109/78.978374 \n| bibcode = 2002ITSP...50..174A|citeseerx=10.1.1.471.8617 }}\n* {{cite journal\n | author = Cappe, O. |author2=Godsill, S. |author3=Moulines, E.\n | year = 2007\n | title = An overview of existing methods and recent advances in sequential Monte Carlo\n | journal = Proceedings of the IEEE\n | volume = 95\n | issue = 5\n | doi = 10.1109/JPROC.2007.893250\n | pages = 899–924\n}}\n* {{cite journal\n | author = Kitagawa, G.\n | year = 1996\n | title =Monte carlo filter and smoother for non-Gaussian nonlinear state space models\n | volume = 5\n | issue = 1\n | journal = Journal of Computational and Graphical Statistics\n | pages = 1–25\n | doi = 10.2307/1390750\n | jstor = 1390750\n}}\n* {{cite journal\n | author = Kotecha, J.H.\n |author2=Djuric, P.\n | year = 2003\n | title =Gaussian Particle filtering\n | volume = 51\n | issue = 10\n | journal = IEEE Transactions on Signal Processing\n}}\n* {{cite journal\n | author = Haug, A.J.\n | year = 2005\n | title = A Tutorial on Bayesian Estimation and Tracking Techniques Applicable to Nonlinear and Non-Gaussian Processes\n | journal = The MITRE Corporation, USA, Tech. Rep., Feb\n | url = http://www.mitre-corporation.net/work/tech_papers/tech_papers_05/05_0211/05_0211.pdf \n | accessdate = 2008-05-06\n}}\n* {{cite journal\n | author = Pitt, M.K.\n |author2=Shephard, N.\n | year = 1999\n | title = Filtering Via Simulation: Auxiliary Particle Filters\n | journal = Journal of the American Statistical Association\n | volume = 94\n | issue = 446\n | pages = 590–591\n | url = https://www.questia.com/PM.qst?a=o&se=gglsc&d=5002321997 \n | accessdate = 2008-05-06\n | doi = 10.2307/2670179\n | jstor = 2670179\n }}\n* {{cite journal\n | author = Gordon, N. J. |author2=Salmond, D. J. |author3=Smith, A. F. M.\n | year = 1993\n | title = Novel approach to nonlinear/non-Gaussian Bayesian state estimation\n | journal = IEE Proceedings F on Radar and Signal Processing\n | volume = 140\n | issue = 2\n | pages = 107–113\n | url = http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=210672 \n | accessdate = 2009-09-19\n | doi = 10.1049/ip-f-2.1993.0015\n}}\n* {{cite journal\n | author = Chen, Z.\n | year = 2003\n | title = Bayesian Filtering: From Kalman Filters to Particle Filters, and Beyond\n | citeseerx = 10.1.1.107.7415\n | doi = \n | accessdate = }}\n* {{cite journal\n  | author = Vaswani, N.\n |author2=Rathi, Y. |author3=Yezzi, A. |author4=Tannenbaum, A.\n  | year = 2007\n  | title = Tracking deforming objects using particle filtering for geometric active contours\n  | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence\n  | volume = 29\n  | issue = 8\n  | pages = 1470–1475\n  | doi=10.1109/tpami.2007.1081\n|pmid=17568149 |pmc=3663080 }}\n\n==External links==\n{{refbegin}}\n* [http://web.maths.unsw.edu.au/~peterdel-moral/simulinks.html Feynman–Kac models and interacting particle algorithms (a.k.a. Particle Filtering)] Theoretical aspects and a list of application domains of particle filters\n* [http://www-sigproc.eng.cam.ac.uk/smc/ Sequential Monte Carlo Methods (Particle Filtering)] homepage on University of Cambridge\n* [https://web.archive.org/web/20060612210237/http://www.cs.washington.edu/ai/Mobile_Robotics/mcl/ Dieter Fox's MCL Animations]\n* [http://blogs.oregonstate.edu/hess/code/particles/ Rob Hess' free software]\n* [http://www.jstatsoft.org/v30/i06/ SMCTC: A Template Class for Implementing SMC algorithms in C++]\n* [http://www.oursland.net/projects/particlefilter/ Java applet on particle filtering]\n* [https://zhouyan.github.io/vSMC/ vSMC : Vectorized Sequential Monte Carlo]\n* [https://www.youtube.com/watch?v=bO_GajDgGJ4/ Particle filter explained in the context of self driving car]\n{{refend}}\n\n{{Stochastic processes}}\n\n{{Statistics}}\n\n{{DEFAULTSORT:Particle Filter}}\n[[Category:Monte Carlo methods]]\n[[Category:Computational statistics]]\n[[Category:Control theory|*]]\n[[Category:Nonlinear filters]]\n[[Category:Robot control]]\n[[Category:Statistical mechanics]]\n[[Category:Sampling techniques]]\n[[Category:Stochastic simulation]]"
    },
    {
      "title": "Preconditioned Crank–Nicolson algorithm",
      "url": "https://en.wikipedia.org/wiki/Preconditioned_Crank%E2%80%93Nicolson_algorithm",
      "text": "In [[computational statistics]], the '''preconditioned Crank–Nicolson algorithm (pCN)''' is a [[Markov chain Monte Carlo]] (MCMC) method for obtaining [[pseudo-random number sampling|random samples]] – sequences of random observations – from a target [[probability distribution]] for which direct sampling is difficult.\n\nThe most significant feature of the pCN algorithm is its dimension robustness, which makes it well-suited for high-dimensional sampling problems.  The pCN algorithm is well-defined, with non-degenerate acceptance probability, even for target distributions on infinite-dimensional [[Hilbert space]]s.  As a consequence, when pCN is implemented on a real-world computer in large but finite dimension ''N'', i.e. on an ''N''-dimensional subspace of the original Hilbert space, the convergence properties (such as [[ergodicity]]) of the algorithm are independent of ''N''.  This is in strong contrast to schemes such as Gaussian random walk Metropolis–Hastings and the [[Metropolis-adjusted Langevin algorithm]], whose acceptance probability degenerates to zero as ''N'' tends to infinity.\n\nThe algorithm was introduced in 2013 by Cotter, [[Gareth Roberts (statistician)|Roberts]], [[Andrew M. Stuart|Stuart]] and White,<ref name=\"CRSW2013\">{{cite journal\n| last1 = Cotter\n| first1 = S. L.\n| last2 = Roberts\n| first2 = G. O.\n| last3 = Stuart\n| first3 = A. M.\n| last4 = White\n| first4 = D.\n| title = MCMC methods for functions: modifying old algorithms to make them faster\n| journal = Statist. Sci.\n| volume = 28\n| year = 2013\n| number = 3\n| pages = 424&ndash;446\n| issn = 0883-4237\n| doi = 10.1214/13-STS421}}</ref> and its ergodicity properties were proved a year later by [[Martin Hairer|Hairer]], Stuart and Vollmer.<ref name=\"HSV2014\">{{cite journal\n| last1 = Hairer\n| first1 = M.\n| last2 = Stuart\n| first2 = A. M.\n| last3 = Vollmer\n| first3 = S. J.\n| title = Spectral gaps for a Metropolis&ndash;Hastings algorithm in infinite dimensions\n| journal = Ann. Appl. Probab.\n| volume = 24\n| year = 2014\n| number = 6\n| pages = 2455&ndash;2490\n| issn = 1050-5164\n| doi = 10.1214/13-AAP982}}</ref>\n\n==Description of the algorithm==\n\n===Overview===\n\n{{see also|Metropolis–Hastings algorithm}}\n\nThe pCN algorithm generates a Markov chain <math>(X_{n})_{n \\in \\mathbb{N}}</math> on a Hilbert space <math>\\mathcal{H}</math> whose [[invariant measure]] is a probability measure <math>\\mu</math> of the form\n:<math>\\mu(E) = \\frac{1}{Z} \\int_{E} \\exp(- \\Phi(x)) \\, \\mu_{0} (\\mathrm{d} x)</math>\nfor each [[measurable set]] <math>E \\subseteq \\mathcal{H}</math>, with normalising constant <math>Z</math> given by\n:<math>Z = \\int_{\\mathcal{H}} \\exp(- \\Phi(x)) \\, \\mu_{0} (\\mathrm{d} x) ,</math>\nwhere <math>\\mu_{0} = \\mathcal{N}(0, C_{0})</math> is a [[Gaussian measure]] on <math>\\mathcal{H}</math> with [[covariance operator]] <math>C_{0}</math> and <math>\\Phi \\colon \\mathcal{H} \\to \\mathbb{R}</math> is some function.  Thus, the pCN method applied to target probability measures that are re-weightings of a reference Gaussian measure.\n\nThe [[Metropolis–Hastings algorithm]] is a general class of methods that try to produce such Markov chains <math>(X_{n})_{n \\in \\mathbb{N}}</math>, and do so by a two-step procedure of first ''proposing'' a new state <math>X'_{n + 1}</math> given the current state <math>X_{n}</math> and then ''accepting'' or ''rejecting'' this proposal, according to a particular acceptance probability, to define the next state <math>X_{n + 1}</math>. The idea of the pCN algorithm is that a clever choice of (non-symmetric) proposal for a new state <math>X'_{n + 1}</math> given <math>X_{n}</math> might have an associated acceptance probability function with very desirable properties.\n\n===The pCN proposal===\n\nThe special form of this pCN proposal is to take\n:<math>X'_{n + 1} = \\sqrt{ 1 - \\beta^{2} } X_{n} + \\beta \\Xi_{n + 1} , </math>\n:<math>\\Xi_{n + 1} \\sim \\mu_{0} \\text{ i.i.d.}</math>\nor, equivalently,\n:<math>X'_{n + 1} | X_{n} \\sim \\mathcal{N} \\left( \\sqrt{ 1 - \\beta^{2} } X_{n} , \\beta C_{0} \\right) .</math>\nThe parameter <math>0 < \\beta < 1</math> is a step size that can be chosen freely (and even optimised for statistical efficiency).  One then generates <math>Z_{n + 1} \\sim \\mathrm{Unif}([0, 1])</math> and sets\n:<math>X_{n + 1} = X'_{n + 1} \\text{ if } Z_{n + 1} \\leq \\alpha(X_{n}, X'_{n + 1}) ,</math>\n:<math>X_{n + 1} = X_{n} \\text{ if } Z_{n + 1} > \\alpha(X_{n}, X'_{n + 1}) .</math>\nThe acceptance probability takes the simple form\n:<math>\\alpha(x, x') = \\min ( 1 , \\exp ( \\phi(x) - \\phi(x') ) ).</math>\n\nIt can be shown<ref name=\"HSV2014\"/> that this method not only defines a Markov chain that satisfies [[detailed balance]] with respect to the target distribution <math>\\mu</math>, and hence has <math>\\mu</math> as an invariant measure, but also possesses a spectral gap that is independent of the dimension of <math>\\mathcal{H}</math>, and so the law of <math>X_{n}</math> converges to <math>\\mu</math> as <math>n \\to \\infty</math>.  Thus, although one may still have to tune the step size parameter <math>\\beta</math> to achieve a desired level of statistical efficiency, the performance of the pCN method is robust to the dimension of the sampling problem being considered.\n\n===Contrast with symmetric proposals===\n\nThis behaviour of pCN is in stark contrast to the Gaussian random walk proposal\n:<math>X'_{n + 1} \\mid X_n \\sim \\mathcal{N} \\left( X_n, \\beta \\Gamma \\right)</math>\nwith any choice of proposal covariance <math>\\Gamma</math>, or indeed any symmetric proposal mechanism.  It can be shown using the [[Cameron–Martin theorem]] that for infinite-dimensional <math>\\mathcal{H}</math> this proposal has acceptance probability zero for <math>\\mu</math>-[[almost all]] <math>X'_{n+1} </math> and <math>X_n</math>.  In practice, when one implements the Gaussian random walk proposal in dimension <math>N</math>, this phenomenon can be seen in the way that\n* for fixed <math>\\beta</math>, the acceptance probability tends to zero as <math>N \\to \\infty</math>, and\n* for a fixed desired positive acceptance probability, <math>\\beta \\to 0</math> as <math>N \\to \\infty</math>.\n\n==References==\n<references />\n\n[[Category:Monte Carlo methods]]\n[[Category:Markov chain Monte Carlo]]\n[[Category:Sampling techniques]]"
    },
    {
      "title": "Probability management",
      "url": "https://en.wikipedia.org/wiki/Probability_management",
      "text": "The discipline of '''probability management''' communicates and calculates uncertainties as vector arrays of simulated or historical realizations and meta data called [[Stochastic Information Packet]]s (SIPs). A set of SIPs, which preserve statistical relationships between variables is said to be coherent and  is referred to as a '''S'''tochastic '''L'''ibrary '''U'''nit with '''R'''elationships '''P'''reserved (SLURP). SIPs and SLURPs allow Stochastic Simulations to Communicate with each other. See for example, Analytica ([[Analytica (software)|Wikipedia]]), Analytica ([http://www.lumina.com/technology/sips-and-slurps/ SIP page]), [https://docs.oracle.com/cd/E12825_01/epm.111/cb_user/frameset.htm?apas10.html Oracle Crystal Ball], [http://www.solver.com/risk-solver-stochastic-libraries Frontline Solvers], and [http://www.autobox.com/cms/ Autobox].\n\nThe first large documented application of SIPs involved the exploration portfolio of Royal Dutch Shell in 2005 as reported by Savage, Scholtes, and Zweidler, who formalized the discipline of probability management in 2006.<ref>Probability Management, Sam Savage, Stefan Scholtes and Daniel Zweidler, OR/MS Today, February 2006, Volume 33 Number 1\n\n<nowiki>http://probabilitymanagement.org/library/Probability_Management_Part1s.pdf</nowiki>\n</ref> The topic is also explored at length in.<ref>{{Cite book|title=The Flaw of Averages, Why we Underestimate Risk in the Face of Uncertainty|last=Savage|first=Sam|publisher=John Wiley & Sons|year=2009|isbn=978 0-471-38197-6|location=Hoboken|pages=}}</ref>\n\nVectors of simulated realizations of probability distributions have been used to drive stochastic optimization since at least 1991.<ref>{{Cite journal|last=Dembo|first=Ron|year=1991|title=Scenario Optimization|url=https://www.springer.com/business+%26+management/operations+research/journal/10479|journal=Annals of Operations Research|volume=30|pages=63–80|via=|doi=10.1007/BF02204809}}</ref> [[Andrew Gelman]] has described such arrays of realizations as Random Variable Objects in 2007.<ref>{{Cite journal|last=Gelman|first=Andrew|year=2007|title=Manipulating and summarizing posterior simulations using random variable objects|url=https://link.springer.com/journal/11222|journal=Statistics and Computing|volume=17|issue=3|pages=235–244|via=|doi=10.1007/s11222-007-9020-4}}</ref>\n\nIn 2013 [http://probabilitymanagement.org/ ProbabilityManagement.org] was incorporated as a 501(c)(3) non-profit that supports this approach through education, tools, and open standards. The Executive Director, Sam Savage, is author of ''The Flaw of Averages: Why we Underestimate Risk in the Face of Uncertainty'' and Adjunct Professor at Stanford University. He is joined on the board by [[Harry Markowitz]], Nobel laureate in Economics. The nonprofit has received financial support from Chevron Corporation, General Electric, Lockheed Martin, PG&E and Wells Fargo Bank. The open SIPmath 2.0 Standard supports XLSX, CSV and XML Formats<ref>SIPmath [http://probabilitymanagement.org/library/SIP%20Standard%20Version%202.0.2.pdf Standard]</ref>\n\n==References==\n{{Reflist}}\n\n[[Category:Simulation]]\n[[Category:Monte Carlo methods]]\n[[Category:Probability distributions]]\n[[Category:Risk analysis]]"
    },
    {
      "title": "Pseudo-marginal Metropolis–Hastings algorithm",
      "url": "https://en.wikipedia.org/wiki/Pseudo-marginal_Metropolis%E2%80%93Hastings_algorithm",
      "text": "In [[computational statistics]], the '''pseudo-marginal Metropolis–Hastings algorithm'''<ref name=\":0\">{{Cite journal|last=Christophe Andrieu and Gareth O. Roberts|first=|date=|title=The pseudo-marginal approach for efficient Monte Carlo computations|url=|journal=Annals of Statistics|volume=37.2|pages=697–725|via=https://projecteuclid.org/euclid.aos/1236693147}}</ref> is a [[Monte Carlo method]] to sample from a probability distribution. It is an instance of the popular [[Metropolis–Hastings algorithm]] that extends its use to cases where the target [[Probability density function|density]] is not available analytically. It relies on the fact that the Metropolis–Hastings algorithm can still sample from the correct target distribution if the target density in the acceptance ratio is replaced by an estimate. It is especially popular in [[Bayesian statistics]], where it is applied if the [[Likelihood function|likelihood]] function is not tractable (see example below).\n\n== Algorithm description ==\nThe aim is to simulate from some [[probability density function]] <math>\\pi(\\theta) </math>. The algorithm follows the same steps as the standard Metropolis–Hastings algorithm except that the evaluation of the target density is replaced by a non-negative and unbiased estimate. For comparison, the main steps of a Metropolis–Hastings algorithm are outlined below.\n\n=== Metropolis–Hastings algorithm ===\n{{See also|Metropolis–Hastings algorithm}}\n\nGiven a current state <math>\\theta_n</math> the Metropolis–Hastings algorithm proposes a new state according to some density <math>\\theta'\\sim Q( \\cdot \\mid \\theta_n)</math>. The algorithm then sets <math>\\theta_{n+1} = \\theta'</math> with probability\n\n:<math>a(\\theta_n, \\theta') = \\min\\left(1,\\frac{\\pi(\\theta')}{\\pi(\\theta_n)}\\frac{Q(\\theta_n\\mid\\theta')}{Q(\\theta'\\mid\\theta_n)}\\right) </math>\n\notherwise the old state is kept, that is, <math>\\theta_{n+1}=\\theta_n</math>.\n\n===  Pseudo-marginal Metropolis–Hastings algorithm ===\nIf the density <math>\\pi</math> is not available analytically the above algorithm can not be employed. The pseudo-marginal Metropolis–Hastings algorithm in contrast only assumes the existence of an estimator  <math>\\hat{\\pi}_\\theta</math> with <math>\\mathbb{E}[\\hat{\\pi}_\\theta] = \\pi(\\theta).</math> Now, given <math>\\theta_n</math>  and the respective estimate  <math>\\hat{\\pi}_{\\theta_n}</math> the algorithm proposes a new state according to some density <math>\\theta'\\sim Q( \\cdot \\mid \\theta_n)</math>. Next, compute an estimate  <math>\\hat{\\pi}_{\\theta'}</math> and set <math>\\theta_{n+1} = \\theta'</math> with probability\n\n:<math> a(\\theta_n, \\theta') = \\min\\left( 1, \\frac{\\hat{\\pi}_{\\theta'}}{\\hat{\\pi}_{\\theta_n}} \\frac{Q(\\theta_n\\mid\\theta')}{Q(\\theta'\\mid\\theta_n)}\\right) </math>\n\notherwise the old state is kept, that is, <math>\\theta_{n+1}=\\theta_n</math>.\n\n== Application to Bayesian statistics ==\nIn Bayesian statistics the target of inference is the posterior distribution\n\n:<math>p(\\theta \\mid y) = \\frac{p_\\theta(y)p(\\theta)}{p(y)},</math>\n\nwhere <math>p_\\theta</math> denotes the likelihood function, <math>p</math> is the [[Prior distribution|prior]] and <math>p(y)</math> is the [[Posterior predictive distribution#Prior vs. posterior predictive distribution|prior predictive distribution]].\nSince there is often no analytic expression of this quantity, one often relies on Monte Carlo methods to sample from the distribution instead. Monte Carlo methods often need the likelihood <math>p_\\theta(y)</math> to be accessible for every parameter value <math>\\theta</math>. In some cases, however, the likelihood does not have an analytic expression. An example of such a case is outlined below.\n\n=== Example: Latent variable model<ref name=\":0\" /><ref>{{Cite web|url=https://hips.seas.harvard.edu/blog/2013/03/31/pseudo-marginal-mcmc/|title=Pseudo-marginal MCMC – Building Intelligent Probabilistic Systems|website=hips.seas.harvard.edu|language=en-US|access-date=2018-02-08}}</ref> ===\nConsider a model consisting of [[i.i.d.]] latent real-valued [[random variable]]s <math>Z_1,\\ldots,Z_n</math> with <math>Z_i \\sim f_\\theta(\\cdot)</math> and suppose one can only observe these variables through some additional noise  <math>Y_i \\mid Z_i = z \\sim g_\\theta(\\cdot\\mid z)</math> for some [[conditional density]] <math>g</math>. (This could be due to [[measurement error]], for instance.) We are interested in Bayesian analysis of this model based on some observed data <math>y_1, \\ldots, y_n</math>.  Therefore, we introduce some prior distribution <math>p(\\theta)</math> on the parameter. In order to compute the posterior distribution\n\n: <math>p(\\theta \\mid y_1, \\ldots, y_n) \\propto p_\\theta(y_1, \\ldots, y_n) p(\\theta) </math>\n\nwe need to find the [[Likelihood function|likelihood]] function <math>p_\\theta(y_1, \\ldots, y_n)</math>. The likelihood contribution of any observed data point <math>y</math> is then\n\n: <math>p_\\theta(y) = \\int g_\\theta(y \\mid z)f_\\theta(z) \\, dz </math>\n\nand the joint likelihood of the observed data <math>y_1, \\ldots, y_n</math> is\n\n: <math>p_\\theta(y_1, \\ldots, y_n) = \\prod_{i=1}^n p_\\theta(y_i) = \\prod_{i=1}^n  \\int g_\\theta(y_i \\mid z_i)f_\\theta(z_i) \\, dz_i.</math>\n\nIf the integral on the right-hand side is not analytically available, importance sampling can be used to estimate the likelihood. Introduce an auxiliary distribution <math>q</math> such that <math>g_\\theta(y\\mid z)f_\\theta(z) > 0 \\Rightarrow q(z) > 0 </math> for all <math>z</math> then\n\n: <math>\\hat{p}_\\theta(y_i)=\\frac{1}{N}\\sum_{k=1}^N \\frac{g_\\theta(y_i \\mid Z_k)f_\\theta(Z_k)}{q(Z_k)}, \\qquad Z_k \\overset{i.i.d.}{\\sim} q(\\cdot)</math>\n\nis an unbiased estimator of <math>p_\\theta(y_i)</math> and the joint likelihood can be estimated unbiasedly by\n\n: <math>\\hat{p}_\\theta(y_1, \\ldots, y_n) = \\prod_{i=1}^n \\hat{p}_\\theta(y_i) = \\prod_{i=1}^n \\frac{1}{N} \\sum_{k=1}^N \\frac{g_\\theta(y_i \\mid Z_{i,k}) f_\\theta(Z_{i,k})}{q(Z_{i,k})}, \\qquad Z_{i,k} \\overset{i.i.d.}{\\sim} q(\\cdot).</math>\n\n== References ==\n<!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. -->\n{{reflist}}\n\n{{DEFAULTSORT:Pseudo-marginal Metropolis-Hastings algorithm}}\n[[Category:Monte Carlo methods]]\n[[Category:Statistical algorithms]]"
    },
    {
      "title": "Quantum jump method",
      "url": "https://en.wikipedia.org/wiki/Quantum_jump_method",
      "text": "{{Use American English|date=January 2019}}{{Short desc|Computational simulation method for open quantum systems}}The '''quantum jump method''', also known as the '''[[Monte Carlo method|Monte Carlo]] wave function (MCWF) method''', is a technique in [[computational physics]] used for simulating [[open quantum system]]s. The quantum jump method was developed by [[Jean Dalibard|Dalibard]], Castin and Mølmer, with a very similar method also developed by Carmichael in the same time frame. Other contemporaneous works on wave-function-based [[Monte Carlo method|Monte Carlo]] approaches to open quantum systems include those of Dum, [[Peter Zoller|Zoller]] and [[Helmut Ritsch|Ritsch]] and Hegerfeldt and Wilser.<ref name=\"MCD1993\" /><ref name=\"PrimaryPapers\">The associated primary sources are, respectively:\n\n*{{cite journal|last=Dalibard|first=Jean|author2=Castin, Yvan |author3=Mølmer, Klaus |title=Wave-function approach to dissipative processes in quantum optics|journal=Physical Review Letters|date=February 1992|volume=68|issue=5|pages=580–583|doi=10.1103/PhysRevLett.68.580|pmid=10045937|bibcode = 1992PhRvL..68..580D |arxiv=0805.4002}}\n*{{cite book |last=Carmichael |first=Howard |title=An Open Systems Approach to Quantum Optics |year=1993 |publisher=Springer-Verlag |isbn=978-0-387-56634-4}}\n*{{cite journal|last=Dum|first=R.|author2=Zoller, P. |author3=Ritsch, H. |title=Monte Carlo simulation of the atomic master equation for spontaneous emission|journal=Physical Review A|year=1992|volume=45|issue=7|pages=4879–4887|doi=10.1103/PhysRevA.45.4879|pmid=9907570|bibcode = 1992PhRvA..45.4879D }}\n*{{cite book |last1=Hegerfeldt |first1=G. C. |last2=Wilser |first2=T. S. |year=1992 |title=Classical and Quantum Systems |series= Proceedings of the Second International Wigner Symposium |publisher=World Scientific|url=http://www.theorie.physik.uni-goettingen.de/~hegerf/collaps_gesamt.pdf|pages=104–105|chapter=Ensemble or Individual System, Collapse or no Collapse:  A Description of a Single Radiating Atom|editor1=H.D. Doebner|editor2=W. Scherer|editor3=F. Schroeck, Jr.}}</ref>\n\n== Method ==\n\n[[File:Master equation unravelings.svg|thumb|An example of the quantum jump method being used to approximate the density matrix of a two-level atom undergoing damped [[Rabi oscillation]]s. The random jumps can clearly be seen in the top subplot, and the bottom subplot compares the fully simulated density matrix to the approximation obtained using the quantum jump method.]]\n\n[[File:MC-ensemble average.gif|thumb|Animation of the Monte Carlo prediction (blue) for the population of a coherently-driven, damped two-level system as more trajectories are added to the ensemble average, compared to the master equation prediction (red).]]\n\nThe quantum jump method is an approach which is much like the [[Lindblad equation|master-equation treatment]] except that it operates on the wave function rather than using a [[density matrix]] approach.  The main component of the method is evolving the system's wave function in time with a pseudo-Hamiltonian; where at each [[time step]], a quantum jump (discontinuous change) may take place with some probability. The calculated system state as a function of time is known as a [[Quantum stochastic calculus#Quantum trajectories|quantum trajectory]], and the desired [[density matrix]] as a function of time may be calculated by averaging over many simulated trajectories. For a Hilbert space of dimension N, the number of wave function components is equal to N while the number of density matrix components is equal to N<sup>2</sup>. Consequently, for certain problems the quantum jump method offers a performance advantage over direct master-equation approaches.<ref name=MCD1993>{{Cite journal | last1 = Mølmer | first1 = K. | last2 = Castin | first2 = Y. | last3 = Dalibard | first3 = J. | doi = 10.1364/JOSAB.10.000524 | title = Monte Carlo wave-function method in quantum optics | journal = Journal of the Optical Society of America B | volume = 10 | issue = 3 | pages = 524 | year = 1993 | pmid =  | pmc = |bibcode = 1993JOSAB..10..524M }}</ref>\n\n<!-- Sections to be written: Algorithm; Equivalence to master equation treatment (maybe); Applications -->\n\n== Further reading ==\n* A recent review is {{cite journal|last=Plenio|first=M. B.|author2=Knight, P. L. |title=The quantum-jump approach to dissipative dynamics in quantum optics|journal=Reviews of Modern Physics|date=1 January 1998|volume=70|issue=1|pages=101–144|doi=10.1103/RevModPhys.70.101|bibcode=1998RvMP...70..101P|arxiv = quant-ph/9702007 }}\n\n== References ==\n\n{{Reflist}}\n* [https://qo.phy.auckland.ac.nz/toolbox/ Quantum Optics Toolbox] for Matlab\n* [http://qutip.org/docs/latest/guide/dynamics/dynamics-monte.html mcsolve] Quantum jump (monte carlo) solver from QuTiP.\n* [https://qojulia.org QuantumOptics.jl] the quantum optics toolbox in Julia.\n[[Category:Quantum mechanics]]\n[[Category:Computational physics]]\n[[Category:Monte Carlo methods]]\n{{Quantum-stub}}"
    },
    {
      "title": "Rejection sampling",
      "url": "https://en.wikipedia.org/wiki/Rejection_sampling",
      "text": "In [[numerical analysis]] and [[computational statistics]], '''rejection sampling''' is a basic technique used to generate observations from a [[probability distribution|distribution]]. It is also commonly called the '''acceptance-rejection method''' or \"accept-reject algorithm\" and is a type of exact simulation method. The method works for any distribution in <math>\\mathbb{R}^m</math> with a density.\n\nRejection sampling is based on the observation that to sample a [[random variable]] in one dimension, one can perform a uniformly random sampling of the two-dimensional Cartesian graph, and keep the samples in the '''region''' under the graph of its density function.<ref>{{Cite book|title = Generalized Accept-Reject sampling schemes|pages = 342–347|doi = 10.1214/lnms/1196285403|first = George|last = Casella|first2 = Christian P.|last2 = Robert|first3 = Martin T.|last3 = Wells|isbn = 9780940600614|publisher = Institute of Mathematical Statistics|year = 2004}}</ref><ref>{{Cite journal|title = Generalized rejection sampling schemes and applications in signal processing|journal = Signal Processing|date = 2010-11-01|pages = 2981–2995|volume = 90|issue = 11|doi = 10.1016/j.sigpro.2010.04.025|first = Luca|last = Martino|first2 = Joaquín|last2 = Míguez|arxiv = 0904.1300|citeseerx = 10.1.1.315.2111}}</ref><ref name=\"radford03\">{{cite journal\n |first=Radford M. |last=Neal\n |title=Slice Sampling\n |journal=[[Annals of Statistics]]\n |volume=31 |issue=3 |pages=705–767 |year=2003\n |doi=10.1214/aos/1056562461\n |mr=1994729 | zbl = 1051.65007\n}}</ref><ref name=\"bishop06\">{{cite book\n  | last = Bishop\n  | first = Christopher\n  | title = Pattern Recognition and Machine Learning\n  | publisher = [[Springer Science+Business Media|Springer]]\n  | year = 2006\n  | chapter = 11.4: Slice sampling\n  | isbn = 978-0-387-31073-2\n}}</ref> Note that this property can be extended to N-dimension functions.\n\n==Description==\nTo visualize the motivation behind rejection sampling, imagine graphing the density function of a random variable onto a large rectangular board and throwing darts at it. Assume that the darts are uniformly distributed around the board. Now remove all of the darts that are outside the area under the curve.  The remaining darts will be distributed uniformly within the area under the curve, and the x-positions of these darts will be distributed according to the random variable's density. This is because there is the most room for the darts to land where the curve is highest and thus the probability density is greatest.\n\nThe visualization as just described is equivalent to a particular form of rejection sampling where the proposal distribution is uniform (hence its graph is a rectangle).  The general form of rejection sampling assumes that the board is not necessarily rectangular but is shaped according to some distribution that we know how to sample from (for example, using [[inversion sampling]]), and which is at least as high at every point as the distribution we want to sample from, so that the former completely encloses the latter. Otherwise, there will be parts of the curved area we want to sample from that can never be reached. Rejection sampling works as follows:\n\n#Sample a point on the x-axis from the proposal distribution.\n#Draw a vertical line at this x-position, up to the curve of the proposal distribution.\n#Sample uniformly along this line from 0 to the maximum of the probability density function. If the sampled value is greater than the value of the desired distribution at this vertical line, return to step 1.\n\nThis algorithm can be used to sample from the area under any curve, regardless of whether the function integrates to 1.  In fact, scaling a function by a constant has no effect on the sampled x-positions.  Thus, the algorithm can be used to sample from a distribution whose [[normalizing constant]] is unknown, which is common in [[computational statistics]].\n\n==Examples==\n[[File:Circle sampling.png|right|140px]]\nAs a simple geometric example, suppose it is desired to generate a random point within the unit circle. Generate a candidate point <math>(x,y)</math> where <math>x</math> and <math>y</math> are independent uniformly distributed between &minus;1 and 1. If it happens that <math>x^2+y^2 \\leq 1</math> then the point is within the unit circle and should be accepted. If not then this point should be rejected and another candidate should be generated.\n\nThe [[ziggurat algorithm]], a more advanced example, is used to efficiently generate [[Normal distribution|normally-distributed]] [[pseudorandom number]]s.\n\n==Theory==\nThe rejection sampling method generates sampling values from a target distribution <math>X</math> with arbitrary [[probability density function]] <math>f(x)</math> by using a proposal distribution <math>Y</math> with probability density <math>g(x)</math>.  The idea is that one can generate a sample value from <math>X</math> by instead sampling from <math>Y</math> and accepting the sample from <math>Y</math> with probability <math>f(x)/(M g(x))</math>, repeating the draws from <math>Y</math> until a value is accepted.  <math>M</math> here is a constant, finite bound on the likelihood ratio <math>f(x)/g(x)</math>, satisfying <math>1 < M < \\infty</math> over the [[Support (mathematics)|support]] of <math>X</math>; in other words, M must satisfy <math>f(x) \\leq M g(x)</math> for all values of <math>x</math>.  Note that this requires that the support of <math>Y</math> must include the support of <math>X</math>—in other words, <math>g(x) > 0</math> whenever <math>f(x) > 0</math>.\n\nThe validation of this method is the '''envelope principle''': when simulating the pair <math display=\"inline\">(x,v=u\\cdot Mg(x))</math>, one produces a uniform simulation over the subgraph of <math display=\"inline\">Mg(x)</math>. Accepting only pairs such that <math display=\"inline\">u<f(x)/(Mg(x))</math> then produces pairs <math>(x,v)</math> uniformly distributed over the subgraph of <math>f(x)</math> and thus, marginally, a simulation from <math>f(x).</math>\n\nThis means that, with enough replicates, the algorithm generates a sample from the desired distribution <math>f(x)</math>. There are a number of extensions to this algorithm, such as the [[Metropolis algorithm]] and the combination with ratio-of-uniforms approach.<ref>{{Cite journal|title = Efficient random variable generation: ratio of uniforms and polar rejection sampling|journal = Electronics Letters|volume = 48|issue = 6|pages = 326|doi = 10.1049/el.2012.0206|first = D.|last = Luengo|first2 = L.|last2 = Martino|year = 2012|url = http://oa.upm.es/22661/|type = Submitted manuscript}}</ref>\n\nThis method relates to the general field of [[Monte Carlo method|Monte Carlo]] techniques, including [[Markov chain Monte Carlo]] algorithms that also use a proxy distribution to achieve simulation from the target distribution <math>f(x)</math>. It forms the basis for algorithms such as the [[Metropolis algorithm]].\n\nThe '''unconditional acceptance probability''' is the proportion of proposed samples which are accepted, which is <blockquote><math>\n\\begin{align}\n\\mathbb{P}\\left(U\\le\\frac{f(Y)}{M g(Y)}\\right) &= \\operatorname{E}\\mathbf{1}_{\\left[U\\le\\frac{f(Y)}{M g(Y)}\\right]}\\\\[6pt]\n&= E\\left[\\operatorname{E}[\\mathbf{1}_{\\left[U\\le\\frac{f(Y)}{M g(Y)}\\right]}| Y]\\right] & (\\text{by tower property } ) \\\\[6pt] \n&= \\operatorname{E}\\left[\\mathbb{P}\\left(U\\le \\frac{f(Y)}{Mg(Y)} \\biggr| Y\\right) \\right]\\\\[6pt]\n&= E\\left[\\frac{f(Y)}{M g(Y)}\\right] & (\\text{because } \\Pr(U \\leq u) = u, \\text{when } U \\text{ is uniform on } (0,1)) \\\\[6pt] \n&=\\int\\limits_{y: g(y) > 0} \\frac{f(y)}{M g(y)} g(y) \\, dy\\\\ [6pt]\n&= \\frac{1}{M}\\int\\limits_{y: g(y) > 0} f(y) \\, dy \\\\[6pt]\n&= \\frac{1}{M} & (\\text{since support of } Y \\text{ includes support of } X)\n\\end{align}\n</math></blockquote>where <math>U\\sim \\mathrm{Unif}(0,1)</math>, and the value of <math>y</math> each time is generated under the density function <math>g(.)</math> of the proposal distribution <math>Y</math>.\n\nThe number of samples required from <math>Y</math> to obtain an accepted value thus follows a [[geometric distribution]] with probability <math>1/M</math>, which has mean <math>M</math>.  Intuitively, <math>M</math> is the expected number of the iterations that are needed, as a measure of the computational complexity of the algorithm.\n\nRewrite the above equation,  <blockquote><math>M=\\frac{1}{\\mathbb{P}\\left(U\\le\\frac{f(Y)}{M g(Y)}\\right)}</math></blockquote>\nNote that <math display=\"inline\">1 \\le M<\\infty</math>, due to the above formula, where <math display=\"inline\">\\mathbb{P}\\left(U\\le\\frac{f(Y)}{M g(Y)}\\right)</math> is a probability which can only take values in the interval <math>[0,1]</math>. When <math>M</math> is chosen closer to one, the unconditional acceptance probability is higher the less that ratio varies, since <math>M</math> is the upper bound for the likelihood ratio <math display=\"inline\">f(x)/g(x)</math>.  In practice, a value of <math>M</math> closer to 1 is preferred as it implies fewer rejected samples, on average, and thus fewer iterations of the algorithm.  In this sense, one prefers to have <math>M</math> as small as possible (while still satisfying <math>f(x) \\leq M g(x)</math>, which suggests that <math>g(x)</math> should generally resemble <math>f(x)</math> in some way.  Note, however, that <math>M</math> cannot be equal to 1: such would imply that <math>f(x)=g(x)</math>, i.e. that the target and proposal distributions are actually the same distribution.\n\nRejection sampling is most often used in cases where the form of <math>f(x)</math> makes sampling difficult.  A single iteration of the rejection algorithm requires sampling from the proposal distribution, drawing from a uniform distribution, and evaluating the <math>f(x)/(M g(x))</math> expression.  Rejection sampling is thus more efficient than some other method whenever M times the cost of these operations—which is the expected cost of obtaining a sample with rejection sampling—is lower than the cost of obtaining a sample using the other method.\n\n==Algorithm==\nThe algorithm (used by [[John von Neumann]] and dating back to Buffon and [[Buffon's needle|his needle]]) to obtain a sample from distribution <math>X</math> with density <math>f</math> using samples from distribution <math>Y</math> with density <math>g</math> is as follows:\n* Obtain a sample <math>y</math> from distribution <math>Y</math> and a sample <math>u</math> from <math>\\mathrm{Unif}(0,1)</math> (the uniform distribution over the unit interval).\n* Check whether or not <math display=\"inline\">u<f(y)/Mg(y)</math>.\n** If this holds, accept <math>y</math> as a sample drawn from <math>f</math>;\n** if not, reject the value of <math>y</math> and return to the sampling step.\n\nThe algorithm will take an average of <math>M</math> iterations to obtain a sample.\n\n== Advantages over sampling using naive methods ==\nRejection sampling can be far more efficient compared with the Naive methods in some situations. For example, given a problem as sampling <math display=\"inline\">X\\sim F(\\cdot)</math> conditionally on <math>X</math> given the set <math>A</math>, i.e., <math display=\"inline\">X|X\\in A</math>, sometimes <math display=\"inline\">X</math> can be easily simulated, using the Naive methods (e.g. by [[inverse transform sampling]]):\n* Sample <math display=\"inline\">X\\sim F(\\cdot)</math> independently, and leave those satisfying <math>\\{n\\ge 1: X_n\\in A\\}</math> \n* Output: <math>\\{X_1,X_2,...,X_N:X_i\\in A, i=1,...,N\\}</math>\nThe problem is this sampling can be difficult and inefficient, if <math display=\"inline\">\\mathbb{P}(X\\in A)\\approx 0</math>. The expected number of iterations would be <math>\\frac{1}{\\mathbb{P}(X\\in A)}</math>, which could be close to infinity. Moreover, even when you apply the Rejection sampling method, it is always hard to optimize the bound <math>M</math> for the likelihood ratio. More often than not, <math>M</math> is large and the rejection rate is high, the algorithm can be very inefficient. The [[Natural exponential families|Natural Exponential Family]] (if it exists), also known as exponential tilting, provides a class of proposal distributions that can lower the computation complexity, the value of <math>M</math> and speed up the computations (see examples: working with Natural Exponential Families).\n\n== Examples: working with natural exponential families ==\nGiven a random variable <math>X\\sim F(\\cdot)</math>, <math>F(x)=\\mathbb{P}(X\\le x)</math> is the target distribution. Assume for the simplicity, the density function can be explicitly written as <math>f(x)</math> . Choose the proposal as<blockquote><math>\\begin{align}\nF_\\theta (x)&=\\mathbb{E}\\left[\\mathrm{exp}(\\theta X-\\psi (\\theta))\\mathbb{I}(X\\le x)\\right]\\\\\n&=\\int^x_{-\\infty}e^{\\theta y-\\psi(\\theta)}f(y)dy\\\\\ng_\\theta(x)&=F^'_\\theta(x)=e^{\\theta x-\\psi(\\theta)}f(x)\n\\end{align}</math></blockquote>where <math>\\psi(\\theta)=\\mathrm{log}\\left(\\mathbb{E}\\mathrm{exp}(\\theta X)\\right)</math> and <math>\\Theta = \\{\\theta :\\psi(\\theta)<\\infty\\}</math>. Clearly, <math>\\{F_\\theta (\\cdot)\\}_{\\theta \\in \\Theta}</math>, is from a [[natural exponential family]]. Moreover, the likelihood ratio is <blockquote><math>Z(x)=\\frac{f(x)}{g_\\theta(x)}=\\frac{f(x)}{e^{\\theta x-\\psi(\\theta)}f(x)}=e^{-\\theta x+\\psi(\\theta)}</math></blockquote>Note that <math>\\psi (\\theta)<\\infty</math> implies that it is indeed a log [[Moment-generating function|moment-generation function]], that is, <math>\\psi(\\theta)=\\log\\mathbb{E}{\\exp(tX)}|_{t=\\theta}=\\log M_X(t)|_{t=\\theta}</math>. And it is easy to derive the log moment-generation function of the proposal and therefore the proposal's moments.<blockquote><math>\\begin{align}\n\\psi_\\theta(\\eta)&=\\log\\left(\\mathbb{E}_\\theta\\exp(\\eta X)\\right)=\\psi(\\theta+\\eta)-\\psi(\\theta)<\\infty\\\\\n\\mathbb{E}_\\theta(X)&=\\frac{\\partial \\psi_\\theta(\\eta)}{\\partial\\eta}\\mid_{\\eta=0}\\\\\nVar_\\theta(X)&=\\frac{\\partial^2 \\psi_\\theta(\\eta)}{\\partial^2\\eta}\\mid_{\\eta=0}\n\\end{align}</math></blockquote>As a simple example, suppose under <math>F(\\cdot)</math>, <math>X \\sim \\mathrm{N}(\\mu, \\sigma^2)</math>, with <math display=\"inline\">\\psi(\\theta)=\\theta \\mu+\\frac{\\sigma^2\\theta^2}{2}</math>. The goal is to sample <math>X|X\\in \\left[b,\\infty\\right]</math>, <math>b>\\mu</math>. The analysis goes as followed.\n* Choose the form of the proposal distribution <math>F_\\theta(\\cdot)</math>, with log moment-generating function as <math display=\"inline\">\\psi_\\theta(\\eta)=\\psi (\\theta+\\eta)-\\psi(\\eta)=\\eta(\\mu+\\theta\\sigma^2)+\\frac{\\sigma^2\\eta^2}{2}</math>, which further implies it is a normal distribution <math>\\mathrm{N}(\\mu+\\theta\\sigma^2, \\sigma^2)</math>. \n* Decide the well chosen <math>\\theta^*</math> for the proposal distribution. In this setup, the intuitive way to choose <math>\\theta^*</math> is to set <math>\\mathbb{E}_{\\theta}(X)=\\mu+\\theta\\sigma^2=b</math>, that is <math>\\theta^*=\\frac{b-\\mu}{\\sigma^2}</math>\n* Explicitly write out the target, the proposal and the likelihood ratio\n<blockquote><math>\\begin{align}\nf_{X|X\\ge b}(x)&=\\frac{f(x)\\mathbb{I}(x\\ge b)}{\\mathbb{P}(x\\ge b)}\\\\\ng_{\\theta^*}(x)&=f(x)\\exp(\\theta^* x-\\psi(\\theta^*))\\\\\nZ(x)&=\\frac{f_{X|X\\ge b}(x)}{g_{\\theta^*}(x)}=\\frac{\\exp(-\\theta^* x+\\psi(\\theta^*))\\mathbb{I}(x\\ge b)}{\\mathbb{P}(x\\ge b)}\n\\end{align}</math></blockquote>\n* Derive the bound <math>M</math> for the likelihood ratio <math>z(x)</math>, which is a decreasing function for <math>x \\in [b, \\infty]</math>, therefore\n<blockquote><math>M=Z(b)=\\frac{\\exp(-\\theta^*b+\\psi(\\theta^*))}{\\mathbb{P}(X\\ge b)}=\\frac{\\exp(-\\frac{(b-\\mu)^2}{2\\sigma^2})}{\\mathbb{P}(X\\ge b)}=\\frac{\\exp(-\\frac{(b-\\mu)^2}{2\\sigma^2})}{\\mathbb{P}(\\mathrm{N}(0,1)\\ge\\frac{b-\\mu}{\\sigma})}</math></blockquote>\n* Rejection sampling criterion: for <math>U\\sim \\mathrm{Unif}(0,1)</math>, if \n<blockquote><math>U\\le \\frac{Z(x)}{M}=e^{-\\theta^*(x-b)}\\mathbb{I}(x\\ge b)</math></blockquote>holds, accept the value of <math>X</math>; if not, continue sampling new <math display=\"inline\">X\\sim_{i.i.d.}\\mathrm{N}(\\mu+\\theta^*\\sigma^2,\\sigma^2)</math> and new <math display=\"inline\">U\\sim \\mathrm{Unif}(0,1)</math> until acceptance.\n\nFor the above example, as the measurement of the efficiency, the expected number of the iterations the NEF-Based Rejection sampling method is of order b, that is <math>M(b)=O(b)</math>, while under the Naive method, the expected number of the iterations is <math display=\"inline\">\\frac{1}{\\mathbb{P}(X\\ge b)}=O(b\\cdot e^{\\frac{(b-\\mu)^2}{2\\sigma^2}})</math>, which is far more inefficient.\n\nIn general, exponential tilting, a parametric class of proposal distribution, solves the optimization problems conveniently, with its useful properties that directly characterize the distribution of the proposal. For this type of problem, to simulate <math>X</math> conditionally on <math>X\\in A</math>, among the class of simple distributions, the trick is to use NEFs, which helps to gain some control over the complexity and considerably speed up the computation. Indeed, there are deep mathematical reasons for using NEFs.\n\n==Drawbacks==\n\nRejection sampling can lead to a lot of unwanted samples being taken if the function being sampled is highly concentrated in a certain region, for example a function that has a spike at some location.  For many distributions, this problem can be solved using an adaptive extension (see [[#Adaptive rejection sampling|adaptive rejection sampling]]). In addition, as the dimensions of the problem get larger, the ratio of the embedded volume to the \"corners\" of the embedding volume tends towards zero, thus a lot of rejections can take place before a useful sample is generated, thus making the algorithm inefficient and impractical. See [[curse of dimensionality]]. In high dimensions, it is necessary to use a different approach, typically a Markov chain Monte Carlo method such as [[Metropolis sampling]] or [[Gibbs sampling]]. (However, Gibbs sampling, which breaks down a multi-dimensional sampling problem into a series of low-dimensional samples, may use rejection sampling as one of its steps.)\n\n==Adaptive rejection sampling==\n\nFor many distributions, finding a proposal distribution that includes the given distribution without a lot of wasted space is difficult.  An extension of rejection sampling that can be used to overcome this difficulty and efficiently sample from a wide variety of distributions (provided that they have [[Logarithmically concave function|log-concave]] density functions, which is in fact the case for most of the common distributions—even those whose ''density'' functions are '''not''' concave themselves!) is known as '''adaptive rejection sampling (ARS)'''.\n\nThere are three basic ideas to this technique as ultimately introduced by Gilks in 1992:<ref>Adaptive Rejection Sampling for Gibbs Sampling. https://stat.duke.edu/~cnk/Links/tangent.method.pdf</ref>\n\n# If it helps, '''define your envelope distribution in log space''' (e.g. log-probability or log-density) '''instead'''. That is, work with <math> h\\left(x\\right) = \\mathrm{ log }\\; g\\left(x\\right)</math> instead of <math> g\\left(x\\right)</math> directly.\n#* Often, distributions that have algebraically messy density functions have reasonably simpler log density functions (i.e. when <math>f\\left( x \\right) </math> is messy, <math> \\mathrm{log}\\; f\\left(x\\right)</math> may be easier to work with or, at least, closer to piecewise linear). \n# Instead of a single uniform envelope density function, '''use a piecewise linear density function as your envelope instead'''.\n#* Each time you have to reject a sample, you can use the value of <math> f \\left(x \\right) </math> that you evaluated, to improve the piecewise approximation  <math> h \\left(x \\right) </math>. This therefore reduces the chance that your next attempt will be rejected. Asymptotically, the probability of needing to reject your sample should converge to zero, and in practice, often very rapidly.\n#* As proposed, any time we choose a point that is rejected, we tighten the envelope with another line segment that is tangent to the curve at the point with the same x-coordinate as the chosen point.\n#* A piecewise linear model of the proposal log distribution results in a set of piecewise [[exponential distribution]]s (i.e. segments of one or more exponential distributions, attached end to end). Exponential distributions are well behaved and well understood. The logarithm of an exponential distribution is a straight line, and hence this method essentially involves enclosing the logarithm of the density in a series of line segments.  This is the source of the log-concave restriction: if a distribution is log-concave, then its logarithm is concave (shaped like an upside-down U), meaning that a line segment tangent to the curve will always pass over the curve. \n#* If not working in log space, a piecewise linear density function can also be sampled via triangle distributions <ref>D.B. Thomas and W. Luk , Non-uniform random number generation through piecewise linear approximations, 2006. http://www.doc.ic.ac.uk/~wl/papers/iee07dt.pdf</ref>\n# We can take even further advantage of the (log) concavity requirement, to potentially '''avoid the cost of evaluating <math>f \\left( x \\right)</math>''' when your sample ''is'' accepted.\n#* Just like we can construct a piecewise linear upper bound (the \"envelope\" function) using the values of <math> h \\left(x \\right) </math> that we had to evaluate in the current chain of rejections, we can also construct a piecewise linear lower bound (the \"squeezing\" function) using these values as well.\n#* Before evaluating (the potentially expensive) <math>f \\left( x \\right)</math> to see if your sample will be accepted, we may ''already know'' if it will be accepted by comparing against the (ideally cheaper) <math> g_l \\left( x \\right) </math> (or <math>h_l \\left( x \\right)</math> in this case) squeezing function that have available.\n#* This squeezing step is optional, even when suggested by Gilks. At best it saves you from only one extra evaluation of your (messy and/or expensive) target density. However, presumably for particularly expensive density functions (and assuming the rapid convergence of the rejection rate toward zero) this can make a sizable difference in ultimate runtime.\n\nThe method essentially involves successively determining an envelope of straight-line segments that approximates the logarithm better and better while still remaining above the curve, starting with a fixed number of segments (possibly just a single tangent line). Sampling from a truncated exponential random variable is straightforward. Just take the log of a uniform random variable (with appropriate interval and corresponding truncation).\n\nIn standard ARS,  the probability of adding a new nodes vanishes to zero as the number of iterations increases. However, there is always a positive probability of adding a new node. For this reason, the number of nodes grows with the iterations. Two variants of the classical ARS scheme have been proposed to speed up the method, keeping fixed the number of nodes or finding a better addition statistical test.<ref>{{Cite journal|last=Luca Martino|first=Francisco Louzada|date=2017|title=Adaptive Rejection Sampling with Fixed Number of Nodes|url=|journal=Communications in Statistics – Simulation and Computation|volume=|pages=|via=|bibcode=2015arXiv150907985M|arxiv=1509.07985}}</ref><ref>{{Cite journal|last=Martino|first=L.|title=Parsimonious adaptive rejection sampling|journal=Electronics Letters|volume=53|issue=16|pages=1115–1117|doi=10.1049/el.2017.1711|year=2017|arxiv=1710.04948}}</ref>\n\nUnfortunately, ARS can only be applied from sampling from log-concave target densities. For this reason, several extensions of ARS have been proposed in literature for tackling non-log-concave target distributions.<ref>{{Cite journal|title = A Rejection Technique for Sampling from T-concave Distributions|journal = ACM Trans. Math. Softw.|date = 1995-06-01|issn = 0098-3500|pages = 182–193|volume = 21|issue = 2|doi = 10.1145/203082.203089|first = Wolfgang|last = Hörmann|citeseerx = 10.1.1.56.6055}}</ref><ref>{{Cite journal|title = Random Variable Generation Using Concavity Properties of Transformed Densities|jstor = 1390680|journal = Journal of Computational and Graphical Statistics|date = 1998-12-01|pages = 514–528|volume = 7|issue = 4|doi = 10.2307/1390680|first = M.|last = Evans|first2 = T.|last2 = Swartz|citeseerx = 10.1.1.53.9001}}</ref><ref>{{Cite journal|title = A generalization of the adaptive rejection sampling algorithm|journal = Statistics and Computing|date = 2010-08-25|issn = 0960-3174|pages = 633–647|volume = 21|issue = 4|doi = 10.1007/s11222-010-9197-9|first = Luca|last = Martino|first2 = Joaquín|last2 = Míguez|hdl = 10016/16624}}</ref><ref>{{Cite journal|title = Concave-Convex Adaptive Rejection Sampling|journal = Journal of Computational and Graphical Statistics|date = 2011-01-01|issn = 1061-8600|pages = 670–691|volume = 20|issue = 3|doi = 10.1198/jcgs.2011.09058|first = Dilan|last = Görür|first2 = Yee Whye|last2 = Teh}}</ref> Furthermore, different combinations of ARS and the Metropolis-Hastings method have been designed in order to obtain a universal sampler that builds a self-tuning proposal densities (i.e., a proposal automatically constructed and adapted to the target). This class of methods are often called as '''Adaptive Rejection Metropolis Sampling (ARMS) algorithms''' <ref>{{Cite journal|title = Adaptive Rejection Metropolis Sampling within Gibbs Sampling|jstor = 2986138|journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1995-01-01|pages = 455–472|volume = 44|issue = 4|doi = 10.2307/2986138|first = W. R.|last = Gilks|first2 = N. G.|last2 = Best|first3 = K. K. C.|last3 = Tan}}</ref><ref>{{Cite journal|title = Adaptive rejection Metropolis sampling using Lagrange interpolation polynomials of degree 2|journal = Computational Statistics & Data Analysis|date = 2008-03-15|pages = 3408–3423|volume = 52|issue = 7|doi = 10.1016/j.csda.2008.01.005|first = Renate|last = Meyer|first2 = Bo|last2 = Cai|first3 = François|last3 = Perron}}</ref><ref>{{Cite journal|title = Independent Doubly Adaptive Rejection Metropolis Sampling Within Gibbs Sampling|journal = IEEE Transactions on Signal Processing|date = 2015-06-01|issn = 1053-587X|pages = 3123–3138|volume = 63|issue = 12|doi = 10.1109/TSP.2015.2420537|first = L.|last = Martino|first2 = J.|last2 = Read|first3 = D.|last3 = Luengo|arxiv = 1205.5494|bibcode = 2015ITSP...63.3123M}}</ref> (see some suitable [http://a2rms.sourceforge.net Matlab code]). The resulting adaptive techniques can be always applied but the generated samples are correlated in this case (although the correlation vanishes quickly to zero as the number of iterations grows).\n\n==See also==\n*[[Inverse transform sampling]]\n*[[Pseudo-random number sampling]]\n\n==References==\n\n{{reflist}}\n*Robert, C.P. and Casella, G. \"Monte Carlo Statistical Methods\" (second edition). New York: Springer-Verlag, 2004.\n*J. von Neumann, \"Various techniques used in connection with random digits. Monte Carlo methods\", Nat. Bureau Standards, 12 (1951), pp.&nbsp;36–38.\n\n[[Category:Monte Carlo methods]]\n[[Category:Non-uniform random numbers]]"
    },
    {
      "title": "Resampling (statistics)",
      "url": "https://en.wikipedia.org/wiki/Resampling_%28statistics%29",
      "text": "{{Other uses|Resampling (disambiguation){{!}}Resampling}}\n{{Merge from | Plug-in_principle | discuss=Talk:Plug-in_principle#Merger discussion | date=August 2018 }}\nIn [[statistics]], '''resampling''' is any of a variety of methods for doing one of the following:\n# Estimating the precision of sample [[statistic]]s ([[median]]s, [[variance]]s, [[percentile]]s) by using subsets of available data ('''[[Jackknife (statistics)|jackknifing]]''') or drawing [[random]]ly with replacement from a set of data points ('''[[bootstrapping (statistics)|bootstrapping]]''')\n# Exchanging labels on data points when performing [[significance test]]s ('''permutation tests''', also called [[exact test]]s, randomization tests, or re-randomization tests)\n# Validating models by using random subsets (bootstrapping, [[Cross-validation (statistics)|cross validation]])\n\n==Bootstrap==\n{{main article|Bootstrap (statistics)}}\nBootstrapping is a statistical method for estimating the [[sampling distribution]] of an [[estimator]] by [[sampling (statistics)|sampling]] with replacement from the original sample, most often with the purpose of deriving robust estimates of [[standard error]]s and [[confidence intervals]] of a population parameter like a [[mean]], [[median]], [[Proportionality (mathematics)|proportion]], [[odds ratio]], [[Pearson product-moment correlation coefficient|correlation coefficient]] or [[Regression analysis|regression]] coefficient. It may also be used for constructing hypothesis tests. It is often used as a robust alternative to inference based on parametric assumptions when those assumptions are in doubt, or where parametric inference is impossible or requires very complicated formulas for the calculation of standard errors. Bootstrapping techniques are also used in the updating-selection transitions of [[particle filter]]s, [[Genetic algorithm|genetic type algorithms]] and related resample/reconfiguration Monte Carlo methods used in [[computational physics]].<ref name=\"dp042\">{{cite book|last = Del Moral|first = Pierre|title = Feynman-Kac formulae. Genealogical and interacting particle approximations|year = 2004|publisher = Springer|quote = Series: Probability and Applications|url = https://www.springer.com/mathematics/probability/book/978-0-387-20268-6|pages = 575}}</ref><ref name=\"dp13\">{{cite book|last = Del Moral|first = Pierre|title = Mean field simulation for Monte Carlo integration|year = 2013|publisher = Chapman & Hall/CRC Press|quote = Monographs on Statistics & Applied Probability|url = http://www.crcpress.com/product/isbn/9781466504059|pages = 626}}</ref> In this context, the bootstrap is used to replace sequentially empirical weighted probability measures by [[empirical measure]]s. The bootstrap allows to replace the samples with low weights by copies of the samples with high weights.\n\n==Jackknife==\n{{main article|Jackknife resampling}}\nJackknifing, which is similar to bootstrapping, is used in [[statistical inference]] to estimate the bias and standard error (variance) of a statistic, when a random sample of observations is used to calculate it. Historically, this method preceded the invention of the bootstrap with [[Maurice Quenouille|Quenouille]] inventing this method in 1949 and [[John Tukey|Tukey]] extending it in 1958.<ref name=Quenouille1949>{{cite book |last=Quenouille |first=M. H. |year=1949 |title=Approximate Tests of Correlation in Time-Series |journal=[[Journal of the Royal Statistical Society, Series B]] |volume=11 |issue=1 |pages=68–84 |jstor=2983696 }}</ref><ref name=Tukey1958>{{cite journal |last=Tukey |first=J. W. |year=1958 |title=Bias and Confidence in Not-quite Large Samples (Preliminary Report) |journal=[[Annals of Mathematical Statistics]] |volume=29 |issue=2 |pages=614 |jstor=2237363 }}</ref> This method was foreshadowed by [[Prasanta Chandra Mahalanobis|Mahalanobis]] who in 1946 suggested repeated estimates of the statistic of interest with half the sample chosen at random.<ref name=Mahalanobis1946>{{cite journal |last=Mahalanobis |first=P. C. |year=1946 |title=Proceedings of a Meeting of the Royal Statistical Society held on July 16th, 1946 |journal=[[Journal of the Royal Statistical Society]] |volume=109 |issue=4 |pages=325–370 |jstor=2981330 }}</ref> He coined the name 'interpenetrating samples' for this method.\n\nQuenouille invented this method with the intention of reducing the bias of the sample estimate. Tukey extended this method by assuming that if the replicates could be considered identically and independently distributed, then an estimate of the variance of the sample parameter could be made and that it would be approximately distributed as a t variate with ''n''−1 degrees of freedom (''n'' being the sample size).\n\nThe basic idea behind the jackknife variance estimator lies in systematically recomputing the statistic estimate, leaving out one or more observations at a time from the sample set. From this new set of replicates of the statistic, an estimate for the bias and an estimate for the variance of the statistic can be calculated.\n\nInstead of using the jackknife to estimate the variance, it may instead be applied to the log of the variance. This transformation may result in better estimates particularly when the distribution of the variance itself may be non normal.\n\nFor many statistical parameters the jackknife estimate of variance tends asymptotically to the true value almost surely. In technical terms one says that the jackknife estimate is [[Consistency (statistics)|consistent]]. The jackknife is consistent for the sample [[mean]]s, sample [[variance]]s, central and non-central t-statistics (with possibly non-normal populations), sample [[coefficient of variation]], [[maximum likelihood estimator]]s, least squares estimators, [[Pearson product-moment correlation coefficient|correlation coefficients]] and [[regression coefficient]]s.\n\nIt is not consistent for the sample [[median]]. In the case of a unimodal variate the ratio of the jackknife variance to the sample variance tends to be distributed as one half the square of a chi square distribution with two [[degrees of freedom]].\n\nThe jackknife, like the original bootstrap, is dependent on the independence of the data. Extensions of the jackknife to allow for dependence in the data have been proposed.\n\nAnother extension is the delete-a-group method used in association with [[Poisson sampling]].\n\n==Comparison of bootstrap and jackknife==\nBoth methods, the bootstrap and the jackknife, estimate the variability of a statistic from the variability of that statistic between subsamples, rather than from parametric assumptions. For the more general jackknife, the delete-m observations jackknife, the bootstrap can be seen as a random approximation of it. Both yield similar numerical results, which is why each can be seen as approximation to the other. Although there are huge theoretical differences in their mathematical insights, the main practical difference for statistics users is that the [[Bootstrapping (statistics)|bootstrap]] gives different results when repeated on the same data, whereas the jackknife gives exactly the same result each time. Because of this, the jackknife is popular when the estimates need to be verified several times before publishing (e.g., official statistics agencies). On the other hand, when this verification feature is not crucial and it is of interest not to have a number but just an idea of its distribution, the bootstrap is preferred (e.g., studies in physics, economics, biological sciences).\n\nWhether to use the bootstrap or the jackknife may depend more on operational aspects than on statistical concerns of a survey. The jackknife, originally used for bias reduction, is more of a specialized method and only estimates the variance of the point estimator. This can be enough for basic statistical inference (e.g., hypothesis testing, confidence intervals). The bootstrap, on the other hand, first estimates the whole distribution (of the point estimator) and then computes the variance from that. While powerful and easy, this can become highly computer intensive.\n\n\"The bootstrap can be applied to both variance and distribution estimation problems. However, the bootstrap variance estimator is not as good as the jackknife or the [[balanced repeated replication]] (BRR) variance estimator in terms of the empirical results. Furthermore, the bootstrap variance estimator usually requires more computations than the jackknife or the BRR. Thus, the bootstrap is mainly recommended for distribution estimation.\" <ref>Shao, J. and Tu, D. (1995). The Jackknife and Bootstrap. Springer-Verlag, Inc. pp. 281.</ref>\n\nThere is a special consideration with the jackknife, particularly with the delete-1 observation jackknife. It should only be used with smooth, differentiable statistics (e.g., totals, means, proportions, ratios, odd ratios, regression coefficients, etc.; not with medians or quantiles). This could become a practical disadvantage. This disadvantage is usually the argument favoring bootstrapping over jackknifing. More general jackknifes than the delete-1, such as the delete-m jackknife or the delete-all-but-2 [[Hodges–Lehmann estimator]], overcome this problem for the medians and quantiles by relaxing the smoothness requirements for consistent variance estimation.\n\nUsually the jackknife is easier to apply to complex sampling schemes than the bootstrap. Complex sampling schemes may involve stratification, multiple stages (clustering), varying sampling weights (non-response adjustments, calibration, post-stratification) and under unequal-probability sampling designs. Theoretical aspects of both the bootstrap and the jackknife can be found in Shao and Tu (1995),<ref>{{cite book |last=Shao |first=J. |last2=Tu |first2=D. |year=1995 |title=The Jackknife and Bootstrap |location= |publisher=Springer }}</ref> whereas a basic introduction is accounted in Wolter (2007).<ref>{{cite book |last=Wolter |first=K. M. |year=2007 |title=Introduction to Variance Estimation |edition=Second |location= |publisher=Springer }}</ref> The bootstrap estimate of model prediction bias is more precise than jackknife estimates with linear models such as linear discriminant function or multiple regression.<ref>{{cite journal |last=Verbyla |first=D. |last2=Litvaitis |first2=J. |year=1989 |title=Resampling methods for evaluating classification accuracy of wildlife habitat models |journal=[[Environmental Management]] |volume=13 |issue=6 |pages=783–787 |doi=10.1007/bf01868317|bibcode=1989EnMan..13..783V }}</ref>\n\n==Subsampling==\n{{main article|Subsampling (statistics)}}\n\nSubsampling is an alternative method for approximating the sampling distribution of an estimator. The two key differences to the bootstrap are: (i) the resample size is smaller than the sample size and (ii) resampling is done without replacement. The advantage of subsampling is that it is valid under much weaker conditions compared to the bootstrap. In particular, a set of sufficient conditions is that the rate of convergence of the estimator is known and that the limiting distribution is continuous; in addition, the resample (or subsample) size must tend to infinity together with the sample size but at a smaller rate, so that their ratio converges to zero. While subsampling was originally proposed for the case of independent and identically distributed (iid) data only, the methodology has been extended to cover time series data as well; in this case, one resamples blocks of subsequent data rather than individual data points. There are many cases of applied interest where subsampling leads to valid inference whereas bootstrapping does not; for example, such cases include examples where the rate of convergence of the estimator is not the square root of the sample size or when the limiting distribution is non-normal.\n\n==Cross-validation==\n{{main article|Cross-validation (statistics)}}\nCross-validation is a statistical method for validating a [[predictive modelling|predictive model]]. Subsets of the data are held out for use as validating sets; a model is fit to the remaining data (a training set) and used to predict for the validation set.  Averaging the quality of the predictions across the validation sets yields an overall measure of prediction accuracy. Cross-validation is employed repeatedly in building decision trees.\n\nOne form of cross-validation leaves out a single observation at a time; this is similar to the jackknife. Another, ''K''-fold cross-validation, splits the data into ''K'' subsets; each is held out in turn as the validation set.\n\nThis avoids \"self-influence\".  For comparison, in [[regression analysis]] methods such as [[linear regression]], each ''y'' value draws the regression line toward itself, making the prediction of that value appear more accurate than it really is.  Cross-validation applied to linear regression predicts the ''y'' value for each observation without using that observation.\n\nThis is often used for deciding how many predictor variables to use in regression.  Without cross-validation, adding predictors always reduces the residual sum of squares (or possibly leaves it unchanged).  In contrast, the cross-validated mean-square error will tend to decrease if valuable predictors are added, but increase if worthless predictors are added.<ref>{{cite journal |last=Verbyla |first=D. |year=1986 |title=Potential prediction bias in regression and discriminant analysis |journal=[[Canadian Journal of Forest Research]] |volume=16 |issue=6 |pages=1255–1257 |doi=10.1139/x86-222 }}</ref>\n\n==Permutation tests==\n\n<!-- [[Permutation test]] redirects to this section name  -->\n{{main article|Exact test}}\n\nA '''permutation test''' (also called a randomization test, re-randomization test, or an [[exact test]]) is a type of [[statistical hypothesis testing|statistical significance test]] in which the distribution of the test statistic under the [[null hypothesis]] is obtained by calculating all possible values of the [[test statistic]] under rearrangements of the labels on the observed data points.  In other words, the method by which treatments are allocated to subjects in an experimental design is mirrored in the analysis of that design. If the labels are exchangeable under the null hypothesis, then the resulting tests yield exact significance levels; see also [[exchangeability]]. Confidence intervals can then be derived from the tests. The theory has evolved from the works of [[Ronald Fisher]] and [[E. J. G. Pitman]] in the 1930s.\n\nTo illustrate the basic idea of a permutation test, suppose we collect random variables <math>X_A</math> and <math>X_B</math> for each individual from two groups <math>A</math> and <math>B</math> whose sample means are <math>\\bar{x}_{A}</math> and <math>\\bar{x}_{B}</math>, and that we want to know whether <math>X_A</math> and <math>X_B</math> come from the same distribution. Let <math>n_{A}</math> and <math>n_{B}</math> be the sample size collected from each group. The permutation test is designed to determine whether the observed difference between the sample means is large enough to reject, at some significance level, the null hypothesis H<math>_{0}</math> that the data drawn from <math>A</math> is from the same distribution as the data drawn from <math>B</math>.\n\nThe test proceeds as follows. First, the difference in means between the two samples is calculated: this is the observed value of the test statistic, <math>T_\\text{obs}</math>. \n\nNext, the observations of groups <math>A</math> and <math>B</math> are pooled, and the difference in sample means is calculated and recorded for every possible way of dividing the pooled values into two groups of size <math>n_{A}</math> and <math>n_{B}</math> (i.e., for every permutation of the group labels A and B).  The set of these calculated differences is the exact distribution of possible differences (for this sample) under the null hypothesis that group labels are exchangeable (i.e., are randomly assigned).\n\nThe one-sided p-value of the test is calculated as the proportion of sampled permutations where the difference in means was greater than or equal to <math>T_\\text{obs}</math>. The two-sided p-value of the test is calculated as the proportion of sampled permutations where the [[absolute difference]] was greater than or equal to <math>|T_\\text{obs}|</math>.\n\nAlternatively, if the only purpose of the test is to reject or not reject the null hypothesis, one could sort the recorded differences, and then observe if <math>T_\\text{obs}</math> is contained within the middle <math>(1 - \\alpha) \\times 100</math>% of them, for some significance level <math>\\alpha</math>. If it is not, we reject the hypothesis of identical probability curves at the <math>\\alpha\\times100\\%</math> significance level.\n\n===Relation to parametric tests===\n\nPermutation tests are a subset of [[non-parametric statistics]]. Assuming that our experimental data come from data measured from two treatment groups, the method simply generates the distribution of mean differences under the assumption that the two groups are not distinct in terms of the measured variable. From this, one then uses the observed statistic (<math>T_\\text{obs}</math> above) to see to what extent this statistic is special, i.e., the likelihood of observing the magnitude of such a value (or larger) if the treatment labels had simply been randomized after treatment.\n\nIn contrast to permutation tests, the distributions underlying many popular [[classical statistics|\"classical\" statistical]] tests, such as the [[t-test|''t''-test]], [[F-test|''F''-test]], [[z-test|''z''-test]], and [[chi-squared test|''χ''<sup>2</sup> test]], are obtained from theoretical probability distributions. [[Fisher's exact test]] is an example of a commonly used permutation test for evaluating the association between two dichotomous variables. When sample sizes are very large, the Pearson's chi-square test will give accurate results. For small samples, the chi-square reference distribution cannot be assumed to give a correct description of the probability distribution of the test statistic, and in this situation the use of Fisher's exact test becomes more appropriate.\n\nPermutation tests exist in many situations where parametric tests do not (e.g., when deriving an optimal test when losses are proportional to the size of an error rather than its square).  All simple and many relatively complex parametric tests have a corresponding permutation test version that is defined by using the same test statistic as the parametric test, but obtains the p-value from the sample-specific permutation distribution of that statistic, rather than from the theoretical distribution derived from the parametric assumption.  For example, it is possible in this manner to construct a permutation [[t-test|''t''-test]], a permutation [[chi-squared test|''χ''<sup>2</sup> test]] of association, a permutation version of Aly's test for comparing variances and so on.\n\nThe major drawbacks to permutation tests are that they\n* Can be computationally intensive and may require \"custom\" code for difficult-to-calculate statistics. This must be rewritten for every case.\n* Are primarily used to provide a p-value. The inversion of the test to get confidence regions/intervals requires even more computation.\n\n===Advantages===\nPermutation tests exist for any test statistic, regardless of whether or not its distribution is known. Thus one is always free to choose the statistic which best discriminates between hypothesis and alternative and which minimizes losses.\n\nPermutation tests can be used for analyzing unbalanced designs<ref>{{cite journal |date=Fall 2011 |title=Invited Articles |url=http://tbf.coe.wayne.edu/jmasm/vol1_no2.pdf |journal=[[Journal of Modern Applied Statistical Methods]] |volume=1 |issue=2 |pages=202–522  |archiveurl=https://web.archive.org/web/20030505044125/http://tbf.coe.wayne.edu/jmasm/vol1_no2.pdf |archivedate=May 5, 2003}}</ref> and for combining dependent tests on mixtures of categorical, ordinal, and metric data (Pesarin, 2001). They can also be used to analyze qualitative data that has been quantitized (i.e., turned into numbers). Permutation tests may be ideal for analyzing quantitized data that do not satisfy statistical assumptions underlying traditional parametric tests (e.g., t-tests, ANOVA) (Collingridge, 2013).\n\nBefore the 1980s, the burden of creating the reference distribution was overwhelming except for data sets with small sample sizes.\n\nSince the 1980s, the confluence of relatively inexpensive fast computers and the development of new sophisticated path algorithms applicable in special situations made the application of permutation test methods practical for a wide range of problems. It also initiated the addition of exact-test options in the main statistical software packages and the appearance of specialized software for performing a wide range of uni- and multi-variable exact tests and computing test-based \"exact\" confidence intervals.\n\n===Limitations===\nAn important assumption behind a permutation test is that the observations are exchangeable under the null hypothesis.  An important consequence of this assumption is that tests of difference in location (like a permutation t-test) require equal variance. In this respect, the permutation t-test shares the same weakness as the classical Student's t-test (the [[Behrens–Fisher problem]]). A third alternative in this situation is to use a bootstrap-based test. Good (2005) explains the difference between permutation tests and bootstrap tests the following way: \"Permutations test hypotheses concerning distributions; bootstraps test hypotheses concerning parameters. As a result, the bootstrap entails less-stringent assumptions.\"  Bootstrap tests are not exact.\n\n===Monte Carlo testing===\nAn asymptotically equivalent permutation test can be created when there are too many possible orderings of the data to allow complete enumeration in a convenient manner. This is done by generating the reference distribution by [[Monte Carlo sampling]], which takes a small (relative to the total number of permutations) random sample of the possible replicates.\nThe realization that this could be applied to any permutation test on any dataset was an important breakthrough in the area of applied statistics.  The earliest known reference to this approach is [[Meyer Dwass|Dwass]] (1957).<ref>{{cite journal |first=Meyer |last=Dwass |title=Modified Randomization Tests for Nonparametric Hypotheses |journal=[[Annals of Mathematical Statistics]] |volume=28 |issue=1 |pages=181–187 |year=1957 |jstor=2237031 |doi=10.1214/aoms/1177707045}}</ref>\nThis type of permutation test is known under various names: ''approximate permutation test'', ''Monte Carlo permutation tests'' or ''random permutation tests''.<ref>{{Cite journal  | author = [[Thomas E. Nichols]], [[Andrew P. Holmes]]  | url = http://www.fil.ion.ucl.ac.uk/spm/doc/papers/NicholsHolmes.pdf  | title = Nonparametric Permutation Tests For Functional Neuroimaging: A Primer with Examples  |journal = [[Human Brain Mapping (journal)|Human Brain Mapping]]  | volume = 15  | pages = 1–25  | year = 2001  | doi = 10.1002/hbm.1058  | pmid = 11747097  | issue = 1 }}</ref>\n\nAfter <math>N </math> random permutations, it is possible to obtain a confidence interval for the p-value based on the Binomial distribution. For example, if after <math> N = 10000</math> random permutations the p-value is estimated to be <math>\\widehat{p}=0.05 </math>, then a 99% confidence interval for the true <math style=\"position:relative;top:.1em\">\\scriptstyle\\ p </math> (the one that would result from trying all possible permutations) is <math>[0.045, 0.055] </math>.\n\nOn the other hand, the purpose of estimating the p-value is most often to decide whether <math> p \\leq \\alpha </math>, where <math style=\"position:relative; top:-.1em\">\\scriptstyle\\ \\alpha </math> is the threshold at which the null hypothesis will be rejected (typically <math> \\alpha=0.05</math>). In the example above, the confidence interval only tells us that there is roughly a 50% chance that the p-value is smaller than 0.05, i.e. it is completely unclear whether the null hypothesis should be rejected at a level <math>\\alpha=0.05 </math>.\n\nIf it is only important to know whether <math>p \\leq \\alpha </math> for a given <math>\\alpha</math>, it is logical to continue simulating until the statement <math>p \\leq \\alpha </math> can be established to be true or false with a very low probability of error. Given a bound <math>\\epsilon </math> on the admissible probability of error (the probability of finding that <math>\\widehat{p} > \\alpha </math> when in fact <math>p \\leq \\alpha </math> or vice versa), the question of how many permutations to generate can be seen as the question of when to stop generating permutations, based on the outcomes of the simulations so far, in order to guarantee that the conclusion (which is either <math>p \\leq \\alpha </math> or <math>p > \\alpha </math>) is correct with probability at least as large as <math>1-\\epsilon </math>. (<math>\\epsilon </math> will typically be chosen to be extremely small, e.g. 1/1000.) Stopping rules to achieve this have been developed<ref>{{cite journal|last=Gandy|first=Axel|title=Sequential implementation of Monte Carlo tests with uniformly bounded resampling risk|journal=[[Journal of the American Statistical Association]]|year=2009|volume=104|issue=488|pages=1504–1511|doi=10.1198/jasa.2009.tm08368|arxiv=math/0612488}}</ref>  which can be incorporated with minimal additional computational cost. In fact, depending on the true underlying p-value it will often be found that the number of simulations required is remarkably small (e.g. as low as 5 and often not larger than 100) before a decision can be reached with virtual certainty.\n\n==See also==\n* [[Bootstrap aggregating]] (bagging)\n* [[Genetic algorithm]]s\n* [[Monte Carlo methods]]\n* [[Nonparametric statistics]]\n* [[Particle filter]]\n* [[Random permutation]]\n* [[Surrogate data testing]]\n\n== References ==\n{{reflist}}\n* {{citation|last=Good|first=Phillip|authorlink=Phillip Good|year=2005|title=Permutation, Parametric and Bootstrap Tests of Hypotheses|edition=3rd|publisher=Springer}}\n\n== Bibliography ==\n{{further cleanup|date=June 2016}}\n\n===Introductory statistics===\n* Good, P. (2005) ''Introduction to Statistics Through Resampling Methods and R/S-PLUS''.  Wiley. {{ISBN|0-471-71575-1}}\n* Good, P. (2005) ''Introduction to Statistics Through Resampling Methods and Microsoft Office Excel''. Wiley. {{ISBN|0-471-73191-9}}\n* Hesterberg, T. C., D. S. Moore, S. Monaghan, A. Clipson, and R. Epstein (2005). ''Bootstrap Methods and Permutation Tests''.{{full citation needed|date=November 2012}}\n* Wolter, K.M. (2007). ''Introduction to Variance Estimation''. Second Edition. Springer, Inc.\n\n===Bootstrap===\n* {{cite journal | last1 = Efron | first1 = Bradley | authorlink = Bradley Efron | year = 1979 | title = Bootstrap methods: Another look at the jackknife | url = http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&id=pdf_1&handle=euclid.aos/1176344552 | journal = [[The Annals of Statistics]] | volume = 7 | issue = | pages = 1–26 | doi=10.1214/aos/1176344552}}\n* {{cite journal | last1 = Efron | first1 = Bradley | authorlink = Bradley Efron | year = 1981 | title = Nonparametric estimates of standard error: The jackknife, the bootstrap and other methods | url = | journal = [[Biometrika]] | volume = 68 | issue = 3| pages = 589–599 | doi=10.2307/2335441| jstor = 2335441 }}\n* [[Bradley Efron|Efron, Bradley]] (1982). ''The jackknife, the bootstrap, and other resampling plans'', In ''Society of Industrial and Applied Mathematics CBMS-NSF Monographs'', 38.\n* [[Persi Diaconis|Diaconis, P.]]; [[Bradley Efron|Efron, Bradley]] (1983), \"Computer-intensive methods in statistics,\" ''[[Scientific American]]'', May, 116-130.\n* [[Bradley Efron|Efron, Bradley]]; Tibshirani, Robert J. (1993). ''An introduction to the bootstrap'', New York: [[Chapman & Hall]], [https://archive.is/20120712124533/http://lib.stat.cmu.edu/S/bootstrap.funs software].\n* Davison, A. C. and Hinkley, D. V. (1997): Bootstrap Methods and their Application, [http://statwww.epfl.ch/davison/BMA/library.html software].\n* Mooney, C Z & Duval, R D (1993). Bootstrapping. A Nonparametric Approach to Statistical Inference.  Sage University Paper series on Quantitative Applications in the Social Sciences, 07-095. Newbury Park, CA: [[SAGE Publications|Sage]].\n* Simon, J. L. (1997): [https://web.archive.org/web/20051223034539/http://www.resample.com/content/text/index.shtml Resampling: The New Statistics].\n\n===Jackknife===\n* {{cite journal | last1 = Berger | first1 = Y.G. | year = 2007 | title = A jackknife variance estimator for unistage stratified samples with unequal probabilities | url = | journal = [[Biometrika]] | volume = 94 | issue = 4| pages = 953–964 | doi=10.1093/biomet/asm072}}\n* {{cite journal | last1 = Berger | first1 = Y.G. | last2 = Rao | first2 = J.N.K. | year = 2006 | title = Adjusted jackknife for imputation under unequal probability sampling without replacement | url = | journal = [[Journal of the Royal Statistical Society, Series B]] | volume = 68 | issue = 3| pages = 531–547 | doi=10.1111/j.1467-9868.2006.00555.x}}\n* {{cite journal | last1 = Berger | first1 = Y.G. | last2 = Skinner | first2 = C.J. | year = 2005 | title = A jackknife variance estimator for unequal probability sampling | url = | journal = [[Journal of the Royal Statistical Society, Series B]] | volume = 67 | issue = 1| pages = 79–89 | doi=10.1111/j.1467-9868.2005.00489.x}}\n* {{cite journal | last1 = Jiang | first1 = J. | last2 = Lahiri | first2 = P. | last3 = Wan | first3 = S-M. | year = 2002 | title = A unified jackknife theory for empirical best prediction with M-estimation | url = | journal = [[The Annals of Statistics]] | volume = 30 | issue = 6| pages = 1782–810 | doi=10.1214/aos/1043351257}}\n* {{cite journal | last1 = Jones | first1 = H.L. | year = 1974 | title = Jackknife estimation of functions of stratum means | url = | journal = [[Biometrika]] | volume = 61 | issue = 2| pages = 343–348 | doi=10.2307/2334363| jstor = 2334363 }}\n* {{cite journal | last1 = Kish | first1 = L. | last2 = Frankel | first2 = M.R. | year = 1974 | title = Inference from complex samples | url = | journal = [[Journal of the Royal Statistical Society, Series B]] | volume = 36 | issue = 1| pages = 1–37 }}\n* {{cite journal | last1 = Krewski | first1 = D. | last2 = Rao | first2 = J.N.K. | year = 1981 | title = Inference from stratified samples: properties of the linearization, jackknife and balanced repeated replication methods | url = | journal = [[The Annals of Statistics]] | volume = 9 | issue = 5| pages = 1010–1019 | doi=10.1214/aos/1176345580}}\n* {{cite journal | last1 = Quenouille | first1 = M.H. | year = 1956 | title = Notes on bias in estimation | url = | journal = [[Biometrika]] | volume = 43 | issue = 3–4| pages = 353–360 | doi=10.1093/biomet/43.3-4.353}}\n* {{cite journal | last1 = Rao | first1 = J.N.K. | last2 = Shao | first2 = J. | year = 1992 | title = Jackknife variance estimation with survey data under hot deck imputation | url = | journal = [[Biometrika]] | volume = 79 | issue = 4| pages = 811–822 | doi=10.1093/biomet/79.4.811}}\n* {{cite journal | last1 = Rao | first1 = J.N.K. | last2 = Wu | first2 = C.F.J. | last3 = Yue | first3 = K. | year = 1992 | title = Some recent work on resampling methods for complex surveys | url = | journal = [[Survey Methodology]] | volume = 18 | issue = 2| pages = 209–217 }}\n* Shao, J. and Tu, D. (1995). The Jackknife and Bootstrap. Springer-Verlag, Inc.\n* {{cite journal | last1 = Tukey | first1 = J.W. | authorlink = John Wilder Tukey | year = 1958 | title = Bias and confidence in not-quite large samples (abstract) | url = | journal = [[The Annals of Mathematical Statistics]] | volume = 29 | issue = 2| page = 614 }}\n* {{cite journal | last1 = Wu | first1 = C.F.J. | authorlink = C.F. Jeff Wu | year = 1986 | title = Jackknife, Bootstrap and other resampling methods in regression analysis | url = | journal = [[The Annals of Statistics]] | volume = 14 | issue = 4| pages = 1261–1295 | doi=10.1214/aos/1176350142}}\n\n===Subsampling===\n* {{cite journal | last1 = Delgado | first1 = M. | last2 = Rodriguez-Poo | first2 = J. | last3 = Wolf | first3 = M. | year = 2001 | title = Subsampling inference in cube root asymptotics with an application to Manski's maximum score estimator | url = | journal = [[Economics Letters]] | volume = 73 | issue = 2| pages = 241–250 | doi=10.1016/s0165-1765(01)00494-3}}\n* {{cite journal | last1 = Gonzalo | first1 = J. | last2 = Wolf | first2 = M. | year = 2005 | title = Subsampling inference in threshold autoregressive models | url = | journal = [[Journal of Econometrics]] | volume = 127 | issue = 2| pages = 201–224 | doi=10.1016/j.jeconom.2004.08.004}}\n* {{cite journal | last1 = Politis | first1 = D.N. | last2 = Romano | first2 = J.P. | year = 1994 | title = Large-sample confidence regions based on subsamples under minimal assumptions | url = | journal = [[The Annals of Statistics]] | volume = 22 | issue = 4| pages = 2031–2050 | doi=10.1214/aos/1176325770}}\n* {{cite journal | last1 = Politis | first1 = D.N. | last2 = Romano | first2 = J.P. | last3 = Wolf | first3 = M. | year = 1997 | title = Subsampling for heteroskedastic time series | url = | journal = [[Journal of Econometrics]] | volume = 81 | issue = 2| pages = 281–317 | doi=10.1016/s0304-4076(97)86569-4}}\n* Politis, D.N., Romano, J.P., and Wolf, M. (1999). ''Subsampling''. Springer, New York.\n* {{cite journal | last1 = Romano | first1 = J.P. | last2 = Wolf | first2 = M. | year = 2001 | title = Subsampling intervals in autoregressive models with linear time trend | url = | journal = [[Econometrica]] | volume = 69 | issue = 5| pages = 1283–1314 | doi=10.1111/1468-0262.00242}}\n\n===Monte Carlo methods===\n* George S. Fishman (1995). ''Monte Carlo: Concepts, Algorithms, and Applications'', Springer, New York. {{ISBN|0-387-94527-X}}.\n* James E. Gentle (2009). ''Computational Statistics'', Springer, New York. Part III: Methods of Computational Statistics. {{ISBN|978-0-387-98143-7}}.\n* Pierre Del Moral (2004). Feynman-Kac formulae. Genealogical and Interacting particle systems with applications, Springer, Series Probability and Applications. {{ISBN|978-0-387-20268-6}}\n* Pierre Del Moral (2013). Del Moral, Pierre (2013). ''Mean field simulation for Monte Carlo integration''. Chapman & Hall/CRC Press, Monographs on Statistics and Applied Probability. {{ISBN|9781466504059}}\n* Dirk P. Kroese, Thomas Taimre and Zdravko I. Botev. ''Handbook of Monte Carlo Methods'', John Wiley & Sons, New York. {{ISBN|978-0-470-17793-8}}.\n* Christian P. Robert and George Casella (2004). ''Monte Carlo Statistical Methods'', Second ed., Springer, New York. {{ISBN|0-387-21239-6}}.\n* [[Shlomo Sawilowsky]] and Gail Fahoome (2003). ''Statistics via Monte Carlo Simulation with Fortran.'' Rochester Hills, MI: JMASM. {{ISBN|0-9740236-0-4}}.\n\n===Permutation tests===\nOriginal references:\n* [[R. A. Fisher|Fisher, R.A.]] (1935) ''[[The Design of Experiments]]'', New York: [[Hafner Publishing|Hafner]]\n* [[E. J. G. Pitman|Pitman, E. J. G.]] (1937) \"Significance tests which may be applied to samples from any population\", ''Royal Statistical Society Supplement'', 4: 119-130 and 225-32 (parts I and II). {{jstor|2984124}} {{jstor|2983647}}\n* {{cite journal | last1 = Pitman | first1 = E. J. G. | authorlink = E. J. G. Pitman | year = 1938 | title = Significance tests which may be applied to samples from any population. Part III. The analysis of variance test | url = | journal = [[Biometrika]] | volume = 29 | issue = 3–4| pages = 322–335 | doi = 10.1093/biomet/29.3-4.322 }}\nModern references:\n* {{cite journal | last1 = Collingridge | first1 = D.S. | year = 2013 | title = A Primer on Quantitized Data Analysis and Permutation Testing | url = | journal = [[Journal of Mixed Methods Research]] | volume = 7 | issue = 1| pages = 79–95 | doi=10.1177/1558689812454457}}\n* Edgington. E.S. (1995) ''Randomization tests'', 3rd ed. New York: [[Marcel-Dekker]]\n* Good, Phillip I. (2005) ''Permutation, Parametric and Bootstrap Tests of Hypotheses'', 3rd ed., [[Springer Science+Business Media|Springer]] {{ISBN|0-387-98898-X}}\n* {{cite journal | last1 = Good | first1 = P | year = 2002 | title = Extensions of the concept of exchangeability and their applications | url = | journal = [[Journal of Modern Applied Statistical Methods]] | volume = 1 | issue = | pages = 243–247 | doi=10.22237/jmasm/1036110240}}\n* Lunneborg, Cliff. (1999) ''Data Analysis by Resampling'', Duxbury Press. {{ISBN|0-534-22110-6}}.\n* Pesarin, F. (2001). ''Multivariate Permutation Tests : With Applications in Biostatistics'', [[John Wiley & Sons]]. {{ISBN|978-0471496700}}\n* {{cite journal | last1 = Welch | first1 = W. J. | year = 1990 | title = Construction of permutation tests | url = | journal = [[Journal of the American Statistical Association]] | volume = 85 | issue = 411| pages = 693–698 | doi=10.1080/01621459.1990.10474929}}\nComputational methods:\n* {{cite journal | last1 = Mehta | first1 = C. R. | last2 = Patel | first2 = N. R. | year = 1983 | title = A network algorithm for performing Fisher's exact test in r x c contingency tables | url = | journal = [[Journal of the American Statistical Association]] | volume = 78 | issue = 382| pages = 427–434 | doi=10.1080/01621459.1983.10477989}}\n* {{cite journal | last1 = Mehta | first1 = C. R. | last2 = Patel | first2 = N. R. | last3 = Senchaudhuri | first3 = P. | year = 1988 | title = Importance sampling for estimating exact probabilities in permutational inference | url = | journal = [[Journal of the American Statistical Association]] | volume = 83 | issue = 404| pages = 999–1005 | doi=10.1080/01621459.1988.10478691}}\n* {{cite journal | last1 = Gill | first1 = P. M. W. | year = 2007 | title = Efficient calculation of p-values in linear-statistic permutation significance tests | url = | journal = [[Journal of Statistical Computation and Simulation]] | volume = 77 | issue = 1| pages = 55–61 | doi = 10.1080/10629360500108053 }}\n\n===Resampling methods===\n* Good, P. (2006) ''Resampling Methods''.  3rd Ed. Birkhauser.\n* Wolter, K.M. (2007). ''Introduction to Variance Estimation''. 2nd Edition. Springer, Inc.\n* Pierre Del Moral (2004). Feynman-Kac formulae. Genealogical and Interacting particle systems with applications, Springer, Series Probability and Applications. {{ISBN|978-0-387-20268-6}}\n* Pierre Del Moral (2013). Del Moral, Pierre (2013). ''Mean field simulation for Monte Carlo integration''. Chapman & Hall/CRC Press, Monographs on Statistics and Applied Probability. {{ISBN|9781466504059}}\n\n==External links==\n\n===Current research on permutation tests===\n* Good, P.I. (2012) Practitioner's Guide to Resampling Methods. [http://zanybooks.com/statist.htm]\n* Good, P.I. (2005) Permutation, Parametric, and Bootstrap Tests of Hypotheses\n* [http://people.revoledu.com/kardi/tutorial/Bootstrap/index.html Bootstrap Sampling tutorial]\n* Hesterberg, T. C., D. S. Moore, S. Monaghan, A. Clipson, and R. Epstein (2005):  [https://web.archive.org/web/20060215221403/http://bcs.whfreeman.com/ips5e/content/cat_080/pdf/moore14.pdf Bootstrap Methods and Permutation Tests], [https://web.archive.org/web/20060110182635/http://www.insightful.com/Hesterberg/bootstrap/ software].\n* Moore, D. S., G. McCabe, W. Duckworth, and S. Sclove (2003): [http://bcs.whfreeman.com/pbs/cat_140/chap18.pdf Bootstrap Methods and Permutation Tests]\n* Simon, J. L. (1997): [https://web.archive.org/web/20051223034539/http://www.resample.com/content/text/index.shtml Resampling: The New Statistics].\n* Yu, Chong Ho (2003): [http://PAREonline.net/getvn.asp?v=8&n=19 Resampling methods: concepts, applications, and justification. Practical Assessment, Research & Evaluation, 8(19)]. ''(statistical bootstrapping)''\n* [http://www.ericdigests.org/1993/marriage.htm Resampling: A Marriage of Computers and Statistics (ERIC Digests)]\n\n===Software===\n*  [http://cran.at.r-project.org/web/packages/boot/index.html Angelo Canty and Brian Ripley (2010). '''boot''': Bootstrap R (S-Plus) Functions. R package version 1.2-43.] Functions and datasets for bootstrapping from the book ''Bootstrap Methods and Their Applications'' by A. C. Davison and D. V. Hinkley (1997, CUP).\n* [http://www.statistics101.net Statistics101: Resampling, Bootstrap, Monte Carlo Simulation program]\n* [https://cran.r-project.org/web/packages/samplingVarEst R package `samplingVarEst': Sampling Variance Estimation. Implements functions for estimating the sampling variance of some point estimators.]\n* [http://www.mansci.uwaterloo.ca/~msmucker/software.html Paired randomization/permutation test for evaluation of TREC results]\n* [https://github.com/searchivarius/PermTest Randomization/permutation tests to evaluate outcomes in information retrieval experiments (with and without adjustments for multiple comparisons).]\n* [http://www.bioconductor.org/packages/release/bioc/html/multtest.html  Bioconductor resampling-based multiple hypothesis testing with Applications to Genomics.]\n* [https://cran.r-project.org/web/packages/permtest/index.html permtest: an R package to compare the variability within and distance between two groups within a set of microarray data.]\n* [http://rosetta.ahmedmoustafa.io/bootstrap/ Bootstrap Resampling: interactive demonstration of hypothesis testing with bootstrap resampling in R.]\n* [http://rosetta.ahmedmoustafa.io/permutation/ Permutation Test: interactive demonstration of hypothesis testing with permutation test in R.]\n\n{{statistics|inference|collapsed}}\n\n{{DEFAULTSORT:Resampling (Statistics)}}\n[[Category:Monte Carlo methods]]\n[[Category:Statistical inference]]\n[[Category:Resampling (statistics)| ]]\n[[Category:Nonparametric statistics]]"
    },
    {
      "title": "Reverse Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Reverse_Monte_Carlo",
      "text": "{{Use dmy dates|date=September 2015}}\nThe '''Reverse Monte Carlo''' (RMC) modelling method is a variation of the standard [[Metropolis-Hastings algorithm]] to solve an [[inverse problem]] whereby a model is adjusted until its parameters have the greatest consistency with experimental data. [[Inverse problem]]s are found in many branches of [[science]] and [[mathematics]], but this approach is probably best known for its applications in [[condensed matter physics]] and [[solid state chemistry]].\n\n==Applications in condensed matter sciences==\n\n===Basic method===\nThis method is often used in [[condensed matter physics|condensed matter sciences]] to produce atom-based structural models that are consistent with [[experimental data]] and subject to a set of constraints.\n\nAn initial configuration is constructed by placing {{math|N}} atoms in a [[periodic boundary conditions|periodic boundary]] cell, and one or more [[physical quantity|measurable quantities]] are calculated based on the current configuration. Commonly used data include the [[pair distribution function]] and its [[Fourier transform]], the latter of which is derived directly from neutron or x-ray scattering data (see [[small-angle neutron scattering]], [[wide-angle X-ray scattering]], [[small-angle X-ray scattering]], and [[X-ray diffraction]]). Other data that are used included [[Bragg diffraction]] data for crystalline materials, and [[Extended X-ray absorption fine structure|EXAFS]] data. The comparison with experiment is quantified using a function of the form\n\n{{math|<var>&chi;</var><sup>2</sup> {{=}} &sum; (<var>y</var><sub>obs</sub> &minus; <var>y</var><sub>calc</sub>)<sup>2</sup> / <var>&sigma;</var><sup>2</sup> }}\n\nwhere {{math|<var>y</var><sub>obs</sub>}} and {{math|<var>y</var><sub>calc</sub>}} are the observed (measured) and calculated quantities respectively, and {{math|<var>&sigma;</var>}} is a measure of the accuracy of the measurement. The sum is over all independent measurements, which will include the sum over all points in a function such as the pair distribution function.\n\nAn iterative procedure is run where one randomly chosen atom is moved a [[random]] amount, followed by a new calculation of the measurable quantities. Such a process will cause {{math|<var>&chi;</var><sup>2</sup>}} to either increase or decrease in value by an amount {{math|&Delta;<var>&chi;</var><sup>2</sup>}}. The move is accepted with the probability {{math|min(1, exp(&minus;&Delta;<var>&chi;</var><sup>2</sup>/2))}} according to the normal [[Metropolis-Hastings algorithm]], ensuring that moves that give better agreement with experimental data are accepted, and moves that worsen agreement with experimental data can be accepted to a greater or lesser extent corresponding to how much the agreement has worsened. Moreover, the move may also be rejected if it breaks certain constraints, even if the agreement with data is improved. An example would be to reject a move which brings two atoms  closer than a preset limit, to prevent overlap or collision between the two atoms.\n\nFollowing the acceptance/rejection test, the procedure is repeated. As the number of accepted atom moves increases, the calculated quantities will become closer to the experimental values until they reach an equilibrium state. From then onward the RMC algorithm will simply generate a small oscillation in the value of {{math|<var>&chi;</var><sup>2</sup>}}. The resulting atomic configuration should be a structure that is consistent with the experimental data within its errors.\n\n===Applications===\nThe RMC method for condensed matter problems was initially developed by McGreevy and Pusztai<ref>RL McGreevy and L Pusztai, Reverse Monte Carlo Simulation: A New Technique for the Determination of Disordered Structures, Molecular Simulation 1, 359&ndash;367, 1988 [https://dx.doi.org/10.1080/08927028808080958]</ref> in 1988, with application to [[liquid]] [[argon]] (Note that there were earlier independent applications of this approach, for example those of Kaplow et al.<ref>R Kaplow, TA Rowe and BL Averebach. Atomic arrangement in vitreous selenium. Physical Review 168, 1068&ndash;1079, 1968 [http://link.aps.org/doi/10.1103/PhysRev.168.1068]</ref> and Gerold and Kern;<ref>V Gerold and J Kern, The determination of atomic interaction energy in solid solutions from short range order coefficients &mdash; an inverse Monte Carlo method. Acta Metallica 35, 393&ndash;399, 1987 [https://dx.doi.org/10.1016/0001-6160(87)90246-X]</ref> it is, however, the McGreevy and Pusztai implementation that is best known). For several years the primary application was for liquids and amorphous materials, particularly because this provides the only means to obtain structural models from data, whereas [[crystallography]] has analysis methods for both single crystal and [[powder diffraction]] data. More recently, it has become clear that RMC can provide important information for disordered crystalline materials also.<ref>DA Keen, MG Tucker and MT Dove. Reverse Monte Carlo modelling of crystalline disorder. Journal of Physics: Condensed Matter 17, S15&ndash;S22, 2005 [https://dx.doi.org/10.1088/0953-8984/17/5/002]</ref>\n\n==Issues with the RMC method==\nThe RMC method suffers from a number of potential problems. The most notable problem is that often more than one qualitatively different model will give similar agreement with experimental data. For example, in the case of amorphous silicon, the integral of the first peak in the [[pair distribution function]] may imply an average atomic coordination number of 4. This might reflect the fact that all atoms have coordination number of 4, but similarly having half the atoms with coordination number of 3 and half with 5 will also be consistent with this data. Unless a constraint on the coordination number is employed, the RMC method will have no means of generating a unique coordination number and most likely a spread of coordination numbers will result. Using amorphous silicon as an example, Biswas, Atta-Fynn and Drabold were the first to elucidate the importance of including constraints in RMC modeling.<ref>Parthapratim Biswas, Raymond Atta-Fynn, and D. A. Drabold, Physical Review B 69, 195207 (2004)</ref>  Since the RMC method follows the normal rules of statistical mechanics, its final solution will be the one with the highest degree of disorder ([[entropy]]) possible. A second problem comes from the fact that without constraints the RMC method will typically have more variables than observables. One result from this will be that the final atomic configuration may have artifacts that arise from the method attempting to fit noise in the data.\n\nOne should remark, however, that most applications of the RMC approach today take account of these problems by appropriate use of implicit or explicit constraints.\n\n==Implementations of the RMC method==\n\nThere are four publicly available implementations of the RMC method.\n\n===fullrmc===\nFUndamental Library Language for Reverse Monte Carlo or fullrmc <ref>Bachir Aoun; Fullrmc, a Rigid Body Reverse Monte Carlo Modeling Package Enabled with Machine Learning and Artificial Intelligence; J. Comput. Chem. 2016, 37, 1102–1111. DOI: 10.1002/jcc.24304</ref><ref>[https://bachiraoun.github.io/fullrmc/ fullrmc online documentation]</ref><ref>[https://github.com/bachiraoun/fullrmc fullrmc github account]</ref><ref>[https://pypi.python.org/pypi/fullrmc fullrmc pypi account]</ref><ref>[https://groups.google.com/forum/#!forum/fullrmc fullrmc public Q&A forum]</ref> is a multicore RMC modeling package. fullrmc is a fully object-oriented [[Python (programming language)|python]] interfaced package where every definition can be overloaded allowing easy development, implementation and maintenance of the code. fullrmc's computation blocks and modules are optimized written in [[cython]]/[[C (programming language)|C]]. fullrmc is not a standard RMC package but it is rather unique in its approach to solving an atomic or molecular structure. fullrmc supports atomic and molecular systems, all types (not limited to cubic) of [[periodic boundary conditions]] systems as well as the so-called infinite boundary conditions to model nanoparticles or isolated systems. fullrmc's Engine is defined and used to launch a RMC calculation. By definition, Engine reads only  [[Protein Data Bank (file format)]] atomic configuration files and handles other definitions and attributes. In fullrmc atoms can be grouped into [[Rigid body|rigid bodies]] or semi-rigid bodies called groups so the system can evolve atomically, clusterly, molecularly or any combination of those. Every group can be assigned a different and customizable move generator (translation, rotation, a combination of moves generators, etc.). Groups selection by the fitting engine can also be customizable. Also fullrmc uses [[Artificial intelligence]] and [[Reinforcement learning]] algorithms to improve the ratio of accepted moves.\n\n===RMCProfile===\nRMCProfile<ref>MG Tucker, DA Keen, MT Dove, AL Goodwin and Q Hui. RMCProfile: reverse Monte Carlo for polycrystalline materials. Journal of Physics: Condensed Matter 19, 335218, 2007 [https://dx.doi.org/10.1088/0953-8984/19/33/335218]</ref><ref>[http://www.rmcprofile.org RMCProfile home page, visited 22 June 2010]</ref> is a significantly developed version of the original RMC code written by McGreevy and Puszta. It is written in [[Fortran 95 language features|Fortran 95]] with some [[Fortran|Fortran 2003]] features. It has maintained the ability to model liquids and amorphous materials using the [[pair distribution function]], [[total scattering]] and [[Extended X-ray absorption fine structure|EXAFS]] data, but also includes the capability of modelling crystalline materials by explicitly using the information contained within the [[Bragg diffraction]] data. RMCProfile gives users a range of constraints, including the inclusion of molecular potentials and distance windows, which exploit possibilities afforded by the lack of significant diffusion in crystalline materials. RMCProfile allows simulation of magnetic materials, using the magnetic component of total scattering data, and also allows simulation of materials where atoms are allowed to swap positions (as found in many [[solid solution]]s).\n\n===RMC++===\nRMC++<ref>G Evrard and L Pusztai. Reverse Monte Carlo modelling of the structure of disordered materials with RMC++: a new implementation of the algorithm in C++. Journal of Physics: Condensed Matter 17, S1&ndash;S13, 2005 [https://dx.doi.org/10.1088/0953-8984/17/5/001]</ref><ref>[http://www.szfki.hu/~nphys/rmc++/opening.html RMC++ homepage, visited 22 June 2010]</ref> a rewritten, C++ version of the original RMC code developed by McGreevy and Pusztain. RMC++ is designed specifically for the study of liquids and amorphous materials, using [[pair distribution function]], [[total scattering]] and [[Extended X-ray absorption fine structure|EXAFS]] data.\n\n===HRMC===\nHybrid Reverse Monte Carlo(HRMC)<ref>G. Opletal, T. C. Petersen, S. P. Russo, HRMC_2.1: Hybrid Reverse Monte Carlo with silicon, germanium and silicon carbide potentials, Com. Phys. Comm., 185(6), 1854-1855 (2014).</ref><ref>[https://research.csiro.au/mmm/hrmc/ HRMC homepage]</ref> is a code capable of fitting both the pair correlation function and structure factor along with bond angle and coordination distributions.  Unique to this code is the implementation of a number of empirical [[interatomic potential]]s for carbon (EDIP), silicon (EDIP<ref>{{cite journal|last1=Justo|first1=J. F.|last2=Bazant|first2=M. K.|last3=Kaxiras|first3=E.|last4=Bulatov|first4=V. V.|last5=Yip|first5=S.|title=Interatomic potential for silicon defects and disordered phases|journal=Phys. Rev. B|date=1998|volume=58|issue=5|page=2539|doi=10.1103/PhysRevB.58.2539|arxiv = cond-mat/9712058 |bibcode = 1998PhRvB..58.2539J }}</ref> and Stillinger-Weber<ref>{{cite journal|last1=Stillinger|first1=F. H.|last2=Weber|first2=T. A.|title=COMPUTER-SIMULATION OF LOCAL ORDER IN CONDENSED PHASES OF SILICON|journal=Phys. Rev. B|date=1985|volume=31|issue=8|page=5262|doi=10.1103/PhysRevB.31.5262|bibcode = 1985PhRvB..31.5262S }}</ref> ) and germanium (Stillinger-Weber).  This allows the code to fit experimental data along with minimizing the total system energy.\n\n==References==\n<references/>\n\n[[Category:Monte Carlo methods]]\n[[Category:Inverse problems]]"
    },
    {
      "title": "Reversible-jump Markov chain Monte Carlo",
      "url": "https://en.wikipedia.org/wiki/Reversible-jump_Markov_chain_Monte_Carlo",
      "text": "{{short description|A simulation method in statistics}}\nIn computational statistics, '''reversible-jump Markov chain Monte Carlo''' is an extension to standard [[Markov chain Monte Carlo]] (MCMC) methodology that allows [[simulation]] of the [[posterior distribution]] on [[space]]s of varying [[dimension]]s.<ref>{{cite journal\n | last = Green |first= P.J. |authorlink=Peter Green (statistician)\n | year = 1995\n | title = Reversible Jump Markov Chain Monte Carlo Computation and Bayesian Model Determination\n | journal = [[Biometrika]]\n | volume = 82\n | issue = 4\n | pages = 711–732\n | doi = 10.1093/biomet/82.4.711\n |mr=1380810 | jstor = 2337340 \n|citeseerx= 10.1.1.407.8942 }}</ref>\nThus, the simulation is possible even if the number of [[parameter]]s in the [[Mathematical model|model]] is not known. \n\nLet \n\n:<math>n_m\\in N_m=\\{1,2,\\ldots,I\\} \\, </math>\n\nbe a model [[indicator variable|indicator]] and <math>M=\\bigcup_{n_m=1}^I \\R^{d_m}</math> the parameter space whose number of dimensions <math>d_m</math> depends on the model <math>n_m</math>. The model indication need not be [[Wikt:finite|finite]]. The stationary distribution is the joint posterior distribution of <math>(M,N_m)</math> that takes the values <math>(m,n_m)</math>. \n\nThe proposal <math>m'</math> can be constructed with a [[map (mathematics)|mapping]] <math>g_{1mm'}</math> of <math>m</math> and <math>u</math>, where <math>u</math> is drawn from a random component\n<math>U</math> with density <math>q</math> on <math>\\R^{d_{mm'}}</math>. The move to state <math>(m',n_m')</math> can thus be formulated as\n\n:<math>\n  (m',n_m')=(g_{1mm'}(m,u),n_m') \\, \n</math>\n\nThe function\n\n:<math>\n  g_{mm'}:=\\Bigg((m,u)\\mapsto \\bigg((m',u')=\\big(g_{1mm'}(m,u),g_{2mm'}(m,u)\\big)\\bigg)\\Bigg) \\, \n</math>\n\nmust be ''one to one'' and differentiable, and have a non-zero support:\n\n:<math> \\mathrm{supp}(g_{mm'})\\ne \\varnothing \\, </math>\n\nso that there exists an [[inverse function]] \n\n:<math>g^{-1}_{mm'}=g_{m'm} \\, </math>\n\nthat is differentiable. Therefore, the <math>(m,u)</math> and <math>(m',u')</math> must be of equal dimension, which is the case if the dimension criterion \n\n:<math>d_m+d_{mm'}=d_{m'}+d_{m'm} \\, </math>\n\nis met where <math>d_{mm'}</math> is the dimension of <math>u</math>. This is known as ''dimension matching''. \n\nIf <math>\\R^{d_m}\\subset \\R^{d_{m'}}</math> then the dimensional matching\ncondition can be reduced to \n\n:<math>d_m+d_{mm'}=d_{m'} \\, </math>\n\nwith\n\n:<math>(m,u)=g_{m'm}(m). \\, </math>\n\nThe acceptance probability will be given by\n\n:<math>\n  a(m,m')=\\min\\left(1,\n  \\frac{p_{m'm}p_{m'}f_{m'}(m')}{p_{mm'}q_{mm'}(m,u)p_{m}f_m(m)}\\left|\\det\\left(\\frac{\\partial g_{mm'}(m,u)}{\\partial (m,u)}\\right)\\right|\\right),\n</math>\n\nwhere <math>|\\cdot |</math> denotes the absolute value and <math>p_mf_m</math> is the joint posterior probability\n\n:<math>\n  p_mf_m=c^{-1}p(y|m,n_m)p(m|n_m)p(n_m), \\, \n</math>\n\nwhere <math>c</math> is the normalising constant.\n\n== Software packages == \nThere is an experimental RJ-MCMC tool available for the open source [[BUGs (statistics)|BUGs]] package.\n\n==References==\n<references/>\n\n[[Category:Computational statistics]]\n[[Category:Monte Carlo methods]]"
    },
    {
      "title": "Sampling in order",
      "url": "https://en.wikipedia.org/wiki/Sampling_in_order",
      "text": "In [[statistics]], some [[Monte Carlo method]]s require independent observations in a sample to be drawn from a one-dimensional distribution in [[sorting algorithm|sorted order]]. In other words, all ''n'' [[order statistic]]s are needed from the ''n'' observations in a sample. The naive method performs a sort and takes ''O''(''n''&nbsp;log&nbsp;''n'') time. There are also ''O''(''n'') algorithms which are better suited for large&nbsp;''n''. The special case of drawing ''n'' sorted observations from the [[uniform distribution (continuous)|uniform distribution]] on [0,1] is equivalent to drawing from the uniform distribution on an ''n''-dimensional [[simplex]]; this task is a part of [[sequential importance resampling]].\n\n==Further reading==\n*{{Citation |last=Bentley |first=Jon Louis | author1-link = Jon Bentley (computer scientist) |last2=Saxe |first2=James B. | author2-link = James B. Saxe |year=1979 |title=Generating sorted lists of random numbers |journal=Computer Science Department |id=Paper 2450 |url=http://repository.cmu.edu/compsci/2450 |accessdate=January 4, 2014}}\n*{{Citation |last=Gerontidis |first=I. |last2=Smith |first2=R. L. |year=1982 |title=Monte Carlo Generation of Order Statistics from General Distributions |journal=[[Journal of the Royal Statistical Society]]. Series C (Applied Statistics) |volume=31 |issue=3 |pages=238–243 |jstor=2347997 }}\n*{{Citation |last=Lurie |first=D. |last2=Hartley |first2=H. O. |year=1972 |title=Machine-Generation of Order Statistics for Monte Carlo Computations |journal=The American Statistician |volume=26 |issue=1 |pages=26–27 |doi=10.1080/00031305.1972.10477319}}\n*{{Citation |last=Ripley |first=Brian D. |year=1987 |title=Stochastic Simulation |isbn=0-471-81884-4 |pages=96–98 |publisher=Wiley}}\n\n[[Category:Monte Carlo methods]]\n\n\n{{statistics-stub}}"
    },
    {
      "title": "Swendsen–Wang algorithm",
      "url": "https://en.wikipedia.org/wiki/Swendsen%E2%80%93Wang_algorithm",
      "text": "The '''Swendsen&ndash;Wang algorithm''' is the first non-local or cluster [[algorithm]] for [[Monte Carlo simulation]] for large systems near [[Critical point (thermodynamics)|criticality]]. It has been introduced by [[Robert Swendsen]] and [[Jian-Sheng Wang]] in 1987 at [[Carnegie Mellon University|Carnegie Mellon]].\n\nThe original algorithm was designed for the [[Ising model|Ising]] and Potts models, and it was later generalized to other systems as well, such as the XY model by [[Wolff algorithm]] and particles of fluids. The key ingredient was the [[random cluster model]], a representation of the Ising or [[Potts model|Potts]] model through percolation models of connecting bonds, due to Fortuin and Kasteleyn. It has been generalized by Barbu and Zhu (2005) to arbitrary sampling probabilities by viewing it as a [[Metropolis–Hastings algorithm]] and computing the acceptance probability of the proposed Monte Carlo move.\n\n== Motivation ==\nThe problem of the critical slowing-down affecting local processes is of fundamental importance in the study of second-order [[phase transition]]s (like ferromagnetic transition in the [[Ising model]]), as increasing the size of the system in order to reduce finite-size effects has the disadvantage of requiring a far larger number of moves to reach thermal equilibrium. Indeed the correlation time <math>\\tau</math> usually increases as <math>L^z</math> with <math>z\\simeq 2</math> or greater; since, to be accurate, the simulation time must be <math>t\\gg\\tau</math>, this is a major limitation in the size of the systems that can be studied through local algorithms. SW algorithm was the first to produce unusually small values for the dynamical critical exponents: <math>z=0.35</math> for the 2D Ising model (<math>z=2.125</math> for standard simulations); <math>z=0.75</math> for the 3D Ising model, as opposed to <math>z=2.0</math> for standard simulations.\n\n== Description ==\n{{Main|Random cluster model}}\nThe algorithm is non-local in the sense that in a single sweep of moves a collective update of the spin variables of the system is done. The key idea is to take an additional number of 'bond' variables, as suggested by Fortuin and Kasteleyn, who mapped the Potts model onto a [[Percolation theory|percolation]] model via the [[random cluster model]].\n\nConsider a typical ferromagnetic Ising model with only nearest-neighbor interaction.\n\n* Starting from a given configuration of spins, we associate to each pair of nearest neighbours on sites <math>n,m</math> a random variable <math>b_{n,m}\\in \\lbrace 0,1\\rbrace</math> which is interpreted in the following way: if <math>b_{n,m}=0</math> there is no link between the sites <math>n</math> and <math>m</math>; if <math>b_{n,m}=1</math>, <math>\\sigma_n</math> and <math>\\sigma_m</math> are connected. These values are assigned according to the following (conditional) probability distribution:\n\n  <math>P\\left[b_{n,m}=0|\\sigma_n\\neq\\sigma_m\\right]=1</math>;\n  <math>P\\left[b_{n,m}=1|\\sigma_n\\neq\\sigma_m\\right]=0</math>;\n  <math>P\\left[b_{n,m}=0|\\sigma_n=\\sigma_m\\right]=e^{-2\\beta J_{nm}}</math>;\n  <math>P\\left[b_{n,m}=1|\\sigma_n=\\sigma_m\\right]=1-e^{-2\\beta J_{nm}}</math>;\nwhere <math>J_{nm}>0</math> is the ferromagnetic interaction intensity.\n\nThis probability distribution has been derived in the following way: the Hamiltonian of the Ising model is\n\n<math>H[\\sigma]=\\sum\\limits_{<i,j>}-J_{i,j}\\sigma_i\\sigma_j</math>, \n\nand the [[Partition function (statistical mechanics)|partition function]] is \n\n<math>Z=\\sum\\limits_{\\lbrace\\sigma\\rbrace}e^{-\\beta H[\\sigma]}</math>. \n\nConsider the interaction between a pair of selected sites <math>n</math> and <math>m</math> and eliminate it from the total Hamiltonian, defining\n<math>H_{nm}[\\sigma]=\\sum\\limits_{<i,j>\\neq<n,m>}-J_{i,j}\\sigma_i\\sigma_j.</math>\n\nDefine also the restricted sums:\n\n<math>Z_{n,m}^{same}=\\sum\\limits_{\\lbrace\\sigma\\rbrace}e^{-\\beta H_{nm}[\\sigma]}\\delta_{\\sigma_n,\\sigma_m}</math>;\n\n<math>Z_{n,m}^{diff}=\\sum\\limits_{\\lbrace\\sigma\\rbrace}e^{-\\beta H_{nm}[\\sigma]}\\left(1-\\delta_{\\sigma_n,\\sigma_m}\\right).</math>\n\n<math>Z=e^{\\beta J_{nm}}Z_{n,m}^{same}+e^{-\\beta J_{nm}}Z_{n,m}^{diff}.</math>\n\nIntroduce the quantity\n\n<math>Z_{nm}^{ind}=Z_{n,m}^{same}+Z_{n,m}^{diff}</math>; \n\nthe partition function can be rewritten as\n\n<math>Z=\\left(e^{\\beta J_{nm}}-e^{-\\beta J_{nm}}\\right)Z_{n,m}^{same}+e^{-\\beta J_{nm}}Z_{n,m}^{ind}.</math>\n\nSince the first term contains a restriction on the spin values whereas there is no restriction in the second term, the weighting factors (properly normalized) can be interpreted as probabilities of forming/not forming a link between the sites: <math>P_{<n,m>\\;link}=1-e^{-2\\beta J_{nm}}.</math>\nThe process can be easily adapted to antiferromagnetic spin systems, as it is sufficient to eliminate <math>Z_{n,m}^{same}</math> in favor of <math>Z_{n,m}^{diff}</math> (as suggested by the change of sign in the interaction constant).\n\n* After assigning the bond variables, we identify the same-spin clusters formed by connected sites and make an inversion of all the variables in the cluster with probability 1/2. At the following time step we have a new starting Ising configuration, which will produce a new clustering and a new collective spin-flip.\n\n== Correctness ==\nIt can be shown that this algorithm leads to equilibrium configurations. The first way to prove it is using the theory of [[Markov chain]]s, either noting that the equilibrium (described by [[Boltzmann distribution|Boltzmann]]-Gibbs distribution) maps into itself, or showing that in a single sweep of the lattice there is a non-zero probability of going from any state of the Markov chain to any other; thus the corresponding irreducible ergodic Markov chain has an asymptotic probability distribution satisfying [[detailed balance]].\n\nAlternatively, we can show explicitily that detailed balance is satisfied. Every transition between two Ising configurations must pass through some bond configuration in the percolation representation. Let's fix a particular bond configuration: what matters in comparing the probabilities related to it is the number of factors <math>q=e^{-2\\beta J}</math> for each missing bond between neighboring spins with the same value; the probability of going to a certain Ising configuration compatible with a given bond configuration is uniform (say <math>p</math>). So the ratio of the transition probabilities of going from one state to another is\n\n<math>\\frac{P_{\\lbrace\\sigma\\rbrace\\rightarrow\\lbrace\\sigma'\\rbrace}}{P_{\\lbrace\\sigma'\\rbrace\\rightarrow\\lbrace\\sigma\\rbrace}}=\\frac{Pr\\left(\\lbrace\\sigma'\\rbrace|B.C.\\right)Pr\\left(B.C.|\\lbrace\\sigma\\rbrace\\right)}{Pr\\left(\\lbrace\\sigma\\rbrace|B.C.\\right)Pr\\left(B.C.|\\lbrace\\sigma'\\rbrace\\right)}=\\frac{p\\cdot \\exp\\left[-2\\beta\\sum\\limits_{<l,m>}\\delta_{\\sigma_l,\\sigma_m}J_{lm}\\right]}{p\\cdot \\exp\\left[-2\\beta\\sum\\limits_{<l,m>}\\delta_{\\sigma'_l,\\sigma'_m}J_{lm}\\right]}\n=e^{-\\beta\\Delta E}</math>\n\nsince <math>\\Delta E=-\\sum\\limits_{<l,m>}J_{lm}\\left(\\sigma'_l \\sigma'_m - \\sigma_l \\sigma_m\\right)=-\\sum\\limits_{<l,m>}J_{lm}\\left[\\delta_{\\sigma'_l,\\sigma'_m}-\\left(1-\\delta_{\\sigma'_l,\\sigma'_m}\\right)-\\delta_{\\sigma_l,\\sigma_m}+\\left(1-\\delta_{\\sigma_l,\\sigma_m}\\right)\\right]=-2\\sum\\limits_{<l,m>}J_{lm}\\left(\\delta_{\\sigma'_l,\\sigma'_m}-\\delta_{\\sigma_l,\\sigma_m}\\right)</math>.\n\nThis is valid for every bond configuration the system can pass through during its evolution, so detailed balance is satisfied for the total transition probability. This proves that the algorithm works.\n\n== Efficiency ==\nAlthough not analytically clear from the original paper, the reason why all the values of z obtained with the SW algorithm are much lower than the exact lower bound for single-spin-flip algorithms (<math>z\\geq\\gamma/\\nu</math>) is that the correlation length divergence is strictly related to the formation of percolation clusters, which are flipped together. In this way the relaxation time is significantly reduced.\n\nThe algorithm is not efficient in simulating [[Geometrical frustration|frustrated systems]].\n\n== See Also ==\n\n* [[Random cluster model]]\n* [[Monte Carlo method]]\n* http://www.hpjava.org/theses/shko/thesis_paper/node69.html\n*http://www-fcs.acs.i.kyoto-u.ac.jp/~harada/monte-en.html\n\n==References==\n*Swendsen, R. H., and Wang, J.-S. (1987), ''Nonuniversal critical dynamics in Monte Carlo simulations'', Phys. Rev. Lett., 58(2):86&ndash;88.\n*Kasteleyn P. W. and Fortuin (1969) J. Phys. Soc. Jpn. Suppl. 26s:11; Fortuin C. M. and Kasteleyn P.W. (1972), Physica 57:536. \n*Wang J.-S. and Swendsen, R. H. (1990),''Cluster Monte Carlo algorithms,'' Physica A 167:565. \n*Barbu, A., Zhu, S. C. (2005), ''Generalizing Swendsen-Wang to sampling arbitrary posterior probabilities'', IEEE Trans Patt. Anal. Mach. Intell., 27(8):1239-1253.\n\n{{DEFAULTSORT:Swendsen-Wang algorithm}}\n[[Category:Monte Carlo methods]]\n[[Category:Statistical mechanics]]\n[[Category:Critical phenomena]]\n[[Category:Phase transitions]]"
    },
    {
      "title": "Tau-leaping",
      "url": "https://en.wikipedia.org/wiki/Tau-leaping",
      "text": "In [[probability theory]], '''tau-leaping''', or '''τ-leaping''', is an approximate method for the [[Computer simulation|simulation]] of a [[stochastic system]].<ref>{{Cite journal | last1 = Gillespie | first1 = D. T. | authorlink1 = Daniel Gillespie| title = Approximate accelerated stochastic simulation of chemically reacting systems | doi = 10.1063/1.1378322 | journal = The Journal of Chemical Physics | volume = 115 | issue = 4 | pages = 1716–1733| year = 2001 | pmid =  | pmc = | url = http://users.soe.ucsc.edu/~msmangel/Gillespie01.pdf| bibcode = 2001JChPh.115.1716G}}</ref> It is based on the [[Gillespie algorithm]], performing all reactions for an interval of length tau before updating the propensity functions.<ref>{{Cite book | last1 = Erhard | first1 = F. | last2 = Friedel | first2 = C. C. | last3 = Zimmer | first3 = R. | doi = 10.1007/978-1-4419-5797-9_30 | chapter = FERN – Stochastic Simulation and Evaluation of Reaction Networks | title = Systems Biology for Signaling Networks | pages = 751 | year = 2010 | isbn = 978-1-4419-5796-2 | pmid =  | pmc = }}</ref> By updating the rates less often this sometimes allows for more efficient simulation and thus the consideration of larger systems.\n\nMany variants of the basic algorithm have been considered.<ref>{{Cite journal | last1 = Cao | first1 = Y. | last2 = Gillespie | first2 = D. T. | authorlink2 = Daniel Gillespie| last3 = Petzold | first3 = L. R. | author3-link = Linda Petzold| doi = 10.1063/1.1992473 | title = Avoiding negative populations in explicit Poisson tau-leaping | journal = The Journal of Chemical Physics | volume = 123 | issue = 5 | pages = 054104 | year = 2005 | pmid =  16108628| pmc = | bibcode = 2005JChPh.123e4104C | citeseerx = 10.1.1.123.3650 }}</ref><ref name=\"1.215\">{{Cite journal | last1 = Cao | first1 = Y. | last2 = Gillespie | first2 = D. T. | authorlink2 = Daniel Gillespie| last3 = Petzold | first3 = L. R. | author3-link = Linda Petzold| doi = 10.1063/1.2159468 | title = Efficient step size selection for the tau-leaping simulation method | journal = The Journal of Chemical Physics | volume = 124 | issue = 4 | pages = 044109 | year = 2006 | pmid =  16460151| url = http://www.cs.ucsb.edu/~cse/Files/NewTau052.pdf| pmc = | bibcode = 2006JChPh.124d4109C}}</ref><ref>{{Cite journal|title = Incorporating postleap checks in tau-leaping|journal = The Journal of Chemical Physics|date = 2008-02-07|issn = 0021-9606|pages = 054103|volume = 128|issue = 5|doi = 10.1063/1.2819665|pmid = 18266441|first = David F.|last = Anderson|arxiv = 0708.0377|bibcode = 2008JChPh.128e4103A}}</ref><ref>{{Cite journal|title = Binomial distribution based τ-leap accelerated stochastic simulation|journal = The Journal of Chemical Physics|date = 2005-01-08|issn = 0021-9606|pages = 024112|volume = 122|issue = 2|doi = 10.1063/1.1833357|pmid = 15638577|first = Abhijit|last = Chatterjee|first2 = Dionisios G.|last2 = Vlachos|first3 = Markos A.|last3 = Katsoulakis|bibcode = 2005JChPh.122b4112C}}</ref>\n<ref>{{Cite journal|title = Hybrid Chernoff Tau-Leap|journal = Multiscale Modeling & Simulation|date = 2014-04-24|issn = 1540-3467|pages = 581–615|volume = 12|issue = 2|doi = 10.1137/130925657|first = Alvaro|last = Moraes|first2 = Raul|last2 = Tempone|first3 = Pedro|last3 = Vilanova|citeseerx = 10.1.1.756.9799}}</ref>\n\n==Algorithm==\nThe algorithm is analogous to the [[Euler method]] for deterministic systems, but instead of making a fixed change\n\n<math>x(t+\\tau)=x(t)+\\tau x'(t)</math>\n\nthe change is\n\n<math>x(t+\\tau)=x(t)+P(\\tau x'(t))</math>\n\nwhere <math>P(\\tau x'(t))</math> is a [[Poisson distribution|Poisson]] distributed random variable with mean <math>\\tau x'(t)</math>.\n\nGiven a state <math>\\mathbf{x}(t)=\\{X_i(t)\\}</math> with events <math>E_j</math> occurring at rate <math>R_j(\\mathbf{x}(t))</math> and with state change vectors <math>\\mathbf{v}_j</math> (where <math>i</math> indexes the state variables, and <math>j</math> indexes the events), the method is as follows:\n\n# Initialise the model with initial conditions <math>\\mathbf{x}(t_0)=\\{X_i(t_0)\\}</math>.\n# Calculate the event rates <math>R_j(\\mathbf{x}(t))</math>.\n# Choose a time step <math>\\tau</math>. This may be fixed, or by some algorithm dependent on the various event rates.\n# For each event <math>E_j</math> generate <math>K_j \\sim \\text{Poisson}(R_j\\tau)</math>, which is the number of times each event occurs during the time interval <math>[t,t+\\tau)</math>.\n# Update the state by\n#:<math>\\mathbf{x}(t+\\tau)=\\mathbf{x}(t)+\\sum_j K_jv_{ij}</math>\n#:where <math>v_{ij}</math> is the change on state variable <math>X_i</math> due to event <math>E_j</math>. At this point it may be necessary to check that no populations have reached unrealistic values (such as a population becoming negative due to the unbounded nature of the Poisson variable <math>K_j</math>).\n# Repeat from Step 2 onwards until some desired condition is met (e.g. a particular state variable reaches 0, or time <math>t_1</math> is reached).\n\n==Algorithm for efficient step size selection==\nThis algorithm is described by Cao et al.<ref name=\"1.215\"/> The idea is to bound the relative change in each event rate <math>R_j</math> by a specified tolerance <math>\\epsilon</math> (Cao et al. recommend <math>\\epsilon=0.03</math>, although it may depend on model specifics). This is achieved by bounding the relative change in each state variable <math>X_i</math> by <math>\\epsilon/g_i</math>, where <math>g_i</math> depends on the rate that changes the most for a given change in <math>X_i</math>.Typically <math>g_i</math> is equal the highest order event rate, but this may be more complex in different situations (especially epidemiological models with non-linear event rates).\n\nThis algorithm typically requires computing <math>2N</math> ''auxiliary values'' (where <math>N</math> is the number of state variables <math>X_i</math>), and should only require reusing previously calculated values <math>R_j(\\mathbf{x})</math>. An important factor in this  since <math>X_i</math> is an integer value, then there is a minimum value by which it can change, preventing the relative change in <math>R_j</math> being bounded by 0, which would result in <math>\\tau</math> also tending to 0.\n\n# For each state variable <math>X_i</math>, calculate the auxiliary values\n#: <math>\\mu_i(\\mathbf{x}) = \\sum_j v_{ij} R_j(\\mathbf{x})</math>\n#: <math>\\sigma_i^2(\\mathbf{x}) = \\sum_j v_{ij}^2 R_j(\\mathbf{x})</math>\n# For each state variable <math>X_i</math>, determine the highest order event in which it is involved, and obtain <math>g_i</math>\n# Calculate time step <math>\\tau</math> as\n#: <math>\\tau = \\min_i {\\left\\{ \\frac{\\max{\\{\\epsilon X_i / g_i, 1\\}}}{|\\mu_i(\\mathbf{x})|}, \\frac{\\max{\\{\\epsilon X_i / g_i, 1\\}}^2}{\\sigma_i^2(\\mathbf{x})} \\right\\}}</math>\n\nThis computed <math>\\tau</math> is then used in Step 3 of the <math>\\tau</math> leaping algorithm.\n\n==References==\n\n{{Reflist}}\n\n[[Category:Chemical kinetics]]\n[[Category:Computational chemistry]]\n[[Category:Monte Carlo methods]]\n[[Category:Stochastic simulation]]"
    },
    {
      "title": "Transition path sampling",
      "url": "https://en.wikipedia.org/wiki/Transition_path_sampling",
      "text": "'''Transition path sampling (TPS)''' is a [[Rare Event Sampling]] method used in [[computer simulation]]s of rare events: physical or chemical transitions of a system from one stable state to another that occur too rarely to be observed on a computer timescale. Examples include [[protein folding]], [[chemical reaction]]s and [[nucleation]]. Standard simulation tools such as [[molecular dynamics]] can generate the dynamical trajectories of all the atoms in the system. However, because of the gap in accessible time-scales between simulation and reality, even present supercomputers might require years of simulations to show an event that occurs once per microsecond without some kind of acceleration.\n\n== Transition path ensemble ==\n\nTPS focuses on the most interesting part of the simulation, ''the transition''. For example, an initially unfolded protein will vibrate for a long time in an open-string configuration before undergoing a transition and fold on itself. The aim of the method is to reproduce precisely those folding moments.\n\nConsider in general a system with two stable states A and B. The system will spend a long time in those states and occasionally jump from one to the other. There are many ways in which the transition can take place. Once a probability is assigned to each of the many pathways, one can construct a [[Monte Carlo method|Monte Carlo]] random walk in the path space of the transition trajectories, and thus generate the ''ensemble'' of all transition paths. All the relevant information can then be extracted from the ensemble, such as the reaction mechanism, the transition states, and the [[rate constant]]s.\n\nGiven an initial path, TPS provides some algorithms to perturb that path and create a new one.  As in all Monte Carlo walks, the new path will then be accepted or rejected in order to have the correct path probability. The procedure is iterated and the ensemble is gradually sampled.\n\nA powerful and efficient algorithm is the so-called ''shooting move''.<ref>{{Cite journal|volume=108|pages=9236 |year=1998|doi=10.1063/1.476378|title=Efficient transition path sampling: Application to Lennard-Jones cluster rearrangements|issue=22|last1=Dellago|first1=Christoph|last2=Bolhuis|first2=Peter G.|last3=Chandler|first3=David|journal=The Journal of Chemical Physics|bibcode=1998JChPh.108.9236D}}</ref> Consider the case of a classical many-body system described by coordinates ''r'' and momenta ''p''. Molecular dynamics generates a path as a set of (''r''<sub>''t''</sub>, ''p''<sub>''t''</sub>) at discrete times ''t'' in [0,''T''] where ''T'' is the length of the path. For a transition from A to B, (''r''<sub>0</sub>, ''p''<sub>0</sub>) is in A, and (''r''<sub>''T''</sub>, ''p''<sub>''T''</sub>) is in ''B''. One of the path times is chosen at random, the momenta ''p'' are modified slightly into ''p''&nbsp;+&nbsp;''δp'', where ''δp'' is a random perturbation consistent with system constraints, e.g. conservation of energy and linear and angular momentum. A new trajectory is then simulated from this point, both backward and forward in time until one of the states is reached. Being in a transition region, this will not take long. If the new path still connects A to B it is accepted, otherwise it is rejected and the procedure starts again.\n\n== Rate constant computation ==\n\nIn the Bennett–Chandler procedure <ref>{{Cite journal|volume=68|pages=2959 |year=1978|doi=10.1063/1.436049|title=Statistical mechanics of isomerization dynamics in liquids and the transition state approximation|issue=6|last1=Chandler|first1=David|journal=The Journal of Chemical Physics|bibcode=1978JChPh..68.2959C}}</ref><ref>{{Cite book|first=C. H.|last= Bennett|title=Algorithms for Chemical Computations, ACS Symposium Series No. 46|editor-first= R. |editor-last=Christofferson |publisher=American Chemical Society|location=Washington, D.C.|year= 1977|isbn=978-0-8412-0371-6}}</ref> the rate constant k<sub>AB</sub> for the transition from ''A'' to ''B'' is derived from the correlation function\n\n: <math>\nC(t) = \\frac{\\langle h_A(0) h_B(t) \\rangle}{\\langle h_A \\rangle}\n</math>\n\nwhere ''h''<sub>''A''(''B'')</sub> is the characteristic function of state A(B), and ''h''<sub>''A''(''B'')</sub>(''t'') is either 1 if the system at time ''t'' is in state ''A''(''B'') or 0 if not. The time-derivative C'(''t'') starts at time 0 at the [[transition state theory]] (TST) value ''k''<sub>''AB''</sub><sup>''TST''</sup> and reaches a plateau ''k''<sub>''AB''</sub> ≤ ''k''<sub>''AB''</sub><sup>''TST''</sup> for times of the order of the transition time. Hence once the function is known up to these times, the rate constant is also available.\n\nIn the TPS framework ''C''(''t'') can be rewritten as an average in the path ensemble\n\n: <math>\nk_{AB}^{TPS}(t) = \\frac{d}{dt}C(t) = \\frac{\\langle \\dot{h_B(t)} \\rangle_{AB}}{\\langle h_B(t') \\rangle_{AB}} C(t')\n</math>\n\nwhere the subscript AB denotes an average in the ensemble of paths that start in A and visit B at least once. Time ''t''' is an arbitrary time in the plateau region of ''C''(''t''). The factor ''C''(''t''<nowiki>'</nowiki>) at this specific time can be computed with a combination of path sampling and [[umbrella sampling]].\n\n== Transition interface sampling ==\n\nThe TPS rate constant calculation can be improved in a variation of the method called Transition interface sampling (TIS).<ref>{{Cite journal |volume=118|pages= 7762 |year=2003|doi=10.1063/1.1562614|title=A novel path sampling method for the calculation of rate constants|issue=17 |last1=Van Erp |first1=Titus S. |last2=Moroni |first2=Daniele |last3=Bolhuis |first3=Peter G. |journal=The Journal of Chemical Physics|arxiv=cond-mat/0210614|bibcode=2003JChPh.118.7762V}}</ref> In this method the transition region is divided in subregions using interfaces. The first interface defines state A and the last state B. The interfaces are not physical interfaces but hypersurfaces in the [[phase space]].\n\nThe rate constant can be viewed as a flux through these interfaces. The rate k<sub>AB</sub> is the flux of trajectories starting before the first interface and going through the last interface. Being a rare event, the flux is very small and practically impossible to compute with a direct simulation. However, using the other interfaces between the states, one can rewrite the flux in terms of transition probabilities between interfaces\n\n<math>\nk_{AB} = \\Phi_{1,0}  \\prod_{i=1}^{n-1} P_A (i+1|i)\n</math>\n\nwhere ''P''<sub>''A''</sub>(''i''&nbsp;+&nbsp;1|''i'') is the probability for trajectories, coming from state ''A'' and crossing interface i, to reach interface&nbsp;''i''&nbsp;+&nbsp;1. Here interface 0 defines state ''A'' and interface n defines state B. The factor Φ<sub>1,0</sub> is the flux through the interface closest to&nbsp;''A''. By making this interface close enough, the quantity can be computed with a standard simulation, as the crossing event through this interface is not a rare event any more.\n\nRemarkably, in the formula above there is no Markov assumption of independent transition probabilities. The quantities ''P''<sub>''A''</sub>(''i''&nbsp;+&nbsp;1|i) carry a subscript ''A'' to indicate that the probabilities are all dependent on the history of the path, all the way from when it left ''A''. These probabilities can be computed with a path sampling simulation using the TPS shooting move. A path crossing interface i is perturbed and a new path is ''shot''. If the path still starts from A and crosses interface&nbsp;''i'', is accepted. The probability ''P''<sub>''A''</sub>(''i''&nbsp;+&nbsp;1|''i'') follows from the ratio of the number of paths that reach interface ''i''&nbsp;+&nbsp;1 to the total number of paths in the ensemble.\n\nTheoretical considerations show that TIS computations are at least twice as fast as TPS, and computer experiments have shown that the TIS rate constant can converge up to 10 times faster. A reason for this is due to TIS using paths of adjustable length and on average shorter than TPS. Also, TPS relies on the correlation function ''C''(''t''), computed by summation of positive and negative terms due to recrossings. TIS instead computes the rate as an effective positive flux, the quantity ''k''<sub>''AB''</sub> is directly computed as an average of only positive terms contributing to the interface transition probabilities.\n\n== Time Dependent Processes ==\n\nTPS/TIS as normally implemented can be acceptable for [[non-equilibrium]] calculations provided that the interfacial fluxes are time-independent ([[stationary process|stationary]]).  To treat non-stationary systems in which there is time dependence in the dynamics, due either to variation of an external parameter or to evolution of the system itself, then other [[Rare Event Sampling|rare event]] methods may be needed, such as [[Stochastic process rare event sampling|Stochastic Process Rare Event Sampling]].<ref>{{Cite journal|volume=133|pages= 244101 |year=2010|doi=10.1063/1.3525099|pmid=21197970|title=Sampling rare events in nonequilibrium and nonstationary systems|issue=24|last1=Berryman|first1=Joshua T.|last2=Schilling|first2=Tanja|journal=The Journal of Chemical Physics|arxiv=1001.2456|bibcode=2010JChPh.133x4101B}}</ref>\n\n== Cited references ==\n{{reflist}}\n\n== More references ==\n\nFor a review of TPS:\n\n*  {{Cite book|volume=123|issue=1|pages=1–84 |year=2002|doi=10.1002/0471231509.ch1|title=Advances in Chemical Physics|isbn=978-0-471-21453-3|last1= Dellago|first1= Christoph|last2= Bolhuis|first2= Peter G.|last3= Geissler|first3= Phillip L.|chapter=Transition Path Sampling}}\n*  {{Cite journal|journal=Annual Review of Physical Chemistry|volume=53|pages=291–318|year=2002|doi=10.1146/annurev.physchem.53.082301.113146|title=TRANSITION PATH SAMPLING: Throwing Ropes Over Rough Mountain Passes, in the Dark|pmid=11972010|last1=Bolhuis|first1=Peter G.|last2=Chandler|first2=David|last3=Dellago|first3=Christoph|last4=Geissler|first4=Phillip L.|bibcode=2002ARPC...53..291B}}\n\nFor a review of TIS\n\n* {{cite thesis|first=D.|last= Moroni|title=Efficient sampling of rare event pathways: from simple models to nucleation|degree= Ph.D. |publisher= Universiteit van Amsterdam |year=2005|url=http://dare.uva.nl/record/149505 |chapter=DARE |hdl=11245/1.240856}}\n\n== External links ==\n* [http://www.berrymanscience.com/downloads.html C++ source code of an S-PRES wrapper program], with optional parallelism using [[OpenMP]].\n\n* http://www.pyretis.org Python open source library to perform transition path sampling, Interfaced with [[GROMACS]], [[LAMMPS]], [[CP2K]].\n\n{{DEFAULTSORT:Transition Path Sampling}}\n[[Category:Computational chemistry]]\n[[Category:Monte Carlo methods]]\n[[Category:Molecular dynamics]]\n[[Category:Theoretical chemistry]]"
    },
    {
      "title": "TraPPE force field",
      "url": "https://en.wikipedia.org/wiki/TraPPE_force_field",
      "text": "{{notability|date=February 2017}}\n{{primary sources|date=February 2017}}\n[[File:TraPPEcrit temp.png|thumb|Graph of TraPPE force field accuracy relative to critical temperatures.]]\n\n'''Transferable Potentials for Phase Equilibria''' ('''TraPPE''') is a family of [[molecular mechanics]] [[Force field (chemistry)|force fields]] developed mainly by the research group of J. Ilja Siepmann at the [[University of Minnesota]].<ref name=\"TraPPE\">{{cite web|url=http://chem-siepmann.oit.umn.edu/siepmann/trappe/index.html|title=TraPPE: Transferable Potentials for Phase Equilibria|work=The Siepmann Group|publisher=University of Minnesota|accessdate=February 4, 2016}}</ref> The force field is parametrized against fluid-phase equilibria data with a strong emphasis on transferability. The term ''transferable'' implies that the same force field parameters are used to describe a given interaction site in different [[molecule]]s (e.g., identical parameters should be used for the methyl group in ''n''-[[pentane]], 1-[[pentene]], and [[1-pentanol]]) and that the force field is applicable to predict different properties (e.g., thermodynamic, structural, or transport) across a wide range of state points (e.g., pressure, temperature, or composition).<ref name=\"TraPPE\" />\n\nFour major versions of the force fields exist for (mostly) organic molecules. They differ in sophistication: TraPPE-CG (coarse grain), TraPPE-UA (united-atom), TraPPE-EH (explicit-hydrogen), and TraPPE-pol (polarizable). Further, TraPPE-SM (small molecule) and TraPPE-zeo ([[zeolite]]s) covers CO{{sub|2}}, N{{sub|2}}, O{{sub|2}}, NH{{sub|3}}, zeolites, etc.<ref name=\"TraPPE\" /> As of 2016, parts of the TraPPE force field are implemented in several software packages including Towhee, Materials Design, Culgi, and Scinomics.\n\n== Functional form ==\nThe basic functional form of the TraPPE force field is (for the united-atom version):<ref name=\"TraPPE-UA\">{{cite web|url=http://chem-siepmann.oit.umn.edu/siepmann/trappe/index.html|title=TraPPE– United Atom |author=<!--Staff writer(s); no by-line.-->|work=The Siepmann Group|publisher=University of Minnesota|accessdate=February 4, 2017}}<!-- note: website is JavaScripted to be separately displayable \"pages\" all within the same URL --></ref>\n\n:<math>\nU(r^N)=\\sum_{j=1} ^{N-1} \\sum_{i=j+1} ^N \\biggl\\{4\\epsilon_{ij}\\biggl[\\left(\\frac{\\sigma_{ij}}{r_{ij}} \\right)^{12} - \\left(\\frac{\\sigma_{ij}}{r_{ij}} \\right)^{6} \\biggr]+ \\frac{q_iq_j}{4\\pi \\epsilon_0 r_{ij}}\\biggr\\} \\ +\\ \\sum_\\text{angles} \\frac{{k_\\text{a} (\\theta - \\theta_0)^2}}2 \\ +\\ \\ U_\\text{torsion}\\ \n</math>\n\nSome considerations regarding the model:\n* In the united-atom model, a CH{{sub|x}} group is treated as one interaction site or ''pseudo [[atom]]'' located on the [[carbon]] center.\n* TraPPE typically uses fixed bond lengths and thus does not include a bond stretching term in the potential. However, the [[molecule]] is still semi-flexible due to the bending and torsional degrees of freedom.\n* The double summation over site indices ''i'' and ''j'' represents nonbonded interactions between two pseudo atoms of different molecules or of the same molecule but separated by (usually) at least four bonds.\n* [[Lennard-Jones potential]] (first term of summation) is used to describe repulsion and dispersion. <math>\\sigma_{ij}</math> is related to the equilibrium distance, <math>R_{0,ij}</math>, by: <math> \\sigma_{ij} = R_{0,ij}/2^{1/6}</math> and <math>\\epsilon_{ij}</math> is the well depth. For unlike Lennard-Jones interactions, standard Lorentz–Berthelot combining rules are used.\n* Coulomb or [[electric potential]] (second term of summation) is used to describe first-order electrostatic interactions.\n* The parameters for the Lennard-Jones and Coulomb potentials reflect effective values that account in a mean-field manner for higher-order and many-body dispersion and induction effects. In general, the parameters used in the TraPPE force field are fit to the [[vapor]] [[liquid]] coexistence curves of a few selected target compounds, but are found to reproduce transport properties also.\n\n== Parameter set ==\nThe parameters for the TraPPE force field can be obtained from the TraPPE website.<ref name=\"TraPPE\" />\n\n== See also ==\n{{columns-list|colwidth=30em|\n* [[Comparison of software for molecular mechanics modeling]]\n* [[Comparison of force field implementations]]\n* [[Molecular dynamics]]\n* [[Monte Carlo method]]\n* [[AMBER]]\n* [[CHARMM]]\n* [[GROMOS]]\n* [[OPLS]]\n}}\n\n== References ==\n{{Reflist}}\n\n== External links ==\n*{{Official website|http://chem-siepmann.oit.umn.edu/siepmann/trappe/index.html}}\n\n[[Category:Monte Carlo methods]]\n[[Category:Force fields]]"
    },
    {
      "title": "Umbrella sampling",
      "url": "https://en.wikipedia.org/wiki/Umbrella_sampling",
      "text": "[[Image:Ergodicity.gif|thumb|right|250px|In an energy landscape with a potential barrier separating two regions of configuration space (bottom sketch), Monte Carlo sampling may be unable to sample the system over a sufficient range of configurations to accurately calculate thermodynamic data, compared to a favourable energy structure (top plot).]]\n\n'''Umbrella sampling''' is a technique in [[computational physics]] and [[chemistry]], used to improve [[Sampling (statistics)|sampling]] of a system (or different systems) where [[ergodicity]] is hindered by the form of the system's [[energy landscape]]. It was first suggested by Torrie and Valleau in 1977 [https://archive.today/20130201215525/http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6WHY-4DDR2HH-3V&_user=126524&_coverDate=02/28/1977&_rdoc=1&_fmt=&_orig=search&_sort=d&view=c&_acct=C000010360&_version=1&_urlVersion=0&_userid=126524&md5=950772b2b4de26ad320fd672ec611557]. It is a particular physical application of the more general [[importance sampling]] in statistics.\n\nSystems in which an energy barrier separates two regions of configuration space may suffer from poor sampling. In [[Metropolis Monte Carlo]] runs, the low probability of overcoming the potential barrier can leave inaccessible configurations poorly sampled &ndash; or even entirely unsampled &ndash; by the simulation. An easily visualised example occurs with a solid at its melting point: considering the state of the system with an [[order parameter]] ''Q'', both liquid (low ''Q'') and solid (high ''Q'') phases are low in energy, but are separated by a [[Thermodynamic free energy|free energy]] barrier at intermediate values of ''Q''. This prevents the simulation from adequately sampling both phases.\n\nUmbrella sampling is a means of \"bridging the gap\" in this situation. The standard Boltzmann weighting for Monte Carlo sampling is replaced by a potential chosen to cancel the influence of the energy barrier present. The [[Markov chain]] generated has a distribution given by:\n\n:<math>\\pi(\\mathbf{r}^N) = \\frac{w(\\textbf{r}^N) \\exp{\\left(- \\frac{U (\\mathbf{r}^N)}{k_B T} \\right)}} {\\int{w(\\mathbf{r^\\prime}^N) \\exp{\\left(-\\frac{U (\\mathbf{r^\\prime}^N)}{k_B T} \\right)} d\\mathbf{r^\\prime}^N}},</math>\n\nwith ''U'' the potential energy, ''w''('''r'''<sup>''N''</sup>) a function chosen to promote configurations that would otherwise be inaccessible to a Boltzmann-weighted Monte Carlo run. In the example above, ''w'' may be chosen such that ''w'' = ''w''(''Q''), taking high values at intermediate ''Q'' and low values at low/high ''Q'', facilitating barrier crossing.\n\nValues for a thermodynamic property ''A'' deduced from a sampling run performed in this manner can be transformed into canonical-ensemble values by applying the formula:\n\n:<math>\\langle A \\rangle = \\frac{\\langle A / w \\rangle_\\pi}{\\langle 1 / w \\rangle_\\pi},</math>\n\nwith the ''<math>\\pi</math>'' subscript indicating values from the umbrella-sampled simulation.\n\nThe effect of introducing the weighting function ''w''('''r'''<sup>''N''</sup>) is equivalent to adding a biasing potential ''V''('''r'''<sup>''N''</sup>) to the potential energy of the system.\n\n:''<math>V(\\mathbf{r}^N) = -k_BT \\ln w(\\mathbf{r}^N)</math>''\n\nIf the biasing potential is strictly a function of a reaction coordinate or order parameter ''<math>Q</math>'', then the (unbiased) free energy profile on the reaction coordinate can be calculated by subtracting the biasing potential from the biased free energy profile.\n\n:<math>F_0(Q) = F_\\pi(Q) - V(Q)</math>\n\nwhere ''<math>F_0(Q)</math>'' is the free energy profile of the unbiased system and ''<math>F_\\pi(Q)</math>'' is the free energy profile calculated for the biased, umbrella-sampled system.\n\nSeries of umbrella sampling simulations can be analyzed using the weighted histogram analysis method (WHAM)<ref>{{cite journal|last=Kumar|first=Shankar|author2=Rosenberg, John M. |author3=Bouzida, Djamal |author4=Swendsen, Robert H. |author5=Kollman, Peter A. |title=THE weighted histogram analysis method for free-energy calculations on biomolecules. I. The method|journal=Journal of Computational Chemistry|date=30 September 1992|volume=13|issue=8|pages=1011–1021|doi=10.1002/jcc.540130812}}</ref> or its generalization.<ref>{{cite journal|last=Bartels|first=C|title=Analyzing biased Monte Carlo and molecular dynamics simulations|journal=Chemical Physics Letters|date=7 December 2000|volume=331|issue=5–6|pages=446–454|doi=10.1016/S0009-2614(00)01215-X|bibcode = 2000CPL...331..446B }}</ref> WHAM can be derived using the [[Maximum likelihood]] method.\n\nSubtleties exist in deciding the most computationally efficient way to apply the umbrella sampling method, as described in Frenkel & Smit's book ''Understanding Molecular Simulation''.\n\nAlternatives to umbrella sampling for computing [[Potential of mean force|potentials of mean force]] or [[reaction rate]]s are [[free energy perturbation]] and [[transition path sampling#Transition interface sampling|transition interface sampling]].  A further alternative which functions in full non-equilibrium is [[Stochastic process rare event sampling|S-PRES]].\n\n== References ==\n{{Reflist}}\n\n== Further reading ==\n* [[Daan Frenkel]] and Berend Smit: \"Understanding Molecular Simulation: From Algorithms to Applications\" [[Academic Press]] 2001, {{ISBN|978-0-12-267351-1}}\n* Johannes Kästner: “Umbrella Sampling”, WIREs Computational Molecular Science 1, 932 (2011) doi:[https://dx.doi.org/10.1002/wcms.66 10.1002/wcms.66]\n\n[[Category:Monte Carlo methods]]\n[[Category:Molecular dynamics]]\n[[Category:Computational chemistry]]\n[[Category:Computational physics]]\n[[Category:Theoretical chemistry]]"
    },
    {
      "title": "Variance reduction",
      "url": "https://en.wikipedia.org/wiki/Variance_reduction",
      "text": "[[File:StratifiedPoints.gif|thumbnail|right|The variance of randomly generated points within a unit square can be reduced through a stratification process.]]\n\nIn [[mathematics]], more specifically in the theory of [[Monte Carlo method]]s, '''variance reduction''' is a procedure used to increase the precision of the estimates that can be obtained for a given simulation or computational effort.<ref name=\"varred17\">{{cite journal|last1=Botev|first1=Z.|last2=Ridder|first2=A.|title=Variance Reduction|journal= Wiley StatsRef: Statistics Reference Online|date=2017|pages=1–6|doi=10.1002/9781118445112.stat07975}}</ref>  Every output random variable from the simulation is associated with a [[variance]] which limits the precision of the simulation results. In order to make a simulation statistically efficient, i.e., to obtain a greater precision and smaller [[confidence interval]]s for the output random variable of interest, variance reduction techniques can be used. The main ones are common random numbers, [[antithetic variates]], [[control variate]]s, [[importance sampling]] and [[stratified sampling]]. For simulation with [[black-box]] models [[subset simulation]] and [[line sampling]] can also be used. Under these headings are a variety of specialized techniques; for example, particle transport simulations make extensive use of \"weight windows\" and \"splitting/Russian roulette\" techniques, which are a form of importance sampling.\n\n==Common Random Numbers (CRN)==\n\nThe common random numbers variance reduction technique is a popular and useful variance reduction technique which applies when we are comparing two or more alternative configurations (of a system) instead of investigating a single configuration. CRN has also been called ''correlated sampling'', ''matched streams'' or ''matched pairs''.\n\nCRN requires synchronization of the random number streams, which ensures that in addition to using the same random numbers to simulate all configurations, a specific random number used for a specific purpose in one configuration is used for exactly the same purpose in all other configurations.  For example, in queueing theory, if we are comparing two different configurations of tellers in a bank, we would want the (random) time of arrival of the ''N''th customer to be generated using the same draw from a random number stream for both configurations.\n\n==Underlying principle of the CRN technique==\n\nSuppose <math>X_{1j}</math> and <math>X_{2j}</math> are the observations from the first and second configurations on the ''j''th independent replication.\n\nWe want to estimate\n:<math>\\xi= E(X_{1j})-E(X_{2j})=\\mu_1-\\mu_2. \\, </math>\n\nIf we perform ''n'' replications of each configuration and let\n:<math>Z_j=X_{1j}-X_{2j} \\quad\\mbox{for } j=1,2,\\ldots, n,</math>\nthen <math>E(Z_j)=\\xi</math> and <math>Z(n) = \\frac{\\sum_{j=1,\\ldots,n} Z_j}{n}</math> is an unbiased estimator of <math>\\xi</math>.\n\nAnd since the <math>Z_j</math>'s are independent identically distributed random variables,\n:<math>\\operatorname{Var}[Z(n)] = \\frac{\\operatorname{Var}(Z_j)}{n} = \\frac{\\operatorname{Var}[X_{1j}] + \\operatorname{Var}[X_{2j}] - 2 \\operatorname{Cov}[X_{1j}, X_{2j}]}{n}. </math>\n\nIn case of independent sampling, i.e., no common random numbers used then Cov(''X''<sub>1''j''</sub>, ''X''<sub>2''j''</sub>) = 0. But if we succeed to induce an element of positive correlation between ''X''<sub>1</sub> and ''X''<sub>2</sub> such that Cov(''X''<sub>1''j''</sub>, ''X''<sub>2''j''</sub>) > 0, it can be seen from the equation above that the variance is reduced.\n\nIt can also be observed that if the CRN induces a negative correlation, i.e., Cov(''X''<sub>1''j''</sub>, ''X''<sub>2''j''</sub>) < 0, this technique can actually backfire, where the variance is increased and not decreased (as intended).<ref name=\"wolfram\">{{cite web|last1=Hamrick|first1=Jeff|title=The Method of Common Random Numbers: An Example|url=http://demonstrations.wolfram.com/TheMethodOfCommonRandomNumbersAnExample/|website=Wolfram Demonstrations Project|accessdate=29 March 2016}}</ref>\n\n==See also==\n*[[Explained variance]]\n\n==References==\n{{Reflist}}\n\n*{{cite book |last=Hammersley |first=J. M. |last2=Handscomb |first2=D. C. |year=1964 |title=Monte Carlo Methods |publisher=Methuen |location=London |isbn=0-416-52340-4 }}\n*{{cite journal |last=Kahn |first=H. |last2=Marshall |first2=A. W. |year=1953 |title=Methods of Reducing Sample Size in Monte Carlo Computations |journal=[[Journal of the Operational Research Society]] |volume=1 |issue=5 |pages=263–271 |doi=10.1287/opre.1.5.263 }}\n*MCNP — A General Monte Carlo N-Particle Transport Code, Version 5  Los Alamos Report LA-UR-03-1987\n\n[[Category:Variance reduction| ]]\n[[Category:Monte Carlo methods]]"
    },
    {
      "title": "VEGAS algorithm",
      "url": "https://en.wikipedia.org/wiki/VEGAS_algorithm",
      "text": "The '''VEGAS algorithm''', due to [[G. Peter Lepage]],<ref name=Lepage1978>{{cite journal|last=Lepage|first=G.P.|title=A New Algorithm for Adaptive Multidimensional Integration|journal=Journal of Computational Physics|date=May 1978|volume=27|pages=192-203|doi=10.1016/0021-9991(78)90004-9}}</ref><ref name=Lepage1980>{{cite journal|last=Lepage|first=G.P.|title=VEGAS: An Adaptive Multi-dimensional Integration Program|journal=Cornell preprint|volume=CLNS 80-447|date=March 1980}}</ref><ref name=Ohl1999>{{cite journal|last=Ohl|first=T.|title=Vegas revisited: Adaptive Monte Carlo integration beyond factorization|journal=Computer Physics Communications|date=July 1999|volume=120|issue=1|pages=13–19|doi=10.1016/S0010-4655(99)00209-X|arxiv=hep-ph/9806432|bibcode=1999CoPhC.120...13O}}</ref> is a method for [[variance reduction|reducing error]] in [[Monte Carlo simulation]]s by using a known or approximate [[probability distribution]] function to concentrate the search in those areas of the [[integrand]] that make the greatest contribution to the final [[integral]].\n\nThe VEGAS algorithm is based on [[importance sampling]]. It samples points from the probability distribution described by the function <math>|f|,</math> so that the points are concentrated in the regions that make the largest contribution to the integral.\n\n==Sampling method==\n{{Further|Importance sampling}}\nIn general, if the Monte Carlo integral of <math>f</math> is sampled with points distributed according to a probability distribution described by the function <math>g,</math> we obtain an estimate <math>\\mathrm{E}_g(f; N),</math>\n\n:<math>\\mathrm{E}_g(f; N) = {1 \\over N } \\sum_i^N { f(x_i)} / g(x_i) .</math>\n\nThe [[variance]] of the new estimate is then\n\n:<math>\\mathrm{Var}_g(f; N) = \\mathrm{Var}(f/g; N)</math>\n\nwhere <math>\\mathrm{Var}(f;N)</math> is the variance of the original estimate, <math>\\mathrm{Var}(f; N) = \\mathrm{E}(f^2; N) - (\\mathrm{E}(f; N))^2.</math>\n\nIf the probability distribution is chosen as <math>g = |f|/I(|f|)</math> then it can be shown that the variance <math>\\mathrm{Var}_g(f; N)</math> vanishes, and the error in the estimate will be zero. In practice it is not possible to sample from the exact distribution g for an arbitrary function, so importance sampling algorithms aim to produce efficient approximations to the desired distribution.\n\n==Approximation of probability distribution==\nThe VEGAS algorithm approximates the exact distribution by making a number of passes over the integration region while [[histogram]]ming the function f. Each histogram is used to define a sampling distribution for the next pass. Asymptotically this procedure converges to the desired distribution. In order to avoid the number of histogram bins growing like <math>K^d</math> with dimension ''d'' the probability distribution is approximated by a separable function: <math>g(x_1, x_2, \\ldots) = g_1(x_1) g_2(x_2) \\cdots</math> so that the number of bins required is only ''Kd''. This is equivalent to locating the peaks of the function from the [[projection (mathematics)|projection]]s of the integrand onto the coordinate axes. The efficiency of VEGAS depends on the validity of this assumption. It is most efficient when the peaks of the integrand are well-localized. If an integrand can be rewritten in a form which is approximately separable this will increase the efficiency of integration with VEGAS.\n\n==See also==\n* [[Las Vegas algorithm]]\n* [[Monte Carlo integration]]\n\n== References ==\n{{reflist}}\n* The [https://www.gnu.org/software/gsl GNU Scientific Library] provides VEGAS routines\n\n[[Category:Monte Carlo methods]]\n[[Category:Computational physics]]\n[[Category:Statistical algorithms]]\n[[Category:Variance reduction]]"
    },
    {
      "title": "Volumetric path tracing",
      "url": "https://en.wikipedia.org/wiki/Volumetric_path_tracing",
      "text": "'''Volumetric path tracing''' is a method for rendering images in [[computer graphics]] which was first introduced by Lafortune and Willems.<ref>{{cite journal|last1=Lafortune|first1=Eric P|last2=Willems|first2=Yves|title=Rendering participating media with bidirectional path tracing|journal=Proceedings of Rendering Techniques'96|date=June 1996|pages=91–100|url=http://luthuli.cs.uiuc.edu/~daf/courses/Rendering/Papers/lafortune96rendering.pdf}}</ref> This method enhances the rendering of the lighting in a scene by extending the [[path tracing]] method with the effect of [[light scattering]]. It is used for photorealistic effects of participating media like fire, explosions, smoke, clouds, fog or soft shadows.\n\nAs in the path tracing method a ray gets followed backwards, beginning from the eye on, until reaching the light source. In volumetric path tracing scatter events can occur while these process. When a light ray hits a surface, a special amount of it can get scattered into the media.<ref name=ref2>{{cite journal|last1=Skånberg|first1=Robin|title=Evaluation of Visual Parameters in Volumetric Path Tracing|date=January 2015|pages=20–22|url=http://www.diva-portal.org/smash/get/diva2:796154/FULLTEXT01.pdf|publisher=Department of Science and Technology, Linköping University}}</ref>\n\n==Description==\nThe algorithm is based on the volumetric rendering equation,<ref>{{cite journal|last1=Chandrasekhar|first1=Subrahmanyan|title=Radiative transfer|journal=Quarterly Journal of the Royal Meteorological Society|date=1950|volume=76|issue=330|pages=498|doi=10.1002/qj.49707633016|publisher=John Wiley & Sons, Ltd|issn=1477-870X}}</ref> which extends the [[rendering equation]] with a scattering term.\nIt is composed of an absorption, out-scattering, emission and an in-scattering part. The absorption and out-scattering together form the extinction term. The in-scattering is the most expensive part to calculate because it needs an integration over all paths in the scene that consist [[radiance]]. Therefore, thousands of paths need to be traced to get a result with a good quality without much noise. For a better handling the in-scattering term can be split into two components, the single scattering and the multiple scattering.<ref name = ref4>{{cite book|last1=Jarosz|first1=Wojciech|title=Efficient Monte Carlo Methods for Light Transport in Scattering Media|date=2008|chapter-url=http://www.cs.dartmouth.edu/~wjarosz/publications/dissertation/|chapter=4-5|pages=55–100|publisher=University of California}}</ref>\n\n==Algorithm==\nIn volumetric path tracing a distance between the ray and the surface gets [[Sampling (signal processing)|sampled]] and compared with the distance of the nearest intersection of the ray with the surface. If the sampled distance is smaller, a scatter event occurs. In that case the path gets evaluated and traced from the scatter point in the media, not from the surface point on which it falls. The rest of the procedure continues the same, until reaching the light source.<ref name=ref2/><ref>{{cite journal|last1=Kulla|first1=Christopher|last2=Fajardo|first2=Marcos|title=Importance Sampling Techniques for Path Tracing in Participating Media|journal=Comp. Graph. Forum|date=June 2012|volume=31|issue=4|pages=1519–1528|doi=10.1111/j.1467-8659.2012.03148.x|publisher=John Wiley \\&amp; Sons, Inc.|issn=0167-7055}}</ref>\n\n==Sampling==\nA possible way of sampling distances is the ''ray marching'' method. It works similar to [[ray tracing (graphics)|ray tracing]] but operates on a [[distance field]] of the scene and acts in discrete steps. The scattering inside the media can be determined by a [[phase function]] using [[importance sampling]]. Therefore, the ''Henyey–Greenstein phase function''<ref>{{cite web|title=The Henyey–Greenstein phase function|url=http://www.astro.umd.edu/~jph/HG_note.pdf}}</ref> can be applied. It is a non-[[isotropic]] phase function for simulating the scattering of materials like oceans, clouds or skin.<ref name=ref4 />\n\n==References==\n{{Reflist}}\n\n==Further reading==\n* [http://www.cs.cornell.edu/courses/cs6630/2012sp/notes/09volpath.pdf Volumetric Path Tracing] (March 2012). Cornell University.\n* [http://www.cs.cornell.edu/courses/cs6630/2012sp/notes/08radiative-transfer.pdf Volume light transport] (March 2012). Cornell University.\n* [https://pdfs.semanticscholar.org/31c3/9ba9975409127ef352b3a4b9024624090cc8.pdf Efficient Volume Rendering in CUDA Path Tracer] (2013). University of Southern California.\n\n[[Category:Global illumination algorithms]]\n[[Category:Computer graphics algorithms]]\n[[Category:Monte Carlo methods]]"
    },
    {
      "title": "Wolff algorithm",
      "url": "https://en.wikipedia.org/wiki/Wolff_algorithm",
      "text": "The '''Wolff algorithm''', named after [[Ulli Wolff]], is an [[algorithm]] for [[Monte Carlo simulation]] of the [[Ising model]] in which the unit to be flipped is not a single spin, as in the heat bath or Metropolis algorithms, but a cluster of them. This cluster is defined as the set of neighbouring spins sharing the same value of the spin. The Wolff algorithm is an improvement over the [[Swendsen–Wang algorithm]] because it has a larger probability of flipping bigger clusters.\n\nThe advantage of Wolff algorithm over other algorithms for magnetic spin simulations like single spin flip is that it allows non-local moves on the energy. One important consequence of this is that in some situations (e.g. ferromagnetic Ising model or fully frustrated Ising model), the scaling of the Multicanonic simulation is <math>N^2</math>, better than <math>N^{2+z}</math>, where z is the exponent associated with the critical slowing down phenomena.\n\n==References==\n*{{citation | doi=10.1103/PhysRevLett.62.361 | title=Collective Monte Carlo Updating for Spin Systems | year=1989 | author=Wolff, Ulli | journal=Physical Review Letters | volume=62 | pages=361–364 | pmid=10040213 | issue=4 | bibcode=1989PhRvL..62..361W}}\n*{{citation | doi=10.1142/S0129183195000150 | title=Parallel Wolff cluster algorithms | year=1995 | author1=Bae, S. | author2=Ko, S.H. | author3=Coddington, P.D. | journal=International Journal of Modern Physics C | volume=6 | issue=2 | pages=197 |bibcode = 1995IJMPC...6..197B | citeseerx=10.1.1.138.1448 }}\n*{{citation | doi=10.1103/PhysRevLett.69.3382 | title=Monte Carlo simulations: Hidden errors from ''good'' random number generators | year=1992 | author1=Ferrenberg, Alan M. | author2=Landau, D.P. | author3=Wong, Y. Joanna | journal=Physical Review Letters | volume=69 | pages=3382–3384 | pmid=10046804 | issue=23 | bibcode=1992PhRvL..69.3382F}}\n\n==External links==\n*[http://www.netlib.org/utk/lsi/pcwLSI/text/node292.html ''Cluster Algorithms''] at [[Netlib]]\n\n[[Category:Monte Carlo methods]]\n[[Category:Statistical mechanics]]\n\n\n{{physics-stub}}"
    },
    {
      "title": "Ziff–Gulari–Barshad model",
      "url": "https://en.wikipedia.org/wiki/Ziff%E2%80%93Gulari%E2%80%93Barshad_model",
      "text": "The '''Ziff–Gulari–Barshad (ZGB) model''' is a simple [[Monte Carlo method]] for [[catalytic reaction]]s of [[oxidation]] of [[carbon monoxide]] to [[carbon dioxide]] on a surface using [[Monte-Carlo methods]] which captures correctly the essential dynamics: the [[phase transition]] between two poisoned states (either CO<sub>2</sub>- or O-poisoned) and a [[steady-state]] in between. It is named after Robert M. Ziff, Erdogan Gulari, and Yoav Barshad, who published it in 1986.<ref>{{cite journal|vauthors=Ziff RM, Gulari E, Barshad Y | title=Kinetic phase transitions in an irreversible surface-reaction model| journal=Phys Rev Lett| volume=56| issue=24| pages=2553–56| date = June 1986| pmid=10033028| bibcode=1986PhRvL..56.2553Z| doi=10.1103/PhysRevLett.56.2553}}</ref>\n\n== Model definition ==\nThe model consists of three steps:\n* ''Adsorption'' of the reacting species [[carbon monoxide|CO]] and [[oxygen|O<sub>2</sub>]] \n* The actual ''reaction step'' on the surface: CO + O → CO<sub>2</sub>\n* Desorption of the products.\nThe simplest implementation considers the catalyst as simple square two-dimensional [[lattice model (physics)|lattice]], but one can also consider other kinds of underlying lattices.<ref>{{cite journal|last=Gao|first=Zhuo|author2=Yang, Z. |title=Dynamic scaling behavior of the Ziff–Gulari–Barshad model on regular fractal lattices: The influence of lacunarity|journal=Physical Review E|date=March 1989|volume=59|issue=3|pages=2795–2800|doi=10.1103/PhysRevE.59.2795|bibcode = 1999PhRvE..59.2795G }}</ref> When a gas-phase molecule touches an empty site, adsorption occurs immediately and the chemical reaction is also instantaneous. Furthermore, assumes that the composition of the [[gas phase]] remains constant.\n\n=== Results and other work ===\nThe model belongs to the [[universality class]] of [[directed percolation]].<ref>{{cite journal|last=Grassberger|first=Peter|title=Are damage spreading transitions generically in the universality class of directed percolation?|journal=Journal of Statistical Physics|date=April 1995|volume=79|issue=1-2|pages=13–23|doi=10.1007/BF02179381|arxiv = cond-mat/9409068 |bibcode = 1995JSP....79...13G }}</ref>  The model was modified several times.<ref>{{cite journal|last=Beney|first=P|author2=Droz, M |author3=Frachebourg, L |title=On the critical behaviour of cellular automata models of nonequilibrium phase transitions|journal=Journal of Physics A: Mathematical and General|date=21 July 1990|volume=23|issue=14|pages=3353–3359|doi=10.1088/0305-4470/23/14/031|bibcode = 1990JPhA...23.3353B }}</ref>\n<ref>{{cite journal|last=Albano|first=Ezequiel|title=Critical exponents for the irreversible surface reaction A+B→AB with B desorption on homogeneous and fractal media|journal=Physical Review Letters|date=July 1992|volume=69|issue=4|pages=656–659|doi=10.1103/PhysRevLett.69.656|bibcode = 1992PhRvL..69..656A }}</ref>\n\n==References==\n{{reflist}}\n\n{{DEFAULTSORT:Ziff-Gulari-Barshad model}}\n[[Category:Chemical physics]]\n[[Category:Monte Carlo methods]]\n[[Category:Statistical mechanics]]\n[[Category:Computational physics]]"
    },
    {
      "title": "Construction of an irreducible Markov chain in the Ising model",
      "url": "https://en.wikipedia.org/wiki/Construction_of_an_irreducible_Markov_chain_in_the_Ising_model",
      "text": "{{Multiple issues|\n{{context|date=June 2015}}\n{{tone|date=June 2015}}\n{{Underlinked|date=August 2015}}\n{{Orphan|date=June 2015}}\n{{original research|date=June 2015}}\n}}\n\nIn applied mathematics, '''construction of an irreducible Markov Chain in the Ising model''' is the first step in overcoming a computational obstruction encountered when a [[Markov chain Monte Carlo]] method is used to get an exact [[goodness-of-fit test]] for the finite [[Ising model]].\n\nThe '''Ising model''' was used to study magnetic [[phase transition]]s at the very beginning, and now it is one of the most famous models of interacting systems.\n\n== Markov bases ==\nEvery integer vector <math>z\\in Z^{N_1\\times\\cdots\\times N_d}</math>, can be uniquely written as <math>z=z^+-z^-</math>, where <math>z^+</math> and <math>z^-</math> are nonnegative vectors.  A Markov basis for the Ising model is a set <math> \\widetilde{Z}\\subset Z ^{N_1\\times\\cdots\\times N_d}</math> of integer vector such that:\n\n(i) For all <math>z\\in \\widetilde{Z}</math>, there must be <math>T_1(z^+)=T_1(z^-)</math> and <math>T_2(z^+)=T_2(z^-)</math>.\n\n(ii) For any <math>a,b\\in Z_{>0}</math> and any <math>x,y\\in S(a,b)</math>, there always exist <math>z_1,\\ldots,z_k \\in \\widetilde{Z}</math> satisfy\n\n: <math>y=x+\\sum_{i=1}^k z_i</math>\n\nand\n\n: <math>x+\\sum_{i=1}^l z_i\\in S(a,b)</math>\n\nfor ''l'' = 1,...,''k''.\n\nThe element of <math>\\widetilde{Z}</math> is moved. Then using the [[Metropolis–Hastings algorithm]], we can get an aperiodic, reversible and irreducible Markov Chain.\n\nThe paper published by P.DIACONIS AND B.STURMFELS in 1998 ‘Algebraic algorithms for sampling from conditional distributions’ shows that a Markov basis can be defined algebraically as in Ising model\n\nThen by the paper published by P.DIACONIS AND B.STURMFELS in 1998,<ref>{{Cite journal|title = Algebraic algorithms for sampling from conditional distributions|url = http://projecteuclid.org/euclid.aos/1030563990|journal = The Annals of Statistics|date = February 1998|issn = 0090-5364|pages = 363–397|volume = 26|issue = 1|doi = 10.1214/aos/1030563990|first = Persi|last = Diaconis|first2 = Bernd|last2 = Sturmfels|citeseerx = 10.1.1.28.6847}}</ref> any generating set for the ideal <math>I:=\\ker({\\psi}*{\\phi})</math> is a Markov basis for the Ising model.\n\n== Construction of an irreducible Markov chain ==\nWe{{who?|date=December 2018}} cannot get a uniform samples from <math>S(a,b)</math> and lead to inaccurate p-value.<ref>{{Cite journal|title = Generalized Monte Carlo significance tests|url = http://biomet.oxfordjournals.org/content/76/4/633|journal = Biometrika|date = December 1989|issn = 0006-3444|pages = 633–642|volume = 76|issue = 4|doi = 10.1093/biomet/76.4.633|language = en|first = Julian|last = Besag|first2 = Peter|last2 = Clifford}}</ref> Thus in the following we will show how to modify the algorithm mentioned in the paper to get the irreducible Markov chain in Ising model.\n\nA simple swap is defined as <math>z\\in Z^{N_1\\times\\cdots\\times N_d}</math> of the form <math>z=e_i-e_j</math>, where the <math>e_i</math> is the canonical basis vector of <math>z\\in Z^{N_1\\times\\cdots\\times N_d}</math> Simple swaps changes the states of two lattice points in ''y''.\n\nZ denotes the set of sample swaps. Then two configurations <math>y',y\\in S(a,b)</math> are <math>S(a,b)</math>-connected by ''Z'', if there is a path between <math>y</math> and <math>y'</math> in <math>S(a,b)</math> consisting of simple swaps <math>z\\in Z</math>, which means there exist <math>z_1,\\ldots,z_k\\in Z</math> such that\n\n: <math>y' = y+\\sum_{i=1}^k z_i</math>\n\nwith\n\n: <math>y+\\sum_{i=1}^l z_i\\in S(a,b)</math>\n\nfor ''l'' = 1,...,''k''\n\nThe algorithm can be describe as:\n\n(i) Start with the Markov chain in a configuration <math>y\\in S(a,b)</math>\n\n(ii) Select <math>z\\in Z</math> uniformly at random and let<math>y' = y+z</math>.\n\n(iii) Accept <math>y'</math> if <math>y'\\in S(a,b)</math>; otherwise remain in ''y''.\n\nAlthough the resulting Markov Chain is possible cannot leave initial states, the problem does not arise for the 1 dimensional Ising model which we will introduce in the following. In high dimension we can overcome this problem by using Metropolis-Hastings algorithm in the smallest expanded sample space <math>S^{\\star}(a,b)</math>\n\n== Irreducibility in the 1-dimensional Ising model ==\nBefore prove of the irreducibility in 1-dimensional Ising model, we present two lemma below:\n\n'''Lemma 1:'''The max-singleton configuration of <math>S(a,b)</math> for the 1-dimension Ising model is unique(up to location of its connected components) and consists of ''b''/2&nbsp;&minus;&nbsp;1 singletons and one connected components of size ''a''&nbsp;&minus;&nbsp;''b''/2&nbsp;+&nbsp;1.\n\n'''Lemma 2:'''For <math>a,b\\in N</math> and <math>y\\in S(a,b)</math>, let <math>y^{\\star}S(a,b)</math> denote the unique max-singleton configuration. There exists a sequence <math>z_1,\\ldots,z_k\\in Z</math> such that:\n\n: <math>y^{\\star} = y+\\sum_{i=1}^k z_i</math>\n\nand\n\n: <math>y+\\sum_{i=1}^l z_i\\in S(a,b)</math>\n\nfor ''l'' = 1,...,''k''\n\nSince <math>S^{\\star}(a,b)</math> is the smallest expanded sample space, which contains <math>S(a,b)</math>. And any two configurations in <math>S(a,b)</math> can be connected by simple swaps Z without\nleaving <math>S^{\\star}(a,b)</math>. This can be prove by the lemma we present above. So we an get the irreducibility of the Markov Chain based on simple swaps for the 1-dimension Ising model.\n\n== Conclusion ==\nEven though we just show the irreducibility of the Markov chain based on simple swaps for the 1-dimension Ising model, we can get the same conclusion of 2-dimension or higher dimension Ising model.\n\n== References ==\n{{Reflist}}\n\n[[Category:Lattice models]]\n[[Category:Markov chain Monte Carlo]]"
    },
    {
      "title": "Gibbs sampling",
      "url": "https://en.wikipedia.org/wiki/Gibbs_sampling",
      "text": "{{Bayesian statistics}}\n\nIn [[statistics]], '''Gibbs sampling''' or a '''Gibbs sampler''' is a [[Markov chain Monte Carlo]] (MCMC) [[algorithm]] for obtaining a sequence of observations which are approximated from a specified [[multivariate distribution|multivariate]] [[probability distribution]], when direct sampling is difficult.  This sequence can be used to approximate the joint distribution (e.g., to generate a histogram of the distribution); to approximate the [[marginal distribution]] of one of the variables, or some subset of the variables (for example, the unknown [[parameter]]s or [[latent variable]]s); or to compute an [[integral]] (such as the [[expected value]] of one of the variables).  Typically, some of the variables correspond to observations whose values are known, and hence do not need to be sampled.\n\nGibbs sampling is commonly used as a means of [[statistical inference]], especially [[Bayesian inference]].  It is a [[randomized algorithm]] (i.e. an algorithm that makes use of [[random number generation|random number]]s), and is an alternative to [[deterministic algorithm]]s for statistical inference such as the [[expectation-maximization algorithm]] (EM).\n\nAs with other MCMC algorithms, Gibbs sampling generates a [[Markov chain]] of samples, each of which is [[autocorrelation|correlated]] with nearby samples. As a result, care must be taken if independent samples are desired. Generally, samples from the beginning of the chain (the ''burn-in period'') may not accurately represent the desired distribution and are usually discarded. It has been shown, however, that using a longer chain instead (e.g. a chain that is ''n'' times as long as the initially considered chain using a thinning factor of ''n'') leads to better estimates of the true posterior. Thus, ''thinning'' should only be applied when time or computer memory are restricted.<ref>{{Cite journal|last=Link|first=William A.|last2=Eaton|first2=Mitchell J.|date=2012-02-01|title=On thinning of chains in MCMC|journal=Methods in Ecology and Evolution|language=en|volume=3|issue=1|pages=112–115|doi=10.1111/j.2041-210X.2011.00131.x|issn=2041-210X}}</ref>\n\n== Introduction ==\nGibbs sampling is named after the physicist [[Josiah Willard Gibbs]], in reference to an analogy between the [[Sampling (statistics)|sampling]] algorithm and [[statistical physics]]. The algorithm was described by brothers [[Stuart Geman|Stuart]] and [[Donald Geman]] in 1984, some eight decades after the death of Gibbs.<ref>{{Cite journal\n | first1=S. |last1=Geman\n | first2=D. |last2=Geman |authorlink2=Donald Geman\n | title = Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images\n | journal = [[IEEE Transactions on Pattern Analysis and Machine Intelligence]]\n | volume = 6 |issue=6\n | pages = 721–741\n | year = 1984\n | doi = 10.1109/TPAMI.1984.4767596\n}}</ref>\n\nIn its basic version, Gibbs sampling is a special case of the [[Metropolis–Hastings algorithm]].  However, in its extended versions (see [[#Variations and extensions|below]]), it can be considered a general framework for sampling from a large set of variables by sampling each variable (or in some cases, each group of variables) in turn, and can incorporate the [[Metropolis–Hastings algorithm]] (or more sophisticated methods such as [[slice sampling]], [[adaptive rejection sampling]] and adaptive rejection Metropolis algorithms<ref name=\":1\">{{Cite journal|title = Adaptive Rejection Metropolis Sampling within Gibbs Sampling |journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1995-01-01|pages = 455–472|volume = 44|issue = 4|jstor=2986138 |first = W. R.|last = Gilks|first2 = N. G.|last2 = Best|first3 = K. K. C.|last3 = Tan}}</ref><ref name=\":2\">{{Cite journal|title = Adaptive rejection Metropolis sampling using Lagrange interpolation polynomials of degree 2 |journal = Computational Statistics & Data Analysis|date = 2008-03-15|pages = 3408–3423|volume = 52|issue = 7|doi = 10.1016/j.csda.2008.01.005|first = Renate|last = Meyer|first2 = Bo|last2 = Cai|first3 = François|last3 = Perron}}</ref><ref name=\":0\">{{Cite journal|title = Independent Doubly Adaptive Rejection Metropolis Sampling Within Gibbs Sampling |journal = IEEE Transactions on Signal Processing|date = 2015-06-01|issn = 1053-587X|pages = 3123–3138|volume = 63|issue = 12|doi = 10.1109/TSP.2015.2420537|first = L.|last = Martino|first2 = J.|last2 = Read|first3 = D.|last3 = Luengo|arxiv = 1205.5494|bibcode = 2015ITSP...63.3123M}}</ref>) to implement one or more of the sampling steps.\n\nGibbs sampling is applicable when the joint distribution is not known explicitly or is difficult to sample from directly, but the [[conditional distribution]] of each variable is known and is easy (or at least, easier) to sample from.   The Gibbs sampling algorithm generates an instance from the distribution of each variable in turn, conditional on the current values of the other variables.  It can be shown that the sequence of samples constitutes a [[Markov chain]], and the stationary distribution of that Markov chain is just the sought-after joint distribution.<ref>{{Cite book|title=Bayesian data analysis|last=Gelman|first=Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B|publisher=CRC press Boca Raton|year=2014|isbn=|volume=2|location=FL|pages=}}</ref>\n\nGibbs sampling is particularly well-adapted to sampling the [[posterior probability|posterior distribution]] of a [[Bayesian network]], since Bayesian networks are typically specified as a collection of conditional distributions.\n\n== Implementation ==\n\nGibbs sampling, in its basic incarnation, is a special case of the [[Metropolis–Hastings algorithm]].  The point of Gibbs sampling is that given a [[multivariate distribution]] it is simpler to sample from a conditional distribution than to [[marginal distribution|marginalize]] by integrating over a [[joint distribution]].  Suppose we want to obtain <math>\\left.k\\right.</math> samples of <math>\\mathbf{X} = (x_1, \\dots, x_n)</math> from a joint distribution <math> p(x_1, \\dots, x_n) </math>.  Denote the <math>i</math>th sample by <math>\\mathbf{X}^{(i)} = \\left(x_1^{(i)}, \\dots, x_n^{(i)}\\right)</math>.  We proceed as follows:\n\n#We begin with some initial value <math>\\mathbf{X}^{(i)}</math>.\n#We want the next sample. Call this next sample <math>\\mathbf{X}^{(i+1)}</math>. Since <math>\\mathbf{X}^{(i+1)} = \\left(x_1^{(i+1)}, x_2^{(i+1)}, \\dots, x_n^{(i+1)}\\right)</math> is a vector, we sample each component of the vector, <math>x_j^{(i+1)}</math>, from the distribution of that component conditioned on all other components sampled so far. But there is a catch: we condition on <math>\\mathbf{X}^{(i+1)}</math>'s components ''up to'' <math>x_{j-1}^{(i+1)}</math>, and thereafter condition on <math>\\mathbf{X}^{(i)}</math>'s components, starting from <math>x_{j+1}^{(i)}</math> to <math>x_n^{(i)}</math>. To achieve this, we sample the components in order, starting from the first component. More formally, to sample <math>x_j^{(i+1)}</math>, we update it according to the distribution specified by <math>p\\left(x_j^{(i+1)}|x_1^{(i+1)},\\dots,x_{j-1}^{(i+1)},x_{j+1}^{(i)},\\dots,x_n^{(i)}\\right)</math>. Note that we use the value that the <math>(j+1)</math>th component had in the <math>i</math>th sample, not the <math>(i+1)</math>th sample.\n#Repeat the above step <math>k</math> times.\n\nIf such sampling is performed, these important facts hold:\n* The samples approximate the joint distribution of all variables.\n* The marginal distribution of any subset of variables can be approximated by simply considering the samples for that subset of variables, ignoring the rest.\n* The [[expected value]] of any variable can be approximated by averaging over all the samples.\n\nWhen performing the sampling:\n*The initial values of the variables can be determined randomly or by some other algorithm such as [[expectation-maximization]].\n*It is not actually necessary to determine an initial value for the first variable sampled.\n*It is common to ignore some number of samples at the beginning (the so-called ''burn-in period''), and then consider only every <math>n</math>th sample when averaging values to compute an expectation.  For example, the first 1,000 samples might be ignored, and then every 100th sample averaged, throwing away all the rest. The reason for this is that (1) the [[stationary distribution]] of the Markov chain is the desired joint distribution over the variables, but it may take a while for that stationary distribution to be reached; (2) successive samples are not independent of each other but form a [[Markov chain]] with some amount of correlation. Sometimes, algorithms can be used to determine the amount of [[autocorrelation]] between samples and the value of <math>n</math> (the period between samples that are actually used) computed from this, but in practice there is a fair amount of \"[[Black magic (programming)|black magic]]\" involved.\n*The process of [[simulated annealing]] is often used to reduce the \"[[random walk]]\" behavior in the early part of the sampling process (i.e. the tendency to move slowly around the sample space, with a high amount of [[autocorrelation]] between samples, rather than moving around quickly, as is desired). Other techniques that may reduce autocorrelation are ''collapsed Gibbs sampling'', ''blocked Gibbs sampling'', and ''ordered overrelaxation''; see below.\n\n=== Relation of conditional distribution and joint distribution ===\nFurthermore, the conditional distribution of one variable given all others is proportional to the joint distribution:\n\n:<math>p(x_j\\mid x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n) = \\frac{p(x_1,\\dots,x_n)}{p(x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n)} \\propto p(x_1,\\dots,x_n)</math>\n\n\"Proportional to\" in this case means that the denominator is not a function of <math>x_j</math> and thus is the same for all values of <math>x_j</math>; it forms part of the [[normalization constant]] for the distribution over <math>x_j</math>.  In practice, to determine the nature of the conditional distribution of a factor <math>x_j</math>, it is easiest to factor the joint distribution according to the individual conditional distributions defined by the [[graphical model]] over the variables, ignore all factors that are not functions of <math>x_j</math> (all of which, together with the denominator above, constitute the normalization constant), and then reinstate the normalization constant at the end, as necessary.  In practice, this means doing one of three things:\n#If the distribution is discrete, the individual probabilities of all possible values of <math>x_j</math> are computed, and then summed to find the normalization constant.\n#If the distribution is continuous and of a known form, the normalization constant will also be known.\n#In other cases, the normalization constant can usually be ignored, as most sampling methods do not require it.\n\n== Inference ==\nGibbs sampling is commonly used for [[statistical inference]] (e.g. determining the best value of a parameter, such as determining the number of people likely to shop at a particular store on a given day, the candidate a voter will most likely vote for, etc.).  The idea is that observed data is incorporated into the sampling process by creating separate variables for each piece of observed data and fixing the variables in question to their observed values, rather than sampling from those variables.  The distribution of the remaining variables is then effectively a [[posterior distribution]] conditioned on the observed data.\n\nThe most likely value of a desired parameter (the [[mode (statistics)|mode]]) could then simply be selected by choosing the sample value that occurs most commonly; this is essentially equivalent to [[maximum a posteriori]] estimation of a parameter. (Since the parameters are usually continuous, it is often necessary to \"bin\" the sampled values into one of a finite number of ranges or \"bins\" in order to get a meaningful estimate of the mode.) More commonly, however, the [[expected value]] ([[mean]] or average) of the sampled values is chosen; this is a [[Bayes estimator]] that takes advantage of the additional data about the entire distribution that is available from Bayesian sampling, whereas a maximization algorithm such as [[expectation maximization]] (EM) is capable of only returning a single point from the distribution.  For example, for a unimodal distribution the mean (expected value) is usually similar to the mode (most common value), but if the distribution is [[skewness|skewed]] in one direction, the mean will be moved in that direction, which effectively accounts for the extra probability mass in that direction. (Note, however, that if a distribution is multimodal, the expected value may not return a meaningful point, and any of the modes is typically a better choice.)\n\nAlthough some of the variables typically correspond to parameters of interest, others are uninteresting (\"nuisance\") variables introduced into the model to properly express the relationships among variables.  Although the sampled values represent the [[joint distribution]] over all variables, the nuisance variables can simply be ignored when computing expected values or modes; this is equivalent to [[marginal distribution|marginalizing]] over the nuisance variables.  When a value for multiple variables is desired, the expected value is simply computed over each variable separately. (When computing the mode, however, all variables must be considered together.)\n\n[[Supervised learning]], [[unsupervised learning]] and [[semi-supervised learning]] (aka learning with missing values) can all be handled by simply fixing the values of all variables whose values are known, and sampling from the remainder.\n\nFor observed data, there will be one variable for each observation—rather than, for example, one variable corresponding to the [[sample mean]] or [[sample variance]] of a set of observations.  In fact, there generally will be no variables at all corresponding to concepts such as \"sample mean\" or \"sample variance\".  Instead, in such a case there will be variables representing the unknown true mean and true variance, and the determination of sample values for these variables results automatically from the operation of the Gibbs sampler.\n\n[[Generalized linear model]]s (i.e. variations of [[linear regression]]) can sometimes be handled by Gibbs sampling as well.  For example, [[probit regression]] for determining the probability of a given binary (yes/no) choice, with [[normal distribution|normally distributed]] priors placed over the regression coefficients, can be implemented with Gibbs sampling because it is possible to add additional variables and take advantage of [[conjugate prior|conjugacy]].  However, [[logistic regression]] cannot be handled this way.  One possibility is to approximate the [[logistic function]] with a mixture (typically 7–9) of normal distributions.  More commonly, however, [[Metropolis–Hastings]] is used instead of Gibbs sampling.\n\n== Mathematical background ==\n\nSuppose that a sample <math>\\left.X\\right.</math> is taken from a distribution depending on a parameter vector <math>\\theta \\in \\Theta \\,\\!</math> of length <math>\\left.d\\right.</math>, with prior distribution <math>g(\\theta_1, \\ldots , \\theta_d)</math>.  It may be that <math>\\left.d\\right.</math> is very large and that numerical integration to find the marginal densities of the <math>\\left.\\theta_i\\right.</math> would be computationally expensive. Then an alternative method of calculating the marginal densities is to create a Markov chain on the space <math>\\left.\\Theta\\right.</math> by repeating these two steps:\n\n# Pick a random index <math>1 \\leq j \\leq d</math>\n# Pick a new value for <math>\\left.\\theta_j\\right.</math> according to <math>g(\\theta_1, \\ldots , \\theta_{j-1} , \\, \\cdot \\, , \\theta_{j+1} , \\ldots , \\theta_d )</math>\n\nThese steps define a [[Markov chain#Reversible Markov chain|reversible Markov chain]] with the desired invariant distribution <math>\\left.g\\right.</math>. This\ncan be proved as follows. Define <math>x \\sim_j y</math> if <math>\\left.x_i = y_i\\right.</math> for all <math>i \\neq j</math> and let <math>\\left.p_{xy}\\right.</math> denote the probability of a jump from <math>x \\in \\Theta</math> to <math>y \\in \\Theta</math>. Then, the transition probabilities are\n\n:<math>p_{xy} = \\begin{cases}\n\\frac{1}{d}\\frac{g(y)}{\\sum_{z \\in \\Theta: z \\sim_j x} g(z) } & x \\sim_j y \\\\\n0 & \\text{otherwise}\n\\end{cases}\n </math>\n\nSo\n:<math>\ng(x) p_{xy} = \\frac{1}{d}\\frac{ g(x) g(y)}{\\sum_{z \\in \\Theta: z \\sim_j x} g(z) }\n= \\frac{1}{d}\\frac{ g(y) g(x)}{\\sum_{z \\in \\Theta: z \\sim_j y} g(z) }\n= g(y) p_{yx}\n</math>\n\nsince <math>x \\sim_j y</math> is an [[equivalence relation]]. Thus the [[detailed balance equations]] are satisfied, implying the chain is reversible and it has invariant distribution <math>\\left.g\\right.</math>.\n\nIn practice, the index <math>\\left.j\\right.</math> is not chosen at random, and the chain cycles through the indexes in order. In general this gives a non-stationary Markov process, but each individual step will still be reversible, and the overall process will still have the desired stationary distribution (as long as the chain can access all states under the fixed ordering).\n\n== Variations and extensions ==\n\nNumerous variations of the basic Gibbs sampler exist.  The goal of these variations is to reduce the [[autocorrelation]] between samples sufficiently to overcome any added computational costs.\n\n=== Blocked Gibbs sampler ===\n*A '''blocked Gibbs sampler''' groups two or more variables together and samples from their [[joint distribution]] conditioned on all other variables, rather than sampling from each one individually.  For example, in a [[hidden Markov model]], a blocked Gibbs sampler might sample from all the [[latent variable]]s making up the [[Markov chain]] in one go, using the [[forward-backward algorithm]].\n\n=== Collapsed Gibbs sampler ===\n*A '''collapsed Gibbs sampler''' integrates out ([[marginal distribution|marginalizes over]]) one or more variables when sampling for some other variable.  For example, imagine that a model consists of three variables ''A'', ''B'', and ''C''.  A simple Gibbs sampler would sample from ''p''(''A''&nbsp;|&nbsp;''B'',''C''), then ''p''(''B''&nbsp;|&nbsp;''A'',''C''), then ''p''(''C''&nbsp;|&nbsp;''A'',''B'').  A collapsed Gibbs sampler might replace the sampling step for ''A'' with a sample taken from the marginal distribution ''p''(''A''&nbsp;|&nbsp;''C''), with variable ''B'' integrated out in this case.  Alternatively, variable ''B'' could be collapsed out entirely, alternately sampling from ''p''(''A''&nbsp;|&nbsp;''C'') and ''p''(''C''&nbsp;|&nbsp;''A'') and not sampling over ''B'' at all.  The distribution over a variable ''A'' that arises when collapsing a parent variable ''B'' is called a [[compound distribution]]; sampling from this distribution is generally tractable when ''B'' is the [[conjugate prior]] for ''A'', particularly when ''A'' and ''B'' are members of the [[exponential family]].  For more information, see the article on [[compound distribution]]s or Liu (1994).<ref>{{cite journal\n| last        = Liu\n| first       = Jun S.\n|date=September 1994\n| title       = The Collapsed Gibbs Sampler in Bayesian Computations with Applications to a Gene Regulation Problem\n| jstor        = 2290921\n| journal     = Journal of the American Statistical Association\n| volume      = 89\n| issue       = 427\n| pages       = 958–966\n| doi         = 10.2307/2290921\n}}</ref>\n\n==== Implementing a collapsed Gibbs sampler ====\n\n===== Collapsing Dirichlet distributions =====\n\nIn [[hierarchical Bayesian model]]s with [[categorical distribution|categorical variable]]s, such as [[latent Dirichlet allocation]] and various other models used in [[natural language processing]], it is quite common to collapse out the [[Dirichlet distribution]]s that are typically used as [[prior distribution]]s over the categorical variables.  The result of this collapsing introduces dependencies among all the categorical variables dependent on a given Dirichlet prior, and the joint distribution of these variables after collapsing is a [[Dirichlet-multinomial distribution]].  The conditional distribution of a given categorical variable in this distribution, conditioned on the others, assumes an extremely simple form that makes Gibbs sampling even easier than if the collapsing had not been done.  The rules are as follows:\n#Collapsing out a Dirichlet prior node affects only the parent and children nodes of the prior.  Since the parent is often a constant, it is typically only the children that we need to worry about.\n#Collapsing out a Dirichlet prior introduces dependencies among all the categorical children dependent on that prior — but ''no'' extra dependencies among any other categorical children. (This is important to keep in mind, for example, when there are multiple Dirichlet priors related by the same hyperprior.  Each Dirichlet prior can be independently collapsed and affects only its direct children.)\n#After collapsing, the conditional distribution of one dependent children on the others assumes a very simple form: The probability of seeing a given value is proportional to the sum of the corresponding hyperprior for this value, and the count of all of the ''other dependent nodes'' assuming the same value.  Nodes not dependent on the same prior '''must not''' be counted.  Note that the same rule applies in other iterative inference methods, such as [[variational Bayes]] or [[expectation maximization]]; however, if the method involves keeping partial counts, then the partial counts for the value in question must be summed across all the other dependent nodes.  Sometimes this summed up partial count is termed the ''expected count'' or similar.  Note also that the probability is ''proportional to'' the resulting value; the actual probability must be determined by normalizing across all the possible values that the categorical variable can take (i.e. adding up the computed result for each possible value of the categorical variable, and dividing all the computed results by this sum).\n#If a given categorical node has dependent children (e.g. when it is a [[latent variable]] in a [[mixture model]]), the value computed in the previous step (expected count plus prior, or whatever is computed) must be multiplied by the actual conditional probabilities (''not'' a computed value that is proportional to the probability!) of all children given their parents.  See the article on the [[Dirichlet-multinomial distribution]] for a detailed discussion.\n#In the case where the group membership of the nodes dependent on a given Dirichlet prior may change dynamically depending on some other variable (e.g. a categorical variable indexed by another latent categorical variable, as in a [[topic model]]), the same expected counts are still computed, but need to be done carefully so that the correct set of variables is included.   See the article on the [[Dirichlet-multinomial distribution]] for more discussion, including in the context of a topic model.\n\n===== Collapsing other conjugate priors =====\n\nIn general, any conjugate prior can be collapsed out, if its only children have distributions conjugate to it.  The relevant math is discussed in the article on [[compound distribution]]s.  If there is only one child node, the result will often assume a known distribution.  For example, collapsing an [[inverse gamma distribution|inverse-gamma-distributed]] [[variance]] out of a network with a single [[Gaussian distribution|Gaussian]] child will yield a [[Student's t-distribution]]. (For that matter, collapsing both the mean and variance of a single Gaussian child will still yield a Student's t-distribution, provided both are conjugate, i.e. Gaussian mean, inverse-gamma variance.)\n\nIf there are multiple child nodes, they will all become dependent, as in the [[Dirichlet distribution|Dirichlet]]-[[categorical distribution|categorical]] case.  The resulting [[joint distribution]] will have a closed form that resembles in some ways the compound distribution, although it will have a product of a number of factors, one for each child node, in it.\n\nIn addition, and most importantly, the resulting [[conditional distribution]] of one of the child nodes given the others (and also given the parents of the collapsed node(s), but ''not'' given the children of the child nodes) will have the same density as the [[posterior predictive distribution]] of all the remaining child nodes.  Furthermore, the posterior predictive distribution has the same density as the basic compound distribution of a single node, although with different parameters.  The general formula is given in the article on [[compound distribution]]s.\n\nFor example, given a Bayes network with a set of conditionally [[independent identically distributed]] [[Gaussian distribution|Gaussian-distributed]] nodes with [[conjugate prior]] distributions placed on the mean and variance, the conditional distribution of one node given the others after compounding out both the mean and variance will be a [[Student's t-distribution]].  Similarly, the result of compounding out the [[gamma distribution|gamma]] prior of a number of [[Poisson distribution|Poisson-distributed]] nodes causes the conditional distribution of one node given the others to assume a [[negative binomial distribution]].\n\nIn these cases where compounding produces a well-known distribution, efficient sampling procedures often exist, and using them will often (although not necessarily) be more efficient than not collapsing, and instead sampling both prior and child nodes separately. However, in the case where the compound distribution is not well-known, it may not be easy to sample from, since it generally will not belong to the [[exponential family]] and typically will not be [[Logarithmically concave function|log-concave]] (which would make it easy to sample using [[adaptive rejection sampling]], since a closed form always exists).\n\nIn the case where the child nodes of the collapsed nodes themselves have children, the conditional distribution of one of these child nodes given all other nodes in the graph will have to take into account the distribution of these second-level children.  In particular, the resulting conditional distribution will be proportional to a product of the compound distribution as defined above, and the conditional distributions of all of the child nodes given their parents (but not given their own children).  This follows from the fact that the full conditional distribution is proportional to the joint distribution.  If the child nodes of the collapsed nodes are [[continuous distribution|continuous]], this distribution will generally not be of a known form, and may well be difficult to sample from despite the fact that a closed form can be written, for the same reasons as described above for non-well-known compound distributions.  However, in the particular case that the child nodes are [[discrete distribution|discrete]], sampling is feasible, regardless of whether the children of these child nodes are continuous or discrete.  In fact, the principle involved here is described in fair detail in the article on the [[Dirichlet-multinomial distribution]].\n\n=== Gibbs sampler with ordered overrelaxation ===\n*A Gibbs sampler with '''ordered overrelaxation''' samples a given odd number of candidate values for <math>x_j^{(i)}</math> at any given step and sorts them, along with the single value for <math>x_j^{(i-1)}</math> according to some well-defined ordering.  If <math>x_j^{(i-1)}</math> is the ''s''<sup>th</sup> smallest in the sorted list then the <math>x_j^{(i)}</math> is selected as the ''s''<sup>th</sup> largest in the sorted list.  For more information, see Neal (1995).<ref>{{cite techreport\n| first       = Radford M.\n| last        = Neal\n| title       = Suppressing Random Walks in Markov Chain Monte Carlo Using Ordered Overrelaxation\n| institution = University of Toronto, Department of Statistics\n| year        = 1995\n| arxiv       = bayes-an/9506004\n| bibcode= 1995bayes.an..6004N\n}}</ref>\n\n=== Samplers-within-Gibbs and other extensions ===\nIt is also possible to extend Gibbs sampling in various ways.  For example, in the case of variables whose conditional distribution is not easy to sample from, a single iteration of [[slice sampling]] or the [[Metropolis–Hastings algorithm]] can be used to sample from the variables in question. A more efficient alternative is the application of the [[adaptive rejection sampling]] (ARS) methods for sampling from the full-conditional densities.<ref>{{Cite journal|title = Adaptive Rejection Sampling for Gibbs Sampling|jstor = 2347565|journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1992-01-01|pages = 337–348|volume = 41|issue = 2|doi = 10.2307/2347565|first = W. R.|last = Gilks|first2 = P.|last2 = Wild}}</ref><ref>{{Cite journal|title = A Rejection Technique for Sampling from T-concave Distributions|journal = ACM Trans. Math. Softw.|date = 1995-06-01|issn = 0098-3500|pages = 182–193|volume = 21|issue = 2|doi = 10.1145/203082.203089|first = Wolfgang|last = Hörmann|citeseerx = 10.1.1.56.6055}}</ref><ref>{{Cite journal|title = A generalization of the adaptive rejection sampling algorithm|journal = Statistics and Computing|date = 2010-08-25|issn = 0960-3174|pages = 633–647|volume = 21|issue = 4|doi = 10.1007/s11222-010-9197-9|first = Luca|last = Martino|first2 = Joaquín|last2 = Míguez|hdl = 10016/16624}}</ref><ref>{{Cite journal|title = Random Variable Generation Using Concavity Properties of Transformed Densities|jstor = 1390680|journal = Journal of Computational and Graphical Statistics|date = 1998-12-01|pages = 514–528|volume = 7|issue = 4|doi = 10.2307/1390680|first = M.|last = Evans|first2 = T.|last2 = Swartz|citeseerx = 10.1.1.53.9001}}</ref><ref>{{Cite journal|title = Concave-Convex Adaptive Rejection Sampling|journal = Journal of Computational and Graphical Statistics|date = 2011-01-01|issn = 1061-8600|pages = 670–691|volume = 20|issue = 3|doi = 10.1198/jcgs.2011.09058|first = Dilan|last = Görür|first2 = Yee Whye|last2 = Teh}}</ref> When the ARS techniques cannot be applied, the '''adaptive rejection Metropolis sampling algorithms''' are often employed.<ref name=\":1\"/><ref name=\":2\"/><ref name=\":0\"/> Furthermore, other alternatives can be found in literature.<ref>{{Cite journal|title = Facilitating the Gibbs Sampler: The Gibbs Stopper and the Griddy–Gibbs Sampler|journal = Journal of the American Statistical Association|date = 1992-09-01|issn = 0162-1459|pages = 861–868|volume = 87|issue = 419|doi = 10.1080/01621459.1992.10475289|first = Christian|last = Ritter|first2 = Martin A.|last2 = Tanner}}</ref><ref>{{Cite journal|title = A fast universal self-tuned sampler within Gibbs sampling|journal = Digital Signal Processing|date = 2015-12-01|pages = 68–83|volume = 47|series = Special Issue in Honour of William J. (Bill) Fitzgerald|doi = 10.1016/j.dsp.2015.04.005|first = L.|last = Martino|first2 = H.|last2 = Yang|first3 = D.|last3 = Luengo|first4 = J.|last4 = Kanniainen|first5 = J.|last5 = Corander}}</ref> The auxiliary samples generated by the internal sampler (such as the MH and ARMS schemes) can be recycled within the final Gibbs estimators, improving their efficiency with no extra cost (the so-called Recycling Gibbs sampling procedure <ref>{{Cite journal|last=Martino|first=Luca|last2=Elvira|first2=Víctor|last3=Camps-Valls|first3=Gustau|title=The Recycling Gibbs sampler for efficient learning|journal=Digital Signal Processing|volume=74|pages=1–13|doi=10.1016/j.dsp.2017.11.012|arxiv=1611.07056|year=2018}}</ref>).\n\nIt is also possible to incorporate variables that are not [[random variables]], but whose value is [[deterministically]] computed from other variables.  [[Generalized linear models]], e.g. [[logistic regression]] (aka \"[[maximum entropy classifier|maximum entropy]] models\"), can be incorporated in this fashion. (BUGS, for example, allows this type of mixing of models.)\n\n== Failure modes ==\n\nThere are two ways that Gibbs sampling can fail.  The first is when there are islands of high-probability states, with no paths between them.  For example, consider a probability distribution  over 2-bit vectors, where the vectors (0,0) and (1,1) each have probability ½, but the other two vectors (0,1) and (1,0) have probability zero.  Gibbs sampling will become trapped in one of the two high-probability vectors, and will never reach the other one.  More generally, for any distribution over high-dimensional, real-valued vectors, if two particular elements of the vector are perfectly correlated (or perfectly anti-correlated), those two elements will become stuck, and Gibbs sampling will never be able to change them.\n\nThe second problem can happen even when all states have nonzero probability and there is only a single island of high-probability states.  For example, consider a probability distribution over 100-bit vectors, where the all-zeros vector occurs with probability ½, and all other vectors are equally probable, and so have a probability of <math>\\frac{1}{2(2^{100}-1)}</math> each.  If you want to estimate the probability of the zero vector, it would be sufficient to take 100 or 1000 samples from the true distribution.  That would very likely give an answer very close to ½.  But you would probably have to take more than <math>2^{100}</math> samples from Gibbs sampling to get the same result.  No computer could do this in a lifetime.\n\nThis problem occurs no matter how long the burn-in period is.  This is because in the true distribution, the zero vector occurs half the time, and those occurrences are randomly mixed in with the nonzero vectors.  Even a small sample will see both zero and nonzero vectors.  But Gibbs sampling will alternate between returning only the zero vector for long periods (about <math>2^{99}</math> in a row), then only nonzero vectors for long periods (about <math>2^{99}</math> in a row).  Thus convergence to the true distribution is extremely slow, requiring much more than <math>2^{99}</math> steps; taking this many steps is not computationally feasible in a reasonable time period. The slow convergence here can be seen as a consequence of the [[curse of dimensionality]].\n\nNote that a problem like this can be solved by block sampling the entire 100-bit vector at once. (This assumes that the 100-bit vector is part of a larger set of variables.  If this vector is the only thing being sampled, then block sampling is equivalent to not doing Gibbs sampling at all, which by hypothesis would be difficult.)\n\n== Software ==\nThe [[OpenBUGS]] software (''Bayesian inference Using Gibbs Sampling'') does a [[Bayesian analysis]] of complex statistical models using [[Markov chain Monte Carlo]].\n\n[[Just another Gibbs sampler|JAGS]] (''Just another Gibbs sampler'') is a GPL program for analysis of Bayesian hierarchical models using Markov Chain Monte Carlo.\n\n[[Church (programming language)|Church]] is free software for performing Gibbs inference over arbitrary distributions that are specified as probabilistic programs.\n\n[[PyMC3]] is an open source [[Python (programming language)|Python]] library for [[Bayesian learning]] of general [[Graphical model|Probabilistic Graphical Model]] with advanced features and easy to use interface.<ref>{{Cite web|url=https://github.com/pymc-devs/pymc3|title=PyMC3 on GitHub|last=|first=|date=2019-01-29|website=|publisher=|archive-url=|archive-date=|dead-url=|accessdate=}}</ref>\n\n[http://a2rms.sourceforge.net IA2RMS] is a Matlab code of the ''Independent Doubly Adaptive Rejection Metropolis Sampling'' method for drawing from the full-conditional densities.<ref name=\":0\" />\n\n[https://turing.ml/ Turing] is a [[Julia (programming language)|Julia]] package that allows multiple sampler types to be run as components of Gibbs sampling.\n\n== Notes ==\n{{Reflist|30em}}\n\n== References ==\n* {{Citation\n  | last1 = Bishop   | first1 = Christopher M.\n  | title = Pattern Recognition and Machine Learning\n  | year = 2006\n  | publisher = Springer\n  | ref = CITEREFBishop2006\n  | isbn = 978-0-387-31073-2\n  }}\n* Bolstad, William M. (2010), ''Understanding Computational Bayesian Statistics'', John Wiley {{ISBN|978-0-470-04609-8}}\n* {{Cite journal | doi = 10.2307/2685208| jstor = 2685208| title = Explaining the Gibbs Sampler| journal = The American Statistician| volume = 46| issue = 3| pages = 167| year = 1992| last1 = Casella | first1 = G. | last2 = George | first2 = E. I. | citeseerx = 10.1.1.554.3993}} (Contains a basic summary and many references.)\n* {{Citation\n |first1=Alan E. |last1=Gelfand\n |first2=Adrian F. M. |last2=Smith\n |title=Sampling-Based Approaches to Calculating Marginal Densities\n |journal=[[Journal of the American Statistical Association]]\n |volume=85 |issue=410 |pages=398–409 |year=1990\n |mr=1141740 |doi=10.2307/2289776\n |jstor=2289776\n}}\n* [[Andrew Gelman|Gelman, A.]], Carlin J. B., Stern H. S., Dunson D., Vehtari A., Rubin D. B. (2013), ''Bayesian Data Analysis'', third edition. London: [[Chapman & Hall]].\n* Levin, David A.; Peres, Yuval; Wilmer, Elizabeth L. (2008), \"[http://www.uoregon.edu/~dlevin/MARKOV/ Markov Chains and Mixing Times]\", [[American Mathematical Society]].\n* Robert, C. P.; Casella, G. (2004), ''Monte Carlo Statistical Methods'' (second edition), Springer-Verlag.\n\n== External links ==\n* [http://www.openbugs.net/ The OpenBUGS Project] — Bayesian inference Using Gibbs Sampling\n* [http://ccmbweb.ccv.brown.edu/gibbs/gibbs.html A practical application of Gibbs sampling in genomics]\n* [https://github.com/pymc-devs/pymc PyMC] — Markov Chain Monte Carlo in Python\n* [http://a2rms.sourceforge.net IA2RMS] is a Matlab code of the ''Independent Doubly Adaptive Rejection Metropolis Sampler'' for drawing from the full-conditional densities.\n\n[[Category:Markov chain Monte Carlo]]"
    },
    {
      "title": "Slice sampling",
      "url": "https://en.wikipedia.org/wiki/Slice_sampling",
      "text": "'''Slice sampling''' is a type of [[Markov chain Monte Carlo]] [[algorithm]] for [[pseudo-random number sampling]], i.e. for drawing random samples from a statistical distribution. The method is based on the observation that to sample a [[random variable]] one can sample uniformly from the region under the graph of its density function.<ref>Damlen, P., Wakefield, J., & Walker, S. (1999). Gibbs sampling for Bayesian non‐conjugate and hierarchical models by using auxiliary variables. Journal of the Royal Statistical Society, Series B (Statistical Methodology), 61(2), 331-344.Chicago</ref><ref name=\"radford03\">{{cite journal\n |first=Radford M. |last=Neal\n |title=Slice Sampling\n |journal=[[Annals of Statistics]]\n |volume=31 |issue=3 |pages=705–767 |year=2003\n |doi=10.1214/aos/1056562461\n |mr=1994729 | zbl = 1051.65007\n}}</ref><ref name=\"bishop06\">{{cite book\n  | last = Bishop\n  | first = Christopher\n  | title = Pattern Recognition and Machine Learning\n  | publisher = [[Springer Science+Business Media|Springer]]\n  | year = 2006\n  | chapter = 11.4: Slice sampling\n  | isbn = 978-0387310732\n}}</ref>\n\n==Motivation==\nSuppose you want to sample some random variable ''X'' with distribution f(x). Suppose that the following is the graph of f(x). The height of f(x) corresponds to the likelihood at that point.\n\n[[File:Some probability distribution.png|350px|alt=alt text]]\n\nIf you were to uniformly sample ''X'', each value would have the same likelihood of being sampled, and your distribution would be of the form f(x)=y for some ''y'' value instead of some non-uniform function f(x). Instead of the original black line, your new distribution would look more like the blue line.\n\n[[File:A horizontally sliced distribution.png|350px|alt=alt text]]\n\nIn order to sample ''X'' in a manner which will retain the distribution f(x), some sampling technique must be used which takes into account the varied likelihoods for each range of f(x).\n\n==Method==\nSlice sampling, in its simplest form, samples uniformly from underneath the curve f(x) without the need to reject any points, as follows:\n#Choose a starting value x<sub>0</sub> for which f(x<sub>0</sub>)>0.\n#Sample a y value uniformly between 0 and f(x<sub>0</sub>).\n#Draw a horizontal line across the curve at this y position.\n#Sample a point (x,y) from the line segments within the curve.\n#Repeat from step 2 using the new x value.\n\nThe motivation here is that one way to sample a point uniformly from within an arbitrary curve is first to draw thin uniform-height horizontal slices across the whole curve.  Then, we can sample a point within the curve by randomly selecting a slice that falls at or below the curve at the x-position from the previous iteration, then randomly picking an x-position somewhere along the slice. By using the x-position from the previous iteration of the algorithm, in the long run we select slices with probabilities proportional to the lengths of their segments within the curve.\n\nGenerally, the trickiest part of this algorithm is finding the bounds of the horizontal slice, which involves inverting the function describing the distribution being sampled from.  This is especially problematic for multi-modal distributions, where the slice may consist of multiple discontiguous parts.  It is often possible to use a form of rejection sampling to overcome this, where we sample from a larger slice that is known to include the desired slice in question, and then discard points outside of the desired slice.\n\nNote also that this algorithm can be used to sample from the area under ''any'' curve, regardless of whether the function integrates to 1.  In fact, scaling a function by a constant has no effect on the sampled x-positions.  This means that the algorithm can be used to sample from a distribution whose [[probability density function]] is only known up to a constant (i.e. whose [[normalizing constant]] is unknown), which is common in [[computational statistics]].\n\n==Implementation==\n\nSlice sampling gets its name from the first step: defining a ''slice'' by sampling from an auxiliary variable <math>Y</math>. This variable is sampled from <math>[0, f(x)]</math>, where <math>f(x)</math> is either the probability density function (pdf) of ''X'' or is at least proportional to its pdf. This defines a slice of ''X'' where <math>f(x) \\ge Y</math>. In other words, we are now looking at a region of ''X'' where the probability density is at least <math>Y</math>. Then the next value of ''X'' is sampled uniformly from this slice. A new value of <math>Y</math> is sampled, then ''X'', and so on. This can be visualized as alternatively sampling the y-position and then the x-position of points under pdf, thus the ''X''s are from the desired distribution. The <math>Y</math> values have no particular consequences or interpretations outside of their usefulness for the procedure.\n\nIf both the pdf and its inverse are available, and the distribution is unimodal, then finding the slice and sampling from it are simple. If not, a stepping-out procedure can be used to find a region whose endpoints fall outside the slice. Then, a sample can be drawn from the slice using [[rejection sampling]]. Various procedures for this are described in detail by Neal.<ref name=\"radford03\"/>\n\nNote that, in contrast to many available methods for generating random numbers from non-uniform distributions, random variates generated directly by this approach will exhibit serial statistical dependence. This is because to draw the next sample, we define the slice based on the value of f(x) for the current sample.\n\n==Compared to Other Methods==\nSlice sampling is a Markov chain method and as such serves the same purpose as Gibbs sampling and Metropolis. Unlike Metropolis, there is no need to manually tune the candidate function or candidate standard deviation.\n\nRecall that Metropolis is sensitive to step size. If the step size is too small [[random walk]] causes slow decorrelation. If the step size is too large there is great inefficiency due to a high rejection rate.\n\nIn contrast to Metropolis, slice sampling automatically adjusts the step size to match the local shape of the density function. Implementation is arguably easier and more efficient than Gibbs sampling or simple Metropolis updates.\n\nNote that, in contrast to many available methods for generating random numbers from non-uniform distributions, random variates generated directly by this approach will exhibit serial statistical dependence. In other words, not all points have the same independent likelihood of selection. This is because to draw the next sample, we define the slice based on the value of f(x) for the current sample. However, the generated samples are [[Markov property|markovian]], and are therefore expected to converge to the correct distribution in long run.\n\nSlice Sampling requires that the distribution to be sampled be evaluable. One way to relax this requirement is to substitute an evaluable distribution which is proportional to the true unevaluable distribution.\n\n==Univariate Case==\n[[File:A horizontally and vertically sliced distribution.png|thumb|350px|alt=alt text|For a given sample x, a value for y is chosen from [0, f(x)], which defines a \"slice\" of the distribution (shown by the solid horizontal line). In this case, there are two slices separated by an area outside the range of the distribution.]]\nTo sample a random variable ''X'' with density f(x) we introduce an auxiliary variable ''Y'' and iterate as follows:\n\n*Given a sample ''x'' we choose ''y'' uniformly at random from the interval [0, f(x)];\n*given ''y'' we choose ''x'' uniformly at random from the set <math>f^{-1}[y, +\\infty)</math>.\n*The sample of ''x'' is obtained by ignoring the ''y'' values.\n\nOur auxiliary variable ''Y'' represents a horizontal \"slice\" of the distribution. The rest of each iteration is dedicated to sampling an ''x'' value from the slice which is representative of the density of the region being considered.\n\nIn practice, sampling from a horizontal slice of a multimodal distribution is difficult. There is a tension between obtaining a large sampling region and thereby making possible large moves in the distribution space, and obtaining a simpler sampling region to increase efficiency. One option for simplifying this process is regional expansion and contraction.\n\n*First, a width parameter ''w'' is used to define the area containing the given 'x'' value. Each endpoint of this area is tested to see if it lies outside the given slice. If not, the region is extended in the appropriate direction(s) by ''w'' until the end both endpoints lie outside the slice.\n*A candidate sample is selected uniformly from within this region. If the candidate sample lies inside of the slice, then it is accepted as the new sample. If it lies outside of the slice, the candidate point becomes the new boundary for the region. A new candidate sample is taken uniformly. The process repeats until the candidate sample is within the slice. (See diagram for a visual example).\n\n[[Image:summary of slice sampling.png|thumb|center|500px|alt=alt text|Finding a sample given a set of slices (the slices are represented here as blue lines and correspond to the solid line slices in the previous graph of f(x) ). a) A width parameter ''w'' is set. b) A region of width ''w'' is identified around a given point <math>x_0</math>. c) The region is expanded by ''w'' until both endpoints are outside of the considered slice. d) <math>x_1</math> is selected uniformly from the region. e) Since <math>x_1</math> lies outside the considered slice, the region's left bound is adjusted to <math>x_1</math>. f) Another uniform sample <math>x</math> is taken and accepted as the sample since it lies within the considered slice.]]→\n\n== Slice-within-Gibbs sampling ==\nIn a [[Gibbs sampling|Gibbs sampler]], one needs to draw efficiently from all the full-conditional distributions. When sampling from a full-conditional density is not easy, a single iteration of slice sampling or the Metropolis-Hastings algorithm can be used within-Gibbs to sample from the variable in question. If the full-conditional density is log-concave, a more efficient alternative is the application of [[Rejection sampling|adaptive rejection sampling]] (ARS) methods.<ref>{{Cite journal|title = Adaptive Rejection Sampling for Gibbs Sampling|jstor = 2347565|journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1992-01-01|pages = 337–348|volume = 41|issue = 2|doi = 10.2307/2347565|first = W. R.|last = Gilks|first2 = P.|last2 = Wild}}</ref><ref>{{Cite journal|title = A Rejection Technique for Sampling from T-concave Distributions|journal = ACM Trans. Math. Softw.|date = 1995-06-01|issn = 0098-3500|pages = 182–193|volume = 21|issue = 2|doi = 10.1145/203082.203089|first = Wolfgang|last = Hörmann|citeseerx = 10.1.1.56.6055}}</ref><ref>{{Cite journal|title = A generalization of the adaptive rejection sampling algorithm|journal = Statistics and Computing|date = 2010-08-25|issn = 0960-3174|pages = 633–647|volume = 21|issue = 4|doi = 10.1007/s11222-010-9197-9|first = Luca|last = Martino|first2 = Joaquín|last2 = Míguez|hdl = 10016/16624}}</ref> When the ARS techniques cannot be applied (since the full-conditional is non-log-concave), the '''adaptive rejection Metropolis sampling algorithms''' are often employed.<ref>{{Cite journal|title = Adaptive Rejection Metropolis Sampling within Gibbs Sampling|jstor = 2986138|journal = Journal of the Royal Statistical Society. Series C (Applied Statistics)|date = 1995-01-01|pages = 455–472|volume = 44|issue = 4|doi = 10.2307/2986138|first = W. R.|last = Gilks|first2 = N. G.|last2 = Best|first3 = K. K. C.|last3 = Tan}}</ref><ref>{{Cite journal|title = Adaptive rejection Metropolis sampling using Lagrange interpolation polynomials of degree 2|journal = Computational Statistics & Data Analysis|date = 2008-03-15|pages = 3408–3423|volume = 52|issue = 7|doi = 10.1016/j.csda.2008.01.005|first = Renate|last = Meyer|first2 = Bo|last2 = Cai|first3 = François|last3 = Perron}}</ref><ref>{{Cite journal|title = Independent Doubly Adaptive Rejection Metropolis Sampling Within Gibbs Sampling|journal = IEEE Transactions on Signal Processing|date = 2015-06-01|issn = 1053-587X|pages = 3123–3138|volume = 63|issue = 12|doi = 10.1109/TSP.2015.2420537|first = L.|last = Martino|first2 = J.|last2 = Read|first3 = D.|last3 = Luengo|arxiv = 1205.5494}}</ref>\n\n==Multivariate Methods==\n\n===Treating each variable independently===\nSingle variable slice sampling can be used in the multivariate case by sampling each variable in turn repeatedly, as in Gibbs sampling. To do so requires that we can compute, for each component <math>x_i</math> a function that is proportional to <math>p(x_i|x_0...x_n)</math>.\n\nTo prevent random walk behavior, overrelaxation methods can be used to update each variable in turn.{{Citation needed|date=July 2016}} Overrelaxation chooses a new value on the opposite side of the mode from the current value, as opposed to choosing a new independent value from the distribution as done in Gibbs.\n\n===Hyperrectangle slice sampling===\nThis method adapts the univariate algorithm to the multivariate case by substituting a hyperrectangle for the one-dimensional ''w'' region used in the original. The hyperrectangle ''H'' is initialized to a random position over the slice. ''H'' is then shrunken as points from it are rejected.\n\n===Reflective slice sampling===\nReflective slice sampling is a technique to suppress random walk behavior in which the successive candidate samples of distribution f(x) are kept within the bounds of the slice by \"reflecting\" the direction of sampling inward toward the slice once the boundary has been hit.\n\nIn this graphical representation of reflective sampling, the shape indicates the bounds of a sampling slice. The dots indicate start and stopping points of a sampling walk. When the samples hit the bounds of the slice, the direction of sampling is \"reflected\" back into the slice.\n\n[[File:An example of reflection sampling.png|350px|alt=alt text]]\n\n==Example==\nConsider a single variable example. Suppose our true distribution is a [[normal distribution]] with mean 0 and standard deviation 3, <math>g(x)\\sim N(0,3^2)</math>. So:\n<math>f(x) = \\frac{1}{\\sqrt{2\\pi \\cdot3^2}}  \\ e^{ -\\frac{(x-0)^2}{2 \\cdot 3^2} }</math>. The peak of the distribution is obviously at <math>x = 0</math>, at which point <math>f(x)\\approx0.1330</math>.\n\n#We first draw a uniform random value ''y'' from the range of f(x) in order to define our slice(es). f(x) ranges from 0 to ~0.1330, so any value between these two extremes suffice. Suppose we take ''y'' = 0.1. The problem becomes how to sample points that have values ''y'' > 0.1.\n#Next, we set our width parameter ''w'' which we will use to expand our region of consideration. This value is arbitrary. Suppose ''w'' = 2.\n#Next, we need an initial value for ''x''. We draw ''x'' from the uniform distribution within the domain of f(x) which satisfies f(x) > 0.1 (our ''y'' parameter). Suppose ''x'' = 2. This works because f(2) = ~0.1065 > 0.1.<ref>Note that if we didn't know how to select ''x'' such that f(x) > ''y'', we can still pick any random value for ''x'', evaluate f(x), and use that as our value of ''y''. ''y'' only initializes the algorithm; as the algorithm progresses it will find higher and higher values of ''y''.</ref>\n#Because ''x'' = 2 and ''w'' = 2, our current region of interest is bounded by (1, 3).\n#Now, each endpoint of this area is tested to see if it lies outside the given slice. Our right bound lies outside our slice (f(3) = ~0.0807 < 0.1), but the left value does not (f(1) = ~0.1258 > 0.1). We expand the left bound by adding ''w'' to it until it extends past the limit of the slice. After this process, the new bounds of our region of interest are (-3,3).\n#Next, we take a uniform sample within (-3,3). Suppose this sample yields x = -2.9. Though this sample is within our region of interest, it does not lie within our slice (f(2.9) = ~0.08334 < 0.1), so we modify the left bound of our region of interest to this point. Now we take a uniform sample from (-2.9, 3). Suppose this time our sample yields x = 1, which is within our slice, and thus is the accepted sample output by slice sampling. Had our new ''x'' not been within our slice, we would continue the shrinking/resampling process until a valid ''x'' within bounds is found.\n\nIf we're interested in the peak of the distribution, we can keep repeating this process since the new point corresponds to a higher f(x) than the original point.\n\n==Another Example==\n\nTo sample from the [[normal distribution]] <math>N(0,1)</math> we first choose an initial ''x''—say 0. After each sample of ''x'' we choose ''y'' uniformly at random from <math>(0, e^{-x^2/2}/\\sqrt{2\\pi}]</math>, which is bounded the pdf of <math>N(0,1)</math>. After each ''y'' sample we choose ''x'' uniformly at random from <math>[-\\alpha, \\alpha]</math> where <math>\\alpha = \\sqrt{-2\\ln(y\\sqrt{2\\pi})}</math>. This is the slice where <math>f(x) > y</math>.\n\nAn implementation in the [[Macsyma]] language is:\n\n<source lang=\"smalltalk\">\nslice(x):=block([y,alpha],\n y:random( exp(-x^2/2.0)/sqrt(2.0*dfloat(%pi))),\n alpha:sqrt(-2.0*ln(y*sqrt(2.0*dfloat(%pi)))),\n x:signum(random())*random(alpha)\n);\n</source>\n\n==See also==\n\n* [[Markov chain Monte Carlo]]\n\n==References==\n\n<references/>\n\n==External links==\n* http://www.probability.ca/jeff/java/slice.html\n\n[[Category:Markov chain Monte Carlo]]\n[[Category:Non-uniform random numbers]]"
    },
    {
      "title": "Wang and Landau algorithm",
      "url": "https://en.wikipedia.org/wiki/Wang_and_Landau_algorithm",
      "text": "The '''Wang and Landau algorithm''', proposed by  Fugao Wang and [[David P. Landau]],<ref name=WangLandau/> is a [[Monte Carlo method]] designed to [[estimator|estimate]] the [[density of states]] of a system. The method performs a non-Markovian [[random walk]] to build the density of states by quickly visiting all the available energy spectrum. The Wang and Landau algorithm is an important method to obtain the density of states required to perform a [[multicanonical ensemble|multicanonical simulation]].\n\nThe Wang–Landau algorithm can be applied to any system which is characterized by a cost (or energy) function. For instance,\nit has been applied to the solution of numerical integrals<ref name=Belardinelli_Integrals/> and the folding of proteins.<ref name=Ojeda1/><ref name=Ojeda2/>\nThe Wang–Landau sampling is related to the [[metadynamics]] algorithm.<ref>Christoph Junghans, Danny Perez, and Thomas Vogel. \"Molecular Dynamics in the Multicanonical Ensemble: Equivalence of Wang–Landau Sampling, Statistical Temperature Molecular Dynamics, and Metadynamics.\" Journal of Chemical Theory and Computation 10.5 (2014): 1843-1847. [[Digital_object_identifier|doi]]:[https://dx.doi.org/10.1021/ct500077d 10.1021/ct500077d]</ref>\n\n==Overview==\n\nThe Wang and Landau algorithm is used to obtain an [[Estimator|estimate]] for the [[density of states]] of a system characterized by a cost function. It uses a non-Markovian [[stochastic process]] which asymptotically converges to a [[multicanonical ensemble]].<ref name=WangLandau/> (I.e. to a [[Metropolis–Hastings algorithm]] with sampling distribution inverse to the density of states.) The major consequence is that this sampling distribution leads to a simulation where the energy barriers are invisible. This means that the algorithm visits all the accessible states (favorable and less favorable) much faster than a Metropolis algorithm.<ref name=Berg/>\n\n==Algorithm==\n\nConsider a system defined on a phase space <math>\\Omega</math>, and a cost function, E, (e.g. the energy), bounded on a spectrum <math>E\\in\\Gamma = [E_\\min,E_\\max]</math>, which has an associated density of states <math>\\rho(E)</math>, which is to be estimated. The [[estimator]] is <math>\\hat \\rho(E) \\equiv \\exp(S(E))</math>. Because Wang and Landau algorithm works in discrete spectra,<ref name=WangLandau/> the spectrum <math>\\Gamma</math> is divided in N discrete values with a difference between them of <math>\\Delta</math>, such that\n\n:<math> N = \\frac{E_\\max-E_\\min}{\\Delta}</math>.\n\nGiven this discrete spectrum, the algorithm is initialized by:\n\n*setting all entries of the microcanonical entropy to zero, <math>S(E_i) = 0\\ \\ i=1,2,...,N</math>\n*initializing <math>f = 1</math> and\n*initializing the system randomly, by putting in a random configuration <math>\\boldsymbol{r}\\in\\Omega</math>.\n\nThe algorithm then performs a [[multicanonical ensemble]] simulation:<ref name=WangLandau/> a [[Metropolis–Hastings algorithm|Metropolis–Hastings]] random walk in the phase space of the system with a probability distribution given by <math>P(\\boldsymbol{r}) = 1/\\hat{\\rho}(E(\\boldsymbol{r})) = \\exp (-S(E(\\boldsymbol{r})))</math> and a probability of proposing a new state given by a probability distribution <math>g(\\boldsymbol{r} \\rightarrow \\boldsymbol{r}')</math>. A histogram <math>H(E)</math> of visited energies is stored. Like in the Metropolis–Hastings algorithm, a proposal-acceptance step is performed, and consists in (see [[Metropolis–Hastings algorithm#Overview|Metropolis–Hastings algorithm overview]]):\n\n# proposing a state <math>\\boldsymbol{r}'\\in\\Omega</math> according to the arbitrary proposal distribution <math>g(\\boldsymbol{r} \\rightarrow \\boldsymbol{r}')</math>\n# accept/refuse the proposed state according to\n\n:::<math>A(\\boldsymbol{r}\\rightarrow \\boldsymbol{r}') = \\min\\left(1,e^{S - S'}\\frac{g(\\boldsymbol{r}'\\rightarrow \\boldsymbol{r})}{g(\\boldsymbol{r}\\rightarrow \\boldsymbol{r}')}\\right)</math>\n\n:::where <math>S = S(E(\\boldsymbol{r}))</math> and <math>S' = S(E(\\boldsymbol{r}'))</math>.\n\nAfter each proposal-acceptance step, the system transits to some value <math>E_i</math>, <math>H(E_i)</math> is incremented by one and the following update is performed:\n\n:<math> S(E_i) \\leftarrow S(E_i) + f</math>.\n\nThis is the crucial step of the algorithm, and it is what makes the Wang and Landau algorithm non-Markovian: the [[stochastic process]] now depends on the history of the process. Hence the next time there is a proposal to a state with that particular energy <math>E_i</math>, that proposal is now more likely refused; in this sense, the algorithm forces the system to visit all of the spectrum equally.<ref name=WangLandau/> The consequence is that the histogram <math>H(E)</math> is more and more flat. However, this flatness depends on how well-approximated the calculated entropy is to the exact entropy, which naturally depends on the value of f.<ref name=Belardinelli_Saturation/> To better and better approximate the exact entropy (and thus histogram's flatness), f is decreased after M proposal-acceptance steps:\n\n:<math>f \\leftarrow f/2</math>.\n\nIt was later shown that updating the f by constantly dividing by two can lead to saturation errors.<ref name=Belardinelli_Saturation/> A small modification to the Wang and Landau method to avoid this problem is to use the f factor proportional to <math>1/t</math>, where <math>t</math> is proportional to the number of steps of the simulation.<ref name=Belardinelli_Saturation/>\n\n==Test system==\n\nWe want to obtain the DOS for the [[harmonic oscillator]] potential.\n\n:<math> E(x) =  x^2, \\, </math>\n\nThe analytical DOS is given by,\n\n:<math> \\rho(E) = \\int \\delta (E(x)-E) \\, dx= \\int \\delta (x^2-E) \\, dx,</math>\n\nby performing the last integral we obtain\n\n:<math> \\rho(E) \\propto \n\\begin{cases} \nE^{-1/2}, \\text{for } x \\in \\mathbb{R}^1 \\\\\n\\text{const}, \\text{for } x \\in \\mathbb{R}^2 \\\\\nE^{1/2}, \\text{for } x \\in \\mathbb{R}^3 \\\\\n\\end{cases}\n</math>\n\nIn general, the DOS for a multidimensional harmonic oscillator will be given by some power of ''E'', the exponent will be a function of the dimension of the system.\n\nHence, we can use a simple harmonic oscillator potential to test the accuracy of Wang–Landau algorithm because we know already the analytic form of the density of states. Therefore, we compare the estimated density of states <math>\\hat \\rho(E)</math> obtained by the Wang–Landau algorithm with <math>\\rho(E)</math>.\n\n==Sample code==\n\nThe following is a sample code of the Wang–Landau algorithm in [[Python (programming language)|Python]], where we assume that a symmetric proposal distribution g is used:\n\n:<math>g(\\boldsymbol{x}'\\rightarrow \\boldsymbol{x})=g(\\boldsymbol{x}\\rightarrow \\boldsymbol{x}')</math>\n\nThe code considers a \"system\" which is the underlying system being studied.\n\n<source lang=python>\n\ncurrentEnergy = system.randomConfiguration() # a random initial configuration\n\nwhile (f > epsilon):\n    system.proposeConfiguration() # a proposed configuration is proposed\n    proposedEnergy = system.proposedEnergy() # the energy of the proposed configuration computed\n\n    if (random() < exp(entropy[currentEnergy]-entropy[proposedEnergy])):\n        # if accepted, update the energy and the system:\n        currentEnergy = proposedEnergy\n        system.acceptProposedConfiguration()\n    else:\n        # if rejected\n        system.rejectProposedConfiguration()\n    \n    H[currentEnergy] += 1\n    entropy[currentEnergy] += f\n    \n    if (isFlat(H)): # isFlat tests whether the histogram is flat (e.g. 95% flatness)\n        H[:] = 0\n        f *= 0.5 # refine the f parameter\n</source>\n\n==Wang and Landau molecular dynamics==\nIt should be noted that the Wang and Landau algorithm can be implemented not only in a Monte Carlo simulation but also in a molecular dynamics simulation. To do this would require an escalation of the temperature of the system as follows:\n\n:<math> T'(E) \\rightarrow  \\dfrac{\\partial S(E)}{\\partial E}\\cdot T(E),</math>\n\nwhere <math>S(E)</math> is the entropy of the system, <math>T(E)</math> the micro-canonical temperature and <math>T'(E)</math> is the \"scaled\" temperature used in the simulation.\n\n==References==\n\n{{reflist|refs=\n<ref name=WangLandau>\n{{cite journal\n| title = Efficient, Multiple-Range Random Walk Algorithm to Calculate the Density of States\n|author1=Wang, Fugao   |author2=Landau, D. P.\n |lastauthoramp=yes | journal = Phys. Rev. Lett.\n|  volume = 86\n|  issue = 10\n|  pages = 2050–2053\n|date=Mar 2001\n| pmid = 11289852\n|  doi = 10.1103/PhysRevLett.86.2050\n| bibcode=2001PhRvL..86.2050W\n|arxiv = cond-mat/0011174 }}\n</ref>\n<ref name=Belardinelli_Integrals>\n{{cite journal\n| title = Analysis of the convergence of the 1∕t and Wang–Landau algorithms in the calculation of multidimensional integrals\n| author = R. E. Belardinelli and S. Manzi and V. D. Pereyra\n| journal = Phys. Rev. E\n|  volume = 78\n|  page = 067701\n|date=Dec 2008\n|  doi = 10.1103/PhysRevE.78.067701\n| pmid = 19256982\n| issue = 6\n|arxiv = 0806.0268 |bibcode = 2008PhRvE..78f7701B }}\n</ref>\n<ref name=Ojeda1>\n{{cite journal\n| title = Monte Carlo Simulations of Proteins in Cages: Influence of Confinement on the Stability of Intermediate States\n| author = P. Ojeda and M. Garcia and A. Londono and N.Y. Chen\n| journal = Biophys. J.\n|  volume = 96\n|  issue = 3\n|  pages = 1076–1082\n|date=Feb 2009\n|  doi = 10.1529/biophysj.107.125369\n| bibcode=2009BpJ....96.1076O\n|arxiv = 0711.0916\n}}\n</ref>\n<ref name=Ojeda2>\n{{cite journal\n| title = Electric Field-Driven Disruption of a Native beta-Sheet Protein Conformation and Generation of alpha-Helix-Structure\n|author1=P. Ojeda  |author2=M. Garcia \n |lastauthoramp=yes\n | journal = Biophys. J.\n|  volume = 99\n|  issue = 2\n|  pages = 595–599\n|date=Jul 2010\n|  doi = 10.1016/j.bpj.2010.04.040\n| bibcode=2009BpJ....96.1076O\n| pmid=20643079\n| pmc=2905109\n}}\n</ref>\n<ref name=Berg>{{Cite journal | last1 = Berg | first1 = B. | last2 = Neuhaus | first2 = T. | doi = 10.1103/PhysRevLett.68.9 | title = Multicanonical ensemble: A new approach to simulate first-order phase transitions | journal = Physical Review Letters | volume = 68 | issue = 1 | pages = 9–12 | year = 1992 | pmid =  10045099| pmc = |arxiv = hep-lat/9202004 |bibcode = 1992PhRvL..68....9B }}</ref>\n<ref name=Belardinelli_Saturation>\n{{cite journal\n| title   = Wang–Landau algorithm: A theoretical analysis of the saturation of the error\n|author1=Belardinelli, R. E.  |author2=Pereyra, V. D.\n |lastauthoramp=yes | journal = Jour. Chem. Phys.\n| volume  = 127\n| issue   = 18\n| page   = 184105 \n| year    = 2007\n| doi     = 10.1063/1.2803061 \n|pmid=18020628  |arxiv = cond-mat/0702414 |bibcode = 2007JChPh.127r4105B }}\n</ref>\n}}\n\n[[Category:Markov chain Monte Carlo]]\n[[Category:Statistical algorithms]]\n[[Category:Computational physics]]\n[[Category:Articles with example Python code]]"
    },
    {
      "title": "Monte Carlo methods in finance",
      "url": "https://en.wikipedia.org/wiki/Monte_Carlo_methods_in_finance",
      "text": "'''[[Monte Carlo method]]s are used in [[corporate finance]] and [[mathematical finance]]''' to value and analyze (complex) [[financial instrument|instrument]]s, [[portfolio (finance)|portfolio]]s and [[investment]]s by [[simulation|simulating]] the various sources of uncertainty affecting their value, and then determining the distribution of their value over the range of resultant outcomes.<ref name=\"puc\">{{cite web | title = Real Options with Monte Carlo Simulation | url = http://www.puc-rio.br/marco.ind/monte-carlo.html | accessdate = 2010-09-24 }}</ref><ref>{{cite web | title = Monte Carlo Simulation | url = http://www.palisade.com/risk/monte_carlo_simulation.asp | publisher = Palisade Corporation | year = 2010 |  accessdate = 2010-09-24 }}</ref> This is usually done by help of [[stochastic asset model]]s. The advantage of Monte Carlo methods over other techniques increases as the dimensions (sources of uncertainty) of the problem increase.\n\nMonte Carlo methods were first introduced to finance in 1964 by [[David B. Hertz]] through his ''[[Harvard Business Review]]'' article,<ref>{{cite web | title = Risk Analysis in Capital Investment | url = http://hbr.org/product/risk-analysis-in-capital-investment-harvard-busine/an/79504-PDF-ENG | publisher = Harvard Business Review | date = Sep 1, 1979 | pages = 12 | accessdate = 2010-09-24 }}</ref> discussing their application in [[Corporate Finance]]. In 1977, [[Phelim Boyle]] pioneered the use of simulation in [[Derivative (finance)|derivative valuation]] in his seminal ''[[Journal of Financial Economics]]'' paper.<ref name=\"Phelim\">{{cite web | title = Options: A Monte Carlo approach | author = Boyle, Phelim P. | url =  http://ideas.repec.org/a/eee/jfinec/v4y1977i3p323-338.html | publisher = Journal of Financial Economics, Volume (Year): 4 (1977), Issue (Month): 3 (May) | pages =  323–338 | accessdate = 2010-09-24 }}</ref>\n\nThis article discusses typical financial problems in which Monte Carlo methods are used. It also touches on the use of so-called \"quasi-random\" methods such as the use of [[Sobol sequence]]s.\n\n==Overview==\n\nThe [[Monte Carlo method]] encompasses any technique of statistical sampling employed to approximate solutions to quantitative problems.<ref>{{cite web | title = Monte Carlo Simulation : Financial Mathematics Glossary K-O | url = http://www.global-derivatives.com/index.php?option=com_content&task=view&id=21 | publisher = Global Derivatives | year = 2009 | accessdate = 2010-09-24}}</ref>  Essentially, the Monte Carlo method solves a problem by directly [[Simulating#Computer simulation|simulating]] the underlying (physical) process and then calculating the (average) result of the process.<ref name=\"puc\"/> This very general approach is valid in areas such as [[physics]], [[chemistry]], [[computer science]] etc.\n\nIn [[finance]], the Monte Carlo method is used to simulate the various sources of uncertainty that affect the value of the [[financial instrument|instrument]], [[portfolio (finance)|portfolio]] or [[investment]] in question, and to then calculate a representative value given these possible values of the underlying inputs.<ref name=\"puc\"/> (\"Covering all conceivable real world contingencies in proportion to their likelihood.\" <ref name=\"savage\">[http://www.analycorp.com/uncertainty/flawarticle.htm The Flaw of Averages] {{webarchive|url=https://web.archive.org/web/20111207025740/http://www.analycorp.com/uncertainty/flawarticle.htm |date=2011-12-07 }}, Prof. Sam Savage, [[Stanford University]].</ref>) In terms of [[financial economics|financial theory]], this, essentially, is an application of  [[Rational pricing#Risk neutral valuation|risk neutral valuation]];<ref name=\"puc2\">{{cite web | title = FAQ Number 4 : Does Risk-Neutral Valuation Mean that Investors Are Risk-Neutral? What Is the Difference Between Real Simulation and Risk-Neutral Simulation? | url = http://www.puc-rio.br/marco.ind/faq4.html | accessdate = 2010-09-24 | deadurl = yes | archiveurl = https://web.archive.org/web/20100716195259/http://www.puc-rio.br/marco.ind/faq4.html | archivedate = 2010-07-16 | df =  }}</ref> see also [[risk neutrality]].\n\nSome examples:\n\n*In [[Corporate Finance]],<ref name=\"Savvides\">{{cite web | title = Risk Analysis in Investment Appraisal | author = Savvakis C. Savvides, Cyprus Development Bank - Project Financing Division | ssrn =  265905 | publisher = Project Appraisal Journal, Vol. 9, No. 1, March 1994 | accessdate = 2010-09-24 }}</ref><ref name=\" Shimko \">{{cite web | title = Quantifying Corporate Financial Risk | author = David Shimko, President, Asset Deployment, USA  | url =  http://www.qfinance.com/financial-risk-management-best-practice/quantifying-corporate-financial-risk?full | publisher = qfinance.com | accessdate = 2011-01-14 }}</ref><ref name=\"Holtan\">{{cite web | title = Using simulation to calculate the NPV of a project  |author1=Marius Holtan |author2=Onward Inc. | url =  http://www.investmentscience.com/Content/howtoArticles/simulation.pdf | date = 2002-05-31 | accessdate = 2010-09-24 }}</ref> [[project finance]] <ref name=\"Savvides\"/> and [[real options analysis]],<ref name=\"puc\"/> Monte Carlo Methods are used by [[financial analyst]]s who wish to construct \"[[stochastic]]\" or [[probabilistic]] financial models as opposed to the traditional static and [[Deterministic system (mathematics)|deterministic]] models. Here, in order to analyze the characteristics of a project’s [[net present value]] (NPV), the cash flow components that are (heavily <ref name=\"Holtan\"/>) impacted by [[uncertainty]] are modeled, incorporating any [[correlation]] between these, mathematically reflecting their \"random characteristics\". Then, these results are combined in a [[histogram]] of NPV (i.e. the project’s [[probability distribution]]), and the average NPV of the potential investment - as well as its [[Volatility (finance)|volatility]] and other sensitivities - is observed. This distribution allows, for example, for an estimate of the probability that the project has a net present value greater than zero (or any other value).<ref>[http://www.simularsoft.com.ar/SimulAr1e.htm]</ref> See [[Corporate finance#Quantifying uncertainty|further]] under Corporate finance.\n\n*In valuing an [[option (finance)|option on equity]], the simulation generates several thousand possible (but random) price paths for the underlying share, with the associated [[Exercise (options)|exercise]] [[Option time value#Intrinsic value|value]] (i.e. \"payoff\") of the option for each path. These payoffs are then averaged and [[present value|discounted]] to today, and this result is the value of the option today.<ref>[http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN96-03.pdf TEACHING NOTE 96-03: MONTE CARLO SIMULATION] [http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN96-03.pdf]</ref> Note that whereas equity options are more commonly valued using [[Lattice model (finance)|lattice based models]], for [[Path dependence|path dependent]] [[exotic derivatives]] - such as [[Asian options]] - simulation is the valuation method most commonly employed; see [[Monte Carlo methods for option pricing]] for discussion as to further - and more [[exotic option|complex]] - option modelling.\n\n*To value [[fixed income|fixed income instruments]] and [[interest rate derivatives]] the underlying source of uncertainty which is simulated is the [[Short-rate model#The short rate|short rate]] - the annualized [[interest rate]] at which an entity can borrow money for a given period of time;  see [[Short-rate model#Particular short-rate models|Short-rate model]]. For example, for [[bond (finance)|bonds]], and [[bond option]]s,<ref name=\"hjm\">{{cite web | title = Simulating American Bond Options in an HJM Framework |author1=Peter Carr |author2=Guang Yang | url = http://www.math.nyu.edu/research/carrp/papers/pdf/hjm.pdf | date = February 26, 1998 | accessdate = 2010-09-24 }}</ref> under each possible evolution of [[interest rate]]s we observe a different [[yield curve]] and a different [[Bond valuation#Arbitrage-free pricing approach|resultant bond price]].  To determine the bond value, these bond prices are then averaged; to value the bond option, as for equity options, the corresponding [[Exercise (options)|exercise value]]s are averaged and present valued. A similar approach is used in valuing [[swap (finance)|swaps]] and [[swaption]]s.<ref name=\"Swaptions\">{{cite web | title = Alternative Valuation Methods for Swaptions:  The Devil is in the Details |author1=Carlos Blanco, Josh Gray  |author2=Marc Hazzard  |lastauthoramp=yes | url = http://www.fea.com/resources/pdf/swaptions.pdf | accessdate = 2010-09-24 }}</ref>  As for equity, for path dependent [[interest rate derivative]]s - such as [[Collateralized mortgage obligation|CMOs]] - simulation is the ''primary'' technique employed;<ref>[[Frank J. Fabozzi]]: [https://books.google.com/books?id=wF8yVzLI6EYC&pg=PA138&lpg=PA138&dq=cmo+valuation+fabozzi+simulation&source=bl&ots=zSvgwSKm2V&sig=lW48IuS6CEQAch0f-uGVyHdIg3A&hl=en&ei=tcfATqPPB8SKhQfGovGzBA&sa=X&oi=book_result&ct=result&resnum=4&ved=0CC4Q6AEwAw#v=onepage&q&f=false ''Valuation of fixed income securities and derivatives'', pg. 138]</ref> (Note that \"to create realistic interest rate simulations\" [[Short rate model#Multi-factor short-rate models|Multi-factor short-rate models]] are sometimes employed.<ref>Donald R. van Deventer (Kamakura Corporation): [http://www.kamakuraco.com/Blog/tabid/231/EntryId/347/Pitfalls-in-Asset-and-Liability-Management-One-Factor-Term-Structure-Models.aspx Pitfalls in Asset and Liability Management: One Factor Term Structure Models]</ref>)\n\n*Monte Carlo Methods are used for [[Portfolio (finance)|portfolio]] evaluation.<ref name=\"MCS\">{{cite web | title = The Monte Carlo Framework, Examples from Finance and Generating Correlated Random Variables | author = Martin Haugh | url = http://www.columbia.edu/~mh2078/MCS04/MCS_framework_FEegs.pdf | date = Fall 2004 | accessdate = 2010-09-24 | deadurl = yes | archiveurl = https://web.archive.org/web/20120105084424/http://www.columbia.edu/~mh2078/MCS04/MCS_framework_FEegs.pdf | archivedate = 2012-01-05 | df =  }}</ref> Here, for each sample, the [[correlation|correlated]] behaviour of the factors impacting the component instruments is simulated over time, the resultant value of each instrument is calculated, and the portfolio value is then observed. As for corporate finance, above, the various portfolio values are then combined in a [[histogram]], and the [[Descriptive statistics|statistical characteristics]] of the portfolio are observed, and the portfolio assessed as required. A similar approach is used in calculating [[Value at risk#Common VaR calculation models|value at risk]],<ref name=\"VAR\">{{cite web | title = Monte Carlo Value-at-Risk | url = http://www.riskglossary.com/link/monte_carlo_transformation.htm | publisher = Contingency Analysis | year = 2004 | accessdate = 2010-09-24 }}</ref><ref name=\"Investopedia\">{{cite web | title = An Introduction To Value at Risk (VAR) | author = David Harper,CFA, FRM | url = http://www.investopedia.com/articles/04/092904.asp | publisher = Investopedia | accessdate = 2010-09-24 }}</ref> a better known application of simulation to portfolios.\n\n* Monte Carlo Methods are used for [[personal financial planning]].<ref name=\"businessweek\">{{cite web | title = A Better Way to Size Up Your Nest Egg : ''Monte Carlo'' models simulate all kinds of scenarios | author = Christopher Farrell | url = http://www.businessweek.com/2001/01_04/b3716156.htm | publisher = Bloomberg Businessweek | date = January 22, 2001 | accessdate = 2010-09-24 }}</ref><ref name=\"finplan\">{{cite web | title = Financial Planning Using Random Walks | author = John Norstad | url = http://homepage.mac.com/j.norstad/finance/finplan.pdf | date = February 2, 2005 | accessdate = 2010-09-24 }}</ref> For instance, by simulating the overall market, the chances of a [[401(k)]] allowing for [[retirement]] on a target income can be calculated. As appropriate, the worker in question can then take greater risks with the retirement portfolio or start saving more money.\n\n*[[Discrete event simulation]] can be used in evaluating a proposed [[capital investment]]'s impact on existing operations. Here, a \"current state\" model is constructed.  Once operating correctly, having been [[model validation|tested and validated]] against historical data, the simulation is altered to reflect the proposed capital investment. This \"future state\" model is then used to assess the investment, by evaluating the improvement in performance (i.e. return) relative to the cost (via histogram as above); it may also be used in [[stress testing]] the design. See [[Discrete event simulation#Evaluating capital investment decisions|Discrete event simulation #Evaluating capital investment decisions]].\n\nAlthough Monte Carlo methods provide flexibility, and can handle multiple sources of uncertainty, the use of these techniques is nevertheless not always appropriate.  In general, simulation methods are preferred to other valuation techniques only when there are several state variables (i.e. several sources of uncertainty).<ref name=\"puc\"/> These techniques are also of limited use in valuing American style derivatives. See below.\n\n==Applicability==\n\n===Level of complexity===\nMany problems in [[mathematical finance]] entail the computation of a particular [[integral]] (for instance the problem of finding the arbitrage-free value of a particular [[derivative (finance)|derivative]]). In many cases these integrals can be valued [[analytic solution|analytically]], and in still more cases they can be valued using [[numerical integration]], or computed using a [[partial differential equation]] (PDE).  However, when the number of dimensions (or degrees of freedom) in the problem is large, PDEs and numerical integrals become intractable, and in these cases [[Monte Carlo method]]s often give better results.\n\nFor more than three or four state variables, formulae such as [[Black–Scholes model|Black–Scholes]] (i.e. [[analytic solution]]s) do not exist, while other [[numerical method]]s such as the [[Binomial options pricing model]]  and [[finite difference method]]s  face several difficulties and are not practical.  In these cases, Monte Carlo methods converge to the solution more quickly than numerical methods, require less memory and are easier to program. For simpler situations, however, simulation is not the better solution because it is very time-consuming and computationally intensive.\n\nMonte Carlo methods can deal with derivatives which have path dependent payoffs in a fairly straightforward manner. On the other hand, Finite Difference (PDE) solvers struggle with path dependence.\n\n=== American options ===\nMonte-Carlo methods are harder to use with [[Option style|American option]]s. This is because, in contrast to a [[partial differential equation]], the Monte Carlo method really only estimates the option value assuming a given starting point and time.\n\nHowever, for early exercise, we would also need to know the option value at the intermediate times between the simulation start time and the option expiry time. In the [[Black–Scholes model|Black–Scholes]] PDE approach these prices are easily obtained, because the simulation runs backwards from the expiry date. In Monte-Carlo this information is harder to obtain, but it can be done for example using the [[least squares]] algorithm of Carriere (see link to original paper) which was made popular a few years later by Longstaff and Schwartz (see link to original paper).\n\n== Monte Carlo methods ==\n\n===Mathematically===\nThe [[fundamental theorem of arbitrage-free pricing]] states that the value of a derivative is equal to the discounted expected value of the derivative payoff where the [[expected value|expectation]] is taken under the [[risk-neutral measure]] <sup>[1]</sup>. An expectation is, in the language of [[pure mathematics]], simply an integral with respect to the measure. Monte Carlo methods are ideally suited to evaluating difficult integrals (see also [[Monte Carlo method]]).\n\nThus if we suppose that our risk-neutral probability space is <math>\\mathbb{P}</math> and that we have a derivative H that depends on a set of [[underlying instruments]] <math>S_1,...,S_n</math>. Then given a sample <math>\\omega</math> from the probability space the value of the derivative is <math>H( S_1(\\omega),S_2(\\omega),\\dots, S_n(\\omega)) =: H(\\omega) </math>. Today's value of the derivative is found by taking the expectation over all possible samples and discounting at the risk-free rate. I.e. the derivative has value:\n\n:<math> H_0 = {DF}_T \\int_\\omega H(\\omega)\\, d\\mathbb{P}(\\omega) </math>\n\nwhere <math>{DF}_T</math> is the [[discount factor]] corresponding to the risk-free rate to the final maturity date ''T'' years into the future.\n\nNow suppose the integral is hard to compute. We can approximate the integral by generating sample paths and then taking an average. Suppose we generate N samples then\n\n:<math> H_0 \\approx {DF}_T \\frac{1}{N} \\sum_{\\omega\\in \\text{sample set}} H(\\omega)</math>\n\nwhich is much easier to compute.\n\n=== Sample paths for standard models ===\nIn finance, underlying random variables (such as an underlying stock price) are usually assumed to follow a path that is a function of a [[Brownian motion]] <sup>2</sup>. For example, in the standard [[Black–Scholes model]], the stock price evolves as\n\n:<math> dS = \\mu S \\,dt + \\sigma S \\,dW_t. </math>\n\nTo sample a path following this distribution from time 0 to T, we chop the time interval into M units of length <math>\\delta t</math>, and approximate the Brownian motion over the interval <math>dt</math> by a single normal variable of mean 0 and variance <math>\\delta t</math>. This leads to a sample path of\n\n:<math> S( k\\delta t) = S(0) \\exp\\left( \\sum_{i=1}^{k} \\left[\\left(\\mu - \\frac{\\sigma^2}{2}\\right)\\delta t + \\sigma\\varepsilon_i\\sqrt{\\delta t}\\right] \\right)</math>\n\nfor each ''k'' between 1 and ''M''. Here each <math>\\varepsilon_i</math> is a draw from a standard normal distribution.\n\nLet us suppose that a derivative H pays the average value of ''S'' between 0 and ''T'' then a sample path <math>\\omega</math> corresponds to a set <math>\\{\\varepsilon_1,\\dots,\\varepsilon_M\\}</math> and\n\n:<math> H(\\omega) = \\frac1{M} \\sum_{k=1}^{M} S( k \\delta t).</math>\n\nWe obtain the Monte-Carlo value of this derivative by generating ''N'' lots of ''M'' normal variables, creating ''N'' sample paths and so ''N'' values of ''H'', and then taking the average.\nCommonly the derivative will depend on two or more (possibly correlated) underlyings. The method here can be extended to generate sample paths of several variables, where the normal variables building up the sample paths are appropriately correlated.\n\nIt follows from the [[central limit theorem]] that quadrupling the number of sample paths approximately halves the error in the simulated price (i.e. the error has order <math>\\epsilon=\\mathcal{O}\\left(N^{-1/2}\\right)</math> convergence in the sense of standard deviation of the solution).\n\nIn practice Monte Carlo methods are used for European-style derivatives involving at least three variables (more direct methods involving numerical integration can usually be used for those problems with only one or two underlyings. ''See'' [[Monte Carlo option model]].\n\n=== Greeks ===\nEstimates for the \"[[Greeks (finance)|Greeks]]\" of an option i.e. the (mathematical) derivatives of option value with respect to input parameters, can be obtained by numerical differentiation. This can be a time-consuming process (an entire Monte Carlo run must be performed for each \"bump\" or small change in input parameters). Further, taking numerical derivatives tends to emphasize the error (or noise) in the Monte Carlo value - making it necessary to simulate with a large number of sample paths. Practitioners regard these points as a key problem with using Monte Carlo methods.\n\n=== Variance reduction ===\nSquare root convergence is slow, and so using the naive approach described above requires using a very large number of sample paths (1 million, say, for a typical problem) in order to obtain an accurate result. Remember that an estimator for the price of a derivative is a random variable, and in the framework of a risk-management activity, uncertainty on the price of a portfolio of derivatives and/or on its risks can lead to suboptimal risk-management decisions.\n\nThis state of affairs can be mitigated by [[variance reduction]] techniques.\n\n==== [[Antithetic variates|Antithetic paths]] ====\nA simple technique is, for every sample path obtained, to take its antithetic path &mdash; that is given a path <math>\\{\\varepsilon_1,\\dots,\\varepsilon_M\\}</math> to also take <math>\\{-\\varepsilon_1,\\dots,-\\varepsilon_M\\}</math>. Since the variables <math>\\varepsilon_i</math> and <math>-\\varepsilon_i</math> form an antithetic pair, a large value of one is accompanied by a small value of the other. This suggests that an unusually large or small output computed from the first path may be balanced by the value computed from the antithetic path, resulting in a reduction in variance.<ref>{{Cite book|title = Monte Carlo methods in financial engineering|last = Glasserman|first = P.|publisher = Springer.|year = 2004|isbn = |location = New York|pages = 205}}</ref> Not only does this reduce the number of normal samples to be taken to generate ''N'' paths, but also, under same conditions, such as negative correlation between two estimates, reduces the variance of the sample paths, improving the accuracy.\n\n==== [[Control variates|Control variate method]] ====\nIt is also natural to use a [[control variate]]. Let us suppose that we wish to obtain the Monte Carlo value of a derivative ''H'', but know the value analytically of a similar derivative I. Then ''H''* = (Value of ''H'' according to Monte Carlo) + B*[(Value of ''I'' analytically) &minus; (Value of ''I'' according to same Monte Carlo paths)] is a better estimate, where B is covar(H,I)/var(H).\n\nThe intuition behind that technique, when applied to derivatives, is the following: note that the source of the variance of a derivative will be directly dependent on the risks (e.g. delta, vega) of this derivative. This is because any error on, say, the estimator for the forward value of an underlier, will generate a corresponding error depending on the delta of the derivative with respect to this forward value. The simplest example to demonstrate this consists in comparing the error when pricing an at-the-money call and an at-the-money straddle (i.e. call+put), which has a much lower delta.\n\nTherefore, a standard way of choosing the derivative ''I'' consists in choosing a [[replicating portfolio]]s of options for ''H''. In practice, one will price ''H'' without variance reduction, calculate deltas and vegas, and then use a combination of calls and puts that have the same deltas and vegas as control variate.\n\n==== Importance sampling ====\n[[Importance sampling#Application to simulation|Importance sampling]] consists of simulating the Monte Carlo paths using a different probability distribution (also known as a change of measure) that will give more likelihood for the simulated underlier to be located in the area where the derivative's payoff has the most convexity (for example, close to the strike in the case of a simple option). The simulated payoffs are then not simply averaged as in the case of a simple Monte Carlo, but are first multiplied by the likelihood ratio between the modified probability distribution and the original one (which is obtained by analytical formulas specific for the probability distribution). This will ensure that paths whose probability have been arbitrarily enhanced by the change of probability distribution are weighted with a low weight (this is how the variance gets reduced).\n\nThis technique can be particularly useful when calculating risks on a derivative. When calculating the delta using a Monte Carlo method, the most straightforward way is the ''black-box'' technique consisting in doing a Monte Carlo on the original market data and another one on the changed market data, and calculate the risk by doing the difference. Instead, the importance sampling method consists in doing a Monte Carlo in an arbitrary reference market data (ideally one in which the variance is as low as possible), and calculate the prices using the weight-changing technique described above. This results in a risk that will be much more stable than the one obtained through the ''black-box'' approach.\n\n=== Quasi-random (low-discrepancy) methods ===\n{{main|Quasi-Monte Carlo methods in finance}}\n\nInstead of generating sample paths randomly, it is possible to systematically (and in fact completely deterministically, despite the \"quasi-random\" in the name) select points in a probability spaces so as to optimally \"fill up\" the space. The selection of points is a [[low-discrepancy sequence]] such as a [[Sobol sequence]]. Taking averages of derivative payoffs at points in a low-discrepancy sequence is often more efficient than taking averages of payoffs at random points.\n\n== Notes ==\n# Frequently it is more practical to take expectations under different measures, however these are still fundamentally integrals, and so the same approach can be applied.\n# More general processes, such as [[Lévy process]]es, are also sometimes used. These may also be simulated.\n\n== See also ==\n* [[Quasi-Monte Carlo methods in finance]]\n* [[Monte Carlo method]]\n* [[Historical simulation (finance)]]\n* [[Stock market simulator]]\n* [[Real options valuation]]\n\n== References ==\n\n=== Notes ===\n<references/>\n\n=== Articles ===\n\n* Boyle, P., Broadie, M. and Glasserman, P. Monte Carlo Methods for Security Pricing. Journal of Economic Dynamics and Control, Volume 21, Issues 8-9, Pages 1267-1321\n* Rubinstein, Samorodnitsky, Shaked. Antithetic Variates, Multivariate Dependence and Simulation of Stochastic Systems. Management Science, Vol. 31, No. 1, Jan 1985, pages 66–67\n\n=== Books ===\n<!-- alpahbetical by author -->\n*{{cite book | title = Interest Rate Models - Theory and Practice with Smile, Inflation and Credit| author = [[Damiano Brigo]], [[Fabio Mercurio]] | publisher = Springer Verlag | year = 2001 | edition = 2nd ed. 2006 | isbn = 978-3-540-22149-4}}\n* {{cite book | title = Monte Carlo Frameworks: Building Customisable High-performance C++ Applications  |author1=Daniel J. Duffy  |author2=Joerg Kienitz  |lastauthoramp=yes | year = 2009 | publisher = Wiley | isbn = 0470060697}}\n* {{cite book | title = Monte Carlo:methodologies and applications for pricing and risk management | author = [[Bruno Dupire]] | year = 1998 | publisher = Risk }}\n* {{cite book | title = Monte Carlo methods in financial engineering | author = Paul Glasserman | year = 2003 | publisher = Springer-Verlag | isbn = 0-387-00451-3 }}\n* {{cite book | title = Options, futures and other derivatives (4th ed.) | author = [[John C. Hull]] | year = 2000 | publisher = Prentice Hall | isbn = 0-13-015822-4 }}\n* {{cite book | title = Monte Carlo methods in finance | author = [[Peter Jaeckel]] | year = 2002 | publisher = John Wiley and Sons | isbn = 0-471-49741-X }}\n* {{cite book | title = Modern Computational Finance: AAD and Parallel Simulations | author = Antoine Savine | year = 2018 | publisher = John Wiley and Sons | isbn = 978-1119539452}}\n* {{cite book | title = Numerical Solution of Stochastic Differential Equations |author1=Peter E. Kloeden  |author2=Eckhard Platen  |lastauthoramp=yes | year = 1992 | publisher = Springer - Verlag }}\n* {{cite book | title = Simulation and Optimization in Finance: Modeling with MATLAB, @Risk, or VBA | author = Dessislava Pachamanova and [[Frank J. Fabozzi]]\n| year = 2010| publisher = John Wiley and Sons |isbn = 0-470-37189-7}}\n\n==External links==\n\n'''General'''\n*[http://www.pjaeckel.webspace.virginmedia.com/eqf013_026.pdf Monte Carlo Simulation] (Encyclopedia of Quantitative Finance), [[Peter Jaeckel]] and Eckhard Plateny\n*[http://www.global-derivatives.com/maths/k-o.php MonteCarlo Simulation in Finance], global-derivatives.com\n*[http://www.riskglossary.com/link/monte_carlo_method.htm Monte Carlo Method], riskglossary.com\n*[https://web.archive.org/web/20120105084424/http://www.columbia.edu/~mh2078/MCS04/MCS_framework_FEegs.pdf The Monte Carlo Framework, Examples from Finance], Martin Haugh, [[Columbia University]]\n*[http://homepages.nyu.edu/~sl1544/articles.html Monte Carlo techniques applied to finance], Simon Leger\n\n'''Derivative valuation'''\n*[http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN96-03.pdf Monte Carlo Simulation], Prof. Don M. Chance, [[Louisiana State University]]\n*[http://finance-old.bi.no/~bernt/gcc_prog/recipes/recipes/node12.html Option pricing by simulation], Bernt Arne Ødegaard, [[Norwegian School of Management]]\n*[http://www.smartquant.com/references/MonteCarlo/mc6.pdf Applications of Monte Carlo Methods in Finance: Option Pricing], Y. Lai and J. Spanier, [[Claremont Graduate University]]\n* [http://spears.okstate.edu/home/tlk/legacy/fin5883/notes6_s05.doc Monte Carlo Derivative valuation], [http://spears.okstate.edu/home/tlk/legacy/fin5883/notes7_s05.doc contd.], Timothy L. Krehbiel, [[Oklahoma State University–Stillwater]]\n*[http://www.quantnotes.com/publications/papers/Fink-montecarlo.pdf Pricing complex options using a simple Monte Carlo Simulation], Peter Fink - reprint at quantnotes.com\n*[http://ideas.repec.org/a/eee/insuma/v19y1996i1p19-30.html Least-Squares Monte-Carlo for American options by Carriere, 1996], ideas.repec.org\n*[http://repositories.cdlib.org/anderson/fin/1-01/ Least-Squares Monte-Carlo for American options by Longstaff and Schwartz, 2001], repositories.cdlib.org\n*[http://www.crystalball.com/articles/download/charnes-options.pdf Using simulation for option pricing], John Charnes\n\n'''Corporate Finance'''\n*[http://www.puc-rio.br/marco.ind/monte-carlo.html Real Options with Monte Carlo Simulation], Marco Dias, [[Pontifícia Universidade Católica do Rio de Janeiro]]\n*[http://www.investmentscience.com/Content/howtoArticles/simulation.pdf Using simulation to calculate the NPV of a project], investmentscience.com\n*[http://pages.stern.nyu.edu/~adamodar/pdfiles/papers/probabilistic.pdf Simulations, Decision Trees and Scenario Analysis in Valuation] Prof. [[Aswath Damodaran]], [[Stern School of Business]]\n*[http://www.ulb.ac.be/cours/solvay/farber/Teaching%20Notes/Monte%20Carlo.pdf The Monte Carlo method in Excel] Prof. André Farber [[Solvay Business School]]\n*[http://www.vertex42.com/ExcelArticles/mc/SalesForecast.html Sales Forecasting], vertex42.com\n*[http://knol.google.com/k/giancarlo-vercellino/pricing-using-monte-carlo-simulation/11d5i2rgd9gn5/3# Pricing using Monte Carlo simulation], a practical example, Prof. Giancarlo Vercellino\n\n'''Value at Risk and portfolio analysis'''\n*[http://www.riskglossary.com/link/monte_carlo_transformation.htm Monte Carlo Value-at-Risk], riskglossary.com\n\n'''Personal finance'''\n*[http://www.businessweek.com/2001/01_04/b3716156.htm A Better Way to Size Up Your Nest Egg], Businessweek Online: January 22, 2001\n*[http://www.flexibleretirementplanner.com  Online Monte Carlo retirement planner with source code], Jim Richmond, 2006\n*[http://www.prospercuity.com  Free spreadsheet-based retirement calculator and Monte Carlo simulator], by Eric C., 2008\n*[http://www.retirementsimulation.com Retirement Simulation]\n*[http://homepage.mac.com/j.norstad/finance/finplan.pdf Financial Planning Using Random Walks], John Norstad, 2005\n*[http://www.vanguard.com/nesteggcalculator Vanguard Nest Egg Calculator], Vanguard\n\n{{DEFAULTSORT:Monte Carlo Methods In Finance}}\n[[Category:Monte Carlo methods in finance| ]]"
    },
    {
      "title": "Agent-based computational economics",
      "url": "https://en.wikipedia.org/wiki/Agent-based_computational_economics",
      "text": "{{Use dmy dates|date=December 2012}}\n'''Agent-based computational economics''' ('''ACE''') is the area of [[computational economics]] that studies economic processes, including whole [[economy|economies]], as [[dynamic system]]s of interacting [[Agent (economics)|agents]]. As such, it falls in the [[paradigm]] of [[complex adaptive system]]s.<ref>• [[W. Brian Arthur]], 1994. \"[https://ocw.tudelft.nl/wp-content/uploads/ElFarolArtur1994.pdf Inductive Reasoning and Bounded Rationality],\" ''American Economic Review'', 84(2), pp. [http://www-personal.umich.edu/~samoore/bit885f2011/arthur-inductive.pdf 406-411] {{Webarchive|url=https://web.archive.org/web/20130521145936/http://www-personal.umich.edu/~samoore/bit885f2011/arthur-inductive.pdf |date=21 May 2013 }}.<br/>&nbsp;&nbsp; • [[Leigh Tesfatsion]], 2003. \"Agent-based Computational Economics: Modeling Economies as Complex Adaptive Systems,\" ''Information Sciences'', 149(4), pp. [http://copper.math.buffalo.edu/urgewiki/uploads/Literature/Tesfatsion2002.pdf 262-268] {{webarchive|url=https://web.archive.org/web/20120426000037/http://copper.math.buffalo.edu/urgewiki/uploads/Literature/Tesfatsion2002.pdf |date=26 April 2012 }}.</ref> In  corresponding [[agent-based model]]s, the \"[[agent (economics)|agents]]\" are \"computational objects modeled as interacting according to rules\" over space and time, not real people. The rules are formulated to model behavior and social interactions based on incentives and information.<ref>Scott E. Page (2008). \"agent-based models,\" ''[[The New Palgrave Dictionary of Economics]]'', 2nd Edition. [http://www.dictionaryofeconomics.com/article?id=pde2008_A000218&edition=current&q=agent-based%20computational%20modeling&topicid=&result_number=1 Abstract].</ref> Such rules could also be the result of optimization, realized through use of AI methods (such as [[Q-learning]] and other reinforcement learning techniques).<ref>Richard S. Sutton and Andrew G. Barto, Reinforcement Learning: An Introduction, The MIT Press, Cambridge, MA, 1998 [http://www.cs.ualberta.ca/~sutton/book/ebook/the-book.html] {{Webarchive|url=https://web.archive.org/web/20090904194934/http://www.cs.ualberta.ca/~sutton/book/ebook/the-book.html |date=4 September 2009 }}</ref>\n\nThe theoretical assumption of [[mathematical optimization]] by agents in [[equilibrium (economics)|equilibrium]] is replaced by the less restrictive postulate of agents with [[bounded rationality]] ''adapting'' to market forces.<ref>• [[John H. Holland]] and John H. Miller (1991). \"Artificial Adaptive Agents in Economic Theory,\" ''American Economic Review'', 81(2),  pp. [http://www.santafe.edu/media/workingpapers/91-05-025.pdf  365-370] {{Webarchive|url=https://web.archive.org/web/20110105015853/http://www.santafe.edu/media/workingpapers/91-05-025.pdf |date=5 January 2011 }} p. 366.<br/>&nbsp;&nbsp; • [[Thomas C. Schelling]] (1978 [2006]).  ''Micromotives and Macrobehavior'', Norton. [http://books.wwnorton.com/books/978-0-393-32946-9/ Description],  [https://books.google.com/books?id=DenWKRgqzWMC&printsec=find&pg=PA1=#v=onepage&q&f=false preview].<br/>&nbsp;&nbsp; •\n[[Thomas J. Sargent]], 1994. ''Bounded Rationality in Macroeconomics'', Oxford. [http://www.oup.com/us/catalog/general/subject/Economics/MacroeconomicTheory/?view=usa&ci=9780198288695 Description] and chapter-preview 1st-page [https://www.questia.com/library/book/bounded-rationality-in-macroeconomics-thomas-j-sargent-by-thomas-j-sargent.jsp links.]</ref> ACE models apply [[numerical methods]] of analysis to [[Computer simulation|computer-based simulations]] of complex dynamic problems for which more conventional methods, such as theorem formulation, may not find ready use.<ref>• Kenneth L. Judd, 2006. \"Computationally Intensive Analyses in Economics,\" ''Handbook of Computational Economics'', v. 2, ch. 17, Introduction, p. 883. [Pp. [https://books.google.com/books?id=6ITfRkNmKQcC&pg=PA881 881-] 893. Pre-pub [http://www2.econ.iastate.edu/tesfatsi/Judd.finalrev.pdf PDF].\n<br/>&nbsp;&nbsp; •  _____, 1998. ''Numerical Methods in Economics'', MIT Press. Links to [http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&tid=3257 description] {{webarchive|url=https://web.archive.org/web/20120211061602/http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&tid=3257 |date=11 February 2012 }} and [https://books.google.com/books?id=9Wxk_z9HskAC&pg=PR7 chapter previews].</ref> Starting from initial conditions specified by the modeler, the computational economy evolves over time as its constituent agents repeatedly interact with each other, including learning from interactions. In these respects, ACE has been characterized as a bottom-up culture-dish approach to the study of [[economic systems]].<ref>• Leigh Tesfatsion (2002). \"Agent-Based Computational Economics: Growing Economies from the Bottom Up,\" ''Artificial Life'', 8(1), pp.55-82. [http://www.mitpressjournals.org/doi/abs/10.1162/106454602753694765 Abstract] and pre-pub [http://www.econ.brown.edu/fac/Peter_Howitt/SummerSchool/Agent.pdf  PDF] {{webarchive|url=https://web.archive.org/web/20130514143904/http://www.econ.brown.edu/fac/Peter_Howitt/SummerSchool/Agent.pdf |date=14 May 2013 }}.<br/>&nbsp;&nbsp; • _____ (1997). \"How Economists Can Get Alife,\" in W. B. Arthur, S. Durlauf, and D. Lane, eds., ''The Economy as an Evolving Complex System, II'',  pp. 533-564. Addison-Wesley. Pre-pub [http://ageconsearch.umn.edu/bitstream/18196/1/er37.pdf PDF].</ref>\n\nACE has a similarity to, and overlap with, [[game theory]] as an agent-based method for modeling social interactions.<ref name=\"COMP&GT\">• [[Joseph Y. Halpern]] (2008). \"computer science and game theory,\" ''The New Palgrave Dictionary of Economics'', 2nd Edition.  [http://www.dictionaryofeconomics.com/article?id=pde2008_C000566&edition=current&q=&topicid=&result_number=1 Abstract].<br/>&nbsp;&nbsp; • Yoav Shoham (2008). \"Computer Science and Game Theory,\" ''Communications of the ACM'',  51(8), pp.\n[http://www.robotics.stanford.edu/~shoham/www%20papers/CSGT-CACM-Shoham.pdf 75-79].<br/>&nbsp;&nbsp; • [[Alvin E. Roth]] (2002). \"The Economist as Engineer: Game Theory, Experimentation, and Computation as Tools for Design Economics,\" ''Econometrica'', 70(4), pp. [https://web.archive.org/web/20040414102216/http://kuznets.fas.harvard.edu/~aroth/papers/engineer.pdf 1341–1378].</ref> But practitioners have also noted differences from standard methods, for example in ACE events modeled being driven solely by initial conditions, whether or not equilibria exist or are computationally tractable, and in the modeling facilitation of agent autonomy and learning.<ref>Tesfatsion, Leigh (2006), \"Agent-Based Computational Economics: A Constructive Approach to Economic Theory,\" ch. 16, ''Handbook of Computational Economics'', v. 2, part 2, ACE study of economic system. [http://www.sciencedirect.com/science/article/pii/S1574002105020162 Abstract] and pre-pub [http://econ2.econ.iastate.edu/tesfatsi/hbintlt.pdf PDF].</ref>\n\nThe method has benefited from continuing improvements in modeling techniques of [[computer science]] and increased computer capabilities.  The ultimate scientific objective of the method is to \"test theoretical findings against real-world data in ways that permit empirically supported theories to cumulate over time, with each researcher’s work building appropriately on the work that has gone before.\"<ref>• Leigh Tesfatsion (2006). \"Agent-Based Computational Economics: A Constructive Approach to Economic Theory,\" ch. 16, ''Handbook of Computational Economics'', v. 2, [pp. 831-880] sect. 5. [http://www.sciencedirect.com/science/article/pii/S1574002105020162 Abstract] and pre-pub [http://econ2.econ.iastate.edu/tesfatsi/hbintlt.pdf PDF].<br/>&nbsp;&nbsp; • [[Kenneth L. Judd]] (2006). \"Computationally Intensive Analyses in Economics,\" ''Handbook of Computational Economics'', v. 2, ch. 17, pp. [https://books.google.com/books?id=6ITfRkNmKQcC&pg=PA881 881-] 893. Pre-pub [http://www2.econ.iastate.edu/tesfatsi/Judd.finalrev.pdf PDF].<br/>&nbsp;&nbsp; • Leigh Tesfatsion and Kenneth L. Judd, ed. (2006). ''Handbook of Computational Economics'', v. 2. [http://www.elsevier.com/wps/find/bookdescription.cws_home/660847/description#description Description] {{Webarchive|url=https://web.archive.org/web/20120306100156/http://www.elsevier.com/wps/find/bookdescription.cws_home/660847/description#description |date=6 March 2012 }} & and chapter-preview\n[http://www.sciencedirect.com/science?_ob=PublicationURL&_hubEid=1-s2.0-S1574002105X02003&_cid=273377&_pubType=HS&_auth=y&_acct=C000228598&_version=1&_urlVersion=0&_userid=10&md5=e4757b4f65755ed6340a11fee9615200 links.]</ref> The subject has been applied to research areas like [[asset pricing]],<ref name=arthuretal>B. Arthur, J. Holland, B. LeBaron, R. Palmer, P. Taylor (1997), 'Asset pricing under endogenous expectations in an artificial stock market,' in ''The Economy as an Evolving Complex System II'', B. Arthur, S. Durlauf, and D. Lane, eds., Addison Wesley.</ref> [[competition]] and [[collaboration]],<ref>[[Robert Axelrod]] (1997). ''The Complexity of Cooperation: Agent-Based Models of Competition and Collaboration'', Princeton. [http://press.princeton.edu/titles/6144.html Description], [http://press.princeton.edu/titles/6144.html#TOC contents], and [https://books.google.com/books?id=J0dgRGMdjmQC&printsec=find&pg=PR11#v=onepage&q&f=false preview].</ref> [[transaction cost]]s,<ref>Tomas B. Klosa and [[Bart Nooteboom]], 2001. \"Agent-based Computational Transaction Cost Economics,\"  ''Journal of Economic Dynamics and Control'' 25(3–4), pp. 503–52. [http://www.sciencedirect.com/science/article/pii/S0165188900000348 Abstract.]</ref> [[market structure]] and [[industrial organization]] and dynamics,<ref>• Roberto Leombruni and Matteo Richiardi, ed. (2004), ''Industry  and Labor Dynamics: The Agent-Based Computational Economics Approach.'' World Scientific Publishing {{ISBN|981-256-100-5}}. [http://www.worldscibooks.com/economics/5706.html Description] {{Webarchive|url=https://web.archive.org/web/20100727221149/http://www.worldscibooks.com/economics/5706.html |date=27 July 2010 }} and chapter-preview [https://books.google.com/books?id=P5O7A5D55nQC&printsec=fond&pg=PR5#v=onepage&q&f=false links].<br/>&nbsp;&nbsp; • [[Joshua M. Epstein]] (2006). \"Growing Adaptive Organizations: An Agent-Based Computational Approach,\" in ''Generative Social Science: Studies in Agent-Based Computational Modeling'', pp. [https://books.google.com/books?id=543OS3qdxBYC&pg=PA309 309-] 344. [http://press.princeton.edu/titles/8277.html Description] {{Webarchive|url=https://web.archive.org/web/20120126180655/http://press.princeton.edu/titles/8277.html |date=26 January 2012 }} and [http://www.santafe.edu/research/working-papers/abstract/99895b6465e8b87656612f8e3570b34c/ abstract].</ref> [[welfare economics]],<ref>[[Robert Axtell]] (2005). \"The Complexity of Exchange,\"  ''Economic Journal'', 115(504, Features), pp. [http://econfaculty.gmu.edu/pboettke/workshop/archives/f05/Axtell.pdf F193-F210].</ref> and [[mechanism design]],<ref>• ''The New Palgrave Dictionary of Economics'' (2008), 2nd Edition: <br/>&nbsp;&nbsp;&nbsp;&nbsp; [[Roger B. Myerson]] \"mechanism design.\" [http://www.dictionaryofeconomics.com/article?id=pde2008_M000132&edition=current&q=mechanism%20design&topicid=&result_number=3 Abstract.]   <br/>&nbsp;&nbsp;&nbsp;&nbsp; _____. \"revelation principle.\" [http://www.dictionaryofeconomics.com/article?id=pde2008_R000137&edition=current&q=moral&topicid=&result_number=1 Abstract.]<br/>&nbsp;&nbsp;&nbsp;&nbsp; Tuomas Sandholm. \"computing in mechanism design.\" [http://www.dictionaryofeconomics.com/article?id=pde2008_C000563&edition=&field=keyword&q=algorithmic%20mechanism%20design&topicid=&result_number=1 Abstract.]<br/>&nbsp;&nbsp; • [[Noam Nisan]] and Amir Ronen (2001). \"Algorithmic Mechanism Design,\" ''Games and Economic Behavior'',  35(1-2), pp. [http://www.cs.cmu.edu/~sandholm/cs15-892F09/Algorithmic%20mechanism%20design.pdf 166–196].<br/>&nbsp;&nbsp; • [[Noam Nisan]] ''et al''., ed. (2007). ''Algorithmic Game Theory'', Cambridge University Press. [http://www.cup.cam.ac.uk/asia/catalogue/catalogue.asp?isbn=9780521872829 Description] {{Webarchive|url=https://web.archive.org/web/20120505140924/http://www.cup.cam.ac.uk/asia/catalogue/catalogue.asp?isbn=9780521872829 |date=5 May 2012 }}.</ref> [[Information economics|information and uncertainty]],<ref>Tuomas W. Sandholm and Victor R. Lesser (2001). \"Leveled Commitment Contracts and Strategic Breach,\" ''Games and Economic Behavior'', 35(1-2), pp. [http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/sandholm/leveled.geb.pdf 212-270].</ref> [[macroeconomics]],<ref>• [[David Colander]], [[Peter Howitt]], Alan Kirman, [[Axel Leijonhufvud]], and [[Perry Mehrling]], 2008. \"Beyond DSGE Models: Toward an Empirically Based Macroeconomics,\" ''American Economic Review'', 98(2), pp. [https://www.jstor.org/pss/29730026 236]-240. Pre-pub [http://www.brown.edu/Departments/Economics/Faculty/Peter_Howitt/publication/complex%20macro6.pdf PDF].<br/>&nbsp;&nbsp; • [[Thomas J. Sargent]] (1994). ''Bounded Rationality in Macroeconomics'', Oxford. [http://www.oup.com/us/catalog/general/subject/Economics/MacroeconomicTheory/?view=usa&ci=9780198288695 Description] and chapter-preview 1st-page [https://www.questia.com/library/book/bounded-rationality-in-macroeconomics-thomas-j-sargent-by-thomas-j-sargent.jsp links].<br/>&nbsp;&nbsp; • M. Oeffner (2009). '[http://www.opus-bayern.de/uni-wuerzburg/volltexte/2009/3927/pdf/OeffnerDissohneAnhang.pdf Agent-based Keynesian Macroeconomics]'. PhD thesis, Faculty of Economics, University of Würzburg.</ref> and [[Marxist economics]].<ref>A. F. Cottrell, P. Cockshott, G. J. Michaelson, I. P. Wright, V. Yakovenko\n(2009), ''Classical Econophysics.'' Routledge, {{ISBN|978-0-415-47848-9}}.</ref><ref>Leigh Tesfatsion (2006), \"Agent-Based Computational Economics: A Constructive Approach to Economic Theory,\" ch. 16, ''Handbook of Computational Economics'', v. 2, part 2, ACE study of economic system. [http://www.sciencedirect.com/science/article/pii/S1574002105020162 Abstract] and pre-pub [http://econ2.econ.iastate.edu/tesfatsi/hbintlt.pdf PDF].</ref>\n\n==Overview==\nThe \"[[Agent (economics)|agents]]\" in ACE models can represent individuals (e.g. people), social groupings (e.g. firms), biological entities (e.g. growing crops), and/or physical systems (e.g. transport systems). The ACE modeler provides the initial configuration of a computational economic system comprising multiple interacting agents. The modeler then steps back to observe the development of the system over time without further intervention. In particular, system events should be driven by agent interactions without external imposition of equilibrium conditions.<ref>[http://www.socsci.aau.dk/ae2006/ Summary of methods] {{Webarchive|url=https://web.archive.org/web/20070526105550/http://www.socsci.aau.dk/ae2006/ |date=26 May 2007 }}: ''Department of Economics, Politics and Public Administration, Aalborg University, Denmark'' website.</ref> Issues include those common to [[experimental economics]] in general<ref>[[Vernon L. Smith]], 2008. \"experimental economics,\" ''The New Palgrave Dictionary of Economics'', 2nd Edition. [http://www.dictionaryofeconomics.com/article?id=pde2008_E000277&q=experimental%20&topicid=&result_number=2 Abstract].</ref> and development of a common framework for empirical validation and resolving open questions in agent-based modeling.<ref>Giorgio Fagiolo, Alessio Moneta, and Paul Windrum, 2007. \"A Critical Guide to Empirical Validation of Agent-Based Models in Economics: Methodologies, Procedures, and Open Problems,\" ''Computational Economics'', 30, pp. [http://www.springerlink.com/content/t683473172528275/ 195]–226.</ref>\n\nACE is an officially designated special interest group (SIG) of the Society for Computational Economics.<ref>[http://comp-econ.org/ Society for Computational Economics] website.</ref> Researchers at the [[Santa Fe Institute]] have contributed to the development of ACE.\n\n==Example: finance==\nOne area where ACE methodology has frequently been applied is asset pricing. [[W. Brian Arthur]], Eric Baum, [[William A. Brock (economist)|William Brock]], Cars Hommes, and Blake LeBaron, among others, have developed computational models in which many agents choose from a set of possible forecasting strategies in order to predict stock prices, which affects their asset demands and thus affects stock prices. These models assume that agents are more likely to choose forecasting strategies which have recently been successful. The success of any strategy will depend on market conditions and also on the set of strategies that are currently being used. These models frequently find that large booms and busts in asset prices may occur as agents switch across forecasting strategies.<ref name=arthuretal/><ref>W. Brock and C. Hommes (1997), 'A rational route to randomness.' ''Econometrica'' 65 (5), pp. 1059-1095.</ref><ref>C. Hommes (2008), 'Interacting agents in finance,' in ''The New Palgrave Dictionary of Economics''.</ref> More recently, Brock, Hommes, and Wagener (2009) have used a model of this type to argue that the introduction of new hedging instruments may destabilize the market,<ref>{{cite journal |first=W. |last=Brock |first2=C. |last2=Hommes |first3=F. |last3=Wagener |year=2009 |title=More hedging instruments may destabilize markets |journal=Journal of Economic Dynamics and Control |volume=33 |issue=11 |pages=1912–1928 |doi=10.1016/j.jedc.2009.05.004 }}</ref> and some papers have suggested that ACE might be a useful methodology for understanding the recent [[financial crisis]].<ref>M. Buchanan (2009), '[http://pagesperso-orange.fr/mark.buchanan/nature_economic_modelling.pdf Meltdown modelling. Could agent-based computer models prevent another financial crisis?].' Nature, Vol. 460, No. 7256. (5 August 2009), pp. 680-682.</ref><ref>J.D. Farmer, D. Foley (2009), 'The economy needs agent-based modelling.' Nature, Vol. 460, No. 7256. (5 August 2009), pp. 685-686.</ref><ref>M. Holcombe, S. Coakley, M.Kiran, S. Chin, C. Greenough, D.Worth, S.Cincotti, M.Raberto, A. Teglio, C. Deissenberg, S. van der Hoog, H. Dawid, S. Gemkow, P. Harting, M. Neugart. Large-scale Modeling of Economic Systems, Complex Systems, 22(2), 175-191, 2013</ref>\n\n==See also==\n* [[ACEGES]]\n* [[Agent-based social simulation]]\n* [[Artificial economics]]\n* [[Computational economics]]\n* [[Econophysics]]\n* [[Macroeconomic model]]\n* [[Multi-agent system]]\n* [[Statistical finance]]\n\n==References==\n{{Reflist|30em}}\n\n\n[[Category:Computational economics]]\n[[Category:Monte Carlo methods in finance]]\n[[Category:Computational fields of study]]"
    },
    {
      "title": "Brownian model of financial markets",
      "url": "https://en.wikipedia.org/wiki/Brownian_model_of_financial_markets",
      "text": "The [[Brownian motion]] models for [[financial markets]] are based on the work of [[Robert C. Merton]] and [[Paul A. Samuelson]], as extensions to the one-period market models of [[Harold Markowitz]] and [[William F. Sharpe]], and are concerned with defining the concepts of financial [[assets]] and [[financial markets|markets]], [[Portfolio (finance)|portfolios]], [[gain (accounting)|gain]]s and [[wealth]] in terms of continuous-time [[stochastic processes]].\n\nUnder this model, these assets have continuous prices evolving continuously in time and are driven by Brownian motion processes.<ref>{{Cite journal|last=Tsekov|first=Roumen|title=Brownian Markets|year=2013|journal=Chin. Phys. Lett.|pages=088901|volume=30|issue=8|doi =10.1088/0256-307X/30/8/088901|arxiv=1010.2061|bibcode=2013ChPhL..30h8901T}}</ref> This model requires an assumption of perfectly divisible assets and a [[frictionless market]] (i.e. that no transaction costs occur either for buying or selling). Another assumption is that asset prices have no jumps, that is there are no surprises in the market.  This last assumption is removed in [[jump diffusion]] models.\n\n==Financial market processes==\nConsider a financial market consisting of <math>N + 1 </math> financial assets, where one of these assets, called a ''[[Bond (finance)|bond]]'' or ''[[money market]]'', is [[risk]] free while the remaining <math>N</math> assets, called ''[[stock]]s'', are risky.\n\n===Definition===\nA ''financial market'' is defined as <math>\\mathcal{M} = (r,\\mathbf{b},\\mathbf{\\delta},\\mathbf{\\sigma},A,\\mathbf{S}(0)) </math> that satisfies the following:\n# A probability space <math>(\\Omega, \\mathcal{F}, P)</math>.\n# A time interval <math>[0,T]</math>.\n# A <math>D</math>-dimensional Brownian process <math>\\mathbf{W}(t) = (W_1(t) \\ldots W_D(t))', </math> where <math> \\; 0 \\leq t \\leq T</math> adapted to the augmented filtration  <math> \\{ \\mathcal{F}(t); \\; 0 \\leq t \\leq T \\} </math>.\n# A measurable risk-free money market rate process <math>r(t) \\in L_1[0,T] </math>.\n# A measurable mean rate of return process  <math>\\mathbf{b}: [0,T] \\times \\mathbb{R}^N \\rightarrow \\mathbb{R} \\in L_2[0,T] </math>.\n# A measurable dividend rate of return process <math>\\mathbf{\\delta}: [0,T] \\times \\mathbb{R}^N \\rightarrow \\mathbb{R} \\in L_2[0,T] </math>.\n# A measurable volatility process <math>\\mathbf{\\sigma}: [0,T] \\times \\mathbb{R}^{N \\times D} \\rightarrow \\mathbb{R}</math>,  such that <math> \\sum_{n=1}^N \\sum_{d=1}^D \\int_0^T \\sigma_{n,d}^2(s)ds < \\infty </math>.\n# A measurable, finite variation, singularly continuous stochastic <math> A(t)</math>.\n# The initial conditions given by <math>\\mathbf{S}(0) = (S_0(0),\\ldots S_N(0))'</math>.\n\n===The augmented filtration===\n\nLet <math>(\\Omega, \\mathcal{F}, p)</math> be a [[probability space]], and a\n<math>\\mathbf{W}(t) = (W_1(t) \\ldots W_D(t))', \\; 0 \\leq t \\leq T</math> be\nD-dimensional Brownian motion [[stochastic process]], with the [[natural filtration]]:\n\n:<math> \\mathcal{F}^\\mathbf{W}(t) \\triangleq \\sigma\\left(\\{\\mathbf{W}(s) ; \\; 0 \\leq s \\leq t\n\\}\\right), \\quad \\forall t \\in [0,T]. </math>\n\nIf <math>\\mathcal{N}</math> are the [[measure (probability)|measure]] 0 (i.e. null under\nmeasure <math>P</math>) subsets of <math>\\mathcal{F}^\\mathbf{W}(t)</math>, then define\nthe [[augmented filtration]]:\n\n:<math> \\mathcal{F}(t) \\triangleq \\sigma\\left(\\mathcal{F}^\\mathbf{W}(t) \\cup\n\\mathcal{N}\\right), \\quad \\forall t \\in [0,T] </math>\n\nThe difference between <math> \\{ \\mathcal{F}^\\mathbf{W}(t); \\; 0 \\leq t \\leq T \\}\n</math> and <math> \\{ \\mathcal{F}(t); \\; 0 \\leq t \\leq T \\} </math> is that the\nlatter is both [[continuous function#Directional continuity|left-continuous]], in the sense that:\n\n:<math> \\mathcal{F}(t) = \\sigma \\left( \\bigcup_{0\\leq s <t}  \\mathcal{F}(s)\n\\right),</math>\n\nand [[continuous function#Directional continuity|right-continuous]], such that:\n\n:<math> \\mathcal{F}(t) = \\bigcap_{t < s \\leq T}  \\mathcal{F}(s),</math>\n\nwhile the former is only left-continuous.<ref>{{Cite book |author1=Karatzas, Ioannis |author2=Shreve, Steven E. | title=Brownian motion and stochastic calculus | year=1991 | publisher=Springer-Verlag | location=New York  | isbn=0-387-97655-8 | pages=}}</ref>\n\n===Bond===\n\nA share of a bond (money market)  has price <math>S_0(t) > 0</math> at time\n<math>t</math> with <math>S_0(0)=1</math>, is continuous,  <math> \\{ \\mathcal{F}(t); \\; 0 \\leq t \\leq T \\} </math>  adapted, and has finite  [[Bounded variation|variation]]. Because it has finite variation, it can be decomposed into an [[Absolute continuity|absolutely continuous]] part <math>S^a_0(t)</math> and a singularly continuous part <math>S^s_0(t)</math>, by [[Lebesgue's decomposition theorem]]. Define:\n\n:<math>r(t) \\triangleq \\frac{1}{S_0(t)}\\frac{d}{dt}S^a_0(t),  </math> and\n\n:<math> A(t) \\triangleq \\int_0^t \\frac{1}{S_0(s)}dS^s_0(s), </math>\n\nresulting in the [[Stochastic differential equation|SDE]]:\n\n:<math>dS_0(t) = S_0(t)[r(t)dt + dA(t)], \\quad \\forall 0\\leq t \\leq T,  </math>\n\nwhich gives:\n:<math>S_0(t) = \\exp\\left(\\int_0^t r(s)ds + A(t)\\right), \\quad \\forall 0\\leq t \\leq T.  </math>\n\nThus, it can be easily seen that if <math>S_0(t)</math> is absolutely continuous (i.e. <math>A(\\cdot) = 0 </math>), then the price of the bond evolves like the value of a risk-free savings account with instantaneous interest rate <math>r(t)</math>, which is random, time-dependent and <math>\\mathcal{F}(t) </math> measurable.\n\n===Stocks===\nStock prices are modeled as being similar to that of bonds, except with a randomly fluctuating component (called its [[Volatility (finance)|volatility]]).  As a premium for the risk originating from these random fluctuations, the mean rate of return of a stock is higher than that of a bond.\n\nLet <math> S_1(t) \\ldots S_N(t) </math> be the strictly positive prices per share of the <math> N</math> stocks, which are continuous stochastic processes satisfying:\n\n:<math> dS_n(t) = S_n(t)\\left[b_n(t)dt + dA(t) + \\sum_{d=1}^D \\sigma_{n,d}(t)dW_d(t)\\right] , \\quad \\forall 0\\leq t \\leq T, \\quad n = 1 \\ldots N.    </math>\n\nHere, <math>\\sigma_{n,d}(t), \\; d=1\\ldots D</math> gives the volatility of the <math>n</math>-th stock, while <math>b_n(t)</math> is its mean rate of return.\n\nIn order for an [[arbitrage]]-free pricing scenario, <math>A(t)</math> must be as defined above.  The solution to this is:\n\n:<math> S_n(t) = S_n(0)\\exp\\left(\\int_0^t \\sum_{d=1}^D \\sigma_{n,d}(s)dW_d(s) + \\int_0^t \\left[b_n(s) - \\frac{1}{2}\\sum_{d=1}^D \\sigma^2_{n,d}(s)\\right]ds  + A(t)\\right), \\quad \\forall 0\\leq t \\leq T, \\quad n = 1 \\ldots N,  </math>\n\nand the discounted stock prices are:\n\n:<math> \\frac{S_n(t)}{S_0(t)} = S_n(0)\\exp\\left(\\int_0^t \\sum_{d=1}^D \\sigma_{n,d}(s)dW_d(s) + \\int_0^t \\left[b_n(s) - \\frac{1}{2}\\sum_{d=1}^D \\sigma^2_{n,d}(s)\\right]ds )\\right), \\quad \\forall 0\\leq t \\leq T, \\quad n = 1 \\ldots N.  </math>\n\nNote that the contribution due to the discontinuites in the bond price <math> A(t) </math> does not appear in this equation.\n\n===Dividend rate===\n\nEach stock may have an associated [[dividend]] rate process <math>\\delta_n(t)</math> giving the rate of dividend payment per unit price of the stock at time <math>t</math>. Accounting for this in the model, gives the ''yield'' process <math>Y_n(t) </math>:\n\n:<math> dY_n(t) = S_n(t)\\left[b_n(t)dt + dA(t) + \\sum_{d=1}^D \\sigma_{n,d}(t)dW_d(t) + \\delta_n(t)\\right] , \\quad \\forall 0\\leq t \\leq T, \\quad n = 1 \\ldots N.   </math>\n\n==Portfolio and gain processes==\n\n===Definition===\nConsider a financial market <math>\\mathcal{M} = (r,\\mathbf{b},\\mathbf{\\delta},\\mathbf{\\sigma}, A,\\mathbf{S}(0)) </math>.\n\nA ''portfolio process'' <math>(\\pi_0, \\pi_1, \\ldots \\pi_N) </math> for this market is an <math>\\mathcal{F}(t) </math> measurable, <math>\\mathbb{R}^{N+1} </math> valued process such that:\n\n:<math>\\int_{0}^T | \\sum_{n=0}^N\\pi_n(t)| \\left[|r(t)|dt + dA(t) \\right] < \\infty </math>, [[almost surely]],\n\n:<math>\\int_{0}^T |\\sum_{n=1}^N\\pi_n(t)[b_n(t) + \\mathbf{\\delta}_n(t) - r(t)]| dt < \\infty </math>, almost surely, and\n\n:<math>\\int_{0}^T \\sum_{d=1}^D|\\sum_{n=1}^N\\mathbf{\\sigma}_{n,d}(t)\\pi_n(t)|^2 dt < \\infty </math>, almost surely.\n\nThe ''gains process'' for this portfolio is:\n:<math>G(t) \\triangleq \\int_0^t \\left[\\sum_{n=0}^N\\pi_n(t)\\right]\\left(r(s)ds + dA(s)\\right) + \\int_0^t \\left[\\sum_{n=1}^N\\pi_n(t)\\left(b_n(t) + \\mathbf{\\delta}_n(t) - r(t)\\right)\\right]dt + \\int_{0}^t \\sum_{d=1}^D\\sum_{n=1}^N\\mathbf{\\sigma}_{n,d}(t)\\pi_n(t) dW_d(s) \\quad 0 \\leq t \\leq T</math>\n\nWe say that the portfolio is ''[[Self-financing portfolio|self-financed]]'' if:\n\n:<math>G(t) = \\sum_{n=0}^N \\pi_n(t) </math>.\n\nIt turns out that for a self-financed portfolio, the appropriate value of <math>\\pi_0</math> is determined from <math>\\pi =(\\pi_1, \\ldots \\pi_N) </math> and therefore sometimes <math>\\pi</math> is referred to as the portfolio process. Also, <math>\\pi_0 < 0</math> implies borrowing money from the money-market, while <math>\\pi_n < 0</math> implies taking a [[short position]] on the stock.\n\nThe term <math>b_n(t) + \\mathbf{\\delta}_n(t) - r(t)</math> in the SDE of <math>G(t)</math> is the ''[[risk premium]]'' process, and it is the compensation received in return for investing in the <math>n</math>-th stock.\n\n===Motivation===\n\nConsider time intervals <math>0 = t_0 < t_1 < \\ldots < t_M = T </math>, and let <math>\\nu_n(t_m) </math> be the number of shares of asset <math>n = 0 \\ldots N </math>, held in a portfolio during time interval at time <math>[t_m,t_{m+1} \\; m = 0 \\ldots M-1 </math>. To avoid the case of [[insider trading]] (i.e. foreknowledge of the future), it is required that <math>\\nu_n(t_m) </math> is <math>\\mathcal{F}(t_m) </math> measurable.\n\nTherefore, the incremental gains at each trading interval from such a portfolio is:\n\n:<math> G(0) = 0, </math>\n:<math> G(t{m+1}) - G(t_m) = \\sum_{n=0}^N \\nu_n(t_m) [Y_n(t_{m+1}) - Y_n(t_m)] , \\quad m = 0 \\ldots M-1, </math>\n\nand <math>G(m)</math> is the total gain over time <math>[0,t_m]</math>, while the total value of the portfolio is <math>\\sum_{n=0}^N \\nu_n(t_m)S_n(t_m)</math>.\n\nDefine <math>\\pi_n(t) \\triangleq \\nu_n(t) </math>, let the time partition go to zero, and substitute for <math>Y(t)</math> as defined earlier, to get the corresponding SDE for the gains process. Here <math>\\pi_n(t) </math> denotes the dollar amount invested in asset <math>n </math> at time <math>t </math>, not the number of shares held.\n\n==Income and wealth processes==\n\n===Definition===\nGiven a financial market <math>\\mathcal{M}</math>, then a ''cumulative income process'' <math>\\Gamma(t) \\; 0 \\leq t \\leq T </math> is a [[semimartingale]] and represents the income accumulated over time <math>[0,t]</math>, due to sources other than the investments in the <math>N+1</math> assets of the financial market.\n\nA ''wealth process'' <math>X(t)</math> is then defined as:\n\n:<math>X(t) \\triangleq G(t) + \\Gamma(t) </math>\n\nand represents the total wealth of an investor at time <math>0 \\leq t \\leq T</math>. The portfolio is said to be ''<math>\\Gamma(t)</math>-financed'' if:\n\n:<math>X(t) = \\sum_{n=0}^N \\pi_n(t).</math>\n\nThe corresponding SDE for the wealth process, through appropriate substitutions, becomes:\n\n<math>dX(t) = d\\Gamma(t) + X(t)\\left[r(t)dt + dA(t)\\right]+ \\sum_{n=1}^N \\left[ \\pi_n(t) \\left( b_n(t) + \\delta_n(t) - r(t) \\right) \\right] + \\sum_{d=1}^D \\left[\\sum_{n=1}^N \\pi_n(t) \\sigma_{n,d}(t)\\right]dW_d(t)</math>.\n\nNote, that again in this case, the value of <math>\\pi_0</math> can be determined from <math>\\pi_n, \\; n = 1 \\ldots N</math>.\n\n==Viable markets==\nThe standard theory of mathematical finance is restricted to viable financial markets, i.e. those in which there are no opportunities for [[arbitrage]]. If such opportunities exists, it implies the possibility of making an arbitrarily large risk-free profit.\n\n===Definition===\nIn a financial market <math>\\mathcal{M}</math>, a self-financed portfolio process <math>\\pi(t)</math> is considered to be an ''[[arbitrage]] opportunity'' if the associated gains process <math>G(T)\\geq 0</math>, almost surely and <math> P[G(T) > 0] > 0</math> strictly. A market <math> \\mathcal{M}</math> in which no such portfolio exists is said to be ''viable''.\n\n===Implications===\nIn a viable market <math>\\mathcal{M}</math>, there exists a <math>\\mathcal{F}(t)</math> adapted process <math>\\theta :[0,T] \\times \\mathbb{R}^D \\rightarrow \\mathbb{R}</math> such that for almost every <math> t \\in [0,T]</math>:\n\n:<math>b_n(t) + \\mathbf{\\delta}_n(t) - r(t) = \\sum_{d=1}^D \\sigma_{n,d}(t) \\theta_d(t)</math>.\n\nThis <math>\\theta</math> is called the ''market price of risk'' and relates the premium for the <math>n</math>-the stock with its volatility <math>\\sigma_{n,\\cdot}</math>.\n\nConversely, if there exists a D-dimensional process <math>\\theta(t)</math> such that it satisfies the above requirement, and:\n\n:<math> \\int_0^T \\sum_{d=1}^D |\\theta_d(t)|^2 dt < \\infty</math>\n:<math>\\mathbb{E}\\left[ \\exp\\left\\{ -\\int_0^T \\sum_{d=1}^D \\theta_d(t)dW_d(t) - \\frac{1}{2}\\int_0^T \\sum_{d=1}^D |\\theta_d(t)|^2 dt \\right\\} \\right] = 1 </math>,\n\nthen the market is viable.\n\nAlso, a viable market <math>\\mathcal{M}</math> can have only one money-market (bond) and hence only one risk-free rate. Therefore, if the <math>n</math>-th stock entails no risk (i.e.  <math>\\sigma_{n,d}=0, \\; d = 1 \\ldots D</math>) and pays no dividend (i.e.<math>\\delta_n(t)=0</math>), then its rate of return is equal to the money market rate (i.e. <math>b_n(t) = r(t)</math>) and its price tracks that of the bond (i.e. <math>S_n(t) = S_n(0)S_0(t)</math>).\n\n==Standard financial market==\n\n===Definition===\nA financial market <math>\\mathcal{M}</math> is said to be ''standard'' if:\n:(i) It is viable.\n:(ii) The number of stocks <math>N</math> is not greater than the dimension <math>D</math> of the underlying Brownian motion process <math>\\mathbf{W}(t)</math>.\n:(iii) The market price of risk process <math>\\theta</math> satisfies:\n::<math>\\int_0^T \\sum_{d=1}^D |\\theta_d(t)|^2 dt < \\infty</math>, almost surely.\n:(iv) The positive process <math>Z_0(t) = \\exp\\left\\{ -\\int_0^t \\sum_{d=1}^D \\theta_d(t)dW_d(t) - \\frac{1}{2}\\int_0^t \\sum_{d=1}^D |\\theta_d(t)|^2 dt \\right\\} </math> is a [[Martingale (probability theory)|martingale]].\n\n===Comments===\nIn case the number of stocks <math>N</math> is greater than the dimension <math>D</math>, in violation of point (ii), from linear algebra, it can be seen that there are <math>N-D</math> stocks  whose volatilies (given by the vector <math>(\\sigma_{n,1} \\ldots \\sigma_{n,D})</math>) are linear combination of the volatilities of <math>D</math> other stocks (because the rank of <math>\\sigma</math> is <math>D</math>). Therefore, the <math>N</math> stocks can be replaced by <math>D</math> equivalent mutual funds.\n\nThe ''standard martingale measure'' <math>P_0</math> on <math> \\mathcal{F}(T)</math> for the standard market, is defined as:\n:<math>P_0(A) \\triangleq \\mathbb{E}[Z_0(T)\\mathbf{1}_A], \\quad \\forall A \\in  \\mathcal{F}(T)</math>.\n\nNote that <math>P</math> and <math>P_0</math> are [[absolutely continuous]] with respect to each other, i.e. they are equivalent. Also, according to [[Girsanov's theorem]],\n\n:<math>\\mathbf{W}_0(t) \\triangleq \\mathbf{W}(t) + \\int_0^t \\theta(s)ds  </math>,\n\nis a <math>D</math>-dimensional Brownian motion process on the filtration <math> \\{\\mathcal{F}(t); \\; 0 \\leq t \\leq T\\}</math> with respect to <math>P_0</math>.\n\n==Complete financial markets==\nA complete financial market is one that allows effective [[hedge (finance)|hedging]] of the risk inherent in any investment strategy.\n\n===Definition===\nLet <math>\\mathcal{M}</math> be a standard financial market, and <math>B</math> be an <math> \\mathcal{F}(T)</math>-measurable random variable, such that:\n\n:<math>P_0\\left[\\frac{B}{S_0(T)} > -\\infty \\right] = 1 </math>.\n\n:<math> x \\triangleq \\mathbb{E}_0\\left[\\frac{B}{S_0(T)} \\right] < \\infty </math>,\n\nThe market <math>\\mathcal{M}</math> is said to be ''complete'' if every such <math>B</math> is ''financeable'', i.e. if there is an <math>x</math>-financed portfolio process <math>(\\pi_n(t); \\; n = 1 \\ldots N)</math>, such that its associated wealth process <math>X(t)</math> satisfies\n\n:<math>X(t) = B</math>, almost surely.\n\n===Motivation===\nIf a particular investment strategy calls for a payment <math>B</math> at time <math>T</math>, the amount of which is unknown at time <math>t=0</math>, then a conservative strategy would be to set aside an amount <math>x = \\sup_\\omega B(\\omega)</math> in order to cover the payment. However, in a complete market it is possible to set aside less capital (viz. <math>x</math>) and invest it so that at time <math>T</math> it has grown to match the size of <math>B</math>.\n\n===Corollary===\nA standard financial market <math>\\mathcal{M}</math> is complete if and only if <math>N=D</math>, and the <math>N \\times D</math> volalatily process <math> \\sigma(t)</math> is non-singular for almost every <math>t \\in [0,T]</math>, with respect to the [[Lebesgue measure]].\n\n==See also==\n*[[Black-Scholes model]]\n*[[Martingale pricing]]\n*[[Mathematical finance]]\n*[[Monte Carlo method]]\n\n==Notes==\n<references/>\n\n==References==\n{{Cite book |author1=Karatzas, Ioannis |author2=Shreve, Steven E. | title=Methods of mathematical finance | year=1998 |\npublisher=Springer | location=New York  | isbn=0-387-94839-2 | pages=}}\n\n{{Cite book |author1=Korn, Ralf |author2=Korn, Elke |\ntitle=Option pricing and portfolio optimization: modern methods of financial mathematics | year=2001 | publisher=American Mathematical Society |\nlocation=Providence, R.I.  | isbn=0-8218-2123-7 | pages=}}\n\n{{Cite journal| first = R. C. | authorlink1 = Robert C. Merton| title = Lifetime Portfolio Selection under Uncertainty: the Continuous-Time Case | journal = The Review of Economics and Statistics | volume = 51| issue = 3| last = Merton | pages = 247–257| date = 1 August 1969 | issn = 0034-6535 | doi = 10.2307/1926560| jstor =  1926560 }}\n\n{{Cite journal|url=http://www.math.uwaterloo.ca/~mboudalh/Merton1971.pdf |title=Optimum consumption and portfolio rules in a continuous-time model |year=1970 |author=Merton, R.C. |journal=Journal of Economic Theory |pages=373–413 |volume=3 |issue=4 |doi=10.1016/0022-0531(71)90038-x |format=PDF |accessdate=2009-05-29 }}{{dead link|date=June 2016|bot=medic}}{{cbignore|bot=medic}}\n\n{{DEFAULTSORT:Brownian Model Of Financial Markets}}\n[[Category:Financial models]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Credit valuation adjustment",
      "url": "https://en.wikipedia.org/wiki/Credit_valuation_adjustment",
      "text": "'''Credit valuation adjustment''' ('''CVA''') is the difference between the risk-free portfolio value and the true [[Portfolio (finance)|portfolio value]] that takes into account the possibility of a [[counterparty]]’s default. In other words, CVA is the [[market value]] of [[Counterparty risk|counterparty credit risk]]. This price depends on counterparty credit spreads as well as on the market risk factors that drive derivatives’ values and, therefore, exposure. CVA is one of a family of related valuation adjustments, collectively [[xVA]];  for further context here see [[Financial economics #Derivative pricing]].\n\nUnilateral CVA is given by the [[risk-neutral]] expectation of the discounted loss. The risk-neutral expectation can be written as\n\n: <math> \\mathrm{CVA(T)} = E^Q[L^*] = (1-R)\\int_0^T E^Q\\left[\\frac{B_0}{B_t} E(t)|t=\\tau\\right] d\\mathrm{PD}(0,t) </math>\n\nwhere <math>T</math>&nbsp; is the [[Maturity (finance)|maturity]] of the longest transaction in the portfolio, <math> B_t </math> is the future value of one unit of the [[base currency]] invested today at the prevailing interest rate for maturity <math>t</math>, <math>R</math> is the fraction of the portfolio value that can be recovered in case of a default, <math>\\tau</math> is the time of default, <math>E(t)</math> is the exposure at time <math>t</math>, and <math> \\mathrm{PD}(s,t)</math> is the risk neutral probability of counterparty default between times <math>s</math> and <math>t</math>. These probabilities can be obtained from the term structure of [[credit default swap]] (CDS) spreads.\n\nMore generally CVA can refer to a few different concepts:\n* The mathematical concept as defined above;\n* A part of the regulatory Capital and RWA ([[Risk-weighted asset]]) calculation introduced under [[Basel 3]];\n* The CVA desk of an investment bank, whose purpose is to:\n** hedge for possible losses due to counterparty default;\n** hedge to reduce the amount of capital required under the CVA calculation of Basel 3;\n* The \"CVA charge\". The hedging of the CVA desk has a cost associated to it, i.e. the bank has to buy the hedging instrument. This cost is then allocated to each business line of an investment bank (usually as a contra revenue). This allocated cost is called the \"CVA Charge\".\n\nAccording to the [[Basel Committee on Banking Supervision]]'s July 2015 consultation document regarding CVA calculations, if CVA is calculated using 100 timesteps with 10,000 scenarios per timestep, 1 million simulations are required to compute the value of CVA. Calculating CVA risk would require 250 daily market risk scenarios over the 12-month stress period. CVA has to be calculated for each market risk scenario, resulting in 250 million simulations. These calculations have to be repeated across 6 risk types and 5 liquidity horizons, resulting in potentially 8.75 billion simulations. <ref>{{cite web|url=http://fixglobal.com/home/the-triple-convergence-of-credit-valuation-adjustment-cva/|author=Alvin Lee|title=The Triple Convergence Of Credit Valuation Adjustment (CVA)|publisher=Global Trading|date=17 August 2015}}</ref>\n\n==Exposure, independent of counterparty default==\n\nAssuming independence between exposure and counterparty’s [[credit quality]] greatly simplifies the analysis. Under this assumption this simplifies to\n\n: <math> \\mathrm{CVA} = (1-R) \\int_0^T \\mathrm{EE}^*(t)~d\\mathrm{PD}(0,t) </math>\n\nwhere <math>\\mathrm{EE}^*</math> is the risk-neutral discounted expected exposure (EE)\n\n== Approximation ==\nFull calculation of CVA is done via [[Monte-Carlo simulation]] of all risk factors which is very computationally demanding. There exists a simple approximation for CVA which consists in buying just one default protection (Credit Default Swap) for amount of NPV of netted set of derivatives for each counterparty.[http://www.pricederivatives.com/en/simple-cva-calculation-example-credit-valuation-adjustment-excel/]\n\n==Function of the CVA desk and implications for technology==\n{{POV-check|section|date=July 2012}}\nIn the view of leading [[Investment banking|investment banks]], CVA is essentially an activity carried out by both finance and a trading desk in the Front Office.  Tier 1 banks either already generate counterparty EPE and ENE (expected positive/negative exposure) under the ownership of the CVA desk (although this often has another name) or plan to do so.  Whilst a CVA platform is based on an exposure measurement platform, the requirements of an active CVA desk differ from those of a Risk Control group and it is not uncommon to see institutions use different systems for risk exposure management on one hand and CVA pricing and hedging on the other. \n\nA good introduction can be found in a paper by Michael Pykhtin and Steven Zhu.<ref>A Guide to Modeling Counterparty Credit Risk, GARP Risk Review,July-August 2007 [http://ssrn.com/abstract_id=1032522 Related SSRN Research Paper]</ref>\nKarlsson et al. (2016) present a numerical efficient method for calculating expected exposure, potential future exposure and CVA for interest rate derivatives, in particular Bermudan [[swaptions]].<ref> Patrik Karlsson, Shashi Jain. and Cornelis W. Oosterlee. Counterparty Credit Exposures for Interest Rate Derivatives using the Stochastic Grid Bundling Method. Applied Mathematical Finance. Forthcoming 2016. [https://dx.doi.org/10.1080/1350486X.2016.1226144]</ref>\n\n== See also ==\n* [[Potential future exposure]]\n\n==References==\n{{Reflist}}\n{{refbegin}}\n{{refend}}\n\n[[Category:Actuarial science]]\n[[Category:Mathematical finance]]\n[[Category:Credit risk]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Datar–Mathews method for real option valuation",
      "url": "https://en.wikipedia.org/wiki/Datar%E2%80%93Mathews_method_for_real_option_valuation",
      "text": "The '''Datar–Mathews method''' <ref>Mathews, S. H., Datar, V. T., and Johnson, B. 2007. [http://onlinelibrary.wiley.com/doi/10.1111/j.1745-6622.2007.00140.x/abstract A practical method for valuing real options]. [[Journal of Applied Corporate Finance]] 19(2): 95–104.</ref> ('''DM method'''<ref>U.S. Patent No. 6,862,579 (issued March 1, 2005). The DM Method and related technologies are available for licensing from Boeing.</ref>) is a method for [[real options valuation]]. The method provides an easy way to determine the real option value of a project simply by using the average of positive outcomes for the project. The method can be understood as an extension of the [[net present value]] (NPV) multi-scenario [[Monte Carlo model]] with an adjustment for [[risk aversion]] and economic decision-making. The method uses information that arises naturally in a standard [[discounted cash flow]] (DCF), or [[net present value|NPV]], project financial valuation.  It was created in 2000 by Professor Vinay Datar, [[Seattle University]], and Scott H. Mathews, [[Boeing Technical Fellowship|Technical Fellow]], [[The Boeing Company]].\n\n==Method==\n[[Image:Datar Mathews Real Option Method Wikipedia Fig 1 Typical Project Cash Flow with Uncertainty.jpg|thumb|right|Fig. 1 Typical project cash flow with uncertainty]]\nThe mathematical equation for the DM method is shown below. The method captures the real option value by discounting the [[Probability distribution|distribution]] of [[operating profit]]s at ''µ'', the market risk rate, and discounting the distribution of the discretionary investment at ''r'', risk-free rate, ''before'' the expected payoff is calculated.  The option value is then the expected value of the maximum of the difference between the two discounted distributions or zero. Fig. 1.\n\n:<math>C_0 = E_0\\left[\\max\\left(S_Te^{-\\mu t}-X_Te^{-rt},0\\right)\\right]</math>\n* ''S<sub>T</sub>'' is a [[random variable]] representing the future benefits, or operating profits at time ''T''. The [[present value|present valuation]] of ''S''<sub>''T''</sub> uses ''μ'', a discount rate consistent with the risk level of ''S''<sub>''T''</sub>. ''μ'' is the [[required rate of return]] for participation in the target market, sometimes termed the [[Minimum acceptable rate of return|hurdle rate]].\n* ''X<sub>T</sub>'' is a random variable representing the [[strike price]]. The present valuation of ''X<sub>T</sub>'' uses ''r'', the rate consistent with the risk of investment, ''X''<sub>''T''</sub> .  In many generalized option applications, the risk-free discount rate is used. However other discount rates can be considered, such as the corporate bond rate, particularly when the application is a risky corporate product development project.\n* ''C''<sub>0</sub>  is the real option value for a single stage project. The option value can be understood as the expected value of the difference of two present value distributions with an economically rational threshold limiting losses on a risk-adjusted basis.\n\nThe differential discount rate for ''μ'' and ''r'' implicitly allows the DM Method to account for the underlying risk. If  ''μ'' > ''r'', then the option will be [[risk-averse]], typical for both financial and real options. If  ''μ'' < ''r'', then the option will be risk-seeking. If ''μ'' = ''r'', then this is termed a [[risk-neutral]] option, and has parallels with NPV-type analyses with decision-making, such as [[decision tree]]s.  The DM Method gives the same results as the [[Black–Scholes]] and the [[Binomial options pricing model|binomial lattice]] option models, provided the same inputs and the discount methods are used. This non-traded real option value therefore is dependent on the risk perception of the evaluator toward a market asset relative to a privately held investment asset.\n\nThe DM method is advantageous for use in real option applications because unlike some other option models it does not require a value for ''sigma'' (a measure of uncertainty) or for ''S''<sub>0</sub> (the value of the project today), both of which are difficult to derive for new product development projects; see [[Real options valuation#Technical considerations|further]] under [[real options valuation]]. Finally, the DM method uses real-world values of [[List of probability distributions|any distribution type]], avoiding the requirement for conversion to risk-neutral values and the restriction of a [[lognormal distribution]];<ref>Datar, Vinay T. and Mathews, Scott H., 2004. [http://papers.ssrn.com/sol3/papers.cfm?abstract_id=560982 European Real Options: An Intuitive Algorithm for the Black–Scholes Formula]. [[Journal of Applied Finance]] 14(1): 7–13</ref> see [[Monte Carlo methods for option pricing#Application|further]] under [[Monte Carlo methods for option pricing]].\n\nExtensions of the method for other real option valuations have been developed such as contract guarantee (put option), Multi-Stage ([[compound option]]), Early Launch (American option), and others.\n\n==Implementation==\n[[Image:Datar Mathews Real Option Method Wikipedia Fig 2A Net Profit Present Value Distribution.jpg|thumb|right|Fig. 2A Net profit present-value distribution]]\n[[Image:Datar Mathews Real Option Method Wikipedia Fig 2B Rational Decision Distribution.jpg|thumb|right|Fig. 2B Rational decision distribution]]\n[[Image:Datar Mathews Real Option Method Wikipedia Fig 2C Payoff Distribution and Option Value.jpg|thumb|right|Fig. 2C Payoff distribution and option value]]\n[[Image:Datar Mathews Real Option Method Wikipedia Fig 3 Range Option Calculation Procedure.png|thumb|left|500x250px|Fig. 3 Range option calculation procedure]]\nThe method may be implemented using [[Monte-Carlo simulation]], or in a simplified, approximate form (the DM range option).\n\nUsing simulation, for each sample, the engine draws a random variable from both ''S<sub>T</sub>'' and ''X<sub>T</sub>'', calculates their present values, and takes the difference.<ref>[https://books.google.com/books?id=Z9xGYj7_uFgC&printsec=frontcover&dq=Tutorials+in+Operations+Research+2007&hl=en&ei=q7EGTpWlCZC6sAPrm7TGDQ&sa=X&oi=book_result&ct=result&resnum=1&ved=0CDMQ6AEwAA#v=onepage&q&f=false Business Engineering: A Practical Approach to Valuing High-Risk, High-Return Projects Using Real Options] Tutorials in Operations Research 2007, Operations Research Tools and Applications: Glimpses of Future Technologies, p157–175</ref><ref>[http://www.vwl.uni-freiburg.de/fakultaet/wt/data/downloads/general/1%20Agliardi%20-%20Mathews%20and%20Salmon.pdf Business Engineering: A Practical Approach to Valuing High-Risk, High-Return Projects Using Real Options] [[INFORMS]] Annual Meeting, November 4–7, 2007</ref> Fig. 2A. The difference value is compared to zero, the maximum of the two is determined, and the resulting value recorded by the simulation engine. Here, reflecting the optionality inherent in the project, a forecast of a net negative value outcome corresponds to an abandoned project, and has a zero value. Fig. 2B. The resulting values create a payoff distribution representing the economically rational set of plausible, discounted value forecasts of the project at time ''t''<sub>0</sub>.\n\nWhen sufficient payoff values have been recorded, typically a few hundred, then the mean, or expected value, of the payoff distribution is calculated. Fig. 2C. The option value is the expected value, the first moment of all positive NPVs, of the payoff distribution.\n\nA simple interpretation is:\n:<math>\\text{Real option value} = \\text{average} \\left[\\max\\left(\\text{operating profit}-\\text{launch costs}\\right),0)\\right]</math>\nwhere ''operating profit'' and ''launch costs'' are the appropriately discounted range of cash flows to time ''t''<sub>0</sub>.\n<ref>Mathews, Scott H., 2009.\n[http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4937494 Tutorial CIFER-T2 Boeing's method for valuing high-risk high-return technology projects using real options]. [[IEEE]] Symposium on Computational Intelligence for Financial Engineering, 2009.</ref>\n\nThe [[Sampling (statistics)|sampled]] [[Probability distribution|distributions]] may take any form, although the [[triangular distribution]] is often used, [[Triangular distribution#Business simulations|as is typical for low data situations]].  Here, the mean value corresponds to the “most likely” scenario, typically the same as for the NPV case. Two other scenarios, “pessimistic” and “optimistic”, represent plausible deviations from the most likely scenario (often modeled as approximating a 1-out-of-20, or 1-out-of-10 likelihood). This range of probabilistic cases tends to be within the organizational memory bounds of the corporation.\n\nAn approximate but conservative option value, termed the DM Range Option, can be estimated simply using range estimates of the present values of operating profit and launch costs.<ref>[http://www.iriweb.org/Public_Site/RTM/Volume_52_Year_2009/September-October2009RTM/Valuing_Risky_Projects_with_Real_Options.aspx Valuing risky projects with real options]. [[Research-Technology Management]] Volume 52 Number 5</ref> Fig. 3. As described, a range is an estimate of a maximum, most-likely (or mode) and minimum (or Optimistic, Most-Likely, Pessimistic) values that circumscribe a triangular distribution. The two distributions are then combined, and, similar to the approach for simulation described, the expected value is the [[Moment (mathematics)|first moment]] of all positive NPVs.  Here, using equations from triangular distributions, the mean of the launch cost distribution is calculated. The present value imputed net profit distribution is the difference between the operating profit distribution and the mean value of the launch cost distribution. In one implementation, the approximate option value is the product of the mean and the probability of the payoff distribution right triangle, the positive value right tail. The DM Range Option requires no simulation. This approach is useful for early-stage estimates of project option value when there has not been sufficient time or resources to gather the necessary quantitative information required for a complete cash flow simulation, or in a portfolio of projects when simulation of all the projects is too computationally demanding.<ref>[http://www.iriweb.org/Public_Site/RTM/Volume_54_Year_2011/September-October2011/Innovation_Portfolio_Architecture_-_Part2.aspx Innovation Portfolio Architecture – Part 2: Attribute Selection and Valuation]. [[Research-Technology Management]] Vol. 54, No. 5 September–October 2011</ref> If the launch cost is a scalar value, then the range option value calculation is exact. The range option method is similar to the [[fuzzy pay-off method for real option valuation|fuzzy method for real options]].\n\n==Interpretation==\nUnder certain constraints, the framework of a project investment problem structured for the Datar–Mathews Method can be converted to an equivalent framework structured for the [[Black–Scholes#Black–Scholes formula|Black–Scholes formula]]. Figure 4, Left. The [[Black–Scholes]] (as well as the [[Binomial options pricing model|binomial lattice]]) option pricing model is constrained to a lognormal distribution for the asset value, ''S'', typical of traded financial options, and requires a value for ''S''<sub>0</sub>, the asset value at time ''t''<sub>0</sub>, and ''sigma'' (''σ''<sub>0</sub>), a measure of volatility of the asset. Assume a project investment problem at time ''T'', and a forecasted lognormal asset value distribution with mean ''S<sub>T</sub>'' and standard deviation ''σ<sub>T</sub>''. The equivalent Black–Scholes values are:\n\n:<math>S_0 = S_Te^{-\\mu T}\\text{ and }\\sigma_0=\\frac{\\sqrt{\\ln\\left(1+\\left(\\frac{\\sigma_T}{S_T}\\right )^2\\right)}}{\\sqrt{T}}.</math>\n\nThe terms ''N''(''d''<sub>1</sub>) and ''N''(''d''<sub>2</sub>) are applied [[Black–Scholes#Black–Scholes formula|in the calculation of the Black–Scholes formula]], and are expressions related to operations on lognormal distributions;<ref name=\"Chance 99-02\">Don Chance (2011). [http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN99-02.pdf  ''Derivation and Interpretation of the Black–Scholes Model''].</ref> see section [[Black–Scholes#Interpretation|\"Interpretation\"]] under [[Black–Scholes]]. The Datar–Mathews method does not use ''N''(''d''<sub>1</sub>) or ''N''(''d''<sub>2</sub>), but instead typically solves the option problem by means of Monte Carlo simulation applicable to many different types of distributions inherent in real option contexts. When the Datar–Mathews method is applied to assets with lognormal distributions, it becomes possible to visualize graphically the operation of ''N''(''d''<sub>1</sub>) and ''N''(''d''<sub>2</sub>).\n[[Image:Datar Mathews Real Option Method Wikipedia Fig 4 Comparison of Black-Scholes and Datar-Mathews frameworks.png|thumb|right|550x300px|Fig. 4 Left: Comparison of Black–Scholes and Datar–Mathews frameworks. Right: Detail of tail distribution at ''t''<sub>0</sub>]]\n\n''N''(''d''<sub>2</sub>) is a measure of the area of the [[Probability distribution#Basic terms|tail of the distribution]] relative to that of the entire distribution, e.g. the probability of tail of the distribution, at time ''t''<sub>0</sub>.  The tail of the distribution is delineated by {{math| ''X''<sub>''t''<sub>0</sub></sub> {{=}} ''X''<sub>''T''</sub>e<sup>&nbsp;−&nbsp;''rT''</sup>}}, the present value of the strike price. Figure 4, Right.  The true probability of expiring in-the-money in the real (“physical”) world is calculated at time ''T'', the launch date, measured by area of the tail of the distribution delineated by ''X<sub>T</sub>''. ''N''(''d''<sub>1</sub>) is the value of the option payoff relative to that of the asset; {{math| ''N''(''d''<sub>1</sub>) {{=}} [''MT'' × ''N''(''d''<sub>2</sub>)]/''S''<sub>0</sub>}}, where ''MT'' is the mean of the tail at time ''t''<sub>0</sub>. Using the DM Method, the value of a call option can be understood as {{math| ''C''<sub>0</sub> {{=}} (''MT'' − ''X''<sub>''t''<sub>0</sub></sub>) × ''N''(''d''<sub>2</sub>)}}.\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://onlinelibrary.wiley.com/doi/10.1111/j.1745-6622.2007.00140.x/abstract A Practical Method for Valuing Real Options: The Boeing Approach]\n\n{{DEFAULTSORT:Datar-Mathews}}\n[[Category:Real options]]\n[[Category:Monte Carlo methods in finance]]\n[[Category:Financial models]]"
    },
    {
      "title": "Expected shortfall",
      "url": "https://en.wikipedia.org/wiki/Expected_shortfall",
      "text": "'''Expected shortfall''' ('''ES''') is a [[risk measure]]—a concept used in the field of financial risk measurement to evaluate the [[market risk]] or [[credit risk]] of a portfolio. The \"expected shortfall at q% level\" is the expected return on the portfolio in the worst <math>q</math>% of cases. ES is an alternative to [[value at risk]] that is more sensitive to the shape of the tail of the loss distribution.\n\nExpected shortfall is also called '''conditional value at risk''' ('''CVaR'''), '''average value at risk''' ('''AVaR'''), and '''expected tail loss''' ('''ETL''').\n\nES estimates the risk of an investment in a conservative way, focusing on the less profitable outcomes. For high values of <math>q</math> it ignores the most profitable but unlikely possibilities, while for small values of <math>q</math> it focuses on the worst losses. On the other hand, unlike the [[discounted maximum loss]], even for lower values of <math>q</math> the expected shortfall does not consider only the single most catastrophic outcome. A value of <math>q</math> often used in practice is 5%.{{Citation needed|date=February 2011}}\n\nExpected shortfall is considered a more useful risk measure than VaR because it is a [[Coherent risk measure|coherent]], and moreover a [[Spectral risk measure|spectral]], [[Risk measure|measure]] of financial portfolio risk. It is calculated for a given [[quantile]]-level <math>q</math>, and is defined to be the mean loss of [[Portfolio (finance)|portfolio]] value given that a loss is occurring at or below the <math>q</math>-quantile.\n\n==Formal definition==\nIf <math>X \\in L^p(\\mathcal{F})</math> (an [[Lp space]]) is the payoff of a portfolio at some future time and <math>0 < \\alpha < 1</math> then we define the expected shortfall as\n\n:<math>ES_{\\alpha} = -\\frac{1}{\\alpha}\\int_0^{\\alpha} \\mbox{VaR}_{\\gamma}(X)d\\gamma</math>\n\nwhere <math>\\mbox{VaR}_{\\gamma}</math> is the [[Value at risk]].  This can be equivalently written as\n\n:<math>ES_{\\alpha} = -\\frac{1}{\\alpha}\\left(E[X \\ 1_{\\{X \\leq x_{\\alpha}\\}}] + x_{\\alpha}(\\alpha - P[X \\leq x_{\\alpha}])\\right)</math>\n\nwhere <math>x_{\\alpha} = \\inf\\{x \\in \\mathbb{R}: P(X \\leq x) \\geq \\alpha\\}</math> is the lower <math>\\alpha</math>-[[quantile]] and <math>1_A(x) = \\begin{cases}1 &\\text{if }x \\in A\\\\ 0 &\\text{else}\\end{cases}</math> is the [[indicator function]].<ref name=\"AcerbiTasche\">{{cite journal|\n    author = Carlo Acerbi|\n    author2= Dirk Tasche|\n    title = Expected Shortfall: a natural coherent alternative to Value at Risk|\n    journal = Economic Notes|\n    year = 2002|\n    volume = 31|\n    issue= 2|\n    pages = 379–388|\n    url = http://www.bis.org/bcbs/ca/acertasc.pdf|\n    accessdate = April 25, 2012\n|doi=10.1111/1468-0300.00091|\n    arxiv= cond-mat/0105191}}</ref>  The dual representation is\n:<math>ES_{\\alpha} = \\inf_{Q \\in \\mathcal{Q}_{\\alpha}} E^Q[X]</math>\nwhere <math>\\mathcal{Q}_{\\alpha}</math> is the set of [[probability measure]]s which are [[absolutely continuous]] to the physical measure <math>P</math> such that <math>\\frac{dQ}{dP} \\leq \\alpha^{-1}</math> [[almost surely]].<ref>{{cite journal|last=Föllmer|first=H.|last2=Schied|first2=A.|year=2008|title=Convex and coherent risk measures|url=http://wws.mathematik.hu-berlin.de/~foellmer/papers/CCRM.pdf|accessdate=October 4, 2011}}</ref>  Note that <math>\\frac{dQ}{dP}</math> is the [[Radon–Nikodym derivative]] of <math>Q</math> with respect to <math>P</math>.\n\nExpected Shortfall can be generalized to a general class of coherent risk measures on <math>L^p</math> spaces ([[Lp space]]) with a corresponding dual characterization in the corresopnding <math>L^q</math> [[Lp space#Dual spaces|dual space]].  The domain can be extended for more general Orlitz Hearts.<ref>{{cite journal|\n    author = Patrick Cheridito|\n    author2= [[Tianhui Li]]|\n    title = Dual characterization of properties of risk measures on Orlicz hearts|\n    journal = Mathematics and Financial Economics|\n    year = 2008|\n    volume = 2|\n    pages = 2–29|\n    doi= 10.1007/s11579-008-0013-7}}</ref>\n\nIf the underlying distribution for <math>X</math> is a continuous distribution then the expected shortfall is equivalent to the [[tail conditional expectation]] defined by <math>TCE_{\\alpha}(X) = E[-X\\mid X \\leq -VaR_{\\alpha}(X)]</math>.<ref>{{cite web|url=https://statistik.ets.kit.edu/download/doc_secure1/7_StochModels.pdf|title=Average Value at Risk|accessdate=February 2, 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20110719222242/https://statistik.ets.kit.edu/download/doc_secure1/7_StochModels.pdf|archivedate=July 19, 2011|df=}}</ref>\n\nInformally, and non rigorously, this equation amounts to saying \"in case of losses so severe that they occur only alpha percent of the time, what is our average loss\".\n\nExpected shortfall can also be written as a [[distortion risk measure]] given by the [[distortion function]] <math>g(x) = \\begin{cases}\\frac{x}{1-\\alpha} & \\text{if }0 \\leq x < 1-\\alpha,\\\\ 1 & \\text{if }1-\\alpha \\leq x \\leq 1.\\end{cases}</math><ref name=\"Wirch\">{{cite web|title=Distortion Risk Measures: Coherence and Stochastic Dominance|author=Julia L. Wirch|author2=Mary R. Hardy|url=http://pascal.iseg.utl.pt/~cemapre/ime2002/main_page/papers/JuliaWirch.pdf|accessdate=March 10, 2012}}</ref><ref name=\"PropertiesDRM\">{{Cite journal | last1 = Balbás | first1 = A. | last2 = Garrido | first2 = J. | last3 = Mayoral | first3 = S. | doi = 10.1007/s11009-008-9089-z | title = Properties of Distortion Risk Measures | journal = Methodology and Computing in Applied Probability | volume = 11 | issue = 3 | pages = 385 | year = 2008 | pmid =  | pmc = | hdl = 10016/14071 }}</ref>\n\n== Examples ==\n\nExample 1.  If we believe our average loss on the worst 5% of the possible outcomes for our portfolio is EUR 1000, then we could say our expected shortfall is EUR 1000 for the 5% tail.\n\nExample 2. Consider a portfolio that will have the following possible values at the end of the period:\n\n{| class=\"wikitable\"\n|-\n! probability\n! ending value\n|-\n! of event\n! of the portfolio\n|-\n| 10%\n| 0\n|-\n| 30%\n| 80\n|-\n| 40%\n| 100\n|-\n| 20%\n| 150\n|}\n\nNow assume that we paid 100 at the beginning of the period for this portfolio.  Then the profit in each case is (''ending value''−100) or:\n\n{| class=\"wikitable\"\n|-\n! probability\n!\n|-\n! of event\n! profit\n|-\n| 10%\n| −100\n|-\n| 30%\n| −20\n|-\n| 40%\n| 0\n|-\n| 20%\n| 50\n|}\n\nFrom this table let us calculate the expected shortfall <math>ES_q</math> for a few values of <math>q</math>:\n\n{| class=\"wikitable\"\n|-\n!<math>q</math>\n! expected shortfall <math>ES_q</math>\n|-\n| 5%\n| 100\n|-\n| 10%\n| 100\n|-\n| 20%\n| 60\n|-\n| 30%\n| 46.<span style=\"text-decoration: overline;\">6</span>\n|-\n| 40%\n| 40\n|-\n| 50%\n| 32\n|-\n| 60%\n| 26.<span style=\"text-decoration: overline;\">6</span>\n|-\n| 80%\n| 20\n|-\n| 90%\n| 12.<span style=\"text-decoration: overline;\">2</span>\n|-\n| 100%\n| 6\n|}\n\nTo see how these values were calculated, consider the calculation of <math>ES_{0.05}</math>, the expectation in the worst 5% of cases.  These cases belong to (are a [[subset]] of) row 1 in the profit table, which have a profit of −100 (total loss of the 100 invested). The expected profit for these cases is −100.\n\nNow consider the calculation of <math>ES_{0.20}</math>, the expectation in the worst 20 out of 100 cases.  These cases are as follows: 10 cases from row one, and 10 cases from row two (note that 10+10 equals the desired 20 cases). For row 1 there is a profit of −100, while for row 2 a profit of −20.  Using the expected value formula we get\n\n:<math>\\frac{ \\frac{10}{100}(-100)+\\frac{10}{100}(-20) }{ \\frac{20}{100}} = -60.</math>\n\nSimilarly for any value of <math>q</math>. We select as many rows starting from the top as are necessary to give a cumulative probability of <math>q</math> and then calculate an expectation over those cases.  In general the last row selected may not be fully used (for example in calculating <math>-ES_{0.20}</math> we used only 10 of the 30 cases per 100 provided by row 2).\n\nAs a final example, calculate <math>-ES_1</math>.  This is the expectation over all cases, or\n\n:<math>0.1(-100)+0.3(-20)+0.4\\cdot 0+0.2\\cdot 50 = -6. \\, </math>\n\nThe [[Value at risk|Value at Risk (VaR)]] is given below for comparison.\n\n{| class=\"wikitable\"\n|-\n!<math>q</math>\n!<math>\\operatorname{VaR}_q</math>\n|-\n| 0% ≤ <math>q</math> < 10%\n| −100\n|-\n| 10% ≤ <math>q</math> < 40%\n| −20\n|-\n| 40% ≤ <math>q</math> < 80%\n| 0\n|-\n| 80% ≤ <math>q</math> ≤ 100%\n| 50\n|}\n\n== Properties ==\nThe expected shortfall <math>ES_q</math> increases as <math>q</math> decreases.\n\nThe 100%-quantile expected shortfall <math>ES_{1.0}</math> equals negative of the [[expected value]] of the portfolio.\n\nFor a given portfolio, the expected shortfall <math>ES_q</math> is greater than or equal to the Value at Risk <math>\\operatorname{VaR}_q</math> at the same <math>q</math> level.\n\n== Formulas for continuous probability distributions ==\nClosed-form formulas exist for calculating the expected shortfall when the payoff of a portfolio <math>X</math> or a corresponding loss <math>L = -X</math> follows a specific continuous distribution. In the former case the expected shortfall corresponds to the opposite number of the left-tail conditional expectation below <math>-VaR_\\alpha (X)</math>:\n\n<math>ES_\\alpha(X) = E[-X\\mid X \\leq -VaR_{\\alpha}(X)] = -\\frac{1}{\\alpha}\\int_0^\\alpha VaR_\\gamma(X)d\\gamma = -\\frac{1}{\\alpha}\\int_{-\\infty}^{-VaR_\\alpha(X)}xf(x)dx</math>. Typical values of <math display=\"inline\">\\alpha</math> in this case are 5% and 1%.\n\nFor engineering or actuarial applications it is more common to consider the distribution of losses <math>L = -X</math>, the expected shortfall in this case corresponds to the right-tail conditional expectation above <math>VaR_\\alpha (L)</math> and the typical values of <math>\\alpha</math> are 95% and 99%:\n\n<math>ES_\\alpha(L) = E[L\\mid L \\geq VaR_{\\alpha}(L)] = \\frac{1}{1-\\alpha}\\int^1_\\alpha VaR_\\gamma(L)d\\gamma = \\frac{1}{1-\\alpha}\\int^{+\\infty}_{VaR_\\alpha(L)}yf(y)dy</math>.\n\nSince some formulas below were derived for the left-tail case and some for the right-tail case, the following reconciliations can be useful:\n\n<math>ES_\\alpha(X) = -\\frac{1}{\\alpha}E[X]+\\frac{1-\\alpha}{\\alpha}ES_\\alpha(L)</math> and <math>ES_\\alpha(L) = \\frac{1}{1-\\alpha}E[L]+\\frac{\\alpha}{1-\\alpha}ES_\\alpha(X)</math>.\n\n=== Normal distribution ===\nIf the payoff of a portfolio <math>X</math> follows [[Normal distribution|normal (Gaussian) distribution]] with the p.d.f. <math>f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}</math> then the expected shortfall is equal to <math>ES_\\alpha(X) = -\\mu+\\sigma\\frac{\\phi(\\Phi^{-1}(\\alpha))}{\\alpha}</math>, where <math>\\phi(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}</math> is the standard normal p.d.f., <math>\\Phi(x)</math> is the standard normal c.d.f., so <math>\\Phi^{-1}(\\alpha)</math> is the standard normal quantile.<ref name=\":0\">{{Cite journal|last=Khokhlov|first=Valentyn|date=2016|title=Conditional Value-at-Risk for Elliptical Distributions|url=|journal=Evropský časopis Ekonomiky a Managementu|volume=2|issue=6|pages=70–79|via=}}</ref>\n\nIf the loss of a portfolio <math>L</math> follows normal distribution, the expected shortfall is equal to <math>ES_\\alpha(L) = \\mu+\\sigma\\frac{\\phi(\\Phi^{-1}(\\alpha))}{1-\\alpha}</math>.<ref name=\":1\">{{cite arxiv|last=Norton|first=Matthew|last2=Khokhlov|first2=Valentyn|last3=Uryasev|first3=Stan|date=2018-11-27|title=Calculating CVaR and bPOE for Common Probability Distributions With Application to Portfolio Optimization and Density Estimation|eprint=1811.11301|class=q-fin.RM}}</ref>\n\n=== Generalized Student's t-distribution ===\nIf the payoff of a portfolio <math>X</math> follows generalized [[Student's t-distribution]] with the p.d.f. <math>f(x) = \\frac{\\Gamma\\bigl(\\frac{\\nu+1}{2}\\bigr)}{\\Gamma\\bigl(\\frac{\\nu}{2}\\bigr)\\sqrt{\\pi\\nu}\\sigma}\\Bigl(1+\\frac{1}{\\nu}\\bigl(\\frac{x-\\mu}{\\sigma}\\bigr)^2\\Bigr)^{-\\frac{\\nu+1}{2}}</math> then the expected shortfall is equal to <math>ES_\\alpha(X) = -\\mu+\\sigma\\frac{\\nu+(\\Tau^{-1}(\\alpha))^2}{\\nu-1}\\frac{\\tau(\\Tau^{-1}(\\alpha))}{1-\\alpha}</math>, where <math>\\tau(x)=\\frac{\\Gamma\\bigl(\\frac{\\nu+1}{2}\\bigr)}{\\Gamma\\bigl(\\frac{\\nu}{2}\\bigr)\\sqrt{\\pi\\nu}}\\Bigl(1+\\frac{x^2}{\\nu}\\Bigr)^{-\\frac{\\nu+1}{2}}</math> is the standard t-distribution p.d.f., <math>\\Tau(x)</math> is the standard t-distribution c.d.f., so <math>\\Tau^{-1}(\\alpha)</math> is the standard t-distribution quantile.<ref name=\":0\" />\n\nIf the loss of a portfolio <math>L</math> follows generalized Student's t-distribution, the expected shortfall is equal to <math>ES_\\alpha(L) = \\mu+\\sigma\\frac{\\nu+(\\Tau^{-1}(\\alpha))^2}{\\nu-1}\\frac{\\tau(\\Tau^{-1}(\\alpha))}{1-\\alpha}</math>.<ref name=\":1\" />\n\n=== Laplace distribution ===\nIf the payoff of a portfolio <math>X</math> follows [[Laplace distribution]] with the p.d.f. <math>f(x) = \\frac{1}{2b}e^{-\\frac{|x-\\mu|}{b}}</math> and the c.d.f. <math>F(x) = \\begin{cases}1 - \\frac{1}{2} e^{-\\frac{x-\\mu}{b}} & \\text{if }x \\geq \\mu,\\\\ \\frac{1}{2} e^\\frac{x-\\mu}{b} & \\text{if }x < \\mu.\\end{cases}</math> then the expected shortfall is equal to <math>ES_\\alpha(X) = -\\mu+b(1-\\ln2\\alpha)</math> for <math>\\alpha \\le 0.5</math>.<ref name=\":0\" />\n\nIf the loss of a portfolio <math>L</math> follows Laplace distribution, the expected shortfall is equal to <math>ES_\\alpha(L) = \\begin{cases}\\mu + b \\frac{\\alpha}{1-\\alpha} (1-\\ln2\\alpha) & \\text{if }\\alpha < 0.5,\\\\ \\mu + b[1 - \\ln(2(1-\\alpha))] & \\text{if }\\alpha \\ge 0.5.\\end{cases}</math>.<ref name=\":1\" />\n\n=== Logistic distribution ===\nIf the payoff of a portfolio <math>X</math> follows [[logistic distribution]] with the p.d.f. <math>f(x) = \\frac{1}{s}e^{-\\frac{x-\\mu}{s}}\\Bigl(1+e^{-\\frac{x-\\mu}{s}}\\Bigr)^{-2}</math> and the c.d.f. <math>F(x) = \\Bigl(1+e^{-\\frac{x-\\mu}{s}}\\Bigr)^{-1}</math> then the expected shortfall is equal to <math>ES_\\alpha(X) = -\\mu+s\\ln\\frac{(1-\\alpha)^{1-\\frac{1}{\\alpha}}}{\\alpha}</math>.<ref name=\":0\" />\n\nIf the loss of a portfolio <math>L</math> follows [[logistic distribution]], the expected shortfall is equal to <math>ES_\\alpha(L) = \\mu + s\\frac{-\\alpha\\ln\\alpha-(1-\\alpha)\\ln(1-\\alpha)}{1-\\alpha}</math>.<ref name=\":1\" />\n\n=== Exponential distribution ===\nIf the loss of a portfolio <math>L</math> follows [[exponential distribution]] with the p.d.f. <math>f(x) = \\begin{cases}\\lambda e^{-\\lambda x} & \\text{if }x \\geq 0,\\\\ 0 & \\text{if }x < 0.\\end{cases}</math> and the c.d.f. <math>F(x) = \\begin{cases}1 - e^{-\\lambda x} & \\text{if }x \\geq 0,\\\\ 0 & \\text{if }x < 0.\\end{cases}</math> then the expected shortfall is equal to <math>ES_\\alpha(L) = \\frac{-\\ln(1-\\alpha)+1}{\\lambda}</math>.<ref name=\":1\" />\n\n=== Pareto distribution ===\nIf the loss of a portfolio <math>L</math> follows [[Pareto distribution]] with the p.d.f. <math>f(x) = \\begin{cases}\\frac{a x_m^a}{x^{a+1}} & \\text{if }x \\geq x_m,\\\\ 0 & \\text{if }x < x_m.\\end{cases}</math> and the c.d.f. <math>F(x) = \\begin{cases}1 - (x_m/x)^a & \\text{if }x \\geq x_m,\\\\ 0 & \\text{if }x < x_m.\\end{cases}</math> then the expected shortfall is equal to <math>ES_\\alpha(L) = \\frac{x_m a}{(1-\\alpha)^{1/a}(a-1)}</math>.<ref name=\":1\" />\n\n=== Generalized Pareto distribution (GPD) ===\nIf the loss of a portfolio <math>L</math> follows [[Generalized Pareto distribution|GPD]] with the p.d.f. <math>f(x) = \\frac{1}{s} \\Bigl( 1+\\frac{\\xi (x-\\mu)}{s} \\Bigr)^{\\bigl(-\\frac{1}{\\xi}-1\\bigr)}</math> and the c.d.f. <math>F(x) = \\begin{cases}1 - \\Big(1+\\frac{\\xi(x-\\mu)}{s}\\Big)^{-\\frac{1}{\\xi}} & \\text{if }\\xi \\ne 0,\\\\ 1-\\exp \\bigl( -\\frac{x-\\mu}{s} \\bigr) & \\text{if }\\xi = 0.\\end{cases}</math> then the expected shortfall is equal to <math>ES_\\alpha(L) = \\begin{cases}\\mu + s \\Bigl[ \\frac{(1-\\alpha)^{-\\xi}}{1-\\xi}+\\frac{(1-\\alpha)^{-\\xi}-1}{\\xi} \\Bigr] & \\text{if }\\xi \\ne 0,\\\\ \\mu + s[1 - \\ln(1-\\alpha)] & \\text{if }\\xi = 0.\\end{cases}</math> and the VaR is equal to <math>VaR_\\alpha(L) = \\begin{cases}\\mu + s \\frac{(1-\\alpha)^{-\\xi}-1}{\\xi}  & \\text{if }\\xi \\ne 0,\\\\ \\mu - s \\ln(1-\\alpha) & \\text{if }\\xi = 0.\\end{cases}</math>.<ref name=\":1\" />\n\n=== Weibull distribution ===\nIf the loss of a portfolio <math>L</math> follows [[Weibull distribution]] with the p.d.f. <math>f(x) = \\begin{cases}\\frac{k}{\\lambda} \\Big(\\frac{x}{\\lambda}\\Big)^{k-1} e^{-(x/\\lambda)^k} & \\text{if }x \\geq 0,\\\\ 0 & \\text{if }x < 0.\\end{cases}</math> and the c.d.f. <math>F(x) = \\begin{cases}1 - e^{-(x/\\lambda)^k} & \\text{if }x \\geq 0,\\\\ 0 & \\text{if }x < 0.\\end{cases}</math> then the expected shortfall is equal to <math>ES_\\alpha(L) = \\frac{\\lambda}{1-\\alpha} \\Gamma\\Big(1+\\frac{1}{k},-\\ln(1-\\alpha)\\Big)</math>, where <math>\\Gamma(s,x)</math> is the [[upper incomplete gamma function]].<ref name=\":1\" />\n\n=== Generalized extreme value distribution (GEV) ===\nIf the payoff of a portfolio <math>X</math> follows [[Generalized extreme value distribution|GEV]] with the p.d.f. <math>f(x) = \\begin{cases} \\frac{1}{\\sigma} \\Bigl( 1+\\xi \\frac{ x-\\mu}{\\sigma} \\Bigr)^{-\\frac{1}{\\xi}-1} \\exp\\Bigl[-\\Bigl( 1+\\xi \\frac{x-\\mu}{\\sigma} \\Bigr)^{-\\frac{1}{\\xi}}\\Bigr] & \\text{if } \\xi \\ne 0,\\\\ \\frac{1}{\\sigma}e^{-\\frac{x-\\mu}{\\sigma}}e^{-e^{-\\frac{x-\\mu}{\\sigma}}} & \\text{if } \\xi = 0. \\end{cases}</math> and the c.d.f. <math>F(x) = \\begin{cases}\\exp\\Big(-\\big(1+\\xi\\frac{x-\\mu}{\\sigma}\\big)^{-\\frac{1}{\\xi}}\\Big) & \\text{if }\\xi \\ne 0,\\\\ \\exp\\Big(-e^{-\\frac{x-\\mu}{\\sigma}}\\Big) & \\text{if }\\xi = 0.\\end{cases}</math> then the expected shortfall is equal to <math>ES_\\alpha(X) = \\begin{cases}-\\mu - \\frac{\\sigma}{\\alpha \\xi} \\big[ \\Gamma(1-\\xi,-\\ln\\alpha)-\\alpha \\big] & \\text{if }\\xi \\ne 0,\\\\ -\\mu - \\frac{\\sigma}{\\alpha} \\big[ \\text{li}(\\alpha) - \\alpha \\ln(-\\ln \\alpha) \\big] & \\text{if }\\xi = 0.\\end{cases}</math> and the VaR is equal to <math>VaR_\\alpha(X) = \\begin{cases}-\\mu - \\frac{\\sigma}{\\xi} \\big[(-\\ln \\alpha)^{-\\xi}-1 \\big]  & \\text{if }\\xi \\ne 0,\\\\ -\\mu + \\sigma \\ln(-\\ln\\alpha) & \\text{if }\\xi = 0.\\end{cases}</math>, where <math>\\Gamma(s,x)</math> is the [[upper incomplete gamma function]], <math>\\text{li}(x)=\\int \\frac{dx}{\\ln x}</math> is the [[logarithmic integral function]].<ref name=\":3\">{{Cite document|ssrn=3200629|title=Conditional Value-at-Risk for Uncommon Distributions|last=Khokhlov|first=Valentyn|date=2018-06-21}}</ref>\n\nIf the loss of a portfolio <math>L</math> follows [[Generalized extreme value distribution|GEV]], then the expected shortfall is equal to <math>ES_\\alpha(X) = \\begin{cases}\\mu + \\frac{\\sigma}{(1-\\alpha) \\xi} \\big[ \\gamma(1-\\xi,-\\ln\\alpha)-(1-\\alpha) \\big] & \\text{if }\\xi \\ne 0,\\\\ \\mu + \\frac{\\sigma}{1-\\alpha} \\big[y - \\text{li}(\\alpha) + \\alpha \\ln(-\\ln \\alpha) \\big] & \\text{if }\\xi = 0.\\end{cases}</math>, where <math>\\gamma(s,x)</math> is the [[lower incomplete gamma function]], <math>y</math> is the [[Euler–Mascheroni constant|Euler-Mascheroni constant]].<ref name=\":1\" />\n\n=== Generalized hyperbolic secant (GHS) distribution ===\nIf the payoff of a portfolio <math>X</math> follows [[Hyperbolic secant distribution|GHS distribution]] with the p.d.f. <math>f(x) = \\frac{1}{2 \\sigma}\\text{sech}(\\frac{\\pi}{2}\\frac{x-\\mu}{\\sigma})</math>and the c.d.f. <math>F(x) = \\frac{2}{\\pi}\\arctan\\Big[\\exp\\Big(\\frac{\\pi}{2}\\frac{x-\\mu}{\\sigma}\\Big)\\Big]</math> then the expected shortfall is equal to <math>ES_\\alpha(X) = -\\mu - \\frac{2\\sigma}{\\pi} \\ln\\Big( \\tan \\frac{\\pi\\alpha}{2} \\Big) - \\frac{2\\sigma}{\\pi^2\\alpha}i\\Big[\\text{Li}_2\\Big(-i\\tan\\frac{\\pi\\alpha}{2}\\Big)-\\text{Li}_2\\Big(i\\tan\\frac{\\pi\\alpha}{2}\\Big)\\Big]</math>, where <math>\\text{Li}_2</math> is the [[Spence's function]], <math>i=\\sqrt{-1}</math> is the imaginary unit.<ref name=\":3\" />\n\n=== Johnson's SU-distribution ===\nIf the payoff of a portfolio <math>X</math> follows [[Johnson's SU-distribution]] with the c.d.f. <math>F(x) = \\Phi\\Big[\\gamma+\\delta\\sinh^{-1}\\Big(\\frac{x-\\xi}{\\lambda}\\Big)\\Big]</math> then the expected shortfall is equal to <math>ES_\\alpha(X) = -\\xi - \\frac{\\lambda}{2\\alpha} \\Big[ exp\\Big(\\frac{1-2\\gamma\\delta}{2\\delta^2}\\Big)\\Phi\\Big(\\Phi^{-1}(\\alpha)-\\frac{1}{\\delta}\\Big) - exp\\Big(\\frac{1+2\\gamma\\delta}{2\\delta^2}\\Big)\\Phi\\Big(\\Phi^{-1}(\\alpha)+\\frac{1}{\\delta}\\Big) \\Big]</math>, where <math>\\Phi</math> is the c.d.f. of the standard normal distribution.<ref>{{Cite document|ssrn=1855986|title=Moment-Based CVaR Estimation: Quasi-Closed Formulas|last=Stucchi|first=Patrizia|date=2011-05-31}}</ref>\n\n=== Burr type XII distribution ===\nIf the payoff of a portfolio <math>X</math> follows the [[Burr Type XII distribution|Burr type XII distribution]] with the p.d.f. <math>f(x) = \\frac{ck}{\\beta}\\Big(\\frac{x-\\gamma}{\\beta}\\Big)^{c-1}\\Big[1+\\Big(\\frac{x-\\gamma}{\\beta}\\Big)^c\\Big]^{-k-1}</math> and the c.d.f. <math>F(x) = 1-\\Big[1+\\Big(\\frac{x-\\gamma}{\\beta}\\Big)^c\\Big]^{-k}</math>, the expected shortfall is equal to <math>ES_\\alpha(X) = -\\gamma -\\frac{\\beta}{\\alpha}\\Big( (1-\\alpha)^{-1/k}-1 \\Big)^{1/c} \\Big[ \\alpha -1+{_2F_1}\\Big(\\frac{1}{c},k;1+\\frac{1}{c};1-(1-\\alpha)^{-1/k}\\Big) \\Big]</math>, where <math>_2F_1</math> is the [[hypergeometric function]]. Alternatively, <math>ES_\\alpha(X) = -\\gamma -\\frac{\\beta}{\\alpha}\\frac{ck}{c+1}\\Big( (1-\\alpha)^{-1/k}-1 \\Big)^{1+\\frac{1}{c}} {_2F_1}\\Big(1+\\frac{1}{c},k+1;2+\\frac{1}{c};1-(1-\\alpha)^{-1/k}\\Big) </math>.<ref name=\":3\" />\n\n=== Dagum distribution ===\nIf the payoff of a portfolio <math>X</math> follows the [[Dagum distribution]] with the p.d.f. <math>f(x) = \\frac{ck}{\\beta}\\Big(\\frac{x-\\gamma}{\\beta}\\Big)^{ck-1}\\Big[1+\\Big(\\frac{x-\\gamma}{\\beta}\\Big)^c\\Big]^{-k-1}</math> and the c.d.f. <math>F(x) = \\Big[1+\\Big(\\frac{x-\\gamma}{\\beta}\\Big)^{-c}\\Big]^{-k}</math>, the expected shortfall is equal to <math>ES_\\alpha(X) = -\\gamma -\\frac{\\beta}{\\alpha}\\frac{ck}{ck+1}\\Big( \\alpha^{-1/k}-1 \\Big)^{-k-\\frac{1}{c}} {_2F_1}\\Big(k+1,k+\\frac{1}{c};k+1+\\frac{1}{c};-\\frac{1}{\\alpha^{-1/k}-1}\\Big) </math>, where <math>_2F_1</math> is the [[hypergeometric function]].<ref name=\":3\" />\n\n=== Lognormal distribution ===\nIf the payoff of a portfolio <math>X</math> follows [[Log-normal distribution|lognormal distribution]], i.e. the random variable <math>\\ln(1+X)</math> follows normal distribution with the p.d.f. <math>f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}</math>, then the expected shortfall is equal to <math>ES_\\alpha(X) = 1-\\exp\\Bigl(\\mu+\\frac{\\sigma^2}{2}\\Bigr) \\frac{\\Phi(\\Phi^{-1}(\\alpha)-\\sigma)}{\\alpha}</math>, where <math>\\Phi(x)</math> is the standard normal c.d.f., so <math>\\Phi^{-1}(\\alpha)</math> is the standard normal quantile.<ref name=\":2\">{{Cite document|ssrn=3197929|title=Conditional Value-at-Risk for Log-Distributions|last=Khokhlov|first=Valentyn|date=2018-06-17}}</ref>\n\n=== Log-logistic distribution ===\nIf the payoff of a portfolio <math>X</math> follows [[log-logistic distribution]], i.e. the random variable <math>\\ln(1+X)</math> follows logistic distribution with the p.d.f. <math>f(x) = \\frac{1}{s}e^{-\\frac{x-\\mu}{s}}\\Bigl(1+e^{-\\frac{x-\\mu}{s}}\\Bigr)^{-2}</math>, then the expected shortfall is equal to <math>ES_\\alpha(X) = 1-\\frac{e^\\mu}{\\alpha}I_\\alpha(1+s,1-s)\\frac{\\pi s}{\\sin\\pi s}</math>, where <math>I_\\alpha</math> is the [[Incomplete beta function|regularized incomplete beta function]], <math>I_\\alpha(a,b)=\\frac{\\Beta_\\alpha(a,b)}{\\Beta(a,b)}</math>.\n\nAs the incomplete beta function is defined only for positive arguments, for a more generic case the expected shortfall can be expressed with the [[hypergeometric function]]: <math>ES_\\alpha(X) = 1-\\frac{e^\\mu \\alpha^s}{s+1} {_2F_1}(s,s+1;s+2;\\alpha)</math>.<ref name=\":2\" />\n\nIf the loss of a portfolio <math>L</math> follows log-logistic distribution with p.d.f. <math>f(x) = \\frac{\\frac{b}{a}(x/a)^{b-1}}{(1+(x/a)^b)^2}</math> and c.d.f. <math>F(x) = \\frac{1}{1+(x/a)^{-b}}</math>, then the expected shortfall is equal to <math>ES_\\alpha(L) = \\frac{a}{1-\\alpha}\\Bigl[\\frac{\\pi}{b}\\csc\n\\Bigl(\\frac{\\pi}{b}\\Bigr)-\\Beta_\\alpha\\Bigl(\\frac{1}{b}+1,1-\\frac{1}{b}\\Bigr)\\Bigr]</math>, where <math>B_\\alpha</math> is the [[incomplete beta function]].<ref name=\":1\" />\n\n=== Log-Laplace distribution ===\nIf the payoff of a portfolio <math>X</math> follows [[log-Laplace distribution]], i.e. the random variable <math>\\ln(1+X)</math> follows Laplace distribution the p.d.f. <math>f(x) = \\frac{1}{2b}e^{-\\frac{|x-\\mu|}{b}}</math>, then the expected shortfall is equal to <math>ES_\\alpha(X) = \\begin{cases}1 - \\frac{e^\\mu (2\\alpha)^b}{b+1} & \\text{if }\\alpha \\le 0.5,\\\\ 1 - \\frac{e^\\mu 2^{-b}}{\\alpha(b-1)}\\big[(1-\\alpha)^{(1-b)}-1\\big] & \\text{if }\\alpha > 0.5.\\end{cases}</math>.<ref name=\":2\" />\n\n=== Log-generalized hyperbolic secant (log-GHS) distribution ===\nIf the payoff of a portfolio <math>X</math> follows log-GHS distribution, i.e. the random variable <math>\\ln(1+X)</math> follows [[Hyperbolic secant distribution|GHS distribution]] with the p.d.f. <math>f(x) = \\frac{1}{2 \\sigma}\\text{sech}(\\frac{\\pi}{2}\\frac{x-\\mu}{\\sigma})</math>, then the expected shortfall is equal to <math>ES_\\alpha(X) = 1-\\frac{1}{\\alpha(\\sigma+{\\pi/2})} \\Big(\\tan\\frac{\\pi \\alpha}{2}\\exp\\frac{\\pi \\mu}{2\\sigma}\\Big)^{2\\sigma/\\pi} \\tan\\frac{\\pi \\alpha}{2} {_2F_1}\\Big(1,\\frac{1}{2}+\\frac{\\sigma}{\\pi};\\frac{3}{2}+\\frac{\\sigma}{\\pi};-\\tan\\big(\\frac{\\pi \\alpha}{2}\\big)^2\\Big)</math>, where <math>_2F_1</math> is the [[hypergeometric function]].<ref name=\":2\" />\n\n== Dynamic expected shortfall ==\nThe [[conditional risk measure|conditional]] version of the expected shortfall at the time ''t'' is defined by\n\n:<math>ES_{\\alpha}^t(X) = \\operatorname*{ess\\sup}_{Q \\in \\mathcal{Q}_{\\alpha}^t} E^Q[-X\\mid\\mathcal{F}_t]</math>\n\nwhere <math>\\mathcal{Q}_{\\alpha}^t = \\{Q = P\\,\\vert_{\\mathcal{F}_t}: \\frac{dQ}{dP} \\leq \\alpha_t^{-1} \\mathrm{ a.s.}\\}</math>.<ref>{{cite journal|title=Conditional and dynamic convex risk measures|first1=Kai|last1=Detlefsen|first2=Giacomo|last2=Scandolo|journal=Finance Stoch.|volume=9|issue=4|pages=539–561|year=2005|url=http://www.dmd.unifi.it/scandolo/pdf/Scandolo-Detlefsen-05.pdf|accessdate=October 11, 2011|doi=10.1007/s00780-005-0159-6|citeseerx=10.1.1.453.4944}}{{Dead link|date=January 2012}}</ref><ref>{{cite journal|title=Dynamic convex risk measures |first1=Beatrice |last1=Acciaio |first2=Irina |last2=Penner |year=2011 |url=http://wws.mathematik.hu-berlin.de/~penner/Acciaio_Penner.pdf |accessdate=October 11, 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20110902182345/http://wws.mathematik.hu-berlin.de/~penner/Acciaio_Penner.pdf |archivedate=September 2, 2011 |df= }}</ref>\n\nThis is not a [[time-consistent]] risk measure.  The time-consistent version is given by\n:<math>\\rho_{\\alpha}^t(X) = \\operatorname*{ess\\sup}_{Q \\in \\tilde{\\mathcal{Q}}_{\\alpha}^t} E^Q[-X\\mid\\mathcal{F}_t]</math>\nsuch that\n:<math>\\tilde{\\mathcal{Q}}_{\\alpha}^t = \\left\\{Q \\ll P: \\mathbb{E}\\left[\\frac{dQ}{dP}\\mid\\mathcal{F}_{\\tau+1}\\right] \\leq \\alpha_t^{-1} \\mathbb{E}\\left[\\frac{dQ}{dP}\\mid\\mathcal{F}_{\\tau}\\right] \\; \\forall \\tau \\geq t \\; \\mathrm{a.s.}\\right\\}.</math><ref>{{cite journal|first1=Patrick|last1=Cheridito|first2=Michael|last2=Kupper|title=Composition of time-consistent dynamic monetary risk measures in discrete time|journal=International Journal of Theoretical and Applied Finance|date=May 2010|url=http://wws.mathematik.hu-berlin.de/~kupper/papers/comp2010.pdf|accessdate=February 4, 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20110719042954/http://wws.mathematik.hu-berlin.de/~kupper/papers/comp2010.pdf|archivedate=July 19, 2011|df=}}</ref>\n\n== See also ==\n* [[Coherent risk measure]]\n* [[Extended Mathematical Programming (EMP)#EMP for stochastic programming|EMP for stochastic programming]] – solution technology for optimization problems involving ES and VaR\n* [[Entropic value at risk]]\n* [[Value at risk]]\n\nMethods of statistical estimation of VaR and ES can be found in \nEmbrechts et al.<ref name=\"Embrechts et al\">Embrechts P., Kluppelberg C. and Mikosch T., Modelling Extremal Events for Insurance and Finance. Springer (1997).</ref> and Novak.<ref name=\"Novak\">Novak S.Y., Extreme value methods with applications to finance. Chapman & Hall/CRC Press (2011). {{ISBN|978-1-4398-3574-6}}.</ref>  When forecasting VaR and ES, or optimizing portfolios to minimize tail risk, it is important to account for asymmetric dependence and non-normalities in the distribution of stock returns such as auto-regression, asymmetric volatility, skewness, and kurtosis.<ref>{{cite journal|last1=Low|first1=R.K.Y.|last2=Alcock|first2=J.|last3=Faff|first3=R.|last4=Brailsford|first4=T.|title=Canonical vine copulas in the context of modern portfolio management: Are they worth it?|journal=Journal of Banking & Finance|date=2013|volume=37|issue=8|pages=3085–3099|doi=10.1016/j.jbankfin.2013.02.036}}</ref>\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://www.ise.ufl.edu/uryasev/files/2011/11/CVaR1_JOR.pdf Rockafellar, Uryasev:  Optimization of conditional Value-at-Risk, 2000.]\n* [https://arxiv.org/pdf/cond-mat/0104295%22%20/ C. Acerbi and D. Tasche: On the Coherence of Expected Shortfall, 2002.]\n* [http://www.ise.ufl.edu/uryasev/files/2011/11/cvar2_jbf.pdf Rockafellar, Uryasev: Conditional Value-at-Risk for general loss distributions, 2002.]\n* [http://www.finance-and-physics.org/susinno/acerbi1.pdf Acerbi: Spectral measures of risk, 2005]\n* [https://editorialexpress.com/cgi-bin/conference/download.cgi?db_name=QMF2004&paper_id=142: Phi-Alpha optimal portfolios and extreme risk management, Best of Wilmott, 2003]\n* CTAC Antoine\n\n[[Category:Financial risk modeling]]\n[[Category:Actuarial science]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Historical simulation (finance)",
      "url": "https://en.wikipedia.org/wiki/Historical_simulation_%28finance%29",
      "text": "{{Cleanup|date=April 2009}}\n\n'''Historical simulation''' in finance's [[value at risk]] (VaR) analysis is a procedure for predicting the value at risk by 'simulating' or constructing the [[cumulative distribution function]] (CDF) of assets returns over time. Unlike [[Parametric statistics|parametric]] VaR models, historical simulation does not assume a particular distribution of the asset returns. Also, it is relatively easy to implement. However, there are a couple of shortcomings of historical simulation. Historical simulation applies equal weight to all returns of the whole period; this is inconsistent with the diminishing predictability of data that are further away from the present. \n\n== Weighted historical simulation ==\nWeighted historical simulation applies decreasing weights to returns that are further away from the present, which overcomes the inconsistency of historical simulation with diminishing predictability of data that are further away from the present. However, weighted historical simulation still assumes independent and identically-distributed (iid) asset returns. <ref>{{cite journal|last=Boudoukh|first=J.|author2=Richardson, M. |author3=Whitelaw, R. |title=The Best of Both Worlds|journal=Risk|year=1998|volume=11|pages=64–67|url=http://pages.stern.nyu.edu/~rwhitela/papers/hybrid%20risk98.pdf}}</ref>\n\n== Filtered historical simulation ==\nFiltered historical simulation tries to capture volatility which is one of the causes for violation of i.i.d.\n\n==See also==\n*[[Monte Carlo methods in finance]]\n*[[Quasi-Monte Carlo methods in finance]]\n*[[Financial modeling]]\n\n== References ==\n{{Reflist}}\n\n==External links==\n* [http://www.filteredhistoricalsimulation.com/ Filtered Historical Simulation]\n\n{{Financial risk}}\n\n[[Category:Financial risk modeling]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Liquidity at risk",
      "url": "https://en.wikipedia.org/wiki/Liquidity_at_risk",
      "text": "{{Distinguish|Liquidity risk}}\nThe '''Liquidity-at-Risk''' (short: '''LaR''') is a quantity to measure [[financial risk]]s and is the maximum net liquidity drain relative to the expected liquidity position which should not be exceeded at a given confidence level (e.g. 95%). The LaR is analog to the [[Value at risk|Value-at-Risk (VaR)]] where a [[quantile]] of the [[Earnings before interest and taxes|EBIT]]-distribution is considered, however it does take stochastic [[cash flow]]s into account.<ref name=XtremValueTheoryCom>{{cite web|title=Liquidity-at-Risk (LaR) of a German private bank|url=http://www.extreme-value-theory.com/case-studies/liquidity-at-risk-lar/|website=extreme-value-theory.com|publisher=RC Banken-Consulting GmbH & Co. KG|accessdate=12 January 2016|location=Buxtehude, Germany|language=English|date=2011}}</ref><ref name=BachelorWork>{{cite book|last1=Conzen|first1=Sander|title=Liquidity at Risk (LaR) und LiquidityValue at Risk (LVaR): Zwei neue Ansätze für das Liquiditätsmanagement|date=6 September 2009|publisher=Diplomica|location=Hamburg, Germany|isbn=978-3-8366-3500-4|edition=Frankfurt School of Finance & Management|url=https://books.google.de/books?id=-VRwAQAAQBAJ|accessdate=12 January 2016|language=German}}</ref>\n\n== Critics ==\nStatistical measures for [[financial risk]] are not intuitive. Increasing the [[confidence level]] (e.g. from 99.0% to 99.9%) does not capture very [[rare events]] with possibly high impact. The only way around is to use [[extreme value theory]] for modelling the distribution tails. In other words: Statistical liquidity risk modelling approaches do not provide certainty in terms of a reliable lower limit for future liquidity.\n\n== See also ==\n* [[Margin at risk]]\n* [[Value at risk]]\n* [[Profit at risk]]\n\n== References ==\n{{reflist}}\n\n{{Financial risk}}\n\n[[Category:Mathematical finance]]\n[[Category:Financial risk]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Margin at risk",
      "url": "https://en.wikipedia.org/wiki/Margin_at_risk",
      "text": "The '''Margin-at-Risk''' (short: '''MaR''') is a quantity used to manage short-term liquidity risks due to variation of margin requirements, i.e. it is a [[financial risk]] occurring when [[commodity market|trading commodities]]. Similar to the [[Value at risk|Value-at-Risk (VaR)]], but instead of the [[Earnings before interest and taxes|EBIT]] it is a [[quantile]] of the (expected) [[cash flow]] distribution. \n\n== Description ==\nA '''MaR''' requires (1) a currency, (2) a confidence level (e.g. 90%) and (3) a holding period (e.g. 3 days).\nThe idea is that a given portfolio loss will be compensated by a [[margin (finance)|margin]] call by the same amount.<ref name=CircRef>{{cite journal|last1=Lang|first1=Joachim|last2=Madlener|first2=Reinhard|title=Portfolio optimization for power pl ants: the impact of credit risk mitigation and margining|journal=Institute for Future Energy Consumer Needs and Behavior - Working Paper|date=September 2010|url=https://www.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaaagvveh|accessdate=1 January 2016|location=Aachen, Germany}}</ref>\nThe MaR quantifies the \"worst case\" margin-call and is only driven by market prices.<ref name=Roeschh2013>{{cite book|last1=Rösch|first1=Daniel|last2=Scheule|first2=Harald|title=Credit Securitisations and Derivatives Challenges for the Global Markets|date=2013|publisher=Wiley|location=New York|isbn=978-1-119-96604-3|page=286|edition=2nd |url=https://books.google.de/books?id=HYiB-mSkjWQC&pg=PA286#v=onepage&q&f=false}}</ref>\n\n== See also ==\n* [[Liquidity at risk]]\n* [[Value at risk]]\n* [[Profit at risk]]\n\n== References ==\n{{reflist}}\n\n{{Financial risk}}\n\n[[Category:Mathematical finance]]\n[[Category:Financial risk management]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Monte Carlo methods for option pricing",
      "url": "https://en.wikipedia.org/wiki/Monte_Carlo_methods_for_option_pricing",
      "text": "In [[mathematical finance]], a '''Monte Carlo option model''' uses [[Monte Carlo method]]s <ref group=\"Notes\">Although the term 'Monte Carlo method' was coined by [[Stanislaw Ulam]] in the 1940s, some trace such methods to the 18th century French naturalist [[Georges-Louis Leclerc, Comte de Buffon|Buffon]], and a question he asked about the results of dropping a needle randomly on a striped floor or table. See [[Buffon's needle]].</ref> to calculate the value of an [[Option (finance)|option]] with multiple sources of uncertainty or with complicated features.<ref name=\"Marco Dias\"/>  The first application to option pricing was by [[Phelim Boyle]] in 1977 (for [[European option]]s).  In 1996, M. Broadie and P. Glasserman showed how to price [[Asian option]]s by Monte Carlo.  In 2001 [[Francis Longstaff|F.&nbsp;A. Longstaff]] and [[Eduardo Schwartz|E.&nbsp;S. Schwartz]] developed a practical Monte Carlo method for pricing [[American option|American-style options]].\n\n==Methodology==\nIn terms of [[financial economics|theory]], Monte Carlo valuation relies on risk neutral valuation.<ref name=\"Marco Dias\">Marco Dias: [http://marcoagd.usuarios.rdc.puc-rio.br/faq4.html Real Options with Monte Carlo Simulation]</ref> Here the price of the option is its [[present value|discounted]] [[expected value]]; see [[risk neutrality]] and [[Rational pricing#Risk neutral valuation|rational pricing]]. The technique  applied then, is  (1) to generate a large number of possible, but [[random]], price paths for the [[underlying]] (or underlyings) via [[simulation]], and (2) to then calculate the associated [[Exercise (options)|exercise]] [[Option time value#Intrinsic value|value]] (i.e. \"payoff\") of the option for each path. (3) These payoffs are then averaged and (4) discounted to today. This result is the value of the option.<ref name=\"Don Chance\">Don Chance: [http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN96-03.pdf Teaching Note 96-03: Monte Carlo Simulation]</ref>\n\nThis approach, although relatively straightforward, allows for increasing complexity:\n\n*An [[option (finance)|option on equity]] may be modelled with one source of uncertainty: the price of the underlying [[stock]] in question.<ref name=\"Don Chance\"/> Here the price of the [[underlying instrument]] <math> \\ S_t \\,</math> is usually modelled such that it follows a [[geometric Brownian motion]] with constant drift <math> \\mu \\,</math> and [[Volatility (finance)|volatility]] <math> \\sigma \\,</math>. So: <math> dS_t = \\mu S_t\\,dt + \\sigma S_t\\,dW_t \\, </math>, where <math> dW_t \\,</math> is found via a [[random sampling]] from a [[normal distribution]]; see [[Black–Scholes#The model|further]] under [[Black–Scholes]]. Since the underlying random process is the same, for enough price paths, the value of a [[european option]] here should be [[Convergence (mathematics)|the same as under Black Scholes]]. More generally though, simulation is employed for [[Path dependence|path dependent]] [[exotic derivatives]], such as [[Asian options]].\n*In other cases, the source of uncertainty may be at a remove. For example, for [[bond option]]s <ref>Peter Carr and Guang Yang: [http://www.math.nyu.edu/research/carrp/papers/pdf/hjm.pdf Simulating American Bond Options in an HJM Framework]</ref> the underlying is a [[Bond (finance)|bond]], but the source of uncertainty is the annualized [[interest rate]] (i.e. the [[Short-rate model#The short rate|short rate]]). Here, for each randomly generated [[yield curve]] we observe a different [[Bond valuation#Arbitrage-free pricing approach|resultant bond price]] on the option's exercise date; this bond price is then the input for the determination of the option's payoff. The same approach is used in valuing [[swaption]]s,<ref>Carlos Blanco, Josh Gray and Marc Hazzard: [http://www.fea.com/resources/pdf/swaptions.pdf Alternative Valuation Methods for Swaptions: The Devil is in the Details]</ref> where the value of the underlying [[swap (finance)|swap]] is also a function of the evolving interest rate. (Whereas these options are more commonly valued using [[Lattice model (finance)|lattice based models]], as above, for path dependent [[interest rate derivative]]s – such as [[Collateralized mortgage obligation|CMOs]] – simulation is the ''primary'' technique employed.<ref>[[Frank J. Fabozzi]]: [https://books.google.com/books?id=wF8yVzLI6EYC&pg=PA138&lpg=PA138&dq=cmo+valuation+fabozzi+simulation&source=bl&ots=zSvgwSKm2V&sig=lW48IuS6CEQAch0f-uGVyHdIg3A&hl=en&ei=tcfATqPPB8SKhQfGovGzBA&sa=X&oi=book_result&ct=result&resnum=4&ved=0CC4Q6AEwAw#v=onepage&q&f=false ''Valuation of fixed income securities and derivatives'', pg. 138]</ref>) For the models used to simulate the interest-rate see [[Short-rate model#Particular short-rate models|further]] under [[Short-rate model]]; note also that \"to create realistic interest rate simulations\" [[Short rate model#Multi-factor short-rate models|Multi-factor short-rate models]] are sometimes employed.<ref>Donald R. van Deventer (Kamakura Corporation): [http://www.kamakuraco.com/Blog/tabid/231/EntryId/347/Pitfalls-in-Asset-and-Liability-Management-One-Factor-Term-Structure-Models.aspx Pitfalls in Asset and Liability Management: One Factor Term Structure Models]</ref>\n*Monte Carlo Methods allow for a [[Joint probability|compounding in the uncertainty]].<ref name=\"Cortazar et al\">Gonzalo Cortazar, Miguel Gravet and Jorge Urzua: [http://www.realoptions.org/papers2005/Cortazar_GU052RealOptionsParis.pdf The valuation of multidimensional American real options using the LSM simulation method]</ref> For example, where the underlying is denominated in a foreign currency, an additional source of uncertainty will be the [[exchange rate]]: the underlying price and the exchange rate must be separately simulated and then combined to determine the value of the underlying in the local currency. In all such models, [[correlation]] between the underlying sources of risk is also incorporated; see [[Cholesky decomposition#Monte Carlo simulation]]. Further complications, such as the impact of [[commodity markets|commodity prices]] or [[inflation]] on the underlying, can also be introduced. Since simulation can accommodate complex problems of this sort, it is often used in analysing [[real options]] <ref name=\"Marco Dias\"/>  where management's decision at any point is a function of multiple underlying variables.\n*Simulation can similarly be used to value options where the payoff depends on the value of multiple underlying assets <ref>global-derivatives.com: [http://www.global-derivatives.com/index.php?option=com_content&task=view&id=26#MCS Basket Options – Simulation]</ref> such as a [[Basket option]] or [[Rainbow option]]. Here, correlation between asset returns is likewise incorporated.\n*As required, Monte Carlo simulation can be used with any type of [[probability distribution]], including changing distributions: the modeller is not limited to [[normal distribution|normal]] or [[lognormal distribution|lognormal]] returns;<ref name=\"Tanenbaum\"/> see for example [[Datar–Mathews method for real option valuation]]. Additionally, the [[stochastic process]] of the underlying(s) may be specified so as to exhibit [[jump process|jumps]] or [[mean reverting process|mean reversion]] or both; this feature makes simulation the primary valuation method applicable to [[energy derivative]]s.<ref>Les Clewlow, Chris Strickland and Vince Kaminski: [http://www.erasmusenergy.com/downloadattachment.php?aId=4b0d2207d4169ee155591c70efa19c63&articleId=139 Extending mean-reversion jump diffusion]</ref> Further, some models even allow for (randomly) varying [[Statistical parameter|statistical]] (and other) [[parameter]]s of the sources of uncertainty. For example, in models incorporating [[stochastic volatility]], the [[Volatility (finance)|volatility]] of the underlying changes with time; see [[Heston model]].\n\n==Least Square Monte Carlo==\nLeast Square Monte Carlo is used in valuing American options. The technique works in a two step procedure.\n\n*First, a [[backward induction]] process is performed in which a value is recursively assigned to every state at every timestep. The value is defined as the [[least squares regression]] against market price of the option value at that [[State prices|state]] and time (-step). Option value for this regression is defined as the value of exercise possibilities (dependent on market price) plus the value of the timestep value which that exercise would result in (defined in the previous step of the process).\n*Secondly, when all states are valued for every timestep, the value of the option is calculated by moving through the timesteps and states by making an optimal decision on option exercise at every step on the hand of a price path and the value of the state that would result in. This second step can be done with multiple price paths to add a stochastic effect to the procedure.\n\n==Application==\nAs can be seen, Monte Carlo Methods are particularly useful in the valuation of options with multiple sources of uncertainty or with complicated features, which would make them difficult to value through a straightforward [[Black–Scholes]]-style or [[BOPM|lattice based]] computation. The technique is thus widely used in valuing path dependent structures like [[Lookback option|lookback-]] and [[Asian option]]s  <ref name=\"Tanenbaum\">Rich Tanenbaum: [http://www.savvysoft.com/treevsmontecarlo.htm Battle of the Pricing Models: Trees vs Monte Carlo]</ref> and in [[real options analysis]].<ref name=\"Marco Dias\"/><ref name=\"Cortazar et al\"/> Additionally, as above, the modeller is not limited as to the probability distribution assumed.<ref name=\"Tanenbaum\"/>\n\nConversely, however, if an [[Closed-form expression|analytical technique]] for valuing the option exists—or even a [[Numerical methods|numeric technique]], such as a (modified) [[binomial options pricing model|pricing tree]] <ref name=\"Tanenbaum\"/>—Monte Carlo methods will usually be too slow to be competitive.  They are, in a sense, a method of last resort;<ref name=\"Tanenbaum\"/> see  [[Monte Carlo methods in finance#Level of complexity|further]] under [[Monte Carlo methods in finance]]. With faster computing capability this computational constraint is less of a concern.\n\n== See also ==\n* [[Comparison of risk analysis Microsoft Excel add-ins]]\n\n== References ==\n'''Notes'''\n{{Reflist|group=\"Notes\"}}\n'''Sources'''\n{{Reflist}}\n'''Primary references'''\n*{{cite journal|last1=Boyle |first1=Phelim P. |url=http://ideas.repec.org/a/eee/jfinec/v4y1977i3p323-338.html |accessdate=June 28, 2012 |title=Options: A Monte Carlo Approach |journal=Journal of Financial Economics |volume=4 |number=3 |year=1977 |pages=323–338 |doi=10.1016/0304-405x(77)90005-8}}\n*{{cite journal|last1=Broadie |first1=M. |first2=P. |last2=Glasserman |url=http://www.columbia.edu/~mnb2/broadie/Assets/bg_ms_1996.pdf |accessdate=June 28, 2012 |title=Estimating Security Price Derivatives Using Simulation |journal=Management Science |volume=42 |issue=2 |year=1996 |pages=269–285 |doi=10.1287/mnsc.42.2.269|citeseerx=10.1.1.196.1128 }}\n*{{cite journal|last1=Longstaff |first1=F.A. |first2=E.S. |last2=Schwartz |url=http://repositories.cdlib.org/anderson/fin/1-01/ |accessdate=June 28, 2012 |title=Valuing American options by simulation: a simple least squares approach |journal=Review of Financial Studies |volume=14 |year=2001 |pages=113–148 |doi=10.1093/rfs/14.1.113|citeseerx=10.1.1.155.3462 }}\n\n'''Bibliography'''\n* {{cite book | title = Monte Carlo:methodologies and applications for pricing and risk management | author = [[Bruno Dupire]] | year = 1998 | publisher = Risk }}\n* {{cite book | title = Monte Carlo methods in financial engineering | author = Paul Glasserman | year = 2003 | publisher = [[Springer-Verlag]] | isbn = 978-0-387-00451-8 }}\n* {{cite book | title = Monte Carlo methods in finance | author = [[Peter Jaeckel]] | year = 2002 | publisher = John Wiley and Sons | isbn = 978-0-471-49741-7 }}\n* {{cite book | title = Monte Carlo Simulation & Finance | author = Don L. McLeish| year = 2005 | publisher = |isbn = 978-0-471-67778-9}}\n* {{cite book | title = Monte Carlo Statistical Methods| author = Christian P. Robert, George Casella| year = 2004 | publisher = |isbn = 978-0-387-21239-5}}\n\n==External links==\n''' Online tools'''\n*[http://25yearsofprogramming.com/blog/20070412c-montecarlostockprices.htm Monte Carlo simulated stock price time series and random number generator] (allows for choice of distribution), Steven Whitney\n\n'''Discussion papers and documents'''\n<!-- alphabetical by author -->\n*[http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN96-03.pdf Monte Carlo Simulation], Prof. Don M. Chance, [[Louisiana State University]]\n*[http://www.quantnotes.com/publications/papers/Fink-montecarlo.pdf Pricing complex options using a simple Monte Carlo Simulation], Peter Fink (reprint at quantnotes.com)\n*[http://www.global-derivatives.com/maths/k-o.php MonteCarlo Simulation in Finance], global-derivatives.com\n*[http://spears.okstate.edu/home/tlk/legacy/fin5883/notes6_s05.doc Monte Carlo Derivative valuation], [http://spears.okstate.edu/home/tlk/legacy/fin5883/notes7_s05.doc contd.], Timothy L. Krehbiel, [[Oklahoma State University–Stillwater]]\n*[http://www.smartquant.com/references/MonteCarlo/mc6.pdf Applications of Monte Carlo Methods in Finance: Option Pricing], Y. Lai and J. Spanier, [[Claremont Graduate University]]\n*[http://finance-old.bi.no/~bernt/gcc_prog/recipes/recipes/node12.html Option pricing by simulation], Bernt Arne Ødegaard, [[Norwegian School of Management]]\n*[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.194.9001 Pricing and Hedging Exotic Options with Monte Carlo Simulations], Augusto Perilla, Diana Oancea, Prof. Michael Rockinger, [[HEC Lausanne]]\n*[http://www.riskglossary.com/link/monte_carlo_method.htm Monte Carlo Method], riskglossary.com\n\n{{Derivatives market}}\n\n[[Category:Monte Carlo methods in finance]]\n[[Category:Options (finance)]]"
    },
    {
      "title": "Potential future exposure",
      "url": "https://en.wikipedia.org/wiki/Potential_future_exposure",
      "text": "{{Unreferenced|date=March 2007}}\n\n'''Potential Future Exposure''' ('''PFE''') is the maximum expected [[Credit Exposure|credit exposure]] over a specified period of time calculated at some level of confidence (i.e. at a given [[quantile]]).\n\nPFE is a measure of [[counterparty]] [[risk]]/[[credit risk]]. It is calculated by evaluating existing [[trade]]s done against the possible [[market price]]s in future during the lifetime of [[Financial transaction|transaction]]s. It can be called [[sensitivity of risk]] with respect to market prices. The calculated expected maximum exposure value is not to be confused with the maximum credit exposure possible. Instead, the maximum credit exposure indicated by the PFE analysis is an upper bound on a [[confidence interval]] for future credit exposure.\n\nCredit risk managers have traditionally remained focused on current exposure measurement (i.e., current [[mark-to-market]] exposure, plus outstanding receivables) and [[collateral management]]. The problem with this focus is that it places excessive emphasis on the present and fails to provide an acceptable indication of credit risk at some point in the future. Because losses from credit risk take a relatively long time to evolve, a more useful measure of exposure is potential exposure. Potential exposure is not like current exposure. It exists in the future and therefore represents a range or distribution of outcomes rather than a single [[point estimate]].\n\n==Relevance==\n\nPFE is essential to [[bank regulation]] under [[Basel III]] and [[Dodd-Frank Wall Street Reform and Consumer Protection Act|Dodd Frank]].\nFundamentally, to assess the safety of a bank's asset portfolio and the adequacy of its [[Tier 1 capital]] (and [[Tier 2 capital]]), one needs to evaluate whether it is resilient under severely stressing market moves. Because PFE is a measure of credit exposure, the most relevant stress move for PFE are not those where a large trading loss occurs (as they are when considering an institution's [[market risk]]). Instead, the scenarios of significant PFE can often be where the institution makes a large [[Mark-to-market_accounting#Simple_example|\"paper\"]] [[Profit (accounting)|profit]] with a [[counterparty]]; and therefore accrues a large unsecured claim on that counterparty (a claim that the counterparty may be unable to pay). For example, a trader might be cheap [[insurance]] contracts against a rare but catastrophic risk. The vast majority of the time - and for many years running - the trader will make a small annual loss (the [[Credit default swap|CDS]] premium) even if the trade has positive [[expected value]]. When the rare event occurs, the trader may suddenly have a huge windfall \"profit\" claim against whoever wrote the \"insurance\". And this would mean a sudden increase in the relevance of whether or not the 'insurance writing' counterparty can actual pay. The possibility that the counterparty cannot pay (this huge new claim) would create a systematically important ''difference'' between the theoretical-credit-risk-free profits of the trader (and his institution) and his realized year end profit. Since institutional market risks are hedged, this ''difference'' could impact the institution's capital not merely as a failure to make excess profits, but actually as a significant net loss (due to losses on the offsetting hedge position). And potentially, exposure to such credit losses could make the \"profit-making\" trader's institution fail (and default on its own obligations to other companies) thereby causing other companies to suffer credit risk losses and fail (in the same way). The theoretical potential for a cascading series of institutional failures (caused by sudden rises in PFE) is apparent. The cost of avoiding or dealing with these risks can fall on the public (the vast majority of whom will not gain directly from the institutional profits made while accruing large PFE claims). This is for two main reasons. First, government directly (or indirectly) insures many retail deposits (to prevent bank runs and to promote savings), and many quasi-government agencies (ex : [[FNMA]], [[Freddie Mac]]) have de facto government backing. Second, even when a major firm does not have government insured deposits, it can be \"systemically important\" (such as AIG) - its failure would potentially cause panic, destroy market liquidity, and precipitate a crash and potential widespread economic contraction / [[Depression (economics)|depression]]. One plan that is intended to reduce the public cost (& private benefit) of the implicit support to \"[[too big to fail]]\" institutions is to reduce the variability and scale of PFE by incentivizing [[Collateral management|collateralization]].\n\n== Expected Exposure ==\nThe '''Expected Exposure''' ('''EE''') is defined similarly to the PFE, except that the average is used instead of a specific quantile.\n\nThe EE represents the estimated average loss at a specific future point of time that a lender would suffer from if the borrower (counterparty) fully defaults on his debt (i.e. if the [[Loss given default|Loss Given Default (LGD)]] was 100%).\n\n== See also ==\n* [[Credit valuation adjustment]]\n\n==External links==\n*[https://www.bis.org/bcbs/basel3.htm] - Basel III, International Regulatory Frameworks for Banks.\n\n[[Category:Credit]]\n[[Category:Financial risk]]\n[[Category:Investment]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Profit at risk",
      "url": "https://en.wikipedia.org/wiki/Profit_at_risk",
      "text": "{{Distinguish|Profit risk}}\n\n'''Profit-at-Risk (PaR)''' is a [[risk management]] quantity most often used for electricity portfolios that contain some mixture of generation assets, trading contracts and end-user consumption. It is used to provide a measure of the downside risk to profitability of a portfolio of physical and financial assets, analysed by time periods in which the energy is delivered. For example, the expected profitability and associated downside risk (PaR) might be calculated and monitored for each of the forward looking 24 months. The measure considers both [[price risk]] and [[volume risk]] (e.g. due to uncertainty in electricity generation volumes or consumer demand).<ref name=ARTdef>{{cite web|title=What is Profit-at-Risk (PaR)?|url=http://www.arbitrage-trading.com/ARTicles_WhatIsPaR.htm|website=.arbitrage-trading.com|publisher=ART Ltd|accessdate=8 January 2016}}</ref> Mathematically, the PaR is the quantile of the profit distribution of a portfolio. Since weather related volume risk drivers can be represented in the form of historical weather records over many years, a [[Monte-Carlo simulation]] approach is often used.\n\n== Example ==\nIf the confidence interval for evaluating the PaR is 95%, there is a 5% probability that due to changing commodity volumes and prices, the\nprofit outcome for a specific period (e.g. December next year) will fall short of the expected profit result by more than the PaR value.\n\nNote that the concept of a set 'holding period' does not apply since the period is always up until the realisation of the profit outcome through the delivery of energy. That is the holding period is different for each of the specific delivery time periods being analysed e.g. it might be six months for December and therefore seven months for January.\n\n== History ==\nThe PaR measure was originally pioneered at Norsk Hydro in Norway as part of an initiative to prepare for deregulation of the electricity market. Petter Longva and Greg Keers co-authored a paper \"Risk Management in the Electricity Industry\" (IAEE 17th Annual International Conference, 1994) which introduced the PaR method. This led to it being adopted as the basis for electricity market risk management at Norsk Hydro and later by most of the other electricity generating utilities in the Nordic region. The approach was based on monte-carlo simulations of paired reservoir inflow and spot price outcomes to produce a distribution of expected profit in future reporting periods. This tied directly with the focus of management reporting on profitability of operations, unlike the Value-at-Risk approach that had been pioneered by JP Morgan for banks focused on their balance sheet risks.\n\n== Critics ==\nAs is the case with ''[[Value at Risk]]'', for risk measures like the PaR, [[Earnings at risk|Earnings-at-Risk]] (EaR), the [[Liquidity at risk|Liquidity-at-Risk]] (LaR) or the [[Margin at risk|Margin-at-Risk]] (MaR), the exact ([[algorithmic trading|algorithmic]]) implementation rule vary from firm to firm.<ref name=EnBW>{{cite web|last1=Burger|first1=Markus|title=Risk measures for large portfolios and their applications in energy trading|url=http://www.risklab.es/es/jornadas/2011/RiskLab2011_Burger.pdf|website=risklab.es|publisher=EnBW Energie Baden-Württemberg AG|accessdate=8 January 2016}}</ref>\n\n== See also ==\n* [[Value at risk]]\n* [[Margin at risk]]\n* [[Liquidity at risk]]\n\n== References ==\n{{reflist}}\n\n{{Financial risk}}\n\n[[Category:Mathematical finance]]\n[[Category:Financial risk management]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Statistical finance",
      "url": "https://en.wikipedia.org/wiki/Statistical_finance",
      "text": "{{context|date=January 2012}}\n\n'''Statistical finance''',<ref>J-P Bouchaud, An introduction to Statistical Finance, Physica A 313 (2002) 238&ndash;251</ref> is the application of [[econophysics]]<ref>V. Perou, E. Gopikrishnan, L A Amaral, M. Meyer, H. E. Stanley, Phys. Rev. E 60 6519 (1999)</ref> to [[financial market]]s. Instead of the [[Normative economics|normative]] roots of much of the field of [[finance]], it uses a [[positivist]] framework including exemplars from [[statistical physics]] with an emphasis on emergent or collective properties of financial markets. The starting point for this approach to understanding financial markets are the empirically observed [[stylized fact]]s.\n\n==Stylized facts ==\n\n# Stock markets are characterised by bursts of price volatility.\n# Price changes are less volatile in bull markets and more volatile in bear markets.\n# Price change correlations are stronger with higher volatility, and their auto-correlations die out quickly.\n# Almost all real data have more extreme events than suspected.\n# Volatility correlations decay slowly.\n# Trading volumes have memory the same way that volatilities do.\n# Past price changes are negatively correlated with future volatilities.\n\n== Research objectives ==\n\nStatistical finance is focused on three areas:\n\n# Empirical studies focused on the discovery of interesting statistical features of financial time-series data aimed at extending and consolidating the known [[stylized fact]]s.\n# The use of these discoveries to build and implement models that better price derivatives and anticipate stock price movement with an emphasis on [[non-Gaussian]] methods and models.\n# The study of collective and emergent behaviour in simulated and real markets to uncover the mechanisms responsible for the observed stylized facts with an emphasis on [[agent-based model]]s.\n\nIt is noteworthy that [[financial econometrics]] also has a focus on the first two of these three areas. However, there is almost no overlap or interaction between the community of statistical finance researchers (who typically publish in physics journals) and the community of financial econometrics researchers (who typically publish in economics journals).\n\n== Behavioral finance and statistical finance ==\n\nBehavioural finance attempts to explain price anomalies in terms of the biased behaviour of individuals, mostly concerned with the agents themselves and to a lesser degree aggregation of agent behaviour. Statistical finance is concerned with emergent properties arising from systems with many interacting agents and as such attempts to explain price anomalies in terms of the collective behaviour. Emergent properties are largely independent of the uniqueness of individual agents because they are dependent on the nature of the interactions of the agents rather than the agents themselves. This approach has drawn strongly on ideas arising from [[complex systems]], [[phase transitions]],  [[Critical phenomena|criticality]], [[self-organized criticality]], non-extensivity (see [[Tsallis entropy]]), q-Gaussian models,  and agents based models (see [[agent based model]]); as these are known to be able to recover some of phenomenology of financial market data, the [[stylized fact]]s, in particular the [[long-range memory]] and scaling due to long-range interactions.\n\n== Criticism ==\n\nWithin the subject the description of financial markets blindly in terms of models of statistical physics has been argued as flawed because it has transpired these do not fully correspond to what we now know about real finance markets. First, traders create largely noise, not long range correlations among themselves, except when they all buy or all sell, such as during a popular IPO or during a crash.  A market is not at an equilibrium critical point, the resulting non-equilibrium market must reflect details of traders' interactions (universality applies only to a limited very class of bifurcations, and the market does not sit at a bifurcation). Even if the notion of a thermodynamics equilibrium is considered not at the level of the agents but in terms of collections of instruments stable configurations are not observed. The market does not 'self-organize' into a stable statistical equilibrium, rather, markets are unstable. Although markets could be 'self-organizing' in the sense used by [[finite-time singularity]] models these models are difficult to falsify. Although Complex systems have never been defined in a broad sense financial markets do satisfy reasonable criterion of being considered complex adaptive systems.<ref>Financial Market Complexity, Johnson, Jefferies and Hui, Oxford 2003</ref> The Tallis doctrine has been put into question as it is apparently a special case of markov dynamics so questioning the very notion of a \"non-linear Fokker-Plank equation\". In addition, the standard 'stylized facts' of financial markets, fat tails, scaling, and universality are not observed in real FX markets even if they are observed in equity markets.\n\nFrom outside the subject the approach has been considered by many as a dangerous view of finance which has drawn criticism from some [[heterodox economics|heterodox economists]] because of:<ref>[[Mauro Gallegati]], [[Steve Keen]], [[Thomas Lux]] and [[Paul Ormerod]], ''Worrying Trends in Econophysics'', [[Physica A]] '''370''', 1-6 (2006).</ref> \n# \"A lack of awareness of work which has been done within economics itself.\"\n# \"Resistance to more rigorous and robust statistical methodology.\"\n# \"The belief that universal empirical regularities can be found in many areas of economic activity.\"\n# \"The theoretical models which are being used to explain empirical phenomena.\"\nIn response to these criticism there are claims of a general maturing of these non-traditional empirical approaches to Finance.<ref>\"Response to worrying trends in econophysics\", McCauley, J. L. Physica A 2.371(2006): pp. 601&ndash;609 http://mpra.ub.uni-muenchen.de/2129/1/MPRA_paper_2129.pdf</ref> This defense of the subject does not flatter the use of physics metaphors but does defend the alternative empirical approach of \"econophysics\" itself.\n\nSome of the key data claims have been questioned in terms of methods of data analysis.<ref>Kevin E. Bassler, Joseph L. McCauley, and Gemunu H. Gunaratne, Nonstationary increments, scaling distributions, and variable diffusion processes in financial markets, Proc. Natl. Acad. Sci. (USA) 104, 17287-17290 (2007). http://www.pnas.org/cgi/doi/10.1073/pnas.0708664104</ref>\n\nSome of the ideas arising from nonlinear sciences and statistical physics have been helpful in shifting our understanding financial markets, and may yet be found useful, but the particular requirements of stochastic analysis to the specific models useful in finance is apparently unique to finance as a subject. There is much lacking in this approach to finance yet it would appear that the canonical approach to finance based optimization of individual behaviour given information and preferences with assumptions to allow aggregation in equilibrium are even more problematic.\n\nIt has been suggested that what is required is a change in mindset within finance and economics that moves the field towards methods of natural science.<ref>J-P. Bouchaud, Economics needs a scientific revolution https://arxiv.org/abs/0810.5306v1</ref> Perhaps finance needs to be thought of more as an observational science where markets are observed in the same way as the observable universe in cosmology, or the observable ecosystems in the environmental sciences. Here local principles can be uncovered by local experiments but meaningful global experiments are difficult to envision as feasible without reproducing the system being observed. The required science becomes that based largely on pluralism (see [[scientific pluralism]] the view that some phenomena observed in science require multiple explanations to account for their nature), as in most sciences that deal with complexity, rather than a singled unified mathematical framework that is to be verified by experiment.\n\n== See also ==\n* [[Mathematical finance]]\n* [[Econophysics]]\n* [[Financial econometrics]]\n* [[Complexity]]\n* [[Statistical physics]]\n* [[Modeling and analysis of financial markets]]\n* [[Time series analysis]]\n\n== References ==\n\n<references/>\n\n== Bibliography ==\n\nSee  [[econophysics#Books|Econophysics bibliography and text books]]\n\n*[[Jean-Philippe Bouchaud]], [[Marc Potters]], ''Theory of Financial Risk and Derivative Pricing'', Cambridge University Press (2003)\n* [[Rosario N. Mantegna]], [[H. Eugene Stanley]], ''An Introduction to Econophysics: Correlations and Complexity in Finance'',  Cambridge University Press (1999)\n* [[Neil F. Johnson]], [[Paul Jefferies]] and [[Pak Ming Hui]], ''Financial Market Complexity: What Physics Can Tell Us About Market Behaviour'', Oxford University Press (2003)\n*{{Cite journal| last = Mantegna | first = Rosario N. | authorlink = |author2=Kertesz, Janos   | year = 2010 | title = Focus on Statistical Physics Modelling in Economics and Finance | journal = [[New Journal of Physics]] | volume =  | issue =  | pages = | doi =  | url = http://iopscience.iop.org/1367-2630/focus/Focus%20on%20Statistical%20Physics%20Modelling%20in%20Economics%20and%20Finance | accessdate = | quote =}}\n\n== External links ==\n* [https://arxiv.org/list/q-fin.ST/recent Statistical Finance at arXiv.org]\n\n{{Finance}}\n\n[[Category:Mathematical finance]]\n[[Category:Applied and interdisciplinary physics]]\n[[Category:Monte Carlo methods in finance]]\n[[Category:Emergence]]"
    },
    {
      "title": "Stochastic investment model",
      "url": "https://en.wikipedia.org/wiki/Stochastic_investment_model",
      "text": "{{Multiple issues|\n{{prose|date=January 2012}}\n{{no footnotes|date=June 2012}}\n}}\n\nA '''stochastic investment model''' tries to forecast how [[rate of return|returns]] and [[price]]s on different assets or asset classes, (e. g. equities or bonds) vary over time. Stochastic models are not applied for making [[point estimation]] rather [[interval estimation]] and they use different [[stochastic process]]es.{{clarify|rason=different to what|date=January 2012}} Investment models can be classified into single-asset and multi-asset models. They are often used for [[actuary|actuarial]] work and [[financial plan]]ning to allow optimization in [[asset allocation]] or [[asset liability management|asset-liability-management (ALM)]].\n\n==Single-asset models==\n\n===Interest rate models===\nInterest rate models can be used to price [[fixed income]] products. They are usually divided into one-factor models and multi-factor assets.\n\n====One-factor models====\n\n* [[Black–Derman–Toy model]]\n* [[Black–Karasinski model]]\n* [[Cox–Ingersoll–Ross model]]\n* [[Ho–Lee model]]\n* [[Hull–White model]]\n* [[Kalotay–Williams–Fabozzi model]]\n* [[Merton model]]\n* [[Rendleman–Bartter model]]\n* [[Vasicek model]]\n\n====Multi-factor models====\n\n* [[Chen model]]\n* [[Longstaff–Schwartz model]]\n\n===Term structure models===\n* [[LIBOR market model|LIBOR market model (Brace Gatarek Musiela model)]]\n\n===Stock price models===\n* [[Binomial model]]\n* [[Black–Scholes model]] ([[geometric Brownian motion]])\n\n===Inflation models===\n\n==Multi-asset models==\n* ALM.IT (GenRe) model\n* Cairns model\n* FIM-Group model\n* Global CAP:Link model\n* Ibbotson and Sinquefield model\n* Morgan Stanley model\n* Russel–Yasuda Kasai model\n* Smith's jump diffusion model\n* TSM (B & W Deloitte) model\n* Watson Wyatt model\n* Whitten & Thomas model\n* [[Wilkie investment model]]\n* Yakoubov, Teeger & Duval model\n\n==Further reading==\n\n*Wilkie, A. D. (1984) [http://www.actuaries.org.uk/sites/all/files/documents/pdf/0341-0403.pdf \"A stochastic investment model for actuarial use\"], ''Transactions of the Faculty of Actuaries'', 39: 341-403\n*Østergaard, Søren Duus (1971) \"Stochastic Investment Models and Decision Criteria\", ''The Swedish Journal of Economics'', 73 (2), 157-183 {{jstor|3439055}}\n*Sreedharan, V. P.; Wein, H. H. (1967) \"A Stochastic, Multistage, Multiproduct Investment Model\", ''SIAM Journal on Applied Mathematics'', 15 (2), 347-358 {{jstor|2946287}}\n\n[[Category:Financial models]]\n[[Category:Monte Carlo methods in finance]]"
    },
    {
      "title": "Stochastic modelling (insurance)",
      "url": "https://en.wikipedia.org/wiki/Stochastic_modelling_%28insurance%29",
      "text": ":''This page is concerned with the '''stochastic modelling''' as applied to the insurance industry.  For other stochastic modelling applications, please see [[Monte Carlo method]] and [[Stochastic asset model]]s.  For mathematical definition, please see [[Stochastic process]].''\n\n\n\"[[Stochastic]]\" means being or having a [[random variable]]. A '''stochastic model''' is a tool for estimating [[probability distribution]]s of potential outcomes by allowing for random variation in one or more inputs over time. The random variation is usually based on fluctuations observed in historical data for a selected period using standard [[time-series]] techniques. Distributions of potential outcomes are derived from a large number of [[simulation]]s (stochastic projections) which reflect the random variation in the input(s).\n\nIts application initially started in [[physics]]. It is now being applied in [[engineering]], [[life sciences]], [[social science]]s, and [[finance]]. See also [[Economic capital]].\n\n==Valuation==\nLike any other company, an [[insurer]] has to show that its [[assets]] exceeds its [[liability (financial accounting)|liabilities]] to be solvent. In the insurance industry, however, assets and liabilities are not known entities. They depend on how many policies result in claims, inflation from now until the claim, investment returns during that period, and so on.\n\nSo the valuation of an insurer involves a set of projections, looking at what is expected to happen, and thus coming up with the best estimate for assets and liabilities, and therefore for the company's level of solvency.\n\n==Deterministic approach==\nThe simplest way of doing this, and indeed the primary method used, is to look at best estimates.\n\nThe projections in financial analysis usually use the most likely rate of claim, the most likely investment return, the most likely rate of inflation, and so on. The projections in engineering analysis usually use both the most likely rate and the most critical rate.  The result provides a point estimate - the best single estimate of what the company's current solvency position is, or multiple points of estimate - depends on the problem definition. Selection and identification of parameter values are frequently a challenge to less experienced analysts.\n\nThe downside of this approach is it does not fully cover the fact that there is a whole range of possible outcomes and some are more probable and some are less.\n\n==Stochastic modelling==\nA stochastic model would be to set up a projection model which looks at a single policy, an entire portfolio or an entire company. But rather than setting investment returns according to their most likely estimate, for example, the model uses random variations to look at what investment conditions might be like.\n\nBased on a set of random variables, the experience of the policy/portfolio/company is projected, and the outcome is noted. Then this is done again with a new set of random variables. In fact, this process is repeated thousands of times.\n\nAt the end, a distribution of outcomes is available which shows not only the most likely estimate but what ranges are reasonable too. The most likely estimate is given by the distribution curve's (formally known as the [[Probability density function]]) center of mass which is typically also the peak(mode) of the curve, but may be different e.g. for asymmetric distributions.\n\nThis is useful when a policy or fund provides a guarantee, e.g. a minimum investment return of 5% per annum. A deterministic simulation, with varying scenarios for future investment return, does not provide a good way of estimating the cost of providing this guarantee. This is because it does not allow for the volatility of investment returns in each future time period or the chance that an extreme event in a particular time period leads to an investment return less than the guarantee. Stochastic modelling builds volatility and variability (randomness) into the simulation and therefore provides a better representation of real life from more angles.\n\n==Numerical evaluations of quantities==\nStochastic models help to assess the interactions between variables, and are useful tools to numerically evaluate quantities, as they are usually implemented using Monte Carlo simulation techniques (see [[Monte Carlo method]]).  While there is an advantage here, in estimating quantities that would otherwise be difficult to obtain using analytical methods, a disadvantage is that such methods are limited by computing resources as well as simulation error.  Below are some examples:\n\n===Means===\n\nUsing statistical notation, it is a well-known result that the [[mean]] of a function, f, of a [[random variable]] X is not necessarily the function of the mean of X.\n\nFor example, in application, applying the best estimate (defined as the mean) of investment returns to discount a set of cash flows will not necessarily give the same result as assessing the best estimate to the [[discounted cash flow]]s.\n\nA stochastic model would be able to assess this latter quantity with simulations.\n\n===Percentiles===\n\nThis idea is seen again when one considers percentiles (see [[percentile]]).  When assessing risks at specific percentiles, the factors that contribute to these levels are rarely at these percentiles themselves.  Stochastic models can be simulated to assess the percentiles of the aggregated distributions.\n\n===Truncations and censors===\n\nTruncating and censoring of data can also be estimated using stochastic models.  For instance, applying a non-proportional  [[reinsurance]] layer to the best estimate losses will not necessarily give us the best estimate of the losses after the reinsurance layer.  In a simulated stochastic model, the simulated losses can be made to \"pass through\" the layer and the resulting losses assessed appropriately.\n\n==The asset model==\nAlthough the text above referred to \"random variations\", the stochastic model does not just use any arbitrary set of values. The asset model is based on detailed studies of how markets behave, looking at averages, variations, correlations, and more.\n\nThe models and underlying parameters are chosen so that they fit historical economic data, and are expected to produce meaningful future projections.\n\nThere are many such [[stochastic investment model|models]], including the [[Wilkie investment model|Wilkie Model]], the [[Thompson Model]] and the [[Falcon Model]].\n\n==The claims model==\nThe claims arising from policies or portfolios that the company has written can also be modelled using stochastic methods.  This is especially important in the general insurance sector, where the  claim severities can have high uncertainties.\n\n===Frequency-Severity models===\n\nDepending on the portfolios under investigation, a model can simulate all or some of the following factors stochastically:\n\n*Number of claims\n*Claim severities\n*Timing of claims\n\nClaims inflations can be applied, based on the inflation simulations that are consistent with the outputs of the asset model, as are dependencies between the losses of different portfolios.\n\nThe relative uniqueness of the policy portfolios written by a company in the general insurance sector means that claims models are typically tailor-made.\n\n===Stochastic reserving models===\n\nEstimating future claims liabilities might also involve estimating the uncertainty around the estimates of claim reserves.\n\nSee J Li's article \"Comparison of Stochastic Reserving Models\" (published in the ''Australian Actuarial Journal'', volume 12 issue 4) for a recent article on this topic.\n\n==References==\n*[http://www.actuaries.org.uk/files/pdf/life_insurance/GN47notes_20050902.pdf Guidance on stochastic modelling for life insurance reserving] (pdf)\n*[http://www.actuaries.asn.au/Library/Vol12_Issue4%28web%29.pdf J Li's article on stochastic reserving from the Australian Actuarial Journal, 2006] (pdf)\n*[http://www.actuarialsociety.org.za/Portals/2/Documents/Convention-StocasticModellingForDummies-PW-YH-2007.pdf Stochastic Modelling For Dummies], [[Actuarial Society of South Africa]]\n\n[[Category:Actuarial science]]\n[[Category:Stochastic models]]\n[[Category:Monte Carlo methods in finance]]"
    }
  ]
}