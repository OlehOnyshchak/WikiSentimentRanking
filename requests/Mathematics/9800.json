{
  "pages": [
    {
      "title": "Frink (programming language)",
      "url": "https://en.wikipedia.org/wiki/Frink_%28programming_language%29",
      "text": "{{notability|date=October 2018}}\n{{Primary sources|date=June 2017}}\n{{Infobox programming language\n| name = Frink\n| logo alt = \n| paradigm = [[Multi-paradigm]]: [[object-oriented programming|object-oriented]] , [[imperative programming|imperative]], [[functional programming|functional]],\n| designer = Eliasen, Alan\n| developer =\n| typing = \n| implementations = [[Java virtual machine]]\n| influenced = \n| license =\n| File extensions = <code>.frink</code>\n| File format = \n| website = {{URL|https://frinklang.org}}\n| wikibooks = \n| year = \n| latest_release_version = \n| latest_release_date = \n| latest_preview_version =\n| latest_preview_date =\n| influenced_by = [[Java (programming language)|Java]]\n}}\n\n'''Frink''' is a computer programming language. It is, according to creator of the language, \"designed to make physical calculations simple, to help ensure that answers come out right, and to make a tool that's really useful in the real world. It tracks units of measure (feet, meters, kilograms, watts, etc.) through all calculations, allowing you to mix units of measure transparently, and helps you easily verify that your answers make sense.\"<ref name=\"frinktool\">{{cite web |last=Eliasen |first=Alan |title=Frink (official website) |url=http://futureboy.us/frinkdocs/ |accessdate=2011-07-30}}</ref>\n\n== Features ==\n\n* units of measure for variables\n* [[Interval arithmetic]]\n* [[Anonymous function]]s\n\n== Name ==\n\nFrink was named after [[Professor Frink]], recurring character in the [[Animated cartoon|animated television series]] ''[[The Simpsons]]''.<ref name=\"frinktool\"/>\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* {{Official website|https://frinklang.org}}\n* [https://rosettacode.org/wiki/Category:Frink Frink examples at Rosetta Code]\n\n\n{{Programming languages}}\n{{Authority control}}\n\n[[Category:Cross-platform software]]\n[[Category:Scripting languages]]\n[[Category:Numerical programming languages]]"
    },
    {
      "title": "GNU Data Language",
      "url": "https://en.wikipedia.org/wiki/GNU_Data_Language",
      "text": "{{Infobox software\n| name                   = GNU Data Language\n| logo                   = [[File:GNU Data Language (logo).png|GDL logo]]\n| screenshot             = Gdl screenshot.png\n| screenshot size        = 250px\n| caption                = GDL rendering the [[Mandelbrot set]]\n| developer              = Marc Schellens\n| released               = {{Start date|2004}}\n| latest release version = 0.9.8\n| latest release date    = {{Start date and age|2018|3|26}}\n| programming language   = [[C++]] ([[wxWidgets]])\n| platform               = [[Linux]], [[Mac OS X]], [[Solaris (operating system)|Solaris]], [[POSIX]], [[Windows]]\n| status                 = Active\n| genre                  = [[List of numerical analysis software|Technical computing]]\n| license                = [[GNU General Public License]]\n| website                = {{URL|http://gnudatalanguage.sourceforge.net/}}\n}}\n\nThe '''GNU Data Language''' ('''GDL''') is a [[free software|free]] alternative to [[IDL (programming language)|IDL]] (Interactive Data Language).<ref name=\"GDL_MacObserver\" /><ref name=\"GDL_MacResearch\" /><ref name=\"Coulais_et_al_2010\" /> Together with its library routines, GDL is developed to serve as a tool for data analysis and visualization in such disciplines as astronomy,<ref name=\"GDL_astro_examples\" /> geosciences, and medical imaging.<ref name=\"GDL_homepage_CC-BY-SA\" /> \nGDL is licensed under the [[GNU General Public License|GPL]]. Other open-source numerical data analysis tools similar to GDL include [[GNU Octave]], [[NCAR Command Language]] (NCL), [[Perl Data Language]] (PDL), [[R (programming language)|R]], [[Scilab]], [[SciPy]], and [[Yorick (programming language)|Yorick]].\n\nGDL as a language is dynamically-typed, vectorized, and has object-oriented programming capabilities. GDL library routines handle numerical calculations (e.g. [[Fast Fourier transform|FFT]]), data visualisation, signal/image processing, interaction with [[host OS]], and data input/output. GDL supports several data formats, such as [[NetCDF]], [[Hierarchical Data Format|HDF]] (v4 & v5), [[GRIB]], [[Portable Network Graphics|PNG]], [[TIFF]], and [[DICOM]]. Graphical output is handled by [[X11]], [[PostScript]], [[SVG]], or z-buffer terminals, the last one allowing output graphics (plots) to be saved in raster graphics formats. GDL features integrated debugging facilities, such as [[breakpoint]]s. GDL has a [[Python (programming language)|Python]] bridge (Python code can be called from GDL; GDL can be compiled as a Python module). GDL uses [[Eigen (C++ library)]] numerical library (similar to Intel MKL) to have excellent computing performance on multi-cores processors, with better benchmark than IDL on large matrix operations.<ref name=\"GDL_homepage_CC-BY-SA\" />\n\nPackaged versions of GDL are available for several [[Linux]] and [[BSD]] flavours as well as [[Mac OS X]]. The source code compiles on [[Microsoft Windows]] (since GDL 0.9.3)<ref name=\"GDL_official_faq\" /> and other [[UNIX]] systems, including [[Solaris (operating system)|Solaris]].\n\nGDL is not an official [[List of GNU packages|GNU package]].\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[Interpreter (computing)]]\n* [[IDL (programming language)]]\n\n==References==\n{{Reflist|refs=\n<ref name=\"GDL_MacObserver\">{{cite web|last=Martellaro |first=John |authorlink= |title=A Free Alternative to IDL |work= |publisher=The Mac Observer |date=2006-12-12 |url=http://www.macobserver.com/tmo/article/A_Free_Alternative_to_IDL |format= |doi= |accessdate=2011-07-31 |archiveurl=https://www.webcitation.org/60as4yWbB?url=http://www.macobserver.com/tmo/article/A_Free_Alternative_to_IDL/ |archivedate=2011-07-31 |deadurl=no |df= }}</ref>\n\n<ref name=\"GDL_MacResearch\">{{cite web|last=Khanna |authorlink= |title=GDL .. a free IDL |work= |publisher=MacResearch |date=2006-12-13 |url=http://www.macresearch.org/gdl_a_free_idl_0 |format= |doi= |accessdate=2011-07-31 |archiveurl=https://www.webcitation.org/60asArIxz?url=http://www.macresearch.org/gdl_a_free_idl_0 |archivedate=2011-07-31 |deadurl=no |df= }}</ref>\n\n<ref name=\"Coulais_et_al_2010\">{{cite conference\n|last=Coulais\n|first=Alain\n|conference=Astronomical Data Analysis Software and Systems XIX\n|year=2010\n|title=Status of GDL - GNU Data Language\n|url=http://www.aspbooks.org/a/volumes/article_details/?paper_id=32122\n|publisher=[[Astronomical Society of the Pacific]]\n|page=187\n|booktitle=Astronomical Society of the Pacific Conference Series\n|volume=434 \n|isbn=978-1-58381-748-3\n|arxiv=1101.0679\n|display-authors=etal|bibcode=2010ASPC..434..187C\n}}</ref>\n\n<ref name=\"GDL_homepage_CC-BY-SA\">{{cite web|last=The GDL Team |authorlink= |title=GDL - GNU Data Language |work= |publisher=[[SourceForge]] |year=2011 |url=http://gnudatalanguage.sourceforge.net/ |doi= |accessdate=2011-09-10 |archiveurl=https://www.webcitation.org/60q5GchPi?url=http://gnudatalanguage.sourceforge.net/ |archivedate=2011-08-10 |deadurl=no |df= }}</ref>\n\n<ref name=\"GDL_astro_examples\">{{cite journal|author1=Mina Koleva|author2=Philippe Prugniel|author3=Antoine Bouchard|author4=Yue Wu|title=ULySS: A Full Spectrum Fitting Package|journal=Astronomy & Astrophysics |volume=501|pages=1269–1279|year=2009|arxiv=0903.2979|bibcode = 2009A&A...501.1269K |doi = 10.1051/0004-6361/200811467 }}; {{cite journal|author1=B.F. Roukema|title=On the suspected timing error in WMAP map-making|year=2010|volume=518|page=A34|journal=Astronomy & Astrophysics |arxiv=1004.4506|doi=10.1051/0004-6361/201014865|bibcode = 2010A&A...518A..34R }}</ref>\n\n<ref name=\"GDL_official_faq\">{{cite web|last1=The GDL Team|title=GDL - GNU Data Language, Frequently Asked Questions|url=http://gnudatalanguage.sourceforge.net/faq.php|accessdate=31 May 2015|year=2015}}</ref>\n}}\n\n==External links==\n* {{Official website|http://gnudatalanguage.sourceforge.net/}}\n* [http://hesperia.gsfc.nasa.gov/colinux/ Running the GNU Data Language on coLinux]\n* {{Openhub|id=gdl___gnu_data_language}}\n* Linux packages: [http://aur.archlinux.org/packages.php?ID=2493 ArchLinux], [http://packages.debian.org/gnudatalanguage Debian], [http://koji.fedoraproject.org/koji/packageinfo?packageID=1830 Fedora], [http://packages.gentoo.org/package/dev-lang/gdl Gentoo], [http://packages.ubuntu.com/gnudatalanguage Ubuntu],\n* BSD/OSX ports: [http://pdb.finkproject.org/pdb/package.php/gdl Fink], [http://www.freebsd.org/cgi/cvsweb.cgi/ports/science/gnudatalanguage/ FreeBSD], [http://trac.macports.org/browser/trunk/dports/math/gnudatalanguage/Portfile Macports]\n* [http://aramis.obspm.fr/~coulais/IDL_et_GDL/Matrice_IDLvsGDL.html A partial list of IDL 6.1 routines available in GDL as of September 2010]\n\n{{DEFAULTSORT:Gnu Data Language}}\n[[Category:Free science software]]\n[[Category:Free software programmed in C++]]\n[[Category:GNU Project software|Data language]]\n[[Category:Numerical programming languages]]\n[[Category:Software that uses wxWidgets]]"
    },
    {
      "title": "HADES (software)",
      "url": "https://en.wikipedia.org/wiki/HADES_%28software%29",
      "text": "'''HADES''' (Haskins Analysis Display and Experiment System)[http://www.haskins.yale.edu/facilities/hades.html] refers to a family of [[signal processing]] computer programs that was developed in the 1980s at [[Haskins Laboratories]] by [[Philip Rubin]] and colleagues to provide for the display and analysis of multiple channel physiological, speech, and other sampled data in an experimental context.  Principal programmers over the years on this project included Vance Maverick[http://portal.acm.org/citation.cfm?id=178251&coll=portal&dl=ACM], Mark Tiede [http://www.haskins.yale.edu/staff/tiede.html], Marian Pressler, and Simon Levy [http://cs.wlu.edu/~levy/]. The most significant feature of HADES was the incorporation of a procedural language known as ''SPIEL'' (Signal Processing Interactive Editing Language) that provided for the creation and customization of specialized analysis procedures that can be stored as text files, edited, etc., and are similar to functions and subroutines in programming languages like [[C (programming language)|C]] and [[Fortran]]. HADES was one of the earliest signal processing systems with an integrated language and, through the use of SPIEL, provided for automated procedural analysis of large datasets, usually speech data or multiple-channel physiological data acquired with specialized hardware such as the EMMA[http://vesicle.nsi.edu/users/patel/speech_database.html] [[magnetometer]] system. Previous systems at the time included ''ILS'' from STI, Inc., and the MITSYN[http://home.earthlink.net/~billhenke/index.html] system designed by Bill Henke. HADES was written in [[C (programming language)|C]] and implemented on [[VAX]] systems running [[VAX/VMS|VMS]]. Although HADES still finds limited use, its functionality was eventually replaced by commercial systems such as [[MATLAB]].\n\n== Bibliography ==\n\n* Rubin, Philip E. (1995). HADES: A Case Study of the Development of a Signal Processing System. In R. Bennett, S. L. Greenspan & A. Syrdal (Eds.), ''Behavioral Aspects of Speech Technology: Theory and Applications''. CRC Press, Boca Raton, 501-520.\n*  Rubin, Philip E. and Löfqvist, Anders (1997). HADES (Haskins Analysis Display and Experiment System). [[Haskins Laboratories]] Technical Report, unpublished.\n\n[[Category:Numerical programming languages]]\n[[Category:Digital signal processing]]"
    },
    {
      "title": "Hoc (programming language)",
      "url": "https://en.wikipedia.org/wiki/Hoc_%28programming_language%29",
      "text": "{{lowercase title}}\n'''hoc''', an acronym for '''High Order Calculator''', is an [[Interpreter (computing)|interpreted]] [[programming language]] that was used in the 1984 book [[The Unix Programming Environment]] to demonstrate how to build interpreters using [[Yacc]].\n\nhoc was developed by [[Brian Kernighan]] and [[Rob Pike]] as a glorified interactive calculator. Its basic functionality is to evaluate floating-point numerical expressions, e.g., \"1+2*sin(0.7)\". Then, variables were added, conditionals, loops, user-defined functions, simple IO, and more, using a syntax resembling C.\n\nAn improved hoc interpreter was included in [[Eighth Edition Unix|Eighth Edition]] [[Research Unix]] in 1985, but it has not been generally adopted by commercial [[Unix]] systems or by [[Linux]] distributions. Instead, the earlier calculator languages [[dc (Unix)|dc]] and [[bc programming language|bc]] have become widespread on those systems. hoc survived and continued to evolve as part of the [[Plan 9 from Bell Labs|Plan 9]] operating system. Several improved versions of Hoc were released as [[free software]] by Bell Labs and other individuals (see list below). hoc is used as the primary scripting language for the [[Neuron (software)|Neuron simulator]]. \n\n==Examples==\nThe following is a simple example of an interactive calculator session in hoc; {{highlight|highlighted|#ffffcc}} text represents hoc's output:\n<source lang=\"bc\" highlight=\"2,6,8\">\n 1+2*3\n     7\n angle=PI/3\n r=sin(angle)\n r\n     0.866025\n r*2\n     1.73205\n</source>\nAnd a simple example of functions and flow control:\n<source lang=\"bc\" highlight=\"17,19,20\">\n func atan2(){\n         if($1>0){\n                 return atan($2/$1)\n         } else if ($1<0){\n                 return atan($2/$1)+PI\n         } else if ($2>0){\n                 return PI/2\n         } else if ($2<0){\n                 return -PI/2\n         } else {\n                 print \"atan2 domain error\"\n                 return 0\n         }\n }\n \n atan2(2,3)\n     0.982794\n atan2(0,0)\n atan2 domain error\n     0.0\n</source>\n\n== References ==\n*{{cite book|last1=Kernighan|first1=Brian W.|last2=Pike|first2=Rob|title=[[The Unix Programming Environment]]|year=1984|publisher=Prentice Hall|isbn=0-13-937681-X}}\n\n==hoc implementations and versions==\n* AT&T versions:\n** [http://cm.bell-labs.com/who/bwk/unixprogenv.tar.gz The original code from the Unix Programming Environment book], including hoc.\n** [http://netlib.bell-labs.com/~bwk/hoc.sh Source code of hoc] from Bell Labs, released as [[free software]]. This is the Research Unix version, slightly improved over the one in the book.\n** [http://plan9.bell-labs.com/sources/plan9/sys/src/cmd/hoc/ Plan9 version of hoc] released under the [[Lucent Public License]]. This version is slightly different from the Research Unix version, with the most notable difference being that numbered function arguments ($1, $2, etc., as in the Unix shell) were replaced by named arguments (as in C). See also Plan 9's [http://plan9.bell-labs.com/magic/man2html/1/hoc hoc manual].\n* Other versions:\n** [http://www.math.utah.edu/pub/hoc/ an extended version of hoc] by Nelson H. F. Beebe.\n** [http://nadav.harel.org.il/homepage/hoc/ an extended version of hoc] by Nadav Y. Har'El.\n** [http://www.linuxjournal.com/?q=article/5810 an extended version of hoc] by Jack Dennon.\n** [http://www.neuron.yale.edu/neuron/static/docs/refman/hoc.html an extended version of hoc] by Michael Hines, John W. Moore, and Ted Carnevale.\n\n[[Category:Software calculators]]\n[[Category:Free mathematics software]]\n[[Category:Numerical programming languages]]\n[[Category:Unix programming tools]]\n[[Category:Plan 9 from Bell Labs]]"
    },
    {
      "title": "Honeywell ARGUS",
      "url": "https://en.wikipedia.org/wiki/Honeywell_ARGUS",
      "text": "{{multiple issues|\n{{citation style|date=April 2010}}\n{{cleanup|date=April 2010}}\n{{lead rewrite|date=April 2010}}\n{{original research|date=April 2010}}\n{{expert needed|date=April 2010}}\n}}\n\n'''ARGUS''' was an [[Assembly Language]] devised in the 1960s by [[Honeywell]] for their [[Honeywell 800]] and 1800 computers. The name ARGUS was an [[acronym]] standing for Automatic Routine Generating and Updating System.<ref name=smanual>[http://archive.computerhistory.org/resources/text/Honeywell/Honeywell.1800II.1974.102646163.pdf Company Sales Manual for the Honeywell 1800]</ref> As with other Assembly Languages, each line of ARGUS was copied on to one card and related to one word in memory, except that one ARGUS command, RESERVE, could reserve any specified number of words in the position specified. The RESERVE command was also exceptional in not prescribing the initial data in the reserved words. With a few exceptions Machine Language words were coded in the same order as the ARGUS lines\n.<ref>The initial author of this article programmed a Honeywell 1800 for [[Eastern Electricity|Eastern Electricity Board]], UK from January to August 1966 and this article is mainly written from memory. If anyone has documentary material and can review and correct the article, providing inline references, that would be useful. This information is broadly correct but a few errors of detail may be found. It seems better to write some article from memory than wait for a fully referenced article that may never emerge. Honeywell was a significant force in the embryo computer industry and its work is worth recording</ref>\n\n==Honeywell 800 Memory==\nThe Honeywell 800 and 1800 had a main memory and a control memory, both using ferrite cores. The main memory had between 4 and 16 banks, depending on customer requirements. Each bank contained 2048 words of 48 bits each. The actual number of banks in an individual installation had to be a multiple of 4.<ref name=smanual/>\n\nThe control memory had 256 registers of 16 bits each. At any given time the machine could theoretically run one Operating System and 7 application programs, each with exclusive use of 32 registers.<ref name=smanual/>\n\nA program that required more than 2048 words (data and instructions combined) had to be split into segments of 2048 words or less. Each segment would have exclusive use of one bank of main memory. There were special instructions to pass control from one segment to another.\n\n==Layout of ARGUS Commands==\nEach line of ARGUS command had fields as follows:\n\nLocation<ref>It may have had another name but its function was to keep track of the word in memory</ref> was an optional ARGUS name to be assigned to that word in memory. When the address of each word had been assigned in memory, the ARGUS name of the line would be linked with the position of its corresponding word. Other lines of ARGUS could refer to that name and their words would be assigned the correct memory address. Within the program, each name had to be unique.\n\nThis field may begin with R,  . If so then the rest of the card is remarks only.\n\nThis field may begin with X,  or X,addressname. If so then this line and any other X, lines will be placed away from the lines not so marked. They can then be addressed by X,+n or by the addressname in the address field.<ref>I never saw this used except in Honeywell’s own macros</ref>\n\nThis field may begin with M,maskname. If so the line defines a [[Honeywell ARGUS#Masks and Switch Commands|Mask]]\n\nOperation: The ARGUS name of a Machine Language command or an ARGUS-only command. This could be followed by the address of a mask, if required. A few commands had extra information.\n\nA, B and C addresses: To be translated into machine code (see below). The A and B addresses were typically the two input words and the C address was the destination.\n\nID: Normally a serial number punched on to the card by the card punch machine. Used to resort any cards that might be dropped.\n\n==Layout of Machine Language Commands==\nEach Machine Language Command used one word of 48 bits. This was split into 4 sections of 12 bits each. The first 12 bits specified the operation, with ancillary information including the offset address of any mask for the command. The three other sections were the A, B and C addresses.\n\nIf a mask was specified then the final result of the command would pass through that mask before reaching the destination. For example, if bit 17 of the mask was 1 then the result would go to bit 17 of the destination. If bit 17 of the mask was 0 then something else would go to bit 17 of the destination. It might be 0 or it might be the unchanged bit 17 of the input word, depending on the command.\n\nA segment was allowed up to 16 masks and they had to be in consecutive words, beginning at an address whose last four bits were all 0. All of them had ARGUS location names. A special register called the Mask Register held the base address. The command field had 4 bits to hold the offset address of the named mask.\n\n==Modes of Addressing Memory==\nFor most commands the A, B and C address sections were used to denote actual locations in memory. There were six modes of addressing. Two were rarely used. The remainder were: Direct, Direct Special Register, Indirect Addressing and Indexed.\n\n===Direct Addressing===\n\nThe main memory address is specified directly by the command. In machine language one of the 12 bits indicates direct mode, the other 11 specify the exact address. 11 bits can represent the numbers 0 to 2047 but nothing larger. However this is the most efficient type of addressing. This dilemma is why a bank has only 2048 words and a segment is confined to only one bank.\n\nThere are two ways of writing this in a line of ARGUS code:\n1. A name, previously defined in the location column. A number (decimal) can be added to this, e.g.: BUFFER0+59\n2. A location several lines (words) beyond the current line, e.g. C,2 means the line two beyond this one.\n\n===Indirect Addressing===\nIn 12 bits the mode of addressing and the address of a register in control memory are identified. Also an increment between 0 and 32 is specified. The main memory address is in the register in control memory. The processor will first obtain the main memory address from the register, then call for the word at that main memory address. Finally it will increase (increment) the register value by the amount specified. The 16 bit address from the register contains a bank address from 0 to 31 using 5 bits and a word in that bank using 11 bits. Incrementing was recommended only for addresses A and B.\n\nIn ARGUS: N,R0,3 means use register R0 and then increase it by 3.\n\n===Direct Special Register===\nA register is addressed directly in the same manner as a word in main memory.\n\nIn ARGUS: Z,R0,3 means read from or write to register R0 directly and then increase it by 3. The increase is not recommended when writing.\n\n===Indexed Addressing===\nThis applies only to 8 registers, called index registers. It takes 3 bits to specify the index register and another 7 to specify an offset of 0 to 127. So the offset is added to a full-length main memory address. This is a powerful tool. It is helpful for processing a multiword text or record. Tape buffers are usually addressed this way.\n\nIn ARGUS: X0,35 or 0,35 means use Index Register 0, increase that number by 35 (decimal) and read from or write to that location in main memory. DO NOT change the value in X0.\n\n===Inactive Address===\nIn ARGUS, the address field was a dash (-). It meant the field would be ignored by the processor, thereby nullifying part of the usual action of the command.\n\n==Registers==\nAs mentioned, the program had access to 32 registers. 8<ref name=numb>Not sure about this number</ref> had special functions, 16<ref name=numb/> registers (R0 to R15) were general purpose and 8 (X0 to X7) were index registers.\n\nIndex addressing was only possible for index registers.\n\nDirect and Indirect addressing were applicable to both general purpose and index registers. They would probably work with other registers too but that would be bad practice.\n\nSC (Sequence Counter)\nSH (Sequence History)\nCSC (Cosequence Counter)\nCSH (Cosequence History)\nMSK (Mask Register)\nAU1 and AU2\n\nIn operation, the Sequence Counter always contains the full address of the command that is running. Normally commands are executed in location order. The Sequence History contains the last value of the Sequence Counter. This value has to be stored immediately upon jumping to a subroutine. Otherwise it will be impossible to return.\nThe Cosequence Counter and History perform the same functions for any command that had X, at the beginning of its ARGUS location.\n\nThe MSK register holds the full location of the first mask (see below).\n\nAU1 and AU2 are used internally by some commands, especially TN. They can also be used by programs. However, there is a risk that an internal operation might interfere so it is not a wise choice.\n\n==Commands==\nEach ARGUS line defines a word in memory. In normal operation the processor performs each command in address order. Some commands can order a JUMP to another address (by Direct Addressing into the same bank).\n\n===Arithmetic===\nThe commands WA, BA and DA, in different ways, all obtain numbers from addresses A and B, add them together and put the result into address C.\n\nThe commands BS and DS both subtract the number in address B from the number in address A, placing the result into address C.\n\nWA (Word Add) treats the two input numbers as binary numbers with no sign. This was often used to add an increment to a known address.\n\nBA and BS (Binary Add and Binary Subtract) treat the two input numbers as signed binary.\n\nDA and DS (Decimal Add and Decimal Subtract) treat the two input numbers as signed decimal.\n\nThe leftmost four bits define the sign. If they are all zero then the sign is positive. Otherwise it is negative.\n\nThe command DM multiplies the number in address B by the number in address A, placing the left half of the result into address C. The remaining low end digits are left in LOP, the Low Output Register. They can be transferred from there to a main memory address by the TX or TS command. DM is fully supported by the Floating Point Adaptor. In its absence, simulation is required.\n\n===Data Transfer and Program Control===\nTX  Transfer from address A to address C. Address B MUST be Inactive (see Modes of Addressing)\n\nTS Transfer from address A to address B then JUMP out of sequence to the command at address C. C must be a direct address. Optionally A and B can be Inactive and the command becomes a pure jump. This is the nearest that this machine gets to a GOTO command.\n\nMT Transfer from address A to address C several times. The number of times is specified as a decimal number in address field B. This number is NOT a true address. It is converted to binary and positioned in the operation section of the machine language command. So the value cannot be large.<ref>I think the maximum was 63</ref> Address C MUST be Indirect with an increment of one or more so that each individual transfer operates on a different word. This command was rarely used in my experience of application programming. However it may be more useful in operating systems and compilers.\n\nTN Transfer from address A to address C. Then transfer from A+1 to C+1. Continue in total for the number of times specified in address B. As for MT this is a decimal number that ends up in binary in the operation section of the machine command.<ref>I think the maximum was 15</ref> This command was frequently used in applications, especially for “blanking” out areas of text. This command used registers AU1 and AU2 to manage the address increments.\n\nNA Compare addresses A and B. If equal continue as normal. If unequal JUMP to address C.<ref>Possibly it jumps on EQUAL and continues on UNEQUAL. Not quite sure</ref>\n\nLA Compare addresses A and B. If A (as unsigned binary) is less than or equal to B then continue as normal. Otherwise JUMP to C.<ref>Possibly the other way around</ref> For a loop with a counter, LA is safer than NA. If the logic goes astray than an NA loop could run away.\n\nPR Proceed. This was a \"do nothing\" command which nevertheless would take some time. All three addresses would be inactive. It could be used in a loop to wait for the operator to take some action before perhaps reminding him.\n\n===Constants and Initial Value Definition===\nThese were ARGUS commands to be translated into the initial value in binary of an address in memory. The actual value would go into address A, continuing into addresses B and C, as long as necessary. Most of these lines were for use as constants and would have a location code for reference by active commands.\n\nOCT        The punched letter or number is translated into a three bit [[octal]] code. So 0 becomes 000, 1 becomes 001, 2 becomes 010.... and 7 becomes 111.\n\nHEX        The punched letter or number is translated into a four bit [[hexadecimal]] code. 0 becomes 0000, 1 becomes 0001, ..... 9 becomes 1001. Then B to G indicate decimal 10 to 15, which in binary is 1010 to 1111. Honeywell hexadecimal code used B to G where IBM used A to F.\n\nDEC         The punched letter or number is translated into a four bit [[decimal]] code. This is like hexadecimal except that only 0 to 9 are valid.\n\nALF          The punched letter or number is translated according to Honeywell's own binary code for Alphanumeric numbers, letters and symbols.\n\nM,x,text    plus separate entries of x,text in EACH address field. Here, x can be O, H, D, or A allowing each 12 bit section of the word to be encoded using any one of the methods above.\n\nFor OCT, HEX and DEC, the leftmost 4 bits are used to denote the sign of the number.\n\n===Masks and Switch Commands===\nA mask was a constant with a location entry of M,maskname. It was good practice to put all masks together in ARGUS. In any case ARGUS would put them together in consecutive words. The maximum number of masks was 15.\n\nA mask could be used to modify the action of any command that could change the value of a word, for example: TX,maskname would apply the mask “maskname” to a TX command. Masking was essential for a Switch Word command but not very valuable for other commands. Some installations had a standard to use them ONLY for Switch Word. The full address of the first mask would be placed in the MSK register and the offset of an individual mask would be placed into the command section of the Machine Language command for which it was specified. Consequently, a program needed and had only one set of masks and they could be used from any segment.\n\nSwitch Word commands were used to move some bits in the word to other bit positions. There were two Switch Word commands and they were very similar. Switch Word and Extract had an ARGUS command of: SWE,maskname, the A address was the source and the C address the destination. The B address field was for the amount of switch:  x,n,d   . x was B, D or A representing Binary, Decimal or Alphanumeric, i.e. units of 1, 4 or 6 bits respectively. d was L or R for Left or Right.\n\nIn operation:\n\nThe word was obtained from address A\nThe bits were moved Left or Right by the number and size of unit specified\nBits that “fell off” the end were put back into the opposite end\nThe shifted word was passed through the mask bit by bit. If the mask bit was 1 then the shifted bit would be copied through. Otherwise a 0 bit would be passed.\nThe modified word was placed in address C\n\nThe other Switch Word command was Switch Word and Superimpose, SWS, with the same syntax. The action differed in the mask stage. If the mask bit was 0 then the unshifted rather than the shifted bit was placed in the output word. For a mask bit of 1 the action was the same as for SWE.\n\nExample\nAddress A contains 8 characters of 6 bits each: ABCDEFGH\nMask ONECHAR contains 1 in its right-most 6 bits and 0 elsewhere.\n\nThe command is:\nSWE,ONECHAR         A       A,4,R       C\nThen Address C will contain: 0000000D\n\nIf the command is:\nSWS,ONECHAR         A       A,4,R       C\nThen Address C will contain: ABCDEFGD\n\nIn Machine Language all shifts were represented as Binary right. All the ARGUS codes in the x,n,d format can be reduced to Binary right.\n\n===Macros and Subroutines===\nA macro would be called by:\nL$,macroname\nThis would request the assembler to insert the ARGUS text of macro “macroname” at that point. This was done during at an early stage of assembly before the ARGUS was translated to machine code. There were quite a few macros in the standard library (held on its own tape) and customers could add more. The macros GET and PUT would get an item from the input tape buffer or put an item into the output tape buffer, reading or writing a record as appropriate.\n\nThere were two types of subroutine. One was entirely written in ARGUS. Here is an example, using the subroutine SUBA:\n\n{| class=\"wikitable\" style=\"text-align: left; width:700pt;\" border=\"1\"\n|-\n!Location\n!Command\n!Address A\n!Address B\n!Address C\n|-\n|  ||U,NEWPROG ||  MYPROG\n|-\n|R,\n|-\n| colspan=\"5\" align=\"left\"|R, MAIN PROGRAM BEGINS\n|-\n| colspan=\"5\" align=\"left\"|R, THE R COMMA DEFINES THE LINE AS A COMMENT LINE.\n|-\n|R,\n|-\n|.......\n|-\n|.......\n|-\n| colspan=\"5\" align=\"left\"|R, THE TS COMMAND CAUSES JUMP TO SUBROUTINE SUBA.  THE NEXT LOCATION IS STORED IN REGISTER SH.\n|-\n|  ||TS|| -|| -|| SUBA\n|-\n| colspan=\"5\" align=\"left\"|R, THE SUBROUTNE WILL JUMP BACK TO HERE.\n|-\n|  ||WA||......\n|-\n|....\n|-\n|....\n|-\n| colspan=\"5\" align=\"left\"|R, MAIN PROGRAM ENDS ABOVE HERE. SUBROUTINES CAN BEGIN.\n|-\n|R,\n|-\n| colspan=\"5\" align=\"left\"|R, SUBROUTINE SUBA\n|-\n|R,\n|-\n| colspan=\"5\" align=\"left\"|R, SUBROUTINE MUST BEGIN BY SAVING CONTENTS OF SEQUENCE HISTORY REGISTER (SH).\n|-\n| colspan=\"5\" align=\"left\"|R, OTHERWISE IT MAY BE LOST BY ANOTHER TS, NA OR LA COMMAND.\n|-\n|R,\n|-\n|SUBA || TX   ||     Z,SH ||       – ||          Z,R0\n|-\n| colspan=\"5\" align=\"left\"|R, SUBROUTINE PROCESS BEGINS\n|-\n|   .........\n|-\n| colspan=\"5\" align=\"left\"|R, SUBROUTINE PROCESS COMPLETED SO GO TO SAVED LOCATION TO CONTINUE MAIN PROGRAM.\n|-\n|         ||     TS   ||     -  ||            - ||           N,R0\n|-\n| colspan=\"5\" align=\"left\"|R, END OF SUBA\n|}\n\nThe other type of subroutine was delivered in machine language with a Macro wrapper. It was normally written by Honeywell staff. The Macro used the command GOSUB to call the subroutine.\n\n===Floating Point Commands===\nThe Honeywell 1800 had an optional [[Floating Point]] Adaptor for scientific computing. There was a set of commands for it.<ref>which I did not learn</ref> These commands were also available in simulation form if the hardware did not include the adaptor but this was not recommended for regular use. The ARGUS floating point commands were the same regardless of whether there was an adaptor. In its absence, ARGUS would supply a machine language simulation of true floating point operation.\n\n===Peripheral Input/Output Control===\nInput and Output device addresses at machine level were two octal digits 0-7. At ARGUS level it was two letters A-G. The first digits identified the controller, the second digit identified the device number on that controller.\n\nFor tape processing, one unit of data on the tape was called, in Honeywell manuals, a record. [[IBM]] called, and still calls, this a block. A subdivision of a record was called an item. IBM called this a record. IBM's terminology became the American standard.\n\nCommands:\n\nThe command RW,AA would rewind the tape on tape unit AA, octal 00.\n\nThe command RF,AA would read the next record on tape unit AA, octal 00.\n\nThe command RB,AA would read back over the previous record on tape unit AA, octal 00, without delivering data. To amend an existing tape, you could use RF to find the first record that you didn't want, then RB to reach the space before it, then WF to write over it and onwards.\n\nThe command WF,AB would write the next record on tape unit AB, octal 01.\n\nThe command RF,GA would read the next card on the card reader, device GA, octal 70.\n\nThe A address would be the first word in the buffer for that read or write operation. It was normal to use two buffers for each device so that reading or writing could run in parallel with processing. This is called [[double-buffering]]. Buffer size was a limiting factor in the size of “records” (blocks) because core memory was limited.\n\nWhen preparing to write a record on tape, each item was terminated by an End of Item word with a prescribed code. Each record was terminated by an Ortho word for error checking followed by an End of Record word. After the output buffer had been filled with items the Compute Ortho (CC) command was used to calculate the Ortho word and provide the End of Record word. For the Compute Ortho command Addresses A and B marked the first and last word positions.<ref>Detail of Compute Ortho needs checking</ref>  Next, the record would be written by the WF command. Finally control would be returned to the main program.\n\nFor normal application work all peripheral commands, except perhaps RW, would be placed in a subroutine.\n\n===Program Administration Commands===\nThere were ARGUS commands to deal with the administration of programs. In order to assemble a program the following were required:<ref>I am guessing a bit here</ref>\n* A deck of cards containing ARGUS code for all the changes required.\n* An input tape containing all the ARGUS programs at the installation.\n* An output scratch tape to contain all the new ARGUS programs and all revisions to old ones.\n* An input tape containing all the machine language programs at the installation.\n* An input tape to contain all the machine language programs - unchanged, new or reassembled.\n* An input tape containing a library of macros. These macros would be added into the ARGUS code during assembly and before translation into machine code.\n* One or more scratch tapes for sorting the card images.\n\nA very few administration commands were required for each program that was to be created or changed.\n\nU,NEWPROG  progname The cards that follow are for a complete, new program called progname.\nU,REASSMB progname The cards that follow are revisions to the existing program progname.\nU,NEWSEG progname segname The cards that follow are a complete, new segment called segname of the (new or existing) program called progname.\nU,SEGMENT progname segname The cards that follow are revisions to segment segname of program progname.\nU,ENDSEG This is the end of the segment (or its revisions).\nU,ENDPROG This is the end of the program (or its revisions).\n\n==References==\n<references/>\n\n==External links==\nAscher Opler  and Myra Gray, (1961),   [http://portal.acm.org/citation.cfm?id=808497&dl=GUIDE&coll=GUIDE&CFID=64042070&CFTOKEN=97323390 Design of a multiprogrammed algebraic compiler] (Subscription only)\n* [http://hopl.murdoch.edu.au/showlanguage.prx?exp=3841 Automatic Routine Generating and Updating System.]   From [https://web.archive.org/web/20080401121517/http://hopl.murdoch.edu.au/ HOPL: an interactive Roster of Programming Languages]. See [[History of Programming Languages Conference]].\n\n{{Honeywell}}\n\n{{DEFAULTSORT:Honeywell Argus}}\n[[Category:Honeywell]]\n[[Category:Numerical programming languages]]\n[[Category:Assembly languages]]"
    },
    {
      "title": "IDL (programming language)",
      "url": "https://en.wikipedia.org/wiki/IDL_%28programming_language%29",
      "text": "{{Distinguish|Interface description language}}\n{{More citations needed|date=February 2010}}\n{{Infobox programming language\n|name = IDL (Interactive Data Language)\n|logo =\n|paradigm = [[Array programming|vector-oriented programming]]\n|designer = David Stern\n|developer = David Stern & [[ITT Visual Information Solutions|ITT Visual Information Solutions (ITT VIS)]]\n|latest release version = IDL 8.7.2\n|latest release date = March 2019\n|typing = [[dynamic typing|Dynamic]]\n|implementations = IDL, [[GNU Data Language]], Fawlty Language\n|dialects =\n|influenced =\n|year = 1977\n|influenced_by =\n}}\n'''IDL''', short for '''Interactive Data Language''', is a [[programming language]] used for [[data analysis]].  It is popular in particular areas of science, such as [[astronomy]], [[atmospheric physics]] and [[medical imaging]].{{Citation needed|date=March 2019}} IDL shares a common [[Syntax (programming languages)|syntax]] with [[PV-Wave]] and originated from the same [[codebase]], though the languages have subsequently diverged in detail. There are also two [[Free software|free]] implementations, [[GNU Data Language]] (GDL) and [http://www.flxpert.hu/fl/ Fawlty Language] (FL).\n\n==Overview==\nIDL is [[Array programming|vectorized]], [[Numerical analysis|numerical]], and interactive, and is commonly used for interactive processing of large amounts of data (including [[image processing]]).  The syntax includes many constructs from [[Fortran]] and some from [[C (programming language)|C]].\n\nIDL originated from early [[VAX/VMS]]/Fortran, and its syntax still shows its heritage:\n<source lang=\"idl\">\n x = findgen(100)/10\n y = sin(x)/x\n plot,x,y\n</source>\nThe <tt>findgen</tt> function in the above example returns a one-dimensional array of floating point numbers, with values equal to a series of integers starting at 0.\n\nNote that the operation in the second line applies in a vectorized manner to the whole 100-element array created in the first line, analogous to the way general-purpose array programming languages (such as [[APL programming language|APL]], [[J programming language|J]] or [[K programming language|K]]) would do it.  This example contains a divide by zero; IDL will report an [[arithmetic overflow]], and store a [[NaN]] value in the corresponding element of the <tt>y</tt> array (the first one), but the other array elements will be finite.  The NaN is excluded from the visualization generated by the <tt>plot</tt> command.\n\nAs with most other array programming languages, IDL is very fast at doing vector operations (sometimes as fast as a well-coded custom loop in Fortran or C) but quite slow if elements need processing individually. Hence part of the art of using IDL (or any other array programming language, for that matter) for numerically heavy computations is to make use of the built-in vector operations.\n\n==History==\n{{original research|section|date=September 2015}}\nThe predecessor versions of IDL were developed in the 1970s at the [[Laboratory for Atmospheric and Space Physics]] (LASP) at the [[University of Colorado at Boulder]]. At LASP, David Stern was involved in efforts to allow scientists to test hypotheses without employing programmers to write or modify individual applications. The first program in the evolutionary chain to IDL that  Stern developed was named Rufus; it was a simple vector-oriented calculator that ran on the [[PDP-12]]. It accepted two-letter codes that specified an arithmetic operation, the input registers to serve as operands, and the destination register. A version of Rufus developed on the [[PDP-8]] was the Mars Mariner Spectrum Editor (MMED). MMED was used by LASP scientists to interpret data from [[Mariner 7]] and [[Mariner 9]]. Later, Stern wrote a program named SOL, which also ran on the PDP-8. Unlike its predecessors, it was a true programming language with a FORTRAN-like syntax. SOL was an array-oriented language with some primitive graphics capabilities.<ref name=\"idl_faq\">{{cite web |last1=Schienle |first1=Mike |title=IDL FAQ |url=http://www.faculty.virginia.edu/rwoclass/astr511/IDLresources/idl-faq-ivsoft-v4.html |accessdate=8 February 2019 |date=1991-01-19}}</ref>\n\nStern left LASP to found Research Systems Inc. (RSI) in 1977. The first RSI product was IDL for the PDP-11.<ref name =\"idl_faq\"/> In this release, the graphics supported by IDL were primarily Tektronix terminals and raster graphics displays. RSI sold its first IDL licenses to NASA's [[Goddard Space Flight Center]] and [[Ball Aerospace & Technologies Corp.]] in 1979. Two years later RSI released an initial VAX/VMS version of IDL, which was written in VAX-11 MACRO and FORTRAN. It took advantage of the VAX virtual memory and 32-bit address space.<ref name =\"idl_faq\"/> The [[National Center for Atmospheric Research]] (NCAR), the [[University of Michigan]], the [[University of Colorado at Boulder|University of Colorado]], and the [[Naval Research Laboratory]] started to use IDL with this version.\n\nIn 1987 RSI shifted development work of IDL to the [[Unix]] environment, which required a complete re-write of the code in C rather than a port of the existing version of VAX IDL. <ref name =\"idl_faq\"/> Stern and Ali Bahrami rewrote IDL for Unix on the Sun 3, taking advantage of the re-write to extend and improve the language. Subsequently, IDL was further expanded and ported to several variants of Unix, VMS, Linux, Microsoft Windows (1992), and Mac OS (1994).\n\nWidgets were added to IDL in 1992, providing [[event-driven programming]] with [[graphical user interface]]s. In 1997 ION (IDL On the Net), a web server-based system, was commercially released. The first version of [[ENVI (software)|ENVI]], an application for [[remote sensing]] [[multispectral]] and [[hyperspectral]] image analysis written in IDL, was released in 1994. [[ENVI (software)|ENVI]] was created, developed and owned by Better Solutions Consulting, LLC, until it was purchased from BSC in October 2000 by Eastman Kodak coincident with their purchase of RSI.  RSI sold, marketed and supported [[ENVI (software)|ENVI]] under the terms of a license agreement with BSC, LLC from 1994 through October 2000.   New object and pointer types, and limited [[object-oriented programming]] capabilities, were added to IDL in 1997.\n\nIDL has been applied widely in space science, for example in [[solarsoft|solar physics]]. The [[European Space Agency]] used IDL to process almost all of the pictures of [[Halley's Comet]] taken by the [[Giotto (spacecraft)|Giotto]] spacecraft. The team repairing the [[Hubble Space Telescope]] used IDL to help them diagnose anomalies in the main mirror. In 1995, astronauts on board a [[Space Shuttle]] used IDL loaded on a laptop to study ultraviolet radiation. Currently, amongst other applications, IDL is being used for most of the analysis of the SECCHI part of the [[STEREO]] mission at [[United States Naval Research Laboratory|NRL]], USA, and at the Rutherford Appleton Laboratory, UK.\n\nRSI became a wholly owned subsidiary of [[ITT Industries]] in March 2004. As of 15 May 2006, RSI began doing business as [[ITT Visual Information Solutions]]. Effective 31 October 2011, as a result of restructuring, that company became [[Exelis Visual Information Solutions]].  {{as of|2015}}, IDL is now owned and maintained by [[Harris Geospatial|Harris Geospatial Solutions]].\n\n==Features==\nAs a computer language, IDL: \n* is [[dynamically typed]].\n* has separate [[namespaces]] for variables, functions and procedures, but no namespace hierarchy.\n* was originally single threaded but now has many multi-threaded functions and procedures.\n* has all function arguments [[Evaluation strategy#Call by reference|passed by reference]]; but see \"problems\", below.\n* has [[named parameter]]s called keywords which are passed by reference.\n* provides named parameter inheritance in nested routine calls, by reference or value.\n* does not require variables to be predeclared.\n* provides COMMON block declarations and system variables to share global values among routines.\n* provides a basic form of object-oriented programming, somewhat similar to [[Smalltalk]], along with [[operator overloading]].\n* implements a persistent, global heap of pointer and object variables, using [[reference counting]] for garbage collection.\n* compiles to an interpreted, stack-based intermediate p-code (à la [[Java Virtual Machine]]).\n* provides a simple and efficient index slice syntax to extract data from large arrays.\n* provides various integer sizes, as well as single and double precision floating point real and complex numbers.\n* provides composite data types such as character strings, homogeneous-type arrays, lists, hash tables, and simple (non-hierarchical) record structures of mixed data types.\n\n==Problems==\n{{original research|section|date=August 2014}}\nSome of these features, which make IDL very simple to use interactively, also cause difficulties when building large programs. The single namespace is particularly problematic; for example, language updates that include new built-in functions have on occasion invalidated large scientific libraries.<ref>{{cite web|last1=Fanning|first1=David|title=Program Naming Conflicts in IDL 8|url=https://www.idlcoyote.com/ng_tips/idl8_name_conflicts.html|accessdate=30 September 2014}}</ref>\n\nArrays are passed by reference, and this mechanism is an advertised feature of the language to pass data back out of a subroutine – in contrast, array slices are copied before being passed, so that data modifications do not flow back into array ranges (after the subroutine exits), violating the [[principle of least surprise]].\n\nMany historical irregularities survive from the early heritage of the language, requiring individual workarounds by the programmer. As an example:\n\n* Array indexing and subroutine entry can both be carried out with exactly the same syntax (parentheses); this ambiguity, coupled with the single namespace for all variables and subroutines, can cause code to stop working when newly defined subroutines or language extensions conflict with local variable names. IDL programmers can avoid many of these problems by using square brackets for array indexing, thereby avoiding conflicts with function names which use parentheses.\n\nThe preceding issue can be alleviated using this compiler option:\n\n COMPILE_OPT STRICTARR\n\n* [[ITT Visual Information Solutions|ITT Visual Information Solutions (ITT VIS)]], the developers of IDL, have taken explicit steps to prevent [[bytecode]] compatibility with other environments. Files containing compiled routines use a binary tagged-data-structure format that has not been officially published but has been investigated and documented by users<ref>{{Cite web| last = Markwardt | first = Craig\n| title = Unofficial Format Specification of the IDL \"SAVE\" File\n| publisher = | date = 2011-12-21\n| url = http://www.physics.wisc.edu/~craigm/idl/savefmt/\n| doi = | accessdate = 2013-02-13}}</ref> but also contain the following notice as ASCII text embedded within each saved file: \"IDL Save/Restore files embody unpublished proprietary information about the IDL program. Reverse engineering of this file is therefore forbidden under the terms of the IDL End User License Agreement (IDL EULA). All IDL users are required to read and agree to the terms of the IDL EULA at the time that they install IDL. Software that reads or writes files in the IDL Save/Restore format must have a license from ITT Visual Information Solutions explicitly granting the right to do so. In this case, the license will be included with the software for your inspection. Please report software that does not have such a license to ITT Visual Information Solutions...\" {{As of|2010|2}}, the statement has not been tested in a court of law.\nAlso, that provision of the IDL EULA has no effect in Australia, as a result of sections [http://www.austlii.edu.au/au/legis/cth/consol_act/ca1968133/s47d.html 47D] and [http://www.austlii.edu.au/au/legis/cth/consol_act/ca1968133/s47h.html 47H] of that country's Copyright Act.\n\n==Examples==\nThe following graphics were created with IDL (source code included):\n\n*[[:Image:Random-data-plus-trend-r2.png|Image of random data plus trend, with best-fit line and different smoothings]]\n*[[:Image:Epica-vostok-40kyr.png|Plots of delta-o-18 against age and depth (from EPICA and Vostok)]]\n*[http://www.idlcoyote.com/gallery/index.html coyote IDL gallery] examples of IDL imaging\n\n==See also==\n* [[List of numerical analysis software]]\n* [[ENVI (software)|ENVI]] – an image processing software package built in IDL\n* [[IRAF]] – a free, graphical data reduction environment produced by NOAO\n* [[MATLAB]] – a technical computing environment providing similar capabilities to IDL\n* [[NumPy]] – an extension for [[Python (programming language)|Python]] that gives it array math capabilities similar to those of IDL\n* [[Perl Data Language]] (PDL) – An extension to [[Perl]] that gives it array math capabilities similar to those of IDL\n* [[Solarsoft]] – library for solar data analysis and spacecraft operation activities written predominately in IDL\n* [[GNU Data Language|GDL]] – GNU Data Language, a free implementation similar to IDL.\n* [http://www.flxpert.hu/fl/ Fawlty Language] – Fawlty Language is an IDL8 (Interactive Data Language) compatible compiler.\n\n==References==\n{{Reflist}}\n\n==External links==\n*[http://www.harrisgeospatial.com/SoftwareandTechnology/IDL.aspx IDL home page]\n*[http://www.idlcoyote.com/ Coyote's Guide to IDL Programming]\n*[http://idlastro.gsfc.nasa.gov/ The IDL Astronomy User's Library at NASA Goddard]\n*[http://www.flxpert.hu/fl/ Fawlty Language home page]\n\n{{Numerical analysis software}}\n{{Statistical software}}\n{{Image processing software}}\n\n[[Category:Array programming languages]]\n[[Category:Earth sciences graphics software]]\n[[Category:Numerical programming languages]]\n[[Category:Plotting software]]"
    },
    {
      "title": "J (programming language)",
      "url": "https://en.wikipedia.org/wiki/J_%28programming_language%29",
      "text": "{{Infobox programming language\n | name                   = J\n | logo                   = [[File:J (programming language) icon.png|64px]]\n | file ext               \n | par-adigm               = [[Array programming|Array]], [[functional programming|functional]], [[function-level programming|function-level]], [[tacit programming|tacit]]\n | released               = {{Start date and age|1990}}\n | designer               = [[Kenneth E. Iverson]], [[Roger Hui]]\n | developer              = JSoftware\n | latest release version = J807\n | latest release date    = {{Start date and age|2018|10|8|df=yes}}<ref>{{cite web |url= https://code.jsoftware.com/wiki/System/ReleaseNotes/J807 |title= J807 release 8 October 2018}}</ref>\n | latest preview version = \n | latest preview date    = \n | typing                 = [[dynamic typing|dynamic]]\n | implementations        = J\n | dialects               = \n | influenced by          = [[APL (programming language)|APL]], [[FP (programming language)|FP]], [[FL (programming language)|FL]]\n | influenced             = [[NumPy]],<ref name=\"Python for Data Analysis\">[http://traims.tumblr.com/post/33883718232/python-for-data-analysis-18-oct-2012-london Wes McKinney at 2012 meeting Python for Data Analysis]</ref> [[SuperCollider]]<ref name=\"SuperCollider documentation\">[http://doc.sccode.org/Reference/Adverbs.html SuperCollider documentation, Adverbs for Binary Operators]</ref>\n | operating system       = [[Cross-platform]]: [[Microsoft Windows|Windows]], [[Linux]], [[macOS]]\n | license                = [[GNU General Public License|GPLv3]]\n | website                = {{URL|www.jsoftware.com}}\n | wikibooks              = \n}}\nThe '''J''' [[programming language]], developed in the early 1990s by [[Kenneth E. Iverson]] and [[Roger Hui]],<ref>[https://web.archive.org/web/20040812193452/http://home1.gte.net/res057qw/APL_J/IversonAPL.htm A Personal View of APL], 1991 essay by K.E. Iverson (archived link)</ref><ref>[http://jsoftware.com/pipermail/general/2002-March/010962.html Overview of J history] by Roger Hui (19 March 2002)</ref> is a synthesis of [[APL (programming language)|APL]] (also by Iverson) and the [[FP (programming language)|FP]] and [[FL (programming language)|FL]] [[function-level]] languages created by [[John Backus]].<ref>{{Cite news |last= Thomson |first= Iain |title= Creator of Fortran dies |url= http://www.v3.co.uk/vnunet/news/2185927/founder-fortran-dies |access-date= 2 August 2010 |newspaper= v3.co.uk |date= 20 March 2007}}</ref>\n\nTo avoid repeating the APL special-character problem, J uses only the basic [[ASCII]] character set, resorting to the use of the dot and colon as ''inflections''<ref>[http://code.jsoftware.com/wiki/Vocabulary/Words J NuVoc Words]</ref> to form short words similar to ''[[digraph (computing)|digraph]]s''. Most such ''primary'' (or ''primitive'') J words serve as mathematical symbols, with the dot or colon extending the meaning of the basic characters available.  Also, many characters which in other languages often must be paired (such as <code>[] {} \"\" ``</code> or <code><></code>) are treated by J as stand-alone words or, when inflected, as single-character roots of multi-character words.\n\nJ is a very terse [[array programming language]], and is most suited to [[mathematical]] and [[statistical]] programming, especially when performing operations on [[matrix (mathematics)|matrices]]. It has also been used in [[extreme programming]]<ref>{{Citation |contribution= Software Development as a Collaborative Writing Project |series= Extreme programming and agile processes in software engineering |place= Oulu, Finland |year= 2006 |first1= Brian |last1= Bussell |first2= Stephen |last2= Taylor |pages= 21–31 |publisher= [[Springer Science+Business Media|Springer]] |isbn= 978-3-540-35094-1}}</ref> and [[network performance]] analysis.<ref>{{Citation |first= Alan |last= Holt |title= Network Performance Analysis: Using the J Programming Language |isbn= 978-1-84628-822-7 |year= 2007 |publisher= [[Springer Science+Business Media|Springer]]}}</ref>\n\nLike the original FP/FL languages, J supports [[function-level programming]] via its ''[[tacit programming]]'' features.\n\nUnlike most languages that support [[object-oriented programming]], J's flexible hierarchical [[namespace]] scheme (where every name exists in a specific ''locale'') can be effectively used as a framework for both [[class-based programming|class-based]] and [[prototype-based programming|prototype-based]] object-oriented programming.\n\nSince March 2011, J is [[free and open-source software]] under the [[GNU General Public License]] version 3 (GPLv3).<ref name=\"j source download\">[http://www.jsoftware.com/source.htm Jsoftware's source download page]</ref><ref name=\"j_gpl\">{{cite web |url= http://thread.gmane.org/gmane.comp.lang.j.programming/20882 |title= J Source GPL |date= 1 March 2011 |author= Eric Iverson |work= J programming mailing list}}</ref><ref>{{github|openj/core|openj}}</ref> One may also purchase source under a negotiated license.<ref name=\"j_source\">[http://www.jsoftware.com/source.htm Jsoftware's sourcing policy]</ref>\n\n==Examples==\nJ permits [[tacit programming|point-free style]] and [[function composition (computer science)|function composition]]. Thus, its programs can be very terse and are [[write-only language|considered difficult to read]] by some programmers.\n\nThe [[\"Hello, World!\" program]] in J is\n\n   'Hello, world!'\n\nThis implementation of hello world reflects the traditional use of J – programs are entered into a J interpreter session, and the results of expressions are displayed.  It's also possible to arrange for J scripts to be executed as standalone programs.  Here's how this might look on a [[Unix]] system:\n<source lang=\"j\">\n   #!/bin/jc\n   echo 'Hello, world!'\n   exit ''\n</source>\nHistorically, APL used <code>/</code> to indicate the [[fold (higher-order function)|fold]], so <code>+/1 2 3</code> was equivalent to <code>1+2+3</code>.  Meanwhile, division was represented with the classic mathematical division symbol (the [[obelus]], ÷), which was implemented by [[overstrike|overstriking]] a minus sign and a colon (on both EBCDIC and ASCII paper [[text terminal]]s). Because ASCII in general does not support overstrikes in a device-independent way, and does not include a division symbol per se, J uses % to represent division, as a visual approximation or reminder. (This illustrates something of the mnemonic character of J's tokens, and some of the quandaries imposed by the use of ASCII.)\n\nDefining a J function named <code>avg</code> to calculate the average of a list of numbers yields:\n\n   {{code|2=j|1=avg=: +/ % #}}\nThis is a test execution of the function:\n   {{code|2=j|1=avg 1 2 3 4}}\n <span style=\"color:sienna;\">2.5</span>\n\n<code># </code>counts the number of items in the array.<code> +/ </code>sums the items\nof the array.<code> % </code>divides the sum by the number of items. Above, ''avg'' is defined using a train of three verbs (<code>+/</code>, <code>%</code>, and <code>#</code>) termed a ''fork''.  Specifically <code>(V0 V1 V2) Ny</code> is the same as <code>(V0(Ny)) V1 (V2(Ny))</code> which shows some of the power of J. (Here V0, V1, and V2 denote verbs and Ny denotes a noun.)\n\nSome examples of using <code>avg</code>:\n\n   {{code|2=j|1=v=: ?. 20 $100}}     <span style=\"color:gray;\">NB. a random vector</span>\n   {{code|v}}\n <span style=\"color:sienna\">46 55 79 52 54 39 60 57 60 94 46 78 13 18 51 92 78 60 90 62</span>\n   {{code|2=j|1=avg v}}\n <span style=\"color:sienna;\">59.2</span>\n\n   {{code|2=j|1=4 avg\\ v}}            <span style=\"color:gray;\">NB. moving average on periods of size 4</span>\n <span style=\"color:sienna;\">58 60 56 51.25 52.5 54 67.75 64.25 69.5 57.75 38.75 40 43.5 59.75 70.25 80 72.5</span>\n\n   {{code|2=j|1=m=: ?. 4 5 $50}}     <span style=\"color:gray;\">NB. a random matrix</span>\n   {{code|m}}\n <span style=\"color:sienna;\">46  5 29  2  4\n 39 10  7 10 44\n 46 28 13 18  1\n 42 28 10 40 12</span>\n\n   {{code|2=j|1=avg\"1 m}}             <span style=\"color:gray;\">NB. apply avg to each rank 1 subarray (each row) of m</span>\n <span style=\"color:sienna;\">17.2 22 21.2 26.4</span>\n\n[[Rank (J programming language)|Rank]] is a crucial concept in J.  Its significance in J is similar to the significance of <code>select</code> in [[SQL]] and of <code>while</code> in [[C (programming language)|C]].\n\nImplementing [[quicksort]], from the J Dictionary yields:\n<source lang=\"j\">\n   sel=: adverb def 'u # ['\n   \n   quicksort=: verb define\n    if. 1 >: #y do. y\n    else.\n     (quicksort y <sel e),(y =sel e),quicksort y >sel e=.y{~?#y\n    end.\n   )\n</source>\nThe following is an implementation of quicksort demonstrating [[tacit programming]]. The later involves composing functions together and not referring explicitly to any variables.  J's support for ''forks'' and ''hooks'' dictates rules on how arguments applied to this function will be applied to its component functions.\n<source lang=\"j\">\n   quicksort=: (($:@(<#[), (=#[), $:@(>#[)) ({~ ?@#)) ^: (1<#)\n</source>\nSorting in J is usually accomplished using the built-in (primitive) verbs <code>/:</code> (sort up) and <code>\\:</code> (sort down). User-defined sorts such as quicksort, above, typically are for illustration only.\n\nThe following example demonstrates the usage of the self-reference verb <code>$:</code> to recursively calculate fibonacci numbers:\n\n<source lang=\"j\">\n1:`($:@-&2+$:@<:)@.(>&2)\n</source>\n\nThis recursion can also be accomplished by referring to the verb by name, although this is of course only possible if the verb is named:\n\n<source lang=\"j\">\nfibonacci=:1:`(fibonacci@-&2+fibonacci@<:)@.(>&2)\n</source>\n\nThe following expression exhibits [[pi]] with n digits and demonstrates the extended precision abilities of J:\n\n   {{code|2=j|1=n=: 50}}                      <span style=\"color:gray;\">NB. set n as the number of digits required</span>\n   {{code|2=j|1=<.@o. 10x^n}}                 <span style=\"color:gray;\">NB. extended precision 10 to the nth * pi</span>\n <span style=\"color:sienna;\">314159265358979323846264338327950288419716939937510</span>\n\n==Data types and structures==\nJ supports three simple types:\n\n* Numeric\n* Literal (Character)\n* Boxed\n\nOf these, numeric has the most variants.\n\nOne of J's numeric types is the ''bit''.  There are two bit values: ''0'', and ''1''.  Also, bits can be formed into lists.  For example, <code> 1 0 1 0 1 1 0 0 </code> is a list of eight bits.  Syntactically, the J parser treats that as one word. (The space character is recognized as a word-forming character between what would otherwise be numeric words.)  Lists of arbitrary length are supported.\n\nFurther, J supports all the usual binary operations on these lists, such as ''and'', ''or'', ''exclusive or'', ''rotate'', ''shift'', ''not'', etc.  For example,\n\n   1 0 0 1 0 0 1 0 +. 0 1 0 1 1 0 1 0     <span style=\"color:gray\">NB. or</span>\n <span style=\"color:sienna\">1 1 0 1 1 0 1 0</span>\n\n   3 |. 1 0 1 1 0 0 1 1 1 1 1             <span style=\"color:gray\">NB. rotate</span>\n <span style=\"color:sienna\">1 0 0 1 1 1 1 1 1 0 1</span>\n\nJ also supports higher order arrays of bits. They can be formed into two-dimensional, three-dimensional, etc. arrays. The above operations perform equally well on these arrays.\n\nOther numeric types include integer (e.g., 3, 42), floating point (3.14, 8.8e22), complex (0j1, 2.5j3e88), extended precision integer (12345678901234567890x), and (extended precision) rational fraction (1r2, 3r4).  As with bits, these can be formed into lists or arbitrarily dimensioned arrays.  As with bits, operations are performed on all numbers in an array.\n\nLists of bits can be converted to integer using the <code>#.</code> verb.  Integers can be converted to lists of bits using the <code>#:</code> verb.  (When parsing J, <code>.</code> (period) and <code>:</code> (colon) are word-forming characters.  They are never tokens alone, unless preceded by [[whitespace character]]s.)\n\nJ also supports the literal (character) type.  Literals are enclosed in quotes, for example, <code>'a'</code> or <code>'b'</code>.  Lists of literals are also supported using the usual convention of putting multiple characters in quotes, such as <code>'abcdefg'</code>.  Typically, individual literals are 8-bits wide (ASCII), but J also supports other literals ([[Unicode]]).  Numeric and boolean operations are not supported on literals, but collection-oriented operations (such as rotate) are supported.\n\nFinally, there is a boxed data type.  Typically, data is put in a box using the <code><</code> operation (with no left argument; if there's a left argument, this would be the ''less than'' operation).  This is analogous to [[C (programming language)|C]]'s <code>&</code> operation (with no left argument).  However, where the result of C's <code>&</code> has reference semantics, the result of J's <code><</code> has value semantics.  In other words, <code><</code> is a function and it produces a result.  The result has 0 dimensions, regardless of the structure of the contained data.  From the viewpoint of a J programmer, <code><</code> ''puts the data into a box'' and allows working with an array of boxes (it can be assembled with other boxes, and/or more copies can be made of the box).\n\n   <1 0 0 1 0\n <span style=\"color:sienna\">+---------+\n |1 0 0 1 0|\n +---------+</span>\n\nThe only collection type offered by J is the arbitrarily dimensioned array.  Most algorithms can be expressed very concisely using operations on these arrays.\n\nJ's arrays are homogeneously typed, for example the list <code> 1 2 3 </code> is a list of integers despite <code> 1 </code> being a bit.  For the most part, these sorts of type issues are transparent to programmers.  Only certain specialized operations reveal differences in type.  For example, the list <code> 1.0  0.0 1.0 0.0 </code> would be treated exactly the same, by most operations, as the list <code> 1 0 1 0 </code>.\n\nJ also supports sparse numeric arrays where non-zero values are stored with their indices.  This is an efficient mechanism where relatively few values are non-zero.\n\nJ also supports objects and classes,<ref>[http://www.jsoftware.com/help/learning/25.htm Chapter 25: Object-Oriented Programming]</ref> but these are an artifact of the way things are named, and are not data types.  Instead, boxed literals are used to refer to objects (and classes).  J data has value semantics, but objects and classes need reference semantics.{{Citation needed|date=March 2017}}\n\nAnother pseudo-type—associated with name, rather than value—is the memory mapped file.\n\n==Documentation==\nJ's documentation includes a [http://code.jsoftware.com/wiki/NuVoc dictionary], with words in J identified as [http://code.jsoftware.com/wiki/Vocabulary/Nouns nouns], [http://code.jsoftware.com/wiki/Vocabulary/Verbs verbs], [http://code.jsoftware.com/wiki/Vocabulary/Modifiers, modifiers], and so on. Primary words are listed in the [http://code.jsoftware.com/wiki/Vocabulary/Words vocabulary], in which their respective [http://code.jsoftware.com/wiki/Vocabulary/PartsOfSpeech parts of speech] are indicated using markup. Note that verbs have two forms: [[Arity|monadic]] (arguments only on the right) and [[Arity|dyadic]] (arguments on the left and on the right). For example, in '<code>-1</code>' the hyphen is a monadic verb, and in '<code>3-2</code>' the hyphen is a dyadic verb. The monadic definition is mostly independent of the dyadic definition, regardless of whether the verb is a primitive verb or a derived verb.\n\n==Control structures==\nJ provides control structures [http://jsoftware.com/help/dictionary/ctrl.htm (details here)] similar to other procedural languages. Prominent control words in each category include:\n* <code>assert.</code>\n* <code>break.</code>\n* <code>continue.</code>\n* <code>for.</code>\n* <code>goto_label.</code>\n* <code>if. else. elseif.</code>\n* <code>return.</code>\n* <code>select. case.</code>\n* <code>throw.</code>\n* <code>try. catch.</code>\n* <code>while. whilst.</code>\n\n==See also==\n* [[K (programming language)]] – another APL-influenced language\n* [[Q (programming language from Kx Systems)|Q]] – The language of KDB+ and a new merged version of K and KSQL.\n\n==References==\n{{Reflist}}\n\n==External links==\n*{{Official website|www.jsoftware.com}} – JSoftware, creators of J\n*{{GitHub|openj}} – Repository\n*[http://www.jsoftware.com/help/learning/contents.htm Learning J] – An Introduction to the J Programming Language by Roger Stokes\n\n{{Use dmy dates|date=September 2010}}\n\n{{APL programming language}}\n\n{{DEFAULTSORT:J (Programming Language)}}\n[[Category:APL programming language family]]\n[[Category:Array programming languages]]\n[[Category:Class-based programming languages]]\n[[Category:Dynamically typed programming languages]]\n[[Category:Function-level languages]]\n[[Category:Functional languages]]\n[[Category:Multi-paradigm programming languages]]\n[[Category:Numerical programming languages]]\n[[Category:Object-oriented programming languages]]"
    },
    {
      "title": "JLab",
      "url": "https://en.wikipedia.org/wiki/JLab",
      "text": "{{about||the nuclear physics laboratory|Thomas Jefferson National Accelerator Facility|the headphone and speaker brand|JLab Audio}}\n{{Unreferenced|date=July 2011}}\n{{Lowercase title}}\n{{Infobox software\n|name = jLab\n|genre = [[List of numerical analysis software|Technical computing]]\n|license = [[GNU GPL]] v2\n|website = https://code.google.com/p/jlabgroovy/\n}}\n\n'''jLab''' is a [[Numerical analysis|numerical computational]] environment implemented in [[Java (programming language)|Java]]. The main scripting engine of jLab is GroovySci, an extension of [[Groovy (programming language)|Groovy]]. Additionally, the interpreted J-Scripts (similar to [[MATLAB]]) and dynamic linking to Java class code are supported.\n\nThe jLab environment aims to provide a MATLAB/Scilab like scientific computing platform that is supported\nby scripting engines implemented in the Java language.\n\nIn the current implementation of jLab there coexist two scripting engines:\n# the interpreted j-Script scripting engine and\n# the compiled Groovy scripting engine. The later (i.e. Groovy) seems to be the preferred  choice, since it is much faster, can execute directly Java code using only the familiar Java packaging rules, and is [[feature-rich]] language, i.e. Groovy enhanced with MATLAB style matrix operations and surrounding support environment.\n\n== See also ==\n* [[List of numerical analysis software]]\n* [[Comparison of numerical analysis software]]\n\n== External links ==\n* https://code.google.com/p/jlabgroovy/\n\n[[Category:Numerical programming languages]]\n[[Category:Free mathematics software]]\n[[Category:Array programming languages]]\n\n\n{{compu-lang-stub}}"
    },
    {
      "title": "M2001",
      "url": "https://en.wikipedia.org/wiki/M2001",
      "text": "'''M2001''' is a [[Modular programming|modular]] [[educational programming language|educational]] mathematical [[programming language]] for developing and presenting mathematical algorithms, from the modern discrete to the classical continuous mathematics. M2001 is built on a semantic framework that is based in [[category theory]] and has a syntax similar to that of [[Pascal (programming language)|Pascal]] or [[Modula-2]].\n\nIt is designed purely for pedagogic use, so efficiency and ease of implementation have been far less important in its development than generality and range of application. It was created to play an important role in forming a formal algorithmic foundation for first-year college math students.\n\n==Overview==\n\nBased on a multi-layered datatyping scheme, M2001 includes a collection of eight ''computational types'' and another of six ''structured types''. Over these two, respectively, collections of ''mathematical classes'' and of ''abstract classes'' have been built, the latter encompassing the most commonly used [[abstract data type]]s in [[computer science]]:\n\n   matrix polynomial rationomial                    stack queue list\n   powerseries series sequence                      tree graph digraph\n   <u>MATHEMATICAL CLASSES</u>                      <u>ABSTRACT CLASSES</u>\n             |                                               |\n             |                                               |\n             |                                               |\n             +-------------------------+---------------------+\n                                       |\n                                       |\n                                       |\n                 product sum set string exponential subdomain\n                             <u>STRUCTURED TYPES</u>\n                                       |\n                                       |\n                                       |\n        boolean character natural integer rational real complex text\n                            <u>COMPUTATIONAL TYPES</u>\n\nThe lower two layers of M2001's typing scheme were based on the earlier experimental called [[CAT programming language]].\n\n== References ==\n\nA modular mathematical programming language By Ronald E. Prather [http://portal.acm.org/citation.cfm?id=275172&jmp=cit&coll=GUIDE&dl=GUIDE&CFID=9683027&CFTOKEN=77604712]\n\n[[Category:Numerical programming languages]]\n\n\n{{compu-lang-stub}}"
    },
    {
      "title": "Magma (computer algebra system)",
      "url": "https://en.wikipedia.org/wiki/Magma_%28computer_algebra_system%29",
      "text": "{{Infobox software\n| name = Magma\n| logo = Magma-logo.png\n| screenshot = \n| caption = \n| developer = Computational Algebra Group, [[Sydney School of Mathematics and Statistics|School of Mathematics and Statistics]], [[University of Sydney]]\n| latest_release_version = 2.24-6<ref>{{cite web|title=Summary of New Features in Magma V2.24|url=http://magma.maths.usyd.edu.au/magma/releasenotes/2/24/}}</ref><ref>{{cite web|title=Change Log for V2.24-6|url=http://magma.maths.usyd.edu.au/magma/releasenotes/2/24/6}}</ref>\n| latest_release_date = {{Start date and age|2019|04|05}}\n| operating_system = [[Cross-platform]]\n| genre = [[Computer algebra system]]\n| license = Cost recovery (non-commercial proprietary)\n| website = {{URL|magma.maths.usyd.edu.au}}\n}}\n'''Magma''' is a [[computer algebra system]] designed to solve problems in [[abstract algebra|algebra]], [[number theory]], [[algebraic geometry|geometry]] and [[combinatorics]]. It is named after the [[algebraic structure]] [[magma (algebra)|magma]]. It runs on [[Unix-like]] [[operating system]]s, as well as [[Microsoft Windows|Windows]].\n\n== Introduction ==\nMagma is produced and distributed by the [http://magma.maths.usyd.edu.au/magma/CayMagCAG/CayMagCAG.html Computational Algebra Group] within the [[Sydney School of Mathematics and Statistics|School of Mathematics and Statistics]] at the [[University of Sydney]].\n\nIn late 2006, the book [https://www.springer.com/math/cse/book/978-3-540-37632-3 Discovering Mathematics with Magma] was published by [[Springer Science+Business Media|Springer]] as volume 19 of the Algorithms and Computations in Mathematics series.<ref>{{cite web|title=Discovering Mathematics with Magma|url=http://magma.maths.usyd.edu.au/magma/dmwm/}}</ref>\n\nThe Magma system is used extensively within pure mathematics. The Computational Algebra Group maintain a list of publications that cite Magma, and as of 2010 there are about 2600 citations, mostly in pure mathematics, but also including papers from areas as diverse as economics and geophysics.<ref>{{cite web|title=Published Research Citing Magma|url=http://magma.maths.usyd.edu.au/magma/citations/}}</ref>\n\n==History==\nThe predecessor of the Magma system was named Cayley (1982–1993), after [[Arthur Cayley]].\n\nMagma was officially released in August 1993 (version 1.0). Version 2.0 of Magma was released in June 1996 and subsequent versions of 2.X have been released approximately once per year.\n\nIn 2013, the Computational Algebra Group finalized an agreement with the Simons Foundation, whereby the Simons Foundation will underwrite all costs of providing Magma to all U.S. non-profit, non-governmental scientific research or educational institutions. All students, researchers and faculty associated with a participating institution will be able to access Magma for free, through that institution.<ref>http://magma.maths.usyd.edu.au/magma/simons_details</ref>\n\n== Mathematical areas covered by the system ==\n* [[Group theory]]\n: Magma includes [[permutation group|permutation]], [[matrix (mathematics)|matrix]], [[finitely presented group|finitely presented]], [[solvable group|soluble]], [[abelian group|abelian]] (finite or infinite), [[polycyclic group|polycyclic]], [[braid group|braid]] and [[straight-line program]] [[group (mathematics)|groups]]. Several databases of groups are also included.\n* [[Number theory]]\n: Magma contains [[Big O notation|asymptotically fast]] algorithms for all fundamental integer and polynomial operations, such as the [[Schönhage–Strassen algorithm]] for fast multiplication of integers and polynomials. [[Integer factorization]] algorithms include the [[Lenstra elliptic curve factorization|Elliptic Curve Method]], the [[Quadratic sieve]] and the [[Number field sieve]].\n* [[Algebraic number theory]]\n: Magma includes the [[KANT computer algebra system]] for comprehensive computations in algebraic number fields. A special type also allows one to compute in the [[algebraic closure]] of a field.\n* [[Module theory]] and [[linear algebra]]\n: Magma contains [[Big O notation|asymptotically fast]] algorithms for all fundamental dense matrix operations, such as [[Strassen algorithm|Strassen multiplication]].\n* [[Sparse matrices]]\n: Magma contains the [[structured Gaussian elimination]] and [[Lanczos]] algorithms for reducing sparse systems which arise in [[index calculus]] methods, while Magma uses [[Markowitz pivoting]] for several other sparse linear algebra problems.\n* [[Lattice (group)|Lattices]] and the [[LLL algorithm]]\n: Magma has a provable implementation of [[fpLLL|''fp''LLL]],<ref>{{cite web |author=Cannon J. |url=http://magma.maths.usyd.edu.au/magma/releasenotes/2/13/#section_13 |title=Magma 2.13 release notes |date=July 2006 }}</ref> which is an LLL algorithm for integer matrices which uses floating point numbers for the Gram–Schmidt coefficients, but such that the result is rigorously proven to be LLL-reduced.\n* [[Commutative algebra]] and [[Gröbner bases]]\n: Magma has an efficient implementation of the [[Faugère F4 algorithm]] for computing [[Gröbner bases]].\n* [[Representation theory]]\n: Magma has extensive tools for computing in representation theory, including the computation of [[character tables]] of finite groups and the [[Meataxe]] algorithm.\n* [[Invariant theory]]\n: Magma has a type for invariant rings of finite groups, for which one can primary, secondary and fundamental invariants, and compute with the module structure.\n* [[Lie theory]]\n* [[Algebraic geometry]]\n* [[Arithmetic geometry]]\n* [[Finite incidence structures]]\n* [[Cryptography]]\n* [[Coding theory]]\n* [[Optimization (mathematics)|Optimization]]\n\n==See also==\n*[[Comparison of computer algebra systems]]\n\n==References==\n{{reflist}}\n\n==External links==\n*{{Official website|magma.maths.usyd.edu.au}}\n*[http://magma.maths.usyd.edu.au/calc/ Magma Free Online Calculator]\n*[http://magma.maths.usyd.edu.au/users/allan/gb/ Magma's High Performance for computing Gröbner Bases] (2004)\n*[http://magma.maths.usyd.edu.au/users/allan/mat/hermite.html Magma's High Performance for computing Hermite Normal Forms of integer matrices]\n*[http://magma.maths.usyd.edu.au/users/allan/gcdcomp.html Magma V2.12 is apparently \"Overall Best in the World at Polynomial GCD\" :-)]\n*[http://www.math.harvard.edu/computing/magma/ Magma example code]\n\n{{Computer algebra systems}}\n\n{{DEFAULTSORT:Magma Computer Algebra System}}\n[[Category:Computer algebra system software for Linux]]\n[[Category:Computer algebra system software for MacOS]]\n[[Category:Computer algebra system software for Windows]]\n[[Category:Cross-platform software]]\n[[Category:Functional languages]]\n[[Category:Numerical programming languages]]\n[[Category:Proprietary commercial software for Linux]]"
    },
    {
      "title": "MATH-MATIC",
      "url": "https://en.wikipedia.org/wiki/MATH-MATIC",
      "text": "{{Infobox programming language\n| name = MATH-MATIC\n| paradigm = [[imperative programming|imperative]]\n| year = {{start-date|1957}}\n| designer = [[Remington Rand]]\n| influenced_by = [[FLOW-MATIC]]\n| influenced = [[UNICODE (programming language)]]\n| platform = [[UNIVAC I]], [[UNIVAC II]]\n}}\n\n'''MATH-MATIC''' is the marketing name for the AT-3 (Algebraic Translator 3) [[compiler]], an early [[programming language]] for the [[UNIVAC I]] and [[UNIVAC II]].\n\nMATH-MATIC was written beginning around 1955 by a team led by [[Charles Katz]] under the direction of [[Grace Hopper]]. A preliminary manual<ref>Ash (1957)</ref> was produced in 1957 and a final manual<ref>Univac (1958)</ref> the following year.\n\nSyntactically, MATH-MATIC was similar to Univac's contemporaneous business-oriented language, [[FLOW-MATIC]], differing in providing algebraic-style expressions and floating-point arithmetic, and arrays rather than record structures.\n\n== Notable features ==\n\nExpressions in MATH-MATIC could contain numeric exponents, including decimals and fractions, by way of a custom typewriter.<ref>Sammet (1969) p.&nbsp;135</ref>\n\nMATH-MATIC programs could include [[inline assembler]] sections of [[ARITH-MATIC]] code and [[UNIVAC I|UNIVAC]] machine code.<ref>Sammet (1969) p.&nbsp;137</ref>\n\nThe [[UNIVAC I]] had only 1000 words of memory, and the successor [[UNIVAC II]] as little as 2000. MATH-MATIC allowed for larger programs, automatically generating code to read [[Overlay (programming)|overlay]] segments from [[UNISERVO]] tape as required. The compiler attempted to avoid splitting loops across segments.<ref>Sammet (1969) p.&nbsp;137</ref>\n\n== Influence ==\n\nIn proposing the collaboration with the [[Association for Computing Machinery|ACM]] that led to [[ALGOL 58]], the [[Gesellschaft für Angewandte Mathematik und Mechanik]] wrote that it considered MATH-MATIC the closest available language to its own proposal.<ref>Bemer (1969) p.&nbsp;161</ref>\n\nIn contrast to [[John Backus|Backus']] [[Fortran|FORTRAN]], MATH-MATIC did not emphasise execution speed of compiled programs. The UNIVAC machines did not have [[floating point|floating-point]] hardware, and MATH-MATIC was translated via A-3 ([[ARITH-MATIC]]) pseudo-assembler code rather than directly to UNIVAC machine code, limiting its usefulness. <ref>Knuth (1976) p.&nbsp;90</ref>\n\n== MATH-MATIC Sample program ==\n\nA sample MATH-MATIC program:<ref>Univac (1958) p. 8</ref>\n\n<!-- Note to editors: MATH-MATIC had specific and rigid rules for placement of space characters. The <pre> or <syntaxhighlight> tags do not work here due to the need for superscripts. Please use {{pre}}. -->\n{{pre|1=\n(2)  TYPE-IN ALPHA . \n(2A) READ A B C SERVO 4 STORAGE A IF SENTINEL JUMP TO SENTENCE 8 . \n(3)  READ D F SERVO 5 . \n(4)  VARY Y 1 (0.1) 3 SENTENCE 5 THRU 6 . \n(5)  X1 = (7*10<sup>3</sup>*Y*A*SIN ALPHA)<sup>3</sup> / (B POW D+C POW E) . \n(6)  WRITE AND EDIT A Y D E X1 SERVO 6 . \n(7)  JUMP TO SENTENCE 2A . \n(8)  CLOSE-INPUT AND REWIND SENTENCE 3 . \n(9)  CLOSE-OUTPUT SENTENCE 6 . \n(10) READ F G H N SERVO 4 STORAGE A IF SENTINEL JUMP TO SENTENCE 20 . \n(11) EXECUTE SENTENCE 3 . \n(12) X2 = (3 ROOT (E-G)+LOG (D+N)) / (F<sup>2.6</sup>*EXP H) . \n(13) WRITE EDIT F D F X2 SERVO 6 . \n(16) JUMP TO SENTENCE 10 . \n(20) STOP . \n}}\n\n==Notes==\n{{reflist|2}}\n\n==References==\n\n* {{cite techreport\n|first1=R.|last1=Ash\n|first2=E.|last2=Broadwin\n|first3=V.|last3=Della Valle\n|first4=M.|last4=Greene\n|first5=A.|last5=Jenny\n|first6=C.|last6=Katz|authorlink6=Charles Katz\n|first7=L.|last7=Yu\n|title=Preliminary Manual for MATH-MATIC and ARITH-MATIC Systems for ALGEBRAIC TRANSLATION and COMPILATION for UNIVAC I and II\n|date=1957-04-19\n|publisher=Remington Rand Univac\n|publication-place=Philadelphia\n|url=http://archive.computerhistory.org/resources/text/Knuth_Don_X4100/PDF_index/k-7-pdf/k-7-u2310-UNIVAC-MATH-MATIC-ARITH-MATIC.pdf\n|format=PDF\n|access-date=2016-03-19\n}}\n\n* {{cite\n|first=Robert W.|last=Bemer|authorlink=Bob Bemer\n|title=A Politico-Social History of Algol (With a Chronology in the Form of a Log Book)\n|date=1969\n|url=http://www.softwarepreservation.org/projects/ALGOL/paper/Bemer-Politico_Social_History_of_Algol.pdf\n|access-date=2016-03-20\n}}\n\n* {{cite techreport\n|first1=Donald|last1=Knuth|authorlink1=Donald Knuth\n|first2=Luis|last2=Trabb Pardo\n|title=The Early Development of Programming Languages\n|date=August 1976\n|publisher=Computer Science Department, School of Humanities and Sciences, Stanford University\n|url=https://archive.org/details/DTIC_ADA032123\n|access-date=2016-03-19\n}}\n\n* {{cite book\n|last=Sammet|first=Jean|authorlink=Jean E. Sammet\n|date=1969\n|title=Programming Languages: History and Fundamentals\n|publisher=Prentice-Hall\n|isbn=978-0-13-729988-1\n|pages=132,135-137\n}}\n\n* {{cite techreport\n|title=Univac MATH-MATIC Programming System\n|date=1958\n|publisher=Remington Rand Univac\n|url=http://bitsavers.org/pdf/univac/univac2/U-1568_MATH-MATIC_PgmgSys_1958.pdf\n|format=PDF\n|access-date=2016-03-19\n}}\n\n* {{cite web\n|url=http://hopl.info/showlanguage.prx?exp=435\n|title=MATH-MATIC — Mathematically oriented autocode (Computer Language)\n|website=Online Historical Encyclopaedia of Programming Languages\n|access-date=2016-03-20\n}}\n\n* {{cite web\n|url=http://hopl.info/showlanguage.prx?exp=29\n|title=UNICODE — UNIVAC hybrid of FORTRAN and MATH-MATIC\n|website=Online Historical Encyclopaedia of Programming Languages\n|access-date=2016-03-20\n}}\n\n[[Category:Numerical programming languages]]\n[[Category:Programming languages]]\n[[Category:Programming languages created in 1957]]\n[[Category:1957 software]]"
    },
    {
      "title": "MEX file",
      "url": "https://en.wikipedia.org/wiki/MEX_file",
      "text": "A '''MEX file''' is a type of [[computer file]] that provides an interface between [[MATLAB]] or [[GNU Octave|Octave]] and functions written in [[C (programming language)|C]], [[C++]] or [[Fortran]]. It stands for \"MATLAB executable\".\n\nWhen compiled, MEX files are dynamically loaded and allow external functions to be invoked from within MATLAB or Octave as if they were built-in functions.\n\nTo support the development of MEX files, both MATLAB and Octave offer external interface functions that facilitate the transfer of data between MEX files and the workspace. In addition to MEX files, Octave has its own format using its own native [[API]], with better performance.<ref>https://www.gnu.org/software/octave/doc/interpreter/Mex_002dFiles.html</ref>\n\n==References==\n{{Reflist}}\n\n== External links ==\n*[http://www.mathworks.com/support/tech-notes/1600/1605.html?s_cid=wiki_mex_1 MEX-files guide from MathWorks]\n*[https://www.gnu.org/software/octave/doc/interpreter/Mex_002dFiles.html MEX-files in the GNU Octave manual]\n\n[[Category:Data analysis software]]\n[[Category:Numerical programming languages]]\n[[Category:Cross-platform software]]\n[[Category:Filename extensions]]\n\n\n{{Compu-stub}}"
    },
    {
      "title": "MIMIC",
      "url": "https://en.wikipedia.org/wiki/MIMIC",
      "text": "{{about|the programming language|the vaccine development tool|MIMIC (Immunology)|other uses|Mimic (disambiguation)}}\n\n'''MIMIC''', known in capitalized form only, is a former [[simulation]] [[computer language]] developed 1964 by [[H. E. Petersen]], F. J. Sansom and L. M. Warshawsky of Systems Engineering Group within the [[Air Force Materiel Command]] at the [[Wright-Patterson AFB]] in [[Dayton, Ohio]], United States.<ref>[http://stinet.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=AD0656301 Defense Technical Information Center]</ref> It is an [[expression-oriented programming languages|expression-oriented]] continuous block simulation language, but capable of incorporating blocks of [[FORTRAN]]-like algebra.\n\nMIMIC is a further development from MIDAS ('''M'''odified '''I'''ntegration '''D'''igital '''A'''nalog '''S'''imulator), which represented [[analog computer]] design. Written completely in FORTRAN but one routine in [[COMPASS]], and ran on [[Control Data Corporation|Control Data]] [[supercomputer]]s, MIMIC is capable of solving much larger simulation models.\n\nWith MIMIC, [[ordinary differential equation]]s describing [[mathematical model]]s in several scientific disciplines as in engineering, physics, chemistry, biology, economics and as well as in social sciences can easily be solved by [[numerical integration]] and the results of the analysis are listed or drawn in diagrams. It also enables the analysis of [[nonlinearity|nonlinear dynamic condition]]s.\n\nThe MIMIC software package, written as FORTRAN overlay programs, executes input statements of the mathematical model in six consecutive passes. Simulation programs written in MIMIC are compiled rather than interpreted. The core of the simulation package is a variable step numerical integrator of fourth-order [[Runge-Kutta method]]. Many useful functions related to electrical circuit elements exist besides some mathematical functions found in most scientific programming languages. There is no need to sort the statements in order of dependencies of the variables, since MIMIC does it internally.\n\nParts of the software organized in overlays are:\n*MIMIN (input)– reads in user simulation program and data,\n*MIMCO (compiler) – compiles the user program and creates an in-core array of instructions,\n*MIMSO (sort)– sorts the instructions array after dependencies of variables,\n*MIMAS (assembler) – converts the [[Binary-coded decimal|BCD]] instructions into [[machine code|machine-oriented code]],\n*MIMEX (execute)– executes the user program by integrating,\n*MIMOUT (output)– puts out the data as a list or diagram of data.\n\n==Example==\n;Problem:\nConsider a predator-prey model from the field of [[marine biology]] to determine the dynamics of fish and shark populations. As a simple model, we choose the [[Lotka–Volterra equation]] and the constants given in a tutorial.<ref>{{cite web |url=http://fluid.stanford.edu/~fringer/teaching/numerical_methods_02/tutorials/tutorial2.pdf |publisher=Stanford University-Dept of Civil and Environmental Engineering, Environmental Fluid Mechanics Lab |title=Tutorial 2: Numerical Solutions of ODE's |date=2002-08-19 |accessdate=2012-02-26 |deadurl=yes |archiveurl=https://web.archive.org/web/20100720073318/http://fluid.stanford.edu/~fringer/teaching/numerical_methods_02/tutorials/tutorial2.pdf |archivedate=2010-07-20 |df= }}</ref>\n\nIf\n: ''f''(t): Fish population over time (fish)\n: ''s''(t): Shark population over time (sharks)\n: d''f'' / dt or <math>\\dot f</math>: growth rate of fish population (fish/year)\n: d''s'' / dt or <math>\\dot s</math>: growth rate of shark population (sharks/year)\n: <math>\\alpha</math>: growth rate of fish in the absence of sharks (1/year)\n: <math>\\beta</math>:  death rate per encounter of fish with sharks (1/sharks and year).\n: <math>\\gamma</math>: death rate of sharks in the absence of their prey, fish (1/year)\n: <math>\\epsilon</math>: efficiency of turning predated fish into sharks (sharks/fish)\nthen\n: <math> \\dot f = \\alpha f - \\beta f s </math> \n: <math> \\dot s = \\epsilon \\beta f s - \\gamma s </math>\nwlth initial conditions\n: <math> f(0) = f_o </math>\n: <math> s(0) = s_o </math>\n\nThe problem's constants are given as:\n*<math>f_o</math> = 600 fish\n*<math>s_o</math> = 50 sharks\n*<math>\\alpha</math> = 0.7 fish/year\n*<math>\\beta</math> = 0.007 fish/shark and year\n*<math>\\gamma</math> = 0.5 shark/year\n*<math>\\epsilon</math> = 0.1 shark/fish\n*tmax = 50 year\n\n;Code sample:\n\n Card columns\n 0        1         2         3         4         5         6         7\n 12345678901234567890123456789012345678901234567890123456789012345678901\n -----------------------------------------------------------------------\n * A SIMPLE PREDATOR-PREY MODEL FROM MARINE BIOLOGY\n / (TUTORIAL 2: NUMERICAL SOLUTION OF ODE'S - 19/08/02)\n / ENVIRONMENTAL FLUID MECHANICS LAB\n / DEPT OF CIVIL AND ENVIRONMENTAL ENGINEERİNG\n / STANFORD UNIVERSITY\n *\n * LOTKA–VOLTERRA EQUATION\n                   CON(F0,S0,TMAX)\n                   CON(ALPHA,BETA,GAMMA,EPS)\n           1DF   = ALPHA*F-BETA*F*S\n           F     = INT(1DF,F0)\n           1DS   = EPS*BETA*F*S-GAMMA*S\n           S     = INT(1DS,S0)\n                   HDR(TIME,FISH,SHARK)\n                   OUT(T,F,S)\n                   PLO(F,S)\n                   FIN(T,TMAX)\n                   END\n <EOR>\n 600.       50.          50.\n 0.7        0.007        0.5         0.1\n <EOF>\n\n==References==\n{{reflist}}\n;Notes\n{{refbegin}}\n* Control Data MIMIC; A Digital Simulation Language, Reference Manual, Publication Number 4461n400, Control Data Corporation, Special Systems Publications, St. Paul, Minnesota (April 1968)\n* MIMIC, An Alternative Programming Language for Industrial Dynamics, N.D. Peterson, Socio-Econ Plan Sci. 6, Pergamon 1972\n*[http://bitsavers.vt100.net/pdf/oregonState/os3/CC-69-05_MIMIC_Apr69.pdf MIMIC Manual (1969), Computer Center Oregon State University]{{dead link|date=May 2017 |bot=InternetArchiveBot |fix-attempted=yes }}\n{{refend}}\n\n[[Category:Object-oriented programming languages]]\n[[Category:Numerical programming languages]]\n[[Category:Simulation programming languages]]\n[[Category:CDC software]]\n[[Category:Wright-Patterson Air Force Base]]\n[[Category:Programming languages created in 1964]]"
    },
    {
      "title": "Nickle (programming language)",
      "url": "https://en.wikipedia.org/wiki/Nickle_%28programming_language%29",
      "text": "{{multiple issues|\n{{Primary sources|date=November 2009}}\n{{Notability|date=November 2009}}\n}}\n\n{{Infobox programming language\n| name = Nickle\n| paradigm = [[Multi-paradigm programming language|multi-paradigm]]\n| year = 2001\n| designer = [[Keith Packard]] and [[Bart Massey]]\n| latest_release_date = May 21, 2006\n| typing = strong\n| influenced_by = [[C (programming language)|C]], [[Lisp (programming language)|Lisp]], [[Modula-3]], [[ML (programming language)|ML]], [[Java (programming language)|Java]]\n| operating_system = [[Cross-platform]]\n| license = [[MIT License]]\n| website = [http://www.nickle.org/ www.nickle.org]\n}}\n\n'''Nickle''' is a numeric oriented [[programming language]] by [[Keith Packard]] and [[Bart Massey]]. Originally used for desktop calculation, it has since expanded for prototyping of complicated algorithms.\n\n==External links==\n*[http://nickle.org The Nickle website]\n\n[[Category:Numerical programming languages]]\n[[Category:Software using the MIT license]]\n\n\n{{Compu-lang-stub}}"
    },
    {
      "title": "O-Matrix",
      "url": "https://en.wikipedia.org/wiki/O-Matrix",
      "text": "{{more citations needed|date=June 2014}}\n{{notability|date=June 2014}}\n\n'''O-Matrix''' is a [[Matrix (mathematics)|matrix]] [[programming language]] for [[mathematics]], [[engineering]], [[science]], and financial analysis, marketed by Harmonic Software.   The language is designed for use in [[high-performance computing]].\n\nO-Matrix provides an [[integrated development environment]]  and a matrix-based [[scripting language]]. The environment includes mathematical, statistical, engineering and visualization functions. The set of analysis functions is designed for development of complex, computationally intensive scientific, mathematical and engineering applications.\n\nThe integrated environment provides a mode that is largely compatible with version 4 of the [[MATLAB]] language in the commercial product from [[MathWorks]]. Certain features of MATLAB, such as non-numeric [[data type]]s (structures, cell arrays and objects), [[error handling]] with try/catch, and [[Nested function|nested]] and [[anonymous function]]s, are missing in O-Matrix.\n\nThe O-Matrix environment includes a [[virtual machine]] of the O-Matrix language to enable re-distribution of applications.\n\n==External links==\n*[http://www.omatrix.com/ O-Matrix site (Harmonic Software).]\n\n[[Category:Array programming languages]]\n[[Category:Numerical programming languages]]\n\n\n{{compu-lang-stub}}"
    },
    {
      "title": "Ox (programming language)",
      "url": "https://en.wikipedia.org/wiki/Ox_%28programming_language%29",
      "text": "{{Infobox Software\n| name = Ox\n| developer = [[OxMetrics Technologies]]\n| latest_release_version = 6.21\n| latest release date = August 2011\n| operating system = [[Microsoft Windows|Windows]], [[Mac OS X]], [[Linux]]\n| genre = [[programming language]], [[econometric software]]\n| license = [[proprietary software|proprietary]] (console version free for academic use)\n| website = [http://www.oxmetrics.net/ www.oxmetrics.net]\n}}\n\n'''Ox''' is an [[object-oriented]] [[Matrix (computer science)|matrix]] [[programming language]] with a mathematical and statistical function library, developed by [[Jurgen Doornik]]. It has been designed for [[econometric]] programming. It is available for Windows, Mac OS X and Linux platforms.\n\nThe downloadable console version of Ox is free for academic use. A commercial version is available for non-academic use. According to its documentation, it should be cited whenever results are published.<ref>{{cite web |title=Ox citation and copyright |accessdate=November 28, 2015 |url=http://www.doornik.com/ox/index.html?content=http://www.doornik.com/ox/oxcite.html }}</ref>\n\nThe programming environment for econometric modelling [[OxMetrics]] is based on Ox.\n\n==See also==\n* [[R (programming language)]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*[http://www.doornik.com/ Official site]\n*[http://www.doornik.com/ox/ Documentation]\n\n[[Category:Numerical programming languages]]\n\n\n{{compu-lang-stub}}"
    },
    {
      "title": "Perl Data Language",
      "url": "https://en.wikipedia.org/wiki/Perl_Data_Language",
      "text": "{{Infobox programming language\n | name                   = Perl Data Language (PDL)\n | paradigm               = [[Array programming|Array]]\n | released               = {{Start date|1996}}\n | developer              = [[Karl Glazebrook]], [[Jarle Brinchmann]], [[Tuomas Lukka]], and [[Christian Soeller]]\n | latest_release_version = 2.019\n | latest_release_date    = {{Start date and age|2018|05|06|df=yes}}<ref>{{cite web | url=https://sourceforge.net/p/pdl/mailman/message/36311018 | title=PDL-2.019 released | date=May 5, 2018 }}</ref>\n | influenced by          = [[APL (programming language)|APL]], [[IDL (programming language)|IDL]], [[Perl]]\n | operating_system       = [[Cross-platform]]\n | license                = [[GNU General Public License]], [[Artistic License]]\n | website                = {{URL|http://pdl.perl.org/}}\n}}\n\n'''Perl Data Language''' (abbreviated '''PDL''') is a set of [[free software]] array programming extensions to the [[Perl|Perl programming language]]. PDL extends the data structures built into Perl, to include large [[Array data structure|multidimensional arrays]], and adds functionality to manipulate those arrays as vector objects. It also provides tools for [[image processing]], [[computer model]]ing of physical systems, and graphical plotting and presentation. Simple operations are automatically vectorized across complete arrays, and higher-dimensional operations (such as matrix multiplication) are supported.\n\n==Language design==\nPDL is a vectorized [[array programming]] language: the expression syntax is a variation on standard mathematical [[Vector (geometric)|vector]] notation, so that the user can combine and operate on large arrays with simple expressions. In this respect, PDL follows in the footsteps of the [[APL programming language]], and it has been compared to commercial languages such as [[MATLAB]] and [[Interactive Data Language]], and to other free languages such as [[NumPy]] and [[GNU Octave#Octave.2C the language|Octave]].<ref>{{Cite web|url=http://blogs.perl.org/users/lhermida/2011/03/hi-everyone-as-a-bioinformatician.html|title=Putting Perl Back on Top in the Fields of Scientific and Financial Computing}}</ref> Unlike MATLAB and IDL, PDL allows great flexibility in indexing and vectorization: for example, if a subroutine normally operates on a 2-D [[matrix (mathematics)|matrix]] array, passing it a 3-D [[data cube]] will generally cause the same operation to happen to each 2-D layer of the cube.<ref>{{Cite web|url=http://pdl.perl.org/?docs=Threading&title=PDL::Threading|title=PDL online documentation (PDL::Threading section)}}</ref>\n\nPDL borrows from Perl at least three basic types of program structure: [[imperative programming]], [[functional programming]], and [[pipeline programming]] forms may be combined. Subroutines may be loaded either via a built-in [[autoload]] mechanism or via the usual Perl module mechanism. PDL-like functionality is being included in the development of [[Perl 6]].<ref>{{Cite web|url=http://www.nntp.perl.org/group/perl.perl6.language.data/2000/08/msg160.html|\ntitle=Re: RFC 169 (v1) Proposed syntax for matrix element access and slicing.}}</ref>\n\n==Graphics==\n[[Image:Pdl-plot.png|thumb|200px|right|A plot generated using PDL]]\n\nTrue to the [[glue language]] roots of Perl, PDL borrows from several different modules for graphics and plotting support. [[NetPBM]] provides image file I/O (though FITS is supported natively). [[Gnuplot]], [[PLplot]], [[PGPLOT]], and [[Prima (graphics software)|Prima]] modules are supported for 2-D graphics and plotting applications, and [[Gnuplot]] and [[OpenGL]] are supported for 3-D plotting and rendering.\n\n==I/O==\nPDL provides facilities to read and write many open data formats, including [[JPEG]], [[Portable Network Graphics|PNG]], [[GIF]], [[portable pixmap|PPM]], [[MPEG]], [[FITS]], [[NetCDF]], [[GRIB]], raw binary files, and delimited ASCII tables. PDL programmers can use the [[CPAN]] Perl I/O libraries to read and write data in hundreds of standard and niche file formats.\n\n==perldl==\nAn installation of PDL usually comes with an interactive [[Shell (computing)|shell]] known as '''perldl''', which can be used to perform simple calculations without requiring the user to create a Perl program file. A typical session of perldl would look something like the following:\n\n<source lang=perl>\n  perldl> $x = pdl [[1, 2], [3, 4]];\n \n  perldl> $y = pdl [[5, 6, 7],[8, 9, 0]];\n \n  perldl> $z = $x x $y;\n \n  perldl> p $z;\n \n  [\n   [21 24  7]\n   [47 54 21]\n  ]\n</source>\n\nThe commands used in the shell are Perl statements that can be used in a program with <code>PDL</code> module included. '''<code>x</code>''' is an [[overloaded operator]] for [[matrix multiplication]], and '''<code>p</code>''' in the last command is a shortcut for '''<code>print</code>'''.\n\n==Implementation==\nThe core of PDL is written in [[C (programming language)|C]]. Most of the functionality is written in '''PP''', a PDL-specific metalanguage that handles the vectorization of simple C snippets and interfaces them with the Perl host language via Perl's [[XS (Perl)|XS]] compiler. Some modules are written in [[Fortran]], with a C/PP interface layer. Many of the supplied functions are written in PDL itself. PP is available to the user to write C-language extensions to PDL. There is also an Inline module (Inline::Pdlpp) that allows PP function definitions to be inserted directly into a Perl script; the relevant code is low-level compiled and made available as a Perl subroutine.\n\nThe PDL API uses the basic Perl 5 object-oriented functionality: PDL defines a new type of Perl scalar object ([[eponym]]ously called a \"PDL\", pronounced \"piddle\") that acts as a Perl scalar, but that contains a conventional [[data type|typed]] [[Array data type|array]] of numeric or character values. All of the standard Perl operators are overloaded so that they can be used on PDL objects transparently, and PDLs can be mixed-and-matched with normal Perl scalars. Several hundred object methods for operating on PDLs are supplied by the core modules.\n\n==Perl 6 version==\nIn [[Perl 6]], PDL is specified as a trait in Synopsis 9.<ref>http://perlcabal.org/syn/S09.html#PDL_support</ref> As of January 2013, this feature is not yet implemented in [[Rakudo Perl 6|Rakudo]], though.{{outdated section|date=March 2017}}\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[List of numerical analysis software]]\n* [[Comparison of numerical analysis software]]\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{Official website|http://pdl.perl.org/}}\n* [http://www.perlmonks.org/?node_id=587436 PDL Quick Reference] PDL Intro & resources\n* [https://www.youtube.com/watch?v=rf1yfZ2yUFo Tutorial lecture on PDL]\n* [http://sourceforge.net/projects/pdl/files/PDL_2013/PDL-Book/PDL-Book-20130322.pdf/download Draft release of the PDL Book for PDL-2.006]\n* [http://adsabs.harvard.edu/abs/2004SoPh..219....3D Example of PDL usage in the scientific literature]\n\n[[Category:Array programming languages]]\n[[Category:Free mathematics software]]\n[[Category:Free science software]]\n[[Category:Numerical programming languages]]\n[[Category:Perl modules]]"
    },
    {
      "title": "Rlab",
      "url": "https://en.wikipedia.org/wiki/Rlab",
      "text": "{{multiple issues|\n{{unreferenced|date=July 2017}}\n{{notability|date=July 2017}}\n}}\n\n'''Rlab''' is an interactive, [[interpreted (programming languages)|interpreted]] [[numerical computation]] [[computer program|program]] and its core [[programming language]], written by [[Ian Searle]]. Rlab (the language) is very high level and is intended to provide fast prototyping and program development, as well as easy data-visualization, and processing.\n\nRlab was not designed as a clone of [[MATLAB]]. However, as Rlab (the program) is intended to provide a good experimental environment (or laboratory) in which to do [[matrix (mathematics)|matrix]] math, the programming language possesses similar operators and concepts and could be called ''MATLAB-like''.\n\nRlab borrows some of the best features of the MATLAB language but provides them through a different [[syntax]] that has been modified in order to be more expressive while reducing ambiguity. The variable scoping rules facilitate the creation of larger programs and re-usable program libraries. A heterogeneous [[associative array]] [[datatype]] has been added to allow users to create and operate on arbitrary data structures. The fundamental data type is the dense [[floating point]] matrix (either real or complex), though string and sparse numerical matrices (both real and complex) are also provided.\n\nRlab 2.1 is no longer under active development. Binary versions are available for [[Linux]] and for [[Microsoft Windows|Windows]], and [[source code]] is available under the [[GNU General Public License|GPL]].\n\nRlab 2.2 has been released as a part of the project '''''rlabplus''''' by [[Marijan Koštrun]].\n\n==External links==\n* [http://rlab.sourceforge.net/ The Rlab home page]\n\n[[Category:Numerical programming languages]]\n[[Category:Array programming languages]]\n[[Category:Free mathematics software]]\n[[Category:Free software programmed in C]]"
    },
    {
      "title": "ScicosLab",
      "url": "https://en.wikipedia.org/wiki/ScicosLab",
      "text": "{{Infobox software\n|name                   = ScicosLab\n|screenshot             = [[Image:ScicosLab 4.4b7 Screenshot.PNG|300px]]\n|caption                = Screenshot of ScicosLab 4.4 beta 7 running under Windows 7\n|developer              = Metalau Project-team and ENPC\n|latest_release_version = 4.4.2\n|latest_release_date    = {{release date and age|2015|10|3}}\n|latest_preview_version =\n|latest_preview_date    =\n|operating_system       = [[Linux]], [[Microsoft Windows|Windows]], [[Mac OS X]]\n|genre                  = [[List of numerical analysis software|Technical computing]]\n|license                = [[Scilab License]]\n|website                = [http://www.scicoslab.org/ www.scicoslab.org]\n}}\n\n'''ScicosLab''' is a software package providing a multi-platform environment for scientific computation. It is based on the official [[Scilab]] 4.x (BUILD4) distribution, and includes the modeling and simulation tool [[Scicos]] and a number of other toolboxes.\n\nThe latest stable version of ScicosLab is ScicosLab 4.4.2.<ref>{{cite web\n| url = http://www.scicoslab.org/\n| title = ScicosLab Download\n| publisher = ScicosLab\n| accessdate = 2016-05-27}}</ref>\n\nIt is possible that Scilab/Scicos is currently the most complete alternative to commercial packages for [[dynamic systems]] modeling and simulation packages such as [[MATLAB]]/[[Simulink]] and MATRIXx/SystemBuild.\"<ref>{{cite book\n| last = Campbell\n| first = Stephen L.\n| last2 = Chancelier\n| first2 = Jean-Philippe\n| last3 = Nikoukhah\n| first3 = Ramine\n| title = Modeling and Simulation in Scilab/Scicos with ScicosLab 4.4\n| edition = Second\n| publisher = Springer Science+Business Media\n| year = 2010\n| page = V\n| doi = 10.1007/978-1-4419-5527-2\n| isbn = 978-1-4419-5527-2 }}</ref>\n\n== Features ==\nScicosLab runs, and is available in binary format, for the main available platforms like Unix/Linux workstations, Microsoft Windows, and MacOSX. Scicoslab was based in [[Scilab]] and [[Scicos]], but it was forked from them. Currently it is separated from the new versions evolution in order to maintain compatibility among them.\n\n== See also ==\n* [[Scilab]]\n* [[Scicos]]\n\n==External links==\n*[http://www.scicoslab.org/ ScicosLab Homepage]\n*[http://cermics.enpc.fr/~jpc/scilab-gtk-tiddly/files/license.txt Scilab License]\n*[http://www.scicos.org/ Scicos Homepage]\n*[http://www.maxplus.org/ Maxplus Homepage]\n*[http://erika.tuxfamily.org/drupal/scilabscicos.html Scicos-FLEX Homepage] - Scicos-FLEX is a toolbox for code generation for embedded microcontrollers\n*[http://www.e4coder.com E4Coder: The toolset based on ScicosLab for simulation and code generation for embedded devices]\n\n== References ==\n<references />\n\n{{-}}\n\n{{Numerical analysis software}}\n\n{{DEFAULTSORT:Scicoslab}}\n\n[[Category:Numerical programming languages]]\n[[Category:Cross-platform software]]\n\n{{software-stub}}"
    },
    {
      "title": "ScientificPython",
      "url": "https://en.wikipedia.org/wiki/ScientificPython",
      "text": "{{distinguish|SciPy}}\n\n'''ScientificPython''' is an [[open source]] library of scientific tools for the [[Python (programming language)|Python programming language]]. Its development started in 1995.<ref>{{cite web |title=ScientificPython |url=http://dirac.cnrs-orleans.fr/ScientificPython/ |access-date=2019-02-21}}</ref>\n\nIt has not been updated since October 1, 2014.<ref>{{Cite web|url=https://sourcesup.renater.fr/projects/scientific-py/|title=SourceSup: ScientificPython: Project Home|website=sourcesup.renater.fr|access-date=2019-02-21}}</ref>\n\nThe library includes\n* mathematical tools like\n** [[wikt:Differentiation|Differentiation]] for functions of any number of variables up to any order\n** Numerical integration using the [[Romberg's method|Romberg algorithm]]\n** [[Newton's method|Newton-Raphson]] for numerical root finding\n** [[Nonlinearity|Non-linear]] [[least squares]] fitting\n* support for [[parallel computing]]\n** [[Bulk synchronous parallel]]\n** [[Message Passing Interface]]\n* and several [[input/output]] interfaces, notably with\n** [[NetCDF]] files\n** [[Protein Data Bank (file format)|Protein Data Bank]] files\n** [[Fortran]]-compatible text formatting\n** [[VRML]] for 3D visualizations\n[[Qt (software)|Qt]] and [[Tk (software)|Tk]] [[widget toolkit]]s are provided for building cross-platform [[graphical user interface]]s.\n\nScientificPython is released under the [[CeCILL]].\n\nThe main developer and maintainer of ScientificPython is Konrad Hinsen of Orléans University who uses it as a building block for his own research code, in particular the ''molecular modeling toolkit'' MMTK<ref>{{cite journal |author=Hinsen K |title=The molecular modeling toolkit: A new approach to molecular simulations |journal=Journal of Computational Chemistry |volume=21 |pages=79–85 |year=2000 |doi=10.1002/(SICI)1096-987X(20000130)21:2<79::AID-JCC1>3.0.CO;2-B |issue=2}}</ref> and the software nMoldyn that uses [[molecular dynamics]] trajectories to predict [[neutron scattering]] spectra.<ref>{{cite journal |author=Róg T, Murzyn K, Hinsen K, Kneller GR |title=nMoldyn: A program package for a neutron scattering oriented analysis of molecular dynamics simulations |journal=Journal of Computational Chemistry |volume=24 |pages=657–667 |year=2003 |last2=Keiner |last3=Kneller |last4=Schiller |doi=10.1002/jcc.10243 |pmid=12632481 |issue=5}}</ref><ref>{{cite journal|author= Calandrini, E. Pellegrini, P. Calligari, K. Hinsen, G.R. Kneller|title=nMoldyn - Interfacing spectroscopic experiments, molecular dynamics simulations and models for time correlation functions|journal=Collection SFN | volume=12 | pages=201–232 | year=2011 |doi=10.1051/sfn/201112010}}</ref> Outside this particular application context, most users are likely to prefer the package [[SciPy]], which has seen a more dynamic evolution in the decade 2000–2010, involving several active developers.\n\n== See also ==\n* [[List of numerical analysis software]]\n\n==References==\n{{Reflist}}\n\n== External links ==\n* {{Official website|http://dirac.cnrs-orleans.fr/ScientificPython/}}\n\n{{DEFAULTSORT:Scientificpython}}\n\n[[Category:Free science software]]\n[[Category:Numerical programming languages]]\n[[Category:Python scientific libraries]]\n\n{{free-software-stub}}"
    },
    {
      "title": "Scilab Image Processing",
      "url": "https://en.wikipedia.org/wiki/Scilab_Image_Processing",
      "text": "\n{{Infobox_Software\n|name = SIP: Scilab Image Processing\n|\n|author = Ricardo Fabbri\n|developer = [[:pt:Lab Macambira|Lab Macambira]] team, Zhang Cheng, Ricardo Fabbri, Nivaldo Bondanca, Fernando Gorodscy\n|latest_release_version = 0.5.6\n| latest_release_date = {{release_date|2011|08|23}}\n|operating_system = [[Linux]], [[UNIX]], [[Microsoft Windows|Windows]]\n|programming language = [[C (programming language)|C]], [[Scilab]]\n|genre = [[Scilab]] Toolbox\n|license = [[GNU General Public License| GPL]]\n|website = [http://siptoolbox.sourceforge.net/ siptoolbox.sourceforge.net/]\n}}\n\n'''SIP''' is a toolbox for processing images in [[Scilab]]. SIP is meant to be a free, complete, and useful image toolbox for Scilab. Its goals include tasks such as filtering, blurring, edge detection, thresholding, histogram manipulation, segmentation, mathematical morphology, and color image processing.\n\nThough SIP is still in early development it can currently import and output image files in many formats including [[BMP file format|BMP]], [[JPEG]], [[GIF]], [[Portable Network Graphics|PNG]], [[TIFF]], [[X PixMap|XPM]], and [[PCX]]. SIP uses [[ImageMagick]] to accomplish this.\n\nSIP is licensed under the [[GPL]].\n\n== External links ==\n* [http://siptoolbox.sourceforge.net SIP homepage]\n* [http://www.scilab.org Scilab site]\n* [http://genie-optique.chez-alice.fr/SIP/index.html Unofficial SIP manual]\n* [http://labmacambira.sourceforge.net Lab Macambira]: the entity fostering the dev team behind SIP.\n\n[[Category:Computer vision software]]\n[[Category:Numerical programming languages]]\n[[Category:Freeware]]\n[[Category:Artificial intelligence]]\n\n\n\n{{graphics-software-stub}}"
    },
    {
      "title": "Speedcoding",
      "url": "https://en.wikipedia.org/wiki/Speedcoding",
      "text": "{{Infobox programming language\n| name                   = Speedcoding\n| logo                   =\n| caption                =\n| paradigm               = [[structured programming|structured]], [[Object-oriented programming|object-oriented]], [[Generic programming|generic]]\n| year                   = {{Start date and age|1953}}\n| designer               = [[John Backus]]\n| developer              = [[John Backus]] and [[IBM]]\n| latest release version = \n| latest release date    = \n| typing                 = [[strongly typed programming language|strong]], [[Type system|static]], [[manifest typing|manifest]]\n| implementations        = \n| dialects               =\n| influenced_by          = [[Assembly language]], [[machine code]]\n| influenced             = [[Fortran]], [[ALGOL 58]], [[BASIC]], [[C (programming language)|C]], [[PL/I]], [[PACT I]], [[MUMPS]], [[Ratfor]]\n| operating_system       =\n| license                =\n| website                =\n| file_ext =\n}}\n\n'''Speedcoding''' or '''Speedcode''' was the first [[high-level programming language]] created for an [[IBM]] computer.<ref name=\"ibmj\">{{cite journal |author= F. E. Allen |title=The History of Language Processor Technology in IBM |journal=IBM Journal of Research and Development |volume=25 |issue=5 |date= September 1981 |pages= 535–548 |doi= 10.1147/rd.255.0535 }}</ref> The language was developed by [[John Backus]] in 1953 for the [[IBM 701]] to support computation with [[floating point| floating point numbers]].<ref>{{cite book |title=Out of their Minds: The Lives and Discoveries of 15 Great Computer Scientists |last=Shasha |first=Dennis |author2=Cathy Lazere  |year=1998 |publisher=Springer-Verlag New York, Inc. |location=New York |isbn=0-387-98269-8 }}</ref> Here high level means symbolic and aiming for [[natural language]] expressivity as a goal as opposed to [[machine language|machine]] or hardware instruction oriented coding.\n\nThe idea arose from the difficulty of programming the [[IBM SSEC]] machine when Backus was hired to calculate astronomical positions in early 1950.<ref>{{cite web |title= Oral History of John Backus |author= Interviewed by Grady Booch |date= September 5, 2006 |work= Reference number: X3715.2007 |publisher= [[Computer History Museum]] |url= http://archive.computerhistory.org/resources/text/Oral_History/Backus_John/Backus_John_1.oral_history.2006.102657970.pdf |accessdate= April 23, 2011 }}</ref>\nThe speedcoding system was an interpreter and focused on ease of use at the expense of system resources. It provided pseudo-instructions for common mathematical functions: logarithms, exponentiation, and trigonometric operations. The resident software analyzed pseudo-instructions one by one and called the appropriate subroutine. Speedcoding was also the first implementation of decimal input/output operations. Although it substantially reduced the effort of writing many jobs, the running time of a program that was written with the help of Speedcoding was usually ten to twenty times that of machine code.<ref>Emerson W. Pugh, Lyle R. Johnson, John H. Palmer, ''IBM's 360 and early 370 systems'', MIT Press, 1991, {{ISBN|0-262-16123-0}}, p. 38</ref> The interpreter took 310 memory words, about 30% of the memory available on a 701.<ref name=\"ibmj\"/>\n\n==See also==\n*[[PACT (compiler)]]\n*[[Short Code (computer language)]]\n\n== References ==\n{{reflist}}\n\n== Further reading ==\n*[[John Backus|Backus, John]], [https://web.archive.org/web/20110813132221/http://www.softwarepreservation.org/projects/FORTRAN/paper/p4-backus.pdf \"The IBM 701 Speedcoding System\"], Journal of the ACM, Volume 1, Issue 1  (January 1954), pp.&nbsp;4–6,   \n*{{cite conference |last=Backus|first=John W.|author2=Harlan, Herrick |title=IBM 701 Speedcoding and Other Automatic-programming Systems|booktitle=Proc. Symp. on Automatic Programming for Digital Computer|location=Washington DC, The Office of Naval Research|date=May 1954|pages=106–113}}\n*{{cite book |last=Sammet|first=Jean E.|title=Programming Languages: History and Fundamentals|publisher=Prentice-Hall|date=1969}}\n\n[[Category:Procedural programming languages]]\n[[Category:Numerical programming languages]]\n[[Category:IBM software]]\n[[Category:Programming languages created in 1953]]\n\n\n{{Soft-eng-stub}}"
    },
    {
      "title": "Sysquake",
      "url": "https://en.wikipedia.org/wiki/Sysquake",
      "text": "{{notability|Products|date=December 2014}}\n{{Infobox Software \n| name = Sysquake\n| screenshot =<!-- Deleted image removed:  [[Image:Sysquake screenshot showing Chebyshev filter design.png|250px]] -->\n| caption = Sysquake 3.5 with the interactive filter application.\n| developer = Calerga Sarl\n| latest_release_version = 6.0.1\n| latest_release_date = January 2017\n|  operating_system = [[Microsoft Windows]], [[Mac OS X]], [[Linux]]\n| genre = [[List of numerical analysis software|Technical computing]]\n| license = [[Proprietary software|Proprietary]]\n| website = [http://www.calerga.com/products/Sysquake/ Sysquake product page]\n}}\n\n'''Sysquake''' is a [[Numerical analysis|numerical computing]] environment based on a [[programming language]]{{which|date=March 2019}} mostly-compatible with [[MATLAB]]. It offers facilities for [[interactive graphics]] which give insights into the problems being analyzed. It is used in teaching, research, and engineering.<ref name=\"bond graph modeling\">{{cite web | url = http://athena.ecs.csus.edu/~grandajj/me171/Granda_Book_Chapter.pdf | title = Automating the Process for Modeling and Simulation of Mechatronics Systems | work = Bond Graph Modeling of Engineering Systems | publisher = Springer New York | author = J. Granda | accessdate = 9 October 2015 |date=May 2011 }}</ref>\n\nSysquake supports two kinds of codes: [[Library (computer science)|libraries]] (collections of related functions which extend Sysquake capabilities), and ''SQ files'', applications with interactive graphics which can have their own menus. Sysquake Pro can also be extended with [[Plug-in (computing)|plugins]].<ref name=\"extension\">{{cite web | url = http://lpsolve.sourceforge.net/5.5/Sysquake.htm | title = Using lpsolve from Sysquake | accessdate = 9 October 2015 |date=April 2013 }}</ref>\n\n== Code ==\nSeveral applications share a large part of Sysquake code:\n\n; Sysquake Application Builder : program which creates stand-alone executable applications (bundled with Sysquake Pro)\n; Sysquake for LaTeX : Sysquake's language and graphics directly in [[LaTeX]] (package file and compiled application)\n\nLibraries are usually compatible with all these applications.\n\n== See also ==\n* [[List of numerical analysis software]]\n* [[Comparison of numerical analysis software]]\n\n==References==\n{{Reflist}}\n\n==External links==\n*[http://www.calerga.com/products/Sysquake/ The Sysquake product page at Calerga]\n\n[[Category:Array programming languages]]\n[[Category:Numerical programming languages]]\n[[Category:Statistical programming languages]]\n\n\n{{Science-software-stub}}"
    },
    {
      "title": "Theano (software)",
      "url": "https://en.wikipedia.org/wiki/Theano_%28software%29",
      "text": "{{Use dmy dates|date=August 2018}}\n{{Infobox software\n| name = Theano\n| logo = Theano_logo.svg\n| author = \n| developer = Montreal Institute for Learning Algorithms (MILA), [[University of Montreal]]\n| released = {{Start date and age|df=yes|2007}}\n| latest release version = 1.0.4<ref>{{Cite news |url = https://github.com/Theano/Theano/releases/tag/rel-1.0.4 |title = Theano Release |accessdate = 17 January 2019 |language = en-US }}</ref>\n| latest release date = {{Start date and age|df=yes|2019|01|16}}\n| repo = {{URL|https://github.com/Theano/Theano}}\n| programming language = [[Python (programming language)|Python]], [[CUDA]]\n| platform = [[Linux]], [[macOS]], [[Windows]]\n| genre = [[Machine learning]] [[Library (computing)|library]]\n| license = [[BSD licenses|The 3-Clause BSD License]]\n| website = {{URL|http://www.deeplearning.net/software/theano/}}\n}}\n\n'''Theano''' is a Python library and optimizing compiler for manipulating and evaluating mathematical expressions, especially matrix-valued ones.<ref>{{cite journal|last=Bergstra|first=J. |author2=O. Breuleux |author3=F. Bastien |author4=P. Lamblin |author5=R. Pascanu |author6=G. Desjardins |author7=J. Turian |author8=D. Warde-Farley |author9=Y. Bengio|title=Theano: A CPU and GPU Math Expression Compiler|journal=Proceedings of the Python for Scientific Computing Conference (SciPy) 2010|date=30 June 2010|url=http://www.iro.umontreal.ca/~lisa/pointeurs/theano_scipy2010.pdf}}</ref>\nIn Theano, computations are expressed using a [[NumPy]]-esque syntax and [[Compiler|compiled]] to run efficiently on either CPU or [[General-purpose computing on graphics processing units|GPU]] architectures.\n\nTheano is an [[Open-source model|open source]] project<ref>{{cite web|title=Github Repository|url=https://github.com/Theano/Theano/}}</ref> primarily developed by a Montreal Institute for Learning Algorithms (MILA) at the [[Université de Montréal]].<ref>{{cite web|url=http://deeplearning.net/|title=deeplearning.net}}</ref>\n\nOn 28 September 2017, Pascal Lamblin posted a message from [[Yoshua Bengio]], \nHead of MILA:  major development would cease after the 1.0 release due to competing offerings by strong industrial players.<ref>{{cite mailing list |url=https://groups.google.com/forum/#!topic/theano-users/7Poq8BZutbY |title=MILA and the future of Theano |date=28 September 2017 |accessdate=28 September 2017 |mailing-list=theano-users |last=Lamblin |first=Pascal }}</ref> Theano 1.0.0 was then released on 15 November 2017.<ref>{{cite web|url=http://deeplearning.net/software/theano/NEWS.html|title=Release Notes – Theano 1.0.0 documentation}}</ref>\n\n==Sample code==\nThe following code is the original Theano's example. It defines a computational graph with 2 scalars ''a'' and ''b'' of type ''double'' and an operation between them (addition) and then creates a python function ''f'' that does the actual computation.<ref name=\"LISA Lab\">{{cite web |title=Theano Documentation Release 1.0.0 |url=http://deeplearning.net/software/theano/theano.pdf |publisher=LISA lab, University of Montreal |accessdate=31 August 2018 |pages=22 |date=21 November 2017}}</ref>\n\n<syntaxhighlight lang=\"python\">\nimport theano\nfrom theano import tensor\n\n# declare two symbolic floating-point scalars\na = tensor.dscalar()\nb = tensor.dscalar()\n\n# create a simple expression\nc = a + b\n\n# convert the expression into a callable object that takes (a,b)\n# values as input and computes a value for c\nf = theano.function([a,b], c)\n\n# bind 1.5 to 'a', 2.5 to 'b', and evaluate 'c'\nassert 4.0 == f(1.5, 2.5)\n</syntaxhighlight><ref name=\"LISA Lab\"/>\n\n==See also==\n* [[Comparison of deep learning software]]\n* [[Differentiable programming]]\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{Official website|https://github.com/Theano/}} (GitHub)\n* [http://deeplearning.net/software/theano/ Theano] at Deep Learning, Université de Montréal\n\n{{Deep Learning Software}}\n\n[[Category:Array programming languages]]\n[[Category:Deep learning]]\n[[Category:Free science software]]\n[[Category:Numerical programming languages]]\n[[Category:Python scientific libraries]]\n[[Category:Software using the BSD license]]\n\n{{Compu-stub}}"
    },
    {
      "title": "Arithmetic IF",
      "url": "https://en.wikipedia.org/wiki/Arithmetic_IF",
      "text": "The '''arithmetic IF''' statement is a three-way arithmetic [[Conditional (programming)|conditional statement]], first seen in the first release of [[Fortran]] in 1957, and found in all later versions, and some other programming languages, such as [[FOCAL (programming language)|FOCAL]]. Unlike the [[Conditional (programming)|logical IF statements]] seen in other languages, the Fortran statement defines three different branches depending on whether the result of an expression is negative, zero, or positive, in said order, written as:\n\n<syntaxhighlight lang=\"fortran\">\n     IF (expression) negative,zero,positive\n</syntaxhighlight>\n\nWhile it originally was the only kind of IF statement provided in Fortran, the feature has been used less and less frequently after the [[Conditional (programming)|logical IF statements]] were introduced, and was finally labeled [[obsolescence|obsolescent]] in Fortran 90.\n\n==See also==\n* [[Sign function]]\n* [[Three-way comparison]]\n* [[Conditional (programming)]]\n\n==References==\n{{Reflist}}\n* [http://www.everything2.com/index.pl?node=arithmetic+IF arithmetic IF @ everything2.com]\n* [https://web.archive.org/web/20080221163807/http://www.liv.ac.uk/HPC/HTMLF90Course/HTMLF90CourseNotesnode34.html Modular Programming with Fortran 90  - Obsolescent Features]\n\n[[Category:Conditional constructs]]\n[[Category:Fortran]]\n\n\n{{computer-science-stub}}"
    },
    {
      "title": "John Backus",
      "url": "https://en.wikipedia.org/wiki/John_Backus",
      "text": "{{about|the computer scientist|the physicist|John Backus (acoustician)|the minister|John Chester Backus}}\n{{Use mdy dates|date=April 2012}}\n{{Infobox scientist\n| name                    = John Backus\n| image                   = File:John Backus 2.jpg\n| image_size              = \n| caption                 = Backus in December 1989\n|birth_name=John Warner Backus\n| birth_date              = {{Birth date|mf=yes|1924|12|3}}\n| birth_place             = [[Philadelphia|Philadelphia, Pennsylvania]]\n| death_date              = {{Death date and age|mf=yes|2007|3|17|1924|12|3}}\n| death_place             = [[Ashland, Oregon]]\n| residence               =\n| citizenship             =\n| nationality             =\n| ethnicity               =\n| field                   = [[Computer science]]\n| work_institution        = [[IBM Research - Almaden|IBM]]\n| alma_mater              = [[University of Virginia]]<br/>[[Columbia University]] (B.S. 1949, M.S. 1950)\n| doctoral_advisor        =\n| doctoral_students       =\n| known_for               = [[Speedcoding]]<br/>[[Fortran|FORTRAN]]<br/>[[ALGOL]]<br/>[[Backus–Naur form]]<br/>[[Function-level programming]]\n| author_abbreviation_bot =\n| author_abbreviation_zoo =\n| prizes                  = [[National Medal of Science]] <small>(1975)</small><br/>[[ACM Turing Award]] <small>(1977)</small><br/>[[Charles Stark Draper Prize]] <small>(1993)</small> \n| religion                =\n| footnotes               =\n}}\n\n'''John Warner Backus''' (December 3, 1924 – March 17, 2007) was an American [[computer scientist]]. He directed the team that invented and implemented [[Fortran|FORTRAN]], the first widely used  [[high-level programming language]], and was the inventor of the [[Backus–Naur form]] (BNF), a widely used notation to define [[formal language]] [[syntax]]. He later did research into the [[function-level programming]] paradigm, presenting his findings in his influential 1977 Turing Award lecture \"Can Programming Be Liberated from the von Neumann Style?\"\n\nThe [[Institute of Electrical and Electronics Engineers|IEEE]] awarded Backus the [[W. Wallace McDowell Award|W. W. McDowell Award]] in 1967 for the development of FORTRAN.<ref name=\"McDowell\">{{cite web| title=W. Wallace McDowell Award| url=http://www.computer.org/portal/site/ieeecs/menuitem.c5efb9b8ade9096b8a9ca0108bcd45f3/index.jsp?&pName=ieeecs_level1&path=ieeecs/about/awards&file=WallaceMcD_recipients.xml&xsl=generic.xsl&| accessdate=April 15, 2008| deadurl=no| archiveurl=https://web.archive.org/web/20070929133553/http://www.computer.org/portal/site/ieeecs/menuitem.c5efb9b8ade9096b8a9ca0108bcd45f3/index.jsp?&pName=ieeecs_level1&path=ieeecs%2Fabout%2Fawards&file=WallaceMcD_recipients.xml&xsl=generic.xsl&| archivedate=September 29, 2007| df=mdy-all}}</ref> He received the [[National Medal of Science]] in 1975<ref name=\"National Science Foundation\">{{cite web | title = The President's National Medal of Science: John Backus | publisher = National Science Foundation | url = https://www.nsf.gov/od/nms/recip_details.cfm?recip_id=25 | accessdate = March 21, 2007 | deadurl = no | archiveurl = https://web.archive.org/web/20070929111636/http://www.nsf.gov/od/nms/recip_details.cfm?recip_id=25 | archivedate = September 29, 2007 | df = mdy-all }}</ref> and the 1977 [[Turing Award|ACM Turing Award]] \"for profound, influential, and lasting contributions to the design of practical high-level programming systems, notably through his work on FORTRAN, and for publication of formal procedures for the specification of programming languages\".<ref name=\"ACM\">{{cite web | title = ACM Turing Award Citation: John Backus | publisher = [[Association for Computing Machinery]] | url = http://www.acm.org/awards/turing_citations/backus.html | accessdate =March 22, 2007 |archiveurl = https://web.archive.org/web/20070204114319/http://www.acm.org/awards/turing_citations/backus.html <!-- Bot retrieved archive --> |archivedate = February 4, 2007}}</ref>\n\nHe retired in 1991 and died at his home in [[Ashland, Oregon]] on March 17, 2007.<ref name=\"nytobit\"/>\n\n==Early life==\n\nBackus was born in [[Philadelphia]] and grew up in nearby [[Wilmington, Delaware]].<ref>{{cite web|url=http://www.thocp.net/biographies/backus_john.htm|title=John Backus|work=The History of Computing Project|accessdate=28 April 2016|deadurl=no|archiveurl=https://web.archive.org/web/20160427013234/http://www.thocp.net/biographies/backus_john.htm|archivedate=April 27, 2016|df=mdy-all}}</ref> He studied at [[The Hill School]] in [[Pottstown, Pennsylvania]], and was apparently not a diligent student.<ref name=\"nytobit\">{{cite news  | first = Steve | last = Lohr | title = John W. Backus, 82, Fortran Developer, Dies | url = https://www.nytimes.com/2007/03/20/business/20backus.html | work = New York Times | date = March 20, 2007 | accessdate =March 21, 2007 }}</ref> After entering the [[University of Virginia]] to study [[chemistry]], he quit and was conscripted into the [[United States Army|U.S. Army]].<ref name=\"nytobit\"/> He began medical training at [[Haverford College]]<ref>{{cite web | url = http://web.mit.edu/invent/iow/backus.html | title = Inventor of the Week Archive John Backus | date = February 2006 | accessdate = August 25, 2011 | deadurl = no | archiveurl = https://web.archive.org/web/20111026012905/http://web.mit.edu/invent/iow/backus.html | archivedate = October 26, 2011 | df = mdy-all }}</ref> and, during an internship at a hospital, he was diagnosed with a cranial [[bone tumor]], which was successfully removed; a plate was installed in his head, and he ended medical training after nine months and a subsequent operation to replace the plate with one of his own design.<ref>{{cite web | url = http://archive.computerhistory.org/resources/text/Oral_History/Backus_John/Backus_John_1.oral_history.2006.102657970.pdf | title = Oral History of John Backus | author = Grady Booch (interviewer) | date = September 25, 2006 | accessdate = August 17, 2009 | deadurl = no | archiveurl = http://archive.wikiwix.com/cache/20110826124340/http://archive.computerhistory.org/resources/text/Oral_History/Backus_John/Backus_John_1.oral_history.2006.102657970.pdf | archivedate = August 26, 2011 | df = mdy-all }}</ref>\n\n==Fortran==\n{{expand section|date=January 2017}}\nAfter moving to [[New York City]] he trained initially as a [[radio]] technician and became interested in mathematics. He graduated from [[Columbia University]] with a bachelor's degree in 1949 and a master's degree in 1950, both in mathematics,<ref>{{cite web|url=http://amturing.acm.org/award_winners/backus_0703524.cfm|title=John Backus - A.M. Turing Award Laureate|author=|date=|website=amturing.acm.org|accessdate=May 4, 2018|deadurl=no|archiveurl=https://web.archive.org/web/20180119064507/https://amturing.acm.org/award_winners/backus_0703524.cfm|archivedate=January 19, 2018|df=mdy-all}}</ref> and joined [[IBM]] in 1950. During his first three years, he worked on the [[IBM SSEC|Selective Sequence Electronic Calculator (SSEC)]]; his first major project was to write a program to calculate positions of the [[Moon]]. In 1953 Backus developed the language [[Speedcoding]], the first high-level language created for an IBM computer, to aid in software development for the [[IBM 701]] computer.<ref>{{cite journal|last=Allen|first=F.E.|title=The History of Language Processor Technology in IBM|journal=IBM Journal of Research and Development|volume=25|issue=5|date=September 1981|pages=535–548|doi=10.1147/rd.255.0535|url=http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5390587|deadurl=no|archiveurl=https://web.archive.org/web/20140523011449/http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5390587|archivedate=May 23, 2014|df=mdy-all}}</ref>\n\nProgramming was very difficult at this time, and in 1954 Backus assembled a team to define and develop [[Fortran]] for the [[IBM 704]] computer. [[Fortran]] was the first high-level programming language to be put to broad use.\n\n==Backus–Naur form==\n{{main|Backus–Naur form}}\nBackus served on the international committees that developed [[ALGOL 58]] and the very influential [[ALGOL 60]], which quickly became the ''de facto'' worldwide standard for publishing [[algorithm]]s. Backus developed the [[Backus–Naur form]] (BNF), in the [[UNESCO]] report on ALGOL 58. It was a formal notation able to describe any [[context-free]] programming language, and was important in the [[History of compiler writing|development of compilers]]. A few deviations from this approach were tried—notably in [[Lisp (programming language)|Lisp]] and [[APL (programming language)|APL]]—but by the 1970s, following the development of automated compiler generators such as [[yacc]], Backus–Naur context-free specifications for computer languages had become quite standard. This contribution helped Backus win the [[Turing Award]] in 1977.\n\n==Function-level programming==\nBackus later worked on a [[Function-level programming|function-level programming language]] known as [[FP programming language|FP]], which was described in his [[Turing Award]] lecture \"Can Programming be Liberated from the [[Von Neumann programming languages|von Neumann Style]]?\". Sometimes viewed as Backus's apology for creating Fortran, this paper did less to garner interest in the FP language than to spark research into [[functional programming]] in general. When Backus publicized the function-level style of programming, his message was mostly misunderstood<ref>Hudak, Paul (1989). \"Conception, Evolution, And Application Of Functional Programming Languages\". ACM Computing Surveys, Vol. 21, No. 3</ref> as being the same as traditional functional programming style languages.\n\nFP was strongly inspired by [[Kenneth E. Iverson]]'s [[APL programming language|APL]], even using a non-standard [[Character encoding|character set]]. An FP [[Interpreter (computing)|interpreter]] was distributed with the [[Berkeley Software Distribution|4.2BSD]] [[Unix]] operating system, but there were relatively few implementations of the language, most of which were used for educational purposes.\n\nBackus spent the latter part of his career developing [[FL programming language|FL]] (from \"Function Level\"), a successor to FP. FL was an internal IBM research project, and development of the language stopped when the project was finished. Only a few papers documenting it remain, and the source code of the compiler described in them was not made public. FL was at odds with functional programming languages being developed in the 1980s, most of which were based on the [[lambda calculus]] and [[static typing]] systems instead of, as in APL, the concatenation of primitive operations. Many of the language's ideas have now been implemented in versions of the [[J (programming language)|J programming language]], Iverson's successor to APL.\n\n==Awards and honors==\n*Named an [[IBM Fellow]] (1963)<ref name=\"IBM\">{{cite web | title=John Backus | work=IBM Archives | url=http://www-03.ibm.com/ibm/history/exhibits/builders/builders_backus.html | accessdate=March 21, 2007 | deadurl=no | archiveurl=http://archive.wikiwix.com/cache/20110826124341/http://www-03.ibm.com/ibm/history/exhibits/builders/builders_backus.html | archivedate=August 26, 2011 | df=mdy-all }}</ref>\n*Awarded [[McDowell Award|W.W. McDowell Award]] (1967)<ref name=\"McDowell\" />\n*Received [[National Medal of Science]] (1975)<ref name=\"National Science Foundation\" />\n*Awarded [[ACM Turing Award]] (1977)<ref name=\"ACM\" />\n*Fellow of the [[American Academy of Arts and Sciences]] (1985)<ref name=AAAS>{{cite web|title=Book of Members, 1780–2010: Chapter B|url=http://www.amacad.org/publications/BookofMembers/ChapterB.pdf|publisher=American Academy of Arts and Sciences|accessdate=April 28, 2011|deadurl=no|archiveurl=https://web.archive.org/web/20110725002054/http://www.amacad.org/publications/BookofMembers/ChapterB.pdf|archivedate=July 25, 2011|df=mdy-all}}</ref>\n*Awarded degree [[honoris causa]] from the [[Université Henri Poincaré]] (1989)<ref name=\"honoris causa\">{{cite web| title=John Backus| url=http://www.thocp.net/biographies/backus_john.htm| accessdate=April 15, 2008| deadurl=no| archiveurl=https://web.archive.org/web/20080514151702/http://www.thocp.net/biographies/backus_john.htm| archivedate=May 14, 2008| df=mdy-all}}</ref>\n*Awarded [[Charles Stark Draper Prize|Draper Prize]] (1993)<ref name=\"Draper\">{{cite web |url=http://www.nae.edu/nae/awardscom.nsf/weblinks/NAEW-4NHMN6?OpenDocument |title=Recipients of the Charles Stark Draper Prize |accessdate=March 26, 2007 |deadurl=yes |archiveurl=https://web.archive.org/web/20100302035959/http://www.nae.edu/nae/awardscom.nsf/weblinks/NAEW-4NHMN6?OpenDocument |archivedate=March 2, 2010 |df=mdy-all }}</ref>\n*Awarded [[Computer History Museum|Computer History Museum Fellow Award]] \"for his development of FORTRAN, contributions to computer systems theory and software project management.\" (1997)<ref>{{cite web| title=Fellow Awards 1997 Recipient John Backus| url=http://www.computerhistory.org/fellowawards/hall/bios/John,Backus/| accessdate=April 15, 2008| deadurl=yes| archiveurl=https://web.archive.org/web/20100709005030/http://www.computerhistory.org/fellowawards/hall/bios/John,Backus/| archivedate=July 9, 2010| df=mdy-all}}</ref>\n*[[Asteroid]] [[6830 Johnbackus]] named in his honor (June 1, 2007) {{JPL|6830|†}}\n\n==See also==\n* [[List of pioneers in computer science]]\n\n==References==\n{{reflist|colwidth=30em}}\n\n==External links==\n{{Wikiquote}}\n*[https://web.archive.org/web/20030605163136/http://www-gap.dcs.st-and.ac.uk/~history/Mathematicians/Backus.html Biography at School of Mathematics and Statistics University of St Andrews, Scotland]\n*[http://www.thocp.net/biographies/backus_john.htm Biography at The History of Computing Project]\n*[http://www.thocp.net/biographies/papers/backus_turingaward_lecture.pdf ''Can Programming Be Liberated From the von Neumann Style?'' 1977 Turing Award Lecture]\n* [https://web.archive.org/web/20050409030420/http://http.cs.berkeley.edu/~aiken/ftp/FL.ps The FL project] (Postscript file)\n* {{cite news |title=Obituary for John W. Backus |newspaper=New York Times |date=20 March 2007 |url=https://www.nytimes.com/2007/03/20/business/20backus.html}}\n* [http://www-03.ibm.com/ibm/history/exhibits/builders/builders_backus.html IBM Archives]\n* [https://web.archive.org/web/20070403083523/http://cui.unige.ch/db-research/Enseignement/analyseinfo/AboutBNF.html About BNF]\n* [http://www.computerhistory.org/fellowawards/index.php?id=70 Hall of Fellows] [[Computer History Museum]]\n* {{cite journal |first=Martin |last=Campbell-Kelly |title=Obituary: John Backus (1924–2007):Inventor of science's most widespread programming language, Fortran |journal=[[Nature (journal)|Nature]] |volume=446 |issue=7139 |page=998 |date=April 2007 |doi= 10.1038/446998a |url=http://www.nature.com/nature/journal/v446/n7139/full/446998a.html}}\n* [http://theory.stanford.edu/~aiken/other/backus.pdf Memorial delivered at the 2007 Conference on Programming Language Design and Implementation]\n\n{{Turing award}}\n{{Winners of the National Medal of Science|math-stat-comp}}\n{{Authority control}}\n\n{{DEFAULTSORT:Backus, John}}\n[[Category:1924 births]]\n[[Category:2007 deaths]]\n[[Category:20th-century American mathematicians]]\n[[Category:21st-century American mathematicians]]\n[[Category:American army personnel of World War II]]\n[[Category:Columbia University alumni]]\n[[Category:Draper Prize winners]]\n[[Category:Fellows of the American Academy of Arts and Sciences]]\n[[Category:Fortran]]\n[[Category:IBM Fellows]]\n[[Category:Members of the United States National Academy of Sciences]]\n[[Category:National Medal of Science laureates]]\n[[Category:IBM Research computer scientists]]\n[[Category:People from Ashland, Oregon]]\n[[Category:Mathematicians from Philadelphia]]\n[[Category:People from Wilmington, Delaware]]\n[[Category:Programming language designers]]\n[[Category:Programming language researchers]]\n[[Category:United States Army soldiers]]\n[[Category:Turing Award laureates]]\n[[Category:University of Virginia alumni]]\n[[Category:The Hill School alumni]]\n[[Category:Scientists from Delaware]]\n[[Category:Scientists from Oregon]]"
    },
    {
      "title": "Paul H. Cress",
      "url": "https://en.wikipedia.org/wiki/Paul_H._Cress",
      "text": "{{More citations needed|date=December 2009}}\n{{ Infobox scientist\n| name              = Paul H. Cress\n| image             = <!--(filename only)-->\n| image_size        = \n| caption           = \n| birth_date        = 1939\n| birth_place       = \n| death_date        = {{Death date|2004|10|20}}\n| death_place       = \n| nationality       = [[Canadians|Canadian]]\n| fields            = [[Computer science]]\n| workplaces        = [[University of Waterloo]]\n| alma_mater        = \n| doctoral_advisor  = \n| doctoral_students = \n| known_for         = \n| awards            = [[Grace Murray Hopper Award]]\n}}\n'''Paul H. Cress''' (1939–2004) was a [[Canadians|Canadian]] computer scientist.\n\nHe was a young lecturer in computer science at the [[University of Waterloo]] ([[Waterloo, Ontario]], Canada) when, starting in 1966, he and his colleague [[Paul Dirksen]] led a team of programmers developing a fast [[Fortran]] programming language [[compiler]] called [[WATFIV programming language|WATFOR]] (WATerloo FORtran), for the [[IBM System/360]] family of computers.  The /360 WATFOR project was initiated by Professor [[J. Wesley Graham]], following the successful implementation in 1965 of a WATFOR compiler for the [[IBM 7040]] computer.  An enhanced version of the /360 WATFOR compiler was called WATFIV, variously interpreted to mean \"WATerloo Fortran IV\" or \"WATFOR-plus-one\".\n\nWATFOR and WATFIV made Fortran programming accessible to university students and researchers and even  high schoolers, and largely established Waterloo's early reputation as a centre for software and Computer Science research. In 1972, Cress and Dirksen were joint winners of the [[Grace Murray Hopper Award]] from the [[Association for Computing Machinery]], \"For the creation of the WATFOR Compiler, the first member of a powerful new family of diagnostic and educational programming tools.\"<ref>{{cite web |title= 1972 – Paul H. Cress |work= Grace Murray Hopper Award |publisher= [[Association for Computing Machinery]] |url= http://awards.acm.org/citation.cfm?id=4117320&srt=all&aw=145&ao=GMHOPPER |accessdate= April 1, 2011 |archive-url= https://web.archive.org/web/20120504100839/http://awards.acm.org/citation.cfm?id=4117320&srt=all&aw=145&ao=GMHOPPER |archive-date= 2012-05-04 |dead-url= yes |df=  }}</ref>   \nCress died August 20, 2004, aged 65.\n\n==Publications==\n* {{cite book |author1= Paul Cress |author2= Paul Dirksen |author3=James Wesley Graham |title=FORTRAN IV with WATFOR |url=https://books.google.com/books?id=reEmAAAAMAAJ |year=1968 |publisher=Prentice-Hall}}\n* {{cite book |author=Paul Cress |title=Description of /360 WATFOR: a fortran-IV compiler |url=https://books.google.com/books?id=hxmnGwAACAAJ |year=1968 |publisher=Dept. of Applied Analysis and Computer Science, Computing Centre, University of Waterloo}}\n* {{cite book |author1= Paul Cress |author2= Paul Dirksen |author3=James Wesley Graham |title=FORTRAN IV with WATFOR and WATFIV |url=https://books.google.com/books?id=VeEmAAAAMAAJ |year=1970 |publisher=Prentice-Hall}}\n* {{cite book |author1=Paul Cress |author2= Paul Dirksen |author3=James Wesley Graham |title=Structured FORTRAN with WATFIV-S |url=https://books.google.com/books?id=LtKTQAAACAAJ |date=January 1, 1980 |publisher=Prentice-Hall |isbn=978-0-13-854752-3}}\n\n==References==\n{{Reflist}}\n{{Hopper winners}}\n\n{{DEFAULTSORT:Cress, Paul}}\n[[Category:1939 births]]\n[[Category:2004 deaths]]\n[[Category:Fortran]]\n[[Category:Grace Murray Hopper Award laureates]]\n[[Category:University of Waterloo faculty]]"
    },
    {
      "title": "Edison Design Group",
      "url": "https://en.wikipedia.org/wiki/Edison_Design_Group",
      "text": "{{Infobox company\n| name = Edison Design Group\n| logo = \n| type = Private\n| foundation = 1988 <ref name=\"ABOUTEDG\"/>\n| location = [[Scotch Plains, New Jersey]]\n| key_people = J. Stephen Adamczyk<br>John Spicer<br>Daveed Vandevoorde\n| industry = Software\n| products = Compiler front ends\n| revenue = \n| operating_income = \n| net_income =\n| num_employees = 5\n| slogan = \n| homepage = {{URL|www.edg.com}}\n}}\nThe '''Edison Design Group''' ('''EDG''') is a company that makes [[compiler]] [[front and back ends|front ends]] (preprocessing and parsing) for [[C++]], [[Java (programming language)|Java]], and [[Fortran]].<ref>{{cite book|title=C++ cookbook|year=2005|publisher=O'Reilly Media, Inc.|isbn=978-0-596-00761-4|page=7|url=https://books.google.com/books?id=XclHqTM37UIC&pg=PT23 |author=D. Ryan Stephens|accessdate=21 December 2010}}</ref><ref>{{cite news|last=Briand|first=Marc|title=Editor's Forum |url=http://www.drdobbs.com/184403431;jsessionid=5MNUUUW04KAXNQE1GHPSKH4ATMY32JVN|accessdate=21 December 2010|newspaper=[[Dr. Dobb's Journal]]|date=1 December 2007}}</ref> Their front ends are widely used in commercially available compilers and code analysis tools. Users include the [[Intel C++ compiler]],<ref>{{cite web |url=http://software.intel.com/en-us/articles/intel-c-compiler-for-windows-general-compatibility-with-other-products/#17 |title=General compatibility of the Intel C++ Compiler for Windows |publisher=Software.intel.com |accessdate=2012-05-04 |deadurl=yes |archiveurl=https://web.archive.org/web/20120207092727/http://software.intel.com/en-us/articles/intel-c-compiler-for-windows-general-compatibility-with-other-products/#17 |archivedate=2012-02-07 |df= }}</ref> [[Microsoft Visual C++]] ([[IntelliSense]]), [[SGI MIPSpro]], [[The Portland Group]], and [[Comeau C++]].<ref>{{cite web|title=Frequently Asked Questions: Who are your customers? |url=http://www.edg.com/faq/customers |publisher=Edison Design Group |accessdate=2018-03-11 |deadurl=no |archiveurl=https://web.archive.org/web/20170827073820/http://edg.com:80/faq |archivedate=2017-08-27 |df= }}</ref> They are widely known for having the first, and likely only, front end to implement the now-deprecated<ref>{{cite web|title=Using export keyword with templates |url=https://stackoverflow.com/questions/5416872/using-export-keyword-with-templates|accessdate=2018-03-11}}</ref> <code>[[Export (C++)|export]]</code> keyword of [[C++]].<ref>{{cite web|url= http://www.open-std.org/Jtc1/sc22/wg21/docs/papers/2003/n1426.pdf |title=Why We Can’t Afford Export }}&nbsp;{{small|(266&nbsp;KB)}}</ref><ref>{{cite book|title=C++ templates: the complete guide|year=2003|publisher=Addison-Wesley|isbn=978-0-201-73484-3|page=70|url=https://books.google.com/books?id=yQU-NlmQb_UC&pg=PA70 |author=David Vandevoorde|author2=Nicolai M. Josuttis|accessdate=21 December 2010}}</ref><ref>Daveed Vandevoorde (10 January 2002). [https://groups.google.com/group/comp.std.c++/msg/f7976e6672db4544 \"Implementability of export\"] comp.std.c++.</ref><ref>Daveed Vandevoorde (28 February 2002). [https://groups.google.com/group/comp.lang.c++.moderated/msg/08ca5b1f06f689db \"The export keyword\"]. comp.lang.c++.moderated.</ref>\n\nEDG was founded in 1988 in New Jersey by J. Stephen \"Steve\" Adamczyk, a 1974 B.S. graduate of the [[Massachusetts Institute of Technology]], a 1977 M.S. graduate of the [[Indiana University Bloomington]], and an experienced compiler engineer who had worked for [[Advanced Computer Techniques]] in New York City.<ref name=\"ABOUTEDG\">{{cite web|title=Company Background |url=http://www.edg.com/company/background |publisher=Edison Design Group |accessdate=2018-03-11 |deadurl=no |archiveurl=https://web.archive.org/web/20170906082205/http://www.edg.com/company/background|archivedate=2017-09-06 |df= }}</ref><ref>{{cite news|title=The On-line Mystique |url=https://pqasb.pqarchiver.com/washingtonpost/access/72226814.html?dids=72226814:72226814&FMT=ABS&FMTS=ABS:FT&type=current&date=Feb+27,+1994&author=Paula+Span&pub=The+Washington+Post+(pre-1997+Fulltext)&desc=THE+ON-LINE+MYSTIQUE&pqatl=google |accessdate=21 December 2010 |newspaper=[[Washington Post]]|date=27 February 1994|author=Paula Span|page=w.11}}</ref>\n\nOther employees include John Spicer and Daveed Vandevoorde.\n\n== See also ==\n* [[Dinkumware]], supplier of the standard library for several commercial C/C++ compilers.\n* [[Plum Hall]], certifies C/C++ compilers and standard libraries.\n\n== References ==\n{{reflist|2}}\n\n== Further reading ==\n* Adamczyk, J. Stephen. ''MU: A System Implementation Language for Microcomputers'', Indiana University, 1977\n\n==External links==\n* {{Official website|http://www.edg.com/ }}\n\n[[Category:Compilers]]\n[[Category:C++]]\n[[Category:Java (programming language)]]\n[[Category:Fortran]]\n\n\n{{ict-company-stub}}"
    },
    {
      "title": "Fortran 95 language features",
      "url": "https://en.wikipedia.org/wiki/Fortran_95_language_features",
      "text": "{{redirects here|Fortran language features|features of previous versions of the language|Fortran#History}}\nThis is an overview of '''Fortran 95 language features'''. Included are the additional features of TR-15581:Enhanced Data Type Facilities, that have been universally implemented. Old features that have been superseded by new ones are not described — few of those historic features are used in modern programs although most have been retained in the language to maintain [[backward compatibility]]. Although the current standard is Fortran 2008, even many of those features first introduced into Fortran 2003 are still being implemented.<ref>http://www.fortranplus.co.uk/fortran-information/</ref> The additional features of Fortran 2003 and Fortran 2008 are described by Metcalf, Reid and Cohen.<ref>{{cite web|url=http://ukcatalogue.oup.com/product/9780199601424.do |title=Modern Fortran Explained: Paperback: Michael Metcalf - Oxford University Press |publisher=Ukcatalogue.oup.com |date=2011-03-24 |accessdate=2013-09-02}}</ref><ref>{{cite web|url=http://www.oup.com/us/catalog/general/subject/ComputerScience/ProgrammingLanguageTheory/?view=usa&ci=9780199601424 |title=Modern Fortran Explained - Michael Metcalf; John Reid; Malcolm Cohen - Oxford University Press |publisher=Oup.com |date=2011-05-19 |accessdate=2013-09-02}}</ref>\n\n==Language elements==\nFortran is [[case-insensitive]]. The convention of writing Fortran keywords in upper case and all other names in lower case is adopted in this article; except, by way of contrast, in the input/output descriptions ([[#Data transfer|Data transfer]] and [[#Operations on external files|Operations on external files]]).\n\n===Basics===\nThe basic component of the Fortran language is its ''character set''. Its members are\n*the letters A ... Z and a ... z (which are equivalent outside a character context)\n*the numerals 0 ... 9\n*the underscore _\n*the special characters <code>=  :  +  blank  -  *  /  (  )  [  ]  ,  .  $  ' !  \"  %  &amp;  ;   &lt;  &gt;  ?</code>\n\n[[Token (parser)|Token]]s that have a syntactic meaning to the compiler are built from those components. There are six classes of tokens: \n{|\n|-\n!Label\n|<code>123</code>\n|-\n!Constant\n|<code>123.456789_long</code>\n|-\n!Keyword\n|<code>ALLOCATABLE</code>\n|-\n!Operator\n|<code>.add.</code>\n|-\n!Name\n|<code>solve_equation</code> (up to 31 characters, including _)\n|-\n!Separator\n|<code> /   (   )   (/   /)  [  ]   ,   =   =&gt;   :   ::   ;   %</code>\n|}\n\nFrom the tokens, [[statement (programming)|statement]]s are built. These can be coded using the new free ''source form'' which does not require positioning in a rigid column structure: \n<syntaxhighlight lang=fortran>\nFUNCTION string_concat(s1, s2)                             ! This is a comment\n   TYPE (string), INTENT(IN) :: s1, s2\n   TYPE (string) string_concat\n   string_concat%string_data = s1%string_data(1:s1%length) // &\n      s2%string_data(1:s2%length)                          ! This is a continuation\n   string_concat%length = s1%length + s2%length\nEND FUNCTION string_concat\n</syntaxhighlight>\n\nNote the trailing comments and the trailing continuation mark. There may be 39 continuation lines, and 132 characters per line. Blanks are significant. Where a token or character constant is split across two lines: \n<syntaxhighlight lang=fortran>\n               ...        start_of&\n        &_name\n               ...   'a very long &\n        &string'\n</syntaxhighlight>\na leading <code>&amp;</code> on the continued line is also required.\n\nAutomatic conversion of source form for existing programs can be carried out by [ftp://ftp.numerical.rl.ac.uk/pub/MRandC/convert.f90 convert.f90].\n\nIts options are\n*significant blank handling; \n*indentation; \n*CONTINUE replaced by END DO; \n*name added to subprogram END statement; and \n*INTEGER*2 etc. syntax converted.\n\n===Intrinsic data types===\nFortran has five ''intrinsic data types'': <code>INTEGER</code>, <code>REAL</code>, <code>COMPLEX</code>, <code>LOGICAL</code> and <code>CHARACTER</code>. Each of those types can be additionally characterized by a ''kind''. Kind, basically, defines internal representation of the type: for the three numeric types, it defines the precision and range, and for the other two, the specifics of storage representation. Thus, it is an abstract concept which models the limits of data types' representation; it is expressed as a member of a set of whole numbers (e.g. it may be {1, 2, 4, 8} for integers, denoting bytes of storage), but those values are not specified by the Standard and not portable. For every type, there is a ''default kind'', which is used if no kind is explicitly specified. For each intrinsic type, there is a corresponding form of ''literal constant''. The numeric types <code>INTEGER</code> and <code>REAL</code> can only be signed (there is no concept of sign for type <code>COMPLEX</code>).\n\n====Literal constants and kinds====\n\n=====INTEGER=====\nInteger literal constants of the default kind take the form\n<syntaxhighlight lang=fortran>\n1   0   -999   32767   +10\n</syntaxhighlight>\n\nKind can be defined as a named constant. If the desired range is ±10<sup>kind</sup>, the portable syntax for defining the appropriate kind, <code>two_bytes</code> is\n<syntaxhighlight lang=fortran>\nINTEGER, PARAMETER :: two_bytes = SELECTED_INT_KIND(4)\n</syntaxhighlight>\n\nthat allows subsequent definition of constants of the form\n<syntaxhighlight lang=fortran>\n-1234_two_bytes   +1_two_bytes\n</syntaxhighlight>\n\nHere, <code>two_bytes</code> is the kind type parameter; it can also be an explicit default integer literal constant, like \n<syntaxhighlight lang=fortran>\n-1234_2\n</syntaxhighlight>\nbut such use is non-portable.\n\nThe KIND function supplies the value of a kind type parameter: \n<syntaxhighlight lang=fortran>\nKIND(1)            KIND(1_two_bytes)\n</syntaxhighlight>\n\nand the <code>RANGE</code> function supplies the actual decimal range (so the user must make the actual mapping to bytes):\n<syntaxhighlight lang=fortran>\nRANGE(1_two_bytes)\n</syntaxhighlight>\n\nAlso, in [[#DATA statement|<code>DATA</code> (initialization) statements]], binary (B), octal (O) and hexadecimal (Z) constants may be used (often informally referred to as \"BOZ constants\"):\n<syntaxhighlight lang=fortran>\nB'01010101'   O'01234567'   Z'10fa'\n</syntaxhighlight>\n\n=====REAL=====\n\nThere are at least two real kinds—the default and one with greater precision (this replaces <syntaxhighlight lang=fortran inline>DOUBLE PRECISION</syntaxhighlight>). <syntaxhighlight lang=fortran inline>SELECTED_REAL_KIND</syntaxhighlight> functions returns the kind number for desired range and precision; for at least 9 decimal digits of precision and a range of 10<sup>−99</sup> to 10<sup>99</sup>, it can be specified as:\n<syntaxhighlight lang=fortran>\nINTEGER, PARAMETER :: long = SELECTED_REAL_KIND(9, 99)\n</syntaxhighlight>\nand literals subsequently specified as\n<syntaxhighlight lang=fortran>\n1.7_long\n</syntaxhighlight>\nAlso, there are the intrinsic functions \n<syntaxhighlight lang=fortran>\nKIND(1.7_long)   PRECISION(1.7_long)   RANGE(1.7_long)\n</syntaxhighlight>\nthat give in turn the kind type value, the actual precision (here at least 9), and the actual range (here at least 99).\n\n=====COMPLEX=====\n\n<code>COMPLEX</code> data type is built of two integer or real components: \n<syntaxhighlight lang=fortran>\n(1, 3.7_long)\n</syntaxhighlight>\n\n=====LOGICAL=====\n\nThere are only two basic values of logical constants: <code>.TRUE.</code> and <code>.FALSE.</code>. Here, there may also be different kinds. Logicals don't have their own kind inquiry functions, but use the kinds specified for <code>INTEGER</code>s; default kind of <code>LOGICAL</code> is the same as of INTEGER.\n<syntaxhighlight lang=fortran>\n.FALSE.   .true._one_byte\n</syntaxhighlight>\n\nand the <code>KIND</code> function operates as expected: \n<syntaxhighlight lang=fortran>\nKIND(.TRUE.)\n</syntaxhighlight>\n\n=====CHARACTER=====\n\nThe forms of literal constants for <code>CHARACTER</code> data type are\n<syntaxhighlight lang=fortran>\n'A string'   \"Another\"   'A \"quote\"'   '''''''\n</syntaxhighlight>\n\n(the last being an empty string). Different kinds are allowed (for example, to distinguish [[ASCII]] and [[UNICODE]] strings), but not widely supported by compilers. Again, the kind value is given by the <code>KIND</code> function: \n<syntaxhighlight lang=fortran>\nKIND('ASCII')\n</syntaxhighlight>\n\n====Number model and intrinsic functions====\nThe numeric types are based on number models with associated inquiry functions (whose values are independent of the values of their arguments; arguments are used only to provide kind). These functions are important for portable numerical software:\n\n{|class=wikitable\n|-\n|<code>DIGITS(X)</code>||Number of significant digits\n|-\n|<code>EPSILON(X)</code>||Almost negligible compared to one (real)\n|-\n|<code>HUGE(X)</code>||Largest number\n|-\n|<code>MAXEXPONENT(X)</code>||Maximum model exponent (real)\n|-\n|<code>MINEXPONENT(X)</code>||Minimum model exponent (real)\n|-\n|<code>PRECISION(X)</code>||Decimal precision (real, complex)\n|-\n|<code>RADIX(X)</code>||Base of the model\n|-\n|<code>RANGE(X)</code>||Decimal exponent range\n|-\n|<code>TINY(X)</code>||Smallest positive number (real)\n|}\n\n===Scalar variables===\n\nScalar [[Variable (programming)|variables]] corresponding to the five intrinsic types are specified as follows:\n<syntaxhighlight lang=fortran>\nINTEGER(KIND=2) :: i\nREAL(KIND=long) :: a\nCOMPLEX         :: current\nLOGICAL         :: Pravda\nCHARACTER(LEN=20) :: word\nCHARACTER(LEN=2, KIND=Kanji) :: kanji_word\n</syntaxhighlight>\n\nwhere the optional <code>KIND</code> parameter specifies a non-default kind, and the <code>::</code> notation delimits the type and attributes from variable name(s) and their optional initial values, allowing full variable specification and initialization to be typed in one statement (in previous standards, attributes and initializers had to be declared in several statements). While it is not required in above examples (as there are no additional attributes and initialization), most Fortran-90 programmers acquire the habit to use it everywhere.\n\n<syntaxhighlight lang=fortran inline>LEN=</syntaxhighlight> specifier is applicable only to <code>CHARACTER</code>s and specifies the string length (replacing the older <code>*len</code> form). \nThe explicit <code>KIND=</code> and <code>LEN=</code> specifiers are optional:\n<syntaxhighlight lang=fortran>\nCHARACTER(2, Kanji) :: kanji_word\n</syntaxhighlight>\nworks just as well.\n\nThere are some other interesting character features. Just as a substring as in \n<syntaxhighlight lang=fortran>\nCHARACTER(80) :: line   \n... = line(i:i)                     ! substring\n</syntaxhighlight>\nwas previously possible, so now is the substring\n<syntaxhighlight lang=fortran>\n'0123456789'(i:i)\n</syntaxhighlight>\n\nAlso, zero-length strings are allowed: \n<syntaxhighlight lang=fortran>\nline(i:i-1)       ! zero-length string\n</syntaxhighlight>\nFinally, there is a set of intrinsic character functions, examples being\n{|class=wikitable\n|-\n| style=\"width:50%;\"|<code>ACHAR</code>||<code>IACHAR</code> (for ASCII set)\n|-\n|<code>ADJUSTL</code>||<code>ADJUSTR</code>\n|-\n|<code>LEN_TRIM</code>||<code>INDEX(s1, s2, BACK=.TRUE.)</code>\n|-\n|<code>REPEAT</code>||<code>SCAN</code>(for one of a set)\n|-\n|<code>TRIM</code>||<code>VERIFY</code>(for all of a set)\n|}\n\n===Derived data types===\nFor derived data types, the form of the type must be defined first: \n<syntaxhighlight lang=fortran>\nTYPE person\n   CHARACTER(10) name\n   REAL          age\nEND TYPE person\n</syntaxhighlight>\n\nand then, variables of that type can be defined: \n<syntaxhighlight lang=fortran>\nTYPE(person) you, me\n</syntaxhighlight>\n\nTo select components of a derived type, <code>%</code> qualifier is used:  \n<syntaxhighlight lang=fortran>\nyou%age\n</syntaxhighlight>\n\nLiteral constants of derived types have the form ''<code>TypeName(1stComponentLiteral, 2ndComponentLiteral, ...)</code>'':\n<syntaxhighlight lang=fortran>\nyou = person('Smith', 23.5)\n</syntaxhighlight>\nwhich is known as a ''structure constructor''. Definitions may refer to a previously defined type: \n<syntaxhighlight lang=fortran>\nTYPE point\n   REAL x, y\nEND TYPE point\nTYPE triangle\n   TYPE(point) a, b, c\nEND TYPE triangle\n</syntaxhighlight>\n\nand for a variable of type triangle, as in \n<syntaxhighlight lang=fortran>\nTYPE(triangle) t\n</syntaxhighlight>\neach component of type <code>point</code> is accessed as\n<syntaxhighlight lang=fortran>\nt%a   t%b   t%c\n</syntaxhighlight>\nwhich, in turn, have ultimate components of type real: \n<syntaxhighlight lang=fortran>\nt%a%x   t%a%y   t%b%x   etc.\n</syntaxhighlight>\n(Note that the <code>%</code> qualifier was chosen rather than dot (<code>.</code>) because of potential ambiguity with operator notation, like <code>.OR.</code>).\n\n===Implicit and explicit typing===\nUnless specified otherwise, all variables starting with letters I, J, K, L, M and N are default <code>INTEGER</code>s, and all others are default <code>REAL</code>; other data types must be explicitly declared. This is known as ''implicit typing'' and is a heritage of early FORTRAN days. Those defaults can be overridden by ''<code>IMPLICIT TypeName (CharacterRange)</code>'' statements, like:\n<syntaxhighlight lang=fortran>\nIMPLICIT COMPLEX(Z)\nIMPLICIT CHARACTER(A-B)\nIMPLICIT REAL(C-H,N-Y)\n</syntaxhighlight>\nHowever, it is a good practice to explicitly type all variables, and this can be forced by inserting the statement <syntaxhighlight lang=fortran inline>IMPLICIT NONE</syntaxhighlight>\nat the beginning of each program unit.\n\n===Arrays===\nArrays are considered to be variables in their own right. Every array is characterized by its [[type (computer programming)|type]], [[rank (computer programming)|rank]], and ''shape'' (which defines the extents of each dimension). Bounds of each dimension are by default 1 and ''size'', but arbitrary bounds can be explicitly specified. <code>DIMENSION</code> keyword is optional and considered an attribute; if omitted, the array shape must be specified after array-variable name. For example,\n<syntaxhighlight lang=fortran>\nREAL:: a(10)\nINTEGER, DIMENSION(0:100, -50:50) :: map\n</syntaxhighlight>\ndeclares two arrays, rank-1 and rank-2, whose elements are in [[column-major order]]. Elements are, for example,\n<syntaxhighlight lang=fortran>\na(1)  a(i*j)\n</syntaxhighlight>\nand are scalars. The subscripts may be any scalar integer expression.\n\n''Sections'' are parts of the array variables, and are arrays themselves:\n<syntaxhighlight lang=fortran>\na(i:j)               ! rank one\nmap(i:j, k:l:m)      ! rank two\na(map(i, k:l))       ! vector subscript\na(3:2)               ! zero length\n</syntaxhighlight>\nWhole arrays and array sections are array-valued objects. Array-valued constants (constructors) are available, enclosed in <code>(/ ... /)</code>: \n<syntaxhighlight lang=fortran>\n(/ 1, 2, 3, 4 /)\n(/ ( (/ 1, 2, 3 /), i = 1, 4) /)\n(/ (i, i = 1, 9, 2) /)\n(/ (0, i = 1, 100) /)\n(/ (0.1*i, i = 1, 10) /)\n</syntaxhighlight>\nmaking use of an implied-DO loop notation. Fortran 2003 allows the use of brackets: <code>\n[1, 2, 3, 4]</code> and <code>[([1,2,3], i=1,4)]</code>\ninstead of the first two examples above, and many compilers support this now.\nA derived data type may, of course, contain array components: \n<syntaxhighlight lang=fortran>\nTYPE triplet\n   REAL, DIMENSION(3) :: vertex\nEND TYPE triplet\nTYPE(triplet), DIMENSION(4) :: t\n</syntaxhighlight>\nso that \n* <syntaxhighlight lang=fortran inline>t(2)</syntaxhighlight>           is a scalar (a structure)\n* <syntaxhighlight lang=fortran inline>t(2)%vertex</syntaxhighlight>    is an array component of a scalar\n\n===Data initialization===\nVariables can be given initial values as specified in a specification statement:\n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(3) :: a = (/ 0.1, 0.2, 0.3 /)\n</syntaxhighlight>\nand a default initial value can be given to the component of a derived data type:\n<syntaxhighlight lang=fortran>\nTYPE triplet\n   REAL, DIMENSION(3) :: vertex = 0.0\nEND TYPE triplet\n</syntaxhighlight>\nWhen local variables are initialized within a procedure they implicitly acquire the SAVE attribute:\n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(3) :: point = (/ 0.0, 1.0, -1.0 /)\n</syntaxhighlight>\nThis declaration is equivalent to\n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(3), SAVE :: point = (/ 0.0, 1.0, -1.0 /)\n</syntaxhighlight>\nfor local variables within a subroutine or function.  The SAVE attribute causes local variables to retain their value after a procedure call and then to initialize the variable to the saved value upon returning to the procedure.\n\n====PARAMETER attribute====\nA named constant can be specified directly by adding the <code>PARAMETER</code> attribute and the constant values to a type statement:\n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(3), PARAMETER :: field = (/ 0., 1., 2. /)\nTYPE(triplet), PARAMETER :: t = triplet( (/ 0., 0., 0. /) )\n</syntaxhighlight>\n\n====DATA statement====\nThe <code>DATA</code> statement can be used for scalars and also for arrays and variables of derived type. It is also the only way to initialise just parts of such objects, as well as to initialise to binary, octal or hexadecimal values: \n<syntaxhighlight lang=fortran>\nTYPE(triplet) :: t1, t2\nDATA t1/triplet( (/ 0., 1., 2. /) )/, t2%vertex(1)/123./\nDATA array(1:64) / 64*0/\nDATA i, j, k/ B'01010101', O'77', Z'ff'/\n</syntaxhighlight>\n\n====Initialization expressions====\nThe values used in <code>DATA</code> and <code>PARAMETER</code> statements, or with these attributes, are constant expressions that may include references to: array and structure constructors, elemental intrinsic functions with integer or character arguments and results, and the six transformational functions <code>REPEAT, SELECTED_INT_KIND, TRIM, SELECTED_REAL_KIND, RESHAPE</code> and <code>TRANSFER</code> (see [[#Intrinsic procedures|Intrinsic procedures]]): \n<syntaxhighlight lang=fortran>\nINTEGER, PARAMETER :: long = SELECTED_REAL_KIND(12),   &\n                      array(3) = (/ 1, 2, 3 /)\n</syntaxhighlight>\n\n===Specification expressions===\nIt is possible to specify details of variables \nusing any non-constant, scalar, integer expression that may also include inquiry \nfunction references:\n<syntaxhighlight lang=fortran>\nSUBROUTINE s(b, m, c)\n   USE mod                                 ! contains a\n   REAL, DIMENSION(:, :)             :: b\n   REAL, DIMENSION(UBOUND(b, 1) + 5) :: x\n   INTEGER                           :: m\n   CHARACTER(LEN=*)                  :: c\n   CHARACTER(LEN= m + LEN(c))        :: cc\n   REAL (SELECTED_REAL_KIND(2*PRECISION(a))) :: z\n</syntaxhighlight>\n\n==Expressions and assignments==\n\n===Scalar numeric===\nThe usual arithmetic operators are available — <code>+, -, *, /, **</code> (given here in increasing order of precedence).\n\nParentheses are used to indicate the order of evaluation where necessary:\n<syntaxhighlight lang=fortran>\na*b + c     ! * first\na*(b + c)   ! + first\n</syntaxhighlight>\nThe rules for ''scalar numeric'' expressions and assignments accommodate the non-default kinds. Thus, the mixed-mode numeric expression and assignment rules incorporate different kind type parameters in an expected way: \n<syntaxhighlight lang=fortran>\nreal2 = integer0 + real1\n</syntaxhighlight>\n\nconverts <code>integer0</code> to a real value of the same kind as <code>real1</code>; the result is of same kind, and is converted to the kind of <code>real2</code> for assignment.\n\nThese functions are available for controlled [[rounding]] of real numbers to integers:\n*<code>NINT</code>: round to nearest integer, return integer result\n*<code>ANINT</code>: round to nearest integer, return real result\n*<code>INT</code>: truncate (round towards zero), return integer result\n*<code>AINT</code>: truncate (round towards zero), return real result\n*<code>CEILING</code>: smallest integral value not less than argument (round up) (Fortran-90)\n*<code>FLOOR</code>: largest integral value not greater than argument (round down) (Fortran-90)\n\n===Scalar relational operations===\nFor ''scalar relational'' operations of numeric types, there is a set of built-in operators: \n <    <=    ==   /=   >   >=\n .LT. .LE. .EQ. .NE. .GT. .GE.\n(the forms above are new to Fortran-90, and older equivalent forms are given below them). Example expressions:\n<syntaxhighlight lang=fortran>\na < b .AND. i /= j      ! for numeric variables\nflag = a == b           ! for logical variable flags\n</syntaxhighlight>\n\n===Scalar characters===\nIn the case of ''scalar characters'' and given <syntaxhighlight lang=fortran inline>CHARACTER(8) result</syntaxhighlight>\n\nit is legal to write \n<syntaxhighlight lang=fortran>\nresult(3:5) = result(1:3)    ! overlap allowed\nresult(3:3) = result(3:2)    ! no assignment of null string\n</syntaxhighlight>\n\nConcatenation is performed by the operator '//'.\n<syntaxhighlight lang=fortran>\nresult = 'abcde'//'123'\nfilename = result//'.dat'\n</syntaxhighlight>\n\n===Derived-data types===\nNo built-in operations (except assignment, defined on component-by component basis) exist between ''derived data types'' mutually or with intrinsic types. The meaning of existing or user-specified operators can be (re)defined though:\n<syntaxhighlight lang=fortran>\nTYPE string80\n   INTEGER       length\n   CHARACTER(80) value\nEND TYPE string80\nCHARACTER::    char1, char2, char3\nTYPE(string80):: str1,  str2,  str3\n</syntaxhighlight>\nwe can write \n<syntaxhighlight lang=fortran>\nstr3  = str1//str2       ! must define operation\nstr3  = str1.concat.str2 ! must define operation\nchar3 = char2//char3     ! intrinsic operator only\nstr3  = char1            ! must define assignment\n</syntaxhighlight>\nNotice the \"[[Operator overloading|overloaded]]\" use of the intrinsic symbol <code>//</code> and the named operator, <code>.concat.</code> . A difference between the two cases is that, for an intrinsic operator token, the usual precedence rules apply, whereas for named operators, precedence is the highest as a unary operator or the lowest as a binary one. In \n<syntaxhighlight lang=fortran>\nvector3 = matrix    *    vector1  + vector2\nvector3 =(matrix .times. vector1) + vector2\n</syntaxhighlight>\nthe two expressions are equivalent only if appropriate parentheses are \nadded as shown. In each case there must be defined, in a [[#Modules|module]], procedures defining the operator and assignment, and corresponding operator-procedure association, as follows:\n<syntaxhighlight lang=fortran>\nINTERFACE OPERATOR(//) !Overloads the // operator as invoking string_concat procedure\n  MODULE PROCEDURE string_concat\nEND INTERFACE\n</syntaxhighlight>\nThe string concatenation function is a more elaborated version of that shown already in [[#Basics|Basics]].  Note that in order to handle the error condition that arises when the two strings together exceed the preset 80-character limit, it would be safer to use a subroutine to perform the concatenation (in this case operator-overloading would not be applicable.)\n<syntaxhighlight lang=fortran>\nMODULE string_type\n   IMPLICIT NONE\n   TYPE string80\n      INTEGER length\n      CHARACTER(LEN=80)   :: string_data\n   END TYPE string80\n   INTERFACE ASSIGNMENT(=)\n      MODULE PROCEDURE c_to_s_assign, s_to_c_assign\n   END INTERFACE\n   INTERFACE OPERATOR(//)\n      MODULE PROCEDURE string_concat\n   END INTERFACE\nCONTAINS\n   SUBROUTINE c_to_s_assign(s, c)\n      TYPE (string80), INTENT(OUT)    :: s\n      CHARACTER(LEN=*), INTENT(IN)  :: c\n      s%string_data = c\n      s%length = LEN(c)\n   END SUBROUTINE c_to_s_assign\n   SUBROUTINE s_to_c_assign(c, s)\n      TYPE (string80), INTENT(IN)     :: s\n      CHARACTER(LEN=*), INTENT(OUT) :: c\n      c = s%string_data(1:s%length)\n   END SUBROUTINE s_to_c_assign\n   TYPE(string80) FUNCTION string_concat(s1, s2)\n      TYPE(string80), INTENT(IN) :: s1, s2\n      TYPE(string80) :: s\n      INTEGER :: n1, n2\n      CHARACTER(160) :: ctot\n      n1 = LEN_TRIM(s1%string_data)\n      n2 = LEN_TRIM(s2%string_data)\n      IF (n1+n2 <= 80) then\n         s%string_data = s1%string_data(1:n1)//s2%string_data(1:n2)\n      ELSE  ! This is an error condition which should be handled - for now just truncate\n         ctot = s1%string_data(1:n1)//s2%string_data(1:n2)\n         s%string_data = ctot(1:80)\n      END IF\n      s%length = LEN_TRIM(s%string_data)\n      string_concat = s\n   END FUNCTION string_concat\nEND MODULE string_type\n\nPROGRAM main\n   USE string_type\n   TYPE(string80) :: s1, s2, s3\n   CALL c_to_s_assign(s1,'My name is')\n   CALL c_to_s_assign(s2,' Linus Torvalds')\n   s3 = s1//s2\n   WRITE(*,*) 'Result: ',s3%string_data\n   WRITE(*,*) 'Length: ',s3%length\nEND PROGRAM\n</syntaxhighlight>\n\nDefined operators such as these are required for the expressions that are \nallowed also in structure constructors (see [[#Derived-data types|Derived-data types]]): \n<syntaxhighlight lang=fortran>\nstr1 = string(2, char1//char2)  ! structure constructor\n</syntaxhighlight>\n\n===Arrays===\nIn the case of arrays then, as long as they are of the same shape (conformable), operations and assignments are extended in an obvious way, on an element-by-element basis. For example, given declarations of\n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(10, 20) :: a, b, c\nREAL, DIMENSION(5)      :: v, w\nLOGICAL                    flag(10, 20)\n</syntaxhighlight>\nit can be written:\n<syntaxhighlight lang=fortran>\na = b                                       ! whole array assignment\nc = a/b                                     ! whole array division and assignment\nc = 0.                                      ! whole array assignment of scalar value\nw = v + 1.                                  ! whole array addition to scalar value\nw = 5/v + a(1:5, 5)                         ! array division, and addition to section\nflag = a==b                                 ! whole array relational test and assignment\nc(1:8, 5:10) = a(2:9, 5:10) + b(1:8, 15:20) ! array section addition and assignment\nv(2:5) = v(1:4)                             ! overlapping section assignment\n</syntaxhighlight>\nThe order of expression evaluation is not specified in order to allow for optimization on parallel and vector machines. Of course, any operators for arrays of derived type must be defined.\n\nSome real intrinsic functions that are useful for numeric \ncomputations are\n<syntaxhighlight lang=fortran>\nCEILING         FLOOR         MODULO (also integer)\nEXPONENT        FRACTION\nNEAREST         RRSPACING     SPACING\nSCALE           SET_EXPONENT\n</syntaxhighlight>\nThese are array valued for array arguments (elemental), like all [[FORTRAN 77]] functions (except LEN):\n<syntaxhighlight lang=fortran>\nINT             REAL          CMPLX\nAINT            ANINT         NINT\nABS             MOD           SIGN\nDIM             MAX           MIN\n\nSQRT            EXP           LOG\nLOG10           SIN           COS\nTAN             ASIN          ACOS\nATAN            ATAN2\nSINH            COSH          TANH\n\nAIMAG           CONJG\n\nLGE             LGT           LLE\nLLT             ICHAR         CHAR\nINDEX   \n</syntaxhighlight>\n(the last seven are for characters).\n\n==Control statements==\n\n===Branching and conditions===\n\nThe simple <code>GO TO</code> ''label'' exists, but is usually avoided &mdash; in most cases, a more specific branching construct will accomplish the same logic with more clarity.\n\nThe simple conditional test is the <code>IF</code> statement: <syntaxhighlight lang=fortran inline>IF (a > b) x = y</syntaxhighlight>\n\nA full-blown <code>IF</code> construct is illustrated by\n<syntaxhighlight lang=fortran>\nIF (i < 0) THEN\n   IF (j < 0) THEN\n      x = 0.\n   ELSE\n      z = 0.\n   END IF\nELSE IF (k < 0) THEN\n   z = 1.\nELSE\n   x = 1.\nEND IF\n</syntaxhighlight>\n\n===CASE construct===\n\nThe <code>CASE</code> construct is a replacement for the computed <code>GOTO</code>, but is better \nstructured and does not require the use of statement labels: \n<syntaxhighlight lang=fortran>\nSELECT CASE (number)       ! number of type integer\nCASE (:-1)                 ! all values below 0\n   n_sign = -1\nCASE (0)                   ! only 0\n   n_sign = 0\nCASE (1:)                  ! all values above 0\n   n_sign = 1\nEND SELECT\n</syntaxhighlight>\nEach <code>CASE</code> selector list may contain a list and/or range of integers, \ncharacter or logical constants, whose values may not overlap within or between \nselectors: \n<syntaxhighlight lang=fortran>\nCASE (1, 2, 7, 10:17, 23)\n</syntaxhighlight>\nA default is available: \n<syntaxhighlight lang=fortran>\nCASE DEFAULT\n</syntaxhighlight>\nThere is only one evaluation, and only one match.\n\n===DO construct===\n\nA simplified but sufficient form of the <code>DO</code> construct is illustrated by \n<syntaxhighlight lang=fortran>\nouter: DO\ninner:    DO i = j, k, l      ! from j to k in steps of l (l is optional)\n             :\n             IF (...) CYCLE\n             :\n             IF (...) EXIT outer\n             :\n          END DO inner\n       END DO outer\n</syntaxhighlight>\nwhere we note that loops may be optionally named so that any EXIT or CYCLE \nstatement may specify which loop is meant.\n\nMany, but not all, simple loops can be replaced by array expressions and \nassignments, or by new intrinsic functions. For instance \n<syntaxhighlight lang=fortran>\ntot = 0.\nDO i = m, n\n   tot = tot + a(i)\nEND DO\n</syntaxhighlight>\nbecomes simply <syntaxhighlight lang=fortran inline>tot = SUM( a(m:n) )</syntaxhighlight>\n\n==Program units and procedures==\n\n===Definitions===\n\nIn order to discuss this topic we need some definitions. In logical terms, an \nexecutable program consists of one ''main program'' and zero or more \n''subprograms'' (or ''procedures'') - these do something. \nSubprograms are either ''functions ''or ''subroutines'', which are \neither ''external, internal'' or ''module'' subroutines. (External \nsubroutines are what we knew from FORTRAN 77.)\n\nFrom an organizational point of view, however, a complete program consists of \n''program units''. These are either ''main programs, external \nsubprograms'' or ''modules'' and can be separately compiled.\n\nAn example of a main (and complete) program is\n<syntaxhighlight lang=fortran>\nPROGRAM test\n   PRINT *, 'Hello world!'\nEND PROGRAM test\n</syntaxhighlight>\nAn example of a main program and an external subprogram, forming an executable program, is\n<syntaxhighlight lang=fortran>\nPROGRAM test\n   CALL print_message\nEND PROGRAM test\nSUBROUTINE print_message\n   PRINT *, 'Hello world!'\nEND SUBROUTINE print_message\n</syntaxhighlight>\nThe form of a function is\n<syntaxhighlight lang=fortran>\nFUNCTION name(arg1, arg2) ! zero or more arguments\n   :                     \n   name = ...\n   :\nEND FUNCTION name\n</syntaxhighlight>\nThe form of reference of a function is <syntaxhighlight lang=fortran inline>x = name(a, b)</syntaxhighlight>\n\n===Internal procedures===\n\nAn internal subprogram is one ''contained'' in another (at a maximum \nof one level of nesting) and provides a replacement for the statement function: \n<syntaxhighlight lang=fortran>\nSUBROUTINE outer\n   REAL x, y\n   :\nCONTAINS\n   SUBROUTINE inner\n      REAL y\n      y = x + 1.\n      :\n   END SUBROUTINE inner     ! SUBROUTINE mandatory\nEND SUBROUTINE outer\n</syntaxhighlight>\nWe say that <code>outer</code> is the ''host'' of <code>inner</code>, and that <code>inner</code> obtains \naccess to entities in <code>outer</code> by ''host association'' (e.g. to <code>x</code>), whereas \n<code>y</code> is a ''local'' variable to <code>inner</code>.\n\nThe ''scope'' of a named entity is a ''scoping unit'', here \n<code>outer</code> less <code>inner</code>, and <code>inner</code>.\n\nThe names of program units and external procedures are ''global'', and \nthe names of implied-DO variables have a scope of the statement that contains \nthem.\n\n===Modules===\n\nModules are used to package\n\n* global data (replaces COMMON and BLOCK DATA from Fortran 77); \n* type definitions (themselves a scoping unit); \n* subprograms (which among other things replaces the use of ENTRY from Fortran 77); \n* interface blocks (another scoping unit, see [[#Interface blocks|Interface blocks]]); \n* namelist groups (see any textbook).\n\nAn example of a module \ncontaining a type definition, interface block and function subprogram is\n<syntaxhighlight lang=fortran>\nMODULE interval_arithmetic\n   TYPE interval\n      REAL lower, upper\n   END TYPE interval\n   INTERFACE OPERATOR(+)\n       MODULE PROCEDURE add_intervals\n   END INTERFACE\n   :\nCONTAINS\n   FUNCTION add_intervals(a,b)\n      TYPE(interval), INTENT(IN) :: a, b\n      TYPE(interval) add_intervals\n      add_intervals%lower = a%lower + b%lower\n      add_intervals%upper = a%upper + b%upper\n   END FUNCTION add_intervals             ! FUNCTION mandatory\n   :\nEND MODULE interval_arithmetic\n</syntaxhighlight>\nand the simple statement \n<syntaxhighlight lang=fortran>     \nUSE interval_arithmetic\n</syntaxhighlight>\nprovides ''use association'' to all the module's entities. Module \nsubprograms may, in turn, contain internal subprograms.\n\n===Controlling accessibility===\nThe <code>PUBLIC</code> and <code>PRIVATE</code> attributes are used in specifications in \nmodules to limit the scope of entities. The attribute form is \n<syntaxhighlight lang=fortran>\nREAL, PUBLIC     :: x, y, z           ! default\nINTEGER, PRIVATE :: u, v, w\n</syntaxhighlight>\nand the statement form is \n<syntaxhighlight lang=fortran>\nPUBLIC  :: x, y, z, OPERATOR(.add.)\nPRIVATE :: u, v, w, ASSIGNMENT(=), OPERATOR(*)\n</syntaxhighlight>\nThe statement form has to be used to limit access to operators, and can \nalso be used to change the overall default: \n<syntaxhighlight lang=fortran>\nPRIVATE                        ! sets default for module\nPUBLIC  :: only_this\n</syntaxhighlight>\nFor derived types there are three possibilities: the type and its \ncomponents are all PUBLIC, the type is PUBLIC and its components PRIVATE (the \ntype only is visible and one can change its details easily), or all of it is \nPRIVATE (for internal use in the module only): \n<syntaxhighlight lang=fortran>\nMODULE mine\n   PRIVATE\n   TYPE, PUBLIC :: list\n      REAL x, y\n      TYPE(list), POINTER :: next\n   END TYPE list\n   TYPE(list) :: tree\n   :\nEND MODULE mine\n</syntaxhighlight>\n\nThe <code>USE</code> statement's purpose is to gain access to entities in a module. \nIt has options to resolve name clashes if an imported name is the \nsame as a local one: \n<syntaxhighlight lang=fortran>\nUSE mine, local_list => list\n</syntaxhighlight>\nor to restrict the used entities to a specified set: \n<syntaxhighlight lang=fortran>\nUSE mine, ONLY : list\n</syntaxhighlight>\nThese may be combined: \n<syntaxhighlight lang=fortran>\nUSE mine, ONLY : local_list => list\n</syntaxhighlight>\n\n===Arguments===\nWe may specify the intent of dummy arguments: \n<syntaxhighlight lang=fortran>\nSUBROUTINE shuffle (ncards, cards)\n  INTEGER, INTENT(IN)  :: ncards\n  INTEGER, INTENT(OUT), DIMENSION(ncards) :: cards\n</syntaxhighlight>\nAlso, INOUT is possible: here the actual argument must be a variable \n(unlike the default case where it may be a constant).\n\nArguments may be optional: \n<syntaxhighlight lang=fortran>\nSUBROUTINE mincon(n, f, x, upper, lower, equalities, inequalities, convex, xstart)\n   REAL, OPTIONAL, DIMENSION :: upper, lower\n   :\n   IF (PRESENT(lower)) THEN   ! test for presence of actual argument\n   :\n</syntaxhighlight>\nallows us to call <code>mincon</code> by \n<syntaxhighlight lang=fortran>\nCALL mincon (n, f, x, upper)\n</syntaxhighlight>\nArguments may be keyword rather than positional (which come first): \n<syntaxhighlight lang=fortran>\nCALL mincon(n, f, x, equalities=0, xstart=x0)\n</syntaxhighlight>\nOptional and keyword arguments are handled by explicit interfaces, that is \nwith internal or module procedures or with interface blocks.\n\n===Interface blocks===\nAny reference to an internal or module subprogram is \nthrough an interface that is 'explicit' (that is, the compiler can see all the \ndetails). A reference to an external (or dummy) procedure is usually 'implicit' \n(the compiler assumes the details). However, we can provide an explicit \ninterface in this case too. It is a copy of the header, specifications and END \nstatement of the procedure concerned, either placed in a module or inserted \ndirectly: \n<syntaxhighlight lang=fortran>\nREAL FUNCTION minimum(a, b, func)\n  ! returns the minimum value of the function func(x)\n  ! in the interval (a,b)\n  REAL, INTENT(in) :: a, b\n  INTERFACE\n    REAL FUNCTION func(x)\n      REAL, INTENT(IN) :: x\n    END FUNCTION func\n  END INTERFACE\n  REAL f,x\n  :\n  f = func(x)   ! invocation of the user function.\n  :\nEND FUNCTION minimum\n</syntaxhighlight>\nAn explicit interface is obligatory for\n\n* optional and keyword arguments; \n* POINTER and TARGET arguments (see [[#Pointers|Pointers]]); \n* POINTER function result; \n* new-style array arguments and array functions ([[#Array handling|Array handling]]).\n\nIt allows \nfull checks at compile time between actual and dummy arguments.\n\n'''In general, the best way to ensure that a procedure interface is explicit is either to place the procedure concerned in a module or to use it as an internal procedure.'''\n\n===Overloading and generic interfaces===\nInterface blocks provide the \nmechanism by which we are able to define generic names for specific procedures: \n<syntaxhighlight lang=fortran>\nINTERFACE gamma                   ! generic name\n   FUNCTION sgamma(X)              ! specific name\n      REAL (SELECTED_REAL_KIND( 6)) sgamma, x\n   END\n   FUNCTION dgamma(X)              ! specific name\n      REAL (SELECTED_REAL_KIND(12)) dgamma, x\n   END\nEND INTERFACE\n</syntaxhighlight>\nwhere a given set of specific names corresponding to a generic name must \nall be of functions or all of subroutines. If this interface is within a module, \nthen it is simply \n<syntaxhighlight lang=fortran>\nINTERFACE gamma\n   MODULE PROCEDURE sgamma, dgamma\nEND INTERFACE\n</syntaxhighlight>\nWe can use existing names, e.g. SIN, and the compiler sorts out the \ncorrect association.\n\nWe have already seen the use of interface blocks for defined operators and \nassignment (see [[#Modules|Modules]]).\n\n===Recursion===\nIndirect recursion is useful for multi-dimensional \nintegration. For \n<syntaxhighlight lang=fortran>\nvolume = integrate(fy, ybounds)\n</syntaxhighlight>\nWe might have \n<syntaxhighlight lang=fortran>\nRECURSIVE FUNCTION integrate(f, bounds)\n   ! Integrate f(x) from bounds(1) to bounds(2)\n   REAL integrate\n   INTERFACE\n      FUNCTION f(x)\n         REAL f, x\n      END FUNCTION f\n   END INTERFACE\n   REAL, DIMENSION(2), INTENT(IN) :: bounds\n   :\nEND FUNCTION integrate\n</syntaxhighlight>\nand to integrate ''f(x, y)'' over a rectangle: \n<syntaxhighlight lang=fortran>\nFUNCTION fy(y)\n   USE func           ! module func contains function f\n   REAL fy, y\n   yval = y\n   fy = integrate(f, xbounds)\nEND\n</syntaxhighlight>\nDirect recursion is when a procedure calls itself, as in \n<syntaxhighlight lang=fortran>\nRECURSIVE FUNCTION factorial(n) RESULT(res)\n   INTEGER res, n\n   IF(n.EQ.0) THEN\n      res = 1\n   ELSE\n      res = n*factorial(n-1)\n   END IF\nEND\n</syntaxhighlight>\nHere, we note the <code>RESULT</code> clause and termination test.\n\n===Pure Procedures===\n\nThis is a feature for parallel computing.\n\nIn [[#The FORALL Statement and Construct|the FORALL Statement and Construct]], any\nside effects in a function can\nimpede optimization on a parallel processor—the order of execution of the assignments could affect the results.\nTo control this situation, we\nadd the <code>PURE</code> keyword to the\n<code>SUBROUTINE</code> or <code> FUNCTION</code>\nstatement—an assertion that the procedure (expressed simply):\n\n* alters no global variable, \n* performs no I/O, \n* has no saved variables (variables with the <code>SAVE</code> attribute that retains values between invocations), and\n* for functions, does not alter any of its arguments.\n\nA compiler can\ncheck that this is the case, as in\n<syntaxhighlight lang=fortran>\nPURE FUNCTION calculate (x)\n</syntaxhighlight>\nAll the intrinsic functions are pure.\n\n==Array handling==\n\nArray handling is included in Fortran for two main reasons:\n\n* the notational convenience it provides, bringing the code closer to the underlying mathematical form; \n* for the additional optimization opportunities it gives compilers (although there are plenty of opportunities for degrading optimization too!).\n\nAt the same time, major extensions of the functionality in this area have been \nadded. We have already met whole arrays above [[#Arrays|#Arrays 1]] and here  [[#Arrays 2]] - now \nwe develop the theme.\n\n===Zero-sized arrays===\nA zero-sized array is handled by Fortran as a \nlegitimate object, without special coding by the programmer. Thus, in \n<syntaxhighlight lang=fortran>\nDO i = 1,n\n   x(i) = b(i) / a(i, i)\n   b(i+1:n) = b(i+1:n) - a(i+1:n, i) * x(i)\nEND DO\n</syntaxhighlight>\nno special code is required for the final iteration where <code>i = n</code>. We note \nthat a zero-sized array is regarded as being defined; however, an array of shape \n(0,2) is not conformable with one of shape (0,3), whereas <syntaxhighlight lang=fortran inline>x(1:0) = 3</syntaxhighlight> is a valid 'do nothing' statement.\n\n===Assumed-shape arrays===\nThese are an extension and replacement for \nassumed-size arrays. Given an actual argument like: \n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(0:10, 0:20) :: a\n   :\nCALL sub(a)\n</syntaxhighlight>\nthe corresponding dummy argument specification defines only the type and \nrank of the array, not its shape. This information has to be made available by an \nexplicit interface, often using an interface block (see [[#Interface blocks|Interface blocks]]). Thus we write just \n<syntaxhighlight lang=fortran>\nSUBROUTINE sub(da)\n   REAL, DIMENSION(:, :) :: da\n</syntaxhighlight>\nand this is as if <code>da</code> were dimensioned (11,21). However, we can specify any \nlower bound and the array maps accordingly.\n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(0:, 0:) :: da\n</syntaxhighlight>\nThe shape, not bounds, is passed, where the default lower bound is 1 and the default upper bound is the corresponding extent.\n\n===Automatic arrays===\nA partial replacement for the uses to which <code>EQUIVALENCE</code> \nwas put is provided by this facility, useful for local, temporary arrays, as in \n<syntaxhighlight lang=fortran>\nSUBROUTINE swap(a, b)\n   REAL, DIMENSION(:)       :: a, b\n   REAL, DIMENSION(SIZE(a)) :: work\n   work = a\n   a = b\n   b = work\nEND SUBROUTINE swap\n</syntaxhighlight>\nThe actual storage is typically maintained on a stack.\n\n===ALLOCATABLE and ALLOCATE===\nFortran provides dynamic allocation of \nstorage; it relies on a heap storage mechanism (and replaces another use of \n<code>EQUIVALENCE</code>). An example for establishing a work array for a whole program is \n<syntaxhighlight lang=fortran>\nMODULE work_array\n   INTEGER n\n   REAL, DIMENSION(:,:,:), ALLOCATABLE :: work\nEND MODULE\nPROGRAM main\n   USE work_array\n   READ (input, *) n\n   ALLOCATE(work(n, 2*n, 3*n), STAT=status)\n   :\n   DEALLOCATE (work)\n</syntaxhighlight>\nThe work array can be propagated through the whole program via a <code>USE</code> \nstatement in each program unit. We may specify an explicit lower bound and \nallocate several entities in one statement. To free dead storage we write, for \ninstance, \n<syntaxhighlight lang=fortran>\nDEALLOCATE(a, b)\n</syntaxhighlight>\nDeallocation of arrays is automatic when they go out of scope.\n\n===Elemental operations, assignments and procedures===\nWe have already met whole array \nassignments and operations: \n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(10) :: a, b\na = 0.          ! scalar broadcast; elemental assignment\nb = SQRT(a)     ! intrinsic function result as array object\n</syntaxhighlight>\nIn the second assignment, an intrinsic function returns an array-valued \nresult for an array-valued argument. We can write array-valued functions \nourselves (they require an explicit interface): \n<syntaxhighlight lang=fortran>\nPROGRAM test\n   REAL, DIMENSION(3) :: a = (/ 1., 2., 3./),       &\n                         b = (/ 2., 2., 2. /),  r\n   r = f(a, b)\n   PRINT *, r\nCONTAINS\n   FUNCTION f(c, d)\n   REAL, DIMENSION(:) :: c, d\n   REAL, DIMENSION(SIZE(c)) :: f\n   f = c*d        ! (or some more useful function of c and d)\n   END FUNCTION f\nEND PROGRAM test\n</syntaxhighlight>\nElemental procedures are specified with scalar dummy arguments that may be called with\narray actual arguments. In the case of a function, the shape of the result is the shape of the array\narguments.\n\nMost intrinsic functions are elemental and\nFortran 95 extends this feature to non-intrinsic procedures, thus providing the effect\nof writing, in Fortran 90, 22 different versions, for ranks 0-0, 0-1, 1-0, 1-1, 0-2,\n2-0, 2-2, ... 7-7, and is further an aid to optimization on parallel processors.\nAn elemental procedure must be pure.\n<syntaxhighlight lang=fortran>\nELEMENTAL SUBROUTINE swap(a, b)\n   REAL, INTENT(INOUT)  :: a, b\n   REAL                 :: work\n   work = a\n   a = b\n   b = work\nEND SUBROUTINE swap\n</syntaxhighlight>\nThe dummy arguments cannot be used in specification expressions \n(see [[#Specification expressions|above]]) except as\narguments to certain intrinsic functions (<code>BIT_SIZE</code>, <code>KIND</code>, \n<code>LEN</code>, and the numeric inquiry ones, (see [[#Intrinsic data types|below]]).\n\n===WHERE===\nOften, we need to mask an assignment. This we can do using the \n<code>WHERE</code>, either as a statement: \n<syntaxhighlight lang=fortran>\nWHERE (a /= 0.0) a = 1.0/a  ! avoid division by 0\n</syntaxhighlight>\n(note: the test is element-by-element, not on whole array), or as a construct: \n<syntaxhighlight lang=fortran>\nWHERE (a /= 0.0)\n   a = 1.0/a\n   b = a             ! all arrays same shape\nEND WHERE\n</syntaxhighlight>\nor \n<syntaxhighlight lang=fortran>\nWHERE (a /= 0.0)\n   a = 1.0/a\nELSEWHERE\n   a = HUGE(a)\nEND WHERE\n</syntaxhighlight>\nFurther:\n\n* it is permitted to mask not only the <code>WHERE</code> statement of the <code>WHERE</code> construct, but also any <code>ELSEWHERE</code> statement that it contains;\n* a <code>WHERE</code> construct may contain any number of masked <code>ELSEWHERE</code> statements but at most one <code>ELSEWHERE</code> statement without a mask, and that must be the final one;\n* <code>WHERE</code>  constructs may be nested within one another, just <code>FORALL</code> constructs;\n* a <code>WHERE</code> assignment statement is permitted to be a defined assignment, provided that it is elemental;\n* a <code>WHERE</code> construct may be named in the same way as other constructs.\n\n===The FORALL Statement and Construct===\n\nWhen a <code>DO</code> construct\nis executed, each successive\niteration is performed in order and one after the other—an impediment to optimization\non a parallel processor.\n<syntaxhighlight lang=fortran>\nFORALL(i = 1:n) a(i, i) = x(i)\n</syntaxhighlight>\nwhere\nthe individual assignments may be carried out in any order, and\neven simultaneously.\nThe <code>FORALL</code> may be considered to be an array assignment\nexpressed with the help of indices.\n<syntaxhighlight lang=fortran>\nFORALL(i=1:n, j=1:n, y(i,j)/=0.) x(j,i) = 1.0/y(i,j)\n</syntaxhighlight>\nwith masking condition.\n\nThe <code>FORALL</code> construct\nallows several\nassignment statements to be executed in order.    \n<syntaxhighlight lang=fortran>\na(2:n-1,2:n-1) = a(2:n-1,1:n-2) + a(2:n-1,3:n) + a(1:n-2,2:n-1) + a(3:n,2:n-1)\nb(2:n-1,2:n-1) = a(2:n-1,2:n-1)\n</syntaxhighlight>\nis equivalent to the array assignments\n<syntaxhighlight lang=fortran>\nFORALL(i = 2:n-1, j = 2:n-1)\n   a(i,j) = a(i,j-1) + a(i,j+1) + a(i-1,j) + a(i+1,j)\n   b(i,j) = a(i,j)\nEND FORALL\n</syntaxhighlight>\nThe <code>FORALL</code> version is more readable.\n\nAssignment in a <code>FORALL</code>\nis like an array assignment: \nas if all the expressions were evaluated in any order, held\nin temporary storage, then all the assignments performed in any order.\nThe first statement must fully complete before the second can begin.\n \nA <code>FORALL</code>\nmay be nested, and\nmay include a <code>WHERE</code>.\nProcedures referenced within a <code>FORALL</code>\nmust be pure.\n\n===Array elements===\nFor a simple case, given \n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(100, 100) :: a\n</syntaxhighlight>\nwe can reference a single element as, for instance, <code>a(1, 1)</code>. For a \nderived-data type like \n<syntaxhighlight lang=fortran>\nTYPE fun_del\n   REAL                  u\n   REAL, DIMENSION(3) :: du\nEND TYPE fun_del\n</syntaxhighlight>\nwe can declare an array of that type: \n<syntaxhighlight lang=fortran>\nTYPE(fun_del), DIMENSION(10, 20) :: tar\n</syntaxhighlight>\nand a reference like <syntaxhighlight lang=fortran inline>tar(n, 2)</syntaxhighlight> is an element (a scalar!) of type fun_del, but <syntaxhighlight lang=fortran inline>tar(n, 2)%du</syntaxhighlight> is an array of type real, and <syntaxhighlight lang=fortran inline>tar(n, 2)%du(2)</syntaxhighlight> is an element of it. The basic rule to remember is that an array element \nalways has a subscript or subscripts qualifying at least the last name.\n\n===Array subobjects (sections)===\nThe general form of subscript for an array \nsection is \n \n       [''lower''] : [''upper''] [:''stride'']\n\n(where [ ] indicates an optional item) as in \n<syntaxhighlight lang=fortran>\nREAL a(10, 10)\na(i, 1:n)                ! part of one row\na(1:m, j)                ! part of one column\na(i, : )                 ! whole row\na(i, 1:n:3)              ! every third element of row\na(i, 10:1:-1)            ! row in reverse order\na( (/ 1, 7, 3, 2 /), 1)  ! vector subscript\na(1, 2:11:2)             ! 11 is legal as not referenced\na(:, 1:7)                ! rank two section\n</syntaxhighlight>\nNote that a vector subscript with duplicate values cannot appear on the \nleft-hand side of an assignment as it would be ambiguous. Thus, \n<syntaxhighlight lang=fortran>\nb( (/ 1, 7, 3, 7 /) ) = (/ 1, 2, 3, 4 /)\n</syntaxhighlight>\nis illegal. Also, a section with a vector subscript must not be supplied \nas an actual argument to an <code>OUT</code> or <code>INOUT</code> dummy argument. Arrays of arrays are not allowed:\n<syntaxhighlight lang=fortran>\ntar%du             ! illegal\n</syntaxhighlight>\nWe note that a given value in an array can be referenced both as an \nelement and as a section: \n<syntaxhighlight lang=fortran>\na(1, 1)            !  scalar (rank zero)\na(1:1, 1)          !  array section (rank one)\n</syntaxhighlight>\ndepending on the circumstances or requirements. By qualifying objects of \nderived type, we obtain elements or sections depending on the rule stated \nearlier: \n<syntaxhighlight lang=fortran>\ntar%u              !  array section (structure component)\ntar(1, 1)%u        !  component of an array element\n</syntaxhighlight>\n\n===Arrays intrinsic functions===\n'''''Vector and matrix multiply'''''\n\n      DOT_PRODUCT        Dot product of 2 rank-one arrays\n      MATMUL             Matrix multiplication\n\n'''''Array reduction'''''\n\n      ALL                True if all values are true\n      ANY                True if any value is true. Example:\n                             IF (ANY( a &gt; b)) THEN\n      COUNT              Number of true elements in array\n      MAXVAL             Maximum value in an array\n      MINVAL             Minimum value in an array\n      PRODUCT            Product of array elements\n      SUM                Sum of array elements\n\n'''''Array inquiry'''''\n\n      ALLOCATED          Array allocation status\n      LBOUND             Lower dimension bounds of an array\n      SHAPE              Shape of an array (or scalar)\n      SIZE               Total number of elements in an array\n      UBOUND             Upper dimension bounds of an array\n\n'''''Array construction'''''\n\n      MERGE              Merge under mask\n      PACK               Pack an array into an array of rank one under a mask\n      SPREAD             Replicate array by adding a dimension\n      UNPACK             Unpack an array of rank one into an array under mask\n\n'''''Array reshape'''''\n\n      RESHAPE            Reshape an array\n\n'''''Array manipulation'''''\n\n      CSHIFT             Circular shift\n      EOSHIFT            End-off shift\n      TRANSPOSE          Transpose of an array of rank two\n\n'''''Array location'''''\n\n      MAXLOC             Location of first maximum value in an array\n      MINLOC             Location of first minimum value in an array\n\n==Pointers==\n\n===Basics===\nPointers are variables with the <code>POINTER</code> attribute; they are not a \ndistinct data type (and so no 'pointer arithmetic' is possible). \n<syntaxhighlight lang=fortran>\nREAL, POINTER :: var\n</syntaxhighlight>\nThey are conceptually a descriptor listing the attributes of the objects \n(targets) that the pointer may point to, and the address, if any, of a target. \nThey have no associated storage until it is allocated or otherwise associated \n(by pointer assignment, see [[#Pointers in expressions and assignments|below]]): \n<syntaxhighlight lang=fortran>\nALLOCATE (var)\n</syntaxhighlight>\nand they are dereferenced automatically, so no special symbol required. In \n<syntaxhighlight lang=fortran>\nvar = var + 2.3\n</syntaxhighlight>\nthe value of the target of var is used and modified. Pointers cannot be \ntransferred via I/O. The statement\n<syntaxhighlight lang=fortran>\nWRITE *, var\n</syntaxhighlight>\nwrites the value of the target of var and not the pointer descriptor \nitself.\n\nA pointer can point to another pointer, and hence to its target, or to a \nstatic object that has the <code>TARGET</code> attribute: \n<syntaxhighlight lang=fortran>\nREAL, POINTER :: object\nREAL, TARGET  :: target_obj\nvar => object                  ! pointer assignment\nvar => target_obj\n</syntaxhighlight>\nbut they are strongly typed: \n<syntaxhighlight lang=fortran>\nINTEGER, POINTER :: int_var\nvar => int_var                 ! illegal - types must match\n</syntaxhighlight>\nand, similarly, for arrays the ranks as well as the type must agree.\n\nA pointer can be a component of a derived type: \n<syntaxhighlight lang=fortran>\nTYPE entry                       ! type for sparse matrix\n   REAL value\n   INTEGER index\n   TYPE(entry), POINTER :: next  ! note recursion\nEND TYPE entry\n</syntaxhighlight>\nand we can define the beginning of a linked chain of such entries: \n<syntaxhighlight lang=fortran>\nTYPE(entry), POINTER :: chain\n</syntaxhighlight>\nAfter suitable allocations and definitions, the first two entries could be \naddressed as \n<syntaxhighlight lang=fortran>\nchain%value           chain%next%value\nchain%index           chain%next%index\nchain%next            chain%next%next\n</syntaxhighlight>\nbut we would normally define additional pointers to point at, for \ninstance, the first and current entries in the list.\n\n===Association===\nA pointer's association status is one of \n{{unordered list\n| undefined (initial state); \n| associated (after allocation or a pointer assignment); \n| disassociated: \n<syntaxhighlight lang=fortran>\nDEALLOCATE (p, q)  ! for returning storage\nNULLIFY (p, q)     ! for setting to 'null'\n</syntaxhighlight>\n}}\nSome care has to be taken not to leave a pointer 'dangling' by \nuse of <code>DEALLOCATE</code> on its target without nullifying any other pointer referring \nto it.\n\nThe intrinsic function <code>ASSOCIATED</code> can test the association status of a \ndefined pointer: \n<syntaxhighlight lang=fortran>\nIF (ASSOCIATED(pointer)) THEN\n</syntaxhighlight>\nor between a defined pointer and a defined target (which may, itself, be a \npointer): \n<syntaxhighlight lang=fortran>\nIF (ASSOCIATED(pointer, target)) THEN\n</syntaxhighlight>\nAn alternative way to initialize a pointer, also in a specification statement,\nis to use the <code>NULL</code> function:\n<syntaxhighlight lang=fortran>\nREAL, POINTER, DIMENSION(:) :: vector => NULL() ! compile time\nvector => NULL()                                ! run time\n</syntaxhighlight>\n\n===Pointers in expressions and assignments===\nFor intrinsic types we can \n'sweep' pointers over different sets of target data using the same code without \nany data movement. Given the matrix manipulation ''y = B C z'', we can write the \nfollowing code (although, in this case, the same result could be achieved more \nsimply by other means): \n<syntaxhighlight lang=fortran>\nREAL, TARGET  :: b(10,10), c(10,10), r(10), s(10), z(10)\nREAL, POINTER :: a(:,:), x(:), y(:)\nINTEGER mult\n:\nDO mult = 1, 2\n   IF (mult == 1) THEN\n      y => r              ! no data movement\n      a => c\n      x => z\n   ELSE\n      y => s              ! no data movement\n      a => b\n      x => r\n   END IF\n   y = MATMUL(a, x)       ! common calculation\nEND DO\n</syntaxhighlight>\nFor objects of derived type we have to distinguish between pointer and \nnormal assignment. In \n<syntaxhighlight lang=fortran>\nTYPE(entry), POINTER :: first, current\n:\nfirst => current\n</syntaxhighlight>\nthe assignment causes first to point at current, whereas \n<syntaxhighlight lang=fortran>\nfirst =  current\n</syntaxhighlight>\ncauses current to overwrite first and is equivalent to \n<syntaxhighlight lang=fortran>\nfirst%value = current%value\nfirst%index = current%index\nfirst%next => current%next\n</syntaxhighlight>\n\n===Pointer arguments===\nIf an actual argument is a pointer then, if the dummy \nargument is also a pointer,\n\n* it must have same rank, \n* it receives its association status from the actual argument, \n* it returns its final association status to the actual argument (note: the target may be undefined!), \n* it may not have the <code>INTENT</code> attribute (it would be ambiguous), \n* it requires an interface block.\n\nIf the dummy argument is not a \npointer, it becomes associated with the target of the actual argument: \n<syntaxhighlight lang=fortran>\n   REAL, POINTER :: a (:,:)\n      :\n   ALLOCATE (a(80, 80))\n      :\n   CALL sub(a)\n      :\nSUBROUTINE sub(c)\n   REAL c(:, :)\n</syntaxhighlight>\n\n===Pointer functions===\nFunction results may also have the <code>POINTER</code> attribute; \nthis is useful if the result size depends on calculations performed in the \nfunction, as in \n<syntaxhighlight lang=fortran>\nUSE data_handler\nREAL x(100)\nREAL, POINTER :: y(:)\n:\ny => compact(x)\n</syntaxhighlight>\nwhere the module data_handler contains \n<syntaxhighlight lang=fortran>\nFUNCTION compact(x)\n   REAL, POINTER :: compact(:)\n   REAL x(:)\n   ! A procedure to remove duplicates from the array x\n   INTEGER n\n   :              ! Find the number of distinct values, n\n   ALLOCATE(compact(n))\n   :              ! Copy the distinct values into compact\nEND FUNCTION compact\n</syntaxhighlight>\nThe result can be used in an expression (but must be associated with a \ndefined target).\n\n===Arrays of pointers===\nThese do not exist as such: given \n<syntaxhighlight lang=fortran>\nTYPE(entry) :: rows(n)\n</syntaxhighlight>\nthen \n<syntaxhighlight lang=fortran>\nrows%next              ! illegal\n</syntaxhighlight>\nwould be such an object, but with an irregular storage pattern. For this \nreason they are not allowed. However, we can achieve the same effect by defining \na derived data type with a pointer as its sole component: \n<syntaxhighlight lang=fortran>\nTYPE row\n   REAL, POINTER :: r(:)\nEND TYPE\n</syntaxhighlight>\nand then defining arrays of this data type\n<syntaxhighlight lang=fortran>\nTYPE(row) :: s(n), t(n)\n</syntaxhighlight>\nwhere the storage for the rows can be allocated by, for instance, \n<syntaxhighlight lang=fortran>\nDO i = 1, n\n   ALLOCATE (t(i)%r(1:i)) ! Allocate row i of length i\nEND DO\n</syntaxhighlight>\nThe array assignment <syntaxhighlight lang=fortran inline>s = t</syntaxhighlight>is then equivalent to the pointer assignments <syntaxhighlight lang=fortran inline>s(i)%r => t(i)%r</syntaxhighlight> for all components.\n\n===Pointers as dynamic aliases===\nGiven an array \n<syntaxhighlight lang=fortran>\nREAL, TARGET :: table(100,100)\n</syntaxhighlight>\n\nthat is frequently referenced with the fixed subscripts \n<syntaxhighlight lang=fortran>\ntable(m:n, p:q)\n</syntaxhighlight>\nthese references may be replaced by \n<syntaxhighlight lang=fortran>\nREAL, DIMENSION(:, :), POINTER :: window\n   :\nwindow => table(m:n, p:q)\n</syntaxhighlight>\nThe subscripts of window are <syntaxhighlight lang=fortran inline>1:n-m+1, 1:q-p+1</syntaxhighlight>. Similarly, for <syntaxhighlight lang=fortran inline>tar%u</syntaxhighlight>\n(as defined in [[#Array elements|already]]), we can use, say, <syntaxhighlight lang=fortran inline>taru => tar%u</syntaxhighlight> to point at all the u components of tar, and subscript it as <syntaxhighlight lang=fortran inline>taru(1, 2)</syntaxhighlight>\n\nThe subscripts are as those of tar itself. (This replaces yet more of <code>EQUIVALENCE</code>.)\n\nIn the pointer association\n<syntaxhighlight lang=fortran>\npointer => array_expression\n</syntaxhighlight>\nthe lower bounds for <code>pointer</code> are determined as if <code>lbound</code> was applied to <code>array_expression</code>. Thus, when a pointer is assigned to a whole array variable, it inherits the lower bounds of the variable, otherwise, the lower bounds default to 1.\n\n[[Fortran 2003]] allows specifying arbitrary lower bounds on pointer association, like\n<syntaxhighlight lang=fortran>\nwindow(r:,s:) => table(m:n,p:q)\n</syntaxhighlight>\nso that the bounds of <code>window</code> become <code>r:r+n-m,s:s+q-p</code>.\n[[Fortran 95]] does not have this feature; however, it can be simulated using the\nfollowing trick (based on the pointer association rules for assumed shape array dummy arguments):\n<syntaxhighlight lang=fortran>\nFUNCTION remap_bounds2(lb1,lb2,array) RESULT(ptr)\n   INTEGER, INTENT(IN)                            :: lb1,lb2\n   REAL, DIMENSION(lb1:,lb2:), INTENT(IN), TARGET :: array\n   REAL, DIMENSION(:,:), POINTER                  :: ptr\n   ptr => array\nEND FUNCTION\n  :\nwindow => remap_bounds2(r,s,table(m:n,p:q))\n</syntaxhighlight>\n\nThe source code of an extended example of the use of pointers to support a \ndata structure is in [ftp://ftp.numerical.rl.ac.uk/pub/MRandC/pointer.f90 pointer.f90].\n\n==Intrinsic procedures==\n\nMost of the intrinsic functions have already been mentioned. Here, we deal \nonly with their general classification and with those that have so far been \nomitted. All intrinsic procedures can be used with keyword arguments: \n<syntaxhighlight lang=fortran>\nCALL DATE_AND_TIME (TIME=t)\n</syntaxhighlight>\nand many have optional arguments.\n\nThe intrinsic procedures are grouped into four categories:\n\n# elemental - work on scalars or arrays, e.g. <code>ABS(a)</code>; \n# inquiry - independent of value of argument (which may be undefined), e.g. <code>PRECISION(a)</code>; \n# transformational - array argument with array result of different shape, e.g. <code>RESHAPE(a, b)</code>; \n# subroutines, e.g. <code>SYSTEM_CLOCK</code>.\n\nThe procedures not already \nintroduced are\n\nBit inquiry\n      BIT_SIZE           Number of bits in the model\n \nBit manipulation\n      BTEST              Bit testing\n      IAND               Logical AND\n      IBCLR              Clear bit\n      IBITS              Bit extraction\n      IBSET              Set bit\n      IEOR               Exclusive OR\n      IOR                Inclusive OR\n      ISHFT              Logical shift\n      ISHFTC             Circular shift\n      NOT                Logical complement\n \nTransfer function, as in\n<syntaxhighlight lang=fortran>\nINTEGER :: i = TRANSFER('abcd', 0)\n</syntaxhighlight>\n(replaces part of EQUIVALENCE)\n \nSubroutines\n      DATE_AND_TIME      Obtain date and/or time\n      MVBITS             Copies bits\n      RANDOM_NUMBER      Returns pseudorandom numbers\n      RANDOM_SEED        Access to seed\n      SYSTEM_CLOCK       Access to system clock\n      CPU_TIME           Returns processor time in seconds\n\n==Data transfer==\n(This is a subset only of the actual features and, exceptionally, lower case is used\nin the code examples.)\n\n===Formatted input/output===\nThese examples illustrate various forms of I/O lists with some simple formats \n(see [[#Edit descriptors|below]]):\n<syntaxhighlight lang=fortran>\ninteger             :: i\nreal, dimension(10) :: a\ncharacter(len=20)   :: word\nprint \"(i10)\",     i\nprint \"(10f10.3)\", a\nprint \"(3f10.3)\",  a(1),a(2),a(3)\nprint \"(a10)\",     word(5:14)\nprint \"(3f10.3)\",  a(1)*a(2)+i, sqrt(a(3:4))\n</syntaxhighlight>\nVariables, but not expressions, are equally valid in input\nstatements using the <code>read</code> statement:\n<syntaxhighlight lang=fortran>\nread \"(i10)\", i\n</syntaxhighlight>\n\nIf an array appears as an item, it is treated as if the elements were\nspecified in array element order.\n\nAny pointers in an I/O list\nmust be associated with a target, and transfer takes place\nbetween the file and the targets.\n\nAn item of derived type is treated as if the components were specified\nin the same order as in the type declaration, so\n<syntaxhighlight lang=fortran>\nread \"(8f10.5)\", p, t  ! types point and triangle\n</syntaxhighlight>\nhas the same effect as the statement\n<syntaxhighlight lang=fortran>\nread \"(8f10.5)\", p%x, p%y, t%a%x, t%a%y, t%b%x, &\n                           t%b%y, t%c%x, t%c%y\n</syntaxhighlight>\nAn object in an I/O list is not permitted to be of a derived type\nthat has a pointer component at any level of component selection.\n \nNote that a zero-sized array\nmay occur as an item in an I/O list.\nSuch an item corresponds to no actual data transfer.\n\nThe format specification may also\nbe given in the form of a character expression:\n<syntaxhighlight lang=fortran>\ncharacter(len=*), parameter :: form=\"(f10.3)\"\n:\nprint form, q\n</syntaxhighlight>\nor as an asterisk—this is a type of I/O known as\n''list-directed''\nI/O (see [[#List-directed I/O|below]]), in which the format is defined by the computer system:\n<syntaxhighlight lang=fortran>\nprint *, \"Square-root of q = \", sqrt(q)\n</syntaxhighlight>\nInput/output operations are used to transfer data between the\nstorage of an executing program and an external medium, specified by a ''unit number''.\nHowever, two I/O statements,  <code>print</code> and a variant of\n<code>read</code>, do not\nreference any unit number: this is referred to as terminal I/O. \nOtherwise the form is:\n<syntaxhighlight lang=fortran>\nread (unit=4,     fmt=\"(f10.3)\") q\nread (unit=nunit, fmt=\"(f10.3)\") q\nread (unit=4*i+j, fmt=\"(f10.3)\") a\n</syntaxhighlight>\nwhere <code>unit=</code> is optional.\nThe value may be any nonnegative integer allowed by the system\nfor this purpose (but 0, 5 and 6 often denote the error, keyboard and terminal, respectively).\n\nAn asterisk is a variant—again from the keyboard:\n<syntaxhighlight lang=fortran>\nread (unit=*, fmt=\"(f10.3)\") q\n</syntaxhighlight>\n\nA read with a unit specifier allows [[exception handling]]:\n<syntaxhighlight lang=fortran>\nread (unit=nunit, fmt=\"(3f10.3)\", iostat=ios) a,b,c\nif (ios == 0) then\n!     Successful read - continue execution.\n   :\nelse\n!     Error condition - take appropriate action.\n   call error (ios)\nend if\n</syntaxhighlight>\n\nThere a second type of formatted output statement, the\n<code>write</code> statement:\n<syntaxhighlight lang=fortran>\nwrite (unit=nout, fmt=\"(10f10.3)\", iostat=ios) a\n</syntaxhighlight>\n\n===Internal files===\nThese allow format conversion between various representations to be carried out by the program in a storage area defined within the program itself.\n<syntaxhighlight lang=fortran>\ninteger, dimension(30)         :: ival\ninteger                        :: key\ncharacter(len=30)              :: buffer\ncharacter(len=6), dimension(3), parameter :: form=(/ \"(30i1)\", \"(15i2)\",\"(10i3)\" /)\nread (unit=*, fmt=\"(a30,i1)\")      buffer, key\nread (unit=buffer, fmt=form (key)) ival(1:30/key)\n</syntaxhighlight>\nIf an internal file is a scalar, it has a single record whose length is that of the scalar.\n\nIf it is an array, its elements, in array element order, are treated as successive records of the file and each has length that of an array element.\n\nAn example using a <code>write</code> statement is\n<syntaxhighlight lang=fortran>\ninteger           :: day\nreal              :: cash\ncharacter(len=50) :: line\n:\n!   write into line\nwrite (unit=line, fmt=\"(a, i2, a, f8.2, a)\") \"Takings for day \", day, \" are \", cash, \" dollars\"\n</syntaxhighlight>\nthat might write\n<pre>\n Takings for day  3 are  4329.15 dollars\n</pre>\n\n===List-directed I/O===\nAn example of a read without a specified format for input is\n<syntaxhighlight lang=fortran>\ninteger               :: i\nreal                  :: a\ncomplex, dimension(2) :: field\nlogical               :: flag\ncharacter(len=12)     :: title\ncharacter(len=4)      :: word\n:\nread *, i, a, field, flag, title, word\n</syntaxhighlight>\nIf this reads the input record\n<syntaxhighlight lang=fortran>\n10 6.4 (1.0,0.0) (2.0,0.0) t test/\n</syntaxhighlight>\n(in which blanks are used as separators),\nthen <code>i</code>, <code>a</code>, \n<code>field</code>, <code>flag</code>, and <code>title</code> will acquire the values 10, 6.4, \n(1.0,0.0) and (2.0,0.0), <code>.true.</code>\nand <code>test</code> respectively,\nwhile <code>word</code> remains unchanged.\n\nQuotation marks or apostrophes are required as delimiters for a string that\ncontains a blank.\n\n===Non-advancing I/O===\nThis is a form of reading and writing\nwithout always advancing the file position to ahead of the next record.\nWhereas an advancing I/O statement always repositions the file after the last\nrecord accessed, a non-advancing I/O statement performs no\nsuch repositioning and may therefore leave the file positioned within a\nrecord.\n<syntaxhighlight lang=fortran>\ncharacter(len=3) :: key\ninteger      :: u, s, ios\n:\nread(unit=u, fmt=\"(a3)\", advance=\"no\", size=s, iostat=ios) key\nif (ios == 0) then\n   :\nelse\n!    key is not in one record\n   key(s+1:) = \"\"\n   :\nend if\n</syntaxhighlight>\nA non-advancing read might read the first\nfew characters of a record and a normal read the remainder.\n\nIn order to write a prompt to a\nterminal screen and to read from the next character position on the\nscreen without an intervening line-feed, we can write\n<syntaxhighlight lang=fortran>\nwrite (unit=*, fmt=\"(a)\", advance=\"no\") \"enter next prime number:\"\nread  (unit=*, fmt=\"(i10)\") prime_number\n</syntaxhighlight>\nNon-advancing I/O is for external files, and is  \nnot available for list-directed I/O.\n\n===Edit descriptors===\nIt is possible to specify that an edit descriptor be repeated a specified number of times, \nusing a ''repeat count'': <code>10f12.3</code>\n\nThe slash edit descriptor (see [[#Control edit descriptors|below]])\nmay have a repeat count, and a repeat count \ncan also apply to a group of edit\ndescriptors, enclosed in parentheses, with nesting:\n<syntaxhighlight lang=fortran>\nprint \"(2(2i5,2f8.2))\", i(1),i(2),a(1),a(2), i(3),i(4),a(3),a(4)\n</syntaxhighlight>\nEntire format specifications can be repeated:\n<syntaxhighlight lang=fortran>\nprint \"(10i8)\", (/ (i(j), j=1,200) /)\n</syntaxhighlight>\nwrites 10 integers, each occupying 8 character positions, on each of 20 lines (repeating the format specification advances to the next line).\n\n====Data edit descriptors====\n{{unordered list\n| Integer: <code> iW   iW.M</code>\n| Real: <code> fW.D   esW.D   esW.DeE</code>\n| Complex: pairs of <code>f</code> or <code>es</code> edit descriptors\n| Logical: <code> lW</code>\n| Character: <code> a   aW</code>\n| Derived types: are edited by the appropriate sequence of edit descriptors corresponding to the intrinsic types of the ultimate components of the derived type.\n<syntaxhighlight lang=fortran>\ntype, public :: string\n   integer   :: length\n   character(len=20) :: word\nend type string\ntype(string) :: text\nread(unit=*, fmt=\"(i2, a)\") text\n</syntaxhighlight>\n}}\n\n====Control edit descriptors====\n\n''Control edit descriptors setting conditions'':\n{{unordered list\n|1= The <code>ss</code> (sign suppress) edit descriptor suppresses leading plus signs. To switch on plus sign printing, the <code>sp</code> (sign print) descriptor is used. The <code>s</code> edit descriptor restores the option to the processor.\n|2= This descriptor remains in force for the remainder of the format specification, unless another of them is met.\n}}\n''Control edit descriptors for immediate processing'':\n{{unordered list\n|1= Tabulation: <code>tN   trN   tlN</code>\n<syntaxhighlight lang=fortran>\nread (unit=*, fmt=\"(t3,i4, tl4,i1, i2)\") i,j,k\n</syntaxhighlight>\n|2= New records:<code> /   N/</code>\n<syntaxhighlight lang=fortran>\nread \"(i5,i3,/,i5,i3,i2)\", i, j, k, l, m\n</syntaxhighlight>\nNote that\n<syntaxhighlight lang=fortran>\nprint \"(i5,4/,i5)\", i, j\n</syntaxhighlight>\nseparates the two values by three blank records.\n|3= Colon editing: <code> :</code>\nterminates format control if there are no further items in\nan I/O list.\n<syntaxhighlight lang=fortran>\nprint \"( i5, :, /, i5, :, /, i5)\", (/(l(i), i=1,n)/)\n</syntaxhighlight>\nstops new records if <code>n</code> equals 1 or 2.\n}}\n\n===Unformatted I/O===\nThis type of I/O should be used only in cases where the records are\ngenerated by a program on one computer, to be read back on the same\ncomputer or another computer using the\nsame internal number representations:\n<syntaxhighlight lang=fortran>\nopen(unit=4, file='test', form='unformatted')\nread(unit=4) q\nwrite(unit=nout, iostat=ios) a  ! no fmt=\n</syntaxhighlight>\n\n===Direct-access files===\nThis form of I/O is also known as random access or indexed I/O.\nHere, all the records have the same\nlength, and each\nrecord is identified by an index number. It is possible to write,\nread, or re-write any specified record without regard to position.\n<syntaxhighlight lang=fortran>\ninteger, parameter :: nunit=2, length=100\nreal, dimension(length)            :: a\nreal, dimension(length+1:2*length) :: b\ninteger                            :: i, rec_length\n:\ninquire (iolength=rec_length) a\nopen (unit=nunit, access=\"direct\", recl=rec_length, status=\"scratch\", action=\"readwrite\")\n:\n!   Write array b to direct-access file in record 14\nwrite (unit=nunit, rec=14) b\n:\n!\n!   Read the array back into array a\nread (unit=nunit, rec=14) a\n:\ndo i = 1, length/2\n   a(i) = i\nend do\n!\n!   Replace modified record\nwrite (unit=nunit, rec=14) a\n</syntaxhighlight>\nThe file must be an external file and \nlist-directed formatting and non-advancing I/O are\nunavailable.\n\n==Operations on external files==\nOnce again, this is an overview only.\n\n===File positioning statements===\n{{unordered list\n|1= The <code>backspace</code> statement:\n<syntaxhighlight lang=fortran>\nbackspace (unit=u [,iostat=ios])      ! where [ ] means optional\n</syntaxhighlight>\n|2= The <code>rewind</code> statement:\n<syntaxhighlight lang=fortran>\nrewind (unit=u [,iostat=ios])\n</syntaxhighlight>\n|3= The <code>endfile</code> statement:\n<syntaxhighlight lang=fortran>\nendfile (unit=u [,iostat=ios])\n</syntaxhighlight>\n}}\n\n===The <code>open</code> statement===\nThe statement is used to connect an external file to a unit,\ncreate a file that is preconnected, or create a file and connect it to a\nunit.\nThe syntax is\n<syntaxhighlight lang=fortran>\nopen (unit=u, status=st, action=act [,olist])\n</syntaxhighlight>\nwhere <code>olist</code> is a list of optional specifiers.\nThe specifiers may appear in any order.\n<syntaxhighlight lang=fortran>\nopen (unit=2, iostat=ios, file=\"cities\", status=\"new\", access=\"direct\",  &\n      action=\"readwrite\", recl=100)\n</syntaxhighlight>\nOther specifiers are <code>form</code> and <code>position</code>.\n\n===The <code>close</code> statement===\nThis is used to disconnect a file from a unit.\n<syntaxhighlight lang=fortran>\nclose (unit=u [,iostat=ios] [,status=st])\n</syntaxhighlight>\nas in\n<syntaxhighlight lang=fortran>\nclose (unit=2, iostat=ios, status=\"delete\")\n</syntaxhighlight>\n\n===The <code>inquire</code> statement===\nAt any time during the execution of a program it is possible to inquire about the status and attributes of a file using this statement.\n\nUsing a variant of this statement, it is similarly possible to determine the status of a unit, for instance whether the unit number exists for that system.\n\nAnother variant permits an inquiry about the length of an output list when used to write an unformatted record.\n\nFor inquire by unit\n<syntaxhighlight lang=fortran>\ninquire (unit=u, ilist)\n</syntaxhighlight>\nor for inquire by file\n<syntaxhighlight lang=fortran>\ninquire (file=fln, ilist)\n</syntaxhighlight>\nor for inquire by I/O list\n<syntaxhighlight lang=fortran>\ninquire (iolength=length) olist\n</syntaxhighlight>\nAs an example\n<syntaxhighlight lang=fortran>\nlogical            :: ex, op\ncharacter (len=11) :: nam, acc, seq, frm\ninteger            :: irec, nr\ninquire (unit=2, exist=ex, opened=op, name=nam, access=acc, sequential=seq, form=frm, &\n         recl=irec, nextrec=nr)\n</syntaxhighlight>\nyields\n<syntaxhighlight lang=fortran>\nex      .true.\nop      .true.\nnam      cities\nacc      DIRECT\nseq      NO\nfrm      UNFORMATTED\nirec     100\nnr       1\n</syntaxhighlight>\n(assuming no intervening read or write operations).\n\nOther specifiers are <code>iostat, opened, number,\nnamed, formatted, position, action, read, write, readwrite</code>.\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Fortran Language Features}}\n[[Category:Fortran|Features]]"
    },
    {
      "title": "FortranM",
      "url": "https://en.wikipedia.org/wiki/FortranM",
      "text": "'''FortranM''' is a [[computer language]] for modular [[parallel programming]].<ref>''Parallel and Distributed Computing Handbook'' by Albert Y. Zomaya 1995 {{ISBN|0-07-073020-2}} page 886</ref><ref>''Patterns for Parallel Software Design'' by Jorge Luis Ortega-Arjona 2010 {{ISBN|0-470-69734-2}}  page 22</ref> Its syntax is based on [[Fortran]] but has additional elements such as channels and ports for communication between processes.<ref name=Argonne />\n\nThe language was designed by [[K. Mani Chandy]]'s group at [[Caltech]], along with an [[Argonne national labs]] team.\n<ref name=Argonne >[http://ftp.mcs.anl.gov/pub/tech_reports/reports/ANL9326.pdf Argonne national labs FortranM]</ref> The compiler for the language is freely available from Argonne labs.<ref name=Argonne />\n\nIn FortranM processes communicate by sending and receiving messages on channels.<ref name=Argonne /> Processes and channels can be dynamically created, but programs remain deterministic.\n\n==Sources==\n{{Reflist}}\n\n[[Category:Fortran]]\n\n\n{{prog-lang-stub}}"
    },
    {
      "title": "Lois Haibt",
      "url": "https://en.wikipedia.org/wiki/Lois_Haibt",
      "text": "{{Infobox scientist\n| name = Lois Haibt\n| birth_name = Lois Mitchell\n| birth_date = 1934\n| birth_place = [[Chicago, Illinois]]\n| nationality = American\n| fields = [[Computer science]]\n| workplaces = [[IBM]], [[Thomas J. Watson Research Center]] <br> [[Bell Laboratories]]\n| alma_mater = [[Vassar College]]\n| known_for = Developer of [[FORTRAN]]\n| spouse = Luther Haibt\n| children = 1\n}}\n\n'''Lois Mitchell Haibt''' (born 1934) is an American [[computer scientist]] best known for being a member of the ten-person team at [[IBM]] that developed [[Fortran|FORTRAN]], the first successful high-level [[programming language]]. She is known as an early pioneer in computer science.\n\n== Education and career==\nHaibt studied mathematics at [[Vassar College]] with an academic scholarship. She graduated with a bachelor's degree in 1955. While at Vassar, Haibt worked at [[Bell Laboratories]] during the summer.<ref name=\":1\">{{Cite web|url=http://www.bobbemer.com/PRORES.HTM|title=The FORTRAN Builders|last=Bemer|first=Bob|website=www.bobbemer.com|access-date=2016-11-15}}</ref>\n\nImmediately after graduating from Vassar, Haibt began working at IBM.<ref name=\":3\">{{Cite book|url=https://books.google.com/books?id=n8jlOWI1ajwC&lpg=PA32&dq=lois%20haibt&pg=PA32#v=onepage&q=lois%20haibt|title=Go To: The Story of the Math Majors, Bridge Players, Engineers, Chess Wizards, Maverick Scientists and Iconoclasts - The Programmers Who Created the Software Revolution|last=Lohr|first=Steve|publisher=Basic Books|year=2002|isbn=978-0465042265|location=|pages=26–27|language=en|quote=|via=}}</ref> She started with an annual salary of $5,100, despite her lack of prior programming experience. This sum was almost double the amount that she would have made at Bell Laboratories. Haibt inferred that any job with such a high salary would be difficult, but fascinating.<ref name=\":2\">{{Cite web|url=http://www.fortran.bcs.org/2001/pioneers.html|title=Pioneers of the 'Fortran' Programming Language|last=Lohr|first=Steve|date=2001-06-13|website=www.fortran.bcs.org|access-date=2016-11-15}}</ref> She was part of an academically diverse team of ten young people with varying academic degrees and unrelated areas of expertise, such as crystallography and cryptography. Experience with mathematics was their one common connection.<ref name=\":2\" /> Haibt was the only woman on the team.<ref name=\":2\" />\n\nAccording to Haibt, the team worked well together: \"No one was worried about seeming stupid or possessive of his or her code. We were all just learning together.\"<ref name=\":3\" /> The FORTRAN team worked nontraditional hours so that they could have unlimited access to the [[IBM 704]] computer.<ref name=\":3\" /> They frequently rented rooms at the nearby Langdon Hotel in order to sleep during the day and work at night.<ref name=\":3\" />\n\nIn 1957, Haibt attended [[Columbia University]].<ref name=\":1\" />\n\nHaibt is a member of the [[Mathematical Association of America]].<ref name=\":1\" />\n\n==Research contributions==\nThe IBM team spent almost three years creating the programming language [[Fortran|FORTRAN]], which reformed the way people communicate instructions to computers.<ref name=\":2\" />\n\nHaibt was in charge of section four of the FORTRAN project.<ref name=\":4\">{{Cite web|url=http://www.softwarepreservation.org/projects/FORTRAN/paper/p165-backus.pdf|title=The History of Fortran I, II, and III|last=Backus|first=John|date=|website=Software Preservation Group|publisher=Computer History Museum|access-date=November 22, 2016}}</ref> She analyzed the flow of programs produced by other sections of the [[compiler]].<ref>{{Cite book|title=Rise of the Rocket Girls: The Women Who Propelled Us From Missiles to the Moon to Mars|last=Holt|first=Nathalia|publisher=Little, Brown|year=2016|isbn=9780316338912|location=|pages=|quote=|via=}}</ref> Her estimates of  flow in high-traffic areas of the computer were obtained by calculating how often basic blocks of the program would execute. Haibt employed [[Monte Carlo method]]s (statistical analysis) for these calculations.<ref name=\":3\" /> Through this process, she also created the first [[Parsing|syntactic analyzer of arithmetic expressions]].<ref>{{Cite journal|last=Lee|first=John A. N.|date=1996-06-01|title=History in the Computer Science Curriculum|journal=SIGCSE Bull.|volume=28|issue=2|pages=15–20|doi=10.1145/228296.228298|issn=0097-8418}}</ref> Haibt planned and programmed the entire section.<ref name=\":4\" />\nHaibt was also part of an eleven-person team to develop and release the first reference manual for FORTRAN in 1956.<ref>{{cite web|title=This Day in History: October 15|url=http://www.computerhistory.org/tdih/October/15/|website=Computer History Museum|publisher=Computer History Museum|accessdate=14 September 2017|ref=8}}</ref>\n\n==Personal life==\nLois Haibt was married to Luther Haibt (May 4, 1929 – December 3, 2000), a systems analyst at IBM in [[Thornwood, NY]].<ref name=\":0\">{{Cite news|url=https://www.nytimes.com/1989/02/12/style/carolyn-haibt-to-wed-edward-norton-in-fall.html|title=Carolyn Haibt to Wed Edward Norton in Fall|date=1989-02-12|newspaper=The New York Times|issn=0362-4331|access-date=2016-11-08}}</ref> The Haibts spent their adult lives in New York state. Haibt's daughter, Carolyn, attended [[Princeton University]] for her bachelor's degree and went on to receive a Ph.D. in mathematics from the [[Massachusetts Institute of Technology]].<ref name=\":0\" /> Haibt's hobbies include interior decorating and reading.<ref name=\":1\" />\n\n== Works ==\n*[http://archive.computerhistory.org/resources/text/Fortran/102663113.05.01.acc.pdf  Original Paper on FORTRAN from 1957]\n*[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703099 Casting Petri Nets into Programs, September 1983]\n\n==See also==\n*[[List of prominent pioneers in computer science]]\n\n==References ==\n{{Reflist}}\n\n==External links==\n*{{cite web\n| title = LOIS HAIBT: An Interview Conducted by Janet Abbate for the IEEE History Center, 2 August 2001\n| work = GHN: IEEE Global History Network\n| accessdate = 2013-11-29\n| url = http://www.ieeeghn.org/wiki/index.php/Oral-History:Lois_Haibt\n}}\n*{{cite web\n| title = Group Photo at 1982 Pioneer Day Banquet\n| work = Computer History Museum\n| accessdate = 2013-11-29\n| url = http://www.computerhistory.org/collections/catalog/102679273\n}}\n{{Timelines of computing}}\n{{Software engineering}}\n{{Authority control}}\n\n{{DEFAULTSORT:Haibt, Lois}}\n[[Category:Living people]]\n[[Category:American computer programmers]]\n[[Category:Fortran]]\n[[Category:Vassar College alumni]]\n[[Category:Women computer scientists]]\n[[Category:1934 births]]\n[[Category:People from Katonah, New York]]\n[[Category:IBM employees]]"
    },
    {
      "title": "Hollerith constant",
      "url": "https://en.wikipedia.org/wiki/Hollerith_constant",
      "text": "'''Hollerith constants''', named in honor of [[Herman Hollerith]], were used in early [[FORTRAN]] programs to allow manipulation of character data.\n\nEarly FORTRAN had no <code>CHARACTER</code> [[data type]], only numeric types.  In order to perform character manipulation, characters needed to be placed into numeric variables using Hollerith constants.  For example, the constant <code>3HABC</code> specified a three-character string \"ABC\", identified by the initial integer representing the string length <code>3</code> and the specified Hollerith character <code>H</code>, followed by the string data <code>ABC</code>.  These constants were ''[[typeless]]'', so that there were no [[type conversion]] issues.  If the constant specified fewer characters than was possible to hold in a data item, the characters were then stored in the item ''left-justified'' and ''blank-filled''.\n\n==Mechanics==\nBy the [[FORTRAN 66]] Standard, Hollerith syntax was allowed in the following uses:\n\n* As constants in <code>DATA</code> statements\n* As constant actual arguments in subroutine <code>CALL</code> statements\n* As edit descriptors in <code>FORMAT</code> statements\n\nPortability was problematic with Hollerith constants.  First, [[Word (data type)|word]] sizes varied on different computer systems, so the number of characters that could be placed in each data item likewise varied.  Implementations varied from as few as two to as many as ten characters per word.  Second, it was difficult to manipulate individual characters within a word in a portable fashion.  This led to a great deal of ''shifting and masking'' code using non-standard, vendor-specific, features.  The fact that character sets varied between machines also complicated the issue.\n\nSome authors were of the opinion that for best portability, only a single character should be used per data item.  However considering the small memory sizes of machines of the day, this technique was considered extremely wasteful.\n\n==Technological obsolescence==\nOne of the major features of FORTRAN 77 was the <code>CHARACTER</code> string data type.  Use of this data type dramatically simplified character manipulation in Fortran programs{{snd}} rendering almost all uses of the Hollerith constant technique obsolete.\n\nHollerith constants were removed from the FORTRAN 77 Standard, though still described in an appendix for those wishing to continue support.  Hollerith edit descriptors were allowed through Fortran 90, and were removed from the Fortran 95 Standard.\n\n==Examples==\nThe following is a FORTRAN 66 [[hello world]] program using Hollerith constants.  It assumes that at least four characters per word are supported by the implementation:\n\n<syntaxhighlight lang=\"fortranfixed\">\n      PROGRAM HELLO1\nC\n      INTEGER IHWSTR(3)\n      DATA IHWSTR/4HHELL,4HO WO,3HRLD/\nC\n      WRITE (6,100) IHWSTR\n      STOP\n  100 FORMAT (3A4)\n      END\n</syntaxhighlight>\n\nBesides <code>DATA</code> statements, Hollerith constants were also allowed as actual arguments in subroutine calls.  However, there was no way that the callee could know how many characters were passed in.  The programmer had to pass the information explicitly.  The [[hello world]] program could be written as follows{{snd}} on a machine where four characters are stored in a word:\n\n       '''PROGRAM''' HELLO2\n       '''CALL''' WRTOUT (11HHELLO WORLD, 11)\n       '''STOP'''\n       '''END'''\n C\n       '''SUBROUTINE''' WRTOUT (IARRAY, NCHRS)\n C\n       INTEGER IARRAY(1)<ref group=\"notes\">FORTRAN 66 did not have a way to indicate a variable-sized array.  So a '1' was typically used to indicate that the size is unknown.</ref>\n       INTEGER NCHRS\n C\n       INTEGER ICPW\n       DATA ICPW/4/<ref group=\"notes\">Four characters per word.</ref>\n       INTEGER I, NWRDS\n C\n       NWRDS = (NCHRS + ICPW - 1) /ICPW\n       WRITE (6,100) (IARRAY(I), I=1,NWRDS)\n       '''RETURN'''\n   100 FORMAT (100A4)<ref group=\"notes\">A count of 100 is a 'large enough' value that any reasonable number of characters can be written.  Also note that four characters per word is hard-coded here too.</ref>\n       '''END'''\n\nAlthough technically not a Hollerith constant, the same Hollerith syntax was allowed as an ''edit descriptor'' in <code>FORMAT</code> statements.  The [[hello world]] program could also be written as:\n\n<syntaxhighlight lang=\"fortranfixed\">\n      PROGRAM HELLO3\n      WRITE (6,100)\n      STOP\n  100 FORMAT (11HHELLO WORLD)\n      END\n</syntaxhighlight>\n\nOne of the most surprising features was the behaviour of Hollerith edit descriptors when used for input.  The following program would change at run time <code>HELLO WORLD</code> to whatever would happen to be the next eleven characters in the input stream and print that input:\n\n<syntaxhighlight lang=\"fortranfixed\">\n      PROGRAM WHAT1\n      READ (5,100)\n      WRITE (6,100)\n      STOP\n  100 FORMAT (11HHELLO WORLD)\n      END\n</syntaxhighlight>\n\n==Notes==\n{{reflist|group=notes}}\n\n==References==\n{{reflist}}\n*{{cite book |title= American Standard FORTRAN |publisher= American Standards Association, X3.9-1966 |pages= 38}}\n\n<blockquote>\n4.2.6 ''Hollerith Type''. A Hollerith datum is a string of characters.  This string may consist of any characters capable of representation in the processor.  The blank character is a valid and significant character in a Hollerith datum.\n</blockquote>\n\n[[Category:Fortran]]\n[[Category:String data structures]]"
    },
    {
      "title": "Roy Nutt",
      "url": "https://en.wikipedia.org/wiki/Roy_Nutt",
      "text": "{{more footnotes|date=October 2008}}\n{{Infobox person\n| name   = Roy Nutt\n| image     = \n| image_size     = \n| caption  = \n| birth_date  = October 20, 1930\n| birth_place = [[Marlborough, Massachusetts]], [[United States|U.S.]]\n| death_date  = June 14, 1990 (age 59)\n| death_place = [[Seattle, Washington]]\n| occupation  = Businessman:<br>Computer software\n}}\n'''Roy Nutt''' (October 20, 1930 &ndash; June 14, 1990) was an American [[businessman]] and [[computer]] pioneer. He was a co-creator of [[Fortran|FORTRAN]]<ref name=\"nyt-obit\">{{cite news\n| title = Roy Nutt Dies at 59; Helped to Develop Computer Language\n| last = Narvaez\n| first = Alfonso\n| date = June 20, 1990\n| work = [[New York Times]]\n| accessdate = 2008-10-05\n}}  As corrected June 22, 1990.</ref> and co-founded [[Computer Sciences Corporation]].\n \n==Fortran==\nBorn in [[Marlborough, Massachusetts]], Roy Nutt grew up in [[Glastonbury, Connecticut]]. He graduated in 1953 with a [[bachelor's degree]] in [[mathematics]] from [[Trinity College (Connecticut)|Trinity College]] in [[Hartford, Connecticut|Hartford]].\n\nA pioneer in the fledgling [[software]] industry of the 1950s, Roy Nutt was a major contributor in the creation of [[IBM|IBM's]] [[FORTRAN]], the first high-level scientific and engineering programming language. Part of the FORTRAN project's team, he was responsible for developing the computer command [[File format|FORMAT]], which controls data for input and output.\n\nNutt also created an assembler for the IBM 704 mainframe that is today seen as the most successful individual programming effort of the 1950s.{{citation needed|date=April 2017}}\n\n==SHARE==\nDuring this period, Roy Nutt met [[Fletcher R. Jones|Fletcher Jones]] when he joined with nineteen others from the aerospace industry to form the influential IBM user group known as [[SHARE (computing)|SHARE]] which developed [[SHARE Operating System|SOS]], one of the first operating systems. Jones, as secretary of the group, became its national spokesman and their working relationship would later result in a business partnership.\n\n==CSC==\nRoy Nutt had become a widely respected [[computer programmer]] for [[United Aircraft and Transport Corporation|United Aircraft Corp.]] in [[East Hartford, Connecticut]], where he developed the [[Symbolic Assembly Program]] for the IBM 704. He left in 1959 to team up with Fletcher Jones to establish [[Computer Sciences Corporation]] (CSC) in [[Los Angeles]].\n\nJones, who ran the business and marketing end of things, obtained a contract from [[Honeywell]] that gave their business profitability and respect within the industry. Nutt was responsible for building Honeywell the first commercial [[compiler]] ([[FACT (computer language)|FACT]]) and oversaw the company's major 1961 entry into the space industry when they obtained a contract to support the [[NASA]] [[Jet Propulsion Laboratory|Jet Propulsion Laboratory's]] Flight Operations Facility.\n\nWithin four years of its founding, CSC became the largest software company in the United States. Taking their business [[Public company|public]] with an [[Initial public offering|IPO]] listed on the [[American Stock Exchange]].  By the end of the 1960s, CSC was listed on the [[New York Stock Exchange]] and had operations in [[Canada]], the [[United Kingdom]], [[Germany]],  [[Italy]], and in [[The Netherlands]].\n\n==Later years==\nIn later years, Roy Nutt used some of his wealth to benefit Trinity College. He set up an endowment fund for a professorship and donated money to assist in the construction of the college's engineering and computing building. Trinity College honored him in May 2012 when they renamed the building the Roy Nutt Mathematics, Engineering & Computer Science Center.<ref>{{cite web\n| url = http://www.trincoll.edu/NewsEvents/NewsArticles/pages/NuttCenter.aspx\n| title = Trinity Honors the Leadership and Legacy of Roy Nutt '53\n| work = Trinity College\n| date = May 18, 2012\n}}</ref>\n\nRoy Nutt died of [[lung cancer]] in [[Seattle, Washington]] on June 14, 1990.<ref name=\"nyt-obit\" /><ref>{{cite web\n| url = http://www.mcjones.org/dustydecks/archives/2004/05/24/20/#comment-9\n| title = Comment to entry \"Daniel N. Leeson\"\n| last = Nutt\n| first = Micah\n| date = 2004-07-07\n| work = Dusty Decks\n| publisher = Paul McJones\n| accessdate = 2008-10-05\n}}</ref>\n\n==References==\n{{Reflist}}\n00\n\n==Further reading==\n* Pollock, John P. (1998) ''Fletcher Jones: An America Success Story''.   Los Angeles: Pollock.\n\n==External links==\n* [http://www.csc.com/about_us Computer Sciences Corporation website with company history]\n* [http://www.trincoll.edu/NewsEvents/NewsArticles/Documents/nutt-dedication-program-web.pdf Trinity College ME & CSC dedication program containing a short biography of Roy Nutt (by Micah Nutt)]\n{{Computer Sciences Corporation}}\n{{Authority control}}\n\n{{DEFAULTSORT:Nutt, Roy}}\n[[Category:1930 births]]\n[[Category:1990 deaths]]\n[[Category:American computer businesspeople]]\n[[Category:American philanthropists]]\n[[Category:Businesspeople in software]]\n[[Category:Deaths from lung cancer]]\n[[Category:Fortran]]\n[[Category:People from Glastonbury, Connecticut]]\n[[Category:People from Marlborough, Massachusetts]]\n[[Category:Trinity College (Connecticut) alumni]]\n[[Category:20th-century American businesspeople]]\n[[Category:20th-century philanthropists]]"
    },
    {
      "title": "OpenACC",
      "url": "https://en.wikipedia.org/wiki/OpenACC",
      "text": "{{Infobox software\n| name = OpenACC\n| logo = \n| author = \n| developer = \n| platform = [[Cross-platform]]\n| genre = [[Application programming interface|API]]\n| license = \n| website = {{URL|http://www.openacc.org/}}\n| latest_release_version = 2.7\n| latest_release_date = November 2018\n| programming_language = [[C (programming language)|C]], [[C++]], and [[Fortran]]\n| operating_system = [[Cross-platform]]\n}}\n'''OpenACC''' (for ''open accelerators'') is a programming standard for [[parallel computing]] developed by [[Cray]], CAPS, [[Nvidia]] and [[The Portland Group|PGI]]. The standard is designed to simplify parallel programming of [[Heterogeneous computing|heterogeneous]] [[Central processing unit|CPU]]/[[Graphics processing unit|GPU]] systems.<ref>{{cite web|url=http://www.theinquirer.net/inquirer/news/2124878/nvidia-cray-pgi-caps-launch-openacc-programming-standard-parallel-computing|title=Nvidia, Cray, PGI, and CAPS launch ‘OpenACC’ programming standard for parallel computing|date=4 November 2011|website=The Inquirer}}</ref>\n\nAs in [[OpenMP]], the programmer can annotate [[C (programming language)|C]], [[C++]] and [[Fortran]] [[source code]] to identify the areas that should be accelerated using [[compiler directives]] and additional functions.<ref name=OpenACC25>{{cite web |url=https://www.openacc.org/sites/default/files/inline-files/OpenACC_2pt5_0.pdf |title=OpenACC standard version 2.5|website=OpenACC.org|accessdate=2 June 2017}}</ref> Like OpenMP 4.0 and newer, OpenACC can target both the [[Central processing unit|CPU]] and [[Graphics processing unit|GPU]] architectures and launch computational code on them.\n\nOpenACC members have worked as members of the OpenMP standard group to merge into OpenMP specification to create a common specification which extends OpenMP to support accelerators in a future release of OpenMP.<ref>{{cite web|url=http://www.openacc.org/?q=node/49|title=How does the OpenACC API relate to the OpenMP API?|website=OpenACC.org|accessdate=14 January 2014}}</ref><ref>{{cite web|url=http://www.openacc.org/?q=node/47|title=How did the OpenACC specifications originate?|website=OpenACC.org|accessdate=14 January 2014}}</ref> These efforts resulted in a technical report<ref>{{cite web|url=http://openmp.org/wp/2012/11/the-openmp-consortium-releases-first-technical-report/|title=The OpenMP Consortium Releases First Technical Report|date=5 November 2012|website=OpenMP.org|accessdate=14 January 2014}}</ref> for comment and discussion timed to include the annual [[ACM/IEEE Supercomputing Conference|Supercomputing Conference]] (November 2012, [[Salt Lake City]]) and to address non-Nvidia accelerator support with input from hardware vendors who participate in OpenMP.<ref>{{cite web|url=http://openmp.org/wp/sc12|title=OpenMP at SC12|date=29 August 2012|website=OpenMP.org|accessdate=14 January 2014}}</ref>\n\nAt ISC’12 OpenACC was demonstrated to work on [[Nvidia]], [[Advanced Micro Devices|AMD]] and [[Intel]] accelerators, without performance data.<ref name=\"isc12\">{{cite web|url=http://www.hpcwire.com/hpcwire/2012-06-20/openacc_group_reports_expanding_support_for_accelerator_programming_standard.html|title=OpenACC Group Reports Expanding Support for Accelerator Programming Standard|date=20 June 2012|website=HPCwire|accessdate=14 January 2014|deadurl=yes|archiveurl=https://web.archive.org/web/20120623082310/http://www.hpcwire.com/hpcwire/2012-06-20/openacc_group_reports_expanding_support_for_accelerator_programming_standard.html|archivedate=23 June 2012|df=}}</ref>\n\nIn November 12, 2012, at the SC12 conference, a draft of the OpenACC version 2.0 specification was presented.<ref>{{cite web|url=http://www.openacc.org/?q=node/173|title=OpenACC Version 2.0 Posted for Comment|date=12 November 2012|website=OpenACC.org|accessdate=14 January 2014}}</ref> New suggested capabilities include new controls over data movement (such as better handling of unstructured data and improvements in support for non-contiguous memory), and support for explicit function calls and separate compilation (allowing the creation and reuse of libraries of accelerated code). OpenACC 2.0 was officially released in June 2013.<ref>{{Cite web|url=http://www.openacc.org/node/297|title=OpenACC 2.0 Spec {{!}} www.openacc.org|website=www.openacc.org|access-date=2016-03-23|archive-url=https://web.archive.org/web/20160404094455/http://www.openacc.org/node/297|archive-date=2016-04-04|dead-url=yes|df=}}</ref>\n\nVersion 2.5 of the specification was released on October 2015,<ref>{{Cite web|url=http://www.openacc.org/content/openacc-standards-group-announces-release-25-specification-member-vendors-add-support-arm|archive-url=https://archive.is/20160726113653/http://www.openacc.org/content/openacc-standards-group-announces-release-25-specification-member-vendors-add-support-arm|dead-url=yes|archive-date=2016-07-26|title=OpenACC Standards Group Announces Release of the 2.5 Specification; Member Vendors Add Support for ARM & x86 as Parallel Devices {{!}} www.openacc.org|website=www.openacc.org|access-date=2016-03-22}}</ref> while version 2.6 was released on November 2017.<ref>{{Cite web|url=https://www.openacc.org/blog/whats-new-openacc-26|title=What’s new in OpenACC 2.6? {{!}} OpenACC|website=www.openacc.org|language=en|access-date=2018-05-01}}</ref> The latest version of specification, version 2.7, was released on November 2018.<ref>{{Cite web|url=https://www.openacc.org/blog/whats-new-openacc-27|title=What’s new in OpenACC 2.7! {{!}} OpenACC|website=www.openacc.org|language=en|access-date=2019-01-07}}</ref>\n\nOn April 3 2019 John Levesque (the director of Cray Supercomputing Center of Excellence at [[Cray]]) announced that Cray are ending support for OpenACC in CCE/9.0. <ref>{{Cite web|url=https://twitter.com/hpc_guru/status/1113565651350589441|title=Cray’s views on #OpenACC vs #OpenMP|access-date=14 May 2019|}}</ref>\n\n== Compiler support ==\nSupport of OpenACC is available in commercial compilers from PGI (from version 12.6), and (for Cray hardware only) Cray.<ref name=\"isc12\"/><ref>{{cite web|url=http://www.xbitlabs.com/news/other/display/20111116234815_OpenACC_Standard_to_Help_Developers_to_Take_Advantage_of_GPU_Compute_Accelerators.html|title=OpenACC Standard to Help Developers to Take Advantage of GPU Compute Accelerators|date=16 November 2011|website=Xbit laboratories|accessdate=14 January 2014|deadurl=yes|archiveurl=https://web.archive.org/web/20140116104603/http://www.xbitlabs.com/news/other/display/20111116234815_OpenACC_Standard_to_Help_Developers_to_Take_Advantage_of_GPU_Compute_Accelerators.html|archivedate=16 January 2014|df=}}</ref>\n\nOpenUH<ref>{{cite web|url=http://web.cs.uh.edu/~openuh/|archive-url=https://web.archive.org/web/20140125202649/http://web.cs.uh.edu/~openuh/|dead-url=yes|archive-date=25 January 2014|title=OpenUH Compiler|accessdate=4 March 2014}}</ref> is an [[Open64]] based open source OpenACC compiler supporting C and FORTRAN, developed by HPCTools group from [[University of Houston]].\n\nOpenARC<ref>{{cite web|url=http://ft.ornl.gov/research/openarc/|title=OpenARC Compiler| accessdate=4 November 2014}}</ref> is an open source C compiler developed at [[Oak Ridge National Laboratory]] to support all features in the OpenACC 1.0 specification. An experimental{{r|phoronix-sep13}} open source compiler, accULL, is developed by the [[University of La Laguna]] ([[C (programming language)|C language]] only).<ref>{{cite web|url=http://accull.wordpress.com/|title=\naccULL The OpenACC research implementation|accessdate=14 January 2014}}</ref>\n\nIPMACC<ref>{{cite web|url=https://www.github.com/lashgar/ipmacc|title=IPMACC Compiler| accessdate=31 January 2017}}</ref> is an open source C compiler developed by [[University of Victoria]] that translates OpenACC to CUDA, OpenCL, and ISPC. Currently, only following directives are supported: ''data'', ''kernels'', ''loop'', and ''cache''.\n\n[[GNU Compiler Collection|GCC]] support for OpenACC was slow in coming.<ref>{{Cite web |first=Michael |last=Larabel |authorlink=Michael Larabel |title=OpenACC Still Not Loved By Open Compilers |website=[[Phoronix]] |date=4 December 2012 |url=https://www.phoronix.com/scan.php?page=news_item&px=MTI0MjM}}</ref> A GPU-targeting implementation from Samsung was announced in September 2013; this translated OpenACC 1.1-annotated code to [[OpenCL]].<ref name=\"phoronix-sep13\">{{Cite web |first=Michael |last=Larabel |authorlink=Michael Larabel |title=GCC Support Published For OpenACC On The GPU |website=[[Phoronix]] |date=30 September 2013 |url=https://www.phoronix.com/scan.php?page=news_item&px=MTQ3Mjg}}</ref> The announcement of a \"real\" implementation followed two months later, this time from NVIDIA and based on OpenACC 2.0.<ref>{{Cite web |first=Michael |last=Larabel |authorlink=Michael Larabel |title=OpenACC 2.0 With GPU Support Coming To GCC |website=[[Phoronix]] |date=14 November 2013 |url=https://www.phoronix.com/scan.php?page=news_item&px=MTUxNTE}}</ref> This sparked some controversy, as the implementation would only target NVIDIA's own [[Parallel Thread Execution|PTX]] assembly language, for which no open source assembler or runtime was available.<ref>{{Cite web |first=Michael |last=Larabel |authorlink=Michael Larabel |title=NVIDIA, Mentor Graphics May Harm GCC |website=[[Phoronix]] |date=15 November 2013 |url=https://www.phoronix.com/scan.php?page=news_item&px=MTUxNjM}}</ref><ref>{{Cite web |first=Michael |last=Larabel |authorlink=Michael Larabel |title=In-Fighting Continues Over OpenACC In GCC |website=[[Phoronix]] |date=21 November 2013 |url=https://www.phoronix.com/scan.php?page=news_item&px=MTUyMjA}}</ref> Experimental support for OpenACC/PTX did end up in GCC as of version 5.1. GCC6 and GCC7 release series include a much improved implementation of the OpenACC 2.0a specification.<ref>https://gcc.gnu.org/wiki/OpenACC</ref><ref>{{cite mailing list|url=https://gcc.gnu.org/ml/gcc-patches/2015-01/msg01258.html|title=Merge current set of OpenACC changes from gomp-4_0-branch |date=15 January 2015 |mailinglist=gcc |last=Schwinge |first=Thomas|accessdate=15 January 2015 |agency=gcc.gnu.org}}</ref> GCC 9.1 offers nearly complete OpenACC 2.5 support. <ref>{{Cite web |first=Jakub |last=Jelinek |title=GCC 9.1 Released |website=[[LWN.net]] |date=3 May 2019 |url=https://lwn.net/ml/gcc/20190503114328.GE2706%40tucnak/}}</ref>\n\n== Usage ==\n\nIn a way similar to [[OpenMP]] 3.x on homogeneous system or the earlier [[OpenHMPP]], the primary mode of programming in OpenACC is directives.<ref>{{cite web|url=http://www.drdobbs.com/parallel/easy-gpu-parallelism-with-openacc/240001776|title=Easy GPU Parallelism with OpenACC|date=11 June 2012|website=Dr.Dobb's|accessdate=14 January 2014}}</ref> The specifications also include a [[runtime library]] defining several support functions. To exploit them, user should include \"openacc.h\" in C or \"openacc_lib.h\" in Fortran;<ref>{{cite web|url=http://www.nvidia.com/docs/IO/116711/OpenACC-API.pdf|title=OpenACC API QuickReference Card, version 1.0|date=November 2011|website=NVidia|accessdate=14 January 2014}}</ref> and then call ''acc_init()'' function.\n\n=== Directives ===\nOpenACC defines an extensive list of pragmas (directives),<ref name=OpenACC20>{{cite web |url=http://www.openacc.org/sites/default/files/OpenACC%202%200.pdf |title=OpenACC standard version 2.0|website=OpenACC.org|accessdate=14 January 2014}}</ref> for example:\n<source lang=c>\n #pragma acc parallel\n #pragma acc kernels\n</source>\nBoth are used to define parallel computation kernels to be executed on the accelerator, using distinct semantics<ref>{{cite web|url=http://www.pgroup.com/lit/articles/insider/v4n2a1.htm|title=OpenACC Kernels and Parallel Constructs|date=August 2012|website=PGI insider|accessdate=14 January 2014}}</ref><ref>{{cite web|url=http://kb.caps-entreprise.com/openacc-parallel-section-vs-kernels/|title=OpenACC parallel section VS kernels|date=3 January 2013|website=CAPS entreprise Knowledge Base|accessdate=14 January 2014|deadurl=yes|archiveurl=https://web.archive.org/web/20140116093940/http://kb.caps-entreprise.com/openacc-parallel-section-vs-kernels/|archivedate=16 January 2014|df=}}</ref>\n\n<source lang=c>\n #pragma acc data\n</source>\nIs the main directive to define and copy data to and from the accelerator.\n\n<source lang=c>\n #pragma acc loop\n</source>\nIs used to define the type of parallelism in a <code>parallel</code> or <code>kernels</code> region.\n\n<source lang=c>\n #pragma acc cache\n #pragma acc update\n #pragma acc declare\n #pragma acc wait\n</source>\n\n=== Runtime API ===\nThere are some runtime [[API]] functions defined too: <code>acc_get_num_devices()</code>, <code>acc_set_device_type()</code>, <code>acc_get_device_type()</code>, <code>acc_set_device_num()</code>, <code>acc_get_device_num()</code>,\n<code>acc_async_test()</code>, <code>acc_async_test_all()</code>, <code>acc_async_wait()</code>, <code>acc_async_wait_all()</code>, <code>acc_init()</code>, <code>acc_shutdown()</code>, <code>acc_on_device()</code>, <code>acc_malloc()</code>, <code>acc_free()</code>.\n\nOpenACC generally takes care of work organisation for the target device however this can be overridden through the use of gangs and workers. A gang consists of workers and operates over a number of processing elements (as with a workgroup in OpenCL).\n\n== See also ==\n* [[C++ AMP]]\n* [[OpenCL]]\n* [[OpenHMPP]]\n* [[OpenMP]]\n\n==References==\n{{Reflist|30em}}\n\n==External links==\n* http://www.openacc.org/\n* Usage example from NVIDIA: [http://developer.nvidia.com/content/openacc-example-part-1 part1], [http://developer.nvidia.com/content/openacc-example-part-2 part2]\n\n{{Parallel Computing}}\n\n[[Category:Application programming interfaces]]\n[[Category:C programming language family]]\n[[Category:Fortran]]\n[[Category:Parallel computing]]\n[[Category:Standards]]"
    },
    {
      "title": "OpenHMPP",
      "url": "https://en.wikipedia.org/wiki/OpenHMPP",
      "text": "{{Multiple issues|\n{{third-party|date=August 2015}}\n{{one source|date=June 2014}}\n{{overly detailed|date=June 2014}}\n}}\n\n'''OpenHMPP''' (HMPP<ref>{{cite conference|url=http://www.caps-entreprise.com/wp-content/uploads/2012/08/caps-hmpp-gpgpu-Boston-Workshop-Oct-2007.pdf|title=HMPP: A Hybrid Multi-core Parallel Programming Environment|conference=Workshop on General Purpose Processing on Graphics Processing Units|conferenceurl=http://www.ece.neu.edu/GPGPU/GPGPU-1/|last1=Dolbeau|first1=Romain|last2=Bihan|first2=Stéphane|last3=Bodin|first3=François|date=4 October 2007|accessdate=14 January 2014|deadurl=yes|archiveurl=https://web.archive.org/web/20140116105646/http://www.caps-entreprise.com/wp-content/uploads/2012/08/caps-hmpp-gpgpu-Boston-Workshop-Oct-2007.pdf|archivedate=16 January 2014|df=}}</ref> for Hybrid Multicore Parallel Programming) - programming standard for [[heterogeneous computing]]. Based on a set of compiler directives, standard is a programming model designed to handle [[hardware accelerator]]s without the complexity associated with [[GPGPU|GPU programming]]. This approach based on directives has been implemented because they enable a loose relationship between an application code and the use of a hardware accelerator (HWA).\n\n== Introduction ==\nThe OpenHMPP directive-based programming model offers a syntax to offload computations on hardware accelerators and to optimize data movement to/from the hardware memory.\n\nThe model is based on works initialized by [http://www.irisa.fr/caps/ CAPS (Compiler and Architecture for Embedded and Superscalar Processors)], a common project from [[National Institute for Research in Computer Science and Control|INRIA]], [[French National Centre for Scientific Research|CNRS]], the [[University of Rennes 1]] and the INSA of Rennes.\n\n== OpenHMPP concept ==\n\nOpenHMPP is based on the concept of codelets, functions that can be remotely executed on HWAs.\n\n=== The OpenHMPP codelet concept ===\n\nA codelet has the following properties:\n# It is a [[pure function]].\n#* It does not contain [[Static variable|static]] or [[Volatile variable|volatile]] variable declarations nor refer to any global variables except if these have been declared by a HMPP directive “resident”\n#* It does not contain any function calls with an invisible body (that cannot be inlined). This includes the use of libraries and system functions such as malloc, printf, ...\n#* Every function call must refer to a static pure function (no function pointers).\n# It does not return any value (void function in [[C (programming language)|C]] or a subroutine in [[Fortran]]).\n# The number of arguments should be fixed (i.e. it can not be a [[variadic function]] as in [[stdarg.h]] in C).\n# It is not recursive.\n# Its parameters are assumed to be non-aliased (see [[Aliasing (computing)]] and [[Pointer aliasing]]).\n# It does not contain callsite directives (i.e. RPC to another codelet) or other HMPP directives.\nThese properties ensure that a codelet [[Remote procedure call|RPC]] can be remotely executed by a HWA. This RPC and its associated data transfers can be asynchronous.\n\n=== Codelet RPCs ===\nHMPP provides synchronous and asynchronous RPC. Implementation of asynchronous operation is hardware dependent.\n[[File:HMPP RPC.png|center|thumb|upright=1.75|Synchronous versus asynchronous RPC]]\n\n=== HMPP Memory Model ===\nHMPP considers two address spaces: the host processor one and the HWA memory.\n\n[[File:HMPP Memory Model.png|center|thumb|upright=1.7|HMPPP memory Model]]\n\n=== Directives concept ===\nThe OpenHMPP directives may be seen as “meta-information” added in the application source code. They are safe meta-information i.e. they do not change the original code behavior. They address the remote execution (RPC) of a function as well as the transfers of data to/from the HWA memory.\n\nThe table below introduces the OpenHMPP directives. OpenHMPP directives address different needs: some of them are dedicated to declarations and others are dedicated to the management of the execution.\n\n{| class=\"wikitable\"\n|- \n| \n! style=\"background: #412682; color: #FFFFFF;\" |Control flow instructions\n! style=\"background: #412682; color: #FFFFFF;\" | Directives for data management\n|- \n! style=\"background: #412682; color: #FFFFFF;\" | Declarations \n| codelet<br />group\n| resident<br />map<br />mapbyname \n|-\n! style=\"background: #412682; color: #FFFFFF;\" | Operational Directives \n| callsite<br />synchronize<br />region\n| allocate<br />release<br />advancedload<br />delegatedstore \n|}\n\n=== Concept of set of directives ===\nOne of the fundamental points of the HMPP approach is the concept of directives and their associated labels which makes it possible to expose a coherent structure on a whole set of directives disseminated in an application.\n\nThere are two kinds of labels: \n* One associated to a codelet. In general, the directives carrying this kind of labels are limited to the management of only one codelet (called stand-alone codelet in the remainder of the document to distinguish it from the group of codelets).\n* One associated to a group of codelets. These labels are noted as follow: “<LabelOfGroup>“, where “LabelOfGroup” is a name specified by the user. In general, the directives which have a label of this type relate to the whole group. The concept of group is reserved to a class of problems which requires a specific management of the data throughout the application to obtain performance.\n\n=== OpenHMPP Directives Syntax ===\nIn order to simplify the notations, [[regular expression]]s will be used to describe the syntax of the HMPP directives.\n\nThe color convention below is used for the description of syntax directives: \n* Reserved HMPP keywords are in <span style=\"color:#339933;\">'''green'''</span>;\n* Elements of grammar which can be declined in HMPP keywords are in <span style=\"color:#990000;\">'''red'''</span>;\n* User’s variables remain in black.\n\n==== General syntax ====\nThe general syntax of OpenHMPP directives is: \n* For C language:\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">></span> [codelet_label]? <span style=\"color:#990000;\">directive_type</span> [<span style=\"color:#339933;\">,</span><span style=\"color:#990000;\">directive_parameters</span>]* [<span style=\"color:#339933;\">&</span>]\n\n* For FORTRAN language:\n <span style=\"color:#339933;\">!$hmpp <</span>grp_label<span style=\"color:#339933;\">></span> [codelet_label]? <span style=\"color:#990000;\">directive_type</span> [<span style=\"color:#339933;\">,</span><span style=\"color:#990000;\">directive_parameters</span>]* [<span style=\"color:#339933;\">&</span>]\n\nWhere:\n*<code><grp_label></code>: is a unique identifier naming a group of codelets. In cases where no groups are defined in the application, this label can simply miss. Legal label name must follow this grammar: [a-z,A-Z,_][a-z,A-Z,0-9,_]*. Note that the “< >” characters belong to the syntax and are mandatory for this kind of label.\n*<code>codelet_label</code>: is a unique identifier naming a codelet. Legal label name must follow this grammar: [a-z,A-Z,_][a-z,A-Z,0-9,_]*\n*<code>directive</code>: is the name of the directive;\n*<code>directive_parameters</code>: designates some parameters associated to the directive. These parameters may be of different kinds and specify either some arguments given to the directive either a mode of execution (asynchronous versus synchronous for example);\n*<code>[&]</code>: is a character used to continue the directive on the next line (same for C and FORTRAN).\n\n==== Directive parameters ====\nThe parameters associated to a directive may be of different types. \nBelow are the directive parameters defined in OpenHMPP: \n* <code>version = major.minor[.micro]</code>: specifies the version of the HMPP directives to be considered by the preprocessor.\n* <code>args[arg_items].size={dimsize[,dimsize]*}</code>: specifies the size of a non scalar parameter (an array).\n* <code>args[arg_items].io=[in|out|inout]</code>: indicates that the specified function arguments are either input, output or both. By default, unqualified arguments are inputs.\n* <code>cond = \"expr\"</code>: specifies an execution condition as a boolean C or Fortran expression that needs to be true in order to start the execution of the group or codelets.\n* <code>target=target_name[:target_name]*</code>: specifies which targets to try to use in the given order.\n* <code>asynchronous</code>: specifies that the codelet execution is not blocking (default is synchronous).\n* <code>args[<arg_items>].advancedload=true</code>: indicates that the specified parameters are preloaded. Only in or inout parameters can be preloaded.\n* <code>args[arg_items].noupdate=true</code>: this property specifies that the data is already available on the HWA and so that no transfer is needed. When this property is set, no transfer is done on the considered argument\n* <code>args[<arg_items>].addr=\"<expr>\"</code>: <code><expr></code> is an expression that gives the address of the data to upload.\n* <code>args[<arg_items>].const=true</code>: indicates that the argument is to be uploaded only once.\n\n== OpenHMPP directives ==\n\n=== Directives for declaring and executing a codelet ===\nA <code>codelet</code> directive declares a computation to be remotely executed on a hardware accelerator.\nFor the <code>codelet</code> directive: \n*The codelet label is mandatory and must be unique in the application\n*The group label is not required if no group is defined.\n*The codelet directive is inserted just before the function declaration.\n\nThe syntax of the directive is:\n\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">></span> codelet_label <span style=\"color:#339933;\">codelet</span> \n                             [<span style=\"color:#339933;\">, version</span> = major.minor[.micro]?]?\n                             [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].io=</span>[[<span style=\"color:#339933;\">in</span>|<span style=\"color:#339933;\">out</span>|<span style=\"color:#339933;\">inout</span>]]*\n                             [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].size={</span>dimsize[,dimsize]*<span style=\"color:#339933;\">}</span>]*\n                             [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].const=true</span>]*\n                             [<span style=\"color:#339933;\">, cond =</span> \"expr\"]\n                             [<span style=\"color:#339933;\">, target=</span><span style=\"color:#990000;\">target_name</span>[:<span style=\"color:#990000;\">target_name</span>]*]\n\nMore than one codelet directive can be added to a function in order to specify different uses or different execution contexts. However, there can be only one codelet directive for a given call site label.\n\nThe <code>callsite</code> directive specifies how the use a codelet at a given point in the program.\n\nThe syntax of the directive is:\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">></span> codelet_label <span style=\"color:#339933;\">callsite</span>\n                      [<span style=\"color:#339933;\">, asynchronous</span>]?\n                      [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].size={</span>dimsize[,dimsize]*<span style=\"color:#339933;\">}</span>]*\n                      [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].advancedload=</span>[[<span style=\"color:#339933;\">true</span>|<span style=\"color:#339933;\">false</span>]]*\n                      [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].addr=\"</span>expr<span style=\"color:#339933;\">\"</span>]*\n                      [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].noupdate=true</span>]*\n\nAn example is shown here :\n<source lang=\"c\">\n /* declaration of the codelet */\n #pragma hmpp simple1 codelet, args[outv].io=inout, target=CUDA\n static void matvec(int sn, int sm, float inv[sm], float inm[sn][sm], float *outv){\n     int i, j;\n     for (i = 0 ; i < sm ; i++) {\n       float temp = outv[i];\n       for (j = 0 ; j < sn ; j++) {\n         temp += inv[j] * inm[i][ j];\n     }\n    outv[i] = temp;\n  }\n  \n  int main(int argc, char **argv) {\n    int n;\n    ........\n  \n  /* codelet use */\n  #pragma hmpp simple1 callsite, args[outv].size={n}\n  matvec(n, m, myinc, inm, myoutv);\n    ........\n  }\n</source>\nIn some cases, a specific management of the data throughout the application is required (CPU/GPU data movements optimization, shared variables...).\n\nThe <code>group</code> directive allows the declaration of a group of codelets. The parameters defined in this directive are applied to all codelets belonging to the group. \nThe syntax of the directive is:\n\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">> group</span> \n                           [<span style=\"color:#339933;\">, version =</span> <major>.<minor>[.<micro>]?]? \n                           [<span style=\"color:#339933;\">, target =</span> <span style=\"color:#990000;\">target_name</span>[:<span style=\"color:#990000;\">target_name</span>]*]]? \n                           [<span style=\"color:#339933;\">, cond  = “</span>expr<span style=\"color:#339933;\">”</span>]?\n\n=== Data transfers directives to optimize communication overhead ===\nWhen using a HWA, the main bottleneck is often the data transfers between the HWA and the main processor.<br />\nTo limit the communication overhead, data transfers can be overlapped with successive executions of the same codelet by using the asynchronous property of the HWA.\n\n* allocate directive\nThe <code>allocate</code> directive locks the HWA and allocates the needed amount of memory.\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">> allocate</span> [<span style=\"color:#339933;\">,args[</span>arg_items<span style=\"color:#339933;\">].size={</span>dimsize[,dimsize]*<span style=\"color:#339933;\">}</span>]*\n\n* release directive\nThe <code>release</code> directive specifies when to release the HWA for a group or a stand-alone codelet.\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">> release</span>\n\n* advancedload directive\nThe <code>advancedload</code> directive prefetches data before the remote execution of the codelet.<br />\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">></span> [codelet_label]? <span style=\"color:#339933;\">advancedload</span>\n                   <span style=\"color:#339933;\">,args[</span>arg_items<span style=\"color:#339933;\">]</span>\n                   [<span style=\"color:#339933;\">,args[</span>arg_items<span style=\"color:#339933;\">].size={</span>dimsize[,dimsize]*<span style=\"color:#339933;\">}</span>]*\n                   [<span style=\"color:#339933;\">,args[</span>arg_items<span style=\"color:#339933;\">].addr=\"</span>expr<span style=\"color:#339933;\">\"</span>]*\n                   [<span style=\"color:#339933;\">,args[</span>arg_items<span style=\"color:#339933;\">].section={</span>[<span style=\"color:#990000;\">subscript_triplet</span><span style=\"color:#339933;\">,</span>]+<span style=\"color:#339933;\">}</span>]*\n                   [<span style=\"color:#339933;\">,asynchronous</span>]\n\n* delegatedstore directive\nThe <code>delegatedstore</code> directive is a synchronization barrier to wait for an asynchronous codelet execution to complete and to then download the results.<br />\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">></span> [codelet_label]? <span style=\"color:#339933;\">delegatedstore</span> \n                 <span style=\"color:#339933;\">,args[</span>arg_items<span style=\"color:#339933;\">]</span>\n                 [<span style=\"color:#339933;\">,args[</span>arg_items<span style=\"color:#339933;\">].addr=\"</span>expr<span style=\"color:#339933;\">\"</span>]*\n                 [<span style=\"color:#339933;\">,args[</span>arg_items<span style=\"color:#339933;\">].section={</span>[<span style=\"color:#990000;\">subscript_triplet</span><span style=\"color:#339933;\">,</span>]+<span style=\"color:#339933;\">}</span>]*\n\n* Asynchronous Computations\nThe <code>synchronize</code> directive specifies to wait until the completion of an asynchronous callsite execution. \nFor the synchronize directive, the codelet label is always mandatory and the group label is required if the codelet belongs to a group.\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">></span> codelet_label <span style=\"color:#339933;\">synchronize</span>\n\n* Example\nIn the following example, the device initialization, memory allocation and upload of the input data are done only once outside the loop and not in each iteration of the loop.\n\nThe <code>synchronize</code> directive allows to wait for the asynchronous execution of the codelet to complete before launching another iteration. Finally the <code>delegatedstore</code> directive outside the loop uploads the sgemm result.\n<source lang=\"c\">\n int main(int argc, char **argv) {\n \n #pragma hmpp sgemm allocate, args[vin1;vin2;vout].size={size,size}\n #pragma hmpp sgemm advancedload, args[vin1;vin2;vout], args[m,n,k,alpha,beta]\n   \n for ( j = 0 ; j < 2 ; j ++) {\n    #pragma hmpp sgemm callsite, asynchronous, args[vin1;vin2;vout].advancedload=true, args[m,n,k,alpha,beta].advancedload=true\n    sgemm (size, size, size, alpha, vin1, vin2, beta, vout);\n    #pragma hmpp sgemm  synchronize\n }\n \n #pragma hmpp sgemm delegatedstore, args[vout]\n #pragma hmpp sgemm release\n</source>\n\n=== Sharing data between codelets ===\nThose directives map together all the arguments sharing the given name for all the group.\n\nThe types and dimensions of all mapped arguments must be identical.\n\nThe <code>map</code> directive maps several arguments on the device. \n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">>  map, args[</span>arg_items<span style=\"color:#339933;\">]</span>\n\nThis directive is quite similar as the <code>map</code> directive except that the arguments to be mapped are directly specified by their name. The <code>mapbyname</code> directive is equivalent to multiple <code>map</code> directives. \n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">> mapbyname</span> [<span style=\"color:#339933;\">,</span>variableName]+\n\n=== Global variable ===\nThe <code>resident</code> directive declares some variables as global within a group. Those variables can then be directly accessed from any codelet belonging to the group. \nThis directive applies to the declaration statement just following it in the source code.\n\nThe syntax of this directive is:\n\n <span style=\"color:#339933;\">#pragma hmpp <</span>grp_label<span style=\"color:#339933;\">> resident</span> \n                [<span style=\"color:#339933;\">, args[::</span>var_name<span style=\"color:#339933;\">].io=</span>[[<span style=\"color:#339933;\">in</span>|<span style=\"color:#339933;\">out</span>|<span style=\"color:#339933;\">inout</span>]]*\n                [<span style=\"color:#339933;\">, args[::</span>var_name<span style=\"color:#339933;\">].size={</span>dimsize[,dimsize]*<span style=\"color:#339933;\">}</span>]*\n                [<span style=\"color:#339933;\">, args[::</span>var_name<span style=\"color:#339933;\">].addr=\"</span>expr<span style=\"color:#339933;\">\"</span>]*\n                [<span style=\"color:#339933;\">, args[::</span>var_name<span style=\"color:#339933;\">].const=true</span>]*\n\nThe notation <code>::var_name</code>  with the prefix <code>::</code>, indicates an  application’s variable declared as resident.\n\n=== Acceleration of regions ===\nA region is a merge of the codelet/callsite directives. The goal is to avoid code restructuration to build the codelet. Therefore, all the attributes available for <code>codelet</code> or <code>callsite</code> directives can be used on <code>regions</code> directives.\n\nIn C language:\n\n <span style=\"color:#339933;\">#pragma hmpp [<</span>MyGroup<span style=\"color:#339933;\">>] [</span>label<span style=\"color:#339933;\">] region</span>         \n                            [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].io=</span>[[<span style=\"color:#339933;\">in</span>|<span style=\"color:#339933;\">out</span>|<span style=\"color:#339933;\">inout</span>]]*\n                            [<span style=\"color:#339933;\">, cond = \"</span>expr<span style=\"color:#339933;\">\"]</span><\n                            [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].const=true</span>]*\n                            [<span style=\"color:#339933;\">, target=</span><span style=\"color:#990000;\">target_name</span>[<span style=\"color:#339933;\">:</span><span style=\"color:#990000;\">target_name</span>]*]\n                            [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].size={</span>dimsize[<span style=\"color:#339933;\">,</span>dimsize]*<span style=\"color:#339933;\">}</span>]*\n                            [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].advancedload=</span>[[<span style=\"color:#339933;\">true</span>|<span style=\"color:#339933;\">false</span>]]*\n                            [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].addr=\"</span>expr<span style=\"color:#339933;\">\"</span>]*\n                            [<span style=\"color:#339933;\">, args[</span>arg_items<span style=\"color:#339933;\">].noupdate=true</span>]*\n                            [<span style=\"color:#339933;\">, asynchronous</span>]?\n                            [<span style=\"color:#339933;\">, private=[</span>arg_items<span style=\"color:#339933;\">]</span>]*\n    {\n C BLOCK STATEMENTS\n    }\n\n== Implementations ==\nThe OpenHMPP Open Standard is based on HMPP Version 2.3 (May 2009, CAPS entreprise).\n\nThe OpenHMPP directive-based programming model is implemented in:\n* CAPS Compilers, CAPS Entreprise compilers for hybrid computing\n* PathScale ENZO Compiler Suite (support the NVIDIA GPUs)\n\nOpenHMPP is used by [[High-performance computing|HPC]] actors{{who|date=August 2015}} in Oil & Gas,{{Citation needed|date=August 2015}} Energy,{{Citation needed|date=August 2015}} Manufacturing,{{Citation needed|date=August 2015}} Finance,{{Citation needed|date=August 2015}} Education & Research.{{Citation needed|date=August 2015}}\n\n== See also ==\n* [[GPGPU]]\n* [[Parallel computing]]\n* [[OpenACC]]\n* [[OpenCL]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* [http://investing.businessweek.com/research/stocks/private/snapshot.asp?privcapId=2839086 CAPS Entreprise SAS and PathScale, Inc to Jointly Collaborate on Making HMPP a New Open Standard]\n* [http://www.informit.com/articles/article.aspx?p=1638075 How Hardware Will Shape Languages] By David Chisnall\n* [https://web.archive.org/web/20110721124847/http://www.ichec.ie/research/hmpp_intro.pdf Code acceleration with HMPP] By ICHEC (Irish Center for High-End Computing)\n* [https://archive.is/20130107142446/http://www-irma.u-strasbg.fr/irmawiki/index.php?title=Expérience_de_programmation_avec_HMPP&redirect=no Expérience de programmation avec HMPP] By IRMA (Institut de Recherche Mathématique Avancée) - FORTRAN examples\n* [http://www.iiis.org/CDs2008/CD2009SCI/CCCT2009/PapersPdf/T030UF.pdf Directive-based Heterogeneous Programming - A GPU-Accelerated RTM Use Case] By TOTAL Technical and Scientific Center and CAPS Entreprise\n* [http://www.prace-project.eu/documents/04_teslahmpp_gcdv.pdf HMPP Port] By CEA (Commissariat à l'Energie Atomique et aux Energies Alternatives) for PRACE (Partnership for Advanced Computing in Europe)\n\n{{Parallel computing}}\n\n[[Category:Application programming interfaces]]\n[[Category:C programming language family]]\n[[Category:Fortran]]\n[[Category:Parallel computing]]"
    },
    {
      "title": "OpenMP",
      "url": "https://en.wikipedia.org/wiki/OpenMP",
      "text": "{{Infobox software\n| name = OpenMP\n| logo = [[File:OpenMP logo.png|OpenMP logo|180px]]\n| author = OpenMP Architecture Review Board<ref name=\"Board\">{{cite web |url=http://openmp.org/wp/about-openmp/ |title=About the OpenMP ARB and |publisher=OpenMP.org |date=2013-07-11 |accessdate=2013-08-14 |deadurl=yes |archiveurl=https://web.archive.org/web/20130809153922/http://openmp.org/wp/about-openmp/ |archivedate=2013-08-09 |df= }}</ref>\n| developer = OpenMP Architecture Review Board<ref name=\"Board\" />\n| latest_release_version = 5.0\n| latest_release_date = {{start date and age|2018|11|8}}\n| operating_system = [[Cross-platform]]\n| platform = Cross-platform\n| genre = Extension to [[C (programming language)|C]], [[C++]], and [[Fortran]]; [[application programming interface|API]]\n| license = Various<ref name=\"openmp.org\">{{cite web|url=http://openmp.org/wp/openmp-compilers/ |title=OpenMP Compilers |publisher=OpenMP.org |date=2013-04-10 |accessdate=2013-08-14}}</ref>\n| website = {{URL|openmp.org}}\n}}\n\n'''OpenMP''' ('''Open Multi-Processing''') is an [[application programming interface]] (API) that supports multi-platform [[shared memory architecture|shared memory]] [[multiprocessing]] programming in [[C (programming language)|C]], [[C++]], and [[Fortran]],<ref name=OSConcepts>{{cite book|last=Gagne|first=Abraham Silberschatz, Peter Baer Galvin, Greg|title=Operating system concepts|publisher=Wiley|location=Hoboken, N.J.|isbn=978-1-118-06333-0|pages=181–182|edition=9th|date=2012-12-17}}</ref> on most platforms, [[instruction set architecture]]s and [[operating system]]s, including [[Solaris (operating system)|Solaris]], [[IBM AIX|AIX]], [[HP-UX]], [[Linux]], [[macOS]], and [[Microsoft Windows|Windows]]. It consists of a set of [[compiler directive]]s, [[library (computing)|library routines]], and [[environment variable]]s that influence run-time behavior.<ref name=\"openmp.org\" /><ref>[http://openmp.org/wp/2008/10/openmp-tutorial-at-supercomputing-2008/ OpenMP Tutorial at Supercomputing 2008]</ref><ref>[http://openmp.org/wp/2009/04/download-book-examples-and-discuss/ Using OpenMP – Portable Shared Memory Parallel Programming – Download Book Examples and Discuss]</ref>\n\nOpenMP is managed by the [[nonprofit organization|nonprofit]] technology [[consortium]] ''OpenMP Architecture Review Board'' (or ''OpenMP ARB''), jointly defined by a group of major computer hardware and software vendors, including [[AMD]], [[IBM]], [[Intel]], [[Cray]], [[Hewlett-Packard|HP]], [[Fujitsu]], [[Nvidia]], [[NEC]], [[Red Hat]], [[Texas Instruments]], [[Oracle Corporation]], and more.<ref name=\"Board\" />\n\nOpenMP uses a [[software portability|portable]], scalable model that gives [[programmer]]s a simple and flexible interface for developing parallel applications for platforms ranging from the standard [[desktop computer]] to the [[supercomputer]].\n\nAn application built with the hybrid model of [[parallel programming]] can run on a [[computer cluster]] using both OpenMP and [[Message Passing Interface]] (MPI), such that OpenMP is used for parallelism ''within'' a (multi-core) node while MPI is used for parallelism ''between'' nodes. There have also been efforts to run OpenMP on [[distributed shared memory|software distributed shared memory]] systems,<ref>{{cite journal |last=Costa |first=J.J.|display-authors=etal|date=May 2006 |title=Running OpenMP applications efficiently on an everything-shared SDSM |journal=Journal of Parallel and Distributed Computing |volume=66 |issue=5 |pages=647–658 |doi=10.1016/j.jpdc.2005.06.018 }}</ref> to translate OpenMP into MPI<ref>{{cite book |last=Basumallik |first=Ayon |last2=Min |first2=Seung-Jai |last3=Eigenmann |first3=Rudolf |title=Programming Distributed Memory Sytems [sic] using OpenMP |journal=Proceedings of the 2007 IEEE International Parallel and Distributed Processing Symposium |pages=1–8 |location=New York |publisher=IEEE Press |year=2007 |doi=10.1109/IPDPS.2007.370397|isbn=978-1-4244-0909-9 |citeseerx=10.1.1.421.8570 }} A [https://www.cs.rochester.edu/~cding/Announcements/HIPS07/openmp.pdf preprint is available on Chen Ding's home page]; see especially Section 3 on Translation of OpenMP to MPI.</ref><ref>{{cite journal |last=Wang |first=Jue |last2=Hu |first2=ChangJun |last3=Zhang |first3=JiLin |last4=Li |first4=JianJiang |date=May 2010 |title=OpenMP compiler for distributed memory architectures |journal=Science China Information Sciences |volume=53 |issue=5 |pages=932–944 |doi=10.1007/s11432-010-0074-0 }} ({{as of|2016}} the KLCoMP software described in this paper does not appear to be publicly available)</ref> and to extend OpenMP for non-shared memory systems.<ref>[https://software.intel.com/en-us/articles/cluster-openmp-for-intel-compilers Cluster OpenMP] (a product that used to be available for [[Intel C++ Compiler]] versions 9.1 to 11.1 but was dropped in 13.0)</ref>\n\n== Design ==\n[[File:Fork join.svg|thumb|An illustration of [[Thread (computer science)|multithreading]] where the master thread forks off a number of threads which execute blocks of code in parallel.]]\n{{See also|Fork–join model}}\n\nOpenMP is an implementation of [[Thread (computer science)|multithreading]], a method of parallelizing whereby a 'master' thread (a series of instructions executed consecutively) [[Fork (system call)|''forks'']] a specified number of sub-threads and the system divides a task among them. The threads then run [[Concurrent computing|concurrently]], with the [[runtime environment]] allocating threads to different processors.\n\nThe section of code that is meant to run in parallel is marked accordingly, with a compiler directive that will cause the threads to form before the section is executed.<ref name=OSConcepts /> Each thread has an ''id'' attached to it which can be obtained using a [[Function (computer science)|function]] (called <code>omp_get_thread_num()</code>). The thread id is an integer, and the master thread has an id of ''0''. After the execution of the parallelized code, the threads ''join'' back into the master thread, which continues onward to the end of the program.\n\nBy default, each thread executes the parallelized section of code independently. ''Work-sharing constructs'' can be used to divide a task among the threads so that each thread executes its allocated part of the code. Both [[task parallelism]] and [[data parallelism]] can be achieved using OpenMP in this way.\n\nThe runtime environment allocates threads to processors depending on usage, machine load and other factors. The runtime environment can assign the number of threads based on [[environment variable]]s, or the code can do so using functions. The OpenMP functions are included in a [[header file]] labelled <tt>omp.h</tt> in [[C (programming language)|C]]/[[C++]].\n\n== History ==\nThe OpenMP Architecture Review Board (ARB) published its first API specifications, OpenMP for Fortran 1.0, in October 1997.   In  October the following year they released the C/C++ standard.  2000 saw version 2.0 of the Fortran specifications with version 2.0 of the C/C++ specifications being released in 2002.  Version 2.5 is a combined C/C++/Fortran specification that was released in 2005.\n\nUp to version 2.0, OpenMP primarily specified ways to parallelize highly regular loops, as they occur in matrix-oriented [[numerical programming]], where the number of iterations of the loop is known at entry time. This was recognized as a limitation, and various task parallel extensions were added to implementations. In 2005, an effort to standardize task parallelism was formed, which published a proposal in 2007, taking inspiration from task parallelism features in [[Cilk]], [[X10 (programming language)|X10]] and [[Chapel (programming language)|Chapel]].<ref>{{cite conference |first1=Eduard |last1=Ayguade |first2=Nawal |last2=Copty |first3=Alejandro |last3=Duran |first4=Jay |last4=Hoeflinger |first5=Yuan |last5=Lin |first6=Federico |last6=Massaioli |first7=Ernesto |last7=Su |first8=Priya |last8=Unnikrishnan |first9=Guansong |last9=Zhang |title=A proposal for task parallelism in OpenMP |conference=Proc. Int'l Workshop on OpenMP |year=2007 |url=http://people.ac.upc.edu/aduran/papers/2007/tasks_iwomp07.pdf}}</ref>\n\nVersion 3.0 was released in May 2008. Included in the new features in 3.0 is the concept of ''tasks'' and the ''task'' construct,<ref>{{cite web|url=http://www.openmp.org/mp-documents/spec30.pdf |title=OpenMP Application Program Interface, Version 3.0 |date=May 2008 |accessdate=2014-02-06 |publisher=openmp.org}}</ref> significantly broadening the scope of OpenMP beyond the parallel loop constructs that made up most of OpenMP 2.0.<ref>{{cite conference |title=A Runtime Implementation of OpenMP Tasks |first1=James |last1=LaGrone |first2=Ayodunni |last2=Aribuki |first3=Cody |last3=Addison |first4=Barbara |last4=Chapman |conference=Proc. Int'l Workshop on OpenMP |year=2011 |pages=165–178 |doi=10.1007/978-3-642-21487-5_13 |citeseerx=10.1.1.221.2775}}</ref>\n\nVersion 4.0 of the specification was released in July 2013.<ref>{{cite web |url=http://openmp.org/wp/openmp-40-api-released/ |title=OpenMP 4.0 API Released |publisher=OpenMP.org |date=2013-07-26 |accessdate=2013-08-14 |deadurl=yes |archiveurl=https://web.archive.org/web/20131109175921/http://openmp.org/wp/openmp-40-api-released/ |archivedate=2013-11-09 |df= }}</ref>  It adds or improves the following features: support for [[hardware acceleration|accelerators]]; [[linearizability|atomics]]; error handling; [[processor affinity|thread affinity]]; tasking extensions; user defined [[fold (higher-order function)|reduction]]; [[SIMD]] support; [[Fortran 2003]] support.<ref>{{cite web|url=http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf |title=OpenMP Application Program Interface, Version 4.0 |date=July 2013 |accessdate=2014-02-06 |publisher=openmp.org}}</ref>{{full citation needed|date=March 2015}}\n\nThe current version is 5.0, released in November 2018.\n\nNote that not all compilers (and OSes) support the full set of features for the latest version/s.\n\n== Core elements ==\n[[File:OpenMP language extensions.svg|thumb|Chart of OpenMP constructs]]\n\nThe core elements of OpenMP are the constructs for thread creation, workload distribution (work sharing), data-environment management, thread synchronization, user-level runtime routines and environment variables.\n\nIn C/C++, OpenMP uses [[C preprocessor#Compiler-specific preprocessor features|#pragmas]]. The OpenMP specific pragmas are listed below.\n\n=== Thread creation ===\nThe pragma ''omp parallel'' is used to fork additional threads to carry out the work enclosed in the construct in parallel. The original thread will be denoted as ''master thread'' with thread ID 0.\n\nExample (C program): Display \"Hello, world.\" using multiple threads.\n\n<syntaxhighlight lang=c>\n#include <stdio.h>\n#include <omp.h>\n\nint main(void)\n{\n    #pragma omp parallel\n    printf(\"Hello, world.\\n\");\n    return 0;\n}\n</syntaxhighlight>\n\nUse flag -fopenmp to compile using GCC:\n<syntaxhighlight lang=bash>\n$ gcc -fopenmp hello.c -o hello\n</syntaxhighlight>\n\nOutput on a computer with two cores, and thus two threads:\n\n<syntaxhighlight lang=bash>\nHello, world.\nHello, world.\n</syntaxhighlight>\n\nHowever, the output may also be garbled because of the [[race condition]] (in the case of using C++ <code>std::cout</code>, for example, the example is always true. <code>printf</code> can be or not thread-safe) caused from the two threads sharing the [[standard output]].\n<syntaxhighlight lang=bash>\nHello, wHello, woorld.\nrld.\n\n</syntaxhighlight>\n\n=== Work-sharing constructs ===\nUsed to specify how to assign independent work to one or all of the threads.\n* ''omp for'' or ''omp do'': used to [[Map (parallel pattern)|split up loop iterations]] among the threads, also called loop constructs.\n* ''sections'': assigning consecutive but independent code blocks to different threads\n* ''single'': specifying a code block that is executed by only one thread, a barrier is implied in the end\n* ''master'': similar to single, but the code block will be executed by the master thread only and no barrier implied in the end.\nExample: initialize the value of a large array in parallel, using each thread to do part of the work\n\n<source lang=\"c\">\nint main(int argc, char **argv)\n{\n    int a[100000];\n\n    #pragma omp parallel for\n    for (int i = 0; i < 100000; i++) {\n        a[i] = 2 * i;\n    }\n\n    return 0;\n}\n</source>\n\nThis example is [[embarrassingly parallel]], and depends only on the value of {{mono|i}}. The OpenMP {{mono|parallel for}} flag tells the OpenMP system to split this task among its working threads. The threads will each receive a unique and private version of the variable.<ref>{{Cite web | url=http://supercomputingblog.com/openmp/tutorial-parallel-for-loops-with-openmp/ | title=Tutorial – Parallel for Loops with OpenMP| date=2009-07-14}}</ref> For instance, with two worker threads, one thread might be handed a version of {{mono|i}} that runs from 0 to 49999 while the second gets a version running from 50000 to 99999.\n\n=== Clauses ===\n\nSince OpenMP is a shared memory programming model, most variables in OpenMP code are visible to all threads by default. But sometimes private variables are necessary to avoid [[race condition]]s and there is a need to pass values between the sequential part and the parallel region (the code block executed in parallel), so data environment management is introduced as ''data sharing attribute clauses'' by appending them to the OpenMP directive. The different types of clauses are:\n\n; Data sharing attribute clauses:\n* ''shared'': the data within a parallel region is shared, which means visible and accessible by all threads simultaneously. By default, all variables in the work sharing region are shared except the loop iteration counter.\n* ''private'': the data within a parallel region is private to each thread, which means each thread will have a local copy and use it as a temporary variable. A private variable is not initialized and the value is not maintained for use outside the parallel region. By default, the loop iteration counters in the OpenMP loop constructs are private.\n* ''default'': allows the programmer to state that the default data scoping within a parallel region will be either ''shared'', or ''none'' for C/C++, or ''shared'', ''firstprivate'', ''private'', or ''none'' for Fortran.  The ''none'' option forces the programmer to declare each variable in the parallel region using the data sharing attribute clauses.\n* ''firstprivate'': like ''private'' except initialized to original value.\n* ''lastprivate'': like ''private'' except original value is updated after construct.\n* ''reduction'': a safe way of joining work from all threads after construct.\n\n; Synchronization clauses:\n* ''critical'': the enclosed code block will be executed by only one thread at a time, and not simultaneously executed by multiple threads. It is often used to protect shared data from [[race condition]]s.\n* ''atomic'': the memory update (write, or read-modify-write) in the next instruction will be performed atomically. It does not make the entire statement atomic; only the memory update is atomic. A compiler might use special hardware instructions for better performance than when using ''critical''.\n* ''ordered'': the structured block is executed in the order in which iterations would be executed in a sequential loop\n* ''barrier'': each thread waits until all of the other threads of a team have reached this point. A work-sharing construct has an implicit barrier synchronization at the end.\n*''nowait'': specifies that threads completing assigned work can proceed without waiting for all threads in the team to finish. In the absence of this clause, threads encounter a barrier synchronization at the end of the work sharing construct.\n\n; Scheduling clauses:\n*''schedule(type, chunk)'': This is useful if the work sharing construct is a do-loop or for-loop. The iteration(s) in the work sharing construct are assigned to threads according to the scheduling method defined by this clause. The three types of scheduling are:\n#''static'': Here, all the threads are allocated iterations before they execute the loop iterations. The iterations are divided among threads equally by default. However, specifying an integer for the parameter ''chunk'' will allocate chunk number of contiguous iterations to a particular thread.\n#''dynamic'': Here, some of the iterations are allocated to a smaller number of threads. Once a particular thread finishes its allocated iteration, it returns to get another one from the iterations that are left. The parameter ''chunk'' defines the number of contiguous iterations that are allocated to a thread at a time.\n#''guided'': A large chunk of contiguous iterations are allocated to each thread dynamically (as above). The chunk size decreases exponentially with each successive allocation to a minimum size specified in the parameter ''chunk''\n\n; IF control:\n*''if'': This will cause the threads to parallelize the task only if a condition is met. Otherwise the code block executes serially.\n\n; Initialization:\n* ''firstprivate'': the data is private to each thread, but initialized using the value of the variable using the same name from the master thread.\n* ''lastprivate'': the data is private to each thread. The value of this private data will be copied to a global variable using the same name outside the parallel region if current iteration is the last iteration in the parallelized loop.  A variable can be both ''firstprivate'' and ''lastprivate''.\n* ''threadprivate'': The data is a global data, but it is private in each parallel region during the runtime. The difference between ''threadprivate'' and ''private'' is the global scope associated with threadprivate and the preserved value across parallel regions.\n\n; Data copying:\n* ''copyin'': similar to ''firstprivate'' for ''private'' variables, ''threadprivate'' variables are not initialized, unless using ''copyin'' to pass the value from the corresponding global variables. No ''copyout'' is needed because the value of a threadprivate variable is maintained throughout the execution of the whole program.\n* ''copyprivate'': used with ''single'' to support the copying of data values from private objects on one thread (the ''single'' thread) to the corresponding objects on other threads in the team.\n\n; Reduction:\n* ''reduction(operator | intrinsic : list)'': the variable has a local copy in each thread, but the values of the local copies will be summarized (reduced) into a global shared variable. This is very useful if a particular operation (specified in ''operator'' for this particular clause) on a variable runs iteratively, so that its value at a particular iteration depends on its value at a prior iteration. The steps that lead up to the operational increment are parallelized, but the threads updates the global variable in a thread safe manner. This would be required in parallelizing [[numerical integration]] of functions and [[differential equation]]s, as a common example.\n\n; Others:\n* ''flush'': The value of this variable is restored from the register to the memory for using this value outside of a parallel part\n* ''master'': Executed only by the master thread (the thread which forked off all the others during the execution of the OpenMP directive). No implicit barrier; other team members (threads) not required to reach.\n\n=== User-level runtime routines ===\nUsed to modify/check the number of threads, detect if the execution context is in a parallel region, how many processors in current system, set/unset locks, timing functions, etc.\n\n=== Environment variables ===\nA method to alter the execution features of OpenMP applications. Used to control loop iterations scheduling, default number of threads, etc. For example, ''OMP_NUM_THREADS'' is used to specify number of threads for an application.\n\n== Implementations ==\nOpenMP has been implemented in many commercial compilers. For instance, Visual C++ 2005, 2008, 2010, 2012 and 2013 support it (OpenMP 2.0, in Professional, Team System, Premium and Ultimate editions<ref>[http://msdn2.microsoft.com/en-us/library/hs24szh9(vs.80).aspx Visual C++ Editions, Visual Studio 2005]</ref><ref>[http://msdn2.microsoft.com/en-us/library/hs24szh9(vs.90).aspx Visual C++ Editions, Visual Studio 2008]</ref><ref>[http://msdn2.microsoft.com/en-us/library/hs24szh9(vs.100).aspx Visual C++ Editions, Visual Studio 2010]</ref>), as well as [[Intel Parallel Studio]] for various processors.<ref>David Worthington, [http://www.sdtimes.com/intel_addresses_development_life_cycle_with_parallel_studio/about_intel_and_multicore/33497 \"Intel addresses development life cycle with Parallel Studio\"] {{Webarchive|url=https://web.archive.org/web/20120215032407/http://www.sdtimes.com/INTEL_ADDRESSES_DEVELOPMENT_LIFE_CYCLE_WITH_PARALLEL_STUDIO/About_INTEL_and_MULTICORE/33497 |date=2012-02-15 }}, SDTimes, 26 May 2009 (accessed 28 May 2009)</ref> [[Oracle Solaris Studio]] compilers and tools support the latest [https://web.archive.org/web/20081004161456/http://openmp.org/wp/openmp-specifications/ OpenMP specifications] with productivity enhancements for Solaris OS (UltraSPARC and x86/x64) and  Linux platforms. The Fortran, C and C++ compilers from [http://www.pgroup.com/ The Portland Group] also support OpenMP 2.5. [[GNU Compiler Collection|GCC]] has also supported OpenMP since version 4.2.\n\nCompilers with an implementation of OpenMP 3.0:\n* GCC 4.3.1\n* Mercurium compiler\n* Intel Fortran and C/C++ versions 11.0 and 11.1 compilers, Intel C/C++ and Fortran Composer XE 2011 and Intel Parallel Studio.\n* IBM XL compiler<ref>[http://www-01.ibm.com/software/awdtools/xlcpp/linux/features/?S_CMP=rnav \"XL C/C++ for Linux Features\"], (accessed 9 June 2009)</ref>\n* Sun Studio 12 update 1 has a full implementation of OpenMP 3.0<ref>{{cite web|url=http://developers.sun.com/sunstudio/features/ |title=Oracle Technology Network for Java Developers &#124; Oracle Technology Network &#124; Oracle |publisher=Developers.sun.com |date= |accessdate=2013-08-14}}</ref>\n\nSeveral compilers support OpenMP 3.1:\n* GCC 4.7<ref name=\"openmp – GCC Wiki\">{{cite web|url=https://gcc.gnu.org/wiki/openmp |title=openmp – GCC Wiki |publisher=Gcc.gnu.org |date=2013-07-30 |accessdate=2013-08-14}}</ref>\n* Intel Fortran and C/C++ compilers 12.1<ref>{{cite web|author=Submitted by Patrick Kennedy... on Fri, 09/02/2011 – 11:28 |url=http://software.intel.com/en-us/articles/intel-c-and-fortran-compilers-now-support-the-openmp-31-specification/ |title=Intel® C++ and Fortran Compilers now support the OpenMP* 3.1 Specification &#124; Intel® Developer Zone |publisher=Software.intel.com |date=2011-09-06 |accessdate=2013-08-14}}</ref>\n* IBM XL C/C++ compilers for AIX and Linux, V13.1<ref name=\"ibm.com\">https://www.ibm.com/support/docview.wss?uid=swg27007322&aid=1</ref> & IBM XL Fortran compilers for AIX and Linux, V14.1<ref name=\"www-01.ibm.com\">http://www-01.ibm.com/support/docview.wss?uid=swg27007323&aid=1</ref>\n* LLVM/Clang 3.7<ref name=\"Clang 3.7 Release Notes\">{{cite web|url=http://llvm.org/releases/3.7.0/tools/clang/docs/ReleaseNotes.html#openmp-support |title=Clang 3.7 Release Notes |publisher=llvm.org |accessdate=2015-10-10}}</ref>\n* [[Absoft Fortran Compilers]] v. 19 for Windows, Mac OS X and Linux<ref name=\"Absoft Pro Fortran Compilers and Debuggers\">{{cite web|url=https://www.absoft.com/ |title=Absoft Home Page |accessdate=2019-02-12}}</ref>\n\nCompilers supporting OpenMP 4.0:\n* GCC 4.9.0 for C/C++, GCC 4.9.1 for Fortran<ref name=\"openmp – GCC Wiki\" /><ref>{{cite web|url=https://www.gnu.org/software/gcc/gcc-4.9/changes.html |title=GCC 4.9 Release Series – Changes |publisher=www.gnu.org }}</ref>\n* Intel Fortran and C/C++ compilers 15.0<ref>{{cite web| url=https://software.intel.com/en-us/articles/openmp-40-features-in-intel-compiler-150 |title=OpenMP* 4.0 Features in Intel Compiler 15.0 |publisher=Software.intel.com |date=2014-08-13 }}</ref>\n* IBM XL C/C++ for Linux, V13.1 (partial)<ref name=\"ibm.com\"/> & XL Fortran for Linux, V15.1 (partial)<ref name=\"www-01.ibm.com\"/>\n* LLVM/Clang 3.7 (partial)<ref name=\"Clang 3.7 Release Notes\"/>\n\n[[Automatic parallelization|Auto-parallelizing]] compilers that generates source code annotated with OpenMP directives:\n* iPat/OMP\n* [[Parallware]]\n* PLUTO\n* [[ROSE (compiler framework)]]\n* S2P by KPIT Cummins Infosystems Ltd.\n\nSeveral profilers and debuggers expressly support OpenMP:\n\n* [[Allinea Distributed Debugging Tool]] (DDT) – debugger for OpenMP and MPI codes\n* [[Allinea MAP]] – profiler for OpenMP and MPI codes\n* TotalView - debugger from [[Rogue Wave Software]] for OpenMP, MPI and serial codes\n* ompP – profiler for OpenMP\n* VAMPIR – profiler for OpenMP and MPI code\n\n== Pros and cons ==\n{{Refimprove section|date=February 2017}}\nPros:\n* Portable multithreading code (in C/C++ and other languages, one typically has to call platform-specific primitives in order to get multithreading).\n* Simple: need not deal with message passing as [[Message Passing Interface|MPI]] does.\n* Data layout and decomposition is handled automatically by directives.\n* Scalability comparable to [[Message Passing Interface|MPI]] on shared-memory systems.<ref name=\"ReferenceA\">{{cite journal|doi=10.1016/j.parco.2012.05.005|title=OpenMP parallelism for fluid and fluid-particulate systems|year=2012|last1=Amritkar|first1=Amit|last2=Tafti|first2=Danesh|last3=Liu|first3=Rui|last4=Kufrin|first4=Rick|last5=Chapman|first5=Barbara|journal=Parallel Computing|volume=38|issue=9|page=501}}</ref>\n* Incremental parallelism: can work on one part of the program at one time, no dramatic change to code is needed.\n* Unified code for both serial and parallel applications: OpenMP constructs are treated as comments when sequential compilers are used.\n* Original (serial) code statements need not, in general, be modified when parallelized with OpenMP. This reduces the chance of inadvertently introducing bugs.\n* Both [[Granularity (parallel computing)|coarse-grained]] and [[Granularity (parallel computing)|fine-grained]] parallelism are possible.\n* In irregular multi-physics applications which do not adhere solely to the [[SPMD]] mode of computation, as encountered in tightly coupled fluid-particulate systems, the flexibility of OpenMP can have a big performance advantage over [[Message Passing Interface|MPI]].<ref name=\"ReferenceA\" /><ref>{{cite journal|doi=10.1016/j.jcp.2013.09.007|title=Efficient parallel CFD-DEM simulations using OpenMP|year=2014|last1=Amritkar|first1=Amit|last2=Deb|first2=Surya|last3=Tafti|first3=Danesh|journal=Journal of Computational Physics|volume=256|page=501|bibcode=2014JCoPh.256..501A|title-link=CFD-DEM}}</ref>\n* Can be used on various accelerators such as [[GPGPU]]<ref>[https://www.openmp.org/updates/openmp-accelerator-support-gpus/ OpenMP Accelerator Support for GPUs]</ref> and [[Field-programmable gate array|FPGAs]].\n\nCons:\n* Risk of introducing difficult to debug synchronization bugs and [[race condition]]s.<ref>[http://developers.sun.com/solaris/articles/cpp_race.html Detecting and Avoiding OpenMP Race Conditions in C++]</ref><ref>[http://software.intel.com/en-us/articles/32-openmp-traps-for-c-developers Alexey Kolosov, Evgeniy Ryzhkov, Andrey Karpov 32 OpenMP traps for C++ developers]</ref>\n* {{As of|2017}} only runs efficiently in shared-memory multiprocessor platforms (see however Intel's [http://software.intel.com/en-us/articles/cluster-openmp-for-intel-compilers Cluster OpenMP] and other [[distributed shared memory]] platforms).\n* Requires a compiler that supports OpenMP.\n* Scalability is limited by memory architecture.\n* No support for [[compare-and-swap]].<ref>Stephen Blair-Chappell, Intel Corporation, Becoming a Parallel Programming Expert in Nine Minutes, presentation on [[ACCU (organisation)|ACCU]] 2010 conference</ref>\n* Reliable error handling is missing.\n* Lacks fine-grained mechanisms to control thread-processor mapping.\n* High chance of accidentally writing [[false sharing]] code.\n\n== Performance expectations ==\n\nOne might expect to get an ''N'' times [[speedup]] when running a program parallelized using OpenMP on a ''N'' processor platform.  However, this seldom occurs for these reasons:\n* When a dependency exists, a process must wait until the data it depends on is computed.\n* When multiple processes share a non-parallel proof resource (like a file to write in), their requests are executed sequentially. Therefore, each thread must wait until the other thread releases the resource.\n* A large part of the program may not be parallelized by OpenMP, which means that the theoretical upper limit of speedup is limited according to [[Amdahl's law]].\n* N processors in a [[symmetric multiprocessing]] (SMP) may have N times the computation power, but the [[memory bandwidth]] usually does not scale up N times. Quite often, the original memory path is shared by multiple processors and performance degradation may be observed when they compete for the shared memory bandwidth.\n* Many other common problems affecting the final speedup in parallel computing also apply to OpenMP, like [[load balancing (computing)|load balancing]] and synchronization overhead.\n* Compiler optimisation may not be as effective when invoking OpenMP. This can commonly lead to a single-threaded OpenMP program running slower than the same code compiled without an OpenMP flag (which will be fully serial).\n\n== Thread affinity ==\n\nSome vendors recommend setting the [[processor affinity]] on OpenMP threads to associate them with particular processor cores.<ref>{{cite journal|doi=10.1535/itj.1104.08|title= Multi-Core Software|date=2007-11-15|last1=Chen|first1=Yurong|journal=Intel Technology Journal|volume=11|issue=4}}</ref><ref>{{cite web|url=http://www.spec.org/omp/results/res2008q1/omp2001-20080128-00288.html|title=OMPM2001 Result|date=2008-01-28|publisher=SPEC}}</ref><ref>{{cite web|url=http://www.spec.org/omp/results/res2003q2/omp2001-20030401-00079.html|title=OMPM2001 Result|date=2003-04-01|publisher=SPEC}}</ref>\nThis minimizes thread migration and context-switching cost among cores. It also improves the data locality and reduces the cache-coherency traffic among the cores (or processors).\n==Benchmarks==\nA variety of benchmarks has been developed to demonstrate the use of OpenMP, test its performance and evaluate correctness. \n\nSimple examples\n* [https://sourceforge.net/projects/ompscr/ OmpSCR: OpenMP Source Code Repository]\n\nPerformance benchmarks include:\n* [https://www.epcc.ed.ac.uk/research/computing/performance-characterisation-and-benchmarking/epcc-openmpmpi-micro-benchmark EPCC OpenMP/MPI micro-benchmark suite]\n* [http://aces.snu.ac.kr/software/snu-npb/ NAS Parallel Benchmark]\n* [https://github.com/bsc-pm/bots Barcelona OpenMP Task Suite] a collection of applications that allow to test OpenMP tasking implementations.\n* SPEC series\n** [https://www.spec.org/omp2012/ SPEC OMP 2012]\n** [https://www.spec.org/accel/ The SPEC ACCEL benchmark suite] testing  OpenMP 4 target offloading API\n** [https://www.spec.org/hpc2002/ The SPEChpc® 2002 benchmark]\n* [https://asc.llnl.gov/sequoia/benchmarks/ ASC Sequoia Benchmark Codes]\n* [https://rodinia.cs.virginia.edu/doku.php Rodinia] focusing on accelerators.\n\nCorrectness benchmarks include:\n* [https://github.com/uhhpctools/omp-validation OpenMP Validation Suite]\n* [https://www.eecis.udel.edu/~schandra/research/openmpvv/ OpenMP Validation and Verification Testsuite]\n* [https://github.com/LLNL/dataracebench DataRaceBench] is a benchmark suite designed to systematically and quantitatively evaluate the effectiveness of OpenMP data race detection tools.\n\n== See also ==\n{{too many see alsos|date=February 2017}}\n\n* [[Chapel (programming language)]]\n* [[Cilk]]\n* [[Cilk Plus]]\n* [[Message Passing Interface]]\n* [[Concurrency (computer science)]]\n* [[Heterogeneous System Architecture]]\n* [[Parallel computing]]\n* [[Parallel programming model]]\n* [[POSIX Threads]]\n* [[Unified Parallel C]]\n* [[X10 (programming language)]]\n* [[Parallel Virtual Machine]]\n* [[Bulk synchronous parallel]]\n* [[Grand Central Dispatch]]\n* [[Partitioned global address space]]\n* [[GPGPU]]\n* [[CUDA]]{{snd}} Nvidia\n* [[AMD FireStream]]\n* [[Octopiler]]\n* [[OpenCL]]\n* [[OpenACC]]\n* [[SequenceL]]\n* [[Enduro/X]]\n\n== References ==\n\n{{Reflist|30em}}\n\n== Further reading ==\n\n{{refbegin}}\n* Quinn Michael J, <cite>Parallel Programming in C with MPI and OpenMP</cite> McGraw-Hill Inc. 2004. {{ISBN|0-07-058201-7}}\n* R. Chandra, R. Menon, L. Dagum, D. Kohr, D. Maydan, J. McDonald, <cite>Parallel Programming in OpenMP.</cite> Morgan Kaufmann, 2000. {{ISBN|1-55860-671-8}}\n* R. Eigenmann (Editor), M. Voss (Editor), <cite>OpenMP Shared Memory Parallel Programming: International Workshop on OpenMP Applications and Tools, WOMPAT 2001, West Lafayette, IN, USA, July 30–31, 2001.</cite> (Lecture Notes in Computer Science). Springer 2001. {{ISBN|3-540-42346-X}}\n* B. Chapman, G. Jost, R. van der Pas, D.J. Kuck (foreword), <cite>Using OpenMP: Portable Shared Memory Parallel Programming.</cite> The MIT Press (October 31, 2007). {{ISBN|0-262-53302-2}}\n* Parallel Processing via MPI & OpenMP, M. Firuziaan, O. Nommensen. Linux Enterprise, 10/2002\n* [http://msdn.microsoft.com/msdnmag/issues/05/10/OpenMP/default.aspx MSDN Magazine article on OpenMP]\n* [http://openmp.org/mp-documents/omp-hands-on-SC08.pdf SC08 OpenMP Tutorial] (PDF) – Hands-On Introduction to OpenMP, Mattson and Meadows, from SC08 (Austin)\n* [https://www.openmp.org/specifications/ OpenMP Specifications]\n* [http://www.openmp.org/wp-content/uploads/F95_OpenMPv1_v2.pdf Parallel Programming in Fortran 95 using OpenMP] (PDF)\n{{refend}}\n\n== External links ==\n\n* {{Official website|openmp.org}}, includes the latest OpenMP specifications, links to resources, lively set of forums where questions can be asked and are answered by OpenMP experts and implementors\n* [http://openmpcon.org/ OpenMPCon], website of the OpenMP Developers Conference\n* [http://www.iwomp.org/ IWOMP], website for the annual International Workshop on OpenMP\n* [https://ukopenmpusers.co.uk// UK OpenMP Users], website for the UK OpenMP Users group and conference\n* [http://domino.research.ibm.com/comm/research_projects.nsf/pages/cellcompiler.index.html IBM Octopiler] with OpenMP support\n* [https://computing.llnl.gov/tutorials/openMP/ Blaise Barney, Lawrence Livermore National Laboratory site on OpenMP]\n* [https://web.archive.org/web/20140223093700/http://geco.mines.edu/workshop/aug2010/slides/thu/hybrid.pdf Combining OpenMP and MPI] (PDF)\n* [http://www.slac.stanford.edu/comp/unix/farm/mpi_and_openmp.html Mixing MPI and OpenMP]\n* [http://myarm.com/blog-measure-and-visualize-parallelism.html Measure and visualize OpenMP parallelism] by means of a [[C++]] routing planner calculating the [[Speedup]] factor\n\n{{Parallel computing}}\n\n[[Category:Application programming interfaces]]\n[[Category:Articles with example Fortran code]]\n[[Category:C programming language family]]\n[[Category:Fortran]]\n[[Category:Parallel computing]]"
    },
    {
      "title": "Photran",
      "url": "https://en.wikipedia.org/wiki/Photran",
      "text": "{{Unreferenced|date=September 2009}}\n{{Infobox software\n| name                   = Photran\n| logo                   =\n| screenshot             =\n| caption                =\n| developer              = [[University of Illinois]] at Urbana-Champaign and [[IBM]]\n| released               =\n| latest release version = 9.1\n| latest release date    = {{Start date and age|2015|06|24}}\n| latest preview version =\n| latest preview date    =\n| programming language   = [[Java (programming language)|Java]]{{Citation needed|date=September 2009}}\n| operating system       = [[Cross-platform]]\n| language               = English\n| genre                  = [[Integrated development environment|IDE]]\n| license                = [[Eclipse Public License]]\n| website                = {{URL|http://www.eclipse.org/photran/}}\n}}\n'''Photran''' is an [[Integrated Development Environment]] (IDE) for [[Fortran 77|FORTRAN 77]], Fortran 90, Fortran 95, Fortran 2003 and Fortran 2008 based on [[Eclipse (software)|Eclipse]] and the CDT. The project is maintained by the [[University of Illinois]] at Urbana-Champaign and [[IBM]].\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[Comparison of integrated development environments]]\n* [[KDevelop]]\n\n==External links==\n* {{official website|http://www.eclipse.org/photran/}}\n\n{{Eclipse Foundation}}\n{{Eclipse plugins}}\n\n[[Category:Eclipse (software)]]\n[[Category:Fortran]]\n[[Category:Free integrated development environments]]\n[[Category:Linux integrated development environments]]\n\n\n{{programming-software-stub}}"
    },
    {
      "title": "David Sayre",
      "url": "https://en.wikipedia.org/wiki/David_Sayre",
      "text": "{{short description|American X-ray crystallographer}}\n{{about||the founder of Sayre Female Institute|David Austin Sayre|the American pioneer|David F. Sayre}}\n{{Infobox scientist\n| name                    = David Sayre\n| image_size             = 100px\n| caption                 =\n| birth_date              = {{Birth date|mf=yes|1924|3|2}}\n| birth_place             = [[New York, New York]]\n| death_date              = {{Death date and age|mf=yes|2012|2|23|1924|3|2}}\n| death_place             = [[Ashland, Oregon]]\n| residence               =\n| citizenship             =\n| nationality             =\n| ethnicity               =\n| field                   = [[X-ray crystallography]]<br />[[X-ray microscopy]]\n| work_institution        = [[IBM]]<br />[[Stony Brook University]]\n| alma_mater              = [[Yale University]] <br /> [[Oxford University]]\n| doctoral_advisor        = [[Dorothy Hodgkin]]\n| doctoral_students       =\n| known_for               = [[Sayre equation]]<br/>[[X-ray microscopy]]<br />[[Coherent diffraction imaging]]<br />[[Fortran|FORTRAN]]\n| author_abbreviation_bot =\n| author_abbreviation_zoo =\n| prizes                  = [[Ewald prize]]\n| religion                =\n| footnotes               =\n}}\n\n'''David Sayre''' (March 2, 1924 – February 23, 2012) was an American scientist, credited with the early development of [[direct methods (crystallography)|direct methods]] for [[X-ray crystallography#Protein crystallography|protein crystallography]] and of diffraction microscopy (also called [[coherent diffraction imaging]]). While working at IBM he was part of the initial team of ten programmers who created [[FORTRAN]], and later suggested the use of [[electron beam lithography]] for the fabrication of X-ray [[Zone plate|Fresnel zone plates]].\n\nThe [[International Union of Crystallography]] awarded Sayre the [[Ewald Prize]] in 2008 for  \nthe \"unique breadth of his contributions to crystallography, which range from seminal contributions to the solving of the phase problem to the complex physics of imaging generic objects by X-ray diffraction and microscopy(...)\".<ref name=\"Ewald\">{{cite web| title=Ewald Prize|url=http://www.iucr.org/iucr/ewald-prize/8th-ewald-prize | accessdate=June 3, 2012}}</ref>\n\n==Life and career==\n\nSayre was born in [[New York City]]. He completed his bachelor's degree in physics at [[Yale University]] at the age of 19. After working at the [[Massachusetts Institute of Technology|MIT]] Radiation Laboratory, he earned his MS degree at [[Auburn University]] in 1948. In 1949, he moved to Oxford with his wife [[Anne Sayre|Anne Colquhoun]], whom he had married in 1947. Sayre completed his doctoral studies in [[Dorothy Hodgkin]]'s group in 1951. It is at this time that Sayre discovered the [[Sayre equation|equation now named after him]], based on the concept of atomicity. Although the key to most [[direct methods (crystallography)|direct methods]] still in use today, Sayre did not share the 1985 chemistry Nobel prize awarded for their discovery. It is also around this time that Sayre, inspired by [[Claude Shannon]]'s recent work, suggested in a short paper that the crystallographic phase problem could be solved more easily if one could measure intensities at a higher density than imposed by Bragg's law. This insight is widely seen as the initial spark that lead to recent [[coherent diffraction imaging|lensless imaging techniques]].\n\nBack in United States, David Sayre worked on structure determination of a carcinogen molecule in the lab of Peter Friedlander at the [[University of Pennsylvania]] in [[Philadelphia]]. The structure determination program he wrote for the IBM 701 attracted the attention of [[John Backus]], who hired him to be part of the initial team of programmers that developed the high-level programming language FORTRAN. Sayre was to remain at IBM until his retirement in 1990. In the early 1970s, Sayre became interested in X-ray microscopy. He suggested to use the newly developed [[electron beam lithography]] apparatus at IBM to produce [[Zone plate|Fresnel zone plates]], a type of X-ray lens now widely used in Synchrotron facilities. In the '80s, he came back to the goal of achieving lensless imaging, which he pursued the rest of his life.\n\n==References==\n{{reflist|colwidth=30em}}\n\n==External links==\n{{Wikiquote}}\n* [http://www.nature.com/nature/journal/v484/n7392/full/484038a.html Obituary: David Sayre (1924–2012) Crystallographer who pioneered methods of X-ray imaging and modern computing], by Janos Kirz and Jianwei Miao, [[Nature (journal)|Nature]] journal, Volume 484 Number 7392, p.&nbsp;34, April 2012.\n* [http://journals.iucr.org/a/issues/2012/04/00/es0396/index.html Obituary: David Sayre (1924–2012)], by [[Jenny P. Glusker]], [[Acta Crystallographica A|Acta Crystallographica]], Volume 68, p.&nbsp;1–2, May 2012.\n* [http://physicstoday.scitation.org/do/10.1063/PT.4.1769/full/ Obituary of David Sayre (1924-2012)], by Janos Kirz, [[Physics Today]] DOI:10.1063/PT.4.1769\n* Link to David Sayre's Memoir written by himself [https://www.researchgate.net/project/History-of-Crystallography]\n\n{{Authority control}}\n\n{{DEFAULTSORT:Sayre, David}}\n[[Category:1924 births]]\n[[Category:2012 deaths]]\n[[Category:Alumni of the University of Oxford]]\n[[Category:20th-century American mathematicians]]\n[[Category:21st-century American mathematicians]]\n[[Category:American physicists]]\n[[Category:Fortran]]\n[[Category:Scientists from New York City]]\n[[Category:Programming language designers]]\n[[Category:Programming language researchers]]\n[[Category:Yale University alumni]]\n[[Category:Mathematicians from New York (state)]]"
    },
    {
      "title": "Simply Fortran",
      "url": "https://en.wikipedia.org/wiki/Simply_Fortran",
      "text": "{{Unreferenced|date=March 2016}}\n{{Infobox software\n| name                   = Simply Fortran\n| logo                   =\n| screenshot             =\n| caption                =\n| developer              = [[Approximatrix, LLC]]\n| released               =\n| latest release version = 2.41\n| latest release date    = {{Start date and age|2018|03|13}}\n| latest preview version =\n| latest preview date    =\n| programming language   = \n| operating system       = [[Windows]], [[Linux]], [[macOS]]\n| language               = English\n| genre                  = [[Integrated development environment|IDE]]\n| license                = [[Proprietary software|Proprietary]]\n| website                = {{URL|http://simplyfortran.com/}}\n}}\n'''Simply Fortran''' is an [[Integrated Development Environment]] (IDE) for [[Fortran 77|FORTRAN 77]], Fortran 90, Fortran 95, Fortran 2003 and Fortran 2008. The project is maintained by the company [[Approximatrix, LLC]].\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[Comparison of integrated development environments]]\n* [[KDevelop]]\n\n==External links==\n* {{official website|http://simplyfortran.com/}}\n\n[[Category:Fortran]]\n[[Category:Integrated development environments]]\n[[Category:Linux integrated development environments]]\n[[Category:Windows integrated development environments]]"
    },
    {
      "title": "SIMSCRIPT",
      "url": "https://en.wikipedia.org/wiki/SIMSCRIPT",
      "text": "{{short description|Simulation language}}\n'''SIMSCRIPT''' is a free-form, [[English language|English]]-like general-purpose [[simulation language]] conceived by [[Harry Markowitz]] and Bernard Hausner at the [[RAND Corporation]] in 1962. It was implemented as a [[Fortran]] [[preprocessor]] on the [[IBM 7090]]<ref>{{cite book\n|title=Simulation With Arena  |isbn=978-1467273411\n|url=https://books.google.com/books?isbn=1467273414 |date=2016\n|quote=SIMSCRIPT ... was implemented asa Fortran preprocessor on the IBM 7090|last1=Reviews\n|first1=C. T. I.\n}}</ref> and was designed for large [[discrete event simulation]]s. It influenced [[Simula]].<ref name=Simula.pdf>{{cite web\n|title=The Development of the SIMULA Languages\n|url=https://hannemyr.com/cache/knojd_acm78.pdf\n|quote=The development of .. SIMULA I and SIMULA 67... were influenced by the design of SIMSCRIPT ...\n|author=Kristen Nygaard |date=1978}}</ref>\n\nThough earlier versions were released into the public domain, SIMSCRIPT was commercialized by Markowitz's company, [[CACI|California Analysis Center, Inc.]] (CACI), which produced proprietary versions SIMSCRIPT I.5<ref>{{cite web   |title=The SIMSCRIPT III Programming Language for Modular Object ...\n  |url=http://www.caciasl.com/docs/SIMSCRIPT_III_Paper_Win_Sim.pdf\n  |author=M. E. Kuhl  \n  |quote=... and was followed by SIMSCRIPT I.5 from CACI in 1965}}</ref><ref>{{cite web  |url=http://www.caci.com/special/story.shtml |title=A Look Back in Time: The CACI Story}}</ref> and [[#SIMSCRIPT II.5|SIMSCRIPT II.5]].\n\n==SIMSCRIPT II.5==\n'''SIMSCRIPT II.5'''<ref>{{cite book |title=Simscript II.5: Programming language\n|author=Philip J Kiviat\n|url=https://www.amazon.com/Simscript-II-5-Programming-Philip-Kiviat/dp/B0000EGCHY}}</ref> <ref>{{cite book |title=Building simulation models with SIMSCRIPT II.5 |author=Edward C. Russell\n|url=https://books.google.com/books/about/Building_simulation_models_with_SIMSCRIP.html&id=zEg7_Pqh_T0C|isbn=9780918417008\n|year=1983\n}}</ref> was the last pre-PC incarnation of SIMSCRIPT, one of the oldest computer [[simulation language]]s.  Although military contractor [[CACI]] released it in 1971, it still enjoys wide use in large-scale military and air-traffic control simulations.<ref>1988 magazine quote: \"today used principally by the U. S. military.\"</ref><ref name=PC1988>{{cite magazine  |magazine=PC Computing   |date=September 1988 |pages=150–157\n|title=Market Value - PCs on Wall Street |author=William G. Shepherd, Jr.}}</ref>\n\n:''SIMSCRIPT II.5 is a powerful, free-form, English-like, general-purpose simulation programming language. It supports the application of software engineering principles, such as structured programming and modularity, which impart orderliness and manageability to simulation models.''<ref>{{cite book | first=Edward C. | last=Russell | title=Building Simulation models with SIMSCRIPT II.5 | publisher=CACI | location=Los Angeles | year=1983}}</ref>\n\n==SIMSCRIPT III==\n''SIMSCRIPT III''<ref>{{cite web |title=The SIMSCRIPT III programming language |website=[[IEEE]].org\n|url=http://ieeexplore.ieee.org/document/1574302\n|quote=SIMSCRIPT III is a programming language for discrete-event simulation. It is a major extension of its predecessor, SIMSCRIPT II.5, providing full support for ...}}</ref> ''Release 4.0'' was available by 2009,<ref>{{cite web\n|website=simscript.com  |url=http://www.simscript.com/products/products.html\n|title=SIMSCRIPT III Object-Oriented, Modular, Integrated software development tool}}</ref> and by then it ran on [[Windows 7]], [[SUN OS]] and [[Linux]] and has [[Object-oriented]] features.<ref>{{cite book\n|author=Harry M. Markowitz |title=Selected Works |page=152  |date=2009\n|url=https://books.google.com/books?isbn=981447021X  |isbn=978-9814470216\n|quote=I told Ana Marjanski, who headed the SIMSCRIPT III project, that SIMSCRIPT already has entities, attributes plus sets. She explained that the clients want object ...}}</ref>\n\nBy 1997, SIMSCRIPT III already had a GUI interface to its compiler.<ref>{{cite web |date=June 26, 1997\n   |url=http://www.simscript.com/cust_center/sim3r2docs/SIMSCRIPTIII_User_Manual.pdf\n   |title=SIMSCRIPT III User's Manual}}</ref> The latest version is ''Release 5''; earlier versions already supported 64-bit processing.<ref>{{cite web\n   |title=CACI Products \n   |accessdate=March 12, 2019\n   |url=http://www.simscript.com/downloads/downloads.html}}</ref>\n\n==PL/I implementation==\nA '''[[PL/I]]''' implementation was developed during 1968-1969, based on the public domain version released by RAND corporation.<ref>{{cite book\n|title=Encyclopedia of Computer Science and Technology: Volume 13\n|url=https://books.google.com/books?isbn=0824722639  |isbn=978-0824722630\n|author1=Jack Belzer |author2=Albert G. Holzman  |author3=Allen Kent |date=1979\n|quote=SIMSCRIPT. This PL/I based version, first developed in 1968-1969  ... of SIMSCRIPT I, particularly in large simulations at The RAND Corporation}}</ref>\n\n== See also ==\n* [[QUIKSCRIPT]]\n*[[GPSS]]\n\n==References==\n<references/>\n{{FOLDOC}}\n\n==External links==\n* [http://www.simscript.net/products/products.html CACI SIMSCRIPT page]\n* [https://web.archive.org/web/20060901042910/http://hopl.murdoch.edu.au/showlanguage.prx?exp=190&language=SIMSCRIPT History of Programming Languages: SIMSCRIPT]\n* [http://purl.umn.edu/107467 Oral history interview with Harry M. Markowitz],  [[Charles Babbage Institute]], University of Minnesota - [[Harry Markowitz|Markowitz]] discusses his development of [[portfolio theory]], sparse matrices, and his work at the [[RAND Corporation]] and elsewhere on simulation software development (including computer language '''SIMSCRIPT'''), modeling, and operations research.\n\n[[Category:Fortran]]\n[[Category:Simulation programming languages]]\n\n{{compu-lang-stub}}"
    },
    {
      "title": "Absoft Fortran Compilers",
      "url": "https://en.wikipedia.org/wiki/Absoft_Fortran_Compilers",
      "text": "{{Infobox company\n| name             = Absoft Corporation\n| logo             = Absoft logo.png\n| foundation       = [[Birmingham, Michigan]] (1980)\n| location_city    = [[Troy, Michigan]]\n| location_country = [[United States]]\n| founders         = Peter Jacobson<br />Wood Lotz\n| area_served      = Worldwide\n| industry         = [[Software]], [[Programming tool]]s\n| products         = [[Compilers]]<br />[[Debuggers]]<br />[[Integrated development environment | IDEs]]\n| homepage         = [http://absoft.com/ Absoft.com]\n| footnotes        =\n}}\n'''Absoft Fortran Compilers''' are set of [[Fortran]] [[compilers]] for [[Microsoft Windows]], [[Apple Macintosh]], and [[Linux]] produced by Absoft Corporation.<ref>[http://absoft.com Absoft Corporation web site]</ref>  The compilers are source code compatible across platforms.<ref>[http://www.absoft.com/wp-content/uploads/2016/03/Absoft_Fortran_Reference.pdf Absoft Fortran Language Reference, page 1]</ref>\n*  Absoft Pro Fortran on 64-bit platforms supports both 32 bit and 64 bit executables; the user selects which format that the compiler will produce.\n* Linux compilers are available in either 32-bit or 64-bit versions.  The 32-bit version produces only 32-bit executables.\nAll are bundled with a graphical debugger and an integrated development environment.  Single thread and parallel multithread support is controlled by the user and includes five optimization levels, OpenMP, Speed Math levels 0 through 9, and other advanced capabilities.\n\n== History ==\n\n=== Origins:  Absoft FORTRAN 77 for MC68000 Systems ===\nThe principals of Absoft, Peter Jacobson and Wood Lotz, met at the [[University of Michigan]].  Together they started an audio store, Absolute Sound, in 1975.  In 1979, they noted the emergence of 16-bit microcomputers and saw a market for high quality Fortran compilers and built a compiler for the [[Western Digital]] WD16 microprocessor, which they released commercially in 1980.  The name Absolute Software was used at first, but the shortened name Absoft was adopted as a more practical trademark.\n\n=== Absoft FORTRAN 77 for Macintosh ===\nAbsoft’s first major sales success was a $500K contract with [[Alpha Microsystems]] for worldwide redistribution rights of a Fortran 77 compiler compatible with their AMOS operating system using a [[Motorola 68000 series]] processor. At this point Absoft still consisted of only the two founders, so this success allowed the company to remain independent, add staff, and move to a larger office facility. Additional OEM contracts for Fortran compilers for various Unix variants followed.  The founders hired a manager for Absolute Sound which continued its success and expanded to three stores; the chain was sold to a larger Hi-Fi chain in 1988.\n\n=== MIL-STD-1753 Supplement for FORTRAN 77 ===\nMIL-STD-1753 was released by the DoD in 1978 to standardize some features of [[Industrial Real-Time Fortran]] as extensions of Fortran 77.<ref>FORTRAN 77 standard: ANSI X3.9 (April 3, 1978)[http://www.fh-jena.de/~kleine/history/languages/ansi-x3dot9-1978-Fortran77.pdf].</ref><ref>[http://www.everyspec.com/MIL-STD/MIL-STD-1700-1799/MIL-STD-1753_11044/ MIL-STD-1753, November 9, 1978]</ref>  This extension added <code>IMPLICIT NONE</code>, <code>DO WHILE</code>, <code>END DO</code> to replace <code>CONTINUE</code> as the statement to end <code>DO</code> loops, and intrinsic functions for testing and setting bits. MIL-STD-1753 was absorbed into the ISO/IEC 1539:1991 standard and later ISO/IEC standards are MIL-STD-1753 compliant, and MIL-STD-1753 was dropped as superfluous in 1995.<ref>[http://www.everyspec.com/MIL-STD/MIL-STD-1700-1799/MIL-STD-1753_NOTICE-1_20897/ MIL-STD-1753 Notice 1, March 25, 1996 on EverySpec.com]</ref>\n\n=== Absoft FORTRAN 77 for Apple Macintosh and Windows ===\n<!-- Deleted image removed: [[File:Absoft Microsoft FORTRAN for Mac front.png|thumb|right|Mac Fortran compiler box]] -->\n<!-- Deleted image removed: [[File:Absoft Microsoft FORTRAN for Mac back.png|thumb|right|Back of the Mac Fortran compiler box, showing the Absoft development credit and a screen shot of the IDE]] -->\nWhen Alpha Micro released their MC68000 based microcomputer, Absoft expanded their offerings to [[Motorola]] and the [[Macintosh]].  The availability of MD68000-based machines made 32-bit Unix viable on small machines, and Absoft offered Fortran compilers for Unix machines by [[Data General]], [[Hewlett-Packard|HP]], [[Sun Microsystems]], [[Tektronix]], and others.\n\nIn 1985 Microsoft licensed MacFortran, which consisted of a native ANSI FORTRAN 77 compiler and graphical debugger.  Shortly thereafter, Microsoft contracted with Absoft to develop Microsoft Fortran for Macintosh, and a Microsoft BASIC compiler that was 100% syntax compatible with the existing Microsoft BASIC interpreter on the Macintosh. Apple was one of the first Mac Fortran customers, with a large order for Drexel University. Variations of the Fortran and BASIC compilers for Macintosh were marketed under the name A/C Fortran and A/C Basic for [[Amiga]]. Fortran compilers for [[Linux]]/[[Unix]] and [[Microsoft Windows]] followed.\n\nThe Mac and Amiga Fortran compilers included an [[Integrated development environment]] (IDE) and profiler.  The IDE was added to the Windows compilers and is included in all succeeding Absoft Fortran compilers.\n\n=== Fortran 90 and the Internet ===\nDuring the 1990s the broadened product lines and internet enabled Absoft to build a base of resellers worldwide.  For a period of time in the mid-1990s Absoft had a full-time representative in California but expanded internet usage eliminated that position and allowed everything to be run out of a single location.\n\n== Company milestones ==\nDetails on milestones since 2006 are available on the Press Releases page of the Absoft web site.<ref>{{Cite web |url=http://www.absoft.com/corporate/pressrelease.html |title=Absoft Press Releases page |access-date=2014-04-26 |archive-url=https://web.archive.org/web/20131214134626/http://www.absoft.com/corporate/pressrelease.html |archive-date=2013-12-14 |dead-url=yes |df= }}</ref>\n* 1980 Absoft founded in [[Birmingham, Michigan]].\n* 1981 Initial compilers for UNIX platforms included a graphical debugger.\n* 1981 Major contract with Alpha Microsystems.\n* 1983 Release of Absoft's first graphical debugger, for Motorola VersaDOS.\n* 1984 Absoft adds support for the Sky Computers<ref>[http://www.skycomputers.com/ Sky Computers web site]</ref> floating point accelerator, SKYFFP-V, on [[VMEbus|VME]] (aka Versabus) and [[S-100 bus|S-100]] systems.\n* 1985 Release of Absoft Mac Fortran compiler with graphical debugger and IDE.\n* 1986 Release of Absoft Mac BASIC compiler with graphical debugger and IDE.\n* 1986 Release of Amiga Fortran\n* 1988 Absoft built a new development facility in Rochester Hills, Michigan.\n* 1994 Release of Absoft Fortran for Mac PPC (still available!).\n* 1994 Release of Fortran for Microsoft Windows.\n* 1997 Release of Linux Fortran as produced for [[CERN]] to port [[ESPACE]] code to Linux.\n* 2000 All releases include Fortran 90\n* 2003 First compiler that produces 64-bit executables (Linux).\n* 2004 Release of IBM XL Fortran and XL C/C++ for Mac OS (PPC).\n* 2004 IBM contract to develop the HPC SDK for POWER, POWER4 and POWER5 architectures.<ref>HPC Software Developers Kit for Linux on IBM POWER processor-based systems (see Absoft logo on lower left of last page)[http://www-07.ibm.com/systems/includes/pdf/absoft.pdf]</ref><ref>Absoft to Provide High Performance Computing Software Developers Kit for IBM Linux on POWER Clusters and Servers [http://www.thefreelibrary.com/Absoft+to+Provide+High+Performance+Computing+Software+Developers+Kit...-a0124334749]</ref>\n* 2005 64-bit executables on the Macintosh\n* 2005 All releases include Fortran 95.\n* 2005 With version 10.0, the previously bundled Absoft C/C++ compiler was dropped in favor of using universally available C/C++ compilers on each platform directly from the IDE.  The profiler and bundled C/C++ compiler was dropped to allow compatibility with system C compilers and linkers.\n* 2006 Max OS/X Intel Pro Fortran released.\n* 2006 IMSL 5.0 for 64-bit Intel/AMD Linux released.\n* 2006 AnCAD<ref>[http://www.ancad.com/ AnCAD web site]</ref> MATFOR<ref>{{Cite web |url=http://www.ancad.com/overview.htm |title=About MATFOR page on the AnCAD web site |access-date=2014-04-26 |archive-url=https://web.archive.org/web/20050405163222/http://ancad.com/overview.htm |archive-date=2005-04-05 |dead-url=yes |df= }}</ref> libraries for Linux and Windows released.\n* 2007 64-bit executables on Microsoft Windows and Mac OS/X.  IMSL available for Mac OS/X.\n* 2007 Absoft releases Pro Fortran 10.1 with tuning for multi-core AMD and Xeon processors for both 32-bit and 64-bit executables.\n* 2008 Releases a \"Roll\" for Clustercorp's [[Rocks Cluster Distribution]] that includes Absoft Pro Fortran 10.1 and is compatible with Rocks+ 4.3 and its open-source software stack.\n* 2008 Absoft and Visual Numerics' release IMSL library qualified for Microsoft's HPC platform.<ref>{{Cite web |url=http://www.absoft.com/corporate/pressreleases/Absoft%20VNI%20MS%20IMSL%20PR.pdf |title=Absoft press release, July 15, 2008 |access-date=April 26, 2014 |archive-url=https://web.archive.org/web/20130325225452/http://absoft.com/corporate/pressreleases/Absoft%20VNI%20MS%20IMSL%20PR.pdf |archive-date=March 25, 2013 |dead-url=yes |df=mdy-all }}</ref>\n* 2009 IMSL 6.0 released as part of Pro Fortran 11.\n* 2010 Absoft Pro Fortran 11.1 for HPC Code Development, compatible with Snow Leopard an Xcode 3.2 released.\n* 2010 NVIDIA CUDA support via CAPS's HMPP 2.4 preprocessor released.\n* 2011 Absoft and Bradly Associates announce a bundle of Absoft Pro Fortran and GINO GUI builder.  GINO GUI Lite is included with Absoft Pro Fortran purchases or upgrades after April 20, 2011 (available on request for purchases or upgrades up to 60 days prior to that date).<ref>{{Cite web |url=http://www.absoft.com/corporate/pressreleases/Gino_Lite_PR.htm |title=Absoft press release, May 20, 2011 |access-date=April 26, 2014 |archive-url=https://web.archive.org/web/20130521011827/http://www.absoft.com/corporate/pressreleases/Gino_Lite_PR.htm |archive-date=May 21, 2013 |dead-url=yes |df=mdy-all }}</ref>\n* 2011 IMSL 7.0 released and bundled with all Absoft Pro Fortran releases.\n* 2012 Sold the Rochester Hills building and moved into an office building in Troy, Michigan.\n\n== Absoft Pro Fortran Compilers ==\nAbsoft Pro Fortran is available (June 2018) in five versions:\n*  Microsoft Windows\n*  Mac Intel x86_64 (OS X)\n*  Mac PPC (OS X PPC G5)\n*  Linux 32-bit Intel x86\n*  Linux 64-bit Intel x86_64\n\nThe Windows, Mac  and 64-bit Linux versions produce either 32-bit or 64-bit executables according to user option.  The Linux 32-bit version produces 32-bit executables.\n\nAll versions offer the IMSL libraries as an extra-cost option.\n\nGINO GUI Lite is available as an optional component without added cost.  GINO GUI and graphics, and Winteracter GUI Toolset are available also are available at extra cost.\n\n=== Parallel processing and optimization ===\n[[File:Absoft Target Options.png|thumb|230px|right|Screen shot from Absoft IDE, showing the optimization and parallel optimizations available by checking the appropriate box]]\n\nAbsoft Pro Fortan parallelization and optimization options are illustrated by the screen shot of the relevant options page to the right.  Absoft Pro Fortran provides five levels of classical optimization and Speed Math options 0 through 9.\n\nParallelization options include auto parallelization as a check box with graphical indications of degrees of success on the source code in the editor pane as highlighting colors.  OpenMP 3.0 is also available as a check box.  Speed OpenMP is available as none or levels 0 through 5.\n\nAbsoft offers support for [[Message Passing Interface|MPI]] ([[MPICH]]2 and [[Open MPI]]).  [[ScaLAPACK]] and BLACS<ref>[http://www.netlib.org/blacs/ BLACS (Basic Linear Algebra Communication Subprograms) web site]</ref> is shipped with all platforms.  IMSL 7.0, integrated but available as a separate license since the v. 7.0 release in 2011, supplies MPICH2.\n\nExecuting programs that use parallelization on machines that do not have Absoft Fortran installed requires inclusion of <code>pthreadVC2.dll</code> for 32-bit executables or, for 64-bit executables, <code>pthreadVC2_64.dll</code>.  This library is distributed under the LGPL 2.1.\n\n=== Fortran 2003 and Fortran 2008 extensions ===\nSome Fortran 2003 and Fortran 2008<ref>''Modern Fortran Explained'' (2011), Michael Metcalf, John Reid, and Malcolm Cohen, {{ISBN|978-0-19-960142-4}}</ref> extensions have been implemented as of April 2014 with version 14.0.3.<ref>Absoft page on compiler features; click on 'New in Pro Fortran 2014\" and 'F2008 Supported Features' to expand text.[http://www.absoft.com/Absoft_Windows_Compiler.htm]</ref>\n\n==== Fortran 2003 ====\nSome Fortran 2003 extensions are available in current versions of Absoft Pro Fortran.  Among these are:\n\n* <code>ISO_C_BINDING</code> and <code>ISO_FORTRAN_ENV</code>\n* <code>ACOS</code>, <code>ASIN</code>, and <code>ATAN</code> generics accept complex arguments\n* <code>COSH</code>, <code>SINH</code>, and <code>TANH</code> generics accept complex arguments\n* <code>MOVE_ALLOC</code> statement\n* <code>GET_COMMAND</code>, <code>GET_COMMAND_ARGUMENT</code> and <code>COMMAND_ARGUMENT_COUNT</code>\n* <code>GET_ENVIRONMENT_VARIABLE</code>\n* <code>FLUSH</code> statement\n* <code>IS_IOSTAT_END</code> and <code>IS_IOSTAT_EOR</code>\n* <code>ENUMERATOR</code> and <code>ENUM</code>\n* <code>NEW_LINE</code>\n* <code>ABSTRACT INTERFACE</code>\n* <code>PROCEDURE</code> pointers\n* enhanced <code>TYPE</code> initialization\n* <code>POINTER</code> bounds remapping\n* recognizes <code>ASYNCHRONOUS</code> I/O specifiers\n* <code>IOMSG=''string_variable_for_error_text_string''</code>  I/O statement specifier\n* IEEE exceptions\n* <code>VALUE</code> statement and declaration attribute\n\n==== Fortran 2008 ====\nSeveral Fortran 2008 extensions are available as of April 2014.  More will be available with updates and new releases.  Those available now include, but are not limited to:\n\n* <code>ACOSH</code>, <code>ASINH</code>, <code>ATANH</code> intrinsics\n* <code>HYPOT</code> intrinsic\n* <code>LEADZ</code> and <code>TRAILZ</code> intrinsics\n* <code>POPCNT</code> and <code>POPPAR</code> intrinsics\n* empty <code>CONTAINS</code> section\n* <code>BESSEL_J0</code>, <code>BESSEL_J1</code>, and <code>BESSEL_JN</code> intrinsic functions\n* <code>BESSEL_Y0</code>, <code>BESSEL_Y1</code>, and <code>BESSEL_YN</code> intrinsics\n* <code>BGE</code>, <code>BGT</code>, <code>BLE</code>, and <code>BLT</code> intrinsics\n* <code>DSHIFTL</code> and <code>DSHIFTR</code> intrinsics\n* <code>SHIFTA</code>, <code>SHIFTL</code> and <code>SHIFTR</code> intrinsics\n* <code>MASKL</code>, <code>MASKR</code> and <code>MERGE_BITS</code> intrinsics\n* <code>EFC_SCALED</code>, <code>GAMMA</code> and <code>LOG_GAMMA</code> intrinsics\n* <code>EXECUTE_COMMAND_LINE</code> intrinsic\n* <code>IS_IOSTAT_END</code> and <code>IS_IOSTAT_EOF</code> intrinsics\n* <code>SELECTED_CHAR_KIND</code> intrinsic\n* Allocatable components of derived types (data structures) (partial implementation)\n* Pointer <code>INTENT</code> attribute\n\n=== Bundled and optional packages ===\n[[File:Absoft Project Options.png|thumb|right|Screen shot from Absoft IDE, showing the libraries that are available for integration into the compiler by checking the appropriate box]]\n\nAll of these packages are included in the IDE and fully integrated into the compiler.  Cost is included in purchase price except IMSL and GINO or Winteracter, which are sold separately.  Installed packages can be selected for inclusion in a build by checkboxes on a tab on the Project Options menu as illustrated in the screen shot to the right.  Some of these are detailed below.\n\n==== Absoft FX3 graphical debugger ====\nThe FX3 graphical debugger is bundled with all Absoft Pro Fortran releases.  The FX3 graphical debugger is compatible with the [[GNU Compiler Collection]] (gcc) (on Macintosh and Linux), Apple C, Microsoft Visual Studio C/C++ (Windows only), and assembly language on all three platforms.\n\n==== GINO's and Winteracter's GUI for Fortran ====\nGINO<ref>[http://gino-graphics.com/ GINO web site]</ref> and Winteracter<ref>[http://winteracter.com Winteracter web site]</ref><ref>[http://www.absoft.com/products/winteracter-gui-toolset/ Absoft page on Winteracter]</ref> are optional third-party APIs for creating complex 2D and 3D graphics and GUI applications using Fortran programs.  GINO Lite (32-bit only, some restrictions) is bundled with Absoft Pro Fortran for Windows at no additional charge and is well suited for most users.  Absoft offers licenses on all platforms for full versions of GINO or Winteracter that includes 64-bit support, has no limitations, and is integrated with the Absoft Pro Fortran suite.\n\n==== IMSL libraries ====\nAbsoft is the only commercial  Fortran vendor to offer [[IMSL Numerical Libraries]] bundles with Fortran compilers for Windows, Mac and Linux. Absoft is the only IMSL provider for MacOS.  Absoft sells licenses for IMSL and documentation as unlocking codes that allow release of IMSL libraries and documentation from the Absoft installation software.  Current releases ship with IMSL 7, the latest release.\n\n==== UNIX and VAX/VMS compatibility libraries ====\nFor use in porting code written on UNIX or VAX systems, libraries of UNIX-specific and VAX-specific Fortran intrinsics are available by checking a box in the Project Options, Libraries/Tools window.  Other extensions important for porting from other platforms, such as Cray pointers, are included in Absoft Pro Fortran as part of the compiler.\n\n==== LAPACK and BLAS ====\nLinear Algebra Package ([[LAPACK]] with Basic Linear Algebra Subprograms ([[BLAS]]), or BLAS alone, are offered as linkable libraries.\n\n==== HDF4, HDF5 ====\n'''[[Hierarchical Data Format]]''' libraries HDF4 release 4.2.8 and HDF5 release 1.8.9 can be included by checking a box in the Project Options, Libraries/Tools window.\n\n==== NetCDF ====\nNetwork Common Data Form ([[NetCDF]]) version 4.3 is available by checking a box.\n\n==== CUDA and CAPS ====\n[[NVIDIA]] manufactures graphics cards that use arrays of '''Complete Unified Device Architecture''' ([[CUDA]]) [[graphics processing units]].  A special version of [[BLAS]] can be included in linking libraries by checking a box in the Project Options, Libraries/Tools window.\n\nCAPS is a many-core compiler for using arrays of CUDA cores in a GPU for computation.\n\n==== PLplot libraries ====\n[[PLplot]] 5.9 is available by checking a box on the Project Options Libraries/Tools window.  Bindings are available for both single and double precision, from FORTRAN 77 or Fortran 95 or for calling from Microsoft WIN32.\n\n==== DLL and system calls ====\nFor all platforms, Absoft Pro Fortran links from user static or dynamic libraries provided by the system, other compilers, or the user.  Absoft Pro Fortran has the capability to generate both static and dynamic libraries.\n\n==== Command line and C/C++ interoperability ====\nAll Absoft compilers can be invoked and fully controlled form the command line.  Since Absoft has used the system linker format for all platforms since version 10.0 in 2005, C/C++ object files can be linked with Absoft compiler object files, and integration with the most common C/C++ compilers is done by settings in the Absoft IDE.\n\nThe Absoft IDE is hard-wired to use the Absoft Fortran compilers, and is customizable to use a C/C++ compiler that produces object files compatible with the system linker.\n\n== Absoft-specific GUI optional features ==\nAbsoft-specific GUI options allow use of programs compiled with Absoft Pro Fortran using the mouse and dealing with pop-ups in the same way that windowed GUI applications are used.  The use of Absoft-specific GUI features is portable between platforms using Absoft Pro Fortran on each platform, but other compilers and platforms cannot use these features, and Absoft-specific feature code will not be recognized by other compilers.\n\n=== MRWE ===\nThe Microsoft/Macintosh Runtime Window Environment (MRWE)<ref>Separate MRWE manual in Absoft Pro Fortran included documentation, provided as a PDF file.</ref> option uses a Fortran 77 overarching main program that calls system GUI libraries to produce a windowed application.  The MRWE environment is selected as an executable type in the IDE options for building an application.  The default MRWE program maps input and output to a scrolling window similar to a command prompt, but the user retains all the output and can save it as a text file after the program exits.  Hooks are provided in the MRWE GUI program to add Windows system calls to enhance the user interface, providing the potential for a full-featured Windows program written entirely in Fortran.  MRWE source code is available as a starting point for an all-Fortran Win32 GUI application.  MRWE was replaced by AWE in 2012 but is still available as a target environment for legacy programs.\n\n=== AWE ===\n'''The Absoft Window Environment''' (AWE<ref>[http://www.absoft.com/wp-content/uploads/2016/03/Windows_ProFortran_17.0_UserGuide.pdf Absoft Pro Fortran 17.0 User Guide, Chapter 8]</ref>) is provided by selecting the application type in the GUI.  When this is done, a file <code>AWE_Preferences.f95</code> is added to your project.  This Fortran file includes small procedures called during initialization that configure AWE by defining stack size for the interactive window, window size and behavior, and the font.\n\nAn AWE application can enhance the interactive console window menu items that can be used to execute program units and exit, providing a GUI for an interactive application.  The program units can operate using pop-ups, menus, and display windows, so that the traditional console I/O is not used at all, and thus providing an all-Fortran GUI driven application on all three supported platforms.\n\nAWE applications distributed for use without the Absoft compiler need to have <code>libgomp.dll</code> included with 32-bit executable files or <code>libgompx64.dll</code> for 64-bit executable files.  These DLLs are released under the [[Free Software Foundation]] [[GNU General Public License]] (version 3 with GCC Library Exception).<ref>[https://www.gnu.org/licenses/gpl.html GNU Public License, Version 3]</ref>\nThe interactive pop-ups, graphics, and spreadsheets are accessed bu a <code>use AWE_Interfaces</code> statement.  Distribution of executables with these features requires inclusion of <code>QtCore4.dll</code> and <code>QtGui4.dll</code>.  Qt<ref>Qt Creator web site on Sourceforge [http://sourceforge.net/projects/qtcreator.mirror/].</ref><ref>Qt x64 web site on Sourceforge [http://sourceforge.net/projects/qtx64].</ref> is licensed under the LGPL v. 2.1.\n\n==== Interactive console window ====\nCompiling as an AWE application maps standard input and output to a scrolling window similar to a command prompt, but the user retains all the output and has the option of saving it as a text file after the program exits.  The other features, detailed below, are enabled by the use of an AWE application.  An interactive AWE application can be written that does not use the interactive console at all, leaving this window available for use as a run log.\n\n==== Menus, pop-up messages, dialog boxes, and forms ====\nThese functions are implemented through calls to procedures in the <code>AWE_Interfaces</code> module.  Coding is about the same as would be needed for an interactive command-line window interface.<ref>Absoft Pro Fortran 14.0 User Guide, Chapter 8, section '''Awe Menus'''.</ref>\n\n==== Built-in graphics ====\nBar charts, pie charts and X-Y charts are supported through calls to procedures in the <code>AWE_Interfaces</code> module.  Defaults provide simplified usage but a great deal of flexibility in output colors, line colors and widths, background, etc. are available if desired.<ref>Absoft Pro Fortran 14.0 User Guide, Chapter 8, section '''Plots'''.</ref>\n\n==== Three-D plots ====\nThree-d plots including perspective x-y-z plots and contour plots also are supported through calls to procedures in the <code>AWE_Interfaces</code> module for the 2015 release and later.\n\n==== Spreadsheets ====\nYou can create spread sheet windows in AWE to display rank 2 arrays. Subroutines are provided to open, close, read, write, and label spread sheets. Menu commands, described above, can be added to an AWE program to manipulate the data in the spread sheet.<ref>Absoft Pro Fortran 14.0 User Guide, Chapter 8, section '''Spread Sheets'''</ref>\n\n== User base ==\nA page on the Absoft web site,<ref>[http://www.absoft.com/corporate/commercial.users.html Absoft page of Selected Users]</ref> lists over 180 corporate and Government license users.  Among these are Apple computer, C.E.R.N Laboratories, Lawrence Livermore National Laboratories, NASA Lewis Research Center, Naval Undersea Warfare Center, Naval Research Laboratory, Naval Surface Warfare Center, Raytheon Systems Company, Seagate Technology, Toshiba Corporation, USAF Phillips Lab, Boeing Defense and Space, Canon, Inc., Nikon Corporation, Computer Sciences Corporation, General Motors, Ford Motor Company, Toyota Motor Company, Hewlett Packard, Institute for Defense Analysis, Lockheed Martin, Los Alamos National Laboratories, McDonnell Douglas, MIT Lincoln Laboratories, Mitsubishi Heavy Industries, SRI International, Texas Instruments, U.S. Air Force, Wolfram Research, Advanced Micro Devices, Argonne National Laboratories, AT&T Bell Laboratories, Boeing Military Airplane Company, Brookhaven National Laboratory, C.S.Draper Laboratories, David Sarnoff Research Center, GE Aerospace, IBM T.J. Watson Research Center, Intel Corporation, Jet Propulsion Laboratory, Lawrence Berkeley Laboratories, Loral Space & Range Systems, Mitre Corporation, NASA Langley Research Center, and many others.\n\n== Gallery ==\n<gallery>\nFile:Example_of_plot_using_AWE.png|Example of plot using AWE\nFile:Example_of_simple_plot_using_PLplot.png|Example of simple plot using PLplot\nFile:Example_of_simple_fishnet_plot_using_PLplot.png|Example of simple fishnet plot using PLplot\n</gallery>\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* {{Official website|https://www.absoft.com/}}\n\n[[Category:Compilers]]\n[[Category:Fortran compilers]]\n[[Category:Debuggers]]\n[[Category:Integrated development environments]]"
    },
    {
      "title": "AMD Optimizing C/C++ Compiler",
      "url": "https://en.wikipedia.org/wiki/AMD_Optimizing_C%2FC%2B%2B_Compiler",
      "text": "{{refimprove|date=May 2017}}\n{{Infobox software\n| name = \n| screenshot = \n| caption = \n| developer = [[AMD]]\n| released = {{Start date and age|2017}}\n| discontinued = yes\n| latest release version = 1.3.0\n| latest release date = {{Start date and age|2018|05|12}}\n| operating system = [[Cross-platform]], [[Linux]]\n| genre = [[Compiler]]\n| license = [[University of Illinois/NCSA Open Source License]]\n| website = {{URL|https://developer.amd.com/amd-aocc/}}\n}}\n\nThe '''AMD Optimizing C/C++ Compiler''' ('''AOCC''') is a [[free software|free]], [[Open-source software|open source]], optimizing [[compiler]] from [[AMD]] targeting 32-bit and 64-bit [[Linux]] platforms.<ref name=\"userguide\">{{cite web|url=http://developer.amd.com/wordpress/media/2017/04/AOCC-User-guide-%E2%80%94-AOCC-LLVM-1.pdf|title=AOCC User guide|publisher=AMD}}</ref><ref name=\"larabel2\">{{cite web|url=https://www.phoronix.com/scan.php?page=news_item&px=AMD-AOCC-1.0-Released|title=AMD Releases Optimizing C/C++ Compiler For Ryzen - Phoronix|website=www.phoronix.com}}</ref> It is based on [[LLVM]] [[Clang]] 6.0<ref>{{cite web|url=https://developer.amd.com/amd-aocc/|title=AMD Optimizing C/C++ Compiler|website=developer.amd.com}}</ref> with various additional patches to improve performance for AMD's [[Ryzen]] microprocessors. AOCC also includes a version of DragonEgg [[GNU Compiler Collection|gcc]] plugin for [[Fortran]] sources.<ref name=\"userguide\"/><ref name=larabel>{{cite web|url=http://www.phoronix.com/scan.php?page=article&item=amd-ryzen-aocc&num=1|title=Benchmarking AMD's New AOCC Compiler For Ryzen - Phoronix|website=www.phoronix.com}}</ref>\n\nIn a May 2017 [[benchmark (computing)|benchmark]] comparing AOCC v1.0 to Clang 4 and 5, and GCC 6 through 8, Phoronix found AOCC provided significant but modest improvement over Clang 4.0 in several benchmarks and no difference in others.<ref name=larabel />  Compilation time generally increased relative to Clang 4.0.  Some benchmarks found some versions of GCC had better performance than some versions of Clang (AOCC included), and vice versa.\n\n==See also==\n*[[Clang]]\n* [[Intel C++ Compiler]]\n* [[List of compilers]]\n\n== References ==\n{{Reflist}}\n\n==External links==\n* {{official|https://developer.amd.com/amd-aocc/}}\n\n[[Category:C compilers]]\n[[Category:C++ compilers]]\n[[Category:Compilers]]\n[[Category:Fortran compilers]]\n[[Category:Free compilers and interpreters]]\n[[Category:Advanced Micro Devices software]]\n\n{{free-software-stub}}"
    },
    {
      "title": "F2c",
      "url": "https://en.wikipedia.org/wiki/F2c",
      "text": "{{Otheruses|F2C (disambiguation)}}\n{{lowercase|f2c}}\n{{inline|date=September 2016}}\n\n{{Infobox software\n| name                   = f2c\n}}\n'''f2c''' is a program to [[Transcompiler|convert]] [[Fortran 77]] to [[C (programming language)|C]] code, developed  at [[Bell Laboratories]].  The standalone f2c program was based on the core of the first complete Fortran 77 [[compiler]] to be implemented, the \"f77\" program by Feldman and Weinberger.  Because the f77 compiler was itself written in C and relied on a C compiler back end to complete its final compilation step, it and its derivatives like f2c were much more portable than compilers generating [[machine code]] directly.\n\nThe f2c program was released as [[free software]] and subsequently became one of the most common means to compile Fortran code on many systems where native Fortran compilers were unavailable or expensive.  Several large Fortran libraries, such as [[LAPACK]], were made available as C libraries via conversion with f2c.  The f2c program also influenced the development of the [[GNU Compiler Collection|GNU g77 compiler]], which uses a modified version of the f2c runtime [[Library (computing)|libraries]].\n\n==See also==\n*[[BCX]] – translates BASIC source code to C/C++ source code\n\n== References ==\n{{reflist}}\n{{refbegin}}\n* S. I. Feldman and P. J. Weinberger. [http://citeseer.ist.psu.edu/feldman90portable.html A portable Fortran 77 compiler]. In ''UNIX Time Sharing System Programmer's Manual'', volume 2. AT&T Bell Laboratories, tenth edition, 1990.\n* S. I. Feldman, David M. Gay, Mark W. Maimone, and N. L. Schryer, \"[http://citeseer.ist.psu.edu/feldman93fortrantoc.html A Fortran to C Converter],\" AT&amp;T Bell Laboratories technical report, 1990.  Also the paper of the same title by S. I. Feldman, published in ''ACM SIGPLAN Fortran Forum'', vol. 9, issue 2, p. 21–22 (1990).\n* The [http://www.netlib.org/f2c/ f2c] source code and documentation, at [[Netlib]].\n{{refend}}\n\n[[Category:Fortran compilers]]\n[[Category:Compilers]]\n[[Category:Source-to-source compilers]]\n[[Category:C (programming language)]]\n[[Category:Free compilers and interpreters]]\n[[Category:Free software programmed in C]]"
    },
    {
      "title": "G95",
      "url": "https://en.wikipedia.org/wiki/G95",
      "text": "{{Distinguish|GNU Fortran|G95 Capital Area Loop Expressway}}\n{{Infobox software\n| name = G95\n| logo = <!-- Image name is enough. -->\n| logo alt = \n| logo caption = \n| screenshot = <!-- Image name is enough. -->\n| screenshot alt = \n| caption = \n| collapsible = <!-- Any text here will collapse the screenshot. -->\n| author = Andy Vaught\n| developer = \n| released = {{Start date and age|2000}}\n| discontinued = yes\n| ver layout = <!-- simple (default) or stacked -->\n| latest release version = 0.93\n| latest release date = {{Start date and age|2012|10|df=yes/no}}\n| latest preview version = \n| latest preview date = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| programming language = [[C (programming language)|C]]\n| operating system = \n| platform = \n| size = \n| language = \n| language count = <!-- Number only -->\n| language footnote = \n| genre = [[Compiler]]\n| license = [[GNU General Public License|GNU GPLv2]]\n| alexa = \n| website = {{Official URL}}\n| repo = {{URL|http://g95.cvs.sourceforge.net/}}\n| standard = \n| AsOf = \n}}\n'''G95''' is a [[free software license|free]], [[porting|portable]], [[open-source software|open-source]] [[Fortran 95]] [[compiler]]. It implements the Fortran 95 standard, part of the [[Fortran 2003]] standard, as well as some old and new extensions including features for the [[Fortran#Fortran 2008|Fortran 2008]] standard like [[coarray Fortran]]. It also supports the [[F programming language]] subset.\n\nG95 was primarily developed by Andy Vaught, before he moved to competing compiler vendor [[PathScale]]. The last stable version, 0.93, was released in October 2012.<ref>http://www.g95.org/downloads.shtml#V0.93</ref> Development of G95 stopped in 2013, and the compiler is not longer maintained.\n\n[[gfortran|GNU Fortran]], a part of GCC also known as gfortran, has now bypassed G95 in terms of its Fortran 2008 implementation and in the speed of the generated code.<ref>http://fortranwiki.org/fortran/show/Fortran+2008+status</ref> [[GNU Fortran]] was originally [[Fork (software development)|forked]], in January 2003, from G95.<ref>{{cite web |title=The other GCC-based Fortran compiler |publisher=[[GNU]]| date=2010 |url=https://gcc.gnu.org/wiki/TheOtherGCCBasedFortranCompiler |accessdate=2015-11-08 }}</ref>\n\n==References==\n{{Reflist}}\n\n== External links ==\n* {{Official website}}\n* {{sourceforge}}\n\n[[Category:Fortran compilers]]\n[[Category:Free compilers and interpreters]]\n\n\n{{compu-prog-stub}}"
    },
    {
      "title": "GNU Compiler Collection",
      "url": "https://en.wikipedia.org/wiki/GNU_Compiler_Collection",
      "text": "{{Redirect|Cc1|other uses|CC1 (disambiguation)}}\n{{Use mdy dates|date=March 2015}}\n{{Infobox software\n| name                   = GNU Compiler Collection\n| logo                   = [[File:GNU Compiler Collection logo.svg|100px]]\n| logo caption           =\n| screenshot             =\n| caption                =\n| collapsible            =\n| author                 =\n| developer              = [[GNU Project]]\n| released               = {{Start date and age|1987|05|23}}<ref name=\"release-history\">{{cite web | url = https://www.gnu.org/software/gcc/releases.html | title = GCC Releases | accessdate = 2006-12-27 | publisher = GNU Project }}</ref>\n| discontinued           =\n| latest release version = 9.1<ref>https://gcc.gnu.org/gcc-9/<!-- sync this with [[GNU Fortran]] --></ref>\n| latest release date    = {{Start date and age|2019|05|03}}<!-- sync this with and [[GNU Fortran]] -->\n| programming language   = [[C (programming language)|C]] with some parts written in [[C++]] <ref name=\"gcc-c++\" />\n| operating system       = [[Cross-platform]]\n| platform               = [[GNU]]\n| size                   =\n| language               =\n| genre                  = [[Compiler]]\n| license                = [[GNU General Public License|GPLv3+]] with GCC Runtime Library Exception<ref>{{cite web | accessdate = 2013-02-28 | url = https://www.gnu.org/licenses/gcc-exception.html | title = GCC Runtime Library Exception}}</ref>\n| alexa                  =\n| website                = {{URL|https://gcc.gnu.org}}\n}}\n\nThe '''GNU Compiler Collection''' ('''GCC''') is a [[compiler]] system produced by the [[GNU Project]] supporting various [[programming language]]s. GCC is a key component of the [[GNU toolchain]] and the standard compiler for most projects related to [[GNU]] and [[Linux]], the most notable is the [[Linux kernel]]. The [[Free Software Foundation]] (FSF) distributes GCC under the [[GNU General Public License]] (GNU GPL). GCC has played an important role in the growth of [[free software]], as both a tool and an example.\n\nWhen it was first released in 1987, GCC 1.0 was named the '''GNU C Compiler''' since it only handled the [[C (programming language)|C programming language]].<ref name=\"release-history\" /> It was extended to compile [[C++]] in December of that year. [[Compiler frontend|Front ends]] were later developed for [[Objective-C]], [[Objective-C++]], [[Fortran]], [[Java (programming language)|Java]], [[Ada (programming language)|Ada]], and [[Go (programming language)|Go]], among others.<ref>{{cite web|url=https://gcc.gnu.org/frontends.html|title=Programming Languages Supported by GCC|accessdate=2014-06-23|publisher=GNU Project }}</ref>\n\nVersion 4.5 of the [[OpenMP]] specification<!--list as a language, [[Clang]] does..--> is now supported in the C and C++ compilers<!-- as opposed to partial support for Fortran, which cites \"Improved support for OpenMP and OpenACC.--><ref name=\"gcc6\">{{cite web |url=https://gcc.gnu.org/gcc-6/changes.html |title=GCC 6 Release Series}}</ref> and a \"much improved\" implementation of the [[OpenACC]] 2.0a specification<ref>{{cite web |url=https://gcc.gnu.org/wiki/OpenACC |title=OpenACC}}</ref> is also supported. <!--cite web |title=Offloading Support in GCC |quote=OpenMP to Intel MIC targets (upcoming Intel Xeon Phi products codenamed KNL) as well as MIC emulation on host. OpenACC to Nvidia PTX targets.--> By default, the current version supports ''gnu++14'', a superset of [[C++14]], and ''gnu11'', a superset of [[C11 (C standard revision)|C11]], with strict standard support also available. It also provides experimental support for [[C++17]] and later.\n\nGCC has been [[porting|ported]] to a wide variety of [[instruction set architecture]]s, and is widely deployed as a tool in the development of both free and [[proprietary software]]. GCC is also available for most [[embedded system]]s,{{Citation needed|date=October 2015}} including [[ARM architecture|ARM]]-based; [[Applied Micro Circuits Corporation|AMCC]], and [[Freescale]] [[Power ISA]]-based chips.<ref name=\"Linux Board Support Packages\">{{cite web|url=http://www.freescale.com/webapp/sps/site/overview.jsp?code=CW_BSP&fsrch=1|title=Linux Board Support Packages|accessdate=2008-08-07 }}</ref> The compiler can target a wide variety of platforms.\n\nAs well as being the official compiler of the [[GNU operating system]], GCC has been adopted as the standard compiler by many other modern [[Unix-like]] computer [[operating system]]s, including [[Linux]] and the [[Berkeley Software Distribution|BSD]] family, although [[FreeBSD]] and [[macOS]] have moved to the [[LLVM]] system.<ref>http://llvm.org/Users.html</ref> Versions are also available for [[Microsoft Windows]] and other operating systems; GCC can compile code for [[Android (operating system)|Android]] and [[iOS]].\n\nGCC is still not able to produce [[reproducible builds]], but patches are available and waiting to be merged.<ref>{{cite web | url = https://lwn.net/Articles/757118/ | last = Yates | first = Tom | title = Toward a fully reproducible Debian [LWN.net] | date = 2018-06-15 | accessdate = 2018-12-31 | publisher = Eklektix, Inc. }}</ref>\n\n== History ==\nIn an effort to bootstrap the [[GNU]] operating system, [[Richard Stallman]] asked [[Andrew S. Tanenbaum]], the author of the [[Amsterdam Compiler Kit]] (also known as the ''[[VU University Amsterdam|Free University]]'' Compiler Kit) for permission to use that software for GNU. When Tanenbaum advised him that the compiler was not free, and that only the ''Free University'' kit was free, Stallman decided to write a new compiler.<ref>{{cite book |last=von Hagen |first=William |date=2006 |title=The Definitive Guide to GCC |edition=2nd |series=Definitive Guides |publisher=Apress |isbn=978-1-4302-0219-6 |page=XXVII |quote=So he wrote to VUCK's author asking if GNU could use it. Evidently, VUCK's developer was uncooperative, responding that the university was free but that the compiler was not. |url=https://books.google.us/books?id=wQ6r3UTivJgC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false}}</ref> Stallman's initial plan<ref name=LLLCompiler>{{cite web | last = Stallman | first = Richard | title = About the GNU Project | publisher = The GNU Project | date = September 20, 2011 | url = https://www.gnu.org/gnu/thegnuproject.html | accessdate = October 9, 2011 }}</ref> was to rewrite an existing compiler from [[Lawrence Livermore Laboratory]] from [[Pastel (programming language)|Pastel]] to C with some help from [[Leonard H. Tower, Jr.|Len Tower]] and others.<ref>{{cite journal | editor-last = Puzo | editor-first = Jerome E. | title = Gnu's Zoo | journal = GNU'S Bulletin | volume = 1 | issue = 1 | date = February 1986 | publisher = Free Software Foundation | url = https://www.gnu.org/bulletins/bull1.txt | accessdate = 2007-08-11 }}</ref> Stallman wrote a new C front end for the Livermore compiler, but then realized that it required megabytes of stack space, an impossibility on a 68000 Unix system with only 64&nbsp;KB, and concluded he would have to write a new compiler from scratch.<ref name=LLLCompiler /> None of the Pastel compiler code ended up in GCC, though Stallman did use the C front end he had written.<ref name=LLLCompiler />\n\nGCC was first released March 22, 1987, available by [[File Transfer Protocol|FTP]] from [[Massachusetts Institute of Technology|MIT]].<ref>{{cite newsgroup | title = GNU C compiler beta test release | author = Richard M. Stallman (forwarded by Leonard H. Tower, Jr.) | date = March 22, 1987 | newsgroup = comp.lang.c |message-id= | url = https://groups.google.com/group/comp.lang.misc/msg/32eda22392c20f98 | accessdate = October 9, 2011 }}</ref> Stallman was listed as the author but cited others for their contributions, including Jack Davidson and Christopher Fraser for the idea of using [[Register transfer language|RTL]] as an intermediate language, Paul Rubin for writing most of the preprocessor and Leonard Tower for \"parts of the parser, RTL generator, RTL definitions, and of the Vax machine description.\"<ref name=GccContributors>{{ citation | last = Stallman | first = Richard M. | title = Using and Porting the GNU Compiler Collection (GCC) | chapter-url = https://gcc.gnu.org/onlinedocs/gcc-2.95.3/gcc_23.html | publisher = Free Software Foundation, Inc. | date = June 22, 2001 | orig-year = First published 1988 | chapter = Contributors to GNU CC | page = 7 | accessdate = June 18, 2015 |postscript=.}}</ref> Described as the \"first free software hit\" by [[Peter H. Salus|Salus]], the GNU compiler arrived just at the time when [[Sun Microsystems]] was unbundling its development tools from [[SunOS|its operating system]], selling them separately at a higher combined price than the previous bundle, which led many of Sun's users to buy or download GCC instead of the vendor's tools.<ref name=\"penguin\">{{cite book |first=Peter H. |last=Salus |authorlink=Peter H. Salus |title=The Daemon, the Gnu and the Penguin |chapter=Chapter 10. SUN and gcc |url=http://www.groklaw.net/article.php?story=20050525231654621 |publisher=[[Groklaw]] |year=2005}}</ref> By 1990, GCC supported thirteen computer architectures, was outperforming several vendor compilers, was shipped by [[Data General]] and [[NeXT]] with their workstations and was used by [[Lotus Development Corporation]].<ref>{{cite news |newspaper=Computerworld |date=6 August 1990 |authorlink=Simson Garfinkel |first=Simson L. |last=Garfinkel |title=Get ready for GNU software |url=https://books.google.com/books?id=mZ0kj6qvsvYC&pg=PT101}}</ref>\n\nAs GCC was licensed under the GPL, programmers wanting to work in other directions—particularly those writing interfaces for languages other than C—were free to develop their own [[Fork (software development)|fork]] of the compiler, provided they meet the GPL's terms, including its requirements to distribute [[source code]]. Multiple forks proved inefficient and unwieldy, however, and the difficulty in getting work accepted by the official GCC project was greatly frustrating for many.<ref name=egcs>{{ citation | last = Henkel-Wallace | first = David | title = A new compiler project to merge the existing GCC forks | url = https://gcc.gnu.org/news/announcement.html | date = August 15, 1997 | accessdate = May 25, 2012 |postscript=.}}</ref> The FSF kept such close control on what was added to the official version of GCC 2.x that GCC was used as one example of the \"cathedral\" development model in [[Eric S. Raymond]]'s essay ''[[The Cathedral and the Bazaar]]''.\n\n{{Anchor|EGCS Fork}}In 1997, a group of developers formed Experimental/Enhanced GNU Compiler System (EGCS) to merge several experimental forks into a single project.<ref name=\"egcs\" /><ref>{{cite web|title=Pentium Compiler FAQ|url=http://home.schmorp.de/pgcc-faq.html#egcs}}</ref> The basis of the merger was a GCC development snapshot taken between the 2.7 and 2.81 releases. Projects merged included g77 (Fortran), PGCC ([[P5 (microarchitecture)|P5]] [[Pentium]]-optimized GCC), many C++ improvements, and many new architectures and [[operating system]] variants.<ref>{{cite web|title=The Short History of GCC development|url=http://www.softpanorama.org/People/Stallman/history_of_gcc_development.shtml}}</ref> EGCS development proved considerably more vigorous than GCC development, so much so that the FSF officially halted development on their GCC 2.x compiler, blessed EGCS as the official version of GCC and appointed the EGCS project as the GCC maintainers in April 1999. With the release of GCC 2.95 in July 1999 the two projects were once again united.\n\nGCC has since been maintained by a varied group of programmers from around the world under the direction of a steering committee.<ref>{{cite web|url=https://gcc.gnu.org/steering.html|title=GCC Steering Committee}}</ref> It has been ported to more kinds of [[central processing unit|processors]] and operating systems than any other compiler.<ref>{{cite web|url=http://www.linfo.org/gcc.html|title=Linux Information Project| quote=The GCC has been ported to (i.e., modified to run on) more than 60 platforms, which is more than for any other compiler. |publisher=LINFO|accessdate=2010-04-27}}</ref>{{Unreliable source?|date=April 2013}}\n\nGCC has been [[porting|ported]] to a wide variety of [[instruction set architecture]]s, and is widely deployed as a tool in the development of both free and [[proprietary software]]. GCC is also available for most [[embedded system]]s,{{Citation needed|date=October 2015}} including [[Symbian]] (called ''gcce''),<ref>{{cite web|url=http://www.inf.u-szeged.hu/symbian-gcc/|title=Symbian GCC Improvement Project|accessdate=2007-11-08 }}</ref> [[ARM architecture|ARM]]-based; [[Applied Micro Circuits Corporation|AMCC]], and [[Freescale]] [[Power ISA]]-based chips.<ref name=\"Linux Board Support Packages\"/> The compiler can target a wide variety of platforms, including [[video game console]]s such as the [[PlayStation 2]],<ref>{{cite web|url=http://ps2stuff.playstation2-linux.com/gcc_build.html |title=setting up gcc as a cross-compiler |work=ps2stuff |date=2002-06-08 |accessdate=2008-12-12 |deadurl=yes |archiveurl=https://web.archive.org/web/20081211044658/http://ps2stuff.playstation2-linux.com/gcc_build.html |archivedate=December 11, 2008 }}</ref> Cell SPE of PlayStation 3<ref>https://gcc.gnu.org/wiki/CompileFarm</ref> and [[Dreamcast]].<ref>{{cite web |url=http://www.ngine.de/gccguide.html |title=sh4 g++ guide |archiveurl=https://web.archive.org/web/20021220025554/http://www.ngine.de/gccguide.html |archivedate=2002-12-20 |accessdate=2008-12-12 }}</ref>\n\n== Design ==\n[[File:Linux kernel interfaces.svg|thumb|300px|To obtain a stable [[Application binary interface|ABI]], like e.g. the [[Linux Standard Base]] aims to procure, the compiler version is important.]]\n\nGCC's external interface follows [[Unix]] conventions. Users invoke a language-specific driver program (<code>gcc</code> for C, <code>g++</code> for C++, etc.), which interprets [[Command-line argument|command arguments]], calls the actual compiler, runs the [[Assembly language assembler|assembler]] on the output, and then optionally runs the [[Linker (computing)|linker]] to produce a complete [[executable]] binary.\n\nEach of the language compilers is a separate program that reads source code and outputs [[machine code]]. All have a common internal structure. A per-language front end [[parsing|parses]] the source code in that language and produces an [[abstract syntax tree]] (\"tree\" for short).\n\nThese are, if necessary, converted to the middle end's input representation, called ''GENERIC'' form; the middle end then gradually transforms the program towards its final form. [[Compiler optimization]]s and [[static code analysis]] techniques (such as FORTIFY_SOURCE,<ref>{{cite web|url=http://fedoraproject.org/wiki/Security/Features |title=Security Features: Compile Time Buffer Checks (FORTIFY_SOURCE) |publisher=fedoraproject.org |accessdate=2009-03-11 }}</ref> a compiler directive that attempts to discover some [[buffer overflow]]s) are applied to the code. These work on multiple representations, mostly the architecture-independent GIMPLE representation and the architecture-dependent [[Register transfer language|RTL]] representation. Finally, [[machine code]] is produced using architecture-specific [[pattern matching]] originally based on an algorithm of Jack Davidson and Chris Fraser.\n\nGCC was written primarily in [[C (programming language)|C]] except for parts of the [[Ada (programming language)|Ada]] front end. The distribution includes the standard libraries for Ada, [[C++]], and [[Java (programming language)|Java]] whose code is mostly written in those languages.<ref>{{cite web | url = http://www.ohloh.net/projects/gcc/analyses/latest | title = languages used to make GCC }}</ref><!-- primary source --> On some platforms, the distribution also includes a low-level runtime library, '''libgcc''', written in a combination of machine-independent C and processor-specific [[machine code]], designed primarily to handle arithmetic operations that the target processor cannot perform directly.<ref>{{cite web|url=https://gcc.gnu.org/onlinedocs/gccint/Libgcc.html|title=GCC Internals|publisher=GCC.org|accessdate=March 1, 2010}}</ref>\n\nIn May 2010, the GCC steering committee decided to allow use of a [[C++]] compiler to compile GCC.<ref name=\"gcc-c++\">{{cite news | title = GCC allows C++&nbsp;– to some degree | url = http://www.h-online.com/open/news/item/GCC-allows-C-to-some-degree-1012611.html | publisher = [[Heinz Heise|The H]] |date=June 1, 2010 }}</ref> The compiler was intended to be written in C plus a subset of features from C++. In particular, this was decided so that GCC's developers could use the [[Destructor (computer science)|destructors]] and [[Generic programming|generics]] features of C++.<ref>{{cite web|url=http://lists.gnu.org/archive/html/emacs-devel/2010-07/msg00518.html|title=An email by Richard Stallman on emacs-devel }}</ref>\n\nIn August 2012, the GCC steering committee announced that GCC now uses C++ as its implementation language.<ref>{{cite web|title=GCC 4.8 Release Series: Changes, New Features, and Fixes|url=https://gcc.gnu.org/gcc-4.8/changes.html|accessdate=October 4, 2013}}</ref> This means that to build GCC from sources, a C++ compiler is required that understands [[C++03|ISO/IEC C++03]] standard.\n\n=== Front ends ===\nEach [[front end (compiler)|front end]] uses a parser to produce the [[abstract syntax tree]] of a given [[source file]]. Due to the syntax tree abstraction, source files of any of the different supported languages can be processed by the same [[back end (Compiler)|back end]]. GCC started out using [[LALR parser]]s generated with [[GNU Bison|Bison]], but gradually switched to hand-written [[Recursive descent parser|recursive-descent parsers]]; for C++ in 2004,<ref>{{cite web|url=https://gcc.gnu.org/gcc-3.4/changes.html|title=GCC 3.4 Release Series Changes, New Features, and Fixes}}</ref> and for C and Objective-C in 2006.<ref>{{cite web|url=https://gcc.gnu.org/gcc-4.1/changes.html|title=GCC 4.1 Release Series Changes, New Features, and Fixes}}</ref> Currently{{When?|date=October 2018}} all front ends use hand-written recursive-descent parsers.\n\nUntil recently,{{When?|date=October 2018}} the tree representation of the program was not fully independent of the processor being targeted.\n\nThe meaning of a tree was somewhat different for different language front ends, and front ends could provide their own tree codes. This was simplified with the introduction of GENERIC and GIMPLE, two new forms of language-independent trees that were introduced with the advent of GCC 4.0. GENERIC is more complex, based on the GCC 3.x Java front end's intermediate representation. GIMPLE is a simplified GENERIC, in which various constructs are ''[[lowering (computer science)|lowered]]'' to multiple GIMPLE instructions. The [[C (Programming Language)|C]], [[C++]] and [[Java (programming language)|Java]] front ends produce GENERIC directly in the front end. Other front ends instead have different intermediate representations after parsing and convert these to GENERIC.\n\nIn either case, the so-called \"gimplifier\" then converts this more complex form into the simpler [[Static single assignment form|SSA]]-based GIMPLE form that is the common language for a large number of powerful language- and architecture-independent global (function scope) optimizations.\n\n=== GENERIC and GIMPLE ===\n''GENERIC'' is an [[intermediate representation]] language used as a \"middle end\" while compiling source code into [[executable|executable binaries]]. A subset, called ''GIMPLE'', is targeted by all the front ends of GCC.\n\nThe middle stage of GCC does all of the code analysis and [[optimizing compiler|optimization]], working independently of both the compiled language and the target architecture, starting from the GENERIC<ref>{{cite web|url=https://gcc.gnu.org/onlinedocs/gccint/GENERIC.html|title=GENERIC in GNU Compiler Collection Internals}}</ref> representation and expanding it to [[register transfer language]] (RTL). The GENERIC representation contains only the subset of the imperative [[computer programming|programming]] constructs optimized by the middle end.\n\nIn transforming the source code to GIMPLE,<ref>{{cite web|url=https://gcc.gnu.org/onlinedocs/gccint/GIMPLE.html|title=GIMPLE in GNU Compiler Collection Internals}}</ref> complex [[Expression (programming)|expressions]] are split into a [[three-address code]] using [[temporary variable]]s. This representation was inspired by the SIMPLE representation proposed in the McCAT compiler<ref>{{cite web |url=http://www-acaps.cs.mcgill.ca/info/McCAT/McCAT.html |title=McCAT |accessdate=2017-09-14 |deadurl=bot: unknown |archiveurl=https://web.archive.org/web/20040812030043/http://www-acaps.cs.mcgill.ca/info/McCAT/McCAT.html |archivedate=August 12, 2004 |df=mdy-all }}</ref> by Laurie J. Hendren<ref>{{cite web|url=http://www.sable.mcgill.ca/~hendren/|title=Laurie J. Hendren}}</ref> for simplifying the analysis and [[Optimization (computer science)|optimization]] of [[Imperative programming|imperative programs]].\n\n=== Optimization ===\nOptimization can occur during any phase of compilation; however, the bulk of optimizations are performed after the syntax and [[Semantic analysis (compiler)|semantic analysis]] of the front end and before the [[Code generation (compiler)|code generation]] of the back end; thus a common, even though somewhat contradictory, name for this part of the compiler is the \"middle end.\"\n\nThe exact set of GCC optimizations varies from release to release as it develops, but includes the standard algorithms, such as [[loop optimization]], [[jump threading]], [[common subexpression elimination]], [[instruction scheduling]], and so forth. The [[Register transfer language|RTL]] optimizations are of less importance with the addition of global SSA-based optimizations on [[GIMPLE]] trees,<ref>{{cite web|url=http://www.redhat.com/magazine/002dec04/features/gcc/|title=From Source to Binary: The Inner Workings of GCC|last=Novillo|first=Diego|work=[[Red Hat#Red Hat Magazine|Red Hat Magazine]]|date=December 2004|deadurl=yes|archiveurl=https://web.archive.org/web/20090401215553/http://www.redhat.com/magazine/002dec04/features/gcc/|archivedate=April 1, 2009|df=mdy-all}}</ref> as RTL optimizations have a much more limited scope, and have less high-level information.\n\nSome of these optimizations performed at this level include [[dead code elimination]], [[partial redundancy elimination]], [[global value numbering]], [[sparse conditional constant propagation]], and [[scalar replacement of aggregates]]. Array dependence based optimizations such as [[automatic vectorization]] and [[automatic parallelization]] are also performed. [[Profile-guided optimization]] is also possible.<ref>{{cite web|url=https://gcc.gnu.org/install/build.html#TOC4|title=Profile-guided optimization is demonstrated here}}</ref>\n\n=== Back end ===\nThe GCC's back end is partly specified by [[C preprocessor|preprocessor macros]] and functions specific to a target architecture, for instance to define its [[endianness]], [[word size]], and [[calling convention]]s. The front part of the back end uses these to help decide RTL generation, so although GCC's RTL is nominally processor-independent, the initial sequence of abstract instructions is already adapted to the target. At any moment, the actual RTL instructions forming the program representation have to comply with the [[machine description]] of the target architecture.\n\nThe machine description file contains RTL patterns, along with operand constraints, and code snippets to output the final assembly. The constraints indicate that a particular RTL pattern might only apply (for example) to certain hardware registers, or (for example) allow immediate operand offsets of only a limited size (''e.g.'' 12, 16, 24, … bit offsets, etc.). During RTL generation, the constraints for the given target architecture are checked. In order to issue a given snippet of RTL, it must match one (or more) of the RTL patterns in the machine description file, and satisfy the constraints for that pattern; otherwise, it would be impossible to convert the final RTL into machine code.\n\nTowards the end of compilation, valid RTL is reduced to a ''strict'' form in which each instruction refers to real machine registers and a pattern from the target's machine description file. Forming strict RTL is a complicated task; an important step is [[register allocation]], where real hardware registers are chosen to replace the initially assigned pseudo-registers. This is followed by a \"reloading\" phase; any pseudo-registers that were not assigned a real hardware register are 'spilled' to the stack, and RTL to perform this spilling is generated. Likewise, offsets that are too large to fit into an actual instruction must be broken up and replaced by RTL sequences that will obey the offset constraints.\n\nIn the final phase, the machine code is built by calling a small snippet of code, associated with each pattern, to generate the real instructions from the target's [[instruction set]], using the final registers, offsets, and addresses chosen during the reload phase. The assembly-generation snippet may be just a string, in which case a simple string substitution of the registers, offsets, and/or addresses into the string is performed. The assembly-generation snippet may also be a short block of C code, performing some additional work, but ultimately returning a string containing the valid assembly code.\n\n=== Features ===\nSome features of GCC include:\n\n* [[Link-time optimization]] optimizes across object file boundaries to directly improve the linked binary. Link-time optimization relies on an intermediate file containing the serialization of some ''Gimple'' representation included in the object file.{{Citation needed|date=January 2016}} The file is generated alongside the object file during source compilation. Each source compilation generates a separate object file and link-time helper file. When the object files are linked, the compiler is executed again and uses the helper files to optimize code across the separately compiled object files.\n* [[Plug-in (computing)|Plugins]] can extend the GCC compiler directly.<ref>{{cite web |title= Plugins |url= https://gcc.gnu.org/onlinedocs/gccint/Plugins.html |work= GCC online documentation |accessdate= July 8, 2013 }}</ref> Plugins allow a stock compiler to be tailored to specific needs by external code loaded as plugins. For example, plugins can add, replace, or even remove middle-end passes operating on ''Gimple'' representations.<ref>{{cite web|last=Starynkevitch|first=Basile|title=GCC plugins thru the MELT example|url=http://gcc-melt.org/gcc-plugin-MELT-LinuxCollabSummit2014.pdf|accessdate=2014-04-10}}</ref> Several GCC plugins have already been published, notably the GCC Python plugin, which links against libpython, and allows one to invoke arbitrary Python scripts from inside the compiler. The aim is to allow GCC plugins to be written in Python. The MELT plugin provides a high-level [[Lisp (programming language)|Lisp]]-like language to extend GCC.<ref>{{cite web |title= About GCC MELT |url= http://gcc-melt.org/ |accessdate= July 8, 2013 }}</ref>\n* \"C++ [[Software transactional memory|transactional memory]] when compiling with -fgnu-tm.\"<ref name=\"gcc6\"/><ref>{{cite web |url=https://gcc.gnu.org/wiki/TransactionalMemory |title=Transactional Memory in GCC}}</ref>\n\n== Languages ==\n<!-- Dates of the first release for each language would be a useful add. -->\n\nThe standard compiler releases since 7 include front ends for [[C (programming language)|C]] (<code>gcc</code>), [[C++]] (<code>g++</code>), [[Objective-C]], [[Objective-C++]], [[Fortran]] (<code>[[gfortran]]</code>), [[Ada (programming language)|Ada]] ([[GNAT]]), and [[Go (programming language)|Go]] (<code>gccgo</code>).<ref>{{cite web|url=https://gcc.gnu.org/frontends.html|title=GCC Front Ends|publisher=gnu.org|accessdate=November 25, 2011}}</ref> A popular parallel language extension, [[OpenMP]], is also supported. Version 5.0 added support for [[Cilk Plus]], version 9.1 added support for [[D (programming language)|D]]<ref>{{cite web |url=https://gcc.gnu.org/gcc-9/changes.html#d | title = GCC 9 Release Series }}</ref>, and since version 5.1, there is preliminary support for [[OpenACC]].<ref>{{cite web | url = https://gcc.gnu.org/gcc-5/changes.html | title = GCC 5 Release Series}}</ref> Versions prior to GCC 7 also supported [[Java (programming language)|Java]] (<code>[[GNU Compiler for Java|gcj]]</code>), allowing compilation of Java to native machine code.<ref>{{cite web|url=https://gcc.gnu.org/gcc-7/changes.html|title=GCC 7 Release Series|publisher=gnu.org|accessdate=March 20, 2018}}</ref>\n\nThe Fortran front end was <code>g77</code> before version 4.0, which only supports [[FORTRAN 77]]. In newer versions, <code>g77</code> is dropped in favor of the new [[GNU Fortran]] front end (retaining most of g77's language extensions) that supports [[Fortran 95]] and large parts of [[Fortran 2003]] and [[Fortran 2008]] as well.<ref name=\"gcc_wiki_f2003\">{{cite web| last =| first =| authorlink =| coauthors =| title =Chart of Fortran 2003 Features supported by GNU Fortran| work =| publisher =[[GNU]]| date =| url = https://gcc.gnu.org/wiki/Fortran2003Status|format =| doi =| accessdate =2009-06-25 }}</ref><ref name=\"gcc_wiki_f2008\">{{cite web| last =| first =| authorlink =| coauthors =| title =Chart of Fortran 2008 Features supported by GNU Fortran| work =| publisher =[[GNU]]| date =| url = https://gcc.gnu.org/wiki/Fortran2008Status|format =| doi =| accessdate =2009-06-25 }}</ref> A front-end for [[CHILL]] was dropped due to a lack of maintenance.<ref>{{cite web|url=https://gcc.gnu.org/ml/gcc-patches/2002-04/msg00887.html|title=PATCH&#93; Remove chill|website=gcc.gnu.org|accessdate=July 29, 2010}}</ref>\n\nThird-party front ends exist for [[Pascal (programming language)|Pascal]] (<code>[[GNU Pascal|gpc]]</code>), [[Modula-2]], [[Modula-3]], [[PL/I]] and [[VHDL]] (<code>ghdl</code>).\n\nA few experimental branches exist to support additional languages, such as the GCC [[Unified Parallel C|UPC]] compiler<ref>{{cite web|url=http://www.gccupc.org/|title=GCC UPC (GCC Unified Parallel C)|publisher=Intrepid Technology, Inc.|date=2006-02-20|accessdate=2009-03-11}}</ref> for [[Unified Parallel C]].\n\n== Architectures ==\nGCC target processor families as of version 4.3 include:\n\n{{div col|colwidth=15em|small=no}}\n* [[DEC Alpha|Alpha]]\n* [[ARM architecture|ARM]]\n* [[Atmel AVR|AVR]]\n* [[Blackfin]]\n* [[Adapteva#Products|Epiphany]] (GCC 4.8)\n* [[Hitachi H8|H8/300]]\n* [[HC12]]\n* [[IA-32]] ([[x86]])\n* [[IA-64]] (Intel Itanium)\n* [[MIPS architecture|MIPS]]\n* [[Motorola 68000]]\n* [[PA-RISC]]\n* [[PDP-11]]\n* [[PowerPC]]\n* [[R8C]] / [[M16C]] / [[M32C]]\n* [[SPARC]]\n* [[Synergistic Processing Unit|SPU]]\n* [[SuperH]]\n* [[System/390]] / [[zSeries]]\n* [[VAX]]\n* [[x86-64]]\n{{Refend}}\n\nLesser-known target processors supported in the standard release have included:\n\n{{div col|colwidth=15em|small=no}}\n* [[68HC11]]\n* [[A29K]]\n* [[CR16]]\n* [[C6x]]\n* [[D30V]]\n* [[DSP16xx]]\n* [[ETRAX CRIS]]\n* [[Fujitsu FR|FR-30]]\n* [[FR-V]]\n* [[Intel i960]]\n* [[IP2000]]\n* [[M32R]]\n* [[MCORE]]\n* [[MIL-STD-1750A]]\n* [[MMIX]]\n* [[MN10200]]\n* [[MN10300]]\n* [[Motorola 88000]]\n* [[NS320xx|NS32K]]\n* [[IBM ROMP]]\n* [[RL78]]\n* [[Stormy16]]\n* [[V850]]\n* [[Xtensa]]\n{{Refend}}\n\nAdditional processors have been supported by GCC versions maintained separately from the FSF version:\n\n{{div col|colwidth=15em|small=no}}\n* [[Cortus APS3]]\n* [[ARC (processor)|ARC]]\n* [[AVR32]]\n* [[C166]] and [[C167]]\n* [[D10V]]\n* [[EISC]]\n* [[eSi-RISC]]\n* [[Hexagon (processor)|Hexagon]]<ref>{{cite web|title=Hexagon Project Wiki|url=https://www.codeaurora.org/xwiki/bin/Hexagon/ }}</ref>\n* [[LatticeMico32]]\n* [[LatticeMico8]]\n* [[MeP]]\n* [[MicroBlaze]]\n* [[Motorola 6809]]\n* [[MSP430]]\n* [[NEC SX architecture]]<ref>{{cite web|title=sx-gcc: port gcc to nec sx vector cpu|url=https://code.google.com/p/sx-gcc/ }}</ref>\n* [[Nios II]] and [[Nios embedded processor|Nios]]\n* [[OpenRISC]]\n* [[PDP-10]]\n* [[PIC30#PIC24 and dsPIC 16-bit microcontrollers|PIC24/dsPIC]]\n* [[PIC30#PIC32 32-bit microcontrollers|PIC32]]\n* [[Parallax Propeller|Propeller]]\n* [[RISC-V]]\n* [[HP Saturn|Saturn]] (HP48XGCC)\n* [[System/370]]\n* [[TIGCC]] ([[m68k]] variant)\n* [[TriCore]]\n* [[Z8000]]\n* [[ZPU (microprocessor)|ZPU]]\n{{Refend}}\n\nThe [[GNU Compiler for Java|gcj]] Java compiler can target either a native machine language architecture or the [[Java virtual machine]]'s [[Java bytecode]].<ref>{{cite web | url = https://gcc.gnu.org/java/ | title = The GNU Compiler for the Java Programming Language | accessdate = 2010-04-22 | deadurl = yes | archiveurl = https://web.archive.org/web/20070509055923/http://gcc.gnu.org/java/ | archivedate = May 9, 2007 | df = mdy-all }}</ref> When [[retargetable compiler|retargeting]] GCC to a new platform, [[bootstrapping (compilers)|bootstrapping]] is often used.\n\n== Development ==\nThe current stable version of GCC is 9.1, which was released on May 5, 2019.<ref>https://www.gnu.org/software/gcc/releases.html</ref>\n\nAs of version 4.8, GCC is implemented in C++.<ref>{{cite web|url=https://gcc.gnu.org/gcc-4.8/changes.html |title=GCC 4.8 Release Series: Changes, New Features, and Fixes}}</ref>\n\nGCC 4.6 supports many new{{When?|date=October 2018}} [[Objective-C]] features, such as declared and synthesized properties, dot syntax, fast enumeration, optional protocol methods, method/protocol/class attributes, class extensions and a new GNU Objective-C runtime API. It also supports the [[Go programming language]] and includes the <code>libquadmath</code> library, which provides [[Quadruple precision floating-point format|quadruple-precision]] mathematical functions on targets supporting the <code>__float128</code> datatype. The library is used to provide the <code>REAL(16)</code> type in GNU [[Fortran]] on such targets.\n\nGCC uses many standard tools in its build, including [[Perl]], [[Flex lexical analyser|Flex]], [[GNU bison|Bison]], and other common tools. In addition it currently requires three additional libraries to be present in order to build: [[GNU Multi-Precision Library|GMP]], [[Multiple Precision Complex|MPC]], and [[MPFR]].\n\nThe trunk concentrates the major part of the development efforts, where new features are implemented and tested.\n\n== License ==\n{{Expand section|date=April 2016}}\nThe ''GCC runtime exception'' permits compilation of [[Proprietary software|proprietary]] and [[free software]] programs with GCC and usage of free software plugins.<ref>{{cite web|publisher=FSF|title=GCC Runtime Exception|url=https://www.gnu.org/licenses/gcc-exception|accessdate=2014-04-10}}</ref> The availability of this exception does not imply any general presumption that third-party software is unaffected by the copyleft requirements of the license of GCC.\n\n== Uses ==\n{{Expand section|date=April 2016}}\nSeveral companies make a business out of supplying and supporting GCC ports to various platforms.<ref>{{cite web|url=http://www.fsf.org/resources/service|title=FSF Service Directory }}</ref>\n\n* [[Linux]]\n* [[Wind River Systems]]\n* [[Arm Holdings]]\n\n== See also ==\n{{Portal|Free and open-source software|Computer programming}}\n* [[List of compilers]]\n* [[MinGW]]\n* [[C++ concepts]], an extension of the C++ standard. This extension is supported exclusively by GCC.\n\n== References ==\n{{Reflist|30em}}\n\n== Further reading ==\n* ''[https://gcc.gnu.org/onlinedocs/gcc-4.4.2/gcc/ Using the GNU Compiler Collection (GCC)]'', Free Software Foundation, 2008.\n* ''[https://gcc.gnu.org/onlinedocs/gccint/ GNU Compiler Collection (GCC) Internals]'', Free Software Foundation, 2008.\n* ''[http://www.network-theory.co.uk/gcc/intro/ An Introduction to GCC]'', Network Theory Ltd., 2004 (Revised August 2005). {{ISBN|0-9541617-9-3}}.\n* Arthur Griffith, ''GCC: The Complete Reference''. McGrawHill / Osborne, 2002. {{ISBN|0-07-222405-3}}.\n\n== External links ==\n{{Commons|GCC}}\n{{Wikibooks|GNU C Compiler Internals}}\n\n=== Official ===\n* {{official website}}\n* [https://www.gnu.org/software/gcc/releases.html GCC Release Timeline]\n* [https://www.gnu.org/software/gcc/develop.html GCC Development Plan]\n\n=== Other ===\n* [http://hanoo.org/index.php?article=gcc-optimisations GCC optimisations]\n* [http://www.cse.iitb.ac.in/grc/ Collection of GCC 4.0.2 architecture and internals documents] at I.I.T. Bombay\n* {{cite news |date=March 2, 2006 |title=New GCC Heavy on Optimization |publisher= internetnews.com |last= Kerner |first=Sean Michael |url = http://www.internetnews.com/dev-news/article.php/3588926 |postscript=none}}\n* {{cite news |date=April 22, 2005 |title=Open Source GCC 4.0: Older, Faster |publisher= internetnews.com |last= Kerner |first=Sean Michael |url = http://www.internetnews.com/dev-news/article.php/3499881 |postscript=none}}\n* [https://web.archive.org/web/20090401215553/http://www.redhat.com/magazine/002dec04/features/gcc/ From Source to Binary: The Inner Workings of GCC], by Diego Novillo, ''[[Red Hat#Red Hat Magazine|Red Hat Magazine]]'', December 2004\n* [ftp://gcc.gnu.org/pub/gcc/summit/2003/GENERIC%20and%20GIMPLE.pdf A 2003 paper on GENERIC and GIMPLE]\n* [http://www.toad.com/gnu/cygnus/index.html Marketing Cygnus Support], an essay covering GCC development for the 1990s, with 30 monthly reports for in the \"Inside Cygnus Engineering\" section near the end\n* [http://oldhome.schmorp.de/egcs.html EGCS 1.0 announcement]\n* [https://gcc.gnu.org/egcs-1.0/features.html EGCS 1.0 features list]\n* [http://linuxmafia.com/faq/Licensing_and_Law/forking.html Fear of Forking], an essay by Rick Moen recording seven well-known forks, including the GCC/EGCS one\n\n{{GNU}}\n{{FOSS}}\n\n[[Category:1987 software]]\n[[Category:C compilers]]\n[[Category:C++ compilers]]\n[[Category:Compilers]]\n[[Category:Cross-platform free software]]\n[[Category:Fortran compilers]]\n[[Category:Free compilers and interpreters]]\n[[Category:GNU Project software|Compiler Collection]]\n[[Category:Java development tools]]\n[[Category:Pascal compilers]]\n[[Category:Software that was rewritten in C++]]\n[[Category:Free software programmed in C++]]\n[[Category:Software using the GPL license]]\n[[Category:Unix programming tools]]"
    },
    {
      "title": "GNU Fortran",
      "url": "https://en.wikipedia.org/wiki/GNU_Fortran",
      "text": "{{Infobox software\n| name                   = \n| title                  = GNU Fortran\n| logo                   = GNU Compiler Collection logo.svg\n| logo size              = 100px\n| logo caption           = \n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = \n| developer              = [[GNU Project]]\n| released               = {{start date and age|2005|04|20}}<ref name=\"release-history\">{{cite web\n | url = https://www.gnu.org/software/gcc/releases.html\n | title = GCC Releases – GNU Project – Free Software Foundation (FSF)\n | accessdate = 2019-02-23\n | publisher = GNU Project\n}}</ref>\n| discontinued           = \n| latest release version = 8.3<!-- sync this with [[GNU Compiler Collection]] --><ref name=\"release-history\"/>\n| latest release date    = {{Start date and age|2019|02|22|df=yes}}<!-- sync this with [[GNU Compiler Collection]]  -->\n| programming language   = [[C (programming language)|C]], [[C++]]\n| operating system       = [[Cross-platform]]\n| platform               = [[GNU]]\n| size                   = \n| language               = \n| genre                  = [[Compiler]]\n| license                = [[GNU General Public License]] (version 3 or later)\n| alexa                  = \n| website                = {{Official URL}}\n}}\n'''GNU Fortran''' or '''GFortran''' is the name of the [[GNU]] [[Fortran]] [[compiler]], which is part of the [[GNU Compiler Collection]] (GCC).\nIt includes full support for the [[Fortran#Fortran 95|Fortran 95]] language, and supports large parts of the [[Fortran#Fortran 2003|Fortran 2003]] and [[Fortran#Fortran 2008|Fortran 2008]] standards.<ref name=\"gcc_wiki_f2003\">{{cite web| last =| first =| authorlink =| coauthors =| title =Chart of Fortran 2003 Features supported by GNU Fortran| work =| publisher =[[GNU]]| date =| url = https://gcc.gnu.org/wiki/Fortran2003Status|format =| doi =| accessdate =2009-06-25 }}</ref><ref name=\"gcc_wiki_f2008\">{{cite web| last =| first =| authorlink =| coauthors =| title =Chart of Fortran 2008 Features supported by GNU Fortran| work =| publisher =[[GNU]]| date =| url = https://gcc.gnu.org/wiki/Fortran2008Status|format =| doi =| accessdate =2009-06-25 }}</ref> It supports the [[OpenMP]]<ref>https://jblevins.org/log/openmp</ref> multi-platform shared memory multiprocessing, up to its latest version (4.5).<ref>https://gcc.gnu.org/onlinedocs/gfortran/OpenMP.html#OpenMP</ref> GFortran is also compatible with most language extensions and compilation options supported by g77,<ref name=\"gcc_ml_2007-01\">{{cite web| last =| first =| authorlink =| coauthors =| title =Discussion of incompatibilities between g77 and gfortran| work =| publisher =[[GNU]]| date =| url = https://gcc.gnu.org/ml/fortran/2007-01/msg00619.html| doi =| accessdate =2007-01-26 }}</ref> and many other popular extensions of the Fortran language.<ref>https://gcc.gnu.org/onlinedocs/gfortran/Extensions-implemented-in-GNU-Fortran.html#Extensions-implemented-in-GNU-Fortran</ref>\n\nSince GCC version 4.0.0, released in April 2005,<ref>https://gcc.gnu.org/gcc-4.0/</ref> GFortran has replaced the older g77 compiler. The new Fortran front-end for GCC was rewritten from scratch,<ref>https://gcc.gnu.org/onlinedocs/gcc-4.1.2/gfortran/GFORTRAN-and-G77.html</ref> after the principal author and maintainer of g77, Craig Burley, decided in 2001 to stop working on the g77 front end.<ref>http://www.kilmnj.com/g77/why.html</ref> GFortran [[fork (software development)|forked]] off from [[g95]] in January 2003, which itself started in early 2000. The two codebases have \"significantly diverged\" according to GCC developers.<ref name=\"...\">{{cite web| last =| first =| authorlink =| coauthors =| title =The other GCC-based Fortran compiler| work =| publisher =[[GNU]]| date =| url = https://gcc.gnu.org/wiki/TheOtherGCCBasedFortranCompiler|format =| doi =| accessdate =2007-04-11 }}</ref> Since 2010 the front-end, like the rest of the GCC project, was migrated to C++, while it was previously written in C.<ref>http://www.h-online.com/open/news/item/GCC-allows-C-to-some-degree-1012611.html</ref>\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[GNU Compiler Collection]]\n\n==References==\n{{reflist}}\n\n==External links==\n* {{Official website}}\n* [https://gcc.gnu.org/wiki/GFortran GFortran on the GCC Wiki]\n* [http://sites.google.com/site/gfortransite/ OpenMP in gfortran information web page]\n\n[[Category:Fortran compilers]]\n[[Category:Free compilers and interpreters]]\n[[Category:GNU Project software|Fortran]]\n\n\n{{programming-software-stub}}"
    },
    {
      "title": "IBM XL Fortran",
      "url": "https://en.wikipedia.org/wiki/IBM_XL_Fortran",
      "text": "XL Fortran is the name of IBM's proprietary optimizing Fortran compiler for IBM-supported environments, including Linux for [[little-endian]] distributions and AIX.\n\n==Features==\n* Tuning for [[Power ISA]]\n* Fortran language standard support ([https://ibm.biz/Fortran2008Status XL Fortran's Fortran 2008 Compliance Status] and [https://ibm.biz/FortranTS29113Status  XL Fortran's TS 29113 Compliance Status])\n* [[CUDA]] Fortran support <ref> {{cite web|title=Reference and limitations for CUDA Fortran support|url=https://www.ibm.com/support/knowledgecenter/SSAT4T_15.1.5/com.ibm.xlf1515.lelinux.doc/getstart_cudaf/limitations.html|website=IBM Knowledge Center|publisher=IBM|accessdate=26 May 2017}}</ref>\n* [[OpenMP]] API support <ref> {{cite web|title=Parallel programming with XL Fortran|url=https://www.ibm.com/support/knowledgecenter/SSAT4T_15.1.5/com.ibm.xlf1515.lelinux.doc/proguide/ompsmp.html|website=IBM Knowledge Center|publisher=IBM|accessdate=26 May 2017}}</ref>\n* Five optimization levels (-O0,-O2,-O3,-O4,-O5) <ref>{{cite web|title=-O|url=https://www.ibm.com/support/knowledgecenter/SSAT4T_15.1.5/com.ibm.xlf1515.lelinux.doc/compiler_ref/opt_optimize.html|website=IBM Knowledge Center|publisher=IBM|accessdate=26 May 2017}}</ref>\n* [[Profile-directed feedback]] optimization\n* [[Interprocedural optimization]] and inlining\n* High order transformations <ref> {{cite web|title=High-order transformation (HOT)|url=https://www.ibm.com/support/knowledgecenter/SSAT4T_15.1.5/com.ibm.xlf1515.lelinux.doc/proguide/optimizehot.html|website=IBM Knowledge Center|publisher=IBM|accessdate=26 May 2017}}</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n* [http://www-03.ibm.com/software/products/en/fortcompfami IBM Fortran Compilers family introduction]\n* [https://www.ibm.com/support/knowledgecenter/SSAT4T_15.1.5/ Product documentation: XL Fortran for Linux, V15.1.5]\n* [https://www.ibm.com/support/knowledgecenter/SSGH4D_15.1.3/ Product documentation: XL Fortran for AIX, V15.1.3]\n* [https://www.ibm.com/developerworks/community/groups/service/html/communitystart?communityUuid=572f1638-121d-4788-8bbb-c4529577ba7d Community: IBM XL C, C++, and Fortran Compilers for Power servers]\n{{DEFAULTSORT:IBM XL Fortran Compilers}}\n[[Category:fortran compilers]]\n[[Category:IBM software]]"
    },
    {
      "title": "Intel Fortran Compiler",
      "url": "https://en.wikipedia.org/wiki/Intel_Fortran_Compiler",
      "text": "{{Infobox software\n| name                   = Intel Fortran Compiler\n| developer              = [[Intel]]\n| latest_release_version = 19.0 (XE 2019)\n| latest_release_date    = {{Start date and age|2018}}<ref>{{cite web |title= Intel Fortran Compiler 19.0 Release Notes|url=https://software.intel.com/en-us/articles/intel-fortran-compiler-190-for-linux-release-notes-for-intel-parallel-studio-xe-2019}}</ref>\n| operating_system       = [[Linux]], [[Microsoft Windows|Windows]], [[OS X]]\n| genre                  = [[Compiler]]\n| license                = Proprietary, Freeware<ref name=\"freelib\">{{cite web|title=No Cost Options for Intel Parallel Studio XE, Support yourself, Royalty-Free|url=https://software.intel.com/en-us/free_tools_and_libraries}}</ref>\n| website                = {{URL|software.intel.com/en-us/intel-compilers}}\n}}\n'''Intel Fortran Compiler''', also known as '''IFORT''', is a group of [[Fortran]] [[compilers]] from [[Intel]] for [[Microsoft Windows|Windows]], [[OS X]], and [[Linux]]. \n\n==Overview==\nThe compilers generate code for [[IA-32]] and [[Intel 64]] processors and certain non-Intel but compatible processors, such as certain [[AMD]] processors. A specific release of the compiler (11.1) remains available for development of Linux-based applications for IA-64 ([[Itanium|Itanium 2]]) processors. On Windows, it is known as Intel Visual Fortran.<ref>{{cite web\n|url=https://www.cnet.com/products/intel-visual-fortran-compiler-professional-edition-for-windows-v-11-0-complete-package-series/specs\n|title=Intel Visual Fortran Compiler Professional Edition for Windows\n|website=cnet.com}}</ref> On OS X and Linux, it is known as Intel Fortran.\n\nThe latest release of the compiler continues to support the [[Intel MIC|Intel Xeon Phi coprocessor]] and Intel Architecture instruction-set capabilities by means of [[automatic vectorization]], which can enable applications to use [[Streaming SIMD Extensions|SSE]], [[SSE2]], [[SSE3]], [[SSSE3]], [[SSE4]] and [[Advanced Vector Extensions|AVX]] [[SIMD]] instructions. Use of such instructions through the compiler can lead to improved application performance in some applications as run on IA-32 and Intel 64 architectures, compared to applications built with compilers that do not support these instructions.\n\nIntel Fortran also continues support for [[OpenMP]] 4.0,<ref>{{cite book |url=https://arxiv.org/abs/1709.04423\n|title=OpenMP GNU and Intel Fortran |author=P. Muruganandam |date=2017}}</ref> [[automatic parallelization]] for [[symmetric multiprocessing]], almost all of the Fortran 2003 standard and much of the Fortran 2008 standard<ref>{{cite web\n|url=https://marketplace.visualstudio.com/items?itemName=ChuckPiper.vs-extension-17264\n|date=2016 |quote=... ... significant Fortran 2008 feature support, including ...\n|title=Intel Fortran}}</ref> including [[Coarray Fortran]], user-defined I/O, BLOCK and submodules. For more information on Fortran standards, a number or resources are available, such as the Wikipedia [[Fortran]] entry or the [http://fortranwiki.org/fortran/show/Standards Fortran] wiki page. When used with Intel cluster tools (see the \"Description of Packaging\" below) the compiler can also automatically generate [[Message Passing Interface]] calls for [[distributed memory multiprocessing]] from OpenMP directives.\n\n==Optimizations==\nIntel compilers are optimized<ref>{{cite web \n|url=http://www.nersc.gov/users/software/compilers/intel-fortran-c-and-c\n|title=Intel (Fortran, C, and C++)  |website=NERSC.gov}}</ref> to computer systems using processors that support Intel architectures. They are designed to minimize stalls and to produce code that executes in the fewest possible number of cycles. Intel Fortran Compilers support three separate high-level techniques for optimizing the compiled program: [[interprocedural optimization]] (IPO), [[profile-guided optimization]] (PGO), and other [[Program optimization|high-level optimizations]] (HLO). They also support a directives-based approach to application offloading to Intel coprocessors, such as the [[Intel MIC|Intel Xeon Phi]] coprocessor.\n\nInterprocedural optimization applies typical compiler optimizations (such as constant propagation) but uses a broader scope that may include multiple procedures, multiple files, or the entire program.<ref>Intel compiler documentation. Select the Fortran compiler of choice and search for Profile-Guided Optimization. ''http://software.intel.com/en-us/intel-software-technical-documentation''</ref>\n\nRegarding [[profile-guided optimization]], the compiler generates a dataset of performance-related information from using the application with representative workloads, which it then analyzes to find which parts of the application are executed more and less frequently. The compiler uses these data to organize application execution to optimize performance based on how the application is actually used.  This is in contrast to IPO which optimizes applications according to the logical flow of the application independent of workloads.  The two can be combined to provide workload-based optimizations within which the logical-flow is optimized.  Thus, all optimizations can benefit from profile-guided feedback because they are less reliant on heuristics when making compilation decisions.\n\nHigh-level optimizations are optimizations performed on a version of the program that more closely represents the source code. This includes [[loop interchange]], [[loop fusion]], [[loop unrolling]], [[loop distribution]], data prefetch, and more.<ref>The Software Optimization Cookbook, High-Performance Recipes for IA-32 Platforms, Richard Gerber, Aart J.C. Bik, Kevin B. Smith, and Xinmin Tian, Intel Press, 2006</ref>\n\n==Standards support==\nThe Intel Fortran compiler supports all of the features of the Fortran 90, Fortran 95, Fortran 2003 standards and most of Fortran 2008. It also supports some draft Fortran 2018 features.  Additionally, it supports various extensions found in VAX Fortran and Compaq Visual Fortran.\n\nA partial list of items from the Fortran 2003 standard supported by Intel Fortran:\n\n* Parameterized derived tpes\n* User-defined derived type I/O\n* Enumerators\n* Type extension and type-bound procedures\n* FINAL routines and GENERIC, OPERATOR, and ASSIGNMENT overloading in type-bound procedures\n* Polymorphic data and the CLASS declaration\n* Allocatable scalar variables (not deferred-length character)\n* SOURCE= keyword for ALLOCATE\n* Intrinsic modules IEEE_EXCEPTIONS, IEEE_ARITHMETIC and IEEE_FEATURES\n* ASSOCIATE construct\n* DO CONCURRENT construct\n* PROCEDURE declaration and procedure pointers\n* CONTIGUOUS attribute\n* Structure constructors with component names and default initialization\n* Array constructors with type and character length specifications\n* I/O keywords BLANK, DECIMAL, DELIM, ENCODING, IOMSG, PAD, ROUND, SIGN, and SIZE\n* PUBLIC types with PRIVATE components and PRIVATE types with PUBLIC components\n* A file can be opened for stream access (ACCESS='STREAM')\n* BIND attribute and ISO_C_BINDING intrinsic module\n* ASYNCHRONOUS attribute\n* VALUE attribute\n* FLUSH statement\n* WAIT statement\n* IMPORT statement\n* Allocatable components of derived types, allocatable dummy arguments, and allocatable function results\n* [[Volatile (computer programming)#In Fortran|VOLATILE attribute]]<ref>{{cite web\n  |url=https://docs.oracle.com/cd/E19957-01/805-4939/6j4m0vnbq/index.html\n  |title=VOLATILE  |website=Oracle.com}}</ref>\n* Names of length up to 63 characters\n* Statements up to 256 lines\n\nA partial list of items from the Fortran 2008 standard supported by Intel Fortran:\n\n* Coarrays\n* Submodules\n* The BLOCK construct to allow dynamic scoping\n* CRITICAL construct\n* The Fortran 2008 standard specifies a maximum rank of 15; the maximum array rank has been raised to 31 dimensions in Intel Fortran\n* A generic interface may have the same name as a derived type\n* Bounds specification and bounds remapping list on a pointer assignment\n* NEWUNIT= specifier in OPEN\n* A CONTAINS section can be empty\n* Coarrays can be specified in ALLOCATABLE, ALLOCATE, and TARGET statements\n* MOLD keyword in ALLOCATE\n* DO CONCURRENT statement\n* ERROR STOP statement\n\n[http://j3-fortran.org/doc/year/16/16-007.pdf Fortran 2018], currently a draft version, includes further interoperability between Fortran and C. Intel Fortran supports draft Fortran 2018 as of version 16.0.\n\n==Architectures==\n* [[IA-32]]\n* [[x86-64]] ([[Intel 64]] and [[AMD64]])\n* [[Intel MIC|Intel Xeon Phi coprocessor]]\n* IA-64 ([[Itanium]] 2)\n\n==Description of packaging==\nThe Intel Fortran compiler is available as part of the [[Intel Parallel Studio]] XE 2016 suite, which focuses on development of parallelism models in application software.  It also includes Intel C++, Intel Math Kernel Library, Intel Integrated Performance Primitives, Intel Data Analytics Acceleration Library and performance analysis tools such as Intel VTune Amplifier and Intel Inspector. There are three forms of Parallel Studio XE: Composer, Professional, and Cluster.  The Composer Edition includes the C++ and/or Fortran compilers, the performance libraries, and parallel models support. The Professional Edition adds the analysis tools that assist in debugging and tuning parallel applications. The Cluster Edition adds support for development of software for [[computer cluster | computer clusters]].  It includes all of the above plus a standards-based [[Message Passing Interface | MPI]] Library, MPI communications profiling and analysis tool, MPI error checking and tuning tools, and [[Intel Cluster Ready | cluster checker]].\n\n==History since 2003==\n{| class=\"wikitable\"\n! Compiler version\n! Release date\n! Major new features\n|-\n| Intel Fortran Compiler 8.0 || December 15, 2003 || Precompiled headers, code-coverage tools.\n|-\n| Intel Fortran Compiler 8.1 || September, 2004 || [[AMD64]] architecture (for Linux).\n|-\n| Intel Fortran Compiler 9.0 || June 14, 2005 || [[AMD64]] architecture (for Windows), software-based speculative pre-computation (SSP) optimization, improved loop optimization reports.\n|-\n| Intel Fortran Compiler 10.0 || June 5, 2007 || Improved parallelizer and vectorizer, Streaming SIMD Extensions 4 ([[SSE4]]), new and enhanced optimization reports for advanced loop transformations, new optimized exception handling implementation.\n|-\n| Intel Fortran Compiler 10.1 || November 7, 2007|| New OpenMP* compatibility runtime library. To use the new libraries, you need to use the new option \"-Qopenmp /Qopenmp-lib:compat\" on Windows, and \"-openmp -openmp-lib:compat\" on Linux. This version of the Intel compiler supports more intrinsics from [[Microsoft Visual Studio]] 2005. VS2008 support - command line only in this release.\n|-\n| Intel Fortran Compiler 11.0 || November 2008|| More Fortran 2003 support. Support for OpenMP 3.0. Source Checker for static memory/parallel diagnostics. Commercial licenses for Windows version include [[Microsoft Visual Studio]] 2005 Premier Partner Edition.\n|-\n| Intel Fortran Compiler 11.1 || June 23, 2009|| Support for latest Intel SSE, AVX and AES instructions. More Fortran 2003 support. Support for latest Intel MKL release (included in compiler products). Commercial licenses for Windows version include [[Microsoft Visual Studio]] 2008 Shell and libraries.\n|-\n| Intel Fortran Composer XE 2011 up to Update 5 (compiler 12.0) || November 7, 2010|| Coarray Fortran, additional 2003 (FINAL subroutines, GENERIC keyword,) and 2008 (Coarrays, CODIMENSION, SYNC ALL, SYNC IMAGES, SYNC MEMORY, CRITICAL, LOCK, ERROR STOP, ALLOCATE/DEALLOCATE)\n|-\n| Intel Fortran Composer XE 2011 Update 6 and above (compiler 12.1) || September 8, 2011|| OpenMP 3.1, additional 2003 (ALLOCATE with SOURCE=, polymorphic source) and 2008 standards support, Windows version ships with Visual Studio 2010 Shell.\n|-\n| Intel Fortran Composer XE 2013 (compiler 13.0) || September 5, 2012 || Linux-based support for Intel Xeon Phi coprocessors, support for Microsoft Visual Studio 12 (Desktop), support for gcc 4.7, support for Intel AVX 2 instructions, updates to existing functionality focused on delivering improved application performance. Continued availability of the Visual Studio 2010 Shell for Windows versions.\n|-\n| Intel Fortran Composer XE 2013 SP1 (compiler 14.0) || July 31, 2013 || User-Defined Derived Type I/O; OpenMP directives, clauses and procedures; coarrays ; Microsoft Visual Studio parallel build support\n|-\n| Intel Fortran Composer XE 2013 SP1 Update 1 (compiler 14.0.1) || October 18, 2013 || Japanese localization of 14.0; Windows 8.1 and Xcode 5.0 support\n|-\n| Intel Fortran Composer XE 2015 (compiler 15.0) || August 5, 2014 || Full support for Fortran 2003; BLOCK from Fortran 2008; EXECUTE_COMMAND_LINE from Fortran 2008; New optimization report annotates the source from within Visual Studio<ref>{{cite web |title=Intel Visual Fortran 15 now available |url=https://software.intel.com/en-us/forums/topic/529178}}</ref>\n|-\n| Intel Fortran Composer XE 2015 Update 1 (compiler 15.0.1) || October 30, 2014 || [[AVX-512]] support; Japanese localization; MIN/MAX Reductions in SIMD Loop Directive\n|-\n| Intel Fortran Compiler 16.0, part of Intel Parallel Studio XE 2016 || August 25, 2015 || Submodules from Fortran 2008, enhanced interoperability of Fortran with C from draft Fortran 2018, OpenMP 4.1 extensions\n|-\n| Intel Fortran Compiler 17.0 || March 4, 2016 ||  OpenMP 4.5 extensions\n|-\n| Intel Fortran Compiler 18.0 || January 17, 2017 ||  Full Fortran 2008 support\n|-\n| Intel Fortran Compiler 19.0 || September 12, 2018 ||  Some Fortran 2018 features\n|-\n|}\n\n==Debugging==\nThe Intel compiler provides debugging information that is standard for the common debuggers ([[DWARF|DWARF 2]] on Linux, similar to [[gdb]], and [[COFF]] for Windows). The flags to compile with debugging information are <tt>/Zi</tt> on Windows and <tt>-g</tt> on Linux. Debugging is done on Windows using the Visual Studio debugger, and on Linux using gdb.\n\nWhile the Intel compiler can generate a gprof-compatible [[profiler (computer science)|profiling]] output, Intel also provides a kernel-level, system-wide statistical profiler as a separate product called [[VTune]]. VTune features an easy-to-use GUI (integrated into [[Visual Studio]] for Windows, [[Eclipse (software)|Eclipse]] for Linux) as well as a command-line interface.  In addition to the VTune profiler, there is [[Intel Advisor]] that specializes in vectorization optimization and tools for threading design and prototyping.\n\nIntel also offers a tool for memory and threading error detection called Intel Inspector XE. Regarding memory errors, it helps detect [[memory leak]]s, memory corruption, allocation/de-allocation of API mismatches and inconsistent memory API usage. Regarding threading errors, it helps detect data races (both heap and stack), deadlocks and thread and synch API errors.\n\n==See also==\n* [[Intel Parallel Studio XE]]\n* Intel [[Integrated Performance Primitives]] (IPP)\n* Intel [[Data Analytics Acceleration Library]] (DAAL)\n* Intel [[Math Kernel Library]] (MKL)\n* Intel [[Threading Building Blocks]] (TBB)\n* [[VTune]] Amplifier\n* [[Intel C++ Compiler]]\n* [[Intel Developer Zone]] (Intel DZ; support and discussion)\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{Official website}}\n\n{{Intel software}}\n\n[[Category:Fortran compilers]]\n[[Category:Intel software|Fortran compiler]]"
    },
    {
      "title": "MinGW",
      "url": "https://en.wikipedia.org/wiki/MinGW",
      "text": "{{primary sources|date=May 2012}}\n{{Infobox software\n| author                 = Colin Peters\n| developer              = MinGW Project\n| released               = {{Start date and age|1998|07|01}}\n| latest release version = GNU BinUtils—2.32-1, Installation Manager—0.6.3, WSL—5.2.1 <ref name=\"paklist\">{{cite web | url=https://osdn.net/projects/mingw/releases/ | title=Download Package list | website=osdn.net}}</ref>\n| latest release date    = {{Start date and age|2019|02|11}}\n| latest preview version = \n| latest preview date    = \n| status                 = Active<ref>Visit the [https://osdn.net/projects/mingw/releases/ list of releases] and notice their dates.</ref>\n| programming language   = [[C (programming language)|C]], [[C++]]\n| operating system       = [[Microsoft Windows]], [[Unix-like]] (as a [[cross compiler]])\n| genre                  = [[Compiler]]\n| license                = [[Public domain]] (headers), [[GNU General Public License]] (compiler and toolchain)\n| website                = {{URL|mingw.org}}\n}}\n\n'''MinGW''' (''Minimalist GNU for Windows''), formerly '''mingw32''', is a [[Free and open-source software|free and open source]] [[software development]] environment to create [[Microsoft Windows]] applications. The development of the MinGW project has slowed down since the creation in 2013 of an alternative project called [[#MinGW-w64|MinGW-w64]] by a different author.\n\nMinGW includes a [[porting|port]] of the [[GNU Compiler Collection]] (GCC), [[GNU Binutils]] for Windows ([[assembler (computing)|assembler]], [[linker (computing)|linker]], [[Archive file|archive manager]]), a set of freely distributable Windows specific [[header file]]s and [[Static library|static import libraries]] which enable the use of the [[Windows API]], a Windows native build of the [[GNU Project]]'s [[GNU Debugger]], and miscellaneous utilities.\n\nMinGW does not rely on [[Third-party software component|third-party]] [[C (programming language)|C]] [[Runtime library|runtime]] [[dynamic-link library]] (DLL) files, and because the runtime libraries are not distributed using the [[GNU General Public License]] (GPL), it is not necessary to distribute the [[source code]] with the programs produced, unless a GPL library is used elsewhere in the program.<ref>{{cite web\n| url= http://mingw.org/wiki/MinGW\n| website=MinGW.org/wiki\n| title=(MinGW on) MinGW\n| date=2008-07-07\n| accessdate=2013-10-16\n}}</ref>\n\nMinGW can be run either on the native Microsoft Windows platform, cross-hosted on [[Linux]] (or other Unix), or \"cross-native\" on [[Cygwin]]. Although programs produced under MinGW are 32 bits executables, they can be used both in 32 and 64 bits versions of Windows.\n\n==History==\nMinGW was originally called mingw32 (''Minimalist GNU for W32''), following the GNU convention whereby Windows is shortened as \"W32\".<ref>{{cite web\n| url=https://www.gnu.org/prep/standards/html_node/System-Portability.html#System-Portability\n| title=GNU Coding Standards\n| date=April 27, 2013\n| website=gnu.org\n| publisher=Free Software Foundation\n| at=5.5 Portability between System Types\n| accessdate=July 1, 2013\n}}</ref><ref>{{cite mailing list\n| url=https://lists.gnu.org/archive/html/libtool/2000-09/msg00000.html\n| title=Libtool Re: Naming a project gnu-win32?\n| date=2000-09-18\n| accessdate=2013-05-21\n| mailinglist=libtool\n| last=Stallman | first=Richard |authorlink=Richard Stallman\n}}</ref> The numbers were dropped in order to avoid the implication that it would be limited to producing [[32-bit application|32-bit binaries]]. Colin Peters authored the initial release in 1998, consisting only of a Cygwin port of GCC.<ref name=\"history\">{{cite web\n| url=http://mingw.org/history\n| title=(MinGW's) History\n| publisher=MinGW.org\n| date=\n| accessdate=2012-07-09\n}}</ref><ref name=\"potm\"/> Jan-Jaap van der Heijden created a Windows-native port of GCC and added [[binutils]] and [[make (software)|make]].<ref name=\"history\"/><ref name=\"potm\"/> Mumit Khan later took over development, adding more Windows-specific features to the package, including the Windows system headers by Anders Norlander.<ref name=\"history\"/><ref name=\"potm\"/> In 2000, the project was moved to [[SourceForge]] in order to solicit more assistance from the community and centralize its development.<ref name=\"history\"/><ref name=\"potm\"/>\n\nMinGW was selected as Project of the Month at SourceForge for September 2005.<ref name=\"potm\">{{cite web\n| url=https://sourceforge.net/blog/potm-2005-09/\n| title=(sourceforge's) Project of the Month\n| publisher=SourceForge.net\n| date=2005-08-31\n| accessdate=2012-07-09\n}}</ref>\n\nIn the last quarter of 2013 a new project was started,<ref>{{cite web\n| url=https://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other\n| title=How are msys, msys2, and msysgit related to each other?\n| website = stackoverflow.com\n| accessdate=2015-04-01\n}}</ref> MSYS2 together with 32-bit and 64-bit MinGW packages. This project was created to keep track with newer advances of the Cygwin project and the fact that the original MSYS was not able to keep up with Cygwin. MSYS2 is an independent rewrite of MSYS, based on modern Cygwin (POSIX compatibility layer) and MinGW-w64 with the aim of better interoperability with native Windows software. It uses [[Arch Linux|Arch Linux's]] Pacman as the package manager.\n\nIn 2018, following a disagreement with SourceForge about the administration of its mailing lists, MinGW migrated to [[OSDN]].<ref>{{cite web | url=https://sourceforge.net/p/mingw/mailman/message/36198954/ | title=Announcement of migration to OSDN.net | website=sourceforge.net}}</ref>\n\n==Programming language support==\nMost languages supported by GCC are supported on the MinGW port as well. These include C, [[C++]], [[Objective-C]], Objective-C++, [[Fortran]], and [[Ada (programming language)|Ada]]. The GCC runtime libraries are used (libstdc++ for C++, libgfortran for Fortran, etc.).\n\nMinGW links by default to the Windows OS component library [[Microsoft Windows library files#MSVCRT.DLL and MSVCPP.DLL|MSVCRT]], which is the C library that [[Visual C++|Visual&nbsp;C]] version 6.0 linked to (the initial target was CRTDLL), which was released in 1998 and therefore does not include support for [[C99]] features, or even all of [[ANSI C|C89]]. While targeting MSVCRT yields programs that require no additional runtime redistributables to be installed, the lack of support for C99 has caused porting problems, particularly where [[printf]]-style conversion specifiers are concerned. These issues have been partially mitigated by the implementation of a C99 compatibility library, ''libmingwex'', but the extensive work required is far from complete and may never be fully realized.<ref>{{cite web\n| url=http://mingw.org/wiki/C99\n| title=(MinGW And) C99\n| website = MinGW.org/wiki\n| date=2010-06-21\n}}</ref> [[#MinGW-w64|MinGW-w64]] has resolved these issues, and provides fully POSIX compliant printf functionality.\n\n==Components==\nThe MinGW project maintains and distributes a number of different core components and supplementary packages, including various ports of the [[GNU toolchain]], such as [[GNU Compiler Collection|GCC]] and [[binutils]], translated into equivalent packages.<ref name=\"FAQ-What\">{{cite web\n| url=http://mingw.org/mingwfaq.shtml#faq-what\n| title=(MinGW) FAQ\n| publisher=MinGW.org\n| date=\n| accessdate=2012-07-09\n}}</ref><ref name=\"MinGWComponents\">{{cite web\n| url=http://sourceforge.net/project/showfiles.php?group_id=2435\n| title=MinGW - Minimalist GNU for Windows\n| publisher=Sourceforge.net\n| date=\n| accessdate=2012-07-09\n}}</ref> These utilities can be used from the [[Windows command line]] or integrated into an [[integrated development environment|IDE]]. Packages may be installed using the command line via mingw-get.<ref>{{cite web\n| title=MinGW Command Line Interface Installer\n| url=http://www.mingw.org/wiki/Getting_Started#toc2\n| accessdate=14 June 2012\n}}</ref>\n\nMinGW supports dynamic libraries named according to the <code><nowiki><name>.lib</nowiki></code> and <code><nowiki><name>.dll</nowiki></code> conventions, as well as static libraries following the <code><nowiki>lib<name>.a</nowiki></code> naming convention common on Unix and Unix-like systems.\n\nIn addition, a component of MinGW known as ''MSYS'' (''minimal system'') provides Windows ports of a lightweight Unix-like [[shell (computer science)|shell]] environment including [[rxvt]] and a selection of [[POSIX]] tools sufficient to enable [[autoconf]] scripts to run,<ref>{{cite web\n| url = http://www.mingw.org/wiki/MSYS\n| title=(wiki:) MSYS\n| publisher=MinGW.org\n| date=\n| accessdate = 2016-02-18\n}}</ref> but it does not provide a C compiler or a [[Case_sensitivity#In_filesystems|case-sensitive file system]].<ref>{{cite web\n| accessdate = 2016-02-18\n| publisher = MinGW.org\n| title = (wiki:) MSYS\n| quote = A common misunderstanding is MSYS is \"UNIX on Windows\", MSYS by itself does not contain a compiler or a C library, [...] nor does it provide any UNIX specific functionality like case-sensitive filenames.\n| url = http://www.mingw.org/wiki/MSYS\n}}</ref>\n\n''mingwPORTs'' are user contributed additions to the MinGW software collection. Rather than providing these \"add-ons\" as precompiled binary packages, they are supplied in the form of interactive [[Bourne shell]] scripts, which guide the end user through the process of automatically downloading and patching original source code, then building and installing it. Users who wish to build any application from a mingwPORT must first install both MinGW and MSYS.<ref>{{cite web\n| url=http://www.mingw.org/wiki/mingwPORT\n| title=(wiki:) mingwPORT\n| publisher=MinGW.org\n| date=\n| accessdate=2012-07-09\n}}</ref>\n\nThe implementation of Windows system headers and static import libraries are released under a [[permissive license]],<ref name=\"w32api\">{{cite web\n| url=http://www.mingw.org/license\n| title=(MinGW) Licensing Terms\n| publisher=MinGW.org\n| date=\n| accessdate=2012-07-09\n}}</ref> while the GNU ports are provided under the [[GNU General Public License]]. Binary downloads of both the complete MSYS package and individual MinGW GNU utilities are available from the MinGW site.\n\n==Comparison with Cygwin==\nAlthough both Cygwin and MinGW can be used to port Unix software to Windows, they have different approaches:<ref name=\"differencesCygwinMinGW\">{{cite web\n| url=http://www.mingw.org/node/21\n| title=(MinGW:) About Cygwin\n| publisher=MinGW.org\n| date=\n| accessdate=2012-07-09\n}}</ref> Cygwin aims to provide a complete [[POSIX]] layer comprising a full implementation of all major Unix system calls and libraries. Compatibility is considered higher priority than performance. On the other hand, MinGW's priorities are simplicity and performance. As such, it does not provide certain [[POSIX]] APIs which cannot easily be implemented using the Windows API, such as <code>[[Fork (operating system)|fork()]]</code>, <code>[[mmap|mmap()]]</code> and <code>[[ioctl|ioctl()]]</code>.<ref name=\"differencesCygwinMinGW\" /> Applications written using a [[cross-platform]] library that has itself been ported to MinGW, such as [[Simple DirectMedia Layer|SDL]], [[wxWidgets]], [[Qt (toolkit)|Qt]], or [[GTK+]], will usually compile as easily in MinGW as they would in Cygwin.\n\nWindows programs written with Cygwin run on top of a [[copyleft]]ed compatibility [[Microsoft Dynamic Link Library|DLL]] that must be distributed with the program, along with the program's source code. MinGW does not require a [[compatibility layer]], since MinGW-based programs are compiled with direct calls to Windows APIs.\n\nThe combination of MinGW and MSYS provides a small, self-contained environment that can be loaded onto removable media without leaving entries in the [[Windows Registry|registry]] or files on the computer.\n\nIt is also possible to [[cross compiler|cross-compile]] Windows applications with MinGW-GCC under POSIX systems. This means that developers do not need a Windows installation with MSYS to compile software that will run on Windows with or without Cygwin.\n\n==MinGW-w64==\n{{Infobox software\n| name = MinGW-w64\n| author = OneVision Software\n| developer = Kai Tietz\n| released = {{Start date and age|2005}}\n| latest release version = 6.0.0<ref>{{cite web |url=http://mingw-w64.org/doku.php/versions | title=MinGW-w64 version history | website=MinGW-w64 site | accessdate=2018-09-23}}</ref>\n| latest release date = {{Start date and age|2018|09|17}}\n| latest preview version = \n| latest preview date = \n| programming language = [[C (programming language)|C]], [[C++]]\n| operating system = [[Microsoft Windows]]\n| genre = [[Compiler]]\n| license = [[Public domain]] (headers), [[GNU General Public License]] (compiler and toolchain), Zope Public License\n| website = {{URL|mingw-w64.org}}\n}}\nIn 2005, [http://mingw-w64.org MinGW-w64] was created by OneVision Software under [[clean room design]] principles, since the original MinGW project was not prompt on updating its code base, including the inclusion of several key new APIs and the much needed 64-bit support. In 2008, OneVision then donated the code to Kai Tietz, one of its lead developers, under the condition that it remain open source.<ref>{{cite web\n| title=(MinGW-w64) History\n| url=https://sourceforge.net/p/mingw-w64/wiki2/History/\n| website= MinGW-w64 Wiki\n| accessdate=2016-02-18\n}}</ref> It was first submitted to the original MinGW project, but refused under suspicion of using non-public or proprietary information.<ref>{{cite mailing list\n| url = http://sourceforge.net/p/mingw/mailman/message/23100595/\n| title = Re: Harmonizing mingwrt / w32api with mingw-w64\n| last = Marshall | first = Keith\n| accessdate = 12 June 2014\n| mailinglist = MinGW-dvlpr\n| quote = However, we would require a formal audit of mingw-64 code, to ensure conformance with our requirements for truly open documentation of sources, before [merge of mingw-w64] could be completed.\n| date = 19 July 2009\n}}</ref> For many reasons, the lead developer and co-founder of the MinGW-w64 project, Kai Tietz, decided not to attempt further cooperation with MinGW.<ref>{{cite mailing list\n| url=http://sourceforge.net/p/mingw/mailman/message/23108552/\n| title=Re: Harmonizing mingwrt / w32api with mingw-w64\n| date=20 July 2014\n| accessdate=12 June 2014\n| mailinglist=MinGW-dvlpr\n| last=Tietz | first=Kai\n}}</ref>\n\nMinGW-w64 provides a more complete Win32 API implementation,<ref>{{cite web\n| url=http://mingw-w64.org\n| title=MinGW-w64\n| publisher=MinGW-w64.org\n| accessdate=30 May 2013\n}}</ref> including:\n* better [[C99]] support\n* [[POSIX Threads]] (pthreads) support (including the possibility to enable [[C++11]] thread-related functionality in GCC's [[libstdc++]])\n* GCC multilib, which allows users to install 32-bit and 64-bit libraries in parallel\n* [[Unicode in Microsoft Windows|Unicode]] entry point (wmain/wWinMain)\n* [[Windows Driver Kit|DDK]] (from [[ReactOS]])\n* [[DirectX]] (from [[Wine (software)|Wine]])\n* [[Large file support]]\n* [[Win64]] support\n* Some useful tools such as <code>gendef</code> (an improved version of MinGW's <code>pexports</code> utility), and <code>widl</code> (an IDL compiler, a free replacement for [[MIDL]]).\n\nAdditionally, the MinGW-w64 project maintains winpthreads, a [[wrapper library]] similar to pthreads-win32, with the main difference that it allows GCC to use it as a threads library resulting in functional C++11 thread libraries <code><thread></code>, <code><future></code>, and <code><mutex></code>.\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[DJGPP]]\n* [[GnuWin32]]\n* [[Interix]]\n* [[Tiny C Compiler]]\n* [[UnxUtils]]\n* [[Watcom C/C++ compiler]]\n\n==References==\n{{reflist|30em}}\n\n==External links==\n* [http://mingw.org/ official website]\n* [https://osdn.net/projects/mingw MinGW] on [http://OSDN.net OSDN.net]\n* {{cite web\n|url=https://msys2.github.io\n|title=MSYS2 installer\n|author=<!--Staff writer(s); no by-line.-->\n|website=github.io\n|publisher=\n|accessdate=2016-02-18\n}}\n\n{{Software in the Public Interest}}\n\n[[Category:1998 software]]\n[[Category:C compilers]]\n[[Category:C++ compilers]]\n[[Category:Cross-compilers]]\n[[Category:Fortran compilers]]\n[[Category:Free compilers and interpreters]]\n[[Category:Public-domain software]]"
    },
    {
      "title": "Numerical Algorithms Group",
      "url": "https://en.wikipedia.org/wiki/Numerical_Algorithms_Group",
      "text": "{{Use dmy dates|date=March 2015}}\n{{Use British English|date=March 2015}}\nThe '''Numerical Algorithms Group''' ('''NAG''')  is a [[software company|software and services company]] which provides methods for the solution of [[mathematical]] and [[statistical]] problems, and offers services to users of [[High performance computing|High performance computing (HPC)]] systems.  Its products and services are employed by tens of thousands of users from [[Financial Times Global 500|Global 500]] companies, universities, [[supercomputing]] sites and numerous independent software vendors.  As a [[Nonprofit_organization|not-for-profit]] organization, NAG reinvests its surpluses into the research and development of its products and services, and the fostering of new numerical and scientific talent. NAG serves its customers from offices in [[Oxford]], [[Manchester]], [[Chicago, Illinois|Chicago]], and [[Tokyo]], through staff in France and Germany, and via a global network of distributors.\n\n==Origins==\nNAG was founded by [[Brian Ford (numerical analyst)|Brian Ford]], [[Joan E. Walsh]], and others in 1970 as the [[Nottingham]] Algorithms Group, a collaborative venture between the universities of [[Birmingham University|Birmingham]], [[Leeds University|Leeds]], [[University of Manchester|Manchester]], [[University of Nottingham|Nottingham]] and [[Oxford University|Oxford]], and the [[Atlas Computer Laboratory]] (now part of the [[Rutherford Appleton Laboratory]]). The original aim of the project was the development of a library of numerical and statistical subroutines for the [[International Computers Limited|ICL]] [[ICT 1900 series#1900 A series|1906A]] and [[ICT 1900 series#The 1900 S series|1906S]] machines which were in use at each of these sites. Code and algorithms for the library were contributed to the project by experts in the project, and elsewhere (for example, some of the [[linear algebra]] code was written by [[James H. Wilkinson|Jim Wilkinson]], who was an early supporter of the NAG project).\n\nThe project attracted the attention of universities with other types of computers and the second release of the library was implemented on new platforms. The project moved from Nottingham to Oxford University in 1973, when its name was changed to The Numerical Algorithms Group. NAG Ltd was founded as a not-for-profit company in 1976, with [[Joan E. Walsh]] as chair, and celebrated the fortieth anniversary of the NAG project in 2010.<ref>[http://www.nag.co.uk/Market/articles/fourdecadesofnag.asp The Numerical Algorithms Group: From 0-40 in a flurry of achievements]</ref><ref>[http://issuu.com/numericalalgorithmsgroup/docs/40_years_of_nag_scrapbook 40 Years of NAG scrapbook]</ref>\n\n==Software Products==\n===The NAG Library===\nThe NAG Library<ref>[https://www.nag.com/content/nag-library NAG Library]</ref> is the oldest and best-known product of NAG. Originally produced in 1971, the current version contains more than 1,700 routines and is used by developers to add mathematical and statistical functionality to their applications, or to solve complicated mathematical problems. The Library includes routines for: \n\n* Local and global [[Optimization problem|optimization]] of multivariate functions\n* Solution of dense, banded and sparse [[linear equations]]; [[eigenvalue]] problems\n* [[curve fitting|Curve & surface fitting]]; [[interpolation]]\n* Solution of [[ordinary differential equation|ordinary]] and [[partial differential equations]]; [[mesh generation]]\n* [[Numerical integration]]; [[integral equations]]\n* Solution of [[Ordinary least squares|linear]] and [[Non-linear least squares|nonlinear]] [[Least squares|least squares problems]]\n* [[Root-finding algorithm|Finding the roots]] of [[Nonlinear system|nonlinear equations]] (including [[polynomials]])\n* [[Random number generation]]\n* [[Time series analysis]]\n* [[Correlation]] and [[Regression analysis|regression]] methods\n* [[Multivariate statistics|Multivariate]] methods\n\nThe original version of the NAG Library was written in [[Fortran]] and [[Algol 60]]; the Fortran implementation [http://www.nag.com/numeric/fl/FLdescription.asp NAG Fortran Library] is still available today, along with the [https://www.nag.com/content/nag-library-c NAG Library for C] [http://www.nag.com/numeric/CL/CLdescription.asp NAG C Library], NAG Library for .NET.[http://www.nag.com/netdevelopers.asp NAG Library for .NET] and the NAG Library for Python. The Library is accessible from several computing environments, including standard languages such as [[C (programming language)|C]], [[C++]], [[Fortran]], [[Visual Basic]], [[Java (programming language)|Java]], [[F Sharp (programming language)|F#]] and [[C Sharp (programming language)|C#]], as well as packages such as [[MATLAB]], [[R (programming language)|R]], [[LabVIEW]] and [[Microsoft Excel|Excel]].  \n\nTwo further versions of the NAG Library are aimed at [[Multiprocessing|multiprocessor machines]]: the NAG Library for SMP & multicore, [http://www.nag.com/numeric/FL/FSdescription.asp NAG Library for SMP & multicore] which takes advantage of the [[Shared memory architecture|shared memory]] parallelism of [[SMP - Symmetric Multiprocessor System|Symmetric Multi-Processors]] (SMP) and [[Multi-core processor|multicore processors]], and the NAG Parallel Library,[http://www.nag.con/numeric/fd/FDdescription.asp NAG Parallel Library] which is designed for [[distributed memory]] parallel computers.\n\n===NAG Fortran Compiler===\nThe NAG Fortran Compiler<ref>[http://www.nag.com/nagware/np.asp NAG Fortran Compiler]</ref> is available on all major [[Unix]] platforms as well as [[Microsoft Windows]].  Based on the world's first [[Fortran 90]] compiler (which was developed by NAG), it currently includes support for the full [[Fortran 95]] language, as well as many [[Fortran 2003]] features.\n\n==Numerical Services and HPC Services & Consulting==\nNAG provide numerical services in the areas of <ref>[https://www.nag.com/content/software-services Numerical Services]</ref>Mathematical Optimization and <ref>[https://www.nag.com/content/adjoint-algorithmic-differentiation Algorithmic Differentiation Solutions]</ref>Algorithmic Differentiation and are global specialists in <ref>[https://www.nag.com/content/high-performance-computing-consulting-and-services High Performance Computing Consulting & Services]</ref>high performance computing consulting and services.\n\n==Management==\nThe current [[Chief Executive Officer]] of NAG is Robert W. Meyer.<ref>{{cite magazine| url=http://www.scientific-computing.com/features/feature.php?feature_id=14 | title=Profile of Rob Meyer, NAG CEO | magazine=[[Scientific Computing World]] | date= April–May 2006 }}</ref> A former engineering student at [[Washington University in St. Louis]], he was the Executive Vice President of U.S. operations for NAG before being promoted to his current post. Dr. Meyer divides his time among NAG's [[Chicago, Illinois|Chicago]], [[Oxford]], and [[Tokyo]] offices, and is a resident of [[Wheaton, Illinois]].\n\n==References==\n{{reflist}}\n\n==External links==\n*[http://www.nag.com NAG website]\n*[https://www.nag.com/blog NAG blog]\n\n[[Category:1970 establishments in England]]\n[[Category:British companies established in 1970]]\n[[Category:Companies based in Nottingham]]\n[[Category:Computer companies of the United Kingdom]]\n[[Category:Fortran compilers]]\n[[Category:Companies associated with the University of Oxford]]\n[[Category:Software companies of the United Kingdom]]\n[[Category:University of Nottingham]]\n[[Category:Services]]"
    },
    {
      "title": "Open64",
      "url": "https://en.wikipedia.org/wiki/Open64",
      "text": "{{more citations needed|date=September 2010}}\n{{Infobox software\n| name                   = Open64\n| screenshot             =\n| caption                =\n| developer              = [[Silicon Graphics]], Inc., Institute of Computing Technology, [[Chinese Academy of Sciences]], [[Hewlett Packard]], [[University of Delaware]]\n| released               = {{Start date and age|2002}}\n|discontinued = yes\n| latest release version = 5.0\n| latest release date    = {{Start date and age|2011|11|10}}\n| operating system       = [[Cross-platform]], [[Linux]]\n| genre                  = [[Compiler]]\n| license                = [[GNU General Public License]]\n| website                = {{URL|sourceforge.net/projects/open64/}}\n}}\n\n'''Open64''' is a [[free software|free]], [[open-source software|open-source]], optimizing [[compiler]] for the [[Itanium]] and [[x86-64]] [[microprocessor]] architectures. It derives from the [[Silicon Graphics|SGI]] compilers for the MIPS [[R10000]] processor, called ''MIPSPro''. It was initially released in 2000 as [[GNU GPL]] software under the name Pro64. The following year, University of Delaware adopted the project and renamed the compiler to Open64. It now mostly serves as a research platform for compiler and [[computer architecture]] research groups. Open64 supports [[Fortran]] 77/95 and C/C++, as well as the [[Shared memory (interprocess communication)|shared memory]] programming model [[OpenMP]]. It can conduct high-quality [[interprocedural optimization|interprocedural analysis]], [[data-flow analysis]], data [[dependence analysis]], and [[array region analysis]].  Development has ceased, although other projects can use the project's source.\n\n== The infrastructure ==\nIts major components are the [[front end processor (program)|frontend]] for C/C++ (using [[GNU Compiler Collection|GCC]]) and Fortran 77/90 (using the CraySoft front-end and libraries), [[interprocedural optimization|Interprocedural analysis]] (IPA), loop nest optimizer (LNO), global optimizer (WOPT), and [[code generator]] (CG). Despite being initially written for a single computer architecture, Open64 has proven that it can generate efficient code for [[complex instruction set computer|CISC]], [[reduced instruction set computer|RISC]], and [[very long instruction word|VLIW]] architectures, including [[MIPS architecture|MIPS]], [[x86]], [[Itanium|IA-64]], [[ARM architecture|ARM]], and others.\n\n== Intermediate representation ==\nA hierarchical [[intermediate representation]] (IR) with five main levels is used in this compiler to serve as the common interface among all the frontend and backend components.  This IR is named WHIRL.\n\n== Versions ==\nThe original version of Open64 that was released in 2002 was missing its very advanced [[software pipelining]] code generator, and had only a rudimentary code generator for Itanium.  The entire original MIPSPro compiler, with this code generator, is available under a commercial license as the Blackbird compiler from Reservoir Labs.  The [http://portal.acm.org/citation.cfm?id=231385 Showdown Paper] documents the code generator that was not included in Open64.  The very advanced compiler from Tilera, for its 64-core TILE64 chip, is based on Blackbird.\n\nOpen64 exists in many [[fork (software development)|forks]], each of which has different features and limitations. The \"classic\" Open64 branch is the [[Open Research Compiler]] (ORC), which produces code only for the Itanium (IA-64), and was funded by [[Intel]]. The ORC effort ended in 2003, and the current official branch (which originated from the Intel ORC project) is managed by [[Hewlett Packard]] and the [[University of Delaware]]'s Computer Architecture and Parallel Systems Laboratory (CAPSL).\n\nOther important branches include the compilers from [[Tensilica]] and the [[AMD]] x86 Open64 Compiler Suite.<ref>{{ cite web | title = x86 Open64 Compiler Suite | publisher = [[AMD]] | url = http://developer.amd.com/tools-and-sdks/cpu-development/x86-open64-compiler-suite/ | accessdate = 12 November 2013 | deadurl = yes | archiveurl = https://web.archive.org/web/20131113100944/http://developer.amd.com/tools-and-sdks/cpu-development/x86-open64-compiler-suite/ | archivedate = 13 November 2013 | df =  }}</ref>\n\n[[Nvidia]] is also using an Open64 fork to optimize code in its [[CUDA]] toolchain.<ref>[http://www.capsl.udel.edu/conferences/open64/2008/Papers/101.doc NVIDIA’s Experience with Open64]</ref>\n\n=== Open64 releases ===\n{| class=wikitable\n!Version !! Release date\n|-\n|5.0\n|2011-11-11\n|-\n|4.2.4\n|2011-04-12\n|-\n|4.2.3\n|2010-04-09\n|-\n|4.2.1\n|2008-12-08\n|-\n|4.2\n|2008-10-01\n|-\n|4.1\n|2007-12-03\n|-\n|4.0\n|2007-06-15\n|-\n|3.1\n|2007-04-13\n|-\n|3.0\n|2006-11-22\n|-\n|2.0\n|2006-10-02\n|-\n|1.0\n|2006-09-22\n|-\n|0.16\n|2003-07-07\n|-\n|0.15\n|2002-11-30\n|-\n|0.14\n|2002-03-04\n|-\n|0.13\n|2002-01-10\n|}\n\n=== AMD x86 Open64 releases ===\n{| class=wikitable\n!Version !! Release date\n|-\n|4.5.2.1\n|2013-03-28\n|-\n|4.5.2\n|2012-08-08\n|-\n|4.5.1\n|2011-12-19\n|-\n|4.2.4\n|2010-06-29\n|-\n|4.2.3.2\n|2010-05-17\n|-\n|4.2.3.1\n|2010-01-29\n|-\n|4.2.3\n|2009-12-11\n|-\n|4.2.2.3\n|2009-11-23\n|-\n|4.2.2.2\n|2009-08-31\n|-\n|4.2.2.1\n|2009-06-03\n|-\n|4.2.2\n|2009-04-24\n|}\n\n== Current development projects ==\nOpen64 is also used in a number of research projects, such as the [[Unified Parallel C]] (UPC) and [[speculative multithreading]] work at various universities.  The 2010 Open64 Developers Forum describes projects done at [[Absoft Fortran Compilers|Absoft]], [[AMD]], [[Chinese Academy of Sciences]], [[Fudan University]], [[Hewlett-Packard|HP]], [[National Tsing Hua University]], [[Nvidia]], [[Tensilica]], [[Tsinghua University]], and [[University of Houston]].<ref>[http://dynopt.ece.udel.edu/open64/program.shtml 2010 Open64 Developers Forum, August 25, 2010]</ref>  The [[Chinese Academy of Sciences]] ported Open64 to the [[Loongson]] II platform.<ref>[http://www.capsl.udel.edu/conferences/open64/2009/Papers/102-Open64onMIPS2.pdf Open64 on MIPS: porting and enhancing Open64 for Loongson II]</ref>\n\n[[AMD]] has extended and productized Open64 with optimizations designed for x86 multi-core processor advancements and multi-threaded code development.<ref>[http://blogs.amd.com/nigel-dessau/2009/06/22/sweet-suite/: Sweet Suite, blog posting by Nigel Dessau, AMD CMO, June 22, 2009]</ref>  AMD supports Open64 as a complementary compiler to [[GNU Compiler Collection|GCC]].<ref>[http://developer.amd.com/tools/cpu-development/x86-open64-compiler-suite/ AMD Open64 download page]</ref>\n\nThe University of Houston's OpenUH project, which is based on Open64, released a new version of its compiler suite in November 2015.<ref>[http://web.cs.uh.edu/~openuh/download/ OpenUH downloads page]</ref>\n\n== See also ==\n{{Portal|Free and open-source software}}\n* [[GNU Compiler Collection]]\n* [[List of compilers]]\n* [[GPGPU]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* {{Official website}}\n* [https://developer.amd.com/x86-open64-compiler-suite/ AMD Open64 page]\n* [http://upc.nersc.gov/ The Berkeley UPC-to-C translator]\n* [http://www2.cs.uh.edu/~openuh/ OpenUH project at University of Houston]\n\n{{FOSS}}\n{{Software in the Public Interest}}\n\n[[Category:C compilers]]\n[[Category:C++ compilers]]\n[[Category:Compilers]]\n[[Category:Fortran compilers]]\n[[Category:Free compilers and interpreters]]"
    },
    {
      "title": "Oracle Developer Studio",
      "url": "https://en.wikipedia.org/wiki/Oracle_Developer_Studio",
      "text": "{{primary sources|date=April 2011}}\n{{one source|date=April 2011}}\n{{Infobox software\n| name                   = Oracle Developer Studio\n| developer              = [[Oracle Corporation]]\n| latest release version = 12.6<ref>{{cite web\n  |url = https://blogs.oracle.com/solaris/http%3awwworaclecomtechnetworkserver-storagedeveloperstudiooverviewindexhtml\n  |title = Announcing Oracle Developer Studio 12.6!\n  |accessdate = 2017-09-13\n  |author = Ikroop Dhillon\n  |date = 2017-07-05\n  |work = Oracle Blogs\n  |publisher = [[Oracle Corporation]]\n  }}</ref>\n| latest release date    = {{start date and age|2017|07|05}}\n| operating system       = [[Solaris (operating system)|Solaris]], [[OpenSolaris]], [[Red Hat Enterprise Linux|RHEL]], [[Oracle Linux]]<ref>[https://www.theregister.co.uk/2011/12/19/oracle_studio_compilers_tuxedo/ Oracle gooses Studio compilers for Solaris, Linux]</ref>\n| genre                  = [[Compiler]], [[debugger]], [[software build]], [[integrated development environment]]\n| website                ={{URL|http://www.oracle.com/technetwork/server-storage/developerstudio/overview}}\n| language               = English, Japanese<br />Simplified Chinese\n| license                = Free for download and use as described in the product license\n}}\n'''Oracle Developer Studio''', formerly named '''Oracle Solaris Studio''', '''Sun Studio''', '''Sun WorkShop''', '''Forte Developer''', and '''SunPro Compilers''', is [[Oracle Corporation]]'s flagship software development product for the [[Solaris (operating system)|Solaris]] and [[Linux]] [[operating system]]s. It includes optimizing C, C++, and Fortran [[compiler]]s, libraries, and performance analysis and debugging tools, for Solaris on SPARC and x86 platforms, and Linux on x86/x64 platforms, including multi-core systems.\n\nOracle Developer Studio is downloadable and usable at no charge; however, there are many security and functionality patch updates which are only available with a support contract from Oracle.<ref>{{cite web|title=Oracle Developer Studio - Downloads |url=http://www.oracle.com/technetwork/server-storage/developerstudio/downloads/index.html |publisher=Oracle Corporation|accessdate=2018-03-16}}</ref>\n\nVersion 12.4 adds support for the [[C++11]] language standard.<ref>{{citation|title=What's New in Oracle® Solaris Studio 12.4|chapter=Support for the C++11 Standard |url=http://docs.oracle.com/cd/E37069_01/html/E37071/gncix.html |publisher=Oracle Corporation|accessdate=2018-03-16}}</ref> All C++11 features are supported except for concurrency and atomic operations, and user-defined literals. Version 12.6 supports the [[C++14]] language standard.<ref>{{citation|title=Oracle® Developer Studio 12.6: C++ User's Guide |chapter=1.5 Standards Conformance |url=https://docs.oracle.com/cd/E77782_01/html/E77789/bkabg.html |publisher=[[Oracle Corporation|Oracle]]|accessdate=2018-03-16}}</ref>\n\n==Languages==\n* [[C (programming language)|C]]\n* [[C++]]\n* [[Fortran]]\n\n==Supported architectures==\n* [[SPARC]]\n* i86pc ([[x86]] and [[x86-64]])\n\n== Components ==\nThe Oracle Developer software suite includes:\n* C, C++, and Fortran compilers and support libraries\n* [[dbx (debugger)|dbx]] and frontends\n* [[lint (software)|lint]]\n* A [[NetBeans]]-based [[interactive development environment|IDE]]\n* [[Performance Analyzer]]<ref>{{cite web| url = http://docs.oracle.com/cd/E19205-01/819-5264\n| title = Oracle Solaris Studio 12.2: Performance Analyzer\n| accessdate = 2010-09-11\n| publisher = Oracle Corporation\n}}</ref>\n* Thread analyzer\n* Sun performance library\n* Distributed make<ref>{{cite web\n| url = http://docs.oracle.com/cd/E19205-01/819-5273/\n| title = Sun Studio 12: Distributed Make (dmake)\n| accessdate = 2016-06-01\n| publisher = Oracle Corporation\n}}</ref>\n\n== Compiler optimizations ==\n\nA common [[compiler optimization|optimizing]] backend is used for code generation.\n\nA high-level intermediate representation called ''[[Sun IR]]'' is used, and high-level optimizations done in the ''iropt'' (intermediate representation optimizer) component are operated at the Sun IR level. Major optimizations include:\n\n* [[Copy propagation]]\n* [[Constant folding]] and constant propagation\n* [[Dead code elimination]]\n* [[Interprocedural optimization]] analysis\n* [[Loop optimization]]s\n* [[Automatic parallelization]]\n* [[Profile-guided optimization]]\n* [[Scalar replacement]]\n* [[Strength reduction]]\n* [[Automatic vectorization]], with <code>-xvector=simd</code>\n\n==OpenMP==\nThe [[OpenMP]] shared memory parallelization API is native to all three compilers.\n\n==Code coverage==\n{{Main article|Tcov}}\n[[Tcov]], a source [[code coverage]] analysis and statement-by-statement profiling tool, comes as a standard utility. Tcov generates exact counts of the number of times each statement in a program is executed and annotates [[source code]] to add instrumentation.\n\nThe tcov utility gives information on how often a [[computer program|program]] executes segments of code. It produces a copy of the source file, annotated with execution frequencies. The code can be annotated at the [[basic block]] level or the source line level. As the statements in a basic block are executed the same number of times, a count of basic block executions equals the number of times each statement in the block is executed. The tcov utility does not produce any time-based data.\n\n==GCCFSS==\nThe GCC for SPARC Systems (GCCFSS) compiler uses [[GNU Compiler Collection]]'s (GCC) front end with the Oracle Developer Studio compiler's code-generating back end. Thus, GCCFSS is able to handle GCC-specific compiler directives, while it is also able to take advantage of the compiler optimizations in the compiler's back end. This greatly facilitates the porting of GCC-based applications to SPARC systems.\n\nGCCFSS 4.2 adds the ability to be used as a [[cross compiler]]; SPARC binaries can be generated on an x86 (or x64) machine running Solaris.<ref>{{cite web\n| url = http://cooltools.sunsource.net/gcc/4.2.0/crosscompile.html\n| title = Cool Tools - GCC for Sun Systems 4.2.0 as a Cross Compiler\n| accessdate = 2008-07-31\n| publisher = Sun Microsystems\n}}</ref>\n\n==Research platform==\nBefore its cancellation, the [[Rock (processor)|Rock]] would have been the first general-purpose processor to support ''hardware [[transactional memory]]'' (HTM). The Oracle Developer Studio compiler is used by a number of research projects, including ''Hybrid Transactional Memory'' (HyTM)<ref>{{cite web\n| url = http://labs.oracle.com/scalable/pubs/ASPLOS2006.pdf\n| title = Hybrid Transactional Memory\n| accessdate = 2007-11-10\n| publisher = Sun Microsystems\n}}</ref> and ''Phased Transactional Memory'' (PhTM),<ref>{{cite web\n | url = http://labs.oracle.com/scalable/pubs/TRANSACT2007-PhTM.pdf\n  |archive-url = https://web.archive.org/web/20120211131402/http://labs.oracle.com/scalable/pubs/TRANSACT2007-PhTM.pdf\n  |archive-date = 2012-02-11\n | title = PhTM: Phased Transactional Memory\n | accessdate = 2016-06-01\n | publisher = Sun Microsystems\n}}</ref> to investigate support and possible HTM optimizations.\n\n==History==\n{| class=\"wikitable plainrowheaders\" style=\"text-align:center\"\n|-\n! scope=\"col\" | Product name \n! scope=\"col\" | Version number\n!C/C++ compiler\n! scope=\"col\" | Supported Operating Systems\n! scope=\"col\" | Release date\n|-\n! scope=\"row\" |SPARCworks 1.0\n|\n|1.0\n|SunOS 4\n|1991\n|-\n! scope=\"row\" |SPARCworks 2.0 (SPARCompiler)\n|\n|2.0\n|Solaris 2.x, SunOS 4.1.x\n|June 1992\n|-\n! scope=\"row\" |SunSoft Workshop 1.0\n|\n|3.0\n|Solaris 2.x, SunOS 4.1.x\n|July 1994\n|-\n! scope=\"row\" |SunSoft Workshop 2.0\n|\n|4.0\n|Solaris 2.2 or later\n|March 1995\n|-\n! scope=\"row\" |Sun Workshop 3.0\n|\n|4.2\n|Solaris 2.4, 2.5, 2.6, 7\n|January 1997\n|-\n! scope=\"row\" |Sun Workshop 5 \n|5\n|5.0\n|Solaris 2.5.1, 2.6, 7\n|December 1998\n|-\n! scope=\"row\" | Forte Developer 6 (Sun WorkShop 6)\n| 6 \n|5.1\n| Solaris 2.6, 7, 8 || {{dts|2000|05}}\n|-\n! scope=\"row\" | Forte Developer 6 update 1\n| 6.1 \n|5.2\n| Solaris 2.6, 7, 8 || {{dts|2000|11}}\n|-\n! scope=\"row\" | Forte Developer 6 update 2\n| 6.2 \n|5.3\n| Solaris 2.6, 7, 8, 9 || {{dts|2001|07}}\n|-\n! scope=\"row\" | Sun ONE Studio 7 (Forte Developer 7)\n| 7 \n|5.4\n| Solaris 7, 8, 9 || {{dts|2002|05}}\n|-\n! scope=\"row\" | Sun ONE Studio 8 Compiler Collection\n| 8 \n|5.5\n| Solaris || {{dts|2003|05}}\n|-\n! scope=\"row\" | Sun Studio 8\n| 8 \n|5.5|| Solaris 7, 8, 9, 10 || {{dts|2004|03}}\n|-\n! scope=\"row\" | Sun Studio 9\n| 9 \n|5.6|| Solaris 8, 9, 10; Linux || {{dts|2004|07}}\n|-\n! scope=\"row\" | Sun Studio 10\n| 10 \n|5.7|| Solaris 8, 9, 10; Linux || {{dts|2005|01}}\n|-\n! scope=\"row\" | Sun Studio 11\n| 11 \n|5.8|| Solaris 8, 9, 10; Linux || {{dts|2005|11}}\n|-\n! scope=\"row\" | Sun Studio 12\n| 12 \n|5.9|| Solaris 9, 10 1/06; Linux || {{dts|2007|06}}\n|-\n! scope=\"row\" | Sun Studio 12 Update 1\n| 12.1 \n|5.10|| Solaris 10 1/06; OpenSolaris 2008.11, 2009.06; Linux || {{dts|2009|06}}\n|-\n! scope=\"row\" | Oracle Solaris Studio 12.2\n| 12.2 \n|5.11|| Solaris 10 1/06 and above; Linux || {{dts|2010|09}}\n|-\n! scope=\"row\" | Oracle Solaris Studio 12.3\n| 12.3 \n|5.12|| Solaris 10 1/08 and above, 11; Linux || {{dts|2011|12}}\n|-\n! scope=\"row\" | Oracle Solaris Studio 12.4\n| 12.4 \n|5.13|| Solaris 10 8/11, 10 1/13, 11.2; Linux || {{dts|2014|11}}\n|-\n! scope=\"row\" | Oracle Developer Studio 12.5\n| 12.5 \n|5.14|| Solaris 10 1/13, 11.3; Linux || {{dts|2016|06}}\n|-\n! scope=\"row\" | Oracle Developer Studio 12.6\n| 12.6\n|5.15|| Solaris 10 1/13, 11.3; Linux || {{dts|2017|06}}\n|}\n– Source: <ref>{{cite web|title=Oracle Developer Studio and Oracle Solaris Studio Component Matrix|url=http://www.oracle.com/technetwork/server-storage/developerstudio/training/index-jsp-141991.html|website=Oracle Technology Network|publisher=Oracle Corporation|accessdate=2018-03-16}}</ref>\n\n== References ==\n{{reflist|30em}}\n\n==External links==\n* [http://www.oracle.com/technetwork/server-storage/developerstudio/overview/ Oracle Developer Studio home page] on Oracle Developer Network\n* [http://www.oracle.com/technetwork/server-storage/developerstudio/documentation/ Product documentation]\n* [https://web.archive.org/web/20071214013716/http://cooltools.sunsource.net/gcc/ Cool Tools - GCC for SPARC Systems]\n* [https://forums.oracle.com/community/developer/english/development_tools/application_development_in_c__c%2B%2B__and_fortran Oracle Studio Forums]\n* [https://web.archive.org/web/20080129213345/http://wikis.sun.com/display/AppPerfTuning/Application+Performance+Tuning+Home Application Performance Tuning on Sun Platform] (archived Jan 29, 2008)\n* [http://www.oracle.com/technetwork/server-storage/developerstudio/downloads/index.html Download Oracle Developer Studio]\n* [http://www.oracle.com/technetwork/server-storage/developerstudio/training/index-jsp-141991.html Oracle Developer Studio Component Matrix]\n\n{{Integrated development environments}}\n{{Sun Microsystems}}\n{{Oracle}}\n\n[[Category:Sun Microsystems software]]\n[[Category:C++ compilers]]\n[[Category:C compilers]]\n[[Category:Fortran compilers]]\n[[Category:compilers and interpreters]]\n[[Category:computer libraries]]"
    },
    {
      "title": "PathScale",
      "url": "https://en.wikipedia.org/wiki/PathScale",
      "text": "{{Refimprove|date=November 2009}}\n{{Infobox software\n| name = PathScale EKOPath Compiler\n| screenshot =\n|  caption =\n| developer = PathScale Inc.\n| released = {{Start date and age|2003}}\n| latest_release_version = 5.0.0\n| latest_release_date = {{Start date and age|2013|12|05}}\n| operating_system = [[Linux]], [[FreeBSD]], and [[Solaris (operating system)|Solaris]]\n| programming language = [[C (programming language)|C]] and [[C++]]\n| platform =  [[x86-64]]\n| genre = [[Compiler]]\n| website = {{URL|https://web.archive.org/web/20170205003605/http://www.pathscale.com:80/|www.pathscale.com}}\n}}\n'''PathScale Inc.''' was a company that developed a highly optimizing [[C (programming language)|C]], [[C++]], and [[Fortran]] compiler suite for the [[x86-64]] [[microprocessor]] architectures. It derives from the [[Silicon Graphics|SGI]] compilers for the [[MIPS architecture]] [[R10000]] processor, called MIPSPro.\n\nAfter being acquired and re-sold, by March 24 2017, Pathscale was reported to be looking for another buyer of its assets.<ref>{{Cite news |title= HPC Compiler Company PathScale Seeks Life Raft|work= HPCWire|author= Tiffany Trader |date= March 23, 2017 |url= https://www.hpcwire.com/2017/03/23/hpc-compiler-company-pathscale-seeks-life-raft/|accessdate= March 24, 2017 }}</ref> As of May 2017 its open source compiler has been removed from its GitHub account and the official company web site is down.\n\n==History==\nPathScale was founded in 2001 as Key Research and its original mission was to develop [[Cluster (computing)|clustered]] [[Linux]] server solutions based on a low-cost 64-bit design. In late 2003 the company came out of [[stealth mode]] and was called PathScale. The word PathScale is descriptive of the company's original design goals for clusters. In early 2003 with the success of the [[AMD Opteron]], efforts at the company switched to other products like high-performance 64-bit [[compiler]]s.\n\nThe seeds of the company were sown over 20 years ago at the [[Lawrence Livermore National Laboratory]]. Four of the company's seven founders all worked together building the [[S1 (supercomputer)|S1]] [[supercomputer]] back in the early 1980s. The first [[chief technical officer]] at PathScale, Tom McWilliams, had the initial idea for the company and incorporated in July 2001. He added three of his LLNL colleagues (Jeff Rubin, Jeff Broughton, Fred Chow) to the company shortly thereafter. McWilliams had been a company founder at [[Valid Logic Systems]] and Key Computer and worked at SGI, [[Sun Microsystems]] and [[Amdahl Corporation]]. Chow was formerly chief scientist for compilers at SGI and MIPS.\n\nPathScale Inc. was acquired and re-sold several times.\nFirst by [[QLogic]] in February 2006, for about $109 million.<ref>{{Cite news |title= QLogic has an Infiniband moment with PathScale buy: $109m Opteron/Xeon play|work= The Register |author= Ashlee Vance |date= February 18, 2006 |url= https://www.theregister.co.uk/2006/02/18/pathscale_goes_qlogic/ |accessdate= February 9, 2017 }}</ref>\nA network technology called InfiniPath was marketed as TrueScale by QLogic, and then sold to [[Intel]] and became the basis of [[Omni-Path]].<ref>{{Cite web |title= A Look At The Latest Omni-Path Claims |author= Gilad Shainer |work= Mellanox blog |date= April 28, 2016 |url= https://www.mellanox.com/blog/2016/04/a-look-at-the-latest-omni-path-claims/ |access-date= April 1, 2017 }}</ref>\nThe compiler technology was acquired by [[SiCortex]] in August 2007, and by [[Cray]] in August 2009, when SiCortex was \n[[liquidated]]. Cray owned the intellectual property until March 2012 when a new PathScale Inc. acquired all assets.<ref>{{cite web |url=http://www.pathscale.com/pathscale_asset_acquisition |title=PathScale Inc. acquires all PathScale Intellectual Property and Assets from Cray |date=March 12, 2012 |work= PRNewswire}}</ref>\n\nOn June 13, 2011, PathScale announced that the EKOPath 4 compiler suite would become open source software and licensed under the [[GPL]].<ref>{{cite web|url=http://www.pathscale.com/ekopath4-open-source-announcement|title=EKOPath 4 Compiler Suite going open source with support available|publisher=PathScale Inc.}}</ref><ref>https://www.phoronix.com/scan.php?page=article&item=pathscale_ekopath4_open PathScale Open-Sources The EKOPath 4 Compiler Suite</ref><ref>https://www.phoronix.com/scan.php?page=news_item&px=OTU2OA More Details From The EKOPath Open-Source Launch</ref>\n\nThe suite contains:\n* [[C (programming language)|C]], [[C++]], and [[Fortran]] 77/90/95/2003 (partial) compilers\n* Complete support for [[OpenMP]] 2.5 (including WORKSHARE)\n* Complete support for 64-bit and 32-bit x86 compilation\n* Code generation for AMD64 [[Application Binary Interface|ABI]], AMD Opteron, and Intel EM64T\n* Optimized AMD Core Math Library\n* Advanced [[multi-threaded]] debugger PathDB\n* Compatible with [[GNU]]/[[GNU Compiler Collection|gcc]] [[tool chain]] and popular third-party debuggers\n* Supported on [[SUSE Linux|SUSE]], [[Red Hat]], and [[Ubuntu (operating system)|Ubuntu]]\n\n== See also ==\n{{Portal|Free and open-source software|Companies}}\n* [[List of compilers]]\n* [[GPGPU]]\n* [[OpenMP]]\n* [[High-performance computing]]\n\n== References ==\n{{Reflist}}\n\n== Further reading ==\n* [https://web.archive.org/web/20110716214231/http://www.tgc.com/hpcwire/hpcwireWWW/04/0521/107693.html PathScale CEO comments on company, Linux Clustering]\n\n== External links ==\n* {{Official website}}\n* [http://www.path64.org/ Path64 page]\n\n{{DEFAULTSORT:Pathscale}}\n[[Category:C++ compilers]]\n[[Category:C compilers]]\n[[Category:Cray]]\n[[Category:Fortran compilers]]"
    },
    {
      "title": "The Portland Group",
      "url": "https://en.wikipedia.org/wiki/The_Portland_Group",
      "text": "{{Infobox company\n| name     = PGI \n| logo     = PGI logo.svg\n| type     = [[Subsidiary|Wholly owned subsidiary]]\n| foundation       = [[Wilsonville, OR]], [[United States]] (1989)\n| location_city    = [[Beaverton, Oregon]]\n| location_country = [[United States]]\n| founder          = Vince Schuster <br /> Larry Meadows <br /> Bob Toelle <br /> Glenn Denison\n| area_served      = Worldwide\n| industry         = [[Software]], [[Programming tool]]s\n| products         = [[Compilers]]<br />[[Debuggers]]<br />[[Profilers]]<br />[[Integrated development environment|IDE]]s\n| homepage         = {{URL|pgroup.com}}\n| footnotes        =\n}}\n\n'''PGI''' (formerly The Portland Group, Inc.), was a company that produced a set of commercially available [[Fortran]], [[C (programming language)|C]] and [[C++]] [[compilers]] for [[high-performance computing]] systems.  On July 29, 2013, [[Nvidia|NVIDIA]] Corporation acquired The Portland Group, Inc. <ref>[https://www.theregister.co.uk/2013/07/30/nvidia_buys_the_portland_group/ \"Nvidia buys Portland Group for compiler smarts\"]</ref> The Portland Group (or PGI) name is now known as a brand of software development tools produced by [[Nvidia|NVIDIA]] Corporation.\n\n==Company history==\n<!-- founded, from Floating Point Systems, early work for Sun?,  Paragon, Linux x86 business, acquisition, ??? -->\n\nThe Portland Group was founded as a privately held company in 1989, using compiler technology developed at and acquired from [[Floating Point Systems]], Inc.  The first products, pipelining Fortran and C compilers, were released in 1991, targeting the [[Intel i860]] processor. These compilers were used on Intel supercomputers like the [[Intel iPSC/860|iPSC/860]], the [[Touchstone Delta]], and the [[Intel Paragon|Paragon]], and were the compilers of choice for the majority of i860-based platforms.\n\nIn the early 1990s PGI was deeply involved in the development of [[High Performance Fortran]], or HPF, a data parallel language extension to [[Fortran 90]] which provides a portable programming interface for a wide variety of architectures. PGI produced an HPF compiler which continues to be available today.\n\nIn 1996 PGI developed [[x86]] compilers for the [[ASCI Red]] Supercomputer at [[Sandia National Laboratories]],<ref>{{cite web|title=The ASCI Option Red Supercomputer |url=http://www.sandia.gov/ASCI/Red/papers/Mattson/OVERVIEW.html |publisher=Intel Corporation |accessdate=25 March 2011 |date=May 1996 |deadurl=yes |archiveurl=https://web.archive.org/web/20100528051556/http://www.sandia.gov/ASCI/Red/papers/Mattson/OVERVIEW.html |archivedate=May 28, 2010 }}</ref> the first computer system to sustain [[teraflop]] performance. In 1997 PGI released x86 compilers for general use on [[Linux]] workstations.\n\nThe Portland Group was acquired by [[STMicroelectronics]] in December, 2000,<ref>{{cite web|title=STMicroelectronics Announces Acquisition of Portland Group Inc.|url=http://investors.st.com/phoenix.zhtml?c=111941&p=irol-newsArticle&ID=1455084&highlight=|publisher=STMicroelectronics|accessdate=25 March 2011|date=19 December 2000}}</ref> and operated as a wholly owned subsidiary producing HPC compilers and tools for Linux, Windows, and Mac OS. [[Nvidia|NVIDIA]] Corporation acquired PGI from [[STMicroelectronics]] on July 29, 2013.<ref>[http://blogs.nvidia.com/blog/2013/07/29/portland/ \"NVIDIA Pushes Further Into High Performance Computing With Portland Group Acquisition\"]. NVIDIA. July 29, 2013.</ref> Today, the same compilers and tools are made available through [[Nvidia|NVIDIA]] under \"[[PGI Compilers and Tools]]\" brand name.<ref>{{cite web|title=PGI Products|url=http://www.pgroup.com/products/index.htm|publisher=NVIDIA|accessdate=1 October 2015|date=1 October 2015}}</ref>\n\nPGI has been deeply involved in the expansion of the use of [[GPGPU]]s for high-performance computing, developing [[CUDA Fortran]]\n<ref>{{cite web|title=PGI and NVIDIA Team To Deliver CUDA Fortran Compiler |url=http://www.pgroup.com/about/news.htm#34|publisher=The Portland Group, Inc.|accessdate=29 June 2011|date=23 June 2009}}</ref>\n<ref>{{cite web|title=PGI CUDA Fortran Now Available from The Portland Group |url=http://www.pgroup.com/about/news.htm#37|publisher=The Portland Group, Inc.|accessdate=29 June 2011|date=17 November 2009}}</ref> \nwith [[NVIDIA]] Corporation and PGI Accelerator Fortran and C compilers\n<ref>{{cite web|title=New PGI 9.0 Compilers Simplify x64+GPU Programming |url=http://www.pgroup.com/about/news.htm#33|publisher=The Portland Group, Inc.|accessdate=29 June 2011|date=23 June 2009}}</ref> \nwhich use [[directive (programming)|programming directives]]. PGI has more recently participated in the specification of the new standard [[OpenACC]] directives for GPU computing, and has released a compiler for the OpenCL language on multi-core [[Arm architecture|ARM]] processors.\n\n==Product and market history==\n\n===Compilers===\nPGI compilers incorporate global optimization, vectorization, software pipelining, and shared-memory parallelization capabilities targeting both Intel and AMD processors.  PGI supports the following high-level languages:\n* Fortran 77\n* Fortran 90/95/2003\n* Fortran 2008 (partial)\n* High Performance Fortran (HPF)\n* ANSI C99 with K&R extensions\n* ANSI/ISO C++\n* CUDA Fortran\n* OpenCL\n* OpenACC\n* OpenMP\n\n===Programming Tools===\nPGI also provides a parallel debugger, PGDBG, and a performance profiler, PGPROF, both of which support OpenMP and MPI parallelism on Linux, Windows, and Mac OS.  On Windows, the PGI Fortran compiler and debugger have been fully integrated into Microsoft [[Visual Studio]] as a product called PGI Visual Fortran.\n\n===PGI Milestones===\n* 1989 - PGI founded\n* 1991 - [[Pipelining]] i860 Compilers\n* 1994 - Parallel i860 Compilers\n* 1996 - [[ASCI Red]] TFLOPS Compilers\n* 1997 - Linux/x86 Compilers\n* 1998 - [[OpenMP]] for Linux/x86\n* 1999 - [[Streaming SIMD Extensions|SSE]]/[[SIMD]] [[Automatic parallelization|Vectorization]]\n* 2001 - [[VLIW]] ST100 Compilers\n* 2003 - 64-bit Linux/x86 Compilers\n* 2004 - ASCI [[Red Storm (computing)|Red Storm]] Compilers\n* 2005 - PGI Unified Binary Technology\n* 2006 - PGI Visual Fortran\n* 2007 - 64-bit [[Mac OS]] Compilers\n* 2008 - PGI Accelerator Compilers\n* 2009 - [[CUDA]] Fortran Compiler<ref>{{cite web|title=Nvidia Announces CUDA Fortran Compiler Beta|url=http://www.eweek.com/c/a/Application-Development/NVIDIA-Announces-New-CUDA-Fortran-Compiler-Beta-225743/|publisher=eWeek|accessdate=29 June 2011|date=29 Sep 2009}}</ref>\n* 2010 - CUDA X86 Compiler\n* 2011 - [[Advanced Vector Extensions|AVX]]/[[FMA instruction set|FMA]] Vectorization\n* 2012 - [[OpenACC]] standard directives for GPU computing\n* 2012 - PGI [[OpenCL]] compiler for Multi-core [[ARM architecture|ARM]] CPUs. Removed after NVIDIA bought PGI.\n\n==See also==\n* [[Fortran]]\n* [[C (programming language)|C]]\n* [[C++]]\n* [[Debugger]]\n* [[Profiling (computer programming)|Profiler]]\n* [[Integrated development environment|IDE]]\n\n==References==\n{{Reflist}}\n\n==External links==\n* {{Official website|www.pgroup.com}}\n* [http://visualstudiogallery.msdn.microsoft.com/420B5C3D-F5C4-4C62-A60F-7F8A50BC614F/ PGI Visual Fortran in the Visual Studio Gallery]\n* [http://www.openacc.org/ OpenACC website]\n* [http://www.khronos.org/opencl/ OpenCL website]\n<!--  add to this list?\n{{ORCompanies}}\n-->\n\n{{DEFAULTSORT:Portland Group}}\n[[Category:Compilers]]\n[[Category:C compilers]]\n[[Category:C++ compilers]]\n[[Category:Fortran compilers]]\n[[Category:Debuggers]]\n[[Category:Profilers]]\n[[Category:Integrated development environments]]"
    },
    {
      "title": "ROSE (compiler framework)",
      "url": "https://en.wikipedia.org/wiki/ROSE_%28compiler_framework%29",
      "text": "{{more citations|date=May 2018}}\n{{Infobox software\n| name                   = ROSE\n| title                  = ROSE\n| logo                   = \n| screenshot             = \n| caption                = \n| collapsible            = \n| author                 = Daniel J. Quinlan, Chunhua (Leo) Liao, Justin Too, Robb P. Matzke, Markus Schordan, et al.\n| developer              = [[Lawrence Livermore National Laboratory]]\n| released               = <!-- {{Start date|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = \n| latest release date    = \n| latest preview version = 0.9.6a\n| latest preview date    = {{Start date and age|2016|03|16|df=yes}}\n| programming language   = [[C++]]\n| operating system       = [[Linux]], [[OS X]]\n| platform               = [[IA-32]], [[x86-64]]\n| size                   = \n| language               = English\n| status                 = \n| genre                  = [[Compiler]]\n| license                = [[BSD licenses|BSD]] modified\n| website                = {{URL|rosecompiler.org}}\n}}\n\nThe '''ROSE''' compiler framework, developed at [[Lawrence Livermore National Laboratory]] (LLNL), is an [[open-source software]] [[compiler]] infrastructure to generate [[Source-to-source compiler|source-to-source]] analyzers and [[Translator (computing)|translators]] for multiple source languages including [[C (programming language)|C]] (C89, C98, [[Unified Parallel C]] (UPC)), [[C++]] (C++98, C++11), [[Fortran]] (77, 95, 2003), [[OpenMP]], [[Java (programming language)|Java]], [[Python (programming language)|Python]], and [[PHP]].\n\nIt also supports certain binary files, and [[Automatic parallelization|auto-parallelizing]] compilers by generating source code annotated with OpenMP directives. Unlike most other research compilers, ROSE is aimed at enabling non-experts to leverage compiler technologies to build their own custom software analyzers and optimizers.\n\n==The infrastructure==\nROSE consists of multiple front-ends, a midend operating on its internal [[intermediate representation]] (IR), and backends regenerating (unparse) source code from IR. Optionally, vendor compilers can be used to compile the unparsed source code into final executables.\n\nTo parse C and C++ applications, ROSE uses the Edison Design Group's C++ front-end.<ref>{{cite web|url=http://www.edg.com/index.php?location=c_frontend|title=Edison Design Group's C++ front-end|website=Edg.com}}</ref><ref> {{webarchive|url=https://web.archive.org/web/20081224123854/http://www.edg.com/index.php?location=c_frontend|date=2008-12-24}}</ref> Fortran support, including F2003 and earlier 1977, 1990, and 1995 versions, is based on the Open Fortran Parser (OFP) developed at [[Los Alamos National Laboratory]].<ref>{{cite web|website=Fortran-parser.sourceforge.net|url=http://fortran-parser.sourceforge.net/|title=Open Fortran Parser (OFP)}}</ref>\n\nThe ROSE IR consists of an [[abstract syntax tree]], symbol tables, control flow graph, etc. It is an [[object-oriented]] IR with several levels of interfaces for quickly building source-to-source translators. All information from the input source code is carefully preserved in the ROSE IR, including C preprocessor control structure, source comments, source position information, and [[C++ template]] information, e.g., template arguments.\n\nROSE is released under a [[BSD licenses|BSD-style license]]. It targets [[Linux]] and [[OS X]] on both [[IA-32]] and [[x86-64]] platforms. Its [[Edison Design Group]] (EDG) parts are [[proprietary software|proprietary]] and distributed in binary form. Source files of the EDG parts can be obtained if users have a commercial or research license from EDG.\n\n==Award==\nThe ROSE compiler infrastructure received one of the 2009 R&D 100 Awards.<ref>{{cite web |url=http://www.rdmag.com/award-winners/2009/07/free-compiler-aids-novices-experts |title=Free compiler aids novices, experts |date=30 July 2009 |website=R&D Magazine |publisher=Advantage Business Media |access-date=18 March 2016}}</ref> The R&D 100 Awards are presented annually by ''R&D Magazine'' to recognize the 100 most significant proven [[research and development]] advances introduced over the past year. An independent expert panel selects the winners.\n\n==See also==\n* [[DMS Software Reengineering Toolkit]]{{snd}} a source-to-source compiler framework using explicit pattern-directed rewrite rules that handles Fortran and C++\n\n==References==\n{{Reflist}}\n\n==External links==\n{{Wikibooks|ROSE Compiler Framework}}\n* {{Official website|www.rosecompiler.org}}\n* [https://web.archive.org/web/20110823215903/https://outreach.scidac.gov/projects/rose/ Development site]\n* {{github|rose-compiler/rose}}\n\n{{Lawrence Livermore National Laboratory|state=autocollapse}}\n{{FOSS}}\n\n[[Category:Compilers]]\n[[Category:C compilers]]\n[[Category:C++ compilers]]\n[[Category:Fortran compilers]]\n[[Category:Free compilers and interpreters]]\n[[Category:Lawrence Livermore National Laboratory]]\n[[Category:Source-to-source compilers]]\n[[Category:Software using the BSD license]]"
    },
    {
      "title": "Silverfrost FTN95",
      "url": "https://en.wikipedia.org/wiki/Silverfrost_FTN95",
      "text": "{{More citations needed|date=June 2016}}\n\n{{Infobox software\n| name                   = Silverfrost FTN95: Fortran for Windows\n| logo                   = Silverfrost ftn95.jpg\n| developer              = Silverfrost\n| genre                  = [[Compiler]]\n| license                = [[Proprietary software|Proprietary]]\n| website                = {{URL|https://www.silverfrost.com/}}\n| latest_release_version = 8.50\n| latest_release_date    = {{release date|2019|05|01}}\n| operating_system       = [[Microsoft Windows]]\n}}\n'''Silverfrost FTN95: Fortran for Windows''' is a [[Fortran]] [[compiler]] for [[Microsoft Windows]]. It generates code for native [[IA-32]] [[Win32]], [[x86-64]]   and for Microsoft's [[.NET Framework|.NET platform]]. FTN95 comes in three licensed editions: Commercial, Academic and Personal. The Personal edition is free and is designed for personal use. Programs written with the Personal edition show a banner for a short time when they are run.\n\n==CHECKMATE==\nFTN95, like its predecessor FTN77, has strong run-time checking options, collectively called CHECKMATE. Compiler switches can turn on various levels of run-time checking. These include array bound checks, constant modification, DO LOOP modification, argument checking and undefined variable use. Program run-times are increased when checking is used.<ref>{{Cite web|url=http://www.silverfrost.com/15/ftn95/checkmate_worlds_best_runtime_checking.aspx|title=CHECKMATE: The World's Best Runtime Checking|last=Silverfrost|website=www.silverfrost.com|access-date=2016-06-04}}</ref>\n\n==ClearWin+==\nClearWin+ is a library built into the FTN95 run-time system. It offers an easy to use interface to the Windows [[API]] and is not available when producing .NET code. It makes use of a set of format codes and [[Callback (computer science)|call-backs]]. The format codes resemble [[C (programming language)|C]] style [[printf]] codes. ClearWin+ is used to power the UI for [[Simfit]]. From FTN95 version 7.00 a 64-bit version of ClearWin+ is included. This can be used with existing, free, 64-bit compilers. From version 8.00 on-wards FTN95 can compile to 32- or 64-bits.<ref>{{Cite web|url=http://www.silverfrost.com/19/ftn95/support/ftn95_revision_history.aspx|title=FTN95 Revision History|last=Silverfrost|website=www.silverfrost.com|access-date=2016-06-04}}</ref>\n\nA simple ClearWin+ program:\n<source lang=\"fortran\">\n\n    INTEGER i,winio@\n    EXTERNAL func\n    i=winio@('Press this to see what happens &')\n    i=winio@('%^bt[PRESS]',func)\n    END\n\nc---Function to do something---\n    INTEGER function func()\n    func=1\n    END\n</source>\n\n==Visual Studio==\nFTN95 was the first Fortran compiler capable of producing code for Microsoft .NET. In addition plug-ins are available that allows FTN95 programs to be written, compiled and debugged inside [[Visual Studio]]. The plug-ins fully support Win32 and .NET code generation. The current release has plug-ins for [[Microsoft Visual Studio|Visual Studio]] 2008, 2010, 2012, 2013 and 2015. The FTN95 plug-ins can be installed into [[Microsoft Visual Studio#Community|Visual Studio Community Edition]].\n\n==Plato==\nPlato is the [[Integrated Development Environment]] supplied with FTN95. It can edit, compile and debug programs in a manner similar to the Visual Studio plug-ins. Although Plato specialises in Fortran it is not limited to it and can be tuned to work with any compiler. It is designed to stand-alone from FTN95.\n\n==Salford Fortran==\nFTN95 was developed by Salford Software Limited, a company owned by [[University of Salford]], and is the successor to their Fortran 77 compiler FTN77. In August 2004 Salford Software relinquished control of FTN95 to Silverfrost Limited. Silverfrost FTN95 is often referred to as Salford FTN95 because of its University of Salford pedigree.\n\n==References==\n{{Reflist}}\n\n[[Category:Fortran compilers]]\n[[Category:Programming tools for Windows]]"
    },
    {
      "title": "VisualAge",
      "url": "https://en.wikipedia.org/wiki/VisualAge",
      "text": "{{ Infobox Software\n| name                   = VisualAge\n| logo                   = \n| screenshot             = \n| caption                = \n| collapsible            = \n| developer              = [[IBM]]\n| discontinued           = yes\n| released               = {{start date and age|1993|10|12}}\n| latest_release_version = 6.0\n| latest_release_date    = {{Start date and age|2007|04|30}}\n| latest_preview_version = \n| latest_preview_date    = \n| status                 = Discontinued\n| operating_system       = [[Cross-platform]]\n| language               = Multilingual\n| programming_language   = [[Smalltalk]] and later [[Java (programming language)|Java]]\n| genre                  = [[Software development]]\n| license                = [[Proprietary software|Proprietary]]\n| website                = {{URL|web.archive.org/web/20110915104218/http://www-01.ibm.com/software/awdtools/vacpp|www-01.ibm.com/software/awdtools/vacpp}}\n}}\n\n'''VisualAge''' is a family of computer [[integrated development environment]]s from [[IBM]], which supports multiple [[programming languages]]. VisualAge was first released in October 1993 and was discontinued April 30, 2007 and its web page removed in September 2011.<ref name=\"FirstVisualAge\">{{cite press release|title=VisualAge for OS/2, Version 1.0 |url=http://www-01.ibm.com/common/ssi/rep_ca/5/877/ENUSZP93-0585/ |author=<!--Staff writer(s); no by-line.-->|publisher=IBM|id=ENUSZP93-0585|date=October 12, 1993 |accessdate=March 12, 2018}}</ref><ref>{{citation|title=Software withdrawal: Selected IBM C, VisualAge C++, and XL Fortran programs |url=http://www.ibm.com/common/ssi/rep_ca/0/897/ENUS905-270/ENUS905-270.PDF |publisher=IBM|id=ENUS905-270|date=December 13, 2005 |accessdate=March 12, 2018}}</ref> VisualAge was also marketed as VisualAge Smalltalk. IBM has stated that [[IBM XL C++|XL C/C++]] is the followup product to VisualAge.<ref>{{Cite web|url=http://www-01.ibm.com/software/awdtools/vacpp |title=VisualAge C++|publisher=IBM|accessdate=January 26, 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20110915104218/http://www-01.ibm.com/software/awdtools/vacpp|archivedate=September 15, 2011}}</ref>\n\n==Early history==\nVisualAge was born in the IBM development lab in [[Cary, North Carolina]], which was established in 1984 and had responsibility for application [[Programming tool|development tools]]. The EZ-VU dialog manager product, a personal computer derivative of the user interface elements of the [[ISPF]] [[IBM 3270|327x]] product was one of the first products in this family. The lab also had a group which was one of the early adopters of [[object-oriented programming]] technologies within IBM using an internally developed language called ClassC to develop applications with more sophisticated [[graphical user interface]]s which were just starting to be widely available.\n\nEventually, the availability of usable implementations of [[Smalltalk]] for [[IBM PC]]-AT class machines allowed IBM advanced technology projects to experiment with Smalltalk. At about the same time, visual interface construction tools were coming up on the radar screens. Smalltalk research projects such as InterCons by David N. Smith of IBM, and [[Fabrik (software)|Fabrik]] by a team at Apple led by [[Dan Ingalls]] were building interactive graphical applications built from composition of graphical primitives. Higher level construction of user interfaces was evidenced by other tools such as [[Jean-Marie Hullot]]'s interface builder first done in [[Lisp (programming language)|Lisp]] and then evolved to become the [[Interface Builder]] tool in [[NeXTStep]] and [[Mac OS X]]. Such tools allow for building user interfaces by [[WYSIWYG]] composition of UI widgets which can be \"wired\" to each other and to application logic written in the system's native object oriented language, or possibly with no coding at all.\n\nThe original prototype which led to VisualAge was an attempt \"to make something like the [[Interface Builder|NeXT interface builder]]\"<ref name=\"RoundInCircles\">{{cite web|url=http://talklikeaduck.denhaven2.com/articles/2008/10/15/will-it-go-round-in-circles |title=Will It Go Round in Circles? (IBM, Smalltalk, and VisualAge) |accessdate=November 1, 2008 |deadurl=yes |archiveurl=https://web.archive.org/web/20081019055616/http://talklikeaduck.denhaven2.com/articles/2008/10/15/will-it-go-round-in-circles |archivedate=October 19, 2008}}</ref> within the [[Smalltalk/V]] development environment. By the time VisualAge was released as a product, much more emphasis was placed on visual construction of application logic as well as of the user interface. This emphasis was in part due to the \"positioning\" for \"strategic\" reasons of Smalltalk as a generator rather than a language within IBM's [[Systems Application Architecture]].\n\n===VisualAge===\nThe name \"VisualAge\" is the result of a contest between the members of the development team. After the initial release of VisualAge/Smalltalk the name VisualAge became a brand of its own and VisualAges were produced for several different combinations of languages and platforms.\n\nThese are the overall supported languages, variously available depending on the platform: [[BASIC]], [[COBOL]], [[C (programming language)|C]], [[C++]], [[EGL (programming language)|EGL]], [[Fortran]], [[Java (programming language)|Java]], [[Pacbase]], [[PL/I]], [[IBM RPG]], and [[Smalltalk]]. \n\nThese are the supported platforms, each of which support different languages: [[AIX]], [[OS/2]], [[i5/OS]] (formerly named [[OS/400]], [[Linux]], [[Mac OS X]], [[Microsoft Windows]], [[Transaction Processing Facility|TPF]], [[z/VM]], [[z/OS]] (formerly named [[OS/390]], [[MVS]]), and [[z/VSE]].\n\nMost of the members of the VisualAge family were written in Smalltalk no matter which language they supported for development. The IBM implementation of Smalltalk was produced by [[Object Technology International]] which was acquired by IBM and run as a wholly owned subsidiary for several years before being absorbed into the overall IBM organization.\n\nVisualAge for Java is based on an extended Smalltalk [[virtual machine]] which executes both Smalltalk and Java [[byte code]]s. Java natives were actually implemented in Smalltalk.<ref name=\"RoundInCircles\"/>\n\nVisualAge Micro Edition, which supports development of embedded Java applications and cross system development, is a reimplementation of the IDE in Java. This version of VisualAge morphed into the [[Eclipse (computing)|Eclipse Framework]].\n\nVarious members of the family have been replaced by products in the [[WebSphere]] Studio family of products. {{As of|2009}}, the original VisualAge product continues to be promoted by IBM as “VisualAge Smalltalk”.<ref>{{cite web|title=Product Overview |url=http://www.ibm.com/software/ad/smalltalk/|publisher=IBM|accessdate=May 19, 2009}}</ref>  In 2005, Smalltalk specialist Instantiations, Inc.<ref>{{cite web|title=VisualAge Smalltalk Transition FAQ |url=http://www.instantiations.com/company/ibm-transition.html |publisher=Instantiations |accessdate=March 12, 2018}}</ref> acquired a worldwide license to VisualAge Smalltalk, and offers an “enhanced product” VA Smalltalk.<ref>{{cite web|url=http://www.instantiations.com/products/vasmalltalk/index.html |title=Smalltalk Products Home |publisher=Instantiations|accessdate=May 19, 2009}}</ref><ref>{{cite web|url=http://www.instantiations.com/company/history.html |title=Instantiations History |publisher=Instantiations|accessdate=May 19, 2009}}</ref> The C, C++ and Fortran compiler on AIX, Linux and z/OS are renamed as [[IBM XL C++|XL C/C++]] series.\n\n==Releases==\nApplications designed with VisualAge C++ may be portable between target platforms without any code changes needed if VisualAge guidelines were followed. IBM also included additional tools and libraries in instances where portability was not possible without code changes.<ref>{{cite web|title=VisualAge C++ |url=http://www.edm2.com/index.php/VisualAge_C%2B%2B |publisher=EDM/2|accessdate=March 12, 2018}}</ref>\n\n===OS/2 and Windows===\n*VisualAge C++ 3.0 (OS/2 and Windows)\n*VisualAge C++ 3.5 (Windows 95/NT only)\n*C and C++ Compilers for OS/2, AIX and Windows NT Version 3.6\n*VisualAge C++ Professional 4.0 (OS/2 and Windows)\n*VisualAge Generator Developer V3.1 for OS/2\n*VisualAge Generator Server V3.1 for OS/2<ref>{{cite press release|title=IBM VisualAge Generator for OS/2 and Windows NT Version 3.1 Boosts Application Development Productivity |url=http://www-01.ibm.com/common/ssi/rep_ca/0/897/ENUS298-190/ |author=<!--Staff writer(s); no by-line.-->|publisher=IBM|date=June 16, 1998 |id=ENUS298-190 |access-date=March 12, 2018 |deadurl=no |archiveurl=https://www-01.ibm.com/common/ssi/cgi-bin/ssialias?htmlfid=897/ENUS298-190&infotype=AN&subtype=CA&appname=skmwww |archivedate=March 12, 2018}}</ref>\n*VisualAge for OS/2 1.0 (1993-10-12)<ref name=\"FirstVisualAge\"/>\n*VisualAge COBOL for OS/2 1.0 (1994-03-29)<ref>{{cite press release|title=VisualAge for OS/2, Version 1.0 |url=http://www-01.ibm.com/common/ssi/rep_ca/2/877/ENUSZP94-0232/ |author=<!--Staff writer(s); no by-line.-->|publisher=IBM|id=ENUSZP94-0232|date=March 29, 1994 |accessdate=March 12, 2018}}</ref>\n*VisualAge for COBOL for OS/2 1.1\n*VisualAge for COBOL for OS/2 1.2\n*VisualAge for COBOL for OS/2, Version 1 Release 2\n*VisualAge COBOL for OS/2 2.0\n*VisualAge for COBOL Version 2.1\n*VisualAge COBOL 2.2 \n*VisualAge COBOL Enterprise 3.07 (Windows only)\n\n===OS/400===\n*VisualAge C++ for AS/400 V3R6\n*VisualAge C++ for AS/400 V3R7\n*VisualAge C++ for AS/400 V4R4\n\n===AIX===\n*VisualAge C++ Professional for AIX\n*VisualAge C++ Professional for AIX, V5.0\n*VisualAge C++ Professional for AIX, V6.0\n\n===POWER Linux===\n*VisualAge C++ V6.0 for Linux\n*VisualAge C++ V6.0 for Linux refresh\n\n==See also==\n* [[IBM Cross System Product (CSP)]]: an article which discusses IBM VisualAge Generator\n* [[Source Code in Database]]\n\n==References==\n===Citations===\n{{reflist}}\n\n===Bibliography===\n{{refbegin}}\nVisualAge - Smalltalk\n\n*   IBM Corp., IBM, (1994). “IBM VisualAge (printed paper bound retail hardboard box)”. . IBM Corp. Part Number 14H0969 and lid Part Number 30H2314 Product Number 17H7495 Bar code: 087944096085\n*   IBM Corp., IBM, (Spring 1995). “Smalltalk resource catalogue”. . IBM Corp. (96 pages) Product Number G325-0813-01 Part Number 30H2238\n*   IBM Corp., IBM, (October 1994). “Development guide”. 1st edition. (250 pages) Product Number SC34-4495-00 Part Number 14H0295\n*   IBM Corp., IBM, (October 1994). “Programmer’s reference”. 2nd edition. IBM Corp. (458 pages) Product Number SC34-4493-01 Part Number 14H0297\n*   IBM Corp., IBM, (October 1994). “IBM Smalltalk”. 2nd edition. IBM Corp. (172 pages) Product Number SC34-4491-01 Part Number 14H0296\n*   IBM Corp., IBM, (October 1994). “Installation guide booklet”. 2nd edition. IBM Corp. (48 pages) Part Number 14H1071\n*   IBM Corp., IBM, (October 1994). “Programmer’s guide to building”. 2nd edition. IBM Corp. (149 pages) Product Number SC34-4496-00 Part Number 14H1070\n*   IBM Corp., IBM, (October 1994). “User’s Guide and Reference”. 2nd edition. IBM Corp. (642 pages) Product Number SC34-4490-01 Part Number 14H0922;\n\nIBM VisualAge for COBOL Standard is “Year 2000 ready” and Requires: Warp Version 4.0 plus FixPak 1 or Windows NT 4.0 plus Service Pack 3\n\n*   IBM Corp., IBM, (1997). “IBM VisualAge for COBOL Standard (printed retail card box)”. Version 2.1. IBM Corp.  Product Number P4301938 Bar Code: 1264301938000104 Part Number 4301978\n*   IBM Corp., IBM, (1997). “IBM VisualAge for COBOL Getting Started on Windows Manual”. IBM Corp. (130 pages) Product number GC26-8944-01 Bar Code: GC26-8944-01 Part No. 4301981\n*   IBM Corp., IBM, (September 1997). “IBM VisualAge for COBOL Getting Started on OS/2 Manual”. IBM Corp. 2nd Edition. (156 pages) Document Number GC26-9051-01\n*   IBM Corp., IBM, (April 1997). “Resource Catalogue for IBM COBOL Family V 1”.  Release 4. (44 pages) Product Number GC26-8488-03 Part Number 4226010\n{{refend}}\n\n==External links==\n*{{Official website}}\n*[https://web.archive.org/web/20041205025652/http://www-306.ibm.com:80/software/awdtools/vaes/ VisualAge Enterprise Suite]\n*[http://www.edm2.com/index.php/VisualAge_C%2B%2B VisualAge C++] description from Electronic Developer Magazine for OS/2 (EDM/2)\n*[http://c2.com/cgi/wiki?VisualAge Visual Age] description from Portland Pattern Repository\n*[http://www.instantiations.com/products/vasmalltalk/index.html VA Smalltalk at Instantiations]\n*[http://www.javadude.com/vaj/ VisualAge for Java Tips and Tricks]\n\n{{Smalltalk programming language}}\n{{Integrated development environments}}\n\n[[Category:C compilers|VisualAge]]\n[[Category:C++ compilers|VisualAge]]\n[[Category:Compilers|VisualAge]]\n[[Category:Eclipse (software)|VisualAge]]\n[[Category:Fortran compilers|VisualAge]]\n[[Category:IBM software|VisualAge]]\n[[Category:Integrated development environments|VisualAge]]\n[[Category:Linux integrated development environments|VisualAge]]\n[[Category:MacOS programming tools|VisualAge]]\n[[Category:OS/2 software|VisualAge]]\n[[Category:Programming tools for Windows|VisualAge]]\n[[Category:Smalltalk programming language family]]"
    },
    {
      "title": "ALTRAN",
      "url": "https://en.wikipedia.org/wiki/ALTRAN",
      "text": "{{About|the FORTRAN extension|Altran Technologies, a consulting firm|Altran}}\n\n'''ALTRAN''' was a [[FORTRAN]] extension providing [[rational algebra]], developed by W.S. Brown, at [[Bell Labs]] around 1968.\n\n==References==\n\n* W.S. Brown, \"A language and system for symbolic algebra on a digital computer\", SYMSAC '66 Proceedings of the first ACM symposium on Symbolic and algebraic manipulation, p. 501- 540, January 1966.\n* W.S. Brown, ALTRAN User's Manual (2nd ed.), Bell Laboratories, Murray Hill, N.J., 1972.\n* Stuart I. Feldman, \"A brief description of Altran\", ACM SIGSAM Bulletin, Volume 9 Issue 4, November 1975, p. 12 - 20.\n* A.D. Hall and S.C. Johnson, \"ALTRAN programs for SIGSAM problem #6\", ACM SIGSAM Bulletin, Volume 8 Issue 2, May 1974, p. 12 - 36.\n* A.D. Hall, \"The ALTRAN System for Rational Function Manipulation — A Survey\".  ''[[Communications of the ACM]]'', 14(8):517–521 (August 1971).\n* Mansour Farah, \"A FORMAL DESCRIPTION OF ALTRAN USING LINKED FOREST MANIPULATION SYSTEMS\", Technical Report CS-73-08, University of Waterloo, April, 1973.\n\n{{Computer algebra systems}}\n\n[[Category:Computer-related introductions in 1968]]\n[[Category:Fortran programming language family]]\n[[Category:Computer algebra systems]]"
    },
    {
      "title": "Coarray Fortran",
      "url": "https://en.wikipedia.org/wiki/Coarray_Fortran",
      "text": "{{More footnotes|date=August 2011}}\n{{Infobox programming language\n| name =Coarray Fortran\n| logo =\n| paradigm = [[multi-paradigm programming language|multi-paradigm]]: [[parallel programming|parallel]], [[message passing]],  [[imperative programming|imperative]] ([[procedural programming|procedural]], [[Object-oriented programming|object-oriented]]), [[structured programming|structured]]\n| year =\n| designer = Robert Numrich and John Reid\n| developer = PL22.3 Fortran Committee\n| latest_release_version = [[Fortran]] 2008 (ISO/IEC 1539-1:2010)\n| latest release date =\n| typing = [[strongly typed programming language|strong]], [[Type system|static]]\n| implementations = Cray, [[g95]], [[GNU Fortran]], [[Intel Fortran Compiler]], [http://caf.rice.edu/ Rice (CAF 2.0)],  [http://web.cs.uh.edu/~openuh/ OpenUH]\n| dialects =\n| influenced_by =[[Fortran]]\n| influenced =\n| operating_system = [[Cross-platform]]\n| website =\n| file_ext =\n}}\n'''Coarray Fortran''' ('''CAF'''), formerly known as '''F--''', started as an extension of [[Fortran]] 95/2003 for [[Parallel computing|parallel processing]] created by Robert Numrich and John Reid in the 1990s. The [[Fortran 2008]] standard (ISO/IEC 1539-1:2010) now includes [[coarray]]s (spelled without hyphen), as decided at the May 2005 meeting of the ISO Fortran Committee; the syntax in the Fortran 2008 standard is slightly different from the original CAF proposal.\n\nA CAF [[computer program|program]] is interpreted as if it were replicated a number of times and all copies were executed asynchronously. Each copy has its own set of data objects and is termed an ''image''. The [[array data structure|array]] syntax of Fortran is extended with additional trailing subscripts in square brackets to provide a concise representation of references to data that is spread across images.\n\nThe CAF extension was implemented in some Fortran [[compiler]]s such as those from [[Cray]] (since release 3.1). Since the inclusion of coarrays in the Fortran 2008 standard, the number of implementations is growing. The first [[open-source software|open-source]] compiler which implemented coarrays as specified in the Fortran 2008 standard for [[Linux architecture]]s is [[G95]]. Currently, [[GNU Fortran]] provides wide coverage of Fortran's coarray features in single- and multi-image configuration (the latter based on the OpenCoarrays library). Another implementation of coarrays and related parallel extensions from Fortran 2008 is available in the OpenUH compiler (a branch of [[Open64]]) developed at the [[University of Houston]].\n\n==Implementation in compilers==\nCAF is often implemented on top of a [[Message Passing Interface]] (MPI) library for portability. Some implementations, such as the ones available in the [[GNU Fortran]] and OpenUH compilers, may run on top of other low-level layers (for example, GASNet) designed for supporting [[partitioned global address space]] languages.\n\n==Examples==\nA simple example is given below. CAF is used in CGPACK, an open source package for simulating polycrystalline materials developed at the [[University of Bristol]].\n<ref>A. Shterenlikht, ''[http://www.pgas2013.org.uk/sites/default/files/finalpapers/Day2/R4/1_paper2.pdf Fortran coarray library for 3D cellular automata microstructure simulation]'', (2013) In Proc. 7th PGAS conf, Eds. M. Weiland, A. Jackson, N. Johnson, Published by The University of Edinburgh, {{ISBN|978-0-9926615-0-2}}</ref><ref>{{Cite journal|title = Fortran 2008 Coarrays|url = https://www.researchgate.net/publication/274608238_Fortran_2008_coarrays|journal = ACM SIGPLAN Fortran Forum|date = 2015-04-01|issn = 1061-7264|pages = 10–30|volume = 34|issue = 1|doi = 10.1145/2754942.2754944|first = Anton|last = Shterenlikht|first2 = Lee|last2 = Margetts|first3 = Luis|last3 = Cebamanos|first4 = David|last4 = Henty}}</ref><ref>{{Cite journal|title = Three-dimensional cellular automata modelling of cleavage propagation across crystal boundaries in polycrystalline microstructures|url = https://www.researchgate.net/publication/274372591_Three-dimensional_cellular_automata_modelling_of_cleavage_propagation_across_crystal_boundaries_in_polycrystalline_microstructures|journal = Proc. R. Soc. A|date = 2015-05-08|issn = 1364-5021|pages = 20150039|volume = 471|issue = 2177|doi = 10.1098/rspa.2015.0039|first = A.|last = Shterenlikht|first2 = L.|last2 = Margetts}}</ref>\n<source lang=\"fortran\">\nprogram Hello_World\n  implicit none\n  integer :: i  ! Local variable\n  character(len=20) :: name[*] ! scalar coarray, one \"name\" for each image.\n  ! Note: \"name\" is the local variable while \"name[<index>]\" accesses the\n  ! variable in a specific image; \"name[this_image()]\" is the same as \"name\".\n\n  ! Interact with the user on Image 1; execution for all others pass by.\n  if (this_image() == 1) then   \n    write(*,'(a)',advance='no') 'Enter your name: '\n    read(*,'(a)') name\n\n    ! Distribute information to other images\n    do i = 2, num_images()\n      name[i] = name\n    end do\n  end if\n\n  sync all ! Barrier to make sure the data have arrived.\n\n  ! I/O from all images, executing in any order, but each record written is intact. \n  write(*,'(3a,i0)') 'Hello ',trim(name),' from image ', this_image()\nend program Hello_world\n</source>\n\nThe program above scales poorly because the loop that distributes information executes sequentially.  Writing scalable programs often requires a sophisticated understanding of parallel algorithms, a detailed knowledge of the underlying network characteristics, and special tuning for application characteristics such as the size of data transfers.  For most application developers, letting the compiler or runtime library decide the best algorithm proves more robust and high-performing.  Fortran 2018 will offer collective communication subroutines that empower compiler and runtime library teams to encapsulate efficient parallel algorithms for collective communication and distributed computation in a set of collective subroutines.  These subroutines and other new parallel  programming features are summarized in a technical specification <ref>TS 18508 Additional Parallel Features in Fortran</ref> that the Fortran standards committee has voted to incorporate into Fortran 2018.  These enable the user to write a more efficient version of the above algorithm\n\n<source lang=\"fortran\">\nprogram Hello_World\n  implicit none\n  character(len=20) :: name[*] ! scalar coarray, one \"name\" for each image.\n  ! Note: \"name\" is the local variable while \"name[<index>]\" accesses the\n  ! variable in a specific image; \"name[this_image()]\" is the same as \"name\".\n\n  ! Interact with the user on Image 1; execution for all others pass by.\n  if (this_image() == 1) then   \n    write(*,'(a)',advance='no') 'Enter your name: '\n    read(*,'(a)') name\n  end if\n  ! Distribute information to all images\n  call co_broadcast(name,source_image=1)\n\n  ! I/O from all images, executing in any order, but each record written is intact. \n  write(*,'(3a,i0)') 'Hello ',trim(name),' from image ', this_image()\nend program Hello_world\n</source>\n\nwhere the lack of explicit synchronization offers the potential for higher performance due to less coordination between the images.  Furthermore, TS 18508 guarantees that  \"A transfer from an image cannot occur before the collective subroutine has been invoked on that image.\"  This implies some partial synchronization inside co_broadcast, but could be higher performing than the \"sync all\" in the prior example.  TS 18508 also incorporates several other new features that address issues targeted by the CAF 2.0 effort described below.  Examples include teams of images and events.\n\n==An alternate perspective==\n{{bias|section|date=September 2018}}\nIn 2011, [[Rice University]] pursued an alternate vision of coarray extensions for the Fortran language.<ref>{{cite web|title=CoArray Fortran 2.0|url=http://caf.rice.edu/}}</ref> Their perspective is that the Fortran 2008 standard committee's design choices were shaped more by the desire to introduce as few modifications to the language as possible than to assemble the best set of extensions to support [[parallel programming]]. In their view, both Numrich and Reid's original design and the coarray extensions proposed for Fortran 2008 suffer from the following shortcomings:\n\n* There is no support for [[Central processing unit|processor]] subsets; for instance, coarrays must be allocated over all images.\n* The coarray extensions lack any notion of global pointers, which are essential for creating and manipulating any kind of linked data structure.\n* Reliance on named critical sections for [[mutual exclusion]] hinders scalable parallelism by associating mutual exclusion with code regions rather than data objects.\n* Fortran 2008's sync images statement does not provide a safe synchronization space. As a result, synchronization operations in user's code that are pending when a library call is made can interfere with synchronization in the library call.\n* There are no mechanisms to avoid or tolerate latency when manipulating data on remote images.\n* There is no support for collective communication.\n\nTo address these shortcomings, the Rice University group is developing a clean-slate redesign of the Coarray Fortran programming model. Rice's new design for Coarray Fortran, which they call Coarray Fortran 2.0, is an expressive set of coarray-based extensions to Fortran designed to provide a productive parallel programming model. Compared to Fortran 2008, Rice's new coarray-based language extensions include some additional features:\n\n* process subsets known as teams, which support coarrays, collective communication, and relative indexing of process images for pair-wise operations,\n* topologies, which augment teams with a logical communication structure,\n* dynamic allocation/deallocation of coarrays and other shared data,\n* team-based coarray allocation and deallocation,\n* global pointers in support of dynamic data structures,\n* support for latency hiding and avoidance, and\n** asynchronous copies,\n** asynchronous collective operations, and\n** function shipping.\n* enhanced support for synchronization for fine-grain control over program execution.\n** safe and scalable support for mutual exclusion, including locks and lock sets,\n** events, which provide a safe space for point-to-point synchronization,\n** cofence, which forces local completion of asynchronous operations,\n** finish, a barrier-like SPMD construct that forces completion of asynchronous operations across a team,\n\n==See also==\n* [[Array programming]]\n* [[Chapel (programming language)|Chapel]]\n* [[Fortress (programming language)|Fortress]]\n* [[Parallel computing]]\n* [[Partitioned global address space]]\n* [[Unified Parallel C]]\n* [[X10 (programming language)|X10]]\n\n==References==\n{{Reflist}}\n\n===General===\n* [http://www.co-array.org Co-Array Fortran homepage  (Not working anymore)]\n* [http://www.nag.co.uk/sc22wg5/ ISO Fortran Committee]\n* [http://j3-fortran.org ANSI/INCITS Fortran Committee]\n* [http://www.nd.edu/~dbalsara/Numerical-PDE-Course Instructional videos on CAF in the Fortran Standard by John Reid (see Appendix B)]\n* [https://gcc.gnu.org/wiki/Coarray Coarray in GNU Fortran]\n* [https://gcc.gnu.org/wiki/CoarrayLib CoarrayLib in GNU Fortran] \n* [http://opencoarrays.org OpenCoarrays library]\n\n[[Category:Fortran programming language family]]"
    },
    {
      "title": "DAP FORTRAN",
      "url": "https://en.wikipedia.org/wiki/DAP_FORTRAN",
      "text": "'''DAP FORTRAN''' was an extension of the non IO parts of [[FORTRAN]] with constructs that supported [[parallel computing]] for the\n[[ICL Distributed Array Processor]] (DAP). The DAP had a [[Single Instruction Multiple Data]] (SIMD) architecture with 64x64 single bit processors.\n\nDAP FORTRAN had the following major features:\n\n* It had matrix and vector operations.\n* Assignments could be performed under a logical mask so only some elements in the target of an assignment were changed.\n* On the negative side - operations were performed using the size of the underlying hardware i.e. on a 64x64 matrix or 64 element vector.\n\nIn a declaration either one or two extents could be omitted as in:\n\n<source lang=\"fortranfixed\">\nC     Multiply vector by matrix\n      REAL M(,), V(), R()\n      R = SUM(M*MATR(A))\n\nC     Converge to a Laplace potential in an area\n      REAL P(,), OLD_P(,)\n      LOGICAL INSIDE(,)\n      DO 1 K = 1, ITERATIONS\n      OLD_P = P\n      P(INSIDE) = 0.25*(P(,+)+P(,-)+P(+,)+P(-,))\n      IF (MAX(ABS(P-OLD_P)) .LT. EPS) RETURN\n    1 CONTINUE\n</source>\n\nThe omitted dimension was taken as 64, the size of one side of the DAP. The speed of arithmetic operations depended strongly on the number of bits in the value. INTEGER*n reserved 8n bits where n is 1 to 8, and REAL*n reserved 8n bits where n is 3 to 8. LOGICAL reserved a single bit.\n\nHowever, DAP FORTRAN fell between two conflicting objectives. It needed to effectively exploit the DAP facilities. But also had to be accessible to the scientific computing community whose primary language, with a design closely tied to serial architectures, was FORTRAN. The dialect used was ICL's 2900-series FORTRAN which was based on an early version of the [[FORTRAN 77]] standard and had mismatches with both FORTRAN 77 and the older [[FORTRAN 66]] standard.\n\nDAP FORTRAN was significantly different from either standard FORTRAN and the machine was not capable of accepting or optimising standard FORTRAN programs. On the other hand, compared with other contemporary languages which were by design extensible (notably [[ALGOL-68]]), FORTRAN was less than well suited to this task. The result was noticeably inelegant and did require a great deal of new learning. Operationally, there was an overhead to transfer computational data into and out of the array, and problems which did not fit the 64x64 matrix imposed additional complexity to handle the boundaries (65x65 was perhaps the worst case!) &ndash; but for problems which suited the architecture, it could outperform the current [[Cray]] pipeline architectures by two orders of magnitude.\n\nA later version of the DAP used [[Fortran-Plus]] instead which was based on\n[[FORTRAN 77]] and had more flexible indexing. In particular it automatically mapped user sized arrays onto the underlying hardware.\n\n==External links==\n* [http://www.hpjava.org/talks/beijing/hpf/introduction/node5.html ICL DAP Fortran]\n* {{cite book |title=Massively parallel computing with the DAP |author1=Dennis Parkinson |author2=John Litt |publisher=Pitman |year=1990 |series=Research monographs in parallel and distributed computing |isbn=978-0-273-08809-7}}\n\n[[Category:Concurrent programming languages]]\n[[Category:Fortran programming language family]]\n[[Category:SIMD computing| ]]\n[[Category:ICL programming languages]]"
    },
    {
      "title": "EFL (programming language)",
      "url": "https://en.wikipedia.org/wiki/EFL_%28programming_language%29",
      "text": "'''EFL''' is a programming language originated by programmer A.D. Hall in the late 1970s and completed by [[Stuart Feldman]]. It was intended to improve on [[Fortran]] by adding control structures similar to those of [[C (programming language)|C]] and was implemented as a preprocessor to a Fortran compiler. Its name is an initialism for ''Extended Fortran Language''. It is roughly a superset of [[Ratfor]].\n\n==References==\n*Feldman, S.I. (1979) The programming language EFL. Proceedings of the SIGNUM Conference on the Programming Environment for Development of Numerical Software. pp.&nbsp;76–79.\n*Feldman, S.I. The Programming Language EFL. [http://stuff.mit.edu/afs/sipb/user/daveg/Info/Links/doc/unix.manual.progsupp2/06.efl/efl.PS]\n\n{{DEFAULTSORT:Efl (Programming Language)}}\n[[Category:Fortran programming language family]]"
    },
    {
      "title": "F (programming language)",
      "url": "https://en.wikipedia.org/wiki/F_%28programming_language%29",
      "text": "{{distinguish|F Sharp (programming language)|F* (programming language)}}\n{{Infobox programming language\n| name                   = F language\n| developer              = [[The Fortran Company]]\n| paradigm               = [[procedural programming|procedural]], [[modular programming|modular]]\n| typing                 = [[Type system|static]], [[Manifest typing|manifest]]\n| influenced_by          = [[Fortran 95]]\n}}\n'''F''' is a [[modular programming|modular]], compiled, numeric programming language, designed for [[computational science|scientific programming]] and scientific computation.<ref name=\"js\">{{cite web | url = http://www.fortran.com/F/about_f.html | title = All About F  | author = The Fortran Company | accessdate = 2014-04-28}}</ref> F was developed as a modern [[Fortran]], thus making it a subset of [[Fortran 95]].<ref name=\"sc\">{{cite web | url = https://www.cisl.ucar.edu/zine/96/fall/articles/2.F.language.html | title = The F Language | first = Jeanne| last = Adams | accessdate = 2014-04-28}}</ref> It combines both numerical and [[data abstraction]] features from these languages. F is also backwards compatible with [[Fortran 77]], allowing calls to [[Fortran 77]] programs. F was first included in the [[g95]] compiler.\n\n== Overview ==\nF is designed to be a minimal subset of Fortran, with only about one hundred intrinsic procedures.<ref name=\"de\">{{cite web | url = https://www.fortran.com/F/java.htm | title = The F Programming Language Tastes Like Java |author1=Walt Brainerd |author2=David Epstein |author3=Richard Hendrickson | accessdate = 2014-04-29}}</ref> Language keywords and intrinsic function names are reserved keywords in F and no other names may take this exact form. F contains the same character set used in [[Fortran 90]]/[[Fortran 95|95]] with a limit of 132 characters. Reserved words are always written in lowercase. Any uppercase letter may appear in a character constant. Variable names do not have restriction and can include upper and lowercase characters.\n\n===Operators===\nF supports many of the standard operators used in Fortran. The operators supported by F are: \n* Arithmetic operators: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>**</code>\n* Relational operators: <code><</code>, <code><=</code>, <code>==</code>, <code>/=</code>, <code>></code>, <code>>=</code> \n* Logical operators: <code>.not.</code>, <code>.and.</code>, <code>.or.</code>, <code>.eqv.</code>, <code>.neqv.</code> \n* character concatenation: <code>//</code>\n\nThe assignment operator is denoted by the equal sign <code>=</code>. In addition, pointer assignment is denoted by <code>=></code>. Comments are denoted by the <code>!</code> symbol:\n<source lang= \"fortran\">\nvariable = expression ! assignment \npointer => target ! pointer assignment\n</source>\n\n===Data types===\nSimilar to [[Fortran]], the type specification is made up of a type, a list of attributes for the declared variables, and the variable list.<ref name=\"sc\"/> F provides all the same types as Fortran as well, with the sole exception of [[double-precision floating-point format|doubles]]:\n\n<source lang = \"fortran\">\n! type [,attribute list] :: entity declaration list\nreal :: x, y ! declaring variables of type real x,y without an attribute list\ninteger (kind = long), dimension (100) :: x ! declaring variable of type big integer array with the identifier x\ncharacter (len = 100) :: student_name ! declaring a character type variable with len 100\n</source>\n\nF does not have intrinsic support for [[object-oriented programming]], but it does allow for [[record (computer science)|records]]:<ref name=\"sc\"/>\n\n<source lang =\"fortran\">\ntype, public :: City\n     character (len = 100) :: name\n     character (len = 50) :: state\nend type City\n</source>\n\nVariable declarations are followed by an attribute list. The attributes allowed are <code>parameter</code>, <code>public</code>, <code>private</code>, <code>allocatable</code>, <code>dimension</code>, <code>intent</code>, <code>optional</code>, <code>[[pointer (computer programming)|pointer]]</code>, <code>save</code> and <code>target</code>. The attribute list is followed by <code>::</code>, which is part of the syntax. F also allows for optional initialization in the list of objects. All items in a list will have the same attributes in a given type declaration statement. In addition, declarations are attribute oriented instead of entity oriented.\n\n===Statement and control flow===\nF supports 3 statements for [[control flow]]: <code>if</code>, a basic [[conditional (computer programming)|conditional]], <code>case</code>, a [[switch statement]], and <code>do</code>, a conditional [[while loop]]. The <code>return</code>, <code>stop</code>, <code>cycle</code>, and <code>exit</code> statements from Fortran may be used to break control flow.\n\n<source lang = \"fortran\">\nreal :: x\n\ndo i = 100\n   x += i\n   print i\n   cycle\nend do\n\nmax : do\n   if (x > y) then\n      exit max:\n   end if\n   x = y;\nend max\nstop\n\nif (x < y) then\n     x = x + y;\nelse if ( x > y) then\n     x = y - x;\nend if\n\nselect case (maximum):\n     case (0)\n         x = 0\n     case (1)\n         x = 1\n     case (5)\n         x = 5\n     case default \n         x = 10\nend select\n</source>\n\n\nF places a heavy emphasis on [[modular programming]]. Modules in F are called \"programs\":<ref name=\"sc\"/>\n\n<source lang = \"fortran\">\nprogram main\n    ! Insert code here\nend program main\n</source>\n\nPlacing procedures  outside of a module is prohibited. F supports most of the modules and subroutines found in the Fortran 95 standard library. All procedures in F are external by default, and require a result clause that returns the value of a function.<ref name=\"sc\"/> F supports [[recursion (computer science)|recursion]].\n\nAll of the intrinsic procedures found in Fortran 95 may be used in F, with the exceptions of <code>achar</code>, <code>iachar</code>, <code>lge</code>, <code>lgt</code>, <code>lge</code>, <code>llt</code>, <code>transfer</code>, <code>dble</code>, <code>dim</code>, <code>dprod</code>, and <code>mod</code>.\n\n== References ==\n{{reflist}}\n\n== External links ==\n* [http://www.fortran.com/F/index.html F Programming Language Homepage]\n* [http://www.g95.org/ g95 compiler]\n\n[[Category:Fortran programming language family]]"
    },
    {
      "title": "FORMAC",
      "url": "https://en.wikipedia.org/wiki/FORMAC",
      "text": "'''FORMAC''', acronym of '''FOR'''mula '''MA'''nipulation '''C'''ompiler, was an early [[computer algebra system]] based on [[FORTRAN]].  It was developed by [[Jean E. Sammet]].\n\nFORMAC supported computation, manipulation, and use of symbolic expressions.<ref name=\"sammet\">{{cite book|first=Jean E.|last=Sammet|authorlink=|coauthors= |year=1969|title=Programming Languages: History and Fundamentals|location=Englewood Cliffs, New Jersey|publisher=Prentice Hall|isbn=0-13-729988-5}}</ref>\n\n==References==\n<references/>  \n\n==Bibliography==\n\n* Jean E. Sammet, \"The beginning and development of FORMAC (FORmula MAnipulation Compiler)\", ''Proceedings of HOPL-II, The second ACM SIGPLAN conference on History of programming languages'', p. 209-230, 1993  {{ISBN|0-89791-570-4}} {{doi|10.1145/154766.155372}}\n\n==External links==\n* [https://web.archive.org/web/20060903201804/http://hopl.murdoch.edu.au/showlanguage.prx?exp=158&language=FORMAC History of Programming Languages: FORMAC]\n\n\n{{compu-lang-stub}}\n\n[[Category:Computer algebra systems]]\n[[Category:Fortran programming language family]]\n[[Category:Procedural programming languages]]\n[[Category:Programming languages created in 1962]]\n[[Category:Programming languages created by women]]"
    },
    {
      "title": "High Performance Fortran",
      "url": "https://en.wikipedia.org/wiki/High_Performance_Fortran",
      "text": "'''High Performance Fortran''' ('''HPF''') is an extension of [[Fortran|Fortran 90]] with constructs that support [[parallel computing]], published by the ''High Performance Fortran Forum'' (HPFF).  The HPFF was convened and chaired by [[Ken Kennedy (computer scientist)|Ken Kennedy]] of [[Rice University]].  The first version of the HPF Report was published in 1993.\n\nBuilding on the array syntax introduced in Fortran 90, HPF uses a [[data parallelism|data parallel]] model of computation to support spreading the work of a single [[Array data structure|array]] computation over multiple processors.  This allows efficient implementation on both [[SIMD]] and [[MIMD]] style architectures.  HPF features included:\n\n* New Fortran statements, such as <code>FORALL</code>, and the ability to create [[pure function|<code>PURE</code>]] ([[side effect (computer science)|side effect]] free) procedures\n* Compiler directives for recommended distributions of array data\n* ''Extrinsic procedure'' interface for interfacing to non-HPF parallel procedures such as those using [[message passing]]\n* Additional library routines - including environmental inquiry, parallel prefix/suffix (e.g., [[prefix sum|'scan']]), data scattering, and [[sorting]] operations\n\nFortran 95 incorporated several HPF capabilities.  In response, the HPFF again convened and published the HPF 2.0 Report.  The updated report removed material which was already covered by Fortran 95.  The report was also reorganized and revised based on experience with HPF 1.0.\n\nWhile some vendors did incorporate HPF into their compilers in the 1990s, some aspects proved difficult to implement and of questionable use.  Since then, most vendors and users have moved to [[OpenMP]]-based parallel processing.{{citation needed|date=March 2007}}  However HPF continues to have influence.  For example, the proposed <code>BIT</code> data type for the upcoming{{Update inline|?=yes|date=August 2016}} [[Fortran#Fortran 2008|Fortran-2008]] standard contains a number of new intrinsic functions taken directly from HPF.\n\n==See also==\n* [[Partitioned global address space]]\n\n==External links==\n* [http://hpff.rice.edu HPFF] - [[Rice University]] HPF Forum\n* http://wotug.org/parallel/standards/hpf\n* [ftp://ftp.fhg.de/archive/gmd/adaptor/ ADAPTOR]- An open-source HPF compilation system \n* [http://www.par.univie.ac.at/project/hpf+/ HPF+] - HPF for advanced applications\n* [http://portal.acm.org/citation.cfm?id=1238844.1238851 The rise and fall of High Performance Fortran: an historical object lesson]\n\n[[Category:Concurrent programming languages]]\n[[Category:Fortran programming language family]]"
    },
    {
      "title": "Iftran",
      "url": "https://en.wikipedia.org/wiki/Iftran",
      "text": "{{Multiple issues|\n{{no footnotes|date=October 2016}}\n{{notability|date=October 2016}}\n}}\n\n'''IFTRAN''' (née Iftran) was created in 1972 by E. F. Miller at General Research Corporation, [[Santa Barbara, California|Santa Barbara]], [[California]] as a mechanism to support [[structured programming]] concepts in a [[FORTRAN]]-based environment.\n\nIFTRAN had these basic structured programming constructs: IF...ELSEIF...ENDIF, DO...ENDDO, FOR...ENDFOR, and CASEOF...CASE...ENDCASE statements that transliterated into pure-FORTRAN.\n\nIFTRAN was bootstrapped through multiple stages from a hand-build parser that added IFTRAN language constructs one at a time.  Eventually the IFTRAN preprocessor was converted entirely into IFTRAN and a pure-FORTRAN version of IFTRAN pre-processing its own code was used to transfer the tool to other computers.  A pretty-printing capability provided automatically indented source program listings as an output of the IFTRAN pre-processor in addition to the pure-FORTRAN code that was sent to the underlying FORTRAN compiler.\n\nAccording to the instruction manual for IFTRAN, a General Research report suggest this rationale for the use of a FORTRAN pre-processor:\n\n''\"While the newer structured languages such as [[Pascal (programming language)|PASCAL]] are enjoying an unusual popularity, particularly in educational institutions, the workhorse language of scientists and engineers is still FORTRAN. FORTRAN can be argued for as the only truly transportable language; when going from site to site, FORTRAN is always expected to be available. Since this is not true of [[ALGOL]], PASCAL, ADA or other structured languages, there is a good motivation for users and authors of code which may be transported to write in FORTRAN.\"''\n\n==References==\n{{reflist}}\n\nMiller, E. F. \"Extensions to [[Fortran|FORTRAN]] and Structured Programming -- An Experiment,\" RM-1608, General Research Corporation, Santa Barbara, California, February 1972.\n\nMiller, E.F. \"Extensions to FORTRAN and Structured Programming - An Experiment\", in Annual ACM IEEE Design Automation Conference Proceedings of the June 1971 design automation workshop on Design automation, Atlantic City, New Jersey, United States.\n\nMiller, E. F.  \"Extensions to Fortran to support structured programming\" in [SIGPLAN] (1973) SIGPLAN Notices 8(06) June 1973 SPECIAL ISSUE: Abstracts in programming language-related research.\n\nMiller, E.F., \"A Compendium of Language Extensions to Support Structured Programming\", in SIGPLAN Notices 8(06) June 1973 SPECIAL ISSUE: Abstracts in programming language-related research.\n\nMiller, E. F., \"IFTRAN -- A Structured Language Preprocessor,\" Twentieth Semi-Annual VIM Conference, [[Portland, Oregon]], April 1974 in [ACM] (1974) Proceedings of the 1974 ACM Annual Conference San Diego, November, 1974.\n\n[[Category:Fortran programming language family]]"
    },
    {
      "title": "Industrial Real-Time Fortran",
      "url": "https://en.wikipedia.org/wiki/Industrial_Real-Time_Fortran",
      "text": "'''Industrial Real-Time Fortran''' ('''IRTF''') was developed, during the decade of 1970-1980, to augment the [[Fortran]] language with library bindings useful for process and device control, and I/O.  Also included in IRTF was a set of bit-manipulation functions which were eventually incorporated into MIL_STD-1753 for Fortran-77, and later into Fortran-90.\n\n== History ==\nThe IRTF standard evolved from a series of workshops held at [[Purdue|Purdue University]] in the early 1970s.  The Fortran committee created a proposal which was approved and published by the [[Instrument Society of America]] (ISA) as ISA Standard S61.1 (1972).  The paper defined library calls for controlling the state of concurrently activated programs, process I/O, and bit manipulation.  A second supplementary paper, ISA S61.2 (1973) was published a year later.  This paper defined additional calls for random unformatted files, and bit manipulation.\n\nAdditional work, including work on management of parallel tasks, was performed both in the U.S. as S61.3, and in Germany as ''Prozess-FORTRAN''.  In 1980, a joint American/European proposal was published.\n\nWhile IRTF held some influence in certain markets in the 1970s, by the early 1980s most process control systems were being built using [[microprocessor]]-based systems where Fortran was not available.  Because of this, the IRTF bindings have fallen into disuse.  Modern systems tend to use [[Pthreads|POSIX Threads]] instead.\n\n== References ==\n* ISA S61.1 (1972) Standard.  Industrial Computer System FORTRAN Procedures for Executive Functions and Process Input-Output.  Instrument Society of America, 1972\n* ISA S61.2 (1973) Draft Standard: Industrial Computer System FORTRAN Procedures for Handling Random Unformatted Files, Bit Manipulation, and Date and Time Information.  Instrument Society of America, 1973\n* Industrial Real-Time FORTRAN (International Purdue Workshop/European Workshop on Industrial Computer Systems Tech Committee 1, Feb 1980)\n* Wilfried Kneis (October 1981). \"Draft standard industrial real-time FORTRAN\". ACM SIGPLAN Notices 16 (7): 45–60.\n* MIL-STD-1753. DoD Supplement to X3.9-1978. U. S. Government Printing Office.\n\n[[Category:Fortran programming language family]]"
    },
    {
      "title": "Mortran",
      "url": "https://en.wikipedia.org/wiki/Mortran",
      "text": "{{Unreferenced|date=January 2008}}\n'''Mortran''' ('''M'''ore F'''ortran''') is an extension of the [[Fortran]] [[programming language]] used for scientific computation. It introduces syntax changes, including the use of semicolons to end statements, in order to improve readability and flexibility. Mortran code is [[Macro (computer science)|macro]]-processed into Fortran code for compilation.\n\nNote that Mortran, like many preprocessors, does not make a complete analysis of the Fortran source and, like many preprocessors, may not always make its assumptions/requirements explicit.  Consider, for example, Mortran multiple assignment.  From the Mortran ''User Guide'':\n<source lang=\"fortran\">\n / I, A(I,K), J / = SQRT(X/2.0);\n</source>\nproduces the following FORTRAN statements:\n<source lang=\"fortran\"> \n          I = SQRT(X/2.0)\n          A(I,K) = SQRT(X/2.0)\n          J = SQRT(X/2.0)\n</source>\nIn this example, the produced Fortran implements the multiple assignment correctly only if X is not aliased to I or to A(I,K), assuming the multiple assignment semantics are left to right.\n\n==External links==\n*[http://www.slac.stanford.edu/exp/e871/documentation/offline/mortran2.html Using MORTRAN 2 (Stanford document)]\n*[https://web.archive.org/web/20050226184156/http://www.sao.nrc.ca/inms/irs/EGSnrc/pirs701/node134.html EGS User Guide to Mortran3]\n*[https://web.archive.org/web/20050409183629/http://ccwww.kek.jp/kek/rad/center/mortran2.pdf Mortran lecture] (Japanese) from [[KEK]] ([[PDF]])\n*[https://web.archive.org/web/20060902211445/http://hopl.murdoch.edu.au/showlanguage.prx?exp=2252&language=MORTRAN History of Programming Languages:Mortran]\n*[http://david.w.h.chin.googlepages.com/mortran-mode.el Emacs major mode for editing Mortran source]{{dead link|date=February 2018 |bot=InternetArchiveBot |fix-attempted=yes }}\n\n[[Category:Fortran programming language family]]\n\n{{Compu-lang-stub}}"
    },
    {
      "title": "Object-Oriented Fortran",
      "url": "https://en.wikipedia.org/wiki/Object-Oriented_Fortran",
      "text": "'''Object-Oriented Fortran''' is an [[object-oriented]] extension of [[Fortran]], in which data items can be grouped into objects, which can be instantiated and executed in parallel.\n\nIt was available for [[Sun Microsystems|Sun]], [[Iris (computer)|Iris]], [[Intel iPSC|iPSC]], and [[nCUBE]], but is definitely supported.\n\n{{FOLDOC}}\n\n[[Category:Fortran programming language family]]\n\n\n{{Compu-lang-stub}}"
    },
    {
      "title": "QUIKTRAN",
      "url": "https://en.wikipedia.org/wiki/QUIKTRAN",
      "text": "'''QUIKTRAN''' is a [[Fortran]]-like, interactive [[computer]] [[programming language]] with [[debugging]] facilities.  \n\n==References==\n*Sammet 1969, p.226.\n\n==External links==\n* [https://web.archive.org/web/20060908020903/http://hopl.murdoch.edu.au/showlanguage.prx?exp=461&language=QUIKTRAN History of Programming Languages: QUIKTRAN]\n\n{{FOLDOC}}\n\n[[Category:Fortran programming language family]]\n[[Category:Procedural programming languages]]\n[[Category:Programming languages created in 1964]]\n\n{{compu-lang-stub}}\nQUIKTRAN:\nMore than a Fortran-based programming language. QUIKTRAN was IBM's first entry in on-line Time Sharing in the 1960s.  It ran on an IBM 7040/7044, using an IBM 7740 as a dial up communications processor. In 1967 an IBM data center supported over 400 commercial customers in a time-sharing environment; users could dial up and log into the Quiktran system.  They could store their own Fortran programs in private libraries for later execution, or execute numerous IBM-supplied programs for applications including linear programming, communication network design, and business programs.  The system on the receiving end allowed teletype or typewriter keyboards using data phones or [[Acoustic coupler|acoustic modems]] to connect. It could support approximately 50 simultaneous users, The hardware used was an IBM 1301 40-platter disk for storage, and an IBM 7320 Magnetic Drum for program swapping.  The QUIKTRAN system was superseded by Call/360.  Quiktran and Call/360 were supported by Service Bureau Corp., a wholly owned subsidiary of IBM.  SBC was later sold to Minneapolis-based company ([[Control Data Corporation]]).\nSource:  Burt McGregor<!-- - In my early IBM career I was a Systems Engineer supporting this system in an IBM Chicago Data Center. Note by later editor: Have I just edited someone's working notes, to be worked up into an article?-->"
    },
    {
      "title": "Ratfiv",
      "url": "https://en.wikipedia.org/wiki/Ratfiv",
      "text": "{{Multiple issues|\n{{refimprove|date=November 2010}}\n{{expert-subject|date=September 2011}}\n{{notability|date=September 2011}}\n}}\n\n'''Ratfiv''' is an enhanced version of the [[Ratfor programming language]], a [[preprocessor]] for [[Fortran]] designed to give it [[C (programming language)|C]]-like capabilities. Fortran was widely used for scientific programming but had very basic [[Control flow|control-flow]] primitives (\"do\" and \"[[goto]]\") and no \"[[Macro (computer science)|macro]]\" facility which limited its expressiveness.\n\nThe name of the language is a pun (''Ratfor'' (RATional FORtran) -> \"Rat Four\" -> \"Rat Five\" -> ''RatFiv'').\n\nRatfiv was developed by [[Bill Wood (developer)|Bill Wood]] at the [[Fox Chase Cancer Center|Institute for Cancer Research]], [[Philadelphia]], PA in the early 1980s and released on several [[DECUS]] (Digital Equipment Users Group) SIG (Special Interest Group) tapes.  It is based on the original Ratfor by [[Brian Kernighan|B. Kernighan]] and [[P. J. Plauger]], with rewrites and enhancements by David Hanson and friends (U. of Arizona), [[Joe Sventek]] and Debbie Scherrer ([[Lawrence Berkeley National Laboratory]]).\n\nRatfiv V2.1 was distributed on the DECUS RSX82a SIG tape.<ref>[http://www.ibiblio.org/pub/academic/computer-science/history/pdp-11/rsx/decus/rsx82a/330015/ Ratfiv V2.1 archive]</ref>\n\n==See also==\n*[[Ratfor]]\n*[[Fortran 77]]\n*[[VAX/VMS]]\n\n== References ==\n\n{{reflist}}\n\n==External links==\n*[http://sepwww.stanford.edu/doku.php?id=sep:software:ratfor90 Ratfor90]\n\n[[Category:Fortran programming language family]]\n\n\n{{software-eng-stub}}"
    },
    {
      "title": "Ratfor",
      "url": "https://en.wikipedia.org/wiki/Ratfor",
      "text": "{{Infobox programming language\n | name                   = Ratfor\n | released               = {{Start date|1976}}\n | developer              = [[Brian Kernighan]]\n | influenced by          = [[Fortran]], [[C (programming language)|C]]\n | website                = [http://sepwww.stanford.edu/doku.php?id=sep:software:ratfor sepwww.stanford.edu]\n}}\n\n'''Ratfor''' (short for ''Rational Fortran'') is a [[programming language]] implemented as a [[preprocessor]] for [[Fortran#FORTRAN 66|Fortran 66]]. It provided [[Structured programming|modern control structures]], unavailable in Fortran 66, to replace [[GOTO]]s and statement numbers.\n\n== Features ==\nRatfor provides the following kinds of flow-control statements, described by Kernighan and Plauger as \"shamelessly stolen from the language [[C (programming language)|C]], developed for the [[Unix|UNIX]] operating system by [[Dennis Ritchie|D.M. Ritchie]]\" (\"Software Tools\", p.&nbsp;318):\n\n* statement grouping with braces\n* '''if-else''', '''while''', '''for''', '''do''', '''repeat-until''', '''break''', '''next'''\n* \"free-form\" statements, i.e., not constrained by Fortran format rules\n* <, >, >=, ... in place of .LT., .GT., .GE., ...\n* '''include'''\n* # comments\n\nFor example, the following code\n<syntaxhighlight lang=\"c\">\nif (a > b) {\n  max = a\n} else {\n  max = b\n}\n</syntaxhighlight>\nmight be translated as\n<syntaxhighlight lang=\"fortranfixed\">\n      IF(.NOT.(A.GT.B))GOTO 1\n      MAX = A\n      GOTO 2\n    1 CONTINUE\n      MAX = B\n    2 CONTINUE\n</syntaxhighlight>\nThe version of Ratfor in ''Software Tools'' is written in Ratfor, as are the sample programs, and inasmuch as its own translation to Fortran is available, it can be ported to any Fortran system. Ratfor source code file names end in .r or .rat.\n\n== History ==\nRatfor was designed and implemented by [[Brian Kernighan]] at [[Bell Telephone Laboratories]] in 1974, and described in ''Software&mdash;Practice & Experience'' in 1975.  It was used in the book \"Software Tools\" ([[Brian Kernighan|Kernighan]] and [[P.J. Plauger|Plauger]], 1976).\n\nIn 1977, at [[Purdue University]], an improved version of the ratfor preprocessor was written. It was called Mouse4, as it was smaller and faster than ratfor. A published document by Dr. [[Douglas Comer]], professor at Purdue, concluded \"contrary to the evidence exhibited by the designer of Ratfor, sequential search is often inadequate for production software. Furthermore, in the case of lexical analysis, well-known techniques do seem to offer efficiency while retaining the simplicity, ease of coding and modularity of ad hoc methods.\" (CSD-TR236).\n\nIn comparison to the ratfor preprocessor on a program of 3000 source lines running on a [[CDC 6500]] system took 185.470 CPU seconds. That was cut by 50% when binary search was used in the ratfor code. Rewriting the ad hoc lexical scanner using a standard method based on finite automata reduced run time to 12.723 seconds.\n\nWith the availability of [[Fortran 77]], a successor named [[ratfiv]] (ratfor=rat4 => rat5=ratfiv) could, with an option /f77, output a more readable Fortran 77 code:\n<syntaxhighlight lang=\"fortranfixed\">\n      IF (A .GT. B) THEN\n        MAX = A\n      ELSE\n        MAX = B\n      ENDIF\n</syntaxhighlight>\n\nInitial Ratfor source code was ported to C in 1985 <ref>{{ cite web|url=http://ratfor.sourcearchive.com/documentation/1.0-11/rat4_8c-source.html |title=Ratfor implementation in C (1985)}}</ref> and improved to produce Fortran 77 code too.<ref>{{ cite web|url=http://sepwww.stanford.edu/doku.php?id=sep:software:ratfor |title=Ratfor77}}</ref> A [[git (software)|git]] tree has been set in 2010 in order to revive ratfor\n.<ref>{{ cite web|url=http://gitorious.org/ratfor-revived/c-ratfor |title=Ratfor Git Revived}}</ref>\nMeanwhile, the [[GNU Compiler Collection|GNU C compiler]] which had the ability to directly compile a Ratfor file (.r) without keeping a useless intermediate Fortran code (.f) (<code>gcc foo.r</code>) lost this functionality in version 4 during the move in 2005 from [[f77]] to [[GNU Fortran]].<ref>{{ cite web|url=https://gcc.gnu.org/bugzilla/show_bug.cgi?id=24357 |title=gcc lost the ratfor preprocessor}}</ref>\n\nSource packages, .[[deb (file format)|deb]] or [[RPM Package Manager|src.rpm package]] <ref>{{ cite web|url=http://www.dgate.org/ratfor/SRPMS/ |title=ratfor-1.01-1.src.rpm}}</ref><ref>{{ cite web|url=http://mirror.corbina.net/mandriva/devel/cooker/SRPMS/contrib/release/|title=Another Ratfor source code|deadurl=yes|archiveurl=https://archive.is/20130703053450/http://mirror.corbina.net/mandriva/devel/cooker/SRPMS/contrib/release/|archivedate=2013-07-03|df=}} ratfiv or ratfiv source [[RPM Package Manager|rpm package]]</ref> are still available for users who needs to compile old Ratfor software on any operating system.\n\n== See also ==\n* [[Ratfiv]]\n* [[Fortran]]\n\n== References ==\n{{reflist|30em}}\n\n== External links ==\n* [http://sepwww.stanford.edu/doku.php?id=sep:software:ratfor Ratfor]\n* [http://sepwww.stanford.edu/doku.php?id=sep:software:ratfor90 Ratfor90]\n* [https://web.archive.org/web/20060903163415/http://hopl.murdoch.edu.au/showlanguage.prx?exp=692&language=RATFOR History of Programming Languages: Ratfor]\n* [https://docs.lib.purdue.edu/cstech/172 Purdue summary]\n\n[[Category:Fortran programming language family]]"
    },
    {
      "title": "WATFIV",
      "url": "https://en.wikipedia.org/wiki/WATFIV",
      "text": "{{Original research|entire article|date=September 2007}}\n\n'''WATFIV''', or '''WAT'''erloo '''F'''ORTRAN '''IV''',  developed at the [[University of Waterloo]], Canada is an implementation of the [[Fortran]] computer [[programming language]]. It is the successor of '''WATFOR'''.\n\nWATFIV was used from the late 1960s into the mid-1980s. WATFIV was in turn succeeded by later versions of WATFOR.\nBecause it could complete the three usual steps (\"compile-link-go\") in just one pass, the system became popular for teaching students computer programming.\n\n==History==\nIn the early 1960s, newly formed [[computer science]] departments started university programs to teach computer [[programming language]]s. The [[Fortran]] language had been developed at [[IBM]], but suffered from slow and error-prone three-stage [[batch processing]] workflow.<ref name=\"design\">{{cite journal |title= Design characteristics of the WATFOR compiler |journal= ACM SIGPLAN Notices: Proceedings of a Symposium on Compiler Optimization |publisher= [[Association for Computing Machinery]] |author1= Donald D. Cowan |author2= [[J. Wesley Graham]] |volume= 5 |number= 7 |pages= 41–44 |date= July 1970  |doi= 10.1145/390013.808481 }}</ref> In the first stage, the [[compiler]] started with [[source code]]  and produced [[object file|object code]]. In the second stage, a [[Linker (computing)|linker]] constructed a complete program using growing libraries of common functions. Finally, the program was repeatedly executed with data for the typical scientific and business problems of customers.  Each step often included a new set of [[punched card]]s or tape.  Students, on the other hand, had very different requirements.  Their programs were generally short, but usually contained logic and syntax errors, resulting in time-consuming repetition of the steps and confusing \"[[core dump]]s\" (It often took a full day to submit and receive the successful or failed output from the computer operator). Once their programs worked correctly, they were turned in and not run again.\n\nIn 1961, the [[University of Wisconsin]] developed a technology called FORGO for the [[IBM 1620]] which combined some of the steps.<ref>{{cite book |title= Programming the IBM 1620 |edition= 2nd |year= 1965 |author= Clarence B. Germain |page= 62 |publisher= Prentice-Hall |url= https://books.google.com/books?id=BtpWAAAAMAAJ }}</ref>\nSimilar experiments were carried out at [[Purdue University]]  on the [[IBM 7090]] in a system called PUFFT.<ref>{{cite journal |title= PUFFT—The Purdue University fast FORTRAN translator |journal= Communications of the ACM |publisher= [[Association for Computing Machinery]] |author1=  Saul Rosen |author1link=Saul Rosen|author2= Robert A. Spurgeon |author3=Joel K. Donnelly |volume= 8 |number= 11 |pages= 661–666 |date= November 1965 |doi= 10.1145/365660.365671 }}</ref>\n\n===WATFOR 7040===\nIn summer 1965, four undergraduate students of the [[University of Waterloo]], Gus German, [[James G. Mitchell]]<ref>{{cite web |title= Java: Where You Want to *Be* Tomorrow: Dr. Jim Mitchell, 1997 Recipient of the J.W. Graham Medal in Computing and Innovation |date= May 30, 1997 |url= http://infranet.uwaterloo.ca/infranet/s199705.htm |publisher= [[University of Waterloo]], Canada |accessdate= April 1, 2011 }}</ref><ref>{{cite web |title= James Mitchell |url= http://labs.oracle.com/people/mybio.php?c=601 |work= The People at Oracle Labs |publisher= Oracle Corporation |accessdate= April 1, 2011 }}</ref>\nRichard Shirley and Robert Zarnke, led by Peter Shantz, developed a Fortran compiler for the [[IBM 7040]] computer called WATFOR.  Its objectives were fast compilation speed and effective error diagnostics at both compile and execution time.<ref name=\"design\"/> It eliminates the need for a separate linking step and, as a result, FORTRAN programs which contain no syntax errors are placed into immediate execution. Professor [[J. Wesley Graham]] provided leadership throughout the project.<ref>{{cite news |title=UW computing pioneer mourned |date= September 8, 1999 |newspaper= UW Gazette |author=Chris Redmond |url= http://communications.uwaterloo.ca/Gazette/1999/sep08/graham.html |publisher= [[University of Waterloo]] |accessdate= April 3, 2011 }}</ref>\n\nThis simple, one-step process allowed non-experienced programmers to learn programming with lower cost in time and computing resources.<ref name=Sigcse1970-11>\n{{cite news \n| url         = http://dl.acm.org/citation.cfm?id=873659\n| title       = A complete package for introducing computer science\n| publisher   = Association for Computing Machinery SIGCSE Bulletin\n|author1=P. C. Brillinger |author2=D. D. Cowan | date        = November 1970\n| pages       = 118–126 \n| accessdate  = 2012-12-18\n| quote       = \n}}\n</ref>\nTo aid in debugging, the compiler uses an innovative approach to checking for undefined variables (an extremely common mistake by beginning programmers). It uses a diagnostic feature of the 7040 that can deliberately set areas of memory to bad parity. When a program tries to reference variables that hadn't been set, the machine takes an interrupt (handled by the Watfor runtime routines) and the error is reported to the user as an undefined variable. This has the pleasant side effect of checking for undefined variables with essentially no CPU overhead.\n\nWATFOR quickly gained popularity and over 75 institutions installed it on their IBM 7040 systems.  The distribution of the compiler was handled by Sandra Bruce (née Hope).\n\n===WATFOR 360===\nIn 1966, the University planned to replace the 7040 with an [[IBM System/360]] computer, which was much faster but not software compatible.  A team of full-time employees and undergraduate students was formed to write an IBM 360 version.<ref name=\"wat\">{{cite web |title= Unbundling Computing at The University of Waterloo |author1=Harold Alkema  |author2=Kenneth McLaughlin   |lastauthoramp=yes |publisher= University of Waterloo |year= 2007 |url= http://www.cs.uwaterloo.ca/40th/Chronology/printable.shtml |accessdate= April 5, 2011 }}</ref> The project members, Betty Schmidt, Paul Dirksen, [[Paul H. Cress]], Lothar K.  \"Ned\" Kesselhut, Bill Kindree and Dereck Meek, who were later joined by Mike Doyle, Rod Milne, Ron Hurdal and Lynn Williams, completed 360 WATFOR in the early part of 1967.  Many other institutions (universities, colleges, businesses and governmental agencies) started using the WATFOR compiler to meet needs similar to those experienced at the University of Waterloo.  The distribution of the software and customer support was carried on by Sandra Ward.\n\n===WATFIV===\nAs a result of proposals from the [[SHARE (computing)|SHARE]] user group Fortran committee and others, a new version called WATFIV was produced in 1968.  WATFIV introduced new features such as CHARACTER variables and direct-access input-output.  The [[Association for Computing Machinery]]  presented Paul Cress and Paul Dirksen the [[Grace Murray Hopper Award]] for contributions to the WATFOR and WATFIV projects in 1972.<ref>{{cite web |title= 1972 – Paul H. Cress |work= Grace Murray Hopper Award |publisher= [[Association for Computing Machinery]] |url= http://awards.acm.org/citation.cfm?id=4117320&srt=all&aw=145&ao=GMHOPPER |accessdate= April 5, 2011 |archive-url= https://web.archive.org/web/20120504100839/http://awards.acm.org/citation.cfm?id=4117320&srt=all&aw=145&ao=GMHOPPER |archive-date= May 4, 2012 |dead-url= yes |df= mdy-all }}</ref>   The WATFIV compiler was included in the DATAPRO Honour Roll for 1975 and 1976.\nPeople involved with maintenance and enhancement included Bernie Murphy, Martin Wiseman and Yvonne Johnson.\n\nWATFIV was pronounced as \"WHAT FIVE\", but, as was realized at the time, could also (almost) still be pronounced as \"WHAT FOR\", as in WAT-F-IV (Waterloo Fortran IV).\n\nUniversities and corporations used these compilers and a number of other software products have been developed in the WATFOR tradition.\nFor example, a version for the [[COBOL]] programming language is called [[WATBOL]].<ref>{{cite web |title= WATBOL  |author1=R. J. Hurdal |author2=W.R. Milne |author3=C.R. Zarnke |publisher= University of Waterloo |year= 1972 |url= http://csg.uwaterloo.ca/sdtp/watbol.html |accessdate= April 5, 2011 }}</ref><ref name=UWaterloo40Years1972>\n{{cite news \n| url         = https://cs.uwaterloo.ca/40th/Chronology/1972.shtml\n| title       = Chronology - 1970s: The Evolution of The University of Waterloo Continues -- 1972\n| publisher   = [[University of Waterloo]] \n| date        = \n| page        = \n| location    = \n| isbn        = \n| accessdate  = 2012-12-17\n|trans-title=| quote       = In 1969 and 1970, the WATBOL compiler was completed. The WATBOL compiler for the COBOL programming language had speed and error diagnostics similar to the WATFOR compilers for FORTRAN. \n}}\n</ref><ref name=ParentsOfInvention>\n{{cite book\n| url         = https://books.google.com/?id=28qmcQCVFcYC&pg=PA10&dq=WATBOL+waterloo#v=onepage&q=WATBOL%20waterloo&f=false\n| title       = Parents of Invention: The Development of Library Automation Systems in the Late 20th Century: The Development of Library Automation Systems in the Late 20th Century\n| publisher   = [[ABC-CLIO]]\n| author      = Christopher Brown-Syed\n| year        = 2011\n| page        = 10\n| isbn        = 9781591587910\n| accessdate  = 2012-12-17\n| quote       = During the 1970s, the University of Waterloo, located in southern Ontario, Canada, was almost as synonymous with computing as MIT or Berkeley.  It had developed extensions to the popular general-purpose Fortran programming language called WATFOR and WATFIV and its own version of the equally popular business computing language COBOL, called WATBOL.\n}}\n</ref>\n[[Daniel D. McCracken]] said \"it is no exaggeration to suggest that WATFOR revolutionized the use of computers in education.\"<ref>{{cite book |author= [[Daniel D. McCracken]] |title=A guide to Fortran IV programming |url=https://books.google.com/books?id=aNhWAAAAMAAJ |year=1972 |page=253 |publisher=Wiley |isbn=978-0-471-58281-6 }}</ref>  At one point, more than 3,000 mini and mainframe computer licenses and over 100,000 microcomputer licenses were held worldwide for this family of software products.\n\n===WATFOR-11, -S and -11S===\nIn 1974, a compiler with characteristics similar to the IBM implementation was created for the [[Digital Equipment Corporation]] [[PDP-11]] computer and called WATFOR-11. The team members, Jack Schueler, Jim Welch and Terry Wilkinson, were later joined by [[Ian McPhee (computer scientist)|Ian McPhee]] who had added new control statements to the WATFIV compiler for [[structured programming]] (SP). These new statements included the block IF (later included in the ANSI X3.9-1978 language standard), WHILE, UNTIL, and others.  WATFIV-S was announced in 1974 and a few months later, WATFOR-11S (the \"S\" indicating the new SP features) was also announced.  The original SP features were later enhanced with additional statements by Bruce Hay in WATFIV-S in 1980 and by Jack Schueler in WATFOR-11S in 1981.\n\n===WATFOR-77===\nDuring the 1970s, the ANSI X3J3 subcommittee (the FORTRAN language standard group) developed a new language standard which was officially approved in April, 1978.  This standard, designated [[FORTRAN 77]], introduced many new statements into the language.  In fact, the previous language standard FORTRAN 66 is a very small document and describes, what is in effect, a subset of most implementations of FORTRAN.  For example, the WATFIV and WATFOR-11 implementations are based upon the IBM definition of [[Fortran#FORTRAN IV|FORTRAN-IV]].\n\nAs programmers used the FORTRAN 77 features, a new compiler was required to combine the advantages of the WATFIV compiler with the new language standard.  In January 1983, a project to develop a FORTRAN 77 compiler was started at [[Watcom|Watcom Systems Inc]]. Under the leadership of Jack Schueler, Watcom employees and undergraduate students from the University of Waterloo's Co-operative Computer Science program became involved in the creation of the WATFOR-77 compiler.  The major work was done by Geno Coschi, Fred Crigger, John Dahms, Jim Graham, Jack Schueler, Anthony Scian and Paul Van Oorschot.  They were assisted by Rod Cremasco, John McCormick, David McKee and Brian Stecher. Many of the team members from former compiler projects provided input.  These included Bruce Hay, Ian McPhee, Sandra Ward, Jim Welch and Terry Wilkinson.\n\nUnlike previous compilers, a significant portion of WATFOR-77 was written in a portable systems language to ease the implementation of the compiler on other computer systems. Earlier WATFOR compilers were written entirely in machine-dependent assembly language.\n\nTwo components of the compiler are not portable.  The code generator translates FORTRAN statements into native computer instructions and stores them in memory.  The first version of WATFOR-77 generates instructions for the IBM 370 computer architecture. Most of the execution-time support (undefined variable checking, subscript evaluation, intrinsic functions) was written in assembly language for good performance.\nIn September 1984, the first version was installed at the University of Waterloo for the Department of Computing Services.  It was an implementation for IBM 370 computers running the [[VM (operating system)|VM/SP CMS]] operating system.\n\nA few months earlier, in May 1984, a project started to implement the WATFOR-77 compiler on the [[IBM Personal Computer]]. This project included Geno Coschi, Fred Crigger, Tim Galvin, Athos Kasapi, Jack Schueler, Terry Skomorowski and Brian Stecher.\nIn April 1985, this second version of WATFOR-77 was installed at the University of Waterloo for use by students of the Faculty of Engineering.  The compiler can run on a 256K IBM Personal Computer using IBM PC DOS 2.0 and does not require special floating-point hardware.\n\nIn the fall of 1985, a Japanese version of WATFOR-77 was delivered to IBM Japan for the [[IBM JX]] Personal Computer. This version produces [[Japanese language]] error messages and supported the Kanji, Hiragana and Katakana character sets for variable names and character strings. To support the JX, the Language Reference manual and User's Guide were translated into Japanese. Another version of WATFOR-77 with the same features mentioned above was also developed for Japanese IBM PS/55 family of personal computers in Spring 1988.\n\nDuring the summer of 1986, the IBM PC version of WATFOR-77 was adapted to run on the [[Unisys ICON]] which runs the [[QNX]] operating system. Since QNX is quite different from IBM PC DOS, parts of the run-time system were rewritten. This implementation of WATFOR-77 was made available in September 1986.\n\nDuring the summer of 1985, a project was started to adapt WATFOR-77 to the Digital Equipment Corporation [[VAX]] computer series running the [[OpenVMS|VMS]] operating system. The members of this project included Geno Coschi, Marc Ouellette, Jack Schueler and Terry Skomorowski. This implementation was made available in March 1987.\n\nAlso, in the spring of 1988, a new project was begun to develop an optimizing FORTRAN 77 compiler. This compiler uses the code generator from the [[Watcom C compiler]], which produces superior machine code to other C compilers. The FORTRAN 77 optimizing compiler was first shipped in mid-1990.\n\nIn October 1990, the 25th anniversary of WATFOR was celebrated.<ref>{{cite web |title= WATFOR's Silver Anniversary |work= WATCOM News volume 8 number 1 |year= 1991 |url= http://csg.uwaterloo.ca/sdtp/watfor.html |accessdate= April 1, 2011 |archive-url= https://archive.is/20120721141408/http://csg.uwaterloo.ca/sdtp/watfor.html |archive-date= July 21, 2012 |dead-url= yes |df= mdy-all }}</ref> Many involved in the development of the WATFOR compilers were invited to the University of Waterloo for a reunion.\n\nIn spring 1992, a version of WATFOR-77 was adapted to the [[NEC PC-9801]] family of personal computers. This version was similar to the IBM PS/55 version but modified to accommodate architectural differences.\nIn January 1992, development of a 32-bit version of WATFOR-77 for [[Intel 80386]] and [[Intel 80486]] personal computers began. The first version was shipped in the fall of 1992.\n\nAs late as 1995, classes for programming in WATFIV were still being held at the [[University of Mississippi]], led by Professor Charles H. (Chuckie) Franke.\n\n==See also==\n* [[Watcom]]\n* [[Donald B. Gillies]] (early adopter at University of Illinois)\n\n==References==\n{{Reflist}}\n\n==Further reading==\n* {{cite journal |title= WATFOR—The University of Waterloo FORTRAN IV Compiler |journal= Communications of the ACM |publisher= [[Association for Computing Machinery]] |author1= Peter W. Shantz  |author2= R. A. German |author3= [[James G. Mitchell]] |author4= Richard SK Shirley |author5=  C. Robert Zarnke |volume= 10 |number= 1 |pages= 41–44 |date= January 1967 |doi= 10.1145/363018.363059 }}\n* {{cite book |title= Computer science at Waterloo: a history to celebrate 25 years, 1967-1992 |author= Peter James Ponzo |publisher= University of Waterloo |year= 1992 }}\n* {{cite book |author1= [[Paul H. Cress]] |author2= Paul Dirksen |author3= [[J. Wesley Graham|James Wesley Graham]] |title=FORTRAN IV with WATFOR |url=https://books.google.com/books?id=reEmAAAAMAAJ |year=1968 |publisher=Prentice-Hall}}\n* {{cite book |author=Paul Cress |title=Description of /360 WATFOR: a fortran-IV compiler |url=https://cs.uwaterloo.ca/research/tr/1968/CSTR-1000.pdf|year=1968 |publisher=Dept. of Applied Analysis and Computer Science, Computing Centre, University of Waterloo}}\n* {{cite book |author1= Paul Cress |author2= Paul Dirksen |author3=James Wesley Graham |title=FORTRAN IV with WATFOR and WATFIV |url=https://books.google.com/books?id=VeEmAAAAMAAJ |year=1970 |publisher=Prentice-Hall}}\n* {{cite book |author1=Paul Cress |author2= Paul Dirksen |author3=James Wesley Graham |title=Structured FORTRAN with WATFIV-S |url=https://books.google.com/books?id=LtKTQAAACAAJ |date=January 1, 1980 |publisher=Prentice-Hall |isbn=978-0-13-854752-3}}\n\n==External links==\n* [http://www.openwatcom.org/ Open Watcom]\n* [http://hopl.murdoch.edu.au/showlanguage.prx?exp=307&language=WATFOR History of Programming Languages: WATFOR]\n\n[[Category:Fortran programming language family]]\n[[Category:Procedural programming languages]]\n[[Category:Programming languages created in the 1960s]]\n[[Category:Software written primarily in assembly language]]"
    },
    {
      "title": "AMBER",
      "url": "https://en.wikipedia.org/wiki/AMBER",
      "text": "{{other uses|Amber (disambiguation)}}\n{{Infobox software\n| name = Assisted Model Building with Energy Refinement (AMBER)\n| logo = \n| screenshot = \n| caption = \n| collapsible = \n| author = [[Peter Kollman]], David Case, Tom Cheatham, Ken Merz, Adrian Roitberg, Carlos Simmerling, Ray Luo, Junmei Wang, Ross Walker\n| developer = [[University of California, San Francisco]]\n| released = {{Start date and age|2002}}\n| latest release version = Amber18, AmberTools19<ref name=\"Amber19Manual\">[http://ambermd.org/doc12/Amber19.pdf Amber 2019 Reference Manual]</ref>\n| latest release date = {{Start date and age|2019|04|26}}\n| latest preview version = \n| latest preview date = \n| programming language = [[C (programming language)|C]], [[C++]], [[Fortran 95]]\n| operating system = [[Microsoft Windows|Windows]], [[OS X]], [[Linux]], [[Unix]], [[CNK operating system|CNK]]\n| platform = [[x86]], [[List of Nvidia graphics processing units|Nvidia GPUs]], [[Blue Gene]]\n| size = Varies\n| language = English\n| status = Active\n| genre = [[Molecular dynamics]]\n| license = Amber: [[Proprietary software|Proprietary]]<br />AmberTools: [[GNU General Public License|GPL]], [[public domain]], other [[open-source software|open-source]]\n| website = {{URL|ambermd.org}}\n}}\n\n[[File:Bond stretching energy.png|thumb|right|AMBER is used to minimize the bond stretching energy of this [[ethane]] molecule.]]\n\n'''Assisted Model Building with Energy Refinement''' ('''AMBER''') is a family of [[Force field (chemistry)|force fields]] for [[molecular dynamics]] of [[biomolecule]]s originally developed by [[Peter Kollman]]'s group at the [[University of California, San Francisco]].  '''AMBER''' is also the name for the molecular dynamics software [[Software package (installation)|package]] that simulates these force fields. It is maintained by an active collaboration between David Case at [[Rutgers University]], Tom Cheatham at the [[University of Utah]], Adrian Roitberg at [[University of Florida]], Ken Merz at Michigan State University, [[Carlos Simmerling]] at [[Stony Brook University]], Ray Luo at [[UC Irvine]], and Junmei Wang at Encysive Pharmaceuticals.\n\n== Force field ==\nThe term ''AMBER [[Force field (chemistry)|force field]]'' generally refers to the functional form used by the family of AMBER force fields. This form includes several parameters; each member of the family of AMBER force fields provides values for these parameters and has its own name.\n\n=== Functional form ===\nThe functional form of the AMBER force field is<ref name=\"Cornell1995\">{{cite journal |vauthors=Cornell WD, Cieplak P, Bayly CI, Gould IR, ((Merz KM Jr)), Ferguson DM, Spellmeyer DC, Fox T, Caldwell JW, Kollman PA |title=A Second Generation Force Field for the Simulation of Proteins, Nucleic Acids, and Organic Molecules |journal=J. Am. Chem. Soc. |volume=117 |issue=19 |pages=5179–5197 |year=1995 |doi=10.1021/ja00124a002|citeseerx=10.1.1.323.4450 }}</ref>\n:<math>\nV(r^N)=\\sum_\\text{bonds} k_b (l-l_0)^2 + \\sum_\\text{angles} k_a (\\theta - \\theta_0)^2</math>\n<blockquote>\n<math>+ \\sum_\\text{torsions} \\sum_n \\frac{1}{2} V_n [1+\\cos(n \\omega- \\gamma)]</math> \n<math>+\\sum_{j=1} ^{N-1} \\sum_{i=j+1} ^N f_{ij}\\biggl\\{\\epsilon_{ij}\\biggl[\\left(\\frac{r_{0ij}}{r_{ij}} \\right)^{12} - 2\\left(\\frac{r_{0ij}}{r_{ij}} \\right)^{6} \\biggr]+ \\frac{q_iq_j}{4\\pi \\epsilon_0 r_{ij}}\\biggr\\}\n</math>\n</blockquote>\nDespite the term ''force field'', this equation defines the potential energy of the system; the force is the derivative of this potential relative to position.\n\nThe meanings of right hand side [[term (mathematics)|terms]] are:\n* First term ([[summation|summing]] over bonds): represents the energy between covalently bonded atoms. This harmonic (ideal spring) force is a good approximation near the equilibrium bond length, but becomes increasingly poor as atoms separate.\n* Second term (summing over angles): represents the energy due to the geometry of electron orbitals involved in covalent bonding.\n* Third term (summing over torsions): represents the energy for twisting a bond due to bond order (e.g., double bonds) and neighboring bonds or lone pairs of electrons. One bond may have more than one of these terms, such that the total torsional energy is expressed as a [[Fourier series]].\n* Fourth term (double summation over <math>i</math> and <math>j</math>): represents the non-bonded energy between all atom pairs, which can be decomposed into [[van der Waals force|van der Waals]] (first term of summation) and [[electrostatics|electrostatic]] (second term of summation) energies.\n\nThe form of the van der Waals energy is calculated using the equilibrium distance (<math> r_{0ij} </math>) and well depth (<math> \\epsilon </math>). The factor of <math>2</math> ensures that the equilibrium distance is <math> r_{0ij} </math>. The energy is sometimes reformulated in terms of <math>\\sigma</math>, where <math> r_{0ij} = 2^{1/6}(\\sigma)</math>, as used e.g. in the implementation of the softcore potentials.\n\nThe form of the electrostatic energy used here assumes that the charges due to the protons and electrons in an atom can be represented by a single point charge (or in the case of parameter sets that employ lone pairs, a small number of point charges.)\n\n=== Parameter sets ===\nTo use the AMBER force field, it is necessary to have values for the parameters of the force field (e.g. force constants, equilibrium bond lengths and angles, charges). A fairly large number of these parameter sets exist, and are described in detail in the AMBER software user manual. Each parameter set has a name, and provides parameters for certain types of molecules.\n*[[Peptide]], [[protein]], and [[nucleic acid]] parameters are provided by parameter sets with names starting with \"ff\" and containing a two digit year number, for instance \"ff99\". As of 2018 the primary protein model used by the AMBER suit is the ff14SB<ref>{{Cite journal |doi = 10.1021/acs.jctc.5b00255|pmid = 26574453|pmc = 4821407|title = Ff14SB: Improving the Accuracy of Protein Side Chain and Backbone Parameters from ff99SB|journal = Journal of Chemical Theory and Computation|volume = 11|issue = 8|pages = 3696–3713|year = 2015|last1 = Maier|first1 = James A|last2 = Martinez|first2 = Carmenza|last3 = Kasavajhala|first3 = Koushik|last4 = Wickstrom|first4 = Lauren|last5 = Hauser|first5 = Kevin E|last6 = Simmerling|first6 = Carlos}}</ref><ref>http://ambermd.org/AmberModels.php</ref> force field.\n* ''General AMBER force field'' (GAFF) provides parameters for small organic molecules to facilitate simulations of drugs and small molecule ligands in conjunction with biomolecules.\n*The GLYCAM force fields have been developed by Rob Woods for simulating carbohydrates.\n*The primary force field used in the AMBER suit for lipids is lipid14.<ref>{{Cite journal |doi = 10.1021/ct4010307|pmid = 24803855|pmc = 3985482|title = Lipid14: The Amber Lipid Force Field|journal = Journal of Chemical Theory and Computation|volume = 10|issue = 2|pages = 865–879|year = 2014|last1 = Dickson|first1 = Callum J|last2 = Madej|first2 = Benjamin D|last3 = Skjevik|first3 = Åge A|last4 = Betz|first4 = Robin M|last5 = Teigen|first5 = Knut|last6 = Gould|first6 = Ian R|last7 = Walker|first7 = Ross C}}</ref>\n\n== Software ==\nThe AMBER software suite provides a set of programs to apply the AMBER forcefields to simulations of biomolecules. It is written in the programming languages [[Fortran 90]] and [[C (programming language)|C]], with support for most major [[Unix-like]] operating systems and [[compiler]]s. Development is conducted by a loose association of mostly academic labs. New versions are released usually in the spring of even numbered years; AMBER 10 was released in April 2008. The software is available under a [[site license]] agreement, which includes full source, currently priced at US$500 for non-commercial and US$20,000 for commercial organizations.\n\n=== Programs ===\n* ''LEaP'' prepares input files for the simulation programs.\n* ''Antechamber'' automates the process of parameterizing small organic molecules using GAFF.\n* ''Simulated Annealing with NMR-Derived Energy Restraints'' (SANDER) is the central simulation program and provides facilities for energy minimizing and molecular dynamics with a wide variety of options.\n* ''pmemd'' is a somewhat more feature-limited reimplementation of SANDER by Bob Duke. It was designed for [[parallel computing]], and performs significantly better than SANDER when running on more than 8–16 processors.\n** ''pmemd.cuda'' runs simulations on machines with [[graphics processing unit]]s (GPUs).\n** ''pmemd.amoeba'' handles the extra parameters in the polarizable AMOEBA force field.\n* ''nmode'' calculates normal modes.\n* ''ptraj'' numerically analyzes simulation results. AMBER includes no visualizing abilities, which is commonly performed with [[Visual Molecular Dynamics]] (VMD). Ptraj is now unsupported as of AmberTools 13. \n* ''cpptraj'' is a rewritten version of ptraj made in [[C++]] to give faster analysis of simulation results. Several actions have been made parallelizable with OpenMP and MPI.\n* ''MM-PBSA'' allows implicit solvent calculations on snap shots from molecular dynamics simulations.\n* ''NAB'' is a built-in nucleic acid building environment made to aid in the process of manipulating proteins and nucleic acids where an atomic level of description will aid computing.\n\n== See also ==\n{{columns-list|colwidth=30em|\n* [[Comparison of software for molecular mechanics modeling]]\n* [[Comparison of force field implementations]]\n* [[Molecular dynamics]]\n* [[Molecular geometry]]\n* [[Molecular design software]]\n* [[Molecular mechanics]]\n* [[MDynaMix]]\n* [[Ascalaph Designer]]\n* [[BOSS (molecular mechanics)]]\n* [[CHARMM]]\n* [[GROMACS]]\n* [[OPLS]]\n* [[Yasara]]\n* [[Folding@home]]\n}}\n\n== References ==\n{{reflist}}\n===Related reading===<!-- These should be moved inline. -->\n1. {{cite journal |last=Duan |first=Yong |last2=Wu |first2=Chun |last3=Chowdhury |first3=Shibasish |last4=Lee |first4=Mathew C. |last5=Xiong |first5=Guoming |last6=Zhang |first6=Wei |last7=Yang |first7=Rong |last8=Cieplak |first8=Piotr |last9=Luo |first9=Ray |displayauthors=8|title=A point-charge force field for molecular mechanics simulations of proteins based on condensed-phase quantum mechanical calculations |journal=Journal of Computational Chemistry |volume=24 |issue=16 |pages=1999–2012 |year=2003 |doi=10.1002/jcc.10349|pmid=14531054 }}\n\n== External links ==\n* {{Official website|ambermd.org}}\n* [https://web.archive.org/web/20050829021414/http://amber.ch.ic.ac.uk/archive/ AMBER mailing list archive]\n* [http://www.bwhpc-c5.de/wiki/index.php/Amber Amber on the German HPC-C5 Cluster-Systems]\n\n{{Chemistry software}}\n\n[[Category:Fortran software]]\n[[Category:Molecular dynamics software]]\n[[Category:Force fields]]"
    },
    {
      "title": "Astronomical Image Processing System",
      "url": "https://en.wikipedia.org/wiki/Astronomical_Image_Processing_System",
      "text": "{{Infobox software\n| name                   = AIPS\n| logo                   = Logo.aips.png\n| logo size              = 64px\n| screenshot             =\n| developer              = [[NRAO]]\n| latest_release_version =\n| latest_release_date    =\n| programming language   = [[FORTRAN]] and [[C (programming language)|C]]\n| operating_system       = [[Unix-like]]\n| genre                  = Astronomical Analysis\n| license                = [[GNU General Public License]]\n| website                = http://www.aips.nrao.edu/index.shtml\n}}\n\nThe '''Astronomical Image Processing System''' (AIPS) is a software package to support the reduction and analysis of data taken with radio telescopes. Developed predominantly for use with the then under-construction [[Very Large Array|VLA]], the generality inherent in its design allowed it to become the standard data-reduction package for most radio interferometers, including [[VLBI]]. Limited single-dish capability is also featured. Although partially replaced by CASA, it continues to evolve and remains widely used.\n\n==History==\n{{more citations needed|date=August 2016}}\nDevelopment of AIPS started at [[NRAO]] in 1978, two years before the VLA became fully operational. Originally written in [[FORTRAN 66]],<ref>{{cite conference|last1=Wells|first1=Donald|title=NRAO's Astronomical Image Processing System|conference=Data Analysis in Astronomy|date=1985|page=202|publisher=[[Kluwer]]}}</ref> AIPS has used [[FORTRAN 77]] since 1989.<ref>{{cite journal|last1=Greisen|first1=Eric|editor1-last=Heck|editor1-first=André|title=AIPS, the VLA, and the VLBA|journal=Information Handling in Astronomy - Historical Vistas|page=114|date=2003}}</ref> The very first AIPS installation was on a [[MODCOMP]] computer, but the package's portability has led to it being installed on many different systems. Pre-compiled versions are today available for users of [[Linux]] and [[MacOS|Mac OS]].<ref name=\"AIPSFAQ\">{{cite web|last1=Greisen|first1=Eric|title=The AIPS FAQ|url=http://www.aips.nrao.edu/aips_faq.html|website=AIPS|publisher=NRAO}}</ref> Since 2018, a pre-compiled version is no longer available for [[Solaris (operating system)|Solaris]] and users must now build AIPS from source.\n\nOver the years, the capabilities of AIPS have greatly expanded. Initial usage was focused on the VLA, but it has gone on to be used to reduce data from practically all radio interferometers, including [[MERLIN]] and the [[GMRT]] and, to a lesser extent, the [[Westerbork Synthesis Radio Telescope|WSRT]] and [[Australia Telescope Compact Array|ATCA]]. The ability to calibrate VLBI data (including [[space VLBI]]) was added in the 1990s, primarily to support operations with the [[Very Long Baseline Array|VLBA]], but in the process becoming the main data-reduction package for the [[European VLBI Network|EVN]] and combined VLBA/EVN observations (Global VLBI). Single-dish support was also added in the 1980s, with particular application to NRAO's [[ARO 12m Radio Telescope|12-m radio telescope]] and the 91-m transit telescope.\n\nAIPS has now been in use for nearly 40 years and has even outlived its supposed replacement [[AIPS++]], which was eventually rebranded as CASA.<ref>{{cite journal|last1=Jaeger|first1=Shannon|title=The Common Astronomy Software Applications (CASA)|journal=Astronomical Data Analysis Software and Systems ASP Conference Series|date=2008|volume=394|url=http://adsabs.harvard.edu/full/2008ASPC..394..623J}}</ref> CASA has gone on to be the main data-reduction package for the upgraded VLA (EVLA) and [[Atacama Large Millimeter Array|ALMA]], but AIPS remains able, to a large degree, to process data from these state-of-the-art instruments. Despite its age and limited resources, AIPS remains widely used and under active development. AIPS is free software and is covered by the terms of the [[GNU General Public License]].\n\n==Description==\nAIPS runs under the [[X Window System]] with commands entered interactively using a command-line interpreter called POPS. Although relatively primitive, this gives access to a useful collection of e.g. mathematical functions, logical operators and flow control statements. Commands can also be placed in a text file which makes repeating complicated procedures much more convenient and which can be used to create data-reduction [[Pipeline (computing)|pipelines]]. A more modern alternative is to install ParselTongue, a [[Python (programming language)|Python]]-based interface.\n\nAs well as the terminal window from which AIPS is started and commands entered, most AIPS sessions will by default contain two other windows, the AIPS TV and the Message Server. The TV is used to visualise data or images and can, for example, be used to interactively edit data or control the progress of a [[deconvolution]]. The Message Server displays useful information reported by each task. Optionally, basic black and white plots can be displayed using TEKSRV, a [[Tektronix 4010|Tektronix 4012]]-based graphics terminal.\n\nBefore any data can be processed by AIPS, they must first be imported into the system's own data areas, usually in [[FITS]] format. The FITS standard was agreed in 1979 and its development is inseparable from that of AIPS. The data can henceforth be processed using a large number (>530) of individual programs, each of which performs a specific task e.g. producing an image from a calibrated data set. Together these allow a user to visualize, edit and calibrate a data set and subsequently make images or fit models. A number of analysis tasks are included (e.g. Gaussian fitting to images or spectra) as well as the possibility to make publication-quality plots.\n\nExtensive help is available to AIPS users, with detailed information on each parameter and task viewable from the command line. There is also a [[user guide]], the AIPS Cookbook, which is built around examples (recipes) of how to run the various tasks. It is available on-line, as well as being packaged with AIPS in PDF and PostScript formats. A newsletter (AIPSLetter) is published biannually.\n\n==Primatology==\nAlthough briefly known as RANCID,<ref>{{cite journal|last1=Greisen|first1=Eric|editor1-last=Heck|editor1-first=André|title=AIPS, the VLA, and the VLBA|journal=Information Handling in Astronomy - Historical Vistas|page=111|date=2003|publisher=Kluwer}}</ref> the eventual choice of name has led to a preponderance of primate-based humour in and around AIPS. The Cookbook contains \"additional recipes\", instructions for preparing food and drink which all feature bananas as an ingredient.<ref>{{cite techreport |first=Eric|last=Greisen|title=The Creation of AIPS|work=AIPS Memo|issue=100|institution=NRAO|page=14|date=1998}}</ref> The programmer's guide is called ''Going AIPS'', the cover of which features a gorilla clutching a [[Tektronix 4010|Tektronix 4012]] graphics terminal whilst standing upon two [[IBM 3420]] Magnetic Tape Units. Various cover designs of the Cookbook and icons also include images of primates.<ref>{{cite techreport |first=Eric|last=Greisen|title=The Creation of AIPS|work=AIPS Memo|issue=100|institution=NRAO|pages=11-13|date=1998}}</ref>\n\n==See also==\n* [[IRAF]] - package for processing data from optical telescopes\n* [[Starlink Project|Starlink]] - package similar to IRAF, but developed for UK astronomers\n\n{{Portal|Astronomy}}\n\n==References==\n{{Reflist}}\n\n==External links==\n* [http://www.aips.nrao.edu/cook.html AIPS Cookbook]\n* [http://www.jive.nl/jivewiki/doku.php?id=parseltongue:parseltongue ParselTongue Wiki]\n* [http://www.linuxjournal.com/article/4040 Article in Linux Journal]\n* [https://casa.nrao.edu/ CASA home page]\n\n[[Category:Radio astronomy]]\n[[Category:Interferometry]]\n[[Category:Astronomical imaging]]\n[[Category:Astronomy software]]\n[[Category:Fortran software]]"
    },
    {
      "title": "CHARMM",
      "url": "https://en.wikipedia.org/wiki/CHARMM",
      "text": "{{Infobox software\n|name                   = CHARMM\n|logo                   = \n|screenshot             = \n|caption                = \n|developer              = [[Martin Karplus]], [[Accelrys]]\n|released               = {{Start date and age|1983}}\n|latest release version = c40b1, c40b2\n|latest release date    = {{Start date and age|2015|df=yes}}\n|latest preview version = c41a1, c41a2\n|latest preview date    = {{Start date and age|2015|df=yes}}\n|status                 = Active\n|programming language   = [[FORTRAN]] 77-95, [[CUDA]]\n|operating system       = [[Unix-like]]: [[Linux]], [[macOS]], [[IBM AIX|AIX]], [[iOS]]<ref name=\"OS+platforms\">{{cite web |url=https://www.charmm.org/charmm/documentation/installation/ |title=Installation |author=<!--Staff writer(s); no by-line.--> |date=2016 |website=CHARMM (Chemistry at HARvard Macromolecular Mechanics) |publisher=Harvard University |access-date=14 November 2016}}</ref>\n|platform               = [[x86]], [[ARM architecture|ARM]], [[Nvidia]] [[Graphics processing unit|GPU]]; [[Cray]] [[Cray XT4|XT4]], [[Cray XT5|XT5]]<ref name=\"OS+platforms\" />\n|size                   = \n|language               = English\n|genre                  = [[Molecular dynamics]]\n|license                = [[Proprietary software|Proprietary]]\n|website                = {{URL|www.charmm.org}}\n}}\n'''Chemistry at Harvard Macromolecular Mechanics''' ('''CHARMM''') is the name of a widely used set of [[force field (chemistry)|force field]]s for [[molecular dynamics]], and the name for the molecular dynamics simulation and analysis computer [[software]] package associated with them.<ref name=Brooks1983>{{cite journal |vauthors=Brooks BR, Bruccoleri RE, Olafson BD, States DJ, Swaminathan S, Karplus M |title=CHARMM: A program for macromolecular energy, minimization, and dynamics calculations |journal=J. Comput. Chem. |volume=4 |issue= 2 |pages=187–217 |year=1983 |doi=10.1002/jcc.540040211}}</ref><ref>{{cite encyclopedia |last=MacKerell |first=A.D., Jr. |author2=Brooks, B. |author3=Brooks, C. L., III |author4=Nilsson, L. |author5=Roux, B. |author6=Won, Y. |author7=Karplus, M. |title=CHARMM: The Energy Function and Its Parameterization with an Overview of the Program |encyclopedia=The Encyclopedia of Computational Chemistry |volume=1 |pages=271–277 |editor=Schleyer, P.v.R. |publisher=John Wiley & Sons |location=Chichester |year=1998|display-editors=etal}}</ref><ref>{{cite journal |vauthors=Brooks BR, Brooks CL 3rd, Mackerell AD Jr, Nilsson L, Petrella RJ, Roux B, Won Y, Archontis G, Bartels C, Boresch S, Caflisch A, Caves L, Cui Q, Dinner AR, Feig M, Fischer S, Gao J, Hodoscek M, Im W, Kuczera K, Lazaridis T, Ma J, Ovchinnikov V, Paci E, Pastor RW, Post CB, Pu JZ, Schaefer M, Tidor B, Venable RM, Woodcock HL, Wu X, Yang W, York DM, Karplus M |title=CHARMM: The biomolecular simulation program |journal=Journal of Computational Chemistry |date=29 July 2009 |volume=30 |issue=10 |pages=1545–1614 |doi=10.1002/jcc.21287 |pmid=19444816 |pmc=2810661}}</ref> The CHARMM Development Project involves a worldwide network of developers working with [[Martin Karplus]] and his group at [[Harvard]] to develop and maintain the CHARMM program. Licenses for this software are available, for a fee, to people and groups working in academia.\n\n== Force fields ==\n\nThe CHARMM [[force field (chemistry)|force field]]s for proteins include: united-atom (sometimes termed ''extended atom'') CHARMM19,<ref name=Reiher1985>{{cite journal |author=Reiher, III WH |title=Theoretical studies of hydrogen bonding |journal=PhD Thesis at Harvard University| year=1985}}</ref> all-atom CHARMM22<ref name=MacKerell1998>{{cite journal |author=MacKerell AD Jr| year=1998 |title=All-atom empirical potential for molecular modeling and dynamics studies of proteins |journal=J Phys Chem B |volume=102 |issue=18 |pages=3586–3616 |doi=10.1021/jp973084f|display-authors=etal}}</ref> and its dihedral potential corrected variant CHARMM22/CMAP.<ref name=MacKerell2004a>{{cite journal |vauthors=MacKerell AD Jr, Feig M, Brooks III CL |year=2004 |title=Extending the treatment of backbone energetics in protein force fields: limitations of gas-phase quantum mechanics in reproducing protein conformational distributions in molecular dynamics simulations |journal=J Comput Chem |volume=25 |pages=1400–1415 |doi=10.1002/jcc.20065 |pmid=15185334 |issue=11}}</ref> In the CHARMM22 protein force field, the atomic partial charges were derived from quantum chemical calculations of the interactions between model compounds and water. Furthermore, CHARMM22 is parametrized for the TIP3P explicit [[water model]]. Nevertheless, it is often used with [[implicit solvent]]s. In 2006, a special version of CHARMM22/CMAP was reparametrized for consistent use with implicit solvent GBSW.<ref name=Brooks2006>{{cite journal |vauthors=Brooks CL, Chen J, Im W |year=2006 |title=Balancing solvation and intramolecular interactions: toward a consistent generalized born force field (CMAP opt. for GBSW) |journal=J Am Chem Soc |volume=128 |pages=3728–3736 |doi=10.1021/ja057216r |pmid=16536547 |issue=11 |pmc=2596729}}</ref>\n\nFor [[DNA]], [[RNA]], and [[lipid]]s, CHARMM27<ref name=MacKerell2001>{{cite journal |vauthors=MacKerell AD Jr, Banavali N, Foloppe N |year=2001 |title=Development and current status of the CHARMM force field for nucleic acids |journal=Biopolymers |volume=56 |pages=257–265 |doi=10.1002/1097-0282(2000)56:4<257::AID-BIP10029>3.0.CO;2-W |pmid=11754339 |issue=4}}</ref> is used. Some force fields may be combined, for example CHARMM22 and CHARMM27 for the simulation of protein-DNA binding. Also, parameters for NAD+, sugars, fluorinated compounds, etc., may be downloaded. These force field version numbers refer to the CHARMM version where they first appeared, but may of course be used with subsequent versions of the CHARMM executable program. Likewise, these force fields may be used within other molecular dynamics programs that support them.\n\nIn 2009, a general force field for drug-like molecules (CGenFF) was introduced. It \"covers a wide range of chemical groups present in biomolecules and drug-like molecules, including a large number of heterocyclic scaffolds\".<ref name=Vanommeslaeghe>{{cite journal |vauthors=Vanommeslaeghe K, Hatcher E, Acharya C, Kundu S, Zhong S, Shim J, Darian E, Guvench O, Lopes P, Vorobyov I, ((Mackerell AD Jr)) |year=2009 |title=CHARMM general force field: A force field for drug-like molecules compatible with the CHARMM all-atom additive biological force fields |journal=J Comput Chem |volume= 31| pages= 671–90| doi=10.1002/jcc.21367 |pmc=2888302 |pmid=19575467 |issue=4}}</ref> The general force field is designed to cover any combination of chemical groups. This inevitably comes with a decrease in accuracy for representing any particular subclass of molecules. Users are repeatedly warned in Mackerell's website not to use the CGenFF parameters for molecules for which specialized force fields already exist (as mentioned above for proteins, nucleic acids, etc.).\n\nCHARMM also includes polarizable force fields using two approaches. One is based on the fluctuating charge (FQ) model, also termed Charge Equilibration (CHEQ).<ref name=Patel2004a>{{cite journal |vauthors=Patel S, Brooks CL 3rd |year=2004 |title=CHARMM fluctuating charge force field for proteins: I parameterization and application to bulk organic liquid simulations |journal=J Comput Chem |volume=25 |pages=1–15 |doi=10.1002/jcc.10355 |pmid=14634989 |issue=1}}</ref><ref name=Patel2004b>{{cite journal |vauthors=Patel S, Mackerell AD Jr, Brooks CL 3rd |year=2004 |title=CHARMM fluctuating charge force field for proteins: II protein/solvent properties from molecular dynamics simulations using a nonadditive electrostatic model |journal=J Comput Chem |volume=25 |pages=1504–1514 |doi=10.1002/jcc.20077 |pmid=15224394 |issue=12}}</ref> The other is based on the [[Drude particle|Drude]] shell or dispersion oscillator model.<ref name=\"Lamoureux\">{{cite journal |vauthors=Lamoureux G, Roux B |year=2003 |title=Modeling induced polarization with classical Drude oscillators: Theory and molecular dynamics simulation algorithm |journal=J Chem Phys |volume=119 |issue=6 |pages=3025–3039 |doi=10.1063/1.1589749|bibcode= 2003JChPh.119.3025L}}</ref><ref name=\"Lamoureux3\">{{cite journal |vauthors=Lamoureux G, Harder E, Vorobyov IV, Roux B, MacKerell AD |year=2006 |title=A polarizable model of water for molecular dynamics simulations of biomolecules |journal=Chem Phys Lett |volume=418 |pages=245–249 |doi=10.1016/j.cplett.2005.10.135|bibcode= 2006CPL...418..245L}}</ref>\n\nParameters for all of these force fields may be downloaded from the Mackerell website for free.<ref>[http://mackerell.umaryland.edu/CHARMM_ff_params.html Mackerell website]</ref>\n\n== Molecular dynamics program ==\n\nThe CHARMM program allows generating and analysing a wide range of molecular simulations. The most basic kinds of simulation are minimizing a given structure and production runs of a molecular dynamics trajectory.\n\nMore advanced features include [[free energy perturbation]] (FEP), quasi-harmonic entropy estimation, correlation analysis and combined quantum, and [[quantum mechanics]] - [[molecular mechanics]] ([[QM/MM]]) methods.\n\nCHARMM is one of the oldest programs for molecular dynamics. It has accumulated many features, some of which are duplicated under several keywords with slight variants. This is an inevitable result of the many outlooks and groups working on CHARMM worldwide. The [https://web.archive.org/web/20070907000754/http://www.charmm.org/package/changelogs/c34log.shtml changelog file], and CHARMM's source code, are good places to look for the names and affiliations of the main developers. The involvement and coordination by [[Charles L. Brooks III]]'s group at the [[University of Michigan]] is salient.\n\n== Software history ==\n\nAround 1969, there was considerable interest in developing potential energy functions for small molecules. CHARMM originated at [[Martin Karplus]]'s group at Harvard. Karplus and his then graduate student Bruce Gelin decided the time was ripe to develop a program that would make it possible to take a given amino acid sequence and a set of coordinates (e.g., from the X-ray structure) and to use this information to calculate the energy of the system as a function of the atomic positions. Karplus has acknowledged the importance of major inputs in the development of the (at the time nameless) program, including:\n\n*Schneior Lifson's group at the Weizmann Institute, especially from [[Arieh Warshel]] who went to Harvard and brought his consistent force field ('''CFF''') program with him\n*[[Harold Scheraga]]'s group at Cornell University\n*Awareness of [[Michael Levitt]]'s pioneering energy calculations for proteins\n\nIn the 1980s, finally a paper appeared and CHARMM made its public début. Gelin's program had by then been considerably restructured. For the publication, Bob Bruccoleri came up with the name HARMM (HARvard Macromolecular Mechanics), but it seemed inappropriate. So they added a C for Chemistry. Karplus said: \"''I sometimes wonder if Bruccoleri's original suggestion would have served as a useful warning to inexperienced scientists working with the program.''\"<ref name=Karplus2006>{{cite journal |author=Karplus M |year=2006 |title=Spinach on the ceiling: a theoretical chemist's return to biology |journal=Annu Rev Biophys Biomol Struct |volume=35 |issue=1 |pages=1–47 |doi=10.1146/annurev.biophys.33.110502.133350 |pmid=16689626}}</ref> CHARMM has continued to grow and the latest release of the executable program was made in August 2009 as CHARMM35b3.\n\n== Running CHARMM under Unix-Linux ==\nThe general syntax for using the program is:\n\n<code>charmm -i filename.inp -o filename.out</code>\n\n* <code>charmm</code> – The name of the program (or script which runs the program) on the computer system being used.\n* <code>filename.inp</code> – A text file which contains the CHARMM commands. It starts by loading the molecular topologies (top) and [[Force field (chemistry)|force field]] (par). Then one loads the molecular structures' Cartesian coordinates (e.g. from PDB files). One can then modify the molecules (adding hydrogens, changing secondary structure). The calculation section can include energy minimization, dynamics production, and analysis tools such as motion and energy correlations.\n* <code>filename.out</code> – The log file for the CHARMM run, containing echoed commands, and various amounts of command output. The output print level may be increased or decreased in general, and procedures such as minimization and dynamics have printout frequency specifications. The values for temperature, energy pressure, etc. are output at that frequency.\n\n== Volunteer computing ==\n[[Docking@Home]], hosted by University of Delaware, one of the projects which use an [[open-source software|open-source]] platform for the [[distributed computing]], [[BOINC]], used CHARMM to analyze the atomic details of protein-ligand interactions in terms of [[molecular dynamics]] (MD) simulations and minimizations.\n\n[[World Community Grid]], sponsored by IBM, ran a project named The Clean Energy Project<ref>[http://www.worldcommunitygrid.org/projects_showcase/cep1/viewCep1Main.do The Clean Energy Project]</ref> which also used CHARMM in its first phase which has completed.\n\n==See also==\n{{columns-list|colwidth=30em|\n*[[AMBER]]\n*[[Ascalaph Designer]]\n*[[GROMACS]]\n*[[NAMD]]\n*[[Comparison of force field implementations]]\n*[[Comparison of software for molecular mechanics modeling]]\n*[[MacroModel]]\n*[[MDynaMix]]\n*[[OPLS]]\n*[[X-PLOR]]\n*[[Yasara]]\n}}\n\n==References==\n{{Reflist|2}}\n\n== External links ==\n* {{Official website|www.charmm.org}}, with [https://www.charmm.org/charmm/documentation/ documentation] and helpful [https://www.charmm.org//ubbthreads/ubbthreads.php?Cat= discussion forums]\n* {{Official website|http://accelrys.com/products/collaborative-science/biovia-discovery-studio/simulations.html}}, BIOVIA\n* [http://www.ch.embnet.org/MD_tutorial/ CHARMM tutorial]\n* [http://www.pharmacy.umaryland.edu/faculty/amackere/ MacKerell] website, hosts package of force field parameters for CHARMM\n* [http://brooks.chem.lsa.umich.edu/ C.Brooks website]\n* [http://yuri.harvard.edu/ CHARMM page at Harvard]\n* [http://thallium.bsd.uchicago.edu/RouxLab/ Roux website]\n* [http://www.lobos.nih.gov/cbs/ Bernard R. Brooks Group website]\n* [http://docking.cis.udel.edu/ Docking@Home]\n* [http://www.charmm-gui.org/ CHARMM-GUI project]\n* [http://www.charmming.org/ CHARMMing (CHARMM Interface and Graphics)]\n* [http://www.charmmtutorial.org/ CHARMM Tutorial]\n\n{{Chemistry software}}\n\n[[Category:Molecular dynamics software]]\n[[Category:Force fields]]\n[[Category:Fortran software]]\n[[Category:Harvard University]]"
    },
    {
      "title": "Cray Time Sharing System",
      "url": "https://en.wikipedia.org/wiki/Cray_Time_Sharing_System",
      "text": "{{Refimprove|date=December 2012}}\n:''This article is about the operating system distributed by Cray Research.  CTSS may also stand for [[Compatible Time Sharing System]], an unrelated operating system developed by the MIT Computation Center.''\n{{Infobox OS\n| name                   = Cray Time Sharing System (CTSS)\n| logo                   = \n| screenshot             = \n| caption                = \n| developer              =  [[Los Alamos National Laboratory|Los Alamos Scientific Laboratory]], [[Lawrence Livermore National Laboratory|Lawrence Livermore Laboratory]]\n| source_model           = \n| kernel_type            = \n| supported_platforms    = [[Cray-1]], [[Cray X-MP]] line\n| ui                     = \n| family                 = \n| released               = \n| latest_release_version = \n| latest_release_date    = \n| latest_test_version    = \n| latest_test_date       = \n| marketing_target       = [[Supercomputer]]s\n| programmed_in          =  \n| prog_language          = \n| language               = [[English language|English]]\n| updatemodel            = \n| package_manager        = \n| working_state          = Historic\n| license                = \n| website                = \n}}\nThe '''Cray Time Sharing System''', also known in the [[Cray]] user community as '''CTSS''', was developed as an [[operating system]] for the [[Cray-1]] or [[Cray X-MP]] line of [[supercomputer]]s. CTSS was developed by the [[Los Alamos National Laboratory|Los Alamos Scientific Laboratory]] (LASL now LANL) in conjunction with the [[Lawrence Livermore National Laboratory|Lawrence Livermore Laboratory]] (LLL now LLNL). CTSS was popular with Cray sites in the [[United States Department of Energy]] (DOE), but was used by several other Cray sites, such as the [[San Diego Supercomputing Center]].<ref>[http://www.the-scientist.com/?articles.view/articleNo/10671/ Supercomputer Centers]</ref>\n\nThe predecessor of CTSS was the [[Livermore Time Sharing System]] (LTSS) which ran on Control Data [[CDC 7600]] line of supercomputers. The first compiler was known as ''LRLTRAN'', for ''[[Lawrence Berkeley National Laboratory|Lawrence Radiation Laboratory]] forTRAN'', a Fortran-66 language but with dynamic memory and other features.  The Cray version, including [[automatic vectorization]], was known as CVC, pronounced \"Civic\" like the Honda car of the period, for [[Cray Vector Compiler]].\n\nSome controversy existed at LASL with the first attempt to develop an operating system for the Cray-1 named [[DEIMOS]], a message-passing, [[Unix-like]] operating system, by [[Forrest Basket]]. DEIMOS had initial \"teething\" problems common to the performance of all early operating systems. This left a bad taste for Unix-like systems at the National Laboratories and with the manufacturer, Cray Research, Inc., of the hardware who went on to develop their own batch oriented operating system, COS ([[Cray Operating System]]) and their own vectorizing Fortran compiler named \"CFT\" ([[Cray ForTran]]) both written in the [[Cray Assembly Language]] (CAL).\n\nCTSS had the misfortune to have certain constants, structures, and lacking certain networking facilities ([[TCP/IP]]) which were optimized to be Cray-1 architecture-dependent without extensive rework when larger memory supercomputers like the Cray-2 and the Cray Y-MP came into use. CTSS has its final breaths running on Cray instruction-set-compatible hardware developed by [[Scientific Computer Systems]] (SCS-40 and SCS-30) and [[Supertek]] S-1, but this did not save the software.\n\nCTSS embodied certain unique ideas such as a market-driven priorities for working/running processes.\n\nAn attempt to succeed CTSS was started by LLNL named NLTSS ([[New Livermore Time Sharing System]]) to embody advanced concepts for operating systems to better integrate communication using a new network protocol named [[LINCS]] while also keeping the best features of CTSS. NLTSS followed the development fate of many operating systems and only briefly ran on period Cray hardware of the late 1980s.\n\nA user-level CTSS Overview<ref>[http://library.lanl.gov/cgi-bin/getfile?00368787.pdf] CTSS Overview, LA-5525-M, Vol 7</ref> from 1982 provides, in Chapter 2, a brief list of CTSS features. Other references are likely to be found in proceedings of the [[Cray User Group]] (CUG) and the [[Association for Computing Machinery|ACM]] SOSP (Symp. on Operating Systems Proceedings). However, owing to the fact that LANL and LLNL were nuclear weapons facilities, some aspects of security are likely to doom finding out greater detail of many of these pieces of software.\n\n==See also==\n*[[EOS (operating system)]]\n*[[Timeline of operating systems]]\n\n==References==\n{{Reflist}}\n\n[[Category:Cray software]]\n[[Category:Fortran software]]\n[[Category:Time-sharing operating systems]]\n[[Category:Proprietary operating systems]]\n[[Category:Supercomputer operating systems]]"
    },
    {
      "title": "FastContact",
      "url": "https://en.wikipedia.org/wiki/FastContact",
      "text": "{{multiple issues|\n{{notability|Products|date=November 2012}}\n{{primary sources|date=November 2012}}\n{{self-published|date=November 2012}}\n}}\n'''FastContact''' is an algorithm for the rapid estimate of contact and binding [[Thermodynamic free energy|free energies]] for [[Protein-protein interaction prediction|protein-protein complex structures]]. It is based on a statistically determined [[solvation|desolvation]] contact potential and [[Coulomb]] [[electrostatic]]s with a distance-dependent [[dielectric constant]]. The application also reports residue contact free energies that rapidly highlight the hotspots of the interaction.\n\nThe programme was written in [[Fortran 77]] by Carlos J. Camacho and Chao Zhang at the Department of Computational Biology, [[University of Pittsburgh]], PA.<ref name=fastcontact>{{cite journal |vauthors=Camacho CJ, Zhang C |title=FastContact: rapid estimate of contact and binding free energies |journal=Bioinformatics |volume=21 |issue=10 |pages=2534–2536 |year=2005 |id= |doi=10.1093/bioinformatics/bti322 |pmid=15713734}}</ref> A web server for running FastContact online or downloading the binary was set up by P. Christoph Champ in July 2005.<ref name=Camacho2006>{{cite journal |vauthors=Camacho CJ, Ma H, Champ PC |title=Scoring a diverse set of high-quality docked conformations: A metascore based on electrostatic and desolvation interactions |journal=Proteins |volume=63 |issue=4 |pages=868–877 |year=2006 |doi=10.1002/prot.20932 |pmid=16506242}}</ref><ref name=Champ2007>{{cite journal |vauthors=Champ PC, Camacho CJ |title=FastContact: a free energy scoring tool for protein-protein complex structures |journal=Nucleic Acids Res |issue=Web addition |year=2007 |doi=10.1093/nar/gkm326 |volume=35 |pages=W556–60 |pmid=17537824 |pmc=1933237}}</ref>\n\n== References ==\n{{reflist}}\n\n==External links==\n*[http://structure.pitt.edu/software/FastContact FastContact binaries] &mdash; binaries are freely available for download (with documentation).\n*[http://structure.pitt.edu/servers/fastcontact/ FastContact Server] &mdash; set up by P. Christoph Champ in July 2005.\n*[http://wiki.christophchamp.com/index.php/FastContact FastContact Wiki]\n\n[[Category:Bioinformatics]]\n[[Category:Fortran software]]\n\n\n{{bioinformatics-stub}}"
    },
    {
      "title": "FHI-aims",
      "url": "https://en.wikipedia.org/wiki/FHI-aims",
      "text": "{{short description|Molecular dynamics modelling software}}\n{{Infobox software\n| name                       = FHI-aims\n| logo                       = Aims-logo.png\n| screenshot                 =\n| caption                    =\n| collapsible                =\n| author                     =\n| developer                  = [https://aimsclub.fhi-berlin.mpg.de/aims_people.php FHI-aims developers group]\n| released                   =\n| latest release version     = 171221_1\n| latest release date        = {{release date and age|2018|02|10|df=yes}}\n| latest preview version     =\n| latest preview date        =\n| programming language       = [[Fortran]], [[Message Passing Interface|MPI]]\n| operating system           = [[Linux]]\n| platform                   =\n| size                       =\n| language                   =\n| genre                      = [[Density Functional Theory]] (simulation)\n| license                    = [[Academic]] / [[Commercial software|Commercial]]\n| website                    = {{URL|https://aimsclub.fhi-berlin.mpg.de/}}\n}}\n\n'''FHI-aims''' (Fritz Haber Institute ab initio molecular simulations) is a [[Shared Source Initiative|shared-source]] software package for computational molecular and materials science written in [[Fortran]]. It uses [[density functional theory]] and [[many-body perturbation theory]] to simulate chemical and physical properties of atoms, molecules, nanostructures, soldis, and surfaces. Originally developed at the [[Fritz Haber Institute]] in [[Berlin]] the ongoing development of the FHI-aims source code is now driven by a world-wide community of collaborating research institutions.<ref>{{cite web|url=https://aimsclub.fhi-berlin.mpg.de/aims_people.php|title=The FHI-aims developers group}}</ref>\n\n== Overview ==\n\nThe FHI-aims software package is an all-electron, full-potential [[electronic structure]] code utilizing numeric atom-centered [[Basis set (chemistry)|basis functions]] for its electronic structure calculations. The localized basis set enables the accurate treatment of all electrons on the same footing in [[Periodic boundary conditions|periodic]] and non-periodic systems without relying on approximation for the [[Core electron|core states]], such as [[pseudopotential]]s. Importantly, the basis sets enable high numerical accuracy on par with the best available all-electron reference methods while remaining scalable to system sizes up to several thousands of atoms. The workload of the simulations is efficiently distributable for [[parallel computing]] using the [[Message Passing Interface|MPI]] communication protocol. The code is routinely used on platforms ranging from laptops to distributed-parallel supercomputers with ten thousands of CPUs and the scalability of the code has been tested up to 100,000's of CPUs.<ref>{{cite web|url=http://juser.fz-juelich.de/record/15866/files/ib-2011-02.pdf|title=Scaling of Eigenvalue Solver Dominated Simulations, in: Juelich Blue Gene/P Extreme Scaling Workshop 2011|author=R. Johanni, A. Marek, H. Lederer, and V. Blum}}</ref>\n\nThe primary production method of FHI-aims is [[Kohn–Sham equations|Kohn-Sham]] [[density functional theory]].<ref>{{cite web|url=https://aimsclub.fhi-berlin.mpg.de/index.php|title=FHI-aims home page}}</ref> For the [[Exchange interaction|exchange]]-[[Electron correlation|correlation]] treatment, local ([[Local-density approximation|LDA]]), semi-local (e.g., PBE, PBEsol), meta-GGA, and [[Hybrid functional|hybrid]] (e.g., HSE06, B3LYP) functionals have been implemented. The resulting Kohn-Sham orbitals can be used within the framework of many-body perturbation theory, such as [[Møller-Plesset perturbation theory]] or the [[GW approximation]]. Moreover, thermodynamic properties of the molecules and solids are accessible via Born-Oppenheimer molecular dynamics and [[Path integral molecular dynamics|path integral]] [[molecular dynamics]] methods.\n\n== History ==\nThe first line of code of the actual FHI-aims code was written in late 2004, using the atomic solver employed in the Fritz Haber Institute pseudopotential program package fhi98PP as a foundation to obtain radial functions for use as basis functions. The first developments benefitted heavily from the excellent set of numerical technologies described in several publications by Bernard Delley<ref>{{cite journal|last1=Delley|first1=B.|doi=10.1063/1.458452|journal=J. Chem. Phys. |title=An all‐electron numerical method for solving the local density functional for polyatomic molecules|date=1998|volume=92|issue=1|page=508}}\n</ref><ref>{{cite journal|last1=Delley|first1=B.|journal=J. Phys. Chem.|doi=10.1021/jp952713n |title=Fast Calculation of Electrostatics in Crystals and Large Molecules|date=1996|volume=100|issue=15|pages=6107–6110}}\n</ref> and coworkers in the context of the [[DMol3]] code,<ref>{{cite journal|doi=10.1063/1.1316015|last1=Delley|first1=B.|journal=J. Chem. Phys.|title=From molecules to solids with the DMol3 approach|date=2000|volume=113|issue=18|page=7756}}</ref> as well as from many broader methodological developments published in the electronic structure theory community over the years. Initial efforts in FHI-aims focused on developing a complete numeric atom-centered basis set library for density-functional theory from \"light\" to highly accurate (few meV/atom) accuracy for total energies, available for all relevant elements (Z=1-102) across the periodic table.<ref>{{cite journal|doi=10.1016/j.cpc.2009.06.022|last1=Blum|first1=Volker|last2=Gehrke|first2=Ralf.|last3=Hanke|first3=Felix|last4=Havu|first4=Paula|display-authors=3 |journal=Comp. Phys. Commun.|title=Ab initio molecular simulations with numeric atom-centered orbitals|date=2009|volume=180|issue=11|pages=2175–2196}}</ref>\n\nBy 2006, work on parallel functionality, support for periodic boundary conditions, total energy gradients (forces) and on exact exchange and many-body perturbation theory had commenced. On May 18, 2009, an initial formal point release of the code, \"051809\", was made available and laid the foundation for broadening the user and developer base of the code.\n\n== See also ==\n\n* [[List of quantum chemistry and solid-state physics software]]\n\n== References ==\n{{reflist}}\n\n\n\n[[Category:Fortran software]]\n[[Category:Computational chemistry software]]\n[[Category:Computational physics]]\n[[Category:Density functional theory software]]\n[[Category:Physics software]]"
    },
    {
      "title": "Genstat",
      "url": "https://en.wikipedia.org/wiki/Genstat",
      "text": "{{multiple issues|\n{{primary sources|date=November 2012}}\n{{COI|date=November 2016}}\n{{advert|date=November 2016}}\n}}\n{{Infobox Software\n|name                       = Genstat\n|logo                       = Genstat_interface.gif\n|screenshot                 = \n|caption                    = \n|collapsible                = \n|author                     = [[John Nelder]]\n|developer                  = VSN International (VSNi)\n|released                   = <!-- {{Start date|YYYY|MM|DD}} -->\n|discontinued               = \n|latest release version     = 19.1\n|latest release date        = {{Start date and age|2017|12}}<ref>[https://genstat.kb.vsni.co.uk/article-categories/whats_new/ What's New].</ref>\n|latest preview version     = \n|latest preview date        = <!-- {{Start date and age|YYYY|MM|DD}} -->\n|programming language       = \n|operating system           = [[Microsoft Windows|Windows]]\n|platform                   = \n|size                       =\n|language                   = English\n|status                     = \n|genre                      = [[Statistical package]]\n|licence                    = proprietary\n|website                    = {{URL|www.vsni.co.uk/software/Genstat}}\n}}\n'''Genstat (General Statistics)''' is a [[List of statistical packages|statistical software package]] with data analysis capabilities, particularly in the field of agriculture.<ref>{{Cite web|url=http://www.agronomix.com/Corporate/GenStat.aspx|title=AGRONOMIX Software inc., Software for plant breeding|last=|first=|date=|website=|publisher=|access-date=}}</ref><ref>{{Cite web|url=http://www2.warwick.ac.uk/services/ldc/researchers/opportunities/development_support/mathstats/additional_resources/software_list/genstat/|title=The university of WARWICK|last=|first=|date=|website=|publisher=|access-date=}}</ref>\n\nSince 1968, it has been developed by many scientific experts in [[Rothamsted Research]], and has a user-friendly interface,<ref>{{Cite book|title=The multivariate Social Scientist|last=|first=|publisher=|year=|isbn=|location=|pages=|quote=|via=}}</ref> professional [[modular design]], excellent [[Mixed model|linear mixed models]]<ref>{{Cite book|title=Mixed Models and Multilevel Data Structures in Agriculture|last=|first=|publisher=|year=|isbn=|location=|pages=|quote=|via=}}</ref> and graphic functions. Leading Genstat’s continued development and distribution is VSN International (VSNi),<ref>{{Cite web|url=http://www.vsni.co.uk/|title=VSNi|last=|first=|date=|website=|publisher=|access-date=}}</ref> which is owned by The [[Numerical Algorithms Group]] and [[Rothamsted Research]].\n\nGenstat is used in a number of research areas, including [[plant science]], [[forestry]], [[animal science]], and [[medicine]],<ref>{{Cite web|url=http://www2.warwick.ac.uk/services/ldc/researchers/opportunities/development_support/mathstats/additional_resources/software_list/genstat/|title=The university of WARWICK|last=|first=|date=|website=|publisher=|access-date=}}</ref> and is recognized by several world-class universities and enterprises.\n\n== Applications ==\nGenstat’s statistical software can be applied to the following user areas:\n* [[Agriculture]] (Animal and Plant)\n* [[Biology]], [[Genetics]]\n* [[Ecology]], [[Natural environment|Environment]] (Forestry and Soil)\n* [[Food science|Food Science]]\n* [[Medicine|Medical]] and [[Pharmaceutical drug|Pharmaceutical]]\n* [[Finance]]\n* [[Industry]], [[Engineering]]\n* [[Statistics]] and [[Mathematics]]\n\n== Software product ==\n[[File:Statistical methods in Genstat.jpg|thumb|260x260px|Genstat includes statistical methods such as statistical tests, ANOVA, regression analysis, REML, etc.]]\n\n=== Statistical features ===\n* Manage data on Genstat’s own spreadsheet (vector, scalar, table, matrix);\n* Compatible with Excel spreadsheets (import/export);\n* Illustrate data with graphics such as [[histogram]]s, [[Box plot|boxplots]], [[scatter plot]]s, [[Line graph of a hypergraph|line graphs]], trellis plots, contour 3-dimensional surface plots, Kernel plots, species, [[Variogram]], [[Regular grid]], [[Irregular grid]], circular plots and [[polar plot]]s;\n* Summarize and compare data with tabular reports, fitted [[Probability distribution|distribution]]s, and [[Statistical hypothesis testing|standard tests]], such as [[Student's t-test|t-tests]], [[Chi-squared test|Chi-square tests]], [[ANOVA]], [[regression analysis|regression]], and various [[Nonparametric statistics|nonparametric tests]];\n* Transform data using a general calculation facility with a wide range of mathematical and statistical functions;\n* Model relationships between variables by linear or nonlinear [[regression analysis|regression]], [[generalized linear model]]s, [[generalized additive model]]s, [[generalized linear mixed model]]s or [[hierarchical generalized linear model]]s, [[Logistic regression|Logistics regression]], Multinomial [[Regression analysis|regression]];\n* Analyze experimental Design, ranging from [[One-way analysis of variance|One-Way ANOVA]], [[Two-way analysis of variance|Two-way ANOVA]], [[Factorial experiment|Factorial Design]], complex designs with several sources of error variation, using a balanced-[[ANOVA]] or a [[Reml|REML]] approach (including the modeling of correlation structures);\n* Design investigations deciding on the sample size, or numbers of replicates, required to detect the anticipated treatment effects;\n* Identify patterns in data by means of Multivariate techniques such as Canonical Variates Analysis, [[Discriminant analysis (in marketing)|Discriminant Analysis]], [[Factor analysis|Factor Analysis]], [[Cluster analysis|Cluster Analysis]], [[Principal component analysis|Principal Components Analysis]], [[principal coordinates analysis]], [[Multivariate analysis of variance|MANOVA]], [[correspondence analysis]], [[Partial least squares regression|partial least squares]], [[classification trees]] and [[cluster analysis]];\n* Analyze results from [[Stratified sampling|Stratified Sampling]] or from Unstructured surveys, Simple Random Sampling, [[Cluster sampling]];\n* Analyze [[Six Sigma]], plot Control charts, print Pareto tables and calculate capability statistics;\n* Analyze [[Time series|Time Series]], using Box-Jenkins Models or spectral analysis, Moving Average, ARIMA, Season Models;\n* Analyze repeated measurements, by profile plot, analysis of variance, Multivariate, Generalized Estimating Equations, or using ante dependence structure, or by modeling the correlation over time;\n* Analyze spatial patterns, using Variogram, Kriging, Automatic Analysis of Row-Column Design, Incomplete Block Design, or spatial point processes.\n\n== See also ==\n* [[ASReml]] - is a statistical package which fits linear mixed models to large data sets with complex variance models using Residual Maximum Likelihood (REML).\n* BMS – Breeding Management Systems\n\n==References==\n{{reflist}}\n\n==Further reading==\n{{Cite journal | doi = 10.1002/wics.32 | title = Genstat | year = 2009 | last1 = Payne | first1 = R. W. | journal = Wiley Interdisciplinary Reviews: Computational Statistics | volume = 1 | issue = 2 | pages = 255–258}}\n\n==External links==\n*[http://www.vsni.co.uk/software/Genstat/ Genstat homepage.] VSN International (VSNi).\n\n{{Statistical software}}\n\n[[Category:Fortran software]]\n[[Category:Statistical software]]\n[[Category:Windows-only software]]\n[[Category:Biostatistics]]\n\n\n{{Windows-software-stub}}"
    },
    {
      "title": "GROMOS",
      "url": "https://en.wikipedia.org/wiki/GROMOS",
      "text": "{{technical|date=November 2012}}\n\n{{Infobox software\n|name                   = GROMOS\n|logo                   = \n|screenshot             = \n|caption                = \n|developer              = Wilfred van Gunsteren. Philippe Hünenberger, Sereina Riniker, Chris Oostenbrink\n|released               = {{Start date and age|1978}}\n|latest release version = GROMOS 11 v1.3.0\n|latest release date    = {{Start date and age|2011|05|df=yes}}\n|latest preview version = \n|latest preview date    = <!--{{Start date and age|yyyy|mm|dd|df=yes}}-->\n|programming language   = [[Fortran]] <= 1996,<br />[[C++]] => 2011\n|operating system       = [[Unix-like]]\n|platform               = [[x86]]\n|size                   = \n|language               = English\n|genre                  = [[Molecular dynamics]]\n|license                = [[Proprietary software|Proprietary]]\n|website                = {{URL|www.gromos.net}}\n}}\n\n'''GROMOS''' is the name of a [[Force field (chemistry)|force field]] for [[molecular dynamics]] [[simulation]], and a related computer [[software]] package. Both are developed at the [[University of Groningen]], and at the Computer-Aided Chemistry Group<ref>[http://www.igc.ethz.ch Computer-Aided Chemistry Group, ETH Zurich]</ref> at the Laboratory for Physical Chemistry<ref>[http://www.lpc.ethz.ch Laboratory for Physical Chemistry, ETH Zurich]</ref> at the Swiss Federal Institute of Technology ([[ETH Zurich]]). At Groningen, [[Herman Berendsen]] was involved in its development.<ref>{{cite web|author= |url=http://www.cecam.org/bja_prize.html |title=Berni J. Alder CECAM Prize |publisher=Centre européen de calcul atomique et moléculaire |date= |accessdate=25 April 2016}}</ref>\n\nThe united atom force field was optimized with respect to the condensed phase properties of [[alkane]]s.\n\n== Versions ==\n\n=== GROMOS87 ===\nAliphatic and aromatic [[hydrogen]] atoms were included implicitly by representing the [[carbon]] atom and attached hydrogen atoms as one group centered on the carbon atom, a united atom force field. The [[van der Waals force]] parameters were derived from calculations of the crystal structures of [[hydrocarbon]]s, and on [[amino acid]]s using short (0.8&nbsp;nm) nonbonded cutoff radii.<ref>W. F. van Gunsteren and H. J. C. Berendsen, ''Groningen Molecular Simulation (GROMOS) Library Manual'', BIOMOS b.v., Groningen, 1987.</ref>\n\n=== GROMOS96 ===\nIn 1996, a substantial rewrite of the software package was released.<ref>van Gunsteren, W. F.; Billeter, S. R.; Eising, A. A.; Hünenberger, P. H.; Krüger, P.; Mark, A. E.; Scott, W. R. P.; Tironi, I. G. ''Biomolecular Simulation: The GROMOS96 Manual and User Guide''; vdf Hochschulverlag AG an der ETH Zürich and BIOMOS b.v.: Zürich, Groningen, 1996.</ref><ref>\"The GROMOS Biomolecular Simulation Program Package\", W. R. P. Scott, P. H. Huenenberger, I. G. Tironi, A. E. Mark, S. R. Billeter, J. Fennen, A. E. Torda, T. Huber, P. Krueger and W. F. van Gunsteren. ''J. Phys. Chem. A'', '''103''', 3596–3607.</ref> The force field was also improved, e.g., in the following way: aliphatic CH<sub>n</sub> groups were represented as united atoms with van der Waals interactions reparametrized on the basis of a series of molecular dynamics simulations of model liquid [[alkane]]s using long (1.4&nbsp;nm) nonbonded cutoff radii.<ref>\"An improved GROMOS96 force field for aliphatic hydrocarbons in the condensed phase\". ''Journal of Computational Chemistry'' 22 (11), August 2001, 1205–1218 by Lukas D. Schuler, Xavier Daura, Wilfred F. van Gunsteren.</ref> This version is continually being refined and several different parameter sets are available. GROMOS96 includes studies of molecular dynamics, stochastic dynamics, and energy minimization. The energy component was also part of the prior GROMOS, named GROMOS87. GROMOS96 was planned and conceived during a time of 20 months. The package is made of 40 different programs, each with a different essential function. An example of two important programs within the GROMOS96 are PROGMT, in charge of constructing molecular topology and also PROPMT, changing the classical molecular topology into the path-integral molecular topology.\n\n=== GROMOS05 ===\nAn updated version of the software package was introduced in 2005.<ref>\"The GROMOS software for biomolecular simulation: GROMOS05\". Christen M, Hünenberger PH, Bakowies D, Baron R, Bürgi R, Geerke DP, Heinz TN, Kastenholz MA, Kräutler V, Oostenbrink C, Peter C, Trzesniak D, van Gunsteren WF. ''J Comput Chem 26'' (16): 1719–51 {{PMID|16211540}}</ref>\n\n=== GROMOS11 ===\nThe current GROMOS release is dated in May 2011.\n\n== Parameter sets ==\nSome of the [[Force field (chemistry)|force field]] parameter sets that are based on the GROMOS force field. The A-version applies to aqueous or [[Hydrophobe|apolar]] solutions of [[protein]]s, [[nucleotide]]s, and [[sugar]]s. The B-version applies to isolated [[molecule]]s (gas phase).\n\n=== 54 ===\n* 54A7<ref name=\"Schmid2011\">Schmid N., Eichenberger A., Choutko A., Riniker S., Winger M., Mark A. & van Gunsteren W., \"Definition and testing of the GROMOS force-field versions 54A7 and 54B7\", ''European Biophysics Journal'', '''40(7)''', (2011), 843–856 [https://dx.doi.org/10.1007/s00249-011-0700-9].</ref> - 53A6 taken and adjusted torsional angle terms to better reproduce helical propensities, altered N–H, C=O repulsion, new CH<sub>3</sub> charge group, parameterisation of Na<sup>+</sup> and Cl<sup>−</sup> to improve free energy of hydration and new improper dihedrals.\n* 54B7<ref name=\"Schmid2011\"/> - 53B6 ''in vacuo'' taken and changed in same manner as 53A6 to 54A7.\n\n=== 53 ===\n* 53A5<ref name=\"Oostenbrink2004\">Oostenbrink C., Villa, A., Mark, A. E., and van Gunsteren, W., \"A biomolecular force field based on the free enthalpy of hydration and solvation: the GROMOS force-field parameter sets 53A5 and 53A6\", ''Journal of Computational Chemistry'', '''25''', (2004), 1656–1676 [https://dx.doi.org/10.1002/Jcc.20090].</ref> - optimised by first fitting to reproduce the thermodynamic properties of pure liquids of a range of small polar molecules and the solvation free enthalpies of amino acid analogs in cyclohexane, is an expansion and renumbering of 45A3.\n* 53A6<ref name=\"Oostenbrink2004\"/> - 53A5 taken and adjusted partial charges to reproduce hydration free enthalpies in water, recommended for simulations of biomolecules in explicit water.\n\n=== 45 ===\n* 45A3<ref name=\"Shuler2001\">Schuler, L. D., Daura, X., and van Gusteren, W. F., An improved GROMOS96 force field for aliphatic hydrocarbons in the condensed phase, ''Journal of Computational Chemistry'' '''22(11)''', (2001), 1205–1218 [https://dx.doi.org/10.1002/jcc.1078].</ref> - suitable to apply to [[lipid]] aggregates such as [[membrane]]s and [[micelle]]s, for mixed systems of aliphatics with or without water, for [[polymer]]s, and other apolar systems that may interact with different biomolecules.\n* 45A4<ref name=\"Soares2005\">Soares, T. A., Hünenberger, P. H., Kastenholz, M. A., Kräutler, V., Lenz, T., Lins, R. D., Oostenbrink, C., and van Gunsteren, W. F., An improved nucleic acid parameter set for the GROMOS force field, ''Journal of Computational Chemistry'', '''26(7)''', (2005), 725–737, [https://dx.doi.org/10.1002/jcc.20193].</ref> - 45A3 reparameterised to improve [[DNA]] representation.\n\n=== 43 ===\n* 43A1<ref name=\"G96Manual\">van Gunsteren, W. F., Billeter, S. R., Eking, A. A., Hiinenberger, P. H., Kriiger, P., Mark, A. E., Scott, W. R. P. and Tironi, I. G., ''Biomolecular Simulation, The GROMOS96 Manual and User Guide'', vdf Hochschulverlag AG an der ETH Ziirich and BIOMOS b.v., Zurich, Groningen, 1996.</ref>\n* 43A2<ref name=\"G96Manual\"/>\n\n== See also ==\n* [[GROMACS]]\n* [[Ascalaph Designer]]\n* [[Comparison of software for molecular mechanics modeling]]\n* [[Comparison of force field implementations]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* {{Official website|www.gromos.net}}\n\n{{Chemistry software}}\n\n{{DEFAULTSORT:Gromos}}\n[[Category:C++ software]]\n[[Category:Fortran software]]\n[[Category:Molecular dynamics software]]\n[[Category:Force fields]]"
    },
    {
      "title": "HEC-1",
      "url": "https://en.wikipedia.org/wiki/HEC-1",
      "text": "{{multiple issues|\n{{notability|date=November 2012}}\n{{primary sources|date=November 2012}}\n{{self-published|date=November 2012}}\n}}\n{{About|the software|the computer|Hollerith Electronic Computer}}\n'''HEC-1''' is [[software]] that was developed by the [[US Army Corps of Engineers]]<ref>{{cite web| url=http://www.hec.usace.army.mil/software/legacysoftware/legacysoftware.html | title=Army Corps of Engineers | website=www.hec.usace.army.mil }}</ref> to estimate river flows as a result of rainfall.  It was written in the [[FORTRAN]] language and until 1984 could only be run on a [[mainframe computer]].\n\nWhen [[desktop computer]]s became popular the program was ported to the [[Personal Computer|PC]].<ref>{{cite web| url=http://www.hec-1.com/ | title=HEC-1 | website=www.hec-1.com }}</ref>  [[Engineer]]s and [[scientist]]s still use it today because of its ability to model a wide range of natural [[hydrology|hydrologic]] systems.{{fact|date=January 2018}}\n\n==References==\n{{reflist}}\n\n==External links==\n* [https://www.hec.usace.army.mil/ HEC-1 website]\n* [http://www.ce.utexas.edu/prof/maidment/grad/kaough/webpage/public_html/termhtml/termhtm1.htm A Study of Hydrologic Simulation Models]\n* [http://www.hec.usace.army.mil/software/legacysoftware/legacysoftware.html Army Hydrologic Engineering Center]\n\n[[Category:Year of introduction missing]]\n[[Category:Fortran software]]\n[[Category:Hydrology software]]\n\n{{software-stub}}"
    },
    {
      "title": "Hopsan",
      "url": "https://en.wikipedia.org/wiki/Hopsan",
      "text": "{{multiple issues|\n{{notability|Products|date=November 2012}}\n{{primary sources|date=November 2012}}\n{{self-published|date=November 2012}}\n}}\n{{Infobox Software\n| name                   = Hopsan\n| screenshot             = HopsanNG Screenshot.png\n| screenshot size        = 350px\n| caption                = A position servo with dynamic pressure feedback modelled in Hopsan\n| developer              = [[Division of Fluid and Mechatronic Systems]], [[Linköping University]]\n| released               = 2011\n| latest_release_version = 2.9.0\n| latest release date    = {{start date and age|2018|07|02}}\n| programming language   = [[C++]]\n| platform               = [[Cross-platform]]\n| language               = [[English language|English]]\n| genre                  = [[Mathematical model|modeling]], [[Computer Simulation|simulation]], [[Optimization (mathematics)|optimization]]\n| license                = [[GNU General Public License]]\n| website                = [https://liu.se/en/research/hopsan Hopsan website]\n}}\n\n'''Hopsan''' is a free [[Computer Simulation|simulation]] environment for [[Fluid power|fluid]] and [[Mechatronics|mechatronic]] systems, developed at [[Linköping University]]. Although originally developed for simulation of fluid power systems, it has also been adopted for other domains such as [[electric power]], [[flight dynamics]], and [[vehicle dynamics]]. It uses [[bi-directional delay line]]s (or transmission line elements) to connect different components.\n\n==History==\nThe development on Hopsan first began in 1977<ref name=\"HOPSANWebsite\">{{cite web | url=http://www.iei.liu.se/flumes/hopsan?l=en | title= HOPSAN website | accessdate= 2011-02-05}}</ref> at the Division of Hydraulics and Pneumatics at Linköping University. The first version was written in [[FORTRAN]], with a [[drag-and-drop]] [[graphical user interface]] written in [[Visual Basic]]. In addition to the simulation capability it also had features for simulation based [[Optimization (mathematics)|optimization]]. This used the COMPLEX direct search optimization method or a [[Generic programming|generic algorithm]] (GA). It also had features for [[frequency analysis]] and [[transfer function]] analysis, on simulated results. It also supported co-simulation under [[Simulink]]. Component models were written as FORTRAN subroutines. A separate tool called COMPGEN, written in [[Mathematica]],was also developed, which can be used to generate component models in a more straightforward way. In 1991 the method of [[Transmission line modelling|bi-directional delay lines]] (or transmission line modelling TLM) was introduced for system simulation.\n\nIn 2009 the development of the first version of Hopsan was dropped in favor for a brand new generation of the software, written in [[C++]]. This working name of the project is Hopsan NG, and the first [[beta version]] was released in February 2011.<ref name=\"HOPSANWebsite\"/> Parts of the source code in Hopsan was used in the OpenModelica Connection Editor (OMEdit)<ref>{{cite web | url=http://www.openmodelica.org/index.php/developer/tools/165 | title=OMEdit website | accessdate=2011-11-06 }}</ref> in a collaboration with the [[Modelica|OpenModelica]] project.<ref>{{cite thesis|degree=M.Sc.|first1=Syed Adeel|last1=Asghar|first2=Sonia|last2=Tariq|title=Design and Implementation of a User Friendly OpenModelica Graphical Connection Editor|publisher=Linköping University|date=2010}}</ref>\n\n==Program Overview==\nThe current generation of Hopsan consists of two parts, a graphical user interface and a simulation core library. These are completely separated, so that the core can be used stand-alone, for example in [[embedded systems]] or target computers. Everything is precompiled, so that no compilation is required during [[run time (program lifecycle phase)|runtime]]. Custom user models can be created and compiled as separate [[Library (computing)|library]] files, which can be loaded from Hopsan. There is also a built-in automated equation based component generator using Modelica syntax. Models can also be generated from equations by using Mathematica. Numerical optimization can be performed by a built-in tool, using COMPLEX or particle swarm algorithms. It is also possible to perform Monte Carlo sensitivity analysis. The plotting tool is capable of generating frequency spectrums and performing frequency analysis to generate Bode diagrams and Nyquist plots.\n\nHopsan models can be exported to Simulink. Plot data can be exported to [[XML]], [[Comma-separated values|CSV]], [[gnuplot]] and [[Matlab]]. Experiments with including the Hopsan simulation core to [[LabVIEW]] Simulation Interface Toolkit by using a [[wrapper library]] have been successful. Support for model exchange, both import and export, by using the [[Functional Mock-up Interface]] is currently being implemented.\n\nHopsan is a [[cross-platform]] project, with the intention of running on [[Windows]], [[Unix]] and [[Macintosh]] systems. The current beta release is only available for Windows, but the intention is to create versions for the other systems as well. The transmission line element method is very suitable for [[Parallel computing|parallel execution]], due to physically motivated time delays between certain components. Hopsan has support for dividing simulations in separate [[Thread (computer science)|threads]], making it possible to take advantage of [[multicore processor]]s.<ref>{{Cite conference\n  | first1 = R.\n  | last1 = Braun\n  | first2 = P.\n  | last2 = Nordin\n  | first3 = B.\n  | last3 = Eriksson\n  | first4 = P.\n  | last4 = Krus\n  | title = High Performance System Simulation Using Multiple Processor Cores\n  | booktitle = The Twelfth Scandinavian International Conference on Fluid Power\n  | date = 2011}}</ref>\n\nFeatures in the graphical user interface include [[Python (programming language)|Python]] scripting, an [[undo]]/redo function, [[XML]]-based model and configuration files, hydraulic symbols according to the ISO 1219-1 standard and global system parameters that can be shared between components.<ref>{{Cite conference\n  | first1 = M.\n  | last1 = Axin\n  | first2 = R.\n  | last2 = Braun\n  | first3 = A.\n  | last3 = Dell'Amico\n  | first4 = B.\n  | last4 = Eriksson\n  | first5 = P.\n  | last5 = Nordin\n  | first6 = K.\n  | last6 = Pettersson\n  | first7 = I.\n  | last7 = Staack\n  | first8 = P.\n  | last8 = Krus\n  | title = Next Generation Simulation Software using Transmission Line Elements\n  | booktitle = Fluid Power and Motion Control\n  | date = 2010}}</ref>\n\n==References==\n{{reflist}}\n\n==External links==\n*[https://liu.se/en/research/hopsan Hopsan website]\n*[https://github.com/Hopsan/hopsan GitHub repository]\n\n[[Category:Fortran software]]\n[[Category:C++ software]]\n[[Category:Simulation software]]"
    },
    {
      "title": "Moog (code)",
      "url": "https://en.wikipedia.org/wiki/Moog_%28code%29",
      "text": "'''MOOG''' is an astronomical [[software]] package. It is an example of [[Fortran]] code that performs a variety of [[spectral line]] analysis and [[spectrum synthesis]] tasks under the assumption of [[Thermodynamic equilibrium#Local thermodynamic equilibrium|local thermodynamic equilibrium]].  Moog uses a [[model photosphere]] together with a list of [[Atomic electron transition|atomic]] or [[Molecular electronic transition|molecular]] transitions to generate an emergent [[spectrum]] by solving the [[Radiative transfer#The equation of radiative transfer|equation of radiative transfer]].\n\nThe typical use of MOOG is to assist in the determination of the [[Metallicity|chemical composition]] of a [[star]], e.g. Sneden (1973).<ref>{{citation |first = Christopher |last = Sneden |title = The nitrogen abundance of the very metal-poor star [[HD 122563]] |bibcode = 1973ApJ...184..839S |journal = Astrophysical Journal  |volume = 184 |date = 1973 |pages = 839–849 |doi = 10.1086/152374}}</ref> This paper contains also the description of the first version of the code and has been cited about 240 times as of 2008-04-24 by publications in international journals studying the abundances of chemical elements in stars.\n\nThe software package has been developed and is maintained by Christopher Sneden, [[University of Texas]] at [[Austin]]. The current supported version of the code was released in August 2010 and is described in the MOOG User's Guide (see references below).  Moog is written in [[Fortran#FORTRAN 77|FORTRAN 77]].\n\n==Coding==\nThe coding is in various subroutines that are called from a few driver routines; these routines are written in standard FORTRAN. The standard MOOG version has been developed on unix, linux and macintosh computers.\n\n==References==\n{{reflist}}\n\n== Further reading ==\n*{{citation |first = Christopher |last = Sneden |title = The nitrogen abundance of the very metal-poor star HD 122563 |bibcode = 1973ApJ...184..839S |journal = Astrophysical Journal  |volume = 184 |date = 1973 |pages = 839–849 |doi = 10.1086/152374}}\n*{{citation |title = MOOG User's Guide |url = http://verdi.as.utexas.edu/codes/WRITEMOOG.ps |format = Postscript |deadurl = yes |archiveurl = https://web.archive.org/web/20061230163208/http://verdi.as.utexas.edu/codes/WRITEMOOG.ps |archivedate = 2006-12-30 |df =  }}\n\n==External links==\n*[http://www.as.utexas.edu/~chris/moog.html MOOG homepage] maintained by developer Chris Sneden\n\n[[Category:Astronomy software]]\n[[Category:Fortran software]]"
    },
    {
      "title": "NEMO (Stellar Dynamics Toolbox)",
      "url": "https://en.wikipedia.org/wiki/NEMO_%28Stellar_Dynamics_Toolbox%29",
      "text": "{{Underlinked|date=February 2015}}\n\n'''NEMO (Not Everybody Must Observe)''' is a toolkit for [[stellar dynamics]]. At its core it manipulates an ''n''-body system (snapshot), but can also derive or compute orbits, derive images and extract tables to take to other analysis systems.\n\n== Architecture ==\n\n'''NEMO''' was developed on Sun Workstations, but ports to most Unix like systems. At its core '''NEMO''' defines a series of objects (SnapShot, Orbit, Image) and associated header files and libraries to operate on them, and these mirror the data stored in a portable binary name and type tagged XML like format, dubbed ''structured file''. The program '''tsf''' in NEMO will show the contents of such a file in a human readable way. Another feature of NEMO is that all its data can be piped from one task into the next, thus creating whole simulations in a simple Unix pipe. For example,\n\n   mkplummer - 1000 | snapscale - - vscale=0.5 | hackcode1 - - tstop=10 | snaptrim - - times=10 | snapgrid - - | ccdfits - final.fits\n\nwould create a 1000 particle Plummer sphere, scale the velocities down to below virial equilibrium, integrate this for 10 virial times to see it collapse, and take the particle distribution of the last snapshot and turn that into a FITS file to view in another astronomical analysis package.\n\n== History ==\n\n'''NEMO''' was conceived and written by Josh Barnes, [[Piet Hut]] and Peter Teuben in 1986, at the Institute for Advanced Study, prompted by the wish to have a toolkit built around the just developed [[Barnes–Hut simulation]]. NEMO was [http://adass.org/adass/proceedings/adass94/teubenp.html presented] at the 1994 [http://www.adass.org/ Astronomical Data Analysis Software and Systems (ADASS)] conference held in Baltimore, MD.\n\nNEMO is still in active use and development, and has been used in many publications. Peter Teuben maintains NEMO, whereas Josh Barnes maintains ZENO, a spin-off from NEMO.\n\n== External links ==\n* [http://www.astro.umd.edu/nemo NEMO home page]\n* [http://www.ifa.hawaii.edu/faculty/barnes/zeno/index.html ZENO home page]  (a NEMO derived toolkit)\n\n[[Category:Astronomical imaging]]\n[[Category:Astronomy software]]\n[[Category:Fortran software]]\n[[Category:C software]]"
    },
    {
      "title": "Orac (MD program)",
      "url": "https://en.wikipedia.org/wiki/Orac_%28MD_program%29",
      "text": "{{About|a [[molecular dynamics]] program|more meanings of the word '''Orac'''|ORAC (disambiguation){{!}}ORAC}}\n{{Infobox software\n| name = Orac\n| logo = <!-- Image name is enough -->\n| logo alt = \n| logo caption = \n| screenshot = <!-- Image name is enough -->\n| screenshot alt = \n| caption = \n| author = Massimo Marchi, Piero Procacci\n| developer = CEA, Saclay, Paris, FR; Florence University, IT\n| released = {{Start date and age|1990}}\n| latest release version = 5.4.1\n| latest release date = {{Start date and age|2010}}\n| latest preview version = 6.0\n| latest preview date = {{Start date and age|2016}}\n| status = Active\n| programming language = [[Fortran]]\n| operating system = [[Unix]], [[Linux]]\n| platform = [[IA-32]], [[x86-64]], [[Non-uniform memory access|NUMA]]\n| size = \n| language = English\n| genre = [[Molecular dynamics]]\n| license = [[GNU General Public License|GPL]]\n| alexa = \n| website = {{URL|www.chim.unifi.it/orac}}\n| repo = <!-- {{URL|example.org}} -->\n| standard = \n| AsOf = \n}}\nIn computer [[software]], '''Orac''' is a classical [[molecular dynamics]] program, to simulate complex molecular systems at the atomistic level. In 1989-1990, the code was written originally by Massimo Marchi during his stay at International Business Machines ([[IBM]]), Kingston (USA). In 1995, the code was developed further at the [[Centre européen de calcul atomique et moléculaire]] (CECAM). It is written in the programming language [[Fortran]]. In 1997, it was released under a [[GNU General Public License]] (GPL).<ref>\n{{cite journal\n |last1= Procacci |first1= P.\n |last2= Darden |first2= T.A.\n |last3= Paci |first3= E.\n |last4= Marchi |first4= M.\n |year= 1997\n |title= ORAC: A Molecular Dynamics Program to Simulate Complex Molecular Systems with Realistic Electrostatic Interactions\n |journal= [[Journal of Computational Chemistry]]\n |volume= 18 |issue= 15 |pages= 1848–1862\n |doi =10.1002/(SICI)1096-987X(19971130)18:15<1848::AID-JCC2>3.0.CO;2-O\n|citeseerx= 10.1.1.554.895\n }}</ref> The latest release <ref>\n{{Cite journal\n |last1= Marsili |first1= S.\n |last2= Signorini |first2= G.F.\n |last3= Chelli |first3= R.\n |last4= Marchi |first4= M.\n |last5= Procacci |first5= P.\n |year= 2010\n |title= ORAC: A molecular dynamics simulation program to explore free energy surfaces in biomolecular systems at the atomistic level\n |journal= [[Journal of Computational Chemistry]]\n |volume= 31 |issue= 5 |pages= 1106–1116\n |doi =10.1002/jcc.21388\n|pmid= 19824035\n }}</ref> of Orac may be run in parallel using the standard [[Message Passing Interface]] (MPI) libraries, allowing [[replica exchange]] simulations, multiple walkers [[metadynamics]]<ref>\n{{Cite journal\n |last1= Laio |first1= A.\n |last2= Gervasio |first2= F. L.\n |year= 2008\n |title= Metadynamics: A method to simulate rare events and reconstruct the free energy in biophysics, chemistry and material science\n |journal= [[Reports on Progress in Physics]]\n |volume= 71 |issue= 12 |pages= 126601\n |doi=10.1088/0034-4885/71/12/126601\n|bibcode= 2008RPPh...71l6601L }}</ref> simulations and multiple steered molecular dynamics<ref>\n{{Cite journal\n |last1= Isralewitz |first1= B.\n |last2= Gao |first2= M.\n |last3= Schulten |first3= K.\n |year= 2001\n |title= Steered molecular dynamics and mechanical functions of proteins\n |journal= [[Current Opinion in Structural Biology]]\n |volume= 11 |issue= 2 |pages= 224–230\n |doi= 10.1016/S0959-440X(00)00194-9\n |pmid= 11297932\n}}</ref> nonequilibrium trajectories.\n\n==See also==\n{{Portal|Free and open-source software}}\n* [[Comparison of software for molecular mechanics modeling]]\n\n==References==\n{{Reflist}}\n\n== External links ==\n* {{Official website|www.chim.unifi.it/orac}}, Università di Firenze, IT\n\n[[Category:Fortran software]]\n[[Category:Molecular dynamics software]]"
    },
    {
      "title": "Protein Local Optimization Program",
      "url": "https://en.wikipedia.org/wiki/Protein_Local_Optimization_Program",
      "text": "{{Infobox software\n| name = Protein Local Optimization Program\n| logo = \n| caption = \n| author = Matthew P. Jacobson, Richard A. Friesner\n| developer = [[University of California, San Francisco]], [[Schrödinger (company)|Schrödinger]]\n| released = {{Start date and age|2000}}\n| latest release version = Schrödinger Release 2016-4<ref>{{cite web|title=Prime|url=https://www.schrodinger.com/prime|website=Schrödinger|publisher=Schrödinger, LLC|accessdate=19 January 2017}}</ref>\n| latest release date = {{Start date and age|2016|04}}\n| status = Active\n| programming language = [[Fortran]]\n| operating system = [[Unix-like]]\n| platform = \n| size = \n| language = English\n| genre = [[Molecular mechanics]]\n| license = [[Proprietary software|Proprietary]] [[Commercial software|commercial]], academic [[freeware]]<ref>http://www.jacobsonlab.org/plop_manual/plop_license.htm</ref>\n| website = {{URL|wiki.jacobsonlab.org}}\n}}\n\n'''Protein Local Optimization Program''' ('''PLOP''') is computer [[software]],<ref>{{cite web |url=http://wiki.jacobsonlab.org/index.php/Plop |title=Plop – Jacobson Lab Wiki |author= |date= |work= |publisher= |access-date=7 November 2012}}</ref> a [[molecular dynamics]] simulation package written in the programming language [[Fortran]]. It was developed originally by Matthew P. Jacobson and Richard A. Friesner of the Friesner lab at [[Columbia University]], and then moved to the Jacobson lab at [[University of California, San Francisco]] (UCSF), and [[Schrödinger (company)|Schrödinger]], LLC.\n\n== See also ==\n* [[Comparison of software for molecular mechanics modeling]]\n\n==References==\n{{Reflist}}\n\n== External links ==\n* {{Official website|wiki.jacobsonlab.org}} wiki\n\n[[Category:Computational chemistry]]\n[[Category:Fortran software]]\n[[Category:Molecular dynamics]]\n\n\n{{chemistry-stub}}\n{{physics-stub}}"
    },
    {
      "title": "Sintran",
      "url": "https://en.wikipedia.org/wiki/Sintran",
      "text": "{{Unreferenced stub|auto=yes|date=December 2009}}\n:''This article is about the computer operating system''.'' \"SINTRAN\" may also refer to the Brazilian organization (union) of workers in traffic and transportation control, localized in [[Porto Alegre]] - Brazil''. ''For the most common incarnation, see [[Sintran III]].''\n\n'''Sintran''' is a range of [[operating system]]s for [[Norsk Data]]'s line of [[minicomputer]]s. The original version of SINTRAN, released in 1968, was developed by the Department of Engineering Cybernetics at the [[Norwegian Institute of Technology]] in cooperation with the affiliated research institute, [[SINTEF]]. The OS's name is a [[portmanteau]] of ''SIN''TEF and [[Fortran|For''tran'']], [[Fortran]] being the implementation language.<!--The different incarnations of the OS shared only name and to a degree purpose.-->\n\nNorsk Data itself took part in the development of '''Sintran II''', a [[multi-user]] system that constituted the software platform for the [[NORD-1]] range of [[terminal server]]s. By far the most common version of the OS was [[Sintran III]], developed solely by Norsk Data and launched in 1974. This [[real-time operating system|real-time]] [[Computer multitasking|multitasking]] system was used for Norsk Data's server machines (such as the [[Nord-10]], [[Nord-100|-100]]) for the remainder of the company's lifetime, i.e. until 1992.\n\n{{Norsk Data}}\n\n{{DEFAULTSORT:Sintran}}\n[[Category:Fortran software]]\n[[Category:Proprietary operating systems]]\n[[Category:Norsk Data software]]\n\n{{Operating-system-stub}}"
    },
    {
      "title": "United States Air Force Stability and Control Digital DATCOM",
      "url": "https://en.wikipedia.org/wiki/United_States_Air_Force_Stability_and_Control_Digital_DATCOM",
      "text": "{{more footnotes|date=March 2009}}\nThe '''[[United States]] [[United States Air Force|Air Force]] Stability and Control Digital DATCOM''' is a computer program that implements the methods contained in the [[USAF Stability and Control DATCOM]] to calculate the static stability, control and dynamic derivative characteristics of [[fixed-wing aircraft]].  Digital DATCOM requires an input file containing a geometric description of an aircraft, and outputs its corresponding dimensionless stability derivatives according to the specified flight conditions.  The values obtained can be used to calculate meaningful aspects of [[flight dynamics]].\n\n== History ==\nIn February 1976, work commenced to automate the methods contained in the USAF Stability and Control DATCOM, specifically those contained in [[USAF Stability and Control DATCOM#Sections|sections 4, 5, 6 and 7]].  The work was performed by the [[McDonnell Douglas Corporation]] under contract with the United States Air Force in conjunction with engineers at the Air Force Flight Dynamics Laboratory in [[Wright-Patterson Air Force Base]].  Implementation of the Digital DATCOM concluded in November 1978.\n\nThe program is written in [[FORTRAN IV]] and has since been updated; however, the core of the program remains the same.\n\nA report was published, separated into three volumes, which explains the use of Digital DATCOM.  The report consists of\n* Volume I, User's Manual\n* Volume II, Implementation of DATCOM Methods\n* Volume III, Plot Module\n\n== Inputs ==\nSection 3 of the USAF Digital DATCOM Manual Volume I defines the inputs available for modeling an aircraft.  The inputs are categorized by namelists to facilitate reading the file into FORTRAN.\n\n=== Flight conditions and options ===\nThe FLTCON Namelist describes the flight conditions for the case.  A maximum of 400 Mach-altitude combinations can be run at once, with up to 20 [[angles of attack]] for each combination.  The user can specify whether the Mach number and altitude varies together, the [[Mach number]] varies at a constant altitude, or the altitude varies at a constant Mach number.  Both subsonic and supersonic analysis can be run in Digital DATCOM.\n\nThe OPTINS Namelist defines the reference parameters for the aircraft.  The theoretical wing area, [[mean aerodynamic chord]], and [[wing span]] are input along with a parameter defining the surface roughness of the aircraft.\n\n=== Synthesis parameters ===\nThe SYNTHS Namelist allows the user to define the positions of the [[center of gravity]] and apexes of the wings.  The X- and Z- coordinates are needed for the [[wing]], [[tailplane|horizontal tail]], and [[vertical tail]] in order for the aircraft to be synthesized correctly.  DATCOM does not require that the origin for the aircraft has to be the nose of the aircraft; any arbitrary point will do, but all of the dimensions need to be referenced from that point.  [[angle of incidence (aerodynamics)|Incidence angles]] can also be added to the wing and horizontal tail.\n\n=== Body parameters ===\nThe BODY Namelist defines the shape of the body.  Digital DATCOM assumes an axisymmetrical shape for the body.  Up to 20 stations can be specified with the fuselage half-width, upper coordinate and lower coordinate being defined at each station.  For supersonic analysis, additional parameters can be input.\n\n=== Wing, Horizontal and Vertical Tail parameters ===\nThe WGPLNF, HTPLNF and VTPLNF Namelists define the wing, horizontal tail and vertical tail, respectively.  The basic parameters such as root chord, tip chord, half-span, [[Wing twist|twist]], [[dihedral (aircraft)|dihedral]] and [[Swept wing|sweep]] are input.  Digital DATCOM also accepts wing planforms which change geometry along the span such as the [[F4 Phantom II]] which had 15 degrees of outboard dihedral.\n\nCanards can also be analyzed in Digital DATCOM.  The [[Canard (aeronautics)|canard]] must be specified as the forward lifting surface (i.e. wing) and the wing as the aft lift surface.\n\nFor airfoil designations, most traditional NACA 4-, 5-, and 6- airfoils can be specified in Digital DATCOM.  Additionally, custom airfoils can be input using the appropriate namelists.  Also, twin vertical tails can be designated in Digital DATCOM, but not twin booms.\n\n=== High Lift and Control Devices ===\nUsing the SYMFLP and ASYFLP Namelists, [[Flap (aircraft)|flaps]], [[Elevator (aircraft)|elevators]], and [[ailerons]] can be defined.  Digital DATCOM allows a multitude of flap types including plain, single-slotted, and fowler flaps.  Up to 9 flap deflections can be analyzed at each Mach-altitude combination.  Unfortunately, the [[rudder]] is not implemented in Digital DATCOM.\n\nDigital DATCOM also offers an automated aircraft TRIM function which calculates elevator deflections needed to [[Longitudinal static stability#Trim|trim]] the aircraft.\n\n=== Other Inputs ===\nOther Digital DATCOM inputs include power effects (propeller and jet), ground effects, trim tabs, and experimental data.  The EXPRXX Namelist allows a user to use experimental data (such as coefficient of lift, coefficient of drag, etc.) in lieu of the data Digital DATCOM produces in the intermediate steps of its component build-up.\n\nAll dimensions are taken in feet and degrees unless specified otherwise.  Digital DATCOM provides commands for outputting the dynamic derivatives (DAMP) as well as the stability coefficients of each components (BUILD).\n\n== Output ==\nDigital DATCOM produces a copious amount of data for the relatively small amount of inputs it requires.  By default, only the data for the aircraft is output, but additional configurations can be output:\n* Body alone\n* Wing alone\n* Horizontal tail alone\n* Vertical tail alone\n* Wing-Body Configuration\n* Body-Horizontal Tail Configuration\n* Body-Vertical Tail Configuration\n* Wing-Body-Horizontal Tail Configuration\n* Wing-Body-Vertical Tail Configuration \n* Wing-Body-Horizontal Tail-Vertical Tail Configuration\n\nFor each configuration, stability coefficients and derivatives are output at each angle of attack specified.  The details of this output are defined in Section 6 of the USAF Digital DATCOM Manual Volume I.  The basic output includes:\n* C<sub>L</sub> - [[Lift Coefficient]]\n* C<sub>D</sub> - [[Drag Coefficient]] \n* C<sub>m</sub> - [[Pitching moment|Pitching Moment Coefficient]]\n* C<sub>N</sub> - Normal Force Coefficient\n* C<sub>A</sub> - Axial Force Coefficient\n* C<sub>Lα</sub> - Lift Curve Slope (Derivative of Lift Coefficient with respect to angle of attack)\n* C<sub>mα</sub> - Pitching Moment Curve Slope (derivative of Pitching Moment Coefficient with respect to angle of attack)\n* C<sub>Yβ</sub> - Derivative of side-force coefficient with respect to [[sideslip angle]]\n* C<sub>nβ</sub> - Derivative of yawing-moment coefficient with respect to sideslip angle\n* C<sub>lβ</sub> - Derivative of rolling-moment coefficient with respect to sideslip angle\n\nFor complete aircraft configurations, [[downwash]] data is also included.\n\nWhen compared with modern methods of [[computational fluid dynamics]], Digital DATCOM may seem antiquated.  However, in its day, the program was an advanced estimation tool, and certainly much faster than plowing through pages and pages of engineering texts.  Digital DATCOM is no longer supported by the USAF and is now [[public domain]] software.\n\n== Limitations ==\nInlets, external stores, and other protuberances cannot be input because Digital DATCOM analyzes the fuselage as a [[body of revolution]].  The simplification affects the coefficient of drag for the aircraft.\n\nDynamic derivatives are not output for aircraft that have wings that are not straight-tapered or have [[leading edge extensions]].  This problem can be overcome by using experimental data for the wing-body (using non-straight tapered wing).\n\nThere is no method to input twin vertical tails mounted on the fuselage, although there is a method for [[Twin tail|H-Tails]].  This problem can be addressed by approximating the twin vertical tails as a single equivalent vertical tail mounted to the fuselage.\n\nDigital DATCOM cannot provide outputs for the control derivatives with regard to the rudder control surface. According to the manual, there is no any input parameters which define the geometriy of rudder.\n\nDigital DATCOM cannot analyze three lifting surfaces at once, such as a canard-wing-horizontal tail configuration.  This problem can be addressed by superposition of lifting surfaces through the experimental input option.\n\n== Current Development ==\nThere are intentions among those that use this package to improve the overall package, through an easier user interface, as well as more comprehensive output data.\n\n[[Image:citation_ac.jpg|right|thumb|320px|[[Cessna Citation|Citation]] in AC3D]]\n\n=== DATCOM+ ===\nWhile the original DIGDAT program has been left relatively untouched, there has been a new front-end created that will allow the user to name the input file with something more significant than FOR005.DAT. The new input file format allows the user to place comments in the input file. There have also been hooks placed in the DIGDAT that allow for alternate outputs in addition to the original output format, which is 132 columns wide and slightly user abusive if you intend to import the data into another application. There is a graphical representation of the aircraft output in [[AC3D]], as well as data table output in [[XML]] for the [[JSBSim]] and [[FlightGear]] projects, as well as a free-format LFI (Linear Function Interpolation) data table file.\n\nAlong with the DIGDAT program, there are viewers for the AC3D, XML, and LFI format output files. Data tables can easily be output to the screen or to PNG files for inclusion into reports.\n[[Image:Navion_in_Datcom3d.jpg|right|thumb|240px|[[Navion]] in MATLAB]]\n\n=== Mathworks Aerospace Toolbox ===\nAerospace Toolbox includes a function for importing output files from Digital DATCOM into MATLAB. This function lets you collect aerodynamic coefficients from static and dynamic analyses and transfer them into MATLAB as a cell array of structures, with each structure containing information about a Digital DATCOM output file.\n\n=== OpenDatcom ===\nOpenDatcom is an open-source GUI for the Digital DATCOM created and hosted by the OpenAE [http://openae.org/software] community. OpenDatcom incorporates all the basic (non-experimental) functionality supported by the Digital DATCOM while providing real-time input error and bounds checking. An alpha version of the program was released November 1, 2009 to the general public. The OpenAE.org web site is no longer active.\n\n=== Predicting Aerodynamics of Structurally Damaged Aircraft ===\n\nThere has been some research in using Digital DATCOM in conjunction with wind tunnel studies to predict aerodynamics of structurally impaired aircraft.  Dr. Bilal Siddiqui at [[DHA Suffa University]] presented an approach <ref>[https://www.researchgate.net/publication/237086362_Using_USAF_DATCOM_to_Predict_Nonlinear_Aerodynamics_of_Structurally_Impaired_Aircraft], Using USAF DATCOM to Predict Nonlinear Aerodynamics of Structurally Impaired Aircraft,</ref> to predict the nonlinear aerodynamics of a structurally damaged aircraft model based on the engineering level aerodynamic prediction methods, DATCOM. Raw results from the code provide good correlation with wind tunnel data at very low angles of attack, but accuracy deteriorates rapidly as the angle of attack increases. A new methodology is then proposed which combines the experimental results of healthy aircraft with the predicted aerodynamics of the damaged cases, to yield better correlation between experimental and predicted aerodynamic coefficients for damaged aircraft. Three damage-configurations are studied at supersonic speeds. The methodology can be used to quickly generate aerodynamic model for damaged aircraft for simulation and reconfigurable control\n\n== See also ==\n* [[Missile Datcom]]\n* [[USAF Stability and Control DATCOM]]\n\n== References ==\n{{Reflist}}\n* Williams, John E., Vukelich, Steven R.  \"The USAF Stability and Control Digital DATCOM. Volume I. Users Manual.\" [http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA086557&Location=U2&doc=GetTRDoc.pdf AFFDL-TR-79-3032 Volume I], Nov. 1979.\n* Williams, John E., Vukelich, Steven R.  \"The USAF Stability and Control Digital DATCOM. Volume II. Implementation of Datcom Methods.\" [http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA086558&Location=U2&doc=GetTRDoc.pdf AFFDL-TR-79-3032 Volume II], Nov. 1979.\n* Williams, John E., Vukelich, Steven R.  \"The USAF Stability and Control Digital DATCOM. Volume III. Plot Module.\" [http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA086559&Location=U2&doc=GetTRDoc.pdf AFFDL-TR-79-3032 Volume III], Nov. 1979.\n* Blake, W. B. \"Prediction of Fighter Aircraft Dynamic Derivatives Using Digital Datcom,\" AIAA 3rd Applied Aerodynamics Conference, [http://www.jsbsim.org/AIAA-1985-4070-141.pdf AIAA-1985-4070], Colorado Spring, CO, October 1985.\n* The Mathworks, Inc. \"Model-Based Design of a New Light-weight Aircraft,\" AIAA Modeling and Simulation Technologies Conference and Exhibit, [http://webstu.db.erau.edu/~mohamb5d/datcom/docs/AIAA-2007-6371.pdf AIAA-2007-6371], Hilton Head, SC, August 2007.\n* Siddiqui, B.A. and Kassem, A. H., \"Using USAF DATCOM to Predict Nonlinear Aerodynamics of Structurally Impaired Aircraft\", [https://www.researchgate.net/publication/237086362_Using_USAF_DATCOM_to_Predict_Nonlinear_Aerodynamics_of_Structurally_Impaired_Aircraft] International Review of Aerospace Engineering (I.RE.AS.E), January 2010.\n\n== External links ==\n* [https://web.archive.org/web/20100424061353/http://openae.org/forum/8-opendatcom OpenDatcom]\n* [http://webstu.db.erau.edu/~mohamb5d/datcom/ Digital DATCOM at Embry-Riddle Aeronautical University]\n* [http://tech.groups.yahoo.com/group/digital_datcom/ Yahoo Digital_Datcom Group]\n* [http://www.rb.afrl.af.mil/org/VAC/VACA/vaca_index.html Air Force Research Laboratory Control Theory Optimization Branch]\n* [http://www.mathworks.com/products/aerotb/ Aerospace Toolbox for MATLAB]\n* [http://jsbsim.sourceforge.net/ JSBSim]\n* [http://flightgear.org/ FlightGear]\n* [http://www.pdas.com/refs/1965-Datcom-Sections1-5.pdf 1965-Datcom-Sections-1-5]\n* [http://www.pdas.com/refs/1965-Datcom-Sections6-9.pdf 1965-Datcom-Sections-6-9]\n* [http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA086557 AFRL-TR-79-3032 USAF DATCOM User's Manual, Volume 1]\n* [http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA086558 AFRL-TR-79-3032 USAF DATCOM User's Manual, Volume 2]\n* [http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA086559 AFRL-TR-79-3032 USAF DATCOM User's Manual, Volume 3]\n* [http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADB072483 AFWAL-TR083-3048 McDonnell Douglas Corporation Final Report for DATCOM, April 1978]\n\n[[Category:Aerospace engineering software]]\n[[Category:Aerodynamics]]\n[[Category:Aircraft controls]]\n[[Category:Fortran software]]\n[[Category:Wright-Patterson Air Force Base]]"
    },
    {
      "title": "USAS (application)",
      "url": "https://en.wikipedia.org/wiki/USAS_%28application%29",
      "text": "{{unref|date=October 2008}}\nThe '''USAS''' [[application software|application]] suite is a series of diverse and relatively complex [[Mainframe computer|mainframe]] applications written for the [[Unisys]] 1100-series, 2200-series, and Clearpath IX environments.  These applications are generally intended for use in the [[airline]], transportation, and [[hospitality]] industries.\n\nOlder USAS applications such as USAS*RES (Reservations System) or USAS*FDC (Flight Data Control) were written originally in [[Fortran]], but elements of various applications were also written in [[COBOL]], Unisys 1100/2200 [[assembly language]] (ASM or [[MASM]]), and the [[LINC 4GL]].\n\nUSAS application mainly developed for Airlines business use. There were many applications in USAS suite. Check-In, Reservation, Cargo operations are the main suites. Lufthansa IT systems plays a major role in developing USAS suite.\n\nMost (if not all) USAS applications are written as text-based online transaction systems which are designed for low overhead and fast response times.  The environment most commonly used is HVTIP (short for High-Volume TIP).\n\nThe original USAS applications such as USAS*RES (Reservation System), USAS*CGO (Cargo Application) was written in the early 70s and were adapted in different forms in varying degrees of customization.\n\nWith recent advancements in computing technology however, the USAS line of products is slowly diminishing and is being replaced (especially in the Airline industry) with other [[Open-source software|open source]] front-end products.\n\n\"USAS\" was originally an acronym for Univac Standard Airline Systems, but the product line is now referred to simply as \"USAS\".\n\n==Current Users==\n*Unisys Cargo Hosting Services, Minneapolis :: Delta Cargo, Air Canada Cargo\n*Lufthansa Systems, Frankfurt (does not include Lufthansa passenger Airlines)\n*Lufthansa Cargo Services\n*Air Iberia\n*Travel Sky, China\n*Amadeus\n*NorthWest (cargo)\n*Cathay Pacific\n*Qantas Airways\n*Air India\n*ANA\n\n==See also==\n*[[List of UNIVAC products]]\n*[[History of computing hardware]]\n\n[[Category:Business software]]\n[[Category:Fortran software]]\n[[Category:UNIVAC software]]"
    },
    {
      "title": "EAS3",
      "url": "https://en.wikipedia.org/wiki/EAS3",
      "text": "{{Primary sources|date=November 2009}}\n{{Infobox software\n| name                   = EAS3\n| logo                   = Eas3logo.png\n| screenshot             =\n| caption                =\n| author                 = Inst. f. Aero- & Gasdynamik ([[University of Stuttgart]])\n| developer              =\n| released               = {{start date and age|1999|08}}\n| latest release version = 1.6.7\n| latest release date    = {{start date and age|2009|04|14}}\n| latest preview version =\n| latest preview date    =\n| programming language   = [[Fortran]], [[C (programming language)|C]]\n| operating system       = all [[POSIX]] systems\n| platform               = platform independent\n| language               = [[English language|English]] / [[German language|German]]\n| status                 = stable / in production\n| genre                  = postprocessing, [[:Category:Computer file formats|computer file format]]\n| license                = [[MIT License]]\n| website                = {{url|https://wiki.iag.uni-stuttgart.de/eas3wiki}}\n| repo                   = none\n}}\n'''EAS3''' (EAS = Ein-Ausgabe-System) is a software toolkit for reading and writing structured binary data with geometry information and for postprocessing of these data. It is meant to exchange floating-point data according to [[IEEE 754|IEEE standard]] between different computers, to modify them or to convert them into other file formats. It can be used for all kinds of structured data sets. It is mainly used in the field of [[direct numerical simulation]]s.\n\n==EAS3 package==\nThe complete package consists of libraries intended for usage in own codes and a separate command-line tool. It is written in [[Fortran]] and [[C (programming language)|C]] and runs on all [[POSIX]] operating systems. The libraries include different numerical algorithms and subroutines for reading and writing files in the binary EAS3 file format. The read/write routines are provided in Fortran and C. Implemented numerical methods include, for example, [[Fast Fourier transform]], [[Tridiagonal matrix algorithm|Thomas algorithm]] and [[interpolation]] routines. The libraries are also suitable for [[vector computer]]s.\n\n==History==\nEAS3 has been developed at the Institut für Aerodynamik und Gasdynamik (IAG) of the [[University of Stuttgart]]. The previous versions (EAS, EAS2) range back to the end of the 1980s, when computer power allowed the first spatial DNS computations.<ref>H. Fasel, U. Rist, U. Konzelmann: ''Numerical investigation of the three-dimensional development in boundary layer transition'', AIAA Journal, Vol. 28, p. 29-37, 1990</ref> The upcoming amount of data required efficient handling and postprocessing. Typically, simulations were, and are still today, performed on a high-performance computer and afterwards postprocessed on other machines of opposite [[endianness]]. This required an endianness-independent file format for data handling.\n\nSince the publication of EAS3 in the 1999, the software has been developed continuously by members of the involved institutes. Since 2007, EAS3 is also available via the [[Heinz Heise|heise]] software directory.<ref>[http://www.heise.de/software/download/eas3/49159 EAS3 page] at heise software directory</ref> EAS3 is used by applications within the European PRACE project.<ref>[http://www.prace-project.eu Website] of Partnership for advanced computing in Europe</ref> The current version number is 1.6.7 from April, 2009.\n\n==File Format==\n{{Infobox file format\n| name = EAS3 (Ein-Ausgabesystem 3)\n| icon =\n| logo =\n| screenshot =\n| caption =\n| extension = <tt>.eas</tt>\n| mime =\n| type code =\n| uniform type =\n| magic = <code>EAS3_I8R8</code>\n| owner = [[Universität Stuttgart]]\n| genre = binary format for floating point data\n| container for =\n| contained by =\n| extended from =\n| extended to =\n| standard =\n}}\nThe EAS3 file format is used to store floating point data in IEEE format and to exchange the files between different computer architectures ([[Endianness|little/big endian]]). The data is organized as parameters with one parameter being a one-, two- or three-dimensional floating point array. Several of these parameters may be combined to one time step. This allows to store five-dimensional arrays. Data can be written in single-precision (32 Bit), double-precision (64 Bit) or quadruple-precision (128 Bit). Geometry information for the different directions are saved in the header of the file. It is also possible to store additional information in user defined arrays there. With the file size being limited only by the computer itself (e.g. file system), EAS3 files are suitable for large simulations and thus for [[high-performance computing]].<ref>A. Babucke, M. Kloker, U. Rist: ''Direct Numerical Simulation of a Serrated Nozzle End for Jet-Noise Reduction'', in High Performance Computing in Science and Engineering 07, p. 319-338, {{ISBN|978-3-540-74738-3}}, Springer 2008</ref><ref>J. Linn, M. Kloker: ''Direct Numerical Simulation of Film Cooling in Hypersonic Boundary-Layer Flow'', in High Performance Computing in Science and Engineering 08, p. 171-189, {{ISBN|978-3-540-88301-2}}, Springer 2009</ref>\n\n==Functionality==\nThe actual EAS3 executable is a command-line interface for alteration of EAS3 files. The implemented commands range from basic operations, e.g. simple computations, file operations, to rather complex operations like Fourier transformation or the computation of derivatives. Specific commands for DNS data are also available, e.g. the [[lambda2 vortex criterion]]. As the commands are read from standard input, EAS3 may be used in shell scripts for automated calls.\n\n[[Image:Eas3 screenshot ableiten.jpg|thumb|361px|right|Screenshot of EAS3: Computing the spatial derivative along the first spatial dimension.]]\n'''Outline of important functions'''\n*file management: rearrangement, attaching two files, cutting\n*conversion to other file formats (ASCII, Covise, Tecplot)\n*mathematical operationes: basic operations, logarithm, etc.\n*derivatives und integration\n*interpolation\n*data reduction: mean values, RMS-values, etc.\n*Fourier transformation: single/double, real/complex\n*DNS specific: vortex criterion\n\n==Installation==\nThe sources can be obtained directly from the [[Concurrent Versions System|CVS]] repository or one may download a zipped tar file. Makefiles for different machine types are included, providing an easy compilation. As linking of object files, created with different Fortran compilers can cause problems, binary packages ([[RPM Package Manager|RPM]], [[.deb]]) are not offered up to now.\n\n==Advantages and disadvantages==\n\n===Advantages===\nThe main profit for the programmer is the easy implementation of reading/writing large (>2[[Byte|GB]]) binary data sets. The library provides that the data is always written [[Endianness|big endian]]. The resulting platform independence allows data exchange between different hardware architectures, e.g. [[supercomputer]]s. The users benefits from the different methods provided for postprocessing, which can be automated using shell scripts.\n\n===Disadvantages===\nBeing specialized on structured grids may be a problem for some users. Up to now, only cartesian grids or a representation of the data in spectral space are implemented. Data in other types of data alignment, e.g. cylindrical coordinates, can be stored in EAS3 files but the existing postprocessing commands may not be used. As the usually used visualization programs do not support the EAS3 file format directly, it is often necessary to convert the data to the corresponding file format. Commands in the EAS3 program are given by a text interface, a graphical user interface does not exist. Completion of the commands in the EAS3 command line provides support for interactive usage but for an extensive help, the descriptions on the webpage are necessary.\n\n==License==\nEAS3 is published under the [[MIT License]]. The MIT License is a free software license originating at the [[Massachusetts Institute of Technology|Massachusetts Institute of Technology (MIT)]]. Specifically, it is a [[GPL]]-compatible permissive license, meaning that it permits reuse within proprietary software on the condition that the license is distributed with that software.\n\n==Usage==\n* Transition group at the Institute of Aerodynamics and Gasdynamics (IAG) of the University of Stuttgart: http://www.iag.uni-stuttgart.de\n* Computational Fluid Dynamics Laboratory of the University of Arizona: http://cfd.ame.arizona.edu\n* Institute of Fluid Dynamics, Eidgenössische Technische Hochschule Zürich: http://www.ifdmavt.ethz.ch\n* Lehrstuhl für Aerodynamik at the Technical University Munich (high-speed aerodynamics group): http://www.aer.mw.tum.de\n\n==Related file formats==\n* [[Common Data Format]] (CDF)\n* [[CGNS]] ([[Computational fluid dynamics|CFD]] General Notation System)\n<!-- * [[EAS3]] (Ein-Ausgabe-System) -->\n* [[FITS]] (Flexible Image Transport System)\n* [[GRIB]] (GRIdded Binary)\n* [[Hierarchical Data Format]] (HDF)\n* [[NetCDF]] (Network Common Data Form)\n* [[Tecplot]] binary files\n* [[XMDF]] (eXtensible Model Data Format)\n\n==References==\n{{reflist}}\n\n==External links==\n{{Commons category|EAS3}}\n{{Portal|Free and open-source software}}\n*[http://www.iag.uni-stuttgart.de/eas3 EAS3 project web page ]\n\n{{DEFAULTSORT:Eas3}}\n[[Category:Free science software]]\n[[Category:Free software programmed in C]]\n[[Category:Free software programmed in Fortran]]\n[[Category:Computer file formats]]\n[[Category:Software using the MIT license]]"
    },
    {
      "title": "MDynaMix",
      "url": "https://en.wikipedia.org/wiki/MDynaMix",
      "text": "{{Infobox software\n| name = Molecular Dynamics of Mixtures\n| logo = <!-- Image name is enough -->\n| logo alt = \n| logo caption = \n| screenshot = Image:MDynaMix-MGE.png\n| screenshot alt = Computer display showing temperature function on left, DNA molecule in center, and various menu items to right and below.\n| caption = DNA simulation on MDynaMix\n| author = Aatto Laaksonen, Alexander Lyubartsev\n| developer = [[Stockholm University]], Department of Materials and Environmental Chemistry, Division of Physical Chemistry\n| released = {{Start date and age|1993}}\n| latest release version = 5.2.7\n| latest release date = {{Start date and age|df=yes|2015|01|31}}\n| latest preview version =\n| latest preview date = <!-- {{Start date and age|df=yes/no|YYYY|MM|DD}} -->\n| status = Active\n| programming language = [[Fortran]] 77-90\n| operating system = [[Unix]], [[Unix-like]], [[Linux]], [[Microsoft Windows|Windows]]\n| platform = [[x86]], [[x86-64]], [[Cray]]\n| size = \n| language = English\n| genre = [[Molecular dynamics]]\n| license = [[GNU General Public License|GPL]]\n| alexa = \n| website = {{URL|www.fos.su.se/~sasha/mdynamix}}\n| repo = <!-- {{URL|example.org}} -->\n| standard = \n| AsOf = \n}}\n'''Molecular Dynamics of Mixtures''' ('''MDynaMix''') is a computer [[software]] package for general purpose [[molecular dynamics]] to simulate mixtures of molecules, interacting by [[AMBER]]- and [[CHARMM]]-like [[Force field (chemistry)|force fields]] in [[periodic boundary conditions]].<ref>{{cite journal |doi= 10.1016/S0010-4655(99)00529-9 |title= MDynaMix - A scalable portable parallel MD simulation package for arbitrary molecular mixtures |author= A.P.Lyubartsev, A.Laaksonen |journal= Computer Physics Communications |volume= 128 |year=2000 |pages= 565–589 |issue= 3}}</ref><ref>{{cite book |title= Applied Parallel Computing Large Scale Scientific and Industrial Problems\n |chapter= Parallel molecular dynamics simulations of biomolecular systems\n |author= A.P.Lyubartsev, A.Laaksonen |series= Lecture Notes in Computer Science\n|publisher= Springer Berlin |location= Heidelberg |volume= 1541 |year=1998 |pages= 296–303\n |isbn= 978-3-540-65414-8 |doi= 10.1007/BFb0095310}}</ref>\nAlgorithms are included for NVE, NVT, NPT, anisotropic NPT ensembles, and [[Ewald summation]] to treat electrostatic interactions.\nThe code was written in a mix of [[Fortran]] 77 and 90 (with [[Message Passing Interface]] (MPI) for parallel execution)<!-- and [[C++]] //No verifying text found on official website.// -->. The package runs on [[Unix]] and [[Unix-like]] ([[Linux]]) workstations, clusters of workstations, and on [[Microsoft Windows|Windows]] in sequential mode.\n\nMDynaMix is developed at the Division of Physical Chemistry, Department of Materials and Environmental Chemistry, [[Stockholm University]], Sweden. It is released as [[open-source software]] under a [[GNU General Public License]] (GPL).\n\n==Programs==\n* ''md'' is the main MDynaMix block\n* ''makemol'' is a utility which provides help to create files describing molecular structure and the [[Force field (chemistry)|force field]]\n* ''tranal'' is a suite of utilities to analyze trajectories\n* ''mdee'' is a version of the program which implements expanded [[Ensemble average (statistical mechanics)|ensemble]] method to compute [[Thermodynamic free energy|free energy]] and [[chemical potential]] (is not parallelized)\n* ''mge'' provides a [[graphical user interface]] to construct [[molecular model]]s and monitor dynamics process\n\n== Field of application ==\n* Thermodynamic properties of liquids<ref>{{cite journal\n |doi= 10.1039/b108726f\n |title= Thermodynamic properties and interfacial tension of a model water–carbon dioxide system\n|author1=T. Kuznetsova |author2=B. Kvamme |lastauthoramp=yes |journal= Phys. Chem. Chem. Phys. |volume= 4 |year=2002 |pages= 937–941\n |issue= 6}}</ref>\n* [[Nucleic acid]] - ions interaction<ref>{{cite journal\n |title= Similarities and differences in interaction of K+ and Na+ with condensed ordered DNA. A molecular dynamics computer simulation study\n|author1=Y. Cheng, N. Korolev |author2=L. Nordenskiöld |lastauthoramp=yes |journal= Nucleic Acids Research |volume= 34 |year=2006 |pages= 686–696\n |pmid= 16449204\n |issue= 2\n |doi= 10.1093/nar/gkj434\n |pmc= 1356527}}</ref>\n* Modeling of lipid bilayers<ref>{{cite journal\n |title= Modification of the CHARMM force field for DMPC lipid bilayer\n|author1=C.-J. Högberg |author2=A.M.Nikitin |author3=A.P. Lyubartsev |lastauthoramp=yes |journal= Journal of Computational Chemistry |volume= 29 |year=2008 |pages= 2359–2369\n |pmid= 18512235\n |issue= 14\n |doi= 10.1002/jcc.20974}}</ref>\n* [[Polyelectrolyte]]s<ref>{{cite journal\n |title= Specifics of solvation of sulfonated polyelectrolytes in water, dimethylmethylphosphonate, and their mixture: A molecular simulation study\n|author1=A. Vishnyakov |author2=A.V. Neimark |lastauthoramp=yes |journal= J. Chem. Phys. |volume= 128 |year=2008 |pages= 164902\n |pmid= 18447495\n |issue= 16\n |doi= 10.1063/1.2899327}}</ref>\n* [[Ionic liquid]]s<ref>{{cite journal\n |title= Thermodynamical and structural properties of imidazolium based ionic liquids from molecular simulation\n|author1=G. Raabe |author2=J. Köhler |lastauthoramp=yes |journal= J. Chem. Phys. |volume= 128 |year=2008 |pages= 154509\n |pmid= 18433237\n |issue= 15\n |doi= 10.1063/1.2907332}}</ref><ref>{{cite journal\n |title= Molecular dynamics simulation of room-temperature ionic liquid mixture of [bmim][BF<sub>4</sub>] and acetonitrile by a refined force field\n |author1=X. Wu |author2=Z. Liu |author3=S. Huang |author4=W. Wang |journal= Phys. Chem. Chem. Phys. |volume= 7 |year=2005 |pages= 2771–2779\n |pmid= 16189592\n |issue= 14\n |doi= 10.1039/b504681p}}</ref>\n* X-ray spectra of liquid water<ref>{{cite journal\n |title= Theoretical modeling and interpretation of X-ray absorption spectra of liquid water\n|author1=R.L.C. Wang, H.J. Kreuzer |author2=M. Grunze |lastauthoramp=yes |journal= Phys. Chem. Chem. Phys. |volume=8 |year=2006 |pages=4744–4751\n |pmid= 17043717\n |issue= 41\n |doi= 10.1039/b607093k}}</ref>\n* [[Force field (chemistry)|Force Field]] development<ref>{{cite journal\n |doi= 10.1002/jcc.20721\n |title= A new six-site acetonitrile model for simulations of liquid acetonitril and its aqueous mixture\n|author1=A.M. Nikitin |author2=A.P. Lyubartsev |lastauthoramp=yes |journal= J. Comput. Chem. |volume=28\n |issue= 12 |year=2007 |pages=2020–2026\n |pmid= 17450554}}</ref><ref>{{cite journal\n |doi= 10.1016/j.chemphys.2007.12.006\n |title= Solvation of monovalent anions in [[formamide]] and [[methanol]]: Parameterization of the IEF-PCM model\n|author1=E.S. Böesa |author2=E. Bernardia |author3=H. Stassena |author4=P.F.B. Gonçalves |journal= Chemical Physics |volume=344 |year=2008 |pages=101–113}}</ref>\n\n==See also==\n{{Portal|Free and open-source software}}\n{{columns-list|colwidth=30em|\n* [[Abalone (molecular mechanics)]]\n* [[AMBER]]\n* [[Ascalaph Designer]]\n* [[BOSS (molecular mechanics)]]\n* [[CHARMM]]\n* [[GROMACS]]\n* [[MacroModel]]\n* [[Molecule editor]]\n* [[Molecular modelling]]\n* [[Molecular design software]]\n* [[NAMD]]\n* [[Tinker (software)]]\n* [[Comparison of software for molecular mechanics modeling]]\n}}\n\n==References==\n{{Reflist}}\n\n== External links ==\n* {{Official website|www.fos.su.se/~sasha/mdynamix}}\n* [http://biomolecular-modeling.com/Ascalaph/ Ascalaph, graphical shell for MDynaMix] (GNU GPL)\n\n[[Category:Molecular dynamics software]]\n[[Category:Free science software]]\n[[Category:Free software programmed in C++]]\n[[Category:Free software programmed in Fortran]]"
    },
    {
      "title": "Physics Analysis Workstation",
      "url": "https://en.wikipedia.org/wiki/Physics_Analysis_Workstation",
      "text": "{{Infobox software\n| name                       = Physics Analysis Workstation\n| logo                       = \n| screenshot                 = PAW.png\n| caption                    = PAW - sample code output\n| collapsible                = \n| author                     = [[CERN]]\n| developer                  = \n| released                   = {{Start date and age|1986}}\n| latest release version     = 2.13/08\n| latest release date        = {{Start date and age|2002|09|16}}\n| latest preview version     = \n| latest preview date        = \n| frequently updated         = \n| programming language       = \n| operating system           = \n| platform                   = \n| size                       = \n| language                   = \n| status                     = \n| genre                      = [[Particle physics]]\n| license                    = [[GNU GPL]]\n| website                    = {{URL|http://cern.ch/paw/}}\n}}\n[[Image:Paw output.gif|thumb|PAW screen capture]]\nThe '''Physics Analysis Workstation''' (PAW) is an interactive, scriptable computer software tool for data analysis and graphical presentation in [[High Energy Physics]] (HEP). \n\nThe development of this software tool started at [[CERN]] in 1986, it was optimized for the processing of very large amounts of data. It was based on and intended for inter-operation with components of [[CERN Program Library|CERNLIB]], an extensive collection of [[Fortran]] libraries. \n\nPAW had been a standard tool in high energy physics for decades, yet was essentially unmaintained.<ref>http://cernlib.web.cern.ch/cernlib/news/future.html</ref> Despite continuing popularity as of 2008, it has been losing ground to the [[C++]]-based [[ROOT]] package. Conversion tutorials exist.<ref>https://root.cern.ch/root/HowtoConvertFromPAW.html</ref> In 2014, development and support were stopped.<ref>https://paw.web.cern.ch/paw/</ref>\n\n==Sample script==\n\nPAW uses its own scripting language. Here is sample code (with its actual output), which can be used to plot data gathered in files.\n\n<pre>\n* read data\nvector/read X,Y input_file.dat\n\n* eps plot\n\nfort/file 55 gg_ggg_dsig_dphid_179181.eps\nmeta 55 -113\n\nopt linx   | linear scale\nopt logy   | logarithmic scale\n\n* here goes plot\n\nset plci 1       | line color\nset lwid 2       | line width\nset dmod 1       | line type (solid, dotted, etc.)\ngraph 32 X Y AL   | 32 stands for input data lines in input file\n\n* plot title and comments\n\nset txci 1\natitle '[f] (deg)' 'd[s]/d[f]! (mb)'\n\nset txci 1\ntext 180.0 2e1 '[f]=179...181 deg' 0.12\n\nclose 55\n</pre>\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* [http://cern.ch/paw/ PAW (at CERN)]\n* [http://ref.web.cern.ch/ref/CERN/CNL/2001/001/paw/ The PAW History Seen by the CERN Computer News Letters]\n* [http://cern.ch/cernlib/ CERNLIB (at CERN)]\n* [http://root.cern.ch/ ROOT (at CERN)]\n\n[[Category:Free science software]]\n[[Category:Free software programmed in Fortran]]\n[[Category:Physics software]]\n[[Category:CERN software]]"
    },
    {
      "title": "SPICE",
      "url": "https://en.wikipedia.org/wiki/SPICE",
      "text": "{{other uses|Spice (disambiguation)}}\n<!-- Deleted image removed: [[Image:spiceopus screenshot.png|thumb|400px|Screen shot of Spice OPUS, a fork of Berkeley SPICE]] -->\n{{Infobox software\n| name                   = SPICE 1\n| title                  = SPICE 1\n| logo                   = <!-- [[File: ]] -->\n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = Laurence Nagel\n| developer              = \n| released               = {{Start date and age|1973}}\n| discontinued           = \n| latest release version = \n| latest release date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| programming language   = [[Fortran]]\n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| genre                  = [[Electronic circuit simulation]]\n| license                = [[Public-domain software]]\n| website                = \n}}\n{{Infobox software\n| name                   = SPICE 2\n| title                  = SPICE 2\n| logo                   = <!-- [[File: ]] -->\n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = \n| developer              = \n| released               = {{Start date and age|1975}}\n| discontinued           = \n| latest release version = 2G.6\n| latest release date    = 1983 <!-- {{Start date and age|1983|MM|DD|df=yes/no}} -->\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| programming language   = [[Fortran]]\n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| genre                  = [[Electronic circuit simulation]]\n| license                = [[BSD 3 Clause]]\n}}\n{{Infobox software\n| name                   = SPICE 3\n| title                  = SPICE 3\n| logo                   = <!-- [[File: ]] -->\n| screenshot             = <!-- [[File: ]] -->\n| caption                = \n| collapsible            = \n| author                 = Thomas Quarles\n| developer              = \n| released               = {{Start date and age|1989}}\n| discontinued           = \n| latest release version = 3f.5\n| latest release date    = July 1993 <!-- {{Start date and age|1993|07|DD|df=yes/no}} -->\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| programming language   = [[C (programming language)|C]]\n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| genre                  = [[Electronic circuit simulation]]\n| license                = [[BSD license]]\n}}\n\n'''SPICE''' (\"'''Simulation Program with Integrated Circuit Emphasis'''\")<ref name=spice1>Nagel, L. W, and Pederson, D. O., ''SPICE (Simulation Program with Integrated Circuit Emphasis)'', Memorandum No. ERL-M382, University of California, Berkeley, Apr. 1973</ref><ref name=spice2>Nagel, Laurence W., ''SPICE2: A Computer Program to Simulate Semiconductor Circuits'', Memorandum No. ERL-M520, University of California, Berkeley, May 1975</ref> is a general-purpose, [[open-source software|open-source]] [[Analogue electronics|analog electronic circuit]] [[Electronic circuit simulation|simulator]].\nIt is a program used in [[integrated circuit]] and board-level design to check the integrity of [[circuit design]]s and to predict [[Electronic circuit|circuit]] behavior.\n\n== Introduction ==\nUnlike board-level designs composed of discrete parts, it is not practical to [[breadboard]] integrated circuits before manufacture. Further, the high costs of [[Photomask|photolithographic masks]] and other manufacturing prerequisites make it essential to design the circuit to be as close to perfect as possible before the integrated circuit is first built.  Simulating the circuit with SPICE is the industry-standard way to verify circuit operation at the transistor level before committing to manufacturing an integrated circuit.\n\nBoard-level circuit designs can often be breadboarded for testing. Even with a breadboard, some circuit properties may not be accurate compared to the final printed wiring board, such as parasitic resistances and capacitances.  These [[parasitic element (electrical networks)|parasitic components]] can often be estimated more accurately using SPICE simulation. Also, designers may want more information about the circuit than is available from a single mock-up. For instance, circuit performance is affected by component manufacturing tolerances.  In these cases it is common to use SPICE to perform [[Monte Carlo method|Monte Carlo]] simulations of the effect of component variations on performance, a task which is impractical using calculations by hand for a circuit of any appreciable complexity.\n\nCircuit simulation programs, of which SPICE and derivatives are the most prominent, take a text [[netlist]] describing the circuit elements ([[transistors]], [[resistors]], [[capacitors]], etc.) and their connections, and translate<ref>{{cite journal |first=Colin |last=Warwick |authorlink=Colin Warwick |url=http://www.nutwooduk.co.uk/pdf/Issue82.PDF#page=27 |work = EMC Journal |issue = 82 |pages = 27–29 |date = May 2009 |title = Everything you always wanted to know about SPICE* (*But were afraid to ask) |publisher = Nutwood UK Limited |issn = 1748-9253 |format = PDF}}</ref> this description into equations to be solved.  The general equations produced are [[nonlinear system|nonlinear]] [[differential algebraic equation]]s which are solved using [[Explicit and implicit methods|implicit integration methods]], [[Newton's method]] and [[sparse matrix]] techniques.\n\n== Origins ==\nSPICE was developed at the Electronics Research Laboratory of the [[University of California, Berkeley]] by [[Laurence Nagel]] with direction from his research advisor, Prof. [[Donald Pederson]].  SPICE1 was largely a derivative of the CANCER program,<ref>{{cite journal |author1=Nagel, L. W. |author2=Rohrer, R. A.  |lastauthoramp=yes |title= Computer Analysis of Nonlinear Circuits, Excluding Radiation |journal=IEEE Journal of Solid-State Circuits |volume=SC-6 |date=August 1971 |pages= 166–182 |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1050166 |doi= 10.1109/JSSC.1971.1050166|bibcode=1971IJSSC...6..166N }}{{dead link|date=March 2015}}</ref> which Nagel had worked on under Prof. Ronald Rohrer. CANCER was an acronym for \"Computer Analysis of Nonlinear Circuits, Excluding Radiation,\" a hint to Berkeley's liberalism in the 1960s:<ref>[http://www.designers-guide.org/Perspective/life-of-spice.pdf Life of SPICE] {{webarchive |url=https://web.archive.org/web/20120204190147/http://www.designers-guide.org/Perspective/life-of-spice.pdf |date=February 4, 2012 }}</ref> at these times many circuit simulators were developed under the [[United States Department of Defense]] contracts that required the capability to evaluate the [[radiation hardness]] of a circuit. When Nagel's original advisor, Prof. Rohrer, left Berkeley, Prof. Pederson became his advisor. Pederson insisted that CANCER, a proprietary program, be rewritten enough that restrictions could be removed and the program could be put in the public domain.<ref>{{cite journal |author=Perry, T. |title=Donald O. Pederson |journal=IEEE Spectrum |date=June 1998 |pages=22–27 |url=<!-- http://www.designers-guide.org/dop1998.pdf --> |doi=10.1109/6.681968 |volume=35}}</ref>\n\nSPICE1 was first presented at a conference in 1973.<ref name=autogenerated1>2nd spice1 ref</ref> SPICE1 was coded in [[FORTRAN]] and used [[nodal analysis]] to construct the circuit equations.  Nodal analysis has limitations in representing inductors, floating voltage sources and the various forms of controlled sources.  SPICE1 had relatively few circuit elements available and used a fixed-timestep [[transient analysis]].  The real popularity of SPICE started with SPICE2<ref name=autogenerated2>2nd spice2 ref</ref> in 1975.  SPICE2, also coded in FORTRAN, was a much-improved program with more circuit elements, variable timestep transient analysis using either the trapezoidal (second order [[Adams-Moulton method]]) or the Gear integration method (also known as [[Backward differentiation formula|BDF]]), equation formulation via [[modified nodal analysis]]<ref>{{cite conference |author=Ho, Ruehli, and Brennan |title=The Modified Nodal Approach to Network Analysis |booktitle=Proc. 1974 Int. Symposium on Circuits and Systems, San Francisco |date=April 1974 |pages=505–509 |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1084079|archive-url=http://webarchive.loc.gov/all/20110515144512/http%3A//ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber%3D1084079|dead-url=yes|archive-date=2011-05-15}}</ref> (avoiding the limitations of nodal analysis), and an innovative FORTRAN-based memory allocation system developed by another graduate student, Ellis Cohen.  The last FORTRAN version of SPICE was 2G.6 in 1983.  SPICE3<ref>Quarles, Thomas L., ''Analysis of Performance and Convergence Issues for Circuit Simulation'', Memorandum No. UCB/ERL M89/42, University of California, Berkeley, Apr. 1989.</ref> was developed by Thomas Quarles (with [[A. Richard Newton]] as advisor) in 1989. It is written in [[C (programming language)|C]], uses the same netlist syntax, and added [[X Window System]] plotting.\n\nAs an early [[public domain software]] program with [[source code]] available,<ref>[http://www.allaboutcircuits.com/textbook/reference/chpt-7/history-of-spice/ history-of-spice] {{webarchive |url=https://web.archive.org/web/20161009084508/http://www.allaboutcircuits.com/textbook/reference/chpt-7/history-of-spice/ |date=October 9, 2016 }} on allaboutcircuits.com ''\"The origin of SPICE traces back to another circuit simulation program called CANCER. Developed by professor Ronald Rohrer of U.C. Berkeley along with some of his students in the late 1960s, CANCER continued to be improved through the early 1970s. When Rohrer left Berkeley, CANCER was re-written and re-named to SPICE, released as version 1 to the public domain in May of 1972. Version 2 of SPICE was released in 1975 (version 2g6—the version used in this book—is a minor revision of this 1975 release). Instrumental in the decision to release SPICE as a public-domain computer program was professor Donald Pederson of Berkeley, who believed that all significant technical progress happens when information is freely shared. I for one thank him for his vision.\"''</ref> SPICE was widely distributed and used. Its ubiquity became such that \"to SPICE a circuit\" remains synonymous with circuit simulation.<ref>{{cite news |last=Pescovitz |first=David |url=http://www.coe.berkeley.edu/labnotes/0502/history.html |title=1972: The release of SPICE, still the industry standard tool for integrated circuit design  |publisher=Lab Notes: Research from the Berkeley College of Engineering |date=2002-05-02 |accessdate=2007-03-10}}</ref> SPICE source code was from the beginning distributed by UC Berkeley for a nominal charge (to cover the cost of magnetic tape). The license originally included distribution restrictions for countries not considered friendly to the US, but the source code is currently covered by the [[BSD license]].\n\nThe birth of SPICE was named an [[List of IEEE milestones|IEEE Milestone]] in 2011; the entry mentions that SPICE \"evolved to become the worldwide standard integrated circuit simulator.\"<ref>{{cite web |url=http://www.ieeeghn.org/wiki/index.php/Milestones:List_of_IEEE_Milestones |title=List of IEEE Milestones |date= |work=IEEE Global History Network |publisher=IEEE |accessdate=4 August 2011}}</ref> Nagel was awarded the ''2019 IEEE Donald O. Pederson Award in Solid-State Circuits'' for the development of SPICE.<ref>[https://sscs.ieee.org/about/awards/donald-o-pederson-solid-state-circuits-award Donald O. Pederson Solid-State Circuits Award], [[IEEE Solid-State Circuits Society]], June 2018</ref>\n\n== Commercial versions and spinoffs ==\nSPICE inspired and served as a basis for many other circuit simulation programs, in academia, in industry, and in commercial products.  The first commercial version of SPICE was ISPICE,<ref>Vladimirescu, Andrei, ''SPICE -- The Third Decade'', Proc. 1990 IEEE Bipolar Circuits and Technology Meeting, Minneapolis, Sept. 1990, pp. 96–101</ref> an interactive version on a timeshare service, [[National CSS]].  The most prominent commercial versions of SPICE include HSPICE (originally commercialized by [[Ashawna Hailey|Ashawna and Kim Hailey]] of Meta Software, but now owned by [[Synopsys]]) and [[PSPICE]] (now owned by [[Cadence Design Systems]]).  The academic spinoffs of SPICE include XSPICE, developed at [[Georgia Institute of Technology|Georgia Tech]], which added mixed analog/digital \"code models\" for behavioral simulation, and Cider (previously CODECS, from UC Berkeley/Oregon State Univ.) which added [[semiconductor device modeling|semiconductor device simulation]]. SPICE, XSPICE and CIDER have been integrated into open source [[ngspice]].<ref>ngspice, current status and future developments, H. Vogt, FOSDEM, Brussels 2019, https://fosdem.org/2019/schedule/event/ngspice/</ref> The integrated circuit industry adopted SPICE quickly, and until commercial versions became well developed many IC design houses had proprietary versions of SPICE.<ref>K. S. Kundert, ''The Designer’s Guide to SPICE and Spectre'', Kluwer. Academic Publishers, Boston , 1995</ref>\n\nToday a few IC manufacturers, typically the larger companies, have groups continuing to develop SPICE-based circuit simulation programs. Among these are ADICE at [[Analog Devices]], [[LTspice]] at [[Linear Technology]] (available to the public as freeware),  Mica at [[Freescale Semiconductor]] and [[TINA (software)|TINA]] at [[Texas Instruments]]. Similarly to Linear Technology, Texas Instruments makes available a freeware Windows version of the TINA software<ref>[http://www.tina.com/ TINA - Circuit Simulator for Analog, Digital, MCU & Mixed Circuit Simulation<!-- Bot generated title -->] {{webarchive |url=https://web.archive.org/web/20161105090338/http://www.tina.com/ |date=November 5, 2016 }}</ref> (called TINA-TI<ref>[http://www.ti.com/tool/tina-ti SPICE-Based Analog Simulation Program - TINA-TI - TI Software Folder<!-- Bot generated title -->] {{webarchive |url=https://web.archive.org/web/20161019062912/http://www.ti.com/tool/tina-ti |date=October 19, 2016 }}</ref>), which also includes their version of SPICE and comes preloaded with models for the company's integrated circuits.<ref name=\"Kay2012\">{{cite book|author=Art Kay|title=Operational Amplifier Noise: Techniques and Tips for Analyzing and Reducing Noise|url=https://books.google.com/books?id=0_PkTgqJD3kC&pg=PA41|year=2012|publisher=Elsevier|isbn=978-0-08-094243-8|page=41}}</ref><ref name=\"Mancini2012\">{{cite book|author=Ron Mancini|title=Op Amps for Everyone|url=https://books.google.com/books?id=0J6GtAlcHUcC&pg=PA162|year=2012|publisher=Newnes|isbn=978-0-12-394406-1|page=162}}</ref> Analog Devices offers a similar free tool called ADIsimPE (based on the SIMetrix/SIMPLIS<ref>[http://www.simetrix.co.uk/site/simetrix-simplis.html SIMertrix/SIMPLIS] {{webarchive |url=http://arquivo.pt/wayback/20160517092453/http://www.simetrix.co.uk/site/simetrix-simplis.html |date=May 17, 2016 }}</ref> implementation of SPICE).<ref>[http://www.analog.com/en/content/adisimpe/fca.html] {{webarchive |url=https://web.archive.org/web/20140706082430/http://www.analog.com/en/content/adisimpe/fca.html |date=July 6, 2014 }}</ref> Other companies maintain internal  circuit simulators which are not directly based upon SPICE, among them PowerSpice at [[IBM]], TITAN at [[Infineon Technologies]], Lynx at [[Intel Corporation]], and Pstar at [[NXP Semiconductor]].{{citation needed|date=October 2014}}\n\n== Program features and structure ==\nSPICE became popular because it contained the analyses and models needed to design integrated circuits of the time, and was robust enough and fast enough to be practical to use.<ref name=\"SPICE4\">Nagel, L., [http://www.cs.sandia.gov/nacdm/talks/Nagal_Larry_NACDM2004.pdf Is it Time for SPICE4?] {{webarchive |url=https://web.archive.org/web/20060926034314/http://www.cs.sandia.gov/nacdm/talks/Nagal_Larry_NACDM2004.pdf |date=September 26, 2006 }}, 2004 Numerical Aspects of Device and Circuit Modeling Workshop, June 23–25, 2004, Santa Fe, New Mexico. Retrieved on 2007-11-10</ref> Precursors to SPICE often had a single purpose: The BIAS<ref>{{cite journal |author=McCalla and Howard |title=BIAS-3&nbsp;– A program for nonlinear D.C. analysis of bipolar transistor circuits |journal=IEEE Journal of Solid-State Circuits |volume=6 |number=1 |date=February 1971 |pages=14–19 |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1050153 |doi=10.1109/JSSC.1971.1050153 |bibcode=1971IJSSC...6...14M }}{{dead link|date=March 2015}}</ref> program, for example, did simulation of bipolar transistor circuit operating points; the SLIC<ref>{{cite journal |author=Idleman, Jenkins, McCalla and Pederson |title=SLIC—a simulator for linear integrated circuits| journal=IEEE Journal of Solid-State Circuits |volume=6 |number=4 |date=August 1971 |pages=188–203 |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1050168 |doi=10.1109/JSSC.1971.1050168 |bibcode=1971IJSSC...6..188I }}{{dead link|date=March 2015}}</ref> program did only small-signal analyses.  SPICE combined operating point solutions, transient analysis, and various small-signal analyses with the circuit elements and device models needed to successfully simulate many circuits.\n\n=== Analyses ===\nSPICE2 included these analyses:\n* AC analysis ([[linear]] [[small signal model|small-signal]] frequency domain analysis)\n* DC analysis (nonlinear [[quiescent point]] calculation)\n* DC transfer curve analysis (a sequence of nonlinear operating points calculated while sweeping an input voltage or current, or a circuit parameter)\n* Noise analysis (a small signal analysis done using an adjoint matrix technique which sums uncorrelated noise currents at a chosen output point)\n* [[Transfer function]] analysis (a small-signal input/output gain and impedance calculation)\n* Transient analysis (time-domain large-signal solution of nonlinear differential algebraic equations)\n\nSince SPICE is generally used to model [[nonlinear]] circuits, the small signal analyses are necessarily preceded by a [[quiescent point]] calculation at which the circuit is linearized. SPICE2 also contained code for other small-signal analyses: [[sensitivity analysis]], [[Pole–zero plot|pole-zero analysis]], and [[small-signal]] [[distortion]] analysis. Analysis at various temperatures was done by automatically updating semiconductor model parameters for temperature, allowing the circuit to be simulated at temperature extremes.\n\nOther circuit simulators have since added many analyses beyond those in SPICE2 to address changing industry requirements. Parametric sweeps were added to analyze circuit performance with changing manufacturing tolerances or operating conditions. Loop gain and stability calculations were added for analog circuits. [[Harmonic balance]] or time-domain steady state analyses were added for RF and switched-capacitor circuit design. However, a public-domain circuit simulator containing the modern analyses and features needed to become a successor in popularity to SPICE has not yet emerged.<ref name=\"SPICE4\"/>\n\nIt is very important to use appropriate analyses with carefully chosen parameters. For example, application of linear analysis to nonlinear circuits should be justified separately. Also, application of transient analysis with default simulation parameters can lead to qualitatively wrong conclusions on circuit dynamics.<ref>{{cite journal |first=Giovanni |last=Bianchi |arxiv=1506.02484| date = 2015 |title = Limitations of PLL simulation: hidden oscillations in SPICE analysis |bibcode=2015arXiv150602484B}}</ref>\n\n=== Device models ===\nSPICE2 included many semiconductor device [[transistor models|compact models]]: three levels of [[MOSFET]] model, a combined [[Ebers-Moll model|Ebers–Moll]] and [[Gummel–Poon model|Gummel–Poon bipolar model]], a [[JFET]] model, and a model for a [[diode|junction diode]]. In addition, it had many other elements: resistors, capacitors, inductors (including [[Inductance#Coupled inductors|coupling]]), independent [[voltage source|voltage]] and [[current source]]s, ideal [[transmission line]]s, active components and voltage and current controlled sources.\n\nSPICE3 added more sophisticated MOSFET models, which were required due to advances in semiconductor technology.\nIn particular, the [[BSIM]] family of models were added, which were also developed at UC Berkeley.\n\nCommercial and industrial SPICE simulators have added many other device models as technology advanced and earlier models became inadequate. To attempt standardization of these models so that a set of model parameters may be used in different simulators, an industry working group was formed, the [[Compact Model Council]],<ref>{{cite web|url=http://www.geia.org/index.asp?bid=597 |title=CMC - Compact Model Council |publisher=GEIA |deadurl=yes |archiveurl=https://web.archive.org/web/20110511071827/http://www.geia.org/index.asp?bid=597 |archivedate=May 11, 2011 }}</ref> to choose, maintain and promote the use of standard models.  The standard models today include [http://www-device.eecs.berkeley.edu/bsim/?page=BSIM3 BSIM3], [http://www-device.eecs.berkeley.edu/bsim/?page=BSIM4 BSIM4], [https://web.archive.org/web/20150224064144/http://www-device.eecs.berkeley.edu/bsim/?page=BSIMSOI BSIMSOI], [https://web.archive.org/web/20071017140132/http://pspmodel.asu.edu/ PSP], [http://www.iee.et.tu-dresden.de/iee/eb/hic_new/hic_start.html HICUM], and [http://mextram.ewi.tudelft.nl/ MEXTRAM].\n\n===Input and output: Netlists, schematic capture and plotting===\nSPICE2 took a text [[netlist]] as input and produced line-printer listings as output, which fit with the computing environment in 1975.  These listings were either columns of numbers corresponding to calculated outputs (typically voltages or currents), or line-printer [[ASCII art|character \"plots\"]].  SPICE3 retained the netlist for circuit description, but allowed analyses to be controlled from a [[command line interpreter|command-line]] interface similar to the [[C shell]].  SPICE3 also added basic [[X Window System|X]] plotting, as [[UNIX]] and engineering [[workstation]]s became common.\n\nVendors and various free software projects have added [[schematic capture]] front-ends to SPICE, allowing a [[schematic diagram]] of the circuit to be drawn and the netlist to be automatically generated. Also, [[graphical user interface]]s were added for selecting the simulations to be done and manipulating the voltage and current output vectors. In addition, very capable graphing utilities have been added to see waveforms and graphs of parametric dependencies. Several free versions of these extended programs are available, some as introductory [[PSpice|limited packages]], and some [[Linear Technology|without restrictions]].\n\n===Transient analysis===\nSince transient analysis is dependent on time, it uses different analysis algorithms, control options with different convergence-related issues and different initialization parameters than DC analysis. However, since a transient analysis first performs a DC operating point analysis (unless the UIC option is specified in the .TRAN statement), most of the DC analysis algorithms, control options, and initialization and convergence issues apply to transient analysis.\n\n====Initial conditions for transient analysis====\nSome circuits, such as oscillators or circuits with feedback, do not have stable operating point solutions. For these circuits, either the feedback loop must be broken so that a DC operating point can be calculated or the initial conditions must be provided in the simulation input. The DC operating point analysis is bypassed if the UIC parameter is included in the .TRAN statement. If UIC is included in the .TRAN statement, a transient analysis is started using node voltages specified in an .IC statement. If a node is set to 5 V in a .IC statement, the value at that node for the first time point (time 0) is 5 V.\n\nYou can use the .OP statement to store an estimate of the DC operating point during a transient analysis.\n\n<code>\n\t.TRAN 1ns 100ns UIC\n\t.OP 20ns\n</code>\n\nThe .TRAN statement UIC parameter in the above example bypasses the initial DC operating point analysis. The .OP statement calculates transient operating point at t = 20 ns during the transient analysis.\n\nAlthough a transient analysis might provide a convergent DC solution, the transient analysis itself can still fail to converge. In a transient analysis, the error message \"internal timestep too small\" indicates that the circuit failed to converge. The convergence failure might be due to stated initial conditions that are not close enough to the actual DC operating point values.\n\n==See also==\n{{Portal|Electronics|Free and open-source software}}\n* [[Comparison of EDA Software]]\n* [[List of free electronics circuit simulators]]\n* [[Input Output Buffer Information Specification]] (IBIS)\n* [[Transistor models]]\n\n== References ==\n{{reflist|30em}}\n\n== External links ==\n{{Commons category|SPICE}}\n* [https://embedded.eecs.berkeley.edu/pubs/downloads/spice/index.htm Spice at UC Berkeley]\n\n=== Histories, original papers ===\n* [http://www.eecs.berkeley.edu/Pubs/TechRpts/1973/22871.html The original SPICE1 paper]\n* [http://www.eecs.berkeley.edu/Pubs/TechRpts/1975/9602.html L. W. Nagel's dissertation (SPICE2)]\n* [http://www.eecs.berkeley.edu/Pubs/TechRpts/1989/1216.html Thomas Quarles' dissertation (SPICE3)]\n* [http://www.ecircuitcenter.com/SpiceTopics/History.htm A brief history of SPICE]\n* [http://embedded.eecs.berkeley.edu/pubs/downloads/spice/index.htm SPICE2 and SPICE3 at UC Berkeley]\n* [http://embedded.eecs.berkeley.edu/pubs/downloads/cider/index.htm Cider at UC Berkeley]\n* [http://www.eeworldonline.com/spice-how-to-choose-an-analysis/ SPICE: how to choose an analysis]\n\n[[Category:1973 software]]\n[[Category:Electronic design automation software]]\n[[Category:Free software programmed in C]]\n[[Category:Free software programmed in Fortran]]\n[[Category:Simulation programming languages]]\n[[Category:Electronic circuit simulators]]\n[[Category:Free simulation software]]\n[[Category:Electronic design automation software for Linux]]\n[[Category:Public-domain software with source code]]\n[[Category:Software using the BSD license]]"
    },
    {
      "title": "XDrawChem",
      "url": "https://en.wikipedia.org/wiki/XDrawChem",
      "text": "{{multiple issues|\n{{notability|Products|date=November 2012}}\n{{primary sources|date=November 2012}}\n{{self-published|date=November 2012}}\n}}\n{{Infobox software\n| name                   = XDrawChem\n| title                  = \n| logo                   = \n| screenshot             = [[File:XDrawChem 1.9.9 German.png|300px]]\n| caption                = XDrawChem 1.9.9\n| collapsible            = \n| author                 = \n| developer              = \n| released               = <!-- {{Start date|YYYY|MM|DD}} -->\n| discontinued           = \n| latest release version = 1.9.9  \n| latest release date    = {{Start date and age|2005|11|30}}\n| latest preview version = \n| latest preview date    =\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\n| programming language   = C++\n| operating system       = UNIX and X Window (Linux, SGI IRIX, Sun Solaris, others...) or macOS\n| platform               =\n| size                   = \n| language               = \n| status                 = \n| genre                  = [[Molecular editor]]\n| license                = GNU GPL\n| website                =\n}}\n\n'''XDrawChem''' is a [[free software]] program for drawing chemical [[structural formula]]s, available for [[Unix]] and [[macOS]]. It is distributed under the [[GNU GPL]]. In [[Microsoft Windows]] this program is called WinDrawChem.\n\n== Major features ==\n* Fixed length and fixed angle drawing\n* Automatic alignment of figures\n* Detection of structures, text, and arrows, and their automatic placement\n* Can automatically draw rings and other structures - has all standard [[amino acid]]s and [[nucleic acid]]s in a built-in library\n* Retrieval of structures from a network database based on [[CAS number]], formula, or name\n* Retrieval of information on a molecule based on a drawing\n* Symbols such as [[partial charge]] and [[Radical (chemistry)|radical]]s\n* Reading MDL Molfiles, CML ([[Chemical Markup Language]]), [[ChemDraw]] binary format, ChemDraw XML text format\n* Writing MDL Molfiles, CML, [[ChemDraw]] XML text format\n* Integration with [[OpenBabel]], allowing XDrawChem to read and write over 20 different [[chemical file format]]s.\n* Image export in [[Portable Network Graphics]] (PNG), Windows bitmap, [[Encapsulated PostScript]] (EPS), and [[Scalable Vector Graphics]] (SVG)\n* 3D structure generation with the help of the external program BUILD3D\n* Simple spectra predictions, including 13C-NMR, 1H-NMR (based on additive rules and functional group lookup methods), and IR\n* Simple property estimation, including pKa, octanol-water partition coefficient, and gas-phase [[enthalpy]] change.\n\n==See also==\n* [[ChemDraw]] &ndash; popular, proprietary chemical editor\n* [[BKchem]] &ndash; another GPL chemical editor\n\n== External links ==\n* [http://xdrawchem.sourceforge.net/ XDrawChem at [[Sourceforge]]]\n\n[[Category:Chemistry software]]\n[[Category:Free science software]]\n[[Category:Free software programmed in C++]]\n[[Category:Free software programmed in Fortran]]\n[[Category:Science software that uses Qt]]\n[[Category:Chemistry software for Linux]]\n{{Chemistry software}}"
    },
    {
      "title": "XFOIL",
      "url": "https://en.wikipedia.org/wiki/XFOIL",
      "text": "{{Infobox software\n| name                   = \n| title                  = \n| logo                   = <!-- Image name is enough -->\n| logo caption           = \n| logo_size              = \n| logo_alt               = \n| screenshot             = <!-- Image name is enough -->\n| caption                = \n| screenshot_size        = \n| screenshot_alt         = \n| collapsible            = \n| author                 = \n| developer              = \n| released               = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| discontinued           = \n| latest release version = \n| latest release date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| latest preview version = \n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\n| status                 = \n| programming language   = [[Fortran]]\n| operating system       = \n| platform               = \n| size                   = \n| language               = \n| language count         = <!-- DO NOT include this parameter unless you know what it does -->\n| language footnote      = \n| genre                  = \n| license                = \n| website                = {{URL|http://web.mit.edu/drela/Public/web/xfoil}}\n}}\n\n'''XFOIL''' is an interactive program for the design and analysis of subsonic isolated [[airfoil]]s. Given the coordinates specifying the shape of a 2D airfoil, [[Reynolds Number|Reynolds]] and [[Mach Number|Mach numbers]], XFOIL can calculate the pressure distribution on the airfoil and hence [[lift (force)|lift]] and [[drag (force)|drag]] characteristics. The program also allows ''inverse design'' - it will vary an airfoil shape to achieve the desired parameters. It is released under the [[GNU GPL]].\n\n==History==\n\nXFOIL was first developed by Mark Drela at [[MIT]] as a design tool for the [[MIT Daedalus]] project in the 1980s.<ref>http://web.mit.edu/aeroastro/news/magazine/aeroastro-no3/2006drela.html</ref> It was further developed in collaboration with Harold Youngren. The current version is 6.99, released in December 2013.  Despite its vintage, it is still widely used.<ref>{{cite web|url=http://www.aoe.vt.edu/~mason/Mason_f/MRsoft.html |title=Archived copy |accessdate=August 3, 2010 |deadurl=yes |archiveurl=https://web.archive.org/web/20100608184358/http://www.aoe.vt.edu/~mason/Mason_f/MRsoft.html |archivedate=June 8, 2010 }}</ref>\n\nXFOIL is written in [[FORTRAN]].\n\n== Similar Programs ==\n* XFOIL was translated to the C++ language and integrated in the program [[XFLR5]], principally for use on model aircraft design. \n* A [[MATLAB]] implementation called [http://www.mathworks.com/matlabcentral/fileexchange/50070-xfoil-for-matlab.html Xfoil for matlab] has been written.\n* An unrelated program called [http://www.mh-aerotools.de/airfoils/javafoil.htm JavaFoil] may be used for similar analysis. It is written in [[Java (programming language)|Java]].\n* [[Vortexje]] is an independent panel method implementation in 3D.\n* [[QBlade]] implements XFOIL via XFLR5 for use in wind turbine design.\n\n==References==\n<references/>\n\n==External links==\n* [http://web.mit.edu/drela/Public/web/xfoil/ The XFOIL home page]\n* [http://www.xflr5.com/xflr5.htm XFLR5]\n\n[[Category:Free computer-aided design software]]\n[[Category:Free software programmed in Fortran]]\n[[Category:Computer-aided engineering software for Linux]]"
    },
    {
      "title": "MODTRAN",
      "url": "https://en.wikipedia.org/wiki/MODTRAN",
      "text": "'''MODTRAN''' (MODerate resolution atmospheric TRANsmission) is a computer program designed to model [[atmosphere|atmospheric]] propagation of [[electromagnetic radiation]] for the 100-50,000&nbsp;cm<sup>−1</sup> (0.2 to 100&nbsp;µm) spectral range.  This covers the spectrum from middle [[ultraviolet]] to [[visible light]] to [[far infrared]]. \n\nThe most recently released version of the code, MODTRAN6, provides a spectral resolution of 0.2&nbsp;cm<sup>−1</sup> using its 0.1&nbsp;cm<sup>−1</sup> band model algorithm.\n\nSome aspects of MODTRAN are patented by [[Spectral Sciences Incorporated|Spectral Sciences, Inc.]] and the [[US Air Force]], who have shared development responsibility for the code and related [[Radiative transfer|radiation transfer]] science collaboratively since 1987.  The acronym MODTRAN was registered as a [[trademark]] of the [[US Government]], represented by the [[US Air Force]], in 2008.\n\nAll MODTRAN code development and maintenance is currently performed by [[Spectral Sciences Incorporated|Spectral Sciences]] while the Air Force handles code validation and verification.  MODTRAN6 may be obtained from [http://www.MODTRAN.com Spectral Sciences, Inc.]\n\nMODTRAN is written entirely in [[FORTRAN]].  MODTRAN6 adds support for JSON formatted input files, along with a graphical user interface that enables users to load existing cases, interactively enter or modify inputs, save their JSON formatted input files, run MODTRAN6, and graphically view the newly generated spectral output data.  Third parties, including Ontar, have also developed graphical user interfaces for MODTRAN in order to facilitate user interaction and ease of use.\n\n==See also==\n* [[HITRAN]] - a compilation of spectroscopic parameters \n* [[List of atmospheric radiative transfer codes]]\n* [[SMARTS (The Simple Model of the Atmospheric Radiative Transfer of Sunshine)]] a software\n\n==External links==\n* [http://www.MODTRAN.com MODTRAN web site] \n* [https://archive.is/20121214155059/http://patft.uspto.gov/netacgi/nph-Parser?patentnumber=5,884,226 USAF patent 5884226]\n* [https://archive.is/20130626173611/http://patft.uspto.gov/netacgi/nph-Parser?patentnumber=7,433,806 USAF patent 7433806]\n* [https://scholar.google.com/scholar?q=MODTRAN Google scholar papers on MODTRAN]\n* [https://web.archive.org/web/20080428080138/http://www.kirtland.af.mil/library/factsheets/factsheet.asp?id=7915 Main Page] Air Force Site\n\n{{DEFAULTSORT:Modtran}}\n[[Category:Electromagnetic radiation]]\n[[Category:Fortran libraries]]\n[[Category:Atmospheric radiative transfer codes]]"
    },
    {
      "title": "PFUnit",
      "url": "https://en.wikipedia.org/wiki/PFUnit",
      "text": "{{multiple issues|\n{{notability|date=October 2012}}\n{{refimprove|date=April 2014}}\n{{context|date=October 2012}}\n}}\n\n{{lowercase|title=pFUnit}}\n'''pFUnit''' is a [[Fortran]] framework for [[unit testing]] following the [[xUnit]] model.<ref>{{cite web | url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5999647&tag=1 | title=Software Testing and Verification in Climate Model Development | accessdate=January 16, 2014 | work=IEEE Software, Vol. 28, Iss. 6, Nov.-Dec. 2011}}</ref> Capabilities include parallel execution using [[Message Passing Interface|MPI]] and [[OpenMP]].<ref>{{cite web | url=http://pfunit.sourceforge.net | title=pFUnit 3 - Documentation `Reference Manual' | accessdate=January 16, 2014}}</ref> Development began at NASA [[Goddard Space Flight Center]] in 2005. The framework makes extensive use of modern standard features of Fortran (2003, 2008), like support for object oriented programming.  A python-based preprocessor provides directives reminiscent of other xUnit testing frameworks (e.g. @assert), as well as support for parameterized test cases.  pFUnit can be built using either a [[GNU make]] or [[CMake]] process.\n\nIt is published under the [[NASA Open Source Agreement]] version 1.3.<ref>{{cite web | url=http://sourceforge.net/p/pfunit/code/ci/master/tree/LICENSE | title=NASA Open Source Agreement version 1.3 | accessdate=January 16, 2014}}</ref>\n\n== See also ==\n* [[List of unit testing frameworks]]\n* [[Fortran]]\n\n== References ==\n{{reflist}}\n\n== External links ==\n* [https://github.com/Goddard-Fortran-Ecosystem/pFUnit GitHub project page]\n* [http://sourceforge.net/projects/pfunit/ SourceForge project page]\n* [http://science.gsfc.nasa.gov/610.3/pFUnit.html NASA GSFC project page]\n* [http://modelingguru.nasa.gov NASA Modeling Guru]\n* [http://sea.ucar.edu/sites/default/files/pFUnitTutorial.pdf pFUnit (Version 1, now superseded by Versions 2 etc.) tutorial at UCAR, T. Clune, NASA/GSFC, 2012 April 31]\n\n[[Category:Unit testing frameworks]]\n[[Category:Fortran libraries]]\n[[Category:Computer programming stubs]]\n\n\n{{compu-prog-stub}}"
    },
    {
      "title": "SLIP (programming language)",
      "url": "https://en.wikipedia.org/wiki/SLIP_%28programming_language%29",
      "text": "{{distinguish|Serial Line Internet Protocol}}\n'''SLIP''' is a list processing [[computer programming language]], invented by [[Joseph Weizenbaum]] in the 1960s.  The name ''SLIP'' stands for '''S'''ymmetric '''LI'''st '''P'''rocessor.  It was first implemented as an extension to the [[Fortran]] programming language, and later embedded into [[MAD programming language|MAD]] and [[ALGOL]].<ref>[http://www.heuse.com/s.htm Computer Programming Languages - S<!-- Bot generated title -->]</ref>\n\n== General Overview ==\nIn a nutshell, SLIP consisted of a set of FORTRAN \"accessor\" functions which operated on [[doubly linked list|circular doubly linked lists]] with fixed-size data fields.  The \"accessor\" functions had direct and indirect addressing variants.\n\n== List Representation ==\nThe list representation had four types of cell: a ''reader'', a ''header'', a ''sublist indicator'', and a ''payload'' cell.  The header included a reference count field for [[Garbage collection (computer science)|garbage collection]] purposes.  The sublist indicator allowed it to be able to represent nested lists, such as (A, B, C, (1, 2, 3), D, E, F) where (1, 2, 3) is a sublist indicated by a cell in the '*' position in the list (A, B, C, *, D, E, F).  The reader was essentially a state history stack—a good example of a [[memento pattern]]—where each cell pointed to the header of the list being read, the current position within the list being read, and the level or depth of the history stack.\n\n==References==\n<references />\n* ''Symmetric List Processor'', Joseph Weizenbaum, CACM 6:524-544(1963). Sammet 1969, p.&nbsp;387.\n* ''[[Computer Power and Human Reason|Computer Power and Human Reason: From Judgment To Calculation]]'', Joseph Weizenbaum, San Francisco: W. H. Freeman, 1976 {{ISBN|0-7167-0463-3}}\n\n[[Category:Fortran libraries]]\n[[Category:Programming languages]]\n\n\n{{compu-lang-stub}}"
    },
    {
      "title": "Comparison of spreadsheet software",
      "url": "https://en.wikipedia.org/wiki/Comparison_of_spreadsheet_software",
      "text": "[[Spreadsheet]] is a class of [[application software]] design to analyze tabular data called \"worksheets\". A collection of worksheets is called a \"workbook\". [[Online spreadsheet]]s do not depend on a particular operating system but require a standards-compliant [[web browser]] instead. One of the incentives for the creation of online spreadsheets was offering worksheet sharing and public sharing or workbooks as part of their features which enables collaboration between multiple users. Some on-line spreadsheets provide remote data update, allowing data values to be extracted from other users' spreadsheets even though they may be inactive at the time.\n\n==General==\n{| class=\"wikitable sortable floatleft\" style=\"font-size: 85%; text-align: center; width: auto;\"\n|-\n! style=\"width: 12em\"|Name\n! Screenshot \n! Creator\n! Development started\n! First public release\n! Latest stable version\n! [[software license|License]]\n|-\n! [[Calligra Sheets]]\n| [[Image:CalligraSheets3.1Screenshot.png|150px]]\n| [[KOffice]] KSpread Team\n| \n| \n| {{Latest stable software release/Calligra Suite}}\n| {{Free|[[GNU Lesser General Public License|LGPL]]}}\n|-\n! [[Gnumeric]]\n| [[Image:Gnumeric 1.8.1.png|150px]]\n| [[GNOME]] community\n| 1998\n| 1998\n| {{Latest stable software release/Gnumeric}}\n| {{Free|[[GNU General Public License|GPL]]}}\n|-\n! [[IBM Lotus Symphony]]\n| \n| [[IBM]]\n| \n| 2008\n| 1.3 / 2009\n| {{Free|[[Freeware]]}}\n|-\n! [[LibreOffice Calc]]\n| [[File:LibreOffice 5.1 Calc (Tango).png|150px]]\n| [[The Document Foundation]]\n| 2010\n| 3.3 / 2011-01-25\n| {{Latest stable software release/LibreOffice}}\n| {{Free|[[Mozilla Public License|MPL]]}}\n|-\n! [[Mariner Calc]]\n| \n| [[Mariner Software]]\n| 1988\n| 1989\n| 5.6.0\n| {{dropped|Discontinued}}\n|-\n! [[Microsoft Excel]]\n| \n| [[Microsoft]]\n| 1982\n| 1985\n| 16 (64-bit) / September 2015\n| {{Nonfree|[[Freemium]]}}\n|-\n! [[Numbers (software)|Numbers]]\n| \n| Apple, Inc.\n| \n| August 7, 2007\n| 3.5 / October 16, 2014\n| {{Nonfree|[[Commercial software|Commercial]] [[Proprietary software]]}}\n|-\n! [[OpenOffice Calc]]\n| [[Image:OpenOffice.org Calc.png|150px]]\n| [[Apache Software Foundation]]\n| 2000\n| Build 638c / October 2001\n| {{Latest stable software release/Apache OpenOffice Calc}}\n| {{Free|[[Apache License]] v2}}\n|-\n![[OnlyOffice]]\n![[File:ONLYOFFICE Spreadsheet Editor.png|thumb|ONLYOFFICE online spreadsheet editor]]\n!Ascensio System SIA\n!2009\n!2014\n!\n!{{Free|[[GNU General Public License|GPL]]}}\n|-\n! [[PlanMaker]]\n| \n| [[SoftMaker|SoftMaker Software GmbH]]\n| \n| 1994<ref>{{cite web |url=http://www.softmaker.de/planmake.htm |title=Infos zu PlanMaker 97 |date=1997-06-03 |accessdate=2010-03-28 |archiveurl=https://web.archive.org/web/19970603185443/http://www.softmaker.de/planmake.htm |archivedate=1997-06-03}}</ref><ref name=\"review\">{{cite web |url=http://www.consortiuminfo.org/standardsblog/article.php?story=2006070509040463 |title=The Emerging ODF Environment, Part IV: Spotlight on SoftMaker Office 2006 |author=Andy Updegrove |date=2006-07-05 |accessdate=2010-03-28}}</ref>\n| 2012\n| {{Nonfree|[[Trialware]]}}\n|-\n! [[Pyspread]]\n| [[File:Pyspread screenshot - sinus large.png|150px]]\n| Martin Manns\n| 2008\n| 2008\n| 1.1.1 / 2017-10-30\n| {{Free|[[GPL]]}}\n|-\n! [[Quattro Pro]]\n|\n| [[Corel]]\n| 1988\n| 1988\n| X7\n| {{Nonfree|[[Trialware]]}}\n|-\n! [[Resolver One]]\n| \n| Resolver Systems\n| 2005\n| 2008-01-16\n| 1.9 / 2010-06-04\n| {{dropped|Discontinued}}\n|-\n! [[Siag Office|Siag]]\n| [[Image:SiagOffice 3.4.9.png|150px]]\n| Ulric Eriksson\n| 1996\n| \n| 3.6.1 / 2006\n| {{Free|[[GPL]]}}\n|-\n! [[WPS Office]]\n| [[File:WPS Office v11.2 Spreadsheet.png|thumb|]]\n| [[Kingsoft]]\n| 1988\n| 1988\n| 2019\n|  {{Nonfree|[[Freemium]]}}\n|-class=\"sortbottom\"\n! style=\"width: 12em\" |Name\n! Screenshot \n! Creator\n! Development started\n! First public release\n! Latest stable version\n! License\n|}\n{| class=\"wikitable floatleft\" style=\"font-size: 85%; width: auto; clear:none\"\n! Legend\n|-\n| {{Free|Licensed at no cost}}\n|-\n| {{Nonfree|Licensed commercially}}\n|}\n{{Clear}}\n\n==Operating system support==\nThe [[operating system]]s the software can run on natively (without [[emulator|emulation]]).\n\n{| class=\"wikitable sortable\" style=\"font-size: 85%; text-align: center; width: auto;\"\n|-\n! style=\"width: 12em\" |Name\n! [[Windows]]\n! [[macOS]]\n! [[Linux]]\n! [[Berkeley Software Distribution|BSD]]\n! [[Unix]]\n|-\n! [[Calligra Sheets]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{no}}\n|-\n! [[Gnumeric]]\n| {{yes}} (old)\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n|-\n! [[IBM Lotus Symphony]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{no}}\n| {{no}}\n|-\n! [[LibreOffice Calc]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n|-\n! [[WPS Office]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{no}}\n| {{no}}\n|-\n! [[Mariner Calc]]\n| {{no}}\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{no}}\n|-\n! [[Microsoft Excel]]\n| {{yes}}\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{no}}\n|-\n! [[Numbers (software)|Numbers]]\n| {{no}}\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{no}}\n|-\n! [[OpenOffice Calc]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n|-\n! [[PlanMaker]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{no}}\n| {{no}}\n|-\n! [[Pyspread]]\n| {{yes}}\n| {{partial|Unsupported}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n|-\n! [[Quattro Pro]]\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{no}}\n| {{no}}\n|-\n! [[Resolver One]]\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{no}}\n| {{no}}\n|-\n! [[Siag Office|Siag]]\n| {{no}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{yes}}\n|}\n\n==Supported file formats==\nThis table gives a comparison of what [[file format]]s each spreadsheet can import and export.  \"Yes\" means can both import and export.\n\n{| class=\"wikitable sortable\" style=\"font-size: 85%; text-align: center; width: auto;\"\n|-\n! style=\"width: 12em\" |Name\n! [[Comma-separated values|CSV]]\n! [[Microsoft Excel file format|Excel]]<br/>(xls)\n! [[HTML]]\n! [[LaTeX]]\n! [[Open Document Format|ODF]]<br/>(ods)\n! [[Office Open XML|OOXML]]<br/>(xlsx)\n! [[PDF]]\n! [[Data Interchange Format|DIF]]\n! [[OpenOffice.org XML]]<br/>(sxc)\n|-\n! [[Calligra Sheets]]\n| {{yes}}\n| {{partial|Import}}\n| {{partial|Export}}\n| {{partial|Export}}\n| {{yes}}\n| {{no}}\n| {{partial|Export}}\n| {{dunno}}\n| {{yes}}\n|-\n! [[Gnumeric]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{partial|Export}}\n| {{yes}}\n| {{yes}}\n| {{partial|Export}}\n| {{partial|Import}}\n| {{partial|Import}}\n|-\n! [[IBM Lotus Symphony]]\n| {{yes}}\n| {{yes}}\n| {{partial|Export}}\n| {{no}}\n| {{yes}}\n| {{partial|Import}}\n| {{partial|Export}}\n|\n| {{yes}}\n|-\n! [[LibreOffice Calc]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{no}}\n| {{yes}}\n| {{Yes}}\n| {{partial|Export}}\n| {{yes}}\n| {{yes}}\n|-\n! [[Mariner Calc]]\n| {{yes}}\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{no}}\n| {{no}}\n| {{partial|Export}}\n|\n| {{no}}\n|-\n! [[Microsoft Excel]]\n| {{yes}}\n| {{yes}}\n| {{partial}}\n| {{no}}\n| {{yes}}\n| {{yes}}\n| {{partial|Export}}\n| {{partial|Import}}\n| {{no}}\n|-\n! [[WPS Office]]\n| {{yes}}\n| {{yes}}\n| {{partial}}\n| {{no}}\n| {{yes}}\n| {{yes}}\n| {{partial|Export}}\n| {{partial|Import}}\n| {{no}}\n|-\n! [[Numbers (software)|Numbers]]\n| {{yes}}\n| {{yes}}\n| {{No}}\n| {{No}}\n| {{partial|Import}}\n| {{partial|Import}}\n| {{partial|Export}}\n|\n| {{No}}\n|-\n! [[OpenOffice Calc]]\n| {{yes}}\n| {{yes}}\n| {{yes}}\n| {{partial|Export<ref>Through extensions: {{cite web |url=http://extensions.openoffice.org/en/project/Calc2LaTeX |title=Calc2LaTeX |date=2009-07-15 |accessdate=2012-05-06}}</ref>}}\n| {{yes}}\n| {{partial|Import}}\n| {{partial|Export}}\n| {{yes}}\n| {{yes}}\n|-\n! [[Quattro Pro]]\n| {{Yes}}\n| {{Yes}}\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{partial|Import}}\n| {{partial|Export}}\n|\n| {{no}}\n|-\n! [[PlanMaker]]\n| {{Yes}}\n| {{Yes}}\n| {{partial|Export}}\n| {{no}}\n| {{no}}\n| {{partial|Import}}\n| {{partial|Export}}\n|\n| {{no}}\n|-\n! [[Pyspread]]\n| {{yes}}\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{partial|Import}}\n| {{partial|Import}}\n| {{partial|Export}}\n|\n| {{no}}\n|-\n! [[Resolver One]]\n| {{yes}}\n| {{yes}}\n| {{no}}\n| {{no}}\n| {{no}}\n| {{no}}\n| {{no}}\n|\n| {{no}}\n|-\n! [[Siag Office|Siag]]\n| {{yes}}\n| {{partial|Import partial}}\n| {{yes}}\n| {{partial|Export}}\n| {{no}}\n| {{no}}\n| {{partial|Export}}\n|\n| {{partial|Import partial}}\n|}\n\n==See also==\n*[[List of spreadsheets]]\n*[[List of online spreadsheets]]\n*[[Comparison of word processors]]\n\n==References==\n{{reflist}}\n\n{{Spreadsheets}}\n\n[[Category:Spreadsheet software|*]]\n[[Category:Comparisons of mathematical software|Spreadsheets]]"
    },
    {
      "title": "List of spreadsheet software",
      "url": "https://en.wikipedia.org/wiki/List_of_spreadsheet_software",
      "text": "The following is a '''list of [[spreadsheet]]s'''.\n\n==Free and open-source software==\n===Cloud and on-line spreadsheets===\n{{main|List of online spreadsheets}}\n* [[Sheetster]] – \"Community Edition\" is available under the [[Affero GPL]]\n*[https://www.zoho.com/sheet/ Zoho Sheet] - A simple, collaborative spreadsheet software.\n* [[Simple Spreadsheet]]\n* [[Tiki Wiki CMS Groupware]] includes a spreadsheet since 2004 and migrated to jQuery.sheet in 2010.<ref>{{Citation | url = http://doc.tiki.org/Spreadsheet | publisher = Tiki | title = Spreadsheet}}.</ref>\n* [[SocialCalc]] (was wikiCalc) by the original spreadsheet inventor Dan Bricklin \n* [[Airtable]] - a spreadsheet-database hybrid, with the features of a database but applied to a spreadsheet.\n* [[Ethercalc]] - multiuser, UI formulas and SocialCalc excel/google sheets formulas\n\n===Spreadsheets that are parts of suites===\n* [[Gnumeric]]&nbsp;— for [[Linux]].  Started as the [[GNOME]] desktop spreadsheet.  Reasonably lightweight but has very advanced features.<ref>{{Citation | contribution-url = http://www.gnome.org/projects/gnumeric/downloads.shtml | publisher = Gnome | title = Office | contribution = Gnumeric | type = downloads}}.</ref>\n* [[KSpread]]&nbsp;— following the fork of the [[Calligra Suite]] from [[KOffice]] in mid-2010, superseded by [[KCells]] in [[KOffice]] and [[Calligra Sheets|Sheets]] in the Calligra Suite.<ref>{{Citation | url = http://www.koffice.org/ | title = The KOffice Project}}.</ref>\n* [[LibreOffice]] [[LibreOffice Calc|Calc]]&nbsp;— developed for MS Windows, GNU/Linux, [[Berkeley Software Distribution|BSD]] and Apple [[OS X|Macintosh]] (Mac) operating systems by [[The Document Foundation]].  The Document Foundation was formed in mid-2010 by several large organisations such as [[Google]], [[Red Hat]], [[Canonical Ltd|Canonical]] ([[Ubuntu (operating system)|Ubuntu]]) and [[Novell]] along with the OpenOffice.org community (developed by [[Sun Microsystems|Sun]]) and various OpenOffice.org forks, notably [[Go-oo]].  Go-oo had been the \"OpenOffice\" used in Ubuntu and elsewhere.  Started as [[StarOffice]] in the late 1990s, it became OpenOffice under [[Sun Microsystems|Sun]] and then LibreOffice in mid-2010.  The Document Foundation works with external organisations such as NeoOffice and [[Apache Foundation]] to help drive all three products forward.<ref>{{Citation | url = http://www.libreoffice.org/ | title = LibreOffice}}.</ref> \n* [[NeoOffice]] Calc&nbsp;— for Mac.  Started as an OpenOffice.org port to Mac, but by using the Mac-specific [[Aqua (user interface)|Aqua]] [[user interface]], instead of the more widely used X11 windowing server, it aimed to be far more stable than the normal ports of other suites.<ref>{{Citation | url = http://www.neooffice.org/ | title = NeoOffice}}.</ref>\n* [[OpenOffice.org]] [[OpenOffice.org Calc|Calc]]&nbsp;— for MS Windows, GNU/Linux and the Apple Macintosh.  Started as [[StarOffice]]. [[Sun Microsystems|Sun]] changed the name to OpenOffice.org and developed a community of developers (and others) between the late 1990s and mid-2010.  Oracle gave it to the Apache Foundation in 2011.  IBM contributed their fork of OpenOffice.org, [[IBM Lotus Symphony]], to Apache a few weeks later.<ref>{{Citation | url = http://www.openoffice.org/ | title = OpenOffice.org}}.</ref>\n* [[Siag Office|Siag]]&nbsp;— for GNU/Linux, [[OpenBSD]] and Apple Mac OS X.  A simple old spreadsheet, part of Siag Office.<ref>{{cite web |url=http://siag.nu/siag/ |title= Scheme In A Grid | publisher = Siag | date=2000-12-07 | place = NU | access-date= 7 March 2017}}</ref>\n* [[Calligra Sheets|Sheets]]&nbsp;— for MS Windows, GNU/Linux, [[FreeBSD]], Apple Mac OS X and [[Haiku (operating system)|Haiku]].  Part of the extensive Calligra Suite.  Possibly still mainly for Linux, but ports have been developed for other [[operating system]]s.<ref>{{Citation | url = http://www.calligra-suite.org/ | title = The Calligra Suite}}.</ref>\n\n===Standalone spreadsheets===\n* [[GNU Oleo]]<ref>{{Citation | contribution-url = https://www.gnu.org/software/oleo/oleo.html | contribution = Oleo software | title = GNU Project | publisher = Free Software Foundation (FSF)}}.</ref>\n* [[Pyspread]]<ref>{{Citation | contribution-url = https://manns.github.io/pyspread | title = manns | publisher = Github | contribution = pyspread}}.</ref>\n\n==Proprietary software==\n===Online spreadsheets===\n{{main |List of online spreadsheets}}\n* [[EditGrid]]<ref>{{Citation | url = http://www.editgrid.com/ | title = EditGrid}}.</ref> &ndash; access, collaborate and share spreadsheets online, with API support; discontinued since 2014\n*[https://www.zoho.com/sheet/ Zoho Sheet] - A simple, collaborative spreadsheet software.\n* [[Google Sheets]] &ndash; as part of [[Google Docs]]\n* [[iRows]]<ref>{{Citation | url = http://www.irows.com/ | title = iRows}}.</ref> &ndash; closed since 31 December 2006\n* [[JotSpot]] Tracker<ref>{{Citation | url = http://tracker.jot.com/ | publisher = Jot | title = Tracker | access-date = 2006-03-02 | archive-url = https://web.archive.org/web/20060316225415/http://tracker.jot.com/ | archive-date = 2006-03-16 | dead-url = yes | df =  }}.</ref> &ndash; acquired by [[Google Inc.]]\n* [[Smartsheet]]<ref>{{Citation | url = http://www.smartsheet.com/ | title = Smartsheet}}.</ref> – Online spreadsheet for project management, interactive Gantt, file sharing, integrated with [[Google Apps]]<ref>{{citation | url = https://www.google.com/enterprise/marketplace/viewListing?productListingId=3429+4388443950638085375&pli=1 | publisher = Google | title = Apps Marketplace Profile}}.</ref>\n* [[ThinkFree Office|ThinkFree Online]] Calc &ndash; as part of the ThinkFree Office online office suite, using [[Java (programming language)|Java]]\n\n===Spreadsheets that are parts of suites===\n* [[Ability Office]] Spreadsheet – for MS Windows.<ref>{{Citation | url = http://www.ability.com/ | title = Ability Plus Software}}.</ref>\n* [[Apple iWork]] [[Numbers (software)|Numbers]], included with Apple's [[iWork]] '08 suite exclusively for Mac OS X v10.4 or higher.\n* [[AppleWorks]] – for MS Windows and Macintosh. This is a further development of the historical [[Claris Works]] Office suite.<ref>{{Citation | url = https://www.apple.com/appleworks/ | publisher = Apple | title = AppleWorks}}.</ref>\n* [[WordPerfect Office]] [[Quattro Pro]] – for MS Windows. Was one of the big three spreadsheets (the others being Lotus 123 and Excel).<ref>{{Citation | url = http://www.corel.com/ | title = Corel}}.</ref>\n* [[EasyOffice]] EasySpreadsheet – for MS Windows. No longer freeware, this suite aims to be more user friendly than competitors.<ref>{{Citation | title = E-Press | url = http://www.e-press.com/}}.</ref>\n* [[Framework (office suite)|Framework]] – for MS Windows. Historical office suite still available and supported.  It includes a spreadsheet.<ref>{{Citation | url = http://www.framework.com/ | title = Framework}}.</ref>\n* [[IBM Lotus Symphony]] – freeware for MS Windows, Apple Mac OS X and GNU/Linux.\n* [[Kingsoft Office]] Spreadsheets 2012 – For MS Windows. Both free and paid versions are available. It can handle Microsoft Excel .xls and .xlsx files, and also produce other file formats such as .et, .txt, .csv, .pdf, and .dbf. It supports multiple tabs, VBA macro and PDF converting.<ref>{{Citation | url = http://www.kingsoftstore.com/spreadsheets.html | publisher = Kingsoft | title = Spreadsheets}}.</ref>\n* [[Lotus SmartSuite]] [[Lotus 123]] – for MS Windows.<ref>{{Citation | url = http://www-142.ibm.com/software/sw-lotus/products/product2.nsf/wdocs/sshome | publisher = IBM | title = Office productivity suite Lotus SmartSuite}}.</ref>  In its MS-DOS (character cell) version, widely considered to be responsible for the explosion of popularity of spreadsheets during the 80s and early 90s.{{Citation needed |date=October 2015}}\n* [[Mariner software|MarinerPak]] [[Mariner software|Mariner Calc]] – for Apple Macintosh. Full featured and light weight.<ref name=autogenerated2>{{Citation | url = http://www.marinersoftware.com/sitepage.php?page=14 | title = Macintosh Spreadsheet Software | publisher = Mariner Software}}.</ref>\n* [[Microsoft Office]] [[Microsoft Excel|Excel]] – for MS Windows and Apple Macintosh. The proprietary spreadsheet leader.<ref>{{Citation | contribution = Excel | title = Office | contribution-url = http://office.microsoft.com/excel/ | publisher = Microsoft}}.</ref>\n* [[Microsoft Works]] Spreadsheet – for MS Windows (previously MS-DOS and Apple Macintosh). Only allows one sheet at a time.<ref>{{Citation | url = http://www.microsoft.com/products/works/ | publisher = Microsoft | title = Works}}.</ref>\n* [[PlanMaker]] – for MS Windows, GNU/Linux, MS Windows Mobile and CE; part of [[SoftMaker Office]]\n* [[Quattro Pro]] – part of [[WordPerfect Office]]\n* [[StarOffice]] Calc – Cross-platform. StarOffice was originally developed by the German company Star Division which was purchased by [[Sun Microsystems|Sun]] in 1998.  The code was made open source and became [[OpenOffice.org]].  Sun continues developing the commercial version which periodically integrates the open source code with their own and third party code to make new low price versions.<ref>{{Citation | url = http://www.sun.com/software/star/staroffice/ | title = StarOffice | publisher = Sun}}.</ref>\n\n===Stand alone spreadsheets===\n* [[As-Easy-As]] – from Trius, Inc.; unsupported; last MS-DOS and Windows versions available with free full license key.\n* [[Mariner software|Mariner Calc]] for the Apple Macintosh.<ref name=autogenerated2 />\n\n===Multi-dimensional spreadsheets===\n* [[Javelin Software|Javelin]]\n* [[Lotus Improv]]\n* [[Lotus Improv#After Improv|Quantrix Financial Modeler]]\n\n===Spreadsheets on different paradigms===\n* [[DADiSP]] – Combines the numerical capability of [[MATLAB]] with a spreadsheet like interface.\n* [[Javelin Software|Javelin]]\n* [[Lotus Improv]]\n* [[Resolver One]] – a business application development tool that represents spreadsheets as [[IronPython]] programs, created and executed in real time and allowing the spreadsheet flow to be fully programmed\n* [[Spreadsheet 2000]]\n\n===Spreadsheet-related developmental software===\n* [[ExtenXLS]] – Java Spreadsheet Toolkit.\n\n==Specifications==\n{{Expand list|date=August 2008}}\n<center>\n{| class=\"sortable wikitable\" style=\"font-size: 85%; text-align: center; width: auto;\"\n|-\n! Program\n! Rows <small>(per sheet)</small>\n! Columns <small>(per sheet)</small>\n! Total Cells <small>(per sheet)</small>\n! Sheets\n! Total Cells <small>(per workbook)</small>\n|-\n|'''[[Gnumeric]]'''<br/>[[Image:Gnumeric.svg|25px]] || 16,777,216 || 16,384 || 274,877,906,944 || 142,648 || 603,103\n|-\n|'''[[KSpread]]'''<br/>[[Image:Crystal kspread.png|25px]] || 32,767 || 32,767 || 1,073,676,289 || 130,645 || 953,923\n|-\n|'''[[LibreOffice Calc|LibreOffice Calc 6.0.1 and 5.4.5]]'''<br/>[[Image:LibreOffice 4.0 Calc Icon.svg|25px]] || 1,048,576 || 1,024|| 1,073,741,824 \n || 1,024 || 1,099,511,627,776\n|-\n|'''[[Lotus 1-2-3]]'''<ref>{{cite web |url= http://www-1.ibm.com/support/docview.wss?uid=swg27003548 |archive-url= https://archive.today/20130103060417/http://www-1.ibm.com/support/docview.wss?uid=swg27003548 |dead-url= yes |archive-date= 2013-01-03 |title= Limitations of 1-2-3 for Windows |accessdate= 2008-04-10 |publisher= IBM }}</ref>|| 65,536|| 256 || 16,777,216 || 256 || 4,294,967,296\n|-\n| '''[[Microsoft Excel]] 2003'''|| 65,536 || 256 || 16,777,216 || 65,531 || 1,099,427,741,696\n |-\n|'''[[Microsoft Excel]] 2007, 2010, 2013 and 2016'''<ref>{{cite web |url= https://support.office.com/en-gb/article/Excel-specifications-and-limits-16c69c74-3d6a-4aaf-ba35-e6eb276e8eaa |title= Excel specifications and limits |accessdate= 2016-11-28 |work= MS Office Support | publisher = Microsoft}}</ref><ref>{{cite web |url= https://support.office.com/en-us/article/Excel-specifications-and-limits-1672b34d-7043-467e-8e27-269d656771c3 |title= Excel specifications and limits |accessdate= 2016-11-28 |work= MS Office Support | publisher = Microsoft}}</ref><ref>{{cite web |url= https://support.office.com/en-us/article/Excel-specifications-and-limits-ca36e2dc-1f09-4620-b726-67c00b05040f |title= Excel specifications and limits |accessdate= 2016-11-28 |work= MS Office Support | publisher = Microsoft}}</ref>|| 1,048,576 || 16,384 || 17,179,869,184\n|Limited by available memory\n|Limited by available memory\n|-\n| '''[[OpenOffice.org Calc]] 2'''<ref name=\"max_cells\">{{cite web |url= http://documentation.openoffice.org/faqs/spreadsheet/023.html |title= What is the maximum number of cells in an OpenOffice.org spreadsheet? |accessdate= 2008-04-10 | publisher = OpenOffice.org | work = FAQ}}</ref><br/>[[Image:OOoCalc.svg|25px]] || 65,536 || 256 || 16,777,216 || 256 || 4,294,967,296\n|-\n| '''[[OpenOffice.org Calc]] 3.0, 3.1 and 3.2'''<ref name=\"ooo3-max_cells\">{{cite web |url= http://wiki.services.openoffice.org/wiki/Documentation/FAQ/Calc/Miscellaneous/What%27s_the_maximum_number_of_rows_and_cells_for_a_spreadsheet_file%3F |title= What's the maximum number of rows and cells for a spreadsheet file? |accessdate= 2008-11-04 |publisher= OpenOffice.org |work= Calc FAQ |archive-url= https://web.archive.org/web/20090504095550/http://wiki.services.openoffice.org/wiki/Documentation/FAQ/Calc/Miscellaneous/What's_the_maximum_number_of_rows_and_cells_for_a_spreadsheet_file |archive-date= 2009-05-04 |dead-url= yes |df=  }}</ref><ref name=\"ooo3-features\">{{cite web |url= http://www.openoffice.org/dev_docs/features/3.0/#1024_Columns_Per_Calc_Sheet_.28Instead_of_256.29 |title= OpenOffice.org 3.0 New Features |accessdate= 2008-11-10 | publisher = OpenOffice.org | work = 3.0 Features}}</ref><br/>[[Image:OOoCalc.svg|25px]] || 65,536 || 1024 || 67,108,864 || 256 || 17,179,869,184\n|-\n| '''[[OpenOffice.org Calc]] 3.3'''<ref name=\"ooo3.3-features\">{{cite web |url= http://www.openoffice.org/dev_docs/features/3.3/#One_Million_Rows_in_a_Spreadsheet |title= OpenOffice.org 3.3 New Features |accessdate= 2010-12-13 | publisher = OpenOffice.org | work = 3.3 Features}}</ref><br/>[[Image:OOoCalc.svg|25px]] || 1,048,576 || 1024 || 1,073,741,824 || 256 || 274,877,906,944\n|-\n| '''[[Pyspread]]'''<br/>[[File:Pyspread_logo.png|25px]] || ~80 000 000 (limited by sum of row heights) || ~30 000 000 (limited by sum of column widths) || Limited by available memory || Limited by available memory || Limited by available memory\n|-\n|'''[[Resolver One]]'''|| limited by machine memory* || limited by machine memory* || limited machine memory* || limited by machine memory* || limited by machine memory*\n|}\n</center>\n\n-* [[32-bit]] addressable memory on Microsoft Windows, i.e. ~2.5 GB.\n\n==Historical==\n* [[VisiCalc]] The first widely used normal spreadsheet with A1 notation etc.\n* [[Lotus 1-2-3]] Took the market from Visicalc in the early 1980s.\n* [[Lotus Improv]] Novel design that went beyond A1 notation.\n* [[Lotus Symphony for DOS]]\n* [[Multiplan]] Early version of Excel.\n* [[20/20 (spreadsheet software)|20/20]] Multiplatform competitor to 1-2-3 with database integration and real-time data updating.\n* [[3D-Calc]] multi-dimensional spreadsheet for [[Atari ST]]<ref>{{Citation | url = https://www.medcalc.org/legacysoftware/atari/3dcalc.php | author = Frank Schoonjans| work = Atari ST | title = 3D-Calc }}.</ref>\n* [[SuperCalc]] – [[CP/M]]-80 Included with early Osborne computers.  It also was ported to [[MS-DOS]] and to [[Microsoft Windows]].\n* [[OS-9|Dynacalc]] — from Computer Systems Center, similar to VisiCalc.  It was designed to run on Microware's OS-9, a [[Unix-like]] operating system.<ref>{{cite web | format = [[Portable document format|PDF]] |title= Dynacalc | type = manual |url= http://www.colorcomputerarchive.com/coco/Documents/Manuals/Applications/Dynacalc%20%28Tandy%29.pdf |publisher= Tandy |accessdate=April 13, 2015}}</ref>\n* [[Paperback Software International|VP Planner]] – Similar in look and feel to Lotus 1-2-3, but included 5 level multi-dimensional database<ref>{{cite book| first1= James | last1 = Stephenson | first2 = Kent | last2 = Brothers | first3 = Dave | last3 = Mitchell | publisher = Paperback Software International, Stephenson Software |title= VP-Planner: Spreadsheet Flexibility with Database Powe|date=December 1, 1986 |isbn= 0-87142021-X }}</ref>\n* [[Informix Wingz|Wingz]] Multi Dimensional preadsheetS from Informix (1988)\n* [[Boeing Calc]] –  was a spreadsheet package written by subsidiary of aviation manufacturer Boeing (1985).\n\n==See also==\n* [[Comparison of spreadsheets]]\n* [[Logical spreadsheet]]\n\n==References==\n{{Reflist|30em}}\n\n{{Spreadsheets}}\n\n[[Category:Lists of software|Spreadsheets]]\n[[Category:Spreadsheet software|*]]"
    }
  ]
}