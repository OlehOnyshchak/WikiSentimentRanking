{
  "pages": [
    {
      "title": "Small retrosnub icosicosidodecahedron",
      "url": "https://en.wikipedia.org/wiki/Small_retrosnub_icosicosidodecahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|Sirsid}}\nIn [[geometry]], the '''small retrosnub icosicosidodecahedron''' or '''small inverted retrosnub icosicosidodecahedron''' is a [[nonconvex uniform polyhedron]], indexed as U<sub>72</sub>. It is also called a '''retroholosnub icosahedron''', ß{3/2,5}.\n\nThe 40 non-snub triangular faces form 20 coplanar pairs, forming star hexagons that are not quite regular. Unlike most snub polyhedra, it has reflection symmetries.\n\n== Convex hull ==\n\nIts [[convex hull]] is a nonuniform [[truncated dodecahedron]].\n\n{| class=wikitable width=200\n|[[File:Truncated dodecahedron.png|100px]]<BR>truncated dodecahedron\n|[[File:Small retrosnub icosicosidodecahedron convex hull.png|100px]]<BR>Convex hull\n|[[File:Small retrosnub icosicosidodecahedron.png|100px]]<BR>Small retrosnub icosicosidodecahedron\n|}\n\n== Cartesian coordinates ==\n[[Cartesian coordinates]] for the vertices of a small retrosnub icosicosidodecahedron are all the even permutations of\n\n: (±(1-ϕ−α), 0, ±(3−ϕα))\n: (±(ϕ-1−α), ±2, ±(2ϕ-1−ϕα))\n: (±(ϕ+1−α), ±2(ϕ-1), ±(1−ϕα))\n: where ϕ = (1+{{radic|5}})/2 is the [[golden ratio]] and α = {{radic|3ϕ−2}}.\n== See also ==\n* [[List of uniform polyhedra]]\n* [[Small snub icosicosidodecahedron]]\n\n== External links ==\n* {{mathworld | urlname = SmallRetrosnubIcosicosidodecahedron| title =Small retrosnub icosicosidodecahedron}}\n* {{KlitzingPolytopes|../incmats/sirsid.htm|3D star|small retrosnub icosicosidodecahedron}}\n\n[[Category:Uniform polyhedra]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Small rhombidodecahedron",
      "url": "https://en.wikipedia.org/wiki/Small_rhombidodecahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|lrD}}\nIn [[geometry]], the '''small rhombidodecahedron''' is a [[nonconvex uniform polyhedron]], indexed as U<sub>39</sub>.  Its [[vertex figure]] is a [[quadrilateral#More quadrilaterals|crossed quadrilateral]].\n\n== Related polyhedra ==\n\nIt shares its [[vertex arrangement]] with the [[small stellated truncated dodecahedron]] and the [[Polyhedron compound#Uniform compounds|uniform compounds]] of [[compound of six pentagrammic prisms|6]] or [[compound of twelve pentagrammic prisms|12 pentagrammic prisms]]. It additionally shares its [[edge arrangement]] with the [[rhombicosidodecahedron]] (having the square faces in common), and with the [[small dodecicosidodecahedron]] (having the decagonal faces in common).\n\n{| class=\"wikitable\" width=\"400\" style=\"vertical-align:top;text-align:center\"\n| [[Image:Small rhombicosidodecahedron.png|100px]]<BR>[[Rhombicosidodecahedron]]\n| [[Image:Small dodecicosidodecahedron.png|100px]]<BR>[[Small dodecicosidodecahedron]]\n| [[Image:Small rhombidodecahedron.png|100px]]<BR>Small rhombidodecahedron\n|-\n| [[Image:Small stellated truncated dodecahedron.png|100px]]<BR>[[Small stellated truncated dodecahedron]]\n| [[Image:UC36-6 pentagrammic prisms.png|100px]]<BR>[[Compound of six pentagrammic prisms]]\n| [[Image:UC37-12 pentagrammic prisms.png|100px]]<BR>[[Compound of twelve pentagrammic prisms]]\n|}\n{{Clear}}\n{{Clear}}\n<HR>\n\n=== Small rhombidodecacron===\n{{Uniform polyhedra db|Uniform dual polyhedron stat table|lrD}}\nThe '''small rhombidodecacron''' is a nonconvex [[Isohedral figure|isohedral]] [[polyhedron]]. It is the [[Dual polyhedron|dual]] of the small rhombidodecahedron. It is visually identical to the [[Small dodecacronic hexecontahedron]]. It has 60 intersecting [[antiparallelogram]] faces.\n\n==References==\n*{{Citation | last1=Wenninger | first1=Magnus | author1-link=Magnus Wenninger | title=Dual Models | publisher=[[Cambridge University Press]] | isbn=978-0-521-54325-5 |mr=730208 | year=1983}}\n\n== External links ==\n* {{mathworld | urlname = SmallRhombidodecahedron| title = Small rhombidodecahedron}}\n* {{mathworld | urlname = SmallRhombidodecacron| title =Small rhombidodecacron}}\n* [http://gratrix.net/polyhedra/uniform/summary Uniform polyhedra and duals]\n\n{{Nonconvex polyhedron navigator}}\n\n[[Category:Uniform polyhedra]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Small snub icosicosidodecahedron",
      "url": "https://en.wikipedia.org/wiki/Small_snub_icosicosidodecahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|Seside}}\nIn [[geometry]], the '''small snub icosicosidodecahedron''' or '''snub disicosidodecahedron''' is a [[uniform star polyhedron]], indexed as U<sub>32</sub>. It has 112 faces (100 [[triangle]]s and 12 [[pentagram]]s), 180 edges, and 60 vertices. Its stellation core is a [[truncated pentakis dodecahedron]]. It also called a '''holosnub icosahedron''', ß{3,5}.\n\nThe 40 non-snub triangular faces form 20 coplanar pairs, forming star hexagons that are not quite regular. Unlike most snub polyhedra, it has reflection symmetries.\n\n== Convex hull ==\n\nIts [[convex hull]] is a nonuniform [[truncated icosahedron]].\n\n{| class=wikitable width=200\n|- valign=top\n|[[File:truncated icosahedron.png|100px]]<BR>Truncated icosahedron<BR>([[Regular polygon|regular]] faces)\n|[[File:Small snub icosicosidodecahedron convex hull.png|100px]]<BR>Convex hull<BR>([[Isogonal figure|isogonal]] [[hexagon]]s)\n|[[File:Small snub icosicosidodecahedron.png|100px]]<BR>Small snub icosicosidodecahedron\n|}\n\n== Cartesian coordinates ==\n[[Cartesian coordinates]] for the vertices of a small snub icosicosidodecahedron are all the even permutations of\n\n: (±(1-ϕ+α), 0, ±(3+ϕα))\n: (±(ϕ-1+α), ±2, ±(2ϕ-1+ϕα))\n: (±(ϕ+1+α), ±2(ϕ-1), ±(1+ϕα))\n\nwhere ϕ = (1+{{radic|5}})/2 is the [[golden ratio]] and α = {{radic|3ϕ−2}}.\n\n== See also ==\n* [[List of uniform polyhedra]]\n* [[Small retrosnub icosicosidodecahedron]]\n\n== External links ==\n* {{mathworld | urlname =  SmallSnubIcosicosidodecahedron| title = Small snub icosicosidodecahedron}}\n* {{KlitzingPolytopes|../incmats/seside.htm|3D star|small snub icosicosidodecahedron}}\n\n[[Category:Uniform polyhedra]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Small stellated truncated dodecahedron",
      "url": "https://en.wikipedia.org/wiki/Small_stellated_truncated_dodecahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|lstD}}\nIn [[geometry]], the '''small stellated truncated dodecahedron''' or '''quasitruncated small stellated dodecahedron''' is a [[nonconvex uniform polyhedron]], indexed as U<sub>58</sub>. It is given a [[Schläfli symbol]] t{5/3,5}, and [[Coxeter diagram]] {{CDD|node_1|5-3|node_1|5|node}}.\n\nIt has 12 [[pentagon]]s and 12 [[Decagram (geometry)|decagrams]], {10/3} faces.\n\n== Related polyhedra ==\n\nIt shares its [[vertex arrangement]] with three other [[uniform polyhedron|uniform polyhedra]]: the convex [[rhombicosidodecahedron]], the [[small dodecicosidodecahedron]] and the [[small rhombidodecahedron]].\n\nIt also has the same vertex arrangement as the [[Uniform polyhedron compound|uniform compounds]] of [[compound of six pentagrammic prisms|6]] or [[compound of twelve pentagrammic prisms|12 pentagrammic prisms]].\n\n{| class=\"wikitable\" width=\"400\" style=\"vertical-align:top;text-align:center\"\n| [[Image:Small rhombicosidodecahedron.png|100px]]<BR>[[Rhombicosidodecahedron]]\n| [[Image:Small dodecicosidodecahedron.png|100px]]<BR>[[Small dodecicosidodecahedron]]\n| [[Image:Small rhombidodecahedron.png|100px]]<BR>[[Small rhombidodecahedron]]\n|-\n| [[Image:Small stellated truncated dodecahedron.png|100px]]<BR>Small stellated truncated dodecahedron\n| [[Image:UC36-6 pentagrammic prisms.png|100px]]<BR>[[Compound of six pentagrammic prisms]]\n| [[Image:UC37-12 pentagrammic prisms.png|100px]]<BR>[[Compound of twelve pentagrammic prisms]]\n|}\n\n== See also ==\n* [[List of uniform polyhedra]]\n\n== External links ==\n* {{mathworld | urlname = SmallStellatedTruncatedDodecahedron| title = Small stellated truncated dodecahedron}}\n\n[[Category:Uniform polyhedra]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Snub dodecadodecahedron",
      "url": "https://en.wikipedia.org/wiki/Snub_dodecadodecahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|Siddid}}\nIn [[geometry]], the '''snub dodecadodecahedron''' is a [[nonconvex uniform polyhedron]], indexed as U<sub>40</sub>. It is given a [[Schläfli symbol]] sr{5/2,5}, as a [[Snub (geometry)|snub]] [[great dodecahedron]].\n\n== Cartesian coordinates ==\n[[Cartesian coordinates]] for the vertices of a snub dodecadodecahedron are all the [[even permutation]]s of\n: (±2α, ±2, ±2β),\n: (±(α+β/τ+τ), ±(-ατ+β+1/τ), ±(α/τ+βτ-1)),\n: (±(-α/τ+βτ+1), ±(-α+β/τ-τ), ±(ατ+β-1/τ)),\n: (±(-α/τ+βτ-1), ±(α-β/τ-τ), ±(ατ+β+1/τ)) and\n: (±(α+β/τ-τ), ±(ατ-β+1/τ), ±(α/τ+βτ+1)),\nwith an even number of plus signs, where\n: β = (α<sup>2</sup>/τ+τ)/(ατ−1/τ),\nwhere τ = (1+{{radic|5}})/2 is the [[golden ratio|golden mean]] and\nα is the positive real [[root of a function|root]] of τα<sup>4</sup>−α<sup>3</sup>+2α<sup>2</sup>−α−1/τ, or approximately 0.7964421.\nTaking the [[odd permutation]]s of the above coordinates with an odd number of plus signs gives another form, the [[Chirality (mathematics)|enantiomorph]] of the other one.\n{{-}}\n\n== Related polyhedra ==\n\n=== Medial pentagonal hexecontahedron ===\n{{Uniform polyhedra db|Uniform dual polyhedron stat table|Siddid}}\nThe '''medial pentagonal hexecontahedron''' is a nonconvex [[Isohedral figure|isohedral]] [[polyhedron]]. It is the [[Dual polyhedron|dual]] of the snub dodecadodecahedron. It has 60 intersecting irregular pentagonal faces.\n\n== See also ==\n* [[List of uniform polyhedra]]\n* [[Inverted snub dodecadodecahedron]]\n\n==References==\n*{{Citation | last1=Wenninger | first1=Magnus | author1-link=Magnus Wenninger | title=Dual Models | publisher=[[Cambridge University Press]] | isbn=978-0-521-54325-5 |mr=730208 | year=1983 | doi=10.1017/CBO9780511569371}}\n\n== External links ==\n* {{mathworld | urlname = MedialPentagonalHexecontahedron| title =Medial pentagonal hexecontahedron}}\n* {{mathworld | urlname = SnubDodecadodecahedron | title = Snub dodecadodecahedron}}\n* [http://gratrix.net/polyhedra/uniform/summary Uniform polyhedra and duals]\n\n{{Nonconvex polyhedron navigator}}\n\n[[Category:Uniform polyhedra]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Snub icosidodecadodecahedron",
      "url": "https://en.wikipedia.org/wiki/Snub_icosidodecadodecahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|Sided}}\nIn [[geometry]], the '''snub [[icosidodecadodecahedron]]''' is a [[nonconvex uniform polyhedron]], indexed as U<sub>46</sub>.\n\nAs the name indicates, it belongs to the family of [[snub polyhedra]].\n== Cartesian coordinates ==\n[[Cartesian coordinates]] for the vertices of a snub icosidodecadodecahedron are all the [[even permutation]]s of\n: (±2α, ±2γ, ±2β),\n: (±(α+β/τ+γτ), ±(-ατ+β+γ/τ), ±(α/τ+βτ-γ)),\n: (±(-α/τ+βτ+γ), ±(-α+β/τ-γτ), ±(ατ+β-γ/τ)),\n: (±(-α/τ+βτ-γ), ±(α-β/τ-γτ), ±(ατ+β+γ/τ)) and\n: (±(α+β/τ-γτ), ±(ατ-β+γ/τ), ±(α/τ+βτ+γ)),\nwith an even number of plus signs, where\n: α = ρ+1 = ρ<sup>3</sup>,\n: β = τ<sup>2</sup>ρ<sup>2</sup>+τ<sup>2</sup>ρ+τ = τ<sup>2</sup>ρ<sup>4</sup>+τ,\n: γ = ρ<sup>2</sup>+τρ,\nand where τ = (1+{{radic|5}})/2 is the [[golden ratio|golden mean]] and\nρ is the real solution to ρ<sup>3</sup>=ρ+1, or approximately 1.3247180.\nρ is called the [[plastic constant]].\nTaking the [[odd permutation]]s of the above coordinates with an odd number of plus signs gives another form, the [[Chirality (mathematics)|enantiomorph]] of the other one.\n\n{{-}}\n\n== Related polyhedra ==\n\n=== Medial hexagonal hexecontahedron===\n{{Uniform polyhedra db|Uniform dual polyhedron stat table|Sided}}\nThe '''medial hexagonal hexecontahedron''' is a nonconvex [[Isohedral figure|isohedral]] [[polyhedron]]. It is the [[Dual polyhedron|dual]] of the [[uniform star polyhedron|uniform]] snub icosidodecadodecahedron.\n\n== See also ==\n* [[List of uniform polyhedra]]\n\n==References==\n*{{Citation | last1=Wenninger | first1=Magnus | author1-link=Magnus Wenninger | title=Dual Models | publisher=[[Cambridge University Press]] | isbn=978-0-521-54325-5 |mr=730208 | year=1983}}\n\n== External links ==\n* {{mathworld | urlname =  SnubIcosidodecadodecahedron| title = Snub icosidodecadodecahedron}}\n* {{mathworld | urlname = MedialHexagonalHexecontahedron| title =Medial hexagonal hexecontahedron}}\n\n{{Nonconvex polyhedron navigator}}\n\n[[Category:Uniform polyhedra]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Stellated truncated hexahedron",
      "url": "https://en.wikipedia.org/wiki/Stellated_truncated_hexahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|stH}}\nIn [[geometry]], the '''stellated truncated hexahedron''' (or '''quasitruncated hexahedron''') is a [[uniform star polyhedron]], indexed as U<sub>19</sub>. It is represented by [[Schläfli symbol]] t{4/3,3}, and [[Coxeter-Dynkin diagram]], {{CDD|node_1|4|rat|d3|node_1|3|node}}. It is sometimes called quasitruncated hexahedron because it is related to the [[truncated cube]], {{CDD|node_1|4|node_1|3|node}}, except that the square faces become inverted into {8/3} octagrams.\n\nThe stellated truncated hexahedron is not a true [[stellation]] of the [[truncated hexahedron]]; its convex 'core' is ''not'' a uniform polyhedron. <!-- how about a picture? -->\n\n== Orthographic projections ==\n[[File:Stellated_truncated_hexahedron_ortho_wireframes.png|480px]]\n\n==Related polyhedra==\nIt shares the [[vertex arrangement]] with three other [[uniform polyhedron|uniform polyhedra]]: the convex [[rhombicuboctahedron]], the [[small rhombihexahedron]], and the [[small cubicuboctahedron]].\n\n{| class=\"wikitable\" width=\"400\" style=\"vertical-align:top;text-align:center\"\n| [[Image:Small rhombicuboctahedron.png|100px]]<BR>[[Rhombicuboctahedron]]\n| [[Image:Small cubicuboctahedron.png|100px]]<BR>[[Small cubicuboctahedron]]\n| [[Image:Small rhombihexahedron.png|100px]]<BR>[[Small rhombihexahedron]]\n| [[Image:Stellated truncated hexahedron.png|100px]]<BR>Stellated truncated hexahedron\n|}\n\n==See also==\n* [[List of uniform polyhedra]]\n\n==External links==\n* {{mathworld | urlname = StellatedTruncatedHexahedron| title = Stellated truncated hexahedron}}\n\n[[Category:Uniform polyhedra]]\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Truncated dodecadodecahedron",
      "url": "https://en.wikipedia.org/wiki/Truncated_dodecadodecahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|tDD}}\nIn [[geometry]], the '''truncated dodecadodecahedron''' is a [[nonconvex uniform polyhedron]], indexed as U<sub>59</sub>. It is given a [[Schläfli symbol]] t<sub>0,1,2</sub>{5/3,5}. It has 120 vertices and 54 faces: 30 squares, 12 [[decagon]]s, and 12 [[Decagram (geometry)|decagrams]]. The central region of the polyhedron is connected to the exterior via 20 small triangular holes.\n\nThe name ''truncated dodecadodecahedron'' is somewhat misleading: truncation of the  [[dodecadodecahedron]] would produce rectangular faces rather than squares, and the pentagram faces of the dodecahedron would turn into truncated pentagrams rather than decagrams. However, it is the quasitruncation of the dodecadodecahedron, as defined by {{harvtxt|Coxeter|Longuet-Higgins|Miller|1954}}.<ref>{{citation\n | last1 = Coxeter | first1 = H. S. M. | author1-link = Harold Scott MacDonald Coxeter\n | last2 = Longuet-Higgins | first2 = M. S. | author2-link = Michael S. Longuet-Higgins\n | last3 = Miller | first3 = J. C. P. | author3-link = J. C. P. Miller\n | journal = Philosophical Transactions of the Royal Society of London. Series A. Mathematical and Physical Sciences\n | jstor = 91532\n | mr = 0062446\n | pages = 401–450\n | title = Uniform polyhedra\n | volume = 246\n | year = 1954 | doi=10.1098/rsta.1954.0003| bibcode = 1954RSPTA.246..401C}}. See especially the description as a quasitruncation on p. 411 and the photograph of a model of its skeleton in Fig. 114, Plate IV.</ref> For this reason, it is also known as the '''quasitruncated dodecadodecahedron'''.<ref>Wenninger writes \"quasitruncated dodecahedron\", but this appear to be a mistake. {{citation|contribution=98 Quasitruncated dodecahedron|pages=152–153|first=Magnus J.|last=Wenninger|authorlink=Magnus Wenninger|title=Polyhedron Models|publisher=Cambridge University Press|year=1971}}.</ref> Coxeter et al. credit its discovery to a paper published in 1881 by Austrian mathematician Johann Pitsch.<ref>{{citation\n | last = Pitsch | first = Johann\n | journal = Zeitschrift für das Realschulwesen\n | pages = 9–24, 72–89, 216\n | title = Über halbreguläre Sternpolyeder\n | volume = 6\n | year = 1881}}. According to {{harvtxt|Coxeter|Longuet-Higgins|Miller|1954}}, the truncated dodecadodecahedron appears as no. XII on p.86.</ref>\n\n== Cartesian coordinates ==\n[[Cartesian coordinates]] for the vertices of a truncated dodecadodecahedron are all the triples of numbers obtained by circular shifts and sign changes from the following points (where <math>\\tau = \\frac{1 + \\sqrt{5}}{2}</math> is the [[golden ratio]]):\n:<math>(1,1,3);\\quad\n(\\frac{1}{\\tau}, \\frac{1}{\\tau^2}, 2\\tau);\\quad\n(\\tau, \\frac{2}{\\tau}, \\tau^2);\\quad\n(\\tau^2, \\frac{1}{\\tau^2}, 2);\\quad\n(\\sqrt{5},1,\\sqrt{5}).</math>\n\nEach of these five points has eight possible sign patterns and three possible circular shifts, giving a total of 120 different points.\n\n==As a Cayley graph==\nThe truncated dodecadodecahedron forms a [[Cayley graph]] for the [[symmetric group]] on five elements, as generated by two group members: one that swaps the first two elements of a five-tuple, and one that performs a [[circular shift]] operation on the last four elements. That is, the 120 vertices of the polyhedron may be placed in one-to-one correspondence with the 5! [[permutations]] on five elements, in such a way that the three neighbors of each vertex are the three permutations formed from it by swapping the first two elements or circularly shifting (in either direction) the last four elements.<ref>{{citation\n | last = Eppstein | first = David | authorlink = David Eppstein\n | editor1-last = Tollis | editor1-first = Ioannis G.\n | editor2-last = Patrignani | editor2-first = Marizio\n | arxiv = 0709.4087\n | contribution = The topology of bendless three-dimensional orthogonal graph drawing\n | doi = 10.1007/978-3-642-00219-9_9\n | location = Heraklion, Crete\n | pages = 78–89\n | publisher = Springer-Verlag\n | series = Lecture Notes in Computer Science\n | title = Proc. 16th Int. Symp. Graph Drawing\n | volume = 5417\n | year = 2008}}.</ref>\n\n== Related polyhedra ==\n\n=== Medial disdyakis triacontahedron===\n{{Uniform polyhedra db|Uniform dual polyhedron stat table|tDD}}\nThe '''medial disdyakis triacontahedron''' is a nonconvex [[Isohedral figure|isohedral]] [[polyhedron]]. It is the [[Dual polyhedron|dual]] of the [[uniform star polyhedron|uniform]] truncated dodecadodecahedron.\n\n== See also ==\n* [[List of uniform polyhedra]]\n\n==References==\n{{reflist}}\n\n*{{Citation | last1=Wenninger | first1=Magnus | author1-link=Magnus Wenninger | title=Dual Models | publisher=[[Cambridge University Press]] | isbn=978-0-521-54325-5 |mr=730208 | year=1983 | doi=10.1017/CBO9780511569371}}\n\n== External links ==\n* {{mathworld | urlname = TruncatedDodecadodecahedron| title = Truncated dodecadodecahedron}}\n* {{mathworld | urlname = MedialDisdyakisTriacontahedron| title =Medial disdyakis triacontahedron}}\n\n{{Star polyhedron navigator}}\n\n[[Category:Uniform polyhedra]]"
    },
    {
      "title": "Truncated great icosahedron",
      "url": "https://en.wikipedia.org/wiki/Truncated_great_icosahedron",
      "text": "{{Uniform polyhedra db|Uniform polyhedron stat table|gtI}}\nIn [[geometry]], the '''truncated great icosahedron''' is a [[nonconvex uniform polyhedron]], indexed as U<sub>55</sub>. It is given a [[Schläfli symbol]] t{3,5/2} or t<sub>0,1</sub>{3,5/2} as a [[Truncation (geometry)|truncated]] [[great icosahedron]].\n\n== Cartesian coordinates ==\n[[Cartesian coordinates]] for the vertices of a ''truncated great icosahedron'' centered at the origin are all the even permutations of\n\n: (±1, 0, ±3/τ)\n: (±2, ±1/τ, ±1/τ<sup>3</sup>)\n: (±(1+1/τ<sup>2</sup>), ±1, ±2/τ)\n\nwhere τ = (1+√5)/2 is the [[golden ratio]] (sometimes written φ). Using 1/τ<sup>2</sup> = 1 − 1/τ one verifies that all vertices are on a sphere, centered at the origin, with the radius squared equal to 10−9/τ. The edges have length 2.\n\n== Related polyhedra ==\n[[File:Great stellated dodecahedron truncations.gif|thumb|right|240px|Animated truncation sequence from {5/2, 3} to {3, 5/2}]]\nThis polyhedron is the [[Truncation (geometry)|truncation]] of the [[great icosahedron]]:\n\nThe [[Truncation (geometry)|truncated]] ''great stellated dodecahedron'' is a degenerate polyhedron, with 20 triangular faces from the truncated vertices, and 12 (hidden) pentagonal faces as truncations of the original pentagram faces, the latter forming a [[great dodecahedron]] inscribed within and sharing the edges of the icosahedron.\n\n{| class=\"wikitable\" width=500\n!Name\n![[Great stellated dodecahedron|Great<BR>stellated<BR>dodecahedron]]\n![[Truncated great stellated dodecahedron]]\n![[Great icosidodecahedron|Great<BR>icosidodecahedron]]\n!Truncated<BR>great<BR>icosahedron\n![[Great icosahedron|Great<BR>icosahedron]]\n|- align=center\n![[Coxeter-Dynkin diagram|Coxeter-Dynkin<BR>diagram]]\n|{{CDD|node|3|node|5|rat|d2|node_1}}\n|{{CDD|node|3|node_1|5|rat|d2|node_1}}\n|{{CDD|node|3|node_1|5|rat|d2|node}}\n|{{CDD|node_1|3|node_1|5|rat|d2|node}}\n|{{CDD|node_1|3|node|5|rat|d2|node}}\n|-\n!Picture\n|[[Image:Great stellated dodecahedron.png|100px]]\n|[[Image:Icosahedron.png|100px]]\n|[[Image:Great icosidodecahedron.png|100px]]\n|[[Image:Great truncated icosahedron.png|100px]]\n|[[Image:Great icosahedron.png|100px]]\n|}\n\n{{-}}\n\n=== Great stellapentakis dodecahedron ===\n{{Uniform polyhedra db|Uniform dual polyhedron stat table|gtI}}\nThe '''great stellapentakis dodecahedron''' is a nonconvex [[Isohedral figure|isohedral]] [[polyhedron]]. It is the dual of the truncated great icosahedron. It has 60 intersecting triangular faces.\n\n== See also ==\n* [[List of uniform polyhedra]]\n\n==References==\n*{{Citation | last1=Wenninger | first1=Magnus | author1-link=Magnus Wenninger | title=Dual Models | publisher=[[Cambridge University Press]] | isbn=978-0-521-54325-5 |mr=730208 | year=1983 | doi=10.1017/CBO9780511569371}}\n\n== External links ==\n* {{mathworld | urlname = GreatTruncatedIcosahedron| title = Truncated great icosahedron}}\n* {{mathworld | urlname = GreatStellapentakisDodecahedron| title =Great stellapentakis dodecahedron}}\n* [http://gratrix.net/polyhedra/uniform/summary Uniform polyhedra and duals]\n\n{{Nonconvex polyhedron navigator}}\n\n[[Category:Uniform polyhedra]]\n\n\n{{polyhedron-stub}}"
    },
    {
      "title": "Uniform star polyhedron",
      "url": "https://en.wikipedia.org/wiki/Uniform_star_polyhedron",
      "text": "[[File:Uniform-Polyhedra-at-the-Science-Museum.jpg|thumb|right|A display of uniform polyhedra at the [[Science Museum (London)|Science Museum]] in London]]\n[[Image:Small snub icosicosidodecahedron.png|thumb|The [[small snub icosicosidodecahedron]] is a ''uniform star polyhedron'', with [[vertex figure]] ''3<sup>5</sup>.<sup>5</sup>/<sub>2</sub>'']]\nIn [[geometry]], a '''uniform star polyhedron''' is a self-intersecting [[uniform polyhedron]]. They are also sometimes called ''nonconvex polyhedra'' to imply self-intersecting. Each polyhedron can contain either [[star polygon]] faces, [[star polygon]] [[vertex figure]]s'' or both.\n\nThe complete set of 57 nonprismatic uniform star polyhedra includes the 4 regular ones, called the [[Kepler–Poinsot polyhedron|Kepler–Poinsot polyhedra]], 5 [[Quasiregular polyhedron#Nonconvex examples|quasiregular]] ones, and 48 semiregular ones.\n\nThere are also two infinite sets of [[Uniform_polyhedron#.28p_2_2.29_Prismatic_.5Bp.2C2.5D.2C_I2.28p.29_family_.28Dph_dihedral_symmetry.29|''uniform star prisms'' and ''uniform star antiprisms'']]. \n\nJust as (nondegenerate) [[star polygon]]s (which have [[density (polytope)|Polygon density]] greater than 1) correspond to circular polygons with overlapping tiles, star polyhedra that do not pass through the center have [[density (polytope)|polytope density]] greater than 1, and correspond to [[spherical polyhedra]] with overlapping tiles; there are 47 nonprismatic such uniform star polyhedra. The remaining 10 nonprismatic uniform star polyhedra, those that pass through the center, are the [[hemipolyhedra]] as well as [[Miller's monster]], and do not have well-defined densities.\n\nThe nonconvex forms are constructed from [[Schwarz triangle]]s.\n\nAll the uniform polyhedra are listed below by their [[symmetry group]]s and subgrouped by their vertex arrangements.\n\nRegular polyhedra are labeled by their [[Schläfli symbol]]. Other nonregular uniform polyhedra are listed with their [[vertex configuration]] or their Uniform polyhedron index U(1-80).\n\nNote: For nonconvex forms below an additional descriptor '''Nonuniform''' is used when the [[convex hull]] [[vertex arrangement]] has same topology as one of these, but has nonregular faces. For example an ''nonuniform cantellated'' form may have [[rectangles]] created in place of the edges rather than [[Square (geometry)|squares]].\n\n== Dihedral symmetry ==\n\nSee [[Prismatic uniform polyhedron]].\n\n== Tetrahedral symmetry ==\n[[File:Tetrahedral reflection domains.png|thumb|(3 3 2) triangles on sphere]]\nThere is one nonconvex form, the [[tetrahemihexahedron]] which has ''[[tetrahedral symmetry]]'' (with fundamental domain [[Möbius triangle]] (3 3 2)).\n\nThere are two [[Schwarz_triangle#A_complete_list_of_Schwarz_triangles_grouped_by_symmetry|Schwarz triangle]]s that generate unique nonconvex uniform polyhedra: one right triangle (3/2 3 2), and one general triangle (3/2 3 3). The general triangle (3/2 3 3) generates the [[octahemioctahedron]] which is given further on with its full [[octahedral symmetry]].\n\n{| class=\"wikitable\"\n![[Vertex arrangement]]<BR>([[Convex hull]])\n!colspan=2|Nonconvex forms\n|- valign=top\n![[Image:Tetrahedron.png|64px]]<BR>[[Tetrahedron]]\n|&nbsp;\n|- valign=top\n![[Image:Rectified tetrahedron.png|64px]]<BR>Rectified tetrahedron<BR>[[Octahedron]]\n||[[Image:Tetrahemihexahedron.png|64px]]<BR>[[Tetrahemihexahedron|(4.3/2.4.3)]]<BR>3/2 3 | 2\n|- valign=top\n![[Image:Truncated tetrahedron.png|64px]]<BR>[[Truncated tetrahedron]]\n|&nbsp;\n|-\n![[Image:Cantellated tetrahedron.png|64px]]<BR>Cantellated tetrahedron<BR>([[Cuboctahedron]])\n|&nbsp;\n|-\n![[File:Uniform polyhedron-33-t012.png|64px]]<BR>Omnitruncated tetrahedron<BR>([[Truncated octahedron]])\n|&nbsp;\n|-\n![[File:Uniform polyhedron-33-s012.png|64px]]<BR>Snub tetrahedron<BR>([[Icosahedron]])\n|&nbsp;\n|}\n\n== Octahedral symmetry ==\n[[File:Octahedral reflection domains.png|thumb|(4 3 2) triangles on sphere]]\nThere are 8 convex forms, and 10 nonconvex forms with ''[[octahedral symmetry]]'' (with fundamental domain [[Möbius triangle]] (4 3 2)).\n\nThere are four [[Schwarz_triangle#A_complete_list_of_Schwarz_triangles_grouped_by_symmetry|Schwarz triangle]]s that generate nonconvex forms, two right triangles (3/2 4 2), and (4/3 3 2), and two general triangles: (4/3 4 3), (3/2 4 4).\n\n{| class=\"wikitable\"\n![[Vertex arrangement]]<BR>([[Convex hull]])\n!colspan=3|Nonconvex forms\n|-\n![[Image:Hexahedron.png|64px]]<BR>[[Cube]]\n|&nbsp;\n|-\n![[Image:Octahedron.png|64px]]<BR>[[Octahedron]]\n|&nbsp;\n|-\n![[Image:Cuboctahedron.png|64px]]<BR>[[Cuboctahedron]]\n| [[Image:Cubohemioctahedron.png|64px]]<BR>[[Cubohemioctahedron|(6.4/3.6.4)]]<BR>4/3 4 | 3\n| [[Image:Octahemioctahedron.png|64px]]<BR>[[Octahemioctahedron|(6.3/2.6.3)]]<BR>3/2 3 | 3\n|-\n![[Image:Truncated hexahedron.png|64px]]<BR>[[Truncated cube]]\n| [[Image:Great rhombihexahedron.png|64px]]<BR>[[Great rhombihexahedron|(4.8/3.4/3.8/5)]]<BR>2 4/3 (3/2 4/2) |\n| [[Image:Great cubicuboctahedron.png|64px]]<BR>[[Great cubicuboctahedron|(8/3.3.8/3.4)]]<BR>3 4 | 4/3\n| [[Image:Uniform great rhombicuboctahedron.png|64px]]<BR>[[Nonconvex great rhombicuboctahedron|(4.3/2.4.4)]]<BR>3/2 4 | 2\n|-\n![[Image:Truncated octahedron.png|64px]]<BR>[[Truncated octahedron]]\n|&nbsp;\n|-\n![[Image:Small rhombicuboctahedron.png|64px]]<BR>[[Rhombicuboctahedron]]\n| [[Image:Small rhombihexahedron.png|64px]]<BR>[[Small rhombihexahedron|(4.8.4/3.8)]]<BR>2 4 (3/2 4/2) |\n| [[Image:Small cubicuboctahedron.png|64px]]<BR>[[Small cubicuboctahedron|(8.3/2.8.4)]]<BR>3/2 4 | 4\n| [[Image:Stellated truncated hexahedron.png|64px]]<BR>[[Stellated truncated hexahedron|(8/3.8/3.3)]]<BR>2 3 | 4/3\n|-\n! [[File:Great truncated cuboctahedron convex hull.png|64px]]<BR>Nonuniform<BR>[[truncated cuboctahedron]]\n| [[Image:Great truncated cuboctahedron.png|64px]]<BR>[[Great truncated cuboctahedron|(4.6.8/3)]]<BR>2 3 4/3 |\n|-\n![[File:Cubitruncated cuboctahedron convex hull.png|64px]]<BR>Nonuniform<BR>[[truncated cuboctahedron]]\n| [[Image:Cubitruncated cuboctahedron.png|64px]]<BR>[[Cubitruncated cuboctahedron|(8/3.6.8)]]<BR>3 4 4/3 |\n|-\n![[Image:Snub hexahedron.png|64px]]<BR>[[Snub cube]]\n|&nbsp;\n|}\n\n== Icosahedral symmetry ==\n[[File:Icosahedral reflection domains.png|thumb|(5 3 2) triangles on sphere]]\nThere are 8 convex forms and 46 nonconvex forms with ''[[icosahedral symmetry]]'' (with fundamental domain [[Möbius triangle]] (5 3 2)). (or 47 nonconvex forms if Skilling's figure is included). Some of the nonconvex snub forms have reflective vertex symmetry.\n\n{| class=\"wikitable\"\n![[Vertex arrangement]]<BR>([[Convex hull]])\n!colspan=8|Nonconvex forms\n|-\n! [[Image:Icosahedron.png|64px]]<BR>[[Icosahedron]]\n| [[Image:Great dodecahedron.png|64px]]<BR>[[Great dodecahedron|{5,5/2}]]\n| [[Image:Small stellated dodecahedron.png|64px]]<BR>[[Small stellated dodecahedron|{5/2,5}]]\n| [[Image:Great icosahedron.png|64px]]<BR>[[Great icosahedron|{3,5/2}]]\n|-\n! [[File:Nonuniform truncated icosahedron.png|64px]]<BR>Nonuniform<BR>[[truncated icosahedron]]<BR>2 5 |3\n| [[Image:Great truncated dodecahedron.png|64px]]<BR>[[Truncated great dodecahedron|U37]]<BR> 2 5/2 | 5\n| [[Image:Great dodecicosidodecahedron.png|64px]]<BR>[[Great dodecicosidodecahedron|U61]]<BR> 5/2 3 | 5/3\n| [[Image:Uniform great rhombicosidodecahedron.png|64px]]<BR>[[Nonconvex great rhombicosidodecahedron|U67]]<BR> 5/3 3 | 2\n| [[Image:Great rhombidodecahedron.png|64px]]<BR>[[Great rhombidodecahedron|U73]]<BR>2 5/3 (3/2 5/4) |\n|-\n! [[File:Rhombidodecadodecahedron convex hull.png|64px]]<BR>Nonuniform<BR>[[truncated icosahedron]]<BR>2 5 |3\n| [[Image:Rhombidodecadodecahedron.png|64px]]<BR>[[Rhombidodecadodecahedron|U38]]<BR>5/2 5 | 2\n| [[Image:Icosidodecadodecahedron.png|64px]]<BR>[[Icosidodecadodecahedron|U44]]<BR>5/3 5 | 3\n| [[Image:Rhombicosahedron.png|64px]]<BR>[[Rhombicosahedron|U56]]<BR>2 3 (5/4 5/2) |\n|-\n! [[File:Small snub icosicosidodecahedron convex hull.png|64px]]<BR>Nonuniform<BR>[[truncated icosahedron]]<BR>2 5 |3\n| [[Image:Small snub icosicosidodecahedron.png|64px]]<BR>[[Small snub icosicosidodecahedron|U32]]<BR> | 5/2 3 3\n|-\n! [[Image:icosidodecahedron.png|64px]]<BR>[[Icosidodecahedron]]<BR> 2 | 3 5\n| [[Image:Small icosihemidodecahedron.png|64px]]<BR>[[Small icosihemidodecahedron|U49]]<BR> 3/2 3 | 5\n| [[Image:Small dodecahemidodecahedron.png|64px]]<BR>[[Small dodecahemidodecahedron|U51]] <BR> 5/4 5 | 5\n| [[Image:Great icosidodecahedron.png|64px]]<BR>[[Great icosidodecahedron|U54]] <BR> 2 | 3 5/2\n| [[Image:Great dodecahemidodecahedron.png|64px]]<BR>[[Great dodecahemidodecahedron|U70]] <BR> 5/3 5/2 | 5/3\n| [[Image:Great icosihemidodecahedron.png|64px]]<BR>[[Great icosihemidodecahedron|U71]] <BR> 3 3 | 5/3\n| [[Image:Dodecadodecahedron.png|64px]]<BR>[[Dodecadodecahedron|U36]] <BR> 2 | 5 5/2\n| [[Image:Small dodecahemicosahedron.png|64px]]<BR>[[Small dodecahemicosahedron|U62]] <BR> 5/3 5/2 | 3\n| [[Image:Great dodecahemicosahedron.png|64px]]<BR>[[Great dodecahemicosahedron|U65]]<BR> 5/4 5 | 3\n|-\n! [[Image:truncated dodecahedron.png|64px]]<BR>[[truncated dodecahedron]]<BR> 2 3 | 5\n| [[Image:Great ditrigonal dodecicosidodecahedron.png|64px]]<BR>[[Great ditrigonal dodecicosidodecahedron|U42]]\n| [[Image:Great icosicosidodecahedron.png|64px]]<BR>[[Great icosicosidodecahedron|U48]]\n| [[Image:Great dodecicosahedron.png|64px]]<BR>[[Great dodecicosahedron|U63]]\n|-\n! [[File:Small retrosnub icosicosidodecahedron convex hull.png|64px]]<BR>Nonuniform<BR>[[truncated dodecahedron]]\n| [[Image:Small retrosnub icosicosidodecahedron.png|64px]]<BR>[[Small retrosnub icosicosidodecahedron|U72]]\n|-\n! [[Image:Dodecahedron.png|64px]]<BR>[[Dodecahedron]]\n| [[Image:Great stellated dodecahedron.png|64px]]<BR>[[Great stellated dodecahedron|{5/2,3}]]\n| [[Image:Small ditrigonal icosidodecahedron.png|64px]]<BR>[[Small ditrigonal icosidodecahedron|U30]]\n| [[Image:Ditrigonal dodecadodecahedron.png|64px]]<BR>[[Ditrigonal dodecadodecahedron|U41]]\n| [[Image:Great ditrigonal icosidodecahedron.png|64px]]<BR>[[Great ditrigonal icosidodecahedron|U47]]\n|-\n! [[Image:Small rhombicosidodecahedron.png|64px]]<BR>[[Rhombicosidodecahedron]]\n| [[Image:Small dodecicosidodecahedron.png|64px]]<BR>[[Small dodecicosidodecahedron|U33]]\n| [[Image:Small rhombidodecahedron.png|64px]]<BR>[[Small rhombidodecahedron|U39]]\n| [[Image:Small stellated truncated dodecahedron.png|64px]]<BR>[[Small stellated truncated dodecahedron|U58]]\n|-\n![[File:Truncated great icosahedron convex hull.png|64px]]<BR>Nonuniform<BR> rhombicosidodecahedron\n|[[Image:Great truncated icosahedron.png|64px]]<BR>[[Truncated great icosahedron|U55]]\n|-\n! [[File:Nonuniform-rhombicosidodecahedron.png|64px]]<BR>Nonuniform<BR>rhombicosidodecahedron\n| [[Image:Small icosicosidodecahedron.png|64px]]<BR>[[Small icosicosidodecahedron|U31]]\n| [[Image:Small ditrigonal dodecicosidodecahedron.png|64px]]<BR>[[Small ditrigonal dodecicosidodecahedron|U43]]\n| [[Image:Small dodecicosahedron.png|64px]]<BR>[[Small dodecicosahedron|U50]]\n| [[Image:Great stellated truncated dodecahedron.png|64px]]<BR>[[Great stellated truncated dodecahedron|U66]]\n|-\n! [[File:Nonuniform2-rhombicosidodecahedron.png|64px]]<BR>Nonuniform<BR>rhombicosidodecahedron\n| [[Image:Great dirhombicosidodecahedron.png|64px]]<BR>[[Great dirhombicosidodecahedron|U75]]\n| [[Image:Great snub dodecicosidodecahedron.png|64px]]<BR>[[Great snub dodecicosidodecahedron|U64]]\n| [[Image:Great disnub dirhombidodecahedron.png|64px]]<BR>[[Great disnub dirhombidodecahedron|Skilling's figure]]<BR>(see below)\n|-\n! [[File:Icositruncated dodecadodecahedron convex hull.png|64px]]<BR>Nonuniform<BR>[[truncated icosidodecahedron]]\n| [[Image:Icositruncated dodecadodecahedron.png|64px]]<BR>[[Icositruncated dodecadodecahedron|U45]]\n|-\n! [[File:Truncated dodecadodecahedron convex hull.png|64px]]<BR>Nonuniform<BR>[[truncated icosidodecahedron]]\n| [[Image:Truncated dodecadodecahedron.png|64px]]<BR>[[Truncated dodecadodecahedron|U59]]\n|-\n![[File:Great truncated icosidodecahedron convex hull.png|64px]]<BR>Nonuniform<BR>[[truncated icosidodecahedron]]\n| [[Image:Great truncated icosidodecahedron.png|64px]]<BR>[[Great truncated icosidodecahedron|U68]]\n|-\n! [[Image:snub dodecahedron ccw.png|64px]]<BR>Nonuniform<BR>[[snub dodecahedron]]\n| [[Image:Snub dodecadodecahedron.png|64px]]<BR>[[Snub dodecadodecahedron|U40]]\n| [[Image:Snub icosidodecadodecahedron.png|64px]]<BR>[[Snub icosidodecadodecahedron|U46]]\n| [[Image:Great snub icosidodecahedron.png|64px]]<BR>[[Great snub icosidodecahedron|U57]]\n| [[Image:Great inverted snub icosidodecahedron.png|64px]]<BR>[[Great inverted snub icosidodecahedron|U69]]\n| [[Image:Inverted snub dodecadodecahedron.png|64px]]<BR>[[Inverted snub dodecadodecahedron|U60]]\n| [[Image:Great retrosnub icosidodecahedron.png|64px]]<BR>[[Great retrosnub icosidodecahedron|U74]]\n|}\n\n== Degenerate cases ==\n[[Coxeter]] identified a number of degenerate star polyhedra by the Wythoff construction method, which contain overlapping edges or vertices.  These degenerate forms include:\n* [[Small complex icosidodecahedron]]\n* [[Great complex icosidodecahedron]]\n* [[Small complex rhombicosidodecahedron]]\n* [[Great complex rhombicosidodecahedron]]\n* [[Complex rhombidodecadodecahedron]]\n\n=== Skilling's figure ===\n\nOne further nonconvex degenerate polyhedron is the [[Great disnub dirhombidodecahedron]], also known as ''Skilling's figure'', which is vertex-uniform, but has pairs of edges which coincide in space such that four faces meet at some edges. \nIt is counted as a degenerate uniform polyhedron rather than a uniform polyhedron because of its double edges. It has '''I'''<sub>h</sub> symmetry.\n\n[[Image:Great disnub dirhombidodecahedron.png|128px]]\n== See also ==\n*[[Star polygon]]\n*[[List of uniform polyhedra]]\n*[[List of uniform polyhedra by Schwarz triangle]]\n\n== Notes ==\n{{reflist}}\n\n==References==\n* {{cite journal| last = Coxeter| first = H. S. M.| authorlink = Harold Scott MacDonald Coxeter| title = Uniform Polyhedra| journal = Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences| volume = 246| number = 916| date = May 13, 1954| pages = 401–450| doi = 10.1098/rsta.1954.0003}}\n* {{cite book | first=Magnus | last=Wenninger | authorlink=Magnus Wenninger  | title=Polyhedron Models | publisher=Cambridge University Press | year=1974 | isbn=0-521-09859-9 | oclc=1738087 }}\n*[[Max Brückner|Brückner, M.]] ''Vielecke und vielflache. Theorie und geschichte.''. Leipzig, Germany: Teubner, 1900. [http://www.hti.umich.edu/cgi/b/bib/bibperm?q1=ABN8316.0001.001]\n*{{Citation | last1=Sopov | first1=S. P. | title=A proof of the completeness on the list of elementary homogeneous polyhedra | mr=0326550  | year=1970 | journal=Ukrainskiui Geometricheskiui Sbornik | issue=8 | pages=139–156}}\n*{{Citation | last1=Skilling | first1=J. | title=The complete set of uniform polyhedra | jstor=74475 | mr=0365333  | year=1975 | journal=Philosophical Transactions of the Royal Society of London. Series A. Mathematical and Physical Sciences | issn=0080-4614 | volume=278 | pages=111–135 | doi=10.1098/rsta.1975.0022}}\n* Har'El, Z. [https://web.archive.org/web/20090715034226/http://www.math.technion.ac.il/~rl/docs/uniform.pdf ''Uniform Solution for Uniform Polyhedra.''], Geometriae Dedicata 47, 57-110, 1993. [https://web.archive.org/web/20090727182130/http://www.math.technion.ac.il/~rl Zvi Har’El], [https://web.archive.org/web/20110520092545/http://www.math.technion.ac.il/~rl/kaleido Kaleido software], [https://web.archive.org/web/20110520080303/http://www.math.technion.ac.il/~rl/kaleido/poly.html Images], [https://web.archive.org/web/20110520080425/http://www.math.technion.ac.il/~rl/kaleido/dual.html dual images]\n*  [http://www.mathconsult.ch/showroom/unipoly Mäder, R. E.] ''Uniform Polyhedra.'' Mathematica J. 3, 48-57, 1993. [http://library.wolfram.com/infocenter/Articles/2254]\n*Messer, Peter W. [http://www.springerlink.com/content/me48wm7823jhdcpe/?p=baeede46029e489f9df9a3152c6cd8f6&pi=2 ''Closed-Form Expressions for Uniform Polyhedra and Their Duals.''], Discrete & Computational Geometry 27:353-375 (2002).\n* {{KlitzingPolytopes|polyhedra-neu.htm|3D|uniform polyhedra}}\n\n== External links ==\n* {{MathWorld | urlname=UniformPolyhedron | title=Uniform Polyhedron}}\n\n[[Category:Uniform polyhedra]]"
    },
    {
      "title": "Archimedean solid",
      "url": "https://en.wikipedia.org/wiki/Archimedean_solid",
      "text": "{{multiple image\n | align = right  | total_width=500\n | image1 = Polyhedron truncated 4a max.png |width1=3927|height1=3873\n | image2 = Polyhedron 6-8 max.png |width2=3850|height2=3680\n | image3 = Polyhedron great rhombi 12-20 max.png |width3=3943|height3=3977\n | footer = [[Truncated tetrahedron]], [[cuboctahedron]] and [[truncated icosidodecahedron]]. The first and the last one can be described as the smallest and the largest Archimedean solid, respectively.\n}}\n{{multiple image\n | align = right  | total_width=400\n | image1 = Polyhedron small rhombi 6-8, davinci.png\n | image2 = Elongated square gyrobicupola, davinci.png\n | footer = [[Rhombicuboctahedron]] and [[elongated square gyrobicupola|pseudo-rhombicuboctahedron]]\n}}\nIn [[geometry]], an '''Archimedean solid''' is one of the 13 solids first enumerated by Archimedes.  They are the semi-regular [[convex polyhedron|convex polyhedra]] composed of [[regular polygon]]s meeting in identical [[vertex (geometry)|vertices]], excluding the 5 [[Platonic solid]]s (which are composed of only one type of polygon) and excluding the prisms and antiprisms. They differ from the [[Johnson solid]]s, whose regular polygonal faces do not meet in identical vertices.\n\n\"Identical vertices\" means that each two vertices are symmetric to each other: A global [[isometry]] of the entire solid takes one vertex to the other while laying the solid directly on its initial position. {{harvs|first=Branko|last=Grünbaum|authorlink=Branko Grünbaum|year=2009|txt}} observed that a 14th polyhedron, the [[elongated square gyrobicupola]] (or pseudo-rhombicuboctahedron), meets a weaker definition of an Archimedean solid, in which \"identical vertices\" means merely that the faces surrounding each vertex are of the same types (i.e. each vertex looks the same from close up), so only a local isometry is required. Grünbaum pointed out a frequent error in which authors define Archimedean solids using this local definition but omit the 14th polyhedron. If only 13 polyhedra are to be listed, the definition must use global symmetries of the polyhedron rather than local neighborhoods.\n\n[[Prism (geometry)|Prisms]] and [[antiprism]]s, whose [[symmetry group]]s are the [[dihedral group]]s, are generally not considered to be Archimedean solids, even though their faces are regular polygons and their symmetry groups act transitively on their vertices. Excluding these two infinite families, there are 13 Archimedean solids. All the Archimedean solids (but not the elongated square gyrobicupola) can be made via [[Wythoff construction]]s from the Platonic solids with [[Tetrahedral symmetry|tetrahedral]], [[Octahedral symmetry|octahedral]] and [[icosahedral symmetry]].\n\n==Origin of name==\nThe Archimedean solids take their name from [[Archimedes]], who discussed them in a now-lost work. [[Pappus of Alexandria|Pappus]] refers to it, stating that Archimedes listed 13 polyhedra.<ref name=\"g09\">{{harvtxt|Grünbaum|2009}}.</ref> During the [[Renaissance]], [[artist]]s and [[mathematician]]s valued ''pure forms'' with high symmetry, and by around 1620 [[Johannes Kepler]] had completed the rediscovery of the 13 polyhedra,<ref>Field J., Rediscovering the Archimedean Polyhedra: Piero della Francesca, Luca Pacioli, Leonardo da Vinci, Albrecht Dürer, Daniele Barbaro, and Johannes Kepler, ''Archive for History of Exact Sciences'', '''50''', 1997, 227</ref> as well as defining the [[prism (geometry)|prisms]], [[antiprisms]], and the non-convex solids known as [[Kepler-Poinsot polyhedra]].\nThe reader may find more information about the rediscovery of the Archimedean solids during the renaissance in the paper by Peter Schreiber et al., published in 2008 (see References below).\n\nKepler may have also found the elongated square gyrobicupola (pseudorhombicuboctahedron): at least, he once stated that there were 14 Archimedean solids. However, his published enumeration only includes the 13 uniform polyhedra, and the first clear statement of the pseudorhombicuboctahedron's existence was made in 1905, by [[Duncan Sommerville]].<ref name=\"g09\"/>\n\n==Classification==\nThere are 13 Archimedean solids (not counting the [[elongated square gyrobicupola]]; 15 if the [[mirror image]]s of two [[chirality (mathematics)|enantiomorphs]], the snub cube and snub dodecahedron, are counted separately).\n\nHere the ''vertex configuration'' refers to the type of regular polygons that meet at any given vertex. For example, a [[vertex configuration]] of (4,6,8) means that a [[square]], [[hexagon]], and [[octagon]] meet at a vertex (with the order taken to be clockwise around the vertex).\n\n{| class=\"wikitable sortable\" style=\"text-align:center\"\n|-\n! Name<BR>(Alternative name)\n![[Schläfli symbol|Schläfli]]<BR>[[Coxeter diagram|Coxeter]]\n!class=\"unsortable\"| Transparent\n!class=\"unsortable\"| Solid\n!class=\"unsortable\"| [[Net (polyhedron)|Net]]\n! Vertex<br>[[vertex configuration|conf.]]/[[Vertex figure|fig.]]\n! colspan=\"2\" | Faces\n! Edges\n! Vert.\n! Volume<BR>(unit edges)\n! [[List of spherical symmetry groups#Polyhedral symmetry|Point<BR>group]]\n! [[Sphericity]]\n|-\n| [[truncated tetrahedron]]||t{3,3}<BR>{{CDD|node_1|3|node_1|3|node}}\n| [[Image:truncatedtetrahedron.jpg|70px|Truncated tetrahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:truncatedtetrahedron.gif]]\n| [[Image:Polyhedron truncated 4a max.png|70px]]\n| [[Image:Polyhedron truncated 4a net.svg|60px]]\n| 3.6.6<BR>[[Image:Polyhedron truncated 4a vertfig.png|50px]]\n| 8\n| 4 triangles<br>4 [[hexagon]]s\n| 18\n| 12\n| {{val|2.710576}}\n| T<sub>d</sub>\n| {{val|0.7754132}}\n|-\n| [[cuboctahedron]]<BR>(rhombitetratetrahedron)||r{4,3} or rr{3,3}<BR>{{CDD|node|4|node_1|3|node}} or {{CDD|node_1|3|node|3|node_1}}\n| [[Image:cuboctahedron.jpg|70px|Cuboctahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:cuboctahedron.gif]]\n| [[Image:Polyhedron 6-8 max.png|70px]]\n| [[Image:Polyhedron 6-8 net.svg|60px]]\n| 3.4.3.4<BR>[[Image:Polyhedron 6-8 vertfig.png|50px]]\n| 14\n| 8 [[triangle]]s<br>6 [[square]]s\n| 24\n| 12\n| {{val|2.357023}}\n| O<sub>h</sub>\n| {{val|0.9049973}}\n|-\n| [[truncated cube]]||t{4,3}<BR>{{CDD|node_1|4|node_1|3|node}}\n| [[Image:truncatedhexahedron.jpg|70px|Truncated hexahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:truncatedhexahedron.gif]]\n| [[Image:Polyhedron truncated 6 max.png|70px]]\n| [[Image:Polyhedron truncated 6 net.svg|60px]]\n| 3.8.8<BR>[[Image:Polyhedron truncated 6 vertfig.png|50px]]\n| 14\n| 8 triangles<br>6 [[octagon]]s\n| 36\n| 24\n| {{val|13.599663}}\n| O<sub>h</sub>\n| {{val|0.8494937}}\n|-\n| [[truncated octahedron]]<BR>(truncated tetratetrahedron)||t{3,4} or tr{3,3}<BR>{{CDD|node_1|3|node_1|4|node}} or {{CDD|node_1|3|node_1|3|node_1}}\n| [[Image:truncatedoctahedron.jpg|70px|Truncated octahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:truncatedoctahedron.gif]]\n| [[Image:Polyhedron truncated 8 max.png|70px]]\n| [[Image:Polyhedron truncated 8 net.svg|60px]]\n| 4.6.6<BR>[[Image:Polyhedron truncated 8 vertfig.png|50px]]\n| 14\n| 6 squares<br>8 hexagons\n| 36\n| 24\n| {{val|11.313709}}\n| O<sub>h</sub>\n| {{val|0.9099178}}\n|-\n| [[rhombicuboctahedron]]<BR>(small rhombicuboctahedron)||rr{4,3}<BR>{{CDD|node_1|4|node|3|node_1}}\n| [[Image:rhombicuboctahedron.jpg|70px|Rhombicuboctahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:rhombicuboctahedron.gif]]\n| [[Image:Polyhedron small rhombi 6-8 max.png|70px]]\n| [[Image:Polyhedron small rhombi 6-8 net.svg|60px]]\n| 3.4.4.4<BR>[[Image:Polyhedron small rhombi 6-8 vertfig.png|50px]]\n| 26\n|8 triangles<br>18 squares\n| 48\n| 24\n| {{val|8.714045}}\n| O<sub>h</sub>\n| {{val|0.9540796}}\n|-\n| [[truncated cuboctahedron]]<BR>(great rhombicuboctahedron)||tr{4,3}<BR>{{CDD|node_1|4|node_1|3|node_1}}\n| [[Image:truncatedcuboctahedron.jpg|70px|Truncated cuboctahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:truncatedcuboctahedron.gif]]\n| [[Image:Polyhedron great rhombi 6-8 max.png|70px]]\n| [[Image:Polyhedron great rhombi 6-8 net.svg|60px]]\n| 4.6.8<BR>[[Image:Polyhedron great rhombi 6-8 vertfig light.png|50px]]\n| 26\n| 12 squares<br>8 hexagons<br>6 octagons\n| 72\n| 48\n| {{val|41.798990}}\n| O<sub>h</sub>\n| {{val|0.9431657}}\n|-\n| [[snub cube]]<BR>(snub cuboctahedron)||sr{4,3}<BR>{{CDD|node_h|4|node_h|3|node_h}}\n| [[Image:snubhexahedronccw.jpg|70px|Snub hexahedron (Ccw)]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:snubhexahedronccw.gif]]\n| [[Image:Polyhedron snub 6-8 left max.png|70px]]\n| [[Image:Polyhedron snub 6-8 left net.svg|60px]]\n| 3.3.3.3.4<BR>[[Image:Polyhedron snub 6-8 left vertfig.png|50px]]\n| 38\n|32 triangles<br>6 squares\n| 60\n| 24\n| {{val|7.889295}}\n| O\n| {{val|0.9651814}}\n|-\n| [[icosidodecahedron]]||r{5,3}<BR>{{CDD|node|5|node_1|3|node}}\n| [[Image:icosidodecahedron.jpg|70px|Icosidodecahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:icosidodecahedron.gif]]\n| [[Image:Polyhedron 12-20 max.png|70px]]\n| [[Image:Polyhedron 12-20 net.svg|60px]]\n| 3.5.3.5<BR>[[Image:Polyhedron 12-20 vertfig.png|50px]]\n| 32\n| 20 triangles<br>12 [[pentagon]]s\n| 60\n| 30\n| {{val|13.835526}}\n| I<sub>h</sub>\n| {{val|0.9510243}}\n|-\n| [[truncated dodecahedron]]||t{5,3}<BR>{{CDD|node_1|5|node_1|3|node}}\n| [[Image:truncateddodecahedron.jpg|70px|Truncated dodecahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:truncateddodecahedron.gif]]\n| [[Image:Polyhedron truncated 12 max.png|70px]]\n| [[Image:Polyhedron truncated 12 net.svg|60px]]\n| 3.10.10<BR>[[Image:Polyhedron truncated 12 vertfig.png|50px]]\n| 32\n|20 triangles<br>12 [[decagon]]s\n| 90\n| 60\n| {{val|85.039665}}\n| I<sub>h</sub>\n| {{val|0.9260125}}\n|-\n| [[truncated icosahedron]]||t{3,5}<BR>{{CDD|node_1|3|node_1|5|node}}\n| [[Image:truncatedicosahedron.jpg|70px|Truncated icosahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:truncatedicosahedron.gif]]\n| [[Image:Polyhedron truncated 20 max.png|70px]]\n| [[Image:Polyhedron truncated 20 net.svg|60px]]\n| 5.6.6<BR>[[Image:Polyhedron truncated 20 vertfig.png|50px]]\n| 32\n| 12 pentagons<br>20 hexagons\n| 90\n| 60\n| {{val|55.287731}}\n| I<sub>h</sub>\n| {{val|0.9666219}}\n|-\n| [[rhombicosidodecahedron]]<BR>(small rhombicosidodecahedron)||rr{5,3}<BR>{{CDD|node_1|5|node|3|node_1}}\n| [[Image:rhombicosidodecahedron.jpg|70px|Rhombicosidodecahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:rhombicosidodecahedron.gif]]\n| [[Image:Polyhedron small rhombi 12-20 max.png|70px]]\n| [[Image:Polyhedron small rhombi 12-20 net.svg|60px]]\n| 3.4.5.4<BR>[[Image:Polyhedron small rhombi 12-20 vertfig.png|50px]]\n| 62\n| 20 triangles<br>30 squares<br>12 pentagons\n| 120\n| 60\n| {{val|41.615324}}\n| I<sub>h</sub>\n| {{val|0.9792370}}\n|-\n| [[truncated icosidodecahedron]]<BR>(great rhombicosidodecahedron)||tr{5,3}<BR>{{CDD|node_1|5|node_1|3|node_1}}\n| [[Image:truncatedicosidodecahedron.jpg|70px|Truncated icosidodecahedron]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:truncatedicosidodecahedron.gif]]\n| [[Image:Polyhedron great rhombi 12-20 max.png|70px]]\n| [[Image:Polyhedron great rhombi 12-20 net.svg|60px]]\n| 4.6.10<BR>[[Image:Polyhedron great rhombi 12-20 vertfig light.png|50px]]\n| 62\n|30 squares<br>20 hexagons<br>12 decagons\n| 180\n| 120\n| {{val|206.803399}}\n| I<sub>h</sub>\n| {{val|0.9703127}}\n|-\n| [[snub dodecahedron]]<BR>(snub icosidodecahedron)||sr{5,3}<BR>{{CDD|node_h|5|node_h|3|node_h}}\n| [[Image:snubdodecahedroncw.jpg|70px|Snub dodecahedron (Cw)]] &nbsp; [[File:Cog-scripted-svg-blue.svg|12px|link=File:snubdodecahedroncw.gif]]\n| [[Image:Polyhedron snub 12-20 left max.png|70px]]\n| [[Image:Polyhedron snub 12-20 left net.svg|60px]]\n| 3.3.3.3.5<BR>[[Image:Polyhedron snub 12-20 left vertfig.png|50px]]\n| 92\n| 80 triangles<br>12 pentagons\n| 150\n| 60\n| {{val|37.616650}}\n| I\n| {{val|0.9820114}}\n|}\n\nSome definitions of [[semiregular polyhedron]] include one more figure, the [[elongated square gyrobicupola]] or \"pseudo-rhombicuboctahedron\".<ref>{{harvtxt|Malkevitch|1988}}, p.&nbsp;85</ref>\n\n== Properties ==\n\nThe number of vertices is 720° divided by the vertex [[Defect (geometry)|angle defect]].\n\nThe cuboctahedron and icosidodecahedron are [[edge-uniform]] and are called [[quasiregular polyhedron|quasi-regular]].\n\nThe [[dual polyhedron|duals]] of the Archimedean solids are called the [[Catalan solid]]s.  Together with the [[bipyramid]]s and [[trapezohedron|trapezohedra]], these are the [[face-uniform]] solids with regular vertices.\n\n=== Chirality ===\n\nThe snub cube and snub dodecahedron are known as ''[[chirality (mathematics)|chiral]]'', as they come in a left-handed (Latin: levomorph or laevomorph) form and right-handed (Latin: dextromorph) form.{{elucidate|reason=Which is left-handed and which is right-handed?|date=February 2017}} When something comes in multiple forms which are each other's three-dimensional [[mirror image]], these forms may be called enantiomorphs.  (This nomenclature is also used for the forms of certain [[chemical compound]]s).\n\n== Construction of Archimedean solids ==\n{{Further information|Uniform polyhedron|Conway polyhedron notation}}\n[[File:Polyhedron truncation example3.png|thumb|The Archimedean solids can be constructed as [[uniform polyhedron#Convex forms by Wythoff construction|generator positions in a kaleidoscope]].]]\nThe different Archimedean and Platonic solids can be related to each other using a handful of general constructions.  Starting with a Platonic solid, [[truncation (geometry)|truncation]] involves cutting away of corners.  To preserve symmetry, the cut is in a plane perpendicular to the line joining a corner to the center of the polyhedron and is the same for all corners.  Depending on how much is truncated (see table below), different Platonic and Archimedean (and other) solids can be created. If the truncation is exactly deep enough such that each pair of faces from adjacent vertices shares exactly one point, it is known as a rectification. An [[expansion (geometry)|expansion]], or [[cantellation]], involves moving each face away from the center (by the same distance so as to preserve the symmetry of the Platonic solid) and taking the convex hull.  Expansion with twisting also involves rotating the faces, thus splitting each rectangle corresponding to an edge into two triangles by one of the diagonals of the rectangle.  The last construction we use here is truncation of both corners and edges.  Ignoring scaling, expansion can also be viewed the rectification of the rectification. Likewise, the cantitruncation can be viewed as the truncation of the rectification.\n{{Clear}}\n{| class=\"wikitable\"\n|+ Construction of Archimedean Solids\n!colspan=2|Symmetry\n![[Tetrahedral symmetry|Tetrahedral]]<BR>[[File:Tetrahedral reflection domains.png|120px]]\n!colspan=2|[[Octahedral symmetry|Octahedral]]<BR>[[File:Octahedral reflection domains.png|120px]]\n!colspan=2|[[Icosahedral symmetry|Icosahedral]]<BR>[[File:Icosahedral reflection domains.png|120px]]\n|-\n! Starting solid<BR>Operation||Symbol<BR>{p,q}<BR>{{CDD|node_1|p|node|q|node}}\n! [[Tetrahedron]]<BR>{3,3}<BR>[[File:Uniform polyhedron-33-t0.png|50px]] || [[Cube]]<BR>{4,3}<BR>[[File:Uniform polyhedron-43-t0.svg|50px]] || [[Octahedron]]<BR>{3,4}<BR>[[File:Uniform polyhedron-43-t2.svg|50px]] || [[Regular dodecahedron|Dodecahedron]]<BR>{5,3}<BR>[[File:Uniform polyhedron-53-t0.svg|50px]] || [[Regular icosahedron|Icosahedron]]<BR>{3,5}<BR>[[File:Uniform polyhedron-53-t2.svg|50px]]\n|- align=center\n! [[truncation (geometry)|Truncation]] (t)||t{p,q}<BR>{{CDD|node_1|p|node_1|q|node}}\n| [[truncated tetrahedron]]<BR>[[File:Uniform polyhedron-33-t01.png|50px]] || [[truncated cube]]<BR>[[File:Uniform polyhedron-43-t01.svg|50px]] || [[truncated octahedron]]<BR>[[File:Uniform polyhedron-43-t12.svg|50px]] || [[truncated dodecahedron]]<BR>[[File:Uniform polyhedron-53-t01.svg|50px]] || [[truncated icosahedron]]<BR>[[File:Uniform polyhedron-53-t12.svg|50px]]\n|- align=center\n! [[Rectification (geometry)|Rectification]] (r)<BR>Ambo (a)||r{p,q}<BR>{{CDD|node|p|node_1|q|node}}\n| [[tetratetrahedron]]<BR>(octahedron)<BR>[[File:Uniform polyhedron-33-t1.png|50px]] ||colspan=2| [[cuboctahedron]]<BR>[[File:Uniform polyhedron-43-t1.svg|50px]] ||colspan=2| [[icosidodecahedron]]<BR>[[File:Uniform polyhedron-53-t1.svg|50px]]\n|- align=center\n! [[Bitruncation]] (2t)<BR>Dual kis (dk)||2t{p,q}<BR>{{CDD|node|p|node_1|q|node_1}}\n| truncated tetrahedron<BR>[[File:Uniform polyhedron-33-t12.png|50px]] || truncated octahedron<BR>[[File:Uniform polyhedron-43-t12.png|50px]] || truncated cube<BR>[[File:Uniform polyhedron-43-t01.svg|50px]] || truncated icosahedron<BR>[[File:Uniform polyhedron-53-t12.svg|50px]] || truncated dodecahedron<BR>[[File:Uniform polyhedron-53-t01.svg|50px]]\n|- align=center\n! [[Birectification]] (2r)<BR>[[Dual polyhedron|Dual]] (d)||2r{p,q}<BR>{{CDD|node|p|node|q|node_1}}\n| tetrahedron<BR>[[File:Uniform polyhedron-33-t2.png|50px]]|| octahedron<BR>[[File:Uniform polyhedron-43-t2.svg|50px]] || cube<BR>[[File:Uniform polyhedron-43-t0.svg|50px]] || icosahedron<BR>[[File:Uniform polyhedron-53-t2.svg|50px]] || dodecahedron<BR>[[File:Uniform polyhedron-53-t0.svg|50px]]\n|- align=center\n! [[cantellation]] (rr)<BR>[[expansion (geometry)|Expansion]] (e)||rr{p,q}<BR>{{CDD|node_1|p|node|q|node_1}}\n| [[rhombitetratetrahedron]]<BR>(cuboctahedron)<BR>[[File:Uniform polyhedron-33-t02.png|50px]] ||colspan=2| [[rhombicuboctahedron]]<BR>[[File:Uniform polyhedron-43-t02.png|50px]] || colspan=2|[[rhombicosidodecahedron]] <BR>[[File:Uniform polyhedron-53-t02.png|50px]]\n|- align=center\n! Snub rectified (sr)<BR>[[Snub (geometry)|Snub]] (s)||sr{p,q}<BR>{{CDD|node_h|p|node_h|q|node_h}}\n| [[snub tetratetrahedron]]<BR>(icosahedron)<BR>[[File:Uniform polyhedron-33-s012.svg|50px]] ||colspan=2| [[snub cuboctahedron]]<BR>[[File:Uniform polyhedron-43-s012.png|50px]] ||colspan=2| [[snub icosidodecahedron]]<BR>[[File:Uniform polyhedron-53-s012.png|50px]]\n|- align=center\n! [[Cantitruncation]] (tr)<BR>Bevel (b)||tr{p,q}<BR>{{CDD|node_1|p|node_1|q|node_1}}\n| [[truncated tetratetrahedron]]<BR>(truncated octahedron)<BR>[[File:Uniform polyhedron-33-t012.png|50px]] ||colspan=2| [[truncated cuboctahedron]]<BR>[[File:Uniform polyhedron-43-t012.png|50px]] ||colspan=2| [[truncated icosidodecahedron]]<BR>[[File:Uniform polyhedron-53-t012.png|50px]]\n|}\n\nNote the duality between the cube and the octahedron, and between the dodecahedron and the icosahedron. Also, partially because the tetrahedron is self-dual, only one Archimedean solid that has at most tetrahedral symmetry. (All Platonic solids have at least tetrahedral symmetry, as tetrahedral symmetry is a symmetry operation of (i.e. is included in) octahedral and isohedral symmetries, which is demonstrated by the fact that an octahedron can be viewed as a rectified tetrahedron, and an isohedron can be used as a snub tetrahedron.)\n\n== See also ==\n* [[Aperiodic tiling]]\n* [[Archimedean graph]]\n* [[List of uniform polyhedra]]\n* [[Toroidal polyhedron]]\n* [[Quasicrystal]]\n* [[Semiregular polyhedron]]\n* [[Regular polyhedron]]\n* [[Uniform polyhedron]]\n* [[Icosahedral twins]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*{{citation\n | last = Grünbaum | first = Branko\n | doi = 10.4171/EM/120\n | issue = 3\n | journal = Elemente der Mathematik\n | mr = 2520469\n | pages = 89–101\n | title = An enduring error\n | volume = 64\n | year = 2009}}. Reprinted in {{citation|title=The Best Writing on Mathematics 2010|editor-first=Mircea|editor-last=Pitici|publisher=Princeton University Press|year=2011|pages=18–31}}.\n*{{cite journal\n | last = Jayatilake | first = Udaya\n | title = Calculations on face and vertex regular polyhedra\n | journal = Mathematical Gazette\n | date = March 2005\n | volume = 89\n | issue = 514\n | pages = 76–81\n}}.\n*{{citation\n | last = Malkevitch | first = Joseph\n | contribution = Milestones in the history of polyhedra\n | pages = 80–92\n | title = Shaping Space: A Polyhedral Approach\n | year = 1988\n | editor1-last = Senechal | editor1-first = M. | editor1-link = Marjorie Senechal\n | editor2-last = Fleck | editor2-first = G.\n | publisher = Birkhäuser\n | location = Boston\n}}.\n* {{cite book\n | last = Pugh | first = Anthony\n | year= 1976\n | title= Polyhedra: A visual approach\n | publisher= University of California Press Berkeley \n | location= California\n | isbn= 0-520-03056-7  \n}} Chapter 2\n* {{The Geometrical Foundation of Natural Structure (book)}} (Section 3-9)\n*{{cite journal\n | last1 = Schreiber | first1 = Peter\n | last2 = Fischer | first2 = Gisela\n | last3 = Sternath | first3 = Maria Luise\n | title = New light on the rediscovery of the Archimedean solids during the renaissance\n | journal =  Archive for History of Exact Sciences\n | issn =  0003-9519\n | volume = 62\n | issue = 4\n | pages = 457–467\n | year = 2008\n | doi = 10.1007/s00407-008-0024-z\n}}.\n\n==External links==\n* {{mathworld | urlname = ArchimedeanSolid | title = Archimedean solid }}\n* [http://demonstrations.wolfram.com/ArchimedeanSolids/ Archimedean Solids] by [[Eric W. Weisstein]], [[Wolfram Demonstrations Project]].\n*[http://www.software3d.com/Archimedean.php Paper models of Archimedean Solids and Catalan Solids]\n*[http://www.korthalsaltes.com/cuadros.php?type=a Free paper models(nets) of Archimedean solids]\n*[http://www.mathconsult.ch/showroom/unipoly/ The Uniform Polyhedra] by Dr. R. Mäder\n*[http://www.georgehart.com/virtual-polyhedra/vp.html Virtual Reality Polyhedra], ''The Encyclopedia of Polyhedra'' by George W. Hart\n*[http://www.cs.utk.edu/~plank/plank/origami/penultimate/intro.html Penultimate Modular Origami] by James S. Plank\n*[https://web.archive.org/web/20050403235101/http://ibiblio.org/e-notes/3Dapp/Convex.htm Interactive 3D polyhedra] in Java\n*[https://kovacsv.github.com/JSModeler/documentation/examples/solids.html Solid Body Viewer] is an interactive 3D polyhedron viewer which allows you to save the model in svg, stl or obj format.\n*[http://www.software3d.com/Stella.php Stella: Polyhedron Navigator]: Software used to create many of the images on this page.\n* [http://www.polyedergarten.de/ Paper Models of Archimedean (and other) Polyhedra]\n\n{{Archimedes}}\n{{Polyhedron navigator}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Archimedean Solid}}\n[[Category:Archimedean solids| ]]"
    },
    {
      "title": "Cuboctahedron",
      "url": "https://en.wikipedia.org/wiki/Cuboctahedron",
      "text": "{{More footnotes|date=September 2013}}\n{{Semireg polyhedra db|Semireg polyhedron stat table|CO}}\nIn [[geometry]], a '''cuboctahedron''' is a [[polyhedron]] with 8 triangular faces and 6 square faces. A cuboctahedron has 12 identical [[vertex (geometry)|vertices]], with 2 triangles and 2 squares meeting at each, and 24 identical [[edge (geometry)|edges]], each separating a triangle from a square. As such, it is a [[quasiregular polyhedron]], i.e. an [[Archimedean solid]] that is not only [[vertex-transitive]] but also [[edge-transitive]]. It is the only [[Cuboctahedron#Symmetries|radially equilateral]] convex polyhedron.\n\nIts [[dual polyhedron]] is the [[rhombic dodecahedron]].\n\nThe cuboctahedron was probably known to [[Plato]]: [[Hero of Alexandria|Heron]]'s ''Definitiones'' quotes [[Archimedes]] as saying that Plato knew of a solid made of 8 triangles and 6 squares.<ref>{{citation|last=Heath|first=Thomas L.|authorlink=Thomas Little Heath|title=A manual of Greek mathematics|publisher= Clarendon|pages=176|year=1931}}</ref>\n\n==Other names==\n*''Heptaparallelohedron'' ([[Buckminster Fuller]])\n**Fuller applied the name \"[[Dymaxion]]\" to this shape, used in an early version of the [[Dymaxion map]]. He also called it the \"Vector Equilibrium\" because of its radial equilateral symmetry (its center-to-vertex radius equals its edge length).<ref>[https://www.youtube.com/watch?v=9sM44p385Ws Vector Equilibrium: R. Buckminster Fuller]</ref> He called a cuboctahedron consisting of rigid struts connected by flexible vertices a \"jitterbug\" (this shape can be progressively deformed into an [[icosahedron]], [[octahedron]], and [[tetrahedron]] by collapsing its square sides).\n*With O<sub>h</sub> symmetry, order 48, it is a ''[[Rectification (geometry)|rectified]] [[cube]]'' or ''rectified octahedron'' ([[Norman Johnson (mathematician)|Norman Johnson]])\n*With T<sub>d</sub> symmetry, order 24, it is a ''[[Cantellation (geometry)|cantellated]] [[tetrahedron]]'' or rhombitetratetrahedron.\n*With D<sub>3d</sub> symmetry, order 12, it is a ''triangular [[gyrobicupola]]''.\n\n==Area and volume==\nThe area ''A'' and the volume ''V'' of the cuboctahedron of edge length ''a'' are:\n:<math>\\begin{align}\nA &= \\left(6+2\\sqrt{3}\\right)a^2 &&\\approx 9.464\\,1016a^2 \\\\\nV &= \\tfrac{5}{3} \\sqrt{2} a^3 &&\\approx 2.357\\,0226a^3. \\end{align}</math>\n\n==Orthogonal projections==\nThe ''cuboctahedron'' has four special [[orthogonal projection]]s, centered on a vertex, an edge, and the two types of faces, triangular and square. The last two correspond to the B<sub>2</sub> and A<sub>2</sub> [[Coxeter plane]]s. The skew projections show a square and hexagon passing through the center of the cuboctahedron.\n{|class=wikitable\n|+ Cuboctahedron (orthogonal projections)\n|-\n!Square<br>Face\n!Triangular<br>Face\n!Vertex\n!Edge\n!colspan=2|Skew\n|- align=center\n|[[File:Polyhedron 6-8 from red max.png|70px]]\n|[[File:Polyhedron 6-8 from yellow max.png|80px]]\n|[[File:Polyhedron 6-8 from blue max.png|60px]]\n|\n|\n|\n|- align=center\n|[[File:3-cube t1 B2.svg|80px]]\n|[[File:3-cube t1.svg|80px]]\n||[[File:Cube t1 v.png|80px]]\n|[[File:Cube t1 e.png|80px]]\n|[[File:Cuboctahedron B2 planes.png|80px]]\n|[[File:Cuboctahedron 3 planes.png|80px]]\n|- align=center\n|[4]\n|[6]\n|[2]\n|[2]\n|\n|\n|-\n!colspan=6|[[Rhombic dodecahedron]] (Dual polyhedron)\n|-\n|[[File:Dual cube t1 B2.png|80px]]\n|[[File:Dual cube t1.png|80px]]\n||[[File:Dual cube t1 v.png|80px]]\n|[[File:Dual cube t1 e.png|80px]]\n|[[File:Dual cube t1 skew1.png|80px]]\n|[[File:Dual cube t1 skew2.png|80px]]\n|}\n\n==Spherical tiling==\nThe cuboctahedron can also be represented as a [[spherical tiling]], and projected onto the plane via a [[stereographic projection]]. This projection is [[Conformal map|conformal]], preserving angles but not areas or lengths. Straight lines on the sphere are projected as circular arcs on the plane.\n{|class=wikitable\n|- align=center valign=top\n|[[File:Uniform tiling 432-t1.png|150px]]\n|[[File:cuboctahedron stereographic projection square.png|155px]]\n|[[File:cuboctahedron stereographic projection triangle.png|160px]]\n|[[File:Cuboctahedron_stereographic_projection_vertex.png|160px]]\n|-\n!rowspan=2|[[orthographic projection]]\n![[square]]-centered||[[triangle]]-centered||Vertex centered\n|-\n!colspan=3|[[Stereographic projection]]\n|}\n\n==Cartesian coordinates==\nThe [[Cartesian coordinates]] for the vertices of a cuboctahedron (of edge length {{sqrt|2}}) centered at the origin are:\n:(±1,±1,0)\n:(±1,0,±1)\n:(0,±1,±1)\n\nAn alternate set of coordinates can be made in 4-space, as 12 permutations of:\n:(0,1,1,2)\n\nThis construction exists as one of 16 [[orthant]] [[Facet (geometry)|facets]] of the [[cantellated 16-cell]].\n\n===Root vectors===\nThe cuboctahedron's 12 vertices can represent the root vectors of the [[simple Lie group]] A<sub>3</sub>. With the addition of 6 vertices of the [[octahedron]], these vertices represent the 18 root vectors of the [[simple Lie group]] B<sub>3</sub>.\n\n== Dissection ==\n\nThe ''cuboctahedron'' can be dissected into two [[triangular cupola]]s by a common hexagon passing through the center of the cuboctahedron. If these two triangular cupolas are twisted so triangles and squares line up, [[Johnson solid]] J<sub>27</sub>, the [[triangular orthobicupola]], is created.\n: [[File:Cuboctahedron 3 planes.png|120px]][[File:Triangular cupola.png|120px]][[File:Triangular_orthobicupola.png|120px]]\n\nThe cuboctahedron can also be dissected into 6 [[square pyramid]]s and 8 [[tetrahedra]] meeting at a central point. This dissection is expressed in the [[alternated cubic honeycomb]] where pairs of square pyramids are combined into [[octahedra]].\n: [[File:TetraOctaHoneycomb-VertexConfig.svg|160px]]\n\n==Geometric relations==\n[[File:P1-A3-P1.gif|thumb|Progression between a [[tetrahedron]], expanded into a cuboctahedron, and reverse expanded into the dual tetrahedron]]\n\n=== Symmetries ===\n[[File:A3-P5-P3.gif|thumb|Progressions between an [[octahedron]], [[pseudoicosahedron]], and cuboctahedron]]\nThe cuboctahedron is the unique convex polyhedron in which the long radius (center to vertex) is the same as the edge length; thus its long diameter (vertex to opposite vertex) is 2 edge lengths. This radial equilateral symmetry is a property of only a few [[polytopes]], including the two-dimensional [[hexagon]], the three-dimensional cuboctahedron, and the four-dimensional [[24-cell]] and [[tesseract|8-cell (tesseract)]]. ''Radially equilateral'' polytopes are those which can be constructed, with their long radii, from equilateral triangles which meet at the center of the polytope, each contributing two radii and an edge. Therefore, all the interior elements which meet at the center of these polytopes have equilateral triangle inward faces, as in the dissection of the cuboctahedron into 6 square pyramids and 8 tetrahedra. Each of these radially equilateral polytopes also occurs as cells of a characteristic space-filling [[tessellation]]: the tiling of regular hexagons, the [[rectified cubic honeycomb]] (of alternating cuboctahedra and octahedra), the [[24-cell honeycomb]] and the [[tesseractic honeycomb]], respectively. Each tessellation has a [[dual tessellation]]; the cell centers in a tessellation are cell vertices in its dual tessellation. The densest known regular [[sphere-packing]] in two, three and four dimensions uses the cell centers of one of these tessellations as sphere centers.\n\nA cuboctahedron has octahedral symmetry. Its first [[stellation]] is the [[polyhedral compound|compound]] of a [[cube (geometry)|cube]] and its dual [[octahedron]], with the vertices of the cuboctahedron located at the midpoints of the edges of either.\n\n=== Constructions ===\nA cuboctahedron can be obtained by taking an equatorial [[cross section (geometry)|cross section]] of a four-dimensional [[24-cell]] or [[16-cell]]. A hexagon can be obtained by taking an equatorial cross section of a cuboctahedron.\n\nThe cuboctahedron is a [[Rectification (geometry)|rectified]] [[cube]] and also a rectified [[octahedron]].\n\nIt is also a [[Cantellation (geometry)|cantellated]] [[tetrahedron]]. With this construction it is given the [[Wythoff symbol]]: {{nowrap|3 3 {{!}} 2}}. [[Image:Cantellated tetrahedron.png|50px]]\n\nA skew cantellation of the tetrahedron produces a solid with faces parallel to those of the cuboctahedron, namely eight triangles of two sizes, and six rectangles. While its edges are unequal, this solid remains ''vertex-uniform'': the solid has the full tetrahedral [[symmetry group]] and its vertices are equivalent under that group.\n\nThe edges of a cuboctahedron form four regular [[hexagon]]s. If the cuboctahedron is cut in the plane of one of these hexagons, each half is a [[triangular cupola]], one of the [[Johnson solid]]s; the cuboctahedron itself thus can also be called a triangular [[bicupola (geometry)|gyrobicupola]], the simplest of a series (other than the [[gyrobifastigium]] or \"digonal gyrobicupola\"). If the halves are put back together with a twist, so that triangles meet triangles and squares meet squares, the result is another Johnson solid, the [[triangular orthobicupola]], also called an anticuboctahedron.\n\nBoth triangular bicupolae are important in [[sphere packing]]. The distance from the solid's center to its vertices is equal to its edge length. Each central [[sphere]] can have up to twelve neighbors, and in a face-centered cubic lattice these take the positions of a cuboctahedron's vertices. In a [[hexagon]]al close-packed lattice they correspond to the corners of the triangular orthobicupola. In both cases the central sphere takes the position of the solid's center.\n\nCuboctahedra appear as cells in three of the [[convex uniform honeycomb]]s and in nine of the convex [[uniform 4-polytope]]s.\n\nThe volume of the cuboctahedron is {{sfrac|5|6}} of that of the enclosing cube and {{sfrac|5|8}} of that of the enclosing octahedron.\n\n=== Vertex arrangement ===\nBecause it is radially equilateral, the cuboctahedron's center can be treated as a 13th ''canonical apical vertex'', one edge length distant from the 12 ordinary vertices, as the [[Apex (geometry)|apex]] of a [[Pyramid (geometry)#Right pyramids with a regular base|canonical pyramid]] is one edge length equidistant from its other vertices.\n\nThe cuboctahedron shares its edges and vertex arrangement with two [[nonconvex uniform polyhedron|nonconvex uniform polyhedra]]: the [[cubohemioctahedron]] (having the square faces in common) and the [[octahemioctahedron]] (having the triangular faces in common). It also serves as a cantellated [[tetrahedron]], as being a rectified [[tetratetrahedron]].\n\n{| class=\"wikitable\" width=\"400\" style=\"vertical-align:top;text-align:center\"\n|[[Image:cuboctahedron.png|100px]]<br>Cuboctahedron\n|[[Image:cubohemioctahedron.png|100px]]<br>[[Cubohemioctahedron]]\n|[[Image:octahemioctahedron.png|100px]]<br>[[Octahemioctahedron]]\n|}\n\nThe cuboctahedron [[covering space|2-covers]] the [[tetrahemihexahedron]],<ref name=\"richter\">{{citation |ref={{harvid|Richter}} |first=David A. |last=Richter |url=http://homepages.wmich.edu/~drichter/rptwo.htm |title=Two Models of the Real Projective Plane}}\n</ref> which accordingly has the same [[abstract polytope|abstract]] [[vertex figure]] (two triangles and two squares: 3.4.3.4) and half the vertices, edges, and faces. (The actual vertex figure of the tetrahemihexahedron is 3.4.{{sfrac|3|2}}.4, with the {{sfrac|''a''|2}} factor due to the cross.)\n{|class=\"wikitable\" width=\"400\" style=\"vertical-align:top;text-align:center\"\n|[[Image:cuboctahedron.png|100px]]<br>Cuboctahedron\n|[[Image:tetrahemihexahedron.png|100px]]<br>[[Tetrahemihexahedron]]\n|}\n\n==Related polyhedra==\nThe cuboctahedron is one of a family of uniform polyhedra related to the cube and regular octahedron.\n{{Octahedral truncations}}\n\nThe cuboctahedron also has tetrahedral symmetry with two colors of triangles.\n{{Tetrahedron family}}\n\n=== Related quasiregular polyhedra and tilings ===\nThe cuboctahedron exists in a sequence of symmetries of quasiregular polyhedra and tilings with [[vertex configuration]]s (3.''n'')<sup>2</sup>, progressing from tilings of the sphere to the Euclidean plane and into the hyperbolic plane. With [[orbifold notation]] symmetry of *''n''32 all of these tilings are [[wythoff construction]] within a [[fundamental domain]] of symmetry, with generator points at the right angle corner of the domain.<ref>{{citation|authorlink=Harold Scott MacDonald Coxeter|last=Coxeter|first=H. S. M.|title=[[Regular Polytopes (book)|Regular Polytopes]]|edition=3rd|year=1973|publisher=Dover|isbn=0-486-61480-8|at=Chapter V: The Kaleidoscope, Section: 5.7 Wythoff's construction}}</ref><ref>[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.8536 ''Two Dimensional symmetry Mutations''] by Daniel Huson</ref>\n{{Quasiregular3 small table}}\n\n{{Quasiregular4 table}}\n\nThis polyhedron is topologically related as a part of sequence of [[Cantellation (geometry)|cantellated]] polyhedra with vertex figure (3.4.''n''.4), and continues as tilings of the [[Hyperbolic space|hyperbolic plane]]. These [[vertex-transitive]] figures have (*''n''32) reflectional [[Orbifold notation|symmetry]].\n\n{{Expanded small table}}\n\n==Related polytopes==\n[[File:Orthogonal projection envelopes 24-cell.png|thumb|Orthogonal projections of [[24-cell]]]]\nThe cuboctahedron can be decomposed into a regular [[octahedron]] and eight irregular but equal octahedra in the shape of the convex hull of a cube with two opposite vertices removed. This decomposition of the cuboctahedron corresponds with the cell-first parallel projection of the [[24-cell]] into three dimensions. Under this projection, the cuboctahedron forms the projection envelope, which can be decomposed into six square faces, a regular octahedron, and eight irregular octahedra. These elements correspond with the images of six of the octahedral cells in the 24-cell, the nearest and farthest cells from the 4D viewpoint, and the remaining eight pairs of cells, respectively.\n\n==Cultural occurrences==\n[[File:Two cuboctahedrons 2.jpg|left|200px|thumbnail|Two cuboctahedra on a chimney in [[Israel]].]]\n*In the ''[[Star Trek]]'' episode \"[[By Any Other Name]]\", aliens seize the [[Starship Enterprise|Enterprise]] by transforming crew members into inanimate cuboctahedra.\n*The \"Geo Twister\" fidget toy [http://www.trainerswarehouse.com/prodinfo.asp?number=FIGEO] is a flexible cuboctahedron.\n*The Coriolis space stations in the computer game series ''[[Elite (video game)|Elite]]'' are cuboctahedron-shaped.\n*Vesak Kuudu, traditional lanterns made in Sri Lanka annually to celebrate Vesak Poya day, are usually cuboctahedral. \n*\"Moonsnakes\" from ''[[Super Mario Odyssey]]''.<ref>{{Cite web|url=https://www.mariowiki.com/File:Moonsnake_Icon_SMO.png|title=File:Moonsnake Icon SMO.png - Super Mario Wiki, the Mario encyclopedia|website=www.mariowiki.com|language=en|access-date=2018-11-05}}</ref>\n*[https://influxdata.com InfluxData], the company behind the [[InfluxDB]] [[time series database]], uses the cuboctahedron [https://influxdata.github.io/branding/logo/story/ in its logo].\n{{Clear}}\n\n== Cuboctahedral graph ==\n{{Infobox graph\n | name = Cuboctahedral graph\n | image = [[File:Cuboctahedral graph.png|240px]]\n | image_caption = 4-fold symmetry\n | namesake = \n | vertices = 12\n | edges = 24\n | automorphisms = 48\n | radius = \n | diameter = \n | girth = \n | chromatic_number =\n | chromatic_index = \n | fractional_chromatic_index = \n | properties = {{plainlist|1=\n*[[Quartic graph|Quartic]]\n*[[hamiltonian graph|Hamiltonian]]\n*[[regular graph|regular]]\n*[[Locally linear graph|locally linear]]\n}}\n}}\nIn the [[mathematics|mathematical]] field of [[graph theory]], a '''cuboctahedral graph''' is the [[1-skeleton|graph of vertices and edges]] of the cuboctahedron, one of the [[Archimedean solid]]s. It can also be constructed as the [[line graph]] of the cube. It has 12 [[Vertex (graph theory)|vertices]] and 24 edges, is [[locally linear graph|locally linear]], and is a [[quartic graph|quartic]] [[Archimedean graph]].<ref>{{citation|last1=Read|first1=R. C.|last2=Wilson|first2=R. J.|title=An Atlas of Graphs|publisher=[[Oxford University Press]]|year= 1998|page=269}}</ref>\n\n{| class=wikitable\n|+ orthogonal projection\n|- align=center\n|[[File:3-cube t1.svg|200px]]<BR>6-fold symmetry\n|}\n{{Clear}}\n\n==See also==\n*[[Icosidodecahedron]]\n*[[Pseudocuboctahedron]]\n*[[Rhombicuboctahedron]]\n*[[Truncated cuboctahedron]]\n*[[Tetradecahedron]]\n\n==References==\n{{reflist|30em}}\n\n==Further reading==\n{{refbegin|30em}}\n*{{cite book|last=Ghyka|first=Matila|title=The geometry of art and life.|year=1977|publisher=[[Dover Publications]]|location=New York|isbn=9780486235424|pages=51&ndash;56, 81&ndash;84|edition=[Nachdr.]}}\n*{{cite encyclopedia|title=Cuboctahedron|last=Weisstein|first=Eric W.|encyclopedia=CRC Concise Encyclopedia of Mathematics.|year=2002|publisher=[[CRC Press]]|location=Hoboken|isbn=9781420035223|pages=620&ndash;621|edition=2nd}}\n*{{The Geometrical Foundation of Natural Structure (book)}} (Section 3-9)\n* Cromwell, P. ''Polyhedra'', CUP hbk (1997), pbk. (1999). Ch.2 p.&nbsp;79-86 ''Archimedean solids''\n{{refend}}\n\n==External links==\n*[http://www.mathconsult.ch/showroom/unipoly/ The Uniform Polyhedra]\n*[http://www.georgehart.com/virtual-polyhedra/vp.html Virtual Reality Polyhedra] The Encyclopedia of Polyhedra\n*{{mathworld2 |urlname=Cuboctahedron |title=Cuboctahedron |urlname2=ArchimedeanSolid |title2=Archimedean solid}}\n*[https://hexnet.org/content/cuboctahedron The Cuboctahedron] on [https://hexnet.org Hexnet] a website devoted to hexagon mathematics.\n*{{KlitzingPolytopes|polyhedra.htm|3D convex uniform polyhedra|o3x4o - co}}\n*[http://www.dr-mikes-math-games-for-kids.com/polyhedral-nets.html?net=dYI7PStK037OedkFHPiwHK2fbnxjxylGZCjWfNh0UwMgy82zEaWFzVL3PBfYB9SDz8RMvhNkpb8sS9R&name=Cuboctahedron#applet Editable printable net of a Cuboctahedron with interactive 3D view]\n*\n\n{{Archimedean solids}}\n{{Polyhedron navigator}}\n\n[[Category:Archimedean solids]]\n[[Category:Quasiregular polyhedra]]"
    },
    {
      "title": "Icosidodecahedron",
      "url": "https://en.wikipedia.org/wiki/Icosidodecahedron",
      "text": "{{Semireg polyhedra db|Semireg polyhedron stat table|ID}}\n\nIn [[geometry]], an '''icosidodecahedron''' is a [[polyhedron]] with twenty (icosi) triangular faces  and twelve (dodeca) pentagonal faces. An icosidodecahedron has 30 identical vertices, with two triangles and two pentagons meeting at each, and 60 identical edges, each separating a triangle from a pentagon. As such it is one of the [[Archimedean solid]]s and more particularly, a [[quasiregular polyhedron]].\n\n== Geometry==\nAn icosidodecahedron has icosahedral symmetry, and its first [[stellation]] is the compound of a [[dodecahedron]] and its dual [[icosahedron]], with the vertices of the icosidodecahedron located at the midpoints of the edges of either.\n\nIts [[dual polyhedron]] is the [[rhombic triacontahedron]]. An icosidodecahedron can be split along any of six planes to form a pair of [[pentagonal rotunda]]e, which belong among the [[Johnson solid]]s.\n\nThe icosidodecahedron can be considered a [[#Pentagonal gyrobirotunda|''pentagonal gyrobirotunda'']], as a combination of two [[pentagonal rotunda|rotundae]] (compare [[pentagonal orthobirotunda]], one of the [[Johnson solid]]s). In this form its symmetry is [[Dihedral symmetry|D<sub>5d</sub>]], [10,2<sup>+</sup>], (2*5), order 20.\n\nThe [[wire-frame figure]] of the icosidodecahedron consists of six [[decagon|flat regular decagons]], meeting in pairs at each of the 30 vertices.\n\nThe icosidodecahedron has 6 central [[decagon]]s. Projected into a sphere, they define 6 [[great circle]]s. [[Buckminster Fuller]] used these 6 great circles, along with 15 and 10 others in two other polyhedra to define his [[31 great circles of the spherical icosahedron]].\n\n==Cartesian coordinates==\nConvenient [[Cartesian coordinates]] for the vertices of an icosidodecahedron with unit edges are given by the [[even permutation]]s of:<ref>{{mathworld |title=Icosahedral group |urlname=IcosahedralGroup}}</ref>\n*(0, 0, ±''φ'')\n*(±{{sfrac|1|2}}, ±{{sfrac|''φ''|2}}, ±{{sfrac|''φ''<sup>2</sup>|2}})\nwhere ''φ'' is the [[golden ratio]], {{sfrac|1 + {{sqrt|5}}|2}}.\n\n==Orthogonal projections==\nThe icosidodecahedron has four special [[orthogonal projection]]s, centered on a vertex, an edge, a triangular face, and a pentagonal face. The last two correspond to the A<sub>2</sub> and H<sub>2</sub> [[Coxeter plane]]s.\n{|class=wikitable\n|+ Orthogonal projections\n|-\n!Centered by\n!Vertex\n!Edge\n!Face<br>Triangle\n!Face<br>Pentagon\n|-\n!Solid\n|[[File:Polyhedron 12-20 from blue max.png|120px]]\n|\n|[[File:Polyhedron 12-20 from yellow max.png|120px]]\n|[[File:Polyhedron 12-20 from red max.png|120px]]\n|-\n!Wireframe\n|[[File:Dodecahedron t1 v.png|120px]]\n|[[File:Dodecahedron t1 e.png|120px]]\n|[[File:Dodecahedron t1 A2.png|120px]]\n|[[File:Dodecahedron t1 H3.png|120px]]\n|- align=center\n!Projective<br>symmetry\n|[2]\n|[2]\n|[6]\n|[10]\n|-\n!Dual\n|[[File:Dual dodecahedron t1 v.png|120px]]\n|[[File:Dual dodecahedron t1 e.png|120px]]\n|[[File:Dual dodecahedron t1 A2.png|120px]]\n|[[File:Dual dodecahedron t1 H3.png|120px]]\n|}\n\n==Surface area and volume==\nThe surface area ''A'' and the volume ''V'' of the icosidodecahedron of edge length ''a'' are:\n:<math>\\begin{align}\nA &= \\left(5\\sqrt{3}+3\\sqrt{5}\\sqrt{3 + 4\\varphi}\\right) a^2 &&= \\left(5\\sqrt{3}+3\\sqrt{25+10\\sqrt{5}}\\right) a^2 &&\\approx 29.3059828a^2 \\\\\nV &= \\frac{14+17\\varphi}{3} a^3 &&= \\frac{45+17\\sqrt{5}}{6} a^3 &&\\approx 13.8355259a^3.\n\\end{align}</math>\n\n==Spherical tiling==\n{{multiple image\n | align = right  | total_width = 400\n | image1 = Polyhedron 12-20, davinci.png\n | image2 = Spherical icosidodecahedron with colored cicles.png\n | footer = The 60 edges form 6 [[decagon]]s corresponding to [[great circle]]s in the spherical tiling.\n}}\n\nThe icosidodecahedron can also be represented as a [[spherical tiling]], and projected onto the plane via a [[stereographic projection]]. This projection is [[Conformal map|conformal]], preserving angles but not areas or lengths. Straight lines on the sphere are projected as circular arcs on the plane.\n{|class=wikitable\n|- align=center valign=top\n|[[Image:Uniform tiling 532-t1.png|160px]]\n|[[Image:icosidodecahedron stereographic projection pentagon.png|160px]]<br>[[Pentagon]]-centered\n|[[Image:icosidodecahedron stereographic projection triangle.png|160px]]<br>[[Triangle]]-centered\n|-\n![[Orthographic projection]]\n!colspan=2|[[Stereographic projection]]s\n|}\n\n{| class=\"wikitable collapsible collapsed\" style=\"text-align: center; float: right;\"\n!colspan=\"5\"| Orthographic projections\n|-\n| [[File:Spherical icosidodecahedron with colored cicles, 2-fold.png|193px]]\n| [[File:Spherical icosidodecahedron with colored cicles, 3-fold.png|193px]]\n| [[File:Spherical icosidodecahedron with colored cicles, 5-fold light.png|193px]]\n|-\n|colspan=\"3\"| 2-fold, 3-fold and 5-fold symmetry axes\n|}\n\n==Related polytopes==\nThe icosidodecahedron is a [[Rectification (geometry)|rectified]] [[dodecahedron]] and also a rectified [[icosahedron]], existing as the full-edge truncation between these regular solids.\n\nThe icosidodecahedron contains 12 pentagons of the [[dodecahedron]] and 20 triangles of the [[icosahedron]]:\n{{Icosahedral truncations}}\n\nThe icosidodecahedron exists in a sequence of symmetries of quasiregular polyhedra and tilings with [[vertex configuration]]s (3.''n'')<sup>2</sup>, progressing from tilings of the sphere to the Euclidean plane and into the hyperbolic plane. With [[orbifold notation]] symmetry of *''n''32 all of these tilings are [[wythoff construction]] within a [[fundamental domain]] of symmetry, with generator points at the right angle corner of the domain.<ref>[[Harold Scott MacDonald Coxeter|Coxeter]] ''[[Regular Polytopes (book)|Regular Polytopes]]'', Third edition, (1973), Dover edition, {{ISBN|0-486-61480-8}} (Chapter V: The Kaleidoscope, Section: 5.7 Wythoff's construction)</ref><ref>[http://www.google.com/search?q=Two-Dimensional+Symmetry+Mutation ''Two Dimensional symmetry Mutations'' by Daniel Huson]</ref>\n{{Quasiregular3 small table}}\n\n{{Quasiregular5 table}}\n\n=== Dissection ===\nThe icosidodecahedron is related to the [[Johnson solid]] called a [[pentagonal orthobirotunda]] created by two [[pentagonal rotunda]] connected as mirror images. The ''icosidodecahedron'' can therefore be called a ''pentagonal gyrobirotunda'' with the gyration between top and bottom halves.\n\n{|class=\"wikitable\"\n|align=center|[[Image:Dissected icosidodecahedron.png|320px]]<br>(Dissection)\n|\n{|\n|align=center valign=bottom|[[Image:Icosidodecahedron.png|100px]]<br>Icosidodecahedron<br>(''pentagonal gyrobirotunda'')\n|-\n|align=center valign=bottom|[[Image:Pentagonal orthobirotunda solid.png|100px]]<br>Pentagonal orthobirotunda\n|-\n|align=center valign=bottom|[[Image:pentagonal rotunda.png|100px]]<br>Pentagonal rotunda\n|}\n|}\n\n=== Related polyhedra ===\n[[File:Icosidecahedron in truncated cube.png|120px|thumb|Icosidodecahedron in truncated cube]]\nThe [[truncated cube]] can be turned into an icosidodecahedron by dividing the octagons into two pentagons and two triangles. It has [[pyritohedral symmetry]].\n\nEight [[uniform star polyhedron|uniform star polyhedra]] share the same [[vertex arrangement]]. Of these, two also share the same [[edge arrangement]]: the [[small icosihemidodecahedron]] (having the triangular faces in common), and the [[small dodecahemidodecahedron]] (having the pentagonal faces in common). The vertex arrangement is also shared with the [[uniform polyhedron compound|compounds]] of [[compound of five octahedra|five octahedra]] and of [[compound of five tetrahemihexahedra|five tetrahemihexahedra]].\n{|class=\"wikitable\" width=\"400\" style=\"vertical-align:top;text-align:center\"\n|align=center|[[Image:Icosidodecahedron.png|100px]]<br>Icosidodecahedron\n|align=center|[[Image:Small icosihemidodecahedron.png|100px]]<br>[[Small icosihemidodecahedron]]\n|align=center|[[Image:Small dodecahemidodecahedron.png|100px]]<br>[[Small dodecahemidodecahedron]]\n|-\n|align=center|[[Image:Great icosidodecahedron.png|100px]]<br>[[Great icosidodecahedron]]\n|align=center|[[Image:Great dodecahemidodecahedron.png|100px]]<br>[[Great dodecahemidodecahedron]]\n|align=center|[[Image:Great icosihemidodecahedron.png|100px]]<br>[[Great icosihemidodecahedron]]\n|-\n|align=center|[[Image:Dodecadodecahedron.png|100px]]<br>[[Dodecadodecahedron]]\n|align=center|[[Image:Small dodecahemicosahedron.png|100px]]<br>[[Small dodecahemicosahedron]]\n|align=center|[[Image:Great dodecahemicosahedron.png|100px]]<br>[[Great dodecahemicosahedron]]\n|-\n|align=center|[[Image:Compound of five octahedra.png|100px]]<br>[[Compound of five octahedra]]\n|align=center|[[Image:UC18-5 tetrahemihexahedron.png|100px]]<br>[[Compound of five tetrahemihexahedra]]\n|}\n\n=== Related polychora ===\n\nIn four-dimensional geometry the '''icosidodecahedron''' appears in the [[Regular polytopes|regular]] [[600-cell]] as the equatorial slice that belongs to the vertex-first passage of the 600-cell through 3D space. In other words: the 30 vertices of the 600-cell which lie at arc distances of 90 degrees on its circumscribed [[hypersphere]] from a pair of opposite vertices, are the vertices of an icosidodecahedron. The wire frame figure of the 600-cell consists of 72 flat regular decagons. Six of these are the equatorial decagons to a pair of opposite vertices. They are precisely the six decagons which form the wire frame figure of the icosidodecahedron.\n\n== Icosidodecahedral graph ==\n{{Infobox graph\n | name = Icosidodecahedral graph\n | image = [[File:Icosidodecahedral graph.png|240px]]\n | image_caption = 5-fold symmetry [[Schlegel diagram]]\n | namesake = \n | vertices = 30\n | edges = 60\n | automorphisms = 120\n | radius = \n | diameter = \n | girth = \n | chromatic_number =\n | chromatic_index = \n | fractional_chromatic_index = \n | properties = [[Quartic graph]], [[hamiltonian graph|Hamiltonian]], [[regular graph|regular]]\n}}\nIn the [[mathematics|mathematical]] field of [[graph theory]], a '''icosidodecahedral graph''' is the [[1-skeleton|graph of vertices and edges]] of the icosidodecahedron, one of the [[Archimedean solid]]s. It has 30 [[Vertex (graph theory)|vertices]] and 60 edges, and is a [[quartic graph]] [[Archimedean graph]].<ref>{{citation|last1=Read|first1=R. C.|last2=Wilson|first2=R. J.|title=An Atlas of Graphs|publisher=[[Oxford University Press]]|year= 1998|page=269}}</ref>\n\n==See also==\n*[[Cuboctahedron]]\n*[[Great truncated icosidodecahedron]]\n*[[Icosahedron]]\n*[[Rhombicosidodecahedron]]\n*[[Truncated icosidodecahedron]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*{{The Geometrical Foundation of Natural Structure (book)}} (Section 3-9)\n*{{cite book|author=Cromwell, P.|year=1997|title=Polyhedra|location=United Kingdom|publisher=Cambridge|pages=79–86 ''Archimedean solids''|isbn=0-521-55432-2}}\n\n==External links==\n*{{mathworld2 |urlname=Icosidodecahedron |title=Icosidodecahedron |urlname2=ArchimedeanSolid |title2=Archimedean solid}}\n*{{KlitzingPolytopes|polyhedra.htm|3D convex uniform polyhedra|o3x5o - id}}\n*[http://www.dr-mikes-math-games-for-kids.com/polyhedral-nets.html?net=1D1NiLVqdeGtmgRYVoqDtRVdULYX8yuwCc3QmkefHkBBQFfG061UUcmoeyIbYKETw4p9pLg3WecHMPxDRy8JGaGKHlYWQJCqLbA3yu66NU9ZKOdvejvHBGtMuZp4O89LBszvnEgWNFbU7I2JwhnVp8hQBn8wSw1ifNCAzgGapWzCkvOVoJPQgcrWxuNXlSA1ESwiCSBVdqj7pKquEaYsKQyb&name=Icosidodecahedron#applet Editable printable net of an icosidodecahedron with interactive 3D view]\n*[http://www.mathconsult.ch/showroom/unipoly/ The Uniform Polyhedra]\n*[http://www.georgehart.com/virtual-polyhedra/vp.html Virtual Reality Polyhedra] The Encyclopedia of Polyhedra\n\n{{Archimedean solids}}\n{{Polyhedron navigator}}\n\n[[Category:Archimedean solids]]\n[[Category:Quasiregular polyhedra]]"
    },
    {
      "title": "Quasiregular polyhedron",
      "url": "https://en.wikipedia.org/wiki/Quasiregular_polyhedron",
      "text": "{| align=right\n|\n{| class=wikitable width=425\n|+ Quasiregular figures\n|-\n!colspan=6|Right triangle domains (p q 2), {{CDD|node|p|node_1|q|node}} = r{p,q}\n|-\n![[cuboctahedron|r{4,3}]]\n![[icosidodecahedron|r{5,3}]]\n![[trihexagonal tiling|r{6,3}]]\n![[triheptagonal tiling|r{7,3}]]...\n![[triapeirogonal tiling|r{&infin;,3}]]\n|-\n!{{CDD|node|4|node_1|3|node}}\n!{{CDD|node|5|node_1|3|node}}\n!{{CDD|node|6|node_1|3|node}}\n!{{CDD|node|7|node_1|3|node}}\n!{{CDD|node|infin|node_1|3|node}}\n|- align=center\n|[[File:Uniform polyhedron-43-t1.svg|60px]]<BR>(3.4)<sup>2</sup>\n|[[File:Uniform polyhedron-53-t1.svg|60px]]<BR>(3.5)<sup>2</sup>\n|[[File:Uniform_tiling_63-t1.svg|60px]]<BR>(3.6)<sup>2</sup>\n|[[File:Triheptagonal tiling.svg|60px]]<BR>(3.7)<sup>2</sup>\n|[[File:H2 tiling 23i-2.png|60px]]<BR>(3.&infin;)<sup>2</sup>\n|-\n!colspan=6| Isosceles triangle domains (p p 3), {{CDD|branch_10ru|split2-pp|node}} = {{CDD|node_h|6|node|p|node}} = h{6,p}\n|-\n![[Alternated order-4 hexagonal tiling|h{6,4}]]\n!h{6,5}\n!h{6,6}\n!h{6,7}...\n!h{6,&infin;}\n|-\n!{{CDD|node_h|6|node|4|node}} = {{CDD|branch_10ru|split2-44|node}}\n!{{CDD|node_h|6|node|5|node}} = {{CDD|branch_10ru|split2-55|node}}\n!{{CDD|node_h|6|node|6|node}} = {{CDD|branch_10ru|split2-66|node}}\n!{{CDD|node_h|6|node|7|node}} = {{CDD|branch_10ru|split2-77|node}}\n!{{CDD|node_h|6|node|infin|node}} = {{CDD|branch_10ru|split2-ii|node}}\n|- align=center\n|[[File:H2 tiling 344-4.png|60px]]<BR>(4.3)<sup>4</sup>\n|[[File:H2 tiling 355-4.png|60px]]<BR>(5.3)<sup>5</sup>\n|[[File:H2 tiling 366-4.png|60px]]<BR>(6.3)<sup>6</sup>\n|[[File:H2 tiling 377-4.png|60px]]<BR>(7.3)<sup>7</sup>\n|[[File:H2 tiling 3ii-4.png|60px]]<BR>(&infin;.3)<sup>&infin;</sup>\n\n|-\n!colspan=6| Isosceles triangle domains (p p 4), {{CDD|label4|branch_10ru|split2-pp|node}} = {{CDD|node_h|8|node|p|node}} = h{8,p}\n|-\n![[Alternated octagonal tiling|h{8,3}]]\n!h{8,5}\n!h{8,6}\n!h{8,7}...\n!h{8,&infin;}\n|-\n!{{CDD|node_h|8|node|3|node}} ={{CDD|label4|branch_10ru|split2|node}}\n!{{CDD|node_h|8|node|5|node}} ={{CDD|label4|branch_10ru|split2-55|node}}\n!{{CDD|node_h|8|node|6|node}} ={{CDD|label4|branch_10ru|split2-66|node}}\n!{{CDD|node_h|8|node|7|node}} ={{CDD|label4|branch_10ru|split2-77|node}}\n!{{CDD|node_h|8|node|infin|node}} ={{CDD|label4|branch_10ru|split2-ii|node}}\n|- align=center\n|[[File:H2 tiling 334-1.png|60px]]<BR>(4.3)<sup>3</sup>\n|[[File:H2 tiling 455-1.png|60px]]<BR>(4.5)<sup>5</sup>\n|[[File:H2 tiling 466-1.png|60px]]<BR>(4.6)<sup>6</sup>\n|[[File:H2 tiling 477-1.png|60px]]<BR>(4.7)<sup>7</sup>\n|[[File:H2 tiling 4ii-1.png|60px]]<BR>(4.&infin;)<sup>&infin;</sup>\n\n|-\n!colspan=6| Scalene triangle domain (5 4 3), {{CDD|branch|split2-45|node}}\n|-\n!{{CDD|branch_01rd|split2-45|node}}\n!{{CDD|branch|split2-45|node_1}}\n!{{CDD|branch_10ru|split2-45|node}}\n!\n!\n|- align=center\n|[[File:H2 tiling 345-1.png|60px]]<BR>(3.5)<sup>4</sup>\n|[[File:H2 tiling 345-2.png|60px]]<BR>(4.5)<sup>3</sup>\n|[[File:H2 tiling 345-4.png|60px]]<BR>(3.4)<sup>5</sup>\n|\n|\n\n|-\n|colspan=7|A '''quasiregular polyhedron''' or '''tiling''' has exactly two kinds of regular face, which alternate around each vertex. Their [[vertex figure]]s are [[Isogonal figure|isogonal polygons]].\n|}\n|-\n|\n{| class=wikitable width=425\n|+ Regular and quasiregular figures\n|-\n!colspan=5|Right triangle domains (p p 2), {{CDD|node_1|split1-pp|nodes}} = {{CDD|node_1|p|node|4|node_h0}} = r{p,p} = {p,4}<sub>{{frac|1|2}}</sub>\n|-\n![[octahedron|{3,4}<sub>{{frac|1|2}}</sub>]]<BR>r{3,3}\n![[square tiling|{4,4}<sub>{{frac|1|2}}</sub>]]<br>r{4,4}\n![[order-4 pentagonal tiling|{5,4}<sub>{{frac|1|2}}</sub>]]<br>r{5,5}\n![[order-4 hexagonal tiling|{6,4}<sub>{{frac|1|2}}</sub>]]<br>r{6,6}...\n![[order-4 apeirogonal tiling|{&infin;,4}<sub>{{frac|1|2}}</sub>]]<br>r{&infin;,&infin;}\n|-\n!{{CDD|node_1|3|node|4|node_h0}} = {{CDD|node_1|split1|nodes}}\n!{{CDD|node_1|4|node|4|node_h0}} = {{CDD|node_1|split1-44|nodes}}\n!{{CDD|node_1|5|node|4|node_h0}} = {{CDD|node_1|split1-55|nodes}}\n!{{CDD|node_1|6|node|4|node_h0}} = {{CDD|node_1|split1-66|nodes}}\n!{{CDD|node_1|infin|node|4|node_h0}} = {{CDD|node_1|split1-ii|nodes}}\n|- align=center\n|[[File:Uniform polyhedron-33-t1.png|60px]]<BR>(3.3)<sup>2</sup>\n|[[File:Uniform tiling 44-t1.svg|60px]]<BR>(4.4)<sup>2</sup>\n|[[File:H2 tiling 255-2.png|60px]]<BR>(5.5)<sup>2</sup>\n|[[File:H2 tiling 266-2.png|60px]]<BR>(6.6)<sup>2</sup>\n|[[File:H2 tiling 2ii-2.png|60px]]<BR>(&infin;.&infin;)<sup>2</sup>\n|-\n!colspan=5| Isosceles triangle domains (p p 3), {{CDD|node_1|split1-pp|branch}} = {{CDD|node_1|p|node|6|node_h0}} = {p,6}<sub>{{frac|1|2}}</sub>\n|-\n![[triangular tiling|{3,6}<sub>{{frac|1|2}}</sub>]]\n![[order-6 square tiling|{4,6}<sub>{{frac|1|2}}</sub>]]\n![[order-6 pentagonal tiling|{5,6}<sub>{{frac|1|2}}</sub>]]\n![[order-6 hexagonal tiling|{6,6}<sub>{{frac|1|2}}</sub>]]...\n![[order-6 apeirogonal tiling|{&infin;,6}<sub>{{frac|1|2}}</sub>]]\n|-\n!{{CDD|node_1|3|node|6|node_h0}} = {{CDD|node_1|split1|branch}}\n!{{CDD|node_1|4|node|6|node_h0}} = {{CDD|node_1|split1-44|branch}}\n!{{CDD|node_1|5|node|6|node_h0}} = {{CDD|node_1|split1-55|branch}}\n!{{CDD|node_1|6|node|6|node_h0}} = {{CDD|node_1|split1-66|branch}}\n!{{CDD|node_1|infin|node|6|node_h0}} = {{CDD|node_1|split1-ii|branch}}\n|- align=center\n|[[File:Uniform tiling 333-t1.svg|60px]]<BR>(3.3)<sup>3</sup>\n|[[File:H2 tiling 344-2.png|60px]]<BR>(4.4)<sup>3</sup>\n|[[File:H2 tiling 355-2.png|60px]]<BR>(5.5)<sup>3</sup>\n|[[File:H2 tiling 366-2.png|60px]]<BR>(6.6)<sup>3</sup>\n|[[File:H2 tiling 3ii-2.png|60px]]<BR>(&infin;.&infin;)<sup>3</sup>\n|-\n!colspan=6| Isosceles triangle domains (p p 4), {{CDD|node_1|split1-pp|branch|label4}} = {{CDD|node_1|p|node|8|node_h0}} = {p,8}<sub>{{frac|1|2}}</sub>\n|-\n![[order-8 triangular tiling|{3,8}<sub>{{frac|1|2}}</sub>]]\n![[order-8 square tiling|{4,8}<sub>{{frac|1|2}}</sub>]]\n![[order-8 pentagonal tiling|{5,8}<sub>{{frac|1|2}}</sub>]]\n![[order-8 hexagonal tiling|{6,8}<sub>{{frac|1|2}}</sub>]]...\n![[order-8 apeirogonal tiling|{&infin;,8}<sub>{{frac|1|2}}</sub>]]\n|-\n!{{CDD|node_1|3|node|8|node_h0}} ={{CDD|node_1|split1|branch|label4}}\n!{{CDD|node_1|4|node|8|node_h0}} ={{CDD|node_1|split1-44|branch|label4}}\n!{{CDD|node_1|5|node|8|node_h0}} ={{CDD|node_1|split1-55|branch|label4}}\n!{{CDD|node_1|6|node|8|node_h0}} ={{CDD|node_1|split1-66|branch|label4}}\n!{{CDD|node_1|infin|node|8|node_h0}} ={{CDD|node_1|split1-ii|branch|label4}}\n|- align=center\n|[[File:H2 tiling 334-4.png|60px]]<BR>(3.3)<sup>4</sup>\n|[[File:H2 tiling 444-2.png|60px]]<BR>(4.4)<sup>4</sup>\n|[[File:H2 tiling 455-2.png|60px]]<BR>(5.5)<sup>4</sup>\n|[[File:H2 tiling 466-2.png|60px]]<BR>(6.6)<sup>4</sup>\n|[[File:H2 tiling 4ii-2.png|60px]](&infin;.&infin;)<sup>4</sup>\n\n|-\n|colspan=6|A '''regular polyhedron''' or '''tiling''' can be considered quasiregular if it has an even number of faces around each vertex (and thus can have alternately colored faces).\n|}\n|}\nIn [[geometry]], a '''quasiregular polyhedron''' is a [[semiregular polyhedron]] that has exactly two kinds of [[regular polygon|regular faces]], which alternate around each [[vertex (geometry)|vertex]]. They are [[edge-transitive]] and hence a step closer to [[regular polyhedra]] than the semiregular which are merely [[vertex-transitive]]. The [[#Quasiregular_duals|dual figures]] is also sometimes considered quasiregular, except that they are edge-transitive, [[face-transitive]], and alternate between two regular [[vertex figure]]s.\n\nThere are only two regular [[Convex polytope|convex]] quasiregular polyhedra, the [[cuboctahedron]] and the [[icosidodecahedron]]. Their names, given by [[Kepler]], come from recognizing their faces contain all the faces of the [[Dual polyhedron|dual]]-pair [[cube]] and [[octahedron]], in the first, and the dual-pair [[icosahedron]] and [[dodecahedron]] in the second case.\n\nThese forms representing a pair of a regular figure and its dual can be given a vertical [[Schläfli symbol]] <math>\\begin{Bmatrix} p \\\\ q \\end{Bmatrix}</math> or r{p,q} to represent their containing the faces of both the regular '''{p,q}''' and dual regular '''{q,p}'''. A quasiregular polyhedron with this symbol will have a [[vertex configuration]] '''p.q.p.q''' (or '''(p.q)<sup>2</sup>''').\n\nMore generally, a uniform quasiregular figure can have a [[vertex configuration]] '''(p.q)<sup>r</sup>''', representing ''r'' (2 or more) instances of the faces around the vertex.\n\n[[Tessellation|Tilings]] of the plane can also be quasiregular, specifically the [[trihexagonal tiling]], with vertex configuration (3.6)<sup>2</sup>. [[Uniform tilings in hyperbolic plane|Other quasiregular tilings]] exist on the hyperbolic plane, like the [[triheptagonal tiling]], (3.7)<sup>2</sup>. Or more generally, (p.q)<sup>2</sup>, with 1/p+1/q<1/2.\n\nSome regular polyhedra and tilings (those with an even number of faces at each vertex) can also be considered quasiregular by differentiating between faces of the same number of sides, but representing them differently, like having different colors, but no surface features defining their orientation. A regular figure with [[Schläfli symbol]] {p,q} can be quasiregular, with vertex configuration (p.p)<sup>q/2</sup>, if q is even.\n\nThe [[octahedron]] can be considered quasiregular as a ''tetratetrahedron'' (2 sets of 4 triangles of the [[tetrahedron]]), (3<sub>a</sub>.3<sub>b</sub>)<sup>2</sup>, alternating two colors of triangular faces. Similarly the [[square tiling]] (4<sub>a</sub>.4<sub>b</sub>)<sup>2</sup> can be considered quasiregular, colored as a ''checkerboard''. Also the [[triangular tiling]] can have alternately colored triangle faces, (3<sub>a</sub>.3<sub>b</sub>)<sup>3</sup>.\n\n== Wythoff construction ==\n{| class=wikitable width=320\n|[[File:Wythoffian construction diagram.png|320px]]<br>Regular (''p &#124; 2 q'') and quasiregular polyhedra (''2 &#124; p q'') are created from a [[Wythoff construction]] with the generator point at one of 3 corners of the fundamental domain. This defines a single edge within the fundamental domain.\n|}\n[[File:Wythoff construction-pqr.png|400px|thumb|Quasiregular polyhedra are generated from all 3 corners of the fundamental domain for [[Schwarz triangle]]s that have no right angles:<br>'''q &#124; 2 p''', '''p &#124; 2 q''', '''2 &#124; p q''']]\n\n[[Coxeter]] defines a ''quasiregular polyhedron'' as one having a [[Wythoff symbol]] in the form ''p | q r'', and it is regular if q=2 or q=r.<ref>[[Coxeter|Coxeter, H.S.M.]], [[Michael S. Longuet-Higgins|Longuet-Higgins, M.S.]] and Miller, J.C.P. Uniform Polyhedra, ''Philosophical Transactions of the Royal Society of London'' '''246 A''' (1954), pp. 401–450. (Section 7, The regular and quasiregular polyhedra ''p | q r'')</ref>\n\nThe [[Coxeter-Dynkin diagram]] is another symbolic representation that shows the quasiregular relation between the two dual-regular forms: \n{| class=wikitable\n!colspan=2|[[Schläfli symbol]]\n![[Coxeter diagram]]\n![[Wythoff symbol]]\n|- align=center\n|<math>\\begin{Bmatrix} p , q \\end{Bmatrix}</math>||{p,q}||{{CDD|node_1|p|node|q|node}}||''q &#124; 2 p''\n|- align=center\n|<math>\\begin{Bmatrix} q , p \\end{Bmatrix}</math>||{q,p}|| {{CDD|node|p|node|q|node_1}}||''p &#124; 2 q''\n|- align=center\n| <math>\\begin{Bmatrix} p \\\\ q \\end{Bmatrix}</math>||r{p,q}|| {{CDD|node|p|node_1|q|node}} or {{CDD|node_1|split1-pq|nodes}}||''2 &#124; p q''\n|}\n\n==The convex quasiregular polyhedra==\n{{Further|Rectification (geometry)}}\nThere are two uniform [[Convex polyhedron|convex]] quasiregular polyhedra:\n#The [[cuboctahedron]] <math>\\begin{Bmatrix} 3 \\\\ 4 \\end{Bmatrix}</math>, vertex configuration '''(3.4)<sup>2</sup>''', [[Coxeter-Dynkin diagram]] {{CDD|node|4|node_1|3|node}}\n#The [[icosidodecahedron]] <math>\\begin{Bmatrix} 3 \\\\ 5 \\end{Bmatrix}</math>, vertex configuration '''(3.5)<sup>2</sup>''', ''Coxeter-Dynkin diagram'' {{CDD|node|5|node_1|3|node}}\n\nIn addition, the [[octahedron]], which is also [[regular polyhedron|regular]], <math>\\begin{Bmatrix} 3 \\\\ 3 \\end{Bmatrix}</math>, vertex configuration '''(3.3)<sup>2</sup>''', can be considered quasiregular if alternate faces are given different colors. In this form it is sometimes known as the tetratetrahedron. The remaining convex regular polyhedra have an odd number of faces at each vertex so cannot be colored in a way that preserves edge transitivity.  It has ''Coxeter-Dynkin diagram'' {{CDD|node|3|node_1|3|node}}\n\nEach of these forms the common core of a [[dual polyhedron|dual]] pair of [[regular polyhedron|regular polyhedra]]. The names of two of these give clues to the associated dual pair, respectively the [[cube]] + [[octahedron]] and the [[icosahedron]] + [[dodecahedron]]. The [[octahedron]] is the core of a dual pair of [[tetrahedron|tetrahedra]] (an arrangement known as the [[stella octangula]]), and when derived in this way is sometimes called the ''tetratetrahedron''.\n\n{| class=\"wikitable\"\n!Regular\n!Dual regular\n!Quasiregular\n![[Vertex figure]]\n|- valign=top align=center\n|[[File:Uniform polyhedron-33-t0.png|75px]]<br>[[Tetrahedron]]<br>{3,3}<br>{{CDD|node_1|3|node|3|node}}<br>3 | 2 3\n|[[File:Uniform polyhedron-33-t2.png|75px]]<br>[[Tetrahedron]]<br>{3,3}<br>{{CDD|node|3|node|3|node_1}}<br>3 | 2 3\n|[[File:Uniform polyhedron-33-t1.png|75px]]<br>[[Octahedron|Tetratetrahedron]]<BR>r{3,3}<br>{{CDD|node|3|node_1|3|node}}<br>2 | 3 3\n|[[File:Tetratetrahedron vertfig.png|75px]]<br>''3.3.3.3''\n|- valign=top align=center\n|[[File:Uniform polyhedron-43-t0.svg|75px]]<br>[[Cube]]<br>{4,3}<br>{{CDD|node_1|4|node|3|node}}<br>3 | 2 4\n|[[File:Uniform polyhedron-43-t2.svg|75px]]<br>[[Octahedron]]<br>{3,4}<br>{{CDD|node|4|node|3|node_1}}<br>4 | 2 3\n|[[File:Uniform polyhedron-43-t1.svg|75px]]<br>[[Cuboctahedron]]<br>r{3,4}<br>{{CDD|node|4|node_1|3|node}}<br>2 | 3 4\n|[[File:Cuboctahedron vertfig.png|75px]]<br>''3.4.3.4''\n|- valign=top align=center\n|[[File:Uniform polyhedron-53-t0.svg|75px]]<br>[[Dodecahedron]]<br>{5,3}<br>{{CDD|node_1|5|node|3|node}}<br>3 | 2 5\n|[[File:Uniform polyhedron-53-t2.svg|75px]]<br>[[Icosahedron]]<br>{3,5}<br>{{CDD|node|5|node|3|node_1}}<br>5 | 2 3\n|[[File:Uniform polyhedron-53-t1.svg|75px]]<br>[[Icosidodecahedron]]<br>r{3,4}<br>{{CDD|node|5|node_1|3|node}}<br>2 | 3 5\n|[[File:Icosidodecahedron vertfig.png|75px]]<br>''3.5.3.5''\n|}\n\nEach of these quasiregular polyhedra can be constructed by a [[Rectification (geometry)|rectification]] operation on either regular parent, [[Truncation (geometry)|truncating]] the edges fully, until the original edges are reduced to a point.\n\n=== Quasiregular tilings ===\nThis sequence continues as the [[trihexagonal tiling]], [[vertex figure]] ''(3.6)<sup>2</sup>'' - a '''quasiregular tiling''' based on the [[triangular tiling]] and [[hexagonal tiling]].\n\n{| class=\"wikitable\"\n!Regular\n!Dual regular\n!Quasiregular\n![[Vertex figure]]\n|- valign=top align=center\n|[[File:Uniform tiling 63-t0.svg|75px]]<br>[[Hexagonal tiling]]<br>{6,3}<br>{{CDD|node|6|node|3|node_1}}<br>6 | 2 3\n|[[File:Uniform tiling 63-t2.svg|75px]]<br>[[Triangular tiling]]<br>{3,6}<br>{{CDD|node_1|6|node|3|node}}<br>3 | 2 6\n|[[File:Uniform tiling 63-t1.svg|75px]]<br>[[Trihexagonal tiling]]<br>r{6,3}<BR>{{CDD|node|6|node_1|3|node}}<br>2 | 3 6\n|[[File:Trihexagonal tiling vertfig.png|75px]]<br>''(3.6)<sup>2</sup>''\n|}\n\nThe [[checkerboard]] pattern is a quasiregular coloring of the [[square tiling]], [[vertex figure]] ''(4.4)<sup>2</sup>'':\n{| class=\"wikitable\"\n!Regular\n!Dual regular\n!Quasiregular\n![[Vertex figure]]\n|- valign=top align=center\n|[[File:Uniform tiling 44-t0.svg|75px]]<br>{4,4}<br>{{CDD|node|4|node|4|node_1}}<br>4 | 2 4\n|[[File:Uniform tiling 44-t2.svg|75px]]<br>{4,4}<br>{{CDD|node_1|4|node|4|node}}<br>4 | 2 4\n|[[File:Uniform tiling 44-t1.svg|75px]]<br>r{4,4}<br>{{CDD|node|4|node_1|4|node}}<br>2 | 4 4\n|[[File:square tiling vertfig.png|75px]]<br>''(4.4)<sup>2</sup>''\n|}\n\nThe [[triangular tiling]] can also be considered quasiregular, with three sets of alternating triangles at each vertex, (3.3)<sup>3</sup>:\n{| class=\"wikitable\"\n|- align=center\n|[[File:Uniform tiling 333-t1.svg|60px]]<BR>h{6,3}<br>3 &#124; 3 3<br>{{CDD|branch_10ru|split2|node}} = {{CDD|node_h|6|node|3|node}}\n|}\n\nIn the hyperbolic plane, this sequence continues further, for example the [[triheptagonal tiling]], [[vertex figure]] ''(3.7)<sup>2</sup>'' - a '''quasiregular tiling''' based on the ''order-7 triangular tiling'' and ''heptagonal tiling''.\n{| class=\"wikitable\"\n!Regular\n!Dual regular\n!Quasiregular\n![[Vertex figure]]\n|- valign=top align=center\n|[[File:Heptagonal tiling.svg|75px]]<br>Heptagonal tiling<br>{7,3}<br>{{CDD|node|7|node|3|node_1}}<br>7 | 2 3\n|[[File:Order-7 triangular tiling.svg|75px]]<br>Triangular tiling<br>{3,7}<br>{{CDD|node_1|7|node|3|node}}<br>3 | 2 7\n|[[File:Triheptagonal tiling.svg|75px]]<br>[[Triheptagonal tiling]]<br>r{3,7}<br>{{CDD|node|7|node_1|3|node}}<br>2 | 3 7\n|[[File:Triheptagonal tiling vertfig.png|75px]]<br>''(3.7)<sup>2</sup>''\n|}\n\n==Nonconvex examples==\n\n[[Coxeter|Coxeter, H.S.M.]] et al. (1954) also classify certain [[star polyhedron|star polyhedra]] having the same characteristics as being quasiregular:\n\nTwo are based on dual pairs of regular [[Kepler–Poinsot solid]]s, in the same way as for the convex examples.\n\nThe [[great icosidodecahedron]] <math>\\begin{Bmatrix} 3 \\\\ 5/2 \\end{Bmatrix}</math> and the  [[dodecadodecahedron]] <math>\\begin{Bmatrix} 5 \\\\ 5/2 \\end{Bmatrix}</math>:\n\n{| class=\"wikitable\"\n!Regular\n!Dual regular\n!Quasiregular\n![[Vertex figure]]\n|- valign=top align=center\n|[[File:Great stellated dodecahedron.png|75px]]<br>[[Great stellated dodecahedron]]<br>{<sup>5</sup>/<sub>2</sub>,3}<br>{{CDD|node_1|5|rat|d2|node|3|node}}<br>3 | 2 5/2\n|[[File:Great icosahedron.png|75px]]<br>[[Great icosahedron]]<br>{3,<sup>5</sup>/<sub>2</sub>}<br>{{CDD|node|5|rat|d2|node|3|node_1}}<br>5/2 | 2 3\n|[[File:Great icosidodecahedron.png|75px]]<br>[[Great icosidodecahedron]]<br>r{3,<sup>5</sup>/<sub>2</sub>}<br>{{CDD|node|5|rat|d2|node_1|3|node}}<br>2 | 3 5/2\n|[[File:Great icosidodecahedron vertfig.png|75px]]<br>''3.<sup>5</sup>/<sub>2</sub>.3.<sup>5</sup>/<sub>2</sub>''\n|- valign=top align=center\n|[[File:Small stellated dodecahedron.png|75px]]<br>[[Small stellated dodecahedron]]<br>{<sup>5</sup>/<sub>2</sub>,5}<br>{{CDD|node_1|5|rat|d2|node|5|node}}<br>5 | 2 5/2\n|[[File:Great dodecahedron.png|75px]]<br>[[Great dodecahedron]]<br>{5,<sup>5</sup>/<sub>2</sub>}<br>{{CDD|node|5|rat|d2|node|5|node_1}}<br>5/2 | 2 5\n|[[File:Dodecadodecahedron.png|75px]]<br>[[Dodecadodecahedron]]<br>r{5,<sup>5</sup>/<sub>2</sub>}<br>{{CDD|node|5|rat|d2|node_1|5|node}}<br>2 | 5 5/2\n|[[File:Dodecadodecahedron vertfig.png|75px]]<br>''5.<sup>5</sup>/<sub>2</sub>.5.<sup>5</sup>/<sub>2</sub>''\n|}\n\nNine more are the [[hemipolyhedron|hemipolyhedra]], which are [[faceting|faceted]] forms of the aforementioned quasiregular polyhedra derived from rectification of regular polyhedra. These include equatorial faces passing through the centre of the polyhedra:\n\n{| class=wikitable width=500\n|- align=center\n!Quasiregular (rectified)\n|[[File:Rectified tetrahedron.png|75px]]<BR>Tetratetrahedron\n|[[File:Cuboctahedron.png|75px]]<BR>Cuboctahedron\n|[[File:Icosidodecahedron.png|75px]]<BR>Icosidodecahedron\n|[[File:Great icosidodecahedron.png|75px]]<BR>Great icosidodecahedron\n|[[File:Dodecadodecahedron.png|75px]]<BR>Dodecadodecahedron\n|- align=center\n!Quasiregular (hemipolyhedra)\n|[[File:Tetrahemihexahedron.png|75px]]<BR>[[Tetrahemihexahedron]]<BR><sup>3</sup>/<sub>2</sub> 3 {{pipe}} 2\n|[[File:Octahemioctahedron.png|75px]]<BR>[[Octahemioctahedron]]<BR><sup>3</sup>/<sub>2</sub> 3 {{pipe}} 3\n|[[File:Small icosihemidodecahedron.png|75px]]<BR>[[Small icosihemidodecahedron|Small&nbsp;icosihemidodecahedron]]<BR><sup>3</sup>/<sub>2</sub> 3 {{pipe}} 5\n|[[File:Great icosihemidodecahedron.png|75px]]<BR>[[Great icosihemidodecahedron|Great&nbsp;icosihemidodecahedron]]<BR><sup>3</sup>/<sub>2</sub> 3 {{pipe}} <sup>5</sup>/<sub>3</sub>\n|[[File:Small dodecahemicosahedron.png|75px]]<BR>[[Small dodecahemicosahedron|Small&nbsp;dodecahemicosahedron]]<BR><sup>5</sup>/<sub>3</sub> <sup>5</sup>/<sub>2</sub> {{pipe}} 3\n|- align=center\n![[Vertex figure]]\n|[[File:Tetrahemihexahedron vertfig.png|75px]]<br>''3.4.<sup>3</sup>/<sub>2</sub>.4''\n|[[File:Octahemioctahedron vertfig.png|75px]]<br>''3.6.<sup>3</sup>/<sub>2</sub>.6''\n|[[File:Small icosihemidodecahedron vertfig.png|75px]]''<br><BR>3.10.<sup>3</sup>/<sub>2</sub>.10''\n|[[File:Great icosihemidodecahedron vertfig.png|75px]]''<br>3.<sup>10</sup>/<sub>3</sub>.<sup>3</sup>/<sub>2</sub>.<sup>10</sup>/<sub>3</sub>''\n|[[File:Small dodecahemicosahedron vertfig.png|75px]]''<br><sup>5</sup>/<sub>2</sub>.6.<sup>5</sup>/<sub>3</sub>.6''\n|- align=center\n!Quasiregular (hemipolyhedra)\n|&nbsp;\n|[[File:Cubohemioctahedron.png|75px]]<BR>[[Cubohemioctahedron]]<BR><sup>4</sup>/<sub>3</sub> 4 {{pipe}} 3\n|[[File:Small dodecahemidodecahedron.png|75px]]<BR>[[Small dodecahemidodecahedron|Small&nbsp;dodecahemidodecahedron]]<BR><sup>5</sup>/<sub>4</sub> 5 {{pipe}} 5\n|[[File:Great dodecahemidodecahedron.png|75px]]<BR>[[Great dodecahemidodecahedron|Great&nbsp;dodecahemidodecahedron]]<BR><sup>5</sup>/<sub>3</sub> <sup>5</sup>/<sub>2</sub> {{pipe}} <sup>5</sup>/<sub>3</sub>\n|[[File:Great dodecahemicosahedron.png|75px]]<BR>[[Great dodecahemicosahedron|Great&nbsp;dodecahemicosahedron]]<BR><sup>5</sup>/<sub>4</sub> 5 {{pipe}} 3\n|- align=center\n!Vertex figure\n|&nbsp;\n|[[File:Cubohemioctahedron vertfig.png|75px]]<br>''4.6.<sup>4</sup>/<sub>3</sub>.6''\n|[[File:Small dodecahemidodecahedron vertfig.png|75px]]<br>''5.10.<sup>5</sup>/<sub>4</sub>.10''\n|[[File:Great dodecahemidodecahedron vertfig.png|75px]]<br>''<sup>5</sup>/<sub>2</sub>.<sup>10</sup>/<sub>3</sub>.<sup>5</sup>/<sub>3</sub>.<sup>10</sup>/<sub>3</sub>''\n|[[File:Great dodecahemicosahedron vertfig.png|75px]]<br>''5.6.<sup>5</sup>/<sub>4</sub>.6''\n|}\n\nLastly there are three [[ditrigonal]] forms, all facetings of the regular dodecahedron, whose vertex figures contain three alternations of the two face types:\n{| class=\"wikitable\"\n!Image\n!Polyhedron name<br>[[Wythoff symbol]]<br>[[Coxeter diagram]]\n![[Vertex figure]]\n|- align=center\n| [[File:Ditrigonal dodecadodecahedron.png|125px]]\n||[[Ditrigonal dodecadodecahedron]]<br>''3 | 5/3 5''<br>[[File:Ditrigonal dodecadodecahedron cd.png]] or {{CDD|node|5|node_h3|5-2|node}}\n||[[File:Ditrigonal dodecadodecahedron vertfig.png|100px]]<br>(5.5/3)<sup>3</sup>\n|- align=center\n| [[File:Small ditrigonal icosidodecahedron.png|125px]]\n||[[Small ditrigonal icosidodecahedron]]<br>''3 | 5/2 3''<br>[[File:Small ditrigonal icosidodecahedron cd.png]] or {{CDD|node_h3|5|node|3|node}}\n||[[File:Small ditrigonal icosidodecahedron vertfig.png|100px]]<br>(3.5/2)<sup>3</sup>\n|- align=center\n| [[File:Great ditrigonal icosidodecahedron.png|125px]]\n||[[Great ditrigonal icosidodecahedron]]<br>''3/2 | 3 5''<br>[[File:Great ditrigonal icosidodecahedron cd.png]] or {{CDD|node_h3|5-2|node|3|node}}\n||[[File:Great ditrigonal icosidodecahedron vertfig.png|100px]]<br>((3.5)<sup>3</sup>)/2\n|}\n\nIn the Euclidean plane, the sequence of hemipolyhedra continues with the following four star tilings, where [[apeirogon]]s appear as the aforementioned equatorial polygons:\n\n{| class=\"wikitable sortable\"\n|-\n!Original<br/>rectified<BR/>tiling!!Edge<br/>diagram!!Solid!!Vertex<br/>Config!!Wythoff!!Symmetry\n|- align=center\n|[[File:Uniform tiling 44-t1.svg|100px]]<BR>Square<BR>tiling||[[File:4.oo.4-3.oo tiling frame.png|100px]]||[[File:Star tiling sha.gif|150px]]||4.&infin;.4/3.&infin;<br/>4.&infin;.-4.&infin; || '''4/3 4 &#124; &infin;''' ||p4m \n|- align=center\n|[[File:Uniform tiling 333-t1.svg|100px]]<BR>Triangular<BR>tiling||[[File:3.oo.3.oo.3oo tiling-frame.png|100px]]||[[File:Star tiling ditatha.gif|150px]]||(3.&infin;.3.&infin;.3.&infin;)/2 || '''3/2 &#124; 3 &infin;'''||rowspan=3|p6m \n|- align=center\n|rowspan=2|[[File:Uniform tiling 63-t1.svg|100px]]<BR>Trihexagonal<BR>tiling\n|rowspan=2|[[File:6.oo.6-5.oo tiling-frame.png|100px]]||[[File:Star tiling hoha.gif|150px]]|| 6.&infin;.6/5.&infin;<br/>6.&infin;.-6.&infin; || '''6/5 6 &#124; &infin;''' \n|- align=center\n|[[File:Star tiling tha.gif|150px]]||&infin;.3.&infin;.3/2<br/>&infin;.3.&infin;.-3 || '''3/2 3 &#124; &infin;''' \n|}\n\n==Quasiregular duals==\n\nSome authorities argue that, since the duals of the quasiregular solids share the same symmetries, these duals should be called quasiregular too. But not everybody uses this terminology. These duals are transitive on their edges and faces (but not on their vertices); they are the edge-transitive [[Catalan solid]]s. The convex ones are, in corresponding order as above:\n#The [[rhombic dodecahedron]], with two ''types'' of alternating vertices, 8 with three rhombic faces, and 6 with four rhombic faces.\n#The [[rhombic triacontahedron]], with two ''types'' of alternating vertices, 20 with three rhombic faces, and 12 with five rhombic faces.\n\nIn addition, by duality with the octahedron, the [[cube]], which is usually [[regular polyhedron|regular]], can be made quasiregular if alternate vertices are given different colors.\n\nTheir [[face configuration]] are of the form V3.n.3.n, and [[Coxeter-Dynkin diagram]] {{CDD|node|3|node_f1|n|node}}\n{| class=\"wikitable\"\n|[[File:Hexahedron.svg|120px]]\n|[[File:Rhombicdodecahedron.jpg|140px]]\n|[[File:Rhombictriacontahedron.svg|120px]]\n|[[File:Rhombic star tiling.png|120px]]\n|[[File:Order73 qreg rhombic til.png|120px]]\n|[[File:Uniform dual tiling 433-t01-yellow.png|120px]]\n|- align=center valign=bottom\n|[[Cube]]<br>V(3.3)<sup>2</sup><br>{{CDD|node|3|node_f1|3|node}}\n|[[Rhombic dodecahedron]]<br>V(3.4)<sup>2</sup><br>{{CDD|node|3|node_f1|4|node}}\n|[[Rhombic triacontahedron]]<br>V(3.5)<sup>2</sup><br>{{CDD|node|3|node_f1|5|node}}\n|[[Rhombille tiling]]<br>V(3.6)<sup>2</sup><br>{{CDD|node|3|node_f1|6|node}}\n|V(3.7)<sup>2</sup><br>{{CDD|node|3|node_f1|7|node}}\n|V(3.8)<sup>2</sup><br>{{CDD|node|3|node_f1|8|node}}\n|}\n\nThese three quasiregular duals are also characterised by having [[rhombus|rhombic]] faces.\n\nThis rhombic-faced pattern continues as V(3.6)<sup>2</sup>, the [[rhombille tiling]].\n\n== Quasiregular polytopes and honeycombs==\nIn higher dimensions, Coxeter defined a quasiregular polytope or honeycomb to have regular facets and quasiregular vertex figures. It follows that all vertex figures are congruent and that there are two kinds of facets, which alternate.<ref name=regpol/>\n\nIn Euclidean 4-space, the regular [[16-cell]] can also be seen as quasiregular as an alternated [[tesseract]], h{4,3,3}, [[Coxeter diagram]]s: {{CDD|node_h1|4|node|3|node|3|node}} = {{CDD|nodes_10ru|split2|node|3|node}}, composed of alternating [[tetrahedron]] and [[tetrahedron]] [[Cell (geometry)|cells]]. Its [[vertex figure]] is the quasiregular [[tetratetrahedron]] (an octahedron with tetrahedral symmetry), {{CDD|node|3|node_1|3|node}}.\n\nThe only quasiregular honeycomb in Euclidean 3-space is the [[alternated cubic honeycomb]], h{4,3,4}, Coxeter diagrams: {{CDD|node_h1|4|node|3|node|4|node}} = {{CDD|nodes_10ru|split2|node|4|node}}, composed of alternating tetrahedral and [[octahedron|octahedral]] [[Cell (geometry)|cells]]. Its vertex figure is the quasiregular [[cuboctahedron]], {{CDD|node|4|node_1|3|node}}.<ref name=regpol>Coxeter, Regular Polytopes, 4.7 Other honeycombs. p.69, p.88</ref>\n\nIn hyperbolic 3-space, one quasiregular honeycomb is the [[alternated order-5 cubic honeycomb]], h{4,3,5}, Coxeter diagrams: {{CDD|node_h1|4|node|3|node|5|node}} = {{CDD|nodes_10ru|split2|node|5|node}}, composed of alternating tetrahedral and [[icosahedron|icosahedral]] [[Cell (geometry)|cells]]. Its vertex figure is the quasiregular [[icosidodecahedron]], {{CDD|node|5|node_1|3|node}}. A related paracompact [[alternated order-6 cubic honeycomb]], h{4,3,6} has alternating tetrahedral and hexagonal tiling cells with vertex figure is a quasiregular [[trihexagonal tiling]], {{CDD|node|6|node_1|3|node}}.\n\n{{Quasiregular polychora and honeycombs}}\n\nRegular polychora or honeycombs of the form {p,3,4} or {{CDD|node_1|p|node|3|node|4|node}} can have their symmetry cut in half as {{CDD|node_1|p|node|3|node|4|node_h0}} into quasiregular form {{CDD|node_1|p|node|split1|nodes}}, creating alternately colored {p,3} cells. These cases include the Euclidean [[cubic honeycomb]] {4,3,4} with [[cube|cubic]] cells, and compact hyperbolic {5,3,4} with [[dodecahedron|dodecahedral]] cells, and paracompact {6,3,4} with infinite [[hexagonal tiling]] cells. They have four cells around each edge, alternating in 2 colors. Their [[vertex figure]]s are quasiregular tetratetrahedra, {{CDD|node_1|3|node|4|node_h0}} = {{CDD|node_1|split1|nodes}}.\n[[File:Uniform polyhedron-33-t1.png|100px|thumb|Common vertex figure is the quasiregular tetratetrahedron, {{CDD|node_1|split1|nodes}}, same as regular [[octahedron]]]]\n{{Regular and Quasiregular honeycombs}}\n\nSimilarly regular hyperbolic honeycombs of the form {p,3,6} or {{CDD|node_1|p|node|3|node|6|node}} can have their symmetry cut in half as {{CDD|node_1|p|node|3|node|6|node_h0}} into quasiregular form {{CDD|node_1|p|node|split1|branch}}, creating alternately colored {p,3} cells. They have six cells around each edge, alternating in 2 colors. Their [[vertex figure]]s are quasiregular [[triangular tiling]]s, {{CDD|node_1|split1|branch}}.\n[[File:Uniform tiling 333-t1.svg|100px|thumb|The common [[vertex figure]] is a quasiregular [[triangular tiling]], {{CDD|node_1|3|node|6|node_h0}} = {{CDD|node_1|split1|branch}}]]\n\n{{Triangular tiling vertex figure tessellations}}\n\n== See also ==\n* [[Chiral polytope]]\n* [[Rectification (geometry)]]\n\n==Notes ==\n{{reflist}}\n\n==References==\n*Cromwell, P. ''Polyhedra'', Cambridge University Press (1977).\n*[[Coxeter]], ''[[Regular Polytopes (book)|Regular Polytopes]]'', (3rd edition, 1973), Dover edition, {{isbn|0-486-61480-8}}, 2.3 ''Quasi-Regular Polyhedra.'' (p.&nbsp;17), Quasi-regular honeycombs p.69\n\n==External links==\n* {{Mathworld | urlname=QuasiregularPolyhedron | title=Quasiregular polyhedron }}\n* {{Mathworld | urlname=UniformPolyhedron | title=Uniform polyhedron }} Quasi-regular polyhedra:  (p.q)<sup>r</sup>\n* George Hart, [http://www.georgehart.com/virtual-polyhedra/quasi-regular-info.html Quasiregular polyhedra]\n\n[[Category:Quasiregular polyhedra]]"
    },
    {
      "title": "Bilinski dodecahedron",
      "url": "https://en.wikipedia.org/wiki/Bilinski_dodecahedron",
      "text": "[[File:Bilinski dodecahedron.png|thumb|Bilinski dodecahedron with edges and front faces colored by their symmetry positions. It has D<sub>2h</sub> symmetry, order 8, containing 3 orthogonal mirrors, bisecting 4 of the 12 rhombic faces.]]\nIn geometry, the '''Bilinski dodecahedron''' is a 12-sided [[convex polyhedron]] with congruent [[rhombus|rhombic]] faces. It has the same topology but different geometry from the [[face transitive]] [[rhombic dodecahedron]], another 12-sided polyhedron with congruent rhombic faces.\n\n==History==\nThis shape appears in a 1752 book by [[John Lodge Cowley]], labeled as the '''dodecarhombus'''.<ref>{{citation\n | last = Hart | first = George W. | authorlink = George W. Hart\n | issue = 1-4\n | journal = Symmetry: Culture and Science\n | mr = 2001417\n | pages = 183–199\n | title = A color-matching dissection of the rhombic enneacontahedron\n | url = http://www.georgehart.com/dissect-re/dissect-re.htm\n | volume = 11\n | year = 2000}}.</ref><ref>{{citation|first=John Lodge|last=Cowley|authorlink=John Lodge Cowley|title=Geometry Made Easy; Or, a New and Methodical Explanation of the Elements of Geometry|year=1752|location=London|at=Plate 5, Fig. 16}}. As cited by {{harvtxt|Hart|2000}}.</ref>\nIt is named after [[Stanko Bilinski]], who rediscovered it in 1960.<ref>{{citation|first=S.|last=Bilinski|authorlink=Stanko Bilinski|title=Über die Rhombenisoeder|journal=Glasnik Mat. Fiz. Astr.|volume=15|year=1960|pages=251–263|zbl=0099.15506}}.</ref> Bilinski himself called it the '''rhombic dodecahedron of the second kind'''.<ref name=\"crom\">{{citation\n | last = Cromwell | first = Peter R.\n | isbn = 0-521-55432-2\n | mr = 1458063\n | page = 156\n | publisher = [[Cambridge University Press]]\n | location=Cambridge\n | title = Polyhedra: One of the most charming chapters of geometry\n | url = https://books.google.com/books?id=OJowej1QWpoC&pg=PA156\n | year = 1997}}.</ref> Bilinski's discovery corrected a 75-year-old omission in [[Evgraf Fedorov]]'s classification of convex polyhedra with congruent rhombic faces.<ref name=\"grun\"/>\n\n==Properties==\n[[File:Bilinski_dodecahedron_parallelohedron.png|thumb|As a [[zonohedron]], a Bilinski dodecahedron can be seen with 4 sets of 6 parallel edges. Contracting any set of 6 parallel edges to zero length produces golden rhombohedra.]]\nIn the rhombi of the Bilinski dodecahedron, the ratio of lengths of the two diagonals is the [[golden ratio]]; that is, the faces of this shape are [[Golden rhombus|golden rhombi]]. In contrast, for the standard rhombic dodecahedron the corresponding ratio is the [[square root of 2]].<ref>[https://www.youtube.com/watch?v=xVBOlbjiHGI A new rhombic dodecahedron], [[Matt Parker]], standupmaths</ref>\n\nThis shape is a [[zonohedron]]. Like the rhombic dodecahedron, it can tile three-dimensional space by translation, making it a [[parallelohedron]].<ref name=\"grun\"/>\n\n== Relation to rhombic dodecahedron ==\nThe Bilinski dodecahedron and [[rhombic dodecahedron]] have the same topology: their vertices, edges, and faces correspond one-for-one, in an adjacency-preserving way. However, their geometry is different.\nIn a 1962 paper,<ref>{{citation\n | last = Coxeter | first = H. S. M. | authorlink = H. S. M. Coxeter\n | journal = [[Journal de Mathématiques Pures et Appliquées]]\n | mr = 0141004\n | pages = 137–156\n | title = The classification of zonohedra by means of projective diagrams\n | volume = 41\n | year = 1962}}. Reprinted in {{citation\n | last = Coxeter | first = H. S. M.\n | location = Carbondale, Ill.\n | mr = 0310745\n | publisher = [[Southern Illinois University Press]]\n | title = Twelve geometric essays\n | year = 1968}} (''The Beauty of Geometry. Twelve Essays'', Dover, 1999, {{MR|1717154}}).</ref> [[H. S. M. Coxeter]] claimed that the Bilinski dodecahedron could be obtained by an [[affine transformation]] from the rhombic dodecahedron, but this is false. For, in the Bilinski dodecahedron, the long body diagonal is parallel to the short diagonals of two faces, and to the long diagonals of two other faces. In the rhombic dodecahedron, the corresponding body diagonal is parallel to four short face diagonals, and in any affine transformation of the rhombic dodecahedron this body diagonal would remain parallel to four equal-length face diagonals. Another difference between the two dodecahedra is that, in the rhombic dodecahedron, all the body diagonals connecting opposite degree-4 vertices are parallel to face diagonals, while in the Bilinski dodecahedron the shorter body diagonals of this type have no parallel face diagonals.<ref name=\"grun\"/>\n\n==Related zonohedra==\nThe Bilinski dodecahedron can be formed from the [[rhombic triacontahedron]] (another zonohedron with 30 golden rhombic faces) by removing or collapsing two zones or belts of faces with parallel edges. Removing only one of these two zones produces, instead, the [[rhombic icosahedron]], and removing three produces the [[golden rhombohedra]].<ref name=\"crom\"/><ref name=\"grun\">{{citation\n |last        = Grünbaum\n |first       = Branko\n |authorlink  = Branko Grünbaum\n |doi         = 10.1007/s00283-010-9138-7\n |issue       = 4\n |journal     = [[The Mathematical Intelligencer]]\n |mr          = 2747698\n |pages       = 5–15\n |title       = The Bilinski dodecahedron and assorted parallelohedra, zonohedra, monohedra, isozonohedra, and otherhedra\n |url         = http://hdl.handle.net/1773/15593\n |volume      = 32\n |year        = 2010\n}}.</ref> The Bilinski dodecahedron can be [[Dissection problem|dissected]] into four golden rhombohedra, two of each type.<ref>{{citation|url=http://www.cutoutfoldup.com/979-golden-rhombohedra.php|title=Golden Rhombohedra|work=CutOutFoldUp|accessdate=2016-05-26}}</ref>\n\nThe vertices of these zonohedra can be computed by linear combinations of 3 to 6 vectors. A [[Parallelohedron#Topological_types|belt]] m<sub>n</sub> means ''n'' directional vectors, each containing ''m'' coparallel congruent edges. The Bilinski dodecahedron has 4 belts of 6 coparallel edges. \n\nThese zonohedra are projection envelopes of the [[hypercube]]s, with n-dimensional projection basis, with [[golden ratio]], φ. The specific basis for n=6 is:\n: x = (1, φ, 0, -1, φ, 0)\n: y = (φ, 0, 1, φ, 0, -1)\n: z = (0, 1, φ, 0, -1, φ)\n\nFor n=5 the basis is the same with the 6th column removed, and for n=4 the 5th and 6th column are removed.\n\n{| class=wikitable\n|+ Zonohedra with golden rhombic faces\n|-\n![[Face (geometry)|Faces]]\n![[Rhombic triacontahedron|Triacontahedron]]\n![[Rhombic icosahedron|Icosahedron]]\n!Dodecahedron\n![[Golden rhombohedron|Hexahedron]]\n!\n|-\n![[List of spherical symmetry groups|Full<BR>symmetry]]\n![[Icosahedral symmetry|I<sub>h</sub>]]<BR>Order 120\n![[Dihedral symmetry in three dimensions|D<sub>5d</sub>]]<BR>Order 20\n!D<sub>2h</sub><BR>Order 8\n!D<sub>3d</sub><BR>Order 12\n!Dih<sub>2</sub><BR>Order 4\n|-\n![[Parallelohedron#Topological_types|Belts]]\n!10<sub>6</sub>\n!8<sub>5</sub>\n!6<sub>4</sub>\n!4<sub>3</sub>\n!2<sub>2</sub>\n|- align=center\n![[Face (geometry)|Faces]]\n|valign=top|30\n|20<BR>(−10)\n|12<BR>(−8)\n|6<BR>(−6)\n|2<BR>(−4)\n|- align=center\n![[Edge (geometry)|Edges]]\n|valign=top|60\n|40<BR>(−20)\n|24<BR>(−16)\n|12<BR>(−12)\n|4<BR>(−8)\n|- align=center\n![[Vertex (geometry)|Vertices]]\n|valign=top|32\n|22<BR>(−10)\n|14<BR>(−8)\n|8<BR>(−6)\n|4<BR>(−4)\n|- align=center\n!Image<BR>Solid\n|[[File:Rhombic triacontahedron middle colored.png|80px]]\n|[[File:Rhombic_icosahedron_colored_as_expanded_Bilinski_dodecahedron.png|80px]]\n|[[File:Bilinski_dodecahedron_as_expanded_golden_rhombohedron.png|80px]]\n|[[File:Acute golden rhombohedron.png|40px]][[File:Flat golden rhombohedron.png|40px]]\n|[[File:GoldenRhombus.svg|80px]]\n|- align=center\n!Image<BR>Parallels\n|[[File:Rhombic tricontahedron 6x10 parallels.png|80px]]\n|[[File:Rhombic_icosahedron_5-color-paralleledges.png|80px]]\n|[[File:Bilinski dodecahedron parallelohedron.png|80px]]\n|\n|\n|- align=center\n!Dissection\n|10[[File:Acute golden rhombohedron.png|20px]] + 10[[File:Flat golden rhombohedron.png|25px]]\n|5[[File:Acute golden rhombohedron.png|20px]] + 5[[File:Flat golden rhombohedron.png|25px]]\n|2[[File:Acute golden rhombohedron.png|20px]] + 2[[File:Flat golden rhombohedron.png|25px]]\n|\n|\n|-\n!Projective<BR>polytope||[[6-cube]]||[[5-cube]]||[[4-cube]]||[[3-cube]]||[[2-cube]]\n|- align=center\n!Image<BR>Projective<BR>n-cube\n|[[File:6Cube-QuasiCrystal.png|80px]]\n|[[File:5-cell-Phi-projection.png|80px]]\n|[[File:4-cell-Phi-projection.png|80px]]\n|\n|\n|}\n\n==References==\n{{reflist|30em}}\n\n==External links==\n* [[VRML]] model, [[George W. Hart]]: [http://www.georgehart.com/virtual-polyhedra/vrml/rhombic_dodecahedron_of_second_kind.wrl]\n\n[[Category:Zonohedra]]\n[[Category:Golden ratio]]"
    },
    {
      "title": "Rhombic enneacontahedron",
      "url": "https://en.wikipedia.org/wiki/Rhombic_enneacontahedron",
      "text": "{| class=wikitable align=\"right\" \n!bgcolor=#e7dcc3 colspan=2|Rhombic enneacontahedron\n|-\n|align=center colspan=2|[[File:Rhombic enneacontahedron.png|240px]]\n|-\n|bgcolor=#e7dcc3|[[Conway polyhedron notation|Conway notation]]||jtI = dakD [https://levskaya.github.io/polyhedronisme/?recipe=C400jtI]\n|-\n|bgcolor=#e7dcc3|Type||[[zonohedron]]\n|-\n|bgcolor=#e7dcc3|Face polygon||[[rhombus]]\n|-\n|bgcolor=#e7dcc3|Faces||90 rhombi:<BR>(60 wide and 30 narrow)\n|-\n|bgcolor=#e7dcc3|Edges||180 (60+120)\n|-\n|bgcolor=#e7dcc3|Vertices||92 (12+20+60)\n|-\n|bgcolor=#e7dcc3|Faces per vertex||3, 5, and 6\n|-\n|bgcolor=#e7dcc3|[[Dual polyhedron]]||[[Rectified truncated icosahedron]]\n|-\n|bgcolor=#e7dcc3|[[List of spherical symmetry groups|Symmetry group]]||[[Icosahedral symmetry|I<sub>h</sub>]], [5,3], *532\n|-\n|bgcolor=#e7dcc3|Properties||convex, [[zonohedron]]\n|-\n|colspan=2 align=center|[[File:Rhombic enneacontahedron flat.png|280px]]<br>[[Net (polyhedron)|Net]]\n|}\nA '''rhombic enneacontahedron''' (plural: '''rhombic enneacontahedra''') is a [[polyhedron]] composed of 90 rhombic faces; with three, five, or six rhombi meeting at each vertex. It has 60 broad [[rhombus|rhombi]] and 30 slim. The rhombic enneacontahedron is a [[zonohedron]] with a superficial resemblance to the [[rhombic triacontahedron]].\n\n== Construction==\nIt can also be seen as a nonuniform [[truncated icosahedron]] with pyramids augmented to the pentagonal and hexagonal faces with heights adjusted until the [[dihedral angle]]s are zero, and the two pyramid type side edges are equal length. This construction is expressed in the [[Conway polyhedron notation]] ''jtI'' with join operator ''j''. Without the equal edge constraint, the wide rhombi are [[kite (geometry)|kites]] if limited only by the [[icosahedral symmetry]].\n[[File:Joined truncated icosahedron.png|thumb|left|joined truncated icosahedron]]\nThe sixty broad rhombic faces in the rhombic enneacontahedron are identical to those in the [[rhombic dodecahedron]], with diagonals in a ratio of 1 to the [[square root of 2]]. The face angles of these rhombi are approximately 70.528° and 109.471°. The thirty slim rhombic faces have face vertex angles of 41.810° and 138.189°; the diagonals are in ratio of 1 to [[Golden ratio|φ<sup>2</sup>]].\n\nIt is also called a '''rhombic enenicontahedron''' in [[Lloyd Kahn]]'s ''Domebook 2''.\n{{-}}\n\n==Close-packing density==\n\nThe optimal [[Packing density|packing fraction]] of rhombic enneacontahedra is given by\n:<math> \\eta = 16 - \\frac{34}{\\sqrt{5}} \\approx 0.7947377530014315 </math>.\nIt was noticed that this optimal value is obtained in a [[Bravais lattice]] by {{harvs|txt|last=de Graaf|year=2011}}. Since the rhombic enneacontahedron is contained in a [[rhombic dodecahedron]] whose\n[[inscribed sphere]] is identical to its own inscribed sphere, the value of the optimal packing fraction is a corollary of the [[Kepler conjecture]]: it can be achieved by putting a rhombicuboctahedron in each cell of the [[rhombic dodecahedral honeycomb]], and it cannot be surpassed, since otherwise the optimal packing density of spheres could be surpassed by putting a sphere in each rhombicuboctahedron of the hypothetical packing which surpasses it.\n\n[[File:Rhombic enneacontahedron.gif|240px]]\n\n==References==\n{{reflist}}\n* {{mathworld | urlname = RhombicEnneacontahedron | title = Rhombic enneacontahedron}}\n* [[VRML]] model: George Hart, [http://www.georgehart.com/virtual-polyhedra/vrml/rhombic_enneacontahedron.wrl]\n* [http://www.georgehart.com/virtual-polyhedra/conway_notation.html George Hart's Conway Generator] Try [[Conway polyhedron notation|dakD]]\n* [http://issuu.com/golfstromen/docs/lloyd-kahn-1971 Domebook2 by Kahn, Lloyd (Editor); Easton, Bob; Calthorpe, Peter; et al., Pacific Domes, Los Gatos, CA (1971), page 102]\n* {{Citation | last1=de Graaf | first1=J. | last2=van Roij | first2=R. | last3=Dijkstra | first3=M. | title=Dense Regular Packings of Irregular Nonconvex Particles | doi=10.1103/PhysRevLett.107.155501 | year=2011 | journal=Phys. Rev. Lett. | volume=107 | pages=155501 | bibcode=2011PhRvL.107o5501D|arxiv = 1107.0603 | pmid=22107298}}\n* {{Citation | last1=Torquato | first1=S. | last2=Jiao | first2=Y. | title=Dense packings of the Platonic and Archimedean solids | doi=10.1038/nature08239 | year=2009 | journal=Nature | volume=460 | pages=876 | pmid=19675649|arxiv = 0908.4107 |bibcode = 2009Natur.460..876T }}\n* {{Citation | last1=Hales | first1=Thomas C. | title=A proof of the Kepler conjecture | doi=10.4007/annals.2005.162.1065 | year=2005 | journal=Annals of Mathematics | volume=162 | pages=1065 | arxiv=math/9811078 }}\n\n==External links==\n*{{mathworld |urlname=RhombicEnneacontahedron |title=Rhombic enneacontahedron}}\n* [http://www.orchidpalms.com/polyhedra/rhombic/rh90/rh90.htm The Rhombic Enneacontahedron and relations]\n*[http://dmccooey.com/polyhedra/RhombicEnneacontahedron.html Rhombic Enneacontahedron] \n* [[George W. Hart|George Hart]]\n**[http://www.georgehart.com/dissect-re/dissect-re.htm A Color-Matching Dissection of the Rhombic Enneacontahedron]\n**[http://www.georgehart.com/virtual-polyhedra/dissection-re.html Color-Matching Dissection of the Rhombic Enneacontahedron]\n**[http://www.georgehart.com/virtual-polyhedra/vrml/rhombic_enneacontahedron.wrl] [[VRML]] model\n\n{{Polyhedra}}\n\n[[Category:Zonohedra]]"
    },
    {
      "title": "Rhombic hectotriadiohedron",
      "url": "https://en.wikipedia.org/wiki/Rhombic_hectotriadiohedron",
      "text": "{| class=wikitable align=\"right\" width=340\n!bgcolor=#e7dcc3 colspan=2|Rhombic hectotriadiohedron\n|-\n|align=center colspan=2|[[File:Rhombic hectotriadiohedron.png|160px]][[File:Rhombic_hectotriadiohedron_type_c.png|160px]]<BR>Type T and Type C\n|-\n|bgcolor=#e7dcc3|Type||[[zonohedron]]\n|-\n|bgcolor=#e7dcc3|Face polygon||[[rhombus]]\n|-\n|bgcolor=#e7dcc3|Faces||132 rhombi\n|-\n|bgcolor=#e7dcc3|Edges||264\n|-\n|bgcolor=#e7dcc3|Vertices||134\n|-\n|bgcolor=#e7dcc3|[[List_of_spherical_symmetry_groups|Symmetry group]]||[[Octahedral symmetry|O<sub>h</sub>]], [4,3], *432\n|-\n|bgcolor=#e7dcc3|Properties||convex, [[zonohedron]]\n|}\nIn [[geometry]], a '''rhombic hectotriadiohedron''', '''rhombhectotriadiohedron''' or '''rhombic 132-hedron''' is a [[polyhedron]] composed of 132 rhombic faces. Rhombic faces have 5 positions within [[octahedral symmetry]]. There are two topological types, with the same number of elements, the same symmetry, but having a somewhat different arrangement of rhombic faces.<ref>Y. Watanabe, T. Betsumiya [http://www.scipress.org/e-library/rpf/pdf/chap2/0055.PDF Derivation of Some Equilateral Zonohedra and Star Zonohedra], ''Research of pattern formation''</ref>\n\nThe type T has 8 rhombi meeting at the center positions of a cube's 6 faces. 3 meet at the 8 corners of a cube. 12 are positioned along the 12 edges of a cube, and 4 more surround each of 12 edges of a cube. It is a 12-zone [[zonohedrification]]<ref>http://www.georgehart.com/virtual-polyhedra/zonohedrification.html</ref> of the [[rhombicuboctahedron]].<ref>http://www.georgehart.com/virtual-polyhedra/zonohedra-index.html</ref>\n\nType C is a 12-zone zonohedrification of a [[truncated cube]].\n\n== See also==\n* [[Trigonal trapezohedron]] - 6 rhombi\n* [[Rhombic dodecahedron]] - 12 rhombi\n* [[Rhombic triacontahedron]] - 30 rhombi\n* [[Rhombic hexecontahedron]] - 60 rhombi\n* [[Rhombic enneacontahedron]] - 90 rhombi\n\n==References==\n{{reflist}}\n* [[George W. Hart|George Hart]]\n**[http://www.georgehart.com/virtual-polyhedra/vrml/zono-12_from_rhombicubocahedron.wrl zono-12 from rhombicubocahedron] [[VRML]] model\n**[http://www.georgehart.com/virtual-polyhedra/vrml/zono-12_from_truncated_cube.wrl zono-12 from truncated cube] VRML model\n* [http://en.orion-metaphysics.com/content3/sacred-geometry-formulation-of-rhombic-polyhedron-with-132-faces-rhombhectotriadiohedron Rhombic Polyhedron with 132 Faces]\n* [https://translate.google.com/translate?hl=en&sl=auto&tl=en&u=https%3A%2F%2Fgeometryka.wordpress.com%2F2016%2F11%2F23%2Fkubus-rhombendodekaeder%2F rhombic 132-hedron within a cube]\n\n{{Polyhedra}}\n[[Category:Zonohedra]]"
    },
    {
      "title": "Rhombic hexecontahedron",
      "url": "https://en.wikipedia.org/wiki/Rhombic_hexecontahedron",
      "text": "{| class=wikitable align=\"right\" \n!bgcolor=#e7dcc3 colspan=2|Rhombic hexecontahedron\n|-\n|align=center colspan=2|[[File:Rhombic hexecontahedron.png|280px]]\n|-\n|bgcolor=#e7dcc3|Type||[[Stellation]] of [[rhombic triacontahedron]]\n|-\n|bgcolor=#e7dcc3|Vertices||62 (12+20+30)\n|-\n|bgcolor=#e7dcc3|Edges||120 (60+60)\n|-\n|bgcolor=#e7dcc3|Faces||60 golden rhombi\n|-\n|bgcolor=#e7dcc3|[[List of spherical symmetry groups|Symmetry]]||I<sub>h</sub>, [5,3], (*532)\n|-\n|bgcolor=#e7dcc3|Properties||[[Convex set#Non-convex set|non-convex]], [[zonohedron]]\n|}\nIn [[geometry]], a '''rhombic [[hexecontahedron]]''' is a [[stellation]] of the [[rhombic triacontahedron]]. It is nonconvex with 60 [[golden rhombus|golden rhombic]] faces with [[icosahedral symmetry]]. It was discovered in 1940 by Helmut Unkelbach.\n\nIt is topologically identical to the convex [[deltoidal hexecontahedron]] which has [[Kite (geometry)|kite]] faces.\n\n== Dissection==\nThe rhombic hexecontahedron can be dissected into 20 [[acute golden rhombohedra]] meeting at a central point. This gives the volume of a hexecontahedron of side length ''a'' to be <math>V = (10 + 2\\sqrt 5)a^3</math> and the area to be <math>A = (24\\sqrt 5)a^2</math>.\n:[[File:Acute golden rhombohedron.png|160px]]\n\n==Construction==\nA rhombic hexecontahedron can be constructed from a [[regular dodecahedron]], by taking its vertices, its face centers and its edge centers and scaling them in or out from the body center to different extents. Thus, if the 20 vertices of a dodecahedron are pulled out to increase the [[circumradius]] by a factor of ([[golden ratio|ϕ]]+1)/2 ≈ 1.309, the 12 face centers are pushed in to decrease the [[inradius]] to (3-ϕ)/2 ≈ 0.691 of its original value, and the 30 edge centers are left unchanged, then a rhombic hexecontahedron is formed. (The circumradius is increased by 30.9% and the inradius is decreased by the same 30.9%.) Scaling the points by different amounts results in [[deltoidal hexecontahedron|hexecontahedra with kite-shaped faces]] or other polyhedra.\n\nEvery golden rhombic face has a face center, a vertex, and two edge centers of the original dodecahedron, with the edge centers forming the short diagonal. Each edge center is connected to two vertices and two face centers. Each face center is connected to five edge centers, and each vertex is connected to three edge centers.\n\n== Stellation==\nThe ''rhombic hexecontahedron'' is one of 227 self-supporting stellations of the rhombic triacontahedron. Its stellation diagram looks like this, with the original rhombic triacontahedron faces as the central rhombus.\n:[[File:Rhombic hexecontahedron stellation diagram.png|240px]]\n\n== Related polyhedra ==\nThe [[great rhombic triacontahedron]] contains the 30 larger intersecting rhombic faces:\n:[[File:DU54 great rhombic triacontahedron.png|320px]][[File:DU54 facets.png|320px]]\n\n== In popular culture ==\nThe Rhombic hexacontahedron is used within the logo for the [[Wolfram Alpha]] answer engine, and [[Wolfram Research]], known as \"Spikey\".\n\nIn Brazilian culture, handcrafted rhombic hexecontahedra used to be made from colored fabric and cardboard, called \"giramundos\" (\"world turners\" in Portuguese) or happiness stars, sewn by mothers and given as wedding gifts to their daughters. The custom got lost with the urbanization of Brazil, though the technique for producing the handicrafts was still taught in Brazilian rural schools up until the first half of the twentieth century.<ref name=\"Giramundos\"/>\n\n== See also==\n* [[Hexecontahedron]]\n\n== References ==\n* Unkelbach, H. \"Die kantensymmetrischen, gleichkantigen Polyeder.'' Deutsche Math. 5, 306-316, 1940.\n* [[Branko Grünbaum|Grünbaum, B.]] ''A New Rhombic Hexecontahedron.'' Geombinatorics 6, 15-18, 1996. \n* [[Branko Grünbaum|Grünbaum, B.]] ''A New Rhombic Hexecontahedron—Once More.'' Geombinatorics, 6, 55-59, 1996. \n* [[Branko Grünbaum|Grünbaum, B.]] ''Still More Rhombic Hexecontahedra.'' Geombinatorics 6, 140-142, 1997. \n* [[Branko Grünbaum|Grünbaum, B.]] ''Parallelogram-Faced Isohedra with Edges in Mirror-Planes.'' Discrete Math. 221, 93-100, 2000.\n{{Reflist|refs=\n<ref name=\"Giramundos\">{{Citation | url = https://impa.br/en_US/page-noticias/artesanato-se-antecipou-a-descoberta-de-poliedro-rombico | title = Artesanato se antecipou à descoberta de poliedro | publisher = [[Instituto Nacional de Matemática Pura e Aplicada|IMPA]] | accessdate = 2019-01-08 | trans-title = Handicraft anticipated discovery of polihedron | language = Portuguese }}</ref>\n}}\n\n== External links ==\n* {{MathWorld|title=Rhombic hexecontahedron|urlname=RhombicHexecontahedron}} \n* http://www.georgehart.com/virtual-polyhedra/zonohedra-info.html\n* http://blog.wolframalpha.com/2009/05/19/whats-in-the-logo-that-which-we-call-a-rhombic-hexecontahedron/\n* [https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/15593/Bilinski_dodecahedron.pdf The Bilinski dodecahedron, and assorted parallelohedra, zonohedra, monohedra, isozonohedra and otherhedra.] [[Branko Grünbaum]]\n\n[[Category:Zonohedra]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Rhombic icosahedron",
      "url": "https://en.wikipedia.org/wiki/Rhombic_icosahedron",
      "text": "{| class=wikitable align=\"right\" \n!bgcolor=#e7dcc3 colspan=2|Rhombic icosahedron\n|-\n|align=center colspan=2|[[Image:Rhombic icosahedron.png|150px]]\n|-\n|bgcolor=#e7dcc3|Type||[[Zonohedron]]\n|-\n|bgcolor=#e7dcc3|[[Face (geometry)|Faces]]||20 [[rhombus|rhombi]]\n|-\n|bgcolor=#e7dcc3|[[Edge (geometry)|Edges]]||40\n|-\n|bgcolor=#e7dcc3|[[Vertex (geometry)|Vertices]]||22\n|-\n|bgcolor=#e7dcc3|Faces per vertex||3, 4 and 5\n|-\n|bgcolor=#e7dcc3|[[Dual polyhedron]]||Irregular-faced<BR>[[pentagonal gyrobicupola]]\n|-\n|bgcolor=#e7dcc3|[[List of spherical symmetry groups|Symmetry]]||D<sub>5d</sub>, [2<sup>+</sup>,10], (2*5)\n|-\n|bgcolor=#e7dcc3|Properties||[[convex set|convex]], [[zonohedron]]\n|}\nA '''rhombic icosahedron''' is a [[polyhedron]] shaped like an [[Oblate spheroid|oblate]] [[sphere]]. It is composed of 20 rhombic faces, of which three, four, or five meet at each vertex. It has 10 faces on the axis of symmetry with 10 rhombi following the equator. It has [[Dihedral symmetry in three dimensions|D<sub>5d</sub>]], [2<sup>+</sup>,10], (2*5) symmetry, order 20.\n\nEven though all the faces are congruent, the rhombic icosahedron is not [[face-transitive]], since one may distinguish whether a particular face is near the equator or a pole by examining the types of vertices surrounding that face.\n\n== Zonohedron==\nThe rhombic icosahedron is a [[zonohedron]] that is dual to an irregular-faced [[pentagonal gyrobicupola]]. It has 5 sets of 8 parallel edges, described as 8<sub>5</sub> [[Parallelohedron#Topological_types|belts]].\n{| class=wikitable width=320\n|[[File:Rhombic icosahedron 5-color-paralleledges.png|160px]]\n|The edges of the rhombic icosahedron exist in 5 parallel sets, seen in this wireframe orthogonal projection.\n|}\n\nThe rhombic icosahedron forms the convex hull of the vertex-first projection of a [[5-cube]] to 3 dimensions. The 32 vertices of a 5-cube map into 22 exterior vertices of the rhombic icosahedron, with the remaining 10 interior vertices forming a [[pentagonal antiprism]]. This is the same way one can obtain a [[Bilinski dodecahedron]] from a [[4-cube]] and a [[rhombic triacontahedron]] from a [[6-cube]].\n\n== Related polyhedra==\nThe rhombic icosahedron can be derived from the [[rhombic triacontahedron]] by removing 10 middle faces.\n{| class=wikitable width=320\n|[[File:Rhombic_triacontahedron_middle_colored.png|160px]]<BR>A [[rhombic triacontahedron]] as an elongated ''rhombic icosahedron''\n|[[File:Dual dodecahedron t1 H3.png|160px]]<BR>The rhombic icosahedron shares its 5-fold symmetry orthogonal projection with the [[rhombic triacontahedron]]\n|}\n\n\n== External links ==\n* {{MathWorld|title=Rhombic icosahedron|urlname=RhombicIcosahedron}} \n* http://www.georgehart.com/virtual-polyhedra/zonohedra-info.html\n** [[VRML]] Model [http://www.georgehart.com/virtual-polyhedra/vrml/rhombic_icosahedron.wrl]\n\n[[Category:Zonohedra]]\n{{Polyhedron-stub}}"
    },
    {
      "title": "K-dron",
      "url": "https://en.wikipedia.org/wiki/K-dron",
      "text": "{{notability|date=October 2018}}\n\n[[File:K-dron.png|180px|right|thumb|K-dron]]\n[[File:K-dron Polyhedral.svg|180px|thumb|A K-dron net diagram]]\nA '''k-dron''' is an '''eleventh-degree''' [[polyhedron]] discovered by [[Janusz Kapusta]] in 1985<ref>{{cite patent|\ninventor-last=Kapusta|inventor-first=Janusz J.|title=Decorative, functional element for construction and the like|\n| issue-date = Jul 21, 1987\n| country-code = US\n| patent-number = 4681481\n}}</ref>. The name k-dron comes from the word ''dron'', which in Greek means the wall, and ''k'' is the eleventh letter of the [[Latin alphabet]].\n\n== History ==\nThe shape was invented during the preparation for an exhibition by [[Janusz Kapusta|Janusza Kapusty]] and his colleague in a [[New York City|New York]] gallery. After printing the leaflets promoting the exhibition, which featured the image of two squares typed one in the other, Janusz Kapusta fell into the spatial form, on the basis of which he then made a spatial model of the solid.\n\nThe k-dron consists of a k-dron surface, which is a [[rhombus]] with attached right triangles and a square base. Two k-drons placed tops together forms a cube. Professor [[Janusz Łysko]] ([[Widener University]] in [[Pennsylvania]] ) gave the pattern features two variables that graphs the upper surface of a k-dron within the bounds of −1&nbsp;≤&nbsp;''x''&nbsp;≤&nbsp;1 and −1&nbsp;≤&nbsp;''y''&nbsp;≤&nbsp;1, namely:\n\n: <math>f(x,y)= \\frac {1}{2} \\cdot (|y-x+1|-|y-x-1|+|y+x+1|-|y+x-1|-|x-1|-|x+1|)+|y-1|</math>\n\nK-dron systems can be arranged a great many different ways, creating a great variety of light and shadow patterns. As the angle of incidence changes, new patterns are created.\n\n[[File:Koło - k-dron.jpg|180px|thumb|A monument to the K-dron in [[Koło]]]]\nIt is used for the design of façades of buildings, toys, games, jewelry, and even car hoods. There are an extreme variety of applications for this body – Janusz Kapusta described 50 applications in his book, and in April 2001 he stated he already found 168.\n\nIn 2009 the k-dron monument was erected before the building of the county seat in [[Koło]].\n\n== References ==\n{{reflist}}\n\n== External links ==\n* [http://www.k-dron.com/ A site dedicated to the k-dron figure]\n* [https://www.youtube.com/watch?v=LYzesU84nDc A film dedicated to the figure]\n\n{{Polyhedron-stub}}\n[[Category:Solids]]"
    },
    {
      "title": "Rhombicuboctahedral prism",
      "url": "https://en.wikipedia.org/wiki/Rhombicuboctahedral_prism",
      "text": "{| class=\"wikitable\" align=\"right\" style=\"margin-left:10px\" width=\"280\"\n!bgcolor=#e7dcc3 colspan=2|Rhombicuboctahedral prism\n|-\n|bgcolor=#e7dcc3|Type||[[Uniform_polychoron#Prismatic_uniform_polychora|Prismatic uniform polychoron]]\n|-\n|bgcolor=#e7dcc3|Uniform index||53\n|-\n|bgcolor=#e7dcc3|[[Schläfli symbol]]||t<sub>0,2,3</sub>{3,4,2} or rr{3,4}×{}<BR>s<sub>2,3</sub>{3,4,2} or s<sub>2</sub>{3,4}×{}\n|-\n|bgcolor=#e7dcc3|[[Coxeter diagram]]||{{CDD||node_1|3|node|4|node_1|2|node_1}}<BR>{{CDD||node_h|3|node_h|4|node_1|2|node_1}}\n|-\n|bgcolor=#e7dcc3|Cells||28 total:<BR>2 [[rhombicuboctahedron|rr{4,3}]] or [[Rhombicuboctahedron#Pyritohedral_symmetry|s<sub>2</sub>{3,4}]]<BR>8 [[triangular prism|{}x{3}]]<BR>18 [[Cube|{4,3}]]\n|-\n|bgcolor=#e7dcc3|Faces||100 total:<BR>16 [[triangle|{3}]]<BR>84 [[Square (geometry)|{4}]]\n|-\n|bgcolor=#e7dcc3|Edges||120\n|-\n|bgcolor=#e7dcc3|Vertices||48\n|-\n|bgcolor=#e7dcc3|[[Vertex figure]]||[[File:Rhombicuboctahedron prism verf.png|80px]]<BR>Trapezoidal [[Pyramid (geometry)|pyramid]]\n|-\n|bgcolor=#e7dcc3|[[Coxeter notation|Symmetry group]]||[4,3,2], order 96<BR>[3<sup>+</sup>,4,2], order 48\n|-\n|bgcolor=#e7dcc3|Properties||[[Convex polytope|convex]]\n|}\nIn [[geometry]], a '''rhombicuboctahedral prism''' is a convex [[uniform polychoron|uniform]] [[polychoron]] (four-dimensional [[polytope]]).\n\nIt is one of 18 convex [[Uniform_polychoron#Polyhedral_hyperprisms|uniform polyhedral prisms]] created by using uniform [[Prism (geometry)|prism]]s to connect pairs of [[Platonic solid]]s or [[Archimedean solid]]s in parallel [[hyperplane]]s.\n\n== Images==\n{| class=wikitable width=500\n|- align=center\n|[[File:Small rhombicuboctahedral prism net.png|250px]]<BR>[[Net (polyhedron)|Net]]\n|[[Image:Rhombicuboctahedral prism.png|250px]]<BR>[[Schlegel diagram]]<BR>One rhombicuboctahedron and triangular prisms show\n|}\n\n== Alternative names ==\n* small rhombicuboctahedral prism\n* (Small) rhombicuboctahedral dyadic prism (Norman W. Johnson) \n* Sircope (Jonathan Bowers: for small-rhombicuboctahedral prism) \n* (small) rhombicuboctahedral hyperprism\n\n== Related polytopes==\n=== Runcic snub cubic hosochoron ===\n{| class=\"wikitable\" align=\"right\" style=\"margin-left:10px\" width=\"250\"\n!bgcolor=#e7dcc3 colspan=2|Runcic snub cubic hosochoron\n|-\n|bgcolor=#e7dcc3|[[Schläfli symbol]]||s<sub>3</sub>{2,4,3}\n|-\n|bgcolor=#e7dcc3|[[Coxeter diagram]]||{{CDD||node_h|2x|node_h|4|node|3|node_1}}\n|-\n|bgcolor=#e7dcc3|Cells||16 total:<BR> 2 [[truncated tetrahedron|t{3,3}]] [[File:truncated tetrahedron.png|20px]]<BR>6 [[tetrahedron|{3,3}]] [[File:tetrahedron.png|20px]]<BR>8 [[triangular cupola|tricup]] [[File:triangular cupola.png|20px]]\n|-\n|bgcolor=#e7dcc3|Faces||52 total:<BR>32 {3}<BR>12{4}<BR>8 {6}\n|-\n|bgcolor=#e7dcc3|Edges||60\n|-\n|bgcolor=#e7dcc3|Vertices|| 24\n|-\n|bgcolor=#e7dcc3|[[Vertex figure]]||[[File:Runcic snub 243 verf.png|80px]]\n|-\n|bgcolor=#e7dcc3|[[Coxeter notation|Symmetry group]]||[4,3,2<sup>+</sup>], order 48\n|-\n|bgcolor=#e7dcc3|Properties||[[Convex polytope|convex]]\n|}\nA related polychoron is the '''runcic snub cubic hosochoron''', or '''parabidiminished [[rectified tesseract]]''' or '''truncated tetrahedral cupoliprism''', s<sub>3</sub>{2,4,3}, {{CDD|node_h|2x|node_h|4|node|3|node_1}}, from 2 [[truncated tetrahedron|truncated tetrahedra]], 6 [[tetrahedron|tetrahedra]], and 8 [[triangular cupola]]e in the gaps, for a total of 16 cells, 52 faces, 60 edges, and 24 vertices. It is [[vertex-transitive]], and equilateral, but not uniform, due to the cupolae. It has symmetry [2<sup>+</sup>,4,3], order 48.<ref>{{KlitzingPolytopes|polychora.htm|4D|tutcup}}</ref><ref>[http://www.polytope.net/hedrondude/simplesc.htm Category S1: Simple Scaliforms] Tutcup</ref><ref>http://bendwavy.org/klitzing/pdf/artConvSeg_8.pdf 4.55\ntruncated tetrahedron || inverse truncated tetrahedron</ref>\n\nIt is related to the [[16-cell]] in its s{2,4,3}, {{CDD|node_h|2x|node_h|4|node|3|node}} construction. \n\nIt can also be seen as a prismatic polytope with two parallel truncated tetrahedra in dual positions, as seen in the [[compound of two truncated tetrahedra]]. Triangular cupolae connect the triangular and hexagonal faces, and the tetrahedral connect edge-wise between.\n{| class=wikitable\n|- align=center\n|[[File:Runcic snub cubic hosochoron.png|240px]]<BR>Projection<br>(triangular cupolae hidden)\n|[[File:Truncated tetrahedral cupoliprism net.png|240px]]<BR>Net\n|}\n{{-}}\n\n== References ==\n{{reflist}}\n\n== External links ==\n* {{PolyCell | urlname = section6.html| title = 6. Convex uniform prismatic polychora - Model 53}}\n* {{KlitzingPolytopes|polychora.htm|4D uniform polytopes (polychora)| x3o4x - sircope}}\n\n[[Category:Polychora]]\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Truncated cuboctahedral prism",
      "url": "https://en.wikipedia.org/wiki/Truncated_cuboctahedral_prism",
      "text": "{| class=\"wikitable\" align=\"right\" style=\"margin-left:10px\" width=\"250\"\n!bgcolor=#e7dcc3 colspan=2|Truncated cuboctahedral prism\n|-\n|bgcolor=#ffffff align=center colspan=2|[[File:Truncated cuboctahedral prism.png|250px]]<BR>[[Schlegel diagram]]\n|-\n|bgcolor=#e7dcc3|Type||[[Uniform polychoron#Prismatic uniform polychora|Prismatic uniform polychoron]]\n|-\n|bgcolor=#e7dcc3|Uniform index||55\n|-\n|bgcolor=#e7dcc3|[[Schläfli symbol]]||t<sub>0,1,2,3</sub>{4,3,2} or tr{4,3}×{}\n|-\n|bgcolor=#e7dcc3|[[Coxeter-Dynkin diagram|Coxeter-Dynkin]]||{{CDD||node_1|3|node_1|4|node_1|2|node_1}}\n|-\n|bgcolor=#e7dcc3|Cells||28 total:<BR>2 [[File:Great rhombicuboctahedron.png|20px]] [[Truncated cuboctahedron|4.6.8]]<BR>12 [[File:Hexahedron.png|20px]] [[Cube|4.4.4]]<BR>8 [[File:Hexagonal prism.png|20px]] [[Hexagonal prism|4.4.6]]<BR>6 [[File:Octagonal prism.png|20px]] [[Octagonal prism|4.4.8]]\n|-\n|bgcolor=#e7dcc3|Faces||124 total:<BR>96 {4}<BR>16 {6}<BR>12 {8}\n|-\n|bgcolor=#e7dcc3|Edges||192\n|-\n|bgcolor=#e7dcc3|Vertices||96\n|-\n|bgcolor=#e7dcc3|Vertex figure||[[File:Truncated cuboctahedral prism verf.png|80px]]<BR>irr. [[tetrahedron]]\n|-\n|bgcolor=#e7dcc3|[[Symmetry group]]||[4,3,2], order 96\n|-\n|bgcolor=#e7dcc3|Properties||[[Convex polytope|convex]]\n|}\nIn [[geometry]], a '''truncated cuboctahedral prism''' or '''great rhombicuboctahedral prism''' is a convex [[uniform polychoron|uniform]] [[polychoron]] (four-dimensional [[polytope]]).\n\nIt is one of 18 convex [[Uniform polychoron#Polyhedral hyperprisms|uniform polyhedral prisms]] created by using uniform [[Prism (geometry)|prism]]s to connect pairs of [[Platonic solid]]s or [[Archimedean solid]]s in parallel [[hyperplane]]s.\n\n[[File:Great rhombicuboctahedral prism net.png|320px]]<BR>Net\n\n== Alternative names ==\n* Truncated-cuboctahedral dyadic prism ([[Norman Johnson (mathematician)|Norman W. Johnson]]) \n* Gircope (Jonathan Bowers: for great rhombicuboctahedral prism/hyperprism) \n* Great rhombicuboctahedral prism/hyperprism\n\n== Related polytopes ==\nA '''full snub cubic antiprism''' or '''omnisnub cubic antiprism''' can be defined as an [[Alternation (geometry)|alternation]] of an truncated cuboctahedral prism, represented by ht<sub>0,1,2,3</sub>{4,3,2}, or {{CDD|node_h|4|node_h|3|node_h|2x|node_h}}, although it cannot be constructed as a uniform polychoron. It has 76 cells: 2 [[snub cube]]s connected by 12 [[tetrahedron]]s, 6 [[square antiprism]]s, and 8 [[octahedron]]s, with 48 [[tetrahedron]]s in the alternated gaps. There are 48 vertices, 192 edges, and 220 faces (12 squares, and 16+192 triangles). It has [4,3,2]<sup>+</sup> symmetry, order 48.\n\n[[File:Snub 432 verf.png|160px]]<BR>[[Vertex figure]] for full snub cuboctahedral antiprism\n\n== External links ==\n* {{PolyCell | urlname = section6.html| title = 6. Convex uniform prismatic polychora - Model 55}}\n* {{KlitzingPolytopes|polychora.htm|4D uniform polytopes (polychora)| x3x4x x - gircope}}\n\n[[Category:Polychora]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Truncated octahedral prism",
      "url": "https://en.wikipedia.org/wiki/Truncated_octahedral_prism",
      "text": "{| class=\"wikitable\" align=\"right\" style=\"margin-left:10px\" width=\"280\"\n!bgcolor=#e7dcc3 colspan=2|Truncated octahedral prism\n|-\n|bgcolor=#e7dcc3|Type||[[Uniform_polychoron#Prismatic_uniform_4-polytopes|Prismatic uniform 4-polytope]]\n|-\n|bgcolor=#e7dcc3|Uniform index||54\n|-\n|bgcolor=#e7dcc3|[[Schläfli symbol]]||t<sub>0,1,3</sub>{3,4,2} or t{3,4}×{}<BR>t<sub>0,1,2,3</sub>{3,3,2} or tr{3,3}×{}\n|-\n|bgcolor=#e7dcc3|[[Coxeter-Dynkin diagram|Coxeter-Dynkin]]||{{CDD|node_1|3|node_1|4|node|2|node_1}}<BR>{{CDD|node_1|3|node_1|3|node_1|2|node_1}}\n|-\n|bgcolor=#e7dcc3|Cells|||16:<BR>2 [[Image:Truncated octahedron.png|20px]] [[Truncated tetrahedron|3.6.6]]<BR>6 [[Image:Hexahedron.png|20px]] [[Cube|{4,3}]]<BR>8 [[Image:Hexagonal prism.png|20px]] [[Hexagonal prism|{}x{6}]]\n|-\n|bgcolor=#e7dcc3|Faces||64:<BR>48 [[Square (geometry)|{4}]]<BR>16 [[Hexagon|{6}]] \n|-\n|bgcolor=#e7dcc3|Edges||96\n|-\n|bgcolor=#e7dcc3|Vertices||48\n|-\n|bgcolor=#e7dcc3|[[Vertex figure]]||[[File:Truncated octahedral prism verf.png|80px]]<BR>Isosceles-[[triangular pyramid]]\n|-\n|bgcolor=#e7dcc3|[[Coxeter notation|Symmetry group]]||[3,4,2], order 96<BR>[3,3,2], order 48\n|-\n|bgcolor=#e7dcc3|[[Dual polytope]]||[[Tetrakis hexahedral bipyramid]]\n|-\n|bgcolor=#e7dcc3|Properties||[[Convex polytope|convex]]\n|}\nIn 4-dimensional [[geometry]], a '''truncated octahedral prism''' or '''omnitruncated tetrahedral prism''' is a convex [[uniform 4-polytope]]. This 4-polytope has 16 [[Cell (geometry)|cell]]s (2 [[truncated octahedron|truncated octahedra]] connected by 6 [[cube]]s, 8 [[hexagonal prism]]s.) It has 64 faces (48 [[Square (geometry)|squares]] and 16 [[hexagon]]s), and 96 edges and 48 vertices.\n\nIt has two symmetry constructions, one from the [[Truncation (geometry)|truncated]] [[octahedron]], and one as an [[omnitruncation]] of the [[tetrahedron]].\n\nIt is one of 18 uniform polyhedral prisms created by using uniform [[Prism (geometry)|prism]]s to connect pairs of parallel [[Platonic solid]]s and [[Archimedean solid]]s.\n==Images==\n{| class=wikitable\n|- align=center\n|[[File:Truncated octahedral prism net.png|240px]]<BR>[[Net (polyhedron)|Net]]\n|[[Image:Truncated octahedral prism.png|240px]]<BR>[[Schlegel diagram]]\n|}\n\n\n==Alternative names==\n* Truncated octahedral dyadic prism ([[Norman Johnson (mathematician)|Norman W. Johnson]]) \n* Truncated octahedral hyperprism \n* Tope (Jonathan Bowers: for truncated octahedral prism)\n\n== Related polytopes ==\nThe '''snub tetrahedral prism''' (also called a [[icosahedral prism]]), {{CDD|node_h|3|node_h|3|node_h|2|node_1}}, sr{3,3}×{ }, is related to this polytope just like a [[snub tetrahedron]] (icosahedron), {{CDD|node_h|3|node_h|3|node_h}} is the alternation of the [[truncated octahedron]] in its tetrahedral symmetry {{CDD|node_1|3|node_1|3|node_1}}. The ''snub tetrahedral prism'' has symmetry [(3,3)<sup>+</sup>,2], order 24, although as an icosahedral prism, its full symmetry is [5,3,2], order 240.\n\nAlso related, the '''full snub tetrahedral antiprism''' or '''omnisnub tetrahedral antiprism''' is defined as an [[Alternation (geometry)|alternation]] of an omnitruncated tetrahedral prism, represented by <math>s\\left\\{\\begin{array}{l}3\\\\3\\\\2\\end{array}\\right\\}</math>  = ht<sub>0,1,2,3</sub>{3,3,2}, or {{CDD|node_h|3|node_h|3|node_h|2x|node_h}}, although it cannot be constructed as a uniform 4-polytope. It can also be seen as an '''alternated truncated octahedral prism''', {{CDD|node|4|node_h|3|node_h|2x|node_h}}. It has 2 [[icosahedron|icosahedra]] connected by 6 [[tetrahedron|tetrahedra]] and 8 [[octahedron|octahedra]], with 24 irregular [[tetrahedron|tetrahedra]] in the alternated gaps. In total it has 40 cells, 112 triangular faces, 96 edges, and 24 vertices. It has [4,(3,2)<sup>+</sup>] symmetry, order 48, and also [3,3,2]<sup>+</sup> symmetry, order 24.\n\n[[File:Snub_332_verf.png|120px]]<BR>[[Vertex figure]] for full snub tetrahedral antiprism\n\n== See also==\n*[[Truncated 16-cell]], {{CDD||node_1|3|node_1|3|node|4|node}}\n\n== External links ==\n* {{PolyCell | urlname = section6.html| title = 6. Convex uniform prismatic polychora - Model 54}}\n* {{KlitzingPolytopes|polychora.htm|4D uniform polytopes (polychora)|x x3x3x - tope}}\n\n{{Polyhedron-stub}}\n\n[[Category:Polychora]]"
    },
    {
      "title": "Truncated tetrahedral prism",
      "url": "https://en.wikipedia.org/wiki/Truncated_tetrahedral_prism",
      "text": "{{More citations needed|date=July 2014}}\n{| class=\"wikitable\" align=\"right\" style=\"margin-left:10px\" width=\"250\"\n!bgcolor=#e7dcc3 colspan=2|Truncated tetrahedral prism\n|-\n|bgcolor=#ffffff align=center colspan=2|[[Image:Truncated tetrahedral prism.png|220px]]<BR>[[Schlegel diagram]]\n|-\n|bgcolor=#e7dcc3|Type||[[Uniform polychoron#Prismatic uniform polychora|Prismatic uniform polychoron]]\n|-\n|bgcolor=#e7dcc3|Uniform index||49\n|-\n|bgcolor=#e7dcc3|[[Schläfli symbol]]||t<sub>0,1</sub>{3,3}×{}\n|-\n|bgcolor=#e7dcc3|[[Coxeter-Dynkin diagram|Coxeter-Dynkin]]||{{CDD|node_1|3|node_1|3|node|2|node_1}}\n|-\n|bgcolor=#e7dcc3|Cells|||10:<BR>2 [[Image:Truncated tetrahedron.png|20px]] [[Truncated tetrahedron|3.6.6]]<BR>4 [[Image:Triangular prism.png|20px]] [[Triangular prism|3.4.4]]<BR>4 [[Image:Hexagonal prism.png|20px]] [[Hexagonal prism|4.4.6]]\n|-\n|bgcolor=#e7dcc3|Faces||24:<BR>8 [[triangle|{3}]] + 18 [[Square (geometry)|{4}]] + 8 [[Hexagon|{6}]]\n|-\n|bgcolor=#e7dcc3|Edges||48\n|-\n|bgcolor=#e7dcc3|Vertices||24\n|-\n|bgcolor=#e7dcc3|[[Vertex figure]]||[[File:Truncated tetrahedral prism verf.png|80px]]<BR>Isosceles-[[triangular pyramid]]\n|-\n|bgcolor=#e7dcc3|[[Coxeter notation|Symmetry group]]||[3,3,2], order 48 \n|-\n|bgcolor=#e7dcc3|Properties||[[Convex polytope|convex]]\n|}\nIn [[geometry]], a '''truncated tetrahedral prism''' is a convex [[uniform polychoron|uniform]] [[polychoron]] (four-dimensional polytope). This polychoron has 10 [[polyhedron|polyhedral]] cells: 2 [[truncated tetrahedron|truncated tetrahedra]] connected by 4 [[triangular prism]]s and 4 [[hexagonal prism]]s. It has 24 faces: 8 triangular, 18 square, and 8 hexagons. It has 48 edges and 24 vertices.\n\nIt is one of 18 uniform polyhedral prisms created by using uniform [[Prism (geometry)|prism]]s to connect pairs of parallel [[Platonic solid]]s and [[Archimedean solid]]s.\n\n[[File:Truncated tetrahedral prism net.png|240px]]<BR>[[Net (polyhedron)|Net]]\n\n==Alternative names==\n# Truncated-tetrahedral dyadic prism ([[Norman Johnson (mathematician)|Norman W. Johnson]]) \n# Tuttip (Jonathan Bowers: for truncated-tetrahedral prism) \n# Truncated tetrahedral hyperprism\n\n== External links ==\n* {{PolyCell | urlname = section6.html| title = 6. Convex uniform prismatic polychora - Model 49}}\n* {{KlitzingPolytopes|polychora.htm|4D uniform polytopes (polychora)|x x3x3o - tuttip}}\n\n[[Category:Polychora]]\n\n\n{{Polyhedron-stub}}"
    },
    {
      "title": "Metaheuristic",
      "url": "https://en.wikipedia.org/wiki/Metaheuristic",
      "text": "{{Use American English|date=January 2019}}{{Short desc|Optimization technique}}In [[computer science]] and [[mathematical optimization]], a '''metaheuristic''' is a higher-level [[procedure (computer science)|procedure]] or [[Heuristic (computer science)|heuristic]] designed to find, generate, or select a heuristic (partial [[search algorithm]]) that may provide a sufficiently good solution to an [[optimization problem]], especially with incomplete or imperfect information or limited computation capacity.<ref name=\"Bala2015\" /><ref name=\"Bianchi2009\" /> Metaheuristics sample a set of solutions which is too large to be completely sampled. Metaheuristics may make few assumptions about the optimization problem being solved, and so they may be usable for a variety of problems.<ref name=\"blum03metaheuristics\" />\n\nCompared to [[optimization algorithm]]s and [[iterative method]]s, metaheuristics do not guarantee that a [[global optimum|globally optimal solution]] can be found on some class of problems.<ref name=blum03metaheuristics /> Many metaheuristics implement some form of [[stochastic optimization]], so that the solution found is dependent on the set of [[random variable]]s generated.<ref name=Bianchi2009 /> In [[combinatorial optimization]], by searching over a large set of [[feasible solution]]s, metaheuristics can often find good solutions with less computational effort than optimization algorithms, iterative methods, or simple heuristics.<ref name=blum03metaheuristics /> As such, they are useful  approaches for optimization problems.<ref name=Bianchi2009 /> Several books and survey papers have been published on the subject.<ref name=Bianchi2009 /><ref name=blum03metaheuristics/><ref name=goldberg89genetic/><ref name=glover03handbook/><ref name=talbi09metaheuristics/>\n\nMost literature on metaheuristics is experimental in nature, describing empirical results based on [[computer experiment]]s with the algorithms. But some formal theoretical results are also available, often on [[convergence (mathematics)|convergence]] and the possibility of finding the global optimum.<ref name=blum03metaheuristics /> Many metaheuristic methods have been published with claims of novelty and practical efficacy. While the field also features high-quality research, many of the publications have been of poor quality; flaws include vagueness, lack of conceptual elaboration, poor experiments, and ignorance of previous literature.<ref name=\"Sörensen2013\">{{cite journal|first=Kenneth|last=Sörensen|title=Metaheuristics—the metaphor exposed|journal=[[International Transactions in Operational Research]]|volume=22|pages=3–18|doi=10.1111/itor.12001|url=http://antor.ua.ac.be/system/files/mme.pdf|deadurl=yes|archiveurl=https://web.archive.org/web/20131102075645/http://antor.ua.ac.be/system/files/mme.pdf|archivedate=2013-11-02|df=|year=2015|citeseerx=10.1.1.470.3422}}</ref>\n\n==Properties==\n\nThese are properties that characterize most metaheuristics:<ref name=\"blum03metaheuristics\" />\n\n* Metaheuristics are strategies that guide the search process.\n* The goal is to efficiently explore the search space in order to find near–optimal solutions.\n* Techniques which constitute metaheuristic algorithms range from simple local search procedures to complex learning processes.\n* Metaheuristic algorithms are approximate and usually non-deterministic.\n* Metaheuristics are not problem-specific.\n\n== Classification ==\n[[Image:Metaheuristics classification.svg|thumb|Euler diagram of the different classifications of metaheuristics.<ref name=nojhan07>[http://metah.nojhan.net/post/2007/10/12/Classification-of-metaheuristics Classification of metaheuristics]</ref>]]\n\nThere are a wide variety of metaheuristics<ref name=Bianchi2009 /> and a number of properties with respect to which to classify them.<ref name=blum03metaheuristics />\n\n=== Local search vs. global search ===\nOne approach is to characterize the type of search strategy.<ref name=\"blum03metaheuristics\" /> One type of search strategy is an improvement on simple local search algorithms. A well known local search algorithm is the [[hill climbing]] method which is used to find local optimums. However, hill climbing does not guarantee finding global optimum solutions.\n\nMany metaheuristic ideas were proposed to improve local search heuristic in order to find better solutions. Such metaheuristics include [[simulated annealing]], [[tabu search]], [[iterated local search]], [[Variable Neighborhood Search|variable neighborhood search]], and [[Greedy randomized adaptive search procedure|GRASP]].<ref name=\"blum03metaheuristics\" /> These metaheuristics can both be classified as local search-based or global search metaheuristics.\n\nOther global search metaheuristic that are not local search-based are usually population-based metaheuristics. Such metaheuristics include [[ant colony optimization]], [[evolutionary computation]], [[particle swarm optimization]], and [[genetic algorithm]]s.<ref name=\"blum03metaheuristics\" />\n\n=== Single-solution vs. population-based ===\nAnother classification dimension is single solution vs population-based searches.<ref name=\"blum03metaheuristics\" /><ref name=\"talbi09metaheuristics\" /> Single solution approaches focus on modifying and improving a single candidate solution; single solution metaheuristics include [[simulated annealing]], [[iterated local search]], [[Variable Neighborhood Search|variable neighborhood search]], and [[Guided Local Search|guided local search]].<ref name=\"talbi09metaheuristics\" /> Population-based approaches maintain and improve multiple candidate solutions, often using population characteristics to guide the search; population based metaheuristics include [[evolutionary computation]], [[genetic algorithms]], and [[particle swarm optimization]].<ref name=\"talbi09metaheuristics\" /> Another category of metaheuristics  is [[Swarm intelligence]] which is a collective behavior of decentralized, self-organized agents in a population or swarm. [[Ant colony optimization]],<ref name=\"M. Dorigo, Optimization, Learning and Natural Algorithms\">M. Dorigo, ''Optimization, Learning and Natural Algorithms'', PhD thesis, Politecnico di Milano, Italie, 1992.</ref> [[particle swarm optimization]],<ref name=\"talbi09metaheuristics\" /> [[social cognitive optimization]], [[Harris hawks optimization]],<ref name=\"HeidariMirjalili2019\">{{cite journal|last1=Heidari|first1=Ali Asghar|last2=Mirjalili|first2=Seyedali|last3=Faris|first3=Hossam|last4=Aljarah|first4=Ibrahim|last5=Mafarja|first5=Majdi|last6=Chen|first6=Huiling|title=Harris hawks optimization: Algorithm and applications|journal=Future Generation Computer Systems|volume=97|year=2019|pages=849–872|issn=0167-739X|doi=10.1016/j.future.2019.02.028}}</ref> penguins search optimization algorithm, and [[Artificial bee colony algorithm|artificial bee colony]] <ref>{{cite journal | last1 = Karaboga | first1 = Dervis | year = 2010 | title = Artificial bee colony algorithm | journal = Scholarpedia | volume = 5 | issue = 3| page = 6915 | doi=10.4249/scholarpedia.6915| bibcode = 2010SchpJ...5.6915K }}</ref> algorithms are examples of this category.\n\n=== Hybridization and memetic algorithms ===\nA hybrid metaheuristic is one which combines a metaheuristic with other optimization approaches, such as algorithms from [[mathematical programming]], [[constraint programming]], and [[machine learning]]. Both components of a hybrid metaheuristic may run concurrently and exchange information to guide the search.\n\nOn the other hand, [[Memetic algorithm]]s<ref name=\"moscato89evolution\" /> represent the synergy of evolutionary or any population-based approach with separate individual learning or local improvement procedures for problem search. An example of memetic algorithm is the use of a local search algorithm instead of a basic mutation operator in evolutionary algorithms.\n\n=== Parallel metaheuristics ===\nA [[parallel metaheuristic]] is one which uses the techniques of [[parallel programming]] to run multiple metaheuristic searches in parallel; these may range from simple [[distributed computing|distributed]] schemes to concurrent search runs that interact to improve the overall solution.\n\n=== Nature-inspired metaheuristics ===\n{{main|Swarm intelligence|List of metaphor-inspired metaheuristics}}\nA very active area of research is the design of nature-inspired metaheuristics. Many recent metaheuristics, especially evolutionary computation-based algorithms, are inspired by natural systems. Nature acts as a source of concepts, mechanisms and principles for designing of artificial computing systems to deal with complex computational problems.<ref>{{Cite journal|last=Harifi|first=Sasan|last2=Khalilian|first2=Madjid|last3=Mohammadzadeh|first3=Javad|last4=Ebrahimnejad|first4=Sadoullah|date=2019-02-25|title=Emperor Penguins Colony: a new metaheuristic algorithm for optimization|journal=Evolutionary Intelligence|volume=12|issue=2|pages=211–226|language=en|doi=10.1007/s12065-019-00212-x|issn=1864-5917}}</ref> Such metaheuristics include [[simulated annealing]], [[evolutionary algorithms]], [[ant colony optimization]] and [[particle swarm optimization]]. A large number of more recent metaphor-inspired metaheuristics have started to [[List of metaphor-inspired metaheuristics#Criticism|attract criticism in the research community]] for hiding their lack of novelty behind an elaborate metaphor.\n\n== Applications ==\n\nMetaheuristics are used for [[combinatorial optimization]] in which an optimal solution is sought over a [[discrete mathematics|discrete]] search-space. An example problem is the [[travelling salesman problem]] where the search-space of candidate solutions grows faster than [[exponential growth|exponentially]] as the size of the problem increases, which makes an [[exhaustive search]] for the optimal solution infeasible. Additionally, multidimensional combinatorial problems, including most design problems in [[engineering]]<ref>Tomoiagă B, Chindriş M, Sumper A, Sudria-Andreu A, Villafafila-Robles R. [http://www.mdpi.com/1996-1073/6/3/1439/pdf Pareto Optimal Reconfiguration of Power Distribution Systems Using a Genetic Algorithm Based on NSGA-II. ] Energies. 2013; 6(3):1439–1455.</ref><ref>{{Cite journal|title = Swarm intelligence and gravitational search algorithm for multi-objective optimization of synthesis gas production|journal = Applied Energy|date = 2013-03-01|pages = 368–374|volume = 103|doi = 10.1016/j.apenergy.2012.09.059|first = T.|last = Ganesan|first2 = I.|last2 = Elamvazuthi|first3 = Ku Zilati|last3 = Ku Shaari|first4 = P.|last4 = Vasant}}</ref><ref>{{Cite book|title = Evolutionary normal-boundary intersection (ENBI) method for multi-objective optimization of green sand mould system|journal = 2011 IEEE International Conference on Control System, Computing and Engineering (ICCSCE)|date = 2011-11-01|pages = 86–91|doi = 10.1109/ICCSCE.2011.6190501|first = T.|last = Ganesan|first2 = I.|last2 = Elamvazuthi|first3 = P.|last3 = Vasant|isbn = 978-1-4577-1642-3}}</ref> such as form-finding and behavior-finding, suffer from the [[curse of dimensionality]], which also makes them infeasible for exhaustive search or [[analytical method]]s. Metaheuristics are also widely used for jobshop scheduling and job selection problems.<ref>Mohammad Hossein Zarei, Mehdi Davvari, Farhad Kolahan, and Kuan Yew Wong, “[http://growingscience.com/ijiec/Vol7/IJIEC_2015_24.pdf Simultaneous Selection and Scheduling with Sequence-Dependent Setup Times, Lateness Penalties, and Machine Availability Constraint: Heuristic Approaches]”, International Journal of Industrial Engineering Computations, vol. 7 no. 1, pp. 147–160, 2016. DOI: 10.5267/j.ijiec.2015.7.001</ref> Popular metaheuristics for combinatorial problems include [[simulated annealing]] by Kirkpatrick et al.,<ref name=kirkpatrick83optimization/> [[genetic algorithms]] by Holland et al.,<ref name=holland75adaptation/> scatter search<ref name=glover77scattersearch/> and [[tabu search]]<ref name=glover86future/> by Glover. Literature review on metaheuristic optimization,<ref>X. S. Yang, Metaheuristic optimization, Scholarpedia, 6(8):11472 (2011).</ref>\nsuggested that it was Fred Glover who coined the word metaheuristics.<ref>Glover F., (1986). [http://leeds-faculty.colorado.edu/glover/fred%20pubs/174%20-%20Future%20Paths%20for%20Integer%20Programming%20TS.pdf Future paths for integer programming and links to artificial intelligence], Computers and Operations Research, 13, 533–549 (1986).</ref>\n\n== Contributions ==\n<!-- PLEASE ONLY ADD THE MOST SIGNIFICANT CONTRIBUTIONS!\n     Entries that are too recent will be removed. Entries that do no have an article will be removed.\n     Articles that do not establish the significance of a particular algorithm (as measured by substantial coverage in secondary and tertiary sources) will be deleted.\n -->\n\nMany different metaheuristics are in existence and new variants are continually being proposed. Some of the most significant contributions to the field are:\n\n* 1952: Robbins and Monro work on stochastic optimization methods.<ref name=robbins52stochastic/>\n* 1954: Barricelli carry out the first simulations of the [[evolution]] process and use them on general optimization problems.<ref name=barricelli54esempi/>\n* 1963: Rastrigin proposes [[random search]].<ref name=rastrigin63convergence/>\n* 1965: Matyas proposes [[random optimization]].<ref name=matyas65random/>\n* 1965: [[John Nelder|Nelder]] and Mead propose a [[Nelder–Mead method|simplex heuristic]], which was shown by [[Michael J. D. Powell|Powell]] to converge to non-stationary points on some problems.<ref name=nelder65simplex/>\n* 1965: [[Ingo Rechenberg]] discovers the first [[Evolution Strategies]] algorithm.<ref name=rechenberg65ES/>\n* 1966: [[Lawrence J. Fogel|Fogel]] et al. propose [[evolutionary programming]].<ref name=fogel66artificial/>\n* 1970: Hastings proposes the [[Metropolis–Hastings algorithm]].<ref name=hastings70monte/>\n* 1970: Cavicchio proposes adaptation of control parameters for an optimizer.<ref name=cavicchio70adaptive/>\n* 1970: Kernighan and Lin propose a graph partitioning method, related to variable-depth search and [[tabu search|prohibition-based (tabu) search]].<ref name=kernighan1970efficient/>\n* 1975: [[John Henry Holland|Holland]] proposes the [[genetic algorithm]].<ref name=holland75adaptation/>\n* 1977: [[Fred W. Glover|Glover]] proposes scatter search.<ref name=glover77scattersearch/>\n* 1978: Mercer and Sampson propose a [[meta-optimization|metaplan]] for tuning an optimizer's parameters by using another optimizer.<ref name=mercer78adaptive/>\n* 1980: Smith describes [[genetic programming]].<ref name=smith80learning/>\n* 1983: Kirkpatrick et al. propose [[simulated annealing]].<ref name=kirkpatrick83optimization/>\n* 1986: [[Fred W. Glover|Glover]] proposes [[tabu search]], first mention of the term ''metaheuristic''.<ref name=glover86future/>\n* 1989: Moscato proposes [[memetic algorithms]].<ref name=moscato89evolution/>\n* 1992: [[Marco Dorigo|Dorigo]] introduces [[ant colony optimization]] in his Phd Thesis.<ref name=\"M. Dorigo, Optimization, Learning and Natural Algorithms\"/>\n* 1995: Wolpert and Macready prove the [[No free lunch in search and optimization|no free lunch]] theorems.<ref name=wolpert95nofreelunch/><ref name=\"Igel2003\" /><ref name=Auger2010/><ref name=Droste2002/>\n\n== See also ==\n<!-- Please don't add a whole list of optimization algorithms, the categories serve that purpose. -->\n<!-- 27/3/11 Updated with more meaningful category organisation – I have tried to keep the list as brief as possible, relying on sub-pages for further breakdown of categories. Please try to maintain this spirit on edits. -->\n\n* [[Stochastic search]]\n* [[Meta-optimization]]\n* [[Matheuristics]]\n* [[Hyper-heuristics]]\n* [[Swarm intelligence]]\n* [[Genetic algorithms]]\n* [[Simulated annealing]]\n* [[Workforce modeling]]\n\n== References ==\n<!-- {{reflist}} -->\n<!-- Please provide complete references to journal / conference papers, tech reports, msc/phd theses, etc. and make sure the reference format is correct. Only include major research contributions on this page. Only add a reference when you use it in a good description in the main article. -->\n{{reflist|2|refs=\n\n<ref name=Bianchi2009>{{cite journal|last=Bianchi|first=Leonora|author2=Marco Dorigo |author3=Luca Maria Gambardella |author4=Walter J. Gutjahr |title=A survey on metaheuristics for stochastic combinatorial optimization|journal=Natural Computing|year=2009|volume=8|issue=2|pages=239–287|doi=10.1007/s11047-008-9098-4|url=http://doc.rero.ch/record/319945/files/11047_2008_Article_9098.pdf}}</ref>\n<ref name=Bala2015>\n{{cite journal\n  | title=Stellar-Mass Black Hole Optimization for Biclustering Microarray Gene Expression Data\n  |author1=R. Balamurugan |author2=A.M. Natarajan|author3=K. Premalatha| journal=Applied Artificial Intelligence an International Journal\n  | volume=29\n  | number=4\n  | pages=353–381\n  | year=2015\n  |doi=10.1080/08839514.2015.1016391 }}</ref>\n<ref name=\"Droste2002\">{{cite journal|author1=Stefan Droste |author2=Thomas Jansen |author3=Ingo Wegener | title=Optimization with Randomized Search Heuristics – The (A)NFL Theorem, Realistic Scenarios, and Difficult Functions| journal=Theoretical Computer Science| year=2002| volume=287| number=1| pages=131–144| doi=10.1016/s0304-3975(02)00094-4|citeseerx=10.1.1.35.5850 }}</ref>\n\n<ref name=\"Igel2003\">{{cite journal| author=Igel, Christian, Toussaint, Marc| title=On classes of functions for which No Free Lunch results hold| journal=Information Processing Letters|date=Jun 2003| volume=86| number=6| pages=317–321| doi=10.1016/S0020-0190(03)00222-9|issn=0020-0190| arxiv=cs/0108011}}</ref>\n\n<ref name=\"Auger2010\">{{cite journal| author=Auger, Anne, Teytaud, Olivier| title=Continuous Lunches Are Free Plus the Design of Optimal Optimization Algorithms|journal=Algorithmica| year=2010| volume=57| issue=1| pages=121–146| doi=10.1007/s00453-008-9244-5|issn=0178-4617| citeseerx=10.1.1.186.6007}}</ref>\n\n<ref name=wolpert95nofreelunch>\n{{Cite journal\n|last1=Wolpert\n|first1=D.H.\n|last2=Macready\n|first2=W.G.\n|title=No free lunch theorems for search\n|journal=Technical Report SFI-TR-95-02-010\n|publisher=Santa Fe Institute\n|year=1995\n|url=https://pdfs.semanticscholar.org/8bdf/dc2c2777b395c086810c03a8cdeccc55c4db.pdf\n}}\n</ref>\n\n<ref name=kernighan1970efficient>\n{{cite journal\n|title=An efficient heuristic procedure for partitioning graphs\n|author1=Kernighan, B.W. |author2=Lin, S. |journal=Bell System Technical Journal\n|volume=49\n|issue=2\n|pages=291–307\n|year=1970\n|doi=10.1002/j.1538-7305.1970.tb01770.x\n}}\n</ref>\n\n<ref name=talbi09metaheuristics>\n{{cite book\n|title=Metaheuristics: from design to implementation\n|last1=Talbi\n|first1=E-G.\n|year=2009\n|publisher=Wiley\n|isbn=978-0-470-27858-1\n}}\n</ref>\n\n<ref name=glover03handbook>\n{{cite book\n|title=Handbook of metaheuristics\n|last1=Glover\n|first1=F.\n|last2=Kochenberger\n|first2=G.A.\n|year=2003\n|publisher=Springer, International Series in Operations Research & Management Science\n|volume=57\n|isbn=978-1-4020-7263-5\n}}\n</ref>\n\n<ref name=glover77scattersearch>\n{{cite journal\n|last1=Glover\n|first1=Fred\n|title=Heuristics for Integer programming Using Surrogate Constraints\n|journal=Decision Sciences\n|year=1977\n|pages=156–166\n|volume=8\n|issue=1\n|doi=10.1111/j.1540-5915.1977.tb01074.x\n|citeseerx=10.1.1.302.4071\n}}\n</ref>\n\n<ref name=glover86future>\n{{cite journal\n|doi=10.1016/0305-0548(86)90048-1\n|last1=Glover\n|first1=F.\n|title=Future Paths for Integer Programming and Links to Artificial Intelligence\n|journal=Computers and Operations Research\n|year=1986\n|pages=533–549\n|volume=13\n|issue=5\n}}\n</ref>\n\n<ref name=blum03metaheuristics>\n{{cite journal\n|title=Metaheuristics in combinatorial optimization: Overview and conceptual comparison\n|last1=Blum\n|first1=C.\n|last2=Roli\n|first2=A.\n|year=2003\n|publisher=ACM Computing Surveys\n|volume=35\n|pages=268–308\n|issue=3\n|url=https://www.researchgate.net/publication/221900771\n}}\n</ref>\n\n<ref name=holland75adaptation>\n{{cite book\n|title=Adaptation in Natural and Artificial Systems\n|last1=Holland\n|first1=J.H.\n|year=1975\n|publisher=University of Michigan Press\n|isbn=978-0-262-08213-6\n}}\n</ref>\n\n<ref name=kirkpatrick83optimization>\n{{cite journal\n|last1=Kirkpatrick\n|first1=S.\n|last2=Gelatt Jr.\n|first2=C.D.\n|last3=Vecchi\n|first3=M.P.\n|title=Optimization by Simulated Annealing\n|journal=Science\n|volume=220\n|year=1983\n|pages=671–680\n|issue=4598\n|pmid=17813860\n|doi=10.1126/science.220.4598.671\n|bibcode=1983Sci...220..671K\n|citeseerx=10.1.1.123.7607\n}}\n</ref>\n\n<ref name=nelder65simplex>\n{{cite journal\n|last1=Nelder\n|first1=J.A.\n|last2=Mead\n|first2=R.\n|title=A simplex method for function minimization\n|journal=Computer Journal\n|year=1965\n|pages=308–313\n|volume=7\n|issue=4\n|doi=10.1093/comjnl/7.4.308\n}}\n</ref>\n\n<ref name=robbins52stochastic>\n{{cite journal\n|doi=10.1214/aoms/1177729586\n|last1=Robbins\n|first1=H.\n|last2=Monro\n|first2=S.\n|title=A Stochastic Approximation Method\n|journal=Annals of Mathematical Statistics\n|year=1951\n|pages=400–407\n|issue=3\n|volume=22\n}}\n</ref>\n\n<ref name=barricelli54esempi>\n{{cite journal\n|last1=Barricelli\n|first1=N.A.\n|title=Esempi numerici di processi di evoluzione\n|journal=Methodos\n|year=1954\n|pages=45–68\n}}\n</ref>\n\n<ref name=rastrigin63convergence>\n{{cite journal\n|last=Rastrigin\n|first=L.A.\n|title=The convergence of the random search method in the extremal control of a many parameter system\n|journal=Automation and Remote Control\n|year=1963\n|volume=24\n|pages=1337–1342\n|issue=10\n}}\n</ref>\n\n<ref name=matyas65random>\n{{cite journal\n|last=Matyas\n|first=J.\n|title=Random optimization\n|journal=Automation and Remote Control\n|year=1965\n|volume=26\n|pages=246–253\n|issue=2\n|url=http://www.mathnet.ru/eng/at11288\n}}\n</ref>\n\n<ref name=fogel66artificial>\n{{cite book\n|title=Artificial Intelligence through Simulated Evolution\n|last1=Fogel\n|first1=L.\n|last2=Owens\n|first2=A.J.\n|last3=Walsh\n|first3=M.J.\n|year=1966\n|publisher=Wiley\n|isbn=978-0-471-26516-0\n}}\n</ref>\n\n<ref name=hastings70monte>\n{{cite journal\n|doi=10.1093/biomet/57.1.97\n|last1=Hastings\n|first1=W.K.\n|title=Monte Carlo Sampling Methods Using Markov Chains and Their Applications\n|journal=Biometrika\n|year=1970\n|pages=97–109\n|volume=57\n|issue=1\n|bibcode=1970Bimka..57...97H\n}}\n</ref>\n\n<ref name=cavicchio70adaptive>\n{{Cite journal\n|last1=Cavicchio\n|first1=D.J.\n|hdl=2027.42/4042 \n|title=Adaptive search using simulated evolution\n|journal=Technical Report \n|publisher=University of Michigan, Computer and Communication Sciences Department\n|year=1970\n}}\n</ref>\n\n<ref name=mercer78adaptive>\n{{cite journal\n|last=Mercer\n|first=R.E.\n|author2=Sampson, J.R.\n|title=Adaptive search using a reproductive metaplan\n|journal=Kybernetes\n|year=1978\n|volume=7\n|issue=3\n|pages=215&ndash;228\n|doi=10.1108/eb005486\n}}\n</ref>\n\n<ref name=goldberg89genetic>\n{{cite book\n|title=Genetic Algorithms in Search, Optimization and Machine Learning\n|last1=Goldberg\n|first1=D.E.\n|year=1989\n|publisher=Kluwer Academic Publishers\n|isbn=978-0-201-15767-3\n}}\n</ref>\n\n<ref name=smith80learning>\n{{cite book\n|type=PhD Thesis\n|title=A Learning System Based on Genetic Adaptive Algorithms\n|last=Smith\n|first=S.F.\n|year=1980\n|publisher=University of Pittsburgh\n|url=https://dl.acm.org/citation.cfm?id=909835\n}}\n</ref>\n\n<ref name=rechenberg65ES>\n{{cite journal\n|last=Rechenberg\n|first=Ingo\n|title=Cybernetic Solution Path of an Experimental Problem\n|journal=Royal Aircraft Establishment, Library Translation\n|year=1965\n}}\n</ref>\n\n<ref name=moscato89evolution>{{cite journal|last=Moscato|first=P.|year=1989|title=On Evolution, Search, Optimization, Genetic Algorithms and Martial Arts: Towards Memetic Algorithms|journal=Caltech Concurrent Computation Program|volume=|issue=report 826|url=https://www.researchgate.net/publication/2354457}}</ref>\n}}\n\n== Further reading ==\n* {{cite book|first1=Kenneth|last1=Sörensen|first2=Marc|last2=Sevaux|first3=Fred|last3=Glover|editor-last1=Martí|editor-first1=Rafael|editor-last2=Panos|editor-first2=Pardalos|editor-last3=Resende|editor-first3=Mauricio|isbn=978-3-319-07123-7|title=Handbook of Heuristics|chapter=A History of Metaheuristics|publisher=Springer|chapter-url=http://leeds-faculty.colorado.edu/glover/468%20-%20A%20History%20of%20Metaheuristics%20w%20Sorensen%20%26%20Sevaux.pdf|date=2017-01-16}}\n\n== External links ==\n<!-- Please don't add software-libraries here! -->\n*{{scholarpedia|title=Metaheuristics|urlname=Metaheuristics|curator=[[Fred W. Glover|Fred Glover]] and Kenneth Sörensen}} \n*[http://www.metaheuristics.eu EU/ME] forum for researchers in the field.\n\n{{Optimization algorithms|heuristic}}\n\n[[Category:Metaheuristics| ]]"
    },
    {
      "title": "EU/ME, the metaheuristics community",
      "url": "https://en.wikipedia.org/wiki/EU%2FME%2C_the_metaheuristics_community",
      "text": "{{Multiple issues|\n{{refimprove|date=November 2016}}{{notability|Organizations|date=November 2016}}}}\n\n{{Infobox organization\n| name = EWG EU/ME, EURO Working Group on Metaheuristics \n| image = Logo-eume.png\n| formation     = 2000\n| status        = Working group\n| purpose       = A platform to share information on optimization using metaheuristics\n| region        = Europe\n| parent_organization = [[Association of European Operational Research Societies]] \n| website       = {{url|http://www.metaheuristics.eu/}}\n}}\n\n'''EWG EU/ME''', the '''EURO Working Group on Metaheuristics''', formerly referred to as '''EU/ME – the metaheuristics community''', is a [[working group]] the main purpose of which is to provide a platform for communication among researchers in the field of [[metaheuristic]] [[Mathematical optimization|optimization]], practitioners interested in applying metaheuristic optimization techniques in practice, developers of [[software|optimization software]], and the general public.\n\nEU/ME is a EURO Working Group, officially sanctioned and financially supported by EURO, the [[Association of European Operational Research Societies]].<ref name=\"euro\"/>\n\n== History ==\nThe Group was founded (under the name EU/ME – EUropean chapter on MEtaheuristics) in 2000 by Marc Sevaux, Kenneth Sörensen and Christelle Wynants, following the 2000 EURO Winter Institute on metaheuristics for combinatorial optimization held in Lac Noir, Switzerland.<ref>Hertz, Alain, and Marino Widmer. \"Guidelines for the use of meta-heuristics in combinatorial optimization.\" ''European Journal of Operational Research'' 151.2 (2003): 247–252.</ref> In 2001, the group received its status as official EURO working group. In that same year, the EU/ME website (the main tool for communication among EU/ME members) was created.\n\nIn 2010, the name was changed to EU/ME – the metaheuristics community. The name was changed again (to EWG EU/ME – EURO Working Group on Metaheuristics) in 2015 following a decision of EURO to harmonize the names of its working groups.\n[[File:Logo-euro.png|alt=EURO, the Association of European Operational Research Societies|thumb|[[Association of European Operational Research Societies|EURO]], the umbrella association to which EURO belongs]]\nThe number of EU/ME members has been steadily increasing, from about 500 in 2001, and 1000 in 2004 to about 1860 now.<ref name=\"history\"/>\n\nIn 2014, a special section on [[Variable Neighborhood Search]] was created.<ref name=\"euro\"/>\n\n== Governance ==\nThe group is managed by 3 Coordinators and an Advisory Board of 3 members. The current coordinators are Andreas Reinholz, Marc Sevaux and Kenneth Sörensen.\n\nThe special section on [[Variable Neighborhood Search]] has its own board (currently Abraham Duarte and Nenad Mladenovic).\n\n== Membership ==\nMembership of EU/ME is free and open to anyone interested in metaheuristic optimization, either in the development of metaheuristics or in the use of metaheuristics to solve optimization problems. Membership of EU/ME consists largely of academic researchers, but the group has a limited number of industrial members from companies such as [[IBM]], [[Thales Group]], [[France Telecom]], and [[Bombardier Inc]].\n\nCurrently (2016), the group has about 1,865 members from 85 countries. Members of EU/ME include many notable authorities in the field of metaheuristics, such as [[Fred W. Glover]] (a supporting member since 2000),<ref>{{cite web |title=Fred Glover|url=http://uahost.uantwerpen.be/eume/index.php?option=com_comprofiler&task=userprofile&user=99&Itemid=59}}</ref> and many others.<ref>{{cite web |title=EU/MEmbers|url=http://uahost.uantwerpen.be/eume/index.php?option=com_comprofiler&task=userslist&Itemid=60}}</ref> In terms of membership, EU/ME is the largest platform for researchers on metaheuristics and also the largest EURO working group. Many researchers in the group are active in the field of [[multi-objective optimization]].<ref>Coello, Carlos A. Coello, Gary B. Lamont, and David A. Van Veldhuizen. ''Evolutionary algorithms for solving multi-objective problems''. Vol. 5. New York: Springer, 2007, p. 482.</ref>\n\n== Conferences ==\n\nEU/ME holds conferences on a yearly basis on a specific topic. The conferences are always co-organized with a local research group.\nPast conferences are:\n\nEU/MEeting 2001 with UK Local Search Group (London, UK)\n\nEU/MEeting 2002 on Multi-Objective Metaheuristics (Paris, France)\n\nEU/MEeting 2003 on Real-Life Applications of Metaheuristics (Antwerp, Belgium)\n\nEU/MEeting 2004 on Design and Evaluation of Advanced Hybrid Meta-Heuristics (Nottingham, UK)\n\nEU/MEeting 2005 on Metaheuristics and Large Scale Optimization (Vilnius Lithuania)\n\nEU/MEeting 2006 on Combination of Metaheuristics and LS with Constraint Programming techniques (Nantes, France)\n\nEU/MEeting 2006 on Adaptive, Self-adaptive and Multi-level Metaheuristics (Málaga, Spain)\n\nEU/MEeting 2007 on Applications of Metaheuristics in the Service Industry (Stuttgart, Germany) Proceedings from this meeting can be found here.\n\nEU/MEeting 2008 on Metaheuristics in Logistics and Routing, in Troyes, France.\n\nEU/MEeting 2009 \"Discussing the future\" in Porto, Portugal.\n\nEU/MEeting 2010 on the 10th anniversary of the metaheuristic community, in Lorient, France.\n\nEU/MEeting 2011 \"Client-centered Logistics and International Aid\", Vienna, Austria.\n\nEU/MEeting 2012 \"Metaheuristics for global challenges\", Copenhagen, Denmark.\n\nEU/MEeting 2013 \"Metaheuristics for all\", Hamburg, Germany.\n\nEU/MEeting 2014 \"Metaheuristics and Engineering\", Istanbul, Turkey.<ref>{{cite web |title=EU/MEeting 2014 \"Metaheuristics and Engineering\"|url=http://mh.bilecik.edu.tr/IcerikDetay.aspx?No=38}}</ref>\n\nEU/MEeting 2015 \"Metaheuristics Applications\", Madrid, Spain.<ref>{{cite web |title=EU/MEeting 2015 \"Metaheuristics Applications\"|url=https://eume15.sciencesconf.org/}}</ref>\n\nEU/MEeting 2016 \"Design and Analysis of Metaheuristics\", Antwerp, Belgium.<ref>{{cite web |title=EU/MEeting 2016 \"Design and Analysis of Metaheuristics\"|url=http://www.eume2016.be/}}</ref>\n\nAdditionally, the Variable Neighborhood Search conference series is now also organized under EU/ME flag (by the EU/ME section on Variable Neighborhood Search).<ref>{{cite web |title=4th International Conference on Variable Neighborhood Search|url=http://www.vnsconference2016.com/home}}</ref>\n\n== Publications ==\n\nThe group has no newsletter but instead use a linkedIn group to distribute information to members.\n<ref>{{cite web |title=EU/ME – The metaheuristics community on Linkedin|url=http://www.linkedin.com/groups?home=&gid=3770481&trk=anet_ug_hm}}</ref>\n\nSeveral books and special issues of academic journals have been published containing results of EU/MEetings.<ref name=\"euro\"/>\n\n== Pronunciation ==\n\nEU/ME is pronounced [uːmɪə] or [uː ænd mɪə] ([[Help:IPA/English]]).\n\n==References==\n{{Reflist|\nrefs=\n<ref name=\"euro\">{{cite web |title=EU/ME: the metaheuristics community (euro-online.org page) |url=https://www.euro-online.org/web/ewg/23/eume-the-metaheuristics-community}}</ref>\n<ref name=\"history\">{{cite web |title=EU/ME History|url=http://uahost.uantwerpen.be/eume/index.php?option=com_content&view=article&id=114&Itemid=80}}</ref>\n}}\n\n==External links==\n* {{url|http://www.scholarpedia.org/article/Metaheuristics}}\n* {{url|http://leeds-faculty.colorado.edu/glover/468%20-%20A%20History%20of%20Metaheuristics%20w%20Sorensen%20&%20Sevaux.pdf}}\n* {{url|http://www.scholarpedia.org/article/Metaheuristic_Optimization}}\n\n{{DEFAULTSORT:EU ME, the metaheuristics community}}\n[[Category:Metaheuristics]]\n[[Category:Working groups]]\n[[Category:Organizations established in 2000]]"
    },
    {
      "title": "Hill climbing",
      "url": "https://en.wikipedia.org/wiki/Hill_climbing",
      "text": "{{about|the mathematical algorithm|other meanings such as the branch of [[motorsport]]|Hillclimbing (disambiguation)}}\n{{Refimprove|date=April 2017}}\n{{Tree search algorithm}}\nIn numerical analysis, '''hill climbing''' is a [[Optimization (mathematics)|mathematical optimization]] technique which belongs to the family of [[Local search (optimization)|local search]]. It is an [[iterative algorithm]] that starts with an arbitrary solution to a problem, then attempts to find a better solution by making an [[incremental heuristic search|incremental]] change to the solution. If the change produces a better solution, another incremental change is made to the new solution, and so on until no further improvements can be found.\n\nFor example, hill climbing can be applied to the [[travelling salesman problem]]. It is easy to find an initial solution that visits all the cities but will likely be very poor compared to the optimal solution. The algorithm starts with such a solution and makes small improvements to it, such as switching the order in which two cities are visited. Eventually, a much shorter route is likely to be obtained.\n\nHill climbing finds optimal solutions for [[convex optimization|convex]] problems – for other problems it will find only [[local optimum|local optima]] (solutions that cannot be improved upon by any neighboring configurations), which are not necessarily the best possible solution (the [[global optimum]]) out of all possible solutions (the [[Candidate solution|search space]]). Examples of algorithms that solve convex problems by hill-climbing include the [[simplex algorithm]] for [[linear programming]] and [[binary search]].<ref>{{cite book |last=Skiena |first=Steven |authorlink=Steven Skiena |title = The Algorithm Design Manual |publisher=[[Springer Science+Business Media]] |edition=2nd |year = 2010 |isbn=1-849-96720-2}}</ref>{{rp|253}} To attempt to avoid getting stuck in local optima, one could use restarts (i.e. repeated local search), or more complex schemes based on iterations (like [[iterated local search]]), or on memory (like reactive search optimization and [[tabu search]]), or on memory-less stochastic modifications (like [[simulated annealing]]).\n\nThe relative simplicity of the algorithm makes it a popular first choice amongst optimizing algorithms. It is used widely in [[artificial intelligence]], for reaching a goal state from a starting node. Different choices for next nodes and starting nodes are used in related algorithms. Although more advanced algorithms such as [[simulated annealing]] or [[tabu search]] may give better results, in some situations hill climbing works just as well. Hill climbing can often produce a better result than other algorithms when the amount of time available to perform a search is limited, such as with real-time systems, so long as a small number of increments typically converges on a good solution (the optimal solution or a close approximation). At the other extreme, [[bubble sort]] can be viewed as a hill climbing algorithm (every adjacent element exchange decreases the number of disordered element pairs), yet this approach is far from efficient for even modest N, as the number of exchanges required grows quadratically. \n\nHill climbing is an [[anytime algorithm]]: it can return a valid solution even if it's interrupted at any time before it ends.\n\n==Mathematical description==\n\nHill climbing attempts to maximize (or minimize) a target [[function (mathematics)|function]] <math>f(\\mathbf{x})</math>, where <math>\\mathbf{x}</math> is a vector of continuous and/or discrete values. At each iteration, hill climbing will adjust a single element in <math>\\mathbf{x}</math> and determine whether the change improves the value of <math>f(\\mathbf{x})</math>. (Note that this differs from [[gradient descent]] methods, which adjust all of the values in <math>\\mathbf{x}</math> at each iteration according to the gradient of the hill.) With hill climbing, any change that improves <math>f(\\mathbf{x})</math> is accepted, and the process continues until no change can be found to improve the value of <math>f(\\mathbf{x})</math>. Then <math>\\mathbf{x}</math> is said to be \"locally optimal\".\n\nIn discrete vector spaces, each possible value for <math>\\mathbf{x}</math> may be visualized as a [[vertex (graph theory)|vertex]] in a [[Graph (discrete mathematics)|graph]]. Hill climbing will follow the graph from vertex to vertex, always locally increasing  (or decreasing) the value of <math>f(\\mathbf{x})</math>, until a [[local maximum]] (or [[local minimum]]) <math>x_m</math> is reached.\n\n[[Image:hill climb.png|thumb|260px|''A surface with only one maximum. Hill-climbers are well-suited for optimizing over such surfaces, and will converge to the global maximum.'']]\n\n==Variants==\n\nIn '''simple hill climbing''', the first closer node is chosen, whereas in '''steepest ascent hill climbing''' all successors are compared and the closest to the solution is chosen. Both forms fail if there is no closer node, which may happen if there are local maxima in the search space which are not solutions. Steepest ascent hill climbing is similar to [[best-first search]], which tries all possible extensions of the current path instead of only one.\n\n'''[[Stochastic hill climbing]]''' does not examine all neighbors before deciding how to move. Rather, it selects a neighbor at random, and decides (based on the amount of improvement in that neighbor) whether to move to that neighbor or to examine another.\n\n[[Coordinate descent]] does a [[line search]] along one coordinate direction at the current point in each iteration. Some versions of coordinate descent randomly pick a different coordinate direction each iteration.\n\n'''Random-restart hill climbing''' is a [[meta-algorithm]] built on top of the hill climbing algorithm. It is also known as '''Shotgun hill climbing'''. It iteratively does hill-climbing, each time with a random initial condition <math>x_0</math>. The best <math>x_m</math> is kept: if a new run of hill climbing produces a better <math>x_m</math> than the stored state, it replaces the stored state.\n\nRandom-restart hill climbing is a surprisingly effective algorithm in many cases. It turns out that it is often better to spend CPU time exploring the space, than carefully optimizing from an initial condition. {{Original research inline|date=September 2007}}\n\n==Problems==\n\n===Local maxima===\n[[Image:local maximum.png|thumb|260px|''A surface with two local maxima. (Only one of them is the global maximum.) If a hill-climber begins in a poor location, it may converge to the lower maximum.'']]\n\nHill climbing will not necessarily find the global maximum, but may instead converge on a [[maxima and minima|local maximum]]. This problem does not occur if the heuristic is convex. However, as many functions are not convex hill climbing may often fail to reach a global maximum. Other local search algorithms try to overcome this problem such as [[stochastic hill climbing]], [[random walk]]s and [[simulated annealing]].\n\n[[File:Hill Climbing with Simulated Annealing.gif|thumb|left|500px|Despite the many local maxima in this graph, the global maximum can still be found using '''simulated annealing'''. Unfortunately, the applicability of simulated annealing is problem-specific because it relies on finding ''lucky jumps'' that improve the position. In such extreme examples, hill climbing will most probably produce a local maximum.]]\n{{clear}}\n\n===Ridges and alleys===\n\n[[Image:ridge.png|thumb|190px|''A ridge'']]\n\n[[Ridge (differential geometry)|Ridges]] are a challenging problem for hill climbers that optimize in continuous spaces. Because hill climbers only adjust one element in the vector at a time, each step will move in an axis-aligned direction. If the target function creates a narrow ridge that ascends in a non-axis-aligned direction (or if the goal is to minimize, a narrow alley that descends in a non-axis-aligned direction), then the hill climber can only ascend the ridge (or descend the alley) by zig-zagging. If the sides of the ridge (or alley) are very steep, then the hill climber may be forced to take very tiny steps as it zig-zags toward a better position. Thus, it may take an unreasonable length of time for it to ascend the ridge (or descend the alley).\n\nBy contrast, gradient descent methods can move in any direction that the ridge or alley may ascend or descend. Hence, gradient descent or the [[conjugate gradient method]] is generally preferred over hill climbing when the target function is differentiable. Hill climbers, however, have the advantage of not requiring the target function to be differentiable, so hill climbers may be preferred when the target function is complex.\n\n===Plateau===\nAnother problem that sometimes occurs with hill climbing is that of a plateau. A plateau is encountered when the search space is flat, or sufficiently flat that the value returned by the target function is indistinguishable from the value returned for nearby regions due to the precision used by the machine to represent its value. In such cases, the hill climber may not be able to determine in which direction it should step, and may wander in a direction that never leads to improvement.\n\n==Pseudocode==\n\n<pre>\n\nDiscrete Space Hill Climbing Algorithm\n   currentNode = startNode;\n   loop do\n      L = NEIGHBORS(currentNode);\n      nextEval = -INF;\n      nextNode = NULL;\n      for all x in L \n         if (EVAL(x) > nextEval)\n              nextNode = x;\n              nextEval = EVAL(x);\n      if nextEval <= EVAL(currentNode)\n         //Return current node since no better neighbors exist\n         return currentNode;\n      currentNode = nextNode;\n</pre>\n\n<pre>\nContinuous Space Hill Climbing Algorithm\n   currentPoint = initialPoint;    // the zero-magnitude vector is common\n   stepSize = initialStepSizes;    // a vector of all 1's is common\n   acceleration = someAcceleration; // a value such as 1.2 is common\n   candidate[0] = -acceleration;\n   candidate[1] = -1 / acceleration;\n   candidate[2] = 0;\n   candidate[3] = 1 / acceleration;\n   candidate[4] = acceleration;\n   loop do\n      before = EVAL(currentPoint);\n      for each element i in currentPoint do\n         best = -1;\n         bestScore = -INF;\n         for j from 0 to 4         // try each of 5 candidate locations\n            currentPoint[i] = currentPoint[i] + stepSize[i] * candidate[j];\n            temp = EVAL(currentPoint);\n            currentPoint[i] = currentPoint[i] - stepSize[i] * candidate[j];\n            if(temp > bestScore)\n                 bestScore = temp;\n                 best = j;\n         if candidate[best] is 0\n            stepSize[i] = stepSize[i] / acceleration;\n         else\n            currentPoint[i] = currentPoint[i] + stepSize[i] * candidate[best];\n            stepSize[i] = stepSize[i] * candidate[best]; // accelerate\n      if (EVAL(currentPoint) - before) < epsilon \n         return currentPoint;\n</pre>\n\nContrast [[genetic algorithm]]; [[random optimization]].\n\n==See also==\n* [[Gradient descent]]\n* [[Greedy algorithm]]\n* [[Walrasian auction|Tâtonnement]]\n* [[Mean-shift]]\n* [[A* search algorithm]]\n\n==References==\n*{{Russell Norvig 2003| pages=111–114}}\n\n{{reflist}}\n\n{{FOLDOC}}\n\n==External links==\n{{Wikibooks}}\n\n{{Optimization algorithms}}\n\n[[Category:Metaheuristics]]\n[[Category:Search algorithms]]\n[[Category:Articles with example pseudocode]]"
    },
    {
      "title": "Late acceptance hill climbing",
      "url": "https://en.wikipedia.org/wiki/Late_acceptance_hill_climbing",
      "text": "'''Late acceptance hill climbing''', created by Yuri Bykov in 2008<ref name=\"bykov2008\">{{cite journal\n | author = E. K. Burke and Y. Bykov,\n | title = The Late Acceptance Hill-Climbing Heuristic\n | journal = European Journal of Operational Research \n }}</ref> is a [[metaheuristic]] search method employing [[Local search (optimization)|local search]] methods used for [[optimization (mathematics)|mathematical optimization]].\n\n[[Category:Metaheuristics]]"
    },
    {
      "title": "Multi-swarm optimization",
      "url": "https://en.wikipedia.org/wiki/Multi-swarm_optimization",
      "text": "'''Multi-swarm optimization''' is a variant of [[particle swarm optimization]] (PSO) based on the use of multiple sub-swarms instead of one (standard) swarm. The general approach in multi-swarm optimization is that each sub-swarm focuses on a specific region while a specific diversification method decides where and when to launch the sub-swarms. The multi-swarm framework is especially fitted for the optimization on multi-modal problems, where multiple (local) optima exist.\n\n==Description==\nIn multi-modal problems it is important to achieve an effective balance between exploration and exploitation. Multi-swarm systems provide a new approach to improve this balance. Instead of trying to achieve a compromise between exploration and exploitation which could weaken both mechanisms of the search process, multi-swarm systems separate them into distinct phases. Each phase is more focused on either exploitation (individual sub-swarms) or exploration (diversification method).\n\nThe coordination of the sub-swarms depends on the specific diversification method(s) implemented by the multi-swarm system. Wave of Swarm of Particles (WOSP),<ref>T. Hendtlass, \"[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.9936&rep=rep1&type=pdf WoSP: A Multi-Optima Particle Swarm Algorithm],\" in Proceedings IEEE Congress on Evolutionary Computation, 2005, pp. 727–734.</ref> for example, bases its diversification mechanism on the \"collision\" of particles. When particles get too close they are expelled by a short range force into new waves/sub-swarms, avoiding thus a complete convergence. The Dynamic Multi-Swarm-Particle Swarm Optimizer (DMS-PSO)<ref>S. Z. Zhao, J. J. Liang, P. N. Suganthan, and M. F. Tasgetiren, \"[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.871.3516&rep=rep1&type=pdf Dynamic Multi-Swarm Particle Swarm Optimizer with Local Search for Large Scale Global Optimization],\" in Proceedings IEEE Congress on Evolutionary Computation, 2008, pp. 3845–3852.</ref> periodically regroups the particles of the sub-swarms (after they have converged) into new sub-swarms, the new swarms are started with particles from previous swarms. Locust swarms<ref>S. Chen, \"Locust Swarms – A New Multi-Optima Search Technique\", in Proceedings of the IEEE Congress on Evolutionary Computation, 2009, pp. 1745–1752.[https://yorku.academia.edu/StephenChen/Papers/1305024/Locust_Swarms-A_new_multi-optima_search_technique]</ref> are based on a \"devour and move on\" strategy – after a sub-swarm \"devours\" a relatively small region of the search space (to find a local optimum) scouts are deployed to look for new promising regions to \"move on\". \n\nA distinctive feature of sub-swarms is that their initial positions and initial velocities are not randomly selected as in normal swarms. Instead, they maintain some information from the previous trajectories of the particles. In general, the development of multi-swarm systems leads to design decisions which did not exist during the original development of particle swarm optimization, such as the number of particles to use in each sub-swarm, the optimal value for the constriction factor  and the effects of non-random initial positions and initial velocities. These design decisions have been thoroughly studied and have well-established guidelines – e.g. the use of non-random initial positions and initial velocities leads to improved results in multi-swarm systems, which is not the case for single-swarms.<ref>S.Chen and J. Montgomery  \"Selection Strategies for Initial Positions and Initial Velocities in Multi–optima Particle Swarms\", in  Proceedings of the Genetic and Evolutionary Computation Conference, 2011 pp. 53–60.[https://yorku.academia.edu/StephenChen/Papers/1305023/Selection_strategies_for_initial_positions_and_initial_velocities_in_multi-optima_particle_swarms]</ref> Other design decisions, such as which diversification method to use or which specific search strategy will select the initial positions and initial velocities of a sub-swarm, have less established guidelines and constitute open questions in the field of multi-swarm systems.\n\nSome of these design decisions can be addressed by relatively independent sub-components which allow different optimization techniques to be inserted. Multi-swarm systems thus provide a useful framework for the development of [[hybrid algorithm]]s. For example, the UMDA-PSO<ref>Antonio Bolufé Röhler and S. Chen, \"Multi-swarm hybrid for multi-modal optimization\", in Proceedings of the IEEE Congress on Evolutionary Computation, 2012, pp. 1759-1766.[https://yorku.academia.edu/StephenChen/Papers/1847348/Multi-swarm_hybrid_for_multi-modal_optimization]</ref> multi-swarm system effectively combines components from [[particle swarm optimization]], [[estimation of distribution algorithm]], and [[differential evolution]] into a multi-swarm hybrid.\n\n== Current work ==\n\nA [http://www.mendeley.com/groups/2389861/multi-swarm-systems/overview/ reading group] on [[Mendeley]] is available to all interested researchers.\n\n== See also ==\n* [[Swarm intelligence]]\n\n== References ==\n{{reflist}}\n\n[[Category:Metaheuristics]]"
    },
    {
      "title": "Paradiseo",
      "url": "https://en.wikipedia.org/wiki/Paradiseo",
      "text": "{{ infobox software\n| logo                   = \n| screenshot             = \n| caption                = \n| latest_release_version = 2.0.1\n| latest_release_date    = {{release date|2012|11|07}}\n| status                 = Stalled\n| developer              = [http://www.inria.fr/recherche/equipes/dolphin.en.html DOLPHIN project-team] of [[INRIA]]\n| operating_system       = [[Cross-platform]]\n| genre                  = [[List of numerical analysis software|Technical computing]]\n| license                = [[CeCILL|CeCill license]]\n| website                = http://paradiseo.gforge.inria.fr\n}}\n\n'''ParadisEO''' is a [[White box (software engineering)|white-box]] [[object-oriented]] [[Software framework|framework]] dedicated to the flexible design of [[metaheuristics]]. It uses EO, a [[Template metaprogramming|template-based]], [[ANSI C|ANSI-C++]] compliant [[Library (computing)|computation library]].<ref>{{cite web |url=http://eodev.sourceforge.net/ |title=Evolving Objects (EO): an Evolutionary Computation Framework |date=2015 |website=SourceForge.net |access-date=14 November 2015}}</ref>  ParadisEO is [[Porting|portable]] across both [[Microsoft Windows|Windows]] system and sequential platforms ([[Unix]], [[Linux]], [[macOS|Mac OS X]], etc.). ParadisEO is distributed under the [[CeCILL|CeCill license]] and can be used under several environments.\n\n== Overview ==\n\nParadisEO is a [[White box (software engineering)|white-box]] [[object-oriented]] [[Software framework|framework]] dedicated to the [[Code reuse|reusable]] design of [[metaheuristics]], hybrid metaheuristics, and [[Parallel algorithm|parallel]] and [[Distributed computing|distributed]] metaheuristics.\nParadisEO provides a broad range of features including [[evolutionary algorithms]], [[Local search (optimization)|local searches]], [[Particle swarm optimization]], the most common parallel and distributed models and hybridization mechanisms, etc. This high content and utility encourages its use at International level. ParadisEO is based on a clear conceptual separation of the solution methods from the problems they are intended to solve. This separation confers to the user a maximum code and design reuse. Furthermore, the fine-grained nature of the classes provided by the framework allow a higher flexibility compared to other frameworks. ParadisEO is of the rare frameworks that provide the most common parallel and distributed models. Their implementation is portable on distributed-memory machines as well as on shared-memory multiprocessors, as it uses standard libraries such as [[Message Passing Interface|MPI]], [[PVM]] and PThreads. The models can be exploited in a transparent way, one has just to instantiate their associated provided classes. Their experimentation on the radio network design real-world application demonstrate their efficiency.\n\n== Modules ==\n=== Paradiseo-EO ===\n\nParadiseo-EO deals with population based metaheuristics, it is a templates-based, ANSI-C++ compliant evolutionary computation library (evolutionary algorithms, particle swarm optimization...). It contains classes for almost any kind of evolutionary computation you might come up to - at least for the ones we could think of. It is component-based, so that if you don't find the class you need in it, it is very easy to subclass existing [[Abstraction (computer science)|abstract or concrete classes]].\n\n=== Paradiseo-MOEO ===\n\nParadiseo-MOEO provides a broad range of tools for the design of [[multiobjective optimization]] metaheuristics: fitness assignment schemes (achievement functions, ranking, indicator-based...), diversity preservation mechanisms (sharing, crowding), elitism, performance metrics (contribution, entropy...), statistical tools and some easy-to-use state-of-the-art multi-objective evolutionary algorithms (NSGA, NSGA-II, IBEA...).\n\n=== Paradiseo-MO ===\n\nParadiseo-MO deals with single-solution based metaheuristics, it provides tools for the development of single solution-based metaheuristics: [[Hill climbing]], [[Tabu search]], [[Iterative Local Search]] (ILS), [[Simulated annealing]], incremental evaluation, partial neighbourhood...\n\n=== Paradiseo-PEO ===\n\nParadiseo-PEO provides tools for the design of parallel and distributed metaheuristics: parallel evaluation, parallel evaluation function, island model, cellular model... Paradiseo-PEO also introduces tools for the design of distributed, hybrid and cooperative models.\n\n== See also ==\n* [[Java_Evolutionary_Computation_Toolkit|ECJ]], A toolkit to implement Evolutionary Algorithms\n* [[MOEA Framework]], an open source Java framework for multiobjective evolutionary algorithms\n\n== External links ==\n* [http://paradiseo.gforge.inria.fr Official site], at ''Paradiseo'' website\n* [http://www.inria.fr/recherche/equipes/dolphin.en.html Team], at DOLPHIN project-team website\n\n== References ==\n{{Reflist}}\n{{refbegin}}\n* [http://doi.ieeecomputersociety.org/10.1109/CCGRID.2006.172 \"Solving the Protein Folding Problem with a Bicriterion Genetic Algorithm on the Grid\"]\n* Protein Sequencing with an Adaptive Genetic Algorithm from Tandem Mass Spectrometry, CEC 2006, 0-7803-9489-5, July 16-21 2006, pp 1412–1419, Vancouver, Canada\n* [https://web.archive.org/web/20120402193400/http://www2.lifl.fr/~jourdan/publi/jourdan_EMO07_A.pdf \"ParadisEO-MOEO: A Framework for Evolutionary Multi-objective Optimization\"] (broken link?)\n* A Multi-Objective Approach to the Design of Conducting Polymer Composites for Electromagnetic Shielding, EMO 2007, Matsushima, Japan\n* A hybrid metaheuristic for knowledge discovery in microarray experiments, In Handbook of Bioinspired Algorithms and Applications, Edited by S. Olariu and A.Y. Zomaya\n* [http://top25.sciencedirect.com/index.php?cat_id=9&subject_area_id=7&journal_id=07437315  Grid computing for parallel bioinspired algorithms] (broken link?)\n* [http://www.springerlink.com/content/up02m74726v1526u/ ParadisEO: A Framework for the Reusable Design of Parallel and Distributed Metaheuristics]  (broken link?)\n* [https://dx.doi.org/10.1016/j.comcom.2006.08.017  Designing cellular networks using a parallel hybrid metaheuristic]\n{{refend}}\n\n[[Category:Distributed computing architecture]]\n[[Category:Metaheuristics]]\n[[Category:Numerical programming languages]]\n[[Category:Numerical analysis software for Linux]]\n[[Category:Numerical analysis software for MacOS]]\n[[Category:Numerical analysis software for Windows]]"
    },
    {
      "title": "Tabu search",
      "url": "https://en.wikipedia.org/wiki/Tabu_search",
      "text": "'''Tabu search''', created by [[Fred W. Glover]] in 1986<ref name=\"glover86\">{{cite journal\n | author = Fred Glover\n | year = 1986\n | title = Future Paths for Integer Programming and Links to Artificial Intelligence\n | journal = Computers and Operations Research \n | volume = 13\n | issue = 5\n | pages = 533–549\n | doi=10.1016/0305-0548(86)90048-1\n }}\n</ref> and formalized in 1989,<ref name=\"glover89\">{{cite journal|author=Fred Glover|year=1989|title=Tabu Search – Part 1|url=|journal=ORSA Journal on Computing|volume=1|issue=2|pages=190–206|doi=10.1287/ijoc.1.3.190|via=}}\n</ref><ref name=\"glover90\">{{cite journal|author=Fred Glover|year=1990|title=Tabu Search – Part 2|url=|journal=ORSA Journal on Computing|volume=2|issue=1|pages=4–32|doi=10.1287/ijoc.2.1.4|via=}}\n</ref> is a [[metaheuristic]] search method employing [[Local search (optimization)|local search]] methods used for [[optimization (mathematics)|mathematical optimization]].\n\n[[local search (optimization)|Local (neighborhood) searches]] take a potential solution to a problem and check its immediate neighbors (that is, solutions that are similar except for very few minor details) in the hope of finding an improved solution. Local search methods have a tendency to become stuck in suboptimal regions or on plateaus where many solutions are equally fit.\n\nTabu search enhances the performance of local search by relaxing its basic rule. First, at each step  ''worsening'' moves can be accepted if no improving move is available (like when the search is stuck at a strict [[Maxima and minima|local minimum]]). In addition, ''prohibitions'' (henceforth the term ''tabu'') are introduced to discourage the search from coming back to previously-visited solutions.\n\nThe implementation of tabu search uses memory structures that describe the visited solutions or user-provided sets of rules.<ref name=\"glover89\"/> If a potential solution has been previously visited within a certain short-term period or if it has violated a rule, it is marked as \"[[taboo|tabu]]\" (forbidden) so that the [[algorithm]] does not consider that possibility repeatedly.\n\n==Background==\n\nThe word ''[[Taboo#Etymology|tabu]]'' comes from  the [[Tongan language|Tongan]] word to indicate things that cannot be touched because they are sacred.<ref name=\"ise.ncsu.edu\">{{Cite web | url=http://www.ise.ncsu.edu/fangroup/ie789.dir/IE789F_tabu.pdf | title=Courses}}</ref>\n\nTabu search (TS) is a [[metaheuristic]] algorithm that can be used for solving [[combinatorial optimization]] problems (problems where an optimal ordering and selection of options is desired).\n\nCurrent applications of TS span the areas of [[Enterprise resource planning|resource planning]], telecommunications, [[Very-large-scale integration|VLSI design]], financial analysis, scheduling, space planning, energy distribution, molecular engineering, logistics, [[pattern classification]], flexible manufacturing, waste management, mineral exploration, biomedical analysis, environmental conservation and scores of others.  In recent years, journals in a wide variety of fields have published tutorial articles and computational studies documenting successes by tabu search in extending the frontier of problems that can be handled effectively — yielding solutions whose quality often significantly surpasses that obtained by methods previously applied. A comprehensive list of applications, including summary descriptions of gains achieved from practical implementations, can be found in <ref name=\"gloverlaguna1997\">{{cite book |author1=F. Glover |author2=M. Laguna | year = 1997 | title = Tabu Search | publisher = Kluwer Academic Publishers |isbn=978-1-4613-7987-4}}</ref> Recent TS developments and applications can also be found in [http://leeds-faculty.colorado.edu/glover/tabusearchvignettes.html Tabu Search Vignettes].\n\n==Basic description==\n\nTabu search uses a [[local search (optimization)|local or neighborhood]] search procedure to iteratively move from one potential solution <math>x</math> to an improved solution <math>x'</math> in the neighborhood of <math>x</math>, until some stopping criterion has been satisfied (generally, an attempt limit or a score threshold). Local search procedures often become stuck in poor-scoring areas or areas where scores plateau. In order to avoid these pitfalls and explore regions of the [[Energy function|search space]] that would be left unexplored by other local search procedures, tabu search carefully explores the neighborhood of each solution as the search progresses. The solutions admitted to the new neighborhood, <math>N^*(x)</math>, are determined through the use of memory structures. Using these memory structures, the search progresses by iteratively moving from the current solution <math>x</math> to an improved solution <math>x'</math> in <math>N^*(x)</math>. \n\nTabu Search has several similarities with Simulated Annealing, as both involve possible down hills moves. In fact, Simulated Annealing could be viewed as a special form of TS, where by we use \"graduated tenure\", that is, a move becomes tabu with a specified probability.\n\nThese memory structures form what is known as the tabu list, a set of rules and banned solutions used to filter which solutions will be admitted to the neighborhood <math>N^*(x)</math> to be explored by the search. In its simplest form, a tabu list is a short-term set of the solutions that have been visited in the recent past (less than <math>n</math> iterations ago, where <math>n</math>  is the number of previous solutions to be stored —  is also called the tabu tenure). More commonly, a tabu list consists of solutions that have changed by the process of moving from one solution to another. It is convenient, for ease of description, to understand a “solution” to be coded and represented by such attributes.\n\n==Types of memory==\nThe memory structures used in tabu search can roughly be divided into three categories:<ref name=\"glover90b\">{{cite journal\n | author = Fred Glover\n | year = 1990\n | title = Tabu Search: A Tutorial\n | journal = Interfaces\n }}\n</ref>\n* Short-term: The list of solutions recently considered. If a potential solution appears on the tabu list, it cannot be revisited until it reaches an expiration point.\n* Intermediate-term: Intensification rules intended to bias the search towards promising areas of the search space.\n* Long-term: Diversification rules that drive the search into new regions (i.e. regarding resets when the search becomes stuck in a plateau or a suboptimal dead-end).\n\nShort-term, intermediate-term and long-term memories can overlap in practice. Within these categories, memory can further be differentiated by measures such as frequency and impact of changes made. One example of an intermediate-term memory structure is one that prohibits or encourages solutions that contain certain attributes (e.g., solutions which include undesirable  or desirable values for certain variables) or a memory structure that prevents or induces certain moves (e.g. based on frequency memory applied to solutions sharing features in common with unattractive or attractive solutions found in the past). In short-term memory, selected attributes in solutions recently visited are labeled \"tabu-active.\" Solutions that contain tabu-active elements are banned. Aspiration criteria are employed that override a solution's tabu state, thereby including the otherwise-excluded solution in the allowed set (provided the solution is “good enough” according to a measure of quality or diversity). A simple and commonly used aspiration criterion is to allow solutions which are better than the currently-known best solution.\n\n\nShort-term memory alone may be enough to achieve solutions superior to those found by conventional local search methods, but intermediate and long-term structures are often necessary for solving harder problems.<ref name=\"malek89\">{{cite journal\n |author1=M. Malek |author2=M. Huruswamy |author3=H. Owens |author4=M. Pandya | year = 1989\n | title = Serial and parallel search techniques for the traveling salesman problem\n | journal = Annals of OR: Linkages with Artificial Intelligence\n }}</ref>  Tabu search is often benchmarked against other [[metaheuristic]] methods — such as [[Simulated annealing]], [[genetic algorithm]]s, [[Ant colony optimization algorithms]], Reactive search optimization, [[Guided Local Search]], or [[greedy randomized adaptive search procedure|greedy randomized adaptive search]]. In addition, tabu search is sometimes combined with other metaheuristics to create hybrid methods. The most common tabu search hybrid arises by joining TS with Scatter Search,<ref name=\"glover2000\">{{cite journal\n |author1=F. Glover, M. Laguna  |author2=R. Marti\n  |lastauthoramp=yes | year = 2000\n | title = Fundamentals of Scatter Search and Path Relinking\n | journal = Control and Cybernetics\n | volume = 29\n | issue = 3\n | pages = 653–684\n }}</ref><ref name=\"laguna2003\">{{cite book\n |author1=M. Laguna  |author2=R. Marti\n  |lastauthoramp=yes | year = 2003\n | title = Scatter Search: Methodology and Implementations in C \n |publisher = Kluwer Academic Publishers\n |isbn=9781402073762\n }}</ref> a class of population-based procedures which has roots in common with tabu search, and is often employed in solving large non-linear optimization problems.\n\n== Pseudocode ==\n\nThe following [[pseudocode]] presents a simplified version of the tabu search algorithm as described above. This implementation has a rudimentary short-term memory, but contains no intermediate or long-term memory structures. The term \"fitness\" refers to an evaluation of the candidate solution, as embodied in an objective function for mathematical optimization.\n\n<syntaxhighlight lang=\"pascal\" line>\nsBest ← s0\nbestCandidate ← s0\ntabuList ← []\ntabuList.push(s0)\nwhile (not stoppingCondition())\n\tsNeighborhood ← getNeighbors(bestCandidate)\n\tfor (sCandidate in sNeighborhood)\n\t\tif ( (not tabuList.contains(sCandidate)) and (fitness(sCandidate) > fitness(bestCandidate)) )\n\t\t\tbestCandidate ← sCandidate\n\t\tend\n\tend\n\tif (fitness(bestCandidate) > fitness(sBest))\n\t\tsBest ← bestCandidate\n\tend\n\ttabuList.push(bestCandidate)\n\tif (tabuList.size > maxTabuSize)\n\t\ttabuList.removeFirst()\n\tend\nend\nreturn sBest\n</syntaxhighlight>\n\nLines 1-4 represent some initial setup, respectively creating an initial solution (possibly chosen at random), setting that initial solution as the best seen to date, and initializing a tabu list with this initial solution. In this example, the tabu list is simply a short term memory structure that will contain a record of the elements of the states visited.\n\nThe core algorithmic loop starts in line 5. This loop will continue searching for an optimal solution until a user-specified stopping condition is met (two examples of such conditions are a simple time limit or a threshold on the fitness score). The neighboring solutions are checked for tabu elements in line 8. Additionally, the algorithm keeps track of the best solution in the neighbourhood, that is not tabu.\n\nThe fitness function is generally a mathematical function, which returns a score or the aspiration criteria are satisfied — for example, an aspiration criterion could be considered as a new search space is found<ref name=\"ise.ncsu.edu\"/>). If the best local candidate has a higher fitness value than the current best (line 12), it is set as the new best (line 13). The local best candidate is always added to the tabu list (line 15) and if the tabu list is full (line 16), some elements will be allowed to expire (line 17). Generally, elements expire from the list in the same order they are added. The procedure will select the best local candidate (although it has worse fitness than the sBest) in order to escape the local optimal.\n\nThis process continues until the user specified stopping criterion is met, at which point, the best solution seen during the search process is returned (line 20).\n\n==Example: the traveling salesman problem==\n\nThe [[traveling salesman problem]] (TSP) is sometimes used to show the functionality of tabu search.<ref name=\"malek89\"/> This problem poses a straightforward question — given a list of cities, what is the shortest route that visits every city? For example, if city&nbsp;A and city&nbsp;B are next to each other, while city&nbsp;C is farther away, the total distance traveled will be shorter if cities A and&nbsp;B are visited one after the other before visiting city&nbsp;C. Since finding an optimal solution is [[NP-hard]], heuristic-based approximation methods (such as local searches) are useful for devising close-to-optimal solutions. To obtain good TSP solutions, it is essential to exploit the graph structure. The value of exploiting problem structure is a recurring theme in metaheuristic methods, and tabu search is well-suited to this. A class of strategies associated with tabu search called ejection chain methods has made it possible to obtain high-quality TSP solutions efficiently <ref name=\"gamboa2005\">{{cite journal\n |author1=D. Gamboa, C. Rego  |author2=F. Glover\n  |lastauthoramp=yes | year = 2005\n | title = Data Structures and Ejection Chains for Solving Large Scale Traveling Salesman Problems\n | journal = European Journal of Operational Research\n | volume = 160\n | issue = 1\n | pages = 154–171\n | doi=10.1016/j.ejor.2004.04.023|citeseerx=10.1.1.417.9789\n  }}\n</ref>\n\nOn the other hand, a simple tabu search can be used to find a [[satisficing]] solution for the traveling salesman problem (that is, a solution that satisfies an adequacy criterion, although not with the high quality obtained by exploiting the graph structure). The search starts with an initial solution, which can be generated randomly or according to some sort of [[nearest neighbor algorithm]]. To create new solutions, the order that two cities are visited in a potential solution is swapped. The total traveling distance between all the cities is used to judge how ideal one solution is compared to another. To prevent cycles – i.e., repeatedly visiting a particular set of solutions – and to avoid becoming stuck in [[local optima]], a solution is added to the tabu list if it is accepted into the solution neighborhood, <math>N^*(x)</math>.\n\nNew solutions are created until some stopping criterion, such as an arbitrary number of iterations, is met. Once the simple tabu search stops, it returns the best solution found during its execution.\n\n== References ==\n{{Reflist}}\n\n== External links==\n* [http://siebn.de/other/tabusearch/ Visualization of the Tabu search algorithm (Applet)]\n* [http://mic2011.diegm.uniud.it/ Metaheuristic International Conference (MIC 2011) – Udine]\n* [http://www.reactive-search.org/ The Reactive Search Community]\n* [http://www.intelligent-optimization.org/LION5/ LION Conference on Learning and Intelligent Optimization techniques]\n* [http://www.cs.mcu.edu.tw/~s9170446/research/Tabu_Search/TABU%20SEARCH.pdf]\n{{Optimization algorithms}}\n\n[[Category:Metaheuristics]]\n[[Category:1989 introductions]]"
    },
    {
      "title": "Convergent matrix",
      "url": "https://en.wikipedia.org/wiki/Convergent_matrix",
      "text": "{{Short description|Matrix that converges to zero matrix}}\nIn [[numerical linear algebra]], a '''convergent matrix''' is a matrix that converges to the [[zero matrix]] under [[matrix exponentiation]].\n\n==Background==\nWhen successive powers of a [[matrix (mathematics)|matrix]] '''T''' become small (that is, when all of the entries of '''T''' approach zero, upon raising '''T''' to successive powers), the matrix '''T''' converges to the zero matrix.  A [[matrix splitting|regular splitting]] of a [[invertible matrix|non-singular]] matrix '''A''' results in a convergent matrix '''T'''.  A semi-convergent splitting of a matrix '''A''' results in a semi-convergent matrix '''T'''.  A general [[iterative method]] converges for every initial vector if '''T''' is convergent, and under certain conditions if '''T''' is semi-convergent.\n\n==Definition==\nWe call an ''n'' &times; ''n'' matrix '''T''' a '''convergent matrix''' if\n\n:{{NumBlk|:|<math> \\lim_{k \\to \\infty}( \\mathbf T^k)_{ij} = 0,</math>|{{EquationRef|1}}}}\n\nfor each ''i'' = 1, 2, ..., ''n'' and ''j'' = 1, 2, ..., ''n''.<ref>{{harvtxt|Burden|Faires|1993|p=404}}</ref><ref>{{harvtxt|Isaacson|Keller|1994|p=14}}</ref><ref>{{harvtxt|Varga|1962|p=13}}</ref>\n\n==Example==\nLet\n:<math>\\begin{align}\n& \\mathbf{T} = \\begin{pmatrix}\n\\frac{1}{4} & \\frac{1}{2} \\\\[4pt]\n0 & \\frac{1}{4}\n\\end{pmatrix}.\n\\end{align}</math>\nComputing successive powers of '''T''', we obtain\n:<math>\\begin{align}\n& \\mathbf{T}^2 = \\begin{pmatrix}\n\\frac{1}{16} & \\frac{1}{4} \\\\[4pt]\n0 & \\frac{1}{16}\n\\end{pmatrix}, \\quad \\mathbf{T}^3 = \\begin{pmatrix}\n\\frac{1}{64} & \\frac{3}{32} \\\\[4pt]\n0 & \\frac{1}{64}\n\\end{pmatrix}, \\quad \\mathbf{T}^4 = \\begin{pmatrix}\n\\frac{1}{256} & \\frac{1}{32} \\\\[4pt]\n0 & \\frac{1}{256}\n\\end{pmatrix}, \\quad \\mathbf{T}^5 = \\begin{pmatrix}\n\\frac{1}{1024} & \\frac{5}{512} \\\\[4pt]\n0 & \\frac{1}{1024}\n\\end{pmatrix},\n\\end{align}</math>\n:<math>\\begin{align}\n\\mathbf{T}^6 = \\begin{pmatrix}\n\\frac{1}{4096} & \\frac{3}{1024} \\\\[4pt]\n0 & \\frac{1}{4096}\n\\end{pmatrix},\n\\end{align}</math>\nand, in general,\n:<math>\\begin{align}\n\\mathbf{T}^k = \\begin{pmatrix}\n(\\frac{1}{4})^k & \\frac{k}{2^{2k - 1}} \\\\[4pt]\n0 & (\\frac{1}{4})^k\n\\end{pmatrix}.\n\\end{align}</math>\nSince\n:<math> \\lim_{k \\to \\infty} \\left( \\frac{1}{4} \\right)^k = 0 </math>\nand\n:<math> \\lim_{k \\to \\infty} \\frac{k}{2^{2k - 1}} = 0, </math>\n'''T''' is a convergent matrix.  Note that ''&rho;''('''T''') = {{math|{{sfrac|1|4}}}}, where ''&rho;''('''T''') represents the [[spectral radius]] of '''T''', since {{math|{{sfrac|1|4}}}} is the only [[eigenvalue]] of '''T'''.\n\n==Characterizations==\nLet '''T''' be an ''n'' &times; ''n'' matrix.  The following properties are equivalent to '''T''' being a convergent matrix:\n#<math> \\lim_{k \\to \\infty} \\| \\mathbf T^k \\| = 0, </math> for some natural norm;\n#<math> \\lim_{k \\to \\infty} \\| \\mathbf T^k \\| = 0, </math> for all natural norms;\n#<math> \\rho( \\mathbf T ) < 1 </math>;\n#<math> \\lim_{k \\to \\infty} \\mathbf T^k \\mathbf x = \\mathbf 0, </math> for every '''x'''.<ref>{{harvtxt|Burden|Faires|1993|p=404}}</ref><ref>{{harvtxt|Isaacson|Keller|1994|pp=14,63}}</ref><ref>{{harvtxt|Varga|1960|p=122}}</ref><ref>{{harvtxt|Varga|1962|p=13}}</ref>\n\n==Iterative methods==\n{{main|Iterative method}}\nA general '''iterative method''' involves a process that converts the [[system of linear equations]]\n\n:{{NumBlk|:|<math> \\mathbf{Ax} = \\mathbf{b} </math>|{{EquationRef|2}}}}\n\ninto an equivalent system of the form\n\n:{{NumBlk|:|<math> \\mathbf{x} = \\mathbf{Tx} + \\mathbf{c} </math>|{{EquationRef|3}}}}\n\nfor some matrix '''T''' and vector '''c'''.  After the initial vector '''x'''<sup>(0)</sup> is selected, the sequence of approximate solution vectors is generated by computing\n\n:{{NumBlk|:|<math> \\mathbf{x}^{(k + 1)} = \\mathbf{Tx}^{(k)} + \\mathbf{c} </math>|{{EquationRef|4}}}}\n\nfor each ''k'' &ge; 0.<ref>{{harvtxt|Burden|Faires|1993|p=406}}</ref><ref>{{harvtxt|Varga|1962|p=61}}</ref>   For any initial vector '''x'''<sup>(0)</sup> &isin; <math> \\mathbb{R}^n </math>, the sequence <math> \\lbrace \\mathbf{x}^{ \\left( k \\right) } \\rbrace _{k = 0}^{\\infty} </math> defined by ({{EquationNote|4}}), for each ''k'' &ge; 0 and '''c''' &ne; 0, converges to the unique solution of ({{EquationNote|3}}) if and only if ''&rho;''('''T''') < 1, that is, '''T''' is a convergent matrix.<ref>{{harvtxt|Burden|Faires|1993|p=412}}</ref><ref>{{harvtxt|Isaacson|Keller|1994|pp=62–63}}</ref>\n\n===Regular splitting===\n{{main|Matrix splitting}}\nA  '''matrix splitting''' is an expression which represents a given matrix as a sum or difference of matrices.  In the system of linear equations ({{EquationNote|2}}) above, with '''A''' non-singular, the matrix '''A''' can be split, that is, written as a difference\n\n:{{NumBlk|:|<math> \\mathbf{A} = \\mathbf{B} - \\mathbf{C} </math>|{{EquationRef|5}}}}\n\nso that ({{EquationNote|2}}) can be re-written as ({{EquationNote|4}}) above.  The expression ({{EquationNote|5}}) is a '''regular splitting of A''' if and only if '''B'''<sup>&minus;1</sup> &ge; '''0''' and '''C''' &ge; '''0''', that is, {{nowrap|'''B'''<sup>&minus;1</sup>}} and '''C''' have only nonnegative entries.  If the splitting ({{EquationNote|5}}) is a regular splitting of the matrix '''A''' and '''A'''<sup>&minus;1</sup> &ge; '''0''', then ''&rho;''('''T''') < 1 and '''T''' is a convergent matrix.  Hence the method ({{EquationNote|4}}) converges.<ref>{{harvtxt|Varga|1960|pp=122–123}}</ref><ref>{{harvtxt|Varga|1962|p=89}}</ref>\n\n==Semi-convergent matrix==\nWe call an ''n'' &times; ''n'' matrix '''T''' a '''semi-convergent matrix''' if the limit\n\n:{{NumBlk|:|<math> \\lim_{k \\to \\infty} \\mathbf T^k </math>|{{EquationRef|6}}}}\n\nexists.<ref>{{harvtxt|Meyer & Plemmons|1977|p=699}}</ref>  If '''A''' is possibly singular but ({{EquationNote|2}}) is consistent, that is, '''b''' is in the range of '''A''', then the sequence defined by ({{EquationNote|4}}) converges to a solution to ({{EquationNote|2}}) for every '''x'''<sup>(0)</sup> &isin; <math> \\mathbb{R}^n </math> if and only if '''T''' is semi-convergent.  In this case, the splitting ({{EquationNote|5}}) is called a '''semi-convergent splitting''' of '''A'''.<ref>{{harvtxt|Meyer & Plemmons|1977|p=700}}</ref>\n\n==See also==\n*[[Gauss–Seidel method]]\n*[[Jacobi method]]\n*[[List of matrices]]\n*[[Nilpotent matrix]]\n*[[Successive over-relaxation]]\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{ citation | first1 = Richard L. | last1 = Burden | first2 = J. Douglas | last2 = Faires | year = 1993 | isbn = 0-534-93219-3 | title = Numerical Analysis | edition = 5th | publisher = [[Prindle, Weber and Schmidt]] | location = Boston }}.\n* {{ citation | first1 = Eugene | last1 = Isaacson | first2 = Herbert Bishop | last2 = Keller| year = 1994 | isbn = 0-486-68029-0 | title = Analysis of Numerical Methods | publisher = [[Dover Publications|Dover]] | location = New York }}.\n* {{ cite journal | title = Convergent Powers of a Matrix with Applications to Iterative Methods for Singular Linear Systems |date=Sep 1977 | author1 = Carl D. Meyer, Jr. | author2 = R. J. Plemmons | journal = [[SIAM Journal on Numerical Analysis]] | volume = 14 | issue = 4 | pages = 699–705 | doi=10.1137/0714047 | ref = {{harvid|Meyer & Plemmons|1977}} }}\n* {{ Cite book | first1 = Richard S. | last1 = Varga | chapter = Factorization and Normalized Iterative Methods | title = Boundary Problems in Differential Equations | editor1-last = Langer | editor1-first = Rudolph E. | publisher = [[University of Wisconsin Press]] | location = Madison | pages = 121&ndash;142 | year = 1960 | lccn = 60-60003 | ref = {{harvid|Varga|1960}} }}\n* {{ citation | first1 = Richard S. | last1 = Varga | title = Matrix Iterative Analysis | publisher = [[Prentice–Hall]] | location = New Jersey | year = 1962 | lccn = 62-21277 }}.\n\n{{Numerical linear algebra}}\n\n[[Category:Limits (mathematics)]]\n[[Category:Matrices]]\n[[Category:Numerical linear algebra]]\n[[Category:Relaxation (iterative methods)]]"
    },
    {
      "title": "Gauss–Seidel method",
      "url": "https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method",
      "text": "In [[numerical linear algebra]], the '''Gauss–Seidel method''', also known as the '''Liebmann method''' or the '''method of successive displacement''',  is an [[iterative method]] used to solve a [[linear system of equations]]. It is named after the [[Germany|German]] [[mathematician]]s [[Carl Friedrich Gauss]] and [[Philipp Ludwig von Seidel]], and is similar to the [[Jacobi method]]. Though it can be applied to any matrix with non-zero elements on the diagonals, convergence is only guaranteed if the matrix is either [[diagonally dominant matrix|diagonally dominant]], or [[Symmetric matrix|symmetric]] and [[Positive-definite matrix|positive definite]]. It was only mentioned in a private letter from Gauss to his student [[Christian Ludwig Gerling|Gerling]] in 1823.<ref>\n{{harvnb|Gauss|1903|p=279}}; [http://gdz.sub.uni-goettingen.de/en/dms/loader/img/?PPN=PPN23601515X&DMDID=DMDLOG_0112&LOGID=LOG_0112&PHYSID=PHYS_0286 direct link].</ref> A publication was not delivered before 1874 by Seidel.\n\n== Description ==\nThe Gauss–Seidel method is an [[Iterative method|iterative technique]] for solving a square system of ''n'' linear equations with unknown '''x''':\n\n:<math>A\\mathbf x = \\mathbf b</math>.\n\nIt is defined by the iteration\n\n:<math> L_* \\mathbf{x}^{(k+1)} = \\mathbf{b} - U \\mathbf{x}^{(k)}, </math>\n\nwhere <math>\\mathbf{x}^{(k)}</math> is the ''k''th approximation or iteration of <math>\\mathbf{x},\\,\\mathbf{x}^{(k+1)}</math> is the next or ''k'' + 1 iteration of <math>\\mathbf{x}</math>, and the matrix ''A'' is decomposed into a [[triangular matrix|lower triangular]] component <math>L_*</math>, and a [[triangular matrix#Strictly triangular matrix|strictly upper triangular]] component ''U'': <math> A = L_* + U </math>.<ref>{{harvnb|Golub|Van Loan|1996|p=511}}.</ref>\n\nIn more detail, write out ''A'', '''x''' and '''b''' in their components:\n\n:<math>A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\a_{n1} & a_{n2} & \\cdots & a_{nn} \\end{bmatrix}, \\qquad  \\mathbf{x} = \\begin{bmatrix} x_{1} \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} , \\qquad  \\mathbf{b} = \\begin{bmatrix} b_{1} \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix}.</math>\n\nThen the decomposition of ''A'' into its lower triangular component and its strictly upper triangular component is given by:\n\n:<math>A=L_*+U \\qquad \\text{where} \\qquad L_* = \\begin{bmatrix} a_{11} & 0 & \\cdots & 0 \\\\ a_{21} & a_{22} & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\a_{n1} & a_{n2} & \\cdots & a_{nn} \\end{bmatrix}, \\quad U = \\begin{bmatrix} 0 & a_{12} & \\cdots & a_{1n} \\\\ 0 & 0 & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\0 & 0 & \\cdots & 0 \\end{bmatrix}. </math>\n\nThe system of linear equations may be rewritten as:\n\n:<math>L_* \\mathbf{x} = \\mathbf{b} - U \\mathbf{x} </math>\n\nThe Gauss–Seidel method now solves the left hand side of this expression for '''x''', using previous value for '''x''' on the right hand side. Analytically, this may be written as:\n\n:<math> \\mathbf{x}^{(k+1)} = L_*^{-1} (\\mathbf{b} - U \\mathbf{x}^{(k)}). </math>\n\nHowever, by taking advantage of the triangular form of <math>L_*</math>, the elements of '''x'''<sup>(''k''+1)</sup> can be computed sequentially using [[forward substitution]]:\n\n:<math> x^{(k+1)}_i  = \\frac{1}{a_{ii}} \\left(b_i - \\sum_{j=1}^{i-1}a_{ij}x^{(k+1)}_j - \\sum_{j=i+1}^{n}a_{ij}x^{(k)}_j \\right),\\quad i=1,2,\\dots,n. </math> <ref>{{harvnb|Golub|Van Loan|1996|loc=eqn (10.1.3)}}.</ref>\n\nThe procedure is generally continued until the changes made by an iteration are below some tolerance, such as a sufficiently small [[Residual (numerical analysis)|residual]].\n\n=== Discussion ===\nThe element-wise formula for the Gauss–Seidel method is extremely similar to that of the [[Jacobi method]].\n\nThe computation of ''x''<sup>(''k''+1)</sup> uses the elements of '''x'''<sup>(''k''+1)</sup> that have already been computed, and only the elements of '''x'''<sup>(''k'')</sup> that have not been computed in the k+1 iteration. This means that, unlike the Jacobi method, only one storage vector is required as elements can be overwritten as they are computed, which can be advantageous for very large problems.\n\nHowever, unlike the Jacobi method, the computations for each element cannot be done in [[Parallel algorithm|parallel]]. Furthermore, the values at each iteration are dependent on the order of the original equations.\n\nGauss-Seidel is the same as [[Successive Over-relaxation|SOR (successive over-relaxation)]] with <math>\\omega=1</math>.\n\n==Convergence==\nThe convergence properties of the Gauss–Seidel method are dependent on the matrix ''A''. Namely, the procedure is known to converge if either:\n* ''A'' is symmetric [[positive-definite matrix|positive-definite]],<ref>{{harvnb|Golub|Van Loan|1996|loc=Thm 10.1.2}}.</ref> or\n* ''A'' is strictly or irreducibly [[diagonally dominant matrix|diagonally dominant]].\n\nThe Gauss–Seidel method sometimes converges even if these conditions are not satisfied.\n\n== Algorithm ==\n\nSince elements can be overwritten as they are computed in this algorithm, only one storage vector is needed, and vector indexing is omitted. The algorithm goes as follows:\n\n Inputs: {{var|A}}, {{var|b}}\n {{nowrap|Output: <math>\\phi</math>}}\n \n {{nowrap|Choose an initial guess <math>\\phi</math> to the solution}}\n '''repeat''' until convergence\n     '''for''' {{var|i}} '''from''' 1 '''until''' {{var|n}} '''do'''\n         {{nowrap|<math>\\sigma \\leftarrow 0</math>}}\n         '''for''' {{var|j}} '''from''' 1 '''until''' {{var|n}} '''do'''\n             '''if''' {{var|j}} &ne; {{var|i}} '''then'''\n                 {{nowrap|<math> \\sigma \\leftarrow \\sigma + a_{ij} \\phi_j </math>}}\n             '''end if'''\n         '''end''' ({{var|j}}-loop)\n         {{nowrap|<math> \\phi_i \\leftarrow \\frac 1 {a_{ii}} (b_i - \\sigma)</math>}}\n     '''end''' ({{var|i}}-loop)\n     check if convergence is reached\n '''end''' (repeat)\n\n==Examples==\n\n===An example for the matrix version===\n\nA linear system shown as <math>A \\mathbf{x} = \\mathbf{b}</math> is given by:\n\n:<math> A=\n      \\begin{bmatrix}\n           16  &   3 \\\\\n            7  & -11 \\\\\n           \\end{bmatrix}\n</math> and <math> b=\n      \\begin{bmatrix}\n           11 \\\\\n           13\n           \\end{bmatrix}.\n</math>\n\nWe want to use the equation\n\n:<math> \\mathbf{x}^{(k+1)} = L_*^{-1} (\\mathbf{b} - U \\mathbf{x}^{(k)}) </math>\n\nin the form\n\n:<math> \\mathbf{x}^{(k+1)} = T \\mathbf{x}^{(k)} + C </math>\n\nwhere:\n\n:<math>T = - L_*^{-1} U</math> and <math>C = L_*^{-1} \\mathbf{b}.</math>\n\nWe must decompose <math>A_{}^{}</math> into the sum of a lower triangular component <math>L_*^{}</math> and a strict upper triangular component <math>U_{}^{}</math>:\n\n:<math> L_*=\n      \\begin{bmatrix}\n           16 &   0 \\\\\n           7  & -11 \\\\\n           \\end{bmatrix}\n</math>  and <math> U =\n        \\begin{bmatrix}\n           0 & 3 \\\\\n           0 & 0\n        \\end{bmatrix}.</math>\n\nThe inverse of <math>L_*^{}</math> is:\n:<math> L_*^{-1} =\n      \\begin{bmatrix}\n           16 &   0 \\\\\n           7  & -11\n           \\end{bmatrix}^{-1}\n      =\n      \\begin{bmatrix}\n           0.0625 &  0.0000 \\\\\n           0.0398 & -0.0909 \\\\\n           \\end{bmatrix}\n</math>.\n\nNow we can find:\n:<math> T = - \n      \\begin{bmatrix}\n           0.0625 &  0.0000 \\\\\n           0.0398 & -0.0909\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           0 & 3 \\\\\n           0 & 0\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.000 & -0.1875 \\\\\n           0.000 & -0.1194\n      \\end{bmatrix},  </math>\n\n:<math> C = \n      \\begin{bmatrix}\n           0.0625 &  0.0000 \\\\\n           0.0398 & -0.0909\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           11 \\\\\n           13\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.6875 \\\\\n          -0.7439\n      \\end{bmatrix}.  </math>\n\nNow we have <math>T_{}^{}</math> and <math>C_{}^{}</math> and we can use them to obtain the vectors <math>\\mathbf{x}</math> iteratively.\n\nFirst of all, we have to choose <math>\\mathbf{x}^{(0)}</math>: we can only guess. The better the guess, the quicker the algorithm will perform.\n\nWe suppose:\n\n:<math> x^{(0)} =\n        \\begin{bmatrix}\n           1.0 \\\\\n           1.0\n        \\end{bmatrix}.</math>\n\nWe can then calculate:\n\n:<math> x^{(1)} = \n      \\begin{bmatrix}\n           0.000 & -0.1875 \\\\\n           0.000 & -0.1193\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           1.0 \\\\\n           1.0\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           0.6875 \\\\\n          -0.7443\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.5000 \\\\\n          -0.8636\n      \\end{bmatrix}.  </math>\n\n:<math> x^{(2)} =\n      \\begin{bmatrix}\n           0.000 & -0.1875 \\\\\n           0.000 & -0.1193\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           0.5000 \\\\\n          -0.8636\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           0.6875 \\\\\n          -0.7443\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.8494 \\\\\n          -0.6413\n      \\end{bmatrix}.  </math>\n\n:<math> x^{(3)} =\n      \\begin{bmatrix}\n           0.000 & -0.1875 \\\\\n           0.000 & -0.1193\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           0.8494 \\\\\n          -0.6413 \\\\\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           0.6875 \\\\\n          -0.7443\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.8077 \\\\\n          -0.6678\n      \\end{bmatrix}.  </math>\n\n:<math> x^{(4)} =\n      \\begin{bmatrix}\n           0.000 & -0.1875 \\\\\n           0.000 & -0.1193\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           0.8077 \\\\\n          -0.6678\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           0.6875 \\\\\n          -0.7443\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.8127 \\\\\n          -0.6646\n      \\end{bmatrix}.  </math>\n\n:<math> x^{(5)} =\n      \\begin{bmatrix}\n           0.000 & -0.1875 \\\\\n           0.000 & -0.1193\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           0.8127 \\\\\n          -0.6646\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           0.6875 \\\\\n          -0.7443\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.8121 \\\\\n          -0.6650\n      \\end{bmatrix}.  </math>\n\n:<math> x^{(6)} =\n      \\begin{bmatrix}\n           0.000 & -0.1875 \\\\\n           0.000 & -0.1193\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           0.8121 \\\\\n          -0.6650\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           0.6875 \\\\\n          -0.7443\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.8122 \\\\\n          -0.6650\n      \\end{bmatrix}.  </math>\n\n:<math> x^{(7)} =\n      \\begin{bmatrix}\n           0.000 & -0.1875 \\\\\n           0.000 & -0.1193\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           0.8122 \\\\\n          -0.6650\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           0.6875 \\\\\n          -0.7443\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.8122 \\\\\n          -0.6650\n      \\end{bmatrix}.  </math>\n\nAs expected, the algorithm converges to the exact solution:\n\n:<math> \\mathbf{x} = A^{-1} \\mathbf{b} \\approx \\begin{bmatrix} 0.8122\\\\ -0.6650 \\end{bmatrix}. </math>\n\nIn fact, the matrix A is strictly diagonally dominant (but not positive definite).\n\n===Another example for the matrix version===\n\nAnother linear system shown as <math>A \\mathbf{x} = \\mathbf{b}</math> is given by:\n\n:<math> A=\n      \\begin{bmatrix}\n           2 & 3 \\\\\n           5 & 7 \\\\\n           \\end{bmatrix}\n</math> and <math> b=\n      \\begin{bmatrix}\n           11 \\\\\n           13 \\\\\n           \\end{bmatrix}.\n</math>\n\nWe want to use the equation\n\n:<math> \\mathbf{x}^{(k+1)} = L_*^{-1} (\\mathbf{b} - U \\mathbf{x}^{(k)}) </math>\n\nin the form\n\n:<math> \\mathbf{x}^{(k+1)} = T \\mathbf{x}^{(k)} + C </math>\n\nwhere:\n\n:<math>T = - L_*^{-1} U</math> and <math>C = L_*^{-1} \\mathbf{b}.</math>\n\nWe must decompose <math>A_{}^{}</math> into the sum of a lower triangular component <math>L_*^{}</math> and a strict upper triangular component <math>U_{}^{}</math>:\n\n:<math> L_*=\n      \\begin{bmatrix}\n           2 & 0 \\\\\n           5 & 7 \\\\\n           \\end{bmatrix}\n</math>  and <math> U =\n        \\begin{bmatrix}\n           0 & 3 \\\\\n           0 & 0 \\\\\n        \\end{bmatrix}.</math>\n\nThe inverse of <math>L_*^{}</math> is:\n:<math> L_*^{-1} =\n      \\begin{bmatrix}\n           2 & 0 \\\\\n           5 & 7 \\\\\n           \\end{bmatrix}^{-1}\n      =\n      \\begin{bmatrix}\n           0.500 & 0.000 \\\\\n          -0.357 & 0.143 \\\\\n           \\end{bmatrix}\n</math>.\n\nNow we can find:\n:<math> T = - \n      \\begin{bmatrix}\n           0.500 & 0.000 \\\\\n          -0.357 & 0.143 \\\\\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           0 & 3 \\\\\n           0 & 0 \\\\\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           0.000 & -1.500 \\\\\n           0.000 &  1.071 \\\\\n      \\end{bmatrix},  </math>\n\n:<math> C = \n      \\begin{bmatrix}\n           0.500 & 0.000 \\\\\n          -0.357 & 0.143 \\\\\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           11 \\\\\n           13 \\\\\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           5.500 \\\\\n          -2.071 \\\\\n      \\end{bmatrix}.  </math>\n\nNow we have <math>T_{}^{}</math> and <math>C_{}^{}</math> and we can use them to obtain the vectors <math>\\mathbf{x}</math> iteratively.\n\nFirst of all, we have to choose <math>\\mathbf{x}^{(0)}</math>: we can only guess. The better the guess, the quicker will perform the algorithm.\n\nWe suppose:\n\n:<math> x^{(0)} =\n        \\begin{bmatrix}\n           1.1 \\\\\n           2.3 \\\\\n        \\end{bmatrix}.</math>\n\nWe can then calculate:\n\n:<math> x^{(1)} = \n      \\begin{bmatrix}\n           0 & -1.500 \\\\\n           0 &  1.071 \\\\\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           1.1 \\\\\n           2.3 \\\\\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           5.500 \\\\\n          -2.071 \\\\\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           2.050 \\\\\n           0.393 \\\\\n      \\end{bmatrix}.  </math>\n\n:<math> x^{(2)} =\n      \\begin{bmatrix}\n           0 & -1.500 \\\\\n           0 &  1.071 \\\\\n      \\end{bmatrix}\n      \\times\n      \\begin{bmatrix}\n           2.050 \\\\\n           0.393 \\\\\n      \\end{bmatrix}\n      +\n      \\begin{bmatrix}\n           5.500 \\\\\n          -2.071 \\\\\n      \\end{bmatrix}  \n      =\n      \\begin{bmatrix}\n           4.911 \\\\\n          -1.651 \\\\\n      \\end{bmatrix}.  </math>\n\n:<math> x^{(3)} = \\cdots. \\,  </math>\n\nIf we test for convergence we'll find that the algorithm diverges. In fact, the matrix A is neither diagonally dominant nor positive definite.\nThen, convergence to the exact solution\n\n:<math> \\mathbf{x} = A^{-1} \\mathbf{b} = \\begin{bmatrix} -38\\\\ 29 \\end{bmatrix} </math>\n\nis not guaranteed and, in this case, will not occur.\n\n===An example for the equation version===\n\nSuppose given ''k'' equations where ''x''<sub>''n''</sub> are vectors of these equations and starting point ''x''<sub>0</sub>.\nFrom the first equation solve for ''x''<sub>1</sub> in terms of <math>x_{n+1}, x_{n+2}, \\dots, x_n.</math>  For the next equations substitute the previous values of&nbsp;''x''s.\n\nTo make it clear consider an example.\n\n:<math>\n\\begin{array}{rrrrl}\n10x_1 &-   x_2 &+  2x_3 &       & = 6, \\\\\n -x_1 &+ 11x_2 &-   x_3 &+ 3x_4 & =  25, \\\\\n 2x_1 &-   x_2 &+ 10x_3 &-  x_4 & =  -11, \\\\\n      &   3x_2 &-   x_3 &+ 8x_4 & =  15.\n\\end{array}\n</math>\n\nSolving for <math>x_1, x_2, x_3</math> and <math>x_4</math> gives:\n\n:<math>\n\\begin{align}\nx_1 & = x_2/10 - x_3/5 + 3/5, \\\\           \nx_2 & = x_1/11 + x_3/11 - 3x_4/11 + 25/11, \\\\\nx_3 & = -x_1/5  + x_2/10 + x_4/10  - 11/10, \\\\\nx_4 & = -3x_2/8  + x_3/8 + 15/8.\n\\end{align}\n</math>\n\nSuppose we choose {{math|(0,&nbsp;0,&nbsp;0,&nbsp;0)}} as the initial approximation, then the first\napproximate solution is given by\n\n:<math>\n\\begin{align}\nx_1 & = 3/5 = 0.6, \\\\\nx_2 & = (3/5)/11 + 25/11 = 3/55 + 25/11 = 2.3272, \\\\\nx_3 & = -(3/5)/5 +(2.3272)/10-11/10 = -3/25 + 0.23272-1.1 = -0.9873,\\\\ \nx_4 & = -3(2.3272)/8 +(-0.9873)/8+15/8 = 0.8789.\n\\end{align}\n</math>\n\nUsing the approximations obtained, the iterative procedure is repeated until\nthe desired accuracy has been reached.  The following are the approximated\nsolutions after four iterations.\n\n:<math>\\begin{array}{llll}\nx_1 &\nx_2 &\nx_3 &\nx_4\n\\\\\n\\hline\n0.6 &\n2.32727 &\n-0.987273 &\n0.878864\n\\\\\n1.03018 &\n2.03694 &\n-1.01446 &\n0.984341\n\\\\\n1.00659 &\n2.00356 &\n-1.00253 &\n0.998351\n\\\\\n1.00086 &\n2.0003 &\n-1.00031 &\n0.99985\n\\end{array}</math>\n\nThe exact solution of the system is {{math|(1,&nbsp;2,&nbsp;&minus;1,&nbsp;1)}}.\n\n===An example using Python and NumPy===\nThe following numerical procedure simply iterates to produce the solution vector.\n\n<source lang=\"numpy\">\nimport numpy as np\n\nITERATION_LIMIT = 1000\n\n# initialize the matrix\nA = np.array([[10., -1., 2., 0.],\n              [-1., 11., -1., 3.],\n              [2., -1., 10., -1.],\n              [0., 3., -1., 8.]])\n# initialize the RHS vector\nb = np.array([6., 25., -11., 15.])\n\nprint(\"System of equations:\")\nfor i in range(A.shape[0]):\n    row = [\"{0:3g}*x{1}\".format(A[i, j], j + 1) for j in range(A.shape[1])]\n    print(\"[{0}] = [{1:3g}]\".format(\" + \".join(row), b[i]))\n\nx = np.zeros_like(b)\nfor it_count in range(1, ITERATION_LIMIT):\n    x_new = np.zeros_like(x)\n    print(\"Iteration {0}: {1}\".format(it_count, x))\n    for i in range(A.shape[0]):\n        s1 = np.dot(A[i, :i], x_new[:i])\n        s2 = np.dot(A[i, i + 1:], x[i + 1:])\n        x_new[i] = (b[i] - s1 - s2) / A[i, i]\n    if np.allclose(x, x_new, rtol=1e-8):\n        break\n    x = x_new\n\nprint(\"Solution: {0}\".format(x))\nerror = np.dot(A, x) - b\nprint(\"Error: {0}\".format(error))\n</source>\n\nProduces the output:\n\n<source lang=\"python\">\nSystem of equations:\n[ 10*x1 +  -1*x2 +   2*x3 +   0*x4] = [  6]\n[ -1*x1 +  11*x2 +  -1*x3 +   3*x4] = [ 25]\n[  2*x1 +  -1*x2 +  10*x3 +  -1*x4] = [-11]\n[  0*x1 +   3*x2 +  -1*x3 +   8*x4] = [ 15]\nIteration 1: [ 0.  0.  0.  0.]\nIteration 2: [ 0.6         2.32727273 -0.98727273  0.87886364]\nIteration 3: [ 1.03018182  2.03693802 -1.0144562   0.98434122]\nIteration 4: [ 1.00658504  2.00355502 -1.00252738  0.99835095]\nIteration 5: [ 1.00086098  2.00029825 -1.00030728  0.99984975]\nIteration 6: [ 1.00009128  2.00002134 -1.00003115  0.9999881 ]\nIteration 7: [ 1.00000836  2.00000117 -1.00000275  0.99999922]\nIteration 8: [ 1.00000067  2.00000002 -1.00000021  0.99999996]\nIteration 9: [ 1.00000004  1.99999999 -1.00000001  1.        ]\nIteration 10: [ 1.  2. -1.  1.]\nSolution: [ 1.  2. -1.  1.]\nError: [  2.06480930e-08  -1.25551054e-08   3.61417563e-11   0.00000000e+00]\n</source>\n\n===Program to solve arbitrary no. of equations using Matlab===\nThe following code uses the formula\n<math>x^{(k+1)}_i  = \\frac{1}{a_{ii}} \\left(b_i - \\sum_{j<i}a_{ij}x^{(k+1)}_j - \\sum_{j>i}a_{ij}x^{(k)}_j \\right),\\quad i,j=1,2,\\ldots,n</math>\n<source lang=\"matlab\">\nfunction [x] = gauss_seidel(A, b, x0, iters)\n    n = length(A);\n    x = x0;\n    for k = 1:iters\n        for i = 1:n\n            x(i) = (1/A(i, i))*(b(i) - A(i, 1:n)*x + A(i, i)*x(i));\n        end\n    end\nend\n</source>\n\n==See also==\n*[[Successive over-relaxation]]\n*[[Kaczmarz method]] (a \"row-oriented\" method, whereas Gauss-Seidel is \"column-oriented.\" See e.g. [https://arxiv.org/abs/1507.05844 this paper].)\n*[[Iterative method#Linear systems|Iterative method. Linear systems]]\n*[[Belief propagation#Gaussian belief propagation .28GaBP.29|Gaussian belief propagation]]\n*[[Matrix splitting]]\n*[[Richardson iteration]]\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{citation | first = Carl Friedrich | last = Gauss | authorlink = Carl Friedrich Gauss | title = Werke | publisher = Köninglichen Gesellschaft der Wissenschaften | location = Göttingen | date = 1903 | volume = 9 | language = German}}.\n* {{citation | first1=Gene H. | last1=Golub | author1-link=Gene H. Golub | first2=Charles F. | last2=Van Loan | author2-link=Charles F. Van Loan | year=1996 | title=Matrix Computations | edition=3rd | publisher=Johns Hopkins | place=Baltimore | isbn=978-0-8018-5414-9}}.\n*{{MathWorld|urlname=Gauss-SeidelMethod|title=Gauss-Seidel Method|author=Black, Noel and Moore, Shirley}}\n{{CFDWiki|name=Gauss-Seidel_method}}\n\n==External links==\n*{{springer|title=Seidel method|id=p/s083810}}\n*[http://www.math-linux.com/spip.php?article48 Gauss–Seidel from www.math-linux.com]\n*[http://numericalmethods.eng.usf.edu/topics/gauss_seidel.html Gauss–Seidel] From Holistic Numerical Methods Institute\n*[https://www.webcitation.org/query?url=http://www.geocities.com/rsrirang2001/Mathematics/NumericalMethods/gsiedel/gsiedel.htm&date=2009-10-26+01:52:27  Gauss Siedel Iteration from www.geocities.com]\n*[http://www.netlib.org/linalg/html_templates/node14.html#figgs  The Gauss-Seidel Method]\n*[https://arxiv.org/abs/0901.4192 Bickson]\n*[http://matlabdb.mathematik.uni-stuttgart.de/gauss_seidel.m?MP_ID=406 Matlab code]\n*[http://adrianboeing.blogspot.com/2010/02/solving-linear-systems.html C code example]\n{{Numerical linear algebra}}\n\n{{DEFAULTSORT:Gauss-Seidel Method}}\n[[Category:Numerical linear algebra]]\n[[Category:Articles with example pseudocode]]\n[[Category:Relaxation (iterative methods)]]\n[[Category:Articles with example Python code]]\n[[Category:Articles with example MATLAB/Octave code]]"
    },
    {
      "title": "Jacobi method",
      "url": "https://en.wikipedia.org/wiki/Jacobi_method",
      "text": "{{confused|Jacobi eigenvalue algorithm}}\n\nIn [[numerical linear algebra]], the '''Jacobi method''' is an iterative algorithm for determining the solutions of a [[Diagonally dominant matrix|diagonally dominant]] [[system of linear equations]]. Each diagonal element is solved for, and an approximate value is plugged in. The process is then iterated until it converges. This algorithm is a stripped-down version of the [[Jacobi eigenvalue algorithm|Jacobi transformation method of matrix diagonalization]]. The method is named after [[Carl Gustav Jacob Jacobi]].\n\n== Description ==\nLet\n\n:<math>A\\mathbf x = \\mathbf b</math>\n\nbe a square system of ''n'' linear equations, where:\n\n<math>A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\a_{n1} & a_{n2} & \\cdots & a_{nn} \\end{bmatrix}, \\qquad  \\mathbf{x} = \\begin{bmatrix} x_{1} \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} , \\qquad  \\mathbf{b} = \\begin{bmatrix} b_{1} \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix}.</math>\n\nThen ''A'' can be decomposed into a [[diagonal matrix|diagonal]] component ''D'', and the remainder ''R'':\n\n:<math>A=D+R \\qquad \\text{where} \\qquad D = \\begin{bmatrix} a_{11} & 0 & \\cdots & 0 \\\\ 0 & a_{22} & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\0 & 0 & \\cdots & a_{nn} \\end{bmatrix} \\text{ and } R = \\begin{bmatrix} 0 & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & 0 & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{n1} & a_{n2} & \\cdots & 0 \\end{bmatrix}. </math>\n\nThe solution is then obtained iteratively via\n:<math> \\mathbf{x}^{(k+1)} = D^{-1} (\\mathbf{b} - R \\mathbf{x}^{(k)}), </math>\n\nwhere <math>\\mathbf{x}^{(k)}</math> is the ''k''th approximation or iteration of <math>\\mathbf{x}</math> and <math>\\mathbf{x}^{(k+1)}</math> is the next or ''k'' + 1 iteration of <math>\\mathbf{x}</math>. The element-based formula is thus:\n\n:<math> x^{(k+1)}_i  = \\frac{1}{a_{ii}} \\left(b_i -\\sum_{j\\ne i}a_{ij}x^{(k)}_j\\right),\\quad i=1,2,\\ldots,n. </math>\n\nThe computation of ''x''<sub>''i''</sub><sup>(''k''+1)</sup> requires each element in '''x'''<sup>(''k'')</sup> except itself. Unlike the [[Gauss–Seidel method]], we can't overwrite ''x''<sub>''i''</sub><sup>(''k'')</sup> with ''x''<sub>''i''</sub><sup>(''k''+1)</sup>, as that value will be needed by the rest of the computation. The minimum amount of storage is two vectors of size ''n''.\n\n== Algorithm ==\n '''Input:''' {{nowrap|initial guess <math>x^{(0)}</math> to the solution}}, (diagonal dominant) matrix <math>A</math>, right-hand side vector <math>b</math>, convergence criterion\n '''Output:''' {{nowrap|solution when convergence is reached}}\n '''Comments:''' {{nowrap|pseudocode based on the element-based formula above}}\n\n {{nowrap|<math> k = 0 </math>}}\n '''while''' convergence not reached '''do'''\n     '''for''' i := 1 '''step until''' n '''do'''\n       {{nowrap|<math> \\sigma = 0 </math>}}  \n       '''for''' j := 1 '''step until''' n '''do'''\n         '''if''' j &ne; i '''then'''\n           {{nowrap|<math> \\sigma  = \\sigma  + a_{ij} x_j^{(k)} </math>}}\n         '''end'''\n       '''end'''\n       {{nowrap|<math>  x_i^{(k+1)}  = {{\\frac{1}{a_{ii}} \\left( {b_i  - \\sigma } \\right)}} </math>}}\n     '''end'''\n     {{nowrap|<math>k = k + 1</math>}}\n '''end'''\n\n==Convergence==\n<!-- [[Matrix splitting]] links here.  Please do not change. -->\n\nThe standard convergence condition (for any iterative method) is when the [[spectral radius]] of the iteration matrix is less than 1:\n\n:<math>\\rho(D^{-1}R) < 1. </math>\n\nA sufficient (but not necessary) condition for the method to converge is that the matrix ''A'' is strictly or irreducibly [[diagonally dominant matrix|diagonally dominant]]. Strict row diagonal dominance means that for each row, the absolute value of the diagonal term is greater than the sum of absolute values of other terms:\n\n:<math>\\left | a_{ii} \\right | > \\sum_{j \\ne i} {\\left | a_{ij} \\right |}. </math>\n\nThe Jacobi method sometimes converges even if these conditions are not satisfied.\n\nNote that the Jacobi method does not converge for every symmetric [[positive-definite matrix]].\nFor example,\n:<math>\nA = \n\\begin{pmatrix}\n  1 & 2 \\\\\n  2 & 1\n\\end{pmatrix}\n\\quad \\Rightarrow \\quad\nD^{-1} R = \n\\begin{pmatrix}\n  0 & 2 \\\\\n  2 & 0\n\\end{pmatrix}\n\\quad \\Rightarrow \\quad\n\\rho(D^{-1}R) = 2 \\,.\n</math>\n\n==Example==\nA linear system of the form <math>Ax=b</math> with initial estimate <math>x^{(0)}</math> is given by\n\n:<math> A=\n      \\begin{bmatrix}\n           2 & 1 \\\\\n           5 & 7 \\\\\n           \\end{bmatrix},\n \\ b=\n      \\begin{bmatrix}\n           11 \\\\\n           13 \\\\\n           \\end{bmatrix}\n\\quad \\text{and} \\quad x^{(0)} =\n        \\begin{bmatrix}\n           1 \\\\\n           1 \\\\\n        \\end{bmatrix} .</math>\nWe use the equation <math> x^{(k+1)}=D^{-1}(b - Rx^{(k)})</math>, described above, to estimate <math>x</math>. First, we rewrite the equation in a more convenient form <math>D^{-1}(b - Rx^{(k)}) = Tx^{(k)} + C</math>, where <math>T=-D^{-1}R</math> and <math>C = D^{-1}b</math>.  Note that <math>R=L+U</math> where <math>L</math> and <math>U</math> are the strictly lower and upper parts of <math>A</math>.  From the known values\n\n:<math> D^{-1}=\n      \\begin{bmatrix}\n           1/2 & 0 \\\\\n           0 & 1/7 \\\\\n           \\end{bmatrix}, \n \\ L=\n      \\begin{bmatrix}\n           0 & 0 \\\\\n           5 & 0 \\\\\n           \\end{bmatrix}\n\\quad \\text{and}  \\quad U =\n        \\begin{bmatrix}\n           0 & 1 \\\\\n           0 & 0 \\\\\n        \\end{bmatrix} .</math>\nwe determine <math> T=-D^{-1}(L+U) </math> as\n:<math> T=\n      \\begin{bmatrix}\n           1/2 & 0 \\\\\n           0 & 1/7 \\\\\n           \\end{bmatrix}\n\\left\\{\n      \\begin{bmatrix}\n           0 & 0 \\\\\n           -5 & 0 \\\\\n           \\end{bmatrix}\n +\n        \\begin{bmatrix}\n           0 & -1 \\\\\n           0 & 0 \\\\\n        \\end{bmatrix}\\right\\}  \n =\n        \\begin{bmatrix}\n           0 & -1/2 \\\\\n           -5/7 & 0 \\\\\n        \\end{bmatrix}  .</math>\nFurther, <math>C</math> is found as\n\n:<math> C =\n      \\begin{bmatrix}\n           1/2 & 0 \\\\\n           0 & 1/7 \\\\\n           \\end{bmatrix}\n      \\begin{bmatrix}\n           11 \\\\\n           13 \\\\\n           \\end{bmatrix}\n =\n        \\begin{bmatrix}\n           11/2 \\\\\n           13/7 \\\\\n        \\end{bmatrix}. </math>\nWith <math>T</math> and <math>C</math> calculated, we estimate <math>x</math> as <math> x^{(1)}= Tx^{(0)}+C </math>:\n:<math> x^{(1)}= \n      \\begin{bmatrix}\n           0 & -1/2 \\\\\n           -5/7 & 0 \\\\\n           \\end{bmatrix}\n      \\begin{bmatrix}\n           1 \\\\\n           1 \\\\\n           \\end{bmatrix}\n +\n        \\begin{bmatrix}\n           11/2 \\\\\n           13/7 \\\\\n        \\end{bmatrix}  \n =\n        \\begin{bmatrix}\n           5.0 \\\\\n           8/7 \\\\\n        \\end{bmatrix}  \n\\approx\n        \\begin{bmatrix}\n           5 \\\\\n           1.143 \\\\\n        \\end{bmatrix} .</math>\nThe next iteration yields\n:<math> x^{(2)}= \n      \\begin{bmatrix}\n           0 & -1/2 \\\\\n           -5/7 & 0 \\\\\n           \\end{bmatrix}\n\n      \\begin{bmatrix}\n           5.0 \\\\\n           8/7 \\\\\n           \\end{bmatrix}\n +\n        \\begin{bmatrix}\n           11/2 \\\\\n           13/7 \\\\\n        \\end{bmatrix} \n= \n        \\begin{bmatrix}\n           69/14 \\\\\n           -12/7 \\\\\n        \\end{bmatrix} \n \\approx\n        \\begin{bmatrix}\n           4.929 \\\\\n           -1.714 \\\\\n        \\end{bmatrix} .</math>\nThis process is repeated until convergence (i.e., until <math>\\|Ax^{(n)} - b\\|</math> is small).  The solution after 25 iterations is\n:<math> x=\\begin{bmatrix}\n7.111\\\\\n-3.222\n\\end{bmatrix}\n.</math>\n\n===Another example===\n\nSuppose we are given the following linear system:\n\n:<math>\n\\begin{align}\n10x_1 -   x_2 +  2x_3 & = 6, \\\\\n-x_1 + 11x_2 -   x_3 + 3x_4 & =  25, \\\\\n2x_1-  x_2+  10x_3 -  x_4 & =  -11, \\\\\n3x_2 -   x_3 +  8x_4 & =  15.\n\\end{align}\n</math>\n\nIf we choose {{math|(0,&nbsp;0,&nbsp;0,&nbsp;0)}} as the initial approximation, then the first approximate solution is given by\n\n:<math>\n\\begin{align}\nx_1 & = (6 + 0 - (2 * 0)) / 10 = 0.6, \\\\\nx_2 & = (25 + 0 - 0 - (3 * 0)) / 11 = 25/11 = 2.2727, \\\\\nx_3 & = (-11 - (2 * 0) + 0 + 0) / 10 = -1.1,\\\\ \nx_4 & = (15 - (3 * 0) + 0) / 8 = 1.875.\n\\end{align}\n</math>\n\nUsing the approximations obtained, the iterative procedure is repeated until the desired accuracy has been reached. The following are the approximated solutions after five iterations.\n\n{| class=\"wikitable\" border=\"1\"\n|-\n! <math>x_1</math>\n! <math>x_2</math>\n! <math>x_3</math>\n! <math>x_4</math>\n|-\n| 0.6\n| 2.27272\n| -1.1\n| 1.875\n|-\n| 1.04727\n| 1.7159\n| -0.80522\n| 0.88522\n|-\n| 0.93263\n| 2.05330\n| -1.0493\n| 1.13088\n|-\n| 1.01519\n| 1.95369\n| -0.9681\n| 0.97384\n|-\n| 0.98899\n| 2.0114\n| -1.0102\n| 1.02135\n|}\nThe exact solution of the system is {{math|(1,&nbsp;2,&nbsp;&minus;1,&nbsp;1)}}.\n\n===An example using Python and Numpy ===\nThe following numerical procedure simply iterates to produce the solution vector.\n\n<source lang=\"numpy\">\nimport numpy as np\n\nITERATION_LIMIT = 1000\n\n# initialize the matrix\nA = np.array([[10., -1., 2., 0.],\n              [-1., 11., -1., 3.],\n              [2., -1., 10., -1.],\n              [0.0, 3., -1., 8.]])\n# initialize the RHS vector\nb = np.array([6., 25., -11., 15.])\n\n# prints the system\nprint(\"System:\")\nfor i in range(A.shape[0]):\n    row = [\"{}*x{}\".format(A[i, j], j + 1) for j in range(A.shape[1])]\n    print(\" + \".join(row), \"=\", b[i])\nprint()\n\nx = np.zeros_like(b)\nfor it_count in range(ITERATION_LIMIT):\n    print(\"Current solution:\", x)\n    x_new = np.zeros_like(x)\n\n    for i in range(A.shape[0]):\n        s1 = np.dot(A[i, :i], x[:i])\n        s2 = np.dot(A[i, i + 1:], x[i + 1:])\n        x_new[i] = (b[i] - s1 - s2) / A[i, i]\n\n    if np.allclose(x, x_new, atol=1e-10, rtol=0.):\n        break\n\n    x = x_new\n\nprint(\"Solution:\")\nprint(x)\nerror = np.dot(A, x) - b\nprint(\"Error:\")\nprint(error)\n</source>\n\nProduces the output:\n\n<pre>\nSystem:\n10.0*x1 + -1.0*x2 + 2.0*x3 + 0.0*x4 = 6.0\n-1.0*x1 + 11.0*x2 + -1.0*x3 + 3.0*x4 = 25.0\n2.0*x1 + -1.0*x2 + 10.0*x3 + -1.0*x4 = -11.0\n0.0*x1 + 3.0*x2 + -1.0*x3 + 8.0*x4 = 15.0\n\nCurrent solution: [ 0.  0.  0.  0.]\nCurrent solution: [ 0.6         2.27272727 -1.1         1.875     ]\nCurrent solution: [ 1.04727273  1.71590909 -0.80522727  0.88522727]\nCurrent solution: [ 0.93263636  2.05330579 -1.04934091  1.13088068]\nCurrent solution: [ 1.01519876  1.95369576 -0.96810863  0.97384272]\nCurrent solution: [ 0.9889913   2.01141473 -1.0102859   1.02135051]\nCurrent solution: [ 1.00319865  1.99224126 -0.99452174  0.99443374]\nCurrent solution: [ 0.99812847  2.00230688 -1.00197223  1.00359431]\nCurrent solution: [ 1.00062513  1.9986703  -0.99903558  0.99888839]\nCurrent solution: [ 0.99967415  2.00044767 -1.00036916  1.00061919]\nCurrent solution: [ 1.0001186   1.99976795 -0.99982814  0.99978598]\nCurrent solution: [ 0.99994242  2.00008477 -1.00006833  1.0001085 ]\nCurrent solution: [ 1.00002214  1.99995896 -0.99996916  0.99995967]\nCurrent solution: [ 0.99998973  2.00001582 -1.00001257  1.00001924]\nCurrent solution: [ 1.00000409  1.99999268 -0.99999444  0.9999925 ]\nCurrent solution: [ 0.99999816  2.00000292 -1.0000023   1.00000344]\nCurrent solution: [ 1.00000075  1.99999868 -0.99999899  0.99999862]\nCurrent solution: [ 0.99999967  2.00000054 -1.00000042  1.00000062]\nCurrent solution: [ 1.00000014  1.99999976 -0.99999982  0.99999975]\nCurrent solution: [ 0.99999994  2.0000001  -1.00000008  1.00000011]\nCurrent solution: [ 1.00000003  1.99999996 -0.99999997  0.99999995]\nCurrent solution: [ 0.99999999  2.00000002 -1.00000001  1.00000002]\nCurrent solution: [ 1.          1.99999999 -0.99999999  0.99999999]\nCurrent solution: [ 1.  2. -1.  1.]\nSolution:\n[ 1.  2. -1.  1.]\nError:\n[ -2.81440107e-08   5.15706873e-08  -3.63466359e-08   4.17092547e-08]\n</pre>\n\n== Weighted Jacobi method ==\n\nThe weighted Jacobi iteration uses a parameter <math>\\omega</math> to compute the iteration as\n\n:<math> \\mathbf{x}^{(k+1)} = \\omega D^{-1} (\\mathbf{b} - R \\mathbf{x}^{(k)}) + \\left(1-\\omega\\right)\\mathbf{x}^{(k)}</math>\nwith <math>\\omega = 2/3</math> being the usual choice.<ref>{{cite book|last=Saad|first=Yousef|authorlink=Yousef Saad|title=Iterative Methods for Sparse Linear Systems|edition=2|year=2003|publisher=[[Society for Industrial and Applied Mathematics|SIAM]]|isbn=0898715342|page=414}}</ref>\n\n=== Convergence in the symmetric positive definite case ===\n\nIn case that the system matrix <math> A </math> is of symmetric [[Positive-definite matrix|positive-definite]] type one can show convergence. \n\nLet <math> C=C_\\omega = I-\\omega D^{-1}A </math> be the iteration matrix.\nThen, convergence is guaranteed for\n:<math>\n\\rho(C_\\omega) < 1\n  \\quad \\Longleftrightarrow \\quad\n  0 < \\omega < \\frac{2}{\\lambda_\\text{max} (D^{-1}A)} \\,,\n</math> \nwhere <math> \\lambda_\\text{max} </math> is the maximal eigenvalue.\n\nThe spectral radius can be minimized for a particular choice of <math> \\omega = \\omega_\\text{opt} </math> as follows\n:<math>\n\\min_\\omega \\rho (C_\\omega) = \\rho (C_{\\omega_\\text{opt}}) = 1-\\frac{2}{\\kappa(D^{-1}A)+1}\n  \\quad \\text{for} \\quad\n  \\omega_\\text{opt} := \\frac{2}{\\lambda_\\text{min}(D^{-1}A)+\\lambda_\\text{max}(D^{-1}A)} \\,,\n</math>\nwhere <math> \\kappa </math> is the [[Condition_number#Matrices|matrix condition number]].\n\n==See also==\n\n*[[Gauss–Seidel method]]\n*[[Successive over-relaxation]]\n*[[Iterative method#Linear systems|Iterative method § Linear systems]]\n*[[Belief propagation#Gaussian belief propagation .28GaBP.29|Gaussian Belief Propagation]]\n*[[Matrix splitting]]\n\n== References ==\n{{reflist}}\n\n==External links==\n* {{springer|title=Jacobi method|id=p/j054090}}\n* {{CFDWiki|name=Jacobi_method}}\n* {{MathWorld|urlname=JacobiMethod|title=Jacobi method|author=Black, Noel; Moore, Shirley; and Weisstein, Eric W.}}\n* [http://www.math-linux.com/spip.php?article49 Jacobi Method from www.math-linux.com]\n* [http://pagerank.suchmaschinen-doktor.de/matrix-inversion.html Numerical matrix inversion]\n\n{{Numerical linear algebra}}\n\n[[Category:Numerical linear algebra]]\n[[Category:Articles with example pseudocode]]\n[[Category:Relaxation (iterative methods)]]\n[[Category:Articles with example Python code]]"
    },
    {
      "title": "Matrix splitting",
      "url": "https://en.wikipedia.org/wiki/Matrix_splitting",
      "text": "{{Short description|Representation of a matrix as a sum}}\nIn the [[mathematics|mathematical]] discipline of [[numerical linear algebra]], a  '''matrix splitting''' is an expression which represents a given [[matrix (mathematics)|matrix]] as a sum or difference of matrices.  Many [[iterative method]]s (for example, for systems of  [[differential equation]]s) depend upon the direct solution of matrix equations involving matrices more general than [[tridiagonal matrix|tridiagonal matrices]].  These matrix equations can often be solved directly and efficiently when written as a matrix splitting.  The technique was devised by [[Richard S. Varga]] in 1960.<ref>{{harvtxt|Varga|1960}}</ref>\n\n==Regular splittings==\nWe seek to solve the [[Matrix(mathematics)#Linear equations|matrix equation]]\n\n{{NumBlk|:|<math> \\mathbf A \\mathbf x = \\mathbf k,  </math>|{{EquationRef|1}}}}\n\nwhere '''A''' is a given ''n'' × ''n'' [[invertible matrix|non-singular]] matrix, and '''k''' is a given [[column vector]] with ''n'' components.  We split the matrix '''A''' into\n\n{{NumBlk|:|<math> \\mathbf A = \\mathbf B - \\mathbf C, </math>|{{EquationRef|2}}}}\n\nwhere '''B''' and '''C''' are ''n'' × ''n'' matrices.  If, for an arbitrary ''n'' × ''n'' matrix '''M''', '''M''' has nonnegative entries, we write '''M''' &ge; '''0'''.  If '''M''' has only positive entries, we write '''M''' &gt; '''0'''.  Similarly, if the matrix '''M'''<sub>1</sub> &minus; '''M'''<sub>2</sub> has nonnegative entries, we write '''M'''<sub>1</sub> &ge; '''M'''<sub>2</sub>.\n\nDefinition:  '''A''' = '''B''' &minus; '''C''' is a '''regular splitting of A''' if '''B'''<sup>&minus;1</sup> &ge; '''0''' and '''C''' &ge; '''0'''.\n\nWe assume that matrix equations of the form\n\n{{NumBlk|:|<math> \\mathbf B \\mathbf x = \\mathbf g,  </math>|{{EquationRef|3}}}}\n\nwhere '''g''' is a given column vector, can be solved directly for the vector '''x'''.  If ({{EquationNote|2}}) represents a regular splitting of '''A''', then the iterative method\n\n{{NumBlk|:|<math> \\mathbf B \\mathbf x^{(m+1)} = \\mathbf C \\mathbf x^{(m)} + \\mathbf k, \\quad m = 0, 1, 2, \\ldots ,  </math>|{{EquationRef|4}}}}\n\nwhere '''x'''<sup>(0)</sup> is an arbitrary vector, can be carried out.  Equivalently, we write ({{EquationNote|4}}) in the form\n\n{{NumBlk|:|<math> \\mathbf x^{(m+1)} = \\mathbf B^{-1} \\mathbf C \\mathbf x^{(m)} + \\mathbf B^{-1} \\mathbf k, \\quad m = 0, 1, 2, \\ldots  </math>|{{EquationRef|5}}}}\n\nThe matrix '''D''' = '''B'''<sup>&minus;1</sup>'''C''' has nonnegative entries if ({{EquationNote|2}}) represents a regular splitting of '''A'''.<ref>{{harvtxt|Varga|1960|pp=121–122}}</ref>\n\nIt can be shown that if '''A'''<sup>&minus;1</sup> &gt; '''0''', then <math>\\rho (\\mathbf D)</math> < 1, where <math>\\rho (\\mathbf D)</math> represents the [[spectral radius]] of '''D''', and thus '''D''' is a [[convergent matrix]].  As a consequence, the iterative method ({{EquationNote|5}}) is necessarily [[Jacobi method#Convergence|convergent]].<ref>{{harvtxt|Varga|1960|pp=122–123}}</ref><ref>{{harvtxt|Varga|1962|p=89}}</ref>\n\nIf, in addition, the splitting ({{EquationNote|2}}) is chosen so that the matrix '''B''' is a [[diagonal matrix]] (with the diagonal entries all non-zero, since '''B''' must be [[Invertible matrix|invertible]]), then '''B''' can be inverted in linear time (see [[Time complexity]]).\n\n==Matrix iterative methods==\nMany iterative methods can be described as a matrix splitting.  If the diagonal entries of the matrix '''A''' are all nonzero, and we express the matrix '''A''' as the matrix sum\n\n{{NumBlk|:|<math> \\mathbf A = \\mathbf D - \\mathbf U - \\mathbf L, </math>|{{EquationRef|6}}}}\n\nwhere '''D''' is the diagonal part of '''A''', and '''U''' and '''L''' are respectively strictly upper and lower [[triangular matrix|triangular]] ''n'' × ''n'' matrices, then we have the following.\n\nThe [[Jacobi method]] can be represented in matrix form as a splitting\n\n{{NumBlk|:|<math> \\mathbf x^{(m+1)} = \\mathbf D^{-1}(\\mathbf U + \\mathbf L)\\mathbf x^{(m)} + \\mathbf D^{-1}\\mathbf k. </math><ref>{{harvtxt|Burden|Faires|1993|p=408}}</ref><ref>{{harvtxt|Varga|1962|p=88}}</ref>|{{EquationRef|7}}}}\n\nThe [[Gauss-Seidel method]] can be represented in matrix form as a splitting\n{{NumBlk|:|<math> \\mathbf x^{(m+1)} = (\\mathbf D - \\mathbf L)^{-1}\\mathbf U \\mathbf x^{(m)} + (\\mathbf D - \\mathbf L)^{-1}\\mathbf k. </math><ref>{{harvtxt|Burden|Faires|1993|p=411}}</ref><ref>{{harvtxt|Varga|1962|p=88}}</ref>|{{EquationRef|8}}}}\n\nThe method of [[successive over-relaxation]] can be represented in matrix form as a splitting\n{{NumBlk|:|<math> \\mathbf x^{(m+1)} = (\\mathbf D - \\omega \\mathbf L)^{-1}[(1 - \\omega) \\mathbf D + \\omega \\mathbf U] \\mathbf x^{(m)} + \\omega (\\mathbf D - \\omega \\mathbf L)^{-1}\\mathbf k. </math><ref>{{harvtxt|Burden|Faires|1993|p=416}}</ref><ref>{{harvtxt|Varga|1962|p=88}}</ref>|{{EquationRef|9}}}}\n\n==Example==\n\n===Regular splitting===\nIn equation ({{EquationNote|1}}), let\n{{NumBlk|:|<math>\n\\mathbf{A} = \\begin{pmatrix}\n6 & -2 & -3 \\\\\n-1 & 4 & -2 \\\\\n-3 & -1 & 5\n\\end{pmatrix}, \\quad \n\\mathbf{k} = \\begin{pmatrix}\n5 \\\\\n-12 \\\\\n10\n\\end{pmatrix}.\n</math>|{{EquationRef|10}}}}\nLet us apply the splitting ({{EquationNote|7}}) which is used in the Jacobi method: we split '''A''' in such a way that '''B''' consists of ''all'' of the diagonal elements of '''A''', and '''C''' consists of ''all'' of the off-diagonal elements of '''A''', negated.  (Of course this is not the only useful way to split a matrix into two matrices.)  We have\n{{NumBlk|:|<math>\\begin{align}\n& \\mathbf{B} = \\begin{pmatrix}\n6 & 0 & 0 \\\\\n0 & 4 & 0 \\\\\n0 & 0 & 5\n\\end{pmatrix}, \\quad \\mathbf{C} = \\begin{pmatrix}\n0 & 2 & 3 \\\\\n1 & 0 & 2 \\\\\n3 & 1 & 0\n\\end{pmatrix},\n\\end{align}</math>|{{EquationRef|11}}}}\n:<math>\\begin{align}\n& \\mathbf{A^{-1}} = \\frac{1}{47} \\begin{pmatrix}\n18 & 13 & 16 \\\\\n11 & 21 & 15 \\\\\n13 & 12 & 22\n\\end{pmatrix}, \\quad \\mathbf{B^{-1}} = \\begin{pmatrix}\n\\frac{1}{6} & 0 & 0 \\\\[4pt]\n0 & \\frac{1}{4} & 0 \\\\[4pt]\n0 & 0 & \\frac{1}{5}\n\\end{pmatrix},\n\\end{align}</math>\n:<math>\\begin{align}\n\\mathbf{D} = \\mathbf{B^{-1}C} = \\begin{pmatrix}\n0 & \\frac{1}{3} & \\frac{1}{2} \\\\[4pt]\n\\frac{1}{4} & 0 & \\frac{1}{2} \\\\[4pt]\n\\frac{3}{5} & \\frac{1}{5} & 0\n\\end{pmatrix}, \\quad \\mathbf{B^{-1}k} = \\begin{pmatrix}\n\\frac{5}{6} \\\\[4pt]\n-3 \\\\[4pt]\n2\n\\end{pmatrix}.\n\\end{align}</math>\nSince '''B'''<sup>&minus;1</sup> &ge; '''0''' and '''C''' &ge; '''0''', the splitting ({{EquationNote|11}}) is a regular splitting.  Since '''A'''<sup>&minus;1</sup> &gt; '''0''', the spectral radius  <math>\\rho (\\mathbf D)</math> < 1.  (The approximate [[eigenvalues]] of '''D''' are <math>\\lambda_i \\approx -0.4599820, -0.3397859, 0.7997679.</math>)   Hence, the matrix '''D''' is convergent and the method ({{EquationNote|5}}) necessarily converges for the problem ({{EquationNote|10}}).  Note that the diagonal elements of '''A''' are all greater than zero, the off-diagonal elements of '''A''' are all less than zero and '''A''' is [[strictly diagonally dominant]].<ref>{{harvtxt|Burden|Faires|1993|p=371}}</ref>\n\nThe method ({{EquationNote|5}}) applied to the problem ({{EquationNote|10}}) then takes the form\n{{NumBlk|:|<math> \\mathbf x^{(m+1)} =\n\\begin{pmatrix}\n0 & \\frac{1}{3} & \\frac{1}{2} \\\\[4pt]\n\\frac{1}{4} & 0 & \\frac{1}{2} \\\\[4pt]\n\\frac{3}{5} & \\frac{1}{5} & 0\n\\end{pmatrix}\n\\mathbf x^{(m)} +\n\\begin{pmatrix}\n\\frac{5}{6} \\\\[4pt]\n-3 \\\\[4pt]\n2\n\\end{pmatrix},\n\\quad m = 0, 1, 2, \\ldots</math>|{{EquationRef|12}}}}\n\nThe exact solution to equation ({{EquationNote|12}}) is\n{{NumBlk|:|<math>\n\\mathbf{x} = \\begin{pmatrix}\n2 \\\\\n-1 \\\\\n3\n\\end{pmatrix}.\n</math>|{{EquationRef|13}}}}\nThe first few iterates for equation ({{EquationNote|12}}) are listed in the table below, beginning with {{math|1='''x'''<sup>(0)</sup> = (0.0, 0.0, 0.0)<sup>T</sup>}}.  From the table one can see that the method is evidently converging to the solution ({{EquationNote|13}}), albeit rather slowly.\n\n{| class=\"wikitable\" border=\"1\"\n|-\n! <math>x^{(m)}_1</math>\n! <math>x^{(m)}_2</math>\n! <math>x^{(m)}_3</math>\n|-\n| 0.0\n| 0.0\n| 0.0\n|-\n| 0.83333\n| -3.0000\n| 2.0000\n|-\n| 0.83333\n| -1.7917\n| 1.9000\n|-\n| 1.1861\n| -1.8417\n| 2.1417\n|-\n| 1.2903\n| -1.6326\n| 2.3433\n|-\n| 1.4608\n| -1.5058\n| 2.4477\n|-\n| 1.5553\n| -1.4110\n| 2.5753\n|-\n| 1.6507\n| -1.3235\n| 2.6510\n|-\n| 1.7177\n| -1.2618\n| 2.7257\n|-\n| 1.7756\n| -1.2077\n| 2.7783\n|-\n| 1.8199\n| -1.1670\n| 2.8238\n|}\n\n===Jacobi method===\nAs stated above, the Jacobi method ({{EquationNote|7}}) is the same as the specific regular splitting ({{EquationNote|11}}) demonstrated above.\n\n===Gauss-Seidel method===\nSince the diagonal entries of the matrix '''A''' in problem ({{EquationNote|10}}) are all nonzero, we can express the matrix '''A''' as the splitting ({{EquationNote|6}}), where\n\n{{NumBlk|:|<math>\n\\mathbf{D} = \\begin{pmatrix}\n6 & 0 & 0 \\\\\n0 & 4 & 0 \\\\\n0 & 0 & 5\n\\end{pmatrix}, \\quad \\mathbf{U} = \\begin{pmatrix}\n0 & 2 & 3 \\\\\n0 & 0 & 2 \\\\\n0 & 0 & 0\n\\end{pmatrix}, \\quad \\mathbf{L} = \\begin{pmatrix}\n0 & 0 & 0 \\\\\n1 & 0 & 0 \\\\\n3 & 1 & 0\n\\end{pmatrix}.\n</math>|{{EquationRef|14}}}}\n\nWe then have\n\n:<math>\\begin{align}\n& \\mathbf{(D-L)^{-1}} = \\frac{1}{120} \\begin{pmatrix}\n20 & 0 & 0 \\\\\n5 & 30 & 0 \\\\\n13 & 6 & 24\n\\end{pmatrix},\n\\end{align}</math>\n\n:<math>\\begin{align}\n& \\mathbf{(D-L)^{-1}U} = \\frac{1}{120} \\begin{pmatrix}\n0 & 40 & 60 \\\\\n0 & 10 & 75 \\\\\n0 & 26 & 51\n\\end{pmatrix}, \\quad \\mathbf{(D-L)^{-1}k} = \\frac{1}{120} \\begin{pmatrix}\n100 \\\\\n-335 \\\\\n233\n\\end{pmatrix}.\n\\end{align}</math>\n\nThe Gauss-Seidel method ({{EquationNote|8}}) applied to the problem ({{EquationNote|10}}) takes the form\n\n{{NumBlk|:|<math> \\mathbf x^{(m+1)} =\n\\frac{1}{120} \\begin{pmatrix}\n0 & 40 & 60 \\\\\n0 & 10 & 75 \\\\\n0 & 26 & 51\n\\end{pmatrix}\n\\mathbf x^{(m)} +\n\\frac{1}{120} \\begin{pmatrix}\n100 \\\\\n-335 \\\\\n233\n\\end{pmatrix},\n\\quad m = 0, 1, 2, \\ldots</math>|{{EquationRef|15}}}}\n\nThe first few iterates for equation ({{EquationNote|15}}) are listed in the table below, beginning with {{math|1='''x'''<sup>(0)</sup> = (0.0, 0.0, 0.0)<sup>T</sup>}}.  From the table one can see that the method is evidently converging to the solution ({{EquationNote|13}}), somewhat faster than the Jacobi method described above.\n\n{| class=\"wikitable\" border=\"1\"\n|-\n! <math>x^{(m)}_1</math>\n! <math>x^{(m)}_2</math>\n! <math>x^{(m)}_3</math>\n|-\n| 0.0\n| 0.0\n| 0.0\n|-\n| 0.8333\n| -2.7917\n| 1.9417\n|-\n| 0.8736\n| -1.8107\n| 2.1620\n|-\n| 1.3108\n| -1.5913\n| 2.4682\n|-\n| 1.5370\n| -1.3817\n| 2.6459\n|-\n| 1.6957\n| -1.2531\n| 2.7668\n|-\n| 1.7990\n| -1.1668\n| 2.8461\n|-\n| 1.8675\n| -1.1101\n| 2.8985\n|-\n| 1.9126\n| -1.0726\n| 2.9330\n|-\n| 1.9423\n| -1.0479\n| 2.9558\n|-\n| 1.9619\n| -1.0316\n| 2.9708\n|}\n\n===Successive over-relaxation method===\nLet ''ω'' = 1.1.  Using the splitting ({{EquationNote|14}}) of the matrix '''A''' in problem ({{EquationNote|10}}) for the successive over-relaxation method, we have\n\n<!-- (D – wL)–1 -->\n:<math>\\begin{align}\n& \\mathbf{(D-\\omega L)^{-1}} = \\frac{1}{12} \\begin{pmatrix}\n2 & 0 & 0 \\\\\n0.55 & 3 & 0 \\\\\n1.441 & 0.66 & 2.4\n\\end{pmatrix},\n\\end{align}</math>\n\n<!-- (D – wL)–1[(1 – w)D + wU] -->\n:<math>\\begin{align}\n& \\mathbf{(D-\\omega L)^{-1}[(1-\\omega )D+\\omega U]} = \\frac{1}{12} \\begin{pmatrix}\n-1.2 & 4.4 & 6.6 \\\\\n-0.33 & 0.01 & 8.415 \\\\\n-0.8646 & 2.9062 & 5.0073\n\\end{pmatrix},\n\\end{align}</math>\n\n<!-- w(D – wL)–1k -->\n:<math>\\begin{align}\n& \\mathbf{\\omega (D-\\omega L)^{-1}k} = \\frac{1}{12} \\begin{pmatrix}\n11 \\\\\n-36.575 \\\\\n25.6135\n\\end{pmatrix}.\n\\end{align}</math>\n\nThe successive over-relaxation method ({{EquationNote|9}}) applied to the problem ({{EquationNote|10}}) takes the form\n\n{{NumBlk|:|<math> \\mathbf x^{(m+1)} =\n\\frac{1}{12} \\begin{pmatrix}\n-1.2 & 4.4 & 6.6 \\\\\n-0.33 & 0.01 & 8.415 \\\\\n-0.8646 & 2.9062 & 5.0073\n\\end{pmatrix}\n\\mathbf x^{(m)} +\n\\frac{1}{12} \\begin{pmatrix}\n11 \\\\\n-36.575 \\\\\n25.6135\n\\end{pmatrix},\n\\quad m = 0, 1, 2, \\ldots</math>|{{EquationRef|16}}}}\n\nThe first few iterates for equation ({{EquationNote|16}}) are listed in the table below, beginning with {{math|1='''x'''<sup>(0)</sup> = (0.0, 0.0, 0.0)<sup>T</sup>}}.  From the table one can see that the method is evidently converging to the solution ({{EquationNote|13}}), slightly faster than the Gauss-Seidel method described above.\n\n{| class=\"wikitable\" border=\"1\"\n|-\n! <math>x^{(m)}_1</math>\n! <math>x^{(m)}_2</math>\n! <math>x^{(m)}_3</math>\n|-\n| 0.0\n| 0.0\n| 0.0\n|-\n| 0.9167\n| -3.0479\n| 2.1345\n|-\n| 0.8814\n| -1.5788\n| 2.2209\n|-\n| 1.4711\n| -1.5161\n| 2.6153\n|-\n| 1.6521\n| -1.2557\n| 2.7526\n|-\n| 1.8050\n| -1.1641\n| 2.8599\n|-\n| 1.8823\n| -1.0930\n| 2.9158\n|-\n| 1.9314\n| -1.0559\n| 2.9508\n|-\n| 1.9593\n| -1.0327\n| 2.9709\n|-\n| 1.9761\n| -1.0185\n| 2.9829\n|-\n| 1.9862\n| -1.0113\n| 2.9901\n|}\n\n==See also==\n*[[List of operator splitting topics]]\n*[[Matrix decomposition]]\n*[[M-matrix]]\n*[[Stieltjes matrix]]\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{citation | first1 = Richard L. | last1 = Burden | first2 = J. Douglas | last2 = Faires | year = 1993 | isbn = 0-534-93219-3 | title = Numerical Analysis | edition = 5th | publisher = [[Prindle, Weber and Schmidt]] | location = Boston }}.\n* {{Cite book | first1 = Richard S. | last1 = Varga | chapter = Factorization and Normalized Iterative Methods | title = Boundary Problems in Differential Equations | editor1-last = Langer | editor1-first = Rudolph E. | publisher = [[University of Wisconsin Press]] | location = Madison | pages = 121&ndash;142 | year = 1960 | lccn = 60-60003 | ref = {{harvid|Varga|1960}} }}\n* {{citation | first1 = Richard S. | last1 = Varga | title = Matrix Iterative Analysis | publisher = [[Prentice-Hall]] | location = New Jersey | year = 1962 | lccn = 62-21277}}.\n\n{{Numerical linear algebra}}\n\n[[Category:Matrices]]\n[[Category:Numerical linear algebra]]\n[[Category:Relaxation (iterative methods)]]"
    },
    {
      "title": "Successive over-relaxation",
      "url": "https://en.wikipedia.org/wiki/Successive_over-relaxation",
      "text": "In [[numerical linear algebra]], the method of '''successive over-relaxation''' ('''SOR''') is a variant of the [[Gauss–Seidel method]] for solving a [[linear system of equations]], resulting in faster convergence. A similar method can be used for any slowly converging [[iterative method|iterative process]].\n\nIt was devised simultaneously by [[David M. Young, Jr.]] and by [[Stan Frankel|Stanley P. Frankel]] in 1950 for the purpose of automatically solving linear systems on digital computers. Over-relaxation methods had been used before the work of Young and Frankel. An example is the method of [[Lewis Fry Richardson]], and the methods developed by [[Richard V. Southwell|R. V. Southwell]]. However, these methods were designed for computation by [[human computer|human calculator]]s, and they required some expertise to ensure convergence to the solution which made them inapplicable for programming on digital computers. These aspects are discussed in the thesis of David M. Young, Jr.<ref>{{citation\n |last=Young |first=David M. |authorlink=David M. Young\n |title=Iterative methods for solving partial difference equations of elliptical type\n |url=http://www.ma.utexas.edu/CNA/DMY/david_young_thesis.pdf\n |date=May 1, 1950\n |series=PhD thesis, Harvard University\n |accessdate=2009-06-15\n}}</ref>\n\n==Formulation==\nGiven a square system of ''n'' linear equations with unknown '''x''':\n\n:<math>A\\mathbf x = \\mathbf b</math>\n\nwhere:\n\n:<math>A=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\a_{n1} & a_{n2} & \\cdots & a_{nn} \\end{bmatrix}, \\qquad  \\mathbf{x} = \\begin{bmatrix} x_{1} \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} , \\qquad  \\mathbf{b} = \\begin{bmatrix} b_{1} \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix}.</math>\n\nThen ''A'' can be decomposed into a [[diagonal matrix|diagonal]] component ''D'', and [[triangular matrix#Strictly triangular matrix|strictly lower and upper triangular]] components ''L'' and ''U'':\n\n:<math>A=D+L+U, </math>\nwhere\n:<math>D = \\begin{bmatrix} a_{11} & 0 & \\cdots & 0 \\\\ 0 & a_{22} & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\0 & 0 & \\cdots & a_{nn} \\end{bmatrix}, \\quad L = \\begin{bmatrix} 0 & 0 & \\cdots & 0 \\\\ a_{21} & 0 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\a_{n1} & a_{n2} & \\cdots & 0 \\end{bmatrix}, \\quad U = \\begin{bmatrix} 0 & a_{12} & \\cdots & a_{1n} \\\\ 0 & 0 & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\0 & 0 & \\cdots & 0 \\end{bmatrix}. </math>\n\nThe system of linear equations may be rewritten as:\n\n:<math>(D+\\omega L) \\mathbf{x} = \\omega \\mathbf{b} - [\\omega U + (\\omega-1) D ] \\mathbf{x} </math>\n\nfor a constant ''&omega;'' > 1, called the ''relaxation factor''.\n\nThe method of successive over-relaxation is an [[Iterative method|iterative technique]] that solves the left hand side of this expression for '''x''', using previous value for '''x''' on the right hand side. Analytically, this may be written as:\n\n:<math> \\mathbf{x}^{(k+1)} = (D+\\omega L)^{-1} \\big(\\omega \\mathbf{b} - [\\omega U + (\\omega-1) D ] \\mathbf{x}^{(k)}\\big)=L_w \\mathbf{x}^{(k)}+\\mathbf{c}, </math>\n\nwhere <math>\\mathbf{x}^{(k)}</math> is the ''k''th approximation or iteration of <math>\\mathbf{x}</math> and <math>\\mathbf{x}^{(k+1)}</math> is the next or ''k'' + 1 iteration of <math>\\mathbf{x}</math>.\nHowever, by taking advantage of the triangular form of (''D''+''&omega;L''), the elements of '''x'''<sup>(''k''+1)</sup> can be computed sequentially using [[forward substitution]]:\n\n:<math> x^{(k+1)}_i  = (1-\\omega)x^{(k)}_i + \\frac{\\omega}{a_{ii}} \\left(b_i - \\sum_{j<i} a_{ij}x^{(k+1)}_j - \\sum_{j>i} a_{ij}x^{(k)}_j \\right),\\quad i=1,2,\\ldots,n. </math>\n\n== Convergence ==\n[[File:Spectral Radius.svg|thumb|Spectral radius <math> \\rho(C_\\omega) </math> of the iteration matrix for the SOR method <math> C_\\omega </math>.\nThe plot shows the dependence on the spectral radius of the Jacobi iteration matrix <math> \\mu := \\rho(C_\\text{Jac}) </math>.]]\n\nThe choice of relaxation factor ''&omega;'' is not necessarily easy, and depends upon the properties of the coefficient matrix.  \nIn 1947, Ostrowski proved that if <math>A</math> is [[Symmetric matrix|symmetric]] and [[Positive-definite matrix|positive-definite]] then <math>\\rho(L_\\omega)<1</math> for <math>0<\\omega<2 </math>. \nThus, convergence of the iteration process follows, but we are generally interested in faster convergence rather than just convergence.\n\n=== Convergence Rate ===\nThe convergence rate for the SOR method can be analytically derived.\nOne needs to assume the following\n* the relaxation parameter is appropriate: <math> \\omega \\in (0,2) </math>\n* [[Jacobi_method|Jacobi's]] iteration matrix <math> C_\\text{Jac}:= I-D^{-1}A </math> has only real eigenvalues\n* [[Jacobi_method|Jacobi's method]] is convergent: <math> \\mu := \\rho(C_\\text{Jac}) < 1 </math>\n* a unique solution exists: <math> \\det A \\neq 0 </math>.\nThen the convergence rate can be expressed as<ref>{{Cite book|title=Iterative Solution of Large Sparse Systems of Equations {{!}} SpringerLink|volume = 95|last=Hackbusch|first=Wolfgang|year=2016|isbn=978-3-319-28481-1|location=|pages=|language=en-gb|chapter=4.6.2|doi=10.1007/978-3-319-28483-5|series = Applied Mathematical Sciences}}</ref>\n:<math>\n\\rho(C_\\omega) = \n\\begin{cases}\n  \\frac{1}{4} \\left( \\omega \\mu + \\sqrt{\\omega^2 \\mu^2-4(\\omega-1)} \\right)^2\\,,\n  & 0 < \\omega \\leq \\omega_\\text{opt}\n  \\\\\n  \\omega -1\\,,\n  & \\omega_\\text{opt} < \\omega < 2\n\\end{cases}\n</math> \nwhere the optimal relaxation parameter is given by\n:<math>\n\\omega_\\text{opt} := 1+ \\left( \\frac{\\mu}{1+\\sqrt{1-\\mu^2}} \\right)^2\\,.\n</math>\n\n== Algorithm ==\n\nSince elements can be overwritten as they are computed in this algorithm, only one storage vector is needed, and vector indexing is omitted. The algorithm goes as follows:\n\n Inputs: {{mvar|A}}, {{mvar|b}}, {{mvar|ω}}\n Output: {{nowrap|<math>\\phi</math>}}\n\n Choose an initial guess {{nowrap|<math>\\phi</math>}} to the solution\n '''repeat''' until convergence\n   '''for''' {{mvar|i}} '''from''' 1 '''until''' {{mvar|n}} '''do'''\n     {{nowrap|<math>\\sigma \\leftarrow 0</math>}}\n     '''for''' {{mvar|j}} '''from''' 1 '''until''' {{mvar|n}} '''do'''\n       '''if''' {{mvar|j}} &ne; {{mvar|i}} '''then'''\n         {{nowrap|<math> \\sigma \\leftarrow \\sigma + a_{ij} \\phi_j </math>}}\n       '''end if'''\n     '''end''' ({{mvar|j}}-loop)\n     {{nowrap|<math> \\phi_i \\leftarrow (1-\\omega)\\phi_i + \\frac{\\omega}{a_{ii}} (b_i - \\sigma)</math>}}\n   '''end''' ({{mvar|i}}-loop)\n   check if convergence is reached\n '''end''' (repeat)\n\n;Note: <math>(1-\\omega)\\phi_i + \\frac{\\omega}{a_{ii}} (b_i - \\sigma)</math> can also be written <math>\\phi_i + \\omega \\left( \\frac{b_i - \\sigma}{a_{ii}} - \\phi_i\\right)</math>, thus saving one multiplication in each iteration of the outer ''for''-loop.\n\n\n==Example==\n\nWe are presented the linear system\n\n:<math>\n  \\begin{align}\n     4x_1 -  x_2 -  6x_3 + 0x_4 =   2, \\\\\n    -5x_1 - 4x_2 + 10x_3 + 8x_4 =  21, \\\\\n     0x_1 + 9x_2 +  4x_3 - 2x_4 = -12, \\\\\n     1x_1 + 0x_2 -  7x_3 + 5x_4 =  -6.\n  \\end{align}\n</math>\n\nTo solve the equations, we choose a relaxation factor <math>\\omega = 0.5</math> and an initial guess vector <math>\\phi = (0, 0, 0)</math>. According to the successive over-relaxation algorithm, following table is obtained, representing an exemplary iteration with approximations, which ideally, but not necessarily, finds the exact solution, {{math|(3,&nbsp;&minus;2,&nbsp;2,&nbsp;1)}}, in 38 steps.\n\n{| class=\"wikitable\" border=\"1\"\n|-\n! Iteration\n! <math>x_1</math>\n! <math>x_2</math>\n! <math>x_3</math>\n! <math>x_4</math>\n|-\n| 1\n| 0.25\n| -2.78125\n| 1.6289062\n| 0.5152344\n|-\n| 2\n| 1.2490234\n| -2.2448974\n| 1.9687712\n| 0.9108547\n|-\n| 3\n| 2.070478\n| -1.6696789\n| 1.5904881\n| 0.76172125\n|-\n| ...\n| ...\n| ...\n| ...\n| ...\n|-\n| 37\n| 2.9999998\n| -2.0\n| 2.0\n| 1.0\n|-\n| 38\n| 3.0\n| -2.0\n| 2.0\n| 1.0\n|}\n\nA simple implementation of the algorithm in Common Lisp is offered below. Beware its proclivity towards floating-point overflows in the general case.\n\n<source lang=\"lisp\">\n\n(defparameter +MAXIMUM-NUMBER-OF-ITERATIONS+ 100\n  \"The number of iterations beyond which the algorithm should\n   cease its operation, regardless of its current solution.\")\n\n(defun get-errors (computed-solution exact-solution)\n  \"For each component of the COMPUTED-SOLUTION vector, retrieves its\n   error with respect to the expected EXACT-SOLUTION, returning a\n   vector of error values.\"\n  (map 'vector #'- exact-solution computed-solution))\n\n(defun is-convergent (errors &key (error-tolerance 0.001))\n  \"Checks whether the convergence is reached with respect to the\n   ERRORS vector which registers the discrepancy betwixt the computed\n   and the exact solution vector.\n   ---\n   The convergence is fulfilled iff each absolute error component is\n   less than or equal to the ERROR-TOLERANCE.\"\n  (flet ((error-is-acceptable (error)\n          (<= (abs error) error-tolerance)))\n    (every #'error-is-acceptable errors)))\n\n(defun make-zero-vector (size)\n  \"Creates and returns a vector of the SIZE with all elements set to 0.\"\n  (make-array size :initial-element 0.0 :element-type 'number))\n\n(defun sor (A b omega\n            &key (phi (make-zero-vector (length b)))\n                 (convergence-check\n                   #'(lambda (iteration phi)\n                       (declare (ignore phi))\n                       (>= iteration +MAXIMUM-NUMBER-OF-ITERATIONS+))))\n  \"Implements the successive over-relaxation (SOR) method, applied upon\n   the linear equations defined by the matrix A and the right-hand side\n   vector B, employing the relaxation factor OMEGA, returning the\n   calculated solution vector.\n   ---\n   The first algorithm step, the choice of an initial guess PHI, is\n   represented by the optional keyword parameter PHI, which defaults\n   to a zero-vector of the same structure as B. If supplied, this\n   vector will be destructively modified. In any case, the PHI vector\n   constitutes the function's result value.\n   ---\n   The terminating condition is implemented by the CONVERGENCE-CHECK,\n   an optional predicate\n     lambda(iteration phi) => generalized-boolean\n   which returns T, signifying the immediate termination, upon achieving\n   convergence, or NIL, signaling continuant operation, otherwise.\"\n  (let ((n (array-dimension A 0)))\n    (loop for iteration from 1 by 1 do\n      (loop for i from 0 below n by 1 do\n        (let ((rho 0))\n          (loop for j from 0 below n by 1 do\n            (when (/= j i)\n              (let ((a[ij]  (aref A i j))\n                    (phi[j] (aref phi j)))\n                (incf rho (* a[ij] phi[j])))))\n          (setf (aref phi i)\n                (+ (* (- 1 omega)\n                      (aref phi i))\n                   (* (/ omega (aref A i i))\n                      (- (aref b i) rho))))))\n      (format T \"~&~d. solution = ~a\" iteration phi)\n      ;; Check if convergence is reached.\n      (when (funcall convergence-check iteration phi)\n        (return))))\n  phi)\n\n;; Summon the function with the exemplary parameters.\n(let ((A              (make-array (list 4 4)\n                        :initial-contents\n                        '((  4  -1  -6   0 )\n                          ( -5  -4  10   8 )\n                          (  0   9   4  -2 )\n                          (  1   0  -7   5 ))))\n      (b              (vector 2 21 -12 -6))\n      (omega          0.5)\n      (exact-solution (vector 3 -2 2 1)))\n  (sor\n    A b omega\n    :convergence-check\n    #'(lambda (iteration phi)\n        (let ((errors (get-errors phi exact-solution)))\n          (format T \"~&~d. errors   = ~a\" iteration errors)\n          (or (is-convergent errors :error-tolerance 0.0)\n              (>= iteration +MAXIMUM-NUMBER-OF-ITERATIONS+))))))\n\n</source>\n\n==Symmetric successive over-relaxation==\n\nThe version for symmetric matrices ''A'', in which\n\n:<math> U=L^T,\\,</math>\n\nis referred to as '''[[symmetric successive overrelaxation|Symmetric Successive Over-Relaxation]]''', or ('''SSOR'''), in which\n\n:<math>P=\\left(\\frac{D}{\\omega}+L\\right)\\frac{1}{2-\\omega}D^{-1}\\left(\\frac{D}{\\omega}+U\\right),</math>\n\nand the iterative method is\n\n:<math>\\mathbf{x}^{k+1}=\\mathbf{x}^k-\\gamma^k P^{-1}(A\\mathbf{x}^k-\\mathbf{b}),\\ k \\ge 0.</math>\n\nThe SOR and SSOR methods are credited to [[David M. Young, Jr.]].\n\n==Other applications of the method==\n{{main|Richardson extrapolation}}\nA similar technique can be used for any iterative method. If the original iteration had the form\n\n:<math>x_{n+1}=f(x_n)</math>\n\nthen the modified version would use\n\n:<math>x^\\mathrm{SOR}_{n+1}=(1-\\omega)x^{\\mathrm{SOR}}_n+\\omega f(x^\\mathrm{SOR}_n).</math>\n\nNote however that the formulation presented above, used for solving systems of linear equations, is not a special case of this formulation if {{mvar|x}} is considered to be the complete vector. If this formulation is used instead, the equation for calculating the next vector will look like\n\n:<math> \\mathbf{x}^{(k+1)} = (1-\\omega)\\mathbf{x}^{(k)} + \\omega L_*^{-1} (\\mathbf{b} - U\\mathbf{x}^{(k)}),</math>\n\nwhere <math>L_* = L + D</math>. Values of <math>\\omega>1</math> are used to speed up convergence of a slow-converging process, while values of <math>\\omega<1</math> are often used to help establish convergence of a diverging iterative process or speed up the convergence of an [[Newton's method#Overshoot|overshooting]] process.\n\nThere are various methods that adaptively set the relaxation parameter <math>\\omega</math> based on the observed behavior of the converging process. Usually they help to reach a super-linear convergence for some problems but fail for the others.\n\n==See also==\n*[[Jacobi method]]\n*[[Belief propagation#Gaussian belief propagation .28GaBP.29|Gaussian Belief Propagation]]\n*[[Matrix splitting]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*{{CFDWiki|name=Successive_over-relaxation_method_-_SOR}}\n* Abraham Berman, [[Robert J. Plemmons]], ''Nonnegative Matrices in the Mathematical Sciences'', 1994, SIAM. {{isbn|0-89871-321-8}}.\n*{{MathWorld|urlname=SuccessiveOverrelaxationMethod|title=Successive Overrelaxation Method|author=Black, Noel and Moore, Shirley}}\n* A. Hadjidimos, ''[http://www.sciencedirect.com/science/article/pii/S0377042700004039 Successive overrelaxation (SOR) and related methods]'', Journal of Computational and Applied Mathematics 123 (2000), 177-199.\n*[[Yousef Saad]], ''[http://www-users.cs.umn.edu/%7Esaad/books.html Iterative Methods for Sparse Linear Systems]'', 1st edition, PWS, 1996.\n*[http://www.netlib.org/utk/papers/templates/node11.html Netlib]'s copy of  \"Templates for the Solution of Linear Systems\", by Barrett et al.\n* [[Richard S. Varga]] 2002 ''Matrix Iterative Analysis'', Second ed. (of 1962 Prentice Hall edition), Springer-Verlag.\n* [[David M. Young, Jr.]] ''Iterative Solution of Large Linear Systems'', Academic Press, 1971. (reprinted by Dover, 2003)\n\n==External links==\n*[https://web.archive.org/web/20040317151200/http://math.fullerton.edu/mathews/n2003/SORmethodMod.html Module for the SOR Method]\n* [https://web.archive.org/web/20140310122757/http://michal.is/projects/tridiagonal-system-solver-sor-c/ Tridiagonal linear system solver] based on SOR, in C++ \n\n{{Numerical linear algebra}}\n\n[[Category:Numerical linear algebra]]\n[[Category:Articles with example pseudocode]]\n[[Category:Relaxation (iterative methods)]]"
    },
    {
      "title": "Mathematical optimization",
      "url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
      "text": "{{redirect|Mathematical programming|the peer-reviewed journal|Mathematical Programming}}\n{{redirect-multi|2|Optimization|Optimum}}\n\n[[File:Max paraboloid.svg|right|thumb|Graph of a [[paraboloid]] given by ''z'' =  f(''x'', ''y'') = −(''x''² + ''y''²) + 4. The global [[maximum (mathematics)|maximum]] at (''x, y, z'') = (0, 0, 4) is indicated by a blue dot.]]\n\n[[File:Nelder-Mead Simionescu.gif|thumb|Nelder-Mead minimum search of [[Test functions for optimization|Simionescu's function]]. Simplex vertices are ordered by their value, with 1 having the lowest (best) value.]]\n\nIn [[mathematics]], [[computer science]] and [[operations research]], '''mathematical optimization''' (alternatively spelled ''optimisation'') or '''mathematical programming''' is the selection of a best element (with regard to some criterion) from some set of available alternatives.<ref>\"[http://glossary.computing.society.informs.org/index.php?page=nature.html The Nature of Mathematical Programming] {{webarchive|url=https://web.archive.org/web/20140305080324/http://glossary.computing.society.informs.org/index.php?page=nature.html |date=2014-03-05 }},\" ''Mathematical Programming Glossary'', INFORMS Computing Society.</ref>\n\nIn the simplest case, an [[optimization problem]] consists of [[maxima and minima|maximizing or minimizing]] a [[Function of a real variable|real function]] by systematically choosing [[Argument of a function|input]] values from within an allowed set and computing the [[Value (mathematics)|value]] of the function. The generalization of optimization theory and techniques to other formulations constitutes a large area of [[applied mathematics]]. More generally, optimization includes finding \"best available\" values of some objective function given a defined [[domain of a function|domain]] (or input), including a variety of different types of objective functions and different types of domains.\n\n== Optimization problems ==\n{{main|Optimization problem}}\nAn optimization problem can be represented in the following way:\n:''Given:'' a [[function (mathematics)|function]] <math>f\\, : A\\to\\mathbb{R}</math> from some [[Set (mathematics)|set]] <math>A</math> to the [[real number]]s\n:''Sought:'' an element <math>\\mathbf{x}_{0}\\in A</math> such that <math>f\\left(\\mathbf{x}_{0}\\right)\\leq f\\left(\\mathbf{x}\\right)</math> for all <math>\\mathbf{x}\\in A</math> (\"minimization\") or such that <math>f\\left(\\mathbf{x}_{0}\\right)\\geq f\\left(\\mathbf{x}\\right)</math> for all <math>\\mathbf{x}\\in A</math> (\"maximization\").\n\nSuch a formulation is called an '''[[optimization problem]]''' or a '''mathematical programming problem''' (a term not directly related to [[computer programming]], but still in use for example in [[linear programming]] – see [[#History|History]] below). Many real-world and theoretical problems may be modeled in this general framework. \n\nSince the following is valid\n:<math>f\\left(\\mathbf{x}_{0}\\right)\\geq f\\left(\\mathbf{x}\\right) \\Leftrightarrow \\tilde{f}\\left(\\mathbf{x}_{0}\\right)\\leq \\tilde{f}\\left(\\mathbf{x}\\right)</math> \nwith\n:<math>\\tilde{f}\\left(\\mathbf{x}\\right) := - f\\left(\\mathbf{x}\\right),\\, \\tilde{f}\\, :\\, A \\rightarrow \\mathbb{R}</math>\nit is more convenient to solve minimization problems. However, the opposite perspective would be valid, too.\nProblems formulated using this technique in the fields of [[physics]] may refer to the technique as '''[[energy]] minimization''', speaking of the value of the function <math>f</math> as representing the energy of the [[system]] being [[Mathematical model|modeled]]. In [[Machine Learning]], it is always necessary to continuously evaluate the quality of a data model by using a [[Loss function|cost function]] where a minimum implies a set of possibly optimal parameters with an optimal (lowest) error. \n\nTypically, <math>A</math> is some [[subset]] of the [[Euclidean space]] <math>\\mathbb{R}^{n}</math>, often specified by a set of ''[[constraint (mathematics)|constraints]]'', equalities or inequalities that the members of <math>A</math> have to satisfy.  The [[domain (mathematics)|domain]] <math>A</math> of <math>f</math> is called the ''search space'' or the ''choice set'',\nwhile the elements of <math>A</math> are called ''[[candidate solution]]s'' or ''feasible solutions''.\n\nThe function <math>f</math> is called, variously, an '''objective function''', a '''[[loss function]]''' or '''cost function''' (minimization),<ref>W. Erwin Diewert  (2008).  \"cost functions,\" ''The New Palgrave Dictionary of Economics'', 2nd Edition [http://www.dictionaryofeconomics.com/article?id=pde2008_C000390&edition=current&q= Contents].</ref>  a '''utility function''' or '''fitness function''' (maximization), or, in certain fields, an '''energy function''' or '''energy [[functional (mathematics)|functional]]'''. A feasible solution that minimizes (or maximizes, if that is the goal) the objective function is called an ''optimal solution''.\n\nIn mathematics, conventional optimization problems are usually stated in terms of minimization.\n\nA ''local minimum''\n<math>\\mathbf{x}^{\\ast}</math>\nis defined as an element for which there exists some <math>\\delta > 0</math> such that\n\n:<math>\\forall\\mathbf{x}\\in A</math> where <math>\\left\\Vert\\mathbf{x}-\\mathbf{x}^{\\ast}\\right\\Vert\\leq\\delta,\\,</math> the expression <math>f\\left(\\mathbf{x}^{\\ast}\\right)\\leq f\\left(\\mathbf{x}\\right)</math> holds;\n\nthat is to say, on some region around\n<math>\\mathbf{x}^{\\ast}</math>\nall of the function values are greater than or equal to the value at that element. \nLocal maxima are defined similarly.\n\nWhile a local minimum is at least as good as any nearby elements, a [[global minimum]] is at least as good as every feasible element.\nGenerally, unless the objective function is [[Convex function|convex]] in a minimization problem, there may be several local minima.\nIn a [[convex optimization|convex problem]], if there is a local minimum that is interior (not on the edge of the set of feasible elements), it is also the global minimum, but a nonconvex problem may have more than one local minimum not all of which need be global minima.\n\nA large number of algorithms proposed for solving nonconvex problems – including the majority of commercially available solvers – are  not capable of making a distinction between locally optimal solutions and globally optimal solutions, and will treat the former as actual solutions to the original problem. [[Global optimization]] is the branch of [[applied mathematics]] and [[numerical analysis]] that is concerned with the development of deterministic algorithms that are capable of guaranteeing convergence in finite time to the actual optimal solution of a nonconvex problem.\n\n== Notation ==\nOptimization problems are often expressed with special notation. Here are some examples:\n\n=== Minimum and maximum value of a function ===\nConsider the following notation:\n:<math>\\min_{x\\in\\mathbb R}\\; (x^2 + 1)</math>\n\nThis denotes the minimum [[Value (mathematics)|value]] of the objective function <math>x^2 + 1</math>, when choosing ''x'' from the set of [[real number]]s <math>\\mathbb R</math>. The minimum value in this case is <math>1</math>, occurring at <math>x = 0</math>.\n\nSimilarly, the notation\n\n:<math>\\max_{x\\in\\mathbb R}\\; 2x</math>\n\nasks for the maximum value of the objective function 2''x'', where ''x'' may be any real number. In this case, there is no such maximum as the objective function is unbounded, so the answer is \"[[infinity]]\" or \"undefined\".\n\n=== Optimal input arguments ===\n{{Main|Arg max}}\nConsider the following notation:\n:<math>\\underset{x\\in(-\\infty,-1]}{\\operatorname{arg\\,min}} \\; x^2 + 1,</math>\nor equivalently\n:<math>\\underset{x}{\\operatorname{arg\\,min}} \\; x^2 + 1, \\; \\text{subject to:} \\; x\\in(-\\infty,-1].</math>\n\nThis represents the value (or values) of the [[Argument of a function|argument]] <math>x</math> in the [[interval (mathematics)|interval]] <math>(-\\infty,-1]</math> that minimizes (or minimize) the objective function <math>x^2+1</math> (the actual minimum value of that function is not what the problem asks for). In this case, the answer is <math>x = -1 </math>, since <math>x = 0</math> is infeasible, i.e. does not belong to the [[feasible set]].\n\nSimilarly,\n:<math>\\underset{x\\in[-5,5], \\; y\\in\\mathbb R}{\\operatorname{arg\\,max}} \\; x\\cos(y),</math>\nor equivalently\n:<math>\\underset{x, \\; y}{\\operatorname{arg\\,max}} \\; x\\cos(y), \\; \\text{subject to:} \\; x\\in[-5,5], \\; y\\in\\mathbb R,</math>\n\nrepresents the <math>(x,y)</math> pair (or pairs) that maximizes (or maximize) the value of the objective function <math>x\\cos(y)</math>, with the added constraint that <math>x</math> lie in the interval <math>[-5,5]</math> (again, the actual maximum value of the expression does not matter). In this case, the solutions are the pairs of the form <math>(5,\\,2k\\pi)</math> and <math>(-5,\\,(2k+1)\\pi)</math>, where <math>k</math> ranges over all [[integer]]s.\n\nOperators <math>\\operatorname{arg\\,min} </math> and <math>\\operatorname{arg\\,max} </math> are sometimes also written as <math>\\operatorname{argmin} </math> and <math>\\operatorname{argmax} </math>, and stand for '''argument of the minimum''' and '''argument of the maximum'''.\n\n== History ==\n[[Pierre de Fermat|Fermat]] and [[Joseph Louis Lagrange|Lagrange]] found calculus-based formulae for identifying optima, while [[Isaac Newton|Newton]] and [[Carl Friedrich Gauss|Gauss]] proposed iterative methods for moving towards an optimum.\n\nThe term \"[[linear programming]]\" for certain optimization cases was due to [[George Dantzig|George&nbsp;B. Dantzig]], although much of the theory had been introduced by [[Leonid Kantorovich]] in 1939. (''Programming'' in this context does not refer to [[computer programming]], but comes from the use of ''program'' by the United States military to refer to proposed training and [[logistics]] schedules, which were the problems Dantzig studied at that time.) Dantzig published the [[Simplex algorithm]] in 1947, and [[John von Neumann]] developed the theory of [[Linear programming#Duality|duality]] in the same year.\n\nOther notable researchers in mathematical optimization include the following:\n{{Div col|colwidth=20em}}\n* [[Richard Bellman]]\n* [[Roger Fletcher (mathematician)|Roger Fletcher]]\n* [[Ronald A. Howard]]\n* [[Fritz John]]\n* [[Narendra Karmarkar]]\n* [[William Karush]]\n* [[Leonid Khachiyan]]\n* [[Bernard Koopman]]\n* [[Harold Kuhn]]\n* [[László Lovász]]\n* [[Arkadi Nemirovski]]\n* [[Yurii Nesterov]]\n* [[Lev Pontryagin]]\n* [[R. Tyrrell Rockafellar]]\n* [[Naum Z. Shor]]\n* [[Albert W. Tucker|Albert Tucker]]\n{{div col end}}\n<!--In fact, some mathematical programming work had been done previously... (anyone? - Gauss did some stuff here), Gauss developed the method of least squares, which is an optimization method. -->\n\n== Major subfields ==\n* [[Convex programming]] studies the case when the objective function is [[convex function|convex]] (minimization) or [[Concave function|concave]] (maximization) and the constraint set is [[convex set|convex]]. This can be viewed as a particular case of nonlinear programming or as generalization of linear or convex quadratic programming.\n** [[Linear programming]] (LP), a type of convex programming, studies the case in which the objective function ''f'' is linear and the constraints are specified using only linear equalities and inequalities. Such a constraint set is called a [[polyhedron]] or a [[polytope]] if it is [[Bounded set|bounded]].\n** [[Second order cone programming]] (SOCP) is a convex program, and includes certain types of quadratic programs.\n** [[Semidefinite programming]] (SDP) is a subfield of convex optimization where the underlying variables are [[semidefinite]] [[matrix (mathematics)|matrices]]. It is a generalization of linear and convex quadratic programming.\n** [[Conic programming]] is a general form of convex programming.  LP, SOCP and SDP can all be viewed as conic programs with the appropriate type of cone.\n** [[Geometric programming]] is a technique whereby objective and inequality constraints expressed as [[posynomials]] and equality constraints as [[monomials]] can be transformed into a convex program.\n* [[Integer programming]] studies linear programs in which some or all variables are constrained to take on [[integer]] values.  This is not convex, and in general much more difficult than regular linear programming.\n* [[Quadratic programming]] allows the objective function to have quadratic terms, while the feasible set must be specified with linear equalities and inequalities.  For specific forms of the quadratic term, this is a type of convex programming.\n* [[Fractional programming]] studies optimization of ratios of two nonlinear functions. The special class of concave fractional programs can be transformed to a convex optimization problem.\n* [[Nonlinear programming]] studies the general case in which the objective function or the constraints or both contain nonlinear parts.  This may or may not be a convex program. In general, whether the program is convex affects the difficulty of solving it.\n* [[Stochastic programming]] studies the case in which some of the constraints or parameters depend on [[random variable]]s.\n* [[Robust optimization|Robust programming]] is, like stochastic programming, an attempt to capture uncertainty in the data underlying the optimization problem. Robust optimization aims to find solutions that are valid under all possible realizations of the uncertainties.\n* [[Combinatorial optimization]] is concerned with problems where the set of feasible solutions is discrete or can be reduced to a [[discrete mathematics|discrete]] one.\n* [[Stochastic optimization]] is used with random (noisy) function measurements or random inputs in the search process.\n* [[Infinite-dimensional optimization]] studies the case when the set of feasible solutions is a subset of an infinite-[[dimension]]al space, such as a space of functions.\n* [[Heuristic (computer science)|Heuristics]] and [[metaheuristic]]s make few or no assumptions about the problem being optimized. Usually, heuristics do not guarantee that any optimal solution need be found. On the other hand, heuristics are used to find approximate solutions for many complicated optimization problems.\n* [[Constraint satisfaction]] studies the case in which the objective function ''f'' is constant (this is used in [[artificial intelligence]], particularly in [[automated reasoning]]).\n** [[Constraint programming]] is a programming paradigm wherein relations between variables are stated in the form of constraints.\n* Disjunctive programming is used where at least one constraint must be satisfied but not all. It is of particular use in scheduling.\n* [[Space mapping]] is a concept for modeling and optimization of an engineering system to high-fidelity (fine) model accuracy exploiting a suitable physically meaningful coarse or [[surrogate model]].\n\nIn a number of subfields, the techniques are designed primarily for optimization in dynamic contexts (that is, decision making over time):\n* [[Calculus of variations]] seeks to optimize an action integral over some space to an extremum by varying a function of the coordinates.\n* [[Optimal control]] theory is a generalization of the calculus of variations which introduces control policies.\n* [[Dynamic programming]] studies the case in which the optimization strategy is based on splitting the problem into smaller subproblems. The equation that describes the relationship between these subproblems is called the [[Bellman equation]].\n* [[Mathematical programming with equilibrium constraints]] is where the constraints include [[variational inequalities]] or  [[complementarity theory|complementarities]].\n\n=== Multi-objective optimization ===\n{{Main|Multi-objective optimization}}\nAdding more than one objective to an optimization problem adds complexity. For example, to optimize a structural design, one would desire a design that is both light and rigid. When two objectives conflict, a trade-off must be created. There may be one lightest design, one stiffest design, and an infinite number of designs that are some compromise of weight and rigidity. The set of trade-off designs that cannot be improved upon according to one criterion without hurting another criterion is known as the [[Pareto set]]. The curve created plotting weight against stiffness of the best designs is known as the [[Pareto frontier]].\n\nA design is judged to be \"Pareto optimal\" (equivalently, \"Pareto efficient\" or in the Pareto set) if it is not dominated by any other design: If it is worse than another design in some respects and no better in any respect, then it is dominated and is not Pareto optimal.\n\nThe choice among \"Pareto optimal\" solutions to determine the \"favorite solution\" is delegated to the decision maker. In other words, defining the problem as multi-objective optimization signals that some information is missing: desirable objectives are given but combinations of them are not rated relative to each other. In some cases, the missing information can be derived by interactive sessions with the decision maker.\n\nMulti-objective optimization problems have been generalized further into [[vector optimization]] problems where the (partial) ordering is no longer given by the Pareto ordering.\n\n=== Multi-modal optimization ===\nOptimization problems are often multi-modal; that is, they possess multiple good solutions. They could all be globally good (same cost function value) or there could be a mix of globally good and locally good solutions. Obtaining all (or at least some of) the multiple solutions is the goal of a multi-modal optimizer.\n\nClassical optimization techniques due to their iterative approach do not perform satisfactorily when they are used to obtain multiple solutions, since it is not guaranteed that different solutions will be obtained even with different starting points in multiple runs of the algorithm. [[Evolutionary algorithm]]s, however, are a very popular approach to obtain multiple solutions in a multi-modal optimization task.\n\n== Classification of critical points and extrema ==\n\n=== Feasibility problem ===\nThe '''[[satisfiability problem]]''', also called the '''feasibility problem''', is just the problem of finding any [[feasible solution]] at all without regard to objective value. This can be regarded as the special case of mathematical optimization where the objective value is the same for every solution, and thus any solution is optimal.\n\nMany optimization algorithms need to start from a feasible point. One way to obtain such a point is to [[Relaxation (approximation)|relax]] the feasibility conditions using a [[slack variable]]; with enough slack, any starting point is feasible. Then, minimize that slack variable until slack is null or negative.\n\n=== Existence ===\nThe [[extreme value theorem]] of [[Karl Weierstrass]] states that a continuous real-valued function on a compact set attains its maximum and minimum value. More generally, a lower semi-continuous function on a compact set attains its minimum; an upper semi-continuous function on a compact set attains its maximum.\n\n=== Necessary conditions for optimality ===\n[[Fermat's theorem (stationary points)|One of Fermat's theorems]] states that optima of unconstrained problems are found at [[stationary point]]s, where the first derivative or the gradient of the objective function is zero (see [[first derivative test]]). More generally, they may be found at [[Critical point (mathematics)|critical points]], where the first derivative or gradient of the objective function is zero or is undefined, or on the boundary of the choice set. An equation (or set of equations) stating that the first derivative(s) equal(s) zero at an interior optimum is called a 'first-order condition' or a set of first-order conditions.\n\nOptima of equality-constrained problems can be found by the [[Lagrange multiplier]] method. The optima of problems with equality and/or inequality constraints can be found using the '[[Karush–Kuhn–Tucker conditions]]'.\n\n=== Sufficient conditions for optimality ===\nWhile the first derivative test identifies points that might be extrema, this test does not distinguish a point that is a minimum from one that is a maximum or one that is neither. When the objective function is twice differentiable, these cases can be distinguished by checking the second derivative or the matrix of second derivatives (called the [[Hessian matrix]]) in unconstrained problems, or the matrix of second derivatives of the objective function and the constraints called the [[Hessian matrix#Bordered Hessian|bordered Hessian]] in constrained problems. The conditions that distinguish maxima, or minima, from other stationary points are called 'second-order conditions' (see '[[Second derivative test]]'). If a candidate solution satisfies the first-order conditions, then satisfaction of the second-order conditions as well is sufficient to establish at least local optimality.\n\n=== Sensitivity and continuity of optima ===\nThe [[envelope theorem]] describes how the value of an optimal solution changes when an underlying [[parameter]] changes. The process of computing this change is called [[comparative statics]].\n\nThe [[maximum theorem]] of [[Claude Berge]] (1963) describes the continuity of an optimal solution as a function of underlying parameters.\n\n===Calculus of optimization===\n{{Main|Karush–Kuhn–Tucker conditions}}\n{{See also|Critical point (mathematics)|Differential calculus|Gradient|Hessian matrix|Positive definite matrix|Lipschitz continuity|Rademacher's theorem|Convex function|Convex analysis}}\n\nFor unconstrained problems with twice-differentiable functions, some [[critical point (mathematics)|critical points]] can be found by finding the points where the [[gradient]] of the objective function is zero (that is, the stationary points). More generally, a zero [[subgradient]] certifies that a local minimum has been found for [[convex optimization|minimization problems with convex]] [[convex function|functions]] and other [[Rademacher's theorem|locally]] [[Lipschitz function]]s.\n\nFurther, critical points can be classified  using the [[positive definite matrix|definiteness]] of the [[Hessian matrix]]: If the Hessian is ''positive'' definite at a critical point, then the point is a local minimum; if the Hessian matrix is negative definite, then the point is a local maximum; finally, if indefinite, then the point is some kind of [[saddle point]].\n\nConstrained problems can often be transformed into unconstrained problems with the help of [[Lagrange multiplier]]s. [[Lagrangian relaxation]] can also provide approximate solutions to difficult constrained problems.\n\nWhen the objective function is [[Convex function|convex]], then any local minimum will also be a global minimum. There exist efficient numerical techniques for minimizing convex functions, such as [[interior-point method]]s.\n\n== Computational optimization techniques ==\n\nTo solve problems, researchers may use [[algorithm]]s that terminate in a finite number of steps, or [[iterative method]]s that converge to a solution (on some specified class of problems), or [[heuristic algorithm|heuristics]] that may provide approximate solutions to some problems (although their iterates need not converge).\n\n===Optimization algorithms===\n{{see also|List of optimization algorithms}}\n* [[Simplex algorithm]] of [[George Dantzig]], designed for [[linear programming]].\n* Extensions of the simplex algorithm, designed for [[quadratic programming]] and for [[linear-fractional programming]].\n* Variants of the simplex algorithm that are especially suited for [[flow network|network optimization]].\n* [[Combinatorial optimization|Combinatorial algorithms]]\n* [[Quantum optimization algorithms]]\n\n'''Optimization algorithms in machine learning'''\n{{Copypaste|section|url=https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f|date=May 2019}}\n\n'''Introduction'''\n\nAn optimization algorithm is a procedure which is executed iteratively by comparing various solutions until an optimum or a satisfactory solution is found. Optimization algorithms help us to minimize or maximize an objective function  E(x) with respect to the internal parameters of a model mapping a set of predictors (X) to target values(Y). There are three types of optimization algorithms which are widely used; Zero order algorithms, First Order Optimization Algorithms and Second Order Optimization Algorithms.<ref name=\"Walia,A 2017\" />\n\n;Zero-order algorithms\n\nZero-order (or derivative-free) algorithms use only the criterion value at some positions.<ref name=\"Walia,A 2017\">{{cite web |last=Walia |first=Anish |date=2017 |title=Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent |work=towardsdatascience.com |url=https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f }}</ref> It is popular when the gradient and Hessian information are difficult to obtain, e.g., no explicit function forms are given.<ref>{{cite web |first=E. |last=Ruffio |first2=D. |last2=Saury |first3=D. |last3=Petit |first4=M. |last4=Girault |title=Zero-Order optimization algorithms |url=http://www.sft.asso.fr/Local/sft/dir/user-3775/documents/actes/Metti5_School/Lectures&Tutorials-Texts/Text-T2-Ruffio.pdf }}</ref>\n\n;First Order Optimization Algorithms\n\nThese algorithms minimize or maximize a Loss function E(x) using its Gradient values with respect to the parameters.<ref name=\"Walia,A 2017\"/> Most widely used First order optimization algorithm is Gradient Descent.  The First order derivative displays whether the function is decreasing or increasing at a particular point. First order Derivative basically will provide us a line which is tangential to a point on its Error Surface.<ref>Ye.Y. Zero-Order and First-Order Optimization Algorithms I. Stanford University: Department of Management Science and Engineering. Retrieved from https://web.stanford.edu/class/msande311/lecture10.pdf</ref>\n\n''Example''\n\n''Gradient descent''\n\nIt is a first-order optimization algorithm for finding the minimum of a function.\n\nθ=θ−η⋅∇J(θ) – this is the formula of the parameter updates, where ‘η’ is the [[learning rate]], ’∇J(θ)’ is the Gradient of Loss function-J(θ) w.r.t parameters-‘θ’.\n\nIt is the most popular optimization algorithm used in optimizing a Neural Network. Gradient descent is used to update Weights in a Neural Network Model, i.e. update and tune the Model's parameters in a direction so that we can minimize the Loss function. A Neural Network trains via a technique called Back-propagation, in which propagating forward calculating the dot product of Inputs signals and their corresponding Weights and then applying an activation function to those sum of products, which transforms the input signal to an output signal and also is important to model complex Non-linear functions and introduces Non-linearity to the Model which enables the Model to learn almost any arbitrary functional mapping.<ref>Evans.J (1992). Optimization algorithms for networks and graphs. CRC Press 2nd edition.</ref>\n\n'''Second Order Optimization Algorithms'''\n\nSecond-order methods use the second order derivative which is also called Hessian to minimize or maximize the loss function.<ref name=\"Walia,A 2017\"/> The Hessian is a matrix of Second Order Partial Derivatives. Since the second derivative is costly to compute, the second order is not used much. The second order derivative informs us whether the first derivative is increasing or decreasing which hints at the function's curvature. It also provides us with a quadratic surface which touches the curvature of the Error Surface.<ref>{{cite journal |last=Manson |first=L. |last2=Baxter |first2=J. |last3=Bartlett |first3=P. |last4=Fream |first4=M. |title=Boosting Algorithms as Gradient Descent |journal=Advances in Neural Information Processing Systems |year=1999 |volume=12 |issue= |pages=512–518 |chapterurl=http://papers.nips.cc/paper/1766-boosting-algorithms-as-gradient-descent }}</ref>\n\n===Iterative methods===\n{{Main|Iterative method}}\n{{See also|Newton's method in optimization|Quasi-Newton method|Finite difference|Approximation theory|Numerical analysis}}\n\nThe [[iterative methods]] used to solve problems of [[nonlinear programming]] differ according to whether they [[subroutine|evaluate]] [[Hessian matrix|Hessians]], gradients, or only function values. While evaluating Hessians (H) and gradients (G) improves the rate of convergence, for functions for which these quantities exist and vary sufficiently smoothly, such evaluations increase the [[Computational complexity theory|computational complexity]] (or computational cost) of each iteration. In some cases, the computational complexity may be excessively high.\n\nOne major criterion for optimizers is just the number of required function evaluations as this often is already a large computational effort, usually much more effort than within the optimizer itself, which mainly has to operate over the N variables.\nThe derivatives provide detailed information for such optimizers, but are even harder to calculate, e.g. approximating the gradient takes at least N+1 function evaluations. For approximations of the 2nd derivatives (collected in the Hessian matrix), the number of function evaluations is in the order of N². Newton's method requires the 2nd order derivatives, so for each iteration, the number of function calls is in the order of N², but for a simpler pure gradient optimizer it is only N. However, gradient optimizers need usually more iterations than Newton's algorithm. Which one is best with respect to the number of function calls depends on the problem itself.\n* Methods that evaluate Hessians (or approximate Hessians, using [[finite difference]]s):\n** [[Newton's method in optimization|Newton's method]]\n** [[Sequential quadratic programming]]: A Newton-based method for small-medium scale ''constrained'' problems. Some versions can handle large-dimensional problems.\n** [[Interior point methods]]: This is a large class of methods for constrained optimization. Some interior-point methods use only (sub)gradient information and others of which require the evaluation of Hessians.\n* Methods that evaluate gradients, or approximate gradients in some way (or even subgradients):\n** [[Coordinate descent]] methods: Algorithms which update a single coordinate in each iteration\n** [[Conjugate gradient method]]s: [[Iterative method]]s for large problems. (In theory, these methods terminate in a finite number of steps with quadratic objective functions, but this finite termination is not observed in practice on finite–precision computers.)\n** [[Gradient descent]] (alternatively, \"steepest descent\" or \"steepest ascent\"): A (slow) method of historical and theoretical interest, which has had renewed interest for finding approximate solutions of enormous problems.\n** [[Subgradient method]]s - An iterative method for large [[Rademacher's theorem|locally]] [[Lipschitz continuity|Lipschitz functions]] using [[subgradient|generalized gradients]]. Following Boris T. Polyak, subgradient–projection methods are similar to conjugate–gradient methods.\n** Bundle method of descent: An iterative method for small–medium-sized problems with locally Lipschitz functions, particularly for [[convex optimization|convex minimization]] problems.  (Similar to conjugate gradient methods)\n** [[Ellipsoid method]]: An iterative method for small problems with [[quasiconvex function|quasiconvex]] objective functions and of great theoretical interest, particularly in establishing the polynomial time complexity of some combinatorial optimization problems. It has similarities with Quasi-Newton methods.\n** [[Frank–Wolfe algorithm|Conditional gradient method (Frank–Wolfe)]] for approximate minimization of specially structured problems with [[linear constraints]], especially with traffic networks. For general unconstrained problems, this method reduces to the gradient method, which is regarded as obsolete (for almost all problems).\n** [[Quasi-Newton method]]s: Iterative methods for medium-large problems (e.g. N<1000).\n** [[Simultaneous perturbation stochastic approximation]] (SPSA) method for stochastic optimization; uses random (efficient) gradient approximation.\n* Methods that evaluate only function values: If a problem is continuously differentiable, then gradients can be approximated using finite differences, in which case a gradient-based method can be used.\n** [[Interpolation]] methods\n** [[Pattern search (optimization)|Pattern search]] methods, which have better convergence properties than the [[Nelder–Mead method|Nelder–Mead heuristic (with simplices)]], which is listed below.\n\n===Global convergence===\nMore generally, if the objective function is not a quadratic function, then many optimization methods use other methods to ensure that some subsequence of iterations converges to an optimal solution. The first and still popular method for ensuring convergence relies on [[line search]]es, which optimize a function along one dimension. A second and increasingly popular method for ensuring convergence uses [[trust region]]s. Both line searches and trust regions are used in modern methods of [[subgradient method|non-differentiable optimization]]. Usually a global optimizer is much slower than advanced local optimizers (such as [[BFGS method|BFGS]]), so often an efficient global optimizer can be constructed by starting the local optimizer from different starting points.\n\n===Heuristics===\n{{Main|Heuristic algorithm}}\n\nBesides (finitely terminating) [[algorithm]]s and (convergent) [[iterative method]]s, there are [[heuristic algorithm|heuristics]]. A heuristic is any algorithm which is not guaranteed (mathematically) to find the solution, but which is nevertheless useful in certain practical situations. List of some well-known heuristics:\n{{div col}}\n* [[Memetic algorithm]]\n* [[Differential evolution]]\n* [[Evolutionary algorithms]]\n* [[Dynamic relaxation]]\n* [[Genetic algorithms]]\n* [[Hill climbing]] with random restart\n* [[Nelder-Mead method|Nelder-Mead simplicial heuristic]]: A popular heuristic for approximate minimization (without calling gradients)\n* [[Particle swarm optimization]]\n* [[Cuckoo search]]\n* [[Gravitational search algorithm]]\n* [[Artificial bee colony optimization]]\n* [[Simulated annealing]]\n* [[Stochastic tunneling]]\n* [[Tabu search]]\n* [[Reactive Search Optimization|Reactive Search Optimization (RSO)]]<ref>\n{{cite book\n|title=Reactive Search and Intelligent Optimization\n|last1=Battiti\n|first1=Roberto\n|authorlink=\n|author2=Mauro Brunato\n|author3=Franco Mascia\n|url=http://reactive-search.org/thebook\n|year=2008\n|publisher=[[Springer Verlag]]\n|location=\n|isbn=978-0-387-09623-0\n|deadurl=yes\n|archiveurl=https://web.archive.org/web/20120316104607/http://reactive-search.org/thebook\n|archivedate=2012-03-16\n|df=\n}}\n</ref> implemented in [[LIONsolver]]\n{{colend}}\n\n== Applications ==\n\n===Mechanics===\nProblems in [[rigid body dynamics]] (in particular articulated rigid body dynamics) often require mathematical programming techniques, since you can view rigid body dynamics as attempting to solve an [[ordinary differential equation]] on a constraint manifold;<ref>{{cite journal |first=A.F. |last=Vereshchagin |title=Modelling and control of motion of manipulation robots |journal=Soviet Journal of Computer and Systems Sciences |volume=27 |issue=5 |pages=29–38 |year=1989}}</ref> the constraints are various nonlinear geometric constraints such as \"these two points must always coincide\", \"this surface must not penetrate any other\", or \"this point must always lie somewhere on this curve\". Also, the problem of computing contact forces can be done by solving a [[linear complementarity problem]], which can also be viewed as a QP (quadratic programming) problem.\n\nMany design problems can also be expressed as optimization programs. This application is called design optimization. One subset is the [[engineering optimization]], and another recent and growing subset of this field is [[multidisciplinary design optimization]], which, while useful in many problems, has in particular been applied to [[aerospace engineering]] problems.\n\nThis approach may be applied in cosmology and astrophysics.<ref>{{cite journal |first=S. |last=Haggag|first2=F. |last2=Desokey|first3=M. |last3=Ramadan   |title=A cosmological inflationary model using optimal control |journal= Gravitation and Cosmology|volume=23 |issue=3 |pages=236–239 |year=2017 |issn=1995-0721 | doi=10.1134/S0202289317030069 |bibcode=2017GrCo...23..236H}}</ref>\n\n===Economics and finance===\n[[Economics]] is closely enough linked to optimization of [[agent (economics)|agents]] that an influential definition relatedly describes economics ''qua'' science as the \"study of human behavior as a relationship between ends and [[scarce]] means\" with alternative uses.<ref>[[Lionel Robbins]] (1935, 2nd ed.) ''[[An Essay on the Nature and Significance of Economic Science#Major propositions|An Essay on the Nature and Significance of Economic Science]]'', Macmillan, p. 16.</ref>  Modern optimization theory includes traditional optimization theory but also overlaps with [[game theory]] and the study of economic [[equilibrium (economics)|equilibria]]. The ''[[Journal of Economic Literature]]'' [[JEL classification codes|codes]] classify mathematical programming, optimization techniques, and related topics under [[JEL classification codes#Mathematical and quantitative methods JEL: C Subcategories|JEL:C61-C63]].\n\nIn microeconomics, the [[utility maximization problem]] and its [[dual problem]], the [[expenditure minimization problem]], are economic optimization problems. Insofar as they behave consistently, [[consumer]]s are assumed to maximize their [[utility]], while [[firm]]s are usually assumed to maximize their [[Profit (economics)|profit]]. Also, agents are often modeled as being [[Risk aversion|risk-averse]], thereby preferring to avoid risk. [[Asset pricing|Asset prices]] are also modeled using optimization theory, though the underlying mathematics relies on optimizing [[stochastic process]]es rather than on static optimization. [[International trade theory]] also uses optimization to explain trade patterns between nations. The optimization of [[Portfolio (finance)|portfolios]] is an example of multi-objective optimization in economics.\n\nSince the 1970s, economists have modeled dynamic decisions over time using [[control theory]].<ref>{{cite journal |first=Robert |last=Dorfman |authorlink=Robert Dorfman |title=An Economic Interpretation of Optimal Control Theory |journal=[[American Economic Review]] |volume=59 |issue=5 |year=1969 |pages=817–831 |jstor=1810679 }}</ref> For example, dynamic [[search theory|search models]] are used to study [[labor economics|labor-market behavior]].<ref>{{cite book |first=Thomas J. |last=Sargent |authorlink=Thomas J. Sargent |chapter=Search |title=Dynamic Macroeconomic Theory |location= |publisher=Harvard University Press |year=1987 |pages=57–91 |isbn= |chapterurl=https://books.google.com/books?id=nVuyXF8ibeIC&pg=PA57 }}</ref> A crucial distinction is between deterministic and stochastic models.<ref>A.G. Malliaris (2008). \"stochastic optimal control,\" ''The New Palgrave Dictionary of Economics'', 2nd Edition. [http://www.dictionaryofeconomics.com/article?id=pde2008_S000269&edition=&field=keyword&q=Taylor's%20th&topicid=&result_number=1 Abstract] {{Webarchive|url=https://web.archive.org/web/20171018182459/http://www.dictionaryofeconomics.com/article?id=pde2008_S000269&edition=&field=keyword&q=Taylor's%20th&topicid=&result_number=1 |date=2017-10-18 }}.</ref>  [[Macroeconomics|Macroeconomists]] build [[dynamic stochastic general equilibrium|dynamic stochastic general equilibrium (DSGE)]] models that describe the dynamics of the whole economy as the result of the interdependent optimizing decisions of workers, consumers, investors, and governments.<ref>{{cite journal |first=Julio |last=Rotemberg |authorlink=Julio Rotemberg |authorlink2=Michael Woodford (economist) |first2=Michael |last2=Woodford |year=1997 |title=An Optimization-based Econometric Framework for the Evaluation of Monetary Policy |journal=NBER Macroeconomics Annual |volume=12 |issue= |pages=297–346 |doi=10.2307/3585236 |jstor=3585236 }}</ref><ref>From ''[[The New Palgrave Dictionary of Economics]]'' (2008),  2nd Edition with Abstract links:<br />&nbsp;&nbsp; • \"[http://www.dictionaryofeconomics.com/article?id=pde2008_N000148&edition=current&q=optimization&topicid=&result_number=1 numerical optimization methods in economics]\" by Karl Schmedders<br />&nbsp;&nbsp; • \"[http://www.dictionaryofeconomics.com/article?id=pde2008_C000348&edition=current&q=optimization&topicid=&result_number=4 convex programming]\"  by [[Lawrence E. Blume]]<br />&nbsp;&nbsp; • \"[http://www.dictionaryofeconomics.com/article?id=pde2008_A000133&edition=current&q=optimization&topicid=&result_number=20 Arrow–Debreu model of general equilibrium]\" by [[John Geanakoplos]].</ref>\n\n===Electrical engineering===\nSome common applications of optimization techniques in [[electrical engineering]] include [[active filter]] design,<ref>{{Cite journal|last=De|first=Bishnu Prasad|last2=Kar|first2=R.|last3=Mandal|first3=D.|last4=Ghoshal|first4=S.P.|date=2014-09-27|title=Optimal selection of components value for analog active filter design using simplex particle swarm optimization|journal=International Journal of Machine Learning and Cybernetics|volume=6|issue=4|pages=621–636|doi=10.1007/s13042-014-0299-0|issn=1868-8071}}</ref> stray field reduction in superconducting magnetic energy storage systems, [[space mapping]] design of [[microwave]] structures,<ref>{{cite journal |last1=Koziel |first1=Slawomir |last2=Bandler |first2=John W. |title=Space Mapping With Multiple Coarse Models for Optimization of Microwave Components |journal=IEEE Microwave and Wireless Components Letters |date=January 2008 |volume=18 |issue=1 |pages=1–3 |doi=10.1109/LMWC.2007.911969|citeseerx=10.1.1.147.5407 }}</ref> handset antennas,<ref>{{cite journal |last1=Tu |first1=Sheng |last2=Cheng |first2=Qingsha S. |last3=Zhang |first3=Yifan |last4=Bandler |first4=John W. |last5=Nikolova |first5=Natalia K. |title=Space Mapping Optimization of Handset Antennas Exploiting Thin-Wire Models |journal=IEEE Transactions on Antennas and Propagation |date=July 2013 |volume=61 |issue=7 |pages=3797–3807 |doi=10.1109/TAP.2013.2254695|bibcode=2013ITAP...61.3797T }}</ref><ref>N. Friedrich, [http://mwrf.com/software/space-mapping-outpaces-em-optimization-handset-antenna-design “Space mapping outpaces EM optimization in handset-antenna design,”] microwaves&rf, Aug. 30, 2013.</ref><ref>{{cite journal |last1=Cervantes-González |first1=Juan C. |last2=Rayas-Sánchez |first2=José E. |last3=López |first3=Carlos A. |last4=Camacho-Pérez |first4=José R. |last5=Brito-Brito |first5=Zabdiel |last6=Chávez-Hurtado |first6=José L. |title=Space mapping optimization of handset antennas considering EM effects of mobile phone components and human body |journal=International Journal of RF and Microwave Computer-Aided Engineering |date=February 2016 |volume=26 |issue=2 |pages=121–128 |doi=10.1002/mmce.20945}}</ref> electromagnetics-based design. Electromagnetically validated design optimization of microwave components and antennas has made extensive use of an appropriate physics-based or empirical [[surrogate model]] and [[space mapping]] methodologies since the discovery of [[space mapping]] in 1993.<ref>{{cite journal |last1=Bandler |first1=J.W. |last2=Biernacki |first2=R.M. |last3=Chen |first3=Shao Hua |last4=Grobelny |first4=P.A. |last5=Hemmers |first5=R.H. |title=Space mapping technique for electromagnetic optimization |journal=IEEE Transactions on Microwave Theory and Techniques |date=1994 |volume=42 |issue=12 |pages=2536–2544 |doi=10.1109/22.339794|bibcode=1994ITMTT..42.2536B }}</ref><ref>{{cite journal |last1=Bandler |first1=J.W. |last2=Biernacki |first2=R.M. |author3=Shao Hua Chen |last4=Hemmers |first4=R.H. |last5=Madsen |first5=K. |title=Electromagnetic optimization exploiting aggressive space mapping |journal=IEEE Transactions on Microwave Theory and Techniques |date=1995 |volume=43 |issue=12 |pages=2874–2882 |doi=10.1109/22.475649|bibcode=1995ITMTT..43.2874B }}</ref>\n\n===Civil engineering===\nOptimization has been widely used in civil engineering. The most common civil engineering problems that are solved by optimization are cut and fill of roads, life-cycle analysis of structures and infrastructures,<ref>{{cite journal |last1=Piryonesi |first1=Sayed Madeh |last2=Tavakolan |first2=Mehdi |title=A mathematical programming model for solving cost-safety optimization (CSO) problems in the maintenance of structures |journal=KSCE Journal of Civil Engineering |date=9 January 2017 |volume=21 |issue=6 |pages=2226–2234 |doi=10.1007/s12205-017-0531-z}}</ref> [[resource leveling]]<ref>{{cite journal |last1=Hegazy |first1=Tarek |title=Optimization of Resource Allocation and Leveling Using Genetic Algorithms |journal=Journal of Construction Engineering and Management |date=June 1999 |volume=125 |issue=3 |pages=167–175 |doi=10.1061/(ASCE)0733-9364(1999)125:3(167) |doi-access=free}}</ref> and schedule optimization.\n\n===Operations research===\nAnother field that uses optimization techniques extensively is [[operations research]].<ref>{{cite web|title=New force on the political scene: the Seophonisten |url=http://www.seophonist-wahl.de/ |accessdate=14 September 2013 |deadurl=yes |archiveurl=https://web.archive.org/web/20141218090504/http://www.seophonist-wahl.de/ |archivedate=18 December 2014 |df= }}</ref> Operations research also uses stochastic modeling and simulation to support improved decision-making. Increasingly, operations research uses [[stochastic programming]] to model dynamic decisions that adapt to events; such problems can be solved with large-scale optimization and [[stochastic optimization]] methods.\n\n===Control engineering===\nMathematical optimization is used in much modern controller design. High-level controllers such as [[model predictive control]] (MPC) or real-time optimization (RTO) employ mathematical optimization. These algorithms run online and repeatedly determine values for decision variables, such as choke openings in a process plant, by iteratively solving a mathematical optimization problem including constraints and a model of the system to be controlled.\n\n===Geophysics===\nOptimization techniques are regularly used in [[geophysics|geophysical]] parameter estimation problems. Given a set of geophysical measurements, e.g. [[seismology|seismic recordings]], it is common to solve for the [[mineral physics|physical properties]] and [[structure of the earth|geometrical shapes]] of the underlying rocks and fluids.\n\n===Molecular modeling===\n{{main|Molecular modeling}}\nNonlinear optimization methods are widely used in [[conformational analysis]].\n\n===Computational systems biology===\n{{main|Computational systems biology}}\nOptimization techniques are used in many facets of computational systems biology such as model building, optimal experimental design, metabolic engineering, and synthetic biology.<ref name=\"Papoutsakis 1984\">{{Cite journal|last=Papoutsakis|first=Eleftherios Terry|date=February 1984|title=Equations and calculations for fermentations of butyric acid bacteria|journal=Biotechnology and Bioengineering|volume=26|issue=2|pages=174–187|doi=10.1002/bit.260260210|pmid=18551704|issn=0006-3592}}</ref> [[Linear programming]] has been applied to calculate the maximal possible yields of fermentation products,<ref name=\"Papoutsakis 1984\" /> and to infer gene regulatory networks from multiple microarray datasets<ref>{{Cite journal|last=Wang|first=Yong|last2=Joshi|first2=Trupti|last3=Zhang|first3=Xiang-Sun|last4=Xu|first4=Dong|last5=Chen|first5=Luonan|date=2006-07-24|title=Inferring gene regulatory networks from multiple microarray datasets |journal=Bioinformatics|language=en|volume=22|issue=19|pages=2413–2420|doi=10.1093/bioinformatics/btl396|pmid=16864593|issn=1460-2059}}</ref> as well as transcriptional regulatory networks from high-throughput data.<ref>{{Cite journal|last=Wang|first=Rui-Sheng|last2=Wang|first2=Yong|last3=Zhang|first3=Xiang-Sun|last4=Chen|first4=Luonan|date=2007-09-22|title=Inferring transcriptional regulatory networks from high-throughput data|journal=Bioinformatics|volume=23|issue=22|pages=3056–3064|doi=10.1093/bioinformatics/btm465|pmid=17890736|issn=1460-2059}}</ref> [[Nonlinear programming]] has been used to analyze energy metabolism<ref>{{Cite journal|last=Vo|first=Thuy D.|last2=Paul Lee|first2=W.N.|last3=Palsson|first3=Bernhard O.|date=May 2007|title=Systems analysis of energy metabolism elucidates the affected respiratory chain complex in Leigh's syndrome|journal=Molecular Genetics and Metabolism|volume=91|issue=1|pages=15–22|doi=10.1016/j.ymgme.2007.01.012|pmid=17336115|issn=1096-7192}}</ref> and has been applied to metabolic engineering and parameter estimation in biochemical pathways.<ref>{{Cite journal|last1=Mendes|first1=P.|authorlink1 = Pedro Pedrosa Mendes|last2=Kell|first2=D.|date=1998|title=Non-linear optimization of biochemical pathways: applications to metabolic engineering and parameter estimation|journal=Bioinformatics|volume=14|issue=10|pages=869–883|issn=1367-4803|pmid=9927716|doi=10.1093/bioinformatics/14.10.869}}</ref>\n\n===Machine Learning===\n{{main|Machine_learning#Relation_to_optimization}}\n\n== Solvers ==\n{{main|List of optimization software}}\n\n==See also==\n* {{Portal-inline|size=tiny|Mathematical optimization}}\n{{colbegin|colwidth=22em}}\n* [[Brachistochrone]]\n* [[Curve fitting]]\n* [[Deterministic global optimization]]\n* [[Goal programming]]\n* [[List of publications in mathematics#Optimization|Important publications in optimization]]\n* [[Least squares]]\n* [[Mathematical Optimization Society]] (formerly Mathematical Programming Society)\n* [[:Category:Optimization algorithms and methods|Mathematical optimization algorithms]]\n* [[:Category:Mathematical optimization software|Mathematical optimization software]]\n* [[Process optimization]]\n* [[Simulation-based optimization]]\n* [[Test functions for optimization]]\n* [[Variational calculus]]\n* [[Vehicle routing problem]]\n{{colend}}\n\n==Notes==\n{{Reflist}}\n\n==Further reading==\n* {{cite book |last=Boyd |first=Stephen P. |authorlink=Stephen P. Boyd |first2=Lieven |last2=Vandenberghe |title=Convex Optimization |location=Cambridge |publisher=Cambridge University Press |year=2004 |isbn=0-521-83378-7 |url=https://web.stanford.edu/~boyd/cvxbook/ }}\n* {{cite book |first=P. E. |last=Gill |first2=W. |last2=Murray |first3=M. H. |last3=Wright |authorlink3=Margaret H. Wright |year=1982 |title=Practical Optimization |publisher=Academic Press |location=London |isbn=0-12-283952-8 }}\n* {{cite book |last=Lee |first=Jon |authorlink=Jon Lee (mathematician) |title=A First Course in Combinatorial Optimization |location= |publisher=Cambridge University Press |year=2004 |isbn=0-521-01012-8 }}\n* {{cite book | year=2006 |url=http://www.ece.northwestern.edu/~nocedal/book/num-opt.html |title=Numerical Optimization |edition=2nd |publisher=Springer |location=Berlin |isbn=0-387-30303-0 |first=Jorge |last=Nocedal |authorlink=Jorge Nocedal |first2=Stephen J. |last2=Wright }}\n* {{cite book |last1=Snyman |first1=J. A. |last2=Wilke |first2=D. N. |title=Practical Mathematical Optimization : Basic Optimization Theory and Gradient-Based Algorithms |location=Berlin |publisher=Springer |edition=2nd |year=2018 |pages= |isbn=978-3-319-77585-2 }}\n\n==External links==\n{{Commonscat}}\n* {{cite web |url=http://plato.asu.edu/guide.html |title=Decision Tree for Optimization Software }} Links to optimization source codes\n* {{cite web |url=https://www.mat.univie.ac.at/~neum/glopt.html |title=Global optimization }}\n* {{cite web |url=https://see.stanford.edu/Course/EE364A |title=EE364a: Convex Optimization I |work=Course from Stanford University }}\n* {{cite web |title=Mathematical Optimization: Finding Minima of Functions |first=Gaël |last=Varoquaux |url=https://scipy-lectures.org/advanced/mathematical_optimization/index.html }}\n\n{{Optimization algorithms |state=expanded}}\n{{Areas of mathematics |collapsed}}\n{{Systems engineering |collapsed}}\n{{Authority control}}\n[[Category:Mathematical optimization| ]]\n[[Category:Operations research]]\n[[Category:Mathematical and quantitative methods (economics)|Optimization]]"
    },
    {
      "title": "Mathematical Optimization Society",
      "url": "https://en.wikipedia.org/wiki/Mathematical_Optimization_Society",
      "text": "The '''Mathematical Optimization Society''' ('''MOS'''), known as the '''Mathematical Programming Society''' until 2010,<ref> [http://www.mathprog.org/?nav=mps_namechange The Mathematical Optimization Society was known as the '''Mathematical Programming Society''' (MPS) until 2010] {{webarchive|url=https://web.archive.org/web/20110214154115/http://www.mathprog.org/?nav=mps_namechange |date=2011-02-14 }}.</ref> is an international association of researchers active in  [[Optimization (mathematics)|optimization]]. The MOS encourages the research, development, and use of optimization—including [[mathematics|mathematical theory]], [[:Category:Mathematical optimization software|software implementation]], and [[operations research|practical applications (operations research)]].\n\nFounded in 1973, the MOS has several activities: Publishing journals and a newsletter, organizing and cosponsoring conferences, and awarding prizes.\n\n== History ==\nIn the 1960s, [[Optimization (mathematics)|mathematical programming]] methods were gaining increasing importance both in mathematical theory and in industrial application. To provide a discussion forum for researchers in the field arose, the journal ''Mathematical Programming'' was founded in 1970. \n\nBased on activities by [[George B. Dantzig|George Dantzig]], [[Albert W. Tucker|Albert Tucker]], [[Philip Wolfe (mathematician)|Philip Wolfe]] and others, the MOS was founded in 1973, with George Dantzig as its first president.\n\n== Activities ==\n=== Conferences ===\nSeveral conferences are organized or co-organized by the Mathematical Optimization Society, for instance:\n* The ''International Symposium on Mathematical Programming (ISMP)'', organized every three years, is open to all fields of mathematical programming.\n* The ''Integer Programming and Combinatorial Optimization (IPCO)'' conference, in [[Integer programming]], is held in those years when there is no ISMP.\n* The ''International Conference on Continuous Optimization (ICCOPT)'', the continuous analog of the IPCO conference, was first held in 2004.\n* The ''International Conference on Stochastic Programming (ICSP)'' takes place every three years and is devoted to optimization using uncertain input data.\n* The ''Nordic MOS'' conference is a biannual meeting of researchers from [[Scandinavia]] working in all fields of optimization.\n* At the [[Université de Montréal]], annual seminars on changing topics are organized by the MOS.\n\n=== Journals and other publications ===\nThere are several publications by the Mathematical Optimization Society:\n* The journal ''[[Mathematical Programming]]'' (series A/B): series A publishes articles from all fields of optimization; each issue of series B is devoted to a particular subject.\n* The journal ''Mathematical Programming Computation'' \n* ''Optima'', the newsletter of the MOS, contains articles on optimization, conference information and book reviews.\n* ''MPS/SIAM Series on Optimization'' is a series of books that is jointly  published by the MOS (formerly MPS) and the [[Society for Industrial and Applied Mathematics]] (SIAM). It has published [[monograph]]s, [[textbook]]s, books collecting applications of optimization, and [[tutorial]]s.\n\n=== Prizes ===\nThe MOS awards prizes in the field of optimization, including the [[Fulkerson Prize]], the [[Dantzig Prize]] and the [[Tucker Prize]].\n\n== References ==\n{{reflist}}\n\n== External links ==\n* [http://www.mathopt.org/ Homepage of the Mathematical Optimization Society]\n\n[[Category:Mathematical optimization|*]]\n[[Category:Operations research societies]]\n[[Category:Engineering societies based in the United States]]\n[[Category:Organizations established in 1973]]"
    },
    {
      "title": "Ackley function",
      "url": "https://en.wikipedia.org/wiki/Ackley_function",
      "text": "{{multiple image\n   | direction = vertical\n   | width     = 300\n   | header    = \n   | image1    = Ackley's function.pdf\n   | caption1  = Ackley function of two variables\n   | image2    = Ackley3.gif\n   | caption2  = Animation of Ackley's function of three variables with time the 3rd variable.\n}}\n\nIn [[mathematical optimization]], the '''Ackley function''' is a non-[[convex function]] used as a performance test problem for [[optimization algorithm]]s. It was proposed by David Ackley in his 1987 PhD Dissertation.<ref>Ackley, D. H. (1987) \"[https://books.google.com/books?id=sx_VBwAAQBAJ&printsec=frontcover#v=snippet&q=%22Ackley%20function%22&f=false A connectionist machine for genetic hillclimbing]\", Kluwer Academic Publishers, Boston MA.</ref>\n\nOn a 2-dimensional domain it is defined by:\n\n: <math>\n\\begin{align}\nf(x,y) = -20&\\exp\\left[-0.2\\sqrt{0.5\\left(x^{2}+y^{2}\\right)}\\right] \\\\\n& {} -\\exp\\left[0.5\\left(\\cos 2\\pi x + \\cos 2\\pi y \\right)\\right] + e + 20\n\\end{align}\n</math>\n\nIts global optimum point is:  \n:<math>f(0,0) = 0</math>\n\n== See also ==\n*[[Test functions for optimization]]\n\n==Notes==\n<references/>\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "AL procedure",
      "url": "https://en.wikipedia.org/wiki/AL_procedure",
      "text": "The '''AL procedure''' is a procedure for [[fair item assignment]] between two people. It finds an [[envy-free item assignment]] of a subset of the items. Moreover, the resulting allocation is [[Pareto efficient]] in the following sense: there is no other envy-free allocation which is better for one person and not worse for the other person.\n\nThe AL procedure was first published by Brams and Kilgour and Klamler.<ref name=bkk13>{{cite journal|last1=Brams|first1=Steven J.|last2=Kilgour|first2=D. Marc|last3=Klamler|first3=Christian|title=Two-Person Fair Division of Indivisible Items: An Efficient, Envy-Free Algorithm|journal=Notices of the American Mathematical Society|date=1 February 2014|volume=61|issue=2|pages=130|doi=10.1090/noti1075 | name-list-format = vanc }}</ref>\nIt was later generalized by Haris Aziz to handle the case where agents may express indifferences.<ref name=\"h15\">{{cite journal|doi=10.1007/s40505-015-0089-1|title=A generalization of the AL method for fair allocation of indivisible objects|journal=Economic Theory Bulletin|volume=4|issue=2|pages=307–324|year=2015|last1=Aziz|first1=Haris|arxiv=1409.6765}}</ref>\n\n== Assumptions ==\nThe AL procedure requires the following assumptions on the people:\n* Each person can rank the items from best to worst (i.e., each person can report a strict [[preference (economics)|preference relation]] on the items).\n* Each person has a preference relation on bundles of items which is compatible with the [[responsive set extension]] of the ordering on items.\n\n== Requirements ==\nIt is ''not'' assumed that the people can report their preference relation on bundles. There are many bundles, and it may be difficult to report a ranking on all of them.\n\nTherefore, the procedure should return an allocation that is envy-free for ''every'' preference relation that is consistent with the item ranking and with weak additivity. In other words, the procedure should return an allocation that is ''necessarily envy-free'' (NEF).<ref>{{Cite ComSoc Handbook 2016}}</ref>{{rp|303}}\n\nSuppose the two people are Alice and George. An allocation is ''NEF for Alice'' if there is an injection ''f'' from George's items to Alice's items, such that for each item ''x'' received by George, Alice prefers ''f''(''x'') to ''x''. An allocation is ''NEF for George'' if the symmetric property is satisfied. An item assignment is ''NEF'' if it is NEF for both partners. Note that in a NEF assignment, Alice and George receive the same number of items.\n\nThe empty allocation is obviously NEF, but it is very inefficient. Therefore, we are looking for an allocation that is \"best\" among all NEF allocations. A NEF allocation is called [[Pareto-efficient]] if there is no other NEF allocation that is better for one person and not worse for the other one.\n\n== The BT procedure ==\nAs an introduction, consider the following simple division procedure:\n\n* Put all items on the table.\n* While there are items on the table, do:\n** Ask the partners to choose their favorite item from all items on the table.\n** If the choices are different, then give each partner his/her favorite item and continue.\n** If the choices are identical, then send the chosen item to the Contested Pile. It will not be allocated.\n\nThis procedure returns a NEF allocation. It is very simple but not very efficient, since many items are discarded to the contested pile. The AL procedure is slightly more complicated, but it guarantees that the contested pile is never larger, and may be smaller than under BT.\n\n== The AL procedure ==\nThe AL procedure works similarly to the BT procedure, but, before moving an item to the contested pile, it tries to allocate it to one partner while compensating the other partner with another item. Only if this doesn't succeed, the item is sent to the contested pile.\n\nFor example, suppose there are four items (1, 2, 3, 4) and the preferences of the partners are:\n* Alice: 1 > 2 > 3 > 4\n* George: 2 > 3 > 4 > 1\n\nThe BT procedure gives 1 to Alice and 2 to George, since these are their favorites and they are different. Then, both Alice and George choose 3 so it is discarded. Then, both choose 4 so it is also discarded. The final allocation is: Alice←{1}, George←{2}. It is NEF but not PE.\n\nThe AL procedure also starts by giving 1 to Alice and 2 to George. Then, instead of discarding item 3, it is given to Alice, and George is compensated with item 4. The final allocation is: Alice&nbsp;←&nbsp;{1,3}, George&nbsp;←&nbsp;{2,4}. It is NEF and PE.\n\nBoth procedures are manipulable: a partner can gain by reporting incorrect preferences. However, such manipulation requires knowledge of the other partner's preferences, so it is difficult in practice.\n\n== The AL procedure with indifferences ==\nThe original AL procedure crucially relies on the assumption that the item rankings are strict.\n\n<ref name=\"h15\"/> generalizes this procedure to general rankings, with possible indifferences.\n\n== References ==\n{{reflist}}\n\n[[Category:Fair division protocols]]\n[[Category:Game theory]]\n[[Category:Mathematical optimization]]\n[[Category:Pareto efficiency]]"
    },
    {
      "title": "Applicable mathematics",
      "url": "https://en.wikipedia.org/wiki/Applicable_mathematics",
      "text": "#REDIRECT [[Applied mathematics#Applicable mathematics]] {{R from merge}} {{R to section}}\n\n[[Category:Mathematical optimization]]\n[[Category:Applied mathematics]]"
    },
    {
      "title": "Backtracking line search",
      "url": "https://en.wikipedia.org/wiki/Backtracking_line_search",
      "text": "In (unconstrained) [[optimization (mathematics)|minimization]], a '''backtracking line search''', a search scheme based on the '''Armijo–Goldstein condition''', is a [[line search]] method to determine the maximum amount to move along a given search direction. It involves starting with a relatively large estimate of the step size for movement along the search direction, and iteratively shrinking the step size (i.e., \"backtracking\") until a decrease of the [[objective function]] is observed that adequately corresponds to the decrease that is expected, based on the local gradient of the objective function.\n\n==Motivation==\nGiven a starting position <math>\\mathbf{x}</math> and a [[Descent direction|search direction]] <math>\\mathbf{p}</math>, the task of a line search is to determine a step size <math>\\alpha > 0</math> that adequately reduces the objective function <math>f:\\mathbb R^n\\to\\mathbb R</math> (assumed [[smooth function|smooth]]), i.e., to find a value of <math>\\alpha</math> that reduces <math>f(\\mathbf{x}+\\alpha\\,\\mathbf{p})</math> relative to <math>f(\\mathbf{x})</math>. However, it is usually undesirable to devote substantial resources to finding a value of <math>\\alpha</math> to precisely minimize <math>f</math>. This is because the computing resources needed to find a more precise minimum along one particular direction could instead be employed to identify a better search direction. Once an improved starting point has been identified by the line search, another subsequent line search will ordinarily be performed in a new direction. The goal, then, is just to identify a value of <math>\\alpha</math> that provides a reasonable amount of improvement in the objective function, rather than to find the actual minimizing value of <math>\\alpha</math>.\n\nThe backtracking line search starts with a large estimate of <math>\\alpha</math> and iteratively shrinks it. The shrinking continues until a value is found that is small enough to provide a decrease in the objective function that adequately matches the decrease that is expected to be achieved, based on the local function gradient <math>\\nabla f(\\mathbf{x})\\,.</math>\n\nDefine the local slope of the function of <math>\\alpha</math> along the search direction <math>\\mathbf{p}</math> as <math>m = \\mathbf{p}^{\\mathrm T}\\,\\nabla f(\\mathbf{x})\\,.</math> It is assumed that <math>\\mathbf{p}</math> is a unit vector in a direction in which some local decrease is possible, i.e., it is assumed that <math>m < 0</math>.\n\nBased on a selected control parameter <math>c\\,\\in\\,(0,1)</math>, the Armijo–Goldstein condition tests whether a step-wise movement from a current position\n<math>\\mathbf{x}</math> to a modified position <math>\\mathbf{x}+\\alpha\\,\\mathbf{p}</math> achieves an adequately corresponding decrease in the objective function. The  condition is fulfilled if <math>f(\\mathbf{x}+\\alpha\\,\\mathbf{p})\\leq f(\\mathbf{x})+\\alpha\\,c\\,m\\,.</math>\n\nThis condition, when used appropriately as part of a line search, can ensure that the step size is not excessively large. However, this condition is not sufficient on its own to ensure that the step size is nearly optimal, since any value of <math>\\displaystyle \\alpha</math> that is sufficiently small will satisfy the condition.\n\nThus, the backtracking line search strategy starts with a relatively large step size, and repeatedly shrinks it by a factor <math>\\tau\\,\\in\\,(0,1)</math> until the Armijo–Goldstein condition is fulfilled.\n\nThe search will terminate after a finite number of steps for any positive values of <math>c</math> and <math>\\tau</math> that are less than 1.  For example, Armijo used {{fraction|1|2}} for both <math>c</math> and <math>\\tau</math> in a paper he published in 1966.\n\n==Algorithm==\nStarting with a maximum candidate step size value <math>\\alpha_0>0\\,</math>, using search control parameters <math>\\tau\\,\\in\\,(0,1)</math> and <math>c\\,\\in\\,(0,1)</math>, the backtracking line search algorithm can be expressed as follows:\n# Set <math>t = -c\\,m</math> and iteration counter <math>j\\,=\\,0</math>.\n# Until the condition is satisfied that <math>f(\\mathbf{x})-f(\\mathbf{x}+\\alpha_j\\,\\mathbf{p})\\geq \\alpha_j\\,t,</math> repeatedly increment <math>j</math> and set <math>\\alpha_j=\\tau\\,\\alpha_{j-1}\\,.</math> \n# Return <math>\\alpha_j</math> as the solution.\n\nIn other words, reduce <math>\\alpha_0</math> by a factor of <math>\\tau\\,</math> in each iteration until the Armijo–Goldstein condition is fulfilled.\n\n==References==\n* {{cite journal | last =  Armijo | first = Larry | year = 1966 | title = Minimization of functions having Lipschitz continuous first partial derivatives | journal = Pacific J. Math. | volume = 16 | issue = 1 | pages = 1–3 | url = http://projecteuclid.org/euclid.pjm/1102995080 | doi=10.2140/pjm.1966.16.1}}\n* {{cite book | first1= J. E. |last1= Dennis |first2= R. B.|last2= Schnabel|title = Numerical Methods for Unconstrained Optimization and Nonlinear Equations|publisher=[[Society for Industrial and Applied Mathematics|SIAM]] Publications|location= Philadelphia|year= 1996| isbn= 978-0-898713-64-0}}\n* {{Citation|last1= Nocedal|first1= Jorge|last2= Wright|first2= Stephen J. |year=2000|title=Numerical Optimization|publisher= [[Springer-Verlag]]| isbn= 0-387-98793-2|url=https://books.google.com/books?id=epc5fX0lqRIC&printsec=frontcover#v=onepage&q&f=false}}\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Basis pursuit",
      "url": "https://en.wikipedia.org/wiki/Basis_pursuit",
      "text": "'''Basis pursuit''' is the [[mathematical optimization]] problem of the form:\n\n:<math>\\min_x \\|x\\|_1 \\quad \\mbox{subject to} \\quad y = Ax.</math>\n\nwhere ''x'' is a ''N'' &times; 1 solution vector (signal), ''y'' is a ''M'' &times; 1 vector of observations (measurements), ''A'' is a ''M''&nbsp;&times;&nbsp;''N'' transform matrix (usually measurement matrix) and ''M''&nbsp;<&nbsp;''N''.\n\nIt is usually applied in cases where there is an underdetermined system of linear equations ''y''&nbsp;=&nbsp;''Ax'' that must be exactly satisfied, and the [[Sparse vector|sparsest]] solution in the ''L''<sub>1</sub> sense is desired.\n\nWhen it is desirable to trade off exact equality of ''Ax'' and ''y'' in exchange for a sparser ''x'', [[basis pursuit denoising]] is preferred.\n\n== See also ==\n*[[Compressed sensing]]\n*[[Group testing]]\n*[[Lasso (statistics)]]\n*[[Matching pursuit]]\n*[[Sparse approximation]]\n*[[Basis pursuit denoising]]\n\n== References & further reading ==\n*Stephen Boyd, Lieven Vandenbergh: ''Convex Optimization'', Cambridge University Press, 2004, {{ISBN|9780521833783}}, pp. 337-337\n*Simon Foucart, Holger Rauhut: ''A Mathematical Introduction to Compressive Sensing''. Springer, 2013,  {{ISBN|9780817649487}}, pp. 77-110\n\n== External links ==\n*Shaobing Chen, David Donoho: [http://redwood.psych.cornell.edu/discussion/papers/chen_donoho_BP_intro.pdf ''Basis Pursuit'']\n*[[Terence Tao]]: [http://www.math.hkbu.edu.hk/~ttang/UsefulCollections/compressed-sensing1.pdf ''Compressed Sensing'']. Mahler Lecture Series (slides)\n\n[[Category:Mathematical optimization]]\n[[Category:Constraint programming]]\n\n\n{{Mathapplied-stub}}\n\n{{unreferenced|date=December 2010}}"
    },
    {
      "title": "Basis pursuit denoising",
      "url": "https://en.wikipedia.org/wiki/Basis_pursuit_denoising",
      "text": "In [[applied mathematics]] and [[statistics]], '''basis pursuit denoising''' (BPDN) refers to a [[mathematical optimization]] problem of the form:\n\n:<math>\\min_x \\frac{1}{2}\\|y-Ax\\|^2_2+\\lambda\\|x\\|_1,</math>\n\nwhere <math>\\lambda</math> is a parameter that controls the trade-off between [[Sparse vector|sparsity]] and reconstruction fidelity, <math>x</math> is an <math>N \\times 1</math> solution vector, <math>y</math> is an <math>M \\times 1</math> vector of observations, <math>A</math> is an <math>M \\times N</math> transform matrix and <math>M < N</math>. This is an instance of [[convex optimization]] and also of [[quadratic programming]].\n\nSome authors refer to basis pursuit denoising as the following closely related problem:\n:<math>\\min_x \\|x\\|_1 \\;\\textrm{subject} \\ \\textrm{to}\\;\\;\\|y-Ax\\|^2_2 \\le \\delta</math>\nwhich, for any given <math>\\lambda</math>, is equivalent to the unconstrained formulation for some (usually unknown ''a priori'') value of <math>\\delta</math>. The two problems are quite similar. In practice, the unconstrained formulation, for which most specialized and efficient computational algorithms are developed, is usually preferred.\n\nEither types of basis pursuit denoising solve a [[Regularization (mathematics)|regularization]] problem with a trade-off between having a small residual (making <math>y</math> close to <math>Ax</math> in terms of the squared error) and making <math>x</math> simple in the <math>\\ell_1</math>-norm sense. It can be thought of as a mathematical statement of [[Occam's razor]], finding the simplest possible explanation (i.e. one that yields <math>\\min_x \\|x\\|_1</math>) capable of accounting for the observations <math> y</math>.\n\nExact solutions to basis pursuit denoising are often the best computationally tractable approximation of an underdetermined system of equations.{{citation needed|date=January 2014}}  Basis pursuit denoising has potential applications in statistics (c.f. the [[Lasso (statistics)#Lasso method|LASSO]] method of [[Regularization (mathematics)|regularization]]), [[image compression]] and [[compressed sensing]].\n\nAs <math>\\lambda \\rightarrow \\infty</math> (or when <math>\\delta = 0</math>), this problem becomes [[basis pursuit]].\n\nBasis pursuit denoising was introduced by Chen and Donoho in 1994, in the field of signal processing. In statistics, it is well known under the name [[Lasso (statistics)|LASSO]], after being introduced by Tibshirani in 1996.\n\n==Solving basis pursuit denoising==\nThe problem is a convex quadratic problem, so it can be solved by many general solvers, such as [[interior point method]]s. For very large problems, many specialized methods that are faster than interior point methods have been proposed.\n\nSeveral popular methods for solving basis pursuit denoising include the [[in-crowd algorithm]] (a fast solver for large, sparse problems<ref>See ''The In-Crowd Algorithm for Fast Basis Pursuit Denoising'', IEEE Trans Sig Proc 59 (10), Oct 1 2011, pp. 4595 - 4605, [http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5940245], demo [[MATLAB]] code available [http://molnargroup.ece.cornell.edu/files/InCrowdBeta1.zip]</ref>), [[homotopy continuation]], [[fixed-point continuation]] (a special case of the [https://web.archive.org/web/20140216231347/http://www.ugcs.caltech.edu/~srbecker/wiki/Forward_Backward_Algorithm forward backward algorithm]) and [[spectral projected gradient for L1 minimization]] (which actually solves [[Lasso (statistics)#Lasso method|LASSO]], a related problem).\n\n==References==\n{{reflist}}\n\n==External links==\n*A list of [https://web.archive.org/web/20150502191143/http://www.ugcs.caltech.edu/~srbecker/wiki/Category:Solvers BPDN solvers] at the [https://web.archive.org/web/20150504060355/http://ugcs.caltech.edu/~srbecker/wiki/Main_Page sparse- and low-rank approximation wiki].\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Bauer maximum principle",
      "url": "https://en.wikipedia.org/wiki/Bauer_maximum_principle",
      "text": "'''Bauer's maximum principle''' is the following theorem in [[mathematical optimization]]:\n\n::Any function that is [[Convex function|convex]] and [[Continuous function|continuous]], and defined on a set that is [[Convex set|convex]] and [[Compact space|compact]], attains its maximum at some extreme point of that set.\n\nIt is attributed to the German mathematician [[Heinz Bauer]].<ref>{{Cite journal|last=Bauer|first=Heinz|date=1958-11-01|title=Minimalstellen von Funktionen und Extremalpunkte|journal=Archiv der Mathematik|language=de|volume=9|issue=4|pages=389–393|doi=10.1007/BF01898615|issn=1420-8938}}</ref>\n\nBauer's maximum principle immediately implies the analogue ''minimum principle'':\n\n::Any function that is [[Concave function|'''concave''']] and [[Continuous function|continuous]], and defined on a set that is [[Convex set|convex]] and [[Compact space|compact]], attains its '''minimum''' at some extreme point of that set.\n\nSince a [[linear function]] is simultaneously convex and concave, it satisfies both principles, i.e., it attains both its maximum and its minimum at extreme points.\n\nBauer's maximization principle has applications in various fields, for example, differential equations<ref>{{Cite journal|last=Kružík|first=Martin|date=2000-11-01|title=Bauer's maximum principle and hulls of sets|journal=Calculus of Variations and Partial Differential Equations|language=en|volume=11|issue=3|pages=321–332|doi=10.1007/s005260000047|issn=1432-0835}}</ref> and economics.<ref>{{Cite journal|date=2007-11-01|title=Multidimensional mechanism design: Revenue maximization and the multiple-good monopoly|journal=Journal of Economic Theory|language=en|volume=137|issue=1|pages=153–185|doi=10.1016/j.jet.2006.12.007|issn=0022-0531|last1=Manelli|first1=Alejandro M.|last2=Vincent|first2=Daniel R.}}</ref>\n\n== References ==\n{{Reflist}}\n{{math-stub}}\n[[Category:Mathematical optimization]]\n[[Category:Mathematical theorems]]"
    },
    {
      "title": "Bayesian efficiency",
      "url": "https://en.wikipedia.org/wiki/Bayesian_efficiency",
      "text": "{{short description|Analog of Pareto efficiency for situations with incomplete information}}\n{{Bayesian statistics}}\n'''Bayesian efficiency''' is an analog of [[Pareto efficiency]] for situations in which there is [[incomplete information]].<ref name=\"implementation\">Palfrey, Thomas R.; Srivastava, Sanjay; Postlewaite, A. (1993) ''[https://books.google.com/books?id=lZTls-JJSxgC&pg=PA13 Bayesian Implementation.]'' Pg. 13-14. {{ISBN|3-7186-5314-1}}</ref> Under Pareto efficiency, an allocation of a resource is Pareto efficient if there is no other allocation of that resource that makes no one worse off while making some agents strictly better off.<ref name=\"implementation\"/> A limitation with the concept of Pareto efficiency is that it assumes that knowledge about other market participants is available to all participants, in that every player knows the payoffs and strategies available to other players so as to have complete information.<ref name=\"implementation\"/> Often, the players have types that are hidden from the other player.<ref name=\"implementation\"/>\n\n==Overview==\nThe lack of complete information raises a question of when the efficiency calculation should be made.<ref name=\"implementation\"/> Should the efficiency check be made at the [[ex ante]] stage before the agent sees their types, at the interim stage after the agent sees their types, or at the [[ex post]] stage where the agent will have complete information about their types? Another issue is incentive.<ref name=\"implementation\"/> If a resource allocation rule is efficient but there is no incentive to abide by that rule or accept that rule, then the [[revelation principle]] asserts that there is no mechanism by which this allocation rule can be realized.<ref name=\"implementation\"/>\n\nBayesian efficiency overcomes problems of the [[Pareto efficiency]] by accounting for incomplete information, by addressing the timing of the evaluation (ex ante efficient, interim efficient, or ex post efficient), and by adding an incentive qualifier so that the allocation rule is incentive compatible.<ref name=\"implementation\"/><ref>Baltagi, Badi Hani. (2001) ''[https://books.google.com/books?id=qjBF3Z3xcWYC&printsec=frontcover A Companion to Theoretical Econometrics.]'' Blackwell Publishing. {{ISBN|1-4051-0676-X}}</ref>\n\nBayesian efficiency separately defines three types of efficiency: ex ante, interim, and ex post. For an allocation rule <math>x:T\\to A</math>:\n\n''Ex ante efficiency'': <math>x</math> is incentive compatible, and there exists no incentive compatible allocation rule <math>y:T\\to A</math> that\n\n:<math>\\int u^i(y(t),t)dG^i(t) \\geq \\int u^i(x(t),t)dG^i(t)</math>\n\nfor all <math>i</math>, with strict inequality for some <math>i</math>.\n\n''Interim efficiency'': <math>x</math> is incentive compatible, and there exists no incentive compatible allocation rule <math>y:T\\to A</math> that\n\n:<math>\\int U^i(y(t),t)dG^i(t_{-i}|t_i) \\geq \\int U^i(x(t),t)dG^i(t_{-i}|t_i)</math>\n\nfor all <math>i</math> and <math>t_i</math>, with strict inequality for some <math>i</math> and <math>t_i</math>.\n\n''Ex post efficiency'': <math>x</math> is incentive compatible, and there exists no incentive compatible allocation rule <math>y:T\\to A</math> that\n\n:<math>U^i(y(t),t) \\geq U^i(x(t),t)</math>\n\nfor all <math>i</math>, with strict inequality for some <math>i</math>.\n\nHere, <math>G^i</math> are beliefs, <math>U^i</math> are utility functions, and <math>i</math> are agents. An ex ante allocation is always interim and ex post efficient, and an interim efficient allocation is always ex post efficient.<ref name=\"implementation\"/>\n\n==References==\n{{reflist}}\n\n{{game theory}}\n\n[[Category:Bayesian statistics]]\n[[Category:Pareto efficiency]]\n[[Category:Game theory]]\n[[Category:Law and economics]]\n[[Category:Mathematical optimization]]\n[[Category:Optimal decisions]]\n[[Category:Electoral system criteria]]\n[[Category:Welfare economics]]"
    },
    {
      "title": "Bilevel optimization",
      "url": "https://en.wikipedia.org/wiki/Bilevel_optimization",
      "text": "{{more citations needed|date=May 2008}}\n\n'''Bilevel optimization''' is a special kind of [[optimization]] where one problem is embedded (nested) within another. The outer optimization task is commonly referred to as the upper-level optimization task, and the inner optimization task is commonly referred to as the lower-level optimization task. These problems involve two kinds of variables, referred to as the upper-level variables and the lower-level variables.\n\n== Mathematical formulation of the problem ==\nA general formulation of the bilevel optimization problem can be written as follows:\n\n<math> \\min\\limits_{x \\in X, y \\in Y}\\;\\; F(x,y) </math>      In the Stackelberg games: Leader problem\n\nsubject to:\n<math> G_i(x,y) \\leq 0</math>, for <math>i \\in \\{ 1,2,\\ldots ,I \\}</math>;\n\n<math> y \\in  \\arg \\min \\limits_{z \\in Y} \\{ f(x,z) : g_{j}(x,z) \\leq 0, j \\in \\{ 1,2,\\ldots,J \\} \\}</math>           In the Stackelberg games: Follower problem\n\nwhere\n:<math> F,f: R^{n_x} \\times R^{n_y} \\to R</math>\n:<math> G_i,g_j: R^{n_x} \\times R^{n_y}  \\to R</math>\n:<math> X \\subseteq R^{n_x}</math>\n:<math> Y \\subseteq R^{n_y}.</math>\n\nIn the above formulation, <math>F</math> represents the upper-level objective function and <math>f</math> represents the lower-level objective function. Similarly <math>x</math> represents the upper-level decision vector and <math>y</math> represents the lower-level decision vector. <math>G_i</math> and <math>g_j</math> represent the inequality constraint functions at the upper and lower levels respectively.\nIf some objective function is to be maximized, it is equivalent to minimize its negative.\nThe formulation above is also capable of representing equality constraints, as these can be easily rewritten in terms of inequality constraints: for instance, <math>h(x)=0</math> can be translated as <math>\\{h(x)\\leq 0,\\ -h(x)\\leq 0\\}</math>.\nHowever, it is usually worthwhile to treat equality constraints separately, to deal with them more efficiently in a dedicated way;\nin the representation above, they have been omitted for brevity.\n\n== [[Stackelberg competition]] ==\n\nBilevel optimization was first realized in the field of game theory by a German economist [[Heinrich Freiherr von Stackelberg]] who published [[Market Structure and Equilibrium]] (Marktform und Gleichgewicht) in 1934 that described this hierarchical problem. The strategic game described in his book came to be known as Stackelberg game that consists of a leader and a follower.  The leader is commonly referred as a Stackelberg leader and the follower is commonly referred as a Stackelberg follower. In a Stackelberg game, the players of the game compete with each other, such that the leader makes the first move, and then the follower reacts optimally to the leader's action. This kind of a hierarchical game is asymmetric in nature, where the leader and the follower can not be interchanged. The leader knows ex ante that the follower observes its actions before responding in an optimal manner. Therefore, if the leader wants to optimize its objective, then it needs to anticipate the optimal response of the follower. In this setting, the leader's optimization problem contains a nested optimization task that corresponds to the follower's optimization problem. In the Stackelberg games, the upper level optimization problem is commonly referred as the leader's problem and the lower level optimization problem is commonly referred as the follower's problem.\n\n== Applications ==\nBilevel optimization problems are commonly found in a number of real-world problems. This includes problems in the domain of [[transportation]], [[economics]], [[decision science]], [[business]], [[engineering]], [[environmental economics]] etc. Some of the practical bilevel problems studied in the literature are briefly discussed.<ref>{{cite web |url=http://bilevel.org/applications/ |title=Scope: Evolutionary Bilevel Optimization |last1= |first1= |last2= |first2= |date= |website=www.bilevel.org |publisher= |accessdate=6 October 2013}}</ref>\n\n===Toll setting problem===\nIn the field of transportation, bilevel optimization commonly appears in the toll-setting problem. Consider a network of highways that is operated by the government. The government wants to maximize its revenues by choosing the optimal toll setting for the highways. However, the government can maximize its revenues only by taking the highway users' problem into account. For any given tax structure the highway users solve their own optimization problem, where they minimize their traveling costs by deciding between utilizing the highways or an alternative route. Under these circumstances, the government's problem needs to be formulated as a bilevel optimization problem. The upper level consists of the governments objectives and constraints, and the lower level consists of the highway users' objectives and constraints for a given tax structure. It is noteworthy that the government will be able to identify the revenue generated by a particular tax structure only by solving the lower level problem that determines to what extent the highways are used.\n\n===Structural optimization===\nStructural optimization problems consist of two levels of optimization task and are commonly referred as mathematical programming problems with equilibrium constraints ([[Mathematical programming with equilibrium constraints|MPEC]]). The upper level objective in such problems may involve cost minimization or weight minimization subject to bounds on displacements, stresses and contact forces. The decision variables at the upper level usually are shape of the structure, choice of materials, amount of material etc. However, for any given set of upper level variables, the state variables (displacement, stresses and contact forces) can only be figured out by solving the potential energy minimization problem that appears as an equilibrium satisfaction constraint or lower level minimization task to the upper level problem.\n\n===Defense applications===\nBilevel optimization has a number of applications in defense, like [[strategic offensive]] and defensive force structure design, strategic bomber force structure, and allocation of tactical aircraft to missions. The offensive entity in this case may be considered a leader and the defensive entity in this case may be considered a follower. If the leader wants to maximize the damage caused to the opponent, then it can only be achieved if the leader takes the reactions of the follower into account. A rational follower will always react optimally to the leaders offensive. Therefore, the leader's problem appears as an upper level optimization task, and the optimal response of the follower to the leader's actions is determined by solving the lower level optimization task.\n\n== Solution methodologies ==\n\nBilevel optimization problems are hard to solve. One solution method is to reformulate bilevel optimization problems to optimization problems for which robust solution algorithms are available. [[Extended Mathematical Programming (EMP)]] is an extension to mathematical programming languages that provides several keywords for bilevel optimization problems. These annotations facilitate the automatic reformulation to [[Mathematical programming with equilibrium constraints|Mathematical Programs with Equilibrium Constraints]] (MPECs) for which mature solver technology exists. [[Extended Mathematical Programming (EMP)|EMP]] is available within [[General Algebraic Modeling System|GAMS]].\n\n== Evolutionary bilevel optimization ==\nFor complex bilevel problems, classical methods fail due to difficulties like [[non-linearity]], [[discrete group|discreteness]], non-[[differentiability]], non-[[convex set|convexity]] etc. In such situations, evolutionary methods, though computationally demanding, could be an alternative tool to offset some of these difficulties and lead to an approximate optimal solution.\n\n==Multi-objective bilevel optimization==\nA bilevel optimization problem can be generalized to a multi-objective bilevel optimization problem with multiple objectives at one or both levels. A general multi-objective bilevel optimization problem can be formulated as follows:\n\n<math> \\min\\limits_{x \\in X, y \\in Y}\\;\\; F(x,y) = ( F_{1} (x,y),F_{2} (x,y),\\ldots,F_{p} (x,y) )</math>     In the Stackelberg games: Leader problem\n\nsubject to:\n<math> G_i(x,y) \\leq 0</math>, for <math>i \\in \\{ 1,2,\\ldots,I \\}</math>;\n\n<math> y \\in \\arg \\min \\limits_{z \\in Y} \\{ f(x,z) = ( f_1 (x,z),f_2 (x,z),\\ldots,f_q (x,z) ) : g_{j}(x,z) \\leq 0, j \\in \\{ 1,2,\\ldots,J \\} \\}</math>   In the Stackelberg games: Follower problem\n \n\nwhere\n:<math> F: R^{n_x} \\times R^{n_y} \\to R^{p}</math>\n:<math> f: R^{n_x} \\times R^{n_y} \\to R^{q}</math>\n:<math> G_i,g_j: R^{n_x} \\times R^{n_y}  \\to R</math>\n:<math> X \\subseteq R^{n_x}</math>\n:<math> Y \\subseteq R^{n_y}.</math>\n\nIn the above formulation, <math>F</math> represents the upper-level objective vector with <math>p</math> objectives and <math>f</math> represents the lower-level objective vector with <math>q</math> objectives. Similarly, <math>x</math> represents the upper-level decision vector and <math>y</math> represents the lower-level decision vector. <math>G_i</math> and <math>g_j</math> represent the inequality constraint functions at the upper and lower levels respectively. Equality constraints may also be present in a bilevel program, but they have been omitted for brevity.\n\n==References==\n{{Reflist}}\n\n== External links==\n*[http://www.bilevel.org/ Evolutionary Bilevel Optimization]\n*[http://glossary.computing.society.informs.org/ Mathematical Programming Glossary]\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Bilinear program",
      "url": "https://en.wikipedia.org/wiki/Bilinear_program",
      "text": "In mathematics, a '''bilinear program''' is a [[nonlinear optimization]] problem whose objective or constraint functions are [[bilinear form|bilinear]]. An example is the  [[pooling problem]].\n\n==References==\n* [http://glossary.computing.society.informs.org/ver2/mpgwiki/index.php?title=Bilinear_program Bilinear program] at the Mathematical Programming Glossary.\n\n[[Category:Mathematical optimization]]\n\n\n{{mathapplied-stub}}"
    },
    {
      "title": "Binary constraint",
      "url": "https://en.wikipedia.org/wiki/Binary_constraint",
      "text": "A '''binary constraint''', in [[mathematical optimization]], is a constraint that involves exactly two variables.\n\nFor example, consider the [[n-queens problem]], where the goal is to place ''n'' [[Queen (chess)|chess queens]] on an ''n''-by-''n'' chessboard such that none of  the queens can attack each other (horizontally, vertically, or diagonally).  The formal set of constraints are therefore \"Queen 1 can't attack Queen 2\", \"Queen 1 can't attack Queen 3\", and so on between all pairs of queens.  Each constraint in this problem is binary, in that it only considers the placement of two individual queens.<ref>{{citation|title=Programming with Constraints: An Introduction|first1=Kim|last1=Marriott|first2=Peter J.|last2=Stuckey|publisher=MIT Press|year=1998|isbn=9780262133418|page=282|url=https://books.google.com/books?id=jBYAleHTldsC&pg=PA282}}.</ref>\n\n[[Linear program]]s in which all constraints are binary can be solved in [[strongly polynomial time]], a result that is not known to be true for more general linear programs.<ref>{{citation\n | last = Megiddo | first = Nimrod | authorlink = Nimrod Megiddo\n | doi = 10.1137/0212022\n | issue = 2\n | journal = [[SIAM Journal on Computing]]\n | mr = 697165\n | pages = 347–353\n | title = Towards a genuinely polynomial algorithm for linear programming\n | volume = 12\n | year = 1983| citeseerx = 10.1.1.76.5}}.</ref>\n\n==References==\n{{reflist}}\n\n[[Category:Mathematical optimization]]\n[[Category:Constraint programming]]\n\n\n{{Mathapplied-stub}}"
    },
    {
      "title": "Cake number",
      "url": "https://en.wikipedia.org/wiki/Cake_number",
      "text": "In [[mathematics]], the '''cake number''', denoted by ''C<sub>n</sub>'', is the maximum number of regions into which a 3-dimensional cube can be partitioned by exactly ''n'' [[plane (geometry)|plane]]s. The cake number is so-called because one may imagine each partition of the cube by a plane as a slice made by a knife through a cube-shaped [[cake]].\n\nThe values of ''C<sub>n</sub>'' for increasing {{nowrap|1=''n'' ≥ 0}} are given by {{nowrap|1=1, 2, 4, 8, 15, 26, 42, 64, 93, &hellip;}}{{OEIS|id=A000125}}\n\nThe cake numbers are the 3-dimensional analogue of the 2-dimensional [[lazy caterer's sequence]]; the difference between successive cake numbers also gives the lazy caterer's sequence.\n\n[[File:Cake number with 4 cutting planes.gif|thumb|Animation showing the cutting planes required to cut a cake into 15 pieces with 4 slices (representing the 5th cake number). Fourteen of the pieces would have an external surface, with one tetrahedron cut out of the middle.]]\n\n== General formula ==\n\nIf ''n''! denotes the [[factorial]], and we denote the [[binomial coefficient]]s by\n:<math>  {n \\choose k} = \\frac{n!}{k! \\, (n-k)!} , </math>\nand we assume that ''n'' planes are available to partition the cube, then the number is:<ref>{{cite web|url=http://mathworld.wolfram.com/SpaceDivisionbyPlanes.html|title=Space Division by Planes|author=Eric Weisstein|location=MathWorld − A Wolfram Web Resource|accessdate=August 19, 2010}}</ref>\n:<math>\nC_n = {n \\choose 3} + {n \\choose 2} + {n \\choose 1} + {n \\choose 0} = \\frac{1}{6}(n^3 + 5n + 6).  </math>\n\n== References ==\n{{Reflist}}\n\n[[Category:Mathematical optimization]]\n\n\n{{combin-stub}}"
    },
    {
      "title": "Central composite design",
      "url": "https://en.wikipedia.org/wiki/Central_composite_design",
      "text": "In [[statistics]], a '''central composite design''' is an experimental design, useful in [[response surface methodology]], for building a second order (quadratic) model for the [[response variable]] without needing to use a complete three-level [[factorial experiment]].\n\nAfter the designed experiment is performed, [[linear regression]] is used, sometimes iteratively, to obtain results. Coded variables are often used when constructing this design.\n\n==Implementation==\n\nThe design consists of three distinct sets of experimental runs:\n\n# A [[factorial design|factorial]] (perhaps [[Fractional factorial design|fractional]]) design in the factors studied, each having two levels;\n# A set of ''center points'', experimental runs whose values of each factor are the medians of the values used in the factorial portion. This point is often replicated in order to improve the precision of the experiment;\n# A set of ''axial points'', experimental runs identical to the centre points except for one factor, which will take on values both below and above the median of the two factorial levels, and typically both outside their range.  All factors are varied in this way.\n\n==Design matrix ==\nThe design matrix for a central composite design experiment involving ''k'' factors is derived from a matrix, '''d''', containing the following three different parts corresponding to the three types of experimental runs:\n#The matrix '''F''' obtained from the factorial experiment.  The factor levels are scaled so that its entries are coded as +1 and &minus;1.  \n#The matrix '''C''' from the center points, denoted in coded variables as (0,0,0,...,0), where there are ''k'' zeros. \n#A matrix '''E''' from the axial points, with 2''k'' rows. Each factor is sequentially placed at ±α and all other factors are at zero. The value of α is determined by the designer; while arbitrary, some values may give the design desirable properties. This part would look like:\n\n:<math> \\mathbf E = \\begin{bmatrix}\n   \\alpha  & 0 & 0 &  \\cdots  &  \\cdots  &  \\cdots  & 0  \\\\\n   { - \\alpha } & 0 & 0 &  \\cdots  &  \\cdots  &  \\cdots  & 0  \\\\\n   0 & \\alpha  & 0 &  \\cdots  &  \\cdots  &  \\cdots  & 0  \\\\\n   0 & { - \\alpha } & 0 &  \\cdots  &  \\cdots  &  \\cdots  & 0  \\\\\n    \\vdots  & {} & {} & {} & {} & {} & \\vdots  \\\\\n   0 & 0 & 0 & 0 &  \\cdots  &  \\cdots  & \\alpha   \\\\\n   0 & 0 & 0 & 0 &  \\cdots  &  \\cdots  & { - \\alpha }  \\\\\n\\end{bmatrix}. </math>\n\nThen '''d''' is the vertical concatenation:\n:<math> \\mathbf d = \\begin{bmatrix} \\mathbf F \\\\ \\mathbf C \\\\ \\mathbf E \n                  \\end{bmatrix}. </math>\n\nThe design matrix '''X''' used in linear regression is the horizontal concatenation of a column of 1s (intercept), '''d''', and all elementwise products of a pair of columns of '''d''':\n\n:<math>\\mathbf X = \\begin{bmatrix} \\mathbf 1 & \\mathbf d & \\mathbf d(1)\\times\\mathbf d(2) & \\mathbf d(1)\\times\\mathbf d(3) & \\cdots & \\mathbf d(k-1)\\times\\mathbf d(k) & \\mathbf d(1)^2 &\\mathbf d(2)^2 &\\cdots & \\mathbf d(k)^2 \\end{bmatrix}, </math>\n\nwhere '''d'''(''i'') represents the ''i''th column in '''d'''. \n \n=== Choosing &alpha; ===\n\nThere are many different methods to select a useful value of α. Let ''F'' be the number of points due to the factorial design and ''T'' = 2''k'' + ''n'', the number of additional points, where ''n'' is the number of central points in the design. Common values are as follows (Myers, 1971):\n#'''Orthogonal design:''': <math>\\alpha  = (Q\\times F/4)^{1/4}\\,\\!</math>, where <math> Q = (\\sqrt{F + T}  -\\sqrt{F})^2 </math>;\n#'''Rotatable design''': α = ''F''<sup>1/4</sup> (the design implemented by [[MATLAB]]’s ''ccdesign'' function).\n\n=== Application of central composite designs for optimization ===\nStatistical approaches such as RSM can be employed to maximize the production of a special substance by optimization of operational factors. In contrast to conventional methods, the interaction among process variables can be determined by statistical techniques. For instance, in a study, a central composite design was employed to investigate the effect of critical parameters of organosolv pretreatment of rice straw including temperature, time, and ethanol concentration. The residual solid, lignin recovery, and hydrogen yield were selected as the response variables.<ref name=\"Organosolv\">{{cite journal|last1=Asadi|first1=Nooshin|last2=Zilouei|first2=Hamid|title=Optimization of organosolv pretreatment of rice straw for enhanced biohydrogen production using Enterobacter aerogenes|journal=Bioresource Technology|date=March 2017|volume=227|pages=335–344|doi=10.1016/j.biortech.2016.12.073|url=https://www.researchgate.net/publication/311881656_Optimization_of_organosolv_pretreatment_of_rice_straw_for_enhanced_biohydrogen_production_using_Enterobacter_aerogenes}}</ref>\n\n==References==\n{{Reflist}}\nMyers, Raymond H. ''Response Surface Methodology''. Boston: Allyn and Bacon, Inc., 1971\n{{Experimental design}}\n{{Statistics}}\n\n[[Category:Design of experiments]]\n[[Category:Educational research]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Chebyshev center",
      "url": "https://en.wikipedia.org/wiki/Chebyshev_center",
      "text": "{{more footnotes|date=October 2011}}\n\nIn [[geometry]], the '''Chebyshev center''' of a bounded set <math>Q</math> having non-empty [[Interior (topology)|interior]] is the center of the minimal-radius ball enclosing the entire set <math>Q</math>, or alternatively (and non-equivalently) the center of largest inscribed ball of <math>Q</math>.<ref name=\"BV\" />\n\nIn the field of [[parameter estimation]], the Chebyshev center approach tries to find an estimator <math> \\hat x </math> for <math> x </math> given the feasibility set <math> Q </math>, such that <math>\\hat x</math> minimizes the worst possible estimation error for x (e.g. best worst case).\n\n== Mathematical representation ==\nThere exist several alternative representations for the Chebyshev center.\nConsider the set <math>Q</math> and denote its Chebyshev center by <math>\\hat{x}</math>. <math>\\hat{x}</math> can be computed by solving:\n\n: <math> \\min_{{\\hat x},r} \\left\\{ r:\\left\\| {\\hat x} - x \\right\\|^2 \\leq r,  \\forall x \\in Q \\right\\} </math>\n\nor alternatively by solving:\n\n:<math> \\operatorname*{\\arg\\min}_{\\hat{x}} \\max_{x \\in Q} \\left\\| x - \\hat x \\right\\|^2. </math><ref name=\"BV\">{{cite book|title=Convex Optimization|first1=Stephen P.|last1=Boyd|first2=Lieven|last2=Vandenberghe|year=2004|publisher=Cambridge University Press|isbn=978-0-521-83378-3|url=http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf|accessdate=October 15, 2011}}</ref>\n\nDespite these properties, finding the Chebyshev center may be a hard [[numerical optimization problem]]. For example, in the second representation above, the inner maximization is [[nonconvex optimization|non-convex]] if the set ''Q'' is not [[convex set|convex]].\n\n== Properties ==\nIn [[inner product spaces]] and two-dimensional spaces, if <math> Q </math> is closed, bounded and convex, then the Chebyshev center is in <math> Q </math>. In other words, the search for the Chebyshev center can be conducted inside <math> Q </math> without loss of generality.<ref>{{cite book|last1=Amir|first1=Dan|title=International Series of Numerical Mathematics / Internationale Schriftenreihe zur Numerischen Mathematik / Série internationale d'Analyse numérique|date=1984|publisher=Birkhäuser|isbn=9783034862530|pages=19–35|chapter=Best Simultaneous Approximation (Chebyshev Centers)}}</ref>\n\nIn other spaces, the Chebyshev center may not be in  <math> Q </math>, even if  <math> Q </math> is convex. For instance, if <math> Q </math> is the tetrahedron formed by the [[convex hull]] of the points (1,1,1), (-1,1,1), (1,-1,1) and (1,1,-1), then computing the Chebyshev center using the <math> \\ell_{\\infty} </math> norm yields<ref>{{cite journal|last1=Dabbene|first1=Fabrizio|last2=Sznaier|first2=Mario|last3=Tempo|first3=Roberto|title=Probabilistic Optimal Estimation With Uniformly Distributed Noise|journal=IEEE Transactions on Automatic Control|date=August 2014|volume=59|issue=8|pages=2113–2127|doi=10.1109/tac.2014.2318092}}</ref>\n\n: <math> 0 = \\operatorname{\\arg \\min }_{\\hat {x}}\\max _{x\\in Q}\\left\\|x-{\\hat {x}}\\right\\|_{\\infty}^{2}. </math>\n\n== Relaxed Chebyshev center ==\nConsider the case in which the set <math>Q</math> can be represented as the intersection of <math>k</math> ellipsoids.\n\n: <math> \\min_{\\hat x} \\max_x \\left\\{ \\left\\| {\\hat x} - x \\right\\|^2 :f_i (x) \\le 0,0 \\le i \\le k \\right\\} </math>\nwith\n: <math> f_i (x) = x^T Q_i x + 2g_i^T x + d_i  \\le 0,0 \\le i \\le k. \\, </math>\n\nBy introducing an additional matrix variable <math>\\Delta = x x^T </math>, we can write the inner maximization problem of the Chebyshev center as:\n\n: <math> \\min_{\\hat x} \\max_{(\\Delta ,x) \\in G} \\left\\{ \\left\\| {\\hat x} \\right\\|^2  - 2{\\hat x}^T x + \\operatorname{Tr}(\\Delta ) \\right\\} </math>\nwhere <math>\\operatorname{Tr}(\\cdot)</math> is the [[trace (linear algebra)|trace operator]] and\n: <math> G = \\left\\{(\\Delta ,x):{\\rm{f}}_i (\\Delta ,x) \\le 0,0 \\le i \\le k,\\Delta  = xx^T \\right\\} </math>\n: <math> f_i (\\Delta ,x) = \\operatorname{Tr}(Q_i \\Delta ) + 2g_i^T x + d_i. </math>\n\nRelaxing our demand on <math>\\Delta</math> by demanding <math> \\Delta \\ge xx^T </math>, i.e. <math>\\Delta - xx^T  \\in S_+</math> where <math>S_+</math> is the set of [[positive semi-definite matrix|positive semi-definite matrices]], and changing the order of the min max to max min (see the references for more details), the optimization problem can be formulated as:\n\n: <math> RCC = \\max_{(\\Delta ,x) \\in {T}} \\left\\{ - \\left\\| x \\right\\|^2  + \\operatorname{Tr}(\\Delta ) \\right\\} </math>\nwith \n: <math> {T} = \\left\\{ (\\Delta ,x):\\rm{f}_i (\\Delta ,x) \\le 0,0 \\le i \\le k,\\Delta \\ge xx^T  \\right\\}. </math>\n\nThis last '''convex''' optimization problem is known as the '''relaxed Chebyshev center''' (RCC).\nThe RCC has the following important properties:\n* The RCC is an upper bound for the exact Chebyshev center.\n* The RCC is unique.\n* The RCC is feasible.\n\n== Constrained least squares ==\nIt can be shown that the well-known [[constrained least squares]] (CLS) problem is a relaxed version of the Chebyshev center.{{citation needed|date=May 2015}}\n\nThe original CLS problem can be formulated as:\n: <math> {\\hat x}_{CLS}  = \\operatorname*{\\arg\\min}_{x \\in C} \\left\\| y - Ax \\right\\|^2 </math>\nwith \n: <math> { C} = \\left\\{ x:f_i (x) = x^T Q_i x + 2g_i^T x + d_i  \\le 0,1 \\le i \\le k \\right\\} \n</math>\n: <math> Q_i  \\ge 0,g_i  \\in R^m ,d_i  \\in R.  </math>\n\nIt can be shown that this problem is equivalent to the following optimization problem:\n: <math> \\max_{(\\Delta ,{{x}}) \\in {V}} \\left\\{ { - \\left\\| {{x}} \\right\\|^2  + \\operatorname{Tr}(\\Delta )} \\right\\} </math>\nwith\n: <math> V = \\left\\{ \\begin{array}{c}\n (\\Delta ,x):x \\in C{\\rm{ }} \\\\ \n \\operatorname{Tr}(A^T A\\Delta ) - 2y^T A^T x + \\left\\| y \\right\\|^2  - \\rho  \\le 0,\\rm{   }\\Delta  \\ge xx^T  \\\\ \n \\end{array} \\right\\}.</math>\n\nOne can see that this problem is a relaxation of the Chebyshev center (though different than the RCC described above).\n\n== RCC vs. CLS ==\nA solution set <math> (x,\\Delta) </math> for the RCC is also a solution for the CLS, and thus <math> T \\in V </math>.\nThis means that the CLS estimate is the solution of a looser relaxation than that of the RCC.\nHence the '''CLS is an upper bound for the RCC''', which is an upper bound for the real Chebyshev center.\n\n== Modeling constraints ==\nSince both the RCC and CLS are based upon relaxation of the real feasibility set <math>Q</math>, the form in which <math>Q</math> is defined affects its relaxed versions. This of course affects the quality of the RCC and CLS estimators.\nAs a simple example consider the linear box constraints: \n: <math> l \\leq a^T x \\leq u </math>\nwhich can alternatively be written as\n: <math> (a^T x - l)(a^T x - u) \\leq 0. </math>\nIt turns out that the first representation results with an upper bound estimator for the second one, hence using it may dramatically decrease the quality of the calculated estimator.\n\nThis simple example shows us that great care should be given to the formulation of constraints when relaxation of the feasibility region is used.\n\n== Linear programming problem  ==\nThis problem can be formulated as a [[linear programming]] problem, provided that the region Q is an intersection of finitely many hyperplanes.<ref>{{Cite web |url=http://www.ifor.math.ethz.ch/teaching/lectures/intro_ss11/Exercises/solutionEx11-12.pdf |title=Archived copy |access-date=2014-09-12 |archive-url=https://web.archive.org/web/20140912204904/http://www.ifor.math.ethz.ch/teaching/lectures/intro_ss11/Exercises/solutionEx11-12.pdf |archive-date=2014-09-12 |dead-url=yes |df= }}</ref>\n\n== See also ==\n* [[Bounding sphere]]\n* [[Smallest-circle problem]]\n* [[Circumscribed circle]] (covers ''circumcenter'')\n* [[Centre (geometry)]]\n* [[Centroid]]\n\n== References ==\n{{Reflist}}\n* Y. C. Eldar, A. Beck, and M. Teboulle, [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4471880 \"A Minimax Chebyshev Estimator for Bounded Error Estimation,\"] IEEE Trans. Signal Process., 56(4): 1388–1397 (2007).\n* A. Beck and Y. C. Eldar, [https://dx.doi.org/10.1137/060656784 \"Regularization in Regression with Bounded Noise: A Chebyshev Center Approach,\"] SIAM J. Matrix Anal. Appl. 29 (2): 606–625 (2007).\n\n[[Category:Estimation methods]]\n[[Category:Geometric centers]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Clarke's generalized Jacobian",
      "url": "https://en.wikipedia.org/wiki/Clarke%27s_generalized_Jacobian",
      "text": "In mathematics, '''Clarke's generalized Jacobian''' is a generalization of the Jacobian matrix of a smooth function to non-smooth functions. It was introduced by {{harvs|txt|last=Clarke|year=1983}}.\n\n==References==\n\n*{{citation|mr=0709590\n|last=Clarke|first= Frank H.\n|title=Optimization and nonsmooth analysis \n|series=Canadian Mathematical Society Series of Monographs and Advanced Texts. A Wiley-Interscience Publication|publisher= John Wiley & Sons, Inc.,place= New York|year= 1983|isbn=0-471-87504-X }}\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Complementarity theory",
      "url": "https://en.wikipedia.org/wiki/Complementarity_theory",
      "text": "{{dablink|This article is related to [[mathematical programming]]. For other uses see [[complementarity (disambiguation)|complementarity]].}}\n\nA '''complementarity problem''' is a type of [[mathematical optimization]] problem. It is the problem of optimizing (minimizing or maximizing) a function of two [[vector space|vector]] variables subject to certain requirements (constraints) which include: that the [[inner product]] of the two vectors must equal zero, i.e. they are orthogonal.<ref>{{Cite journal | last1=Billups | first1=Stephen | last2=Murty | first2=Katta | title=Complementarity Problems | doi=10.1016/S0377-0427(00)00432-5|url=http://www-personal.umich.edu/~murty/LCPart.ps | year=2000 | journal=Journal of Computational and Applied Mathematics | volume=124 | pages=303| bibcode=2000JCoAM.124..303B }}</ref> In particular for finite-dimensional real vector spaces this means that, if one has vectors ''X'' and ''Y'' with all ''nonnegative'' components (''x''<sub>''i''</sub>&nbsp;≥&nbsp;0 and ''y''<sub>''i''</sub>&nbsp;≥&nbsp;0 for all <math>i</math>: in the [[first quadrant]] if 2-dimensional, in the first [[octant (solid geometry)|octant]] if 3-dimensional), then for each pair of components ''x''<sub>''i''</sub> and ''y''<sub>''i''</sub> one of the pair must be zero, hence the name ''complementarity''. e.g. ''X''&nbsp;=&nbsp;(1,&nbsp;0) and ''Y''&nbsp;=&nbsp;(0,&nbsp;2) are complementary, but ''X''&nbsp;=&nbsp;(1,&nbsp;1) and ''Y''&nbsp;=&nbsp;(2,&nbsp;0) are not. A complementarity problem is a special case of a [[variational inequality]].\n\n==History==\nComplementarity problems were originally studied because the [[Karush–Kuhn–Tucker conditions]] in [[linear programming]] and [[quadratic programming]] constitute a [[linear complementarity problem]] (LCP) or a [[mixed complementarity problem]] (MCP). In 1963 [[Carlton E. Lemke|Lemke]] and [[J.T. Howson|Howson]] showed that, for two person games, computing a [[Nash equilibrium]] point is equivalent to an LCP. In 1968 [[Richard W. Cottle|Cottle]] and [[George B. Dantzig|Dantzig]] unified linear and quadratic programming and [[bimatrix game]]s. Since then the study of complementarity problems and variational inequalities has expanded enormously.\n\nAreas of [[mathematics]] and [[science]] that contributed to the development of complementarity theory\ninclude: [[Optimization (mathematics)|optimization]], [[equilibrium point|equilibrium]] problems, [[Variational inequality|variational inequality theory]], [[fixed point theory]], [[topological degree theory]] and [[nonlinear analysis]].\n\n==See also==\n* [[Mathematical programming with equilibrium constraints]]\n* [[nl (format)|nl format]] for representing complementarity problems\n\n==References==\n<references/>\n\n==Further reading==\n\n* {{cite book |author1=Richard W. Cottle |author2=Jong-Shi Pang |author3=Richard E. Stone | title=The Linear Complementarity Problem\n | publisher=[[Academic Press]] | year=1992 | isbn=978-0-12-192350-1}}\n* {{cite book | author=George Isac | title=Complementarity Problems | publisher=Springer | year=1992 | isbn=978-3-540-56251-1}}\n* {{cite book | author=George Isac | title=Topological Methods in Complementarity Theory | publisher=Springer | year=2000 | isbn=978-0-7923-6274-6}}\n* {{cite book |author1=Francisco Facchinei |author2=Jong-Shi Pang | title=Finite-Dimensional Variational Inequalities and Complementarity Problems: v.1 and v.2 | publisher=Springer | year=2003 | isbn=978-0-387-95580-3}}\n* {{cite book |last=Murty |first=K. G. |title=Linear complementarity, linear and nonlinear programming |series=Sigma Series in Applied Mathematics |volume=3 |publisher=Heldermann Verlag |location=Berlin |year=1988 |pages=xlviii+629 pp. |isbn=3-88538-403-5 |url=http://ioe.engin.umich.edu/people/fac/books/murty/linear_complementarity_webbook/ |mr=949214 |deadurl=yes |archiveurl=https://web.archive.org/web/20100401043940/http://ioe.engin.umich.edu/people/fac/books/murty/linear_complementarity_webbook/ |archivedate=2010-04-01 |df= }}\n\n===Collections===\n\n* {{cite book |editor1=Richard Cottle |editor2=F. Giannessi |editor3=Jacques Louis Lions | title=Variational Inequalities and Complementarity Problems: Theory and Applications | publisher=[[John Wiley & Sons]] | year=1980 | isbn=978-0-471-27610-4}}\n* {{cite book |editor1=Michael C. Ferris |editor2=Jong-Shi Pang | title=Complementarity and Variational Problems: State of the Art | publisher=[[SIAM]] | year=1997 | isbn=978-0-89871-391-6}}\n\n==External links==\n*[https://web.archive.org/web/20080615162953/http://www.cs.wisc.edu/cpnet/ CPNET:Complementarity Problem Net]\n\n[[Category:Mathematical optimization]]\n[[Category:Functional analysis]]\n[[Category:Topology]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Compressed sensing",
      "url": "https://en.wikipedia.org/wiki/Compressed_sensing",
      "text": "{{pp-semi|small=yes}}\n'''Compressed sensing''' (also known as '''compressive sensing''', '''compressive sampling''', or '''sparse sampling''') is a [[signal processing]] technique for efficiently acquiring and reconstructing a [[Signal (electronics)|signal]], by finding solutions to [[Underdetermined system|underdetermined linear systems]]. This is based on the principle that, through optimization, the sparsity of a signal can be exploited to recover it from far fewer samples than required by the [[Nyquist–Shannon sampling theorem]]. There are two conditions under which recovery is possible.<ref>[http://nuit-blanche.blogspot.com/2009/09/cs.html CS: Compressed Genotyping, DNA Sudoku – Harnessing high throughput sequencing for multiplexed specimen analysis].</ref> The first one is [[sparsity]], which requires the signal to be sparse in some domain. The second one is [[Coherence (signal processing)|incoherence]], which is applied through the isometric property, which is sufficient for sparse signals.<ref>{{cite journal | last1 = Donoho | first1 = David L. | year = 2006 | title =  For most large underdetermined systems of linear equations the minimal 1-norm solution is also the sparsest solution| url = | journal = Communications on Pure and Applied Mathematics | volume = 59 | issue = 6| pages = 797–829 | doi = 10.1002/cpa.20132 }}</ref><ref>M. Davenport, [http://www.brainshark.com/brainshark/brainshark.net/portal/title.aspx?pid=zCdz10BfTRz0z0 \"The Fundamentals of Compressive Sensing\"], SigView, April 12, 2013.</ref>\n\n== Overview ==\nA common goal of the engineering field of [[signal processing]] is to reconstruct a signal from a series of sampling measurements. In general, this task is impossible because there is no way to reconstruct a signal during the times that the signal is not measured. Nevertheless, with prior knowledge or assumptions about the signal, it turns out to be possible to perfectly reconstruct a signal from a series of measurements (acquiring this series of measurements is called [[Sampling (signal processing)|sampling]]). Over time, engineers have improved their understanding of which assumptions are practical and how they can be generalized.\n\nAn early breakthrough in signal processing was the [[Nyquist–Shannon sampling theorem]]. It states that if a [[Real number|real]] signal's highest frequency is less than half of the sampling rate (or less than the sampling rate, if the signal is [[Complex number|complex]]), then the signal can be reconstructed perfectly by means of [[Whittaker–Shannon interpolation formula|sinc interpolation]]. The main idea is that with prior knowledge about constraints on the signal's frequencies, fewer samples are needed to reconstruct the signal.\n\nAround 2004, [[Emmanuel Candès]], [[Justin Romberg]], [[Terence Tao]], and [[David Donoho]] proved that given knowledge about a signal's [[sparsity]], the signal may be reconstructed with even fewer samples than the sampling theorem requires.<ref>{{Cite journal|doi=10.1002/cpa.20124|url=http://www-stat.stanford.edu/~candes/papers/StableRecovery.pdf|title=Stable signal recovery from incomplete and inaccurate measurements|year=2006|last1=Candès|first1=Emmanuel J.|last2=Romberg|first2=Justin K.|last3=Tao|first3=Terence|journal=Communications on Pure and Applied Mathematics|volume=59|issue=8|pages=1207–1223|arxiv=math/0503066}}</ref><ref name=Donoho>{{Cite journal|doi=10.1109/TIT.2006.871582|title=Compressed sensing|year=2006|last1=Donoho|first1=D.L.|journal=IEEE Transactions on Information Theory|volume=52|issue=4|pages=1289–1306}}</ref> This idea is the basis of compressed sensing.\n\n==History==\nCompressed sensing relies on [[Lp space|L1]] techniques, which several other scientific fields have used historically.<ref>[http://2.bp.blogspot.com/_0ZCyAOBrUtA/TTwqLEeLvdI/AAAAAAAAEXI/7S0_SnWoC0E/s1600/l1-minimization.JPG List of L1 regularization ideas] from Vivek Goyal, Alyson Fletcher, Sundeep Rangan, [http://www.math.uiuc.edu/%7Elaugesen/imaha10/goyal_talk.pdf The Optimistic Bayesian: Replica Method Analysis of Compressed Sensing]</ref> In statistics, the [[least squares]] method was complemented by the [[Lp norm|<math>L^1</math>-norm]], which was introduced by [[Pierre-Simon Laplace|Laplace]]. Following the introduction of [[linear programming]] and [[George Dantzig|Dantzig]]'s [[simplex algorithm]], the <math>L^1</math>-norm was used in [[computational statistics]]. In statistical theory, the <math>L^1</math>-norm was used by [[George W. Brown (academic)|George W. Brown]] and later writers on [[median-unbiased estimator]]s. It was used by Peter J. Huber and others working on [[robust statistics]]. The <math>L^1</math>-norm was also used in signal processing, for example, in the 1970s, when seismologists constructed images of reflective layers within the earth based on data that did not seem to satisfy the [[Nyquist–Shannon sampling theorem|Nyquist–Shannon criterion]].<ref>{{Cite journal |doi = 10.1511/2009.79.276 |title = The Best Bits |year = 2009 |last1 = Hayes |first1 = Brian |journal = American Scientist |volume = 97 |issue = 4 |pages = 276 }}</ref>  It was used in [[matching pursuit]] in 1993, the [[Lasso regression|LASSO estimator]] by [[Robert Tibshirani]] in 1996<ref>{{Cite journal |url = http://www-stat.stanford.edu/~tibs/lasso.html |first = Robert |last = Tibshirani |title = Regression shrinkage and selection via the lasso |journal = [[Journal of the Royal Statistical Society, Series B]] |volume = 58 |issue = 1 |pages = 267–288 }}</ref> and [[basis pursuit]] in 1998.<ref>\"Atomic decomposition by basis pursuit\", by Scott Shaobing Chen, David L. Donoho, Michael, A. Saunders. SIAM Journal on Scientific Computing</ref>  There were theoretical results describing when these algorithms recovered sparse solutions, but the required type and number of measurements were sub-optimal and subsequently greatly improved by compressed sensing.{{citation needed|date=May 2013}}\n\nAt first glance, compressed sensing might seem to violate [[Nyquist–Shannon sampling theorem|the sampling theorem]], because compressed sensing depends on the [[Sparse matrix|sparsity]] of the signal in question and not its highest frequency. This is a misconception, because the sampling theorem guarantees perfect reconstruction given sufficient, not necessary, conditions. A sampling method fundamentally different from classical fixed-rate sampling cannot \"violate\" the sampling theorem. Sparse signals with high frequency components can be highly under-sampled using compressed sensing compared to classical fixed-rate sampling.<ref>{{Cite journal |url = http://www-stat.stanford.edu/~candes/papers/ExactRecovery.pdf |title = Robust Uncertainty Principles: Exact Signal Reconstruction from Highly Incomplete Fourier Information |year = 2006 |last1 = Candès |first1 = Emmanuel J. |last2 = Romberg |first2 = Justin K. |last3 = Tao |first3 = Terence |journal = IEEE Trans. Inf. Theory |volume = 52 |issue = 8 |pages = 489–509 |doi=10.1109/tit.2005.862083|arxiv = math/0409186 |citeseerx = 10.1.1.122.4429 }}</ref>\n\n==Method==\n\n===Underdetermined linear system===\nAn [[underdetermined system]] of linear equations has more unknowns than equations and generally has an infinite number of solutions. The figure below shows such an equation system <math> \\mathbf{y}=D\\mathbf{x} </math> where we want to find a solution for <math> \\mathbf{x} </math>.\n\n[[File:Underdetermined equation system.svg|200px|alt=Underdetermined linear equation system|Underdetermined linear equation system]]\n\nIn order to choose a solution to such a system, one must impose extra constraints or conditions (such as smoothness) as appropriate. In compressed sensing, one adds the constraint of sparsity, allowing only solutions which have a small number of nonzero coefficients. Not all underdetermined systems of linear equations have a sparse solution. However, if there is a unique sparse solution to the underdetermined system, then the compressed sensing framework allows the recovery of that solution.\n\n===Solution / reconstruction method===\nCompressed sensing takes advantage of the redundancy in many interesting signals—they are not pure noise. In particular, many signals are [[sparse matrix|sparse]], that is, they contain many coefficients close to or equal to zero, when represented in some domain.<ref>Candès, E.J., & Wakin, M.B., ''An Introduction To Compressive Sampling'', IEEE Signal Processing Magazine, V.21, March 2008 [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4472240&isnumber=4472102]</ref> This is the same insight used in many forms of [[lossy compression]].\n\nCompressed sensing typically starts with taking a weighted linear combination of samples also called compressive measurements in a [[Basis (linear algebra)|basis]] different from the basis in which the signal is known to be sparse. The results found by  [[Emmanuel Candès]], [[Justin Romberg]],  [[Terence Tao]] and  [[David Donoho]], showed that the number of these compressive measurements can be small and still contain nearly all the useful information. Therefore, the task of converting the image back into the intended domain involves solving an underdetermined [[matrix equation]] since the number of compressive measurements taken is smaller than the number of pixels in the full image. However, adding the constraint that the initial signal is sparse enables one to solve this underdetermined [[system of linear equations]].\n\nThe least-squares solution to such problems is to minimize the [[L2 norm|<math>L^2</math> norm]]—that is, minimize the amount of energy in the system. This is usually simple mathematically (involving only a [[matrix multiplication]] by the [[pseudo-inverse]] of the basis sampled in). However, this leads to poor results for many practical applications, for which the unknown coefficients have nonzero energy.\n\nTo enforce the sparsity constraint when solving for the underdetermined system of linear equations, one can minimize the number of nonzero components of the solution. The function counting the number of non-zero components of a vector was called the [[L0 norm|<math>L^0</math> \"norm\"]] by David Donoho{{refn|group=note|The quotation marks served two warnings.  First, the number-of-nonzeros <math>L^0</math>-\"norm\" is not a proper [[F-space|F-norm]], because it is not continuous in its scalar argument: ''nnzs''(α''x'') is constant as α approaches zero. Unfortunately, authors now neglect the quotation marks and [[abuse of terminology|abused terminology]]—clashing with the established use of the <math>L^0</math> norm for the space of measurable functions (equipped with an appropriate metric) or for the [[F-space|space]] of sequences with [[F-space|F–norm]] <math>(x_n) \\mapsto \\sum_n{2^{-n} x_n/(1+x_n)}</math>.<ref>Stefan Rolewicz. ''Metric Linear Spaces''.</ref>}}.\n\n[[Emmanuel Candès|Candès]] et al. proved that for many problems it is probable that the [[L1 norm|<math>L^1</math> norm]] is equivalent to the [[L0 norm|<math>L^0</math> norm]], in a technical sense: This equivalence result allows one to solve the <math>L^1</math> problem, which is easier than the <math>L^0</math> problem. Finding the candidate with the smallest <math>L^1</math> norm can be expressed relatively easily as a [[linear program]], for which efficient solution methods already exist.<ref>[http://www.acm.caltech.edu/l1magic/ L1-MAGIC is a collection of MATLAB routines]</ref>  When measurements may contain a finite amount of noise, [[basis pursuit denoising]] is preferred over linear programming, since it preserves sparsity in the face of noise and can be solved faster than an exact linear program.\n\n=== Total variation based CS reconstruction ===\n{{see also|Total variation denoising}}\n{{split section|Total variation reconstruction|date=May 2017}}<!-- reason=Longest section in current article. -->\n\n==== Motivation and applications ====\n\n===== Role of TV regularization =====\n[[Total variation]] can be seen as a [[non-negative]] [[real number|real]]-valued [[functional (mathematics)|functional]] defined on the space of [[real number|real-valued]] [[function (mathematics)|function]]s (for the case of functions of one variable) or on the space of [[integrable function]]s (for the case of functions of several variables). For signals, especially, [[total variation]] refers to the integral of the absolute [[gradient]] of the signal. In signal and image reconstruction, it is applied as [[total variation regularization]] where the underlying principle is that signals with excessive details have high total variation and that removing these details, while retaining important information such as edges, would reduce the total variation of the signal and make the signal subject closer to the original signal in the problem.\n\nFor the purpose of signal and image reconstruction, <math>l1</math> minimization models are used. Other approaches also include the least-squares as has been discussed before in this article. These methods are extremely slow and return a not-so-perfect reconstruction of the signal. The current CS Regularization models attempt to address this problem by incorporating sparsity priors of the original image, one of which is the total variation (TV). Conventional TV approaches are designed to give piece-wise constant solutions. Some of these include (as discussed ahead) – constrained l1-minimization which uses an iterative scheme. This method, though fast, subsequently leads to over-smoothing of edges resulting in blurred image edges.<ref name = \"EPTV\" /> TV methods with iterative re-weighting have been implemented to reduce the influence of large gradient value magnitudes in the images. This has been used in [[Tomography|computed tomography]] (CT) reconstruction as a method known as edge-preserving total variation. However, as gradient magnitudes are used for estimation of relative penalty weights between the data fidelity and regularization terms, this method is not robust to noise and artifacts and accurate enough for CS image/signal reconstruction and, therefore, fails to preserve smaller structures.\n\nRecent progress on this problem involves using an iteratively directional TV refinement for CS reconstruction.<ref name = \"Orientation and directional refinement\" /> This method would have 2 stages: the first stage would estimate and refine the initial orientation field – which is defined as a noisy point-wise initial estimate, through edge-detection, of the given image. In the second stage, the CS reconstruction model is presented by utilizing directional TV regularizer. More details about these TV-based approaches – iteratively reweighted l1 minimization, edge-preserving TV and iterative model using directional orientation field and TV- are provided below.\n\n==== Existing approaches ====\n\n=====Iteratively reweighted <math>l_{1}</math> minimization =====\n[[File:IRLS.png|thumb|iteratively reweighted l1 minimization method for CS]]\nIn the CS reconstruction models using constrained <math>l_{1}</math> minimization,<ref name=\"Original source for IRLS\">{{cite journal | last1 = Candes | first1 = E. J. | last2 = Wakin | first2 = M. B. | last3 = Boyd | first3 = S. P. | year = 2008 | title = Enhancing sparsity by reweighted l1 minimization | url = | journal = J. Fourier Anal. Applicat | volume = 14 | issue = 5–6| pages = 877–905 | doi=10.1007/s00041-008-9045-x| arxiv = 0711.1612 }}</ref> larger coefficients are penalized heavily in the <math>l_{1}</math> norm. It was proposed to have a weighted formulation of <math>l_{1}</math> minimization designed to more democratically penalize nonzero coefficients. An iterative algorithm is used for constructing the appropriate weights.<ref name=\"Iteration\">Lange, K.: Optimization, Springer Texts in Statistics. Springer, New York (2004)</ref> Each iteration requires solving one <math>l_{1}</math> minimization problem by finding the local minimum of a concave penalty function that more closely resembles the <math>l_{0}</math> norm. An additional parameter, usually to avoid any sharp transitions in the penalty function curve, is introduced into the iterative equation to ensure stability and so that a zero estimate in one iteration does not necessarily lead to a zero estimate in the next iteration. The method essentially involves using the current solution for computing the weights to be used in the next iteration.\n\n====== Advantages and disadvantages ======\nEarly iterations may find inaccurate sample estimates, however this method will down-sample these at a later stage to give more weight to the smaller non-zero signal estimates. One of the disadvantages is the need for defining a valid starting point as a global minimum might not be obtained every time due to the concavity of the function. Another disadvantage is that this method tends to uniformly penalize the image gradient irrespective of the underlying image structures. This causes over-smoothing of edges, especially those of low contrast regions, subsequently leading to loss of low contrast information. The advantages of this method include: reduction of the sampling rate for sparse signals; reconstruction of the image while being robust to the removal of noise and other artifacts; and use of very few iterations. This can also help in recovering images with sparse gradients.\n\nIn the figure shown below, '''P1''' refers to the first-step of the iterative reconstruction process, of the projection matrix '''P''' of the fan-beam geometry, which is constrained by the data fidelity term. This may contain noise and artifacts as no regularization is performed. The minimization of '''P1''' is solved through the conjugate gradient least squares method. '''P2''' refers to the second step of the iterative reconstruction process wherein it utilizes the edge-preserving total variation regularization term to remove noise and artifacts, and thus improve the quality of the reconstructed image/signal. The minimization of '''P2''' is done through a simple gradient descent method. Convergence is determined by testing, after each iteration, for image positivity, by checking if <math>f^{k-1} = 0</math> for the case when <math>f^{k-1} < 0</math> (Note that <math>f</math> refers to the different x-ray linear attenuation coefficients at different voxels of the patient image).\n\n=====Edge-preserving total variation (TV) based compressed sensing<ref name =\"EPTV\">{{cite journal | last1 = Tian | first1 = Z. | last2 = Jia | first2 = X. | last3 = Yuan | first3 = K. | last4 = Pan | first4 = T. | last5 = Jiang | first5 = S. B. | year = 2011 | title = Low-dose CT reconstruction via edge preserving total variation regularization | url = | journal = Phys Med Biol | volume = 56 | issue = 18| pages = 5949–5967 | doi=10.1088/0031-9155/56/18/011| pmid = 21860076 | pmc = 4026331 | arxiv = 1009.2288 | bibcode = 2011PMB....56.5949T }}</ref>=====\n[[File:Edge preserving TV.png|thumb|Flow diagram figure for edge preserving total variation method for compressed sensing]]\nThis is an iterative CT reconstruction algorithm with edge-preserving TV regularization to reconstruct CT images from highly undersampled data obtained at low dose CT through low current levels (milliampere).  In order to reduce  the imaging dose, one of the approaches used is to reduce the number of x-ray projections acquired by the scanner detectors. However, this insufficient projection data which is used to reconstruct the CT image can cause streaking artifacts. Furthermore, using these insufficient projections in standard TV algorithms end up making the problem under-determined and thus leading to infinitely many possible solutions. In this method, an additional penalty weighted function is assigned to the original TV norm. This allows for easier detection of sharp discontinuities in intensity in the images and thereby adapt the weight to store the recovered edge information during the process of signal/image reconstruction. The parameter <math>\\sigma</math> controls the amount of smoothing applied to the pixels at the edges to differentiate them from the non-edge pixels. The value of <math>\\sigma</math> is changed adaptively based on the values of the histogram of the gradient magnitude so that a certain percentage of pixels have gradient values larger than <math>\\sigma</math>. The edge-preserving total variation term, thus, becomes sparser and this speeds up the implementation. A two-step iteration process known as forward-backward splitting algorithm is used.<ref name = \"Forward-Backward\">{{cite journal | last1 = Combettes | first1 = P | last2 = Wajs | first2 = V | year = 2005 | title = Signal recovery by proximal forward-backward splitting | url = | journal = Multiscale Model Simul | volume = 4 | issue = 4| pages = 1168–200 | doi=10.1137/050626090}}</ref> The optimization problem is split into two sub-problems which are then solved with the conjugate gradient least squares method<ref name=\"CGLS\">{{cite journal | last1 = Hestenes | first1 = M | last2 = Stiefel | first2 = E | year = 1952 | title = Methods of conjugate gradients for solving linear systems | url = | journal = J Res Natl Bur Stand | volume = 49 | issue = 6| pages = 409–36 | doi=10.6028/jres.049.044}}</ref> and the simple gradient descent method respectively. The method is stopped when the desired convergence has been achieved or if the maximum number of iterations is reached.\n\n===== Advantages and disadvantages =====\nSome of the disadvantages of this method are the absence of smaller structures in the reconstructed image and degradation of image resolution. This edge preserving TV algorithm, however, requires fewer iterations than the conventional TV algorithm.<ref name =\"EPTV\" /> Analyzing the horizontal and vertical intensity profiles of the reconstructed images, it can be seen that there are sharp jumps at edge points and negligible, minor fluctuation at non-edge points. Thus, this method leads to low relative error and higher correlation as compared to the TV method. It also effectively suppresses and removes any form of image noise and image artifacts such as streaking.\n\n=====Iterative model using a directional orientation field and directional total variation<ref name=\"Orientation and directional refinement\">{{Cite journal | doi=10.1109/LSP.2013.2280571| title=Iterative Directional Total Variation Refinement for Compressive Sensing Image Reconstruction| journal=IEEE Signal Processing Letters| volume=20| issue=11| pages=1070–1073| year=2013| last1=Xuan Fei| last2=Zhihui Wei| last3=Liang Xiao|bibcode = 2013ISPL...20.1070F}}</ref>=====\nTo prevent over-smoothing of edges and texture details and to obtain a reconstructed CS image which is accurate and robust to noise and artifacts, this method is used. First, an initial estimate of the noisy point-wise orientation field of the image <math>I</math>, <math>\\hat{d}</math>, is obtained. This noisy orientation field is defined so that it can be refined at a later stage to reduce the noise influences in orientation field estimation.A coarse orientation field estimation is then introduced based on structure tensor which is formulated as:<ref name=\"Structure tensor\">{{cite journal | last1 = Brox | first1 = T. | last2 = Weickert | first2 = J. | last3 = Burgeth | first3 = B. | last4 = Mrázek | first4 = P. | year = 2006 | title = Nonlinear structure tensors | url = | journal = Image Vis. Comput | volume = 24 | issue = 1| pages = 41–55 | doi=10.1016/j.imavis.2005.09.010| citeseerx = 10.1.1.170.6085 }}</ref> <math> J_\\rho(\\nabla I_{\\sigma}) = G_\\rho * (\\nabla I_{\\sigma} \\otimes \\nabla I_{\\sigma}) = \\begin{pmatrix}J_{11} & J_{12}\\\\J_{12} & J_{22}\\end{pmatrix}</math>. Here, <math> J_\\rho </math> refers to the structure tensor related with the image pixel point (i,j) having standard deviation <math>\\rho</math>. <math>G</math> refers to the Gaussian kernel <math>(0, \\rho ^2)</math> with standard deviation <math>\\rho</math>. <math>\\sigma</math> refers to the manually defined parameter for the image <math>I</math> below which the edge detection is insensitive to noise. <math>\\nabla I_{\\sigma}</math> refers to the gradient of the image <math>I</math> and <math>(\\nabla I_{\\sigma} \\otimes \\nabla I_{\\sigma})</math> refers to the tensor product obtained by using this gradient.\n\nThe structure tensor obtained is convolved with a Gaussian kernel <math>G</math> to improve the accuracy of the orientation estimate with <math>\\sigma</math> being set to high values to account for the unknown noise levels. For every pixel (i,j) in the image, the structure tensor J is a symmetric and positive semi-definite matrix. Convolving all the pixels in the image with <math>G</math>, gives orthonormal eigen vectors  ω and υ of the <math>J</math> matrix. ω points in the direction of the dominant orientation having the largest contrast and υ points in the direction of the structure orientation having the smallest contrast.  The orientation field coarse initial estimation <math>\\hat{d}</math> is defined as <math>\\hat{d}</math> = υ.  This estimate is accurate at strong edges. However, at weak edges or on regions with noise, its reliability decreases.\n\nTo overcome this drawback, a refined orientation model is defined in which the data term reduces the effect of noise and improves accuracy while the second penalty term with the L2-norm is a fidelity term which ensures accuracy of initial coarse estimation.\n\nThis orientation field is introduced into the directional total variation optimization model for CS reconstruction through the equation: <math>min_\\Chi\\lVert \\nabla \\Chi \\bullet d \\rVert _{1} + \\frac{\\lambda}{2}\\ \\lVert Y - \\Phi\\Chi \\rVert ^2_{2}</math>. <math>\\Chi</math> is the objective signal which needs to be recovered. Y is the corresponding measurement vector, d is the iterative refined orientation field and <math>\\Phi</math> is the CS measurement matrix. This method undergoes a few iterations ultimately leading to convergence.<math>\\hat{d}</math> is the orientation field approximate estimation of the reconstructed image <math>X^{k-1}</math> from the previous iteration (in order to check for convergence and the subsequent optical performance, the previous iteration is used). For the two vector fields represented by  <math>\\Chi</math> and <math>d</math>, <math>\\Chi \\bullet d</math> refers to the multiplication of respective horizontal and vertical vector elements of <math>\\Chi</math> and <math>d</math> followed by their subsequent addition. These equations are reduced to a series of convex minimization problems which are then solved with a combination of variable splitting and augmented Lagrangian (FFT-based fast solver with a closed form solution) methods.<ref name = \"Orientation and directional refinement\" /> It (Augmented Lagrangian) is considered equivalent to the split Bregman iteration which ensures convergence of this method.  The orientation field, d is defined as being equal to <math>(d_{h}, d_{v})</math>, where <math>d_{h},  d_{v}</math> define the horizontal and vertical estimates of <math>d</math>.\n\n[[File:Augmented Lagrangian.png|thumb|right|Augmented Lagrangian method for orientation field and iterative directional field refinement models]]\n\nThe Augmented Lagrangian method for the orientation field,  <math>min_\\Chi\\lVert \\nabla \\Chi \\bullet d \\rVert _{1} + \\frac{\\lambda}{2}\\ \\lVert Y - \\Phi\\Chi \\rVert ^2_{2}</math>,  involves initializing <math>d_{h}, d_{v}, H, V</math> and then finding the approximate minimizer of <math>L_{1}</math> with respect to these variables.  The Lagrangian multipliers are then updated and the iterative process is stopped when convergence is achieved. For the iterative directional total variation refinement model, the augmented lagrangian method involves initializing <math>\\Chi, P, Q, \\lambda_{P}, \\lambda_{Q}</math>.<ref name=\"TV\">{{cite journal | last1 = Goldluecke | first1 = B. | last2 = Strekalovskiy | first2 = E. | last3 = Cremers | first3 = D. | last4 = Siims | first4 = P.-T. A. I. | year = 2012 | title = The natural vectorial total variation which arises from geometric measure theory | url = | journal = SIAM J. Imaging Sci. | volume = 5 | issue = 2| pages = 537–563 | doi=10.1137/110823766| citeseerx = 10.1.1.364.3997 }}</ref>\n\nHere, <math>H, V, P, Q</math> are newly introduced variables where <math>H</math> = <math>\\nabla d_{h}</math>, <math>V</math> = <math>\\nabla d_{v}</math>, <math>P</math> = <math>\\nabla \\Chi</math>, and <math>Q</math> = <math>P \\bullet d</math>. <math>\\lambda_{H}, \\lambda_{V}, \\lambda_{P}, \\lambda_{Q}</math> are the Lagrangian multipliers for <math>H, V, P, Q</math>. For each iteration, the approximate minimizer of <math>L_{2}</math> with respect to variables (<math>\\Chi, P, Q</math>) is calculated. And as in the field refinement model, the lagrangian multipliers are updated and the iterative process is stopped when convergence is achieved.\n\nFor the orientation field refinement model, the Lagrangian multipliers are updated in the iterative process as follows:\n\n<math>(\\lambda_{H})^k = (\\lambda_{H})^{k-1} +  \\gamma_{H}(H^k - \\nabla (d_{h})^k)</math>\n\n<math>(\\lambda_{V})^k = (\\lambda_{V})^{k-1} +  \\gamma_{V}(V^k - \\nabla (d_{v})^k)</math>\n\nFor the iterative directional total variation refinement model, the Lagrangian multipliers are updated as follows:\n\n<math>(\\lambda_{P})^k = (\\lambda_{P})^{k-1} +  \\gamma_{P}(P^k - \\nabla (\\Chi)^k)</math>\n\n<math>(\\lambda_{Q})^k = (\\lambda_{Q})^{k-1} +  \\gamma_{Q}(Q^k - P^{k} \\bullet d)</math>\n\nHere, <math>\\gamma_{H}, \\gamma_{V}, \\gamma_{P}, \\gamma_{Q}</math> are positive constants.\n\n=====Advantages and disadvantages=====\n\nBased on [[peak signal-to-noise ratio]] (PSNR) and [[structural similarity]] index (SSIM) metrics and known ground-truth images for testing performance, it is concluded that iterative directional total variation has a better reconstructed performance than the non-iterative methods in preserving edge and texture areas. The orientation field refinement model plays a major role in this improvement in performance as it increases the number of directionless pixels in the flat area while enhancing the orientation field consistency in the regions with edges.\n\n==Applications==\nThe field of compressive sensing is related to several topics in signal processing and computational mathematics, such as [[underdetermined system|underdetermined linear-system]]s, [[group testing]], heavy hitters, [[sparse coding]], [[multiplexing]], sparse sampling, and finite rate of innovation. Its broad scope and generality has enabled several innovative CS-enhanced approaches in signal processing and compression, solution of inverse problems, design of radiating systems, radar and through-the-wall imaging, and antenna characterization.<ref>{{Cite journal|author1=Andrea Massa |author2=Paolo Rocca |author3=Giacomo Oliveri |title = Compressive Sensing in Electromagnetics – A Review|journal = IEEE Antennas and Propagation Magazine|volume = 57|pages=224–238 |number = 1|year = 2015|doi = 10.1109/MAP.2015.2397092|url = http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7046378|bibcode=2015IAPM...57..224M}}</ref>  Imaging techniques having a strong affinity with compressive sensing include [[coded aperture]] and [[computational photography]]. Implementations of compressive sensing in hardware at different [[technology readiness level]]s is available.<ref>Compressive Sensing Hardware, http://sites.google.com/site/igorcarron2/compressedsensinghardware</ref>\n\nConventional CS reconstruction uses sparse signals (usually sampled at a rate less than the Nyquist sampling rate) for reconstruction through constrained <math>l_{1}</math> minimization. One of the earliest applications of such an approach was in reflection seismology which used sparse reflected signals from band-limited data for tracking changes between sub-surface layers.<ref name=\"Seismic sparse signals\">Taylor, H.L., Banks, S.C., McCoy, J.F. \"Deconvolution with the 1 norm. ''Geophysics'' 44(1), 39–52 (1979)</ref>  When the LASSO model came into prominence in the 1990s as a statistical method for selection of sparse models,<ref name=\"LASSO\">Tibshirani, R. \"Regression shrinkage and selection via the lasso. ''J. R. Stat. Soc. B'' 58(1), 267–288 (1996)</ref> this method was further used in computational harmonic analysis for sparse signal representation from over-complete dictionaries. Some of the other applications include incoherent sampling of radar pulses. The work by ''Boyd et al.''<ref name = \"Original source for IRLS\" /> has applied the LASSO model- for selection of sparse models- towards analog to digital converters (the current ones use a sampling rate higher than the Nyquist rate along with the quantized Shannon representation). This would involve a parallel architecture in which the polarity of the analog signal changes at a high rate followed by digitizing the integral at the end of each time-interval to obtain the converted digital signal.\n\n===Photography===\nCompressed sensing is used in a mobile phone camera sensor. The approach allows a reduction in image acquisition energy per image by as much as a factor of 15 at the cost of complex decompression algorithms; the computation may require an off-device implementation.<ref>{{cite magazine|title=New Camera Chip Captures Only What It Needs|author=David Schneider|journal=IEEE Spectrum|date=March 2013|url=http://spectrum.ieee.org/semiconductors/optoelectronics/camera-chip-makes-alreadycompressed-images|accessdate=2013-03-20}}</ref>\n\nCompressed sensing is used in single-pixel cameras from [[Rice University]].<ref name=cscamera>{{cite web |url=http://dsp.rice.edu/cscamera |archive-url=https://web.archive.org/web/20100605170550/http://dsp.rice.edu/cscamera |dead-url=yes |archive-date=2010-06-05 |title=Compressive Imaging: A New Single-Pixel Camera |website=Rice DSP |date= |accessdate=2013-06-04 }}</ref> [[Bell Labs]] employed the technique in a lensless single-pixel camera that takes stills using repeated snapshots of randomly chosen apertures from a grid. Image quality improves with the number of snapshots, and generally requires a small fraction of the data of conventional imaging, while eliminating lens/focus-related aberrations.<ref>{{cite web |url=http://www.technologyreview.com/view/515651/bell-labs-invents-lensless-camera/ |title=Bell Labs Invents Lensless Camera |website=MIT Technology Review |date=2013-05-25 |accessdate=2013-06-04}}</ref><ref>{{cite conference|author1=Gang Huang|author2=Hong Jiang|author3=Kim Matthews|author4=Paul Wilford|title=Lensless Imaging by Compressive Sensing|year=2013|volume=2393|pages=2101–2105|conference=2013 IEEE International Conference on Image Processing |arxiv=1305.7181 |bibcode=2013arXiv1305.7181H |doi=10.1109/ICIP.2013.6738433 |isbn=978-1-4799-2341-0}}</ref>\n\n===Holography===\nCompressed sensing can be used to improve image reconstruction in [[holography]] by increasing the number of [[voxel]]s one can infer from a single hologram.<ref>{{cite journal | last1 = Brady | first1 = David | last2 = Choi | first2 = Kerkil | last3 = Marks | first3 = Daniel | last4 = Horisaki | first4 = Ryoichi | last5 = Lim | first5 = Sehoon | year = 2009 | title = Compressive holography | url = | journal = Optics Express | volume = 17 | issue = 15| pages = 13040–13049 | doi=10.1364/oe.17.013040| bibcode = 2009OExpr..1713040B }}</ref><ref>{{cite journal | last1 = Rivenson | first1 = Y. | last2 = Stern | first2 = A. | last3 = Javidi | first3 = B. | year = 2010 | title = Compressive fresnel holography | url = | journal = Display Technology, Journal of | volume = 6 | issue = 10| pages = 506–509 | doi=10.1109/jdt.2010.2042276| bibcode = 2010JDisT...6..506R | citeseerx = 10.1.1.391.2020 }}</ref><ref>{{cite journal | last1 = Denis | first1 = Loic | last2 = Lorenz | first2 = Dirk | last3 = Thibaut | first3 = Eric | last4 = Fournier | first4 = Corinne | last5 = Trede | first5 = Dennis | year = 2009 | title = Inline hologram reconstruction with sparsity constraints | url = https://hal-ujm.archives-ouvertes.fr/ujm-00397994/file/OL_sparse_reconstruction_DH_revised_2line.pdf| journal = Opt. Lett. | volume = 34 | issue = 22| pages = 3475–3477 | doi=10.1364/ol.34.003475| pmid = 19927182 | bibcode = 2009OptL...34.3475D }}</ref> It is also used for image retrieval from undersampled measurements in optical<ref>{{cite journal | last1 = Marim | first1 = M. | last2 = Angelini | first2 = E. | last3 = Olivo-Marin | first3 = J. C. | last4 = Atlan | first4 = M. | year = 2011 | title = Off-axis compressed holographic microscopy in low-light conditions | arxiv = 1101.1735| journal = Optics Letters | volume = 36 | issue = 1| pages = 79–81 | doi=10.1364/ol.36.000079| pmid = 21209693 | bibcode = 2011OptL...36...79M }}</ref><ref>{{cite journal | last1 = Marim | first1 = M. M. | last2 = Atlan | first2 = M. | last3 = Angelini | first3 = E. | last4 = Olivo-Marin | first4 = J. C. | year = 2010 | title = Compressed sensing with off-axis frequency-shifting holography | arxiv = 1004.5305| journal = Optics Letters | volume = 35 | issue = 6| pages = 871–873 | doi=10.1364/ol.35.000871| pmid = 20237627 | bibcode = 2010OptL...35..871M }}</ref> and millimeter-wave<ref>{{cite journal | last1 = Fernandez Cull | first1 = Christy | last2 = Wikner | first2 = David A. | last3 = Mait | first3 = Joseph N. | last4 = Mattheiss | first4 = Michael | last5 = Brady | first5 = David J. | year = 2010 | title = Millimeter-wave compressive holography | url = | journal = Appl. Opt. | volume = 49 | issue = 19| pages = E67–E82 | doi=10.1364/ao.49.000e67| pmid = 20648123 | bibcode = 2010ApOpt..49E..67C | citeseerx = 10.1.1.1018.5231 }}</ref> holography.\n\n===Facial recognition===\nCompressed sensing is being used in facial recognition applications.<ref>[https://www.wired.com/science/discoveries/news/2008/03/new_face_recognition Engineers Test Highly Accurate Face Recognition]</ref>\n\n===Magnetic resonance imaging===\nCompressed sensing has been used<ref name=\"dx.doi.org\">Sparse MRI: The application of compressed sensing for rapid MR imaging; See Lustig, Michael and Donoho, David and Pauly, John M, Magnetic resonance in medicine, 58(6), 1182–1195 (2007)  {{DOI|10.1002/mrm.21391}}</ref><ref name=\"Compressed Sensing MRI 2008\">{{cite journal | last1 = Lustig | first1 = M. | last2 = Donoho | first2 = D.L. | last3 = Santos | first3 = J.M. | last4 = Pauly | first4 = J.M. | year = 2008 | title = Compressed Sensing MRI; | url = | journal = IEEE  Signal Processing Magazine| volume = 25 | issue = 2| pages = 72–82 | doi = 10.1109/MSP.2007.914728 | bibcode = 2008ISPM...25...72L }}</ref>  to shorten [[magnetic resonance imaging]] scanning sessions on conventional hardware.<ref>{{cite journal|author=Jordan EllenbergEmail Author |url=https://www.wired.com/magazine/2010/02/ff_algorithm/all/1 |title=Fill in the Blanks: Using Math to Turn Lo-Res Datasets Into Hi-Res Samples &#124; Wired Magazine |journal=Wired |volume=18 |issue=3 |date=2010-03-04 |accessdate=2013-06-04}}</ref><ref>[http://nuit-blanche.blogspot.com/2010/03/why-compressed-sensing-is-not-csi.html Why Compressed Sensing is NOT a CSI \"Enhance\" technology ... yet !]</ref><ref>[http://nuit-blanche.blogspot.com/2010/03/surely-you-must-be-joking-mr.html Surely You Must Be Joking Mr. Screenwriter]</ref> Reconstruction methods include\n* ISTA\n* FISTA\n* SISTA\n* ePRESS<ref>{{cite journal|last1=Zhang|first1=Y.|last2=Peterson|first2=B.|title=Energy Preserved Sampling for Compressed Sensing MRI|journal=Computational and Mathematical Methods in Medicine|date=2014|volume=2014|doi=10.1155/2014/546814|pmid=24971155|pmc=4058219|url=http://www.hindawi.com/journals/cmmm/2014/546814|pages=546814|bibcode=2015CMMM.201514104T|arxiv=1501.03915}}</ref>\n* EWISTA<ref name=Zhang_2015>{{cite journal|last1=Zhang|first1=Y.|title=Exponential Wavelet Iterative Shrinkage Thresholding Algorithm for Compressed Sensing Magnetic Resonance Imaging|journal=Information Sciences|date=2015|volume=322|pages=115–132|url=http://www.sciencedirect.com/science/article/pii/S0020025515004491|doi=10.1016/j.ins.2015.06.017}}</ref>\n* EWISTARS<ref>{{cite journal|last1=Zhang|first1=Y.|last2=Wang|first2=S.|title=Exponential Wavelet Iterative Shrinkage Thresholding Algorithm with Random Shift for Compressed Sensing Magnetic Resonance Imaging|journal=IEEJ Transactions on Electrical and Electronic Engineering|date=2015|volume=10|issue=1|pages=116–117|doi=10.1002/tee.22059}}</ref> etc.\n\nCompressed sensing addresses the issue of high scan time by enabling faster acquisition by measuring fewer Fourier coefficients. This produces a high-quality image with relatively lower scan time. Another application (also discussed ahead) is for CT reconstruction with fewer X-ray projections. Compressed sensing, in this case, removes the high spatial gradient parts – mainly, image noise and artifacts. This holds tremendous potential as one can obtain high-resolution CT images at low radiation doses (through lower current-mA settings).<ref name=\"MRI\">{{cite journal | last1 = Figueiredo | first1 = M. | last2 = Bioucas-Dias | first2 = J.M. | last3 = Nowak | first3 = R.D. | year = 2007 | title = Majorization–minimization algorithms for wavelet-based image restoration | url = | journal = IEEE Trans. Image Process. | volume = 16 | issue = 12| pages = 2980–2991 | doi=10.1109/tip.2007.909318| bibcode = 2007ITIP...16.2980F }}</ref>\n\n===Network tomography===\nCompressed sensing has showed outstanding results in the application of [[network tomography]] to [[network management]]. [[Network delay]] estimation and [[network congestion]] detection can both be modeled as underdetermined [[System of linear equations|systems of linear equations]] where the coefficient matrix is the network routing matrix. Moreover, in the [[Internet]], network routing matrices usually satisfy the criterion for using compressed sensing.<ref>[Network tomography via compressed sensing|http://www.ee.washington.edu/research/funlab/Publications/2010/CS-Tomo.pdf]</ref>\n\n===Shortwave-infrared cameras===\nCommercial shortwave-infrared cameras based upon compressed sensing are available.<ref>{{cite web|title=InView web site|url=http://www.inviewcorp.com/products |website=inviewcorp.com}}</ref> These cameras have light sensitivity from 0.9&nbsp;[[µm]] to 1.7&nbsp;µm, which are wavelengths invisible to the human eye.\n\n===Aperture synthesis in radio astronomy===\nIn the field of [[radio astronomy]], compressed sensing has been proposed for deconvolving an interferometric image.<ref>[http://mnras.oxfordjournals.org/content/395/3/1733|Compressed sensing imaging techniques for radio interferometry]</ref> In fact, the [[CLEAN (algorithm)|Högbom CLEAN algorithm]] that has been in use for the deconvolution of radio images since 1974, is similar to compressed sensing's matching pursuit algorithm.\n\n===Transmission electron microscopy===\nCompressed sensing combined with a moving aperture has been used to increase the acquisition rate of images in a [[transmission electron microscopy|transmission electron microscope]].<ref>{{cite journal|last1=Stevens|first1=Andrew|last2=Kovarik|first2=Libor|last3=Abellan|first3=Patricia|last4=Yuan|first4=Xin|last5=Carin|first5=Lawrence|last6=Browning|first6=Nigel D.|title=Applying compressive sensing to TEM video: a substantial frame rate increase on any camera|journal=Advanced Structural and Chemical Imaging|date=13 August 2015|volume=1|issue=1|doi=10.1186/s40679-015-0009-3}}</ref> In [[Scanning transmission electron microscopy|scanning mode]], compressive sensing combined with random scanning of the electron beam has enabled both faster acquisition and less electron dose, which allows for imaging of electron beam sensitive materials.<ref>{{cite journal|last1=Kovarik|first1=L.|last2=Stevens|first2=A.|last3=Liyu|first3=A.|last4=Browning|first4=N. D.|title=Implementing an accurate and rapid sparse sampling approach for low-dose atomic resolution STEM imaging|journal=Applied Physics Letters|date=17 October 2016|volume=109|issue=16|pages=164102|doi=10.1063/1.4965720|bibcode=2016ApPhL.109p4102K}}</ref>\n\n==See also==\n*[[Noiselet]]\n*[[Sparse approximation]]\n*[[Sparse coding]]\n*[[Low-density parity-check code]]\n*[[Compressed sensing in speech signals]]\n\n==Notes==\n{{reflist|group=note}}\n\n==References==\n{{reflist|30em}}\n\n==Further reading==\n* \"The Fundamentals of Compressive Sensing\" [http://www.brainshark.com/brainshark/brainshark.net/portal/title.aspx?pid=zCdz10BfTRz0z0 Part 1], [http://www.brainshark.com/brainshark/brainshark.net/portal/title.aspx?pid=zCgzXgcEKz0z0 Part 2] and [http://www.brainshark.com/brainshark/brainshark.net/portal/title.aspx?pid=zAvz9F41cz0z0 Part 3]: video tutorial by Mark Davenport, Georgia Tech. at [http://www.brainshark.com/sps SigView, the IEEE Signal Processing Society Tutorial Library].\n* [https://www.wired.com/magazine/2010/02/ff_algorithm/all/1 Using Math to Turn Lo-Res Datasets Into Hi-Res Samples] Wired Magazine article\n* [http://arquivo.pt/wayback/20160516193158/http://dsp.rice.edu/cs/ Compressive Sensing Resources] at [[Rice University]].\n* [http://igorcarron.googlepages.com/cs Compressed Sensing: The Big Picture]\n* [http://igorcarron.googlepages.com/compressedsensinghardware A list of different hardware implementation of Compressive Sensing]\n* [http://compressedsensing.googlepages.com/home Compressed Sensing 2.0 ]\n* [http://www.ams.org/happening-series/hap7-pixel.pdf Compressed Sensing Makes Every Pixel Count] – article in the AMS ''What's Happening in the Mathematical Sciences'' series\n* [http://nuit-blanche.blogspot.com/search/label/CS Nuit Blanche] A blog on Compressive Sensing featuring the most recent information on the subject (preprints, presentations, Q/As)\n* [http://igorcarron.googlepages.com/csvideos Online Talks focused on Compressive Sensing]\n* [https://web.archive.org/web/20150504060355/http://ugcs.caltech.edu/~srbecker/wiki/Main_Page Wiki on sparse reconstruction]\n* [https://stemblab.github.io/intuitive-cs/ Intuitive Compressive Sensing]\n\n{{DEFAULTSORT:Compressed Sensing}}\n[[Category:Information theory]]\n[[Category:Signal estimation]]\n[[Category:Linear algebra]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Constrained optimization",
      "url": "https://en.wikipedia.org/wiki/Constrained_optimization",
      "text": "In [[mathematical optimization]], '''constrained optimization''' (in some contexts called '''constraint optimization''') is the process of optimizing an objective function with respect to some [[variable (mathematics)|variables]]  in the presence of [[Constraint (mathematics)|constraints]] on those variables. The objective function is either a [[Loss function|cost function]] or [[energy function]], which is to be [[Maxima and minima|minimized]], or a [[reward function]] or [[utility function]], which is to be [[maximize]]d. Constraints can be either '''hard constraints''', which set conditions for the variables that are required to be satisfied, or '''soft constraints''', which have some variable values that are penalized in the objective function if, and based on the extent that, the conditions on the variables are not satisfied.\n\n==General form==\n\nA general constrained minimization problem may be written as follows:\n\n: <math>\n\\begin{array}{rcll}\n\\min &~& f(\\mathbf{x}) & \\\\\n\\mathrm{subject~to} &~& g_i(\\mathbf{x}) = c_i &\\text{for } i=1,\\ldots,n \\quad \\text{Equality constraints} \\\\\n &~& h_j(\\mathbf{x}) \\geqq d_j &\\text{for } j=1,\\ldots,m \\quad \\text{Inequality constraints}\n\\end{array}\n</math>\n\nwhere <math> g_i(\\mathbf{x}) = c_i ~\\mathrm{for~} i=1,\\ldots,n </math> and <math> h_j(\\mathbf{x}) \\ge d_j ~\\mathrm{for~} j=1,\\ldots,m  </math> are constraints that are required to be satisfied (these are called [[Constraint (mathematics)#Hard and soft constraints|hard constraints]]), and <math>f(\\mathbf{x})</math> is the objective function that needs to be optimized subject to the constraints.\n\nIn some problems, often called ''constraint optimization problems'', the objective function is actually the sum of cost functions, each of which penalizes the extent (if any) to which a [[Constraint (mathematics)#Hard and soft constraints|soft constraint]] (a constraint which is preferred but not required to be satisfied) is violated.\n\n==Solution methods==\n\nMany unconstrained optimization algorithms can be adapted to the constrained case, often via the use of a [[penalty method]]. However, search steps taken by the unconstrained method may be unacceptable for the constrained problem, leading to a lack of convergence. This is referred to as the Maratos effect.<ref>Wenyu Sun; Ya-Xiang Yua (2010). ''Optimization Theory and Methods: Nonlinear Programming'', Springer, {{ISBN|978-1441937650}}. p. 541</ref>\n\n===Equality constraints===\n\nIf the constrained problem has only equality constraints, the method of [[Lagrange multipliers]] can be used to convert it into an unconstrained problem whose number of variables is the original number of variables plus the original number of equality constraints. Alternatively, if the constraints are all equality constraints and are all linear, they can be solved for some of the variables in terms of the others, and the former can be substituted out of the objective function, leaving an unconstrained problem in a smaller number of variables.\n\n===Inequality constraints===\n\nWith inequality constraints, the problem can be characterized in terms of the [[geometric optimality conditions]], [[Fritz John conditions]] and [[Karush–Kuhn–Tucker conditions]], under which simple problems may be solvable.\n\n====Linear programming====\n\nIf the objective function and all of the hard constraints are linear and some hard constraints are inequalities, then the problem is a [[linear programming]] problem. This can be solved by the [[simplex method]], which usually works in [[polynomial time]] in the problem size but is not guaranteed to, or by [[interior point method]]s which are guaranteed to work in polynomial time.\n\n====Quadratic programming====\n\nIf all the hard constraints are linear and some are inequalities, but the objective function is quadratic, the problem is a [[quadratic programming]] problem. It can still be solved in polynomial time by the [[ellipsoid method]] if the objective function is [[Convex function|convex]]; otherwise the problem is [[NP hard]].\n\n===Constraint optimization problems===\n\n====Branch and bound====\n\nConstraint optimization can be solved by [[branch and bound]] algorithms. These are backtracking algorithms storing the cost of the best solution found during execution and using it to avoid part of the search. More precisely, whenever the algorithm encounters a partial solution that cannot be extended to form a solution of better cost than the stored best cost, the algorithm backtracks, instead of trying to extend this solution.\n\nAssuming that cost is to be minimized, the efficiency of these algorithms depends on how the cost that can be obtained from extending a partial solution is evaluated. Indeed, if the algorithm can backtrack from a partial solution, part of the search is skipped. The lower the estimated cost, the better the algorithm, as a lower estimated cost is more likely to be lower than the best cost of solution found so far.\n\nOn the other hand, this estimated cost cannot be lower than the effective cost that can be obtained by extending the solution, as otherwise the algorithm could backtrack while a solution better than the best found so far exists. As a result, the algorithm requires an upper bound on the cost that can be obtained from extending a partial solution, and this upper bound should be as small as possible.\n\nA variation of this approach called Hansen's method uses [[Interval arithmetic#History|interval methods]].<ref>{{cite book |last=Leader|first=Jeffery J. | title=Numerical Analysis and Scientific Computation |year=2004|publisher=Addison Wesley |location= |isbn= 0-201-73499-0 }}</ref> It inherently implements rectangular constraints.\n\n====First-choice bounding functions====\n\nOne way for evaluating this upper bound for a partial solution is to consider each soft constraint separately. For each soft constraint, the maximal possible value for any assignment to the unassigned variables is assumed. The sum of these values is an upper bound because the soft constraints cannot assume a higher value. It is exact because the maximal values of soft constraints may derive from different evaluations: a soft constraint may be maximal for <math>x=a</math> while another constraint is maximal for <math>x=b</math>.\n\n=====Russian doll search=====\n\nThis method<ref>Verfaillie, Gérard, Michel Lemaître, and Thomas Schiex. \"[https://pdfs.semanticscholar.org/c83b/19ca9cc73aefb1a9e7b4780ba161b2149a03.pdf Russian doll search for solving constraint optimization problems].\" AAAI/IAAI, Vol. 1. 1996.</ref> runs a branch-and-bound algorithm on <math>n</math> problems, where <math>n</math> is the number of variables. Each such problem is the subproblem obtained by dropping a sequence of variables <math>x_1,\\ldots,x_i</math> from the original problem, along with the constraints containing them. After the problem on variables <math>x_{i+1},\\ldots,x_n</math> is solved, its optimal cost can be used as an upper bound while solving the other problems,\n\nIn particular, the cost estimate of a solution having <math>x_{i+1},\\ldots,x_n</math> as unassigned variables is added to the cost that derives from the evaluated variables. Virtually, this corresponds on ignoring the evaluated variables and solving the problem on the unassigned ones, except that the latter problem has already been solved. More precisely, the cost of soft constraints containing both assigned and unassigned variables is estimated as above (or using an arbitrary other method); the cost of soft constraints containing only unassigned variables is instead estimated using the optimal solution of the corresponding problem, which is already known at this point.\n\nThere is similarity between the Russian Doll Search method and [[Dynamic programming|Dynamic Programming]]. Like Dynamic Programming,Russian Doll Search solves sub-problems in order to solve the whole problem. But, whereas Dynamic Programming\ndirectly combines the results obtained on sub-problems to get the result of the whole problem, Russian Doll Search only uses them as bounds during its search.\n\n====Bucket elimination====\n\nThe [[bucket elimination]] algorithm can be adapted for constraint optimization. A given variable can be indeed removed from the problem by replacing all soft constraints containing it with a new soft constraint. The cost of this new constraint is computed assuming a maximal value for every value of the removed variable. Formally, if <math>x</math> is the variable to be removed, <math>C_1,\\ldots,C_n</math> are the soft constraints containing it, and <math>y_1,\\ldots,y_m</math> are their variables except <math>x</math>, the new soft constraint is defined by:\n<!-- not exactly the correct notation, but clear enough -->\n:<math>C(y_1=a_1,\\ldots,y_n=a_n) = \\max_a \\sum_i C_i(x=a,y_1=a_1,\\ldots,y_n=a_n).</math>\n\nBucket elimination works with an (arbitrary) ordering of the variables. Every variable is associated a bucket of constraints; the bucket of a variable contains all constraints having the variable has the highest in the order. Bucket elimination proceed from the last variable to the first. For each variable, all constraints of the bucket are replaced as above to remove the variable. The resulting constraint is then placed in the appropriate bucket.\n\n==See also==\n* [[Constrained least squares]]\n* [[Distributed constraint optimization]]\n* [[Integer programming]]\n* [[Penalty method]]\n* [[Superiorization]]\n\n==References==\n{{reflist}}\n\n*{{cite book\n| first=Rina\n| last=Dechter\n| title=Constraint Processing\n| publisher=Morgan Kaufmann\n| url=http://www.ics.uci.edu/~dechter/books/index.html\n| year=2003\n| isbn=1-55860-890-7\n}}\n\n[[Category:Mathematical optimization]]\n[[Category:Constraint programming]]"
    },
    {
      "title": "Constraint (mathematics)",
      "url": "https://en.wikipedia.org/wiki/Constraint_%28mathematics%29",
      "text": "{{for |constraints in Hamiltonian mechanics|constraint (classical mechanics)|first class constraint|primary constraint|holonomic constraint}}\n{{no footnotes|date=September 2016}}\nIn [[mathematics]], a '''constraint''' is a condition of an [[optimization (mathematics)|optimization]] problem that the solution must satisfy. There are several types of constraints&mdash;primarily [[Equality (mathematics)|equality]] constraints, [[Inequality (mathematics)|inequality]] constraints, and [[Integer programming|integer constraints]]. The set of [[candidate solution]]s that satisfy all constraints is called the [[feasible set]].<ref>{{cite book |first=Akira |last=Takayama |title=Mathematical Economics |location=New York |publisher=Cambridge University Press |edition=2nd |year=1985 |isbn=0-521-31498-4 |page=61 |url=https://books.google.com/books?id=j6PLOBFotPQC&pg=PA61 }}</ref>\n\n==Example==\nThe following is a simple optimization problem:\n:<math>\\min f(\\mathbf x) = x_1^2+x_2^4</math>\n\nsubject to\n\n:<math>x_1 \\ge 1</math>\n\nand\n\n:<math>x_2 = 1,</math>\n\nwhere <math>\\mathbf x</math> denotes the vector (x<sub>1</sub>, x<sub>2</sub>).\n\nIn this example, the first line defines the function to be minimized (called the [[objective function]], loss function, or cost function). The second and third lines define two constraints, the first of which is an inequality constraint and the second of which is an equality constraint. These two constraints are [[hard constraint]]s, meaning that it is required that they be satisfied; they define the feasible set of candidate solutions.\n\nWithout the constraints, the solution would be (0,0), where <math>f(\\mathbf x)</math> has the lowest value. But this solution does not satisfy the constraints. The solution of the [[constrained optimization]] problem stated above is <math>\\mathbf x = (1,1)</math>, which is the point with the smallest value of <math>f(\\mathbf x)</math> that satisfies the two constraints.\n\n== Terminology ==\n* If an inequality constraint holds with ''equality'' at the optimal point, the constraint is said to be '''{{visible anchor|binding}}''', as the point ''cannot'' be varied in the direction of the constraint even though doing so would improve the value of the objective function.\n* If an inequality constraint holds as a ''strict inequality'' at the optimal point (that is, does not hold with equality), the constraint is said to be '''{{visible anchor|non-binding}}''', as the point ''could'' be varied in the direction of the constraint, although it would not be optimal to do so. If a constraint is non-binding, the optimization problem would have the same solution even in the absence of that constraint.\n* If a constraint is not satisfied at a given point, the point is said to be '''[[Feasible region|infeasible]]'''.\n\n==Hard and soft constraints==\n\nIf the problem mandates that the constraints be satisfied, as in the above discussion, the constraints are sometimes referred to as ''hard constraints''. However, in some problems, called [[Constraint satisfaction problem#Flexible CSPs|flexible constraint satisfaction problems]], it is preferred but not required that certain constraints be satisfied; such non-mandatory constraints are known as ''[[Constraint optimization#Definition|soft constraints]]''. Soft constraints arise in, for example, [[preference-based planning]]. In a [[MAX-CSP]] problem, a number of constraints are allowed to be violated, and the quality of a solution is measured by the number of satisfied constraints.\n\n== See also ==\n{{Div col|colwidth=25em}}\n* [[Constraint algebra]]\n* [[Constraint satisfaction problem]]\n* [[Karush&ndash;Kuhn&ndash;Tucker conditions]]\n* [[Lagrange multipliers]]\n* [[Level set]]\n* [[Linear programming]]\n* [[Nonlinear programming]]\n* [[Restriction (mathematics)|Restriction]]\n{{Div col end}}\n\n== References ==\n{{Reflist}}\n\n== Further reading ==\n* {{cite book |first=Gordon S. G. |last=Beveridge |first2=Robert S. |last2=Schechter |chapter=Essential Features in Optimization |title=Optimization: Theory and Practice |location=New York |publisher=McGraw-Hill |year=1970 |pages=5–8 |isbn=0-07-005128-3 |chapterurl=https://books.google.com/books?id=TfhVXlWtOPQC&pg=PA5 }}\n\n== External links ==\n*[http://www.neos-guide.org/non-lp-faq Nonlinear programming FAQ]\n*[http://glossary.computing.society.informs.org/ Mathematical Programming Glossary]\n\n[[Category:Mathematical optimization]]\n[[Category:Constraint programming]]\n\n[[ca:Restricció]]\n[[es:Restricción (matemáticas)]]"
    },
    {
      "title": "Continuous optimization",
      "url": "https://en.wikipedia.org/wiki/Continuous_optimization",
      "text": "{{more citations needed|date=February 2014}}\n\n'''Continuous optimization''' is a branch of [[Optimization (mathematics)|optimization]] in [[applied mathematics]].<ref name=\"JeyakumarRubinov2006\">{{cite book|author1=V. Jeyakumar|author2=Alexander M. Rubinov|title=Continuous Optimization: Current Trends and Modern Applications|url=https://books.google.com/books?id=QePsbLIwwEoC&printsec=frontcover&dq=%22Continuous+optimization%22&hl=en&sa=X&ved=0ahUKEwjnkpy2uOziAhXMup4KHdBZDUUQ6AEIKjAA#v=onepage&q=%22Continuous%20optimization%22&f=false|date=9 March 2006|publisher=Springer Science & Business Media|isbn=978-0-387-26771-5}}</ref>\n\nAs opposed to [[discrete optimization]], the [[Variable (mathematics)|variables]] used in the [[objective function]] are required to be [[continuous variable]]s&mdash;that is, to be chosen from a set of [[real number|real]] values between which there are no gaps (values from [[Interval (mathematics)|interval]]s of the [[real line]]). Because of this [[continuity (mathematics)|continuity]] assumption, continuous optimization allows the use of [[calculus]] techniques.\n\n==References==\n{{Reflist}}\n\n[[Category:Mathematical optimization]]\n\n\n{{Mathapplied-stub}}"
    },
    {
      "title": "Convex optimization",
      "url": "https://en.wikipedia.org/wiki/Convex_optimization",
      "text": "{{multiple issues|\n{{Technical|date=June 2013}}\n{{More footnotes|date=February 2012}}\n}}\n\n'''Convex optimization''' is a subfield of [[mathematical optimization]] that studies the problem of minimizing [[convex function]]s over [[convex set]]s. Many classes of convex optimization problems admit polynomial-time algorithms,<ref>{{harvnb|Nesterov|Nemirovskii|1994}}</ref> whereas mathematical optimization is in general [[NP-hard]].<ref>\n{{cite journal\n  | last1 = Murty\n  | first1 = Katta \n  | last2 = Kabadi\n  | first2 = Santosh\n  | title =  Some NP-complete problems in quadratic and nonlinear programming\n  | journal = Mathematical Programming\n  | volume = 39\n  | issue = 2\n  | pages = 117–129 \n  | year = 1987\n  | doi = 10.1007/BF02592948\n}}\n</ref><ref>Sahni, S.  \"Computationally related problems,\" in SIAM Journal on Computing, 3, 262--279, 1974.</ref><ref>[https://link.springer.com/article/10.1007/BF00120662 Quadratic programming with one negative eigenvalue is NP-hard], Panos M. Pardalos and Stephen A. Vavasis in ''Journal of Global Optimization'', Volume 1, Number 1, 1991, pg.15-22.</ref>\n\nConvex optimization has applications in a wide range of disciplines, such as automatic [[control systems]], estimation and [[signal processing]], communications and networks, electronic [[circuit design]],<ref>{{harvnb|Boyd|Vandenberghe|2004|p=17}}</ref> data analysis and modeling, [[finance]], [[statistics]] ([[optimal design|optimal experimental design]]),<ref>Chritensen/Klarbring, chpt. 4.</ref> and [[structural optimization]].<ref>{{harvnb|Boyd|Vandenberghe|2004}}</ref> With recent advancements in computing and [[Mathematical_optimization#Computational_optimization_techniques|optimization algorithms]], convex programming is nearly as straightforward as [[linear programming]].<ref>{{harvnb|Boyd|Vandenberghe|2004|p=8}}</ref>\n\n==Definition==\n\nA convex optimization problem is an [[optimization problem]] in which the objective function is a [[convex function]] and the [[Feasible region|feasible set]] is a [[convex set]]. A function <math>f</math>  mapping some subset of <math>\\mathbb{R}^n</math> into <math>\\mathbb{R} \\cup \\{\\pm \\infty\\}</math> is convex if its domain is convex and for all <math>\\theta \\in [0, 1]</math> and all <math>x, y</math> in its domain, <math>f(\\theta x + (1 - \\theta)y) \\leq \\theta f(x) + (1 - \\theta) f(y)</math>; a set is convex if for all members <math>x, y</math> and all <math>\\theta \\in [0, 1]</math>., <math>\\theta x + (1 - \\theta) y</math> is also in the set.\n\nConcretely, a convex optimization problem is the problem of finding some <math>\\mathbf{x^\\ast} \\in C</math> attaining\n:<math>\\inf \\{ f(\\mathbf{x}) : \\mathbf{x} \\in C \\}</math>,\nwhere the objective function <math>f</math> is convex, as is the feasible set <math>C</math>. <ref>{{cite book|url=https://books.google.com/?id=Gdl4Jc3RVjcC&printsec=frontcover&dq=lemarechal+convex+analysis+and+minimization#v=onepage&q=convex%20minimization&f=false|title=Convex analysis and minimization algorithms: Fundamentals|last1=Hiriart-Urruty|first1=Jean-Baptiste|last2=Lemaréchal|first2=Claude|year=1996|page=291|isbn=9783540568506}}</ref>\n<ref>{{cite book|url=https://books.google.com/?id=M3MqpEJ3jzQC&printsec=frontcover&dq=Lectures+on+Modern+Convex+Optimization:+Analysis,+Algorithms,#v=onepage&q=convex%20programming&f=false|title=Lectures on modern convex optimization: analysis, algorithms, and engineering applications|last1=Ben-Tal|first1=Aharon|last2=Nemirovskiĭ|first2=Arkadiĭ Semenovich|year=2001|pages=335–336|isbn=9780898714913}}</ref> If such a point exists, it is referred to as an ''optimal point''; the set of all optimal points is called the ''optimal set''. If <math>f</math> is unbounded below over <math>C</math> or the infimum is not attained, then the optimization problem is said to be ''unbounded''. Otherwise, if <math>C</math> is the empty set, the problem is said to be ''infeasible''.<ref name=\"bv4\">{{harvnb|Boyd|Vandenberghe|2004|loc=chpt. 4}}</ref>\n\n===Standard form===\nA convex optimization problem is said to be in the ''standard form'' if it is written as\n\n:<math>\\begin{align}\n&\\underset{\\mathbf{x}}{\\operatorname{minimize}}& & f(\\mathbf{x}) \\\\\n&\\operatorname{subject\\ to}\n& &g_i(\\mathbf{x}) \\leq 0, \\quad i = 1, \\dots, m \\\\\n&&&h_i(\\mathbf{x}) = 0, \\quad i = 1, \\dots, p,\n\\end{align}</math>\n\nwhere <math>x \\in \\mathbb{R}^n</math> is the optimization variable, the functions <math>f, g_1, \\ldots, g_m</math> are convex, and the functions <math>h_1, \\ldots, h_p</math> are [[affine transformation|affine]]. <ref name=\"bv4\"/>\nIn this notation, the function <math>f</math> is the objective function of the problem, and the functions <math>g_i</math> and <math>h_i</math> are referred to as the constraint functions. The feasible set of the optimization problem is the set consisting of all points <math>x \\in \\mathbb{R}^n</math> satisfying <math>g_1(x) \\leq 0, \\ldots, g_m(x) \\leq 0</math> and <math>h_1(x) = 0, \\ldots, h_p(x) = 0</math>. This set is convex because the [[sublevel set|sublevel sets]] of convex functions are convex, affine sets are convex, and the intersection of convex sets is convex. <ref>{{harvnb|Boyd|Vandenberghe|2004|loc=chpt. 2}}</ref>\n\nMany optimization problems can be equivalently formulated in this standard form. For example, the problem of maximizing a [[concave function]] <math>f</math> can be re-formulated equivalently as the problem of minimizing the convex function <math>-f</math>; as such, the problem of maximizing a concave function over a convex set is often referred to as a convex optimization problem.\n\n==Properties==\nThe following are useful properties of convex optimization problems:<ref name=\"rockafellar93\">{{cite journal\n  | author = Rockafellar, R. Tyrrell\n  | title = Lagrange multipliers and optimality\n  | journal = SIAM Review\n  | volume = 35 | issue = 2\n  | year = 1993\n  | pages = 183–238\n  |url = http://web.williams.edu/Mathematics/sjmiller/public_html/105Sp10/handouts/Rockafellar_LagrangeMultAndOptimality.pdf\n  | doi=10.1137/1035044\n| citeseerx = 10.1.1.161.7209\n  }}</ref><ref name=\"bv4\"/>\n:\n* every [[local minimum]] is a [[global minimum]];\n* the optimal set is convex;\n* if the objective function is ''strictly'' convex, then the problem has at most one optimal point.\n\nThese results are used by the theory of convex minimization along with geometric notions from [[functional analysis]] (in Hilbert spaces) such as the [[Hilbert projection theorem]], the [[separating hyperplane theorem]], and [[Farkas' lemma]].\n\n==Examples==\nThe following problem classes are all convex optimization problems, or can be reduced to convex optimization problems via simple transformations: <ref name=\"bv4\"/> <ref name=\"rewriting\">\n{{cite journal|url=http://web.stanford.edu/~boyd/papers/pdf/cvxpy_rewriting.pdf|last1=Agrawal|first1=Akshay|last2=Verschueren|first2=Robin|last3=Diamond|first3=Steven|last4=Boyd|first4=Stephen|title=A rewriting system for convex optimization problems|journal=Control and Decision|volume=5|issue=1|year=2018|pages=42–60|doi=10.1080/23307706.2017.1397554}}</ref>\n \n[[File:Hierarchy-of-convex-programs.svg|right|thumb|A hierarchy of convex optimization problems. (LP: linear program, QP: quadratic program, SOCP second-order cone program, SDP: semidefinite program, CP: cone program, GFP: graph form program.)]]\n\n*[[Least squares]]\n*[[Linear programming]]\n* Convex [[quadratic programming|quadratic minimization]] with linear constraints\n*[[Quadratically constrained quadratic programming|Quadratic minimization with convex quadratic constraints]]\n*[[Conic optimization]]\n*[[Geometric programming]]\n*[[Second order cone programming]]\n*[[Semidefinite programming]]\n*[[Entropy maximization]] with appropriate constraints\n\n==Lagrange multipliers==\nConsider a convex minimization problem given in standard form by a cost function <math>f(x)</math> and inequality constraints <math>g_i(x)\\leq 0</math> for <math> 1 \\leq i \\leq m</math>. Then the domain <math>\\mathcal{X}</math> is:\n\n:<math>\\mathcal{X} = \\left\\{x\\in X \\vert g_1(x), \\ldots, g_m(x)\\leq 0\\right\\}.</math>\n\nThe Lagrangian function for the problem is\n\n:<math>L(x,\\lambda_{0},\\lambda_1, \\ldots ,\\lambda_{m})=\\lambda_{0} f(x) + \\lambda_{1} g_{1} (x)+\\cdots + \\lambda_{m} g_{m} (x).</math>\n\nFor each point <math>x</math> in <math>X</math> that minimizes <math>f</math> over <math>X</math>, there exist real numbers <math>\\lambda_{0},\\lambda_1, \\ldots, \\lambda_{m},</math> called [[Lagrange multipliers]], that satisfy these conditions simultaneously:\n\n# <math>x</math> minimizes <math>L(y,\\lambda_{0},\\lambda_{1},\\ldots ,\\lambda_{m})</math> over all <math>y \\in X,</math>\n# <math>\\lambda_{0},\\lambda_{1},\\ldots ,\\lambda_{m} \\geq 0,</math> with at least one <math>\\lambda_{k} > 0,</math>\n# <math>\\lambda_{1}g_{1}(x)=\\cdots = \\lambda_{m}g_{m}(x) = 0</math> (complementary slackness).\n\nIf there exists a \"strictly feasible point\", that is, a point <math>z</math> satisfying\n\n:<math>g_{1}(z), \\ldots, g_{m}(z)<0,</math>\n\nthen the statement above can be strengthened to require that <math>\\lambda_{0}=1</math>.\n\nConversely, if some <math>x</math> in <math>X</math> satisfies (1)–(3) for [[scalar (mathematics)|scalar]]s <math>\\lambda_{0},\\ldots,\\lambda_{m} </math> with <math>\\lambda_{0}=1</math> then <math>x</math> is certain to minimize <math>f</math> over <math>X</math>.\n\n==Algorithms==\nConvex optimization problems can be solved by the following contemporary methods:<ref>For methods for convex minimization, see the volumes by Hiriart-Urruty and Lemaréchal (bundle) and the textbooks by [[Andrzej Piotr Ruszczyński|Ruszczyński]], [[Dimitri Bertsekas|Bertsekas]], and \nBoyd and Vandenberghe (interior point).\n</ref>\n* [[Subgradient_method#Subgradient-projection_&_bundle_methods |Bundle methods]] (Wolfe, Lemaréchal, Kiwiel), and\n* [[Subgradient method#Subgradient-projection & bundle methods|Subgradient projection]] methods (Polyak),\n* [[Interior-point methods]]<ref>{{harvnb|Nesterov|Nemirovskii|1994}}</ref>, which make use of [[self-concordant function|self-concordant]] barrier functions <ref>{{cite book |title=Interior-Point Polynomial Algorithms in Convex Programming  |last1= Nesterov |first1=Yurii |first2=Nemirovskii |last2=Arkadii |year=1995 |publisher=Society for Industrial and Applied Mathematics |isbn=978-0898715156 |pages= }}</ref> and self-regular barrier functions.<ref name=\"PengRoos2002\">{{cite journal|last1=Peng|first1=Jiming|last2=Roos|first2=Cornelis|last3=Terlaky|first3=Tam&#x000E1;s|title=Self-regular functions and new search directions for linear and semidefinite optimization|journal=Mathematical Programming|volume=93|issue=1|year=2002|pages=129–171|issn=0025-5610|doi=10.1007/s101070200296}}</ref>\n*[[Cutting-plane methods]]\n*[[Ellipsoid method]]\n*[[Subgradient method]]\n*[[Drift plus penalty|Dual subgradients and the drift-plus-penalty method]]\nSubgradient methods can be implemented simply and so are widely used.<ref>Bertsekas</ref>   Dual subgradient methods are subgradient methods applied to a [[Duality (optimization)|dual problem]].  The [[Drift plus penalty|drift-plus-penalty]] method is similar to the dual subgradient method, but takes a time average of the primal variables.\n\n==Extensions==\n\nExtensions of convex optimization include the optimization of [[Biconvex optimization|biconvex]], [[pseudo-convex function|pseudo-convex]], and [[quasiconvex]] functions. Extensions of the theory of [[convex analysis]] and iterative methods for approximately solving non-convex minimization problems occur in the field of [[Convexity (mathematics)#Generalizations and extensions for convexity|generalized convexity]], also known as abstract convex analysis.\n\n==See also==\n* [[Duality (optimization)|Duality]]\n* [[Karush–Kuhn–Tucker conditions]]\n* [[Optimization problem]]\n* [[Proximal gradient method]]\n\n==Notes==\n<references/>\n\n==References==\n* {{cite book\n|last1=Bertsekas\n|first1=Dimitri P.\n|last2=Nedic\n|first2=Angelia\n|last3 = Ozdaglar\n|first3 = Asuman\n| title = Convex Analysis and Optimization\n| publisher = Athena Scientific\n| year = 2003\n| location = Belmont, MA.\n| isbn =  978-1-886529-45-8  \n}} \n* {{cite book\n  | last = Bertsekas\n  | first = Dimitri P.\n  | authorlink = Dimitri P. Bertsekas\n  | title = Convex Optimization Theory\n  | publisher = Athena Scientific\n  | year = 2009\n  | location = Belmont, MA.\n  | isbn =  978-1-886529-31-1   \n}} \n* {{cite book\n  | last = Bertsekas\n  | first = Dimitri P.\n  | authorlink = Dimitri P. Bertsekas\n  | title = Convex Optimization Algorithms\n  | publisher = Athena Scientific\n  | year = 2015\n  | location = Belmont, MA.\n  | isbn =  978-1-886529-28-1  \n}}\n\n* {{cite book\n  |title=Convex Optimization\n  |first1=Stephen P.\n  |last1=Boyd\n  |first2=Lieven\n  |last2=Vandenberghe\n  |year=2004\n  |publisher=Cambridge University Press\n  |isbn=978-0-521-83378-3\n  |url=http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf\n  |accessdate=October 15, 2011\n  |ref=harv\n}}\n\n* [[Jonathan M. Borwein|Borwein, Jonathan]], and Lewis, Adrian. (2000). ''Convex Analysis and Nonlinear Optimization''. Springer. \n* {{cite book\n  | author1 = Christensen, Peter W.\n  | author2 = Anders Klarbring\n  | title = An introduction to structural optimization\n  | volume = 153\n  | publisher = Springer Science & Businees Media\n  | year = 2008\n  | url = https://books.google.com/books?id=80IeN__MYI8C&printsec=frontcover#v=onepage&q=%22convex%20optimization%22&f=false\n| isbn = 9781402086663\n  }}\n\n* Hiriart-Urruty, Jean-Baptiste, and [[Claude Lemaréchal|Lemaréchal, Claude]]. (2004). ''Fundamentals of Convex analysis''. Berlin: Springer.\n* {{cite book|last1=Hiriart-Urruty|first1=Jean-Baptiste|last2=Lemaréchal|first2=Claude|title=Convex analysis and minimization algorithms, Volume&nbsp;I: Fundamentals|series=Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]|volume=305|publisher=Springer-Verlag|location=Berlin|year=1993|pages=xviii+417|isbn=978-3-540-56850-6|mr=1261420|authorlink2=Claude Lemaréchal}}\n*{{cite book|last1=Hiriart-Urruty|first1=Jean-Baptiste|last2=Lemaréchal|first2=Claude|title=Convex analysis and minimization algorithms, Volume&nbsp;II: Advanced theory and bundle methods|series=Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]|volume=306|publisher=Springer-Verlag|location=Berlin|year=1993|pages=xviii+346|isbn=978-3-540-56852-0|ref=harv|mr=1295240|authorlink2=Claude Lemaréchal}}\n* {{cite book|first=Krzysztof C.|last=Kiwiel|title=Methods of Descent for Nondifferentiable Optimization|year=1985|publisher=Springer-Verlag|location= New York|series=Lecture Notes in Mathematics|isbn=978-3-540-15642-0 |ref=harv}}\n* {{cite book|last=Lemaréchal|first=Claude|chapter=Lagrangian relaxation|pages=112–156|title=Computational combinatorial optimization: Papers from the Spring School held in Schloß Dagstuhl, May&nbsp;15–19,&nbsp;2000|editor=Michael Jünger and Denis Naddef|series=Lecture Notes in Computer Science|volume=2241|publisher=Springer-Verlag|location=Berlin|year=2001|isbn=978-3-540-42877-0|mr=1900016|doi=10.1007/3-540-45586-8_4|authorlink=Claude Lemaréchal}}\n* {{cite book |last1=Nesterov|first1=Yurii|last2=Nemirovskii|first2=Arkadii|year=1994|title=Interior Point Polynomial Methods in Convex Programming|publisher=SIAM|ref=harv\n}}\n* Nesterov, Yurii. (2004). ''[https://books.google.com/books?hl=en&lr=&id=2-ElBQAAQBAJ&oi=fnd&pg=PA1&dq=%22Introductory+Lectures+on+Convex+Optimization%22&ots=wltU7svijv&sig=iknjb0X1jb2uiVAPSn0QPyYGBYg#v=onepage&q=%22Introductory%20Lectures%20on%20Convex%20Optimization%22&f=false Introductory Lectures on Convex Optimization]'',  Kluwer Academic Publishers\n* {{cite book\n  | last = Rockafellar\n  | first = R. T.\n  | authorlink = R. Tyrrell Rockafellar\n  | title = Convex analysis\n  | publisher = Princeton University Press\n  | year = 1970\n  | location = Princeton\n}}\n\n* {{cite book\n  | last = Ruszczyński\n  | first = Andrzej\n  | authorlink = Andrzej Piotr Ruszczyński\n  | title = Nonlinear Optimization\n  | publisher = Princeton University Press\n  | year = 2006\n}}\n\n==External links==\n{{Commonscat}}\n* Stephen Boyd and Lieven Vandenberghe, [http://www.stanford.edu/~boyd/cvxbook/ ''Convex optimization'']  (book in pdf)\n*[http://www.stanford.edu/class/ee364a/ EE364a: Convex Optimization I] and [http://www.stanford.edu/class/ee364b/ EE364b: Convex Optimization II], Stanford course homepages\n*[https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-253-convex-analysis-and-optimization-spring-2012/lecture-notes/ 6.253: Convex Analysis and Optimization], an MIT OCW course homepage\n* Brian Borchers, [http://infohost.nmt.edu/~borchers/presentation.pdf An overview of software for convex optimization]\n\n{{Optimization algorithms|convex}}\n\n[[Category:Mathematical optimization]]\n[[Category:Convex analysis]]\n[[Category:Convex optimization| ]]"
    },
    {
      "title": "Corner solution",
      "url": "https://en.wikipedia.org/wiki/Corner_solution",
      "text": "{{unreferenced|date=August 2012}}\nA '''corner solution''' is a special solution to an [[Agent (economics)|agent]]'s [[Maximization (economics)|maximization]] problem in which the quantity of one of the arguments in the maximized function is [[0 (number)|zero]]. In non-technical terms, a corner solution is when the chooser is either unwilling or unable to make a tradeoff.  \n\n== In economics ==\nIn [[economics]] when someone says \"I wouldn't buy that at any price\" or \"I will do X no matter the cost\", those are corner solutions.  Another example is \"zero-tolerance\" policies, or parents who are unwilling to expose their children to any risk, no matter how small and no matter what the benefits of the activity might be. \"Nothing is more important than my child's safety\" is a corner solution in its refusal to admit there might be tradeoffs.  The term \"corner solution\" is sometimes used by economists in a more colloquial fashion to refer to these sorts of situations.  The word \"corner\" refers to the fact that if one graphs the maximization problem, the optimal point will occur at the \"corner\" created by the budget constraint and one axis.\n\n== In mathematics ==\nA corner solution is an instance where the \"best\" solution (i.e. maximizing profit, or utility, or whatever value is sought) is achieved based not on the market-efficient maximization of related quantities, but rather based on brute-force boundary conditions. Such a solution lacks [[mathematical elegance]], and most examples are characterized by externally forced conditions (such as \"variables ''x'' and ''y'' cannot be negative\") that put the actual [[local extrema]] outside the permitted values.\n\nAnother technical way to state it is that a corner solution is a solution to a minimization or maximization problem where the non-corner solution is infeasible, that is, not in the domain. Instead, the solution is a corner solution on an axis where either ''x'' or ''y'' is equal to zero. For instance, from the example above in economics, if the maximal utility of two goods is achieved when the quantity of goods ''x'' and ''y'' are (−2,&nbsp;5), and the utility is subject to the constraint ''x'' and ''y'' are greater than or equal to 0 (one cannot consume a negative quantity of goods) as is usually the case, then the actual solution to the problem would be a corner solution where ''x'' = 0.\n\n== In consumer theory ==\nThe more usual solution will lie in the non-zero interior at the point of tangency between the [[objective function]] and the constraint. For example, in [[consumer theory]] the objective function is the [[indifference curve|indifference-curve]] map (the [[utility function]]) of the consumer. The budget line is the constraint.  In the usual case, constrained utility is maximized on the budget constraint with strictly positive quantities consumed of both goods.  For a corner solution, however, utility is maximized at a point on one axis where the budget constraint intersects the highest attainable indifference curve at zero consumption for one good with all income used for the other good.  Furthermore, a range of lower prices for the good with initial zero consumption may leave quantity demanded unchanged at zero, rather than increasing it as in the more usual case.\n\n==See also==\n*[[Indifference curve#Assumptions of consumer preference theory|Indifference curve: Assumptions section]]\n*[[Interior solution (optimization)]]\n\n[[Category:Mathematical optimization]]\n[[Category:Utility]]\n[[Category:Economics]]\n[[Category:Consumer theory]]"
    },
    {
      "title": "Dead-end elimination",
      "url": "https://en.wikipedia.org/wiki/Dead-end_elimination",
      "text": "The '''dead-end elimination''' algorithm '''(DEE)''' is a method for [[optimization (mathematics)|minimizing]] a function over a discrete set of independent variables.  The basic idea is to identify \"dead ends\", i.e., combinations of variables that are not necessary to define a global minimum because there is always a way of replacing such combination by a better or equivalent one. Then we can refrain from searching such combinations further. Hence, dead-end elimination is a mirror image of [[dynamic programming]], in which \"good\" combinations are identified and explored further. Although the method itself is general, it has been developed and applied mainly to the problems of [[protein structure prediction|predicting]] and [[protein design|designing]] the structures of [[protein]]s. It closely related to the notion of dominance in optimization also known as substitutability in a [[Constraint Satisfaction Problem]]. The original description and proof of the dead-end elimination theorem can be found in {{ref|Desmet}}.\n\n==Basic requirements==\nAn effective DEE implementation requires four pieces of information:\n# A well-defined finite set of discrete independent variables\n# A precomputed numerical value (considered the \"energy\") associated with each element in the set of variables (and possibly with their pairs, triples, etc.)\n# A criterion or criteria for determining when an element is a \"dead end\", that is, when it cannot possibly be a member of the solution set\n# An [[objective function]] (considered the \"energy function\") to be minimized\n\nNote that the criteria can easily be reversed to identify the maximum of a given function as well.\n\n==Applications to protein structure prediction==\nDead-end elimination has been used effectively to predict the structure of side chains on a given [[tertiary structure|protein backbone structure]] by minimizing an energy function <math>E</math>.  The [[dihedral angle]] search space of the side chains is restricted to a discrete set of [[rotamer]]s for each [[amino acid]] position in the protein (which is, obviously, of fixed length). The original DEE description included criteria for the elimination of single rotamers and of rotamer pairs, although this can be expanded.\n\nIn the following discussion, let <math>N</math> be the length of the protein and let <math>r_{k}</math> represent the rotamer of the <math>\\mathrm{k^{th}}</math> side chain.  Since atoms in proteins are assumed to interact only by two-body [[potential]]s, the energy may be written\n\n:<math>\nE_{TOT} = \\sum_{k} E_{k}(r_{k}) + \\sum_{k \\neq l} E_{kl}(r_{k}, r_{l})\\,\n</math>\n\nWhere <math>E_{k}(r_{k})</math> represents the \"self-energy\" of a particular rotamer <math>r_{k}</math>, and <math>E_{kl}(r_{k}, r_{l})</math> represents the \"pair energy\" of the rotamers <math>r_{k}, r_{j}</math>.\n\nAlso note that <math>E_{kk}(r_{k}^{A}, r_{k}^{A})</math> (that is, the pair energy between a rotamer and itself) is taken to be zero, and thus does not affect the summations. This notation simplifies the description of the pairs criterion below.\n\n===Singles elimination criterion===\n\nIf a particular rotamer <math>r_{k}^{A}</math> of sidechain <math>k</math> cannot possibly give a better energy than another rotamer <math>r_{k}^{B}</math> of the same sidechain, then rotamer A can be eliminated from further consideration, which reduces the search space.  Mathematically, this condition is expressed by the inequality\n\n:<math>\nE_{k}(r_{k}^{A}) + \\sum_{l=1}^{N} \\min_{X} E_{kl}(r_{k}^{A}, r_{l}^{X}) > E_{k}(r_{k}^{B}) + \\sum_{l=1}^{N} \\max_{X} E_{kl}(r_{k}^{B}, r_{l}^{X})\n</math>\n\nwhere <math>\\min_{X} E_{kl}(r_{k}^{A}, r_{l}^{X})</math> is the minimum (best) energy possible between rotamer <math>r_{k}^{A}</math> of sidechain <math>k</math> and ''any'' rotamer X of side chain <math>l</math>.  Similarly, <math>\\max_{X} E_{kl}(r_{k}^{B}, r_{l}^{X})</math> is the maximum (worst) energy possible between rotamer <math>r_{k}^{B}</math> of sidechain <math>k</math> and ''any'' rotamer X of side chain <math>l</math>.\n\n===Pairs elimination criterion===\n\nThe pairs criterion is more difficult to describe and to implement, but it adds significant eliminating power. For brevity, we define the shorthand variable <math>U_{kl}^{AB}</math> that is the ''intrinsic'' energy of a pair of rotamers <math>A</math> and <math>B</math> at positions <math>k</math> and <math>l</math>, respectively\n\n:<math>\nU_{kl}^{AB} \\ \\stackrel{\\mathrm{def}}{=}\\  E_{k}(r_{k}^{A}) + E_{l}(r_{l}^{B}) + E_{kl}(r_{k}^{A}, r_{l}^{B})\n</math>\n\nA given pair of rotamers <math>A</math> and <math>B</math> at positions <math>k</math> and <math>l</math>, respectively, cannot ''both'' be in the final solution (although one or the other may be) if there is another pair <math>C</math> and <math>D</math> that always gives a better energy. Expressed mathematically,\n\n:<math>\nU_{kl}^{AB} + \\sum_{i=1}^{N} \\min_{X} \\left(E_{ki}(r_{k}^{A}, r_{i}^{X}) + E_{lj}(r_{l}^{B}, r_{j}^{X})\\right) > U_{kl}^{CD} + \\sum_{i=1}^{N} \\max_{X} \\left(E_{ki}(r_{k}^{C}, r_{i}^{X}) + E_{lj}(r_{l}^{D}, r_{j}^{X})\\right)\n</math>\n\nwhere <math>A \\neq C</math>, <math>B \\neq D</math> and <math>k \\neq l</math>.\n\n===Energy matrices===\nFor large <math>N</math>, the matrices of precomputed energies can become costly to store. Let <math>N</math> be the number of amino acid positions, as above, and let <math>p</math> be the number of rotamers at each position (this is usually, but not necessarily, constant over all positions). Each self-energy matrix for a given position requires <math>p</math> entries, so the total number of self-energies to store is <math>Np</math>. ''Each'' pair energy matrix between two positions <math>r_{k}</math> and <math>r_{l}</math>, for <math>p</math> discrete rotamers at each position, requires a <math>p \\times p</math> matrix. This makes the total number of entries in an unreduced pair matrix <math>N^{2}p^{2}</math>. This can be trimmed somewhat, at the cost of additional complexity in implementation, because pair energies are symmetrical and the pair energy between a rotamer and itself is zero.\n\n==Implementation and efficiency==\nThe above two criteria are normally applied iteratively until convergence, defined as the point at which no more rotamers or pairs can be eliminated. Since this is normally a reduction in the sample space by many orders of magnitude, simple enumeration will suffice to determine the minimum within this pared-down set.\n\nGiven this model, it is clear that the DEE algorithm is guaranteed to find the optimal solution; that is, it is a [[global optimization]] process. The single-rotamer search scales [[quadratic growth|quadratically]] in time with ''total'' number of rotamers. The pair search scales cubically and is the slowest part of the algorithm (aside from energy calculations). This is a dramatic improvement over the brute-force enumeration which scales as <math>O(p^{N})</math>.\n\nA large-scale [[benchmark (computing)|benchmark]] of DEE compared with alternative methods of [[protein structure prediction]] and design finds that DEE reliably converges to the optimal solution for protein lengths for which it runs in a reasonable amount of time{{ref|Voigt}}. It significantly outperforms the alternatives under consideration, which involved techniques derived from [[mean field theory]], [[genetic algorithm]]s, and the [[Monte Carlo method]]. However, the other algorithms are appreciably faster than DEE and thus can be applied to larger and more complex problems; their relative accuracy can be extrapolated from a comparison to the DEE solution within the scope of problems accessible to DEE.\n\n==Protein design==\n{{main|Protein design}}\nThe preceding discussion implicitly assumed that the rotamers <math>r_{k}</math> are all different orientations of the same amino acid side chain. That is, the sequence of the protein was assumed to be fixed. It is also possible to allow multiple side chains to \"compete\" over a position <math>k</math> by including both types of side chains in the set of rotamers for that position. This allows a novel sequence to be designed onto a given protein backbone. A short [[zinc finger]] protein fold has been redesigned this way{{ref|Dahiyat}}. However, this greatly increases the number of rotamers per position and still requires a fixed protein length.\n\n==Generalizations==\nMore powerful and more general criteria have been introduced that improve both the efficiency and the eliminating power of the method for both prediction and design applications. One example is a refinement of the singles elimination criterion known as the Goldstein criterion{{ref|Goldstein}}, which arises from fairly straightforward algebraic manipulation before applying the minimization:\n\n:<math>\nE_{k}(r_{k}^{A}) - E_{k}(r_{k}^{B}) + \\sum_{l=1}^{N} \\min_{X} \\left(E_{kl}(r_{k}^{A}, r_{l}^{X}) - E_{kl}(r_{k}^{B}, r_{l}^{X})\\right) > 0\n</math>\n\nThus rotamer <math>r_{k}^{A}</math> can be eliminated if any alternative rotamer from the set at <math>r_{k}</math> contributes less to the total energy than <math>r_{k}^{A}</math>. This is an improvement over the original criterion, which requires comparison of the best possible (that is, the smallest) energy contribution from <math>r_{k}^{A}</math> with the ''worst'' possible contribution from an alternative rotamer.\n\nAn extended discussion of elaborate DEE criteria and a benchmark of their relative performance can be found in {{ref|Peirce}}.\n\n==References==\n\n# {{note|Desmet}} Desmet J, de Maeyer M, Hazes B, Lasters I. (1992). The dead-end elimination theorem and its use in protein side-chain positioning. ''Nature'', '''356''', 539-542. {{PMID|21488406}}.\n# {{note|Voigt}} Voigt CA, Gordon DB, Mayo SL. (2000). Trading accuracy for speed: A quantitative comparison of search algorithms in protein sequence design. ''J Mol Biol''  299(3):789-803.\n# {{note|Dahiyat}} Dahiyat BI, Mayo SL. (1997). De novo protein design: fully automated sequence selection. ''Science'' 278(5335):82-7.\n# {{note|Goldstein}} Goldstein RF. (1994). Efficient rotamer elimination applied to protein side-chains and related spin glasses. ''Biophys J'' 66(5):1335-40.\n# {{note|Peirce}} Pierce NA, Spriet JA, Desmet J, Mayo SL. (2000). Conformational splitting: a more powerful criterion for dead-end elimination. ''J Comput Chem'' 21: 999-1009.\n\n[[Category:Mathematical optimization]]\n[[Category:Protein methods]]"
    },
    {
      "title": "Descent direction",
      "url": "https://en.wikipedia.org/wiki/Descent_direction",
      "text": "In [[optimization (mathematics)|optimization]], a '''descent direction''' is a vector <math>\\mathbf{p}\\in\\mathbb R^n</math> that, in the sense below, moves us closer towards a local minimum <math>\\mathbf{x}^*</math> of our objective function <math>f:\\mathbb R^n\\to\\mathbb R</math>.\n\nSuppose we are computing <math>\\mathbf{x}^*</math> by an iterative method, such as [[line search]]. We define a descent direction <math>\\mathbf{p}_k\\in\\mathbb R^n</math> at the <math>k</math>th iterate to be any <math>\\mathbf{p}_k</math> such that <math>\\langle\\mathbf{p}_k,\\nabla f(\\mathbf{x}_k)\\rangle < 0</math>, where <math> \\langle , \\rangle </math> denotes the [[inner product]]. The motivation for such an approach is that small steps along <math>\\mathbf{p}_k</math> guarantee that <math>\\displaystyle f</math> is reduced, by [[Taylor's theorem]].\n\nUsing this definition, the negative of a non-zero gradient is always a\ndescent direction, as <math> \\langle -\\nabla f(\\mathbf{x}_k), \\nabla f(\\mathbf{x}_k) \\rangle = -\\langle \\nabla f(\\mathbf{x}_k), \\nabla f(\\mathbf{x}_k) \\rangle < 0 </math>.\n\nNumerous methods exist to compute descent directions, all with differing merits. For example, one could use [[gradient descent]] or the [[conjugate gradient method]].\n\nMore generally, if <math>P</math> is a [[positive definite]] matrix, then\n<math>d = -P \\nabla f(x)</math>\nis a descent direction\n<ref name=\"?\">{{cite book | author =  J. M. Ortega and W. C. Rheinbold | title = Iterative Solution of Nonlinear Equations in Several Variables | pages = 243 | year = 1970 | doi = 10.1137/1.9780898719468\n }}</ref>\nat <math>x</math>.\nThis generality is used in [[preconditioned]] gradient descent methods.\n\n{{Reflist}}\n\n{{DEFAULTSORT:Descent Direction}}\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Deterministic global optimization",
      "url": "https://en.wikipedia.org/wiki/Deterministic_global_optimization",
      "text": "'''Deterministic global optimization''' is a branch of numerical [[optimization]] which focuses on finding the global solutions of an optimization problem whilst providing theoretical guarantees that the reported solution is indeed the global one, within some predefined tolerance. The term \"deterministic global optimization\" typically refers to '''complete''' or '''rigorous''' (see below) optimization methods. Rigorous methods converge to the global optimum in finite time. Deterministic global optimization methods are typically used when locating the global solution is a necessity (i.e. when the only naturally occurring state described by a mathematical model is the global minimum of an optimization problem), when it is extremely difficult to find a feasible solution, or simply when the user  desires to locate the best possible solution to a problem.\n\n== Overview ==\nNeumaier<ref>Complete Search in Continuous Global Optimization and Constraint Satisfaction, Acta Numerica 2004 (A. Iserles, ed.), Cambridge University Press 2004</ref> classified global optimization methods in four categories, depending on their degree of rigour with which they approach the optimum, as follows:\n\n* An '''incomplete''' method uses clever intuitive heuristics for searching but has no safeguards if the search gets stuck in a local minimum\n* An '''asymptotically complete''' method reaches a global minimum with certainty or at least with probability one if allowed to run indefinitely long, but has no means to know when a global minimizer has been found.\n* A '''complete''' method reaches a global minimum with certainty, assuming exact computations and indefinitely long run time, and knows after a finite time that an approximate global minimizer has been found (to within prescribed tolerances).\n* A '''rigorous''' method reaches a global minimum with certainty and within given tolerances even in the presence of rounding errors, except in near-degenerate cases, where the tolerances may be exceeded.\n\nDeterministic global optimization methods typically belong to the last two categories. Note that building a rigorous piece of software is extremely difficult as the process requires that all the dependencies are also coded rigorously.\n\nDeterministic global optimization methods require ways to rigorously bound function values over regions of space. One could say that a main difference between deterministic and non-deterministic methods in this context is that the former perform calculations over regions of the solution space, whereas the latter perform calculations on single points. This is either done by exploiting particular functional forms (e.g. McCormick relaxations<ref>Computability of global solutions to factorable nonconvex programs: Part I – Convex underestimating problems, Mathematical Programming, 1976, 1(10), 147–175</ref>), or using [[interval analysis]] in order to work with more general functional forms. In any case bounding is required, which is why deterministic global optimization methods cannot give a rigorous result when working with [[black-box]] code, unless that code is explicitly written to also return function bounds. For this reason, it is common for problems in deterministic global optimization to be represented using a [[Directed acyclic graph|computational graph]], as it is straightforward to overload all operators such that the resulting function values or derivatives yield interval (rather than scalar) results.\n\n== Classes of deterministic global optimization problems ==\n=== [[Linear programming]] problems (LP) ===\nLinear programming problems are a highly desirable formulation for any practical problem. The reason is that, with the rise of interior-point algorithms, it is possible to efficiently solve very large problems (involving hundreds of thousands or even millions of variables) to global optimality. Linear programming optimization problems strictly fall under the category of deterministic global optimization.\n\n=== [[Linear programming#Integer unknowns|Mixed-integer linear programming]] problems (MILP) ===\nMuch like linear programming problems, MILPs are very important when solving decision-making models. Efficient algorithms for solving complex problems of this type are known and are available in the form of solvers such as [[CPLEX]] or [[Gurobi]].\n\n=== [[Non-linear programming]] problems (NLP) ===\nNon-linear programming problems are extremely challenging in deterministic global optimization. The order of magnitude that a modern solver can be expected to handle in reasonable time is roughly 100 to a few hundreds of non-linear variables. It should be noted that, at the time of this writing, there exist no parallel solvers for the deterministic solution of NLPs, which accounts for the complexity gap between deterministic LP and NLP programming.\n\n=== Mixed-integer non-linear programming problems (MINLP) ===\nEven more challenging than their NLP counterparts, deterministically solving an MINLP problem can be very difficult. Techniques such as [[Cutting-plane method|integer cuts]], or branching a problem on its integer variables (hence creating NLP sub-problems which can in turn be solved deterministically), are commonly used.\n\n== Zero-order methods ==\nZero-order methods consist of methods which make use of zero-order [[interval arithmetic]].<ref>Hansen, E.R. Global optimization using interval analysis, Marcel Dekker Inc, New York 1992</ref> A representative example is interval bisection.\n\n== First-order methods ==\nFirst-order methods consist of methods which make use of first-order information, e.g., interval gradients or interval slopes.\n\n== Second-order methods ==\nSecond-order methods make use of second-order information, usually eigenvalue bounds derived from interval [[Hessian matrices]]. One of the most general second-order methodologies for handling problems of general  type is the [[αΒΒ]] algorithm.\n\n== Deterministic global optimization solvers == \n* [http://helios.princeton.edu/ANTIGONE/ ANTIGONE]\n* [http://www.minlp.com/baron BARON]\n* [https://projects.coin-or.org/Couenne/ Couenne]\n* [https://www.lindo.com/ LINDO Global]\n* [https://www.octeract.co.uk/products Octeract]\n* [http://scip.zib.de/ SCIP]\n\n==References==\n{{Reflist}}\n\n[[Category:Mathematical optimization]]\n[[Category:Deterministic global optimization| ]]"
    },
    {
      "title": "Discrete optimization",
      "url": "https://en.wikipedia.org/wiki/Discrete_optimization",
      "text": "{{short description|branch of mathematical optimization}}\n'''Discrete optimization''' is a branch of [[Optimization (mathematics)|optimization]] in [[applied mathematics]] and [[computer science]].\n\n==Scope==\nAs opposed to [[continuous optimization]], some or all of the [[Variable (mathematics)|variables]] used in a discrete [[optimization (mathematics)|mathematical program]] are restricted to be [[discrete variable]]s&mdash;that is, to assume only a [[discrete mathematics|discrete]] set of values, such as the integers.<ref>{{citation|title=A First Course in Combinatorial Optimization|volume=36|series=Cambridge Texts in Applied Mathematics|first=Jon|last=Lee|publisher=Cambridge University Press|year=2004|isbn=9780521010122|page=1|url=https://books.google.com/books?id=3pL1B7WVYnAC&pg=PA1}}.</ref>\n\n==Branches==\nTwo notable branches of discrete optimization are:<ref>{{citation\n | last1 = Hammer | first1 = P. L.\n | last2 = Johnson | first2 = E. L.\n | last3 = Korte | first3 = B. H.\n | contribution = Conclusive remarks\n | pages = 427–453\n | publisher = Elsevier\n | series = Annals of Discrete Mathematics\n | title = Discrete Optimization II\n | volume = 5\n | year = 2000}}.</ref>\n* [[combinatorial optimization]], which refers to problems on [[Graph (discrete mathematics)|graph]]s, [[matroid]]s and other discrete structures\n* [[integer programming]] \nThese branches are closely intertwined however since many combinatorial optimization problems can be modeled as integer programs (e.g. [[Shortest path#Linear programming formulation|shortest path]]) and conversely, integer programs can often be given a combinatorial interpretation.\n\n==See also==\n*[[Diophantine equation]]\n\n==References==\n{{reflist}}\n\n{{Authority control}}\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Distributed constraint optimization",
      "url": "https://en.wikipedia.org/wiki/Distributed_constraint_optimization",
      "text": "'''Distributed constraint optimization''' ('''DCOP''' or '''DisCOP''') is the [[Distributed computing|distributed]] analogue to [[constraint optimization]].  A DCOP is a problem in which a group of agents must distributedly choose values for a set of variables such that the cost\nof a set of constraints over the variables is minimized.\n\nDistributed Constraint Satisfaction is a framework for describing a problem in terms of constraints that are known and enforced by distinct participants (agents). The constraints are described on some variables with predefined domains, and have to be assigned to the same values by the different agents.\n\nProblems defined with this framework can be solved by any of the algorithms that are designed for it.\n\nThe framework was used under different names in the 1980s. The first known usage with the current name is in 1990. {{Citation needed|date=July 2018}}\n\n==Definitions==\n\n===DCOP===\n\nA '''DCOP''' can be defined as a [[tuple]] <math>\\langle A, V, \\mathfrak{D}, f, \\alpha, \\eta \\rangle</math>, where:\n*<math>A</math> is a [[set (mathematics)|set]] of [[Intelligent agent|agents]];\n*<math>V</math> is a set of variables, <math>\\{v_1,v_2,\\cdots,v_{|V|}\\}</math>;\n*<math>\\mathfrak{D}</math> is a set of domains, <math>\\{D_1, D_2, \\ldots, D_{|V|}\\}</math>, where each <math>D \\in \\mathfrak{D}</math> is a [[finite set]] containing the values to which its associated variable may be assigned;\n*<math>f</math> is a function<ref>\"<math>\\mathfrak{P}(\\mathfrak{V})</math>\" denotes the [[power set]] of <math>V</math></ref><ref>\"<math>\\times</math>\" and \"<math>\\sum</math>\" denote the [[Cartesian product]].</ref><center><math>f : \\bigcup_{S \\in \\mathfrak{P}(V)}\\sum{v_i \\in S} \\left( \\{v_i\\} \\times D_i \\right) \\rightarrow \\mathbb{N} \\cup \\{\\infty\\}</math></center>that maps every possible variable assignment to a cost.  This function can also be thought of as defining constraints between variables however the variables must not be Hermitian;\n*<math>\\alpha</math> is a function <math>\\alpha: V \\rightarrow A</math> mapping variables to their associated agent.  <math>\\alpha(v_i) \\mapsto a_j</math> implies that it is agent <math>a_j</math>'s responsibility to assign the value of variable <math>v_i</math>.  Note that it is not necessarily true that <math>\\alpha</math> is either an [[Injective function|injection]] or [[surjection]]; and\n*<math>\\eta</math> is an [[Operator (mathematics)|operator]] that aggregates all of the individual <math>f</math> costs for all possible variable assignments.  This is usually accomplished through summation:<center><math>\\eta(f) \\mapsto \\sum_{s \\in \\bigcup_{S \\in \\mathfrak{P}(V)}\\sum{v_i \\in S} \\left( \\{v_i\\} \\times D_i \\right)} f(s)</math>.</center>\n\nThe objective of a DCOP is to have each agent assign values to its associated variables in order to either minimize or maximize <math>\\eta(f)</math> for a given assignment of the variables.\n\n===Context===\n\nA '''context''' is a variable assignment for a DCOP.  This can be thought of as a function mapping variables in the DCOP to their current values:<center><math>t : V \\rightarrow (D \\in \\mathfrak{D}) \\cup \\{\\emptyset\\}.</math></center>  Note that a context is essentially a partial solution and need not contain values for ''every'' variable in the problem; therefore, <math>t(v_i) \\mapsto \\emptyset</math> implies that the agent <math>\\alpha(v_i)</math> has not yet assigned a value to variable <math>v_i</math>.  Given this representation, the \"[[Domain (mathematics)|domain]]\" (''i.e.'', the set of  input values) of the function <code>f</code> can be thought of as the set of all possible contexts for the DCOP.  Therefore, in the remainder of this article we may use the notion of a context (''i.e.'', the <math>t</math> function) as an input to the <math>f</math> function.\n\n==Example problems==\n\n===Distributed graph coloring===\nThe [[graph coloring]] problem is as follows: given a [[Graph (discrete mathematics)|graph]] <math>G = \\langle N, E \\rangle</math> and a set of colors <math>C</math>, assign each [[Vertex (graph theory)|vertex]], <math>n\\subset N</math>, a color, <math>c\\leq C</math>, such that the number of adjacent vertices with the same color is minimized.\n\nAs a DCOP, there is one agent per vertex that is assigned to decide the associated color.  Each agent has a single variable whose associated domain is of [[cardinality]] <math>|C|</math> (there is one domain value for each possible color).  For each vertex <math>n_i \\leq N</math>, create a variable in the DCOP <math>v_i \\in V</math> with domain <math>D_i = C</math>.  For each pair of adjacent vertices <math>\\langle n_i, n_j \\rangle \\in E</math>, create a constraint of cost 1 if both of the associated variables are assigned the same color: <center><math>(\\forall c \\subseteq C : f(\\langle v_i, c \\rangle, \\langle v_j, c \\rangle ) \\mapsto 1).</math></center>The objective, then, is to minimize <math>\\eta(f)</math>.\n\n===Distributed multiple knapsack problem===\nThe ''distributed multiple-'' variant of the [[knapsack problem]] is as follows: given a set of items of varying volume and a set of knapsacks of varying capacity, assign each item to a knapsack such that the amount of overflow is minimized.  Let <math>I</math> be the set of items, <math>K</math> be the set of knapsacks, <math>s : I \\rightarrow \\mathbb{N}</math> be a function mapping items to their volume, and <math>c : K \\rightarrow \\mathbb{N}</math> be a function mapping knapsacks to their capacities.\n\nTo encode this problem as a DCOP, for each <math>i \\in I</math> create one variable <math>v_i \\in V</math> with associated domain <math>D_i = K</math>.  Then for all possible contexts <math>t</math>:<center><math>f(t) \\mapsto \\sum_{k \\in K} \\begin{cases}\n                    0&  r(t,k) \\leq c(k),\\\\\n                    r(t,k)-c(k) & \\text{otherwise},\n                  \\end{cases}</math></center>where <math>r(t,k)</math> is a function such that<center><math>r(t,k) = \\sum_{v_i \\in t^{-1}(k)} s(i).</math></center>\n\n==Algorithms==\n\nDCOP algorithms can be classified according to the search strategy (best-first search or depth-first branch-and-bound search), the synchronization among agents (synchronous or asynchronous), the communication among agents (point-to-point with neighbors in the constraint graph or broadcast) and the main communication topology (chain or tree).<ref name=\"yeoh06\">\n{{Citation\n  | last1 = Yeoh    | first1 = William\n  | last2 = Felner | first2 = Ariel\n  | last3 = Koenig | first3 = Sven\n  | contribution = BnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm\n  | title = Proceedings of the Seventh International Joint Conference on Autonomous Agents and Multiagent Systems\n  | year = 2008\n  | pages = 591&ndash;598\n  | contribution-url = http://idm-lab.org/bib/abstracts/Koen08d.html}}</ref>\nADOPT, for example, uses best-first search, asynchronous synchronization, point-to-point communication between neighboring agents in the constraint graph and a constraint tree as main communication topology.\n\n{| class=\"wikitable\"\n|-\n! Algorithm Name\n! Year Introduced\n! [[Computational complexity theory|Memory Complexity]]\n! Number of Messages\n! [[Correctness (computer science)]]/<br />[[Completeness (logic)]]\n! Implementations\n|-\n| '''NCBB'''<br />No-Commitment Branch and Bound<ref name=\"chechetka06no\">\n{{Citation\n  | last1 = Chechetka    | first1 = Anton\n  | last2 = Sycara | first2 = Katia\n  | contribution = No-Commitment Branch and Bound Search for Distributed Constraint Optimization\n  | title = Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multiagent Systems\n  | date = May 2006\n  | pages = 1427&ndash;1429\n  | contribution-url = http://www.ri.cmu.edu/pub_files/pub4/chechetka_anton_2006_2/chechetka_anton_2006_2.pdf}}</ref>\n| 2006\n| Polynomial (or any-space<ref name=\"chechetka06anyspace\">\n{{Citation\n  | last1 = Chechetka | first1 = Anton\n  | last2 = Sycara | first2 = Katia\n  | contribution = An Any-space Algorithm for Distributed Constraint Optimization\n  | title = Proceedings of the AAAI Spring Symposium on Distributed Plan and Schedule Management\n  | date = March 2006\n  | contribution-url = http://www.ri.cmu.edu/pub_files/pub4/chechetka_anton_2006_1/chechetka_anton_2006_1.pdf| title-link = AAAI\n  }}</ref>)\n| Exponential\n| Proven\n| ''Reference Implementation:'' not publicly released<br />\n[https://archive.is/20080919011453/http://dcopolis.sourceforge.net/ DCOPolis] ([[GNU Lesser General Public License|GNU LGPL]])\n|-\n| '''DPOP'''<br />Distributed Pseudotree Optimization Procedure<ref name=\"petcu04distributed\">\n{{Citation\n  | last1 = Petcu    | first1 = Adrian\n  | last2 = Faltings | first2 = Boi\n  | contribution = DPOP: A Scalable Method for Multiagent Constraint Optimization\n  | title = Proceedings of the 19th International Joint Conference on Artificial Intelligence, IJCAI 2005, Edinburgh, Scotland, pp. 266-271\n  | date = August 2005\n  | contribution-url = http://liawww.epfl.ch/cgi-bin/Pubs/single_entry?bibtex_key=Petcu2005}}</ref>\n| 2005\n| Exponential\n| Linear\n| Proven\n| ''Reference Implementation:'' [https://web.archive.org/web/20070629200035/http://liawww.epfl.ch/frodo/ FRODO] ([[Affero General Public License|GNU Affero GPL]])<br />\n[https://archive.is/20080919011453/http://dcopolis.sourceforge.net/ DCOPolis] ([[GNU Lesser General Public License|GNU LGPL]])\n|-\n| '''OptAPO'''<br />Asynchronous Partial Overlay<ref name=\"mailler04solving\">\n{{Citation\n  | last1 = Mailler    | first1 = Roger\n  | last2 = Lesser | first2 = Victor\n  | contribution = Solving Distributed Constraint Optimization Problems Using Cooperative Mediation\n  | title = Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems\n  | pages = 438&ndash;445\n  | publisher = [[IEEE Computer Society]]\n  | year = 2004\n  | contribution-url = ftp://mas.cs.umass.edu/pub/mailler/mailler-569.pdf}}</ref>\n| 2004\n| Polynomial \n| Exponential\n| Proven, but proof of completeness has been challenged<ref name=\"dcr07proceedings\">\n{{Citation\n  | last1 = Grinshpoun    | first1 = Tal\n  | last2 = Zazon | first2 = Moshe\n  | last3 = Binshtok | first3 = Maxim\n  | last4 = Meisels | first4 = Amnon\n  | contribution = Termination Problem of the APO Algorithm\n  | title = Proceedings of the Eighth International Workshop on Distributed Constraint Reasoning\n  | pages = 117&ndash;124\n  | year = 2007\n  | contribution-url = http://liawww.epfl.ch/Publications/Archive/DCR07Proceedings.pdf}}</ref>\n| ''Reference Implementation:'' {{cite web|url=http://www.ai.sri.com/~mailler/optapo.html|archiveurl=https://web.archive.org/web/20070715063706/http://www.ai.sri.com/~mailler/optapo.html|archivedate=2007-07-15|title=OptAPO|work=[[Artificial Intelligence Center]]|publisher=[[SRI International]]}}<br />\n[https://archive.is/20080919011453/http://dcopolis.sf.net/ DCOPolis] ([[GNU Lesser General Public License|GNU LGPL]]); In Development\n|-\n| '''Adopt'''<br />Asynchronous Backtracking<ref>The originally published version of Adopt was uninformed, see\n{{Citation\n  | last1 = Modi    | first1 = Pragnesh Jay\n  | last2 = Shen | first2 = Wei-Min\n  | last3 = Tambe     | first3 = Milind\n  | last4 = Yokoo | first4 = Makoto\n  | contribution = An asynchronous complete method for distributed constraint optimization\n  | title = Proceedings of the second international joint conference on autonomous agents and multiagent systems\n  | publisher = [[Association for Computing Machinery|ACM]] Press\n  | year = 2003\n  | pages = 161&ndash;168\n  | contribution-url = http://teamcore.usc.edu/papers/2003/modi-aamas03.pdf}}. The original version of Adopt was later extended to be informed, that is, to use estimates of the solution costs to focus its search and run faster, see\n{{Citation\n  | last1 = Ali    | first1 = Syed\n  | last2 = Koenig | first2 = Sven\n  | last3 = Tambe     | first3 = Milind\n  | contribution = Preprocessing Techniques for Accelerating the DCOP Algorithm ADOPT\n  | title = Proceedings of the fourth international joint conference on autonomous agents and multiagent systems\n  | publisher = [[Association for Computing Machinery|ACM]] Press\n  | year = 2005\n  | pages = 1041&ndash;1048\n  | contribution-url = http://teamcore.usc.edu/papers/2005/aamas-paper.pdf}}. This extension of Adopt is typically used as reference implementation of Adopt.</ref>\n| 2003\n| Polynomial (or any-space<ref name=\"matsui05efficient\">\n{{Citation\n  | last1 = Matsui    | first1 = Toshihiro\n  | last2 = Matsuo | first2 = Hiroshi\n  | last3 = Iwata | first3 = Akira\n  | contribution = Efficient Method for Asynchronous Distributed Constraint Optimization Algorithm\n  | title = Proceedings of Artificial Intelligence and Applications\n  | date = February\n  | pages = 727&ndash;732\n  | year = 2005\n  | contribution-url = http://www.matlab.nitech.ac.jp/~matsuo/AIA05-1.pdf}}</ref>)\n| Exponential\n| Proven\n| ''Reference Implementation:'' [http://teamcore.usc.edu/dcop/ Adopt]<br />\n[https://archive.is/20080919011453/http://dcopolis.sf.net/ DCOPolis] ([[GNU Lesser General Public License|GNU LGPL]])<br />\n[https://web.archive.org/web/20070629200035/http://liawww.epfl.ch/frodo/ FRODO] ([[Affero General Public License|GNU Affero GPL]])\n|-\n| '''Secure Multiparty Computation For Solving DisCSPs'''<br>(MPC-DisCSP1-MPC-DisCSP4){{Citation needed|date=October 2010}}\n| 2003\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>Note: secure if 1/2 of the participants are trustworthy</small>\n| {{Citation needed|date=October 2010}}\n|-\n| '''Secure Computation with Semi-Trusted Servers'''{{Citation needed|date=October 2010}}\n| 2002\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>Note: security increases with the number of trustworthy servers</small>\n| {{Citation needed|date=October 2010}}\n|-\n| '''ABTR'''{{Citation needed|date=October 2010}}<br>Asynchronous Backtracking with Reordering\n| 2001\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>Note: eordering in ABT with bounded nogoods</small>\n| {{Citation needed|date=October 2010}}\n|-\n| '''DMAC'''{{Citation needed|date=October 2010}}<br>Maintaining Asynchronously Consistencies\n| 2001\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>Note: the fastest algorithm</small>\n| {{Citation needed|date=October 2010}}\n|-\n| '''AAS'''{{Citation needed|date=October 2010}}<br>Asynchronous Aggregation Search\n| 2000\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>aggregation of values in ABT</small>\n| {{Citation needed|date=October 2010}}\n|-\n| '''DFC'''{{Citation needed|date=October 2010}}<br>Distributed Forward Chaining\n| 2000\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>Note: low, comparable to ABT</small>\n| {{Citation needed|date=October 2010}}\n|-\n| '''DBA'''<br>Distributed Breakout Algorithm\n| 1995\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>Note: incomplete but fast</small>\n| [http://liawww.epfl.ch/frodo1/ FRODO version 1]{{dead link|date=September 2017 |bot=InternetArchiveBot |fix-attempted=yes }}\n|-\n| '''AWC'''{{Citation needed|date=October 2010}}<br>Asynchronous Weak-Commitment\n| 1994\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>Note: reordering, fast, complete (only with exponential space)</small>\n| {{Citation needed|date=October 2010}}\n|-\n| '''ABT'''{{Citation needed|date=October 2010}}<br>Asynchronous Backtracking\n| 1992\n| {{Citation needed|date=October 2010}}\n| {{Citation needed|date=October 2010}}\n| <small>Note: static ordering, complete</small>\n| {{Citation needed|date=October 2010}}\n|-\n| '''CFL'''<br />Communication-Free Learning<ref name=\"cfl\">\n{{Citation\n  | last1 = Duffy | first1 = K.R.\n  | last2 = Leith | first2 = D.J.\n  | contribution = Decentralized Constraint Satisfaction\n  | title = IEEE/ACM Transactions on Networking, 21(4)\n  | volume = 21\n  | issue = 4\n  | pages = 1298–1308\n  | date = August 2013\n  | doi = 10.1109/TNET.2012.2222923\n  | arxiv = 1103.3240\n  }}</ref>\n| 2013\n| Linear\n| None <small>Note: no messages are sent, but assumes knowledge about satisfaction of local constraint</small>\n| Incomplete\n| \n|-\n|}\n\nHybrids of these DCOP algorithms also exist. BnB-Adopt,<ref name=\"yeoh06\" /> for example, changes the search strategy of Adopt from best-first search to depth-first branch-and-bound search.\n\n==See also==\n* [[Constraint satisfaction problem]]\n\n==Notes and references==\n<references/>\n\n==Books and surveys==\n\n* {{Citation |last=Fioretto |first=Ferdinando | last2=Pontelli | first2=Enrico | last3=Yeoh | first3=William  |title=Distributed Constraint Optimization Problems and Applications: A Survey |year=2018 |journal=[[Journal of Artificial Intelligence Research (JAIR)]] |url= http://www.jair.org/papers/paper5565.html |doi= 10.1613/jair.5565 |volume= 61 |pages= 623–698|arxiv=1602.06347 }}\n* {{Citation |last=Faltings |first=Boi |editor1-last=Walsh |editor1-first=Toby |title=Handbook of Constraint Programming |year=2006 |publisher=[[Elsevier]] | chapter-url=http://www.elsevier.com/wps/find/bookdescription.cws_home/708863/description |isbn=978-0-444-52726-4 |chapter=Distributed Constraint Programming }} A chapter in an edited book.\n* {{Citation | last1=Meisels | first1=Amnon | title=Distributed Search by Constrained Agents | publisher = [[Springer Science+Business Media|Springer]] | isbn=978-1-84800-040-7 | year=2008}}\n* {{Citation | last1=Shoham | first1=Yoav | last2=Leyton-Brown | first2=Kevin | title=Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations | publisher=[[Cambridge University Press]] | isbn=978-0-521-89943-7 | url=http://www.masfoundations.org | year=2009 | location=New York}} See Chapters 1 and 2; [http://www.masfoundations.org/download.html downloadable free online].\n* {{Citation | last1=Yokoo | first1=Makoto | title=Distributed constraint satisfaction: Foundations of cooperation in multi-agent systems | publisher = [[Springer Science+Business Media|Springer]] | isbn=978-3-540-67596-9 | year=2001}}\n* Yokoo, M., and Hirayama, K. (2000). Algorithms for distributed constraint satisfaction: A review. Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems (pp.&nbsp;185–207). A survey.\n\n{{DEFAULTSORT:Distributed Constraint Optimization}}\n[[Category:Mathematical optimization]]\n[[Category:Constraint programming]]"
    },
    {
      "title": "Dual norm",
      "url": "https://en.wikipedia.org/wiki/Dual_norm",
      "text": "In [[functional analysis]], the '''dual norm''' is a measure of the \"size\" of each [[continuous function|continuous]] [[linear functional]] defined on a [[normed vector space]].\n\n== Definition ==\n\nLet <math>X</math> be a [[normed vector space]] with norm <math>|\\cdot |</math> and let <math>X^*</math> be the [[dual space]]. The '''dual norm''' of a continuous [[linear functional]] <math>f</math> belonging to <math>X^*</math> is defined to be the real number\n\n:<math>\\| f\\| := \\sup\\{| f(x)| : x \\in X, |x| \\leq 1\\}</math>\n\nwhere <math>\\sup</math> denotes the [[supremum]].<ref>{{harvnb|Rudin|1991|loc= p. 87}}</ref>\n\nThe map <math>f \\mapsto \\|f\\|</math> defines a [[normed vector space|norm]] on <math>X^*</math>. (See Theorems 1 and 2 below.)\n\nThe dual norm is a special case of the [[operator norm]] defined for each (bounded) linear map between normed vector spaces.\n\nThe topology on <math>X^*</math> [[normed vector space#Topological structure|induced by]] <math>|\\cdot |</math> turns out to be as strong as the [[Weak topology#The weak-.2A topology|weak-* topology]] on <math>X^*</math>.\n\nIf the [[ground field]] of <math>X</math> is [[complete metric space|complete]] then <math>X^*</math> is a [[Banach space#Linear operators, isomorphisms|Banach space]].\n\n== The double dual of a normed linear space ==\n\nThe [[double dual]] (or second dual) <math>X^{**}</math> of <math>X</math> is the dual of the normed vector space <math>X^*</math>. There is a natural map <math>\\varphi: X \\to X^{**}</math>. Indeed, for each <math>w^*</math> in <math>X^*</math> define\n\n: <math>\\varphi(v)(w^*): = w^*(v).</math>\n\nThe map <math>\\varphi</math> is [[linear map|linear]], [[injective]], and [[Isometry|distance preserving]].<ref>{{harvnb|Rudin|1991|loc=section 4.5, p. 95}}</ref> In particular, if <math>X</math> is complete (i.e. a Banach space), then <math>\\varphi</math> is an isometry onto a closed subspace of <math>X^{**}</math>.<ref>{{harvnb|Rudin|1991|loc=p. 95}}</ref>\n\nIn general, the map <math>\\varphi</math> is not surjective. For example, if <math>X</math> is the Banach space <math>L^{\\infty}</math> consisting of bounded functions on the real line with the supremum norm, then the map <math>\\varphi</math> is not surjective. (See [[Lp spaces|<math>L^p</math> space]]). If <math>\\varphi</math> is surjective, then <math>X</math> is said to be a [[reflexive Banach space]]. If <math>1 < p < \\infty,</math> then the [[Lp spaces|space <math>L^p</math>]] is a reflexive Banach space.\n\n== Mathematical Optimization ==\nLet <math>\\|\\cdot\\|</math> be a norm on <math>\\R^{n}.</math> The associated ''dual norm'', denoted <math>\\| \\cdot \\|_*,</math> is defined as\n\n:<math>\\|z\\|_* = \\sup\\{z^\\intercal x\\; |\\; \\|x\\| \\leq 1 \\}.</math>\n\n(This can be shown to be a norm.) The dual norm can be interpreted as the [[operator norm]] of <math>z^\\intercal</math>, interpreted as a <math>1 \\times n</math> matrix, with the norm <math>\\|\\cdot\\|</math> on <math>\\R^n</math>, and the absolute value on <math>\\R</math>:\n\n:<math>\\|z\\|_* = \\sup\\{|z^\\intercal x|\\; |\\; \\|x\\| \\leq 1 \\}.</math>\n\nFrom the definition of dual norm we have the inequality\n\n:<math>z^\\intercal x = \\| x \\| \\left (z^\\intercal \\frac{x}{\\|x \\|} \\right ) \\leq \\| x \\| \\| z \\| _*</math>\n\nwhich holds for all {{mvar|x}} and {{mvar|z}}.<ref>This inequality is tight, in the following sense: for any {{mvar|x}} there is a {{mvar|z}} for which the inequality holds with equality. (Similarly, for any {{mvar|z}} there is an {{mvar|x}} that gives equality.)</ref> The dual of the dual norm is the original norm: we have <math>\\| x \\|_{**} = \\| x \\| </math> for all {{mvar|x}}. (This need not hold in infinite-dimensional vector spaces.)\n\nThe dual of the [[Norm (mathematics)#Euclidean norm|Euclidean norm]] is the Euclidean norm, since\n\n:<math>\\sup\\{z^\\intercal x\\; |\\; \\| x \\| _2 \\leq 1 \\} = \\| z \\| _2.</math>\n\n(This follows from the [[Cauchy–Schwarz inequality]]; for nonzero {{mvar|z}}, the value of {{mvar|x}} that maximises <math>z^\\intercal x</math> over <math>\\| x \\| _2 \\leq 1</math> is <math>\\tfrac{z}{\\| z \\| _2}</math>.)\n\nThe dual of the <math>\\ell_1</math>-norm is the <math>\\ell_\\infty</math>-norm:\n\n:<math>\\sup\\{z^\\intercal x\\; |\\; \\| x \\| _\\infty \\leq 1\\} = \\sum_{i=1}^n |z_i| = \\| z \\| _1,</math>\n\nand the dual of the <math>\\ell_\\infty</math>-norm is the <math>\\ell_1</math>-norm.\n\nMore generally, [[Hölder's inequality]] shows that the dual of the [[Lp spaces|<math>\\ell_p</math>-norm]] is the <math>\\ell_q</math>-norm, where, {{mvar|q}} satisfies <math>\\tfrac{1}{p} + \\tfrac{1}{q} = 1</math>, i.e., <math>q = \\tfrac{p}{p-1}.</math>\n\nAs another example, consider the <math>\\ell_2</math>- or spectral norm on <math>\\R^{m\\times n}</math>. The associated dual norm is\n\n:<math>\\| Z \\| _{2*} = \\sup\\{\\mathrm{\\bf tr}(Z^\\intercal X) | \\| X \\| _2 \\leq 1 \\},</math>\n\nwhich turns out to be the sum of the singular values,\n\n:<math>\\| Z \\| _{2*} = \\sigma_1(Z) + \\cdots + \\sigma_r(Z) = \\mathrm{\\bf tr} (Z^\\intercal Z)^{\\frac{1}{2}},</math>\n\nwhere <math>r = \\mathrm{\\bf rank} Z.</math> This norm is sometimes called the [[nuclear operator|''nuclear'' norm]].<ref>{{harvnb|Boyd|Vandenberghe|2004|loc=[http://web.stanford.edu/~boyd/cvxbook/ p. 637]}}</ref>\n\n== Examples ==\n<!-- commenting out for now as this example seems to be redundant with the def'n provided in mathematical optimisation section.\n# '''Dual Norm of Vectors'''\n#:If ''p'', ''q'' ∈ <math>[1, \\infty]</math> satisfy <math>1/p+1/q=1</math>, then the ℓ<sup>''p''</sup> and ℓ<sup>''q''</sup> norms are dual to each other. \n#:In particular the [[L2 norm|Euclidean norm]] is self-dual ({{nowrap|1=''p'' = ''q'' = 2}}). Similarly, the [[Matrix_norm|Schatten ''p''-norm]] on matrices is dual to the Schatten ''q''-norm.\n#:For <math>\\sqrt{x^{\\mathrm{T}}Qx}</math>, the dual norm is <math>\\sqrt{y^{\\mathrm{T}}Q^{-1}y}</math> with <math>Q</math> positive definite. -->\n\n===Dual norm for matrices===\n{{main|Hilbert–Schmidt operator|Matrix norm#Frobenius norm}}\n\nThe [[Matrix norm#Frobenius norm|''Frobenius norm'']] defined by\n\n:<math>\\| A\\|_{\\text{F}} = \\sqrt{\\sum_{i=1}^m\\sum_{j=1}^n \\left| a_{ij} \\right|^2} = \\sqrt{\\operatorname{trace}(A^*A)} = \\sqrt{\\sum_{i=1}^{\\min\\{m,n\\}} \\sigma_{i}^2}</math>\n\nis self-dual, i.e., its dual norm is <math> \\| \\cdot \\|'_{\\text{F}} = \\| \\cdot \\|_{\\text{F}}.</math>\n\nThe ''spectral norm'', a special case of the [[Matrix norm#induced norm|''induced norm'']] when <math>p=2</math>, is defined by the maximum [[singular value decomposition#singular values, singular vectors, and their relation to the SVD|singular values]] of a matrix, i.e.,\n\n:<math>\\| A \\| _2 = \\sigma_{\\max}(A),</math>\n\nhas the nuclear norm as its dual norm, which is defined by \n\n:<math>\\|B\\|'_2 = \\sum_i \\sigma_i(B),</math> \n\nfor any matrix <math>B</math> where <math>\\sigma_i(B)</math> denote the singular values{{Citation needed|date=March 2018}}.\n\n== Some basic results about the operator norm==\n\nMore generally, let <math>X</math> and <math>Y</math> be topological vector spaces, and <math>L(X,Y)</math><ref>Each <math>L(X,Y)</math> is a [[vector space]], with the usual definitions of addition and scalar multiplication of functions; this only depends on the vector space structure of <math>Y</math>, not <math>X</math>.</ref> be the collection of all [[bounded operator|bounded linear mappings]] (or ''operators'') of <math>X</math> into <math>Y</math>. In the case where <math>X</math> and <math>Y</math> are normed vector spaces, <math>L(X,Y)</math> can be normed in a natural way.\n\n:'''Theorem 1.''' Let <math>X</math> and <math>Y</math> be normed spaces, and associate to each <math>f \\in L(X,Y)</math> the number:\n::<math>\\| f\\| = \\sup\\{ | f(x) | : x \\in X, \\| x \\| \\leq 1\\}.</math>\n:This turns <math>L(X,Y)</math> into a normed space. Moreover if <math>Y</math> is a Banach space, so is <math>L(X,Y)</math>.<ref>{{harvnb|Rudin|1991|page=92}}</ref>\n\n'''Proof.''' A subset of a normed space is bounded [[if and only if]] it lies in some multiple of the [[unit sphere]]; thus <math>\\| f \\| < \\infty</math> for every <math>f \\in L(X,Y)</math> if <math>\\alpha</math> is a scalar, then <math>(\\alpha f)(x) = \\alpha \\cdot fx</math> so that \n\n:<math>\\|\\alpha f\\| = |\\alpha|\\|f\\|</math>\n\nThe [[triangle inequality]] in <math>Y</math> shows that\n\n:<math>\\begin{align}\n\\| (f_1 + f_2)x \\| &= \\| f_1 x + f_2 x \\| \\\\\n&\\leq \\| f_1 x \\| + \\| f_2 x \\| \\\\\n&\\leq (\\|f_1\\| + \\|f_2\\|)\\|x\\| \\\\\n&\\leq \\|f_1\\| + \\|f_2\\|\n\\end{align}</math>\n\nfor every <math>x \\in X</math> with <math>\\|x\\| \\leq 1</math>. Thus\n\n:<math>\\| f_1 + f_2 \\| \\leq \\|f_1\\| + \\|f_2\\|</math>\n\nIf <math>f \\neq 0</math>, then <math>fx \\neq 0</math> for some <math>x \\in X</math>; hence <math>\\|f\\| > 0</math>. Thus, <math>L(X,Y)</math> is a normed space.<ref>{{harvnb|Rudin|1991|page=93}}</ref>\n\nAssume now that <math>Y</math> is complete, and that <math>\\{f_n\\}</math> is a [[Cauchy sequence]] in <math>L(X,Y)</math>. Since\n\n:<math>\\|f_n x - f_m x \\| \\leq \\| f_n - f_m \\|\\|x\\|</math>\n\nand it is assumed that <math>\\|f_n - f_m\\| \\to 0</math> as <math>n,m \\to\\infty</math>, <math>\\{f_nx\\}</math> is a Cauchy sequence in <math>Y</math> for every <math>x \\in X</math>. Hence\n\n:<math>fx = \\lim_{n\\to\\infty} f_n x</math>\n\nexists. It is clear that <math>f: X \\to Y</math> is linear. If <math>\\varepsilon > 0</math>, <math>\\| f_n - f_m \\|\\|x\\| \\leq \\varepsilon \\|x\\|</math> for sufficiently large {{mvar|n}} and {{mvar|m}}. It follows\n\n:<math>\\| fx - f_m x \\| \\leq \\varepsilon\\|x\\|</math>\n\nfor sufficiently large {{mvar|m}}. Hence <math>\\| fx\\| \\leq (\\|f_m\\| + \\varepsilon)\\|x\\|</math>, so that <math>f \\in L(X,Y)</math> and <math>\\| f - f_m \\| \\leq \\varepsilon</math>. Thus <math>f_m \\to f</math> in the norm of <math>L(X,Y)</math>. This establishes the completeness of <math>L(X,Y).</math><ref>{{harvnb|Rudin|1991|page=93}}</ref>\n\nWhen <math>Y</math> is a [[scalar field]] (i.e. <math>Y=\\C</math> or <math>Y=\\R</math>) so that <math>L(X,Y)</math> is the [[dual space]] <math>X^*</math> of <math>X</math>.\n\n:'''Theorem 2.''' Suppose <math>B</math> is the closed unit ball of normed space <math>X</math>. For every <math>x^* \\in X^*</math> define:\n::<math>\\|x^*\\| = \\sup\\{|\\langle{x,x^*}\\rangle|: x \\in B\\}</math>\n:Then\n::(a) This norm makes <math>X^*</math> into a Banach space.<ref>{{harvnb|Aliprantis|2005|page=230}}</ref>\n::(b) Let <math>B^*</math> be the closed unit ball of <math>X^*</math>. For every <math>x \\in X</math>,\n:::<math>\\|x\\| = \\sup \\{|\\langle{x,x^*}\\rangle|:x^* \\in B^*\\}.</math>\n::Consequently, <math>x^* \\to \\langle{x,x^*}\\rangle</math> is a bounded [[linear functional]] on <math>X^*</math> of norm <math>\\|x\\|</math>.\n::(c) <math>B^*</math> is weak*-compact.\n\n'''Proof.''' Since <math>L(X,Y) = X^*</math>, when <math>Y</math> is the [[scalar field]], (a) is a corollary of Theorem 1. Fix <math>x \\in X</math>. There exists<ref>{{harvnb|Rudin|1991|loc='''Theorem 3.3 Corollary''', p. 59}}</ref> <math>y^* \\in B^*</math> such that\n\n:<math>\\langle{x,y^*}\\rangle = \\|x\\|.</math>\n\nbut,\n\n:<math>|\\langle{x,x^*}\\rangle| \\leq \\|x\\|\\|x^*\\| \\leq \\|x\\|</math>\n\nfor every <math>x^* \\in B^*</math>. (b) follows from the above. Since the open unit ball <math>U</math> of <math>X</math> is dense in <math>B</math>, the definition of <math>\\|x^*\\|</math> shows that <math>x^* \\in B^*</math> [[if and only if]] <math>|\\langle{x,x^*}\\rangle| \\leq 1</math> for every <math>x \\in U</math>. The proof for (c)<ref>{{harvnb|Rudin|1991|loc='''Theorem 3.15 The [[Banach–Alaoglu theorem]] algorithm''', p. 68}}</ref> now follows directly.<ref>{{harvnb|Rudin|1991|page=94}}</ref>\n<!--The [[dual space|''topological dual'']] (or ''conjugate'') ''normed'' space <math>X'</math> is defined as the set of all continuous linear functionals from <math>X</math> into the base field <math>F</math>. Let {{mvar|X}} and {{mvar|X'}} be normed -->\n<!--If <math>f:X\\to F</math> is such a linear functional, then the ''dual norm''wrong ref <ref>{{harvtxt|A.N.Kolmogorov, S.V.Fomin|1957|loc=III §23}}</ref> <math>\\|\\cdot\\|'</math> of <math>f</math> is defined by-->\n<!--: <math>\\left\\| f \\right\\| ' = \\sup\\{ \\left| f(x) \\right| : x \\in X, \\left\\| x \\right\\| \\leq 1\\} = \\sup \\left\\{ \\frac{ \\left| f(x) \\right| }{ \\left\\| x \\right\\| }: x \\in X, x \\ne 0 \\right\\} .</math>-->\n\n== See also ==\n* [[convex conjugate]]\n* [[operator norm]]\n* [[Lp spaces]]\n* [[Hölder's inequality]]\n\n== Notes ==\n\n{{reflist}}\n\n== References ==\n* {{cite book|title=Infinite Dimensional Analysis: A Hitchhiker's Guide|first1=Charalambos D.|last1=Aliprantis|first2=Kim C.| last2= Border|publisher=Springer|year=2007|edition=3rd|isbn=9783540326960}}\n* {{cite book|last1=Boyd|first1=Stephen|author-link1=Stephen P. Boyd|last2=Vandenberghe|first2=Lieven|title=Convex Optimization |year= 2004|publisher=[[Cambridge University Press]]|isbn=9780521833783}}\n* {{cite book|last1 = Kolmogorov| first1 = A.N.| author-link1=Andrei Kolmogorov | last2 = Fomin | first2 = S.V. | author-link2=Sergei Fomin | year = 1957 | title = Elements of the Theory of Functions and Functional Analysis, Volume 1: Metric and Normed Spaces | publisher = Graylock Press | location = Rochester | isbn = }}\n* {{citation|authorlink=Walter Rudin|first=Walter|last=Rudin|title=Functional analysis|publisher=McGraw-Hill Science| year=1991 |isbn= 978-0-07-054236-5}}.\n\n==External links==\n* [http://www.seas.ucla.edu/~vandenbe/236C/lectures/proxop.pdf Notes on the proximal mapping by Lieven Vandenberge]\n\n{{Functional Analysis}}\n\n[[Category:Linear algebra]]\n[[Category:Functional analysis]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "ELECTRE",
      "url": "https://en.wikipedia.org/wiki/ELECTRE",
      "text": "{{one source|date=February 2019}}\n'''ELECTRE''' is a family of [[multi-criteria decision analysis]] methods that originated in [[Europe]] in the mid-1960s.  The [[acronym]] ELECTRE stands for: ELimination Et Choix Traduisant la REalité (ELimination and Choice Expressing REality).\n\nThe method was first proposed by [[Bernard Roy]] and his colleagues at [[Sema Group|SEMA]] consultancy company. A team at SEMA was working on the concrete, multiple criteria, real-world problem of how firms could decide on new activities and had encountered problems using a [[Weighted sum model|weighted sum technique]]. Bernard Roy was called in as a consultant and the group devised the ELECTRE method. As it was first applied in 1965, the ELECTRE method was to choose the best action(s) from a given set of actions, but it was soon applied to three main problems: choosing, ranking and sorting. The method became more widely known when a paper by B. Roy appeared in a French [[operations research]] journal.<ref>{{cite journal|title=Classement et choix en présence de points de vue multiples (la méthode ELECTRE) |journal=La Revue d'Informatique et de Recherche Opérationelle (RIRO)|year=1968|first=Bernard|last=Roy|volume=|issue=8|pages=57–75|id= |url=|format= }}</ref> It evolved into ELECTRE I (''electre one'') and the evolutions have continued with ELECTRE II, ELECTRE III, ELECTRE IV, ELECTRE IS and ELECTRE TRI (''electre tree''), to mention a few.<ref>{{cite book | last = Figueira | first = José | authorlink = |author2=Salvatore Greco |author3=Matthias Ehrgott  | title = Multiple Criteria Decision Analysis: State of the Art Surveys | publisher = Springer Science + Business Media, Inc. | year = 2005 | location = New York, | pages = | url = | doi = | id = | isbn = 0-387-23081-5 }}</ref> They are used in the fields of business, development,<ref>{{Cite journal | doi = 10.1590/S0101-74382009000300007| title = Decision theory with multiple criteria: An {{sic|nolink=y|aplication}} of ELECTRE IV and TODIM to SEBRAE/RJ| journal = Pesquisa Operacional| volume = 29| issue = 3| pages = 577| year = 2009| last1 = Rangel | first1 = L. S. A. D. | last2 = Gomes | first2 = L. F. V. A. M. | last3 = Moreira | first3 = R. R. A. }}</ref> design,<ref>{{Cite journal | doi = 10.1016/j.electacta.2006.01.055| title = A non-compensatory compromised solution for material selection of bipolar plates for polymer electrolyte membrane fuel cell (PEMFC) using ELECTRE IV| journal = Electrochimica Acta| volume = 51| issue = 25| pages = 5307| year = 2006| last1 = Shanian | first1 = A.| last2 = Savadogo | first2 = O.}}</ref> and small hydropower.<ref>{{Cite journal | doi = 10.1155/2015/548460| title = An Experimental Research Study on the Solution of a Private Small Hydropower Plant Investments Selection Problem by ELECTRE III/IV, Shannon's Entropy, and Saaty's Subjective Criteria Weighting| journal = Advances in Decision Sciences| volume = 2015| pages = 1| year = 2015| last1 = Saracoglu | first1 = B. O. }}</ref>\n\nBernard Roy is widely recognized as the father of the ELECTRE method, which was one of the earliest approaches in what is sometimes known as the French School of [[decision making]]. It is usually classified as an \"outranking method\" of decision making.\n\nThere are two main parts to an ELECTRE application: first, the construction of one or several outranking relations, which aims at comparing in a comprehensive way each pair of actions; second, an exploitation procedure that elaborates on the recommendations obtained in the first phase. The nature of the recommendation depends on the problem being addressed: choosing, ranking or sorting.\n\nUsually the Electre Methods are used to discard some alternatives to the problem, which are unacceptable.  After that we can use another MCDA to select the best one. The Advantage of using the Electre Methods before is that we can apply another MCDA with a restricted set of alternatives saving much time.\n\nCriteria in ELECTRE methods have two distinct sets of parameters: the importance [[coefficient]]s and the veto thresholds.\n\n==References==\n{{reflist}}\n\n== Online Tools ==\n1. [https://decision-radar.com/ Decision Radar] : A free online ELECTRE calculator written in [[Python (programming language)|Python]].\n\n[[Category:Decision analysis]]\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis| ]]"
    },
    {
      "title": "Energy minimization",
      "url": "https://en.wikipedia.org/wiki/Energy_minimization",
      "text": "{{about||the method in optimal control theory|Shape optimization|the general physical principle|Principle of minimum energy}}\n\nIn the field of [[computational chemistry]], '''energy minimization''' (also called '''energy optimization''', '''geometry minimization''', or '''geometry optimization''') is the process of finding an arrangement in space of a collection of atoms where, according to some computational model of chemical bonding, the net inter-atomic force on each atom is acceptably close to zero and the position on the [[potential energy surface]] (PES) is a stationary point (described later). The collection of atoms might be a single [[molecule]], an [[ion]], a [[condensed phase]], a [[transition state]] or even a collection of any of these. The computational model of chemical bonding might, for example, be quantum mechanics.\n\nAs an example, when optimizing the geometry of a [[Water (molecule)|water molecule]], one aims to obtain the hydrogen-oxygen bond lengths and the hydrogen-oxygen-hydrogen bond angle which minimize the forces that would otherwise be pulling atoms together or pushing them apart.\n\nThe motivation for performing a geometry optimization is the physical significance of the obtained structure: optimized structures often correspond to a substance as it is found in nature and the geometry of such a structure can be used in a variety of experimental and theoretical investigations in the fields of [[chemical structure]], [[thermodynamics]], [[chemical kinetics]], [[spectroscopy]] and others.\n\nTypically, but not always, the process seeks to find the geometry of a particular arrangement of the atoms that represents a local or global energy minimum. Instead of searching for global energy minimum, it might be desirable to optimize to a [[transition state]], that is, a saddle point on the potential energy surface.<ref>{{cite web|url=http://manual.cp2k.org/trunk/CP2K_INPUT/MOTION/GEO_OPT.html#desc_TYPE|title=Input reference of CP2K version trunk, Section GEO_OPT, Keyword TYPE|publisher=CP2K|accessdate=30 April 2015}}</ref> Additionally, certain coordinates (such as a chemical bond length) might be fixed during the optimization.\n\n== Molecular geometry and mathematical interpretation ==\n\nThe geometry of a set of atoms can be described by a vector of the atoms' positions. This could be the set of the Cartesian coordinates of the atoms or, when considering molecules, might be so called ''internal coordinates'' formed from a set of bond lengths, bond angles and dihedral angles.\n\nGiven a set of atoms and a vector, {{math| '''r'''}}, describing the atoms' positions, one can introduce the concept of the energy as a function of the positions, {{math| ''E''('''r''')}}. Geometry optimization is then a [[mathematical optimization]] problem, in which it is desired to find the value of {{math| '''r'''}} for which {{math| ''E''('''r''')}} is at a [[local minimum]], that is, the derivative of the energy with respect to the position of the atoms, {{math| &part;''E''/&part;'''r'''}}, is the zero vector and the second derivative matrix of the system, {{math| &part;&part;''E''/&part;''r''<sub>i</sub>&part;''r''<sub>j</sub>}}, also known as the [[Hessian matrix]], which describes the curvature of the PES at {{math| '''r'''}}, has all positive [[eigenvalues]] (is [[positive-definite matrix|positive definite]]).\n\nA special case of a geometry optimization is a search for the geometry of a [[transition state]]; this is discussed below.\n\nThe computational model that provides an approximate {{math| ''E''('''r''')}} could be based on [[Quantum chemistry|quantum mechanics]] (using either [[density functional theory]] or [[Semi-empirical quantum chemistry method|semi-empirical methods]]), [[Force field (chemistry)|force fields]], or a combination of those in case of [[QM/MM]]. Using this computational model and an initial guess (or [[ansatz]]) of the correct geometry, an iterative optimization procedure is followed, for example:\n\n# calculate the force on each atom (that is, {{math| -&part;''E''/&part;'''r'''}})\n# if the force is less than some threshold, '''finish'''\n# otherwise, move the atoms by some computed step {{math|∆'''r'''}} that is predicted to reduce the force\n# '''repeat '''from the start\n\n== Practical aspects of optimization ==\n\nAs described above, some method such as quantum mechanics can be used to calculate the energy, {{math| ''E''('''r''') }}, the gradient of the PES, that is, the derivative of the energy with respect to the position of the atoms, {{math| &part;''E''/&part;'''r'''}} and the second derivative matrix of the system, {{math| &part;&part;''E''/&part;''r''<sub>i</sub>&part;''r''<sub>j</sub>}}, also known as the [[Hessian matrix]], which describes the curvature of the PES at {{math| '''r'''}}.\n\nAn [[Optimization (mathematics)|optimization]] algorithm can use some or all of {{math| ''E''('''r''') }}, {{math| &part;''E''/&part;'''r'''}} and {{math| &part;&part;''E''/&part;''r''<sub>i</sub>&part;''r''<sub>j</sub>}} to try to minimize the forces and this could in theory be any method such as gradient descent, conjugate gradient or Newton's method, but in practice, algorithms which use knowledge of the PES curvature, that is the Hessian matrix, are found to be superior. For most systems of practical interest, however, it may be prohibitively expensive to compute the second derivative matrix, and it is estimated from successive values of the gradient, as is typical in a [[Quasi-Newton method|Quasi-Newton]] optimization.\n\nThe choice of the coordinate system can be crucial for performing a successful optimization. Cartesian coordinates, for example, are redundant since a non-linear molecule with {{math| ''N''}} atoms has {{math|3''N''–6}} vibrational [[Degrees of freedom (physics and chemistry)|degrees of freedom]] whereas the set of Cartesian coordinates has {{math|3''N''}} dimensions. Additionally, Cartesian coordinates are highly correlated, that is, the Hessian matrix has many non-diagonal terms that are not close to zero. This can lead to numerical problems in the optimization, because, for example, it is difficult to obtain a good approximation to the Hessian matrix and calculating it precisely is too computationally expensive. However, in case that energy is expressed with standard force fields, computationally efficient methods have been developed <ref>{{cite journal |last=Chatzieleftheriou |first=S. |last2=Adendorff |first2=M. R. |last3=Lagaros |first3=N. D.  |year=2016 |title=Generalized Potential Energy Finite Elements for Modeling Molecular Nanostructures|journal=J. Chem. Inf. Model. |volume=56 |issue=10 |pages=1963–1978 |doi=10.1021/acs.jcim.6b00356|pmid=27653992 }}</ref> able to derive analytically the Hessian matrix in Cartesian coordinates while preserving a computational complexity of the same order to that of gradient computations. Internal coordinates tend to be less correlated but are more difficult to set-up and it can be difficult to describe some systems, such as ones with symmetry or large condensed phases.<ref>{{cite journal |last=Peng|first=C. |last2=Ayala |first2=P. Y. |last3=Schlegel |first3=H. B. |year=1996 |title=Using Redundant Internal Coordinates to Optimize Equilibrium Geometries and Transition States|journal=Journal of Computational Chemistry |volume=17 |issue=1 |pages=49–56 |doi=10.1002/(sici)1096-987x(19960115)17:1<49::aid-jcc5>3.3.co;2-#}}</ref> Many modern computational chemistry software packages contain automatic procedures for the automatic generation of reasonable coordinate systems for optimization.<ref>http://www.gaussian.com</ref>\n\n=== Degree of freedom restriction ===\n\nSome degrees of freedom can be eliminated from an optimization, for example, positions of atoms or bond lengths and angles can be given fixed values. Sometimes these are referred to as being ''frozen'' degrees of freedom.\n\nFigure 1 depicts a geometry optimization of the atoms in a carbon nanotube in the presence of an external electrostatic field. In this optimization, the atoms on the left have their positions frozen. Their interaction with the other atoms in the system are still calculated, but alteration the atoms' position during the optimization is prevented.\n\n[[Image:Electric deflection CNT.JPG|thumb|700px|center|Figure 1: [[Electrostatic deflection (structural element)|Electrostatic deflection]]s of a [[carbon nanotube]] in an [[electric field]].\n]]\n\n== Transition state optimization ==\n\n[[Transition state]] structures can be determined by searching for [[saddle points]] on the PES of the chemical species of interest.<ref>{{Cite book|title=Introduction to Computational Chemistry|publisher= John Wiley and Sons Ltd|location= England|year=1999|author= Frank Jensen}}</ref> A first-order saddle point is a position on the PES corresponding to a minimum in all directions except one; a second-order saddle point is a minimum in all directions except two, and so on. Defined mathematically, an ''n''th order saddle point is characterized by the following:  {{math|1 = &part;''E''/&part;'''r''' = '''0'''}} and the Hessian matrix, {{math| &part;&part;''E''/&part;''r''<sub>i</sub>&part;''r''<sub>j</sub>}}, has exactly ''n'' negative eigenvalues.\n\nAlgorithms to locate transition state geometries fall into two main categories: local methods and semi-global methods. Local methods are suitable when the starting point for the optimization is very close to the true transition state (''very close'' will be defined shortly) and semi-global methods find application when it is sought to locate the transition state with very little ''a priori'' knowledge of its geometry. Some methods, such as the Dimer method (see below), fall into both categories.\n\n=== Local searches ===\nA so-called local optimization requires an initial guess of the transition state that is very close to the true transition state. ''Very close'' typically means that the initial guess must have a  corresponding Hessian matrix with one negative eigenvalue, or, the negative eigenvalue corresponding to the reaction coordinate must be greater in magnitude than the other negative eigenvalues. Further, the eigenvector with the most negative eigenvalue must correspond to the reaction coordinate, that is, it must represent the geometric transformation relating to the process whose transition state is sought.\n\nGiven the above pre-requisites, a local optimization algorithm can then move \"uphill\" along the eigenvector with the most negative eigenvalue and \"downhill\" along all other degrees of freedom, using something similar to a quasi-Newton method.\n\n=== Dimer method ===\nThe dimer method<ref>{{cite journal|title=A dimer method for finding saddle points on high dimensional potential surfaces using only first derivatives|journal= J. Chem. Phys. |volume=111 |year=1999| pages=7010–7022|author1=Graeme Henkelman |author2=Hannes Jónsson |doi=10.1063/1.480097|issue=15|bibcode = 1999JChPh.111.7010H }}\n</ref> can be used to find possible transition states without knowledge of the final structure or to refine a good guess of a transition structure. The “dimer” is formed by two images very close to each other on the PES. The method works by moving the dimer uphill from the starting position whilst rotating the dimer to find the direction of lowest curvature (ultimately negative).\n\n=== Activation Relaxation Technique (ART) ===\n\nThe Activation Relaxation Technique (ART)<ref>{{cite journal|title=Event-Based Relaxation of Continuous Disordered Systems|journal= Phys. Rev. Lett. |volume=77 |year=1996| pages=4358–4361|author1=G.T. Barkema |author2=Normand Mousseau |doi=10.1103/PhysRevLett.77.4358|issue=21|arxiv = cond-mat/9607156 |bibcode = 1996PhRvL..77.4358B |pmid=10062518}}</ref><ref>{{cite journal|title=Optimized energy landscape exploration using the ab initio based activation-relaxation technique.|journal= J Chem Phys|volume=135 |year=2011| pages=7723–7728|author1=Rachid Malek |author2=Normand Mousseau |doi=10.1103/PhysRevE.62.7723|issue=6|arxiv = cond-mat/0006042 |bibcode = 2000PhRvE..62.7723M }}</ref><ref>{{cite journal|title=Optimized energy landscape exploration using the ab initio based activation-relaxation technique|journal= J. Chem. Phys. |volume=62 |year=2011| pages=034102–034112|author1=Eduardo Machado-Charry |author2=Laurent Karim Béland |author3=Damien Caliste |author4=Luigi Genovese |author5=Thierry Deutsch |author6=Normand Mousseau |author7=Pascal Pochet |doi=10.1063/1.3609924|pmid= 21786982 |issue=3|bibcode = 2011JChPh.135c4102M }}\n</ref> is also an open-ended method to find new transition states or to refine known saddle points on the PES. The method follows the direction of lowest negative curvature (computed using the [[Lanczos algorithm]]) on the PES to reach the saddle point, relaxing in the perpendicular hyperplane between each \"jump\" (activation) in this direction.\n\n=== Chain-of-state methods ===\nChain-of-state<ref>Jensen, F. Introduction to Computational Chemistry; Wiley: 2 ed.; 2006</ref> methods can be used to find the ''approximate'' geometry of the transition state based on the geometries of the reactant and product. The generated approximate geometry can then serve as a starting point for refinement via a local search, which was described above.\n\nChain-of-state methods use a series of vectors, that is points on the PES, connecting the reactant and product of the reaction of interest, {{math| '''r'''<sub>reactant</sub>}} and {{math| '''r'''<sub>product</sub>}}, thus discretizing the reaction pathway. Very commonly, these points are referred to as ''beads ''due to an analogy of a set of beads connected by strings or springs, which connect the reactant and products. The series of beads is often initially created by interpolating between {{math| '''r'''<sub>reactant</sub>}} and {{math| '''r'''<sub>product</sub>}}, for example, for a series of {{math|''N'' + 1}} beads, bead {{math|''i''}} might be given by\n\n<math>\\mathbf{r}_i = \\frac{i}{N}\\mathbf{r}_\\mathrm{product} + \\left(1 - \\frac{i}{N} \\right)\\mathbf{r}_\\mathrm{reactant}</math>\n\nwhere {{math|''i'' &isin; 0, 1, ..., ''N''}}. Each of the beads {{math|'''r'''<sub>''i''</sub>}} has an energy, {{math| ''E''('''r'''<sub>''i''</sub>)}}, and forces, {{math|-&part;''E''/&part;'''r'''<sub>''i''</sub>}} and these are treated with a constrained optimization process that seeks to get an as accurate as possible representation of the reaction pathway. For this to be achieved, spacing constraints must be applied so that each bead {{math|'''r'''<sub>''i''</sub>}} does not simply get optimized to the reactant and product geometry.\n\nOften this constraint is achieved by [[Vector projection|projecting]] out components of the force on each bead {{math|'''r'''<sub>''i''</sub>}}, or alternatively the movement of each bead during optimization, that are tangential to the reaction path. For example, if for convenience, it is defined that {{math|1 = '''g'''<sub>''i''</sub> = &part;''E''/&part;'''r'''<sub>''i''</sub>}}, then the energy gradient at each bead minus the component of the energy gradient that is tangential to the reaction pathway is given by\n\n<math>\\mathbf{g}_i^\\perp = \\mathbf{g}_i - \\mathbf{\\tau}_i(\\mathbf{\\tau}_i\\cdot\\mathbf{g}_i) = \\left( I - \\mathbf{\\tau}_i \\mathbf{\\tau}_i^T \\right)\\mathbf{g}_i</math>\n\nwhere {{math|''I''}} is the identity matrix and {{math|'''τ'''<sub>''i''</sub>}} is a unit vector representing the reaction path tangent at {{math|'''r'''<sub>''i''</sub>}}. By projecting out components of the energy gradient  or the optimization step that are parallel to the reaction path, an optimization algorithm significantly reduces the tendency of each of the beads to be optimized directly to a minimum.\n\n==== Synchronous transit ====\nThe simplest chain-of-state method is the linear synchronous transit (LST) method. It operates by taking interpolated points between the reactant and product geometries and choosing the one with the highest energy for subsequent refinement via a local search. The quadratic synchronous transit (QST) method extends LST by allowing a parabolic reaction path, with optimization of the highest energy point orthogonally to the parabola.\n\n==== Nudged elastic band ====\nIn Nudged elastic band<ref>(a) G. Mills and H. Jónsson, Phys. Rev. Lett. 72, 1124 (1994) (b) Graeme Henkelman and Hannes Jónsson, Improved tangent estimate in the nudged elastic band method for finding minimum energy paths and saddle points, J. Chem. Phys. 113, 9978 - 9985 (2000)</ref> method, the beads along the reaction pathway have simulated spring forces in addition to the chemical forces, {{math|-&part;''E''/&part;'''r'''<sub>''i''</sub>}}, to cause the optimizer to maintain the spacing constraint. Specifically, the force {{math|'''f'''<sub>''i''</sub>}} on each point ''i'' is given by\n\n<math>\\mathbf{f}_i = \\mathbf{f}_i^{\\parallel} -\\mathbf{g}_i^{\\perp}</math>\n\nwhere\n\n<math>\\mathbf{f}_i^{\\parallel} = k\\left[\\left( \\left(\\mathbf{r}_{i+1} - \\mathbf{r}_i\\right) - \\left(\\mathbf{r}_i - \\mathbf{r}_{i-1}\\right)\\right)\\cdot\\tau_i \\right] \\tau_i</math>\n\nis the spring force parallel to the pathway at each point {{math|'''r'''<sub>''i''</sub>}} (''k'' is a spring constant and {{math|τ<sub>''i''</sub>}}, as before, is a unit vector representing the reaction path tangent at {{math|'''r'''<sub>''i''</sub>}}).\n\nIn a traditional implementation, the point with the highest energy is used for subsequent refinement in a local search.There are many variations on the NEB (nudged elastic band) method,<ref>{{cite web |url=http://theory.cm.utexas.edu/vtsttools/neb/ |title=Nudged Elastic Band |work=UT Austin |deadurl=yes |archiveurl=https://web.archive.org/web/20140203094132/http://theory.cm.utexas.edu/vtsttools/neb/ |archivedate=2014-02-03 |df= }}</ref> such including the climbing image NEB, in which the point with the highest energy is pushed upwards during the optimization procedure so as to (hopefully) give a geometry which is even closer to that of the transition state.\n\n==== String method ====\nThe string method<ref>{{cite web|url=http://www.math.princeton.edu/string/index.html|title=Rare Events, Transition Pathways and Reaction Rates}} and {{Cite web|url = http://cims.nyu.edu/~eve2/string.htm |title = The string method page}}</ref><ref>{{cite journal|title=String method for the study of rare Events|author= Weinan E, Weiqing Ren, [[Eric Vanden-Eijnden]]|journal=Phys. Rev. B|volume= 66|pages=052301 |year=2002|doi=10.1103/PhysRevB.66.052301|issue=5|arxiv = cond-mat/0205527 |bibcode = 2002PhRvB..66e2301E }}</ref><ref>{{Cite  arXiv | title= Modified string method for finding minimum energy path|author1=Amit Samanta |author2=Weinan E |eprint=1009.5612}}</ref> uses splines connecting the points, {{math|'''r'''<sub>''i''</sub>}}, to measure and enforce distance constraints between the points and to calculate the tangent at each point. In each step of an optimization procedure, the points might be moved according to the force acting on them perpendicular to the path, and then, if the equidistance constraint between the points is no-longer satisfied, the points can be redistributed, using the spline representation of the path to generate new vectors with the required spacing.\n\nVariations on the string method include the growing string method,<ref>{{cite journal|title=A growing string method for determining transition states: Comparison to the nudged elastic band and string methods|journal= J. Chem. Phys.|volume= 120 |year=2004|pages=7877–7886|author1=Baron Peters |author2=Andreas Heyden |author3=Alexis T. Bell |author4=Arup Chakraborty |doi=10.1063/1.1691018|pmid=15267702|issue=17|bibcode = 2004JChPh.120.7877P }}</ref> in which the guess of the pathway is grown in from the end points (that is the reactant and products) as the optimization progresses.\n\n== Comparison with other techniques ==\n\nGeometry optimization is fundamentally different from a [[molecular dynamics]] simulation. The latter simulates the motion of molecules with respect to time, subject to temperature, chemical forces, initial velocities, [[Brownian motion]] of a solvent, and so on, via the application of [[Newton's laws of motion|Newton's laws of Motion]]. This means that the trajectories of the atoms which get computed, have some physical meaning. Geometry optimization, by contrast, does not produce a \"trajectory\" with any physical meaning – it is concerned with minimization of the forces acting on each atom in a collection of atoms, and the pathway via which it achieves this lacks meaning. Different optimization algorithms could give the same result for the minimum energy structure, but arrive at it via a different pathway.\n\n==See also==\n* [[Constraint Composite Graph]]\n* [[Graph cuts in computer vision]] – apparatus for solving [[computer vision]] problems that can be formulated in terms of energy minimization\n* [[Energy principles in structural mechanics]]\n\n==References==\n{{reflist|2}}\n\n==External links==\n* [http://www.nrbook.com/a/bookfpdf.php Numerical Recipes in Fortran 77]\n\n==Additional references==\n* Payne et al.<!-- \"et al\" should be used only when a list of all authors appears somewhere -->, \"Iterative minimization techniques for ab initio total-energy calculations: Molecular dynamics and conjugate gradients\", ''Reviews of Modern Physics'' 64 (4), pp.&nbsp;1045&ndash;1097. (1992) [https://dx.doi.org/10.1103/RevModPhys.64.1045 (abstract)]  \n* Stich et al., \"[https://journals.aps.org/prb/abstract/10.1103/PhysRevB.39.4997 Conjugate gradient minimization of the energy functional: A new method for electronic structure calculation]\", ''Physical Review B'' 39 (8), pp.&nbsp;4997&ndash;5004, (1989)\n* Chadi, \"[https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.41.1062 Energy-minimization approach to the atomic geometry of semiconductor surfaces]\", ''Physical Review Letters'' 41 (15), pp.&nbsp;1062&ndash;1065 (1978)\n\n[[Category:Mathematical optimization]]\n[[Category:Computational chemistry]]"
    },
    {
      "title": "Energy modeling",
      "url": "https://en.wikipedia.org/wiki/Energy_modeling",
      "text": "{{about|modeling energy systems|the simulation of energy use in buildings|building energy simulation}}\n\n{{use dmy dates|date=August 2016}}\n{{use American English|date=May 2016}}\n\n'''Energy modeling''' or '''energy system modeling''' is the process of building computer models of [[energy system]]s in order to analyze them.  Such models often employ [[scenario analysis]] to investigate different assumptions about the technical and economic conditions at play.  Outputs may include the system feasibility, [[greenhouse gas]] emissions, cumulative [[Cost|financial costs]], [[natural resource]] use, and [[Efficient energy use|energy efficiency]] of the system under investigation.  A wide range of techniques are employed, ranging from broadly economic to broadly engineering.  [[Mathematical optimization]] is often used to determine the least-cost in some sense.  Models can be international, regional, national, municipal, or stand-alone in scope.  Governments maintain national energy models for [[energy policy]] development.\n\nEnergy models are usually intended to contribute variously to system operations, [[Engineering design process|engineering design]], or [[energy policy]] development.  This page concentrates on policy models.  Individual [[building energy simulation]]s are explicitly excluded, although they too are sometimes called energy models.  [[Intergovernmental Panel on Climate Change|IPCC]]-style [[integrated model]]s, which also contain a representation of the world energy system and are used to examine global transformation pathways through to 2050 or 2100 are not considered here in detail.\n\nEnergy modeling has increased in importance as the need for [[climate change mitigation]] has grown in importance.  The energy supply sector is the largest contributor to global [[greenhouse gas]] emissions.<ref name=\"bruckner-etal-2014\">\n{{cite book\n | first1 = Thomas | last1 = Bruckner\n | first2 = Igor Alexeyevic | last2 = Bashmakov\n | first3 = Yacob | last3 = Mulugetta\n | display-authors = etal\n | editor = IPCC\n | date = 2014\n | title = Climate change 2014: mitigation of climate change. Contribution of Working Group III to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change\n | chapter = Chapter 7: Energy systems\n | publisher = [[Cambridge University Press]]\n | location = Cambridge, United Kingdom and New York, NY, USA\n | pages = 511–597\n | isbn = 978-1-107-65481-5\n | chapter-url = http://www.ipcc.ch/pdf/assessment-report/ar5/wg3/ipcc_wg3_ar5_full.pdf\n | access-date = 2016-05-09\n}}\n</ref>  The [[IPCC Fifth Assessment Report|IPCC reports]] that climate change mitigation will require a fundamental transformation of the energy supply system, including the substitution of unabated (not captured by [[Carbon capture and storage|CCS]]) [[fossil fuel]] conversion technologies by low-GHG alternatives.<ref name=\"bruckner-etal-2014\"/>\n\n== Model types ==\n\nA wide variety of model types are in use.  This section attempts to categorize the key types and their usage.  The divisions provided are not hard and fast and mixed-paradigm models exist.  In addition, the results from more general models can be used to inform the specification of more detailed models, and vice versa, thereby creating a [[hierarchy]] of models.  Models may, in general, need to capture \"complex dynamics such as:\n* energy system operation\n* technology stock turnover\n* technology innovation\n* firm and household behaviour\n* energy and non-energy capital investment and labour market adjustment dynamics leading to economic restructuring\n* infrastructure deployment and urban planning\"<ref name=\"pye-and-bataille-2016\">\n{{cite journal\n | first1 = Steve | last1 = Pye\n | first2 = Chris | last2 = Bataille\n | title = Improving deep decarbonization modelling capacity for developed and developing country contexts\n | date = 2016\n | journal = Climate Policy\n | volume = 16\n | number = S1\n | pages = S27–S46\n | doi = 10.1080/14693062.2016.1173004\n}}\n</ref>{{rp|S28–S29}}{{nbsp}}{{rp|at=point form added}}\n\nModels may be limited in scope to the electricity sector or they may attempt to cover an energy system in its entirety (see below).\n\nMost energy models are used for [[scenario analysis]].  A scenario is a coherent set of assumptions about a possible system.  New scenarios are tested against a baseline scenario – normally [[Business as usual (business)|business-as-usual]] (BAU) – and the differences in outcome noted.\n\nThe [[time horizon]] of the model is an important consideration.  Single-year models – set in either the present or the future (say 2050) – assume a non-evolving [[Capital (economics)|capital]] structure and focus instead on the operational dynamics of the system.  Single-year models normally embed considerable temporal (typically hourly resolution) and technical detail (such as individual generation plant and transmissions lines).  Long-range models – cast over one or more decades (from the present until say 2050) – attempt to encapsulate the structural evolution of the system and are used to investigate capacity expansion and energy system transition issues.\n\nModels often use [[mathematical optimization]] to solve for redundancy in the specification of the system.  Some of the techniques used derive from [[operations research]].   Most rely on [[linear programming]] (including [[Linear programming#Integer unknowns|mixed-integer programming]]), although some use [[nonlinear programming]].  Solvers may use classical or [[Genetic programming|genetic optimisation]], such as [[CMA-ES]].  Models may be recursive-dynamic, solving sequentially for each time interval, and thus evolving through time.  Or they may be framed as a single forward-looking intertemporal problem, and thereby assume perfect foresight.  Single-year engineering-based models usually attempt to minimize the [[Long run and short run|short-run]] financial cost, while single-year market-based models use optimization to determine [[market clearing]].  Long-range models, usually spanning decades, attempt to minimize both the short and long-run costs as a single intertemporal problem.\n\nThe demand-side (or end-user domain) has historically received relatively scant attention, often modeled by just a simple [[demand curve]].  End-user energy demand curves, in the short-run at least, are normally found to be highly [[Elasticity (economics)|inelastic]].\n\nAs [[intermittent energy source]]s and [[energy demand management]] grow in importance, models have needed to adopt an hourly temporal resolution in order to better capture their real-time dynamics.<ref name=\"acatech-etal-2016b\">\n{{cite book\n | editor1 = acatech\n | editor2 = Lepoldina\n | editor3 = Akademienunion\n | date = 2016\n | title = Flexibility concepts for the German power supply in 2050: ensuring stability in the age of renewable energies\n | publisher = acatech – National Academy of Science and Engineering\n | place = Berlin, Germany\n | isbn = 978-3-8047-3549-1\n | url = http://www.acatech.de/fileadmin/user_upload/Baumstruktur_nach_Website/Acatech/root/de/Publikationen/Kooperationspublikationen/ESYS_Position_Paper_Flexibility_concepts.pdf\n | access-date = 2016-12-19\n}}\n</ref><ref name=\"lunz-etal-2016\">\n{{cite journal\n | last1 = Lunz | first1 = Benedikt\n | last2 = Stöcker | first2 = Philipp\n | last3 = Eckstein | first3 = Sascha\n | last4 = Nebel | first4 = Arjuna\n | last5 = Samadi | first5 = Sascha\n | last6 = Erlach | first6 = Berit\n | last7 = Fischedick | first7 = Manfred\n | last8 = Elsner | first8 = Peter\n | last9 = Sauer | first9 = Dirk Uwe\n | title = Scenario-based comparative assessment of potential future electricity systems – A new methodological approach using Germany in 2050 as an example\n | date = 2016\n | journal = Applied Energy\n | volume = 171\n | pages = 555–580\n | doi = 10.1016/j.apenergy.2016.03.087\n}}\n</ref>  Long-range models are often limited to calculations at yearly intervals, based on typical day profiles, and are hence less suited to systems with significant [[variable renewable energy]]. Day-ahead dispatching optimization is used to aid in the planning of systems with a significant portion of intermittent energy production in which uncertainty around future energy predictions is accounted for using stochastic optimization.<ref name=\"Rachunok 1–6\">{{Cite journal|last=Rachunok|first=Benjamin|last2=Staid|first2=Andrea|last3=Watson|first3=Jean-Paul|last4=Woodruff|first4=David L.|last5=Yang|first5=Dominic|date=June 2018|title=Stochastic Unit Commitment Performance Considering Monte Carlo Wind Power Scenarios|url=https://ieeexplore.ieee.org/document/8440563/|journal=2018 IEEE International Conference on Probabilistic Methods Applied to Power Systems (PMAPS)|location=Boise, ID|publisher=IEEE|pages=1–6|doi=10.1109/PMAPS.2018.8440563|isbn=9781538635964}}</ref>\n\nImplementing [[Programming language|languages]] include [[General Algebraic Modeling System|GAMS]], [[MathProg]], [[MATLAB]], [[Mathematica]], [[Python (programming language)|Python]], [[Pyomo]], [[R (programming language)|R]], [[Fortran]], [[Java (programming language)|Java]], [[C (programming language)|C]], [[C++]], and [[Vensim]].  Occasionally [[spreadsheet]]s are used.\n\nAs noted, [[Intergovernmental Panel on Climate Change|IPCC]]-style [[integrated model]]s (also known as integrated assessment models or IAM) are not considered here in any detail.<ref name=\"clarke-etal-2014\">\n{{cite book\n | first1 = Leon | last1 = Clarke\n | first2 = Kejun | last2 = Jiang\n | display-authors = etal\n | editor = IPCC\n | date = 2014\n | title = Climate change 2014: mitigation of climate change. Contribution of Working Group III to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change\n | chapter = Chapter 6: Assessing transformation pathways\n | publisher = [[Cambridge University Press]]\n | place = Cambridge, United Kingdom and New York, NY, USA\n | isbn = 978-1-107-65481-5\n | chapter-url = http://www.ipcc.ch/pdf/assessment-report/ar5/wg3/ipcc_wg3_ar5_full.pdf\n | access-date = 2016-05-09\n}}\n</ref><ref name=\"kelly-and-kolstad-1998\">\n{{cite book\n | first1 = David L | last1 = Kelly\n | first2 = Charles D | last2 = Kolstad\n | title = Integrated assessment models for climate change control\n | date = 1998\n | url = http://aida.econ.yale.edu/~nordhaus/homepage/documents/Kelly-Kolstad_IAM.pdf\n | access-date = 2016-05-09\n}}\n</ref>  Integrated models combine simplified sub-models of the [[world economy]], agriculture and [[Land use|land-use]], and the global [[climate]] system in addition to the world energy system.  Examples include GCAM,<ref name=\"riahi-etal-2012\">\n{{cite book\n | last1 = Riahi | first1 = Keywan\n | last2 = Dentener | first2 = Frank\n | last3 = Gielen | first3 = Dolf\n | last4 = Grubler | first4 = Arnulf\n | last5 = Jewell | first5 = Jessica\n | last6 = Klimont | first6 = Zbigniew\n | last7 = Krey | first7 = Volker\n | last8 = McCollum | first8 = David\n | last9 = Pachauri | first9 = Shonali\n | last10 = Rao | first10 = Shilpa\n | last11 = Ruijven | first11 = Bas van \n | last12 = Vuuren | first12 = Detlef P van\n | last13 = Wilson | first13 = Charlie\n | chapter = Chapter 17: Energy pathways for sustainable development\n | title = Global energy assessment: toward a sustainable future\n | date = 2012\n | pages = 1203–1306\n | editor-first1 = L | editor-last1 = Gomez-Echeverri\n | editor-first2 = TB | editor-last2 = Johansson\n | editor-first3 = N | editor-last3 = Nakicenovic\n | editor-first4 = A | editor-last4 = Patwardhan\n | publisher = [[International Institute for Applied Systems Analysis]] and [[Cambridge University Press]]\n | place = Laxenburg, Austria, Cambridge, UK, and New York, NY, USA\n | citeseerx = 10.1.1.434.4160\n }}\n</ref> MESSAGE, and REMIND.<ref name=\"bauer-etal-2016\">\n{{cite journal\n | last1 = Bauer | first1 = Nico\n | last2 = Mouratiadou | first2 = Ioanna\n | last3 = Luderer | first3 = Gunnar\n | last4 = Baumstark | first4 = Lavinia\n | last5 = Brecha | first5 = Robert J\n | last6 = Edenhofer | first6 = Ottmar\n | last7 = Kriegler | first7 = Elmar\n | title = Global fossil energy markets and climate change mitigation – an analysis with REMIND\n | journal = [[Climatic Change]]\n | date = 2016\n | volume = 136\n | number = 1\n | pages = 69–82\n | doi = 10.1007/s10584-013-0901-6\n | url = https://www.pik-potsdam.de/research/climate-impacts-and-vulnerabilities/projects/project-pages/world-bank-report/publications/rose-bauer-fossil-markets-cc14.pdf\n | access-date = 2016-05-10\n}}\n</ref>\n\nPublished surveys on energy system modeling have focused on techniques,<ref name=\"bahn-etal-2005\">\n{{cite book\n | first1 = O | last1 = Bahn\n | first2 = A | last2 = Haurie\n | first3 = DS | last3 = Zachary\n | title = Encyclopedia of Life Support Systems (EOLSS) \n | date = May 2005\n | chapter = Mathematical modeling and simulation methods in energy systems\n | publisher = EOLSS Publishers\n | location = Oxford, UK\n | issn = 0711-2440\n | chapter-url = http://www.eolss.net/sample-chapters/c02/e6-03b-03-06.pdf\n | access-date = 2016-10-25\n}}\n</ref> general classification,<ref name=\"van-beeck-1999\">\n{{cite book\n | last1 = Van Beeck | first1 = Nicole MJP\n | title = Classification of energy models — FEW Research Memorandum — Vol 777\n | date = August 1999\n | publisher = Tilburg University, Faculty of Economics and Business Administration\n | location = Tilburg, Netherlands\n | url = https://pure.uvt.nl/portal/files/532108/777.pdf\n | access-date = 2016-10-25\n}}\n</ref> an overview,<ref name=\"bhattacharyya-and-timilsina-2010\">\n{{cite journal\n | last1 = Bhattacharyya | first1 = Subhes C\n | last2 = Timilsina | first2 = Govinda R\n | title = A review of energy system models\n | date = 23 November 2010\n | journal = International Journal of Energy Sector Management\n | volume = 4\n | issue = 4\n | pages = 494–518\n | doi = 10.1108/17506221011092742\n | issn = 1750-6220\n | url = http://www.ewp.rpi.edu/hartford/~ernesto/S2013/MMEES/Papers/ENERGY/1EnergySystemsModeling/Bhattacharyya2010-ReviewEnergySystemModels.pdf\n | access-date = 2016-12-13\n}}\n</ref> decentralized planning,<ref name=\"hiremath-etal-2007\">\n{{cite journal\n | last1 = Hiremath | first1 = RB\n | last2 = Shikha | first2 = S\n | last3 = Ravindranath | first3 = NH\n | date = 2007\n | title = Decentralized energy planning: modeling and application — a review\n | journal = Renewable and Sustainable Energy Reviews\n | volume = 11\n | issue = 5\n | pages = 729–752\n | doi = 10.1016/j.rser.2005.07.005\n}}\n</ref> modeling methods,<ref name=\"jebaraj-and-iniyan-2006\">\n{{cite journal\n | last1 = Jebaraj | first1 = S\n | last2 = Iniyan | first2 = S\n | date = August 2006\n | title = A review of energy models\n | journal = Renewable and Sustainable Energy Reviews\n | volume = 10\n | issue = 4\n | pages = 281–311\n | doi = 10.1016/j.rser.2004.09.004\n | url = http://aoatools.aua.gr/pilotec/files/bibliography/renew_models-1547752705/renew_models.pdf\n | accessdate = 2013-03-02\n}}\n</ref> renewables integration,<ref name=\"Rachunok 1–6\"/><ref name=\"connolly-etal-2010\">\n{{cite journal\n | last1 = Connolly | first1 = David\n | last2 = Lund | first2 = Henrik\n | last3 = Mathiesen | first3 = Brian Vad\n | last4 = Leahy | first4 = Marti\n | date = 2010\n | title = A review of computer tools for analysing the integration of renewable energy into various energy systems\n | journal = Applied Energy\n | volume = 87\n | issue = 4\n | pages = 1059–1082\n | doi = 10.1016/j.apenergy.2009.09.026\n}}\n</ref> energy efficiency policies,<ref name=\"mundaca-etal-2010a\">\n<!-- document listing: http://www.osti.gov/scitech/biblio/1001644 -->\n{{cite journal\n | last1 = Mundaca | first1 = Luis\n | last2 = Neij | first2 = Lena\n | last3 = Worrell | first3 = Ernst\n | last4 = McNeil | first4 = Michael A\n | title = Evaluating energy efficiency policies with energy-economy models — Report number LBNL-3862E\n | journal = Annual Review of Environment and Resources\n | volume = 35\n | pages = 305–344\n | date = 1 August 2010\n | osti = 1001644\n | doi = 10.1146/annurev-environ-052810-164840\n | url = http://www.osti.gov/scitech/servlets/purl/1001644\n | access-date = 2016-11-04\n}}\n</ref><ref name=\"mundaca-etal-2010b\">\n{{cite journal\n | last1 = Mundaca | first1 = Luis\n | last2 = Neij | first2 = Lena\n | last3 = Worrell | first3 = Ernst\n | last4 = McNeil | first4 = Michael A\n | title = Evaluating energy efficiency policies with energy-economy models\n | date = 2010\n | journal = Annual Review of Environment and Resources\n | volume = 35\n | issue = 1\n | pages = 305–344\n | issn = 1543-5938\n | doi = 10.1146/annurev-environ-052810-164840\n}}\n</ref> electric vehicle integration,<ref name=\"mahmud-and-town-2016\">\n{{cite journal\n | last1 = Mahmud | first1 = Khizir\n | last2 = Town | first2 = Graham E\n | title = A review of computer tools for modeling electric vehicle energy requirements and their impact on power distribution networks\n | date = 15 June 2016\n | journal = Applied Energy\n | volume = 172\n | pages = 337–359\n | doi = 10.1016/j.apenergy.2016.03.100\n}}\n</ref> [[international development]],<ref name=\"van-ruijven-etal-2008\">\n{{cite journal\n | last1 = van Ruijven | first1 = Bas\n | last2 = Urban | first2 = Frauke\n | last3 = Benders | first3 = René MJ\n | last4 = Moll | first4 = Henri C\n | last5 = van der Sluijs | first5 = Jeroen P\n | last6 = de Vries | first6 = Bert\n | last7 = van Vuuren | first7 = Detlef P\n | title = Modeling energy and development: an evaluation of models and concepts\n | date = December 2008\n | journal = World Development\n | volume = 36\n | issue = 12\n | pages = 2801–2821\n | doi = 10.1016/j.worlddev.2008.01.011\n | issn = 0305-750X\n | url = http://dspace.library.uu.nl/bitstream/handle/1874/32954/NWS-E-2008-55.pdf\n | access-date = 2016-10-25\n}}\n</ref> and the use of layered models to support [[Climate change|climate protection]] policy.<ref name=\"unger-etal-2010\">\n<!-- dead URL: http://www.nordicenergyperspectives.org/modellrapport.pdf -->\n{{cite book\n | last1 = Unger | first1 = Thomas\n | last2 = Springfeldt | first2 = Per Erik\n | last3 = Tennbakk | first3 = Berit\n | last4 = Ravn | first4 = Hans\n | last5 = Havskjold | first5 = Monica\n | last6 = Niemi | first6 = Janne\n | last7 = Koljonen | first7 = Tiina\n | last8 = Fritz | first8 = Peter\n | last9 = Koreneff | first9 = Göran\n | last10 = Rydén | first10 = Bo\n | last11 = Lehtilä | first11 = Antti\n | last12 = Sköldberg | first12 = Håkan\n | last13 = Jakobsson | first13 = Tobias\n | last14 = Honkatukia | first14 = Juha\n | title = Coordinated use of energy system models in energy and climate policy analysis: lessons learned from the Nordic Energy Perspectives project\n | date = 2010\n | publisher = Elforsk\n | location = Stockholm, Sweden\n | isbn = 978-91-978585-9-5\n | url = http://www.ewp.rpi.edu/hartford/~ernesto/F2014/MMEES/Papers/ENERGY/1EnergySystemsModeling/NEP2010-modellrapport.pdf\n | access-date = 2016-11-14\n}}\n</ref>  [[Deep Decarbonization Pathways Project]] researchers have also analyzed model typologies.<ref name=\"pye-and-bataille-2016\"/>{{rp|S30–S31}}  A 2014 paper outlines the modeling challenges ahead as energy systems become more complex and human and social factors become increasingly relevant.<ref name=\"pfenninger-etal-2014\">\n{{cite journal\n | last1 = Pfenninger | first1 = Stefan\n | last2 = Hawkes | first2 = Adam\n | last3 = Keirstead | first3 = James\n | title = Energy systems modeling for twenty-first century energy challenges\n | date = May 2014\n | journal = Renewable and Sustainable Energy Reviews\n | volume = 33\n | pages = 74–86\n | doi = 10.1016/j.rser.2014.02.003\n | issn = 1364-0321\n | url = https://www.pfenninger.org/publications-pdf/Pfenninger%20et%20al_2014_Energy%20systems%20modeling%20for%20twenty-first%20century%20energy%20challenges.pdf\n | access-date = 2017-03-14\n}}\n</ref>\n\n=== Electricity sector models ===\n\nElectricity sector models are used to model electricity systems.  The scope may be national or regional, depending on circumstances.  For instance, given the presence of national interconnectors, the western European electricity system may be modeled in its entirety.\n\nEngineering-based models usually contain a good characterization of the technologies involved, including the high-voltage [[Alternating current|AC]] [[transmission grid]] where appropriate.  Some models (for instance, models for Germany) may assume a single common bus or \"copper plate\" where the grid is strong.  The demand-side in electricity sector models is typically represented by a fixed [[load profile]].\n\nMarket-based models, in addition, represent the prevailing [[electricity market]], which may include [[Electricity market#Bid-based, security-constrained, economic dispatch with nodal prices|nodal pricing]].\n\n[[Game theory]] and [[agent-based model]]s are used to capture and study [[Perfect competition|strategic behavior]] within [[electricity market]]s.<ref name=\"david-and-wen-2000\">\n{{cite conference\n | first1 = AK | last1 = David\n | first2 = Fushuan | last2 = Wen\n | title = Strategic bidding in competitive electricity markets: a literature survey\n | conference = Power Engineering Society Summer Meeting – Volume 4\n | date = 16–20 July 2000\n | publisher = IEEE\n | place = Seattle, WA, USA\n | doi = 10.1109/PESS.2000.866982\n | isbn = 0-7803-6420-1\n}}\n</ref><ref name=\"semsfuss-etal-2007\">\n{{cite book\n | last1 = Sensfuß | first1 = Frank\n | last2 = Ragwitz | first2 = Mario\n | last3 = Genoese | first3 = Massimo\n | last4 = Möst | first4 = Dominik\n | title = Agent-based simulation of electricity markets: a literature review — Working paper sustainability and innovation S5/2007\n | date = 2007\n | publisher = Fraunhofer ISI\n | place = Karlsruhe, Germany\n | url = https://www.econstor.eu/dspace/bitstream/10419/28520/1/570113083.pdf\n | access-date = 2016-05-09\n}}\n</ref><ref name=\"weidlich-and-veit-2008\">\n{{cite journal\n | first1 = Anke | last1 = Weidlich\n | first2 = Daniel | last2 = Veit\n | title = A critical survey of agent-based wholesale electricity market models\n | journal = [[Energy Economics]]\n | volume = 30\n | number = 4\n | pages = 1728–1759\n | date = 2008\n | doi = 10.1016/j.eneco.2008.01.003\n}}\n</ref>\n\n=== Energy system models ===\n\nIn addition to the electricity sector, energy system models include the heat, gas, mobility, and other sectors as appropriate.<ref name=\"abrell-and-weigt-2012\">\n{{cite news\n | last1 = Abrell | first1 = Jan\n | last2 = Weigt | first2 = Hannes\n | title = Combining energy networks\n | date = 2012\n | journal = [[Networks and Spatial Economics]]\n | volume = 12\n | number = 3\n | pages = 377–401\n | doi = 10.1007/s11067-011-9160-0\n}}\n</ref>  Energy system models are often national in scope, but may be municipal or international.\n\nSo-called ''top-down models'' are broadly economic in nature and based on either [[partial equilibrium]] or [[Computable general equilibrium|general equilibrium]].  General equilibrium models represent a specialized activity and require dedicated [[algorithms]].  Partial equilibrium models are more common.\n\nSo-called ''bottom-up models'' capture the engineering well and often rely on techniques from [[operations research]].  Individual plants are characterized by their efficiency curves (also known as input/output relations), nameplate capacities, investment costs ([[Capital expenditure|capex]]), and operating costs ([[Operating expense|opex]]).  Some models allow for these parameters to depend on external conditions, such as ambient temperature.<ref name=\"bruckner-etal-2003\">\n{{cite journal\n | last1 = Bruckner | first1 = Thomas\n | last2 = Morrison | first2 = Robbie\n | last3 = Handley | first3 = Chris\n | last4 = Patterson | first4 = Murray\n | title = High-resolution modeling of energy-services supply systems using ''deeco'': overview and application to policy development\n | date = 2003\n | journal = Annals of Operations Research\n | volume = 121\n | number = 1-4\n | pages = 151–180\n | doi = 10.1023/A:1023359303704\n | url = http://www.wifa.uni-leipzig.de/fileadmin/user_upload/iirm-tm/energiemanagement/publikationen/reviewed_journals/2003_HighResolModelingEnergySystemsDeeco.pdf\n | access-date = 2016-05-08\n}}\n</ref>\n\nProducing hybrid top-down/bottom-up models to capture both the economics and the engineering has proved challenging.<ref name=\"boehringer-and-rutherford-2008\">\n{{cite journal\n | first1 = Christoph | last1 = Böhringer\n | first2 = Thomas F | last2 = Rutherford\n | title = Combining bottom-up and top-down\n | date = 2008\n | journal = [[Energy Economics]]\n | volume = 30\n | number = 2\n | pages = 574–596\n | doi = 10.1016/j.eneco.2007.03.004\n| citeseerx = 10.1.1.184.8384\n }}\n</ref>\n\n== Established models ==\n\nThis section lists some of the major models in use.  These are typically run by national governments.\nIn a community effort, a large number of existing energy system models were collected in model fact sheets on the [[Open energy system databases#OpenEnergy Platform|Open Energy Platform]].<ref name=\"oep-2018\">\n{{cite web\n | title = Open Energy Platform: Model Factsheets\n | url = https://openenergy-platform.org/factsheets/models/\n | access-date = 2018-12-18\n}}</ref>\n\n=== LEAP ===\n\nLEAP (Long range Energy Alternatives Planning System) is a software tool for [[energy policy]] analysis and [[climate change mitigation]] assessment.<ref name=\"sei-2012\">\n{{cite book\n | author = SEI\n | title = LEAP: Long range Energy Alternatives Planning System: a tool for energy policy analysis and climate change mitigation assessment – Flyer\n | date = May 2012\n | publisher = [[Stockholm Environment Institute]] (SEI) US Center\n | place = Somerville, MA, USA\n | url = http://www.sei-us.org/Publications_PDF/SEI-LEAP-brochure-Jan2012.pdf\n | access-date = 2016-05-04\n}}\n</ref><ref name=\"leap-website\">\n{{cite web\n | title = LEAP: tools for sustainable energy analysis \n | url = https://www.energycommunity.org/default.asp\n | access-date = 2016-05-04\n}}\n</ref>  LEAP was developed at the [[Stockholm Environment Institute]]'s (SEI) US Center.  LEAP can be used to examine city, statewide, national, and regional energy systems.  LEAP is normally used for forecast studies of between 20–50 years.  Most of its calculations occur at yearly intervals.  LEAP allows policy analysts to create and evaluate alternative [[Scenario analysis|scenarios]] and to compare their energy requirements, [[Social cost|social costs and benefits]], and environmental impacts.\n\n=== Power System Simulation ===\n[[General Electric]]'s MAPS (Multi-Area Production Simulation) is a production simulation model used by various [[Regional transmission organization (North America)|Regional Transmission Organizations]] and [[Regional transmission organization (North America)#Independent System Operators (ISOs)|Independent System Operators]] in the United States to plan for the economic impact of proposed electric transmission and generation facilities in FERC-regulated electric wholesale markets. Portions of the model may also be used for the commitment and dispatch phase (updated on 5 minute intervals) in operation of wholesale electric markets for RTO and ISO regions. [[ABB]]'s PROMOD is a similar software package. These ISO and RTO regions also utilize a GE software package called MARS (Multi-Area Reliability Simulation) to ensure the power system meets reliability criteria (a loss-of-load-expectation (LOLE) of no greater than 0.1 days per year). Further, a GE software package called PSLF (Positive Sequence Load Flow) and a [[Siemens]] software package called PSSE (Power System Simulation for Engineering) analyzes load flow on the power system for short-circuits and stability during preliminary planning studies by RTOs and ISOs.<ref>{{cite web|title=ABB PROMOD Market Simulation|url=https://new.abb.com/enterprise-software/energy-portfolio-management/market-analysis/promod|work=new.abb.com|accessdate=November 26, 2018}}</ref><ref>{{cite web|title=GE Multi-Area Production Simulation|url=https://www.geenergyconsulting.com/practice-area/software-products/maps|work=www.geenergyconsulting.com|accessdate=November 26, 2018}}</ref><ref>{{cite web|title=GE Multi-Area Reliability Simulation|url=https://www.geenergyconsulting.com/practice-area/software-products/mars|work=www.geenergyconsulting.com|accessdate=November 26, 2018}}</ref><ref>{{cite web|title=GE Power System Load Flow Simulation|url=https://www.geenergyconsulting.com/practice-area/software-products/pslf|work=www.geenergyconsulting.com|accessdate=November 26, 2018}}</ref><ref>{{cite web|title=NYSRC 2018 IRM Study Report|url=http://www.nysrc.org/pdf/Reports/2018%20IRM%20Study%20Report%20Final%2012-8-17[2098].pdf|p=2|work=www.nysrc.org|date=December 8, 2017|accessdate=November 26, 2018}}</ref><ref>{{cite web|title=NYISO Notice to Stakeholders of Request for MAPS data|url=https://www.nyiso.com/public/webdocs/markets_operations/documents/Legal_and_Regulatory/Notices/MP_Notices/Notice%20to%20Generators%20re%20GE%20MAPS%20database%20input%20files%20for%20CARIS%202%20-%209-9-14.pdf|work=www.nyiso.com|date=August 2000|accessdate=November 26, 2018}}</ref><ref>{{cite web|title=Siemens PSSE|url=https://www.siemens.com/global/en/home/products/energy/services/transmission-distribution-smart-grid/consulting-and-planning/pss-software/pss-e.html|work=www.siemens.com|accessdate=November 26, 2018}}</ref><ref>{{cite web|title=New York State Resource Planning Analysis (NYSPSC)|url=https://www.nyiso.com/public/webdocs/markets_operations/committees/mc/meeting_materials/2015-12-17/Agenda%2004_NYSDPS%20SRP%20Presentation_revised.pdf|work=www.nyiso.com|date=December 17, 2015|accessdate=November 26, 2018}}</ref>\n\n=== MARKAL/TIMES ===\n\n{{main|MARKAL}}\n\nMARKAL (MARKet ALlocation) is an integrated energy systems modeling platform, used to analyze energy, economic, and environmental issues at the global, national, and municipal level over time-frames of up to several decades.  MARKAL can be used to quantify the impacts of policy options on technology development and natural resource depletion.  The software was developed by the Energy Technology Systems Analysis Programme (ETSAP) of the [[International Energy Agency]] (IEA) over a period of almost two decades.\n\nTIMES (The Integrated MARKAL-EFOM System) is an evolution of MARKAL – both energy models have many similarities.<ref name=\"comparison-times-markal-2009\">\n<!-- previous (now dead) URL was: http://www.iea-etsap.org/web/TOOLS/TIMESVsMARKAL.pdf -->\n{{cite book|url=http://iea-etsap.org/tools/TIMESVsMARKAL.pdf|title=A comparison of the TIMES and MARKAL models|date=2009|access-date=2016-10-31}}\n</ref>  TIMES succeeded MARKAL in 2008.<ref name=\"markal\">\n<!-- previous (now dead) URL was: http://www.iea-etsap.org/web/Markal.asp -->\n{{cite web|url=http://iea-etsap.org/index.php/etsap-tools/model-generators/markal|title=MARKAL|access-date=2016-10-31}}\n</ref>  Both models are technology explicit, dynamic [[partial equilibrium]] models of [[energy market]]s. In both cases, the equilibrium is determined by maximizing the total [[Economic surplus|consumer and producer surplus]] via [[linear programming]].  Both MARKAL and TIMES are written in [[General Algebraic Modeling System|GAMS]].\n\nThe TIMES model generator was also developed under the Energy Technology Systems Analysis Program (ETSAP).  TIMES combines two different, but complementary, systematic approaches to modeling energy – a technical engineering approach and an economic approach.  TIMES is a technology rich, bottom-up model generator, which uses [[linear programming]] to produce a least-cost energy system, optimized according to a number of user-specified constraints, over the medium to long-term.  It is used for \"the exploration of possible energy futures based on contrasted scenarios\".<ref name=\"loulou-etal-2005\">\n<!-- previous (now dead) URL was: http://www.iea-etsap.org/web/docs/timesdoc-intro.pdf -->\n{{cite book|url=http://iea-etsap.org/docs/TIMESDoc-Intro.pdf|title=Documentation for the TIMES model – Part I|last1=Loulou|first1=Richard|last2=Remne|first2=Uwe|last3=Kanudia|first3=Amit|last4=Lehtila|first4=Antti|last5=Goldstein|first5=Gary|date=April 2005|publisher=Energy Technology Systems Analysis Programme (ETSAP)|access-date=2016-10-31}}\n</ref>{{rp|7}}\n\n{{as of|2015}}, the MARKAL and TIMES model generators are in use in 177 institutions spread over 70 countries.<ref name=\"giannakidis-etal-2015\">\n{{cite book\n | editor1-last = Giannakidis | editor1-first = George\n | editor2-last = Labriet | editor2-first = Maryse\n | editor3-last = Gallachóir | editor3-first = Brian Ó\n | editor4-last = Tosato | editor4-first = GianCarlot\n | title = Informing energy and climate policies using energy systems models: insights from scenario analysis increasing the evidence base\n | volume = 30\n | date = 2015\n | publisher = Springer International Publishing\n | location = Cham, Switzerland\n | isbn = 978-3-319-16540-0\n | doi = 10.1007/978-3-319-16540-0\n| series = Lecture Notes in Energy\n }}\n</ref>{{rp|5}}\n\n=== NEMS ===\n\n{{main|National Energy Modeling System}}\n\n[[National Energy Modeling System|NEMS]] (National Energy Modeling System) is a long-standing United States government policy model, run by the [[United States Department of Energy|Department of Energy]] (DOE).  NEMS computes equilibrium fuel prices and quantities for the US energy sector.  To do so, the software iteratively solves a sequence of linear programs and nonlinear equations.<ref name=\"gabriel-etal-1999\">\n{{cite journal\n | first1 = Steven A | last1 = Gabriel\n | first2 = Andy S | last2 = Kydes\n | first3 = Peter | last3 = Whitman\n | title = The National Energy Modeling System: a large-scale energy-economic equilibrium model\n | date = 1999\n | journal = [[Operations Research (journal)|Operations Research]]\n | volume = 49\n | number = 1\n | pages = 14–25\n | doi = 10.1287/opre.49.1.14.11195\n }}\n</ref>  NEMS has been used to explicitly model the demand-side, in particular to determine consumer technology choices in the residential and commercial building sectors.<ref name=\"wilkerson-etal-2013\">\n{{cite journal\n | first1 = Jordan T | last1 = Wilkerson\n | first2 = Danny | last2 = Cullenward\n | first3 = Danielle | last3 = Davidian\n | first4 = John P | last4 = Weyant\n | title = End use technology choice in the National Energy Modeling System (NEMS): an analysis of the residential and commercial building sectors\n | date = 2013\n | journal = [[Energy Economics (journal)|Energy Economics]]\n | volume = 40\n | pages = 773–784\n | doi = 10.1016/j.eneco.2013.09.023\n | url = https://www.researchgate.net/publication/260336985\n | access-date = 2016-05-09\n}}\n</ref>\n\nNEMS is used to produce the ''Annual Energy Outlook'' each year – for instance in 2015.<ref name=\"eia-2015\">\n{{cite book\n | title = Annual energy outlook 2015: with projections to 2040 – DOE/EIA-0383(2015)\n | date = April 2015\n | publisher = US Energy Information Administration, Office of Integrated and International Energy Analysis, US Department of Energy\n | place = Washington, DC, USA\n | url = https://www.eia.gov/forecasts/aeo/pdf/0383%282015%29.pdf\n | access-date = 2016-05-09\n}}\n</ref>\n\n== Criticisms ==\n\nPublic policy energy models have been criticized for being insufficiently [[Open research|transparent]].  The [[source code]] and data sets should at least be available for [[peer review]], if not explicitly published.<ref name=\"acatech-etal-2016a\">\n<!-- alternative URL: http://www.akademienunion.de/fileadmin/redaktion/user_upload/Publikationen/Stellungnahmen/Stellungnahme_Energy_scenarios.pdf -->\n{{cite book\n | editor1 = acatech\n | editor2 = Lepoldina\n | editor3 = Akademienunion\n | title = Consulting with energy scenarios: requirements for scientific policy advice\n | date = 2016\n | publisher = acatech — National Academy of Science and Engineering\n | place = Berlin, Germany\n | isbn = 978-3-8047-3550-7\n | url = http://www.acatech.de/fileadmin/user_upload/Baumstruktur_nach_Website/Acatech/root/de/Publikationen/Kooperationspublikationen/ESYS_Position_Paper_Energy_scenarios.pdf\n | access-date = 2016-12-19\n}}\n</ref>  To improve transparency and public acceptance, some models are undertaken as [[open-source software]] projects, often developing a diverse community as they proceed.  OSeMOSYS is one such example.<ref name=\"howells-etal-2011\">\n{{cite journal\n | first1 = Mark | last1 = Howells\n | first2 = Holger | last2 = Rogner\n | first3 = Neil | last3 = Strachan\n | first4 = Charles | last4 = Heaps\n | first5 = Hillard | last5 = Huntington\n | first6 = Socrates | last6 = Kypreos\n | first7 = Alison | last7 = Hughes\n | first8 = Semida | last8 = Silveira\n | first9 = Joe | last9 = DeCarolis\n | first10 = Morgan | last10 = Bazillian\n | first11 = Alexander | last11 = Roehrl\n | title = OSeMOSYS: the open source energy modeling system: an introduction to its ethos, structure and development\n | date = 2011\n | journal = Energy Policy\n | volume = 39\n | number = 10\n | pages = 5850–5870\n | doi = 10.1016/j.enpol.2011.06.033\n}}\n</ref><ref name=\"osemosys-website\">\n{{cite web\n | title = OSeMOSYS: an open-source energy modelling system\n | url = http://www.osemosys.org\n | access-date = 2016-05-08\n}}\n</ref>\n\n== See also ==\n\n'''General'''\n\n* [[Climate change mitigation]] – actions to limit long-term climate change\n* [[Climate change mitigation scenarios]] – possible futures in which global warming is reduced by deliberate actions\n* [[Economic model]]\n* [[Energy system]] – the interpretation of the energy sector in system terms\n* [[Energy Modeling Forum]] – a [[Stanford University]]-based modeling forum\n* [[Open Energy Modelling Initiative]] – an [[open source]] energy modeling initiative, centered on Europe\n* [[Open energy system databases]] – database projects which collect, clean, and republish energy-related datasets \n* [[Open energy system models]] – a review of [[energy system]] models that are also [[open source software|open source]]\n* [[Power system simulation]]\n\n'''Models'''\n\n* [[ACEGES]] – a global agent-based computational economics model\n* [[iNEMS]] (Integrated National Energy Modeling System) – a national energy model for China\n* [[MARKAL]] – an energy model\n* [[National Energy Modeling System|NEMS]] – the US government national energy model\n* [[Prospective Outlook on Long-term Energy Systems]] (POLES) – an energy sector world simulation model\n* KAPSARC Energy Model - an energy sector model for Saudi Arabia<ref>{{cite web|title=KAPSARC Energy Model|url=https://www.researchgate.net/project/KAPSARC-Energy-Model-KEM|accessdate=January 12, 2019}}</ref>\n\n== References ==\n\n{{reflist|30em}}\n\n== External links ==\n\n* [https://info.zib.de/confluence/display/COSTTD1207/Main COST TD1207 Mathematical Optimization in the Decision Support Systems for Efficient and Robust Energy Networks wiki] – a typology for optimization models\n* [http://www.energyplan.eu EnergyPLAN] — a [[freeware]] energy model from the Department of Development and Planning, [[Aalborg University]], Denmark\n* [http://wiki.openmod-initiative.org/wiki/Open_Models Open Energy Modelling Initiative open models page] – a list of open energy models\n\n<!-- templates and categories -->\n{{Energy modeling|state=expanded}}\n{{Computer modeling}}\n\n[[Category:Climate change policy]]\n[[Category:Computational science]]\n[[Category:Computer programming]]\n[[Category:Economics models]]\n[[Category:Energy models]]\n[[Category:Energy policy]]\n[[Category:Mathematical modeling]]\n[[Category:Mathematical optimization]]\n[[Category:Simulation]]\n[[Category:Systems theory]]"
    },
    {
      "title": "Feasible region",
      "url": "https://en.wikipedia.org/wiki/Feasible_region",
      "text": "{{single source|date=November 2018}}\n[[File:IP polytope with LP relaxation.svg|350px|thumb|A problem with five linear constraints (in blue, including the non-negativity constraints). In the absence of integer constraints the feasible set is the entire region bounded by blue, but with [[integer constraint]]s it is the set of red dots.]]\n[[File:3dpoly.svg|thumb|right|A closed feasible region of a [[linear programming]] problem with three variables is a convex [[polyhedron]].]]\n\nIn [[mathematical optimization]], a '''feasible region''', '''feasible set''', '''search space''', or '''solution space''' is the set of all possible points (sets of values of the choice variables) of an [[optimization problem]] that satisfy the problem's [[Constraint (mathematics)|constraints]], potentially including [[Inequality (mathematics)|inequalities]], [[Equality (mathematics)|equalities]], and [[integer]] constraints.<ref>{{cite book |first=Brian |last=Beavis |first2=Ian |last2=Dobbs |title=Optimisation and Stability Theory for Economic Analysis |location=New York |publisher=Cambridge University Press |year=1990 |isbn=0-521-33605-8 |page=32 |url=https://books.google.com/books?id=L7HMACFgnXMC&pg=PA32 }}</ref> This is the initial set of [[candidate solution]]s to the problem, before the set of candidates has been narrowed down.\n\nFor example, consider the problem\n\n:'''Minimize''' <math> x^2+y^4 </math>\n\nwith respect to the variables <math>x</math> and <math>y,</math>\n\nsubject to\n\n:<math> 1 \\le x \\le 10 </math>\n\nand\n\n:<math> 5 \\le y \\le 12. \\, </math>\n\nHere the feasible set is the set of pairs (''x'', ''y'') in which the value of ''x'' is at least 1 and at most 10 and the value of ''y'' is at least 5 and at most 12. Note that the feasible set of the problem is separate from the [[objective function]], which states the criterion to be optimized and which in the above example is <math> x^2+y^4. </math>\n\nIn many problems, the feasible set reflects a constraint that one or more variables must be non-negative. In pure [[integer programming]] problems, the feasible set is the set of integers (or some subset thereof).  In [[linear programming]] problems, the feasible set is a [[Convex set|convex]] [[polytope]]: a region in [[Dimension (mathematics and physics)|multidimensional space]] whose boundaries are formed by [[hyperplanes]] and whose corners are [[vertex (geometry)|vertices]].\n\n[[Constraint satisfaction]] is the process of finding a point in the feasible region.\n\n==Convex feasible set==\n{{See also|Convex optimization}}\n[[File:Linear Programming Feasible Region.svg|frame|In a linear programming problem, a series of linear constraints produce a convex feasible region of possible values for those variables. In the two-variable case this region is in the shape of a convex [[simple polygon]].]]\n\nA [[convex set|convex]] feasible set is one in which a line segment connecting any two feasible points goes through only other feasible points, and not through any points outside the feasible set.  Convex feasible sets arise in many types of problems, including linear programming problems, and they are of particular interest because, if the problem has a [[convex function|convex objective function]] that is to be maximized, it will generally be easier to solve in the presence of a convex feasible set and any [[local optimum]] will also be a [[global optimum]].\n\n==No feasible set==\n\nIf the constraints of an optimization problem are mutually contradictory, there are no points that satisfy all the constraints and thus the feasible region is the [[null set]]. In this case the problem has no solution and is said to be ''infeasible''.\n\n==Bounded and unbounded feasible sets==\n\n [[Image:Bounded unbounded.svg|right|thumb|A bounded feasible set (top) and an unbounded feasible set (bottom). The set at the bottom continues forever towards the right.]]\n\nFeasible sets may be [[Bounded set|bounded or unbounded]]. For example, the feasible set defined by the constraint set {''x'' ≥ 0, ''y'' ≥ 0} is unbounded because in some directions there is no limit on how far one can go and still be in the feasible region. In contrast, the feasible set formed by the constraint set {''x'' ≥ 0, ''y'' ≥ 0, ''x'' + 2''y'' ≤ 4} is bounded because the extent of movement in any direction is limited by the constraints.\n\nIn linear programming problems with ''n'' variables, a [[Necessary and sufficient conditions|necessary but not sufficient condition]] for the feasible set to be bounded is that the number of constraints be at least ''n'' + 1 (as illustrated by the above example).\n\nIf the feasible set is unbounded, there may or may not be an optimum, depending on the specifics of the objective function. For example, if the feasible region is defined by the constraint set {''x'' ≥ 0, ''y'' ≥ 0}, then the problem of maximizing ''x'' + ''y'' has no optimum since any candidate solution can be improved upon by increasing ''x'' or ''y''; yet if the problem is to ''minimize'' ''x'' + ''y'', then there is an optimum (specifically at (''x'', ''y'') = (0, 0)).\n\n==Candidate solution==\nIn [[mathematical optimization|optimization]] and other branches of [[mathematics]], and in [[search algorithm]]s (a topic in  [[computer science]]), a '''candidate solution''' is a [[Element (mathematics)|member]] of the [[Set (mathematics)|set]] of possible solutions in the feasible region of a given problem.{{citation needed|date=August 2013}} A candidate solution does not have to be a likely or reasonable solution to the problem&mdash;it is simply in the set that satisfies all [[Constraint (mathematics)|constraints]]; that is, it is in the set of ''feasible solutions''. Algorithms for solving various types of optimization problems often narrow the set of candidate solutions down to a subset of the feasible solutions, whose points remain as candidate solutions while the other feasible solutions are henceforth excluded as candidates.\n\nThe space of all candidate solutions, before any feasible points have been excluded, is called the feasible region, feasible set, search space, or solution space.{{citation needed|date=August 2013}} This is the set of all possible solutions that satisfy the problem's constraints. [[Constraint satisfaction]] is the process of finding a point in the feasible set.\n\n===Genetic algorithm===\nIn the case of the [[genetic algorithm]], the candidate solutions are the individuals in the population being evolved by the algorithm.<ref>{{Cite journal | last=Whitley | first=Darrell | title=A genetic algorithm tutorial | journal=Statistics and Computing | doi=10.1007/BF00175354 | volume=4 | issue=2 | pages=65–85 | year=1994 | ref=harv | url=http://www.cs.uga.edu/~potter/CompIntell/ga_tutorial.pdf }}</ref>\n\n===Calculus===\nIn calculus, an optimal solution is sought using the [[first derivative test]]: the [[first derivative]] of the function being optimized is equated to zero, and any values of the choice variable(s) that satisfy this equation are viewed as candidate solutions (while those that do not are ruled out as candidates). There are several ways in which a candidate solution might not be an actual solution. First, it might give a minimum when a maximum is being sought (or vice versa), and second, it might give neither a minimum nor a maximum but rather a [[saddle point]] or an [[inflection point]], at which a temporary pause in the local rise or fall of the function occurs. Such candidate solutions may be able to be ruled out by use of the [[second derivative test]], the satisfaction of which is sufficient for the candidate solution to be at least locally optimal. Third, a candidate solution may be a [[local optimum]] but not a [[global optimum]].\n\nIn taking [[antiderivative]]s of [[monomial]]s of the form <math>x^n,</math> the candidate solution using [[Cavalieri's quadrature formula]] would be <math>\\tfrac{1}{n+1}x^{n+1}+C.</math> This candidate solution is in fact correct except when <math>n=-1.</math>\n\n===Linear programming===\n[[Image:Linear_Programming_Feasible_Region.svg|frame|A series of [[linear programming]] constraints on two variables produce a region of possible values for those variables. Solvable two-variable problems will have a feasible region in the shape of a [[Convex set|convex]] [[simple polygon]] if it is bounded. In an algorithm that tests feasible points sequentially, each tested point is in turn a candidate solution.]]\nIn the [[simplex method]] for solving [[linear programming]] problems, a [[Vertex (geometry)|vertex]] of the feasible [[polytope]] is selected as the initial candidate solution and is tested for optimality; if it is rejected as the optimum, an adjacent vertex is considered as the next candidate solution. This process is continued until a candidate solution is found to be the optimum.\n\n== References ==\n{{reflist}}\n[[Category:Optimal decisions]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Fritz John conditions",
      "url": "https://en.wikipedia.org/wiki/Fritz_John_conditions",
      "text": "The '''Fritz John conditions''' (abbr. '''FJ conditions'''), in [[mathematics]], are a [[necessary and sufficient conditions|necessary condition]] for a solution in [[nonlinear programming]] to be [[Optimization (mathematics)|optimal]].<ref>{{cite book |first=Akira |last=Takayama |authorlink=Akira Takayama |title=Mathematical Economics |location=New York |publisher=Cambridge University Press |year=1985 |pages=90–112 |isbn=0-521-31498-4 }}</ref> They are used as lemma in the proof of the [[Karush–Kuhn–Tucker conditions]], but they are relevant on their own.\n\nWe consider the following [[optimization problem]]:\n\n:<math>\n\\begin{align}\n    \\text{minimize } & f(x) \\, \\\\\n    \\text{subject to: } & g_i(x) \\ge 0,\\ i \\in \\left \\{1,\\dots,m \\right \\}\\\\\n        & h_j(x) = 0, \\ j \\in \\left \\{m+1,\\dots,n \\right \\}\n\\end{align}\n</math>\n\nwhere ''&fnof;'' is the [[function (mathematics)|function]] to be minimized, <math>g_i</math> the inequality [[constraint (mathematics)|constraints]] and <math>h_j</math> the equality constraints, and where, respectively, <math>\\mathcal{I}</math>, <math>\\mathcal{I'}</math> and <math>\\mathcal{E}</math> are the [[indexed family|indices]] [[Set (mathematics)|set]] of inactive, active and equality constraints and <math>x^*</math> is an optimal solution of <math>f</math>, then there exists a non-zero vector <math>\\lambda=[\\lambda_0, \\lambda _1, \\lambda _2,\\dots,\\lambda _n]</math> such that:\n\n:<math> \\begin{cases}\n   \\lambda_0 \\nabla f(x^*) + \\sum\\limits_{i\\in \\mathcal{I}'} \\lambda_i \\nabla g_i(x^*) + \\sum\\limits_{i\\in \\mathcal{E}} \\lambda_i \\nabla h_i (x^*) =0\\\\[10pt]\n   \\lambda_i \\ge 0,\\  i\\in \\mathcal{I}'\\cup\\{0\\} \\\\[10pt]\n   \\exists i\\in \\left( \\{0,1,\\ldots ,n\\} \\backslash \\mathcal{I} \\right) \\left( \\lambda_i \\ne 0 \\right)\n\\end{cases} </math>\n\n<math>\\lambda_0>0</math> [[If and only if|if]] the <math>\\nabla g_i (i\\in\\mathcal{I}')</math> and <math>\\nabla h_i (i\\in\\mathcal{E})</math> are [[linearly independent]] or, more generally, when a [[Karush–Kuhn–Tucker conditions#Regularity conditions .28or constraint qualifications.29|constraint qualification]] holds.\n\nNamed after [[Fritz John]], these conditions are equivalent to the [[Karush–Kuhn–Tucker conditions]] in the case <math>\\lambda_0 > 0</math>. When <math>\\lambda_0=0</math>, the condition is equivalent to the violation of [[Mangasarian–Fromovitz constraint qualification]] (MFCQ). In other words, the Fritz John condition is equivalent to the optimality condition KKT or not-MFCQ.{{cn|date=June 2019}}\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Fritz John Conditions}}\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Geometric median",
      "url": "https://en.wikipedia.org/wiki/Geometric_median",
      "text": "{{distinguish|Median (geometry)}}\n\n[[File:Geometric median example.svg|thumb|right|320px|Example of '''geometric median''' (in yellow) of a series of points. In blue the [[Center of mass]].]]\n\nThe '''geometric median''' of a discrete set of sample points in a [[Euclidean space]] is the point minimizing the sum of distances to the sample points. This generalizes the [[median]], which has the property of minimizing the sum of distances for one-dimensional data, and provides a [[central tendency]] in higher dimensions. It is also known as the '''1-median''',<ref>The more general [[k-median problem|''k''-median problem]] asks for the location of ''k'' cluster centers minimizing the sum of distances from each sample point to its nearest center.</ref> '''spatial median''',<ref name=\"dksw\"/> '''Euclidean minisum point''',<ref name=\"dksw\">{{harvtxt|Drezner|Klamroth|Schöbel|Wesolowsky|2002}}</ref>  or '''Torricelli point'''.{{sfnp|Cieslik|2006}}\n\nThe geometric median is an important [[estimator]] of [[location parameter|location]] in statistics,{{sfnp|Lawera|Thompson|1993}} where it is also known as the '''''L''<sub>1</sub> estimator'''.<ref name=\"lr\"/> It is also a standard problem in [[facility location]], where it models the problem of locating a facility to minimize the cost of transportation.{{sfnp|Eiselt|Marianov|2011}}\n\nThe special case of the problem for three points in the plane (that is, ''m'' = 3 and ''n'' = 2 in the definition below) is sometimes also known as Fermat's problem; it arises in the construction of minimal [[Steiner tree]]s, and was originally posed as a problem by [[Pierre de Fermat]] and solved by [[Evangelista Torricelli]].{{sfnp|Krarup|Vajda|1997}} Its solution is now known as the [[Fermat point]] of the triangle formed by the three sample points.{{sfnp|Spain|1996}} The geometric median may in turn be generalized to the problem of minimizing the sum of ''weighted'' distances, known as the [[Weber problem]] after [[Alfred Weber]]'s discussion of the problem in his 1909 book on facility location.<ref name=\"dksw\"/> Some sources instead call Weber's problem the Fermat–Weber problem,{{sfnp|Brimberg|1995}} but others use this name for the unweighted geometric median problem.{{sfnp|Bose|Maheshwari|Morin|2003}}\n\n{{harvtxt|Wesolowsky|1993}} provides a survey of the geometric median problem. See {{harvtxt|Fekete|Mitchell|Beurer|2005}} for generalizations of the problem to non-discrete point sets.\n\n==Definition==\n\nFormally, for a given set of ''m'' points <math>x_1, x_2, \\dots, x_m\\,</math> with each <math>x_i \\in \\mathbb{R}^n</math>, the geometric median is defined as\n\n:<math>\\underset{y \\in \\mathbb{R}^n}{\\operatorname{arg\\,min}} \\sum_{i=1}^m \\left \\| x_i-y \\right \\|_2</math>\n\nHere, [[arg min]] means the value of the argument <math>y</math> which minimizes the sum. In this case, it is the point <math>y</math> from where the sum of all [[Euclidean distance]]s to the <math>x_i</math>'s is minimum.\n\n==Properties==\n* For the 1-dimensional case, the geometric median coincides with the [[median]]. This is because the [[univariate]] median also minimizes the sum of distances from the points.<ref name=\"haldane\"/>\n* The geometric median is '''unique''' whenever the points are not [[Line (geometry)#Collinear points|collinear]].<ref name=\"vz\">{{harvtxt|Vardi|Zhang|2000}}</ref>\n* The geometric median is [[equivariant]] for Euclidean [[Similarity (geometry)|similarity transformations]], including [[translation (geometry)|translation]] and [[rotation (mathematics)|rotation]].<ref name=\"lr\"/><ref name=\"haldane\">{{harvtxt|Haldane|1948}}</ref> This means that one would get the same result either by transforming the geometric median, or by applying the same transformation to the sample data and finding the geometric median of the transformed data. This property follows from the fact that the geometric median is defined only from pairwise distances, and doesn't depend on the system of orthogonal [[Cartesian coordinates]] by which the sample data is represented. In contrast, the component-wise median for a multivariate data set is not in general rotation invariant, nor is it independent of the choice of coordinates.<ref name=\"lr\"/>\n* The geometric median has a [[breakdown point]] of 0.5.<ref name=\"lr\">{{harvtxt|Lopuhaä|Rousseeuw|1991}}</ref> That is, up to half of the sample data may be arbitrarily corrupted, and the median of the samples will still provide a [[robust estimator]] for the location of the uncorrupted data.\n\n==Special cases==\n*'''For 3 (non-[[collinear]]) points,''' if any angle of the triangle formed by those points is 120° or more, then the geometric median is the point at the vertex of that angle. If all the angles are less than 120°, the geometric median is the point inside the triangle which subtends an angle of 120° to each three pairs of triangle vertices.<ref name=\"haldane\"/> This is also known as the [[Fermat point]] of the triangle formed by the three vertices. (If the three points are collinear then the geometric median is the point between the two other points, as is the case with a one-dimensional median.)\n*'''For 4 [[coplanar]] points,''' if one of the four points is inside the triangle formed by the other three points, then the geometric median is that point. Otherwise, the four points form a convex [[quadrilateral]] and the geometric median is the crossing point of the diagonals of the quadrilateral. The geometric median of four coplanar points is the same as the unique [[Radon point]] of the four points.<ref>{{harvtxt|Cieslik|2006}}, p.&nbsp;6; {{harvtxt|Plastria|2006}}. The convex case was originally proven by [[Giovanni Fagnano]].</ref>\n\n==Computation==\nDespite the geometric median's being an easy-to-understand concept, computing it poses a challenge. The [[centroid]] or [[center of mass]], defined similarly to the geometric median as minimizing the sum of the ''squares'' of the distances to each point, can be found by a simple formula — its coordinates are the averages of the coordinates of the points — but it has been shown that no [[Closed-form expression|explicit formula]], nor an exact algorithm involving only arithmetic operations and ''k''th roots, can exist in general for the geometric median. Therefore, only numerical or symbolic approximations to the solution of this problem are possible under this [[model of computation]].<ref>{{harvtxt|Bajaj|1986}}; {{harvtxt|Bajaj|1988}}. Earlier, {{harvtxt|Cockayne|Melzak|1969}} proved that the Steiner point for 5 points in the plane cannot be constructed with [[ruler and compass]]</ref>\n\nHowever, it is straightforward to calculate an approximation to the geometric median using an iterative procedure in which each step produces a more accurate approximation. Procedures of this type can be derived from the fact that the sum of distances to the sample points is a [[convex function]], since the distance to each sample point is convex and the sum of convex functions remains convex. Therefore, procedures that decrease the sum of distances at each step cannot get trapped in a [[local optimum]].\n\nOne common approach of this type, called '''Weiszfeld's algorithm''' after the work of [[Endre Weiszfeld]],<ref>{{harvtxt|Weiszfeld|1937}}; {{harvtxt|Kuhn|1973}}; {{harvtxt|Chandrasekaran|Tamir|1989}}.</ref> is a form of [[iteratively re-weighted least squares]]. This algorithm defines a set of weights that are inversely proportional to the distances from the current estimate to the sample points, and creates a new estimate that is the weighted average of the sample according to these weights. That is,\n:<math>\\left. y_{i+1}=\\left( \\sum_{j=1}^m \\frac{x_j}{\\| x_j - y_i \\|} \\right) \\right/ \\left( \\sum_{j=1}^m \\frac{1}{\\| x_j - y_i \\|} \\right).</math>\nThis method converges for almost all initial positions, but may fail to converge when one of its estimates falls on one of the given points. It can be modified to handle these cases so that it converges for all initial points.<ref name=\"vz\"/>\n\n{{harvtxt|Bose|Maheshwari|Morin|2003}} describe more sophisticated geometric optimization procedures for finding approximately optimal solutions to this problem. As {{harvtxt|Nie|Parrilo|Sturmfels|2008}} show, the problem can also be represented as a [[semidefinite programming|semidefinite program]].\n\n{{harvtxt|Cohen|Lee|Miller|Pachocki|2016}} show how to compute the geometric median to arbitrary precision in nearly linear time.\n\n==Characterization of the geometric median==\nIf ''y'' is distinct from all the given points, ''x''<sub>''j''</sub>, then ''y'' is the geometric median if and only if it satisfies:\n:<math>0 = \\sum_{j=1}^m \\frac {x_j - y} {\\left \\| x_j - y \\right \\|}.</math>\n\nThis is equivalent to:\n:<math>\\left. y = \\left( \\sum_{j=1}^m \\frac{x_j}{\\| x_j - y \\|} \\right) \\right/ \\left( \\sum_{j=1}^m \\frac{1}{\\| x_j - y \\|} \\right),</math>\n\nwhich is closely related to Weiszfeld's algorithm.\n\nIn general,  ''y'' is the geometric median if and only if there are vectors ''u''<sub>''j''</sub> such that:\n:<math>0 =  \\sum_{j=1}^m u_j </math>\nwhere for ''x''<sub>''j''</sub> ≠ ''y'', \n:<math>u_j = \\frac {x_j - y} {\\left \\| x_j - y \\right \\|}</math>\nand for ''x''<sub>''j''</sub> = ''y'', \n:<math>\\| u_j \\| \\leq 1 .</math>\nAn equivalent formulation of this condition is\n:<math>\\sum _{1\\le j\\le m, x_j\\ne y}\n\\frac {x_j - y} {\\left \\| x_j - y \\right \\|} \\le \\left|\\{\n\\,j\\mid 1\\le j\\le m, x_j= y\\,\\}\\right|.</math>\n\nIt can be seen as a generalization of the median property, in the sense that any partition of the points, in particular as induced by any hyperplane through ''y'', has the same and opposite sum of positive ''directions'' from ''y'' on each side. In the one dimensional case, the hyperplane is the point ''y'' itself, and the sum of directions simplifies to the (directed) counting measure.\n\n== Generalizations ==\nThe geometric median can be generalized from Euclidean spaces to general [[Riemannian manifold]]s (and even [[metric space]]s) using the same idea which is used to define the [[Fréchet mean]] on a Riemannian manifold.{{sfnp|Fletcher|Venkatasubramanian|Joshi|2009}} Let <math>M</math> be a Riemannian manifold with corresponding distance function <math>d(\\cdot, \\cdot)</math>, let <math>w_1, \\ldots, w_n</math> be <math>n</math> weights summing to 1, and let <math>x_1, \\ldots, x_n</math>\nbe <math>n</math> observations from <math>M</math>.  Then we define the  weighted geometric median <math>m</math> (or weighted Fréchet median) of the data points as\n: <math> m = \\underset{x \\in M}{\\operatorname{arg\\,min}} \\sum_{i=1}^n w_i d(x,x_i) </math>.\nIf all the weights are equal, we say simply that <math>m</math> is the geometric median.\n\n== See also ==\n* [[Medoid]]\n* [[Median_absolute_deviation#Geometric_median_absolute_deviation|Geometric median absolute deviation]]\n\n== Notes ==\n{{reflist|30em}}\n\n== References ==\n{{refbegin|30em}}\n*{{cite journal\n | last = Bajaj | first = C. | authorlink = Chandrajit Bajaj\n | title = Proving geometric algorithms nonsolvability: An application of factoring polynomials\n | journal = [[Journal of Symbolic Computation]]\n | year = 1986\n | volume = 2\n | pages = 99–102\n | doi =  10.1016/S0747-7171(86)80015-3\n | ref = harv   \n}}\n*{{cite journal\n | last = Bajaj | first = C. | authorlink = Chandrajit Bajaj\n | title = The algebraic degree of geometric optimization problems\n | journal = [[Discrete and Computational Geometry]]\n | year = 1988\n | volume = 3\n | pages = 177–191\n | doi = 10.1007/BF02187906\n | ref = harv| url = http://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1415&context=cstech}}\n*{{cite journal\n | title = Fast approximations for sums of distances, clustering and the Fermat–Weber problem\n | last1 = Bose | first1= Prosenjit | author1-link = Jit Bose | last2 = Maheshwari | first2 = Anil | last3 = Morin | first3 = Pat\n | journal = [[Computational Geometry (journal)|Computational Geometry: Theory and Applications]]\n | volume = 24\n | issue = 3\n | pages = 135–146\n | year = 2003\n | doi = 10.1016/S0925-7721(02)00102-5\n | url = http://www.scs.carleton.ca/~jit/publications/papers/bmm01.ps\n | ref = harv}}\n*{{cite journal\n | last = Brimberg | first = J.\n | doi = 10.1007/BF01592245\n | issue = 1, Ser. A\n | journal = [[Mathematical Programming]]\n | mr = 1362958\n | pages = 71–76\n | title = The Fermat–Weber location problem revisited\n | volume = 71\n | year = 1995\n | ref = harv}}\n*{{cite journal\n | last1 = Chandrasekaran | first1 = R. | last2 = Tamir | first2 = A.\n | title = Open questions concerning Weiszfeld's algorithm for the Fermat-Weber location problem\n | journal = [[Mathematical Programming]] | series = Series A\n | volume = 44\n | year = 1989\n | pages = 293–295\n | doi = 10.1007/BF01587094\n | ref = harv}}\n*{{cite book|title=Shortest Connectivity: An Introduction with Applications in Phylogeny|volume=17|series=Combinatorial Optimization|first=Dietmar|last=Cieslik|publisher=Springer|year=2006|isbn=9780387235394|page=3|url=https://books.google.com/books?id=4E0r3oWkn6AC&pg=PA3|ref=harv}}\n*{{cite journal\n | doi = 10.2307/2688541\n | last1 = Cockayne | first1 = E. J. | last2 = Melzak | first2 = Z. A.\n | title = Euclidean constructability in graph minimization problems\n | jstor = 2688541\n | journal = [[Mathematics Magazine]]\n | volume = 42\n | issue = 4\n | pages = 206–208\n | year = 1969\n | ref = harv}}\n*{{cite conference|contribution=Geometric median in nearly linear time|last1=Cohen|first1=Michael|last2=Lee|first2=Yin Tat|last3=Miller|first3=Gary|author3-link=Gary Miller (computer scientist)|last4=Pachocki|first4=Jakub|last5=Sidford|first5=Aaron|publisher=[[Association for Computing Machinery]]|title=Proc. 48th [[Symposium on Theory of Computing]] (STOC 2016)|year=2016|ref=harv}}\n*{{cite conference\n | last1 = Drezner | first1 = Zvi\n | last2 = Klamroth | first2 = Kathrin\n | last3 = Schöbel | first3 = Anita\n | last4 = Wesolowsky | first4 = George O.\n | title = The Weber problem\n | mr = 1933966\n | pages = 1–36\n | publisher = Springer, Berlin\n | booktitle = Facility Location: Applications and Theory\n | url = https://books.google.com/books?id=sxpcsGN7K1YC&pg=PA1\n | year = 2002\n | ref = harv}}\n*{{cite book|title=Foundations of Location Analysis|volume=155series=International Series in Operations Research & Management Science|first1=H. A.|last1=Eiselt|first2=Vladimir|last2=Marianov|publisher=Springer|year=2011|isbn=9781441975720|page=6|url=https://books.google.com/books?id=6bQ8JJ_Rx6sC&pg=PA6|ref=harv}}\n*{{cite journal\n | last1 = Fekete | first1 = Sándor P.\n | last2 = Mitchell | first2 = Joseph S. B. | author2-link = Joseph S. B. Mitchell\n | last3 = Beurer | first3 = Karin\n | title = On the continuous Fermat-Weber problem\n | journal = [[Operations Research (journal)|Operations Research]]\n | volume = 53 | issue = 1\n | pages = 61–76\n | year = 2005\n | ref = harv\n | arxiv = cs.CG/0310027\n | doi = 10.1287/opre.1040.0137}}\n*{{cite journal\n | first1 = P. Thomas | last1 = Fletcher | first2 = Suresh | last2 = Venkatasubramanian | first3 = Sarang | last3 = Joshi\n | title  = The geometric median on Riemannian manifolds with application to robust atlas estimation\n | journal = NeuroImage \n | volume = 45\n | year = 2009\n | pages = s143–s152 \n | doi = 10.1016/j.neuroimage.2008.10.052 \n | pmid = 19056498 \n | issue = 1 Suppl \n | pmc = 2735114 \n | ref = harv}}\n*{{cite journal|first=J. B. S.|last=Haldane|authorlink=J. B. S. Haldane|title=Note on the median of a multivariate distribution|journal=Biometrika|year=1948|volume=35|issue=3–4|pages=414–417|doi=10.1093/biomet/35.3-4.414|ref=harv}}\n*{{cite journal\n | last1 = Krarup | first1 = Jakob\n | last2 = Vajda | first2 = Steven\n | doi = 10.1093/imaman/8.3.215\n | issue = 3\n | journal = IMA Journal of Mathematics Applied in Business and Industry\n | mr = 1473041\n | pages = 215–224\n | title = On Torricelli's geometrical solution to a problem of Fermat\n | volume = 8\n | year = 1997\n | ref = harv}}\n*{{cite journal\n | last = Kuhn | first = Harold W. | authorlink = Harold W. Kuhn\n | title = A note on Fermat's problem\n | journal = [[Mathematical Programming]]\n | year = 1973\n | volume = 4\n | issue = 1\n | pages = 98–107\n | doi = 10.1007/BF01584648\n | ref = harv}}\n*{{cite conference|title=Some problems of estimation and testing in multivariate statistical process control|first1=Martin|last1=Lawera|first2=James R.|last2=Thompson|author2-link=James R. Thompson (statistician)|year=1993|pages=99–126|url=http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA390709|booktitle=Proceedings of the 38th Conference on the Design of Experiments|series=U.S. Army Research Office Report|volume=93-2|ref=harv}}\n*{{cite journal\n | last1 = Lopuhaä | first1 = Hendrick P.\n | last2 = Rousseeuw | first2 = Peter J. | author2-link = Peter Rousseeuw\n | title = Breakdown points of affine equivariant estimators of multivariate location and covariance matrices\n | year = 1991\n | journal = [[Annals of Statistics]]\n | volume = 19\n | pages = 229–248\n | issue = 1\n | doi = 10.1214/aos/1176347978\n | ref = harv\n | jstor=2241852}}\n*{{Cite book\n | first1 = Jiawang | last1 = Nie | first2 = Pablo A. |last2 = Parrilo | first3 = Bernd | last3 = Sturmfels | author3-link = Bernd Sturmfels\n | contribution = Semidefinite representation of the ''k''-ellipse\n | series = IMA Volumes in Mathematics and its Applications\n | volume = 146\n | editor1-first = A. | editor1-last = Dickenstein\n | editor2-first = F.-O. | editor2-last = Schreyer\n | editor3-first = A.J. | editor3-last = Sommese\n | publisher = Springer-Verlag | pages = 117–132 | year = 2008 | arxiv = math/0702005 \n | title = Algorithms in Algebraic Geometry\n | ref = harv| bibcode = 2007math......2005N}}\n*{{cite journal\n | last = Ostresh | first = L.\n | title = Convergence of a Class of Iterative Methods for Solving Weber Location Problem\n | year = 1978\n | journal = [[Operations Research (journal)|Operations Research]]\n | volume = 26\n | pages = 597–609\n | doi = 10.1287/opre.26.4.597\n | ref = harv\n | issue = 4}}\n*{{cite journal|title=Four-point Fermat location problems revisited. New proofs and extensions of old results|first=Frank|last=Plastria|authorlink=Frank Plastria|year=2006|doi=10.1093/imaman/dpl007|journal=IMA Journal of Management Mathematics|url=http://mosi.vub.ac.be/papers/Plastria2005_Fegnano.pdf|ref=harv|zbl=1126.90046|volume=17|issue=4|pages=387–396}}.\n*{{cite journal\n | last = Spain | first = P. G.\n | issue = 2\n | journal = Mathematics Magazine\n | jstor = 2690672?origin=pubexport\n | mr = 1573157\n | pages = 131–133\n | title = The Fermat Point of a Triangle\n | volume = 69\n | year = 1996\n | ref = harv}}\n*{{cite journal\n | last1 = Vardi | first1 = Yehuda\n | last2 = Zhang | first2 = Cun-Hui\n | doi = 10.1073/pnas.97.4.1423\n | issue = 4\n | journal = Proceedings of the National Academy of Sciences of the United States of America\n | mr = 1740461\n | pages = 1423–1426 (electronic)\n | title = The multivariate ''L''<sub>1</sub>-median and associated data depth\n | volume = 97\n | year = 2000\n | ref = harv| pmc = 26449\n | bibcode = 2000PNAS...97.1423V\n }}\n*{{cite book\n | last = Weber | first = Alfred | authorlink = Alfred Weber\n | title = Über den Standort der Industrien, Erster Teil: Reine Theorie des Standortes\n | location = Tübingen\n | publisher = Mohr\n | year = 1909\n | ref = harv}}\n*{{cite journal\n | last = Wesolowsky | first = G.\n | title = The Weber problem: History and perspective\n | journal = Location Science\n | volume = 1\n | pages = 5–23\n | year = 1993\n | ref = harv}}\n*{{cite journal\n | last = Weiszfeld | first = E. | authorlink = Andrew Vázsonyi\n | title = Sur le point pour lequel la somme des distances de ''n'' points donnes est minimum\n | journal = [[Tohoku Mathematical Journal]]\n | volume = 43\n | year = 1937\n | pages = 355–386\n | ref = harv}}\n{{refend}}\n\n[[Category:Means]]\n[[Category:Multivariate statistics]]\n[[Category:Nonparametric statistics]]\n[[Category:Mathematical optimization]]\n[[Category:Geometric algorithms]]\n[[Category:Descriptive statistics]]"
    },
    {
      "title": "Goal programming",
      "url": "https://en.wikipedia.org/wiki/Goal_programming",
      "text": "{{short description|Branch of multiobjective optimization}}\n'''Goal programming''' is a branch of [[multiobjective optimization]], which in turn is a branch of [[multi-criteria decision analysis]] (MCDA). This is an optimization programme. It can be thought of as an extension or generalisation of [[linear programming]] to handle multiple, normally conflicting objective measures. Each of these measures is given a goal or target value to be achieved. Unwanted deviations from this set of target values are then minimised in an achievement function. This can be a [[vector (mathematics)|vector]] or a [[weighted sum]] dependent on the goal programming variant used. As satisfaction of the target is deemed to satisfy the decision maker(s), an underlying [[satisficing]] philosophy is assumed. Goal programming is used to perform three types of analysis:\n# Determine the required resources to achieve a desired set of objectives.\n# Determine the degree of attainment of the goals with the available resources.\n# Providing the best satisfying solution under a varying amount of resources and priorities of the goals.\n\n== History ==\nGoal programming was first used by Charnes, [[William W. Cooper|Cooper]] and Ferguson in 1955,<ref>A Charnes, [[William W. Cooper|WW Cooper]], R Ferguson (1955) Optimal estimation of executive compensation by linear programming, Management Science, 1, 138-151.</ref> although the actual name first appeared in a 1961 text by Charnes and Cooper.<ref>A Charnes, WW Cooper (1961) Management models and industrial applications of linear programming, Wiley, New York</ref> Seminal works by Lee,<ref>SM Lee (1972) Goal programming for decision analysis, Auerback, Philadelphia</ref> Ignizio,<ref name= \"IG\">JP Ignizio (1976) Goal programming and extensions, Lexington Books, Lexington, MA.</ref> Ignizio and Cavalier,<ref>JP Ignizio, TM Cavalier (1994) Linear programming, Prentice Hall.</ref>  and [[Carlos Romero López|Romero]] <ref name= \"Rom\">C Romero (1991) Handbook of critical issues in goal programming, Pergamon Press, Oxford.</ref> followed. Schniederjans gives in a bibliography of a large number of pre-1995 articles relating to goal programming,<ref>MJ Scniederjans (1995) Goal programming methodology and applications, Kluwer publishers, Boston.</ref> and Jones and Tamiz give an annotated bibliography of the period 1990-2000.<ref name= \"DFJ\">DF Jones, M Tamiz (2002) Goal programming in the period 1990-2000, in Multiple Criteria Optimization: State of the art annotated bibliographic surveys, M. Ehrgott and X.Gandibleux (Eds.), 129-170. Kluwer</ref> A recent textbook by Jones and Tamiz .<ref name=\"JT\">Jones DF, Tamiz M (2010) Practical Goal Programming, Springer Books.</ref> gives a comprehensive overview of the state-of-the-art in goal programming.\n\nThe first engineering application of goal programming, due to Ignizio in 1962, was the design and placement of the antennas employed on the second stage of the [[Saturn V]]. This was used to launch the Apollo space capsule that landed the first men on the moon.\n\n== Variants ==\nThe initial goal programming formulations ordered the unwanted deviations into a number of priority levels, with the minimisation of a deviation in a  higher priority level being infinitely more important than any deviations in lower priority levels. This is known as ''[[lexicographic]]'' or pre-emptive goal programming. Ignizio<ref name= \"IG\"/> gives an algorithm showing how a lexicographic goal programme can be solved as a series of linear programmes. Lexicographic goal programming is used when there exists a clear priority ordering amongst the goals to be achieved.\n\nIf the decision maker is more interested in direct comparisons of the objectives then ''weighted'' or non-pre-emptive goal programming should be used. In this case all the unwanted deviations  are multiplied by weights, reflecting their relative importance, and added together as a single sum to form the achievement function. Deviations measured in different units cannot be summed directly due to the phenomenon of [[unit commensurability|incommensurability]].\n\nHence each unwanted deviation is multiplied by a normalisation constant to allow direct comparison. Popular choices for normalisation constants are the goal target value of the corresponding objective (hence turning all deviations into percentages) or the range of the corresponding objective (between the best and the worst possible values, hence mapping all deviations onto a zero-one range).<ref name= \"Rom\"/> For decision makers more interested in obtaining a balance between the competing objectives, ''Chebyshev'' goal programming is used. Introduced by Flavell in 1976,<ref>RB Flavell (1976) A new goal programming formulation, Omega, 4, 731-732.</ref> this variant seeks to minimise the maximum unwanted deviation, rather than the sum of deviations. This utilises the [[Chebyshev distance]] metric.\n\n== Strengths and weaknesses ==\nA major strength of goal programming is its simplicity and ease of use. This accounts for the large number of goal programming applications in many and diverse fields. Linear goal programmes can be solved using linear programming software as either a single linear programme, or in the case of the lexicographic variant, a series of connected linear programmes. \n \nGoal programming can hence handle relatively large numbers of variables, constraints and objectives. A debated weakness is the ability of goal programming to produce solutions that are not [[Pareto efficient]]. This violates a fundamental concept of [[decision theory]], that no rational decision maker will knowingly choose a solution that is not Pareto efficient. However, techniques are available<ref name= \"Rom\"/><ref>EL Hannan (1980) Non-dominance in goal programming, INFOR, 18, 300-309</ref><ref>M Tamiz, SK Mirrazavi, DF Jones (1999) Extensions of Pareto efficiency analysis to integer goal programming, Omega, 27, 179-188.</ref> to detect when this occurs and project the solution onto the Pareto efficient solution in an appropriate manner.\n\nThe setting of appropriate weights in the goal programming model is another area that has caused debate, with some authors<ref>SI Gass (1987) A process for determining priorities and weights for large scale linear goal programmes, Journal of the Operational Research Society, 37, 779-785.</ref> suggesting the use of the [[analytic hierarchy process]] or interactive methods<ref>BJ White (1996) Developing Products and Their Rhetoric from a Single Hierarchical Model, 1996 Proceedings of the Annual Conference of the Society for Technical Communication, 43, 223-224.</ref> for this purpose.\n\n== See also ==\n* [[Decision-making software]]\n\n== External links ==\n* [http://sourceforge.net/projects/lipside/ LiPS] — Free easy-to-use GUI program intended for solving linear, integer and goal programming problems.\n* [http://www.netikka.net/tsneti/pc/link/tslin.zip LINSOLVE] - Free Windows command-line window linear programming and linear goal programming]\n\n== References ==\n{{reflist}}\n\n{{DEFAULTSORT:Goal Programming}}\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis]]\n[[Category:Goal]]\n\n[[de:Entscheidung unter Sicherheit#Zielprogrammierung]]"
    },
    {
      "title": "Guess value",
      "url": "https://en.wikipedia.org/wiki/Guess_value",
      "text": "{{unreferenced|date=June 2012}}\n\nIn [[mathematical modeling]], a '''guess value''' is more commonly called a '''starting value''' or '''initial value'''. These are necessary for most [[Optimization (mathematics)|optimization]] problems which use [[search algorithms]], because those algorithms are mainly [[Deterministic algorithm|deterministic]] and [[iterative]], and they need to start somewhere. One common type of application is  [[nonlinear regression]].\n\n==Use==\nThe quality of the initial values can have a considerable impact on the success or lack of such of the search algorithm. This is because the [[fitness function]] or [[objective function]] (in many cases a sum of squared errors ([[Sum of squared errors of prediction|SSE]])) can have difficult shapes. In some parts of the search region, the function may increase exponentially, in others quadratically, and there may be regions where the function [[asymptotes]] to a [[Plateau (mathematics)|plateau]]. Starting values that fall in an exponential region can lead to algorithm failure because of [[arithmetic overflow]]. Starting values that fall in the asymptotic plateau region can lead to algorithm failure because of \"[[dithering]]\". Deterministic search algorithms may use a slope function to go to a minimum. If the slope is very small, then underflow errors can cause the algorithm to wander, seemingly aimlessly; this is dithering.\n\n==Finding value==\nGuess values can be determined a number of ways. Guessing is one of them. If one is familiar with the type of problem, then this is an educated guess or [[guesstimate]]. Other techniques include [[linearization]], solving [[simultaneous equations]], reducing [[dimensions]], treating the problem as a [[time series]], converting the problem to a (hopefully) [[linear]] [[differential equation]], and using [[mean]] values. Further methods for determining starting values and optimal values in their own right come from [[stochastic]] methods, the most commonly known of these being [[evolutionary algorithms]] and particularly [[genetic algorithms]].\n\n[[Category:Mathematical optimization]]\n[[Category:Regression analysis]]\n[[Category:Computational statistics]]"
    },
    {
      "title": "Highly optimized tolerance",
      "url": "https://en.wikipedia.org/wiki/Highly_optimized_tolerance",
      "text": "{{technical|date=June 2012}}\n\nIn [[applied mathematics]], '''highly optimized tolerance (HOT)''' is a method of generating [[power law]] behavior in systems by including a [[global optimization]] principle. It was developed by [[Jean M. Carlson]] in the early 2000s.<ref>{{Cite journal|last=Carlson|first=null|last2=Doyle|first2=null|date=2000-03-13|title=Highly optimized tolerance: robustness and design in complex systems|url=https://www.ncbi.nlm.nih.gov/pubmed/11018927|journal=Physical Review Letters|volume=84|issue=11|pages=2529–2532|doi=10.1103/PhysRevLett.84.2529|issn=1079-7114|pmid=11018927}}</ref> For some systems that display a characteristic scale, a global optimization term could potentially be added that would then yield power law behavior.  It has been used to generate and describe internet-like graphs, [[forest fire]] models and may also apply to biological systems.\n\n==Example==\nThe following is taken from Sornette's book.\n\nConsider a [[random variable]], <math>X</math>, that takes on values <math>x_i</math> with probability <math>p_i</math>.  Furthmore, lets assume for another parameter <math>r_i</math>\n:<math>x_i = r_i^{ - \\beta }</math>\nfor some fixed <math>\\beta</math>.  We then want to minimize\n:<math> L = \\sum_{i=0}^{N-1} p_i x_i </math>\nsubject to the constraint\n:<math> \\sum_{i=0}^{N-1} r_i = \\kappa </math>\nUsing [[Lagrange multipliers]], this gives\n:<math> p_i \\propto x_i^{ - ( 1 + 1/ \\beta) } </math>\ngiving us a power law.  The global optimization of minimizing the energy along with the power law dependence between <math>x_i</math> and <math>r_i</math> gives us a power law distribution in probability.\n\n==See also==\n* [[self-organized criticality]]\n\n==References==\n<references />\n*{{citation\n | last1 = [[Jean M. Carlson| Carlson]] | first1 = J. M.\n | last2 = Doyle | first2 = John\n | date = August 1999\n | doi = 10.1103/PhysRevE.60.1412\n | issue = 2\n | journal = [[Physical Review E]]\n | pages = 1412–1427\n | title = Highly optimized tolerance: A mechanism for power laws in designed systems\n | volume = 60| arxiv = cond-mat/9812127| bibcode = 1999PhRvE..60.1412C}}.\n*{{citation\n | last1 = Carlson | first1 = J. M.\n | last2 = Doyle | first2 = John\n | date = March 2000\n | doi = 10.1103/PhysRevLett.84.2529\n | issue = 11\n | journal = [[Physical Review Letters]]\n | pages = 2529–2532\n | title = Highly Optimized Tolerance: Robustness and Design in Complex Systems\n | volume = 84\n | bibcode=2000PhRvL..84.2529C}}.\n*{{citation\n | last1 = Doyle | first1 = John\n | last2 = Carlson | first2 = J. M.\n | date = June 2000\n | doi = 10.1103/PhysRevLett.84.5656\n | issue = 24\n | journal = [[Physical Review Letters]]\n | pages = 5656–5659\n | title = Power Laws, Highly Optimized Tolerance, and Generalized Source Coding\n | volume = 84\n | bibcode=2000PhRvL..84.5656D\n | pmid=10991018}}.\n*{{citation\n | last = Greene | first = Katie\n | doi = 10.2307/4016836\n | issue = 15\n | journal = [[Science News]]\n | pages = 230–230\n | title = Untangling a web: The internet gets a new look\n | url = http://www.thefreelibrary.com/Untangling+a+Web%3A+the+Internet+gets+a+new+look.-a0138661490\n | volume = 168\n | year = 2005}}.\n*{{citation\n | last1 = Li | first1 = Lun\n | last2 = Alderson | first2 = David\n | last3 = Doyle | first3 = John C.\n | last4 = Willinger | first4 = Walter\n | arxiv = cond-mat/0501169\n | issue = 4\n | journal = Internet Mathematics\n | mr = 2241756\n | pages = 431–523\n | title = Towards a theory of scale-free graphs: definition, properties, and implications\n | url = http://projecteuclid.org/euclid.im/1150477667\n | volume = 2\n | year = 2005 | doi=10.1080/15427951.2005.10129111}}.\n*{{citation\n | last1 = Robert | first1 = Carl\n | last2 = Carlson | first2 = J. M.\n | last3 = Doyle | first3 = John\n | date = April 2001\n | doi = 10.1103/PhysRevE.63.056122\n | issue = 5\n | journal = [[Physical Review E]]\n | page = 056122\n | title = Highly optimized tolerance in epidemic models incorporating local optimization and regrowth\n | url = http://link.aps.org/doi/10.1103/PhysRevE.63.056122\n | volume = 63| bibcode = 2001PhRvE..63e6122R}}.\n*{{citation\n | last = Sornette | first = Didier | author-link = Didier Sornette\n | doi = 10.1007/978-3-662-04174-1\n | isbn = 3-540-67462-4\n | location = Berlin\n | mr = 1782504\n | publisher = Springer-Verlag\n | series = Springer Series in Synergetics\n | title = Critical Phenomena in Natural Sciences: Chaos, Fractals, Selforganization and Disorder: Concepts and Tools\n | year = 2000}}.\n*{{citation\n | last1 = Zhou | first1 = Tong\n | last2 = Carlson | first2 = J. M.\n | doi = 10.1103/PhysRevE.62.3197\n | journal = Physical Review E\n | pages = 3197–3204\n | title = Dynamics and changing environments in highly optimized tolerance\n | volume = 62\n | year = 2000| bibcode = 2000PhRvE..62.3197Z}}.\n*{{citation\n | last1 = Zhou | first1 = Tong\n | last2 = Carlson | first2 = J. M.\n | last3 = Doyle | first3 = John\n | doi = 10.1073/pnas.261714399\n | issue = 4\n | journal = [[Proceedings of the National Academy of Sciences]]\n | pages = 2049–2054\n | title = Mutation, specialization, and hypersensitivity in highly optimized tolerance\n | volume = 99\n | year = 2002 | pmid=11842230 | pmc=122317| bibcode = 2002PNAS...99.2049Z}}.\n\n[[Category:Mathematical optimization]]\n\n\n{{sci-stub}}"
    },
    {
      "title": "Himmelblau's function",
      "url": "https://en.wikipedia.org/wiki/Himmelblau%27s_function",
      "text": "{{multiple image\n   | direction = vertical\n   | width     = 300\n   | header    = Himmelblau's function\n   | image1    = Himmelblau function.svg\n   | caption1  = In 3D\n   | image2    = Himmelblau contour.svg\n   | caption2  = Log-spaced level curve plot  \n}}\n\nIn [[mathematical optimization]], '''Himmelblau's function''' is a multi-modal function, used to test the performance of [[optimization algorithm]]s.\nThe function is defined by:\n\n: <math>f(x, y) = (x^2+y-11)^2 + (x+y^2-7)^2.\\quad</math>\n\nIt has one local maximum at <math>x = -0.270845 </math> and <math>y = -0.923039 </math> where <math>f(x,y) = 181.617 </math>, and four identical local minima:\n\n* <math>f(3.0, 2.0) = 0.0, \\quad</math>\n* <math>f(-2.805118, 3.131312) = 0.0, \\quad</math>\n* <math>f(-3.779310, -3.283186) = 0.0, \\quad</math>\n* <math>f(3.584428, -1.848126) = 0.0. \\quad</math>\n\nThe locations of all the [[Maxima and minima|minima]] can be found analytically. However, because they are roots of [[cubic polynomial]]s, when written in terms of radicals, the expressions are somewhat complicated.{{citation needed|date=November 2011}}\n\nThe function is named after [[David Mautner Himmelblau]] (1924–2011), who introduced it.<ref>{{cite book |last=Himmelblau |first=D. |title=Applied Nonlinear Programming |location= |publisher=McGraw-Hill |year=1972 |isbn=0-07-028921-2 }}</ref>\n\n== See also ==\n*[[Test functions for optimization]]\n\n== References ==\n{{reflist}}\n\n[[Category:Mathematical optimization]]\n\n\n{{mathanalysis-stub}}"
    },
    {
      "title": "Hyperparameter optimization",
      "url": "https://en.wikipedia.org/wiki/Hyperparameter_optimization",
      "text": "In [[machine learning]], '''hyperparameter optimization''' or tuning is the problem of choosing a set of optimal [[Hyperparameter (machine learning)|hyperparameters]] for a learning algorithm. A hyperparameter is a [[parameter]] whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.\n\nThe same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined [[loss function]] on given independent data.<ref name=abs1502.02127>{{cite arxiv |eprint=1502.02127|last1=Claesen|first1=Marc|title=Hyperparameter Search in Machine Learning|author2=Bart De Moor|class=cs.LG|year=2015}}</ref>  The objective function takes a tuple of hyperparameters and returns the associated loss.<ref name=abs1502.02127/> [[Cross-validation (statistics)|Cross-validation]] is often used to estimate this generalization performance.<ref name=\"bergstra\">{{cite journal|last1=Bergstra|first1=James|last2=Bengio|first2=Yoshua|year=2012|title=Random Search for Hyper-Parameter Optimization|url=http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf|journal=Journal of Machine Learning Research|volume=13|pages=281–305}}</ref>\n\n== Approaches ==\n\n=== Grid search ===\nThe traditional way of performing hyperparameter optimization has been ''grid search'', or a ''parameter sweep'', which is simply an [[Brute-force search|exhaustive searching]] through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by [[Cross-validation (statistics)|cross-validation]] on the training set<ref>Chin-Wei Hsu, Chih-Chung Chang and Chih-Jen Lin (2010). [http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf A practical guide to support vector classification]. Technical Report, [[National Taiwan University]].</ref>\nor evaluation on a held-out validation set.<ref>{{cite journal \n| vauthors = Chicco D\n| title = Ten quick tips for machine learning in computational biology \n| journal = BioData Mining\n| volume = 10\n| issue =  35\n| pages = 35 \n| date = December 2017 \n| pmid = 29234465\n| doi = 10.1186/s13040-017-0155-3\n| pmc= 5721660}}</ref>\n\nSince the parameter space of a machine learner may include real-valued or unbounded value spaces for certain parameters, manually set bounds and discretization may be necessary before applying grid search.\n\nFor example, a typical soft-margin [[support vector machine|SVM]] [[statistical classification|classifier]] equipped with an [[radial basis function kernel|RBF kernel]] has at least two hyperparameters that need to be tuned for good performance on unseen data: a regularization constant ''C'' and a kernel hyperparameter γ. Both parameters are continuous, so to perform grid search, one selects a finite set of \"reasonable\" values for each, say\n\n:<math>C \\in \\{10, 100, 1000\\}</math>\n:<math>\\gamma \\in \\{0.1, 0.2, 0.5, 1.0\\}</math>\n\nGrid search then trains an SVM with each pair (''C'', γ) in the [[Cartesian product]] of these two sets and evaluates their performance on a held-out validation set (or by internal cross-validation on the training set, in which case multiple SVMs are trained per pair). Finally, the grid search algorithm outputs the settings that achieved the highest score in the validation procedure.\n\nGrid search suffers from the [[curse of dimensionality]], but is often [[embarrassingly parallel]] because typically the hyperparameter settings it evaluates are independent of each other.<ref name=\"bergstra\"/>\n\n=== Random search ===\n{{main|Random search}}\n\nRandom Search replaces the exhaustive enumeration of all combinations by selecting them randomly. This can be simply applied to the discrete setting described above, but also generalizes to continuous and mixed spaces. It can outperform Grid search, especially when only a small number of hyperparameters affects the final performance of the machine learning algorithm.<ref name=\"bergstra\" /> In this case, the optimization problem is said to have a low intrinsic dimensionality.<ref>{{Cite journal|last=Ziyu|first=Wang|last2=Frank|first2=Hutter|last3=Masrour|first3=Zoghi|last4=David|first4=Matheson|last5=Nando|first5=de Feitas|date=2016|title=Bayesian Optimization in a Billion Dimensions via Random Embeddings|journal=Journal of Artificial Intelligence Research|language=en|volume=55|pages=361–387|doi=10.1613/jair.4806}}</ref> Random Search is also [[embarrassingly parallel]], and additionally allows the inclusion of prior knowledge by specifying the distribution from which to sample.\n\n=== Bayesian optimization ===\n{{main|Bayesian optimization}}\n\nBayesian optimization is a global optimization method for noisy black-box functions.  Applied to hyperparameter optimization, Bayesian optimization builds a probabilistic model of the function mapping from hyperparameter values to the objective evaluated on a validation set. By iteratively evaluating a promising hyperparameter configuration based on the current model, and then updating it, Bayesian optimization, aims to gather observations revealing as much information as possible about this function and, in particular, the location of the optimum. It tries to balance exploration (hyperparameters for which the outcome is most uncertain) and exploitation (hyperparameters expected close to the optimum). In practice, Bayesian optimization has been shown<ref name=\"hutter\">{{Citation\n | last = Hutter\n | first = Frank\n | last2 = Hoos\n | first2 = Holger\n | last3 = Leyton-Brown\n | first3 = Kevin\n | title = Sequential model-based optimization for general algorithm configuration\n | journal = Learning and Intelligent Optimization\n | volume = 6683\n | pages = 507–523\n | year = 2011\n | url = http://www.cs.ubc.ca/labs/beta/Projects/SMAC/papers/11-LION5-SMAC.pdf | doi = 10.1007/978-3-642-25566-3_40\n | citeseerx = 10.1.1.307.8813\n | series = Lecture Notes in Computer Science\n | isbn = 978-3-642-25565-6\n }}</ref><ref name=\"bergstra11\">{{Citation\n | last = Bergstra\n | first = James\n | last2 = Bardenet\n | first2 = Remi\n | last3 = Bengio\n | first3 = Yoshua\n | last4 = Kegl\n | first4 = Balazs\n | title = Algorithms for hyper-parameter optimization\n | journal = Advances in Neural Information Processing Systems\n | year = 2011\n | url = http://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf }}</ref><ref name=\"snoek\">{{cite journal\n | last = Snoek\n | first = Jasper\n | last2 = Larochelle\n | first2 = Hugo\n | last3 = Adams\n | first3 = Ryan\n | title = Practical Bayesian Optimization of Machine Learning Algorithms\n | journal = Advances in Neural Information Processing Systems\n | volume =<!-- -->\n | pages =<!-- -->\n | year = 2012\n | url = http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf\n | bibcode = 2012arXiv1206.2944S\n | arxiv = 1206.2944\n }}</ref><ref name=\"thornton\">{{cite journal\n | last = Thornton\n | first = Chris\n | last2 = Hutter\n | first2 = Frank\n | last3 = Hoos\n | first3 = Holger\n | last4 = Leyton-Brown\n | first4 = Kevin\n | title = Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms\n | journal = Knowledge Discovery and Data Mining\n | volume = <!-- -->\n | pages = <!-- -->\n | year = 2013\n | url = http://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/autoweka.pdf\n | bibcode = 2012arXiv1208.3719T\n | arxiv = 1208.3719\n }}</ref> to obtain better results in fewer evaluations compared to grid search and random search, due to the ability to reason about the quality of experiments before they are run.\n\n=== Gradient-based optimization ===\nFor specific learning algorithms, it is possible to compute the gradient with respect to hyperparameters and then optimize the hyperparameters using gradient descent. The first usage of these techniques was focused on neural networks.<ref>{{cite journal |last1=Larsen|first1=Jan|last2= Hansen |first2=Lars Kai|last3=Svarer|first3=Claus|last4=Ohlsson|first4=M|title=Design and regularization of neural networks: the optimal use of a validation set|journal=Proceedings of the 1996 IEEE Signal Processing Society Workshop|date=1996}}</ref> Since then, these methods have been extended to other models such as [[support vector machine]]s<ref>{{cite journal |author1=Olivier Chapelle |author2=Vladimir Vapnik |author3=Olivier Bousquet |author4=Sayan Mukherjee |title=Choosing multiple parameters for support vector machines |journal=Machine Learning |year=2002 |volume=46 |pages=131–159 |url=http://www.chapelle.cc/olivier/pub/mlj02.pdf | doi = 10.1023/a:1012450327387 }}</ref> or logistic regression.<ref>{{cite journal |author1 =Chuong B|author2= Chuan-Sheng Foo|author3=Andrew Y Ng|journal = Advances in Neural Information Processing Systems 20|title = Efficient multiple hyperparameter learning for log-linear models|year =2008}}</ref>\n\nA different approach in order to obtain a gradient with respect to hyperparameters consists in differentiating the steps of an iterative optimization algorithm using  [[automatic differentiation]].<ref>{{cite journal|last1=Domke|first1=Justin|title=Generic Methods for Optimization-Based Modeling|journal=Aistats |date=2012|volume=22|url=http://www.jmlr.org/proceedings/papers/v22/domke12/domke12.pdf}}</ref><ref name=abs1502.03492>{{cite arXiv |last1=Maclaurin|first1=Douglas|last2=Duvenaud|first2=David|last3=Adams|first3=Ryan P.|eprint=1502.03492|title=Gradient-based Hyperparameter Optimization through Reversible Learning|class=stat.ML|date=2015}}</ref>\n\n=== Evolutionary optimization ===\n{{main|Evolutionary algorithm}}\n\nEvolutionary optimization is a methodology for the global optimization of noisy black-box functions. In hyperparameter optimization, evolutionary optimization uses [[evolutionary algorithms]] to search the space of hyperparameters for a given algorithm.<ref name=\"bergstra11\" /> Evolutionary hyperparameter optimization follows a [[Evolutionary algorithm#Implementation|process]] inspired by the biological concept of [[evolution]]:\n\n# Create an initial population of random solutions (i.e., randomly generate tuples of hyperparameters, typically 100+)\n# Evaluate the hyperparameters tuples and acquire their [[fitness function]] (e.g., 10-fold [[Cross-validation (statistics)|cross-validation]] accuracy of the machine learning algorithm with those hyperparameters)\n# Rank the hyperparameter tuples by their relative fitness\n# Replace the worst-performing hyperparameter tuples with new hyperparameter tuples generated through [[crossover (genetic algorithm)|crossover]] and [[mutation (genetic algorithm)|mutation]]\n# Repeat steps 2-4 until satisfactory algorithm performance is reached or algorithm performance is no longer improving\n\nEvolutionary optimization has been used in hyperparameter optimization for statistical machine learning algorithms,<ref name=\"bergstra11\" /> [[automated machine learning]], [[Deep learning#Deep neural networks|deep neural network]] architecture search,<ref name=\"miikkulainen1\">{{cite arxiv | vauthors = Miikkulainen R, Liang J, Meyerson E, Rawal A, Fink D, Francon O, Raju B, Shahrzad H, Navruzyan A, Duffy N, Hodjat B | year = 2017 | title = Evolving Deep Neural Networks |eprint=1703.00548| class = cs.NE }}</ref><ref name=\"jaderberg1\">{{cite arxiv | vauthors = Jaderberg M, Dalibard V, Osindero S, Czarnecki WM, Donahue J, Razavi A, Vinyals O, Green T, Dunning I, Simonyan K, Fernando C, Kavukcuoglu K | year = 2017 | title = Population Based Training of Neural Networks |eprint=1711.09846| class = cs.LG }}</ref> as well as training of the weights in deep neural networks.<ref name=\"such1\">{{cite arxiv | vauthors = Such FP, Madhavan V, Conti E, Lehman J, Stanley KO, Clune J | year = 2017 | title = Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning |eprint=1712.06567| class = cs.NE }}</ref>\n\n=== Population-based ===\nPopulation Based Training (PBT) learns both hyperparameter values and network weights. Multiple learning processes operate independently, using different hyperparameters. Poorly performing models are iteratively replaced with models that adopt modified hyperparameter values from a better performer. The modification allows the hyperparameters to evolve and eliminates the need for manual hypertuning. The process makes no assumptions regarding model architecture, loss functions or training procedures.<ref>{{cite arxiv|last=Li|first=Ang|last2=Spyra|first2=Ola|last3=Perel|first3=Sagi|last4=Dalibard|first4=Valentin|last5=Jaderberg|first5=Max|last6=Gu|first6=Chenjie|last7=Budden|first7=David|last8=Harley|first8=Tim|last9=Gupta|first9=Pramod|date=2019-02-05|title=A Generalized Framework for Population Based Training|eprint=1902.01894|class=cs.AI}}</ref>\n\n=== Others ===\n[[Radial basis function|RBF]]<ref name=abs1705.08520>{{cite arxiv |eprint=1705.08520|last1=Diaz|first1=Gonzalo|title=An effective algorithm for hyperparameter optimization of neural networks|last2=Fokoue|first2=Achille|last3=Nannicini|first3=Giacomo|last4=Samulowitz|first4=Horst|class=cs.AI|year=2017}}</ref> and [[spectral method|spectral]]<ref name=abs1706.00764>{{cite arxiv |eprint=1706.00764|last1=Hazan|first1=Elad|title=Hyperparameter Optimization: A Spectral Approach|last2=Klivans|first2=Adam|last3=Yuan|first3=Yang|class=cs.LG|year=2017}}</ref> approaches have also been developed.\n\n== Open-source software ==\n\n===Grid search===\n* [[scikit-learn]] is a Python package which includes [http://scikit-learn.sourceforge.net/modules/grid_search.html grid] search.\n*[https://github.com/autonomio/talos Talos] includes grid search for [[Keras]].\n\n===Random search===\n* [https://github.com/hyperopt/hyperopt hyperopt], also via [https://github.com/maxpumperla/hyperas hyperas] and [https://github.com/hyperopt/hyperopt-sklearn hyperopt-sklearn], are Python packages which include random search.\n* [[scikit-learn]] is a Python package which includes [http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html random] search.\n*[https://github.com/autonomio/talos Talos] includes a customizable random search for [[Keras]].\n\n===Bayesian===\n* [https://github.com/automl/auto-sklearn Auto-sklearn]<ref name=\"autosklearn\">{{cite journal | vauthors = Feurer M, Klein A, Eggensperger K, Springenberg J, Blum M, Hutter F | year = 2015 | title = Efficient and Robust Automated Machine Learning | url = https://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning | journal = Advances in Neural Information Processing Systems 28 (NIPS 2015) | pages = 2962–2970 }}</ref> is a Bayesian hyperparameter optimization layer on top of [[scikit-learn]].\n* [https://github.com/facebook/Ax Ax]<ref name=AxBoTorch>{{cite web |url=https://ai.facebook.com/blog/open-sourcing-ax-and-botorch-new-ai-tools-for-adaptive-experimentation/ |title=Open-sourcing Ax and BoTorch: New AI tools for adaptive experimentation |year=2019}}</ref> is a Python-based experimentation platform that supports Bayesian optimization and bandit optimization as exploration strategies.\n* [https://github.com/baptistar/BOCS BOCS] is a Matlab package which uses [[semidefinite programming]] for minimizing a black-box function over discrete inputs.<ref name=\"arXiv:1806.08838\">{{cite arXiv |year=2018 |title=Bayesian Optimization of Combinatorial Structures |eprint=1806.08838|last1=Baptista |first1=Ricardo |last2=Poloczek |first2=Matthias |class=stat.ML }}</ref> A Python 3 implementation is also included.\n* [https://github.com/automl/HpBandSter HpBandSter] is a Python package which combines Bayesian optimization with bandit-based methods.<ref name=\"arXiv:1807.01774\">{{cite arXiv |year=2018 |title=BOHB: Robust and Efficient Hyperparameter Optimization at Scale |eprint=1807.01774|last1=Falkner |first1=Stefan |last2=Klein |first2=Aaron |last3=Hutter |first3=Frank |class=stat.ML }}</ref>\n* [https://github.com/mlr-org/mlrMBO mlrMBO], also with [https://github.com/mlr-org/mlr mlr], is an [[R (programming language)|R]] package for model-based/Bayesian optimization of black-box functions.\n* [https://github.com/scikit-optimize/scikit-optimize scikit-optimize] is a Python package or sequential model-based optimization with a scipy.optimize interface.<ref name=skopt>{{Cite web|url=https://scikit-optimize.github.io/|title=skopt API documentation|website=scikit-optimize.github.io}}</ref>\n* [https://github.com/automl/SMAC3 SMAC] SMAC is a Python/Java library implementing Bayesian optimization.<ref name=\"SMAC\">{{cite journal | vauthors = Hutter F, Hoos HH, Leyton-Brown K | title = Sequential Model-Based Optimization for General Algorithm Configuration | url = https://www.cs.ubc.ca/~hutter/papers/10-TR-SMAC.pdf | journal = Proceedings of the Conference on Learning and Intelligent OptimizatioN (LION 5)}}</ref>\n* [https://github.com/PhilippPro/tuneRanger tuneRanger] is an R package for tuning random forests using model-based optimization.\n\n===Evolutionary===\n* [https://github.com/DEAP/deap deap] is a Python framework for general evolutionary computation which is flexible and integrates with parallelization packages like [https://github.com/soravux/scoop scoop] and [[Apache Spark|pyspark]], and other Python frameworks like [[Scikit-learn|sklearn]] via [https://github.com/rsteca/sklearn-deap sklearn-deap].\n* [https://github.com/joeddav/devol devol] is a Python package that performs Deep Neural Network architecture search using [[genetic programming]].\n* [https://github.com/facebookresearch/nevergrad nevergrad]<ref name=nevergrad_issue1/> is a Python package which includes population control methods and particle swarm optimization.<ref name=nevergrad/>\n\n===Other===\n* [[dlib]]<ref name=dlib_github>{{Cite web|url=https://github.com/davisking/dlib|title=A toolkit for making real world machine learning and data analysis applications in C++: davisking/dlib|date=February 25, 2019|via=GitHub}}</ref> is a C++ package with a Python API which has a parameter-free optimizer based on [https://arxiv.org/abs/1703.02628 LIPO] and [[trust region]] optimizers working in tandem.<ref name=dlib_blog>{{cite web |last1=King |first1=Davis |title=A Global Optimization Algorithm Worth Using |url=http://blog.dlib.net/2017/12/a-global-optimization-algorithm-worth.html}}</ref>\n* [https://github.com/callowbird/Harmonica Harmonica] is a Python package for spectral hyperparameter optimization.<ref name=abs1706.00764/>\n* [https://github.com/hyperopt/hyperopt hyperopt], also via [https://github.com/maxpumperla/hyperas hyperas] and [https://github.com/hyperopt/hyperopt-sklearn hyperopt-sklearn], are Python packages which include [[kernel density estimation|Tree of Parzen Estimators]] based distributed hyperparameter optimization.\n* [https://github.com/facebookresearch/nevergrad nevergrad]<ref name=nevergrad_issue1>{{Cite web|url=https://github.com/facebookresearch/nevergrad/issues/1|title=[QUESTION] How to use to optimize NN hyperparameters · Issue #1 · facebookresearch/nevergrad|website=GitHub}}</ref> is a Python package for gradient-free optimization using techniques such as differential evolution, sequential quadratic programming, fastGA, covariance matrix adaptation, population control methods, and particle swarm optimization.<ref name=nevergrad>{{Cite web|url=https://code.fb.com/ai-research/nevergrad/|title=Nevergrad: An open source tool for derivative-free optimization|date=December 20, 2018}}</ref>\n* [https://github.com/Microsoft/nni nni] is a Python package which includes hyperparameter tuning for neural networks in local and distributed environments. Its techniques include TPE, random, anneal, evolution, SMAC, batch, grid, and hyperband.\n* [https://github.com/CMA-ES/pycma pycma] is a Python implementation of [[CMA-ES|Covariance Matrix Adaptation Evolution Strategy]].\n* [https://github.com/coin-or/rbfopt rbfopt] is a Python package that uses a [[radial basis function]] model<ref name=abs1705.08520/>\n\n== Commercial services ==\n* [https://aws.amazon.com/sagemaker/ Amazon Sagemaker] uses Gaussian processes to tune hyperparameters. \n* [https://bigml.com/api/optimls BigML OptiML] supports mixed search domains\n* [https://cloud.google.com/ml-engine/docs/tensorflow/using-hyperparameter-tuning Google HyperTune] supports mixed search domains\n* [https://indiesolver.com Indie Solver] supports multiobjective, multifidelity and constraint optimization\n* [https://mindfoundry.ai/OPTaaS Mind Foundry OPTaaS] supports mixed search domains, multiobjective, constraints, parallel optimization and surrogate models.\n* [https://sigopt.com SigOpt] supports mixed search domains, multiobjective, multisolution, multifidelity, constraint (linear and black-box), and parallel optimization.\n\n== See also ==\n* [[Automated machine learning]]\n* [[Neural architecture search]]\n* [[Meta-optimization]]\n* [[Model selection]]\n* [[Self-tuning]]\n\n== References ==\n{{Reflist|30em}}\n\n[[Category:Machine learning]]\n[[Category:Mathematical optimization]]\n[[Category:Model selection]]"
    },
    {
      "title": "International Society for Structural and Multidisciplinary Optimization",
      "url": "https://en.wikipedia.org/wiki/International_Society_for_Structural_and_Multidisciplinary_Optimization",
      "text": "{{more citations needed|date=June 2013}}\nThe '''International Society for Structural and Multidisciplinary Optimization''' is a [[learned society]] in the field of [[multidisciplinary design optimization]] that was founded in October 1991. It has more than 1000 members in 45 countries.<ref name=\"about\">{{cite web|author=|url=http://www.issmo.net/about/welcome.asp|title=About ISSMO|publisher=International Society for Structural and Multidisciplinary Optimization|date=|accessdate=2013-06-11|archive-url=https://archive.is/20130620204222/http://www.issmo.net/about/welcome.asp|archive-date=2013-06-20|dead-url=yes|df=}}</ref> The current president is [[Ole Sigmund]] ([[Technical University of Denmark]]).<ref>{{cite web|author=|url=http://www.issmo.net/about/committee.asp|title=Executive Committee|publisher=International nongovernmental organizations|date=|accessdate=2013-06-11|archive-url=https://archive.is/20130620204250/http://www.issmo.net/about/committee.asp|archive-date=2013-06-20|dead-url=yes|df=}}</ref> The society is an affiliated organization of the [[International Union of Theoretical and Applied Mechanics]] (IUTAM).<ref>{{cite web |url=http://iutam.org/?page_id=1049 |title=Affiliated Organizations |publisher=International Union of Theoretical and Applied Mechanics |date=2013 |accessdate=2013-06-11}}</ref>\n\n== Objectives ==\nThe objectives are:<ref name=\"about\"/>\n<blockquote>\n* to stimulate and promote research into all aspects of the optimal design of structures and related topics, including engineering systems consisting partially of structures and/or fluids;\n* to encourage practical applications of optimization methods and the corresponding software development in all branches of technology;\n* to foster the interchange of ideas amongst various fields contributing to structural and multidisciplinary optimization;\n* to support the role of optimization in multidisciplinary design;\n* to provide a framework for the organization of meetings and other means for the dissemination of knowledge on structural optimization; and\n* to promote teaching of structural optimization in tertiary institutions.\n</blockquote>\n\nThe society works towards these objectives by organizing a biennial \"World Congress of Structural and Multidisciplinary Optimization\" and publishing an official journal, ''[[Structural and Multidisciplinary Optimization]]'', in collaboration with [[Springer Science+Business Media]].<ref>{{cite web |url=https://www.springer.com/materials/mechanics/journal/158 |title=Structural and Multidisciplinary Optimization |publisher=Springer Science+Business Media |date= |accessdate=2013-06-11}}</ref>\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* {{Official website|http://www.issmo.net}}\n\n[[Category:Organizations established in 1991]]\n[[Category:International learned societies]]\n[[Category:Mathematical optimization]]\n\n\n{{Org-stub}}"
    },
    {
      "title": "Jeep problem",
      "url": "https://en.wikipedia.org/wiki/Jeep_problem",
      "text": "{{About|mathematics problem |military exercises  to assess potential outcomes of an invasion of Iraq |\"Desert Crossing\" 1999}}\nThe '''jeep problem''',<ref name=wolfram>{{MathWorld|urlname = JeepProblem|title = Jeep Problem}}</ref> '''desert crossing problem'''<ref>{{cite book\n  | last = Gardner\n  | first = Martin\n  | authorlink = Martin Gardner\n  | title = My Best Mathematical and Logic Puzzles \n  | publisher = Dover\n  | date = 1994\n  | pages = 53\n  | isbn = 0-486-28152-3}}</ref> or '''exploration problem'''<ref name=coxeter>\"'''Exploration problems.''' Another common question is concerned with the maximum distance into a desert which could be reached from a frontier settlement by an explorer capable of carrying provisions that would last him for ''a'' days.\" [[W. W. Rouse Ball]] and [[H.S.M. Coxeter]] (1987). ''Mathematical Recreations and Essays'', Thirteenth Edition, Dover, p32. {{ISBN|0-486-25357-0}}.</ref> is a mathematics problem in which a [[Willys MB|jeep]] must maximise the distance it can travel into a desert with a given quantity of fuel. The jeep can only carry a fixed and limited amount of fuel, but it can leave fuel and collect fuel at fuel dumps anywhere in the desert.\n\nThe problem first appeared in the 9th-century collection ''[[Propositiones ad Acuendos Juvenes]]'' (''Problems to Sharpen the Young''), attributed to [[Alcuin]].<ref name=a>[https://www.jstor.org/stable/3620384 Problems to Sharpen the Young], John Hadley and David Singmaster, ''The Mathematical Gazette'', '''76''', #475 (March 1992), pp. 102&ndash;126.</ref>  The ''De viribus quantitatis'' (c. 1500) of [[Luca Pacioli]] also discusses the problem.  A modern treatment was given by [[Nathan Fine|N. J. Fine]] in 1947.<ref name=wolfram/>\n\n==Problem==\nThere are ''n'' units of fuel stored at a fixed base. The jeep can carry at most 1 unit of fuel at any time, and can travel 1 unit of distance on 1 unit of fuel (the jeep's fuel consumption is assumed to be constant). At any point in a trip the jeep may leave any amount of fuel that it is carrying at a fuel dump, or may collect any amount of fuel that was left at a fuel dump on a previous trip, as long as its fuel load never exceeds 1 unit. There are two variants of the problem:\n\n*'''Exploring the desert'''{{spaced ndash}} the jeep must return to the base at the end of every trip.\n*'''Crossing the desert'''{{spaced ndash}} the jeep must return to the base at the end of every trip except for the final trip, when the jeep travels as far as it can before running out of fuel.\n\nIn either case the objective is to maximise the distance travelled by the jeep on its final trip. Alternatively, the objective may be to find the least amount of fuel required to produce a final trip of a given distance.\n\nIn the classic problem the fuel in the jeep and at fuel dumps is treated as a [[continuous function|continuous]] quantity. More complex variations on the problem have been proposed in which the fuel can only be left or collected in discrete amounts.<ref>[http://page.mi.fu-berlin.de/rote/Papers/pdf/Optimal+logistics+for+expeditions+-+the+jeep+problem+with+complete+refilling.pdf Optimal Logistics for Expeditions: the Jeep Problem with Complete Refilling], Gunter Rote and Guochuan Zhang, June 1996</ref>\n\n==Solution==\n[[File:Jeep problem 1.png|thumb|250px|Solution to \"exploring the desert\" variant for ''n''&nbsp;=&nbsp;3, showing fuel contents of jeep and fuel dumps at start of each trip and at turnround point on each trip.]]\nA strategy that maximises the distance travelled on the final trip for the \"exploring the desert\" variant is as follows:\n\n*The jeep makes ''n'' trips. On each trip it starts from base with 1 unit of fuel.\n*On the first trip the jeep travels a distance of 1/(2''n'') units and leaves (''n''&nbsp;&minus;&nbsp;1)/''n'' units of fuel at a fuel dump. The jeep still has 1/(2''n'') units of fuel &ndash; just enough to return to base.\n*On each of the subsequent ''n''&nbsp;&minus;&nbsp;1 trips the jeep collects 1/(2''n'') units of fuel from this first fuel dump on the way out, so that it leaves the fuel dump carrying 1 unit of fuel. It also collects 1/(2''n'') units of fuel from this first fuel dump on the way back, which is just enough fuel to return to base.\n*On the second trip the jeep travels to the first fuel dump and refuels. It then travels a distance of 1/(2''n''&nbsp;&minus;&nbsp;2) units and leaves (''n''&nbsp;&minus;&nbsp;2)/(''n''&nbsp;&minus;&nbsp;1) units of fuel at a second fuel dump. The jeep still has 1/(2''n''&nbsp;&minus;&nbsp;2) units of fuel, which is just enough to return to the first fuel dump. Here it collects 1/(2''n'') units of fuel, which is just enough fuel to return to base.\n*On each of the subsequent ''n''&nbsp;&minus;&nbsp;2 trips the jeep collects 1/(2''n''&nbsp;&minus;&nbsp;2) units of fuel from this second fuel dump on the way out, so that it leaves the fuel dump carrying 1 unit of fuel. It also collects 1/(2''n''&nbsp;&minus;&nbsp;2) units of fuel from the second fuel dump on the way back, which is just enough fuel to return to the first fuel dump.\n*The jeep continues in this way, so that on trip ''k'' it establishes a new ''k''th fuel dump at a distance of 1/(2''n''&nbsp;&minus;&nbsp;2''k''&nbsp;+&nbsp;2) units from the previous fuel dump and leaves (''n''&nbsp;&minus;&nbsp;''k'')/(''n''&nbsp;&minus;&nbsp;''k''&nbsp;+&nbsp;1) units of fuel there. On each of the subsequent ''n''&nbsp;&minus;&nbsp;''k'' trips it collects 1/(2''n''&nbsp;&minus;&nbsp;2''k''&nbsp;+&nbsp;2) units of fuel from the ''k''th dump on its way out and another 1/(2''n''&nbsp;&minus;&nbsp;2''k''&nbsp;+&nbsp;2) units of fuel on its way back.\n\nWhen the jeep starts its final trip, there are ''n''&nbsp;&minus;&nbsp;1 fuel dumps. The farthest contains 1/2 of a unit of fuel, the next farthest contain 1/3 of a unit of fuel, and so on, and the nearest fuel dump has just 1/''n'' units of fuel left. Together with 1 unit of fuel with which it starts from base, this means that the jeep can travel a total round trip distance of\n\n:<math>1 + \\frac{1}{2} + \\frac{1}{3} + \\cdots + \\frac{1}{n} = \\sum_{k=1}^n \\frac{1}{k}</math>\n\nunits on its final trip (the maximum distance travelled into the desert is half of this).<ref name=coxeter/> It collects half of the remaining fuel at each dump on the way out, which fills its tank. After leaving the farthest fuel dump it travels 1/2 a unit further into the desert and then returns to the farthest fuel dump. It collects the remaining fuel from each fuel dump on the way back, which is just enough to reach the next fuel dump or, in the final step, to return to base.\n\n[[File:Jeep problem 2.png|thumb|250px|Solution to \"crossing the desert\" variant for ''n''&nbsp;=&nbsp;3, showing fuel contents of jeep and fuel dumps at start of each trip, at turnround point on first two trips, and at end of final trip.]]\nThe distance travelled on the last trip is the ''n''th [[harmonic number]], ''H''<sub>''n''</sub>. As the harmonic numbers are unbounded, it is possible to exceed any given distance on the final trip, as along as sufficient fuel is available at the base. However, the amount of fuel required and the number of fuel dumps both increase exponentially with the distance to be travelled.\n\nThe \"crossing the desert\" variant can be solved with a similar strategy, except that there is now no requirement to collect fuel on the way back on the final trip. So on trip ''k'' the jeep establishes a new ''k''th fuel dump at a distance of 1/(2''n''&nbsp;&minus;&nbsp;2''k''&nbsp;+&nbsp;1) units from the previous fuel dump and leaves (2''n''&nbsp;&minus;&nbsp;2''k''&nbsp;&minus;&nbsp;1)/(2''n''&nbsp;&minus;&nbsp;2''k''&nbsp;+&nbsp;1) units of fuel there. On each of the next ''n''&nbsp;&minus;&nbsp;''k''&nbsp;&minus;&nbsp;1 trips it collects 1/(2''n''&nbsp;&minus;&nbsp;2''k''&nbsp;+&nbsp;1) units of fuel from the ''k''th dump on its way out and another 1/(2''n''&nbsp;&minus;&nbsp;2''k''&nbsp;+&nbsp;1) units of fuel on its way back.\n\nNow when the jeep starts its final trip, there are ''n''&nbsp;&minus;&nbsp;1 fuel dumps. The farthest contains 1/3 of a unit of fuel, the next farthest contain 1/5 of a unit of fuel, and so on, and the nearest fuel dump has just 1/(2''n''&nbsp;&minus;&nbsp;1) units of fuel left. Together with 1 unit of fuel with which it starts from base, this means that the jeep can travel a total distance of\n\n:<math>1 + \\frac{1}{3} + \\frac{1}{5} + \\cdots + \\frac{1}{2n-1} = \\sum_{k=1}^n \\frac{1}{2k-1}=H_{2n-1}-\\frac{1}{2}H_{n-1}</math>\n\nunits on its final trip.<ref name=wolfram/><ref name=coxeter/> It collects all of the remaining fuel at each dump on the way out, which fills its tank. After leaving the farthest fuel dump it travels a further distance of 1&nbsp;unit.\n\nNote that\n\n:<math>\\sum_{k=1}^n \\frac{1}{2k-1} > \\sum_{k=1}^n \\frac{1}{2k} = \\frac{1}{2}H_{n}</math>\n\nso it is possible in theory to cross a desert of any size given enough fuel at the base. As before, the amount of fuel required and the number of fuel dumps both increase exponentially with the distance to be travelled.\n\n===Order independence===\nNote that the order of the jeep trips is not fixed.  For example in the \"exploring the desert\" version of the problem, the jeep could make {{math|''n'' − 1}} roundtrips between the base and the first fuel dump, leaving {{math|(''n'' − 1) / ''n''}} units of fuel at the fuel dump each time and then make an {{math|''n''}}-th trip one-way to the first fuel dump, thus arriving there with a total of {{math|(''n'' − 1) + 1/(2''n'')}} units of fuel available.  The {{math|1/(2''n'')}} units are saved for the return trip to base at the very end and the other {{math|''n'' − 1}} units of fuel are used to move fuel between the first and second fuel dump, using {{math|''n'' − 1}} roundtrips and then an {{math|(''n''−1)}}-th trip one-way to the second fuel dump.  And so on.\n\n===Continuous amount of fuel===\nThe number of fuel units available at the base need not be an integer.  In the general case, the maximum distance achievable for the \"explore the desert\" problem with {{math|''n''}} units of fuel is\n:<math>\\mathrm{explore}(n) = \\int_0^n \\frac{\\mathrm{d}f}{2 \\lceil n-f \\rceil}</math>\nand maximum distance achievable for the \"cross the desert\" problem with {{math|''n''}} units of fuel is\n:<math>\\mathrm{cross}(n) = \\int_0^n \\frac{\\mathrm{d}f}{2 \\lceil n-f \\rceil - 1}\\,.</math>\n\n==Practical applications==\nThe problem can have a practical application in wartime situations, especially with respect to fuel efficiency. In the context of the bombing of Japan in [[World War II]] by [[B-29]]s, [[Robert McNamara]] says in the film ''[[The Fog of War]]'' that understanding the fuel efficiency issue caused by having to transport the fuel to forward bases was the main reason why the strategy of launching bombing raids from mainland China was abandoned in favor of the [[island hopping]] strategy:\n\n{{quote|\"We had to fly those planes from the bases in Kansas to India. Then we had to fly fuel over the hump into China. [...] We were supposed to take these [[B-29]]s—there were no [[tanker aircraft]] there. We were to fill them with fuel, fly from [[India]] to [[Chengdu|Chengtu]]; offload the fuel; fly back to India; make enough missions to build up fuel in Chengtu; fly to [[Yawata]], [[Japan]]; bomb the [[steel mills]]; and go back to India.\n\nWe had so little training on this problem of maximizing [fuel] efficiency, we actually found to get some of the B-29s back instead of offloading fuel, they had to take it on. To make a long story short, it wasn't worth a damn. And it was [[Curtis LeMay|LeMay]] who really came to that conclusion, and led the [[Combined Chiefs of Staff|Chiefs]] to move the whole thing to the [[Marianas]], which devastated Japan.\"<ref>[http://www.errolmorris.com/film/fow_transcript.html Fog of War transcript], www.errolmorris.com</ref>}}\n\n(The [[Atomic bombings of Hiroshima and Nagasaki|atomic bombing missions]] at the end of World War II were flown using B-29 [[Superfortresses]] from the [[Pacific Ocean|Pacific]] island of [[Tinian]] in the [[Northern Marianas Islands]].)\n\nSee also [[Operation Black Buck]] for an application of these ideas. In these missions, conducted during the [[Falklands War]], the [[Royal Air Force]] used air to air refuelling by staging tankers to enable the [[Avro Vulcan|Vulcan]] bombers based on [[Ascension Island]] to bomb targets in the [[Falkland Islands]].\n\n==See also==\n*[[Harmonic series (mathematics)|Harmonic series (<nowiki/>mathematics)]]\n*[[Optimization (mathematics)]]\n\n== References ==\n{{reflist}}\n\n[[Category:Mathematical optimization]]\n[[Category:Recreational mathematics]]"
    },
    {
      "title": "Karush–Kuhn–Tucker conditions",
      "url": "https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions",
      "text": "In [[mathematical optimization]], the '''Karush–Kuhn–Tucker (KKT) conditions''', also known as the '''Kuhn–Tucker conditions''', are [[first-order condition|first derivative tests]] (sometimes called first-order) [[necessary and sufficient conditions|necessary conditions]] for a solution in [[nonlinear programming]] to be [[Optimization (mathematics)|optimal]], provided that some [[#Regularity conditions (or constraint qualifications)|regularity condition]]s are satisfied. Allowing inequality constraints, the KKT approach to nonlinear programming generalizes the method of [[Lagrange multipliers]], which allows only equality constraints. The system of equations and inequalities corresponding to the KKT conditions is usually not solved directly, except in the few special cases where a [[Closed-form expression|closed-form]] solution can be derived analytically. In general, many optimization algorithms can be interpreted as methods for numerically solving the KKT system of equations and inequalities.<ref>{{cite book|last=Boyd|first=Stephen|last2=Vandenberghe|first2=Lieven|title=Convex Optimization|publisher=[[Cambridge University Press]]|location=Cambridge |year=2004|pages=244|isbn=0-521-83378-7|mr=2061575}}</ref>\n\nThe KKT conditions were originally named after [[Harold W. Kuhn]] and [[Albert W. Tucker]], who first published the conditions in 1951.<ref>{{cite conference\n  | first = H. W.\n  | last = Kuhn\n  |authorlink1=Harold W. Kuhn\n  | first2 = A. W.\n  | last2 = Tucker\n  |authorlink2=Albert W. Tucker\n  | booktitle = Proceedings of 2nd Berkeley Symposium\n  | pages = 481–492\n  | title=Nonlinear programming\n  | publisher = University of California Press\n  | year = 1951\n  | location = Berkeley\n  | url = http://projecteuclid.org/euclid.bsmsp/1200500249\n |MR=47303}}</ref> Later scholars discovered that the necessary conditions for this problem had been stated by [[William Karush]] in his <!-- unpublished --> master's thesis in 1939.<ref>{{cite journal\n|author=W. Karush\n|title=Minima of Functions of Several Variables with Inequalities as Side Constraints\n|version=M.Sc. Dissertation\n|publisher=Dept. of Mathematics, Univ. of Chicago, Chicago, Illinois\n|year=1939\n}}\n</ref><ref>{{cite journal |last=Kjeldsen |first=Tinne Hoff|authorlink= Tinne Hoff Kjeldsen |title=A contextualized historical analysis of the Kuhn-Tucker theorem in nonlinear programming: the impact of World War II |journal=Historia Math. |volume=27 |year=2000 |issue=4 |pages=331–361 |mr=1800317 |doi=10.1006/hmat.2000.2289}}</ref>\n\n== Nonlinear optimization problem ==\n\nConsider the following nonlinear [[optimization problem|minimization or maximization problem]]:\n\n:Optimize <math>f(\\mathbf{x})</math>\n\n:subject to\n\n::<math> g_i(\\mathbf{x}) \\geq 0, </math>\n\nwhere <math>\\mathbf{x} \\in \\mathbf{X}</math> is the optimization variable chosen from a [[Convex set|convex subset]] of <math>\\mathbb{R}^{n}</math>, <math>f</math> is the [[objective function|objective]] or [[utility]] function, <math> g_i \\ (i = 1, \\ldots, m) </math> are the inequality [[Constraint (mathematics)|constraint]] functions. The numbers of inequality are denoted <math>m</math>. Corresponding to the constraint optimization problem one can form the Lagrangian function\n\n:<math>L(\\mathbf{x},\\mathbf{\\mu}) = f(\\mathbf{x}) + \\mathbf{\\mu}^\\mathsf{T} \\mathbf{g}(\\mathbf{x})</math>\n\nwhere <math>\\mathbf{g}(\\mathbf{x}) = \\left( g_{1}(\\mathbf{x}), \\ldots, g_{m}(\\mathbf{x}) \\right)^{\\mathsf{T}}</math>. The '''Karush–Kuhn–Tucker theorem''' then states the following.\n\n'''Theorem.''' If <math>(\\mathbf{x}^{\\ast},\\mathbf{\\mu}^\\ast)</math> is a [[saddle point]] of <math>L(\\mathbf{x},\\mathbf{\\mu})</math> in <math>\\mathbf{x} \\in \\mathbf{X}</math>, <math>\\mathbf{\\mu} \\geq \\mathbf{0}</math>, then <math>\\mathbf{x}^{\\ast}</math> is an optimal vector for the above optimization problem. Suppose that <math>f(\\mathbf{x})</math> and <math>g_i(\\mathbf{x})</math>, <math>i = 1, \\ldots, m</math>, are [[concave]] in <math>\\mathbf{x}</math> and that there exists <math>\\mathbf{x}_{0} \\in \\mathbf{X}</math> such that <math>\\mathbf{g}(\\mathbf{x}) > 0</math>. Then with an optimal vector <math>\\mathbf{x}^{\\ast}</math> for the above optimization problem there is associated a non-negative vector <math>\\mathbf{\\mu}^\\ast</math> such that <math>L(\\mathbf{x}^{\\ast},\\mathbf{\\mu}^\\ast)</math> is a saddle point of <math>L(\\mathbf{x},\\mathbf{\\mu})</math>.\n\nSince the idea of this approach is to find a [[supporting hyperplane]] on the feasible set <math>\\mathbf{\\Gamma} = \\left\\{ \\mathbf{x} \\in \\mathbf{X} : g_i(\\mathbf{x}) \\geq 0, i = 1, \\ldots, m \\right\\}</math>, the proof of the Karush–Kuhn–Tucker theorem makes use of the [[hyperplane separation theorem]].<ref>{{cite book |first=Murray C. |last=Kemp |first2=Yoshio |last2=Kimura |title=Introduction to Mathematical Economics |location=New York |publisher=Springer |year=1978 |isbn=0-387-90304-6 |pages=38–44 }}</ref>\n\n== Necessary conditions ==\n\nSuppose that the [[objective function]] <math>f : \\mathbb{R}^n \\rightarrow \\mathbb{R}</math> and the constraint functions <math>g_i : \\,\\!\\mathbb{R}^n \\rightarrow \\mathbb{R}</math> and <math>h_j : \\,\\!\\mathbb{R}^n \\rightarrow \\mathbb{R}</math> are [[smooth function|continuously differentiable]] at a point <math>x^*</math>. If <math>x^*</math> is a [[local optimum]] and the optimization problem  satisfies some regularity conditions (see below), then there exist constants <math>\\mu_i\\ (i = 1,\\ldots,m)</math> and <math>\\lambda_j\\ (j = 1,\\ldots,\\ell)</math>, called KKT multipliers, such that\n\n[[File:Inequality constraint diagram.svg|thumb|upright=2|Inequality constraint diagram for optimization problems]]\n\n;Stationarity\n: For maximizing <math>f(x)</math>: <math>\\nabla f(x^*) = \\sum_{i=1}^m \\mu_i \\nabla g_i(x^*) + \\sum_{j=1}^\\ell \\lambda_j \\nabla h_j(x^*),</math>\n: For minimizing <math>f(x)</math>: <math>-\\nabla f(x^*) = \\sum_{i=1}^m \\mu_i \\nabla g_i(x^*) + \\sum_{j=1}^\\ell \\lambda_j \\nabla h_j(x^*),</math>\n\n;Primal feasibility\n:<math>g_i(x^*) \\le 0, \\text{ for } i = 1, \\ldots, m</math>\n:<math>h_j(x^*) = 0, \\text{ for } j = 1, \\ldots, \\ell \\,\\!</math>\n\n;Dual feasibility\n:<math>\\mu_i \\ge 0, \\text{ for } i = 1, \\ldots, m</math>\n\n;Complementary slackness\n:<math>\\mu_i g_i (x^*) = 0, \\text{ for }\\; i = 1,\\ldots,m.</math>\n\nIn the particular case <math>m=0</math>, i.e., when there are no inequality constraints, the KKT conditions turn into the Lagrange conditions, and the KKT multipliers are called [[Lagrange multipliers]].\n\nIf some of the functions are non-differentiable, [[subderivative|subdifferential]] versions of Karush–Kuhn–Tucker (KKT) conditions are available.<ref>\n{{cite book |authorlink=Andrzej Piotr Ruszczyński |last=Ruszczyński |first=Andrzej |title=Nonlinear Optimization |publisher=[[Princeton University Press]] |location=Princeton, NJ |year=2006 |pages= |isbn=978-0691119151 |mr=2199043}}</ref>\n\n== Regularity conditions (or constraint qualifications) ==\nIn order for a minimum point <math>x^*</math> to satisfy the above KKT conditions, the problem should satisfy some regularity conditions; some common examples are tabulated here:\n\n{| class=\"wikitable\"\n!Constraint\n!Acronym\n!Statement\n|-\n|Linearity constraint qualification\n|LCQ\n|If <math>g_i</math> and <math>h_j</math> are [[affine function]]s, then no other condition is needed.\n|-\n|Linear independence constraint qualification\n|LICQ\n|The gradients of the active inequality constraints and the gradients of the equality constraints are [[Linear independence|linearly independent]] at <math>x^*</math>.\n|-\n|Mangasarian-Fromovitz constraint qualification\n|MFCQ\n|The gradients of the equality constraints are linearly independent at <math>x^*</math> and there exists a vector <math>d \\in \\mathbb{R}^n</math> such that <math>\\nabla g_i(x^*)^\\top d < 0</math> for all active inequality constraints and <math>\\nabla h_j(x^*)^\\top d = 0</math> for all equality constraints.<ref>{{cite book|author=[[Dimitri Bertsekas]]|title=Nonlinear Programming|year=1999|publisher=Athena Scientific|edition=2|pages=329–330|isbn=9781886529007}}</ref>\n|-\n|[[Constant rank theorem|Constant rank constraint qualification]]\n|CRCQ\n|For each subset of the gradients of the active inequality constraints and the gradients of the equality constraints the rank at a vicinity of <math>x^*</math> is constant.\n|-\n|Constant positive linear dependence constraint qualification\n|CPLD\n|For each subset of gradients of active inequality constraints and gradients of equality constraints, if the subset of vectors is linearly dependent at <math>x^*</math> with non-negative scalars associated with the inequality constraints, then it remains linearly dependent in a neighborhood of <math>x^*</math>.\n|-\n|Quasi-normality constraint qualification\n|QNCQ\n|If the gradients of the active inequality constraints and the gradients of the equality constraints are linearly dependent at <math>x^*</math> with associated multipliers <math>\\lambda_j</math> for equalities and <math>\\mu_i\\geq0</math> for inequalities, then there is no sequence <math>x_k\\to x^*</math> such that <math>\\lambda_j \\neq 0 \\Rightarrow \\lambda_j h_j(x_k)>0</math> and <math>\\mu_i \\neq 0 \\Rightarrow \\mu_i g_i(x_k)>0</math>.\n|-\n|[[Slater condition|Slater's condition]]\n|SC\n|For a [[Convex optimization|convex problem]] (i.e., assuming minimization, <math>f,g_i</math> are convex and <math>h_j</math> is affine), there exists a point <math>x</math> such that <math>h(x)=0</math> and <math> g_i(x) < 0 </math>.\n|}\n\nIt can be shown that\n\n: LICQ ⇒ MFCQ ⇒ CPLD ⇒ QNCQ\n\nand\n\n: LICQ ⇒ CRCQ ⇒ CPLD ⇒ QNCQ\n\n(and the converses are not true), although MFCQ is not equivalent to CRCQ.<ref>{{cite techreport\n| url         = http://people.ufpr.br/~ademir.ribeiro/ensino/cm721/kkt.pdf\n| title       = Constraint Qualification for Nonlinear Programming\n|author1=Rodrigo Eustaquio |author2=Elizabeth Karas |author3=Ademir Ribeiro | year        = \n| institution = Federal University of Parana\n}}</ref>\nIn practice weaker constraint qualifications are preferred since they provide stronger optimality conditions.\n\n== Sufficient conditions ==\n\nIn some cases, the necessary conditions are also sufficient for optimality. In general, the necessary conditions are not sufficient for optimality and additional information is necessary, such as the Second Order Sufficient Conditions (SOSC). For smooth functions, SOSC involve the second derivatives, which explains its name.\n\nThe necessary conditions are sufficient for optimality if the objective function <math>f</math> of a maximization problem is a [[concave function]], the inequality constraints <math>g_j</math> are continuously differentiable [[convex function]]s and the equality constraints <math>h_i</math> are [[affine function]]s.\n\nIt was shown by Martin in 1985 that the broader class of functions in which KKT conditions guarantees global optimality are the so-called Type 1 '''[[invex function]]s'''.<ref>{{cite journal |first=D. H. |last=Martin |journal=J. Optim. Theory Appl. |volume=47 |issue=1 |pages=65–76 |title=The Essence of Invexity |year= 1985 |doi=10.1007/BF00941316 }}</ref><ref>{{cite journal |first=M. A. |last=Hanson |title=Invexity and the Kuhn-Tucker Theorem |journal=J. Math. Anal. Appl. |volume=236 |issue=2 |pages=594–604 |year=1999 |doi=10.1006/jmaa.1999.6484 }}</ref>\n\n=== Second-order sufficient conditions ===\n\nFor smooth, [[Nonlinear programming|non-linear optimization]] problems, a second order sufficient condition is given as follows.\n\nThe solution <math>x^*, \\lambda^*, \\mu^*</math> found in the above section is a constrained local minimum if for the Lagrangian,\n\n:<math> L(x,\\lambda,\\mu) = f(x) + \\sum_{i=1}^m \\mu_i g_i(x) + \\sum_{j=1}^\\ell \\lambda_j h_j(x) </math>\n\nthen,\n\n:<math>s^T\\nabla ^2_{xx}L(x^*,\\lambda^*,\\mu^*)s \\ge 0</math>\n\nwhere <math>s \\ne 0</math> is a vector satisfying the following,\n\n:<math>\\left[ \\nabla_x g_i(x^*),  \\nabla_x h_j(x^*) \\right]^T s = 0</math>\n\nwhere only those active inequality constraints <math>g_i(x)</math> corresponding to strict complementarity (i.e. where <math>\\mu_i > 0</math>) are applied. The solution is a strict constrained local minimum in the case the inequality is also strict.\n\n== Economics ==\n{{see also|Profit maximization}}\nOften in [[mathematical economics]] the KKT approach is used in theoretical models in order to obtain qualitative results. For example,<ref>Chiang, Alpha C. ''Fundamental Methods of Mathematical Economics'', 3rd edition, 1984, pp. 750–752.</ref> consider a firm that maximizes its sales revenue subject to a minimum profit constraint. Letting <math>Q</math> be the quantity of output produced (to be chosen), <math>R(Q)</math> be sales revenue with a positive first derivative and with a zero value at zero output, <math>C(Q)</math> be production costs with a positive first derivative and with a non-negative value at zero output, and <math>G_{\\min}</math> be the positive minimal acceptable level of [[Profit (economics)|profit]], then the problem is a meaningful one if the revenue function levels off so it eventually is less steep than the cost function.  The problem expressed in the previously given minimization form is\n\n:Minimize <math> -R(Q)</math> \n:subject to \n:<math> G_{\\min} \\le R(Q) - C(Q)  </math> \n:<math> Q \\ge 0,</math>\n\nand the KKT conditions are\n\n: <math>\n\\begin{align}\n& \\left(\\frac{\\text{d} R}{\\text{d} Q} \\right) (1+\\mu ) - \\mu \\left( \\frac{\\text{d} C}{\\text{d} Q} \\right) \\le 0, \\\\[5pt]\n& Q \\ge 0, \\\\[5pt]\n& Q \\left[ \\left( \\frac{\\text{d} R}{\\text{d} Q} \\right) (1+\\mu ) - \\mu \\left( \\frac{\\text{d} C}{\\text{d} Q}\\right) \\right] = 0, \\\\[5pt]\n& R(Q) - C(Q) - G_{\\min} \\ge 0, \\\\[5pt]\n& \\mu \\ge 0, \\\\[5pt]\n& \\mu [R(Q) - C(Q) - G_{\\min}] = 0.\n\\end{align}\n</math>\n\nSince <math>Q = 0</math> would violate the minimum profit constraint, we have <math>Q > 0</math> and hence the third condition implies that the first condition holds with equality. Solving that equality gives\n\n:<math> \\frac{\\text{d} R}{\\text{d} Q} = \\frac{\\mu}{1+ \\mu} \\left( \\frac{\\text{d} C}{\\text{d} Q} \\right).</math>\n\nBecause it was given that <math>\\text{d} R / \\text{d} Q</math> and <math>\\text{d} C / \\text{d} Q</math> are strictly positive, this inequality along with the non-negativity condition on <math>\\mu</math> guarantees that <math>\\mu</math> is positive and so the revenue-maximizing firm operates at a level of output at which [[marginal revenue]] <math> \\text{d} R / \\text{d} Q</math> is less than [[marginal cost]] <math> \\text{d} C / \\text{d} Q</math> — a result that is of interest because it contrasts with the behavior of a [[profit maximization|profit maximizing]] firm, which operates at a level at which they are equal.\n\n== Value function ==\nIf we reconsider the optimization problem as a maximization problem with constant inequality constraints:\n:<math> \\text{Maximize }\\; f(x) </math>\n\n:<math> \\text{subject to }\\ </math>\n\n::<math> g_i(x) \\le a_i , h_j(x) = 0.</math>\n\nThe value function is defined as\n:<math>V(a_1, \\ldots, a_n) = \\sup\\limits_x f(x) </math>\n\n:<math> \\text{subject to }\\ </math>\n\n::<math> g_i(x) \\le a_i , h_j(x) = 0 </math>\n\n::<math> j \\in \\{1,\\ldots, \\ell\\}, i\\in\\{1,\\ldots,m\\},</math>\n\nso the domain of <math>V</math> is <math>\\{a \\in \\mathbb{R}^m \\mid \\text{for some }x\\in X, g_i(x) \\leq a_i, i \\in \\{1,\\ldots,m\\}\\}.</math>\n\nGiven this definition, each coefficient <math>\\mu_i</math> is the rate at which the value function  increases as <math>a_i</math> increases.  Thus if each <math>a_i</math> is interpreted as a resource constraint, the coefficients tell you how much increasing a resource will increase the optimum value of our function <math>f</math>.  This interpretation is especially important in economics and is used, for instance, in [[utility maximization problem]]s.\n\n== Generalizations ==\n\nWith an extra multiplier <math>\\mu_0\\geq0</math>, which may be zero (as long as <math>(\\mu_0,\\mu,\\lambda)\\neq0</math>), in front of <math>\\nabla f(x^*)</math> the KKT stationarity conditions turn into\n\n: <math>\n\\begin{align}\n& \\mu_0 \\,\\nabla f(x^*) + \\sum_{i=1}^m \\mu_i \\,\\nabla g_i(x^*) + \\sum_{j=1}^\\ell \\lambda_j \\,\\nabla h_j(x^*) = 0, \\\\[4pt]\n& \\mu_jg_i(x^*)=0, \\quad i=1,\\dots,m,\n\\end{align}\n</math>\n\nwhich are called the [[Fritz John conditions]]. This optimality conditions holds without constraint qualifications and it is equivalent to the optimality condition ''KKT or (not-MFCQ)''.\n\nThe KKT conditions belong to a wider class of the first-order necessary conditions (FONC), which allow for non-smooth functions using [[subderivative]]s.\n\n== See also ==\n* [[Farkas' lemma]]\n*The [[Big M method]], for linear problems, which extends the [[simplex algorithm]] to problems that contain \"greater-than\" constraints.\n\n== References ==\n<references/>\n\n== Further reading ==\n* {{cite journal |first=R. |last=Andreani |first2=J. M. |last2=Martínez |first3=M. L. |last3=Schuverdt |title=On the relation between constant positive linear dependence condition and quasinormality constraint qualification |journal=Journal of Optimization Theory and Applications |volume=125 |issue=2 |pages=473–485 |year=2005 |doi=10.1007/s10957-004-1861-9 }}\n* {{cite book |last=Avriel |first=Mordecai |year=2003 |title=Nonlinear Programming: Analysis and Methods |publisher=Dover |location= |isbn=0-486-43227-0 }}\n* {{cite book |first=S. |last=Boyd |first2=L. |last2=Vandenberghe |year=2004 |chapter=Optimality Conditions |chapterurl=https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf#page=255 |title=Convex Optimization |publisher=Cambridge University Press |isbn=0-521-83378-7 |pages=241–249 }}\n* {{cite book |first=Murray C. |last=Kemp |first2=Yoshio |last2=Kimura |title=Introduction to Mathematical Economics |location=New York |publisher=Springer |year=1978 |isbn=0-387-90304-6 |pages=38–73 }}\n* {{cite book |first=J. |last=Nocedal |first2=S. J. |last2=Wright |year=2006 |title=Numerical Optimization |publisher=Springer |location=New York |isbn=978-0-387-30303-1 }}\n* {{cite book |first=Rangarajan K. |last=Sundaram |chapter=Inequality Constraints and the Theorem of Kuhn and Tucker |title=A First Course in Optimization Theory |location=New York |publisher=Cambridge University Press |year=1996 |isbn=0-521-49770-1 |pages=145–171 |chapterurl=https://books.google.com/books?id=yAfug81P-8YC&pg=PA145 }}\n\n== External links ==\n*[http://www.onmyphd.com/?p=kkt.karush.kuhn.tucker Karush–Kuhn–Tucker conditions with derivation and examples]\n*[http://apmonitor.com/me575/index.php/Main/KuhnTucker Examples and Tutorials on the KKT Conditions]\n\n<!--\n-->\n\n{{DEFAULTSORT:Karush-Kuhn-Tucker conditions}}\n[[Category:Mathematical optimization]]\n[[Category:Mathematical economics]]"
    },
    {
      "title": "Keynes–Ramsey rule",
      "url": "https://en.wikipedia.org/wiki/Keynes%E2%80%93Ramsey_rule",
      "text": "In [[macroeconomics]], the '''Keynes–Ramsey rule''' is an optimality condition for the rate of change of [[Consumption (economics)|consumption]].<ref>{{cite book |first=Olivier Jean |last=Blanchard |authorlink=Olivier Blanchard |first2=Stanley |last2=Fischer |authorlink2=Stanley Fischer |title=Lectures on Macroeconomics |location=Cambridge |publisher=MIT Press |year=1989 |isbn=0-262-02283-4 |pages=41–43 |url=https://books.google.com/books?id=j_zs7htz9moC&pg=PA41 }}</ref> Usually it is a [[differential equation]] relating consumption with [[interest rate]]s, [[time preference]], and (intertemporal) [[elasticity of substitution]]. The Keynes–Ramsey rule is named after [[Frank P. Ramsey]], who derived it in 1928,<ref>{{cite journal |first=F. P. |last=Ramsey |year=1928 |title=A Mathematical Theory of Saving |journal=[[Economic Journal]] |volume=38 |issue=152 |pages=543–559 |jstor=2224098 |ref=harv }}</ref> and his mentor [[John Maynard Keynes]], who provided an economic interpretation.<ref>See {{harvtxt|Ramsey|1928|p=545}}: “Enough must therefore be saved to reach or approach bliss some time, but this does not mean that our whole income should be saved. The more we save the sooner we shall reach bliss, but the less enjoyment we shall have now, and we have to set the one against the other. Mr. Keynes has shown me that the rule governing the amount to be saved can be determined at once from these considerations.”</ref>\n\nMathematically, the Keynes–Ramsey rule is a necessary condition for a dynamic [[optimal control]] problem, also known as an [[Euler–Lagrange equation]].<ref>{{cite book |first=Michael D. |last=Intriligator |authorlink=Michael Intriligator |title=Mathematical Optimization and Economic Theory |location=Englewood Cliffs |publisher=Prentice-Hall |year=1971 |isbn=0-13-561753-7 |pages=308–311 }}</ref>\n\n== See also ==\n* [[Ramsey–Cass–Koopmans model]]\n* [[Hamiltonian (control theory)]]\n\n== References ==\n{{Reflist}}\n\n{{DEFAULTSORT:Keynes-Ramsey rule}}\n[[Category:Economic growth]]\n[[Category:Intertemporal economics]]\n[[Category:Mathematical optimization]]\n\n\n{{Economics-stub}}"
    },
    {
      "title": "Lagrange multiplier",
      "url": "https://en.wikipedia.org/wiki/Lagrange_multiplier",
      "text": "In [[mathematical optimization]], the '''method of Lagrange multipliers''' is a strategy for finding the local [[maxima and minima]] of a [[function (mathematics)|function]] subject to [[constraint (mathematics)|equality constraints]] (i.e., subject to the condition that one or more [[equation]]s have to be satisfied exactly by the chosen values of the variables).<ref>{{cite book |last=Hoffmann |first=Laurence D. |last2=Bradley |first2=Gerald L. |title=Calculus for Business, Economics, and the Social and Life Sciences |location= |publisher= |year=2004 |edition=8th |pages=575–588 |isbn=0-07-242432-X }}</ref> The basic idea is to convert a constrained problem into a form such that the [[derivative test]] of an unconstrained problem can still be applied. Once [[stationary point]]s have been identified from the first-order necessary conditions, the [[Definiteness of a matrix|definiteness]] of the [[Bordered Hessian|bordered Hessian matrix]] determines whether those points are maxima, minima, or [[saddle point]]s.<ref name=\"SilberbergSuen\">{{cite book |first=Eugene |last=Silberberg |first2=Wing |last2=Suen |title=The Structure of Economics : A Mathematical Analysis |location=Boston |publisher=Irwin McGraw-Hill |edition=Third |year=2001 |isbn=0-07-234352-4 |pages=134–141 }}</ref>\n\nThe Lagrange multiplier theorem roughly states that at any [[stationary point]] of the function that also satisfies the equality constraints, the [[gradient]] of the function at that point can be expressed as a [[linear combination]] of the gradients of the constraints at that point, with the Lagrange multipliers acting as [[coefficient]]s.<ref>{{cite book |first=David G. |last=Luenberger |authorlink=David Luenberger |title=Optimization by Vector Space Methods |location=New York |publisher=John Wiley & Sons |year=1969 |isbn= |pages=188–189 }}</ref> The relationship between the gradient of the function and gradients of the constraints rather naturally leads to a reformulation of the original problem, known as the '''Lagrangian function'''.<ref>{{cite book |first=Brian |last=Beavis |first2=Ian M. |last2=Dobbs |chapter=Static Optimization |title=Optimization and Stability Theory for Economic Analysis |location=New York |publisher=Cambridge University Press |year=1990 |isbn=0-521-33605-8 |page=40 |chapterurl=https://books.google.com/books?id=L7HMACFgnXMC&pg=PA40 }}</ref>\n\nThe great advantage of this method is that it allows the optimization to be solved without explicit [[parameterization]] in terms of the constraints. As a result, the method of Lagrange multipliers is widely used to solve challenging constrained optimization problems. The method can be summarized as follows: in order to find the stationary points of a function <math>f(x)</math> subject to the equality constraints <math>g_{i}(x) = 0</math>, <math>i = 1, 2, \\ldots, m</math>, form the Lagrangian function\n:<math>\\mathcal{L}(x, \\lambda) = f(x) - \\sum_{i=1}^{m} \\lambda_{i} g_{i}(x)</math>\nand find the stationary points of <math>\\mathcal{L}</math> considered as a function of <math>x</math> and the Lagrange multiplier <math>\\lambda</math>.<ref>{{cite book |first=Murray H. |last=Protter |authorlink=Murray H. Protter |first2=Charles B., Jr. |last2=Morrey |authorlink2=Charles B. Morrey Jr. |title=Intermediate Calculus |location=New York |publisher=Springer |edition=2nd |year=1985 |page=267 |isbn=0-387-96058-9 }}</ref>\n\n== Single constraint ==\n[[Image:LagrangeMultipliers2D.svg|thumb|right|300px|Figure 1: The red curve shows the constraint <span style=\"color: DarkRed\">{{math|''g''(''x'', ''y'') {{=}} ''c''}}</span>. The blue curves are contours of <span style=\"color:DarkSlateBlue\">{{math|''f''(''x'', ''y'')}}</span>. The point where the red constraint tangentially touches a blue contour is the maximum of <span style=\"color:DarkSlateBlue\">{{math|''f''(''x'', ''y'')}}</span> along the constraint, since {{math|''d''<sub>1</sub> > ''d''<sub>2</sub>}}.]]\n\nFor the case of only one constraint and only two choice variables (as exemplified in Figure 1), consider the [[optimization problem]]\n\n:maximize  {{math|''f''(''x'', ''y'')}}\n:subject to {{math|''g''(''x'', ''y'') {{=}} 0}}.\n\n(Sometimes an additive constant is shown separately rather than being included in ''g'', in which case the constraint is written {{math|''g''(''x'', ''y'') {{=}} ''c''}}, as in Figure 1.) We assume that both {{mvar|f}} and {{mvar|g}} have continuous first [[partial derivative]]s.  We introduce a new variable ({{mvar|λ}}) called a '''Lagrange multiplier''' (or '''Lagrange undetermined multiplier''') and study the '''Lagrange function''' (or '''Lagrangian''' or '''Lagrangian expression''') defined by\n\n:<math> \\mathcal{L}(x,y,\\lambda) = f(x,y) - \\lambda g(x,y),</math>\n\nwhere the {{mvar|λ}} term may be either added or subtracted. If {{math|''f''(''x''<sub>0</sub>, ''y''<sub>0</sub>)}} is a maximum of {{math|''f''(''x'', ''y'')}} for the original constrained problem, then there exists {{math|''λ''<sub>0</sub>}} such that {{math|(''x''<sub>0</sub>, ''y''<sub>0</sub>, ''λ''<sub>0</sub>)}} is a [[stationary point]] for the Lagrange function (stationary points are those points where the first partial derivatives of <math>\\mathcal{L}</math> are zero). Also, it must be assumed that <math>\\nabla g \\ne 0.</math> However, not all stationary points yield a solution of the original problem, as the method of Lagrange multipliers yields only a [[necessary condition]] for optimality in constrained problems.<ref>{{cite book  | last = Bertsekas  | first = Dimitri P.| authorlink = Dimitri P. Bertsekas | title = Nonlinear Programming| edition=  Second  | publisher = Athena Scientific | year = 1999  | location = Cambridge, MA.  | isbn = 1-886529-00-0 |ref=harv}}</ref><ref>{{springer | id=Lagrange_multipliers | title=Lagrange multipliers| first=I.B. | last=Vapnyarskii }}.</ref><ref>{{cite book|last=Lasdon|first=Leon&nbsp;S.|title=Optimization Theory for Large Systems|publisher=Dover |location=Mineola, New York|year=2002 |edition=Reprint of the 1970 Macmillan |mr=1888251 |isbn=0-486-41999-1 }}</ref><ref>{{cite book|last1=Hiriart-Urruty|first1=Jean-Baptiste|last2=Lemaréchal|first2=Claude|chapter=XII&nbsp;Abstract duality for practitioners|title=Convex analysis and minimization algorithms, Volume&nbsp;II: Advanced theory and bundle methods|series=Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]| volume=306 |publisher=Springer-Verlag |location=Berlin|year=1993| isbn=3-540-56852-2|mr=1295240|authorlink2=Claude Lemaréchal|ref=harv|pages=136–193 (and Bibliographical comments on pp.&nbsp;334–335)}}</ref><ref>{{Cite book |title=Computational combinatorial optimization: Papers from the Spring School held in Schloß Dagstuhl, May&nbsp;15–19,&nbsp;2000 |last=Lemaréchal |first=Claude |publisher=Springer-Verlag |year=2001 |isbn=3-540-42877-1 |editor-last=Jünger |editor-first=Michael |series=Lecture Notes in Computer Science |volume=2241 |location=Berlin |pages=112–156 |chapter=Lagrangian relaxation |doi=10.1007/3-540-45586-8_4 |mr=1900016 |author-link=Claude Lemaréchal |editor-last2=Naddef |editor-first2=Denis}}</ref> Sufficient conditions for a minimum or maximum [[Bordered Hessian|also exist]], but if a particular [[candidate solution]] satisfies the sufficient conditions, it is only guaranteed that that solution is the best one ''locally'' – that is, it is better than any permissible nearby points. The ''global'' optimum can be found by comparing the values of the original objective function at the points satisfying the necessary and locally sufficient conditions.\n\nThe method of Lagrange multipliers relies on the intuition that at a maximum, {{math|''f''(''x'', ''y'')}} cannot be increasing in the direction of any such neighboring point that also has {{math|''g'' {{=}} 0}}. If it were, we could walk along {{math|''g'' {{=}} 0}} to get higher, meaning that the starting point wasn't actually the maximum.\n\nWe can visualize [[Contour line|contour]]s of {{mvar|f}} given by {{math|''f''(''x'', ''y'') {{=}} ''d''}} for various values of {{mvar|d}}, and the contour of {{mvar|g}} given by {{math|''g''(''x'', ''y'') {{=}} ''c''}}.\n\nSuppose we walk along the contour line with {{math|''g'' {{=}} ''c''}}. We are interested in finding points where {{mvar|f}} does not change as we walk, since these points might be maxima.\n\nThere are two ways this could happen: \n\n# We could be following a contour line of {{mvar|f}}, since by definition {{mvar|f}} does not change as we walk along its contour lines. This would mean that the contour lines of {{mvar|f}} and {{mvar|g}} are parallel here.\n# We have reached a \"level\" part of {{mvar|f}}, meaning that {{mvar|f}} does not change in any direction.\n\nTo check the first possibility (we are following a contour line of {{mvar|f}}), notice that since the [[gradient]] of a function is perpendicular to the contour lines, the contour lines of {{mvar|f}} and {{mvar|g}}  are parallel if and only if the gradients of {{mvar|f}} and {{mvar|g}} are parallel. Thus we want points {{math|(''x'', ''y'')}} where {{math|''g''(''x'', ''y'') {{=}} 0}} and\n\n:<math>\\nabla_{x,y} f = \\lambda \\, \\nabla_{x,y} g,</math>\n\nfor some {{mvar|λ}}\n\nwhere\n\n:<math> \\nabla_{x,y} f= \\left( \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right), \\qquad \\nabla_{x,y} g= \\left( \\frac{\\partial g}{\\partial x}, \\frac{\\partial g}{\\partial y} \\right).</math>\n\nare the respective gradients. The constant {{mvar|λ}} is required because although the two gradient vectors are parallel, the magnitudes of the gradient vectors are generally not equal. This constant is called the Lagrange multiplier. (In some conventions {{mvar|λ}} is preceded by a minus sign).\n\nNotice that this method also solves the second possibility, that {{mvar|f}} is level: if {{mvar|f}} is level, then its gradient is zero, and setting {{math|''λ'' {{=}} 0}} is a solution regardless of <math>\\nabla_{x,y}g</math>.\n\nTo incorporate these conditions into one equation, we introduce an auxiliary function\n\n:<math> \\mathcal{L}(x,y,\\lambda) = f(x,y) - \\lambda g(x,y), </math>\n\nand solve\n\n:<math> \\nabla_{x,y,\\lambda} \\mathcal{L}(x , y, \\lambda)=0. </math>\n\nNote that this amounts to solving three equations in three unknowns. This is the method of Lagrange multipliers. Note that <math>\\nabla_{\\lambda} \\mathcal{L}(x , y, \\lambda)=0</math> implies {{math|''g''(''x'', ''y'') {{=}} 0}}. To summarize\n:<math>\n\\nabla_{x,y,\\lambda} \\mathcal{L}(x , y, \\lambda)=0 \\iff \n\\begin{cases}\n\\nabla_{x,y} f(x , y) = \\lambda \\, \\nabla_{x,y} g(x , y)\\\\\n g(x,y) = 0\n\\end{cases}</math>\n\nThe method generalizes readily to functions on <math>n</math> variables\n\n:<math> \\nabla_{x_1, \\dots, x_n,\\lambda} \\mathcal{L}(x_1, \\dots, x_n, \\lambda)=0</math>\n\nwhich amounts to solving <math>n+1</math> equations in <math>n+1</math> unknowns.\n\nThe constrained extrema of {{mvar|f}} are ''[[Critical point (mathematics)|critical points]]'' of the Lagrangian <math>\\mathcal{L}</math>, but they are not necessarily ''local extrema'' of <math>\\mathcal{L}</math> (see [[#Example 2|Example 2]] below).\n\nOne may [[Hamiltonian mechanics#As a reformulation of Lagrangian mechanics|reformulate the Lagrangian]] as a [[Hamiltonian mechanics|Hamiltonian]], in which case the solutions are local minima for the Hamiltonian. This is done in [[optimal control]] theory, in the form of [[Pontryagin's minimum principle]].\n\nThe fact that solutions of the Lagrangian are not necessarily extrema also poses difficulties for numerical optimization. This can be addressed by computing the ''magnitude'' of the gradient, as the zeros of the magnitude are necessarily local minima, as illustrated in the [[#Example 4: Numerical optimization|numerical optimization example]].\n\n== Multiple constraints ==\n[[Image:As wiki lgm parab.svg|thumb|right|300px|Figure 2: A paraboloid constrained along two intersecting lines.]]\n[[Image:As wiki lgm levelsets.svg|thumb|right|300px|Figure 3: Contour map of Figure 2.]]\nThe method of Lagrange multipliers can be extended to solve problems with multiple constraints using a similar argument. Consider a [[paraboloid]] subject to two line constraints that intersect at a single point. As the only feasible solution, this point is obviously a constrained extremum. However, the [[level set]] of <math>f</math> is clearly not parallel to either constraint at the intersection point (see Figure 3); instead, it is a linear combination of the two constraints' gradients. In the case of multiple constraints, that will be what we seek in general: the method of Lagrange seeks points not at which the gradient of <math>f</math> is multiple of any single constraint's gradient necessarily, but in which it is a linear combination of all the constraints' gradients.\n\nConcretely, suppose we have <math>M</math> constraints and are walking along the set of points satisfying <math>g_i(\\mathbf{x})=0, i=1, \\dots, M</math>. Every point <math>\\mathbf{x}</math> on the contour of a given constraint function <math>g_i</math> has a space of allowable directions: the space of vectors perpendicular to <math>\\nabla g_i(\\mathbf{x})</math>.  The set of directions that are allowed by all constraints is thus the space of directions perpendicular to all of the constraints' gradients.  Denote this space of allowable moves by <math>A</math> and denote the span of the constraints' gradients by <math>S</math>.  Then <math>A = S^{\\perp}</math>, the space of vectors perpendicular to every element of <math>S</math>.\n\nWe are still interested in finding points where <math>f</math> does not change as we walk, since these points might be (constrained) extrema. We therefore seek <math>\\mathbf{x}</math> such that any allowable direction of movement away from <math>\\mathbf{x}</math> is perpendicular to <math>\\nabla f(\\mathbf{x})</math> (otherwise we could increase <math>f</math> by moving along that allowable direction).  In other words, <math>\\nabla f(\\mathbf{x}) \\in A^{\\perp} = S</math>.  Thus there are scalars {{math|''λ''<sub>1</sub>, ''λ''<sub>2</sub>, ..., ''λ<sub>M</sub>''}} such that\n\n: <math>\\nabla f(\\mathbf{x}) = \\sum_{k=1}^M  \\lambda_k \\, \\nabla g_k (\\mathbf{x})  \\quad \\iff \\quad \\nabla f(\\mathbf{x}) - \\sum_{k=1}^M {\\lambda_k \\nabla g_k (\\mathbf{x})} = 0.</math>\n\nThese scalars are the Lagrange multipliers. We now have <math>M</math> of them, one for every constraint.\n\nAs before, we introduce an auxiliary function\n\n: <math>\\mathcal{L}\\left( x_1,\\ldots , x_n, \\lambda_1, \\ldots, \\lambda _M \\right) = f\\left( x_1, \\ldots, x_n \\right) - \\sum\\limits_{k=1}^M {\\lambda_k g_k\\left( x_1, \\ldots , x_n \\right)}</math>\n\nand solve\n\n:<math> \\nabla_{x_1, \\ldots , x_n, \\lambda_1, \\ldots, \\lambda _M} \\mathcal{L}(x_1, \\ldots , x_n, \\lambda_1, \\ldots, \\lambda _M)=0 \\iff \n\\begin{cases}\n\\nabla f(\\mathbf{x}) - \\sum_{k=1}^M {\\lambda_k \\, \\nabla g_k (\\mathbf{x})} = 0\\\\\n g_1(\\mathbf{x}) = \\cdots = g_M(\\mathbf{x}) = 0\n\\end{cases}</math>\n\nwhich amounts to solving <math>n+M</math> equations in <math>n+M</math> unknowns.\n\nThe method of Lagrange multipliers is generalized by the [[Karush–Kuhn–Tucker conditions]], which can also take into account inequality constraints of the form {{math|''h''('''x''')&nbsp;≤&nbsp;''c''}}.\n\n==Modern formulation via differentiable manifolds==\n\nThe problem of finding the local maxima and minima subject to constraints can be generalized to finding local maxima and minima on a [[differentiable manifold]] <math>M</math>.<ref>{{cite book|last1=Lafontaine|first1=Jacques|title=An Introduction to Differential Manifolds|publisher=Springer|isbn=9783319207353|page=70|url=https://books.google.com/books?id=KNhJCgAAQBAJ&pg=PA70 |year=2015  |ref=harv }}</ref> In what follows, it is not necessary that <math>M</math> be a Euclidean space, or even a Riemannian manifold. All appearances of the gradient <math>\\nabla</math> (which depends on a choice of Riemannian metric) can be replaced with the [[exterior derivative]] <math>d</math>.\n\n===Single constraint===\nLet <math>M</math> be a [[smooth manifold]] of dimension <math>m</math>. Suppose that we wish to find the stationary points <math>x</math> of a smooth function <math>f:M\\to\\R</math> when restricted to the submanifold <math>N</math> defined by <math>g(x)=0,</math> where <math>g:M\\to\\R</math> is a smooth function for which 0 is a [[regular value]] of <math>g</math>.\n\nLet <math>df</math> and <math>dg</math> be the [[exterior derivative]]s. Stationarity for the restriction <math>f|_{N}</math> at <math>x\\in N</math> means <math>d(f|_N)_x=0.</math> Equivalently, the kernel <math>\\ker(df_x)</math> contains <math>T_x N=\\ker(dg_x).</math> In other words, <math>df_x</math> and <math>dg_x</math> are proportional vectors. For this it is necessary and sufficient that the following system of <math>m(m-1)/2</math> equations holds:\n\n:<math>df_x \\wedge dg_x = 0 \\in \\Lambda^2(T^{*}_x M)</math>\n\nwhere <math>\\wedge</math> denotes the [[exterior algebra|exterior product]]. The stationary points <math>x</math> are the solutions of the above system of equations plus the constraint <math>g(x)=0.</math> Note that the <math>\\tfrac{1}{2} m(m-1)</math> equations are not independent, since the left-hand side of the equation belongs to the subvariety of <math>\\Lambda^{2}(T^*_x M)</math> consisting of [[exterior algebra|decomposable elements]].\n\nIn this formulation, it is not necessary to explicitly find the Lagrange multiplier, a number <math>\\lambda</math> such that <math>df_x = \\lambda \\, dg_x.</math>\n\n===Multiple constraints===\nLet <math>M</math> and <math>f</math> be as in the above section regarding the case of a single constraint. Rather than the function <math>g</math> described there, now consider a smooth function <math>G:M\\to \\R^p (p>1),</math> with component functions <math>g_i: M \\to\\R,</math> for which <math>0\\in\\R^p</math> is a [[regular value]]. Let <math>N</math> be the submanifold of <math>M</math> defined by <math>G(x)=0.</math>\n\n<math>x</math> is a stationary point of <math>f|_{N}</math> if and only if <math>\\ker(df_x)</math> contains <math>\\ker(dG_x)</math>. For convenience let <math>L_x=df_x</math> and <math>K_x=dG_x,</math> where <math>dG</math> denotes the tangent map or Jacobian <math>TM\\to T\\R^p.</math> The subspace <math>\\ker(K_x)</math> has dimension smaller than that of <math>\\ker(L_x)</math>, namely <math>\\dim(\\ker(L_x))=n-1</math> and <math>\\dim(\\ker(K_x))=n-p.</math> <math>\\ker(K_x)</math> belongs to <math>\\ker(L_x)</math> if and only if <math>L_x \\in T^*_x M</math> belongs to the image of <math>K^*_x:\\R^{p*}\\to T^*_x M.</math> Computationally speaking, the condition is that <math>L_x</math> belongs to the row space of the matrix of <math>K_x,</math> or equivalently the column space of the matrix of <math>K^*_x</math> (the transpose). If <math>\\omega_x \\in \\Lambda^{p}(T^*_x M)</math> denotes the exterior product of the columns of the matrix of <math>K^*_x,</math> the stationary condition for <math>f|_{N}</math> at <math>x</math> becomes\n\n:<math>L_x \\wedge \\omega_x = 0 \\in \\Lambda^{p+1} \\left (T^*_x M \\right )</math>\n\nOnce again, in this formulation it is not necessary to explicitly find the Lagrange multipliers, the numbers <math>\\lambda_1,\\ldots,\\lambda_p</math> such that \n\n:<math>df_x = \\sum_{i=1}^p \\lambda_i d(g_i)_x.</math>\n\n==Interpretation of the Lagrange multipliers==\nOften the Lagrange multipliers have an interpretation as some quantity of interest.  For example, if the Lagrangian expression is\n\n: <math>\n\\begin{align}\n& \\mathcal{L}(x_1, x_2, \\ldots;\\lambda_1, \\lambda_2, \\ldots) \\\\[4pt]\n= {} & f(x_1, x_2, \\ldots) + \\lambda_1(c_1-g_1(x_1, x_2, \\ldots))+\\lambda_2(c_2-g_2(x_1, x_2, \\dots))+\\cdots\n\\end{align}\n</math>\n\nthen\n\n:<math>\\frac{\\partial \\mathcal{L}}{\\partial c_k} = \\lambda_k.</math>\n\nSo, {{math|''λ<sub>k</sub>''}} is the rate of change of the quantity being optimized as a function of the constraint parameter.\nAs examples, in [[Lagrangian mechanics]] the equations of motion are derived by finding stationary points of the [[Action (physics)|action]], the time integral of the difference between kinetic and potential energy.  Thus, the force on a particle due to a scalar potential, {{math|''F'' {{=}} −∇''V''}}, can be interpreted as a Lagrange multiplier determining the change in action (transfer of potential to kinetic energy) following a variation in the particle's constrained trajectory.  \nIn control theory this is formulated instead as [[costate equations]].\n\nMoreover, by the [[envelope theorem]] the optimal value of a Lagrange multiplier has an interpretation as the marginal effect of the corresponding constraint constant upon the optimal attainable value of the original objective function: if we denote values at the optimum with an asterisk, then it can be shown that\n\n:<math>\\frac{\\text{d} f(x_1^*(c_1, c_2, \\dots), x_2^*(c_1, c_2, \\dots), \\dots)}{\\text{d} c_k} = \\lambda_k^*.</math>\n\nFor example, in economics the optimal profit to a player is calculated subject to a constrained space of actions, where a Lagrange multiplier is the change in the optimal value of the objective function (profit) due to the relaxation of a given constraint (e.g. through a change in income); in such a context {{math|''λ''*}} is the [[marginal cost]] of the constraint, and is referred to as the [[shadow price]].\n\n==Sufficient conditions==\n{{Main|Bordered Hessian}}\n\nSufficient conditions for a constrained local maximum or minimum can be stated in terms of a sequence of principal minors (determinants of upper-left-justified sub-matrices) of the bordered [[Hessian matrix]] of second derivatives of the Lagrangian expression.<ref name=\"SilberbergSuen\" /><ref>{{cite book|authorlink=Alpha Chiang |last=Chiang |first= Alpha C. |title=Fundamental Methods of Mathematical Economics |publisher=McGraw-Hill |edition=Third |date=1984 |page=386 |isbn=0-07-010813-7 }}</ref>\n\n== Examples ==\n\n=== Example 1===\n[[Image:Lagrange very simple.svg|thumb|right|300px|Illustration of the constrained optimization problem]]\n\n====Example 1a====\n\nSuppose we wish to maximize <math>f(x,y)=x+y</math> subject to the constraint <math>x^2+y^2=1</math>. The [[Candidate solution|feasible set]] is the unit circle, and the [[level set]]s of {{mvar|f}} are diagonal lines (with slope −1), so we can see graphically that the maximum occurs at <math>\\left(\\tfrac{\\sqrt{2}}{2},\\tfrac{\\sqrt{2}}{2}\\right)</math>, and that the minimum occurs at <math>\\left(-\\tfrac{\\sqrt{2}}{2},-\\tfrac{\\sqrt{2}}{2}\\right)</math>.\n\nFor the method of Lagrange multipliers, the constraint is\n\n:<math>g(x,y)=x^2+y^2-1,</math>\n\nhence\n\n:<math>\\begin{align} \n\\mathcal{L}(x, y, \\lambda) &= f(x,y) + \\lambda \\cdot g(x,y) \\\\[4pt]\n&= x+y +  \\lambda (x^2 + y^2 - 1).\n\\end{align}</math>\n\nNow we can calculate the gradient:\n\n:<math>\\begin{align}\n\\nabla_{x,y,\\lambda} \\mathcal{L}(x , y, \\lambda) &= \\left( \\frac{\\partial \\mathcal{L}}{\\partial x}, \\frac{\\partial \\mathcal{L}}{\\partial y}, \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} \\right ) \\\\[4pt]\n&= \\left ( 1  + 2 \\lambda x, 1 + 2 \\lambda y, x^2 + y^2 -1 \\right)\n\\end{align}</math>\n\nand therefore:\n\n:<math>\\nabla_{x,y,\\lambda} \\mathcal{L}(x , y, \\lambda)=0 \\quad \\Leftrightarrow \\quad \\begin{cases} 1 + 2 \\lambda x = 0 \\\\ 1 + 2 \\lambda y = 0 \\\\ x^2 + y^2 -1  = 0 \\end{cases}</math>\n\nNotice that the last equation is the original constraint.\n\nThe first two equations yield\n\n:<math>x= y = - \\frac{1}{2\\lambda}, \\qquad \\lambda \\neq 0.</math>\n\nBy substituting into the last equation we have:\n\n:<math>\\frac{1}{4\\lambda^2}+\\frac{1}{4\\lambda^2} - 1=0, </math>\n\nso\n\n:<math>\\lambda = \\pm \\frac{1}{\\sqrt{2}},</math>\n\nwhich implies that the stationary points of <math>\\mathcal{L}</math> are\n\n:<math>\\left(\\tfrac{\\sqrt{2}}{2},\\tfrac{\\sqrt{2}}{2}, -\\tfrac{1}{\\sqrt{2}}\\right), \\qquad \\left(-\\tfrac{\\sqrt{2}}{2}, -\\tfrac{\\sqrt{2}}{2}, \\tfrac{1}{\\sqrt{2}}\\right).</math>\n\nEvaluating the objective function {{mvar|f}} at these points yields\n\n:<math>f\\left(\\tfrac{\\sqrt{2}}{2},\\tfrac{\\sqrt{2}}{2}\\right)=\\sqrt{2}, \\qquad  f\\left(-\\tfrac{\\sqrt{2}}{2}, -\\tfrac{\\sqrt{2}}{2}\\right)=-\\sqrt{2}.</math>\n\nThus the constrained maximum is <math>\\sqrt{2}</math> and the constrained minimum is <math>-\\sqrt{2}</math>.\n\n====Example 1b====\n\nNow we modify the objective function of Example 1a so that we minimize <math>f(x,y)=(x+y)^2</math> instead of <math>f(x,y)=x+y,</math> again along the circle <math>g(x,y)=x^2+y^2-1=0</math>.  Now the level sets of ''f'' are still lines of slope −1, and the points on the circle tangent to these level sets are again <math>(\\sqrt{2}/2,\\sqrt{2}/2)</math> and <math>(-\\sqrt{2}/2,-\\sqrt{2}/2)</math>. These tangency points are maxima of&nbsp;''f''.\n\nOn the other hand, the minima occur on the level set for ''f''&nbsp;=&nbsp;0 (since by its construction ''f'' cannot take negative values), at <math>(\\sqrt{2}/2,-\\sqrt{2}/2)</math> and <math> (-\\sqrt{2}/2, \\sqrt{2}/2)</math>, where the level curves of ''f'' are not tangent to the constraint. The condition that <math>\\nabla f=\\lambda \\, \\nabla g</math> correctly identifies all four points as extrema; the minima are characterized in particular by <math>\\lambda =0.</math>\n\n=== Example 2 ===\n[[Image:Lagrange simple.svg|thumb|right|300px| Illustration of the constrained optimization problem]]\n\nIn this example we will deal with some more strenuous calculations, but it is still a single constraint problem.\n\nSuppose we want to find the maximum values of\n\n:<math> f(x, y) = x^2 y</math>\n\nwith the condition that the {{mvar|x}} and {{mvar|y}} coordinates lie on the circle around the origin with radius {{radic|3}}, that is, subject to the constraint\n\n:<math> g(x,y) = x^2 + y^2 - 3 = 0.</math>\n\nAs there is just a single constraint, we will use only one multiplier, say {{mvar|λ}}.\n\nThe constraint {{math|''g''(''x'', ''y'')}} is identically zero on the circle of radius {{radic|3}}. See that any multiple of {{math|''g''(''x'', ''y'')}} may be added to {{math|''f''(''x'',&nbsp;''y'')}} leaving {{math|''f''(''x'',&nbsp;''y'')}} unchanged in the region of interest (on the circle where our original constraint is satisfied).\n\nApply the ordinary Langrange multiplier method. Let:\n\n:<math>\\begin{align}\n\\mathcal{L}(x, y, \\lambda) &= f(x,y) + \\lambda \\cdot g(x, y) \\\\\n&= x^2y +  \\lambda (x^2 + y^2 - 3)\n\\end{align}</math>\n\nNow we can calculate the gradient:\n\n:<math>\\begin{align}\n\\nabla_{x,y,\\lambda} \\mathcal{L}(x , y, \\lambda) &= \\left ( \\frac{\\partial \\mathcal{L}}{\\partial x}, \\frac{\\partial \\mathcal{L}}{\\partial y}, \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} \\right ) \\\\\n&= \\left ( 2 x y + 2 \\lambda x, x^2 + 2 \\lambda y, x^2 + y^2 -3 \\right )\n\\end{align}</math>\n\nAnd therefore:\n\n:<math>\\nabla_{x,y,\\lambda} \\mathcal{L}(x , y, \\lambda)=0 \\quad \\Leftrightarrow \\quad \\begin{cases} 2 x y + 2 \\lambda x = 0 \\\\ x^2 + 2 \\lambda y = 0 \\\\ x^2 + y^2 - 3 = 0 \\end{cases} \\quad \\Leftrightarrow \\quad \\begin{cases} x (y + \\lambda) = 0 & \\text{(i)} \\\\ x^2 = -2 \\lambda y & \\text{(ii)} \\\\ x^2 + y^2 = 3 & \\text{(iii)} \\end{cases} </math>\n\nNotice that (iii) is just the original constraint. (i) implies {{math|''x'' {{=}} 0}} ''or'' {{math|''λ'' {{=}} −''y''}}. If {{math|''x'' {{=}} 0}} then <math>y = \\pm \\sqrt{3}</math> by (iii) and consequently  {{math|''λ'' {{=}} 0}} from (ii). If {{math|''λ'' {{=}} −''y''}}, substituting in (ii) we get {{math|''x''<sup>2</sup> {{=}} 2''y''<sup>2</sup>}}. Substituting this in (iii) and solving for {{mvar|y}} gives {{math|''y'' {{=}} ±1}}. Thus there are six critical points of <math>\\mathcal{L}</math>:\n\n:<math> (\\sqrt{2},1,-1); \\quad (-\\sqrt{2},1,-1); \\quad (\\sqrt{2},-1,1); \\quad (-\\sqrt{2},-1,1); \\quad (0,\\sqrt{3}, 0); \\quad (0,-\\sqrt{3}, 0). </math>\n\nEvaluating the objective at these points, we find that\n\n:<math> f(\\pm\\sqrt{2},1) = 2; \\quad f(\\pm\\sqrt{2},-1) = -2; \\quad f(0,\\pm \\sqrt{3})=0. </math>\n\nTherefore, the  objective function attains the [[global maximum]] (subject to the constraints) at <math>(\\pm\\sqrt{2},1)</math> and the [[global minimum]] at <math>(\\pm\\sqrt{2},-1).</math> The point <math>(0,\\sqrt{3})</math> is a [[local minimum]] of ''f'' and <math>(0,-\\sqrt{3})</math> is a [[local maximum]] of ''f'', as may be determined by consideration of the [[Hessian (mathematics)#Bordered Hessian|Hessian matrix]] of <math>\\mathcal{L}(x,y,0)</math>.\n\nNote that while <math>(\\sqrt{2}, 1, -1)</math> is a critical point of <math>\\mathcal{L}</math>, it is not a local extremum of <math>\\mathcal{L}.</math> We have\n\n:<math>\\mathcal{L} \\left (\\sqrt{2} + \\varepsilon, 1, -1 + \\delta \\right ) = 2 + \\delta \\left( \\varepsilon^2 + \\left (2\\sqrt{2} \\right)\\varepsilon \\right ).</math>\n\nGiven any neighbourhood of <math>(\\sqrt{2}, 1, -1)</math>, we can choose a small positive <math>\\varepsilon</math> and a small <math>\\delta</math> of either sign to get <math>\\mathcal{L}</math> values both greater and less than <math>2</math>. This can also be seen from the fact that the Hessian matrix of <math>\\mathcal{L}</math> evaluated at this point (or indeed at any of the critical points) is an [[indefinite matrix]]. Each of the critical points of <math>\\mathcal{L}</math> is a [[saddle point]] of <math>\\mathcal{L}.</math>\n\n=== Example 3: [[Entropy]] ===\nSuppose we wish to find the [[Probability distribution#Discrete probability distribution|discrete probability distribution]] on the points <math>\\{p_1, p_2, \\ldots, p_n\\}</math> with maximal [[information entropy]]. This is the same as saying that we wish to find the [[Principle of maximum entropy|least structured]] probability distribution on the points <math>\\{p_1, p_2, \\cdots, p_n\\}</math>. In other words, we wish to maximize the [[Shannon entropy]] equation:\n\n:<math>f(p_1,p_2,\\ldots,p_n) = -\\sum_{j=1}^n p_j\\log_2 p_j.</math>\n\nFor this to be a probability distribution the sum of the probabilities <math> p_i </math> at each point <math>x_i</math> must equal 1, so our constraint is:\n\n:<math>g(p_1,p_2,\\ldots,p_n)=\\sum_{j=1}^n p_j = 1.</math>\n\nWe use Lagrange multipliers to find the point of maximum entropy, <math>\\vec{p}^{\\,*}</math>, across all discrete probability distributions <math>\\vec{p}</math> on <math>\\{x_1,x_2, \\ldots, x_n\\}</math>. We require that:\n\n:<math>\\left.\\frac{\\partial}{\\partial \\vec{p}}(f+\\lambda (g-1))\\right|_{\\vec{p}=\\vec{p}^{\\,*}}=0,</math>\n\nwhich gives a system of {{mvar|n}} equations, <math> k = 1,\\ldots,n</math>, such that:\n\n:<math>\\left.\\frac{\\partial}{\\partial p_k}\\left\\{-\\left (\\sum_{j=1}^n p_j \\log_2 p_j \\right ) + \\lambda \\left(\\sum_{j=1}^n p_j - 1\\right) \\right\\}\\right|_{p_k=p^*_k} = 0.</math>\n\nCarrying out the differentiation of these {{mvar|n}} equations, we get\n\n:<math>-\\left(\\frac{1}{\\ln 2}+\\log_2 p^*_k \\right)  + \\lambda = 0.</math>\n\nThis shows that all <math>p^*_k</math> are equal (because they depend on {{mvar|λ}} only). By using the constraint\n\n:<math>\\sum_j p_j =1,</math>\n\nwe find\n\n:<math>p^*_k = \\frac{1}{n}.</math>\n\nHence, the uniform distribution is the distribution with the greatest entropy, among distributions on {{mvar|n}} points.\n\n=== Example 4: Numerical optimization ===\n[[Image:lagnum1.png|thumb|right|300px|Lagrange multipliers cause the critical points to occur at saddle points.]]\n\n[[Image:lagnum2.png|thumb|right|300px|The magnitude of the gradient can be used to force the critical points to occur at local minima.]]\n\nThe critical points of Lagrangians occur at [[saddle point]]s, rather than at local maxima (or minima).<ref name=\"Heath2005\">{{cite book|first=Michael T.|last= Heath|authorlink=Michael Heath (computer scientist)|title=Scientific Computing: An Introductory Survey|url=https://books.google.com/books?id=gwBrMAEACAAJ|pages=203|year=2005|publisher=McGraw-Hill|isbn=978-0-07-124489-3|ref=harv}}</ref> Unfortunately, many numerical optimization techniques, such as [[hill climbing]], [[gradient descent]], some of the [[quasi-Newton method]]s, among others, are designed to find local maxima (or minima) and not saddle points. For this reason, one must either modify the formulation to ensure that it's a minimization problem (for example, by extremizing the square of the [[gradient]] of the Lagrangian as below), or else use an optimization technique that finds [[stationary points]] (such as [[Newton's method in optimization|Newton's method]] without an extremum seeking [[line search]]) and not necessarily extrema.\n\nAs a simple example, consider the problem of finding the value of {{mvar|x}} that minimizes <math>f(x)=x^2</math>, constrained such that <math>x^2=1</math>. (This problem is somewhat pathological because there are only two values that satisfy this constraint, but it is useful for illustration purposes because the corresponding unconstrained function can be visualized in three dimensions.)\n\nUsing Lagrange multipliers, this problem can be converted into an unconstrained optimization problem:\n\n:<math>\\mathcal{L}(x,\\lambda)=x^2+\\lambda(x^2-1).</math>\n\nThe two critical points occur at saddle points where {{math|''x'' {{=}} 1}} and {{math|''x'' {{=}} −1}}.\n\nIn order to solve this problem with a numerical optimization technique, we must first transform this problem such that the critical points occur at local minima. This is done by computing the magnitude of the gradient of the unconstrained optimization problem.\n\nFirst, we compute the partial derivative of the unconstrained problem with respect to each variable:\n\n:<math>\n\\begin{align}\n& \\frac{\\partial \\mathcal{L}}{\\partial x}=2x+2x\\lambda \\\\[5pt]\n& \\frac{\\partial \\mathcal{L}}{\\partial \\lambda}=x^2-1.\n\\end{align}\n</math>\n\nIf the target function is not easily differentiable, the differential with respect to each variable can be approximated as\n\n: <math>\n\\begin{align}\n\\frac{\\partial \\mathcal{L}}{\\partial x}\\approx\\frac{\\mathcal{L}(x+\\varepsilon,\\lambda)-\\mathcal{L}(x,\\lambda)}{\\varepsilon}, \\\\[5pt]\n\\frac{\\partial \\mathcal{L}}{\\partial \\lambda}\\approx\\frac{\\mathcal{L}(x,\\lambda+\\varepsilon)-\\mathcal{L}(x,\\lambda)}{\\varepsilon},\n\\end{align}\n</math>\n\nwhere <math>\\varepsilon</math> is a small value.\n\nNext, we compute the magnitude of the gradient, which is the square root of the sum of the squares of the partial derivatives:\n\n: <math>\n\\begin{align}\nh(x,\\lambda) & = \\sqrt{(2x+2x\\lambda)^2+(x^2-1)^2} \\\\[4pt]\n& \\approx\\sqrt{\\left(\\frac{\\mathcal{L}(x+\\varepsilon,\\lambda)-\\mathcal{L}(x,\\lambda)}{\\varepsilon}\\right)^2+\\left(\\frac{\\mathcal{L}(x,\\lambda+\\varepsilon)-\\mathcal{L}(x,\\lambda)}{\\varepsilon}\\right)^2}.\n\\end{align}\n</math>\n\n(Since magnitude is always non-negative, optimizing over the squared-magnitude is equivalent to optimizing over the magnitude. Thus, the <nowiki>''</nowiki>square root\" may be omitted from these equations with no expected difference in the results of optimization.)\n\nThe critical points of {{mvar|h}} occur at {{math|''x'' {{=}} 1}} and {{math|''x'' {{=}} −1}}, just as in <math>\\mathcal{L}</math>. Unlike the critical points in <math>\\mathcal{L}</math>, however, the critical points in {{mvar|h}} occur at local minima, so numerical optimization techniques can be used to find them.\n\n==Applications==\n\n===Control theory===\nIn [[optimal control]] theory, the Lagrange multipliers are interpreted as [[costate]] variables, and Lagrange multipliers are reformulated as the minimization of the [[Hamiltonian (control theory)|Hamiltonian]], in [[Pontryagin's minimum principle]].\n\n===Nonlinear programming===\nThe Lagrange multiplier method has several generalizations. In [[nonlinear programming]] there are several multiplier rules, e.g. the Carathéodory–John Multiplier Rule and the Convex Multiplier Rule, for inequality constraints.<ref>{{Cite journal |last=Pourciau |first=Bruce H. |date=1980 |title=Modern multiplier rules |url=http://www.maa.org/programs/maa-awards/writing-awards/modern-multiplier-rules |journal=[[American Mathematical Monthly]] |volume=87 |issue=6 |pages=433–452 |doi=10.2307/2320250 |jstor=2320250}}</ref>\n\n==See also==\n{{div col}}\n* [[Adjustment of observations]]\n* [[Duality (optimization)|Duality]]\n* [[Gittins index]]\n* [[Karush–Kuhn–Tucker conditions]]: generalization of the method of Lagrange multipliers\n* [[Lagrange multipliers on Banach spaces]]: another generalization of the method of Lagrange multipliers\n* [[Lagrange multiplier test]] in maximum likelihood estimation\n* [[Lagrangian relaxation]]\n{{colend}}\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n*{{cite book |first=Brian |last=Beavis |first2=Ian M. |last2=Dobbs |chapter=Static Optimization |title=Optimization and Stability Theory for Economic Analysis |location=New York |publisher=Cambridge University Press |year=1990 |isbn=0-521-33605-8 |pages=32–72 |chapterurl=https://books.google.com/books?id=L7HMACFgnXMC&pg=PA32 }}\n*{{cite book |first=Dimitri P. |last=Bertsekas |authorlink=Dimitri Bertsekas |title=Constrained Optimization and Lagrange Multiplier Methods |location=New York |publisher=Academic Press |year=1982 |isbn=0-12-093480-9 }}\n*{{cite book |first=Gordon S. G. |last=Beveridge |first2=Robert S. |last2=Schechter |chapter=Lagrangian Multipliers |title=Optimization: Theory and Practice |location=New York |publisher=McGraw-Hill |year=1970 |pages=244–259 |isbn=0-07-005128-3 |chapterurl=https://books.google.com/books?id=TfhVXlWtOPQC&pg=PA244 }}\n*{{cite book |first=Michael |last=Carter |chapter=Equality Constraints |title=Foundations of Mathematical Economics |location=Cambridge |publisher=MIT Press |year=2001 |pages=516–549 |isbn=0-262-53192-5 |chapterurl=https://books.google.com/books?id=KysvrGGfzq0C&pg=PA516 }}\n*{{cite book |first=Magnus R. |last=Hestenes |authorlink=Magnus Hestenes |chapter=Minima of functions subject to equality constraints |title=Calculus of Variations and Optimal Control Theory |location=New York |publisher=Wiley |year=1966 |pages=29–34 |isbn= }}\n*{{cite book |first=C. Ray |last=Wylie |first2=Louis C. |last2=Barrett |chapter=The Extrema of Integrals under Constraint |title=Advanced Engineering Mathematics |location=New York |publisher=McGraw-Hill |edition=Sixth |year=1995 |pages=1096–1103 |isbn=0-07-072206-4 }}\n\n==External links==\n{{wikibooks|Calculus optimization methods|Lagrange multipliers}}\nExposition\n*[http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html Conceptual introduction] (plus a brief discussion of Lagrange multipliers in the [[calculus of variations]] as used in physics)\n*[http://ece.k-state.edu/people/faculty/carpenter/documents/lagrange.pdf Lagrange Multipliers for Quadratic Forms With Linear Constraints] by Kenneth H. Carpenter\nFor additional text and interactive applets\n*[http://www.umiacs.umd.edu/~resnik/ling848_fa2004/lagrange.html Simple explanation with an example of governments using taxes as Lagrange multipliers]\n*[http://nlp.cs.berkeley.edu/tutorials/lagrange-multipliers.pdf Lagrange Multipliers without Permanent Scarring] Explanation with focus on the intuition by Dan Klein\n*[http://demonstrations.wolfram.com/GeometricRepresentationOfMethodOfLagrangeMultipliers Geometric Representation of Method of Lagrange Multipliers] Provides compelling insight in 2 dimensions that at a minimizing point, the direction of steepest descent must be perpendicular to the tangent of the constraint curve at that point. [Needs InternetExplorer/Firefox/Safari] ''Mathematica'' demonstration by Shashi Sathyanarayana\n*[http://ocw.mit.edu/ans7870/18/18.02/f07/tools/LagrangeMultipliersTwoVariables.html Applet]\n*[http://ocw.mit.edu/courses/mathematics/18-02-multivariable-calculus-fall-2007/video-lectures/lecture-13-lagrange-multipliers/ MIT OpenCourseware Video Lecture on Lagrange Multipliers from Multivariable Calculus course]\n*[http://www.athenasc.com/NLP_Slides.pdf Slides accompanying Bertsekas's nonlinear optimization text], with details on Lagrange multipliers (lectures 11 and 12)\n*[http://www-mtl.mit.edu/Courses/6.050/2004/unit9/wyatt.apr.7.pdf Geometric idea behind Lagrange multipliers]\n*[http://matlab.cheme.cmu.edu/2011/12/24/using-lagrange-multipliers-in-optimization/ MATLAB example of using Lagrange Multipliers in Optimization]\n\n[[Category:Multivariable calculus]]\n[[Category:Mathematical optimization]]\n[[Category:Mathematical and quantitative methods (economics)]]"
    },
    {
      "title": "Linear complementarity problem",
      "url": "https://en.wikipedia.org/wiki/Linear_complementarity_problem",
      "text": "In mathematical [[optimization (mathematics)|optimization theory]], the '''linear complementarity problem (LCP)''' arises frequently in [[computational mechanics]] and encompasses the well-known [[quadratic programming]] as a special case.  It was proposed by Cottle and [[George Dantzig|Dantzig]] {{nowrap|in&nbsp;1968.<ref name=\"Murty88\"/><ref name=\"CPS92\"/><ref>R. W. Cottle and [[G. B. Dantzig]]. Complementary pivot theory of mathematical programming. ''Linear Algebra and its Applications'', 1:103-125, 1968.</ref>}}\n\n== Formulation ==\nGiven a real matrix ''M'' and vector ''q'', the linear complementarity problem LCP(''M'', ''q'') seeks vectors ''z'' and ''w'' which satisfy the following constraints:\n\n* <math>w, z \\geqslant 0,</math> (that is, each component of these two vectors is non-negative)\n* <math>z^Tw = 0</math> or equivalently <math>\\sum\\nolimits_i w_i z_i = 0.</math> This is the [[Complementarity theory|complementarity]] condition, since it implies that, for all <math>i</math>, at most one of <math>w_i</math> and <math>z_i</math> can be positive.\n* <math>w = Mz + q</math>\n\nA sufficient condition for existence and uniqueness of a solution to this problem is that ''M'' be [[Symmetric matrix|symmetric]] [[Positive-definite matrix|positive-definite]]. If ''M'' is such that {{math|LCP(''M'', ''q'')}} have a solution for every ''q'', then ''M'' is a [[Q-matrix]]. If ''M'' is such that {{math|LCP(''M'', ''q'')}} have a unique solution for every ''q'', then ''M'' is a [[P-matrix]]. Both of these characterizations are sufficient and necessary.<ref>{{cite journal|last1=Murty|first1=Katta G.|title=On the number of solutions to the complementarity problem and spanning properties of complementary cones|journal=Linear Algebra and its Applications|date=January 1972|volume=5|issue=1|pages=65–108|doi=10.1016/0024-3795(72)90019-5}}</ref>\n\nThe vector ''w'' is a [[slack variable]],<ref>{{citation|title=Convex Optimization of Power Systems|first=Joshua Adam|last=Taylor|publisher=Cambridge University Press|year=2015| isbn=9781107076877|page=172|url=https://books.google.com/books?id=JBdoBgAAQBAJ&pg=PA172}}.</ref> and so is generally discarded after ''z'' is found. As such, the problem can also be formulated as:\n\n* <math>Mz+q \\geqslant 0</math>\n* <math>z \\geqslant 0</math>\n* <math>z^{\\mathrm{T}}(Mz+q) = 0</math> (the complementarity condition)\n\n==Convex quadratic-minimization: Minimum conditions==\nFinding a solution to the linear complementarity problem is associated with minimizing the quadratic function\n\n: <math>f(z) = z^T(Mz+q)</math>\n\nsubject to the constraints\n\n: <math>{Mz}+q \\geqslant 0</math>\n: <math>z \\geqslant 0</math>\n\nThese constraints ensure that ''f'' is always non-negative. The minimum of ''f'' is 0 at ''z'' if and only if ''z'' solves the linear complementarity problem.\n\nIf ''M'' is [[Positive-definite matrix|positive definite]], any algorithm for solving (strictly) convex [[Quadratic programming|QPs]] can solve the LCP.  Specially designed basis-exchange pivoting algorithms, such as [[Lemke's algorithm]] and a variant of the [[simplex algorithm|simplex algorithm of Dantzig]] have been used for decades. Besides having polynomial time complexity, interior-point methods are also effective in practice.\n\nAlso, a quadratic-programming problem stated as minimize <math>f(x)=c^Tx+\\tfrac{1}{2} x^T Qx</math> subject to <math>Ax \\geqslant b</math> as well as <math>x \\geqslant 0</math> with ''Q'' symmetric\n\nis the same as solving the LCP with\n\n:<math>q = \\begin{bmatrix} c \\\\ -b \\end{bmatrix}, \\qquad M = \\begin{bmatrix} Q & -A^T \\\\ A & 0 \\end{bmatrix}</math>\n\nThis is because the [[Karush–Kuhn–Tucker]] conditions of the QP problem can be written as:\n\n:<math>\\begin{cases} \nv = Q x - A^T {\\lambda} + c \\\\ \ns = A x - b \\\\ \nx, {\\lambda}, v, s \\geqslant 0 \\\\ \nx^{T} v+ {\\lambda}^T s = 0\n\\end{cases}</math>\n\nwith ''v'' the Lagrange multipliers on the non-negativity constraints, ''λ'' the <!-- Lagrange  -->multipliers on the inequality constraints, and ''s'' the slack variables for the inequality constraints. The fourth condition derives from the complementarity of each group of variables {{math|(''x'', ''s'')}} with its set of KKT vectors (optimal Lagrange multipliers) being {{math|(''v'', ''λ'')}}. In that case,\n\n: <math>z = \\begin{bmatrix} x \\\\ \\lambda \\end{bmatrix}, \\qquad w = \\begin{bmatrix} v \\\\ s \\end{bmatrix}</math>\n\nIf the non-negativity constraint on the ''x'' is relaxed, the dimensionality of the LCP problem can be reduced to the number of the inequalities, as long as ''Q'' is non-singular (which is guaranteed if it is [[Positive-definite matrix|positive definite]]). The multipliers ''v'' are no longer present, and the first KKT conditions can be rewritten as:\n\n: <math>Q x = A^{T} {\\lambda} - c</math>\n\nor:\n\n: <math> x = Q^{-1}(A^{T} {\\lambda} - c)</math>\n\npre-multiplying the two sides by ''A'' and subtracting ''b'' we obtain:\n\n: <math> A x - b = A Q^{-1}(A^{T} {\\lambda} - c) -b \\,</math>\n\nThe left side, due to the second KKT condition, is ''s''. Substituting and reordering:\n\n: <math> s = (A Q^{-1} A^{T}) {\\lambda} + (- A Q^{-1} c - b )\\,</math>\n\nCalling now\n\n:<math>\\begin{align}\nM &:= (A Q^{-1} A^{T}) \\\\\nQ &:=  (- A Q^{-1} c - b)\n\\end{align}</math>\n\nwe have an LCP, due to the relation of complementarity between the slack variables ''s'' and their Lagrange multipliers ''λ''. Once we solve it, we may obtain the value of ''x'' from ''λ''  through the first KKT condition.\n\nFinally, it is also possible to handle additional equality constraints:\n\n: <math>A_{eq}x = b_{eq}</math>\n\nThis introduces a vector of Lagrange multipliers ''μ'', with the same dimension as <math>b_{eq}</math>.\n\nIt is easy to verify that the ''M'' and ''Q'' for the LCP system <math> s = M {\\lambda} + Q</math> are now expressed as:\n\n:<math>\\begin{align}\nM &:= \\begin{bmatrix} A & 0 \\end{bmatrix}  \\begin{bmatrix} Q & A_{eq}^{T} \\\\ -A_{eq} & 0 \\end{bmatrix}^{-1}  \\begin{bmatrix} A^T \\\\ 0 \\end{bmatrix}  \\\\\nQ &:= - \\begin{bmatrix} A & 0 \\end{bmatrix}  \\begin{bmatrix} Q & A_{eq}^{T} \\\\ -A_{eq} & 0 \\end{bmatrix}^{-1} \\begin{bmatrix} c \\\\ b_{eq} \\end{bmatrix} - b\n\\end{align}</math>\n\nFrom ''λ'' we can now recover the values of both ''x'' and the Lagrange multiplier of equalities ''μ'':\n\n:<math>\\begin{bmatrix} x \\\\ \\mu \\end{bmatrix} = \\begin{bmatrix} Q & A_{eq}^{T} \\\\ -A_{eq} & 0 \\end{bmatrix}^{-1} \\begin{bmatrix} A^T \\lambda - c \\\\ -b_{eq} \\end{bmatrix}</math>\n\nIn fact, most QP solvers work on the LCP formulation, including the [[interior point method]], principal / complementarity pivoting, and [[active set]] methods.<ref name=\"Murty88\">{{harvtxt|Murty|1988}}</ref><ref name=\"CPS92\">{{harvtxt|Cottle|Pang|Stone|1992}}</ref> LCP problems can be solved also by the [[criss-cross algorithm]],<ref>{{harvtxt|Fukuda|Namiki|1994}}</ref><ref>{{harvtxt|Fukuda|Terlaky|1997}}</ref><ref name=\"HRT\">{{cite journal|first1=D. |last1=den&nbsp;Hertog |first2=C.| last2=Roos |first3=T. |last3=Terlaky|title=The linear complementarity problem, sufficient matrices, and the criss-cross method|journal=Linear Algebra and its Applications|volume=187|date=1 July 1993|pages=1–14|url=http://core.ac.uk/download/pdf/6714737.pdf|doi=10.1016/0024-3795(93)90124-7}}</ref><ref name=\"CIsufficient\">{{cite journal |first1=Zsolt |last1=Csizmadia |first2=Tibor |last2=Illés|title=New criss-cross type algorithms for linear complementarity problems with sufficient matrices|journal=Optimization Methods and Software| volume=21 |year=2006 |number=2 |pages=247–266|doi=10.1080/10556780500095009|url=http://www.cs.elte.hu/opres/orr/download/ORR03_1.pdf|<!-- ref=harv -->}}</ref> conversely, for linear complementarity problems, the criss-cross algorithm terminates finitely only if the matrix is a sufficient matrix.<ref name=\"HRT\"/><ref name=\"CIsufficient\"/> A [[sufficient&nbsp;matrix]] is a generalization both of a [[positive-definite matrix]] and of a [[P-matrix]], whose [[principal&nbsp;minor]]s are each positive.<ref name=\"HRT\"/><ref name=\"CIsufficient\"/><ref>{{cite journal| last1=Cottle | first1=R.&nbsp;W. |authorlink1=Richard W. Cottle|last2=Pang|first2=J.-S.|last3=Venkateswaran|first3=V.|title=Sufficient matrices and the linear&nbsp;complementarity problem |journal=Linear Algebra and its Applications|volume=114–115|date=March–April 1989|pages=231–249|doi=10.1016/0024-3795(89)90463-1 |url=http://www.sciencedirect.com/science/article/pii/0024379589904631 |mr=986877|ref=harv}}</ref>\nSuch LCPs can be solved when they are formulated abstractly using [[oriented matroid|oriented-matroid]] theory.<ref name=\"Todd\" >{{harvtxt|Todd|1985|}}</ref><ref>{{harvtxt|Terlaky|Zhang|1993}}: {{cite journal|last1=Terlaky|first1=Tamás|<!-- authorlink1=Tamás Terlaky -->|last2=Zhang|first2=Shu&nbsp;Zhong|title=Pivot rules for linear programming: A Survey on recent theoretical developments|series=Degeneracy in optimization problems|journal=Annals of Operations Research|volume=46–47|year=1993|issue=1|pages=203–233|doi=10.1007/BF02096264|mr=1260019|citeseerx=10.1.1.36.7658 |issn=0254-5330|ref=harv}}</ref><ref>{{cite book|last=Björner|first=Anders|last2=Las&nbsp;Vergnas|author2-link=Michel Las Vergnas|first2=Michel|last3=Sturmfels|first3=Bernd|authorlink3=Bernd Sturmfels|last4=White|first4=Neil|last5=Ziegler|first5=Günter|authorlink5=Günter M. Ziegler|title=Oriented Matroids|chapter=10 Linear programming|publisher=Cambridge University Press|year=1999|isbn=978-0-521-77750-6|chapter-url=http://ebooks.cambridge.org/ebook.jsf?bid=CBO9780511586507|pages=417–479|doi=10.1017/CBO9780511586507|mr=1744046}}</ref>\n\n== See also ==\n*[[Complementarity theory]]\n*[[Physics engine]] Impulse/constraint type physics engines for games use this approach.\n*[[Contact dynamics]] Contact dynamics with the nonsmooth approach.\n*[[Bimatrix game]]s can be reduced to a LCP.\n\n==Notes==\n{{Reflist}}\n\n== References ==\n\n* {{cite book|last1=Cottle|first1=Richard W.|last2=Pang|first2=Jong-Shi|last3=Stone|first3=Richard E.|title=The linear complementarity problem | series=Computer Science and Scientific Computing|publisher=Academic Press, Inc.|location=Boston, MA|year=1992|pages=xxiv+762 pp|isbn=978-0-12-192350-1|mr=1150683|ref=harv}}\n*{{cite journal|last1=Cottle|first1=R.&nbsp;W.|authorlink1=Richard W. Cottle|last2=Pang|first2=J.-S.|last3=Venkateswaran|first3=V.|title=Sufficient matrices and the linear&nbsp;complementarity problem|journal=Linear Algebra and its Applications|volume=114–115|date=March–April 1989|pages=231–249|doi=10.1016/0024-3795(89)90463-1| url=http://www.sciencedirect.com/science/article/pii/0024379589904631|mr=986877|ref=harv}}\n* {{cite journal|first1=Zsolt|last1=Csizmadia|first2=Tibor|last2=Illés|title=New criss-cross type algorithms for linear complementarity problems with sufficient matrices|journal=Optimization Methods and Software|volume=21|year=2006|number=2|pages=247–266|doi=10.1080/10556780500095009|\nurl=http://www.cs.elte.hu/opres/orr/download/ORR03_1.pdf|<!-- ref=harv -->}}\n* {{cite journal|last1=Fukuda|first1=Komei|authorlink1=Komei Fukuda|last2=Namiki|first2=Makoto|title=On extremal behaviors of Murty's least index method|journal=Mathematical Programming|date=March 1994|pages=365–370|volume=64|issue=1|doi=10.1007/BF01582581|ref=harv|mr=1286455}}\n* {{cite journal|first1=D. |last1=den&nbsp;Hertog|first2=C.|last2=Roos|first3=T.|last3=Terlaky|title=The linear complementarity problem, sufficient matrices, and the criss-cross method| journal=Linear Algebra and its Applications|volume=187|date=1 July 1993|pages=1–14|url=http://core.ac.uk/download/pdf/6714737.pdf|doi=10.1016/0024-3795(93)90124-7|ref=harv}}\n* {{cite book|last=Murty|first=K. G.|title=Linear complementarity, linear and nonlinear programming|series=Sigma Series in Applied Mathematics|volume=3|publisher=Heldermann Verlag|location=Berlin|year=1988|pages=xlviii+629 pp|isbn=978-3-88538-403-8|url=http://ioe.engin.umich.edu/people/fac/books/murty/linear_complementarity_webbook/|mr=949214|id=[http://www-personal.umich.edu/~murty/ Updated and free PDF version at Katta G. Murty's website]|ref=harv|deadurl=yes|archiveurl=https://web.archive.org/web/20100401043940/http://ioe.engin.umich.edu/people/fac/books/murty/linear_complementarity_webbook/|archivedate=2010-04-01|df=}}\n* {{cite journal|first1=Komei|last1=Fukuda|<!-- authorlink1=Komei Fukuda -->|first2=Tamás|last2=Terlaky|<!-- authorlink2=Tamás Terlaky -->|title=Criss-cross methods: A fresh view on pivot algorithms|journal=Mathematical Programming, Series B|volume=79|issue=1–3| pages=369–395|series=Papers from the&nbsp;16th International Symposium on Mathematical Programming held in Lausanne,&nbsp;1997|editors=Thomas&nbsp;M. Liebling and Dominique de&nbsp;Werra|year=1997|doi=10.1007/BF02614325|mr=1464775|ref=harv|id=[http://www.cas.mcmaster.ca/~terlaky/files/crisscross.ps Postscript preprint]|citeseerx=10.1.1.36.9373}}\n*{{cite journal|last=Todd|first=Michael&nbsp;J.|authorlink=Michael J. Todd (mathematician)|title=Linear and quadratic programming in oriented matroids|journal=Journal of Combinatorial Theory|series=Series&nbsp;B|volume=39|year=1985|issue=2|pages=105–133|mr=811116|doi=10.1016/0095-8956(85)90042-5|ref=harv}}\n*{{cite web | url=http://www.utdallas.edu/~chandra/documents/6311/bimatrix.pdf | title=Bimatrix games | accessdate=18 December 2015 | author=R. Chandrasekaran | pages=5–7}}\n\n==Further reading==\n* R. W. Cottle and [[G. B. Dantzig]]. Complementary pivot theory of mathematical programming. ''Linear Algebra and its Applications'', 1:103-125, 1968.\n* {{cite journal|last1=Terlaky|first1=Tamás|<!-- authorlink1=Tamás Terlaky -->|last2=Zhang|first2=Shu&nbsp;Zhong|title=Pivot rules for linear programming: A Survey on recent theoretical developments|series=Degeneracy in optimization problems|journal=Annals of Operations Research|volume=46–47|year=1993|issue=1|pages=203–233|doi=10.1007/BF02096264|mr=1260019|citeseerx=10.1.1.36.7658 |issn=0254-5330|ref=harv}}\n\n== External links ==\n* [https://web.archive.org/web/20041029022008/http://www.american.edu/econ/gaussres/optimize/quadprog.src LCPSolve] &mdash; A simple procedure in GAUSS to solve a linear complementarity problem\n* [[Siconos]]/Numerics open-source GPL  implementation in C of Lemke's algorithm and other methods to solve LCPs and MLCPs\n\n{{Mathematical programming}}\n\n[[Category:Linear algebra]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Linear search problem",
      "url": "https://en.wikipedia.org/wiki/Linear_search_problem",
      "text": "In [[computational complexity theory]]<!-- I think -->, the '''linear search problem''' is an optimal search problem introduced by [[Richard E. Bellman]].<ref>R. Bellman. An optimal search problem, SIAM Rev. (1963).</ref> (independently considered by [[Anatole Beck]]<ref>A. Beck. On the linear search Problem, Israel J. Mathematics (1964).</ref><ref>A. Beck. More on the linear search problem, Israel J. Mathematics (1965).</ref><ref>A. Beck and M. Beck. The linear search problem rides again, Israel J. Mathematics (1986).</ref>).\n\n== The problem ==\n\n\"An immobile hider is located on the real line according to a known probability distribution. A searcher, whose maximal velocity is one, starts from the origin and wishes to discover the hider in minimal expected time. It is assumed that the searcher can change the direction of his motion without any loss of time. It is also assumed that the searcher cannot see the hider until he actually reaches the point at which the hider is located and the time elapsed until this moment is the duration of the game.\" In order to find the hider the searcher has to go a distance x<sub>1</sub> in one direction, return to the origin and go distance x<sub>2</sub> in the other direction etc., (the length of the n-th step being denoted by x<sub>n</sub>), and to do it in an optimal way. (However, an optimal solution need not have a first step and could start with an infinite number of small 'oscillations'.) This problem is usually called the linear search problem and a search plan is called a trajectory. It has attracted much research, some of it quite recent.\n\nThe linear search problem for a general probability distribution is unsolved.<ref>{{citation|contribution=Chapter 8. Search on the Infinite Line|title=The Theory of Search Games and Rendezvous, Part 2|series=International Series in Operations Research & Management Science|volume=55|year=2003|pages=123–144|doi=10.1007/0-306-48212-6_8|first1=Steve|last1=Alpern|first2=Shmuel|last2=Gal}}. On p.&nbsp;124, Alpern and Gal write \"no algorithm for solving the problem for a general probability distribution function has been found during about 37 years since the LSP was first presented.\"</ref> However, there exists a [[dynamic programming]] algorithm that produces a solution for any discrete distribution<ref>F. T. Bruss and J. B. Robertson. A survey of the linear-search problem. Math. Sci. 13, 75-84, (1988).</ref> and also an approximate solution, for any probability distribution, with any desired accuracy.<ref>S. Alpern and S. Gal. ''The Theory of Search Games and Rendezvous''. Springer (2003): 139--143.</ref>\n\nThe linear search problem was solved by Anatole Beck and [[Donald J. Newman]] (1970) as a two-person zero-sum game. Their [[minimax]] trajectory is to double the distance on each step and the optimal strategy is a mixture of trajectories that increase the distance by some fixed constant.<ref>A. Beck and D.J. Newman. Yet More on the linear search problem. Israel J. Math. (1970).</ref> This solution gives search strategies that are not sensitive to assumptions concerning the distribution of the target. Thus, it also presents an upper bound for a worst-case scenario. This solution was obtained in the framework of an [[online algorithm]] by [[Shmuel Gal]], who also generalized this result to a set of concurrent rays.<ref>S. Gal. SEARCH GAMES, Academic Press (1980).</ref> The best online [[competitive ratio]] for the search on the line is 9 but it can be reduced to 4.6 by using a randomized strategy. The online solution with a turn cost is given in.<ref>E. Demaine, S. Fekete and S. Gal. Online searching with turn cost. Theoretical Computer Science (2006).</ref>\n\nThese results were rediscovered in the 1990s by computer scientists as the '''cow path problem'''.\n\n==See also==\n*[[Linear search]]\n*[[Search games]]\n\n== References ==\n{{reflist}}\n\n{{DEFAULTSORT:Linear Search Problem}}\n[[Category:Computational problems]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Local optimum",
      "url": "https://en.wikipedia.org/wiki/Local_optimum",
      "text": "{{Unreferenced|date=June 2019|bot=noref (GreenC bot)}}\n[[Image:local_search_attraction_basins.png|thumb|right|220px|Attraction basins around locally optimal points]]\n[[Image:Polynomialdeg4.png|thumb|right|233px|Polynomial of degree 4: the trough on the right is a local minimum and the one on the left is the global minimum. The peak in the center is a local maximum.]]\n\nIn [[applied mathematics]] and [[computer science]], a '''local optimum''' of an [[optimization problem]] is a solution that is optimal (either [[maxima and minima|maximal or minimal]]) within a [[Neighbourhood (mathematics)|neighboring set]] of candidate solutions. This is in contrast to a [[global optimum]], which is the optimal solution among [[solution space|all possible solutions]], not just those in a particular neighborhood of values. \n\n==Continuous domain==\n\nWhen the function to be optimized is [[Continuous function|continuous]], it may be possible to employ [[calculus]] to find local optima. If the [[First derivative test|first derivative]] exists everywhere, it can be equated to zero; if the function has an [[Bounded set|unbounded]] [[Domain (mathematics)|domain]], for a point to be a local optimum it is [[necessary and sufficient conditions|necessary]] that it satisfy this equation. Then the [[second derivative test]] provides a [[necessary and sufficient conditions|sufficient]] condition for the point to be a local maximum or local minimum.\n\n==Search techniques==\n\n[[Local search (optimization)|Local search]] or [[hill climbing]] methods for solving optimization problems start from an initial configuration and repeatedly move to an ''improving neighboring configuration''. A trajectory in search space is generated, which maps an initial point to a local optimum, where local search is stuck (no improving neighbors\nare available). The search space is therefore subdivided into [[basin of attraction|basins of attraction]], each consisting of\nall initial points which have a given local optimum as the final point of the local search trajectory.\nA local optimum can be isolated (surrounded by non-locally-optimal points) or \npart of a [[Plateau (mathematics)|plateau]], a locally optimal region with more than one point of equal value.\n\nIf the problem to be solved has all locally optimal points with the same value of the function to be\noptimized, local search effectively solves the global problem: finding a local optimum delivers\na globally optimal solution.\n\nThe locality of the optimum is dependent on the [[Neighbourhood (mathematics)|neighborhood structure]] as defined by the local search method that is used for optimizing the function.\n\nIn many cases, local optima deliver sub-optimal solutions to the global problem, and\na local search method needs to be modified to continue the search\nbeyond local optimality; see for example [[iterated local search]], [[tabu search]], reactive search optimization, and\n[[simulated annealing]].\n\n==See also==\n{{Commons category|Local optimum}}\n*[[Maxima and minima]]\n\n\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Low-rank approximation",
      "url": "https://en.wikipedia.org/wiki/Low-rank_approximation",
      "text": "In mathematics, '''low-rank approximation''' is a [[mathematical optimization|minimization]] problem, in which the [[Loss function|cost function]] measures the fit between a given matrix (the data) and an approximating matrix (the optimization variable), subject to a constraint that the approximating matrix has reduced [[rank (linear algebra)|rank]]. The problem is used for [[mathematical model]]ing and [[data compression]]. The rank constraint is related to a constraint on the complexity of a model that fits the data. In applications, often there are other constraints on the approximating matrix apart from the rank constraint, e.g., [[nonnegative matrix factorization|non-negativity]] and [[Hankel matrix|Hankel structure]].\n\nLow-rank approximation is closely related to:\n\n* [[principal component analysis]],\n* [[factor analysis]],\n* [[total least squares]],\n* [[latent semantic analysis]], and\n* [[orthogonal regression]].\n\n== Definition ==\n\nGiven\n\n* structure specification <math>\\mathcal{S} : \\mathbb{R}^{n_p} \\to \\mathbb{R}^{m\\times n}</math>,\n* vector of structure parameters <math>p\\in\\mathbb{R}^{n_p}</math>, \n* [[norm (mathematics)|norm]] <math> \\| \\cdot \\| </math>, and\n* desired rank <math>r</math>,\n\n:<math>\n\\text{minimize} \\quad \\text{over } \\widehat p \\quad \\|p - \\widehat p\\| \\quad\\text{subject to}\\quad \\operatorname{rank}\\big(\\mathcal{S}(\\widehat p)\\big) \\leq r.\n</math>\n\n== Applications ==\n\n* Linear [[system identification]], in which case the approximating matrix is [[Hankel matrix|Hankel structured]].<ref name=sysid-aut>\nI. Markovsky, Structured low-rank approximation and its applications, Automatica, Volume 44, Issue 4, April 2008, Pages 891–909. {{DOI|10.1016/j.automatica.2007.09.011}}</ref><ref name=sysid-ac>\nI. Markovsky, J. C. Willems, [[Sabine Van Huffel|S. Van Huffel]], B. De Moor, and R. Pintelon, Application of structured total least squares for system identification and model reduction. IEEE Transactions on Automatic Control, Volume 50, Number 10, 2005, pages 1490–1500.</ref>\n* [[Machine learning]], in which case the approximating matrix is nonlinearly structured.<ref name=book-springer>I. Markovsky, Low-Rank Approximation: Algorithms, Implementation, Applications, Springer, 2012, {{isbn|978-1-4471-2226-5}}</ref>\n* [[Recommender system]]s, in which cases the data matrix has [[missing values]] and the approximation is [[categorical data|categorical]].\n* Distance [[matrix completion]], in which case there is a positive definiteness constraint.\n* [[Natural language processing]], in which case the approximation is [[nonnegative matrix|nonnegative]].\n* [[Computer algebra]], in which case the approximation is [[Sylvester matrix|Sylvester structured]].\n\n== Basic low-rank approximation problem ==\n\nThe unstructured problem with fit measured by the [[Frobenius norm]], i.e., \n:<math>\n\\text{minimize} \\quad \\text{over } \\widehat D \\quad \\|D - \\widehat D\\|_{\\text{F}}\n\\quad\\text{subject to}\\quad \\operatorname{rank}\\big(\\widehat D\\big) \\leq r\n</math>\nhas analytic solution in terms of the [[singular value decomposition]] of the data matrix. The result is referred to as the matrix approximation lemma or Eckart–Young–Mirsky theorem.<ref name=EYM-thm>C. Eckart, G. Young, The approximation of one matrix by another of lower rank. Psychometrika, Volume 1, 1936, Pages 211–8. {{doi|10.1007/BF02288367}}</ref> Let\n:<math>\nD = U\\Sigma V^{\\top} \\in \\mathbb{R}^{m\\times n}, \\quad m \\leq n\n</math>\nbe the singular value decomposition of <math>D</math> and partition <math>U</math>, <math>\\Sigma=:\\operatorname{diag}(\\sigma_1,\\ldots,\\sigma_m)</math>, and <math>V</math> as follows:\n:<math>\nU =: \\begin{bmatrix} U_1 & U_2\\end{bmatrix}, \\quad \n\\Sigma =: \\begin{bmatrix} \\Sigma_1 & 0 \\\\ 0 & \\Sigma_2 \\end{bmatrix}, \\quad\\text{and}\\quad \nV =: \\begin{bmatrix} V_1 & V_2 \\end{bmatrix},\n</math>\nwhere <math>U_1</math> is <math>m\\times r</math>, <math>\\Sigma_1</math> is <math>r\\times r</math>, and <math>V_1</math> is <math>n\\times r</math>. Then the rank-<math>r</math> matrix, obtained from the truncated singular value decomposition\n:<math>\n\\widehat D^* = U_1 \\Sigma_1 V_1^{\\top},\n</math>\nis such that\n:<math>\n\\|D-\\widehat D^*\\|_{\\text{F}} = \\min_{\\operatorname{rank}(\\widehat D) \\leq r} \\|D-\\widehat D\\|_{\\text{F}} = \\sqrt{\\sigma^2_{r+1} + \\cdots + \\sigma^2_m}.\n</math>\nThe minimizer <math>\\widehat D^*</math> is unique if and only if <math>\\sigma_{r+1}\\neq\\sigma_{r}</math>.\n\n== Proof of Eckart–Young–Mirsky theorem (for [[spectral norm]]) ==\nLet <math>A\\in\\mathbb{R}^{m\\times n}</math> be a real (possibly rectangular) matrix with <math>m\\geq n</math>. Suppose that \n:<math>\nA = U\\Sigma V^\\top\n</math>\n\nis the [[singular value decomposition]] of <math>A</math>. Recall that <math> U</math> and <math>V</math> are [[Orthogonal matrix|orthogonal]] matrices, and <math>\\Sigma</math> is an <math>m\\times n</math> [[Diagonal matrix|diagonal]] matrix with entries <math>(\\sigma_{1}, \\sigma_{2}, \\cdots ,\\sigma_{n})</math> such that <math>\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_n\\geq 0</math>.\n\nWe claim that the best rank <math>k</math> approximation to <math>A</math> in the spectral norm, denoted by <math>\\|\\cdot\\|_2</math>, is given by\n\n: <math>\nA_k = \\sum_{i=1}^k \\sigma_i u_i v_i^\\top\n</math>\n\nwhere <math>u_i</math>and <math>v_i</math> denote the <math>i</math>th column of <math>U</math> and <math>V</math>, respectively.\n\nFirst, note that we have\n\n: <math>\n\\|A-A_k\\|_2 = \\left\\|\\sum_{i=k+1}^n \\sigma_i u_i v_i^\\top \\right\\|_2 = \\sigma_{k+1}\n</math>\n\nTherefore, we need to show that if <math>B_k = XY^\\top</math> where <math>X</math> and <math>Y</math> have <math>k</math> columns then <math>\n\\|A-A_k\\|_2=\\sigma_{k+1}\\leq \\|A-B_k\\|_2</math>.\n\nSince <math>Y</math> has <math>k</math> columns, then there must be a linear combination of the first <math>k+1</math> columns of <math>V</math>, i.e.,\n\n: <math>\nw = \\gamma_1v_1+\\cdots+\\gamma_{k+1}v_{k+1},\n</math>\n\nsuch that <math>Y^\\top w = 0</math>. Without loss of generality, we can scale <math>w</math> so that <math>\\|w\\|_2 = 1</math> or (equivalently) <math>\\gamma_1^2+\\cdots +\\gamma_{k+1}^2 = 1</math>. Therefore,\n\n: <math>\n\\|A-B_k\\|_2^2 \\geq \\|(A-B_k)w\\|_2^2 = \\|Aw\\|_2^2 = \\gamma_1^2\\sigma_1^2+\\cdots+\\gamma_{k+1}^2\\sigma_{k+1}^2\\geq \\sigma_{k+1}^2.\n</math>\n\nThe result follows by taking the square root of both sides of the above inequality.\n\n== Proof of Eckart–Young–Mirsky theorem (for [[Frobenius norm]]) ==\n\nLet <math>A\\in\\mathbb{R}^{m\\times n}</math> be a real (possibly rectangular) matrix with <math>m\\geq n</math>. Suppose that\n\n:<math>\nA = U\\Sigma V^\\top\n</math>\n\nis the [[singular value decomposition]] of <math>A</math>.\n\nWe claim that the best rank <math>k</math> approximation to <math>A</math> in the Frobenius norm, denoted by <math>\\|\\cdot\\|_F</math>, is given by\n\n: <math>\nA_k = \\sum_{i=1}^k \\sigma_i u_i v_i^\\top\n</math>\n\nwhere <math>u_i</math> and <math>v_i</math> denote the <math>i</math>th column of <math>U</math> and <math>V</math>, respectively.\n\nFirst, note that we have\n\n: <math>\n\\|A-A_k\\|_F^2 = \\left\\|\\sum_{i=k+1}^n \\sigma_i u_iv_i^\\top \\right\\|_F^2 = \\sum_{i=k+1}^n \\sigma_i^2\n</math>\n\nTherefore, we need to show that if <math>B_k = XY^\\top</math> where <math>X</math> and <math>Y</math> have <math>k</math> columns then\n\n: <math>\\|A-A_k\\|_F^2=\\sum_{i=k+1}^n\\sigma_{i}^2\\leq \\|A-B_k\\|_F^2.</math>\n\nBy the triangle inequality with the spectral norm, if <math>A = A' + A''</math> then <math>\\sigma_1(A)\\leq \\sigma_1(A') + \\sigma_1(A'')</math>. Suppose <math> A'_k</math> and <math>A''_k</math> respectively denote the rank <math>k</math> approximation to <math>A'</math> and <math>A''</math> by SVD method described above. Then, for any <math>i,j\\geq1 </math>\n\n: <math>\n\\begin{align}\n\\sigma_i(A')+\\sigma_j(A'') &= \\sigma_1(A'-A'_{i-1}) + \\sigma_1(A''-A''_{j-1})\\\\\n&\\geq \\sigma_1(A-A'_{i-1}-A''_{j-1})\\\\\n&\\geq \\sigma_1(A-A_{i+j-2})\\ (rank(A'_{i-1}+A''_{j-1})\\leq rank(A_{i+j-2}))\\\\\n&\\geq \\sigma_{i+j-1}(A).\n\\end{align}\n</math>\n\nSince <math>\\sigma_{k+1}(B_k) = 0 </math>, when <math>A' = A-B_k</math> and <math>A'' = B_k</math> we conclude that for <math>i\\geq 1,j=k+1</math>\n\n: <math>\n\\sigma_i(A-B_k) \\geq \\sigma_{k+i}(A).\n</math>\n\nTherefore,\n\n: <math>\n\\|A-B_k\\|_F^2 = \\sum_{i=1}^n \\sigma_i(A-B_k)^2 \\geq \\sum_{i=k+1}^n\\sigma_i(A)^2 = \\|A-A_k\\|_F^2,\n</math>\n\nas required.\n\n== Weighted low-rank approximation problems ==\n\nThe Frobenius norm weights uniformly all elements of the approximation error  <math>D - \\widehat D</math>. Prior knowledge about distribution of the errors can be taken into account by considering the weighted low-rank approximation problem\n:<math>\n\\text{minimize} \\quad \\text{over } \\widehat D \\quad \n\\operatorname{vec}^{\\top}(D - \\widehat D) W \\operatorname{vec}(D - \\widehat D)\n\\quad\\text{subject to}\\quad \\operatorname{rank}(\\widehat D) \\leq r,\n</math>\nwhere <math>vec(A)</math> [[vectorization (mathematics)|vectorizes]] the matrix  <math>A</math> column wise and <math>W</math> is a given positive (semi)definite weight matrix.\n\nThe general weighted low-rank approximation problem does not admit an analytic solution in terms of the singular value decomposition and is solved by local optimization methods, which provide no guarantee that a globally optimal solution is found.\n\nInspired by Netflix prize application, weighted low-rank approximation problem also can be formulated in this way <ref>{{cite conference|title=Weighted Low-Rank Approximations| conference = ICML'03 |url=https://www.aaai.org/Papers/ICML/2003/ICML03-094.pdf|last1=Srebro|first1=Nathan|last2=Jaakkola|first2=Tommi|year=2003}}</ref> <ref>{{cite conference|title=Weighted Low Rank Approximations with Provable Guarantees| conference = STOC '16 Proceedings of the forty-eighth annual ACM symposium on Theory of Computing|url=https://dl.acm.org/citation.cfm?id=2897639|last1=Razenshteyn|first1=Ilya|last2=Song|first2=Zhao|last3=Woodruff|first3=David P.|year=2016}}</ref>  : for a non-negative matrix <math>W</math> and a matrix <math>A</math> we want to minimize <math>\\sum_{i,j} ( W_{i,j}( A_{i,j} - B_{i,j} ))^2</math>.\n\n== Entry-wise <math>L_p</math> low-rank approximation problems == \nLet <math>\\|A\\|_p = (\\sum_{i,j}|A_{i,j}^p|)^{1/p} </math>. For <math> p = 2 </math>, the fastest algorithm runs in <math> nnz(A) + n \\cdot poly(k/\\epsilon) </math> time <ref>{{cite conference|title=Low Rank Approximation and Regression in Input Sparsity Time | conference = STOC '13 Proceedings of the forty-fifth annual ACM symposium on Theory of Computing|last1=Clarkson|first1=Kenneth L.|last2=Woodruff|first2=David P.|year=2013| arxiv = 1207.6365}}</ref>, <ref>{{cite conference|title= OSNAP: Faster numerical linear algebra algorithms via sparser subspace embeddings | conference = FOCS '13 |last1=Nelson |first1=Jelani |last2=Nguyen|first2= Huy L. |year=2013| arxiv = 1211.1002}}</ref>. One of the important ideas been used is called Oblivious Subspace Embedding (OSE), it is first proposed by Sarlos <ref>{{cite conference|title=Improved approximation algorithms for large matrices via random projections | conference = FOCS'06 |last1 = Sarlos | first1 = Tamas |year=2006| }}</ref>.\n\nFor <math> p = 1 </math>, it is known that this entry-wise L1 norm is more robust than the Frobenius norm in the presence of outliers and is indicated in models where Gaussian assumptions on the noise may not apply. It is natural to seek to minimize <math>\\|B - A\\|_1</math> <ref>{{cite conference|title=Low Rank Approximation with Entrywise L1-Norm Error| conference = STOC '17 Proceedings of the forty-ninth annual ACM symposium on Theory of Computing|last1=Song|first1=Zhao|last2=Woodruff|first2=David P.|last3=Zhong|first3=Peilin|year=2017| arxiv = 1611.00898}}</ref>. For <math>p=0</math> and <math>p \\geq 1</math>, there are some algorithms with provable guarantees <ref>{{cite conference|title=Approximation Algorithms for L0-Low Rank Approximation | conference = NIPS'17 |last1=Bringmann|first1= Karl |last2= Kolev |first2= Pavel |last3=Woodruff|first3=David P.|year=2017| arxiv = 1710.11253 }}</ref>, <ref>{{cite conference|title=Algorithms for Lp Low-Rank Approximation | conference = ICML'17 | last1 = Chierichetti |first1= Flavio |last2= Gollapudi |first2= Sreenivas | last3 = Kumar | first3 = Ravi | last4 = Lattanzi | first4 = Silvio | last5 = Panigrahy | first5 = Rina |last6=Woodruff|first6=David P.|year=2017| arxiv = 1705.06730 }}</ref>.\n\n== Distance low-rank approximation problem ==\nLet <math>P = \\{ p_1 , \\ldots, p_m \\} </math> and <math> Q = \\{ q_1, \\ldots, q_n \\} </math> be two point sets in an arbitrary metric space. Let <math> A </math> represent the <math> m \\times n </math> matrix where <math>A_{i,j} = dist(p_i,q_i) </math>. Such distances matrices are commonly computed in software packages and have applications to learning image manifolds, handwriting recognition, and multi-dimensional unfolding. In an attempt to reduce their description size,  <ref>{{cite conference|title= Sublinear Time Low-Rank Approximation of Distance Matrices | conference = NeurIPS |last1= Bakshi |first1= Ainesh L.|last2=Woodruff|first2=David P.|year=2018| arxiv = 1809.06986}}</ref> <ref>{{cite conference|title= Sample-Optimal Low-Rank Approximation of Distance Matrices | conference = COLT |last1= Indyk |first1= Piotr |last2=Vakilian|first2=Ali|last3=Wagner|first3=Tal|last4=Woodruff|first4=David P.|year=2019|}}</ref> one can study low rank approximation of such matrices.\n\n== Distributed/Streaming low-rank approximation problem ==\n\nThe low-rank approximation problems in the distributed and streaming setting has been consider in <ref>{{cite conference|title= Optimal Principal Component Analysis in Distributed and Streaming Models | conference = STOC |last1 = Boutsidis |first1 = Christos |last2 = Woodruff | first2 = David P. | last3 = Zhong | first3 = Peilin |year=2016| arxiv = 1504.06729}}</ref>.\n\n== Image and kernel representations of the rank constraints ==\n\nUsing the equivalences\n:<math>\n\\operatorname{rank}(\\widehat D) \\leq r \n\\quad\\iff\\quad\n\\text{there are } P\\in\\R^{m\\times r} \\text{ and } L\\in\\R^{r\\times n}\n\\text{ such that } \\widehat D  = PL\n</math>\nand\n:<math>\n\\operatorname{rank}(\\widehat D) \\leq r \n\\quad\\iff\\quad\n\\text{there is full row rank } R\\in\\R^{m - r\\times m} \\text{ such that } R \\widehat D  = 0\n</math>\nthe weighted low-rank approximation problem becomes equivalent to the parameter optimization problems\n:<math>\n\\text{minimize} \\quad \\text{over } \\widehat D, P \\text{ and } L \\quad \n\\operatorname{vec}^{\\top}(D - \\widehat D) W \\operatorname{vec}(D - \\widehat D)\n\\quad\\text{subject to}\\quad \\widehat D = PL\n</math>\nand\n:<math>\n\\text{minimize} \\quad \\text{over } \\widehat D \\text{ and } R \\quad \n\\operatorname{vec}^{\\top}(D - \\widehat D) W \\operatorname{vec}(D - \\widehat D)\n\\quad\\text{subject to}\\quad R \\widehat D = 0 \\quad\\text{and}\\quad RR^{\\top} = I_r,\n</math>\nwhere <math>I_r</math> is the [[identity matrix]] of size <math>r</math>.\n\n== Alternating projections algorithm ==\n\nThe image representation of the rank constraint suggests a parameter optimization method in which the cost function is minimized alternatively over one of the variables (<math>P</math> or <math>L</math>) with the other one fixed. Although simultaneous minimization over both <math>P</math> and <math>L</math> is a difficult [[biconvex optimization]] problem, minimization over one of the variables alone is a [[linear least squares (mathematics)|linear least squares]] problem and can be solved globally and efficiently.\n\nThe resulting optimization algorithm (called alternating projections) is globally convergent with a linear convergence rate to a locally optimal solution of the weighted low-rank approximation problem. Starting value for the <math>P</math> (or <math>L</math>) parameter should be given. The iteration is stopped when a user defined convergence condition is satisfied.\n\n[[Matlab]] implementation of the alternating projections algorithm for weighted low-rank approximation:\n\n<source lang=\"matlab\">\nfunction [dh, f] = wlra_ap(d, w, p, tol, maxiter)\n[m, n] = size(d); r = size(p, 2); f = inf;\nfor i = 2:maxiter\n    % minimization over L\n    bp = kron(eye(n), p);\n    vl = (bp' * w * bp) \\ bp' * w * d(:);\n    l  = reshape(vl, r, n);\n    % minimization over P\n    bl = kron(l', eye(m));\n    vp = (bl' * w * bl) \\ bl' * w * d(:);\n    p  = reshape(vp, m, r);\n    % check exit condition\n    dh = p * l; dd = d - dh;\n    f(i) = dd(:)' * w * dd(:);\n    if abs(f(i - 1) - f(i)) < tol, break, end\nend \n</source>\n\n== Variable projections algorithm ==\n\nThe alternating projections algorithm exploits the fact that the low rank approximation problem, parameterized in the image form, is bilinear in the variables <math>P</math> or <math>L</math>. The bilinear nature of the problem is effectively used in an alternative approach, called variable projections.<ref>G. Golub and V. Pereyra, Separable nonlinear least squares: the variable projection method and its applications, Institute of Physics, Inverse Problems, Volume 19, 2003, Pages 1-26.</ref>\n\nConsider again the weighted low rank approximation problem, parameterized in the image form. Minimization with respect to the <math>L</math> variable (a linear least squares problem) leads to the closed form expression of the approximation error as a function of <math>P</math>\n:<math>\nf(P) = \\sqrt{\\operatorname{vec}^{\\top}(D)\\Big( \nW - W (I_n \\otimes P) \\big( (I_n \\otimes P)^{\\top} W (I_n \\otimes P) \\big)^{-1} (I_n \\otimes P)^{\\top} W\n\\Big) \\operatorname{vec}(D)}.\n</math> \nThe original problem is therefore equivalent to the [[Least squares#Non-linear least squares|nonlinear least squares problem]] of minimizing <math>f(P)</math> with respect to <math>P</math>. For this purpose standard optimization methods, e.g. the [[Levenberg-Marquardt algorithm]] can be used.\n\n[[Matlab]] implementation of the variable projections algorithm for weighted low-rank approximation:\n\n<source lang=\"matlab\">\nfunction [dh, f] = wlra_varpro(d, w, p, tol, maxiter)\nprob = optimset(); prob.solver = 'lsqnonlin';\nprob.options = optimset('MaxIter', maxiter, 'TolFun', tol); \nprob.x0 = p; prob.objective = @(p) cost_fun(p, d, w);\n[p, f ] = lsqnonlin(prob); \n[f, vl] = cost_fun(p, d, w); \ndh = p * reshape(vl, size(p, 2), size(d, 2));\n\nfunction [f, vl] = cost_fun(p, d, w)\nbp = kron(eye(size(d, 2)), p);\nvl = (bp' * w * bp) \\ bp' * w * d(:);\nf = d(:)' * w * (d(:) - bp * vl);\n</source>\n \nThe variable projections approach can be applied also to low rank approximation problems parameterized in the kernel form. The method is effective when the number of eliminated variables is much larger than the number of optimization variables left at the stage of the nonlinear least squares minimization. Such problems occur in system identification, parameterized in the kernel form, where the eliminated variables are the approximating trajectory and the remaining variables are the model parameters. In the context of [[LTI system theory|linear time-invariant systems]], the elimination step is equivalent to [[Kalman filter|Kalman smoothing]].\n\n==A Variant: convex-restricted low rank approximation==\nUsually, we want our new solution not only to be of low rank, but also satisfy other convex constraints due to application requirements. Our interested problem would be as follows,\n\n: <math>\n\\text{minimize} \\quad \\text{over } \\widehat p \\quad \\|p - \\widehat p\\| \\quad\\text{subject to}\\quad \\operatorname{rank}\\big(\\mathcal{S}(\\widehat p)\\big) \\leq r \\text{ and }\ng(\\widehat p) \\leq 0\n</math>\n\nThis problem can find tons of real applications, including to recover a good solution from an inexact (semidefinite programming) relaxation. If additional constraint <math>g(\\widehat p) \\leq 0</math> is linear, like we require all elements to be nonnegative, the problem is called structured low rank approximation.<ref>{{cite journal|title=structured low-rank approximation| doi=10.1016/S0024-3795(02)00505-0 | volume=366|journal=Linear Algebra and its Applications|pages=157–172|year=2003 |last1=Chu |first1=Moody T. |last2=Funderlic |first2=Robert E. |last3=Plemmons |first3=Robert J. }}</ref> And the more general form is named as convex-restricted low rank approximation.\n\nThis problem is helpful in solving many problems. However, it is challenging due to the combination of the convex and nonconvex (low-rank) constraints. Different techniques were developed based on different realizations of <math>g(\\widehat p) \\leq 0</math>. However, the Alternating Direction Method of Multipliers (ADMM) can be applied to solve the nonconvex problem with convex objective function, rank constraints and other convex constraints,<ref>{{cite web|title=A General System for Heuristic Solution of Convex Problems over Nonconvex Sets|url=http://stanford.edu/~boyd/papers/pdf/ncvx.pdf}}</ref> and is thus suitable to solve our above problem. Moreover, unlike the general nonconvex problems, ADMM will guarantee to converge a feasible solution as long as its dual variable converges in the iterations\n\n== See also==\n* [[CUR matrix approximation]] is made from the rows and columns of the original matrix\n\n==References==\n{{reflist}}\n* M. T. Chu, R. E. Funderlic, R. J. Plemmons, Structured low-rank approximation, Linear Algebra and its Applications, Volume 366, 1 June 2003, Pages 157–172 {{doi|10.1016/S0024-3795(02)00505-0}}\n\n==External links==\n*[https://github.com/slra/slra C++ package for structured-low rank approximation]\n\n[[Category:Numerical linear algebra]]\n[[Category:Dimension reduction]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Map segmentation",
      "url": "https://en.wikipedia.org/wiki/Map_segmentation",
      "text": "In [[mathematics]], the '''map segmentation''' problem is a kind of [[optimization problem]]. It involves a certain geographic region that has to be partitioned into smaller sub-regions in order to achieve a certain goal. Typical optimization objectives include:<ref name=rag14>{{cite book | url=http://search.proquest.com/docview/1614472017 | title=Geometric Partitioning Algorithms for Fair Division of Geographic Resources | publisher=A Ph.D. thesis submitted to the faculty of university of Minnesota | author=Raghuveer Devulapalli (Advisor: John Gunnar Carlsson) | year=2014}}</ref>\n* Minimizing the workload of a fleet of vehicles assigned to the sub-regions;\n* Balancing the consumption of a resource, as in [[fair cake-cutting]].\n* Determining the optimal locations of supply depots;\n* Maximizing the surveillance coverage.\n\nFair division of land has been an important issue since ancient times, e.g. in [[ancient Greece]].<ref>{{Cite journal|doi=10.2307/147876|jstor=147876|title=Urban and Rural Land Division in Ancient Greece|journal=Hesperia|volume=50|issue=4|pages=327|year=1981|last1=Boyd|first1=Thomas D.|last2=Jameson|first2=Michael H.}}</ref>\n\n== Notation ==\nThere is a geographic region denoted by C (\"cake\").\n\nA partition of C, denoted by X, is a list of disjoint subregions whose union is C:\n:<math>C = X_1\\sqcup\\cdots\\sqcup X_n</math>\n\nThere is a certain set of additional parameters (such as: obstacles, fixed points or probability density functions), denoted by P.\n\nThere is a real-valued function denoted by G (\"goal\") on the set of all partitions.\n\nThe map segmentation problem is to find:\n:<math>\\arg\\min_X G(X_1,\\dots,X_n \\mid P)</math>\nwhere the minimization is on the set of all partitions of C.\n\nOften, there are geometric shape constraints on the partitions, e.g., it may be required that each part be a [[convex set]] or a [[connected set]] or at least a [[measurable set]].\n\n== Examples ==\n1. '''Red-blue partitioning''': there is a set <math>P_b</math> of blue points and a set <math>P_r</math> of red points. Divide the plane into <math>n</math> regions such that each region contains approximately a fraction <math>1/n</math> of the blue points and <math>1/n</math> of the red points. Here:\n* The cake ''C'' is the entire plane <math>\\mathbb{R}^2</math>;\n* The parameters ''P'' are the two sets of points;\n* The goal function ''G'' is\n:: <math>G(X_1,\\dots,X_n) := \\max_{i\\in \\{1,\\dots, n\\}} \\left( \\left |\\frac{|P_b\\cap X_i| - |P_b|} n \\right| + \\left| \\frac{|P_r\\cap X_i| - |P_r|} n\\right| \\right).</math>\n: It equals 0 if each region has exactly a fraction <math>1/n</math> of the points of each color.\n\n== Related problems ==\n* A [[Voronoi diagram]] is a specific type of map-segmentation problem.\n* [[Fair cake-cutting]], when the cake is two-dimensional, is another specific map-segmentation problem when the cake is two-dimensional, like in the [[Hill–Beck land division problem]].\n* The [[Stone–Tukey theorem]] is related to a specific map-segmentation problem.\n\n== References ==\n{{reflist}}\n\n[[Category:Fair division]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Mathematical programming with equilibrium constraints",
      "url": "https://en.wikipedia.org/wiki/Mathematical_programming_with_equilibrium_constraints",
      "text": "'''Mathematical programming with equilibrium constraints (MPEC)''' is the study of \n[[constrained optimization]] problems  where the constraints include [[variational inequalities]] or  [[complementarity theory|complementarities]]. MPEC is related to the [[Stackelberg game]]. \n\nMPEC is used in the study of [[engineering design]], [[economic equilibrium]], and [[multilevel games]].\n\nMPEC is difficult to deal with because its [[feasible region]] is not necessarily [[Convex set|convex]] or even [[Connected space|connected]].\n\n==References==\n<references/>\n* Z.-Q. Luo, J.-S. Pang and D. Ralph: ''Mathematical Programs with Equilibrium Constraints''. Cambridge University Press, 1996, {{isbn|0-521-57290-8}}.\n* B. Baumrucker, J. Renfro, L. T. Biegler, MPEC problem formulations and solution strategies with chemical engineering applications, Computers & Chemical Engineering, 32 (12) (2008) 2903-2913.\n* A. U. Raghunathan, M. S. Diaz, L. T. Biegler, An MPEC formulation for dynamic optimization of distillation operations, Computers & Chemical Engineering, 28 (10) (2004) 2037-2052.\n\n==External links==\n* [http://apmonitor.com/wiki/index.php/Apps/MpecExamples MPEC examples] such as SIGN, ABS, MIN, and MAX\n* [http://apmonitor.com/me575/index.php/Main/LogicalConditions Formulating logical statements] as continuously differentiable nonlinear programming problems\n\n[[Category:Mathematical optimization]]\n\n{{mathapplied-stub}}"
    },
    {
      "title": "Maxima and minima",
      "url": "https://en.wikipedia.org/wiki/Maxima_and_minima",
      "text": "{{For|use in statistics|Sample maximum and minimum}}\n{{redirect|Extreme value|the concept in statistics|Extreme value theory|the concept in calculus|Extreme value theorem}}\n{{redirect-multi|2|Maximum|Minimum}}\n[[File:Extrema example original.svg|thumb|Local and global maxima and minima for cos(3&pi;''x'')/''x'', 0.1&le;'' x ''&le;1.1]]\nIn [[mathematical analysis]], the '''maxima and minima''' (the respective plurals of '''maximum''' and '''minimum''') of a [[function (mathematics)|function]], known collectively as '''extrema''' (the plural of '''extremum'''), are the largest and smallest value of the function, either within a given range (the '''local''' or '''relative''' extrema) or on the entire [[domain of a function]] (the '''global''' or '''absolute''' extrema).<ref>{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}</ref><ref>{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}</ref><ref>{{cite book | last1 = Thomas | first1 = George B. | last2=Weir | first2= Maurice D. | last3=Hass | first3=Joel |author3-link = Joel Hass| authorlink=George B. Thomas | title=Thomas' Calculus: Early Transcendentals | publisher=[[Addison-Wesley]] | year=2010 | edition=12th | isbn=0-321-58876-2}}</ref> [[Pierre de Fermat]] was one of the first mathematicians to propose a general technique, [[adequality]], for finding the maxima and minima of functions.\n\nAs defined in [[set theory]], the maximum and minimum of a [[set (mathematics)|set]] are the [[greatest and least elements]] in the set, respectively. Unbounded infinite sets, such as the set of [[real number]]s, have no minimum or maximum.\n\n==Definition==\nA real-valued [[function (mathematics)|function]] ''f'' defined on a [[Domain of a function|domain]] ''X'' has a '''global''' (or '''absolute''') '''maximum point''' at ''x''<sup>&lowast;</sup> if ''f''(''x''<sup>&lowast;</sup>) &ge; ''f''(''x'') for all ''x'' in ''X''. Similarly, the function has a '''global''' (or '''absolute''') '''minimum point''' at ''x''<sup>&lowast;</sup> if ''f''(''x''<sup>&lowast;</sup>) &le; ''f''(''x'') for all ''x'' in ''X''. The value of the function at a maximum point is called the '''maximum value''' of the function and the value of the function at a minimum point is called the '''minimum value''' of the function. Symbolically, this can be written as follows:\n:<math>x_0 \\in \\mathrm{X}</math> is a global maximum point of function <math>f:\\mathrm{X} \\to \\mathbb{R}</math> if  <math>(\\forall x \\in \\mathrm{X})\\, f(x_0) \\geq f(x).</math>\nSimilarly for global minimum point.\n\nIf the domain ''X'' is a [[metric space]] then ''f'' is said to have a '''local''' (or '''relative''') '''maximum point''' at the point ''x''<sup>&lowast;</sup> if there exists some ''&epsilon;'' > 0 such that ''f''(''x''<sup>&lowast;</sup>) &ge; ''f''(''x'') for all ''x'' in ''X'' within distance ''&epsilon;'' of ''x''<sup>&lowast;</sup>. Similarly, the function has a '''local minimum point''' at ''x''<sup>&lowast;</sup> if ''f''(''x''<sup>&lowast;</sup>) &le; ''f''(''x'') for all ''x'' in ''X'' within distance ''&epsilon;'' of ''x''<sup>&lowast;</sup>. A similar definition can be used when ''X'' is a [[topological space]], since the definition just given can be rephrased in terms of neighbourhoods. Mathematically, the given definition is written as follows:\n:Let <math>(\\mathrm{X}, d_\\mathrm{X})</math> be a metric space and function <math> f:\\mathrm{X} \\to \\mathbb{R}</math>. Then <math>x_0 \\in \\mathrm{X}</math> is a local maximum point of function <math>f</math>  if <math> (\\exists \\varepsilon > 0)</math> such that <math>(\\forall x \\in \\mathrm{X})\\, d_\\mathrm{X}(x, x_0)<\\varepsilon \\implies f(x_0)\\geq f(x).</math>\n\nSimilarly for a local minimum point.\n\nIn both the global and local cases, the concept of a '''strict''' extremum can be defined. For example, ''x''<sup>&lowast;</sup> is a '''strict global maximum point''' if, for all ''x'' in ''X'' with ''x'' ≠ ''x''<sup>&lowast;</sup>, we have ''f''(''x''<sup>&lowast;</sup>) > ''f''(''x''), and ''x''<sup>&lowast;</sup> is a '''strict local maximum point''' if there exists some ''&epsilon;'' > 0 such that, for all ''x'' in ''X'' within distance ''&epsilon;'' of ''x''<sup>&lowast;</sup> with ''x'' ≠ ''x''<sup>&lowast;</sup>, we have ''f''(''x''<sup>&lowast;</sup>) > ''f''(''x''). Note that a point is a strict global maximum point if and only if it is the unique global maximum point, and similarly for minimum points.\n\nA [[Continuous function|continuous]] real-valued function with a [[Compact space|compact]] domain always has a maximum point and a minimum point. An important example is a function whose domain is a closed (and bounded) [[Interval (mathematics)|interval]] of [[real number]]s (see the graph above).\n\n==Search==\nFinding global maxima and minima is the goal of [[mathematical optimization]]. If a function is continuous on a closed interval, then by the [[extreme value theorem]] global maxima and minima exist. Furthermore, a global maximum (or minimum) either must be a local maximum (or minimum) in the interior of the domain, or must lie on the boundary of the domain. So a method of finding a global maximum (or minimum) is to look at all the local maxima (or minima) in the interior, and also look at the maxima (or minima) of the points on the boundary, and take the largest (or smallest) one.\n\nLikely the most important, yet quite obvious, feature of [[Continuous function|continuous]] [[Real-valued function|real-valued]] functions of [[Function of a real variable|a real variable]] is that they [[Decreasing function|decrease]] before local minima and [[Increasing function|increase]] afterwards, likewise for maxima. (Formally, if ''f'' is continuous real-valued function of a real variable ''x'' then ''x<sub>0</sub>'' is a local minimum [[If and only if|iff]] there exist ''a<x<sub>0</sub><b'' such that ''f'' decreases on ''(a,x<sub>0</sub>)'' and increases on ''(x<sub>0</sub>,b)'')<ref>{{Cite book|url=https://www.worldcat.org/oclc/799468131|title=Problems in mathematical analysis|date=1964|publisher=Moskva|others=Demidovǐc, Boris P., Baranenkov, G.|isbn=0846407612|location=Moscow(IS)|oclc=799468131}}</ref> A direct consequence of this is the [[Fermat's theorem (stationary points)|Fermat's theorem]], which states that local extrema must occur at [[critical point (mathematics)|critical point]]s. One can distinguish whether a critical point is a local maximum or local minimum by using the [[first derivative test]], [[derivative test#Second derivative test (single variable)|second derivative test]], or [[higher-order derivative test]], given sufficient differentiability.\n\nFor any function that is defined [[piecewise]], one finds a maximum (or minimum) by finding the maximum (or minimum) of each piece separately, and then seeing which one is largest (or smallest).\n\n==Examples==\n[[Image:xth root of x.svg|thumb|right|The global maximum of <math>\\sqrt[x]{x}</math> occurs at ''x'' = ''[[e (mathematical constant)|e]]''.]]\n* The function ''x''<sup>2</sup> has a unique global minimum at ''x'' = 0.\n* The function ''x''<sup>3</sup> has no global minima or maxima.  Although the first derivative (3''x''<sup>2</sup>) is 0 at ''x'' = 0, this is an [[inflection point]].\n* The function <math>\\sqrt[x]{x}</math> has a unique global maximum at ''x'' = ''[[e (mathematical constant)|e]]''. (See figure at right)\n* The function x<sup>−x</sup> has a unique global maximum over the positive real numbers at ''x'' = 1/''e''.\n* The function ''x''<sup>3</sup>/3 − ''x'' has first derivative ''x''<sup>2</sup> − 1 and [[second derivative]] 2''x''.  Setting the first derivative to 0 and solving for ''x'' gives stationary points at −1 and +1.  From the sign of the second derivative we can see that −1 is a local maximum and +1 is a local minimum.  Note that this function has no global maximum or minimum.\n* The function |''x''| has a global minimum at ''x'' = 0 that cannot be found by taking derivatives, because the derivative does not exist at ''x'' = 0.\n* The function cos(''x'') has infinitely many global maxima at 0, ±2{{pi}}, ±4{{pi}}, ..., and infinitely many global minima at ±&pi;, ±3&pi;, ....\n* The function 2 cos(''x'') − ''x'' has infinitely many local maxima and minima, but no global maximum or minimum.\n* The function cos(3{{pi}}''x'')/''x'' with 0.1&nbsp;&le;&nbsp;''x''&nbsp;&le;&nbsp;1.1 has a global maximum at ''x''&nbsp;= 0.1 (a boundary), a global minimum near ''x''&nbsp;= 0.3, a local maximum near ''x''&nbsp;= 0.6, and a local minimum near ''x''&nbsp;= 1.0. (See figure at top of page.)\n* The function ''x''<sup>3</sup> + 3''x''<sup>2</sup> − 2''x'' + 1 defined over the closed interval (segment) [−4,2] has a local and maximum at ''x'' = −1−{{radic|15}}/3, a local minimum at ''x'' = −1+{{radic|15}}/3, a global maximum at ''x'' = 2 and a global minimum at ''x'' = −4.\n\n==Functions of more than one variable==<!-- This section is linked from [[Indifference curve]] -->\n{{main|Second partial derivative test}}\n[[File:Modell einer Peanoschen Fläche -Schilling XLIX, 1-.jpg|thumb|[[Peano surface]], a counterexample to some criteria of local maxima of the 19th century]]\nFor functions of more than one variable, similar conditions apply. For example, in the (enlargeable) figure at the right, the necessary conditions for a ''local'' maximum are similar to those of a function with only one variable. The first [[partial derivatives]] as to  ''z'' (the variable to be maximized) are zero at the maximum (the glowing dot on top in the figure).  The second partial derivatives are negative.  These are only necessary, not sufficient, conditions for a local maximum because of the possibility of a [[saddle point]]. For use of these conditions to solve for a maximum, the function ''z'' must also be [[Differentiable function|differentiable]] throughout. The [[second partial derivative test]] can help classify the point as a relative maximum or relative minimum.\nIn contrast, there are substantial differences between functions of one variable and functions of more than one variable in the identification of global extrema. For example, if a bounded differentiable function ''f'' defined on a closed interval in the real line has a single critical point, which is a local minimum, then it is also a global minimum (use the [[intermediate value theorem]] and [[Rolle's theorem]] to prove this by [[reductio ad absurdum]]). In two and more dimensions, this argument fails, as the function\n:<math>f(x,y)= x^2+y^2(1-x)^3,\\qquad x,y\\in\\mathbb{R},</math>\nshows. Its only critical point is at (0,0), which is a local minimum with ƒ(0,0)&nbsp;=&nbsp;0. However, it cannot be a global one, because ƒ(2,3)&nbsp;=&nbsp;−5.\n{{Gallery\n|title=Multivariate functions\n|File:MaximumParaboloid.png\n |The global maximum is the point at the top\n|File:MaximumCounterexample.png\n |Counterexample: The red dot shows a local minimum that is not a global minimum\n}}\n\n==Maxima or minima of a functional==\nIf the domain of a function for which an extremum is to be found consists itself of functions, i.e. if an extremum is to be found of a [[Functional (mathematics)|functional]], the extremum is found using the [[calculus of variations]].\n\n==In relation to sets==\nMaxima and minima can also be defined for sets. In general, if an [[ordered set]] ''S'' has a [[greatest element]] ''m'', ''m'' is a [[maximal element]]. Furthermore, if ''S'' is a subset of an ordered set ''T'' and ''m'' is the greatest element of ''S'' with respect to order induced by ''T'', ''m'' is a [[supremum|least upper bound]] of ''S'' in ''T''. The similar result holds for [[least element]], [[minimal element]] and [[infimum|greatest lower bound]]. The maximum and minimum function for sets are used in [[database]]s, and can be computed rapidly, since the maximum (or minimum) of a set can be computed from the maxima of a partition; formally, they are self-[[decomposable aggregation function]]s.\n\nIn the case of a general [[partial order]], the '''least element''' (smaller than all other) should not be confused with a '''minimal element''' (nothing is smaller).  Likewise, a '''[[greatest element]]''' of a [[partially ordered set]] (poset) is an [[upper bound]] of the set which is contained within the set, whereas a '''maximal element''' ''m'' of a poset ''A'' is an element of ''A'' such that if ''m'' ≤ ''b'' (for any ''b'' in ''A'') then ''m'' = ''b''. Any least element or greatest element of a poset is unique, but a poset can have several minimal or maximal elements.  If a poset has more than one maximal element, then these elements will not be mutually comparable.\n\nIn a [[total order|totally ordered]] set, or ''chain'', all elements are mutually comparable, so such a set can have at most one minimal element and at most one maximal element.  Then, due to mutual comparability, the minimal element will also be the least element and the maximal element will also be the greatest element. Thus in a totally ordered set we can simply use the terms '''''minimum''''' and '''''maximum'''''. If a chain is finite then it will always have a maximum and a minimum.  If a chain is infinite then it need not have a maximum or a minimum.  For example, the set of [[natural number]]s has no maximum, though it has a minimum. If an infinite chain ''S'' is bounded, then the [[topological closure|closure]] ''Cl(S)'' of the set occasionally has a minimum and a maximum, in such case they are called the '''greatest lower bound''' and the '''least upper bound''' of the set ''S'', respectively.\n\n==See also==\n*[[Derivative test]]\n*[[Infimum and supremum]]\n*[[Limit superior and limit inferior]]\n*[[Mechanical equilibrium]]\n*[[Sample maximum and minimum]]\n*[[Saddle point]]\n\n==References==\n{{reflist}}\n\n==External links==\n{{Commons category|Extrema (calculus)}}\n{{Wiktionary|maxima|minima|extremum}}\n*[http://mathworld.wolfram.com/topics/MaximaandMinima.html Maxima and Minima] From MathWorld—A Wolfram Web Resource.\n*[http://www.maa.org/publications/periodicals/convergence/thomas-simpson-and-maxima-and-minima Thomas Simpson's work on Maxima and Minima] at [https://web.archive.org/web/20070713083148/http://mathdl.maa.org/convergence/1/ Convergence]\n*[http://www.mathalino.com/reviewer/differential-calculus/application-of-maxima-and-minima Application of Maxima and Minima with sub pages of solved problems]\n\n[[Category:Calculus]]\n[[Category:Mathematical analysis]]\n[[Category:Mathematical optimization]]\n[[Category:Superlatives]]"
    },
    {
      "title": "Maximum theorem",
      "url": "https://en.wikipedia.org/wiki/Maximum_theorem",
      "text": "The '''maximum theorem''' provides conditions for the [[continuous function|continuity]] of an [[Optimization (mathematics)|optimized]] function and the set of its maximizers with respect to its parameters. The statement was first proven by [[Claude Berge]] in 1959.<ref>{{cite book\n  | first = Efe |last=Ok\n  | title = Real Analysis with Economics Applications\n  | year = 2007\n  | publisher = Princeton University Press\n  | isbn = 0-691-11768-3\n  | page = 306\n  }}</ref> The theorem is primarily used in [[mathematical economics]] and [[optimal control]].\n\n==Statement of theorem==\n'''Maximum Theorem'''.<ref> The original reference is the Maximum Theorem in Chapter 6, Section 3 {{cite book  |author = Claude Berge  |title = Topological Spaces  |year = 1963  |publisher = Oliver and Boyd  |pages = 116}} Famously, or perhaps infamously, Berge only considers Hausdorff topological spaces and only allows those compact sets which are themselves Hausdorff spaces. He also requires that upper hemicontinuous correspondences be compact-valued. These properties have been clarified and disaggregated in later literature.</ref><ref>Compare with Theorem 17.31 in {{cite book  |author1 = Charalambos D. Aliprantis |author2 = Kim C. Border |title=Infinite Dimensional Analysis: A Hitchhiker's Guide |publisher=Springer |year=2006 |pages=570}} This is given for arbitrary topological spaces. They also consider the possibility that <math>f</math> may only be defined on the graph of <math>C</math>.</ref><ref>Compare with Theorem 3.5 in {{cite book| author1 = Shouchuan Hu| author2 = Nikolas S. Papageorgiou| title = Handbook of Multivalued Analysis| volume = 1: Theory| year = 1997| publisher = Springer-Science + Business Media, B. V| pages = 84}} They consider the case that <math>\\Theta</math> and <math>X</math> are Hausdorff spaces.</ref><ref>Theorem 3.6 in {{cite book |first=Brian |last=Beavis |first2=Ian |last2=Dobbs |title=Optimization and Stability Theory for Economic Analysis |location=New York |publisher=Cambridge University Press |year=1990 |isbn=0-521-33605-8 |pages=83–84 }}</ref> \nLet <math>X</math> and <math>\\Theta</math> be topological spaces, <math>f:X\\times\\Theta\\to\\mathbb{R}</math> be a continuous function on the [[Product topology|product]] <math>X \\times \\Theta</math>, and <math>C:\\Theta\\rightrightarrows X</math> be a compact-valued [[Multivalued function|correspondence]] such that <math>C(\\theta) \\ne \\emptyset</math> for all <math>\\theta \\in \\Theta</math>. Define the ''marginal function'' (or ''value function'') <math>f^* : \\Theta \\to \\mathbb{R}</math> by\n\n:<math>f^*(\\theta)=\\sup\\{f(x, \\theta) : x\\in C(\\theta)\\}</math>\n\nand the ''set of maximizers'' <math>C^* : \\Theta \\rightrightarrows X</math> by\n\n:<math>\nC^*(\\theta)= \n\\mathrm{arg}\\sup\\{f(x,\\theta) : x \\in C(\\theta)\\} \n= \\{x \\in C(\\theta) : f(x, \\theta) = f^*(\\theta)\\}\n</math>.\n\nIf <math>C</math> is continuous (i.e. both upper and lower [[hemicontinuity|hemicontinuous]]) at  <math>\\theta</math>, then <math>f^*</math> is continuous and <math>C^*</math>is upper hemicontinuous with nonempty and compact values. As a consequence, the <math>\\sup</math> may be replaced by <math>\\max</math> and the <math>\\mathrm{arg}\\,\\sup</math> by <math display=\"inline\">\\mathrm{arg}\\,\\max</math>.\n\n==Interpretation==\nThe theorem is typically interpreted as providing conditions for a parametric optimization problem to have continuous solutions with regard to the parameter. In this case, <math>\\Theta</math> is the parameter space, <math>f(x,\\theta)</math> is the function to be maximized, and <math>C(\\theta)</math> gives the constraint set that <math>f</math> is maximized over. Then, <math>f^*(\\theta)</math> is the maximized value of the function and <math>C^*</math> is the set of points that maximize <math>f</math>.\n\nThe result is that if the elements of an optimization problem are sufficiently continuous, then some, but not all, of that continuity is preserved in the solutions.\n\n==Proof==\nThroughout this proof we will use the term ''neighborhood'' to refer to an [[open set]] containing a particular point. We preface with a preliminary lemma, which is a general fact in the calculus of correspondences. Recall that a correspondence is ''closed'' if its [[hemicontinuity#Closed_Graph_Theorem|graph]] is closed.\n\n'''Lemma'''.<ref> Compare with Theorem 7 in Chapter 6, Section 1 of {{cite book\n  | author = Claude Berge\n  | title = Topological Spaces\n  | year = 1963\n  | publisher = Oliver and Boyd\n  | pages = 112\n  }} Berge assumes that the underlying spaces are Hausdorff and employs this property for <math>X</math> (but not for <math>C</math>) in his proof.</ref><ref>Compare with Proposition 2.46 in {{cite book\n  | author1 = Shouchuan Hu\n  | author2 = Nikolas S. Papageorgiou\n  | title = Handbook of Multivalued Analysis\n  | volume = 1: Theory\n  | year = 1997\n  | publisher = Springer-Science + Business Media, B. V\n  | pages = 53\n  }} They assume implicitly that <math>\\Theta</math> and <math>X</math> are Hausdorff spaces, but their proof is general.</ref><ref>Compare with Corollary 17.18 in {{cite book \n  |author1 = Charalambos D. Aliprantis \n  |author2 = Kim C. Border \n  |title=Infinite Dimensional Analysis: A Hitchhiker's Guide \n  |publisher=Springer \n  |year=2006 \n  |pages=564 \n}} This is given for arbitrary topological spaces, but the proof relies on the machinery of topological nets.</ref> \n''If <math>A, B : \\Theta \\rightrightarrows X</math> are correspondences, <math>A</math> is upper hemicontinuous and compact-valued, and <math>B</math> is closed, then <math>A \\cap B : \\Theta \\rightrightarrows X</math> defined by <math>(A \\cap B) (\\theta) = A(\\theta) \\cap B(\\theta)</math> is upper hemicontinuous.''\n\n{{Collapse top|title = Proof}}\nLet <math>\\theta \\in \\Theta</math>, and suppose <math>G</math> is an open set containing <math>(A\\cap B)(\\theta)</math>. If <math>A(\\theta) \\subseteq G</math>, then the result follows immediately. Otherwise, observe that for each <math>x \\in A(\\theta) \\setminus G</math> we have <math>x \\notin B(\\theta)</math>, and since <math>B</math> is closed there is a neighborhood <math>U_x \\times V_x</math> of <math>(\\theta, x)</math> in which <math>x' \\notin B(\\theta')</math> whenever <math>(\\theta', x') \\in U_x \\times V_x</math>. The collection of sets <math>\\{G\\} \\cup \\{V_x : x \\in A(\\theta) \\setminus G\\}</math> forms an open cover of the compact set <math>A(\\theta)</math>, which allows us to extract a finite subcover <math>G, V_{x_1}, \\dots, V_{x_n}</math>. Then whenever <math>\\theta \\in U_{x_1} \\cap \\dots \\cap U_{x_n}</math>, we have <math>A(\\theta) \\subseteq G \\cup V_{x_1} \\cup \\dots \\cup V_{x_n}</math>, and so <math>(A \\cap B)(\\theta) \\subseteq G</math>. This completes the proof. <math>\\square</math>\n{{Collapse bottom}}\n\nThe continuity of <math>f^*</math> in the maximum theorem is the result of combining two independent theorems together.\n\n'''Theorem 1'''.<ref> Compare with Theorem 2 in Chapter 6, Section 3 of {{cite book\n  | author = Claude Berge\n  | title = Topological Spaces\n  | year = 1963\n  | publisher = Oliver and Boyd\n  | pages = 116\n  }} Berge's argument is essentially the one presented here, but he again uses auxiliary results proven with the assumptions that the underlying spaces are Hausdorff.</ref><ref>Compare with Proposition 3.1 in {{cite book\n  | author1 = Shouchuan Hu\n  | author2 = Nikolas S. Papageorgiou\n  | title = Handbook of Multivalued Analysis\n  | volume = 1: Theory\n  | year = 1997\n  | publisher = Springer-Science + Business Media, B. V\n  | pages = 82\n  }} They work exclusively with Hausdorff spaces, and their proof again relies on topological nets. Their result also allows for <math>f</math> to take on the values <math>\\pm \\infty</math>.</ref><ref>Compare with Lemma 17.30 in {{cite book \n  |author1 = Charalambos D. Aliprantis \n  |author2 = Kim C. Border \n  |title=Infinite Dimensional Analysis: A Hitchhiker's Guide \n  |publisher=Springer \n  |year=2006 \n  |pages=569 \n}} They consider arbitrary topological spaces, and use an argument based on topological nets.</ref> \n''If <math>f</math> is upper semicontinuous and <math>C</math> is upper hemicontinuous, nonempty and compact-valued, then <math>f^*</math> is upper semicontinuous.''\n\n{{Collapse top|title = Proof of Theorem 1}}\nFix <math>\\theta \\in \\Theta</math>, and let <math>\\varepsilon > 0</math> be arbitrary. For each <math>x \\in C(\\theta)</math>, there exists a neighborhood <math>U_x \\times V_x</math> of <math>(\\theta, x)</math> such that whenever <math>(\\theta', x') \\in U_x \\times V_x</math>, we have <math>u(\\theta', x') < u(\\theta, x) + \\varepsilon</math>. The set of neighborhoods <math>\\{V_x : x \\in C(\\theta)\\}</math> covers <math>C(\\theta)</math>, which is compact, so <math>V_{x_1}, \\dots, V_{x_n}</math> suffice. Furthermore, since <math>C</math> is upper hemicontinuous, there exists a neighborhood <math>U'</math> of <math>\\theta</math> such that whenever <math>\\theta' \\in U'</math> it follows that <math>C(\\theta') \\subseteq \\bigcup_{k=1}^{n} U_k</math>. Let <math>U = U' \\cap U_{x_1} \\cap \\dots \\cap U_{x_n}</math>. Then for all <math>\\theta' \\in U</math>, we have <math>f(x', \\theta') < f(x, \\theta) + \\varepsilon</math> for each <math>x' \\in C(\\theta')</math>. It follows that\n\n:<math> f^*(\\theta') = \\sup_{x' \\in C(\\theta')} f(x', \\theta') < \\max_{k=1, \\dots, n} f(x_k, \\theta) + \\varepsilon \\leq f^*(\\theta) + \\varepsilon,\n</math>\n\nwhich was desired. <math>\\square</math>\n{{Collapse bottom}}\n\n'''Theorem 2'''.<ref> Compare with Theorem 1 in Chapter 6, Section 3 of {{cite book\n  | author = Claude Berge\n  | title = Topological Spaces\n  | year = 1963\n  | publisher = Oliver and Boyd\n  | pages = 115\n  }} The argument presented here is essentially his.</ref><ref>Compare with Proposition 3.3 in {{cite book\n  | author1 = Shouchuan Hu\n  | author2 = Nikolas S. Papageorgiou\n  | title = Handbook of Multivalued Analysis\n  | volume = 1: Theory\n  | year = 1997\n  | publisher = Springer-Science + Business Media, B. V\n  | pages = 83\n  }} They work exclusively with Hausdorff spaces, and their proof again relies on topological nets. Their result also allows for <math>f</math> to take on the values <math>\\pm \\infty</math>.</ref><ref>Compare with Lemma 17.29 in {{cite book \n  |author1 = Charalambos D. Aliprantis \n  |author2 = Kim C. Border \n  |title=Infinite Dimensional Analysis: A Hitchhiker's Guide \n  |publisher=Springer \n  |year=2006 \n  |pages=569 \n}} They consider arbitrary topological spaces and use an argument involving topological nets.</ref> \n''If <math>f</math> is lower semicontinuous and <math>C</math> is lower hemicontinuous, then <math>f^*</math> is lower semicontinuous.''\n\n{{Collapse top|title = Proof of Theorem 2}} \nFix <math>\\theta \\in \\Theta</math>, and let <math>\\varepsilon > 0</math> be arbitrary. \nBy definition of <math>f^*</math>, there exists <math>x \\in C(\\theta)</math> such that <math>f^*(\\theta) < f(x,\\theta) + \\frac{\\varepsilon}{2}</math>. \nNow, since <math>f</math> is lower semicontinuous, there exists a neighborhood <math>U_1 \\times V</math> of <math>(\\theta, x)</math> such that whenever <math>(\\theta', x') \\in U_1 \\times V</math> we have <math>f(x, \\theta) < f(x', \\theta') + \\frac{\\varepsilon}{2}</math>. Observe that <math>C(\\theta) \\cap V \\ne \\emptyset</math> (in particular, <math>x \\in C(\\theta) \\cap V</math>). Therefore, since <math>C</math> is lower hemicontinuous, there exists a neighborhood <math>U_2</math> such that whenever <math>\\theta' \\in U_2</math> there exists <math>x' \\in C(\\theta') \\cap V</math>. \nLet <math>U = U_1 \\cap U_2</math>. \nThen whenever <math>\\theta' \\in U</math> there exists <math>x' \\in C(\\theta') \\cap V</math>, which implies \n\n:<math>f^*(\\theta) < f(x, \\theta) + \\frac{\\varepsilon}{2} < f(x', \\theta') + \\varepsilon \\leq f^*(\\theta') + \\varepsilon</math>\n\nwhich was desired. <math>\\square</math>\n{{Collapse bottom}}\n\nUnder the hypotheses of the Maximum theorem, <math>f^*</math> is continuous. It remains to verify that <math>C^*</math> is an upper hemicontinuous correspondence with compact values. Let <math>\\theta \\in \\Theta</math>. To see that <math>C^*(\\theta)</math> is nonempty, observe that the function <math>f_\\theta : C(\\theta) \\to \\mathbb{R}</math> by <math>f_\\theta(x) = f(x, \\theta)</math> is continuous on the compact set <math>C(\\theta)</math>. The [[extreme value theorem|Extreme Value theorem]] implies that <math>C^*(\\theta)</math> is nonempty. In addition, since <math>f_\\theta</math> is continuous, it follows that <math>C^*(\\theta)</math> a closed subset of the compact set <math>C(\\theta)</math>, which implies <math>C^*(\\theta)</math> is compact. Finally, let <math>D : \\Theta \\rightrightarrows X</math> be defined by <math display=\"inline\">D(\\theta) = \\{x \\in C(\\theta) : f(x, \\theta) = f^*(\\theta)\\}</math>. Since <math>f</math>  is a continuous function, <math>D</math> is a closed correspondence. Moreover, since <math>C^*(\\theta) = C(\\theta) \\cap D(\\theta)</math>,  the preliminary Lemma implies that <math>C^*</math> is upper hemicontinuous. <math>\\square</math>\n\n==Variants and generalizations==\nA natural generalization from the above results gives sufficient ''local'' conditions for <math>f^*</math>to be continuous and <math>C^*</math>to be nonempty, compact-valued, and upper semi-continuous.\n\nIf in addition to the conditions above, <math>f</math> is [[quasiconcave]] in <math>x</math> for each <math>\\theta</math> and <math>C</math> is convex-valued, then <math>C^*</math> is also convex-valued. If <math>f</math> is strictly quasiconcave in <math>x</math> for each <math>\\theta</math> and <math>C</math> is convex-valued, then <math>C^*</math> is single-valued, and thus is a continuous function rather than a correspondence.\n\nIf <math>f</math> is [[Concave function|concave]] and <math>C</math> has a [[Convex set|convex]] graph, then <math>f^*</math> is concave and <math>C^*</math> is convex-valued. Similarly to above, if <math>f</math> is strictly concave, then <math>C^*</math> is a continuous function.<ref>{{cite book\n  | first = Rangarajan K. |last=Sundaram\n  | title = A First Course in Optimization Theory\n  | year = 1996\n  | publisher = Cambridge University Press\n  | isbn = 0-521-49770-1\n  | page= 239 }}</ref>\n\nIt is also possible to generalize Berge's theorem to non-compact set-valued correspondences if the objective function is K-inf-compact.<ref>Theorem 1.2 in {{cite journal\n  |last1=Feinberg\n  |first1=Eugene A.\n  |last2=Kasyanov\n  |first2=Pavlo O.\n  |last3=Zadoianchuk\n  |first3=Nina V.\n  |title=Berge’s theorem for noncompact image sets\n  |journal=Journal of Mathematical Analysis and Applications\n  |date=January 2013\n  |volume=397\n  |issue=1\n  |pages=255–259\n  |doi=10.1016/j.jmaa.2012.07.051\n  |arxiv=1203.1340\n  }}</ref>\n\n==Examples==\nConsider a [[utility maximization problem]] where a consumer makes a choice from their budget set. Translating from the notation above to the standard consumer theory notation,\n* <math>X=\\mathbb{R}_+^l</math> is the space of all bundles of <math>l</math> commodities,\n* <math>\\Theta=\\mathbb{R}_{++}^l \\times \\mathbb{R}_{++}</math> represents the price vector of the commodities <math>p</math> and the consumer's wealth <math>w</math>,\n* <math>f(x,\\theta)=u(x)</math> is the consumer's [[utility function]], and\n* <math>C(\\theta)=B(p,w)=\\{x \\,|\\, px \\leq w\\}</math> is the consumer's [[budget set]].\n\nThen, \n* <math>f^*(\\theta)=v(p,w)</math> is the [[indirect utility function]] and\n* <math>C^*(\\theta)=x(p,w)</math> is the [[Marshallian demand]].\n\nProofs in [[general equilibrium theory]] often apply the [[Brouwer fixed-point theorem|Brouwer]] or [[Kakutani fixed-point theorem]]s to the consumer's demand, which require compactness and continuity, and the maximum theorem provides the sufficient conditions to do so.\n\n==See also==\n* [[Envelope theorem]]\n*[[Brouwer fixed-point theorem|Brouwer fixed point theorem]]\n*[[Kakutani fixed-point theorem|Kakutani fixed point theorem for correspondences]]\n\n==Notes==\n{{reflist}}\n\n==References==\n* {{cite book\n  | author = Claude Berge\n  | title = Topological Spaces\n  | year = 1963\n  | publisher = Oliver and Boyd\n  | pages = 115-117\n  }}\n* {{cite book\n  | author1 = Charalambos D. Aliprantis\n  | author2 = Kim C. Border\n  | title = Infinite Dimensional Analysis: A Hitchhiker's Guide\n  | year = 2006\n  | publisher = Springer\n  | pages = 569-571\n  }}\n* {{cite book\n  | author1 = Shouchuan Hu\n  | author2 = Nikolas S. Papageorgiou\n  | title = Handbook of Multivalued Analysis\n  | volume = 1: Theory\n  | year = 1997\n  | publisher = Springer-Science + Business Media, B. V\n  | pages = 82-89\n  }}\n\n[[Category:Mathematical optimization]]\n[[Category:Continuous mappings]]\n[[Category:Mathematical economics]]\n[[Category:Mathematical theorems]]"
    },
    {
      "title": "MCACEA",
      "url": "https://en.wikipedia.org/wiki/MCACEA",
      "text": "'''MCACEA''' ('''Multiple Coordinated Agents Coevolution Evolutionary Algorithm''') is a general framework that uses a single [[evolutionary algorithm]] (EA) per agent sharing their optimal solutions to coordinate the evolutions of the EAs populations using cooperation objectives. This framework can be used to optimize some characteristics of multiple cooperating agents in [[mathematical optimization]] problems. More specifically, due to its nature in which both individual and cooperation objectives are optimize, MCACEA is used in [[multi-objective optimization]] problems.\n\n==Description and implementation==\nMCACEA, uses multiple EAs (one per each agent) that evolve their own populations to find the best solution for its associated problem according to their individual and cooperation constraints and objective indexes. Each EA is an optimization problem that runs in parallel and that exchanges some information with the others during its evaluation step. This information is needed to let each EA to measure the coordination objectives of the solutions encoded in its own population, taking into account the possible optimal solutions of the remaining populations of the other EAs. With this purpose, each single EA receives information related to the best solutions of the remaining ones before evaluating the cooperative objectives of each possible solution of its own population.\n\nAs the cooperation objective values depend on the best solutions of the other populations and the optimality of a solution depends both on the individual and cooperation objectives, it is not really possible to select and send the best solution of \neach planner to the others. However, MCACEA divides the evaluation step inside each EA in three parts: In the first part, the \nEAs identify the best solution considering only its individual objective values and send it to the others EAs; in the second part, the cooperation objective values of all solutions are calculated taking into account the received information; and in the third part, the EAs calculate the fitness of the solutions considering all the individual and cooperation objective values. \n\nAlthough each population can only offer a unique optimal solution, each EA maintains a [[pareto set]] of optimal solutions and selects the unique optimal solution at the end, when the last population has already been obtained. Therefore, to be able to determine a unique optimal solution according with the individual objectives in each generation (and so, using it with the MCACEA framework), a step in charge of selecting the final optimal solution must also be included in the evaluation step of each EA.\n\n==Evaluation phase in MCACEA==\nThe complete evaluation phase of the individual cooperating EAs is divided in six steps. When searching for the solution of a single EA, only the first two steps of this new evaluation process are used. MCACEA extends this process from these two only steps to the next six:\n\n1. Evaluating the individual objectives of each solution.\n\n2. Calculating the fitness of each solution with the single evaluation function (containing only the individual objectives).\n\n3. Finding the best solution of the population.\n\n4. Sending (and receiving) the best solution to (of) the other single EAs.\n\n5. Calculating the cooperation objectives taking into account the received information from the other EAs.\n\n6. Calculating the fitness of each solution with the complete evaluation function (containing both the individual and the cooperation objectives), which have been obtained in steps 1 and 5.\n\n==Similar approaches==\nAlthough MCACEA may look similar to the habitual parallelization of EAs, in this case, instead of distributing the solutions of the whole problem between different EAs that share their solutions periodically, the algorithm is dividing the problem into smaller problems that are solved simultaneously by each EA taking into account the solutions of the part of the problems that the other EAs are obtaining.\n\nAnother possibility,<ref>C. Zheng, L. Li, F. Xu, F. Sun, and M. Ding, ''Evolutionary route planner for unmanned air vehicles,'' IEEE Transactions on Robotics, vol. 21, no. 4, pp. 609–620, Aug. 2005.</ref> is to send the best completely evaluated solutions of the previous generation to the other EAs instead of our current best only individual objective evaluated one. Nevertheless, that approach introduces a bias toward outdated completely evaluated trajectories, while MCACEA does it toward currently good individual objective evaluated ones.\n\n==Applications==\nMCACEA has been used for finding and optimizing [[unmanned aerial vehicles]] (UAVs) trajectories when flying simultaneously in the same scenario.<ref>[http://www.cs.bham.ac.uk/~wbl/biblio/gecco2008/docs/p1477.pdf J. M. de la Cruz, E. Besada-Portas, L. de la Torre, B. Andrés-Toro, and J. A. Lopez-Orozco, ''Evolutionary path planner for UAVs in realistic environments,'' in Proceedings of the Genetic and Evolutionary Compututation Conference, 2008, pp. 1447–1155.]</ref>\n\n==See also==\n* [[Artificial development]]\n* [[Developmental biology]]\n* [[Evolutionary computation]]\n* [[Evolutionary robotics]]\n* [[Fitness function]]\n* [[Fitness landscape]]\n* [[Fitness approximation]]\n* [[Genetic operators]]\n* [[Interactive evolutionary computation]]\n* [[MOEA Framework]], an open source Java framework for multiobjective evolutionary algorithms\n* [[Java Evolutionary Computation Toolkit|ECJ]], a toolkit to implement evolutionary algorithms\n* [[Paradiseo]], a metaheuristics framework\n\n==References==\n<references/>\n\n==Bibliography==\nL. de la Torre, J. M. de la Cruz, and B. Andrés-Toro. ''Evolutionary trajectory planner for multiple UAVs in realistic scenarios''. IEEE Transactions on Robotics, vol. 26, no. 4, pp.&nbsp;619–634, August 2010.\n\n[[Category:Evolutionary computation]]\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Mean field annealing",
      "url": "https://en.wikipedia.org/wiki/Mean_field_annealing",
      "text": "{{one source|date=June 2017}}\n{{technical|date=June 2017}}\n'''Mean field annealing''' is a [[deterministic]] [[approximation]] to the [[simulated annealing]] technique of solving [[optimization]] problems.<ref>{{cite journal | url=http://www.ece.ncsu.edu/imaging/Publications/1992/BilbroSnyderTNN.pdf | title=Mean field annealing: a formalism for constructing GNC-like algorithms |author1=Bilbro, G.L. |author2=Snyder, W.E. |author3=Garnier, S.J. |author4=Gault, J.W. | journal=IEEE Transactions on Neural Networks |date=Jan 1992 | volume=3 | issue=1 | pages=131–138 | doi=10.1109/72.105426}}</ref> This method uses [[mean field theory]] and is based on [[Trace inequalities#Peierls.E2.80.93Bogoliubov inequality|Peierls' inequality]].\n\n==References==\n{{reflist}}\n\n[[Category:Mathematical optimization]]\n\n\n{{applied-math-stub}}"
    },
    {
      "title": "Measuring attractiveness by a categorical-based evaluation technique (MACBETH)",
      "url": "https://en.wikipedia.org/wiki/Measuring_attractiveness_by_a_categorical-based_evaluation_technique_%28MACBETH%29",
      "text": "{{Underlinked|date=May 2017}}\n\n'''Measuring attractiveness through a categorical-based evaluation technique'''<ref name=\"Bana\">Bana e Costa CA, De Corte J-M, Vansnick J-C. MACBETH. [[International Journal of Information Technology & Decision Making]]. 2012;11(02):359–87.</ref><ref name=\"Bana2\">Bana e Costa CA, De Corte JM, Vansnick JC. On the mathematical foundations of MACBETH. In: Figueira J, Greco S, Ehrgott M, (Eds.) Multiple Criteria Decision Analysis: The State of the Art Surveys. New York: Springer; 2005. pp. 409–42.</ref><ref name=\"Bana3\">Bana e Costa CA, Chagas MP. A career choice problem: An example of how to use MACBETH to build a quantitative value model based on qualitative value judgments. European Journal of Operational Research. 2004;153(2):323–31.</ref> is the goal of the MACBETH approach that was designed by [http://web.ist.utl.pt/carlosbana/ Carlos António Bana e Costa], from the University of Lisbon, in cooperation with Professor Jean-Claude Vansnick and Dr. Jean-Marie De Corte, from the Université de Mons.\n\nMACBETH permits the evaluation of options against multiple criteria. The key distinction between MACBETH and other [[multiple-criteria decision analysis]] (MCDA) methods is that it needs only qualitative judgements about the difference of attractiveness between two elements at a time, in order to generate numerical scores for the options in each criterion and to weight the criteria. The seven MACBETH semantic categories are: no, very weak, weak, moderate, strong, very strong, and extreme difference of attractiveness.\n\n== Uses and applications==\nMACBETH has been extensively applied in various evaluation contexts, namely:<ref name=\"Bana2\"/>\n\n=== Agriculture, manufacturing, and services===\n* Finance<ref name=\"Bana e Costa 2007\">Bana e Costa, C. A., J. C. Lourenço, et al. (2007). \"An interval weighting assignment model for credit analysis.\" Journal of Financial Decision Making 3(2): 1–9.</ref><ref name=\"Bana e Costa 2007\"/><ref>Bana e Costa, C. A., L. Barroso, et al. (2002). \"Qualitative modelling of credit scoring: A case study in banking.\" Journal of European Research Studies 5(1-2): 37–51.</ref><ref>Bana e Costa, C. A. and J. O. Soares (2004). \"A multicriteria model for portfolio management.\" European Journal of Finance 10(3): 198–211.</ref><ref>Bortuluzzi, S. C., S. R. Ensslin, et al. (2010). \"Avaliação de Desempenho dos Aspectos Tangíveis e Intangíveis da Área de Mercado: Estudo de caso em uma média empresa industrial.\" Revista Brasileira de Gestão de Negócios 12(37): 425–446.</ref><ref>Bortuluzzi, S. C., S. R. Ensslin, et al. (2011). \"Avaliação de desempenho das variáveis financeiras e não financeiras que respondem pelo desempenho de uma indústria de móveis.\" Revista Gestão Industria 7(2): 24–47.</ref><ref>Bortuluzzi, S. C., S. R. Ensslin, et al. (2011b). \"Avaliação de desempenho económico-financeiro: Uma proposta de integração de indicadores contábeis tradicionais por meio da Metodologia Multicritério de Apoio à Decisão Construtivista (MCDA-C).\" Revista Alcance (Online) 18(2): 200–218.</ref><ref>Cabello, J. M., F. Ruiz, et al. (2014). \"Synthetic indicators of mutual funds' environmental responsibility: An application of the Reference Point Method.\" European Journal of Operational Research. https://dx.doi.org/10.1016/j.ejor.2013.11.031.</ref><ref>Ensslin, L., G. N. Montibeller, et al. (2000). Constructing and implementing a DSS to help evaluate perceived risk of accounts receivable. Research and Practice in Multiple Criteria Decision Making, Springer-Verlag, Berlin. 487: 245–259.</ref><ref>Ferreira, F. A. F. (2006). Bank Branches' Performance Evaluation. IADIS International Conference e-Society, Dublin, Ireland: 392–394.</ref><ref>Ferreira, F., S. P. Santos, et al. (2014). \"Assessing Credit Risk Of Mortgage Lending Using MACBETH: A Methodological Framework.\" Management Decision 52(2): 1–36.</ref><ref>Ferreira, F. A. F., S. P. Santos, et al. (2011). \"Adding value to bank branch performance evaluation using cognitive maps and MCDA: A case study.\" Journal of the Operational Research Society 62(7): 1320–1333.</ref><ref>Ferreira, F. A. F., R. W. Spahr, et al. (2012). \"A Multiple Criteria Framework to Evaluate Bank Branch Potential Attractiveness.\" International Journal of Strategic Property Management 16(3): 254–276.</ref><ref>Hurson, C., K. Mastorakis, et al. (2012). \"Application of a synergy of MACBETH and MAUT multicriteria methods to portfolio selection in Athens stock exchange.\" International Journal of Multicriteria Decision Making 2(2): 113–127.</ref><ref>Soares, J. O. and C. A. Bana e Costa (2001). Value judgements in portfolio management, CEG-IST, Technical University of Lisbon.</ref>\n* Information systems<ref>Sousa, J. V. M., J. S. de v Silva, et al. (2012). MAC-OLSR: Improving OLSR protocol in mesh networks using multiple metrics. Valencia, 6th Euro American Conference on Telematics and Information Systems: 1–8.</ref><ref>Flix, B., A. Vasconcelos, et al. (2012). \"SimplexIS: Evaluating the impact of e-Gov simplication measures in the information system architecture.\" World Academy of Science 63: 636–641.</ref><ref>Bana e Costa, C. A., J. M. De Corte, et al. (2012). \"MACBETH.\" International Journal of Information Technology and Decision Making 11(2): 359–387.</ref>\n* Performance measurement<ref>Berrah, L. and V. Clivill\\'e (2007). \"Towards an aggregation performance measurement system model in a supply chain context.\" Computers in Industry 58(7): 709–719.</ref><ref>Berrah, L., G. Mauris, et al. (2008a). \"Monitoring the improvement of an overall industrial performance based on a Choquet integral aggregation.\" Omega 36(3): 340–351.</ref><ref>Berrah, L., G. Mauris, et al. (2008b). \"Efficacy and efficiency indexes for a multi-criteria industrial performance synthesized by Choquet integral aggregation.\" International Journal of Computer Integrated Manufacturing 21(4): 415–425.</ref><ref>Berrah, L., G. Mauris, et al. (2006). \"Industrial performance measurement: An approach based on the aggregation of unipolar or bipolar expressions.\" International Journal of Production Research 44(18–19): 4145–4158.</ref><ref>Bortuluzzi, S. C., S. R. Ensslin, et al. (2009). \"Proposta de um modelo multicritério de avaliação de desempenho económico-financeiro para apoiar decisões de investimentos em empresas de capital aberto.\" CAP Accounting and Management 3(3): 100–110.</ref><ref>Bortuluzzi, S. C., S. R. Ensslin, et al. (2010). \"Construção de um modelo de avaliaço de desempenho para a gestão financeira de uma empresa de informática.\" CAP Accounting and Management 4(4): 12–22.</ref><ref>Clivillé, V., L. Berrah, et al. (2007). \"Quantitative expression and aggregation of performance measurements based on the MACBETH multi-criteria method.\" International Journal of Production Economics 105(1): 171–189.</ref><ref>Dutra, A., S. R. Ensslin, et al. (2009). \"A incorporação da dimensão integrativa nos processos de avaliação do desempenho organizacional: Um estudo de caso.\" Revista Contemporânea de Contabilidade 6(11): 109–136.</ref><ref>Ensslin, L., E. Giffhorn, et al. (2010). \"Avaliação do Desempenho de Empresas Terceirizadas com o Uso da Metodologia Multicritério de Apoio à Decisão-Construtivista.\" Revista Pesquisa Operacional 30(1): 125–152.</ref><ref>Ensslin, L., L. C. M. Scheid, et al. (2012). \"Software process assessment and improvement using multicriteria decision aiding-constructivist.\" JISTEM – Journal of Information Systems and Technology Management 9(3): 473–496.</ref><ref>de Azevedo, R., R. de Oliveira Lacerda, et al. (2013). \"Performance Measurement to Aid Decision Making in the Budgeting Process for Apartment-Building Construction: Case Study Using MCDA-C.\" Journal of Construction Engineering and Management 139(2): 225–235.</ref><ref>Gallon, A. V., S. R. Ensslin, et al. (2011). \"Avaliaço de desempenho organizacional em incubadoras de empresas por meio da metodologia multicritério de apoio à decisão construtivista (MCDA-C): A experiência do midi tecnológico.\" RAI: Revista de Administraço e Inovação 8(1): 37–63.</ref><ref>Giffhorn, E., L. Ensslin, et al. (2010). \"Avaliação do Desempenho de Empresas Terceirizadas com o uso da Metodologia Multicritério em Apoio à Decisão – Construtivista.\" Pesquisa Operacional 30(1): 125–152.</ref><ref>Giffhorn, E., L. Ensslin, et al. (2009). Proposal of a Multicriteria Performance Evaluation for Outsourced Project Providers. Performance Measurement Association Conference 2009. University of Otago, New Zealand, (18p.).</ref><ref>Junior, A. G. M., M. M. C. Junior, et al. (2012). \"Multicriteria and multivariate analysis for port performance Evaluation.\" International Journal of Production Economics 140(1): 450–456.</ref><ref>Lauras, M., G. Marques, et al. (2010). \"Towards a multi-dimensional project Performance Measurement System.\" Decision Support Systems 48(2): 342–353.</ref><ref>Lacerda, R. T. O., L. Ensslin, et al. (2010). \"Um estudo de caso sobre gerenciamento de portfólio de projectos e apoio à decisão multicritério.\" Revista Gestão Industrial 6(1): 1–29.</ref><ref>Lacerda, R. T. O., L. Ensslin, et al. (2011a). \"A Performance Measurement Framework in Portfolio Management: A Constructivist Case.\" Management Decision 49(4): 648–668.</ref><ref>Lacerda, R. T. O., L. Ensslin, et al. (2011b). \"A performance measurement view of IT project management.\" International Journal of Productivity and Performance Management 60(2): 132–151.</ref><ref>Marques, G., D. Gourc, et al. (2010). \"Multi-criteria performance analysis for decision making in project management.\" International Journal of Project Management 29(8): 1057–1069.</ref><ref>Stolt, R. and L. Ensslin (2009). \"Avaliação de pilotos Very Light Jets Utilizando-se a MCDA-C.\" Conexão Sipaer 1(1): 85–103.</ref><ref>Vernadat, F., L. Shah, et al. (2013). \"VR-PMS: A new approach for performance measurement and management of industrial systems.\" International Journal of Production Research 51(23–24): 7420–7438.</ref>\n* Production & service planning<ref>Amora Silva, M. B. F. and C. A. Bana e Costa (2008). \"Modelo multicritério de avaliação de capacidade empreendedora em empresas de base tecnológica.\" Engevista 10(1): 4–14.</ref><ref>Andrade, A. C. Z. B. and C. A. Bana e Costa (2001). Measuring security value: a multi-criteria decision analysis approach, CEG-IST, Technical University of Lisbon.</ref><ref>Bana e Costa, C. A., L. Ensslin, et al. (1998). Structuring the Process of Choosing Rice Varieties at the South of Brazil, Dordrecht, Kluwer Academic.</ref><ref name=\"Bana e Costa 1997\">Bana e Costa, C. A., M. L. Costa-Lobo, et al. (1997). \"Contributo da metodologia multicritério na elaboração do Plano Estratégico de Barcelos.\" Sociedade e Território 24: 102–115.</ref><ref>Cardoso, F. J. P., L. F. A. M. Gomes, et al. (2003). \"Administração das operações de telecomunicação: Uma análise de decisão.\" Revista Portuguesa e Brasileira de Gestão 2(2): 91–103.</ref><ref>de Castro, A. K. A., P. R. Pinheiro, et al. (2006). \"A Scheduling Process Applied to Newspaper Production.\" IEEE Transactions on Evolutionary Computation.</ref><ref>de Castro, A. K. A., P. R. Pinheiro, et al. (2008). Application Multicriteria Decision Analysis on TV Digital. Advances in Computer and Information Sciences and Engineering, Springer: 39–44.</ref><ref>Grzebieluckas, C., M. A. Busson, et al. (2011). \"Instrumento para identificação das necessidades do consumidor no processo de desenvolvimento do design: Ilustrado ao caso de projeto de um automóvel.\" Gestão & produção 18(2): 335–350.</ref><ref>Karande, P. and S. Chakraborty (2013). \"Evaluation and selection of flexible manufacturing systems using MACBETH method.\" International Journal of Services and Operations Management 16(1): 123–144.</ref><ref>Montmain, J., C. Sanchez, et al. (2009). \"Multi criteria analyses for managing motorway company facilities: The decision support system SINERGIE.\" Advanced Engineering Informatics 23(3): 265–287.</ref><ref>Palacios, O. Y. S., P. C. N. Rincón, et al. (2013). \"Multicriteria optimization of production conditions for a new phthalate-free PVC plasticizer.\" Journal of Industrial and Engineering Chemistry. Doi: 10.1016/j.jiec.2013.09.021.</ref><ref>Pedro, M. I. and F. L. Cabral (2013). \"A New Innovative Model Using RFID: A System Design and Its Implementation.\" International Journal of Latest Trends in Finance & Economic Sciences 3(2): 508–219.</ref><ref>Rodrigues, A., P. R. Pinheiro, et al. (2009). Towards the Selection of Testable Use Cases and a Real Experience. WSKS (2), Springer. 49: 513–521.</ref><ref>Sanchez, C., J. Montmain, et al. (2007). Planning of Maintenance Operations for a Motorway Operator based upon Multicriteria Evaluations over a Finite Scale and Sensitivity Analyses. Conference on Informatics in Control, Automation and Robotics: 23–35.</ref>\n* Quality management<ref>Bana e Costa, C. A., M. C. Carnero, et al. (2012). \"A multi-criteria model for auditing a Predictive Maintenance Programme.\" European Journal of Operational Research 217(2): 381–393.</ref><ref name=\"Bana e Costa 2000\">Bana e Costa, C. A. and E. C. Corrêa (2000). O processo de construção do índice FUNCEME de vulnerabilidade à seca, CEG-IST, Technical University of Lisbon.</ref><ref>Carnero, M. C. (2009a). \"Evaluating a Maintenance Department in a Service Company.\" International Journal of Mathematical models and Methods in Applied Sciences 3(3): 230–237.</ref><ref>Carnero, M. C. (2009b). Maintenance Audit by means of an additive multicriteria model. Advances in Marketing, Management and Finances, WSEAS Press: 147–152.</ref><ref>Fakhfakh, N., F. Pourraz, et al. (2011). Client-Oriented Preferences Model for QoS Aggregation in Service-Based Applications. E-Business and Telecommunications. Seville, Spain, Springer Berlin Heidelberg. 314: 141–155.</ref>\n* R&D project selection<ref>de Lima, A. S. and J. H. S. Damiani (2009). A Proposed Method for Modeling Research and Development (R&D) Project Prioritization Criteria. Management of Engineering & Technology, 2009, PICMET 2009.</ref>\n* Risk management<ref>Costa, H. R., M. D. O. Barros, et al. (2007). \"Evaluating software project portfolio risks.\" Journal of Systems and Software 80(1): 16–31.</ref><ref>Figueiredo, M. S. M. and M. D. Oliveira (2009). Prioritizing Risks Based on Multicriteria Decision Aid Methodology: Development of Methods Applied to ALSTOM Power. IEEE International Conference on Industrial Engineering and Engineering Management, Hong Kong, China: 1568–1572.</ref><ref>Ntouskas, T. and N. Polemi (2012). \"STORM-RM: A collaborative and multicriteria risk management methodology.\" International Journal of Multicriteria Decision Making 2(2): 159–177.</ref>\n* Strategy & resource allocation<ref>Bana e Costa, C. A., L. Ensslin, et al. (1998b). A Real-World MCDA Application in Cellular Telephony Systems. Trends in Multicriteria Decision Making, Springer-Verlag, Berlin. 465: 412–423.</ref><ref>Bana e Costa, C. A., E. C. Corrêa, et al. (1999). \"Decision support systems in action: Integrated application in a multicriteria decision aid process.\" European Journal of Operational Research 113(2): 315–335.</ref>\n* Supply chain and logistics<ref>Della Bruna Jr., E., L. Ensslin, et al. (2011). Supply chain performance evaluation: a case study in a company of equipment for refrigeration. Proceedings of the 2011 IEEE International Technology Management Conference. San Jose, USA.</ref><ref>Dhouib, D. (2013). Fuzzy Macbeth method to analyze alternatives in automobile tire wastes reverse logistics. Sousse, International Conference on Advanced Logistics and Transport: 321–326.</ref><ref>Dhouib, D. (2014). \"An extension of MACBETH method for a fuzzy environment to analyze alternatives in reverse logistics for automobile tire wastes.\" Omega: The International Journal of Management Science 42(1): 25–32.</ref><ref>Gurbuz, T., S. E. Alptekin, et al. (2012). \"A hybrid MCDM methodology for ERP selection problem with interacting criteria.\" Decision Support Systems 54(1): 206–214.</ref><ref>Karande, P. and S. Chakraborty (2013). \"Using MACBETH method for supplier selection in manufacturing environment.\" International Journal of Industrial Engineering Computations 4: 259–272.</ref><ref>Khaled, A. and M. A. J. Idrissi (2012). \"A semi-structured tailoring-driven approach for ERP selection.\" International Journal of Computer Science Issues 9(5): 71–80.</ref><ref>Oliveira, R. C. and J. C. Lourenço (2002a). \"A multicriteria model for assigning new orders to service suppliers.\" European Journal of Operational Research 139(2): 390–399.</ref><ref>Shah, L. A., F. Vernadat, et al. (2013). Value-Risk Graph: A Decision-Making Tool for Supply Chain and Industrial System Engineering. Center for Information Technology Renato Archer, Fortaleza, Brazil, Management and Control of Production and Logistics. 6: 414–419.</ref><ref>Zamcopé, C. F., L. Ensslin, et al. (2010). \"Modelo para avaliar o desempenho de Operadores logísticos – Um estudo de caso na indústria textil.\" Gestão & Produção 17(4): 693–705.</ref>\n\n=== Energy===\n* Project prioritization and selection<ref>Bana e Costa, C. A., J. C. Lourenço, et al. (2008). \"Development of reusable bid evaluation models for the Portuguese Electric Transmission Company.\" Decision Analysis 5(1): 22–42.</ref><ref>Dias-Sardinha, I., J. Carolino, et al. (2013). REHMINE Project – Redevelopment of São Domingos Mine. Mértola, Portugal, School of Economics & Management.</ref>\n* Technology choice<ref>Barin, A., L. N. Canha, et al. (2012). Selection of hybrid renewable energy systems in landfills. Florence, 9th International Conference on the European Energy Market (EEM): 1–5.</ref><ref>Barin, A., L. F. Martins, et al. (2012). Fuelling the Future: Advances in Science and Technologies for Energy Generation, Transmission and Storage, Universal-Publishers.</ref><ref>Burton, J. and K. Hubacek (2007). \"Is small beautiful? A multicriteria assessment of small-scale energy technology applications in local governments.\" Energy Policy 35(12): 6402–6412.</ref><ref>Ertay, T. and C. Kahraman (2010). Evaluation of Renewable Energy Alternatives Using MACBETH Multicriteria Method. 9th International FLINS Conference on Foundations and Applications of Computational Intelligence, Chengdu, China: 937–943.</ref><ref>Fernandes, M. B., M. C. Almeida, et al. (2008). \"Assessing desalination as a sustainable alternative using a multiple criteria decision support model.\" Water Practice & Technology 3(3): 1–8.</ref><ref>Ferreira, J., M. D. Pinheiro, et al. (2014). \"Portuguese sustainable construction assessment tools benchmarked with BREEAM and LEED: An energy analysis.\" Energy and Buildings 69: 451–463.</ref><ref>Montignac, F. (2008). An MCDA approach for evaluating hydrogen storage systems for future vehicles.</ref><ref>Montignac, F., I. Noirot, et al. (2009). \"Multi-criteria evaluation of on-board hydrogen storage technologies using the MACBETH approach.\" International Journal of Hydrogen Energy 34(10): 4561–4568.</ref><ref>Wancura, H., R. Mubbala, et al. (2013). A Technology Monitoring and Assessment Tool for Technology Road Mapping. Lucerne, Switzerland, 4th European PEFC and H2 Forum: 1–5.</ref>\n\n=== Environment===\n* Landscape management<ref>Soguel, N., M. J. Martin, et al. (2008). \"The Impact of Housing Market Segmentation Between Tourists and Residents on the Hedonic Price for Landscape Quality.\" Swiss Journal of Economics and Statistics 144(IV): 655–678.</ref><ref>Tangerini, A., J. Pictet, et al. (2006). Using A MultiPLE criteria Decision Analysis approach for Landscape Quality Assessment, Chavannes-près-Renens, Chaire de Finances publiques.</ref>\n* Climate change<ref>Bana e Costa, C. A., L. Angulo-Meza, et al. (2013). \"O método MACBETH e aplicação no Brasil.\" Engevista 15(1): 3–27.</ref><ref>Cox, R., J. Sanchez, et al. (2013). \"Multi-Criteria Decision Analysis Tools for Prioritising Emerging or Re-Emerging Infectious Diseases Associated with Climate Change in Canada.\" PLoS ONE 8(8): 1–16.</ref>\n* Risk management<ref name=\"Bana e Costa 2000\"/><ref>Bana e Costa, C. A., C. S. Oliveira, et al. (2008). \"Prioritization of bridges and tunnels in earthquake risk mitigation using multicriteria decision analysis: Application to Lisbon.\" Omega 36(3): 442–450.</ref><ref>Dall'Osso, F., M. Gonella, et al. (2009). \"A revised (PTVA) model for assessing the vulnerability of buildings to tsunami damage.\" Natural Hazards and Earth System Sciences 9(5): 1557–1565.</ref><ref>Joerin, F., G. Cool, et al. (2010). \"Using multi-criteria decision analysis to assess the vulnerability of drinking water utilities.\" Environmental Monitoring and Assessment 166(1-4): 313–330.</ref><ref>Oliveira, C. S., M. A. Ferreira, et al. (2004). Seismic Vulnerability and Impact Analysis: Elements for Mitigation Policies. XI Congresso Nazionale \"L'ingegneria Sismica in Italia. Genova (29p.).</ref><ref>Silva, J. S. V. and C. A. Bana e Costa (2001). Especificação de uma ferramenta de apoio à decisão para gestão pública em regiões semi-áridas, CEG-IST, Technical University of Lisbon.</ref>\n* Sustainable development<ref>Romeiro, A. R., P. Bernasconi, et al. (2012). Assessment of existing and proposed policy instruments for biodiversity conservation in São Paulo – Brazil: A coarse grain analysis, POLICYMIX: 1–60.</ref><ref>Merad, M., N. Dechy, et al. (2013). \"Using a multi-criteria decision aid methodology to implement sustainable development principles within an organization.\" European Journal of Operational Research 224(3): 603–613.</ref>\n* Water resource management<ref name=\"Silva, P. 2000\">Antão da Silva, P., C. A. Bana e Costa, et al. (2000). Avaliação Multicritério das Incidências Ambientais de Medidas de Controlo de Cheias: Aplicação à Bacia Hidrográfica da Ribeira do Livramento. Trabalhos Técnicos do 1º Congresso sobre Aproveitamentos e Gestão de Recursos Hídricos em Países de Idioma Portu¬guês, Rio de Janeiro, Associação Brasileira de Engenharia Sanitária e Ambiental.</ref><ref name=\"Silva, P. 2000\"/><ref>Ba, F., C. Bouchard, et al. (2011). \"Analyse multicritère pour la priorisation des interventions en matière d'approvisionnement en eau en milieu rural au Sénégal: cas de la région de Diourbel.\" Revue des sciences de l'eau 24(1): 9–22.</ref><ref>Bana e Costa, C. A., P. An1 ao da Silva, et al. (2004). \"Multicriteria evaluation of flood control measures: The case of Ribeira do Livramento.\" Water Resources Management 18(3): 263–283.</ref>\n\n=== Medical===\n* Medical<ref>de Castro, A., P. R. Pinheiro, et al. (2009). An Approach for the Neuropsychological Diagnosis of Alzheimer's Disease: A Hybrid Model in Decision Making. Rough Sets and Knowledge Technology: 216–223.</ref><ref>de Castro, A., P. R. Pinheiro, et al. (2009). Towards the Neuropsychological Diagnosis of Alzheimer's Disease: A Hybrid Model in Decision Making. Best Practices for the Knowledge Society: Knowledge, Learning, Development and Technology for All, Springer-Verlag Berlin.</ref><ref>de Castro, A., P. R. Pinheiro, et al. (2011). Towards the Applied Hybrid Model in Decision Making: A Neuropsychological Diagnosis of Alzheimer's Disease Study Case. 4th International Conference on Rough Sets and Knowledge Technology Australia, Atlantis Press.</ref><ref>de Castro, A. K. A., P. R. Pinheiro, et al. (2008). A Multicriteria Model Applied in the Diagnosis of Alzheimer's Disease: A Bayesian Network. 11th IEEE International Conference on Computational Science and Engineering, São Paulo, Brazil.</ref><ref>Moraes, L., R. Garcia, et al. (2010). \"The Multicriteria Analysis for construction of Benchmarkers to Support the Clinical Engineering in the Healthcare Technology Management.\" European Journal of Operational Research 200(3): 607–615.</ref><ref>Lopes, D. F. (2013). Development of a multicriteria decision aiding model for monitoring and evaluating the performance of Health Care Units. Atas do XVI Congresso da Associação Portuguesa de Investigação Operacional, Bragan\\cca, Associação Portuguesa de Investigação Operacional.</ref><ref>Menezes, A. C., P. R. Pinheiro, et al. (2013). A hybrid model to support the diagnosis of disease: A case study for diabetes. Regina, Saskatchewan, Canada, 26th IEEE Canadian Conference Of Electrical And Computer Engineering (CCECE).</ref><ref>Nunes, L. C., P. R. Pinheiro, et al. (2009). An Expert System Applied to the Diagnosis of Psychological Disorders. IEEE International Conference on Intelligent Computing and Intelligent Systems. Shanghai, China: 363–367.</ref><ref>Nunes, L. C., P. R. Pinheiro, et al. (2010). Support tool in the diagnosis of major depressive disorder. 3rd World Summit on the Knowledge Society, WSKS (2) 2010. Corfu, Greece: 136–145.</ref><ref>Nunes, L. C., P. R. Pinheiro, et al. (2011). \"Toward an Application to Psychological Disorders Diagnosis.\" Software Tools and Algorithms for Biological Systems 696: 573–580.</ref><ref>Rodrigues, T., M. D. Oliveira, et al. (2011). Multicriteria model to allocate human resources in community care programmes. 1st Portuguese Meeting in Bioengineering (ENBENG), Lisbon, Bioengineering (ENBENG).</ref><ref name=\"Santos, F. A. 2012\">Santos, F. A., A. E. Margotti, et al. (2012). Multi-Criteria Decision Aid (MCDA) as a Tool to Support Health Technology Incorporation Process. World Congress on Medical Physics and Biomedical Engineering. Beijing, China, Springer Berlin Heidelberg. 39: 692–695.</ref>\n\n=== Military===\n* Military<ref>Bana e Costa, C. A. and M. S. Marques (2009). Procurement Decision Support for the Portuguese MoD: The MACBETH Approach and the Acquisition of 8x8 AWV. Decision Support Methodologies for Acquisition of Military Equipment, NATO Research and Technology Organisation, Brussels, Belgium (1–1, 1–14).</ref><ref>Bana e Costa, C. A. and J. F. Thomaz (2000). Locating centres of information and recruitment of volunteers for the Portuguese Armed Forces: A decision-analysis case-study. Proceedings of the 42nd Annual Conference of the International Military Testing Association, International Military Testing Association, Edinburgh.</ref><ref>Junior, A. G. M., T. J. M. Gon\\ccalves, et al. (2011). \"MACBETH Aplicado ao Cálculo da Pena Base do Direito Penal Militar.\" INGEPRO – Inovação, Gestão e Produção 3(1): 56–66.</ref><ref>Junior, H. V., K. H. Kienitz, et al. (2009). \"Metodologia de Apoio a Decisão para os Processos de Seleção de Alvos e Armamentos.\" Spectrum – Revista do Comando-Geral de Operações Aéreas 12: 25–27.</ref>\n\n=== Public sector===\n* Conflict analysis and management<ref>Bana e Costa, C. A. (2001). \"The use of multicriteria decision analysis to support the search for less conflicting policy options in a multi-actor context: Case-study.\" Journal of Multi-Criteria Decision Analysis 10(2): 111–125.</ref><ref>Bana e Costa, C. A., F. N. Silva, et al. (2001). \"Conflict dissolution in the public sector: A case-study.\" European Journal of Operational Research 130(2): 388–401.</ref><ref>Bollinger, D. and J. Pictet (2003). \"Potential Use of e-Democracy in MCDA Processes. Analysis on the Basis of a Swiss Case.\" Journal of Multi-Criteria Decision Analysis 12(2-3): 65–76.</ref><ref>Eklund, P., R. A., et al. (2008). \"A consensus model of political decision-making.\" Annals of Operations Research 158(1): 5–20.</ref><ref>Roubens, M., A. Rusinowska, et al. (2006). \"Using MACBETH to determine utilities of governments to parties in coalition formation.\" European Journal of Operational Research 172(2): 588–603.</ref><ref>Soguel, N. C. and F. Chatagny (2006). Analysing Municipalities Amalgamation and Collaboration through the Principle of Fiscal Equivalence and the Principal-Agent Model.</ref>\n* Project prioritization & resource allocation<ref>Abtahi, M. S. (2012). The Effectiveness in Distance Education for Iranian Higher Education. Procedia – Social and Behavioral Sciences. North Cyprus, Cyprus International Conference on Educational Research (CY-ICER). 47: 1315–1319.</ref><ref>Cuadrado, M. R. and M. G. Fernández (2013). \"Methodology to Select the Best Business Game in Higher Education.\" American Journal of Industrial and Business Management 3: 589–594.</ref>\n* Procurement<ref>Bana e Costa, C. A. (1999). \"O modelo de apoio à avaliação de propostas nos concursos do Metro do Porto.\" FER XXI XVIII: 111, 113–115.</ref><ref name=\"Bana e Costa 2002\">Bana e Costa, C. A. (2002). Issues in facilitating bid evaluation in public call for tenders. Proceedings of the 3rd International Conference on Decision Making in Urban and Civil Engineering, London, SOAS.</ref><ref name=\"Bana e Costa 2002\"/><ref>Bana e Costa, C. A. and E. C. Corrêa (1999). Framing public calls for tenders through a multicriteria approach. Proceedings of the 5th International Conference of the Decision Sciences Institute, Athens, Athens University of Business and Economics.</ref><ref>Bana e Costa, C. A. and J. A. Ferreira (1994). Concursos de obras públicas: Metodologia de avaliação de propostas. Aplicação a uma grande empreitada de infraestruturas de transportes. Actas do Congresso 94, Engenharia Portuguesa na Viragem do S\\'eculo. Lisbon, Ordem dos Engenheiros: 47-w/49.</ref><ref>Bana e Costa, C. A., J. A. Ferreira, et al. (1995). \"Avaliação multicritério de propostas: O caso de uma nova linha do Metropolitano de Lisboa.\" Revista de Transporte e Tecnologia VII(14): 31–65.</ref><ref>Bana e Costa, C. A., J. C. Lourenço, et al. (2006). Building MACBETH value-function models for bid evaluation at the Portuguese electric transmission company (REN). Proceedings of the 19th Mini EURO Conference on Operational Research Models and Methods in the Energy Sector, INESC Coimbra.</ref><ref>Lourenço, J. C. (2002). Apoio à Avaliação de Propostas no Concurso Limitado por Prévia Qualificação para a Realização dos Projectos de Especialidades (ao nível de projecto de execução) para a Construção do Parque de Estacionamento Subterrâneo na Praça D. Dinis em Coimbra, CEG-IST, Technical University of Lisbon.</ref><ref>Porto, J. L. (1999). \"Analyse multicrit\\`ere dans le cadre des appels d'offres pour la constrution de travaux publics et prives: Le cas du métro de Porto au Portugal.\" Newsletter of the European Working Group `Multiple Criteria Decision Aiding' Serie II(15): 1–2.</ref>\n* Project prioritization & resource allocation<ref name=\"Bana e Costa 1997\"/><ref>Bana e Costa, C. A., T. G. Fernandes, et al. (2006). \"Prioritisation of public investments in social infrastructures using multicriteria value analysis and decision conferencing: a case study.\" International Transactions in Operational Research 13(4): 279–297.</ref><ref>Bana e Costa, C. A. and R. C. Oliveira (2002). \"Assigning priorities for maintenance, repair and refurbishment in managing a municipal housing stock.\" European Journal of Operational Research 138(2): 380–391.</ref><ref name=\"Santos, F. A. 2012\"/><ref>Bana e Costa, C. A., R. C. Oliveira, et al. (1994). Concepção de um Sistema Multicritério de Definição de Prioridades de Intervenção/Conservação do Património Habitacional da Câmara Municipal de Lisboa. 2º ENCORE – Encontro sobre Conservação e Reabilitação de Edifícios, Comunicações LNEC, Laboratório Nacional de Engenharia Civil, Lisbon.</ref><ref>Bana e Costa, C. A. and J. C. Vansnick (1997). \"Applications of the MACBETH approach in the framework of an additive aggregation model.\" Journal of Multi-Criteria Decision Analysis 6(2): 107–114.</ref><ref>C3E, Ed. (1995). Applying the Multi-criteria Method to the Evaluation of Structural Programmes. Brussels, European Commission, DG XVI/02.</ref><ref>C3E, Ed. (1995). Evaluation Pilote Multicritere du Hainaut. Brussels, European Commission, DG XVI/02.</ref><ref>Mateus, R., J. A. Ferreira, et al. (2008). \"Multicriteria decision analysis (MCDA): Central Porto high-speed railway station.\" European Journal of Operational Research 187(1): 1–18.</ref><ref>Oliveira, M. D., T. C. Rodrigues, et al. (2011a). Prioritizing Health Care Interventions: A Multicriteria Resource Allocation Model to Inform the Choice of Community Care Programmes. 15º Congresso da Associação Portuguesa de Investigação Operacional, Coimbra, INESC: 177–186.</ref><ref>Oliveira, M. D., T. C. Rodrigues, et al. (2011b). Prioritizing Health Care Interventions: A Multicriteria Resource Allocation Model to Inform the Choice of Community Care Programmes. 37th International Conference on Operational Research Applied to Health Services, Cardiff: 255–265.</ref><ref>Oliveira, M. D., T. C. Rodrigues, et al. (2012). Prioritizing Health Care Interventions: A Multicriteria Resource Allocation Model to Inform the Choice of Community Care Programmes. Advanced Decision Making Methods Applied to Health Care, Springer: 139–152.</ref><ref>Sanchez, C. e., J. Montmain, et al. (2009). Planning of maintenance operations for a motorway operator based upon multicriteria evaluations over a finite scale and sensitivity analyses. Informatics in control, automation and robotics. Selected papers from the international conference on informatics in control, automation and robotics (INCINO 2007), Angers, France, May 9–12, 2007, Berlin: Springer.</ref><ref>Vieira, V., C. S. Oliveira, et al. (2000). A Methodology to Evaluate the Strategic Importance of Bridges and Tunnels Considering Seismic Vulnerability: Application to Lisbon. EuroConference on Global Change and Catastrophe Risk Management: Earthquake Risks in Europe, Laxenburg, Austria, IIASA (10 p.).</ref>\n* Strategic planning & development<ref name=\"Bana e Costa 1997\"/><ref>Bana e Costa, C. A., M. L. da Costa-Lobo, et al. (2002). Multicriteria approach for strategic town planning: The case of Barcelos. Aiding Decisions with Multiple Criteria. Essays in Honor of Bernard Roy, Kluwer Academic Publishers, Boston: 429–456.</ref><ref>Bana e Costa, C. A., M. T. Craveiro, et al. (2010). Avaliação Multicritério na Elaboração da Matriz Estratégica do Programa Local de Habitação de Lisboa. Proceedings do 54º IFHP World Congress, Porto Alegre, Brasil.</ref><ref>Bana e Costa, C. A., J. C. Lourenço, et al. (2009). Concepção de uma estratégia de desenvolvimento a médio prazo para Pernambuco. Actas do 15º Congresso da APDR – Associação Portuguesa para o Desenvolvimento Regional. Cabo Verde, APDR (1959–1681).</ref><ref>Bana e Costa, C. A., J. C. Lourenço, et al. (2013). \"A social-technical approach for group decision support in public strategic planning: The Pernambuco PPA case.\" Group Decision and Negotiation 23(1): 5–29.</ref><ref>Neves, A. R., J. C. Louren\\cco, et al. (2012). A Multi-criteria Approach to Local Energy Planning – The Case of Barreiro Municipality. Procedia – Social and Behavioral Sciences. Vilamoura, Algarve, Portugal, SciTePress: 313–320.</ref><ref>Vindigni, G., E. Caniglia, et al. (2010). Supporting Small Producers in Mexico's Economic Integration Process. A Case Study on Rural Michoacan Based on an MCDA Approach. 119th EAAE Seminar `Sustainability in the Food Sector: Rethinking the Relationship between the Agro-Food System and the Natural, Social, Economic and Institutional Environments', Capri, Italy.</ref>\n\n=== Others===\n* Human resource management<ref>Bana e Costa, C. A., P. A. F. Martins, et al. (2010). Faculty evaluation using multicriteria value measurement. Advances in Mathematical and Computational Methods – 12th WSEAS International Conference on Mathematical and Computational Methods in Science and Engineering (MACMESE '10). University of Algarve, Faro, Portugal, WSEAS Press.</ref><ref>Bana e Costa, C. A. and M. D. Oliveira (2011). \"A Multicriteria Decision Analysis Model for Faculty Evaluation.\" Omega: The International Journal of Management Science 40(4): 424–436.</ref><ref>Ensslin, L., A. Dutra, et al. (2000). \"MCDA: A constructivist approach to the management of human resources at a governmental agency.\" International Transactions in Operational Research 7(1): 79–100.</ref><ref>Ensslin, L. and S. Ensslin (1998). \"Elaboração de um modelo construtivista para identificação de oportunidades de aperfeiçoamento de docentes do EPS-UFSC.\" Revista Produto & Produção 2(3): 143–149.</ref><ref>Ensslin, S. R., L. Ensslin, et al. (2013). \"Improved decision aiding in human resource management: A case using constructivist multi-criteria decision aiding.\" International Journal of Productivity and Performance Management 62(7): 735–757.</ref><ref>Ensslin, L., G. N. Montibeller, et al. (2001). Apoio à Decisão: Metodologias para Estruturação de Problemas e Avaliação Multicritério de Alternativas. Florianópolis (SC), Editora Insular.</ref><ref>Filho, A. B., A. S. MarMarçal, et al. (2009). \"A Novel Approach Based on Staff Scheduling Optimization in Information Technology Projects.\" International Journal of Computer Science and Network Security 9(9): 277–286.</ref><ref>Gurbuz, T. (2010). \"Multiple Criteria Human Performance Evaluation Using Choquet Integral.\" International Journal of Computational Intelligence Systems 3(3): 290–300.</ref><ref>Leitão, M. A. L. S., J. F. Thomaz, et al. (2002). Multimethodology in practice: An application in the Portuguese army performance appraisal model. Proceedings of the 44th Annual Conference of the International Military Testing Association, IMTA. Ottawa, Canada: 511–527.</ref><ref>Leitão, M. A. L. S., J. F. Thomaz, et al. (2002). Using decision conferencing and process consultation to facilitate the structuring of a performance appraisal model in the Portuguese Army, CEG-IST, Technical University of Lisbon.</ref><ref>Thomaz, J. F. and C. A. Bana e Costa (2004). Decision conferencing within a multimethodological framework: Developing a performance appraisal model for the Portuguese Army officers. 46th Annual Conference of the International Military Testing Association (IMTA) & NATO's Research Task Group on Recruiting and Retention of Military Personnel, IMTA, Brussels, Belgium (13 p.).</ref>\n* Job selection<ref name=\"Bana3\" />\n* Sports<ref>Brando, L. C., F. V. S. Andrade, et al. (2013). 2012 UEFA Euro efficiency evaluation based on market expectations, Leuven, Belgium, 4th International Conference on Mathematics in Sport.</ref>\n\n== Decision support systems==\n\nSeveral [[decision support systems]] (DSS) implement the MACBETH approach, namely:\n* [[Decision-making software]] \n* [http://www.m-macbeth.com M-MACBETH],<ref name=\"Bana4\">Bana Consulting.  [http://www.m-macbeth.com/help/pdf/M-MACBETH%20User's%20Guide.pdf M-MACBETH Version 1.1:User's Guide]. 2005.</ref> \n* mini-MACBETH (within [http://www.catalyze.co.uk/index.php/software/hiview3/ HIVIEW3)] \n* [http://www.solidus.ca/macbeth.html CA-MACBETH]\n\n==References==\n{{Reflist}}\n\n{{DEFAULTSORT:Measuring Attractiveness by a Categorical Based Evaluation Technique (MACBETH)}}\n[[Category:Multiple-criteria decision analysis]]\n[[Category:Sampling (statistics)]]\n[[Category:Decision analysis]]\n[[Category:Design of experiments]]\n[[Category:Actuarial science]]\n[[Category:Single-equation methods (econometrics)]]\n[[Category:Regression models]]\n[[Category:Mathematical and quantitative methods (economics)]]\n[[Category:Mathematical optimization]]\n[[Category:Medical statistics]]\n[[Category:Clinical trials]]\n[[Category:Epidemiology]]\n[[Category:Utility]]"
    },
    {
      "title": "Minimax theorem",
      "url": "https://en.wikipedia.org/wiki/Minimax_theorem",
      "text": "A '''minimax theorem''' is a theorem providing conditions that guarantee that the [[max–min inequality]] is also an equality. \nThe first theorem in this sense is [[John von Neumann|von Neumann]]'s minimax theorem from 1928, which was considered the starting point of [[game theory]]. \nSince then, several generalizations and alternative versions of von Neumann's original theorem have appeared in the literature.<ref>{{cite book|editor1-last=Du|editor1-first=Ding-Zhu|editor2-last=Pardalos|editor2-first=Panos M.|title=Minimax and Applications|date=1995|publisher=Springer US|location=Boston, MA|isbn=9781461335573}}</ref><ref>{{Cite journal|last1=Brandt|first1=Felix|last2=Brill|first2=Markus|last3=Suksompong|first3=Warut|year=2016|title=An ordinal minimax theorem|url=http://www.sciencedirect.com/science/article/pii/S0899825615001670|journal=Games and Economic Behavior|volume=95|pages=107–112|doi=10.1016/j.geb.2015.12.010|arxiv=1412.4198}}</ref>\n\n== Zero-sum Games ==\nThe minimax theorem was first proven and published in 1928 by [[John von Neumann]],<ref>{{cite journal |last=Von Neumann |first=J. |title=Zur Theorie der Gesellschaftsspiele |journal=[[Mathematische Annalen|Math. Ann.]] |volume=100 |year=1928 |issue= |pages=295–320 |doi=10.1007/BF01448847 }}</ref> who is quoted as saying \"''As far as I can see, there could be no theory of games … without that theorem … I thought there was nothing worth publishing until the Minimax Theorem was proved''\".<ref name=Casti>{{cite book\n|author=John L Casti\n|title=Five golden rules: great theories of 20th-century mathematics – and why they matter\n|url=http://worldcat.org/isbn/0-471-00261-5\n|publisher=Wiley-Interscience\n|location=New York \n|year=1996\n|page=19\n|isbn=978-0-471-00261-1}}</ref>\n\nFormally, von Neumann's minimax theorem states:\n\nLet <math>X \\subset \\mathbb{R}^n</math> and <math>Y \\subset \\mathbb{R}^m</math> be [[compact space|compact]] [[Convex set|convex]] sets. If <math>f: X \\times Y \\rightarrow \\mathbb{R}</math> is a continuous function that is concave-convex, i.e.\n\n: <math>f(\\cdot,y):X\\rightarrow\\mathbb{R}</math> is concave for fixed <math>y</math>, and\n: <math>f(x,\\cdot):Y\\rightarrow\\mathbb{R}</math> is convex for fixed <math>x</math>.\n\nThen we have that\n\n: <math>\\max_{x\\in X}\\min_{y\\in Y} f(x,y)=\\min_{y\\in Y}\\max_{x\\in X}f(x,y).</math>\n\n== See also ==\n* [[Sion's minimax theorem]]\n* [[Parthasarathy's theorem]]\n*[[Dual linear program]] can be used to prove the minimax theorem for zero-sum games.\n\n== References ==\n{{Reflist}}\n\n[[Category:Game theory]]\n[[Category:Mathematical optimization]]\n[[Category:Mathematical theorems]]\n\n\n{{mathanalysis-stub}}\n{{gametheory-stub}}"
    },
    {
      "title": "Mixed complementarity problem",
      "url": "https://en.wikipedia.org/wiki/Mixed_complementarity_problem",
      "text": "'''Mixed Complementarity Problem''' ('''MCP''') is a problem formulation in [[mathematical programming]]. Many well-known problem types are special cases of, or may be reduced to MCP. It is a generalization of [[nonlinear complementarity problem]] (NCP).\n\n== Definition ==\nThe mixed complementarity problem is defined by a mapping <math>F(x): \\mathbb{R}^n \\to \\mathbb{R}^n</math>, lower values <math>\\ell_i \\in \\mathbb{R} \\cup \\{-\\infty\\}</math> and upper values <math>u_i \\in \\mathbb{R}\\cup\\{\\infty\\}</math>.\n\nThe '''solution''' of the MCP is a vector <math>x \\in \\mathbb{R}^n</math> such that for each index <math>i \\in \\{1, \\ldots, n\\}</math> one of the following alternatives holds:\n\n* <math>x_i = \\ell_i, \\; F_i(x) \\ge 0</math>;\n* <math>\\ell_i < x_i < u_i, \\; F_i(x) = 0</math>;\n* <math>x_i = u_i, \\; F_i(x) \\le 0</math>.\n\nAnother definition for MCP is: it is a [[variational inequality]] on the [[parallelepiped]] <math>[\\ell, u]</math>.\n\n== See also ==\n* [[Complementarity theory]]\n\n== References ==\n* {{cite paper|author=Stephen C. Billups|title=Algorithms for complementarity problems and generalized equations|date=1995|\nurl=ftp://ftp.cs.wisc.edu/math-prog/tech-reports/95-14.ps|\nformat=[[Adobe Photoshop|PS]]|accessdate=2006-08-14}}\n* {{cite book|author=Francisco Facchinei, Jong-Shi Pang|title=Finite-Dimensional Variational Inequalities and Complementarity Problems, Volume I|date=2003}}\n\n{{Mathematical programming}}\n\n[[Category:Mathematical optimization]]"
    },
    {
      "title": "Mixed linear complementarity problem",
      "url": "https://en.wikipedia.org/wiki/Mixed_linear_complementarity_problem",
      "text": "In mathematical [[optimization (mathematics)|optimization theory]], the '''mixed linear complementarity problem''', often abbreviated as '''MLCP''' or '''LMCP''', is a generalization of the [[linear complementarity problem]] to include [[free variables]].\n\n== References ==\n* [http://www.uclm.es/area/gsee/Web/Raquel/Complementarity_Problems.pdf Complementarity problems]\n* [ftp://ftp.cs.wisc.edu/math-prog/tech-reports/95-14.ps Algorithms for complementarity problems and generalized equations]\n* [http://www.mcs.anl.gov/~leyffer/listn/slides-07/morales.pdf An Algorithm for the Approximate and Fast Solution of Linear Complementarity Problems]\n\n{{Mathematical programming}}\n\n[[Category:Linear algebra]]\n[[Category:Mathematical optimization]]\n\n\n{{Linear-algebra-stub}}\n{{mathanalysis-stub}}"
    },
    {
      "title": "Multi-attribute global inference of quality",
      "url": "https://en.wikipedia.org/wiki/Multi-attribute_global_inference_of_quality",
      "text": "{{No footnotes|date=September 2011}}\n'''Multi-attribute global inference of quality''' ('''MAGIQ''') is a [[multi-criteria decision analysis]] technique. MAGIQ is based on a hierarchical decomposition of comparison attributes and rating assignment using rank order centroids.\n\n== Description ==\nThe MAGIQ technique is used to assign a single, overall measure of quality to each member of a set of systems where each system has an arbitrary number of comparison attributes. The MAGIQ technique has features similar to the [[analytic hierarchy process]] and the simple multi-attribute rating technique exploiting ranks (SMARTER) technique. The MAGIQ technique was first published by [[James D. McCaffrey]]. The MAGIQ process begins with an evaluator determining which system attributes are to be used as the basis for system comparison. These attributes are ranked by importance to the particular problem domain, and the ranks are converted to ratings using rank order centroids. Each system under analysis is ranked against each comparison attribute and the ranks are transformed into rank order centroids. The final overall quality metric for each system is the weighted (by comparison attribute importance) sum of each attribute rating. The references provide specific examples of the process. There is little direct research on the theoretical soundness and effectiveness of the MAGIQ technique as a whole, however the use of hierarchical decomposition and the use of rank order centroids in multi-criteria decision analyses have been studied, with generally positive results. Anecdotal evidence suggests that the MAGIQ technique is both practical and useful.\n\n== See also ==\n* [[Multi-attribute utility]]\n\n== References ==\n<!--- See [[Wikipedia:Footnotes]] on how to create references using <ref></ref> tags which will then appear here automatically -->\n{{Reflist|30em}}\n\n==Sources==\n* Edwards, W. and Barron, F.H. \"SMARTS and SMARTER: Improved Simple Methods for Multiattribute Utility Measurement\", Organizational Behavior and Human Decision Processes, 60, (1994), pp.&nbsp;306&ndash;25.\n* Jia, Jianmin, Fischer, Gregory W., and Dyer, James S. \"Attribute Weighting Methods and Decision Quality in the Presence of Response Error: A Simulation Study\", Journal of Behavioral Decision Making (in press).\n* McCaffrey, James. \"The Analytic Hierarchy Process\", MSDN Magazine, June 2005 (Vol. 20, No. 6), pp.&nbsp;139&ndash;144. See [http://msdn2.microsoft.com/en-us/magazine/cc163785.aspx].\n* McCaffrey, James. \"Multi-Attribute Global Inference of Quality (MAGIQ)\", Software Test and Performance Magazine, August 2005 (Vol. 2, No. 7), pp.&nbsp;28&ndash;32.\n* McCaffrey, James, and Koski, Nasa. \"Competitive Analysis Using MAGIQ\", MSDN Magazine, October 2006 (Vol. 21, No. 11), pp.&nbsp;35&ndash;39. See [http://msdn2.microsoft.com/en-us/magazine/cc300812.aspx].\n\n[[Category:Group decision-making]]\n[[Category:Multiple-criteria decision analysis]]\n[[Category:Sampling (statistics)]]\n[[Category:Decision analysis]]\n[[Category:Design of experiments]]\n[[Category:Actuarial science]]\n[[Category:Single-equation methods (econometrics)]]\n[[Category:Regression models]]\n[[Category:Mathematical and quantitative methods (economics)]]\n[[Category:Mathematical optimization]]\n[[Category:Parametric statistics]]"
    },
    {
      "title": "Multiple-criteria decision analysis",
      "url": "https://en.wikipedia.org/wiki/Multiple-criteria_decision_analysis",
      "text": "{{redirect|MCDM|the use in cosmology|Meta-cold dark matter}}\n{{See also|Multi-objective optimization}}\n\n[[Image:Pareto Efficient Frontier for the Markowitz Portfolio selection problem..png|thumb|right|200px|Plot of two criteria when maximizing return and minimizing risk in [[Portfolio (finance)|financial portfolios]] (Pareto-optimal points in red)]]\n'''Multiple-criteria decision-making''' ('''MCDM''') or '''multiple-criteria decision analysis''' ('''MCDA''') is a sub-discipline of [[operations research]] that explicitly evaluates multiple conflicting [[wikt:criterion|criteria]] in [[decision making]] (both in daily life and in settings such as business, government and medicine).  Conflicting criteria are typical in evaluating options: [[cost]] or price is usually one of the main criteria, and some measure of quality is typically another criterion, easily in conflict with the cost.  In purchasing a car, cost, comfort, safety, and fuel economy may be some of the main criteria we consider – it is unusual that the cheapest car is the most comfortable and the safest one.  In [[Investment management|portfolio management]], we are interested in getting high returns but at the same time reducing our risks, but the stocks that have the potential of bringing high returns typically also carry high risks of losing money.  In a service industry, customer satisfaction and the cost of providing service are fundamental conflicting criteria.<ref>Madurika, HKGM, & Hemakumara, GPTS. (2015). Gis Based Analysis For Suitability Location Finding In The Residential Development Areas Of Greater Matara Region. International Journal of Scientific & Technology Research, 4(8), 96-105.</ref>\n\nIn our daily lives, we usually weigh multiple criteria implicitly and we may be comfortable with the consequences of such decisions that are made based on only [[Intuition (psychology)|intuition]].<ref>{{cite journal| author=Rew, L.| year=1988| title=Intuition in Decision‐making| journal=Journal of Nursing Scholarship| volume=20| pages=150–154| number=3| doi=10.1111/j.1547-5069.1988.tb00056.x}}</ref> On the other hand, when stakes are high, it is important to properly structure the problem and explicitly evaluate multiple criteria.{{Citation needed|date=March 2016}} In making the decision of whether to build a nuclear power plant or not, and where to build it, there are not only very complex issues involving multiple criteria, but there are also multiple parties who are deeply affected by the consequences.\n\nStructuring complex problems well and considering multiple criteria explicitly leads to more informed and better decisions.  There have been important advances in this field since the start of the modern multiple-criteria decision-making discipline in the early 1960s. A variety of approaches and methods, many implemented by specialized [[decision-making software]],<ref name=\"Weistrofferetal\">Weistroffer, H. R., Smith, C. H., and Narula, S. C., \"Multiple criteria decision support software\", Ch 24 in: Figueira, J., Greco, S., and Ehrgott, M., eds, ''Multiple Criteria Decision Analysis: State of the Art Surveys Series'', Springer: New York, 2005.</ref><ref name=\"orms\">{{citation |author=McGinley, P. |title=Decision analysis software survey |url=http://www.orms-today.org/surveys/das/das.html |work=OR/MS Today |year=2012 |volume=39 |deadurl=no |archiveurl=https://web.archive.org/web/20130328035733/http://www.orms-today.org/surveys/das/das.html |archivedate=28 March 2013 |df=dmy-all }}.</ref> have been developed for their application in an array of disciplines, ranging from politics and business to the environment and energy.<ref>{{cite journal|title=Multicriteria analysis for the selection of the most appropriate energy crops: the case of Cyprus|journal=Angeliki Kylili, Elias Christoforou, Paris A. Fokaides, Polycarpos Polycarpou|volume=35|pages=47–58|doi=10.1080/14786451.2014.898640|year=2016|last1=Kylili|first1=Angeliki|last2=Christoforou|first2=Elias|last3=Fokaides|first3=Paris A.|last4=Polycarpou|first4=Polycarpos}}</ref>\n\n==Foundations, concepts, definitions==\n\nMCDM or MCDA are well-known acronyms for ''multiple-criteria decision-making'' and ''multiple-criteria decision analysis''; Stanley Zionts helped popularizing the acronym with his 1979 article \"MCDM – If not a Roman Numeral, then What?\", intended for an entrepreneurial audience. \n\nMCDM is concerned with structuring and solving decision and planning problems involving multiple criteria. The purpose is to support decision-makers facing such problems. Typically, there does not exist a unique [[optimum|optimal]] solution for such problems and it is necessary to use decision-maker's preferences to differentiate between solutions.\n\n\"Solving\" can be interpreted in different ways. It could correspond to choosing the \"best\" alternative from a set of available alternatives (where \"best\" can be interpreted as \"the most preferred alternative\" of a decision-maker).  Another interpretation of \"solving\" could be choosing a small set of good alternatives, or grouping alternatives into different preference sets. An extreme interpretation could be to find all \"efficient\" or \"[[nondominated]]\" alternatives (which we will define shortly).\n\t\nThe difficulty of the problem originates from the presence of more than one criterion. There is no longer a unique optimal solution to an MCDM problem that can be obtained without incorporating preference information. The concept of an optimal solution is often replaced by the set of nondominated solutions. A nondominated solution has the property that it is not possible to move away from it to any other solution without sacrificing in at least one criterion.  Therefore, it makes sense for the decision-maker to choose a solution from the nondominated set. Otherwise, she/he could do better in terms of some or all of the criteria, and not do worse in any of them. Generally, however, the set of nondominated solutions is too large to be presented to the decision-maker for the final choice. Hence we need tools that help the decision-maker focus on the preferred solutions (or alternatives). Normally one has to \"tradeoff\" certain criteria for others.\n\nMCDM has been an active area of research since the 1970s. There are several MCDM-related organizations including the International Society on Multi-criteria Decision Making,<ref>{{cite web|url=http://www.mcdmsociety.org/|title=Multiple Criteria Decision Making – International Society on MCDM|author=|date=|website=www.mcdmsociety.org|accessdate=26 April 2018|deadurl=no|archiveurl=https://web.archive.org/web/20171003052248/http://www.mcdmsociety.org/|archivedate=3 October 2017|df=dmy-all}}</ref> Euro Working Group on MCDA,<ref>{{cite web|url=http://www.cs.put.poznan.pl/ewgmcda/|title=Welcome to EWG-MCDA website|author=|date=|website=www.cs.put.poznan.pl|accessdate=26 April 2018|deadurl=no|archiveurl=https://web.archive.org/web/20171007035425/http://www.cs.put.poznan.pl/ewgmcda/|archivedate=7 October 2017|df=dmy-all}}</ref> and INFORMS Section on MCDM.<ref>{{cite web |url=http://www.informs.org/Community/MCDM/ |title=Archived copy |accessdate=2011-08-07 |deadurl=no |archiveurl=https://web.archive.org/web/20110811111549/http://www.informs.org/Community/MCDM |archivedate=11 August 2011 |df=dmy-all }}</ref>  For a history see: Köksalan, Wallenius and Zionts (2011).<ref name=\"Multiple Criteria Decision Making: From Early History to the 21st Century\">{{cite book|last=Köksalan, M., Wallenius, J., and Zionts, S.|title=Multiple Criteria Decision Making: From Early History to the 21st Century|year=2011|publisher=World Scientific|location=Singapore}}</ref>\nMCDM draws upon knowledge in many fields including:\n\n* [[Mathematics]]\n* [[Decision analysis]]\n* [[Economics]]\n* [[Computer technology]]\n* [[Software engineering]]\n* [[Information systems]]\n\n===A typology===\n\nThere are different classifications of MCDM problems and methods.  A major distinction between MCDM problems is based on whether the solutions are explicitly or implicitly defined.\n\n* ''Multiple-criteria evaluation problems'': These problems consist of a finite number of alternatives, explicitly known in the beginning of the solution process.  Each alternative is represented by its performance in multiple criteria.  The problem may be defined as finding the best alternative for a decision-maker (DM), or finding a set of good alternatives.  One may also be interested in \"sorting\" or \"classifying\" alternatives.  Sorting refers to placing alternatives in a set of preference-ordered classes (such as assigning credit-ratings to countries), and classifying refers to assigning alternatives to non-ordered sets (such as diagnosing patients based on their symptoms). Some of the MCDM methods in this category have been studied in a comparative manner in the book by Triantaphyllou on this subject, 2000.<ref name='MCDMbook'>{{cite book | last = Triantaphyllou | first = E. | title = Multi-Criteria Decision Making: A Comparative Study | publisher = Kluwer Academic Publishers (now Springer) | year = 2000 | location = Dordrecht, The Netherlands | page = 320 | url = http://www.csc.lsu.edu/trianta/Books/DecisionMaking1/Book1.htm | doi =  | id =  | isbn = 978-0-7923-6607-2 | deadurl = no | archiveurl = https://web.archive.org/web/20100624022632/http://csc.lsu.edu/trianta/Books/DecisionMaking1/Book1.htm | archivedate = 24 June 2010 | df = dmy-all }}</ref>\n* ''Multiple-criteria design problems (multiple objective mathematical programming problems)'':  In these problems, the alternatives are not explicitly known. An alternative (solution) can be found by solving a mathematical model.  The number of alternatives is either infinite and not countable (when some variables are continuous) or typically very large if countable (when all variables are discrete).\n\nWhether it is an evaluation problem or a design problem, preference information of DMs is required in order to differentiate between solutions.  The solution methods for MCDM problems are commonly classified based on the timing of preference information obtained from the DM.\n\nThere are methods that require the DM's preference information at the start of the process, transforming the problem into essentially a single criterion problem.  These methods are said to operate by \"prior articulation of preferences\".  Methods based on estimating a value function or using the concept of \"outranking relations\", analytical hierarchy process, and some decision rule-based methods try to solve multiple criteria evaluation problems utilizing prior articulation of preferences.  Similarly, there are methods developed to solve multiple-criteria design problems using prior articulation of preferences by constructing a value function.  Perhaps the most well-known of these methods is goal programming.  Once the value function is constructed, the resulting single objective mathematical program is solved to obtain a preferred solution.\n\nSome methods require preference information from the DM throughout the solution process.  These are referred to as interactive methods or methods that require \"progressive articulation of preferences\". These methods have been well-developed for both the multiple criteria evaluation (see for example Geoffrion, Dyer and Feinberg, 1972,<ref>An Interactive Approach for Multi-Criterion Optimization, with an Application to the Operation of an Academic Department,\nA. M. Geoffrion, J. S. Dyer and A. Feinberg,\nManagement Science,\nVol. 19, No. 4, Application Series, Part 1 (Dec., 1972), pp. 357–368\nPublished by: INFORMS</ref> and Köksalan and Sagala, 1995<ref>{{cite journal|last=Köksalan, M.M. and Sagala, P.N.S.|title=Interactive Approaches for Discrete Alternative Multiple Criteria Decision Making with Monotone Utility Functions|journal=Management Science|year=1995|volume=41|pages=1158–1171|doi=10.1287/mnsc.41.7.1158|first1=M. M.|last2=Sagala|first2=P. N. S.|issue=7}}</ref> ) and design problems (see Steuer, 1986<ref>{{cite book|last=Steuer, R.E.|title=Multiple Criteria Optimization: Theory, Computation and Application|year=1986|publisher=John Wiley|location=New York}}</ref>).\n\nMultiple-criteria design problems typically require the solution of a series of mathematical programming models in order to reveal implicitly defined solutions.  For these problems, a representation or approximation of \"efficient solutions\" may also be of interest.  This category is referred to as \"posterior articulation of preferences\", implying that the DM's involvement starts posterior to the explicit revelation of \"interesting\" solutions (see for example Karasakal and Köksalan, 2009<ref>{{cite journal|last=Karasakal, E. K. and Köksalan, M.|title=Generating a Representative Subset of the Efficient Frontier in Multiple Criteria Decision Making|journal=Operations Research|year=2009|volume=57|pages=187–199|doi=10.1287/opre.1080.0581|first1=E.|last2=Koksalan|first2=M.}}</ref>).\n\nWhen the mathematical programming models contain integer variables, the design problems become harder to solve.  Multiobjective Combinatorial Optimization (MOCO) constitutes a special category of such problems posing substantial computational difficulty (see Ehrgott and Gandibleux,<ref>{{cite journal|author1=Ehrgott, M.  |author2=Gandibleux, X. |lastauthoramp=yes |title=Multiobjective Combinatorial Optimization|year=2002|series=Multiple Criteria Optimization, State of the Art Annotated Bibliographic Surveys|pages=369–444}}</ref> 2002, for a review).\n\n===Representations and definitions===\n\nThe MCDM problem can be represented in the criterion space or the decision space.  Alternatively, if different criteria are combined by a weighted linear function, it is also possible to represent the problem in the weight space.  Below are the demonstrations of the criterion and weight spaces as well as some formal definitions.\n\n====Criterion space representation====\n\nLet us assume that we evaluate solutions in a specific problem situation using several criteria.  Let us further assume that more is better in each criterion.  Then, among all possible solutions, we are ideally interested in those solutions that perform well in all considered criteria.  However, it is unlikely to have a single solution that performs well in all considered criteria.  Typically, some solutions perform well in some criteria and some perform well in others.  Finding a way of trading off between criteria is one of the main endeavors in the MCDM literature.\n\nMathematically, the MCDM problem corresponding to the above arguments can be represented as\n\n::{{math|\"max\" <var>'''q'''</var>}}\n\n:: subject to\n\n:::{{math|'''q''' ∈ '''Q'''}}\n\nwhere {{math|'''q'''}} is the vector of ''k'' criterion functions (objective functions) and {{math|'''Q'''}} is the feasible set, {{math|'''Q''' ⊆ '''R'''<sup>''k''</sup>}}.\n\nIf {{math|'''Q'''}} is defined explicitly (by a set of alternatives), the resulting problem is called a multiple-criteria evaluation problem.\n\nIf {{math|'''Q'''}} is defined implicitly (by a set of constraints), the resulting problem is called a multiple-criteria design problem.\n\nThe quotation marks are used to indicate that the maximization of a vector is not a well-defined mathematical operation.  This corresponds to the argument that we will have to find a way to resolve the trade-off between criteria (typically based on the preferences of a decision maker) when a solution that performs well in all criteria does not exist.\n\n====Decision space representation====\n\nThe decision space corresponds to the set of possible decisions that are available to us.  The criteria values will be consequences of the decisions we make.  Hence, we can define a corresponding problem in the decision space.  For example, in designing a product, we decide on the design parameters (decision variables) each of which affects the performance measures (criteria) with which we evaluate our product.\n\nMathematically, a multiple-criteria design problem can be represented in the decision space as follows:\n\n: <math>\n\\begin{align}\n\\max q & = f(x) = f(x_1,\\ldots,x_n) \\\\\n\\text{subject to} \\\\\nq\\in Q & = \\{f(x) : x\\in X,\\, X\\subseteq \\mathbb R^n\\}\n\\end{align}\n</math>\n\nwhere {{math|<var>'''X'''</var>}} is the feasible set and {{math|<var>'''x'''</var>}} is the decision variable vector of size n.\n\nA well-developed special case is obtained when {{math|<var>'''X'''</var>}} is a polyhedron defined by linear inequalities and equalities. If all the objective functions are linear in terms of the decision variables, this variation leads to multiple objective linear programming (MOLP), an important subclass of MCDM problems.\n\nThere are several definitions that are central in MCDM.  Two closely related definitions are those of nondominance (defined based on the criterion space representation) and efficiency (defined based on the decision variable representation).\n\n''Definition 1.''  {{math|'''q*''' ∈ '''Q'''}} is nondominated if there does not exist another {{math|'''q''' ∈ '''Q'''}} such that {{math|'''q''' ≥ '''q*'''}} and {{math|'''q''' ≠ '''q*'''}}.\n\nRoughly speaking, a solution is nondominated so long as it is not inferior to any other available solution in all the considered criteria.\n\n''Definition 2.''  {{math|'''x*''' ∈ '''X'''}} is efficient if there does not exist another {{math|'''x''' ∈ '''X'''}} such that {{math|'''f'''('''x''') ≥ '''f'''('''x'''*)}} and {{math|'''f'''('''x''') ≠ '''f'''('''x'''*)}}.\n\nIf an MCDM problem represents a decision situation well, then the most preferred solution of a DM has to be an efficient solution in the decision space, and its image is a nondominated point in the criterion space.  Following definitions are also important.\n\n''Definition 3.''  {{math|'''q*''' ∈ '''Q'''}} is weakly nondominated if there does not exist another {{math|'''q''' ∈ '''Q'''}} such that {{math|'''q''' > '''q*'''}}.\n\n''Definition 4.''  {{math|'''x*''' ∈ '''X'''}} is weakly efficient if there does not exist another {{math|'''x''' ∈ '''X'''}} such that {{math|<var>'''f'''('''x''') > '''f'''('''x'''*)}}.\n\nWeakly nondominated points include all nondominated points and some special dominated points.  The importance of these special dominated points comes from the fact that they commonly appear in practice and special care is necessary to distinguish them from nondominated points.  If, for example, we maximize a single objective, we may end up with a weakly nondominated point that is dominated. The dominated points of the weakly nondominated set are located either on vertical or horizontal planes (hyperplanes) in the criterion space.\n\n''Ideal point'': (in criterion space) represents the best (the maximum for maximization problems and the minimum for minimization problems) of each objective function and typically corresponds to an infeasible solution.\n\n''Nadir point'': (in criterion space) represents the worst  (the minimum for maximization problems and the maximum for minimization problems) of each objective function among the points in the nondominated set and is typically a dominated point.\n\nThe ideal point and the nadir point are useful to the DM to get the \"feel\" of the range of solutions (although it is not straightforward to find the nadir point for design problems having more than two criteria).\n\n====Illustrations of the decision and criterion spaces====\n\nThe following two-variable MOLP problem in the decision variable space will help demonstrate some of the key concepts graphically.\n\n[[File:MCDMFigure1.png|thumb|Figure 1. Demonstration of the decision space\n]]\n\n: <math>\n\\begin{align}\n\\max f_1(\\mathbf{x}) & = -x_1 + 2x_2 \\\\\n\\max f_2(\\mathbf{x}) & = 2x_1 - x_2 \\\\\n\\text{subject to} \\\\\nx_1 & \\le 4 \\\\\nx_2 & \\le 4 \\\\\nx_1+x_2 & \\le 7 \\\\\n-x_1+x_2 & \\le 3 \\\\\nx_1 - x_2 & \\le 3 \\\\\nx_1, x_2 & \\ge 0\n\\end{align}\n</math>\n\t\nIn Figure 1, the extreme points \"e\" and \"b\" maximize the first and second objectives, respectively. The red boundary between those two extreme points represents the efficient set. It can be seen from the figure that, for any feasible solution outside the efficient set, it is possible to improve both objectives by some points on the efficient set. Conversely, for any point on the efficient set, it is not possible to improve both objectives by moving to any other feasible solution.  At these solutions, one has to sacrifice from one of the objectives in order to improve the other objective.\n\nDue to its simplicity, the above problem can be represented in criterion space by replacing the {{math| <var>x</var>'s}} with the {{math| <var>f</var> 's}} as follows:\n\n[[File:MCDMFigure2.png|thumb|Figure 2. Demonstration of the solutions in the criterion space]]\n\n::{{math|Max <var>f<sub>1</sub></var>}}\n\n::{{math|Max <var>f<sub>2</sub></var>}}\n\n:: subject to\n\n:::{{math| ''f''<sub>1</sub> + 2''f''<sub>2</sub> ≤ 12}}\n\n:::{{math| 2''f''<sub>1</sub> + ''f''<sub>2</sub> ≤ 12}}\n\n:::{{math| ''f''<sub>1</sub> + ''f''<sub>2</sub> ≤ 7}}\n\n:::{{math| ''f''<sub>1</sub> – ''f''<sub>2</sub> ≤ 9}}\n\n:::{{math| −''f''<sub>1</sub> + ''f''<sub>2</sub> ≤ 9}}\n\n:::{{math| ''f''<sub>1</sub> + 2''f''<sub>2</sub> ≥ 0}}\n\n:::{{math| 2''f''<sub>1</sub> + ''f''<sub>2</sub> ≥ 0}}\n\nWe present the criterion space graphically in Figure 2.  It is easier to detect the nondominated points (corresponding to efficient solutions in the decision space) in the criterion space. The north-east region of the feasible space constitutes the set of nondominated points (for maximization problems).\n\n===Generating nondominated solutions===\n\nThere are several ways to generate nondominated solutions.  We will discuss two of these.  The first approach can generate a special class of nondominated solutions whereas the second approach can generate any nondominated solution.\n\n* ''Weighted sums'' (Gass & Saaty, 1955<ref>{{cite journal|last=Gass|first=S.|author2=Saaty, T.|title=Parametric Objective Function Part II|journal=Operations Research|year=1955|volume=3|issue=3|pages=316–319|doi=10.1287/opre.2.3.316 }}</ref>)\n\nIf we combine the multiple criteria into a single criterion by multiplying each criterion with a positive weight and summing up the weighted criteria, then the solution to the resulting single criterion problem is a special efficient solution.  These special efficient solutions appear at  corner points of the set of available solutions.  Efficient solutions that are not at corner points have special characteristics and this method is not capable of finding such points.  Mathematically, we can represent this situation as\n\n::{{math|max <var> '''w'''<sup>T</sup>.'''q'''</var>}} = {{math|<var> '''w'''<sup>T</sup>.'''f(x)''', '''w'''> </var>0}}\n\n:: subject to\n\n:::{{math|'''x''' ∈ '''X'''}}\n\nBy varying the weights, weighted sums can be used for generating efficient extreme point solutions for design problems, and supported (convex nondominated) points for evaluation problems.\n\n* ''Achievement scalarizing function'' (Wierzbicki, 1980<ref>{{cite book|last=Wierzbicki|first=A.|title=The Use of Reference Objectives in Multiobjective Optimization|journal=Lecture Notes in Economics and Mathematical Systems|year=1980|volume=177|series=Springer, Berlin|pages=468–486|doi=10.1007/978-3-642-48782-8_32|isbn=978-3-540-09963-5}}</ref>)\n\n[[File:MCDMFigure3.png|thumb|Figure 3. Projecting points onto the nondominated set with an Achievement Scalarizing Function]]\n\nAchievement scalarizing functions also combine multiple criteria into a single criterion by weighting them in a very special way.  They create rectangular contours going away from a reference point towards the available efficient solutions.  This special structure empower achievement scalarizing functions to reach any efficient solution.  This is a powerful property that makes these functions very useful for MCDM problems.\n\nMathematically, we can represent the corresponding problem as\n\n::{{math|Min ''s''('''g, q, w,''' ''ρ'')}} =  {{math|Min  {max<sub>''i''</sub> [(''g''<sub>''i''</sub> − ''q''<sub>''i''</sub>)/''w''<sub>''i''</sub> ] + ''ρ'' ∑<sub>''i''</sub> (''g''<sub>''i''</sub> − ''q''<sub>''i''</sub>)}}},\t\n\n::subject to\n\n:::{{math|'''q''' ∈ '''Q'''}}\n\nThe achievement scalarizing function can be used to project any point (feasible or infeasible) on the efficient frontier. Any point (supported or not) can be reached. The second term in the objective function is required to avoid generating inefficient solutions. Figure 3 demonstrates how a feasible point, {{math|'''g'''<sub>'''1'''</sub>}}, and an infeasible point, {{math|'''g'''<sub>'''2'''</sub>}}, are projected onto the nondominated points, {{math|'''q'''<sub>'''1'''</sub>}} and {{math|<var>'''q'''<sub>'''2'''</sub></var>}}, respectively, along the direction {{math|<var>'''w'''</var>}} using an achievement scalarizing function.  The dashed and solid contours correspond to the objective function contours with and without the second term of the objective function, respectively.\n\n===Solving MCDM problems===\n\nDifferent schools of thought have developed for solving MCDM problems (both of the design and evaluation type). For a bibliometric study showing their development over time, see Bragge, Korhonen, H. Wallenius and J. Wallenius [2010].<ref>{{cite book|last=Bragge|first=J. |author2=Korhonen, P. |author3=Wallenius, H. |author4=Wallenius, J.|title=Bibliometric Analysis of Multiple Criteria Decision Making/Multiattribute Utility Theory|journal=IXX International MCDM Conference Proceedings, (Eds.) M. Ehrgott, B. Naujoks, T. Stewart, and J. Wallenius|year=2010|volume=634|series=Springer, Berlin|pages=259–268|doi=10.1007/978-3-642-04045-0_22|isbn=978-3-642-04044-3 }}</ref>\n\n'''''Multiple objective mathematical programming school'''''\n\n(1) ''Vector maximization'': The purpose of vector maximization is to approximate the nondominated set; originally developed for Multiple Objective Linear Programming problems (Evans and Steuer, 1973;<ref>{{cite journal|last=Evans|first=J.|author2=Steuer, R.|title=A Revised Simplex Method for Linear Multiple Objective Programs|journal=Mathematical Programming|year=1973|volume=5|pages=54–72|doi=10.1007/BF01580111}}</ref> Yu and Zeleny, 1975<ref>{{cite journal|last=Yu|first=P.L.|author2=Zeleny, M.|title=The Set of All Non-Dominated Solutions in Linear Cases and a Multicriteria Simplex Method|journal=Journal of Mathematical Analysis and Applications|year=1975|volume=49|pages=430–468|doi=10.1016/0022-247X(75)90189-4|issue=2}}</ref>).\n\n(2) ''Interactive programming'': Phases of computation alternate with phases of decision-making (Benayoun et al., 1971;<ref>{{cite journal|last=Benayoun|first=R.|author2=deMontgolfier, J. |author3=Tergny, J. |author4=Larichev, O. |title=Linear Programming with Multiple Objective Functions: Step-method (STEM)|year=1971|volume=1|pages=366–375 |doi=10.1007/bf01584098 |journal=Mathematical Programming}}</ref> Geoffrion, Dyer and Feinberg, 1972;<ref>{{cite journal|last=Geoffrion|first=A. |author2=Dyer, J. |author3=Feinberg, A.|title=An Interactive Approach for Multicriterion Optimization with an Application to the Operation of an Academic Department|journal=Management Science|year=1972|volume=19|pages=357–368|doi=10.1287/mnsc.19.4.357|issue=4–Part–1}}</ref> Zionts and Wallenius, 1976;<ref>{{cite journal|last=Zionts|first=S.|author2=Wallenius, J.|title=An Interactive Programming Method for Solving the Multiple Criteria Problem|journal=Management Science|year=1976|volume=22|pages=652–663|doi=10.1287/mnsc.22.6.652|issue=6}}</ref> Korhonen and Wallenius, 1988<ref>{{cite journal|last=Korhonen|first=P.|author2=Wallenius, J.|title=A Pareto Race|journal=Naval Research Logistics|volume=35|pages=615–623|doi=10.1002/1520-6750(198812)35:6<615::AID-NAV3220350608>3.0.CO;2-K|year=1988|issue=6}}</ref>). No explicit knowledge of the DM's value function is assumed.\n\n'''''[[Goal programming|Goal programming school]]'''''\n\nThe purpose is to set apriori target values for goals, and to minimize weighted deviations from these goals. Both importance weights as well as lexicographic pre-emptive weights have been used (Charnes and Cooper, 1961<ref>{{cite book|last=Charnes, A. and [[William W. Cooper|Cooper, W.W.]]|title=Management Models and Industrial Applications of Linear Programming|year=1961|publisher=Wiley|location=New York}}</ref>).\n\n'''''Fuzzy-set theorists'''''\n\nFuzzy sets were introduced by Zadeh (1965)<ref>{{cite journal|last=Zadeh|first=L.|title=Fuzzy Sets|journal=Information and Control|year=1965|volume=8|pages=338–353|doi=10.1016/S0019-9958(65)90241-X|issue=3}}</ref> as an extension of the classical notion of sets. This idea is used in many MCDM algorithms to model and solve fuzzy problems.\n\n'''''Multi-attribute utility theorists'''''\n\n[[Multi-attribute utility]] or value functions are elicited and used to identify the most preferred alternative or to rank order the alternatives. Elaborate interview techniques, which exist for eliciting linear additive utility functions and multiplicative nonlinear utility functions, are used (Keeney and Raiffa, 1976<ref>{{cite book|author1=Keeney, R.  |author2=Raiffa, H. |lastauthoramp=yes |title=Decisions with Multiple Objectives: Preferences and Value Tradeoffs|year=1976|publisher=Wiley|location=New York}}</ref>).\n\n'''''French school'''''\n\nThe French school focuses on decision aiding, in particular the [[ELECTRE]] family of outranking methods that originated in France during the mid-1960s. The method was first proposed by Bernard Roy (Roy, 1968<ref>{{cite journal|last=Roy|first=B.|title=La méthode ELECTRE|journal=Revue d'Informatique et de Recherche Opérationelle (RIRO)|year=1968|volume=8|pages=57–75}}</ref>).\n\n'''''Evolutionary multiobjective optimization school (EMO)'''''\n\nEMO algorithms start with an initial population, and update it by using processes designed to mimic natural survival-of-the-fittest principles and genetic variation operators to improve the average population from one generation to the next. The goal is to converge to a population of solutions which represent the nondominated set (Schaffer, 1984;<ref>{{cite book|last=Shaffer|first=J.D.|title=Some Experiments in Machine Learning Using Vector Evaluated Genetic Algorithms, PhD thesis|year=1984|publisher=Vanderbilt University|location=Nashville}}</ref> Srinivas and Deb, 1994<ref>{{cite journal|last=Srinivas|first=N.|author2=Deb, K.|title=Multiobjective Optimization Using Nondominated Sorting in Genetic Algorithms|journal=Evolutionary Computation|year=1994|volume=2|pages=221–248|doi=10.1162/evco.1994.2.3.221|issue=3}}</ref>).  More recently, there are efforts to incorporate preference information into the solution process of EMO algorithms (see Deb and Köksalan, 2010<ref>{{cite journal|last=Deb|first=K.|author2=Köksalan, M.|title=Guest Editorial Special Issue on Preference-Based Multiobjective Evolutionary Algorithms|journal=IEEE Transactions on Evolutionary Computation|year=2010|volume=14|pages=669–670|doi=10.1109/TEVC.2010.2070371|issue=5}}</ref>).\n\n'''''[[Analytic hierarchy process|Analytic hierarchy process (AHP)]]'''''\n\nThe AHP first decomposes the decision problem into a hierarchy of subproblems. Then the decision-maker evaluates the relative importance of its various elements by pairwise comparisons. The AHP converts these evaluations to numerical values (weights or priorities), which are used to calculate a score for each alternative (Saaty, 1980<ref>{{cite book|last=Saaty|first=T.L.|title=The Analytic Hierarchy Process: Planning, Priority Setting, Resource Allocation|year=1980|publisher=McGraw-Hill|location=New York}}</ref>). A consistency index measures the extent to which the decision-maker has been consistent in her responses. AHP is one of the more controversial techniques listed here, with some researchers in the MCDA community believing it to be flawed. The underlying mathematics is also more complicated, though it has gained some popularity as a result of commercially available software.\n\nSeveral papers reviewed the application of MCDM techniques in various disciplines such as fuzzy MCDM,<ref>{{Cite journal|last=Mardani|first=Abbas|last2=Jusoh|first2=Ahmad|last3=Zavadskas|first3=Edmundas Kazimieras|date=2015-05-15|title=Fuzzy multiple criteria decision-making techniques and applications – Two decades review from 1994 to 2014|journal=Expert Systems with Applications|volume=42|issue=8|pages=4126–4148|doi=10.1016/j.eswa.2015.01.003}}</ref> classic MCDM,<ref>{{Cite journal|last=Mardani|first=Abbas|last2=Jusoh|first2=Ahmad|last3=Nor|first3=Khalil MD|last4=Khalifah|first4=Zainab|last5=Zakwan|first5=Norhayati|last6=Valipour|first6=Alireza|date=2015-01-01|title=Multiple criteria decision-making techniques and their applications – a review of the literature from 2000 to 2014|journal=Economic Research-Ekonomska Istraživanja|volume=28|issue=1|pages=516–571|doi=10.1080/1331677X.2015.1075139|issn=1331-677X|url=http://hrcak.srce.hr/file/253067}}</ref> sustainable and renewable energy,<ref>{{Cite journal|last=Mardani|first=Abbas|last2=Jusoh|first2=Ahmad|last3=Zavadskas|first3=Edmundas Kazimieras|last4=Cavallaro|first4=Fausto|last5=Khalifah|first5=Zainab|date=2015-10-19|title=Sustainable and Renewable Energy: An Overview of the Application of Multiple Criteria Decision Making Techniques and Approaches|journal=Sustainability|language=en|volume=7|issue=10|pages=13947–13984|doi=10.3390/su71013947|df=dmy-all}}</ref> VIKOR technique,<ref>{{Cite journal|last=Mardani|first=Abbas|last2=Zavadskas|first2=Edmundas Kazimieras|last3=Govindan|first3=Kannan|last4=Amat Senin|first4=Aslan|last5=Jusoh|first5=Ahmad|date=2016-01-04|title=VIKOR Technique: A Systematic Review of the State of the Art Literature on Methodologies and Applications|journal=Sustainability|language=en|volume=8|issue=1|pages=37|doi=10.3390/su8010037|df=dmy-all}}</ref> transportation systems,<ref>{{Cite journal|last=Mardani|first=Abbas|last2=Zavadskas|first2=Edmundas Kazimieras|last3=Khalifah|first3=Zainab|last4=Jusoh|first4=Ahmad|last5=Nor|first5=Khalil MD|date=2016-07-02|title=Multiple criteria decision-making techniques in transportation systems: a systematic review of the state of the art literature|journal=Transport|volume=31|issue=3|pages=359–385|doi=10.3846/16484142.2015.1121517|issn=1648-4142}}</ref> service quality,<ref>{{Cite journal|last=Mardani|first=Abbas|last2=Jusoh|first2=Ahmad|last3=Zavadskas|first3=Edmundas Kazimieras|last4=Khalifah|first4=Zainab|last5=Nor|first5=Khalil MD|date=2015-09-03|title=Application of multiple-criteria decision-making techniques and approaches to evaluating of service quality: a systematic review of the literature|journal=Journal of Business Economics and Management|volume=16|issue=5|pages=1034–1068|doi=10.3846/16111699.2015.1095233|issn=1611-1699}}</ref> TOPSIS method,<ref>{{Cite journal|last=Zavadskas|first=Edmundas Kazimieras|last2=Mardani|first2=Abbas|last3=Turskis|first3=Zenonas|last4=Jusoh|first4=Ahmad|last5=Nor|first5=Khalil MD|date=2016-05-01|title=Development of TOPSIS Method to Solve Complicated Decision-Making Problems — An Overview on Developments from 2000 to 2015|journal=[[International Journal of Information Technology & Decision Making]]|volume=15|issue=3|pages=645–682|doi=10.1142/S0219622016300019|issn=0219-6220}}</ref> energy management problems,<ref>{{Cite journal|last=Mardani|first=Abbas|last2=Zavadskas|first2=Edmundas Kazimieras|last3=Khalifah|first3=Zainab|last4=Zakuan|first4=Norhayati|last5=Jusoh|first5=Ahmad|last6=Nor|first6=Khalil Md|last7=Khoshnoudi|first7=Masoumeh|date=2017-05-01|title=A review of multi-criteria decision-making applications to solve energy management problems: Two decades from 1995 to 2015|journal=Renewable and Sustainable Energy Reviews|volume=71|pages=216–256|doi=10.1016/j.rser.2016.12.053}}</ref> e-learning,<ref>{{Cite journal|last=Zare|first=Mojtaba|last2=Pahl|first2=Christina|last3=Rahnama|first3=Hamed|last4=Nilashi|first4=Mehrbakhsh|last5=Mardani|first5=Abbas|last6=Ibrahim|first6=Othman|last7=Ahmadi|first7=Hossein|date=2016-08-01|title=Multi-criteria decision making approach in E-learning: A systematic review and classification|journal=Applied Soft Computing|volume=45|pages=108–128|doi=10.1016/j.asoc.2016.04.020}}</ref> tourism and hospitality,<ref>{{Cite web|url=http://www.transformations.knf.vu.lt/37/article/appl|title=Transformations in Business & Economics – Vol. 15, No 1 (37), 2016 – Article|last=Diedonis|first=Antanas|website=www.transformations.knf.vu.lt|access-date=2017-08-29|deadurl=no|archiveurl=https://web.archive.org/web/20170829121038/http://www.transformations.knf.vu.lt/37/article/appl|archivedate=29 August 2017|df=dmy-all}}</ref> SWARA and WASPAS methods.<ref>{{Cite journal|last=Mardani|first=Abbas|last2=Nilashi|first2=Mehrbakhsh|last3=Zakuan|first3=Norhayati|last4=Loganathan|first4=Nanthakumar|last5=Soheilirad|first5=Somayeh|last6=Saman|first6=Muhamad Zameri Mat|last7=Ibrahim|first7=Othman|date=2017-08-01|title=A systematic review and meta-Analysis of SWARA and WASPAS methods: Theory and applications with recent fuzzy developments|journal=Applied Soft Computing|volume=57|pages=265–292|doi=10.1016/j.asoc.2017.03.045}}</ref>\n\n===MCDM methods===\nThe following MCDM methods are available, many of which are implemented by specialized [[decision-making software]]:<ref name=\"Weistrofferetal\"/><ref name=\"orms\"/>\n\n* [[Aggregated Indices Randomization Method]] (AIRM)\n* [[Analytic hierarchy process]] (AHP)\n* [[Analytic network process]] (ANP)\n*Balance Beam process\n* [[Best worst method]] (BWM)<ref>Rezaei, J. (2015) \"[http://www.sciencedirect.com/science/article/pii/S0305048314001480 Best-Worst Multi-Criteria Decision-Making Method]\", Omega, 53, 49-57.</ref><ref>Rezaei, J. (2016) \"[http://www.sciencedirect.com/science/article/pii/S0305048315002479 Best-worst multi-criteria decision-making method: Some properties and a linear model]\", Omega, 64, 126-130.</ref>\n* [[Brown–Gibson model]]\n* [[Characteristic Objects METhod]] (COMET)<ref>Sałabun, W. (2015). The Characteristic Objects Method: A New Distance‐based Approach to Multicriteria Decision‐making Problems. Journal of Multi‐Criteria Decision Analysis, 22(1-2), 37-50.</ref><ref>Sałabun, W., Piegat, A. (2016). Comparative analysis of MCDM methods for the assessment of mortality in patients with acute coronary syndrome. Artificial Intelligence Review. First Online: 03 September 2016.</ref>\n* [[Choosing By Advantages (CBA)]]\n* [[Data envelopment analysis]]\n* [[Decision EXpert]] (DEX)\n*  Disaggregation – Aggregation Approaches (UTA*, UTAII, UTADIS)\n* [[Rough set]] (Rough set approach)\n* [[Dominance-based rough set approach]] (DRSA)\n* [[ELECTRE]] (Outranking)\n* [[Evaluation Based on Distance from Average Solution]] (EDAS)<ref>Keshavarz Ghorabaee, M. et al. (2015) \"[http://content.iospress.com/articles/informatica/inf1070 Multi-Criteria Inventory Classification Using a New Method of Evaluation Based on Distance from Average Solution (EDAS)] {{webarchive|url=https://web.archive.org/web/20160902111422/http://content.iospress.com/articles/informatica/inf1070 |date=2 September 2016 }}\", Informatica, 26(3), 435-451.</ref>\n* [[Evidential reasoning approach]] (ER)\n* [[Goal programming]] (GP)\n* [[Grey relational analysis]] (GRA)\n* [[Inner product of vectors]] (IPV)\n* [[Measuring Attractiveness by a Categorical Based Evaluation Technique (MACBETH)|Measuring Attractiveness by a categorical Based Evaluation Technique]] (MACBETH)\n* [[Simple Multi-Attribute Rating Technique]] (SMART)\n* [https://www.sciencedirect.com/science/article/pii/S0950705118303502 Stratified multi criteria decision making method] (SMCDM)<ref>Asadabadi, M. R. (2018). The stratified multi-criteria decision-making method. Knowledge-Based Systems.</ref>\n* [https://www.sciencedirect.com/science/article/pii/S0377221717305246 Markovian Multi-Criteria Decision Making] <ref>Asadabadi, M. R. (2017). A customer based supplier selection process that combines quality function deployment, the analytic network process and a Markov chain. European Journal of Operational Research, 263(3), 1049-1062.</ref> <ref>Asadabadi, M. R. (2016). A Markovian-QFD approach in addressing the changing priorities of the customer needs. International Journal of Quality & Reliability Management, 33(8), 1062-1075.</ref>\n* [[Multi-Attribute Global Inference of Quality]] (MAGIQ)\n* [[Multi-attribute utility|Multi-attribute utility theory]] (MAUT)\n* Multi-attribute value theory (MAVT)\n* [[New Approach to Appraisal]] (NATA)\n* Nonstructural Fuzzy Decision Support System (NSFDSS)\n* [[Potentially All Pairwise RanKings of all possible Alternatives]] (PAPRIKA)\n* [[PROMETHEE]] (Outranking)\n* Ranking based on optimal points (RBOP)<ref>Zakeri, S. (2018). Ranking based on optimal points multi-criteria decision-making method. Grey Systems: Theory and Application. doi:[https://doi.org/10.1108/GS-09-2018-0040 10.1108/GS-09-2018-0040]</ref>\n* [[Stochastic multicriteria acceptability analysis|Stochastic Multicriteria Acceptability Analysis]] (SMAA)\n* [[Superiority and inferiority ranking method]] (SIR method)\n* [[TOPSIS|Technique for the Order of Prioritisation by Similarity to Ideal Solution (TOPSIS)]]\n* [[Value analysis]] (VA)\n* [[Value engineering]] (VE)\n* [[VIKOR method]]<ref>{{cite journal | last1 = Serafim | first1 = Opricovic | last2 = Gwo-Hshiung | first2 = Tzeng | year = 2007 | title = Extended VIKOR Method in Comparison with Outranking Methods | doi = 10.1016/j.ejor.2006.01.020 | journal = European Journal of Operational Research | volume = 178 | issue = 2| pages = 514–529 }}</ref>\n* Fuzzy [[VIKOR method]]<ref>{{cite journal | last1 = Serafim | first1 = Opricovic | year = 2011 | title = Fuzzy VIKOR with an application to water resources planning | doi = 10.1016/j.eswa.2011.04.097 | journal = Expert Systems with Applications | volume = 38 | issue = 10| pages = 12983–12990 }}</ref>\n* [[Weighted product model]]  (WPM)\n* [[Weighted sum model]]  (WSM)\n* Rembrandt method\n* Modelo Integrado de Valor para Estructuras Sostenibles (MIVES)<ref>Joglekar, S. N., Kharkar, R. A., Mandavgane, S. A., & Kulkarni, B. D. (2018). Sustainability\nassessment of brick work for low-cost housing: A comparison between waste based bricks and burnt\nclay bricks. Sustainable cities and society, 37, 396-406.</ref><ref> Alarcon, B., Aguado, A., Manga, R., Josa, A.: A value function for assessing\nsustainability: Application to industrial buildings. Sustainability. 3, 35–50 (2011).\ndoi:10.3390/su3010035.</ref>\n\n==See also==\n* [[Architecture tradeoff analysis method]]\n* [[Decision-making]]\n* [[Decision-making software]]\n* [[Decision-making paradox]]\n* [[Decisional balance sheet]]\n* [[Multicriteria classification|Multicriteria classification problems]]\n* [[Rank reversals in decision-making]]\n\n==References==\n<!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using  tags which will then appear here automatically -->\n\n\n{{Reflist|30em}}\n\n\n{{Use dmy dates|date=August 2010}}\n\n==Further reading==\n\n*{{cite journal | author=Maliene, V. |title=Specialised property valuation: Multiple criteria decision analysis |journal=Journal of Retail & Leisure Property |volume=9 |issue=5 |pages= 443–50 |year= 2011 | doi= 10.1057/rlp.2011.7 }}\n*{{cite journal |vauthors=Mulliner E, Smallbone K, Maliene V |title=An assessment of sustainable housing affordability using a multiple criteria decision making method |journal=Omega |volume=41 |issue= 2 |pages= 270–79 |year= 2013 |doi= 10.1016/j.omega.2012.05.002 |url=http://eprints.maths.manchester.ac.uk/1906/1/mulliner13.pdf }}\n*{{cite journal | author=Maliene, V.|title=Application of a new multiple criteria analysis method in the valuation of property |journal=FIG XXII International Congress |pages=19–26|year= 2002 | url= http://www.fig.net/pub/fig_2002/Ts9-3/TS9_3_maliene_etal.pdf |display-authors=etal}}\n*[http://www.mcdmsociety.org/content/short-mcdm-history-0 A Brief History prepared by Steuer and Zionts]\n*Malakooti, B. (2013). Operations and Production Systems with Multiple Objectives. John Wiley & Sons.\n\n{{Group creativity techniques|state=collapsed}}\n\n{{DEFAULTSORT:Multi-Criteria Decision Analysis}}\n[[Category:Decision analysis]]\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis| ]]\n[[Category:Utility]]\n\n[[sr:Вишекритеријумска оптимизација]]"
    },
    {
      "title": "Multi-objective optimization",
      "url": "https://en.wikipedia.org/wiki/Multi-objective_optimization",
      "text": "{{See also|Multiple-criteria decision analysis|Vector optimization}}\n\n'''Multi-objective optimization''' (also known as '''multi-objective programming''', '''vector optimization''', '''multicriteria optimization''', '''multiattribute optimization''' or '''Pareto optimization''') is an area of [[MCDM|multiple criteria decision making]] that is concerned with [[Mathematical optimization|mathematical optimization problems]] involving more than one [[Loss function|objective function]] to be optimized simultaneously. Multi-objective optimization has been applied in many fields of science, including engineering, economics and logistics where optimal decisions need to be taken in the presence of [[trade-off]]s between two or more conflicting objectives. Minimizing cost while maximizing comfort while buying a car, and maximizing performance whilst minimizing fuel consumption and emission of pollutants of a vehicle are examples of multi-objective optimization problems involving two and three objectives, respectively. In practical problems, there can be more than three objectives.\n\nFor a [[nontrivial]] multi-objective optimization problem, no single solution exists that simultaneously optimizes each objective. In that case, the objective functions are said to be conflicting, and there exists a (possibly infinite) number of Pareto optimal solutions. A solution is called [[Maxima of a point set|nondominated]], Pareto optimal, [[Pareto efficient]] or noninferior, if none of the objective functions can be improved in value without degrading some of the other objective values. Without additional [[Subjectivity|subjective]] preference information, all Pareto optimal solutions are considered equally good (as vectors cannot be ordered completely). Researchers study multi-objective optimization problems from different viewpoints and, thus, there exist different solution philosophies and goals when setting and solving them. The goal may be to find a representative set of Pareto optimal solutions, and/or quantify the trade-offs in satisfying the different objectives, and/or finding a single solution that satisfies the subjective preferences of a human decision maker (DM).\n\n== Introduction ==\n\nA multi-objective optimization problem is an [[optimization problem]] that involves multiple objective functions.<ref name=\"Miettinen1999\"/><ref name=\"HwangMasud1979\"/><ref name=hassanzadeh>{{cite journal|last1=Hassanzadeh|first1=Hamidreza|last2=Rouhani|first2=Modjtaba|title=A multi-objective gravitational search algorithm|journal=In Computational Intelligence, Communication Systems and Networks (CICSyN)|date=2010|pages=7–12}}</ref> In mathematical terms, a multi-objective optimization problem can be formulated as\n: <math>\n\\begin{align}\n\\min &\\left(f_1(x), f_2(x),\\ldots, f_k(x) \\right)  \\\\\n\\text{s.t. } &x\\in X,\n\\end{align}\n</math>\nwhere the integer <math>k\\geq 2</math> is the number of objectives and the set <math>X</math> is the [[feasible set]] of decision vectors. The feasible set is typically defined by some constraint functions. In addition, the vector-valued objective function is often defined as\n:<math>f:X\\to\\mathbb R^k, \\ f(x)= (f_1(x),\\ldots,f_k(x))^T</math>. If some objective function is to be maximized, it is equivalent to minimize its negative. The image of <math>X</math> is denoted by <math>Y \\in \\mathbb R^k</math>\n\n[[File:Front pareto.svg|thumb|300px|Example of a [[Pareto frontier]] (in red), the set of Pareto optimal solutions (those that are not dominated by any other feasible solutions). The boxed points represent feasible choices, and smaller values are preferred to larger ones. Point ''C'' is not on the Pareto frontier because it is dominated by both point ''A'' and point ''B''. Points ''A'' and ''B'' are not strictly dominated by any other, and hence do lie on the frontier.]]\n\nAn element <math>x^*\\in X</math> is called a [[feasible solution]] or a '''feasible decision'''. A vector <math>z^* := f(x^*)\\in \\mathbb R^k</math> for a feasible solution <math>x^*</math> is called an '''objective vector''' or an '''outcome'''. In multi-objective optimization, there does not typically exist a feasible solution that minimizes all objective functions simultaneously. Therefore, attention is paid to [[Pareto optimality|Pareto optimal]] solutions; that is, solutions that cannot be improved in any of the objectives without degrading at least one of the other objectives. In mathematical terms, a feasible solution <math>x^1\\in X</math> is said to [[Pareto improvement|(Pareto) dominate]] another solution <math>x^2\\in X</math>, if\n#<math>f_i(x^1)\\leq f_i(x^2)</math> for all indices <math>i \\in \\left\\{ {1,2,\\dots,k } \\right\\}</math> and\n#<math>f_j(x^1) < f_j(x^2)</math> for at least one index <math>j \\in \\left\\{ {1,2,\\dots,k } \\right\\}</math>.\nA solution <math>x^*\\in X</math> (and the corresponding outcome <math>f(x^*)</math>) is called Pareto optimal, if there does not exist another solution that dominates it. The set of Pareto optimal outcomes is often called the '''[[Pareto front]]''', Pareto frontier, or Pareto boundary.\n\nThe Pareto front of a multi-objective optimization problem is bounded by a so-called '''nadir objective vector''' <math> z^{nad} </math> and an '''ideal objective vector''' <math> z^{ideal} </math>, if these are finite. The nadir objective vector is defined as\n:<math> z^{nad}_i= \\sup_{x\\in X\\text{ is Pareto optimal}} f_i(x) \\text{ for all } i=1,\\ldots,k </math>\nand the ideal objective vector as\n:<math> z^{ideal}_i=\\inf_{x\\in X}{f_i(x)}\\text{ for all } i=1,\\ldots,k.</math>\nIn other words, the components of a nadir and an ideal objective vector define upper and lower bounds for the objective function values of Pareto optimal solutions, respectively. In practice, the nadir objective vector can only be approximated as, typically, the whole Pareto optimal set is unknown. In addition, a '''utopian objective vector''' <math>z^{utopian}</math> with\n:<math> z^{utopian}_i = z^{ideal}_{i}-\\epsilon \\text{ for all } i=1,\\ldots,k,</math>\nwhere <math>\\epsilon>0</math> is a small constant, is often defined because of numerical reasons.\n\n== Examples of applications ==\n\n===Economics===\n\nIn [[economics]], many problems involve multiple objectives along with constraints on what combinations of those objectives are attainable. For example, consumer's [[demand]] for various goods is determined by the process of maximization of the [[utility|utilities]] derived from those goods, subject to a constraint based on how much income is available to spend on those goods and on the prices of those goods. This constraint allows more of one good to be purchased only at the sacrifice of consuming less of another good; therefore, the various objectives (more consumption of each good is preferred) are in conflict with each other. A common method for analyzing such a problem is to use a graph of [[indifference curve]]s, representing preferences, and a budget constraint, representing the trade-offs that the consumer is faced with.\n\nAnother example involves the [[production possibilities frontier]], which specifies what combinations of various types of goods can be produced by a society with certain amounts of various resources. The frontier specifies the trade-offs that the society is faced with — if the society is fully utilizing its resources, more of one good can be produced only at the expense of producing less of another good. A society must then use some process to choose among the possibilities on the frontier.\n\n[[Macroeconomics#Macroeconomic policy|Macroeconomic policy]]-making is a context requiring multi-objective optimization. Typically a [[central bank]] must choose a stance for [[monetary policy]] that balances competing objectives — low [[inflation]], low [[unemployment]], low [[balance of trade]] deficit, etc. To do this, the central bank uses a [[economic model|model of the economy]] that quantitatively describes the various causal linkages in the economy; it [[simulation|simulates]] the model repeatedly under various possible stances of monetary policy, in order to obtain a menu of possible predicted outcomes for the various variables of interest. Then in principle it can use an aggregate objective function to rate the alternative sets of predicted outcomes, although in practice central banks use a non-quantitative, judgement-based, process for ranking the alternatives and making the policy choice.\n\n===Finance===\n\nIn [[finance]], a common problem is to choose a portfolio when there are two conflicting objectives — the desire to have the [[expected value]] of portfolio returns be as high as possible, and the desire to have [[financial risk|risk]], often measured by the [[standard deviation]] of portfolio returns, be as low as possible. This problem is often represented by a graph in which the [[efficient frontier]] shows the best combinations of risk and expected return that are available, and in which indifference curves show the investor's preferences for various risk-expected return combinations. The problem of optimizing a function of the expected value (first [[moment (mathematics)|moment]]) and the standard deviation (square root of the second central moment) of portfolio return is called a [[two-moment decision model]].\n\n===Optimal control===\n{{Main article|Optimal control|Dynamic programming|Linear-quadratic regulator}}\n\nIn [[engineering]] and [[economics]], many problems involve multiple objectives which are not describable as the-more-the-better or the-less-the-better; instead, there is an ideal target value for each objective, and the desire is to get as close as possible to the desired value of each objective. For example, energy systems typically have a trade-off between performance and cost<ref>{{Cite journal|last=Shirazi|first=Ali|last2=Najafi|first2=Behzad|last3=Aminyavari|first3=Mehdi|last4=Rinaldi|first4=Fabio|last5=Taylor|first5=Robert A.|date=2014-05-01|title=Thermal–economic–environmental analysis and multi-objective optimization of an ice thermal energy storage system for gas turbine cycle inlet air cooling|journal=Energy|volume=69|pages=212–226|doi=10.1016/j.energy.2014.02.071}}</ref><ref>{{Cite journal|last=Najafi|first=Behzad|last2=Shirazi|first2=Ali|last3=Aminyavari|first3=Mehdi|last4=Rinaldi|first4=Fabio|last5=Taylor|first5=Robert A.|date=2014-02-03|title=Exergetic, economic and environmental analyses and multi-objective optimization of an SOFC-gas turbine hybrid cycle coupled with an MSF desalination system|journal=Desalination|volume=334|issue=1|pages=46–59|doi=10.1016/j.desal.2013.11.039}}</ref> or one might want to adjust a rocket's fuel usage and orientation so that it arrives both at a specified place and at a specified time; or one might want to conduct [[open market operations]] so that both the [[inflation rate]] and the [[unemployment rate]] are as close as possible to their desired values.\n\nOften such problems are subject to linear equality constraints that prevent all objectives from being simultaneously perfectly met, especially when the number of controllable variables is less than the number of objectives and when the presence of random shocks generates uncertainty. Commonly a multi-objective [[quadratic function#Bivariate (two variable) quadratic function|quadratic objective function]] is used, with the cost associated with an objective rising quadratically with the distance of the objective from its ideal value. Since these problems typically involve adjusting the controlled variables at various points in time and/or evaluating the objectives at various points in time, [[intertemporal optimization]] techniques are employed.<ref>{{cite journal|last=Amirahmadi|first=Ahmadreza |author2=A. Dastfan |author3=S.M.R. Rafiei|title=Optimal Controller Design for Single-phase PWM Rectifier Using SPEA Multi-objective Optimization|journal=Journal of Power Electronics|date=January 2012|volume=12|issue=1}}</ref><ref>{{cite journal|last=Rafiei|first=S.M.R. |author2=A. Amirahmadi |author3=G. Griva|title=Chaos Rejection and Optimal Dynamic Response for Boost Converter Using SPEA Multi-Objective Optimization Approach|journal=IEEE Iecon2009|date=Nov 2009|pages=3351–3358|url=http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5415056&queryText%3DChaos+Rejection+and+Optimal+Dynamic+Response+for+Boost+Converter+Using+SPEA+Multi-Objective+Optimization+Approach|doi=10.1109/IECON.2009.5415056 |isbn=978-1-4244-4648-3 }}</ref>\n\n===Optimal design===\n\nProduct and process design can be largely improved using modern modeling, simulation and optimization techniques.{{citation needed|date=February 2017}}  The key question in optimal design is the measure of what is good or desirable about a design. Before looking for optimal designs it is important to identify characteristics which contribute the most to the overall value of the design. A good design typically involves multiple criteria/objectives such as capital cost/investment, operating cost, profit, quality and/or recovery of the product, efficiency, process safety, operation time etc. Therefore, in practical applications, the performance of process and product design is often measured with respect to multiple objectives. These objectives typically are conflicting, i.e. achieving the optimal value for one objective requires some compromise on one or more of other objectives.\n\nFor example, when designing a paper mill, one can seek to decrease the amount of capital invested in a paper mill and enhance the quality of paper simultaneously. If the design of a paper mill is defined by large storage volumes and paper quality is defined by quality parameters, then the problem of optimal design of a paper mill can include objectives such as: i) minimization of expected variation of those quality parameter from their nominal values, ii) minimization of expected time of breaks and iii) minimization of investment cost of storage volumes. Here, maximum volume of towers are design variables. This example of optimal design of a paper mill is a simplification of the model used in.<ref name=RoRiPi11>{{Cite journal | last1 = Ropponen | first1 = A. | last2 = Ritala | first2 = R. | last3 = Pistikopoulos | first3 = E. N. | doi = 10.1016/j.compchemeng.2010.12.012 | title = Optimization issues of the broke management system in papermaking | journal = Computers & Chemical Engineering | volume = 35 | issue = 11 | pages = 2510 | year = 2011 | pmid =  | pmc = }}</ref>  Multi-objective design optimization have also been implemented in engineering systems in circumstances such as control cabinet layout optimization,<ref>{{cite arxiv|last1=Pllana |first1=Sabri |last2=Memeti |first2=Suejb |last3=Kolodziej |first3=Joanna |title=Customizing Pareto Simulated Annealing for Multi-objective Optimization of Control Cabinet Layout |arxiv=1906.04825 }}</ref> airfoil shape optimization using scientific workflows,<ref>{{cite journal |last1=Nguyen |first1=Hoang Anh |last2=van Iperen |first2=Zane |last3=Raghunath |first3=Sreekanth |last4=Abramson |first4=David |last5=Kipouros |first5=Timoleon |last6=Somasekharan |first6=Sandeep |title=Multi-objective optimisation in scientific workflow |journal=Procedia Computer Science |date=2017 |volume=108 |pages=1443–1452 |hdl=1826/12173|doi=10.1016/j.procs.2017.05.213 }}</ref> design of nano-[[CMOS]] semiconductors,<ref>{{Cite journal|title = Multiobjective design optimization of a nano-CMOS voltage-controlled oscillator using game theoretic-differential evolution|journal = Applied Soft Computing|date = 2015-07-01|pages = 293–299|volume = 32|doi = 10.1016/j.asoc.2015.03.016|first = T.|last = Ganesan|first2 = I.|last2 = Elamvazuthi|first3 = P.|last3 = Vasant}}</ref> [[System on a chip|system on chip]] design, design of solar-powered irrigation systems,<ref>{{Cite book|title = Hypervolume-Driven Analytical Programming for Solar-Powered Irrigation System Optimization|publisher = Springer International Publishing|date = 2013-01-01|isbn = 978-3-319-00541-6|pages = 147–154|series = Advances in Intelligent Systems and Computing|doi = 10.1007/978-3-319-00542-3_15|first = T.|last = Ganesan|first2 = I.|last2 = Elamvazuthi|first3 = Ku Zilati Ku|last3 = Shaari|first4 = P.|last4 = Vasant|editor-first = Ivan|editor-last = Zelinka|editor-first2 = Guanrong|editor-last2 = Chen|editor-first3 = Otto E.|editor-last3 = Rössler|editor-first4 = Vaclav|editor-last4 = Snasel|editor-first5 = Ajith|editor-last5 = Abraham}}</ref> optimization of sand mould systems,<ref>{{Cite book|title = Multiobjective Optimization of Green Sand Mould System Using Chaotic Differential Evolution|publisher = Springer Berlin Heidelberg|date = 2013-01-01|isbn = 978-3-642-45317-5|pages = 145–163|series = Lecture Notes in Computer Science|first = T.|last = Ganesan|first2 = I.|last2 = Elamvazuthi|first3 = Ku Zilati Ku|last3 = Shaari|first4 = P.|last4 = Vasant|editor-first = Marina L.|editor-last = Gavrilova|editor-first2 = C. J. Kenneth|editor-last2 = Tan|editor-first3 = Ajith|editor-last3 = Abraham|doi = 10.1007/978-3-642-45318-2_6}}</ref><ref>{{Cite journal|title = Multi-objective optimization of green sand mould system using evolutionary algorithms|journal = The International Journal of Advanced Manufacturing Technology|date = 2011-05-07|issn = 0268-3768|pages = 9–17|volume = 58|issue = 1–4|doi = 10.1007/s00170-011-3365-8|first = B.|last = Surekha|first2 = Lalith K.|last2 = Kaushik|first3 = Abhishek K.|last3 = Panduy|first4 = Pandu R.|last4 = Vundavilli|first5 = Mahesh B.|last5 = Parappagoudar}}</ref> engine design,<ref>{{Cite web|title = MultiObjective Optimization in Engine Design Using Genetic Algorithms to Improve Engine Performance {{!}} ESTECO|url = http://www.esteco.com/modefrontier/multiobjective-optimization-engine-design-using-genetic-algorithms-improve-engine-perfo|website = www.esteco.com|accessdate = 2015-12-01}}</ref><ref>{{Cite book|chapter = Multi-Objective Robust Design Optimization of an Engine Mounting System|chapter-url = http://papers.sae.org/2005-01-2412/|date = 2005-05-16|location = Warrendale, PA|first = E.|last = Courteille|first2 = F.|last2 = Mortier|first3 = L.|last3 = Leotoing|first4 = E.|last4 = Ragneau|doi = 10.4271/2005-01-2412|title = SAE Technical Paper Series|volume = 1|url = https://hal.archives-ouvertes.fr/hal-00913315/file/SAE_HAL.pdf}}</ref> optimal sensor deployment<ref>{{cite journal|last1=Domingo-Perez|first1=Francisco|last2=Lazaro-Galilea|first2=Jose Luis|last3=Wieser|first3=Andreas|last4=Martin-Gorostiza|first4=Ernesto|last5=Salido-Monzu|first5=David|last6=Llana|first6=Alvaro de la|title=Sensor placement determination for range-difference positioning using evolutionary multi-objective optimization|journal=Expert Systems with Applications|date=April 2016|volume=47|pages=95–105|doi=10.1016/j.eswa.2015.11.008}}</ref> and optimal controller design.<ref>{{Cite journal|title = Multiobjective model predictive control|journal = Automatica|date = 2009-12-01|pages = 2823–2830|volume = 45|issue = 12|doi = 10.1016/j.automatica.2009.09.032|first = Alberto|last = Bemporad|first2 = David|last2 = Muñoz de la Peña}}</ref><ref>{{Cite journal|title = Multi-objective evolutionary algorithm for SSSC-based controller design|journal = Electric Power Systems Research|date = 2009-06-01|pages = 937–944|volume = 79|issue = 6|doi = 10.1016/j.epsr.2008.12.004|first = Sidhartha|last = Panda}}</ref>\n\n=== {{anchor|MOGA}} Process optimization ===\nMulti-objective optimization has been increasingly employed in [[chemical engineering]] and [[manufacturing]]. In 2009, Fiandaca and Fraga used the multi-objective genetic algorithm (MOGA) to optimize the pressure swing adsorption process (cyclic separation process). The design problem involved the dual maximization of nitrogen recovery and nitrogen purity. The results provided a good approximation of the Pareto frontier with acceptable trade-offs between the objectives.<ref>{{Cite journal|title = A multi-objective genetic algorithm for the design of pressure swing adsorption|url = http://www.research.ed.ac.uk/portal/en/publications/a-multiobjective-genetic-algorithm-for-the-design-of-pressure-swing-adsorption(b0048cd0-b338-4263-954b-c28ad4058666)/export.html|journal = Engineering Optimization|volume = 41|issue = 9|pages = 833–854|accessdate = 2015-12-01|doi = 10.1080/03052150903074189|year = 2009|last1 = Fiandaca|first1 = Giovanna|last2 = Fraga|first2 = Eric S.|last3 = Brandani|first3 = Stefano}}</ref>\n\nIn 2010, Sendín et al. solved a multi-objective problem for the thermal processing of food. They tackled two case studies (bi-objective and triple objective problems) with nonlinear dynamic models and used a hybrid approach consisting of the weighted Tchebycheff and the Normal Boundary Intersection approach.  The novel hybrid approach was able to construct a Pareto optimal set for the thermal processing of foods.<ref>{{Cite journal|title = Efficient and robust multi-objective optimization of food processing: A novel approach with application to thermal sterilization|journal = Journal of Food Engineering|date = 2010-06-01|pages = 317–324|volume = 98|issue = 3|doi = 10.1016/j.jfoodeng.2010.01.007|first = José Oscar H.|last = Sendín|first2 = Antonio A.|last2 = Alonso|first3 = Julio R.|last3 = Banga|hdl = 10261/48082}}</ref>\n\nIn 2013, Ganesan et al. carried out the multi-objective optimization of the combined carbon dioxide reforming and partial-oxidation of methane. The objective functions were methane conversion, carbon monoxide selectivity and hydrogen to carbon monoxide ratio. Ganesan used the Normal Boundary Intersection (NBI) method in conjunction with two swarm-based techniques (Gravitational Search Algorithm (GSA) and Particle Swarm Optimization (PSO)) to tackle the problem.<ref>{{Cite journal|title = Swarm intelligence and gravitational search algorithm for multi-objective optimization of synthesis gas production|journal = Applied Energy|date = 2013-03-01|pages = 368–374|volume = 103|doi = 10.1016/j.apenergy.2012.09.059|first = T.|last = Ganesan|first2 = I.|last2 = Elamvazuthi|first3 = Ku Zilati|last3 = Ku Shaari|first4 = P.|last4 = Vasant}}</ref>Applications involving chemical extraction<ref>{{Cite book|title = Multiobjective Optimization of Bioactive Compound Extraction Process via Evolutionary Strategies|publisher = Springer International Publishing|date = 2015-03-23|isbn = 978-3-319-15704-7|pages = 13–21|series = Lecture Notes in Computer Science|doi = 10.1007/978-3-319-15705-4_2|first = Timothy|last = Ganesan|first2 = Irraivan|last2 = Elamvazuthi|first3 = Pandian|last3 = Vasant|first4 = Ku Zilati Ku|last4 = Shaari|editor-first = Ngoc Thanh|editor-last = Nguyen|editor-first2 = Bogdan|editor-last2 = Trawiński|editor-first3 = Raymond|editor-last3 = Kosala}}</ref> and bioethanol production processes<ref>{{Cite book|title = Contemporary Advancements in Information Technology Development in Dynamic Environments|url = https://books.google.com/books?id=L6N_BAAAQBAJ|publisher = IGI Global|date = 2014-06-30|isbn = 9781466662537|first = Khosrow-Pour|last = Mehdi}}</ref> have posed similar multi-objective problems.\n\nIn 2013, Abakarov et al proposed an alternative technique to solve multi-objective optimization problems arising in food engineering.<ref>{{Cite journal|title=Multi-criteria optimization and decision-making approach for improving of food engineering processes.|author=Abakarov. A., Sushkov. Yu., Mascheroni. R.H. | year=2012| url=http://tomakechoice.com/paper/MCDM&OD_IJFS.pdf| journal=International Journal of Food Studies|volume=2|pages=1–21| doi=10.7455/ijfs/2.1.2013.a1}}</ref>  The Aggregating Functions Approach, the Adaptive Random Search Algorithm, and the Penalty Functions Approach were used to compute the initial set of the non-dominated or Pareto-optimal solutions. The [[Analytic Hierarchy Process]] and Tabular Method were used simultaneously for choosing the best alternative among the computed subset of non-dominated solutions for osmotic dehydration processes.<ref>{{Cite journal|author=Abakarov, A, Sushkov, Y, Almonacid, S, and Simpson, R. | year=2009| title=Multiobjective Optimisation Approach: Thermal Food Processing.|journal=Journal of Food Science|volume=74 |issue=9|pages= E471–E487|doi=10.1111/j.1750-3841.2009.01348.x| pmid=20492109}}</ref>\n\nIn 2018, Pearce et al. formulated task allocation to human and robotic workers as a multi-objective optimization problem, considering production time and the ergonomic impact on the human worker as the two objectives considered in the formulation. Their approach used a [[Linear programming|Mixed-Integer Linear Program]] to solve the optimization problem for a weighted sum of the two objectives to calculate a set of [[Pareto efficiency|Pareto optimal]] solutions. The application of the approach to several manufacturing tasks showed improvements in at least one objective in most tasks and in both objectives in some of the processes.<ref>{{Cite journal|last=Pearce|first=Margaret|last2=Mutlu|first2=Bilge|last3=Shah|first3=Julie|last4=Radwin|first4=Robert|date=2018|title=Optimizing Makespan and Ergonomics in Integrating Collaborative Robots Into Manufacturing Processes|journal=IEEE Transactions on Automation Science and Engineering|volume=15|issue=4|language=en-US|pages=1772–1784|doi=10.1109/tase.2018.2789820|issn=1545-5955}}</ref>\n\n===Radio resource management===\n\nThe purpose of [[radio resource management]] is to satisfy the data rates that are requested by the users of a cellular network.<ref name=fnt2013>E. Björnson and E. Jorswieck, [http://kth.diva-portal.org/smash/get/diva2:608533/FULLTEXT01 Optimal Resource Allocation in Coordinated Multi-Cell Systems], Foundations and Trends in Communications and Information Theory, vol. 9, no. 2-3, pp. 113-381, 2013.</ref> The main resources are time intervals, frequency blocks, and transmit powers. Each user has its own objective function that, for example, can represent some combination of the data rate, latency, and energy efficiency. These objectives are conflicting since the frequency resources are very scarce, thus there is a need for tight spatial [[frequency reuse]] which causes immense inter-user interference if not properly controlled. [[Multi-user MIMO]] techniques are nowadays used to reduce the interference by adaptive [[precoding]]. The network operator would like to both bring great coverage and high data rates, thus the operator would like to find a Pareto optimal solution that balance the total network data throughput and the user fairness in an appropriate subjective manner.\n\nRadio resource management is often solved by scalarization; that is, selection of a network utility function that tries to balance throughput and user fairness. The choice of utility function has a large impact on the computational complexity of the resulting single-objective optimization problem.<ref name=fnt2013 /> For example, the common utility of weighted sum rate gives an [[NP-hard]] problem with a complexity that scales exponentially with the number of users, while the weighted max-min fairness utility results in a quasi-convex optimization problem with only a polynomial scaling with the number of users.<ref name=luo2008>Z.-Q. Luo and S. Zhang, [http://www.ece.umn.edu/~luozq/assets/pdf/publications_files/Zhang08.pdf Dynamic spectrum management: Complexity and duality], IEEE Journal of Selected Topics in Signal Processing, vol. 2, no. 1, pp. 57–73, 2008.</ref>\n\n=== Electric power systems ===\n\nReconfiguration, by exchanging the functional links between the elements of the system, represents one of the most important measures which can improve the operational performance of a distribution system. The problem of optimization through the reconfiguration of a power distribution system, in terms of its definition, is a historical single objective problem with constraints. Since 1975, when Merlin and Back <ref>Merlin, A.; Back, H. Search for a Minimal-Loss Operating Spanning Tree Configuration in an Urban Power Distribution System. In Proceedings of the 1975 Fifth Power Systems Computer Conference (PSCC), Cambridge, UK, 1–5 September 1975; pp. 1–18.</ref> introduced the idea of distribution system reconfiguration for active power loss reduction, until nowadays, a lot of researchers have proposed diverse methods and algorithms to solve the reconfiguration problem as a single objective problem. Some authors have proposed Pareto optimality based approaches (including active power losses and reliability indices as objectives). For this purpose, different artificial intelligence based methods have been used: microgenetic,<ref>Mendoza, J.E.; Lopez, M.E.; Coello, C.A.; Lopez, E.A. Microgenetic multiobjective reconfiguration algorithm considering power losses and reliability indices for medium voltage distribution network. IET Gener. Transm. Distrib. 2009, 3, 825–840.</ref> branch exchange,<ref>Bernardon, D.P.; Garcia, V.J.; Ferreira, A.S.Q.; Canha, L.N. Multicriteria distribution network reconfiguration considering subtransmission analysis. IEEE Trans. Power Deliv. 2010, 25, 2684–2691.</ref> particle swarm optimization <ref>Amanulla, B.; Chakrabarti, S.; Singh, S.N. Reconfiguration of power distribution systems considering reliability and power loss. IEEE Trans. Power Deliv. 2012, 27, 918–926.</ref> and non-dominated sorting genetic algorithm.<ref>Tomoiagă, B.; Chindriş, M.; Sumper, A.; Sudria-Andreu, A.; Villafafila-Robles, R. [http://www.mdpi.com/1996-1073/6/3/1439/pdf Pareto Optimal Reconfiguration of Power Distribution Systems Using a Genetic Algorithm Based on NSGA-II.] Energies 2013, 6, 1439-1455.</ref>\n\n=== Inspection of Infrastructure ===\n\nAutonomous inspection of infrastructure has the potential to reduce costs, risks and environmental impacts, as well as ensuring better periodic maintenance of inspected assets. Typically, planning such missions has been viewed as a single-objective optimization problem, where one aims to minimize the energy or time spent in inspecting an entire target structure<ref name=\"GalceranCarreras2013\">{{cite journal|last1=Galceran|first1=Enric|last2=Carreras|first2=Marc|title=A survey on coverage path planning for robotics|journal=Robotics and Autonomous Systems|volume=61|issue=12|year=2013|pages=1258–1276|issn=09218890|doi=10.1016/j.robot.2013.09.004|citeseerx=10.1.1.716.2556}}</ref>. For complex, real-world structures, however, covering 100% of an inspection target is not feasible, and generating an inspection plan may be better viewed as a multiobjective optimization problem, where one aims to both maximize inspection coverage and minimize time and costs. A recent study has indicated that multiobjective inspection planning indeed has the potential to outperform traditional methods on complex structures<ref name=\"EllefsenLepikson2017\">{{cite journal|last1=Ellefsen|first1=K.O.|last2=Lepikson|first2=H.A.|last3=Albiez|first3=J.C.|title=Multiobjective coverage path planning: Enabling automated inspection of complex, real-world structures|journal=Applied Soft Computing|volume=61|year=2017|pages=264–282|issn=15684946|doi=10.1016/j.asoc.2017.07.051|url=https://www.researchgate.net/publication/318893583|hdl=10852/58883|arxiv=1901.07272}}</ref>\n\n== Solution ==\n\nAs there usually exist multiple [[Pareto optimality|Pareto optimal]] solutions for multi-objective optimization problems, what it means to solve such a problem is not as straightforward as it is for a conventional single-objective optimization problem. Therefore, different researchers have defined the term \"solving a multi-objective optimization problem\" in various ways. This section summarizes some of them and the contexts in which they are used. Many methods convert the original problem with multiple objectives into a single-objective [[optimization problem]]. This is called a scalarized problem. If scalarization is done neatly,{{Clarify|reason=What does \"neatly\" mean?|date=October 2018}} Pareto optimality of the solutions obtained can be guaranteed.\n\nSolving a multi-objective optimization problem is sometimes understood as approximating or computing all or a representative set of Pareto optimal solutions.<ref name=\"Ehrgott2005\">{{cite book|author=Matthias Ehrgott|title=Multicriteria Optimization|url=https://books.google.com/books?id=yrZw9srrHroC|accessdate=29 May 2012|date=1 June 2005|publisher=Birkhäuser|isbn=978-3-540-21398-7}}</ref><ref name=\"CoelloLamont2007\">{{cite book|author1=Carlos A. Coello Coello|author2=Gary B. Lamont|author3=David A. Van Veldhuisen|title=Evolutionary Algorithms for Solving Multi-Objective Problems|url=https://books.google.com/books?id=rXIuAMw3lGAC|accessdate=1 November 2012|year=2007|publisher=Springer|isbn=978-0-387-36797-2}}</ref>\n\nWhen [[Multiple-criteria decision analysis|decision making]] is emphasized, the objective of solving a multi-objective optimization problem is referred to supporting a decision maker in finding the most preferred Pareto optimal solution according to his/her subjective preferences.<ref name=\"Miettinen1999\">{{cite book|author=Kaisa Miettinen|title=Nonlinear Multiobjective Optimization|url=https://books.google.com/books?id=ha_zLdNtXSMC|accessdate=29 May 2012|year=1999|publisher=Springer|isbn=978-0-7923-8278-2}}</ref><ref name=\"BrankeDeb2008\">{{cite book|author1=Jürgen Branke|author2=Kalyanmoy Deb|author3=Kaisa Miettinen|author4=Roman Slowinski|title=Multiobjective Optimization: Interactive and Evolutionary Approaches|url=https://books.google.com/books?id=N-1hWMNUa2EC|accessdate=1 November 2012|date=21 November 2008|publisher=Springer|isbn=978-3-540-88907-6}}</ref> The underlying assumption is that one solution to the problem must be identified to be implemented in practice. Here, a human [[decision maker]] (DM) plays an important role. The DM is expected to be an expert in the problem domain.\n\nThe most preferred results can be found using different philosophies. Multi-objective optimization methods can be divided into four classes.<ref name=\"HwangMasud1979\">{{cite book|author1=Ching-Lai Hwang|author2=Abu Syed Md Masud|title=Multiple objective decision making, methods and applications: a state-of-the-art survey|url=https://books.google.com/books?id=Hz-yAAAAIAAJ|accessdate=29 May 2012|year=1979|publisher=Springer-Verlag|isbn=978-0-387-09111-2}}</ref> In so-called no preference methods, no DM is expected to be available, but a neutral compromise solution is identified without preference information.<ref name=\"Miettinen1999\">{{cite book|author=Kaisa Miettinen|title=Nonlinear Multiobjective Optimization|url=https://books.google.com/books?id=ha_zLdNtXSMC|accessdate=29 May 2012|year=1999|publisher=Springer|isbn=978-0-7923-8278-2}}</ref> The other classes are so-called a priori, a posteriori and interactive methods and they all involve preference information from the DM in different ways.\n\nIn a priori methods, preference information is first asked from the DM and then a solution best satisfying these preferences is found. In a posteriori methods, a representative set of Pareto optimal solutions is first found and then the DM must choose one of them. In interactive methods, the decision maker is allowed to iteratively search for the most preferred solution. In each iteration of the interactive method, the DM is shown Pareto optimal solution(s) and describes how the solution(s) could be improved. The information given by the decision maker is then taken into account while generating new Pareto optimal solution(s) for the DM to study in the next iteration. In this way, the DM learns about the feasibility of his/her wishes and can concentrate on solutions that are interesting to him/her. The DM may stop the search whenever he/she wants to. More information and examples of different methods in the four classes are given in the following sections.\n\n== Scalarizing  ==\n\nScalarizing a multi-objective optimization problem is an a priori method, which means formulating a single-objective optimization problem such that optimal solutions to the single-objective optimization problem are Pareto optimal solutions to the multi-objective optimization problem.<ref name=\"HwangMasud1979\"/> In addition, it is often required that every Pareto optimal solution can be reached with some parameters of the scalarization.<ref name=\"HwangMasud1979\">{{cite book|author1=Ching-Lai Hwang|author2=Abu Syed Md Masud|title=Multiple objective decision making, methods and applications: a state-of-the-art survey|url=https://books.google.com/books?id=Hz-yAAAAIAAJ|accessdate=29 May 2012|year=1979|publisher=Springer-Verlag|isbn=978-0-387-09111-2}}</ref> With different parameters for the scalarization, different Pareto optimal solutions are produced. A general formulation for a scalarization of a multiobjective optimization is thus\n:<math>\n\\begin{array}{ll}\n\\min & g(f_1(x),\\ldots,f_k(x),\\theta)\\\\\n\\text{s.t }x\\in X_\\theta,\n\\end{array}\n</math> \nwhere <math>\\theta</math> is a vector parameter, the set <math>X_\\theta\\subseteq X</math> is a set depending on the parameter <math>\\theta</math> and <math>g:\\mathbb R^{k+1}\\mapsto \\mathbb R</math> is a function.\n\nVery well-known examples are the so-called\n\n* '''linear scalarization''' \n::<math>\n\\min_{x\\in X} \\sum_{i=1}^k w_if_i(x),\n</math>\n:where the weights of the objectives <math>w_i>0</math> are the parameters of the scalarization, and the\n\n* '''<math>\\epsilon</math>-constraint method''' (see, e.g.<ref name=\"Miettinen1999\"/>)\n::<math>\n\\begin{array}{ll}\n\\min & f_j(x)\\\\\n\\text{s.t. }&x \\in X\\\\\n            &f_i(x)\\leq \\epsilon_j \\text{ for }i\\in\\{1,\\ldots,k\\}\\setminus\\{j\\},\n\\end{array}\n</math>\n:where upper bounds <math> \\epsilon_j</math> are parameters as above and <math> f_j </math> is the objective to be minimized.\n\nSomewhat more advanced examples are the:\n*  '''achievement scalarizing problems of Wierzbicki'''.<ref name=\"Wierzbicki1982\">{{Cite journal | doi = 10.1016/0270-0255(82)90038-0| title = A mathematical basis for satisficing decision making| year = 1982| last1 = Wierzbicki | first1 = A. P. | journal = Mathematical Modelling| volume = 3| issue = 5| pages = 391–405}}</ref> One example of the achievement scalarizing problems can be formulated as \n:<math>\n\\begin{array}{ll}\n\\min & \\max_{i=1,\\ldots,k} \\left[ \\frac{f_i(x)-\\bar z_i}{z^{\\text{nad}}_i-z_i^{\\text{utopia}}}\\right] + \\rho\\sum_{i=1}^k\\frac{f_i(x)}{z_i^{nad}-z_i^{\\text{utopian}}}\\\\\n\\text{subject to }& x\\in S,\n\\end{array}\n</math>\n:where the term <math>\\rho\\sum_{i=1}^k\\frac{f_i(x)}{z_i^{nad}-z_i^{\\text{utopia}}}</math> is called the augmentation term, <math>\\rho>0</math> is a small constant, and <math>z^{\\text{nad}}</math> and <math>z^{\\text{utopian}}</math> are the nadir vector and a utopian vectors, respectively. In the above problem, the parameter is the so-called reference point <math>\\bar z</math> which represents objective function values preferred by the decision maker.\n\n* '''Sen's Multi-Objective Programming'''<ref>Sen, Chandra, (1983) A new approach for multi-objective rural development planning, The Indian Economic Journal, Vol.30, (4), 91-96.</ref>\n<math display=\"block\"> \n\\begin{array}{ll}\n\\max & \\frac{\\sum_{j=1}^r  Z_j}{W_j}- \\frac{\\sum_{j=r+1}^s  Z_j}{W_{r+1}} \\\\\n\\text{s.t. }&AX=b \\\\\n            &X\\geq 0,\n\\end{array}\n</math>\n:where <math>W_j</math> is individual optima (Absolute) for objectives of maximization <math>r</math> and minimization <math>r+1</math> to <math>s</math>.  \n\nFor example, [[portfolio optimization]] is often conducted in terms of [[Modern portfolio theory|mean-variance analysis]]. In this context, the efficient set is a subset of the portfolios parametrized by the portfolio mean return <math>\\mu_P</math> in the problem of choosing portfolio shares so as to minimize the portfolio's variance of return <math>\\sigma_P</math> subject to a given value of <math>\\mu_P</math>; see [[Mutual fund separation theorem#Portfolio separation in mean-variance analysis|Mutual fund separation theorem]] for details. Alternatively, the efficient set can be specified by choosing the portfolio shares so as to maximize the function <math>\\mu_P - b \\sigma_P </math>; the set of efficient portfolios consists of the solutions as ''b'' ranges from zero to infinity.\n\n== No-preference methods ==\n\nWhen a decision maker does not explicitly articulate any preference information  the multi-objective optimization method can be classified as no-preference method.<ref name=\"HwangMasud1979\"/> A well-known example is the method of global criterion,<ref name=\"Zeleny1973\">{{Citation\n| last1 = Zeleny\n| first1 = M.\n| chapter = Compromise Programming\n| editor-last = Cochrane\n| editor-first = J.L.\n| editor2-last = Zeleny\n| editor2-first = M.\n| pages = 262–301\n| title = Multiple Criteria Decision Making\n| publisher = University of South Carolina Press, Columbia\n| year = 1973\n}}</ref> in which a scalarized problem of the form\n:<math>\n\\begin{align}\n\\min&\\|f(x)-z^{ideal}\\|\\\\\n\\text{s.t. }&x\\in X\n\\end{align}\n</math>\nis solved. In the above problem, <math>\\|\\cdot\\|</math> can be any [[Lp space#The p-norm in finite dimensions|<math>L_p</math> norm]], with common choices including <math>L_1</math>, <math>L_2</math> and <math>L_\\infty</math>.<ref name=\"Miettinen1999\">{{cite book|author=Kaisa Miettinen|title=Nonlinear Multiobjective Optimization|url=https://books.google.com/books?id=ha_zLdNtXSMC|accessdate=29 May 2012|year=1999|publisher=Springer|isbn=978-0-7923-8278-2}}</ref> The method of global criterion is sensitive to the scaling of the objective functions, and thus, it is recommended that the objectives are normalized into a uniform, dimensionless scale.<ref name=\"Miettinen1999\">{{cite book|author=Kaisa Miettinen|title=Nonlinear Multiobjective Optimization|url=https://books.google.com/books?id=ha_zLdNtXSMC|accessdate=29 May 2012|year=1999|publisher=Springer|isbn=978-0-7923-8278-2}}</ref><ref name=\"BrankeDeb2008\"/>\n\n== A priori methods ==\n\nA priori methods require that sufficient preference information is expressed before the solution process.<ref name=\"HwangMasud1979\">{{cite book|author1=Ching-Lai Hwang|author2=Abu Syed Md Masud|title=Multiple objective decision making, methods and applications: a state-of-the-art survey|url=https://books.google.com/books?id=Hz-yAAAAIAAJ|accessdate=29 May 2012|year=1979|publisher=Springer-Verlag|isbn=978-0-387-09111-2}}</ref> Well-known examples of a priori methods include the '''utility function method''', [[Lexicographical order|lexicographic]] method, and [[goal programming]].\n\nIn the utility function method, it is assumed that the decision maker's [[utility|utility function]] is available. A mapping <math> u\\colon Y\\rightarrow\\mathbb{R}</math> is a utility function if for all <math>\\mathbf{y}^1,\\mathbf{y}^2\\in Y</math> if it holds that <math>u(\\mathbf{y}^1)>u(\\mathbf{y}^2)</math> if the decision maker prefers <math>\\mathbf{y}^1</math> to <math>\\mathbf{y}^2</math>, and <math>u(\\mathbf{y}^1)=u(\\mathbf{y}^2)</math> if the decision maker is indifferent between <math>\\mathbf{y}^1</math> and <math>\\mathbf{y}^2</math>. The utility function specifies an ordering of the decision vectors (recall that vectors can be ordered in many different ways). Once <math>u</math> is obtained, it suffices to solve\n:<math>    \\max\\;u(\\mathbf{f}(\\mathbf{x}))\\text{ subject to }\\mathbf{x}\\in X,</math>\nbut in practice it is very difficult to construct a utility function that would accurately represent the decision maker's preferences<ref name=\"Miettinen1999\">{{cite book|author=Kaisa Miettinen|title=Nonlinear Multiobjective Optimization|url=https://books.google.com/books?id=ha_zLdNtXSMC|accessdate=29 May 2012|year=1999|publisher=Springer|isbn=978-0-7923-8278-2}}</ref> - particularly since the Pareto front is unknown before the optimization begins.\n\nThe [[lexicographic preferences|lexicographic]] method assumes that the objectives can be ranked in the order of importance. We can assume, without loss of generality, that the objective functions are in the order of importance so that <math>f_1</math> is the most important and <math>f_k</math> the least important to the decision maker. The lexicographic method consists of solving a sequence of single-objective optimization problems of the form\n:<math>\n\\begin{align}\n    \\min&f_l(\\mathbf{x})\\\\\n    \\text{s.t. }&f_j(\\mathbf{x})\\leq\\mathbf{y}^*_j,\\;j=1,\\dotsc,l-1,\\\\\n    &\\mathbf{x}\\in X,\n\\end{align}\n</math>\nwhere <math>\\mathbf{y}^*_j</math> is the optimal value of the above problem with <math>l=j</math>. Thus, <math>\\mathbf{y}^*_1:=\\min\\{f_1(\\mathbf{x})\\mid\\mathbf{x}\\in X\\}</math> and each new problem of the form in the above problem in the sequence adds one new constraint as <math>l</math> goes from <math>1</math> to <math>k</math>. Note that a goal or target value is not specified for any objective here, which makes it different from the Lexicographic [[Goal Programming]] method.\n\n== A posteriori methods ==\n\nA posteriori methods aim at producing all the Pareto optimal solutions or a representative subset of the Pareto optimal solutions. Most a posteriori methods fall into either one of the following two classes: [[mathematical programming]]-based a posteriori methods, where an algorithm is repeated and each run of the algorithm produces one Pareto optimal solution, and [[evolutionary algorithm]]s where one run of the algorithm produces a set of Pareto optimal solutions.\n\nWell-known examples of mathematical programming-based a posteriori methods are the Normal Boundary Intersection (NBI),<ref name=\"doi10.1137/S1052623496307510\">{{Cite journal | last1 = Das | first1 = I. | last2 = Dennis | first2 = J. E. | doi = 10.1137/S1052623496307510 | title = Normal-Boundary Intersection: A New Method for Generating the Pareto Surface in Nonlinear Multicriteria Optimization Problems | journal = SIAM Journal on Optimization | volume = 8 | issue = 3 | pages = 631 | year = 1998 | pmid =  | pmc = }}</ref> Modified Normal Boundary Intersection (NBIm) <ref name=\"S. Motta\">{{cite journal|last=S. Motta|first=Renato|author2=Afonso, Silvana M. B. |author3=Lyra, Paulo R. M. |title=A modified NBI and NC method for the solution of N-multiobjective optimization problems|journal=Structural and Multidisciplinary Optimization|date=8 January 2012|doi=10.1007/s00158-011-0729-5|volume=46|issue=2|pages=239–259}}</ref> Normal Constraint (NC),<ref name=\"ReferenceA\">{{cite journal|first1=A.|last1=Messac|first2=A.|last2=Ismail-Yahaya|first3=C.A.|last3=Mattson|title=The normalized normal constraint method for generating the Pareto frontier|journal=Structural and Multidisciplinary Optimization|volume=25|issue=2|pages=86–98|year=2003|doi=10.1007/s00158-002-0276-1}}</ref><ref name=\"ReferenceB\">{{cite journal|first1=A.|last1=Messac|first2=C. A.|last2=Mattson|title=Normal constraint method with guarantee of even representation of complete Pareto frontier|journal=AIAA Journal|volume=42|issue=10|pages=2101–2111|year=2004|doi=10.2514/1.8977}}</ref> Successive Pareto Optimization (SPO)<ref name=\"ReferenceC\">{{cite journal|first1=Daniel|last1=Mueller-Gritschneder|first2=Helmut|last2=Graeb|first3=Ulf|last3=Schlichtmann|title=A Successive Approach to Compute the Bounded Pareto Front of Practical Multiobjective Optimization Problems|journal=SIAM Journal on Optimization|volume=20|issue=2|pages=915–934|year=2009|doi=10.1137/080729013}}</ref> and Directed Search Domain (DSD)<ref name=\"EU11\">{{cite journal|url=http://personalpages.manchester.ac.uk/staff/S.Utyuzhnikov/Papers/DSDreprint.pdf|accessdate=October 17, 2011|first1=Tohid|last1=Erfani|first2=Sergei V.|last2=Utyuzhnikov|title=Directed Search Domain: A Method for Even Generation of Pareto Frontier in Multiobjective Optimization|journal=Journal of Engineering Optimization|volume=43|issue=5|pages=1–18|year=2011|doi=10.1080/0305215X.2010.497185}}</ref> methods that solve the multi-objective optimization problem by constructing several scalarizations. The solution to each scalarization yields a Pareto optimal solution, whether locally or globally. The scalarizations of the NBI, NBIm, NC and DSD methods are constructed with the target of obtaining evenly distributed Pareto points that give a good evenly distributed approximation of the real set of Pareto points.\n\n[[Evolutionary algorithms]] are popular approaches to generating Pareto optimal solutions to a multi-objective optimization problem. Currently, most evolutionary multi-objective optimization (EMO) algorithms apply Pareto-based ranking schemes. Evolutionary algorithms such as the Non-dominated Sorting Genetic Algorithm-II (NSGA-II) <ref name=\"doi10.1109/4235.996017\">{{Cite journal | doi = 10.1109/4235.996017| title = A fast and elitist multiobjective genetic algorithm: NSGA-II| journal = IEEE Transactions on Evolutionary Computation| volume = 6| issue = 2| pages = 182| year = 2002| last1 = Deb | first1 = K.| last2 = Pratap | first2 = A.| last3 = Agarwal | first3 = S.| last4 = Meyarivan | first4 = T.| citeseerx = 10.1.1.17.7771}}</ref> and Strength Pareto Evolutionary Algorithm 2 (SPEA-2)<ref>Zitzler, E., Laumanns, M., Thiele, L.: SPEA2: Improving the Performance of the Strength Pareto Evolutionary Algorithm, Technical Report 103, Computer Engineering and Communication Networks Lab (TIK), Swiss Federal Institute of Technology (ETH) Zurich (2001) [http://www.tik.ee.ethz.ch/publications/?db=publications&form=report_single_publication&publication_id=1319]</ref> have become standard approaches, although some schemes based on [[Particle swarm optimization#Variants|particle swarm optimization]] and [[simulated annealing]]<ref>{{cite journal|first1=B.|last1=Suman|first2=P.|last2=Kumar|title=A survey of simulated annealing as a tool for single and multiobjective optimization|journal=Journal of the Operational Research Society|volume=57|issue=10|pages=1143–1160|year=2006|doi=10.1057/palgrave.jors.2602068}}</ref> are significant. The main advantage of evolutionary algorithms, when applied to solve multi-objective optimization problems, is the fact that they typically generate sets of solutions, allowing computation of an approximation of the entire Pareto front. The main disadvantage of evolutionary algorithms is their lower speed and the Pareto optimality of the solutions cannot be guaranteed. It is only known that none of the generated solutions dominates the others.\n\nAnother paradigm for multi-objective optimization based on novelty using evolutionary algorithms was recently improved upon.<ref name=vargas2015>Danilo Vasconcellos Vargas, Junichi Murata, Hirotaka Takano, Alexandre Claudio Botazzo Delbem (2015), \"General Subpopulation Framework and Taming the Conflict Inside Populations\", Evolutionary computation 23 (1), 1-36.</ref> This paradigm searches for novel solutions in objective space (i.e., novelty search<ref>Lehman, Joel, and Kenneth O. Stanley. \"Abandoning objectives: Evolution through the search for novelty alone.\" Evolutionary computation 19.2 (2011): 189-223.</ref> on objective space) in addition to the search for non-dominated solutions. Novelty search is like stepping stones guiding the search to previously unexplored places. It is specially useful in overcoming bias and plateaus as well as guiding the search in many-objective optimization problems. \n\nCommonly known a posteriori methods are listed below:\n* Normal Boundary Intersection (NBI) <ref name=\"doi10.1137/S1052623496307510\"/>\n* Modified Normal Boundary Intersection (NBIm) <ref name=\"S. Motta\"/> Normal Constraint (NC),<ref name=\"ReferenceA\"/><ref name=\"ReferenceB\"/>\n* Successive Pareto Optimization (SPO)<ref name=\"ReferenceC\"/> \n* Directed Search Domain (DSD)<ref name=\"EU11\">{{cite journal|url=http://personalpages.manchester.ac.uk/staff/S.Utyuzhnikov/Papers/DSDreprint.pdf|accessdate=October 17, 2011|first1=Tohid|last1=Erfani|first2=Sergei V.|last2=Utyuzhnikov|title=Directed Search Domain: A Method for Even Generation of Pareto Frontier in Multiobjective Optimization|journal=Journal of Engineering Optimization|volume=43|issue=5|pages=1–18|year=2011|doi=10.1080/0305215X.2010.497185}}</ref>\n* NSGA-II  <ref name=\"doi10.1109/4235.996017\"/>  \n* PGEN (Pareto surface generation for convex multi-objective instances)<ref>{{cite journal|first1=D.|last1=Craft|first2=T.|last2=Halabi|first3=H.|last3=Shih|first4=T.|last4=Bortfeld|title= Approximating convex Pareto surfaces in multiobjective radiotherapy planning|journal=Medical Physics|volume=33|issue=9|pages=3399–3407|year=2006|doi=10.1118/1.2335486|pmid=17022236}}</ref>\n* [[IOSO]] (Indirect Optimization on the basis of Self-Organization)\n* SMS-EMOA (S-metric selection evolutionary multi-objective algorithm)<ref name=SMS-EMOA>{{Cite journal | last1 = Beume | first1 = N. | last2 = Naujoks | first2 = B. | last3 = Emmerich | first3 = M. | doi = 10.1016/j.ejor.2006.08.008 | title = SMS-EMOA: Multiobjective selection based on dominated hypervolume | journal = European Journal of Operational Research | volume = 181 | issue = 3 | pages = 1653 | year = 2007 | pmid =  | pmc = }}</ref>\n* Approximation-Guided Evolution (first algorithm to directly implement and optimise the formal concept of [[Approximation algorithm|approximation]] from theoretical computer science)<ref name=AGE>{{Cite journal | last1 = Bringmann | first1 = Karl | last2 = Friedrich | first2 = Tobias | last3 = Neumann | first3 = Frank | last4 = Wagner | first4 = Markus | doi = 10.5591/978-1-57735-516-8/IJCAI11-204 | title = Approximation-Guided Evolutionary Multi-Objective Optimization | journal = IJCAI | volume =  | issue =  | pages =  | year = 2011 | pmid =  | pmc = }}</ref>\n* [[Reactive Search Optimization]] (using machine learning for adapting strategies and objectives),<ref>{{cite book\n|title=Reactive Search and Intelligent Optimization\n|last=Battiti|first=Roberto|authorlink=|author2=Mauro Brunato |author3=Franco Mascia |year=2008|publisher=[[Springer Verlag]]|location=|isbn=978-0-387-09623-0}}</ref><ref>{{cite book|title=Reactive Business Intelligence. From Data to Models to Insight.|last=Battiti|first=Roberto|authorlink=|author2=Mauro Brunato| url        =http://www.reactivebusinessintelligence.com/|year=2011|publisher= Reactive Search Srl|location= Trento, Italy|isbn=978-88-905795-0-9}}</ref> implemented in [[LIONsolver]]\n*[[Benson's algorithm]] for [[Multi-objective linear programming|multiple objective linear programs]] and for multiple objective convex programs\n*[[Particle swarm optimization#Variants|Multi-objective particle swarm optimization]]\n*Subpopulation Algorithm based on Novelty<ref name=vargas2015>Danilo Vasconcellos Vargas, Junichi Murata, Hirotaka Takano, Alexandre Claudio Botazzo Delbem (2015), \"General Subpopulation Framework and Taming the Conflict Inside Populations\", Evolutionary computation 23 (1), 1-36.</ref>\n\n== Interactive methods ==\n\nIn interactive methods of optimizing multiple objective problems, the solution process is iterative and the decision maker continuously interacts with the method when searching for the most preferred solution (see e.g. Miettinen 1999<ref name = Miettinen1999/>, Miettinen 2008<ref name = Miettinen2008/>). In other words, the decision maker is expected to express preferences at each iteration in order to get ''Pareto optimal solutions'' that are of interest to the decision maker and learn what kind of solutions are attainable. \n\nThe following steps are commonly present in interactive methods of optimization :<ref name=Miettinen2008>{{Cite book | last1 = Miettinen | first1 = K. | last2 = Ruiz | first2 = F. | last3 = Wierzbicki | first3 = A. P. | doi = 10.1007/978-3-540-88908-3_2 | chapter = Introduction to Multiobjective Optimization: Interactive Approaches | title = Multiobjective Optimization | series = Lecture Notes in Computer Science | volume = 5252 | pages = 27 | year = 2008 | isbn = 978-3-540-88907-6 | pmid =  | pmc = | citeseerx = 10.1.1.475.465 }}</ref>\n\n# initialize (e.g. calculate ideal and approximated nadir objective vectors and show them to the decision maker)\n# generate a Pareto optimal starting point (by using e.g. some no-preference method or solution given by the decision maker)\n# ask for preference information from the decision maker (e.g. aspiration levels or number of new solutions to be generated)\n# generate new Pareto optimal solution(s) according to the preferences and show it/them and possibly some other information about the problem to the decision maker\n# if several solutions were generated, ask the decision maker to select the best solution so far\n# stop (if the decision maker wants to; otherwise, go to step 3).\n\nThe above aspiration levels refer to desirable objective function values forming a reference point. Instead of mathematical convergence that is often used as a stopping criterion in [[mathematical optimization]] methods, a psychological convergence is often emphasized in interactive methods. Generally speaking, a method is terminated when the decision maker is confident that he/she has found the ''most preferred solution available''.\n\n=== Types of preference information ===\nThere are different interactive methods involving different types of preference information. Three of those types can be identified  based on \n# trade-off information, \n# reference points and \n# classification of objective functions.<ref name=Miettinen2008/>\n\nOn the other hand, a fourth type of generating a small sample of solutions is included in<ref name=Luque2011>{{Cite journal | last1 = Luque | first1 = M. | last2 = Ruiz | first2 = F. | last3 = Miettinen | first3 = K. | title = Global formulation for interactive multiobjective optimization | doi = 10.1007/s00291-008-0154-3 | journal = OR Spectrum | volume = 33 | pages = 27–48 | year = 2008 | pmid =  | pmc = | url = http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-65364 }}</ref> and.<ref name=Ruiz2012>{{Cite journal | last1 = Ruiz | first1 = F. | last2 = Luque | first2 = M. | last3 = Miettinen | first3 = K. | title = Improving the computational efficiency in a global formulation (GLIDE) for interactive multiobjective optimization | doi = 10.1007/s10479-010-0831-x | journal = Annals of Operations Research | volume = 197 | pages = 47–70 | year = 2011 | pmid =  | pmc = | url = http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-63800 }}</ref> An example of interactive method utilizing trade-off information is the [[Zionts-Wallenius method]],<ref name=Zionts1976>{{Cite journal | last1 = Zionts | first1 = S. | last2 = Wallenius | first2 = J. | doi = 10.1287/mnsc.22.6.652 | title = An Interactive Programming Method for Solving the Multiple Criteria Problem | journal = Management Science | volume = 22 | issue = 6 | pages = 652 | year = 1976 | pmid =  | pmc = }}</ref> where the decision maker is shown several objective trade-offs at each iteration, and (s)he is expected to say whether (s)he likes, dislikes or is indifferent with respect to each trade-off. In reference point based methods (see e.g.<ref name=Wierzbicki1986>{{Cite journal | last1 = Wierzbicki | first1 = A. P. | title = On the completeness and constructiveness of parametric characterizations to vector optimization problems | doi = 10.1007/BF01719738 | journal = OR Spektrum | volume = 8 | issue = 2 | pages = 73–78 | year = 1986 | pmid =  | pmc = }}</ref><ref name=\"WierzbickiMakowski2000\">{{cite book|author1=Andrzej P. Wierzbicki|author2=Marek Makowski|author3-link=Jaap Wessels|author3=Jaap Wessels|title=Model-Based Decision Support Methodology with Environmental Applications|url=https://books.google.com/books?id=Von7GW4h68MC|accessdate=17 September 2012|date=31 May 2000|publisher=Springer|isbn=978-0-7923-6327-9}}</ref>), the decision maker is expected at each iteration to specify a reference point consisting of desired values for each objective and a corresponding Pareto optimal solution(s) is then computed and shown to him/her for analysis. In classification based interactive methods, the decision maker is assumed to give preferences in the form of classifying objectives at the current Pareto optimal solution into different classes indicating how the values of the objectives should be changed to get a more preferred solution. Then, the classification information given is taken into account when new (more preferred) Pareto optimal solution(s) are computed. In the satisficing trade-off method (STOM)<ref name=\"Nakayama1984\">{{Citation\n| last1 = Nakayama\n| first1 = H.\n| last2 = Sawaragi\n| first2 = Y.\n| chapter = Satisficing Trade-Off Method for Multiobjective Programming\n| editor-last = Grauer\n| editor-first = M.\n| editor2-last = Wierzbicki\n| editor2-first = A. P.\n| pages = 113–122\n| title = Interactive Decision Analysis\n| publisher = Springer-Verlag Berlin, Heidelberg\n| year = 1984\n}}</ref> three classes are used: objectives whose values 1) should be improved, 2) can be relaxed, and 3) are acceptable as such. In the NIMBUS method,<ref name=\"Miettinen1995\">{{Cite journal | last1 = Miettinen | first1 = K. | last2 = Mäkelä | first2 = M. M. | doi = 10.1080/02331939508844109 | title = Interactive bundle-based method for nondifferentiable multiobjeective optimization: Nimbus§ | journal = Optimization | volume = 34 | issue = 3 | pages = 231 | year = 1995 | pmid =  | pmc = }}</ref><ref name=\"Miettinen2006\">{{Cite journal | last1 = Miettinen | first1 = K. | last2 = Mäkelä | first2 = M. M. | doi = 10.1016/j.ejor.2004.07.052 | title = Synchronous approach in interactive multiobjective optimization | journal = European Journal of Operational Research | volume = 170 | issue = 3 | pages = 909 | year = 2006 | pmid =  | pmc = }}</ref> two additional classes are also used: objectives whose values 4) should be improved until a given bound and 5) can be relaxed until a given bound.\n\n== Hybrid methods ==\n\nDifferent [[hybrid algorithm|hybrid]] methods exist, but here we consider hybridizing MCDM ([[multi-criteria decision making]]) and EMO (evolutionary multi-objective optimization). A hybrid algorithm in the context of multi-objective optimization is a combination of algorithms/approaches from these two fields (see e.g.<ref name=Miettinen2008/>). Hybrid algorithms of EMO and MCDM are mainly used to overcome shortcomings by utilizing strengths. Several types of hybrid algorithms have been proposed in the literature, e.g. incorporating MCDM approaches into EMO algorithms as a local search operator and to lead a DM to the most preferred solution(s) etc. A local search operator is mainly used to enhance the rate of convergence of EMO algorithms.\n\nThe roots for hybrid multi-objective optimization can be traced to the first Dagstuhl seminar organized in November 2004 (see, [http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=04461 here]). Here some of the best minds{{Citation needed|date=July 2018}} in EMO (Professor Kalyanmoy Deb, Professor Jürgen Branke etc.) and MCDM (Professor Kaisa Miettinen, Professor Ralph E. Steuer etc.) realized the potential in combining ideas and approaches of MCDM and EMO fields to prepare hybrids of them. Subsequently many more Dagstuhl seminars have been arranged to foster collaboration. Recently, hybrid multi-objective optimization has become an important theme in several international conferences in the area of EMO and MCDM (see e.g.<ref name=Sindhya2011>{{Cite book | last1 = Sindhya | first1 = K. | last2 = Ruiz | first2 = A. B. | last3 = Miettinen | first3 = K. | doi = 10.1007/978-3-642-19893-9_15 | chapter = A Preference Based Interactive Evolutionary Algorithm for Multi-objective Optimization: PIE | title = Evolutionary Multi-Criterion Optimization | series = Lecture Notes in Computer Science | volume = 6576 | pages = 212 | year = 2011 | isbn = 978-3-642-19892-2 | pmid =  | pmc = }}</ref> and.<ref name=Sindhya2008>{{Cite book | last1 = Sindhya | first1 = K. | last2 = Deb | first2 = K. | last3 = Miettinen | first3 = K. | doi = 10.1007/978-3-540-87700-4_81 | chapter = A Local Search Based Evolutionary Multi-objective Optimization Approach for Fast and Accurate Convergence | title = Parallel Problem Solving from Nature – PPSN X | series = Lecture Notes in Computer Science | volume = 5199 | pages = 815 | year = 2008 | isbn = 978-3-540-87699-1 | pmid =  | pmc = }}</ref>)\n\n== Visualization of the Pareto front ==\n\nVisualization of the Pareto front is one of the a posteriori preference techniques of multi-objective optimization. The a posteriori preference techniques (see, for example,<ref name=\"Miettinen1999\"/>) provide an important class of multi-objective optimization techniques. Usually the a posteriori preference techniques include four steps: (1) computer approximates the Pareto front, i.e. the Pareto optimal set in the objective space; (2) the decision maker studies the Pareto front approximation; (3) the decision maker identifies the preferred point at the Pareto front; (4) computer provides the Pareto optimal decision, which output coincides with the objective point identified by the decision maker. From the point of view of the decision maker, the second step of the a posteriori preference techniques is the most complicated one. There are two main approaches to informing the decision maker. First, a number of points of the Pareto front can be provided in the form of a list (interesting discussion and references are given in<ref name=\"BensonSayin1997\">{{cite journal|last1=Benson|first1=Harold P.|last2=Sayin|first2=Serpil|title=Towards finding global representations of the efficient set in multiple objective mathematical programming|journal=Naval Research Logistics|volume=44|issue=1|year=1997|pages=47–67|issn=0894-069X|doi=10.1002/(SICI)1520-6750(199702)44:1<47::AID-NAV3>3.0.CO;2-M|hdl=11693/25666}}</ref>) or using Heatmaps.<ref name=\"Pryke,Mostaghim,Nazemi\">{{cite book|last=Pryke|first=Andy|author2=Sanaz Mostaghim |author3=Alireza Nazemi |title=Heatmap Visualisation of Population Based Multi Objective Algorithms|journal=Evolutionary Multi-Criterion Optimization|volume=4403|year=2007|pages=361–375|doi=10.1007/978-3-540-70928-2_29|series=Lecture Notes in Computer Science|isbn=978-3-540-70927-5}}</ref>\n\n=== Visualization in bi-objective problems: tradeoff curve ===\n\nIn the case of bi-objective problems, informing the decision maker concerning the Pareto front is usually carried out by its visualization: the Pareto front, often named the tradeoff curve in this case, can be drawn at the objective plane. The tradeoff curve gives full information on objective values and on objective tradeoffs, which inform how improving one objective is related to deteriorating the second one while moving along the tradeoff curve. The decision maker takes this information into account while specifying the preferred Pareto optimal objective point. The idea to approximate and visualize the Pareto front was introduced for linear bi-objective decision problems by S.Gass and T.Saaty.<ref name=\"GassSaaty1955\">{{cite journal|last1=Gass|first1=Saul|last2=Saaty|first2=Thomas|title=The computational algorithm for the parametric objective function|journal=Naval Research Logistics Quarterly|volume=2|issue=1–2|year=1955|pages=39–45|issn=0028-1441|doi=10.1002/nav.3800020106}}</ref> This idea was developed and applied in environmental problems by J.L. Cohon.<ref name=\"Cohon2004\">{{cite book|author=Jared L. Cohon|title=Multiobjective Programming and Planning|url=https://books.google.com/books?id=i4Qese2aNooC|accessdate=29 May 2012|date=13 January 2004|publisher=Courier Dover Publications|isbn=978-0-486-43263-2}}</ref> A review of methods for approximating the Pareto front for various decision problems with a small number of objectives (mainly, two) is provided in.<ref name=\"RuzikaWiecek2005\">{{cite journal|last1=Ruzika|first1=S.|last2=Wiecek|first2=M. M.|title=Approximation Methods in Multiobjective Programming|journal=Journal of Optimization Theory and Applications|volume=126|issue=3|year=2005|pages=473–501|issn=0022-3239|doi=10.1007/s10957-005-5494-4}}</ref>\n\n=== Visualization in high-order multi-objective optimization problems ===\nThere are two generic ideas how to visualize the Pareto front in high-order multi-objective decision problems (problems with more than two objectives). One of them, which is applicable in the case of a relatively small number of objective points that represent the Pareto front, is based on using the visualization techniques developed in statistics (various diagrams, etc. – see the corresponding subsection below). The second idea proposes the display of bi-objective cross-sections (slices) of the Pareto front. It was introduced by W.S. Meisel in 1973<ref>{{Citation| title = Tradeoff decision in multiple criteria decision making| editor1 = J. L. Cochrane | editor2 = M. Zeleny| journal = Multiple Criteria Decision Making| pages = 461–476 | year = 1973 | last1 = Meisel\t | first1 =  W. L. }}</ref> who argued that such slices inform the decision maker on objective tradeoffs. The figures that display a series of bi-objective slices of the Pareto front for three-objective problems are known as the decision maps. They give a clear picture of tradeoffs between three criteria. Disadvantages of such an approach are related to two following facts. First, the computational procedures for constructing the bi-objective slices of the Pareto front are not stable since the Pareto front is usually not stable. Secondly, it is applicable in the case of only three objectives. In the 1980s, the idea W.S. Meisel of implemented in a different form – in the form of the [[Interactive Decision Maps]] (IDM) technique.<ref name=\"LotovBushenkov2004\">{{cite book|author1=A. V. Lotov|author2=V. A. Bushenkov|author3=G. K. Kamenev|title=Interactive Decision Maps: Approximation and Visualization of Pareto Frontier|url=https://books.google.com/books?id=4OAeBt8gOqcC|accessdate=29 May 2012|date=29 February 2004|publisher=Springer|isbn=978-1-4020-7631-2}}</ref>More recently N. Wesner<ref>{{Citation| title = Multiobjective Optimization via Visualization|  journal = Economics Bulletin| pages = 1226–1233| year = 2017| last1 = Wesner\t | first1 =  N. |volume = 37|number = 2}}</ref> proposed to use a combination of a Venn diagramm and multiple scatterplots views of the objective space for the exploration of the Pareto frontier and the selection of optimal solutions.\n\n== See also ==\n\n*[[Multi-criteria decision analysis]]\n**[[MCDM|Multiple criteria decision making]]\n*[[Multi-objective linear programming]]\n*[[Multidisciplinary design optimization]]\n*[[Pareto efficiency]]\n*[[Goal programming]]\n*[[Concurrent computing|Concurrent programming]]\n*[[Vector optimization]]\n*[[Interactive Decision Maps]]\n*[[Utility function]]\n*[[Decision-making software]]\n\n== References ==\n{{Reflist|2}}\n\n== External links ==\n* [http://mcdmsociety.org/ International Society on Multiple Criteria Decision Making]\n* [http://demonstrations.wolfram.com/EvolutionaryMultiobjectiveOptimization/ Evolutionary Multiobjective Optimization], [[The Wolfram Demonstrations Project]]\n* [http://www.openeering.com/sites/default/files/Multiobjective_Optimization_NSGAII_0.pdf A Tutorial on Multiobjective Optimization and Genetic Algorithms], [[Scilab]] Professional Partner\n* [http://www.mdpi.com/1996-1073/6/3/1439/pdf Tomoiagă, Bogdan; Chindriş, Mircea; Sumper, Andreas; Sudria-Andreu, Antoni; Villafafila-Robles, Roberto. 2013. \"Pareto Optimal Reconfiguration of Power Distribution Systems Using a Genetic Algorithm Based on NSGA-II.\" Energies 6, no. 3: 1439-1455.]\n* [http://www.lania.mx/~ccoello/EMOO/EMOObib.html  List of References on Evolutionary Multiobjective Optimization]\n\n[[Category:Decision analysis]]\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis]]"
    },
    {
      "title": "Multicriteria classification",
      "url": "https://en.wikipedia.org/wiki/Multicriteria_classification",
      "text": "In [[multi-criteria decision analysis|multiple criteria decision aiding]] (MCDA), '''multicriteria classification''' (or sorting) involves problems where a finite set of alternative actions should be assigned into a predefined set of preferentially ordered categories (classes).<ref>{{cite book|last = Doumpos|first = M.|author2=Zopounidis, C|title = Multicriteria Decision Aid Classification Methods|publisher = Kluwer|location = Heidelberg|year = 2002}}</ref> For example, credit analysts classify loan applications into risk categories (e.g., acceptable/unacceptable applicants), customers rate products and classify them into attractiveness groups, candidates for a job position are evaluated and their applications are approved or rejected, technical systems are prioritized for inspection on the basis of their failure risk, etc.\n\n== Problem statement ==\n\nIn a multicriteria classification problem (MCP) a set\n\n: <math> X=\\{\\mathbf{x}_1,\\mathbf{x}_2,\\ldots,\\mathbf{x}_m\\}</math>\n\nof ''m'' alternative actions is available. Each alternative is evaluated over a set of ''n'' criteria. The scope of the analysis is to assign each alternative into a given set of categories (classes) ''C''&nbsp;=&nbsp;{''c''<sub>1</sub>, ''c''<sub>2</sub>, ..., ''c''<sub>''k''</sub>}.\n\nThe categories are defined in an ordinal way. Assuming (without loss of generality) an ascending order, this means that category ''c''<sub>1</sub> consists of the worst alternatives whereas ''c''<sub>''k''</sub> includes the best (most preferred) ones. The alternatives in each category cannot be assumed be equivalent in terms of their overall evaluation (the categories are not [[equivalence class]]es).\n\nFurthermore, the categories are defined independently of the set of alternatives under consideration. In that regard, MCPs are based on an absolute evaluation scheme. For instance, a predefined specific set of categories is often used to classify industrial accidents (e.g., major, minor, etc.). These categories are not related to a specific event under consideration. Of course, in many cases the definition of the categories is adjusted over time to take into consideration the changes in the decision environment.\n\n== Relationship to pattern recognition ==\n\nIn comparison to [[statistical classification]] and [[pattern recognition]] in a [[machine learning]] sense, two main distinguishing features of MCPs can be identified:<ref>{{cite journal|last=Doumpos|first=M.|author2=Zopounidis, C.|title=Preference disaggregation and statistical learning for multicriteria decision support: A review|journal=European Journal of Operational Research|year=2011|volume=209|issue=3|pages=203–214|doi=10.1016/j.ejor.2010.05.029}}</ref><ref>{{cite journal|last=Waegeman|first=W. |author2=De Baets, B. |author3=Boullart, L.|title=Kernel-based learning methods for preference aggregation|journal=4OR|year=2009|volume=7|issue=2|pages=169–189|doi=10.1007/s10288-008-0085-5}}</ref>\n\n# In MCPs the categories are defined in an ordinal way. This ordinal definition of the categories implicitly defines a preference structure. In contrast, machine learning is usually involved with nominal classification problems, where classes of observations are defined in a nominal way (i.e., collection of cases described by some common patterns), without any preferential implications.\n# In MCPs, the alternatives are evaluated over a set of criteria. A criterion is an attribute that incorporates preferential information. Thus, the decision model should have some form of monotonic relationship with respect to the criteria. This kind of information is explicitly introduced (a priory) in multicriteria methods for MCPs.\n\n== Methods ==\n\nThe most popular modeling approach for MCPs are based on value function models, outranking relations, and decision rules:\n\n* In a value function model, the classification rules can be expressed as follows: Alternative ''i'' is assigned to group ''c''<sub>''r''</sub> if and only if\n\n:: <math> t_{r+1}<V(\\mathbf{x}_i)<t_r </math>\n\n:where ''V'' is a value function (non-decreasing with respect to the criteria) and ''t''<sub>1</sub> > ''t''<sub>2</sub> > ... > ''t''<sub>''k''−1</sub> are thresholds defining the category limits.\n\n* Examples of outranking techniques include the [[ELECTRE]] TRI method and its variants, models based on the [[PROMETHEE]] method such as the FlowSort method,<ref>{{cite journal|last=Nemery|first=Ph.|author2=Lamboray, C.|title=FlowSort: a flow-based sorting method with limiting or central profiles|journal=TOP|year=2008|volume=16|issue=1|pages=90–113|doi=10.1007/s11750-007-0036-x}}</ref> and the [[Proaftn]] method.<ref>{{cite journal|title= Multicriteria assignment method PROAFTN: Methodology and medical application|journal=European Journal of Operational Research|year=2000|first=N.|last=Belacel |volume=125|issue=3|pages=175–83|doi=10.1016/S0377-2217(99)00192-7}}</ref> Outranking models are expressed in a relational form. In a typical setting used in ELECTRE TRI, the assignment of the alternatives is based on pairwise comparisons of the alternatives to predefined category boundaries.\n* Rule-based models are expressed in the form of \"If ... then ... \" decision rules. The conditions part involve a conjunction of elementary conditions on the set of criteria, whereas the conclusion of each rule provides a recommendation for the assignment of the alternatives that satisfy the conditions of the rule. The [[dominance-based rough set approach]] is an example of this type of models.\n\n== Model development ==\nThe development of MCP models can be made either through direct or indirect approaches. Direct techniques involve the specification of all parameters of the decision model (e.g., the weights of the criteria) through an interactive procedure, where the decision analyst elicits the required information from the decision-maker. This is can be a time-consuming process, but it is particularly useful in strategic decision making.\n\nIndirect procedures are referred to as ''preference disaggregation analysis''.<ref>{{cite journal|last=Jacquet-Lagrèze|first=E.|author2=Siskos, J.|title=Preference disaggregation: Twenty years of MCDA experience|journal=European Journal of Operational Research|year=2001|volume=130|issue=2|pages=233–245|doi=10.1016/s0377-2217(00)00035-7}}</ref> The preference disaggregation approach refers to the analysis of the decision–maker's global judgments in order to specify the parameters of the criteria aggregation model that best fit the decision-maker's evaluations. In the case of MCP, the decision–maker's global judgments are expressed by classifying a set of reference alternatives (training examples). The reference set may include: (a) some decision alternatives evaluated in similar problems in the past, (b) a subset of the alternatives under consideration, (c) some fictitious alternatives, consisting of performances on the criteria which can be easily judged by the decision-maker to express his/her global evaluation. Disaggregation techniques provide an estimate ''β''<sup>*</sup> for the parameters of a decision model <math>f</math> based on the solution of an optimization problem of the following general form:\n:<math> \n\\beta^*= \\underset{\\beta\\in B}{\\operatorname{argmin}{}} L[D(X),D^'(X,f_\\beta)]\n</math>\nwhere ''X'' is the set of reference alternatives, ''D''(''X'') is the classification of the reference alternatives by the decision-maker, ''D''<sup>'</sup>(''X'',''f''<sub>''β''</sub>) are the recommendations of the model for the reference alternatives, ''L'' is a function that measures the differences between the decision-maker's evaluations and the model's outputs, and ''B'' is the set of feasible values for the model's parameters.\n\nFor example, the following linear program can be formulated in the context of a weighted average model ''V''('''x'''<sub>i</sub>)&nbsp;=&nbsp;''w''<sub>1</sub>''x''<sub>''i''1</sub>&nbsp;+&nbsp;...&nbsp;+&nbsp;''w''<sub>''n''</sub>''x''<sub>''in''</sub> with ''w''<sub>''j''</sub> being the (non-negative) trade-off constant for criterion ''j'' (''w''<sub>1</sub>&nbsp;+&nbsp;...&nbsp;+&nbsp;''w''<sub>''n''</sub>&nbsp;=&nbsp;1) and ''x''<sub>''ij''</sub> being the data for alternative ''i'' on criterion ''j'':\n:<math> \\begin{align}\n& \\text{minimize} && \\sum_i (s_i^+ + s_i^-) \\\\\n& \\text{subject to:} && w_1x_{i1}+\\cdots+w_nx_{in}-t_r+s_i^+\\ge\\delta& \\text{for all reference alternatives in class } c_r (r=1,\\ldots,k-1)\\\\\n& && w_1x_{i1}+\\cdots+w_nx_{in}-t_{r-1}-s_i^-\\leq-\\delta& \\text{for all reference alternatives in class } c_r (r=2,\\ldots,k)\\\\\n& && w_1+\\cdots+w_n=1\\\\\n& && w_j,s_i^+,s_i^-,t_r\\ge 0\n\\end{align}\n</math>\nThis linear programming formulation can be generalized in context of additive value functions.<ref>{{cite book|last = Doumpos|first = M.|author2=Zopounidis, C|title = Multicriteria Decision Aid Classification Methods|publisher = Kluwer|location = Heidelberg|year = 2002}}</ref><ref>{{cite journal|last=Köksalan|first=M.|author2=Özpeynirci, B.S.|title=An interactive sorting method for additive utility functions|journal=Computers and Operations Research|year=2009|volume=36|issue=9|pages=2565–2572|doi=10.1016/j.cor.2008.11.006}}</ref> Similar optimization problems (linear and nonlinear) can be formulated for outranking models,<ref>{{cite journal|last=Doumpos|first=M.|author2=Marinakis, Y. |author3=Marinaki, M. |author4= Zopounidis, C. |title=An evolutionary approach to construction of outranking models for multicriteria classification: The case of the ELECTRE TRI method|journal=European Journal of Operational Research|year=2009|volume=199|issue=2|pages=496–505|doi=10.1016/j.ejor.2008.11.035}}</ref><ref>{{cite journal|last=Mousseau|first=V.|author2=Slowinski, R.|title=Inferring an ELECTRE-TRI model from assignment examples|journal=Journal of Global Optimization|year=1998|volume=12|issue=2|pages=157–174|doi=10.1023/A:1008210427517}}</ref><ref>{{cite journal|last=Belacel|first=N. |author2=Raval, H. |author3=Punnen, A.|title=Learning multicriteria fuzzy classification method PROAFTN from data|journal=Computers and Operations Research|year=2007|volume=34|issue=7 |pages=1885–1898|doi=10.1016/j.cor.2005.07.019}}</ref> whereas [[Dominance-based rough set approach|decision rule models]] are built through [[rule induction]] algorithms.\n\n== See also ==\n* [[Decision making]]\n* [[Decision-making software]]\n* [[Multi-criteria decision analysis]]\n* [[Pairwise comparison]]\n* [[Preference]]\n\n== References ==\n{{Reflist}}\n\n== External links ==\n* [http://mcsc2.ist.utl.pt/index.html Site dedicated to the sorting problematic of MCDA]\n\n{{DEFAULTSORT:Multicriteria Classification}}\n[[Category:Decision analysis]]\n[[Category:Mathematical optimization]]\n[[Category:Multiple-criteria decision analysis]]"
    }
  ]
}