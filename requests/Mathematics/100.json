{
  "pages": [
    {
      "title": "Mathematics",
      "url": "https://en.wikipedia.org/wiki/Mathematics",
      "text": "{{about|the study of topics such as quantity and structure|other uses|Mathematics (disambiguation)}}\n{{redirect|Math}}\n{{semiprotected|small=yes}}\n{{pp-move-indef}}\n{{short description|Field of study concerning quantity, patterns and change}}\n{{Use mdy dates|date=October 2014}}\n[[File:Euclid.jpg|thumb|[[Euclid]] (holding [[calipers]]), Greek mathematician, 3rd century BC, as imagined by [[Raphael]] in this detail from ''[[The School of Athens]]''.{{efn|No likeness or description of Euclid's physical appearance made during his lifetime survived antiquity. Therefore, Euclid's depiction in works of art depends on the artist's imagination (see ''[[Euclid]]'').}}]]\n\n'''Mathematics''' (from [[Ancient Greek|Greek]] μάθημα ''máthēma'', \"knowledge, study, learning\") includes the study of such topics as [[quantity]],<ref name=\"OED\">{{cite web |url=http://oed.com/view/Entry/114974 |title=mathematics, ''n.'' |publisher=Oxford University Press |website=Oxford English Dictionary |year=2012 |accessdate=June 16, 2012 |quote=The science of space, number, quantity, and arrangement, whose methods involve logical reasoning and usually the use of symbolic notation, and which includes geometry, arithmetic, algebra, and analysis.}}</ref> [[mathematical structure|structure]],<ref name=\"Kneebone\">{{cite book |title=Mathematical Logic and the Foundations of Mathematics: An Introductory Survey |publisher=Dover |author=Kneebone, G.T. |year=1963 |page=[https://books.google.com/books?id=tCXxf4vbXCcC&pg=PA4 4] |isbn=978-0-486-41712-7 |quote=Mathematics&nbsp;... is simply the study of abstract structures, or formal patterns of connectedness.}}</ref> [[space]],<ref name=OED/> and [[calculus|change]].<ref name=\"LaTorre\">{{cite book |title=Calculus Concepts: An Informal Approach to the Mathematics of Change |publisher=Cengage Learning |first1=Donald R. |last1=LaTorre |first2=John W. |last2=Kenelly |first3=Sherry S. |last3=Biggers |first4=Laurel R. |last4=Carpenter |first5=Iris B. |last5=Reed |first6=Cynthia R. |last6=Harris |year=2011 |page=[https://books.google.com/books?id=1Ebu2Tij4QsC&pg=PA2 2] |isbn=978-1-4390-4957-0 |quote=Calculus is the study of change—how things change, and how quickly they change.}}</ref><ref name=\"Ramana\">{{cite book |title=Applied Mathematics |publisher=Tata McGraw–Hill Education |author=Ramana |year=2007 |page=[https://books.google.com/books?id=XCRC6BeKhIIC&pg=SA2–PA10 2.10] |isbn=978-0-07-066753-2 |quote=The mathematical study of change, motion, growth or decay is calculus.}}</ref><ref name=\"Ziegler\">{{cite book |title=An Invitation to Mathematics: From Competitions to Research |publisher=Springer |author=Ziegler, Günter M. |authorlink=Günter M. Ziegler |year=2011 |page=[https://books.google.com/books?id=9TATfteVeVYC&pg=PR7 vii] |isbn=978-3-642-19532-7 |chapter=What Is Mathematics?}}</ref><!--<<< Please do NOT change the opening sentence without discussion; much time and discussion have been invested in its current form.--> It has no generally accepted [[definition]].<ref name=Mura/><ref name=Runge/>\n\nMathematicians seek and use [[patterns]]<ref name=future/><ref name=devlin/> to formulate new [[conjecture]]s; they resolve the truth or falsity of conjectures by [[mathematical proof]]. When mathematical structures are good models of real phenomena, then mathematical reasoning can provide insight or predictions about nature. Through the use of [[abstraction (mathematics)|abstraction]] and [[logic]], mathematics developed from [[counting]], [[calculation]], [[measurement]], and the systematic study of the [[shape]]s and [[motion (physics)|motions]] of physical objects. Practical mathematics has been a human activity from as far back as [[History of Mathematics|written records]] exist. The research required to solve mathematical problems can take years or even centuries of sustained inquiry.\n\n[[Logic|Rigorous arguments]] first appeared in [[Greek mathematics]], most notably in [[Euclid]]'s ''[[Euclid's Elements|Elements]]''. Since the pioneering work of [[Giuseppe Peano]] (1858–1932), [[David Hilbert]] (1862–1943), and others [[Foundations of mathematics|on axiomatic systems in the late 19th&nbsp;century]], it has become customary to view mathematical research as establishing [[truth]] by [[Mathematical rigor|rigorous]] [[deductive reasoning|deduction]] from appropriately chosen [[axiom]]s and [[definition]]s. Mathematics developed at a relatively slow pace until the [[Renaissance]], when mathematical innovations interacting with new [[timeline of scientific discoveries|scientific discoveries]] led to a rapid increase in the rate of mathematical discovery that has continued to the present day.<ref>Eves, p. 306</ref>\n\nMathematics is essential in many fields, including [[natural science]], engineering, medicine, finance, and the [[social sciences]]. [[Applied mathematics]] has led to entirely new mathematical disciplines, such as statistics and [[game theory]]. Mathematicians engage in [[pure mathematics]] (mathematics for its own sake) without having any application in mind, but practical applications for what began as pure mathematics are often discovered later.<ref>Peterson, p. 12</ref><ref name=wigner1960 />\n\n{{TOC limit|3}}\n\n==History==\n{{main|History of mathematics}}\n[[Image:Plimpton 322.jpg|thumb|The Babylonian mathematical tablet Plimpton 322, dated to 1800 BC.]]\n[[File:Archimedes pi.svg|thumb|right|Archimedes used the [[method of exhaustion]] to approximate the value of [[pi]].]]\n[[File:Bakhshali numerals 2.jpg|thumb|right|350px|The numerals used in the [[Bakhshali manuscript]], dated between the 2nd century BCE and the 2nd century CE.]]\nThe history of mathematics can be seen as an ever-increasing series of [[abstraction (mathematics)|abstractions]]. The first abstraction, which is shared by many animals,<ref>{{cite journal |title=Abstract representations of numbers in the animal and human brain |journal=Trends in Neurosciences |volume=21 |issue=8 |date=Aug 1998 |pages=355–61 |doi=10.1016/S0166-2236(98)01263-6 |pmid=9720604 |ref=harv |last1=Dehaene |first1=Stanislas |last2=Dehaene-Lambertz |first2=Ghislaine |last3=Cohen |first3=Laurent}}</ref> was probably that of numbers: the realization that a collection of two apples and a collection of two oranges (for example) have something in common, namely quantity of their members.\n\nAs evidenced by [[tally sticks|tallies]] found on bone, in addition to recognizing how to [[counting|count]] physical objects, [[prehistoric]] peoples may have also recognized how to count abstract quantities, like time&nbsp;– days, seasons, years.<ref>See, for example, Raymond L. Wilder, ''Evolution of Mathematical Concepts; an Elementary Study'', ''passim''</ref>\n\nEvidence for more complex mathematics does not appear until around 3000&nbsp;[[Before Christ|BC]], when the [[Babylonia]]ns and Egyptians began using [[arithmetic]], [[algebra]] and [[geometry]] for taxation and other financial calculations, for building and construction, and for [[astronomy]].<ref>Kline 1990, Chapter 1.</ref> The most ancient mathematical texts from [[Mesopotamia]] and [[Ancient Egypt|Egypt]] are from 2000–1800 BC. Many early texts mention [[Pythagorean triple]]s and so, by inference, the [[Pythagorean theorem]] seems to be the most ancient and widespread mathematical development after basic arithmetic and geometry. It is in [[Babylonian mathematics]] that [[elementary arithmetic]] ([[addition]], [[subtraction]], [[multiplication]] and [[division (mathematics)|division]]) first appear in the archaeological record. The Babylonians also possessed a place-value system, and used a [[sexagesimal]] numeral system, still in use today for measuring angles and time.{{sfn|Boyer|1991|loc=\"Mesopotamia\" p. 24–27}}\n\nBeginning in the 6th century BC with the [[Pythagoreans]], the [[Ancient Greeks]] began a systematic study of mathematics as a subject in its own right with [[Greek mathematics]].<ref>{{cite book |last=Heath |first=Thomas Little |url=https://books.google.com/?id=drnY3Vjix3kC&pg=PA1&dq#v=onepage&q=&f=false |title=A History of Greek Mathematics: From Thales to Euclid |location=New York |publisher=Dover Publications |date=1981 |orig-year=originally published 1921 |isbn=978-0-486-24073-2}}</ref> Around 300 BC, [[Euclid]] introduced the [[axiomatic method]] still used in mathematics today, consisting of definition, axiom, theorem, and proof. His textbook ''[[Euclid's Elements|Elements]]'' is widely considered the most successful and influential textbook of all time.{{sfn|Boyer|1991|loc=\"Euclid of Alexandria\" p. 119}} The greatest mathematician of antiquity is often held to be [[Archimedes]] (c. 287–212 BC) of [[Syracuse, Italy|Syracuse]].{{sfn|Boyer|1991|loc=\"Archimedes of Syracuse\" p. 120}} He developed formulas for calculating the surface area and volume of [[solids of revolution]] and used the [[method of exhaustion]] to calculate the [[area]] under the arc of a [[parabola]] with the [[Series (mathematics)|summation of an infinite series]], in a manner not too dissimilar from modern calculus.{{sfn|Boyer|1991|loc=\"Archimedes of Syracuse\" p. 130}} Other notable achievements of Greek mathematics are [[conic sections]] ([[Apollonius of Perga]], 3rd century BC),{{sfn|Boyer|1991|loc=\"Apollonius of Perga\" p. 145}} [[trigonometry]] ([[Hipparchus of Nicaea]] (2nd century BC),{{sfn|Boyer|1991|loc= \"Greek Trigonometry and Mensuration\" p. 162}} and the beginnings of algebra ([[Diophantus]], 3rd century AD).{{sfn|Boyer|1991|loc= \"Revival and Decline of Greek Mathematics\" p. 180}}\n\nThe [[Hindu–Arabic numeral system]] and the rules for the use of its operations, in use throughout the world today, evolved over the course of the first millennium AD in [[Indian mathematics|India]] and were transmitted to the [[Western world]] via [[Islamic mathematics]]. Other notable developments of Indian mathematics include the modern definition of [[sine]] and [[cosine]], and an early form of [[infinite series]].\n\n[[File:Image-Al-Kitāb al-muḫtaṣar fī ḥisāb al-ğabr wa-l-muqābala.jpg|left|thumb|200px|A page from al-Khwārizmī's ''Algebra'']]\nDuring the [[Islamic Golden Age|Golden Age of Islam]], especially during the 9th and 10th&nbsp;centuries, mathematics saw many important innovations building on Greek mathematics. The most notable achievement of [[Islamic mathematics]] was the development of [[algebra]]. Other notable achievements of the Islamic period are advances in [[spherical trigonometry]] and the addition of the [[decimal point]] to the Arabic numeral system. Many notable mathematicians from this period were Persian, such as [[Muhammad ibn Musa al-Khwarizmi|Al-Khwarismi]], [[Omar Khayyam]] and [[Sharaf al-Dīn al-Ṭūsī]].\n\nDuring the [[early modern period]], mathematics began to develop at an accelerating pace in [[Western Europe]]. The development of [[calculus]] by Newton and Leibniz in the 17th century revolutionized mathematics. [[Leonhard Euler]] was the most notable mathematician of the 18th century, contributing numerous theorems and discoveries. Perhaps the foremost mathematician of the 19th century was the German mathematician [[Carl Friedrich Gauss]], who made numerous contributions to fields such as [[algebra]], [[mathematical analysis|analysis]], [[differential geometry and topology|differential geometry]], [[matrix theory]], [[number theory]], and [[statistics]]. In the early 20th century, [[Kurt Gödel]] transformed mathematics by publishing his [[Gödel's incompleteness theorems|incompleteness theorems]], which show that any axiomatic system that is consistent will contain unprovable propositions.\n\nMathematics has since been greatly extended, and there has been a fruitful interaction between mathematics and science, to the benefit of both. Mathematical discoveries continue to be made today. According to Mikhail B. Sevryuk, in the January&nbsp;2006 issue of the ''[[Bulletin of the American Mathematical Society]]'', \"The number of papers and books included in the ''[[Mathematical Reviews]]'' database since 1940 (the first year of operation of MR) is now more than 1.9&nbsp;million, and more than 75&nbsp;thousand items are added to the database each year. The overwhelming majority of works in this ocean contain new mathematical [[theorem]]s and their [[mathematical proof|proofs]].\"{{sfn|Sevryuk|2006|pp=101–09}}\n\n===Etymology===\nThe word ''mathematics'' comes from [[Ancient Greek]] μάθημα (''máthēma''), meaning \"that which is learnt\",<ref>{{cite dictionary |title=mathematic |dictionary=[[Online Etymology Dictionary]] |url=http://www.etymonline.com/index.php?term=mathematic&allowed_in_frame=0 |deadurl=no |archiveurl=https://web.archive.org/web/20130307093926/http://etymonline.com/index.php?term=mathematic&allowed_in_frame=0 |archivedate=March 7, 2013 |df=mdy-all }}</ref> \"what one gets to know\", hence also \"study\" and \"science\". The word for \"mathematics\" came to have the narrower and more technical meaning \"mathematical study\" even in Classical times.<ref>Both meanings can be found in Plato, the narrower in [[Republic (Plato)|''Republic'']] [http://www.perseus.tufts.edu/hopper/text?doc=Plat.+Rep.+6.510c&fromdoc=Perseus%3Atext%3A1999.01.0168 510c], but Plato did not use a ''math-'' word; Aristotle did, commenting on it. {{LSJ|maqhmatiko/s|μαθηματική|ref}}. ''OED Online'' , \"Mathematics\".</ref> Its adjective is {{lang|grc|μαθηματικός}} (''mathēmatikós''), meaning \"related to learning\" or \"studious\", which likewise further came to mean \"mathematical\". In particular, {{lang|grc|μαθηματικὴ τέχνη}} (''mathēmatikḗ tékhnē''), {{lang-la|ars mathematica}}, meant \"the mathematical art\".\n\nSimilarly, one of the two main schools of thought in [[Pythagoreanism]] was known as the ''mathēmatikoi'' (μαθηματικοί)—which at the time meant \"teachers\" rather than \"mathematicians\" in the modern sense.\n\nIn Latin, and in English until around 1700, the term ''mathematics'' more commonly meant \"astrology\" (or sometimes \"astronomy\") rather than \"mathematics\"; the meaning gradually changed to its present one from about 1500 to 1800. This has resulted in several mistranslations. For example, [[Saint Augustine]]'s warning that Christians should beware of ''mathematici'', meaning astrologers, is sometimes mistranslated as a condemnation of mathematicians.<ref name=\"Boas\">{{cite book | title=Lion Hunting and Other Mathematical Pursuits: A Collection of Mathematics, Verse, and Stories by the Late Ralph P. Boas, Jr | publisher=Cambridge University Press | author=Boas, Ralph | authorlink=Ralph P. Boas Jr. | year=1995 | orig-year=1991 | page=257 | chapter-url=https://books.google.com/books?id=f-EWj5WtQHgC&pg=PA257 | chapter=What Augustine Didn't Say About Mathematicians}}</ref>\n\nThe apparent plural form in English, like the French plural form {{lang|fr|les mathématiques}} (and the less commonly used singular derivative {{lang|fr|la mathématique}}), goes back to the Latin neuter plural {{lang|la|mathematica}} ([[Cicero]]), based on the Greek plural {{lang|el|τὰ μαθηματικά}} (''ta mathēmatiká''), used by [[Aristotle]] (384–322&nbsp;BC), and meaning roughly \"all things mathematical\"; although it is plausible that English borrowed only the adjective ''mathematic(al)'' and formed the noun ''mathematics'' anew, after the pattern of ''[[physics]]'' and ''[[metaphysics]]'', which were inherited from Greek.<ref>''[[The Oxford Dictionary of English Etymology]]'', ''[[Oxford English Dictionary]]'', ''sub'' \"mathematics\", \"mathematic\", \"mathematics\"</ref> In English, the noun ''mathematics'' takes a singular verb. It is often shortened to ''maths'' or, in North America, ''math''.<ref name=maths>[http://oed.com/view/Entry/114982 \"maths, ''n.''\"] and [http://oed.com/view/Entry/114962 \"math, ''n.3''\"]. ''Oxford English Dictionary,'' on-line version (2012).</ref>\n\n==Definitions of mathematics==\n{{main|Definitions of mathematics}}\n[[File:Fibonacci.jpg|thumb|upright|[[Leonardo Fibonacci]], the Italian mathematician who introduced the [[Hindu–Arabic numeral system]] invented between the 1st and 4th&nbsp;centuries by Indian mathematicians, to the Western World]]\nMathematics has [[definitions of mathematics|no generally accepted definition]].<ref name=\"Mura\">{{cite journal |title=Images of Mathematics Held by University Teachers of Mathematical Sciences |author=Mura, Roberta |journal=Educational Studies in Mathematics |date=Dec 1993 |volume=25 |issue=4 |pages=375–385 |ref=harv |doi=10.1007/BF01273907 |jstor=3482762}}</ref><ref name=\"Runge\">{{cite book |title=Iris Runge: A Life at the Crossroads of Mathematics, Science, and Industry |publisher=Springer |author1=Tobies, Renate|author1-link= Renate Tobies |author2=Helmut Neunzert |lastauthoramp=yes |year=2012 |page=[https://books.google.com/books?id=EDm0eQqFUQ4C&pg=PA9 9] |isbn=978-3-0348-0229-1 |quote=[I]t is first necessary to ask what is meant by ''mathematics'' in general. Illustrious scholars have debated this matter until they were blue in the face, and yet no consensus has been reached about whether mathematics is a natural science, a branch of the humanities, or an art form.|title-link=Iris Runge }}</ref> [[Aristotle]] defined mathematics as \"the science of quantity\" and this definition prevailed until the 18th century.<ref name=\"Franklin\">{{Cite book |url=https://books.google.com/books?id=mbn35b2ghgkC&pg=PA104#v=onepage&q&f=false |title=Philosophy of Mathematics |last=Franklin |first=James |date=2009-07-08 |isbn=978-0-08-093058-9 |page=104}}</ref> In the 19th&nbsp;century, when the study of mathematics increased in rigor and began to address abstract topics such as [[group theory]] and [[projective geometry]], which have no clear-cut relation to quantity and measurement, mathematicians and philosophers began to propose a variety of new definitions.<ref name=\"Cajori\">{{cite book |title=A History of Mathematics |publisher=American Mathematical Society (1991 reprint) |author=Cajori, Florian |authorlink=Florian Cajori |year=1893 |pages=[https://books.google.com/books?id=mGJRjIC9fZgC&pg=PA285 285–86] |isbn=978-0-8218-2102-2}}</ref> Three leading types of definition of mathematics today are called [[logicist]], [[intuitionist]], and [[Formalism (mathematics)|formalist]], each reflecting a different philosophical school of thought.<ref name=Snapper>{{Cite journal |doi=10.2307/2689412 |title=The Three Crises in Mathematics: Logicism, Intuitionism, and Formalism |journal=Mathematics Magazine |date=September 1979 |first=Ernst |last=Snapper |volume=52 |issue=4 |pages=207–16 |id= |jstor=2689412 |ref=harv|bibcode=1975MathM..48...12G }}</ref> All have severe problems, none has widespread acceptance, and no reconciliation seems possible.<ref name=Snapper/>\n\nAn early definition of mathematics in terms of logic was [[Benjamin Peirce]]'s \"the science that draws necessary conclusions\" (1870).<ref name=\"Peirce\">{{cite book |title=Linear Associative Algebra |author=Peirce, Benjamin |authorlink=Benjamin Peirce |year=1882 |page=1 |url=https://books.google.com/books?id=De0GAAAAYAAJ&pg=PA1#v=onepage&q&f=false |deadurl=no |archiveurl=https://web.archive.org/web/20150906135700/https://books.google.com/books?id=De0GAAAAYAAJ&pg=PA1#v=onepage&q&f=false |archivedate=September 6, 2015 |df=mdy-all }}</ref> In the ''[[Principia Mathematica]]'', [[Bertrand Russell]] and [[Alfred North Whitehead]] advanced the philosophical program known as [[logicism]], and attempted to prove that all mathematical concepts, statements, and principles can be defined and proved entirely in terms of [[symbolic logic]]. A logicist definition of mathematics is Russell's \"All Mathematics is Symbolic Logic\" (1903).<ref name=\"Russell\">{{Cite book |url=https://books.google.com/books?id=kj0a_aV2mxIC&pg=PA5#v=onepage&q&f=false |page=5|title=The Principles of Mathematics|year=1903|last1=Russell|first1=Bertrand}}</ref>\n\n[[Intuitionist]] definitions, developing from the philosophy of mathematician [[L. E. J. Brouwer]], identify mathematics with certain mental phenomena. An example of an intuitionist definition is \"Mathematics is the mental activity which consists in carrying out constructs one after the other.\"<ref name=Snapper/> A peculiarity of intuitionism is that it rejects some mathematical ideas considered valid according to other definitions. In particular, while other philosophies of mathematics allow objects that can be proved to exist even though they cannot be constructed, intuitionism allows only mathematical objects that one can actually construct.\n\n[[Formalism (mathematics)|Formalist]] definitions identify mathematics with its symbols and the rules for operating on them. [[Haskell Curry]] defined mathematics simply as \"the science of formal systems\".<ref name=\"Curry\">{{cite book |title=Outlines of a Formalist Philosophy of Mathematics |publisher=Elsevier |author=Curry, Haskell |authorlink=Haskell Curry |year=1951 |page=[https://books.google.com/books?id=tZHrBQgp1bkC 56] |isbn=978-0-444-53368-5}}</ref> A [[formal system]] is a set of symbols, or ''tokens'', and some ''rules'' telling how the tokens may be combined into ''formulas''. In formal systems, the word ''axiom'' has a special meaning, different from the ordinary meaning of \"a self-evident truth\". In formal systems, an axiom is a combination of tokens that is included in a given formal system without needing to be derived using the rules of the system.\n\nA great many professional mathematicians take no interest in a definition of mathematics, or consider it undefinable.<ref name=Mura/> There is not even consensus on whether mathematics is an art or a science.<ref name=Runge/> Some just say, \"Mathematics is what mathematicians do.\"<ref name=Mura/>\n\n===Mathematics as science===\n[[File:Carl Friedrich Gauss.jpg|upright|thumb|left|[[Carl Friedrich Gauss]], known as the prince of mathematicians]]\nThe German mathematician [[Carl Friedrich Gauss]] referred to mathematics as \"the Queen of the Sciences\".<ref name=\"Waltershausen\">Waltershausen, p. 79</ref> More recently, [[Marcus du Sautoy]] has called mathematics \"the Queen of Science&nbsp;... the main driving force behind scientific discovery\".<ref>{{Cite episode |title=Nicolas Bourbaki |url=http://www.bbc.co.uk/programmes/b00stcgv |access-date=26 October 2017 |series=A Brief History of Mathematics |first=Marcus |last=du Sautoy |station=BBC Radio 4 |date=25 June 2010 |time=min. 12:50 |deadurl=no |archiveurl=https://web.archive.org/web/20161216050402/http://www.bbc.co.uk/programmes/b00stcgv |archivedate=December 16, 2016 |df=mdy-all }}</ref> In the original Latin ''Regina Scientiarum'', as well as in German ''Königin der Wissenschaften'', the word corresponding to ''science'' means a \"field of knowledge\", and this was the original meaning of \"science\" in English, also; mathematics is in this sense a field of knowledge. The specialization restricting the meaning of \"science\" to ''[[natural science]]'' follows the rise of [[Baconian method|Baconian science]], which contrasted \"natural science\" to [[scholasticism]], the [[Organon|Aristotelean method]] of inquiring from [[first principles]]. The role of empirical experimentation and observation is negligible in mathematics, compared to natural sciences such as [[biology]], [[chemistry]], or [[physics]]. [[Albert Einstein]] stated that \"as far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.\"<ref name=certain>Einstein, p. 28. The quote is Einstein's answer to the question: \"How can it be that mathematics, being after all a product of human thought which is independent of experience, is so admirably appropriate to the objects of reality?\" This question was inspired by [[Eugene Wigner]]'s paper \"[[The Unreasonable Effectiveness of Mathematics in the Natural Sciences]]\".</ref>\n\nMany philosophers believe that mathematics is not experimentally [[falsifiability|falsifiable]], and thus not a science according to the definition of [[Karl Popper]].<ref>{{cite book |title=Out of Their Minds: The Lives and Discoveries of 15 Great Computer Scientists |author1=Shasha, Dennis Elliot |author2=Lazere, Cathy A. |publisher=Springer |year=1998 |page=228}}</ref> However, in the 1930s [[Gödel's incompleteness theorems]] convinced many mathematicians{{Who|date=January 2011}} that mathematics cannot be reduced to logic alone, and Karl Popper concluded that \"most mathematical theories are, like those of [[physics]] and [[biology]], [[hypothesis|hypothetico]]-[[deductive]]: pure mathematics therefore turns out to be much closer to the natural sciences whose hypotheses are conjectures, than it seemed even recently.\"<ref>Popper 1995, p. 56</ref> Other thinkers, notably [[Imre Lakatos]], have applied a version of [[falsificationism]] to mathematics itself.<ref>[[Imre Lakatos]] (1976), ''[[Proofs and Refutations]]''. Cambridge: Cambridge University Press.</ref><ref>{{cite web|url=http://hps.elte.hu/~kutrovatz/LakatosEng.pdf |title=Gábor Kutrovátz, \"Imre Lakatos's Philosophy of Mathematics\" |format=PDF |date= |accessdate=2018-05-08}}</ref>\n\nAn alternative view is that certain scientific fields (such as [[theoretical physics]]) are mathematics with axioms that are intended to correspond to reality. Mathematics shares much in common with many fields in the physical sciences, notably the [[deductive reasoning|exploration of the logical consequences]] of assumptions. [[Intuition (knowledge)|Intuition]] and experimentation also play a role in the formulation of [[conjecture]]s in both mathematics and the (other) sciences. [[Experimental mathematics]] continues to grow in importance within mathematics, and computation and simulation are playing an increasing role in both the sciences and mathematics.\n\nThe opinions of mathematicians on this matter are varied. Many mathematicians<ref>See, for example [[Bertrand Russell]]'s statement \"Mathematics, rightly viewed, possesses not only truth, but supreme beauty ...\" in his ''History of Western Philosophy''</ref> feel that to call their area a science is to downplay the importance of its aesthetic side, and its history in the traditional seven [[liberal arts]]; others{{Who|date=August 2009}} feel that to ignore its connection to the sciences is to turn a blind eye to the fact that the interface between mathematics and its applications in science and engineering has driven much development in mathematics. One way this difference of viewpoint plays out is in the philosophical debate as to whether mathematics is ''created'' (as in art) or ''discovered'' (as in science). It is common to see universities divided into sections that include a division of ''Science and Mathematics'', indicating that the fields are seen as being allied but that they do not coincide. In practice, mathematicians are typically grouped with scientists at the gross level but separated at finer levels. This is one of many issues considered in the [[philosophy of mathematics]].{{Citation needed|date=August 2009}}\n\n==Inspiration, pure and applied mathematics, and aesthetics==\n{{main|Mathematical beauty}}\n\n{{multiple image\n|footer = [[Isaac Newton]] (left) and [[Gottfried Wilhelm Leibniz]] developed infinitesimal calculus.\n|total_width = 330\n|width1 = 407\n|height1 = 559\n|image1 = GodfreyKneller-IsaacNewton-1689.jpg\n|alt1 = Isaac Newton\n|width2 = 320\n|height2 = 390\n|image2 = Gottfried Wilhelm Leibniz, Bernhard Christoph Francke.jpg\n|alt2 = Gottfried Wilhelm von Leibniz}}\nMathematics arises from many different kinds of problems. At first these were found in commerce, [[land measurement]], architecture and later [[astronomy]]; today, all sciences suggest problems studied by mathematicians, and many problems arise within mathematics itself. For example, the [[physicist]] [[Richard Feynman]] invented the [[path integral formulation]] of [[quantum mechanics]] using a combination of mathematical reasoning and physical insight, and today's [[string theory]], a still-developing scientific theory which attempts to unify the four [[Fundamental interaction|fundamental forces of nature]], continues to inspire new mathematics.<ref>{{Cite journal |title=The Feynman Integral and Feynman's Operational Calculus |journal=Physics Today |volume=54 |issue=8 |page=48 |author=Meinhard E. Mayer |year=2001 |bibcode=2001PhT....54h..48J |doi=10.1063/1.1404851}}</ref>\n\nSome mathematics is relevant only in the area that inspired it, and is applied to solve further problems in that area. But often mathematics inspired by one area proves useful in many areas, and joins the general stock of mathematical concepts. A distinction is often made between [[pure mathematics]] and [[applied mathematics]]. However pure mathematics topics often turn out to have applications, e.g. [[number theory]] in [[cryptography]]. This remarkable fact, that even the \"purest\" mathematics often turns out to have practical applications, is what [[Eugene Wigner]] has called \"[[The Unreasonable Effectiveness of Mathematics in the Natural Sciences|the unreasonable effectiveness of mathematics]]\".<ref name=wigner1960>{{cite journal |last=Wigner |first=Eugene |year=1960 |title=The Unreasonable Effectiveness of Mathematics in the Natural Sciences |url=http://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html |journal=[[Communications on Pure and Applied Mathematics]] |volume=13 |issue=1 |pages=1–14 |doi=10.1002/cpa.3160130102 |ref=harv |bibcode=1960CPAM...13....1W |deadurl=no |archiveurl=https://web.archive.org/web/20110228152633/http://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html |archivedate=February 28, 2011 |df=mdy-all }}</ref> As in most areas of study, the explosion of knowledge in the scientific age has led to specialization: there are now hundreds of specialized areas in mathematics and the latest [[Mathematics Subject Classification]] runs to 46&nbsp;pages.<ref>{{cite web |url=http://www.ams.org/mathscinet/msc/pdfs/classification2010.pdf |title=Mathematics Subject Classification 2010 |format=PDF |date= |accessdate=November 9, 2010 |deadurl=no |archiveurl=https://web.archive.org/web/20110514091144/http://www.ams.org/mathscinet/msc/pdfs/classification2010.pdf |archivedate=May 14, 2011 |df=mdy-all }}</ref> Several areas of applied mathematics have merged with related traditions outside of mathematics and become disciplines in their own right, including statistics, [[operations research]], and [[computer science]].\n\nFor those who are mathematically inclined, there is often a definite aesthetic aspect to much of mathematics. Many mathematicians talk about the ''elegance'' of mathematics, its intrinsic [[aesthetics]] and inner beauty. [[Simplicity]] and generality are valued. There is beauty in a simple and elegant [[proof (mathematics)|proof]], such as [[Euclid]]'s proof that there are infinitely many [[prime number]]s, and in an elegant [[numerical method]] that speeds calculation, such as the [[fast Fourier transform]]. [[G. H. Hardy]] in ''[[A Mathematician's Apology]]'' expressed the belief that these aesthetic considerations are, in themselves, sufficient to justify the study of pure mathematics. He identified criteria such as significance, unexpectedness, inevitability, and economy as factors that contribute to a mathematical aesthetic.<ref>{{cite book |title=A Mathematician's Apology |author=Hardy, G. H. |publisher=Cambridge University Press |year=1940 |isbn=978-0-521-42706-7}}</ref> Mathematical research often seeks critical features of a mathematical object. A theorem expressed as a [[characterization (mathematics)|characterization]] of the object by these features is the prize. Examples of particularly succinct and revelatory mathematical arguments has been published in ''[[Proofs from THE BOOK]]''.\n\nThe popularity of [[recreational mathematics]] is another sign of the pleasure many find in solving mathematical questions. And at the other social extreme, philosophers continue to find problems in [[philosophy of mathematics]], such as the nature of [[mathematical proof]].<ref>{{cite book |title=Proof and Other Dilemmas: Mathematics and Philosophy |author1=Gold, Bonnie|author1-link=Bonnie Gold |author2=Simons, Rogers A. |publisher=MAA |year=2008}}</ref>\n\n==Notation, language, and rigor==\n{{main|Mathematical notation}}\n[[File:Leonhard Euler 2.jpg|upright|thumb|[[Leonhard Euler]] created and popularized much of the mathematical notation used today.]]\n\nMost of the mathematical notation in use today was not invented until the 16th century.<ref>{{cite web |url=http://jeff560.tripod.com/mathsym.html |title=Earliest Uses of Various Mathematical Symbols |publisher= |accessdate=September 14, 2014 |deadurl=no |archiveurl=https://web.archive.org/web/20160220073955/http://jeff560.tripod.com/mathsym.html |archivedate=February 20, 2016 |df=mdy-all }}</ref> Before that, mathematics was written out in words, limiting mathematical discovery.<ref>Kline, p. 140, on [[Diophantus]]; p. 261, on [[Franciscus Vieta|Vieta]].</ref> [[Leonhard Euler|Euler]] (1707–1783) was responsible for many of the notations in use today. Modern notation makes mathematics much easier for the professional, but beginners often find it daunting. According to [[Barbara Oakley]], this can be attributed to the fact that mathematical ideas are both more ''abstract'' and more ''encrypted'' than those of natural language.<ref>Oakley 2014, p. 16: \"Focused problem solving in math and science is often more effortful than focused-mode thinking involving language and people. This may be because humans haven't evolved over the millennia to manipulate mathematical ideas, which are frequently more abstractly encrypted than those of conventional language.\"</ref> Unlike natural language, where people can often equate a word (such as ''cow'') with the physical object it corresponds to, mathematical symbols are abstract, lacking any physical analog.<ref>Oakley 2014, p. 16: \"What do I mean by abstractness? You can point to a real live ''cow'' chewing its cud in a pasture and equate it with the letters ''c–o–w'' on the page. But you can't point to a real live ''plus sign'' that the symbol '+' is modeled after – the idea underlying the plus sign is more ''abstract''.\"</ref> Mathematical symbols are also more highly encrypted than regular words, meaning a single symbol can encode a number of different operations or ideas.<ref>Oakley 2014, p. 16: \"By ''encryptedness'', I mean that one symbol can stand for a number of different operations or ideas, just as the multiplication sign symbolizes repeated addition.\"</ref>\n\n[[Language of mathematics|Mathematical language]] can be difficult to understand for beginners because even common terms, such as ''or'' and ''only'', have a more precise meaning than they have in everyday speech, and other terms such as ''[[open set|open]]'' and ''[[Field (mathematics)|field]]'' refer to specific mathematical ideas, not covered by their laymen's meanings. Mathematical language also includes many technical terms such as ''[[homeomorphism]]'' and ''[[Integral|integrable]]'' that have no meaning outside of mathematics. Additionally, shorthand phrases such as ''iff'' for \"[[if and only if]]\" belong to [[mathematical jargon]]. There is a reason for special notation and technical vocabulary: mathematics requires more precision than everyday speech. Mathematicians refer to this precision of language and logic as \"rigor\".\n\n[[Mathematical proof]] is fundamentally a matter of [[rigor]]. Mathematicians want their theorems to follow from axioms by means of systematic reasoning. This is to avoid mistaken \"[[theorem]]s\", based on fallible intuitions, of which many instances have occurred in the history of the subject.{{efn|See ''[[false proof]]'' for simple examples of what can go wrong in a formal proof.}} The level of rigor expected in mathematics has varied over time: the Greeks expected detailed arguments, but at the time of [[Isaac Newton]] the methods employed were less rigorous. Problems inherent in the definitions used by Newton would lead to a resurgence of careful analysis and formal proof in the 19th&nbsp;century. Misunderstanding the rigor is a cause for some of the common misconceptions of mathematics<!--This part needs improvement |>>-->. Today, mathematicians continue to argue among themselves about [[computer-assisted proof]]s. Since large computations are hard to verify, such proofs may not be sufficiently rigorous.<ref>Ivars Peterson, ''The Mathematical Tourist'', Freeman, 1988, {{isbn|0-7167-1953-3}}. p. 4 \"A few complain that the computer program can't be verified properly\", (in reference to the Haken–Apple proof of the Four Color Theorem).</ref>\n\n[[Axiom]]s in traditional thought were \"self-evident truths\", but that conception is problematic.<ref>\"The method of 'postulating' what we want has many advantages; they are the same as the advantages of theft over honest toil.\" [[Bertrand Russell]] (1919), ''Introduction to Mathematical Philosophy'', New York and London, [http://www-history.mcs.st-and.ac.uk/Quotations/Russell.html p. 71.] {{webarchive|url=https://web.archive.org/web/20150620162751/http://www-history.mcs.st-and.ac.uk/Quotations/Russell.html |date=June 20, 2015 }}</ref> At a formal level, an axiom is just a string of symbols, which has an intrinsic meaning only in the context of all derivable formulas of an [[axiomatic system]]. It was the goal of [[Hilbert's program]] to put all of mathematics on a firm axiomatic basis, but according to [[Gödel's incompleteness theorem]] every (sufficiently powerful) axiomatic system has [[independence (mathematical logic)|undecidable]] formulas; and so a final [[axiomatization]] of mathematics is impossible. Nonetheless mathematics is often imagined to be (as far as its formal content) nothing but [[set theory]] in some axiomatization, in the sense that every mathematical statement or proof could be cast into formulas within set theory.<ref>Patrick Suppes, ''Axiomatic Set Theory'', Dover, 1972, {{isbn|0-486-61630-4}}. p. 1, \"Among the many branches of modern mathematics set theory occupies a unique place: with a few rare exceptions the entities which are studied and analyzed in mathematics may be regarded as certain particular sets or classes of objects.\"</ref>\n\n==Fields of mathematics==\n{{see also|Areas of mathematics|Glossary of areas of mathematics}}\n[[File:Abacus 6.png|right|thumb|The [[abacus]] is a simple calculating tool used since ancient times.]]\nMathematics can, broadly speaking, be subdivided into the study of quantity, structure, space, and change (i.e. [[arithmetic]], [[algebra]], [[geometry]], and [[mathematical analysis|analysis]]). In addition to these main concerns, there are also subdivisions dedicated to exploring links from the heart of mathematics to other fields: to [[mathematical logic|logic]], to [[set theory]] ([[foundations of mathematics|foundations]]), to the empirical mathematics of the various sciences ([[applied mathematics]]), and more recently to the rigorous study of [[uncertainty]]. While some areas might seem unrelated, the [[Langlands program]] has found connections between areas previously thought unconnected, such as [[Galois groups]], [[Riemann surface]]s and [[number theory]].\n\n===Foundations and philosophy===\nIn order to clarify the [[foundations of mathematics]], the fields of [[mathematical logic]] and [[set theory]] were developed. Mathematical logic includes the mathematical study of [[logic]] and the applications of formal logic to other areas of mathematics; set theory is the branch of mathematics that studies [[set (mathematics)|sets]] or collections of objects. [[Category theory]], which deals in an abstract way with [[mathematical structure]]s and relationships between them, is still in development. The phrase \"crisis of foundations\" describes the search for a rigorous foundation for mathematics that took place from approximately 1900 to 1930.<ref>Luke Howard Hodgkin & Luke Hodgkin, ''A History of Mathematics'', Oxford University Press, 2005.</ref> Some disagreement about the foundations of mathematics continues to the present day. The crisis of foundations was stimulated by a number of controversies at the time, including the [[controversy over Cantor's theory|controversy over Cantor's set theory]] and the [[Brouwer–Hilbert controversy]].\n\nMathematical logic is concerned with setting mathematics within a rigorous [[axiom]]atic framework, and studying the implications of such a framework. As such, it is home to [[Gödel's incompleteness theorems]] which (informally) imply that any effective [[formal system]] that contains basic arithmetic, if ''sound'' (meaning that all theorems that can be proved are true), is necessarily ''incomplete'' (meaning that there are true theorems which cannot be proved ''in that system''). Whatever finite collection of number-theoretical axioms is taken as a foundation, Gödel showed how to construct a formal statement that is a true number-theoretical fact, but which does not follow from those axioms. Therefore, no formal system is a complete axiomatization of full number theory. Modern logic is divided into [[recursion theory]], [[model theory]], and [[proof theory]], and is closely linked to [[theoretical computer science]],{{Citation needed|date=March 2011}} as well as to [[category theory]]. In the context of recursion theory, the impossibility of a full axiomatization of number theory can also be formally demonstrated as a [[MRDP theorem#Further applications|consequence of the MRDP theorem]].\n\n[[Theoretical computer science]] includes [[computability theory (computation)|computability theory]], [[computational complexity theory]], and [[information theory]]. Computability theory examines the limitations of various theoretical models of the computer, including the most well-known model&nbsp;– the [[Turing machine]]. Complexity theory is the study of tractability by computer; some problems, although theoretically solvable by computer, are so expensive in terms of time or space that solving them is likely to remain practically unfeasible, even with the rapid advancement of computer hardware. A famous problem is the \"[[P = NP problem|{{nowrap|'''P''' {{=}} '''NP'''?}}]]\" problem, one of the [[Millennium Prize Problems]].<ref>[https://www.webcitation.org/5Qj76uCbF?url=http://www.claymath.org/millennium/P_vs_NP/ Clay Mathematics Institute], P=NP, claymath.org</ref> Finally, information theory is concerned with the amount of data that can be stored on a given medium, and hence deals with concepts such as [[data compression|compression]] and [[Entropy (information theory)|entropy]].\n\n:{|style=\"border:1px solid #ddd; text-align:center; margin:auto\" cellspacing=\"15\"\n|<math>p \\Rightarrow q </math>|| [[File:Venn A intersect B.svg|128px]] || [[File:Commutative diagram for morphism.svg|96px]] || [[File:DFAexample.svg|96px]]\n|-\n|[[Mathematical logic]] || [[Set theory]] || [[Category theory]] || [[Theory of computation]]\n|}\n\n===Pure mathematics===\n====Quantity====\n{{Main|Arithmetic}}\n<!--This section is linked from [[List of basic mathematics topics]]-->\nThe study of quantity starts with numbers, first the familiar [[natural number]]s and [[integer]]s (\"whole numbers\") and arithmetical operations on them, which are characterized in [[arithmetic]]. The deeper properties of integers are studied in [[number theory]], from which come such popular results as [[Fermat's Last Theorem]]. The [[twin prime]] conjecture and [[Goldbach's conjecture]] are two unsolved problems in number theory.\n\nAs the number system is further developed, the integers are recognized as a [[subset]] of the [[rational number]]s (\"[[Fraction (mathematics)|fractions]]\"). These, in turn, are contained within the [[real number]]s, which are used to represent [[Continuous function|continuous]] quantities. Real numbers are generalized to [[complex number]]s. These are the first steps of a hierarchy of numbers that goes on to include [[quaternion]]s and [[octonion]]s. Consideration of the natural numbers also leads to the [[transfinite number]]s, which formalize the concept of \"[[infinity]]\". According to the [[fundamental theorem of algebra]] all solutions of equations in one unknown with complex coefficients are complex numbers, regardless of degree. Another area of study is the size of sets, which is described with the [[cardinal number]]s. These include the [[aleph number]]s, which allow meaningful comparison of the size of infinitely large sets.\n\n:{|style=\"border:1px solid #ddd; text-align:center; margin:auto\" cellspacing=\"20\"\n|<math>(0), 1, 2, 3,\\ldots</math> || <math>\\ldots,-2, -1, 0, 1, 2\\,\\ldots</math> || <math> -2, \\frac{2}{3}, 1.21</math> || <math>-e, \\sqrt{2}, 3, \\pi</math> || <math>2, i, -2+3i, 2e^{i\\frac{4\\pi}{3}}</math>\n|-\n|[[Natural number]]s|| [[Integer]]s || [[Rational number]]s || [[Real number]]s || [[Complex number]]s\n|}\n\n====Structure====\n{{Main|Algebra}}\n<!--This section is linked from [[List of basic mathematics topics]]-->\nMany mathematical objects, such as [[set (mathematics)|sets]] of numbers and [[function (mathematics)|functions]], exhibit internal structure as a consequence of [[operation (mathematics)|operations]] or [[relation (mathematics)|relations]] that are defined on the set. Mathematics then studies properties of those sets that can be expressed in terms of that structure; for instance [[number theory]] studies properties of the set of [[integer]]s that can be expressed in terms of [[arithmetic]] operations. Moreover, it frequently happens that different such structured sets (or [[mathematical structure|structures]]) exhibit similar properties, which makes it possible, by a further step of [[abstraction]], to state [[axiom]]s for a class of structures, and then study at once the whole class of structures satisfying these axioms. Thus one can study [[group (mathematics)|groups]], [[ring (mathematics)|rings]], [[field (mathematics)|fields]] and other abstract systems; together such studies (for structures defined by algebraic operations) constitute the domain of [[abstract algebra]].\n\nBy its great generality, abstract algebra can often be applied to seemingly unrelated problems; for instance a number of ancient problems concerning [[compass and straightedge constructions]] were finally solved using [[Galois theory]], which involves field theory and group theory. Another example of an algebraic theory is [[linear algebra]], which is the general study of [[vector space]]s, whose elements called [[vector (geometric)|vectors]] have both quantity and direction, and can be used to model (relations between) points in space. This is one example of the phenomenon that the originally unrelated areas of [[geometry]] and [[algebra]] have very strong interactions in modern mathematics. [[Combinatorics]] studies ways of enumerating the number of objects that fit a given structure.\n\n:{|style=\"border:1px solid #ddd; text-align:center; margin:auto\" cellspacing=\"15\"\n|<math>\\begin{matrix} (1,2,3) & (1,3,2) \\\\ (2,1,3) & (2,3,1) \\\\ (3,1,2) & (3,2,1) \\end{matrix}</math> || [[File:Elliptic curve simple.svg|96px]] || [[File:Rubik's cube.svg|96px]] || [[File:Group diagdram D6.svg|96px]] || [[File:Lattice of the divisibility of 60.svg|96px]] || [[File:Braid-modular-group-cover.svg|96px]]\n|-\n|| [[Number theory]] || [[Algebra]] || [[Group theory]] || [[Combinatorics]] || [[Graph theory]] || [[Order theory]] \n|}\n\n====Space====\n{{Main|Geometry}}\n<!--This section is linked from [[List of basic mathematics topics]]-->\nThe study of space originates with [[geometry]]&nbsp;– in particular, [[Euclidean geometry]], which combines space and numbers, and encompasses the well-known [[Pythagorean theorem]]. [[Trigonometry]] is the branch of mathematics that deals with relationships between the sides and the angles of triangles and with the trigonometric functions. The modern study of space generalizes these ideas to include higher-dimensional geometry, [[non-Euclidean geometries]] (which play a central role in [[general relativity]]) and [[topology]]. Quantity and space both play a role in [[analytic geometry]], [[differential geometry]], and [[algebraic geometry]]. [[Convex geometry|Convex]] and [[discrete geometry]] were developed to solve problems in [[geometry of numbers|number theory]] and [[functional analysis]] but now are pursued with an eye on applications in [[convex optimization|optimization]] and [[computational geometry|computer science]]. Within differential geometry are the concepts of [[fiber bundles]] and calculus on [[manifold]]s, in particular, [[vector calculus|vector]] and [[tensor calculus]]. Within algebraic geometry is the description of geometric objects as solution sets of [[polynomial]] equations, combining the concepts of quantity and space, and also the study of [[topological groups]], which combine structure and space. [[Lie group]]s are used to study space, structure, and change. [[Topology]] in all its many ramifications may have been the greatest growth area in 20th-century mathematics; it includes [[point-set topology]], [[set-theoretic topology]], [[algebraic topology]] and [[differential topology]]. In particular, instances of modern-day topology are [[metrizability theory]], [[axiomatic set theory]], [[homotopy theory]], and [[Morse theory]]. Topology also includes the now solved [[Poincaré conjecture]], and the still unsolved areas of the [[Hodge conjecture]]. Other results in geometry and topology, including the [[four color theorem]] and [[Kepler conjecture]], have been proved only with the help of computers.\n\n:{|style=\"border:1px solid #ddd; text-align:center; margin:auto\" cellspacing=\"15\"\n|[[File:Illustration to Euclid's proof of the Pythagorean theorem.svg|96px]] || [[File:Sinusvåg 400px.png|96px]] || [[File:Hyperbolic triangle.svg|96px]] || [[File:Torus.svg|96px]] || [[File:Mandel zoom 07 satellite.jpg|96px]] || [[File:Measure illustration (Vector).svg|70px]]\n|-\n|[[Geometry]] || [[Trigonometry]] || [[Differential geometry]] || [[Topology]] || [[Fractal|Fractal geometry]] || [[Measure theory]]\n|}\n\n====Change====\n{{Main|Calculus}}\n<!--This section is linked from [[List of basic mathematics topics]]-->\nUnderstanding and describing change is a common theme in the [[natural science]]s, and [[calculus]] was developed as a tool to investigate it. [[Function (mathematics)|Functions]] arise here, as a central concept describing a changing quantity. The rigorous study of [[real number]]s and functions of a real variable is known as [[real analysis]], with [[complex analysis]] the equivalent field for the [[complex number]]s. [[Functional analysis]] focuses attention on (typically infinite-dimensional) [[Space#Mathematics|spaces]] of functions. One of many applications of functional analysis is [[quantum mechanics]]. Many problems lead naturally to relationships between a quantity and its rate of change, and these are studied as [[differential equation]]s. Many phenomena in nature can be described by [[dynamical system]]s; [[chaos theory]] makes precise the ways in which many of these systems exhibit unpredictable yet still [[deterministic system (mathematics)|deterministic]] behavior.\n\n{|style=\"border:1px solid #ddd; text-align:center; margin:auto\" cellspacing=\"20\"\n|-\n|[[File:Integral as region under curve.svg|96px]] || [[File:Vector field.svg|96px]] || [[File:Navier Stokes Laminar.svg|96px]] || [[File:Limitcycle.svg|96px]] || [[File:Lorenz attractor.svg|96px]] || [[File:Conformal grid after Möbius transformation.svg|96px]]\n|-\n|[[Calculus]] || [[Vector calculus]]|| [[Differential equation]]s || [[Complex analysis]] || [[Dynamical system]]s || [[Chaos theory]]\n|}\n\n===Applied mathematics===\n{{Main|Applied mathematics}}\n[[Applied mathematics]] concerns itself with mathematical methods that are typically used in science, engineering, business, and industry. Thus, \"applied mathematics\" is a [[mathematical science]] with specialized knowledge. The term ''applied mathematics'' also describes the professional specialty in which mathematicians work on practical problems; as a profession focused on practical problems, ''applied mathematics'' focuses on the \"formulation, study, and use of mathematical models\" in science, engineering, and other areas of mathematical practice.\n\nIn the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics, where mathematics is developed primarily for its own sake. Thus, the activity of applied mathematics is vitally connected with research in [[pure mathematics]].\n\n====Statistics and other decision sciences====\n{{Main|Statistics}}\nApplied mathematics has significant overlap with the discipline of statistics, whose theory is formulated mathematically, especially with [[probability theory]]. Statisticians (working as part of a research project) \"create data that makes sense\" with [[random sampling]] and with randomized [[design of experiments|experiments]];<ref>[[C.R. Rao|Rao, C.R.]] (1997) ''Statistics and Truth: Putting Chance to Work'', World Scientific. {{isbn|981-02-3111-3}}</ref> the design of a statistical sample or experiment specifies the analysis of the data (before the data be available). When reconsidering data from experiments and samples or when analyzing data from [[observational study|observational studies]], statisticians \"make sense of the data\" using the art of [[statistical model|modelling]] and the theory of [[statistical inference|inference]]&nbsp;– with [[model selection]] and [[estimation theory|estimation]]; the estimated models and consequential [[Scientific method#Predictions from the hypothesis|predictions]] should be [[statistical hypothesis testing|tested]] on [[Scientific method#Evaluation and improvement|new data]].{{efn|Like other mathematical sciences such as [[physics]] and [[computer science]], statistics is an autonomous discipline rather than a branch of applied mathematics. Like research physicists and computer scientists, research statisticians are mathematical scientists. Many statisticians have a degree in mathematics, and some statisticians are also mathematicians.}}\n\n[[Statistical theory]] studies [[statistical decision theory|decision problems]] such as minimizing the [[risk]] ([[expected loss]]) of a statistical action, such as using a [[statistical method|procedure]] in, for example, [[parameter estimation]], [[hypothesis testing]], and [[selection algorithm|selecting the best]]. In these traditional areas of [[mathematical statistics]], a statistical-decision problem is formulated by minimizing an [[objective function]], like expected loss or [[cost]], under specific constraints: For example, designing a survey often involves minimizing the cost of estimating a population mean with a given level of confidence.<ref name=\"RaoOpt\">{{cite book |editor1-last=Arthanari |editor1-first=T.S. |editor2-last=Dodge |editor2-first=Yadolah |editor2-link=Yadolah Dodge |last=Rao |first=C.R. |authorlink=C.R. Rao |chapter=Foreword |title=Mathematical programming in statistics |series=Wiley Series in Probability and Mathematical Statistics |publisher=Wiley |location=New York |year=1981 |pages=vii–viii |isbn=978-0-471-08073-2 |mr=607328 |ref=harv}}</ref> Because of its use of [[mathematical optimization|optimization]], the mathematical theory of statistics shares concerns with other [[decision science]]s, such as [[operations research]], [[control theory]], and [[mathematical economics]].<ref name=\"Whittle\">{{harvtxt|Whittle|1994|pp=10–11, 14–18}}: {{cite book |first=Peter |last=Whittle |authorlink=Peter Whittle (mathematician) |chapter=Almost home |editor-link=Frank Kelly (mathematician) |editor-first=F.P. |editor-last=Kelly |year=1994 |title=Probability, statistics and optimisation: A Tribute to Peter Whittle |location=Chichester |publisher=John Wiley |isbn=978-0-471-94829-2 |pages=1–28 |ref=harv |url=http://www.statslab.cam.ac.uk/History/2history.html#6._1966--72:_The_Churchill_Chair |edition=previously \"A realised path: The Cambridge Statistical Laboratory upto 1993 (revised 2002)\" |deadurl=no |archiveurl=https://web.archive.org/web/20131219080017/http://www.statslab.cam.ac.uk/History/2history.html#6._1966--72:_The_Churchill_Chair |archivedate=December 19, 2013 |df=mdy-all }}</ref>\n\n====Computational mathematics====\n[[Computational mathematics]] proposes and studies methods for solving [[mathematical problem]]s that are typically too large for human numerical capacity. [[Numerical analysis]] studies methods for problems in [[analysis (mathematics)|analysis]] using [[functional analysis]] and [[approximation theory]]; numerical analysis includes the study of [[approximation]] and [[discretization]] broadly with special concern for [[rounding error]]s. Numerical analysis and, more broadly, scientific computing also study non-analytic topics of mathematical science, especially [[algorithm]]ic [[numerical linear algebra|matrix]] and [[graph theory]]. Other areas of computational mathematics include [[computer algebra]] and [[symbolic computation]].\n\n{|style=\"border:1px solid #ddd; text-align:center; margin:0 auto\" cellspacing=\"20\"\n|-\n|[[File:Arbitrary-gametree-solved.svg|96px]]|| [[File:BernoullisLawDerivationDiagram.svg|96px]] || [[File:Composite trapezoidal rule illustration small.svg|96px]] || [[File:Maximum boxed.png|96px]] || [[File:Two red dice 01.svg|96px]] || [[File:Oldfaithful3.png|96px]] || [[File:Caesar3.svg|96px]]\n|-\n|[[Game theory]] || [[Fluid dynamics]] || [[Numerical analysis]] || [[Mathematical optimization|Optimization]] || [[Probability theory]] || [[Statistics]] || [[Cryptography]]\n|-\n|[[File:Market Data Index NYA on 20050726 202628 UTC.png|96px]] || [[File:Gravitation space source.svg|96px]] || [[File:CH4-structure.svg|96px]] || [[File:Signal transduction pathways.svg|96px]] || [[File:GDP PPP Per Capita IMF 2008.svg|96px]] || [[File:Simple feedback control loop2.svg|96px]]\n|-\n|[[Mathematical finance]] || [[Mathematical physics]] || [[Mathematical chemistry]] || [[Mathematical biology]]|| [[Mathematical economics]] || [[Control theory]]\n|}\n\n==Mathematical awards==\nArguably the most prestigious award in mathematics is the [[Fields Medal]],{{sfn|Monastyrsky|2001|p=1|ps=: \"The Fields Medal is now indisputably the best known and most influential award in mathematics.\"}}{{sfn|Riehm|2002|pp=778–82}} established in 1936 and awarded every four years (except around World War II) to as many as four individuals. The Fields Medal is often considered a mathematical equivalent to the Nobel Prize.\n\nThe [[Wolf Prize in Mathematics]], instituted in 1978, recognizes lifetime achievement, and another major international award, the [[Abel Prize]], was instituted in 2003. The [[Chern Medal]] was introduced in 2010 to recognize lifetime achievement. These accolades are awarded in recognition of a particular body of work, which may be innovational, or provide a solution to an outstanding problem in an established field.\n\nA famous list of 23 [[open problem]]s, called \"[[Hilbert's problems]]\", was compiled in 1900 by German mathematician [[David Hilbert]]. This list achieved great celebrity among mathematicians, and at least nine of the problems have now been solved. A new list of seven important problems, titled the \"[[Millennium Prize Problems]]\", was published in 2000. Only one of them, the [[Riemann hypothesis]], duplicates one of Hilbert's problems. A solution to any of these problems carries a $1&nbsp;million reward.\n\n==See also==\n{{Portal|Mathematics}}\n{{div col|colwidth=30em}}\n* [[International Mathematical Olympiad]]\n* [[Lists of mathematics topics]]\n* [[Mathematical sciences]]\n* [[Mathematics and art]]\n* [[Mathematics education]]\n* [[National Museum of Mathematics]]\n* [[Philosophy of mathematics]]\n* [[Relationship between mathematics and physics]]\n* [[Science, Technology, Engineering, and Mathematics]]\n{{div col end}}\n\n==Notes==\n{{notelist}}\n\n==References==\n{{Reflist|30em\n|refs=\n<ref name=future>[[Lynn Steen|Steen, L.A.]] (April 29, 1988). ''The Science of Patterns'' [[Science (journal)|Science]], 240: 611–16. And summarized at [http://www.ascd.org/publications/curriculum-handbook/409/chapters/The-Future-of-Mathematics-Education.aspx Association for Supervision and Curriculum Development] {{webarchive|url=https://web.archive.org/web/20101028101034/http://www.ascd.org/publications/curriculum-handbook/409/chapters/The-Future-of-Mathematics-Education.aspx |date=October 28, 2010 }}, www.ascd.org.</ref>\n<ref name=devlin>[[Keith Devlin|Devlin, Keith]], ''Mathematics: The Science of Patterns: The Search for Order in Life, Mind and the Universe'' (Scientific American Paperback Library) 1996, {{isbn|978-0-7167-5047-5}}</ref>}}\n\n==Bibliography==\n{{refbegin|30em}}\n* {{cite book |last=Boyer |first=C.B. |authorlink=Carl Benjamin Boyer |title=A History of Mathematics |edition=2nd |place=New York |publisher=Wiley |year=1991 |isbn=978-0-471-54397-8 |ref=harv}}\n* {{cite book |last1=Courant |first1=Richard |authorlink1=Richard Courant |last2=Robbins |first2=Herbert |authorlink2=Herbert Robbins |title=What Is Mathematics?: An Elementary Approach to Ideas and Methods |location=New York |publisher=Oxford University Press |edition=2nd |year=1996 |isbn=978-0-19-510519-3}}\n* {{cite episode |title=Nicolas Bourbaki |url=http://www.bbc.co.uk/programmes/b00stcgv |access-date=26 October 2017 |series=A Brief History of Mathematics |first=Marcus |last=du Sautoy |authorlink=Marcus du Sautoy |station=BBC Radio 4 |date=25 June 2010}}\n* {{cite book |last=Einstein |first=Albert |authorlink=Albert Einstein |title=Sidelights on Relativity: I. Ether and relativity. II. Geometry and experience (translated by G.B. Jeffery, D.Sc., and W. Perrett, Ph.D) |publisher=E.P. Dutton & Co., New York |url=http://searchworks.stanford.edu/view/1216826 |year=1923}}\n* {{cite book |last=Eves |first=Howard |title=An Introduction to the History of Mathematics |edition=6th |publisher=Saunders |year=1990 |isbn=978-0-03-029558-4}}\n* {{cite book |last=Kline |first=Morris |authorlink=Morris Kline |title=Mathematical Thought from Ancient to Modern Times |location=New York |publisher=Oxford University Press |edition=Paperback |year=1990 |isbn=978-0-19-506135-2}}\n* {{cite journal |url=http://www.fields.utoronto.ca/aboutus/FieldsMedal_Monastyrsky.pdf |year=2001 |title=Some Trends in Modern Mathematics and the Fields Medal |last=Monastyrsky |first=Michael |publisher=Canadian Mathematical Society |accessdate=July 28, 2006 |format=PDF |ref=harv}}\n* {{cite book |last=Oakley |first=Barbara |authorlink=Barbara Oakley |title=A Mind For Numbers: How to Excel at Math and Science (Even If You Flunked Algebra) |date=2014 |publisher=Penguin Random House |location=New York |url=https://books.google.com/?id=Jv3YCwAAQBAJ&printsec=frontcover&dq=A+Mind+for+Numbers#v=onepage&q&f=false|isbn=978-0-399-16524-5 }}\n* {{cite book |last=Pappas |first=Theoni |title=The Joy Of Mathematics |publisher=Wide World Publishing |edition=Revised |date=June 1989 |isbn=978-0-933174-65-8}}\n* {{cite journal |pages=97–229 |title=Linear associative algebra |first=Benjamin |last=Peirce |authorlink=Benjamin Peirce |editor-link=Charles Sanders Peirce |editor-first=Charles&nbsp;Sanders |editor-last=Peirce |edition=Corrected, expanded, and annotated revision with an 1875 paper by B.&nbsp;Peirce and annotations by his son, C.S. Peirce, of the 1872 lithograph |journal=American Journal of Mathematics |volume=4 |year=1881 |url=https://books.google.com/?id=De0GAAAAYAAJ&pg=PA1&dq=Peirce+Benjamin+Linear+Associative+Algebra+&q= |id=Corrected, expanded, and annotated revision with an 1875 paper by B.&nbsp;Peirce and annotations by his son, C.&nbsp;S.&nbsp;Peirce, of the 1872 lithograph ed. ''Google'' [https://books.google.com/books?id=LQgPAAAAIAAJ&pg=PA221 Eprint] and as an extract, D.&nbsp;Van Nostrand, 1882, ''Google'' [https://books.google.com/books?id=De0GAAAAYAAJ&printsec=frontcover Eprint] |issue=1–4 |doi=10.2307/2369153 |ref=harv |jstor=2369153}}.\n* {{cite book |last=Peterson |first=Ivars |title=Mathematical Tourist, New and Updated Snapshots of Modern Mathematics |publisher=Owl Books |year=2001 |isbn=978-0-8050-7159-7}}\n* {{cite book |first=Karl R. |last=Popper |authorlink=Karl Popper |title=In Search of a Better World: Lectures and Essays from Thirty Years |journal=New York: Routledge |chapter=On knowledge |year=1995 |isbn=978-0-415-13548-1|bibcode=1992sbwl.book.....P }}\n* {{cite journal |last=Riehm |first=Carl |title=The Early History of the Fields Medal |journal=Notices of the AMS |volume=49 |issue=7 |pages=778–72 |date=August 2002 |url=http://www.ams.org/notices/200207/comm-riehm.pdf |format=PDF |ref=harv}}\n* {{cite journal |last=Sevryuk |first=Mikhail B. |date=January 2006 |title=Book Reviews |journal=[[Bulletin of the American Mathematical Society]] |volume=43 |issue=1 |pages=101–09 |url=http://www.ams.org/bull/2006-43-01/S0273-0979-05-01069-4/S0273-0979-05-01069-4.pdf |format=PDF |accessdate=June 24, 2006 |doi=10.1090/S0273-0979-05-01069-4 |ref=harv|bibcode=1994BAMaS..30..205W }}\n* {{cite book |last=Waltershausen |first=Wolfgang Sartorius von |authorlink=Wolfgang Sartorius von Waltershausen |title=Gauss zum Gedächtniss |year=1965 |origyear=first published 1856 |publisher=Sändig Reprint Verlag H. R. Wohlwend |isbn=978-3-253-01702-5}}\n{{refend}}\n\n==Further reading==\n{{Sister project links|Mathematics}}\n{{Wikiversity school}}\n{{Library resources box |by=no |onlinebooks=no |others=no |about=yes |label=Mathematics}}\n{{refbegin|30em}}\n* {{cite book |last=Benson |first=Donald C. |title=The Moment of Proof: Mathematical Epiphanies |publisher=Oxford University Press |year=2000 |isbn=978-0-19-513919-8}}\n* {{cite book |last=Davis |first=Philip J. |last2=Hersh |first2=Reuben |title=The Mathematical Experience |publisher=Mariner Books |edition=Reprint |year=1999 |isbn=978-0-395-92968-1|title-link=The Mathematical Experience }}\n* {{cite book |last=Gullberg |first=Jan |authorlink=Jan Gullberg |title=Mathematics: From the Birth of Numbers |publisher=W. W. Norton & Company |edition=1st |year=1997 |isbn=978-0-393-04002-9}}\n* {{cite book |editor=Hazewinkel, Michiel |title=Encyclopaedia of Mathematics |publisher=Kluwer Academic Publishers |year=2000|title-link=Encyclopaedia of Mathematics }}&nbsp;– A translated and expanded version of a Soviet mathematics encyclopedia, in ten volumes. Also in paperback and on CD-ROM, and [http://www.encyclopediaofmath.org/ online].\n* {{cite book |last=Jourdain |first=Philip E. B. |chapter=The Nature of Mathematics |title=The World of Mathematics |editor=James R. Newman |publisher=Dover Publications |year=2003 |isbn=978-0-486-43268-7}}\n* {{cite book |last=Maier |first=Annaliese |title=At the Threshold of Exact Science: Selected Writings of Annaliese Maier on Late Medieval Natural Philosophy |editor=Steven Sargent |location=Philadelphia |publisher=University of Pennsylvania Press |year=1982}}\n{{refend}}\n\n{{Areas of mathematics}}\n\n{{Authority control}}\n\n[[Category:Mathematics| ]]\n[[Category:Formal sciences]]\n[[Category:Mathematical terminology| ]]\n[[Category:Main topic articles]]"
    },
    {
      "title": "Outline of mathematics",
      "url": "https://en.wikipedia.org/wiki/Outline_of_mathematics",
      "text": "{{Short description|1=Overview of and topical guide to mathematics}}\n'''[[Mathematics]]''' is a field of study that investigates topics including number, space, structure, and change.  For more on the relationship between [[mathematics]] and [[science]], refer to the article on [[science#Mathematics|science]].\n\n{{TOC limit|limit=2}}\n\n==Nature of mathematics==\n*[[Definitions of mathematics]] – Mathematics has no generally accepted definition. Different schools of thought, particularly in philosophy, have put forth radically different definitions, all of which are controversial.\n*[[Philosophy of mathematics]] – its aim is to provide an account of the nature and methodology of mathematics and to understand the place of mathematics in people's lives.\n\n===Mathematics is===\n*an [[academic discipline]] – branch of knowledge that is taught at all levels of education and researched typically at the college or university level. Disciplines are defined (in part), and recognized by the academic journals in which research is published, and the learned societies and academic departments or faculties to which their practitioners belong.\n*a [[formal science]] – branch of knowledge concerned with the properties of formal systems based on definitions and rules of inference. Unlike other sciences, the formal sciences are not concerned with the validity of theories based on observations in the physical world.\n\n===General reference===\n\n====Classification systems====\n*[[List of Dewey Decimal Classes#500-599 – Science|Mathematics in the Dewey Decimal Classification system]]\n<!--*[[Mathematics in the Library of Congress Classification system]]-->\n*''[[Mathematics Subject Classification]]'' – alphanumerical classification scheme collaboratively produced by staff of and based on the coverage of the two major mathematical reviewing databases, Mathematical Reviews and Zentralblatt MATH.\n\n====Reference databases====\n*''[[Mathematical Reviews]]'' – journal and online database published by the American Mathematical Society (AMS) that contains brief synopses (and occasionally evaluations) of many articles in mathematics, statistics and theoretical computer science.\n*''[[Zentralblatt MATH]]'' – service providing reviews and abstracts for articles in pure and applied mathematics, published by Springer Science+Business Media. It is a major international reviewing service which covers the entire field of mathematics. It uses the Mathematics Subject Classification codes for organizing their reviews by topic.\n\n==Subjects==\n\n===Quantity===\n[[Mathematics#Quantity|Quantity]]\n*[[Arithmetic]]\n*[[Natural number]]s\n*[[Integer]]s\n*[[Rational number]]s\n*[[Real number]]s\n*[[Complex number]]s\n*[[Hypercomplex number]]s\n*[[Infinity]]\n\n===Structure===\n[[Mathematics#Structure|Structure]]\n*[[Abstract algebra]]\n*[[Linear algebra]]\n*[[Number theory]]\n*[[Order theory]]\n*[[Function (mathematics)]]\n\n===Space===\n[[Mathematics#Space|Space]]\n*[[Geometry]]\n*[[Algebraic geometry]]\n*[[Trigonometry]]\n*[[Differential geometry]]\n*[[Topology]]\n*[[Fractal geometry]]\n\n===Change===\n[[Mathematics#Change|Change]]\n*[[Calculus]]\n*[[Vector calculus]]\n*[[Differential equation]]s\n*[[Dynamical system]]s\n*[[Chaos theory]]\n*[[Mathematical analysis|Analysis]]\n\n===Foundations and philosophy===\n[[Foundations of mathematics]]\n*[[Philosophy of mathematics]]\n*[[Category theory]]\n*[[Set theory]]\n*[[Type theory]]\n\n===Mathematical logic===\n{{see also|Outline of mathematical logic}}\n[[Mathematical logic]]\n*[[Model theory]]\n*[[Proof theory]]\n*[[Set theory]]\n*[[Type theory]]\n*[[Recursion theory]]\n*[[Theory of Computation]]\n\n===Discrete mathematics===\n[[Discrete mathematics]]\n*[[Combinatorics]]\n*[[Cryptography]]\n*[[Graph theory]]\n\n===Applied mathematics===\n[[Applied mathematics]]\n*[[Mathematical physics]]\n*[[Mechanics|Analytical mechanics]]\n*[[Fluid mechanics|Mathematical fluid dynamics]]\n*[[Numerical analysis]]\n*[[Control theory]]\n*[[Dynamical system]]s\n*[[Mathematical optimization]]\n*[[Operations research]]\n*[[Probability]]\n*[[Statistics]]\n*[[Game theory]]\n*[[Mathematical economics]]\n*[[Financial mathematics]]\n*[[Information theory]]\n*[[Cryptography]]\n*[[Mathematical biology]]\n\n==History==\n\n[[History of mathematics]]\n*[[Babylonian mathematics]]\n*[[Egyptian mathematics]]\n*[[Indian mathematics]]\n*[[Greek mathematics]]\n*[[Chinese mathematics]]\n*[[History of the Hindu–Arabic numeral system]]\n*[[Islamic mathematics]]\n*[[Japanese mathematics]]\n*[[History of algebra]]\n*[[History of geometry]]\n*[[History of mathematical notation]]\n*[[History of trigonometry]]\n*[[History of writing numbers]]\n\n==Psychology==\n*[[Mathematics education]]\n*[[Numeracy]]\n*[[Numerical Cognition]]\n*[[Subitizing]]\n*[[Mathematical anxiety]]\n*[[Dyscalculia]]\n*[[Acalculia]]\n*[[Ageometresia]]\n*[[Number sense]]\n*[[Numerosity adaptation effect]]\n*[[Approximate number system]]\n*[[Mathematical maturity]]\n\n==Influential mathematicians==\nSee [[Lists of mathematicians]].\n\n==Mathematical notation==\n\n[[Mathematical notation]]\n* [[List of mathematical abbreviations]]\n* [[List of mathematical symbols]]\n* [[List of mathematical symbols by subject]]\n* [[Table of mathematical symbols by introduction date]]\n* [[Notation in probability and statistics]]\n* [[Table of logic symbols]]\n* [[Physical constant]]s\n* [[Greek letters used in mathematics, science, and engineering]]\n* [[Latin letters used in mathematics]]\n* [[Mathematical alphanumeric symbols]]\n* [[Mathematical operators and symbols in Unicode]]\n* [[ISO 31-11]] (Mathematical signs and symbols for use in physical sciences and technology)\n<!--\n* [[Wikipedia:Mathematical symbols]]\n* {{ml|Help:Advanced editing|Special characters}}\n* [[Help:Displaying a formula]]\n-->\n\n==See also==\n{{portal|Mathematics}}\n*[[Lists of mathematics topics]]\n*[[Areas of mathematics]]\n*[[Glossary of areas of mathematics]]\n\n== External links ==\n{{Sister project links|Mathematics}}\n*[http://www.maa.org/press/maa-reviews/the-basic-library-list-maas-recommendations-for-undergraduate-libraries MAA Reviews – The Basic Library List – Mathematical Association of America]\n*[http://www.math.ucdavis.edu/~saito/books.html Naoki's Recommended Books, compiled by Naoki Saito, U. C. Davis]\n*[http://www.math.cornell.edu/~hatcher/Other/topologybooks.pdf A List of Recommended Books in Topology, compiled by Allen Hatcher, Cornell U.]\n*[http://ncatlab.org/nlab/show/books+in+algebraic+geometry Books in algebraic geometry in nLab]\n\n{{Outline footer}}\n\n[[Category:Mathematics|+]]\n[[Category:Fields of mathematics|+]]\n[[Category:Wikipedia outlines|Mathematics]]\n[[Category:Mathematics-related lists]]"
    },
    {
      "title": "Analysis of Boolean functions",
      "url": "https://en.wikipedia.org/wiki/Analysis_of_Boolean_functions",
      "text": "In [[mathematics]] and [[theoretical computer science]], '''analysis of Boolean functions'''<ref>{{cite book |last=O'Donnell|first=Ryan|date=2014|title=Analysis of Boolean functions|publisher=Cambridge University Press|isbn=978-1-107-03832-5}}</ref> is the study of real-valued functions on <math>\\{0,1\\}^n</math> or <math>\\{-1,1\\}^n</math> from a spectral perspective (such functions are sometimes known as [[pseudo-Boolean function]]s). The functions studied are often, but not always, Boolean-valued, making them [[Boolean function]]s. The area has found many applications in [[combinatorics]], [[social choice theory]], [[random graph]]s, and theoretical computer science, especially in [[hardness of approximation]], [[property testing]] and [[probably approximately correct learning|PAC learning]].\n\n==Basic concepts==\n\nWe will mostly consider functions defined on the domain <math>\\{-1,1\\}^n</math>. Sometimes it is more convenient to work with the domain <math>\\{0,1\\}^n</math> instead. If <math>f</math> is defined on <math>\\{-1,1\\}^n</math>, then the corresponding function defined on <math>\\{0,1\\}^n</math> is\n\n:<math>f_{01}(x_1,\\ldots,x_n) = f((-1)^{x_1},\\ldots,(-1)^{x_n}).</math>\n\nSimilarly, for us a Boolean function is a <math>\\{-1,1\\}</math>-valued function, though often it is more convenient to consider <math>\\{0,1\\}</math>-valued functions instead.\n\n===Fourier expansion===\n\nEvery real-valued function <math>f\\colon \\{-1,1\\}^n \\to \\mathbb{R}</math> has a unique expansion as a multilinear polynomial:\n\n:<math> f(x) = \\sum_{S \\subseteq [n]} \\hat{f}(S) \\chi_S(x), \\quad \\chi_S(x) = \\prod_{i \\in S} x_i. </math>\n\nThis is the [[Hadamard transform]] of the function <math>f</math>, which is the [[Fourier transform]] in the [[group (mathematics)|group]] <math>\\mathbb{Z}_2^n</math>. The coefficients <math>\\hat{f}(S)</math> are known as ''Fourier coefficients'', and the entire sum is known as the ''Fourier expansion'' of <math>f</math>. The functions <math>\\chi_S</math> are known as ''Fourier characters'', and they form an orthonormal basis for the space of all functions over <math>\\{-1,1\\}^n</math>, with respect to the inner product <math>\\langle f,g \\rangle = 2^{-n} \\sum_{x \\in \\{-1,1\\}^n} f(x) g(x)</math>.\n\nThe Fourier coefficients can be calculated using an inner product:\n\n:<math> \\hat{f}(S) = \\langle f, \\chi_S \\rangle. </math>\n\nIn particular, this shows that <math>\\hat{f}(\\emptyset) = \\mathbb{E}[f].</math> Parseval's identity states that\n\n:<math> \\|f\\|^2 = \\mathbb{E}[f^2] = \\sum_S \\hat{f}(S)^2. </math>\n\nIf we skip <math>S = \\emptyset</math>, then we get the variance of <math>f</math>:\n\n:<math> \\mathbb{V}[f] = \\sum_{S \\neq \\emptyset} \\hat{f}(S)^2. </math>\n\n=== Fourier degree and Fourier levels ===\n\nThe ''degree'' of a function <math>f\\colon \\{-1,1\\}^n \\to \\mathbb{R}</math> is the maximum <math>d</math> such that <math>\\hat{f}(S) \\neq 0</math> for some set <math>S</math> of size <math>d</math>. In other words, the degree of <math>f</math> is its degree as a multilinear polynomial.\n\nIt is convenient to decompose the Fourier expansion into ''levels'': the Fourier coefficient <math>\\hat{f}(S)</math> is on level <math>|S|</math>.\n\nThe ''degree <math>d</math>'' part of <math>f</math> is\n\n:<math> f^{=d} = \\sum_{|S| = d} \\hat{f}(S) \\chi_S. </math>\n\nIt is obtained from <math>f</math> by zeroing out all Fourier coefficients not on level <math>d</math>.\n\nWe similarly define <math>f^{>d},f^{<d},f^{\\geq d},f^{\\leq d}</math>.\n\n===Influence===\n\nThe <math>i</math>'th influence of a function <math>f\\colon \\{-1,1\\}^n \\to \\mathbb{R}</math> can be defined in two equivalent ways:\n\n: <math>\n\\begin{align}\n& \\operatorname{Inf}_i[f] = \\mathbb{E}\\left[ \\left(\\frac{f - f^{\\oplus i}}{2} \\right)^2 \\right] = \\sum_{S \\ni i} \\hat{f}(S)^2, \\\\[5pt]\n& f^{\\oplus i}(x_1,\\ldots,x_n) = f(x_1,\\ldots,x_{i-1},-x_i,x_{i+1},\\ldots,x_n).\n\\end{align}\n</math>\n\nIf <math>f</math> is Boolean then <math>\\operatorname{Inf}_i[f]</math> is the probability that flipping the <math>i</math>'th coordinate flips the value of the function:\n\n:<math>\\operatorname{Inf}_i[f] = \\Pr[f(x) \\neq f^{\\oplus i}(x)]. </math>\n\nIf <math>\\operatorname{Inf}_i[f] = 0</math> then <math>f</math> doesn't depend on the <math>i</math>'th coordinate.\n\nThe ''total influence'' of <math>f</math> is the sum of all of its influences:\n\n:<math>\\operatorname{Inf}[f] = \\sum_{i=1}^n \\operatorname{Inf}_i[f] = \\sum_S |S| \\hat{f}(S)^2. </math>\n\nThe total influence of a Boolean function is also the ''average sensitivity'' of the function. The ''sensitivity'' of a Boolean function <math>f</math> at a given point is the number of coordinates <math>i</math> such that if we flip the <math>i</math>'th coordinate, the value of the function changes. The average value of this quantity is exactly the total influence.\n\nThe total influence can also be defined using the [[Discrete Laplace operator#Graph Laplacians|discrete Laplacian]] of the [[Hamming graph]], suitably normalized:  <math>\\operatorname{Inf}[f] = \\langle f,Lf \\rangle</math>.\n\n===Noise stability===\n\nGiven <math>-1 \\leq \\rho \\leq 1</math>, we say that two random vectors <math>x,y \\in \\{-1,1\\}^n</math> are ''<math>\\rho</math>-correlated'' if the marginal distributions of <math>x,y</math> are uniform, and <math>\\mathbb{E}[x_iy_i] = \\rho</math>. Concretely, we can generate a pair of <math>\\rho</math>-correlated random variables by first choosing <math>x,z \\in \\{-1,1\\}^n</math> uniformly at random, and then choosing <math>y</math> according to one of the following two equivalent rules, applied independently to each coordinate:\n\n:<math> y_i = \\begin{cases} x_i & \\text{w.p. } \\rho, \\\\ z_i & \\text{w.p. } 1-\\rho. \\end{cases} \\quad \\text{or} \\quad y_i = \\begin{cases} x_i & \\text{w.p. } \\frac{1+\\rho}{2}, \\\\ -x_i & \\text{w.p. } \\frac{1-\\rho}{2}. \\end{cases} </math>\n\nWe denote this distribution by <math> y \\sim N_\\rho(x) </math>.\n\nThe ''noise stability'' of a function <math>f\\colon \\{-1,1\\}^n \\to \\mathbb{R}</math> at <math>\\rho</math> can be defined in two equivalent ways:\n\n:<math> \\operatorname{Stab}_\\rho[f] = \\operatorname{\\mathbb{E}}_{x; y \\sim N_\\rho(x)}[f(x) f(y)] = \\sum_{S \\subseteq [n]} \\rho^{|S|} \\hat{f}(S)^2. </math>\n\nFor <math>0 \\leq \\delta \\leq 1</math>, the ''noise sensitivity'' of <math>f</math> at <math>\\delta</math> is\n\n:<math> \\operatorname{NS}_\\delta[f] = \\frac{1}{2} - \\frac{1}{2} \\operatorname{Stab}_{1-2\\delta}[f]. </math>\n\nIf <math>f</math> is Boolean, then this is the probability that the value of <math>f</math> changes if we flip each coordinate with probability <math>\\delta</math>, independently.\n\n===Noise operator===\n\nThe ''noise operator'' <math>T_\\rho</math> is an operator taking a function <math>f\\colon \\{-1,1\\}^n \\to \\mathbb{R}</math> and returning another function <math>T_\\rho f\\colon \\{-1,1\\}^n \\to \\mathbb{R}</math> given by\n\n:<math> (T_\\rho f)(x) = \\mathbb{E}_{y \\sim N_\\rho(x)}[f(y)] = \\sum_{S \\subseteq [n]} \\rho^{|S|} \\hat{f}(S) \\chi_S. </math>\n\nWhen <math>\\rho > 0</math>, the noise operator can also be defined using a [[continuous-time Markov chain]] in which each bit is flipped independently with rate 1. The operator <math>T_\\rho</math> corresponds to running this Markov chain for <math>\\frac{1}{2}\\log\\frac{1}{\\rho}</math> steps starting at <math>x</math>, and taking the average value of <math>f</math> at the final state. This Markov chain is generated by the Laplacian of the Hamming graph, and this relates total influence to the noise operator.\n\nNoise stability can be defined in terms of the noise operator: <math> \\operatorname{Stab}_\\rho[f] = \\langle f, T_\\rho f \\rangle </math>.\n\n===Hypercontractivity===\n\nFor <math>1 \\leq q < \\infty</math>, the [[Lp space#Lp spaces|<math>L_q</math>-norm]] of a function <math>f\\colon \\{-1,1\\}^n \\to \\mathbb{R}</math> is defined by\n\n:<math> \\|f\\|_q = \\sqrt[q]{\\mathbb{E}[|f|^q]}. </math>\n\nWe also define <math>\\|f\\|_\\infty = \\max_{x \\in \\{-1,1\\}^n} |f(x)|.</math>\n\nThe hypercontractivity theorem states that for any <math>q > 2</math> and <math>q' = 1/(1-1/q)</math>,\n\n:<math> \\|T_\\rho f\\|_q \\leq \\|f\\|_2 \\quad \\text{and} \\quad \\|T_\\rho f\\|_2 \\leq \\|f\\|_{q'}. </math>\n\nHypercontractivity is closely related to the [[logarithmic Sobolev inequalities]] of [[functional analysis]].<ref>{{cite journal|last1=Diaconis|first1=Persi|last2=Saloff-Coste|first2=Laurent|date=1996|title=Logarithmic Sobolev inequalities for finite Markov chains|journal=Ann. Appl. Probab.|volume=6|number=3|pages=695–750|doi=10.1214/aoap/1034968224}}</ref>\n\nA similar result for <math>q < 2</math> is known as ''reverse hypercontractivity''.<ref>{{cite journal|last1=Mossel|first1=Elchanan|last2=Oleszkiewicz|first2=Krzysztof|last3=Sen|first3=Arnab|date=2013|title=On reverse hypercontractivity|journal=GAFA|volume=23|number=3|pages=1062–1097|doi=10.1007/s00039-013-0229-4|arxiv=1108.1210}}</ref>\n\n===''p''-Biased analysis===\n\nIn many situations the input to the function is not uniformly distributed over <math>\\{-1,1\\}^n</math>, but instead has a bias toward <math>-1</math> or <math>1</math>. In these situations it is customary to consider functions over the domain <math>\\{0,1\\}^n</math>. For <math>0 < p < 1</math>, the ''p''-biased measure <math>\\mu_p</math> is given by\n\n:<math> \\mu_p(x) = p^{\\sum_i x_i} (1-p)^{\\sum_i (1-x_i)}. </math>\n\nThis measure can be generated by choosing each coordinate independently to be 1 with probability <math>p</math> and 0 with probability <math>1-p</math>.\n\nThe classical Fourier characters are no longer orthogonal with respect to this measure. Instead, we use the following characters:\n\n:<math> \\omega_S(x) = \\left(\\sqrt{\\frac{p}{1-p}}\\right)^{|\\{i \\in S : x_i = 0\\}|} \\left(-\\sqrt{\\frac{1-p}{p}}\\right)^{|\\{i \\in S : x_i = 1\\}|}. </math>\n\nThe ''p''-biased Fourier expansion of <math>f</math> is the expansion of <math>f</math> as a linear combination of ''p''-biased characters:\n\n:<math> f = \\sum_{S \\subseteq [n]} \\hat{f}(S) \\omega_S. </math>\n\nWe can extend the definitions of influence and the noise operator to the ''p''-biased setting by using their spectral definitions.\n\n====Influence====\n\nThe <math>i</math>'s influence is given by\n\n:<math> \\operatorname{Inf}_i[f] = \\sum_{S \\ni i} \\hat{f}(S)^2 = p(1-p) \\mathbb{E}[(f-f^{\\oplus i})^2]. </math>\n\nThe total influence is the sum of the individual influences:\n\n:<math>\\operatorname{Inf}[f] = \\sum_{i=1}^n \\operatorname{Inf}_i[f].</math>\n\n====Noise operator====\n\nA pair of <math>\\rho</math>-correlated random variables can be obtained by choosing <math>x,z \\sim \\mu_p</math> independently and <math>y \\sim N_\\rho(x)</math>, where <math>N_\\rho</math> is given by\n\n:<math> y_i = \\begin{cases} x_i & \\text{w.p. } \\rho, \\\\ z_i & \\text{w.p. } 1-\\rho. \\end{cases} </math>\n\nThe noise operator is then given by\n\n:<math> (T_\\rho f)(x) = \\sum_{S \\subseteq [n]} \\rho^{|S|} \\hat{f}(S) \\omega_S(x) = \\operatorname{\\mathbb{E}}_{y \\sim N_\\rho(x)} [f(y)]. </math>\n\nUsing this we can define the noise stability and the noise sensitivity, as before.\n\n====Russo–Margulis formula====\n\nThe Russo–Margulis formula states that for monotone Boolean functions <math>f\\colon \\{0,1\\}^n \\to \\{0,1\\}</math>,\n\n:<math> \\frac{d}{dp} \\operatorname{\\mathbb{E}}_{x \\sim \\mu_p} [f(x)] = \\frac{\\operatorname{Inf}[f]}{p(1-p)} = \\sum_{i=1}^n \\Pr[f \\neq f^{\\oplus i}]. </math>\n\nBoth the influence and the probabilities are taken with respect to <math>\\mu_p</math>, and on the right-hand side we have the average sensitivity of <math>f</math>. If we think of <math>f</math> as a property, then the formula states that as <math>p</math> varies, the derivative of the probability that <math>f</math> occurs at <math>p</math> equals the average sensitivity at <math>p</math>.\n\nThe Russo–Margulis formula is key for proving sharp threshold theorems such as [[#Friedgut's sharp threshold theorem|Friedgut's]].\n\n===Gaussian space===\n\nOne of the deepest results in the area, the [[#Invariance principle|invariance principle]], connects the distribution of functions on the Boolean cube <math>\\{-1,1\\}^n</math> to their distribution on ''Gaussian space'', which is the space <math>\\mathbb{R}^n</math> endowed with the standard <math>n</math>-dimensional [[Gaussian measure]].\n\nMany of the basic concepts of Fourier analysis on the Boolean cube have counterparts in Gaussian space:\n\n* The counterpart of the Fourier expansion in Gaussian space is the Hermite expansion, which is an expansion to an infinite sum (converging in <math>L^2</math>) of multivariate [[Hermite polynomials]].\n* The counterpart of total influence or average sensitivity for the indicator function of a set is Gaussian surface area, which is the Minkowski content of the boundary of the set.\n* The counterpart of the noise operator is the [[Ornstein–Uhlenbeck process|Ornstein–Uhlenbeck operator]] (related to the [[Mehler kernel|Mehler transform]]), given by <math>(U_\\rho f)(x) = \\operatorname{\\mathbb{E}}_{z \\sim N(0,1)}[f(\\rho x + \\sqrt{1-\\rho^2}z)]</math>, or alternatively by <math>(U_\\rho f)(x) = \\operatorname{\\mathbb{E}}[f(y)]</math>, where <math>x,y</math> is a pair of <math>\\rho</math>-correlated standard Gaussians.\n* Hypercontractivity holds (with appropriate parameters) in Gaussian space as well.\n\nGaussian space is more symmetric than the Boolean cube (for example, it is rotation invariant), and supports continuous arguments which may be harder to get through in the discrete setting of the Boolean cube. The invariance principle links the two settings, and allows deducing results on the Boolean cube from results on Gaussian space.\n\n==Basic results==\n\n===Friedgut–Kalai–Naor theorem===\n\nIf <math>f\\colon \\{-1,1\\}^n \\to \\{-1,1\\}</math> has degree at most 1, then <math>f</math> is either constant, equal to a coordinate, or equal to the negation of a coordinate. In particular, <math>f</math> is a ''dictatorship'': a function depending on at most one coordinate.\n\nThe Friedgut–Kalai–Naor theorem,<ref>{{cite journal |last1=Friedgut |first1=Ehud |last2=Kalai |first2=Gil |last3=Naor |first3=Assaf |date=2002 |title=Boolean functions whose Fourier transform is concentrated on the first two levels |journal=Adv. Appl. Math. |volume=29 |issue=3 |pages=427–437 |doi=10.1016/S0196-8858(02)00024-6}}</ref> also known as the ''FKN theorem'', states that if <math>f</math> ''almost'' has degree 1 then it is ''close'' to a dictatorship. Quantitatively, if <math>f\\colon \\{-1,1\\}^n \\to \\{-1,1\\}</math> and <math>\\|f^{>1}\\|^2 < \\varepsilon</math>, then <math>f</math> is <math>O(\\varepsilon)</math>-close to a dictatorship, that is, <math>\\|f - g\\|^2 = O(\\varepsilon)</math> for some Boolean dictatorship <math>g</math>, or equivalently, <math>\\Pr[f \\neq g] = O(\\varepsilon)</math> for some Boolean dictatorship <math>g</math>.\n\nSimilarly, a Boolean function of degree at most <math>d</math> depends on at most <math>C_{W}2^{d}</math> coordinates, making it a ''junta'' (a function depending on a constant number of coordinates), where <math>C_{W}</math> is an absolute constant equal to at least 1.5, and at most 4.41, as shown by Wellens. The Kindler–Safra theorem<ref>{{cite thesis |last=Kindler |first=Guy |date=2002 |title=Property testing, PCP, and juntas |chapter=16 |publisher=Tel Aviv University}}</ref> generalizes the Friedgut–Kalai–Naor theorem to this setting. It states that if <math>f\\colon \\{-1,1\\}^n \\to \\{-1,1\\}</math> satisfies <math>\\|f^{>d}\\|^2 < \\varepsilon</math> then <math>f</math> is <math>O(\\varepsilon)</math>-close to a Boolean function of degree at most <math>d</math>.\n\n===Kahn–Kalai–Linial theorem===\n\nThe Poincaré inequality for the Boolean cube (which follows from formulas appearing above) states that for a function <math>f\\colon \\{-1,1\\}^n \\to \\mathbb{R}</math>,\n\n:<math>\\mathbb{V}[f] \\leq \\operatorname{Inf}[f] \\leq \\deg f \\cdot \\mathbb{V}[f]. </math>\n\nThis implies that <math>\\max_i \\operatorname{Inf}_i[f] \\geq \\frac{\\mathbb{V}[f]}{n}</math>.\n\nThe Kahn–Kalai–Linial theorem,<ref>{{cite conference |title=The influence of variables on Boolean functions. |last1=Kahn |first1=Jeff |last2=Kalai |first2=Gil |last3=Linial |first3=Nati |date=1988 |publisher=IEEE |book-title=Proc. 29th Symp. on Foundations of Computer Science |pages=68–80 |location=White Plains |conference=SFCS'88 |doi=10.1109/SFCS.1988.2192 }}</ref> also known as the ''KKL theorem'', states that if <math>f</math> is Boolean then <math>\\max_i \\operatorname{Inf}_i[f] = \\Omega\\left(\\frac{\\log n}{n}\\right)</math>.\n\nThe bound given by the Kahn–Kalai–Linial theorem is tight, and is achieved by the ''Tribes'' function of Ben-Or and Linial:<ref>{{cite conference |title=Collective coin flipping, robust voting schemes and minima of Banzhaf values |last1=Ben-Or |first1=Michael |last2=Linial |first2=Nathan |date=1985 |publisher=IEEE |book-title=Proc. 26th Symp. on Foundations of Computer Science |pages=408–416 |location=Portland, Oregon |conference=SFCS'85 |doi=10.1109/SFCS.1985.15}}</ref>\n\n:<math> (x_{1,1} \\land \\cdots \\land x_{1,w}) \\lor \\cdots \\lor (x_{2^w,1} \\land \\cdots \\land x_{2^w,w}). </math>\n\nThe Kahn–Kalai–Linial theorem was one of the first results in the area, and was the one introducing hypercontractivity into the context of Boolean functions.\n\n===Friedgut's junta theorem===\n\nIf <math>f\\colon \\{-1,1\\}^n \\to \\{-1,1\\}</math> is an <math>M</math>-junta (a function depending on at most <math>M</math> coordinates) then <math>\\operatorname{Inf}[f] \\leq M</math> according to the Poincaré inequality.\n\nFriedgut's theorem<ref>{{cite journal |last=Friedgut |first=Ehud |date=1998 |title=Boolean functions with low average sensitivity depend on few coordinates |journal=Combinatorica |volume=18 |issue=1 |pages=474–483 |doi=10.1007/PL00009809|citeseerx=10.1.1.7.5597 }}</ref> is a converse to this result. It states that for any <math>\\varepsilon > 0</math>, the function <math>f</math> is <math>\\varepsilon</math>-close to a Boolean junta depending on <math>\\exp (\\operatorname{Inf}[f]/\\varepsilon)</math> coordinates.\n\nCombined with the Russo–Margulis lemma, Friedgut's junta theorem implies that for every <math>p</math>, every monotone function is close to a junta with respect to <math>\\mu_q</math> for some <math>q \\approx p</math>.\n\n===Invariance principle===\n\nThe invariance principle<ref>{{cite journal |last1=Mossel |first1=Elchanan |last2=O'Donnell |first2=Ryan |last3=Oleszkiewicz |first3=Krzysztof |date=2010 |title=Noise stability of functions with low influences: Invariance and optimality |journal=Ann. Math. |volume=171 |issue=1 |pages=295–341 |doi=10.4007/annals.2010.171.295|arxiv=math/0503503 }}</ref> generalizes the [[Berry–Esseen theorem]] to non-linear functions.\n\nThe Berry–Esseen theorem states (among else) that if <math>f = \\sum_{i=1}^n c_i x_i</math> and no <math>c_i</math> is too large compared to the rest, then the distribution of <math>f</math> over <math>\\{-1,1\\}^n</math> is close to a normal distribution with the same mean and variance.\n\nThe invariance principle (in a special case) informally states that if <math>f</math> is a multilinear polynomial of bounded degree over <math>x_1,\\ldots,x_n</math> and all influences of <math>f</math> are small, then the distribution of <math>f</math> under the uniform measure over <math>\\{-1,1\\}^n</math> is close to its distribution in Gaussian space.\n\nMore formally, let <math>\\psi</math> be a univariate [[Lipschitz continuity|Lipschitz function]], let <math>f = \\sum_{S \\subseteq [n]} \\hat{f}(S) \\chi_S</math>, let <math>k=\\deg f</math>, and let\n<math> \\varepsilon = \\max_i \\sum_{S \\ni i} \\hat{f}(S)^2</math>. Suppose that <math>\\sum_{S \\neq \\emptyset} \\hat{f}(S)^2 \\leq 1</math>. Then\n\n:<math> \\left| \\mathbb{E}_{x \\sim \\{-1,1\\}^n} [\\psi(f(x))] - \\mathbb{E}_{g \\sim N(0,I)} [\\psi(f(g))] \\right| = O(k9^k \\varepsilon). </math>\n\nBy choosing appropriate <math>\\psi</math>, this implies that the distributions of <math>f</math> under both measures are close in [[Cumulative distribution function|CDF distance]], which is given by <math>\\sup_t |\\Pr[f(x)<t] - \\Pr[f(g)<t]|</math>.\n\nThe invariance principle was the key ingredient in the original proof of the [[#Majority is Stablest|''Majority is Stablest'' theorem]].\n\n==Some applications==\n\n===Linearity testing===\n\nA Boolean function <math>f\\colon \\{-1,1\\}^n \\to \\{-1,1\\}</math> is ''linear'' if it satisfies <math>f(xy) = f(x)f(y)</math>, where <math>xy = (x_1y_1,\\ldots,x_ny_n)</math>. It is not hard to show that the Boolean linear functions are exactly the characters <math>\\chi_S</math>.\n\nIn [[property testing]] we want to test whether a given function is linear. It is natural to try the following test: choose <math>x,y \\in \\{-1,1\\}^n</math> uniformly at random, and check that <math>f(xy) = f(x)f(y)</math>. If <math>f</math> is linear then it always passes the test. Blum, Luby and Rubinfeld<ref>{{cite journal |last1=Blum |first1=Manuel |last2=Luby |first2=Michael |last3=Rubinfeld |first3=Ronitt |date=1993 |title=Self-testing/correcting with applications to numerical problems |journal=J. Comput. Syst. Sci. |volume=47 |number=3 |pages=549–595 |doi=10.1016/0022-0000(93)90044-W}}</ref> showed that if the test passes with probability <math>1-\\varepsilon</math> then <math>f</math> is <math>O(\\varepsilon)</math>-close to a Fourier character. Their proof was combinatorial.\n\nBellare et al.<ref>{{cite conference |last1=Bellare |first1=Mihir |last2=Coppersmith |first2=Don |last3=Håstad |first3=Johan |last4=Kiwi |first4=Marcos |last5=Sudan |first5=Madhu |date=1995 |title= Linearity testing in characteristic two |booktitle = Proc. 36th Symp. on Foundations of Computer Science |conference=FOCS'95}}</ref> gave an extremely simple Fourier-analytic proof, that also shows that if the test succeeds with probability <math>1/2 + \\varepsilon</math>, then <math>f</math> is correlated with a Fourier character. Their proof relies on the following formula for the success probability of the test:\n\n:<math> \\frac{1}{2} + \\frac{1}{2} \\sum_{S \\subseteq [n]} \\hat{f}(S)^3. </math>\n\n===Arrow's theorem===\n\n[[Arrow's impossibility theorem]] states that for three and more candidates, the only unanimous voting rule for which there is always a [[Condorcet criterion|Condorcet winner]] is a dictatorship.\n\nThe usual proof of Arrow's theorem is combinatorial. Kalai<ref>{{cite journal |last=Kalai |first=Gil |date=2002 |title=A Fourier-theoretic perspective on the Condorcet paradox and Arrow's theorem |journal=Adv. Appl. Math. |volume=29 |number=3 |pages=412–426 |doi=10.1016/S0196-8858(02)00023-4}}</ref> gave an alternative proof of this result in the case of three candidates using Fourier analysis. If <math>f\\colon \\{-1,1\\}^n \\to \\{-1,1\\}</math> is the rule that assigns a winner among two candidates given their relative orders in the votes, then the probability that there is a Condorcet winner given a uniformly random vote is <math>\\frac{3}{4} - \\frac{3}{4} \\operatorname{Stab}_{-1/3}[f]</math>, from which the theorem easily follows.\n\nThe [[#Friedgut–Kalai–Naor theorem|FKN theorem]] implies that if <math>f</math> is a rule for which there is almost always a Condorcet winner, then <math>f</math> is close to a dictatorship.\n\n===Sharp thresholds===\n\nA classical result in the theory of [[random graph]]s states that the probability that a <math>G(n,p)</math> random graph is connected tends to <math>e^{-e^{-c}}</math> if <math>p \\sim \\frac{\\log n + c}{n}</math>. This is an example of a ''sharp threshold'': the width of the \"threshold window\", which is <math>O(1/n)</math>, is asymptotically smaller than the threshold itself, which is roughly <math>\\frac{\\log n}{n}</math>. In contrast, the probability that a <math>G(n,p)</math> graph contains a triangle tends to <math>e^{-c^3/6}</math> when <math>p \\sim \\frac{c}{n}</math>. Here both the threshold window and the threshold itself are <math>\\Theta(1/n)</math>, and so this is a ''coarse threshold''.\n\nFriedgut's sharp threshold theorem<ref>{{cite journal |last=Friedgut |first=Ehud |date=1999 |title=Sharp thresholds of graph properties and the k-SAT problem |journal=J. Am. Math. Soc. |volume=12 |issue=4 |pages=1017–1054 |doi=10.1090/S0894-0347-99-00305-7}}</ref> states, roughly speaking, that a monotone graph property (a graph property is a property which doesn't depend on the names of the vertices) has a sharp threshold unless it is correlated with the appearance of small subgraphs. This theorem has been widely applied to analyze random graphs and [[percolation]].\n\nOn a related note, the [[#Kahn–Kalai–Linial theorem|KKL theorem]] implies that the width of threshold window is always at most <math>O(1/\\log n)</math>.<ref>{{cite journal |last1=Friedgut |first1=Ehud |last2=Kalai |first2=Gil |date=1996 |title=Every monotone graph property has a sharp threshold |journal= Proc. Am. Math. Soc. |volume=124 |issue=10 |pages=2993–3002 |doi=10.1090/S0002-9939-96-03732-X}}</ref>\n\n===Majority is stablest===\n\nLet <math>\\operatorname{Maj}_n\\colon \\{-1,1\\}^n \\to \\{-1,1\\}</math> denote the majority function on <math>n</math> coordinates. Sheppard's formula gives the asymptotic noise stability of majority:\n\n:<math> \\operatorname{Stab}_\\rho[\\operatorname{Maj}_n] \\longrightarrow 1 - \\frac{2}{\\pi} \\arccos \\rho. </math>\n\nThis is related to the probability that if we choose <math>x \\in \\{-1,1\\}^n</math> uniformly at random and form <math>y \\in \\{-1,1\\}^n</math> by flipping each bit of <math>x</math> with probability <math>\\frac{1-\\rho}{2}</math>, then the majority stays the same:\n:<math> \\operatorname{Stab}_\\rho[\\operatorname{Maj}_n] = 2\\Pr[\\operatorname{Maj}_n(x) = \\operatorname{Maj}_n(y)]-1</math>.\n\nThere are Boolean functions with larger noise stability. For example, a dictatorship <math>x_i</math> has noise stability <math>\\rho</math>.\n\nThe Majority is Stablest theorem states, informally, then the only functions having noise stability larger than majority have influential coordinates. Formally, for every <math>\\varepsilon > 0</math> there exists <math>\\tau > 0</math> such that if <math>f\\colon \\{-1,1\\}^n \\to \\{-1,1\\}</math> has expectation zero and <math>\\max_i \\operatorname{Inf}_i[f] \\leq \\tau</math>, then <math>\\operatorname{Stab}_\\rho[f] \\leq 1 - \\frac{2}{\\pi} \\arccos \\rho + \\varepsilon</math>.\n\nThe first proof of this theorem used the [[#Invariance principle|invariance principle]] in conjunction with an isoperimetric theorem of Borell in Gaussian space; since then more direct proofs were devised.\n\nMajority is Stablest implies that the [[Semidefinite programming#Example 3 .28Goemans-Williamson MAX CUT approximation algorithm.29|Goemans–Williamson approximation algorithm]] for [[Maximum cut|MAX-CUT]] is optimal, assuming the [[unique games conjecture]]. This implication, due to Khot et al.,<ref>{{citation\n | author1-link = Subhash Khot\n | last1 = Khot | first1 = Subhash\n | last2 = Kindler | first2 = Guy\n | last3 = Mossel | first3 = Elchanan\n | last4 = O'Donnell | first4 = Ryan\n | doi = 10.1137/S0097539705447372\n | issue = 1\n | journal = [[SIAM Journal on Computing]]\n | pages = 319–357\n | title = Optimal inapproximability results for MAX-CUT and other two-variable CSPs?\n | url = http://www.cs.cornell.edu/~abrahao/tdg/papers/KKMO-maxcut.pdf\n | volume = 37\n | year = 2007\n| citeseerx = 10.1.1.130.8886 }}</ref> was the impetus behind proving the theorem.\n\n==References==\n{{reflist}}\n\n[[Category:Boolean algebra]]\n[[Category:Mathematical optimization]]\n[[Category:Mathematics]]\n[[Category:Theoretical computer science]]"
    },
    {
      "title": "The Archimedeans",
      "url": "https://en.wikipedia.org/wiki/The_Archimedeans",
      "text": "'''The Archimedeans''' are the mathematical [[List of social activities at the University of Cambridge|society]] of the [[University of Cambridge]], founded in 1935. It currently has over 2000 active members<ref>{{Cite web|url=https://www.maths.cam.ac.uk/archimedeans-shaken-or-stirred|title=The Archimedeans: Shaken or stirred? Interview with Yanni Du.|last=|first=|date=|website=Faculty of Mathematics, University of Cambridge|archive-url=|archive-date=|dead-url=|access-date=20 May 2018}}</ref>, many of them alumni, making it one of the largest student societies in Cambridge. The society hosts regular talks at the [[Centre for Mathematical Sciences (Cambridge)|Centre for Mathematical Sciences]], including in the past by many well-known speakers in the field of mathematics. It publishes two magazines, [[Eureka (University of Cambridge magazine)|''Eureka'']] and ''QARCH''.<ref>{{Cite web|url=https://the-archimedeans.org.uk/|title=The Archimedeans|last=|first=|date=|website=the-archimedeans.org.uk|archive-url=|archive-date=|dead-url=|access-date=2019-02-25}}</ref>\n\nOne of several aims of the society, as laid down in its constitution, is to encourage co-operation between the existing mathematical societies of individual [[Colleges of the University of Cambridge|Cambridge colleges]], which at present are just the Adam's society of [[St John's College, Cambridge|St John's College]] and the [[Trinity Mathematical Society]], but in the past have included many more.\n\nThe society is mentioned in [[G. H. Hardy]]'s essay [[A Mathematician's Apology]].\n\nPast presidents of The Archimedeans include [[Michael Atiyah]] and [[Richard Taylor (mathematician)|Richard Taylor]].\n\n== Activity ==\nThe main focus of the society's activities are the regular talks, which generally concern topics from mathematics or theoretical physics, and are accessible to students on an undergraduate level. Among the list of recent speakers are [[Fields Medal|Fields medalists]] [[Michael Atiyah]], [[Wendelin Werner]] and [[Alain Connes]], as well as authors [[Ian Stewart (mathematician)|Ian Stewart]] and [[Simon Singh]]. Many of the speakers are international, and are hosted by The Archimedeans during their visit.\n\nAfter exams and University-wide project deadlines, the society is also known to organise social events, which have shown to be highly popular.\n\n== Publications ==\n''Eureka'' is a mathematical journal that is published annually by The Archimedeans. It includes articles on a variety of topics in mathematics, written by students and academics from all over the world, as well as a short summary of the activities of the society, [[Problem set|problem sets]], puzzles, artwork and book reviews. The magazine has been published 60 times since 1939, and authors include many famous mathematicians and scientists such as [[Paul Erdős]], [[Martin Gardner]], [[Douglas Hofstadter]], [[Godfrey Hardy]], [[Béla Bollobás]], [[John Horton Conway|John Conway]], [[Stephen Hawking]], [[Roger Penrose]], [[Ian Stewart (mathematician)|Ian Stewart]], Fields Medallist [[Timothy Gowers]] and [[Nobel Prize|Nobel laureate]] [[Paul Dirac]].\n\nThe journal is distributed free of charge to all current members of the Archimedeans. In addition, there are many subscriptions by other students, alumni and libraries. Subscriptions to ''Eureka'' are the society's main source of income.\n\nThe Archimedeans also publish ''QARCH'', a magazine containing problem sets and solutions or partial solutions submitted by readers. It is published on an irregular basis and distributed free of charge.\n\n== References ==\n<references />\n{{Authority control}}\n{{DEFAULTSORT:Archimedeans}}\n[[Category:British mathematicians]]\n[[Category:Mathematics]]\n[[Category:Clubs and societies of the University of Cambridge]]\n[[Category:Student organizations established in 1935]]"
    },
    {
      "title": "Archives of American Mathematics",
      "url": "https://en.wikipedia.org/wiki/Archives_of_American_Mathematics",
      "text": "The '''Archives of American Mathematics,''' located at the [[University of Texas at Austin]],  aims to collect, preserve, and provide access to the papers principally of American mathematicians and the records of American mathematical organizations.\n\n==  History  ==\n\nThe Archives  began in 1975 at the University of Texas at Austin with the preservation of the papers of Texas mathematicians [[Robert Lee Moore|R.L. Moore]] and [[Harry Vandiver|H.S. Vandiver]].<ref>{{Cite journal|last=Corry|first=Leo|date=2007|title=A Clash of Mathematical Titans in Austin: Robert Lee Moore and Harry Schultz Vandiver (1924-1974)|url=|journal=Mathematical Intelligencer|volume=29|pages=62–74|via=}}</ref>\n\nIn 1978, the [[Mathematical Association of America]] established the university as the official repository for its archival records and the name \"Archives of American Mathematics\" was adopted to encompass all of the mathematical archival collections at the university.<ref>The Minutes of the Board of Regents of The University of Texas System, 8–9 June 1978. https://www.utsystem.edu/sites/default/files/offices/board-of-regents/board-meetings/board-minutes/6-78meeting754.pdf pp. 3307-3312, accessed 17 July 2017.</ref>  Originally a part of the [[Harry Ransom Center]], in 1984, the Archives was added to the special collections of the [[Dolph Briscoe Center for American History|Briscoe Center for American History]] at the University of Texas at Austin.<ref>{{Cite journal|last1=Mead|first1=Carol|last2=Lewis|first2=Albert C.|date=September 2017|title=The Archives of American Mathematics|url=http://www.ems-ph.org/journals/newsletter/pdf/2017-09-105.pdf|journal=Newsletter of the European Mathematical Society|volume=105|pages=34–38|via=}}</ref>\n\n== Collections ==\n\nThe AAM includes approximately 120 collections.<ref>{{Cite web|url=http://www.cah.utexas.edu/collections/math_findingaids.php|title=Finding Aids - Archives of American Mathematics|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=20 July 2017}}</ref>\n\n=== Notable Examples ===\n\n*[[Mathematical Association of America]] Records.\n*[[Thomas Banchoff|Thomas F. Banchoff]] Papers  document a career of teaching, writing, and making mathematical films.\n*[[Marion Walter]] Photograph Collection  includes photographs of A.A.  Albert, H.S.M.  Coxeter, Paul Erdős, Fritz John, D.H. Lehmer, Alexander Ostrowski, George Polya, Mina Rees, and Olga Taussky-Todd.<ref>{{Cite web|url=https://www.maa.org/press/periodicals/maa-focus/introducing-the-marion-walter-collection|title=Introducing the Marion Walter Collection {{!}} Mathematical Association of America|website=www.maa.org|access-date=2017-07-20}}</ref>\n*[[School Mathematics Study Group]] Records  document the history of the \"New Math\" movement of the 1960s, and includes the files of the director, Edward G.  Begle.\n*[[Dorothy Lewis Bernstein|Dorothy L. Bernstein]] Papers  reflect both her professional and personal life.\n*[[Paul Halmos|Paul R. Halmos]] Photograph Collection  consists of 14,000 photographs Halmos and others took from the 1930s to 2006.\n*[[Ivor Grattan-Guinness]] Papers  reflect the career of a mathematics historian.\n*[[Paul Erdős]] and [[Carl Pomerance]] Correspondence Collection  consists of 435 letters between Erdős and Pomerance.\n\n=== Related Collections Elsewhere ===\nSignificant archives of American mathematicians and their organizations are held by other repositories. The following are examples which include a few Canadian collections with substantial United States connections. For the complete holdings, the catalogs of the individual repositories would need to be consulted. In addition, the archives of academic institutions will typically include administrative records of mathematics departments and clubs as well as the papers of faculty.\n\n* John Hay Library, [[Brown University]]   -- [[American Mathematical Society]] Records (1888- ); [[Raymond Clare Archibald]] (1875-1957); James Glaisher (1848-1928); R. G. D. Richardson (1878-1949); [[Marshall Harvey Stone]] (1903-1989); [[James Joseph Sylvester]] (1814-1897) also at St. John's College (Cambridge).<ref>{{Cite web|url=http://library.brown.edu/hay/|title=John Hay Library, Brown University|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=20 February 2018}}</ref>\n* [[American Philosophical Society]] -- [[Robert Patterson (educator)|Robert Patterson]]  (1743-1824); [[David Rittenhouse]]  (1732-1796); [[Robert Adrain]]  (1775-1843); [[Samuel S. Wilks|Samuel Stanley Wilks]]  (1906-1964).<ref>{{Cite web|url=https://amphilsoc.org/library/manuscripts|title=American Philosophical Society, Manuscripts Department|last=|first=|date=|website=|archive-url=https://web.archive.org/web/20170213163012/https://amphilsoc.org/library/manuscripts|archive-date=13 February 2017|dead-url=yes|access-date=20 February 2018}}</ref>\n* [[Amherst College]]—Ebenezer Strong Snell  (1801-1876).<ref>{{Cite web|url=https://www.amherst.edu/library|title=Amherst College, Library|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=20 February 2018}}</ref>\n* [[Boston Public Library]] -- [[Nathaniel Bowditch]]  (1773-1838); Nicholas Pike  (1743-1819).<ref>{{Cite web|url=http://www.bpl.org/research/rb/index.htm|title=Boston Public Library, Rare Books and Manuscripts Department|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=20 February 2018}}</ref>\n* College of Charleston Library—Lewis Reeves Gibbes  (1810-1894), also Library of Congress;<ref>{{Cite web|url=http://archives.library.cofc.edu/findingaids/mss0020.html|title=Gibbes Papers, College of Charleston|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=20 February 2018}}</ref>\n* [[Columbia University]] --  [[Arthur Korn]]  (1870-1945);  [[Cassius Jackson Keyser]]  (1862-1947); [[Christine Ladd-Franklin|Christine Franklin]] (1847-1930) and Fabian Franklin  (1853-1939); [[Frederick Augustus Porter Barnard|F. A. P. Barnard]]  (1809-1889);  [[Harold Hotelling]]  (1895-); [[Henry Seely White]]  (1861-1943);  [[John Howard Van Amringe]]  (1835-1915); [[Thomas Fiske|Thomas Scott Fiske]]  (1865-1944); [[David Eugene Smith]]  (1860-1944).<ref>{{Cite web|url=http://library.columbia.edu/locations/rbml.html|title=Rare Book & Manuscript Library, Columbia University|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=20 February 2018}}</ref>\n* [[Dartmouth College]] -- [[George Stibitz|George Robert Stibitz]]  (1904-1995).<ref>{{Cite web|url=http://libcat.dartmouth.edu/search~S1?/Xstibitz&searchscope=1&SORT=D&Da=&Db=&p=/Xstibitz&searchscope=1&SORT=D&Da=&Db=&p=&SUBKEY=stibitz/1%2C10%2C10%2CB/frameset&FF=Xstibitz&searchscope=1&SORT=D&Da=&Db=&p=&2%2C2%2C|title=Stibitz Papers, Dartmouth University|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=20 February 2018}}</ref>\n* [[Duke University]]—Edward Henry Courtenay  (1803-1853).<ref>{{Cite web|url=http://library.duke.edu/rubenstein/findingaids/purviancefamily/|title=Courtenay/Purviance Finding Aid|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[Hampshire College]]—Herman Goldstine  (1913-2004).<ref>{{cite web|url=https://asteria.fivecolleges.edu/findaids/hampshire/mah001_main.html|website=Five College Archives and Manuscript Collections, Hampshire College Archives|title=Herman H. Goldstine Collection, 1941-1971}}</ref>\n* [[Harvard University]] --  [[Benjamin Peirce]]  (1809-1880);  [[Charles Sanders Peirce]]  (1839-1914); [[Damodar Dharmananda Kosambi|Damodar Dharmanand Kosambi]]  (1907–1966); [[Isaac Greenwood]]  (1702-1745);  [[John Farrar (scientist)|John Farrar]]  (1779-1853); [[John Winthrop (educator)|John Winthrop]]  (1714–1779);  [[Maxime Bôcher]]  (1867-1918); [[Richard von Mises|Richard Von Mises]]  (1883-1953);  [[Thomas Hill (clergyman)|Thomas Hill]]  (1818-1891); [[George David Birkhoff]]  (1884-1944).<ref>{{Cite web|url=http://library.harvard.edu/university-archives/using-the-collections/homepage|title=Harvard University Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[Iowa State University]] --  [[American Statistical Association]] (1839-); [[Herbert Solomon]]  (1919-2004); [[Edward Wegman|Edward J. Wegman]]  (1943-);  [[Eugene Lukacs]]  (1906-1987); [[Ingram Olkin]]  (1924-).<ref>{{Cite web|url=http://archives.lib.iastate.edu/|title=Iowa State University, Special Collections and University Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[Hope College]]—Albert Eugene Lampen  (1887-1963); Jay Erenst Folkert  (1916-).<ref>{{cite web|title=Joint Archives of Holland, Hope College|url=https://hope.edu/library/joint-archives-holland/}}</ref>\n* [[Library of Congress]] --  [[Andrew Ellicott]]  (1754-1820); George F. Becker  (1847-1919); [[Oswald Veblen]]  (1880-1960); Lewis Reeves Gibbes  (1810-1894), [[John von Neumann]] (1903-1957), also College of Charleston.<ref>{{Cite web|url=http://rs5.loc.gov/service/mss/eadxmlmss/eadpdfmss/2004/ms004009.pdf|title=Lewis Reeves Gibbes Papers. A Finding Aid.|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[Maryland Historical Society]] --  [[John Henry Alexander]]  (1812-1867).<ref>{{Cite web|url=http://m60006.eos-intl.net/M60006/OPAC/Index.aspx|title=H. Furlong Baldwin Library, Maryland Historical Society|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[McMaster University]] (Canada) -- [[Bertrand Russell]]  (1872-1970).<ref>{{Cite web|url=http://www.mcmaster.ca/russdocs/russell.htm|title=Bertrand Russell Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[Massachusetts Institute of Technology]] --  [[John Daniel Runkle]]  (1822-1902); [[Norbert Wiener]]  (1894-1964).<ref>{{Cite web|url=https://libraries.mit.edu/archives/|title=Institute Archives & Special Collections, MIT|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[New Jersey Historical Society]] --  [[Francis Robbins Upton]]  (1852-1921).<ref>{{Cite web|url=http://www.jerseyhistory.org/findingaid.php?aid=0988|title=Upton Collection|last=|first=|date=|website=|archive-url=https://web.archive.org/web/20170219013652/http://jerseyhistory.org/findingaid.php?aid=0988|archive-date=19 February 2017|dead-url=yes|access-date=3 March 2018}}</ref>\n* [[New York Public Library]] -- [[Ferdinand Rudolph Hassler]]  (1770-1843).<ref>{{Cite web|url=http://archives.nypl.org/mss/1348|title=Hassler Correspondence|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[New York University]] --  [[Richard Courant]]  (1888-1972).<ref>{{Cite web|url=http://dlib.nyu.edu/findingaids/html/archives/courant/|title=Courant Collection|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=3 March 2018}}</ref>\n* [[Northwestern University]] --  [[Ernst Hellinger|Ernst D. Hellinger]]  (1883-1950); Helen M. Clark  (1908-1974); [[Lois Wilfred Griffiths|Lois W. Griffiths]]  (1899-1981).<ref>{{Cite web|url=http://www.library.northwestern.edu/libraries-collections/university-archives/index.html|title=Northwestern University Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[Ohio History Connection]] --  [[Jared Mansfield]]  (1759-1830), also  U.S. Military Academy.<ref>{{Cite web|url=http://catalog.ohiohistory.org/Presto/home/home.aspx|title=Ohio History Connection|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[Princeton University]] --  [[Alfred J. Lotka|Alfred James Lotka]]  (1880-1949);  Walter Minto (1753-1796);  [[Eugene Wigner|Eugene Paul Wigner]]  (1902-1995); Henry Dallas Thompson  (1864-1927); [[Kurt Gödel]]  (1906-1978); [[Nicola Fergola]]  (1757-1824); Sylvester Robins  (files: 1880-1899).<ref>{{Cite web|url=http://rbsc.princeton.edu/mudd|title=Princeton University Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[Rice University]]—Fred Terry Rogers  (1914-1956);  [[Salomon Bochner]]  (1899-1982).<ref>{{Cite web|url=https://library.rice.edu/woodson|title=Rice University, Woodson Research Center Special Collections & Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[Rockefeller University]] --  [[Mark Kac]]  (1914-1984).<ref>{{Cite web|url=http://rockarch.org/collections/ru/|title=Rockefeller University Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[Rutgers University]]—Edward Albert Bowser  (1837-1910);  George Washington Coakley  (1814-1893).<ref>{{Cite web|url=http://www.libraries.rutgers.edu/scua|title=Rutgers University, Special Collections & University Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[Smith College]], Sophia Smith Collection --  [[Dorothy Maud Wrinch]]  (1895-1976).<ref>{{Cite web|url=http://asteria.fivecolleges.edu/findaids/sophiasmith/mnsss403_main.html|title=Five College Archives & Manuscript Collections, Wrinch Collectoni|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[Stanford University]] --  [[George Pólya|Georg Pólya]]  (1887-1985).<ref>{{Cite web|url=http://www.oac.cdlib.org/findaid/ark:/13030/kt7q2nf5cb/|title=Pólya (George) Papers|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[University of Chicago]] --  [[Abraham Adrian Albert|A. Adrian Albert]]  (1905-1972 ); [[Saunders Mac Lane]] (1909-2005); [[E. H. Moore]] (1862-1932); Alfred L. Putnam (1916-2004); [[Nicolas Rashevsky]] (1899-1972); [[Ernest Julius Wilczynski]] (1876-1932).<ref>{{Cite web|url=https://www.lib.uchicago.edu/scrc/|title=University of Chicago, Special Collections Research Center|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[University of Illinois at Urbana–Champaign|University of Illinois at Urbana-Champaign]] --  [[Arnold Emch]]  (1871-1959); [[Arthur Byron Coble]]  (1878-1966); [[George Abram Miller]]  (1863-1951);  George William Meyers  (1864-1931); [https://archives.library.illinois.edu/archon/?p=creators/creator&id=1152 Leonard L. Steimley]  (1890-1975);  [[Olive Hazlett|Olive C. Hazlett]]  (1890-1974); [[Robert Daniel Carmichael]]  (1879-1967).<ref>{{Cite web|url=https://archives.library.illinois.edu/|title=University of Illinois Archives|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[University of Michigan]]—Wooster Woodruff Beman<ref>{{Cite web|url=http://umhistory.dc.umich.edu/history/Faculty_History/B/Beman,_Wooster_Woodruff.html|title=WOOSTER WOODRUFF BEMAN|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref> (1850-1922);  Louis Allen Hopkins <ref>{{Cite web|url=https://www.lib.umich.edu/faculty-history/faculty/louis-allen-hopkins|title=Louis Allen Hopkins|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref> (1881-).<ref>{{Cite web|url=http://bentley.umich.edu/|title=Bentley Historical Library, University of Michigan|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[State Historical Society of Missouri]]—Joseph Ficklin  (1833-1887).<ref>{{Cite web|url=https://shsmo.org/manuscripts/columbia/c0100.pdf|title=Joseph Ficklin finding aid|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[University of North Carolina at Chapel Hill|University of North Carolina]]; [[University of Texas at Austin|U. of Texas]] --  [[Charles S. Venable|Charles Scott Venable]]  (1827-1900).<ref>{{Cite web|url=http://library.unc.edu/|title=UNC University Libraries|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref><ref>{{Cite web|url=https://www.cah.utexas.edu/projects/nhprc/collections.php#V|title=The Dolph Briscoe Center for American History|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>\n* [[University of Oklahoma|University of Oklahoma Library]] -- [[Nathan Altshiller Court]]  (1881-1968).<ref>{{Cite web|url=https://libraries.ou.edu/locations/docs/westhist/pdf/CourtNathanA.pdf|title=Nathan A. Court Collection|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=10 May 2018}}</ref>\n* [[University of Toronto]] --  [[Kenneth O. May]]  (1915-1977).<ref>{{Cite web|url=https://search.library.utoronto.ca/details?8884301|title=Kenneth Ownsworth May fonds|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=10 May 2018}}</ref>\n* [[University of Virginia]] -- [[Gordon Thomas Whyburn|G. T. Whyburn]] (1904-1969)<ref>{{Cite web|url=https://search.lib.virginia.edu/catalog/u4595280|title=Gordon Thomas Whyburn Papers|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=19 July 2018}}</ref>\n* [[University of Washington Libraries]] --  [[Carl B. Allendoerfer]]  (1911-1974).<ref>{{Cite web|url=http://archiveswest.orbiscascade.org/ark:/80444/xv53686/pdf|title=Carl Allendoerfer papers|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=10 May 2018}}</ref>\n* [[University of Wisconsin–Madison|University of Wisconsin]] --  [[Albert Charles Schaeffer|Albert C. Schaeffer]]  (files: 1954-1956); Bronson Barlow (Mathematics of Design)   (b. 1924); Charles S. Slichter  (files: 1891-1941); [[Cyrus Colton MacDuffee|Cyrus C. MacDuffee]]  (1895-1961); [[Edward Burr Van Vleck]]  (1863-1943); Ernest B. Skinner  (files: 1892-1935); [[Isaac Jacob Schoenberg|Isaac Schoenberg]]  (files: 1930-1980); Ivan Sokolnikoff  (1901-); [[J. Barkley Rosser]]  (1907-1989); John D. Mayor  (?);  Mark H. Ingraham  (1896-1982); Military Training Programs, WW II  (1943-1945); U.S. Naval Research Office  (1951-1955); Rudolph E. Langer  (1894-1968); [[Stephen Cole Kleene|Stephen Kleene]]  (1909-1994); [[Warren Weaver]]  (1894-1978).<ref>{{Cite web|url=https://www.library.wisc.edu/archives/|title=UW Archives and Records Management|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=14 May 2018}}</ref>\n* [[Virginia Military Institute]] --  [[Claudius Crozet]]  (1789-1864).<ref>{{Cite web|url=https://archivesspace.vmi.edu/repositories/3/resources/585|title=VMI Collections: Claudius Crozet Papers|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=15 May 2018}}</ref>\n* [[Virginia Polytechnic Institute And State Univ|Virginia Polytechnic Institute and State U.]] --  [[I. J. Good|Irving John Good]]  (1916-2009);<ref>{{Cite web|url=http://ead.lib.virginia.edu/vivaxtf/view?docId=vt/viblbv01155.xml|title=A Guide to the Irving J. Good Papers|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=15 May 2018}}</ref> John Edward Williams  (1867-1943).<ref>{{Cite web|url=http://ead.lib.virginia.edu/vivaxtf/view?docId=vt/viblbv00221.xml;query=John%20Edward%20Williams;brand=default|title=Guide to the John Edward Williams Papers|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=15 May 2018}}</ref>\n* [[Wake Forest University]]—John Wesley Sawyer  (1916-);<ref>{{Cite web|url=https://wakespace.lib.wfu.edu/handle/10339/27859|title=John Wesley Sawyer Papers {{!}} ZSR Library|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=17 May 2018}}</ref>  Roland L. Gay  (1905-1979)<ref>{{Cite web|url=https://wakespace.lib.wfu.edu/handle/10339/28048|title=Roland L. Gay Papers {{!}} ZSR Library|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=17 May 2018}}</ref>\n* [[Western Reserve Historical Society]] (Cleveland) --  [[Elisha Scott Loomis]]  (1852-1940).<ref>{{Cite web|url=https://www.wrhs.org/research/search/|title=Search {{!}} Western Reserve Historical Society|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=17 May 2018}}</ref>\n* [[Yale University Library]] --  [[Abraham Robinson]]  (1918-1974);  [[Elias Loomis]]  (1811-1889); [[Josiah Willard Gibbs]]  (1839-1903).<ref>{{Cite web|url=http://search.library.yale.edu/|title=YUL Quicksearch|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=17 May 2018}}</ref>\n* [[Yeshiva University]] -- [[Jekuthiel Ginsburg]] (1889-1957)<ref>{{Cite web|url=https://libguides.yu.edu/home|title=Yeshiva University Libraries|last=|first=|date=|website=|archive-url=https://web.archive.org/web/20180522021159/https://libguides.yu.edu/home|archive-date=22 May 2018|dead-url=yes|access-date=17 May 2018}}</ref>\n\n== References ==\n<!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using<ref></ref> tags, these references will then appear here automatically -->\n{{Reflist}}\n\n== External links ==\n* [http://www.cah.utexas.edu/collections/math.php Archives of American Mathematics]\n\n{{coord missing|United States}}\n\n[[Category:Archives in the United States]]\n[[Category:Mathematics]]\n[[Category:University of Texas at Austin]]"
    },
    {
      "title": "Cayley–Menger determinant",
      "url": "https://en.wikipedia.org/wiki/Cayley%E2%80%93Menger_determinant",
      "text": "In [[linear algebra]], [[geometry]], and [[trigonometry]], the '''Cayley–Menger determinant''' is a formula for the content, i.e.&nbsp;the higher-dimensional [[volume]], of a <math display=\"inline\">n</math>-dimensional [[simplex]] in terms of the squares of all of the [[distance]]s between pairs of its vertices.\n\n== Definition ==\nLet <math display=\"inline\">A_0, A_1,\\ldots, A_n</math> be <math>n+1</math> points in <math>k </math>-dimensional [[Euclidean space]], often with <math>k \\ge n</math>. These points are the vertices of an ''n''-dimensional simplex: a triangle when <math>n = 2</math>; a tetrahedron when <math>n = 3</math>, and so on. Let <math display=\"inline\">d_{ij}</math> be the distances between <math>A_i</math> and <math display=\"inline\">A_j</math>, for <math>0 \\leq i < j \\leq n</math>. The content, i.e. the ''n''-dimensional volume of this simplex, denoted by <math>v_n</math>, can be expressed as a function of [[determinant]]s of certain matrices, as follows:<ref>{{Cite book|title=An Introduction to the Geometry of ''n'' Dimensions|last=Sommerville|first=D. M. Y.|publisher=Dover Publications|year=1958|isbn=|location=New York|pages=}}</ref>\n\n<math display=\"block\">\n\\begin{align}\nv_n^2 & = \\frac{1}{(n!)^2 2^n}\n\\begin{vmatrix} \n2d_{01}^2 & d_{01}^2 + d_{02}^2 - d_{12}^2 & \\cdots & d_{01}^2 + d_{0n}^2 - d_{1n}^2 \\\\\nd_{01}^2 + d_{02}^2 - d_{12}^2 & 2d_{02}^2 & \\cdots & d_{02}^2 + d_{0n}^2 - d_{1n}^2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nd_{01}^2 + d_{0n}^2 - d_{1n}^2 & d_{02}^2 + d_{0n}^2 - d_{1n}^2 & \\cdots & 2d_{0n}^2\n\\end{vmatrix} \\\\[10pt]\n& = \\frac{(-1)^{n+1}}{(n!)^2 2^n} \n\\begin{vmatrix} \n0 & d_{01}^2 & d_{02}^2 & \\cdots & d_{0n}^2 & 1 \\\\\nd_{01}^2 & 0 & d_{12}^2 & \\cdots & d_{1n}^2 & 1 \\\\\nd_{02}^2 & d_{12}^2 & 0 & \\cdots & d_{2n}^2 & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\nd_{0n}^2 & d_{1n}^2 & d_{2n}^2 & \\cdots & 0 & 1 \\\\\n1 & 1 & 1 & \\cdots & 1 & 0\n\\end{vmatrix}.\n\\end{align}\n</math>\n\nThis is the '''Cayley–Menger determinant'''. It is a [[symmetric polynomial]] in the <math>d_{ij} </math>'s and is thus invariant under permutation of these quantities.\n\nA proof of the second equation can be found <ref>{{Cite web|url=https://www.mathpages.com/home/kmath664/kmath664.htm|title=Simplex Volumes and the Cayley-Menger Determinant|last=|first=|date=|website=www.mathpages.com|archive-url=https://web.archive.org/web/20190516033847/https://www.mathpages.com/home/kmath664/kmath664.htm|archive-date=16 May 2019|dead-url=|access-date=2019-06-08}}</ref>. From the second equation, the first can be derived by [[Elementary row operation|elementary row and colomn operations]]:\n\n<math>\\begin{vmatrix} \n0 & d_{01}^2 & d_{02}^2 & \\cdots & d_{0n}^2 & 1 \\\\\nd_{01}^2 & 0 & d_{12}^2 & \\cdots & d_{1n}^2 & 1 \\\\\nd_{02}^2 & d_{12}^2 & 0 & \\cdots & d_{2n}^2 & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\nd_{0n}^2 & d_{1n}^2 & d_{2n}^2 & \\cdots & 0 & 1 \\\\\n1 & 1 & 1 & \\cdots & 1 & 0\n\\end{vmatrix} = \n\\begin{vmatrix} \n0 & 0 & 0 & \\cdots & 0 & 1 \\\\\n\n0 & -2d_{01}^2 & d_{12}^2-d_{02}^2-d_{01}^2 & \\cdots & d_{1n}^2-d_{0n}^2-d_{01}^2 & 0 \\\\\n\n0 & d_{12}^2-d_{01}^2-d_{02}^2 & -2d_{02}^2 & \\cdots & d_{2n}^2-d_{0n}^2-d_{02}^2 & 0 \\\\\n\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n\n0 & d_{1n}^2-d_{01}^2-d_{0n}^2 & d_{2n}^2-d_{02}^2-d_{0n}^2 & \\cdots & -2d_{0n}^2& 0 \\\\\n\n1 & 0 & 0 & \\cdots & 0 & 0\n\\end{vmatrix} </math>then exchange the first and last column, gaining a <math>-1</math>, and multiply each of its <math>n</math> inner rows by <math>-1</math>.\n\n== Generalization to hyperbolic and spherical geometry ==\nThere are spherical and hyperbolic generalizations.<ref name=\":0\">{{Cite journal|last=Blumenthal|first=L. M.|last2=Gillam|first2=B. E.|date=1943|title=Distribution of Points in n-Space|url=https://www.tandfonline.com/doi/pdf/10.1080/00029890.1943.11991349|journal=The American Mathematical Monthly|language=en|volume=|pages=|doi=10.2307/2302400|via=}}</ref> A proof can be found here <ref>{{Cite web|url=https://terrytao.wordpress.com/2019/05/25/the-spherical-cayley-menger-determinant-and-the-radius-of-the-earth/|title=The spherical Cayley-Menger determinant and the radius of the Earth|last=Tao|first=Terrence|date=2019-05-25|website=What's new|language=en|archive-url=|archive-date=|dead-url=|access-date=2019-06-10}}</ref>.\n\nIn a [[Spherical space form|spherical space]] of dimension <math>(n-1)</math> and constant curvature <math>1/R</math>, any <math>(n+1)</math> points satisfy\n\n<math>\\begin{vmatrix} \n0 & f(d_{01}) & f(d_{02}) & \\cdots & f(d_{0n}) & 1 \\\\\nf(d_{01}) & 0 & f(d_{12}) & \\cdots & f(d_{1n}) & 1 \\\\\nf(d_{02}) & f(d_{12}) & 0 & \\cdots & f(d_{2n}) & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\nf(d_{0n}) & f(d_{1n}) & f(d_{2n}) & \\cdots & 0 & 1 \\\\\n1 & 1 & 1 & \\cdots & 1 & \\frac{1}{2R^2}\n\\end{vmatrix} = 0 </math>\n\nwhere <math>f(d) = 2R^2 \\left(1-\\cos\\frac{d}{R}\\right)</math>, and <math>d_{ij}</math> is the spherical distance between points <math>i, j</math>.\n\nIn a [[hyperbolic space]] of dimension <math>(n-1)</math> and constant curvature <math>-1/R</math>, any <math>(n+1)</math> points satisfy\n\n<math>\\begin{vmatrix} \n0 & f(d_{01}) & f(d_{02}) & \\cdots & f(d_{0n}) & 1 \\\\\nf(d_{01}) & 0 & f(d_{12}) & \\cdots & f(d_{1n}) & 1 \\\\\nf(d_{02}) & f(d_{12}) & 0 & \\cdots & f(d_{2n}) & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\nf(d_{0n}) & f(d_{1n}) & f(d_{2n}) & \\cdots & 0 & 1 \\\\\n1 & 1 & 1 & \\cdots & 1 & -\\frac{1}{2R^2}\n\\end{vmatrix} = 0 </math>\n\nwhere <math>f(d) = 2R^2 \\left(\\cosh\\frac{d}{R} - 1\\right)</math>, and <math>d_{ij}</math> is the hyperbolic distance between points <math>i, j</math>.\n\n== Example ==\nIn the case of <math>n = 2 </math>, we have that <math>v_2 </math> is the [[area]] of a [[triangle]] and thus we will denote this by <math>A </math>. By the Cayley–Menger determinant, where the triangle has side lengths <math>a</math>, <math>b</math> and <math>c</math>,\n\n: <math>\\begin{align}\n16A^2 &= \\begin{vmatrix} 2a^2 & a^2+b^2-c^2 \\\\ a^2+b^2-c^2 & 2b^2 \\end{vmatrix} \\\\[8pt]\n&= 4a^2b^2 - (a^2+b^2-c^2)^2 \\\\[6pt]\n&= (a^2+b^2+c^2)^2 - 2(a^4+b^4+c^4) \\\\[6pt]\n&= (a+b+c)(a+b-c)(a-b+c)(-a+b+c)\n\\end{align}</math>\n\nThe result in the third line is due to the [[Brahmagupta–Fibonacci identity|Fibonacci identity]]. The final line can be rewritten to obtain [[Heron's formula]] for the area of a triangle given three sides, which was known to Archimedes prior<ref>{{cite book|title=A History of Greek Mathematics (Vol II)|author=Heath, Thomas L.|publisher=Oxford University Press|year=1921|pages=321–323}}</ref>.\n\nIn the case of <math>n=3</math>, the quantity <math>v_3</math> gives the volume of a [[tetrahedron]], which we will denote by <math>V</math>. For distances between <math>A_i</math> and <math>A_j</math> given by <math>d_{ij}</math>, the Cayley–Menger determinant gives us<ref>{{Cite journal|last=Audet|first=Daniel|date=|title=Déterminants sphérique et hyperbolique de Cayley–Menger|url=https://archimede.mat.ulaval.ca/amq/bulletins/mai11/Chronique_note_math.mai11.pdf|journal=Bulletin AMQ|volume=LI|pages=45-52|via=}}</ref><ref>{{Cite book|title=100 Great Problems of Elementary Mathematics|last=Dörrie|first=Heinrich|publisher=Dover Publications|year=1965|isbn=|location=New York|pages=285-9}}</ref>\n\n: <math>\\begin{align}\n144V^2 = {} & \\frac{1}{2}\n\\begin{vmatrix}\n2d_{01}^2 & d_{01}^2+d_{02}^2-d_{12}^2 & d_{01}^2+d_{03}^2-d_{13}^2 \\\\\nd_{01}^2+d_{02}^2-d_{12}^2 & 2d_{02}^2 & d_{02}^2+d_{03}^2-d_{23}^2 \\\\\nd_{01}^2+d_{03}^2-d_{13}^2 & d_{02}^2+d_{03}^2-d_{23}^2 & 2d_{03}^2\n\\end{vmatrix} \\\\[8pt]\n= {} & 4d_{01}^2 d_{02}^2 d_{03}^2 + (d_{01}^2+d_{02}^2-d_{12}^2)(d_{01}^2+d_{03}^2-d_{13}^2)(d_{02}^2+d_{03}^2-d_{23}^2) \\\\[6pt]\n& {} -d_{01}^2(d_{02}^2+d_{03}^2-d_{23}^2)^2 - d_{02}^2(d_{01}^2+d_{03}^2-d_{13}^2)^2 - d_{03}^2(d_{01}^2+d_{02}^2-d_{12}^2)^2.\n\\end{align}</math>\n\n=== Finding the circumradius of a simplex ===\nGiven a nondegenerate n-simplex, it has a circumscribed n-sphere, with radius <math>r</math>. Then the (n+1)-simplex made of the vertices of the n-simplex and the center of the n-sphere is degenerate. Thus, we have \n\n<math>\n\\begin{vmatrix} \n0 & r^2 & r^2 & r^2 & \\cdots & r^2  & 1 \\\\\nr^2 & 0 & d_{01}^2 & d_{02}^2 & \\cdots & d_{0n}^2 & 1 \\\\\nr^2 & d_{01}^2 & 0 & d_{12}^2 & \\cdots & d_{1n}^2 & 1 \\\\\nr^2 & d_{02}^2 & d_{12}^2 & 0 & \\cdots & d_{2n}^2 & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\nr^2 & d_{0n}^2 & d_{1n}^2 & d_{2n}^2 & \\cdots & 0 & 1 \\\\\n1 & 1 & 1 & 1 & \\cdots & 1 & 0\n\\end{vmatrix} = 0\n</math>\n\nIn particular, when <math>\nn = 2\n</math>, this gives the circumradius of a triangle in terms of its edge lengths.\n\n== See also ==\n\n* [[Distance geometry]]\n\n== References ==\n{{reflist}}\n\n[[Category:Mathematics]]"
    },
    {
      "title": "Data-driven control system",
      "url": "https://en.wikipedia.org/wiki/Data-driven_control_system",
      "text": "'''Data-driven control systems''' are a broad family of [[Control theory|control systems]], in which the [[System identification|identification]] of the process model and/or the design of the controller are based entirely on ''experimental data'' collected from the plant <ref>Bazanella, A.S., Campestrini, L., Eckhard, D. (2012). Data-driven controller design: the <math>H_2</math> approach. Springer, {{ISBN|978-94-007-2300-9}}, 208 pages.</ref>.\n\nIn many control applications, trying to write a mathematical model of the plant is considered a hard task, requiring efforts and time to the process and control engineers. This problem is overcome by ''data-driven'' methods, which allow to fit a system model to the experimental data collected, choosing it in a specific models class. The control engineer can then exploit this model to design a proper controller for the system. However, it is still difficult to find a simple yet reliable model for a physical system, that includes only those dynamics of the system that are of interest for the control specifications. The ''direct'' data-driven methods allow to tune a controller, belonging to a given class, without the need of an identified model of the system. In this way, one can also simply weight process dynamics of interest inside the control cost function, and exclude those dynamics that are out of interest.\n\n== Overview ==\n\nThe ''standard'' approach to control systems design is organized in two-steps: \n# Model identification aims at estimating a nominal model of the system <math>\\widehat{G} = G\\left(q; \\widehat{\\theta}_N\\right)</math>, where <math>q</math> is the unit-delay operator (for discrete-time transfer functions representation) and <math>\\widehat{\\theta}_N</math> is the vector of parameters of <math>G</math> identified on a set of <math>N</math> data. Then, validation consists in constructing the ''uncertainty set'' <math>\\Gamma</math> that contains the true system <math>G_0</math> at a certain probability level.\n# Controller design aims at finding a controller <math>C</math> achieving closed-loop stability and meeting the required performance with <math>\\widehat{G}</math>.\nTypical objectives of [[System Identification|system identification]] are to have <math>\\widehat{G}</math> as close as possible to <math>G_0</math>, and to have <math>\\Gamma</math> as small as possible. However, from an [[System identification#Identification for control|identification for control]] perspective, what really matters is the performance achieved by the controller, not the intrinsic quality of the model.\n\nOne way to deal with uncertainty is to design a controller that has an acceptable performance with all models in <math>\\Gamma</math>, including <math>G_0</math>. This is the main idea behind [[robust control]] design procedure, that aims at building frequency domain uncertainty descriptions of the process. However, being based on worst-case assumptions rather than on the idea of averaging out the noise, this approach typically leads to ''conservative'' uncertainty sets. Rather, data-driven techniques deal with uncertainty by working on experimental data, and avoiding excessive conservativism.\n\nIn the following, the main classifications of data-driven control systems are presented.\n\n=== Indirect and direct methods ===\nThere are many methods available to control the systems. \nThe fundamental distinction is between '''indirect''' and '''direct''' controller design methods. The former group of techniques is still retaining the standard two-step approach, ''i.e.'' first a model is identified, then a controller is tuned based on such model. The main issue in doing so is that the controller is computed from the estimated model <math>\\widehat{G}</math> (according to the [[Stochastic control#Certainty equivalence|certainty equivalence]] principle), but in practice <math>\\widehat{G} \\neq G_0</math>. To overcome this problem, the idea behind the latter group of techniques is to map the experimental data ''directly'' onto the controller, without any model to be identified in between.\n\n=== Iterative and noniterative methods ===\n\nAnother important distinction is between '''iterative''' and '''noniterative''' (or '''one-shot''') methods. In the former group, repeated iterations are needed to estimate the controller parameters, during which the [[Optimization_problem|optimization problem]] is performed based on the results of the previous iteration, and the estimation is expected to become more and more accurate at each iteration. This approach is also prone to on-line implementations (see below). In the latter group, the (optimal) controller parametrization is provided with a single optimization problem. This is particularly important for those systems in which iterations or repetitions of data collection experiments are limited or even not allowed (for example, due to economic aspects). In such cases, one should select a design technique capable of delivering a controller on a single data set. This approach is often implemented off-line (see below).\n\n=== On-line and off-line methods ===\n\nSince, on practical industrial applications, open-loop or closed-loop data are often available continuously, '''on-line''' data-driven techniques use those data to improve the quality of the identified model and/or the performance of the controller each time new information is collected on the plant. Instead, '''off-line''' approaches work on batch of data, which may be collected only once, or multiple times at a regular (but rather long) interval of time.\n\n== Iterative feedback tuning ==\n\nThe iterative feedback tuning (IFT) method was introduced in 1994 <ref>Hjalmarsson, H., Gevers, M., Gunnarsson, S., & Lequin, O. (1998). Iterative feedback tuning: theory and applications. IEEE control systems, 18(4), 26–41.</ref>, starting from the observation that, in identification for control, each iteration is based on the (wrong) certainty equivalence principle.\n\nIFT is a model-free technique for the direct iterative optimization of the parameters of a fixed-order controller; such parameters can be successively updated using information coming from standard (closed-loop) system operation.\n\nLet <math>y^d</math> be a desired output to the reference signal <math>r</math>; the error between the achieved and desired response is <math>\\tilde{y}(\\rho)=y(\\rho)-y^d</math>. The control design objective can be formulated as the minimization of the objective function:\n\n:<math> J(\\rho) = \\frac{1}{2N}\\sum_{t=1}^N E\\left[\\tilde{y}(t,\\rho)^2\\right].</math>\n\nGiven the objective function to minimize, the ''quasi-Newton method'' can be applied, i.e. a gradient-based minimization using a gradient search of the type:\n\n:<math> \\rho_{i+1} = \\rho_i - \\gamma_i R_i^{-1}  \\frac{d\\widehat{J}}{d\\rho}(\\rho_i). </math>\n\nThe value <math>\\gamma_i</math> is the step size, <math>R_i</math> is an appropriate positive definite matrix and <math>\\frac{d\\widehat{J}}{d\\rho}</math> is an approximation of the gradient; the true value of the gradient is given by the following:\n\n: <math> \\frac{dJ}{d\\rho} (\\rho) = \\frac{1}{N} \\sum_{t=1}^N \\left[\\tilde{y}(t,\\rho)\\frac{\\delta y}{\\delta \\rho}(t,\\rho)\\right]. </math>\n\nThe value of <math>\\frac{\\delta y}{\\delta \\rho}(t,\\rho)</math> is obtained through the following three-step methodology:\n\n# Normal Experiment: Perform an experiment on the closed loop system with <math>C(\\rho)</math> as controller and <math>r</math> as reference; collect N measurements of the output <math>y(\\rho)</math>, denoted as <math>y^{(1)} (\\rho) </math>.\n# Gradient Experiment: Perform an experiment on the closed loop system with <math>C(\\rho)</math> as controller and 0 as reference <math>r</math>; inject the signal <math>r-y^{(1)} (\\rho)</math> such that it is summed to the control variable output by <math>C(\\rho)</math>, going as input into the plant. Collect the output, denoted as <math>y^{(2)} (\\rho) </math>.\n# Take the following as gradient approximation: <math> \\frac{\\delta \\widehat{y}}{\\delta \\rho} (\\rho) = \\frac{\\delta C}{\\delta \\rho} (\\rho) y^{(2)} (\\rho)</math>.\n\nA crucial factor for the convergence speed of the algorithm is the choice of <math>R_i</math>; when <math>\\tilde{y}</math> is small, a good choice is the approximation given by the Gauss–Newton direction:\n\n: <math> R_i = \\frac 1 N \\sum_{t=1}^N \\frac{\\delta \\widehat{y}}{\\delta \\rho} (\\rho_i) \\frac{\\delta \\widehat{y}^T}{\\delta \\rho} (\\rho_i).</math>\n\n== Noniterative correlation-based tuning ==\n\nNoniterative correlation-based tuning (nCbT) is a noniterative method for data-driven tuning of a fixed-structure controller<ref>van Heusden, K., Karimi, A. and Bonvin, D. (2011), Data-driven model reference control with asymptotically guaranteed stability. Int. J. Adapt. Control Signal Process., 25: 331–351. doi:10.1002/acs.1212</ref>. It provides a one-shot method to directly synthesize a controller based on a single dataset.\n\nSuppose that <math>G</math> denotes an unknown LTI stable SISO plant, <math>M</math> a user-defined reference model and <math>F</math> a user-defined weighting function. An LTI fixed-order controller is indicated as <math>K(\\rho)=\\beta^T \\rho</math>, where <math> \\rho \\in \\mathbb R ^n</math>, and <math>\\beta</math> is a vector of LTI basis functions. Finally, <math>K^*</math> is an ideal LTI controller of any structure, guaranteeing a closed-loop function <math>M</math> when applied to <math>G</math>.\n\nThe goal is to minimize the following objective function:\n\n: <math>J(\\rho)=\\left\\| F \\bigg( \\frac{ K^* G-K(\\rho)G }{ (1+K^* G)^2 } \\bigg) \\right\\|_2^2. </math>\n\n<math>J(\\rho)</math> is a convex approximation of the objective function obtained from a model reference problem, supposing that <math>\\frac{1}{ (1+K(\\rho)G) } \\approx \\frac{1}{ (1+K^*G) }</math>.\n\nWhen <math>G</math> is stable and minimum-phase, the approximated model reference problem is equivalent to the minimization of the norm of <math>\\varepsilon(t)</math> in the scheme in figure.\n\n[[File:Noniterative Correlation-based Tuning Scheme.svg|thumb|483x180px|The idea is that, when ''G'' is stable and minimum phase, the approximated model reference problem is equivalent to the minimization of the norm of <math>\\varepsilon</math>.]]\n\nThe input signal <math>r(t)</math> is supposed to be a persistently exciting input signal and <math>v(t)</math> to be generated by a stable data-generation mechanism. The two signals are thus uncorrelated in an open-loop experiment; hence, the ideal error <math>\\varepsilon(t,\\rho^* )</math> is uncorrelated with <math>r(t)</math>. The control objective thus consists in finding <math>\\rho</math> such that <math>r(t)</math> and <math>\\varepsilon(t,\\rho^* )</math> are uncorrelated.\n\nThe vector of ''instrumental variables'' <math>\\zeta(t)</math> is defined as:\n\n: <math> \\zeta(t)=[r_W (t+\\ell_1 ),r_W (t+\\ell_1-1),\\ldots,r_W (t),\\ldots,r_W (t-\\ell_1) ]^T </math>\n\nwhere <math>\\ell_1</math> is large enough and <math>r_W (t)=Wr(t)</math>, where <math>W</math> is an appropriate filter.\n\nThe correlation function is:\n\n: <math>f_{N,\\ell_1} (\\rho) = \\frac{1}{N} \\sum_{t=1}^N \\zeta(t) \\varepsilon(t,\\rho)</math>\n\nand the optimization problem becomes:\n\n:<math>\\widehat{\\rho} = \\underset{\\rho \\in D_k}{\\operatorname{arg\\,min}} J_{N,\\ell_1}(\\rho) = \\underset{\\rho \\in D_k}{\\operatorname{arg\\,min}} f_{N,\\ell_1}^T f_{N,\\ell_1}.\n</math>\n\nDenoting with <math>\\phi_r (\\omega)</math> the spectrum of <math>r(t)</math>, it can be demonstrated that, under some assumptions, if <math>W</math> is selected as:\n\n:<math>W(e^{-j\\omega}) = \\frac{F(e^{-j\\omega})(1-M(e^{-j\\omega}))}{\\phi_r (\\omega)}</math>\n\nthen, the following holds:\n\n:<math>\\lim_{N,\\ell_1 \\to \\infty, \\ell_1/N \\to \\infty} \\widehat{\\rho} = \\rho^*.</math>\n\n=== Stability constraint ===\n\nThere is no guarantee that the controller <math>K</math> that minimizes <math>J_{N,\\ell_1}</math> is stable. Instability may occur in the following cases:\n\n* If <math>G</math> is non-minimum phase, <math>K^*</math> may lead to cancellations in the right-half complex plane.\n* If <math>K^*</math> (even if stabilizing) is not achievable, <math>K(\\rho)</math> may not be stabilizing.\n* Due to measurement noise, even if <math>K^*=K(\\rho)</math> is stabilizing, data-estimated <math>\\widehat{K}(\\rho)</math> may not be so.\n\nConsider a stabilizing controller <math>K_s</math> and the closed loop transfer function <math>M_s=\\frac{K_s G}{1+K_s G}</math>.\nDefine:\n\n:<math> \\Delta(\\rho) := M_s - K(\\rho) G (1-M_s) </math>\n:<math> \\delta(\\rho) := \\left\\| \\Delta(\\rho) \\right\\|_\\infty. </math>\n\n:'''Theorem''' \n:''The controller <math>K(\\rho)</math> stabilizes the plant <math>G</math> if\n\n# <math> \\Delta(\\rho) </math> is stable\n# <math>\\exist \\delta_N \\in (0,1) </math> s.t. <math> \\delta (\\rho) \\leq \\delta_N. </math>''\n\nCondition 1. is enforced when:\n\n* <math>K(\\rho)</math> is stable\n* <math>K(\\rho)</math> contains an integrator (it is canceled).\n\nThe model reference design with stability constraint becomes:\n\n:<math> \\rho_s = \\underset{\\rho \\in D_k}{\\operatorname{arg\\,min}} J(\\rho) </math>\n:<math> \\text{s.t. } \\delta(\\rho) \\leq \\delta_N. </math>\n\nA '''convex data-driven estimation''' of <math>\\delta(\\rho)</math> can be obtained through the [[discrete Fourier transform]]. \n\nDefine the following:\n\n: <math>\n\\begin{align}\n& \\widehat{R}_r (\\tau) = \\frac{1}{N} \\sum_{t=1}^N r(t-\\tau) r(t) \\text{ for } \\tau = -\\ell_2,\\ldots,\\ell_2 \\\\[4pt]\n& \\widehat{R}_{r\\varepsilon} (\\tau) = \\frac{1}{N} \\sum_{t=1}^N r(t-\\tau) \\varepsilon(t,\\rho) \\text{ for } \\tau = -\\ell_2,\\ldots,\\ell_2.\n\\end{align}\n</math>\n\nFor '''stable minimum phase plants''', the following '''convex data-driven oprimization problem''' is given:\n\n:<math>\n\\begin{align}\n\\widehat{\\rho} & = \\underset{\\rho \\in D_k}{\\operatorname{arg\\,min}} J_{N,\\ell_1}(\\rho) \\\\[3pt]\n& \\text{s.t.} \\\\[3pt]\n& \\bigg| \\sum_{\\tau=-\\ell_2}^{\\ell_2} \\widehat{R}_{r\\varepsilon} (\\tau,\\rho) e^{-j\\tau\\omega_k} \\bigg| \\leq \\delta_N \\bigg| \\sum_{\\tau=-\\ell_2}^{\\ell_2} \\widehat{R}_r (\\tau,\\rho) e^{-j\\tau\\omega_k} \\bigg| \\\\[4pt]\n\\omega_k & = \\frac{2 \\pi k}{2\\ell_2+1}, \\qquad k=0,\\ldots,\\ell_2+1.\n\\end{align}\n</math>\n\n== Virtual reference feedback tuning ==\n\nVirtual Reference Feedback Tuning (VRFT) is a noniterative method for data-driven tuning of a fixed-structure controller. It provides a one-shot method to directly synthesize a controller based on a single dataset.\n\nVRFT was first proposed in <ref>Campi, Marco C., Andrea Lecchini, and Sergio M. Savaresi. \"Virtual reference feedback tuning: a direct method for the design of feedback controllers.\" Automatica 38.8 (2002): 1337–1346.</ref> and then extended to LPV systems <ref>Formentin, S., Piga, D., Tóth, R., & Savaresi, S. M. (2016). Direct learning of LPV controllers from data. Automatica, 65, 98–110.</ref>. VRFT also builds on ideas given in <ref>Guardabassi, Guido O., and Sergio M. Savaresi. \"Approximate feedback linearization of discrete-time non-linear systems using virtual input direct design.\" Systems & Control Letters 32.2 (1997): 63–74.</ref> as <math>VRD^2</math>. \n\nThe main idea is to define a desired closed loop model <math>M</math> and to use its inverse dynamics to obtain a virtual reference <math>r_v (t)</math> from the measured output signal <math>y(t)</math>.\n\n[[File:Virtual Reference Feedback Tuning Scheme.svg|thumb|483x180px|The main idea is to define a desired closed loop model M and to use its inverse dynamics to obtain a virtual reference from the measured output signal y.]]\n\nThe virtual signals are <math>r_v (t)=M^{-1} y(t)</math> and <math> e_v (t)=r_v (t) - y(t). </math>\n\nThe optimal controller is obtained from noiseless data by solving the following optimization problem:\n\n: <math>\\widehat{\\rho}_\\infty = \\underset{\\rho}{\\operatorname{arg\\,min}} \\lim_{N \\to \\infty} J_{vr} (\\rho)</math>\n\nwhere the optimization function is given as follows:\n\n:<math> J_{vr}^N (\\rho) = \\frac{1}{N} \\sum_{t=1}^N \\left(u(t)-K(\\rho) e_v(t) \\right)^2. </math>\n\n== References ==\n\n{{reflist}}\n\n[[Category:Mathematics]]\n[[Category:Robotics]]\n[[Category:Systems]]\n[[Category:Control theory]]\n[[Category:Control engineering]]\n[[Category:Computational mathematics]]"
    },
    {
      "title": "Discrete Logarithm Problem (DLP)",
      "url": "https://en.wikipedia.org/wiki/Discrete_Logarithm_Problem_%28DLP%29",
      "text": "#REDIRECT [[Discrete_logarithm#Algorithms]]\n[[Category:Mathematics]]\n[[Category:Cryptography]]\n[[Category:Computer science]]"
    },
    {
      "title": "Intersection",
      "url": "https://en.wikipedia.org/wiki/Intersection",
      "text": "{{about|a broad mathematical concept|the point where roads meet|Road intersection|other uses}}\n{{refimprove|date=January 2014}}\n[[Image:Circle-line intersection.svg|thumb|right|The [[circle]] (black) intersects the [[line (geometry)|line]] (purple) in two points (red). The disk (yellow) intersects the line in the [[line segment]] between the two red points.]]\n[[File:Venn0001.svg|220px|thumb|The intersection (red) of two disks (white and red with black boundaries).]]\n[[File:Example of a non pairwise disjoint family of sets.svg|220px|thumb|The intersection of D and E is shown in grayish purple. The intersection of A with any of B, C, D, or E is the [[empty set]].]]\n\nIn [[mathematics]], the '''intersection''' of two or more objects is another, usually \"smaller\" object. All objects are presumed to lie in a certain common [[space (mathematics)|space]] except in [[set theory]], where the intersection of arbitrary sets is defined. The intersection is one of basic concepts of [[geometry]]. Intuitively, the intersection of two or more [[mathematical object|objects]] is a new object that lies in each of original objects. An intersection can have various [[geometric shape]]s, but a [[point (geometry)|point]] is the most common in a <!-- indefinite article: there are different “plane geometries” -->[[plane geometry]].\n\nDefinitions vary in different contexts: set theory formalizes the idea that a smaller object lies in a larger object with [[inclusion (set theory)|inclusion]], and the [[intersection (set theory)|intersection of sets]] is formed of [[element (set theory)|elements]] that belong to all intersecting sets. It is always [[well-definition|defined]], but may be [[empty set|empty]]. [[Incidence geometry]] defines an <!-- yes, must be indefinite article -->intersection (usually, of [[flat (geometry)|flats]]) as an object of lower [[dimension (mathematics)|dimension]] that is [[incidence (geometry)|incident]] to each of original objects. In this approach an intersection can be sometimes undefined, such as for [[parallel lines]]. In both cases the concept of intersection relies on [[logical conjunction]].\n\n[[Algebraic geometry]] defines intersections in its own way with [[intersection theory]].\n<!-- In set theory, there are also intersections of [[class (mathematics)|classes]] blah-blah-blah not sure it’s very topical --Incnis Mrsi -->\n[[Euclidean geometry]] deals with the intersections of planar and solid shapes.\n\n==Uniqueness==\nThere can be more than one primitive object, such as points (pictured above), that form an intersection. The intersection can be viewed collectively as all of the shared objects (i.e., the intersection [[operation (mathematics)|operation]] results in a [[set (mathematics)|set]], possibly empty), or as [[multivalued function|several intersection objects]] ([[partial function|possibly zero]]).\n\n== In set theory ==\n{{Main|Intersection (set theory)}}\n\nThe intersection of two sets ''A'' and ''B'' is the set of elements which are in both ''A'' and ''B''.  In symbols,\n\n:<math>A  \\cap B = \\{ x: x \\in A \\text{  and  } x \\in B\\}</math>.<ref name=\":0\">{{Cite book|url=https://books.google.com/books?id=LBvpfEMhurwC|title=Basic Set Theory|last=Vereshchagin|first=Nikolai Konstantinovich|last2=Shen|first2=Alexander|date=2002-01-01|publisher=American Mathematical Soc.|isbn=9780821827314|language=en}}</ref>\n\nFor example, if ''A'' = {1, 3, 5, 7} and ''B'' = {1, 2, 4, 6} then ''A'' ∩ ''B'' = {1}.  A more elaborate example (involving infinite sets) is:\n: ''A'' = {''x'' is an even [[integer]]}\n: ''B'' = {''x'' is an integer divisible by 3}\n: <math>A \\cap B = \\{6, 12, 18, \\dots\\}</math>\n\nAs another example, the number 9 is ''not'' contained in the intersection of the set of [[prime number]]s {2, 3, 5, 7, 11, …} and the set of [[even number]]s {2, 4, 6, 8, 10, …}, because 9 is neither prime nor even.\n\n==In Euclidean geometry==\n{{further|Intersection (Euclidean geometry)}}\n* [[Line–line intersection]]\n* [[Line–plane intersection]]\n* [[Line–sphere intersection]]\n* [[Intersection of a polyhedron with a line]]\n* [[Line segment intersection]]\n* [[Intersection curve]]\n\n==Notation==\nIntersection is denoted by the {{unichar|2229|intersection}} from [[Unicode Mathematical Operators]]. \n{{expand section|history of the symbol|date=January 2014}}\n\n==See also==\n* [[Constructive solid geometry]], Boolean Intersection is one of the ways of combining 2D/3D shapes\n* [[Meet (lattice theory)]]\n\n==References==\n<references />\n\n==External links==\n*{{MathWorld|Intersection}}\n\n[[Category:Mathematics]]\n[[Category:Broad-concept articles]]"
    },
    {
      "title": "Peano kernel theorem",
      "url": "https://en.wikipedia.org/wiki/Peano_kernel_theorem",
      "text": "{{short description|Mathematical theorem used in numerical analysis}}\nIn [[numerical analysis]], the '''Peano kernel theorem''' is a general result on error bounds for a wide class of numerical approximations (such as [[numerical quadrature|numerical quadratures]]), defined in terms of [[linear functionals]]. It is attributed to [[Giuseppe Peano]].<ref name=\"Ridgway Scott 2011\">{{Cite book|url=https://www.worldcat.org/oclc/679940621|title=Numerical analysis|last=Ridgway Scott|first=L.|date=2011|publisher=Princeton University Press|year=|isbn=9780691146867|location=Princeton, N.J.|pages=209|oclc=679940621}}</ref>\n\n== Statement of theorem ==\nLet  <math>\\mathcal{V}[a,b]</math> be the space of all [[differentiable function]]s <math>f</math> defined for <math>x \\in (a,b)</math> that are of [[bounded variation]] on <math>[a,b]</math>, and let <math>L</math> be a [[linear functional]] on <math>\\mathcal{V}[a,b]</math>. Assume that <math>f</math> is <math display=\"inline\">\\nu+1</math> times [[continuously differentiable]] and that <math>L</math> ''annihilates'' all polynomials of degree <math>\\leq \\nu</math>, i.e.<math display=\"block\">Lp=0,\\qquad \\forall p\\in\\mathbb{P}_\\nu[x].</math>Suppose further that for any [[bivariate function]] <math>g(x,\\theta)</math> with <math>g(x,\\cdot),\\,g(\\cdot,\\theta)\\in C^{\\nu+1}[a,b]</math>, the following is valid:<math display=\"block\">L\\int_a^bg(x,\\theta)\\,d\\theta=\\int_a^bLf(x,\\theta)\\,d\\theta,</math>and define the '''Peano kernel''' of <math>L</math> as<math display=\"block\">k(\\theta)=L[(x-\\theta)^\\nu_+],\\qquad\\theta\\in[a,b],</math>introducing notation<math display=\"block\">(x-\\theta)^\\nu_+ = \\begin{cases} (x-\\theta)^\\nu, & x\\geq\\theta, \\\\ 0, & x\\leq\\theta. \\end{cases}</math>The ''Peano kernel theorem'' then states that <math display=\"block\">Lf=\\frac{1}{\\nu!}\\int_a^bk(\\theta)f^{(\\nu+1)}(\\theta)\\,d\\theta,</math>provided <math>k\\in\\mathcal{V}[a,b]</math>.<ref name=\"Ridgway Scott 2011\" /><ref name=\"Iserles 2009\">{{Cite book|url=https://www.worldcat.org/oclc/277275036|title=A first course in the numerical analysis of differential equations|last=Iserles|first=Arieh|date=2009|publisher=Cambridge University Press|year=|isbn=9780521734905|edition=2nd|location=Cambridge|pages=443–444|oclc=277275036}}</ref>\n\n=== Bounds ===\nSeveral bounds on the value of <math>Lf</math> follow from this result:<math display=\"block\">\\begin{align}\n|Lf|&\\leq\\frac{1}{\\nu!}\\|k\\|_1\\|f^{(\\nu+1)}\\|_\\infty\\\\[5pt]\n|Lf|&\\leq\\frac{1}{\\nu!}\\|k\\|_\\infty\\|f^{(\\nu+1)}\\|_1\\\\[5pt]\n|Lf|&\\leq\\frac{1}{\\nu!}\\|k\\|_2\\|f^{(\\nu+1)}\\|_2\n\\end{align}</math>\n\nwhere <math>\\|\\cdot\\|_1</math>, <math>\\|\\cdot\\|_2</math> and <math>\\|\\cdot\\|_\\infty</math>are the [[Taxicab norm|taxicab]], [[Euclidean distance|Euclidean]] and [[Maximum norm|maximum]] [[Norm (mathematics)|norms]] respectively.<ref name=\"Iserles 2009\" />\n\n== Application ==\nIn practice, the main application of the Peano kernel theorem is to bound the error of an approximation that is exact for all <math>f\\in\\mathbb{P}_\\nu</math>. The theorem above follows from the [[Taylor polynomial]] for <math>f</math> with integral remainder:\n\n: <math>\n\\begin{align}\nf(x)=f(a) + {} & (x-a)f'(a) + \\frac{(x-a)^2}{2}f''(a)+\\cdots \\\\[6pt]\n& \\cdots+\\frac{(x-a)^\\nu}{\\nu!}f^\\nu(a)+\n\\frac{1}{\\nu!}\\int_a^x(x-a)^\\nu f^{(\\nu+1)}(\\theta)\\,d\\theta,\n\\end{align}\n</math>\n\ndefining <math>L(f)</math> as the error of the approximation, using the [[Linear map|linearity]] of <math>L</math> together with exactness for <math>f\\in\\mathbb{P}_\\nu</math> to annihilate all but the final term on the right-hand side, and using the <math>(\\cdot)_+</math> notation to remove the <math>x</math>-dependence from the integral limits.<ref>{{Cite web|url=http://www.damtp.cam.ac.uk/user/examples/D3Ll.pdf|title=Numerical Analysis|last=Iserles|first=Arieh|date=1997|website=|archive-url=|archive-date=|dead-url=|access-date=2018-08-09}}</ref>\n\n== See also ==\n\n* [[Divided differences]]\n\n== References ==\n<!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. -->\n{{reflist}}\n\n[[Category:Numerical analysis]]\n[[Category:Mathematics]]"
    },
    {
      "title": "Permutation category",
      "url": "https://en.wikipedia.org/wiki/Permutation_category",
      "text": "{{short description|type of mathematical category}}\nIn mathematics, the '''permutation category'''<ref>{{harvnb|Trimble|loc=§ 1}}</ref> is a [[category (mathematics)|category]] where\n# an object is a natural number,\n# a morphism <math>n \\to m</math> is an element of the [[symmetric group]] <math>\\Sigma_n</math> when <math>n = m</math> and is none otherwise.\n\nIt is [[equivalence of categories|equivalent as an category]] to the category of finite sets and bijections between them.\n\n== References ==\n{{reflist}}\n*Todd Trimble, [http://math.ucr.edu/home/baez/trimble/trimble_lie_operad.pdf Notes on operads and the Lie operad]\n\n\n{{categorytheory-stub}}\n\n\n\n[[Category:Mathematics]]"
    },
    {
      "title": "Phase reduction",
      "url": "https://en.wikipedia.org/wiki/Phase_reduction",
      "text": "'''Phase reduction''' is a method used to reduce a multi-dimensional dynamical equation describing a nonlinear [[limit cycle]] [[oscillator]] into a one-dimensional phase equation.<ref>{{Cite journal |url=https://www.sciencedirect.com/science/article/abs/pii/S0167577X05000522 |title=A simple solution-phase reduction method for the synthesis of shape-controlled platinum nanoparticles |date=2005-05-01 |journal=Materials Letters |volume=59 |issue=12 |publisher=[[ScienceDirect]] |pages=1567–1570 |language=en |doi=10.1016/j.matlet.2005.01.024 |access-date=2019-01-09|last1=Tang |first1=Zhicheng |last2=Geng |first2=Dongsheng |last3=Lu |first3=Gongxuan }}</ref><ref name=\"Nakao\">{{cite journal |author=H.Nakao |title=Phase reduction approach to synchronization of nonlinear oscillators |journal=Contemporary Physics |volume=57 |issue=2 |pages=188–214 |date=2017 |doi=10.1080/00107514.2015.1094987|arxiv=1704.03293 }}</ref> Many phenomena in our world such as chemical reactions, electric circuits, mechanical vibrations, cardiac cells, and spiking neurons are examples of [[rhythm]]ic phenomena, and can be considered as nonlinear limit cycle oscillators.<ref name=\"Nakao\"/>\n\n==History==\nThe theory of phase reduction method was first introduced in the 1950s, the existence of [[periodic solution]]s to nonlinear oscillators under [[wikt:perturbation|perturbation]], has been discussed by Malkin in,<ref>{{cite book |author=Hoppensteadt F.C. and Izhikevich E.M |title=Weakly connected neural networks |publisher=Springer-Verlag, New York |volume=126 |date=1997 |doi=10.1007/978-1-4612-1828-9|series=Applied Mathematical Sciences |isbn=978-1-4612-7302-8 }}</ref> in the 1960s, Winfree illustrated the importance of the notion of phase and formulated the [[phase model]] for a population of nonlinear oscillators in his studies on biological synchronization.<ref name \"Winfree2001\">{{cite book |author=Winfree A.T. |title=The Geometry of Biological Time |publisher=Springer, New York |date=2001}}</ref> Since then, many researchers have discovered different rhythmic phenomena related to phase reduction theory.\n\n== Phase model of reduction==\nConsider the dynamical system of the form\n:<math>\n\\frac{dx}{dt}=f(x),  \n</math>\nwhere <math>x\\in \\mathbb{R}^N</math> is the oscillator state variable, <math>f(x)</math> is the baseline vector field. Let <math>\\varphi:\\mathbb{R}^N\\times \\mathbb{R} \\rightarrow \\mathbb{R}^N</math> be the [[flow (mathematics)|flow]] induced by the system, that is, <math>\\varphi(x_0,t)</math> is the solution of the system for the initial condition <math>x(0)=x_0</math>. This system of differential equations can describe for a neuron model for conductance with <math> x=(V,n)\\in \\mathbb{R}^N</math>, where <math> V</math> represents the voltage difference across the membrane and <math> n</math> represents the <math> (N-1)</math>-dimensional vector that defines [[gating variable]]s. <ref name=\"BrownMoehlisHolmes\">{{cite journal |author=E.Brown, J.Moehlis, P.Holmes |title=On the Phase Reduction and Response Dynamics of Neural Oscillator Populations |journal=Neural Computation |volume=16 |issue=4 |pages=673–715 |date=2004|doi=10.1162/089976604322860668 |pmid=15025826 }}</ref> When a neuron is perturbed by a stimulus current, the dynamics of the perturbed system will no longer be the same with the dynamics of the baseline neural oscillator. \n\n[[File:Isochron-stable limit cycle.png|thumb|upright=2.1|Isochrons and a stable limit cycle of the planar system <math>\\dot{x}=x - y - x(x^2+y^2);  \\dot{y}= x + y - y(x^2+y^2)</math>. The system has a unique stable limit cycle (solid circle). Only isochrons corresponding to phases <math>nT/5, n=1, 2, 3, 4, 5</math>, where <math>T=2\\pi</math> is the period of the orbit, are shown (dotted lines). Neighbouring trajectories (blue dotted curves) with different initial conditions are attracted to the cycle (except the origin).]]\n\nThe target here is to reduce the system by defining a [[Phase (waves)|phase]] for each point in some neighbourhood of the limit cycle. The allowance of sufficiently small perturbations (e.g. external forcing or stimulus effect to the system) might cause a large deviation of the phase, but the amplitude is perturbed slightly because of the attracting of the limit cycle.<ref>{{cite journal |author=M.Rosenblum and A.Pikovsky |title=Synchronization: from pendulum clocks to chaotic lasers and chemical oscillators |journal=Contemporary Physics |volume=44 |issue=5 |page=401–416 |date=2003|doi=10.1080/00107510310001603129 }}</ref> Hence we need to extend the definition of the phase to points in the neighborhood of the cycle by introducing the definition of [[asymptotic phase]] (or [[latent phase]]).<ref name \"Winfree2001\"/> This helps us to assign a phase to each point in the [[basin of attraction]] of a periodic orbit. The set of points in the basin of attraction of <math>\\gamma</math> that share the same asymptotic phase <math>\\Phi(x)</math> is called the [[isochron]] (e.g. see [[:File:Isochron_limit_cycle.png|Figure 1]]), which were first introduced by Winfree.<ref name=\"Winfree67\">{{cite journal |author=A.T.Winfree |title=Biological rhythms and the behavior of populations of coupled oscillators |journal=Journal of Theoretical Biology |volume=16 |page=15–42 |date=1967|doi=10.1016/0022-5193(67)90051-3 }}</ref> Isochrons can be shown to exist for such a stable hyperbolic limit cycle <math>\\gamma</math>. <ref name=\"Guckenkeimer\">{{cite journal |author=J.Guckenkeimer |title=Isochrons and phaseless sets |journal=Springer-Verlag, Journal of Mathematical Biology |volume=1 |issue=3 |pages=259–273 |date=1975|doi=10.1007/BF01273747 |pmid=28303309 }}</ref> So for all point <math>x</math> in some neighbourhood of the cycle, the evolution of the phase <math>\\varphi=\\Phi(x)</math> can be given by the relation <math> \\frac{d\\varphi}{dt}=\\omega </math>, where <math>\\omega=\\frac{2\\pi}{T_0}</math> is the [[natural frequency]] of the oscillation.<ref name=\"BrownMoehlisHolmes\"/><ref name=\"Schultheiss\">{{cite book |author=N.W.Schultheiss|display-authors=etal|title = The Theory of Weakly Coupled Oscillators |journal=Springer Series in Computational Neuroscience |volume=6 |pages = 3–31 |date=2012 |doi=10.1007/978-1-4614-0739-3_1|isbn = 978-1-4614-0738-6 |citeseerx = 10.1.1.225.4260 }}</ref> By the [[chain rule]] we then obtain an equation that govern the evolution of the phase of the neuron model is given by the phase model:\n:<math>\n\\frac{d\\varphi}{dt}=\\nabla\\Phi(x)\\cdot f(x)=\\omega,\n</math>\nwhere <math>\\nabla\\Phi(x)</math> is the gradient of the phase function <math>\\Phi(x)</math> with respect to the vector of the neuron's state vector <math>x</math>, for the derivation of this result, see <ref name=\"Nakao\"/><ref name=\"BrownMoehlisHolmes\"/><ref name=\"Schultheiss\"/> This means that the <math>N</math>-dimensional system describing the oscillating neuron dynamics is then reduced to a simple one-dimensional phase equation. One can notice that, it is impossible to retrieve the full information of the oscillator <math>x</math> from the phase <math>\\Phi</math> because \n<math>\\Phi(x)</math> is not one-to-one mapping.<ref name=\"Nakao\"/>\n\n==Phase model with external forcing==\nConsider now a [[weakly perturbed system]] of the form\n:<math>\n\\frac{dx(t)}{dt}=f(x)+\\varepsilon g(t),\n</math>\nwhere <math> f(x)</math> is the baseline vector field, <math>\\varepsilon g(t) </math> is a weak periodic external forcing (or stimulus effect) of period <math>T</math>, which can be different from <math>T_0</math> (in general), and frequency <math>\\Omega=2\\pi/T </math>, which might depend on the oscillator state <math>x</math>. Assuming that the baseline neural oscillator (that is, when <math>\\varepsilon=0</math>)  has an [[exponentially stable]] [[limit cycle]] <math> \\gamma</math> with period <math>T_0</math> (example, see [[:File:Isochron-stable_limit_cycle.png|Figure 1]]) <math> \\gamma </math> that is [[normally hyperbolic]], <ref>{{cite book |author= J.Guckenheimer and P.Holmes |title=Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields |publisher=Springer, NY |date=1983}}</ref> it can be shown that <math>\\gamma</math> persists under small perturbations. <ref>{{cite journal |author=N.Fenichel |title=Persistence and smoothness of invariant manifolds for flows |journal=Indiana University Mathematics JOurnal |volume=21 |issue=3 |date=1971}}</ref> This implies that for a small perturbation, the perturbed system will remain close to the limit cycle. Hence we assume that such a limit cycle always exists for each neuron.\n\nThe evolution of the perturbed system in terms of the isochrons is <ref name=\"Kuramoto\"/>\n:<math>\n\\frac{d\\varphi}{dt}=\\omega +\\varepsilon \\, \\nabla\\Phi(x)\\cdot g(t),\n</math>\nwhere <math>\\nabla\\Phi(x)</math> is the gradient of the phase <math>\\Phi(x)</math> with respect to the vector of the neuron's state vector <math>x</math>, and <math>g(t)</math> is the stimulus effect driving the firing of the neuron as a function of time <math>t</math>. This phase equation is a [[partial differential equation]] (PDE).\n\nFor a sufficiently small <math>\\varepsilon>0</math>, a reduced phase model evaluated on the limit cycle <math>\\gamma</math> of the unperturbed system can be given by, up to the first order of <math>\\varepsilon</math>,\n:<math>\n\\frac{d\\varphi}{dt}=\\omega + \\varepsilon \\, Z(\\varphi) \\cdot g(t),\n</math>\nwhere function <math>Z(\\varphi):=\\nabla\\Phi(\\gamma(t))</math> measures the normalized phase shift due to a small perturbation delivered at any point <math> x</math> on the limit cycle <math>\\gamma</math>, and is called the [[phase sensitivity function]] or infinitesimal [[phase response curve]]. <ref name=\"Winfree67\"/> <ref name=\"Kuramoto\">{{cite book |author=Y.Kuramoto |title=Chemical oscillations, waves, and turbulence |publisher=Springer-Verlag, Berlin |volume=19 |date=1984 |doi=10.1007/978-3-642-69689-3|series=Springer Series in Synergetics |isbn=978-3-642-69691-6 }}</ref>\n\nIn order to analyze the reduced phase equation corresponding to the perturbed nonlinear system, we need to solve a PDE, which is not a trivial one. So we need to simplify it into an [[autonomous]] phase equation for <math>\\varphi</math>, which can more easily be analyzed. <ref name=\"Kuramoto\"/> Assuming that the frequencies <math>\\omega</math> and <math>\\Omega</math> are sufficiently small so that\n<math>\\omega-\\Omega=\\varepsilon\\delta </math>, where <math>\\delta</math> is <math>O(1)</math>, we can introduce a new phase function <math> \\psi(t)=\\varphi(t)-\\Omega t</math>.<ref name=\"Kuramoto\"/>\n\nBy the [[method of averaging]]<ref>{{cite book |author=J.A.Sanders|display-authors=etal|title=Averaging methods in nonlinear dynamical systems |publisher=Springer-Verlag, New York |volume=59 |date=2010 |doi=10.1007/978-0-387-48918-6|series=Applied Mathematical Sciences|isbn=978-0-387-48916-2}}</ref>, assuming that <math>\\psi(t)</math> does not vary within <math>T</math>, we obtain an approximated phase equation\n:<math>\n\\frac{d\\psi(t)}{dt}=\\Delta_\\varepsilon + \\varepsilon\\Gamma(\\psi),\n</math>\nwhere <math>\\Delta_\\varepsilon=\\varepsilon\\delta </math>, and <math>\\Gamma(\\psi)</math> is a <math>2\\pi</math>-periodic function representing the effect of the periodic external forcing on the oscillator phase,<ref name=\"Kuramoto\"/> defined by\n:<math>\n\\Gamma(\\psi)= \\frac 1 {2\\pi} \\int_0^{2\\pi}Z(\\psi+\\eta)\\cdot g\\left(\\frac\\eta\\Omega\\right) \\, d\\eta .\n</math> \nThe graph of this function <math>\\Gamma(\\psi)</math> can be shown to exhibit the dynamics of the approximated phase model, for more illustrations see <ref name=\"Nakao\"/>.\n\n==Examples of phase reduction==\nFor a sufficiently small perturbation of a certain nonlinear oscillator or a network of coupled oscillators, we can compute the corresponding phase sensitivity function or infinitesimal PRC <math>Z(\\varphi)</math>.\n\n== References ==\n{{reflist}}\n\n[[Category:Mathematics]]"
    },
    {
      "title": "Priority heuristic",
      "url": "https://en.wikipedia.org/wiki/Priority_heuristic",
      "text": "{{Underlinked|date=March 2019}}\n\nThe '''priority heuristic''' is a simple, lexicographic decision strategy that correctly predicts classic violations of [[expected utility theory]] such as the [[Allais paradox]], the four-fold pattern, the certainty effect, the possibility effect, or intransitivities.<ref name=\"Brandstätter\">Brandstätter, E., Gigerenzer, G., & Hertwig, R. (2006). The priority heuristic: Making choices without trade-offs. Psychological Review, 113, 409–432.</ref> \n\nThe heuristic maps onto Rubinstein’s three-step-model, according to which people first check dominance and stop if it is present, otherwise they check for dissimilarity.<ref name=\"Rubinstein\">Rubinstein, A. (1988). Similarity and decision making under risk (Is there a utility resolution to the Allais-paradox?). Journal of Economic Theory, 46, 145–153.</ref> To highlight Rubinstein’s model consider the following choice problem:\n\n'''I:''' 50% chance to win 2,000<br>\n:50% chance to win nothing\n\n'''II:''' 52% chance to win 1,000<br>\n:48% chance to win nothing\n\nDominance is absent, and while chances are similar monetary outcomes are not. Rubinstein’s model predicts that people check for dissimilarity and consequently choose Gamble I. Unfortunately, dissimilarity checks are often not decisive, and Rubinstein suggested that people, proceed to a third step that he left unspecified. The priority heuristic elaborates on Rubinstein’s framework by specifying this Step 3.\n\n== Priority heuristic ==\nFor illustrative purposes consider a choice between two simple gambles of the type “a chance c of winning monetary amount x; a chance (100 - c) of winning amount y.” A choice between two such gambles contains four reasons for choosing: the maximum gain, the minimum gain, and their respective chances; because chances are complementary, three reasons remain: the minimum gain, the chance of the minimum gain, and the maximum gain.\n\nFor choices between gambles in which all outcomes are positive or 0, the priority heuristic consists of the following three steps (for all other choices see Brandstätter et al. 2006):\n\n'''Priority rule:''' Go through reasons in the order of minimum gain, chance of minimum gain, and maximum gain.\n\n'''Stopping rule:''' Stop examination if the minimum gains differ by 1/10 (or more) of the maximum gain; otherwise, stop examination if chances differ by 10% (or more).\n\n'''Decision rule:''' Choose the gamble with the more attractive gain (chance). The term “attractive” refers to the gamble with the higher (minimum or maximum) gain and to the lower chance of the minimum gain.\n\n== Examples ==\nConsider the following two choice problems, which were developed to support prospect theory, not the priority heuristic.<ref name=\"Kahneman\">Kahneman, D., & Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47, 263–291.</ref>\n\n'''Problem 1'''<br>\n'''A:''' 80% chance to win 4,000<br>\n:20% chance to win nothing\n'''B:''' 100% chance to win 3,000\n\nMost people chose B (80%). The priority heuristic starts by comparing the minimum gains of the Gambles A (0) and B (3,000). The difference is 3,000, which is larger than 400 (10% of the maximum gain), examination is stopped; and the heuristic predicts that people prefer the sure gain B, which is in fact the majority choice.<sup>A</sup>\n\n'''Problem 2'''<br>\n'''C:''' 45% chance to win 6,000<br>\n:55% chance to win nothing\n'''D:''' 90% chance to win 3,000 <br>\n:10% chance to win nothing\n\nMost people (86%) chose Gamble D. The priority heuristic starts by comparing the minimum gains (0 and 0). Because they do not differ, the probabilities (.45 and .90 or their logical complements .55 and .10) are compared. This difference is larger than 10%, examination stops and people are correctly predicted to choose D because of its higher probability of winning.\n\n== Empirical support ==\nThe priority heuristic correctly predicted the majority choice in all (one-stage) gambles in Kahneman and Tversky (1979). Across four different data sets with a total of 260 problems, the heuristic predicted the majority choice better than (a) cumulative prospect theory, (b) two other modifications of expected utility theory, and (c) ten well-known heuristics (such as minimax or equal-weight) did.<ref name=\"Brandstätter\" /> However, the priority heuristic has no free parameters, which triggered criticism,<ref name=\"Birnbaum\">Birnbaum, M. H. (2008). Evaluation of the priority heuristic as a descriptive model of risky decision making: Comment on Brandstaätter, Gigerenzer, and Hertwig (2006). Psychological Review, 115, 253–262.</ref><ref name=\"Johnson\">Johnson, E. J., Schulte-Mecklenbeck, M., & Willemsen, M. C. (2008). Process models deserve process data: A comment on Brandstätter, Gigerenzer, and Hertwig (2006). Psychological Review, 115, 263–273.</ref>\nand countercriticism.<ref name=\"Brandstätter2\">Brandstätter, E., Gigerenzer, G., & Hertwig, R. (2008). Risky choice with heuristics: Reply to Birnbaum (2008), Johnson, Schulte-Mecklenbeck, and Willemsen (2008), and Rieger and Wang (2008). Psychological Review, 115, 281–289.</ref><ref name=\"Brandstätter3\">Brandstätter, E., & Gussmack, M. (2013). The cognitive processes underlying risky choice. Journal of Behavioral Decision Making, 26, 185–197.</ref><ref name=\"Su\">Su, Y., Rao, L. L., Sun, H. Y., Du, X. L., Li, X., & Li, S. (2013). Is making a risky choice based on a weighting and adding process? An eye-tracking investigation. Journal of Experimental Psychology: Learning, Memory, and Cognition, 39, 1765–1780.</ref>\n\n== Footnotes ==\nA For ease of exposure prominent numbers are neglected.\n\n== References ==\n<references />\n\n== Weblinks ==\n* http://library.mpib-berlin.mpg.de/ft/eb/EB_Priority_2006.pdf\n\n[[Category:Mathematics]]\n[[Category:Heuristics]]"
    },
    {
      "title": "Proof School",
      "url": "https://en.wikipedia.org/wiki/Proof_School",
      "text": "{{Infobox school\n| name              = Proof School\n| native_name       = \n| logo              = File:Squircle-Official-purple.svg\n| image             = \n| image_size        = \n| alt               = \n| caption           = \n| motto             = \n| streetaddress     = 973 Mission Street\n| city              = [[San Francisco]]\n| state             = [[California]]\n| province          = \n| country           = [[United States|USA]]\n| coordinates       = {{coord|37.781271|-122.407927|type:edu_globe:earth_region:US-CA|display=ti}}\n| type              = [[Private School]] [[Middle school#United States|Secondary]]\n| established       = \n| founder           = Ian Brown, Paul Zeitz, and Dennis Leary\n| status            = \n| closed            = \n| district          =\n| category          = \n| oversight         = \n| chairman          = \n| dean              =  Sam Vandervelde (mathematics); Zachary Sifuentes (humanities)\n| administrator     = \n| rector            = \n| principal         = \n| campus_director   = \n| headmaster        = \n| head              =  \n| chaplain          = \n| faculty           = \n| teaching_staff    = \n| grades            = 6–12\n| gender            = \n| enrollment        = 95\n| houses            = \n| colours           = \n| athletics         = \n| mascot            = \n| nickname          = \n| rival             = \n| accreditation     =WASC \n| national_ranking  = \n| test_name         = \n| test_average      = \n| yearbook          = \n| affiliations      = \n| website           = http://proofschool.org\n| footnotes         = \n| picture           = \n| picture_caption   = \n| picture2          = \n| picture_caption2  = \n| category_label    = \n| gender_label      = \n| affiliation       = \n| assst_admin       = \n| president         = \n| chairman_label    = \n| asst principal    = \n| head_name         = \n| head_name2        = \n| head2             = \n| officer_in_charge = \n| grades_label      = \n| latitude          = \n| longitude         = \n| campus            = Urban\n| colors            = \n| student_union     = \n| free_label        = \n| free_text         = \n| newpaper          = \n| free_label_1      = \n| free_1            = \n| free_label_2      = \n| free_2            = \n| free_label_3      = \n| free_3            = \n}}\n\n'''Proof School''' is a school in [[San Francisco]] for pupils who love [[mathematics]]. Their slogan is \"For kids who love math.\" The school opened in the fall of 2015 with 45 students in grades 6–10.<ref name=\"MyUser_Bizjournals.com_July_5_2015c\">{{cite web |url=http://www.bizjournals.com/sanfrancisco/print-edition/2014/10/31/stem-education-math-skills-add-up-at-proof-school.html |title=Math skills add up at Proof School – San Francisco Business Times |newspaper=Bizjournals.com |date=  |author= |accessdate= July 5, 2015}}</ref> Currently, 94.4 students in grades 6–12 are enrolled in Proof School for the academic year (2018–2019).\n\n==Academics==\n\nProof School is a full-curriculum day school that emphasizes communication, collaboration, and problem solving. The school is accredited by [[Western Association of Schools and Colleges]].\n\nThe school year is divided into 5 'blocks', each of which consist of 6 normal academic weeks and a build week.\n\nEach student has 5 courses: 4 'morning' courses that vary across grades, and a math class. The morning courses meet twice a week for 80 minutes per class. The math courses meet for two hours and ten minutes every day in the afternoon.  \n\nThe (non-post-calculus) math classes focus on a different subject each block: Block 1 is Combinatorics, Block 2 is Algebra, Block 3 is Geometry, Block 4 is Algebra and Pre-Calculus, and Block 5 is Number Theory.\n\n<br />\n\n== Teams and Clubs ==\nProof School currently has a number of internal clubs, as well as a [[Zero Robotics]] team called [https://proofrobotics.com Proof Robotics]. The team qualified for the competition finals, and is the leading member of the alliance Hit or Miss with the following teams: [http://www.liceocecioni.gov.it/index.php?option=com_content&view=article&id=880&Itemid=503 Crab Nebula] from Liveo Cecioni in Livorno, Italy and [http://www.crzerog.org/zero-robotics.html Rock Rovers] from Council Rock High School South in Holland, PA, USA. Hit or Miss placed 2nd place internationally, and performed one of the first satellite hookings aboard the ISS.\n\n==References==\n{{reflist}}\n\n[[Category:Private schools in California]]\n[[Category:Schools in San Francisco]]\n[[Category:Mathematics]]"
    },
    {
      "title": "Quota rule",
      "url": "https://en.wikipedia.org/wiki/Quota_rule",
      "text": "In [[mathematic]]s and [[political science]], the '''quota rule''' governs the way a state should [[Apportionment (politics)|apportion]] representative seats. It states that the number of seats that should be allocated to a given party should be no more than the upper or lower roundings (called upper and lower quotas) of the [[proportional representation]];<ref name=\"maa\">Michael J. Caulfield. [https://www.maa.org/press/periodicals/convergence/apportioning-representatives-in-the-united-states-congress-the-quota-rule \"Apportioning Representatives in the United States Congress - The Quota Rule\"]. MAA Publications. Retrieved October 22, 2018</ref> e.g., if a party deserves 10.56 seats out of 15, the quota rule states that when the seats are allotted, the party may get 10 or 11 seats, but not lower or higher. The use of this rule is important when allocating seats for elected chambers such as the [[U.S. House of Representatives]], which use proportional representation.\n\n==Mathematics==\nIf <math>P</math> is the population of the party, <math>T</math> is the total population, and <math>S</math> is the number of available seats, then the natural quota for that party (the number of seats the party would ideally get) is\n:<math> \\frac P T \\cdot S</math>\n\nThe lower quota is then the natural quota rounded down to the nearest [[integer]] while the upper quota is the natural quota rounded up. The quota rule states that the only two allocations that a party can receive should be either the lower or upper quota.<ref name=\"maa\"/> If at any time an allocation gives a party a greater or lesser number of seats than the upper or lower quota, that allocation (and by extension, the method used to allocate it) is said to be in violation of the quota rule. Another way to state this is to say that a given method only satisfies the quota rule if each party's allocation differs from its natural quota by less than one, where each party's allocation is an integer value.<ref>Alan Stein. [http://www.math.uconn.edu/~stein/math103/Slides/math103-02.pdf Apportionment Methods] Retrieved December 9, 2018</ref>\n\n===Example===\nIf there are 5 available seats in the council of a club with 300 members, and party ''A'' has 106 members, then the natural quota for party ''A'' is <math> \\frac {106} {300} \\cdot 5 \\approx 1.8</math>. The lower quota for party ''A'' is 1, because 1.8 rounded down equal 1. The upper quota, 1.8 rounded up, is 2. Therefore, the quota rule states that the only two allocations allowed for party ''A'' are 1 or 2 seats on the council. If there is a second party, ''B'', that has 137 members, then the quota rule states that party ''B'' gets <math> \\frac {137} {300} \\cdot 5 \\approx 2.3</math>, rounded up and down equals either 2 or 3 seats. Finally, a party ''C'' with the remaining 57 members of the club has a natural quota of <math> \\frac {57} {300} \\cdot 5 \\approx 0.95</math>, which means its allocated seats should be either 0 or 1. In all cases, the method for actually allocating the seats determines whether an allocation violates the quota rule, which in this case would mean giving party ''A'' any seats other than 1 or 2, giving party ''B'' any other than 2 or 3, or giving party ''C'' any other than 0 or 1 seat.\n\n===Relation to other apportionment paradoxes===\nThe [[Apportionment_paradox#Balinski–Young_theorem|Balinski–Young theorem]] proved in 1980 that if an apportionment method satisfies the quota rule, it must fail to satisfy some other [[apportionment paradox]].<ref>Beth-Allyn Osikiewicz, Ph.D. [http://www.personal.kent.edu/~bosikiew/Math11008/imposs-apportion.pdf  Impossibilities of Apportionment] Retrieved October 23, 2018.</ref> For instance, although [[Largest remainder method|Hamilton's method]] satisfies the quota rule, it violates the [[Alabama paradox]] and the [[population paradox]].<ref>Warren D. Smith. (2007).[https://rangevoting.org/Apportion.html Apportionment and rounding schemes] Retrieved October 23, 2018</ref> The theorem itself is broken up into several different proofs that cover a wide number of circumstances.<ref name=\"Balinski\">M.L. Balinski and H.P. Young. (1980). [http://pure.iiasa.ac.at/id/eprint/1338/1/WP-80-131.pdf \"The Theory of Apportionment\"]. Retrieved October 23 2018</ref>\n\nSpecifically, there are two main statements that apply to the quota rule:\n*Any method that follows the quota rule must fail the population paradox.<ref name=\"Balinski\"/>\n*Any method that is free of both the Alabama paradox and the population paradox must necessarily fail the quota rule for some circumstances.<ref name=\"Balinski\"/>\n\n==Use in apportionment methods==\nDifferent methods for allocating seats may or may not satisfy the quota rule. While many methods do violate the quota rule, it is sometimes preferable to violate the rule very rarely than to violate some other apportionment paradox; some sophisticated methods violate the rule so rarely that it has not ever happened in a real apportionment, while some methods that never violate the quota rule violate other paradoxes in much more serious fashions.\n\n[[Hamilton's method]] does satisfy the quota rule. The method works by proportioning seats equally until a fractional value is reached; the surplus seats are then given to the state with the largest fractional parts until there are no more surplus seats. Because it is impossible to give more than one surplus seat to a state, every state will always get either its lower or upper quota.<ref>Hilary Freeman. [http://www.math.colostate.edu/~freeman/m130/apportionment1.pdf \"Apportionment\"]. Retrieved October 22 2018</ref> \n\n[[Jefferson's method]], which was one of the first used by the [[United States]],<ref>[http://people.cas.uab.edu/~jcmayer/Apportionment%202.pdf \"Apportionment 2\"] Retrieved October 22, 2018.</ref> sometimes violated the quota rule by allocating more seats than the upper quota allowed.<ref> [http://www.math.colostate.edu/~spriggs/m130/apportionment2.pdf Jefferson’s Method] Retrieved October 22, 2018.</ref> This violation led to a growing problem where larger states receive more representatives than smaller states, which was not corrected until [[Webster/Sainte-Laguë method|Webster's method]] was implemented in 1842; even though Webster's method does violate the quota rule, it happens extremely rarely.<ref>Ghidewon Abay Asmerom. [http://www.people.vcu.edu/~gasmerom/MAT131/lecture4.html Apportionment. Lecture 4.] Retrieved October 23, 2018.</ref>\n\n==See also==\n*[[Apportionment in the European Parliament]]\n*[[Highest averages method]]\n*[[Huntington–Hill method]]\n*[[Apportionment (politics)#Malapportionment|Malapportionment]]\n\n==References==\n{{reflist}}\n\n[[Category:Mathematics]]\n[[Category:Politics]]"
    },
    {
      "title": "Radial basis function interpolation",
      "url": "https://en.wikipedia.org/wiki/Radial_basis_function_interpolation",
      "text": "'''Radial basis function (RBF) interpolation''' is an advanced method in [[approximation theory]] for constructing [[Order of accuracy|high-order]] accurate [[interpolation|interpolants]] of unstructured data, possibly in high-dimensional spaces. The interpolant takes the form of a weighted sum of [[radial basis function]]s. RBF interpolation is a [[Meshfree method|mesh-free method]], meaning the nodes (points in the domain) need not lie on a structured grid, and does not require the formation of a [[Types of mesh|mesh]]. It is often spectrally accurate<ref>{{cite journal |last1=Buhmann |first1=Martin |last2=Nira |first2=Dyn |title=Spectral convergence of multiquadric interpolation |journal=Proceedings of the Edinburgh Mathematical Society |date=June 1993 |volume=36 |issue=2 |pages=319–333 |doi=10.1017/S0013091500018411 |url=https://www.researchgate.net/publication/231865033}}</ref> and stable for large numbers of nodes even in high dimensions.\n\nMany interpolation methods can be used as the theoretical foundation of algorithms for approximating [[linear operator]]s, and RBF interpolation is no exception. RBF interpolation has been used to approximate [[differential operator]]s, integral operators, and [[Differential geometry of surfaces|surface differential operators]]. These algorithms have been used to find highly accurate solutions of many differential equations including [[Navier–Stokes equations]]<ref>{{\n\ncite journal |last1=Flyer |first1=Natasha |last2=Barnett |first2=Gregory A. |last3=Wicker |first3=Louis J. |title=Enhancing finite differences with radial basis functions: Experiments on the Navier–Stokes equations |journal=Journal of Computational Physics |date=2016 |volume=316 |pages=39–62 |url=http://www.sciencedirect.com/science/article/pii/S0021999116300195\n\n|doi=10.1016/j.jcp.2016.02.078 }}</ref>, [[Cahn–Hilliard equation]], and the [[shallow water equations]]<ref>{{\ncite journal |last1=Wong |first1=S.M. |last2=Hon |first2=Y.C. |last3=Golberg |first3=M.A. |title=Compactly supported radial basis functions for shallow water equations |journal=Applied Mathematics and Computation |date=2002 |volume=127 |issue=1 |pages=79–101 |url=http://www.sciencedirect.com/science/article/pii/S0096300301000066\n|doi=10.1016/S0096-3003(01)00006-6 }}</ref><ref>{{\ncite journal |last1=Flyer |first1=Natasha |last2=Wright |first2=Grady B. |title=A radial basis function method for the shallow water equations on a sphere |journal=Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences |date=2009 |volume=465 |issue=2106 |pages=1949–1976 |doi=10.1098/rspa.2009.0033 }}</ref>.\n\n==Examples==\nLet <math>f(x) = \\exp(x \\cos(3 \\pi x))-1</math> and let <math>x_k = \\frac{k}{14}, k=0, 1, \\dots, 14</math> be 15 equally spaced points on the interval <math>[0, 1]</math>. We will form <math>s(x) = \\sum\\limits_{k=0}^{14} w_k \\varphi(\\|x-x_k\\|)</math> where <math>\\varphi</math> is a [[radial basis function]], and choose <math>w_k, k=0, 1, \\dots, 14</math> such that <math>s(x_k)=f(x_k), k=0, 1, \\dots, 14</math> (<math>s</math> interpolates <math>f</math> at the chosen points). In matrix notation this can be written as\n: <math display=\"block\">\n\\begin{bmatrix}\n\\varphi(\\|x_0 - x_0\\|) & \\varphi(\\|x_1 - x_0\\|) & \\dots & \\varphi(\\|x_{14} - x_0\\|) \\\\\n\\varphi(\\|x_0 - x_1\\|) & \\varphi(\\|x_1 - x_1\\|) & \\dots & \\varphi(\\|x_{14} - x_{1}\\|) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\varphi(\\|x_0 - x_{14}\\|) & \\varphi(\\|x_1 - x_{14}\\|) & \\dots & \\varphi(\\|x_{14} - x_{14}\\|) \\\\\n\\end{bmatrix}\n\\begin{bmatrix}w_0 \\\\ w_1 \\\\ \\vdots \\\\ w_{14}\\end{bmatrix}\n= \\begin{bmatrix}f(x_0) \\\\ f(x_1) \\\\ \\vdots \\\\ f(x_{14})\\end{bmatrix}.\n</math>\n\nChoosing <math>\\varphi(r) = \\exp(-(\\varepsilon r)^2)</math>, the [[Gaussian function|Gaussian]], with a shape parameter of <math>\\varepsilon \\approx 3.05048</math>, we can then solve the matrix equation for the weights and plot the interpolant. Plotting the interpolating function below, we see that it is visually the same everywhere except near the left boundary (an example of [[Runge's phenomenon]]), where it is still a very close approximation. More precisely the maximum error is roughly <math>\\|f - s\\|_\\infty \\approx 0.02476</math>.\n\n[[File:Radial basis function interpolation, f(x)=exp(x*cos(3pix))-1, gaussian.png|frame|center|The function <math>f(x)=\\exp(x\\cos(3 \\pi x))-1</math> sampled at <math>n=15</math> equally spaced nodes in the unit interval, and interpolated using the Gaussian RBF with a shape parameter of <math>\\varepsilon \\approx 3.05048</math>.]]\n\n==Motivation==\nThe Mairhuber–Curtis theorem says that for any vector space <math>V</math> with dimension higher than 2, and <math>f_1, f_2, \\dots, f_n</math> linearly independent functions on <math>V</math>, there exists a set of <math>n</math> points in the domain such that the interpolation matrix\n: <math display=\"block\">\n\\begin{bmatrix}\nf_1(x_1) & f_2(x_1) & \\dots & f_n(x_1) \\\\\nf_1(x_2) & f_2(x_2) & \\dots & f_n(x_2) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nf_1(x_n) & f_2(x_n) & \\dots & f_n(x_n)\n\\end{bmatrix}\n</math>\nis not singular.<ref>{{cite journal |last1=Mairhuber |first1=John C. |title=On Haar's Theorem Concerning Chebychev Approximation Problems Having Unique Solutions |journal=Proceedings of the American Mathematical Society |date=1956 |volume=7 |issue=4 |pages=609–615 |jstor=2033359 }}</ref>\n\nThis means that if one wishes to have a general interpolation algorithm, one must choose the basis functions to depend on the interpolation points. In 1971, Rolland Hardy developed a method of interpolating scattered data using interpolants of the form <math>s(\\mathbf{x}) = \\sum\\limits_{k=1}^N \\sqrt{\\|\\mathbf{x} - \\mathbf{x}_k\\|^2 + C}</math>. This is interpolation using a basis of shifted multiquadric functions, now more commonly written as <math>\\varphi(r) = \\sqrt{1+(\\varepsilon r)^2}</math>, and is the first instance of radial basis function interpolation.<ref>{{\ncite journal |\nlast1=Hardy |\nfirst1=Rolland L. |\ntitle=Multiquadric equations of topography and other irregular surfaces \n|journal=Journal of Geophysical Research \n|date=1971 |volume=7 |issue=8 |pages=1905–1915 \n|\ndoi=10.1029/JB076i008p01905 }}</ref> It has been shown that the resulting interpolation matrix will always be non-singular. This does not violate the Mairhuber–Curtis theorem since the basis functions depend on the points of interpolation. Choosing a radial kernel such that the interpolation matrix is non-singular is exactly the definition of a radial basis function. It has been shown that any function that is [[Bernstein's theorem on monotone functions|completely monotone]] will have this property, including the [[Gaussian function|Gaussian]], inverse quadratic, and inverse multiquadric functions.<ref>{{\ncite book |\nlast1=Fasshaur |\nfirst1=Greg |\ntitle=Meshfree Approximation Methods with MATLAB |\ndate=2007 |\npublisher=World Scientific Publishing |\nisbn=978-981-270-633-1\n}}</ref>\n\n== Shape-parameter tuning ==\nMany radial basis functions have a parameter that controls their relative flatness or peakedness. This parameter is usually represented by the symbol <math>\\varepsilon</math> with the function becoming increasingly flat as <math>\\varepsilon \\to 0</math>. For example, Rolland Hardy used the formula <math>\\varphi(r) = \\sqrt{r^2 + C}</math> for the [[multiquadric]], however nowadays the formula <math>\\varphi(r) = \\sqrt{1 + (\\varepsilon r)^2}</math> is used instead. These formulas are equivalent up to a scale factor. This factor is inconsequential since the [[basis (linear algebra)|basis vectors]] have the same [[linear span|span]] and the interpolation weights will compensate. By convention, the basis function is scaled such that <math>\\varphi(0) = 1</math> as seen in the plots of the [[Gaussian function]]s and the [[Bump function]]s.\n<gallery>\nFile:Gaussian function shape parameter.png|A [[Gaussian function]] for several choices of <math>\\varepsilon</math>.\nFile:Bump function shape.png|A plot of the scaled [[Bump function]] with several choices of shape parameter.\n</gallery>\n\n[[File:Bed of nails.png|thumb|An RBF interpolant of the function f(x)=e^(x*cos(3*pi*x))-1 sampled at 15 points, using Gaussians, with a very large shape parameter e=100. The \"[[Bed of nails|bed-of-nails]] interpolant.\"]]\nA consequence of this choice, is that the interpolation matrix approaches the identity matrix as <math>\\varepsilon \\to \\infty</math> leading to stability when solving the matrix system. The resulting interpolant will in general be a poor approximation to the function since it will be near zero everywhere, except near the interpolation points where it will sharply peak − the so-called \"bed-of-nails interpolant\" (as seen in the plot to the right).\n\n[[File:Edge of ill-conditioning.png|thumb|A plot of the condition number by the shape parameter for a 15x15 radial basis function interpolation matrix using the Gaussian.]]\nOn the opposite side of the spectrum, the [[condition number]] of the interpolation matrix will diverge to infinity as <math>\\varepsilon \\to 0</math> leading to ill-conditioning of the system. In practice, one chooses a shape parameter so that the interpolation matrix is \"on the edge of ill-conditioning\" (eg. with a condition number of roughly <math>10^{12}</math> for [[Double-precision floating-point format|double-precision]] floating point).\n\nThere are sometimes other factors to consider when choosing a shape-parameter. For example the [[bump function]]\n<math display=\"block\">\\varphi(r) = \n\\begin{cases}\n\\exp\\left( -\\frac{1}{1 - (\\varepsilon r)^2}\\right) & \\mbox{ for } r<\\frac{1}{\\varepsilon} \\\\\n0 & \\mbox{ otherwise} \n\\end{cases}\n</math>\nhas a [[Support_(mathematics)#Compact_support|compact support]] (it is zero everywhere except when <math>r< \\tfrac{1}{\\varepsilon}</math>) leading to a [[sparse matrix|sparse]] interpolation matrix.\n\nSome radial basis functions such as the [[polyharmonic spline]]s have no shape-parameter.\n\n== References ==\n{{reflist}}\n\n[[Category:Mathematics]]\n[[Category:Physics]]"
    },
    {
      "title": "Areas of mathematics",
      "url": "https://en.wikipedia.org/wiki/Areas_of_mathematics",
      "text": "[[Mathematics]] encompasses a growing variety and depth of subjects over [[History of mathematics|history]], and comprehension requires a system to categorize and organize the many subjects into more general '''areas of mathematics'''. A number of different classification schemes have arisen, and though they share some similarities, there are differences due in part to the different purposes they serve. In addition, as mathematics continues to be developed, these classification schemes must change as well to account for newly created areas or newly discovered links between different areas. Classification is made more difficult by some subjects, often the most active, which straddle the boundary between different areas.\n\nA traditional division of mathematics is into [[pure mathematics]], mathematics studied for its intrinsic interest, and [[applied mathematics]], mathematics which can be directly applied to real world problems.<ref>For example the [[Encyclopædia Britannica Eleventh Edition]] groups its mathematics articles as [[wikisource:1911 Encyclopædia Britannica/Classified List of Articles#Mathematics|Pure, Applied, and Biographies]].</ref>\nThis division is not always clear and many subjects have been developed as pure mathematics to find unexpected applications later on. Broad divisions, such as [[discrete mathematics]] and [[computational mathematics]], have emerged more recently.\n\nAn ideal system of classification permits adding new areas into the organization of previous knowledge, and fitting surprising discoveries and unexpected interactions into the outline.\nFor example, the [[Langlands program]] has found unexpected connections between areas previously thought unconnected, at least [[Galois groups]], [[Riemann surface]]s and [[number theory]].\n\n==Classification systems==\n*The [[Mathematics Subject Classification]] (MSC) is produced by the staff of the review databases [[Mathematical Reviews]] and [[Zentralblatt MATH]]. Many mathematics journals ask authors to label their papers with MSC subject codes. The MSC divides mathematics into over 60 areas, with further subdivisions within each area.\n*In the [[Library of Congress Classification]], mathematics is assigned the subclass QA within the class Q (Science). The LCC defines [[Library of Congress Classification: Class Q -- Science#QA Mathematics|broad divisions]], and individual subjects are assigned specific numerical values.\n*The [[List of Dewey Decimal classes#500 – Science|Dewey Decimal Classification]] assigns mathematics to division 510, with subdivisions for [[Algebra]] & [[number theory]], [[Arithmetic]], [[Topology]], [[Analysis]], [[Geometry]], [[Numerical analysis]], and [[Probabilities]] & [[applied mathematics]].\n*The [https://arxiv.org/archive/math Categories within Mathematics] list is used by the [[Arxiv]] for categorizing [[preprints]]. It differs from MSC; for example, it includes things like [[quantum algebra]].\n*The [[International Mathematical Union|IMU]] uses its [http://www.mathunion.org/activities/icm/icm-2010-program-structure/ programme structure] for organizing the lectures at its four-yearly [[International Congress of Mathematicians|ICM]]. One of its top-level sections that MSC doesn't have is [[Lie theory]].\n*The [[ACM Computing Classification System]] includes a couple of mathematical [http://portal.acm.org/ccs.cfm?part=author&coll=portal&dl=GUIDE categories] F. Theory of Computation and G. Mathematics of Computing.\n*[[MathOverflow]] has a [http://mathoverflow.net/tags tag system].\n*Mathematics book publishers such as [[Springer Science+Business Media|Springer]] ([https://www.springer.com/mathematics?SGWID=0-10042-0-0-0 subdisciplines]), [[Cambridge University Press|Cambridge]] ([http://www.cambridge.org/gb/knowledge/other_subject/item1521/?site_locale=en_GB Browse Mathematics and statistics]) and the [[American Mathematical Society|AMS]] ([http://www.ams.org/bookstore/textbooks subject area]) use their own subject lists on their websites to enable customers to browse books or filter searches by subdiscipline, including topics such as [[mathematical biology]] and [[mathematical finance]] as top-level headings.\n*Schools and other educational bodies have [[syllabus]]es.\n*Research institutes and university mathematics departments often have sub-departments or study groups. e.g. [[Society for Industrial and Applied Mathematics|SIAM]] has [http://siam.org/activity/ activity groups] for its members.\n*Wikipedia uses a [[:Category: Mathematics]] system on its articles, and also has a [[list of mathematics lists]].\n\n==Major divisions of mathematics==\n\n===Pure mathematics===\n\n====Foundations====\n;[[Foundations of mathematics|Foundations]], including [[set theory]] and [[mathematical logic]]\n: Mathematicians have always worked with logic and symbols, but for centuries the underlying laws of logic were taken for granted, and never expressed symbolically. '''Mathematical logic''', also known as '''symbolic logic''', was developed when people finally realized that the tools of mathematics can be used to study the structure of logic itself. Areas of research in this field have expanded rapidly, and are usually subdivided into several distinct departments.\n:;[[Proof theory]] and [[constructive mathematics]]\n:: '''Proof theory''' grew out of [[David Hilbert]]'s ambitious program to formalize all the proofs in mathematics. The most famous result in the field is encapsulated in [[Gödel's incompleteness theorems]]. A closely related and now quite popular concept is the idea of [[Turing machines]]. '''Constructivism''' is the outgrowth of [[L.E.J. Brouwer|Brouwer]]'s unorthodox view of the nature of logic itself; constructively speaking, mathematicians cannot assert \"Either a circle is round, or it is not\" until they have actually exhibited a circle and measured its roundness.\n:;[[Model theory]]\n:: Model theory studies mathematical [[structure (mathematical logic)|structures]] in a general framework. Its main tool is [[first-order logic]].\n:;[[Set theory]]\n:: A [[Set (mathematics)|set]] can be thought of as a collection of distinct things united by some common feature. Set theory is subdivided into three main areas. [[Naive set theory]] is the original set theory developed by mathematicians at the end of the 19th century. [[Axiomatic set theory]] is a rigorous [[axiom]]atic theory developed in response to the discovery of serious flaws (such as [[Russell's paradox]]) in naive set theory.  It treats sets as \"whatever satisfies the axioms\", and the notion of collections of things serves only as motivation for the axioms. [[Internal set theory]] is an axiomatic extension of set theory that supports a [[logically consistent]] identification of ''illimited'' (enormously large) and ''infinitesimal'' (unimaginably small) elements within the [[real number]]s. See also [[List of set theory topics]].\n;[[History of mathematics|History]] and [[List of mathematicians|biography]]\n: The history of mathematics is inextricably intertwined with the subject itself. This is perfectly natural: mathematics has an internal organic structure, deriving new theorems from those that have come before. As each new generation of mathematicians builds upon the achievements of our ancestors, the subject itself expands and grows new layers, like an onion.\n;[[Recreational mathematics]]\n: From [[magic square]]s to the [[Mandelbrot set]], numbers have been a source of amusement and delight for millions of people throughout the ages. Many important branches of \"serious\" mathematics have their roots in what was once a mere puzzle and/or game.\n\n====[[Number Theory]]====\n[[Number theory]] is the study of numbers and the properties of operations between them. Number theory is traditionally concerned with the properties of integers, but more recently, it has come to be concerned with wider classes of problems that have arisen naturally from the study of integers. \n; [[Arithmetic]]  \n: An elementary part of number theory that primarily focuses upon the study of [[natural numbers]], [[integers]], [[fractions]], and [[decimals]], as well as the properties of the traditional operations on them: [[addition]], [[subtraction]], [[multiplication]] and [[Division (mathematics)|division]]. Up until the 19th century, ''arithmetic'' and ''number theory'' were synonyms, but the evolution and growth of the field has resulted in arithmetic referring only to the elementary branch of number theory. \n; Elementary number theory\n: The study of integers at a higher level than [[arithmetic]], where the term 'elementary' here refers to the fact that no techniques from other mathematical fields are used.\n; [[Analytic number theory]] \n: [[Calculus]] and [[complex analysis]] are used as tools to study the integers.\n; [[Algebraic number theory]]\n: The study of algebraic numbers, the roots of [[polynomial]]s with integer [[coefficient]]s.\n; Other number theory subfields\n: [[Geometric number theory]]; [[combinatorial number theory]]; [[transcendental number theory]]; and [[computational number theory]]. See also the [[list of number theory topics]]\n\n====Algebra====\nThe study of structure begins with [[number]]s, first the familiar [[natural number]]s and [[integer]]s and their [[arithmetic]]al operations, which are recorded in [[elementary algebra]]. The deeper properties of these numbers are studied in [[number theory]]. The investigation of methods to solve equations leads to the field of [[abstract algebra]], which, among other things, studies [[ring (mathematics)|rings]] and [[field (mathematics)|field]]s, structures that generalize the properties possessed by everyday numbers. Long standing questions about [[compass and straightedge]] construction were finally settled by [[Galois theory]]. The physically important concept of [[vector (geometric)|vector]]s, generalized to [[vector space]]s, is studied in [[linear algebra]].\n\n; [[Order theory]]\n: For any two distinct  real numbers, one must be greater than the other. Order Theory extends this idea to sets in general. It includes notions like [[lattice (order)|lattices]] and ordered [[algebraic structure]]s. See also the [[order theory glossary]] and the [[list of order topics]].\n; General [[algebraic system]]s\n: Given a [[Set (mathematics)|set]], different ways of combining or relating members of that set can be defined. If these obey certain rules, then a particular algebraic structure is formed. [[Universal algebra]] is the more formal study of these structures and systems.\n; [[Field theory (mathematics)|Field theory]] and polynomials\n: Field theory studies the properties of [[Field (mathematics)|fields]]. A field is a mathematical entity for which addition, subtraction, multiplication and division are [[well-defined]].  A polynomial is an expression in which constants and variables are combined using only addition, subtraction, and multiplication.\n; [[Commutative ring]]s and [[commutative algebra|algebras]]\n: In [[ring theory]], a branch of abstract algebra, a commutative ring is a ring in which the multiplication operation obeys the [[commutative operation|commutative law]]. This means that if a and b are any elements of the ring, then a×b=b×a.  Commutative algebra is the field of study of commutative rings and their ideals, modules and algebras.  It is foundational both for [[algebraic geometry]] and for algebraic number theory. The most prominent examples of commutative rings are [[polynomial ring|rings of polynomials]].\n\n====Combinatorics====\n[[Combinatorics]] is the study of finite or discrete collections of objects that satisfy specified criteria. In particular, it is concerned with \"counting\" the objects in those collections ([[enumerative combinatorics]]) and with deciding whether certain \"optimal\" objects exist ([[extremal combinatorics]]). It includes [[graph theory]], used to describe inter-connected objects (a graph in this sense is a network, or collection of connected points). See also the [[list of combinatorics topics]], [[list of graph theory topics]] and [[glossary of graph theory]].  A ''combinatorial flavour'' is present in many parts of [[problem-solving]].\n\n====Geometry and topology====\n[[Geometry]] deals with spatial relationships, using fundamental qualities or [[axiom]]s. Such axioms can be used in conjunction with mathematical definitions for points, straight lines, curves, surfaces, and solids to draw logical conclusions.  See also [[List of geometry topics]]\n\n;[[Convex geometry]] and [[discrete geometry]]\n: Includes the study of objects such as [[polytopes]] and [[polyhedra]]. See also [[List of convexity topics]]\n;Discrete or [[combinatorial geometry]]\n: The study of geometrical objects and properties that are [[discrete mathematics|discrete]] or [[combinatorial]], either by their nature or by their representation. It includes the study of shapes such as the [[Platonic solids]] and the notion of [[tessellation]].\n;[[Differential geometry]]\n: The study of geometry using calculus. It is very closely related to [[differential topology]]. Covers such areas as [[Riemannian geometry]], [[curvature]] and [[differential geometry of curves]]. See also the [[glossary of differential geometry and topology]].\n;[[Algebraic geometry]]\n: Given a [[polynomial]] of two real [[Variable (mathematics)|variables]], then the points on a plane where that function is zero will form a curve. An [[algebraic curve]] extends this notion to polynomials over a [[field (mathematics)|field]] in a given number of variables. Algebraic geometry may be viewed as the study of these curves. See also the [[list of algebraic geometry topics]] and [[list of algebraic surfaces]].\n:;[[Arithmetic geometry]]\n:: The study of [[scheme (mathematics)|schemes]] of finite type over the [[spectrum of a ring|spectrum]] of the [[ring of integers]]. Alternatively defined as the application of the techniques of algebraic geometry to problems in [[number theory]].\n:;[[Diophantine geometry]]\n:: The study of the points of [[algebraic variety|algebraic varieties]] with coordinates in [[field (mathematics)|field]]s that are not [[algebraically closed]] and occur in [[algebraic number theory]], such as the field of [[rational number]]s, [[number field]]s, [[finite field]]s, [[Algebraic function field|function field]]s, and [[p-adic number|''p''-adic field]]s, but not including the [[real number]]s.\n:;[[Real algebraic geometry]]\n:: The study of [[semialgebraic set]]s, i.e. real-number solutions to algebraic [[inequality (mathematics)|inequalities]] with-real number coefficients, and mappings between them.\n;[[Topology]]\n: Deals with the properties of a figure that do not change when the figure is continuously deformed. The main areas are point set topology (or [[general topology]]), [[algebraic topology]], and the topology of [[manifold]]s, defined below.\n:;[[General topology]]\n:: Also called ''point set topology''. Properties of [[topological space]]s. Includes such notions as [[open set|open]] and [[closed set|closed]] [[Set (mathematics)|sets]], [[compact space]]s, [[continuous function]]s, [[limit of a sequence|convergence]], [[separation axiom]]s, [[metric space]]s, [[dimension theory]].  See also the [[glossary of general topology]] and the [[list of general topology topics]].\n:;[[Algebraic topology]]\n:: Properties of algebraic objects associated with a topological space and how these algebraic objects capture properties of such spaces.  Contains areas like [[homology theory]], [[cohomology theory]], [[homotopy theory]], and [[homological algebra]], some of them examples of [[functor]]s.  Homotopy deals with [[homotopy group]]s (including the [[fundamental group]]) as well as [[simplicial complexes]] and [[CW complexes]] (also called ''cell complexes'').  See also the [[list of algebraic topology topics]].\n:;[[Differential topology]]\n:: The field dealing with [[differentiable function]]s on [[differentiable manifold]]s, which can be thought of as an ''n''-[[dimension]]al generalization of a [[Surface (topology)|surface]] in the usual 3-dimensional [[Euclidean space]].\n\n====Analysis==== \nWithin the world of mathematics, '''[[Mathematical analysis|analysis]]''' is the branch that focuses on change: [[Derivative|rates of change]], [[Integral|accumulated change]], and multiple things changing relative to (or independently of) one another.\n\nModern analysis is a vast and rapidly expanding branch of mathematics that touches almost every other subdivision of the discipline, finding direct and indirect applications in topics as diverse as [[number theory]], [[cryptography]], and [[abstract algebra]]. It is also the language of science itself and is used across [[chemistry]], [[biology]], and [[physics]], from [[astrophysics]] to [[X-ray crystallography]].\n\n===Applied mathematics===\n\n====Probability and statistics====\n{{See also|glossary of probability and statistics}}\n\n*[[Probability theory]]: The mathematical theory of [[Statistical randomness|random]] phenomena. Probability theory studies [[random variable]]s and [[event (probability theory)|event]]s, which are mathematical abstractions of [[determinism|non-deterministic]] events or measured quantities. See also [[:Category:probability theory]], and the [[list of probability topics]].\n**[[Stochastic process]]es: An extension of probability theory that studies collections of random variables, such as [[time series]] or [[random field|spatial processes]]. See also [[List of stochastic processes topics]], and [[:Category:Stochastic processes]].\n*[[Statistics]]: The science of making effective use of numerical [[data]] from experiments or from populations of individuals. Statistics includes not only the collection, analysis and interpretation of such data, but also the planning of the collection of data, in terms of the design of [[Survey sampling|surveys]] and [[experimental design|experiments]]. See also the [[list of statistical topics]].\n\n====Computational sciences====\n;[[Numerical analysis]]\n: Many problems in mathematics cannot in general be solved exactly. Numerical analysis is the study of [[iterative method]]s and [[algorithms]] for approximately solving problems to a specified error bound. Includes [[numerical differentiation]], [[numerical integration]] and [[numerical methods]]; c.f. [[scientific computing]]. See also [[List of numerical analysis topics]]\n;[[Computer algebra]]\n: This area is also called '''symbolic computation''' or '''algebraic computation'''. It deals with exact computation, for example with integers of arbitrary size, polynomials or elements of finite fields. It includes also the computation with non numeric mathematical objects like polynomial [[ideal (ring theory)|ideals]] or series.\n\n====Physical sciences====\n; [[Mechanics]]\n: Addresses what happens when a real physical object is subjected to forces. This divides naturally into the study of rigid solids, deformable solids, and fluids, detailed below.\n: {{further|Continuum mechanics|Elasticity (physics)|Plasticity (physics)}}\n; [[Mechanics of structures]]\n: Mechanics of structures is a field of study within [[applied mechanics]] that investigates the behavior of structures under mechanical loads, such as bending of a beam, buckling of a column, torsion of a shaft, deflection of a thin shell, and vibration of a bridge.\n: {{further|Energy principles in structural mechanics|Flexibility method|Direct stiffness method|Finite element method}}\n; [[Materials science|Mechanics of deformable solids]]\n: Most real-world objects are not point-like nor perfectly rigid. More importantly, objects change shape when subjected to forces. This subject has a very strong overlap with [[continuum mechanics]], which is concerned with continuous matter. It deals with such notions as [[stress (physics)|stress]], [[Strain (materials science)|strain]] and [[Elasticity (physics)|elasticity]].\n: {{further|Solid state physics|Materials science|Mechanics of materials|Mechanics of solids|Fracture mechanics|Deformation (mechanics)|Deformable bodies}}\n; [[Fluid mechanics]]\n: [[Fluid]]s in this sense includes not just [[liquid]]s, but flowing [[gas]]es, and even [[solid]]s under certain situations. (For example, dry [[sand]] can behave like a fluid). It includes such notions as [[viscosity]], [[turbulent flow]] and [[laminar flow]] (its opposite).\n: {{further|Fluid dynamics|Mechanics of fluids|Rheology|Electrodynamics|Plasma Physics|Gas dynamics|Aerodynamics}}\n; [[Particle mechanics]]\n: In mathematics, a [[particle]] is a point-like, perfectly rigid, solid object. Particle mechanics deals with the results of subjecting particles to forces. It includes [[celestial mechanics]]—the study of the motion of celestial objects.\n\n====Other applied mathematics====\n*[[Operations research]] (OR), also known as operational research, provides optimal or near-optimal solutions to complex problems. OR uses [[mathematical model]]ing, [[statistics|statistical analysis]], and [[mathematical optimization]].\n*[[Mathematical programming]] (or mathematical optimization) minimizes (or maximizes) a real-valued function over a domain that is often specified by constraints on the variables. Mathematical programming studies these problems and develops [[iterative method]]s and [[algorithm]]s for their solution.\n\n== See also ==\n* {{Portal-inline|size=tiny|Areas of mathematics}}\n*[[Mathematics Subject Classification]]\n*[[Glossary of areas of mathematics]]\n*[[Outline of mathematics]]\n\n==Notes==\n{{reflist}}\n\n==External links==\n*[https://web.archive.org/web/20100815034900/http://www.math.niu.edu/~rusin/known-math/index/tour_div.html The Divisions of Mathematics] [from the Web Archive; Last modified 2006/01/25]\n\n{{Areas of mathematics}}\n\n[[Category:Fields of mathematics| ]]"
    },
    {
      "title": "Glossary of areas of mathematics",
      "url": "https://en.wikipedia.org/wiki/Glossary_of_areas_of_mathematics",
      "text": "{{Use American English|date = March 2019}}\n{{Short description|Mathematics glossary}}\nThis is a glossary of terms that are or have been considered areas of study in [[mathematics]].\n\n{{Compact ToC|short1|sym=yes|seealso=yes|refs=no}}\n\n==A==\n\n* '''[[Tensor|Absolute differential calculus]]''': the original name for [[tensor calculus]] developed around 1890.\n* '''[[Absolute geometry]]''': an extension of [[ordered geometry]] that is sometimes referred to as ''neutral geometry'' because its [[axiom system]] is neutral to the [[parallel postulate]].\n* '''[[Abstract algebra]]''': the study of [[algebraic structures]] and their properties. Originally it was known as ''modern algebra''.\n* '''[[Abstract analytic number theory]]''': a branch of mathematics that takes ideas from [[analytic number theory|classical analytic number theory]] and applies them to various other areas of mathematics.\n* '''[[Abstract differential geometry]]''': a form of [[differential geometry]] without the notion of [[smoothness]] from [[calculus]]. Instead it is built using [[sheaf theory]] and [[sheaf cohomology]].\n* '''[[Abstract harmonic analysis]]''': a modern branch of [[harmonic analysis]] that extends upon the generalized [[Fourier transforms]] that can be defined on [[locally compact group]]s.\n* '''[[homotopy theory|Abstract homotopy theory]]''': a part of [[topology]] that deals with homotopic functions, i.e. functions from one topological space to another which are homotopic (the functions can be deformed into one another).\n* '''[[Additive combinatorics]]''': the part of [[arithmetic combinatorics]] devoted to the operations of [[addition]] and [[subtraction]].\n* '''[[Additive number theory]]''': a part of [[number theory]] that studies subsets of [[integer]]s and their behaviour under addition.\n* '''[[Affine geometry]]''': a branch of [[geometry]] that is centered on the study of geometric properties that remain unchanged by [[affine transformation]]s. It can be described as a generalization of Euclidean geometry.\n* '''[[Affine geometry of curves]]''': the study of [[curve]]s in [[affine space]].\n* '''[[Affine differential geometry]]''': a type of [[differential geometry]] dedicated to differential [[invariant (mathematics)|invariants]] under [[volume]]-preserving [[affine transformation]]s.\n* '''[[Ahlfors theory]]''': a part of [[complex analysis]] being the geometric counterpart of [[Nevanlinna theory]]. It was invented by [[Lars Ahlfors]]\n* '''[[Algebra]]''': a major part of [[pure mathematics]] centered on [[operation (mathematics)|operations]] and [[relation (mathematics)|relations]]. Beginning with [[elementary algebra]], it introduces the concept of [[variable (mathematics)|variables]] and how these can be manipulated towards [[problem solving]]; known as [[equation solving]]. Generalizations of [[operation (mathematics)|operations]] and [[relation (mathematics)|relations]] defined on [[set (mathematics)|sets]] have led to the idea of an [[algebraic structure]] which are studied in abstract algebra. Other branches of algebra include [[universal algebra]], linear algebra and [[multilinear algebra]].\n* '''[[Algebraic analysis]]''': motivated by systems of [[Linear differential equation|linear]] [[partial differential equation]]s, it is a branch of [[algebraic geometry]] and [[algebraic topology]] that uses methods from [[sheaf theory]] and complex analysis, to study the properties and generalizations of [[function (mathematics)|function]]s. It was started by [[Mikio Sato]].\n* '''[[Algebraic combinatorics]]''': an area that employs methods of abstract algebra to problems of [[combinatorics]]. It also refers to the application of methods from combinatorics to problems in abstract algebra.\n* '''[[Algebraic computation]]''': see ''symbolic computation''.\n* '''[[Algebraic geometry]]''': a branch that combines techniques from abstract algebra with the language and problems of geometry. Fundamentally, it studies [[algebraic varieties]].\n* '''[[Algebraic graph theory]]''': a branch of [[graph theory]] in which methods are taken from algebra and employed to problems about [[Graph (discrete mathematics)|graphs]]. The methods are commonly taken from [[group theory]] and linear algebra.\n* '''[[Algebraic K-theory]]''': an important part of [[homological algebra]] concerned with defining and applying a certain sequence of [[functor]]s from [[ring (mathematics)|rings]] to [[abelian group]]s.\n* '''[[Algebraic number theory]]''': a part of algebraic geometry devoted to the study of the points of the [[algebraic varieties]] whose coordinates belong to an [[algebraic number field]]. It is a major branch of [[number theory]] and is also said to study algebraic structures related to [[algebraic integer]]s.\n* '''[[Algebraic statistics]]''': the use of algebra to advance [[statistics]], although the term is sometimes restricted to label the use of algebraic geometry and [[commutative algebra]] in [[statistics]].\n* '''[[Algebraic topology]]''': a branch that uses tools from [[abstract algebra]] for [[topology]] to study [[topological space]]s.\n* '''[[Algorithmic number theory]]''': also known as ''computational number theory'', it is the study of [[algorithm]]s for performing [[number theory|number theoretic]] [[computations]].\n* '''[[Anabelian geometry]]''': an area of study based on the theory proposed by [[Alexander Grothendieck]] in the 1980s that describes the way a geometric object of an [[algebraic variety]] (such as an [[algebraic fundamental group]]) can be mapped into another object, without it being an [[abelian group]].\n* '''[[Mathematical analysis|Analysis]]''': a rigorous branch of [[pure mathematics]] that had its beginnings in the formulation of [[infinitesimal calculus]]. (Then it was known as ''infinitesimal analysis''.) The classical forms of analysis are [[real analysis]] and its extension [[complex analysis]], whilst more modern forms are those such as [[functional analysis]].\n* '''[[Analytic combinatorics]]''': part of [[enumerative combinatorics]] where methods of complex analysis are applied to [[generating function]]s.\n* '''[[Analytic geometry]]''': usually this refer to the study of geometry using a [[coordinate system]] (also known as ''Cartesian geometry''). Alternatively it can refer to the geometry of [[analytic variety|analytic varieties]]. In this respect it is essentially equivalent to [[real algebraic geometry|real]] and [[complex algebraic geometry]].\n* '''[[Analytic number theory]]''': part of [[number theory]] using methods of analysis (as opposed to [[algebraic number theory]])\n* '''[[Applied mathematics]]''': a combination of various parts of mathematics that concern a variety of mathematical methods that can be applied to practical and theoretical problems. Typically the methods used are for [[science]], [[engineering]], [[finance]], [[economics]] and [[logistics]].\n* '''[[Approximation theory]]''': part of [[analysis]] that studies how well functions can be approximated by simpler ones (such as [[polynomial]]s or [[trigonometric polynomial]]s)\n* '''[[Arakelov geometry]]''': also known as ''Arakelov theory''\n* '''[[Arakelov theory]]''': an approach to [[Diophantine geometry]] used to study [[Diophantine equations]] in higher dimensions (using techniques from algebraic geometry). It is named after [[Suren Arakelov]].\n* '''[[Arithmetic]]''': to most people this refers to the branch known as [[elementary arithmetic]] dedicated to the usage of [[addition]], [[subtraction]], [[multiplication]] and [[division (mathematics)|division]]. However arithmetic also includes [[higher arithmetic]] referring to advanced results from [[number theory]].\n* '''[[Arithmetic algebraic geometry]]''': see ''arithmetic geometry''\n* '''[[Arithmetic combinatorics]]''': the study of the estimates from [[combinatorics]] that are associated with [[arithmetic operation]]s such as addition, [[subtraction]], [[multiplication]] and [[division (mathematics)|division]].\n* '''[[Arithmetic dynamics]]''':Arithmetic dynamics is the study of the number-theoretic properties of [[integer point|integer]], [[rational point|rational]], {{mvar|p}}-adic, and/or algebraic points under repeated application of a [[polynomial]] or [[rational function]]. A fundamental goal is to describe arithmetic properties in terms of underlying geometric structures.\n* '''[[Arithmetic geometry]]''': the study of [[scheme (mathematics)|schemes]] of finite type over the [[spectrum of a ring|spectrum]] of the [[ring of integers]]\n* '''[[Arithmetic topology]]''': a combination of [[algebraic number theory]] and [[topology]] studying analogies between [[prime ideals]] and [[knots]]\n* '''[[Arithmetical algebraic geometry]]''': an alternative name for ''arithmetic algebraic geometry''\n* '''[[Asymptotic combinatorics]]''':It uses the internal structure of the objects to derive formulas for their [[generating function]]s and then complex analysis techniques to get asymptotics.\n* '''[[Asymptotic geometric analysis]]'''\n* '''[[Asymptotic theory]]''': the study of [[asymptotic expansions]]\n* '''[[Auslander–Reiten theory]]''': the study of the [[representation theory]] of [[Artinian ring]]s\n* '''Axiomatic geometry''': also known as ''[[synthetic geometry]]'': it is a branch of geometry that uses [[axioms]] and [[logical argument]]s to draw conclusions as opposed to [[analytic geometry|analytic]] and algebraic methods.\n* '''[[Axiomatic homology theory]]'''\n* '''[[Axiomatic set theory]]''': the study of systems of [[axiom]]s in a context relevant to [[set theory]] and [[mathematical logic]].\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==B==\n\n* '''[[Bifurcation theory]]''': the study of changes in the qualitative or topological structure of a given family. It is a part of [[dynamical systems theory]]\n* '''[[Birational geometry]]''': a part of [[algebraic geometry]] that deals with the geometry (of an algebraic variety) that is dependent only on its [[function field of an algebraic variety|function field]].\n* '''Bolyai–Lobachevskian geometry''': see ''[[#hyperbolic-geometry|hyperbolic geometry]]''.\n* Bivariate data: a data comparison that deals with two independent variables.\n\n==C==\n\n* '''[[C*-algebra|C*-algebra theory]]''': a [[complex number|complex]] [[algebra over a field|algebra]] ''A'' of [[continuous linear operator]]s on a [[complex number|complex]] [[Hilbert space]] with two additional properties-(i) ''A'' is a topologically [[closed set]] in the [[norm topology]] of operators.(ii)''A'' is closed under the operation of taking [[adjoint of an operator|adjoint]]s of operators.\n* '''[[Cartesian geometry]]''': see ''analytic geometry''\n* '''[[Calculus]]''': a branch usually associated with [[limit (mathematics)|limits]], [[function (mathematics)|functions]], [[derivative]]s, [[integrals]] and [[series (mathematics)|infinite series]]. It forms the basis of classical analysis, and historically was called the ''calculus of infinitesimals'' or ''infinitesimal calculus''. Now it can refer to a system of [[calculation]] guided by symbolic manipulation.\n* '''[[Infinitesimal calculus|Calculus of infinitesimals]]''': also known as ''infinitesimal calculus''. It is a branch of calculus built upon the concepts of [[infinitesimal]]s.\n* '''[[Calculus of moving surfaces]]''': an extension of the theory of [[tensor|tensor calculus]] to include deforming [[manifold]]s.\n* '''[[Calculus of variations]]''': the field dedicated to maximizing or minimizing [[functional (mathematics)|functionals]]. It used to be called ''functional calculus''.\n* '''[[Catastrophe theory]]''': a branch of [[bifurcation theory]] from [[dynamical systems theory]], and also a special case of the more general [[singularity theory]] from geometry. It analyses the [[germ (mathematics)|germs]] of the catastrophe geometries.\n* '''[[Categorical logic]]''': a branch of [[category theory]] adjacent to the [[mathematical logic]]. It is based on [[type theory]] for [[intuitionistic logic]]s.\n* '''[[Category theory]]''': the study of the properties of particular mathematical concepts by formalising them as collections of objects and arrows.\n* '''[[Chaos theory]]''': the study of the behaviour of [[dynamical systems]] that are highly sensitive to their initial conditions.\n* '''[[Character theory]]''': a branch of [[group theory]] that studies the characters of [[group representation]]s or [[modular representation theory|modular representation]]s.\n* '''[[Class field theory]]''': a branch of [[algebraic number theory]] that studies [[abelian extension]]s of [[number field]]s.\n* '''[[Differential geometry|Classical differential geometry]]''': also known as [[differential geometry|Euclidean differential geometry]]. see ''Euclidean differential geometry''.\n* '''[[Algebraic topology|Classical algebraic topology]]'''\n* '''[[Classical analysis]]''': usually refers to the more traditional topics of analysis such as [[real analysis]] and complex analysis. It includes any work that does not use techniques from [[functional analysis]] and is sometimes called ''hard analysis''. However it may also refer to mathematical analysis done according to the principles of [[classical mathematics]].\n* '''[[Analytic number theory|Classical analytic number theory]]'''\n* '''[[Differential calculus|Classical differential calculus]]'''\n* '''[[Diophantine geometry|Classical Diophantine geometry]]'''\n* '''[[Euclidean geometry|Classical Euclidean geometry]]''': see ''Euclidean geometry''\n* '''Classical geometry''': may refer to [[solid geometry]] or classical Euclidean geometry. See ''geometry''\n* '''[[Invariant theory|Classical invariant theory]]''': the form of [[invariant theory]] that deals with describing [[polynomial function]]s that are [[invariant (mathematics)|invariant]] under transformations from a given [[linear group]].\n* '''[[Classical mathematics]]''': the standard approach to mathematics based on [[classical logic]] and [[ZFC set theory]].\n* '''[[Projective geometry|Classical projective geometry]]'''\n* '''[[tensor|Classical tensor calculus]]'''\n* '''[[Clifford analysis]]''': the study of [[Dirac operator]]s and [[Dirac operator|Dirac type operators]] from geometry and analysis using [[clifford algebra]]s.\n* '''[[Clifford theory]]''' is a branch of [[representation theory]] spawned from [[Clifford theory|Cliffords theorem]].\n* '''[[Cobordism theory]]'''\n* '''[[Cohomology theory]]'''\n* '''[[Combinatorial analysis]]'''\n* '''[[Combinatorial commutative algebra]]''': a discipline viewed as the intersection between [[commutative algebra]] and combinatorics. It frequently employs methods from one to address problems arising in the other. [[Polyhedral geometry]] also plays a significant role.\n* '''[[Combinatorial design theory]]''': a part of combinatorial mathematics that deals with the existence and construction of [[Set system|systems of finite sets]] whose intersections have certain properties.\n* '''[[Combinatorial game theory]]'''\n* '''[[Combinatorial geometry]]''': see ''discrete geometry''\n* '''[[Combinatorial group theory]]''': the theory of [[free group]]s and the [[presentation of a group]]. It is closely related to [[geometric group theory]] and is applied in [[geometric topology]].\n* '''[[Combinatorial mathematics]]'''\n* '''[[Combinatorial number theory]]'''\n* '''[[Combinatorial set theory]]''': also known as [[Infinitary combinatorics]]. see ''infinitary combinatorics''\n* '''[[Combinatorial theory]]'''\n* '''[[Combinatorial topology]]''': an old name for algebraic topology, when [[topological invariant]]s of spaces were regarded as derived from combinatorial decompositions.\n* '''[[Combinatorics]]''': a branch of [[discrete mathematics]] concerned with [[countable set|countable]] [[mathematical structure|structures]]. Branches of it include [[enumerative combinatorics]], [[combinatorial design theory]], [[matroid theory]], [[extremal combinatorics]] and [[algebraic combinatorics]], as well as many more.\n* '''[[Commutative algebra]]''': a branch of abstract algebra studying [[commutative ring]]s.\n* '''[[Complex algebra]]'''\n* '''[[Complex algebraic geometry]]''':  the mainstream of algebraic geometry devoted to the study of the [[complex number|complex]] points of [[algebraic varieties]].\n* {{anchor|complex-analysis}}'''[[Complex analysis]]''': a part of [[analysis]] that deals with functions of a [[complex numbers|complex]] variable.\n* '''[[Complex analytic dynamics]]''': a subdivision of [[complex dynamics]] being the study of the [[dynamic system]]s defined by [[analytic function]]s.\n* '''[[Complex analytic geometry]]''': the application of complex numbers to [[plane geometry]].\n* '''[[Differential geometry|Complex differential geometry]]''': a branch of [[differential geometry]] that studies [[complex manifolds]].\n* '''[[Complex dynamics]]''': the study of [[dynamical system]]s defined by [[iterated function]]s on complex [[number space]]s.\n* '''[[Complex geometry]]''': the study of [[complex manifolds]] and functions of [[complex numbers|complex]] variables. It includes [[complex algebraic geometry]] and [[complex analytic geometry]].\n* '''[[Complexity theory (disambiguation)|Complexity theory]]''': the study of [[complex system]]s with the inclusion of the theory of [[complex systems]].\n* '''[[Computable analysis]]''': the study of which parts of [[real analysis]] and [[functional analysis]] can be carried out in a [[computability theory|computable]] manner. It is closely related to [[constructive analysis]].\n* '''[[Computable model theory]]''': a branch of [[model theory]] dealing with the relevant questions [[computability]].\n* '''[[Computability theory]]''': a branch of [[mathematical logic]] originating in the 1930s with the study of [[computable function]]s and [[Turing degree]]s, but now includes the study of generalized computability and definability. It overlaps with [[proof theory]] and [[effective descriptive set theory]].\n* '''[[Computational algebraic geometry]]'''\n* '''[[Computational complexity theory]]''': a branch of mathematics and [[theoretical computer science]] that focuses on classifying [[computational problems]] according to their inherent difficulty, and relating those [[complexity class|classes]] to each other.\n* '''[[Computational geometry]]'''\n* '''[[Computational group theory]]''': the study of [[group (mathematics)|groups]] by means of computers.\n* '''[[Computational mathematics]]''': the mathematical research in areas of [[science]] where [[computation|computing]] plays an essential role.\n* '''[[Computational number theory]]''': also known as ''algorithmic number theory'', it is the study of [[algorithm]]s for performing [[number theory|number theoretic]] [[computations]].\n* '''[[Computational real algebraic geometry]]'''\n* '''[[Computational synthetic geometry]]'''\n* '''[[Computational topology]]'''\n* '''[[Computer algebra]]''': see ''symbolic computation''\n* '''[[Conformal geometry]]''': the study of [[conformal map|conformal]] transformations on a space.\n* '''[[Constructive analysis]]''': mathematical analysis done according to the principles of [[constructive mathematics]]. This differs from ''classical analysis''.\n* '''[[Constructive function theory]]''': a branch of analysis that is closely related to [[approximation theory]], studying the connection between the [[smooth function|smoothness of a function]] and its [[approximation theory|degree of approximation]]\n* '''[[Constructive mathematics]]''': mathematics which tends to use [[intuitionistic logic]]. Essentially that is classical logic but without the assumption that the [[law of the excluded middle]] is an [[axiom]].\n* '''[[Constructive quantum field theory]]''': a branch of [[mathematical physics]] that is devoted to showing that [[quantum mechanics|quantum theory]] is mathematically compatible with [[special relativity]].\n* '''[[Constructive set theory]]'''\n* '''[[Contact geometry]]''': a branch of [[differential geometry]] and [[differential topology|topology]], closely related to and considered the odd-dimensional counterpart of [[symplectic geometry]]. It is the study of a geometric structure called a contact structure on a [[differentiable manifold]].\n* '''[[Convex analysis]]''': the study of properties of [[convex function]]s and [[convex set]]s.\n* '''[[Convex geometry]]''': part of geometry devoted to the study of [[convex set]]s.\n* '''[[Coordinate geometry]]''': see ''analytic geometry''\n* '''[[CR geometry]]''': a branch of [[differential geometry]], being the study of [[CR manifold]]s.\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==D==\n\n* '''[[Noncommutative algebraic geometry|Derived noncommutative algebraic geometry]]'''\n* '''[[Descriptive set theory]]''': a part of [[mathematical logic]], more specifically a part of [[set theory]] dedicated to the study of [[Polish space]]s.\n* '''[[Differential algebraic geometry]]''': the adaption of methods and concepts from algebraic geometry to systems of [[algebraic differential equation]]s.\n* '''[[Differential calculus]]''': a subfield of calculus concerned with [[derivative]]s or the rates that quantities change. It is one of two traditional divisions of calculus, the other being [[integral calculus]].\n* '''[[Differential Galois theory]]''': the study of the [[Galois group]]s of [[differential field]]s.\n* '''[[Differential geometry]]''': a form of geometry that uses techniques from [[integral calculus|integral]] and [[differential calculus]] as well as [[linear algebra|linear]] and [[multilinear algebra]] to study problems in geometry. Classically, these were problems of Euclidean geometry, although now it has been expanded. It is generally concerned with geometric structures on [[differentiable manifolds]]. It is closely related to differential topology.\n* '''[[Differential geometry of curves]]''': the study of [[curve|smooth curves]] in [[Euclidean space]] by using techniques from [[differential geometry]]\n* '''[[Differential geometry of surfaces]]''': the study of [[smooth manifold|smooth]] [[Surface (topology)|surface]]s with various additional structures using the techniques of [[differential geometry]].\n* '''[[Differential topology]]''': a branch of [[topology]] that deals with [[differentiable function]]s on [[differentiable manifold]]s.\n* '''[[Diffiety|Diffiety theory]]'''\n* '''[[Diophantine geometry]]''': in general the study of algebraic varieties over [[field (mathematics)|fields]] that are finitely generated over their [[prime field]]s.\n* '''[[Discrepancy theory]]'''\n* '''[[Discrete computational geometry]]'''\n* '''[[Discrete differential geometry]]'''\n* '''[[Discrete dynamics]]'''\n* '''[[Discrete exterior calculus]]'''\n* '''[[Discrete geometry]]'''\n* '''[[Discrete mathematics]]'''\n* '''[[Discrete Morse theory]]''': a [[combinatorial]] adaption of [[Morse theory]].\n* '''[[Distance geometry]]'''\n* '''[[Domain theory]]'''\n* '''[[Donaldson theory]]''': the study of smooth [[4-manifold]]s using [[gauge theory]].\n* '''[[Dynamical systems theory]]'''\n\n==E==\n\n* '''[[Econometrics]]''': the application of mathematical and [[statistics|statistical]] methods to [[Economics|economic]] [[data]].\n* '''[[Effective descriptive set theory]]''': a branch of [[descriptive set theory]] dealing with [[set (mathematics)|set]] of [[real number]]s that have [[lightface]] definitions. It uses aspects of [[computability theory]].\n* '''[[Elementary algebra]]''': a fundamental form of [[algebra]] extending on [[elementary arithmetic]] to include the concept of [[variable (mathematics)|variable]]s.\n* '''[[Elementary arithmetic]]''': the simplified portion of arithmetic considered necessary for [[primary education]]. It includes the usage addition, [[subtraction]], [[multiplication]] and [[division (mathematics)|division]] of the [[natural number]]s. It also includes the concept of [[fraction (mathematics)|fractions]] and [[negative number]]s.\n* '''[[Elementary mathematics]]''': parts of mathematics frequently taught at the [[primary school|primary]] and [[secondary school]] levels. This includes [[elementary arithmetic]], geometry, [[probability and statistics]], [[elementary algebra]] and [[trigonometry]]. (calculus is not usually considered a part)\n* '''[[Elementary group theory]]''': the study of the basics of [[group theory]]\n* '''[[Elimination theory]]''': the classical name for algorithmic approaches to eliminating between [[polynomial]]s of several variables. It is a part of [[commutative algebra]] and algebraic geometry.\n* '''[[Elliptic geometry]]''': a type of [[non-Euclidean geometry]] (it violates [[Euclid]]'s [[parallel postulate]]) and is based on [[spherical geometry]]. It is constructed in [[elliptic space]].\n* '''[[Enumerative combinatorics]]''': an area of combinatorics that deals with the number of ways that certain patterns can be formed.\n* '''[[Enumerative geometry]]''': a branch of algebraic geometry concerned with counting the number of solutions to geometric questions. This is usually done by means of [[intersection theory]].\n* '''[[Noncommutative algebraic geometry|Equivariant noncommutative algebraic geometry]]'''\n* '''[[Ergodic Ramsey theory]]''': a branch where problems are motivated by [[additive combinatorics]] and solved using [[ergodic theory]].\n* '''[[Ergodic theory]]''': the study of [[dynamical systems]] with an [[invariant measure]], and related problems.\n* '''[[Euclidean geometry]]'''\n* '''[[Differential geometry|Euclidean differential geometry]]''': also known as ''classical differential geometry''. See ''differential geometry''.\n* '''[[Euler calculus]]'''\n* '''[[Experimental mathematics]]'''\n* '''[[Extraordinary cohomology theory]]'''\n* '''[[Extremal combinatorics]]''': a branch of combinatorics, it is the study of the possible sizes of a collection of finite objects given certain restrictions.\n* '''[[Extremal graph theory]]'''\n\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==F==\n\n* '''[[Field theory (mathematics)|Field theory]]''': branch of abstract algebra studying [[field (mathematics)|fields]].\n* '''[[Finite geometry]]'''\n* '''[[Finite model theory]]'''\n* '''[[Finsler geometry]]''': a branch of [[differential geometry]] whose main object of study is the [[Finsler manifold]] (a generalisation of a [[Riemannian manifold]]).\n* '''[[Arithmetic|First order arithmetic]]'''\n* '''[[Fourier analysis]]'''\n* '''[[Fractional calculus]]''': a branch of analysis that studies the possibility of taking [[real number|real]] or complex powers of the [[differentiation operator]].\n* '''[[Fractional dynamics]]''': investigates the behaviour of objects and systems that are described by [[Derivative|differentiation]] and [[integral|integration]] of [[fraction (mathematics)|fractional]] orders using methods of [[fractional calculus]].\n* '''[[Fredholm theory]]''': part of [[spectral theory]] studying [[integral equation]]s.\n* '''Function theory''': part of analysis devoted to properties of [[function (mathematics)|functions]], especially functions of a complex variable (see ''[[#complex-analysis|complex analysis]]'').\n* '''[[Functional analysis]]'''\n* '''[[Functional calculus]]''': historically the term was used synonymously with [[calculus of variations]], but now refers to a branch of [[functional analysis]] connected with [[spectral theory]]\n* '''[[Fuzzy arithmetic]]'''\n* '''[[Fuzzy geometry]]'''\n* '''[[Fuzzy Galois theory]]'''\n* '''[[Fuzzy mathematics]]''': a branch of mathematics based on [[fuzzy set theory]] and [[fuzzy logic]].\n* '''[[Fuzzy measure theory]]'''\n* '''[[Fuzzy qualitative trigonometry]]'''\n* '''[[Fuzzy set theory]]''': a form of [[set theory]] that studies [[fuzzy set]]s, that is [[set (mathematics)|sets]] that have degrees of membership.\n* '''[[Fuzzy topology]]'''\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==G==\n\n* '''[[Galois cohomology]]''': an application of [[homological algebra]], it is the study of [[group cohomology]] of [[Galois module]]s.\n* '''[[Galois theory]]''': named after [[Évariste Galois]], it is a branch of abstract algebra providing a connection between [[field theory (mathematics)|field theory]] and [[group theory]].\n* '''[[Galois geometry]]''': a branch of [[finite geometry]] concerned with algebraic and [[analytic geometry|analytic]] geometry over a [[Galois field]].\n* '''[[Game theory]]'''\n* '''[[Gauge theory]]'''\n* '''[[General topology]]''': also known as ''point-set topology'', it is a branch of [[topology]] studying the properties of [[topological space]]s and structures defined on them. It differs from other branches of [[topology]] as the [[topological space]]s do not have to be similar to manifolds.\n* '''[[Generalized trigonometry]]''': developments of [[trigonometry|trigonometric]] methods from the application to [[real number]]s of Euclidean geometry to any geometry or [[space]]. This includes [[spherical trigonometry]], [[hyperbolic geometry|hyperbolic trigonometry]], [[gyrotrigonometry]], [[rational trigonometry]], [[rational trigonometry|universal hyperbolic trigonometry]], [[fuzzy qualitative trigonometry]], [[operator trigonometry]] and [[lattice trigonometry]].\n* '''[[Geometric algebra]]''': an alternative approach to classical, [[computational geometry|computational]] and [[relativistic geometry]]. It shows a natural correspondence between geometric entities and elements of algebra.\n* '''[[Geometric analysis]]''': a discipline that uses methods from [[differential geometry]] to study [[partial differential equations]] as well as the applications to geometry.\n* '''[[Geometric calculus]]'''\n* '''[[Geometric combinatorics]]'''\n* '''[[Geometric function theory]]''': the study of geometric properties of [[analytic function]]s.\n* '''[[Geometric homology theory]]'''\n* '''[[Geometric invariant theory]]'''\n* '''[[Geometric graph theory]]'''\n* '''[[Geometric group theory]]'''\n* '''[[Geometric measure theory]]'''\n* '''[[Geometric topology]]''': a branch of [[topology]] studying manifolds and mappings between them; in particular the [[embedding]] of one manifold into another.\n* '''[[Geometry]]''': a branch of mathematics concerned with [[shape]] and the properties of [[space (mathematics)|space]]. Classically it arose as what is now known as [[solid geometry]]; this was concerning practical knowledge of [[length]], [[area]] and [[volume]]. It was then put into an [[axiomatic system|axiomatic form]] by [[Euclid]], giving rise to what is now known as classical Euclidean geometry. The use of [[coordinates]] by [[René Descartes]] gave rise to [[Cartesian geometry]] enabling a more analytical approach to geometric entities. Since then many other branches have appeared including [[projective geometry]], [[differential geometry]], [[non-Euclidean geometry]], [[Fractal geometry]] and algebraic geometry. Geometry also gave rise to the modern discipline of [[topology]].\n* '''[[Geometry of numbers]]''': initiated by [[Hermann Minkowski]], it is a branch of [[number theory]] studying [[convex bodies]] and [[integer]] [[Euclidean vector|vector]]s.\n* '''[[Global analysis]]''': the study of [[differential equation]]s on manifolds and the relationship between [[differential equation]]s and [[topology]].\n* '''[[Arithmetic dynamics|Global arithmetic dynamics]]'''\n* '''[[Graph theory]]''': a branch of [[discrete mathematics]] devoted to the study of [[Graph (discrete mathematics)|graphs]]. It has many applications in [[physical science|physical]], [[biological science|biological]] and [[social science|social]] systems.\n* '''[[Character theory|Group-character theory]]''': the part of character theory dedicated to the study of characters of [[group representation]]s.\n* '''[[Group representation theory]]'''\n* '''[[Group theory]]'''\n* '''[[Gyrotrigonometry]]''': a form of [[trigonometry]] used in [[gyrovector space]] for [[hyperbolic geometry]]. (An analogy of the [[vector space]] in Euclidean geometry.)\n\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==H==\n\n* '''[[Hard analysis]]''': see ''classical analysis''\n* '''[[Harmonic analysis]]''': part of analysis concerned with the representations of [[function (mathematics)|function]]s in terms of [[wave|waves]]. It generalizes the notions of [[Fourier series]] and [[Fourier transforms]] from the [[Fourier analysis]].\n* '''[[High-dimensional topology]]'''\n* '''[[Arithmetic|Higher arithmetic]]'''\n* '''[[Higher category theory]]'''\n* '''[[Higher-dimensional algebra]]'''\n* '''[[Hodge theory]]'''\n* '''[[Holomorphic functional calculus]]''': a branch of [[functional calculus]] starting with [[holomorphic function]]s.\n* '''[[Homological algebra]]''': the study of [[homology (mathematics)|homology]] in general algebraic settings.\n* '''[[Homology theory]]'''\n* '''[[Homotopy theory]]'''\n* {{anchor|hyperbolic-geometry}}'''[[Hyperbolic geometry]]''': also known as ''Lobachevskian geometry'' or ''Bolyai-Lobachevskian geometry''. It is a [[non-Euclidean geometry]] looking at [[hyperbolic space]].\n* '''[[Hyperbolic geometry|hyperbolic trigonometry]]''': the study of [[hyperbolic triangle]]s in [[hyperbolic geometry]], or [[hyperbolic function]]s in Euclidean geometry. Other forms include [[gyrotrigonometry]] and [[rational trigonometry|universal hyperbolic trigonometry]].\n* '''[[Hypercomplex analysis]]'''\n* '''[[Hyperfunction|Hyperfunction theory]]'''\n\n==I==\n\n* '''[[Ideal theory]]''': once the precursor name for what is now known as [[commutative algebra]]; it is the theory of [[ideal (ring theory)|ideals]] in [[commutative ring]]s.\n* '''[[Idempotent analysis]]'''\n* '''[[Incidence geometry]]''': the study of relations of [[incidence (geometry)|incidence]] between various geometric objects, like [[curve (mathematics)|curves]] and [[line (mathematics)|lines]].\n* '''[[Inconsistent mathematics]]''': see ''paraconsistent mathematics''.\n* '''[[Infinitary combinatorics]]''': an expansion of ideas in combinatorics to account for [[infinite set]]s.\n* '''[[Infinitesimal calculus|Infinitesimal analysis]]''': once a synonym for ''infinitesimal calculus''\n* '''[[Infinitesimal calculus]]''': see ''calculus of infinitesimals''\n* '''[[Information geometry]]'''\n* '''[[Integral calculus]]'''\n* '''[[Integral geometry]]'''\n* '''[[Intersection theory]]''': a branch of algebraic geometry and algebraic topology\n* '''[[Intuitionistic type theory]]'''\n* '''[[Invariant theory]]''': studies how [[Group action (mathematics)|group action]]s on algebraic varieties affect functions.\n* '''[[Inversive geometry]]''': the study of invariants preserved by a type of transformation known as inversion\n* '''[[Inversive geometry|Inversive plane geometry]]''': inversive geometry that is limited to two dimensions\n* '''[[Inversive ring geometry]]'''\n* '''[[Itō calculus]]'''\n* '''[[Iwasawa theory]]'''\n\n==J==\n\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==K==\n\n* '''[[K-theory]]''': originated as the study of a [[ring (mathematics)|ring]] generated by [[vector bundle]]s over a [[topological space]] or [[scheme (mathematics)|scheme]]. In algebraic topology it is an [[extraordinary cohomology theory]] known as [[topological K-theory]]. In algebra and algebraic geometry it is referred to as [[algebraic K-theory]]. In [[mathematical physics|physics]], [[K-theory (physics)|K-theory]] has appeared in [[type II string theory]]. (In particular [[twisted K-theory]].)\n* '''[[K-homology]]'''\n* '''[[Kähler manifold|Kähler geometry]]''': a branch of [[differential geometry]], more specifically a union of [[Riemannian geometry]], [[differential geometry|complex differential geometry]] and [[symplectic geometry]]. It is the study of [[Kähler manifold]]s. (named after [[Erich Kähler]])\n* '''[[KK-theory]]'''\n* '''[[Klein geometry]]''': More specifically, it is a [[homogeneous space]] ''X'' together with a [[Group action (mathematics)|transitive action]] on ''X'' by a [[Lie group]] ''G'', which acts as the [[symmetry group]] of the geometry.\n* '''[[Knot theory]]''': part of [[topology]] dealing with [[knot (mathematics)|knots]]\n* '''[[Kummer theory]]''': provides a description of certain types of [[field extension]]s involving the [[adjunction (field theory)|adjunction]] of ''n''th roots of elements of the base [[field (mathematics)|field]]\n\n==L==\n\n* '''[[L-theory]]'''\n* '''[[Large deviations theory]]''': part of [[probability theory]] studying [[event (probability theory)|events]] of small probability ([[event (probability theory)|tail events]]).\n* '''[[Large sample theory]]''': also known as ''asymptotic theory''\n* '''[[Lattice theory]]''': the study of [[lattice (order)|lattices]], being important in [[order theory]] and [[universal algebra]]\n* '''[[Lattice trigonometry]]'''\n* '''[[Lie algebra theory]]'''\n* '''[[Lie group theory]]'''\n* '''[[Lie sphere geometry]]'''\n* '''[[Lie theory]]'''\n* '''[[Line geometry]]'''\n* '''[[Linear algebra]]''' &ndash; a branch of algebra studying [[linear space]]s and [[linear map]]s. It has applications in fields such as abstract algebra and [[functional analysis]]; it can be represented in analytic geometry and it is generalized in [[operator theory]] and in [[module theory]]. Sometimes [[Matrix (mathematics)|matrix theory]] is considered a branch, although linear algebra is restricted to only finite dimensions. Extensions of the methods used belong to [[multilinear algebra]].\n* '''[[Functional analysis|Linear functional analysis]]'''\n* '''[[List of graphical methods]]''' Included are diagram techniques, chart techniques, plot techniques, and other forms of visualization.\n* '''[[Local algebra]]''': a term sometimes applied to the theory of [[local ring]]s.\n* '''[[P-adic dynamics|Local arithmetic dynamics]]''': also known as ''p-adic dynamics'' or ''nonarchimedean dynamics''.\n* '''[[Local class field theory]]'''\n* '''[[Low-dimensional topology]]'''\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==M==\n\n* '''[[Malliavin calculus]]'''\n* '''[[Mathematical finance]]'''\n* '''[[Mathematical logic]]'''\n* '''[[Mathematical optimization]]'''\n* '''[[Mathematical physics]]''': a part of mathematics that develops mathematical methods motivated by problems in [[physics]].\n* '''[[Mathematical sciences]]''': refers to [[academic disciplines]] that are mathematical in nature, but are not considered proper subfields of mathematics. Examples include [[statistics]], [[cryptography]], [[game theory]] and [[actuarial science]].\n* '''[[Matrix ring|Matrix algebra]]'''\n* '''[[Matrix calculus]]'''\n* '''[[Matrix (mathematics)|Matrix theory]]'''\n* '''[[Matroid theory]]'''\n* '''[[Measure theory]]'''\n* '''[[Metric geometry]]'''\n* '''[[Microlocal analysis]]'''\n* '''[[Model theory]]'''\n* '''[[Abstract algebra|Modern algebra]]''': see ''abstract algebra''\n* '''[[Scheme (mathematics)|Modern algebraic geometry]]''': the form of algebraic geometry given by [[Alexander Grothendieck]] and [[Jean-Pierre Serre]] drawing on [[sheaf theory]].\n* '''[[Invariant theory|Modern invariant theory]]''': the form of [[invariant theory]] that analyses the decomposition of [[representation (mathematics)|representations]] into irreducibles.\n* '''[[Modular representation theory]]'''\n* '''[[Module theory]]'''\n* '''[[Molecular geometry]]'''\n* '''[[Morse theory]]''': a part of differential topology, it analyzes the [[topological space]] of a manifold by studying [[differentiable function]]s on that manifold.\n* '''[[Motivic cohomology]]'''\n* '''[[Multilinear algebra]]''': an extension of linear algebra building upon concepts of [[p-vector]]s and [[multivector]]s with [[Grassmann algebra]].\n* '''[[Multiplicative calculus]]''': multiplicative alternatives to the classical additive calculus of Newton and Leibniz.\n* '''[[Multiplicative number theory]]''': a subfield of analytic number theory that deals with [[prime number]]s, [[factorization]] and [[divisor]]s.\n* '''[[Multivariable calculus]]'''\n* '''[[Multiple-scale analysis]]'''\n\n==N==\n\n* '''[[Neutral geometry]]''': see ''absolute geometry''\n* '''[[Nevanlinna theory]]''': part of complex analysis studying the value distribution of [[meromorphic function]]s. It is named after [[Rolf Nevanlinna]]\n* '''[[Nielsen theory]]''': an area of mathematical research with its origins in [[fixed point topology]], developed by [[Jakob Nielsen (mathematician)|Jakob Nielsen]]\n* '''[[Non-abelian class field theory]]'''\n* '''[[Non-classical analysis]]'''\n* '''[[Non-Euclidean geometry]]'''\n* '''[[Multiplicative calculus|Non-Newtonian calculus]]''': alternatives to the classical calculus of Newton and Leibniz\n* '''[[Non-standard analysis]]'''\n* '''[[Non-standard calculus]]'''\n* '''[[Arithmetic dynamics|Nonarchimedean dynamics]]''': also known as ''p-adic analysis'' or ''local arithmetic dynamics''\n* '''[[Noncommutative algebraic geometry]]''': a direction in [[noncommutative geometry]] studying the geometric properties of formal duals of non-commutative algebraic objects.\n* '''[[Noncommutative geometry]]'''\n* '''[[Noncommutative harmonic analysis]]''': see ''representation theory''\n* '''[[Noncommutative topology]]'''\n* '''[[Nonlinear analysis]]'''\n* '''[[Nonlinear functional analysis]]'''\n* '''[[Number theory]]''': a branch of [[pure mathematics]] primarily devoted to the study of the [[integer]]s. Originally it was known as ''arithmetic'' or ''higher arithmetic''.\n* '''[[Numerical analysis]]'''\n* '''[[Numerical geometry]]'''\n* '''[[Numerical linear algebra]]'''\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==O==\n\n* '''[[Operad theory]]''': a type of abstract algebra concerned with prototypical [[algebra over a field|algebras]].\n* '''[[Operator geometry]]'''\n* '''[[Operator K-theory]]'''\n* '''[[Operator theory]]''': part of [[functional analysis]] studying [[operator (mathematics)|operators]].\n* '''[[Operator trigonometry]]'''\n* '''[[Optimal control theory]]''': a generalization of the [[calculus of variations]].\n* '''[[Orbifold theory]]'''\n* '''[[Order theory]]''': a branch that investigates the intuitive notion of [[wikt:order|order]] using [[binary relations]].\n* '''[[Ordered geometry]]''': a form of geometry  omitting the notion of [[measurement]] but featuring the concept of [[intermediacy]]. It is a fundamental geometry forming a common framework for [[affine geometry]], Euclidean geometry, [[absolute geometry]] and [[hyperbolic geometry]].\n* '''[[Oriented elliptic geometry]]'''\n* '''[[Oriented spherical geometry]]'''\n* '''[[Oscillation theory]]'''\n\n==P==\n\n* '''[[p-adic analysis]]''': a branch of [[number theory]] that deals with the analysis of functions of [[p-adic number]]s.\n* '''[[p-adic analysis|p-adic dynamics]]''': an application of [[p-adic analysis]] looking at [[P-adic number|p-adic]] [[differential equation]]s.\n* '''[[p-adic Hodge theory]]'''\n* '''[[Parabolic geometry (disambiguation)|Parabolic geometry]]'''\n* '''[[Paraconsistent mathematics]]''': sometimes called ''inconsistent mathematics'', it is an attempt to develop the classical infrastructure of mathematics based on a foundation of [[paraconsistent logic]] instead of [[classical logic]].\n* '''[[Partition theory]]'''\n* '''[[Perturbation theory]]'''\n* '''[[Picard&ndash;Vessiot theory]]'''\n* '''[[Plane geometry]]'''\n* '''[[Point-set topology]]''': see ''general topology''\n* '''[[Pointless topology]]'''\n* '''[[Poisson geometry]]'''\n* '''[[Polyhedral combinatorics]]''': a branch within combinatorics and [[discrete geometry]] that studies the problems of  describing [[convex polytope]]s.\n* '''[[Polyhedral geometry]]'''\n* '''[[Possibility theory]]'''\n* '''[[Potential theory]]'''\n* '''[[Precalculus]]'''\n* '''[[Predicative mathematics]]'''\n* '''[[Probability theory]]'''\n* '''[[Probabilistic combinatorics]]'''\n* '''[[Probabilistic graph theory]]'''\n* '''[[Probabilistic number theory]]'''\n* '''[[Projective geometry]]''': a form of geometry that studies geometric properties that are [[invariant (mathematics)|invariant]] under a [[projective transformation]].\n* '''[[Projective differential geometry]]'''\n* '''[[Proof theory]]'''\n* '''[[Pseudo-Riemannian geometry]]''': generalizes [[Riemannian geometry]] to the study of [[pseudo-Riemannian manifold]]s.\n* '''[[Pure mathematics]]''': the part of mathematics that studies entirely abstract concepts.\n\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==Q==\n\n* '''[[Quantum calculus]]''': a form of calculus without the notion of [[limit (mathematics)|limits]]. There are 2 forms known as [[q-calculus]] and [[h-calculus]]\n* '''[[Quantum geometry]]''': the generalization of concepts of geometry used to describe the [[physics|physical]] phenomena of [[quantum physics]]\n* '''[[Quaternion|Quaternionic analysis]]'''\n* '''[[Quick maths]]''': The rapid application of arithmetic in the form of a rap.{{citation needed|date=February 2018}}\n\n==R==\n\n* '''[[Ramsey theory]]''': the study of the conditions in which order must appear. It is named after [[Frank P. Ramsey]].\n* '''[[Rational geometry]]'''\n* '''[[Rational trigonometry]]''': a reformulation of [[trigonometry]] in terms of [[spread (trigonometry)|spread]] and [[quadrance (trigonometry)|quadrance]] instead of [[angle]] and [[length]].\n* '''[[Real algebraic geometry|Real algebra]]''': the study of the part of algebra relevant to [[real algebraic geometry]].\n* '''[[Real algebraic geometry]]''': the part of algebraic geometry that studies [[real number|real]] points of the algebraic varieties.\n* '''[[Real analysis]]''': a branch of mathematical analysis; in particular ''hard analysis'', that is the study of [[real number]]s and [[function (mathematics)|functions]] of [[real number|Real]] values. It provides a rigorous formulation of the calculus of [[real number]]s in terms of [[continuous function|continuity]] and [[smooth function|smoothness]], whilst the theory is extended to the [[complex number]]s in [[complex analysis]].\n* '''[[Real analytic geometry]]'''\n* '''[[Real K-theory]]'''\n* '''[[Recreational mathematics]]''': the area dedicated to [[mathematical puzzle]]s and [[mathematical game]]s.\n* '''[[Recursion theory]]''': see ''computability theory''\n* '''[[Representation theory]]''': a subfield of abstract algebra; it studies [[algebraic structure]]s by representing their elements as [[linear transformation]]s of [[vector space]]s. It also studies [[module (mathematics)|modules]] over these algebraic structures, providing a way of reducing problems in abstract algebra to problems in linear algebra.\n* '''[[Representation theory of algebraic groups]]'''\n* '''[[Representation theory of algebras]]'''\n* '''[[Representation theory of diffeomorphism groups]]'''\n* '''[[Representation theory of finite groups]]'''\n* '''[[Group representation|Representation theory of groups]]'''\n* '''[[Representation theory of Hopf algebras]]'''\n* '''[[Representation theory of Lie algebras]]'''\n* '''[[Representation theory of Lie groups]]'''\n* '''[[Representation theory of the Galilean group]]'''\n* '''[[Representation theory of the Lorentz group]]'''\n* '''[[Representation theory of the Poincaré group]]'''\n* '''[[Representation theory of the symmetric group]]'''\n* '''[[Ribbon theory]]''': a branch of [[topology]] studying [[ribbon (mathematics)|ribbons]].\n* '''[[Riemannian geometry]]''': a branch of [[differential geometry]] that is more specifically, the study of [[Riemannian manifolds]]. It is named after [[Bernhard Riemann]] and it features many generalizations of concepts from Euclidean geometry, analysis and calculus.\n* '''[[Rough set|Rough set theory]]''': the a form of [[set theory]] based on [[rough set]]s.\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==S==\n\n* '''[[Scheme (mathematics)|Scheme theory]]''': the study of [[scheme (mathematics)|schemes]] introduced by [[Alexander Grothendieck]]. It allows the use of [[sheaf theory]] to study algebraic varieties and is considered the central part of ''modern algebraic geometry''.\n* '''[[Secondary calculus]]'''\n* '''[[Self-similarity]]''' an object is exactly or approximately similar to a part of itself (i.e. the whole has the same shape as one or more of the parts).\n* '''[[Real algebraic geometry|Semialgebraic geometry]]''': a part of algebraic geometry; more specifically a branch of [[real algebraic geometry]] that studies [[semialgebraic set]]s.\n* '''[[Set-theoretic topology]]'''\n* '''[[Set theory]]'''\n* '''[[Sheaf theory]]'''\n* '''[[Sheaf cohomology]]'''\n* '''[[Sieve theory]]'''\n* '''[[Operator theory|Single operator theory]]''': deals with the properties and classifications of single [[operator (mathematics)|operators]].\n* '''[[Singularity theory]]''': a branch, notably of geometry; that studies the failure of manifold structure.\n* '''[[Smooth infinitesimal analysis]]''': a rigorous reformation of [[infinitesimal calculus]] employing methods of [[category theory]]. As a theory, it is a subset of [[synthetic differential geometry]].\n* '''[[Solid geometry]]'''\n* '''[[Spatial geometry]]'''\n* '''[[Spectral geometry]]''': a field that concerns the relationships between geometric structures of manifolds and [[spectrum of an operator|spectra]] of canonically defined [[differential operator]]s.\n* '''[[Spectral graph theory]]''': the study of properties of a [[Graph (discrete mathematics)|graph]] using methods from [[Matrix (mathematics)|matrix theory]].\n* '''[[Spectral theory]]''': part of ''operator theory'' extending the concepts of [[eigenvalue]]s and [[eigenvector]]s from linear algebra and [[Matrix (mathematics)|matrix theory]].\n* '''[[Spectral theory of ordinary differential equations]]''': part of [[spectral theory]] concerned with the [[spectrum of an operator|spectrum]] and [[eigenfunction]] expansion associated with [[linear differential equation|linear]] [[ordinary differential equation]]s.\n* '''[[Spectrum continuation analysis]]''': generalizes the concept of a [[Fourier series]] to non-periodic [[function (mathematics)|functions]].\n* '''[[Spherical geometry]]''': a branch of [[non-Euclidean geometry]], studying the 2-dimensional surface of a [[sphere]].\n* '''[[Spherical trigonometry]]''': a branch of [[spherical geometry]] that studies [[polygon]]s on the surface of a [[sphere]]. Usually the [[polygon]]s are [[triangle]]s.\n* '''[[Mathematical statistics|Statistics]]''': although the term may refer to the more general study of [[statistics]], the term is used in mathematics to refer to the [[mathematical statistics|mathematical study of statistics and related fields]]. This includes [[probability theory]].\n* '''[[Stochastic calculus]]'''\n* '''[[Malliavin calculus|Stochastic calculus of variations]]'''\n* '''[[Stochastic geometry]]''': the study of random patterns of points\n* '''[[Stratified Morse theory]]'''\n* '''[[Super category theory]]'''\n* '''[[Super linear algebra]]'''\n* '''[[Surgery theory]]''': a part of [[geometric topology]] referring to methods used to produce one manifold from another (in a controlled way.)\n* '''[[Symbolic computation]]''': also known as ''algebraic computation'' and ''computer algebra''. It refers to the techniques used to manipulate [[expression (mathematics)|mathematical expressions]] and [[equation]]s in [[symbol|symbolic form]] as opposed to manipulating them by the numerical quantities represented by them.\n* '''[[Symbolic dynamics]]'''\n* '''[[Symmetric function theory]]'''\n* '''[[Symplectic geometry]]''': a branch of [[differential geometry]] and topology whose main object of study is the [[symplectic manifold]].\n* '''[[Symplectic topology]]'''\n* '''[[Synthetic differential geometry]]''': a reformulation of [[differential geometry]] in the language of [[topos theory]] and in the context of an [[intuitionistic logic]].\n* {{anchor|synthetic-geometry}}'''[[Synthetic geometry]]''': also known as '''axiomatic geometry''', it is a branch of geometry that uses [[axioms]] and [[logical argument]]s to draw conclusions as opposed to [[analytic geometry|analytic]] and algebraic methods.\n* '''[[Systolic geometry]]''': a branch of [[differential geometry]] studying systolic [[invariant (mathematics)|invariant]]s of [[manifold]]s and [[polyhedra]].\n* '''[[Systolic geometry|Systolic hyperbolic geometry]]''': the study of [[systolic geometry|systoles]] in [[hyperbolic geometry]].\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==T==\n\n* '''[[Tensor analysis]]''': the study of [[tensor]]s, which play a role in subjects such as [[differential geometry]], [[mathematical physics]], algebraic topology, [[multilinear algebra]], [[homological algebra]] and [[representation theory]].\n* '''[[Tensor calculus]]''': an older term for ''tensor analysis''.\n* '''[[Tensor|Tensor theory]]''': an alternative name for ''tensor analysis''.\n* '''[[Tessellation]]''': when periodic tiling has a repeating pattern.\n* '''[[Theoretical physics]]''': a branch primarily of the [[science]] [[physics]] that uses [[mathematical model]]s and [[abstraction]] of [[mathematical physics|physics]] to rationalize and predict [[phenomena]].\n* '''[[Time-scale calculus]]'''\n* '''[[Topology]]'''\n* '''[[Topological combinatorics]]''': the application of methods from algebraic topology to solve problems in combinatorics.\n* '''[[Topological degree theory]]'''\n* '''[[Fixed point theorems|Topological fixed point theory]]'''\n* '''[[Topological graph theory]]'''\n* '''[[Topological K-theory]]'''\n* '''[[Topos theory]]'''\n* '''[[Toric geometry]]'''\n* '''[[Transcendental number theory]]''': a branch of [[number theory]] that revolves around the [[transcendental number]]s.\n* '''[[Transfinite order theory]]'''\n* '''[[Transformation geometry]]'''\n* '''[[Trigonometry]]''': the study of [[triangle]]s and the relationships between the [[length]] of their sides, and the [[angle]]s between them. It is essential to many parts of [[applied mathematics]].\n* '''[[Tropical analysis]]''': see ''idempotent analysis''\n* '''[[Tropical geometry]]'''\n* '''[[Twisted K-theory]]''': a variation on [[K-theory]], spanning abstract algebra, algebraic topology and [[operator theory]].\n* '''[[Type theory]]'''\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==U==\n\n* '''[[Umbral calculus]]''': the study of [[Sheffer sequences]]\n* '''[[Uncertainty theory]]''': a new branch of [[mathematics]] based on normality, monotonicity, self-duality, countable subadditivity, and product measure [[axiom]]s.\n* '''[[Unitary representation theory]]'''\n* '''[[Universal algebra]]''': a field studying the formalization of algebraic structures itself.\n* '''[[Rational trigonometry|Universal hyperbolic trigonometry]]''': an approach to [[hyperbolic geometry|hyperbolic trigonometry]] based on [[rational geometry]].\n\n==V==\n\n* '''[[Valuation theory]]'''\n* '''[[Variational analysis]]'''\n* '''Vector algebra''': a part of linear algebra concerned with the [[operation (mathematics)|operations]] of [[vector (mathematics)|vector]] addition and [[number (mathematics)|scalar]] [[multiplication]], although it may also refer to [[vector (mathematics)|vector]] [[operation (mathematics)|operation]]s of [[vector calculus]], including the [[dot product|dot]] and [[cross product]]. In this case it can be contrasted with [[geometric algebra]] which generalizes into higher dimensions.\n* '''[[Vector analysis]]''': also known as [[vector calculus]], see ''vector calculus''.\n* '''[[Vector calculus]]''': a branch of [[multivariable calculus]] concerned with [[Derivative|differentiation]] and [[integral|integration]] of [[vector field]]s. Primarily it is concerned with 3-dimensional [[Euclidean space]].\n\n==W==\n* '''[[Wavelet]]s'''\n* '''[[Windowed Fourier transform]]'''\n* '''[[Window function]]s'''\n\n==X==\n\n==Y==\n\n==Z==\n\n\n\n{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}\n\n==See also==\n* [[Glossary of astronomy]]\n* [[Glossary of biology]]\n* [[Glossary of calculus]]\n* [[Glossary of chemistry terms|Glossary of chemistry]]\n* [[Glossary of engineering]]\n* [[Glossary of physics]]\n* [[Glossary of probability and statistics]]\n\n[[Category:Glossaries of science|areas of mathematics]]\n[[Category:Fields of mathematics|* ]]\n[[Category:Glossaries of mathematics|A]]\n[[Category:Wikipedia glossaries|Mathematics]]\n{{Glossaries of science and engineering}}"
    },
    {
      "title": "Glossary of calculus",
      "url": "https://en.wikipedia.org/wiki/Glossary_of_calculus",
      "text": "''Most of the terms listed in Wikipedia glossaries are already defined and explained within Wikipedia itself.  However, glossaries like this one are useful for looking up, comparing and reviewing large numbers of terms together.  You can help enhance this page by adding new terms or writing definitions for existing ones.''\n\n\nThis '''glossary of calculus''' is a list of definitions about '''[[calculus]]''', its sub-disciplines, and related fields.\n\n{{compact ToC|side=yes|center=yes|nobreak=yes|seealso=yes|refs=yes|}}\n\n{{Calculus}}\n\n== A ==\n{{glossary}}\n\n{{term|[[Abel's test]]}}\n{{defn|defn=A method of testing for the [[Convergent series|convergence]] of an [[series (mathematics)|infinite series]].}}\n{{term|[[Absolute convergence]]}}\n{{defn|defn=An [[series (mathematics)|infinite series]] of numbers is said to '''converge absolutely''' (or to be '''absolutely convergent''') if the sum of the [[absolute value]]s of the summands is finite<!-- don't link to [[finite set]], please -->.  More precisely, a real or complex series <math>\\textstyle\\sum_{n=0}^\\infty a_n</math> is said to '''converge absolutely''' if <math>\\textstyle\\sum_{n=0}^\\infty \\left|a_n\\right| = L</math> for some real number <math>\\textstyle L</math>. Similarly, an [[improper integral]] of a [[function (mathematics)|function]], <math>\\textstyle\\int_0^\\infty f(x)\\,dx</math>, is said to converge absolutely if the integral of the absolute value of the integrand is finite—that is, if <math>\\textstyle\\int_0^\\infty \\left|f(x)\\right|dx = L.</math>}}\n{{term|[[Maxima and minima|Absolute maximum]]}}\n{{defn|defn=}}\n{{term|[[Maxima and minima|Absolute minimum]]}}\n{{defn|defn=}}\n{{term|[[Absolute value]]}}\n{{defn|defn= The '''absolute value''' or '''modulus''' {{math|{{!}}''x''{{!}}}} of a [[real number]]&nbsp;{{mvar|x}} is the [[non-negative]] value of&nbsp;{{mvar|x}} without regard to its [[sign (mathematics)|sign]]. Namely, {{math|1={{!}}''x''{{!}} = ''x''}} for a [[positive number|positive]]&nbsp;{{mvar|x}}, {{math|1={{!}}''x''{{!}} = −''x''}} for a [[negative number|negative]]&nbsp;{{mvar|x}} (in which case {{math|−''x''}} is positive), and {{math|1={{!}}0{{!}} = 0}}. For example, the absolute value of 3 is 3, and the absolute value of −3 is also 3. The absolute value of a number may be thought of as its [[distance]] from zero.}}\n{{term|[[Alternating series]]}}\n{{defn|defn= An [[infinite series]] whose terms alternate between positive and negative.}}\n{{term|[[Alternating series test]]}}\n{{defn|defn= Is the method used to prove that an [[alternating series]] with terms that decrease in absolute value is a [[convergent series]]. The test was used by [[Gottfried Leibniz]] and is sometimes known as '''Leibniz's test''', '''Leibniz's rule''', or the '''Leibniz criterion'''.}}\n{{term|[[Annulus (mathematics)|Annulus]]}}\n{{defn|defn= A ring-shaped object, a region bounded by two [[concentric circles]].}}\n{{term|[[Antiderivative]]}}\n{{defn|defn= An '''antiderivative''', '''primitive function''', '''primitive integral''' or '''indefinite integral'''{{#tag:ref|Antiderivatives are also called '''general integrals''', and sometimes '''integrals'''. The latter term is generic, and refers not only to indefinite integrals (antiderivatives), but also to [[definite integral]]s. When the word ''integral'' is used without additional specification, the reader is supposed to deduce from the context whether it refers to a definite or indefinite integral. Some authors define the indefinite integral of a function as the set of its infinitely many possible antiderivatives. Others define it as an arbitrarily selected element of that set. Wikipedia adopts the latter approach.{{citation needed|date=June 2016}}|group=Note}} of a [[function (mathematics)|function]] {{math|''f''}} is a differentiable function {{math|''F''}} whose [[derivative]] is equal to the original function {{math|''f''}}. This can be stated symbolically as <math>F' = f</math>.<ref>{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}</ref><ref>{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}</ref> The process of solving for antiderivatives is called '''antidifferentiation''' (or '''indefinite integration''') and its opposite operation is called differentiation, which is the process of finding a derivative.}}\n{{term|[[Inverse trigonometric functions|Arcsin]]}}\n{{defn|defn=}}\n{{term|[[Area under a curve]]}}\n{{defn|defn=}}\n{{term|[[Asymptote]]}}\n{{defn|defn= In [[analytic geometry]], an '''asymptote'''  of a [[curve]] is a line such that the distance between the curve and the line approaches zero as one or both of the ''x'' or ''y'' coordinates [[Limit of a function#Limits at infinity|tends to infinity]]. Some sources include the requirement that the curve may not cross the line infinitely often, but this is unusual for modern authors.<ref>[https://web.archive.org/web/*/http://rowdy.msudenver.edu/~talmanl/PDFs/APCalculus/OnAsymptotes.pdf \"Asymptotes\" by Louis A. Talman]</ref> In [[projective geometry]] and related contexts, an asymptote of a curve is a line which is [[tangent]] to the curve at a [[point at infinity]].<ref>{{citation|title=An elementary treatise on the differential calculus|chapter=Asymptotes|first=Benjamin|last=Williamson|url=https://books.google.com/?id=znsXAAAAYAAJ&pg=241|year=1899}}</ref><ref>{{citation|first=Jeffrey|last=Nunemacher|title=Asymptotes, Cubic Curves, and the Projective Plane|journal=Mathematics Magazine|volume=72|issue=3|year=1999|pages=183–192|jstor=2690881|doi=10.2307/2690881|citeseerx=10.1.1.502.72}}</ref>}}\n{{term|[[Automatic differentiation]]}}\n{{defn|defn=In [[mathematics]] and [[computer algebra]], '''automatic differentiation''' ('''AD'''), also called '''algorithmic differentiation''' or '''computational differentiation''',<ref>{{cite journal|last=Neidinger|first=Richard D.|title=Introduction to Automatic Differentiation and MATLAB Object-Oriented Programming|journal=SIAM Review|year=2010|volume=52|issue=3|pages=545–563|url=http://academics.davidson.edu/math/neidinger/SIAMRev74362.pdf|doi=10.1137/080743627}}</ref><ref name=\"baydin2018automatic\">{{cite journal|last=Baydin|first=Atilim Gunes|last2=Pearlmutter|first2=Barak|last3=Radul|first3=Alexey Andreyevich|last4=Siskind|first4=Jeffrey|title=Automatic differentiation in machine learning: a survey|journal=Journal of Machine Learning Research|year=2018|volume=18|pages=1–43|url=http://jmlr.org/papers/v18/17-468.html}}</ref> is a set of techniques to numerically evaluate the [[derivative]] of a function specified by a computer program. AD exploits the fact that every computer program, no matter how complicated, executes a sequence of elementary arithmetic operations (addition, subtraction, multiplication, division, etc.) and elementary functions (exp, log, sin, cos, etc.). By applying the [[chain rule]] repeatedly to these operations, derivatives of arbitrary order can be computed automatically, accurately to working precision, and using at most a small constant factor more arithmetic operations than the original program.}}\n\n{{term|[[Rate (mathematics)#rate of change|Average rate of change]]}}\n{{defn|defn=}}\n\n{{glossary end}}\n==B==\n{{glossary}}\n\n{{term|[[Binomial coefficient]]}}\n{{defn|Any of the positive [[integer]]s that occurs as a [[coefficient]] in the [[binomial theorem]] is a '''binomial coefficient'''.  Commonly, a binomial coefficient is indexed by a pair of integers {{math|''n'' ≥ ''k'' ≥ 0}} and is written <math>\\tbinom{n}{k}.</math> It is the [[coefficient]] of the {{math|''x''<sup>''k''</sup>}} term in the [[polynomial expansion]] of the [[binomial (polynomial)|binomial]] [[exponentiation|power]] {{math|(1 + ''x'')<sup>''n''</sup>}}, and it is given by the formula\n\n:<math>\\binom{n}{k} = \\frac{n!}{k! (n-k)!}.</math>}}\n{{term|[[Binomial theorem]]''' (or '''[[binomial expansion]])}}\n{{defn| Describes the algebraic expansion of [[exponentiation|powers]] of a [[binomial (polynomial)|binomial]].}}\n{{term|[[Bounded function]]}}\n{{defn|A [[function (mathematics)|function]] ''f'' defined on some [[Set (mathematics)|set]] ''X'' with [[real number|real]] or [[complex number|complex]] values is called '''bounded''', if the set of its values is [[bounded set|bounded]]. In other words, [[there exists]] a real number ''M'' such that \n:<math>|f(x)|\\le M</math>\n[[for all]] ''x'' in ''X''. A function that is ''not'' bounded is said to be '''unbounded'''.\n\nSometimes, if ''f''(''x'') ≤ ''A'' for all ''x'' in ''X'', then the function is said to be '''bounded above''' by ''A''. On the other hand, if ''f''(''x'') ≥ ''B'' for all ''x'' in ''X'', then the function is said to be '''bounded below''' by ''B''.}}\n{{term|[[Bounded function#bounded sequence|Bounded sequence]]}}\n{{defn| .}}\n\n{{glossary end}}\n==C==\n{{glossary}}\n\n{{term|[[Calculus]]}}\n{{defn|(From [[Latin]] ''calculus'', literally 'small pebble', used for counting and calculations, as on an [[abacus]])<ref name=\"oxdic\">{{cite web|title=Calculus|url=http://www.oxforddictionaries.com/us/definition/american_english/calculus|website=OxfordDictionaries|accessdate=15 September 2017}}</ref> is the [[mathematics|mathematical]] study of <!-- Please, do not link \"continuous\", it has the common-language meaning, and does not refer to the technical mathematical concept -->continuous change, in the same way that [[geometry]] is the study of shape and [[algebra]] is the study of generalizations of [[arithmetic operations]].}}\n{{term|[[Cavalieri's principle]]}}\n{{defn| In [[geometry]], '''Cavalieri's principle''', a modern implementation of the '''method of indivisibles''', named after [[Bonaventura Cavalieri]], is as follows:<ref>Howard Eves, \"Two Surprising Theorems on Cavalieri Congruence\", ''The College Mathematics Journal'', volume 22, number 2, March, 1991), pages 118&ndash;124</ref>\n* '''2-dimensional case''': Suppose two regions in a plane are included between two parallel lines in that plane. If every line parallel to these two lines intersects both regions in line segments of equal length, then the two regions have equal areas.\n* '''3-dimensional case''': Suppose two regions in three-space (solids) are included between two parallel planes. If every plane parallel to these two planes intersects both regions in [[cross section (geometry)|cross-sections]] of equal area, then the two regions have equal volumes.}}\n{{term|[[Chain rule]]}}\n{{defn|The '''chain rule''' is a [[formula]] for computing the [[derivative]] of the [[Function composition|composition]] of two or more [[function (mathematics)|functions]]. That is, if ''f'' and ''g'' are functions, then the chain rule expresses the derivative of their composition {{math|''f'' {{large|∘}} ''g''}} (the function which maps ''x'' to ''f''(''g''(''x'')) ) in terms of the derivatives of ''f'' and ''g'' and the [[pointwise product|product of functions]] as follows:\n\n:<math>(f\\circ g)'=(f'\\circ g)\\cdot g'.</math>\n\nThis may equivalently be expressed in terms of the variable. Let {{math|1=''F'' = ''f'' {{large|∘}} ''g''}}, or equivalently, {{math|1=''F''(''x'') = ''f''(''g''(''x''))}} for all ''x''. Then one can also write\n:<math>F'(x) = f'(g(x)) g'(x).</math>\n\nThe chain rule may be written in [[Leibniz's notation]] in the following way. If a variable ''z'' depends on the variable ''y'', which itself depends on the variable ''x'', so that ''y'' and ''z'' are therefore [[dependent variable]]s, then ''z'', via the intermediate variable of ''y'', depends on ''x'' as well.  The chain rule then states,\n\n:<math>\\frac{dz}{dx} = \\frac{dz}{dy} \\cdot \\frac{dy}{dx}. </math>\n\nThe two versions of the chain rule are related; if <math>z=f(y)</math> and <math>y=g(x)</math>, then\n\n:<math>\\frac{dz}{dx}=\\frac{dz}{dy}\\cdot\\frac{dy}{dx} = f'(y)g'(x) = f'(g(x))g'(x).</math>\n\nIn [[integral|integration]], the counterpart to the chain rule is the [[substitution rule]].}}\n{{term|[[Change of variables]]}}\n{{defn| Is a basic technique used to simplify problems in which the original [[variable (mathematics)|variable]]s are replaced with [[function (mathematics)|functions]] of other variables. The intent is that when expressed in new variables, the problem  may become simpler, or equivalent to a better understood problem.}}\n{{term|[[Cofunction]]}}\n{{defn|defn=A [[function (mathematics)|function]] ''f'' is '''cofunction''' of a function ''g'' if ''f''(''A'') = ''g''(''B'') whenever ''A'' and ''B'' are [[complementary angles]].<ref name=\"Hall_1909\">{{cite book |title=Trigonometry |volume=Part I: Plane Trigonometry |author-first1=Arthur Graham |author-last1=Hall |author-first2=Fred Goodrich |author-last2=Frink |date=January 1909 |location=Ann Arbor, Michigan, USA |chapter=Chapter II. The Acute Angle [10] Functions of complementary angles |publisher=[[Henry Holt and Company]] / Norwood Press / J. S. Cushing Co. - Berwick & Smith Co., Norwood, Massachusetts, USA |publication-place=New York, USA |pages=11-12 |url=https://archive.org/stream/planetrigonometr00hallrich#page/n26/mode/1up |access-date=2017-08-12 |dead-url=no}}</ref> This definition typically applies to [[trigonometric functions]].<ref name=\"Aufmann_Nation_2014\">{{cite book |title=Algebra and Trigonometry |author-first1=Richard |author-last1=Aufmann |author-first2=Richard |author-last2=Nation |edition=8 |publisher=[[Cengage Learning]] |year=2014 |isbn=978-128596583-3 |page=528 |url=https://books.google.com/books?id=JEDAAgAAQBAJ&pg=PA528 |access-date=2017-07-28}}</ref><ref name=\"Bales_2012\">{{cite web |title=5.1 The Elementary Identities |work=Precalculus |author-first=John W. |author-last=Bales |date=2012 |orig-year=2001 |url=http://jwbales.home.mindspring.com/precal/part5/part5.1.html |access-date=2017-07-30 |dead-url=no |archive-url=https://web.archive.org/web/20170730201433/http://jwbales.home.mindspring.com/precal/part5/part5.1.html |archive-date=2017-07-30}}</ref> The prefix \"co-\" can be found already in [[Edmund Gunter]]'s ''Canon triangulorum'' (1620).<ref name=\"Gunter_1620\">{{cite book |author-first=Edmund |author-last=Gunter |author-link=Edmund Gunter |title=Canon triangulorum |date=1620}}</ref><ref name=\"Roegel_2010\">{{cite web |title=A reconstruction of Gunter's Canon triangulorum (1620) |editor-first=Denis |editor-last=Roegel |type=Research report |publisher=HAL |date=2010-12-06 |id=inria-00543938 |url=https://hal.inria.fr/inria-00543938/document |access-date=2017-07-28 |dead-url=no |archive-url=https://web.archive.org/web/20170728192238/https://hal.inria.fr/inria-00543938/document |archive-date=2017-07-28}}</ref> .}}\n{{term|[[Concave function]]}}\n{{defn| Is the [[additive inverse|negative]] of a [[convex function]]. A concave function is also [[synonym]]ously called '''concave downwards''', '''concave down''', '''convex upwards''', '''convex cap''' or '''upper convex'''.}}\n{{term|[[Constant of integration]]}}\n{{defn|defn= The [[indefinite integral]] of a given function (i.e., the [[Set (mathematics)|set]] of all [[antiderivative]]s of the function) on a [[connected set|connected domain]] is only defined [[up to]] an additive constant, the '''constant of integration'''.<ref>{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}</ref><ref>{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}</ref> This constant expresses an ambiguity inherent in the construction of antiderivatives.  If a function <math>f(x)</math> is defined on an [[interval (mathematics)|interval]] and <math>F(x)</math> is an antiderivative of <math>f(x)</math>, then the set of ''all'' antiderivatives of <math>f(x)</math> is given by the functions <math>F(x) + C</math>, where ''C'' is an arbitrary constant (meaning that ''any'' value for ''C'' makes <math>F(x) + C</math> a valid antiderivative). The constant of integration is sometimes omitted in [[lists of integrals]] for simplicity.}}\n{{term|[[Continuous function]]}}\n{{defn|defn= Is a [[function (mathematics)|function]] for which sufficiently small changes in the input result in arbitrarily small changes in the output. Otherwise, a function is said to be a ''discontinuous'' function. A continuous function with a continuous [[inverse function]] is called a [[homeomorphism]].}}\n{{term|[[Differentiable function#Differentiability classes|Continuously differentiable]]}}\n{{defn|defn=A function ''f''  is said to be ''continuously differentiable'' if the derivative ''{{prime|f}}''(''x'') exists and is itself a continuous function.}}\n{{term|[[Methods of contour integration|Contour integration]]}}\n{{defn|defn= In the mathematical field of [[complex analysis]], '''contour integration''' is a method of evaluating certain [[integral]]s along paths in the complex plane.<ref name=Stalker>{{Cite book|title=Complex Analysis: Fundamentals of the Classical Theory of Functions |first=John |last=Stalker |page=77 | url=https://books.google.com/books?id=yl3GIXd3dFIC&pg=PP12&dq=%22calculus+of+residues%22#PPA77,M1|isbn=0-8176-4038-X |publisher=Springer |year=1998}}</ref><ref name=Bak>{{Cite book|title=Complex Analysis |first1=Joseph |last1=Bak |first2=Donald J. |last2=Newman |chapter=Chapters 11 & 12 |pages=130–156 |url=https://books.google.com/books?id=JX2YSgfZwbYC&pg=PA130&dq=%22contour+integral%22#PPA130,M1 |isbn=0-387-94756-6 |year=1997 |publisher=Springer}}</ref><ref name=Krantz>{{Cite book|title=Handbook of Complex Variables |first=Steven George |last=Krantz |chapter= Chapter 2 |url=https://books.google.com/books?id=aYU2AdF_0dIC&pg=PT13&dq=Calculus++Residues+inauthor:krantz#PPT47,M1 |isbn=0-8176-4011-8 |year=1999 |publisher=Springer }}</ref>}}\n{{term|[[Convergence test]]s}}\n{{defn|defn=Are methods of testing for the [[Convergent series|convergence]], [[conditional convergence]], [[absolute convergence]], [[interval of convergence]] or divergence of an [[series (mathematics)|infinite series]] <math>\\sum_{n=1}^\\infty a_n</math>.}}\n{{term|[[Convergent series]]}}\n{{defn|defn= In [[mathematics]], a [[series (mathematics)|series]] is the [[summation|sum]] of the terms of an [[infinite sequence]] of numbers.\n\nGiven an infinite sequence <math>\\left ( a_1,\\ a_2,\\ a_3,\\dots \\right )</math>, the ''n''th [[partial sum]] <math>S_n</math> is the sum of the first ''n'' terms of the sequence, that is,\n\n:<math>S_n = \\sum_{k=1}^n a_k.</math>\n\nA series is '''convergent''' if the sequence of its partial sums <math>\\left \\{ S_1,\\ S_2,\\ S_3,\\dots \\right \\}</math> tends to a [[limit of a sequence|limit]]; that means that the partial sums become closer and closer to a given number when the number of their terms increases. More precisely, a series converges, if there exists a number <math>\\ell</math> such that for any arbitrarily small positive number <math>\\varepsilon</math>, there is a (sufficiently large) [[integer]] <math>N</math> such that for all <math>n \\ge \\ N</math>,\n\n:<math>\\left | S_n - \\ell \\right \\vert \\le \\ \\varepsilon.</math>\nIf the series is convergent, the number <math>\\ell</math> (necessarily unique) is called the '''sum of the series'''.\n\nAny series that is not convergent is said to be [[Divergent series|divergent]].\n}}\n{{term|[[Convex function]]}}\n{{defn|defn= In [[mathematics]], a [[real-valued function]] defined on an [[interval (mathematics)#Multi-dimensional intervals|''n''-dimensional interval]] is called '''convex''' (or '''convex downward''' or '''concave upward''') if the [[line segment]] between any two points on the [[graph of a function|graph of the function]] lies above or on the graph, in a [[Euclidean space]] (or more generally a [[vector space]]) of at least two dimensions. Equivalently, a function is convex if its [[epigraph (mathematics)|epigraph]] (the set of points on or above the graph of the function) is a [[convex set]]. For a twice differentiable function of a single variable, if the second derivative is always greater than or equal to zero for its entire domain then the function is convex.<ref>{{Cite web|url=http://www.stat.cmu.edu/~larry/=stat705/Lecture2.pdf|title=Lecture Notes 2|last=|first=|date=|website=www.stat.cmu.edu|archive-url=|archive-date=|dead-url=|access-date=3 March 2017}}</ref> Well-known examples of convex functions include the [[quadratic function]] <math>x^2</math> and the [[exponential function]] <math>e^x</math>.}}\n{{term|[[Cramer's rule]]}}\n{{defn| In [[linear algebra]], '''Cramer's rule''' is an explicit formula for the solution of a [[system of linear equations]] with as many equations as unknowns, valid whenever the system has a unique solution. It expresses the solution in terms of the [[determinant]]s of the (square) coefficient [[Matrix (mathematics)|matrix]] and of matrices obtained from it by replacing one column by the column vector of right-hand-sides of the equations. It is named after [[Gabriel Cramer]] (1704&ndash;1752), who published the rule for an arbitrary number of unknowns in 1750,<ref>{{cite web \n  | title = Introduction à l'Analyse des lignes Courbes algébriques\n  | author = Cramer, Gabriel\n  | year = 1750\n  | location = Geneva\n  | language = French\n  | url = https://www.europeana.eu/resolve/record/03486/E71FE3799CEC1F8E2B76962513829D2E36B63015\n  | accessdate = 2012-05-18\n  | publisher = Europeana\n  | pages = 656–659\n}}</ref><ref>\n{{Cite journal\n | last = Kosinski\n | first = A. A.\n | title = Cramer's Rule is due to Cramer\n | journal = Mathematics Magazine\n | volume = 74\n | pages = 310–312\n | year = 2001\n | doi = 10.2307/2691101\n}}</ref> although [[Colin Maclaurin]] also published special cases of the rule in 1748<ref>{{Cite book\n  | last = MacLaurin\n  | first = Colin\n  | title = A Treatise of Algebra, in Three Parts.\n  | url = https://archive.org/details/atreatisealgebr03maclgoog\n  | year = 1748\n}}</ref> (and possibly knew of it as early as 1729).<ref>\n{{Cite book\n  | last = Boyer\n  | first = Carl B.\n  | authorlink = Carl Benjamin Boyer\n  | title = A History of Mathematics\n  | edition = 2nd\n  | publisher = Wiley\n  | year = 1968\n  | pages = 431\n}}\n</ref><ref>\n{{cite book\n | last = Katz\n | first = Victor\n | title = A History of Mathematics\n | publisher = Pearson Education\n | edition = Brief\n | year = 2004\n | pages = 378–379\n}}\n</ref><ref>\n{{Cite journal\n | last = Hedman\n | first = Bruce A.\n | title = An Earlier Date for \"Cramer's Rule\"\n | journal = Historia Mathematica\n | volume = 26\n | issue =4\n | pages = 365–368\n | year = 1999\n | url = http://professorhedman.com/Cramers.Rule.pdf\n | doi = 10.1006/hmat.1999.2247\n \n }}\n</ref>.}}\n{{term|[[Critical point (mathematics)|Critical point]]}}\n{{defn|defn=A '''critical point''' or '''stationary point''' of a [[differentiable function]] of a [[Function of a real variable|real]] or [[complex variable]] is any value in its [[domain of a function|domain]] where its [[derivative]] is 0.<ref>{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}</ref><ref>{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}</ref>}}\n{{term|[[Curve]]}}\n{{defn|defn= A '''curve''' (also called a '''curved line''' in older texts) is, generally speaking, an object similar to a [[line (geometry)|line]] but that need not be [[Linearity|straight]].}} \n{{term|[[Curve sketching]]}}\n{{defn|defn= \n In [[geometry]], '''curve sketching''' (or '''curve tracing''') includes techniques that can be used to produce a rough idea of overall shape of a [[plane curve]] given its equation without computing the large numbers of points required for a detailed plot. It is an application of the theory of curves to find their main features. Here input is an equation.\n In [[digital geometry]] it is a method of drawing a curve pixel by pixel. Here input is an array ( digital image).}}\n\n{{glossary end}}\n==D==\n{{glossary}}\n{{term|term=[[Damped sine wave]]}}\n{{defn|defn= Is a [[Sine wave|sinusoidal function]] whose amplitude approaches zero as time increases.<ref>Douglas C. Giancoli (2000). [''Physics for Scientists and Engineers with Modern Physics (3rd Edition)'']. Prentice Hall. {{ISBN|0-13-021517-1}}</ref>}}\n{{term|term=[[Degree of a polynomial]]}}\n{{defn|defn=Is the highest degree of its [[monomial]]s (individual terms) with non-zero coefficients. The [[degree of a monomial|degree of a term]] is the sum of the exponents of the [[Variable (mathematics)|variables]] that appear in it, and thus is a non-negative integer.}}\n{{term|term=[[Derivative]]}}\n{{defn|defn=The '''derivative''' of a [[function of a real variable]] measures the sensitivity to change of the function value (output value) with respect to a change in its argument (input value). Derivatives are a fundamental tool of [[calculus]].  For example, the derivative of the position of a moving object with respect to [[time]] is the object's [[velocity]]: this measures how quickly the position of the object changes when time advances.}}\n{{term|term=[[Derivative test]]}}\n{{defn|defn=A '''derivative test''' uses the [[derivative]]s of a function to locate the [[stationary point|critical point]]s of a function and determine whether each point is a [[local maximum]], a [[local minimum]], or a [[saddle point]]. Derivative tests can also give information about the [[Concave function|concavity]] of a function.}}\n{{term|term=[[Differentiable function]]}}\n{{defn|defn=A '''differentiable function''' of one [[Real number|real]] variable is a function whose [[derivative]] exists at each point in its [[Domain of a function|domain]]. As a result, the [[Graph of a function|graph]] of a differentiable function must have a (non-[[Vertical tangent|vertical]]) [[tangent line]] at each point in its domain, be relatively smooth, and cannot contain any breaks, bends, or [[Cusp (singularity)|cusps]].}}\n{{term|term=[[Differential (infinitesimal)]]}}\n{{defn|defn=The term '''differential''' is used in [[calculus]] to refer to an [[infinitesimal]] (infinitely small) change in some [[Variable (mathematics)|varying quantity]]. For example, if ''x'' is a [[Variable (mathematics)|variable]], then a change in the value of ''x'' is often denoted Δ''x'' (pronounced ''[[Delta (Greek)|delta]] x''). The differential ''dx'' represents an infinitely small change in the variable ''x''. The idea of an infinitely small or infinitely slow change is extremely useful intuitively, and there are a number of ways to make the notion mathematically precise.\n\nUsing calculus, it is possible to relate the infinitely small changes of various variables to each other mathematically using [[derivative]]s. If ''y'' is a function of ''x'', then the differential ''dy'' of ''y'' is related to ''dx'' by the formula\n:<math>dy = \\frac{dy}{dx} \\,dx,</math>\nwhere ''dy''/''dx'' denotes the [[derivative]] of ''y'' with respect to ''x''. This formula summarizes the intuitive idea that the derivative of ''y'' with respect to ''x'' is the limit of the ratio of differences Δ''y''/Δ''x'' as Δ''x'' becomes infinitesimal.}}\n{{term|term=[[Differential calculus]]}}\n{{defn|defn=Is a subfield of calculus<ref>{{Cite web|url=https://www.merriam-webster.com/dictionary/differential%20calculus|title=Definition of DIFFERENTIAL CALCULUS|website=www.merriam-webster.com|language=en|access-date=2018-09-26}}</ref> concerned with the study of the rates at which quantities change. It is one of the two traditional divisions of calculus, the other being [[integral calculus]], the study of the area beneath a curve.<ref>{{Cite web|url=https://www.merriam-webster.com/dictionary/integral%20calculus|title=\"Integral Calculus - Definition of Integral calculus by Merriam-Webster\"|last=|first=|date=|website=www.merriam-webster.com|language=en|archive-url=|archive-date=|dead-url=|access-date=2018-05-01}}</ref>}}\n{{term|term=[[Differential equation]]}}\n{{defn|defn=Is a [[mathematics|mathematical]] [[equation]] that relates some [[function (mathematics)|function]] with its [[derivative]]s. In applications, the functions usually represent physical quantities, the derivatives represent their rates of change, and the equation defines a relationship between the two.}}\n{{term|term=[[Differential operator]]}}\n{{defn|defn=.}}\n{{term|term=[[Differential of a function]]}}\n{{defn|defn=In [[calculus]], the '''differential''' represents the [[principal part#Calculus|principal part]] of the change in a function ''y''&nbsp;=&nbsp;''f''(''x'') with respect to changes in the independent variable. The differential ''dy'' is defined by\n:<math>dy = f'(x)\\,dx,</math>\nwhere <math>f'(x)</math> is the [[derivative]] of ''f'' with respect to ''x'', and ''dx'' is an additional real [[variable (mathematics)|variable]] (so that ''dy'' is a function of ''x'' and ''dx'').  The notation is such that the equation\n\n:<math>dy = \\frac{dy}{dx}\\, dx</math>\n\nholds, where the derivative is represented in the [[Leibniz notation]] ''dy''/''dx'', and this is consistent with regarding the derivative as the quotient of the differentials. One also writes\n\n:<math>df(x) = f'(x)\\,dx.</math>\n\nThe precise meaning of the variables ''dy'' and ''dx'' depends on the context of the application and the required level of mathematical rigor. The domain of these variables may take on a particular geometrical significance if the differential is regarded as a particular [[differential form]], or analytical significance if the differential is regarded as a [[linear approximation]] to the increment of a function.  Traditionally, the variables ''dx'' and ''dy'' are considered to be very small ([[infinitesimal]]), and this interpretation is made rigorous in [[non-standard analysis]].}}\n{{term|term=[[Differentiation rules]]}}\n{{defn|defn=.}}\n{{term|term=[[Direct comparison test]]}}\n{{defn|defn=A convergence test in which an infinite series or an improper integral is compared to one with known convergence properties.}}\n{{term|term=[[Dirichlet's test]]}}\n{{defn|defn=Is a method of testing for the [[Convergent series|convergence]] of a [[series (mathematics)|series]]. It is named after its author [[Peter Gustav Lejeune Dirichlet]], and was published posthumously in the ''[[Journal de Mathématiques Pures et Appliquées]]'' in 1862.<ref>''Démonstration d’un théorème d’Abel.'' Journal de mathématiques pures et appliquées 2nd series, tome 7 (1862), [http://portail.mathdoc.fr/JMPA/afficher_notice.php?id=JMPA_1862_2_7_A43_0 p. 253-255].</ref>   The test states that if <math>\\{a_n\\}</math> is a [[sequence]] of [[real number]]s and <math>\\{b_n\\}</math> a sequence of [[complex number]]s satisfying\n\n:* <math>a_{n+1} \\le a_n</math>\n\n:* <math>\\lim_{n \\rightarrow \\infty}a_n = 0</math>\n\n:* <math>\\left|\\sum^{N}_{n=1}b_n\\right|\\leq M</math> for every positive integer ''N''\n\nwhere ''M'' is some constant, then the series\n\n:<math>\\sum^{\\infty}_{n=1}a_n b_n</math>\n\nconverges.}}\n{{term|term=[[Disc integration]]}}\n{{defn|defn=Also known in [[integral calculus]] as the '''disc method''', is a means of calculating the [[volume]] of a [[solid of revolution]] of a solid-state material when [[Integral|integrating]] along an axis \"parallel\" to the [[axis of revolution]].}}\n{{term|term=[[Divergent series]]}}\n{{defn|defn=Is an [[infinite series]] that is not [[Convergent series|convergent]], meaning that the infinite [[sequence]] of the [[partial sum]]s of the series does not have a finite [[limit of a sequence|limit]].}}\n{{term|term=[[Discontinuity (mathematics)|Discontinuity]]}}\n{{defn|defn=[[Continuous function]]s are of utmost importance in [[mathematics]], functions and applications. However, not all [[function (mathematics)|functions]] are continuous. If a function is not continuous at a point in its [[domain (mathematics)|domain]], one says that it has a '''discontinuity''' there. The set of all points of discontinuity of a function may be a [[discrete set]], a [[dense set]], or even the entire domain of the function.}}\n{{term|term=[[Dot product]]}}\n{{defn|defn=In [[mathematics]], the '''dot product''' or '''scalar product'''<ref group=note>The term ''scalar product'' is often also used more generally to mean a [[symmetric bilinear form]], for example for a [[pseudo-Euclidean space]].{{cn|date=March 2017}}</ref> is an [[algebraic operation]] that takes two equal-length sequences of numbers (usually [[coordinate vector]]s) and returns a single number.  In [[Euclidean geometry]], the dot product of the [[Cartesian coordinates]] of two [[vector (mathematics and physics)|vectors]] is widely used and often called \"the\" '''inner product''' (or rarely '''projection product''') of Euclidean space even though it is not the only inner product that can be defined on Euclidean space; see also [[inner product space]].}}\n{{term|term=[[Double integral]]}}\n{{defn|defn= The '''multiple integral''' is a [[definite integral]] of a [[Function (mathematics)|function]] of more than one real [[Variable (mathematics)|variable]], for example, {{math|''f''(''x'', ''y'')}} or {{math|''f''(''x'', ''y'', ''z'')}}. Integrals of a function of two variables over a region in {{math|'''R'''<sup>2</sup>}} are called [[double integrals]], and integrals of a function of three variables over a region of {{math|'''R'''<sup>3</sup>}} are called [[triple integrals]].<ref name= \"Stewart\">{{cite book|authorlink=James Stewart (mathematician) |last=Stewart |first=James |date=2008 |title=Calculus: Early Transcendentals |edition=6th |publisher=Brooks Cole Cengage Learning |ISBN=978-0-495-01166-8}}</ref>}}\n\n{{glossary end}}\n==E==\n{{glossary}}\n\n{{term|term=[[e (mathematical constant)]]}}\n{{defn|defn=The number '''{{mvar|e}}''' is a [[mathematical constant]] that is the base of the [[natural logarithm]]: the unique number whose natural logarithm is equal to one. It is approximately equal to '''2.71828''',<ref>[[Oxford English Dictionary]], 2nd ed.: [http://oxforddictionaries.com/definition/english/natural-logarithm natural logarithm]</ref> and is the [[Limit of a sequence|limit]] of {{math|(1 + 1/''n'')<sup>''n''</sup>}} as {{mvar|n}} approaches [[infinity]], an expression that arises in the study of [[compound interest]]. It can also be calculated as the sum of the infinite [[Series (mathematics)|series]]<ref>[[Encyclopedic Dictionary of Mathematics]] 142.D</ref>\n\n:<math>e =  \\displaystyle\\sum\\limits_{n = 0}^{ \\infty} \\dfrac{1}{n!} = \\frac{1}{1} + \\frac{1}{1} + \\frac{1}{1\\cdot 2} + \\frac{1}{1\\cdot 2\\cdot 3} + \\cdots</math>}}\n{{term|term=[[Elliptic integral]]}}\n{{defn|defn=In [[integral calculus]], '''elliptic integrals''' originally arose in connection with the problem of giving the [[arc length]] of an [[ellipse]].  They were first studied by [[Giulio Carlo de' Toschi di Fagnano|Giulio Fagnano]] and [[Leonhard Euler]] ({{Circa|1750}}).  Modern mathematics defines an \"elliptic integral\" as any [[function (mathematics)|function]] {{math|''f''}} which can be expressed in the form\n\n: <math> f(x) = \\int_{c}^{x} R \\left(t, \\sqrt{P(t)} \\right) \\, dt, </math>\n\nwhere {{math|''R''}} is a [[rational function]] of its two arguments, {{math|''P''}} is a [[polynomial]] of degree 3 or 4 with no repeated roots, and {{math|''c''}} is a constant..}}\n{{term|term=[[Classification of discontinuities#Essential discontinuity|Essential discontinuity]]}}\n{{defn|defn=For an essential discontinuity, only one of the two one-sided limits needs not exist or be infinite.\nConsider the function \n:<math>f(x) = \\begin{cases}\n  \\sin\\frac{5}{x-1} & \\mbox{ for } x < 1 \\\\\n  0                 & \\mbox{ for } x = 1 \\\\\n  \\frac{1}{x-1}   & \\mbox{ for } x > 1\n\\end{cases}</math>\n\nThen, the point <math>\\scriptstyle x_0 \\;=\\; 1</math> is an ''essential discontinuity''. \n\nIn this case,  <math>\\scriptstyle L^{-}</math> doesn't exist and  <math>\\scriptstyle L^{+}</math> is infinite – thus satisfying twice the conditions of essential discontinuity. So ''x''<sub>0</sub> is an ''essential discontinuity'', ''infinite discontinuity'', or ''discontinuity of the second kind''. (This is distinct from the term ''[[essential singularity]]'' which is often used when studying [[complex analysis|functions of complex variables]].}}\n{{term|term=[[Euler method]]}}\n{{defn|defn=Euler's method is a numerical method to solve first order first degree differential equation with a given initial value. It is the most basic [[explicit and implicit methods|explicit method]] for [[numerical ordinary differential equations|numerical integration of ordinary differential equations]] and is the simplest [[Runge–Kutta method]]. The Euler method is named after [[Leonhard Euler]], who treated it in his book ''[[Institutionum calculi integralis]]'' (published 1768–1870).<ref>{{harvnb|Butcher|2003|p=45}}; {{harvnb|Hairer|Nørsett|Wanner|1993|p=35}}</ref>}}\n{{term|term=[[Exponential function]]}}\n{{defn|defn=In [[mathematics]], an '''exponential function''' is a function of the form\n{{block indent|<math> f(x) = ab^x, </math>}}\nwhere {{mvar|b}} is a positive real number, and in which the argument {{math|''x''}} occurs as an exponent. For real numbers {{mvar|c}} and {{mvar|d,}} a function of the form <math>f(x)=ab^{cx+d}</math> is also an exponential function, as it can be rewritten as \n:<math>ab^{cx+d}=\\left(ab^d\\right) \\left(b^c\\right)^x.</math>}}\n{{term|term=[[Extreme value theorem]]}}\n{{defn|defn=States that if a real-valued [[Function (mathematics)|function]] ''f'' is [[Continuous function|continuous]] on the [[Bounded interval#Classification of intervals|closed]] interval [''a'',''b''], then ''f'' must attain a [[maximum]] and a [[minimum]], each at least once. That is, there exist numbers ''c'' and ''d'' in [''a'',''b''] such that:\n\n:<math>f(c) \\ge f(x) \\ge f(d)\\quad\\text{for all }x\\in [a,b].</math>\n\nA related theorem is '''the boundedness theorem''' which states that a continuous function ''f'' in the closed interval [''a'',''b''] is [[Bounded function|bounded]] on that interval. That is, there exist real numbers ''m'' and ''M'' such that:\n\n:<math>m < f(x) < M\\quad\\text{for all }x \\in [a,b].</math>\n\nThe extreme value theorem enriches the boundedness theorem by saying that not only is the function bounded, but it also attains its least upper bound as its maximum and its greatest lower bound as its minimum.}}\n{{term|term=[[Maxima and minima|Extremum]]}}\n{{defn|defn=In [[mathematical analysis]], the '''maxima and minima''' (the respective plurals of '''maximum''' and '''minimum''') of a [[function (mathematics)|function]], known collectively as '''extrema''' (the plural of '''extremum'''), are the largest and smallest value of the function, either within a given range (the '''local''' or '''relative''' extrema) or on the entire [[domain of a function]] (the '''global''' or '''absolute''' extrema).<ref>{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}</ref><ref>{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}</ref><ref>{{cite book | last1 = Thomas | first1 = George B. | last2=Weir | first2= Maurice D. | last3=Hass | first3=Joel |author3-link = Joel Hass| authorlink=George B. Thomas | title=Thomas' Calculus: Early Transcendentals | publisher=[[Addison-Wesley]] | year=2010 | edition=12th | isbn=0-321-58876-2}}</ref> [[Pierre de Fermat]] was one of the first mathematicians to propose a general technique, [[adequality]], for finding the maxima and minima of functions.\n\nAs defined in [[set theory]], the maximum and minimum of a [[set (mathematics)|set]] are the [[greatest and least elements]] in the set, respectively. Unbounded infinite sets, such as the set of [[real number]]s, have no minimum or maximum.}}\n\n{{glossary end}}\n==F==\n{{glossary}}\n\n{{term|[[Faà di Bruno's formula]]}}\n{{defn|defn= Is an identity in [[mathematics]] generalizing the [[chain rule]] to higher derivatives, named after {{harvs|txt|authorlink=Francesco Faà di Bruno|first=Francesco|last= Faà di Bruno|year=1855|year2=1857}}, though he was not the first to state or prove the formula. In 1800, more than 50 years before Faà di Bruno, the French mathematician [[Louis François Antoine Arbogast]] stated the formula in a calculus textbook,<ref>{{harv|Arbogast|1800}}.</ref> considered the first published reference on the subject.<ref>According to {{harvtxt|Craik|2005|pp=120–122}}: see also the analysis of Arbogast's work by {{harvtxt|Johnson|2002|p=230}}.</ref>\n\nPerhaps the most well-known form of Faà di Bruno's formula says that\n\n:<math>{d^n \\over dx^n} f(g(x))=\\sum \\frac{n!}{m_1!\\,1!^{m_1}\\,m_2!\\,2!^{m_2}\\,\\cdots\\,m_n!\\,n!^{m_n}}\\cdot f^{(m_1+\\cdots+m_n)}(g(x))\\cdot \\prod_{j=1}^n\\left(g^{(j)}(x)\\right)^{m_j},</math>\n\nwhere the sum is over all ''n''-[[tuple]]s of nonnegative integers (''m''<sub>1</sub>, …, ''m''<sub>''n''</sub>) satisfying the constraint\n\n:<math>1\\cdot m_1+2\\cdot m_2+3\\cdot m_3+\\cdots+n\\cdot m_n=n.</math>\n\nSometimes, to give it a memorable pattern, it is written in a way in which the coefficients that have the combinatorial interpretation discussed below are less explicit:\n\n:<math>{d^n \\over dx^n} f(g(x))\n=\\sum \\frac{n!}{m_1!\\,m_2!\\,\\cdots\\,m_n!}\\cdot\nf^{(m_1+\\cdots+m_n)}(g(x))\\cdot\n\\prod_{j=1}^n\\left(\\frac{g^{(j)}(x)}{j!}\\right)^{m_j}.</math>\n\nCombining the terms with the same value of ''m''<sub>1</sub>&nbsp;+&nbsp;''m''<sub>2</sub>&nbsp;+&nbsp;...&nbsp;+&nbsp;''m''<sub>''n''</sub>&nbsp;=&nbsp;''k'' and noticing that ''m''<sub>&nbsp;''j''</sub> has to be zero for ''j''&nbsp;>&nbsp;''n''&nbsp;&minus;&nbsp;''k''&nbsp;+&nbsp;1 leads to a somewhat simpler formula expressed in terms of [[Bell polynomial]]s ''B''<sub>''n'',''k''</sub>(''x''<sub>1</sub>,...,''x''<sub>''n''&minus;''k''+1</sub>):\n\n:<math>{d^n \\over dx^n} f(g(x)) = \\sum_{k=1}^n f^{(k)}(g(x))\\cdot B_{n,k}\\left(g'(x),g''(x),\\dots,g^{(n-k+1)}(x)\\right).</math>}}\n{{term|[[Degree of a polynomial|First-degree polynomial]]}}\n{{defn|defn=}}\n{{term|[[Derivative test#First derivative test|First derivative test]]}}\n{{defn|defn=The first derivative test examines a function's [[monotonic function|monotonic]] properties (where the function is increasing or decreasing) focusing on a particular point in its domain. If the function \"switches\" from increasing to decreasing at the point, then the function will achieve a highest value at that point. Similarly, if the function \"switches\" from decreasing to increasing at the point, then it will achieve a least value at that point. If the function fails to \"switch\", and remains increasing or remains decreasing, then no highest or least value is achieved.}}\n{{term|[[Fractional calculus]]}}\n{{defn|defn=Is a branch of [[mathematical analysis]] that studies the several different possibilities of defining [[real number]] powers or [[complex number]] powers of the [[derivative|differentiation operator]] {{mvar|D}}\n\n:<math>D f(x) = \\dfrac{d}{dx} f(x)</math>,\n\nand of the integration operator {{mvar|J}}\n\n:<math>J f(x) = \\int_0^x\\!\\!\\!\\! f(s) {ds}</math>,<ref group=Note>The symbol {{mvar|J}} is commonly is used instead of the intuitive {{mvar|I}} in order to avoid confusion with other concepts identified by similar {{mvar|I}}–like [[glyph]]s, e.g. [[identity (mathematics)|identities]].</ref>\n\nand developing a [[calculus]] for such operators generalizing the classical one.\n\nIn this context, the term ''powers'' refers to iterative application of a linear operator to a function, in some analogy to [[function composition]] acting on a variable, i.e. {{math|''f''&nbsp;{{ssup|∘2}}(''x'')&nbsp;{{=}}&nbsp;''f''&nbsp;∘&nbsp;''f''&nbsp;(''x'')&nbsp;{{=}}&nbsp;''f''&nbsp;(&nbsp;''f''&nbsp;(''x'')&nbsp;)}}.}}\n{{term|[[Frustum]]}}\n{{defn|defn=In [[geometry]], a '''frustum''' (plural: ''frusta'' or ''frustums'') is the portion of a [[polyhedron|solid]] (normally a [[cone (geometry)|cone]] or [[pyramid (geometry)|pyramid]]) that lies between one or two [[parallel planes]] cutting it. A '''right frustum''' is a parallel [[truncation (geometry)|truncation]] of a [[right pyramid]] or right cone.<ref>William F. Kern, James R. Bland, ''Solid Mensuration with proofs'', 1938, p.&nbsp;67</ref>}}\n{{term|[[Function (mathematics)|Function]]}}\n{{defn|defn=Is a process or a relation<!-- Please, do not link to [[Binary relation]], this is not the technical meaning that is intended--> that associates each element {{mvar|x}} of a [[set (mathematics)|set]] {{mvar|X}},  the ''[[domain of a function|domain]]'' of the function, to a single element {{mvar|y}} of another set {{mvar|Y}} (possibly the same set), the ''codomain'' of the function. If the function is called {{mvar|f}}, this relation is denoted {{math|1=''y'' = ''f''{{space|hair}}(''x'')}} (read {{mvar|f}} of {{mvar|x}}), the element {{mvar|x}} is the ''[[argument of a function|argument]]'' or ''input'' of the function, and {{mvar|y}} is the ''value of the function'', the ''output'', or the ''image'' of {{mvar|x}} by {{mvar|f}}.<ref name=MacLane>{{cite book | last = MacLane | first = Saunders | authorlink = Saunders MacLane | last2 = Birkhoff | first2 = Garrett | author2-link = Garrett Birkhoff | title = Algebra | publisher = Macmillan | edition = First | year = 1967 | location = New York | pages = 1–13 }}</ref> The symbol that is used for representing the input is the [[variable (mathematics)|variable]] of the function (one often says that {{mvar|f}} is a function of the variable {{mvar|x}}).}}\n{{term|[[Function composition]]}}\n{{defn|defn=Is an operation that takes two [[function (mathematics)|functions]] {{math|''f''}} and {{math|''g''}} and produces a function {{math|''h''}} such that {{math|1=''h''(''x'') = ''g''(''f''(''x''))}}. In this operation, the function {{math|''g''}} is [[function application|applied]] to the result of applying the function {{math|''f''}} to {{math|''x''}}. That is, the functions {{math|''f'' : ''X'' → ''Y''}} and {{math|''g'' : ''Y'' → ''Z''}} are '''composed''' to yield a function that maps {{math|''x''}} in {{math|''X''}} to {{math|''g''(''f''(''x''))}} in {{math|''Z''}}.}}\n{{term|[[Fundamental theorem of calculus]]}}\n{{defn|The '''fundamental theorem of calculus''' is a [[theorem]] that links the concept of [[derivative|differentiating]] a [[function (mathematics)|function]] with the concept of [[integral|integrating]] a function. The first part of the theorem, sometimes called the '''first fundamental theorem of calculus''', states that one of the [[antiderivative]]s (also called ''indefinite integral''), say ''F'', of some function ''f'' may be obtained as the integral of ''f'' with a variable bound of integration. This implies the existence of [[antiderivative]]s for [[continuous function]]s.<ref>{{Citation |last=Spivak|first=Michael|year=1980|title=Calculus|edition=2nd|publication-place=Houston, Texas|publisher=Publish or Perish Inc.}}</ref>  Conversely, the second part of the theorem, sometimes called the '''second fundamental theorem of calculus''', states that the integral of a function ''f'' over some interval can be computed by using any one, say ''F'', of its infinitely many [[antiderivative]]s. This part of the theorem has key practical applications, because explicitly finding the antiderivative of a function by [[symbolic integration]] avoids [[numerical integration]] to compute integrals. This provides generally a better numerical accuracy.}}\n\n{{glossary end}}\n==G==\n{{glossary}}\n\n{{term|term=[[General Leibniz rule]]}}\n{{defn|defn= The '''general Leibniz rule''',<ref>{{cite book |last=Olver |first=Peter J. |year=2000 |title=Applications of Lie Groups to Differential Equations |publisher=Springer |pages=318–319 |url=https://books.google.com/books?id=sI2bAxgLMXYC&pg=PA318 }}</ref> named after [[Gottfried Wilhelm Leibniz]], generalizes the [[product rule]] (which is also known as \"Leibniz's rule\").  It states that if <math>f</math> and <math>g</math> are <math>n</math>-times [[differentiable function]]s, then the product <math>fg</math> is also <math>n</math>-times differentiable and its <math>n</math>th derivative is given by\n\n:<math>(fg)^{(n)}=\\sum_{k=0}^n {n \\choose k} f^{(n-k)} g^{(k)},</math>\n\nwhere <math>{n \\choose k}={n!\\over k! (n-k)!}</math> is the [[binomial coefficient]] and <math>f^{(0)}\\equiv f.</math>\n\nThis can be proved by using the product rule and [[mathematical induction]].}}\n{{term|term=[[Maxima and minima|Global maximum]]}}\n{{defn|defn= In [[mathematical analysis]], the '''maxima and minima''' (the respective plurals of '''maximum''' and '''minimum''') of a [[function (mathematics)|function]], known collectively as '''extrema''' (the plural of '''extremum'''), are the largest and smallest value of the function, either within a given range (the '''local''' or '''relative''' extrema) or on the entire [[domain of a function]] (the '''global''' or '''absolute''' extrema).<ref>{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}</ref><ref>{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}</ref><ref>{{cite book | last1 = Thomas | first1 = George B. | last2=Weir | first2= Maurice D. | last3=Hass | first3=Joel |author3-link = Joel Hass| authorlink=George B. Thomas | title=Thomas' Calculus: Early Transcendentals | publisher=[[Addison-Wesley]] | year=2010 | edition=12th | isbn=0-321-58876-2}}</ref> [[Pierre de Fermat]] was one of the first mathematicians to propose a general technique, [[adequality]], for finding the maxima and minima of functions.\n\nAs defined in [[set theory]], the maximum and minimum of a [[set (mathematics)|set]] are the [[greatest and least elements]] in the set, respectively. Unbounded infinite sets, such as the set of [[real number]]s, have no minimum or maximum.}}\n{{term|term=[[Maxima and minima|Global minimum]]}}\n{{defn|defn= In [[mathematical analysis]], the '''maxima and minima''' (the respective plurals of '''maximum''' and '''minimum''') of a [[function (mathematics)|function]], known collectively as '''extrema''' (the plural of '''extremum'''), are the largest and smallest value of the function, either within a given range (the '''local''' or '''relative''' extrema) or on the entire [[domain of a function]] (the '''global''' or '''absolute''' extrema).<ref>{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}</ref><ref>{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}</ref><ref>{{cite book | last1 = Thomas | first1 = George B. | last2=Weir | first2= Maurice D. | last3=Hass | first3=Joel |author3-link = Joel Hass| authorlink=George B. Thomas | title=Thomas' Calculus: Early Transcendentals | publisher=[[Addison-Wesley]] | year=2010 | edition=12th | isbn=0-321-58876-2}}</ref> [[Pierre de Fermat]] was one of the first mathematicians to propose a general technique, [[adequality]], for finding the maxima and minima of functions.\n\nAs defined in [[set theory]], the maximum and minimum of a [[set (mathematics)|set]] are the [[greatest and least elements]] in the set, respectively. Unbounded infinite sets, such as the set of [[real number]]s, have no minimum or maximum.}}\n{{term|term=[[Golden spiral]]}}\n{{defn|defn=In [[geometry]], a '''golden spiral''' is a [[logarithmic spiral]] whose growth factor is [[Phi|{{math|&phi;}}]], the [[golden ratio]].<ref>Chang, Yu-sung, \"[http://demonstrations.wolfram.com/GoldenSpiral/ Golden Spiral]\", [[The Wolfram Demonstrations Project]].</ref> That is, a golden spiral gets wider (or further from its origin) by a factor of {{math|&phi;}} for every quarter turn it makes.}}\n{{term|term=[[Gradient]]}}\n{{defn|defn= Is a multi-variable generalization of the [[derivative]].  While a derivative can be defined on functions of a single variable, for [[function of several variables|functions of several variables]], the gradient takes its place.  The gradient is a [[vector-valued function]], as opposed to a derivative, which is [[Scalar-valued function|scalar-valued]].}}\n\n{{glossary end}}\n==H==\n{{glossary}}\n\n{{term|term=[[Harmonic progression (mathematics)|Harmonic progression]]}}\n{{defn|defn=In [[mathematics]], a '''harmonic progression''' (or '''harmonic sequence''') is a progression formed by taking the reciprocals of an [[arithmetic progression]]. It is a [[sequence]] of the form\n\n:<math> \\frac{1}{a} ,\\ \\frac{1}{a+d}\\ , \\frac{1}{a+2d}\\ , \\frac{1}{a+3d}\\ , \\cdots, \\frac{1}{a+kd},</math>\n\nwhere &minus;a/''d'' is not a [[natural number]] and ''k'' '''is''' a natural number.\n\nEquivalently, a sequence is a harmonic progression when each term is the [[harmonic mean]] of the neighboring terms.\n\nIt is not possible for a harmonic progression (other than the trivial case where ''a'' = 1 and ''k'' = 0)  to sum to an [[integer]]. The reason is that, necessarily, at least one denominator of the progression will be divisible by a [[prime number]] that does not divide any other denominator.<ref>{{citation|first=P.|last= Erdős |authorlink=Paul Erdős |title=Egy Kürschák-féle elemi számelméleti tétel általánosítása|trans-title=Generalization of an elementary number-theoretic theorem of Kürschák|language=Hungarian|journal=Mat. Fiz. Lapok|volume=39|year=1932|pages=17–24|url=https://www.renyi.hu/~p_erdos/1932-02.pdf}}. As cited by {{citation\n | last = Graham | first = Ronald L. | authorlink = Ronald Graham\n | contribution = Paul Erdős and Egyptian fractions\n | doi = 10.1007/978-3-642-39286-3_9\n | mr = 3203600\n | pages = 289–309\n | publisher = János Bolyai Math. Soc., Budapest\n | series = Bolyai Soc. Math. Stud.\n | title = Erdős centennial\n | volume = 25\n | year = 2013}}.</ref>}}\n\n{{term|term=[[Derivative#Higher derivatives|Higher derivative]]}}\n{{defn|defn= Let {{math|''f''}} be a differentiable function, and let {{math|''f'' ′}} be its derivative. The derivative of {{math|''f'' ′}} (if it has one) is written {{math|''f'' ′′}} and is called the ''[[second derivative]] of {{math|f}}''.  Similarly, the derivative of the second derivative, if it exists, is written {{math|''f'' ′′′}} and is called the ''[[third derivative]] of {{math|f}}''. Continuing this process, one can define, if it exists, the {{math|''n''}}th derivative as the derivative of the {{math|(''n''-1)}}th derivative. These repeated derivatives are called ''higher-order derivatives''. The {{math|''n''}}th derivative is also called the '''derivative of order {{math|''n''}}'''.}}\n{{term|term=[[Homogeneous differential equation|Homogeneous linear differential equation]]}}\n{{defn|defn=A [[differential equation]] can be '''homogeneous''' in either of two respects. \n\nA [[first order differential equation]] is said to be homogeneous if it may be written\n:<math>f(x,y)dy = g(x,y)dx,</math>\nwhere {{mvar|f}} and {{mvar|g}} are [[homogeneous function]]s of the same degree of {{mvar|x}} and {{mvar|y}}. In this case, the change of variable {{math|1=''y'' = ''ux''}} leads to an equation of the form \n:<math>\\frac{dx}x = h(u)du,</math>\nwhich is easy to solve by [[integral|integration]] of the two members.\n\nOtherwise, a differential equation is homogeneous if it is a homogeneous function of the unknown function and its derivatives. In the case of [[linear differential equation]]s, this means that there are no constant terms. The solutions of any linear [[ordinary differential equation]] of any order may be deduced by integration from the solution of the homogeneous equation obtained by removing the constant term.}}\n{{term|term=[[Hyperbolic function]]}}\n{{defn|defn= '''Hyperbolic functions''' are analogs of the ordinary [[trigonometric function|trigonometric]], or [[unit circle|circular]], functions.}}\n\n{{glossary end}}\n\n==I==\n{{glossary}}\n\n\n{{term|term=[[Identity function]]}}\n{{defn|defn= Also called an '''identity relation''' or '''identity map''' or '''identity transformation''', is a [[function (mathematics)|function]] that always returns the same value that was used as its argument. In [[equation]]s, the function is given by {{math|1=''f''(''x'') = ''x''}}.}}\n{{term|term=[[Imaginary number]]}}\n{{defn|defn=Is a [[complex number]] that can be written as a [[real number]] multiplied by the [[imaginary unit]] {{mvar|i}},<ref group=note>''j'' is usually used in Engineering contexts where ''i'' has other meanings (such as electrical current)</ref> which is defined by its property {{math|1=''i''<sup>2</sup> = −1}}.<ref>\n{{cite book\n|url=https://books.google.com/books?id=SGVfGIewvxkC&pg=PA38\n|title=Fundamentals of Waves and Oscillations\n|last=Uno Ingard\n|first=K.\n|publisher=Cambridge University Press\n|year=1988\n|isbn=0-521-33957-X\n|page=38\n|chapter=Chapter 2\n}}\n</ref> The [[square (algebra)|square]] of an imaginary number {{mvar|bi}} is {{math|−''b''<sup>2</sup>}}. For example, {{math|5''i''}} is an imaginary number, and its square is {{math|−25}}. Zero is considered to be both real and imaginary.<ref>{{cite book|url=https://books.google.com/books?id=mqdzqbPYiAUC&pg=SA11-PA2|title=A Text Book of Mathematics Class XI|last=Sinha|first=K.C.|publisher=Rastogi Publications|year=2008|isbn=978-81-7133-912-9|edition=Second|location=|page=11.2|pages=}}</ref>}}\n{{term|term=[[Implicit function]]}}\n{{defn|defn=In [[mathematics]], an implicit equation is a [[relation (mathematics)|relation]]  of the form <math>R(x_1,\\ldots, x_n) = 0</math>, where <math>R</math> is a [[function (mathematics)|function]] of several variables (often a [[polynomial]]). For example, the implicit equation of the [[unit circle]] is <math> x^2 +y^2-1 = 0</math>.\n\nAn '''implicit function''' is a [[function (mathematics)|function]] that is defined implicitly by an implicit equation, by associating one of the variables (the [[value (mathematics)|value]]) with the others (the [[argument of a function|argument]]s).<ref name=Chiang>{{cite book |last=Chiang |first=Alpha C. |authorlink=Alpha Chiang |title=Fundamental Methods of Mathematical Economics |location=New York |publisher=McGraw-Hill |edition=Third |year=1984 |isbn=0-07-010813-7 |url=https://books.google.com/books?id=6gcoAQAAMAAJ }}</ref>{{rp|204–206}} Thus, an implicit function for <math>y</math> in the context of the [[unit circle]] is defined implicitly by <math> x^2 +f(x)^2-1 = 0</math>. This implicit equation defines <math>f</math> as a function of <math>x</math> only if <math>-1 \\leq x \\leq 1</math> and one considers only non-negative (or non-positive) values for the values of the function.\n\nThe [[implicit function theorem]] provides conditions under which some kinds of relations define an implicit function, namely relations defined as the [[indicator function]] of the [[zero set]] of some [[continuously differentiable]] [[Multivariable calculus|multivariate]] function.}}\n{{term|term=[[Improper fraction]]}}\n{{defn|defn=Common fractions can be classified as either proper or improper. When the numerator and the denominator are both positive, the fraction is called proper if the numerator is less than the denominator, and improper otherwise.<ref>{{cite web|url=http://www.worldwidewords.org/qa/qa-vul1.htm|title=World Wide Words: Vulgar fractions|work=World Wide Words|accessdate=2014-10-30}}</ref><ref>{{MathWorld |title=Improper Fraction |id=ImproperFraction}}</ref> In general, a common fraction is said to be a proper fraction if the [[absolute value]] of the fraction is strictly less than one—that is, if the fraction is greater than −1 and less than 1.<ref>{{cite web|url=http://mathforum.org/library/drmath/view/65128.html|title=Math Forum – Ask Dr. Math:Can Negative Fractions Also Be Proper or Improper?|author=Laurel|date=31 March 2004|publisher=|accessdate=2014-10-30}}</ref><ref>{{cite web|url=http://www.necompact.org/ea/gle_support/Math/resources_number/prop_fraction.htm|title=New England Compact Math Resources|publisher=}}</ref>\nIt is said to be an improper fraction, or sometimes top-heavy fraction,<ref>{{cite book|last1=Greer|first1=A.|title=New comprehensive mathematics for 'O' level|date=1986|publisher=Thornes|location=Cheltenham|isbn=978-0-85950-159-0|page=5|edition=2nd ed., reprinted.|url=https://books.google.com/books?id=wX2dxeDahAwC&pg=PA5|accessdate=2014-07-29}}</ref> if the absolute value of the fraction is greater than or equal to 1. Examples of proper fractions are 2/3, –3/4, and 4/9; examples of improper fractions are 9/4, –4/3, and 3/3.}}\n{{term|term=[[Improper integral]]}}\n{{defn|defn=In [[mathematical analysis]], an improper integral is the [[limit (mathematics)|limit]] of a [[definite integral]] as an endpoint of the interval(s) of integration approaches either a specified [[real number]], <math>\\infty</math>, <math>-\\infty</math>, or in some instances as both endpoints approach limits. Such an integral is often written symbolically just like a standard definite integral, in some cases with ''infinity'' as a limit of integration.\n\nSpecifically, an improper integral is a limit of the form:\n:<math>\\lim_{b\\to\\infty} \\int_a^bf(x)\\, dx, \\qquad \\lim_{a\\to -\\infty} \\int_a^bf(x)\\, dx,</math>\nor\n:<math>\\lim_{c\\to b^-} \\int_a^cf(x)\\, dx,\\quad\n\\lim_{c\\to a^+} \\int_c^bf(x)\\, dx,</math>\nin which one takes a limit in one or the other (or sometimes both) endpoints {{harv|Apostol|1967|loc=§10.23}}.}}\n{{term|term=[[Inflection point]]}} \n{{defn|defn= In [[differential calculus]], an '''inflection point''', '''point of inflection''', '''flex''', or '''inflection''' (British English: '''inflexion''') is a point on a [[Continuous function|continuous]] [[plane curve]] at which the curve changes from being [[Concave function|concave]] (concave downward) to [[convex function|convex]] (concave upward), or vice versa.}}\n{{term|term=[[Derivative|Instantaneous rate of change]]}}\n{{defn|defn= .}}\n{{term|term=[[Velocity#Instantaneous velocity|Instantaneous velocity]]}}\n{{defn|defn= .}}\n{{term|term=[[Integral]]}}\n{{defn|defn= .}}\n{{term|term=[[Integral symbol]]}}\n{{defn|defn= .}}\n{{term|term=[[Integrand]]}} \n{{defn|defn= The function to be integrated in an integral.}}\n{{term|term=[[Integration by parts]]}}\n{{defn|defn= .}}\n{{term|term=[[Integration by substitution]]}}\n{{defn|defn= .}}\n{{term|term=[[Intermediate value theorem]]}}\n{{defn|defn= .}}\n{{term|term=[[Inverse trigonometric functions]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n\n==J==\n{{glossary}}\n\n\n{{term|term=[[Classification of discontinuities#Jump discontinuity|Jump discontinuity]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==K==\n\n{{glossary}}\n\n{{glossary end}}\n==L==\n\n{{glossary}}\n\n{{term|term=[[Law of cosines]]}}\n{{defn|defn= .}}\n{{term|term=[[Law of sines]]}}\n{{defn|defn= .}}\n{{term|term=[[Lebesgue integration]]}}\n{{defn|defn= In mathematics, the [[integral]] of a non-negative [[Function (mathematics)|function]] of a single variable can be regarded, in the simplest case, as the [[area]] between the [[Graph of a function|graph]] of that function and the {{math|''x''}}-axis. The '''Lebesgue integral''' extends the integral to a larger class of functions. It also extends the [[Domain (mathematics)|domain]]s on which these functions can be defined.}}\n{{term|term=[[L'Hôpital's rule]]}}\n{{defn|defn= '''L'Hôpital's rule''' or '''L'Hospital's rule'''  uses [[derivative]]s to help evaluate [[limit of a function|limits]] involving [[indeterminate form]]s.  Application (or repeated application) of the rule often converts an indeterminate form to an expression that can be evaluated by substitution, allowing easier evaluation of the limit. The rule is named after the 17th-century [[France|French]] [[mathematician]] [[Guillaume de l'Hôpital]]. Although the contribution of the rule is often attributed to L'Hôpital, the theorem was first introduced to L'Hôpital in 1694 by the Swiss mathematician [[Johann Bernoulli]].\n\nL'Hôpital's rule states that for functions {{math|{{var|f}}}} and {{math|{{var|g}}}} which are [[Differentiable function|differentiable]] on an open [[Interval (mathematics)|interval]] {{math|{{var|I}}}} except possibly at a point {{math|{{var|c}}}} contained in {{math|{{var|I}}}}, if\n<math>\\lim_{x\\to c}f(x)=\\lim_{x\\to c}g(x)=0 \\text{ or } \\pm\\infty,</math> <math>g'(x)\\ne 0</math> for all {{math|{{var|x}}}} in {{math|{{var|I}}}} with {{math|1={{var|x}} ≠ {{var|c}}}}, and <math>\\lim_{x\\to c}\\frac{f'(x)}{g'(x)}</math> exists, then\n:<math>\\lim_{x\\to c}\\frac{f(x)}{g(x)} = \\lim_{x\\to c}\\frac{f'(x)}{g'(x)}.</math>\n\nThe differentiation of the numerator and denominator often simplifies the quotient or converts it to a limit that can be evaluated directly.}}\n{{term|term=[[Limit comparison test]]}}\n{{defn|defn= .}}\n{{term|term=[[Limit of a function]]}}\n{{defn|defn= .}}\n{{term|term=[[Limits of integration]]}}\n{{defn|defn= .}}\n{{term|term=[[Linear combination]]}}\n{{defn|defn= .}}\n{{term|term=[[Linear equation]]}}\n{{defn|defn= .}}\n{{term|term=[[Linear system]]}}\n{{defn|defn= .}}\n{{term|term=[[List of integrals]]}}\n{{defn|defn= .}}\n{{term|term=[[Logarithm]]}}\n{{defn|defn= .}}\n{{term|term=[[Logarithmic differentiation]]}}\n{{defn|defn= .}}\n{{term|term=[[Upper and lower bounds#Bounds of functions|Lower bound]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n\n==M==\n\n{{glossary}}\n\n\n{{term|term=[[Mean value theorem]]}}\n{{defn|defn= .}}\n{{term|term=[[Monotonic function#Monotonicity in calculus and analysis|Monotonic function]]}}\n{{defn|defn= .}}\n{{term|term=[[Multiple integral]]}}\n{{defn|defn= .}}\n{{term|term=[[Multiplicative calculus]]}}\n{{defn|defn= .}}\n{{term|term=[[Multivariable calculus]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n== N ==\n{{glossary}}\n\n{{term|term=[[Natural logarithm]]}}\n{{defn|defn= The '''natural logarithm''' of a number is its [[logarithm]] to the [[base (exponentiation)|base]] of the [[mathematical constant]] [[e (mathematical constant)|''e'']], where ''e'' is an [[Irrational number|irrational]] and [[Transcendental number|transcendental]] number approximately equal to {{val|2.718281828459}}. The natural logarithm of ''x'' is generally written as {{nowrap|ln ''x''}}, {{nowrap|log<sub>''e''</sub> ''x''}},  or sometimes, if the base ''e'' is implicit, simply {{nowrap|log ''x''}}.<ref>{{cite book |title=Mathematics for physical chemistry |edition=3rd |author-first=Robert G. |author-last=Mortimer |publisher=[[Academic Press]] |date=2005 |isbn=0-12-508347-5 |page=9 |url=https://books.google.com/books?id=nGoSv5tmATsC}} [https://books.google.com/books?id=nGoSv5tmATsC&pg=PA9 Extract of page 9]</ref> [[Parentheses]] are sometimes added for clarity, giving ln(''x''), log<sub>''e''</sub>(''x'') or log(''x''). This is done in particular when the argument to the logarithm is not a single symbol, to prevent ambiguity.}}\n{{term|term=[[Multiplicative calculus#History|Non-Newtonian calculus]]}}\n{{defn|defn= .}}\n{{term|term=[[Nonstandard calculus]]}}\n{{defn|defn= .}}\n{{term|term=[[Notation for differentiation]]}}\n{{defn|defn= .}}\n{{term|term=[[Numerical integration]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==O==\n{{glossary}}\n\n\n{{term|term=[[One-sided limit]]}}\n{{defn|defn= .}}\n{{term|term=[[Ordinary differential equation]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==P==\n{{glossary}}\n\n{{term|term=[[Pappus's centroid theorem]]}}\n{{defn|defn= (Also known as  the '''Guldinus theorem''', '''Pappus–Guldinus theorem''' or '''Pappus's theorem''') is either of two related [[theorem]]s dealing with the [[surface area]]s and [[volume]]s of [[surface of revolution|surface]]s and [[solid of revolution|solid]]s of revolution.}}\n{{term|term=[[Parabola]]}}\n{{defn|defn= Is a [[plane curve]] that is [[Reflection symmetry|mirror-symmetrical]] and is approximately U-[[shape]]d. It fits several superficially different other [[Mathematics|mathematical]] descriptions, which can all be proved to define exactly the same curves.}}\n{{term|term=[[Paraboloid]]}}\n{{defn|defn= .}}\n{{term|term=[[Partial derivative]]}}\n{{defn|defn= .}}\n{{term|term=[[Partial differential equation]]}}\n{{defn|defn= .}}\n{{term|term=[[Partial fraction decomposition]]}}\n{{defn|defn= .}}\n{{term|term=[[Particular solution]]}}\n{{defn|defn= .}}\n{{term|term=[[Piecewise|Piecewise-defined function]]}}\n{{defn|defn= A function defined by multiple sub-functions that apply to certain intervals of the function's domain.}}\n{{term|term=[[Position (vector)|Position vector]]}}\n{{defn|defn= .}}\n{{term|term=[[Power rule]]}}\n{{defn|defn= .}}\n{{term|term=[[Product integral]]}}\n{{defn|defn= .}}\n{{term|term=[[Product rule]]}}\n{{defn|defn= .}}\n{{term|term=[[Proper fraction]]}}\n{{defn|defn= .}}\n{{term|term=[[Proper rational function]]}}\n{{defn|defn= .}}\n{{term|term=[[Pythagorean theorem]]}}\n{{defn|defn= .}}\n{{term|term=[[Pythagorean trigonometric identity]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n\n==Q==\n{{glossary}}\n\n{{term|term=[[Quadratic function]]}}\n{{defn|defn= In [[algebra]], a '''quadratic function''', a '''quadratic polynomial''', a '''polynomial of degree 2''', or simply a '''quadratic''', is a [[polynomial function]] with one or more variables in which the highest-degree term is of the second degree. For example, a quadratic function in three variables ''x'', ''y,'' and ''z'' contains exclusively terms ''x''<sup>2</sup>, ''y''<sup>2</sup>, ''z''<sup>2</sup>, ''xy'', ''xz'', ''yz'', ''x'', ''y'', ''z'', and a constant:\n\n:<math>f(x,y,z)=ax^2+by^2+cz^2+dxy+exz+fyz+gx+hy+iz +j,</math>\n\nwith at least one of the [[coefficient]]s ''a, b, c, d, e,'' or ''f'' of the second-degree terms being non-zero.\n\nA ''univariate'' (single-variable) quadratic function has the form<ref name=\"wolfram\">{{cite web | url=http://mathworld.wolfram.com/QuadraticEquation.html | title=Quadratic Equation -- from Wolfram MathWorld | accessdate=January 6, 2013}}</ref>\n\n:<math>f(x)=ax^2+bx+c,\\quad a \\ne 0</math>\nin the single variable ''x''. The [[graph of a function|graph]] of a univariate quadratic function is a [[parabola]] whose axis of symmetry is parallel to the {{math|''y''}}-axis, as shown at right.\n\nIf the quadratic function is set equal to zero, then the result is a [[quadratic equation]]. The solutions to the univariate equation are called the [[root of a function|root]]s of the univariate function.\n\nThe bivariate case in terms of variables ''x'' and ''y'' has the form\n\n:<math> f(x,y) = a x^2 + by^2 + cx y+ d x+ ey + f \\,\\!</math>\n\nwith at least one of ''a, b, c'' not equal to zero, and an equation setting this function equal to zero gives rise to a [[conic section]] (a [[circle]] or other [[ellipse]], a [[parabola]], or a [[hyperbola]]).\n\nIn general there can be an arbitrarily large number of variables, in which case the resulting [[surface (geometry)|surface]] is called a [[quadric]], but the highest degree term must be of degree 2, such as ''x''<sup>2</sup>, ''xy'', ''yz'', etc.}}\n{{term|term=[[Quadratic polynomial]]}}\n{{defn|defn= .}}\n{{term|term=[[Quotient rule]]}}\n{{defn|defn= A formula for finding the derivative of a function that is the ratio of two functions.}}\n\n{{glossary end}}\n\n==R==\n{{glossary}}\n\n{{term|term=[[Radian]]}}\n{{defn|defn= .}}\n{{term|term=[[Ratio test]]}}\n{{defn|defn= .}}\n{{term|term=[[Reciprocal function]]}}\n{{defn|defn= .}}\n{{term|term=[[Reciprocal rule]]}}\n{{defn|defn= .}}\n{{term|term=[[Riemann integral]]}}\n{{defn|defn= .}}\n{{term|term=[[Related rates]]}}\n{{defn|defn= .}}\n{{term|term=[[Classification of discontinuities#Removable discontinuity|Removable discontinuity]]}}\n{{defn|defn= .}}\n{{term|term=[[Rolle's theorem]]}}\n{{defn|defn= .}}\n{{term|term=[[Root test]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==S==\n{{glossary}}\n\n{{term|term=[[Scalar (mathematics)|Scalar]]}}\n{{defn|defn= .}}\n{{term|term=[[Secant line]]}}\n{{defn|defn= .}}\n{{term|term=[[Second-degree polynomial]]}}\n{{defn|defn= .}}\n{{term|term=[[Second derivative]]}}\n{{defn|defn= .}}\n{{term|term=[[Second derivative#Second derivative test|Second derivative test]]}}\n{{defn|defn= .}}\n{{term|term=[[Differential equation#Equation order|Second-order differential equation]]}}\n{{defn|defn= .}}\n{{term|term=[[Series (mathematics)|Series]]}}\n{{defn|defn= .}}\n{{term|term=[[Shell integration]]}}\n{{defn|defn= .}}\n{{term|term=[[Simpson's rule]]}}\n{{defn|defn= .}}\n{{term|term=[[Sine]]}}\n{{defn|defn= .}}\n{{term|term=[[Sine wave]]}}\n{{defn|defn= .}}\n{{term|term=[[Slope field]]}}\n{{defn|defn= .}}\n{{term|term=[[Squeeze theorem]]}}\n{{defn|defn= .}}\n{{term|term=[[Sum rule in differentiation]]}}\n{{defn|defn= .}}\n{{term|term=[[Sum rule in integration]]}}\n{{defn|defn= .}}\n{{term|term=[[Summation]]}}\n{{defn|defn= .}}\n{{term|term=[[Supplementary angle]]}}\n{{defn|defn= .}}\n{{term|term=[[Surface area]]}}\n{{defn|defn= .}}\n{{term|term=[[System of linear equations]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==T==\n{{glossary}}\n\n{{term|term=[[List of integrals|Table of integrals]]}}\n{{defn|defn= .}}\n{{term|term=[[Taylor series]]}}\n{{defn|defn= .}}\n{{term|term=[[Taylor's theorem]]}}\n{{defn|defn= .}}\n{{term|term=[[Tangent]]}}\n{{defn|defn= .}}\n{{term|term=[[Degree of a polynomial|Third-degree polynomial]]}}\n{{defn|defn= .}}\n{{term|term=[[Third derivative]]}}\n{{defn|defn= .}}\n{{term|term=[[Toroid]]}}\n{{defn|defn= .}}\n{{term|term=[[Total differential]]}}\n{{defn|defn= .}}\n{{term|term=[[Trigonometric functions]]}}\n{{defn|defn= .}}\n{{term|term=[[List of trigonometric identities|Trigonometric identities]]}}\n{{defn|defn= .}}\n{{term|term=[[Trigonometric integral]]}}\n{{defn|defn= .}}\n{{term|term=[[Trigonometric substitution]]}}\n{{defn|defn= .}}\n{{term|term=[[Trigonometry]]}}\n{{defn|defn= .}}\n{{term|term=[[Triple integral]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==U==\n{{glossary}}\n\n{{term|term=[[Upper and lower bounds#Bounds of functions|Upper bound]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==V==\n{{glossary}}\n\n{{term|term=[[Variable (mathematics)|Variable]]}}\n{{defn|defn= .}}\n{{term|term=[[Vector (mathematics and physics)|Vector]]}}\n{{defn|defn= .}}\n{{term|term=[[Vector calculus]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==W==\n{{glossary}}\n\n{{term|term=[[Disc integration#Washer method|Washer]]}}\n{{defn|defn= .}}\n{{term|term=[[Disc integration#Washer method|Washer method]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n==X==\n{{glossary}}\n\n{{glossary end}}\n==Y==\n{{glossary}}\n\n{{glossary end}}\n==Z==\n{{glossary}}\n\n{{term|term=[[Zero vector]]}}\n{{defn|defn= .}}\n\n{{glossary end}}\n== See also ==\n*'''[[Calculus]]'''\n*'''[[Outline of calculus]]'''\n*'''[[Glossary of areas of mathematics]]'''\n*'''[[Glossary of astronomy]]'''\n*'''[[Glossary of biology]]'''\n*'''[[Glossary of botanical terms|Glossary of botany]]'''\n*'''[[Glossary of chemistry terms|Glossary of chemistry]]'''\n*'''[[Glossary of ecology]]'''\n*'''[[Glossary of engineering]]'''\n*'''[[Glossary of physics]]'''\n*'''[[Glossary of probability and statistics]]'''\n\n==References==\n<references />\n\n==Notes==\n\n{{reflist|group=note}}\n{{reflist|group=Note}}\n{{reflist|group=lower-alpha}}\n\n{{Glossaries of science and engineering}}\n{{Integral}}\n{{Infinitesimals}}\n{{Calculus topics}}\n[[Category:Fields of mathematics|* ]]\n[[Category:Glossaries of mathematics|C]]\n[[Category:Wikipedia glossaries|Calculus]]"
    },
    {
      "title": "Algebraic geometry",
      "url": "https://en.wikipedia.org/wiki/Algebraic_geometry",
      "text": "{{short description|Branch of mathematics}}\n{{distinguish|text=[[Geometric algebra]], an application of Clifford algebra to geometry}}\n{{about||the book by Robin Hartshorne|Algebraic Geometry (book)|the journal|Algebraic Geometry (journal)}}\n{{more footnotes|date=August 2016}}\n[[File:Togliatti surface.png|thumb|This [[Togliatti surface]] is an [[algebraic surface]] of degree five. The picture represents a portion of its real [[locus (mathematics)|locus]].]]\n{{General geometry |branches}}\n\n'''Algebraic geometry''' is a branch of [[mathematics]], classically studying [[zero of a function|zeros]] of [[multivariate polynomial]]s. Modern algebraic geometry is based on the use of abstract algebraic techniques, mainly from [[commutative algebra]], for solving  [[geometry|geometrical problems]] about these sets of zeros.\n\nThe fundamental objects of study in algebraic geometry are [[algebraic variety|algebraic varieties]], which are geometric manifestations of [[solution set|solutions]] of [[systems of polynomial equations]]. Examples of the most studied classes of algebraic varieties are: [[plane algebraic curve]]s, which include [[line (geometry)|lines]], [[circle]]s, [[parabola]]s, [[ellipse]]s, [[hyperbola]]s, [[cubic curve]]s like [[elliptic curve]]s, and quartic curves like [[lemniscate of Bernoulli|lemniscate]]s and [[Cassini oval]]s. A point of the plane belongs to an algebraic curve if its coordinates satisfy a given [[polynomial equation]]. Basic questions involve the study of the points of special interest like the [[singular point of a curve|singular point]]s, the [[inflection point]]s and the [[point at infinity|points at infinity]]. More advanced questions involve the [[topology]] of the curve and relations between the curves given by different equations.\n\nAlgebraic geometry occupies a central place in modern mathematics and has multiple conceptual connections with such diverse fields as [[complex analysis]], [[topology]] and [[number theory]]. Initially a study of [[systems of polynomial equations]] in several variables, the subject of algebraic geometry starts where [[equation solving]] leaves off, and it becomes even more important to understand the intrinsic properties of the totality of solutions of a system of equations, than to find a specific solution; this leads into some of the deepest areas in all of mathematics, both conceptually and in terms of technique.\n<!-- this paragraph is misplaced in the lead. May be in the history section?\n\n[[Descartes]]'s idea of [[coordinates]] is central to algebraic geometry, because a '''point''' of an algebraic variety is a point whose coordinates are a solution of the equations defining the variety. However it has undergone a series of remarkable transformations beginning in the early 19th century. Before then, the coordinates were assumed to be [[tuple]]s of [[real number]]s, but this changed when first [[complex number]]s, and then elements of an arbitrary [[field (mathematics)|field]] became acceptable. [[Homogeneous coordinates]] of [[projective geometry]] offered an extension of the notion of coordinate system in a different direction, and enriched the scope of algebraic geometry. -->\n\nIn the 20th century, algebraic geometry split into several subareas.\n* The mainstream of algebraic geometry is devoted to the study of the complex points of the algebraic varieties and more generally to the points with coordinates in an [[algebraically closed field]].\n* [[Real algebraic geometry]] is the study of the real points of an algebraic variety.\n* [[Diophantine geometry]] and, more generally, [[arithmetic geometry]] is the study of the points of an algebraic variety with coordinates in [[field (mathematics)|field]]s that are not [[algebraically closed]] and occur in [[algebraic number theory]], such as the field of [[rational number]]s, [[number field]]s, [[finite field]]s, [[Algebraic function field|function fields]], and [[p-adic number|''p''-adic field]]s.\n* A large part of [[Singularity theory#Singularities in algebraic geometry|singularity theory]] is devoted to the singularities of algebraic varieties.\n* [[#Computational algebraic geometry|Computational algebraic geometry]] is an area that has emerged at the intersection of algebraic geometry and [[computer algebra]], with the rise of computers. It consists mainly of [[algorithm]] design and [[software]] development for the study of properties of explicitly given algebraic varieties.\n\nMuch of the development of the mainstream of algebraic geometry in the 20th century occurred within an abstract algebraic framework, with increasing emphasis being placed on \"intrinsic\" properties of algebraic varieties not dependent on any particular way of embedding the variety in an ambient coordinate space; this parallels developments in [[topology]], [[differential geometry|differential]] and [[complex geometry]]. One key achievement of this abstract algebraic geometry is [[Grothendieck]]'s [[scheme theory]] which allows one to use [[sheaf theory]] to study algebraic varieties in a way which is very similar to its use in the study of [[differential manifold|differential]] and [[complex manifold|analytic manifolds]]. This is obtained by extending the notion of point: In classical algebraic geometry, a point of an affine variety may be identified, through [[Hilbert's Nullstellensatz]], with a [[maximal ideal]] of the [[coordinate ring]], while the points of the corresponding affine scheme are all prime ideals of this ring. This means that a point of such a scheme may be either a usual point or a subvariety. This approach also enables a unification of the language and the tools of classical algebraic geometry, mainly concerned with complex points, and of algebraic number theory. [[Wiles's proof of Fermat's Last Theorem|Wiles' proof]] of the longstanding conjecture called [[Fermat's last theorem]] is an example of the power of this approach.\n\n==Basic notions==\n{{Further|Algebraic variety}}\n\n=== Zeros of simultaneous polynomials ===\n[[File:Slanted circle.png|thumb|right|Sphere and slanted circle]]\nIn classical algebraic geometry, the main objects of interest are the vanishing sets of collections of [[polynomial]]s, meaning the set of all points that simultaneously satisfy one or more [[systems of polynomial equations|polynomial equations]]. For instance, the [[N-sphere|two-dimensional]] [[sphere]] of radius 1 in three-dimensional [[Euclidean space]] '''R'''<sup>3</sup> could be defined as the set of all points (''x'',''y'',''z'') with\n\n:<math>x^2+y^2+z^2-1=0.\\,</math>\n\nA \"slanted\" circle in '''R'''<sup>3</sup> can be defined as the set of all points (''x'',''y'',''z'') which satisfy the two polynomial equations\n\n:<math>x^2+y^2+z^2-1=0,\\,</math>\n:<math>x+y+z=0.\\,</math>\n\n=== Affine varieties ===\n{{main|Affine variety}}\n\nFirst we start with a [[field (mathematics)|field]] ''k''. In classical algebraic geometry, this field was always the complex numbers '''C''', but many of the same results are true if we assume only that ''k'' is [[algebraically closed field|algebraically closed]]. We consider the [[affine space]] of dimension ''n'' over ''k'', denoted '''A'''<sup>n</sup>(''k'') (or more simply '''A'''<sup>''n''</sup>, when ''k'' is clear from the context). When one fixes a coordinate system, one may identify '''A'''<sup>n</sup>(''k'') with ''k''<sup>''n''</sup>. The purpose of not working with ''k''<sup>''n''</sup> is to emphasize that one \"forgets\" the vector space structure that ''k''<sup>n</sup> carries.\n\nA function ''f'' : '''A'''<sup>''n''</sup> → '''A'''<sup>1</sup> is said to be ''polynomial'' (or ''regular'') if it can be written as a polynomial, that is, if there is a polynomial ''p'' in ''k''[''x''<sub>1</sub>,...,''x''<sub>''n''</sub>] such that ''f''(''M'') = ''p''(''t''<sub>1</sub>,...,''t''<sub>''n''</sub>) for every point ''M'' with coordinates (''t''<sub>1</sub>,...,''t''<sub>''n''</sub>) in '''A'''<sup>''n''</sup>. The property of a function to be polynomial (or regular) does not depend on the choice of a coordinate system in '''A'''<sup>''n''</sup>.\n\nWhen a coordinate system is chosen, the regular functions on the affine ''n''-space may be identified with the ring of [[polynomial function]]s in ''n'' variables over ''k''. Therefore, the set of the regular functions on '''A'''<sup>''n''</sup> is a ring, which is denoted ''k''['''A'''<sup>''n''</sup>].\n\nWe say that a polynomial ''vanishes'' at a point if evaluating it at that point gives zero. Let ''S'' be a set of polynomials in ''k''['''A'''<sup>n</sup>]. The ''vanishing set of S'' (or ''vanishing locus'' or ''zero set'') is the set ''V''(''S'') of all points in '''A'''<sup>''n''</sup> where every polynomial in ''S'' vanishes. Symbolically,\n\n:<math>V(S) = \\{(t_1,\\dots,t_n) \\mid p(t_1,\\dots,t_n) = 0 \\text{ for all } p \\in S\\}.\\,</math>\n\nA subset of '''A'''<sup>''n''</sup> which is ''V''(''S''), for some ''S'', is called an ''algebraic set''. The ''V'' stands for ''variety'' (a specific type of algebraic set to be defined below).\n\nGiven a subset ''U'' of '''A'''<sup>''n''</sup>, can one recover the set of polynomials which generate it? If ''U'' is ''any'' subset of '''A'''<sup>''n''</sup>, define ''I''(''U'') to be the set of all polynomials whose vanishing set contains ''U''. The ''I'' stands for [[ideal (ring theory)|ideal]]: if two polynomials ''f'' and ''g'' both vanish on ''U'', then ''f''+''g'' vanishes on ''U'', and if ''h'' is any polynomial, then ''hf'' vanishes on ''U'', so ''I''(''U'') is always an ideal of the polynomial ring ''k''['''A'''<sup>''n''</sup>].\n\nTwo natural questions to ask are:\n* Given a subset ''U'' of '''A'''<sup>''n''</sup>, when is ''U'' = ''V''(''I''(''U''))?\n* Given a set ''S'' of polynomials, when is ''S'' = ''I''(''V''(''S''))?\n\nThe answer to the first question is provided by introducing the [[Zariski topology]], a topology on '''A'''<sup>''n''</sup> whose closed sets are the algebraic sets, and which directly reflects the algebraic structure of ''k''['''A'''<sup>''n''</sup>]. Then ''U'' = ''V''(''I''(''U'')) if and only if ''U'' is an algebraic set or equivalently a Zariski-closed set. The answer to the second question is given by [[Hilbert's Nullstellensatz]]. In one of its forms, it says that ''I''(''V''(''S'')) is the [[radical of an ideal|radical]] of the ideal generated by ''S''. In more abstract language, there is a [[Galois connection]], giving rise to two [[closure operator]]s; they can be identified, and naturally play a basic role in the theory; the [[Galois connection#Examples|example]] is elaborated at Galois connection.\n\nFor various reasons we may not always want to work with the entire ideal corresponding to an algebraic set ''U''. [[Hilbert's basis theorem]] implies that ideals in ''k''['''A'''<sup>''n''</sup>] are always finitely generated.\n\nAn algebraic set is called ''[[irreducible component|irreducible]]'' if it cannot be written as the union of two smaller algebraic sets. Any algebraic set is a finite union of irreducible algebraic sets and this decomposition is unique. Thus its elements are called the ''irreducible components'' of the algebraic set. An irreducible algebraic set is also called a ''[[algebraic variety|variety]]''. It turns out that an algebraic set is a variety if and only if it may be defined as the vanishing set of a [[prime ideal]] of the polynomial ring.\n\nSome authors do not make a clear distinction between algebraic sets and varieties and use ''irreducible variety'' to make the distinction when needed.\n\n=== Regular functions ===\n{{main|Regular function}}\n\nJust as [[continuous function]]s are the natural maps on [[topological space]]s and [[smooth function]]s are the natural maps on [[differentiable manifold]]s, there is a natural class of functions on an algebraic set, called ''regular functions'' or ''polynomial functions''. A regular function on an algebraic set ''V'' contained in '''A'''<sup>''n''</sup> is the restriction to ''V'' of a regular function on '''A'''<sup>''n''</sup>. For an algebraic set defined on the field of the complex numbers, the regular functions are smooth and even [[analytic function|analytic]].\n\nIt may seem unnaturally restrictive to require that a regular function always extend to the ambient space, but it is very similar to the situation in a [[normal space|normal]] [[topological space]], where the [[Tietze extension theorem]] guarantees that a continuous function on a closed subset always extends to the ambient topological space.\n\nJust as with the regular functions on affine space, the regular functions on ''V'' form a ring, which we denote by ''k''[''V'']. This ring is called the ''[[coordinate ring]] of V''.\n\nSince regular functions on V come from regular functions on '''A'''<sup>''n''</sup>, there is a relationship between the coordinate rings. Specifically, if a regular function on ''V'' is the restriction of two functions ''f'' and ''g'' in ''k''['''A'''<sup>''n''</sup>], then ''f''&nbsp;&minus;&nbsp;''g'' is a polynomial function which is null on ''V'' and thus belongs to ''I''(''V''). Thus ''k''[''V''] may be identified with ''k''['''A'''<sup>''n''</sup>]/''I''(''V'').\n\n=== Morphism of affine varieties ===\nUsing regular functions from an affine variety to '''A'''<sup>1</sup>, we can define [[morphism of algebraic varieties|regular map]]s from one affine variety to another. First we will define a regular map from a variety into affine space: Let ''V'' be a variety contained in '''A'''<sup>''n''</sup>. Choose ''m'' regular functions on ''V'', and call them ''f''<sub>1</sub>, ..., ''f''<sub>''m''</sub>. We define a ''regular map'' ''f'' from ''V'' to '''A'''<sup>''m''</sup> by letting {{nowrap|1=''f'' = (''f''<sub>1</sub>, ..., ''f''<sub>''m''</sub>)}}. In other words, each ''f''<sub>''i''</sub> determines one coordinate of the [[image (mathematics)|range]] of ''f''.\n\nIf ''V''′ is a variety contained in '''A'''<sup>''m''</sup>, we say that ''f'' is a ''regular map'' from ''V'' to ''V''′ if the range of ''f'' is contained in ''V''′.\n\nThe definition of the regular maps apply also to algebraic sets.\nThe regular maps are also called ''morphisms'', as they make the collection of all affine algebraic sets into a [[category theory|category]], where the objects are the affine algebraic sets and the [[morphism]]s are the regular maps. The affine varieties is a subcategory of the category of the algebraic sets.\n\nGiven a regular map ''g'' from ''V'' to ''V''′ and a regular function ''f'' of ''k''[''V''′], then {{nowrap|''f'' ∘ ''g'' ∈ ''k''[''V'']}}. The map {{nowrap|''f'' → ''f'' ∘ ''g''}} is a [[ring homomorphism]] from ''k''[''V''′] to ''k''[''V'']. Conversely, every ring homomorphism from ''k''[''V''′] to ''k''[''V''] defines a regular map from ''V'' to ''V''′. This defines an [[equivalence of categories]] between the category of algebraic sets and the [[dual (category theory)|opposite category]] of the finitely generated [[reduced ring|reduced]] ''k''-algebras. This equivalence is one of the starting points of [[scheme theory]].\n\n=== Rational function and birational equivalence ===\n{{main|Rational mapping}}\nIn contrast to the preceding sections, this section concerns only varieties and not algebraic sets. On the other hand, the definitions extend naturally to projective varieties (next section), as an affine variety and its projective completion have the same field of functions.\n\nIf ''V'' is an affine variety, its coordinate ring is an [[integral domain]] and has thus a [[field of fractions]] which is denoted ''k''(''V'') and called the ''field of the rational functions'' on ''V'' or, shortly, the ''[[function field of an algebraic variety|function field]]'' of ''V''. Its elements are the restrictions to ''V'' of the [[rational function]]s over the affine space containing ''V''. The [[domain of a function|domain]] of a rational function ''f'' is not ''V'' but the [[complement (set theory)|complement]] of the subvariety (a hypersurface) where the denominator of ''f'' vanishes.\n\nAs with regular maps, one may define a ''rational map'' from a variety ''V'' to a variety ''V''<nowiki>'</nowiki>. As with the regular maps, the rational maps from ''V'' to ''V''<nowiki>'</nowiki> may be identified to the [[ring homomorphism|field homomorphism]]s from ''k''(''V''<nowiki>'</nowiki>) to ''k''(''V'').\n\nTwo affine varieties are ''birationally equivalent'' if there are two rational functions between them which are [[function inverse|inverse]] one to the other in the regions where both are defined. Equivalently, they are birationally equivalent if their function fields are isomorphic.\n\nAn affine variety is a ''[[rational variety]]'' if it is birationally equivalent to an affine space. This means that the variety admits a rational parameterization. For example, the circle of equation <math>x^2+y^2-1=0</math> is a rational curve, as it has the parameterization\n:<math>x=\\frac{2\\,t}{1+t^2}</math>\n:<math>y=\\frac{1-t^2}{1+t^2}\\,,</math>\nwhich may also be viewed as a rational map from the line to the circle.\n\nThe problem of [[resolution of singularities]] is to know if every algebraic variety is birationally equivalent to a variety whose projective completion is nonsingular (see also [[smooth completion]]). It was solved in the affirmative in characteristic 0 by [[Heisuke Hironaka]] in 1964 and is yet unsolved in finite characteristic.\n\n=== Projective variety ===\n{{Main|Algebraic geometry of projective spaces}}\n\n[[File:Parabola & cubic curve in projective space.png|thumb|Parabola ({{nowrap|1=''y'' = ''x''<sup>2</sup>}}, red) and cubic ({{nowrap|1=''y'' = ''x''<sup>3</sup>}}, blue) in projective space]]\nJust as the formulas for the roots of second, third, and fourth degree polynomials suggest extending real numbers to the more algebraically complete setting of the complex numbers, many properties of algebraic varieties suggest extending affine space to a more geometrically complete projective space. Whereas the complex numbers are obtained by adding the number ''i'', a root of the polynomial {{nowrap|''x''<sup>2</sup> + 1}}, projective space is obtained by adding in appropriate points \"at infinity\", points where parallel lines may meet.\n\nTo see how this might come about, consider the variety {{nowrap|''V''(''y'' &minus; ''x''<sup>2</sup>)}}. If we draw it, we get a [[parabola]]. As ''x'' goes to positive infinity, the slope of the line from the origin to the point (''x'',&nbsp;''x''<sup>2</sup>) also goes to positive infinity. As ''x'' goes to negative infinity, the slope of the same line goes to negative infinity.\n\nCompare this to the variety ''V''(''y''&nbsp;&minus;&nbsp;''x''<sup>3</sup>). This is a [[cubic curve]]. As ''x'' goes to positive infinity, the slope of the line from the origin to the point (''x'',&nbsp;''x''<sup>3</sup>) goes to positive infinity just as before. But unlike before, as ''x'' goes to negative infinity, the slope of the same line goes to positive infinity as well; the exact opposite of the parabola. So the behavior \"at infinity\" of ''V''(''y''&nbsp;&minus;&nbsp;''x''<sup>3</sup>) is different from the behavior \"at infinity\" of ''V''(''y''&nbsp;&minus;&nbsp;''x''<sup>2</sup>).\n\nThe consideration of the ''projective completion'' of the two curves, which is their prolongation \"at infinity\" in the [[projective plane]], allows us to quantify this difference: the point at infinity of the parabola is a [[regular point of an algebraic variety|regular point]], whose tangent is the [[line at infinity]], while the point at infinity of the cubic curve is a [[cusp (singularity)|cusp]]. Also, both curves are rational, as they are parameterized by ''x'', and the [[Riemann-Roch theorem for algebraic curves|Riemann-Roch theorem]] implies that the cubic curve must have a singularity, which must be at infinity, as all its points in the affine space are regular.\n\nThus many of the properties of algebraic varieties, including birational equivalence and all the topological properties, depend on the behavior \"at infinity\" and so it is natural to study the varieties in projective space. Furthermore, the introduction of projective techniques made many theorems in algebraic geometry simpler and sharper: For example, [[Bézout's theorem]] on the number of intersection points between two varieties can be stated in its sharpest form only in projective space. For these reasons, projective space plays a fundamental role in algebraic geometry.\n\nNowadays, the ''[[projective space]]'' '''P'''<sup>''n''</sup> of dimension ''n'' is usually defined as the set of the lines passing through a point, considered as the origin, in the affine space of dimension {{nowrap|''n'' + 1}}, or equivalently to the set of the vector lines in a vector space of dimension {{nowrap|''n'' + 1}}. When a coordinate system has been chosen in the space of dimension {{nowrap|''n'' + 1}}, all the points of a line have the same set of coordinates, up to the multiplication by an element of ''k''. This defines the [[homogeneous coordinates]] of a point of '''P'''<sup>''n''</sup> as a sequence of {{nowrap|''n'' + 1}} elements of the base field ''k'', defined up to the multiplication by a nonzero element of ''k'' (the same for the whole sequence).\n\nA polynomial in {{nowrap|''n'' + 1}} variables vanishes at all points of a line passing through the origin if and only if it is [[Homogeneous polynomial|homogeneous]]. In this case, one says that the polynomial ''vanishes'' at the corresponding point of '''P'''<sup>''n''</sup>. This allows us to define a ''projective algebraic set'' in '''P'''<sup>''n''</sup> as the set {{nowrap|''V''(''f''<sub>1</sub>, ..., ''f''<sub>''k''</sub>)}}, where a finite set of homogeneous polynomials {{nowrap|{''f''<sub>1</sub>, ..., ''f''<sub>''k''</sub>} }} vanishes. Like for affine algebraic sets, there is a bijection between the projective algebraic sets and the reduced [[homogeneous ideal]]s which define them. The ''projective varieties'' are the projective algebraic sets whose defining ideal is prime. In other words, a projective variety is a projective algebraic set, whose [[homogeneous coordinate ring]] is an [[integral domain]], the ''projective coordinates ring'' being defined as the quotient of the graded ring or the polynomials in {{nowrap|''n'' + 1}} variables by the homogeneous (reduced) ideal defining the variety. Every projective algebraic set may be uniquely decomposed into a finite union of projective varieties.\n\nThe only regular functions which may be defined properly on a projective variety are the constant functions. Thus this notion is not used in projective situations. On the other hand, the ''field of the rational functions'' or ''function field '' is a useful notion, which, similarly to the affine case, is defined as the set of the quotients of two homogeneous elements of the same degree in the homogeneous coordinate ring.\n\n==Real algebraic geometry==\n{{main|Real algebraic geometry}}\n\nReal algebraic geometry is the study of the real points of algebraic varieties.\n\nThe fact that the field of the real numbers is an [[ordered field]] cannot be ignored in such a study. For example, the curve of equation <math>x^2+y^2-a=0</math> is a circle if <math> a>0</math>, but does not have any real point if <math> a<0</math>. It follows that real algebraic geometry is not only the study of the real algebraic varieties, but has been generalized to the study of the ''semi-algebraic sets'', which are the solutions of systems of polynomial equations and polynomial inequalities. For example, a branch of the [[hyperbola]] of equation <math>x y-1 = 0</math> is not an algebraic variety, but is a semi-algebraic set defined by <math>x y-1=0</math> and <math>x>0</math> or by <math>x y-1=0</math> and <math>x+y>0</math>.\n\nOne of the challenging problems of real algebraic geometry is the unsolved [[Hilbert's sixteenth problem]]: Decide which respective positions are possible for the ovals of a nonsingular [[plane curve]] of degree 8.\n\n== Computational algebraic geometry ==\nOne may date the origin of computational algebraic geometry to meeting EUROSAM'79 (International Symposium on Symbolic and Algebraic Manipulation) held at [[Marseille]], France in June 1979. At this meeting,\n* Dennis S. Arnon showed that [[George E. Collins]]'s [[Cylindrical algebraic decomposition]] (CAD) allows the computation of the topology of semi-algebraic sets,\n* [[Bruno Buchberger]] presented the [[Gröbner basis|Gröbner bases]] and his algorithm to compute them,\n* [[Daniel Lazard]] presented a new algorithm for solving systems of homogeneous polynomial equations with a [[computational complexity]] which is essentially polynomial in the expected number of solutions and thus simply exponential in the number of the unknowns. This algorithm is strongly related with [[Francis Sowerby Macaulay|Macaulay]]'s [[Resultant|multivariate resultant]].\n\nSince then, most results in this area are related to one or several of these items either by using or improving one of these algorithms, or by finding algorithms whose complexity is simply exponential in the number of the variables.\n\nA body of mathematical theory complementary to symbolic methods called [[numerical algebraic geometry]] has been developed over the last several decades.  The main computational method is [[homotopy continuation]].  This supports, for example, a model of [[floating point]] computation for solving problems of algebraic geometry.\n\n===Gröbner basis===\n\n{{main|Gröbner basis}}\n\nA [[Gröbner basis]] is a system of [[Ideal (ring theory)#Definitions_and_motivation|generators]] of a polynomial [[ideal (ring theory)|ideal]] whose computation allows the deduction of many properties of the affine algebraic variety defined by the ideal.\n\nGiven an ideal ''I'' defining an algebraic set ''V'':\n* ''V'' is empty (over an algebraically closed extension of the basis field), if and only if the Gröbner basis for any [[monomial order]]ing is reduced to {1}.\n* By means of the [[Hilbert series]] one may compute the [[dimension of an algebraic variety|dimension]] and the [[degree of an algebraic variety|degree]] of ''V'' from any Gröbner basis of ''I'' for a monomial ordering refining the total degree.\n* If the dimension of ''V'' is 0, one may compute the points (finite in number) of ''V'' from any Gröbner basis of ''I'' (see [[Systems of polynomial equations]]).\n* A Gröbner basis computation allows one to remove from ''V'' all irreducible components which are contained in a given hypersurface.\n* A Gröbner basis computation allows one to compute the Zariski closure of the image of ''V'' by the projection on the ''k'' first coordinates, and the subset of the image where the projection is not proper.\n* More generally Gröbner basis computations allow one to compute the Zariski closure of the image and the [[critical point (mathematics)|critical point]]s of a rational function of ''V'' into another affine variety.\n\nGröbner basis computations do not allow one to compute directly the primary decomposition of ''I'' nor the prime ideals defining the irreducible components of ''V'', but most algorithms for this involve Gröbner basis computation. The algorithms which are not based on Gröbner bases use [[regular chain]]s but may need Gröbner bases in some exceptional situations.\n\nGröbner bases are deemed to be difficult to compute. In fact they may contain, in the worst case, polynomials whose degree is doubly exponential in the number of variables and a number of polynomials which is also doubly exponential. However, this is only a worst case complexity, and the complexity bound of Lazard's algorithm of 1979 may frequently apply. [[Faugère F5 algorithm]] realizes this complexity, as it may be viewed as an improvement of Lazard's 1979 algorithm. It follows that the best implementations allow one to compute almost routinely with algebraic sets of degree more than 100. This means that, presently, the difficulty of computing a Gröbner basis is strongly related to the intrinsic difficulty of the problem.\n\n===Cylindrical algebraic decomposition (CAD)===\nCAD is an algorithm which was introduced in 1973 by G. Collins to implement with an acceptable complexity the [[Tarski–Seidenberg theorem]] on [[quantifier elimination]] over the real numbers.\n\nThis theorem concerns the formulas of the [[first-order logic]] whose [[atomic formula]]s are polynomial equalities or inequalities between polynomials with real coefficients. These formulas are thus the formulas which may be constructed from the atomic formulas by the logical operators ''and'' (∧), ''or'' (∨), ''not'' (¬), ''for all'' (∀) and ''exists'' (∃). Tarski's theorem asserts that, from such a formula, one may compute an equivalent formula without quantifier (∀, ∃).\n\nThe complexity of CAD is doubly exponential in the number of variables. This means that CAD allows, in theory, to solve every problem of real algebraic geometry which may be expressed by such a formula, that is almost every problem concerning explicitly given varieties and semi-algebraic sets.\n\nWhile Gröbner basis computation has doubly exponential complexity only in rare cases, CAD has almost always this high complexity. This implies that, unless if most polynomials appearing in the input are linear, it may not solve problems with more than four variables.\n\nSince 1973, most of the research on this subject is devoted either to improve CAD or to find alternative algorithms in special cases of general interest.\n\nAs an example of the state of art, there are efficient algorithms to find at least a point in every connected component of a semi-algebraic set, and thus to test if a semi-algebraic set is empty. On the other hand, CAD is yet, in practice, the best algorithm to count the number of connected components.\n\n=== Asymptotic complexity vs. practical efficiency ===\nThe basic general algorithms of computational geometry have a double exponential worst case [[Computational complexity theory|complexity]]. More precisely, if ''d'' is the maximal degree of the input polynomials and ''n'' the number of variables, their complexity is at most <math>d^{2^{c n}}</math> for some constant ''c'', and, for some inputs, the complexity is at least <math>d^{2^{c' n}}</math> for another constant ''c''′.\n\nDuring the last 20 years of 20th century, various algorithms have been introduced to solve specific subproblems with a better complexity. Most of these algorithms have a complexity <math>d^{O(n^2)}</math>.{{Citation needed|reason=both the most claim and the order need substantiation|date=November 2018}}\n\nAmong these algorithms which solve a sub problem of the problems solved by Gröbner bases, one may cite ''testing if an affine variety is empty'' and ''solving nonhomogeneous polynomial systems which have a finite number of solutions.'' Such algorithms are rarely implemented because, on most entries [[Faugère's F4 and F5 algorithms]] have a better practical efficiency and probably a similar or better complexity (''probably'' because the evaluation of the complexity of Gröbner basis algorithms on a particular class of entries is a difficult task which has been done only in a few special cases).\n\nThe main algorithms of real algebraic geometry which solve a problem solved by CAD are related to the topology of semi-algebraic sets. One may cite ''counting the number of connected components'', ''testing if two points are in the same components'' or ''computing a [[Whitney stratification]] of a real algebraic set''. They have a complexity of\n<math>d^{O(n^2)}</math>, but the constant involved by ''O'' notation is so high that using them to solve any nontrivial problem effectively solved by CAD, is impossible even if one could use all the existing computing power in the world. Therefore, these algorithms have never been implemented and this is an active research area to search for algorithms with have together a good asymptotic complexity and a good practical efficiency.\n\n== Abstract modern viewpoint ==\nThe modern approaches to algebraic geometry redefine and effectively extend the range of basic objects in various levels of generality to schemes, [[formal scheme]]s, [[ind-scheme]]s, [[algebraic space]]s, [[algebraic stack]]s and so on. The need for this arises already from the useful ideas within theory of varieties, e.g. the formal functions of Zariski can be accommodated by introducing nilpotent elements in structure rings; considering spaces of loops and arcs, constructing quotients by group actions and developing formal grounds for natural intersection theory and deformation theory lead to some of the further extensions.\n\nMost remarkably, in late 1950s, algebraic varieties were subsumed into [[Alexander Grothendieck]]'s concept of a [[scheme (mathematics)|scheme]]. Their local objects are affine schemes or prime spectra which are locally ringed spaces which form a category which is antiequivalent to the category of commutative unital rings, extending the duality between the category of affine algebraic varieties over a field ''k'', and the category of finitely generated reduced ''k''-algebras. The gluing is along Zariski topology; one can glue within the category of locally ringed spaces, but also, using the Yoneda embedding, within the more abstract category of presheaves of sets over the category of affine schemes. The Zariski topology in the set theoretic sense is then replaced by a [[Grothendieck topology]]. Grothendieck introduced Grothendieck topologies having in mind more exotic but geometrically finer and more sensitive examples than the crude Zariski topology, namely the [[étale topology]], and the two flat Grothendieck topologies: fppf and fpqc; nowadays some other examples became prominent including [[Nisnevich topology]]. Sheaves can be furthermore generalized to stacks in the sense of Grothendieck, usually with some additional representability conditions leading to Artin stacks and, even finer, [[Deligne-Mumford stack]]s, both often called algebraic stacks.\n\nSometimes other algebraic sites replace the category of affine schemes. For example, [[Nikolai Durov]] has introduced commutative algebraic monads as a generalization of local objects in a generalized algebraic geometry. Versions of a [[tropical geometry]], of an [[absolute geometry]] over a field of one element and an algebraic analogue of [[Arakelov's geometry]] were realized in this setup.\n\nAnother formal generalization is possible to [[universal algebraic geometry]] in which every [[Variety (universal algebra)|variety of algebras]] has its own algebraic geometry. The term ''variety of algebras'' should not be confused with ''algebraic variety''.\n\nThe language of schemes, stacks and generalizations has proved to be a valuable way of dealing with geometric concepts and became cornerstones of modern algebraic geometry.\n\nAlgebraic stacks can be further generalized and for many practical questions like deformation theory and intersection theory, this is often the most natural approach. One can extend the [[Grothendieck site]] of affine schemes to a [[higher category theory|higher categorical]] site of [[derived affine scheme]]s, by replacing the commutative rings with an infinity category of [[differential graded commutative algebra]]s, or of simplicial commutative rings or a similar category with an appropriate variant of a Grothendieck topology. One can also replace presheaves of sets by presheaves of simplicial sets (or of infinity groupoids). Then, in presence of an appropriate homotopic machinery one can develop a notion of derived stack as such a presheaf on the infinity category of derived affine schemes, which is satisfying certain infinite categorical version of a sheaf axiom (and to be algebraic, inductively a sequence of representability conditions). [[Quillen model category|Quillen model categories]], Segal categories and [[quasicategory|quasicategories]] are some of the most often used tools to formalize this yielding the ''[[derived algebraic geometry]]'', introduced by the school of [[Carlos Simpson]], including Andre Hirschowitz, [[Bertrand Toën]], Gabrielle Vezzosi, Michel Vaquié and others; and developed further by [[Jacob Lurie]], [[Bertrand Toën]], and [[Gabrielle Vezzosi]]. Another (noncommutative) version of derived algebraic geometry, using A-infinity categories has been developed from early 1990s by [[Maxim Kontsevich]] and followers.\n\n== History ==\n\n===Before the 16th century===\nSome of the roots of algebraic geometry date back to the work of the [[Hellenistic Greece|Hellenistic Greeks]] from the 5th century BC. The [[Delian problem]], for instance, was to construct a length ''x'' so that the cube of side ''x'' contained the same volume as the rectangular box ''a''<sup>2</sup>''b'' for given sides ''a'' and ''b''. [[Menaechmus]] (circa 350 BC) considered the problem geometrically by intersecting the pair of plane conics ''ay''&nbsp;=&nbsp;''x''<sup>2</sup> and ''xy''&nbsp;=&nbsp;''ab''.<ref name=\"Dieudonné\">{{Cite journal |last=Dieudonné |first=Jean |authorlink=Jean Dieudonné |title=The historical development of algebraic geometry |journal=The American Mathematical Monthly |volume=79 |issue=8 |year=1972 |pages=827–866 |doi=10.2307/2317664 |jstor=2317664 }}</ref> The later work, in the 3rd century BC, of [[Archimedes]] and [[Apollonius of Perga|Apollonius]] studied more systematically problems on [[conic sections]],<ref>Kline, M. (1972) ''Mathematical Thought from Ancient to Modern Times'' (Volume 1). Oxford University Press. pp. 108, 90.</ref> and also involved the use of coordinates.<ref name=\"Dieudonné\"/> The [[Mathematics in medieval Islam|Arab mathematicians]] were able to solve by purely algebraic means certain cubic equations, and then to interpret the results geometrically. This was done, for instance, by [[Ibn al-Haytham]] in the 10th century AD.<ref>Kline, M. (1972) ''Mathematical Thought from Ancient to Modern Times'' (Volume 1). Oxford University Press. p. 193.</ref> Subsequently, [[Persian people|Persian]] mathematician [[Omar Khayyám]] (born 1048 A.D.) discovered a method for solving [[cubic equation]]s by intersecting a parabola with a circle<ref>Kline, M. (1972) ''Mathematical Thought from Ancient to Modern Times'' (Volume 1). Oxford University Press. pp. 193&ndash;195.</ref> and seems to have been the first to conceive a general theory of cubic equations.<ref>[http://www-history.mcs.st-andrews.ac.uk/Biographies/Khayyam.html/ St Andrews] {{Webarchive|url=https://web.archive.org/web/20171112123436/http://www-history.mcs.st-andrews.ac.uk/Biographies/Khayyam.html# |date=2017-11-12 }} \"Khayyam himself seems to have been the first to conceive a general theory of cubic equations.\"</ref> A few years after Omar Khayyám, [[Sharaf al-Din al-Tusi]]'s ''Treatise on equations'' has been described as \"inaugurating the beginning of algebraic geometry\".<ref>Rashed ([[#CITEREFRashed1994|1994]], pp.[https://archive.org/stream/RoshdiRashedauth.TheDevelopmentOfArabicMathematicsBetweenArithmeticAndAlgebraSpringerNetherlands1994/Roshdi%20Rashed%20%28auth.%29-The%20Development%20of%20Arabic%20Mathematics_%20Between%20Arithmetic%20and%20Algebra-Springer%20Netherlands%20%281994%29#page/n111/mode/1up 102-3])</ref>\n\n===Renaissance===\n\nSuch techniques of applying geometrical constructions to algebraic problems were also adopted by a number of [[Renaissance]] mathematicians such as [[Gerolamo Cardano]] and [[Niccolò Fontana Tartaglia|Niccolò Fontana \"Tartaglia\"]] on their studies of the cubic equation. The geometrical approach to construction problems, rather than the algebraic one, was favored by most 16th and 17th century mathematicians, notably [[Blaise Pascal]] who argued against the use of algebraic and analytical methods in geometry.<ref>Kline, M. (1972) ''Mathematical Thought from Ancient to Modern Times'' (Volume 1). Oxford University Press. p. 279.</ref> The French mathematicians [[Franciscus Vieta]] and later [[René Descartes]] and [[Pierre de Fermat]] revolutionized the conventional way of thinking about construction problems through the introduction of [[coordinate geometry]]. They were interested primarily in the properties of ''algebraic curves'', such as those defined by [[Diophantine equations]] (in the case of Fermat), and the algebraic reformulation of the classical Greek works on conics and cubics (in the case of Descartes).\n\nDuring the same period, Blaise Pascal and [[Gérard Desargues]] approached geometry from a different perspective, developing the [[synthetic geometry|synthetic]] notions of [[projective geometry]]. Pascal and Desargues also studied curves, but from the purely geometrical point of view: the analog of the Greek ''ruler and compass construction''. Ultimately, the [[analytic geometry]] of Descartes and Fermat won out, for it supplied the 18th century mathematicians with concrete quantitative tools needed to study physical problems using the new calculus of [[Isaac Newton|Newton]] and [[Gottfried Wilhelm Leibniz|Leibniz]]. However, by the end of the 18th century, most of the algebraic character of coordinate geometry was subsumed by the ''calculus of infinitesimals'' of [[Joseph Louis Lagrange|Lagrange]] and [[Leonhard Euler|Euler]].\n\n===19th and early 20th century===\nIt took the simultaneous 19th century developments of [[non-Euclidean geometry]] and [[Abelian integral]]s in order to bring the old algebraic ideas back into the geometrical fold. The first of these new developments was seized up by [[Edmond Laguerre]] and [[Arthur Cayley]], who attempted to ascertain the generalized metric properties of projective space. Cayley introduced the idea of ''homogeneous polynomial forms'', and more specifically [[quadratic form]]s, on projective space. Subsequently, [[Felix Klein]] studied projective geometry (along with other types of geometry) from the viewpoint that the geometry on a space is encoded in a certain class of [[transformation group|transformations]] on the space. By the end of the 19th century, projective geometers were studying more general kinds of transformations on figures in projective space. Rather than the projective linear transformations which were normally regarded as giving the fundamental [[Kleinian geometry]] on projective space, they concerned themselves also with the higher degree [[birational transformation]]s. This weaker notion of congruence would later lead members of the 20th century [[Italian school of algebraic geometry]] to classify [[algebraic surface]]s up to [[birational isomorphism]].\n\nThe second early 19th century development, that of Abelian integrals, would lead [[Bernhard Riemann]] to the development of [[Riemann surface]]s.\n\nIn the same period began the algebraization of the algebraic geometry through [[commutative algebra]]. The prominent results in this direction are [[Hilbert's basis theorem]] and [[Hilbert's Nullstellensatz]], which are the basis of the connexion between algebraic geometry and commutative algebra, and [[Francis Sowerby Macaulay|Macaulay]]'s [[multivariate resultant]], which is the basis of [[elimination theory]]. Probably because of the size of the computation which is implied by multivariate resultants, elimination theory was forgotten during the middle of the 20th century until it was renewed by [[singularity theory]] and computational algebraic geometry.<ref>\nA witness of this oblivion is the fact that [[Van der Waerden]] removed the chapter on elimination theory from the third edition (and all the subsequent ones) of his treatise ''Moderne algebra'' (in German).</ref>\n\n===20th century===\n[[B. L. van der Waerden]], [[Oscar Zariski]] and [[André Weil]] developed a foundation for algebraic geometry based on contemporary [[commutative algebra]], including [[valuation theory]] and the theory of [[ideal (ring theory)|ideals]]. One of the goals was to give a rigorous framework for proving the results of [[Italian school of algebraic geometry]]. In particular, this school used systematically the notion of [[generic point]] without any precise definition, which was first given by these authors during the 1930s.\n\nIn the 1950s and 1960s, [[Jean-Pierre Serre]] and [[Alexander Grothendieck]] recast the foundations making use of [[sheaf theory]]. Later, from about 1960, and largely led by Grothendieck, the idea of [[scheme (mathematics)|schemes]] was worked out, in conjunction with a very refined apparatus of [[homological algebra|homological techniques]]. After a decade of rapid development the field stabilized in the 1970s, and new applications were made, both to [[number theory]] and to more classical geometric questions on algebraic varieties, [[singularity theory|singularities]], [[moduli space|moduli]], and [[formal moduli]].\n\nAn important class of varieties, not easily understood directly from their defining equations, are the [[abelian variety|abelian varieties]], which are the projective varieties whose points form an abelian [[group (mathematics)|group]]. The prototypical examples are the [[elliptic curve]]s, which have a rich theory. They were instrumental in the proof of [[Fermat's last theorem]] and are also used in [[elliptic-curve cryptography]].\n\nIn parallel with the abstract trend of the algebraic geometry, which is concerned with general statements about varieties, methods for effective computation with concretely-given varieties have also been developed, which lead to the new area of computational algebraic geometry. One of the founding methods of this area is the theory of [[Gröbner basis|Gröbner bases]], introduced by [[Bruno Buchberger]] in 1965. Another founding method, more specially devoted to real algebraic geometry, is the [[cylindrical algebraic decomposition]], introduced by [[George E. Collins]] in 1973.\n\nSee also: [[derived algebraic geometry]].<!-- related to this, we really should mention more recent stuff like moduli of curves, connection to theoretical physics, etc.-->\n\n==Analytic geometry==\nAn '''[[analytic variety]]''' is defined locally as the set of common solutions of several equations involving [[analytic function]]s. It is analogous to the included concept of real or complex [[algebraic variety]]. Any [[complex manifold]] is an analytic variety. Since analytic varieties may have [[Mathematical singularity|singular points]], not all analytic varieties are manifolds.\n\nModern analytic geometry is essentially equivalent to real and complex algebraic geometry, as has been shown by [[Jean-Pierre Serre]] in his paper ''[[GAGA]]'', the name of which is French for ''Algebraic geometry and analytic geometry''. Nevertheless, the two fields remain distinct, as the methods of proof are quite different and algebraic geometry includes also geometry in finite [[Characteristic (algebra)|characteristic]].\n\n==Applications==\nAlgebraic geometry now finds applications in [[algebraic statistics|statistics]],<ref>{{cite book| last1 = Drton| first1 = Mathias| last2 = Sturmfels| first2 = Bernd| last3 = Sullivant| first3 = Seth| title = Lectures on Algebraic Statistics| url = https://books.google.com/?id=TytYUTy5V_IC| year = 2009| publisher = Springer| isbn = 978-3-7643-8904-8 }}</ref> [[control theory]],<ref>{{cite book| last = Falb| first = Peter| title = Methods of Algebraic Geometry in Control Theory Part II Multivariable Linear Systems and Projective Algebraic Geometry| url = https://books.google.com/?id=V--84aGmWh4C| year = 1990| publisher = Springer| isbn = 978-0-8176-4113-9 }}</ref><ref>[[Allen Tannenbaum]] (1982), Invariance and Systems Theory: Algebraic and Geometric Aspects, Lecture Notes in Mathematics, volume 845, Springer-Verlag, {{ISBN|9783540105657}}</ref> [[robotics]],<ref>{{cite book| last = Selig| first = J.M.| title = Geometric Fundamentals of Robotics| url = https://books.google.com/?id=9FljXoISr8AC| year = 2005| publisher = Springer| isbn = 978-0-387-20874-9 }}</ref> [[algebraic geometric code|error-correcting codes]],<ref>{{cite book |last1=Tsfasman |first1=Michael A. |last2=Vlăduț |first2=Serge G. |last3=Nogin |first3=Dmitry |title=Algebraic Geometric Codes Basic Notions |year=1990 |publisher=American Mathematical Soc. |isbn=978-0-8218-7520-9 |url=https://books.google.com/?id=o2sA-wzDBLkC}}</ref> [[computational phylogenetics|phylogenetics]]<ref>[[Barry Arthur Cipra]] (2007), [http://siam.org/pdf/news/1146.pdf Algebraic Geometers See Ideal Approach to Biology] {{Webarchive|url=https://web.archive.org/web/20160303230428/http://siam.org/pdf/news/1146.pdf# |date=2016-03-03 }}, SIAM News, Volume 40, Number 6</ref> and [[geometric modelling]].<ref>{{cite book |last1=Jüttler |first1=Bert |last2=Piene |first2=Ragni |title=Geometric Modeling and Algebraic Geometry |year=2007 |publisher=Springer |isbn=978-3-540-72185-7 |url=https://books.google.com/?id=1wNGq87gWykC}}</ref> There are also connections to [[Homological mirror symmetry|string theory]],<ref>{{cite book |last1=Cox |first1=David A. |authorlink1=David A. Cox |last2=Katz |first2=Sheldon |title=Mirror Symmetry and Algebraic Geometry |url=https://books.google.com/?id=Z8u3ngEACAAJ |year=1999 |publisher=American Mathematical Soc. |isbn=978-0-8218-2127-5}}</ref> [[game theory]],<ref>{{cite journal |url=http://econwpa.wustl.edu/econ-wp/game/papers/9309/9309001.pdf |title=The algebraic geometry of perfect and sequential equilibrium |first=L. E. |last=Blume |first2=W. R. |last2=Zame |journal=[[Econometrica]] |volume=62 |issue=4 |year=1994 |pages=783–794 |jstor=2951732 }}{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}</ref> [[Matching (graph theory)|graph matching]]s,<ref>{{cite arXiv |last1=Kenyon |first1=Richard |last2=Okounkov |first2=Andrei |last3=Sheffield |first3=Scott |title=Dimers and Amoebae |eprint=math-ph/0311005 |year=2003}}</ref> [[soliton]]s<ref>{{cite book |last=Fordy |first=Allan P. |title=Soliton Theory A Survey of Results |url=https://books.google.com/?id=eO_PAAAAIAAJ |year=1990 |publisher=Manchester University Press |isbn=978-0-7190-1491-8}}</ref> and [[integer programming]].<ref>{{cite book |last1=Cox |first1=David A. |authorlink1=David A. Cox |last2=Sturmfels |first2=Bernd |editor-last=Manocha |editor-first=Dinesh N. |title=Applications of Computational Algebraic Geometry |url=https://books.google.com/?id=fe0MJEPDwzAC |publisher=American Mathematical Soc. |isbn=978-0-8218-6758-7}}</ref>\n\n==See also==\n{{div col |colwidth=27em}}\n* [[Algebraic statistics]]\n* [[Differential geometry]]\n* [[Geometric algebra]]\n* [[Glossary of classical algebraic geometry]]\n* [[Intersection theory]]\n* [[List of publications in mathematics#Algebraic geometry|Important publications in algebraic geometry]]\n* [[List of algebraic surfaces]]\n* [[Noncommutative algebraic geometry]]\n* [[Diffiety|Diffiety theory]]\n* [[Differential algebraic geometry]]\n* [[Real algebraic geometry]]\n{{div col end}}\n\n==Notes==\n{{Reflist|30em}}\n\n==Further reading==\n;Some classic textbooks that predate schemes:\n* {{cite book\n |last=van der Waerden |first=B. L. |authorlink=B. L. van der Waerden\n |year = 1945\n |title = Einfuehrung in die algebraische Geometrie\n |publisher = [[Dover]]\n}}\n* {{cite book |last1=Hodge |first1=W. V. D. |authorlink1=W. V. D. Hodge |last2=Pedoe |first2=Daniel |authorlink2=Daniel Pedoe |title=Methods of Algebraic Geometry Volume 1 |year=1994 |publisher=[[Cambridge University Press]] |isbn=978-0-521-46900-5 |zbl=0796.14001}}\n* {{cite book| last1 = Hodge| first1 = W. V. D.| authorlink1 = W. V. D. Hodge| last2 = Pedoe| first2 = Daniel| authorlink2 = Daniel Pedoe| title = Methods of Algebraic Geometry Volume 2| year = 1994| publisher = [[Cambridge University Press]]| isbn = 978-0-521-46901-2| zbl = 0796.14002 }}\n* {{cite book| last1 = Hodge| first1 = W. V. D.| authorlink1 = W. V. D. Hodge| last2 = Pedoe| first2 = Daniel| authorlink2 = Daniel Pedoe| title = Methods of Algebraic Geometry Volume 3| year = 1994| publisher = [[Cambridge University Press]]| isbn = 978-0-521-46775-9| zbl = 0796.14003 }}\n\n;Modern textbooks that do not use the language of schemes:\n* {{cite book| last = Garrity| first = Thomas| title = Algebraic Geometry A Problem Solving Approach| year = 2013| publisher = [[American Mathematical Society]]| isbn = 978-0-821-89396-8|display-authors=etal}}\n* {{cite book\n | last1=Griffiths | first1=Phillip | authorlink1=Phillip Griffiths\n | last2=Harris | first2=Joe | authorlink2=Joe Harris (mathematician)\n | year = 1994\n | title = Principles of Algebraic Geometry\n | publisher = [[Wiley-Interscience]]\n | isbn = 978-0-471-05059-9\n | zbl = 0836.14001\n}}\n* {{cite book| last = Harris| first = Joe| authorlink = Joe Harris (mathematician)| title = Algebraic Geometry A First Course| year = 1995| publisher = [[Springer Science+Business Media|Springer-Verlag]]| isbn = 978-0-387-97716-4| zbl = 0779.14001 }}\n* {{cite book| last = Mumford| first = David| authorlink = David Mumford| title = Algebraic Geometry I Complex Projective Varieties| edition = 2nd| year = 1995| publisher = [[Springer Science+Business Media|Springer-Verlag]]| isbn = 978-3-540-58657-9| zbl = 0821.14001 }}\n* {{cite book| last = Reid| first = Miles| authorlink = Miles Reid| title = Undergraduate Algebraic Geometry| year = 1988| publisher = [[Cambridge University Press]]| isbn = 978-0-521-35662-6| zbl = 0701.14001 }}\n* {{cite book| last = Shafarevich| first = Igor| authorlink = Igor Shafarevich| title = Basic Algebraic Geometry I Varieties in Projective Space| edition = 2nd| year = 1995| publisher = [[Springer Science+Business Media|Springer-Verlag]]| isbn = 978-0-387-54812-8| zbl = 0797.14001 }}\n\n;Textbooks in computational algebraic geometry\n* {{cite book |last1=Cox |first1=David A. |authorlink1=David A. Cox |last2=Little |first2=John |last3=O'Shea |first3=Donal |title=Ideals, Varieties, and Algorithms |edition=2nd |year=1997 |publisher=[[Springer Science+Business Media|Springer-Verlag]] |isbn=978-0-387-94680-1 |zbl=0861.13012}}\n* {{cite book\n | last1=Basu |first1 = Saugata \n | last2=Pollack |first2=Richard\n | last3=Roy |first3=Marie-Françoise \n | year = 2006\n | title = Algorithms in real algebraic geometry\n | publisher = [[Springer Science+Business Media|Springer-Verlag]]\n | url = http://perso.univ-rennes1.fr/marie-francoise.roy/bpr-ed2-posted1.html\n}}\n* {{cite book\n | last1=González-Vega |first1=Laureano\n | last2=Recio |first2=Tómas \n | year = 1996\n | title = Algorithms in algebraic geometry and applications\n | publisher = Birkhaüser\n}}\n* {{cite book\n | editor1-last=Elkadi |editor1-first=Mohamed \n | editor2-last=Mourrain |editor2-first=Bernard \n | editor3-last=Piene |editor3-first=Ragni \n | year = 2006\n | title = Algebraic geometry and geometric modeling\n | publisher = [[Springer Science+Business Media|Springer-Verlag]]\n}}\n* {{cite book\n | editor1-last=Dickenstein |editor1-first=Alicia|editor1-link=Alicia Dickenstein\n | editor2-last=Schreyer |editor2-first=Frank-Olaf\n | editor3-last=Sommese |editor3-first=Andrew J.\n | year = 2008\n | title = Algorithms in Algebraic Geometry\n | volume=146\n | series=The IMA Volumes in Mathematics and its Applications\n | publisher = [[Springer Science+Business Media|Springer]]\n | isbn=9780387751559\n | lccn=2007938208\n}}\n* {{cite book\n | last1=Cox |first1=David A. |authorlink1=David A. Cox\n | last2=Little |first2=John B.\n | last3=O'Shea |first3=Donal \n | year = 1998\n | title = Using algebraic geometry\n | publisher = [[Springer Science+Business Media|Springer-Verlag]]\n}}\n* {{cite book\n | last1=Caviness |first1=Bob F.\n | last2=Johnson |first2=Jeremy R. \n | year = 1998\n | title = Quantifier elimination and cylindrical algebraic decomposition\n | publisher = [[Springer Science+Business Media|Springer-Verlag]]\n}}\n\n;Textbooks and references for schemes:\n* {{cite book |last1=Eisenbud |first1=David |authorlink1=David Eisenbud |last2=Harris |first2=Joe |authorlink2=Joe Harris (mathematician) |title=The Geometry of Schemes |year=1998 |publisher=[[Springer Science+Business Media|Springer-Verlag]] |isbn=978-0-387-98637-1 |zbl=0960.14002}}\n* {{cite book\n | last=Grothendieck |first=Alexander |authorlink=Alexander Grothendieck\n | year = 1960\n | title = Éléments de géométrie algébrique\n | publisher = [[Publications Mathématiques de l'IHÉS]]\n | zbl = 0118.36206\n|title-link=Éléments de géométrie algébrique }}\n* {{cite book |last1=Grothendieck |first1=Alexander |authorlink1=Alexander Grothendieck |last2=Dieudonné |first2=Jean Alexandre |title=Éléments de géométrie algébrique |edition=2nd |volume=1 |year=1971 |publisher=[[Springer Science+Business Media|Springer-Verlag]] |isbn=978-3-540-05113-8 |zbl=0203.23301|title-link=Éléments de géométrie algébrique }}\n* {{cite book |last=Hartshorne |first=Robin |authorlink=Robin Hartshorne |title=Algebraic Geometry |year=1977 |publisher=[[Springer Science+Business Media|Springer-Verlag]] |isbn=978-0-387-90244-9 |zbl=0367.14001|title-link=Algebraic Geometry (book) }}\n* {{cite book |last=Mumford |first=David |authorlink=David Mumford |title=The Red Book of Varieties and Schemes Includes the Michigan Lectures on Curves and Their Jacobians |edition=2nd |year=1999 |publisher=[[Springer Science+Business Media|Springer-Verlag]] |isbn=978-3-540-63293-1 |zbl=0945.14001}}\n* {{cite book |last=Shafarevich |first=Igor |authorlink=Igor Shafarevich |title = Basic Algebraic Geometry II Schemes and complex manifolds| edition = 2nd| year = 1995| publisher = [[Springer Science+Business Media|Springer-Verlag]]| isbn = 978-3-540-57554-2| zbl = 0797.14002 }}\n\n==External links==\n{{Wikiquote}}\n* [http://math.stanford.edu/~vakil/216blog/FOAGjun1113public.pdf ''Foundations of Algebraic Geometry'' by Ravi Vakil, 764 pp.]\n* [https://web.archive.org/web/20040415021548/http://planetmath.org/encyclopedia/AlgebraicGeometry.html ''Algebraic geometry''] entry on [http://planetmath.org/ PlanetMath]\n* [http://neo-classical-physics.info/uploads/3/0/6/5/3065888/van_der_waerden_-_algebraic_geometry.pdf English translation of the van der Waerden textbook]\n* {{cite web |first=Jean |last=Dieudonné |authorlink=Jean Dieudonné |date=March 3, 1972 |title=The History of Algebraic Geometry |url=https://www.youtube.com/watch?v=Jzx-0poj3Eo |publisher=Talk at the Department of Mathematics of the [[University of Wisconsin–Milwaukee]] |via=[[YouTube]] }} \n* [http://stacks.math.columbia.edu/ The Stacks Project], an open source textbook and reference work on algebraic stacks and algebraic geometry\n\n{{Areas of mathematics | state=collapsed}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Algebraic Geometry}}\n[[Category:Algebraic geometry| ]]\n[[Category:Fields of mathematics]]"
    },
    {
      "title": "Algebraic number theory",
      "url": "https://en.wikipedia.org/wiki/Algebraic_number_theory",
      "text": "{{Ring theory sidebar}}\n[[Image:Disqvisitiones-800.jpg|thumb|Title page of the first edition of [[Disquisitiones Arithmeticae]], one of the founding works of modern algebraic number theory.]]\n\n'''Algebraic number theory''' is a branch of [[number theory]] that uses the techniques of [[abstract algebra]] to study the [[integers]], [[rational numbers]], and their generalizations. Number-theoretic questions are expressed in terms of properties of algebraic objects such as [[algebraic number field]]s and their [[rings of integers]], [[finite field]]s, and [[Algebraic function field|function field]]s. These properties, such as whether a [[ring (mathematics)|ring]] admits unique [[factorization]], the behavior of [[ideal (ring theory)|ideal]]s, and the [[Galois group]]s of [[field (mathematics)|field]]s, can resolve questions of primary importance in number theory, like the existence of solutions to [[Diophantine equation]]s.\n\n==History of algebraic number theory==\n\n===Diophantus===\nThe beginnings of algebraic number theory can be traced to Diophantine equations,<ref>Stark, pp. 145–146.</ref> named after the 3rd-century [[Alexandria]]n mathematician, [[Diophantus]], who studied them and developed methods for the solution of some kinds of Diophantine equations. A typical Diophantine problem is to find two integers ''x'' and ''y'' such that their sum, and the sum of their squares, equal two given numbers ''A'' and ''B'', respectively:\n\n:<math>A = x + y\\ </math>\n:<math>B = x^2 + y^2.\\ </math>\n\nDiophantine equations have been studied for thousands of years.  For example, the solutions to the quadratic Diophantine equation ''x''<sup>2</sup> + ''y''<sup>2</sup> = ''z''<sup>2</sup> are given by the [[Pythagorean triple]]s, originally solved by the Babylonians (c. 1800 BC).<ref>Aczel, pp. 14–15.</ref> Solutions to linear Diophantine equations, such as 26''x'' + 65''y'' = 13, may be found using the [[Euclidean algorithm]] (c. 5th century BC).<ref>Stark, pp. 44–47.</ref>\n\nDiophantus' major work was the ''[[Arithmetica]]'', of which only a portion has survived.\n\n===Fermat===\n[[Fermat's last theorem]] was first [[conjectured]] by [[Pierre de Fermat]] in 1637, famously in the margin of a copy of ''Arithmetica'' where he claimed he had a proof that was too large to fit in the margin. No successful proof was published until 1995 despite the efforts of countless mathematicians during the 358 intervening years. The unsolved problem stimulated the development of algebraic number theory in the 19th century and the proof of the [[modularity theorem]] in the 20th century.\n\n===Gauss===\nOne of the founding works of algebraic number theory, the '''''Disquisitiones Arithmeticae''''' ([[Latin]]: ''Arithmetical Investigations'') is a textbook of number theory written in Latin<ref>[http://yalepress.yale.edu/yupbooks/book.asp?isbn=9780300094732 ''Disquisitiones Arithmeticae''] at Yalepress.yale.edu</ref> by [[Carl Friedrich Gauss]] in 1798 when Gauss was 21 and first published in 1801 when he was 24. In this book Gauss brings together results in number theory obtained by mathematicians such as Fermat, [[Euler]], [[Joseph Louis Lagrange|Lagrange]] and [[Adrien-Marie Legendre|Legendre]] and adds important new results of his own. Before the ''Disquisitiones'' was published, number theory consisted of a collection of isolated theorems and conjectures. Gauss brought the work of his predecessors together with his own original work into a systematic framework, filled in gaps, corrected unsound proofs, and extended the subject in numerous ways.\n\nThe ''Disquisitiones'' was the starting point for the work of other nineteenth century [[Europe]]an mathematicians including [[Ernst Kummer]], [[Peter Gustav Lejeune Dirichlet]] and [[Richard Dedekind]]. Many of the annotations given by Gauss are in effect announcements of further research of his own, some of which remained unpublished. They must have appeared particularly cryptic to his contemporaries; we can now read them as containing the germs of the theories of [[L-function]]s and [[complex multiplication]], in particular.\n\n===Dirichlet===\nIn a couple of papers in 1838 and 1839 [[Peter Gustav Lejeune Dirichlet]] proved the first [[class number formula]], for [[quadratic form]]s (later refined by his student [[Leopold Kronecker]]). The formula, which Jacobi called a result \"touching the utmost of human acumen\", opened the way for similar results regarding more general [[number field]]s.<ref name=Elstrodt>{{cite journal | last = Elstrodt | first = Jürgen | journal = Clay Mathematics Proceedings\n  | title = The Life and Work of Gustav Lejeune Dirichlet (1805–1859) | work = | publisher = | year = 2007\n  | url = http://www.uni-math.gwdg.de/tschinkel/gauss-dirichlet/elstrodt-new.pdf | format = [[PDF]] | doi =\n  | accessdate = 2007-12-25}}</ref> Based on his research of the structure of the [[unit group]] of [[quadratic field]]s, he proved the [[Dirichlet unit theorem]], a fundamental result in algebraic number theory.<ref name=Kanemitsu>{{cite book| last = Kanemitsu| first = Shigeru|author2=Chaohua Jia| title=Number theoretic methods: future trends | year=2002| publisher=Springer| location  = | isbn= 978-1-4020-1080-4| pages= 271–274}}</ref>\n\nHe first used the [[pigeonhole principle]], a basic counting argument, in the proof of a theorem in [[diophantine approximation]], later named after him [[Dirichlet's approximation theorem]]. He published important contributions to Fermat's last theorem, for which he proved the cases ''n''&nbsp;=&nbsp;5 and ''n''&nbsp;=&nbsp;14, and to the [[quartic reciprocity|biquadratic reciprocity law]].<ref name=Elstrodt/> The [[Dirichlet divisor problem]], for which he found the first results, is still an unsolved problem in number theory despite later contributions by other researchers.\n\n===Dedekind===\n[[Richard Dedekind]]'s study of Lejeune Dirichlet's work was what led him to his later study of algebraic number fields and ideals. In 1863, he published Lejeune Dirichlet's lectures on number theory as ''[[Vorlesungen über Zahlentheorie]]'' (\"Lectures on Number Theory\") about which it has been written that:\n<blockquote>\"Although the book is assuredly based on Dirichlet's lectures, and although Dedekind himself referred to the book throughout his life as Dirichlet's, the book itself was entirely written by Dedekind, for the most part after Dirichlet's death.\" (Edwards 1983)</blockquote>\n\n1879 and 1894 editions of the ''Vorlesungen'' included supplements introducing the notion of an ideal, fundamental to [[ring (algebra)|ring theory]]. (The word \"Ring\", introduced later by [[David Hilbert|Hilbert]], does not appear in Dedekind's work.) Dedekind defined an ideal as a subset of a set of numbers, composed of [[algebraic integer]]s that satisfy polynomial equations with integer coefficients. The concept underwent further development in the hands of Hilbert and, especially, of [[Emmy Noether]]. Ideals generalize Ernst Eduard Kummer's [[ideal number]]s, devised as part of Kummer's 1843 attempt to prove Fermat's Last Theorem.\n\n===Hilbert===\n[[David Hilbert]] unified the field of algebraic number theory with his 1897 treatise ''[[Zahlbericht]]'' (literally \"report on numbers\"). He also resolved a significant number-theory [[Waring's problem|problem formulated by Waring]] in 1770.  As with [[#The finiteness theorem|the finiteness theorem]], he used an existence proof that shows there must be solutions for the problem rather than providing a mechanism to produce the answers.<ref>Reid, Constance, 1996. ''Hilbert'', [[Springer Science and Business Media|Springer]], {{ISBN|0-387-94674-8}}.</ref>  He then had little more to publish on the subject; but the emergence of [[Hilbert modular form]]s in the dissertation of a student means his name is further attached to a major area.\n\nHe made a series of conjectures on [[class field theory]]. The concepts were highly influential, and his own contribution lives on in the names of the [[Hilbert class field]] and of the [[Hilbert symbol]] of [[local class field theory]]. Results were mostly proved by 1930, after work by [[Teiji Takagi]].<ref>This work established Takagi as Japan's first mathematician of international stature.</ref>\n\n===Artin===\n[[Emil Artin]] established the [[Artin reciprocity law]] in a series of papers (1924; 1927; 1930). This law is a general theorem in number theory that forms a central part of global class field theory.<ref>[[Helmut Hasse]], ''History of Class Field Theory'', in ''Algebraic Number Theory'', edited by Cassels and Frölich, Academic Press, 1967, pp. 266&ndash;279</ref> The term \"[[reciprocity law (mathematics)|reciprocity law]]\" refers to a long line of more concrete number theoretic statements which it generalized, from the [[quadratic reciprocity law]] and the reciprocity laws of [[Gotthold Eisenstein|Eisenstein]] and Kummer to Hilbert's product formula for the [[Hilbert symbol|norm symbol]]. Artin's result provided a partial solution to [[Hilbert's ninth problem]].\n\n===Modern theory===\nAround 1955, Japanese mathematicians [[Goro Shimura]] and [[Yutaka Taniyama]] observed a possible link between two apparently completely distinct, branches of mathematics, [[elliptic curve]]s and [[modular form]]s. The resulting [[modularity theorem]] (at the time known as the Taniyama–Shimura conjecture) states that every elliptic curve is [[modular elliptic curve|modular]], meaning that it can be associated with a unique [[modular form]].\n\nIt was initially dismissed as unlikely or highly speculative, and was taken more seriously when number theorist [[André Weil]] found evidence supporting it, but no proof; as a result the \"astounding\"<ref name=\"Singh\">''[[Fermat's Last Theorem (book)|Fermat's Last Theorem]]'', [[Simon Singh]], 1997, {{ISBN|1-85702-521-0}}></ref> conjecture was often known as the Taniyama–Shimura-Weil conjecture. It became a part of the [[Langlands program]], a list of important conjectures needing proof or disproof.\n\nFrom 1993 to 1994, [[Andrew Wiles]] provided a proof of the [[modularity theorem]] for [[semistable elliptic curve]]s, which, together with [[Ribet's theorem]], provided a proof for Fermat's Last Theorem. Almost every mathematician at the time had previously considered both Fermat's Last Theorem and the Modularity Theorem either impossible or virtually impossible to prove, even given the most cutting edge developments. Wiles first announced his proof in June 1993<ref name=nyt>{{cite news|last=Kolata|first=Gina|title=At Last, Shout of 'Eureka!' In Age-Old Math Mystery|url=https://www.nytimes.com/1993/06/24/us/at-last-shout-of-eureka-in-age-old-math-mystery.html|accessdate=21 January 2013|newspaper=The New York Times|date=24 June 1993}}</ref> in a version that was soon recognized as having a serious gap at a key point. The proof was corrected by Wiles, partly in collaboration with [[Richard Taylor (mathematician)|Richard Taylor]], and the final, widely accepted version was released in September 1994, and formally published in 1995. The proof uses many techniques from [[algebraic geometry]] and number theory, and has many ramifications in these branches of mathematics. It also uses standard constructions of modern algebraic geometry, such as the [[category (mathematics)|category]] of [[scheme (mathematics)|schemes]] and [[Iwasawa theory]], and other 20th-century techniques not available to Fermat.\n\n==Basic notions==\n\n===Failure of unique factorization===\nAn important property of the ring of integers is that it satisfies the [[fundamental theorem of arithmetic]], that every (positive) integer has a factorization into a product of [[prime number]]s, and this factorization is unique up to the ordering of the factors. This may no longer be true in the ring of integers {{math|''O''}} of an algebraic number field {{math|''K''}}.\n\nA ''prime element'' is an element {{math|''p''}} of {{math|''O''}} such that if {{math|''p''}} divides a product {{math|''ab''}}, then it divides one of the factors {{math|''a''}} or {{math|''b''}}. This property is closely related to primality in the integers, because any positive integer satisfying this property is either {{math|1}} or a prime number. However, it is strictly weaker.  For example, {{math|&minus;2}} is not a prime number because it is negative, but it is a prime element. If factorizations into prime elements are permitted, then, even in the integers, there are alternative factorizations such as\n:<math>6 = 2 \\cdot 3 = (-2) \\cdot (-3).</math>\nIn general, if {{math|''u''}} is a [[unit (ring theory)|unit]], meaning a number with a multiplicative inverse in {{math|''O''}}, and if {{math|''p''}} is a prime element, then {{math|''up''}} is also a prime element. Numbers such as {{math|''p''}} and {{math|''up''}} are said to be ''associate''. In the integers, the primes {{math|''p''}} and {{math|&minus;''p''}} are associate, but only one of these is positive. Requiring that prime numbers be positive selects a unique element from among a set of associated prime elements. When ''K'' is not the rational numbers, however, there is no analog of positivity. For example, in the [[Gaussian integers]] {{math|'''Z'''[''i'']}}, the numbers {{math|1 + 2''i''}} and {{math|&minus;2 + ''i''}} are associate because the latter is the product of the former by {{math|''i''}}, but there is no way to single out one as being more canonical than the other. This leads to equations such as\n:<math>5 = (1 + 2i)(1 - 2i) = (2 + i)(2 - i),</math>\nwhich prove that in {{math|'''Z'''[''i'']}}, it is not true that factorizations are unique up to the order of the factors. For this reason, one adopts the definition of unique factorization used in [[unique factorization domain]]s (UFDs). In a UFD, the prime elements occurring in a factorization are only expected to be unique up to units and their ordering.\n\nHowever, even with this weaker definition, many rings of integers in algebraic number fields do not admit unique factorization. There is an algebraic obstruction called the ideal class group. When the ideal class group is trivial, the ring is a UFD. When it is not, there is a distinction between a prime element and an [[irreducible element]]. An ''irreducible element'' {{math|''x''}} is an element such that if {{math|1=''x'' = ''yz''}}, then either {{math|''y''}} or {{math|''z''}} is a unit. These are the elements that cannot be factored any further. Every element in ''O'' admits a factorization into irreducible elements, but it may admit more than one. This is because, while all prime elements are irreducible, some irreducible elements may not be prime. For example, consider the ring {{math|'''Z'''[√{{Overline|-5}}]}}. In this ring, the numbers {{math|3}}, {{math|2 + √{{Overline|-5}}}} and {{math|2 - √{{Overline|-5}}}} are irreducible. This means that the number {{math|9}} has two factorizations into irreducible elements,\n:<math>9 = 3^2 = (2 + \\sqrt{-5})(2 - \\sqrt{-5}).</math>\nThis equation shows that {{math|3}} divides the product {{math|1=(2 + √{{Overline|-5}})(2 - √{{Overline|-5}}) = 9}}. If {{math|3}} were a prime element, then it would divide {{math|2 + √{{Overline|-5}}}} or {{math|2 - √{{Overline|-5}}}}, but it does not, because all elements divisible by {{math|3}} are of the form {{math|3''a'' + 3''b''√{{Overline|-5}}}}.  Similarly, {{math|2 + √{{Overline|-5}}}} and {{math|2 - √{{Overline|-5}}}} divide the product {{math|3<sup>2</sup>}}, but neither of these elements divides {{math|3}} itself, so neither of them are prime. As there is no sense in which the elements {{math|3}}, {{math|2 + √{{Overline|-5}}}} and {{math|2 - √{{Overline|-5}}}} can be made equivalent, unique factorization fails in {{math|'''Z'''[√{{Overline|-5}}]}}. Unlike the situation with units, where uniqueness could be repaired by weakening the definition, overcoming this failure requires a new perspective.\n\n===Factorization into prime ideals===\nIf {{math|''I''}} is an ideal in {{math|''O''}}, then there is always a factorization\n:<math>I = \\mathfrak{p}_1^{e_1} \\cdots \\mathfrak{p}_t^{e_t},</math>\nwhere each <math>\\mathfrak{p}_i</math> is a [[prime ideal]], and where this expression is unique up to the order of the factors. In particular, this is true if {{math|''I''}} is the principal ideal generated by a single element. This is the strongest sense in which the ring of integers of a general number field admits unique factorization. In the language of ring theory, it says that rings of integers are [[Dedekind domain]]s.\n\nWhen {{math|''O''}} is a UFD, every prime ideal is generated by a prime element. Otherwise, there are prime ideals which are not generated by prime elements. In {{math|'''Z'''[√{{Overline|-5}}]}}, for instance, the ideal {{math|(2, 1 + √{{Overline|-5}})}} is a prime ideal which cannot be generated by a single element.\n\nHistorically, the idea of factoring ideals into prime ideals was preceded by Ernst Kummer's introduction of ideal numbers. These are numbers lying in an extension field {{math|''E''}} of {{math|''K''}}. This extension field is now known as the Hilbert class field. By the [[principal ideal theorem]], every prime ideal of {{math|''O''}} generates a principal ideal of the ring of integers of {{math|''E''}}. A generator of this principal ideal is called an ideal number. Kummer used these as a substitute for the failure of unique factorization in [[cyclotomic field]]s. These eventually led Richard Dedekind to introduce a forerunner of ideals and to prove unique factorization of ideals.\n\nAn ideal which is prime in the ring of integers in one number field may fail to be prime when extended to a larger number field. Consider, for example, the prime numbers. The corresponding ideals {{math|''p'''''Z'''}} are prime ideals of the ring {{math|'''Z'''}}. However, when this ideal is extended to the Gaussian integers to get {{math|''p'''''Z'''[''i'']}}, it may or may not be prime. For example, the factorization {{math|1=2 = (1 + ''i'')(1 &minus; ''i'')}} implies that\n:<math>2\\mathbf{Z}[i] = (1 + i)\\mathbf{Z}[i] \\cdot (1 - i)\\mathbf{Z}[i] = ((1 + i)\\mathbf{Z}[i])^2;</math>\nnote that because {{math|1=1 + ''i'' = (1 &minus; ''i'') ⋅ ''i''}}, the ideals generated by {{math|1 + ''i''}} and {{math|1 &minus; ''i''}} are the same. A complete answer to the question of which ideals remain prime in the Gaussian integers is provided by [[Fermat's theorem on sums of two squares]].  It implies that for an odd prime number {{math|''p''}}, {{math|''p'''''Z'''[''i'']}} is a prime ideal if {{math|''p'' ≡ 3 (mod 4)}} and is not a prime ideal if {{math|''p'' ≡ 1 (mod 4)}}. This, together with the observation that the ideal {{math|(1 + ''i'')'''Z'''[''i'']}} is prime, provides a complete description of the prime ideals in the Gaussian integers. Generalizing this simple result to more general rings of integers is a basic problem in algebraic number theory. Class field theory accomplishes this goal when ''K'' is an [[abelian extension]] of '''Q''' (i.e. a [[Galois extension]] with [[abelian group|abelian]] Galois group).\n\n===Ideal class group===\nUnique factorization fails if and only if there are prime ideals that fail to be principal. The object which measures the failure of prime ideals to be principal is called the ideal class group. Defining the ideal class group requires enlarging the set of ideals in a ring of algebraic integers so that they admit a [[group (mathematics)|group]] structure. This is done by generalizing ideals to [[fractional ideal]]s. A fractional ideal is an additive subgroup {{math|''J''}} of {{math|''K''}} which is closed under multiplication by elements of {{math|''O''}}, meaning that {{math|''xJ'' ⊆ ''J''}} if {{math|''x'' ∈ ''O''}}. All ideals of {{math|''O''}} are also fractional ideals. If {{math|''I''}} and {{math|''J''}} are fractional ideals, then the set {{math|''IJ''}} of all products of an element in {{math|''I''}} and an element in {{math|''J''}} is also a fractional ideal. This operation makes the set of non-zero fractional ideals into a group. The group identity is the ideal {{math|1=(1) = ''O''}}, and the inverse of {{math|''J''}} is a (generalized) [[ideal quotient]], {{math|1=''J''<sup>−1</sup> = (''O'' : ''J'') = <nowiki>{</nowiki> ''x'' ∈ ''K'' : ''xJ'' ⊆ ''O'' <nowiki>}</nowiki>}}.\n\nThe principal fractional ideals, meaning the ones of the form {{math|''Ox''}} where {{math|''x'' ∈ ''K''<sup>×</sup>}}, form a subgroup of the group of all non-zero fractional ideals. The quotient of the group of non-zero fractional ideals by this subgroup is the ideal class group. Two fractional ideals {{math|''I''}} and {{math|''J''}} represent the same element of the ideal class group if and only if there exists an element {{math|''x'' ∈ ''K''}} such that {{math|1=''xI'' = ''J''}}. Therefore, the ideal class group makes two fractional ideals equivalent if one is as close to being principal as the other is. The ideal class group is generally denoted {{math|Cl ''K''}}, {{math|Cl ''O''}}, or {{math|Pic ''O''}} (with the last notation identifying it with the [[Picard group]] in algebraic geometry).\n\nThe number of elements in the class group is called the '''class number''' of ''K''. The class number of {{math|'''Q'''(√{{Overline|-5}})}} is 2.  This means that there are only two ideal classes, the class of principal fractional ideals, and the class of a non-principal fractional ideal such as {{math|(2, 1 + √{{Overline|-5}})}}.\n\nThe ideal class group has another description in terms of [[divisor (algebraic geometry)|divisor]]s. These are formal objects which represent possible factorizations of numbers. The divisor group {{math|Div ''K''}} is defined to be the [[free abelian group]] generated by the prime ideals of {{math|''O''}}. There is a [[group homomorphism]] from {{math|''K''<sup>×</sup>}}, the non-zero elements of {{math|''K''}} up to multiplication, to {{math|Div ''K''}}. Suppose that {{math|''x'' ∈ ''K''}} satisfies\n:<math>(x) = \\mathfrak{p}_1^{e_1} \\cdots \\mathfrak{p}_t^{e_t}.</math>\nThen {{math|div ''x''}} is defined to be the divisor\n:<math>\\operatorname{div} x = \\sum_{i=1}^t e_i[\\mathfrak{p}_i].</math>\nThe [[kernel (algebra)|kernel]] of {{math|div}} is the group of units in {{math|''O''}}, while the [[cokernel]] is the ideal class group. In the language of [[homological algebra]], this says that there is an [[exact sequence]] of abelian groups (written multiplicatively),\n:<math>1 \\to O^\\times \\to K^\\times \\xrightarrow{\\text{div}} \\operatorname{Div} K \\to \\operatorname{Cl} K \\to 1.</math>\n\n===Real and complex embeddings===\nSome number fields, such as {{math|'''Q'''(√{{Overline|2}})}}, can be specified as subfields of the real numbers. Others, such as {{math|'''Q'''(√{{Overline|&minus;1}})}}, cannot. Abstractly, such a specification corresponds to a field homomorphism {{math|''K'' → '''R'''}} or {{math|''K'' → '''C'''}}. These are called '''real embeddings''' and '''complex embeddings''', respectively.\n\nA real quadratic field {{math|'''Q'''(√{{Overline|''a''}})}}, with {{math|''a'' ∈ '''R''', ''a'' > 0}}, and {{math|''a''}} not a [[square number|perfect square]], is so-called because it admits two real embeddings but no complex embeddings. These are the field homomorphisms which send {{math|√{{Overline|''a''}}}} to {{math|√{{Overline|''a''}}}} and to {{math|&minus;√{{Overline|''a''}}}}, respectively. Dually, an imaginary quadratic field {{math|'''Q'''(√{{Overline|&minus;''a''}})}} admits no real embeddings but admits a conjugate pair of complex embeddings. One of these embeddings sends {{math|√{{Overline|&minus;''a''}}}} to {{math|√{{Overline|&minus;''a''}}}}, while the other sends it to its [[complex conjugate]], {{math|&minus;√{{Overline|&minus;''a''}}}}.\n\nConventionally, the number of real embeddings of {{math|''K''}} is denoted {{math|''r''<sub>1</sub>}}, while the number of conjugate pairs of complex embeddings is denoted {{math|''r''<sub>2</sub>}}.  The '''signature''' of ''K'' is the pair {{math|(''r''<sub>1</sub>, ''r''<sub>2</sub>)}}. It is a theorem that {{math|1=''r''<sub>1</sub> + 2''r''<sub>2</sub> = ''d''}}, where {{math|''d''}} is the degree of {{math|''K''}}.\n\nConsidering all embeddings at once determines a function\n:<math>M \\colon K \\to \\mathbf{R}^{r_1} \\oplus \\mathbf{C}^{2r_2}.</math>\nThis is called the '''Minkowski embedding'''. The subspace of the codomain fixed by complex conjugation is a real vector space of dimension {{math|''d''}} called [[Minkowski space (number field)|Minkowski space]]. Because the Minkowski embedding is defined by field homomorphisms, multiplication of elements of {{math|''K''}} by an element {{math|''x'' ∈ ''K''}} corresponds to multiplication by a [[diagonal matrix]] in the Minkowski embedding. The dot product on Minkowski space corresponds to the trace form <math>\\langle x, y \\rangle = \\operatorname{Tr}(xy)</math>.\n\nThe image of {{math|''O''}} under the Minkowski embedding is a {{math|''d''}}-dimensional [[lattice (group)|lattice]]. If {{math|''B''}} is a basis for this lattice, then {{math|det ''B''<sup>T</sup>''B''}} is the '''discriminant''' of {{math|''O''}}. The discriminant is denoted {{math|&Delta;}} or {{math|''D''}}. The covolume of the image of {{math|''O''}} is <math>\\sqrt{|\\Delta|}</math>.\n\n===Places===\nReal and complex embeddings can be put on the same footing as prime ideals by adopting a perspective based on [[valuation (algebra)|valuation]]s. Consider, for example, the integers. In addition to the usual [[absolute value]] function |·| : '''Q''' → '''R''', there are [[p-adic absolute value]] functions |·|<sub>p</sub> : '''Q''' → '''R''', defined for each prime number ''p'', which measure divisibility by ''p''. [[Ostrowski's theorem]] states that these are all possible absolute value functions on '''Q''' (up to equivalence). Therefore, absolute values are a common language to describe both the real embedding of '''Q''' and the prime numbers.\n\nA '''place''' of an algebraic number field is an equivalence class of [[absolute value (algebra)|absolute value]] functions on ''K''. There are two types of places. There is a <math>\\mathfrak{p}</math>-adic absolute value for each prime ideal <math>\\mathfrak{p}</math> of ''O'', and, like the ''p''-adic absolute values, it measures divisibility. These are called '''finite places'''.  The other type of place is specified using a real or complex embedding of ''K'' and the standard absolute value function on '''R''' or '''C'''. These are '''infinite places'''. Because absolute values are unable to distinguish between a complex embedding and its conjugate, a complex embedding and its conjugate determine the same place. Therefore, there are {{math|''r''<sub>1</sub>}} real places and {{math|''r''<sub>2</sub>}} complex places. Because places encompass the primes, places are sometimes referred to as '''primes'''.  When this is done, finite places are called '''finite primes''' and infinite places are called '''infinite primes'''. If {{math|''v''}} is a valuation corresponding to an absolute value, then one frequently writes <math>v \\mid \\infty</math> to mean that {{math|''v''}} is an infinite place and <math>v \\nmid \\infty</math> to mean that it is a finite place.\n\nConsidering all the places of the field together produces the [[adele ring]] of the number field. The adele ring allows one to simultaneously track all the data available using absolute values. This produces significant advantages in situations where the behavior at one place can affect the behavior at other places, as in the [[Artin reciprocity law]].\n\n===Units===\nThe integers have only two units, {{math|1}} and {{math|&minus;1}}. Other rings of integers may admit more units. The Gaussian integers have four units, the previous two as well as {{math|±''i''}}. The [[Eisenstein integers]] {{math|'''Z'''[exp(2&pi;''i'' / 3)]}} have six units. The integers in real quadratic number fields have infinitely many units. For example, in {{math|'''Z'''[√{{Overline|3}}]}}, every power of {{math|2 + √{{Overline|3}}}} is a unit, and all these powers are distinct.\n\nIn general, the group of units of {{math|''O''}}, denoted {{math|''O''<sup>×</sup>}}, is a finitely generated abelian group. The [[fundamental theorem of finitely generated abelian groups]] therefore implies that it is a direct sum of a torsion part and a free part. Reinterpreting this in the context of a number field, the torsion part consists of the [[root of unity|roots of unity]] that lie in {{math|''O''}}. This group is cyclic. The free part is described by [[Dirichlet's unit theorem]]. This theorem says that rank of the free part is {{math|''r''<sub>1</sub> + ''r''<sub>2</sub> &minus; 1}}. Thus, for example, the only fields for which the rank of the free part is zero are {{math|'''Q'''}} and the imaginary quadratic fields. A more precise statement giving the structure of ''O''<sup>×</sup> ⊗<sub>'''Z'''</sub> '''Q''' as a [[Galois module]] for the Galois group of ''K''/'''Q''' is also possible.<ref>See proposition VIII.8.6.11 of {{harvnb|Neukirch|Schmidt|Wingberg|2000}}</ref>\n\nThe free part of the unit group can be studied using the infinite places of {{math|''K''}}. Consider the function\n:<math>L \\colon K^\\times \\to \\mathbf{R}^{r_1 + r_2}</math>\ndefined by\n:<math>L(x) = (\\log |x|_v)_v,</math>\nwhere {{math|''v''}} varies over the infinite places of {{math|''K''}} and |·|<sub>''v''</sub> is the absolute value associated with {{math|''v''}}. The function {{math|''L''}} is a homomorphism from {{math|''K''<sup>×</sup>}} to a real vector space. It can be shown that the image of {{math|''O''<sup>×</sup>}} is a lattice that spans the hyperplane defined by <math>x_1 + \\cdots + x_{r_1 + r_2} = 0</math>. The covolume of this lattice is the '''regulator''' of the number field. One of the simplifications made possible by working with the adele ring is that there is a single object, the [[idele class group]], that describes both the quotient by this lattice and the ideal class group.\n\n===Zeta function===\nThe [[Dedekind zeta function]] of a number field, analogous to the [[Riemann zeta function]] is an analytic object which describes the behavior of prime ideals in {{math|''K''}}. When {{math|''K''}} is an abelian extension of {{math|'''Q'''}}, Dedekind zeta functions are products of [[Dirichlet L-function]]s, with there being one factor for each [[Dirichlet character]].  The trivial character corresponds to the Riemann zeta function. When {{math|''K''}} is a [[Galois extension]], the Dedekind zeta function is the [[Artin L-function]] of the [[regular representation]] of the Galois group of {{math|''K''}}, and it has a factorization in terms of irreducible [[Artin representation]]s of the Galois group.\n\nThe zeta function is related to the other invariants described above by the [[class number formula]].\n\n===Local fields===\n{{main|Local field}}\n[[Completion (metric space)|Completing]] a number field ''K'' at a place ''w'' gives a [[complete field]]. If the valuation is archimedean, one gets '''R''' or '''C''', if it is non-archimedean and lies over a prime ''p'' of the rationals, one gets a finite extension ''K''<sub>w</sub> / '''Q'''<sub>p</sub>: a complete, discrete valued field with finite residue field. This process simplifies the arithmetic of the field and allows the local study of problems. For example, the [[Kronecker–Weber theorem]] can be deduced easily from the analogous local statement. The philosophy behind the study of local fields is largely motivated by geometric methods. In algebraic geometry, it is common to study varieties locally at a point by localizing to a maximal ideal. Global information can then be recovered by gluing together local data. This spirit is adopted in algebraic number theory. Given a prime in the ring of algebraic integers in a number field, it is desirable to study the field locally at that prime. Therefore, one localizes the ring of algebraic integers to that prime and then completes the fraction field much in the spirit of geometry.\n\n==Major results==\n\n===Finiteness of the class group===\nOne of the classical results in algebraic number theory is that the ideal class group of an algebraic number field ''K'' is finite. The order of the class group is called the [[Class number (number theory)|class number]], and is often denoted by the letter ''h''.\n\n===Dirichlet's unit theorem===\n{{Main|Dirichlet's unit theorem}}\nDirichlet's unit theorem provides a description of the structure of the multiplicative group of units ''O''<sup>×</sup> of the ring of integers ''O''. Specifically, it states that ''O''<sup>×</sup> is isomorphic to ''G'' × '''Z'''<sup>''r''</sup>, where ''G'' is the finite cyclic group consisting of all the roots of unity in ''O'', and ''r'' = ''r''<sub>1</sub>&nbsp;+&nbsp;''r''<sub>2</sub>&nbsp;−&nbsp;1 (where ''r''<sub>1</sub> (respectively, ''r''<sub>2</sub>) denotes the number of real embeddings (respectively, pairs of conjugate non-real embeddings) of ''K''). In other words, ''O''<sup>×</sup> is a [[finitely generated abelian group]] of [[Rank of an abelian group|rank]] ''r''<sub>1</sub>&nbsp;+&nbsp;''r''<sub>2</sub>&nbsp;−&nbsp;1 whose torsion consists of the roots of unity in ''O''.\n\n===Reciprocity laws===\n{{Main|Reciprocity law}}\n\nIn terms of the [[Legendre symbol]], the law of quadratic reciprocity for positive odd primes states\n:<math> \\left(\\frac{p}{q}\\right) \\left(\\frac{q}{p}\\right) = (-1)^{\\frac{p-1}{2}\\frac{q-1}{2}}.</math>\n\nA '''reciprocity law''' is a generalization of the [[law of quadratic reciprocity]].\n\nThere are several different ways to express reciprocity laws. The early reciprocity laws found in the 19th century were usually expressed in terms of a [[power residue symbol]] (''p''/''q'') generalizing the [[Legendre symbol|quadratic reciprocity symbol]],  that describes when a [[prime number]] is an ''n''th power residue [[modular arithmetic|modulo]] another prime, and gave a relation between (''p''/''q'') and (''q''/''p'').  Hilbert reformulated the reciprocity laws as saying that a product over ''p'' of Hilbert symbols (''a'',''b''/''p''), taking values in roots of unity, is equal to 1. [[Emil Artin|Artin]]'s reformulated [[Artin reciprocity law|reciprocity law]] states that the Artin symbol from ideals (or ideles) to elements of a Galois group is trivial on a certain subgroup. Several more recent generalizations express reciprocity laws using cohomology of groups or representations of adelic groups or algebraic K-groups, and their relationship with the original quadratic reciprocity law can be hard to see.\n\n===Class number formula===\n{{Main|Class number formula}}\nThe '''class number formula''' relates many important invariants of a [[number field]] to a special value of its Dedekind zeta function.\n\n==Related areas==\nAlgebraic number theory interacts with many other mathematical disciplines. It uses tools from [[homological algebra]]. Via the analogy of function fields vs. number fields, it relies on techniques and ideas from algebraic geometry. Moreover, the study of higher-dimensional schemes over '''Z''' instead of number rings is referred to as [[arithmetic geometry]]. Algebraic number theory is also used in the study of [[arithmetic hyperbolic 3-manifold]]s.\n\n==See also==\n*[[Tamagawa number]]\n*[[Kummer theory]]\n\n==Notes==\n<references/>\n* {{Neukirch et al. CNF|edition=1}}\n\n==Further reading==\n\n===Introductory texts===\n* Stein, William (2012). ''Algebraic Number Theory, A Computational Approach.'' Retrieved from https://wstein.org/books/ant/ant.pdf\n* Ireland, Kenneth and Rosen, Michael (2013). ''A classical introduction to modern number theory'' (Vol. 84). Springer Science & Business Media. {{doi|10.1007/978-1-4757-2103-4}}\n* [[Ian Stewart (mathematician)|Stewart, Ian]] and [[David Tall|Tall, David]] (2015). ''Algebraic number theory and Fermat's last theorem.'' CRC Press.\n\n===Intermediate texts===\n* Marcus, Daniel A. (1977). ''Number fields'' (Vol. 8). New York: Springer.\n\n===Graduate level texts===\n*{{Citation\n| editor-last=Cassels\n| editor-first=J. W. S.\n| editor-link=J. W. S. Cassels\n| editor2-last=Fröhlich\n| editor2-first=Albrecht\n| editor2-link=Albrecht Fröhlich\n| title=Algebraic number theory\n| year=1967\n| place=London\n| publisher=Academic Press\n| mr=0215665 \n}}\n*{{Citation\n| last=Fröhlich\n| first=Albrecht\n| author-link=Albrecht Fröhlich\n| last2=Taylor\n| first2=Martin J.\n| author2-link=Martin J. Taylor\n| title=Algebraic number theory\n| publisher=[[Cambridge University Press]]\n| year=1993\n| series=Cambridge Studies in Advanced Mathematics\n| volume=27\n| isbn=0-521-43834-9\n| mr=1215934\n}}\n*{{Citation\n| last=Lang\n| first=Serge\n| author-link=Serge Lang\n| title=Algebraic number theory\n| edition=2\n| publisher=[[Springer-Verlag]]\n| year=1994\n| series=[[Graduate Texts in Mathematics]]\n| volume=110\n| place=New York\n| isbn=978-0-387-94225-4\n| mr=1282723\n}}\n*{{Neukirch ANT}}\n\n==External links==\n*{{Commonscat-inline}}\n*{{springer|title=Algebraic number theory|id=p/a011600}}\n\n{{Number theory-footer}}\n\n[[Category:Algebraic number theory| ]]\n[[Category:Fields of mathematics]]"
    },
    {
      "title": "Arithmetic geometry",
      "url": "https://en.wikipedia.org/wiki/Arithmetic_geometry",
      "text": "{{short description|A branch of algebraic geometry focused on problems in number theory}}\n{{General geometry|branches}}\n[[File:Example of a hyperelliptic curve.svg|thumb|The [[hyperelliptic curve]] defined by <math>y^2=x(x+1)(x-3)(x+2)(x-2)</math> has only finitely many [[rational point]]s (such as the points <math>(-2, 0)</math> and <math>(-1, 0)</math>) by [[Faltings's theorem]].]]\n\nIn mathematics, '''arithmetic geometry''' is roughly the application of techniques from [[algebraic geometry]] to problems in [[number theory]].<ref>{{cite web|title=Introduction to Arithmetic Geometry|last=Sutherland|first=Andrew V.|url=https://ocw.mit.edu/courses/mathematics/18-782-introduction-to-arithmetic-geometry-fall-2013/lecture-notes/MIT18_782F13_lec1.pdf||date=September 5, 2013|accessdate=22 March 2019}}</ref> Arithmetic geometry is centered around [[Diophantine geometry]], the study of [[rational point]]s of [[algebraic variety|algebraic varieties]].<ref name=\"Quanta\">{{cite web|url=https://www.quantamagazine.org/peter-scholze-and-the-future-of-arithmetic-geometry-20160628/|title=Peter Scholze and the Future of Arithmetic Geometry|last=Klarreich|first=Erica|date=June 28, 2016|accessdate=March 22, 2019}}</ref><ref name=\"poonen-notes\">{{cite web|title=Introduction to Arithmetic Geometry|last=Poonen|first=Bjorn|authorlink=Bjorn Poonen|url=http://math.mit.edu/~poonen/782/782notes.pdf|year=2009|accessdate=March 22, 2019}}</ref>\n\nIn more abstract terms, arithmetic geometry can be defined as the study of [[scheme (mathematics)|schemes]] of [[Finite morphism#Morphisms of finite type|finite type]] over the [[spectrum of a ring|spectrum]] of the [[ring of integers]].<ref>{{nlab|id=arithmetic+geometry|title=Arithmetic geometry}}</ref>\n\n==Overview==\nThe classical objects of interest in arithmetic geometry are rational points: [[solution set|sets of solutions]] of a [[system of polynomial equations]] over [[number field]]s, [[finite field]]s, [[p-adic field]]s, or [[Algebraic function field|function field]]s, i.e. [[field (mathematics)|field]]s that are not [[algebraically closed]] excluding the [[real number]]s. Rational points can be directly characterized by [[height function]]s which measure their arithmetic complexity.<ref>{{cite book | first=Serge | last=Lang | authorlink=Serge Lang | title=Survey of Diophantine Geometry | publisher=[[Springer-Verlag]] | year=1997 | isbn=3-540-61223-8 | zbl=0869.11051 | pages=43–67 }}</ref>\n\nThe structure of algebraic varieties defined over non-algebraically-closed fields has become a central area of interest that arose with the modern abstract development of algebraic geometry. Over finite fields, [[étale cohomology]] provides [[Topological property|topological invariant]]s associated to algebraic varieties.<ref name=\"grothendieck-cohomology\"/> [[p-adic Hodge theory]] gives tools to examine when cohomological properties of varieties over the [[complex number]]s extend to those over p-adic fields.<ref>{{cite journal | last=Serre | first=Jean-Pierre | author-link=Jean-Pierre Serre | title=Résumé des cours, 1965–66 | journal=Annuaire du Collège de France | location=Paris | year=1967 | pages=49–58}}</ref>\n\n==History==\n===19th century: early arithmetic geometry===\nIn the early 19th century, [[Carl Friedrich Gauss]] observed that non-zero [[integer]] solutions to [[homogeneous polynomial]] equations with [[rational number|rational]] coefficients exist if non-zero rational solutions exist.<ref>{{cite book|title=Diophantine Equations|last=Mordell|first=Louis J.|authorlink=Louis J. Mordell|year=1969|publisher=Academic Press|isbn=978-0125062503|page=1}}</ref>\n\nIn the 1850s, [[Leopold Kronecker]] formulated the [[Kronecker–Weber theorem]], introduced the theory of [[Divisor (algebraic geometry)|divisor]]s, and made numerous other connections between number theory and [[algebra]]. He then conjectured his \"[[Kronecker's Jugendtraum|liebster Jugendtraum]]\" (\"dearest dream of youth\"), a generalization that was later put forward by Hilbert in a modified form as his [[Hilbert's problems|twelfth problem]], which outlines a goal to have number theory operate only with rings that are quotients of [[polynomial ring]]s over the integers.<ref name=\"Princeton\">{{cite book| last1 = Gowers| first1 = Timothy| last2 = Barrow-Green| first2 = June| last3 = Leader| first3 = Imre| title = The Princeton companion to mathematics| year = 2008| publisher = Princeton University Press| isbn = 978-0-691-11880-2| pages = 773–774 }}</ref>\n\n===Early-to-mid 20th century: algebraic developments and the Weil conjectures===\nIn the late 1920s, [[André Weil]] demonstrated profound connections between algebraic geometry and number theory with his doctoral work leading to the [[Mordell–Weil theorem]] which demonstrates that the set of rational points of an [[abelian variety]] is a [[finitely generated abelian group]].<ref>A. Weil, ''L'arithmétique sur les courbes algébriques'', Acta Math 52, (1929) p.&nbsp;281-315, reprinted in vol 1 of his collected papers {{isbn|0-387-90330-5}}.</ref>\n\nModern foundations of algebraic geometry were developed based on contemporary [[commutative algebra]], including [[valuation theory]] and the theory of [[ideal (ring theory)|ideals]] by [[Oscar Zariski]] and others in the 1930s and 1940s.<ref>{{cite book | last1=Zariski | first1=Oscar | author1-link=Oscar Zariski | editor1-last=Abhyankar | editor1-first=Shreeram S. | editor1-link=Shreeram Shankar Abhyankar| editor2-last=Lipman | editor2-first=Joseph | editor2-link=Joseph Lipman| editor3-last=Mumford | editor3-first=David | editor3-link=David Mumford | title=Algebraic surfaces | origyear=1935 | url=https://books.google.com/books?id=d6Zzhm9eCmgC | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=second supplemented | series=Classics in mathematics | isbn=978-3-540-58658-6 | year=2004 | mr=0469915}}</ref>\n\nIn 1949, [[André Weil]] posed the landmark [[Weil conjectures]] about the [[local zeta-function]]s of algebraic varieties over finite fields.<ref>{{cite journal | last1=Weil | first1=André | author1-link=André Weil | title=Numbers of solutions of equations in finite fields | url=http://www.ams.org/bull/1949-55-05/S0002-9904-1949-09219-4/home.html | doi=10.1090/S0002-9904-1949-09219-4  | mr=0029393 | year=1949 | journal=[[Bulletin of the American Mathematical Society]] | issn=0002-9904 | volume=55 | pages=497–508 | issue=5}} Reprinted in Oeuvres Scientifiques/Collected Papers by André Weil {{isbn|0-387-90330-5}}</ref> These conjectures offered a framework between algebraic geometry and number theory that propelled [[Alexander Grothendieck]] to recast the foundations making use of [[sheaf theory]] (together with [[Jean-Pierre Serre]]), and later scheme theory, in the 1950s and 1960s.<ref>{{cite journal | last1 = Serre | first1 = Jean-Pierre | year = 1955 | title = Faisceaux Algebriques Coherents | url = | journal = The Annals of Mathematics | volume = 61 | issue = 2| pages = 197–278 | doi=10.2307/1969915}}</ref> [[Bernard Dwork]] proved one of the four Weil conjectures (rationality of the local zeta function) in 1960.<ref>{{cite journal | last1=Dwork | first1=Bernard | author1-link=Bernard Dwork | title=On the rationality of the zeta function of an algebraic variety | jstor=2372974 | mr=0140494 | year=1960 | journal=[[American Journal of Mathematics]] | issn=0002-9327 | volume=82 | pages=631–648 | doi=10.2307/2372974 | issue=3 | publisher=American Journal of Mathematics, Vol. 82, No. 3}}</ref> Grothendieck developed étale cohomology theory to prove two of the Weil conjectures (together with [[Michael Artin]] and [[Jean-Louis Verdier]]) by 1965.<ref name=\"grothendieck-cohomology\">{{cite book | last1=Grothendieck | first1=Alexander | author1-link=Alexander Grothendieck | title=Proc. Internat. Congress Math. (Edinburgh, 1958) | publisher=[[Cambridge University Press]] | mr=0130879 | year=1960 | chapter=The cohomology theory of abstract algebraic varieties | pages=103–118|url=http://grothendieckcircle.org/}}</ref><ref>{{cite book | last1=Grothendieck | first1=Alexander | author1-link=Alexander Grothendieck | title=Séminaire Bourbaki | url=http://www.numdam.org/item?id=SB_1964-1966__9__41_0 | publisher=[[Société Mathématique de France]] | location=Paris | mr=1608788 | year=1995 | volume=9 | chapter=Formule de Lefschetz et rationalité des fonctions L | pages=41–55|origyear=1965 |ref= {{harvid|Grothendieck|1965}} }}</ref> The last of the Weil conjectures (an analogue of the [[Riemann hypothesis]]) would be finally proven in 1974 by [[Pierre Deligne]].<ref>{{cite journal | last1=Deligne | first1=Pierre | author1-link=Pierre Deligne | title=La conjecture de Weil. I | url=http://www.numdam.org/item?id=PMIHES_1974__43__273_0 | mr=0340258 | year=1974 | journal=[[Publications Mathématiques de l'IHÉS]] | issn=1618-1913 | issue=43 | pages=273–307}}</ref>\n\n===Mid-to-late 20th century: developments in modularity, p-adic methods, and beyond===\nBetween 1956 and 1957, [[Yutaka Taniyama]] and [[Goro Shimura]] posed the [[Modularity theorem|Taniyama–Shimura conjecture]] (now known as the modularity theorem) relating [[elliptic curves]] to [[modular forms]].<ref>{{cite journal|last=Taniyama|first=Yutaka |journal=Sugaku|volume=7|page=269|year=1956|title=Problem 12|language=Japanese}}</ref><ref>{{cite journal | last1=Shimura | first1=Goro | title=Yutaka Taniyama and his time. Very personal recollections | doi=10.1112/blms/21.2.186 | mr=976064 | year=1989 | journal=The Bulletin of the London Mathematical Society | issn=0024-6093 | volume=21 | issue=2 | pages=186–196}}</ref> This connection would ultimately lead to [[Wiles's proof of Fermat's Last Theorem|the first proof]] of [[Fermat's Last Theorem]] in number theory through algebraic geometry techniques of [[Lift (mathematics)|modularity lifting]] developed by [[Andrew Wiles]] in 1995.<ref name=\"wiles1995\">{{cite journal|last=Wiles|first=Andrew|authorlink=Andrew Wiles|year=1995|title=Modular elliptic curves and Fermat's Last Theorem|url=http://math.stanford.edu/~lekheng/flt/wiles.pdf|journal=Annals of Mathematics|volume=141|issue=3|pages=443–551|oclc=37032255|doi=10.2307/2118559|jstor=2118559|citeseerx=10.1.1.169.9076}}</ref>\n\nIn the 1960s, Goro Shimura introduced [[Shimura variety|Shimura varieties]] as generalizations of [[modular curve]]s.<ref>{{cite book|last=Shimura|first=Goro|title=The Collected Works of Goro Shimura|publisher=Springer Nature|isbn=978-0387954158|year=2003|}}</ref> Since the 1979, Shimura varieties have played a crucial role in the [[Langlands program]] as a natural realm of examples for testing conjectures.<ref>{{cite book|title=Automorphic Forms, Representations, and L-Functions: Symposium in Pure Mathematics|publisher=Chelsea Publishing Company|editor-last1=Borel|editor-first1=Armand|editor-link1=Armand Borel|editor-last2=Casselman|editor-first2=William|editor-link2=Bill Casselman (mathematician)|year=1979|volume=XXXIII Part 1|last=Langlands|first=Robert|authorlink=Robert Langlands|chapter-url=http://www.sunsite.ubc.ca/DigitalMathArchive/Langlands/pdf/autoreps-ps.pdf|chapter=Automorphic Representations, Shimura Varieties, and Motives. Ein Märchen|pages=205–246}}</ref>\n\nIn papers in 1977 and 1978, [[Barry Mazur]] proved the [[torsion conjecture]] giving a complete list of the possible torsion subgroups of elliptic curves over the rational numbers. Mazur's first proof of this theorem depended upon a complete analysis of the rational points on certain [[modular curve]]s.<ref>{{cite journal|last=Mazur|first=Barry|authorlink=Barry Mazur|title=Modular curves and the Eisenstein ideal|volume=47|issue=1|pages=33-186|year=1977|doi=10.1007/BF02684339|mr=0488287|journal=[[Publications Mathématiques de l'IHÉS]]|ref=harv}}</ref><ref>{{cite journal|last=Mazur|first=Barry|title=Rational isogenies of prime degree|volume=44|issue=2|pages=129-162|year=1978|doi=10.1007/BF01390348|mr=0482230|journal=[[Inventiones Mathematicae]]|others=with appendix by [[Dorian Goldfeld]]|bibcode=1978InMat..44..129M}}</ref> In 1996, the proof of the torsion conjecture was extended to all number fields by [[Loïc Merel]].<ref>{{cite journal | last1=Merel | first1=Loïc | author1link=Loïc Merel | title=Bornes pour la torsion des courbes elliptiques sur les corps de nombres | trans-title=Bounds for the torsion of elliptic curves over number fields | language=French | doi=10.1007/s002220050059 |mr=1369424 | year=1996 | journal=[[Inventiones Mathematicae]] | volume=124 | issue=1 | pages=437–449 | ref=harv| bibcode=1996InMat.124..437M }}</ref>\n\nIn 1983, [[Gerd Faltings]] proved the [[Faltings's theorem|Mordell conjecture]], demonstrating that a curve of genus greater than 1 has only finitely many rational points (where the Mordell–Weil theorem only demonstrates [[finitely generated abelian group|finite generation]] of the set of rational points as opposed to finiteness).<ref>{{cite journal |authorlink=Gerd Faltings| last=Faltings |first=Gerd |year=1983 |title=Endlichkeitssätze für abelsche Varietäten über Zahlkörpern |journal=[[Inventiones Mathematicae]] |volume=73 |issue=3 |pages=349–366 |doi=10.1007/BF01388432 | mr=0718935 | trans-title=Finiteness theorems for abelian varieties over number fields | language=de | ref=harv}}</ref><ref>{{cite journal |last=Faltings |first=Gerd |year=1984 |title=Erratum: Endlichkeitssätze für abelsche Varietäten über Zahlkörpern |journal=[[Inventiones Mathematicae]] |volume=75 |issue=2 |pages=381 |doi=10.1007/BF01388572 | mr=0732554 | language=de | ref=harv}}</ref>\n\nIn 2001, the proof of the [[Local Langlands conjectures#Local Langlands conjectures for GLn|local Langlands conjectures for GL<sub>n</sub>]] was based on the geometry of certain Shimura varieties.<ref>{{cite book |  author1-link=Michael Harris (mathematician)| last1=Harris | first1=Michael |  author2-link=Richard Taylor (mathematician)| last2=Taylor | first2=Richard | title=The geometry and cohomology of some simple Shimura varieties | url=https://books.google.com/books?id=sigBbO69hvMC | publisher=[[Princeton University Press]] | series=Annals of Mathematics Studies | isbn=978-0-691-09090-0 | mr=1876802 | year=2001 | volume=151}}</ref>\n\nIn the 2010s, [[Peter Scholze]] developed [[perfectoid space]]s and new cohomology theories in arithmetic geometry over p-adic fields with application to [[Galois representations]] and certain cases of the [[weight-monodromy conjecture]].<ref>{{cite web |title=Fields Medals 2018 |url=https://www.mathunion.org/imu-awards/fields-medal/fields-medals-2018 |publisher=[[International Mathematical Union]] |accessdate=2 August 2018}}</ref><ref>{{cite web|last=Scholze|first=Peter|url=http://www.math.uni-bonn.de/people/scholze/CDM.pdf|title=Perfectoid spaces: A survey|website=University of Bonn|accessdate=4 November 2018}}</ref>\n\n==See also==\n*[[Arithmetic of abelian varieties]]\n*[[Siegel's theorem on integral points]]\n\n==References==\n{{reflist}}\n\n{{Number theory |expanded}}\n{{Areas of mathematics | state=collapsed}}\n\n{{Authority control}}\n\n{{DEFAULTSORT:Arithmetic Geometry}}\n[[Category:Algebraic geometry]]\n[[Category:Fields of mathematics]]"
    },
    {
      "title": "Diophantine geometry",
      "url": "https://en.wikipedia.org/wiki/Diophantine_geometry",
      "text": "{{General geometry|branches}}\n{{Refimprove|date=October 2015}}\nIn mathematics, '''Diophantine geometry''' is the study of points of [[algebraic variety|algebraic varieties]] with coordinates in the [[integer]]s, [[rational number]]s, and their generalizations. These generalizations typically are [[field (mathematics)|field]]s that are not [[algebraically closed]], such as [[number field]]s, [[finite field]]s, [[Algebraic function field|function field]]s, and [[p-adic number|''p''-adic field]]s (but not the [[real number]]s which are used in [[real algebraic geometry]]). It is a sub-branch of [[arithmetic geometry]] and is one approach to the theory of [[Diophantine equation]]s, formulating questions about such equations in terms of [[algebraic geometry]].\n\nA single equation defines a [[hypersurface]], and simultaneous Diophantine equations give rise to a general [[algebraic variety]] ''V'' over ''K''; the typical question is about the nature of the set ''V''(''K'') of points on ''V'' with co-ordinates in ''K'', and by means of [[height function]]s quantitative questions about the \"size\" of these solutions may be posed, as well as the qualitative issues of whether any points exist, and if so whether there are an infinite number. Given the geometric approach, the consideration of [[homogeneous equation]]s and [[homogeneous co-ordinates]] is fundamental, for the same reasons that [[projective geometry]] is the dominant approach in algebraic geometry. Rational number solutions therefore are the primary consideration; but integral solutions (i.e. [[lattice point]]s) can be treated in the same way as an [[affine variety]] may be considered inside a projective variety that has extra [[points at infinity]].\n\nThe general approach of Diophantine geometry is illustrated by [[Faltings's theorem]] (a conjecture of [[L. J. Mordell]]) stating that an [[algebraic curve]] ''C'' of [[genus (curve)|genus]] ''g'' > 1 over the rational numbers has only finitely many [[rational point]]s. The first result of this kind may have been the theorem of Hilbert and Hurwitz dealing with the case ''g'' = 0. The theory consists both of theorems and many conjectures and open questions.\n\n==Background==\n[[Serge Lang]] published a book ''Diophantine Geometry'' in the area, in 1962. The traditional arrangement of material on Diophantine equations was by degree and number of variables, as in Mordell's ''Diophantine Equations'' (1969). Mordell's book starts with a remark on homogeneous equations ''f'' = 0 over the rational field, attributed to [[C. F. Gauss]], that non-zero solutions in integers (even primitive lattice points) exist if non-zero rational solutions do, and notes a caveat of [[L. E. Dickson]], which is about parametric solutions.<ref>{{cite book|title=Diophantine Equations|last=Mordell|first=Louis J.|authorlink=Louis J. Mordell|year=1969|publisher=Academic Press|isbn=978-0125062503|page=1}}</ref> The Hilbert–Hurwitz result from 1890 reducing the Diophantine geometry of curves of genus 0 to degrees 1 and 2 ([[conic section]]s) occurs in Chapter 17, as does Mordell's conjecture. [[Siegel's theorem on integral points]] occurs in Chapter 28. [[Mordell's theorem]] on the finite generation of the group of rational points on an [[elliptic curve]] is in Chapter 16, and integer points on the [[Mordell curve]] in Chapter 26.\n\nIn a hostile review of Lang's book, Mordell wrote\n\n{{cquote|In recent times, powerful new geometric ideas and methods have been developed by means of which important new arithmetical theorems and related results have been found and proved and some of these are not easily proved otherwise. Further, there has been a tendency to clothe the old results, their extensions, and proofs in the new geometrical language. Sometimes, however, the full implications of results are best described in a geometrical setting. Lang has these aspects very much in mind in this book, and seems to miss no opportunity for geometric presentation. This accounts for his title \"Diophantine Geometry.\"<ref>{{cite web|url=http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&id=pdf_1&handle=euclid.bams/1183526083 |title=Mordell : Review: Serge Lang, Diophantine geometry |publisher=Projecteuclid.org |date=2007-07-04 |accessdate=2015-10-07}}</ref>}}\n\nHe notes that the content of the book is largely versions of the [[Mordell–Weil theorem]], [[Thue–Siegel–Roth theorem]], Siegel's theorem, with a treatment of [[Hilbert's irreducibility theorem]] and applications (in the style of Siegel). Leaving aside issues of generality, and a completely different style, the major mathematical difference between the two books is that Lang used [[abelian varieties]] and offered a proof of Siegel's theorem, while Mordell noted that the proof \"is of a very advanced character\" (p. 263).\n\nDespite a bad press initially, Lang's conception has been sufficiently widely accepted for a 2006 tribute to call the book \"visionary\".<ref>{{cite web|author=Marc Hindry|title=''La géométrie diophantienne, selon Serge Lang''|publisher=Gazette des mathématiciens|url=http://www.math.jussieu.fr/~hindry/Lang.pdf|format=PDF|accessdate=2015-10-07}}</ref> A larger field sometimes called [[arithmetic of abelian varieties]] now includes Diophantine geometry along with [[class field theory]], [[complex multiplication]], [[local zeta-function]]s and [[L-function]]s.<ref>{{Springer|id=A/a011720|title=Algebraic varieties, arithmetic of}}</ref> [[Paul Vojta]] wrote:\n\n:While others at the time shared this viewpoint (e.g., [[André Weil|Weil]], [[John Tate|Tate]], [[Jean-Pierre Serre|Serre]]), it is easy to forget that others did not, as Mordell's review of ''Diophantine Geometry'' attests.<ref>{{cite web|url=http://www.ams.org/notices/200704/fea-lang-web.pdf |format=PDF |title=The Mathematical Contributions of Serge Lang |author1=Jay Jorgenson |author2=Steven G. Krantz |publisher=Ams.org |accessdate=2015-10-07}}</ref>\n\n==See also==\n*[[Glossary of arithmetic and Diophantine geometry]]\n\n==References==\n*{{Springer|id=d/d032630|title=Diophantine geometry}}\n\n==Notes==\n{{Reflist}}\n\n==Further reading==\n* {{cite book | first1=Alan | last1=Baker | authorlink1=Alan Baker (mathematician)| first2=Gisbert | last2= Wüstholz | authorlink2=Gisbert Wüstholz | title=Logarithmic Forms and Diophantine Geometry | series=New Mathematical Monographs | volume=9 | publisher=[[Cambridge University Press]] | year=2007 | isbn=978-0-521-88268-2 | zbl=1145.11004 }}\n* {{cite book | first1=Enrico | last1=Bombieri | authorlink1=Enrico Bombieri | first2=Walter | last2=Gubler | title=Heights in Diophantine Geometry | series=New Mathematical Monographs | volume=4 | publisher=[[Cambridge University Press]] | year=2006 | isbn=978-0-521-71229-3 | zbl=1115.11034 }}\n* {{cite book | first1=Marc | last1=Hindry | first2=Joseph H. | last2=Silverman | authorlink2=Joseph H. Silverman | title=Diophantine Geometry: An Introduction | series=[[Graduate Texts in Mathematics]] | volume=201 | year=2000 | isbn=0-387-98981-1 | zbl=0948.11023 }}\n* {{cite book | first=Serge | last=Lang | authorlink=Serge Lang | title=Survey of Diophantine Geometry | publisher=[[Springer-Verlag]] | year=1997 | isbn=3-540-61223-8 | zbl=0869.11051 }}\n\n==External links==\n*[http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&id=pdf_1&handle=euclid.bams/1183532391 Lang's review of Mordell's ''Diophantine Equations'']\n*[http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&id=pdf_1&handle=euclid.bams/1183526083 Mordell's review of Lang's ''Diophantine Geometry'']\n\n{{Number theory |expanded}}\n{{Areas of mathematics | state=collapsed}}\n\n[[Category:Diophantine geometry]]\n[[Category:Fields of mathematics]]"
    },
    {
      "title": "Mathematics Subject Classification",
      "url": "https://en.wikipedia.org/wiki/Mathematics_Subject_Classification",
      "text": "{{math|}}The '''Mathematics Subject Classification (MSC)''' is an alphanumerical [[classification scheme]] collaboratively produced by staff of, and based on the coverage of, the two major mathematical reviewing databases, [[Mathematical Reviews]] and [[Zentralblatt MATH]]. The MSC is used by many mathematics [[Academic journal|journals]], which ask authors of [[research papers]] and expository articles to list subject codes from the Mathematics Subject Classification in their papers. The current version is MSC2010.\n\n== Structure ==\n\nThe MSC is a hierarchical scheme, with three levels of structure. A classification can be two, three or five digits long, depending on how many levels of the classification scheme are used.\n\nThe first level is represented by a two-digit number, the second by a letter, and the third by another two-digit number. For example:\n\n* '''53''' is the classification for [[differential geometry]]\n* '''53A''' is the classification for classical differential geometry\n* '''53A45''' is the classification for [[Euclidean vector|vector]] and [[tensor]] analysis\n\n=== First level ===\nAt the top level, 64 mathematical disciplines are labeled with a unique two-digit number. As well as the typical areas of mathematical research, there are top-level categories for \"[[History]] and [[Biography]]\", \"[[Mathematics Education]]\", and for the overlap with different sciences. [[Physics]] (i.e. mathematical physics) is particularly well represented in the classification scheme with a number of different categories including:\n* [[Fluid mechanics]]\n* [[Quantum mechanics]]\n* [[Geophysics]]\n* [[Optics]] and [[electromagnetic theory]]\n\nAll valid MSC classification codes must have at least the first-level identifier.\n\n=== Second level ===\n\nThe second-level codes are a single letter from the Latin alphabet. These represent specific areas covered by the first-level discipline. The second-level codes vary from discipline to discipline.\n\nFor example, for differential geometry, the top-level code is '''53''', and the second-level codes are:\n* '''A''' for classical differential geometry\n* '''B''' for local differential geometry\n* '''C''' for global differential geometry\n* '''D''' for symplectic geometry and contact geometry\n\nIn addition, the special second-level code \"-\" is used for specific kinds of materials. These codes are of the form:\n\n* '''53-00''' General reference works (handbooks, dictionaries, bibliographies, etc.)\n* '''53-01''' Instructional exposition (textbooks, tutorial papers, etc.)\n* '''53-02''' Research exposition (monographs, survey articles)\n* '''53-03''' Historical (must also be assigned at least one classification number from Section 01)\n* '''53-04''' Explicit machine computation and programs (not the theory of computation or programming)\n* '''53-06''' Proceedings, conferences, collections, etc.\n\nThe second and third level of these codes are always the same - only the first level changes. For example, it is not valid to use '''53-''' as a classification. Either '''53''' on its own or, better yet, a more specific code should be used.\n\n=== Third level ===\n\nThird-level codes are the most specific, usually corresponding to a specific kind of mathematical object or a well-known problem or research area.\n\nThe third-level code 99 exists in every category and means ''none of the above, but in this section''.\n\n== Using the scheme ==\n\nThe AMS recommends that papers submitted to its journals for publication have one primary classification and one or more optional secondary classifications. A typical MSC subject class line on a research paper looks like\n\nMSC Primary 03C90; Secondary 03-02;\n\n=={{anchor|MOS|AMS Classification|MSC1990|MSC2000|MSC2010}}History==\n{{expand section|date=January 2014}}\nAccording to the [[American Mathematical Society]] (AMS) help page about MSC,<ref>[http://www.ams.org/mathscinet/help/field_help.html#mscp]</ref> the MSC has been revised a number of times since 1940. Based on a scheme to organize AMS's ''Mathematical Offprint Service'' (MOS scheme), the ''AMS Classification'' was established for the classification of reviews in ''Mathematical Reviews'' in the 1960s. It saw various ad-hoc changes. Despite its shortcomings, [[Zentralblatt für Mathematik]] started to use it as well in the 1970s. In the late 1980s, a jointly revised scheme with more formal rules was agreed upon by Mathematical Reviews and Zentralblatt für Mathematik under the new name Mathematics Subject Classification. It saw various revisions as ''MSC1990'', ''MSC2000'' and ''MSC2010''.<ref>Bernd Wegner. ''Indexierung mathematischer Literatur Die Revision der Mathematics Subject Classification MSC''. Institute of Mathematics, TU Berlin. http://fidmath.de/fileadmin/download/graz_wegner.ppt</ref> In July 2016, Mathematical Reviews and zbMATH started collecting input from the mathematical community on the next revision of MSC, which is due to be released in 2020.<ref>[https://msc2020.org Announcement of the plan to revise the Mathematics Subject Classification]</ref> The original classification of older items has not been changed. This can sometimes make it difficult to search for older works dealing with particular topics. Changes at the first level involved the subjects with (present) codes 03, 08, 12-20, 28, 37, 51, 58, 74, 90, 91, 92.\n\n== Relation to other classification schemes ==\n\nFor physics papers the [[Physics and Astronomy Classification Scheme]] (PACS) is often used. Due to the large overlap between mathematics and physics research it is quite common to see both PACS and MSC codes on research papers, particularly for multidisciplinary journals and repositories such as the [[arXiv]].\n\nThe [[ACM Computing Classification System]] (CCS) is a similar hierarchical classification scheme for [[computer science]]. There is some overlap between the AMS and ACM classification schemes, in subjects related to both mathematics and computer science, however the two schemes differ in the details of their organization of those topics.\n\nThe classification scheme used on the arXiv is chosen to reflect the papers submitted. As arXiv is multidisciplinary its classification scheme does not fit entirely with the MSC, ACM or PACS classification schemes. It is common to see codes from one or more of these schemes on individual papers.\n\n==First-level areas==\nThe top-level subjects under the MSC are, grouped here by common area names that are not part of the MSC:\n\n===General/foundations [Study of foundations of mathematics and logic]===\n*00: General (Includes topics such as [[recreational mathematics]], [[philosophy of mathematics]] and [[mathematical model]]ing.)\n*01: [[History of mathematics|History]] and [[List of mathematicians|biography]]\n*03: [[Mathematical logic]] and [[Foundations of mathematics|foundations]] (including [[model theory]], [[computability theory]], [[set theory]], [[proof theory]], and [[algebraic logic]])\n\n===Discrete mathematics/algebra [Study of structure of mathematical abstractions]===\n*05: [[Combinatorics]]\n*06: [[Order theory|Order]], lattices, ordered algebraic structures\n*08: General [[algebraic system]]s\n*11: [[Number theory]]\n*12: [[Field theory (mathematics)|Field theory]] and [[polynomial]]s \n*13: Commutative algebra ([[Commutative ring]]s and [[commutative algebra|algebras]])\n*14: [[Algebraic geometry]]\n*15: [[Linear algebra|Linear]] and [[multilinear algebra]]; [[Matrix (mathematics)|matrix theory]] \n*16: [[Associative ring]]s and [[associative algebra|(associative) algebra]]s\n*17: [[Non-associative ring]]s and [[non-associative algebra|(non-associative) algebra]]s\n*18: [[Category theory]]; [[homological algebra]]\n*19: [[K-theory|{{math|''K''}}-theory]]\n*20: [[Group theory]] and generalizations \n*22: [[Topological group]]s, [[Lie group]]s (and analysis upon them)\n\n===Analysis [Study of change and quantity]===\n*26: [[Real function]]s (including [[derivative]]s and [[integral]]s)\n*28: [[Measure (mathematics)|Measure]] and [[Integral|integration]]\n*30: [[Complex function|Functions of a complex variable]] (including [[approximation theory]] in the [[complex number|complex domain]])\n*31: [[Potential theory]] \n*32: [[Several complex variables]] and [[analytic space]]s\n*33: [[Special functions]]\n*34: [[Ordinary differential equation]]s \n*35: [[Partial differential equation]]s \n*37: [[Dynamical system]]s and [[ergodic theory]] \n*39: [[Difference equation|Difference (equations)]] and [[functional equation]]s \n*40: [[Sequence]]s, [[series (mathematics)|series]], [[summability]] \n*41: [[Approximation theory|Approximations]] and [[Expansion (approximation theory)|expansions]]\n*42: [[Harmonic analysis]] on Euclidean spaces (including [[Fourier analysis]], [[Fourier transform]]s, [[trigonometric approximation]], [[trigonometric interpolation]], and [[orthogonal function]]s)\n*43: Abstract [[harmonic analysis]] \n*44: [[Integral transform]]s, [[operational calculus]] \n*45: [[Integral equation]]s   \n*46: [[Functional analysis]] (including [[infinite-dimensional holomorphy]], [[integral transform]]s in [[distribution space]]s)\n*47: [[Operator theory]] \n*49: [[Calculus of variations]] and [[optimal control]]; [[Optimization (mathematics)|optimization]] (including [[geometric integration theory]])\n\n===Geometry and topology [Study of space]===\n*51: [[Geometry]] \n*52: [[Convex geometry|Convex (geometry)]] and [[discrete geometry]]\n*53: [[Differential geometry]] \n*54: [[General topology]] \n*55: [[Algebraic topology]] \n*57: [[Manifold]]s and cell complexes\n*58: [[Global analysis]], [[analysis on manifolds]] (including [[infinite-dimensional holomorphy]])\n\n===[[Applied mathematics]] / other [Study of applications of mathematical abstractions]===\n*60: [[Probability theory]] and [[stochastic processes]]\n*62: [[Statistics]]\n*65: [[Numerical analysis]]\n*68: [[Computer science]]\n*70: [[Mechanics]] of particles and systems (including [[particle mechanics]])\n*74: [[Mechanics of deformable solids]] \n*76: [[Fluid mechanics]]\n*78: [[Optics]], [[electromagnetic theory]] \n*80: Classical [[thermodynamics]], [[heat transfer]]\n*81: [[Quantum mechanics|Quantum theory]]\n*82: [[Statistical mechanics]], structure of matter\n*83: [[Theory of relativity|Relativity]] and [[gravitational theory]] (including [[relativistic mechanics]]) \n*85: [[Astronomy]] and [[astrophysics]]\n*86: [[Geophysics]]\n*90: [[Operations research]], [[mathematical programming]] \n*91: [[Game theory]], [[mathematical economics|economics]], [[mathematical sociology|social]] and [[mathematical psychology|behavioral sciences]]\n*92: [[Biology]] and other [[natural science]]s\n*93: [[Systems theory]]; control (including [[optimal control]])\n*94: [[Information]] and [[communication]], [[electrical network|circuits]]\n*97: [[Mathematics education]]\n\n==See also==\n{{Wikidata property|P3285}}\n* [[Areas of mathematics]]\n* [[Mathematical knowledge management]]\n* [[MathSciNet]]\n\n==References==\n{{reflist}}\n\n==External links==\n*[http://msc2010.org/mscwiki/index.php?title=MSC2010 Mathematics Subject Classification 2010] The site where the MSC2010 revision was carried out publicly in an MSCwiki.  A view of the whole scheme and the changes made from MSC2000, as well as PDF files of the MSC and ancillary documents are there.  A personal copy of the MSC in [[TiddlyWiki]] form can be had also.\n*The [[American Mathematical Society]] page on [http://www.ams.org/msc/ the Mathematics Subject Classification].\n*The [[Zentralblatt MATH]] page on the [https://zbmath.org/classification/ Mathematics Subject Classification].\n*{{cite web |last1=Rusin |first1=Dave |title=A Gentle Introduction to the Mathematics Subject Classification Scheme |url=http://www.math.niu.edu/~rusin/known-math/index/beginners.html |website= <!-- https://web.archive.org/web/20150616152045/http://www.math-atlas.org/ --> Mathematical Atlas |archiveurl=https://web.archive.org/web/20150516045812/http://www.math.niu.edu/~rusin/known-math/index/beginners.html |archivedate=2015-05-16}}\n\n[[Category:Fields of mathematics]]\n[[Category:Classification systems]]"
    },
    {
      "title": "Physical mathematics",
      "url": "https://en.wikipedia.org/wiki/Physical_mathematics",
      "text": "The subject of '''physical mathematics''' is concerned with physically motivated mathematics and is different from [[mathematical physics]]. The ''Journal of Physical Mathematics''<ref>{{cite web|url=https://projecteuclid.org/euclid.jpm |title=Publication Information |website=Projecteuclid.org |date= |accessdate=2016-04-03}}</ref> is an important journal in the field.\n\nString theorist [[Greg Moore (physicist)|Greg Moore]] said this about physical mathematics in his vision talk at Strings 2014.<ref>{{cite web|url=http://www.physics.rutgers.edu/~gmoore/PhysicalMathematicsAndFuture.pdf |format=PDF |title=Physical Mathematics and the Future\n|author=Gregory W. Moore |website=Physics.rutgers.edu |accessdate=2016-04-03}}</ref>\n{{quote|\"The use of the term “Physical Mathematics” in contrast to the more traditional “[[Mathematical Physics]]” by myself and others is not meant to detract from the venerable subject of Mathematical Physics but rather to delineate a smaller subfield characterized by questions and goals that are often motivated, on the physics side, by [[quantum gravity]], [[string theory]], and [[supersymmetry]], (and more recently by the notion of [[topological phase]]s in [[condensed matter physics]]), and, on the mathematics side, often involve deep relations to infinite-dimensional [[Lie algebra]]s (and groups), [[topology]], [[geometry]], and even [[analytic number theory]], in addition to the more traditional relations of physics to algebra, [[group theory]], and analysis.\"}}\n\n==See also==\n* [[Theoretical physics]]\n\n==References==\n{{Reflist}}\n*[[Eric Zaslow]], Physmatics, {{arxiv|physics/0506153}}\n*[[Arthur Jaffe]], [[Frank Quinn (mathematician)|Frank Quinn]], ``Theoretical mathematics``: Toward a cultural synthesis of mathematics and theoretical physics, Bull. Am. Math. Soc. 30: 178-207, 1994, {{arXiv|math/9307227}}\n*[[Michael Atiyah]] et al., Responses to ``Theoretical Mathematics: Toward a cultural synthesis of mathematics and theoretical physics``, by A. Jaffe and F. Quinn, Bull. Am. Math. Soc. 30: 178-207, 1994, {{arXiv|math/9404229}}\n*Michael Stöltzner, Theoretical Mathematics: On the Philosophical Significance of the Jaffe-Quinn Debate, in: The Role of Mathematics in Physical Sciences pp 197-222, {{doi|10.1007/1-4020-3107-6_13}}\n\n[[Category:Fields of mathematics]]\n[[Category:Mathematical physics]]\n\n{{applied-math-stub}}"
    },
    {
      "title": "Pure mathematics",
      "url": "https://en.wikipedia.org/wiki/Pure_mathematics",
      "text": "{{short description|Mathematics studies that are independent of any application outside mathematics}}\n[[File:E8Petrie.svg|thumb|251x251px|Pure mathematics studies the properties and structure of abstract objects, such as the [[E8 (mathematics)|E8 group]], in [[group theory]]. This may be done without focusing on concrete applications of the concepts in the physical world]]\n'''Pure mathematics''' is the study of mathematical concepts independently of any application outside [[mathematics]]. These concepts may originate in real-world concerns, and the results obtained may later turn out to be useful for practical applications, but the pure mathematicians are not primarily motivated by such applications. Instead, the appeal is attributed to the intellectual challenge and aesthetic beauty of working out the logical consequences of basic principles.\n\nWhile pure mathematics has existed as an activity since at least [[Ancient Greece]], the concept was elaborated upon around the year 1900,<ref>{{MacTutor|id=Sadleirian_Professors|title=Sadleirian Professors|last=Piaggio|first=H. T. H.|class=Extras}}</ref> after the introduction of theories with counter-intuitive properties (such as [[non-Euclidean geometries]] and [[Georg Cantor|Cantor's]] theory of infinite sets), and the discovery of apparent paradoxes (such as [[continuous function]]s that are nowhere [[differentiable function|differentiable]], and [[Russell's paradox]]). This introduced the need of renewing the concept of [[mathematical rigor]] and rewriting all mathematics accordingly, with a systematic use of [[axiomatic method]]s. This led many mathematicians to focus on mathematics for its own sake, that is, pure mathematics.\n\nNevertheless, almost all mathematical theories remained motivated by problems coming from the real world or from less abstract mathematical theories. Also, many mathematical theories, which had seemed to be totally pure mathematics, were eventually used in applied areas, mainly [[physics]] and [[computer science]]. A famous early example is [[Isaac Newton]]'s demonstration that his [[law of universal gravitation]] implied that [[planet]]s move in orbits that are [[conic section]]s, geometrical curves that had been studied in antiquity by [[Apollonius of Perga|Apollonius]]. Another example is the problem of [[factorization|factoring]] large [[integer]]s, which is the basis of the [[RSA cryptosystem]], widely used to secure [[internet]] communications.<ref>{{cite journal |url=http://www.msri.org/people/members/sara/articles/rsa.pdf |journal=SIAM News |volume=36 |issue=5 |date=June 2003 |title=Still Guarding Secrets after Years of Attacks, RSA Earns Accolades for its Founders |first=Sara |last=Robinson }}</ref>\n\nIt follows that, presently, the distinction between pure and [[applied mathematics|applied]] mathematics is more a philosophical point of view or a mathematician's preference than a rigid subdivision of mathematics. In particular, it is not uncommon that some members of a department of applied mathematics describe themselves as pure mathematicians.\n\n==History==\n\n===Ancient Greece===\nAncient Greek mathematicians were among the earliest to make a distinction between pure and applied mathematics. [[Plato]] helped to create the gap between \"arithmetic\", now called [[number theory]], and \"logistic\", now called [[arithmetic]]. Plato regarded logistic (arithmetic) as appropriate for businessmen and men of war who \"must learn the art of numbers or [they] will not know how to array [their] troops\" and arithmetic (number theory) as appropriate for philosophers \"because [they have] to arise out of the sea of change and lay hold of true being.\"<ref>{{cite book|first=Carl B. |last=Boyer |authorlink=Carl Benjamin Boyer |title=A History of Mathematics |edition=Second |publisher=John Wiley & Sons, Inc. |year=1991 |isbn=0-471-54397-7|chapter=The age of Plato and Aristotle|pages=86|quote=Plato is important in the history of mathematics largely for his role as inspirer and director of others, and perhaps to him is due the sharp distinction in ancient Greece between arithmetic (in the sense of the theory of numbers) and logistic (the technique of computation). Plato regarded logistic as appropriate for the businessman and for the man of war, who \"must learn the art of numbers or he will not know how to array his troops.\" The philosopher, on the other hand, must be an arithmetician \"because he has to arise out of the sea of change and lay hold of true being.\"}}</ref> [[Euclid of Alexandria]], when asked by one of his students of what use was the study of geometry, asked his slave to give the student threepence, \"since he must make gain of what he learns.\"<ref>{{cite book|first=Carl B. |last=Boyer |authorlink=Carl Benjamin Boyer |title=A History of Mathematics |edition=Second |publisher=John Wiley & Sons, Inc. |year=1991 |isbn=0-471-54397-7|chapter=Euclid of Alexandria |pages=101 |quote=Evidently Euclid did not stress the practical aspects of his subject, for there is a tale told of him that when one of his students asked of what use was the study of geometry, Euclid asked his slave to give the student threepence, \"since he must make gain of what he learns.\"}}</ref> The Greek mathematician [[Apollonius of Perga]] was asked about the usefulness of some of his theorems in Book IV of ''Conics'' to which he proudly asserted,<ref name=\"Apollonius\">{{cite book|first=Carl B. |last=Boyer |authorlink=Carl Benjamin Boyer |title=A History of Mathematics |edition=Second |publisher=John Wiley & Sons, Inc. |year=1991 |isbn=0-471-54397-7|chapter=Apollonius of Perga|pages=152|quote=It is in connection with the theorems in this book that Apollonius makes a statement implying that in his day, as in ours, there were narrow-minded opponents of pure mathematics who pejoratively inquired about the usefulness of such results. The author proudly asserted: \"They are worthy of acceptance for the sake of the demonstrations themselves, in the same way as we accept many other things in mathematics for this and for no other reason.\" (Heath 1961, p.lxxiv).<BR>The preface to Book V, relating to maximum and minimum straight lines drawn to a conic, again argues that the subject is one of those that seem \"worthy of study for their own sake.\" While one must admire the author for his lofty intellectual attitude, it may be pertinently pointed out that s day was beautiful theory, with no prospect of applicability to the science or engineering of his time, has since become fundamental in such fields as terrestrial dynamics and celestial mechanics.}}</ref>\n<blockquote>They are worthy of acceptance for the sake of the demonstrations themselves, in the same way as we accept many other things in mathematics for this and for no other reason.</blockquote>\nAnd since many of his results were not applicable to the science or engineering of his day, Apollonius further argued in the preface of the fifth book of ''Conics'' that the subject is one of those that \"...seem worthy of study for their own sake.\"<ref name=\"Apollonius\" />\n\n===19th century===\nThe term itself is enshrined in the full title of the [[Sadleirian Professor of Pure Mathematics|Sadleirian Chair]], '''Sadleirian Professor of Pure Mathematics''', founded (as a professorship) in the mid-nineteenth century. The idea of a separate discipline of ''pure'' mathematics may have emerged at that time. The generation of [[Carl Friedrich Gauss|Gauss]] made no sweeping distinction of the kind, between ''pure'' and ''applied''. In the following years, specialisation and professionalisation (particularly in the [[Weierstrass]] approach to [[mathematical analysis]]) started to make a rift more apparent.\n\n===20th century===\nAt the start of the twentieth century mathematicians took up the [[axiomatic method]], strongly influenced by [[David Hilbert]]'s example. The logical formulation of '''pure mathematics''' suggested by [[Bertrand Russell]] in terms of a [[Quantifier (logic)|quantifier]] structure of [[Proposition (mathematics)|proposition]]s seemed more and more plausible, as large parts of mathematics became axiomatised and thus subject to the simple criteria of ''[[rigorous proof]]''.\n\nPure mathematics, according to a view that can be ascribed to the [[Bourbaki group]], is what is proved. '''Pure mathematician''' became a recognized vocation, achievable through training.\n\nThe case was made that pure mathematics is useful in [[engineering education]]:<ref>[[A. S. Hathaway]] (1901) [http://www.ams.org/journals/bull/1901-07-06/S0002-9904-1901-00797-5/S0002-9904-1901-00797-5.pdf \"Pure mathematics for engineering students\"], [[Bulletin of the American Mathematical Society]] 7(6):266–71.</ref>\n\n:There is a training in habits of thought, points of view, and intellectual comprehension of ordinary engineering problems, which only the study of higher mathematics can give.\n\n==Generality and abstraction==\n[[File:Banach-Tarski Paradox.svg|thumbnail|right|350px|An illustration of the [[Banach–Tarski paradox]], a famous result in pure mathematics. Although it is proven that it is possible to convert one sphere into two using nothing but cuts and rotations, the transformation involves objects that cannot exist in the physical world.]]\nOne central concept in pure mathematics is the idea of generality; pure mathematics often exhibits a trend towards increased generality. Uses and advantages of generality include the following:\n\n* Generalizing theorems or mathematical structures can lead to deeper understanding of the original theorems or structures\n* Generality can simplify the presentation of material, resulting in shorter proofs or arguments that are easier to follow.\n* One can use generality to avoid duplication of effort, proving a general result instead of having to prove separate cases independently, or using results from other areas of mathematics.\n* Generality can facilitate connections between different branches of mathematics. [[Category theory]] is one area of mathematics dedicated to exploring this commonality of structure as it plays out in some areas of math.\n\nGenerality's impact on [[intuition (knowledge)|intuition]] is both dependent on the subject and a matter of personal preference or learning style.  Often generality is seen as a hindrance to intuition, although it can certainly function as an aid to it, especially when it provides analogies to material for which one already has good intuition.\n\nAs a prime example of generality, the [[Erlangen program]] involved an expansion of [[geometry]] to accommodate [[non-Euclidean geometries]] as well as the field of [[topology]], and other forms of geometry, by viewing geometry as the study of a space together with a [[Group (mathematics)|group]] of transformations.  The study of [[number]]s, called [[algebra]] at the beginning undergraduate level, extends to [[abstract algebra]] at a more advanced level; and the study of [[function (mathematics)|function]]s, called [[calculus]] at the college freshman level becomes [[mathematical analysis]] and [[functional analysis]] at a more advanced level.  Each of these branches of more ''abstract'' mathematics have many sub-specialties, and there are in fact many connections between pure mathematics and applied mathematics disciplines. A steep rise in [[abstraction]] was seen mid 20th century.\n\nIn practice, however, these developments led to a sharp divergence from [[physics]], particularly from 1950 to 1983. Later this was criticised, for example by [[Vladimir Arnold]], as too much [[David Hilbert|Hilbert]], not enough [[Henri Poincaré|Poincaré]]. The point does not yet seem to be settled, in that [[string theory]] pulls one way, while [[discrete mathematics]] pulls back towards proof as central.\n\n==Purism==\nMathematicians have always had differing opinions regarding the distinction between pure and applied mathematics. \nOne of the most famous (but perhaps misunderstood) modern examples of this debate can be found in [[G.H. Hardy]]'s ''[[A Mathematician's Apology]]''.\n\nIt is widely believed that Hardy considered applied mathematics to be ugly and dull. Although it is true that Hardy preferred pure mathematics, which he often compared to [[painting]] and [[poetry]], Hardy saw the distinction between pure and applied mathematics to be simply that applied mathematics sought to express ''physical'' truth in a mathematical framework, whereas pure mathematics expressed truths that were independent of the physical world. Hardy made a separate distinction in mathematics between what he called \"real\" mathematics, \"which has permanent aesthetic value\", and \"the dull and elementary parts of mathematics\" that have practical use.\n\nHardy considered some physicists, such as [[Albert Einstein|Einstein]], and [[Paul Dirac|Dirac]], to be among the \"real\" mathematicians, but at the time that he was writing the ''Apology'' he also considered [[general relativity]] and [[quantum mechanics]] to be \"useless\", which allowed him to hold the opinion that only \"dull\" mathematics was useful. Moreover, Hardy briefly admitted that—just as the application of [[matrix theory]] and [[group theory]] to physics had come unexpectedly—the time may come where some kinds of beautiful, \"real\" mathematics may be useful as well.\n\nAnother insightful view is offered by Magid:\n{{quote|I've always thought that a good model here could be drawn from ring theory. In that subject, one has the subareas of [[commutative ring|commutative ring theory]] and [[non-commutative ring|non-commutative ring theory]]. An uninformed observer might think that these represent a dichotomy, but in fact the latter subsumes the former: a non-commutative ring is a not-necessarily-commutative ring. If we use similar conventions, then we could refer to applied mathematics and nonapplied mathematics, where by the latter we ''mean not-necessarily-applied mathematics''... [emphasis added]<ref name=Magid>[[Andy Magid]] (November 2005) [http://www.ams.org/notices/200510/commentary.pdf Letter from the Editor], [[Notices of the American Mathematical Society]], page 1173</ref>}}\n\n==See also==\n*[[Applied mathematics]]\n*[[Logic]]\n*[[Metalogic]]\n*[[Metamathematics]]\n\n==References==\n{{reflist|2}}\n\n==External links==\n{{Wikiquote}}\n*[https://uwaterloo.ca/pure-mathematics/about-pure-math/what-is-pure-math ''What is Pure Mathematics?''] – Department of Pure Mathematics, University of Waterloo\n*[http://www.liv.ac.uk/maths/PURE/wipm.html '' What is Pure Mathematics?''] by Professor P. J. Giblin The University of Liverpool\n*[http://fair-use.org/bertrand-russell/the-principles-of-mathematics ''The Principles of Mathematics''] by [[Bertrand Russell]]\n*[http://hk.mathphy.googlepages.com/puremath.htm How to Become a Pure Mathematician (or Statistician)], a list of undergraduate and basic graduate textbooks and lecture notes, with several comments and links to solutions, companion sites, data sets, errata pages, etc.\n\n{{Areas of mathematics | state=collapsed}}\n\n{{DEFAULTSORT:Pure Mathematics}}\n[[Category:Fields of mathematics]]\n[[Category:Abstraction]]"
    },
    {
      "title": "Algebra",
      "url": "https://en.wikipedia.org/wiki/Algebra",
      "text": "{{for|the kind of algebraic structure|Algebra over a field}}\n{{pp-move-indef}}\n{{pp-semi-indef}}\n\n[[File:Quadratic formula.svg|thumb|The [[quadratic formula]] expresses the solution of the equation {{math|1=''ax''<sup>2</sup> + ''bx'' + ''c'' = 0}}, where {{mvar|a}} is not zero, in terms of its coefficients {{math|''a'', ''b''}} and {{mvar|c}}.]]\n\n'''Algebra''' (from [[Arabic]] ''\"al-jabr\"'', literally meaning \"reunion of broken parts\"<ref name=oed>{{cite web|title=algebra|url=http://www.oxforddictionaries.com/us/definition/english/algebra|work=Oxford English Dictionary|publisher=Oxford University Press}}</ref>) is one of the [[areas of mathematics|broad parts]] of [[mathematics]], together with [[number theory]], [[geometry]] and [[mathematical analysis|analysis]]. In its most general form, algebra is the study of [[mathematical symbol]]s and the rules for manipulating these symbols;<ref>See {{harv|Herstein|1964}}, page 1: \"An algebraic system can be described as a set of objects together with some operations for combining them\".</ref> it is a unifying thread of almost all of mathematics.<ref>See {{harv|Herstein|1964}} , page 1: \"...it also serves as the unifying thread which interlaces almost all of mathematics\".</ref> It includes everything from elementary equation solving to the study of abstractions such as [[group (mathematics)|groups]], [[ring (mathematics)|rings]], and [[field (mathematics)|fields]]. The more basic parts of algebra are called [[elementary algebra]]; the more abstract parts are called [[abstract algebra]] or modern algebra. Elementary algebra is generally considered to be essential for any study of mathematics, science, or engineering, as well as such applications as medicine and economics. Abstract algebra is a major area in advanced mathematics, studied primarily by professional mathematicians.\n\nElementary algebra differs from [[arithmetic]] in the use of abstractions, such as using letters to stand for numbers that are either unknown or allowed to take on many values.<ref name=citeboyer /> For example, in <math>x + 2 = 5</math> the letter <math>x</math> is unknown, but applying [[additive inverse]]s can reveal its value: <math>x=3</math>. In [[E=mc2|{{math|1=''E'' = ''mc''{{smallsup|2}}}}]], the letters <math>E</math> and <math>m</math> are variables, and the letter <math>c</math> is a [[Constant (mathematics)|constant]], the speed of light in a vacuum. Algebra gives methods for writing formulas and solving equations that are much clearer and easier than the older method of writing everything out in words.\n\nThe word ''algebra'' is also used in certain specialized ways. A special kind of mathematical object in abstract algebra is called an \"algebra\", and the word is used, for example, in the phrases [[linear algebra]] and [[algebraic topology]].\n\nA mathematician who does research in algebra is called an '''algebraist'''.\n\n== Etymology ==\n[[File:Muḥammad ibn Mūsā al-Khwārizmī.png|thumb|180px|The name of ''algebra'' comes from the title of a book by [[Muhammad ibn Musa al-Khwarizmi]]<ref>Esposito, John L. (2000-04-06). ''The Oxford History of Islam''. Oxford University Press. p. 188. {{ISBN|978-0-19-988041-6}}.</ref>]]\nThe word ''algebra'' comes from the [[Arabic language|Arabic]] {{lang|ar|الجبر}} (''{{transl|ar|al-jabr}}'' lit. \"the reunion of broken parts\") from the title of the book ''[[The Compendious Book on Calculation by Completion and Balancing|Ilm al-jabr wa'l-muḳābala]]'' by the [[Persian people|Persian]] mathematician and astronomer [[Muḥammad ibn Mūsā al-Khwārizmī|al-Khwarizmi]]. The word entered the English language during the fifteenth century, from either Spanish, Italian, or [[Medieval Latin]]. It originally referred to the surgical procedure of setting broken or dislocated bones. The mathematical meaning was first recorded in the sixteenth century.<ref>{{cite encyclopedia|title=Algebra|editor=T.F. Hoad|encyclopedia=The Concise Oxford Dictionary of English Etymology|publisher=Oxford University Press|location=Oxford|year= 2003|url=http://www.oxfordreference.com/view/10.1093/acref/9780192830982.001.0001/acref-9780192830982-e-349|url-access=subscription|doi=10.1093/acref/9780192830982.001.0001|isbn=978-0-19-283098-2}}</ref>\n\n== Different meanings of \"algebra\" ==\nThe word \"algebra\" has several related meanings in mathematics, as a single word or with qualifiers.\n* As a single word without an article, \"algebra\" names a broad part of mathematics.\n* As a single word with an article or in plural, \"an algebra\" or \"algebras\" denotes a specific mathematical structure, whose precise definition depends on the author. Usually, the structure has an addition, multiplication, and a scalar multiplication (see [[Algebra over a field]]). When some authors use the term \"algebra\", they make a subset of the following additional assumptions: [[Associative property|associative]], [[Commutative property|commutative]], [[Unital algebra|unital]], and/or finite-dimensional. In [[universal algebra]], the word \"algebra\" refers to a generalization of the above concept, which allows for [[Operation (mathematics)|n-ary operations]].\n* With a qualifier, there is the same distinction:\n** Without an article, it means a part of algebra, such as [[linear algebra]], [[elementary algebra]] (the symbol-manipulation rules taught in elementary courses of mathematics as part of [[primary education|primary]] and [[secondary education]]), or [[abstract algebra]] (the study of the algebraic structures for themselves).\n** With an article, it means an instance of some abstract structure, like a [[Lie algebra]], an [[associative algebra]], or a [[vertex operator algebra]].\n** Sometimes both meanings exist for the same qualifier, as in the sentence: ''[[Commutative algebra]] is the study of [[commutative ring]]s, which are [[algebra (ring theory)|commutative algebras]] over the integers''.\n\n== Algebra as a branch of mathematics ==\n\nAlgebra began with computations similar to those of [[arithmetic]], with letters standing for numbers.<ref name=citeboyer /> This allowed proofs of properties that are true no matter which numbers are involved. For example, in the [[quadratic equation]]\n:<math>ax^2+bx+c=0,</math>\n<math>a, b, c</math> can be any numbers whatsoever (except that <math>a</math> cannot be <math>0</math>), and the [[quadratic formula]] can be used to quickly and easily find the values of the unknown quantity <math>x</math> which satisfy the equation. That is to say, to find all the solutions of the equation.\n\nHistorically, and in current teaching, the study of algebra starts with the solving of equations such as the [[quadratic equation]] above. Then more general questions, such as \"does an equation have a solution?\", \"how many solutions does an equation have?\", \"what can be said about the nature of the solutions?\" are considered. These questions led extending algebra to non-numerical objects, such as [[permutation]]s, [[vector (mathematics)|vectors]], [[matrix (mathematics)|matrices]], and [[polynomial]]s. The structural properties of these non-numerical objects were then abstracted into [[algebraic structure]]s such as [[group (mathematics)|groups]], [[ring (mathematics)|rings]], and [[field (mathematics)|fields]].\n\nBefore the 16th century, mathematics was divided into only two subfields, [[arithmetic]] and [[geometry]]. Even though some methods, which had been developed much earlier, may be considered nowadays as algebra, the emergence of algebra and, soon thereafter, of [[infinitesimal calculus]] as subfields of mathematics only dates from the 16th or 17th century. From the second half of 19th century on, many new fields of mathematics appeared, most of which made use of both arithmetic and geometry, and almost all of which used algebra.\n\nToday, algebra has grown until it includes many branches of mathematics, as can be seen in the [[Mathematics Subject Classification]]<ref>{{cite web|url=http://www.ams.org/mathscinet/msc/msc2010.html|title=2010 Mathematics Subject Classification|access-date=2014-10-05}}</ref>\nwhere none of the first level areas (two digit entries) is called ''algebra''. Today algebra includes section 08-General algebraic systems, 12-[[Field theory (mathematics)|Field theory]] and [[polynomial]]s, 13-[[Commutative algebra]], 15-[[Linear algebra|Linear]] and [[multilinear algebra]]; [[matrix theory]], 16-[[associative algebra|Associative rings and algebras]], 17-[[Nonassociative ring]]s and [[Non-associative algebra|algebras]], 18-[[Category theory]]; [[homological algebra]], 19-[[K-theory]] and 20-[[Group theory]]. Algebra is also used extensively in 11-[[Number theory]] and 14-[[Algebraic geometry]].\n\n== History ==\n{{Main|History of algebra|Timeline of algebra}}\n\n=== Early history of algebra ===\n\n[[File:Image-Al-Kitāb al-muḫtaṣar fī ḥisāb al-ğabr wa-l-muqābala.jpg|thumb|A page from [[:en:Muhammad ibn Musa al-Khwarizmi|Al-Khwārizmī]]'s ''[[The Compendious Book on Calculation by Completion and Balancing|al-Kitāb al-muḫtaṣar fī ḥisāb al-ğabr wa-l-muqābala]]'']]\n\nThe roots of algebra can be traced to the ancient [[Babylonian mathematics|Babylonians]],<ref>{{cite book |last=Struik |first=Dirk J. |year=1987 |title=A Concise History of Mathematics |location=New York |publisher=Dover Publications |isbn=978-0-486-60255-4 }}</ref> who developed an advanced arithmetical system with which they were able to do calculations in an [[algorithm]]ic fashion. The Babylonians developed formulas to calculate solutions for problems typically solved today by using [[linear equation]]s, [[quadratic equation]]s, and [[indeterminate equation|indeterminate linear equations]]. By contrast, most [[Egyptian mathematics|Egyptians]] of this era, as well as [[Greek mathematics|Greek]] and [[Chinese mathematics]] in the 1st millennium BC, usually solved such equations by geometric methods, such as those described in the ''[[Rhind Mathematical Papyrus]]'', [[Euclid's Elements|Euclid's ''Elements'']], and ''[[The Nine Chapters on the Mathematical Art]]''. The geometric work of the Greeks, typified in the ''Elements'', provided the framework for generalizing formulae beyond the solution of particular problems into more general systems of stating and solving equations, although this would not be realized until [[Mathematics in medieval Islam|mathematics developed in medieval Islam]].<ref>See {{harv|Boyer|1991}}.</ref>\n\nBy the time of [[Plato]], Greek mathematics had undergone a drastic change. The Greeks created a [[Greek geometric algebra|geometric algebra]] where terms were represented by sides of geometric objects, usually lines, that had letters associated with them.<ref name=citeboyer>See {{harv|Boyer|1991}}, ''Europe in the Middle Ages'', p. 258: \"In the arithmetical theorems in Euclid's ''Elements'' VII–IX, numbers had been represented by line segments to which letters had been attached, and the geometric proofs in al-Khwarizmi's ''Algebra'' made use of lettered diagrams; but all coefficients in the equations used in the ''Algebra'' are specific numbers, whether represented by numerals or written out in words. The idea of generality is implied in al-Khwarizmi's exposition, but he had no scheme for expressing algebraically the general propositions that are so readily available in geometry.\"</ref> [[Diophantus]] (3rd century AD) was an [[Alexandria]]n Greek mathematician and the author of a series of books called ''[[Arithmetica]]''. These texts deal with solving [[algebraic equation]]s,<ref>{{cite book |author-link=Florian Cajori |first=Florian |last=Cajori |year=2010 |url=https://books.google.com/?id=gZ2Us3F7dSwC&pg=PA34&dq#v=onepage&q=&f=false |title=A History of Elementary Mathematics – With Hints on Methods of Teaching |page=34 |isbn=978-1-4460-2221-4 }}</ref> and have led, in [[number theory]] to the modern notion of [[Diophantine equation]].\n\nEarlier traditions discussed above had a direct influence on the [[Persian people|Persian]] mathematician Muḥammad ibn Mūsā al-Khwārizmī (c. 780–850). He later wrote ''[[The Compendious Book on Calculation by Completion and Balancing]]'', which established algebra as a mathematical discipline that is independent of [[geometry]] and [[arithmetic]].<ref>{{Cite book|title=Al Khwarizmi: The Beginnings of Algebra|author=Roshdi Rashed|publisher=Saqi Books|date=November 2009|isbn=978-0-86356-430-7}}</ref>\n\nThe [[Hellenistic civilization|Hellenistic]] mathematicians [[Hero of Alexandria]] and Diophantus<ref>{{cite web|url=http://library.thinkquest.org/25672/diiophan.htm |title=Diophantus, Father of Algebra |access-date=2014-10-05 |deadurl=yes |archiveurl=https://web.archive.org/web/20130727040815/http://library.thinkquest.org/25672/diiophan.htm |archive-date=2013-07-27}}</ref> as well as [[Indian mathematics|Indian mathematicians]] such as [[Brahmagupta]] continued the traditions of Egypt and Babylon, though Diophantus' ''Arithmetica'' and Brahmagupta's ''[[Brāhmasphuṭasiddhānta]]'' are on a higher level.<ref>{{cite web|url=http://www.algebra.com/algebra/about/history/|title=History of Algebra |access-date=2014-10-05}}</ref>{{Better source|date=October 2017}} For example, the first complete arithmetic solution (including zero and negative solutions) to quadratic equations was described by Brahmagupta in his book ''Brahmasphutasiddhanta''.{{citation needed|date=January 2018}} Later, Persian and Arabic mathematicians developed algebraic methods to a much higher degree of sophistication. Although Diophantus and the Babylonians used mostly special ''ad hoc'' methods to solve equations, Al-Khwarizmi's contribution was fundamental. He solved linear and quadratic equations without algebraic symbolism, [[negative numbers]] or [[zero]], thus he had to distinguish several types of equations.<ref name=\"Meri2004\">{{cite book|first=Josef W. |last= Meri|title=Medieval Islamic Civilization|url=https://books.google.com/books?id=H-k9oc9xsuAC&pg=PA31|access-date=2012-11-25|year=2004|publisher=Psychology Press|isbn=978-0-415-96690-0|page=31}}</ref>\n\nIn the context where algebra is identified with the [[theory of equations]], the Greek mathematician Diophantus has traditionally been known as the \"father of algebra\" and in context where it is identified with rules for manipulating and solving equations, Persian mathematician al-Khwarizmi is regarded as \"the father of algebra\".<ref>See {{harv|Boyer|1991}}, page 181: \"If we think primarily of matter of notations, Diophantus has good claim to be known as the 'father of algebra', but in terms of motivation and concept, the claim is less appropriate. The Arithmetica is not a systematic exposition of the algebraic operations, or of algebraic functions or of the solution of algebraic equations\".</ref><ref>See {{harv|Boyer|1991}}, page 230: \"The six cases of equations given above exhaust all possiblities for linear and quadratic equations...In this sense, then, al-Khwarizmi is entitled to be known as 'the father of algebra'\".</ref><ref>See {{harv|Boyer|1991}}, page 228: \"Diophantus sometimes is called the father of algebra, but this title more appropriately belongs to al-Khowarizmi\".</ref><ref name=\"Gandz\">See {{harv|Gandz|1936}}, page 263–277: \"In a sense, al-Khwarizmi is more entitled to be called \"the father of algebra\" than Diophantus because al-Khwarizmi is the first to teach algebra in an elementary form and for its own sake, Diophantus is primarily concerned with the theory of numbers\".</ref><ref>{{Cite journal|last=Christianidis|first=Jean|date=August 2007|title=The way of Diophantus: Some clarifications on Diophantus' method of solution|journal=[[Historia Mathematica]]|volume=34|issue=3|pages=289–305|quote=It is true that if one starts from a conception of algebra that emphasizes the solution of equations, as was generally the case with the Arab mathematicians from al-Khwārizmī onward as well as with the Italian algebraists of the Renaissance, then the work of Diophantus appears indeed very different from the works of those algebraists|doi=10.1016/j.hm.2006.10.003}}</ref><ref>{{cite|first=G.C. |last= Cifoletti |title= La question de l'algèbre: Mathématiques et rhétorique des homes de droit dans la France du 16e siècle |journal= Annales de l'École des Hautes Études en Sciences Sociales, 50 (6)|year= 1995 |pages= 1385–1416 |quote= Le travail des Arabes et de leurs successeurs a privilégié la solution des problèmes.Arithmetica de Diophantine ont privilégié la théorie des equations}}</ref> A debate now exists whether who (in general sense) is more entitled to be known as \"the father of algebra\". Those who support Diophantus point to the fact that the algebra found in ''Al-Jabr'' is slightly more elementary than the algebra found in ''Arithmetica'' and that ''Arithmetica'' is syncopated while ''Al-Jabr'' is fully rhetorical.<ref>See {{harv|Boyer|1991}}, page 228.</ref> Those who support Al-Khwarizmi point to the fact that he introduced the methods of \"[[Reduction (mathematics)|reduction]]\" and \"balancing\" (the transposition of subtracted terms to the other side of an equation, that is, the cancellation of [[like terms]] on opposite sides of the equation) which the term ''al-jabr'' originally referred to,<ref name=Boyer-229>See {{harv|Boyer|1991}}, ''The Arabic Hegemony'', p. 229: \"It is not certain just what the terms ''al-jabr'' and ''muqabalah'' mean, but the usual interpretation is similar to that implied in the translation above. The word ''al-jabr'' presumably meant something like \"restoration\" or \"completion\" and seems to refer to the transposition of subtracted terms to the other side of an equation; the word ''muqabalah'' is said to refer to \"reduction\" or \"balancing\" – that is, the cancellation of like terms on opposite sides of the equation\".</ref> and that he gave an exhaustive explanation of solving quadratic equations,<ref>See {{harv|Boyer|1991}}, ''The Arabic Hegemony'', p. 230: \"The six cases of equations given above exhaust all possibilities for linear and quadratic equations having positive root. So systematic and exhaustive was al-Khwarizmi's exposition that his readers must have had little difficulty in mastering the solutions\".</ref> supported by geometric proofs, while treating algebra as an independent discipline in its own right.<ref name=\"Gandz\"/> His algebra was also no longer concerned \"with a series of problems to be resolved, but an [[Expository writing|exposition]] which starts with primitive terms in which the combinations must give all possible prototypes for equations, which henceforward explicitly constitute the true object of study\". He also studied an equation for its own sake and \"in a generic manner, insofar as it does not simply emerge in the course of solving a problem, but is specifically called on to define an infinite class of problems\".<ref name=Rashed-Armstrong>{{Cite book |last1= Rashed |first1= R. |last2= Armstrong |first2= Angela |year= 1994 |title= The Development of Arabic Mathematics |publisher= [[Springer Science+Business Media|Springer]] |isbn= 978-0-7923-2565-9 |oclc= 29181926 |pages= 11–12}}</ref>\n\nAnother Persian mathematician [[Omar Khayyam]] is credited with identifying the foundations of [[algebraic geometry]] and found the general geometric solution of the [[cubic equation]]. His book ''Treatise on Demonstrations of Problems of Algebra'' (1070), which laid down the principles of algebra, is part of the body of Persian mathematics that was eventually transmitted to Europe.<ref>{{cite|title=Mathematical Masterpieces: Further Chronicles by the Explorers |page= 92}}</ref> Yet another Persian mathematician, [[Sharaf al-Dīn al-Tūsī]], found algebraic and numerical solutions to various cases of cubic equations.<ref>{{MacTutor|id=Al-Tusi_Sharaf|title=Sharaf al-Din al-Muzaffar al-Tusi}}</ref> He also developed the concept of a [[Function (mathematics)|function]].<ref>{{Cite journal|last=Victor J. Katz|first=Bill Barton|title=Stages in the History of Algebra with Implications for Teaching|journal=Educational Studies in Mathematics|volume=66|issue=2|date=October 2007|doi=10.1007/s10649-006-9023-7|pages=185–201 [192]|last2=Barton|first2=Bill}}</ref> The Indian mathematicians [[Mahavira (mathematician)|Mahavira]] and [[Bhaskara II]], the Persian mathematician [[Al-Karaji]],<ref name=\"Boyer al-Karkhi ax2n\">See {{harv|Boyer|1991}}, ''The Arabic Hegemony'', p. 239: \"Abu'l Wefa was a capable algebraist as well as a trigonometer.&nbsp;... His successor al-Karkhi evidently used this translation to become an Arabic disciple of Diophantus – but without Diophantine analysis!&nbsp;... In particular, to al-Karkhi is attributed the first numerical solution of equations of the form ax<sup>2n</sup> + bx<sup>n</sup> = c (only equations with positive roots were considered),\"</ref> and the Chinese mathematician [[Zhu Shijie]], solved various cases of cubic, [[quartic equation|quartic]], [[quintic equation|quintic]] and higher-order [[polynomial]] equations using numerical methods. In the 13th century, the solution of a cubic equation by [[Fibonacci]] is representative of the beginning of a revival in European algebra. [[Abū al-Ḥasan ibn ʿAlī al-Qalaṣādī]] (1412–1486) took \"the first steps toward the introduction of algebraic symbolism\". He also computed ∑''n''<sup>2</sup>, ∑''n''<sup>3</sup> and used the method of successive approximation to determine square roots.<ref>{{Cite web|url=http://www-history.mcs.st-andrews.ac.uk/Biographies/Al-Qalasadi.html|title=Al-Qalasadi biography|website=www-history.mcs.st-andrews.ac.uk|access-date=2017-10-17}}</ref>\n\n=== Modern history of algebra ===\n[[File:Gerolamo Cardano (colour).jpg|thumb|200px|Italian mathematician [[Girolamo Cardano]] published the solutions to the [[cubic equation|cubic]] and [[quartic equation]]s in his 1545 book ''[[Ars Magna (Gerolamo Cardano)|Ars magna]]''.]]\n\n[[François Viète]]'s work on [[new algebra]] at the close of the 16th century was an important step towards modern algebra. In 1637, [[René Descartes]] published ''[[La Géométrie]]'', inventing [[analytic geometry]] and introducing modern algebraic notation. Another key event in the further development of algebra was the general algebraic solution of the cubic and quartic equations, developed in the mid-16th century. The idea of a [[determinant]] was developed by [[Japanese mathematics|Japanese mathematician]] [[Seki Kōwa]] in the 17th century, followed independently by [[Gottfried Leibniz]] ten years later, for the purpose of solving systems of simultaneous linear equations using [[matrix (mathematics)|matrices]]. [[Gabriel Cramer]] also did some work on matrices and determinants in the 18th century. Permutations were studied by [[Joseph-Louis Lagrange]] in his 1770 paper ''Réflexions sur la résolution algébrique des équations'' devoted to solutions of algebraic equations, in which he introduced [[Resolvent (Galois theory)|Lagrange resolvents]]. [[Paolo Ruffini]] was the first person to develop the theory of [[permutation group]]s, and like his predecessors, also in the context of solving algebraic equations.\n\n[[Abstract algebra]] was developed in the 19th century, deriving from the interest in solving equations, initially focusing on what is now called [[Galois theory]], and on [[constructible number|constructibility]] issues.<ref>\"[http://www.math.hawaii.edu/~lee/algebra/history.html The Origins of Abstract Algebra]\". University of Hawaii Mathematics Department.</ref> [[George Peacock]] was the founder of axiomatic thinking in arithmetic and algebra. [[Augustus De Morgan]] discovered [[relation algebra]] in his ''Syllabus of a Proposed System of Logic''. [[Josiah Willard Gibbs]] developed an algebra of vectors in three-dimensional space, and [[Arthur Cayley]] developed an algebra of matrices (this is a noncommutative algebra).<ref>\"[http://www.cambridge.org/catalogue/catalogue.asp?ISBN=978-1108005043 The Collected Mathematical Papers]\".Cambridge University Press.</ref>\n\n== Areas of mathematics with the word algebra in their name ==\n\nSome areas of mathematics that fall under the classification abstract algebra have the word algebra in their name; [[linear algebra]] is one example. Others do not: [[group theory]], [[ring theory]], and [[field (mathematics)|field theory]] are examples. In this section, we list some areas of mathematics with the word \"algebra\" in the name.\n* [[Elementary algebra]], the part of algebra that is usually taught in elementary courses of mathematics.\n* [[Abstract algebra]], in which [[algebraic structure]]s such as [[group (mathematics)|groups]], [[ring (mathematics)|rings]] and [[field (mathematics)|fields]] are [[axiomatization|axiomatically]] defined and investigated.\n* [[Linear algebra]], in which the specific properties of [[linear equation]]s, [[vector space]]s and [[matrix (mathematics)|matrices]] are studied.\n* [[Boolean algebra]], a branch of algebra abstracting the computation with the [[truth value]]s ''false'' and ''true''.\n* [[Commutative algebra]], the study of [[commutative ring]]s.\n* [[Computer algebra]], the implementation of algebraic methods as [[algorithm]]s and [[computer program]]s.\n* [[Homological algebra]], the study of algebraic structures that are fundamental to study [[topological space]]s.\n* [[Universal algebra]], in which properties common to all algebraic structures are studied.\n* [[Algebraic number theory]], in which the properties of numbers are studied from an algebraic point of view.\n* [[Algebraic geometry]], a branch of geometry, in its primitive form specifying curves and surfaces as solutions of polynomial equations.\n* [[Algebraic combinatorics]], in which algebraic methods are used to study combinatorial questions.\n* [[Relational algebra]]: a set of [[finitary relation]]s that is [[closure (mathematics)|closed]] under certain operators.\n\nMany mathematical structures are called '''algebras''':\n* [[Algebra over a field]] or more generally [[Algebra (ring theory)|algebra over a ring]].<br>Many classes of algebras over a field or over a ring have a specific name:\n** [[Associative algebra]]\n** [[Non-associative algebra]]\n** [[Lie algebra]]\n** [[Hopf algebra]]\n** [[C*-algebra]]\n** [[Symmetric algebra]]\n** [[Exterior algebra]]\n** [[Tensor algebra]]\n* In [[measure theory]],\n** [[Sigma-algebra]]\n** [[Algebra over a set]]\n* In [[category theory]]\n** [[F-algebra]] and [[F-coalgebra]]\n** [[T-algebra]]\n* In [[logic]],\n** [[Relation algebra]], a residuated Boolean algebra expanded with an involution called converse.\n** [[Boolean algebra (structure)|Boolean algebra]], a [[complemented lattice|complemented]] [[distributive lattice]].\n** [[Heyting algebra]]\n\n== Elementary algebra ==\n{{main|Elementary algebra}}\n[[File:algebraic equation notation.svg|thumb|right|Algebraic expression notation:<br />&nbsp; 1 – power (exponent)<br />&nbsp; 2 – coefficient<br />&nbsp; 3 – term<br />&nbsp; 4 – operator<br />&nbsp; 5 – constant term<br />&nbsp; ''x'' ''y'' ''c'' – variables/constants]]\n'''Elementary algebra''' is the most basic form of algebra. It is taught to students who are presumed to have no knowledge of [[mathematics]] beyond the basic principles of [[arithmetic]]. In arithmetic, only [[number]]s and their arithmetical operations (such as +, −, ×, ÷) occur. In algebra, numbers are often represented by symbols called [[variable (mathematics)|variables]] (such as ''a'', ''n'', ''x'', ''y'' or ''z''). This is useful because:\n* It allows the general formulation of arithmetical laws (such as ''a'' + ''b'' = ''b'' + ''a'' for all ''a'' and ''b''), and thus is the first step to a systematic exploration of the properties of the [[real number|real number system]].\n* It allows the reference to \"unknown\" numbers, the formulation of [[equation]]s and the study of how to solve these. (For instance, \"Find a number ''x'' such that 3''x'' + 1 = 10\" or going a bit further \"Find a number ''x'' such that ''ax'' + ''b'' = ''c''\". This step leads to the conclusion that it is not the nature of the specific numbers that allows us to solve it, but that of the operations involved.)\n* It allows the formulation of [[function (mathematics)|functional]] relationships. (For instance, \"If you sell ''x'' tickets, then your profit will be 3''x'' − 10 dollars, or ''f''(''x'') = 3''x'' − 10, where ''f'' is the function, and ''x'' is the number to which the function is applied\".)\n\n=== Polynomials ===\n[[File:Polynomialdeg3.svg|The [[graph of a function|graph]] of a polynomial function of degree 3.|thumb|upright]]\n{{main|Polynomial}}\n\nA '''polynomial''' is an [[expression (mathematics)|expression]] that is the sum of a finite number of non-zero [[term (mathematics)|terms]], each term consisting of the product of a constant and a finite number of [[Variable (mathematics)|variables]] raised to whole number powers. For example, ''x''<sup>2</sup> + 2''x'' − 3 is a polynomial in the single variable ''x''. A '''polynomial expression''' is an expression that may be rewritten as a polynomial, by using commutativity, associativity and distributivity of addition and multiplication. For example, (''x'' − 1)(''x'' + 3) is a polynomial expression, that, properly speaking, is not a polynomial. A '''polynomial function''' is a function that is defined by a polynomial, or, equivalently, by a polynomial expression. The two preceding examples define the same polynomial function.\n\nTwo important and related problems in algebra are the [[factorization of polynomials]], that is, expressing a given polynomial as a product of other polynomials that can not be factored any further, and the computation of [[polynomial greatest common divisor]]s. The example polynomial above can be factored as (''x'' − 1)(''x'' + 3). A related class of problems is finding algebraic expressions for the [[root of a function|roots]] of a polynomial in a single variable.\n\n=== Education ===\n{{see also|Mathematics education}}\nIt has been suggested that elementary algebra should be taught to students as young as eleven years old,<ref>{{Cite web |title=Hull's Algebra |work=New York Times |date=July 16, 1904 |url=https://timesmachine.nytimes.com/timesmachine/1904/07/16/101345282.pdf |format=[[pdf]] |access-date=2012-09-21}}</ref> though in recent years it is more common for public lessons to begin at the eighth grade level (≈&nbsp;13&nbsp;y.o.&nbsp;±) in the United States.<ref>{{Cite web |last=Quaid |first=Libby |title=Kids misplaced in algebra |publisher=[[Associated Press]] |date=2008-09-22 |url=https://www.usatoday.com/news/nation/2008-09-22-357650952_x.htm |format=Report |access-date=2012-09-23}}</ref> However, in some US schools, algebra is started in ninth grade.\n\n== Abstract algebra ==\n{{Main|Abstract algebra|Algebraic structure}}\n\n'''Abstract algebra''' extends the familiar concepts found in elementary algebra and [[arithmetic]] of [[number]]s to more general concepts. Here are listed fundamental concepts in abstract algebra.\n\n'''[[Set (mathematics)|Sets]]''': Rather than just considering the different types of [[number]]s, abstract algebra deals with the more general concept of ''sets'': a collection of all objects (called [[Element (mathematics)|elements]]) selected by property specific for the set. All collections of the familiar types of numbers are sets. Other examples of sets include the set of all two-by-two [[Matrix (mathematics)|matrices]], the set of all second-degree [[polynomials]] (''ax''<sup>2</sup> + ''bx'' + ''c''), the set of all two dimensional [[Vector (geometric)|vectors]] in the plane, and the various [[finite groups]] such as the [[cyclic group]]s, which are the groups of integers [[modular arithmetic|modulo]] ''n''. [[Set theory]] is a branch of [[logic]] and not technically a branch of algebra.\n\n'''[[Binary operation]]s''': The notion of [[addition]] (+) is abstracted to give a ''binary operation'', ∗ say. The notion of binary operation is meaningless without the set on which the operation is defined. For two elements ''a'' and ''b'' in a set ''S'', ''a'' ∗ ''b'' is another element in the set; this condition is called [[Closure (mathematics)|closure]]. [[Addition]] (+), [[subtraction]] (−), [[multiplication]] (×), and [[Division (mathematics)|division]] (÷) can be binary operations when defined on different sets, as are addition and multiplication of matrices, vectors, and polynomials.\n\n'''[[Identity element]]s''': The numbers zero and one are abstracted to give the notion of an ''identity element'' for an operation. Zero is the identity element for addition and one is the identity element for multiplication. For a general binary operator ∗ the identity element ''e'' must satisfy ''a'' ∗ ''e'' = ''a'' and ''e'' ∗ ''a'' = ''a'', and is necessarily unique, if it exists. This holds for addition as ''a'' + 0 = ''a'' and 0 + ''a'' = ''a'' and multiplication ''a'' × 1 = ''a'' and 1 × ''a'' = ''a''. Not all sets and operator combinations have an identity element; for example, the set of positive natural numbers (1, 2, 3,&nbsp;...) has no identity element for addition.\n\n'''[[Inverse elements]]''': The negative numbers give rise to the concept of ''inverse elements''. For addition, the inverse of ''a'' is written −''a'', and for multiplication the inverse is written ''a''<sup>−1</sup>. A general two-sided inverse element ''a''<sup>−1</sup> satisfies the property that ''a'' ∗ ''a''<sup>−1</sup> = ''e'' and ''a''<sup>−1</sup> ∗ ''a'' = ''e'', where ''e'' is the identity element.\n\n'''[[Associativity]]''': Addition of integers has a property called associativity. That is, the grouping of the numbers to be added does not affect the sum. For example: {{nowrap|1=(2 + 3) + 4 = 2 + (3 + 4)}}. In general, this becomes (''a'' ∗ ''b'') ∗ ''c'' = ''a'' ∗ (''b'' ∗ ''c''). This property is shared by most binary operations, but not subtraction or division or [[octonion multiplication]].\n\n'''[[Commutative operation|Commutativity]]''': Addition and multiplication of real numbers are both commutative. That is, the order of the numbers does not affect the result. For example: 2 + 3 = 3 + 2. In general, this becomes ''a'' ∗ ''b'' = ''b'' ∗ ''a''. This property does not hold for all binary operations. For example, [[matrix multiplication]] and [[Quaternion|quaternion multiplication]] are both non-commutative.\n\n=== Groups ===\n{{main|Group (mathematics)}}\n{{see also|Group theory|Examples of groups}}\n\nCombining the above concepts gives one of the most important structures in mathematics: a '''[[group (mathematics)|group]]'''. A group is a combination of a set ''S'' and a single [[binary operation]] ∗, defined in any way you choose, but with the following properties:\n* An identity element ''e'' exists, such that for every member ''a'' of ''S'', ''e'' ∗ ''a'' and ''a'' ∗ ''e'' are both identical to ''a''.\n* Every element has an inverse: for every member ''a'' of ''S'', there exists a member ''a''<sup>−1</sup> such that ''a'' ∗ ''a''<sup>−1</sup> and ''a''<sup>−1</sup> ∗ ''a'' are both identical to the identity element.\n* The operation is associative: if ''a'', ''b'' and ''c'' are members of ''S'', then (''a'' ∗ ''b'') ∗ ''c'' is identical to ''a'' ∗ (''b'' ∗ ''c'').\n\nIf a group is also [[commutativity|commutative]] – that is, for any two members ''a'' and ''b'' of ''S'', ''a'' ∗ ''b'' is identical to ''b'' ∗ ''a'' – then the group is said to be [[Abelian group|abelian]].\n\nFor example, the set of integers under the operation of addition is a group. In this group, the identity element is 0 and the inverse of any element ''a'' is its negation, −''a''. The associativity requirement is met, because for any integers ''a'', ''b'' and ''c'', (''a'' + ''b'') + ''c'' = ''a'' + (''b'' + ''c'')\n\nThe non-zero [[rational number]]s form a group under multiplication. Here, the identity element is 1, since 1 × ''a'' = ''a'' × 1 = ''a'' for any rational number ''a''. The inverse of ''a'' is 1/''a'', since ''a'' × 1/''a'' = 1.\n\nThe integers under the multiplication operation, however, do not form a group. This is because, in general, the multiplicative inverse of an integer is not an integer. For example, 4 is an integer, but its multiplicative inverse is ¼, which is not an integer.\n\nThe theory of groups is studied in [[group theory]]. A major result in this theory is the [[classification of finite simple groups]], mostly published between about 1955 and 1983, which separates the [[finite set|finite]] [[simple group]]s into roughly 30 basic types.\n\n[[Semi-group]]s, [[quasi-group]]s, and [[monoid]]s are structures similar to groups, but more general. They comprise a set and a closed binary operation, but do not necessarily satisfy the other conditions. A [[semi-group]] has an ''associative'' binary operation, but might not have an identity element. A [[monoid]] is a semi-group which does have an identity but might not have an inverse for every element. A [[quasi-group]] satisfies a requirement that any element can be turned into any other by either a unique left-multiplication or right-multiplication; however the binary operation might not be associative.\n\nAll groups are monoids, and all monoids are semi-groups.\n\n{| class=\"wikitable\"\n|+Examples\n|-\n!Set\n| colspan=2|[[Natural numbers]] '''N'''\n| colspan=2|[[Integers]] '''Z'''\n| colspan=4|[[Rational numbers]] '''Q''' (also [[Real numbers|real]] '''R''' and [[Complex numbers|complex]] '''C''' numbers)\n| colspan=2|Integers [[modular arithmetic|modulo]] 3: '''Z'''<sub>3</sub> = {0, 1, 2}\n|-\n!Operation\n| +\n| × (w/o zero)\n| +\n| × (w/o zero)\n| +\n| −\n| × (w/o zero)\n| ÷ (w/o zero)\n| +\n| × (w/o zero)\n|-\n!Closed\n| Yes\n| Yes\n| Yes\n| Yes\n| Yes\n| Yes\n| Yes\n| Yes\n| Yes\n| Yes\n|-\n| Identity\n| 0\n| 1\n| 0\n| 1\n| 0\n| N/A\n| 1\n| N/A\n| 0\n| 1\n|-\n| Inverse\n| N/A\n| N/A\n| −''a''\n| N/A\n| −''a''\n| N/A\n| 1/''a''\n| N/A\n| 0, 2, 1, respectively\n| N/A, 1, 2, respectively\n|-\n| Associative\n| Yes\n| Yes\n| Yes\n| Yes\n| Yes\n| No\n| Yes\n| No\n| Yes\n| Yes\n|-\n| Commutative\n| Yes\n| Yes\n| Yes\n| Yes\n| Yes\n| No\n| Yes\n| No\n| Yes\n| Yes\n|-\n| Structure\n| [[monoid]]\n| [[monoid]]\n| [[abelian group]]\n| [[monoid]]\n| [[abelian group]]\n| [[quasi-group]]\n| [[abelian group]]\n| [[quasi-group]]\n| [[abelian group]]\n| [[abelian group]] ('''Z'''<sub>2</sub>)\n|}\n\n=== Rings and fields ===\n{{main|Ring (mathematics)|Field (mathematics)}}\n{{see also|Ring theory|Glossary of ring theory|Field theory (mathematics)|Glossary of field theory}}\n\nGroups just have one binary operation. To fully explain the behaviour of the different types of numbers, structures with two operators need to be studied. The most important of these are [[Ring (mathematics)|rings]], and [[Field (mathematics)|fields]].\n\nA '''[[Ring (mathematics)|ring]]''' has two binary operations (+) and (×), with × distributive over +. Under the first operator (+) it forms an ''abelian group''. Under the second operator (×) it is associative, but it does not need to have identity, or inverse, so division is not required. The additive (+) identity element is written as 0 and the additive inverse of ''a'' is written as −''a''.\n\n'''[[Distributivity]]''' generalises the ''distributive law'' for numbers. For the integers {{nowrap|1=(''a'' + ''b'') × ''c'' = ''a'' × ''c'' + ''b'' × ''c''}} and {{nowrap|1=''c'' × (''a'' + ''b'') = ''c'' × ''a'' + ''c'' × ''b'',}} and × is said to be ''distributive'' over +.\n\nThe integers are an example of a ring. The integers have additional properties which make it an '''[[integral domain]]'''.\n\nA '''[[Field (mathematics)|field]]''' is a ''ring'' with the additional property that all the elements excluding 0 form an ''abelian group'' under ×. The multiplicative (×) identity is written as 1 and the multiplicative inverse of ''a'' is written as ''a''<sup>−1</sup>.\n\nThe rational numbers, the real numbers and the complex numbers are all examples of fields.\n\n== See also ==\n* {{Portal inline|size=tiny|Algebra}}\n* [[Outline of algebra]]\n* [[Outline of linear algebra]]\n* [[Algebra tile]]\n\n== References ==\n{{reflist}}\n\n==== Works cited ====\n* {{cite |last= Boyer |first= Carl B. |author-link= Carl Benjamin Boyer |title= A History of Mathematics |edition= 2nd |publisher= John Wiley & Sons, Inc. |year= 1991 |isbn= 978-0-471-54397-8 }}\n* {{cite |last= Gandz |first= S. |title= The Sources of Al-Khowārizmī's Algebra |journal= [[Osiris (journal)|Osiris]] |volume= 1 |year= 1936 |pages= 263-277}}\n* {{cite |last= Herstein |first= I.N. |title= Topics in Algebra |publisher= Ginn and Company |year= 1964 |isbn= 0-471-02371-X }}\n\n== Further reading ==\n* {{cite |last= Allenby |first= R.B.J.T. |title= Rings, Fields and Groups |isbn= 0-340-54440-6 }}\n* {{cite book|last=Asimov|first=Isaac|title=Realm of Algebra|year=1961|publisher=Houghton Mifflin|authorlink=Isaac Asimov}}\n* {{cite |last= Boyer |first= Carl B. |author-link= Carl Benjamin Boyer |title= A History of Mathematics |edition= 2nd |publisher= John Wiley & Sons, Inc. |year= 1991 |isbn= 978-0-471-54397-8 }}\n* {{cite |last= Euler |first=Leonhard |author-link= Leonhard Euler |url= https://web.archive.org/web/20110413234352/http://web.mat.bham.ac.uk/C.J.Sangwin/euler/ |title= Elements of Algebra |isbn= 978-1-899618-73-6 }}\n* {{cite |last= Herstein |first= I.N. |title= Topics in Algebra |isbn= 0-471-02371-X }}\n* {{cite |last= Hill |first= Donald R. |title= Islamic Science and Engineering |publisher= Edinburgh University Press |year= 1994}}\n* {{cite |last= Joseph |first= George Gheverghese |title= The Crest of the Peacock: Non-European Roots of Mathematics |publisher= [[Penguin Books]] |year= 2000}}\n* {{cite |last1= O'Connor |first1= John J. |last2= Robertson |first2= Edmund F. |url= http://www-history.mcs.st-andrews.ac.uk/Indexes/Algebra.html |title= History Topics: Algebra Index. |website= [[MacTutor History of Mathematics archive]] |publisher= [[University of St Andrews]] |year= 2005}}\n* {{cite |last1= Sardar |first1= Ziauddin |last2= Ravetz |first2= Jerry |last3= Loon |first3= Borin Van |title= Introducing Mathematics |publisher= Totem Books |year= 1999}}\n\n== External links ==\n{{Wiktionary|algebra}}\n{{Wikibooks|Algebra}}\n{{EB1911 poster|Algebra}}\n* [http://www.khanacademy.org/math/algebra Khan Academy: Conceptual videos and worked examples]\n* [https://www.khanacademy.org/math/algebra/introduction-to-algebra/overview_hist_alg/v/origins-of-algebra Khan Academy: Origins of Algebra, free online micro lectures]\n* [http://algebrarules.com Algebrarules.com: An open source resource for learning the fundamentals of Algebra]\n* [https://web.archive.org/web/20071004172100/http://www.gresham.ac.uk/event.asp?PageId=45&EventId=620 4000 Years of Algebra], lecture by Robin Wilson, at [[Gresham College]], October 17, 2007 (available for MP3 and MP4 download, as well as a text file).\n* {{cite SEP |url-id=algebra |title=Algebra |last=Pratt |first=Vaughan}}\n\n{{Algebra |expanded}}\n{{Areas of mathematics |collapsed}}\n\n{{Authority control}}\n\n[[Category:Algebra| ]]"
    },
    {
      "title": "Dialgebra",
      "url": "https://en.wikipedia.org/wiki/Dialgebra",
      "text": "{{orphan|date=January 2015}}\n\n'''Dialgebra''' is the generalization of both [[algebra]] and [[coalgebra]]. Many algebraic notions have previously been generalized to dialgebras.<ref>{{cite web|title=University of Nijmegen research papers|url=http://www.cs.ru.nl/E.Poll/papers/cmcs01.pdf|accessdate=1 January 2015}}</ref> Dialgebra also attempts to obtain Lie algebras from associated algebras.<ref>{{cite web|title=zbmaths|url=https://zbmath.org/?format=complete&q=an:0999.17002|accessdate=1 January 2015}}</ref>\n\n==References==\n{{reflist}}\n\n{{algebra-stub}}\n\n[[Category:Algebra| ]]"
    },
    {
      "title": "Outline of algebra",
      "url": "https://en.wikipedia.org/wiki/Outline_of_algebra",
      "text": "{{Short description|1=Overview of and topical guide to algebra}}\n'''[[Algebra]]''' is one of the main branches of [[mathematics]], covering the study of [[structure (algebraic)|structure]], [[relation (mathematics)|relation]]  and [[quantity]]. Algebra studies the effects of [[addition|add]]ing and [[multiplication|multiply]]ing [[number]]s, [[Variable (mathematics)|variables]], and [[polynomial]]s, along with their [[factorization]] and determining their [[root of a function|root]]s. In addition to working directly with numbers, algebra also covers [[symbols]], variables, and [[Set (mathematics)|set]] [[element (mathematics)|elements]]. Addition and multiplication are general [[operation (mathematics)|operations]], but their precise definitions lead to structures such as [[group (mathematics)|groups]], [[ring (mathematics)|rings]], and [[field (mathematics)|fields]].\n\n==Branches==\n* [[Pre-algebra]]\n* [[Elementary algebra]]\n* [[Abstract algebra]]\n* [[Linear algebra]]\n* [[Universal algebra]]\n\n== Algebraic equations ==\n{{see also|Equation}}\n\nAn [[algebraic equation]] is an equation involving only algebraic expressions in the unknowns. These are further classified by [[Degree of a polynomial|degree]].\n\n* [[Linear equation]] &ndash; algebraic equation of degree one.\n* [[Polynomial#Polynomial_equations|Polynomial equation]] &ndash; equation in which a polynomial is set equal to another polynomial.\n* [[Transcendental equation]] &ndash; equation involving a transcendental function of one of its  variables.\n* [[Functional equation]] &ndash; equation in which the unknowns are [[Function (mathematics)|functions]] rather than simple quantities.\n* [[Differential equation]] &ndash; equation involving [[derivative]]s.\n* [[Integral equation]] &ndash; equation involving [[integral]]s.\n* [[Diophantine equation]] &ndash; equation where the unknowns are required to be [[integer]]s.\n* [[Polynomials]]\n* [[Variable (mathematics)|Variables]]\n\n==History==\n\n* [[History of algebra]]\n\n==General algebra concepts==\n* [[Algebra]] &ndash; \n* [[Fundamental theorem of algebra]] &ndash; states that every non-constant single-variable polynomial with complex coefficients has at least one complex root. This includes polynomials with real coefficients, since every real number is a complex number with an imaginary part equal to zero.\n* [[Linear equation]] &ndash; an algebraic equation with a degree of one\n* [[Quadratic equation]] &ndash; an algebraic equation with a degree of two\n* [[Cubic equation]] &ndash; an algebraic equation with a degree of  three\n* [[Quartic equation]] &ndash; an algebraic equation with a degree of four\n* [[Quintic equation]] &ndash; an algebraic equation with a degree of five\n* [[Polynomial]] &ndash; \n<!--\n===Boolean algebra===\n[[Algebra of sets]] [[Talk:Algebra of sets| ]] -\n[[Algebraic normal form]] [[Talk:Algebraic normal form| ]] -\n[[Ampheck]] [[Talk:Ampheck| ]] -\n[[And-inverter graph]] [[Talk:And-inverter graph| ]] -\n[[George Boole|Boole, George]] [[Talk:George Boole| ]] -\n[[Boolean algebra (structure)]] [[Talk:Boolean algebra (structure)| ]] -\n[[Boolean algebras canonically defined]] [[Talk:Boolean algebras canonically defined| ]] -\n[[Boolean conjunctive query]] -\n[[Boolean domain]] [[Talk:Boolean domain| ]] -\n[[Boolean function]] [[Talk:Boolean function| ]] -\n[[Boolean algebra (logic)]] [[Talk:Boolean algebra (logic)| ]] -\n[[Implicant|Boolean implicant]] [[Talk:Implicant| ]] -\n[[Boolean prime ideal theorem]] [[Talk:Boolean prime ideal theorem| ]] -\n[[Boolean-valued function]] [[Talk:Boolean-valued function| ]] -\n[[Boolean-valued model]] [[Talk:Boolean-valued model| ]] -\n[[Boolean satisfiability problem]] [[Talk:Boolean satisfiability problem| ]] -\n[[Boole's syllogistic]] [[Talk:Boole's syllogistic| ]] -\n[[Canonical form (Boolean algebra)]] [[Talk:normal form (Boolean algebra)| ]] -\n[[Characteristic function]] [[Talk:Characterisitic function| ]] -\n[[Compactness theorem]] [[Talk:compactness theorem| ]] -\n[[Complete Boolean algebra]] [[Talk:Complete Boolean algebra| ]] -\n[[Consensus theorem]] [[Talk:Consensus theorem| ]] -\n[[Augustus De Morgan|De Morgan, Augustus]] [[Talk:Augustus De Morgan| ]] -\n[[De Morgan's laws]] [[Talk:de Morgan's laws| ]] -\n[[Duality (order theory)]] [[Talk:duality (order theory)| ]] -\n[[Entitative graph]] [[Talk:Entitative graph| ]] -\n[[Minilog|Espresso heuristic logic minimizer]] -\n[[Existential graph]] [[Talk:Existential graph| ]] -\n[[First-order logic]] [[Talk:First-order logic| ]] -\n[[Formal system]] [[Talk:formal system| ]] -\n[[Free Boolean algebra]] [[Talk:free Boolean algebra| ]] -\n[[Heyting algebra]] [[Talk:Heyting algebra| ]] -\n[[Indicator function]] [[Talk:Indicator function| ]] -\n[[Interior algebra]] [[Talk:interior algebra| ]] -\n[[William Stanley Jevons|Jevons, William Stanley]] [[Talk:William Stanley Jevons| ]] -\n[[Johnston diagram]] [[Talk:Johnston diagram| ]] -\n[[Karnaugh map]] [[Talk:Karnaugh map| ]] -\n[[Laws of Form]] [[Talk:Laws of Form| ]] -\n[[Lindenbaum–Tarski algebra]] [[Talk:Lindenbaum–Tarski algebra| ]] -\n[[Logic gate]] [[Talk:logic gate| ]] -\n[[Logical connective]] [[Talk:logical connective| ]] -\n[[Logical graph]] [[Talk:Logical graph| ]] -\n[[Logical matrix]] [[Talk:Logical matrix| ]] -\n[[Logical value]] [[Talk:Logical value| ]] -\n[[Minimal negation operator]] [[Talk:Minimal negation operator| ]] -\n[[Monadic Boolean algebra]] [[Talk:monadic Boolean algebra| ]] -\n[[Charles Peirce|Peirce, Charles Sanders]] [[Talk:Charles Peirce| ]] -\n[[Peirce's law]] [[Talk:Peirce's law| ]] -\n[[Propositional calculus]] [[Talk:propositional calculus| ]] -\n[[Sole sufficient operator]] [[Talk:Sole sufficient operator| ]] -\n[[Marshall Harvey Stone|Stone, Marshall Harvey]] [[Talk:Marshall Harvey Stone| ]] -\n[[Stone duality]] [[Talk:Stone duality| ]] -\n[[Stone's representation theorem for Boolean algebras]] [[Talk:Stone's representation theorem for Boolean algebras| ]] -\n[[Stone's representation theorem for Boolean algebras|Stone space]] -\n[[Topological Boolean algebra]] [[Talk:topological Boolean algebra| ]] -\n[[Truth table]] [[Talk:truth table| ]] -\n[[Two-element Boolean algebra]] [[Talk:Two-element Boolean algebra| ]] -\n[[John Venn|Venn, John]] [[Talk:John Venn| ]] -\n[[Venn diagram]] [[Talk:Venn diagram| ]] -\n[[Zeroth-order logic]] [[Talk:Zeroth-order logic| ]]\n-->\n\n==See also==\n{{Portal|Algebra}}\n\n* [[Table of mathematical symbols]]\n\n==External links==\n*[http://www.gresham.ac.uk/event.asp?PageId=45&EventId=620 '4000 Years of Algebra'], lecture by Robin Wilson, at [[Gresham College]], 17 October 2007 (available for MP3 and MP4 download, as well as a text file).\n* [http://www.exampleproblems.com ExampleProblems.com] Example problems and solutions from [http://www.exampleproblems.com/wiki/index.php/Algebra basic] and [http://www.exampleproblems.com/wiki/index.php/Abstract_Algebra abstract] algebra.\n\n{{Outline footer}}\n{{Sister project links|Algebra}}\n{{Use dmy dates|date=September 2011}}\n\n[[Category:Algebra| List]]\n[[Category:Mathematics-related lists|Algebra]]\n[[Category:Wikipedia outlines|Algebra]]"
    },
    {
      "title": "Timeline of geometry",
      "url": "https://en.wikipedia.org/wiki/Timeline_of_geometry",
      "text": "{{Use dmy dates|date=September 2010}}\nA [[timeline]] of '''[[algebra]]''' and '''[[geometry]]'''\n\n==Before 1000 BC==\n* ca. 2000 BC — [[Scotland]], [[Carved Stone Balls]] exhibit a variety of symmetries including all of the symmetries of [[Platonic solid]]s.\n* 1800 BC — [[Moscow Mathematical Papyrus]], findings volume of a frustum\n* 1650 BC — [[Rhind Mathematical Papyrus]], copy of a lost scroll from around 1850 BC, the scribe [[Ahmes]] presents one of the first known approximate values of [[pi|π]] at 3.16, the first attempt at [[squaring the circle]], earliest known use of a sort of [[cotangent]], and knowledge of solving first order linear equations\n\n==1st millennium BC==\n* 800 BC — Baudhayana, author of the Baudhayana [[Sulba Sutras|Sulba Sutra]], a [[Vedic Sanskrit]] geometric text, contains [[quadratic equations]], and calculates the [[square root of 2]] correct to five decimal places\n* ca. 600 BC — the other [[Vedic civilization|Vedic]] “[[Sulba Sutras]]” (“rule of chords” in [[Sanskrit]]) use [[Pythagorean triples]], contain of a number of geometrical proofs, and approximate [[pi|π]] at 3.16\n* 5th century BC — [[Hippocrates of Chios]] utilizes [[Lune (mathematics)|lunes]] in an attempt to [[squaring the circle|square the circle]]\n* 5th century BC — [[Apastamba]], author of the Apastamba [[Sulba Sutras|Sulba Sutra]], another [[Vedic Sanskrit]] geometric text, makes an attempt at [[squaring the circle]] and also calculates the [[square root]] of 2 correct to five decimal places\n* 530 BC — [[Pythagoras]] studies propositional [[geometry]] and vibrating lyre strings; his group also discover the [[irrational number|irrationality]] of the [[square root]] of [[two]],\n* 370 BC — [[Eudoxus of Cnidus|Eudoxus]] states the [[method of exhaustion]] for [[area]] determination\n* 300 BC — [[Euclid]] in his ''[[Euclid's Elements|Elements]]'' studies [[geometry]] as an [[axiomatic system]], proves the [[Infinite set|infinitude]] of [[prime number]]s and presents the [[Euclidean algorithm]]; he states the law of reflection in  ''Catoptrics'', and he proves the [[fundamental theorem of arithmetic]]\n* 260 BC — [[Archimedes]] [[method of exhaustion|proved]] that the value of [[pi|π]] lies between 3&nbsp;+&nbsp;1/7 (approx. 3.1429) and 3&nbsp;+&nbsp;10/71 (approx. 3.1408), that the area of a circle was equal to π multiplied by the square of the radius of the circle and that the area enclosed by a parabola and a straight line is 4/3 multiplied by the area of a triangle with equal base and height. He also gave a very accurate estimate of the value of the square root of 3.\n* 225 BC — [[Apollonius of Perga]] writes  ''On [[Conic section|Conic Sections]]'' and names the [[ellipse]], [[parabola]], and [[hyperbola]],\n* 150 BC — [[Jainism|Jain]] mathematicians in [[History of India|India]] write the “Sthananga Sutra”, which contains work on the theory of numbers, arithmetical operations, [[geometry]], operations with [[fractions]], simple equations, [[cubic equations]], quartic equations, and [[permutations]] and [[combinations]]\n* 140 BC — [[Hipparchus]] develops the bases of [[trigonometry]].\n\n==1st millennium==\n* ca. 340 — [[Pappus of Alexandria]] states his [[Pappus's hexagon theorem|hexagon theorem]] and his [[Pappus's centroid theorem|centroid theorem]]\n* 500 — [[Aryabhata]] writes the “Aryabhata-Siddhanta”, which first introduces the trigonometric functions and methods of calculating their approximate numerical values. It defines the concepts of [[sine]] and [[cosine]], and also contains the [[Aryabhata's sine table|earliest tables of sine]] and cosine values (in 3.75-degree intervals from 0 to 90 degrees)\n* 7th century — [[Bhaskara I]] gives a rational approximation of the sine function\n* 8th century — [[Virasena]] gives explicit rules for the [[Fibonacci sequence]], gives the derivation of the [[volume]] of a [[frustum]] using an [[Infinity|infinite]] procedure, and also deals with the [[logarithm]] to [[base 2]] and knows its laws\n* 8th century — [[Shridhara]] gives the rule for finding the volume of a sphere and also the formula for solving quadratic equations\n* 820 — [[Al-Mahani]] conceived the idea of reducing [[Geometry|geometrical]] problems such as [[doubling the cube]] to problems in algebra.\n* ca. 900 — [[Abu Kamil]] of Egypt had begun to understand what we would write in symbols as <math>x^n \\cdot x^m = x^{m+n}</math>\n* 975 — [[Al-Batani]] — Extended the Indian concepts of sine and cosine to other trigonometrical ratios, like tangent, secant and their inverse functions. Derived the formula: <math> \\sin \\alpha = \\tan \\alpha / \\sqrt{1+\\tan^2 \\alpha} </math> and <math> \\cos \\alpha = 1 / \\sqrt{1 + \\tan^2 \\alpha}</math>.\n\n==1000–1500==\n*ca. 1000 — [[Law of sines]] is discovered by [[Islamic mathematics|Muslim mathematicians]], but it is uncertain who discovers it first between [[Abu-Mahmud al-Khujandi]], [[Abu Nasr Mansur]], and [[Abū al-Wafā' al-Būzjānī|Abu al-Wafa]].\n* ca. 1100 — [[Omar Khayyám]] “gave a complete classification of [[cubic equation]]s with geometric solutions found by means of intersecting [[conic section]]s.” He became the first to find general [[geometry|geometric]] solutions of [[cubic equation]]s and laid the foundations for the development of [[analytic geometry]] and [[non-Euclidean geometry]]. He also extracted [[root of a function|roots]] using the [[decimal]] system ([[Hindu-Arabic numeral system]]).\n* 1135 — [[Sharafeddin Tusi]] followed al-Khayyam's application of algebra to geometry, and wrote a treatise on [[cubic equation]]s which “represents an essential contribution to another [[algebra]] which aimed to study [[curve]]s by means of [[equation]]s, thus inaugurating the beginning of [[algebraic geometry]].”<ref name=MacTutor>[http://www-groups.dcs.st-and.ac.uk/~history/HistTopics/Arabic_mathematics.html Arabic mathematics], ''[[MacTutor History of Mathematics archive]]'', [[University of St Andrews]], Scotland</ref>\n* ca. 1250 — [[Nasir Al-Din Al-Tusi]] attempts to develop a form of [[non-Euclidean geometry]].\n* 15th century — [[Nilakantha Somayaji]], a [[Kerala school of astronomy and mathematics|Kerala school]] mathematician, writes the “Aryabhatiya Bhasya”, which contains work on infinite-series expansions, problems of algebra, and spherical geometry\n\n==17th century==\n* 17th century – Putumana Somayaji writes the \"Paddhati\", which presents a detailed discussion of various trigonometric series\n* 1619 –  [[Johannes Kepler]] discovers two of the [[Kepler-Poinsot polyhedra]].\n\n==18th century==\n* 1722 –  [[Abraham de Moivre]] states [[de Moivre's formula]] connecting [[trigonometric function]]s and [[complex number]]s,\n* 1733 –  [[Giovanni Gerolamo Saccheri]] studies what geometry would be like if [[parallel postulate|Euclid's fifth postulate]] were false,\n* 1796 –  [[Carl Friedrich Gauss]] proves that the [[heptadecagon|regular 17-gon]] can be constructed using only a [[compass and straightedge]]\n* 1797 –  [[Caspar Wessel]] associates vectors with [[complex number]]s and studies complex number operations in geometrical terms,\n* 1799 –  [[Gaspard Monge]] publishes Géométrie descriptive, in which he introduces [[descriptive geometry]].\n\n==19th century==\n* 1806 –  [[Louis Poinsot]] discovers the two remaining [[Kepler-Poinsot polyhedra]].\n* 1829 –  [[Bolyai]], [[Carl Friedrich Gauss|Gauss]], and [[Nikolai Ivanovich Lobachevsky|Lobachevsky]] invent hyperbolic [[non-Euclidean geometry]],\n* 1837 –  [[Pierre Wantzel]] proves that doubling the cube and [[trisecting the angle]] are impossible with only a compass and straightedge, as well as the full completion of the problem of [[Constructible polygon|constructibility]] of regular polygons\n* 1843 –  [[William Rowan Hamilton|William Hamilton]] discovers the calculus of [[quaternion]]s and deduces that they are non-commutative,\n* 1854 –  [[Bernhard Riemann]] introduces [[Riemannian geometry]],\n* 1854 –  [[Arthur Cayley]] shows that [[quaternion]]s can be used to represent rotations in four-dimensional [[space]],\n* 1858 –  [[August Ferdinand Möbius]] invents the [[Möbius strip]],\n* 1870 –  [[Felix Klein]] constructs an analytic geometry for Lobachevski's geometry thereby establishing its self-consistency and the logical independence of Euclid's fifth postulate,\n* 1873 –  [[Charles Hermite]] proves that [[e (mathematical constant)|e]] is transcendental,\n* 1878 – Charles Hermite solves the general quintic equation by means of elliptic and modular functions\n* 1882 –  [[Ferdinand von Lindemann]] proves that π is transcendental and that therefore the circle cannot be squared with a compass and straightedge,\n* 1882 –  Felix Klein invents the [[Klein bottle]],\n* 1899 –  [[David Hilbert]] presents a set of self-consistent geometric axioms in ''Foundations of Geometry''\n\n==20th century==\n* 1901 –  [[Élie Cartan]] develops the [[exterior derivative]],\n* 1912 –  [[Luitzen Egbertus Jan Brouwer]] presents the [[Brouwer fixed-point theorem]],\n* 1916 – [[Albert Einstein|Einstein's]] theory of [[general relativity]].\n* 1930 –  [[Casimir Kuratowski]] shows that the [[three-cottage problem]] has no solution,\n* 1931 –  [[Georges de Rham]] develops theorems in [[cohomology]] and [[characteristic class]]es,\n* 1933 –  [[Karol Borsuk]] and [[Stanislaw Ulam]] present the [[Borsuk-Ulam Theorem|Borsuk-Ulam antipodal-point theorem]],\n* 1955 –  [[H. S. M. Coxeter]] et al. publish the complete list of [[uniform polyhedron]],\n* 1975 –  [[Benoit Mandelbrot]], [[fractal]]s theory,\n* 1981 – [[Mikhail Gromov (mathematician)|Mikhail Gromov]] develops the theory of [[hyperbolic group]]s, revolutionizing both infinite group theory and global differential geometry,\n* 1983 –  the [[classification of finite simple groups]], a collaborative work involving some hundred mathematicians and spanning thirty years, is completed,\n* 1991 –  [[Alain Connes]] and [[John Lott (mathematician)|John Lott]] develop [[non-commutative geometry]],\n* 1998 –  [[Thomas Callister Hales]] proves the [[Kepler conjecture]],\n\n==21st century==\n* 2003 – [[Grigori Perelman]] proves the [[Poincaré conjecture]],\n* 2007 – a team of researches throughout North America and Europe used networks of computers to map [[E8 (mathematics)]].<ref>Elizabeth A. Thompson, MIT News Office, ''Math research team maps E8'' http://www.huliq.com/15695/mathematicians-map-e8</ref>\n\n==References==\n{{Reflist}}<!--added above categories/infobox footers by script-assisted edit-->\n\n{{DEFAULTSORT:Timeline Of Algebra And Geometry}}\n[[Category:Mathematics timelines|Algebra and geometry]]\n[[Category:Algebra| Timeline]]\n[[Category:Geometry| ]]"
    },
    {
      "title": "Akivis algebra",
      "url": "https://en.wikipedia.org/wiki/Akivis_algebra",
      "text": "{{Multiple issues|{{refimprove|date=November 2018}}{{more footnotes|date=November 2018}}}}\n\nIn [[mathematics]], and in particular the study of [[algebra]], an '''Akivis algebra''' is a [[nonassociative algebra]] equipped with a binary operator, the commutator <math>[x,y]</math> and a ternary operator, the associator <math>[x,y,z]</math> that satisfy a particular relationship known as the Akivis identity. They are named in honour of Russian mathematician Maks A. Akivis.\n\nFormally, if <math>A</math> is a [[vector space]] over a field <math>\\mathbb{F}</math> of [[characteristic (algebra)|characteristic zero]], we say <math>A</math> is an '''Akivis algebra''' if the operation <math>\\left(x,y\\right)\\mapsto\\left[x,y\\right]</math> is bilinear and [[anticommutative]]; and the trilinear operator <math>\\left(x,y,z\\right)\\mapsto\\left[x,y,z\\right]</math> satisfies the ''Akivis identity'':\n\n:<math>\n\\left[\\left[x,y\\right],z\\right]+\n\\left[\\left[y,z\\right],x\\right]+\n\\left[\\left[z,x\\right],y\\right]=\n\\left[x,y,z\\right]+\n\\left[y,z,x\\right]+\n\\left[z,x,y\\right]-\n\\left[x,z,y\\right]-\n\\left[y,x,z\\right]-\n\\left[z,y,x\\right].\n</math>\n\nAn Akivis algebra with <math>\\left[x,y,z\\right]=0</math> is a [[Lie algebra]], for the Akivis identity reduces to the [[Jacobi identity]]. Note that the terms on the right hand side have positive sign for even permutations and negative sign for odd permutations of <math>x,y,z</math>.\n\nAny nonassociative algebra is an Akivis algebra if we define <math>\\left[x,y\\right]=xy-yx</math> and <math>\\left[x,y,z\\right]=(xy)z-x(yz)</math>. It is known that all Akivis algebras may be represented as a subalgebra of a nonassociative algebra in this way (for associative algebras, the associator is identically zero, and the Akivis identity reduces to the Jacobi identity).\n\n== References ==\n* M. R. Bremner, I. R. Hentzel, and L. A. Peresi 2005. \"Dimension formulas for the free nonassociative algebra\". ''Communications in Algebra'' 33:4063-4081.\n\n[[Category:Algebra]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Rational difference equation",
      "url": "https://en.wikipedia.org/wiki/Rational_difference_equation",
      "text": "A '''rational difference equation''' is a nonlinear [[difference equation]] of the form<ref>Skellam,  J.G. (1951).  “Random dispersal in theoretical populations”, ''Biometrika'' '''38''' 196−218, eqns (41,42)</ref><ref>[https://books.google.com/books?id=4Kb3lO31NcAC&printsec=frontcover&dq=on+third+order+rational+difference+equations&source=bl&ots=JSV5xuGLO3&sig=Y_oeukThSmjZhsLRbloxDPuHnSg&hl=en&ei=artgTOvYOcL-8Ab2lMTgCQ&sa=X&oi=book_result&ct=result&resnum=6&ved=0CCsQ6AEwBQ#v=onepage&q&f=false Dynamics of third-order rational difference equations with open problems and Conjectures]</ref><ref name=\"Ladas-Kulenovic\">[https://books.google.com/books?id=zW7N4r64aZgC&printsec=frontcover&dq=on+second+order+rational+difference+equations&hl=en&ei=5b9gTPvTLoH78AaA6fyQCQ&sa=X&oi=book_result&ct=result&resnum=1&ved=0CC8Q6AEwAA#v=onepage&q&f=false Dynamics of Second-order rational difference equations with open problems and Conjectures]</ref><ref>Newth, Gerald, \"World order from chaotic beginnings\", ''Mathematical Gazette'' 88, March 2004, 39-45 gives a trigonometric approach.</ref>\n: <math>x_{n+1} = \\frac{\\alpha+\\sum_{i=0}^k \\beta_ix_{n-i}}{A+\\sum_{i=0}^k B_ix_{n-i}}~,</math>\nwhere the initial conditions <math>x_{0}, x_{-1},\\dots, x_{-k}</math> are such that the denominator  never vanishes for any {{mvar|n}}.\n\n==First-order rational difference equation==\nA '''first-order rational difference equation''' is a nonlinear [[difference equation]] of the form\n\n: <math>w_{t+1} = \\frac{aw_t+b}{cw_t+d}.</math>\n\nWhen <math>a,b,c,d</math> and the initial condition <math>w_{0}</math> are real numbers, this difference equation is called a '''Riccati difference equation'''.<ref name=\"Ladas-Kulenovic\"/>\n\nSuch an equation can be solved by writing <math>w_t</math> as a nonlinear transformation of another variable <math>x_t</math> which itself evolves linearly.  Then standard methods can be used to solve the [[linear difference equation]] in <math>x_t</math>.\n\n== Solving a first-order equation==\n\n===First approach===\n\nOne approach <ref>Brand, Louis, \"A sequence defined by a difference equation,\" ''[[American Mathematical Monthly]]'' '''62''', September 1955, 489&ndash;492.   [https://www.jstor.org/discover/10.2307/2307362  online]</ref> to developing the transformed variable <math>x_t</math>, when <math>ad-bc \\neq 0</math>, is to write\n: <math>y_{t+1}= \\alpha - \\frac{\\beta}{y_t}</math>\nwhere <math>\\alpha = (a+d)/c</math>  and <math>\\beta = (ad-bc)/c^{2}</math> and where <math>w_t = y_t -d/c</math>.\n\nFurther writing  <math>y_t = x_{t+1}/x_t</math> can be shown to yield\n: <math>x_{t+2} - \\alpha x_{t+1} + \\beta x_t =0. </math>\n\n===Second approach===\n\nThis approach <ref>Mitchell, Douglas W., \"An analytic Riccati solution for two-target discrete-time control,\" ''[[Journal of Economic Dynamics and Control]]'' 24, 2000, 615&ndash;622.</ref>  gives a first-order difference equation for <math>x_t</math> instead of a second-order one, for the case in which <math>(d-a)^{2}+4bc</math> is non-negative.  Write  <math>x_t = 1/(\\eta + w_t)</math>  implying <math>w_t = (1- \\eta x_t)/x_t</math>, where <math>\\eta</math> is given by <math>\\eta = (d-a+r)/2c</math> and where <math>r=\\sqrt{(d-a)^{2}+4bc}</math>.  Then it can be shown that <math>x_t</math> evolves according to\n\n: <math>x_{t+1} =\\left( \\frac{d-\\eta c}{\\eta c+a}\\right)x_t + \\frac{c}{\\eta c+a}.</math>\n\n===Third approach===\n\nThe equation\n\n: <math>w_{t+1} = \\frac{aw_t+b}{cw_t+d}</math>\n\ncan also be solved by treating it as a special case of the [[Matrix difference equation#Nonlinear matrix difference equations: Riccati equations|more general matrix equation]]\n\n:<math>X_{t+1} = -(E+BX_t)(C+AX_t)^{-1},</math>\n\nwhere all of ''A, B, C, E,'' and ''X'' are ''n''×''n'' matrices (in this case ''n''=1); the  solution of this is<ref>Martin, C. F., and Ammar, G., \"The geometry of the matrix Riccati equation and associated eigenvalue method,\" in Bittani, Laub, and Willems (eds.), ''The Riccati Equation'', Springer-Verlag, 1991.</ref>\n\n:<math>X_{t}=N_tD_t^{-1}</math>\n\nwhere\n\n:<math>\\begin{pmatrix} N_{t} \\\\ D_{t}\\end{pmatrix} = \\begin{pmatrix} -B & -E \\\\ A & C \\end{pmatrix}^t\\begin{pmatrix} X_0\\\\ I \\end{pmatrix}. </math>\n\n==Application==\n\nIt was shown in <ref>Balvers, Ronald J., and Mitchell, Douglas W., \"Reducing the dimensionality of linear quadratic control problems,\" ''[[Journal of Economic Dynamics and Control]]'' 31, 2007, 141&ndash;159.</ref> that a dynamic [[matrix Riccati equation]] of the form\n\n: <math> H_{t-1} = K +A'H_tA - A'H_tC(C'H_tC)^{-1}C'H_tA, </math>\n\nwhich can arise in some [[discrete-time]] [[optimal control]] problems, can be solved using the second approach above if the matrix ''C'' has only one more row than column.\n\n==References==\n\n<references/>\n\n==Further reading==\n\n* Simons, Stuart, \"A non-linear difference equation,\" ''Mathematical Gazette'' 93, November 2009, 500-504.\n\n{{DEFAULTSORT:Rational Difference Equation}}\n[[Category:Algebra|Algebra]]\n[[Category:Recurrence relations|Recurrence relations]]\n[[Category:Dynamical systems]]"
    },
    {
      "title": "List of algebraic constructions",
      "url": "https://en.wikipedia.org/wiki/List_of_algebraic_constructions",
      "text": "An '''algebraic construction''' is a method by which an [[algebra]]ic entity is defined or derived from another.\n\nInstances include:\n{{Expand list|date=February 2011}}\n* [[Cayley–Dickson construction]]\n* [[Proj construction]]\n* [[Grothendieck group]]\n* [[Gelfand–Naimark–Segal construction]]\n* [[Ultraproduct]]\n* [[ADHM construction]]\n* [[Burnside ring]]\n* [[Simplicial set]]\n* [[Fox derivative]]\n* [[Mapping cone (homological algebra)]]\n* [[Prym variety]]\n* [[Todd class]]\n* [[Adjunction (field theory)]]\n* [[Vaughan Jones construction]]\n* [[Strähle construction]]\n* [[Coset construction]]\n* [[Plus construction]]\n* [[Algebraic K-theory]]\n* [[Gelfand–Naimark–Segal construction]]\n* [[Stanley–Reisner ring]] construction\n* [[Quotient ring#Formal quotient ring construction|Quotient ring construction]]\n* [[Ward's twistor construction]]\n* [[Hilbert symbol]]\n* [[Hilbert's arithmetic of ends]]\n* [[Colombeau algebra|Colombeau's construction]]\n* [[Vector bundle]]\n* [[Integral monoid ring]] construction\n* [[Integral group ring]] construction\n* Category of [[Eilenberg–Moore algebra]]s\n* [[Kleisli category]]\n* [[Adjunction (field theory)]]\n* [[Lindenbaum–Tarski algebra]] construction\n* [[Freudenthal magic square]]\n* [[Stone–Čech compactification]]\n\n{{DEFAULTSORT:Algebraic constructions}}\n[[Category:Mathematics-related lists]]\n[[Category:Algebra]]"
    },
    {
      "title": "Algebraic signal processing",
      "url": "https://en.wikipedia.org/wiki/Algebraic_signal_processing",
      "text": "{{Orphan|date=September 2011}}\n\nIn the [[Abstract algebra|algebraic]] theory of linear [[signal processing]], a set of [[Filter (signal processing)|filter]]s is treated as an [[Algebra (ring theory)|algebra]] and a set of [[Signal (electrical engineering)|signal]]s is treated as a [[Module (mathematics)|module]] and the [[z-transform]] is generalized to [[linear map]]s.\n\n==References==\n* {{cite arxiv | last1=Püschel | first1=Markus | last2=Moura | first2=Jose M. F. | title=Algebraic Signal Processing Theory | date=2006 | eprint=cs/0612077}}.\n\n==External links==\n*[http://www.ece.cmu.edu/~smart/research.html Smart Project: Algebraic Theory of Signal Processing] at the Department of Electrical and Computer Engineering at Carnegie Mellon University.\n\n[[Category:Algebra]]\n[[Category:Signal processing]]\n\n\n{{electronics-stub}}"
    },
    {
      "title": "Algebraic solution",
      "url": "https://en.wikipedia.org/wiki/Algebraic_solution",
      "text": "{{Use American English|date = January 2019}}\n{{Short description|Close form expression of addition, subtraction, multiplication, division, powers and roots}}\n{{Confuse|Algebraic number}}\n\nAn '''algebraic solution''' or '''solution in radicals''' is a [[closed-form expression]], and more specifically a closed-form [[algebraic expression]], that is the solution of an [[algebraic equation]] in terms of the coefficients, relying only on [[addition]], [[subtraction]], [[multiplication]], [[Division (mathematics)|division]], raising to integer powers, and the extraction of [[nth root]]s (square roots, cube roots, and other integer roots). \n\nThe most well-known example is the solution \n\n:<math>\nx=\\frac{-b \\pm \\sqrt {b^2-4ac\\  }}{2a},</math>\n\nintroduced in secondary school, of the [[quadratic equation]]\n\n:<math>ax^2 + bx + c =0</math>\n\n(where ''a'' ≠ 0).\n\nThere exist more complicated algebraic solutions for the general [[cubic equation]]<ref>Nickalls, R. W. D., \"[http://img2.timg.co.il/forums/1_90809354.pdf A new approach to solving the cubic: Cardano's solution revealed],\" ''Mathematical Gazette'' 77, November 1993, 354-359.</ref> and [[quartic equation]].<ref>Carpenter, William, \"On the solution of the real quartic,\" ''Mathematics Magazine'' 39, 1966, 28-30.</ref>  The [[Abel–Ruffini theorem]]<ref>Jacobson, Nathan (2009), Basic Algebra 1 (2nd ed.), Dover, {{ISBN|978-0-486-47189-1}}</ref>{{rp|211}} states that the general [[quintic equation]] lacks an algebraic solution, and this directly implies that the general polynomial equation of degree ''n'', for ''n'' ≥ 5, cannot be solved algebraically. However, for ''n''  ≥ 5, some polynomial equations have algebraic solutions; for example, the equation <math>x^{10} = a</math> can be solved as <math>x=a^{1/10}.</math> See {{slink|Quintic function|Other solvable quintics}} for various other examples in degree 5.\n\n[[Évariste Galois]] introduced a criterion allowing one to decide which equations are solvable in radicals. See [[Radical extension]] for the precise formulation of his result.\n\nAlgebraic solutions form a subset of [[closed-form expression]]s, because the latter permit [[transcendental function]]s (non-algebraic functions) such as the exponential function, the logarithmic function, and the trigonometric functions and their inverses.\n\n==See also==\n*[[quintic equation#Solvable quintics|Solvable quintics]]\n*[[sextic equation#Solvable sextics|Solvable sextics]]\n*[[septic equation#Solvable septics|Solvable septics]]\n\n==References==\n{{reflist}}\n\n{{DEFAULTSORT:Algebraic Solution}}\n[[Category:Algebra]]\n[[Category:Equations]]\n\n{{algebra-stub}}"
    },
    {
      "title": "Amitsur complex",
      "url": "https://en.wikipedia.org/wiki/Amitsur_complex",
      "text": "In algebra, the '''Amitsur complex''' is a natural [[chain complex|complex]] associated to a [[ring homomorphism]] that, when the homomorphism is a [[faithfully flat]], is exact (thus determining a resolution). It was introduced in {{harv|Amitsur|1959}}.\n\nThe notion should be thought of as a mechanism to go beyond the conventional [[localization of rings and modules]]: see {{harv|M. Artin|loc=III.7.}}.\n\n== Definition ==\nLet <math>\\theta: R \\to S</math> be a homomorphism of (not-necessary-commutative) rings. First define the [[cosimplicial set]] <math>C^\\bullet = S^{\\otimes \\bullet+1}</math> as follows. Define the face maps <math>d^i: S^{\\otimes {n+1}} \\to S^{\\otimes n+2}</math> by inserting 1 at the ''i''-th spot:<ref group=note>Note the reference (M. Artin) seems to have a typo, and this should be the correct formula; see the calculation of ''s''<sup>0</sup> and ''d''<sup>2</sup> in the note.</ref>\n:<math>d^i(x_0 \\otimes \\cdots \\otimes x_n) = x_0 \\otimes \\cdots \\otimes x_{i-1} \\otimes 1 \\otimes x_i \\otimes \\cdots \\otimes x_n.</math>\nDefine the degeneracies <math>s^i: S^{\\otimes n+1} \\to S^{\\otimes n}</math> by multiplying out the ''i''-th and (''i''&nbsp;+&nbsp;1)-th spots:\n:<math>s^i(x_0 \\otimes \\cdots \\otimes x_n) = x_0 \\otimes \\cdots \\otimes x_i x_{i+1} \\otimes \\cdots \\otimes x_n.</math>\nThey satisfy the \"obvious\" cosimplicial identities and thus <math>S^{\\otimes \\bullet + 1}</math> is a cosimplicial set. It then determines the complex with the augumentation <math>\\theta</math>, the '''Amitsur complex''':<ref>{{harvnb|M. Artin|loc=III.6.}}</ref>\n:<math>0 \\to R \\,\\overset{\\theta}\\to\\, S \\,\\overset{\\delta^0}\\to\\, S^{\\otimes 2} \\,\\overset{\\delta^1}\\to\\, S^{\\otimes 3} \\to \\cdots</math>\nwhere <math>\\delta^n = \\sum_{i=0}^{n+1} (-1)^i d^i.</math>\n\n== A theorem of Grothendieck ==\nIn the notations of [[#Definition]], if <math>\\theta</math> is right faithfully flat, then a theorem of Grothendieck states that the (augmented) complex <math>0 \\to R \\overset{\\theta}\\to S^{\\otimes \\bullet + 1}</math> is exact and thus is a resolution. More generally,<ref>{{harvnb|M. Artin|loc=Theorem III.6.6.}}</ref>\n\n{{math_theorem|note=Grothendieck|math_statement=If <math>\\theta</math> is right faithfully flat, then, for each left ''R''-module ''M'',\n:<math>0 \\to M \\to S \\otimes_R M \\to S^{\\otimes 2} \\otimes_R M \\to S^{\\otimes 3} \\otimes_R M \\to \\cdots</math>\nis exact.}}\n\n''Proof'':\n\n'''Step 1''': The statement is true if <math>\\theta: R \\to S</math> splits as a ring homomorphism.\n\nThat \"<math>\\theta</math> splits\" is to say <math>\\rho \\circ \\theta = \\operatorname{id}_R</math> for some homomorphism <math>\\rho: S \\to R</math> (<math>\\rho</math> is a retraction and <math>\\theta</math> a section). Given such a <math>\\rho</math>, define\n:<math>h: S^{\\otimes n+1} \\otimes M \\to S^{\\otimes n} \\otimes M</math>\nby\n:<math>\\begin{align}\n& h(x_0 \\otimes m) = \\rho(x_0) \\otimes m, \\\\\n& h(x_0 \\otimes \\cdots \\otimes x_n \\otimes m) = \\theta(\\rho(x_0)) x_1 \\otimes \\cdots \\otimes x_n \\otimes m.\n\\end{align}</math>\nAn easy computation shows the following identity: with <math>\\delta^{-1}: M \\overset{\\theta \\otimes \\operatorname{id}_M}\\to S \\otimes_R M</math>,\n:<math>h \\circ \\delta^n + \\delta^{n-1} \\circ h = \\operatorname{id}_{S^{\\otimes n+1} \\otimes M}</math>.\nThis is to say that ''h'' is a [[homotopy operator]] and so <math>\\operatorname{id}_{S^{\\otimes n+1} \\otimes M}</math> determines the zero map on cohomology: i.e., the complex is exact.\n\n'''Step 2''': The statement is true in general.\n\nWe remark that <math>S \\to T := S \\otimes_R S, \\, x \\mapsto 1 \\otimes x</math> is a section of <math>T \\to S, \\, x \\otimes y \\mapsto xy</math>. Thus, Step 1 applied to the split ring homomorphism <math>S \\to T</math> implies:\n:<math>0 \\to M_S \\to T \\otimes_S M_S \\to T^{\\otimes 2} \\otimes_S M_S \\to \\cdots,</math>\nwhere <math>M_S = S \\otimes_R M</math>, is exact. Since <math>T \\otimes_S M_S \\simeq S^{\\otimes 2} \\otimes_R M</math>, etc., by \"faithfully flat\", the original sequence is exact. <math>\\square</math>\n\n== References ==\n{{reflist|group=note}}\n{{reflist}}\n*M. Artin, [http://www-math.mit.edu/~etingof/artinnotes.pdf noncommutative rings]\n*Shimshon Amitsur, “Simple algebras and cohomology groups of arbitrary fields,” Transactions of the American Mathematical Society Vol. 90, No. 1 (Jan., 1959), pp.&nbsp;73–112\n\n* {{nlab|id=Amitsur+complex|title=Amitsur complex}}\n\n[[Category:Algebra]]"
    },
    {
      "title": "Antiisomorphism",
      "url": "https://en.wikipedia.org/wiki/Antiisomorphism",
      "text": "{{Use American English|date = March 2019}}\n{{Short description|Isomorphism from A to the opposite of B}}\nIn [[category theory]], a branch of [[mathematics]], an '''antiisomorphism''' (or '''anti-isomorphism''') between [[Mathematical structure|structured sets]] ''A'' and ''B'' is an [[isomorphism]] from ''A'' to the [[Dual (category theory)|opposite]] of ''B'' (or equivalently from the opposite of ''A'' to ''B'').<ref>{{harvnb|Pareigis|loc=p. 19}}</ref> If there exists an antiisomorphism between two structures, they are said to be ''antiisomorphic.''\n\nIntuitively, to say that two mathematical structures are ''antiisomorphic'' is to say that they are basically opposites of one another.\n\nThe concept is particularly useful in an algebraic setting, as, for instance, when applied to [[ring (mathematics)|rings]].\n\n==Simple example==\nLet ''A'' be the [[binary relation]] (or [[directed graph]]) consisting of elements {1,2,3} and binary relation <math>\\rightarrow</math> defined as follows:\n* <math>1 \\rightarrow 2,</math>\n* <math>1 \\rightarrow 3,</math>\n* <math>2 \\rightarrow 1.</math>\n\nLet ''B'' be the binary relation set consisting of elements {''a'',''b'',''c''} and binary relation <math>\\Rightarrow</math> defined as follows:\n* <math>b \\Rightarrow a,</math>\n* <math>c \\Rightarrow a,</math>\n* <math>a \\Rightarrow b.</math>\n\nNote that the opposite of ''B'' (denoted ''B''<sup>op</sup>) is the same set of elements with the opposite binary relation <math>\\Leftarrow</math> (that is, reverse all the arcs of the directed graph):\n* <math>b \\Leftarrow a,</math>\n* <math>c \\Leftarrow a,</math>\n* <math>a \\Leftarrow b.</math>\n\nIf we replace ''a'', ''b'', and ''c'' with 1, 2, and 3 respectively, we see that each rule in ''B''<sup>op</sup> is the same as some rule in ''A''. That is, we can define an isomorphism <math>\\phi</math> from ''A'' to ''B''<sup>op</sup> by <math>\\phi(1) = a, \\phi(2) = b, \\phi(3) = c</math>. <math>\\phi</math> is then an antiisomorphism between ''A'' and ''B''.\n\n==Ring anti-isomorphisms==\nSpecializing the general language of category theory to the algebraic topic of rings, we have:\nLet ''R'' and ''S'' be rings and ''f'': ''R'' → ''S'' be a [[bijection]]. Then ''f'' is a ''ring anti-isomorphism''<ref>{{harvnb|Jacobson|loc=p. 16}}</ref> if\n:<math>f(x +_R y) = f(x) +_S f(y) \\ \\ \\ \\text{and} \\ \\ \\ f(x \\cdot_R y) = f(y) \\cdot_S f(x) \\ \\ \\ \\text{for all } x,y \\in R.</math>\nIf ''R'' = ''S'' then ''f'' is a ring ''anti-automorphism''.\n\nAn example of a ring anti-automorphism is given by the conjugate mapping of [[quaternion]]s:<ref>{{harvnb|Baer|loc=p. 96}}</ref>\n:<math> x_0 + x_1 \\mathbf{i} + x_2 \\mathbf{j} + x_3 \\mathbf{k} \\ \\ \\mapsto \\ \\ x_0 - x_1 \\mathbf{i} - x_2 \\mathbf{j} - x_3 \\mathbf{k}.</math>\n\n==Notes==\n{{reflist|3}}\n\n==References==\n* {{citation|first=Reinhold|last=Baer|title=Linear Algebra and Projective Geometry|year=2005|origyear=1952|publisher=Dover|isbn=0-486-44565-8}}\n* {{citation|first=Nathan|last=Jacobson|title=The Theory of Rings|year=1948|publisher=American Mathematical Society|isbn=0-8218-1502-4}}\n* {{citation|first=Bodo|last=Pareigis|title=Categories and Functors|year=1970|publisher=Academic Press|isbn=0-12-545150-4}}\n\n[[Category:Morphisms]]\n[[Category:Ring theory]]\n[[Category:Algebra]]"
    },
    {
      "title": "Antivector",
      "url": "https://en.wikipedia.org/wiki/Antivector",
      "text": "An '''antivector''' is an element of grade {{nowrap|''n'' − 1}} in an ''n''-dimensional [[exterior algebra]].<ref>{{cite book |title=Foundations of Game Engine Development, Volume 1: Mathematics |last1=Lengyel |first1=Eric |publisher= Terathon Software LLC|year=2016 |isbn=978-0-9858117-4-7}}</ref> An antivector is always a [[Blade (geometry) | blade]], and it gets its name from the fact that its components each involve a combination of all except one basis vector, thus being the opposite of a vector whose components each involve exactly one basis vector. Like a vector, an antivector has ''n'' components in ''n''-dimensional space, and this sometimes leads to an inadequate distinction being made between the two types of entities. However, antivectors transform differently with a change of basis than vectors do, which shows that they are different kinds of quantities. \n\nIn physics, the names ''[[pseudovector]]'' and ''axial vector'' are used to describe vectors that transform in the same way that an antivector transforms. These typically arise as the result of cross products between two vectors.\n\n==See also==\n*[[Exterior algebra]]\n*[[Geometric algebra]]\n\n== References ==\n{{reflist}}\n\n[[Category:Algebra]]\n\n{{algebra-stub}}"
    },
    {
      "title": "Basic element",
      "url": "https://en.wikipedia.org/wiki/Basic_element",
      "text": "{{Other uses|Basic Element (disambiguation)}}\n{{orphan|date=April 2014}}\nIn algebra, a '''basic element''' ''x'' with respect to an element ''y'' is an element of a [[cochain complex]] <math>(C^*, d)</math> (e.g., complex of [[differential form]]s on a manifold) that is closed: <math>dx = 0</math> and the contraction of ''x'' by ''y'' is zero.\n\n[[Category:Algebra]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Binomial (polynomial)",
      "url": "https://en.wikipedia.org/wiki/Binomial_%28polynomial%29",
      "text": "{{other uses|Binomial (disambiguation){{!}}Binomial}}\n\nIn [[algebra]], a '''binomial''' is a [[polynomial]] that is the sum of two terms, each of which is a [[monomial]].<ref>{{Cite web\n  | last = Weisstein\n  | first = Eric\n  | authorlink = Eric Weisstein\n  | coauthors = \n  | title = Binomial\n  | work = \n  | publisher = Wolfram MathWorld\n  | date = \n  | url = http://mathworld.wolfram.com/Binomial.html\n  | doi = \n  | accessdate = 29 March 2011}}</ref> It is the simplest kind of polynomial after the monomials.\n\n==Definition==\nA binomial is a polynomial which is the sum of two [[monomial]]s. A binomial in a single indeterminate (also known as a [[univariate]] binomial) can be written in the form\n:<math>a x^m - bx^n \\,,</math>\nwhere {{math|''a''}} and {{math|''b''}} are [[number]]s, and {{math|''m''}} and {{math|''n''}} are distinct [[nonnegative integer]]s and {{math|''x''}} is a symbol which is called an [[indeterminate (variable)|indeterminate]] or, for historical reasons, a [[variable (mathematics)|variable]]. In the context of [[Laurent polynomial]]s, a ''Laurent binomial'', often simply called a ''binomial'', is similarly defined, but the exponents {{math|''m''}} and {{math|''n''}} may be negative.\n\nMore generally, a binomial may be written<ref name=Sturmfels62>{{Cite journal\n  | last = Sturmfels\n  | first = Bernd\n  | authorlink = Bernd Sturmfels\n  | journal = CBMS Regional Conference Series in Mathematics\n  | title = Solving Systems of Polynomial Equations\n  | publisher = Conference Board of the Mathematical Sciences\n  | issue = 97\n  | page = 62\n  | year = 2002\n  | url = https://books.google.com/books?id=N9c8bWxkz9gC\n  | accessdate = 21 March 2014}}</ref> as:\n:<math>a x_1^{n_1}\\dotsb x_i^{n_i} - b x_1^{m_1}\\dotsb x_i^{m_i}</math>\n\nSome examples of binomials are:\n:<math>3x - 2x^2</math>\n:<math>xy + yx^2</math>\n:<math>0.9 x^3 + \\pi y^2</math>\n\n==Operations on simple binomials==\n*The binomial {{math|''x''<sup>2</sup> − ''y''<sup>2</sup>}} can be [[factored]] as the product of two other binomials:\n::<math> x^2 - y^2 = (x + y)(x - y). </math>\n:This is a [[special case]] of the more general formula:\n::<math> x^{n+1} - y^{n+1} = (x - y)\\sum_{k=0}^{n} x^{k}\\,y^{n-k}.</math>\n:When working over the complex numbers, this can also be extended to:\n::<math> x^2 + y^2 = x^2 - (iy)^2 = (x - iy)(x + iy). </math>\n*The product of a pair of linear binomials {{math|(''ax'' + ''b'')}} and {{math|(''cx'' + ''d'')}} is a [[trinomial]]:\n::<math> (ax+b)(cx+d) = acx^2+(ad+bc)x+bd.</math>\n*A binomial raised to the {{math|''n''}}<sup>th</sup> [[Exponentiation|power]], represented as {{math|(''x + y'')<sup>''n''</sup>}} can be expanded by means of the [[binomial theorem]] or, equivalently, using [[Pascal's triangle]]. For example, the square {{math|(''x + y'')<sup>2</sup>}} of the binomial {{math|(''x + y'')}} is equal to the sum of the squares of the two terms and twice the product of the terms, that is:\n::<math> (x + y)^2 = x^2 + 2xy + y^2.</math>\n:The numbers (1,&nbsp;2,&nbsp;1) appearing as multipliers for the terms in this expansion are [[binomial coefficient]]s two rows down from the top of Pascal's triangle. The expansion of the {{math|''n''}}<sup>th</sup> power uses the numbers {{math|''n''}} rows down from the top of the triangle.\n*An application of above formula for the square of a binomial is the \"{{math|(''m, n'')}}-formula\" for generating [[Pythagorean triple]]s:\n:For {{math|''m < n''}}, let {{math|''a'' {{=}} ''n''<sup>2</sup> − ''m''<sup>2</sup>}}, {{math|''b'' {{=}} 2''mn''}}, and {{math|''c'' {{=}} ''n''<sup>2</sup> + ''m''<sup>2</sup>}}; then {{math|''a''<sup>2</sup> + ''b''<sup>2</sup> {{=}} ''c''<sup>2</sup>}}.\n* Binomials that are sums or differences of cubes can be factored into lower-order polynomials as follows:\n::<math> x^3 + y^3 = (x + y)(x^2 - xy + y^2) </math>\n::<math> x^3 - y^3 = (x - y)(x^2 + xy + y^2) </math>\n\n==See also==\n*[[Completing the square]]\n*[[Binomial distribution]]\n*[[List of factorial and binomial topics]] (which contains a large number of related links)\n\n== Notes ==\n{{reflist}}\n\n==References==\n* {{cite book |first1=L. |last1=Bostock |author-link1=Linda Bostock |first2=S. |last2=Chandler |author-link2=Sue Chandler |title=Pure Mathematics 1 |isbn=0-85950-092-6 |publisher=[[Oxford University Press]] |date=1978 |page=36}}\n\n[[Category:Algebra]]\n[[Category:Factorial and binomial topics]]\n\n{{polynomials}}"
    },
    {
      "title": "Board puzzles with algebra of binary variables",
      "url": "https://en.wikipedia.org/wiki/Board_puzzles_with_algebra_of_binary_variables",
      "text": "{{multiple issues|\n{{original research|date=December 2012}}\n{{refimprove|date=October 2010}}\n}}\n\n'''Board puzzles with algebra of binary variables''' ask players to locate the hidden objects based on a set of clue cells and their neighbors marked as variables (unknowns). A variable with value of 1 corresponds to a cell with an object. Contrary, a variable with value of 0 corresponds to an empty cell—no hidden object.\n\n==Overview==\nThese puzzles are based on algebra with binary variables taking a pair of values, for example, (no, yes), (false, true), (not exists, exists), ('''0''',&nbsp;'''1'''). It invites the player quickly establish some equations, and  inequalities for the solution. The [[Partition of a set|partitioning]] can be used to reduce the complexity of the problem. Moreover, if the puzzle is prepared in a way that there exists [[Unique (mathematics)|a unique solution only]], this fact can be used to eliminate some variables without calculation.\n\nThe problem can be modeled as [[Linear program#Integer unknowns|binary integer linear programming]] which is a special case of integer linear programming.<ref>Schrijver 1986</ref>\n\n==History==\n[[Minesweeper (video game)|Minesweeper]], along with its [[Minesweeper (video game)#Distribution and variants|variants]], is the most notable example of this type of puzzle.\n\n==Algebra with binary variables==\n\nBelow the letters in the mathematical statements are used as variables where each can take the value either '''0''' or '''1''' only. A simple example of an equation with binary variables is given below:\n\n:'''''a''''' '''+''' '''''b''''' '''=''' '''0'''\n\nHere there are two variables '''''a''''' and '''''b''''' but one equation. The solution is constrained by the fact that '''''a''''' and '''''b''''' can take only values '''0''' or '''1'''. There is only one solution here, both '''''a''''' '''= 0''', and '''''b''''' '''= 0'''. Another simple example is given below:\n\n:'''''a''''' '''+''' '''''b''''' '''=''' '''2'''\n\nThe solution is straightforward: '''''a''''' and '''''b''''' must be '''1''' to make '''''a''''' '''+''' '''''b''''' equal to '''2'''.\n\nAnother interesting case is shown below:\n\n:'''''a''''' '''+''' '''''b''''' '''+''' '''''c''''' '''=''' '''2'''\n\n:'''''a''''' '''+''' '''''b''''' '''≤''' '''1'''\n\nHere, the first statement is an equation and the second statement is an inequality indicating the three possible cases:\n\n#'''''a''''' '''= 1''' and '''''b''''' '''= 0''',\n#'''''a''''' '''= 0''' and '''''b''''' '''= 1''', and\n#'''''a''''' '''= 0''' and '''''b''''' '''= 0''',\n\nThe last case causes a contradiction on '''''c''''' by forcing '''''c''''' '''= 2''', which is not possible. Therefore, either first or second case is correct. This leads to the fact that '''''c''''' must be '''1'''.\n\nThe modification of a large equation into smaller form is not difficult. However, an equation set with binary variables cannot be always solved by applying linear algebra. The following is an example for applying the subtraction of two equations:\n\n:'''''a''''' '''+''' '''''b''''' '''+''' '''''c''''' '''+''' '''''d''''' '''= 3'''\n\n:'''''c''''' '''+''' '''''d''''' '''= 1'''\n\nThe first statement has four variables whereas the second statement has only two variables. The latter one means that the sum of '''''c''''' and '''''d''''' is '''1'''. Using this fact on the first statement, the equations above can be reduced to\n\n:'''''a''''' '''+''' '''''b''''' '''= 2'''\n\n:'''''c''''' '''+''' '''''d''''' '''= 1'''\n\n==The algebra on a board==\n[[File:tentaizu 4x4 example.png|thumb|right|alt=tentaizu_4x4_example|Figure 1: An example puzzle on 4x4 board]]\n\nA game based on the algebra with binary variables can be visualized in many different ways. One generic way is to represent the right side of an equation as a clue in a cell (clue cell), and the neighbors of a clue cell as variables. A simple case is shown in Figure 1. The neighbors can be assumed to be the up/down, left/right, and corner cells that are sharing an edge or a corner. The white cells may contain a hidden object or nothing. In other words, they are the binary variables.  They take place on the left side of the equations. Each clue cell, a cell with blue background in Figure 1, contains a positive number corresponding to the number of its neighbors that have hidden objects. The total number of the objects on the board can be given as an additional clue. The same board with variables marked is shown in Figure 2.\n\n===The reduction into a set of equations with binary variables===\nThe main equation is written by using the total number of the hidden objects given. From the first figure this corresponds to the following equation\n\n:'''''a''''' '''+''' '''''b''''' '''+''' '''''c''''' '''+''' '''''d''''' '''+''' '''''e''''' '''+''' '''''f''''' '''+''' '''''g''''' '''+''' '''''h''''' '''+''' '''''i''''' '''+''' '''''j''''' '''+''' '''''k''''' '''+''' '''''m''''' '''= 3'''\n\nThe other equations are composed one by one for each clue cells:\n\n:'''''a''''' '''+''' '''''b''''' '''+''' '''''c''''' '''+''' '''''e''''' '''+''' '''''f''''' '''+''' '''''h''''' '''+''' '''''i''''' '''+''' '''''j''''' '''= 1'''\n\n:'''''f''''' '''+''' '''''g''''' '''+''' '''''j''''' '''+''' '''''m''''' '''= 1'''\n\n:'''''h''''' '''+''' '''''i''''' '''+''' '''''j''''' '''+''' '''''k''''' '''= 2'''\n\n:'''''i''''' '''+''' '''''j''''' '''+''' '''''m''''' '''= 2'''\n\nAlthough there are several ways to solve the equations above, the following explicit way can be applied:\n\n#It is known from the equation set that '''''i''''' '''+''' '''''j''''' '''+''' '''''m''''' '''= 2'''. However, since '''''j''''' and '''''m''''' are neighbors of a cell with number '''1''', the following is true: '''''j''''' '''+''' '''''m''''' '''≤ 1'''. This means that the variable '''''i''''' must be '''1'''.\n#Since '''''i''''' '''= 1''' and the variable '''''i''''' is the neighbor to the clue cell with number '''1''', the variables '''''a''''', '''''b''''', '''''c''''', '''''e''''', '''''f''''', '''''h''''', and '''''j''''' must be zero. The same result can be obtained by replacing '''''i''''' '''= 1''' into the second equation as follows: '''''a''''' '''+''' '''''b''''' '''+''' '''''c''''' '''+''' '''''e''''' '''+''' '''''f''''' '''+''' '''''h''''' '''+''' '''''j''''' '''= 0'''. This is equivalent to '''''a''''' '''= 0''', '''''b''''' '''= 0''', '''''c''''' '''= 0''', '''''e''''' '''= 0''', '''''f''''' '''= 0''', '''''h''''' '''= 0''', '''''j''''' '''= 0'''.\n#Figure 3 is obtained after Step 1 and Step 2. The grayed cells with '–' are the variables with value '''0'''. The cell with the symbol '''Δ''' corresponds to the variable with value '''1'''. The variable '''''k''''' is the only neighbor of the left most clue cell with value '''2'''. This clue cell has one neighbor with an object and only one remaining cell with variable '''''k'''''. Therefore, '''''k''''' must be '''1'''.\n#Similarly, the variable '''''m''''' must be '''1''' too because it is the only remaining variable neighbor to the right most clue cell with value '''2'''.\n#Since '''''k''''' '''= 1''', '''''m''''' '''= 1''' and '''''i''''' '''= 1''', we complete the marking of three hidden objects therefore '''''d''''' '''= 0''', and '''''g''''' '''= 0'''. The final solution is given in Figure 4.\n\n{|\n| [[Image:tentaizu 4x4 example with variables.png|thumb|upright|alt=tentaizu_4x4_example_with_variables|Figure 2: Binary variables are marked]]\n| [[Image:tentaizu 4x4 example with variables solved partially.png|thumb|upright|alt=tentaizu_4x4_example_solved_partially|Figure 3: The example solved partially]]\n| [[Image:tentaizu 4x4 example solved.png|thumb|upright|alt=tentaizu_4x4_example_with_variables_solved|Figure 4: The example solved]]\n|}\n\n===Use of uniqueness===\n\nIn the example above (Figure 2), the variables '''''a''''', '''''b''''', '''''c''''', and '''''e''''' are the neighbors of the clue cell '''1''' and they are not neighbors of any other cell. It is obvious that the followings are possible solutions:\n\n*'''''a''''' '''= 1''', '''''b''''' '''= 0''', '''''c''''' '''= 0''', '''''e''''' '''= 0'''\n*'''''a''''' '''= 0''', '''''b''''' '''= 1''', '''''c''''' '''= 0''', '''''e''''' '''= 0'''\n*'''''a''''' '''= 0''', '''''b''''' '''= 0''', '''''c''''' '''= 1''', '''''e''''' '''= 0'''\n*'''''a''''' '''= 0''', '''''b''''' '''= 0''', '''''c''''' '''= 0''', '''''e''''' '''= 1'''\n\nHowever, if the puzzle is prepared so that we should have one only one (unique) solution, we can set that all these variables '''''a''''', '''''b''''', '''''c''''', and '''''e''''' must be 0. Otherwise there become more than one solutions.\n\n===Use of partitioning===\n[[File:tentaizu 4x4 example partitioned.png|thumb|right|alt=tentaizu_4x4_example_partitioned|Figure 5: An example for partitioning]]\n\nSome puzzle configurations may allow the player to use partitioning<ref>Halmos 1960</ref> for complexity reduction. An example is given in Figure 5. Each partition corresponds to a number of the objects hidden. The sum of the hidden objects in the partitions must be equal to the total number of objects hidden on the board. One possible way to determine a partitioning is to choose the lead clue cells which have no common neighbors. The cells outside of the red transparent zones in Figure 5 must be empty. In other words, there are no hidden objects in the all-white cells. Since there must be a hidden object within the upper partition zone, the third row from top shouldn't contain a hidden object. This leads to the fact that the two variable cells on the bottom row around the clue cell must have hidden objects. The rest of the solution is straightforward.\n\n===Use of try-and-check method===\n[[File:tentaizu 4x4 example for inconsistency.png|thumb|left|alt=tentaizu_4x4_example_for_inconsistency|Figure 6: An example for try-and-check method]]\n\nAt some cases, the player can set a variable cell as '''1''' and check if any inconsistency occurs. The example in Figure 6 shows an inconsistency check. The cell marked with an hidden object '''Δ''' is under the test. Its marking leads to the set all the variables (grayed cells) to be '''0'''. This follows the inconsistency. The clue cell marked red with value '''1''' does not have any remaining neighbor that can include a hidden object. Therefore, the cell under the test must not include a hidden object. In algebraic form we have two equations:\n\n:'''''a''''' '''+''' '''''b''''' '''+''' '''''c''''' '''+''' '''''d''''' '''= 1'''\n\n:'''''a''''' '''+''' '''''b''''' '''+''' '''''c''''' '''+''' '''''d''''' '''+''' '''''e''''' '''+''' '''''f''''' '''+''' '''''g''''' '''= 1'''\n\nHere '''''a''''', '''''b''''', '''''c''''', and '''''d''''' correspond to the top four grayed cells in Figure 6. The cell with '''''Δ''''' is represented by the variable '''''f''''', and the other two grayed cells are marked as '''''e''''' and '''''g'''''. If we set '''''f''''' '''= 1''', then '''''a''''' '''= 0''', '''''b''''' '''= 0''', '''''c''''' '''= 0''', '''''d''''' '''= 0''', '''''e''''' '''= 0''', '''''g''''' '''= 0'''. The first equation above will have the left hand side equal to '''0''' while the right hand side has '''1'''. A contradiction.\n\nTry-and-check may need to be applied consequently in more than one step on some puzzles in order to reach a conclusion. This is equivalent to [[binary search algorithm]]<ref>Drozdek 2000</ref> to eliminate possible paths which lead to inconsistency.\n\n==Complexity==\n\nBecause of binary variables, the equation set for the solution does not possess linearity property. In other words, the rank of the equation matrix may not always address the right complexity.\n\nThe complexity of this class of puzzles can be adjusted in several ways. One of the simplest method is to set a ratio of the number of the clue cells to the total number of the cells on the board. However, this may result a largely varying complexity range for a fixed ratio. Another method is to reduce clue cells based on some problem solving strategies step by step. The complex strategies may be enabled for high complexity levels such as subtracting an equation with another one, or the higher depth of try-and-check steps. When the board size increases, the range of the problem cases increases. The ratio of the number of hidden objects to the total number of cells affects the complexity of the puzzle too.\n\n==See also==\n*[[Minesweeper (video game)|Minesweeper]]\n\n==Notes==\n{{Reflist|2}}\n\n==References==\n*[[Paul Halmos]], ''Naive set theory''. Princeton, NJ: D. Van Nostrand Company, 1960. Reprinted by Springer-Verlag, New York, 1974. {{ISBN|0-387-90092-6}} (Springer-Verlag edition).\n*[[Alexander Schrijver]], ''Theory of Linear and Integer Programming''. John Wiley & Sons, 1986. Reprinted in 1999. {{ISBN|0-471-98232-6}}.\n*Adam Drozdek, ''Data Structures and Algorithms in C++'', Brooks/Cole, second edition, 2000. {{ISBN|0-534-37597-9}}.\n\n==External links==\n* [https://tentaizuhexontheweb.appspot.com Tentaizu Hex (free of charge web app)]\n\n[[Category:Puzzles]]\n[[Category:Algebra]]\n[[Category:Variables (mathematics)]]\n[[Category:Equations]]"
    },
    {
      "title": "Boolean differential calculus",
      "url": "https://en.wikipedia.org/wiki/Boolean_differential_calculus",
      "text": "{{short description|a subject field of Boolean algebra discussing changes of Boolean variables and functions}}\n{{bots|deny=Citation bot}}\n{{Use dmy dates|date=May 2019|cs1-dates=y}}\n'''Boolean differential calculus''' ('''BDC''') (German: '''{{lang|de|Boolescher Differentialkalkül}}''' ('''BDK''')) is a subject field of [[Boolean algebra]] discussing changes of [[Boolean variable]]s and [[Boolean function]]s.\n\nThe Boolean differential calculus allows various aspects of [[dynamical systems theory]] like\n\n* [[automata theory]] on [[finite automata]]\n* [[Petri net theory]]<ref name=\"Scheuring_Wehlan_1991_Petri\"/>\n* [[supervisory control theory]] (SCT)\n\nto be discussed in a united and closed form and their specific advantages to be combined.\n\n== History and applications ==\nOriginally inspired by the design and testing of [[switching circuit]]s and the utilization of [[error-correcting code]]s in [[electrical engineering]], the roots for the development of what later would evolve into the Boolean differential calculus were initiated by works of [[Irving S. Reed]],<ref name=\"Reed_1954\"/> [[David E. Muller]],<ref name=\"Muller_1954\"/> [[David A. Huffman]],<ref name=\"Huffman_1958\"/> [[Sheldon B. Akers|Sheldon B.<!-- Buckingham --> Akers, Jr.]]<ref name=\"Akers_1959\"/> and {{lang|ru|[[A. D. Talantsev]]}} ({{lang|ru|A. D. Talancev}}, {{lang|ru|А. Д. Таланцев}})<ref name=\"Talantsev_1959\"/> between 1954 and 1959, and of [[Frederick F. Sellers|Frederick F. Sellers, Jr.]],<ref name=\"Sellers_Hsiao_Bearnson_1968_1\"/><ref name=\"Sellers_Hsiao_Bearnson_1968_2\"/> [[Mu-Yue Hsiao]]<ref name=\"Sellers_Hsiao_Bearnson_1968_1\"/><ref name=\"Sellers_Hsiao_Bearnson_1968_2\"/> and [[Leroy W. Bearnson]]<ref name=\"Sellers_Hsiao_Bearnson_1968_1\"/><ref name=\"Sellers_Hsiao_Bearnson_1968_2\"/> in 1968.\n\nSince then, significant advances were accomplished in both, the theory and in the application of the BDC in switching circuit design and [[logic synthesis]].\n\nWorks of {{lang|fr|[[André Thayse]]}},<ref name=\"Thayse_1970\"/><ref name=\"Thayse_1971\"/><ref name=\"Thayse_Davio_1973\"/><ref name=\"Davio_Deschamps_Thayse_1978\"/><ref name=\"Thayse_1981\"/> [[Marc Davio]]<ref name=\"Thayse_1971\"/><ref name=\"Thayse_Davio_1973\"/><ref name=\"Davio_Deschamps_Thayse_1978\"/> and {{lang|fr|[[Jean-Pierre Deschamps]]}}<ref name=\"Davio_Deschamps_Thayse_1978\"/> in the 1970s formed the basics of BDC on which {{lang|de|{{ill|Dieter Bochmann|de}}}},<ref name=\"Bochmann_Posthoff_1981\"/> {{lang|de|[[Christian Posthoff]]}}<ref name=\"Bochmann_Posthoff_1981\"/> and {{lang|de|{{ill|Bernd Steinbach|de}}}}<ref name=\"Bochmann_Steinbach_1991\"/> further developed BDC into a self-contained mathematical theory later on.\n\n{{anchor|Boolean integral calculus}}A complementary theory of '''Boolean integral calculus''' (German: '''{{lang|de|Boolescher Integralkalkül}}''') has been developed as well.<ref name=\"Bochmann_Posthoff_1981\"/><ref name=\"Steinbach_Posthoff_2013_2\"/>\n\nBDC has also found uses in [[discrete event dynamic system]]s (DEDS)<ref name=\"Scheuring_Wehlan_1991_DEDS\"/> in [[digital network]] [[communication protocol]]s.\n\n{{anchor|Logic differential calculus}}Meanwhile BDC has seen extensions to [[multi-valued function|multi-valued]] variables and functions<ref name=\"Bochmann_Posthoff_1981\"/><ref name=\"Yanushkevich_1998\"/><ref name=\"Bochmann_2006_2008\"/> as well as to [[lattice (module)<!-- TBD? -->|lattice]]s of Boolean functions.<ref name=\"Steinbach_Posthoff_2013_1\"/><ref name=\"Steinbach_Posthoff_2017\"/>\n\n== Overview ==\nBoolean [[differential operator]]s play a significant role in BDC. They allow the application of [[differential (mathematics)|differential]]s as known from classical [[analysis (mathematics)|analysis]] to be extended to logical functions.\n\nThe differentials <math>dx_i</math> of a Boolean variable <math>x_i</math> models the relation:\n\n: <math>dx_i = \\begin{cases}\n  0,  & \\text{no change of } x_i\\\\\n  1, & \\text{change of } x_i\n\\end{cases}\n</math>\n\nThere are no constraints in regard to the nature, the causes and consequences of a change.\n\nThe differentials <math>dx_i</math> are binary. They can be used just like common binary variables.\n\n== See also ==\n* [[Boole's expansion theorem]]\n* [[Ramadge–Wonham framework]]\n\n== References ==\n{{reflist|refs=\n<ref name=\"Reed_1954\">{{cite journal |author-first=Irving Stoy |author-last=Reed |author-link=Irving Stoy Reed |date=1954 |title=A Class of Multiple-Error-Correcting Codes and the Decoding Scheme |work=Transactions of the [[IRE Professional Group on Information Theory]] (PGIT) |publisher=[[Institute of Radio Engineers]] (IRE) |volume=PGIT-4 |issue=4 |pages=38–49}} (12 pages)</ref>\n<ref name=\"Muller_1954\">{{cite journal |author-first=David Eugene |author-last=Muller |author-link=David Eugene Muller |title=Application of Boolean algebra to switching circuit design and to error detection |journal=Transactions of the [[IRE Professional Group on Electronic Computers]] (PGEC) |volume=PGEC-3 |date=1954 |pages=6–12}} (7 pages)</ref>\n<ref name=\"Huffman_1958\">{{cite journal |author-first=David Albert |author-last=Huffman |author-link=David Albert Huffman |title=Solvability criterion for simultaneous logical equations |publisher=MIT Research Laboratory of Electronics |location=Cambridge, MA, USA |journal=Quarterly Progress Report |number=48 |id=AD 156-161 |date=1958-01-15 |pages=87–88}} (2 pages)</ref>\n<ref name=\"Akers_1959\">{{cite journal |author-first=Sheldon Buckingham |author-last=Akers, Jr. |title=On a Theory of Boolean Functions |journal=[[Journal of the Society for Industrial and Applied Mathematics]] |publisher=[[Society for Industrial and Applied Mathematics]] (SIAM) |volume=7 |number=4 |date=December 1959 |orig-year=1957-09-27 (submission), 1959-05-28 (revision) |issn=0368-4245 |doi=10.1137/0107041 |pages=487-498}} (12 pages)</ref>\n<ref name=\"Talantsev_1959\">{{cite journal |author-first=А. Д. [A. D.] |author-last=Таланцев [Talantsev<!-- Talancev -->] |script-title=ru:б анализе и синтезе некоторых электрических схем при помощи специальных логических операторов |title=Ob analize i sinteze nekotorykh električeskikh skhem pri pomośći special'nykh logičeskikh operatorov |language=Russian |trans-title=Analysis and synthesis of certain electric circuits by means of special logical operators |journal=[[Автоматика и телемеханика]] ([[Avtomatika i telemekhanika]]) <nowiki>[</nowiki>[[Automation and Remote Control]]<nowiki>]</nowiki> |volume=20 |number=7 |date=1959 |orig-year=1958-11-01 (submission) |location=Moscow, Russia |pages=898–907 |id={{mathnet|at12783}} |url=http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=at&paperid=12783&option_lang=rus |access-date=2017-10-17 |dead-url=no |archive-url=https://web.archive.org/web/20171017090358/http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=at&paperid=12783&option_lang=rus |archive-date=2017-10-17 |quote=[…] Основное содержание статьи доложено на семинаре по техническим приложениям математической логики в МГУ 2/Х 1958 г. и 16/1 1959 […] Автор считает своим долгом выразить признательность {{ill|Vadim Aleksandrovich Trapeznikov{{!}}В. А. Трапезникову|ru|Трапезников, Вадим Александрович}}, [[Виктор Иванович Шестаков|В. И. Шестакову]] и [[Михаил Львович Цетлин|М. Л. Цетлину]] за интерес к работе и ценные замечания при обсуждении результатов. […] [[…] The main content of the article was presented at the technical application workshop on mathematical logic at the [[Moscow State University]] on 1958-10-02 and 1959-01-16 […] The author considers it his duty to express gratitude to {{ill|Vadim Aleksandrovich Trapeznikov{{!}}V. A. Trapeznikov|ru|Трапезников, Вадим Александрович}}, [[Victor Ivanovich Shestakov|V. I. Shestakov]] and [[Michael Lvovitch Tsetlin|M. L. Tsetlin]] for interest in the work and valuable comments in discussing the results.[…]]}} (10 pages)</ref>\n<ref name=\"Sellers_Hsiao_Bearnson_1968_1\">{{cite journal |author-first1=Frederick F. |author-last1=Sellers, Jr. |author-first2=Mu-Yue |author-last2=Hsiao |author-first3=Leroy W. |author-last3=Bearnson |title=Analyzing Errors with the Boolean Difference |journal=[[IEEE Transactions on Computers]] |volume=C-17 |issue=7 |pages=676-683 |date=July 1968 |issn=0018-9340 |doi=10.1109/TC.1968.227417}} (8 pages)</ref>\n<ref name=\"Sellers_Hsiao_Bearnson_1968_2\">{{cite book |author-first1=Frederick F. |author-last1=Sellers, Jr. |author-first2=Mu-Yue |author-last2=Hsiao |author-first3=Leroy W. |author-last3=Bearnson |title=Error Detecting Logic for Digital Computers |publisher=[[McGraw-Hill Book Company]] |location=New York, USA |edition=1st |oclc=439460 |lccn=68-16491 |pages=17–37 |date=November 1968}} (21 of xviii+295 pages)</ref>\n<ref name=\"Thayse_1970\">{{cite journal |author-first=André |author-last=Thayse |title=Transient analysis of logical networks applied to hazard detection |journal=[[Philips Research Reports]] |publisher=[[Philips Research Laboratory]], {{lang|fr|Manufacture Belge de Lampes et de Materiel Electronique}} (MBLE Research Laboratory) |location=Brussels, Belgium |volume=25 |number=5 |date=October 1970 |orig-year=May 1970 |pages=261-336 |id=R737 |url=http://www.extra.research.philips.com/hera/people/aarts/_Philips%20Bound%20Archive/PRRep/PRRep-25-1970-261.pdf |access-date=2017-10-17 |dead-url=yes |quote=[…] The author is indebted to Dr [[Marc Davio|M. Davio]] for his continuing interest and comments on this work. Thanks are also due to Mr [[Claude Fosséprez|C. Fosséprez]] who initially suggested the basic problem considered here. […] |archive-url=https://web.archive.org/web/20170308203506/http://www.extra.research.philips.com/hera/people/aarts/_Philips%20Bound%20Archive/PRRep/PRRep-25-1970-261.pdf |archive-date=8 March 2017 }} (76 pages)</ref>\n<ref name=\"Thayse_1971\">{{cite journal |author-first=André |author-last=Thayse |title=Boolean Differential Calculus |journal=[[Philips Research Reports]] |publisher=[[Philips Research Laboratory]], {{lang|fr|Manufacture Belge de Lampes et de Materiel Electronique}} (MBLE Research Laboratory) |location=Brussels, Belgium |volume=26 |number=2 |date=February 1971 |pages=229–246 |id=R764 |url=http://www.extra.research.philips.com/hera/people/aarts/_Philips%20Bound%20Archive/PRRep/PRRep-26-1971-229.pdf |access-date=2017-10-16 |dead-url=yes |quote=[…] Abstract: After a brief outline of classical concepts relative to Boolean differential calculus, a theoretical study of various differential operators is undertaken. Application of these concepts to several important problems arising in switching practice is mentioned. […] Acknowledgement: The author is especially grateful to Dr [[Marc Davio|M. Davio]] for his encouragement and support and for several ideas in the presentation. […] |archive-url=https://web.archive.org/web/20170308203806/http://www.extra.research.philips.com/hera/people/aarts/_Philips%20Bound%20Archive/PRRep/PRRep-26-1971-229.pdf |archive-date=8 March 2017 }} (18 pages)</ref>\n<ref name=\"Thayse_Davio_1973\">{{cite journal |author-first1=André |author-last1=Thayse |author-first2=Marc |author-last2=Davio |title=Boolean Differential Calculus and its Application to Switching Theory |journal=[[IEEE Transactions on Computers]] |publisher=[[IEEE Computer Society]] |publication-place=Washington, DC, USA |location=[[Philips Research Laboratory]], {{lang|fr|Manufacture Belge de Lampes et de Materiel Electronique}} (MBLE Research Laboratory), Brussels, Belgium |volume=C-22 |issue=4 |date=1973-04-01 |pages=409–420 |issn=0018-9340 |doi=10.1109/T-C.1973.223729 |url=https://dl.acm.org/citation.cfm?id=1310445 |access-date=2017-10-15}} (12 pages)</ref>\n<ref name=\"Davio_Deschamps_Thayse_1978\">{{cite book |author-first1=Marc |author-last1=Davio |author-first2=Jean-Pierre |author-last2=Deschamps |author-first3=André |author-last3=Thayse |title=Discrete and Switching Functions |publisher=Georgi Publishing Company / [[McGraw-Hill International Book Company]] |publication-place=New York, USA |location=St. Saphorin, Switzerland |edition=1st |date=1978-08-01 |isbn=0-07-015509-7 |lccn=77-030718}} (xx+729 pages)</ref>\n<ref name=\"Thayse_1981\">{{cite book |author-first=André |author-last=Thayse |editor-first1=Gerhard |editor-last1=Goos |editor-link1=:de:Gerhard Goos |editor-first2=Juris |editor-last2=Hartmanis |editor-link2=Juris Hartmanis |title=Boolean Calculus of Differences |work=Lecture Notes in Computer Science |volume=101 |publisher=[[Springer-Verlag]] |publication-place=Berlin, Germany |location=[[Philips Research Laboratory]], Brussels, Belgium |edition=1st |date=1981 |isbn=3-540-10286-8}} (144 pages)</ref>\n<ref name=\"Bochmann_Posthoff_1981\">{{cite book |author-first1=Dieter |author-last1=Bochmann |author-link1=:de:Dieter Bochmann |author-first2=Christian |author-last2=Posthoff |title=Binäre dynamische Systeme |language=German |trans-title=Binary dynamic systems |publisher=[[Akademie-Verlag]], Berlin / {{ill|R. Oldenbourg Verlag|de}}, München |edition=1st |date=1981 |isbn=3-486-25071-X |id={{DNB-IDN|810757168|810200317|}}. License number: 202.100/408/81. Order code: 7623619&nbsp;(6391).}} (397 pages) (NB. Per {{DNB-IDN|368893146}} a Russian translation of this work was released in 1986.)</ref>\n<ref name=\"Bochmann_Steinbach_1991\">{{cite book |author-first1=Dieter |author-last1=Bochmann |author-link1=:de:Dieter Bochmann |author-first2=Bernd |author-last2=Steinbach |author-link2=:de:Bernd Steinbach |title=Logikentwurf mit XBOOLE – Algorithmen und Programme |language=German |trans-title=Logic design with XBOOLE – Algorithms and programs |publisher={{ill|Verlag Technik|de}} |location=Berlin, Germany |edition=1st |date=1991 |isbn=3-341-01006-8 |id={{DNB-IDN|911196102}}}} (303 pages + 5.25-inch floppy disk)</ref>\n<ref name=\"Scheuring_Wehlan_1991_DEDS\">{{cite journal |title=On the Design of Discrete Event Dynamic Systems by Means of the Boolean Differential Calculus |author-first1=Rainer |author-last1=Scheuring |author-first2=Herbert \"Hans\"<!-- This source identifies the author as Hans Wehlan --> |author-last2=Wehlan |date=1991-09-01 |work=First IFAC Symposium on Design Methods of Control Systems |publisher=[[International Federation of Automatic Control]] (IFAC) / [[Pergamon Press]] |location=Zürich, Switzerland |editor-first1=Dieter |editor-last1=Franke |editor-first2=Franta |editor-last2=Kraus |volume=2 |doi=10.1016/S1474-6670(17)54214-7 |pages=723–728}} (6 pages)</ref>\n<ref name=\"Scheuring_Wehlan_1991_Petri\">{{cite journal |title=Der Boolesche Differentialkalkül – eine Methode zur Analyse und Synthese von Petri-Netzen |language=German |trans-title=The Boolean differential calculus – A method for analysis and synthesis of Petri nets |author-first1=Rainer |author-last1=Scheuring |author-first2=Herbert \"Hans\"<!-- This source identifies the author as Herbert Wehlan --> |author-last2=Wehlan |editor-first=Georg |editor-last=Bretthauer |orig-year=July 1991 |date=1991-12-01 |journal=at – Automatisierungstechnik – Methoden und Anwendungen der Steuerungs-, Regelungs- und Informationstechnik |publisher={{ill|R. Oldenbourg Verlag|de}} |issn=0178-2312 |location=Stuttgart, Germany |volume=39 |number=7 |pages=226–233 |doi=10.1524/auto.1991.39.112.226 |url=https://www.degruyter.com/view/j/auto.1991.39.issue-1-12/auto.1991.39.112.226/auto.1991.39.112.226.xml |access-date=2017-10-16 |dead-url=no |archive-url=https://web.archive.org/web/20171016190403/https://www.degruyter.com/view/j/auto.1991.39.issue-1-12/auto.1991.39.112.226/auto.1991.39.112.226.png |archive-date=2017-10-16}} (8 pages)</ref>\n<ref name=\"Yanushkevich_1998\">{{cite book |author-first=Svitlana N. [Svetlana N.] |author-last=Ânuškevič [Yanushkevich] |title=Logic Differential Calculus in Multi-Valued Logic Design |type=PhD thesis |publisher=Instytut Informatyki, Technical University of Szczecin |journal=Journal Prace Naukowe Politechniki Szczecińskiej |location=Szczecin, Poland |edition=1st |date=1998 |issue=537/1 |issn=1506-3054 |isbn=978-8-387423-16-2 |id={{ISBN|8-387423-16-5}}}} (326<!-- 322? --> pages)</ref>\n<ref name=\"Bochmann_2006_2008\">{{cite book |author-first=Dieter |author-last=Bochmann |author-link=:de:Dieter Bochmann |title=Binary Systems - A BOOLEAN Book |publisher=TUDpress Verlag der Wissenschaften |location=Dresden, Germany |edition=1st |date=2008-09-01 |isbn=978-3-940046-87-1 |id={{DNB-IDN|989771636}}}} (421 pages) Translation of: {{cite book |author-first=Dieter |author-last=Bochmann |author-link=:de:Dieter Bochmann |title=Binäre Systeme - Ein BOOLEAN Buch |language=German |trans-title=Binary systems - A Boolean book |publisher=LiLoLe-Verlag GmbH (Life-Long-Learning) / BoD GmbH |location=Hagen, Germany |edition=1st |date=February 2006 |isbn=3-934447-10-4 |id={{ISBN|978-3-934447-10-3}}. {{DNB-IDN|978899873}}}} (452 pages)</ref>\n<ref name=\"Steinbach_Posthoff_2013_1\">{{cite journal |author-first1=Bernd |author-last1=Steinbach |author-link1=:de:Bernd Steinbach |author-first2=Christian |author-last2=Posthoff |title=Derivative Operations for Lattices of Boolean Functions |journal=Proceedings Reed-Muller Workshop 2013 |location=Toyama, Japan |date=2013 |pages=110–119 |url=http://www.informatik.tu-freiberg.de/prof2/publikationen/RM_2013_dolbf.pdf |access-date=2017-10-21 |dead-url=no |archive-url= https://web.archive.org/web/20171021224454/http://www.informatik.tu-freiberg.de/prof2/publikationen/RM_2013_dolbf.pdf |archive-date=2017-10-21}} (10 pages)</ref>\n<ref name=\"Steinbach_Posthoff_2013_2\">{{cite journal |author-first1=Bernd |author-last1=Steinbach |author-link1=:de:Bernd Steinbach |author-first2=Christian |author-last2=Posthoff |editor-first=Mitchell A. |editor-last=Thornton |title=Boolean Differential Equations |series=Synthesis Lectures on Digital Circuits and Systems |issn=1932-3166 |publisher=Morgan & Claypool Publishers |location=San Rafael, CA, USA |date=2013-07-01 |volume=8 |issue=3 <!-- |number=42 -->|id=Lecture #42 |edition=1st |isbn=978-1-62705-241-2 |doi=10.2200/S00511ED1V01Y201305DCS042 |url=http://www.morganclaypool.com/doi/abs/10.2200/S00511ED1V01Y201305DCS042 |access-date=2017-10-15 |dead-url=no}} (158 pages)</ref>\n<ref name=\"Steinbach_Posthoff_2017\">{{cite journal |author-first1=Bernd |author-last1=Steinbach |author-link1=:de:Bernd Steinbach |author-first2=Christian |author-last2=Posthoff |editor-first=Mitchell A. |editor-last=Thornton |title=Boolean Differential Calculus |series=Synthesis Lectures on Digital Circuits and Systems |issn=1932-3166 |publisher=Morgan & Claypool Publishers |location=San Rafael, CA, USA |date=2017-06-07 |volume=12 |issue=1 <!-- |number=52 -->|id=Lecture #52 |edition=1st |isbn=978-1-62705-922-0 |doi=10.2200/S00766ED1V01Y201704DCS052 |url=http://www.morganclaypool.com/doi/abs/10.2200/S00766ED1V01Y201704DCS052 |access-date=2017-10-15 |dead-url=no}} (216 pages)</ref>\n}}\n\n== Further reading ==\n* {{cite journal |author-first1=Marc |author-last1=Davio |author-first2=Philippe M. |author-last2=Piret |title=Les dérivées Booléennes et leur application au diagnostic |language=French |trans-title=Boolean derivatives and their application and diagnosis |journal=[[Philips Revue]] |publisher=[[Philips Research Laboratory]], {{lang|fr|Manufacture Belge de Lampes et de Materiel Electronique}} (MBLE Research Laboratory) |location=Brussels, Belgium |volume=12 |issue=3  |pages=63-76 |date=July 1969}} (14 pages)\n* {{cite book |author-first=Sergiu |author-last=Rudeanu |title=Boolean Functions and Equations |date=September 1974 |publisher=[[North-Holland Publishing Company]]/[[American Elsevier Publishing Company]] |isbn=0-44410520-4 |id={{isbn|0-72042082-2}}}} (462 pages)\n* {{cite journal |author-first=Dieter |author-last=Bochmann |author-link=:de:Dieter Bochmann |title=Boolean differential calculus (a survey) |journal=Engineering Cybernetics |publisher=[[Institute of Electrical and Electronics Engineers]] (IEEE) |volume=15 |number=5 |date=1977 |issn=0013-788X |pages=67–75}} (9 pages) Translation of: {{cite journal |author-first=Dieter |author-last=Bochmann |author-link=:de:Dieter Bochmann  |language=Russian |title=[Boolean differential calculus (survey)] |journal=Известия Академии наук СССР – Техническая кибернетика (Izvestii︠a︡ Akademii Nauk SSSR – Tekhnicheskai︠a︡ kibernetika) [Proceedings of the Academy of Sciences of the USSR – Engineering Cybernetics] |number=5 |date=1977 |pages=125–133}} (9 pages)\n* {{cite journal |author-first=Martin |author-last=Kühnrich |title=Differentialoperatoren über Booleschen Algebren |language=German |trans-title=Differential operators on Boolean algebras |journal=Zeitschrift für mathematische Logik und Grundlagen der Mathematik |date=1986 |orig-year=1984-07-31 (submission) |location=Berlin, Germany (East) |doi=10.1002/malq.19860321703 |volume=32 |issue=17-18 |id=#18 |pages=271–288 |url=http://onlinelibrary.wiley.com/doi/10.1002/malq.19860321703/full}} (18 pages)\n* {{cite book |author-first=Frank |author-last=Dresig |title=Gruppierung – Theorie und Anwendung in der Logiksynthese |language=German |trans-title=Grouping – Theory and application in logic synthesis |work=Fortschritt-Berichte VDI |series=9 |volume=145 |publisher={{ill|VDI-Verlag|de}} |location=Düsseldorf, Germany |date=1992 |isbn=3-18-144509-6 |id={{DNB-IDN|940164671}}}} (NB. Also: Chemnitz, Technische Universität, Dissertation.) (147 pages)\n* {{cite book |chapter=Control of Discrete Event Systems by Means of the Boolean Differential Calculus |author-first1=Rainer |author-last1=Scheuring |author-first2=Herbert \"Hans\"<!-- This source identifies the author variously as Hans or Herbert Wehlan --> |author-last2=Wehlan |date=1993 |editor-first1=Silvano |editor-last1=Balemi |editor-first2=Petr |editor-last2=Kozák |editor-first3=Rein |editor-last3=Smedinga |title=Discrete Event Systems: Modeling and Control |series=Progress in Systems and Control Theory (PSCT) |volume=13 |publisher=[[Birkhäuser Verlag]] |publication-place=Basel, Switzerland |location=Institut für Systemdynamik und Regelungstechnik (ISR), [[Universität Stuttgart]], Stuttgart, Germany |pages=79-93 |url=https://link.springer.com/chapter/10.1007%2F978-3-0348-9120-2_7 |access-date=2017-10-16 |dead-url=no}} (15 pages)\n* {{cite book |author-first1=Christian |author-last1=Posthoff |author-first2=Bernd |author-last2=Steinbach |author-link2=:de:Bernd Steinbach |title=Logic Functions and Equations – Binary Models for Computer Science |publisher=[[Springer Science + Business Media B.&nbsp;V.]] |publication-place=Dordrecht, Netherlands |location=Freiberg, Germany |date=2004-02-04 |edition=1st |isbn=1-4020-2937-3 |oclc=254106952 |doi=10.1007/978-1-4020-2938-7 |id={{ISBN|978-1-4020-2937-0}} |url=https://archive.org/details/springer_10.1007-978-1-4020-2938-7 |access-date=2017-10-19 |dead-url=no}} (392 pages)\n* {{cite book |author-first1=Bernd |author-last1=Steinbach |author-link1=:de:Bernd Steinbach |author-first2=Christian |author-last2=Posthoff |title=Logic Functions and Equations – Examples and Exercises |publisher=[[Springer Science + Business Media B.&nbsp;V.]] |publication-place=Dordrecht, Netherlands |location=Freiberg, Germany |date=2009-02-12 |edition=1st |isbn=978-1-4020-9594-8 |lccn=2008941076 |doi=10.1007/978-1-4020-9595-5}} (xxii+232 pages) [http://www.e-reading.club/bookreader.php/135805/Posthoff%2C_Steinbach_-_Logic_Functions_and_Equations_-_Examples_and_Exercises.pdf] (NB. Per {{DNB-IDN|1010457748}} this hardcover edition has been rereleased as softcover edition in 2010.)\n* {{cite journal |author-first1=Bernd |author-last1=Steinbach |author-link1=:de:Bernd Steinbach |author-first2=Christian |author-last2=Posthoff |title=Boolean Differential Calculus – Theory and Applications |journal=Journal of Computational and Theoretical Nanoscience |publisher=American Scientific Publishers |volume=7 |issue=6 |date=2010-06-01 |pages=933-981 |issn=1546-1955 |doi=10.1166/jctn.2010.1441 |url=http://www.ingentaconnect.com/content/asp/jctn/2010/00000007/00000006/art00001}} (49 pages)\n* {{cite book |author-first1=Bernd |author-last1=Steinbach |author-link1=:de:Bernd Steinbach |author-first2=Christian |author-last2=Posthoff |title=Chapter 3: Boolean Differential Calculus}} In {{cite journal |author-first1=Tsutomu |author-last1=Sasao |author-first2=Jon T. |author-last2=Butler |editor-first=Mitchell A. |editor-last=Thornton |title=Progress in Applications of Boolean Functions |series=Synthesis Lectures on Digital Circuits and Systems |issn=1932-3166 |location=San Rafael, CA, USA |publisher=Morgan & Claypool Publishers |orig-year=2009 |date=2010-01-15 |volume=4 |issue=1 <!-- |number=26 -->|id=Lecture #26 |edition=1st |isbn=978-1-60845-181-4 |pages=55–78, 121–126 |doi=10.2200/S00243ED1V01Y200912DCS026 |url=http://www.morganclaypool.com/doi/abs/10.2200/S00243ED1V01Y200912DCS026 |access-date=2017-10-15 |dead-url=no}} (24 of 153 pages)\n\n=={{anchor|XBOOLE}}External links==\n* {{cite book |title=Boolean differential calculus |author-first=Herbert \"Hans\" |author-last=Wehlan |work=[[Encyclopedia of Mathematics]] |isbn=978-1-4020-0609-8 |editor-first=Michiel |editor-last=Hazewinkel |editor-link=Michiel Hazewinkel\n|publisher=[[Springer Science+Business Media]] |date=2010-12-06 |url=http://www.encyclopediaofmath.org/index.php?title=Boolean_differential_calculus&oldid=12153 |access-date=2017-10-16 |dead-url=no |archive-url=https://web.archive.org/web/20171016111554/https://www.encyclopediaofmath.org/index.php/Boolean_differential_calculus |archive-date=2017-10-16}}\n* {{cite web |title=XBOOLE |author=Institut für Informatik (IfI) |publisher=TU Bergakademie Freiberg |date=2017 |url=http://www.informatik.tu-freiberg.de/xboole/index.php?language=English&aktwindow=home |access-date=2017-10-31 |dead-url=no |archive-url=https://web.archive.org/web/20171031105416/http://www.informatik.tu-freiberg.de/xboole/index.php?language=English&aktwindow=home |archive-date=2017-10-31}} with {{cite web |title=XBOOLE Monitor |date=2008-07-23 |url=http://www.informatik.tu-freiberg.de/xboole/XBOOLEMonitor.zip?Submit=XBOOLE+Monitor |access-date=2017-10-31 |dead-url=yes |archive-url=https://web.archive.org/web/20171031002108/http://www.informatik.tu-freiberg.de/xboole/XBOOLEMonitor.zip?Submit=XBOOLE+Monitor |archive-date=31 October 2017 }}\n\n[[Category:Algebra]]\n[[Category:Automata (computation)]]\n[[Category:Mathematical logic]]\n[[Category:Order theory]]\n[[Category:Set theory]]"
    },
    {
      "title": "Bose–Mesner algebra",
      "url": "https://en.wikipedia.org/wiki/Bose%E2%80%93Mesner_algebra",
      "text": "In [[mathematics]], a '''Bose–Mesner algebra''' is a special set of [[Matrix (mathematics)|matrices]] which arise from a combinatorial structure known as an [[association scheme]], together with the usual set of rules for combining (forming the products of) those matrices, such that they form an [[associative algebra]], or, more precisely, a [[Unital algebra|unitary commutative algebra]]. Among these rules are:\n:*the result of a product is also within the set of matrices,\n:*there is an identity matrix in the set, and\n:*taking products is [[Commutativity|commutative]].\n\nBose–Mesner algebras have applications in [[physics]] to [[spin model]]s, and in [[statistics]] to the [[design of experiments]]. They are named for [[R. C. Bose]] and Dale Marsh Mesner.<ref>Bose & Mesner (1959)</ref>\n\n==Definition==\nLet ''X'' be a set of ''v'' elements. Consider a partition of the 2-element subsets of ''X'' into ''n'' non-empty subsets, ''R''<sub>1</sub>, ..., ''R''<sub>''n''</sub> such that:\n* given an <math>x \\in X</math>, the number of <math>y \\in X</math> such that <math>\\{x,y\\} \\in R_i</math> depends only on i (and not on ''x''). This number will be denoted by v<sub>i</sub>, and\n* given <math>x,y \\in X</math> with <math>\\{x,y\\} \\in R_k</math>, the number of <math>z \\in X</math> such that <math>\\{x,z\\} \\in R_i</math> and <math>\\{z,y\\} \\in R_j</math> depends only on ''i'',''j'' and ''k'' (and not on ''x'' and ''y''). This number will be denoted by <math>p^k_{ij}</math>.\nThis structure is enhanced by adding all pairs of repeated elements of ''X'' and collecting them in a subset ''R''<sub>0</sub>. This enhancement permits the parameters ''i'', ''j'', and ''k'' to take on the value of zero, and lets some of ''x'',''y'' or ''z'' be equal.\n\nA set with such an enhanced partition is called an [[association scheme]].<ref>{{harvnb|Cameron|van Lint|1991|loc=pp.197–198}}</ref> One may view an association scheme as a partition of the edges of a [[complete graph]] (with vertex set ''X'') into n classes, often thought of as color classes. In this representation, there is a loop at each vertex and all the loops receive the same 0th color.\n\nThe association scheme can also be represented algebraically. Consider the [[Matrix (mathematics)|matrices]] ''D''<sub>''i''</sub> defined by:\n: <math>(D_i)_{x,y} = \\begin{cases} \n1,& \\text{if } \\left(x,y\\right)\\in R_{i},\\\\ \n0,& \\text{otherwise.}  \\end{cases} \\qquad (1)</math>\n\nLet <math>\\mathcal{A}</math> be the [[vector space]] consisting of all [[Matrix (mathematics)|matrices]] <math>\\sideset{}{_{i=0}^{n}}\\sum a_{i}D_{i}</math>, with <math>a_{i}</math> complex.<ref>{{harvnb|Camion|1998}}</ref><ref>{{harvnb|Delsarte|Levenshtein|1998}}</ref>\n\nThe definition of an [[association scheme]] is equivalent to saying that the <math>D_{i}</math> are ''v''&nbsp;&times;&nbsp;''v'' (0,1)-[[Matrix (mathematics)|matrices]] which satisfy\n\n# <math>D_i</math> is symmetric,\n# <math>\\sum_{i=0}^n D_{i}=J </math> (the all-ones matrix),\n# <math>D_0=I,</math>\n# <math>D_i D_j = \\sum_{k=0}^n p^k_{ij} D_k = D_j D_i,\\qquad i,j=0,\\ldots,n.</math>\n\nThe (''x'',''y'')-th entry of the left side of 4. is the number of two colored paths of length two joining ''x'' and ''y'' (using \"colors\" ''i'' and ''j'') in the graph. Note that the rows and columns of <math>D_i</math> contain <math>v_i</math> 1s:\n\n: <math>D_i J=J D_i = v_i J. \\qquad (2)</math>\n\nFrom 1., these [[Matrix (mathematics)|matrices]] are [[Symmetric matrix|symmetric]]. From 2., <math>D_{0},\\ldots,D_{n}</math> are [[Linear independence|linearly independent]], and the dimension of <math>\\mathcal{A}</math> is <math>n+1</math>. From 4., <math>\\mathcal{A}</math> is closed under multiplication, and multiplication is always associative. This [[Associative algebra|associative]] [[commutative algebra]] <math>\\mathcal{A}</math> is called the '''Bose–Mesner algebra''' of the [[association scheme]]. Since the [[Matrix (mathematics)|matrices]] in <math>\\mathcal{A}</math> are symmetric and commute with each other, they can be simultaneously diagonalized. This means that there is a [[Matrix (mathematics)|matrix]] <math>S</math> such that to each <math>A\\in\\mathcal{A}</math> there is a [[diagonal matrix]] <math>\\Lambda_{A}</math> with <math>S^{-1}A S=\\Lambda_{A}</math>. This means that <math>\\mathcal{A}</math> is semi-simple and has a unique basis of primitive idempotents <math>J_{0},\\ldots,J_{n}</math>. These are complex n &times; n [[Matrix (mathematics)|matrices]] satisfying\n\n: <math>\nJ_i^2 =J_i, i=0,\\ldots,n, \\qquad (3)\n</math>\n\n: <math>\nJ_i J_k=0, i\\neq k, \\qquad (4)\n</math>\n\n: <math>\n\\sum_{i=0}^n J_i = I. \\qquad (5)\n</math>\n\nThe '''Bose–Mesner algebra''' has two distinguished bases: the basis consisting of the [[Adjacency matrix|adjacency matrices]] <math>D_i</math>, and the basis consisting of the irreducible [[Idempotent matrix|idempotent matrices]] <math>E_k</math>. By definition, there exist well-defined [[complex number]]s such that\n\n: <math>\nD_{i}=\\sum_{k=0}^n p_i (k) E_k, \\qquad (6)\n</math>\n\nand\n\n: <math>\n|X|E_{k}=\\sum_{i=0}^n q_k\\left(i\\right)D_i. \\qquad (7)\n</math>\n\nThe p-numbers <math>p_i (k)</math>, and the q-numbers <math>q_k(i)</math>, play a prominent role in the theory.<ref>{{harvnb|Camion|1998}}</ref> They satisfy well-defined orthogonality relations. The p-numbers are the [[eigenvalues]] of the [[adjacency matrix]] <math>D_i</math>.\n\n==Theorem==\n\nThe [[eigenvalues]] of <math>p_i(k)</math> and <math>q_k(i)</math>, satisfy the orthogonality conditions:\n\n: <math>\n\\sum_{k=0}^n \\mu_i p_i (k)p_\\ell (k)=v v_i \\delta_{i \\ell}, \\quad(8)\n</math>\n\n: <math>\n\\sum_{k=0}^n \\mu_i q_k (i) q_\\ell (i)=v \\mu_k \\delta_{k \\ell}. \\quad(9)\n</math>\n\nAlso\n\n: <math>\n\\mu_j p_i (j) = v_i q_ j (i),\\quad i,j=0,\\ldots,n. \\quad(10)\n</math>\n\nIn [[Matrix (mathematics)|matrix]] notation, these are\n\n: <math>\nP^T \\Delta_\\mu P=v\\Delta_v, \\quad(11)\n</math>\n\n: <math>\nQ^T \\Delta_v Q=v\\Delta_\\mu, \\quad(12)\n</math>\n\nwhere <math>\\Delta_v = \\operatorname{diag} \\{v_0,v_1,\\ldots,v_n\\},\\qquad \\Delta_\\mu = \\operatorname{diag} \\{\\mu_0,\\mu_1,\\ldots,\\mu_n\\}.</math>\n\n==Proof of theorem==\n\nThe [[eigenvalue]]s of <math>D_i D_\\ell</math> are <math>p_i (k)p_\\ell (k)</math> with multiplicities <math>\\mu_k</math>. This implies that\n\n: <math>\nv v_i \\delta_{i\\ell} = \\operatorname{trace}D_i D_\\ell = \\sum_{k=0}^n \\mu_i p_i(k) p_\\ell (k), \\quad(13)\n</math>\n\nwhich proves Equation <math>\\left(8\\right)</math> and Equation <math>\\left(11\\right)</math>,\n\n: <math>\nQ = v P^{-1} = \\Delta_v^{-1} P^T \\Delta_\\mu, \\quad(14)\n</math>\n\nwhich gives Equations <math>(9)</math>, <math>(10)</math> and <math>(12)</math>.<math>\\Box</math>\n\nThere is an analogy between extensions of [[association scheme]]s and [[Kronecker's theorem|extensions]] of [[finite field]]s. The cases we are most interested in are those where the extended schemes are defined on the <math>n</math>-th [[Cartesian power]] <math>X=\\mathcal{F}^{n}</math> of a set <math>\\mathcal{F}</math> on which a basic [[association scheme]] <math>\\left(\\mathcal{F},K\\right)</math> is defined. A first [[association scheme]] defined on <math>X=\\mathcal{F}^{n}</math> is called the <math>n</math>-th [[Kronecker product|Kronecker power]] <math>\\left(\\mathcal{F},K\\right)_{\\otimes}^{n}</math> of <math>\\left(\\mathcal{F},K\\right)</math>. Next the extension is defined on the same set <math>X=\\mathcal{F}^{n}</math> by gathering classes of <math>\\left(\\mathcal{F},K\\right)_{\\otimes}^{n}</math>. The [[Kronecker product|Kronecker power]] corresponds to the [[polynomial ring]] <math>F\\left[X\\right]</math> first defined on a [[Finite field|field]] <math>\\mathbb{F}</math>, while the extension scheme corresponds to the [[extension field]] obtained as a quotient. An example of such an extended scheme is the [[Hamming scheme]].\n\n[[Association scheme]]s may be merged, but merging them leads to non-symmetric [[association scheme]]s, whereas all usual [[code]]s are [[subgroup]]s in symmetric [[Abelian variety|Abelian schemes]].<ref>{{harvnb|Delsarte|Levenshtein|1998}}</ref><ref>{{harvnb|Camion|1998}}</ref><ref>{{harvnb|MacWilliams|Sloane|1978}}</ref>\n\n==See also==\n* [[Association scheme]]\n\n{{More footnotes|date=September 2010}}\n\n==Notes==\n\n{{Reflist}}\n\n==References==\n* {{citation|first=Rosemary&nbsp;A.|last=Bailey|authorlink=Rosemary A. Bailey|url=http://www.maths.qmul.ac.uk/~rab/Asbook |title=Association schemes: Designed experiments, algebra and combinatorics|series=Cambridge Studies in Advanced Mathematics|volume=84|publisher=Cambridge University Press|year=2004|pages=387|isbn=978-0-521-82446-0| mr=2047311|ref=harv}}\n* {{citation | last1=Bannai | first1=Eiichi | last2=Ito | first2=Tatsuro | title=Algebraic combinatorics I: Association schemes |  publisher=The Benjamin/Cummings Publishing Co., Inc. | location=Menlo Park, CA | year=1984 | pages=xxiv+425 | isbn=0-8053-0490-8 | mr=0882540}}\n* {{citation | last1=Bannai | first1=Etsuko |year=2001 |title=Bose–Mesner algebras associated with four-weight spin models|journal=[[Graphs and Combinatorics]]|volume=17|issue=4|pages=589–598|doi=10.1007/PL00007251}}\n* {{citation| last1=Bose|first1=R.&nbsp;C.| authorlink1=R. C. Bose| last2=Mesner|first2=D.&nbsp;M.|year=1959|title=On linear associative algebras corresponding to association schemes of partially balanced designs|journal=[[Annals of Mathematical Statistics]]|volume=30|issue=1|pages=21&ndash;38| url=http://projecteuclid.org/euclid.aoms/1177706356 | doi=10.1214/aoms/1177706356 | mr = 102157 | jstor = 2237117}}\n* {{citation|last=Cameron|first=P.&nbsp;J.|last2=van Lint|first2=J.&nbsp;H.|title=Designs, Graphs, Codes and their Links|year=1991|publisher=Cambridge University Press|location=Cambridge|isbn=0-521-42385-6}}\n* {{citation|last1= Camion|first1=P.|authorlink1=Paul Camion|chapter=Codes and association schemes: Basic properties of association schemes relevant to coding| title=Handbook of coding theory|editor1-last= Pless|editor1-first=V.&nbsp;S.|editor1-link=Vera Pless|editor2-last=Huffman|editor2-first=W.&nbsp;C.|publisher=Elsevier|place= The Netherlands|year= 1998}}\n* {{citation|last1=Delsarte|first1=P.|last2=Levenshtein|first2=V.&nbsp;I.|authorlink2=Vladimir Levenshtein|title=Association schemes and coding theory|journal=IEEE Transactions on Information Theory| volume= 44| issue= 6|pages= 2477&ndash;2504|year= 1998|doi=10.1109/18.720545}}\n* {{citation| first1=F. J.|last1= MacWilliams|first2=N.&nbsp;J.&nbsp;A.|last2= Sloane|authorlink2=Neil J. A. Sloane|title=The theory of error-correcting codes|publisher= Elsevier|place= New York|year= 1978}}\n* {{citation|last=Nomura|first= K.|year=1997|title=An algebra associated with a spin model|journal=Journal of Algebraic Combinatorics|volume=6|issue=1|pages= 53–58|doi=10.1023/A:1008644201287}}\n\n{{Experimental design|state=expanded}}\n\n{{DEFAULTSORT:Bose-Mesner Algebra}}\n[[Category:Algebraic combinatorics]]\n[[Category:Design of experiments]]\n[[Category:Analysis of variance]]\n[[Category:Representation theory]]\n[[Category:Algebra]]"
    },
    {
      "title": "Boundedly generated group",
      "url": "https://en.wikipedia.org/wiki/Boundedly_generated_group",
      "text": "In [[mathematics]], a  [[group (mathematics)|group]] is called '''boundedly generated'''  if it can be expressed as a finite product of [[cyclic group|cyclic]] [[subgroup]]s. The property of bounded generation is also closely related with the [[congruence subgroup#Congruence subgroups and topological groups|congruence subgroup problem]] (see {{harvnb|Lubotzky|Segal|2003}}).\n\n== Definitions ==\n\nA group ''G'' is called ''boundedly generated'' if there exists a finite subset ''S'' of ''G'' and a positive integer ''m'' such that every element ''g'' of ''G'' can be represented as a product of at most ''m'' powers of the elements of ''S'':\n \n: <math>g = s_1^{k_1} \\cdots s_m^{k_m},</math> where <math>s_i \\in S</math> and <math>k_i</math> are integers.\n\nThe finite set ''S'' generates ''G'', so  a boundedly generated group is [[finitely generated group|finitely generated]].\n\nAn equivalent definition can be given in terms of cyclic subgroups. A group ''G'' is called ''boundedly generated'' if there is a finite family ''C''<sub>1</sub>, …, ''C''<sub>''M''</sub> of not necessarily distinct [[cyclic group|cyclic]] subgroups such that ''G'' = ''C''<sub>1</sub>…''C''<sub>''M''</sub> as a set.\n\n== Properties ==\n\n* Bounded generation is unaffected by passing to a subgroup of [[index of a subgroup|finite index]]: if ''H'' is a finite index subgroup of ''G'' then ''G'' is boundedly generated if and only if ''H'' is boundedly generated.\n* Any [[quotient group]] of a boundedly generated group is also boundedly generated.\n* A [[Finitely generated group|finitely generated]] [[torsion group]] must be ''finite'' if it is boundedly generated; equivalently, an ''infinite'' finitely generated torsion group is not boundedly generated.\n\nA ''pseudocharacter'' on a discrete group ''G'' is defined to be a real-valued function ''f'' on a ''G'' such that \n: ''f''(''gh'') &minus; ''f''(''g'') &minus; ''f''(''h'') is uniformly bounded and ''f''(''g''<sup>''n''</sup>) = ''n''·''f''(''g'').\n\n* The vector space of pseudocharacters of a boundedly generated group ''G'' is finite-dimensional.\n\n== Examples ==\n* If ''n'' ≥ 3, the group ''SL''<sub>''n''</sub>('''Z''') is boundedly generated by its ''elementary subgroups,'' formed by matrices differing from the identity matrix only in one off-diagonal entry. In 1984, Carter and Keller gave an elementary proof of this result, motivated by a question in [[algebraic K-theory]].\n* A [[free group]] on at least two generators is not boundedly generated (see below).\n* The group ''SL''<sub>''2''</sub>('''Z''') is not boundedly generated, since it contains a free subgroup with two generators of index 12.\n* A [[Gromov-hyperbolic group]] is boundedly generated if and only if it is ''virtually cyclic'' (or ''elementary''), i.e. contains a cyclic subgroup of finite index.\n\n== Free groups are not boundedly generated ==\nSeveral authors have stated in the mathematical literature that it is obvious that finitely generated free groups are not boundedly generated. This section contains various obvious and less obvious ways of proving this. Some of the methods, which touch on bounded cohomology, are important because they are geometric rather than algebraic, so can be applied to a wider class of groups, for example Gromov-hyperbolic groups.\n\nSince for any ''n'' ≥ 2, the [[free group]] on 2 generators ''F''<sub>2</sub>  contains the free group on ''n'' generators ''F''<sub>''n''</sub> as a subgroup of finite index (in fact ''n'' – 1), once one non-cyclic free group on finitely many generators is known to be not boundedly generated, this will be true for all of them. Similarly, since ''SL''<sub>2</sub>('''Z''') contains  ''F''<sub>2</sub>  as a subgroup of index 12, it is enough to consider ''SL''<sub>2</sub>('''Z'''). In other words, to show that no ''F''<sub>''n''</sub> with ''n'' ≥ 2 has bounded generation, it is sufficient to prove this for one of them or even just for ''SL''<sub>2</sub>('''Z''') .\n\n===Burnside couterexamples===\nSince bounded generation is preserved under taking homomorphic images, if a single finitely generated group with at least two generators is known to be not boundedly generated, this will be true for the free group on the same number of generators, and hence for all free groups. To show that no (non-cyclic) free group has bounded generation, it is therefore enough to produce one example of a finitely generated group which is not boundedly generated, and any finitely generated infinite [[torsion group]] will work. The existence of such groups constitutes [[Golod–Shafarevich theorem|Golod and Shafarevich]]'s negative solution of the [[Burnside problem|generalized Burnside problem]] in 1964; later, other explicit examples of infinite finitely generated torsion groups were constructed by Aleshin, Olshanskii, and Grigorchuk, using [[automata theory|automata]]. Consequently, free groups of rank at least two are not boundedly generated.\n\n===Symmetric groups===\nThe [[symmetric group]] ''S''<sub>''n''</sub> can be generated by two elements, a 2-cycle and an ''n''-cycle, so that it is a quotient group of  ''F''<sub>2</sub>. On the other hand, it is easy to show that the maximal order ''M''(''n'') of an element in ''S''<sub>''n''</sub> satisfies\n\n: log ''M''(''n'') ≤ n/e\n\n([[Edmund Landau]] proved the more precise asymptotic estimate log ''M''(''n'') ~ (''n'' log ''n'')<sup>1/2</sup>).  In fact if the cycles in a [[cycle decomposition (group theory)|cycle decomposition]] of a [[permutation]] have length ''N''<sub>1</sub>, ..., ''N''<sub>''k''</sub> with ''N''<sub>1</sub> + ··· + ''N''<sub>''k''</sub> = ''n'', then the order of the permutation divides the product ''N''<sub>1</sub> ···''N''<sub>''k''</sub>, which in turn is bounded by (''n''/''k'')<sup>''k''</sup>, using the [[inequality of arithmetic and geometric means]]. On the other hand, (''n''/''x'')<sup>''x''</sup> is maximized when ''x''=''e''. If ''F''<sub>2</sub> could be written as a product of ''m'' cyclic subgroups, then necessarily ''n''! would have to be less than or equal to ''M''(''n'')<sup>''m''</sup> for all ''n'', contradicting [[Stirling's approximation|Stirling's asymptotic formula]].\n\n===Hyperbolic geometry===\nThere is also a simple geometric proof that ''G'' = ''SL''<sub>2</sub>('''Z''') is not boundedly generated. It acts by [[Möbius transformation]]s on the [[upper half-plane]] '''H''', with the [[Poincaré metric]]. Any [[compact support|compactly supported]] [[1-form]] α on a [[fundamental domain]] of ''G'' extends uniquely to a ''G''-invariant 1-form on '''H'''. If ''z'' is in '''H''' and γ is the [[geodesic]] from ''z'' to ''g''(''z''), the function defined by\n \n:<math>  F(g)\\equiv F_{\\alpha,z}(g)=\\int_{\\gamma}\\, \\alpha</math>\n\nsatisfies the first condition for a pseudocharacter since by the [[Stokes theorem]]\n \n:<math>  F(gh) - F(g)-F(h) = \\int_{\\Delta}\\, d\\alpha,</math>\n\nwhere Δ is the geodesic triangle with vertices ''z'', ''g''(''z'') and ''h''<sup>−1</sup>(''z''), and geodesics triangles have area bounded by π. The homogenized function\n\n:<math>f_\\alpha(g) = \\lim_{n\\rightarrow \\infty} F_{\\alpha,z}(g^n)/n</math>\n\ndefines a pseudocharacter, depending only on α. As is well known from the theory of [[dynamical system]]s, any orbit (''g''<sup>''k''</sup>(''z'')) of a [[Möbius transformation#Hyperbolic transforms|hyperbolic element]] ''g'' has limit set consisting of two fixed points on the extended real axis; it follows that the geodesic segment from ''z'' to ''g''(''z'') cuts through only finitely many translates of the fundamental domain. It is therefore easy to choose α so that ''f''<sub>α</sub> equals one on a given hyperbolic element and vanishes on a finite set of other hyperbolic elements with distinct fixed points. Since ''G'' therefore has an infinite-dimensional space of pseudocharacters, it cannot be boundedly generated.\n\nDynamical properties of hyperbolic elements can similarly be used to prove that any non-elementary Gromov-hyperbolic group is not boundedly generated.\n\n===Brooks pseudocharacters===\nRobert Brooks gave a combinatorial scheme to produce pseudocharacters of any free group ''F''<sub>''n''</sub>; this scheme was later shown to yield\nan infinite-dimensional family of pseudocharacters (see {{harvnb|Grigorchuk|1994}}). [[David B. A. Epstein|Epstein]] and Fujiwara later extended these results to all non-elementary Gromov-hyperbolic groups.\n\n===Gromov boundary===\nThis simple [[folklore]] proof uses dynamical properties of the action of hyperbolic elements on the [[Gromov boundary]] of a [[Gromov-hyperbolic group]]. For the special case of the free group ''F''<sub>''n''</sub>, the boundary (or space of ends) can be identified with the space ''X'' of [[semi-infinite]] [[word (group theory)#Reduced words|reduced words]]\n\n:''g''<sub>1</sub> ''g''<sub>2</sub> ···\n\nin the generators and their inverses. It gives a natural compactification of the [[tree (graph theory)|tree]], given by the [[Cayley graph]] with respect to the generators. A sequence of semi-infinite words converges to another such word provided that the initial segments agree after a certain stage, so that ''X'' is compact (and [[metrizable]]). The free group acts by left multiplication on the semi-infinite words. Moreover, any element ''g'' in ''F''<sub>''n''</sub> has exactly two fixed points ''g''<sup>±∞</sup>, namely the reduced infinite words given by the limits of ''g''<sup>''n''</sup> as ''n'' tends to ±∞. Furthermore, ''g''<sup>''n''</sup>·''w'' tends to ''g''<sup>±∞</sup> as ''n'' tends to ±∞ for any semi-infinite word ''w''; and more generally if ''w''<sub>''n''</sub> tends to ''w''≠ ''g''<sup> ±∞</sup>, then ''g''<sup>''n''</sup>·''w''<sub>''n''</sub> tends to ''g''<sup>+∞</sup> as ''n'' tends to ∞.\n\nIf ''F''<sub>''n''</sub> were boundedly generated, it could be written as a product of cyclic groups ''C''<sub>''i''</sub>\ngenerated by elements ''h''<sub>''i''</sub>. Let ''X''<sub>0</sub> be the countable subset given by the finitely many ''F''<sub>''n''</sub>-orbits\nof the fixed points ''h''<sub>''i''</sub><sup> ±∞</sup>, the fixed points of the ''h''<sub>''i''</sub> and all their conjugates. Since ''X'' is uncountable, there\nis an element of ''g'' with fixed points outside ''X''<sub>0</sub> and a point ''w'' outside ''X''<sub>0</sub> different from these fixed points. Then for\nsome subsequence (''g''<sub>m</sub>) of (''g''<sup>n</sup>)\n\n:''g''<sub>''m''</sub> = ''h''<sub>1</sub><sup>''n''(''m'',1)</sup> ··· ''h''<sub>''k''</sub><sup>''n''(''m'',''k'')</sup>, with each ''n''(''m'',''i'') constant or strictly monotone.\n\nOn the one hand, by successive use of the rules for computing limits of the form ''h''<sup>''n''</sup>·''w''<sub>''n''</sub>, the limit of the right hand side applied to ''x'' is necessarily a fixed point of one of the conjugates of the ''h''<sub>''i''</sub>'s. On the other hand, this limit also must be ''g''<sup>+∞</sup>, which is not one of these points, a contradiction.\n\n== References ==\n*{{cite journal\n|author1=Carter, David  |author2=Keller, Gordon |lastauthoramp=yes |title= Elementary expressions for unimodular matrices|journal=Communications in Algebra|volume=12|year=1984|pages=379–389|doi= 10.1080/00927878408823008\n|ref = harv\n|issue = 4}}\n\n*{{cite journal\n|author1=Epstein, David  |author2=Fujiwara, Koji |lastauthoramp=yes | title = The second bounded cohomology of word-hyperbolic groups| journal=Topology|volume=36|year=1997|pages=1275–1289| doi = 10.1016/S0040-9383(96)00046-8\n|ref= harv\n|issue= 6}}\n\n*{{cite journal |author1=Ghys, Etienne  |author2=Barge, Jean |lastauthoramp=yes | title= Surfaces et cohomologie bornée| journal=Inventiones Mathematicae| year=1988|volume=92|\npages=509–526| doi= 10.1007/BF01393745 | ref= harv | issue= 3|bibcode=1988InMat..92..509B}}\n\n*{{cite journal|\nauthor=Grigorchuk, R.I.|  title=On Burnside's problem on periodic groups|journal= Functional Anal. Appl.|volume= 14|year =1980|pages=41–43|\nref=harv}}\n\n*{{cite journal\n|author= Grigorchuk, R.I.|title=Some results in bounded cohomology |journal =London Mathematical Society Lecture Note Series|volume=224|year =1994|pages=111–163\n|ref= harv\n|isbn= 0-521-46595-8}}\n\n*{{cite book\n|author = Landau, Edmund |title =Handbuch der Lehrer von der Verteilung der Primzahlen, Vol. I|publisher =Chelsea|year= 1974| isbn =  0-8284-0096-2}} (see pages 222-229, also available on the [[arXiv|Cornell archive]])\n\n*{{Cite journal\n|last = [[Alexander Lubotzky|Lubotzky]]|first=Alexander|last2=Segal|first2= Dan | title = Subgroup growth | series= Progress in Mathematics| publisher=Birkhäuser|year=2003\n|ref = harv\n|postscript = <!--None-->\n|isbn = 3-7643-6989-2}}.\n\n*{{cite journal |author1=Polterovich, Leonid  |author2=Rudnick, Zeev |lastauthoramp=yes | title= Stable mixing for cat maps and quasi-morphisms of the modular group| year=2004| journal = Erg. Th. & Dynam. Syst.| volume=24|pages=609–619| doi= 10.1017/S0143385703000531 | ref = harv | issue = 2|arxiv=math/0009143}}\n\n[[Category:Algebra]]\n[[Category:Geometric group theory]]"
    },
    {
      "title": "Brahmagupta–Fibonacci identity",
      "url": "https://en.wikipedia.org/wiki/Brahmagupta%E2%80%93Fibonacci_identity",
      "text": "In [[algebra]], the '''Brahmagupta–Fibonacci identity'''<ref>http://www.cut-the-knot.org/m/Algebra/BrahmaguptaFibonacci.shtml</ref><ref>Marc Chamberland: ''Single Digits: In Praise of Small Numbers''. Princeton University Press, 2015, {{ISBN|9781400865697}}, p. 60</ref> expresses the product of two sums of two squares as a sum of two squares in two different ways. Hence the set of all sums of two squares is [[closure (mathematics)|closed]] under multiplication. Specifically, the identity says\n:<math>\\begin{align}\n\\left(a^2 + b^2\\right)\\left(c^2 + d^2\\right) & {}= \\left(ac-bd\\right)^2 + \\left(ad+bc\\right)^2 & & (1) \\\\\n                                             & {}= \\left(ac+bd\\right)^2 + \\left(ad-bc\\right)^2. & & (2)\n\\end{align}</math>\nFor example,\n:<math>(1^2 + 4^2)(2^2 + 7^2) = 26^2 + 15^2 = 30^2 + 1^2.</math>\n\nThe identity is also known as the '''Diophantus identity''',<ref name=stillwell2>{{Harvnb|Stillwell|2002|p =76}}</ref><ref>[[Daniel Shanks]], Solved and unsolved problems in number theory, p.209, American Mathematical Society, Fourth edition 1993.</ref>  as it was first proved by [[Diophantus|Diophantus of Alexandria]].  It is a special case of [[Euler's four-square identity]], and also of [[Lagrange's identity]]. \n\n[[Brahmagupta]] proved and used a more general identity (the [[Brahmagupta identity]]), equivalent to\n:<math>\\begin{align}\n\\left(a^2 + nb^2\\right)\\left(c^2 + nd^2\\right) & {}= \\left(ac-nbd\\right)^2 + n\\left(ad+bc\\right)^2 & & (3) \\\\\n                                               & {}= \\left(ac+nbd\\right)^2 + n\\left(ad-bc\\right)^2. & & (4)\n\\end{align}</math>\nThis shows that, for any fixed ''A'', the set of all numbers of the form ''x''<sup>2</sup>&nbsp;+&nbsp;''A''&nbsp;''y''<sup>2</sup> is closed under multiplication.\n\nThe identity holds in the [[integer|ring of integers]], the [[rational number|ring of rational numbers]] and, more generally, any [[commutative ring]].  All four forms of the identity can be verified by [[polynomial expansion|expanding]] each side of the equation.  Also, (2) can be obtained from (1), or (1) from (2), by changing ''b'' to&nbsp;&minus;''b'', and likewise with (3) and (4).\n\n==History==\nThe identity is actually first found in [[Diophantus]]' ''[[Arithmetica]]'' (III, 19), of the third century A.D.\nIt was rediscovered by Brahmagupta (598&ndash;668), an [[Indian mathematicians|Indian mathematician]] and [[Indian astronomy|astronomer]], who generalized it (to the [[Brahmagupta's identity|Brahmagupta identity]]) and used it in his study of what is now called [[Pell's equation]]. His ''[[Brahmasphutasiddhanta]]'' was translated from [[Sanskrit]] into [[Arabic language|Arabic]] by [[Mohammad al-Fazari]], and was subsequently translated into [[Latin]] in 1126.<ref name=Joseph>{{Harvnb|Joseph|2000|p=306}}</ref> The identity later appeared in [[Fibonacci]]'s ''[[The Book of Squares|Book of Squares]]'' in 1225.\n\n==Related identities==\n\nAnalogous identities are [[Euler's four-square identity|Euler's four-square]] related to [[quaternions]], and [[Degen's eight-square identity|Degen's eight-square]] derived from the [[octonions]] which has connections to [[Bott periodicity]]. There is also [[Pfister's sixteen-square identity]], though it is no longer bilinear.\n\n== Multiplication of complex numbers ==\n\nIf ''a'', ''b'', ''c'', and ''d'' are [[real number]]s, the Brahmagupta–Fibonacci identity is equivalent to the multiplicativity property for absolute values of [[complex numbers]]:\n\n:<math>  | a+bi | \\cdot | c+di | = | (a+bi)(c+di) | .</math>\n\nThis can be seen as follows: expanding the right side and squaring both sides, the multiplication property is equivalent to\n\n:<math>  | a+bi |^2 \\cdot | c+di |^2 = | (ac-bd)+i(ad+bc) |^2,</math>\n\nand by the definition of absolute value this is in turn equivalent to\n\n:<math>  (a^2+b^2)\\cdot (c^2+d^2)= (ac-bd)^2+(ad+bc)^2. </math>\n\nAn equivalent calculation in the case that the variables ''a'', ''b'', ''c'', and ''d'' are [[rational number]]s shows the identity may be interpreted as the statement that the [[field norm|norm]] in the [[field (mathematics)|field]] '''Q'''(''i'') is multiplicative: the norm is given by \n: <math>N(a+bi) = a^2 + b^2,</math>\nand the multiplicativity calculation is the same as the preceding one.\n\n== Application to Pell's equation ==\nIn its original context, Brahmagupta applied his discovery of this identity to the solution of [[Pell's equation]] ''x''<sup>2</sup>&nbsp;&minus;&nbsp;''Ay''<sup>2</sup>&nbsp;=&nbsp;1. Using the identity in the more general form\n\n:<math>(x_1^2 - Ay_1^2)(x_2^2 - Ay_2^2) = (x_1x_2 + Ay_1y_2)^2 - A(x_1y_2 + x_2y_1)^2, </math>\n\nhe was able to \"compose\" triples (''x''<sub>1</sub>,&nbsp;''y''<sub>1</sub>,&nbsp;''k''<sub>1</sub>) and (''x''<sub>2</sub>,&nbsp;''y''<sub>2</sub>,&nbsp;''k''<sub>2</sub>) that were solutions of ''x''<sup>2</sup>&nbsp;&minus;&nbsp;''Ay''<sup>2</sup>&nbsp;=&nbsp;''k'', to generate the new triple\n\n:<math>(x_1x_2 + Ay_1y_2 \\,,\\, x_1y_2 + x_2y_1 \\,,\\, k_1k_2).</math>\n\nNot only did this give a way to generate infinitely many solutions to ''x''<sup>2</sup>&nbsp;&minus;&nbsp;''Ay''<sup>2</sup>&nbsp;=&nbsp;1 starting with one solution, but also, by dividing such a composition by ''k''<sub>1</sub>''k''<sub>2</sub>, integer or \"nearly integer\" solutions could often be obtained. The general method for solving the Pell equation given by [[Bhaskara II]] in 1150, namely the [[chakravala method|chakravala (cyclic) method]], was also based on this identity.<ref name=stillwell>{{Harvnb|Stillwell|2002|pp=72–76}}</ref>\n\n== Writing integers as a sum of two squares ==\nWhen used in conjunction with one of [[Fermat's theorem on sums of two squares|Fermat's theorems]], the Brahmagupta–Fibonacci identity proves that the product of a square and any number of primes of the form 4''n''&nbsp;+&nbsp;1 is a sum of two squares.\n\n==See also==\n{{Div col}}\n* [[Brahmagupta matrix]]\n* [[Indian mathematics]]\n* [[List of Indian mathematicians]]\n* [[Sum of two squares theorem]]\n{{Div col end}}\n\n==Notes==\n{{reflist|2}}\n\n==References==\n*{{citation | last=Joseph | first=George G. | author-link=George G. Joseph | year=2000 | title=The Crest of the Peacock: The Non-European Roots of Mathematics | edition=2nd | publisher=[[Princeton University Press]] | page=306 | isbn=978-0-691-00659-8 | url={{Google books|c-xT0KNJp0cC|plainurl=yes}}}}<!-- Google books links to the 3rd edition. -->\n*{{citation | last=Stillwell | first=John | author-link = John Stillwell | year=2002 | title = Mathematics and its history | edition=2nd | publisher=[[Springer Science+Business Media|Springer]] | isbn=978-0-387-95336-6 | pages=72–76 | url={{Google books|WNjRrqTm62QC|page=72|plainurl=yes}}}}\n\n==External links==\n*[http://planetmath.org/SumsOfTwoSquares Brahmagupta's identity at [[PlanetMath]]]\n*[http://mathworld.wolfram.com/BrahmaguptaIdentity.html Brahmagupta Identity] on [[MathWorld]]\n*[http://sites.google.com/site/tpiezas/005b/  A Collection of Algebraic Identities]\n[[ru:Брахмагупта#Тождество Брахмагупты]]\n\n{{DEFAULTSORT:Brahmagupta-Fibonacci identity}}\n[[Category:Algebra]]\n[[Category:Brahmagupta]]\n[[Category:Elementary algebra]]\n[[Category:Mathematical identities]]\n[[Category:Squares in number theory]]"
    },
    {
      "title": "Brahmagupta's identity",
      "url": "https://en.wikipedia.org/wiki/Brahmagupta%27s_identity",
      "text": "In [[algebra]], '''Brahmagupta's identity''' says that the product of two numbers of the form <math>a^2+nb^2</math> is itself a number of that form. In other words, the set of such numbers is [[closure (mathematics)|closed]] under multiplication. Specifically:\n\n:<math>\\begin{align}\n\\left(a^2 + nb^2\\right)\\left(c^2 + nd^2\\right) & {}= \\left(ac-nbd\\right)^2 + n\\left(ad+bc\\right)^2 & & & (1) \\\\\n                                               & {}= \\left(ac+nbd\\right)^2 + n\\left(ad-bc\\right)^2, & & & (2)\n\\end{align}</math>\n\nBoth (1) and (2) can be verified by [[polynomial expansion|expanding]] each side of the equation.  Also, (2) can be obtained from (1), or (1) from (2), by changing ''b'' to&nbsp;&minus;''b''.\n\nThis identity holds in both the [[integer|ring of integers]] and the [[rational number|ring of rational numbers]], and more generally in any [[commutative ring]].\n\n==History==\nThe identity is a generalization of the so-called [[Brahmagupta–Fibonacci identity|Fibonacci identity]] (where ''n''=1) which is actually found in [[Diophantus]]' ''[[Arithmetica]]'' (III, 19).\nThat identity was rediscovered by [[Brahmagupta]] (598&ndash;668), an [[Indian mathematicians|Indian mathematician]] and [[Indian astronomy|astronomer]], who generalized it and used it in his study of what is now called [[Pell's equation]]. His ''[[Brahmasphutasiddhanta]]'' was translated from [[Sanskrit]] into [[Arabic language|Arabic]] by [[Mohammad al-Fazari]], and was subsequently translated into [[Latin]] in 1126.<ref>George G. Joseph (2000). ''The Crest of the Peacock'', p. 306. [[Princeton University Press]]. {{ISBN|0-691-00659-8}}.</ref> The identity later appeared in [[Fibonacci]]'s ''[[The Book of Squares|Book of Squares]]'' in 1225.\n\n== Application to Pell's equation ==\nIn its original context, Brahmagupta applied his discovery to the solution of what was later called [[Pell's equation]], namely ''x''<sup>2</sup>&nbsp;&minus;&nbsp;''Ny''<sup>2</sup>&nbsp;=&nbsp;1. Using the identity in the form\n\n:<math>(x_1^2 - Ny_1^2)(x_2^2 - Ny_2^2) = (x_1x_2 + Ny_1y_2)^2 - N(x_1y_2 + x_2y_1)^2, </math>\n\nhe was able to \"compose\" triples (''x''<sub>1</sub>,&nbsp;''y''<sub>1</sub>,&nbsp;''k''<sub>1</sub>) and (''x''<sub>2</sub>,&nbsp;''y''<sub>2</sub>,&nbsp;''k''<sub>2</sub>) that were solutions of ''x''<sup>2</sup>&nbsp;&minus;&nbsp;''Ny''<sup>2</sup>&nbsp;=&nbsp;''k'', to generate the new triple\n\n:<math>(x_1x_2 + Ny_1y_2 \\,,\\, x_1y_2 + x_2y_1 \\,,\\, k_1k_2).</math>\n\nNot only did this give a way to generate infinitely many solutions to ''x''<sup>2</sup>&nbsp;&minus;&nbsp;''Ny''<sup>2</sup>&nbsp;=&nbsp;1 starting with one solution, but also, by dividing such a composition by ''k''<sub>1</sub>''k''<sub>2</sub>, integer or \"nearly integer\" solutions could often be obtained. The general method for solving the Pell equation given by [[Bhaskara II]] in 1150, namely the [[chakravala method|chakravala (cyclic) method]], was also based on this identity.<ref name=stillwell>{{citation | year=2002 | title = Mathematics and its history | author1=[[John Stillwell]] | edition=2 | publisher=Springer | isbn=978-0-387-95336-6 | pages=72–76 | url=https://books.google.com/books?id=WNjRrqTm62QC&pg=PA72}}</ref>\n\n==See also==\n* [[Brahmagupta matrix]]\n* [[Brahmagupta–Fibonacci identity]]\n* [[Brahmagupta's interpolation formula]]\n* [[Indian mathematics]]\n* [[List of Indian mathematicians]]\n\n==References==\n{{reflist}}\n\n==External links==\n*[https://web.archive.org/web/20121129133237/http://planetmath.org/encyclopedia/BrahmaguptasIdentity.html Brahmagupta's identity at [[PlanetMath]]]\n*[http://mathworld.wolfram.com/BrahmaguptaIdentity.html Brahmagupta Identity] on [[MathWorld]]\n*[http://sites.google.com/site/tpiezas/005b/  A Collection of Algebraic Identities]\n\n[[Category:Algebra]]\n[[Category:Elementary algebra]]\n[[Category:Mathematical identities]]\n[[Category:Brahmagupta]]"
    },
    {
      "title": "Calabi–Yau algebra",
      "url": "https://en.wikipedia.org/wiki/Calabi%E2%80%93Yau_algebra",
      "text": "In algebra, a '''Calabi–Yau algebra''' was introduced by [[Victor Ginzburg]] to transport the geometry of a [[Calabi–Yau manifold]] to [[noncommutative algebraic geometry]].\n\n== References ==\n*{{cite arXiv |first1=Victor |last1=Ginzburg |title=Calabi-Yau algebras |year=2007 |eprint=math/0612139}}\n\n{{DEFAULTSORT:Calabi-Yau algebra}}\n[[Category:Algebra]]\n\n\n{{algebraic-geometry-stub}}"
    },
    {
      "title": "Canonical form",
      "url": "https://en.wikipedia.org/wiki/Canonical_form",
      "text": "{{for|\"canonical form\" in linguistics|Lemma (morphology)}}\n{{refimprove|date=December 2007}}\n[[File:Anagram canonical svg.svg|thumb|Algorithmic [[anagram]] test using [[multiset]]s as canonical forms: The strings \"<tt>madam curie</tt>\" and \"<tt>radium came</tt>\" are given as [[C (programming language)|C]] arrays. Each one is converted into a canonical form by sorting. Since both sorted strings literally agree, the original strings were anagrams of each other.]]\nIn [[mathematics]] and [[computer science]], a '''canonical''', '''normal''', or '''standard'''  '''form''' of a [[mathematical object]] is a standard way of presenting that object as a [[mathematical expression]]. The distinction between \"canonical\" and \"normal\" forms varies by subfield. In most fields, a canonical form specifies a ''unique'' representation for every object, while a normal form simply specifies its form, without the requirement of uniqueness.\n\nThe canonical form of a [[positive integer]] in [[decimal representation]] is a finite sequence of digits that does not begin with zero.\n\nMore generally, for a class of objects on which an [[equivalence relation]] is defined, a '''canonical form''' consists in the choice of a specific object in each class. For example, [[Jordan normal form]] is a canonical form for [[matrix similarity]], and the [[row echelon form]] is a canonical form, when one considers as equivalent a matrix and its left product by an [[invertible matrix]].\n\nIn computer science, and more specifically in [[computer algebra]], when representing mathematical objects in a computer, there are usually many different ways to represent the same object. In this context, a '''canonical form''' is a representation such that every object has a unique representation. Thus, the equality of two objects can easily be tested by testing the equality of their canonical forms. However canonical forms frequently depend on arbitrary choices (like ordering the variables), and this introduces difficulties for testing the equality of two objects resulting on independent computations. Therefore, in computer algebra, ''normal form'' is a weaker notion: A '''normal form''' is a representation such that zero is uniquely represented. This allows testing for equality by putting the difference of two objects in normal form.\n\n'''Canonical form''' can also mean a [[differential form]] that is defined in a natural (canonical) way.\n\nIn computer science, data that has more than one possible representation can often be canonicalized into a completely unique representation called its '''canonical form'''.  Putting something into canonical form is [[canonicalization]].<ref>The term 'canonization' is sometimes incorrectly used for this.</ref>\n\n==Definition==\nSuppose we have some set ''S'' of objects, with an [[equivalence relation]] ''R''. A '''canonical form''' is given by designating some objects of ''S'' to be \"in canonical form\", such that every object under consideration is equivalent to exactly one object in canonical form. In other words, the canonical forms in ''S'' represent the equivalence classes, once and only once. To test whether two objects are equivalent, it then suffices to test their canonical forms for equality.\nA canonical form thus provides a [[classification theorem]] and more, in that it not just classifies every class, but gives a distinguished (canonical) representative.\n\nFormally, a canonicalization with respect to an equivalence relation ''R'' on a set ''S'' is a mapping ''c'':''S''→''S'' such that for all ''s'', ''s''<sub>1</sub>, ''s''<sub>2</sub> ∈ ''S'':\n# ''c''(''s'') = ''c''(''c''(''s'')) &nbsp; ([[idempotence]]),\n# ''s''<sub>1</sub> ''R'' ''s''<sub>2</sub> if and only if ''c''(''s''<sub>1</sub>) = ''c''(''s''<sub>2</sub>) &nbsp; (decisiveness), and \n# ''s'' ''R'' ''c''(''s'') &nbsp; (representativeness). \nProperty 3 is redundant, it follows by applying 2 to 1.\n\nIn practical terms, one wants to be able to recognize the canonical forms. There is also a practical, algorithmic question to consider: how to pass from a given object ''s'' in ''S'' to its canonical form ''s''*? Canonical forms are generally used to make operating with equivalence classes more effective. For example, in [[modular arithmetic]], the canonical form for a residue class is usually taken as the least non-negative integer in it. Operations on classes are carried out by combining these representatives and then reducing the result to its least non-negative residue.\nThe uniqueness requirement is sometimes relaxed, allowing the forms to be unique up to some finer equivalence relation, like allowing reordering of terms (if there is no natural ordering on terms).\n\nA canonical form may simply be a convention, or a deep theorem.\n\nFor example, polynomials are conventionally written with the terms in descending powers: it is more usual to write ''x''<sup>2</sup> + ''x'' + 30 than ''x'' + 30 + ''x''<sup>2</sup>, although the two forms define the same polynomial. By contrast, the existence of [[Jordan canonical form]] for a matrix is a deep theorem.\n\n==Examples==\nNote: in this section, \"[[up to]]\" some equivalence relation E means that the canonical form is not unique in general, but that if one object has two different canonical forms, they are E-equivalent.\n\n=== Large number notation ===\n\nStandard form is used by many mathematicians and scientists to write extremely [[large numbers#Standardized system of writing very large numbers|large numbers]] in a more concise and understandable way.\n\n=== Number theory ===\n* [[Canonical representation of a positive integer]]\n* Canonical form of a [[continued fraction]]\n\n=== Linear algebra ===\n{| class=\"wikitable\"\n|-\n! Objects\n! ''A'' is equivalent to ''B'' if:\n! Normal form\n! Notes\n|- \n| [[Normal matrix|Normal]] matrices over the [[complex numbers]]\n| <math>A=U^* B U</math> for some [[unitary matrix]] ''U'' \n| [[Diagonal matrices]] (up to reordering)\n| This is the [[Spectral theorem]]\n|- \n| Matrices over the complex numbers\n| <math>A=U B V^*</math> for some [[unitary matrix|unitary matrices]] ''U'' and ''V''\n| Diagonal matrices with real positive entries (in descending order)\n| [[Singular value decomposition]]\n|- \n| Matrices over an [[algebraically closed field]]\n| <math>A=P^{-1} B P</math> for some [[invertible]] matrix ''P'' \n| [[Jordan normal form]] (up to reordering of blocks)\n|\n|- \n| Matrices over an [[algebraically closed field]]\n| <math>A=P^{-1} B P</math> for some [[invertible]] matrix ''P'' \n| [[Weyr canonical form]] (up to reordering of blocks)\n|\n|-\n| Matrices over a field\n| <math>A=P^{-1} B P</math> for some [[invertible]] matrix ''P''\n| [[Frobenius normal form]]\n|\n|-\n| Matrices over a [[principal ideal domain]]\n| <math>A=P^{-1} B Q</math> for some [[invertible]] Matrices ''P'' and ''Q''\n| [[Smith normal form]]\n| The equivalence is the same as allowing invertible elementary row and column transformations\n|-\n| Matrices over the integers\n| <math>A=UB</math> for some [[unimodular matrix|unimodular]] matrix ''U''\n| [[Hermite normal form]]\n|\n|- \n| Finite-dimensional [[vector space]]s over a field ''K''\n| ''A'' and ''B'' are isomorphic as vector spaces\n| <math>K^n</math>, ''n'' a non-negative integer\n|\n|}\n\n=== Algebra ===\n{| class=\"wikitable\"\n|-\n! Objects\n! ''A'' is equivalent to ''B'' if:\n! Normal form\n|-\n| Finitely generated ''R''-modules with ''R'' a [[principal ideal domain]]\n| ''A'' and ''B'' are isomorphic as ''R''-modules\n| [[Structure theorem for finitely generated modules over a principal ideal domain|Primary decomposition (up to reordering) or invariant factor decomposition]]\n|}\n\n=== Geometry ===\nIn [[analytic geometry]]:\n*The equation of a line: ''Ax''&nbsp;+&nbsp;''By''&nbsp;=&nbsp;''C'', with  ''A<sup>2</sup>''&nbsp;+&nbsp;''B''<sup>2</sup>&nbsp;=&nbsp;1 and ''C''&nbsp;≥&nbsp;0\n*The equation of a circle: <math>(x - h)^2 + (y - k)^2 = r^2</math>\n\nBy contrast, there are alternative forms for writing equations. For example, the equation of a line may be written as a [[linear equation]] in point-slope and slope-intercept form.\n\n[[Convex polyhedra]] can be put into [[Midsphere#Canonical_polyhedron|canonical form]] such that:\n* All faces are flat,\n* All edges are tangent to the unit sphere, and\n* The centroid of the polyhedron is at the origin.<ref>{{citation|title=Lectures on Polytopes|authorlink=Günter M. Ziegler|first=Günter M.|last=Ziegler|year=1995|isbn=0-387-94365-X|series=Graduate Texts in Mathematics|publisher=Springer-Verlag|volume=152|pages=117–118}}</ref>\n===Integrable systems===\nEvery differentiable [[manifold]] has a [[cotangent bundle]]. That bundle can always be endowed with a certain [[differential form]], called the [[canonical one-form]]. This form gives the cotangent bundle the structure of a [[symplectic manifold]]. This allows vector fields on the manifold to be integrated by means of the [[Euler-Lagrange equation]]s, or by means of [[Hamiltonian mechanics]]. Such systems of integrable [[differential equation]]s are called [[integrable system]]s.\n\n=== Dynamical systems ===\nThe study of [[dynamical systems]] overlaps with that of integrable systems; there one has the idea of a [[normal form (dynamical systems)]].\n\n=== Three dimensional geometry ===\nIn the study of manifolds in three dimensions, one has the [[first fundamental form]], the [[second fundamental form]] and the [[third fundamental form]].\n\n=== Functional analysis ===\n{| class=\"wikitable\"\n|-\n! Objects\n! ''A'' is equivalent to ''B'' if:\n! Normal form\n|-\n| [[Hilbert spaces]]\n| If ''A'' and ''B'' are both [[Separable space|separable]] Hilbert spaces of infinite dimension, then ''A'' and ''B'' are isometrically isomorphic.\n| <math>\\ell^2(I)</math> [[Hilbert space#Sequence spaces|sequence spaces]] (up to exchanging the index set ''I'' with another index set of the same [[cardinality]])\n|- \n<!-- please double-check this one -->\n| Commutative <math>C^*</math>-algebras with unit\n| ''A'' and ''B'' are isomorphic as <math>C^*</math>-algebras\n| The algebra <math>C(X)</math> of continuous functions on a [[compact space|compact]] [[Hausdorff space]], up to [[homeomorphism]] of the base space.\n|}\n\n=== Classical logic ===\n{{main article|Canonical form (Boolean algebra)}}\n* [[Negation normal form]]\n* [[Conjunctive normal form]]\n* [[Disjunctive normal form]]\n* [[Algebraic normal form]]\n* [[Prenex normal form]]\n* [[Skolem normal form]]\n* [[Blake canonical form]], also known as the complete sum of prime implicants, the complete sum, or the disjunctive prime form\n\n=== Set theory ===\n* [[Cantor normal form#Cantor normal form|Cantor normal form]] of an [[ordinal number]]\n\n=== Game theory ===\n* [[Normal form game]]\n\n=== Proof theory ===\n* [[Normal form (natural deduction)]]\n\n===Rewriting systems===\n{{main|Normal form (abstract rewriting)}}\nThe symbolic manipulation of a formula from one form to another is called a \"rewriting\" of that formula. One can study the abstract properties of rewriting generic formulas; one need only specify a collection of rules by which formulas can be validly manipulated.  These are the \"rewriting rules\", they form an [[abstract rewriting system]].  A common question is whether it is possible to bring some generic expression to a single, common form, the normal form. If different sequences of rewrites still result in the same form, then that form can be termed a normal form; and the rewrite is called confluent. It is not always possible to obtain a normal form.\n\n=== Lambda calculus===\n* A lambda term is in [[beta normal form]] if no beta reduction is possible; [[lambda calculus]] is a particular case of an abstract rewriting system. In the untyped lambda calculus, e.g., the term <math>(\\lambda x.(x x) \\; \\lambda x.(x x))</math> doesn't have a normal form. In the typed lambda calculus, every well-formed term can be rewritten to its normal form.\n\n===Graph theory===\n{{main article|Graph canonization}}\nIn [[graph theory]], a branch of mathematics, '''graph canonization''' is the problem of finding a canonical form of a given graph ''G''. A canonical form is a [[Graph labeling|labeled graph]] Canon(''G'') that is [[graph isomorphism|isomorphic]] to ''G'', such that every graph that is isomorphic to ''G'' has the same canonical form as ''G''. Thus, from a solution to the graph canonization problem, one could also solve the problem of [[graph isomorphism]]: to test whether two graphs ''G'' and ''H'' are isomorphic, compute their canonical forms Canon(''G'') and Canon(''H''), and test whether these two canonical forms are identical.\n\n=== Computing ===\nIn [[computing]], the reduction of data to any kind of canonical form is commonly called ''data normalization''.\n\nFor instance, [[database normalization]] is the process of organizing the [[Field (computer science)|fields]] and [[Table (database)|table]]s of a [[relational database]] to minimize [[Data redundancy|redundancy]] and dependency. \n\nIn the field of [[software security]], a common [[Vulnerability (computing)|vulnerability]] is unchecked [[malicious input]]. The mitigation for this problem is proper [[input validation]]. Before input validation may be performed, the input must be normalized, i.e., eliminating encoding (for instance [[Character encodings in HTML|HTML encoding]]) and reducing the input data to a single common [[character set]].\n\nOther forms of data, typically associated with [[signal processing]] (including [[Audio signal processing|audio]] and [[Image processing|imaging]]) or [[machine learning]], can be normalized in order to provide a limited range of values.\n\n==See also==\n* [[Canonicalization]]\n* [[Canonical basis]]\n* [[Canonical class]]\n* [[Normalization (disambiguation)]]\n* [[Standardization]]\n\n==Notes==\n<references/>\n\n==References==\n*{{citation | last=Shilov | first=Georgi E. | title=Linear Algebra | editor-last=Silverman | editor-first=Richard A. | date=1977 | publisher=Dover | isbn=0-486-63518-X }}.\n*{{citation | last=Hansen | first=Vagn Lundsgaard | title = Functional Analysis: Entering Hilbert Space | date=2006 | publisher=World Scientific Publishing | isbn=981-256-563-9}}.\n\n[[Category:Algebra]]\n[[Category:Concepts in logic]]\n[[Category:Mathematical terminology]]\n[[Category:Formalism (deductive)]]\n\n[[nl:Normaalvorm]]"
    },
    {
      "title": "Classical Lie algebras",
      "url": "https://en.wikipedia.org/wiki/Classical_Lie_algebras",
      "text": "The '''classical Lie algebras''' are finite-dimensional [[Lie algebra]]s<!-- over complex numbers? --> that can be classified into four types: <math> A_n, B_n, C_n </math> and <math> D_n </math>. These types are defined as follows:\n\n: <math> A_n := \\operatorname{sl}(n+1) </math> – The special linear Lie algebra, <math> \\operatorname{sl}(n+1)=\\left\\{ X \\in \\operatorname{gl}(n+1): \\operatorname{tr}(X)=0 \\right\\}; </math>\n\n: <math> B_n := \\operatorname{so}(2n+1) </math> – The odd-dimensional orthogonal Lie algebra, <math> \\operatorname{so}(2n+1) = \\left\\{ X \\in \\operatorname{gl}(2n+1): X + X^t=0 \\right\\}; </math>\n\n: <math> C_n := \\operatorname{sp}(2n) </math> – The symplectic Lie algebra, <math> \\operatorname{sp}(2n)  = \\left\\{ X \\in \\operatorname{gl}(2n): J_n X + X^t J_n = 0, J_n =  \\begin{pmatrix} 0 & I_n \\\\ -I_n & 0 \\end{pmatrix} \\right\\}; </math>\n\n: <math> D_n := \\operatorname{so}(2n) </math> – The even-dimensional orthogonal Lie algebra, <math> \\operatorname{so}(2n) = \\left\\{ X \\in \\operatorname{gl}(2n): X + X^t=0 \\right\\}, </math>\n\nwhere <math>\\operatorname{gl}(n)</math> is the general Lie algebra of matrices <math>n</math> by <math>n</math> with coefficients in <math>R</math> or <math>C</math>,  <math>I_n</math> is the identity matrix of dimension <math> n  </math>, <math> t  </math> denotes transposition and <math> n>0 \\in N </math>.\nExcept for the low-dimensional cases <math> D_1 = \\operatorname{so}(2) </math> and <math> D_2 = \\operatorname{so}(4) </math>, the classical Lie algebras are simple.<ref>{{Cite book|url=https://www.worldcat.org/oclc/468609320|title=Dictionary on Lie algebras and superalgebras|last=Antonino.|first=Sciarrino,|last2=Paul.|first2=Sorba,|date=2000-01-01|publisher=Academic Press|isbn=9780122653407|oclc=468609320}}</ref><ref>{{Cite book|url=https://www.worldcat.org/oclc/952065417|title=Introduction to finite and infinite dimensional lie (super)algebras|last=1945–|first=Sthanumoorthy, Neelacanta,|isbn=9780128046753|oclc=952065417}}</ref>\n\nThe [[Moyal bracket|Moyal algebra]] is an infinite-dimensional Lie algebra that contains all classical Lie algebras as subalgebras.\n\n==References==\n{{reflist}}\n\n[[Category:Algebra]]"
    },
    {
      "title": "Closed-form expression",
      "url": "https://en.wikipedia.org/wiki/Closed-form_expression",
      "text": "{{Use American English|date = January 2019}}\n{{Short description|Mathematical formula built with arithmetic operations and other previously defined functions}}\n{{Redirect|Closed formula|\"closed formula\" in the sense of a logic formula with no free variables|Sentence (mathematical logic)}}\n{{refimprove|date=June 2014}}\n\nIn [[mathematics]], a '''closed-form expression''' is a [[expression (mathematics)|mathematical expression]] that can be evaluated in a [[finite set|finite]] number of operations. It may contain [[Constant (mathematics)|constants]], [[Variable (mathematics)|variables]], certain \"well-known\" [[Operation (mathematics)|operations]] (e.g., + − × ÷), and [[function (mathematics)|function]]s (e.g., [[Nth root|''n''th root]], [[exponent]], [[logarithm]], [[trigonometric functions]], and [[inverse hyperbolic functions]]), but usually no [[limit of a sequence|limit]]. The set of operations and functions admitted in a closed-form expression may vary with author and context.\n\n== Example: roots of polynomials ==\n\nThe solutions of any [[quadratic equation]] with [[complex number|complex]] [[coefficients]] can be expressed in closed form in terms of [[addition]], [[subtraction]], [[multiplication]], [[Division (mathematics)|division]], and [[square root]] extraction, each of which is an [[elementary function]]. For example, the quadratic equation\n\n:<math>ax^2+bx+c=0,</math>\n\nis tractable since its solutions can be expressed as a closed-form expression, i.e. in terms of elementary functions:\n\n:<math>x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}.</math>\n\nSimilarly solutions of cubic and quartic (third and fourth degree) equations can be expressed using arithmetic, square roots, and [[cube root]]s, or alternatively using arithmetic and trigonometric functions. However, there are [[quintic equation]]s without closed-form solutions using elementary functions, such as ''x''<sup>5</sup>&nbsp;−&nbsp;''x''&nbsp;+&nbsp;1&nbsp;=&nbsp;0.\n\nAn area of study in mathematics referred to broadly as [[Galois theory]] involves proving that no closed-form expression exists in certain contexts, based on the central example of closed-form solutions to polynomials.\n\n== Alternative definitions ==\n\nChanging the definition of \"well-known\" to include additional functions can change the set of equations with closed-form solutions.  Many [[cumulative distribution function]]s cannot be expressed in closed form, unless one considers [[special functions]] such as the [[error function]] or [[gamma function]] to be well known.  It is possible to solve the quintic equation if general [[hypergeometric function]]s are included, although the solution is far too complicated algebraically to be useful.  For many practical computer applications, it is entirely reasonable to assume that the gamma function and other special functions are well-known since numerical implementations are widely available.\n\n== Analytic expression ==\n\nAn '''analytic expression''' (or '''expression in analytic form''') is a [[mathematical expression]] constructed using well-known operations that lend themselves readily to calculation. Similar to closed-form expressions, the set of well-known functions allowed can vary according to context but always includes the [[Arithmetic#Arithmetic operations|basic arithmetic operations]] (addition, subtraction, multiplication, and division), exponentiation to a real exponent (which includes extraction of the [[nth root|{{math|''n''}}th root]]), logarithms, and trigonometric functions.\n\nHowever, the class of expressions considered to be analytic expressions tends to be wider than that for closed-form expressions. In particular, [[special functions]] such as the [[Bessel functions]] and the [[gamma function]] are usually allowed, and often so are [[Series (mathematics)|infinite series]] and [[continued fraction]]s. On the other hand, [[Limit of a sequence|limits]] in general, and [[integral]]s in particular, are typically excluded.{{cn|reason=This paragraph seems [[WP:OR]]. In particular, here, the distinction between series and limits is completely irrelevant.|date=June 2018}}\n\nIf an analytic expression involves only the algebraic operations (addition, subtraction, multiplication, division, and exponentiation to a rational exponent) and rational constants then it is more specifically referred to as an [[algebraic expression]].\n\n==<span id=\"Closed-form_vs._analytical_expressions\"></span> Comparison of different classes of expressions ==\n\nClosed-form expressions are an important sub-class of analytic expressions, which contain a bounded{{citation needed|reason=This would make the sub-class non-closed e.g. wrt. addition: if e.g. up to one application of 'sin' is allowed, both 'sin(x)' and 'sin(y)' would be a member, but their sum would not. I wonder if any author can be found for this.|date=October 2014}} or an unbounded number of applications of well-known functions. Unlike the broader analytic expressions, the closed-form expressions do not include [[Series (mathematics)#Infinite series|infinite series]] or [[continued fraction]]s; neither includes [[integral]]s or [[limit of a sequence|limits]]. Indeed, by the [[Stone–Weierstrass theorem]], any [[continuous function]] on the [[unit interval]] can be expressed as a limit of polynomials, so any class of functions containing the polynomials and closed under limits will necessarily include all continuous functions.\n\nSimilarly,  an [[equation]] or [[system of equations]] is said to have a '''closed-form solution''' if, and only if, at least one [[equation solving|solution]] can be expressed as a closed-form expression; and it is said to have an '''analytic solution''' if and only if at least one solution can be expressed as an analytic expression. There is a subtle distinction between a \"closed-form ''function''\" and a \"[[#Closed-form number|closed-form ''number'']]\" in the discussion of a \"closed-form solution\", discussed in {{Harv|Chow|1999}} and [[#Closed-form number|below]]. A closed-form or analytic solution is sometimes referred to as an '''explicit solution'''.\n\n{{Mathematical expressions}}\n\n== Dealing with non-closed-form expressions ==\n\n=== Transformation into closed-form expressions ===\n\nThe expression:\n\n:<math>f(x) = \\sum_{i=0}^\\infty {x \\over 2^i}</math>\n\nis not in closed form because the summation entails an infinite number of elementary operations. However, by summing a [[geometric series]] this expression can be expressed in the closed form:<ref>{{cite web|last=Holton|first=Glyn|title=Numerical Solution, Closed-Form Solution|url=http://www.riskglossary.com/link/closed_form_solution.htm|accessdate=31 December 2012}}</ref>\n\n:<math>f(x) = 2x.</math>\n\n=== Differential Galois theory ===\n{{main article|Differential Galois theory}}\n\nThe integral of a closed-form expression may or may not itself be expressible as a closed-form expression. This study is referred to as [[differential Galois theory]], by analogy with algebraic Galois theory.\n\nThe basic theorem of differential Galois theory is due to [[Joseph Liouville]] in the 1830s and 1840s and hence referred to as '''[[Liouville's theorem (differential algebra)|Liouville's theorem]]'''.\n\nA standard example of an elementary function whose antiderivative does not have a closed-form expression is:\n\n:<math>e^{-x^2},</math>\n\nwhose antiderivative is (up to constants) the [[error function]]:\n\n:<math>\\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_{0}^x e^{-t^2}\\,dt.</math>\n\n=== Mathematical modelling and computer simulation ===\n\nEquations or systems too complex for closed-form or analytic solutions can often be analysed by [[mathematical model]]ling and [[computer simulation]].\n\n== Closed-form number ==\n{{see also|Transcendental number theory}}\n\nThree subfields of the complex numbers '''C''' have been suggested as encoding the notion of a \"closed-form number\"; in increasing order of generality, these are the [[Liouville number]]s, [[EL number]]s and [[elementary number]]s. The '''Liouville numbers''', denoted '''L''' (not to be confused with [[Liouville number]]s in the sense of rational approximation), form the smallest ''[[algebraically closed]]'' subfield of '''C''' closed under exponentiation and logarithm (formally, intersection of all such subfields)—that is, numbers which involve ''explicit'' exponentiation and logarithms, but allow explicit and ''implicit'' polynomials (roots of polynomials); this is defined in {{Harv|Ritt|1948|loc=p. 60}}. '''L''' was originally referred to as '''elementary numbers''', but this term is now used more broadly to refer to numbers defined explicitly or implicitly in terms of algebraic operations, exponentials, and logarithms. A narrower definition proposed in {{Harv|Chow|1999|loc=pp. 441–442}}, denoted '''E''', and referred to as '''EL numbers''', is the smallest subfield of '''C''' closed under exponentiation and logarithm—this need not be algebraically closed, and correspond to ''explicit'' algebraic, exponential, and logarithmic operations. \"EL\" stands both for \"Exponential-Logarithmic\" and as an abbreviation for \"elementary\".\n\nWhether a number is a closed-form number is related to whether a number is [[transcendental number|transcendental]]. Formally, Liouville numbers and elementary numbers contain the [[algebraic number]]s, and they include some but not all transcendental numbers. In contrast, EL numbers do not contain all algebraic numbers, but do include some transcendental numbers. Closed-form numbers can be studied via [[transcendental number theory]], in which a major result is the [[Gelfond–Schneider theorem]], and a major open question is [[Schanuel's conjecture]].\n\n== Numerical computations ==\n\nFor purposes of numeric computations, being in closed form is not in general necessary, as many limits and integrals can be efficiently computed.\n\n== Conversion from numerical forms ==\n\nThere is software that attempts to find closed-form expressions for numerical values, including RIES,<ref>{{cite web |last = Munafo |first = Robert |title = RIES - Find Algebraic Equations, Given Their Solution |url = http://mrob.com/pub/ries/index.html |accessdate = 30 April 2012 }}</ref> <tt>identify</tt> in [[Maple (software)|Maple]]<ref>{{cite web |title = identify |url = http://www.maplesoft.com/support/help/Maple/view.aspx?path=identify |work = Maple Online Help |publisher = Maplesoft |accessdate = 30 April 2012 }}</ref> and [[SymPy]],<ref>{{cite web |title = Number identification |url = http://docs.sympy.org/0.7.1/modules/mpmath/identification.html |work = SymPy documentation }}</ref> Plouffe's Inverter,<ref>{{cite web |title = Plouffe's Inverter |url = http://pi.lacim.uqam.ca/eng/server_en.html |accessdate = 30 April 2012 }}</ref> and the [[Inverse Symbolic Calculator]].<ref>{{cite web |title = Inverse Symbolic Calculator |url = http://oldweb.cecm.sfu.ca/projects/ISC/ |accessdate = 30 April 2012 |deadurl = yes |archiveurl = https://web.archive.org/web/20120329145758/http://oldweb.cecm.sfu.ca/projects/ISC/ |archivedate = 29 March 2012 |df =  }}</ref>\n\n== See also ==\n* [[Direct method (computational mathematics)|Direct method]]\n* [[Algebraic solution]]\n* [[Finitary operation]]\n* [[Numerical solution]]\n* [[Computer simulation]]\n* [[Symbolic regression]]\n* [[Term (logic)]]\n* [[Liouvillian function]]\n* [[Elementary function]]\n\n==References==\n{{reflist}}\n\n== Further reading ==\n* {{ Citation | title = Integration in finite terms | last = Ritt | first = J. F. | authorlink = Joseph Ritt | year = 1948 }}\n* {{Citation | title = What is a Closed-Form Number? | first = Timothy Y. | last = Chow | volume = 106 | number = 5 | pages = 440–448 | jstor = 2589148 | journal = [[American Mathematical Monthly]] |date=May 1999 | doi=10.2307/2589148| arxiv = math/9805045 }}\n* {{Citation | title = Closed Forms: What They Are and Why We Care | author = Jonathan M. Borwein and Richard E. Crandall | volume = 60 | number = 1 | pages = 50–65 | journal = [[Notices of the American Mathematical Society]] | date = January 2013 | doi= 10.1090/noti936}}\n\n== External links ==\n* {{MathWorld | urlname = Closed-FormSolution | title = Closed-Form Solution}}\n\n{{DEFAULTSORT:Closed-Form Expression}}\n[[Category:Algebra]]\n[[Category:Special functions]]"
    },
    {
      "title": "Co-Hopfian group",
      "url": "https://en.wikipedia.org/wiki/Co-Hopfian_group",
      "text": "In the mathematical subject of [[group theory]], a '''co-Hopfian group''' is a [[Group (mathematics)|group]] that is not [[Isomorphism|isomorphic]] to any of its proper [[subgroup]]s. The notion is dual to that of a [[Hopfian group]], named after [[Heinz Hopf]]. <ref>[[Wilhelm Magnus]], Abraham Karrass, Donald Solitar, ''Combinatorial group theory. Presentations of groups in terms of generators and relations'', Reprint of the 1976 second edition, Dover Publications, Inc., Mineola, NY, 2004. {{ISBN|0-486-43830-9}}</ref>\n\n==Formal definition ==\n\nA group ''G'' is called '''co-Hopfian''' if whenever <math>\\varphi:G\\to G</math> is an [[Injective function|injective]] [[group homomorphism]] then  <math>\\varphi</math> is [[bijective function|bijective]], that is <math>\\varphi(G)=G</math>.<ref name=DLH>P. de la Harpe, [https://books.google.com/books?id=OEsJhiE_C00C&pg=PA58&dq=co-hopfian+group&hl=en&sa=X&ved=0ahUKEwjy69bwksHVAhWS0YMKHdy-Dq4Q6AEIKDAA#v=onepage&q=co-hopfian%20group&f=false ''Topics in geometric group theory''.] Chicago Lectures in Mathematics. University of Chicago Press, Chicago, IL, 2000. {{ISBN|0-226-31719-6}}; p. 58</ref>\n\n==Examples and non-examples==\n\n*Every finite group ''G'' is co-Hopfian.\n*The infinite cyclic group <math>\\mathbb Z</math> is not co-Hopfian since <math>f:\\mathbb Z\\to \\mathbb Z, f(n)=2n</math> is an injective but non-surjective homomorphism.\n*The additive group of real numbers <math>\\mathbb R</math> is not co-Hopfian, since  <math>\\mathbb R</math> is an infinite-dimensional vector space over <math>\\mathbb Q</math> and therefore, as a group <math>\\mathbb R\\cong \\mathbb R\\times \\mathbb R</math>.<ref name=DLH/> \n*The additive group of rational numbers <math>\\mathbb Q</math> and the quotient group <math>\\mathbb Q/\\mathbb Z</math> are co-Hopfian.<ref name=DLH/>\n*The multiplicative group <math>\\mathbb Q^\\ast</math> of nonzero rational numbers is not co-Hopfian, since the map <math>\\mathbb Q^\\ast\\to\\mathbb Q^\\ast, q\\mapsto \\operatorname{sign}(q)\\,q^2</math> is an injective but non-surjective homomorphism.<ref name=DLH/> In the same way, the group <math>\\mathbb Q^{\\ast}_+</math> of positive rational numbers is not co-Hopfian.\n*The multiplicative group <math>\\mathbb C^\\ast</math> of nonzero complex numbers is not co-Hopfian.<ref name=DLH/>\n*For every <math>n\\ge 1</math> the [[free abelian group]] <math>\\mathbb Z^n</math> is not co-Hopfian.<ref name=DLH/>\n*For every <math>n\\ge 1</math> the [[free group]] <math>F_n</math> is not co-Hopfian.<ref name=DLH/>\n*There exists a finitely generated non-elementary (that is, not virtually cyclic)  [[virtually free group]] which is co-Hopfian. Thus a subgroup of finite index in a finitely generated co-Hopfian group need not be co-Hopfian, and being co-Hopfian is not a [[quasi-isometry]] invariant for finitely generated groups.<ref name=COR/>\n*[[Baumslag–Solitar group]]s <math>BS(1,m)</math>, where <math>m\\ge 1</math>, are not co-Hopfian.<ref name=NP/>\n*If ''G'' is the [[fundamental group]] of a closed aspherical manifold with nonzero [[Euler characteristic]] (or with nonzero [[simplicial volume]] or nonzero [[L2-Betti number|L<sup>2</sup>-Betti number]]), then ''G'' is co-Hopfian.<ref name=B/>\n*If ''G'' is the fundamental group of a closed connected oriented irreducible 3-manifold ''M'' then ''G'' is co-Hopfian if and only if no finite cover of ''M'' is a torus bundle over the circle or the product of a circle and a closed surface.<ref>Shi Cheng Wang, and Ying Qing Wu, ''Covering invariants and co-Hopficity of 3-manifold groups.''\n[[Proceedings of the London Mathematical Society]] '''68''' (1994), no. 1, pp. 203–224 </ref>\n*If ''G'' is an irreducible lattice in a real [[semi-simple Lie group]] and ''G'' is not a [[virtually free group]] then ''G'' is co-Hopfian.<ref>[[Gopal Prasad]]\n''Discrete subgroups isomorphic to lattices in semisimple Lie groups''.  [[American Journal of Mathematics]] '''98''' (1976), no. 1, 241–261</ref> E.g. this fact applies to the group <math>SL(n,\\mathbb Z)</math> for <math>n\\ge 3</math>.\n*If ''G'' is a one-ended torsion-free [[word-hyperbolic group]] then ''G'' is co-Hopfian, by a result of [[Zlil Sela|Sela]].<ref>[[Zlil Sela]], \n''Structure and rigidity in (Gromov) hyperbolic groups and discrete groups in rank 1 Lie groups. II.''\n[[Geometric and Functional Analysis]] '''7''' (1997), no. 3, pp. 561–593 </ref>\n*If ''G'' is the fundamental group of a complete finite volume smooth Riemannian ''n''-manifold (where ''n'' > 2) of pinched negative curvature then ''G'' is co-Hopfian. <ref>I. Belegradek, \n''On Mostow rigidity for variable negative curvature''. [[Topology (journal)|Topology]] '''41''' (2002), no. 2, pp. 341–361 </ref>\n*The [[mapping class group]] of a closed hyperbolic surface is co-Hopfian.<ref>Nikolai Ivanov and John McCarthy, ''On injective homomorphisms between Teichmüller modular groups. I.'' [[Inventiones Mathematicae]] '''135''' (1999), no. 2, pp. 425–486 </ref>\n*The group [[Out(Fn)|Out(''F<sub>n</sub>'')]] (where ''n''>2) is co-Hopfian.<ref>[[Benson Farb]] and Michael Handel,\n''Commensurations of Out(''F<sub>n</sub>'')'', [[Publications Mathématiques de l'IHÉS]] '''105''' (2007), pp. 1–48</ref>\n*Delzant and Polyagailo gave a characterization of co-Hopficity for geometrically finite [[Kleinian group]]s of isometries of <math>\\mathbb H^n</math> without 2-torsion.<ref>Thomas Delzant and Leonid Potyagailo, ''Endomorphisms of Kleinian groups''. [[Geometric and Functional Analysis]] '''13''' (2003), no. 2, pp. 396–436 </ref>\n*A [[right-angled Artin group]] <math>A(\\Gamma)</math> (where <math>\\Gamma</math> is a finite nonempty graph) is not co-Hopfian; sending every standard generator of <math>A(\\Gamma)</math> to a power <math>>1</math> defines and endomorphism  of <math>A(\\Gamma)</math>  which is injective but not surjective.<ref>Montserrat Casals-Ruiz, ''Embeddability and quasi-isometric classification of partially commutative groups''.  [[Algebraic and Geometric Topology]] '''16''' (2016), no. 1, 597–620</ref>\n*A finitely generated torsion-free [[nilpotent group]] ''G'' may be either co-Hopfian or not co-Hopfian, depending on the properties of its associated rational [[Lie algebra]].<ref name=B> Igor Belegradek, ''On co-Hopfian nilpotent groups''. [[Bulletin of the London Mathematical Society]] '''35''' (2003), no. 6, pp. 805–811</ref><ref name=COR> Yves Cornulier, ''Gradings on Lie algebras, systolic growth, and cohopfian properties of nilpotent groups''. [[Bulletin de la Société Mathématique de France]] '''144''' (2016), no. 4, pp. 693–744  </ref>\n*If ''G'' is a [[relatively hyperbolic group]] and <math>\\varphi:G\\to G</math> is an injective but non-surjective endomorphism of ''G'' then either <math>\\varphi^k(G)</math> is parabolic for some ''k'' >1 or ''G'' splits over a virtually cyclic or a parabolic subgroup.<ref>[[Cornelia Druţu]] and [[Mark Sapir]], ''Groups acting on tree-graded spaces and splittings of relatively hyperbolic groups''.  [[Advances in Mathematics]] '''217''' (2008), no. 3, pp. 1313–1367 </ref>  \n*[[Grigorchuk group]] ''G'' of intermediate growth is not co-Hopfian.<ref>Igor Lysënok, ''A set of defining relations for the Grigorchuk group.'' {{icon ru}}\n[[Matematicheskie Zametki]] '''38''' (1985), no. 4, 503–516 </ref>\n*[[Thompson groups|Thomposon group]] ''F'' is not co-Hopfian.<ref>Bronlyn Wassink, ''Subgroups of R. Thompson's group F that are isomorphic to F.'' Groups, Complexity, Cryptology '''3''' (2011), no. 2, 239–256 </ref>\n*There exists a [[finitely generated group]] ''G'' which is not co-Hopfian but has [[Kazhdan's property (T)]].<ref>Yann Ollivier, and [[Daniel Wise (mathematician)|Daniel Wise]], ''Kazhdan groups with infinite outer automorphism group''. [[Transactions of the American Mathematical Society]] '''359''' (2007), no. 5, pp. 1959–1976 </ref>\n*If ''G'' is Higman's [[Higman's embedding theorem|universal finitely presented group]] then ''G'' is not co-Hopfian, and ''G'' cannot be embedded in a finitely generated recursively presented co-Hopfian group.<ref>Charles F. Miller, and [[Paul Schupp]], ''Embeddings into Hopfian groups''.  [[Journal of Algebra]] '''17''' (1971), pp. 171–176 </ref>\n\n==Generalizations and related notions==\n\n*A group ''G'' is called '''finitely co-Hopfian'''<ref>[[Martin Bridson]], Daniel Groves, Jonathan Hillman, [[Gaven Martin]], ''Cofinitely Hopfian groups, open mappings and kno complements.'' [[Groups, Geometry, and Dynamics]] '''4''' (2010), no. 4, pp. 693–707</ref> if whenever <math>\\varphi:G\\to G</math> is an injective endomorphism whose image has finite index in ''G'' then <math>\\varphi(G)=G</math>. For example, for <math>n\\ge 2</math> the [[free group]] <math>F_n</math> is not co-Hopfian but it is finitely co-Hopfian.\n*A finitely generated group ''G'' is called '''scale-invariant''' if there exists a nested sequence of subgroups of finite index of ''G'', each isomorphic to ''G'', and whose intersection is a finite group.<ref name=NP> Volodymyr Nekrashevych, and Gábor Pete, ''Scale-invariant groups''. [[Groups, Geometry, and Dynamics]] '''5''' (2011), no. 1, pp. 139–167</ref> \n*A group ''G'' is called '''dis-cohopfian'''<ref name=COR/> if there exists an injective endomorphism <math>\\varphi:G\\to G</math> such that <math>\\bigcap_{n=1}^\\infty \\varphi^n(G)=\\{1\\}</math>. \n*In [[coarse geometry]], a metric space ''X'' is called '''quasi-isometrically co-Hopf''' if every [[quasi-isometry|quasi-isometric embedding]] <math>f:X\\to X</math> is coarsely surjective (that is, is a quasi-isometry). Similarly, ''X'' is called '''coarsely co-Hopf''' if every [[coarse embedding]] <math>f:X\\to X</math> is coarsely surjective. <ref>Ilya Kapovich, and Anton Lukyanenko, [http://www.ams.org/journals/ecgd/2012-16-14/S1088-4173-2012-00246-9/S1088-4173-2012-00246-9.pdf ''Quasi-isometric co-Hopficity of non-uniform lattices in rank-one semi-simple Lie groups.'']  Conformal Geometry and Dynamics '''16''' (2012), pp. 269–282 </ref>\n*In [[metric geometry]], a metric space ''K'' is called '''quasisymmetrically co-Hopf''' if every [[quasisymmetric map|quasisymmetric embedding]] <math>K\\to K</math> is onto. <ref> Sergei Merenkov, ''A Sierpiński carpet with the co-Hopfian property''. [[Inventiones Mathematicae]] '''180''' (2010), no. 2, pp. 361–388</ref>\n\n==See also==\n*[[Hopfian object]]\n\n==References==\n{{Reflist}}\n\n==Further reading==\n* K. Varadarajan,  [http://mat.uab.cat/pubmat/fitxers/download/FileType:pdf/FolderName:v36(1)/FileName:36192_21.pdf Hopfian and co-Hopfian Objects], Publicacions Matemàtiques  '''36''' (1992), no. 1, pp. 293–317\n\n[[Category:Group theory]] [[Category:Algebra]]"
    },
    {
      "title": "Coefficient",
      "url": "https://en.wikipedia.org/wiki/Coefficient",
      "text": "{{short description|Multiplicative factor in a mathematical expression}}\n{{Other uses}}\n{{Multiple issues|\n{{no footnotes|date=May 2017}}\n{{refimprove|date=May 2017}}\n}}\nIn [[mathematics]], a '''coefficient''' is a multiplicative factor in some [[term (mathematics)|term]] of a [[polynomial]], a [[series (mathematics)|series]], or any [[expression (mathematics)|expression]]; it is usually a number, but may be any expression. In the latter case, the [[variable (mathematics)|variables]] appearing in the coefficients are often called [[parameter]]s, and must be clearly distinguished from the other variables. \n\nFor example, in\n:<math>7x^2-3xy+1.5+y,</math>\nthe first two terms respectively have the coefficients 7 and −3. The third term 1.5 is a constant coefficient. The final term does not have any explicitly written coefficient, but is considered to have coefficient 1, since multiplying by that factor would not change the term. \n\nOften coefficients are numbers as in this example, although they could be parameters of the problem or any expression in these parameters. In such a case one must clearly distinguish between symbols representing variables and symbols representing parameters. Following [[René Descartes]], the variables are often denoted by {{mvar|x}}, {{mvar|y}}, ..., and the parameters by {{mvar|a}}, {{mvar|b}}, {{mvar|c}}, ..., but it is not always the case. For example, if {{mvar|y}} is considered as a parameter in the above expression, the coefficient of {{mvar|x}} is {{math|−3''y''}}, and the constant coefficient is {{math|1.5 + ''y''}}.\n\nWhen one writes \n:<math>ax^2+bx+c,</math>\nit is generally supposed that {{mvar|x}} is the only variable and that {{mvar|a}}, {{mvar|b}} and {{mvar|c}} are parameters; thus the constant coefficient is {{mvar|c}} in this case.\n\nSimilarly, any [[polynomial]] in one variable {{mvar|x}} can be written as\n:<math>a_k x^k + \\dotsb + a_1 x^1 + a_0</math>\nfor some positive integer <math>k</math>, where <math>a_k, \\dotsc, a_1, a_0</math> are coefficients; to allow this kind of expression in all cases one must allow introducing terms with 0 as coefficient.\nFor the largest <math>i</math> with <math>a_i \\ne 0</math> (if any), <math>a_i</math> is called the '''leading coefficient''' of the polynomial. So for example the leading coefficient of the polynomial\n\n:<math>\\, 4x^5 + x^3 + 2x^2</math>\n\nis 4.\n\nSome specific coefficients that occur frequently in mathematics have received a name. This is the case of the [[binomial coefficient]]s, the coefficients which occur in the expanded form of <math>(x+y)^n</math>, and are tabulated in [[Pascal's triangle]].\n\n==Linear algebra==\nIn [[linear algebra]], the '''leading coefficient''' (also '''leading entry''') of a row in a matrix is the first nonzero entry in that row. So, for example, given\n\n:<math>\nM = \\begin{pmatrix}\n1 & 2 & 0 & 6\\\\\n0 & 2 & 9 & 4\\\\\n0 & 0 & 0 & 4\\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}.\n</math>\n\nThe leading coefficient of the first row is 1; 2 is the leading coefficient of the second row; 4 is the leading coefficient of the third row, and the last row does not have a leading coefficient.\n\nThough coefficients are frequently viewed as [[constant (mathematics)|constants]] in elementary algebra, they can be variables more generally. For example, the [[coordinates]] <math>(x_1, x_2, \\dotsc, x_n)</math> of a [[vector (geometric)|vector]] <math>v</math> in a [[vector space]] with [[basis (linear algebra)|basis]] <math>\\lbrace e_1, e_2, \\dotsc, e_n \\rbrace </math>, are the coefficients of the basis vectors in the expression \n:<math> v = x_1 e_1 + x_2 e_2 + \\dotsb + x_n e_n .</math>\n\n==See also==\n*[[Degree of a polynomial]]\n*[[Monic polynomial]]\n\n==References==\n\n*Sabah Al-hadad and C.H. Scott (1979) ''College Algebra with Applications'', page 42, Winthrop Publishers, Cambridge Massachusetts {{ISBN|0-87626-140-3}} .\n*Gordon Fuller, Walter L Wilson, Henry C Miller, (1982) ''College Algebra'', 5th edition, page 24, Brooks/Cole Publishing, Monterey California {{ISBN|0-534-01138-1}} .\n* Steven Schwartzman (1994) ''The Words of Mathematics: an etymological dictionary of mathematical terms used in English'', page 48, [[Mathematics Association of America]], {{ISBN|0-88385-511-9}}.\n\n[[Category:Polynomials]]\n[[Category:Mathematical terminology]]\n[[Category:Algebra]]\n[[Category:Numbers]]\n[[Category:Variables (mathematics)]]"
    },
    {
      "title": "Coherent algebra",
      "url": "https://en.wikipedia.org/wiki/Coherent_algebra",
      "text": "{{refimprove|date=September 2017}}\nA '''coherent algebra''' is an [[Algebra over a field|algebra]] of complex square matrices that is closed under [[Matrix multiplication|ordinary matrix multiplication]], [[Hadamard product (matrices)|Schur product]], [[Matrix transpose|transposition]], and contains both the [[identity matrix]] <math>I</math> and the all-ones matrix <math>J</math>.<ref name=\":0\">{{Cite web|url=http://www.math.uwaterloo.ca/~cgodsil/pdfs/assoc2.pdf|title=Association Schemes|last=Godsil|first=Chris|date=2010|website=|archive-url=|archive-date=|dead-url=}}</ref>\n\n== Definitions ==\nA subspace <math>\\mathcal{A}</math> of <math>\\mathrm{Mat}_{n \\times n}(\\mathbb{C})</math> is said to be a coherent algebra of order <math>n</math> if:\n* <math>I, J \\in \\mathcal{A}</math>.\n* <math>M^{T} \\in \\mathcal{A}</math> for all <math>M \\in \\mathcal{A}</math>.\n* <math>MN \\in \\mathcal{A}</math> and <math>M \\circ N \\in \\mathcal{A}</math> for all <math>M, N \\in \\mathcal{A}</math>.\nA coherent algebra <math>\\mathcal{A} </math> is said to be:\n* ''Homogeneous'' if every matrix in <math>\\mathcal{A} </math> has a constant diagonal.\n* ''Commutative'' if <math>\\mathcal{A} </math> is commutative with respect to ordinary matrix multiplication.\n* ''Symmetric'' if every matrix in <math>\\mathcal{A} </math> is symmetric.\nThe set <math>\\Gamma(\\mathcal{A})</math> of ''Schur-primitive matrices'' in a coherent algebra <math>\\mathcal{A}</math> is defined as <math>\\Gamma(\\mathcal{A}) := \\{ M \\in \\mathcal{A} : M \\circ M = M, M \\circ N \\in \\operatorname{span} \\{ M \\} \\text{ for all } N \\in \\mathcal{A} \\} </math>.\n\nDually, the set <math>\\Lambda(\\mathcal{A})</math> of ''primitive matrices'' in a coherent algebra <math>\\mathcal{A}</math> is defined as <math>\\Lambda(\\mathcal{A}) := \\{ M \\in \\mathcal{A} : M^{2} = M, MN \\in \\operatorname{span} \\{ M \\} \\text{ for all } N \\in \\mathcal{A} \\} </math>.\n\n== Examples ==\n* The [[Centralizer and normalizer|centralizer]] of a group of permutation matrices is a coherent algebra, i.e. <math>\\mathcal{W}</math> is a coherent algebra of order <math>n</math> if <math>\\mathcal{W} := \\{ M \\in \\mathrm{Mat}_{n \\times n}(\\mathbb{C}) : MP = PM \\text { for all } P \\in S \\}</math> for a group <math>S</math> of <math>n \\times n</math> permutation matrices.  Additionally, the centralizer of the [[Group (mathematics)|group]] of permutation matrices representing the [[Graph automorphism|automorphism group]] of a graph <math>G</math> is homogeneous if and only if <math>G</math> is [[vertex-transitive]].<ref>{{Cite journal|last=Godsil|first=Chris|date=2011-01-26|title=Periodic Graphs|url=http://www.combinatorics.org/ojs/index.php/eljc/article/view/v18i1p23|journal=The Electronic Journal of Combinatorics|volume=18|issue=1|pages=P23|issn=1077-8926}}</ref>\n* The span of the set of matrices relating pairs of elements lying in the same orbit of a diagonal action of a finite group on a finite set is a coherent algebra,   i.e. <math>\\mathcal{W} := \\operatorname{span} \\{ A(u,v) : u,v \\in V \\}</math> where <math>A(u,v) \\in \\operatorname{Mat}_{V \\times V}(\\mathbb{C})</math> is defined as <math>(A(u,v))_{x, y} := \\begin{cases} 1 \\ \\text{if } (x, y) = (u^{g}, v^{g}) \\text { for some } g \\in G \\\\ 0 \\text{ otherwise } \\end{cases}</math>for all <math>u, v \\in V</math> of a finite set <math>V</math> acted on by a finite group <math>G</math>.\n* The span of a [[regular representation]] of a finite group as a group of permutation matrices over <math>\\mathbb{C}</math> is a coherent algebra.\n\n== Properties ==\n* The [[Intersection (set theory)|intersection]] of a set of coherent algebras of order <math>n</math> is a coherent algebra.\n* The [[Kronecker product|tensor product]] of coherent algebras is a coherent algebra, i.e. <math>\\mathcal{A} \\otimes \\mathcal{B} := \\{ M \\otimes N : M \\in \\mathcal{A} \\text{ and } N \\in \\mathcal{B} \\}</math> if <math>\\mathcal{A} \\in \\operatorname{Mat}_{m \\times m}(\\mathbb{C})</math> and <math>\\mathcal{B} \\in \\mathrm{Mat}_{n \\times n}(\\mathbb{C})</math> are coherent algebras.\n* The ''symmetrization'' <math>\\widehat{\\mathcal{A}} := \\operatorname{span} \\{ M + M^{T} : M \\in \\mathcal{A} \\}</math> of a commutative coherent algebra <math>\\mathcal{A}</math> is a coherent algebra.\n* If <math>\\mathcal{A}</math> is a coherent algebra, then <math>M^{T} \\in \\Gamma(\\mathcal{A})</math> for all <math>M \\in \\mathcal{A}</math>, <math>\\mathcal{A} = \\operatorname{span} \\left ( \\Gamma(\\mathcal{A} \\right ))</math>, and <math>I \\in \\Gamma(\\mathcal{A})</math> if <math>\\mathcal{A}</math> is homogeneous.\n* Dually, if <math>\\mathcal{A}</math> is a commutative coherent algebra (of order <math>n</math>), then <math>E^{T}, E^{*} \\in \\Lambda(\\mathcal{A})</math> for all <math>E \\in \\mathcal{A}</math>, <math>\\frac{1}{n} J \\in \\Lambda(\\mathcal{A})</math>, and <math>\\mathcal{A} = \\operatorname{span} \\left ( \\Lambda(\\mathcal{A} \\right ))</math> as well.\n* Every symmetric coherent algebra is commutative, and every commutative coherent algebra is homogeneous.\n* A coherent algebra is commutative if and only if it is the [[Bose–Mesner algebra]] of a (commutative) [[association scheme]].<ref name=\":0\" />\n* A coherent algebra forms a [[principal ideal ring]] under Schur product; moreover, a commutative coherent algebra forms a principal ideal ring under ordinary matrix multiplication as well. \n\n== See also ==\n* [[Association scheme]]\n* [[Bose–Mesner algebra]]\n\n== References ==\n<references />\n\n[[Category:Algebra]]\n[[Category:Algebraic combinatorics]]"
    },
    {
      "title": "Comeasuring",
      "url": "https://en.wikipedia.org/wiki/Comeasuring",
      "text": "{{Multiple issues|\n{{Expert-subject|mathematics|date=September 2011}}\n{{orphan|date=September 2011}}\n{{context|date=September 2011}}\n}}\n\nLet ''A'' be an [[Algebra over a field|algebra]]. A '''comeasuring''' of ''A'' is a pair (''B'',&nbsp;''β'') where:\n# ''B'' is an algebra.\n# ''β: A → A ⊗ B'' is an [[algebra map]].\n\n== References ==\n* {{Citation| last=Majid| first=Shahn| authorlink=Shahn Majid | year=2002| title=A quantum groups primer | url=https://books.google.com/books?id=o9D8S-vZdbUC| series=London Mathematical Society Lecture Note Series | publisher=Cambridge Univ. Press| isbn = 978-0-521-01041-2|edition=1.}}.\n\n[[Category:Algebra]]\n{{Math-stub}}"
    },
    {
      "title": "Congruence relation",
      "url": "https://en.wikipedia.org/wiki/Congruence_relation",
      "text": "{{no footnotes|date=February 2015}}\n{{For|the term as used in elementary geometry|congruence (geometry)}}\n\nIn [[abstract algebra]], a '''congruence relation''' (or simply '''congruence''') is an [[equivalence relation]] on an [[algebraic structure]] (such as a [[group (mathematics)|group]], [[ring (mathematics)|ring]], or [[vector space]]) that is compatible with the structure in the sense that algebraic operations done with equivalent elements will yield equivalent elements.<ref>Hungerford,  Thomas W.. ''Algebra''. Springer-Verlag, 1974, p. 27</ref>  Every congruence relation has a corresponding [[quotient]] structure, whose elements are the [[equivalence class]]es (or '''congruence classes''') for the relation.<ref>Hungerford, 1974, p. 26</ref>\n\n==Basic example==\n{{About|the ''(mod n)'' notation|the binary ''mod'' operation|modulo operation|section=yes}}\n\nThe prototypical example of a congruence relation is [[Modular arithmetic#Congruence relation|congruence modulo <math>n</math>]] on the set of [[integer]]s.  For a given [[positive integer]] <math>n</math>, two integers <math>a</math> and <math>b</math> are called '''congruent modulo <math>n</math>''', written\n: <math>a \\equiv b \\pmod{n}</math>\nif <math>a - b</math> is [[divisible]] by <math>n</math> (or equivalently if <math>a</math> and <math>b</math> have the same [[remainder]] when divided by <math>n</math>).\n\nfor example, <math>37</math> and <math>57</math> are congruent modulo <math>10</math>,\n\n: <math>37 \\equiv 57 \\pmod{10}</math>\n\nsince <math>37 - 57 = -20</math> is a multiple of 10, or equivalently since both <math>37</math> and <math>57</math> have a remainder of <math>7</math> when divided by <math>10</math>.\n\nCongruence modulo <math>n</math> (for a fixed <math>n</math>) is compatible with both [[addition]] and [[multiplication]] on the integers.  That is,\n\nif\n\n: <math>a_1 \\equiv a_2 \\pmod{n} </math> and <math> b_1 \\equiv b_2 \\pmod{n}</math>\n\nthen\n\n: <math>a_1 + b_1 \\equiv a_2 + b_2 \\pmod{n} </math>  and  <math> a_1 b_1 \\equiv a_2b_2 \\pmod{n}</math>\n\nThe corresponding addition and multiplication of equivalence classes is known as [[modular arithmetic]].  From the point of view of abstract algebra, congruence modulo <math>n</math> is a congruence relation on the [[ring (mathematics)|ring]] of integers, and arithmetic modulo <math>n</math> occurs on the corresponding [[quotient ring]].\n\n==Definition==\nThe definition of a congruence depends on the type of [[algebraic structure]] under consideration.  Particular definitions of congruence can be made for [[group (mathematics)|groups]], [[ring (mathematics)|rings]], [[vector space]]s, [[module (mathematics)|modules]], [[semigroup]]s, [[lattice (order)|lattices]], and so forth.  The common theme is that a congruence is an [[equivalence relation]] on an algebraic object that is compatible with the algebraic structure, in the sense that the [[Operation (mathematics)|operations]] are [[well-defined]] on the [[equivalence classes]].\n\nFor example, a group is an algebraic object consisting of a [[set (mathematics)|set]] together with a single [[binary operation]], satisfying certain axioms.  If <math>G</math> is a group with operation <math>\\ast</math>, a '''congruence relation''' on <math>G</math> is an equivalence relation &equiv; on the elements of <math>G</math> satisfying\n:<math>g_1 \\equiv g_2 \\text{ and } h_1 \\equiv h_2 \\implies g_1 \\ast h_1 \\equiv g_2 \\ast h_2</math> \nfor all <math>g_1</math>, <math>g_2</math>, <math>h_1</math>, <math>h_2 \\in G</math>. For a congruence on a group, the equivalence class containing the [[identity element]] is always a [[normal subgroup]], and the other equivalence classes are the [[coset]]s of this subgroup.  Together, these equivalence classes are the elements of a [[quotient group]].\n\nWhen an algebraic structure includes more than one operation, congruence relations are required to be compatible with each operation.  For example, a ring possesses both addition and multiplication, and a congruence relation on a ring must satisfy\n:<math>r_1 + s_1 \\equiv r_2 + s_2 \\text{ and } r_1 s_1 \\equiv r_2 s_2</math>\nwhenever <math>r_1 \\equiv r_2 \\text{ and } s_1 \\equiv s_2</math>. For a congruence on a ring, the equivalence class containing 0 is always a two-sided [[Ideal (ring theory)|ideal]], and the two operations on the set of equivalence classes define the corresponding quotient ring.\n\nThe general notion of a congruence relation can be given a formal definition in the context of [[universal algebra]], a field which studies ideas common to all [[algebraic structures]].  In this setting, a congruence relation is an equivalence relation &equiv; on an algebraic structure that satisfies\n:<math>\\mu \\left( a_1\\text{, } a_2\\text{, }\\ldots{}\\text{, } a_n \\right) \\equiv \\mu \\left( a_1'\\text{, } a_2'\\text{, }\\ldots{}\\text{, } a_n' \\right)</math>\nfor every ''n''-ary operation ''&mu;'', and all elements <math>a_1\\text{, } \\ldots{}\\text{, } a_n\\text{, } a_1'\\text{, } \\ldots{}\\text{, } a_n' </math> such that <math>a_i \\equiv a_i' </math> for each <math> i </math>.\n\n==Relation with homomorphisms==\nIf <math>f:A\\, \\rightarrow B</math> is a [[homomorphism]] between two algebraic structures (such as [[group homomorphism|homomorphism of groups]], or a [[linear map]] between [[vector space]]s), then the relation <math>R</math> defined by\n\n:<math>a_1\\, R\\, a_2</math> if and only if <math>f \\left(a_1\\right) = f\\left(a_2\\right)</math> \n\nis a congruence relation.  By the [[first isomorphism theorem]], the [[image (mathematics)|image]] of ''A'' under <math>f</math> is a substructure of ''B'' [[Isomorphism|isomorphic]] to the quotient of ''A'' by this congruence.\n\n==Congruences of groups, and normal subgroups and ideals==\nIn the particular case of [[group (mathematics)|groups]], congruence relations can be described in elementary terms as follows:\nIf ''G'' is a group (with [[identity element]] ''e'' and operation *) and ~ is a [[binary relation]] on ''G'', then ~ is a congruence whenever:\n#[[Given any]] element ''a'' of ''G'', ''a'' ~ ''a'' ('''[[Reflexive relation|reflexivity]]''');\n#Given any elements ''a'' and ''b'' of ''G'', [[material conditional|if]] ''a'' ~ ''b'', then ''b'' ~ ''a'' ('''[[Symmetric relation|symmetry]]''');\n#Given any elements ''a'', ''b'', and ''c'' of ''G'', if ''a'' ~ ''b'' [[logical conjunction|and]] ''b'' ~ ''c'', then ''a'' ~ ''c'' ('''[[Transitive relation|transitivity]]''');\n#Given any elements ''a'', ''a' '', ''b'', and ''b' '' of ''G'', if ''a'' ~ ''a' '' and ''b'' ~ ''b' '', then ''a'' * ''b'' ~ ''a' '' * ''b' '';\n#Given any elements ''a'' and ''a' '' of ''G'', if ''a'' ~ ''a' '', then ''a''<sup>&minus;1</sup> ~ ''a' ''<sup>&minus;1</sup> (this can actually be proven from the other four, so is strictly redundant).\n\nConditions 1, 2, and 3 say that ~ is an [[equivalence relation]].\n\nA congruence ~ is determined entirely by the set {''a'' ∈ ''G'' : ''a'' ~ ''e''} of those elements of ''G'' that are congruent to the identity element, and this set is a [[normal subgroup]].\nSpecifically, ''a'' ~ ''b'' if and only if ''b''<sup>&minus;1</sup> * ''a'' ~ ''e''.\nSo instead of talking about congruences on groups, people usually speak in terms of normal subgroups of them; in fact, every congruence corresponds uniquely to some normal subgroup of ''G''.\n\n=== Ideals of rings and the general case ===\n\nA similar trick allows one to speak of kernels in [[ring (mathematics)|ring theory]] as [[ideal (ring theory)|ideals]] instead of congruence relations, and in [[module (mathematics)|module theory]] as [[submodule]]s instead of congruence relations.\n\nA more general situation where this trick is possible is with [[Omega-group]]s (in the general sense allowing operators with multiple arity). But this cannot be done with, for example, [[monoid]]s, so the study of congruence relations plays a more central role in monoid theory.\n\n==Universal algebra==\n\nThe idea is generalized in [[universal algebra]]:\nA congruence relation on an algebra ''A'' is a [[subset]] of the [[direct product]] ''A'' &times; ''A'' that is both an [[equivalence relation]] on ''A'' and a [[subalgebra]] of ''A'' &times; ''A''.\n\nThe [[kernel (universal algebra)|kernel]] of a [[homomorphism]] is always a congruence. Indeed, every congruence arises as a kernel.\nFor a given congruence ~ on ''A'', the set ''A''/~ of [[equivalence class]]es can be given the structure of an algebra in a natural fashion, the [[quotient (universal algebra)|quotient algebra]].\nThe function that maps every element of ''A'' to its equivalence class is a homomorphism, and the kernel of this homomorphism is ~.\n\nThe [[lattice (order)|lattice]] '''Con'''(''A'') of all congruence relations on an algebra ''A'' is [[algebraic lattice|algebraic]].\n\n[[John M. Howie]] described how [[semigroup]] theory illustrates congruence relations in universal algebra:\n:In a group a congruence is determined if we know a single congruence class, in particular if we know the normal subgroup which is the class containing the identity. Similarly, in a ring a congruence is determined if we know the ideal which is the congruence class containing the zero. In semigroups there is no such fortunate occurrence, and we are therefore faced with the necessity of studying congruences as such. More than anything else, it is this necessity that gives semigroup theory its characteristic flavour. Semigroups are in fact the first and simplest type of algebra to which the methods of universal algebra must be applied…<ref>J. M. Howie (1975) ''An Introduction to Semigroup Theory'', page v, [[Academic Press]]</ref>\n\n==See also==\n*[[Table of congruences]]\n*[[Linear congruence theorem]]\n*[[Congruence lattice problem]]\n\n==Notes==\n{{reflist}}\n\n==References==\n* Horn and Johnson, ''Matrix Analysis,'' Cambridge University Press, 1985. {{ISBN|0-521-38632-2}}. (Section 4.5 discusses congruency of matrices.)\n\n{{DEFAULTSORT:Congruence Relation}}\n[[Category:Modular arithmetic]]\n[[Category:Algebra]]\n[[Category:Binary relations]]\n[[Category:Equivalence (mathematics)]]"
    },
    {
      "title": "Conjugate (square roots)",
      "url": "https://en.wikipedia.org/wiki/Conjugate_%28square_roots%29",
      "text": "{{About|conjugation by changing the sign of a square root|other uses|Conjugate (disambiguation)}}\nIn [[mathematics]], the '''conjugate''' of an expression of the form <math>a+b\\sqrt d</math> is <math>a-b\\sqrt d,</math> provided that <math>\\sqrt d</math> does not appear in {{mvar|a}} and {{mvar|b}}. One says also that the two expressions are conjugate. In particular, the conjugate of a root of a [[quadratic polynomial]] is the other root, obtained by changing the sign of the [[square root]] appearing in the [[quadratic formula]].\n\n[[Complex conjugation]] is the special case where the square root is <math>i=\\sqrt{-1}.</math>\n\nAs\n:<math>(a+b\\sqrt d)(a-b\\sqrt d)= a^2-db^2,</math>\nand\n::<math>(a+b\\sqrt d) + (a-b\\sqrt d)= 2a,</math>\nthe sum and the product of conjugate expressions do not involve the square root anymore.\n\nThis property is used for removing a square root from a [[denominator]], by multiplying the [[numerator]] and the denominator of a [[fraction (mathematics)|fraction]] by the conjugate of the denominator (see [[rationalisation (mathematics)|rationalisation]]). Typically, one has\n:<math>\\frac{a_1+b_1\\sqrt d}{a_2+b_2\\sqrt d} = \\frac{(a_1+b_1\\sqrt d)(a_2-b_2\\sqrt d)}{(a_2+b_2\\sqrt d)(a_2-b_2\\sqrt d)} \n= \\frac{a_1a_2-db_1b_2+(a_2b_1-a_1b_2)\\sqrt d}{a_2^2-db_2^2}.</math>\nIn particular\n:<math>\\frac{1}{a+b\\sqrt d} = \\frac{a-b\\sqrt d}{a^2-db^2}.</math>\n\n== See also ==\n* [[Conjugate element (field theory)]], the generalization to the roots of a polynomial of any degree\n\n\n[[Category:Algebra]]\n{{algebra-stub}}"
    },
    {
      "title": "Conservation form",
      "url": "https://en.wikipedia.org/wiki/Conservation_form",
      "text": "'''Conservation form''' or ''Eulerian form'' refers to an arrangement of an [[equation]] or [[system of equations]], usually representing a [[hyperbolic system]], that emphasizes that a property represented is conserved, i.e. a type of [[continuity equation]]. The term is usually used in the context of [[continuum mechanics]].\n\n== General form ==\nEquations in conservation form take the form\n:<math>\\frac{d \\xi}{d t} + \\nabla \\cdot f(\\xi) = 0</math>\nfor any conserved quantity <math>\\xi</math>, with a suitable function <math>f</math>. An equation of this form can be transformed into an [[integral equation]]\n:<math>\\frac d{d t} \\int_V \\xi dV = \\int_{\\partial V} f(\\xi) \\cdot \\nu ~ dS</math>\nusing the [[divergence theorem]]. The integral equation states that the change rate of the integral of the quantity <math>\\xi</math> over an arbitrary control volume <math>V</math> is given by the [[flux]] <math>f(\\xi)</math> through the boundary of the control volume, with <math>\\nu</math> being the [[surface normal]] through the boundary. <math>\\xi</math> is neither produced nor consumed inside of <math>V</math> and is hence conserved. A typical choice for <math>f</math> is <math>f(\\xi) = \\xi \\mathbf u</math>, with velocity <math>\\mathbf u</math>, meaning that the quantity <math>\\xi</math> flows with a given velocity field.\n\nThe integral form of such equations is usually the physically more natural formulation, and the differential equation arises from differentiation. Since the integral equation can also have non-differentiable solutions, the equality of both formulations can break down in some cases, leading to [[weak solution]]s and severe numerical difficulties in simulations of such equations.\n\n== Example ==\nAn example of a set of equations written in conservation form are the [[Euler equations (fluid dynamics)|Euler equations]] of fluid flow:\n\n:<math>\n{\\partial\\rho\\over\\partial t}+\n\\nabla\\cdot(\\rho\\mathbf u)=0\n</math>\n:<math>\n{\\partial\\rho{\\mathbf u}\\over\\partial t}+\n\\nabla\\cdot(\\rho \\mathbf u \\otimes \\mathbf u + p \\mathbf I)=0\n</math>\n:<math>\n{\\partial E\\over\\partial t}+\n\\nabla\\cdot(\\mathbf u(E+pV))=0</math>\n\nEach of these represents the [[conservation of mass]], [[conservation of momentum|momentum]] and [[conservation of energy|energy]], respectively.\n\n==See also==\n* [[Conservation law]]\n* [[Lagrangian and Eulerian specification of the flow field]]\n\n== Further reading ==\n* {{cite book | ref=Toro| first=E.F. | last=Toro | title=Riemann Solvers and Numerical Methods for Fluid Dynamics | publisher=Springer-Verlag | year=1999 | isbn=3-540-65966-8}}\n* Randall J. LeVeque: ''Finite Volume Methods for Hyperbolic Problems.'' Cambridge University Press, Cambridge 2002, {{ISBN|0-521-00924-3}} (''Cambridge Texts in Applied Mathematics'').\n\n[[Category:Algebra]]\n[[Category:Conservation equations]]"
    },
    {
      "title": "Consistent and inconsistent equations",
      "url": "https://en.wikipedia.org/wiki/Consistent_and_inconsistent_equations",
      "text": "{{unreferenced|date=April 2018}}\n\nIn [[mathematics]] and in particular in [[algebra]], a [[linear equation system|linear]] or [[nonlinear equation system|nonlinear]] [[system of equations]] is '''consistent''' if there is at least one set of values for the unknowns that satisfies every equation in the system&mdash;that is, that when substituted into each of the equations makes each equation hold true as an [[identity (mathematics)|identity]]. In contrast, an equation system is '''inconsistent''' if there is no set of values for the unknowns that satisfies all of the equations.\n\nIf a system of equations is inconsistent, then it is possible to manipulate and combine the equations in such a way as to obtain contradictory information, such as 2 = 1, or ''x''<sup>3</sup> + ''y''<sup>3</sup> = 5 ''and'' ''x''<sup>3</sup> + ''y''<sup>3</sup> = 6 (which implies 5 = 6).\n\nBoth types of equation system, consistent and inconsistent, can be any of [[overdetermined system|overdetermined]] (having more equations than unknowns), [[underdetermined system|underdetermined]] (having fewer equations than unknowns), or exactly determined.\n\n==Simple examples==\n\n===Underdetermined and consistent===\nThe system\n:<math>x+y+z=3,</math>\n\n:<math>x+y+2z=4</math>\n\nhas an infinite number of solutions, all of them having ''z'' = 1 (as can be seen by subtracting the first equation from the second), and all of them therefore having ''x+y'' = 2 for any values of ''x'' and ''y''.\n\nThe nonlinear system\n\n:<math>x^2+y^2+z^2=10,</math>\n:<math>x^2+y^2=5</math>\n\nhas an infinitude of solutions, all involving <math>z=\\pm \\sqrt{5}.</math>\n\nSince each of these systems has more than one solution, it is an [[indeterminate system]].\n\n===Underdetermined and inconsistent===\n\nThe system\n\n:<math>x+y+z=3,</math>\n\n:<math>x+y+z=4</math>\n\nhas no solutions, as can be seen by subtracting the first equation from the second to obtain the impossible 0 = 1.\n\nThe nonlinear system\n\n:<math>x^2+y^2+z^2=17,</math>\n:<math>x^2+y^2+z^2=14</math>\n\nhas no solutions, because if one equation is subtracted from the other we obtain the impossible 0 = 3.\n\n===Exactly determined and consistent===\n \nThe system\n \n:<math>x+y=3,</math>\n:<math>x+2y= 5</math>\n \nhas exactly one solution: ''x'' = 1, ''y''= 2.\n \nThe nonlinear system\n \n:<math>x+y=1,</math>\n:<math>x^2+y^2=1</math>\n \nhas the two solutions (''x, y'') = (1, 0) and (''x, y'') = (0, 1), while\n \n:<math>x^3+y^3+z^3=10,</math>\n:<math>x^3+2y^3+z^3=12,</math>\n:<math>3x^3+5y^3+3z^3=34</math>\n \nhas an infinite number of solutions because the third equation is the first equation plus twice the second one and hence contains no independent information; thus any value of ''z'' can be chosen and values of ''x'' and ''y'' can be found to satisfy the first two (and hence the third) equations.\n\n===Exactly determined and inconsistent===\n\nThe system \n\n:<math>x+y=3,</math>\n:<math>4x+4y=10</math>\n\nhas no solutions; the inconsistency can be seen by multiplying the first equation by 4 and subtracting the second equation to obtain the impossible 0 = 2.\n\nLikewise, \n\n:<math>x^3+y^3+z^3=10,</math>\n:<math>x^3+2y^3+z^3=12,</math>\n:<math>3x^3+5y^3+3z^3=32</math>\n\nis an inconsistent system because the first equation plus twice the second minus the third contains the contradiction 0 = 2.\n\n===Overdetermined and consistent===\n\nThe system \n\n:<math>x+y=3,</math>\n:<math>x+ 2y= 7,</math>\n:<math>4x+6y=20</math>\n\nhas a solution, ''x''  = –1, ''y'' = 4, because the first two equations do not contradict each other and the third equation is redundant (since it contains the same information as can be obtained from the first two equations by multiplying each through by 2 and summing them).\n\nThe system\n\n:<math>x+2y=7,</math>\n:<math>3x+6y=21,</math>\n:<math>7x+14y=49</math>\n\nhas an infinitude of solutions since all three equations give the same information as each other (as can be seen by multiplying through the first equation by either 3 or 7). Any value of ''y'' is part of a solution, with the corresponding value of ''x'' being 7–2y.\n\nThe nonlinear system\n\n:<math>x^2-1=0,</math>\n:<math>y^2-1=0,</math>\n:<math>(x-1)(y-1)=0</math>\n\nhas the three solutions (''x, y'') = (1, –1), (–1, 1), and (1, 1).\n\n===Overdetermined and inconsistent===\n\nThe system\n\n:<math>x+y=3,</math>\n:<math>x+ 2y= 7,</math>\n:<math>4x+6y=21</math>\n\nis inconsistent because the last equation contradicts the information embedded in the first two, as seen by multiplying each of the first two through by 2 and summing them.\n\nThe system\n\n:<math>x^2+y^2=1,</math>\n:<math>x^2+2y^2=2,</math>\n:<math>2x^2+3y^2=4</math>\n\nis inconsistent because the sum of the first two equations contradicts the third one.\n\n==Criteria for consistency==\n\nAs can be seen from the above examples, consistency versus inconsistency is a different issue from comparing the numbers of equations and unknowns.\n\n===Linear systems===\n{{Main|Linear equation system#Consistency}}\n\nA linear system is consistent [[if and only if]] its [[coefficient matrix]] has the same [[rank (linear algebra)|rank]] as does its [[augmented matrix]] (the coefficient matrix with an extra column added, that column being the [[column vector]] of constants).\n\n===Nonlinear systems===\n{{Main|System of polynomial equations#What is solving?}}\n\n\n[[Category:Equations]]\n[[Category:Algebra]]"
    },
    {
      "title": "Constant (mathematics)",
      "url": "https://en.wikipedia.org/wiki/Constant_%28mathematics%29",
      "text": "{{refimprove|date=August 2012}}\n{{for|a narrower treatment related to this subject|Mathematical constant}}\nIn [[mathematics]], the adjective '''constant''' means non-varying. The noun '''constant''' may have two different meanings. It may refer to a fixed and well-defined number or other [[mathematical object]]. The term [[mathematical constant]] (and also [[physical constant]]) is sometimes used to distinguish this meaning from the other one.  A '''constant''' may also refer to a [[constant function]] or its [[value (mathematics)|value]] (it is a common usage to identify them). Such a constant is commonly represented by a [[variable (mathematics)|variable]] which does not depend on the main variable(s) of the studied problem. This is the case, for example, for a [[constant of integration]] which is an arbitrary constant function (not depending on the variable of integration) added to a particular [[antiderivative]] to get all the antiderivatives of the given function.\n\nFor example, a general quadratic function is commonly written as:\n\n:<math>a x^2 + b x + c\\, ,</math>\n\nwhere ''a'', ''b'' and ''c'' are constants (or parameters), while ''x'' is the variable, a placeholder for the argument of the function being studied. A more explicit way to denote this function is\n\n:<math>x\\mapsto a x^2 + b x + c \\, ,</math>\n\nwhich makes the function-argument status of ''x'' clear, and thereby implicitly the constant status of ''a'', ''b'' and ''c''. In this example ''a'', ''b'' and ''c'' are [[coefficient]]s of the polynomial. Since ''c'' occurs in a term that does not involve ''x'', it is called the [[Constant term|constant term of the polynomial]] and can be thought of as the coefficient of ''x''<sup>0</sup>; any polynomial term or expression of [[Degree of a polynomial|degree]] zero is a constant.<ref>{{cite book | last = Foerster | first = Paul A. | title = Algebra and Trigonometry: Functions and Applications, Teacher's Edition | edition = Classics | year = 2006 | isbn = 0-13-165711-9 | publisher = [[Prentice Hall]] | location = Upper Saddle River, NJ}}</ref>{{rp|18}}\n\n== Constant function ==\n{{Main|Constant function|Nullary}}\n\nA constant may be used to define a [[constant function]] that ignores its arguments and always gives the same value. A constant function of a single variable, such as <math>f(x)=5</math>, has a [[graph of a function|graph]] that is a horizontal straight line, parallel to the ''x''-axis. Such a function always takes the same value (in this case, 5) because its argument does not appear in the expression defining the function.\n\n== Context-dependence ==\n\nThe context-dependent nature of the concept of \"constant\" can be seen in this example from elementary calculus:\n\n:<math>\\begin{align}\n\\frac{d}{dx} 2^x  & = \\lim_{h\\to 0} \\frac{2^{x+h} - 2^x} h = \\lim_{h\\to 0} 2^x\\frac{2^h - 1} h \\\\[8pt]\n& = 2^x \\lim_{h\\to 0} \\frac{2^h - 1} h & & \\text{since } x \\text{ is constant (i.e. does not depend on } h\\text{)} \\\\[8pt]\n & = 2^x \\cdot\\mathbf{constant,} & & \\text{where }\\mathbf{constant}\\text{ means not depending on } x.\n\\end{align}</math>\n\"Constant\" means not depending on some variable; not changing as that variable changes. In the first case above, it means not depending on&nbsp;''h''; in the second, it means not depending on&nbsp;''x''.\n\n==Notable mathematical constants==\n{{main|Mathematical constant}}\nSome values occur frequently in mathematics and are conventionally denoted by a specific symbol. These standard symbols and their values are called mathematical constants. Examples include:\n* 0 ([[zero]]).\n* 1 ([[one]]), the [[natural number]] after zero.\n* {{pi}} ([[pi]]), the constant representing the [[ratio]] of a circle's circumference to its diameter, approximately equal to 3.141592653589793238462643...<ref>{{cite book | last = Arndt | first = Jörg | last2 = Haenel | first2 = Christoph | title = Pi – Unleashed | page = 240 | year = 2001 | publisher = Springer | isbn = 978-3540665724}}</ref>\n* ''[[e (mathematical constant)|e]]'', approximately equal to 2.718281828459045235360287...\n* ''i'', the [[imaginary unit]] such that ''i''<sup>2</sup> = −1.\n* <math alt=\"Square root of 2\">\\sqrt{2}</math> ([[square root of 2]]), the length of the diagonal of a square with unit sides, approximately equal to 1.414213562373095048801688.\n* ''φ'' ([[golden ratio]]), approximately equal to 1.618033988749894848204586, or algebraically, <math>1+ \\sqrt{5} \\over 2</math>.\n\n==Constants in calculus==\nIn [[calculus]], constants are treated in several different ways depending on the operation. For example, the [[derivative]] of a constant function is zero. This is because the derivative measures the rate of change of a function with respect to a variable, and since constants, by definition, do not change, their derivative is therefore zero. Conversely, when [[Antiderivative|integrating]] a constant function, the constant is multiplied by the variable of integration. During the evaluation of a [[limit (mathematics)|limit]], the constant remains the same as it was before and after evaluation.\n\nIntegration of a function of one variable often involves a [[constant of integration]]. This arises because of the integral operator's nature as the inverse of the [[derivative|differential operator]], meaning the aim of integration is to recover the original function before differentiation. The differential of a constant function is zero, as noted above, and the differential operator is a linear operator, so functions that only differ by a constant term have the same derivative. To acknowledge this, a constant of integration is added to an [[indefinite integral]]; this ensures that all possible solutions are included. The constant of integration is generally written as 'c' and represents a constant with a fixed but undefined value.\n\n===Examples===\nIf {{math|''f''}} is the constant function such that <math>f(x) = 72</math> for every {{math|''x''}} then\n:<math>\\begin{align}\n           f'(x) &= 0 \\\\\n  \\int f(x) \\,dx &= 72x + c\n\\end{align}</math>\n\n==See also==\n*[[Expression (mathematics)|Expression]]\n*[[Physical constant]]\n*[[Constant (disambiguation)]]\n\n==References==\n{{reflist}}\n\n[[Category:Algebra]]\n[[Category:Elementary mathematics]]\n[[Category:Constants| ]]"
    },
    {
      "title": "Cramer's theorem (algebraic curves)",
      "url": "https://en.wikipedia.org/wiki/Cramer%27s_theorem_%28algebraic_curves%29",
      "text": "In [[mathematics]], '''Cramer's theorem on algebraic curves''' gives the [[necessary and sufficient]] number of points in the real [[plane (mathematics)|plane]] falling on an [[algebraic curve]] to uniquely determine the curve in non-degenerate cases. This number is \n\n:<math>\\frac {n(n+3)} 2,</math>\n\nwhere ''n'' is the [[degree of a polynomial|degree]] of the curve. The theorem is due to [[Gabriel Cramer]], who published it in 1750.<ref>* {{google books|HzcVAAAAQAAJ|Introduction à l'analyse des lignes courbes algébriques}}. Geneva: Frères Cramer & Cl. Philibert, 1750.</ref>\n\nFor example, a line (of degree 1) is determined by 2 distinct points on it: one and only one line goes through those two points. Likewise, a [[degenerate conic|non-degenerate conic]] ([[polynomial equation]] in ''x'' and ''y'' with the sum of their powers in any term not exceeding 2, hence with degree&nbsp;2) is uniquely determined by 5 points in [[general position]] (no three of which are on a straight line).\n\nThe intuition of the conic case is this: Suppose the given points fall on, specifically, an [[ellipse]]. Then five pieces of information are necessary and sufficient to identify the ellipse&mdash;the horizontal location of the ellipse's center, the vertical location of the center, the [[major axis]] (the length of the longest [[chord (geometry)|chord]]), the [[minor axis]] (the length of the shortest chord through the center, [[perpendicular]] to the major axis), and the ellipse's [[rotation (mathematics)|rotational orientation]] (the extent to which the major axis departs from the horizontal). Five points in general position suffice to provide these five pieces of information, while four points do not.\n\n==Derivation of the formula==\n\nThe number of distinct terms (including those with a zero coefficient) in an ''n''-th degree equation in two variables is (''n''&nbsp;+&nbsp;1)(''n''&nbsp;+&nbsp;2)&nbsp;/&nbsp;2. This is because the ''n''-th degree terms are <math>x^n, \\, x^{n-1}y^1, \\, \\dots , \\, y^n,</math> numbering ''n''&nbsp;+&nbsp;1 in total; the (''n''&nbsp;−&nbsp;1) degree terms are <math>x^{n-1}, \\, x^{n-2}y^1, \\, \\dots , \\, y^{n-1},</math> numbering ''n'' in total; and so on through the first degree terms <math>x</math> and <math>y,</math> numbering 2 in total, and the single zero degree term (the constant). The sum of these is (''n''&nbsp;+&nbsp;1)&nbsp;+&nbsp;''n''&nbsp;+&nbsp;(''n''&nbsp;–&nbsp;1)&nbsp;+&nbsp;...&nbsp;+&nbsp;2&nbsp;+&nbsp;1 =&nbsp;(''n''&nbsp;+&nbsp;1)(''n''&nbsp;+&nbsp;2)&nbsp;/&nbsp;2 terms, each with its own [[coefficient]]. However, one of these coefficients is redundant in determining the curve, because we can always divide through the polynomial equation by any one of the coefficients, giving an equivalent equation with one coefficient fixed at&nbsp;1, and thus [(''n''&nbsp;+&nbsp;1)(''n''&nbsp;+&nbsp;2)&nbsp;/&nbsp;2]&nbsp;−&nbsp;1 =&nbsp;''n''(''n''&nbsp;+&nbsp;3)&nbsp;/&nbsp;2  remaining coefficients. \n\nFor example, a fourth degree equation has the general form\n\n:<math>x^4+c_1x^3y+c_2x^2y^2+ c_3xy^3+c_4y^4+c_5x^3+c_6x^2y+c_7xy^2+c_8y^3+c_9x^2+c_{10}xy+c_{11}y^2+c_{12}x+c_{13}y+c_{14}=0,</math>\n\nwith 4(4+3)/2 = 14 coefficients.\n\nDetermining an algebraic curve through a set of points consists of determining values for these coefficients in the algebraic equation such that each of the points satisfies the equation. Given ''n''(''n''&nbsp;+&nbsp;3)&nbsp;/&nbsp;2 points (''x''<sub>''i''</sub>, ''y''<sub>''i''</sub>), each of these points can be used to create a separate equation by substituting it into the general polynomial equation of degree ''n'', giving ''n''(''n''&nbsp;+&nbsp;3)&nbsp;/&nbsp;2 equations linear in the ''n''(''n''&nbsp;+&nbsp;3)&nbsp;/&nbsp;2 unknown coefficients. If this system is non-degenerate in the sense of having a non-zero [[determinant (mathematics)|determinant]], the unknown coefficients are uniquely determined and hence the [[polynomial equation]] and its curve are uniquely determined. More than this number of points would be redundant, and fewer would be insufficient to solve the system of equations uniquely for the coefficients.\n\n==Degenerate cases==\n\nAn example of a degenerate case, in which ''n''(''n''&nbsp;+&nbsp;3)&nbsp;/&nbsp;2 points on the curve are not sufficient to determine the curve uniquely, was provided by Cramer as part of [[Cramer's paradox]]. Let the degree be ''n''&nbsp;=&nbsp;3, and let nine points be all combinations of ''x''&nbsp;=&nbsp;–1,&nbsp;0,&nbsp;1 and ''y'' = –1, 0, 1. More than one cubic contains all of these points, namely all cubics of equation <math>a(x^3-x) +b(y^3-y)=0.</math> Thus these points do not determine a unique cubic, even though there are ''n''(''n''&nbsp;+&nbsp;3)&nbsp;/&nbsp;2&nbsp;=&nbsp;9 of them. More generally, there are infinitely many cubics that pass through the nine intersection points of two cubics ([[Bézout's theorem]] implies that two cubics have, in general, nine intersection points)\n\nLikewise, for the conic case of ''n'' = 2, if three of five given points all fall on the same straight line, they may not uniquely determine the curve.\n\n==Restricted cases==\n\nIf the curve is required to be in a particular sub-category of ''n''-th degree polynomial equations, then fewer than ''n''(''n''&nbsp;+&nbsp;3)&nbsp;/&nbsp;2 points may be necessary and sufficient to determine a unique curve. For example, the generic [[circle]] is given by the equation <math>(x-a)^2+(y-b)^2=r^2</math> where the center is located at (''a'', ''b'') and the [[radius]] is ''r''. Equivalently, by expanding the squared terms, the generic equation is <math>x^2-2ax+y^2-2by=k,</math> where <math>k=r^2-a^2-b^2.</math> Two restrictions have been imposed here compared to the general conic case of ''n''&nbsp;=&nbsp;2: the coefficient of the term in ''xy'' is restricted to equal 0, and the coefficient of ''y''<sup>2</sup> is restricted to equal the coefficient of ''x''<sup>2</sup>. Thus instead of five points being needed, only 5&nbsp;–&nbsp;2&nbsp;=&nbsp;3 are needed, coinciding with the 3 parameters ''a'',&nbsp;''b'',&nbsp;''k'' (equivalently ''a'',&nbsp;''b'',&nbsp;''r'') that need to be identified.\n\n==See also==\n\n*[[Five points determine a conic]]\n\n==References==\n{{reflist}}\n\n\n[[Category:Algebra]]\n[[Category:Analytic geometry]]"
    },
    {
      "title": "Cyclic algebra",
      "url": "https://en.wikipedia.org/wiki/Cyclic_algebra",
      "text": "In algebra, a '''cyclic division algebra''' is one of the basic examples of a [[division algebra]] over a field, and plays a key role in the theory of [[central simple algebra]]s.\n\n== Definition ==\nLet ''A'' be a finite-dimensional [[central simple algebra]] over a field ''F''. Then ''A'' is said to be '''cyclic''' if it contains a [[strictly maximal subfield]] ''E'' such that ''E''/''F'' is a [[cyclic field extension]] (i.e., the [[Galois group]] is a [[cyclic group]]).\n\n== See also ==\n* [[Factor system#Cyclic algebras]] - cyclic algebras described by factor systems.\n* [[Brauer group#Cyclic algebras]] - cyclic algebras are representative of Brauer classes.\n\n== References ==\n* {{cite book|last=Pierce|first=Richard S.|title=Associative Algebras|publisher=Springer-Verlag|year=1982|isbn=978-0-387-90693-5|series=[[Graduate Texts in Mathematics]], volume 88|oclc=249353240}}\n* {{cite book|last=Weil|first=André|author-link=André Weil|title=Basic Number Theory|edition=third|publisher=Springer|year=1995|isbn=978-3-540-58655-5|oclc=32381827}}\n\n\n{{algebra-stub}}\n\n\n\n[[Category:Algebra]]"
    },
    {
      "title": "Cyclotomic polynomial",
      "url": "https://en.wikipedia.org/wiki/Cyclotomic_polynomial",
      "text": "In [[mathematics]] the''' ''n''th cyclotomic polynomial''', for any positive [[integer]] ''n'', is the unique [[irreducible polynomial]] with integer coefficients that is a [[divisor]] of <math>x^n-1</math> and is not a divisor of <math>x^k-1</math> for any {{nowrap|''k'' < ''n''.}} Its [[root of a function|roots]] are all ''n''th [[primitive root of unity|primitive roots of unity]] \n<math>\ne^{2i\\pi\\frac{k}{n}}\n</math>, where ''k'' runs over the positive integers not greater than ''n'' and [[coprime integers|coprime]] to ''n''. In other words, the''' ''n''th cyclotomic polynomial''' is equal to\n:<math>\n\\Phi_n(x) =\n\\prod_\\stackrel{1\\le k\\le n}{\\gcd(k,n)=1}\n\\left(x-e^{2i\\pi\\frac{k}{n}}\\right).\n</math>\n\nIt may also be defined as the [[monic polynomial]] with integer coefficients that is the [[minimal polynomial (field theory)|minimal polynomial]] over the [[Field (mathematics)|field]] of the [[rational number]]s of any [[Root of unity#Definition|primitive ''n''th-root of unity]] (<math> e^{2i\\pi/n} </math> is an example of such a root).\n\nAn important relation linking cyclotomic polynomials and primitive roots of unity is\n:<math>\\prod_{d\\mid n}\\Phi_d(x) = x^n - 1,</math>\nshowing that {{math|''x''}} is a root of <math>x^n - 1</math> if and only if it is a ''d''{{space|hair}}th primitive root of unity for some ''d'' that divides ''n''.\n\n==Examples==\n\nIf ''n'' is a [[prime number]], then \n:<math>\\Phi_n(x) = 1+x+x^2+\\cdots+x^{n-1}=\\sum_{k=0}^{n-1} x^k.</math>\nIf ''n'' = 2''p'' where ''p'' is an odd [[prime number]], then\n:<math>\\Phi_{2p}(x) = 1-x+x^2-\\cdots+x^{p-1}=\\sum_{k=0}^{p-1} (-x)^k.</math>\n\nFor ''n'' up to 30, the cyclotomic polynomials are:<ref>{{Cite OEIS|A013595}}</ref>\n\n:<math>\\begin{align}\n\\Phi_1(x) &= x - 1 \\\\\n\\Phi_2(x) &= x + 1 \\\\\n\\Phi_3(x) &= x^2 + x + 1 \\\\\n\\Phi_4(x) &= x^2 + 1 \\\\\n\\Phi_5(x) &= x^4 + x^3 + x^2 + x +1 \\\\\n\\Phi_6(x) &= x^2 - x + 1 \\\\\n\\Phi_7(x) &= x^6 + x^5 + x^4 + x^3 + x^2 + x + 1 \\\\\n\\Phi_8(x) &= x^4 + 1 \\\\\n\\Phi_9(x) &= x^6 + x^3 + 1 \\\\\n\\Phi_{10}(x) &= x^4 - x^3 + x^2 - x + 1 \\\\\n\\Phi_{11}(x) &= x^{10} + x^9 + x^8 + x^7 + x^6 + x^5 + x^4 + x^3 + x^2 + x + 1 \\\\\n\\Phi_{12}(x) &= x^4 - x^2 + 1 \\\\\n\\Phi_{13}(x) &= x^{12} + x^{11} + x^{10} + x^9 + x^8 + x^7 + x^6 + x^5 + x^4 + x^3 + x^2 + x + 1 \\\\\n\\Phi_{14}(x) &= x^6 - x^5 + x^4 - x^3 + x^2 - x + 1 \\\\\n\\Phi_{15}(x) &= x^8 - x^7 + x^5 - x^4 + x^3 - x + 1 \\\\\n\\Phi_{16}(x) &= x^8 + 1 \\\\\n\\Phi_{17}(x) &= x^{16} + x^{15} + x^{14} + x^{13} + x^{12} + x^{11} + x^{10} + x^9 + x^8 + x^7 + x^6 + x^5 + x^4 + x^3 + x^2 + x + 1\\\\\n\\Phi_{18}(x) &= x^6 - x^3 + 1 \\\\\n\\Phi_{19}(x) &= x^{18} + x^{17} + x^{16} + x^{15} + x^{14} + x^{13} + x^{12} + x^{11} + x^{10} + x^9 + x^8 + x^7 + x^6 + x^5 + x^4 + x^3 + x^2 + x + 1\\\\\n\\Phi_{20}(x) &= x^8 - x^6 + x^4 - x^2 + 1 \\\\\n\\Phi_{21}(x) &= x^{12} - x^{11} + x^9 - x^8 + x^6 - x^4 + x^3 - x + 1 \\\\\n\\Phi_{22}(x) &= x^{10} - x^9 + x^8 - x^7 + x^6 - x^5 + x^4 - x^3 + x^2 - x + 1 \\\\\n\\Phi_{23}(x) &= x^{22} + x^{21} + x^{20} + x^{19} + x^{18} + x^{17} + x^{16} + x^{15} + x^{14} + x^{13} + x^{12} + x^{11} \\\\\n& \\qquad\\quad + x^{10} + x^9 + x^8 + x^7 + x^6 + x^5 + x^4 + x^3 + x^2 + x + 1 \\\\\n\\Phi_{24}(x) &= x^8 - x^4 + 1 \\\\\n\\Phi_{25}(x) &= x^{20} + x^{15} + x^{10} + x^5 + 1 \\\\\n\\Phi_{26}(x) &= x^{12} - x^{11} + x^{10} - x^9 + x^8 - x^7 + x^6 - x^5 + x^4 - x^3 + x^2 - x + 1 \\\\\n\\Phi_{27}(x) &= x^{18} + x^9 + 1 \\\\\n\\Phi_{28}(x) &= x^{12} - x^{10} + x^8 - x^6 + x^4 - x^2 + 1 \\\\\n\\Phi_{29}(x) &= x^{28} + x^{27} + x^{26} + x^{25} + x^{24} + x^{23} + x^{22} + x^{21} + x^{20} + x^{19} + x^{18} + x^{17} + x^{16} + x^{15} + x^{14} \\\\\n& \\qquad\\quad + x^{13} + x^{12} + x^{11} + x^{10} + x^9 + x^8 + x^7 + x^6 + x^5 + x^4 + x^3 + x^2 + x + 1 \\\\\n\\Phi_{30}(x) &= x^8 + x^7 - x^5 - x^4 - x^3 + x + 1.\n\\end{align}</math>\n\nThe case of the 105th cyclotomic polynomial is interesting because 105 is the lowest integer that is the product of three distinct odd prime numbers (3*5*7) and this polynomial is the first one that has a [[coefficient]] other than 1, 0, or −1:\n\n:<math>\\begin{align}\n\\Phi_{105}(x) &= x^{48} + x^{47} + x^{46} - x^{43} - x^{42} - 2 x^{41} - x^{40} - x^{39} + x^{36} + x^{35} + x^{34} + x^{33} + x^{32} + x^{31} - x^{28} - x^{26} \\\\\n&\\qquad\\quad - x^{24} - x^{22} - x^{20} + x^{17} + x^{16} + x^{15} + x^{14} + x^{13} + x^{12} - x^9 - x^8 - 2 x^7 - x^6 - x^5 + x^2 + x + 1.\n\\end{align}</math>\n\n==Properties==\n\n===Fundamental tools===\n\nThe cyclotomic polynomials are monic polynomials with integer coefficients that are [[irreducible polynomial|irreducible]] over the field of the rational numbers. Except for ''n'' equal to 1 or 2, they are [[Reciprocal polynomial#Palindromic polynomial|palindromic]]s of even degree.\n\nThe degree of <math>\\Phi_n</math>, or in other words the number of ''n''th primitive roots of unity, is <math>\\varphi (n)</math>, where <math>\\varphi</math> is [[Euler's totient function]].\n\nThe fact that <math>\\Phi_n</math> is an irreducible polynomial of degree <math>\\varphi (n)</math> in the [[ring (mathematics)|ring]] <math>\\Z[x]</math> is a nontrivial result due to [[Carl Friedrich Gauss|Gauss]].<ref>{{Lang Algebra}}</ref> Depending on the chosen definition, it is either the value of the degree or the irreducibility which is a nontrivial result. The case of prime ''n'' is easier to prove than the general case, thanks to [[Eisenstein's criterion#Cyclotomic polynomials|Eisenstein's criterion]].\n\nA fundamental relation involving cyclotomic polynomials is \n\n:<math>x^n - 1 =\\prod_{1\\leqslant k\\leqslant n} \\left(x- e^{2i\\pi\\frac{k}{n}} \\right)= \\prod_{d \\mid n} \\prod_{1 \\leqslant k \\leqslant n \\atop \\gcd(k, n) = d} \\left(x- e^{2i\\pi\\frac{k}{n}} \\right) =\\prod_{d \\mid n} \\Phi_{\\frac{n}{d}}(x) =  \\prod_{d\\mid n} \\Phi_d(x).</math>\n\nwhich means that each ''n''-th root of unity is a primitive ''d''-th root of unity for a unique ''d'' dividing ''n''.\n\nThe [[Möbius inversion formula#Multiplicative notation|Möbius inversion formula]] allows the expression of <math>\\Phi_n(x)</math> as an explicit rational fraction:\n\n:<math>\\Phi_n(x)=\\prod_{d\\mid n}(x^d-1)^{\\mu \\left (\\frac{n}{d} \\right )}, </math>\n\nwhere <math>\\mu</math> is the [[Möbius function]].\n\nThe [[Discrete Fourier transform|Fourier transform]] of functions of the [[greatest common divisor]] together with the [[Möbius inversion formula]] gives:<ref>{{cite journal |last=Schramm |first=Wolfgang |title=Eine alternative Produktdarstellung für die Kreisteilungspolynome |journal=Elemente der Mathematik |volume=70 |issue=4 |pages=137–143 |publisher=[[Swiss Mathematical Society]] |year=2015 |url=https://www.ems-ph.org/journals/show_abstract.php?issn=0013-6018&vol=70&iss=4&rank=1 |accessdate=2015-10-10 |deadurl=yes |archiveurl=https://web.archive.org/web/20151222122149/https://www.ems-ph.org/journals/show_abstract.php?issn=0013-6018&vol=70&iss=4&rank=1 |archivedate=2015-12-22 |df= }}</ref> \n\n:<math>\\Phi_n(x)=\\prod_{k=1}^n \\left (x^{\\gcd(k,n)}-1 \\right )^{\\cos \\left(\\frac{2\\pi k}{n}\\right)} .</math>\n\nThe cyclotomic polynomial <math>\\Phi_{n}(x)</math> may be computed by (exactly) dividing <math>x^n-1</math> by the cyclotomic polynomials of the proper divisors of ''n'' previously computed recursively by the same method:\n\n:<math>\\Phi_n(x)=\\frac{x^{n}-1}{\\prod_{\\stackrel{d|n}{{}_{d<n}}}\\Phi_{d}(x)}</math>\n\n(Recall that <math>\\Phi_{1}(x)=x-1</math>.)\n\nThis formula allows computation of <math>\\Phi_n(x)</math> on a computer for any ''n'', as soon as [[integer factorization]] and [[Euclidean division of polynomials|division of polynomials]] are available. Many [[computer algebra systems]] have a built in function to compute the cyclotomic polynomials. For example, this function is called by typing <code>cyclotomic_polynomial(n,x)</code> in [[SageMath]], <code>numtheory[cyclotomic](n,x);</code> in [[Maple (software)|Maple]], and <code>Cyclotomic[n,x]</code> in [[Mathematica]].\n\n===Easy cases for computation===\nAs noted above, if {{math|''n''}} is a prime number, then\n\n:<math>\\Phi_n(x) = 1+x+x^2+\\cdots+x^{n-1}=\\sum_{i=0}^{n-1}x^i.</math>\n\nIf ''n'' is an odd integer greater than one, then \n\n:<math>\\Phi_{2n}(x) = \\Phi_n(-x).</math>\n\nIn particular, if {{math|1=''n'' = 2''p''}} is twice an odd prime, then (as noted above)\n\n:<math>\\Phi_n(x) = 1-x+x^2-\\cdots+x^{p-1}=\\sum_{i=0}^{p-1}(-x)^i.</math>\n\nIf {{math|1=''n'' = ''p<sup>m</sup>''}} is a [[prime power]] (where ''p'' is prime), then\n\n:<math>\\Phi_n(x) = \\Phi_p(x^{p^{m-1}}) =\\sum_{i=0}^{p-1}x^{ip^{m-1}}.</math>\n\nMore generally, if {{math|1=''n'' = ''p<sup>m</sup>r''}} with {{math|''r''}} relatively prime to {{math|''p''}}, then \n\n:<math>\\Phi_n(x) = \\Phi_{pr}(x^{p^{m-1}}).</math>\n\nThese formulas may be applied repeatedly to get a simple expression for any cyclotomic polynomial <math>\\Phi_n(x)</math> in term of a cyclotomic polynomial of [[square-free number|square free]] index: If {{math|''q''}} is the product of the prime divisors of {{math|''n''}} (its [[Radical of an integer|radical]]), then<ref>{{citation\n | last = Cox | first = David A. | authorlink = David A. Cox  | contribution = Exercise 12  | doi = 10.1002/9781118218457 | edition = 2nd  | isbn = 978-1-118-07205-9 | page = 237 | publisher = John Wiley & Sons  | title = Galois Theory | year = 2012}}.</ref>\n\n:<math>\\Phi_n(x) = \\Phi_q(x^{n/q}).</math>\n\nThis allows to give formulas for the {{math|''n''}}th cyclotomic polynomial when {{math|''n''}} has at most one odd prime factor: If {{math|''p''}} is an odd prime number, and {{math|''h''}} and {{math|''k''}} are positive integers, then: \n:<math>\\Phi_{2^h}(x) = x^{2^{h-1}}+1</math>\n:<math>\\Phi_{p^k}(x) = \\sum_{i=0}^{p-1}x^{ip^{k-1}}</math>\n:<math>\\Phi_{2^hp^k}(x) = \\sum_{i=0}^{p-1}(-1)^ix^{i2^{h-1}p^{k-1}}</math>\n\nFor the other values of {{math|''n''}}, the computation of the {{math|''n''}}th cyclotomic polynomial is similarly reduced to that of  <math>\\Phi_q(x),</math> where {{math|''q''}} is the product of the distinct odd prime divisors of {{math|''n''}}. To deal with this case, one has that, for {{math|''p''}} prime and not dividing {{math|''n''}},<ref name=\"WolframCyclotomic\">{{cite web | url=http://mathworld.wolfram.com/CyclotomicPolynomial.html | title=Cyclotomic Polynomial | accessdate=12 March 2014 | author=Weisstein, Eric W.}}</ref>\n\n:<math>\\Phi_{np}(x)=\\Phi_{n}(x^p)/\\Phi_n(x).</math>\n\n===Integers appearing as coefficients===\n\nThe problem of bounding the magnitude of the coefficients of the cyclotomic polynomials has been the object of a number of research papers.\n \nIf ''n'' has at most two distinct odd prime factors, then Migotti showed that the coefficients of <math>\\Phi_n</math> are all in the set {1, −1, 0}.<ref>{{cite book |title=Algebra: A Graduate Course |first=Martin |last=Isaacs |page=310 |isbn=978-0-8218-4799-2 |publisher=AMS Bookstore |year=2009}}</ref>\n\nThe first cyclotomic polynomial for a product of three different odd prime factors is <math>\\Phi_{105}(x);</math> it has a coefficient −2 (see its expression [[#Examples|above]]). The converse is not true: <math>\\Phi_{231}(x)=\\Phi_{3\\times 7\\times 11}(x)</math> only has coefficients in {1, −1, 0}.\n\nIf ''n'' is a product of more different odd prime factors, the coefficients may increase to very high values. E.g., <math>\\Phi_{15015}(x) =\\Phi_{3\\times 5\\times 7\\times 11\\times 13}(x)</math> has coefficients running from −22 to 23, <math>\\Phi_{255255}(x)=\\Phi_{3\\times 5\\times 7\\times 11\\times 13\\times 17}(x)</math>, the smallest ''n'' with 6 different odd primes, has coefficients up to ±532.\n\nLet ''A''(''n'') denote the maximum absolute value of the coefficients of Φ<sub>''n''</sub>.  It is known that for any positive ''k'', the number of ''n'' up to ''x'' with ''A''(''n'') > ''n''<sup>''k''</sup> is at least ''c''(''k'')⋅''x'' for a positive ''c''(''k'') depending on ''k'' and ''x'' sufficiently large.  In the opposite direction, for any function ψ(''n'') tending to infinity with ''n'' we have ''A''(''n'') bounded above by ''n''<sup>ψ(''n'')</sup> for almost all ''n''.<ref name=Mei2008>Meier (2008)</ref>\n\n===[[Carl Friedrich Gauss|Gauss]]'s formula===\n\nLet ''n'' be odd, square-free, and greater than 3. Then:<ref>Gauss, DA, Articles 356-357</ref><ref>Riesel, pp. 315-316, p. 436</ref>\n\n:<math>4\\Phi_n(z) = A_n^2(z) - (-1)^{\\frac{n-1}{2}}nz^2B_n^2(z)</math>\n\nwhere  both ''A<sub>n</sub>''(''z'') and ''B<sub>n</sub>''(''z'') have integer coefficients, ''A<sub>n</sub>''(''z'') has degree ''&phi;''(''n'')/2, and ''B<sub>n</sub>''(''z'') has degree ''&phi;''(''n'')/2 − 2. Furthermore, ''A<sub>n</sub>''(''z'') is palindromic when its degree is even; if its degree is odd it is antipalindromic. Similarly, ''B<sub>n</sub>''(''z'') is palindromic unless ''n'' is composite and ≡ 3 (mod 4), in which case it is antipalindromic.\n\nThe first few cases are\n\n:<math>\\begin{align}\n4\\Phi_5(z) &=4(z^4+z^3+z^2+z+1)\\\\ \n&= (2z^2+z+2)^2 - 5z^2  \\\\[6pt]\n4\\Phi_7(z) &=4(z^6+z^5+z^4+z^3+z^2+z+1)\\\\ \n&= (2z^3+z^2-z-2)^2+7z^2(z+1)^2 \\\\ [6pt]\n4\\Phi_{11}(z)\n&=4(z^{10}+z^9+z^8+z^7+z^6+z^5+z^4+z^3+z^2+z+1)\\\\ \n&= (2z^5+z^4-2z^3+2z^2-z-2)^2+11z^2(z^3+1)^2\n\\end{align}</math>\n\n===[[Édouard Lucas|Lucas]]'s formula===\n\nLet ''n'' be odd, square-free and greater than 3. Then<ref>Riesel, pp. 309-315, p. 443</ref>\n\n:<math>\\Phi_n(z) = U_n^2(z) - (-1)^{\\frac{n-1}{2}}nzV_n^2(z)</math>\n\nwhere  both ''U<sub>n</sub>''(''z'') and ''V<sub>n</sub>''(''z'') have integer coefficients, ''U<sub>n</sub>''(''z'') has degree ''&phi;''(''n'')/2, and ''V<sub>n</sub>''(''z'') has degree ''&phi;''(''n'')/2 − 1. This can also be written\n\n:<math>\\Phi_n \\left ((-1)^{\\frac{n-1}{2}}z \\right ) = C_n^2(z) - nzD_n^2(z).</math>\n\nIf ''n'' is even, square-free and greater than 2 (this forces ''n''/2 to be odd),\n\n:<math>\\Phi_{\\frac{n}{2}} \\left (-z^2 \\right ) = \\Phi_{2n}(z)= C_n^2(z) - nzD_n^2(z)</math>\n\nwhere both ''C<sub>n</sub>''(''z'') and ''D<sub>n</sub>''(''z'') have integer coefficients, ''C<sub>n</sub>''(''z'') has degree ''&phi;''(''n''), and ''D<sub>n</sub>''(''z'') has degree ''&phi;''(''n'') − 1. ''C<sub>n</sub>''(''z'') and ''D<sub>n</sub>''(''z'') are both palindromic.\n\nThe first few cases are:\n\n:<math>\\begin{align}\n\\Phi_3(-z) &=\\Phi_6(z) =z^2-z+1 \\\\\n&= (z+1)^2 - 3z \\\\[6pt]\n\\Phi_5(z) &=z^4+z^3+z^2+z+1 \\\\\n&= (z^2+3z+1)^2 - 5z(z+1)^2 \\\\[6pt]\n\\Phi_{6/2}(-z^2) &=\\Phi_{12}(z)=z^4-z^2+1 \\\\\n&= (z^2+3z+1)^2 - 6z(z+1)^2\n\\end{align}</math>\n\n== Cyclotomic polynomials over a finite field and over {{math|p}}-adic integers ==\n{{see also|Finite field#Roots of unity}}\nOver a [[finite field]] with a prime number {{math|''p''}} of elements, for any integer {{math|''n''}} that is not a multiple of {{math|''p''}}, the cyclotomic polynomial <math>\\Phi_n</math> factorizes into <math>\\frac{\\varphi (n)}{d}</math> irreducible polynomials of degree {{math|''d''}}, where <math>\\varphi (n)</math> is [[Euler's totient function]], and {{math|''d''}} is the [[multiplicative order]] of {{math|''p''}} modulo {{math|''n''}}. In particular, <math>\\Phi_n</math> is irreducible [[if and only if]] {{math|''p''}} is a [[primitive root modulo n|primitive root modulo {{mvar|n}}]], that is, {{math|''p''}} does not divide {{math|''n''}}, and its multiplicative order modulo {{math|''n''}} is <math>\\varphi(n),</math> the degree of <math>\\Phi_n</math>.{{Citation needed|date=October 2018}}\n\nThese results are also true over the [[p-adic integer|{{mvar|p}}-adic integers]], since [[Hensel's lemma]] allows lifting a factorization over the field with {{math|''p''}} of elements to a factorization over the {{math|p}}-adic integers.\n\n==Polynomial values==\n{{unreferenced section|date=April 2014}}\n\nIf {{math|''x''}} takes any real value, then <math>\\Phi_n(x)>0</math> for every {{math|''n'' ≥ 3}} (this follows from the fact that the roots of a cyclotomic polynomial are all non-real, for {{math|''n'' ≥ 3}}).\n\nFor studying the values that a cyclotomic polynomial may take when {{math|''x''}} is given an integer value, it suffices to consider only the case {{math|''n'' ≥ 3}}, as the cases {{math|1=''n'' = 1}} and  {{math|1=''n'' = 2}} are trivial (one has <math>\\Phi_1(x)=x-1</math> and <math>\\Phi_2(x)=x+1</math>). \n\nFor {{math|''n'' ≥ 2}}, one has\n\n:<math>\\Phi_n(0) =1,</math>\n:<math>\\Phi_n(1) =1</math> if {{math|''n''}} is not a [[prime power]],\n:<math>\\Phi_n(1) =p</math> if <math>n=p^k</math> is a prime power with {{math|''k'' ≥ 1}}.\n\nThe values that a cyclotomic polynomial <math>\\Phi_n(x)</math> may take for other integer values of {{math|''x''}} is strongly related with the [[multiplicative order]] modulo a prime number. \n\nMore precisely, given a prime number {{math|''p''}} and an integer {{math|''b''}} coprime with {{math|''p''}}, the multiplicative order of {{math|''b''}} modulo {{math|''p''}}, is the smallest positive integer {{math|''n''}} such that {{math|''p''}} is a divisor of <math>x^n-1.</math> For {{math|''b'' > 1}}, the multiplicative order of {{math|''b''}} modulo {{math|''p''}} is also the [[periodic function|shortest period]] of the representation of {{math|1/''p''}} in the [[numeral base]] {{math|''b''}} (see [[Unique prime]]; this explains the notation choice). \n\nThe definition of the multiplicative order implies that, if {{math|''n''}} is the multiplicative order of {{math|''b''}} modulo {{math|''p''}}, then {{math|''p''}} is a divisor of <math>\\Phi_n(b).</math> The converse is not true, but one has the following.\n\nIf {{math|''n'' > 0}} is a positive integer and {{math|''b'' > 1}} is an integer, then (see below for a proof)\n:<math>\\Phi_n(b)=2^kgh,</math>\nwhere \n* {{math|''k''}} is a non-negative integer, always equal to 0 when {{math|''b''}} is even. (In fact, if {{math|''n''}} is neither 1 nor 2, then {{math|''k''}} is either 0 or 1. Besides, if {{math|''n''}} is not a [[power of 2]], then {{math|''k''}} is always equal to 0)\n* {{math|''g''}} is 1 or the largest odd prime factor of {{math|''n''}}.\n* {{math|''h''}} is odd, coprime with {{math|''n''}}, and its [[prime factor]]s are exactly the odd primes {{math|''p''}} such that {{math|''n''}} is the multiplicative order of {{math|''b''}} modulo {{math|''p''}}.\n\nThis implies that, if {{math|''p''}} is an odd prime divisor of <math>\\Phi_n(b),</math> then either {{math|''n''}} is a divisor of {{math|''p'' − 1}} or {{math|''p''}} is a divisor of {{math|''n''}}. In the latter case <math>p^2</math> does not divides <math>\\Phi_n(b).</math>\n\n[[Zsigmondy's theorem]] implies that the only cases where  {{math|1=''b'' > 1}} and {{math|1=''h'' = 1}} are\n\n:<math>\\begin{align}\n\\Phi_1(2) &=1 \\\\\n\\Phi_2 \\left (2^k-1 \\right ) & =2^k && k >0 \\\\\n\\Phi_6(2) &=3\n\\end{align}</math> \n\nIt follows from above factorization that the odd prime factors of\n\n:<math>\\frac{\\Phi_n(b)}{\\gcd(n,\\Phi_n(b))}</math>\n\nare exactly the odd primes {{math|''p''}} such that {{math|''n''}} is the multiplicative order of {{math|''b''}} modulo {{math|''p''}}. This fraction may be even only when {{math|''b''}} is odd. In this case, the multiplicative order of {{math|''b''}} modulo {{math|2}} is always {{math|1}}.\n\nThere are many pairs {{math|(''n'', ''b'')}} with {{math|''b'' > 1}} such that <math>\\Phi_n(b)</math> is prime. In fact, [[Bunyakovsky conjecture]] implies that, for every {{math|''n''}}, there are infinitely many {{math|''b'' > 1}} such that <math>\\Phi_n(b)</math> is prime. See {{oeis|id=A085398}} for the list of the smallest {{math|''b'' > 1}} such that <math>\\Phi_n(b)</math> is prime (the smallest {{math|''b'' > 1}} such that <math>\\Phi_n(b)</math> is prime is about <math>\\lambda \\cdot \\varphi(n)</math>, where <math>\\lambda</math> is [[Euler–Mascheroni constant]], and <math>\\varphi</math> is [[Euler's totient function]]). See also {{oeis|id=A206864}} for the list of the smallest primes of the form <math>\\Phi_n(b)</math> with {{math|''n'' > 2}} and {{math|''b'' > 1}}, and, more generally, {{oeis|id=A206942}}, for the smallest positive integers of this form.\n{{cot| title=Proofs}}\n* ''Values of'' <math>\\Phi_n(1).</math> If <math>n=p^{k+1}</math> is a prime power, then \n::<math>\\Phi_n(x)=1+x^{p^k}+x^{p^{2k}}+\\cdots+x^{(p-1)p^k} \\qquad \\text{and} \\qquad \\Phi_n(1)=p.</math> \n:If {{math|''n''}} is not a prime power, let <math>P(x)=1+x+\\cdots+x^{n-1},</math> we have <math>P(1)=n,</math> and {{math|''P''}} is the product of the <math>\\Phi_k(x)</math> for {{math|''k''}} dividing {{math|''n''}} and different of {{math|1}}. If {{math|''p''}} is a prime divisor of multiplicity {{math|''m''}} in {{math|''n''}}, then <math>\\Phi_p(x), \\Phi_{p^2}(x), \\cdots, \\Phi_{p^m}(x)</math> divide {{math|''P''(''x'')}}, and their values at {{math|1}} are {{math|''m''}} factors equal to {{math|''p''}} of <math>n=P(1).</math> As {{math|''m''}} is the multiplicity of {{math|''p''}} in {{math|''n''}}, {{math|''p''}} cannot divide the value at {{math|1}} of the other factors of <math>P(x).</math> Thus there is no prime that divides <math>\\Phi_n(1).</math>\n\n*''If'' {{math|''n''}} ''is the multiplicative order of'' {{math|''b''}} ''modulo'' {{math|''p''}}, ''then'' <math>p \\mid \\Phi_n(b).</math> By definition, <math>p \\mid b^n-1.</math> If <math>p \\nmid \\Phi_n(b),</math> then {{math|''p''}} would divide another factor <math>\\Phi_k(b)</math> of <math>b^n-1,</math> and would thus divide <math>b^k-1,</math> showing that, if there would be the case, {{math|''n''}} would not be the multiplicative order of {{math|''b''}} modulo {{math|''p''}}.\n\n*''The other prime divisors of'' <math>\\Phi_n(b)</math> ''are divisors of'' {{math|''n''}}. Let {{math|''p''}} be a prime divisor of <math>\\Phi_n(b)</math> such that {{math|''n''}} is not be the multiplicative order of {{math|''b''}} modulo {{math|''p''}}. If {{math|''k''}} is the multiplicative order of {{math|''b''}} modulo {{math|''p''}}, then {{math|''p''}} divides both <math>\\Phi_n(b)</math> and <math>\\Phi_k(b).</math> The [[resultant]] of <math>\\Phi_n(x)</math> and <math>\\Phi_k(x)</math> may be written <math>P\\Phi_k+Q\\Phi_n,</math> where {{math|''P''}} and {{math|''Q''}} are polynomials. Thus {{math|''p''}} divides this resultant. As {{math|''k''}} divides {{math|''n''}}, and the resultant of two polynomials divides the [[discriminant]] of any common multiple of these polynomials, {{math|''p''}} divides also the discriminant <math>n^n</math> of <math>x^n-1.</math> Thus {{math|''p''}} divides {{math|''n''}}.\n\n*{{math|''g''}} ''and'' {{math|''h''}} ''are coprime''. In other words, if {{math|''p''}} is a prime common divisor of {{math|''n''}} and <math>\\Phi_n(b),</math> then {{math|''n''}} is not the multiplicative order of {{math|''b''}} modulo {{math|''p''}}. By [[Fermat's little theorem]], the multiplicative order of {{math|''b''}} is a divisor of {{math|''p'' − 1}}, and thus smaller than {{math|''n''}}.\n\n*{{math|''g''}} ''is square-free''. In other words, if  {{math|''p''}} is a prime common divisor of {{math|''n''}} and <math>\\Phi_n(b),</math> then <math>p^2</math> does not divide <math>\\Phi_n(b).</math> Let {{math|1=''n'' = ''pm''}}. It suffices to prove that <math>p^2</math> does not divides {{math|''S''(''b'')}} for some polynomial {{math|''S''(''x'')}}, which is a multiple of <math>\\Phi_n(x).</math> We take \n::<math>S(x)=\\frac{x^n-1}{x^m-1} = 1 + x^m + x^{2m} + \\cdots + x^{(p-1)m}.</math> \n:The multiplicative order of {{math|''b''}} modulo {{math|''p''}} divides {{math|gcd(''n'', ''p'' − 1)}}, which is a divisor of {{math|1=''m'' = ''n''/''p''}}. Thus  {{math|1=''c'' = ''b<sup>m</sup>'' − 1}} is a multiple of {{math|''p''}}. Now, \n::<math>S(b) = \\frac{(1+c)^p-1}{c} = p+ \\binom{p}{2}c + \\cdots + \\binom{p}{p}c^{p-1}.</math> \n:As {{math|''p''}} is prime and greater than 2, all the terms but the first one are multiples of <math>p^2.</math> This proves that <math>p^2 \\nmid \\Phi_n(b).</math>\n{{cob}}\n\n==Applications==\n\nUsing <math>\\Phi_n</math>, one can give an elementary proof for the infinitude of [[prime]]s [[Congruence relation|congruent]] to 1 modulo ''n'',<ref>S. Shirali. ''Number Theory''. Orient Blackswan, 2004. p. 67. {{isbn|81-7371-454-1}}</ref> which is a special case of [[Dirichlet's theorem on arithmetic progressions]].\n{{cot| title=Proof}}\nSuppose <math>p_1, p_2, \\ldots, p_k</math> are a finite list of primes congruent to <math>1</math> modulo <math>n.</math> Let <math>N = np_1p_2\\cdots  p_k</math> and consider <math>\\Phi_n(N)</math>. Let <math>q</math> be a prime factor of <math>\\Phi_n(N)</math> (to see that <math>\\Phi_n(N) \\neq \\pm 1</math> decompose it into linear factors and note that 1 is the closest root of unity to <math>N</math>). Since <math>\\Phi_n(x) \\equiv \\pm 1 \\pmod x,</math> we know that <math>q</math> is a new prime not in the list. We will show that <math>q \\equiv 1 \\pmod n.</math>\n\nLet <math>m</math> be the order of <math>N</math> modulo <math>q.</math> Since <math>\\Phi_n(N) \\mid N^n - 1</math> we have <math>N^n -1 \\equiv 0 \\pmod{q}</math>. Thus <math>m \\mid n</math>.  We will show that <math>m = n</math>.\n\nAssume for contradiction that <math>m < n</math>. Since \n\n:<math>N^m - 1 \\equiv \\prod_{d \\mid m} \\Phi_d(N) \\equiv 0 \\pmod q</math> \n\nwe have \n\n:<math>\\Phi_d(N) \\equiv 0 \\pmod q,</math> \n\nfor some <math>d < n</math>. Then <math>N</math> is a double root of \n\n:<math>\\prod_{d \\mid n} \\Phi_d(x) \\equiv x^n -1 \\pmod q.</math>\n\nThus <math>N</math> must be a root of the derivative so \n\n:<math>\\left.\\frac{d(x^n -1)}{dx}\\right|_N \\equiv nN^{n-1} \\equiv 0 \\pmod q.</math>\n\nBut <math>q \\nmid N</math> and therefore <math>q \\nmid n.</math> This is a contradiction so <math>m = n</math>. The order of <math>N \\pmod q,</math> which is <math>n</math>, must divide <math>q-1</math>. Thus <math>q \\equiv 1 \\pmod n.</math>\n{{cob}}\n\n==See also==\n* [[Cyclotomic field]]\n* [[Aurifeuillean factorization]]\n* [[Root of unity]]\n\n==Notes==\n\n{{Reflist}}\n\n==References==\n\nGauss's book ''[[Disquisitiones Arithmeticae]]'' has been translated from Latin into English and German. The German edition includes all of his papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes.\n*{{Cite book\n | last = Gauss\n | first = Carl Friedrich\n | others = Translated into English by Clarke, Arthur A.\n | title = Disquisitiones Arithmeticae\n | edition = 2nd corr.\n | publisher = [[Springer Science+Business Media|Springer]]\n | location = New York\n | year = 1986\n | origyear = 1801\n | isbn = 0387962549\n}}\n*{{Cite book\n | last = Gauss\n | first = Carl Friedrich\n | others = Translated into German by Maser, H. \n | title = Untersuchungen uber hohere Arithmetik (Disquisitiones Arithmeticae & other papers on number theory)\n | edition = 2nd\n | publisher = Chelsea\n | location = New York\n | year = 1965\n | origyear = 1801\n | isbn = 0-8284-0191-8\n}}\n*{{Cite book\n | last1 = Lemmermeyer  | first1 = Franz\n | title = Reciprocity Laws: from Euler to Eisenstein\n | publisher = [[Springer Science+Business Media|Springer]]\n | location = Berlin\n | year = 2000\n | isbn = 978-3-642-08628-1\n | doi= 10.1007/978-3-662-12893-0\n}}\n*{{Citation\n | last = Maier\n | first = Helmut\n | chapter = Anatomy of integers and cyclotomic polynomials\n | editor1-last = De Koninck\n | editor1-first = Jean-Marie\n | editor2-last = Granville\n | editor2-first = Andrew\n | editor2-link = Andrew Granville\n | editor3-last = Luca\n | editor3-first = Florian\n | title = Anatomy of integers. Based on the CRM workshop, Montreal, Canada, March 13-17, 2006\n | location = Providence, RI\n | publisher = [[American Mathematical Society]]\n | series = CRM Proceedings and Lecture Notes\n | volume = 46\n | pages = 89–95\n | year = 2008\n | isbn = 978-0-8218-4406-9\n | zbl = 1186.11010\n}}\n*{{Cite book\n | last1 = Riesel  | first1 = Hans\n | title = Prime Numbers and Computer Methods for Factorization\n | edition = 2nd\n | publisher = Birkhäuser\n | location = Boston\n | year = 1994\n | isbn = 0-8176-3743-5\n}}\n\n==External links==\n*{{mathworld|urlname=CyclotomicPolynomial|title=Cyclotomic polynomial}}\n*{{springer|title=Cyclotomic polynomials|id=p/c027580}}\n*{{OEIS el|sequencenumber=A013595|name=Triangle of coefficients of cyclotomic polynomial Phi_n(x) (exponents in increasing order)}}\n*{{OEIS el|sequencenumber=A013594|name=Smallest order of cyclotomic polynomial containing n or −n as a coefficient}}\n\n[[Category:Polynomials]]\n[[Category:Algebra]]\n[[Category:Number theory]]"
    },
    {
      "title": "Cylindrical algebraic decomposition",
      "url": "https://en.wikipedia.org/wiki/Cylindrical_algebraic_decomposition",
      "text": "In [[mathematics]], '''cylindrical algebraic decomposition''' ('''CAD''') is a notion, and an [[algorithm]] to compute it, which are fundamental for [[computer algebra]] and [[real algebraic geometry]]. Given a set ''S'' of polynomials in '''R'''<sup>''n''</sup>, a cylindrical algebraic decomposition is a decomposition of '''R'''<sup>''n''</sup> into connected [[semialgebraic set]]s called ''cells'', on which each polynomial has constant sign, either +, − or 0. To be ''cylindrical'', this decomposition must satisfy the following condition: If 1&nbsp;≤&nbsp;''k''&nbsp;<&nbsp;''n'' and π is the projection from '''R'''<sup>''n''</sup> onto '''R'''<sup>''n''−''k''</sup> consisting in removing the ''k'' last coordinates, then for every pair of cells ''c'' and ''d'', one has either π(''c'')&nbsp;=&nbsp;π(''d'') or π(''c'')&nbsp;∩&nbsp;π(''d'')&nbsp;=&nbsp;∅. This implies that the images by π of the cells define a cylindrical decomposition of&nbsp;'''R'''<sup>''n''−''k''</sup>.\n\nThe notion was introduced by [[George E. Collins]] in 1975, together with an [[algorithm]] for computing it.\n\nCollins' algorithm has a [[Analysis of algorithms|computational complexity]] that is [[double exponential function|double exponential]] in ''n''. This is an upper bound, which is reached on most entries. There are also examples for which the minimal number of cells is doubly exponential, showing that every general algorithm for cylindrical algebraic decomposition has a double exponential complexity.\n\n'''CAD''' provides an effective version of [[quantifier elimination]] over the reals, which has a much better computational complexity than that which results from the original proof of [[Tarski–Seidenberg theorem]]. It is efficient enough to be implemented on a computer. It is one of the most important algorithms of computational [[real algebraic geometry]]. Searching to improve Collins algorithm, or to provide algorithms that have a better complexity for subproblems of general interest, is an active field of research.\n\n==Implementations==\n* [[Mathematica]]: [https://reference.wolfram.com/mathematica/ref/CylindricalDecomposition.html CylindricalDecomposition]\n==References==\n*Basu, Saugata; Pollack, Richard; Roy, Marie-Françoise Algorithms in real algebraic geometry. Second edition. Algorithms and Computation in Mathematics, 10. Springer-Verlag, Berlin, 2006. x+662 pp. {{ISBN|978-3-540-33098-1}}; 3-540-33098-4\n*Strzebonski, Adam. ''[http://mathworld.wolfram.com/CylindricalAlgebraicDecomposition.html Cylindrical Algebraic Decomposition]''  from [[MathWorld]].\n*[http://planning.cs.uiuc.edu/node292.html Cylindrical Algebraic Decomposition] in ''Planning algorithms'' by Steven M. LaValle. Accessed 13 July 2007\n\n[[Category:Algebra]]\n[[Category:Real algebraic geometry]]\n\n\n{{algebraic-geometry-stub}}"
    },
    {
      "title": "De Morgan algebra",
      "url": "https://en.wikipedia.org/wiki/De_Morgan_algebra",
      "text": "__NOTOC__\nIn [[mathematics]], a '''De Morgan algebra''' (named after [[Augustus De Morgan]], a British mathematician and logician) is a structure ''A'' =&nbsp;(A,&nbsp;∨,&nbsp;∧,&nbsp;0,&nbsp;1,&nbsp;¬) such that:\n\n* (''A'',&nbsp;∨,&nbsp;∧,&nbsp;0,&nbsp;1) is a [[Bounded set|bounded]] [[distributive lattice]], and\n* ¬ is a De Morgan involution:  ¬(''x''&nbsp;∧&nbsp;''y'') = ¬''x''&nbsp;∨&nbsp;¬''y'' and ¬¬''x'' = ''x''. (i.e. an  [[Involution (mathematics)|involution]] that additionally satisfies [[De Morgan's laws]])\n\nIn a De Morgan algebra, the laws\n\n* ¬''x''&nbsp;∨&nbsp;''x'' = 1 ([[law of the excluded middle]]), and\n* ¬''x''&nbsp;∧&nbsp;''x'' = 0 ([[law of noncontradiction]])\n\ndo not always hold. In the presence of the De Morgan laws, either law implies the other, and an algebra which satisfies them becomes a [[Boolean algebra (structure)|Boolean algebra]].\n\nRemark: It follows that ¬( x∨y)  = ¬x∧¬y,  ¬1 = 0 and ¬0 = 1 (e.g. ¬1 = ¬1∨0 = ¬1∨¬¬0 = ¬(1∧¬0) = ¬¬0 = 0). Thus ¬ is a dual [[automorphism]].\n\nIf the lattice is defined in terms of the order instead, i.e. (A,&nbsp;≤) is a bounded partial order with a least upper bound and greatest lower bound for every pair of elements, and the meet and join operations so defined satisfy the distributive law, then the complementation can also be defined as an involutive anti-automorphism, that is, a structure ''A'' =&nbsp;(A,&nbsp;≤,&nbsp;¬) such that:\n\n* (A,&nbsp;≤) is a [[Bounded set|bounded]] [[distributive lattice]], and\n* ¬¬''x'' = ''x'', and\n* ''x'' ≤ ''y'' → ¬''y'' ≤ ¬''x''.\n\nDe Morgan algebras were introduced by [[Grigore Moisil]]<ref name=\"BV\">{{cite book| ref = harv| first1=T. S.|last1=Blyth|first2=J. C.|last2=Varlet|title=Ockham algebras|year=1994|publisher=Oxford University Press|isbn=978-0-19-859938-8|pages=4–5}}</ref><ref name=\"Bez\">{{cite book |  ref = harv | editor1-first=Dov M. | editor1-last=Gabbay | editor2-first=Francis Jeffry | editor2-last=Pelletier | editor3-first=John | editor3-last=Woods|title=Logic: A History of its Central Concepts| year=2012|publisher=North Holland (an imprint of Elsevier)|isbn=978-0-08-093170-8 | first1= Jean-Yves | last1 = Béziau| chapter=A History of Truth-Values|pages=280–281}}</ref> around 1935.<ref name=\"Bez\"/> although without the restriction of having a 0 and a 1.<ref name=\"Cignoli75\">{{cite journal|url=http://www.ams.org/journals/proc/1975-047-02/S0002-9939-1975-0357259-4/S0002-9939-1975-0357259-4.pdf |title=Injective de Morgan and Kleene Algebras|first=Roberto |last=Cignoli |journal=Proceedings of the American Mathematical Society|volume=47|number= 2|year=1975 |pages=269–278|ref=harv|doi=10.1090/S0002-9939-1975-0357259-4|jstor=2039730}}</ref> They were then variously called '''quasi-boolean algebras''' in the Polish school, e.g. by [[Helena Rasiowa|Rasiowa]] and also '''distributive ''i''-lattices''' by [[John Arnold Kalman|J. A. Kalman]].<ref name=\"Bez\"/> (''i''-lattice being an abbreviation for lattice with involution.) They have been further studied in the Argentinian algebraic logic school of [[Antonio Monteiro (mathematician)|Antonio Monteiro]].<ref name=\"BV\"/><ref name=\"Bez\"/>\n\nDe Morgan algebras are important for the study of the mathematical aspects of [[fuzzy logic]]. The standard fuzzy algebra ''F'' =&nbsp;([0,&nbsp;&nbsp;1],&nbsp;max(''x'',&nbsp;''y''),&nbsp;min(''x'',&nbsp;''y''),&nbsp;0,&nbsp;1,&nbsp;1&nbsp;&minus;&nbsp;''x'') is an example of a De Morgan algebra where the laws of excluded middle and noncontradiction do not hold.\n\nAnother example is [[J. Michael Dunn|Dunn]]'s 4-valued logic, in which ''false'' < ''neither-true-nor-false'' < ''true'' and ''false'' < ''both-true-and-false'' < ''true'', while ''neither-true-nor-false'' and ''both-true-and-false'' are not comparable.<ref name=\"Bez\"/>\n\n== Kleene algebra ==\nIf a De Morgan algebra additionally satisfies ''x'' ∧ ¬''x'' ≤ ''y'' ∨ ¬''y'', it is called a '''Kleene algebra'''.<ref name=\"BV\"/><ref name=\"Cignoli75\"/> (This notion should not to be confused with the other [[Kleene algebra]] generalizing regular expressions.) This notion has also been called a '''normal ''i''-lattice''' by Kalman.\n\nExamples of Kleene algebras in the sense defined above include: [[lattice-ordered group]]s, [[Post algebra]]s and [[Łukasiewicz algebra]]s.<ref name=\"Cignoli75\"/> [[Boolean algebra (structure)|Boolean algebra]]s also meet this definition of Kleene algebra. The simplest Kleene algebra that is not Boolean is Kleene's [[three-valued logic]] K<sub>3</sub>.<ref name=\"KaarliPixley2000\">{{cite book|first1=Kalle |last1=Kaarli|first2=Alden F. |last2=Pixley|title=Polynomial Completeness in Algebraic Systems|url=https://books.google.com/books?id=YVHDN_EiA0YC&pg=PA297|date=21 July 2000|publisher=CRC Press|isbn=978-1-58488-203-9|pages=297–}}</ref> K<sub>3</sub> made its first appearance in [[Stephen Cole Kleene|Kleene]]'s ''On notation for [[ordinal numbers]]'' (1938).<ref>{{cite journal |first=S. C. |last=Kleene |authorlink=Stephen Cole Kleene |title=On Notation for Ordinal Numbers |journal=The Journal of Symbolic Logic |volume=3 |number=4 |year=1938 |pages=150–155 |doi=10.2307/2267778 |jstor=2267778}}</ref> The algebra was named after Kleene by Brignole and Monteiro.<ref>{{cite journal |last1=Brignole |first1=D.  |last2=Monteiro |first2=A. |authorlink2=Antonio Monteiro (mathematician) |title=Caracterisation des algèbres de Nelson par des egalités |journal=Notas de Logica Matematica |publisher=Instituto de Matematica Universidad del sur Bahia Blanca |volume=20 |year=1964}} A (possibly abbreviated) version of this paper appeared later in ''Proceedings of the Japan Academy'': {{cite journal |title=Caracterisation des algèbres de Nelson par des egalités, I|doi=10.3792/pja/1195521624|postscript=,}} {{cite journal |title=Caracterisation des algèbres de Nelson par des egalités, II|doi=10.3792/pja/1195521625}}</ref>\n\n== Related notions ==\nDe Morgan algebra is not the only plausible way to generalize the Boolean algebra. Another way is to keep ¬''x''&nbsp;∧&nbsp;''x'' = 0 (i.e. the law of noncontradiction) but to drop the law of the excluded middle and the law of double negation. This approach (called ''semicomplementation'') is well-defined even for a [meet] [[semilattice]]; if the set of semicomplements has a [[greatest element]] it is usually called [[pseudocomplement]]. If the pseudocomplement thus defined satisfies the law of the excluded middle, the resulting algebra is also Boolean. However, if only the weaker law ¬''x''&nbsp;∨&nbsp;¬¬''x'' = 1 is required, this results in [[Stone algebra]]s.<ref name=\"BV\"/> More generally, both De Morgan and Stone algebras are proper subclasses of [[Ockham algebras]].\n\n== See also ==\n* [[orthocomplemented lattice]]\n\n==References==\n{{reflist}}\n\n==Further reading==\n* {{cite book|first1=Raymond |last1=Balbes|first2=Philip |last2=Dwinger|title=Distributive lattices|year=1975|publisher=University of Missouri Press|isbn=978-0-8262-0163-8|chapter=Chapter IX. De Morgan Algebras and Lukasiewicz Algebras}}\n* {{cite journal |last=Birkhoff |first=G. |authorlink=Garrett Birkhoff |title=Reviews: Moisil Gr. C.. ''Recherches sur l'algèbre de la logique.'' ''Annales scientifiques de l'Université de Jassy, vol. 22 (1936), pp.&nbsp;1–118'' |journal=The Journal of Symbolic Logic |volume=1 |number=2 |year=1936 |page=63 |doi=10.2307/2268551 |jstor=2268551}}\n*  {{cite journal |first=J. A. |last=Kalman |url=http://www.ams.org/journals/tran/1958-087-02/S0002-9947-1958-0095135-X/S0002-9947-1958-0095135-X.pdf |title=Lattices with involution |journal=Transactions of the American Mathematical Society |volume=87 |number=2 |year=1958 |pages=485–491 |doi=10.1090/S0002-9947-1958-0095135-X |jstor=1993112}}\n* {{cite book|first1=Piero|last1=Pagliani|first2=Mihir|last2=Chakraborty|title=A Geometry of Approximation: Rough Set Theory: Logic, Algebra and Topology of Conceptual Patterns|year=2008|publisher=Springer Science & Business Media|isbn=978-1-4020-8622-9|at=Part II. Chapter 6. Basic Logico-Algebraic Structures, pp. 193-210}}\n* {{cite book |last1=Cattaneo |first1=G. |last2=Ciucci |first2=D. |title=Lattices with Interior and Closure Operators and Abstract Approximation Spaces |series=Lecture Notes in Computer Science 67–116 |year=2009 |doi=10.1007/978-3-642-03281-3_3}}\n* {{cite book|editor1-first=S. E. |editor1-last=Rodabaugh |editor2-first=E. P. |editor2-last=Klement|title=Topological and Algebraic Structures in Fuzzy Sets: A Handbook of Recent Developments in the Mathematics of Fuzzy Sets|year=2003|publisher=Springer|isbn=978-1-4020-1515-1|first1=M. |last1=Gehrke |first2=C. |last2=Walker |first3=E. |last3=Walker|chapter=Fuzzy Logics Arising From Strict De Morgan Systems}}\n* {{cite book|first1=Maria Luisa |last1=Dalla Chiara|first2=Roberto |last2=Giuntini|first3=Richard |last3=Greechie|title=Reasoning in Quantum Theory: Sharp and Unsharp Quantum Logics|year=2004|publisher=Springer|isbn=978-1-4020-1978-4}}\n\n[[Category:Algebra]]\n[[Category:Lattice theory]]\n[[Category:Algebraic logic]]\n[[Category:Ockham algebras]]"
    },
    {
      "title": "Determinant",
      "url": "https://en.wikipedia.org/wiki/Determinant",
      "text": "{{about|determinants in mathematics|determinants in epidemiology|Risk factor|determinants in immunology|Epitope}}\nIn [[linear algebra]], the '''determinant''' is a scalar value that can be computed from the elements of a [[square matrix]] and encodes certain properties of the [[Linear map|linear transformation]] described by the matrix.  The determinant of a matrix {{math|''A''}} is denoted {{math|det(''A'')}}, {{math|det ''A''}}, or {{math|{{abs|''A''}}}}. Geometrically, it can be viewed as the volume scaling factor of the linear transformation described by the matrix. This is also the signed volume of the ''n''-dimensional [[parallelepiped]] spanned by the column or row vectors of the matrix. The determinant is positive or negative according to whether the linear mapping preserves or reverses the orientation of ''n''-space.\n\nIn the case of a {{nowrap|2 × 2}} matrix the determinant may be defined as:\n:<math>\\begin{align}|A| = \\begin{vmatrix} a & b\\\\c & d \\end{vmatrix}=ad - bc .\\end{align}</math>\n\nSimilarly, for a 3 × 3 matrix ''A'', its determinant is:\n:<math>\\begin{align}\n  |A| = \\begin{vmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{vmatrix}\n     &= a\\,\\begin{vmatrix} \\Box & \\Box & \\Box \\\\ \\Box & e & f \\\\ \\Box & h & i \\end{vmatrix} - \n        b\\,\\begin{vmatrix} \\Box & \\Box & \\Box \\\\ d & \\Box & f \\\\ g & \\Box & i \\end{vmatrix} + \n        c\\,\\begin{vmatrix} \\Box & \\Box & \\Box \\\\ d & e & \\Box \\\\ g & h & \\Box \\end{vmatrix} \\\\[3pt]\n     &= a\\,\\begin{vmatrix} e & f \\\\ h & i \\end{vmatrix} - \n        b\\,\\begin{vmatrix} d & f \\\\ g & i \\end{vmatrix} + \n        c\\,\\begin{vmatrix} d & e \\\\ g & h \\end{vmatrix} \\\\[3pt]\n     &= aei + bfg + cdh - ceg - bdi - afh.\n\\end{align}</math>\n\nEach determinant of a {{nowrap|2 × 2}} matrix in this equation is called a \"[[minor (linear algebra)|minor]]\" of the matrix {{math|''A''}}.  This procedure can be extended to give a recursive definition for the determinant of an {{nowrap|n × n}} matrix, the ''minor expansion formula''.\n\nDeterminants occur throughout mathematics. For example, a matrix is often used to represent the [[coefficient]]s in a [[system of linear equations]], and the determinant can be used to [[Cramer's rule|solve]] those equations, although other methods of solution are much more computationally efficient. In linear algebra, a matrix (with entries in a [[Field (mathematics)|field]]) is [[Inverse matrix|invertible]] (also called nonsingular) [[If and only if|if and only if]] its determinant is non-zero, and correspondingly the matrix is singular if and only if its determinant is zero. This leads to the use of determinants in defining the [[characteristic polynomial]] of a matrix, whose roots are the [[eigenvalue]]s. In analytic geometry, determinants express the signed ''n''-dimensional volumes of ''n''-dimensional parallelepipeds. This leads to the use of determinants in [[calculus]], the [[Jacobian matrix and determinant|Jacobian determinant]] in the [[change of variables]] rule for integrals of functions of several variables. Determinants appear frequently in algebraic identities such as the [[Vandermonde identity]].\n\nDeterminants possess many algebraic properties, including that the determinant of a [[matrix multiplication|product of matrices]] is equal to the product of determinants. Special types of matrices have special determinants; for example, the determinant of an [[orthogonal matrix]] is always plus or minus one, and the determinant of a complex [[Hermitian matrix]] is always [[real number|real]].\n\n==Geometric meaning==\nIf an {{nowrap|''n'' × ''n''}} [[Real number|real]] matrix ''A'' is written in terms of its column vectors <math>A = [\\begin{array}{c|c|c|c} \\mathbf{a}_1 & \\mathbf{a}_2 & \\cdots & \\mathbf{a}_n\\end{array}]</math> then \n:<math>\n  A\\begin{pmatrix}1 \\\\ 0\\\\ \\vdots \\\\0\\end{pmatrix} = \\mathbf{a}_1, \\quad\n  A\\begin{pmatrix}0 \\\\ 1\\\\ \\vdots \\\\0\\end{pmatrix} = \\mathbf{a}_2, \\quad\n                                                         \\ldots, \\quad\n  A\\begin{pmatrix}0 \\\\0 \\\\ \\vdots \\\\1\\end{pmatrix} = \\mathbf{a}_n. \n</math>\n\nThis means that <math>A</math> maps the unit [[Hypercube|''n''-cube]] to the ''n''-dimensional [[parallelepiped#Parallelotope|parallelotope]] defined by the vectors <math>\\mathbf{a}_1, \\mathbf{a}_2, \\ldots,  \\mathbf{a}_n,</math> the region <math>P = \\left\\{c_1 \\mathbf{a}_1 + \\cdots + c_n\\mathbf{a}_n \\mid 0 \\leq c_i\\leq 1 \\ \\forall i\\right\\}.</math>\n\nThe determinant gives the [[orientation (vector space)|signed]] ''n''-dimensional volume of this parallelotope, <math>\\det(A) = \\pm \\text{vol}(P),</math> and hence describes more generally the ''n''-dimensional volume scaling factor of the [[linear transformation]] produced by ''A''.<ref>{{cite web|url=https://textbooks.math.gatech.edu/ila/determinants-volumes.html|title=Determinants and Volumes|author=|date=|website=textbooks.math.gatech.edu|accessdate=16 March 2018}}</ref> (The sign shows whether the transformation preserves or reverses [[Orientation (vector space)|orientation]].) In particular, if the determinant is zero, then this parallelotope has volume zero and is not fully ''n''-dimensional, which indicates that the dimension of the image of ''A'' is less than ''n''. This [[Rank–nullity theorem|means]] that ''A'' produces a linear transformation which is neither [[surjective function|onto]] nor [[Injective function|one-to-one]], and so is not invertible.\n\n== Definition ==\nThere are various equivalent ways to define the determinant of a [[square matrix]] ''A'', i.e. one with the same number of rows and columns.  Perhaps the simplest way to express the determinant is by considering the elements in the top row and the respective [[minor (linear algebra)|minors]]; starting at the left, multiply the element by the minor, then subtract the product of the next element and its minor, and alternate adding and subtracting such products until all elements in the top row have been exhausted.  For example, here is the result for a 4 × 4 matrix:\n:<math>\n  \\begin{vmatrix} a & b & c & d\\\\ e & f & g & h\\\\ i & j & k & l\\\\ m & n & o & p \\end{vmatrix} =\n  a\\,\\begin{vmatrix} f & g & h\\\\ j & k & l\\\\ n & o & p \\end{vmatrix} -\n    b\\,\\begin{vmatrix} e & g & h\\\\ i & k & l\\\\ m & o & p \\end{vmatrix} +\n    c\\,\\begin{vmatrix} e & f & h\\\\ i & j & l\\\\ m & n & p \\end{vmatrix} -\n    d\\,\\begin{vmatrix} e & f & g\\\\ i & j & k\\\\ m & n & o \\end{vmatrix}.\n</math>\nAnother way to define the determinant is expressed in terms of the columns of the matrix.  If we write an {{nowrap|''n'' × ''n''}} matrix ''A'' in terms of its column vectors\n: <math>A = \\begin{bmatrix} a_1 & a_2 & \\cdots & a_n \\end{bmatrix}</math>\n\nwhere the <math>a_j</math> are vectors of size ''n'', then the determinant of ''A'' is defined so that\n:<math>\\begin{align}\n  \\det \\begin{bmatrix} a_1 & \\cdots & b a_j + c v & \\cdots & a_n \\end{bmatrix}\n          &= b\\det(A) + c \\det \\begin{bmatrix} a_1 & \\cdots & v & \\cdots & a_n \\end{bmatrix} \\\\\n  \\det \\begin{bmatrix} a_1 & \\cdots & a_j & a_{j+1} & \\cdots & a_n \\end{bmatrix}\n          &= -\\det \\begin{bmatrix} a_1 & \\cdots & a_{j+1} & a_j & \\cdots & a_n \\end{bmatrix} \\\\\n  \\det(I) &= 1\n\\end{align}</math>\n\nwhere ''b'' and ''c'' are scalars, ''v'' is any vector of size ''n'' and ''I'' is the [[identity matrix]] of size ''n''.  These equations say that the determinant is a linear function of each column, that interchanging adjacent columns reverses the sign of the determinant, and that the determinant of the identity matrix is 1. These properties mean that the determinant is an alternating multilinear function of the columns that maps the identity matrix to the underlying unit scalar.  These suffice to uniquely calculate the determinant of any square matrix. Provided the underlying scalars form a field (more generally, a commutative ring with unity), the definition below shows that such a function exists, and it can be shown to be unique.<ref>[[Serge Lang]], ''Linear Algebra'', 2nd Edition, Addison-Wesley, 1971, pp 173, 191.</ref>\n\nEquivalently, the determinant can be expressed as a sum of products of entries of the matrix where each product has ''n'' terms and the coefficient of each product is −1 or 1 or 0 according to a given rule: it is a [[polynomial expression]] of the matrix entries. This expression grows rapidly with the size of the matrix (an {{nowrap|''n'' × ''n''}} matrix contributes [[Factorial|''n''!]] terms), so it will first be given explicitly for the case of {{nowrap|2 × 2}} matrices and {{nowrap|3 × 3}} matrices, followed by the rule for arbitrary size matrices, which subsumes these two cases.\n\nAssume ''A'' is a square matrix with ''n'' rows and ''n'' columns, so that it can be written as\n:<math>A = \\begin{bmatrix}\n  a_{1,1} & a_{1,2} &  \\dots & a_{1,n} \\\\\n  a_{2,1} & a_{2,2} &  \\dots & a_{2,n} \\\\\n   \\vdots &  \\vdots & \\ddots &  \\vdots \\\\\n  a_{n,1} & a_{n,2} &  \\dots & a_{n,n}\n\\end{bmatrix}.</math>\n\nThe entries can be numbers or expressions (as happens when the determinant is used to define a [[characteristic polynomial]]); the definition of the determinant depends only on the fact that they can be added and multiplied together in a [[Commutativity|commutative]] manner.\n\nThe determinant of ''A'' is denoted by det(''A''), or it can be denoted directly in terms of the matrix entries by writing enclosing bars instead of brackets:\n:<math>\\begin{vmatrix}\n  a_{1,1} & a_{1,2} &  \\dots & a_{1,n} \\\\\n  a_{2,1} & a_{2,2} &  \\dots & a_{2,n} \\\\\n   \\vdots &  \\vdots & \\ddots &  \\vdots \\\\\n  a_{n,1} & a_{n,2} &  \\dots & a_{n,n}\n\\end{vmatrix}.</math>\n\n=== 2 × 2 matrices ===\n[[File:Area parallellogram as determinant.svg|thumb|right|The area of the parallelogram is the absolute value of the determinant of the matrix formed by the vectors representing the parallelogram's sides.]]\nThe [[Leibniz formula for determinants|Leibniz formula]] for the determinant of a {{nowrap|2 × 2}} matrix is\n:<math>\\begin{vmatrix} a & b \\\\c & d \\end{vmatrix} = ad - bc.</math>\n\nIf the matrix entries are real numbers, the matrix ''A'' can be used to represent two [[linear map]]s:  one that maps the [[standard basis]] vectors to the rows of ''A'', and one that maps them to the columns of ''A''.  In either case, the images of the basis vectors form a [[parallelogram]] that represents the image of the [[unit square]] under the mapping.  The parallelogram defined by the rows of the above matrix is the one with vertices at {{nowrap|(0, 0)}}, {{nowrap|(''a'', ''b'')}}, {{nowrap|(''a'' + ''c'', ''b'' + ''d'')}}, and {{nowrap|(''c'', ''d'')}}, as shown in the accompanying diagram.\n\nThe absolute value of {{nowrap|''ad'' − ''bc''}} is the area of the parallelogram, and thus represents the scale factor by which areas are transformed by ''A''. (The parallelogram formed by the columns of ''A'' is in general a different parallelogram, but since the determinant is symmetric with respect to rows and columns, the area will be the same.)\n\nThe absolute value of the determinant together with the sign becomes the ''oriented area'' of the parallelogram. The oriented area is the same as the usual [[area (geometry)|area]], except that it is negative when the angle from the first to the second vector defining the parallelogram turns in a clockwise direction (which is opposite to the direction one would get for the [[identity matrix]]).\n\nTo show that {{nowrap|''ad'' − ''bc''}} is the signed area, one may consider a matrix containing two vectors {{nowrap|1='''a''' = (''a'', ''b'')}} and {{nowrap|1='''b''' = (''c'', ''d'')}} representing the parallelogram's sides. The signed area can be expressed as {{nowrap|{{!}}'''a'''{{!}}{{!}}'''b'''{{!}}sin''θ''}} for the angle ''θ'' between the vectors, which is simply base times height, the length of one vector times the perpendicular component of the other. Due to the [[sine]] this already is the signed area, yet it may be expressed more conveniently using the [[cosine]] of the complementary angle to a perpendicular vector, e.g. {{nowrap|1='''a'''<sup>⊥</sup> = (−''b'', ''a'')}}, such that {{nowrap|{{!}}'''a'''<sup>⊥</sup>{{!}}{{!}}'''b'''{{!}}cos''θ' ''}}, which can be determined by the pattern of the [[scalar product]] to be equal to {{nowrap|''ad'' − ''bc''}}:\n\n: <math>\\text{Signed area} =\n  |\\boldsymbol{a}| |\\boldsymbol{b}|\\sin\\theta = \\left|\\boldsymbol{a}^\\perp\\right| |\\boldsymbol{b}|\\cos\\theta' =\n  \\begin{pmatrix} -b \\\\ a \\end{pmatrix} \\cdot \\begin{pmatrix} c \\\\ d \\end{pmatrix} = ad - bc.\n</math>\n\nThus the determinant gives the scaling factor and the orientation induced by the mapping represented by ''A''. When the determinant is equal to one, the linear mapping defined by the matrix is [[Equiareal map|equi-areal]] and orientation-preserving.\n\nThe object known as the ''[[bivector]]'' is related to these ideas. In 2D, it can be interpreted as an ''oriented plane segment'' formed by imagining two vectors each with origin {{nowrap|(0, 0)}}, and coordinates {{nowrap|(''a'', ''b'')}} and {{nowrap|(''c'', ''d'')}}. The bivector magnitude (denoted by {{nowrap|(''a'', ''b'') ∧ (''c'', ''d'')}}) is the ''signed area'', which is also the determinant {{nowrap|''ad'' − ''bc''}}.<ref>[https://www.youtube.com/watch?v=6XghF70fqkY WildLinAlg episode 4], Norman J Wildberger, Univ. of New South Wales, 2010, lecture via youtube</ref>\n\n=== 3 × 3 matrices ===\n[[File:Determinant parallelepiped.svg|300px|right|thumb|The volume of this [[parallelepiped]] is the absolute value of the determinant of the matrix formed by the rows constructed from the vectors r1, r2, and r3.]]\n\nThe [[Laplace expansion|Laplace formula]] for the determinant of a {{nowrap|3 × 3}} matrix is\n\n:<math>\n   \\begin{vmatrix}a&b&c\\\\ d&e&f\\\\ g&h&i\\end{vmatrix} =\n  a\\begin{vmatrix}e&f\\\\ h&i\\end{vmatrix} - b\\begin{vmatrix}d&f\\\\ g&i\\end{vmatrix} + c\\begin{vmatrix}d&e\\\\ g&h\\end{vmatrix}\n</math>\n\nthis can be expanded out to give\n\n:<math>\\begin{align}\n  \\begin{vmatrix}a&b&c\\\\d&e&f\\\\g&h&i\\end{vmatrix}\n    &= a(ei - fh) - b(di - fg) + c(dh - eg) \\\\\n    &= aei + bfg + cdh - ceg - bdi - afh.\n\\end{align}</math>\n\nwhich is the [[Leibniz formula for determinants|Leibniz formula]] for the determinant of a {{nowrap|3 × 3}} matrix.\n\n[[File:Sarrus rule.svg|thumb|left|upright=1.25|''Sarrus' rule'': The determinant of the three columns on the left is the sum of the products along the solid diagonals minus the sum of the products along the dashed diagonals]]\n\nThe [[rule of Sarrus]] is a mnemonic for the {{nowrap|3 × 3}} matrix determinant: the sum of the products of three diagonal north-west to south-east lines of matrix elements, minus the sum of the products of three diagonal south-west to north-east lines of elements, when the copies of the first two columns of the matrix are written beside it as in the illustration. This scheme for calculating the determinant of a {{nowrap|3 × 3}} matrix does not carry over into higher dimensions.\n\n=== ''n'' × ''n'' matrices ===\nThe determinant of a matrix of arbitrary size can be defined by the [[Leibniz formula for determinants|Leibniz formula]] or the [[Laplace expansion|Laplace formula]].\n\nThe Leibniz formula for the determinant of an {{nowrap|''n'' × ''n''}} matrix ''A'' is\n\n:<math>\\det(A) = \\sum_{\\sigma \\in S_n} \\left( \\sgn(\\sigma) \\prod_{i=1}^n a_{i,\\sigma_i}\\right).</math>\n\nHere the sum is computed over all [[permutation]]s σ of the set {{nowrap|{1, 2, …, ''n''}.}} A permutation is a function that reorders this set of integers. The value in the ''i<sup>th</sup>'' position after the reordering σ is denoted by σ<sub>''i''</sub>. For example, for {{nowrap|1=''n'' = 3}}, the original sequence 1, 2, 3 might be reordered to {{nowrap|1=σ = [2, 3, 1]}}, with {{nowrap|1=σ<sub>1</sub> = 2}}, {{nowrap|1=σ<sub>2</sub> = 3}}, and {{nowrap|1=σ<sub>3</sub> = 1}}.  The set of all such permutations (also known as the [[symmetric group]] on ''n'' elements) is denoted by S<sub>''n''</sub>. For each permutation σ, sgn(σ) denotes the [[signature (permutation)|signature]] of σ, a value that is +1 whenever the reordering given by σ can be achieved by successively interchanging two entries an even number of times, and −1 whenever it can be achieved by an odd number of such interchanges.\n\nIn any of the <math>n!</math> summands, the term\n\n:<math>\\prod_{i=1}^n a_{i, \\sigma_i}</math>\n\nis notation for the product of the entries at positions {{nowrap|(''i'', σ<sub>''i''</sub>)}}, where ''i'' ranges from 1 to ''n'':\n\n:<math>a_{1,\\sigma_1} \\cdot a_{2,\\sigma_2} \\cdots  a_{n,\\sigma_n}.</math>\n\nFor example, the determinant of a {{nowrap|3 × 3}} matrix ''A'' ({{nowrap|1=''n'' = 3}}) is\n\n:<math>\\begin{align}\n      &\\sum_{\\sigma \\in S_n} \\sgn(\\sigma) \\prod_{i=1}^n a_{i,\\sigma_i} \\\\\n  ={} &\\sgn([1,2,3]) \\prod_{i=1}^n a_{i,[1,2,3]_i} + \\sgn([1,3,2]) \\prod_{i=1}^n a_{i,[1,3,2]_i} + \\sgn([2,1,3]) \\prod_{i=1}^n a_{i,[2,1,3]_i} +{} \\\\\n      &\\sgn([2,3,1]) \\prod_{i=1}^n a_{i,[2,3,1]_i} + \\sgn([3,1,2]) \\prod_{i=1}^n a_{i,[3,1,2]_i} + \\sgn([3,2,1]) \\prod_{i=1}^n a_{i,[3,2,1]_i} \\\\\n  ={} &\\prod_{i=1}^n a_{i,[1,2,3]_i} - \\prod_{i=1}^n a_{i,[1,3,2]_i} - \\prod_{i=1}^n a_{i,[2,1,3]_i} + \\prod_{i=1}^n a_{i,[2,3,1]_i} + \\prod_{i=1}^n a_{i,[3,1,2]_i} - \\prod_{i=1}^n a_{i,[3,2,1]_i} \\\\[2pt]\n  ={} & a_{1,1}a_{2,2}a_{3,3} - a_{1,1}a_{2,3}a_{3,2} - a_{1,2}a_{2,1}a_{3,3} +\n        a_{1,2}a_{2,3}a_{3,1} + a_{1,3}a_{2,1}a_{3,2} - a_{1,3}a_{2,2}a_{3,1}.\n\\end{align}</math>\n\n==== Levi-Civita symbol ====\nIt is sometimes useful to extend the Leibniz formula to a summation in which not only permutations, but all sequences of ''n'' indices in the  range {{nowrap|1, …, ''n''}} occur, ensuring that the contribution of a sequence will be zero unless it denotes a permutation. Thus the totally antisymmetric [[Levi-Civita symbol]] <math>\\varepsilon_{i_1,\\cdots,i_n}</math> extends the signature of a permutation, by setting <math>\\varepsilon_{\\sigma(1),\\cdots,\\sigma(n)} = \\operatorname{sgn}(\\sigma)</math> for any permutation σ of ''n'', and <math>\\varepsilon_{i_1,\\cdots,i_n} = 0</math> when no permutation σ exists such that <math>\\sigma(j) = i_j</math> for <math>j=1,\\ldots,n</math> (or equivalently, whenever some pair of indices are equal). The determinant for an {{nowrap|''n'' × ''n''}} matrix can then be expressed using an ''n''-fold summation as\n:<math>\\det(A) = \\sum_{i_1,i_2,\\ldots,i_n=1}^n \\varepsilon_{i_1\\cdots i_n} a_{1,i_1} \\cdots a_{n,i_n},</math>\n\nor using two epsilon symbols as\n:<math> \\det(A) = \\frac{1}{n!}\\sum\\varepsilon_{i_1\\cdots i_n} \\varepsilon_{j_1\\cdots j_n} a_{i_1 j_1} \\cdots a_{i_n j_n},</math>\n\nwhere now each ''i<sub>r</sub>'' and each ''j<sub>r</sub>'' should be summed over {{nowrap|1, …, ''n''}}.\n\nHowever, through the use of tensor notation and the supression of the summation symbol (Einstein's summation convention) we can obtain a much more compact expression of the determinant of the second order system of <math>n=3</math> dimensions, <math>a^m_n</math>;\n\n:<math>\\det(a^m_n)e_{rst} = e_{ijk}a_r^i a_s^j a_t^k</math>\n\nwhere <math>e_{rst}</math> and <math>e_{ijk}</math> represent 'e-systems' that take on the values 0, +1 and -1 given the number of permutations of <math>ijk</math> and <math>rst</math>. More specifically, <math>e_{ijk}</math> is equal to 0 when there is a repeated index in <math>ijk</math>; +1 when an even number of permutations of <math>ijk</math> is present; -1 when an odd number of permutations of <math>ijk</math> is present. Note, that the number of indices present in the e-systems is equal to <math>n</math> and thus can be generalized in this manner <ref>{{cite book |last1=McConnell |title=Applications of Tensor Analysis |date=1957 |publisher=Dover Publications |pages=10-17}}</ref>.\n\n== Properties of the determinant ==\nThe determinant has many properties. Some basic properties of determinants are\n\n# <math>\\det\\left(I_n\\right) = 1</math> where ''I''<sub>''n''</sub> is the {{nowrap|''n'' × ''n''}} [[identity matrix]].\n# <math>\\det\\left(A^\\textsf{T}\\right) = \\det(A),</math> where <math>A^\\textsf{T}</math> denotes the [[transpose]] of <math>A</math>.\n# <math>\\det\\left(A^{-1}\\right) = \\frac{1}{\\det(A)} = \\det(A)^{-1}.</math>\n# For square matrices ''A'' and ''B'' of equal size,\n#: <math>\\det(AB) = \\det(A)\\det(B).</math>\n# <li value=\"5\"><math>\\det(cA) = c^n\\det(A)</math> for an {{nowrap|''n'' × ''n''}} matrix, A. \n# For [[positive-definite matrix|positive semidefinite matrices]] ''A'', ''B'', and ''C'' of equal size, <math>\\det(A + B + C) + \\det(C) \\geq \\det(A + C) + \\det(B + C)</math>, for <math>A,B,C \\geq 0</math> with the corollary <math>\\det(A + B) \\geq \\det(A) + \\det(B).</math><ref>{{cite arxiv|last1=Lin|first1=Minghua|last2=Sra|first2=Suvrit|title=Completely strong superadditivity of generalized matrix functions|eprint=1410.1958|class=math.FA|year=2014}}</ref><ref>{{cite journal|last1=Paksoy|last2=Turkmen|last3=Zhang|title=Inequalities of Generalized Matrix Functions via Tensor Products|journal=Electronic Journal of Linear Algebra|date=4-1-2014|volume=27|doi=10.13001/1081-3810.1622}}</ref>\n# If ''A'' is a [[triangular matrix]], i.e. {{nowrap|1=''a''<sub>''i'',''j''</sub> = 0}} whenever {{nowrap|''i'' > ''j''}} or, alternatively, whenever {{nowrap|''i'' < ''j''}}, then its determinant equals the product of the diagonal entries:\n#:<math>\\det(A) = a_{1,1} a_{2,2} \\cdots a_{n,n} = \\prod_{i=1}^n a_{i,i}.</math>\n\nThis can be deduced from some of the properties below, but it follows most easily directly from the Leibniz formula (or from the Laplace expansion), in which the identity permutation is the only one that gives a non-zero contribution.\n\nA number of additional properties relate to the effects on the determinant of changing particular rows or columns:\n# <li value=\"8\">Viewing an <math>n\\times n</math> matrix as being composed of <math>n</math> columns, the determinant is an [[multilinear map|''n''-linear function]]. This means that if the <math>j^{th}</math> column of a matrix <math>A</math> is written as a sum <math>\\mathbf a_j = \\mathbf v + \\mathbf w</math> of two [[column vector]]s, and all other columns are left unchanged, then the determinant of <math>A</math> is the sum of the determinants of the matrices obtained from <math>A</math> by replacing the <math>j^{th}</math> column by <math>\\mathbf v</math> (denoted <math>A_v</math>) and then by <math>\\mathbf{w}</math> (denoted <math>A_w</math>) (and a similar relation holds when writing a column as a scalar multiple of a column vector).\n#: <math>\\begin{align}\\det(A)\n  &= \\det([\\mathbf{a}_1|\\dots|\\mathbf{a}_j|\\dots|\\mathbf{a}_n]) \\\\\n  &= \\det([\\dots|\\mathbf{v} + \\mathbf{w}|\\dots]) \\\\\n  &= \\det([\\dots|\\mathbf{v}|\\dots]) + \\det([\\dots|\\mathbf{w}|\\dots]) \\\\\n  &= \\det\\left(A_v\\right) + \\det\\left(A_w\\right)\n\\end{align}</math>\n# <li value=\"9\">If in a matrix, any row or column has all elements equal to zero, then the determinant of that matrix is 0.\n# This ''n''-linear function is an [[alternating form]]. This means that whenever two columns of a matrix are identical, or more generally some column can be expressed as a linear combination of the other columns (i.e. the columns of the matrix form a [[Linearly independent|linearly dependent]] set), its determinant is 0.\n\nProperties 1, 8 and 10 — which all follow from the Leibniz formula — completely characterize the determinant; in other words the determinant is the unique function from {{nowrap|''n'' × ''n''}} matrices to scalars that is ''n''-linear alternating in the columns, and takes the value 1 for the identity matrix (this characterization holds even if scalars are taken in any given [[commutative ring]]). To see this it suffices to expand the determinant by multi-linearity in the columns into a (huge) linear combination of determinants of matrices in which each column is a [[standard basis]] vector. These determinants are either 0 (by property&nbsp;9) or else ±1 (by properties 1 and&nbsp;12 below), so the linear combination gives the expression above in terms of the Levi-Civita symbol. While less technical in appearance, this characterization cannot entirely replace the Leibniz formula in defining the determinant, since without it the existence of an appropriate function is not clear. For matrices over non-commutative rings, properties 8 and 9 are incompatible for {{nowrap|''n'' ≥ 2}},<ref>In a non-commutative setting left-linearity (compatibility with left-multiplication by scalars) should be distinguished from right-linearity. Assuming linearity in the columns is taken to be left-linearity, one would have, for non-commuting scalars ''a'', ''b'':\n:<math>ab =\n  ab \\left|\\begin{matrix}1&0 \\\\ 0&1\\end{matrix} \\right| =\n   a \\left|\\begin{matrix}1&0 \\\\ 0&b\\end{matrix} \\right| =\n     \\left|\\begin{matrix}a&0 \\\\ 0&b\\end{matrix} \\right| =\n   b \\left|\\begin{matrix}a&0 \\\\ 0&1\\end{matrix} \\right| =\n  ba \\left|\\begin{matrix}1&0 \\\\ 0&1\\end{matrix} \\right|= ba,\n</math>\n\na contradiction. There is no useful notion of multi-linear functions over a non-commutative ring.</ref> so there is no good definition of the determinant in this setting.\n\nProperty 2 above implies that properties for columns have their counterparts in terms of rows:\n# <li value=\"11\">Viewing an {{nowrap|''n'' × ''n''}} matrix as being composed of ''n'' rows, the determinant is an ''n''-linear function.\n# This ''n''-linear function is an alternating form: whenever two rows of a matrix are identical, its determinant is 0.\n# Interchanging any pair of columns or rows of a matrix multiplies its determinant by&nbsp;−1. This follows from properties 8 and 10 (it is a general property of multilinear alternating maps). More generally, any permutation of the rows or columns multiplies the determinant by the [[parity of a permutation|sign]] of the permutation. By permutation, it is meant viewing each row as a vector '''R'''<sub>''i''</sub> (equivalently each column as '''C'''<sub>''i''</sub>) and reordering the rows (or columns) by interchange of '''R'''<sub>''j''</sub> and '''R'''<sub>''k''</sub> (or '''C'''<sub>''j''</sub> and '''C'''<sub>''k''</sub>), where ''j'',''k'' are two indices chosen from 1 to ''n'' for an {{nowrap|''n'' × ''n''}} square matrix.\n# Adding a scalar multiple of one column to ''another'' column does not change the value of the determinant. This is a consequence of properties 8 and 10 in the following way: by property&nbsp;8 the determinant changes by a multiple of the determinant of a matrix with two equal columns, which determinant is 0 by property&nbsp;10. Similarly, adding a scalar multiple of one row to another row leaves the determinant unchanged.\n</li>\n\nProperty 5 says that the determinant on {{nowrap|''n'' × ''n''}} matrices is [[Homogeneous function|homogeneous]] of degree ''n''. These properties can be used to facilitate the computation of determinants by simplifying the matrix to the point where the determinant can be determined immediately. Specifically, for matrices with coefficients in a [[field (mathematics)|field]], properties 13 and 14 can be used to transform any matrix into a triangular matrix, whose determinant is given by property&nbsp;7; this is essentially the method of [[Gaussian elimination]].\n\nFor example, the determinant of\n\n:<math>A = \\begin{bmatrix}\n  -2 & 2 & -3 \\\\\n  -1 & 1 &  3 \\\\\n   2 & 0 & -1\n\\end{bmatrix} </math>\n\ncan be computed using the following matrices:\n:<math>\n  B = \\begin{bmatrix}\n    -2 & 2 & -3\\\\\n     0 & 0 &  4.5\\\\\n     2 & 0 & -1\n  \\end{bmatrix},\\quad\n  C = \\begin{bmatrix}\n    -2 & 2 & -3\\\\\n     0 & 0 &  4.5\\\\\n     0 & 2 & -4\n  \\end{bmatrix},\\quad\n  D = \\begin{bmatrix}\n    -2 & 2 & -3\\\\\n     0 & 2 & -4\\\\\n     0 & 0 &  4.5\n  \\end{bmatrix}.\n</math>\n\nHere, ''B'' is obtained from ''A'' by adding −1/2×the first row to the second, so that {{nowrap|1=det(''A'') = det(''B'')}}. ''C'' is obtained from ''B'' by adding the first to the third row, so that {{nowrap|1=det(''C'') = det(''B'')}}. Finally, ''D'' is obtained from ''C'' by exchanging the second and third row, so that {{nowrap|1=det(''D'') = −det(''C'')}}. The determinant of the (upper) triangular matrix ''D'' is the product of its entries on the [[main diagonal]]: {{nowrap|1=(−2) · 2 · 4.5 = −18}}. Therefore, {{nowrap|1=det(''A'') = −det(''D'') = +18}}.\n\n=== Schur complement ===\nThe following identity holds for a [[Schur complement]] of a square [[Matrix (mathematics)|matrix]]:\n\nThe Schur complement arises as the result of performing a block [[Gaussian elimination]] by multiplying the matrix ''M'' from the right with a ''block lower triangular'' matrix\n:<math>L = \\left[\\begin{matrix} I_p & 0 \\\\ -D^{-1}C & I_q \\end{matrix}\\right].</math>\n\nHere ''I''<sub>''p''</sub> denotes a ''p''&#xD7;''p'' [[identity matrix]]. After multiplication with the matrix ''L'' the Schur complement appears in the upper ''p''&#xD7;''p'' block. The product matrix is\n:<math>\\begin{align}\n  ML &= \\left[\\begin{matrix} A & B \\\\ C & D \\end{matrix}\\right]\\left[\\begin{matrix} I_p & 0 \\\\ -D^{-1}C & I_q \\end{matrix}\\right] = \\left[\\begin{matrix} A - BD^{-1}C & B \\\\ 0 & D \\end{matrix}\\right] \\\\\n     &= \\left[\\begin{matrix} I_p & BD^{-1} \\\\ 0 & I_q \\end{matrix}\\right] \\left[\\begin{matrix} A - BD^{-1}C & 0 \\\\ 0 & D \\end{matrix}\\right].\n\\end{align}</math>\n\nThat is, we have effected a Gaussian decomposition\n:<math>\n  \\left[\\begin{matrix} A & B \\\\ C & D \\end{matrix}\\right] =\n  \\left[\\begin{matrix} I_p & BD^{-1} \\\\ 0 & I_q \\end{matrix}\\right]\n    \\left[\\begin{matrix} A-BD^{-1}C & 0 \\\\ 0 & D \\end{matrix}\\right]\n    \\left[\\begin{matrix} I_p & 0 \\\\ D^{-1}C & I_q \\end{matrix}\\right],\n</math>\n\nThe first and last matrices on the RHS have determinant unity,  so we have\n:<math>\n  {\\rm det}\\left|\\begin{matrix} A & B \\\\ C & D \\end{matrix}\\right| =\n  {\\rm det}|D|\\,{\\rm det} \\left|A - BD^{-1} C\\right|.\n</math>\n\nThis is Schur's determinant identity.\n\n=== Multiplicativity and matrix groups ===\nThe determinant of a [[matrix product]] of square matrices equals the product of their determinants:\n:<math>\\det(AB) = \\det (A) \\det (B).</math>\n\nThus the determinant is a ''multiplicative map''. This property is a consequence of the characterization given above of the determinant as the unique ''n''-linear alternating function of the columns with value&nbsp;1 on the identity matrix, since the function {{nowrap|M<sub>''n''</sub>(''K'') → ''K''}} that maps {{nowrap|''M'' ↦ det(''AM'')}} can easily be seen to be ''n''-linear and alternating in the columns of ''M'', and takes the value det(''A'') at the identity. The formula can be generalized  to (square) products of rectangular matrices, giving the [[Cauchy–Binet formula]], which also provides an independent proof of the multiplicative property.\n\nThe determinant det(''A'') of a matrix ''A'' is non-zero if and only if ''A'' is invertible or, yet another equivalent statement, if its [[rank (linear algebra)|rank]] equals the size of the matrix. If so, the determinant of the inverse matrix is given by\n:<math>\\det\\left(A^{-1}\\right) = \\frac{1}{\\det(A)}.</math>\n\nIn particular, products and inverses of matrices with determinant one still have this property. Thus, the set of such matrices (of fixed size ''n'') form a group known as the [[special linear group]]. More generally, the word \"special\" indicates the subgroup of another [[matrix group]] of matrices of determinant one. Examples include the [[special orthogonal group]] (which if ''n'' is 2 or 3 consists of all [[rotation matrix|rotation matrices]]), and the [[special unitary group]].\n\n=== Laplace's formula and the adjugate matrix ===\n[[Laplace expansion|Laplace's formula]] expresses the determinant of a matrix in terms of its [[minor (matrix)|minors]]. The minor ''M''<sub>''i'',''j''</sub> is defined to be the determinant of the {{nowrap|(''n''−1) × (''n''−1)}}-matrix that results from ''A'' by removing the ''i''-th row and the ''j''-th column. The expression {{nowrap|(−1)<sup>''i'' + ''j''</sup>''M''<sub>''i'',''j''</sub>}} is known as a [[cofactor (linear algebra)|cofactor]]. The determinant of ''A'' is given by\n\n:<math>\\det(A) = \\sum_{j=1}^n (-1)^{i+j} a_{i,j} M_{i,j}</math> (for a fixed <math>i</math>) <math>= \\sum_{i=1}^n (-1)^{i+j} a_{i,j} M_{i,j}</math> (for a fixed <math>j</math>)\n\nCalculating det(''A'') by means of this formula is referred to as expanding the determinant along a row, the ''i''-th row using the first form with fixed ''i'', or expanding along a column, using the second form with fixed ''j''. For example, the Laplace expansion of the {{nowrap|3 × 3}} matrix\n:<math>A = \\begin{bmatrix}\n -2 & 2 & -3\\\\\n -1 & 1 &  3\\\\\n  2 & 0 & -1\n\\end{bmatrix},</math>\n\nalong the second column ({{nowrap|1=''j'' = 2}} and the sum runs over ''i'') is given by,\n{| border=\"0\"\n|-\n|<math>\\det(A)</math>\n|<math>=</math>\n|<math>(-1)^{1+2}\\cdot 2 \\cdot \\begin{vmatrix}-1&3\\\\ 2 &-1\\end{vmatrix} + (-1)^{2+2}\\cdot 1 \\cdot \\begin{vmatrix}-2&-3\\\\ 2&-1\\end{vmatrix} + (-1)^{3+2}\\cdot 0 \\cdot \\begin{vmatrix}-2&-3\\\\ -1&3\\end{vmatrix} </math>\n|-\n|\n|<math>=</math>\n|<math>(-2)\\cdot((-1)\\cdot(-1)-2\\cdot3)+1\\cdot((-2)\\cdot(-1)-2\\cdot(-3))</math>\n|-\n|\n|<math>=</math>\n|<math>(-2)\\cdot(-5)+8 = 18.</math>\n|-\n|\n|}\n\nHowever, Laplace expansion is efficient for small matrices only.\n\nThe [[adjugate matrix]] adj(''A'') is the transpose of the matrix consisting of the cofactors, i.e.,\n:<math>(\\operatorname{adj}(A))_{i,j} = (-1)^{i+j} M_{j,i}.</math>\n\nIn terms of the adjugate matrix, Laplace's expansion can be written as<ref>§&nbsp;0.8.2 of R. A. Horn & C. R. Johnson: ''Matrix Analysis'' 2nd ed. (2013) Cambridge University Press. {{ISBN|978-0-521-54823-6}}.</ref>\n:<math>(\\operatorname{det}A) I = A\\,\\operatorname{adj}A = (\\operatorname{adj}A)\\,A. </math>\n\n=== Sylvester's determinant theorem ===\n[[Sylvester's determinant theorem]] states that for ''A'', an {{nowrap|''m'' × ''n''}} matrix, and ''B'', an {{nowrap|''n'' × ''m''}} matrix (so that ''A'' and ''B'' have dimensions allowing them to be multiplied in either order forming a square matrix):\n\n:<math>\\det\\left(I_\\mathit{m} + AB\\right) = \\det\\left(I_\\mathit{n} + BA\\right)</math>,\n\nwhere ''I''<sub>''m''</sub> and ''I''<sub>''n''</sub> are the {{nowrap|''m'' × ''m''}} and {{nowrap|''n'' × ''n''}} identity matrices, respectively.\n\nFrom this general result several consequences follow.\n{{ordered list\n| list-style-type=lower-alpha\n| For the case of column vector ''c'' and row vector ''r'', each with ''m'' components, the formula allows quick calculation of the determinant of a matrix that differs from the identity matrix by a matrix of rank 1:\n:<math>\\det\\left(I_\\mathit{m} + cr\\right) = 1 + rc</math>.\n| More generally,<ref>Proofs can be found in http://www.ee.ic.ac.uk/hp/staff/dmb/matrix/proof003.html</ref> for any invertible {{nowrap|''m'' × ''m''}} matrix ''X'',\n:<math>\\det(X + AB) = \\det(X) \\det\\left(I_\\mathit{n} + BX^{-1}A\\right)</math>,\n| For a column and row vector as above:\n: <math>\\det(X + cr) = \\det(X) \\det\\left(1 + rX^{-1}c\\right) = \\det(X) + r\\,\\operatorname{adj}(X)\\,c</math>.\n| For square matrices <math>A</math> and <math>B</math> of the same size, the matrices <math>AB</math> and <math>BA</math> have the same characteristic polynomials (hence the same eigenvalues).\n}}\n\n== Properties of the determinant in relation to other notions ==\n\n=== Relation to eigenvalues and trace ===\n{{Main|Eigenvalues and eigenvectors}}\nLet  {{mvar|A}} be an arbitrary {{math|''n×n''}} matrix of complex numbers with [[eigenvectors|eigenvalues]] <math>\\lambda_1</math>, <math>\\lambda_2</math>, …, <math>\\lambda_n</math>. (Here it is understood that an eigenvalue with [[algebraic multiplicity]]  {{mvar|μ}} occurs {{mvar|μ}} times in this list.) Then the determinant of   {{mvar|A}} is the product of all eigenvalues,\n:<math>\\operatorname{det}(A) = \\prod_{i=1}^n \\lambda_i=\\lambda_1\\lambda_2\\cdots\\lambda_n</math>.\nThe product of all non-zero eigenvalues is referred to as [[pseudo-determinant]].\n\nConversely, determinants can be used to find the [[eigenvalue]]s of the matrix {{mvar|A}}: they are the solutions of the [[characteristic polynomial|characteristic equation]]\n:<math>\\det(A - \\lambda I) = 0~,</math>\nwhere ''I'' is the [[identity matrix]] of the same dimension as {{mvar|A}} and {{mvar|λ}} is a (scalar) number which solves the equation (there are no more than {{mvar|n}} solutions, where {{mvar|n}} is the dimension of {{mvar|A}}).\n\nA [[Hermitian matrix]] is [[positive definite matrix|positive definite]] if all its eigenvalues are positive. [[Sylvester's criterion]] asserts that this is equivalent to the determinants of the submatrices\n:<math>A_k := \\begin{bmatrix}\n  a_{1,1} & a_{1,2} &  \\dots & a_{1,k} \\\\\n  a_{2,1} & a_{2,2} &  \\dots & a_{2,k} \\\\\n   \\vdots &  \\vdots & \\ddots &  \\vdots \\\\\n  a_{k,1} & a_{k,2} &  \\dots & a_{k,k}\n\\end{bmatrix}</math>\n\nbeing positive, for all {{mvar|k}} between 1 and {{mvar|n}}.\n\nThe [[Trace (linear algebra)|trace]] tr(''A'') is by definition the sum of the diagonal entries of {{mvar|A}} and also equals the sum of the eigenvalues. Thus, for complex matrices {{mvar|A}},\n:<math>\\det(\\exp(A)) = \\exp(\\operatorname{tr}(A))</math>\n\nor, for real matrices {{mvar|A}},\n:<math>\\operatorname{tr}(A) = \\log(\\det(\\exp(A))).</math>\n\nHere exp({{mvar|A}}) denotes the [[matrix exponential]] of {{mvar|A}}, because every eigenvalue {{mvar|λ}} of {{mvar|A}} corresponds to the eigenvalue exp({{mvar|λ}}) of exp({{mvar|A}}). In particular, given any [[matrix logarithm|logarithm]] of {{mvar|A}}, that is, any matrix {{mvar|L}} satisfying\n:<math>\\exp(L) = A</math>\n\nthe determinant of {{mvar|A}} is given by\n:<math>\\det(A) = \\exp(\\operatorname{tr}(L)).</math>\n\nFor example, for {{nowrap|1=''n'' = 2}}, {{nowrap|1=''n'' = 3}}, and {{nowrap|1=''n'' = 4}}, respectively,\n:<math>\\begin{align}\n  \\det(A) &= \\frac{1}{2}\\left(\\left(\\operatorname{tr}(A)\\right)^2 -  \\operatorname{tr}\\left(A^2\\right)\\right), \\\\\n  \\det(A) &= \\frac{1}{6}\\left(\\left(\\operatorname{tr}(A)\\right)^3 - 3\\operatorname{tr}(A) ~ \\operatorname{tr}\\left(A^2\\right) + 2 \\operatorname{tr}\\left(A^3\\right)\\right), \\\\\n  \\det(A) &= \\frac{1}{24}\\left(\\left(\\operatorname{tr}(A)\\right)^4 - 6\\operatorname{tr}\\left(A^2\\right)\\left(\\operatorname{tr}(A)\\right)^2 + 3\\left(\\operatorname{tr}\\left(A^2\\right)\\right)^2 + 8\\operatorname{tr}\\left(A^3\\right)~\\operatorname{tr}(A) - 6\\operatorname{tr}\\left(A^4\\right)\\right).\n\\end{align}</math>\n\ncf. [[Cayley–Hamilton theorem#Illustration for specific dimensions and practical applications|Cayley-Hamilton theorem]]. Such expressions are deducible from combinatorial arguments, [[Newton's identities#Computing coefficients|Newton's identities]], or the [[Faddeev–LeVerrier algorithm]]. That is, for generic {{mvar|n}}, {{math|det''A'' {{=}} (−)<sup>''n''</sup>''c''<sub>0</sub>}} the signed constant term of the [[characteristic polynomial]], determined recursively from\n:<math>c_n = 1; ~~~c_{n-m} = -\\frac{1}{m}\\sum_{k=1}^m c_{n-m+k}  \\operatorname{tr}\\left(A^k\\right) ~~(1 \\le m \\le n)~.</math>\n\nIn the general case, this may also be obtained from<ref>A proof can be found in the Appendix B of {{cite journal | last1 = Kondratyuk | first1 = L. A. | last2 = Krivoruchenko | first2 = M. I. | year = 1992 | title = Superconducting quark matter in SU(2) color group | url = | journal = Zeitschrift für Physik A | volume = 344 | issue = | pages = 99–115 | doi = 10.1007/BF01291027 | bibcode = 1992ZPhyA.344...99K }}</ref>\n:<math>\\det(A) = \\sum_{k_1,k_2,\\ldots,k_n}\\prod_{l=1}^n \\frac{(-1)^{k_l+1}}{l^{k_l}k_l!} \\operatorname{tr}\\left(A^l\\right)^{k_l},</math>\n\nwhere the sum is taken over the set of all integers ''k<sub>l</sub>'' ≥ 0 satisfying the equation\n:<math>\\sum_{l=1}^n lk_l = n.</math>\n\nThe formula can be expressed in terms of the complete exponential [[Bell polynomial]] of ''n'' arguments ''s''<sub>''l''</sub> = −(''l'' – 1)! tr(''A''<sup>''l''</sup>) as\n:<math>\\det(A) = \\frac{(-1)^n}{n!} B_n(s_1, s_2, \\ldots, s_n).</math>\n\nThis formula can also be used to find the determinant of a matrix {{math|''A<sup>I</sup><sub>J</sub>''}} with multidimensional indices {{nowrap|1=''I'' = (i<sub>1</sub>, i<sub>2</sub>, …, i<sub>r</sub>)}} and {{nowrap|1=''J'' = (j<sub>1</sub>, j<sub>2</sub>, …, j<sub>r</sub>)}}. The product and trace of such matrices are defined in a natural way as\n:<math>(AB)^I_J = \\sum_K A^I_K B^K_J, \\operatorname{tr}(A) = \\sum_I A^I_I.</math>\n\nAn important arbitrary  dimension {{mvar|n}}  identity can be obtained from the  [[Mercator series]] expansion of the logarithm when the expansion converges.  If every eigenvalue of ''A'' is less than 1 in absolute value,\n:<math>\\det(I + A) = \\sum_{k=0}^\\infty \\frac{1}{k!} \\left(-\\sum_{j=1}^\\infty \\frac{(-1)^j}{j} \\operatorname{tr}\\left(A^j\\right)\\right)^k\\,,</math>\n\nwhere {{math|''I''}} is the identity matrix.  More generally, if \n:<math>\\sum_{k=0}^\\infty \\frac{1}{k!} \\left(-\\sum_{j=1}^\\infty \\frac{(-1)^j s^j}{j}\\operatorname{tr}\\left(A^j\\right)\\right)^k\\,,</math>\n\nis expanded as a formal power series in {{mvar|s}} then all coefficients of {{mvar|s}}<sup>{{mvar|m}}</sup> for {{math|''m'' &gt; ''n''}} are zero and the remaining polynomial is {{math|det(''I'' + ''sA'')}}.\n\n=== Upper and lower bounds ===\nFor a positive definite matrix {{math|''A''}}, the trace operator gives the following tight lower and upper bounds on the log determinant\n:<math>\\operatorname{tr}\\left(I - A^{-1}\\right) \\le \\log\\det(A) \\le \\operatorname{tr}(A - I)</math>\n\nwith equality if and only if  {{math|''A''{{=}}''I''}}. This relationship can be derived via the formula for the KL-divergence between two [[multivariate normal]] distributions.\n\nAlso,\n:<math>\\frac{n}{\\operatorname{tr}(A^{-1})} \\leq \\det (A)^\\frac{1}{n} \\leq \\frac{1}{n}\\operatorname{tr}(A) \\leq \\sqrt{\\frac{1}{n}\\operatorname{tr}\\left(A^2\\right)}.</math>\n\nThese inequalities can be proved by bringing the matrix ''A'' to the diagonal form. As such, they represent the well-known fact that the harmonic mean is less than the geometric mean, which is less than the arithmetic mean, which is, in turn, less than the root mean square.\n\n=== Cramer's rule ===\n{{Main|Cramer's rule}}\nFor a matrix equation\n:<math> Ax = b</math>, given that A has a nonzero determinant,\n\nthe solution is given by [[Cramer's rule]]:\n:<math> x_i = \\frac{\\det(A_i)}{\\det(A)} \\qquad i = 1, 2, 3, \\ldots, n </math>\nwhere ''A''<sub>''i''</sub> is the matrix formed by replacing the ''i''th column of ''A'' by the column vector ''b''. This follows immediately by column expansion of the determinant, i.e.\n:<math> \\det(A_i) = \\det\\begin{bmatrix}a_1, & \\ldots, & b, & \\ldots, & a_n\\end{bmatrix} = \\sum_{j=1}^n x_j\\det\\begin{bmatrix}a_1, & \\ldots, a_{i-1}, & a_j, & a_{i+1}, & \\ldots, & a_n \\end{bmatrix} = x_i \\det(A)</math>\nwhere the vectors <math>a_j</math> are the columns of ''A''.  The rule is also implied by the identity\n\n:<math>A\\, \\operatorname{adj}(A) = \\operatorname{adj}(A)\\, A = \\det(A)\\, I_n.</math>\n\nIt has recently been shown that Cramer's rule can be implemented in O(''n''<sup>3</sup>) time,<ref>{{Cite journal|doi=10.1016/j.jda.2011.06.007|title=A condensation-based application of Cramerʼs rule for solving large-scale linear systems|journal=Journal of Discrete Algorithms|volume=10|pages=98–109|year=2012|last1=Habgood|first1=Ken|last2=Arel|first2=Itamar}}</ref> which is comparable to more common methods of solving systems of linear equations, such as [[LU decomposition|LU]], [[QR decomposition|QR]], or [[singular value decomposition]].\n\n=== Block matrices ===\nSuppose ''A'', ''B'', ''C'', and ''D'' are matrices of dimension {{nowrap|''n'' × ''n''}}, {{nowrap|''n'' × ''m''}}, {{nowrap|''m'' × ''n''}}, and {{nowrap|''m'' × ''m''}}, respectively. Then\n\n:<math>\\det\\begin{pmatrix}A& 0\\\\ C& D\\end{pmatrix} = \\det(A)\\det(D) = \\det\\begin{pmatrix}A& B\\\\ 0& D\\end{pmatrix}.</math>\n\nThis can be seen from the [[Leibniz formula for determinants|Leibniz formula]], or from a decomposition like (for the former case)\n\n:<math>\\begin{pmatrix}A& 0\\\\ C& D\\end{pmatrix} = \\begin{pmatrix}A& 0\\\\ C& I_m\\end{pmatrix}\\begin{pmatrix}I_n& 0\\\\ 0& D\\end{pmatrix}.</math>\n\nWhen ''A'' is [[Invertible matrix|invertible]], one has\n\n:<math>\\det\\begin{pmatrix}A& B\\\\ C& D\\end{pmatrix} = \\det(A) \\det\\left(D - C A^{-1} B\\right) .</math>\n\nas can be seen by employing the decomposition\n\n:<math>\\begin{pmatrix}A& B\\\\ C& D\\end{pmatrix} = \\begin{pmatrix}A& 0\\\\ C& I_m\\end{pmatrix} \\begin{pmatrix}I_n& A^{-1} B\\\\ 0& D - C A^{-1} B\\end{pmatrix}.</math>\n\nWhen ''D'' is invertible, a similar identity with <math>\\det(D)</math> factored out can be derived analogously,<ref>These identities were taken from http://www.ee.ic.ac.uk/hp/staff/dmb/matrix/proof003.html</ref> that is,\n\n:<math>\\det\\begin{pmatrix}A& B\\\\ C& D\\end{pmatrix} = \\det(D)\\det\\left(A - B D^{-1} C\\right).</math>\n\nWhen the blocks are square matrices of the same order further formulas hold. For example, if ''C'' and ''D'' commute (i.e., {{nowrap|1=''CD'' = ''DC''}}), then the following formula comparable to the determinant of a {{nowrap|2 × 2}} matrix holds:<ref>Proofs are given in {{Cite journal|first=J. R.|last= Silvester|title= Determinants of Block Matrices|journal= Math. Gazette|volume=84 |year=2000\n|pages= 460–467|jstor=3620776|url= http://www.ee.iisc.ernet.in/new/people/faculty/prasantg/downloads/blocks.pdf}}</ref>\n\n:<math>\\det\\begin{pmatrix}A& B\\\\ C& D\\end{pmatrix} = \\det(AD - BC).</math>\n\nGenerally, if all pairs of {{nowrap|''n'' × ''n''}} matrices of the {{nowrap|''np'' × ''np''}} block matrix commute, then the determinant of the block matrix is equal to the determinant of the matrix  obtained by computing the determinant of the block matrix considering its entries as the entries of a {{nowrap|''p'' × ''p''}} matrix.<ref>{{cite journal|last1=Sothanaphan|first1=Nat|title=Determinants of block matrices with noncommuting blocks|journal=Linear Algebra and its Applications|date=January 2017|volume=512|pages=202–218|doi=10.1016/j.laa.2016.10.004|arxiv=1805.06027}}</ref> As the previous formula shows, for ''p'' = 2, this criterion is sufficient, but not necessary.\n\nWhen ''A'' = ''D'' and ''B'' = ''C'', the blocks are square matrices of the same order and the following formula holds (even if ''A'' and ''B'' do not commute)\n:<math>\\det\\begin{pmatrix}A& B\\\\ B& A\\end{pmatrix} = \\det(A - B)\\det(A + B).</math>\n\nWhen ''D'' is a 1×1 matrix, ''B'' is a column vector, and ''C'' is a row vector then\n:<math>\\det\\begin{pmatrix}A& B\\\\ C& D\\end{pmatrix} = \\left(D - CA^{-1}B\\right)\\det(A) \\,.</math>\n\nLet <math>s</math> be a scalar complex number.  If a block matrix is square, its [[characteristic polynomial]] can be factored with\n: <math>\\begin{align}\n  \\det\\begin{pmatrix}\n    A - sI & B \\\\\n         C & D - sI\n  \\end{pmatrix}\n    &= \\det(A - sI)\\det\\left(D - \\frac{C\\operatorname{adj}(A - sI)B}{\\det(A - sI)} - sI\\right)\\quad\\mathrm{if}\\quad s \\notin \\operatorname{eig}(A)\\\\\n    &= \\det(A - sI)^{1-n-m}\\det\\left(\\det(A - sI)D - C\\operatorname{adj}(A - sI)B - \\det(A - sI)sI\\right)\n\\end{align}</math>\n\n=== Derivative ===\nIt can be seen, e.g. using the [[Leibniz formula for determinants|Leibniz formula]], that the determinant of real (or analogously for complex) square matrices is a [[polynomial]] function from {{nowrap|'''R'''<sup>''n'' × ''n''</sup>}} to '''R''', and so it is everywhere [[derivative|differentiable]]. Its derivative can be expressed using [[Jacobi's formula]]:<ref>§&nbsp;0.8.10 of R. A. Horn & C. R. Johnson: ''Matrix Analysis'' 2nd ed. (2013) Cambridge University Press. {{isbn|978-0-521-54823-6}}.</ref>\n\n:<math>\\frac{d \\det(A)}{d \\alpha} = \\operatorname{tr}\\left(\\operatorname{adj}(A) \\frac{d A}{d \\alpha}\\right).</math>\n\nwhere adj(''A'') denotes the [[adjugate]] of ''A''. In particular, if ''A'' is invertible, we have\n\n:<math>\\frac{d \\det(A)}{d \\alpha} = \\det(A) \\operatorname{tr}\\left(A^{-1} \\frac{d A}{d \\alpha}\\right).</math>\n\nExpressed in terms of the entries of ''A'', these are\n\n: <math> \\frac{\\partial \\det(A)}{\\partial A_{ij}}= \\operatorname{adj}(A)_{ji} = \\det(A)\\left(A^{-1}\\right)_{ji}.</math>\n\nYet another equivalent formulation is\n\n:<math>\\det(A + \\epsilon X) - \\det(A) = \\operatorname{tr}(\\operatorname{adj}(A) X) \\epsilon + O\\left(\\epsilon^2\\right) = \\det(A) \\operatorname{tr}\\left(A^{-1} X\\right) \\epsilon + O\\left(\\epsilon^2\\right)</math>,\n\nusing [[big O notation]]. The special case where <math>A = I</math>, the identity matrix, yields\n\n:<math>\\det(I + \\epsilon X) = 1 + \\operatorname{tr}(X) \\epsilon + O\\left(\\epsilon^2\\right).</math>\n\nThis identity is used in describing the [[tangent space]] of certain matrix [[Lie groups]].\n\nIf the matrix A is written as <math>A = \\begin{bmatrix}\\mathbf{a} & \\mathbf{b} & \\mathbf{c}\\end{bmatrix}</math> where '''a''', '''b''', '''c''' are column vectors of length 3, then the gradient over one of the three vectors may be written as the [[cross product]] of the other two:\n\n: <math>\\begin{align}\n  \\nabla_\\mathbf{a}\\det(A) &= \\mathbf{b} \\times \\mathbf{c} \\\\\n  \\nabla_\\mathbf{b}\\det(A) &= \\mathbf{c} \\times \\mathbf{a} \\\\\n  \\nabla_\\mathbf{c}\\det(A) &= \\mathbf{a} \\times \\mathbf{b}.\n\\end{align}</math>\n\n== Abstract algebraic aspects {{anchor|Abstract formulation}} ==\n\n=== Determinant of an endomorphism ===\nThe above identities concerning the determinant of products and inverses of matrices imply that [[matrix similarity|similar matrices]] have the same determinant: two matrices ''A'' and ''B'' are similar, if there exists an invertible matrix ''X'' such that {{nowrap|1=''A'' = ''X''<sup>−1</sup>''BX''}}. Indeed, repeatedly applying the above identities yields\n\n:<math>\\det(A) = \\det(X)^{-1} \\det(B)\\det(X) = \\det(B) \\det(X)^{-1} \\det(X) = \\det(B).</math>\n\nThe determinant is therefore also called a [[similarity invariance|similarity invariant]]. The determinant of a [[linear transformation]]\n:<math>T : V \\rightarrow V</math>\nfor some finite-dimensional [[vector space]] ''V'' is defined to be the determinant of the matrix describing it, with respect to an arbitrary choice of [[basis (linear algebra)|basis]] in ''V''. By the similarity invariance, this determinant is independent of the choice of the basis for ''V'' and therefore only depends on the endomorphism ''T''.\n\n=== Exterior algebra ===\n{{See also|Exterior algebra#Linear algebra}}\n\nThe determinant of a linear transformation {{nowrap|''A'' : ''V'' → ''V''}} of an ''n''-dimensional vector space ''V'' can be formulated in a coordinate-free manner by considering the ''n''th [[exterior algebra|exterior power]] Λ<sup>''n''</sup>''V'' of ''V''. ''A'' induces a linear map\n:<math>\\begin{align}\n                \\Lambda^n A: \\Lambda^n V &\\rightarrow \\Lambda^n V \\\\\n  v_1 \\wedge v_2 \\wedge \\dots \\wedge v_n &\\mapsto A v_1 \\wedge A v_2 \\wedge \\dots \\wedge A v_n.\n\\end{align}</math>\n\nAs Λ<sup>''n''</sup>''V'' is one-dimensional, the map Λ<sup>''n''</sup>A is given by multiplying with some scalar. This scalar coincides with the determinant of ''A'', that is to say\n:<math>\\left(\\Lambda^n A\\right)\\left(v_1 \\wedge \\dots \\wedge v_n\\right) = \\det(A) \\cdot v_1 \\wedge \\dots \\wedge v_n.</math>\n\nThis definition agrees with the more concrete coordinate-dependent definition. This follows from the characterization of the determinant given above. For example, switching two columns changes the sign of the determinant; likewise, permuting the vectors in the exterior product {{nowrap|''v''<sub>1</sub> ∧ ''v''<sub>2</sub> ∧ ''v''<sub>3</sub> ∧ … ∧ ''v''<sub>''n''</sub>}} to {{nowrap|''v''<sub>2</sub> ∧ ''v''<sub>1</sub> ∧ ''v''<sub>3</sub> ∧ … ∧ ''v''<sub>''n''</sub>}}, say, also changes its sign.\n\nFor this reason, the highest non-zero exterior power Λ<sup>''n''</sup>(''V'') is sometimes also called the determinant of ''V'' and similarly for more involved objects such as [[vector bundle]]s or [[chain complex]]es of vector spaces. Minors of a matrix can also be cast in this setting, by considering lower alternating forms Λ<sup>''k''</sup>''V'' with {{nowrap|''k'' < ''n''}}.\n\n==== Transformation on alternating multilinear ''n''-forms ====\nThe vector space ''W'' of all alternating multilinear ''n''-forms on an ''n''-dimensional vector space ''V'' has dimension one.  To each linear transformation ''T'' on ''V'' we associate a linear transformation ''T''′ on ''W'', where for each ''w'' in ''W'' we define {{nowrap|1=(''T''′''w'')(''x''<sub>1</sub>, …, ''x''<sub>''n''</sub>) = ''w''(''Tx''<sub>1</sub>, …, ''Tx''<sub>''n''</sub>)}}.  As a linear transformation on a one-dimensional space, ''T''′ is equivalent to a scalar multiple.  We call this scalar the determinant of ''T''.\n\n=== Square matrices over commutative rings and abstract properties ===\nThe determinant can also be characterized as the unique function\n:<math>D: M_n(K) \\to K</math>\nfrom the set of all {{nowrap|''n'' × ''n''}} matrices with entries in a field ''K'' to this field satisfying the following three properties: first, ''D'' is an [[Multilinear map|''n''-linear]] function: considering all but one column of ''A'' fixed, the determinant is linear in the remaining column, that is\n:<math>D (v_1, \\dots, v_{i-1}, a v_i + b w, v_{i+1}, \\dots, v_n) = a D (v_1, \\dots, v_{i-1}, v_i, v_{i+1}, \\dots, v_n) + b D (v_1, \\dots, v_{i-1}, w, v_{i+1}, \\dots, v_n)</math>\nfor any column vectors ''v''<sub>1</sub>, ..., ''v''<sub>''n''</sub>, and ''w'' and any scalars (elements of ''K'') ''a'' and ''b''. Second, ''D'' is an [[alternating form|alternating]] function: for any matrix ''A'' with two identical columns, {{nowrap|1=''D''(''A'') = 0}}. Finally, {{nowrap|1=''D''(''I''<sub>''n''</sub>) = 1}}, where ''I''<sub>''n''</sub> is the identity matrix.\n\nThis fact also implies that every other ''n''-linear alternating function {{nowrap|''F'': M<sub>''n''</sub>(''K'') → ''K''}} satisfies\n:<math>F(M)=F(I)D(M).</math>\n\nThis definition can also be extended where ''K'' is a [[commutative ring]] ''R'', in which case a matrix is invertible if and only if its determinant is an [[Unit (ring theory)|invertible element]] in ''R''. For example, a matrix ''A'' with entries in '''Z''', the integers, is invertible (in the sense that there exists an inverse matrix with integer entries) if the determinant is +1 or −1. Such a matrix is called [[unimodular matrix|unimodular]].\n\nThe determinant defines a mapping\n:<math>\\operatorname{GL}_n(R) \\rightarrow R^\\times, </math>\nbetween the group of invertible {{nowrap|''n'' × ''n''}} matrices with entries in ''R'' and the [[multiplicative group]] of units in ''R''. Since it respects the multiplication in both groups, this map is a [[group homomorphism]]. Secondly, given a [[ring homomorphism]] {{nowrap|''f'': ''R'' → ''S''}}, there is a map {{nowrap|''GL<sub>n</sub>(f)'': GL<sub>''n''</sub>(''R'') → GL<sub>''n''</sub>(''S'')}} given by replacing all entries in ''R'' by their images under ''f''. The determinant respects these maps, i.e., given a matrix {{nowrap|1=''A'' = (''a''<sub>''i'',''j''</sub>)}} with entries in ''R'', the identity\n:<math>f(\\det((a_{i,j}))) = \\det ((f(a_{i,j})))</math>\nholds. In other words, the following diagram commutes:\n\n:[[Image:Determinant as a natural transformation.svg|300px]]\n\nFor example, the determinant of the [[complex conjugate]] of a complex matrix (which is also the determinant of its conjugate transpose) is the complex conjugate of its determinant, and for integer matrices: the reduction modulo&nbsp;''m'' of the determinant of such a matrix is equal to the determinant of the matrix reduced modulo&nbsp;''m'' (the latter determinant being computed using [[modular arithmetic]]). In the language of [[category theory]], the determinant is a [[natural transformation]] between the two functors GL<sub>''n''</sub> and (⋅)<sup>×</sup> (see also [[Natural transformation#Determinant]]).<ref>{{Citation | first = Saunders | last = Mac Lane | authorlink = Saunders Mac Lane | year = 1998 | title = [[Categories for the Working Mathematician]] | series = Graduate Texts in Mathematics '''5''' | edition = (2nd ed.) | publisher = Springer-Verlag | isbn = 0-387-98403-8}}</ref> Adding yet another layer of abstraction, this is captured by saying that the determinant is a morphism of [[algebraic group]]s, from the general linear group to the [[multiplicative group]],\n:<math>\\det: \\operatorname{GL}_n \\rightarrow \\mathbb G_m.</math>\n\n== Generalizations and related notions ==\n\n=== Infinite matrices ===\nFor matrices with an infinite number of rows and columns, the above definitions of the determinant do not carry over directly. For example, in the Leibniz formula, an infinite sum (all of whose terms are infinite products) would have to be calculated. [[Functional analysis]] provides different extensions of the determinant for such infinite-dimensional situations, which however only work for particular kinds of operators.\n\nThe [[Fredholm determinant]] defines the determinant for operators known as [[trace class operator]]s by an appropriate generalization of the formula\n:<math>\\det(I+A) = \\exp(\\operatorname{tr}(\\log(I+A))). </math>\n\nAnother infinite-dimensional notion of determinant is the [[functional determinant]].\n\n===Operators in von Neumann algebras===\nFor operators in a finite [[von Neumann algebra#Factors|factor]], one may define a positive real-valued determinant called the [[Fuglede−Kadison determinant]] using the canonical trace. In fact, corresponding to every [[State (functional analysis)#tracial state|tracial state]] on a [[von Neumann algebra]] there is a notion of Fuglede−Kadison determinant.\n\n=== Related notions for non-commutative rings ===\nFor square matrices with entries in a non-commutative ring, there are various difficulties in defining determinants analogously to that for commutative rings. A meaning can be given to the Leibniz formula provided that the order for the product is specified, and similarly for other ways to define the determinant, but non-commutativity then leads to the loss of many fundamental properties of the determinant, for instance the multiplicative property or the fact that the determinant is unchanged under transposition of the matrix. Over non-commutative rings, there is no reasonable notion of a multilinear form (existence of a nonzero {{clarify span|text=bilinear form|explain=What exactly is meant by this term must be specified.  This statement is valid only if the bilinear form is required to be linear on the same side for both arguments; in contrast, Bourbaki defines a bilinear form B as having the property B(ax,yb) = aB(x,y)b, i.e., left-linear in the left argument and right-linear in the other.|date=October 2017}} with a [[Regular element (ring theory)|regular element]] of ''R'' as value on some pair of arguments implies that ''R'' is commutative). Nevertheless, various notions of non-commutative determinant have been formulated, which preserve some of the properties of determinants, notably [[quasideterminant]]s and the [[Dieudonné determinant]]. It may be noted that if one considers certain specific classes of matrices with non-commutative elements, then there are examples where one can define the determinant and prove linear algebra theorems that are very similar to their commutative analogs. Examples include quantum groups and ''q''-determinant, Capelli matrix and [[Capelli determinant]], super-matrices and [[Berezinian]]; [[Manin matrices]] is the class of matrices which is most close to matrices with commutative elements.\n\n=== Further variants ===\nDeterminants of matrices in [[superring]]s (that is, Z<sub>2</sub>-[[graded ring]]s) are known as [[Berezinian]]s or superdeterminants.<ref>{{Citation | url = https://books.google.com/?id=sZ1-G4hQgIIC&pg=PA116&dq=Berezinian#v=onepage&q=Berezinian&f=false | title = Supersymmetry for mathematicians: An introduction | isbn = 978-0-8218-3574-6 | author1 = Varadarajan | first1 = V. S | year = 2004 | postscript = .}}</ref>\n\nThe [[Permanent (mathematics)|permanent]] of a matrix is defined as the determinant, except that the factors sgn(''σ'') occurring in Leibniz's rule are omitted. The [[immanant of a matrix|immanant]] generalizes both by introducing a [[character theory|character]] of the [[symmetric group]] S<sub>''n''</sub> in Leibniz's rule.\n\n== Calculation ==\nDeterminants are mainly used as a theoretical tool. They are rarely calculated explicitly in [[numerical linear algebra]], where for applications like checking invertibility and finding eigenvalues the determinant has largely been supplanted by other techniques.<ref name=Trefethen>L. N. Trefethen and D. Bau, ''Numerical Linear Algebra'' (SIAM, 1997). e.g. in Lecture 1: \"... we mention that the determinant, though a convenient notion theoretically, rarely finds a useful role in numerical algorithms.\"</ref> [[Computational geometry]], however, does frequently use calculations related to determinants.<ref>\nA survey of state-of-the-art algorithms for computing determinants and their advantages and disadvantages including results of performance tests, is included in\n{{cite journal\n | last1 = Fisikopoulos | first1 = Vissarion\n | last2 = Peñaranda | first2 = Luis\n | title = Faster geometric algorithms via dynamic determinant computation\n | journal = Computational Geometry\n | volume = 54\n | pages = 1–16\n | publisher = Elsevier B. V.\n | date = 2016\n | url = https://arxiv.org/pdf/1206.7067.pdf\n | issn = 0925-7721\n | doi = 10.1016/j.comgeo.2015.12.001| arxiv = 1206.7067\n }}\nThe survey is section 1.1 Previous work, and the results of tests are in section 4.3 Determinant computation experiments.</ref>\n\nNaive methods of implementing an algorithm to compute the determinant include using the [[Leibniz formula for determinants|Leibniz formula]] or [[Laplace expansion|Laplace's formula]]. Both these approaches are extremely inefficient for large matrices, though, since the number of required operations grows very quickly: it is [[Big O notation|of order]] ''n''! (''n'' [[factorial]]) for an {{nowrap|''n'' × ''n''}} matrix ''M''. For example, Leibniz's formula requires calculating ''n''! products. Therefore, more involved techniques have been developed for calculating determinants.\n\n=== Decomposition methods ===\nGiven a matrix ''A'', some methods compute its determinant by writing ''A'' as a product of matrices whose determinants can be more easily computed. Such techniques are referred to as decomposition methods. Examples include the [[LU decomposition]], the [[QR decomposition]] or the [[Cholesky decomposition]] (for [[Positive definite matrix|positive definite matrices]]). These methods are of order O(''n''<sup>3</sup>), which is a significant improvement over O(''n''!)\n\nThe LU decomposition expresses ''A'' in terms of a lower triangular matrix ''L'', an upper triangular matrix ''U'' and a [[permutation matrix]] ''P'':\n:<math> A = PLU. </math>\nThe determinants of ''L'' and ''U'' can be quickly calculated, since they are the products of the respective diagonal entries.  The determinant of ''P'' is just the sign <math>\\varepsilon</math> of the corresponding permutation (which is +1 for an even number of permutations and is −1 for an uneven number of permutations). The determinant of ''A'' is then\n\n:<math> \\det(A) = \\varepsilon \\det(L)\\cdot\\det(U). </math>\n\n(See [[determinant identities]].) Moreover, the decomposition can be chosen such that ''L'' is a [[unitriangular matrix]] and therefore has determinant&nbsp;1, in which case the formula further simplifies to\n\n:<math> \\det(A) = \\varepsilon\\det(U).</math>\n\n=== Further methods ===\nIf the determinant of ''A'' and the inverse of ''A'' have already been computed, the [[matrix determinant lemma]] allows rapid calculation of the determinant of {{nowrap|''A'' + ''uv''<sup>T</sup>}}, where ''u'' and ''v'' are column vectors.\n\nSince the definition of the determinant does not need divisions, a question arises: do fast algorithms exist that do not need divisions? This is especially interesting for matrices over rings. Indeed, algorithms with run-time proportional to ''n''<sup>4</sup> exist. An algorithm of Mahajan and Vinay, and Berkowitz<ref>http://page.inf.fu-berlin.de/~rote/Papers/pdf/Division-free+algorithms.pdf</ref> is based on [[closed ordered walk]]s (short ''clow''). It computes more products than the determinant definition requires, but some of these products cancel and the sum of these products can be computed more efficiently. The final algorithm looks very much like an iterated product of triangular matrices.\n\nIf two matrices of order ''n'' can be multiplied in time ''M''(''n''), where {{nowrap|''M''(''n'') ≥ ''n''<sup>''a''</sup>}} for some {{nowrap|''a'' > 2}}, then the determinant can be computed in time O(''M''(''n'')).<ref>{{cite journal |first=J. R. |last=Bunch |first2=J. E. |last2=Hopcroft |title=Triangular Factorization and Inversion by Fast Matrix Multiplication |journal=[[Mathematics of Computation]] |volume=28 |year=1974 |issue= 125|pages=231–236 |doi=10.1090/S0025-5718-1974-0331751-8 }}</ref> This means, for example, that an O(''n''<sup>2.376</sup>) algorithm exists based on the [[Coppersmith–Winograd algorithm]].\n\nCharles Dodgson (i.e. [[Lewis Carroll]] of [[Alice's Adventures in Wonderland]] fame) invented a method for computing determinants called [[Dodgson condensation]].  Unfortunately this interesting method does not always work in its original form.\n\nAlgorithms can also be assessed according to their [[bit complexity]], i.e., how many bits of accuracy are needed to store intermediate values occurring in the computation. For example, the [[Gaussian elimination]] (or LU decomposition) method is of order O(''n''<sup>3</sup>), but the bit length of intermediate values can become exponentially long.<ref>{{Cite conference\n  | first1 = Xin Gui\n  | last1 = Fang\n  | first2 = George\n  | last2 = Havas\n  | title = On the worst-case complexity of integer Gaussian elimination\n  | booktitle = Proceedings of the 1997 international symposium on Symbolic and algebraic computation\n  | conference = ISSAC '97\n  | pages = 28–31\n  | publisher = ACM\n  | year = 1997\n  | location = Kihei, Maui, Hawaii, United States\n  | url = http://perso.ens-lyon.fr/gilles.villard/BIBLIOGRAPHIE/PDF/ft_gateway.cfm.pdf\n  | doi = 10.1145/258726.258740\n  | isbn = 0-89791-875-4}}</ref> The [[Bareiss Algorithm]], on the other hand, is an exact-division method based on [[Sylvester's determinant theorem|Sylvester's identity]] is also of order ''n''<sup>3</sup>, but the bit complexity is roughly the bit size of the original entries in the matrix times ''n''.<ref>{{citation|first=Erwin|last=Bareiss|title= Sylvester's Identity and Multistep Integer-Preserving Gaussian Elimination|pages=565–578|url=http://www.ams.org/journals/mcom/1968-22-103/S0025-5718-1968-0226829-0/S0025-5718-1968-0226829-0.pdf|journal=Mathematics of Computation|year=1968|volume=22|issue=102|doi=10.2307/2004533|jstor=2004533}}</ref>\n\n== History ==\nHistorically, determinants were used long before matrices: originally, a determinant was defined as a property of a [[system of linear equations]]. \nThe determinant \"determines\" whether the system has a unique solution (which occurs precisely if the determinant is non-zero). \nIn this sense, determinants were first used in the Chinese mathematics textbook ''[[The Nine Chapters on the Mathematical Art]]'' (九章算術, Chinese scholars, around the 3rd century BCE). \nIn Europe, {{nowrap|2 × 2}} determinants were considered by [[Gerolamo Cardano|Cardano]] at the end of the 16th century and larger ones by [[Gottfried Leibniz|Leibniz]].<ref name=\"Campbell\" /><ref name=\"Eves\">Eves, H: \"An Introduction to the History of Mathematics\", pages 405, 493–494, Saunders College Publishing, 1990.</ref><ref>A Brief History of Linear Algebra and Matrix Theory : {{cite web |url=http://darkwing.uoregon.edu/~vitulli/441.sp04/LinAlgHistory.html |title=Archived copy |accessdate=2012-01-24 |deadurl=yes |archiveurl=https://web.archive.org/web/20120910034016/http://darkwing.uoregon.edu/~vitulli/441.sp04/LinAlgHistory.html |archivedate=2012-09-10 |df= }}</ref><ref>Cajori, F. [https://books.google.com/books?id=bBoPAAAAIAAJ&pg=PA80#v=onepage&f=false ''A History of Mathematics'' p.&nbsp;80]</ref>\n\nIn Japan, [[Seki Takakazu]] (関 孝和) is credited with the discovery of the resultant and the determinant (at first in 1683, the complete version no later than 1710). \nIn Europe, [[Gabriel Cramer|Cramer]] (1750) added to the theory, treating the subject in relation to sets of equations. \nThe recurrence law was first announced by [[Bézout]] (1764).\n\nIt was [[Vandermonde]] (1771) who first recognized determinants as independent functions.<ref name=\"Campbell\">Campbell, H: \"Linear Algebra With Applications\", pages 111–112. Appleton Century Crofts, 1971</ref> [[Laplace]] (1772)<ref>Expansion of determinants in terms of minors: Laplace, Pierre-Simon (de) \"Researches sur le calcul intégral et sur le systéme du monde,\" ''Histoire de l'Académie Royale des Sciences'' (Paris), seconde partie, pages 267–376 (1772).</ref><ref>Muir, Sir Thomas, ''The Theory of Determinants in the historical Order of Development'' [London, England: Macmillan and Co., Ltd., 1906]. {{JFM|37.0181.02}}</ref> gave the general method of expanding a determinant in terms of its complementary [[minor (matrix)|minors]]: Vandermonde had already given a special case. Immediately following, [[Joseph Louis Lagrange|Lagrange]] (1773) treated determinants of the second and third order and applied it to questions of [[elimination theory]]; he proved many special cases of general identities.\n\n[[Carl Friedrich Gauss|Gauss]] (1801) made the next advance. Like Lagrange, he made much use of determinants in the [[theory of numbers]]. He introduced the word '''''determinant''''' (Laplace had used ''resultant''), though not in the present signification, but rather as applied to the [[discriminant]] of a [[algebraic form|quantic]]. Gauss also arrived at the notion of reciprocal (inverse) determinants, and came very near the multiplication theorem.\n\nThe next contributor of importance is [[Jacques Philippe Marie Binet|Binet]] (1811, 1812), who formally stated the theorem relating to the product of two matrices of ''m'' columns and ''n'' rows, which for the special case of {{nowrap|1=''m'' = ''n''}} reduces to the multiplication theorem. On the same day (November 30, 1812) that Binet presented his paper to the Academy, [[Cauchy]] also presented one on the subject. (See [[Cauchy–Binet formula]].) In this he used the word '''''determinant''''' in its present sense,<ref>The first use of the word \"determinant\" in the modern sense appeared in: Cauchy, Augustin-Louis \"Memoire sur les fonctions qui ne peuvent obtenir que deux valeurs égales et des signes contraires par suite des transpositions operées entre les variables qu'elles renferment,\" which was first read at the Institute de France in Paris on November 30, 1812, and which was subsequently published in the ''Journal de l'Ecole Polytechnique'', Cahier 17, Tome 10, pages 29–112 (1815).</ref><ref>Origins of mathematical terms: http://jeff560.tripod.com/d.html</ref> summarized and simplified what was then known on the subject, improved the notation, and gave the multiplication theorem with a proof more satisfactory than Binet's.<ref name=\"Campbell\" /><ref>History of matrices and determinants: http://www-history.mcs.st-and.ac.uk/history/HistTopics/Matrices_and_determinants.html</ref> With him begins the theory in its generality.\n\nThe next important figure was [[Carl Gustav Jakob Jacobi|Jacobi]]<ref name=\"Eves\" /> (from 1827). He early used the functional determinant which Sylvester later called the [[Jacobian matrix and determinant|Jacobian]], and in his memoirs in ''[[Crelle's Journal]]'' for 1841 he specially treats this subject, as well as the class of alternating functions which Sylvester has called ''alternants''. About the time of Jacobi's last memoirs, [[James Joseph Sylvester|Sylvester]] (1839) and [[Arthur Cayley|Cayley]] began their work.<ref>The first use of vertical lines to denote a determinant appeared in: Cayley, Arthur \"On a theorem in the geometry of position,\" ''Cambridge Mathematical Journal'', vol. 2, pages 267–271 (1841).</ref><ref>History of matrix notation: http://jeff560.tripod.com/matrices.html</ref>\n\nThe study of special forms of determinants has been the natural result of the completion of the general theory. Axisymmetric determinants have been studied by [[Lebesgue]], [[Otto Hesse|Hesse]], and Sylvester; [[persymmetric]] determinants by Sylvester and [[Hermann Hankel|Hankel]]; [[circulant]]s by [[Eugène Charles Catalan|Catalan]], [[William Spottiswoode|Spottiswoode]], [[James Whitbread Lee Glaisher|Glaisher]], and Scott; skew determinants and [[Pfaffian]]s, in connection with the theory of [[orthogonal transformation]], by Cayley; continuants by Sylvester; [[Wronskian]]s (so called by [[Thomas Muir (mathematician)|Muir]]) by [[Elwin Bruno Christoffel|Christoffel]] and [[Ferdinand Georg Frobenius|Frobenius]]; compound determinants by Sylvester, Reiss, and Picquet; Jacobians and [[Hessian matrix|Hessians]] by Sylvester; and symmetric gauche determinants by [[Trudi]]. Of the textbooks on the subject Spottiswoode's was the first. In America, Hanus (1886), Weld (1893), and Muir/Metzler (1933) published treatises.\n\n== Applications ==\n\n=== Linear independence ===\nAs mentioned above, the determinant of a matrix (with real or complex entries, say) is zero if and only if the column vectors (or the row vectors) of the matrix are linearly dependent. Thus, determinants can be used to characterize linearly dependent vectors. For example, given two linearly independent vectors ''v''<sub>1</sub>, ''v''<sub>2</sub> in '''R'''<sup>3</sup>, a third vector ''v''<sub>3</sub> lies in the [[Plane (geometry)|plane]] [[Linear span|spanned]] by the former two vectors exactly if the determinant of the {{nowrap|3 × 3}} matrix consisting of the three vectors is zero. The same idea is also used in the theory of [[differential equation]]s: given ''n'' functions ''f''<sub>1</sub>(''x''), …, ''f''<sub>''n''</sub>(''x'') (supposed to be {{nowrap|''n'' − 1}} times differentiable), the [[Wronskian]] is defined to be\n:<math>W(f_1, \\ldots, f_n)(x) =\n  \\begin{vmatrix}\n            f_1(x) &         f_2(x) & \\cdots &         f_n(x) \\\\\n           f_1'(x) &        f_2'(x) & \\cdots &        f_n'(x) \\\\\n            \\vdots &         \\vdots & \\ddots &         \\vdots \\\\\n    f_1^{(n-1)}(x) & f_2^{(n-1)}(x) & \\cdots & f_n^{(n-1)}(x)\n\\end{vmatrix}.</math>\n\nIt is non-zero (for some ''x'') in a specified interval if and only if the given functions and all their derivatives up to order ''n''−1 are linearly independent. If it can be shown that the Wronskian is zero everywhere on an interval then, in the case of [[analytic function]]s, this implies the given functions are linearly dependent. See [[Wronskian#The Wronskian and linear independence|the Wronskian and linear independence]].\n\n=== Orientation of a basis ===\n{{Main|Orientation (vector space)}}\nThe determinant can be thought of as assigning a number to every [[sequence]] of ''n'' vectors in '''R'''<sup>''n''</sup>, by using the square matrix whose columns are the given vectors. For instance, an [[orthogonal matrix]] with entries in '''R'''<sup>''n''</sup> represents an [[orthonormal basis]] in [[Euclidean space]]. The determinant of such a matrix determines whether the [[orientation (mathematics)|orientation]] of the basis is consistent with or opposite to the orientation of the [[standard basis]]. If the determinant is +1, the basis has the same orientation. If it is −1, the basis has the opposite orientation.\n\nMore generally, if the determinant of ''A'' is positive, ''A'' represents an orientation-preserving [[linear transformation]] (if ''A'' is an orthogonal {{nowrap|2 × 2}} or {{nowrap|3 × 3}} matrix, this is a [[rotation (mathematics)|rotation]]), while if it is negative, ''A'' switches the orientation of the basis.\n\n=== Volume and Jacobian determinant ===\nAs pointed out above, the [[absolute value]] of the determinant of real vectors is equal to the volume of the [[parallelepiped]] spanned by those vectors. As a consequence, if {{nowrap|''f'' : '''R'''<sup>''n''</sup> → '''R'''<sup>''n''</sup>}} is the linear map represented by the matrix ''A'', and ''S'' is any [[Lebesgue measure|measurable]] [[subset]] of '''R'''<sup>''n''</sup>, then the volume of ''f''(''S'') is given by {{abs|det(''A'')}} times the volume of ''S''. More generally, if the linear map {{nowrap|''f'' : '''R'''<sup>''n''</sup> → '''R'''<sup>''m''</sup>}} is represented by the {{nowrap|''m'' × ''n''}} matrix ''A'', then the ''n''-[[dimension]]al volume of ''f''(''S'') is given by:\n:<math>\\operatorname{volume}(f(S)) = \\sqrt{\\det\\left(A^\\textsf{T} A\\right)} \\times \\operatorname{volume}(S).</math>\n\nBy calculating the volume of the [[tetrahedron]] bounded by four points, they can be used to identify [[skew line]]s. The volume of any tetrahedron, given its vertices '''a''', '''b''', '''c''', and '''d''', is {{nowrap|(1/6)·{{abs|det('''a''' − '''b''', '''b''' − '''c''', '''c''' − '''d''')}}}}, or any other combination of pairs of vertices that would form a [[spanning tree]] over the vertices.\n\nFor a general [[differentiable function]], much of the above carries over by considering the [[Jacobian matrix]] of ''f''. For\n:<math>f: \\mathbf R^n \\rightarrow \\mathbf R^n,</math>\n\nthe Jacobian matrix is the {{nowrap|''n'' × ''n''}} matrix whose entries are given by\n:<math>D(f) = \\left(\\frac {\\partial f_i}{\\partial x_j}\\right)_{1 \\leq i, j \\leq n}.</math>\n\nIts determinant, the [[Jacobian determinant]], appears in the higher-dimensional version of [[integration by substitution]]: for suitable functions ''f'' and an [[open subset]] ''U'' of '''R'''<sup>''n''</sup> (the domain of ''f''), the integral over ''f''(''U'') of some other function {{nowrap|''φ'' : '''R'''<sup>''n''</sup> → '''R'''<sup>''m''</sup>}} is given by\n:<math>\\int_{f(U)} \\phi(\\mathbf{v})\\, d\\mathbf{v} = \\int_U \\phi(f(\\mathbf{u})) \\left|\\det(\\operatorname{D}f)(\\mathbf{u})\\right| \\,d\\mathbf{u}.</math>\n\nThe Jacobian also occurs in the [[inverse function theorem]].\n\n=== Vandermonde determinant (alternant) ===\n{{Main|Vandermonde matrix}}\nThe third order Vandermonde determinant is\n:<math>\\left|\n\\begin{array}{ccc}\n 1 & 1 & 1 \\\\\n x_1 & x_2 & x_3 \\\\\n x_1^2 & x_2^2 & x_3^2\n\\end{array}\n\\right|=(x_3-x_2)(x_3-x_1)(x_2-x_1).</math>\nIn general, the ''n''th-order Vandermonde determinant is<ref name=\"Gradshteyn\">{{cite book |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |editor-first1=Alan |editor-last1=Jeffrey |editor-first2=Daniel |editor-last2=Zwillinger |translator=Scripta Technica, Inc. |title=Table of Integrals, Series, and Products |publisher=[[Academic Press, Inc.]] |date=February 2007 |edition=7 |language=English |isbn=0-12-373637-4 |lccn=2010481177 |mr=2360010 <!-- |url=https://books.google.com/books?id=aBgFYxKHUjsC |access-date=2016-02-21 -->|title-link=Gradshteyn and Ryzhik |chapter=14.31}}</ref>\n:<math>\\left|\\begin{array}{ccccc}\n            1 &         1 &         1 & \\cdots &         1 \\\\\n          x_1 &       x_2 &       x_3 & \\cdots &       x_n \\\\\n        x_1^2 &     x_2^2 &     x_3^2 & \\cdots &     x_n^2 \\\\\n       \\vdots &    \\vdots &    \\vdots & \\ddots &    \\vdots \\\\\n    x_1^{n-1} & x_2^{n-1} & x_3^{n-1} & \\cdots & x_n^{n-1}\n  \\end{array}\\right| =\n  \\prod_{1 \\leq i < j \\leq n} \\left(x_j - x_i\\right),\n</math>\n\nwhere the right-hand side is the continued product of all the differences that can be formed from the ''n''(''n''−1)/2 pairs of numbers taken from ''x''<sub>1</sub>, ''x''<sub>2</sub>, …, ''x''<sub>''n''</sub>, with the order of the differences taken in the reversed order of the suffixes that are involved.\n\n=== Circulants ===\n{{Main|Circulant matrix}}\nSecond order\n:<math>\\left|\\begin{array}{cc}\n  x_1 & x_2 \\\\\n  x_2 & x_1\n\\end{array}\\right| = \\left(x_1 + x_2\\right)\\left(x_1 - x_2\\right).</math>\n\nThird order\n:<math>\\left|\\begin{array}{ccc}\n    x_1 & x_2 & x_3 \\\\\n    x_3 & x_1 & x_2 \\\\\n    x_2 & x_3 & x_1\n  \\end{array}\\right| =\n  \\left(x_1 + x_2 + x_3\\right)\\left(x_1 + \\omega x_2 + \\omega^2 x_3\\right)\\left(x_1 + \\omega^2 x_2 + \\omega x_3\\right),\n</math>\n\nwhere ''ω'' and ''ω''<sup>2</sup> are the complex cube roots of 1. In general, the ''n''th-order circulant determinant is<ref name=\"Gradshteyn\" />\n:<math>\\left|\\begin{array}{ccccc}\n    x_1     & x_2    & x_3    & \\cdots & x_n     \\\\\n    x_n     & x_1    & x_2    & \\cdots & x_{n-1} \\\\\n    x_{n-1} & x_n    & x_1    & \\cdots & x_{n-2} \\\\\n    \\vdots  & \\vdots & \\vdots & \\ddots & \\vdots  \\\\\n    x_2     & x_3    & x_4    & \\cdots & x_1\n  \\end{array}\\right| =\n  \\prod_{j=1}^n \\left(x_1 + x_2\\omega_j + x_3\\omega_j^2 + \\cdots + x_n\\omega_j^{n-1}\\right),\n</math>\n\nwhere ''ω''<sub>''j''</sub> is an ''n''th root of 1.\n\n== See also ==\n{{portal|Mathematics}}\n{{colbegin}}\n* [[Cauchy determinant]]\n* [[Dieudonné determinant]]\n* [[Determinant identities]]\n* [[Functional determinant]]\n* [[Immanant of a matrix|Immanant]]\n* [[Matrix determinant lemma]]\n* [[Permanent (mathematics)|Permanent]]\n* [[Slater determinant]]\n{{colend}}\n\n== Notes ==\n{{Reflist|group=nb}}\n{{Reflist|45em}}\n\n== References ==\n{{See also|Linear algebra#Further reading}}\n* {{Citation | last = Axler | first = Sheldon Jay | authorlink=Sheldon Axler | year = 1997 | title = Linear Algebra Done Right | publisher = Springer-Verlag | edition = 2nd | isbn = 0-387-98259-0 }}\n* {{Citation | last1=de Boor | first1=Carl | author1-link=Carl R. de Boor | title=An empty exercise | url=http://ftp.cs.wisc.edu/Approx/empty.pdf | doi=10.1145/122272.122273 |year=1990 | journal=ACM SIGNUM Newsletter | volume=25 | issue=2 | pages=3–7}}.\n* {{Citation\n | last = Lay\n | first = David C.\n | date = August 22, 2005\n | title = Linear Algebra and Its Applications\n | publisher = Addison Wesley\n | edition = 3rd\n | isbn = 978-0-321-28713-7\n}}\n* {{Citation\n |last        = Meyer\n |first       = Carl D.\n |date        = February 15, 2001\n |title       = Matrix Analysis and Applied Linear Algebra\n |publisher   = Society for Industrial and Applied Mathematics (SIAM)\n |isbn        = 978-0-89871-454-8\n |url         = http://www.matrixanalysis.com/DownloadChapters.html\n |deadurl     = yes\n |archiveurl  = https://web.archive.org/web/20091031193126/http://matrixanalysis.com/DownloadChapters.html\n |archivedate = 2009-10-31\n |df          = \n}}\n* {{citation | last=Muir | first=Thomas | authorlink=Thomas Muir (mathematician) | title=A treatise on the theory of determinants | others=Revised and enlarged by William H. Metzler | origyear=1933 | year=1960 | publisher=Dover | location=New York, NY }}\n* {{Citation\n | last = Poole\n | first = David\n | year = 2006\n | title = Linear Algebra: A Modern Introduction\n | publisher = Brooks/Cole\n | edition = 2nd\n | isbn = 0-534-99845-3\n}}\n* [[G. Baley Price]] (1947) \"Some identities in the theory of determinants\", [[American Mathematical Monthly]] 54:75–90 {{mr|id=0019078}}\n* {{Citation\n | last1 = Horn\n | first1 = R. A.\n | last2 = Johnson\n | first2 = C. R.\n | year = 2013\n | title = Matrix Analysis\n | publisher = Cambridge University Press\n | edition = 2nd\n | isbn = 978-0-521-54823-6\n}}\n* {{Citation\n | last = Anton\n | first = Howard\n | year = 2005\n | title = Elementary Linear Algebra (Applications Version)\n | publisher = Wiley International\n | edition = 9th\n}}\n* {{Citation\n | last = Leon\n | first = Steven J.\n | year = 2006\n | title = Linear Algebra With Applications\n | publisher = Pearson Prentice Hall\n | edition = 7th\n}}\n\n== External links ==\n{{Wikibooks|1= Linear Algebra\n |2= Linear Algebra#Determinants\n |3= Determinants\n}}\n{{EB1911 poster|Determinant}}\n* {{SpringerEOM|title=Determinant|id=Determinant&oldid=12692|last=Suprunenko|first=D.A.}}\n* {{MathWorld|title=Determinant|urlname=Determinant}}\n* {{MacTutor|class=HistTopics||id=Matrices_and_determinants|title=Matrices and determinants}}\n* [http://people.revoledu.com/kardi/tutorial/LinearAlgebra/MatrixDeterminant.html Determinant Interactive Program and Tutorial]\n* [http://www.umat.feec.vutbr.cz/~novakm/determinanty/en/ Linear algebra: determinants.] Compute determinants of matrices up to order 6 using Laplace expansion you choose.\n* [http://www.economics.soton.ac.uk/staff/aldrich/matrices.htm Matrices and Linear Algebra on the Earliest Uses Pages]\n* [http://algebra.math.ust.hk/course/content.shtml Determinants explained in an easy fashion in the 4th chapter as a part of a Linear Algebra course.]\n* [https://khanexercises.appspot.com/video?v=H9BWRYJNIv4 Instructional Video on taking the determinant of an nxn matrix (Khan Academy)]\n* {{Cite web |title=The determinant |work=Essence of linear algebra |via=[[YouTube]] |url=https://www.youtube.com/watch?v=Ip3X9LOh2dk&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=7 }}\n\n{{Linear algebra}}\n\n[[Category:Determinants| ]]\n[[Category:Matrix theory]]\n[[Category:Linear algebra]]\n[[Category:Homogeneous polynomials]]\n[[Category:Algebra]]"
    },
    {
      "title": "Differential equations of addition",
      "url": "https://en.wikipedia.org/wiki/Differential_equations_of_addition",
      "text": "In [[cryptography]], '''differential equations of addition''' (DEA) are one of the most basic equations related to [[differential cryptanalysis]] that mix additions over two different groups (e.g. addition modulo 2<sup>32</sup> and addition over GF(2)) and  where input and output differences are expressed as XORs.\n\n== Examples of Differential Equations of Addition ==\n'''Differential equations of addition''' (DEA) are of the following form:\n\n<math>(x+y)\\oplus((x\\oplus a)+(y\\oplus b))=c</math>\n\nwhere <math>x</math> and <math>y</math> are <math>n</math>-bit '''unknown''' variables and <math>a</math>, <math>b</math> and <math>c</math> are '''known''' variables. The symbols <math>+</math> and <math>\\oplus</math> denote ''addition modulo'' <math>2^n</math> and ''bitwise exclusive-or'' respectively. The above equation is denoted by <math>(a, b, c)</math>.\n\nLet a set <math>S=\\{(a_i, b_i, c_i)|i</math> is an integer less than <math>k\\}</math> denote a system of <math>k</math> '''DEA''' where <math>k</math> is a polynomial in <math>n</math>. It has been proved that the satisfiability of an arbitrary set of DEA is in the '''[[P = NP problem|complexity class P]]''' when a brute force search requires an [[exponential time]]. In 2013, some properties of a special form of\n\nDEA were reported by Chengqing Li et al., where <math>a=0</math> and <math>y</math> is assumed known. Essentially, the special DEA can be represented as <math>(x \\dotplus \\alpha) \\oplus (x\\dotplus \\beta)=c</math>. Based on the found properties, a algorithm for deriving <math>x</math> was proposed and analyzed.<ref>{{Cite journal|last=Li|first=Chengqing|last2=Liu|first2=Yuansheng|last3=Zhang|first3=Leo Yu|last4=Chen|first4=Michael Z. Q.|date=2013-04-01|title=Breaking a chaotic image encryption algorithm based on modulo addition and xor operation|url=http://www.worldscientific.com/doi/abs/10.1142/S0218127413500752|journal=International Journal of Bifurcation and Chaos|volume=23|issue=04|pages=1350075|doi=10.1142/S0218127413500752|issn=0218-1274|arxiv=1207.6536|bibcode=2013IJBC...2350075L}}</ref>\n\n== Usage of Differential Equations of Addition ==\nSolution to an arbitrary set of DEA (either in batch and or in adaptive query model) was due to [[Souradyuti Paul]] and [[Bart Preneel]]. The solution techniques have been used to attack the stream cipher [[Phelix|Helix]].\n\n== References ==\n* [[Souradyuti Paul]] and [[Bart Preneel]], Solving Systems of Differential Equations of Addition, ACISP 2005.  [http://www.cosic.esat.kuleuven.be/publications/article-566.pdf Full version] ([[PDF]])\n* [[Souradyuti Paul]] and [[Bart Preneel]], Near Optimal Algorithms for Solving Differential Equations of Addition With Batch Queries, [[Indocrypt]] 2005.  [http://www.cosic.esat.kuleuven.be/publications/article-587.pdf Full version] ([[PDF]])\n* Helger Lipmaa, Johan Wallén, Philippe Dumas: On the Additive Differential Probability of Exclusive-Or. [[Fast Software Encryption|FSE]] 2004: 317-331.<references />\n\n{{Cryptography navbox | block}}\n\n[[Category:Cryptographic attacks]]\n[[Category:Theory of cryptography]]\n[[Category:Ciphers]]\n[[Category:Algebra]]"
    },
    {
      "title": "Digital root",
      "url": "https://en.wikipedia.org/wiki/Digital_root",
      "text": "{{no footnotes|date=January 2016}}\nThe '''digital root''' (also '''repeated digital sum''') of a [[non-negative integer]] is the (single digit) value obtained by an iterative process of [[digit sum|summing digits]], on each iteration using the result from the previous iteration to compute a digit sum. The process continues until a single-digit number is reached.\n\nFor example, the digital root of 65,536 is 7, because {{nowrap|1=6 + 5 + 5 + 3 + 6 = 25}} and {{nowrap|1=2 + 5 = 7.}}\n\nDigital roots can be calculated with [[Congruence relation|congruence]]s in [[modular arithmetic#Congruence_relation|modular arithmetic]] rather than by adding up all the digits, a procedure that can save time in the case of very large numbers.\n\nDigital roots can be used as a sort of [[checksum]], to check that a sum has been performed correctly. If it has, then the digital root of the sum of the given numbers will equal the digital root of the sum of the digital roots of the given numbers. This check, which involves only single-digit calculations, can catch many errors in calculation.\n\nDigital roots are used in Western [[numerology]], but certain numbers deemed to have occult significance (such as 11 and 22) are not always completely reduced to a single digit.\n\nThe number of times the digits must be summed to reach the digital root is called a number's additive [[Persistence of a number|persistence]]; in the above example, the additive persistence of 65,536 is 2.\n\n== Significance and formula of the digital root ==\nIt helps to see the digital root of a positive integer as the position it holds with respect to the largest multiple of 9 less than the number itself. For example, the digital root of 11 is 2, which means that 11 is the second number after 9. Likewise, the digital root of 2035 is 1, which means that 2035&nbsp;−&nbsp;1 is a multiple of 9. If a number produces a digital root of exactly 9, then the number is a multiple of 9.\n\nWith this in mind the digital root of a positive integer <math>n</math> may be defined by using [[floor function]] <math>\\lfloor x\\rfloor </math>, as\n:<math>\\operatorname{dr}(n)=n-9\\left\\lfloor\\frac{n-1}{9}\\right\\rfloor.</math>\n\n== Abstract multiplication of digital roots ==\nThe table below shows the digital roots produced by the familiar [[multiplication table]] in the decimal system.\n<div align=\"center\">\n{|class=\"wikitable\" style=\"text-align:center; width:270px; height:270px\" border=\"1\"\n! <math>\\circ</math> !! 1 !! 2 !! 3 !! 4 !! 5 !! 6 !! 7 !! 8 !! 9\n|-\n! 1\n|style=\"background-color:#fbb\"|1||style=\"background-color:#EFD7FF\"|2||style=\"background-color:#ffa\"|3||style=\"background-color:#EAFFEF\"|4||style=\"background-color:#A4F0B7\"|5||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#CEFFFD\"|7||style=\"background-color:#EEEEFF\"|8||style=\"background-color:#2FAACE\"|9\n|-\n!2\n|style=\"background-color:#EFD7FF\"|2||style=\"background-color:#EAFFEF\"|4||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#EEEEFF\"|8||style=\"background-color:#fbb\"|1||style=\"background-color:#ffa\"|3||style=\"background-color:#A4F0B7\"|5||style=\"background-color:#CEFFFD\"|7||style=\"background-color:#2FAACE\"|9\n|-\n!3\n|style=\"background-color:#ffa\"|3||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#2FAACE\"|9||style=\"background-color:#ffa\"|3||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#2FAACE\"|9||style=\"background-color:#ffa\"|3||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#2FAACE\"|9\n|-\n!4\n|style=\"background-color:#EAFFEF\"|4||style=\"background-color:#EEEEFF\"|8||style=\"background-color:#ffa\"|3||style=\"background-color:#CEFFFD\"|7||style=\"background-color:#EFD7FF\"|2||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#fbb\"|1||style=\"background-color:#A4F0B7\"|5||style=\"background-color:#2FAACE\"|9\n|-\n!5\n|style=\"background-color:#A4F0B7\"|5||style=\"background-color:#fbb\"|1||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#EFD7FF\"|2||style=\"background-color:#CEFFFD\"|7||style=\"background-color:#ffa\"|3||style=\"background-color:#EEEEFF\"|8||style=\"background-color:#EAFFEF\"|4||style=\"background-color:#2FAACE\"|9\n|-\n!6\n|style=\"background-color:#BBDAFF\"|6||style=\"background-color:#ffa\"|3||style=\"background-color:#2FAACE\"|9||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#ffa\"|3||style=\"background-color:#2FAACE\"|9||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#ffa\"|3||style=\"background-color:#2FAACE\"|9\n|-\n!7\n|style=\"background-color:#CEFFFD\"|7||style=\"background-color:#A4F0B7\"|5||style=\"background-color:#ffa\"|3||style=\"background-color:#fbb\"|1||style=\"background-color:#EEEEFF\"|8||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#EAFFEF\"|4||style=\"background-color:#EFD7FF\"|2||style=\"background-color:#2FAACE\"|9\n|-\n!8\n|style=\"background-color:#EEEEFF\"|8||style=\"background-color:#CEFFFD\"|7||style=\"background-color:#BBDAFF\"|6||style=\"background-color:#A4F0B7\"|5||style=\"background-color:#EAFFEF\"|4||style=\"background-color:#ffa\"|3||style=\"background-color:#EFD7FF\"|2||style=\"background-color:#fbb\"|1||style=\"background-color:#2FAACE\"|9\n|-\n!9\n|style=\"background-color:#2FAACE\"|9||style=\"background-color:#2FAACE\"|9||style=\"background-color:#2FAACE\"|9||style=\"background-color:#2FAACE\"|9||style=\"background-color:#2FAACE\"|9||style=\"background-color:#2FAACE\"|9||style=\"background-color:#2FAACE\"|9||style=\"background-color:#2FAACE\"|9||style=\"background-color:#2FAACE\"|9\n|}\n</div>\n\nThe table shows a number of interesting [[patterns]] and [[symmetries]] and is known as the [[Vedic square]].\n\n== Formal definition ==\nLet <math>S(n)</math> denote the sum of the digits of <math>n</math> and let the composition of <math>S(n)</math> be as follows:\n:<math>S^{1}(n)=S(n),\\ \\ S^{m}(n)=S\\left(S^{m-1}(n)\\right),\\ \\text{for}\\ m\\ge2.</math>\nEventually the sequence <math>S^{1}(n),S^{2}(n),S^{3}(n),\\ldots</math> becomes a one digit number. Let <math>S^{*}(n)</math> (the digital root of <math>n</math>) represent this one digit number.\n\n=== Example ===\nLet us find the digital root of <math>1853</math>.\n\n:<math>S(1853)=17</math>\n\n:<math>S(17)=8</math>\n\nThus,\n\n:<math>S^{2}(1853)=8.</math>\n\nFor simplicity let us agree simply that\n\n:<math>S^{*}(1853)=\\operatorname{dr}(1853)=8.</math>\n\n=== Proof that a constant value exists ===\nHow do we know that the sequence <math>S^{1}(n),S^{2}(n),S^{3}(n),\\ldots</math> eventually becomes a one digit number? Here's a proof:\n\nLet <math>n=d_1+10d_2+\\cdots+10^{m-1}d_m</math>, for all <math>i</math>, <math>d_i</math> is an [[integer]] greater than or equal to 0 and less than 10. Then, <math>S(n)=d_1+d_2+\\cdots+d_m</math>. This means that <math>S(n)<n</math>, unless <math>d_2,d_3,\\ldots,d_m=0</math>, in which case <math>n</math> is a one digit number. Thus, repeatedly using the <math>S(n)</math> function would cause <math>n</math> to decrease by at least 1, until it becomes a one digit number, at which point it will stay constant, as <math>S(d_1)=d_1</math>.\n\n==Congruence formula==\nThe formula is:\n:<math> \\operatorname{dr}(n) = \\begin{cases}0 & \\mbox{if}\\ n = 0, \\\\ 9 & \\mbox{if}\\ n \\neq 0,\\ n\\ \\equiv 0\\pmod{9},\\\\ n\\ {\\rm mod}\\ 9 & \\mbox{if}\\ n \\not\\equiv 0\\pmod{9}\\end{cases}</math>\nor,\n:<math>\\operatorname{dr}(n) = 1\\ +\\ ((n-1)\\ {\\rm mod}\\ 9).</math>\n\nTo generalize the concept of digital roots to other bases ''b'', one can simply change the 9 in the formula to ''b'' - 1.\n\n{{OEIS|id=A010888}}\n\nThe digital root is the value modulo 9 because <math>10 \\equiv 1\\pmod{9},</math> and thus <math>10^k \\equiv 1^k \\equiv 1\\pmod{9},</math> so regardless of position, the value mod 9 is the same – <math>a\\cdot 100 \\equiv a\\cdot 10 \\equiv a\\pmod{9}</math> – which is why digits can be meaningfully added. Concretely, for a three-digit number,\n:<math>\\operatorname{dr}(abc) \\equiv a\\cdot 10^2 + b\\cdot 10 + c \\cdot 1 \\equiv a\\cdot 1 + b\\cdot 1 + c \\cdot 1 \\equiv a + b + c \\pmod{9}</math>.\n\nTo obtain the modular value with respect to other numbers ''n,'' one can take [[weighted sum]]s, where the weight on the ''k''th digit corresponds to the value of <math>10^k</math> modulo ''n,'' or analogously for <math>b^k</math> for different bases. This is simplest for 2, 5, and 10, where higher digits vanish (since 2 and 5 divide 10), which corresponds to the familiar fact that the divisibility of a decimal number with respect to 2, 5, and 10 can be checked by the last digit (even numbers end in 0, 2, 4, 6, or 8).\n\nAlso of note is the modulus 11: since <math>10 \\equiv -1\\pmod{11},</math> and thus <math>10^2 \\equiv (-1)^2 \\equiv 1\\pmod{11},</math> taking the ''alternating'' sum of digits yields the value modulo 11.\n\n== Some properties of digital roots ==\nThe digital root of a number is zero if and only if the number is itself zero.\n:<math>\\operatorname{dr}(n)=0 \\Leftrightarrow n=0.</math>\nThe digital root of a number is a positive integer if and only if the number is itself a positive integer.\n:<math>\\operatorname{dr}(n)>0 \\Leftrightarrow n>0.</math>\nThe digital root of <math>n</math> is <math>n</math> itself if and only if the number has exactly one digit.\n:<math>\\operatorname{dr}(n)=n \\Leftrightarrow n \\in \\{0,1,2,3,4,5,6,7,8,9\\}.</math>\nThe digital root of <math>n</math> is less than <math>n</math> if and only if the number is greater than or equal to 10.\n:<math>\\operatorname{dr}(n)<n \\Leftrightarrow n \\ge 10.</math>\nThe digital root of <math>a</math> + <math>b</math> is digital root of the sum of the digital root of <math>a</math> and the digital root of <math>b</math>.\n:<math>\\operatorname{dr}(a+b) = \\operatorname{dr}(\\operatorname{dr}(a)+\\operatorname{dr}(b) ).</math>\nThe digital root of <math>a</math> - <math>b</math> is congruent with the difference of the digital root of <math>a</math> and the digital root of <math>b</math> modulo 9.\n:<math>\\operatorname{dr}(a-b) \\equiv \\operatorname{dr}(a)-\\operatorname{dr}(b) \\pmod{9}.</math>\nEspecially, we can define the digital root of minus <math>n</math> as follows:\n:<math>\\operatorname{dr}(-n) \\equiv -\\operatorname{dr}(n) \\pmod{9}.</math>\nThe digital root of <math>a</math> &times; <math>b</math> is digital root of the product of the digital root of <math>a</math> and the digital root of <math>b</math>.\n:<math>\\operatorname{dr}(ab) = \\operatorname{dr}(\\operatorname{dr}(a)\\cdot\\operatorname{dr}(b) ).</math>\n*The digital root of a nonzero number is 9 if and only if the number is itself a [[multiple (mathematics)|multiple]] of 9.\n:<math>\\operatorname{dr}(n)=9 \\Leftrightarrow n=9m \\quad \\text{for } m=1,2,3,\\ldots.</math>\n*The digital root of a nonzero number is a multiple of 3 if and only if the number is itself a multiple of 3.\n:<math>\\begin{align} \\operatorname{dr}(n) &=3 \\Leftrightarrow n=9m+3 & \\text{ for } m=0,1,2,\\ldots,\\\\ \\operatorname{dr}(n) &=6 \\Leftrightarrow n=9m+6 & \\ \\text{for}\\  m=0,1,2,\\ldots,\\\\ \\operatorname{dr}(n) &=9 \\Leftrightarrow n=9m   & \\ \\text{for}\\  m=1,2,3,\\ldots.\\end{align}</math>\n*The digital root of a [[factorial]] ≥ 6! is 9.\n:<math>\\operatorname{dr}(n!)=9 \\Leftrightarrow n \\ge 6.</math>\n*The digital root of a [[square number|square]] is 1, 4, 7, or 9. Digital roots of square numbers progress in the sequence 1, 4, 9, 7, 7, 9, 4, 1, 9.\n*The digital root of a [[perfect cube]] is 1, 8 or 9, and digital roots of perfect cubes progress in that exact sequence.\n*The digital root of integers raised to integer powers greater than 3 is 1, 2, 4, 5, 7, 8 or 9.\n*The digital root of a [[prime number]] (except 3) is 1, 2, 4, 5, 7, or 8.\n*The digital root of a [[power of two|power of 2]] is 1, 2, 4, 5, 7, or 8. Digital roots of the powers of 2 progress in the sequence 1, 2, 4, 8, 7, 5. This even applies to negative powers of 2; for example, 2 to the power of 0 is 1; 2 to the power of -1 (minus one) is .5, with a digital root of 5; 2 to the power of -2 is .25, with a digital root of 7; and so on, ad infinitum in both directions. This is because negative powers of 2 share the same digits (after removing leading zeroes) as corresponding positive powers of 5, whose digital roots progress in the sequence 1, 5, 7, 8, 4, 2.\n* The digital root of a power of 5 is 1, 2, 4, 5, 7 or 8. Digital roots of the powers of 5 progress in the sequence 1, 5, 7, 8, 4, 2. This even applies to negative powers of 5; for example, 5 to the power of 0 is 1; 5 to the power of -1 (minus one) is .2, with a digital root of 2; 5 to the power of -2 is .04, with a digital root of 4; and so on, ad infinitum in both directions. This is because the negative powers of 5 share the same digits (after removing leading zeroes) as corresponding positive powers of 2, whose digital roots progress in sequence 1, 2, 4, 8, 7, 5.\n* The digital roots of powered numbers progress in sequence (only certain for positive powers, although in for some exceptions it also may occur for negative powers), and this is because of one of the previously shown properties. As the digital root of ''a''  ''b'' is congruent with the multiple of the digital root of ''a'' and the digital root of ''b'' modulo 9, the digital root of ''a''  ''a'' will also do it. So, for example, as shown above, powers of 2 will follows the sequence 1, 2, 4, 8, 7, 5; Powers of 47 (whose digital root is 2) will also follow this sequence. The very sequence follows this rule, and is applicable to any other number. Hence, it is easy to demonstrate that an integer raised to a positive integer power will never have a digital root of 3 or 6.\n:<math>\\operatorname{dr}(a^n) \\equiv \\operatorname{dr}(a)^n \\pmod{9}.</math>\n*The digital root of an even [[perfect number]] (except 6) is 1.\n*The digital root of a centered hexagram, or [[star number]] is 1 or 4. Digital roots of star numbers progress in the sequence 1, 4, 1.\n*The digital root of a [[centered hexagonal number]] is 1 or 7, their digital roots progressing in the sequence 1, 7, 1.\n*The digital root of a [[triangular number]] is 1, 3, 6 or 9. Digital roots of triangular numbers progress in the sequence 1, 3, 6, 1, 6, 3, 1, 9, 9, which is palindromic after the first eight terms.\n*The digital root of [[Fibonacci number]]s is a repeating pattern of 1, 1, 2, 3, 5, 8, 4, 3, 7, 1, 8, 9, 8, 8, 7, 6, 4, 1, 5, 6, 2, 8, 1, 9.\n*The digital root of [[Lucas number]]s is a repeating pattern of 2, 1, 3, 4, 7, 2, 9, 2, 2, 4, 6, 1, 7, 8, 6, 5, 2, 7, 9, 7, 7, 5, 3, 8.\n*The digital root of the product of [[twin prime]]s, other than 3 and 5, is 8. The digital root of the product of 3 and 5 (twin primes) is 6.\n\n== In other bases ==\nThis article is about the digital root in [[decimal]] or base ten, hence it is the number mod 9. It is nothing different as the number converted to base 9 and then only the last digit taken.\nIn other radixes the digital root is number mod (base-1) so in [[duodecimal|base 12]] a digital root of a number is the number mod 11 (Ɛ<sub>duod</sub>), for example, 1972<sub>duod</sub> is 1 + 9 + 7 + 2 = 19 = 17<sub>duod</sub> which is 1 + 7 = 8, while in decimal the root of the same number (3110) is 5; and in [[hexadecimal|base 16]] a digital root of a number is the number mod 15 (0xF), for example, 0x7DF is 7 + 13 + 15 = 35 = 0x23 which is 2 + 3 = 5, while in decimal the root of the same number (2015) is 8.\n\n== In popular culture ==\nDigital roots form an important mechanic in the visual novel adventure game [[Nine Hours, Nine Persons, Nine Doors]].\n\n== See also ==\n{{Div col}}\n*[[Base 9]]\n*[[Casting out nines]]\n*[[Digit sum]]\n*[[Hamming weight]]\n*[[Multiplicative digital root]]\n*[[Vedic square]]\n{{Div col end}}\n\n==References==\n*{{Citation|last1=Averbach|first1=Bonnie|author1-link=Bonnie Averbach|last2=Chein|first2=Orin|author2-link=Orin Chein|date=27 May 1999|title=Problem Solving Through Recreational Mathematics|publisher=Courier Dover Publications|location=Mineola, NY|edition=reprinted|series=Dover Books on Mathematics|isbn=0-486-40917-1|pages=125–127}} ({{Google books|qtMoAwAAQBAJ|online copy|page=125}})\n*{{Citation|last=Ghannam|first=Talal|author-link=Talal Ghannam|date=4 January 2011|title=The Mystery of Numbers: Revealed Through Their Digital Root|publisher=CreateSpace Publications|isbn=978-1-4776-7841-1|url=https://www.createspace.com/3529186|pages=68–73}} ({{Google books|PN4dzi8eoZQC|online copy|page=68}})\n*{{Citation|last=Hall|first=F. M.|author-link=Frederick Michael Hall|year=1980|title=An Introduction into Abstract Algebra|publisher=CUP Archive|location=Cambridge, U.K.|edition=2nd|volume=1|isbn=978-0-521-29861-2|page=101}} ({{Google books|qqs8AAAAIAAJ|online copy|page=101}})\n*{{Citation|last=O'Beirne|first=T. H.|author-link=T. H. O'Beirne|date=13 March 1961|title=Puzzles and Paradoxes|journal=New Scientist|publisher=Reed Business Information|volume=10|issue=230|issn=0262-4079|pages=53–54}} ({{Google books|j4VdAP43V7cC|online copy|page=53}})\n*{{Citation|last1=Rouse Ball|first1=W. W.|author1-link=Walter William Rouse Ball|last2=Coxeter|first2=H. S. M.|author2-link=Harold Scott Macdonald Coxeter|date=6 May 2010|title=Mathematical Recreations and Essays|publisher=Dover Publications|location=NY|edition=13th|series=Dover Recreational Mathematics|isbn=978-0-486-25357-2}} ({{Google books|9lJqNJhYc9oC|online copy}})\n\n== External links ==\n* [http://people.revoledu.com/kardi/tutorial/DigitSum/index.html pattern of digital root using MS Excel]\n*{{MathWorld|title=Digital Root|id=DigitalRoot}}\n\n[[Category:Algebra]]\n[[Category:Number theory]]\n\n[[de:Quersumme#Einstellige (oder iterierte) Quersumme]]"
    },
    {
      "title": "Distribution (number theory)",
      "url": "https://en.wikipedia.org/wiki/Distribution_%28number_theory%29",
      "text": "In [[algebra]] and [[number theory]], a '''distribution''' is a function on a system of finite sets into an [[abelian group]] which is analogous to an integral: it is thus the algebraic analogue of a [[distribution (mathematics)|distribution]] in the sense of [[generalised function]].\n\nThe original examples of distributions occur, unnamed, as functions φ on '''Q'''/'''Z''' satisfying<ref>Kubert & Lang (1981) p.1</ref>\n\n:<math> \\sum_{r=0}^{N-1} \\phi\\left(x + \\frac r N\\right) = \\phi(Nx) \\ . </math>\n\nWe shall call these '''ordinary distributions'''.<ref>Lang (1990) p.53</ref>  They also occur in ''p''-adic integration theory in [[Iwasawa theory]].<ref name=MSD36>Mazur & Swinnerton-Dyer (1972) p.&nbsp;36</ref>\n\nLet ... → ''X''<sub>''n''+1</sub> → ''X''<sub>''n''</sub> → ... be a [[projective system]] of finite sets with surjections, indexed by the natural numbers, and let ''X'' be their [[projective limit]].  We give each ''X''<sub>''n''</sub> the [[discrete topology]], so that ''X'' is [[compact space|compact]].  Let φ = (φ<sub>''n''</sub>) be a family of functions on ''X''<sub>''n''</sub> taking values in an abelian group ''V'' and compatible with the projective system:\n\n:<math> w(m,n) \\sum_{y \\mapsto x} \\phi(y) = \\phi(x) </math>\n\nfor some ''weight function'' ''w''.  The family φ is then a ''distribution'' on the projective system ''X''.\n\nA function ''f'' on ''X'' is \"locally constant\", or a \"step function\" if it factors through some ''X''<sub>''n''</sub>.  We can define an integral of a step function against φ as\n\n:<math> \\int f \\, d\\phi = \\sum_{x \\in X_n} f(x) \\phi_n(x) \\ . </math>\n\nThe definition extends to more general projective systems, such as those indexed by the positive integers ordered by divisibility.  As an important special case consider the projective system '''Z'''/''n''{{zwnj}}'''Z''' indexed by positive integers ordered by divisibility.   We identify this with the system (1/''n'')'''Z'''/'''Z''' with limit '''Q'''/'''Z'''.\n\nFor ''x'' in ''R'' we let ⟨''x''⟩ denote the fractional part of ''x'' normalised to 0 ≤ ⟨''x''⟩ < 1, and let {''x''} denote the fractional part normalised to 0&nbsp;<&nbsp;{''x''}&nbsp;≤&nbsp;1.\n\n==Examples==\n\n===Hurwitz zeta function===\nThe [[multiplication theorem]] for the [[Hurwitz zeta function]]\n\n:<math>\\zeta(s,a) = \\sum_{n=0}^\\infty (n+a)^{-s} </math>\n\ngives a distribution relation\n\n:<math>\\sum_{p=0}^{q-1}\\zeta(s,a+p/q)=q^s\\,\\zeta(s,qa) \\ .</math>\n\nHence for given ''s'', the map <math>t \\mapsto \\zeta(s,\\{t\\})</math> is a distribution on '''Q'''/'''Z'''.\n\n===Bernoulli distribution===\nRecall that the ''[[Bernoulli polynomials]]''  ''B''<sub>''n''</sub> are defined by\n\n:<math>B_n(x) = \\sum_{k=0}^n {n \\choose n-k} b_k x^{n-k} \\ ,</math>\n\nfor ''n'' ≥ 0, where ''b''<sub>''k''</sub> are the [[Bernoulli number]]s, with  [[generating function]]\n\n:<math>\\frac{t e^{xt}}{e^t-1}= \\sum_{n=0}^\\infty B_n(x) \\frac{t^n}{n!} \\ .</math>\n\nThey satisfy the ''distribution relation''\n\n:<math> B_k(x) = n^{k-1} \\sum_{a=0}^{n-1} b_k\\left({\\frac{x+a}{n}}\\right)\\ . </math>\n\nThus the map\n\n:<math> \\phi_n : \\frac{1}{n}\\mathbb{Z}/\\mathbb{Z} \\rightarrow \\mathbb{Q} </math>\n\ndefined by\n\n:<math> \\phi_n : x \\mapsto n^{k-1} B_k(\\langle x \\rangle) </math>\n\nis a distribution.<ref>Lang (1990) p.36</ref>\n\n===Cyclotomic units===\nThe [[cyclotomic unit]]s satisfy ''distribution relations''.  Let ''a'' be an element of '''Q'''/'''Z''' prime to ''p'' and let ''g''<sub>''a''</sub> denote exp(2πi''a'')−1.  Then for ''a''≠ 0 we have<ref>Lang (1990) p.157</ref>\n\n:<math> \\prod_{p b=a} g_b = g_a \\ . </math>\n\n==Universal distribution==\nOne considers the distributions on ''Z'' with values in some abelian group ''V'' and seek the \"universal\" or most general distribution possible.\n\n==Stickelberger distributions==\nLet ''h'' be an ordinary distribution on '''Q'''/'''Z''' taking values in a field ''F''.  Let ''G''(''N'') denote the multiplicative group of '''Z'''/''N''{{zwnj}}'''Z''', and for any function ''f'' on ''G''(''N'') we extend ''f'' to a function on '''Z'''/''N''{{zwnj}}'''Z''' by taking ''f'' to be zero off ''G''(''N'').  Define an element of the group algebra ''F''[''G''(''N'')] by\n\n:<math> g_N(r) = \\frac{1}{|G(N)|} \\sum_{a \\in G(N)} h\\left({\\left\\langle{\\frac{ra}{N}}\\right\\rangle}\\right) \\sigma_a^{-1} \\ . </math>\n\nThe group algebras form a projective system with limit ''X''.  Then the functions ''g''<sub>''N''</sub> form a distribution on '''Q'''/'''Z''' with values in ''X'', the '''Stickelberger distribution''' associated with ''h''.\n\n==p-adic measures==\nConsider the special case when the value group ''V'' of a distribution φ on ''X'' takes values in a [[local field]] ''K'', finite over '''Q'''<sub>''p''</sub>, or more generally, in a finite-dimensional\n''p''-adic Banach space ''W'' over ''K'', with valuation |·|.  We call φ a '''measure''' if |φ| is bounded on compact open subsets of ''X''.<ref name=MSD37>Mazur & Swinnerton-Dyer (1974) p.37</ref>  Let ''D'' be the ring of integers of ''K'' and ''L'' a lattice in ''W'', that is, a free ''D''-submodule of ''W'' with ''K''⊗''L'' = ''W''.  Up to scaling a measure may be taken to have values in ''L''.\n\n===Hecke operators and measures===\nLet ''D'' be a fixed integer prime to ''p'' and consider '''Z'''<sub>''D''</sub>, the limit of the system '''Z'''/''p''<sup>''n''</sup>''D''.  Consider any [[eigenfunction]] of the [[Hecke operator]] ''T''<sup>''p''</sup> with eigenvalue ''λ''<sub>''p''</sub> prime to ''p''.  We describe a procedure for deriving a measure of '''Z'''<sub>''D''</sub>.\n\nFix an integer ''N'' prime to ''p'' and to ''D''.  Let ''F'' be the ''D''-module of all functions on rational numbers with denominator coprime to ''N''.  For any prime ''l'' not dividing ''N'' we define the ''Hecke operator'' ''T''<sub>''l''</sub> by\n\n:<math> (T_l f)\\left(\\frac a b\\right) = f\\left(\\frac{la}{b}\\right) + \\sum_{k=0}^{l-1} f\\left({\\frac{a+kb}{lb}}\\right) - \\sum_{k=0}^{l-1} f\\left(\\frac k l \\right) \\ . </math>\n\nLet ''f'' be an eigenfunction for ''T''<sub>''p''</sub> with eigenvalue λ<sub>''p''</sub> in ''D''.  The quadratic equation ''X''<sup>2</sup>&nbsp;−&nbsp;λ<sub>''p''</sub>''X''&nbsp;+&nbsp;''p''&nbsp;=&nbsp;0 has roots π<sub>1</sub>, π<sub>2</sub> with π<sub>1</sub> a unit and  π<sub>2</sub> divisible by ''p''.  Define a sequence ''a''<sub>0</sub>&nbsp;=&nbsp;2, ''a''<sub>1</sub> =&nbsp;π<sub>1</sub>+π<sub>2</sub> =&nbsp;''λ''<sub>''p''</sub> and\n\n:<math>a_{k+2} = \\lambda_p a_{k+1} - p a_k \\ , </math>\n\nso that\n\n:<math>a_k = \\pi_1^k + \\pi_2^k \\ . </math>\n\n==References==\n{{reflist}}\n* {{cite book | first1=Daniel S. | last1=Kubert | authorlink1=Daniel Kubert | first2=Serge | last2=Lang | authorlink2=Serge Lang | title=Modular Units | series= Grundlehren der Mathematischen Wissenschaften | volume=244 | publisher=[[Springer-Verlag]] | year=1981 | isbn=0-387-90517-0 | zbl=0492.12002 }}\n* {{cite book | last=Lang | first=Serge | authorlink=Serge Lang | title=Cyclotomic Fields I and II | edition=second combined | publisher=[[Springer Verlag]] | series=[[Graduate Texts in Mathematics]] | volume=121 | isbn=3-540-96671-4 | zbl=0704.11038 | year=1990 }}\n* {{cite journal | zbl=0281.14016 | last1=Mazur | first1=B. | author1-link=Barry Mazur | last2=Swinnerton-Dyer | first2=P. | author2-link=Peter Swinnerton-Dyer | title=Arithmetic of Weil curves | journal=[[Inventiones Mathematicae]] | volume=25 | pages=1–61 | year=1974 | url=http://www.springerlink.com/content/l30185r823104886/ | doi=10.1007/BF01389997 }}\n\n[[Category:Algebra]]\n[[Category:Number theory]]"
    },
    {
      "title": "Distribution algebra",
      "url": "https://en.wikipedia.org/wiki/Distribution_algebra",
      "text": "{{Orphan|date=December 2012}}\n\nIn [[algebra]], the '''distribution algebra''' <math>D(G, K)</math> of a [[p-adic Lie group|''p''-adic Lie group]] ''G'' is the ''K''-algebra of ''K''-valued distributions on ''G''. (See the reference for a more precise definition.)\n\n== References ==\n*{{cite journal |journal=Representation theory An electric journal of the American Mathematical Society |title=<math>U(\\mathfrak{g})</math>-finite locally analytic representations |last1= Schneider |first1=P. |first2=J. |last2=Teitelbaum |url=http://www.ams.org/journals/ert/2001-005-05/S1088-4165-01-00109-1/S1088-4165-01-00109-1.pdf}}\n\n[[Category:Algebra]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Distributive homomorphism",
      "url": "https://en.wikipedia.org/wiki/Distributive_homomorphism",
      "text": "{{multiple issues|\n{{expert-subject|date=November 2011}}\n{{technical|date=November 2011}}\n}}\n\nA [[Congruence relation|congruence]] θ of a [[Semilattice|join-semilattice]] ''S'' is ''monomial'', if the θ-[[equivalence class]] of any element of ''S'' has a largest element. We say that θ is ''distributive'', if it is a [[Join (mathematics)|join]], in the [[Compact element|congruence lattice]] Con ''S'' of ''S'', of monomial join-congruences of ''S''.\n\nThe following definition originates in Schmidt's 1968 work and was subsequently adjusted by Wehrung.\n\n'''Definition (weakly distributive homomorphisms).''' A homomorphism \n''&mu; : S → T'' between join-semilattices ''S'' and ''T'' is ''weakly distributive'', if for all ''a, b'' in ''S'' and all ''c'' in ''T'' such that ''&mu;(c)&le; a &or; b'', there are elements ''x'' and ''y'' of ''S'' such that ''c&le; x &or; y'', ''&mu;(x)&le; a'', and ''&mu;(y)&le; b''.\n\n'''Examples:'''\n\n(1) For an [[Universal algebra|algebra]] ''B'' and a ''reduct'' ''A'' of ''B'' (that is, an algebra with same underlying set as ''B'' but whose set of operations is a subset of the one of ''B''), the canonical (∨, 0)-homomorphism from Con<sub>c</sub> A to Con<sub>c</sub> B is weakly distributive. Here, Con<sub>c</sub> A denotes the (∨, 0)-semilattice of all [[Compact element|compact congruences]] of ''A''.\n\n(2) For a [[Lattice (order)|convex sublattice]] ''K'' of a lattice ''L'', the canonical (∨, 0)-homomorphism from Con<sub>c</sub> ''K'' to Con<sub>c</sub> ''L'' is weakly distributive.\n\n== References ==\n\nE.T. Schmidt, ''Zur Charakterisierung der Kongruenzverbände der Verbände'', Mat. Casopis Sloven. Akad. Vied. '''18''' (1968), 3--20.\n\nF. Wehrung, ''A uniform refinement property for congruence lattices'', Proc. Amer. Math. Soc. '''127''', no. 2 (1999), 363–370.\n\nF. Wehrung, ''A solution to Dilworth's congruence lattice problem'', preprint 2006.\n\n[[Category:Algebra]]"
    },
    {
      "title": "Elementary algebra",
      "url": "https://en.wikipedia.org/wiki/Elementary_algebra",
      "text": "{{Image frame|align=right|width=200|caption=The [[quadratic formula]], which is the solution to the [[quadratic equation]] <math>ax^2+bx+c=0</math> where <math>a\\neq0</math>. Here the symbols {{mvar|a,b,c}} represent arbitrary numbers, and {{mvar|x}} is a variable which represents the solution of the equation.|content=<math>\\overset{}{\\underset{}{ x=\\frac{-b\\pm\\sqrt{b^2-4ac} }{2a} } }</math>}}\n[[File:Polynomialdeg2.svg|thumb|right|200px|Two-dimensional plot (red curve) of the algebraic equation <math>y = x^2 - x - 2</math>]]\n\n'''Elementary algebra''' encompasses some of the basic concepts of [[algebra]], one of the main branches of [[mathematics]]. It is typically taught to [[secondary school]] students and builds on their understanding of [[arithmetic]]. Whereas arithmetic deals with specified numbers,<ref>[[Herbert Ellsworth Slaught|H.E. Slaught]] and N.J. Lennes, ''Elementary algebra'', Publ. Allyn and Bacon, 1915, [https://books.google.com/books?id=gLii_eO4dNsC&lpg=PA1&dq=%22Elementary%20algebra%22%20letters&pg=PA1#v=onepage&q&f=false page 1] (republished by Forgotten Books)</ref> algebra introduces quantities without fixed values, known as variables.<ref>Lewis Hirsch, Arthur Goodman, ''Understanding Elementary Algebra With Geometry: A Course for College Students'', Publisher: Cengage Learning, 2005, {{ISBN|0534999727}}, 9780534999728, 654 pages, [https://books.google.com/books?id=7hdK4RSub5cC&lpg=PA2&dq=what%20is%20algebra%20for&pg=PA2#v=onepage&q=generalization&f=false page 2]</ref> This use of variables entails a use of algebraic notation and an understanding of the general rules of the [[Operation (mathematics)|operator]]s introduced in arithmetic.  Unlike [[abstract algebra]], elementary algebra is not concerned with [[algebraic structures]] outside the realm of [[real number|real]] and [[complex number]]s.\n\nThe use of variables to denote quantities allows general relationships between quantities to be formally and concisely expressed, and thus enables solving a broader scope of problems. Many quantitative relationships in science and mathematics are expressed as algebraic [[equation]]s.\n\n==Algebraic notation ==\n{{main|Mathematical notation}}\nAlgebraic notation describes the rules and conventions for writing [[Expression (mathematics)|mathematical expressions]], as well as the terminology used for talking about parts of expressions. For example, the expression <math style=\"margin-bottom:8px\">3x^2 - 2xy + c</math> has the following components:\n\n[[File:algebraic equation notation.svg|256px|thumb|center|{{ordered list\n| [[Exponent]] (power), \n| [[Coefficient]], \n| [[addend|term]], \n| [[Operation (mathematics)|operator]], \n| [[Constant (mathematics)|constant]], {{mvar|x, y}} : [[Variable (mathematics)|variable]]s}}]]\n\nA ''coefficient'' is a numerical value, or letter representing a numerical constant, that multiplies a variable (the operator is omitted). A ''term'' is an [[Addend#Notation and terminology|addend or a summand]], a group of coefficients, variables, constants and exponents that may be separated from the other terms by the plus and minus operators.<ref>Richard N. Aufmann, Joanne Lockwood, ''Introductory Algebra: An Applied Approach'', Publisher Cengage Learning, 2010, {{ISBN|1439046042}}, 9781439046043, [https://books.google.com/books?id=MPIWikTHVXQC&lpg=PP1&ots=yG1m9DkIiH&dq=coefficient%20algebra&pg=PA78#v=onepage&q=coefficient%20&f=false page 78]</ref> Letters represent variables and constants. By convention, letters at the beginning of the alphabet (e.g. <math>a, b, c</math>) are typically used to represent [[Mathematical constant|constant]]s, and those toward the end of the alphabet (e.g. <math>x, y</math> and {{mvar|z}}) are used to represent [[Variable (mathematics)|variable]]s.<ref>William L. Hosch (editor), ''The Britannica Guide to Algebra and Trigonometry'', Britannica Educational Publishing, The Rosen Publishing Group, 2010, {{ISBN|1615302190}}, 9781615302192, [https://books.google.com/books?id=ad0P0elU1_0C&lpg=PA71&dq=elementary%20algebra%20letters%20alphabet%20constants%20variables&pg=PA71#v=onepage&q=letters&f=false page 71]</ref> They are usually written in italics.<ref>James E. Gentle, ''Numerical Linear Algebra for Applications in Statistics'', Publisher: Springer, 1998, {{ISBN|0387985425}}, 9780387985428, 221 pages, [James E. Gentle page 183]</ref>\n\n[[Algebraic operation]]s work in the same way as [[arithmetic operations]],<ref>Horatio Nelson Robinson, ''New elementary algebra: containing the rudiments of science for schools and academies'', Ivison, Phinney, Blakeman, & Co., 1866, [https://books.google.com/books?id=dKZXAAAAYAAJ&dq=Elementary%20algebra%20notation&pg=PA7#v=onepage&q=Elementary%20algebra%20notation&f=false page 7]</ref> such as [[addition]], [[subtraction]], [[multiplication]], [[Division (mathematics)|division]] and [[exponentiation]].<ref>Ron Larson, Robert Hostetler, Bruce H. Edwards, ''Algebra And Trigonometry: A Graphing Approach'', Publisher: Cengage Learning, 2007, {{ISBN|061885195X}}, 9780618851959, 1114 pages, [https://books.google.com/books?id=5iXVZHhkjAgC&lpg=PA6&ots=iwrSrCrrOb&dq=operations%20addition%2C%20subtraction%2C%20multiplication%2C%20division%20exponentiation.&pg=PA6#v=onepage&q=operations%20addition,%20subtraction,%20multiplication,%20division%20exponentiation.&f=false page 6]</ref> and are applied to algebraic variables and terms.  Multiplication symbols are usually omitted, and implied when there is no space between two variables or terms, or when a [[coefficient]] is used. For example, <math style=\"margin-bottom:8px\">3 \\times x^2</math> is written as <math style=\"margin-bottom:8px\">3x^2</math>, and <math>2 \\times x \\times y</math> may be written <math>2xy</math>.<ref>Sin Kwai Meng, Chip Wai Lung, Ng Song Beng, \"Algebraic notation\", in ''Mathematics Matters Secondary 1 Express Textbook'', Publisher Panpac Education Pte Ltd, {{ISBN|9812738827}}, 9789812738820, [https://books.google.com/books?id=nL5ObMmDvPEC&lpg=PR9-IA8&ots=T_h6l40AE5&dq=%22Algebraic%20notation%22%20multiplication%20omitted&pg=PR9-IA8#v=onepage&q=%22Algebraic%20notation%22%20multiplication%20omitted&f=false page 68]</ref>\n\nUsually terms with the highest power ([[Exponentiation|exponent]]), are written on the left, for example, <math style=\"margin-bottom:8px\">x^2</math> is written to the left of {{mvar|x}}. When a coefficient is one, it is usually omitted (e.g. <math style=\"margin-bottom:8px\">1x^2</math> is written <math style=\"margin-bottom:8px\">x^2</math>).<ref>David Alan Herzog, ''Teach Yourself Visually Algebra'', Publisher John Wiley & Sons, 2008, {{ISBN|0470185597}}, 9780470185599, 304 pages, [https://books.google.com/books?id=Igs6t_clf0oC&lpg=PA72&ots=Excnhf1AgW&dq=algebra%20coefficient%20one&pg=PA72#v=onepage&q=coefficient%20of%201&f=false page 72]</ref> Likewise when the exponent (power) is one, (e.g. <math style=\"margin-bottom:8px\">3x^1</math> is written <math style=\"margin-bottom:8px\">3x</math>).<ref>John C. Peterson, ''Technical Mathematics With Calculus'', Publisher Cengage Learning, 2003, {{ISBN|0766861899}}, 9780766861893, 1613 pages, [https://books.google.com/books?id=PGuSDjHvircC&lpg=PA31&ots=NKrtZZ1KDE&dq=%22when%20the%20exponent%20is%201%22&pg=PA32#v=onepage&q=%22when%20the%20exponent%20is%201%22&f=false page 31]</ref> When the exponent is zero, the result is always 1 (e.g. <math style=\"margin-bottom:8px\">x^0</math> is always rewritten to {{mvar|1}}).<ref>Jerome E. Kaufmann, Karen L. Schwitters, ''Algebra for College Students'', Publisher Cengage Learning, 2010, {{ISBN|0538733543}}, 9780538733540, 803 pages, [https://books.google.com/books?id=-AHtC0IYMhYC&lpg=PP1&ots=kL8erjajyR&dq=algebra%20exponents%20zero%20one&pg=PA222#v=onepage&q=exponents%20&f=false page 222]</ref> However <math>0^0</math>, being undefined, should not appear in an expression, and care should be taken in simplifying expressions in which variables may appear in exponents.\n\n===Alternative notation===\nOther types of notation are used in algebraic expressions when the required formatting is not available, or can not be implied, such as where only letters and symbols are available. For example, exponents are usually formatted using superscripts, e.g. <math style=\"margin-bottom:8px\">x^2</math>. In [[plain text]], and in the [[TeX]] mark-up language, the [[caret]] symbol \"^\" represents exponents, so <math style=\"margin-bottom:8px\">x^2</math> is written as \"x^2\".<ref>Ramesh Bangia, ''Dictionary of Information Technology'', Publisher Laxmi Publications, Ltd., 2010, {{ISBN|9380298153}}, 9789380298153, [https://books.google.com/books?id=zQa5I2sHPKEC&lpg=PA212&ots=s6pWav1Z_D&dq=%22plain%20text%22%20math%20caret%20exponent&pg=PA212#v=onepage&q=exponentiation%20caret&f=false page 212]</ref><ref>George Grätzer, ''First Steps in LaTeX'', Publisher Springer, 1999, {{ISBN|0817641327}}, 9780817641320, [https://books.google.com/books?id=mLdg5ZdDKToC&lpg=PP1&ots=V9DFIaAAh0&dq=tex%20math&pg=PA17#v=onepage&q=subscripts%20and%20superscripts%20caret&f=false page 17]</ref> In programming languages such as [[Ada (programming language)|Ada]],<ref>S. Tucker Taft, Robert A. Duff, Randall L. Brukardt, Erhard Ploedereder, Pascal Leroy, ''Ada 2005 Reference Manual'', Volume 4348 of Lecture Notes in Computer Science, Publisher Springer, 2007, {{ISBN|3540693351}}, 9783540693352, [https://books.google.com/books?id=694P3YtXh-0C&lpg=PA718&ots=O_EgQ75FeB&dq=ada%20%20asterisk&pg=PA12#v=onepage&q=double%20star%20exponentiate&f=false page 13]</ref> [[Fortran]],<ref>C. Xavier, ''Fortran 77 And Numerical Methods'', Publisher New Age International, 1994, {{ISBN|812240670X}}, 9788122406702, [https://books.google.com/books?id=WYMgF9WFty0C&lpg=PA20&ots=BTtzs9F-NB&dq=fortran%20asterisk%20exponentiation&pg=PA20#v=onepage&q=fortran%20asterisk%20exponentiation&f=false page 20]</ref> [[Perl]],<ref>Randal Schwartz, Brian Foy, Tom Phoenix, ''Learning Perl'', Publisher O'Reilly Media, Inc., 2011, {{ISBN|1449313140}}, 9781449313142, [https://books.google.com/books?id=l2IwEuRjeNwC&lpg=PA24&ots=5nsYOLHxlD&dq=perl%20asterisk%20exponentiation&pg=PA24#v=onepage&q=double%20asterisk%20exponentiation&f=false page 24]</ref> [[Python (programming language)|Python]] <ref>Matthew A. Telles, ''Python Power!: The Comprehensive Guide'', Publisher Course Technology PTR, 2008, {{ISBN|1598631586}}, 9781598631586, [https://books.google.com/books?id=754knV_fyf8C&lpg=PA46&ots=8fEi1F-H8-&dq=python%20asterisk%20exponentiation&pg=PA46#v=onepage&q=double%20asterisk%20exponentiation&f=false page 46]</ref> and [[Ruby (programming language)|Ruby]],<ref>Kevin C. Baird, ''Ruby by Example: Concepts and Code'', Publisher No Starch Press, 2007, {{ISBN|1593271484}}, 9781593271480, [https://books.google.com/books?id=kq2dBNdAl3IC&lpg=PA72&ots=0UU3k-Pvh8&dq=ruby%20asterisk%20exponentiation&pg=PA72#v=onepage&q=double%20asterisk%20exponentiation&f=false page 72]</ref> a double asterisk is used, so <math style=\"margin-bottom:8px\">x^2</math> is written as \"x**2\". Many programming languages and calculators use a single asterisk to represent the multiplication symbol,<ref>William P. Berlinghoff, Fernando Q. Gouvêa, ''Math through the Ages: A Gentle History for Teachers and Others'', Publisher MAA, 2004, {{ISBN|0883857367}}, 9780883857366, [https://books.google.com/books?id=JAXNVaPt7uQC&lpg=PA75&ots=-P78Lrz792&dq=calculator%20asterisk%20multiplication&pg=PA75#v=onepage&q=calculator%20asterisk%20multiplication&f=false page 75]</ref> and it must be explicitly used, for example, <math style=\"margin-bottom:8px\">3x</math> is written \"3*x\".\n\n==Concepts==\n\n===Variables===\n[[File:Pi-equals-circumference-over-diametre.svg|thumb|right|Example of variables showing the relationship between a circle's diameter and its circumference. For any [[circle]], its [[circumference]] {{mvar|c}}, divided by its [[diameter]] {{mvar|d}}, is equal to the constant [[pi]], <math>\\pi</math> (approximately 3.14).]]\n{{Main|Variable (mathematics)}}\nElementary algebra builds on and extends arithmetic<ref>Thomas Sonnabend, ''Mathematics for Teachers: An Interactive Approach for Grades K-8'', Publisher: Cengage Learning, 2009, {{ISBN|0495561665}}, 9780495561668, 759 pages, [https://books.google.com/books?id=gBa2GzyXCF8C&lpg=PR17&ots=qee3RsTC6V&dq=algebra%20%22extends%20arithmetic%22&pg=PR17#v=onepage&q=extends%20arithmetic&f=false page xvii]</ref> by introducing letters called variables to represent general (non-specified) numbers.  This is useful for several reasons.\n\n#'''Variables may represent numbers whose values are not yet known'''. For example, if the temperature of the current day, C, is 20 degrees higher than the temperature of the previous day, P,  then the problem can be described algebraically as <math>C = P + 20</math>.<ref>Lewis Hirsch, Arthur Goodman, ''Understanding Elementary Algebra With Geometry: A Course for College Students'', Publisher: Cengage Learning, 2005, {{ISBN|0534999727}}, 9780534999728, 654 pages, [https://books.google.com/books?id=jsT7kqZubvIC&lpg=PA48&ots=EI4_yaKasG&dq=%22elementary%20algebra%22%20variables%20unknown&pg=PA48#v=onepage&q=%22elementary%20algebra%22%20variables%20unknown&f=false page 48]</ref>\n#'''Variables allow one to describe ''general'' problems,<ref>Lawrence S. Leff, ''College Algebra: Barron's Ez-101 Study Keys'', Publisher: Barron's Educational Series, 2005, {{ISBN|0764129147}}, 9780764129148, 230 pages, [https://books.google.com/books?id=XesryURrNKAC&lpg=PA2&ots=Ga44CTvNHI&dq=algebra%20variables%20generalize&pg=PA2#v=onepage&q=algebra%20variables%20generalize&f=false page 2]</ref> without specifying the values of the quantities that are involved.''' For example, it can be stated specifically that 5 minutes is equivalent to <math>60 \\times 5 = 300</math> seconds. A more general (algebraic) description may state that the number of seconds, <math>s = 60 \\times m</math>, where m is  the number of minutes.\n#'''Variables allow one to describe mathematical relationships between quantities that may vary.'''<ref>Ron Larson, Kimberly Nolting, ''Elementary Algebra'', Publisher: Cengage Learning, 2009, {{ISBN|0547102275}}, 9780547102276, 622 pages, [https://books.google.com/books?id=U6v78M5nYKAC&lpg=PP1&ots=R0dl97lfm0&dq=%22elementary%20algebra%22%20relationships&pg=PA210#v=onepage&q=relationships&f=false page 210]</ref> For example, the relationship between the circumference, ''c'', and diameter, ''d'', of a circle is described by <math>\\pi = c /d</math>.\n#'''Variables allow one to describe some mathematical properties.''' For example, a basic property of addition is [[commutativity]] which states that the order of numbers being added together does not matter. Commutativity is stated algebraically as <math>(a + b) = (b + a)</math>.<ref>Charles P. McKeague, ''Elementary Algebra'', Publisher: Cengage Learning, 2011, {{ISBN|0840064217}}, 9780840064219, 571 pages, [https://books.google.com/books?id=etTbP0rItQ4C&lpg=PA49&ots=I16eebO3LV&dq=%22elementary%20algebra%22%20commutative&pg=PA49#v=onepage&q=%22elementary%20algebra%22%20commutative&f=false page 49]</ref>\n\n=== Evaluating expressions ===\n{{Main|Expression (mathematics)}}\nAlgebraic expressions may be evaluated and simplified, based on the basic properties of arithmetic operations ([[addition]], [[subtraction]], [[multiplication]], [[Division (mathematics)|division]] and [[exponentiation]]). For example,\n*Added terms are simplified using coefficients. For example, <math>x + x + x</math> can be simplified as <math>3x</math> (where 3 is a numerical coefficient).\n*Multiplied terms are simplified using exponents. For example, <math>x \\times x \\times x</math> is represented as <math>x^3</math>\n*Like terms are added together,<ref>Andrew Marx, ''Shortcut Algebra I: A Quick and Easy Way to Increase Your Algebra I Knowledge and Test Scores'', Publisher Kaplan Publishing, 2007, {{ISBN|1419552880}}, 9781419552885, 288 pages, [https://books.google.com/books?id=o9GYQjZ7ZwUC&lpg=PP1&ots=pT-MpWMJty&dq=algebra%20addition%20%22like%20terms%22&pg=PA51#v=onepage&q=like%20terms&f=false page 51]</ref> for example, <math>2x^2 + 3ab - x^2 + ab</math> is written as <math>x^2 + 4ab</math>, because the terms containing <math>x^2</math> are added together, and, the terms containing <math>ab</math> are added together.\n*Brackets can be \"multiplied out\", using [[Distributive property|the distributive property]]. For example, <math>x (2x + 3)</math> can be written as <math>(x \\times 2x) + (x \\times 3)</math> which can be written as <math>2x^2 + 3x</math>\n*Expressions can be factored. For example, <math>6x^5 + 3x^2</math>, by dividing both terms by <math>3x^2</math> can be written as <math>3x^2 (2x^3 + 1)</math>\n\n=== Equations ===\n[[File:Pythagorean theorem - Ani.gif|thumb|Animation illustrating [[Pythagorean theorem|Pythagoras' rule]] for a right-angle triangle, which shows the algebraic relationship between the triangle's hypotenuse, and the other two sides.]]\n{{Main|Equation}}\nAn equation states that two expressions are equal using the symbol for equality, {{=}} (the [[equals sign]]).<ref>Mark Clark, Cynthia Anfinson, ''Beginning Algebra: Connecting Concepts Through Applications'', Publisher Cengage Learning, 2011, {{ISBN|0534419380}}, 9780534419387, 793 pages, [https://books.google.com/books?id=wCzuRMC5048C&lpg=PA134&ots=UdyGuk1ihH&dq=algebra%20equation%20%22two%20expressions%22&pg=PA134#v=onepage&q=equation&f=false page 134]</ref> One of the best-known equations describes Pythagoras' law relating the length of the sides of a [[right angle]] triangle:<ref>Alan S. Tussy, R. David Gustafson, ''Elementary and Intermediate Algebra'', Publisher Cengage Learning, 2012, {{ISBN|1111567689}}, 9781111567682, 1163 pages, [https://books.google.com/books?id=xqio_Xn4t7oC&lpg=PA493&ots=pmzfzBO1KX&dq=algebra%20Pythagoras%20hypotenuse&pg=PA493#v=onepage&q=algebra%20Pythagoras%20hypotenuse&f=false page 493]</ref>\n\n:<math>c^2 = a^2 + b^2</math>\n\nThis equation states that <math>c^2</math>, representing the square of the length of the side that is the hypotenuse (the side opposite the right angle), is equal to the sum (addition) of the squares of the other two sides whose lengths are represented by {{mvar|a}} and {{mvar|b}}.\n\nAn equation is the claim that two expressions have the same value and are equal. Some equations are true for all values of the involved variables (such as <math>a + b = b + a</math>); such equations are called [[identity (mathematics)|identities]]. Conditional equations are true for only some values of the involved variables, e.g. <math>x^2 - 1 = 8</math> is true only for <math>x = 3</math> and <math>x = -3</math>. The values of the variables which make the equation true are the solutions of the equation and can be found through [[equation solving]].\n\nAnother type of equation is an inequality. Inequalities are used to show that one side of the equation is greater, or less, than the other. The symbols used for this are: <math> a > b </math> where <math> > </math> represents 'greater than', and <math> a < b </math> where <math> < </math> represents 'less than'. Just like standard equality equations, numbers can be added, subtracted, multiplied or divided. The only exception is that when multiplying or dividing by a negative number, the inequality symbol must be flipped.\n\n==== Properties of equality ====\n\nBy definition, equality is an [[equivalence relation]], meaning it has the properties (a) [[reflexive relation|reflexive]] (i.e. <math>b = b</math>), (b) [[symmetric relation|symmetric]] (i.e. if <math>a = b</math> then <math>b = a</math>) (c) [[transitive relation|transitive]] (i.e. if <math>a = b</math> and <math>b = c</math> then <math>a = c</math>).<ref>Douglas Downing, ''Algebra the Easy Way'', Publisher Barron's Educational Series, 2003, {{ISBN|0764119729}}, 9780764119729, 392 pages, [https://books.google.com/books?id=RiX-TJLiQv0C&lpg=PA20&ots=BjArsBq8vc&dq=algebra%20equality%20%20%20reflexive%20%20symmetric%20%20transitive&pg=PA20#v=onepage&q=algebra%20equality%20%20%20reflexive%20%20symmetric%20%20transitive&f=false page 20]</ref> It also satisfies the important property that if two symbols are used for equal things, then one symbol can be substituted for the other in any true statement about the first and the statement will remain true. This implies the following properties:\n\n* if <math>a = b</math> and <math>c = d</math> then <math>a + c = b + d</math> and <math>ac = bd</math>;\n* if <math>a = b</math> then <math>a + c = b + c</math>;\n* more generally, for any function {{mvar|f}}, if <math>a=b</math> then <math>f(a) = f(b)</math>.\n\n==== Properties of inequality ====\n\nThe relations ''less than'' <math> < </math> and greater than <math> > </math> have the property of transitivity:<ref>Ron Larson, Robert Hostetler, ''Intermediate Algebra'', Publisher Cengage Learning, 2008, {{ISBN|0618753524}}, 9780618753529, 857 pages, [https://books.google.com/books?id=b3vqad8tbiAC&lpg=PA96&ots=FF2OYYGNCV&dq=algebra%20inequality%20properties&pg=PA96#v=onepage&q=algebra%20inequality%20properties&f=false page 96]</ref>\n* If &nbsp; <math>a < b</math> &nbsp; and &nbsp; <math>b < c</math> &nbsp; then &nbsp; <math>a < c</math>;\n* If &nbsp; <math>a < b</math> &nbsp; and &nbsp; <math>c < d</math> &nbsp; then &nbsp; <math>a + c < b + d</math>;<ref>{{cite web|url=http://math.stackexchange.com/a/1043755/19368|title=What is the following property of inequality called?|author=|date=|website=Mathematics Stack Exchange|accessdate=4 May 2018}}</ref>\n* If &nbsp; <math>a < b</math> &nbsp; and &nbsp; <math>c > 0</math> &nbsp; then &nbsp; <math>ac < bc</math>;\n* If &nbsp; <math>a < b</math> &nbsp; and &nbsp; <math>c < 0</math> &nbsp; then &nbsp; <math>bc < ac</math>.\nBy reversing the inequation, <math> < </math> and <math> > </math> can be swapped,<ref>Chris Carter, ''Physics: Facts and Practice for A Level'', Publisher Oxford University Press, 2001, {{ISBN|019914768X}}, 9780199147687, 144 pages, [https://books.google.com/books?id=Ff9gxZPYafcC&lpg=PA50&ots=KQ5ufGdcHk&dq=algebra%20inequality%20less%20greater%20exchange&pg=PA50#v=onepage&q=turned%20around&f=false page 50]</ref> for example:\n* <math>a < b</math> is equivalent to <math>b > a</math>\n\n=== Substitution ===\n{{main|Substitution (algebra)}}\n{{see also|Substitution (logic)}}\n\nSubstitution is replacing the terms in an expression to create a new expression. Substituting 3 for a in the expression a*5 makes a new expression 3*5 with meaning 15. Substituting the terms of a statement makes a new statement. When the original statement is true independent of the values of the terms, the statement created by substitutions is also true. Hence definitions can be made in symbolic terms and interpreted through substitution: if <math>a^2:=a*a</math>, where := means \"is defined to equal\", substituting 3 for {{mvar|a}} informs the reader of this statement that <math>3^2</math> means 3*3=9. Often it's not known whether the statement is true independent of the values of the terms, and substitution allows one to derive restrictions on the possible values, or show what conditions the statement holds under. For example, taking the statement x+1=0, if x is substituted with 1, this imples 1+1=2=0, which is false, which implies that if x+1=0 then x can't be 1.\n\nIf ''x'' and ''y'' are [[integers]], [[rationals]], or [[real numbers]], then ''xy''=0 implies ''x''=0 or ''y''=0. Suppose ''abc''=0. Then, substituting ''a'' for ''x'' and ''bc'' for ''y'', we learn ''a''=0 or ''bc''=0. Then we can substitute again, letting ''x''=''b'' and ''y''=''c'', to show that if ''bc''=0 then ''b''=0 or ''c''=0. Therefore, if ''abc''=0, then ''a''=0 or (''b''=0 or ''c''=0), so ''abc''=0 implies ''a''=0 or ''b''=0 or ''c''=0.\n\nConsider if the original fact were stated as \"''ab''=0 implies ''a''=0 or ''b''=0.\" Then when we say \"suppose ''abc''=0,\" we have a conflict of terms when we substitute. Yet the above logic is still valid to show that if ''abc''=0 then ''a''=0 or ''b''=0 or ''c''=0 if instead of letting ''a''=''a'' and ''b''=''bc'' we substitute ''a'' for ''a'' and ''b'' for ''bc'' (and with ''bc''=0, substituting ''b'' for ''a'' and ''c'' for ''b''). This shows that substituting for the terms in a statement isn't always the same as letting the terms from the statement equal the substituted terms. In this situation it's clear that if we substitute an expression ''a'' into the ''a'' term of the original equation, the ''a'' substituted does not refer to the ''a'' in the statement \"''ab''=0 implies ''a''=0 or ''b''=0.\"\n\n== Solving algebraic equations ==\n{{see also|Equation solving}}\n[[File:Algebraproblem.jpg|thumb|A typical algebra problem.]]\n\nThe following sections lay out examples of some of the types of algebraic equations that may be encountered.\n\n=== Linear equations with one variable ===\n{{Main|Linear equation}}\n\nLinear equations are so-called, because when they are plotted, they describe a straight line. The simplest equations to solve are [[linear equation]]s that have only one variable. They contain only constant numbers and a single variable without an exponent. As an example, consider:\n\n:Problem in words: If you double the age of a child and add 4, the resulting answer is 12. How old is the child?\n\n:Equivalent equation: <math>2x + 4 = 12</math> where  {{mvar|x}} represent the child's age\n\nTo solve this kind of equation, the technique is add, subtract, multiply, or divide both sides of the equation by the same number in order to isolate the variable on one side of the equation.  Once the variable is isolated, the other side of the equation is the value of the variable.<ref>{{Cite book|title=All the Math You'll Ever Need|author=Slavin, Steve|publisher=[[John Wiley & Sons]]|year=1989|isbn=0-471-50636-2|page=72}}</ref> This problem and its solution are as follows:\n{|\n|-\n| 1. Equation to solve:\n| <math>2x + 4 = 12</math>\n|-\n| 2. Subtract 4 from both sides:\n| <math>2x + 4 - 4 = 12 - 4</math>\n|-\n| 3. This simplifies to:\n| <math>2x = 8</math>\n|-\n| 4. Divide both sides by 2:\n| <math>\\frac{2x}{2} = \\frac{8}{2}</math>\n|-\n| 5. This simplifies to the solution:\n| <math>x = 4</math>\n|}\nIn words: the child is 4 years old.\n\nThe general form of a linear equation with one variable, can be written as: <math>ax+b=c</math>\n\nFollowing the same procedure (i.e. subtract {{mvar|b}} from both sides, and then divide by {{mvar|a}}), the general solution is given by <math>x=\\frac{c-b}{a}</math>\n\n=== Linear equations with two variables ===\n[[File:Linear-equations-two-unknowns.svg|thumb|right|Two linear equations|Solving two linear equations with a unique solution at the point that they intersect.]]\nA linear equation with two variables has many (i.e. an infinite number of) solutions.<ref>Sinha, ''The Pearson Guide to Quantitative Aptitude for CAT 2/e''Publisher: Pearson Education India, 2010, {{ISBN|8131723666}}, 9788131723661, 599 pages, [https://books.google.com/books?id=eOnaFSKRSR0C&lpg=PA195&ots=K9A5d10dUc&dq=linear%20equation%20%20two%20variables%20%20many%20solutions&pg=PA195#v=onepage&q=many%20solutions&f=false page 195]</ref> For example:\n\n:Problem in words: A father is 22 years older than his son. How old are they?\n:Equivalent equation: <math>y = x + 22</math> where {{mvar|y}} is the father's age, {{mvar|x}} is the son's age.\n\nThis cannot be worked out by itself. If the son's age was made known, then there would no longer be two unknowns (variables), and the problem becomes a linear equation with just one variable, that can be solved as described above.\n\nTo solve a linear equation with two variables (unknowns), requires two related equations. For example, if it was also revealed that:\n; Problem in words\n: In 10 years, the father will be twice as old as his son.\n;Equivalent equation\n: <math>\\begin{align}\ny + 10 &= 2 \\times (x + 10)\\\\\ny &= 2 \\times (x + 10) - 10 && \\text{Subtract 10 from both sides}\\\\\ny &= 2x + 20 - 10 && \\text{Multiple out brackets}\\\\\ny &= 2x + 10 && \\text{Simplify}\n\\end{align}</math>\n\nNow there are two related linear equations, each with two unknowns, which enables the production of a linear equation with just one variable, by subtracting one from the other (called the elimination method):<ref>Cynthia Y. Young, ''Precalculus'', Publisher John Wiley & Sons, 2010, {{ISBN|0471756849}}, 9780471756842, 1175 pages, [https://books.google.com/books?id=9HRLAn326zEC&lpg=PA703&ots=t83cFBL8TU&dq=linear%20equation%20%20two%20variables%20%20many%20solutions&pg=PA699#v=onepage&q=linear%20equation%20%20two%20variables%20%20many%20solutions&f=false page 699]</ref>\n:<math>\\begin{cases}\ny = x + 22 & \\text{First equation}\\\\\ny = 2x + 10 & \\text{Second equation}\n\\end{cases}</math>\n:<math>\\begin{align}\n&&&\\text{Subtract the first equation from}\\\\\n(y - y) &= (2x - x) +10 - 22 && \\text{the second in order to remove } y\\\\\n0 &= x - 12 && \\text{Simplify}\\\\\n12 &= x && \\text{Add 12 to both sides}\\\\\nx &= 12 && \\text{Rearrange}\n\\end{align}</math>\n\nIn other words, the son is aged 12, and since the father 22 years older, he must be 34. In 10 years time, the son will be 22, and the father will be twice his age, 44. This problem is illustrated on the associated plot of the equations.\n\nFor other ways to solve this kind of equations, see below, '''[[#System of linear equations|System of linear equations]]'''.\n\n=== Quadratic equations ===\n{{Main|Quadratic equation}}\n[[File:Quadratic-equation.svg|thumb|right|Quadratic equation plot of <math>y = x^2 + 3x - 10</math> showing its roots at <math>x = -5</math> and <math>x = 2</math>, and that the quadratic can be rewritten as <math>y = (x + 5)(x - 2)</math>\n]]\nA quadratic equation is one which includes a term with an exponent of 2, for example, <math>x^2</math>,<ref>Mary Jane Sterling, ''Algebra II For Dummies'', Publisher: John Wiley & Sons, 2006, {{ISBN|0471775819}}, 9780471775812, 384 pages, [https://books.google.com/books?id=_0rTMuSpTY0C&lpg=PA43&ots=J8_1q1Vkul&dq=quadratic%20equations&pg=PA37#v=onepage&q=quadratic%20equations&f=false page 37]</ref> and no term with higher exponent. The name derives from the Latin ''quadrus'', meaning square.<ref>John T. Irwin, ''The Mystery to a Solution: Poe, Borges, and the Analytic Detective Story'', Publisher JHU Press, 1996, {{ISBN|0801854660}}, 9780801854668, 512 pages, [https://books.google.com/books?id=jsxTenuOQKgC&lpg=PA372&ots=T7p7Porq55&dq=quadratic%20quadrus&pg=PA372#v=onepage&q=quadratic%20quadrus&f=false page 372]</ref> In general, a quadratic equation can be expressed in the form <math>ax^2 + bx + c = 0</math>,<ref>Sharma/khattar, ''The Pearson Guide To Objective Mathematics For Engineering Entrance Examinations, 3/E'', Publisher Pearson Education India, 2010, {{ISBN|8131723631}}, 9788131723630, 1248 pages, [https://books.google.com/books?id=2v-f9x7-FlsC&lpg=RA13-PA33&ots=P-Dz70fXbv&dq=quadratic%20equations%20%20ax2%20%2B%20bx%20%2B%20c%20%3D%200&pg=RA13-PA33#v=onepage&q&f=false page 621]</ref> where {{mvar|a}} is not zero (if it were zero, then the equation would not be quadratic but linear). Because of this a quadratic equation must contain the term <math>ax^2</math>, which is known as the quadratic term.  Hence <math>a \\neq 0</math>, and so we may divide by {{mvar|a}} and rearrange the equation into the standard form\n\n: <math>x^2 + px + q = 0 </math>\n\nwhere <math>p = \\frac{b}{a}</math> and <math>q = \\frac{c}{a}</math>. Solving this, by a process known as [[completing the square]], leads to the [[quadratic formula]]\n\n:<math>x=\\frac{-b \\pm \\sqrt {b^2-4ac}}{2a},</math>\n\nwhere [[plus-minus sign|the symbol \"±\"]] indicates that both\n\n: <math> x=\\frac{-b + \\sqrt {b^2-4ac}}{2a}\\quad\\text{and}\\quad x=\\frac{-b - \\sqrt {b^2-4ac}}{2a}</math>\n\nare solutions of the quadratic equation.\n\nQuadratic equations can also be solved using [[factorization]] (the reverse process of which is [[polynomial expansion|expansion]], but for two [[linear function|linear terms]] is sometimes denoted [[FOIL rule|foiling]]).  As an example of factoring:\n\n: <math>x^{2} + 3x - 10 = 0, </math>\n\nwhich is the same thing as\n\n: <math>(x + 5)(x - 2) = 0. </math>\n\nIt follows from the [[zero-product property]] that either <math>x = 2</math> or <math>x = -5</math> are the solutions, since precisely one of the factors must be equal to [[zero]]. All quadratic equations will have two solutions in the [[complex number]] system, but need not have any in the [[real number]] system. For example,\n\n: <math>x^{2} + 1 = 0 </math>\n\nhas no real number solution since no real number squared equals −1.\nSometimes a quadratic equation has a root of [[multiplicity (mathematics)|multiplicity]] 2, such as:\n\n: <math>(x + 1)^2 = 0. </math>\n\nFor this equation, −1 is a root of multiplicity 2. This means −1 appears twice, since the equation can be rewritten in factored form as\n\n:<math>[x-(-1)][x-(-1)]=0.</math>\n\n====Complex numbers====\n\nAll quadratic equations have exactly two solutions in [[complex numbers]] (but they may be equal to each other), a category that includes [[real number]]s, [[imaginary number]]s, and sums of real and imaginary numbers. Complex numbers first arise in the teaching of quadratic equations and the quadratic formula. For example, the quadratic equation\n\n:<math>x^2+x+1=0</math>\n\nhas solutions\n\n:<math>x=\\frac{-1 + \\sqrt{-3}}{2}  \\quad \\quad \\text{and} \\quad \\quad x=\\frac{-1-\\sqrt{-3}}{2}.</math>\n\nSince <math>\\sqrt{-3}</math> is not any real number, both of these solutions for ''x'' are complex numbers.\n\n=== Exponential and logarithmic equations ===\n{{Main|Logarithm}}\n[[File:Binary logarithm plot with ticks.svg|right|thumb|upright=1.35|alt=Graph showing a logarithm curves, which crosses the ''x''-axis where ''x'' is 1 and extend towards minus infinity along the ''y''-axis.|The [[graph of a function|graph]] of the logarithm to base 2 crosses the [[x axis|''x'' axis]] (horizontal axis) at 1 and passes through the points with [[coordinate]]s {{nowrap|(2, 1)}}, {{nowrap|(4, 2)}}, and {{nowrap|(8, 3)}}. For example, {{nowrap|log<sub>2</sub>(8) {{=}} 3}}, because {{nowrap|2<sup>3</sup> {{=}} 8.}} The graph gets arbitrarily close to the ''y'' axis, but [[asymptotic|does not meet or intersect it]].]]\n\nAn exponential equation is one which has the form <math>a^x = b</math> for <math>a > 0</math>,<ref>Aven Choo, ''LMAN OL Additional Maths Revision Guide 3'', Publisher Pearson Education South Asia, 2007, {{ISBN|9810600011}}, 9789810600013, [https://books.google.com/books?id=NsBXDMrzcJIC&lpg=RA2-PA29&ots=WmZmHLaTey&dq=%22%20exponential%20equation%20%22%20aX%20%3D%20b&pg=RA2-PA29#v=onepage&q=%22%20exponential%20equation%20%22%20aX%20=%20b&f=false page 105]</ref> which has solution\n\n: <math>X = \\log_a b = \\frac{\\ln b}{\\ln a}</math>\n\nwhen <math>b > 0</math>. Elementary algebraic techniques are used to rewrite a given equation in the above way before arriving at the solution. For example, if\n\n: <math>3 \\cdot 2^{x - 1} + 1 = 10</math>\n\nthen, by subtracting 1 from both sides of the equation, and then dividing both sides by 3 we obtain\n\n: <math>2^{x - 1} = 3</math>\n\nwhence\n\n: <math>x - 1 = \\log_2 3</math>\n\nor\n\n: <math>x = \\log_2 3 + 1.</math>\n\nA logarithmic equation is an equation of the form <math>log_a(x) = b</math> for <math>a > 0</math>, which has solution\n\n: <math>X = a^b.</math>\n\nFor example, if\n\n: <math>4\\log_5(x - 3) - 2 = 6</math>\n\nthen, by adding 2 to both sides of the equation, followed by dividing both sides by 4, we get\n\n: <math>\\log_5(x - 3) = 2</math>\n\nwhence\n\n: <math>x - 3 = 5^2 = 25</math>\n\nfrom which we obtain\n\n: <math>x = 28.</math>\n\n=== Radical equations ===\n{{Image frame|align=right|width=150|caption=Radical equation showing two ways to represent the same expression. The triple bar means the equation is true for all values of ''x''|content=<math>\\overset{}{\\underset{}{\\sqrt[2]{x^3} \\equiv x^{\\frac 3 2} } }</math>}}\nA radical equation is one that includes a radical sign, which includes [[square root]]s, <math>\\sqrt{x},</math>  [[cube root]]s, <math>\\sqrt[3]{x}</math>, and [[nth root|''n''th roots]], <math>\\sqrt[n]{x}</math>. Recall that an ''n''th root can be rewritten in exponential format, so that <math>\\sqrt[n]{x}</math> is equivalent to <math>x^{\\frac{1}{n}}</math>. Combined with regular exponents (powers), then  <math>\\sqrt[2]{x^3}</math> (the square root of {{mvar|x}} cubed), can be rewritten as <math>x^{\\frac{3}{2}}</math>.<ref>John C. Peterson, ''Technical Mathematics With Calculus'', Publisher Cengage Learning, 2003, {{ISBN|0766861899}}, 9780766861893, 1613 pages, [https://books.google.com/books?id=PGuSDjHvircC&lpg=PA525&ots=NKrt__3KKE&dq=%22%20radical%20equation%22&pg=PA525#v=onepage&q=%22%20radical%20equation%22&f=false page 525]</ref> So a common form of a radical equation is <math> \\sqrt[n]{x^m}=a</math> (equivalent to <math> x^\\frac{m}{n}=a</math>) where {{mvar|m}} and {{mvar|n}} are [[integer]]s. It has [[real number|real]] solution(s):\n{| class=\"wikitable\" style=\"text-align:center\"\n|- style=\"vertical-align:top\"\n!{{mvar|n}} is odd\n!{{mvar|n}} is even<br>and <math>a \\ge 0</math>\n!{{mvar|n}} '''and''' {{mvar|m}} are '''even'''<br>'''and''' <math>a<0</math>\n!{{mvar|n}} '''is even,''' {{mvar|m}} '''is odd''', '''and''' <math>a<0</math>\n|-\n|<math>x = \\sqrt[n]{a^m}</math>\n\nequivalently\n\n:<math>x = \\left(\\sqrt[n]a\\right)^m</math>\n|<math>x = \\pm \\sqrt[n]{a^m}</math>\n\nequivalently\n\n:<math>x = \\pm \\left(\\sqrt[n]a\\right)^m</math>\n\n|<math>x=\\pm \\sqrt[n]{a^m}</math>\n|no real solution\n|}\n\nFor example, if:\n\n:<math>(x + 5)^{3/2} = 4</math>\n\nthen\n\n: <math>\\begin{align}\nx + 5 & = \\pm (\\sqrt{4})^3\\\\\nx + 5 & = \\pm 8\\\\\nx &  = -5 \\pm 8\\\\\nx & = 3,-13\n\\end{align}</math>\n\n=== System of linear equations ===\n{{Main|System of linear equations}}\n\nThere are different methods to solve a system of linear equations with two variables.\n\n==== Elimination method ====\n[[File:Intersecting Lines.svg|thumb|right|The solution set for the equations <math>x - y = -1</math> and <math>3x + y = 9</math> is the single point (2,&nbsp;3).]]\n\nAn example of solving a system of linear equations is by using the elimination method:\n\n: <math>\\begin{cases}4x + 2y&= 14 \\\\\n2x - y&= 1.\\end{cases} </math>\n\nMultiplying the terms in the second equation by 2:\n\n: <math>4x + 2y = 14 </math>\n: <math>4x - 2y = 2. </math>\n\nAdding the two equations together to get:\n\n: <math>8x = 16 </math>\n\nwhich simplifies to\n\n: <math>x = 2. </math>\n\nSince the fact that <math>x = 2</math> is known, it is then possible to deduce that <math>y = 3</math>  by either of the original two equations (by using ''2'' instead of {{mvar|x}} ) The full solution to this problem is then\n\n: <math>\\begin{cases} x = 2 \\\\ y = 3. \\end{cases}</math>\n\nNote that this is not the only way to solve this specific system; {{mvar|y}} could have been solved before {{mvar|x}}.\n\n==== Substitution method ====\n\nAnother way of solving the same system of linear equations is by substitution.\n\n: <math>\\begin{cases}4x + 2y &= 14\n\\\\ 2x - y &= 1.\\end{cases} </math>\n\nAn equivalent for {{mvar|y}} can be deduced by using one of the two equations. Using the second equation:\n\n: <math>2x - y = 1 </math>\n\nSubtracting <math>2x</math> from each side of the equation:\n\n: <math>\\begin{align}2x - 2x - y & = 1 - 2x  \\\\\n- y & = 1 - 2x\n\\end{align}</math>\n\nand multiplying by −1:\n\n: <math> y = 2x - 1. </math>\n\nUsing this {{mvar|y}} value in the first equation in the original system:\n\n: <math>\\begin{align}4x + 2(2x - 1) &= 14\\\\\n4x + 4x - 2 &= 14 \\\\\n8x - 2 &= 14 \\end{align}</math>\n\nAdding ''2'' on each side of the equation:\n\n: <math>\\begin{align}8x - 2 + 2 &= 14 + 2 \\\\\n8x &= 16 \\end{align}</math>\n\nwhich simplifies to\n\n: <math>x = 2 </math>\n\nUsing this value in one of the equations, the same solution as in the previous method is obtained.\n\n: <math>\\begin{cases} x = 2 \\\\ y = 3. \\end{cases}</math>\n\nNote that this is not the only way to solve this specific system; in this case as well, {{mvar|y}} could have been solved before {{mvar|x}}.\n\n=== Other types of systems of linear equations ===\n\n==== Inconsistent systems ====\n[[File:Parallel Lines.svg|thumb|right|The equations <math>3x + 2y = 6</math> and <math>3x + 2y = 12</math> are parallel and cannot intersect, and is unsolvable.]]\n[[File:Quadratic-linear-equations.svg|thumb|right|Plot of a quadratic equation (red) and a linear equation (blue) that do not intersect, and consequently for which there is no common solution.]]\n\nIn the above example, a solution exists. However, there are also systems of equations which do not have any solution. Such a system is called [[inconsistent system|inconsistent]]. An obvious example is\n\n: <math>\\begin{cases}\\begin{align} x + y &= 1 \\\\\n0x + 0y &= 2\\,. \\end{align} \\end{cases}</math>\n\nAs 0≠2, the second equation in the system has no solution. Therefore, the system has no solution.\nHowever, not all inconsistent systems are recognized at first sight. As an example, consider the system \n: <math>\\begin{cases}\\begin{align}4x + 2y &= 12 \\\\\n-2x - y &= -4\\,. \\end{align}\\end{cases}</math>\n\nMultiplying by 2 both sides of the second equation, and adding it to the first one results in\n: <math>0x+0y = 4 \\,,</math>\nwhich clearly has no solution.\n\n==== Undetermined systems ====\n\nThere are also systems which have infinitely many solutions, in contrast to a system with a unique solution (meaning, a unique pair of values for {{mvar|x}} and {{mvar|y}}) For example:\n\n: <math>\\begin{cases}\\begin{align}4x + 2y & = 12 \\\\\n-2x - y & = -6 \\end{align}\\end{cases}</math>\n\nIsolating {{mvar|y}} in the second equation:\n\n: <math>y = -2x + 6 </math>\n\nAnd using this value in the first equation in the system:\n\n: <math>\\begin{align}4x + 2(-2x + 6) = 12 \\\\\n4x - 4x + 12 = 12 \\\\\n12 = 12 \\end{align}</math>\n\nThe equality is true, but it does not provide a value for {{mvar|x}}. Indeed, one can easily verify (by just filling in some values of {{mvar|x}}) that for any {{mvar|x}} there is a solution as long as <math>y = -2x + 6</math>. There is an infinite number of solutions for this system.\n\n==== Over- and underdetermined systems ====\n\nSystems with more variables than the number of linear equations are called [[underdetermined system|underdetermined]]. Such a system, if it has any solutions, does not have a unique one but rather an infinitude of them. An example of such a system is\n\n: <math>\\begin{cases}\\begin{align}x + 2y & = 10\\\\\ny - z  & = 2 .\\end{align}\\end{cases}</math>\n\nWhen trying to solve it, one is led to express some variables as functions of the other ones if any solutions exist, but cannot express ''all'' solutions [[Number|numerically]] because there are an infinite number of them if there are any.\n\nA system with a greater number of equations than variables is called [[overdetermined system|overdetermined]]. If an overdetermined system has any solutions, necessarily some equations are [[linear combination]]s of the others.\n\n== See also ==\n* [[History of elementary algebra]]\n* [[Binary operation]]\n* [[Gaussian elimination]]\n* [[Mathematics education]]\n* [[Number line]]\n* [[Polynomial]]\n* [[Cancelling out]]\n* [[Tarski's high school algebra problem]]\n\n== References ==\n*[[Leonhard Euler]],  '' [[Elements of Algebra]]'', 1770.  English translation [[Tarquin Press]], 2007, {{ISBN|978-1-899618-79-8}}, also online digitized editions<ref>[http://web.mat.bham.ac.uk/C.J.Sangwin/euler/ Euler's Elements of Algebra<!-- Bot generated title -->] {{webarchive|url=https://web.archive.org/web/20110413234352/http://web.mat.bham.ac.uk/C.J.Sangwin/euler/ |date=2011-04-13 }}</ref> 2006,<ref>{{cite web|url=https://books.google.com/books?id=X8yv0sj4_1YC&dq=euler+elements&psp=1|title=Elements of Algebra|first1=Leonhard|last1=Euler|first2=John|last2=Hewlett|first3=Francis|last3=Horner|first4=Jean|last4=Bernoulli|first5=Joseph Louis|last5=Lagrange|date=4 May 2018|publisher=Longman, Orme|accessdate=4 May 2018|via=Google Books}}</ref> 1822.\n*Charles Smith, ''[http://digital.library.cornell.edu/cgi/t/text/text-idx?c=math;idno=smit025 A Treatise on Algebra]'', in [http://historical.library.cornell.edu/math Cornell University Library Historical Math Monographs].\n*Redden, John. [http://catalog.flatworldknowledge.com/bookhub/reader/128?e=fwk-redden-ch01 ''Elementary Algebra'']. Flat World Knowledge, 2011\n{{reflist}}\n\n==External links==\n*{{Commonscat-inline}}\n\n{{Algebra}}\n{{Areas of mathematics | state=collapsed}}\n\n{{DEFAULTSORT:Elementary Algebra}}\n[[Category:Elementary algebra| ]]\n[[Category:Algebra]]"
    },
    {
      "title": "Equivalence class",
      "url": "https://en.wikipedia.org/wiki/Equivalence_class",
      "text": "{{about|equivalency in mathematics|equivalency in music|equivalence class (music)}}\n\n[[File:Congruent non-congruent triangles.svg|thumb|370px|[[Congruence (geometry)|Congruence]] is an example of an equivalence relation. The leftmost two triangles are congruent, while the third and fourth triangles are not congruent to any other triangle shown here. Thus, the first two triangles are in the same equivalence class, while the third and fourth triangles are each in their own equivalence class.]]\n\nIn mathematics, when the elements of some [[set (mathematics)|set]] {{math|''S''}} have a notion of equivalence (formalized as an [[equivalence relation]]) defined on them, then one may naturally split the set {{math|''S''}} into '''equivalence classes'''. These equivalence classes are constructed so that elements {{math|''a''}} and {{math|''b''}} belong to the same '''equivalence class''' if and only if {{math|''a''}} and {{math|''b''}} are equivalent.\n\nFormally, given a set {{math|''S''}} and an equivalence relation {{math|~}} on {{math|''S''}}, the ''equivalence class'' of an element {{math|''a''}} in {{math|''S''}} is the set\n\n:<math>\\{ x \\in S \\mid x \\sim a \\}</math>\n\nof elements which are equivalent to {{math|''a''}}. It may be proven from the defining properties of \"equivalence relations\" that the equivalence classes form a [[Partition of a set|partition]] of {{math|''S''}}. This partition – the set of equivalence classes – is sometimes called the '''quotient set''' or the '''quotient space''' of {{math|''S''}} by {{math|~}} and is denoted by {{math|''S'' / ~}}.\n\nWhen the set {{math|''S''}} has some structure (such as a [[group (mathematics)|group operation]] or a [[topological space|topology]]) and the equivalence relation {{math|~}} is defined in a manner suitably compatible with this structure, then the quotient set often inherits a similar structure from its parent set. Examples include [[quotient space (linear algebra)|quotient spaces in linear algebra]], [[quotient space (topology)|quotient spaces in topology]], [[quotient group]]s, [[homogeneous space]]s, [[quotient ring]]s, [[quotient monoid]]s, and [[quotient category|quotient categories]].\n\n==Examples==\n* If {{mvar|X}} is the set of all cars, and {{math|~}} is the [[equivalence relation]] \"has the same color as\", then one particular equivalence class consists of all green cars. {{math|''X''/~}} could be naturally identified with the set of all car colors.\n* Let {{mvar|X}} be the set of all rectangles in a plane, and {{math|~}} the equivalence relation \"has the same area as\". For each positive real number ''A'' there will be an equivalence class of all the rectangles that have area ''A''.<ref>{{harvnb|Avelsgaard|1989|loc=p. 127}}</ref>\n* Consider the [[modular arithmetic|modulo]] 2 equivalence relation on the set {{math|'''Z'''}} of [[integer]]s: {{math|''x'' ~ ''y''}} if and only if their difference {{math|''x'' &minus; ''y''}} is an [[even number]]. This relation gives rise to exactly two equivalence classes: one class consisting of all even numbers, and the other consisting of all odd numbers. Under this relation {{math|[7]}}, {{math|[9]}}, and {{math|[1]}} all represent the same element of {{math|'''Z'''/~}}.<ref>{{harvnb|Devlin|2004|loc=p. 123}}</ref>\n* Let {{mvar|X}} be the set of ordered pairs of integers {{math|(''a'',''b'')}} with {{mvar|b}} not zero, and define an equivalence relation {{math|~}} on {{mvar|X}} according to which {{math|(''a'',''b'') ~ (''c'',''d'')}} if and only if {{math|1=''ad'' = ''bc''}}. Then the equivalence class of the pair {{math|(''a'',''b'')}} can be identified with the [[rational number]] {{math|''a''/''b''}}, and this equivalence relation and its equivalence classes can be used to give a formal definition of the set of rational numbers.<ref>{{harvnb|Maddox|2002|loc=pp. 77–78}}</ref> The same construction can be generalized to the [[field of fractions]] of any [[integral domain]].\n* If {{mvar|X}} consists of all the lines in, say the [[Euclidean plane]], and ''L'' ~ ''M'' means that ''L'' and ''M'' are [[parallel lines]], then the set of lines that are parallel to each other form an equivalence class as long as a [[parallel (geometry)#Reflexive variant|line is considered parallel to itself]]. In this situation, each equivalence class determines a [[point at infinity]].\n\n==Notation and formal definition<!--linked from 'Bracket'-->==\nAn [[equivalence relation]] is a [[homogeneous binary relation|binary relation]] {{math|~}} satisfying three properties:<ref>{{harvnb|Devlin|2004|loc=p. 122}}</ref>\n*For every element {{mvar|a}} in {{mvar|X}}, {{math|''a'' ~ ''a''}} ([[Reflexive relation|reflexivity]]),\n*For every two elements {{mvar|a}} and {{mvar|b}} in {{mvar|X}}, if {{math|''a'' ~ ''b''}}, then {{math|''b'' ~ ''a''}} ([[Symmetric relation|symmetry]]),\n*For every three elements {{mvar|a}}, {{mvar|b}}, and {{mvar|c}} in {{mvar|X}}, if {{math|''a'' ~ ''b''}} and {{math|''b'' ~ ''c''}}, then {{math|''a'' ~ ''c''}} ([[Transitive relation|transitivity]]).\n\nThe equivalence class of an element {{mvar|a}} is denoted {{math|[''a'']}} and is defined as the set\n\n:<math>[a] = \\{ x \\in X \\mid a \\sim x \\}</math>\n\nof elements that are related to {{mvar|a}} by&nbsp;{{math|~}}. An alternative notation {{math|[''a'']<sub>''R''</sub>}} can be used to denote the equivalence class of the element {{mvar|a}}, specifically with respect to the equivalence relation {{mvar|R}}. This is said to be the {{mvar|R}}-equivalence class of {{mvar|a}}.\n\nThe set of all equivalence classes in {{mvar|X}} with respect to an equivalence relation {{math|''R''}} is denoted as {{math|''X''/''R''}} and called {{mvar|X}} '''modulo''' {{mvar|R}} (or the '''quotient set''' of {{mvar|X}} by {{math|''R''}}).<ref>{{harvnb|Wolf|1998|loc=p. 178}}</ref> The [[surjective map]] <math> x\\mapsto [x]</math> from {{mvar|X}} onto {{math|''X''/''R''}}, which maps each element to its equivalence class, is called the '''canonical surjection''' or the '''canonical projection map'''.\n\nWhen an element is chosen (often implicitly) in each equivalence class, this defines an [[injective map]] called a ''[[section (category theory)|section]]''. If this section is denoted by {{math|''s''}}, one has {{math|1= [''s''(''c'')] = ''c''}} for every equivalence class {{math|''c''}}. The element {{math|''s''(''c'')}} is called a '''representative''' of {{math|''c''}}. Any element of a class may be chosen as a representative of the class, by choosing the section appropriately.\n\nSometimes, there is a section that is more \"natural\" than the other ones. In this case, the representatives are called ''[[Canonical form|canonical]] representatives''. For example, in [[modular arithmetic]], consider the equivalence relation on the integers defined by {{math|''a'' ~ ''b''}} if {{math|''a'' − ''b''}} is a multiple of a given integer {{math| ''n''}}, called the ''modulus''. Each class contains a unique non-negative integer smaller than {{math|''n''}}, and these integers are the canonical representatives. The class and its representative are more or less identified, as is witnessed by the fact that the notation {{math| ''a'' mod ''n''}} may denote either the class or its canonical representative (which is the [[remainder]] of the [[Euclidean division|division]] of {{math| ''a''}} by {{math|''n''}}).\n\n==Properties==\nEvery element {{mvar|x}} of {{mvar|X}} is a member of the equivalence class {{math|[''x'']}}. Every two equivalence classes {{math|[''x'']}} and {{math|[''y'']}} are either equal or [[disjoint sets|disjoint]]. Therefore, the set of all equivalence classes of {{mvar|X}} forms a [[partition of a set|partition]] of {{mvar|X}}: every element of {{mvar|X}} belongs to one and only one equivalence class.<ref>{{harvnb|Maddox|2002|loc=p. 74, Thm. 2.5.15}}</ref> Conversely every partition of {{mvar|X}} comes from an equivalence relation in this way, according to which {{math|''x'' ~ ''y''}} if and only if {{mvar|x}} and {{mvar|y}} belong to the same set of the partition.<ref>{{harvnb|Avelsgaard|1989|loc=p. 132, Thm. 3.16}}</ref>\n\nIt follows from the properties of an equivalence relation that\n:: {{math|''x'' ~ ''y''}} if and only if {{math|1=[''x''] = [''y'']}}.\n\nIn other words, if {{math|~}} is an equivalence relation on a set {{math|''X''}}, and {{mvar|x}} and {{mvar|y}} are two elements of {{mvar|X}}, then these statements are equivalent:\n\n* <math>x \\sim y</math>\n* <math>[x] = [y]</math>\n* <math>[x] \\cap [y] \\ne \\emptyset.</math>\n\n==Graphical representation==\n[[File:Equivalentie.svg|thumb|160px|Graph of an example equivalence with 7 classes]]\nAn [[undirected graph]] may be associated to any [[symmetric relation]] on a set {{math|''X''}}, where the vertices are the elements of {{math|''X''}}, and two vertices {{mvar|s}} and {{mvar|t}} are joined if and only if {{math|''s'' ~ ''t''}}. Among these graphs are the graphs of equivalence relations; they are characterized as the graphs such that the [[connected component (graph theory)|connected components]] are [[glossary of graph theory|cliques]].<ref>{{harvnb|Devlin|2004|loc=p. 123}}</ref>\n\n==Invariants==\nIf {{math|~}} is an equivalence relation on {{mvar|X}}, and {{math|''P''(''x'')}} is a property of elements of {{mvar|X}} such that whenever {{math|''x'' ~ ''y''}}, {{math|''P''(''x'')}} is true if {{math|''P''(''y'')}} is true, then the property {{mvar|P}} is said to be an [[Invariant (mathematics)|invariant]] of {{math|~}}, or [[well-defined]] under the relation {{math|~}}.\n\nA frequent particular case occurs when {{mvar|f}} is a function from {{mvar|X}} to another set {{mvar|Y}}; if  {{math|1=''f''(''x''<sub>1</sub>) = ''f''(''x''<sub>2</sub>)}} whenever {{math|''x''<sub>1</sub> ~ ''x''<sub>2</sub>}}, then {{mvar|f}} is said to be ''class invariant under'' {{math|~}}, or simply ''invariant under'' {{math|~}}. This occurs, e.g. in the character theory of finite groups. Some authors use \"compatible with {{math|~}}\" or just \"respects {{math|~}}\" instead of \"invariant under {{math|~}}\".\n\nAny [[function (mathematics)|function]] {{math|''f'' : ''X'' → ''Y''}} itself defines an equivalence relation on {{mvar|X}} according to which {{math|''x''<sub>1</sub> ~ ''x''<sub>2</sub>}} if and only if {{math|1=''f''(''x''<sub>1</sub>) = ''f''(''x''<sub>2</sub>)}}. The equivalence class of {{mvar|x}} is the set of all elements in {{mvar|X}} which get mapped to {{math|''f''(''x'')}}, i.e. the class {{math|[''x'']}} is the [[inverse image]] of {{math|''f''(''x'')}}. This equivalence relation is known as the [[kernel of a function|kernel]] of {{mvar|f}}.\n\nMore generally, a function may map equivalent arguments (under an equivalence relation {{math|~<sub>''X''</sub>}} on {{mvar|X}}) to equivalent values (under an equivalence relation {{math|~<sub>''Y''</sub>}} on {{mvar|Y}}). Such a function is a [[morphism]] of sets equipped with an equivalence relation.\n\n==Quotient space in topology==\n\nIn [[topology]], a [[Quotient space (topology)|quotient space]] is a [[topological space]] formed on the set of equivalence classes of an equivalence relation on a topological space using the original space's topology to create the topology on the set of equivalence classes.\n\nIn [[abstract algebra]], [[congruence relation]]s on the underlying set of an algebra allow the algebra to induce an algebra on the equivalence classes of the relation, called a [[Quotient (universal algebra)|quotient algebra]]. In [[linear algebra]], a [[Quotient space (linear algebra)|quotient space]] is a vector space formed by taking a [[quotient group]] where the quotient homomorphism is a [[linear map]]. By extension, in abstract algebra, the term quotient space may be used for [[quotient module]]s, [[quotient ring]]s, [[quotient group]]s, or any quotient algebra. However, the use of the term for the more general cases can as often be by analogy with the orbits of a group action.\n\nThe orbits of a [[Group action (mathematics)|group action]] on a set may be called the quotient space of the action on the set, particularly when the orbits of the group action are the right [[coset]]s of a subgroup of a group, which arise from the action of the subgroup on the group by left translations, or respectively the left cosets as orbits under right translation.\n\nA normal subgroup of a topological group, acting on the group by translation action, is a quotient space in the senses of topology, abstract algebra, and group actions simultaneously.\n\nAlthough the term can be used for any equivalence relation's set of equivalence classes, possibly with further structure, the intent of using the term is generally to compare that type of equivalence relation on a set {{math|''X''}} either to an equivalence relation that induces some structure on the set of equivalence classes from a structure of the same kind on {{math|''X''}}, or to the orbits of a group action. Both the sense of a structure preserved by an equivalence relation and the study of [[Invariant (mathematics)|invariants]] under group actions lead to the definition of [[#Invariants|invariants]] of equivalence relations given above.\n\n==See also==\n*[[Equivalence partitioning]], a method for devising test sets in [[software testing]] based on dividing the possible program inputs into equivalence classes according to the behavior of the program on those inputs\n*[[Homogeneous space]], the quotient space of [[Lie group]]s\n*[[Transversal (combinatorics)]]\n\n==Notes==\n{{reflist|30em}}\n\n==References==\n* {{citation|first=Carol|last=Avelsgaard|title=Foundations for Advanced Mathematics|publisher=Scott Foresman|year=1989|isbn=0-673-38152-8}}\n* {{citation|last=Devlin|first=Keith|title=Sets, Functions, and Logic: An Introduction to Abstract Mathematics|year=2004|publisher=Chapman & Hall/ CRC Press|edition=3rd|isbn=978-1-58488-449-1}}\n* {{citation|last=Maddox|first=Randall B.|title=Mathematical Thinking and Writing|year=2002|publisher=Harcourt/ Academic Press|isbn=0-12-464976-9}}\n* {{citation|last=Morash|first=Ronald P.|title=Bridge to Abstract Mathematics|publisher=Random House|year=1987|isbn=0-394-35429-X}}\n* {{citation|last=Wolf|first=Robert S.|title=Proof, Logic and Conjecture: A Mathematician's Toolbox|year=1998|publisher=Freeman|isbn=978-0-7167-3050-7}}\n\n==Further reading==\nThis material is basic and can be found in any text dealing with the fundamentals of proof technique, such as any of the following:\n*{{citation|last=Sundstrom|title=Mathematical Reasoning: Writing and Proof|year=2003|publisher=Prentice-Hall}}\n*{{citation|last1=Smith|last2=Eggen|last3=St.Andre|title=A Transition to Advanced Mathematics (6th Ed.)|year=2006|publisher=Thomson (Brooks/Cole)}}\n*{{citation|last=Schumacher|first=Carol|title=Chapter Zero: Fundamental Notions of Abstract Mathematics|year=1996|publisher=Addison-Wesley|isbn=0-201-82653-4}}\n*{{citation|last=O'Leary|title=The Structure of Proof: With Logic and Set Theory|year=2003|publisher=Prentice-Hall}}\n*{{citation|last=Lay|title=Analysis with an introduction to proof|year=2001|publisher=Prentice Hall}}\n*{{citation|last1=Gilbert|last2=Vanstone|title=An Introduction to Mathematical Thinking|year=2005|publisher=Pearson Prentice-Hall}}\n*{{citation|last1=Fletcher|last2=Patty|title=Foundations of Higher Mathematics|publisher=PWS-Kent}}\n*{{citation|last1=Iglewicz|last2=Stoyle|title=An Introduction to Mathematical Reasoning|publisher=MacMillan}}\n*{{citation|last1=D'Angelo|last2=West|title=Mathematical Thinking: Problem Solving and Proofs|year=2000|publisher=Prentice Hall}}\n*{{citation|last=Cupillari|title=The Nuts and Bolts of Proofs|publisher=Wadsworth}}\n*{{citation|last=Bond|title=Introduction to Abstract Mathematics|publisher=Brooks/Cole}}\n*{{citation|last1=Barnier|last2=Feldman|title=Introduction to Advanced Mathematics|year=2000|publisher=Prentice Hall}}\n*{{citation|last=Ash|title=A Primer of Abstract Mathematics|publisher=MAA}}\n\n==External links==\n*{{Commonscatinline|Equivalence classes}}\n\n{{DEFAULTSORT:Equivalence Class}}\n[[Category:Algebra]]\n[[Category:Binary relations]]\n[[Category:Set theory]]"
    },
    {
      "title": "Euler's totient function",
      "url": "https://en.wikipedia.org/wiki/Euler%27s_totient_function",
      "text": "{{Redirect|Φ(n)||phi}}\n\n[[Image:EulerPhi.svg|thumb|The first thousand values of {{math|''φ''(''n'')}}. The points on the top line represent {{Math|''φ''(''p'')}} when {{mvar|p}} is a prime number, which is {{Math|''p'' − 1.}}<ref>{{Cite web\n| url = https://www.khanacademy.org/computing/computer-science/cryptography/modern-crypt/v/euler-s-totient-function-phi-function\n| title = Euler's totient function\n| website = Khan Academy\n| access-date = 2016-02-26\n}}</ref>]]\n\nIn [[number theory]], '''Euler's totient function''' counts the positive integers up to a given integer {{mvar|n}} that are [[relatively prime]] to {{mvar|n}}. It is written using the Greek letter [[phi]] as {{math|''φ''(''n'')}} or {{math|''ϕ''(''n'')}}, and may also be called '''Euler's phi function'''. In other words, it is the number of integers {{mvar|k}} in the range {{math|1 ≤ ''k'' ≤ ''n''}} for which the [[greatest common divisor]] {{math|gcd(''n'', ''k'')}} is equal to 1.<ref>{{harvtxt|Long|1972|p=85}}</ref><ref>{{harvtxt|Pettofrezzo|Byrkit|1970|p=72}}</ref> The integers {{mvar|k}} of this form are sometimes referred to as [[totative]]s of {{mvar|n}}.\n\nFor example, the totatives of {{math|1= ''n'' = 9}} are the six numbers 1, 2, 4, 5, 7 and 8. They are all relatively prime to 9, but the other three numbers in this range, 3, 6, and 9 are not, because {{math|1= gcd(9, 3) = gcd(9, 6) = 3}} and {{math|1= gcd(9, 9) = 9}}. Therefore, {{math|1= ''φ''(9) = 6}}. As another example, {{math|1= ''φ''(1) = 1}} since for {{math|1= ''n'' = 1}} the only integer in the range from 1 to {{mvar|n}} is 1 itself, and {{math|1= gcd(1, 1) = 1}}.\n\nEuler's totient function is a [[multiplicative function]], meaning that if two numbers {{mvar|m}} and {{mvar|n}} are relatively prime, then {{math|1= ''φ''(''mn'') = ''φ''(''m'')''φ''(''n'')}}.<ref>{{harvtxt|Long|1972|p=162}}</ref><ref>{{harvtxt|Pettofrezzo|Byrkit|1970|p=80}}</ref>\nThis function gives the [[order (group theory)|order]] of the [[multiplicative group of integers modulo n|multiplicative group of integers modulo {{mvar|n}}]] (the [[Multiplicative group of integers modulo n|group]] of [[unit (ring theory)|unit]]s of the [[ring (algebra)|ring]] {{math|'''ℤ'''/''n'''''ℤ'''}}).<ref>See [[#Euler's theorem|Euler's theorem]].</ref> It also plays a key role in the definition of the [[RSA (cryptosystem)|RSA encryption system]].\n\n== History, terminology, and notation ==\n\n[[Leonhard Euler]] introduced the function in 1763.<ref>L. Euler \"[http://eulerarchive.maa.org/pages/E271.html Theoremata arithmetica nova methodo demonstrata]\" (An arithmetic theorem proved by a new method), ''Novi commentarii academiae scientiarum imperialis Petropolitanae'' (New Memoirs of the Saint-Petersburg Imperial Academy of Sciences), '''8''' (1763), 74–104. (The work was presented at the Saint-Petersburg Academy on October 15, 1759. A work with the same title was presented at the Berlin Academy on June 8, 1758). Available on-line in: [[Ferdinand Rudio]], {{abbr|ed.|editor}}, ''Leonhardi Euleri Commentationes Arithmeticae'', volume 1, in: ''Leonhardi Euleri Opera Omnia'', series 1, volume 2 (Leipzig, Germany, B. G. Teubner, 1915), [http://gallica.bnf.fr/ark:/12148/bpt6k6952c/f571.image pages 531–555]. On page 531, Euler defines {{mvar|n}} as the number of integers that are smaller than {{mvar|N}} and relatively prime to {{mvar|N}} (… aequalis sit multitudini numerorum ipso N minorum, qui simul ad eum sint primi, …), which is the phi function, φ(N).</ref><ref name=\"Sandifer, p. 203\">Sandifer, p. 203</ref><ref>Graham et al. p. 133 note 111</ref> However, he did not at that time choose any specific symbol to denote it. In a 1784 publication, Euler studied the function further, choosing the Greek letter {{mvar|π}} to denote it: he wrote {{math|''πD''}} for \"the multitude of numbers less than {{mvar|D}}, and which have no common divisor with it\".<ref>L. Euler, ''[http://math.dartmouth.edu/~euler/docs/originals/E564.pdf Speculationes circa quasdam insignes proprietates numerorum]'', Acta Academiae Scientarum Imperialis Petropolitinae, vol. 4, (1784), pp. 18–30, or Opera Omnia, Series 1, volume 4, pp. 105–115. (The work was presented at the Saint-Petersburg Academy on October 9, 1775).</ref> This definition varies from the current definition for the totient function at {{math|1=''D'' = 1}} but is otherwise the same. The now-standard notation<ref name=\"Sandifer, p. 203\"/><ref>Both {{math|''φ''(''n'')}} and {{math|''ϕ''(''n'')}} are seen in the literature. These are two forms of the lower-case Greek letter [[phi]].</ref> {{math|''φ''(''A'')}} comes from [[Gauss]]'s 1801 treatise ''[[Disquisitiones Arithmeticae]]'',<ref>Gauss, ''Disquisitiones Arithmeticae'' article&nbsp;38</ref> although Gauss didn't use parentheses around the argument and wrote {{math|''φA''}}. Thus, it is often called '''Euler's phi function''' or simply the '''phi function'''.\n\nIn 1879, [[James Joseph Sylvester|J. J. Sylvester]] coined the term '''totient''' for this function,<ref>J. J. Sylvester (1879) \"On certain ternary cubic-form equations\", ''American Journal of Mathematics'', '''2''' : 357-393; Sylvester coins the term \"totient\" on [https://books.google.com/books?id=-AcPAAAAIAAJ&pg=PA361#v=onepage&q&f=false page 361].</ref><ref>{{cite OED2|totient}}</ref> so it is also referred to as '''Euler's totient function''', the '''Euler totient''', or '''Euler's totient'''. [[Jordan's totient function|Jordan's totient]] is a generalization of Euler's.\n\nThe '''cototient''' of {{mvar|n}} is defined as {{math|''n'' − ''φ''(''n'')}}. It counts the number of positive integers less than or equal to {{mvar|n}} that have at least one [[prime number|prime factor]] in common with {{mvar|n}}.\n\n== Computing Euler's totient function ==\n\nThere are several formulas for computing {{math|''φ''(''n'')}}.\n\n===Euler's product formula===\n\nIt states\n:<math>\\varphi(n) =n \\prod_{p\\mid n} \\left(1-\\frac{1}{p}\\right),</math>\nwhere the product is over the distinct [[prime number]]s dividing {{mvar|n}}. (The notation is described in the article [[Arithmetical function#Notation|Arithmetical function]].)\n\nThe proof of Euler's product formula depends on two important facts.\n\n==== The function is multiplicative ====\n\nThis means that if {{math|1=gcd(''m'', ''n'') = 1}}, then {{math|1=''φ''(''mn'') = ''φ''(''m'') ''φ''(''n'')}}. (''Outline of proof'': let {{mvar|A}}, {{mvar|B}}, {{mvar|C}} be the sets of nonnegative integers, which are, respectively, [[coprime]] to and less than {{mvar|m}}, {{mvar|n}}, and {{mvar|mn}}; then there is a [[bijection]] between {{math|''A'' × ''B''}} and {{mvar|C}}, by the [[Chinese remainder theorem]].)\n\n==== Value for a prime power argument ====\n\nIf {{mvar|p}} is prime and {{math|''k'' ≥ 1}}, then\n\n:<math>\\varphi \\left(p^k\\right) = p^{k-1}(p-1) = p^k \\left( 1 - \\frac{1}{p} \\right).</math>\n\n''Proof'': since {{mvar|p}} is a prime number the only possible values of {{math|gcd(''p''<sup>''k''</sup>, ''m'')}} are {{math|1, ''p'', ''p''<sup>2</sup>, ..., ''p''<sup>''k''</sup>}}, and the only way for {{math|gcd(''p''<sup>''k''</sup>, ''m'')}} to not equal 1 is for {{mvar|m}} to be a multiple of {{mvar|p}}. The multiples of {{mvar|p}} that are less than or equal to {{math|''p''<sup>''k''</sup>}} are {{math|1=''p'', 2''p'', 3''p'', ..., ''p''<sup>''k'' − 1</sup>''p'' = ''p''<sup>''k''</sup>}}, and there are {{math|''p''<sup>''k'' − 1</sup>}}{{math|}} of them. Therefore, the other {{math|''p''<sup>''k''</sup> − ''p''<sup>''k'' − 1</sup>}} numbers are all relatively prime to {{math|''p''<sup>''k''</sup>}}.\n\n====Proof of Euler's product formula====\n\nThe [[fundamental theorem of arithmetic]] states that if {{math|''n'' > 1}} there is a unique expression for {{mvar|n}},\n\n:<math>n = {p_1}^{k_1} \\cdots {p_r}^{k_r}, </math>\n\nwhere {{math|''p''<sub>1</sub> < ''p''<sub>2</sub> < ... < ''p''<sub>''r''</sub>}} are [[prime number]]s and each {{math|''k''<sub>''i''</sub> ≥ 1}}. (The case {{math|1=''n'' = 1}} corresponds to the empty product.)\n\nRepeatedly using the multiplicative property of {{mvar|φ}} and the formula for {{math|''φ''(''p''<sup>''k''</sup>)}} gives\n\n:<math>\\begin{align} \n\\varphi(n)&= \\varphi\\left(p_1^{k_1}\\right) \\varphi\\left(p_2^{k_2}\\right) \\cdots\\varphi\\left(p_r^{k_r}\\right)\\\\\n&= p_1^{k_1} \\left(1- \\frac{1}{p_1} \\right) p_2^{k_2} \\left(1- \\frac{1}{p_2} \\right) \\cdots p_r^{k_r} \\left(1- \\frac{1}{p_r} \\right)\\\\\n&= p_1^{k_1} p_2^{k_2} \\cdots p_r^{k_r} \\left(1- \\frac{1}{p_1} \\right) \\left(1- \\frac{1}{p_2} \\right) \\cdots \\left(1- \\frac{1}{p_r} \\right)\\\\\n&=n \\left(1- \\frac{1}{p_1} \\right)\\left(1- \\frac{1}{p_2} \\right) \\cdots\\left(1- \\frac{1}{p_r} \\right).\n\\end{align}</math>\n\nThis is Euler's product formula.\n\n====Example====\n\n:<math>\\varphi(36)=\\varphi\\left(2^2 3^2\\right)=36\\left(1-\\tfrac12\\right)\\left(1-\\tfrac13\\right)=36\\cdot\\tfrac12\\cdot\\tfrac23=12.</math>\n\nIn words, this says that the distinct prime factors of 36 are 2 and 3; half of the thirty-six integers from 1 to 36 are divisible by 2, leaving eighteen; a third of those are divisible by 3, leaving twelve numbers that are coprime to 36. And indeed there are twelve positive integers that are coprime with 36 and lower than 36: 1, 5, 7, 11, 13, 17, 19, 23, 25, 29, 31, and 35.\n\n===Fourier transform===\n\nThe totient is the [[discrete Fourier transform]] of the [[Greatest common divisor|gcd]], evaluated at 1.<ref>{{harvtxt|Schramm|2008}}</ref> Let\n\n:<math> \\mathcal{F} \\{ \\mathbf{x} \\}[m] = \\sum\\limits_{k=1}^n x_k \\cdot e^{{-2\\pi i}\\frac{mk}{n}}</math>\n\nwhere {{math|''x<sub>k</sub>'' {{=}} gcd(''k'',''n'')}} for {{math|''k'' ∈ {1, …, ''n''}|}}. Then\n\n:<math>\\varphi (n) = \\mathcal{F} \\{ \\mathbf{x} \\}[1] = \\sum\\limits_{k=1}^n \\gcd(k,n) e^{-2\\pi i\\frac{k}{n}}.</math>\n\nThe real part of this formula is\n\n:<math>\\varphi (n)=\\sum\\limits_{k=1}^n \\gcd(k,n) \\cos {2\\pi\\frac{k}{n}}.</math>\n\nNote that unlike the other two formulae (the Euler product and the divisor sum) this one does not require knowing the factors of {{mvar|n}}. However, it does involve the calculation of the greatest common divisor of {{mvar|n}} and every positive integer less than {{mvar|n}}, which suffices to provide the factorization anyway.\n\n===Divisor sum===\n\nThe property established by Gauss,<ref>Gauss, DA, art 39</ref> that\n\n:<math>\\sum_{d\\mid n}\\varphi(d)=n,</math>\n\nwhere the sum is over all positive divisors {{mvar|d}} of {{mvar|n}}, can be proven in several ways. (see [[Arithmetical function#Notation|Arithmetical function]] for notational conventions.)\n\nOne way is to note that {{math|''φ''(''d'')}} is also equal to the number of possible generators of the [[cyclic group]] {{math|''C''<sub>''d''</sub>}}; specifically, if {{math|''C''<sub>''d''</sub> {{=}} ⟨''g''⟩}}, then {{math|''g''<sup>''k''</sup>}} is a generator for every {{mvar|k}} coprime to {{mvar|d}}. Since every element of {{math|''C''<sub>''n''</sub>}} generates a cyclic [[subgroup]], and all subgroups of {{math|''C''<sub>''d''</sub> ≤ ''C''<sub>''n''</sub>}} are generated by some element of {{math|''C''<sub>''n''</sub>}}, the formula follows.<ref>Gauss, DA art. 39, arts. 52-54</ref> In the article [[Root of unity#Elementary facts|Root of unity]] Euler's formula is derived by using this argument in the special case of the multiplicative group of the {{mvar|n}}th roots of unity.\n\nThis formula can also be derived in a more concrete manner.<ref>Graham et al. pp. 134-135</ref> Let {{math|''n'' {{=}} 20}} and consider the fractions between 0 and 1 with denominator 20:\n:<math>\n \\tfrac{ 1}{20},\\,\\tfrac{ 2}{20},\\,\\tfrac{ 3}{20},\\,\\tfrac{ 4}{20},\\,\n \\tfrac{ 5}{20},\\,\\tfrac{ 6}{20},\\,\\tfrac{ 7}{20},\\,\\tfrac{ 8}{20},\\,\n \\tfrac{ 9}{20},\\,\\tfrac{10}{20},\\,\\tfrac{11}{20},\\,\\tfrac{12}{20},\\,\n \\tfrac{13}{20},\\,\\tfrac{14}{20},\\,\\tfrac{15}{20},\\,\\tfrac{16}{20},\\,\n \\tfrac{17}{20},\\,\\tfrac{18}{20},\\,\\tfrac{19}{20},\\,\\tfrac{20}{20}\n</math>\n\nPut them into lowest terms:\n:<math>\n \\tfrac{ 1}{20},\\,\\tfrac{ 1}{10},\\,\\tfrac{ 3}{20},\\,\\tfrac{ 1}{ 5},\\,\n \\tfrac{ 1}{ 4},\\,\\tfrac{ 3}{10},\\,\\tfrac{ 7}{20},\\,\\tfrac{ 2}{ 5},\\,\n \\tfrac{ 9}{20},\\,\\tfrac{ 1}{ 2},\\,\\tfrac{11}{20},\\,\\tfrac{ 3}{ 5},\\,\n \\tfrac{13}{20},\\,\\tfrac{ 7}{10},\\,\\tfrac{ 3}{ 4},\\,\\tfrac{ 4}{ 5},\\,\n \\tfrac{17}{20},\\,\\tfrac{ 9}{10},\\,\\tfrac{19}{20},\\,\\tfrac{1}{1}\n</math>\n\nFirst note that all the divisors of 20 are denominators. And second, note that there are 20 fractions. Which fractions have 20 as denominator? The ones whose numerators are relatively prime to 20 ({{sfrac|1|20}}, {{sfrac|3|20}}, {{sfrac|7|20}}, {{sfrac|9|20}}, {{sfrac|11|20}}, {{sfrac|13|20}}, {{sfrac|17|20}}, {{sfrac|19|20}}). By definition this is {{math|''φ''(20)}} fractions. Similarly, there are {{math|''φ''(10) {{=}} 4}} fractions with denominator 10 ({{sfrac|1|10}}, {{sfrac|3|10}}, {{sfrac|7|10}}, {{sfrac|9|10}}), {{math|''φ''(5) {{=}} 4}} fractions with denominator 5 ({{sfrac|1|5}}, {{sfrac|2|5}}, {{sfrac|3|5}}, {{sfrac|4|5}}), and so on.\n\nIn detail, we are considering the fractions of the form {{mvar|{{sfrac|k|n}}}} where {{mvar|k}} is an integer from 1 to {{mvar|n}} inclusive. Upon reducing these to lowest terms, each fraction will have as its denominator some divisor of {{mvar|n}}. We can group the fractions together by denominator, and we must show that for a given divisor {{mvar|d}} of {{mvar|n}}, the number of such fractions with denominator {{mvar|d}} is {{math|''φ''(''d'')}}.\n\nNote that to reduce {{mvar|{{sfrac|k|n}}}} to lowest terms, we divide the numerator and denominator by {{math|gcd(''k'', ''n'')}}. The reduced fractions with denominator {{mvar|d}} are therefore precisely the ones originally of the form {{mvar|{{sfrac|k|n}}}} in which {{math|gcd(''k'', ''n'') {{=}} ''{{sfrac|n|d}}''}}. The question therefore becomes: how many {{mvar|k}} are there less than or equal to {{mvar|n}} which verify {{math|gcd(''k'', ''n'') {{=}} ''{{sfrac|n|d}}''}}? Any such {{mvar|k}} must clearly be a multiple of {{mvar|{{sfrac|n|d}}}}, but it must also be coprime to {{mvar|d}} (if it had any common divisor {{mvar|s}} with {{mvar|d}}, then {{mvar|{{sfrac|sn|d}}}} would be a larger common divisor of {{mvar|n}} and {{mvar|k}}). Conversely, any multiple {{mvar|k}} of {{mvar|{{sfrac|n|d}}}} which is coprime to {{mvar|d}} will satisfy {{math|gcd(''k'', ''n'') {{=}} ''{{sfrac|n|d}}''}}. We can generate {{math|''φ''(''d'')}} such numbers by taking the numbers less than {{mvar|d}} coprime to {{mvar|d}} and multiplying each one by {{mvar|{{sfrac|n|d}}}} (these products will of course each be smaller than {{mvar|n}}, as required). This in fact generates all such numbers, as if {{mvar|k}} is a multiple of {{mvar|{{sfrac|n|d}}}} coprime to {{mvar|d}} (and less than {{mvar|n}}), then {{math|{{sfrac|''k''|{{frac|''n''|''d''}}}}}} will still be coprime to {{mvar|d}}, and must also be smaller than {{mvar|d}}, else {{mvar|k}} would be larger than {{mvar|n}}. Thus there are precisely {{math|''φ''(''d'')}} values of {{mvar|k}} less than or equal to {{mvar|n}} such that {{math|gcd(''k'', ''n'') {{=}} ''{{sfrac|n|d}}''}}, which was to be demonstrated.\n\n[[Möbius inversion]] gives\n:<math> \\varphi(n) = \\sum_{d\\mid n} \\mu\\left( d \\right) \\cdot \\frac{n}{d}  = n\\sum_{d\\mid n} \\frac{\\mu (d)}{d},</math>\n\nwhere {{mvar|μ}} is the [[Möbius function]].\n\nThis formula may also be derived from the product formula by multiplying out\n\n:<math> \\prod_{p\\mid n} \\left(1 - \\frac{1}{p}\\right) </math>\n\nto get\n\n:<math> \\sum_{d\\mid n} \\frac{\\mu (d)}{d}. </math>\n\n==Some values of the function==\n\nThe first 143 values {{OEIS|A000010}} are shown in the table and graph below:<ref>The cell for {{math|''n'' {{=}} 0}} in the upper-left corner of the table is empty, as the function {{math|''φ''(''n'')}} is commonly defined only for positive integers, so it is not defined for {{math|''n'' {{=}} 0}}.</ref>\n\n[[File:EulerPhi100.svg|thumb|Graph of the first 100 values]]\n:{| class=\"wikitable\" style=\"text-align: right\"\n|+{{math|''φ''(''n'')}} for {{math|1 ≤ ''n'' ≤ 143}}\n! +\n! 0 || 1 || 2 || 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11\n|- \n! 0 \n| {{n/a}} || 1 || 1 || 2 || 2 || 4 || 2 || 6 || 4 || 6 || 4 || 10\n|-\n! 12\n| 4 || 12 || 6 || 8 || 8 || 16 || 6 || 18 || 8 || 12 || 10 || 22\n|- \n! 24\n| 8 || 20 || 12 || 18 || 12 || 28 || 8 || 30 || 16 || 20 || 16 || 24\n|-\n! 36\n| 12 || 36 || 18 || 24 || 16 || 40 || 12 || 42 || 20 || 24 || 22 || 46\n|-\n! 48\n| 16 || 42 || 20 || 32 || 24 || 52 || 18 || 40 || 24 || 36 || 28 || 58\n|-\n! 60\n| 16 || 60 || 30 || 36 || 32 || 48 || 20 || 66 || 32 || 44 || 24 || 70\n|-\n! 72\n| 24 || 72 || 36 || 40 || 36 || 60 || 24 || 78 || 32 || 54 || 40 || 82\n|-\n! 84\n| 24 || 64 || 42 || 56 || 40 || 88 || 24 || 72 || 44 || 60 || 46 || 72\n|-\n! 96\n| 32 || 96 || 42 || 60 || 40 || 100 || 32 || 102 || 48 || 48 || 52 || 106\n|-\n! 108\n| 36 || 108 || 40 || 72 || 48 || 112 || 36 || 88 || 56 || 72 || 58 || 96\n|-\n! 120\n| 32 || 110 || 60 || 80 || 60 || 100 || 36 || 126 || 64 || 84 || 48 || 130\n|-\n! 132\n| 40 || 108 || 66 || 72 || 64 || 136 || 44 || 138 || 48 || 92 || 70 || 120\n|}\n\nThe top line in the graph, {{math|''y'' {{=}} ''n'' − 1}}, is a true [[upper bound]]. It is attained whenever {{mvar|n}} is prime. There is no [[lower bound]] that is a straight line of positive slope; no matter how gentle the slope of a line is, there will eventually be points of the plot below the line. More precisely, the lower limit of the graph is proportional to {{math|{{sfrac|''n''|log log ''n''}}}} rather than being linear.<ref name=\"hw328\"/>\n{{clear}}\n\n==Euler's theorem==\n\n{{main article|Euler's theorem}}\n\nThis states that if {{mvar|a}} and {{mvar|n}} are [[relatively prime]] then\n\n:<math> a^{\\varphi(n)} \\equiv 1\\mod n.</math>\n\nThe special case where {{mvar|n}} is prime is known as [[Fermat's little theorem]].\n\nThis follows from [[Lagrange's theorem (group theory)|Lagrange's theorem]] and the fact that {{math|''φ''(''n'')}} is the [[order (group theory)|order]] of the [[multiplicative group of integers modulo n|multiplicative group of integers modulo {{mvar|n}}]].\n\nThe [[RSA (algorithm)|RSA cryptosystem]] is based on this theorem: it implies that the [[inverse function|inverse]] of the function {{math|''a'' ↦ ''a<sup>e</sup>'' mod ''n''}}, where {{mvar|e}} is the (public) encryption exponent, is the function {{math|''b'' ↦ ''b<sup>d</sup>'' mod ''n''}}, where {{mvar|d}}, the (private) decryption exponent, is the [[multiplicative inverse]] of {{mvar|e}} modulo {{math|''φ''(''n'')}}. The difficulty of computing {{math|''φ''(''n'')}} without knowing the factorization of {{mvar|n}} is thus the difficulty of computing {{mvar|d}}: this is known as the [[RSA problem]] which can be solved by factoring {{mvar|n}}. The owner of the private key knows the factorization, since an RSA private key is constructed by choosing {{mvar|n}} as the product of two (randomly chosen) large primes {{mvar|p}} and {{mvar|q}}. Only {{mvar|n}} is publicly disclosed, and given the [[Integer factorization|difficulty to factor large numbers]] we have the guarantee that no-one else knows the factorization.\n\n==Other formulae==\n\n*<math>a\\mid b \\implies \\varphi(a)\\mid\\varphi(b)</math>\n*<math> n \\mid \\varphi(a^n-1) \\quad \\text{for } a,n > 1</math>\n*<math>\\varphi(mn) = \\varphi(m)\\varphi(n)\\cdot\\frac{d}{\\varphi(d)} \\quad\\text{where }d = \\operatorname{gcd}(m,n)</math>\n:Note the special cases\n:*<math>\\varphi(2m) = \\begin{cases}\n2\\varphi(m) &\\text{ if } m \\text{ is even} \\\\\n\\varphi(m) &\\text{ if } m \\text{ is odd}\n\\end{cases}</math>\n:*<math>\\varphi\\left(n^m\\right) = n^{m-1}\\varphi(n)</math>\n\n*<math>\\varphi(\\operatorname{lcm}(m,n))\\cdot\\varphi(\\operatorname{gcd}(m,n)) = \\varphi(m)\\cdot\\varphi(n)</math>\n\n:Compare this to the formula\n:*<math>\\operatorname{lcm}(m,n)\\cdot \\operatorname{gcd}(m,n) = m \\cdot n</math>\n:(See [[least common multiple]].)\n\n*{{math|''φ''(''n'')}} is even for {{math|''n'' ≥ 3}}. Moreover, if {{mvar|n}} has {{mvar|r}} distinct odd prime factors, {{math|2<sup>''r''</sup> {{!}} ''φ''(''n'')}}\n* For any {{math|''a'' > 1}} and {{math|''n'' > 6}} such that {{math|4 ∤ ''n''}} there exists an {{math|''l'' ≥ 2''n''}} such that {{math|''l'' {{!}} ''φ''(''a<sup>n</sup>'' − 1)}}.\n*<math>\\frac{\\varphi(n)}{n}=\\frac{\\varphi(\\operatorname{rad}(n))}{\\operatorname{rad}(n)}</math>\n:where {{math|rad(''n'')}} is the [[radical of an integer|radical of {{mvar|n}}]].\n*<math>\\sum_{d \\mid n} \\frac{\\mu^2(d)}{\\varphi(d)} = \\frac{n}{\\varphi(n)}</math>&nbsp;<ref>Dineva (in external refs), prop. 1</ref>\n*<math>\\sum_{1\\le k\\le n \\atop (k,n)=1}\\!\\!k = \\tfrac12 n\\varphi(n) \\quad \\text{for }n>1</math>\n*<math>\\sum_{k=1}^n\\varphi(k) = \\tfrac12 \\left(1+ \\sum_{k=1}^n \\mu(k)\\left\\lfloor\\frac{n}{k}\\right\\rfloor^2\\right)\n=\\frac3{\\pi^2}n^2+O\\left(n(\\log n)^\\frac23(\\log\\log n)^\\frac43\\right)</math>&nbsp;(<ref name=Wal1963>{{cite book | zbl=0146.06003 | last=Walfisz | first=Arnold | authorlink=Arnold Walfisz | title=Weylsche Exponentialsummen in der neueren Zahlentheorie | language=German | series=Mathematische Forschungsberichte | volume=16 | location=Berlin | publisher=[[VEB Deutscher Verlag der Wissenschaften]] | year=1963 }}</ref> cited in<ref>{{citation | last = Lomadse | first = G. | title = The scientific work of Arnold Walfisz | journal = Acta Arithmetica | volume = 10 | issue = 3 | pages = 227–237 | url = http://matwbn.icm.edu.pl/ksiazki/aa/aa10/aa10111.pdf}}</ref>)\n\n*<math>\\sum_{k=1}^n\\frac{\\varphi(k)}{k} = \\sum_{k=1}^n\\frac{\\mu(k)}{k}\\left\\lfloor\\frac{n}{k}\\right\\rfloor=\\frac6{\\pi^2}n+O\\left((\\log n)^\\frac23(\\log\\log n)^\\frac43\\right)</math>&nbsp;<ref name=Wal1963/>\n*<math>\\sum_{k=1}^n\\frac{k}{\\varphi(k)} = \\frac{315\\,\\zeta(3)}{2\\pi^4}n-\\frac{\\log n}2+O\\left((\\log n)^\\frac23\\right)</math>&nbsp;<ref name=Sita>{{cite journal|first=R. |last=Sitaramachandrarao |title=On an error term of Landau II |journal=Rocky Mountain J. Math. |volume=15 |date=1985 |pages=579–588}}</ref>\n*<math>\\sum_{k=1}^n\\frac{1}{\\varphi(k)} = \\frac{315\\,\\zeta(3)}{2\\pi^4}\\left(\\log n+\\gamma-\\sum_{p\\text{ prime}}\\frac{\\log p}{p^2-p+1}\\right)+O\\left(\\frac{(\\log n)^\\frac23}n\\right)</math>&nbsp;<ref name=Sita />\n\n:(where {{mvar|γ}} is the [[Euler–Mascheroni constant]]).\n\n*<math>\\sum_\\stackrel{1\\le k\\le n}{\\operatorname{gcd}(k,m)=1} \\!\\!\\!\\! 1 = n \\frac {\\varphi(m)}{m} + O \\left ( 2^{\\omega(m)} \\right )</math>\n:where {{math|''m'' > 1}} is a positive integer and {{math|''ω''(''m'')}} is the number of distinct prime factors of {{mvar|m}}.<ref>Bordellès in the [[#External links|external links]]</ref>\n\n===Menon's identity===\n\n{{Main article|Arithmetic_function#Menon.27s_identity|l1=Menon's identity}}\nIn 1965 P. Kesava Menon proved\n:<math>\\sum_{\\stackrel{1\\le k\\le n}{ \\gcd(k,n)=1}} \\!\\!\\!\\! \\gcd(k-1,n)=\\varphi(n)d(n),</math>\nwhere [[Divisor function|{{math|''d''(''n'') {{=}} ''σ''<sub>0</sub>(''n'')}}]] is the number of divisors of {{mvar|n}}.\n\n===Formulae involving the golden ratio===\n\nSchneider<ref>All formulae in the section are from Schneider (in the external links)</ref> found a pair of identities connecting the totient function, the [[golden ratio]] and the [[Möbius function]] {{math|''μ''(''n'')}}. In this section {{math|''φ''(''n'')}} is the totient function, and {{math|''ϕ'' {{=}} {{sfrac|1 + {{sqrt|5}}|2}} {{=}} 1.618…}} is the golden ratio.\n\nThey are:\n:<math>\\phi=-\\sum_{k=1}^\\infty\\frac{\\varphi(k)}{k}\\log\\left(1-\\frac{1}{\\phi^k}\\right)</math>\nand\n:<math>\\frac{1}{\\phi}=-\\sum_{k=1}^\\infty\\frac{\\mu(k)}{k}\\log\\left(1-\\frac{1}{\\phi^k}\\right).</math>\nSubtracting them gives\n:<math>\\sum_{k=1}^\\infty\\frac{\\mu(k)-\\varphi(k)}{k}\\log\\left(1-\\frac{1}{\\phi^k}\\right)=1.</math>\nApplying the exponential function to both sides of the preceding identity yields an infinite product formula for [[e (mathematical constant)|{{mvar|e}}]]:\n\n:<math>e= \\prod_{k=1}^{\\infty} \\left(1-\\frac{1}{\\phi^k}\\right)^\\frac{\\mu(k)-\\varphi(k)}{k}. </math>\n\nThe proof is based on the two formulae\n:<math>\\begin{align}\n\\sum_{k=1}^\\infty\\frac{\\varphi(k)}{k}\\left(-\\log\\left(1-x^k\\right)\\right)&=\\frac{x}{1-x} \\\\\n\\text{and}\\; \\sum_{k=1}^\\infty\\frac{\\mu(k)}{k}\\left(-\\log\\left(1-x^k\\right)\\right)&=x, \\qquad \\quad \\text{for } 0<x<1.\n\\end{align}</math>\n\n==Generating functions==\n\nThe [[Dirichlet series]] for {{math|''φ''(''n'')}} may be written in terms of the [[Riemann zeta function]] as:<ref>{{harvnb|Hardy|Wright|1979|loc=thm. 288}}</ref>\n:<math>\\sum_{n=1}^\\infty \\frac{\\varphi(n)}{n^s}=\\frac{\\zeta(s-1)}{\\zeta(s)}.</math>\n\nThe [[Lambert series]] generating function is<ref>{{harvnb|Hardy|Wright|1979|loc=thm. 309}}</ref>\n\n:<math>\\sum_{n=1}^{\\infty} \\frac{\\varphi(n) q^n}{1-q^n}= \\frac{q}{(1-q)^2}</math>\n\nwhich converges for {{math|{{abs|''q''}} < 1}}.\n\nBoth of these are proved by elementary series manipulations and the formulae for {{math|''φ''(''n'')}}.\n\n==Growth rate==\n\nIn the words of Hardy & Wright, the order of {{math|''φ''(''n'')}} is “always ‘nearly {{mvar|n}}’.”<ref>{{harvnb|Hardy|Wright|1979|loc=intro to § 18.4}}</ref>\n\nFirst<ref>{{harvnb|Hardy|Wright|1979|loc=thm. 326}}</ref>\n\n:<math>\\lim\\sup \\frac{\\varphi(n)}{n}= 1,</math>\n\nbut as ''n'' goes to infinity,<ref>{{harvnb|Hardy|Wright|1979|loc=thm. 327}}</ref> for all {{math|''δ'' > 0}}\n\n:<math>\\frac{\\varphi(n)}{n^{1-\\delta}}\\rightarrow\\infty.</math>\n\nThese two formulae can be proved by using little more than the formulae for {{math|''φ''(''n'')}} and the [[divisor function|divisor sum function]] {{math|''σ''(''n'')}}.\n\nIn fact, during the proof of the second formula, the inequality\n\n:<math>\\frac {6}{\\pi^2} < \\frac{\\varphi(n) \\sigma(n)}{n^2} < 1,</math>\n\ntrue for {{math|''n'' > 1}}, is proved.\n \nWe also have<ref name=\"hw328\">{{harvnb|Hardy|Wright|1979|loc=thm. 328}}</ref>\n\n:<math>\\lim\\inf\\frac{\\varphi(n)}{n}\\log\\log n = e^{-\\gamma}.</math>\n\nHere {{mvar|γ}} is [[Euler–Mascheroni constant|Euler's constant]], {{math|''γ'' {{=}} 0.577215665...}}, so {{math|''e<sup>γ</sup>'' {{=}} 1.7810724...}} and {{math|''e''<sup>−''γ''</sup> {{=}} 0.56145948...}}.\n\nProving this does not quite require the [[prime number theorem]].<ref>In fact Chebyshev's theorem ({{harvnb|Hardy|Wright|1979|loc=thm.7}}) and\nMertens' third theorem is all that is needed.</ref><ref>{{harvnb|Hardy|Wright|1979|loc=thm. 436}}</ref> Since {{math|log log (''n'')}} goes to infinity, this formula shows that\n\n:<math>\\lim\\inf\\frac{\\varphi(n)}{n}= 0.</math>\n\nIn fact, more is true.<ref>Theorem 15 of {{cite journal|last1=Rosser |first1=J. Barkley |last2=Schoenfeld |first2=Lowell |title=Approximate formulas for some functions of prime numbers |journal=Illinois J. Math. |volume=6 |date=1962 |issue=1 |pages=64–94 |url=http://projecteuclid.org/euclid.ijm/1255631807}}</ref><ref>Bach & Shallit, thm. 8.8.7</ref><ref name=Rib320>{{cite book|last=Ribenboim|title=The Book of Prime Number Records|at=Section 4.I.C}}{{full citation needed|date=July 2017}}</ref>\n\n:<math>\\varphi(n) > \\frac {n} {e^\\gamma\\; \\log \\log n + \\frac {3} {\\log \\log n}} \\quad\\text{for } n>2</math>\n\nand\n\n:<math>\\varphi(n) < \\frac {n} {e^{ \\gamma}\\log \\log n} \\quad\\text{for infinitely many } n.</math>\n\nThe second inequality was shown by [[Jean-Louis Nicolas]]. Ribenboim says \"The method of proof is interesting, in that the inequality is shown first under the assumption that the [[Riemann hypothesis]] is true, secondly under the contrary assumption.\"<ref name=Rib320/>\n\nFor the average order, we have<ref name=Wal1963/><ref name=SMC2425>Sándor, Mitrinović & Crstici (2006) pp.24–25</ref>\n\n:<math>\\varphi(1)+\\varphi(2)+\\cdots+\\varphi(n) = \\frac{3n^2}{\\pi^2}+O\\left(n(\\log n)^\\frac23(\\log\\log n)^\\frac43\\right) \\quad\\text{as }n\\rightarrow\\infty,</math>\ndue to [[Arnold Walfisz]], its proof exploiting estimates on exponential sums due to [[Ivan Matveevich Vinogradov|I. M. Vinogradov]] and [[N. M. Korobov]] (this is currently the best known estimate of this type). The [[Big O notation|\"Big {{mvar|O}}\"]] stands for a quantity that is bounded by a constant times the function of {{mvar|n}} inside the parentheses (which is small compared to {{math|''n''<sup>2</sup>}}).\n\nThis result can be used to prove<ref>{{harvnb|Hardy|Wright|1979|loc=thm. 332}}</ref> that the probability of two randomly chosen numbers being relatively prime is {{sfrac|6|{{pi}}<sup>2</sup>}}.\n\n==Ratio of consecutive values==\n\nIn 1950 Somayajulu proved<ref name=Rib38>Ribenboim, p.38</ref><ref name=SMC16>Sándor, Mitrinović & Crstici (2006) p.16</ref>\n\n:<math>\\begin{align}\n\\lim\\inf \\frac{\\varphi(n+1)}{\\varphi(n)}&= 0 \\quad\\text{and} \\\\[5px]\n\\lim\\sup \\frac{\\varphi(n+1)}{\\varphi(n)}&= \\infty.\n\\end{align}</math>\n\nIn 1954 [[Andrzej Schinzel|Schinzel]] and [[Wacław Sierpiński|Sierpiński]] strengthened this, proving<ref name=Rib38/><ref name=SMC16/> that the set\n\n:<math>\\left\\{\\frac{\\varphi(n+1)}{\\varphi(n)},\\;\\;n = 1,2,\\cdots\\right\\}</math>\n\nis [[Dense set|dense]] in the positive real numbers. They also proved<ref name=Rib38/> that the set\n\n:<math>\\left\\{\\frac{\\varphi(n)}{n},\\;\\;n = 1,2,\\cdots\\right\\}</math>\n\nis dense in the interval (0,1).\n\n==Totient numbers==\nA '''totient number''' is a value of Euler's totient function: that is, an {{mvar|m}} for which there is at least one {{mvar|n}} for which {{math|''φ''(''n'') {{=}} ''m''}}. The ''valency'' or ''multiplicity'' of a totient number {{mvar|m}} is the number of solutions to this equation.<ref name=Guy144>Guy (2004) p.144</ref> A ''[[nontotient]]'' is a natural number which is not a totient number. Every odd integer exceeding 1 is trivially a nontotient. There are also infinitely many even nontotients,<ref name=SC230>Sándor & Crstici (2004) p.230</ref> and indeed every positive integer has a multiple which is an even nontotient.<ref name=Zha1993>{{cite journal | zbl=0772.11001 | last=Zhang | first=Mingzhi | title=On nontotients | journal=[[Journal of Number Theory]] | volume=43 | number=2 | pages=168–172 | year=1993 | issn=0022-314X | doi=10.1006/jnth.1993.1014}}</ref>\n\nThe number of totient numbers up to a given limit {{mvar|x}} is\n\n:<math>\\frac{x}{\\log x}e^{ \\big(C+o(1)\\big)(\\log\\log\\log x)^2 } </math>\n\nfor a constant {{math|''C'' {{=}} 0.8178146...}}.<ref name=Ford1998>{{cite journal | zbl=0914.11053 | last=Ford | first=Kevin | title=The distribution of totients | journal=Ramanujan J. | volume=2 | number=1–2 | pages=67–151 | year=1998 | issn=1382-4090 | doi=10.1007/978-1-4757-4507-8_8| arxiv=1104.3264 }}</ref>\n\nIf counted accordingly to multiplicity, the number of totient numbers up to a given limit {{mvar|x}} is\n\n:<math>\\Big\\vert\\{ n : \\phi(n) \\le x \\}\\Big\\vert = \\frac{\\zeta(2)\\zeta(3)}{\\zeta(6)} \\cdot x + R(x)</math>\n\nwhere the error term {{mvar|R}} is of order at most {{math|{{sfrac|''x''|(log ''x'')<sup>''k''</sup>}}}} for any positive {{mvar|k}}.<ref name=SMC22>Sándor et al (2006) p.22</ref>\n\nIt is known that the multiplicity of {{mvar|m}} exceeds {{math|''m''<sup>''δ''</sup>}} infinitely often for any {{math|''δ'' < 0.55655}}.<ref name=SMC21>Sándor et al (2006) p.21</ref><ref name=Guy145>Guy (2004) p.145</ref>\n\n===Ford's theorem===\n\n{{harvtxt|Ford|1999}} proved that for every integer {{math|''k'' ≥ 2}} there is a totient number {{mvar|m}} of multiplicity {{mvar|k}}: that is, for which the equation {{math|''φ''(''n'') {{=}} ''m''}} has exactly {{mvar|k}} solutions; this result had previously been conjectured by [[Wacław Sierpiński]],<ref name=SC229>Sándor & Crstici (2004) p.229</ref> and it had been obtained as a consequence of [[Schinzel's hypothesis H]].<ref name=Ford1998/> Indeed, each multiplicity that occurs, does so infinitely often.<ref name=Ford1998/><ref name=Guy145/>\n\nHowever, no number {{mvar|m}} is known with multiplicity {{math|''k'' {{=}} 1}}. [[Carmichael's totient function conjecture]] is the statement that there is no such {{mvar|m}}.<ref name=SC228>Sándor & Crstici (2004) p.228</ref>\n\n===Perfect totient numbers===\n\n{{main article|Perfect totient number}}\n\n==Applications==\n\n===Cyclotomy===\n\n{{main article|Constructible polygon}}\n\nIn the last section of the [[Disquisitiones Arithmeticae|''Disquisitiones'']]<ref>Gauss, DA. The 7th § is arts. 336–366</ref><ref>Gauss proved if {{mvar|n}} satisfies certain conditions then the {{mvar|n}}-gon can be constructed. In 1837 [[Pierre Wantzel]] proved the converse, if the {{mvar|n}}-gon is constructible, then {{mvar|n}} must satisfy Gauss's conditions</ref> Gauss proves<ref>Gauss, DA, art 366</ref> that a regular {{mvar|n}}-gon can be constructed with straightedge and compass if {{math|''φ''(''n'')}} is a power of 2. If {{mvar|n}} is a power of an odd prime number the formula for the totient says its totient can be a power of two only if {{mvar|n}} is a first power and {{math|''n'' − 1}} is a power of 2. The primes that are one more than a power of 2 are called [[Fermat prime]]s, and only five are known: 3, 5, 17, 257, and 65537. Fermat and Gauss knew of these. Nobody has been able to prove whether there are any more.\n\nThus, a regular {{mvar|n}}-gon has a straightedge-and-compass construction if ''n'' is a product of distinct Fermat primes and any power of 2. The first few such {{mvar|n}} are<ref>Gauss, DA, art. 366. This list is the last sentence in the ''Disquisitiones''</ref>\n:2, 3, 4, 5, 6, 8, 10, 12, 15, 16, 17, 20, 24, 30, 32, 34, 40,... {{OEIS|A003401}}.\n\n===The RSA cryptosystem===\n\n{{main article|RSA (algorithm)}}\n\nSetting up an RSA system involves choosing large prime numbers {{mvar|p}} and {{mvar|q}}, computing {{math|''n'' {{=}} ''pq''}} and {{math|''k'' {{=}} ''φ''(''n'')}}, and finding two numbers {{mvar|e}} and {{mvar|d}} such that {{math|''ed'' ≡ 1 (mod ''k'')}}. The numbers {{mvar|n}} and {{mvar|e}} (the \"encryption key\") are released to the public, and {{mvar|d}} (the \"decryption key\") is kept private.\n\nA message, represented by an integer {{mvar|m}}, where {{math|0 < ''m'' < ''n''}}, is encrypted by computing {{math|''S'' {{=}} ''m''<sup>''e''</sup> (mod ''n'')}}.\n\nIt is decrypted by computing {{math|''t'' {{=}} ''S''<sup>''d''</sup> (mod ''n'')}}. Euler's Theorem can be used to show that if {{math|0 < ''t'' < ''n''}}, then {{math|''t'' {{=}} ''m''}}.\n\nThe security of an RSA system would be compromised if the number {{mvar|n}} could be factored or if {{math|''φ''(''n'')}} could be computed without factoring {{mvar|n}}.\n\n==Unsolved problems==\n\n===Lehmer's conjecture===\n\n{{main article|Lehmer's totient problem}}\n\nIf {{mvar|p}} is prime, then {{math|''φ''(''p'') {{=}} ''p'' − 1}}. In 1932 [[D. H. Lehmer]] asked if there are any composite numbers {{mvar|n}} such that {{math|''φ''(''n'') {{!}} ''n'' − 1}}. None are known.<ref>Ribenboim, pp. 36–37.</ref>\n\nIn 1933 he proved that if any such {{mvar|n}} exists, it must be odd, square-free, and divisible by at least seven primes (i.e. {{math|''ω''(''n'') ≥ 7}}). In 1980 Cohen and Hagis proved that {{math|''n'' > 10<sup>20</sup>}} and that {{math|''ω''(''n'') ≥ 14}}.<ref>{{cite journal | zbl=0436.10002 | last1=Cohen | first1=Graeme L. | last2=Hagis | first2=Peter, Jr. | title=On the number of prime factors of {{mvar|n}} if {{math|''φ''(''n'')}} divides {{math|''n'' − 1}} | journal=Nieuw Arch. Wiskd., III. Ser. | volume=28 | pages=177–185 | year=1980 | issn=0028-9825 }}</ref> Further, Hagis showed that if 3 divides {{mvar|n}} then {{math|''n'' > 10<sup>1937042</sup>}} and {{math|''ω''(''n'') ≥ 298848}}.<ref>{{cite journal | zbl=0668.10006 | last=Hagis | first=Peter, Jr. | title=On the equation {{math|''M''·φ(''n'') {{=}} ''n'' − 1}} | journal=Nieuw Arch. Wiskd., IV. Ser. | volume=6 | number=3 | pages=255–261 | year=1988 | issn=0028-9825 }}</ref><ref name=Guy142>Guy (2004) p.142</ref>\n\n===Carmichael's conjecture===\n\n{{main article|Carmichael's totient function conjecture}}\n\nThis states that there is no number {{mvar|n}} with the property that for all other numbers {{mvar|m}}, {{math|''m'' ≠ ''n''}}, {{math|''φ''(''m'') ≠ ''φ''(''n'')}}. See [[#Ford's theorem|Ford's theorem]] above.\n\nAs stated in the main article, if there is a single counterexample to this conjecture, there must be infinitely many counterexamples, and the smallest one has at least ten billion digits in base 10.<ref name=Guy144/>\n\n== See also ==\n*[[Carmichael function]]\n*[[Duffin–Schaeffer conjecture]]\n*[[Fermat's little theorem#Generalizations|Generalizations of Fermat's little theorem]]\n*[[Highly composite number]]\n*[[Multiplicative group of integers modulo n|Multiplicative group of integers modulo {{mvar|n}}]]\n*[[Ramanujan sum]]\n\n== Notes ==\n{{Reflist|30em}}\n\n==References==\n{{refbegin|colwidth=30em}}\n\nThe ''[[Disquisitiones Arithmeticae]]'' has been translated from Latin into English and German. The German edition includes all of Gauss' papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes.\n\nReferences to the ''Disquisitiones'' are of the form Gauss, DA, art. ''nnn''.\n\n*{{citation\n | last1 = Abramowitz | first1 = M. | author1-link = Milton Abramowitz\n | last2 = Stegun | first2 = I. A. | author2-link = Irene A. Stegun\n | isbn = 0-486-61272-4\n | location = New York\n | publisher = [[Dover Publications]]\n | title = Handbook of Mathematical Functions\n | year = 1964}}. See paragraph 24.3.2.\n*{{citation\n | last1 = Bach | first1 = Eric | author1-link = Eric Bach\n | last2 = Shallit | first2 = Jeffrey | author2-link = Jeffrey Shallit\n | title = Algorithmic Number Theory (Vol I: Efficient Algorithms)\n | publisher = [[The MIT Press]]\n | location = Cambridge, MA\n | year = 1996\n | isbn = 0-262-02405-5\n | zbl=0873.11070\n | series=MIT Press Series in the Foundations of Computing\n}}\n*{{citation\n | last = Ford | first = Kevin\n | doi = 10.2307/121103\n | mr = 1715326 | zbl=0978.11053\n | issn= 0003-486X\n | issue = 1\n | journal = [[Annals of Mathematics]]\n | jstor = 121103\n | pages = 283–311\n | title = The number of solutions of φ(''x'')&nbsp;=&nbsp;''m''\n | volume = 150\n | year = 1999}}.\n*{{citation\n | last1 = Gauss | first1 = Carl Friedrich | author1-link = Carl Friedrich Gauss\n | last2 = Clarke | first2 = Arthur A. (translator into English) \n | title = Disquisitiones Arithmeticae (Second, corrected edition)\n | publisher = [[Springer Publishing|Springer]]\n | location = New York\n | year = 1986\n | isbn = 0-387-96254-9}}\n*{{citation\n | last1 = Gauss | first1 = Carl Friedrich | author1-link = Carl Friedrich Gauss\n | last2 = Maser | first2 = H. (translator into German) \n | title = Untersuchungen uber hohere Arithmetik (Disquisitiones Arithmeticae & other papers on number theory) (Second edition)\n | publisher = Chelsea\n | location = New York\n | year = 1965\n | isbn = 0-8284-0191-8}}\n*{{citation\n | last1 = Graham | first1 = Ronald | author1-link = Ronald Graham\n | last2 = Knuth | first2 = Donald | author2-link = Donald Knuth\n | last3 = Patashnik | first3 = Oren | author3-link = Oren Patashnik\n | title = [[Concrete Mathematics]]: a foundation for computer science\n | edition=2nd\n | publisher = Addison-Wesley\n | location = Reading, MA\n | year = 1994\n | isbn = 0-201-55802-5 | zbl=0836.00001}}\n* {{citation | first=Richard K. | last=Guy | authorlink=Richard K. Guy | title=Unsolved Problems in Number Theory | edition=3rd | publisher=[[Springer-Verlag]] | year=2004 | isbn=0-387-20860-7 | zbl=1058.11001 | series=Problem Books in Mathematics | location=New York, NY }}\n*{{citation\n | last1 = Hardy | first1 = G. H. | author1-link = G. H. Hardy\n | last2 = Wright | first2 = E. M. | author2-link = E. M. Wright\n | title = [[An Introduction to the Theory of Numbers]]\n | edition = Fifth\n | publisher = [[Oxford University Press]]\n | location = Oxford\n | year = 1979\n | isbn = 978-0-19-853171-5}}\n* {{citation | first1 = Calvin T. | last1 = Long | year = 1972 | title = Elementary Introduction to Number Theory | edition = 2nd | publisher = [[D. C. Heath and Company]] | location = Lexington | lccn = 77-171950 }}\n* {{citation | first1 = Anthony J. | last1 = Pettofrezzo | first2 = Donald R. | last2 = Byrkit | year = 1970 | title = Elements of Number Theory | publisher = [[Prentice Hall]] | location = Englewood Cliffs | lccn = 77-81766 }}\n*{{citation\n | last1 = Ribenboim | first1 = Paulo | authorlink = Paulo Ribenboim\n | title = The New Book of Prime Number Records | edition=3rd\n | publisher = [[Springer Science+Business Media|Springer]]\n | location = New York\n | year = 1996\n | zbl=0856.11001\n | isbn = 0-387-94457-5}}\n*{{citation\n | last1 = Sandifer | first1 = Charles\n | title = The early mathematics of Leonhard Euler\n | publisher = MAA\n | year = 2007\n | isbn = 0-88385-559-3}}\n* {{citation | editor1-last=Sándor | editor1-first=József | editor2-last=Mitrinović | editor2-first=Dragoslav S. | editor3-last=Crstici |editor3-first=Borislav | title=Handbook of number theory I | location=Dordrecht | publisher=[[Springer-Verlag]] | year=2006 | isbn=1-4020-4215-9 | zbl=1151.11300 | pages=9–36}}\n* {{cite book | last1=Sándor | first1=Jozsef | last2=Crstici | first2=Borislav | title=Handbook of number theory II | location=Dordrecht | publisher=Kluwer Academic | year=2004 | isbn=1-4020-2546-7 | zbl=1079.11001 | pages=179–327 }}\n*{{citation\n | last = Schramm | first = Wolfgang\n | issue = 8(1)\n | journal = Electronic Journal of Combinatorial Number Theory\n | title = The Fourier transform of functions of the greatest common divisor\n | volume = A50\n | year = 2008\n |url=http://www.integers-ejcnt.org/vol8.html }}.\n{{refend}}\n\n==External links==<!-- This section is linked from [[Euler's totient function]] -->\n* {{springer|title=Totient function|id=p/t110040}}\n*[http://www.oxfordmathcenter.com/drupal7/node/172 Euler's Phi Function and the Chinese Remainder Theorem — proof that {{math|''φ''(''n'')}} is multiplicative]\n*[http://www.javascripter.net/math/calculators/eulertotientfunction.htm Euler's totient function calculator in JavaScript — up to 20 digits]\n*Dineva, Rosica, [http://www.mtholyoke.edu/~robinson/reu/reu05/rdineva1.pdf The Euler Totient, the Möbius, and the Divisor Functions]\n*Plytage, Loomis, Polhill [http://facstaff.bloomu.edu/jpolhill/cmj034-042.pdf Summing Up The Euler Phi Function]\n\n{{Totient}}\n\n[[Category:Modular arithmetic]]\n[[Category:Multiplicative functions]]\n[[Category:Articles containing proofs]]\n[[Category:Algebra]]\n[[Category:Number theory]]\n[[Category:Leonhard Euler]]"
    },
    {
      "title": "Factorization of polynomials over finite fields",
      "url": "https://en.wikipedia.org/wiki/Factorization_of_polynomials_over_finite_fields",
      "text": "In [[mathematics]] and [[computer algebra]] the [[factorization of polynomials|factorization of a polynomial]] consists of decomposing it into a [[product (mathematics)|product]] of [[irreducible polynomial|irreducible factors]]. This decomposition is theoretically possible and is unique for [[polynomial]]s with [[coefficient]]s in any [[field (mathematics)|field]], but rather strong restrictions on the field of the coefficients are needed to allow the computation of the factorization by means of an [[algorithm]]. In practice, algorithms have been designed only for polynomials with coefficients in a [[finite field]], in the [[field of rationals]] or in a [[finitely generated field extension]] of one of them.\n\nAll factorization algorithms, including the case of multivariate polynomials over the rational numbers, reduce the problem to this case; see [[polynomial factorization]]. It is also used for various applications of finite fields, such as [[coding theory]] ([[cyclic redundancy]] codes and [[BCH code]]s), [[cryptography]] ([[public key cryptography]] by the means of [[elliptic curve cryptography|elliptic curves]]), and [[computational number theory]].\n\nAs the reduction of the factorization of [[multivariate polynomial]]s to that of univariate polynomials does not have any specificity in the case of coefficients in a finite field, only polynomials with one variable are considered in this article.\n\n==Background==\n\n===Finite field===\n{{main article|Finite field}}\nThe theory of finite fields, whose origins can be traced back to the works of [[Gauss]] and [[Galois]], has played a part in various branches of mathematics. Due to the applicability of the concept in other topics of mathematics and sciences like computer science there has been a resurgence of interest in finite fields and this is partly due to important applications in [[coding theory]] and [[cryptography]]. Applications of finite fields introduce some of these developments in [[cryptography]], [[computer algebra]] and [[coding theory]].\n\nA finite field or [[Galois field]] is a field with a [[Wikt:finite|finite]] order (number of elements). The order of a finite field is always a [[prime]] or a power of prime. For each [[prime power]] ''q'' = ''p<sup>r</sup>'', there exists exactly one finite field with ''q'' elements, [[up to]] isomorphism. This field is denoted ''GF''(''q'') or '''F'''<sub>''q''</sub>. If ''p'' is prime, ''GF''(''p'') is the [[prime field]] of order ''p''; it is the field of [[residue class#Ring of congruence classes|residue class]]es modulo ''p'', and its ''p'' elements are denoted 0, 1, ..., ''p''−1. Thus ''a''&nbsp;=&nbsp;''b'' in ''GF''(''p'') means the same as ''a'' ≡ ''b'' (mod ''p'').\n\n===Irreducible polynomials===\nLet ''F'' be a finite field. As for general fields, a non-constant polynomial ''f'' in ''F''[''x''] is said to be [[irreducible polynomial|irreducible]] over ''F'' if it is not the product of two polynomials of positive degree. A polynomial of positive degree that is not irreducible over ''F'' is called ''reducible over'' ''F''.\n\nIrreducible polynomials allow us to construct the finite fields of non-prime order. In fact, for a prime power ''q'', let '''F'''<sub>''q''</sub> be the finite field with ''q'' elements, unique up to isomorphism. A polynomial ''f'' of degree ''n'' greater than one, which is irreducible over '''F'''<sub>''q''</sub>, defines a field extension of degree ''n'' which is isomorphic to the field with ''q''<sup>''n''</sup> elements: the elements of this extension are the polynomials of degree lower than ''n''; addition, subtraction and multiplication by an element of '''F'''<sub>''q''</sub> are those of the polynomials; the product of two elements is the remainder of the division by ''f'' of their product as polynomials; the inverse of an element may be computed by the extended GCD algorithm (see [[Polynomial greatest common divisor|Arithmetic of algebraic extensions]]).\n\nIt follows that, to compute in a finite field of non prime order, one needs to generate an irreducible polynomial. For this, the common method is to take a polynomial at random and test it for irreducibility. For sake of efficiency of the multiplication in the field, it is usual to search for polynomials of the shape ''x''<sup>''n''</sup> + ''ax'' + ''b''.{{Citation needed|date=February 2014}}\n\nIrreducible polynomials over finite fields are also useful for [[Pseudorandom]] number generators using feedback shift registers and [[discrete logarithm]] over '''F'''<sub>2<sup>''n''</sup></sub>.\n\nThe number of irreducible [[monic polynomial]]s of degree n over '''F'''<sub>''q''</sub> is the number of [[Necklace (combinatorics)#Aperiodic necklaces|aperioidic necklaces]], given by [[Necklace polynomial|Moreau's necklace-counting function]] ''M''<sub>''q''</sub>(''n''). The closely related necklace function ''N''<sub>''q''</sub>(''n'') counts monic polynomials of degree ''n'' which are primary (a power of an irreducible); or alternatively irreducible polynomials of all degrees d which divide n.<ref>Christophe Reutenauer, ''Mots circulaires et polynomes irreductibles'', Ann. Sci. math Quebec, vol 12, no 2, pp. 275-285</ref>\n\n=== Example ===\nThe polynomial ''P'' = ''x''<sup>4</sup> + 1 is irreducible over '''Q''' but not over any finite field.\n\n* On any field extension of '''F'''<sub>2</sub>, ''P'' = (''x''+1)<sup>4</sup>.\n*On every other finite field, at least one of −1, 2 and −2 is a square, because the product of two non-squares is a square and so we have\n#If <math>-1=a^2,</math> then <math>P=(x^2+a)(x^2-a).</math>\n#If <math>2=b^2,</math> then <math>P=(x^2+bx+1)(x^2-bx+1).</math>\n#If <math>-2=c^2,</math> then <math>P=(x^2+cx-1)(x^2-cx-1).</math>\n\n===Complexity===\nPolynomial factoring algorithms use basic polynomial operations such as products, divisions, gcd, powers of one polynomial modulo another, etc. A [[Multiplication algorithm#Polynomial multiplication|multiplication]] of two polynomials of degree at most ''n'' can be done in [[Big O notation|''O''(''n''<sup>2</sup>)]] operations in '''F'''<sub>''q''</sub> using \"classical\" arithmetic, or in ''O''(''n''log(''n'') log(log(''n'')) ) operations in '''F'''<sub>''q''</sub> using [[Multiplication algorithm#Fast multiplication algorithms for large inputs|\"fast\" arithmetic]]. A [[Euclidean division]] (division with remainder) can be performed within the same time bounds. The cost of a [[polynomial greatest common divisor]] between two polynomials of degree at most ''n'' can be taken as ''O''(''n''<sup>2</sup>) operations in '''F'''<sub>''q''</sub> using classical methods, or as ''O''(''n''log<sup>2</sup>(''n'') log(log(''n'')) ) operations in '''F'''<sub>''q''</sub> using fast methods.  For polynomials ''h'', ''g'' of degree at most ''n'', the exponentiation ''h<sup>q</sup>'' mod ''g'' can be done with ''O''(log(''q'')) polynomial products, using [[exponentiation by squaring]] method, that is ''O''(''n''<sup>2</sup>log(''q'')) operations in '''F'''<sub>''q''</sub> using classical methods, or ''O''(''n''log(''q'')log(''n'') log(log(''n''))) operations in '''F'''<sub>''q''</sub> using fast methods.\n\nIn the algorithms that follow, the complexities are expressed in terms of number of arithmetic operations in '''F'''<sub>''q''</sub>, using classical algorithms for the arithmetic of polynomials.\n\n==Factoring algorithms==\nMany algorithms for factoring polynomials over finite fields include the following three stages:\n# [[#Square-free factorization|Square-free factorization]]\n# [[#Distinct-degree factorization|Distinct-degree factorization]]\n# [[#Equal-degree factorization|Equal-degree factorization]]\nAn important exception is [[Berlekamp's algorithm]], which combines stages 2 and 3.\n\n===Berlekamp's algorithm===\n{{main article|Berlekamp's algorithm}}\n\nThe Berlekamp's algorithm is historically important as being the first factorization algorithm, which works well in practice. However, it contains a loop on the elements of the ground field, which implies that it is practicable only over small finite fields. For a fixed ground field, its [[time complexity]] is polynomial, but, for general ground fields, the complexity is exponential in the size of the ground field.\n\n===Square-free factorization===\nThe algorithm determines a [[square-free polynomial|square-free]] factorization for polynomials whose coefficients come from the finite field '''F'''<sub>''q''</sub> of order ''q'' = ''p<sup>m</sup>'' with ''p'' a prime.  This algorithm firstly determines the [[derivative]] and then computes the gcd of the polynomial and its derivative. If it is not one then the gcd is again divided into the original polynomial, provided that the derivative is not zero (a case that exists for non-constant polynomials defined over finite fields).\n\nThis algorithm uses the fact that, if the derivative of a polynomial is zero, then it is a polynomial in ''x''<sup>''p''</sup>, which is, if the coefficients belong to '''F'''<sub>''p''</sub>, the ''p''th power of the polynomial obtained by substituting ''x'' by ''x''<sup>1/''p''</sup>. If the coefficients do not belong to '''F'''<sub>''p''</sub>, the ''p''-th root of a polynomial with zero derivative is obtained by the same substitution on ''x'', completed by applying the inverse of the [[Frobenius endomorphism|Frobenius automorphism]] to the coefficients.\n\nThis algorithm works also over a field of [[characteristic (algebra)|characteristic]] zero, with the only difference that it never enters in the blocks of instructions where ''p''th roots are computed. However, in this case, [[Square-free polynomial#Yun's algorithm|Yun's algorithm]] is much more efficient because it computes the greatest common divisors of polynomials of lower degrees. A consequence is that, when factoring a polynomial over the integers, the algorithm which follows is not used: one compute first the square-free factorization over the integers, and to factor the resulting polynomials, one chooses a ''p'' such that they remain square-free modulo ''p''. \n    '''Algorithm''': '''SFF''' (Square-Free Factorization)\n    '''Input''': A [[monic polynomial]] ''f'' in '''F'''<sub>''q''</sub>[''x''] where ''q=p<sup>m</sup>''\n    '''Output''': Square-free factorization of ''f''\n    ''R'' ← 1\n    \n    # Make ''w'' be the product (without multiplicity) of all factors of ''f'' that have \n    # multiplicity not divisible by ''p''\n    ''c'' ← '''gcd'''(''f'', ''f''&prime;)\n    ''w'' ← ''f''/''c'' \n    \n    # Step 1: Identify all factors in ''w''\n    ''i''←1 \n    '''while''' ''w'' ≠ 1 '''do'''\n        ''y'' ← '''gcd'''(''w'', ''c'')\n        ''fac'' ← ''w''/''y''\n        ''R'' ← ''R''·''fac''<sup>''i''</sup>\n        ''w'' ← ''y''; ''c'' ← ''c''/''y''; ''i'' ← ''i+1'' \n    '''end while'''\n    # ''c'' is now the product (with multiplicity) of the remaining factors of ''f''\n    \n    # Step 2: Identify all remaining factors using recursion\n    # Note that these are the factors of ''f'' that have multiplicity divisible by ''p''\n    '''if''' ''c'' ≠ 1 '''then'''\n        ''c'' ← ''c''<sup>1/''p''</sup>\n        ''R'' ← ''R''·'''SFF'''(''c'')<sup>''p''</sup>\n    '''end if''' \n    \n    '''Output'''(''R'')\n \nThe idea is to identify the product of all irreducible factors of ''f'' with the same multiplicity. This is done in two steps. The first step uses the formal derivative of ''f'' to find all the factors with multiplicity not divisible by ''p''. The second step identifies the remaining factors. As all of the remaining factors have multiplicity divisible by ''p'', meaning they are powers of ''p'', one can simply take the ''p''-th square root and apply recursion. \n\n====Example of a square-free factorization====\nLet\n\n:<math> f = x^{11} + 2 x^9 + 2x^8 + x^6 + x^5 + 2x^3 + 2x^2 +1 \\in \\mathbf{F}_3[x],</math>\nto be factored over the field with three elements.\n\nThe algorithm computes first\n\n:<math> c = \\gcd(f, f') = x^9 + 2x^6 + x^3 + 2.</math>\n\nSince the derivative is non-zero we have {{math|1=''w'' = ''f''/''c'' = ''x''<sup>2</sup> + 2}} and we enter the while loop.  After one loop we have {{math|1=''y'' = ''x'' + 2}}, {{math|1=''z'' = ''x'' + 1}} and {{math|1=''R'' = ''x'' + 1}} with updates {{math|1=''i'' = 2}}, {{math|1=''w'' = ''x'' + 2}} and {{math|1=''c'' = ''x''<sup>8</sup> + ''x''<sup>7</sup> + ''x''<sup>6</sup> + ''x''<sup>2</sup>+''x''+1}}. The second time through the loop gives {{math|1=''y'' = ''x'' + 2}}, {{math|1=''z'' = 1}}, {{math|1=''R'' = ''x'' + 1}}, with updates {{math|1=''i'' = 3}}, {{math|1=''w'' = ''x'' + 2}} and {{math|1=''c'' = ''x''<sup>7</sup> + 2''x''<sup>6</sup> + ''x'' + 2}}. The third time through the loop also does not change {{math|1=''R''}}. For the fourth time through the loop we get {{math|1= ''y'' = 1}}, {{math|1=''z'' = ''x'' + 2}}, {{math|1=''R'' = (''x'' + 1)(''x'' + 2)<sup>4</sup>}}, with updates {{math|1=''i'' = 5}}, {{math|1=''w'' = 1}} and {{math|1=''c'' = ''x''<sup>6</sup> + 1}}. Since ''w'' = 1, we exit the while loop. Since ''c'' ≠ 1, it must be a perfect cube. The cube root of ''c'', obtained by replacing ''x''<sup>3</sup> by ''x'' is ''x''<sup>2</sup>&nbsp;+&nbsp;1, and calling the square-free procedure recursively determines that it is square-free. Therefore, cubing it and combining it with the value of ''R'' to that point gives the square-free decomposition\n\n:<math> f= (x+1)(x^2+1)^3(x+2)^4.</math>\n\n===Distinct-degree factorization===\nThis algorithm splits a square-free polynomial into a product of polynomials whose irreducible factors all have the same degree. Let ''f'' ∈ '''F'''<sub>''q''</sub>[''x''] of degree ''n'' be the polynomial to be factored.\n\n    '''Algorithm''' Distinct-degree factorization(DDF)\n    '''Input''': A monic square-free polynomial  ''f'' ∈ '''F'''<sub>''q''</sub>[''x'']\n    '''Output''': The set of all pairs (''g'', ''d''), such that \n              ''f'' has an irreducible factor of degree ''d'' and\n              ''g'' is the product of all monic irreducible factors of ''f'' of degree ''d''.\n    '''Begin'''\n        <math>i:=1;\\qquad S:=\\emptyset,\\qquad f^*:=f;</math>\n        '''while''' <math>\\deg f^*\\ge 2i</math> '''do''' \n            <math>g=\\gcd(f^*, x^{q^i}-x)</math>\n            '''if''' ''g'' ≠ 1, '''then''' \n              <math>S:=S\\cup{(g,i)}</math>;\n              ''f*'' := ''f*''/''g'';\n            '''end if'''\n            ''i'' := ''i''+1;\n        '''end while''';\n        '''if''' ''f*'' ≠ 1, '''then''' <math>S:= S\\cup{(f^*,\\deg f^*)}</math>;\n        '''if''' ''S'' = ∅\n            '''then return''' {(''f'', 1)}\n            '''else return''' ''S''\n     '''End'''\nThe correctness of the algorithm is based on the following:\n\n<blockquote>'''Lemma.''' For ''i'' ≥ 1 the polynomial\n\n:<math>x^{q^i}-x \\in \\mathbf{F}_q[x]</math>\n\nis the product of all monic irreducible polynomials in '''F'''<sub>''q''</sub>[''x''] whose degree divides ''i''.</blockquote>\n\nAt first glance, this is not efficient since it involves computing the GCD of polynomials of a degree which is exponential in the degree of the input polynomial. However\n\n:<math>g=\\gcd \\left (f^*, x^{q^i}-x \\right )</math>\n\nmay be replaced by\n\n:<math>g=\\gcd \\left (f^*, \\left (x^{q^i}-x \\mod f^* \\right ) \\right ).</math>\n\nTherefore, we have to compute:\n\n:<math>x^{q^i}-x \\mod f^*,</math>\n\nthere are two methods:\n\n<blockquote>'''Method I.''' Start from the value of\n\n:<math>x^{q^{i-1}}\\mod f^* </math>\n\ncomputed at the preceding step and to compute its ''q''-th power modulo the new ''f*'', using [[exponentiation by squaring]] method. This needs\n\n:<math>O \\left (\\log(q) \\deg(f)^2 \\right )</math>\n\narithmetic operations in '''F'''<sub>''q''</sub> at each step, and thus\n\n:<math>O \\left (\\log(q) \\deg(f)^3 \\right )</math>\n\narithmetic operations for the whole algorithm.</blockquote>\n\n<blockquote>'''Method II.''' Using the fact that the ''q''-th power is a linear map over '''F'''<sub>''q''</sub> we may compute its matrix with\n\n:<math>O \\left (\\deg(f)^2(\\log(q)+\\deg(f)) \\right )</math>\n\noperations. Then at each iteration of the loop, compute the product of a matrix by a vector (with ''O''(deg(''f'')<sup>2</sup>) operations). This induces a total number of operations in '''F'''<sub>''q''</sub> which is\n\n:<math>O \\left (\\deg(f)^2 (\\log(q)+\\deg(f)) \\right ).</math>\n\nThus this second method is more efficient and is usually preferred. Moreover, the matrix that is computed in this method is used, by most algorithms, for equal-degree factorization (see below); thus using it for the distinct-degree factorization saves further computing time.</blockquote>\n\n===Equal-degree factorization===\n\n====Cantor–Zassenhaus algorithm====\n{{main article|Cantor–Zassenhaus algorithm}}\nIn this section, we consider the factorization of a monic squarefree univariate polynomial ''f'', of degree ''n'', over a finite field '''F'''<sub>''q''</sub>, which has ''r'' ≥ 2 pairwise distinct irreducible factors <math> f_1,\\ldots,f_r</math> each of degree ''d''.\n\nWe first describe an algorithm by Cantor and Zassenhaus (1981) and then a variant that has a slightly better complexity. Both are probabilistic algorithms whose running time depends on random choices ([[Las Vegas algorithm]]s), and have a good average running time. In next section we describe an algorithm by Shoup (1990), which is also an equal-degree factorization algorithm, but is deterministic. All these algorithms require an odd order ''q'' for the field of coefficients. For more factorization algorithms see e.g. Knuth's book [[The Art of Computer Programming]] volume 2.\n\n     Algorithm Cantor–Zassenhaus algorithm.\n     Input: A finite field '''F'''<sub>''q''</sub> of odd order ''q''.\n            A monic square free polynomial ''f'' in '''F'''<sub>''q''</sub>[''x''] of degree ''n'' = ''rd'', \n                 which has ''r'' ≥ 2 irreducible factors each of degree ''d''\n     Output: The set of monic irreducible factors of ''f''.\n\n     Factors:={''f''};\n     while Size(Factors) < ''r'' do,\n        Choose ''h'' in '''F'''<sub>''q''</sub>[''x''] with deg(''h'') < ''n'' at random;\n        <math>g:=h^{\\frac{q^d-1}{2}}- 1 \\pmod f</math>\n        for each ''u'' in Factors with deg(''u'') > ''d'' do\n            if gcd(''g'', ''u'') ≠ 1 and gcd(''g'', ''u'') ≠ ''u'', then\n              Factors:= Factors<math>\\,\\setminus\\, \\{u\\}\\cup\\{(\\gcd(g,u),u/\\gcd(g,u))\\}</math>;\n            endif;\n     endwhile\n     return Factors.\n\nThe correctness of this algorithm relies on the fact that the ring '''F'''<sub>''q''</sub>[''x'']/''f'' is a direct product of the fields '''F'''<sub>''q''</sub>[''x'']/''f<sub>i</sub>'' where ''f<sub>i</sub>'' runs on the irreducible factors of ''f''. As all these fields have ''q<sup>d</sup>'' elements, the component of ''g'' in any of these fields is zero with probability\n\n:<math>\\frac{q^d-1}{2q^d} \\sim \\tfrac{1}{2}.</math>\n\nThis implies that the polynomial gcd(''g'', ''u'') is the product of the factors of ''g'' for which the component of ''g'' is zero.\n\nIt has been shown that the average number of iterations of the while loop of the algorithm is less than <math>2.5 \\log_2 r</math>, giving an average number of arithmetic operations in '''F'''<sub>''q''</sub> which is <math>O(dn^2\\log(r)\\log(q))</math>.<ref>{{citation|first1=Philippe|title=Automata, Languages and Programming|last1=Flajolet|first2=Jean-Marc | last2=Steayaert | booktitle = Automata, languages and programming (Aarhus, 1982)| series = Lecture Notes in Comput. Sci.|volume = 140|pages = 239–251|publisher = Springer|year=1982|doi=10.1007/BFb0012773|isbn=978-3-540-11576-2}}</ref>\n\nIn the typical case where ''d''log(''q'') > ''n'', this complexity may be reduced to\n\n:<math>O(n^2(\\log(r)\\log(q)+n))</math>\n\nby choosing ''h'' in the kernel of the linear map\n\n:<math> v \\to v^q-v \\pmod f</math>\n\nand replacing the instruction\n\n:<math>g:=h^{\\frac{q^d-1}{2}}- 1 \\pmod f</math>\n\nby\n\n:<math>g:=h^{\\frac{q-1}{2}}- 1 \\pmod f.</math>\n\nThe proof of validity is the same as above, replacing the direct product of the fields '''F'''<sub>''q''</sub>[''x'']/''f<sub>i</sub>'' by the direct product of their subfields with ''q'' elements. The complexity is decomposed in <math>O(n^2\\log(r)\\log(q))</math> for the algorithm itself, <math>O(n^2(\\log(q)+n))</math> for the computation of the matrix of the linear map (which may be already computed in the square-free factorization) and ''O''(''n''<sup>3</sup>) for computing its kernel. It may be noted that this algorithm works also if the factors have not the same degree (in this case the number ''r'' of factors, needed for stopping the while loop, is found as the dimension of the kernel). Nevertheless, the complexity is slightly better if square-free factorization is done before using this algorithm (as ''n'' may decrease with square-free factorization, this reduces the complexity of the critical steps).\n\n====Victor Shoup's algorithm====\nLike the algorithms of the preceding section, [[Victor Shoup]]'s algorithm is an equal-degree factorization algorithm.<ref>Victor Shoup, [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.9136&rep=rep1&type=pdf On the deterministic complexity of factoring polynomials over finite fields], Information Processing Letters 33:261-267, 1990</ref> Unlike them, it is a deterministic algorithm. However, it is less efficient, in practice, that the algorithms of preceding section. For Shoup's algorithm, the input is restricted to polynomials over prime fields '''F'''<sub>''p''</sub>.\n\nThe worst case [[time complexity]] of Shoup's algorithm has a factor <math>\\sqrt{p}.</math> Although exponential, this complexity is much better that previous deterministic algorithms (Berlekamp's algorithm) which have {{math|''p''}} as a factor. However, there are very few polynomials for which the computing time is exponential, and the average time complexity of the algorithm is polynomial in <math>d\\log(p),</math> where {{mvar|''d''}} is the degree of the polynomial, and {{math|''p''}} is the number of elements of the ground field.\n\nLet ''g'' = ''g''<sub>1</sub> ... ''g<sub>k</sub>'' be the desired factorization, where the ''g<sub>i</sub>'' are distinct monic irreducible polynomials of degree ''d''. Let ''n'' = deg(''g'') = ''kd''. We consider the [[ring (mathematics)|ring]] ''R'' = '''F'''<sub>''q''</sub>[''x'']/''g'' and denote also by ''x'' the image of ''x'' in ''R''. The ring ''R'' is the direct product of the fields ''R<sub>i</sub>'' = '''F'''<sub>''q''</sub>[''x'']/''g<sub>i</sub>'', and we denote by ''p<sub>i</sub>'' the natural [[homomorphism]] from the ''R'' onto ''R<sub>i</sub>''. The [[Galois group]] of ''R<sub>i</sub>'' over '''F'''<sub>''q''</sub> is cyclic of order ''d'', generated by the  [[field automorphism]] ''u'' → ''u<sup>p</sup>''. It follows that the roots of ''g<sub>i</sub>'' in ''R<sub>i</sub>'' are\n\n:<math> p_i(x), p_i(x^q), p_i \\left (x^{q^2} \\right ), p_i \\left (x^{q^{d-1}} \\right ).</math>\n\nLike in the preceding algorithm, this algorithm uses the same [[subalgebra]] ''B'' of ''R'' as the [[Berlekamp's algorithm]], sometimes called the \"Berlekamp subagebra\" and defined as\n\n:<math>\\begin{align}\nB &= \\left \\{\\alpha \\in R \\ : \\ p_1(\\alpha), \\cdots, p_k(\\alpha) \\in \\mathbf{F}_q \\right \\} \\\\\n&= \\{u\\in R \\ : \\ u^q=u\\}\n\\end{align}</math>\n\nA subset ''S'' of ''B'' is said a [[separating set]] if, for every 1&nbsp;≤&nbsp;''i''&nbsp;<&nbsp;''j''&nbsp;≤&nbsp;''k'' there exists ''s''&nbsp;∈&nbsp;''S'' such that <math>p_i(s) \\ne p_j(s)</math>. In the preceding algorithm, a separating set is constructed by choosing at random the elements of ''S''. In Shoup's algorithm, the separating set is constructed in the following way. Let ''s'' in ''R''[''Y''] be such that\n\n:<math>\\begin{align}\ns&=(Y-x) \\left (Y-x^q \\right )\\cdots \\left (Y-x^{q^{d-1}} \\right ) \\\\\n&=s_0+\\cdots+s_{d-1}Y^{d-1}+Y^d\n\\end{align}</math>\n\nThen <math>\\{s_0,\\dots ,s_{d-1}\\}</math> is a separating set because <math>p_i(s)=g_i</math> for ''i'' =1, ..., ''k'' (the two monic polynomials have the same roots). As the ''g<sub>i</sub>'' are pairwise distinct, for every pair of distinct indexes (''i'', ''j''), at least one of the coefficients ''s<sub>h</sub>'' will satisfy <math>p_i(s_h)\\ne p_j(s_h).</math>\n\nHaving a separating set, Shoup's algorithm proceeds as the last algorithm of the preceding section, simply by replacing the instruction \"choose at random ''h'' in the kernel of the linear map <math> v \\to v^q-v \\pmod f</math>\" by \"choose ''h'' + ''i'' with ''h'' in ''S'' and ''i'' in {1, ..., ''k''−1}\".\n\n==Time complexity==\nAs described in previous sections, for the factorization over finite fields, there are [[randomized algorithm]]s of polynomial [[time complexity]] (for example Cantor-Zassenhaus algorithm). There are also deterministic algorithms with a polynomial average complexity (for example Shoup's algorithm).\n\nThe existence of a deterministic algorithm with a polynomial worst-case complexity is still an open problem.\n\n==Rabin's test of irreducibility==\nLike distinct-degree factorization algorithm, Rabin's algorithm<ref>{{cite journal |last1=Rabin |first1=Michael |year=1980 |title=Probabilistic algorithms in finite fields |journal=SIAM Journal on Computing |volume=9 |issue=2 |pages=273–280 |doi=10.1137/0209024 |citeseerx=10.1.1.17.5653 }}</ref> is based on the Lemma stated above. Distinct-degree factorization algorithm tests every ''d'' not greater than half the degree of the input polynomial. Rabin's algorithm takes advantage that the factors are not needed for considering fewer ''d''. Otherwise, it is similar to distinct-degree factorization algorithm. It is based on the following fact.\n\nLet ''p''<sub>1</sub>, ..., ''p<sub>k</sub>'', be all the prime divisors of ''n'', and denote <math>n/p_i=n_i</math>, for 1 ≤ ''i'' ≤ ''k'' polynomial ''f'' in '''F'''<sub>''q''</sub>[''x''] of degree ''n'' is irreducible in '''F'''<sub>''q''</sub>[''x''] if and only if <math> \\gcd \\left (f,x^{q^{n_i}}-x \\right )=1</math>, for 1&nbsp;≤&nbsp;''i''&nbsp;≤&nbsp;''k'', and ''f'' divides <math>x^{q^n}-x</math>. In fact, if ''f'' has a factor of degree not dividing ''n'', then ''f'' does not divide <math>x^{q^n}-x</math>; if ''f'' has a factor of degree dividing ''n'', then this factor divides at least one of the <math>x^{q^{n_i}}-x.</math>\n\n  '''Algorithm''' Rabin Irreducibility Test\n  '''Input''': A monic polynomial ''f'' in '''F'''<sub>''q''</sub>[''x''] of degree ''n'', \n         ''p''<sub>1</sub>, ..., ''p<sub>k</sub>'' all distinct prime divisors of ''n''.\n  '''Output''': Either \"''f'' is irreducible\" or \"''f'' is reducible\".\n  '''Begin'''\n      '''for''' ''j'' = 1 to ''k'' '''do''' \n         <math>n_j=n/p_j</math>;\n      '''for''' ''i'' = 1 to ''k'' '''do''' \n         <math>h:=x^{q^{n_i}}-x \\bmod f</math>;\n         ''g'' := gcd(''f'', ''h'');\n         '''if''' ''g'' ≠ 1, '''then return''' 'f is reducible' '''and STOP''';\n      '''end for''';\n      <math>g:= x^{q^{n}}-x \\bmod f</math>;\n      '''if''' ''g'' = 0, '''then return''' \"f is irreducible\", \n          '''else return''' \"''f'' is reducible\"\n  '''end.'''\n\nThe basic idea of this algorithm is to compute <math> x^{q^{n_i}} \\bmod f</math> starting from the smallest <math> n_1,\\ldots,n_k</math> by repeated squaring or using the [[Finite field#Frobenius automorphisms|Frobenius automorphism]], and then to take the correspondent gcd. Using the elementary polynomial arithmetic, the computation of the matrix of the Frobenius automorphism needs <math>O(n^2 (n+\\log q))</math> operations in '''F'''<sub>''q''</sub>, the computation of\n\n:<math>x^{q^{n_i}}-x \\pmod f</math>\n\nneeds ''O''(''n''<sup>3</sup>) further operations, and the algorithm itself needs ''O''(''kn''<sup>2</sup>) operations, giving a total of <math>O(n^2 (n+\\log q))</math> operations in '''F'''<sub>''q''</sub>. Using fast arithmetic (complexity <math>O(n\\log n)</math> for multiplication and division, and <math>O(n(\\log n)^2)</math> for GCD computation), the computation of the <math>x^{q^{n_i}}-x \\bmod f</math> by repeated squaring is <math>O(n^2\\log n\\log q)</math>, and the algorithm itself is <math>O(kn(\\log n)^2)</math>, giving a total of <math>O(n^2\\log n\\log q)</math> operations in '''F'''<sub>''q''</sub>.\n\n==See also==\n* [[Berlekamp's algorithm]]\n* [[Cantor–Zassenhaus algorithm]]\n* [[Polynomial factorization]]\n\n==References==\n{{Refbegin}}\n*KEMPFERT,H (1969) [https://www.sciencedirect.com/science/article/pii/0022314X69900304/pdf?md5=c31af090ceec6b08d71eedf57d709ab0&isDTMRedir=Y&pid=1-s2.0-0022314X69900304-main.pdf&_valck=1 On the ''Factorization of Polynomials''] Department of Mathematics, The Ohio State University,Columbus,Ohio 43210\n*Shoup,Victor (1996) ''[https://www.shoup.net/papers/smooth.ps Smoothness and Factoring Polynomials over Finite Fields]'' Computer Science Department University of Toronto\n* [[Joachim von zur Gathen|Von Zur Gathen, J.]]; Panario, D. (2001). [https://dx.doi.org/10.1006/jsco.1999.1002 Factoring Polynomials Over Finite Fields: A Survey]. [[Journal of Symbolic Computation]], Volume 31, Issues 1-2, January 2001, 3--17.\n*Gao Shuhong, Panario Daniel,''Test and Construction of Irreducible Polynomials over Finite Fields'' Department of mathematical Sciences, Clemson University, South Carolina, 29634-1907, USA. and Department of computer science University of Toronto, Canada M5S-1A4\n*Shoup, Victor (1989) [https://www.ams.org/journals/mcom/1990-54-189/S0025-5718-1990-0993933-0/S0025-5718-1990-0993933-0.pdf New Algorithms for Finding Irreducible Polynomials over Finite Fields] Computer Science Department University of Wisconsin&ndash;Madison\n*[[Keith Geddes|Geddes, Keith O.]]; Czapor, Stephen R.; Labahn, George (1992). [https://dx.doi.org/10.1007/b102438 Algorithms for computer algebra]. Boston, MA: Kluwer Academic Publishers. pp. xxii+585. {{ISBN|0-7923-9259-0}}.\n{{Refend}}\n\n==External links==\n* Some irreducible polynomials http://www.math.umn.edu/~garrett/m/algebra/notes/07.pdf\n* Field and Galois Theory :http://www.jmilne.org/math/CourseNotes/FT.pdf\n* Galois Field:http://designtheory.org/library/encyc/topics/gf.pdf\n* Factoring polynomials over finite fields: http://www.science.unitn.it/~degraaf/compalg/polfact.pdf\n\n==Notes==\n{{Reflist}}\n\n[[Category:Polynomials]]\n[[Category:Algebra]]\n[[Category:Computer algebra]]\n[[Category:Coding theory]]\n[[Category:Cryptography]]\n[[Category:Computational number theory]]"
    },
    {
      "title": "Field arithmetic",
      "url": "https://en.wikipedia.org/wiki/Field_arithmetic",
      "text": "In [[mathematics]], '''field arithmetic''' is a subject that studies the interrelations between arithmetic properties of a {{ql|field_(mathematics)|field}} and its [[absolute Galois group]].\nIt is an interdisciplinary subject as it uses tools from [[algebraic number theory]], [[arithmetic geometry]], [[algebraic geometry]], [[model theory]], the theory of [[finite groups]] and of [[profinite groups]].\n\n==Fields with finite absolute Galois groups==\nLet ''K'' be a field and let ''G'' = Gal(''K'') be its absolute Galois group. If ''K'' is [[algebraically closed]], then ''G'' = 1. If ''K'' = '''R''' is the real numbers, then\n\n:<math>G=\\operatorname{Gal}(\\mathbf{C}/\\mathbf{R})=\\mathbf{Z}/2 \\mathbf{Z}.</math>\n\nHere '''C''' is the field of complex numbers and '''Z''' is the ring of integer numbers. \nA [[Artin–Schreier theorem|theorem of Artin and Schreier]] asserts that (essentially) these are all the possibilities for finite absolute Galois groups.\n\n'''Artin–Schreier theorem.''' Let ''K'' be a field whose absolute Galois group ''G'' is finite. Then either ''K'' is separably closed and ''G'' is trivial or ''K'' is [[real closed]] and ''G'' = '''Z'''/2'''Z'''.\n\n==Fields that are defined by their absolute Galois groups==\nSome profinite groups occur as the absolute Galois group of non-isomorphic fields.  A first example for this is\n\n:<math>\\hat{\\mathbf{Z}}=\\lim_{\\longleftarrow}\\mathbf{Z}/n \\mathbf{Z}.</math>\n\nThis group is isomorphic to the absolute Galois group of an arbitrary [[finite field]]. Also the absolute Galois group of the field of [[formal Laurent series]] '''C'''((''t'')) over the complex numbers is isomorphic to that group.\n\nTo get another example, we bring below two non-isomorphic fields whose absolute Galois groups are free (that is [[free profinite group]]).\n\n* Let ''C'' be an [[algebraically closed]] field and ''x'' a variable.  Then Gal(''C''(''x'')) is free of rank equal to the cardinality of ''C''. (This result is due to [[Adrien Douady]] for 0 characteristic and has its origins in [[Riemann's existence theorem]]. For a field of arbitrary characteristic it is due to [[David Harbater]] and [[Florian Pop]], and was also proved later by [[Dan Haran]] and [[Moshe Jarden]].)\n* The absolute Galois group Gal('''Q''') (where '''Q''' are the rational numbers) is compact, and hence equipped with a normalized [[Haar measure]]. For a Galois automorphism ''s'' (that is an element in Gal('''Q''')) let ''N<sub>s</sub>'' be the maximal Galois extension of '' '''Q''' '' that ''s'' fixes. Then with probability 1 the absolute Galois group Gal(''N''<sub>''s''</sub>) is free of countable rank. (This result is due to [[Moshe Jarden]].)\n\nIn contrast to the above examples, if the fields in question are finitely generated over '''''Q''''', [[Florian Pop]] proves that an isomorphism of the absolute Galois groups yields an isomorphism of the fields:\n\n'''Theorem.''' Let ''K'', ''L'' be finitely generated fields over '''''Q''''' and let ''a'':&nbsp;Gal(''K'')&nbsp;→&nbsp;Gal(''L'') be an isomorphism. Then there exists a unique isomorphism of the algebraic closures, ''b'': ''K''<sub>alg</sub>&nbsp;→&nbsp;''L''<sub>alg</sub>, that induces  ''a''.\n\nThis generalizes an earlier work of [[Jürgen Neukirch]] and [[Koji Uchida]] on number fields.\n\n==Pseudo algebraically closed fields==\n{{Main|Pseudo algebraically closed field}}\n\nA [[pseudo algebraically closed field]] (in short PAC) ''K'' is a field satisfying the following geometric property. Each [[absolutely irreducible]] algebraic variety ''V'' defined over ''K'' has a ''K''-[[rational point]].\n\nOver PAC fields there is a firm link between arithmetic properties of the field and group theoretic properties of its absolute Galois group. A nice theorem in this spirit connects [[Hilbertian field]]s with ω-free fields (''K'' is ω-free if any [[embedding problem]] for ''K'' is properly solvable).\n\n'''Theorem.''' Let ''K'' be a PAC field. Then ''K'' is Hilbertian if and only if ''K'' is ω-free.\n\n[[Peter Roquette]] proved the right-to-left direction of this theorem and conjectured the opposite direction. [[Michael Fried (mathematician)|Michael Fried]] and [[Helmut Völklein]] applied algebraic topology and complex analysis to establish Roquette's conjecture in characteristic zero. Later Pop \nproved the Theorem for arbitrary characteristic by developing \"[[rigid patching]]\".\n\n==References==\n{{reflist}}\n* {{cite book | last1=Fried | first1=Michael D. | last2=Jarden | first2=Moshe | title=Field arithmetic | edition=2nd revised and enlarged | series=Ergebnisse der Mathematik und ihrer Grenzgebiete. 3. Folge | volume=11 | publisher=[[Springer-Verlag]] | year=2004 | isbn=3-540-22811-X | zbl=1055.12003 }}\n*{{Neukirch et al. CNF}}\n\n[[Category:Algebra]]\n[[Category:Galois theory]]"
    },
    {
      "title": "Filtration (mathematics)",
      "url": "https://en.wikipedia.org/wiki/Filtration_%28mathematics%29",
      "text": "In [[mathematics]], a '''filtration''' <math>\\mathcal{F}</math>  is an [[indexed set]] <math>S_i</math> of [[subobject|subobjects]] of a given [[algebraic structure]] <math>S</math>, with the index <math>i</math> running over some [[index set]] <math>I</math> that is a [[totally ordered set]], subject to the condition that\n\n::if <math>i\\leq j</math> in <math>I</math>, then <math>S_i\\subset S_j</math>.\n\nIf the index <math>i</math> is the time parameter of some stochastic process, then the filtration can be interpreted as representing all historical but not future information available about the stochastic process, with the algebraic object <math>S_i</math> gaining in complexity with time. Hence, a process that is [[adapted process|adapted]] to a filtration <math>\\mathcal{F}</math>, is also called '''non-anticipating''', i.e. one that cannot '''see into the future'''.<ref>{{cite book|last=Björk|first=Thomas|year=2005|title=Arbitrage Theory in Continuous Time|isbn=978-0-19-927126-9|section=Appendix B}}</ref>\n\nSometimes, as in a [[filtered algebra]], there is instead the requirement that the <math>S_i</math> be [[Subalgebra#Subalgebras in universal algebra|subalgebras]] with respect to some operations (say, vector addition), but not with respect to other operations (say, multiplication), that satisfy <math>S_i \\cdot S_j \\subset S_{i+j}</math>, where the index set is the natural numbers; this is by analogy with a [[graded algebra]].\n\nSometimes, filtrations are supposed to satisfy the additional requirement that the union of the <math>S_i</math> be the whole <math>S</math>, or (in more general cases, when the notion of union does not make sense) that the canonical homomorphism from the direct limit of the <math>S_i</math> to <math>S</math> is an isomorphism. Whether this requirement is assumed or not usually depends on the author of the text and is often explicitly stated. This article does ''not'' impose this requirement.\n\nThere is also the notion of a '''descending filtration''', which is required to satisfy <math>S_i \\supseteq S_j</math> in lieu of <math>S_i \\subseteq S_j</math> (and, occasionally, <math>\\bigcap_{i\\in I} S_i=0</math> instead of <math>\\bigcup_{i\\in I} S_i=S</math>). Again, it depends on the context how exactly the word \"filtration\" is to be understood. Descending filtrations are not to be confused with cofiltrations (which consist of [[quotient object|quotient objects]] rather than subobjects).\n\nThe concept [[Dual (category theory)|dual]] to a filtration is called a ''cofiltration''.\n\nFiltrations are widely used in [[abstract algebra]], [[homological algebra]] (where they are related in an important way to [[spectral sequence]]s), and in [[measure theory]] and [[probability theory]] for nested sequences of [[sigma algebra|σ-algebras]]. In [[functional analysis]] and [[numerical analysis]], other terminology is usually used, such as [[scale of spaces]] or [[nested spaces]].\n\n==Examples==\n\n===Algebra===\n{{See also|Filtered algebra}}\n\n====Groups====\n{{See also|Length function}}\n\nIn algebra, filtrations are ordinarily indexed by <math>\\mathbb{N}</math>, the set of natural numbers. A ''filtration'' of a group <math>G</math>, is then a nested sequence <math>G_n</math> of [[normal subgroup]]s of <math>G</math> (that is, for any <math>n</math> we have <math>G_{n+1}\\subset G_n</math>). Note that this use of the word \"filtration\" corresponds to our \"descending filtration\".\n\nGiven a group <math>G</math> and a filtration <math>G_n</math>, there is a natural way to define a topology on <math>G</math>, said to be ''associated'' to the filtration. A basis for this topology is the set of all translates of subgroups appearing in the filtration, that is, a subset of <math>G</math> is defined to be open if it is a union of sets of the form <math>aG_n</math>, where <math>a\\in G</math> and <math>n</math> is a natural number.\n\nThe topology associated to a filtration on a group <math>G</math> makes <math>G</math> into a [[topological group]].\n\nThe topology associated to a filtration <math>G_n</math> on a group <math>G</math> is [[Hausdorff space|Hausdorff]] if and only if <math>\\bigcap G_n=\\{1\\}</math>.\n\nIf two filtrations <math>G_n</math> and <math>G'_n</math> are defined on a group <math>G</math>, then the identity map from <math>G</math> to <math>G</math>, where the first copy of <math>G</math> is given the <math>G_n</math>-topology and the second the <math>G'_n</math>-topology, is continuous if and only if for any <math>n</math> there is an <math>m</math> such that <math>G_m\\subset G'_n</math>, that is, if and only if the identity map is continuous at 1. In particular, the two filtrations define the same topology if and only if for any subgroup appearing in one there is a smaller or equal one appearing in the other.\n\n====Rings and modules: descending filtrations====\n\nGiven a ring <math>R</math> and an <math>R</math>-module <math>M</math>, a ''descending filtration'' of <math>M</math> is a decreasing sequence of submodules <math>M_n</math>. This is therefore a special case of the notion for groups, with the additional condition that the subgroups be submodules. The associated topology is defined as for groups.\n\nAn important special case is known as the <math>I</math>-adic topology (or <math>J</math>-adic, etc.). Let <math>R</math> be a commutative ring, and <math>I</math> an ideal of <math>R</math>.\n\nGiven an <math>R</math>-module <math>M</math>, the sequence <math>I^n M</math> of submodules of <math>M</math> forms a filtration of <math>M</math>. The ''<math>I</math>-adic topology'' on <math>M</math> is then the topology associated to this filtration. If <math>M</math> is just the ring <math>R</math> itself, we have defined the ''<math>I</math>-adic topology'' on <math>R</math>.\n\nWhen <math>R</math> is given the <math>I</math>-adic topology, <math>R</math> becomes a [[topological ring]]. If an <math>R</math>-module <math>M</math> is then given the <math>I</math>-adic topology, it becomes a [[topological module|topological <math>R</math>-module]], relative to the topology given on <math>R</math>.\n\n====Rings and modules: ascending filtrations====\n\nGiven a ring <math>R</math> and an <math>R</math>-module <math>M</math>, an ''ascending filtration'' of <math>M</math> is an increasing sequence of submodules <math>M_n</math>. In particular, if <math>R</math> is a field, then an ascending filtration of the <math>R</math>-vector space <math>M</math> is an increasing sequence of vector subspaces of <math>M</math>. [[Flag (linear algebra)|Flags]] are one important class of such filtrations.\n\n====Sets====\nA maximal filtration of a set is equivalent to an ordering (a [[permutation]]) of the set. For instance, the filtration <math>\\{0\\} \\subset \\{0,1\\} \\subset \\{0,1,2\\}</math> corresponds to the ordering <math>(0,1,2)</math>. From the point of view of the [[field with one element]], an ordering on a set corresponds to a maximal [[Flag (linear algebra)|flag]] (a filtration on a vector space), considering a set to be a vector space over the field with one element.\n\n===Measure theory===\n{{main article|Filtration (probability theory)}}\nIn [[measure theory]], in particular in [[martingale theory]] and the theory of [[stochastic process]]es, a filtration is an increasing [[sequence (mathematics)|sequence]] of [[sigma algebra|<math>\\sigma</math>-algebras]] on a [[measurable space]]. That is, given a measurable space <math>(\\Omega, \\mathcal{F})</math>, a filtration is a sequence of <math>\\sigma</math>-algebras <math>\\{ \\mathcal{F}_{t} \\}_{t \\geq 0}</math> with <math>\\mathcal{F}_{t} \\subseteq \\mathcal{F}</math> where each <math>t</math> is a non-negative real number and\n\n:<math>t_{1} \\leq t_{2} \\implies \\mathcal{F}_{t_{1}} \\subseteq \\mathcal{F}_{t_{2}}.</math>\n\nThe exact range of the \"times\" ''<math>t</math>'' will usually depend on context: the set of values for <math>t</math> might be [[discrete set|discrete]] or continuous, [[bounded set|bounded]] or unbounded. For example,\n\n:<math>t \\in \\{ 0, 1, \\dots, N \\}, \\mathbb{N}_{0}, [0, T] \\mbox{ or } [0, + \\infty).</math>\n\nSimilarly, a '''filtered probability space''' (also known as a '''stochastic basis''') <math>\\left(\\Omega, \\mathcal{F}, \\left\\{\\mathcal{F}_{t}\\right\\}_{t\\geq 0}, \\mathbb{P}\\right)</math>, is a [[probability space]] equipped with the filtration <math>\\left\\{\\mathcal{F}_t\\right\\}_{t\\geq 0}</math> of its <math>\\sigma</math>-algebra <math>\\mathcal{F}</math>. A filtered probability space is said to satisfy the ''usual conditions'' if it is [[complete measure|complete]] (i.e., <math>\\mathcal{F}_0</math> contains all <math>\\mathbb{P}</math>-[[null set]]s) and [[right-continuous]] (i.e. <math>\\mathcal{F}_t = \\mathcal{F}_{t+} := \\bigcap_{s > t} \\mathcal{F}_s</math> for all times <math>t</math>).<ref>{{cite web|title=Stochastic Processes: A very simple introduction|author=Péter Medvegyev|date=January 2009|url=http://medvegyev.uni-corvinus.hu/St1.pdf|accessdate=June 25, 2012}}</ref><ref>{{cite book|title=Probabilities and Potential|author=Claude Dellacherie|publisher=Elsevier|year=1979|isbn=9780720407013}}</ref><ref>{{cite web|title=Filtrations and Adapted Processes|author=George Lowther|url=http://almostsure.wordpress.com/2009/11/08/filtrations-and-adapted-processes/|date=November 8, 2009|accessdate=June 25, 2012}}</ref>\n\nIt is also useful (in the case of an unbounded index set) to define <math>\\mathcal{F}_{\\infty}</math> as the <math>\\sigma</math>-algebra generated by the infinite union of the <math>\\mathcal{F}_{t}</math>'s, which is contained in <math>\\mathcal{F}</math>:\n\n:<math>\\mathcal{F}_{\\infty} = \\sigma\\left(\\bigcup_{t \\geq 0} \\mathcal{F}_{t}\\right) \\subseteq \\mathcal{F}.</math>\n\nA ''σ''-algebra defines the set of events that can be measured, which in a [[probability]] context is equivalent to events that can be discriminated, or \"questions that can be answered at time <math>t</math>\". Therefore, a filtration is often used to represent the change in the set of events that can be measured, through gain or loss of [[information]]. A typical example is in [[mathematical finance]], where a filtration represents the information available up to and including each time <math>t</math>, and is more and more precise (the set of measurable events is staying the same or increasing) as more information from the evolution of the stock price becomes available.\n\n====Relation to stopping times: stopping time sigma-algebras====\n{{main article|Σ-Algebra of τ-past}}\nLet <math>\\left(\\Omega, \\mathcal{F}, \\left\\{\\mathcal{F}_{t}\\right\\}_{t\\geq 0}, \\mathbb{P}\\right)</math> be a filtered probability space. A random variable <math>\\tau : \\Omega \\rightarrow [0, \\infty]</math> is a [[stopping time]] with respect to the [[#Measure theory|filtration]] <math>\\left\\{\\mathcal{F}_{t}\\right\\}_{t\\geq 0}</math>, if <math>\\{\\tau \\leq t\\} \\in \\mathcal{F}_t</math> for all <math>t\\geq 0</math>. \nThe ''stopping time'' <math>\\sigma</math>-algebra is now defined as\n:<math>\\mathcal{F}_{\\tau} := \\left\\{A\\in\\mathcal{F}:A\\cap\\{\\tau \\leq t\\}\\in\\mathcal{F}_t, \\ \\forall t\\geq 0\\right\\} </math>.\n\nIt is not difficult to show that <math>\\mathcal{F}_{\\tau}</math> is indeed a [[sigma-algebra|<math>\\sigma</math>-algebra]].\nThe set <math>\\mathcal{F}_{\\tau}</math> encodes information up to the ''random'' time <math>\\tau</math> in the sense that, if the filtered probability space is interpreted as a random experiment, the maximum information that can be found out about it from arbitrarily often repeating the experiment until the random time <math>\\tau</math> is <math>\\mathcal{F}_{\\tau}</math>.<ref name=\"Fischer (2013)\">{{cite journal|last=Fischer|first=Tom|title=On simple representations of stopping times and stopping time sigma-algebras|journal=Statistics and Probability Letters|year=2013|volume=83|issue=1|pages=345–349|doi=10.1016/j.spl.2012.09.024|arxiv=1112.1603}}</ref> In particular, if the underlying probability space is finite (i.e. <math>\\mathcal{F}</math> is finite), the minimal sets of <math>\\mathcal{F}_{\\tau}</math> (with respect to set inclusion) are given by the union over all <math>t\\geq 0</math> of the sets of minimal sets of <math>\\mathcal{F}_{t}</math> that lie in <math>\\{\\tau = t\\} </math>.<ref name=\"Fischer (2013)\"/>\n\nIt can be shown that <math>\\tau</math> is <math>\\mathcal{F}_{\\tau}</math>-measurable. However, simple examples<ref name=\"Fischer (2013)\"/> show that, in general, <math>\\sigma(\\tau) \\neq \\mathcal{F}_{\\tau}</math>. If <math>\\tau_ 1</math> and <math>\\tau_ 2</math> are [[stopping time]]s on <math>\\left(\\Omega, \\mathcal{F}, \\left\\{\\mathcal{F}_{t}\\right\\}_{t\\geq 0}, \\mathbb{P}\\right)</math>, and <math>\\tau_1 \\leq \\tau_2</math> [[almost surely]], then <math>\\mathcal{F}_{\\tau_1} \\subseteq \\mathcal{F}_{\\tau_2}.</math>\n\n==See also==\n*[[Natural filtration]]\n\n==References==\n{{Reflist}}\n* {{cite book | author=Øksendal, Bernt K. | authorlink=Bernt Øksendal | title=Stochastic Differential Equations: An Introduction with Applications | publisher=Springer| location=Berlin | year=2003 | isbn=978-3-540-04758-2}}\n\n[[Category:Algebra]]\n[[Category:Measure theory]]\n[[Category:Stochastic processes]]"
    },
    {
      "title": "Free presentation",
      "url": "https://en.wikipedia.org/wiki/Free_presentation",
      "text": "In algebra, a '''free presentation''' of a module ''M'' over a commutative ring ''R'' is an exact sequence of ''R''-modules:\n\n:<math>\\bigoplus_{i \\in I} R \\overset{f} \\to \\bigoplus_{j \\in J} R \\overset{g}\\to M \\to 0.</math>\n\nNote the image under ''g'' of the standard basis [[generating set of a module|generates ''M'']]. In particular, if ''J'' is finite, then ''M'' is a [[finitely generated module]]. If ''I'' and ''J'' are finite sets, then the presentation is called a '''finite presentation'''; a module is called [[finitely presented module|finitely presented]] if it admits a finite presentation.\n\nSince ''f'' is a [[module homomorphism]] between free modules, it can be visualized as an (infinite) matrix with entries in ''R'' and ''M'' as its cokernel.\n\nA free presentation always exists: any module is a quotient of a free module: <math>F \\overset{g}\\to M \\to 0</math>, but then the kernel of ''g'' is again a quotient of a free module: <math>F' \\overset{f} \\to \\ker g \\to 0</math>. The combination of ''f'' and ''g'' is a free presentation of ''M''. Now, one can obviously keep \"resolving\" the kernels in this fashion; the result is called a [[free resolution]]. Thus, a free presentation is the early part of the free resolution.\n\nA presentation is useful for computation. For example, since [[tensor product of modules|tensoring]] is right-exact, tensoring the above presentation with a module, say, ''N'' gives:\n\n: <math>\\bigoplus_{i \\in I} N \\overset{f \\otimes 1} \\to \\bigoplus_{j \\in J} N \\to M \\otimes_R N \\to 0.</math>\n\nThis says that <math>M \\otimes_R N</math> is the cokernel of <math>f \\otimes 1</math>. If ''N'' is an ''R''-algebra, then this is the presentation of the ''N''-module <math>M \\otimes_R N</math>; that is, the presentation extends under base extension.\n\nFor left-exact functors, there is for example\n{{math_theorem|name=Proposition|Let ''F'', ''G'' be left-exact contravariant functors from the category of modules over a commutative ring ''R'' to abelian groups and θ a [[natural transformation]] from ''F'' to ''G''. If <math>\\theta: F(R^{\\oplus n}) \\to G(R^{\\oplus n})</math> is an isomorphism for each natural number ''n'', then <math>\\theta: F(M) \\to G(M)</math> is an isomorphism for any finitely-presented module ''M''.}}\nProof: Applying ''F'' to a finite presentation <math>R^{\\oplus n} \\to R^{\\oplus m} \\to M</math> results in\n:<math>0 \\to F(M) \\to F(R^{\\oplus m}) \\to F(R^{\\oplus n})</math>\nand the same for ''G''. Now apply the [[snake lemma]]. <math>\\square</math>\n\n== See also ==\n*[[Coherent module]]\n*[[Finitely-related module]]\n*[[Fitting ideal]]\n*[[Quasi-coherent sheaf]]\n\n== References ==\n* [[David Eisenbud|Eisenbud, David]], ''Commutative Algebra with a View Toward Algebraic Geometry'', Graduate Texts in Mathematics, 150, Springer-Verlag, 1995, {{ISBN|0-387-94268-8}}.\n\n\n{{algebra-stub}}\n\n\n\n[[Category:Algebra]]"
    },
    {
      "title": "Free product of associative algebras",
      "url": "https://en.wikipedia.org/wiki/Free_product_of_associative_algebras",
      "text": "In algebra, the '''free product''' ('''[[coproduct]]''') of a family of [[associative algebra]]s <math>A_i, i \\in I</math> over a commutative ring ''R'' is the associative algebra over ''R'' that is, roughly, defined by the generators and the relations of the <math>A_i</math>'s. The free product of two algebras ''A'', ''B'' is denoted by ''A'' * ''B''. The notion is a ring-theoretic analog of a [[free product]] of groups.\n\nIn the [[category of commutative algebras|category of commutative ''R''-algebras]], the free product of two algebras (in that category) is their [[tensor product of algebras|tensor product]].\n\n== Construction ==\n{{expand section|date=March 2019}}\nWe first define a free product of two algebras. Let ''A'', ''B'' be two algebras over a commutative ring ''R''. Consider their [[tensor algebra]], the direct sum of all possible finite tensor products of ''A'', ''B''; explicitly, <math>T = \\bigoplus_{n=0}^{\\infty} T_n</math> where\n:<math>T_0 = R, \\, T_1 = A \\oplus B, \\, T_2 = (A \\otimes A) \\oplus (A \\otimes B) \\oplus (B \\otimes A) \\oplus (B \\otimes B), \\, T_3 = \\cdots, \\dots</math>\n\nWe then set\n:<math>A * B = T/I</math>\nwhere ''I'' is the two-sided ideal generated by elements of the form\n:<math>a \\otimes a' - a a', \\, b \\otimes b' - bb', \\, 1_A - 1_B.</math>\n\nWe then verify the universal property of [[coproduct]] holds for this (this is straightforward but we should give details.)\n\n== References ==\n*Beidar, Martindale and Mikhalev, ''Rings with generalized identities,'' Section 1.4. This reference was mentioned in https://math.stackexchange.com/questions/143098/coproduct-in-the-category-of-noncommutative-associative-algebras\n\n== External links ==\n*https://math.stackexchange.com/questions/625874/how-to-construct-the-coproduct-of-two-non-commutative-rings\n\n\n{{algebra-stub}}\n\n\n\n[[Category:Algebra]]"
    },
    {
      "title": "Freshman's dream",
      "url": "https://en.wikipedia.org/wiki/Freshman%27s_dream",
      "text": "[[File:Freshman's Dream.svg|right|thumbnail|An illustration of the Freshman's dream in two dimensions. Each side of the square is X+Y in length. The area of the square is the sum of the area of the yellow region (=X<sup>2</sup>), the area of the green region (=Y<sup>2</sup>), and the area of the two white regions (=2×X×Y).]]\n\nThe '''freshman's dream''' is a name sometimes given to the erroneous equation (''x''&nbsp;+&nbsp;''y'')<sup>''n''</sup>&nbsp;=&nbsp;''x''<sup>''n''</sup>&nbsp;+&nbsp;''y''<sup>''n''</sup>, where ''n'' is a real number (usually a positive integer greater than 1). Beginning students commonly make this error in computing the [[exponentiation|power]] of a sum of real numbers, falsely assuming powers [[distributive law|distribute]] over sums.<ref>Julio R. Bastida, ''Field Extensions and Galois Theory'', Addison-Wesley Publishing Company, 1984, p.8.</ref><ref>Fraleigh, John B., ''A First Course in Abstract Algebra'', Addison-Wesley Publishing Company, 1993, p.453, {{ISBN|0-201-53467-3}}.</ref> When ''n'' = 2, it is easy to see why this is incorrect: (''x''&nbsp;+&nbsp;''y'')<sup>2</sup> can be correctly computed  as ''x''<sup>2</sup>&nbsp;+&nbsp;2''xy''&nbsp;+&nbsp;''y''<sup>2</sup> using [[distributivity]] (commonly known as the [[FOIL method]]). For larger positive integer values of ''n'', the correct result is given by the [[binomial theorem]].\n\nThe name \"freshman's dream\" also sometimes refers to the theorem that says that for a [[prime number]] ''p'', if ''x'' and ''y'' are members of a [[commutative ring]] of [[characteristic (algebra)|characteristic]] ''p'', then \n(''x''&nbsp;+&nbsp;''y'')<sup>''p''</sup>&nbsp;=&nbsp;''x''<sup>''p''</sup>&nbsp;+&nbsp;''y''<sup>''p''</sup>. In this more exotic type of arithmetic, the \"mistake\" actually gives the correct result, since ''p'' divides all the [[binomial coefficient]]s save the first and the last, making all intermediate terms equal to zero.\n\nThe identity is actually true in the context of [[Tropical geometry]], where multiplication is replaced with addition, and addition is replaced with [[Minimum (mathematics)|minimum]]<ref>{{Citation|last=Difusión DM|title=Introduction to Tropical Algebraic Geometry (1 of 5)|date=2018-02-23|url=https://www.youtube.com/watch?v=unjVp6HQVmc|access-date=2019-06-11}}</ref>.\n\n==Examples==\n*<math>(1+4)^2 = 5^2 = 25</math>, but <math>1^2+4^2 = 17</math>. \n*<math>\\sqrt{x^2+y^2}</math> does not generally equal <math>\\sqrt{x^2}+\\sqrt{y^2}=|x|+|y|</math>. For example, <math>\\sqrt{9+16}=\\sqrt{25}=5</math>, which does not equal {{nowrap|1=3 + 4 = 7}}. In this example, the error is being committed with the exponent {{nowrap|1=''n'' = {{sfrac|1|2}}}}.\n\n==Prime characteristic==\n\nWhen ''p'' is a prime number and ''x'' and ''y'' are members of a [[commutative ring]] of [[characteristic (algebra)|characteristic]] ''p'', then {{nowrap|1=(''x'' + ''y'')<sup>''p''</sup> = ''x''<sup>''p''</sup> + ''y''<sup>''p''</sup>}}. This can be seen by examining the prime factors of the binomial coefficients: the ''n''th binomial coefficient is\n\n:<math>\\binom{p}{n} = \\frac{p!}{n!(p-n)!}.</math>\n\nThe [[numerator]] is ''p'' [[factorial]], which is divisible by ''p''. However, when {{nowrap|0 < ''n'' < ''p''}}, neither ''n''! nor {{nowrap|(''p'' &minus; ''n'')!}} is divisible by ''p'' since all the terms are less than ''p'' and ''p'' is prime. Since a binomial coefficient is always an integer, the ''n''th binomial coefficient is divisible by ''p'' and hence equal to 0 in the ring. We are left with the zeroth and ''p''th coefficients, which both equal 1, yielding the desired equation.\n\nThus in characteristic ''p'' the freshman's dream is a valid identity. This result demonstrates that exponentiation by ''p'' produces an [[endomorphism]], known as the [[Frobenius endomorphism]] of the ring.\n\nThe demand that the characteristic ''p'' be a prime number is central to the truth of the freshman's dream. A related theorem states that if a number ''n'' is prime then {{nowrap|(''x'' + 1)<sup>''n''</sup> ≡ ''x<sup>n</sup>'' + 1 (mod ''n'')}} in the [[polynomial ring]] <math>\\mathbb{Z}_n[x]</math>. This theorem is a direct consequence of [[Fermat's little theorem]] and it is a key fact in modern primality testing.<ref name=Granville>A. Granville, ''[http://www.ams.org/bull/2005-42-01/S0273-0979-04-01037-7/S0273-0979-04-01037-7.pdf It Is Easy To Determine Whether A Given Integer Is Prime]'', Bull. of the AMS, Volume 42, Number 1 (Sep. 2004), Pages 3–38.</ref>\n\n==History and alternate names==\nThe history of the term \"freshman's dream\" is somewhat unclear. In a 1940 article on [[modular field]]s, [[Saunders Mac Lane]] quotes [[Stephen Cole Kleene|Stephen Kleene]]'s remark that a knowledge of {{nowrap|1=(''a'' + ''b'')<sup>2</sup> = ''a''<sup>2</sup> + ''b''<sup>2</sup>}} in a [[field (mathematics)|field]] of characteristic 2 would corrupt freshman students of [[abstract algebra|algebra]]. This may be the first connection between \"freshman\" and binomial expansion in fields of positive characteristic.<ref>Colin R. Fletcher, Review of ''Selected papers on algebra, edited by [[Susan Montgomery]], Elizabeth W. Ralston and others. Pp xv, 537. 1977. {{ISBN|0-88385-203-9}} (Mathematical Association of America)'', ''The Mathematical Gazette'', Vol. 62, No. 421 (Oct., 1978), The Mathematical Association. p. 221.</ref> Since then, authors of undergraduate algebra texts took note of the common error. The first actual attestation of the phrase \"freshman's dream\" seems to be in [[Thomas W. Hungerford|Hungerford's]] graduate algebra textbook (1974), where he quotes McBrien.<ref>Thomas W. Hungerford, ''Algebra,'' Springer, 1974, p. 121; also in ''Abstract Algebra: An Introduction'', 2nd edition. Brooks Cole, July 12, 1996, p. 366.</ref> Alternative terms include \"'''freshman exponentiation'''\", used in Fraleigh (1998).<ref>John B. Fraleigh, ''A First Course In Abstract Algebra'', 6th edition, Addison-Wesley, 1998. pp. 262 and 438.</ref> The term \"freshman's dream\" itself, in non-mathematical contexts, is recorded since the 19th century.<ref>[http://www.google.com/search?tbo=p&tbm=bks&q=%22freshman%27s+dream%22&tbs=,cdr:1,cd_min:Jan%201_2%201800,cd_max:Dec%2031_2%201900&num=10 Google books 1800–1900 search for \"freshman's dream\"]: [https://books.google.com/books?id=3XNHAAAAYAAJ&pg=PA176&dq=%22freshman%27s+dream%22 Bentley's miscellany, Volume 26, p. 176], 1849</ref>\n\nSince the expansion of {{nowrap|1=(''x'' + ''y'')<sup>''n''</sup>}} is correctly given by the [[binomial theorem]], the freshman's dream is also known as the \"'''child's binomial theorem'''\"<ref name=Granville/> or \"'''schoolboy binomial theorem'''\".\n\n==See also==\n*[[Primality test]]\n*[[Sophomore's dream]]\n*[[Frobenius endomorphism]]\n\n==References==\n{{reflist|2}}\n\n[[Category:Algebra]]\n[[Category:Mathematics education]]"
    },
    {
      "title": "Gelfand–Kirillov dimension",
      "url": "https://en.wikipedia.org/wiki/Gelfand%E2%80%93Kirillov_dimension",
      "text": "In [[algebra]], the '''Gelfand–Kirillov dimension''' (or '''GK dimension''') of a [[right module]] ''M'' over a [[K-algebra|''k''-algebra]] ''A'' is:\n\n:<math>\\operatorname{GKdim} = \\sup_{V, M_0} \\limsup_{n \\to \\infty} \\log_n \\dim_k M_0 V^n</math>\n\nwhere the sup is taken over all finite-dimensional [[Linear subspace|subspace]]s <math>V \\subset A</math> and <math>M_0 \\subset M</math>.\n\nAn algebra is said to have polynomial growth if its Gelfand–Kirillov dimension is finite.\n\n== Basic facts ==\n*The Gelfand–Kirillov dimension of a finitely generated commutative algebra ''A'' over a field is the [[Krull dimension]] of ''A'' (or equivalently the transcendence degree of the field of fractions of ''A'' over the base field.)\n*In particular, the GK dimension of the polynomial ring <math>k[x_1, \\dots, x_n]</math> Is ''n''.\n*(Warfield) For any real number ''r ''≥ 2, there exists a finitely generated algebra whose GK dimension is ''r''.<ref>{{harvnb|Artin|1999|loc=Theorem VI.2.1.}}</ref>\n\n== In the theory of D-Modules ==\n\nGiven a right module ''M'' over the [[Weyl algebra]] <math>A_n</math>, the Gelfand–Kirillov dimension of ''M'' over the Weyl algebra coincides with the dimension of ''M'', which is by definition the degree of the [[Hilbert polynomial]] of ''M''. This enables to prove additivity in [[short exact sequence]]s for the Gelfand–Kirillov dimension and finally to prove [[Weyl algebra#Properties of the Weyl algebra|Bernstein's inequality]], which states that the dimension of ''M'' must be at least ''n''. This leads to the definition of [[D-module|holonomic D-Module]]s as those with the minimal dimension ''n'', and these modules play a great role in the [[geometric Langlands program]].\n\n== References ==\n{{Reflist}}\n*{{cite journal|title=A remark on Gelfand–Kirillov dimension|url=http://www.math.washington.edu/~smith/Research/GK-rmk.pdf |last1=Smith |first1=S. Paul |last2=Zhang |first2=James J. |year=1998 |journal=[[Proceedings of the American Mathematical Society]] |volume=126 |number=2 |pages=349–352 | doi = 10.1090/S0002-9939-98-04074-X }}\n* Coutinho: A primer of algebraic D-modules. Cambridge, 1995\n\n==Further reading==\n*{{cite web|last=Artin|first=Michael|authorlink=Michael Artin|title=Noncommutative Rings|url=http://math.mit.edu/~etingof/artinnotes.pdf|year=1999|location=Chapter VI}}\n\n{{DEFAULTSORT:Gelfand-Kirillov dimension}}\n[[Category:Algebra]]\n[[Category:Dimension]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Generalized arithmetic progression",
      "url": "https://en.wikipedia.org/wiki/Generalized_arithmetic_progression",
      "text": "{{Cleanup rewrite|date=May 2009}}\n\nIn [[mathematics]], a '''multiple arithmetic progression''', '''generalized arithmetic progression''', ''k''-'''dimensional arithmetic progression''' or a '''linear set''', is a set of [[integer]]s or [[tuple]]s of integers constructed as an [[arithmetic progression]] is, but allowing several possible differences. So, for example, we start at 17 and may add a multiple of 3 ''or'' of 5, repeatedly.  In algebraic terms we look at integers\n\n:<math>a + mb + nc + \\cdots</math> \n\nwhere <math>a, b, c</math> and so on are fixed, and <math>m, n</math> and so on are confined to some ranges\n\n:<math>0 \\le m \\le M</math>\n\nand so on, for a finite progression. The number&nbsp; <math>k</math>, that is the number of permissible differences, is called the ''dimension'' of the generalized progression.\n\nMore generally, let\n\n:<math>L(C;P)</math>\n\nbe the set of all elements <math>x</math> in <math>N^n</math> of the form\n\n:<math>x = c_0 + \\sum_{i=1}^m k_i x_i,</math>\n\nwith <math>c_0</math> in <math>C</math>, <math>x_1, \\ldots, x_m</math> in <math>P</math>, and <math>k_1, \\ldots, k_m</math> in <math>N</math>. <math>L</math> is said to be a ''linear set'' if <math>C</math> consists of exactly one element, and <math>P</math> is finite.\n\nA subset of <math>N^n</math> is said to be '''semilinear'''{{Anchor|semilinear set}} if it is a finite union of linear sets. The semilinear sets are exactly the sets definable in [[Presburger arithmetic]].<ref>{{cite journal|last1=Ginsburg|first1=Seymour|last2=Spanier|first2=Edwin Henry|title=Semigroups, Presburger Formulas, and Languages|journal=Pacific Journal of Mathematics|date=1966|volume=16|pages=285–296}}</ref>\n\n==See also==\n* [[Freiman's theorem]]\n\n==References==\n{{Reflist}}\n*{{cite book| last=Nathanson | first=Melvyn B. | year=1996 | title=Additive Number Theory: Inverse Problems and Geometry of Sumsets | volume=165 | series=[[Graduate Texts in Mathematics]] | publisher=Springer | isbn=0-387-94655-1 | zbl=0859.11003 }}\n\n{{DEFAULTSORT:Generalized Arithmetic Progression}}\n[[Category:Algebra]]\n[[Category:Combinatorics]]"
    },
    {
      "title": "Generalized Cohen–Macaulay ring",
      "url": "https://en.wikipedia.org/wiki/Generalized_Cohen%E2%80%93Macaulay_ring",
      "text": "In algebra, a '''generalized Cohen–Macaulay ring''' is a commutative Noetherian [[local ring]] <math>(A, \\mathfrak{m})</math> of [[Krull dimension]] ''d'' > 0 that satisfies any of the following equivalent conditions:<ref>{{harvnb|Herrmann–Ikeda–Orbanz|loc=Theorem 37.4.}}</ref><ref>{{harvnb|Herrmann–Ikeda–Orbanz|loc=Theorem 37.10.}}</ref>\n*For each integer <math>i = 0, \\dots, d - 1</math>, the length of the ''i''-th [[local cohomology]] of ''A'' is finite:\n*:<math>\\operatorname{length}_A(\\operatorname{H}^i_{\\mathfrak{m}}(A)) < \\infty</math>.\n*<math>\\sup_Q (\\operatorname{length}_A(A/Q) - e(Q)) < \\infty</math> where the sup is over all [[parameter ideal]]s <math>Q</math> and <math>e(Q)</math> is the [[multiplicity of a module|multiplicity]] of <math>Q</math>.\n*There is an <math>\\mathfrak{m}</math>-[[primary ideal]] <math>Q</math> such that for each system of parameters <math>x_1, \\dots, x_d</math> in <math>Q</math>, <math>(x_1, \\dots, x_{d-1}) : x_d = (x_1, \\dots, x_{d-1}) : Q.</math>\n*For each prime ideal <math>\\mathfrak{p}</math> of <math>\\widehat{A}</math> that is not <math>\\mathfrak{m} \\widehat{A}</math>, <math>\\dim \\widehat{A}_{\\mathfrak{p}} + \\dim \\widehat{A}/\\mathfrak{p} = d</math> and <math>\\widehat{A}_{\\mathfrak{p}}</math> is [[Cohen–Macaulay ring|Cohen–Macaulay]].\n\nThe last condition implies that the localization <math>A_\\mathfrak{p}</math> is Cohen–Macaulay for each prime ideal <math>\\mathfrak{p} \\ne \\mathfrak{m}</math>.\n\nA standard example is the local ring at the vertex of an affine cone over a smooth [[projective variety]]. Historically, the notion grew up out of the study of a [[Buchsbaum ring]], a Noetherian local ring ''A'' in which <math>\\operatorname{length}_A(A/Q) - e(Q)</math> is constant for <math>\\mathfrak{m}</math>-primary ideals <math>Q</math>; see the introduction of {{harv|Trung|1986}}.\n\n== References ==\n{{reflist}}\n*Herrmann, M., S. Ikeda, and U. Orbanz: Equimultiplicity and Blowing Up. An Algebraic Study with an Appendix by B. Moonen. Springer Verlag, Berlin Heidelberg New-York, 1988.\n*N. V. Trung, Towards a theory of generalized Cohen-Macaulay modules, Nagoya Math. J. 102, 1 – 49(1986)\n\n\n{{algebra-stub}}\n\n\n\n[[Category:Algebra]]"
    },
    {
      "title": "Goursat's lemma",
      "url": "https://en.wikipedia.org/wiki/Goursat%27s_lemma",
      "text": "{{distinguish|text=[[Goursat's integral lemma]] from [[complex analysis]]}}\n\n'''Goursat's lemma''', named after the French mathematician [[Édouard Goursat]], is an [[algebra]]ic [[theorem]] about [[subgroup]]s of the [[Direct product of groups|direct product]] of two [[Group (mathematics)|groups]].\n\nIt can be stated more generally in a [[Goursat variety]] (and consequently it also holds in any [[Maltsev variety]]), from which one recovers a more general version of [[Zassenhaus lemma|Zassenhaus' butterfly lemma]]. In this form, Goursat's theorem also implies the [[snake lemma]].\n\n== Groups ==\nGoursat's lemma for groups can be stated as follows.\n:Let <math>G</math>, <math>G'</math> be groups, and let <math>H</math> be a subgroup of <math>G\\times G'</math> such that the two [[projection (mathematics)|projections]] <math>p_1: H\\rightarrow G</math> and <math>p_2: H\\rightarrow G'</math> are [[surjective]] (i.e., <math>H</math> is a [[subdirect product]] of <math>G</math> and <math>G'</math>). Let <math>N</math> be the kernel of <math>p_2</math> and <math>N'</math> the [[Kernel (algebra)|kernel]] of <math>p_1</math>. One can identify <math>N</math> as a [[normal subgroup]] of <math>G</math>, and <math>N'</math> as a normal subgroup of <math>G'</math>. Then the image of <math>H</math> in <math>G/N\\times G'/N'</math> is the [[graph of a function|graph]] of an [[isomorphism]] <math>G/N\\approx G'/N'</math>.\n\nAn immediate consequence of this is that the subdirect product of two groups can be described as a [[Direct product of groups#Fiber products|fiber product]] and vice versa.\n\nNotice that if <math>H</math> is ''any'' subgroup of <math>G\\times G'</math> (the projections <math>p_1: H\\rightarrow G</math> and <math>p_2: H\\rightarrow G'</math> need not be surjective), then the projections from <math>H</math> onto <math>p_1(G)\\times p_2(G')</math>  ''are'' surjective. Then one can apply Goursat's lemma to <math>H \\leq p_1(G)\\times p_2(G')</math>. \n\nTo motivate the proof, consider the slice <math>S={g}\\times G'</math> in <math>G \\times G'</math>, for any arbitrary <math>{g}\\in G</math>. By the surjectivity of the projection map to <math>G</math>, this has a non trivial intersection with <math>H</math>.  Then essentially, this intersection represents exactly one particular coset of <math>N'</math>. Indeed, if we had distinct elements <math>(g,a), (g,b)\\in S\\cap H</math> with <math>a\\in pN' \\subset G'</math> and <math>b\\in qN' \\subset G'</math>  , then <math>H</math> being a group, we get that <math>(e, ab^{-1})\\in H</math>, and hence, <math>(e, ab^{-1})\\in N'</math>. But this a contradiction, as <math>a,b</math> belong to distinct cosets of <math>N'</math>, and thus <math>ab^{-1}N' \\neq N'</math>, and thus the element <math>(e, ab^{-1})\\in N'</math> cannot belong to the kernel <math>N'</math> of the projection map from <math>H</math> to <math>G</math>. Thus the intersection of <math>H</math> with every \"horizontal\" slice isomorphic to <math>G' \\in G\\times G'</math> is exactly one particular coset of <math>N' </math> in <math>G'</math>.\nBy an identical argument, the intersection of <math>H</math> with every \"vertical\" slice isomorphic to <math>G \\in G\\times G'</math> is exactly one particular coset of <math>N </math> in <math>G</math>.\n\nAll the cosets of <math>G,G'</math> are present in the group <math>H</math>, and by the above argument, there is an exact 1:1 correspondence between them. The proof below further shows that the map is an isomorphism.\n\n=== Proof ===\n\nBefore proceeding with the [[Mathematical proof|proof]], <math>N</math> and <math>N'</math> are shown to be normal in <math>G \\times \\{e'\\}</math> and <math>\\{e\\} \\times G'</math>, respectively.  It is in this sense that <math>N</math> and <math>N'</math> can be identified as normal in ''G'' and ''G''', respectively.\n\nSince <math>p_2</math> is a [[homomorphism]], its kernel ''N'' is normal in ''H''. Moreover, given <math>g \\in G</math>, there exists <math>h=(g,g') \\in H</math>, since <math>p_1</math> is surjective.  Therefore, <math>p_1(N)</math> is normal in ''G'', viz:\n:<math>gp_1(N)=p_1(h)p_1(N)=p_1(hN)=p_1(Nh)=p_1(N)g</math>.\nIt follows that <math>N</math> is normal in <math>G \\times \\{e'\\}</math> since\n: <math>(g,e')N = (g,e')(p_1(N) \\times \\{e'\\}) = gp_1(N) \\times \\{e'\\} = p_1(N)g \\times \\{e'\\} = (p_1(N) \\times \\{e'\\})(g,e')=N(g,e')</math>.\n\nThe proof that <math>N'</math> is normal in <math>\\{e\\} \\times G'</math> proceeds in a similar manner.\n\nGiven the identification of <math>G</math> with <math>G \\times \\{e'\\}</math>, we can write <math>G/N</math> and <math>gN</math> instead of <math>(G \\times \\{e'\\})/N</math> and <math>(g,e')N</math>, <math>g \\in G</math>.  Similarly, we can write <math>G'/N'</math> and <math>g'N'</math>, <math>g' \\in G'</math>.\n\nOn to the proof. Consider the map <math>H \\rightarrow G/N \\times G'/N'</math> defined by <math>(g,g') \\mapsto (gN, g'N')</math>. The image of <math>H</math> under this map is <math>\\{(gN,g'N') | (g,g') \\in H \\}</math>. Since <math>H \\rightarrow G/N</math> is surjective, this [[Relation (mathematics)|relation]] is the graph of a [[well-defined]] function <math>G/N \\rightarrow G'/N'</math> provided <math>g_1N=g_2N \\Rightarrow g_1'N'=g_2'N'</math> for every <math>(g_1,g_1'),(g_2,g_2')\\in H</math>, essentially an application of the [[vertical line test]].\n\nSince <math>g_1N=g_2N</math> (more properly, <math>(g_1,e')N=(g_2,e')N</math>), we have <math>(g_2^{-1}g_1,e') \\in N \\subset H</math>. Thus <math>(e,g_2'^{-1}g_1') = (g_2,g_2')^{-1}(g_1,g_1')(g_2^{-1}g_1,e')^{-1} \\in H</math>, whence <math>(e,g_2'^{-1}g_1') \\in N'</math>, that is, <math>g_1'N'=g_2'N'</math>.\n\nFurthermore, for every <math>(g_1,g_1'),(g_2,g_2')\\in H</math> we have <math>(g_1g_2,g_1'g_2')\\in H</math>. It follows that this function is a group homomorphism.\n\nBy symmetry, <math>\\{(g'N',gN) | (g,g') \\in H \\}</math> is the graph of a well-defined homomorphism <math>G'/N' \\rightarrow G/N</math>. These two homomorphisms are clearly inverse to each other and thus are indeed isomorphisms.\n\n== Goursat varieties ==\n{{expand section|date=April 2015}}\n\nAs a consequence of Goursat's theorem, one can derive a very general version on the [[Jordan–Hölder theorem|Jordan–Hölder]]–[[Schreier refinement theorem|Schreier theorem]] in Goursat varieties.\n\n== References ==\n* Édouard Goursat, \"Sur les substitutions orthogonales et les divisions régulières de l'espace\", ''Annales Scientifiques de l'École Normale Supérieure'' (1889), Volume: 6, pages 9–102\n* {{cite book|editors=Aldo Ursini, Paulo Agliano|title=Logic and Algebra|year=1996|publisher=CRC Press|isbn=978-0-8247-9606-8|pages=161–180|author=[[Joachim Lambek|J. Lambek]]|chapter=The Butterfly and the Serpent}}\n* [[Ken Ribet|Kenneth A. Ribet]] (Autumn 1976), \"[[Galois]] [[Group action (mathematics)|Action]] on Division Points of [[Abelian Variety|Abelian Varieties]] with Real Multiplications\", ''[[American Journal of Mathematics]]'', Vol. 98, No. 3, 751–804.\n\n[[Category:Algebra]]\n[[Category:Lemmas]]\n[[Category:Articles containing proofs]]"
    },
    {
      "title": "Graph algebra (social sciences)",
      "url": "https://en.wikipedia.org/wiki/Graph_algebra_%28social_sciences%29",
      "text": "'''Graph algebra''' is [[systems-centric]] modeling tool for the [[social sciences]].<ref>{{citation|title=Graph Algebra: Mathematical Modeling With a Systems Approach|volume=151|series=Quantitative Applications in the Social Sciences|first=Courtney|last=Brown|publisher=SAGE|year=2008|isbn=9781412941099|url=https://books.google.com/books?id=pLuuYWK5V4oC&printsec=frontcover#v=onepage&q&f=false}}.</ref>  It was first developed by Sprague, Pzeworski, and Cortes<ref>Cortés, Fernando, Adam Przeworski, and John Sprague. 1974. Systems Analysis for Social Scientists. New York: John Wiley & Sons.</ref> as a hybridized version of engineering plots to describe social phenomena.\n\n== Notes and references ==\n\n{{Reflist}}\n\n{{DEFAULTSORT:Graph Algebra (Social Sciences)}}\n[[Category:Algebra]]\n[[Category:Social science methodology]]"
    },
    {
      "title": "Graph dynamical system",
      "url": "https://en.wikipedia.org/wiki/Graph_dynamical_system",
      "text": "In [[mathematics]], the concept of '''graph dynamical systems''' can be used to capture a wide range of processes taking place on graphs or networks. A major theme in the mathematical and computational analysis of GDSs is to relate their structural properties (e.g. the network connectivity) and the global dynamics that result.\n\nThe work on GDSs considers finite graphs and finite state spaces. As such, the research typically involves techniques from, e.g., [[graph theory]], [[combinatorics]], [[algebra]], and [[dynamical systems]] rather than differential geometry. In principle, one could define and study GDSs over an infinite graph (e.g. [[cellular automata]] or [[Stochastic cellular automata|probabilistic cellular automata]] over <math>\\mathbb{Z}^k</math> or [[interacting particle systems]] when some randomness is included), as well as GDSs with infinite state space (e.g. <math>\\mathbb{R}</math> as in coupled map lattices); see, for example, Wu.<ref name=wu-05>{{cite journal |doi=10.1088/0951-7715/18/3/007 |last=Wu |first=Chai Wah |year=2005 |title=Synchronization in networks of nonlinear dynamical systems coupled via a directed graph |journal=Nonlinearity |volume= 18 |issue= 3|pages=1057–1064 |ref=Wu:05|bibcode=2005Nonli..18.1057W }}</ref> In the following, everything is implicitly assumed to be finite unless stated otherwise.\n\n==Formal definition==\n\nA graph dynamical system is constructed from the following components:\n\n<blockquote>\n* A finite ''graph'' ''Y'' with vertex set v[''Y''] = {1,2, ... , n}. Depending on the context the graph can be directed or undirected.\n* A state ''x<sub>v</sub>'' for each vertex ''v'' of ''Y'' taken from a finite set ''K''. The ''system state'' is the ''n''-tuple ''x'' = (''x''<sub>1</sub>, ''x''<sub>2</sub>, ... , ''x<sub>n</sub>''), and ''x''[''v''] is the tuple consisting of the states associated to the vertices in the 1-neighborhood of ''v'' in ''Y'' (in some fixed order).\n* A ''vertex function'' ''f<sub>v</sub>'' for each vertex ''v''. The vertex function maps the state of vertex ''v'' at time ''t'' to the vertex state at time ''t''&nbsp;+&nbsp;1 based on the states associated to the 1-neighborhood of ''v'' in ''Y''.\n* An ''update scheme'' specifying the mechanism by which the mapping of individual vertex states is carried out so as to induce a discrete dynamical system with map ''F'': ''K<sup>n</sup> → K<sup>n</sup>''.\n</blockquote>\n\nThe ''phase space'' associated to a dynamical system with map ''F'': ''K<sup>n</sup> → K<sup>n</sup>'' is the finite directed graph with vertex set ''K<sup>n</sup>'' and directed edges (''x'', ''F''(''x'')). The structure of the phase space is governed by the properties of the graph ''Y'', the vertex functions (''f<sub>i</sub>'')''<sub>i</sub>'', and the update scheme. The research in this area seeks to infer phase space properties based on the structure of the system constituents. The analysis has a local-to-global character.\n\n== Generalized cellular automata (GCA) ==\n\nIf, for example, the update scheme consists of applying the vertex functions synchronously one obtains the class of ''generalized cellular automata'' (CA). In this case, the global map ''F'': ''K<sup>n</sup> → K<sup>n</sup>'' is given by\n\n<math>F(x)_v = f_v(x[v]) \\;.</math>\n\nThis class is referred to as generalized cellular automata since the classical or standard [[Cellular automaton|cellular automata]] are typically defined and studied over regular graphs or grids, and the vertex functions are typically assumed to be identical.\n\n'''Example:''' Let ''Y'' be the circle graph on vertices {1,2,3,4} with edges {1,2}, {2,3}, {3,4} and {1,4}, denoted Circ<sub>4</sub>. Let ''K'' = {0,1} be the state space for each vertex and use the function nor<sub>3</sub> : ''K<sup>3</sup>'' → ''K'' defined by nor<sub>3</sub>(''x,y,z'')&nbsp;=&nbsp;(1&nbsp;+&nbsp;''x'')(1&nbsp;+&nbsp;''y'')(1&nbsp;+&nbsp;''z'') with arithmetic modulo 2 for all vertex functions. Then for example the system state (0,1,0,0) is mapped to (0,&nbsp;0,&nbsp;0,&nbsp;1) using a synchronous update. All the transitions are shown in the phase space below.\n\n[[File:circ-4-nor.jpg|frame|center | 326]]\n\n== Sequential dynamical systems (SDS) ==\n\nIf the vertex functions are applied asynchronously in the sequence specified by a word ''w'' = (''w''<sub>1</sub>, ''w''<sub>2</sub>, ... , ''w<sub>m</sub>'') or permutation <math>\\pi</math> = ( <math>\\pi_1</math>, <math>\\pi_2,\\dots,\\pi_n</math>) of ''v''[''Y''] one obtains the class of ''[[Sequential dynamical system]]s'' (SDS).<ref name=Mortveit-08>{{cite book |last=Mortveit |first=Henning S. |author2=Reidys, Christian M. | year=2008 |title=An introduction to sequential dynamical systems |publisher=[[Springer Verlag]] |location=New York |isbn=978-0-387-30654-4 | series=Universitext| ref=Mortveit:08}}</ref> In this case it is convenient to introduce the ''Y''-local maps ''F<sub>i</sub>'' constructed from the vertex functions by\n\n: <math>F_i (x) = (x_1, x_2,\\ldots, x_{i-1}, f_i(x[i]), x_{i+1}, \\ldots , x_n) \\;. </math>\n\nThe SDS map ''F'' = [''F<sub>Y</sub>'' , ''w''] : ''K<sup>n</sup>'' → ''K<sup>n</sup>'' is the function composition\n\n: <math>[F_Y ,w] = F_{w(m)} \\circ F_{w(m-1)} \\circ \\cdots \\circ F_{w(2)} \\circ F_{w(1)} \\;. </math>\n\nIf the update sequence is a permutation one frequently speaks of a ''permutation SDS'' to emphasize this point.\n\n'''Example:''' Let ''Y'' be the circle graph on vertices {1,2,3,4} with edges {1,2}, {2,3}, {3,4} and {1,4}, denoted Circ<sub>4</sub>. Let ''K''={0,1} be the state space for each vertex and use the function nor<sub>3</sub> : ''K''<sup>3</sup> → ''K'' defined by nor<sub>3</sub>(''x,&nbsp;y,&nbsp;z'') = (1&nbsp;+&nbsp;''x'')(1&nbsp;+&nbsp;''y'')(1&nbsp;+&nbsp;''z'') with arithmetic modulo 2 for all vertex functions. Using the update sequence (1,2,3,4) then the system state (0,&nbsp;1,&nbsp;0,&nbsp;0) is mapped to (0,&nbsp;0,&nbsp;1,&nbsp;0). All the system state transitions for this sequential dynamical system are shown in the phase space below.\n\n[[File:circ-4-nor-1234.jpg|frame|center | 326]]\n\n== Stochastic graph dynamical systems ==\n\nFrom, e.g., the point of view of applications it is interesting to consider the case where one or more of the components of a GDS contains stochastic elements. Motivating applications could include processes that are not fully understood (e.g. dynamics within a cell) and where certain aspects for all practical purposes seem to behave according to some probability distribution. There are also applications governed by deterministic principles whose description is so complex or unwieldy that it makes sense to consider probabilistic approximations.\n\nEvery element of a graph dynamical system can be made stochastic in several ways. For example, in a sequential dynamical system the update sequence can be made stochastic. At each iteration step one may choose the update sequence ''w'' at random from a given distribution of update sequences with corresponding probabilities. The matching probability space of update sequences induces a probability space of SDS maps. A natural object to study in this regard is the [[Markov chain]] on state space induced by this collection of SDS maps. This case is referred to as ''update sequence stochastic GDS'' and is motivated by, e.g., processes where \"events\" occur at random according to certain rates (e.g. chemical reactions), synchronization in parallel computation/discrete event simulations, and in computational paradigms described later<!-- Make sure this cross ref stays/works. -->.\n\nThis specific example with stochastic update sequence illustrates two general facts for such systems: when passing to a stochastic graph dynamical system one is generally led to (1) a study of Markov chains (with specific structure governed by the constituents of the GDS), and (2) the resulting Markov chains tend to be large having an exponential number of states. A central goal in the study of stochastic GDS is to be able to derive reduced models.\n\nOne may also consider the case where the vertex functions are stochastic, i.e., ''function stochastic GDS''. For example, Random [[Boolean network]]s are examples of function stochastic GDS using a synchronous update scheme and where the state space is ''K'' = {0,&nbsp;1}. Finite [[probabilistic cellular automata]] (PCA) is another example of function stochastic GDS. In principle the class of Interacting particle systems (IPS) covers finite and infinite [[probabilistic cellular automata|PCA]], but in practice the work on IPS is largely concerned with the infinite case since this allows one to introduce more interesting topologies on state space.\n\n==Applications==\n\nGraph dynamical systems constitute a natural framework for capturing distributed systems such as biological networks and epidemics over social networks, many of which are frequently referred to as complex systems.\n\n==See also==\n\n*[[Chemical reaction network theory]]\n*[[Dynamic network analysis]] (a [[social science]] topic)\n*[[Finite state machine]]s\n*[[Hopfield net]]works\n*[[Kauffman network]]s\n*[[Petri net]]s\n\n==References==\n\n{{reflist}}\n\n==Further reading==\n* {{cite journal |doi=10.1088/0951-7715/22/2/010 |last=Macauley |first=Matthew |author2=Mortveit, Henning S. |year=2009 |title=Cycle equivalence of graph dynamical systems |journal=Nonlinearity |volume=22 |issue=2 |pages=421&ndash;436 |ref=Macauley:09a|arxiv=0802.4412 |bibcode=2009Nonli..22..421M }}\n*{{cite book |last=Golubitsky |first=Martin |authorlink=Marty Golubitsky|author2=Stewart, Ian |year=2003 |title =The Symmetry Perspective |publisher=Birkhauser |location=Basel | ref=Golubitsky:03 |isbn=0-8176-2171-7}}\n\n==External links==\n*[http://www.samsi.info/sites/default/files/samsi-05-dec-08.pdf Graph Dynamical Systems – A Mathematical Framework for Interaction-Based Systems, Their Analysis and Simulations by Henning Mortveit]\n\n\n{{DEFAULTSORT:Graph Dynamical System}}\n[[Category:Dynamical systems]]\n[[Category:Algebra]]\n[[Category:Graph theory]]\n[[Category:Combinatorics]]"
    },
    {
      "title": "Groupoid algebra",
      "url": "https://en.wikipedia.org/wiki/Groupoid_algebra",
      "text": "In [[mathematics]], the concept of '''groupoid algebra''' generalizes the notion of [[group algebra]].<ref>Khalkhali (2009), [{{Google books|plainurl=y|id=UInc5AyTAikC|page=48|text=groupoid algebra}} p. 48]</ref>\n\n== Definition ==\nGiven a [[groupoid]] <math>(G, \\cdot)</math> and a [[field (mathematics)|field]] <math>K</math> (in the sense of a [[category theory|category]] with all arrows invertible), it is possible to define the groupoid algebra <math>KG</math> as the [[Algebra over a field|algebra]] over <math>K</math> formed by the [[vector space]] having the elements of (the arrows of) <math>G</math> as [[generator (mathematics)|generator]]s and having the [[multiplication]] of these elements defined by <math>g * h = g \\cdot h</math>, whenever this product is defined, and <math>g * h = 0</math> otherwise. The product is then extended by [[linearity]].<ref>Dokuchaev, Exel & Piccione (2000), p. 7</ref>\n\n== Examples ==\nSome examples of groupoid algebras are the following:<ref>da Silva & Weinstein (1999), [{{Google books|plainurl=y|id=2fcC1EGKz08C|page=97|text=groupoid algebras}} p. 97]</ref>\n* [[Group algebra]]s\n* [[Matrix ring|Matrix algebra]]s\n* [[Algebra of functions|Algebras of functions]]\n\n== Properties ==\n* When a groupoid has a [[Wikt:finite|finite]] number of [[Object (category theory)|objects]] and a finite number of [[morphism (category theory)|morphisms]], the groupoid algebra is a [[direct sum]] of [[tensor product]]s of group algebras and matrix algebras.<ref>Khalkhali & [[Matilde Marcolli|Marcolli]] (2008), [{{Google books|plainurl=y|id=HsTkPOj0iusC|page=210|text=Groupoid algebra of a finite groupoid}} p. 210]</ref>\n\n== See also ==\n* [[Hopf algebra]]\n* [[Partial group algebra]]\n\n== Notes ==\n<references />\n\n== References ==\n* {{cite book |last1=Khalkhali |first1=Masoud |authorlink1= |last2= |first2= |authorlink2= |title=Basic Noncommutative Geometry |DUPLICATE_url= |edition= |series=EMS Series of Lectures in Mathematics |volume= |year=2009 |publisher=European Mathematical Society |location= |isbn=978-3-03719-061-6 | url=https://books.google.com/books?id=UInc5AyTAikC&printsec=frontcover#v=onepage&q=%22groupoid%20algebra%22&f=false}}\n* {{cite book |last1=da Silva |first1=Ana Cannas |authorlink1= |last2=Weinstein |first2=Alan |authorlink2= |title=Geometric models for noncommutative algebras |url= |edition=2 |series=Berkeley mathematics lecture notes |volume=10 |year=1999 |publisher=AMS Bookstore |location= |isbn=978-0-8218-0952-5 }}\n* {{cite journal |last1=Dokuchaev |first1=M. |last2=Exel |first2=R. |last3=Piccione |first3=P. |year=2000 |title=Partial Representations and Partial Group Algebras |journal=Journal of Algebra |volume=226 |issue= |pages=505–532 |publisher=Elsevier |issn=0021-8693 |doi= 10.1006/jabr.1999.8204|url=|arxiv= math/9903129\n}}\n* {{cite book |last1=Khalkhali |first1=Masoud |authorlink1= |last2=Marcolli |first2=Matilde | authorlink2=Matilde Marcolli |title=An invitation to noncommutative geometry |url= |edition= |series= |volume= |year=2008 |publisher=World Scientific |location= |isbn=978-981-270-616-4 }}\n\n[[Category:Algebra]]"
    },
    {
      "title": "Hecke algebra acting on modular forms",
      "url": "https://en.wikipedia.org/wiki/Hecke_algebra_acting_on_modular_forms",
      "text": "In [[number theory]] in mathematics, the '''Hecke algebra''' is the algebra generated by [[Hecke operator]]s. The algebra is commutative.<ref>{{harvnb|Serre|1973|loc=Ch. VII, § 5. Corollary 2.}}</ref>\n\n== References ==\n{{reflist}}\n*[[Jean-Pierre Serre]], ''A course in arithmetic''.\n\n[[Category:Algebra]]\n[[Category:Number theory]]\n[[Category:Modular forms]]\n\n\n{{algebra-stub}}"
    },
    {
      "title": "Height function",
      "url": "https://en.wikipedia.org/wiki/Height_function",
      "text": "\n{{short description|Mathematical functions that quantify complexity}}\n{{About|mathematical functions that quantify complexity|other uses of height|Height (disambiguation)}}\nA '''height function''' is a [[function (mathematics)|function]] that quantifies the complexity of mathematical objects. In [[Diophantine geometry]], height functions quantify the size of solutions to [[Diophantine equations]] and are typically functions from a set of points on [[algebraic variety|algebraic varieties]] (or a set of algebraic varieties) to the [[real numbers]].<ref>{{harvs|txt|last=Lang|authorlink=Serge Lang|year=1997|loc1=pp. 43–67}}</ref>\n\nFor instance, the ''classical'' or ''naive height'' over the [[rational number]]s is typically defined to be the maximum of the numerators and denominators of the coordinates (e.g. 2 for the coordinates {{math|(3/9, 1/2)}}), but in a [[logarithmic scale]].\n\n{{TOC limit|3}}\n\n==Significance==\nHeight functions allow mathematicians to count objects, such as [[rational point]]s, that are otherwise infinite in quantity. For instance, the set of rational numbers of naive height (the maximum of the numerator and denominator when [[Irreducible fraction|expressed in lowest terms]]) below any given constant is finite despite the set of rational numbers being infinite.<ref>{{harvs|txt|last1=Bombieri|last2=Gubler|authorlink1=Enrico Bombieri|year=2006|loc1=pp. 15–21}}</ref> In this sense, height functions can be used to prove [[Asymptotic analysis|asymptotic results]] such as [[Baker's theorem]] in [[transcendental number theory]] which was proved by {{harvs|txt|authorlink=Alan Baker (mathematician)|first=Alan|last= Baker|year1=1966|year2=1967a|year3=1967b}}.\n\nIn other cases, height functions can distinguish some objects based on their complexity. For instance, the [[subspace theorem]] proved by {{harvs|txt|authorlink=Wolfgang M. Schmidt|first=Wolfgang M. |last=Schmidt|year= 1972}} demonstrates that points of small height (i.e. small complexity) in [[projective space]] lie in a finite number of [[hyperplane]]s and generalizes [[Siegel's theorem on integral points]] and solution of the [[S-unit equation]].<ref>{{harvs|txt|last1=Bombieri|last2=Gubler|authorlink1=Enrico Bombieri|year=2006|loc1=pp. 176–230}}</ref>\n\nHeight functions were crucial to the proofs of the [[Mordell–Weil theorem]] and [[Faltings's theorem]] by {{harvs|txt||last=Weil|authorlink=André Weil|year=1929}} and {{harvs|txt|last=Faltings|authorlink=Gerd Faltings|year=1983}} respectively. Several outstanding unsolved problems about the heights of rational points on algebraic varieties, such as the [[Manin conjecture]] and [[Vojta's conjecture]], have far-reaching implications for problems in [[Diophantine approximation]], [[Diophantine equation]]s, [[arithmetic geometry]], and [[mathematical logic]].<ref>{{harvs|txt|last1=Vojta|authorlink=Paul Vojta|year=1987}}</ref><ref>{{harvs|txt|last1=Faltings|authorlink1=Gerd Faltings|year=1991}}</ref>\n\n==Height functions in Diophantine geometry==\n\n===History===\nHeights in Diophantine geometry were initially developed by [[André Weil]] and [[Douglas Northcott]] beginning in the 1920s.<ref>{{harvs|txt||last=Weil|authorlink=André Weil|year=1929}}</ref> Innovations in 1960s were the [[Néron–Tate height]] and the realization that heights were linked to projective representations in much the same way that [[ample line bundle]]s are in other parts of [[algebraic geometry]]. In the 1970s, [[Suren Arakelov]] developed Arakelov heights in [[Arakelov theory]].<ref>{{harvs|txt|last=Lang|authorlink=Serge Lang|year=1988}}</ref> In 1983, Faltings developed his theory of Faltings heights in his proof of Faltings's theorem.<ref>{{harvs|txt|last=Faltings|authorlink=Gerd Faltings|year=1983}}</ref>\n\n===Naive height===\n''Classical'' or ''naive height'' is defined in terms of ordinary absolute value on [[homogeneous coordinates]]. It is typically a logarithmic scale and therefore can be viewed as being proportional to the \"algebraic complexity\" or number of [[bit]]s needed to store a point.<ref>{{harvs|txt|last1=Bombieri|last2=Gubler|authorlink1=Enrico Bombieri|year=2006|loc1=pp. 15–21}}</ref> It is typically defined to be the [[logarithm]] of the maximum absolute value of the vector of coprime integers obtained by multiplying through by a [[lowest common denominator]]. This may be used to define height on a point in projective space over '''Q''', or of a polynomial, regarded as a vector of coefficients, or of an algebraic number, from the height of its minimal polynomial.<ref>{{harvs|txt|last1=Baker | authorlink1=Alan Baker (mathematician)|last2= Wüstholz | authorlink2=Gisbert Wüstholz|year=2007|loc1=p. 3}}</ref>\n\nThe naive height of a [[rational number]] ''x'' = ''p''/''q'' (in lowest terms) is \n* multiplicative height <math> H(p/q) = \\max\\{|p|,|q|\\}</math> <ref>[https://planetmath.org/heightfunction planetmath: height function]</ref>\n* logarithmic height: <math> h(p/q) = \\log H (p/q)</math> <ref>[https://mathoverflow.net/questions/203852/average-height-of-rational-points-on-a-curve mathoverflow question: average-height-of-rational-points-on-a-curve]</ref>\n\nTherefore, the naive multiplicative and logarithmic heights of {{math|4/10}} are {{math|5}} and {{math|log(5)}}, for example.\n\nThe naive height ''H'' of an [[elliptic curve]] ''E'' given by {{math|''y<sup>2</sup> {{=}} x<sup>2</sup> + Ax + B''}} is defined to be {{math|''H(E)'' {{=}} log max(4&#124;''A''&#124;<sup>3</sup>, 27&#124;''B''&#124;<sup>2</sup>)}}.<ref name=\"planetmath\">{{PlanetMath |urlname=https://planetmath.org/canonicalheightonanellipticcurve |title=Canonical height on an elliptic curve }}</ref>\n\n===Néron–Tate height===\n{{Main|Néron–Tate height}}\nThe ''Néron–Tate height'', or ''canonical height'', is a [[quadratic form]] on the [[Mordell–Weil group]] of [[rational points]] of an abelian variety defined over a [[global field]]. It is named after [[André Néron]], who first defined it as a sum of local heights,<ref>{{harvs|txt|last=Néron|authorlink=André Néron|year=1965}}</ref> and [[John Tate]], who defined it globally in an unpublished work.<ref>{{harvs|txt|last=Lang|authorlink=Serge Lang|year=1997|page=72}}</ref>\n\n===Weil height===\nThe ''Weil height'' is defined on a [[projective variety]] ''X'' over a number field ''K'' equipped with a line bundle ''L'' on ''X''. Given a [[Ample line bundle|very ample line bundle]] ''L<sub>0</sub>'' on ''X'', one may define a height function using the naive height function ''h''. Since ''L<sub>0</sub>''' is very ample, its complete linear system gives a map ''ϕ'' from ''X'' to projective space. Then for all points ''p'' on ''X'', define\n<math>h_{L_0}(p) := h(\\phi(p)).</math><ref name=Silverman/><ref name=Gubler/>\n\nOne may write an arbitrary line bundle ''L'' on ''X'' as the difference of two very ample line bundles ''L<sub>1</sub>'' and ''L<sub>2</sub>'' on ''X'', up to [[Proj construction#The twisting sheaf of Serre|Serre's twisting sheaf]] ''O(1)'', so one may define the Weil height ''h<sub>L</sub>'' on ''X'' with respect to ''L'' via\n<math>h_{L} := h_{L_1} - h_{L_2},</math>\n(up to ''O(1)'').<ref name=Silverman>{{harvs|txt|last=Silverman|authorlink=Joseph H. Silverman|year=1994|loc1=III.10}}</ref><ref name=Gubler>{{harvs|txt|last1=Bombieri|last2=Gubler|authorlink1=Enrico Bombieri|year=2006|loc1=Sections 2.2–2.4}}</ref>\n\n====Arakelov height====\nThe ''Arakelov height'' on a projective space over the field of algebraic numbers is a global height function with local contributions coming from [[Fubini–Study metric]]s on the [[Archimedean field]]s and the usual metric on the [[non-Archimedean field]]s.<ref>{{harvs|txt|last1=Bombieri|last2=Gubler|authorlink1=Gerd Faltings|year=2006|loc1=pp. 66–67}}</ref><ref>{{harvs|txt|last=Lang|authorlink=Serge Lang|year=1988|loc1=pp. 156–157}}</ref> It is the usual Weil height equipped with a different metric.<ref>{{harvs|txt|last1=Fili|last2=Petsche|last3=Pritsker|year=2017|loc1=p. 441}}</ref>\n\n===Faltings height===\nThe ''Faltings height'' of an [[abelian variety]] defined over a [[number field]] is a measure of its arithmetic complexity. It is defined in terms of the height of a [[Hermitian form|metrized]] [[line bundle]]. It was introduced by {{harvs|txt|last=Faltings|authorlink=Gerd Faltings|year=1983}} in his proof of the [[Mordell conjecture]].\n\n==Height functions in algebra==\n===Height of a polynomial===\nFor a [[polynomial]] ''P'' of degree ''n'' given by\n\n:<math>P = a_0 + a_1 x + a_2 x^2 + \\cdots + a_n x^n , </math>\n\nthe '''height''' ''H''(''P'') is defined to be the maximum of the magnitudes of its coefficients:<ref>{{harvs|txt|last=Borwein|authorlink=Peter Borwein|year=2002}}</ref>\n\n:<math>H(P) = \\underset{i}{\\max} \\,|a_i|. </math>\n\nOne could similarly define the '''length''' ''L''(''P'') as the sum of the magnitudes of the coefficients:\n\n:<math>L(P) = \\sum_{i=0}^n |a_i|.</math>\n\n====Relation to Mahler measure====\nThe [[Mahler measure]] ''M''(''P'')  of ''P'' is also a measure of the complexity of ''P''.<ref>{{harvs|txt|last=Mahler|authorlink=Kurt Mahler|year=1963}}</ref> The three functions ''H''(''P''), ''L''(''P'') and ''M''(''P'') are related by the  [[inequality (mathematics)|inequalities]]\n\n:<math>\\binom{n}{\\lfloor n/2 \\rfloor}^{-1} H(P) \\le M(P) \\le H(P) \\sqrt{n+1} ; </math>\n\n:<math>L(p) \\le 2^n M(p) \\le 2^n L(p) ; </math>\n\n:<math>H(p) \\le L(p) \\le (n+1) H(p) </math>\n\nwhere <math>\\scriptstyle \\binom{n}{\\lfloor n/2 \\rfloor}</math> is the [[binomial coefficient]].\n\n==Height functions in automorphic forms==\nOne of the conditions in the definition of an [[automorphic form]] on the [[general linear group]] of an [[adelic algebraic group]] is ''moderate growth'', which is an asymptotic condition on the growth of a height function on the general linear group viewed as an [[affine variety]].<ref>{{harvs|txt|last=Bump|authorlink=Daniel Bump|year=1998}}</ref>\n\n==See also==\n*[[abc conjecture]]\n*[[Birch and Swinnerton-Dyer conjecture]]\n*[[Lehmer conjecture#Elliptic analogues|Elliptic Lehmer conjecture]]\n*[[Heath-Brown–Moroz constant]]\n*[[Height zeta function]]\n*[[Raynaud's isogeny theorem]]\n\n==References==\n{{reflist|30em}}\n\n==Sources==\n*{{cite journal| last1=Baker | first1=Alan | authorlink = Alan Baker (mathematician) | title=Linear forms in the logarithms of algebraic numbers. I | doi=10.1112/S0025579300003971 | mr=0220680 | year=1966 | journal=Mathematika. A Journal of Pure and Applied Mathematics | issn=0025-5793 | volume=13 | pages=204–216 |ref=harv}}\n*{{cite journal| last1=Baker | first1=Alan | title=Linear forms in the logarithms of algebraic numbers. II | doi=10.1112/S0025579300008068 | mr=0220680 | year=1967a | journal=Mathematika. A Journal of Pure and Applied Mathematics | issn=0025-5793 | volume=14 | pages=102–107 |ref=harv}}\n*{{cite journal| last1=Baker | first1=Alan | title=Linear forms in the logarithms of algebraic numbers.  III | doi=10.1112/S0025579300003843  | mr=0220680 | year=1967b | journal=Mathematika. A Journal of Pure and Applied Mathematics | issn=0025-5793 | volume=14 | pages=220–228 |ref=harv}}\n*{{cite book | first1=Alan | last1=Baker | first2=Gisbert | last2= Wüstholz | authorlink2=Gisbert Wüstholz | title=Logarithmic Forms and Diophantine Geometry | series=New Mathematical Monographs | volume=9 | publisher=[[Cambridge University Press]] | year=2007 | isbn=978-0-521-88268-2 | zbl=1145.11004 | page=3 | ref=harv}}\n*{{cite book | first1=Enrico | last1=Bombieri | authorlink1=Enrico Bombieri | first2=Walter | last2=Gubler | title=Heights in Diophantine Geometry | series=New Mathematical Monographs | volume=4 | publisher=[[Cambridge University Press]] | year=2006 | isbn=978-0-521-71229-3 | zbl=1130.11034 | doi=10.2277/0521846153 | ref=harv}}\n*{{cite book | first=Peter | last=Borwein | authorlink=Peter Borwein | title=Computational Excursions in Analysis and Number Theory | series=CMS Books in Mathematics | publisher=[[Springer-Verlag]] | year=2002 | isbn=0-387-95444-9 | zbl=1020.12001 | pages=2,3,142,148 | ref=harv}}\n*{{cite book | first=Daniel | last=Bump| authorlink1=Daniel Bump | title=Automorphic Forms and Representations | series=Cambridge Studies in Advanced Mathematics | volume=55 | publisher=Cambridge University Press | year=1998 | isbn=9780521658188 | page=300 | ref=harv}}\n*{{cite book |title=Arithmetic geometry |last=Cornell |first=Gary |last2=Silverman | first2=Joseph H. |authorlink2=Joseph H. Silverman |year=1986 |publisher=Springer |location= New York |isbn=0387963111 |pages= }} → Contains an English translation of {{harvtxt|Faltings|1983}}\n*{{cite journal |last=Faltings |first=Gerd |year=1983 |title=Endlichkeitssätze für abelsche Varietäten über Zahlkörpern |journal=Inventiones Mathematicae |volume=73 |issue=3 |pages=349&ndash;366 |doi=10.1007/BF01388432 | mr=0718935 | trans-title=Finiteness theorems for abelian varieties over number fields | language=German | ref=harv}}\n*{{cite journal |last1=Faltings | first1=Gerd | author1link=Gerd Faltings | title=Diophantine approximation on abelian varieties | journal=Annals of Mathematics | mr=1109353| year=1991 | volume=123 | pages=549–576 | doi=10.2307/2944319 | issue=3 | ref=harv}}\n*{{cite journal|title=Energy integrals and small points for the Arakelov height|journal=Archiv der Mathematik|last1=Fili|first1=Paul|last2=Petsche|first2=Clayton|last3=Pritsker|first3=Igor|volume=109|issue=5|year=2017|pages=441–454 | ref=harv}}\n*{{cite journal | first=K. | last=Mahler | authorlink=Kurt Mahler | title=On two extremum properties of polynomials | journal=Illinois J. Math. | volume=7 | pages=681–701 | year= 1963 | zbl=0117.04003 | ref=harv}}\n*{{cite journal | first=André | last=Néron | authorlink=André Néron | title=Quasi-fonctions et hauteurs sur les variétés abéliennes | journal=[[Ann. of Math.]] |  volume=82 | year=1965 | pages=249–331 | doi=10.2307/1970644 | mr=0179173 | language=fr | ref=harv}}\n*{{cite book | last=Schinzel | first= Andrzej | authorlink=Andrzej Schinzel | title=Polynomials with special regard to reducibility | zbl=0956.12001 | series=Encyclopedia of Mathematics and Its Applications | volume=77 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2000 | isbn=0-521-66225-7 | page=212}}\n*{{cite journal | last1=Schmidt | first1=Wolfgang M. | authorlink=Wolfgang M. Schmidt | title=Norm form equations | mr=0314761 | year=1972 | journal=[[Annals of Mathematics]] |series=Second Series | volume=96 | pages=526–551 | issue=3 | doi=10.2307/1970824 | ref=harv}}\n*{{cite book | first=Serge | last=Lang | authorlink=Serge Lang | title=Introduction to Arakelov theory | publisher=[[Springer-Verlag]] | place=New York | year=1988 | isbn=0-387-96793-1 | mr=0969124 | zbl=0667.14001 | ref=harv}}\n*{{cite book | first=Serge | last=Lang | title=Survey of Diophantine Geometry | publisher=[[Springer-Verlag]] | year=1997 | isbn=3-540-61223-8 | zbl=0869.11051 | ref=harv}}\n*{{cite journal|last=Weil|first=André|authorlink=André Weil|title=L'arithmétique sur les courbes algébriques|journal=[[Acta Mathematica]]|volume=52|year=1929|pages=281–315|issue=1|doi=10.1007/BF02592688|mr=1555278 | ref=harv}}\n*{{cite book |title=Advanced Topics in the Arithmetic of Elliptic Curves |last=Silverman |first=Joseph H. |authorlink=Joseph H. Silverman |year=1994|publisher=Springer |location= New York |isbn=978-1-4612-0851-8 | ref=harv}}\n*{{cite book | last1=Vojta | first1=Paul | author1link=Paul Vojta | title=Diophantine approximations and value distribution theory | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | isbn=978-3-540-17551-3 | doi=10.1007/BFb0072989 | zbl=0609.14011 | mr=883451 | year=1987 | volume=1239 | ref=harv}}\n\n==External links==\n\n* [http://mathworld.wolfram.com/PolynomialHeight.html  Polynomial height at Mathworld]\n\n[[Category:Number theory]]\n[[Category:Polynomials]]\n[[Category:Abelian varieties]]\n[[Category:Elliptic curves]]\n[[Category:Diophantine geometry]]\n[[Category:Algebraic geometry]]\n[[Category:Algebraic number theory]]\n[[Category:Algebra]]"
    },
    {
      "title": "Horner's method",
      "url": "https://en.wikipedia.org/wiki/Horner%27s_method",
      "text": "{{cleanup|reason = See [[Talk:Horner's method#This Article is about Two Different Algorithms]]|date=November 2018}}\n\nIn [[mathematics]], the term '''Horner's rule''' (or '''Horner's method''', '''Horner's scheme''' etc) refers to a polynomial evaluation method named after [[William George Horner]] expressed by\n\n<math display=\"block\">\\begin{align}\np(x) &= a_0 + a_1x + a_2x^2 + a_3x^3 + \\cdots + a_nx^n \\\\\n &= a_0 + x \\bigg(a_1 + x \\Big(a_2 + x \\big(a_3 + \\cdots + x(a_{n-1} + x \\, a_n) \\cdots \\big) \\Big) \\bigg) \\\\\n\\end{align}</math>\n\nThis allows evaluation of a polynomial of degree {{mvar|n}} with only <math>n</math> multiplications and <math>n</math> additions. This is optimal, since there are polynomials of degree {{mvar|n}} that cannot be evaluated with fewer arithmetic operations.{{cn|date=November 2018}}\n\nThis algorithm is much older than Horner. He himself ascribed it to [[Joseph-Louis Lagrange]] but it can be traced back many hundreds of years to Chinese and Persian mathematicians.<ref>600 years earlier, by the Chinese mathematician [[Qin Jiushao]] and 700 years earlier, by the Persian mathematician [[Sharaf al-Dīn al-Ṭūsī]]</ref>\n\nHorner's root-finding method: Until computers came into general use in about 1970 the term 'Horner's method' was used to refer to a root-finding method for polynomials named after Horner who described a similar method in 1819. This method was widely used and became a standard method for hand calculation. It gave a convenient way for using the [[Newton's method|Newton–Raphson method]] for polynomials. It relied on the algorithm for polynomial evaluation now named after Horner. After the introduction of computers this root-finding method went out of use and as a result the term Horner's method (rule etc) has become understood to mean just the polynomial evaluation algorithm.\n\n== Description of the algorithm ==\n\nGiven the polynomial\n\n:<math>p(x) = \\sum_{i=0}^n a_i x^i = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots + a_n x^n,</math>\n\nwhere <math>a_0, \\ldots, a_n</math> are constant coefficients, we wish to evaluate the polynomial at a specific value of <math>x</math> that we'll call <math>x_0</math>.\n\nTo accomplish this, we define a new sequence of constants as follows:\n\n:<math>\\begin{align}\nb_n & := a_n \\\\\nb_{n-1} & := a_{n-1} + b_n x_0 \\\\\nb_{n-2} & := a_{n-2} + b_{n-1} x_0 \\\\\n & ~~~ \\vdots \\\\\nb_0 & := a_0 + b_1 x_0.\n\\end{align}</math>\n\nThen <math>b_0</math> is the value of <math>p(x_0)</math>.\n\nTo see why this works, note that the polynomial can be written in the form\n\n:<math>p(x) = a_0 + x \\bigg(a_1 + x \\Big(a_2 + x \\big(a_3 + \\cdots + x(a_{n-1} + x \\, a_n) \\cdots \\big) \\Big) \\bigg) \\ .</math>\n\nThus, by iteratively substituting the <math>b_i</math> into the expression,\n: <math>\n\\begin{align}\np(x_0) & = a_0 + x_0\\Big(a_1 + x_0\\big(a_2 + \\cdots + x_0(a_{n-1} + b_n x_0) \\cdots \\big)\\Big) \\\\\n& = a_0 + x_0\\Big(a_1 + x_0\\big(a_2 + \\cdots + x_0 b_{n-1}\\big)\\Big) \\\\\n& ~~ \\vdots \\\\\n& = a_0 + x_0 b_1 \\\\\n& = b_0.\n\\end{align}\n</math>\n\n== Examples ==\n\nEvaluate <math>f(x)=2x^3-6x^2+2x-1</math> for <math>x=3.</math>\n\nWe use [[synthetic division]] as follows:\n\n  ''x<sub>0</sub>''│   ''x<sup>3</sup>''    ''x<sup>2</sup>''    ''x<sup>1</sup>''    ''x<sup>0</sup>''\n  3 │   2    −6     2    −1\n    │         6     0     6\n    └────────────────────────\n        2     0     2     5\n\nThe entries in the third row are the sum of those in the first two. Each entry in the second row is the product of the ''x''-value (3 in this example) with the third-row entry immediately to the left. The entries in the first row are the coefficients of the polynomial to be evaluated. Then the remainder of <math>f(x)</math> on division by <math>x-3</math> is 5.\n\nBut by the [[polynomial remainder theorem]], we know that the remainder is <math>f(3) </math>. Thus <math>f(3) = 5</math>\n\nIn this example, if <math>a_3 = 2, a_2 = -6, a_1 = 2, a_0 = -1</math> we can see that <math>b_3 = 2, b_2 = 0, b_1 = 2, b_0 = 5 </math>, the entries in the third row. So, synthetic division is based on Horner's method.\n\nAs a consequence of the polynomial remainder theorem, the entries in the third row are the coefficients of the second-degree polynomial, the quotient of <math>f(x)</math> on division by <math> x-3 </math>. \nThe remainder is 5. This makes Horner's method useful for [[polynomial long division]].\n\nDivide <math>x^3-6x^2+11x-6</math> by <math>x-2</math>:\n\n  2 │   1    −6    11    −6\n    │         2    −8     6\n    └────────────────────────\n        1    −4     3     0\n\nThe quotient is <math>x^2-4x+3</math>.\n\nLet <math>f_1(x)=4x^4-6x^3+3x-5</math> and <math>f_2(x)=2x-1</math>. Divide <math>f_1(x)</math> by <math>f_2\\,(x)</math> using Horner's method.\n\n \n \n   0.5 │ 4  -6   0   3  -5\n       │     2  -2  -1   1\n └───────────────────────\n         2  -2  -1   1  -2\n\n\nThe third row is the sum of the first two rows, divided by 2. Each entry in the second row is the product of 1 with the third-row entry to the left. The answer is\n\n:<math>\\frac{f_1(x)}{f_2(x)}=2x^3-2x^2-x+1-\\frac{4}{2x-1}.</math> \n\n===Floating-point multiplication and division===\n{{main|multiplication algorithm#Shift and add}}\n\nHorner's method is a fast, code-efficient method for multiplication and division of binary numbers on a [[microcontroller]] with no [[binary multiplier|hardware multiplier]].  One of the binary numbers to be multiplied is represented as a trivial polynomial, where (using the above notation) <math>a_i = 1</math>, and <math>x = 2</math>.  Then, ''x'' (or ''x'' to some power) is repeatedly factored out.  In this [[binary numeral system]] (base 2), <math>x = 2</math>, so powers of 2 are repeatedly factored out.\n\n====Example====\nFor example, to find the product of two numbers (0.15625) and ''m'':\n\n:<math>\n\\begin{align}\n(0.15625) m & = (0.00101_b) m = ( 2^{-3} + 2^{-5}) m = (2^{-3})m + (2^{-5})m \\\\\n & = 2^{-3} (m + (2^{-2})m) = 2^{-3} (m + 2^{-2} (m)).\n\\end{align}\n</math>\n\n====Method====\nTo find the product of two binary numbers ''d'' and ''m'':\n:1. A register holding the intermediate result is initialized to ''d''.\n:2. Begin with the least significant (rightmost) non-zero bit in ''m''.\n::2b. Count (to the left) the number of bit positions to the next most significant non-zero bit.  If there are no more-significant bits, then take the value of the current bit position.\n::2c. Using that value, perform a left-shift operation by that number of bits on the register holding the intermediate result\n:3. If all the non-zero bits were counted, then the intermediate result register now holds the final result.  Otherwise, add d to the intermediate result, and continue in step 2 with the next most significant bit in ''m''.\n\n====Derivation====\nIn general, for a binary number with bit values (<math> d_3 d_2 d_1 d_0 </math>) the product is\n:<math> (d_3 2^3 + d_2 2^2 + d_1 2^1 + d_0 2^0)m = d_3 2^3 m + d_2 2^2 m + d_1 2^1 m + d_0 2^0 m. </math>\nAt this stage in the algorithm, it is required that terms with zero-valued coefficients are dropped, so that only binary coefficients equal to one are counted, thus the problem of multiplication or [[division by zero]] is not an issue, despite this implication in the factored equation:\n\n:<math> = d_0\\left(m + 2 \\frac{d_1}{d_0} \\left(m + 2 \\frac{d_2}{d_1} \\left(m + 2 \\frac{d_3}{d_2} (m)\\right)\\right)\\right). </math>\n\nThe denominators all equal one (or the term is absent), so this reduces to\n:<math> = d_0(m + 2 {d_1} (m + 2 {d_2} (m + 2 {d_3} (m)))),</math>\nor equivalently (as consistent with the \"method\" described above)\n:<math> = d_3(m + 2^{-1} {d_2} (m + 2^{-1}{d_1} (m + {d_0} (m)))). </math>\n\nIn binary (base-2) math, multiplication by a power of 2 is merely a [[arithmetic shift|register shift]] operation.  Thus, multiplying by 2 is calculated in base-2 by an [[arithmetic shift]].  The factor (2<sup>−1</sup>) is a right [[arithmetic shift]], a (0) results in no operation (since 2<sup>0</sup> = 1 is the multiplicative [[identity element]]), and a (2<sup>1</sup>) results in a left arithmetic shift.\nThe multiplication product can now be quickly calculated using only arithmetic shift operations, addition and subtraction.\n\nThe method is particularly fast on processors supporting a single-instruction shift-and-addition-accumulate.  Compared to a C floating-point library, Horner's method sacrifices some accuracy, however it is nominally 13 times faster (16 times faster when the \"[[canonical signed digit]]\" (CSD) form is used) and uses only 20% of the code space.<ref>{{harvnb|Kripasagar|2008|p=62}}.</ref>\n\n=== Polynomial root finding ===\nUsing Horner's method in combination with [[Newton's method]], it is possible to approximate the real roots of a polynomial. The algorithm works as follows. Given a polynomial <math>p_n(x)</math> of degree <math>n</math> with zeros <math> z_n < z_{n-1} < \\cdots < z_1,</math> make some initial guess <math> x_0 </math> such that <math> x_0 > z_1 </math>. Now iterate the following two steps:\n\n1. Using [[Newton's method]], find the largest zero <math>z_1</math> of <math>p_n(x)</math> using the guess <math>x_0</math>.\n\n2. Using Horner's method, divide out <math>(x-z_1)</math> to obtain <math>p_{n-1}</math>. Return to step 1 but use the polynomial <math>p_{n-1}</math> and the initial guess <math>z_1</math>.\n\nThese two steps are repeated until all real zeros are found for the polynomial. If the approximated zeros are not precise enough, the obtained values can be used as initial guesses for Newton's method but using the full polynomial rather than the reduced polynomials.<ref>{{harvnb|Kress|1991|p=112}}.</ref>\n\n==== Example ====\n\n[[File:HornerandNewton.gif|thumb|right|400px|Polynomial root finding using Horner's method]]\n\nConsider the polynomial\n\n: <math>\np_6(x) = (x-3)(x+3)(x+5)(x+8)(x-2)(x-7)\n</math>\n\nwhich can be expanded to\n\n: <math>\np_6(x) = x^6 + 4x^5 - 72x^4 -214x^3 + 1127x^2 + 1602x -5040.\n</math>\n\nFrom the above we know that the largest root of this polynomial is 7 so we are able to make an initial guess of 8. Using Newton's method the first zero of 7 is found as shown in black in the figure to the right. Next <math>p(x)</math> is divided by <math>(x-7)</math> to obtain\n\n: <math>\np_5(x) = x^5 + 11x^4 + 5x^3 - 179x^2 - 126x + 720\n</math>\n\nwhich is drawn in red in the figure to the right. Newton's method is used to find the largest zero of this polynomial with an initial guess of 7. The largest zero of this polynomial which corresponds to the second largest zero of the original polynomial is found at 3 and is circled in red. The degree 5 polynomial is now divided by <math>(x-3)</math> to obtain\n\n: <math>\np_4(x) = x^4 + 14x^3 + 47x^2 - 38x - 240\n</math>\n\nwhich is shown in yellow. The zero for this polynomial is found at 2 again using Newton's method and is circled in yellow. Horner's method is now used to obtain\n\n: <math>\np_3(x) = x^3 + 16x^2 + 79x + 120\n</math>\n\nwhich is shown in green and found to have a zero at&nbsp;&minus;3. This polynomial is further reduced to\n\n: <math>\np_2(x) = x^2 + 13x + 40\n</math>\n\nwhich is shown in blue and yields a zero of&nbsp;&minus;5. The final root of the original polynomial may be found by either using the final zero as an initial guess for Newton's method, or by reducing <math>p_2(x)</math> and solving the linear equation. As can be seen, the expected roots of &minus;8, &minus;5, &minus;3, 2, 3, and 7 were found.\n\n== Application ==\n\nHorner's method can be used to convert between different positional [[numeral system]]s – in which case ''x'' is the base of the number system, and the ''a''<sub>''i''</sub> coefficients are the digits of the base-''x'' representation of a given number – and can also be used if ''x'' is a [[matrix (math)|matrix]], in which case the gain in computational efficiency is even greater. In fact, when ''x'' is a matrix, further acceleration is possible which exploits the structure of [[matrix multiplication]], and only <math>\\sqrt{n}</math> instead of ''n'' multiplies are needed (at the expense of requiring more storage) using the 1973 method of Paterson and Stockmeyer.<ref>{{harvnb|Higham|2002|loc=Section 5.4}}.</ref>\n\n== Efficiency ==\n\nEvaluation using the monomial form of a degree-''n'' polynomial requires at most ''n'' additions and (''n''<sup>2</sup>&nbsp;+&nbsp;''n'')/2 multiplications, if powers are calculated by repeated multiplication and each monomial is evaluated individually.  (This can be reduced to ''n'' additions and 2''n''&nbsp;&minus;&nbsp;1 multiplications by evaluating the powers of ''x'' iteratively.)  If numerical data are represented in terms of digits (or bits), then the naive algorithm also entails storing approximately 2''n'' times the number of bits of ''x'' (the evaluated polynomial has approximate magnitude ''x<sup>n</sup>'', and one must also store ''x<sup>n</sup>'' itself).  By contrast, Horner's method requires only ''n'' additions and ''n'' multiplications, and its storage requirements are only ''n'' times the number of bits of ''x''. Alternatively, Horner's method can be computed with ''n'' [[fused multiply–add]]s.  Horner's method can also be extended to evaluate the first ''k'' derivatives of the polynomial with ''kn'' additions and multiplications.<ref>{{harvnb|Pankiewicz|1968}}.</ref>\n\nHorner's method is optimal, in the sense that any algorithm to evaluate an arbitrary polynomial must use at least as many operations. [[Alexander Ostrowski]] proved in 1954 that the number of additions required is minimal.<ref>{{harvnb|Ostrowski|1954}}.</ref> [[Victor Pan]] proved in 1966 that the number of multiplications is minimal.<ref>{{harvnb|Pan|1966}}.</ref> However, when ''x'' is a matrix, Horner's method is not optimal.{{Citation needed|date=September 2017}}\n\nThis assumes that the polynomial is evaluated in monomial form and no [[preconditioning]] of the representation is allowed, which makes sense if the polynomial is evaluated only once. However, if preconditioning is allowed and the polynomial is to be evaluated many times, then faster algorithms are possible. They involve a transformation of the representation of the polynomial. In general, a degree-''n'' polynomial can be evaluated using only {{floor|''n''/2}}+2 multiplications and ''n'' additions.<ref>{{harvnb|Knuth|1997}}.</ref>\n\n===Parallel evaluation===\n{{also|Estrin's scheme}}\nA disadvantage of Horner's rule is that all of the operations are [[data dependency|sequentially dependent]], so it is not possible to take advantage of [[instruction level parallelism]] on modern computers.  In most applications where the efficiency of polynomial evaluation matters, many low-order polynomials are evaluated simultaneously (for each pixel or polygon in computer graphics, or for each grid square in a numerical simulation), so it is not necessary to find parallelism within a single polynomial evaluation.\n\nIf, however, one is evaluating a single polynomial of very high order, it may be useful to break it up as follows:\n:<math>\\begin{align}\np(x) & = \\sum_{i=0}^n a_i x^i \\\\\n     & = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots + a_n x^n \\\\\n     & = \\left( a_0 + a_2 x^2 + a_4 x^4 + \\cdots\\right) + \\left(a_1 x + a_3 x^3 + a_5 x^5 + \\cdots \\right) \\\\\n     & = \\left( a_0 + a_2 x^2 + a_4 x^4 + \\cdots\\right) + x \\left(a_1 + a_3 x^2 + a_5 x^4 + \\cdots \\right) \\\\\n     & = \\sum_{i=0}^{\\lfloor n/2 \\rfloor} a_{2i} x^{2i} + x \\sum_{i=0}^{\\lfloor n/2 \\rfloor} a_{2i+1} x^{2i} \\\\\n     & = p_0(x^2) + x p_1(x^2). \\\\\n\\end{align}</math>\n\nMore generally, the summation can be broken into ''k'' parts:\n:<math>\\begin{align}\np(x) & = \\sum_{i=0}^n a_i x^i \\\\\n     & = \\sum_{j=0}^{k-1} x^j \\sum_{i=0}^{\\lfloor n/k \\rfloor} a_{ki+j} x^{ki} \\\\\n     & = \\sum_{j=0}^{k-1} x^j p_j(x^k) \\\\\n\\end{align}</math>\nwhere the inner summations may be evaluated using separate parallel instances of Horner's method.  This requires slightly more operations than the basic Horner's method, but allows ''k''-way [[SIMD]] execution of most of them.\n\n== Divided difference of a polynomial ==\n\nHorner's method can be modified to compute the divided difference <math>(p(y) - p(x))/(y - x).</math> Given the polynomial (as before)\n\n:<math>p(x) = \\sum_{i=0}^n a_i x^i = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots + a_n x^n,</math>\n\nproceed as follows<ref name=\"Fateman & Kahan\">{{harvnb|Fateman|Kahan|2000}}</ref>\n\n:<math>\\begin{align}\nb_n & = a_n,                 &\\quad d_n &= b_n, \\\\\nb_{n-1} & = a_{n-1} + b_n x, &\\quad d_{n-1} &= b_{n-1} + d_n y, \\\\\n& {}\\  \\  \\vdots             &\\quad &  {}\\ \\ \\vdots\\\\\nb_1 & = a_1 + b_2 x,         &\\quad d_1 &= b_1 + d_2 y,\\\\\nb_0 & = a_0 + b_1 x.\n\\end{align}</math>\n\nAt completion, we have\n:<math>\\begin{align}\np(x) &= b_0, \\\\\n\\frac{p(y) - p(x)}{y - x} &= d_1, \\\\\np(y) &= b_0 + (y - x) d_1.\n\\end{align}</math>\nThis computation of the divided difference is subject to less\nround-off error than evaluating <math>p(x)</math> and <math>p(y)</math> separately, particularly when\n<math> x \\approx y</math>.  Substituting\n<math>y = x</math> in this method gives <math>d_1 = p'(x)</math>, the derivative of <math>p(x)</math>.\n\n== History ==\n[[File:Qingjiushaoquad1.GIF|thumb|right|200px|[[Qin Jiushao]]'s algorithm for solving the quadratic polynomial equation<math>-x^4+763200x^2-40642560000=0</math><br />result: x=840<ref>{{harvnb|Libbrecht|2005|pages=181&ndash;191}}.</ref>]]\nHorner's paper, titled \"A new method of solving numerical equations of all orders, by continuous approximation\",<ref name=\"Horner\">{{harvnb|Horner|1819}}.</ref> was read before the Royal Society of London, at its meeting on July 1, 1819, with [[Davies Gilbert]], Vice-President and Treasurer, in the chair; this was the final [http://hdl.handle.net/2027/mdp.39015014105277?urlappend=%3Bseq=158 meeting] of the session before the Society adjourned for its Summer recess. When a sequel was read before the Society in 1823, it was again at the final meeting of the session. On both occasions, papers by [[James Ivory (mathematician)|James Ivory]], FRS, were also read. In 1819, it was Horner's paper that got through to publication in the \"Philosophical Transactions\".<ref name=\"Horner\" /> later in the year, Ivory's paper falling by the way, despite Ivory being a Fellow; in 1823, when a total of ten papers were read, fortunes as regards publication, were reversed. Gilbert, who had strong connections with the West of England and may have had social contact with Horner, resident as Horner was in Bristol and Bath, published his own [http://turing.une.edu.au/~ernie/Horner/Gilbert1823QJSLA.pdf survey] of Horner-type methods earlier in 1823.\n\nHorner's paper in Part II of ''Philosophical Transactions of the Royal Society of London'' for 1819 was warmly and expansively welcomed by a [http://turing.une.edu.au/~ernie/Horner/Horner1820MonthlyRev91-4.pdf reviewer] in the issue of ''The Monthly Review: or, Literary Journal'' for April, 1820; in comparison, a technical paper by [[Charles Babbage]] is dismissed curtly in this review. However, the reviewer noted that another, similar method had also recently been published by the architect and mathematical expositor, Peter Nicholson. This theme is developed in a further [http://turing.une.edu.au/~ernie/Horner/Horner1820MonthlyRev93-12.pdf review] of some of Nicholson's books in the issue of ''The Monthly Review'' for December, 1820, which in turn ends with notice of the appearance of a booklet by Theophilus Holdred, from whom Nicholson acknowledges he obtained the gist of his approach in the first place, although claiming to have improved upon it. The sequence of reviews is concluded in the issue of ''The Monthly Review'' for September, 1821, with the [http://turing.une.edu.au/~ernie/Horner/Horner1821MonthlyRev96-9.pdf reviewer] concluding that whereas Holdred was the first person to discover a direct and general practical solution of numerical equations, he had not reduced it to its simplest form by the time of Horner's publication, and saying that had Holdred published forty years earlier when he first discovered his method, his contribution could be more easily recognized. The reviewer is exceptionally well-informed, even having cited Horner's preparatory correspondence with [[Peter Barlow (mathematician)|Peter Barlow]] in 1818, seeking work of [[François Budan de Boislaurent|Budan]]. The Bodlean Library, Oxford has the Editor's annotated copy of ''The Monthly Review'' from which it is clear that the most active reviewer in mathematics in 1814 and 1815 (the last years for which this information has been published) was none other than Peter Barlow, one of the foremost specialists on approximation theory of the period, suggesting that it was Barlow, who wrote this sequence of reviews. As it also happened, Henry Atkinson, of Newcastle, devised a similar approximation scheme in 1809; he had consulted his fellow [[Geordie]], [[Charles Hutton]], another specialist and a senior colleague of Barlow at the Royal Military Academy, Woolwich, only to be advised that, while his work was publishable, it was unlikely to have much impact. J. R. Young, writing in the mid-1830s, concluded that Holdred's first method replicated Atkinson's while his improved method was only added to Holdred's booklet some months after its first appearance in 1820, when Horner's paper was already in circulation.\n\nThe feature of Horner's writing that most distinguishes it from his English contemporaries is the way he draws on the Continental literature, notably the work of [[Louis François Antoine Arbogast|Arbogast]]. The advocacy, as well as the detraction, of Horner's Method has this as an unspoken subtext. Quite how he gained that familiarity has not been determined. Horner is known to have made a close reading of John Bonneycastle's book on algebra. Bonneycastle recognizes that Arbogast has the general, combinatorial expression for the reversion of series, a project going back at least to Newton. But Bonneycastle's main purpose in mentioning Arbogast is not to praise him, but to observe that Arbogast's notation is incompatible with the approach he adopts. The gap in Horner's reading was the work of [[Paolo Ruffini]], except that, as far as awareness of Ruffini goes, citations of Ruffini's work by authors, including medical authors, in ''Philosophical Transactions'' speak volumes, as there are none&nbsp;— Ruffini's name<ref>http://hdl.handle.net/2027/njp.32101013501372?urlappend=%3Bseq=695</ref> only appears in 1814, recording a work he donated to the Royal Society. Ruffini might have done better if his work had appeared in French, as had [[Malfatti circles|Malfatti's Problem]] in the reformulation of [[Joseph Diez Gergonne]], or had he written in French, as had [[:it:Antonio Cagnoli|Antonio Cagnoli]], a source quoted by Bonneycastle on series reversion. (Today, Cagnoli is in the Italian Wikipedia, as shown, but has yet to make it into either French or English.)\n\nFuller<ref>{{harvnb|Fuller|1999|pages=29–51}}.</ref> showed that the method in Horner's 1819 paper differs from what afterwards became known as \"Horner's method\" and that in consequence the priority for this method should go to Holdred (1920). This view may be compared with the remarks concerning the works of Horner and Holdred in the previous paragraph. Fuller also takes aim at [[Augustus De Morgan]]. Precocious though Augustus de Morgan was, he was not the reviewer for ''The Monthly Review'', while several others&nbsp;— [[Thomas Stephens Davies]], J. R. Young, Stephen Fenwick, T. T. Wilkinson&nbsp;— wrote Horner firmly into their records, not least Horner, as he published extensively up until the year of his death in 1837. His paper in 1819 was one that would have been difficult to miss. In contrast, the only other mathematical sighting of Holdred is a single named contribution to ''The Gentleman's Mathematical Companion'', an answer to a problem.\n\nIt is questionable to what extent it was De Morgan's advocacy of Horner's priority in discovery<ref name=\"Cajori\">{{harvnb|Cajori|1911}}.</ref><ref name=\"St Andrews\" /> that led to \"Horner's method\" being so called in textbooks, but it is true that those suggesting this tend to know of Horner largely through intermediaries, of whom De Morgan made himself a prime example. However, this method ''qua'' method was known long before Horner. In reverse chronological order, Horner's method was already known to:\n\n* [[Paolo Ruffini]] in 1809 (see [[Ruffini's rule]])<ref name=\"Cajori\" /><ref name=\"St Andrews\">{{MacTutor|id=Horner}}</ref>\n* [[Isaac Newton]] in 1669 (but precise reference needed)\n* the [[Chinese mathematics|Chinese mathematician]] [[Zhu Shijie]] in the 14th century<ref name=\"St Andrews\" />\n* the [[Chinese mathematics|Chinese mathematician]] [[Qin Jiushao]] in his ''[[Mathematical Treatise in Nine Sections]]'' in the 13th century\n* the [[Persian people|Persian]] [[Mathematics in medieval Islam|mathematician]] [[Sharaf al-Dīn al-Ṭūsī ]] in the 12th century (the first to use that method in a general case of cubic equation)<ref>{{harvnb|Berggren|1990|pages=304–309}}.</ref>\n* the Chinese mathematician [[Jia Xian]] in the 11th century ([[Song dynasty]])\n* ''[[The Nine Chapters on the Mathematical Art]]'', a Chinese work of the [[Han dynasty]] (202 BC&nbsp;– 220 AD) edited by [[Liu Hui]] (fl. 3rd century).<ref>{{harvnb|Temple|1986|p=142}}.</ref>\n\nHowever, this observation on its own masks significant differences in conception and also, as noted with Ruffini's work, issues of accessibility.\n\n[[Qin Jiushao]], in his ''Shu Shu Jiu Zhang'' (''[[Mathematical Treatise in Nine Sections]]''; 1247), presents a portfolio of methods of Horner-type for solving polynomial equations, which was based on earlier works of the 11th century Song dynasty mathematician [[Jia Xian]]; for example, one method is specifically suited to bi-quintics, of which Qin gives an instance, in keeping with the then Chinese custom of case studies. The first person writing in English to note the connection with Horner's method was [[Alexander Wylie (missionary)|Alexander Wylie]], writing in ''The North China Herald'' in 1852; perhaps conflating and misconstruing different Chinese phrases, Wylie calls the method ''Harmoniously Alternating Evolution'' (which does not agree with his Chinese, ''linglong kaifang'', not that at that date he uses [[pinyin]]), working the case of one of Qin's quartics and giving, for comparison, the working with Horner's method. [[Yoshio Mikami]] in ''Development of Mathematics in China and Japan'' published in Leipzig in 1913, gave a detailed description of Qin's method, using the quartic illustrated to the above right in a worked example; he wrote:\n{{Quote | style=font-size:100% | text=\"...&nbsp;who can deny the fact of Horner's illustrious process being used in China at least nearly six long centuries earlier than in Europe&nbsp;... We of course don't intend in any way to ascribe Horner's invention to a Chinese origin, but the lapse of time sufficiently makes it not altogether impossible that the Europeans could have known of the Chinese method in a direct or indirect way.\"<ref>{{harvnb|Mikami|1913|p=77}}</ref>}}\nHowever, as Mikami is also aware, it was ''not altogether impossible'' that a related work, ''Si Yuan Yu Jian'' (''Jade Mirror of the Four Unknowns; 1303)'' by [[Zhu Shijie]] might make the shorter journey across to Japan, but seemingly it never did, although another work of Zhu, ''Suan Xue Qi Meng'', had a seminal influence on the development of traditional mathematics in the Edo period, starting in the mid-1600s. [[Ulrich Libbrecht]] (at the time teaching in school, but subsequently a professor of comparative philosophy) gave a detailed description in his doctoral thesis of Qin's method, he concluded: ''It is obvious that this procedure is a Chinese invention&nbsp;... the method was not known in India''. He said, Fibonacci probably learned of it from Arabs, who perhaps borrowed from the Chinese.<ref>{{harvnb|Libbrecht|2005|p=208}}.</ref> Here, the problems is that there is no more evidence for this speculation than there is of the method being known in India. Of course, the extraction of square and cube roots along similar lines is already discussed by [[Liu Hui]] in connection with Problems IV.16 and 22 in ''Jiu Zhang Suan Shu'', while [[Wang Xiaotong]] in the 7th century supposes his readers can solve cubics by an approximation method described in his book [[Jigu Suanjing]].\n\n== See also ==\n\n*[[Clenshaw algorithm]] to evaluate polynomials in [[Chebyshev form]]\n*[[De Boor's algorithm]] to evaluate [[spline curve|splines]] in [[B-spline]] form\n*[[De Casteljau's algorithm]] to evaluate polynomials in [[Bézier form]]\n*[[Estrin's scheme]] to facilitate parallelization on modern computer architectures\n*[[Lill's method]] to approximate roots graphically\n*[[Ruffini's rule]] to divide a polynomial by a binomial of the form x − r\n\n== Notes ==\n{{Reflist}}\n\n== References ==\n\n*{{cite journal\n | last = Berggren\n | first = J. L.\n | year = 1990\n | title = Innovation and Tradition in Sharaf al-Din al-Tusi's Muadalat\n | journal = Journal of the American Oriental Society\n | volume = 110\n | issue = 2\n | pages = 304–309\n | doi = 10.2307/604533\n | ref = harv\n | jstor = 604533\n }}\n*{{cite journal\n | last = Cajori\n | first = Florian\n | author-link = Florian Cajori\n | title = Horner's method of approximation anticipated by Ruffini\n | journal = Bulletin of the American Mathematical Society\n | volume = 17\n | number = 8\n | pages = 409&ndash;414\n | year = 1911\n | url = http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&id=pdf_1&handle=euclid.bams/1183421253\n | ref = harv\n | doi = 10.1090/s0002-9904-1911-02072-9\n}} Read before the Southwestern Section of the American Mathematical Society on November 26, 1910.\n*{{cite journal\n | last1 = Cormen\n | first1 = Thomas H.\n | author1-link = Thomas H. Cormen\n | last2 = Leiserson\n | first2 = Charles E.\n | author2-link = Charles E. Leiserson\n | last3 = Rivest\n | first3 = Ronald L.\n | author3-link = Ron Rivest\n | last4 = Stein10.1016/0315-0860(81)90069-0\n | first4 = Clifford\n | author4-link = Clifford Stein\n | title = Introduction to Algorithms\n | journal = Historia Mathematica\n | volume = 8\n | issue = 3\n | pages = 277–318\n | edition = 3rd\n | year = 2009\n | publisher = MIT Press\n | ref = harv\n| doi = 10.1016/0315-0860(81)90069-0\n }}\n*{{cite report\n | last1 = Fateman\n | first1 = R. J.\n | authorlink1 = Richard Fateman\n | last2 = Kahan\n | first2 = W.\n | authorlink2 = William Kahan\n | title = Improving exact integrals from symbolic algebra systems\n | series = PAM\n | number = 386\n | year = 2000\n | institution = Center for Pure and Applied Mathematics\n | location = University of California, Berkeley\n | url = https://people.eecs.berkeley.edu/~fateman/papers/nform.pdf\n | ref = harv\n}}\n*{{cite journal\n | last = Fuller\n | first = A. T.\n | title = Horner versus Holdred: An Episode in the History of Root Computation\n | journal = Historia Mathematica\n | volume = 26\n | year = 1999\n | ref = harv\n | doi = 10.1006/hmat.1998.2214\n | pages=29–51\n}}\n*{{cite book\n | last = Higham\n | first = Nicholas\n | year = 2002\n | title = Accuracy and Stability of Numerical Algorithms\n | publisher = SIAM\n | isbn = 978-0-89871-521-7\n | ref = harv\n}}\n*{{cite book\n | last = Holdred\n | first = T.\n | year = 1820\n | url = http://turing.une.edu.au/~ernie/Horner/Holdred1820.pdf\n | title = A New Method of Solving Equations with Ease and Expedition; by which the True Value of the Unknown Quantity is Found Without Previous Reduction. With a Supplement, Containing Two Other Methods of Solving Equations, Derived from the Same Principle\n | publisher = Richard Watts\n | ref = harv\n}}\n*: Holdred's method is in the supplement following page numbered 45 (which is the 52nd page of the pdf version).\n*{{cite journal|last = Horner|first = William George|author-link = William George Horner|date = July 1819|title = A new method of solving numerical equations of all orders, by continuous approximation|url=https://www.ece.cmu.edu/~ece447/s15/lib/exe/fetch.php?media=horner-1819.pdf|journal = Philosophical Transactions|publisher = Royal Society of London|volume=109|pages = pp.&nbsp;308&ndash;335|jstor=107508|ref = harv|via=|doi = 10.1098/rstl.1819.0023}}\n*: Directly available online via the link, but also reprinted with appraisal in D.E. Smith: ''A Source Book in Mathematics'', McGraw-Hill, 1929; Dover reprint, 2 vols, 1959.\n*{{cite book\n | last = Knuth\n | first = Donald\n | author-link = Donald Knuth\n | title = The Art of Computer Programming\n | volume = Vol. 2: Seminumerical Algorithms\n | edition = 3rd\n | year = 1997\n | publisher = Addison-Wesley\n | isbn = 978-0-201-89684-8\n | pages = 486&ndash;488 in section 4.6.4\n | ref = harv\n}}\n*{{cite book\n | last = Kress\n | first = Rainer\n | title = Numerical Analysis\n | publisher = Springer\n | year = 1991\n | ref = harv\n}}\n*{{cite journal\n | last = Kripasagar \n | first =  Venkat\n | title = Efficient Micro Mathematics &ndash; Multiplication and Division Techniques for MCUs\n | journal = Circuit Cellar Magazine\n | issue = 212\n | date = March 2008\n | ref = harv\n}}\n*{{cite book\n | last = Libbrecht\n | first = Ulrich\n | title = Chinese Mathematics in the Thirteenth Century\n | chapter = Chapter 13\n | edition = 2nd\n | year = 2005\n | publisher = Dover\n | isbn = 978-0-486-44619-6\n | ref = harv\n | chapter-url = http://store.doverpublications.com/0486446190.html\n}}\n*{{cite book\n | last = Mikami\n | first = Yoshio\n | title = The Development of Mathematics in China and Japan\n | chapter = Chapter 11. Ch'in Chiu-Shao\n | edition = 1st\n | year = 1913\n | publisher = Chelsea Publishing Co reprint\n | pages = 74–77\n | chapter-url = https://archive.org/stream/treatiseindynami033561mbp#page/n89/mode/2up\n | ref = harv\n}} <!-- Yes, really! It looks as though the link is taking you to a completely different work, but you end up at Mikami's book, as you find on checking the specified pages. -->\n*{{cite book\n | last = Ostrowski\n | first = Alexander M.\n | year = 1954\n | chapter = On two problems in abstract algebra connected with Horner's rule\n | title = Studies in Mathematics and Mechanics presented to Richard von Mises\n | pages = 40–48\n | publisher = Academic Press\n | isbn = 978-1-4832-3272-0\n | chapter-url = http://www.sciencedirect.com/science/book/9781483232720\n | ref = harv\n}}\n*{{cite journal\n | last = Pan\n | first = Y. Ja\n | year = 1966\n | title = On means of calculating values of polynomials\n | journal = Russian Math. Surveys\n | volume = 21\n | pages = 105–136\n | doi = 10.1070/rm1966v021n01abeh004147\n | ref = harv\n}}\n*{{cite journal\n | last = Pankiewicz\n | first = W.\n | url = http://portal.acm.org/citation.cfm?doid=364063.364089\n | title = Algorithm 337: calculation of a polynomial and its derivative values by Horner scheme\n | journal = [[Communications of the ACM]]\n | volume = 11\n | issue = 9\n | year = 1968\n | page = 633\n | publisher = ACM\n | ref = harv\n | doi=10.1145/364063.364089\n}}\n*{{cite book\n | last = Spiegel\n | first = Murray R.\n | title = Schaum's Outline of Theory and Problems of College Algebra\n | year = 1956\n | publisher = McGraw-Hill\n | ref = harv\n}}\n*{{cite book\n | last = Temple\n | first = Robert\n | year = 1986\n | title = The Genius of China: 3,000 Years of Science, Discovery, and Invention\n | publisher = Simon and Schuster\n | isbn = 978-0-671-62028-8\n | ref = harv\n}}\n* {{cite book\n | last1 = Whittaker\n | first1 = E.T.\n | author1-link = E._T._Whittaker\n | last2 = Robinson\n | first2 = G.\n | title = The Calculus of Observations\n | location = London\n | year = 1924\n | publisher = Blackie\n | url = https://archive.org/stream/calculusofobserv031400mbp#page/n119/mode/2up/search/100\n | ref = harv\n}}\n* {{cite book\n | last = Wylie\n | first = Alexander\n | title = Chinese Researches\n | chapter = Jottings on the Science of Chinese Arithmetic\n | year = 1897\n | pages = 159–194\n | location = Shanghai\n | chapter-url = https://archive.org/details/chineseresearche00wyliuoft\n | ref = harv\n}}\n*: Reprinted from issues of ''The North China Herald'' (1852).\n\n== External links ==\n* {{springer|title=Horner scheme|id=p/h048030}}\n* Qiu Jin-Shao, [http://turing.une.edu.au/~ernie/Chinese/SSJZ.pdf Shu Shu Jiu Zhang] (Cong Shu Ji Cheng ed.)\n\n{{DEFAULTSORT:Horner Scheme}}\n[[Category:Algebra]]\n[[Category:Polynomials]]\n[[Category:Numerical analysis]]\n[[Category:Articles with example Python code]]\n[[Category:Articles with example MATLAB/Octave code]]\n[[Category:Articles with example C code]]"
    },
    {
      "title": "Howson property",
      "url": "https://en.wikipedia.org/wiki/Howson_property",
      "text": "In the mathematical subject of [[group theory]], the '''Howson property''', also known as the '''finitely generated intersection property (FGIP)''', is the property of a group saying that the intersection of any two finitely generated subgroups of this group is again finitely generated. The property is named after [[Albert G. Howson]] who in a 1954 paper established that [[free group]]s have this property.<ref>A. G. Howson, ''On the intersection of finitely generated free groups''. \n[[Journal of the London Mathematical Society]] '''29''' (1954), 428–434</ref>\n\n==Formal definition==\n\nA [[group (mathematics)|group]] <math>G</math> is said to have the '''Howson property''' if for every [[finitely generated group|finitely generated]] [[subgroup]]s <math>H,K</math> of <math>G</math> their intersection <math>H\\cap K</math> is again a finitely generated subgroup of <math>G</math>.<ref>O. Bogopolski, \n[https://books.google.com/books?id=jEw8MpP6DIgC&pg=PA103&dq=Howson+property&hl=en&sa=X&ved=0ahUKEwjGg4TZjOHWAhWJ7IMKHRwcBqQQ6AEIKDAA#v=onepage&q=Howson%20property&f=false ''Introduction to group theory''.] \nTranslated, revised and expanded from the 2002 Russian original. EMS Textbooks in Mathematics. European Mathematical Society (EMS), Zürich, 2008.  {{ISBN|978-3-03719-041-8}}; p. 102</ref>\n\n==Examples and non-examples==\n\n*Every finite group has the Howson property.\n*The group <math>G=F(a,b)\\times \\mathbb Z</math> does not have the Howson property.  Specifically, if <math>t</math> is the generator of the <math>\\mathbb Z</math> factor of <math>G</math>, then for <math>H=F(a,b)</math> and <math>K=\\langle a,tb\\rangle \\le G </math>, one has <math>H\\cap K=\\operatorname{ncl}_{F(a,b)}(a)</math>. Therefore, <math>H\\cap K</math> is not finitely generated.<ref name=Mol>D. I. Moldavanskii, ''The intersection of finitely generated subgroups'' {{icon ru}} Siberian Mathematical Journal '''9''' (1968), 1422–1426</ref> \n*If <math>\\Sigma</math> is a compact surface then the [[fundamental group]] <math>\\pi_1(\\Sigma)</math> of <math>\\Sigma</math> has the Howson property.<ref>L. Greenberg, ''Discrete groups of motions''. \n[[Canadian Journal of Mathematics]] '''12''' (1960), 415–426</ref>\n*A [[free-by-cyclic group|free-by-(infinite cyclic group)]] <math>F_n\\rtimes \\mathbb Z</math>, where <math>n\\ge 2</math>, never has the Howson property.<ref>R. G. Burns and A. M. Brunner, ''Two remarks on the group property of Howson'', Algebra i Logika '''18''' (1979), 513–522</ref>\n*In view of the recent proof of the [[Virtually Haken conjecture]] and the [[Virtually fibered conjecture]] for 3-manifolds, previously established results imply that if ''M'' is a closed hyperbolic 3-manifold then <math>\\pi_1(M)</math> does not have the Howson property.<ref name=Soma>T. Soma, [http://www.ams.org/journals/tran/1992-331-02/S0002-9947-1992-1042289-4/S0002-9947-1992-1042289-4.pdf 3-manifold groups with the finitely generated intersection property], [[Transactions of the American Mathematical Society]], '''331''' (1992), no. 2, 761–769</ref> \n*Among 3-manifold groups, there are many examples that do and do not have the Howson property. 3-manifold groups with the Howson property include fundamental groups of hyperbolic 3-manifolds of infinite volume, 3-manifold groups based on [[Sol geometry|Sol]] and [[Nil geometry|Nil]] geometries, as well as 3-manifold groups obtained by some connected sum and [[JSJ decomposition]] constructions.<ref name=Soma/>  \n*For every <math>n\\ge 1</math> the [[Baumslag–Solitar group]] <math>BS(1,n)=\\langle a,t\\mid t^{-1}at=a^n\\rangle</math> has the Howson property.<ref name=Mol/> \n*If ''G'' is group where every finitely generated subgroup is [[Noetherian group|Noetherian]] then ''G'' has the Howson property. In particular, all [[abelian group]]s and all [[nilpotent group]]s have the Howson property.  \n*Every polycyclic-by-finite group has the Howson property.<ref name=ASilSyk>V. Araújo, P. Silva, M. Sykiotis, ''Finiteness results for subgroups of finite extensions''. [[Journal of Algebra]] '''423''' (2015), 592–614</ref>\n*If <math>A,B</math> are groups with the Howson property then their free product <math>A\\ast B</math> also has the Howson property.<ref>B. Baumslag, ''Intersections of finitely generated subgroups in free products''. [[Journal of the London Mathematical Society]] '''41''' (1966), 673–679</ref> More generally, the Howson property is preserved under taking amalgamated free products and [[HNN-extension]] of groups with the Howson property over finite subgroups.<ref>D. E. Cohen,\n''Finitely generated subgroups of amalgamated free products and HNN groups''. \nJ. Austral. Math. Soc. Ser. A '''22''' (1976), no. 3, 274–281</ref>\n*In general, the Howson property is rather sensitive to amalgamated products and HNN extensions over infinite subgroups. In particular, for free groups <math>F,F'</math> and an infinite cyclic group <math>C</math>, the amalgamated free product <math>F\\ast_C F'</math> has the Howson property if and only if <math>C</math> is a maximal cyclic subgroup in both <math>F</math> and <math>F'</math>.<ref>R. G. Burns,\n''On the finitely generated subgroups of an amalgamated product of two groups''. \n[[Transactions of the American Mathematical Society]] '''169''' (1972), 293–306</ref>\n*A [[right-angled Artin group]] <math>A(\\Gamma)</math> has the Howson property if and only if every connected component of <math>\\Gamma</math> is a complete graph.<ref>H. Servatius, C. Droms, [[Brigitte Servatius|B. Servatius]], ''The finite basis extension property and graph groups''. Topology and combinatorial group theory (Hanover, NH, 1986/1987; Enfield, NH, 1988), 52–58, \nLecture Notes in Math., 1440, Springer, Berlin, 1990</ref>\n*[[Limit group]]s have the Howson property.<ref>F. Dahmani, [https://archive.org/details/arxiv-math0203258 ''Combination of convergence groups''.] [[Geometry & Topology]] '''7''' (2003), 933–963</ref>\n*It is not known whether <math>SL(3,\\mathbb Z)</math> has the Howson property.<ref name=LR>D. D. Long and A. W. Reid,  [https://projecteuclid.org/download/pdf_1/euclid.em/1323367155 Small Subgroups of <math> SL(3, \\mathbb Z)</math>], [[Experimental Mathematics (journal)|Experimental Mathematics]], 20(4):412–425, 2011</ref>\n*For <math>n\\ge 4</math> the group <math>SL(n,\\mathbb Z)</math> contains a subgroup isomorphic to <math>F(a,b)\\times F(a,b)</math> and does not have the Howson property.<ref name=LR/>\n*Many [[small cancellation theory|small cancellation groups]] and [[Coxeter groups]], satisfying the ``perimeter reduction\" condition on their presentation, are locally quasiconvex [[hyperbolic group|word-hyperbolic groups]] and therefore have the Howson property.<ref>J. P. McCammond, D. T. Wise, ''Coherence, local quasiconvexity, and the perimeter of 2-complexes''. [[Geometric and Functional Analysis]] '''15''' (2005), no. 4, 859–927</ref><ref>P. Schupp, ''Coxeter groups, 2-completion, perimeter reduction and subgroup separability'', [[Geometriae Dedicata]] '''96''' (2003) 179–198</ref>\n*One-relator groups <math>G=\\langle x_1,\\dots, x_k \\mid r^n=1\\rangle</math>, where <math>n\\ge |r|</math> are also locally quasiconvex [[hyperbolic group|word-hyperbolic groups]] and therefore have the Howson property.<ref>G. Ch. Hruska, D. T. Wise, \n''Towers, ladders and the B. B. Newman spelling theorem''.\n[[Journal of the Australian Mathematical Society]] '''71''' (2001), no. 1, 53–69</ref>\n*The [[Grigorchuk group]] ''G'' of intermediate growth does not have the Howson property.<ref>A. V. Rozhkov,\n''Centralizers of elements in a group of tree automorphisms''. {{icon ru}}\nIzv. Ross. Akad. Nauk Ser. Mat. '''57''' (1993), no. 6, 82–105; translation in: \nRussian Acad. Sci. Izv. Math. '''43''' (1993), no. 3, 471–492</ref>\n*The Howson property is not a [[First-order logic|first-order]] property, that is the Howson property cannot be characterized by a collection of first order [[group language]] formulas.<ref>B. Fine, A. Gaglione, A. Myasnikov, G. Rosenberger, D. Spellman, [https://books.google.com/books?id=pgbpBQAAQBAJ&pg=PA236&lpg=PA236&dq=%22Howson+property%22&source=bl&ots=h_NB7Xl1RE&sig=4gPSSIePYnDV-4qKaLgkR3x17-o&hl=en&sa=X&ved=0ahUKEwifvfX7n-PWAhWPwYMKHVufBUk4ChDoAQgzMAM#v=onepage&q=%22Howson%20property%22&f=false ''The elementary theory of groups. A guide through the proofs of the Tarski conjectures.''] De Gruyter Expositions in Mathematics, 60. De Gruyter, Berlin, 2014. {{ISBN|978-3-11-034199-7}}; Theorem 10.4.13 on p. 236</ref>\n*A free [[pro-p group]] <math>F</math> satisfies a topological version of the Howson property: If <math>H,K</math> are topologically finitely generated closed subgroups of <math>F</math> then their intersection <math>H\\cap K</math> is topologically finitely generated.<ref>L. Ribes,  and P. Zalesskii, ''Profinite groups''. Second edition. Ergebnisse der Mathematik und ihrer Grenzgebiete. 3. Folge. A Series of Modern Surveys in Mathematics [Results in Mathematics and Related Areas. 3rd Series. A Series of Modern Surveys in Mathematics], 40. Springer-Verlag, Berlin, 2010. {{ISBN|978-3-642-01641-7}}; Theorem 9.1.20 on p. 366</ref>\n*For any fixed integers <math>m\\ge 2,n\\ge 1,d\\ge 1,</math> a ``generic\" <math>m</math>-generator <math>n</math>-relator group <math>G=\\langle x_1,\\dots x_m|r_1,\\dots, r_n\\rangle</math> has the property that for any <math>d</math>-generated subgroups <math>H,K\\le G</math> their intersection <math>H\\cap K</math> is again finitely generated.<ref>G. N. Arzhantseva, \n''Generic properties of finitely presented groups and Howson's theorem''. \n[[Communications in Algebra]] '''26''' (1998), no. 11, 3783–3792</ref>\n*The [[wreath product]] <math>\\mathbb Z\\ wr\\ \\mathbb Z</math> does not have the Howson property.<ref>A. S. Kirkinski,\n[https://link.springer.com/article/10.1007/BF01669493 ''Intersections of finitely generated subgroups in metabelian groups''.]\n[[Algebra i Logika]] '''20''' (1981), no. 1, 37–54; Lemma 3.</ref>\n\n==See also==\n*[[Hanna Neumann conjecture]]\n\n==References==\n{{Reflist}}\n\n[[Category:Group theory]]\n[[Category:Algebra]]"
    },
    {
      "title": "Hundred Fowls Problem",
      "url": "https://en.wikipedia.org/wiki/Hundred_Fowls_Problem",
      "text": "The '''Hundred Fowls Problem''' is a problem first discussed in the fifth century CE [[Chinese mathematics]] text ''[[Zhang Qiujian Suanjing|Zhang Qiujian suanjing]]'' (The Mathematical Classic of Zhang Qiujian), a book of mathematical problems written by Zhang Qiujian. It is one of the best known examples of indeterminate problems in the early history of mathematics.<ref name=Victor>{{cite book|last1=Victor J. Katz, [[Annette Imhausen]] (Editors)|title=The Mathematics of Egypt, Mesopotamia, China, India, and Islam: A Sourcebook|date=2007|publisher=Princeton University Press|isbn=9780691114859|page=307}}</ref> The problem appears as the final problem in ''Zhang Qiujian suanjing'' (Problem 38 in Chapter 3). However, the problem  and its variants have appeared in the  medieval mathematical literature of  India, Europe and the Arab world.<ref name=\"Nine\">{{cite book|author1=Kangshen Shen |author2=John N. Crossley |author3=Anthony Wah-Cheung Lun |author4=Hui Liu |title=The Nine Chapters on the Mathematical Art: Companion and Commentary|date=1999|publisher=Oxford University Press|isbn=9780198539360|pages=415–420}}</ref>\n\nThe name \"Hundred Fowls Problem\" is due to the Belgian historian Louis van Hee.<ref name=Hist/>\n\n==Problem statement==\n\nThe Hundred Fowls Problem as presented in ''Zhang Qiujian suanjing'' can be translated as follows:<ref name=\"Lam\">{{cite journal|last1=Lam Lay Yong|title=Zhang Qiujian Suanjing (The Mathematical Classic of Zhang Qiujian). An Overview|journal=Archive for History of Exact Sciences|date=September 1997|volume=50|issue=34|pages=201–240|jstor=41134109}}</ref>\n\n: \"Now one cock is worth 5 qian, one hen 3 qian and 3 chicks 1 qian. It is required to buy 100 fowls with 100 qian. In each case, find the number of cocks, hens and chicks bought.\"\n\n==Mathematical formulation==\nLet ''x'' be the number of cocks, ''y'' be the number of hens, and ''z'' be the number of chicks, then the problem is to find ''x'', ''y'' and ''z'' satisfying the following equations:\n\n: ''x'' + ''y'' +''z'' = 100\n: 5''x'' + 3''y'' + ''z''/3 = 100\n\nObviously, only non-negative integer values are acceptable. Expressing ''y'' and ''z'' in terms of ''x'' we get\n\n: ''y'' = 25 &minus; (7/4)''x''\n: ''z'' = 75 + (3/4)''x''\n\nSince ''x'', ''y'' and ''z'' all must be integers, the expression for ''y'' suggests that ''x'' must be a multiple of 4. Hence the general solution of the system of equations can be expressed using an integer parameter ''t'' as follows:<ref>{{cite book|last1=Oystein Ore|title=Number Theory and its History|date=2012|publisher=Courier Corporation|isbn=9780486136431|pages=116–141}}</ref>\n\n: ''x'' = 4''t''\n: ''y'' = 25 &minus; 7''t''\n: ''z'' = 75 + 3''t''\n\nSince ''y'' should be a non-negative integer, the only possible values of ''t'' are 0, 1, 2 and 3. So the complete set of solutions is given by\n\n:(''x'',''y'',''z'') = (0,25,75), (4,18,78), (8,11,81), (12,4,84).\n\nof which the last three have been given in ''Zhang Qiujian suanjing''.<ref name=Hist/>  However, no general method for solving such problems has been indicated, leading to a suspicion of whether the solutions have been obtained by trial and error.<ref name=Victor/>\n\nThe Hundred Fowls Problem found in ''Zhang Qiujian suanjing'' is a special case of the general problem of finding integer solutions of the following system of equations:\n\n: ''x'' + ''y'' + ''z'' = ''d''\n: ''ax'' + ''by'' + ''cz'' = ''d''\n\nAny problem of this type is sometime referred to as \"Hundred Fowls problem\".<ref name=\"Hist\">{{cite book|last1=Jean-Claude Martzloff|title=A History of Chinese Mathematics|date=1997|publisher=Springer-verlag|location=Berlin|pages=307–309}}</ref>\n\n==Variations==\n\nSome variants of the Hundred Fowls Problem have appeared in the mathematical literature of several cultures.<ref name=Victor/><ref name=\"Nine\"/> In the following we present a few sample problems discussed in these cultures.\n\n===Indian mathematics===\n[[Mahāvīra (mathematician)|Mahavira]]'s ''Ganita-sara-sangraha'' contains the following problem:\n\n:Pigeons are sold at the rate of 5 for 3, sarasa-birds at the rate of 7 for 5, swans at the rate of 9 for 7, and peacocks at the rate of 3 for 9 (''pana''s).  A certain man was told to bring 100 birds for 100 ''pana''s. What does he give for each of the various kinds of birds he buys?\n\nThe [[Bakshali manuscript]] gives the problem of solving the following equations:\n\n:''x'' + ''y'' + ''z'' = 20\n:3''x'' + (3/2)''y'' + (1/2)''z'' = 20\n\n===Medieval Europe===\nThe English mathematician [[Alcuin]] of York (6th century) has stated seven problems similar to the Hundred Fowls Problem in his ''Propositiones ad acuendos iuvenes''. Here is a typical problem:\n\n:If 100 bushels of corn be distributed among 100 people such that each man gets 3 bushels, each woman 2 bushels and each child half a bushel, then how many men, women and children were there?\n\n===Arabian mathematics===\n[[Abu Kamil]] (850 - 930 CE) considered non-negative integer solutions of the following equations:\n:''x'' + ''y'' + ''z'' = 100\n:3''x'' + (/20)''y''+ (1/3)''z'' = 100.\n\n==References==\n{{reflist}}\n\n[[Category:Chinese mathematics]]\n[[Category:Algebra]]\n[[Category:Number theory]]\n[[Category:Diophantine equations]]"
    },
    {
      "title": "Idempotent matrix",
      "url": "https://en.wikipedia.org/wiki/Idempotent_matrix",
      "text": "{{Use American English|date = January 2019}}\n{{Short description|Matrix that, squared, equals itself}}\nIn [[linear algebra]], an '''idempotent matrix''' is a [[matrix (mathematics)|matrix]] which, when multiplied by itself, yields itself.<ref>{{cite book |last=Chiang |first=Alpha C. |title=Fundamental Methods of Mathematical Economics |publisher=McGraw–Hill |edition=3rd |year=1984 |page=80 |location=New York |isbn=0070108137 }}</ref><ref name=Greene>{{cite book |last=Greene |first=William H. |title=Econometric Analysis |publisher=Prentice–Hall |location=Upper Saddle River, NJ |edition=5th |year=2003 |pages=808–809 |isbn=0130661899 }}</ref> That is, the matrix <math>A</math> is idempotent if and only if <math>A^2 = A</math>. For this product <math>A^2</math> to be [[matrix multiplication|defined]], <math>A</math> must necessarily be a [[square matrix]]. Viewed this way, idempotent matrices are [[idempotent element (ring theory)|idempotent element]]s of [[matrix ring]]s.\n\n==Definition==\nA <math>n \\times n</math> [[square matrix]] <math>A</math> is called '''idempotent''' if, multiplied by itself, yields itself, i.e.\n\n{{Equation box 1\n|indent =\n|title=\n|equation = <math>A \\text{ idempotent} \\quad \\iff \\quad A^2 = A</math>\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\n\n==Example==\nExamples of <math>2 \\times 2</math> idempotent matrices are:\n<math display=\"block\">\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\n\\qquad\n\\begin{bmatrix}\n3 & -6 \\\\\n1 & -2\n\\end{bmatrix}\n</math>\n\nExamples of <math>3 \\times 3</math> idempotent matrices are:\n<math display=\"block\">\n\\begin{bmatrix}\n 1 & 0 & 0 \\\\\n 0 & 0 & 0 \\\\\n 0 & 0 & 1\n\\end{bmatrix}\n\\qquad\n\\begin{bmatrix}\n 2 & -2 & -4 \\\\\n-1 &  3 &  4 \\\\\n 1 & -2 & -3\n\\end{bmatrix}\n</math>\n\n==Real 2 × 2 case==\nIf a matrix <math>\\begin{pmatrix}a & b \\\\ c & d \\end{pmatrix}</math> is idempotent, then\n* <math>a = a^2 + bc,</math>\n* <math>b = ab + bd,</math> implying <math>b(1 - a - d) = 0</math> so <math>b = 0</math> or <math>d = 1 - a,</math>\n* <math>c = ca + cd,</math> implying <math>c(1 - a - d) = 0</math> so <math>c = 0</math> or <math>d = 1 - a,</math>\n* <math>d = bc + d^2.</math>\n\nThus a necessary condition for a 2 × 2 matrix to be idempotent is that either it is [[diagonal matrix|diagonal]] or its [[trace (linear algebra)|trace]] equals 1.\nNotice that, for idempotent diagonal matrices, <math>a</math> and <math>d</math> must be either 1 or 0.\n\nIf <math>b=c</math>, the matrix <math>\\begin{pmatrix}a & b \\\\ b & 1 - a \\end{pmatrix}</math> will be idempotent provided <math>a^2 + b^2 = a ,</math> so ''a'' satisfies the [[quadratic equation]]\n:<math>a^2 - a + b^2 = 0 ,</math> or <math>\\left(a - \\frac{1}{2}\\right)^2 + b^2 = \\frac{1}{4}</math>\n\nwhich is a [[circle]] with center (1/2, 0) and radius 1/2. In terms of an angle &theta;,\n:<math>A = \\frac{1}{2}\\begin{pmatrix}1 - \\cos\\theta & \\sin\\theta \\\\ \\sin\\theta & 1 + \\cos\\theta \\end{pmatrix}</math> is idempotent.\n\nHowever, <math>b=c</math> is not a necessary condition: any matrix\n:<math>\\begin{pmatrix}a & b \\\\ c & 1 - a\\end{pmatrix}</math> with <math>a^2 + bc = a</math> is idempotent.\n\n==Properties==\n===Singularity and regularity===\nThe only non-[[singular matrix|singular]] idempotent matrix is the [[identity matrix]]; that is, if a non-identity matrix is idempotent, its number of independent rows (and columns) is less than its number of rows (and columns).\n\nThis can be seen from writing <math>A^2 = A</math>, assuming that {{mvar|A}} has full rank (is non-singular), and pre-multiplying by <math>A^{-1}</math> to obtain <math>A = IA = A^{-1}A^2 = A^{-1}A = I</math>.\n\nWhen an idempotent matrix is subtracted from the identity matrix, the result is also idempotent. This holds since\n:<math>(I-A)(I-A) = I-A-A+A^2 = I-A-A+A = I-A</math>.\n\nA matrix {{mvar|A}} is idempotent if and only if for all positive integers n, <math>A^n = A</math>. The 'if' direction trivially follows by taking <math>n=2</math>. The 'only if' part can be shown using proof by induction. Clearly we have the result for <math>n = 1</math>, as <math>A^1 = A</math>. Suppose that <math>A^{k-1} = A</math>. Then, <math>A^k = A^{k-1}A = AA = A</math>, as required. Hence by the principle of induction, the result follows.\n\n===Eigenvalues===\nAn idempotent matrix is always [[diagonalizable]] and its [[eigenvalue]]s are either 0 or 1.<ref>{{cite book |first=Roger A. |last=Horn |first2=Charles R. |last2=Johnson |title=Matrix analysis |publisher=Cambridge University Press |year=1990 |page=[{{Google books|plainurl=y|id=PlYQN0ypTwEC|page=148|text=every idempotent matrix is diagonalizable}} p. 148] |isbn=0521386322 }}</ref>\n\n===Trace===\nThe [[trace (linear algebra)|trace]] of an idempotent matrix — the sum of the elements on its main diagonal — equals the [[rank (linear algebra)|rank]] of the matrix and thus is always an integer. This provides an easy way of computing the rank, or alternatively an easy way of determining the trace of a matrix whose elements are not specifically known (which is helpful in [[statistics]], for example, in establishing the degree of [[bias (statistics)|bias]] in using a [[variance|sample variance]] as an estimate of a [[variance|population variance]]).\n\n==Applications==\nIdempotent matrices arise frequently in [[regression analysis]] and [[econometrics]]. For example, in [[ordinary least squares]], the regression problem is to choose a vector {{mvar|&beta;}} of coefficient estimates so as to minimize the sum of squared residuals (mispredictions) ''e''<sub>''i''</sub>: in matrix form,\n: Minimize <math>(y - X\\beta)^\\textsf{T}(y - X\\beta) </math>\n\nwhere <math>y</math> is a vector of [[Dependent and independent variables#Statistics|dependent variable]] observations, and <math>X</math> is a matrix each of whose columns is a column of observations on one of the [[Dependent and independent variables#Statistics|independent variables]]. The resulting estimator is\n\n:<math>\\hat\\beta = \\left(X^\\textsf{T}X\\right)^{-1}X^\\textsf{T}y </math>\n\nwhere superscript ''T'' indicates a [[transpose]], and the vector of residuals is<ref name=Greene/>\n\n:<math>\n  \\hat{e} = y - X \\hat\\beta\n          = y - X\\left(X^\\textsf{T}X\\right)^{-1}X^\\textsf{T}y\n          = \\left[I - X\\left(X^\\textsf{T}X\\right)^{-1}X^\\textsf{T}\\right]y\n          = My.\n</math>\n\nHere both <math>M</math> and <math>X\\left(X^\\textsf{T}X\\right)^{-1}X^\\textsf{T}</math>(the latter being known as the [[hat matrix]]) are idempotent and symmetric matrices, a fact which allows simplification when the sum of squared residuals is computed:\n\n:<math>\\hat{e}^\\textsf{T}\\hat{e} = (My)^\\textsf{T}(My) = y^\\textsf{T}M^\\textsf{T}My = y^\\textsf{T}MMy = y^\\textsf{T}My.</math>\n\nThe idempotency of <math>M</math> plays a role in other calculations as well, such as in determining the variance of the estimator <math>\\hat{\\beta}</math>.\n\nAn idempotent linear operator <math>P</math> is a projection operator on the [[column space|range space]] {{tmath|R(P)}} along its [[null space]] {{tmath|N(P)}}. <math>P</math> is an [[orthogonal projection]] operator if and only if it is idempotent and [[Symmetric matrix|symmetric]].\n\n==See also==\n* [[Idempotence]]\n* [[Nilpotent]]\n* [[Projection (linear algebra)]]\n* [[Hat matrix]]\n\n==References==\n{{reflist}}\n\n[[Category:Algebra]]\n[[Category:Regression analysis]]\n[[Category:Matrices]]"
    },
    {
      "title": "Identity element",
      "url": "https://en.wikipedia.org/wiki/Identity_element",
      "text": "{{single source|date=July 2013}}\nIn [[mathematics]], an '''identity element''' or '''neutral element''' is a special type of element of a [[Set (mathematics)|set]] with respect to a [[binary operation]] on that set, which leaves any element of the set unchanged when combined with it. This concept is used in [[algebraic structure]]s such as [[group (mathematics)|group]]s and [[ring (mathematics)|ring]]s. The term ''identity element'' is often shortened to ''identity'' (as will be done in this article) when there is no possibility of confusion, but the identity implicitly depends on the binary operation it is associated with.\n\nLet {{math|(''S'', ∗)}} be a set&nbsp;{{mvar|S}} with a binary operation&nbsp;∗ on it. Then an element&nbsp;{{mvar|e}} of&nbsp;{{mvar|S}} is called a '''[[left and right (algebra)|left]] identity''' if {{math|1=''e'' ∗ ''a'' = ''a''}} for all&nbsp;{{mvar|a}} in&nbsp;{{mvar|S}}, and a '''[[left and right (algebra)|right]] identity''' if {{math|1=''a'' ∗ ''e'' = ''a''}} for all&nbsp;{{mvar|a}} in&nbsp;{{mvar|S}}. If {{mvar|e}} is both a left identity and a right identity, then it is called a '''two-sided identity''', or simply an '''identity'''.\n\nAn identity with respect to addition is called an [[additive identity]] (often denoted as&nbsp;0) and an identity with respect to multiplication is called a [[multiplicative identity]] (often denoted as&nbsp;1). These need not be ordinary addition and multiplication, but rather arbitrary operations. The distinction is used most often for sets that support both binary operations, such as [[ring (mathematics)|ring]]s and [[field (mathematics)|field]]s. The multiplicative identity is often called '''unity''' in the latter context (a ring with unity). This should not be confused with a [[unit (ring theory)|unit]] in ring theory, which is any element having a [[multiplicative inverse]]. Unity itself is necessarily a unit.\n\n==Examples==\n{| class=\"wikitable\"\n! Set !! Operation !! Identity\n|-\n| [[Real number]]s || + ([[addition]]) || [[0 (number)|0]]\n|-\n| Real numbers || · ([[multiplication]]) || [[1 (number)|1]]\n|-\n| [[Positive integer]]s || [[Least common multiple]] || 1\n|-\n| [[Non-negative integer]]s || [[Greatest common divisor]] || 0 (under most definitions of GCD)\n|-\n<!-- ||' ''R'''<sup>''n''</sup> || · (multiplication) || [[1 (number)|1]] -->\n| {{mvar|m}}-by-{{mvar|n}} [[matrix (mathematics)|matrices]] || [[Matrix addition]]\n| [[Zero matrix]]\n|-\n| {{mvar|n}}-by-{{mvar|n}} square matrices || [[Matrix multiplication]]\n| ''I''<sub>''n''</sub> ([[identity matrix]])\n|-\n| {{mvar|m}}-by-{{mvar|n}} matrices || ○ ([[Hadamard product (matrices)|Hadamard product]])\n| {{math|''J''<sub>''m'', ''n''</sub>}} ([[matrix of ones]])\n|-\n| All [[function (mathematics)|functions]] from a set,&nbsp;{{mvar|M}}, to itself || ∘ ([[function composition]]) || [[Identity function]]\n|-\n| All [[distribution (mathematics)|distributions]] on a [[group (mathematics)|group]],&nbsp;{{mvar|G}}<!-- a crap refurbished --> || ∗ ([[convolution]]) || {{math|''δ''}} ([[Dirac delta]])\n|-\n| [[Extended real number]]s || [[Minimum]]/infimum || +∞\n|-\n| Extended real numbers || [[Maximum]]/supremum || −∞\n|-\n| Subsets of a [[Set (mathematics)|set]]&nbsp;{{mvar|M}} || ∩ ([[set intersection|intersection]]) || {{mvar|M}}\n|-\n| Sets || ∪ ([[set union|union]]) || ∅ ([[empty set]])\n|-\n| [[string (computer science)|Strings]], [[tuple|lists]] || [[Concatenation]] || [[Empty string]], empty list\n|-\n| A [[Boolean algebra (structure)|Boolean algebra]] || ∧ ([[logical and]]) || ⊤ (truth)\n|-\n| A Boolean algebra || ∨ ([[logical or]]) || ⊥ (falsity)\n|-\n| A Boolean algebra || ⊕ ([[exclusive or]]) || ⊥ (falsity)\n|-\n| [[knot (mathematics)|Knots]] || [[Knot sum]] || [[Unknot]]\n|-\n| [[Compact surfaces]] || # ([[connected sum]]) || [[sphere|''S''<sup>2</sup>]]\n|-\n| [[Group (mathematics)|Groups]] || [[Direct product]] || [[Trivial group]]\n|-\n| Two elements, {{math|{''e'', ''f''} }}\n| ∗ defined by<br> {{math|1=''e'' ∗ ''e'' = ''f'' ∗ ''e'' = ''e''}} and <br> {{math|1=''f'' ∗ ''f'' = ''e'' ∗ ''f'' = ''f''}}\n| Both {{mvar|e}} and {{mvar|f}} are left identities,<br> but there is no right identity<br> and no two-sided identity\n|-\n| [[Homogeneous relation]]s on a set ''X'' || [[Relative product]] || [[Identity relation]]\n|}\n\n==Properties==\nAs the last example (a [[semigroup]]) shows, it is possible for {{math|(''S'', ∗)}} to have several left identities. In fact, every element can be a left identity. Similarly, there can be several right identities. But if there is both a right identity and a left identity, then they are equal and there is just a single two-sided identity. To see this, note that if {{mvar|l}} is a left identity and {{mvar|r}} is a right identity then {{math|1=''l'' = ''l'' ∗ ''r'' = ''r''}}. In particular, there can never be more than one two-sided identity.  If there were two, {{mvar|e}} and {{mvar|f}}, then {{math|''e'' ∗ ''f''}} would have to be equal to both {{mvar|e}} and {{mvar|f}}.\n\nIt is also quite possible for {{math|(''S'', ∗)}} to have ''no'' identity element. A common example of this is the [[cross product]] of [[Euclidean vector|vectors]]; in this case, the absence of an identity element is related to the fact that the [[Direction (geometry)|direction]] of any nonzero cross product is always [[orthogonal]] to any element multiplied&nbsp;– so that it is not possible to obtain a non-zero vector in the same direction as the original. Another example would be the additive [[semigroup]] of [[Positive number|positive]] [[natural number]]s.\n\n==See also==\n* [[Absorbing element]]\n* [[Additive inverse]]\n* [[Generalized inverse]]\n* [[Inverse element]]\n* [[Monoid]]\n* [[Pseudo-ring #Properties weaker than having an identity|Pseudo-ring]]\n* [[Quasigroup]]\n* [[Unital (disambiguation)]]\n\n==References==\n* M. Kilp, U. Knauer, A.V. Mikhalev, ''Monoids, Acts and Categories with Applications to Wreath Products and Graphs'', De Gruyter Expositions in Mathematics vol.&nbsp;29, Walter de Gruyter, 2000, {{ISBN|3-11-015248-7}}, p.&nbsp;14–15\n\n[[Category:Abstract algebra]]\n[[Category:Algebra]]\n[[Category:Binary operations|*Identity element]]\n[[Category:1 (number)]]"
    },
    {
      "title": "Immanant",
      "url": "https://en.wikipedia.org/wiki/Immanant",
      "text": ":''Not be confused with the philosophical [[Immanence|immanent]], the temporal [[imminence (disambiguation)|imminence]], or the prominent [[eminence (disambiguation)|eminence]].''\n\nIn mathematics, the '''immanant''' of a [[matrix (mathematics)|matrix]] was defined by [[Dudley E. Littlewood]] and [[Archibald Read Richardson]] as a generalisation of the concepts of [[determinant]] and [[Permanent (mathematics)|permanent]].\n\nLet <math>\\lambda=(\\lambda_1,\\lambda_2,\\ldots)</math> be a [[Partition (number theory)|partition]] of <math>n</math> and let <math>\\chi_\\lambda</math> be the corresponding irreducible [[Group representation|representation-theoretic]] [[Character (group theory)|character]] of the [[symmetric group]] <math>S_n</math>. The ''immanant'' of an <math>n\\times n</math> [[Matrix (mathematics)|matrix]] <math>A=(a_{ij})</math> associated with the character <math>\\chi_\\lambda</math> is defined as the expression\n\n:<math>\\operatorname{Imm}_\\lambda(A)=\\sum_{\\sigma\\in S_n} \\chi_\\lambda(\\sigma) a_{1\\sigma(1)} a_{2\\sigma(2)} \\cdots a_{n\\sigma(n)}.</math>\n\nThe determinant is a special case of the immanant, where <math>\\chi_\\lambda</math> is the [[alternating character]] <math>\\sgn</math>, of ''S''<sub>''n''</sub>, defined by the [[parity of a permutation]].\n\nThe permanent is the case where <math>\\chi_\\lambda</math> is the [[trivial character]], which is identically equal to&nbsp;1.\n\nFor example, for <math>3 \\times 3</math> matrices, there are three irreducible representations of <math>S_3</math>, as shown in the character table:\n{| class=\"wikitable\"\n|-\n! <math>S_3</math>\n! <math>e</math>\n! <math>(1\\ 2)</math>\n! <math>(1\\ 2\\ 3)</math>\n|-\n| <math>\\chi_1</math>\n| 1\n| 1\n| 1\n|-\n| <math>\\chi_2</math>\n| 1\n| −1\n| 1\n|-\n| <math>\\chi_3</math>\n| 2\n| 0\n| −1\n|}\nAs stated above, <math>\\chi_1</math> produces the permanent and <math>\\chi_2</math> produces the determinant, but <math>\\chi_3</math> produces the operation that maps as follows:\n\n:<math>\\begin{pmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{pmatrix} \\rightsquigarrow 2 a_{11} a_{22} a_{33} - a_{12} a_{23} a_{31} - a_{13} a_{21} a_{32}</math>\n\nLittlewood and Richardson also studied its relation to [[Schur polynomial|Schur functions]] in the [[representation theory of the symmetric group]].\n\n==References==\n\n* {{cite journal | author=D. E. Littlewood | authorlink=Dudley E. Littlewood |author2=A.R. Richardson |authorlink2=Archibald Read Richardson  | title=Group characters and algebras | journal=[[Philosophical Transactions of the Royal Society A]] | year=1934 | volume=233 | pages=99–124 | doi=10.1098/rsta.1934.0015 | issue=721–730 }}\n* {{cite book | author=D. E. Littlewood | authorlink=Dudley E. Littlewood | title=The Theory of Group Characters and Matrix Representations of Groups | edition=2nd | year=1950 | publisher=Oxford Univ. Press (reprinted by AMS, 2006) | page=81 }}\n\n==External links==\n*[http://planetmath.org/immanent Immanent] at ''[[PlanetMath]]''\n\n[[Category:Algebra]]\n[[Category:Linear algebra]]\n[[Category:Matrix theory]]\n[[Category:Permutations]]"
    },
    {
      "title": "Indeterminate equation",
      "url": "https://en.wikipedia.org/wiki/Indeterminate_equation",
      "text": "An '''indeterminate equation''', in [[mathematics]], is an equation for which there is more than one solution; for example, 2''x'' = ''y'' is a simple indeterminate equation, as are a''x'' + b''y'' = c and ''x''<sup>2</sup> = 1.  Indeterminate equations cannot be solved uniquely. Prominent examples include the following:\n\n'''[[Univariate]] [[polynomial equation]]''':\n:<math>a_nx^n+a_{n-1}x^{n-1}+\\dots +a_2x^2+a_1x+a_0 = 0,</math>\n\nwhich has multiple solutions for the variable ''x'' in the [[complex plane]] unless it can be rewritten in the form <math>a_n(x-b)^n=0</math>.\n\n'''Non-degenerate [[Conic section|conic equation]]:\n\n:<math>Ax^2 + Bxy + Cy^2 +Dx + Ey + F = 0,</math>\n\nwhere at least one of the given [[Parameter#Mathematical functions|parameters]] ''A'', ''B'', and ''C'' is non-zero, and ''x'' and ''y'' are real variables.\n\n'''[[Pell's equation]]''':\n:<math>\\ x^2 - Py^2 = 1,</math>\n\nwhere ''P'' is a given integer that is not a [[square number]], and in which the variables ''x'' and ''y'' are required to be integers.\n\n'''The equation of [[Pythagorean triple]]s''':\n:<math>x^2+y^2=z^2,</math>\n\nin which the variables ''x'', ''y'', and ''z'' are required to be positive integers.\n\n'''The equation of the [[Fermat–Catalan conjecture]]''':\n:<math>a^m+b^n=c^k,</math>\n\nin which the variables ''a'', ''b'', ''c'' are required to be [[coprime]] positive integers and the variables ''m'', ''n'', and ''k'' are required to be positive integers the sum of whose reciprocals is less than 1.\n\n== See also ==\n* [[Indeterminate system]]\n* [[Indeterminate (variable)]]\n* [[Linear algebra]]\n\n== References ==\n{{Unreferenced|date=August 2008}}\n\n[[Category:Algebra]]\n\n{{algebra-stub}}"
    },
    {
      "title": "Infrastructure (number theory)",
      "url": "https://en.wikipedia.org/wiki/Infrastructure_%28number_theory%29",
      "text": "In [[mathematics]], an '''infrastructure''' is a [[Group (mathematics)|group]]-like structure appearing in [[global field]]s.\n\n== Historic development ==\n\nIn 1972, [[Daniel Shanks|D. Shanks]] first discovered the infrastructure of a [[Quadratic field|real quadratic number field]] and applied his [[baby-step giant-step]] algorithm to compute the [[Dirichlet's unit theorem#The regulator|regulator]] of such a field in <math>\\mathcal{O}(D^{1/4+\\varepsilon})</math> binary operations (for every <math>\\varepsilon > 0</math>), where <math>D</math> is the [[Quadratic field#Discriminant|discriminant]] of the quadratic field; previous methods required <math>\\mathcal{O}(D^{1/2+\\varepsilon})</math> binary operations.<ref name=\"shanks-infrastructure\">D. Shanks: The infrastructure of a real quadratic field and its applications. Proceedings of the Number Theory Conference (Univ. Colorado, Boulder, Colo., 1972), pp. 217-224. University of Colorado, Boulder, 1972. {{MR|389842}}</ref> Ten years later, [[Hendrik Lenstra|H. W. Lenstra]] published<ref name=\"lenstra-infrastructure\">H. W. Lenstra Jr.: On the calculation of regulators and class numbers of quadratic fields. Number theory days, 1980 (Exeter, 1980), 123&ndash;150, London Math. Soc. Lecture Note Ser., 56, Cambridge University Press, Cambridge, 1982. {{MR|697260}}</ref> a mathematical framework describing the infrastructure of a real quadratic number field in terms of \"circular groups\". It was also described by R. Schoof<ref name=\"schoof-infrastructure1\">R. J. Schoof: Quadratic fields and factorization. Computational methods in number theory, Part II, 235&ndash;286, Math. Centre Tracts, 155, Math. Centrum, Amsterdam, 1982. {{MR|702519}}</ref> and H. C. Williams,<ref name=\"williams-infrastructure1\">H. C. Williams: Continued fractions and number-theoretic computations. Number theory (Winnipeg, Man., 1983). Rocky Mountain J. Math. 15 (1985), no. 2, 621&ndash;655. {{MR|823273}}</ref> and later extended by H. C. Williams, G. W. Dueck and B. K. Schmid to certain [[Cubic field|cubic number fields]] of [[Dirichlet's unit theorem|unit rank]] one<ref name=\"williams-dueck-schmid\">H. C. Williams, G. W. Dueck, B. K. Schmid: A rapid method of evaluating the regulator and class number of a pure cubic field. Math. Comp. 41 (1983), no. 163, 235&ndash;286. {{MR|701638}}</ref><ref name=\"williams-dueck\">G. W. Dueck, H. C. Williams: Computation of the class number and class group of a complex cubic field. Math. Comp. 45 (1985), no. 171, 223&ndash;231. {{MR|790655}}</ref> and by J. Buchmann and H. C. Williams to all number fields of unit rank one.<ref name=\"buchmann-williams-infrastructure\">J. Buchmann, H. C. Williams: On the infrastructure of the principal ideal class of an algebraic number field of unit rank one. Math. Comp. 50 (1988), no. 182, 569&ndash;579. {{MR|929554}}</ref> In his [[Habilitation|habilitation thesis]], J. Buchmann presented a baby-step giant-step algorithm to compute the regulator of a number field of ''arbitrary'' unit rank.<ref name=\"buchmann-habil\">J. Buchmann: Zur Komplexität der Berechnung von Einheiten und Klassenzahlen algebraischer Zahlkörper. Habilitationsschrift, Düsseldorf, 1987. [http://www.cdc.informatik.tu-darmstadt.de/~buchmann/Lecture%20Notes/habil.pdf PDF]</ref> The first description of infrastructures in number fields of arbitrary unit rank was given by R. Schoof using [[Arakelov divisor]]s in 2008.<ref>R. Schoof: Computing Arakelov class groups. (English summary) Algorithmic number theory: lattices, number fields, curves and cryptography, 447&ndash;495, Math. Sci. Res. Inst. Publ., 44, Cambridge University Press, 2008. {{MR|2467554}} [http://www.mat.uniroma2.it/~schoof/papers.html PDF]</ref>\n\nThe infrastructure was also described for other [[global field]]s, namely for [[algebraic function field]]s over [[finite field]]s. This was done first by A. Stein and H. G. Zimmer in the case of real [[Hyperelliptic curve|hyperelliptic]] function fields.<ref name=\"stein-zimmer\">A. Stein, H. G. Zimmer: An algorithm for determining the regulator and the fundamental unit of hyperelliptic congruence function field. In \"Proceedings of the 1991 International Symposium on Symbolic and Algebraic Computation, ISSAC '91,\" Association for Computing Machinery, (1991), 183&ndash;184.</ref> It was extended to certain cubic function fields of unit rank one by R. Scheidler and A. Stein.<ref name=\"stein-scheidler-cubicinfra\">R. Scheidler, A. Stein: Unit computation in purely cubic function fields of unit rank 1. (English summary) Algorithmic number theory (Portland, OR, 1998), 592&ndash;606, Lecture Notes in Comput. Sci., 1423, Springer, Berlin, 1998. {{MR|1726104}}</ref><ref name=\"scheidler-infrapurecubic\">R. Scheidler: Ideal arithmetic and infrastructure in purely cubic function fields. (English, French summary) J. Théor. Nombres Bordeaux 13 (2001), no. 2, 609&ndash;631. {{MR|1879675}}</ref> In 1999, S. Paulus and H.-G. Rück related the infrastructure of a real quadratic function field to the divisor class group.<ref name=\"paulus-rueck\">S. Paulus, H.-G. Rück: Real and imaginary quadratic representations of hyperelliptic function fields. (English summary) Math. Comp. 68 (1999), no. 227, 1233&ndash;1241. {{MR|1627817}}</ref> This connection can be generalized to arbitrary function fields and, combining with R. Schoof's results, to all global fields.<ref name=\"fontein-infrastructure\">{{cite journal | first=F. | last=Fontein | title=The Infrastructure of a Global Field of Arbitrary Unit Rank | journal=Math. Comp. | volume=80 | year=2011 | number=276 | pages=2325–2357 | doi=\t10.1090/S0025-5718-2011-02490-7 | arxiv=0809.1685 }}</ref>\n\n== One-dimensional case ==\n\n=== Abstract definition ===\n\nA '''one-dimensional (abstract) infrastructure''' <math>(X, d)</math> consists of a [[real number]] <math>R > 0</math>, a [[finite set]] <math>X \\neq \\emptyset</math> together with an [[Injective function|injective]] map <math>d : X \\to \\mathbb{R}/R\\mathbb{Z}</math>.<ref name=\"fontein-pohlighellman\">F. Fontein: Groups from cyclic infrastructures and Pohlig-Hellman in certain infrastructures. (English summary) Adv. Math. Commun. 2 (2008), no. 3, 293&ndash;307. {{MR|2429459}}</ref> The map <math>d</math> is often called the ''distance map''.\n\nBy interpreting <math>\\mathbb{R}/R\\mathbb{Z}</math> as a [[circle]] of [[circumference]] <math>R</math> and by identifying <math>X</math> with <math>d(X)</math>, one can see a one-dimensional infrastructure as a circle with a finite set of points on it.\n\n=== Baby steps ===\n\nA '''baby step''' is a [[unary operation]] <math>bs : X \\to X</math> on a one-dimensional infrastructure <math>(X, d)</math>. Visualizing the infrastructure as a circle, a baby step assigns each point of <math>d(X)</math> the next one. Formally, one can define this by assigning to <math>x \\in X</math> the real number <math>f_x := \\inf\\{ f' > 0 \\mid d(x) + f' \\in d(X) \\}</math>; then, one can define <math>bs(x) := d^{-1}(d(x) + f_x)</math>.\n\n=== Giant steps and reduction maps ===\n\nObserving that <math>\\mathbb{R}/R\\mathbb{Z}</math> is naturally an [[abelian group]], one can consider the sum <math>d(x) + d(y) \\in \\mathbb{R}/R\\mathbb{Z}</math> for <math>x, y \\in X</math>. In general, this is not an element of <math>d(X)</math>. But instead, one can take an element of <math>d(X)</math> which lies ''nearby''. To formalize this concept, assume that there is a map <math>red : \\mathbb{R}/R\\mathbb{Z} \\to X</math>; then, one can define <math>gs(x, y) := red(d(x) + d(y))</math> to obtain a [[binary operation]] <math>gs : X \\times X \\to X</math>, called the '''giant step''' operation. Note that this operation is in general ''not'' [[Associativity|associative]].\n\nThe main difficulty is how to choose the map <math>red</math>. Assuming that one wants to have the condition <math>red \\circ d = \\mathrm{id}_X</math>, a range of possibilities remain.   One possible choice<ref name=\"fontein-pohlighellman\" /> is given as follows: for <math>v \\in \\mathbb{R}/R\\mathbb{Z}</math>, define <math>f_v := \\inf\\{ f \\ge 0 \\mid v - f \\in d(X) \\}</math>; then one can define <math>red(v) := d^{-1}(v - f_v)</math>. This choice, seeming somewhat arbitrary, appears in a natural way when one tries to obtain infrastructures from global fields.<ref name=\"fontein-infrastructure\" /> Other choices are possible as well, for example choosing an element <math>x \\in d(X)</math> such that <math>|d(x) - v|</math> is minimal (here, <math>|d(x) - v|</math> is stands for <math>\\inf\\{ |f - v| \\mid f \\in d(x) \\}</math>, as <math>d(x)</math> is of the form <math>v + R\\mathbb{Z}</math>); one possible construction in the case of real quadratic hyperelliptic function fields is given by S. D. Galbraith, M. Harrison and D. J. Mireles Morales.<ref name=\"galbraith-harrison-mirelesmorales\">S. D. Galbraith, M. Harrison, D. J. Mireles Morales: Efficient hyperelliptic arithmetic using balanced representation for divisors. (English summary) Algorithmic number theory, 342&ndash;356, Lecture Notes in Comput. Sci., 5011, Springer, Berlin, 2008. {{MR|2467851}}</ref>\n\n=== Relation to real quadratic fields ===\n\nD. Shanks observed the infrastructure in real quadratic number fields when he was looking at cycles of reduced [[binary quadratic form]]s. Note that there is a close relation between reducing binary quadratic forms and [[continued fraction]] expansion; one step in the continued fraction expansion of a certain [[quadratic irrational]]ity gives a [[unary operation]] on the set of reduced forms, which cycles through all reduced forms in one equivalence class. Arranging all these reduced forms in a cycle, Shanks noticed that one can quickly jump to reduced forms further away from the beginning of the circle by [[Composition of binary quadratic forms|composing]] two such forms and reducing the result. He called this [[binary operation]] on the set of reduced forms a '''giant step''', and the operation to go to the next reduced form in the cycle a '''baby step'''.\n\n=== Relation to <math>\\mathbb{R}/R\\mathbb{Z}</math> ===\n\nThe set <math>\\mathbb{R}/R\\mathbb{Z}</math> has a natural group operation and the giant step operation is defined in terms of it. Hence, it makes sense to compare the arithmetic in the infrastructure to the arithmetic in <math>\\mathbb{R}/R\\mathbb{Z}</math>. It turns out that the group operation of <math>\\mathbb{R}/R\\mathbb{Z}</math> can be described using giant steps and baby steps, by representing elements of <math>\\mathbb{R}/R\\mathbb{Z}</math> by elements of <math>X</math> together with a relatively small real number; this has been first described by D. Hühnlein and S. Paulus<ref name=\"huehnlein-paulus\">D. Hühnlein, S. Paulus: On the implementation of cryptosystems based on real quadratic number fields (extended abstract). Selected areas in cryptography (Waterloo, ON, 2000), 288&ndash;302, Lecture Notes in Comput. Sci., 2012, Springer, 2001. {{MR|1895598}}</ref> and by M. J. Jacobson, Jr., R. Scheidler and H. C. Williams<ref name=\"jacobson-scheidler-williams\">M. J. Jacobson Jr., R. Scheidler, H. C. Williams: The efficiency and security of a real quadratic field based key exchange protocol. Public-key cryptography and computational number theory (Warsaw, 2000), 89&ndash;112, de Gruyter, Berlin, 2001 {{MR|1881630}}</ref> in the case of infrastructures obtained from real quadratic number fields. They used floating point numbers to represent the real numbers, and called these representations CRIAD-representations resp. <math>(f, p)</math>-representations. More generally, one can define a similar concept for all one-dimensional infrastructures; these are sometimes called <math>f</math>-representations.<ref name=\"fontein-pohlighellman\" />\n\nA '''set of <math>f</math>-representations''' is a subset <math>fRep</math> of <math>X \\times \\mathbb{R}/R\\mathbb{Z}</math> such that the map <math>\\Psi_{fRep} : fRep \\to \\mathbb{R}/R\\mathbb{Z}, \\; (x, f) \\mapsto d(x) + f</math> is a bijection and that <math>(x, 0) \\in fRep</math> for every <math>x \\in X</math>. If <math>red : \\mathbb{R}/R\\mathbb{Z} \\to X</math> is a reduction map, <math>fRep_{red} := \\{ (x, f) \\in X \\times \\mathbb{R}/R\\mathbb{Z} \\mid red(d(x) + f) = x \\}</math> is a set of <math>f</math>-representations; conversely, if <math>fRep</math> is a set of <math>f</math>-representations, one can obtain a reduction map by setting <math>red(f) = \\pi_1(\\Psi_{fRep}^{-1}(f))</math>, where <math>\\pi_1 : X \\times \\mathbb{R}/R\\mathbb{Z} \\to X, \\; (x, f) \\mapsto x</math> is the projection on $X$. Hence, sets of <math>f</math>-representations and reduction maps are in a [[one-to-one correspondence]].\n\nUsing the bijection <math>\\Psi_{fRep} : fRep \\to \\mathbb{R}/R\\mathbb{Z}</math>, one can pull over the group operation on <math>\\mathbb{R}/R\\mathbb{Z}</math> to <math>fRep</math>, hence turning <math>fRep</math> into an abelian group <math>(fRep, +)</math> by <math>x + y := \\Psi_{fRep}^{-1}(\\Psi_{fRep}(x) + \\Psi_{fRep}(y))</math>, <math>x, y \\in fRep</math>. In certain cases, this group operation can be explicitly described without using <math>\\Psi_{fRep}</math> and <math>d</math>.\n\nIn case one uses the reduction map <math>red : \\mathbb{R}/R\\mathbb{Z} \\to X, \\; v \\mapsto d^{-1}(v - \\inf\\{ f \\ge 0 \\mid v - f \\in d(X) \\})</math>, one obtains <math>fRep_{red} = \\{ (x, f) \\mid f \\ge 0, \\; \\forall f' \\in [0, f) : d(x) + f' \\not\\in d(X) \\}</math>. Given <math>(x, f), (x', f') \\in fRep_{red}</math>, one can consider <math>(x'', f'')</math> with <math>x'' = gs(x, x')</math> and <math>f'' = f + f' + (d(x) + d(x') - d(gs(x, x'))) \\ge 0</math>; this is in general no element of <math>fRep_{red}</math>, but one can reduce it as follows: one computes <math>bs^{-1}(x'')</math> and <math>f'' - (d(x'') - d(bs^{-1}(x'')))</math>; in case the latter is not negative, one replaces <math>(x'', f'')</math> with <math>(bs^{-1}(x''), f'' - (d(x'') - d(bs^{-1}(x''))))</math> and continues. If the value was negative, one has that <math>(x'', f'') \\in fRep_{red}</math> and that <math>\\Psi_{fRep_{red}}(x, f) + \\Psi_{fRep_{red}}(x', f') = \\Psi_{fRep_{red}}(x'', f'')</math>, i.e. <math>(x, f) + (x', f') = (x'', f'')</math>.\n\n== References ==\n{{Reflist}}\n\n{{DEFAULTSORT:Infrastructure (Number Theory)}}\n[[Category:Algebra]]\n[[Category:Algebraic structures]]"
    },
    {
      "title": "Inverse element",
      "url": "https://en.wikipedia.org/wiki/Inverse_element",
      "text": "{{See also|Inversion (disambiguation){{!}}Inversion}}\n\nIn [[abstract algebra]], the idea of an '''inverse element''' generalises concepts of a [[additive inverse|negation (sign reversal)]] in relation to [[addition]], and a [[Multiplicative inverse|reciprocal]] in relation to [[multiplication]]. The intuition is of an element that can 'undo' the effect of combination with another given element. While the precise definition of an inverse element varies depending on the algebraic structure involved, these definitions coincide in a [[Group (mathematics)|group]].\n\nThe word 'inverse' is derived from {{lang-la|[[wikt:inversus|inversus]]}} that means 'turned upside down', 'overturned'.\n\n== Formal definitions ==\n\n=== In a unital magma ===\nLet <math>S</math> be a [[Set (mathematics)|set]] [[Closure (mathematics)|closed]] under a [[binary operation]] <math>*</math> (i.e., a [[Magma (algebra)|magma]]). If <math>e</math> is an [[identity element]] of <math>(S,*)</math> (i.e., ''S'' is a unital magma) and <math>a*b=e</math>, then <math>a</math> is called a '''left inverse''' of <math>b</math> and <math>b</math> is called a '''right inverse''' of <math>a</math>. If an element <math>x</math> is both a left inverse and a right inverse of <math>y</math>, then <math>x</math> is called a '''two-sided inverse''', or simply an '''inverse''', of <math>y</math>. An element with a two-sided inverse in <math>S</math> is called '''invertible''' in <math>S</math>. An element with an inverse element only on one side is '''left invertible''', resp. '''right invertible'''. A unital magma in which all elements are invertible is called a [[loop (mathematics)|loop]]. A loop whose binary operation satisfies the [[associative law]] is a [[group (mathematics)|group]].\n\nJust like <math>(S,*)</math> can have several left identities or several right identities, it is possible for an element to have several left inverses or several right inverses (but note that their definition above uses a ''two-sided'' identity <math>e</math>). It can even have several left inverses ''and'' several right inverses.\n\nIf the operation <math>*</math> is [[associative]] then if an element has both a left inverse and a right inverse, they are equal. In other words, in a [[monoid]] (an associative unital magma) every element has at most one inverse (as defined in this section). In a monoid, the set of (left and right) invertible elements is a [[group (mathematics)|group]], called the [[group of units]] of <math>S</math>, and denoted by <math>U(S)</math> or ''H''<sub>1</sub>.\n\nA left-invertible element is left-[[cancellation property|cancellative]], and analogously for right and two-sided.\n\n=== In a semigroup ===\n{{main|Regular semigroup}}\nThe definition in the previous section generalizes the notion of inverse in group relative to the notion of identity. It's also possible, albeit less obvious, to generalize the notion of an inverse by dropping the identity element but keeping associativity, i.e., in a [[semigroup]].\n\nIn a semigroup ''S'' an element ''x'' is called '''(von Neumann) regular''' if there exists some element ''z'' in ''S'' such that ''xzx'' = ''x''; ''z'' is sometimes called a '''pseudoinverse'''. An element ''y'' is called (simply) an '''inverse''' of ''x'' if ''xyx'' = ''x'' and ''y'' = ''yxy''. Every regular element has at least one inverse: if ''x'' = ''xzx'' then it is easy to verify that ''y'' = ''zxz'' is an inverse of ''x'' as defined in this section. Another easy to prove fact: if ''y'' is an inverse of ''x'' then ''e'' = ''xy'' and ''f'' = ''yx'' are [[idempotent element|idempotent]]s, that is ''ee'' = ''e'' and ''ff'' = ''f''. Thus, every pair of (mutually) inverse elements gives rise to two idempotents, and ''ex'' = ''xf'' = ''x'', ''ye'' = ''fy'' = ''y'', and ''e'' acts as a left identity on ''x'', while ''f'' acts a right identity, and the left/right roles are reversed for ''y''. This simple observation can be generalized using [[Green's relations]]: every idempotent ''e'' in an arbitrary semigroup is a left identity for ''R<sub>e</sub>'' and right identity for ''L<sub>e</sub>''.<ref>Howie, prop. 2.3.3, p. 51</ref> An intuitive description of this fact is that every pair of mutually inverse elements produces a local left identity, and respectively, a local right identity.\n\nIn a monoid, the notion of inverse as defined in the previous section is strictly narrower than the definition given in this section. Only elements in the Green class  [[Green's relations#The H and D relations|''H''<sub>1</sub>]] have an inverse from the unital magma perspective, whereas for any idempotent ''e'', the elements of ''H''<sub>e</sub> have an inverse as defined in this section. Under this more general definition, inverses need not be unique (or exist) in an arbitrary semigroup or monoid. If all elements are regular, then the semigroup (or monoid) is called regular, and every element has at least one inverse. If every element has exactly one inverse as defined in this section, then the semigroup is called an [[inverse semigroup]]. Finally, an inverse semigroup with only one idempotent is a group. An inverse semigroup may have an [[absorbing element]] 0 because 000 = 0, whereas a group may not.\n\nOutside semigroup theory, a unique inverse as defined in this section is sometimes called a '''quasi-inverse'''. This is generally justified because in most applications (e.g., all examples in this article) associativity holds, which makes this notion a generalization of the left/right inverse relative to an identity.\n\n=== ''U''-semigroups ===\n\nA natural generalization of the inverse semigroup is to define an (arbitrary) unary operation ° such that (''a''°)° = ''a'' for all ''a'' in ''S''; this endows ''S'' with a type {{langle}}2,1{{rangle}} algebra. A semigroup endowed with such an operation is called a '''''U''-semigroup'''. Although it may seem that ''a''° will be the inverse of ''a'', this is not necessarily the case. In order to obtain interesting notion(s), the unary operation must somehow interact with the semigroup operation. Two classes of ''U''-semigroups have been studied:<ref>Howie p. 102</ref>\n\n* '''''I''-semigroups''', in which the interaction axiom is ''aa''°''a'' = ''a''\n* '''[[Semigroup with involution|*-semigroups]]''', in which the interaction axiom is (''ab'')° = ''b''°''a''°. Such an operation is called an [[involution (mathematics)|involution]], and typically denoted by ''a''*\n\nClearly a group is both an ''I''-semigroup and a *-semigroup. A class of semigroups important in semigroup theory are [[completely regular semigroup]]s; these are ''I''-semigroups in which one additionally has ''aa''° = ''a''°''a''; in other words every element has commuting pseudoinverse ''a''°. There are few concrete examples of such semigroups however; most are [[completely simple semigroup]]s. In contrast, a subclass of *-semigroups, the [[Semigroup with involution#Drazin|*-regular semigroup]]s (in the sense of Drazin), yield one of best known examples of a (unique) pseudoinverse, the [[Moore–Penrose inverse]]. In this case however the involution ''a''* is not the pseudoinverse. Rather, the pseudoinverse of ''x'' is the unique element ''y'' such that ''xyx'' = ''x'', ''yxy'' = ''y'',   (''xy'')* = ''xy'', (''yx'')* = ''yx''. Since *-regular semigroups generalize inverse semigroups, the unique element defined this way in a *-regular semigroup is called the '''generalized inverse''' or '''Penrose–Moore inverse'''.\n\n=== Rings and semirings ===\n{{main|Quasiregular element}}\n\n== Examples ==\nAll examples in this section involve associative operators, thus we shall use the terms left/right inverse for the unital magma-based definition, and quasi-inverse for its more general version.\n\n=== Real numbers ===\nEvery [[real number]] <math>x</math> has an [[additive inverse]] (i.e., an inverse with respect to [[addition]]) given by <math>-x</math>. Every nonzero real number <math>x</math> has a [[multiplicative inverse]] (i.e., an inverse with respect to [[multiplication]]) given by <math>\\frac 1{x}</math> (or <math>x^{-1}</math>). By contrast, [[0 (number)|zero]] has no multiplicative inverse, but it has a unique quasi-inverse, \"<math>0</math>\" itself.\n\n=== Functions and partial functions ===\nA function <math>g</math> is the left (resp. right) [[inverse function|inverse of a function]] <math>f</math> (for [[function composition]]), if and only if <math>g \\circ f</math> (resp. <math>f \\circ g</math>) is the [[identity function]] on the [[domain of a function|domain]] (resp. [[codomain]]) of <math>f</math>. The inverse of a function <math>f</math> is often written <math>f^{-1}</math>, but [[inverse function#Note on notation|this notation is sometimes ambiguous]]. Only [[bijection]]s have two-sided inverses, but ''any'' function has a quasi-inverse, i.e., the [[full transformation monoid]] is regular. The monoid of [[partial functions]] is also regular, whereas the [[symmetric inverse semigroup|monoid of injective partial transformations]] is the prototypical inverse semigroup.\n\n=== Galois connections ===\nThe lower and upper adjoints in a (monotone) [[Galois connection]], ''L'' and ''G'' are quasi-inverses of each other, i.e. ''LGL'' = ''L'' and ''GLG'' = ''G'' and one uniquely determines the other. They are not left or right inverses of each other however.\n\n=== Matrices <!-- [[Generalized inverse]] links here.  Please do not change. --> ===\nA [[square matrix]] <math>M</math> with entries in a [[field (mathematics)|field]] <math>K</math> is invertible (in the set of all square matrices of the same size, under [[matrix multiplication]]) if and only if its [[determinant]] is different from zero. If the determinant of <math>M</math> is zero, it is impossible for it to have a one-sided inverse; therefore a left inverse or right inverse implies the existence of the other one. See [[invertible matrix]] for more.\n\nMore generally, a square matrix over a [[commutative ring]] <math>R</math> is invertible [[if and only if]] its determinant is invertible in <math>R</math>.\n\nNon-square matrices of [[full rank]] have several one-sided inverses:<ref>[http://ocw.mit.edu/OcwWeb/Mathematics/18-06Spring-2005/VideoLectures/detail/lecture33.htm MIT Professor Gilbert Strang Linear Algebra Lecture #33 – Left and Right Inverses; Pseudoinverse.]</ref>\n* For <math>A:m\\times n \\mid m>n</math> we have a left inverse: <math>\\underbrace{ \\left(A^\\text{T}A\\right)^{-1}A^\\text{T} }_{ A^{-1}_\\text{left} } A = I_n</math>\n* For <math>A:m\\times n \\mid m<n</math> we have a right inverse: <math>A \\underbrace{ A^\\text{T}\\left(AA^\\text{T}\\right)^{-1} }_{ A^{-1}_\\text{right} } = I_m</math>\n\nThe left inverse can be used to determine the least norm solution of <math>Ax = b</math>, which is also the [[least squares]] formula for [[regression analysis|regression]] and is given by <math>x = \\left(A^\\text{T}A\\right)^{-1}A^\\text{T}b.</math>\n\nNo [[rank deficient]] matrix has any (even one-sided) inverse.  However, the [[Moore–Penrose inverse]] exists for all matrices, and coincides with the left or right (or true) inverse when it exists.\n\nAs an example of matrix inverses, consider:\n\n: <math>A:2 \\times 3 =\n  \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6\n  \\end{bmatrix}\n</math>\n\nSo, as ''m'' < ''n'', we have a right inverse, <math>A^{-1}_\\text{right} = A^\\text{T}\\left(AA^\\text{T}\\right)^{-1}.</math> By components it is computed as\n\n: <math>\\begin{align}\n  AA^\\text{T} &= \\begin{bmatrix}\n              1 & 2 & 3 \\\\\n              4 & 5 & 6\n            \\end{bmatrix}\\cdot\n            \\begin{bmatrix}\n              1 & 4\\\\\n              2 & 5\\\\\n              3 & 6\n            \\end{bmatrix} =  \n            \\begin{bmatrix}\n              14 & 32\\\\\n              32 & 77\n            \\end{bmatrix} \\\\[3pt]\n  \\left(AA^\\text{T}\\right)^{-1} &= \\begin{bmatrix}\n                     14 & 32\\\\\n                     32 & 77\n                   \\end{bmatrix}^{-1} = \\frac{1}{54}\n                   \\begin{bmatrix}\n                      77 & -32\\\\\n                     -32 & 14\n                   \\end{bmatrix} \\\\[3pt]\n  A^\\text{T}\\left(AA^\\text{T}\\right)^{-1} &= \\frac{1}{54}\n                   \\begin{bmatrix}\n                     1 & 4\\\\\n                     2 & 5\\\\\n                     3 & 6\n                   \\end{bmatrix}\\cdot\n                   \\begin{bmatrix}\n                      77 & -32\\\\\n                     -32 & 14\n                   \\end{bmatrix} = \\frac{1}{18}\n                   \\begin{bmatrix}\n                     -17 & 8\\\\\n                      -2 & 2\\\\\n                      13 & -4\n                   \\end{bmatrix} = A^{-1}_\\text{right}\n\\end{align}</math>\n\nThe left inverse doesn't exist, because\n\n: <math>\n  A^\\text{T}A = \\begin{bmatrix}\n             1 & 4\\\\\n             2 & 5\\\\\n             3 & 6\n           \\end{bmatrix} \\cdot\n           \\begin{bmatrix}\n             1 & 2 & 3 \\\\\n             4 & 5 & 6\n           \\end{bmatrix} =\n           \\begin{bmatrix}\n             17 & 22 & 27 \\\\\n             22 & 29 & 36\\\\\n             27 & 36 & 45\n           \\end{bmatrix}\n</math>\n\nwhich is a [[singular matrix]], and cannot be inverted.\n\n== See also ==\n*[[Loop (algebra)]]\n*[[Division ring]]\n*[[Unit (ring theory)]]\n*[[Latin square property]]\n\n==Notes==\n{{Reflist}}\n\n==References==\n* M. Kilp, U. Knauer, A.V. Mikhalev, ''Monoids, Acts and Categories with Applications to Wreath Products and Graphs'', De Gruyter Expositions in Mathematics vol. 29, Walter de Gruyter, 2000, {{ISBN|3-11-015248-7}}, p.&nbsp;15 (def in unital magma) and p.&nbsp;33 (def in semigroup)\n*{{cite book|last= Howie|first= John M.|title=Fundamentals of Semigroup Theory|year=1995|publisher=[[Clarendon Press]]|isbn=0-19-851194-9}} contains all of the semigroup material herein except *-regular semigroups.\n* Drazin, M.P., ''Regular semigroups with involution'', Proc. Symp. on Regular Semigroups (DeKalb, 1979), 29–46\n* Miyuki Yamada, ''P-systems in regular semigroups'', [[Semigroup Forum]], 24(1), December 1982, pp.&nbsp;173–187\n*Nordahl, T.E., and H.E. Scheiblich, Regular * Semigroups, [[Semigroup Forum]], 16(1978), 369–377.\n\n[[Category:Algebra]]\n[[Category:Abstract algebra]]\n[[Category:Binary operations|*Inverse element]]"
    },
    {
      "title": "Invertible module",
      "url": "https://en.wikipedia.org/wiki/Invertible_module",
      "text": "In [[mathematics]], particularly [[commutative algebra]], an '''invertible module''' is intuitively a [[module (mathematics)|module]] that has an [[inverse element|inverse]] with respect to the [[tensor product]]. Invertible modules form the foundation for the definition of [[invertible sheaf|invertible sheaves]] in [[algebraic geometry]].\n\nFormally, a [[finitely generated module]] ''M'' over a ring ''R'' is said to be invertible if it is locally a [[free module]] of [[rank of a free module|rank]] 1. In other words, <math> M_P\\cong R_P </math> for all [[prime element|primes]] ''P'' of ''R''. Now, if ''M'' is an invertible ''R''-module, then its [[Duality (mathematics)#Dual objects|dual]] {{nowrap|''M''<sup>*</sup> {{=}} Hom(''M'',''R'')}} is its inverse with respect to the tensor product, i.e. <math>M\\otimes _R M^*\\cong R</math>.\n\nThe theory of invertible modules is closely related to the theory of [[codimension]] one [[algebraic variety|varieties]] including the theory of [[divisor (algebraic geometry)|divisor]]s.\n\n==See also==\n* [[Picard group]]\n\n==References==\n* [[David Eisenbud|Eisenbud, David]], ''Commutative Algebra with a View Toward Algebraic Geometry'', Springer, {{ISBN|978-0-387-94269-8}}\n\n[[Category:Mathematical structures]]\n[[Category:Algebra]]"
    },
    {
      "title": "Irreducible polynomial",
      "url": "https://en.wikipedia.org/wiki/Irreducible_polynomial",
      "text": "{{more footnotes|date=March 2015}}\n{{about|non-factorizable polynomials|polynomials which are not a composition of polynomials|polynomial decomposition}}\nIn [[mathematics]], an '''irreducible polynomial''' (or '''prime polynomial''') is, roughly speaking, a non-[[constant (mathematics)|constant]] [[polynomial]] that cannot be factored into the product of two non-constant polynomials. The property of irreducibility depends on the nature of the coefficients that are accepted for the possible factors, that is, the [[field (mathematics)|field]] or [[ring (mathematics)|ring]] to which the [[coefficient]]s of the polynomial and its possible factors are supposed to belong. For example, the polynomial {{math|''x''<sup>2</sup> − 2}} is a polynomial with [[integer]] coefficients, but, as every integer is also a [[real number]], it is also a polynomial with real coefficients. It is irreducible if it is considered as a polynomial with [[integer]] coefficients, but it factors as <math>(x-\\sqrt{2})(x+\\sqrt {2})</math> if it is considered as a polynomial with [[real number|real]] coefficients. One says that the polynomial {{math|''x''<sup>2</sup> − 2}} is irreducible over the integers but not over the reals.\n\nA polynomial that is irreducible over any field containing the coefficients is [[absolutely irreducible]]. By the [[fundamental theorem of algebra]], a [[univariate polynomial]] is absolutely irreducible if and only if its degree is one. On the other hand, with several [[indeterminate (variable)|indeterminate]]s, there are absolutely irreducible polynomials of any degree, such as <math>x^2+y^n-1,</math> for any positive integer {{math|''n''}}.\n\nA polynomial that is not irreducible is sometimes said to be '''reducible'''.<ref>Gallian 2012, p. 311.</ref><ref>Mac Lane and Birkhoff (1999) do not explicitly define \"reducible\", but they use it in several places. For example: \"For the present, we note only that any reducible quadratic or cubic polynomial must have a linear factor.\" (p. 268).</ref> However, this term must be used with care, as it may refer to other notions of [[reduction (disambiguation)|reduction]].\n\nIrreducible polynomials appear naturally in the study of [[polynomial factorization]] and [[algebraic field extension]]s.\n\nIt is helpful to compare irreducible polynomials to [[prime number]]s: prime numbers (together with the corresponding negative numbers of equal magnitude) are the irreducible [[integer]]s. They exhibit many of the general properties of the concept of \"irreducibility\" that equally apply to irreducible polynomials, such as the essentially unique factorization into prime or irreducible factors.\n\n==Definition==\n\nIf ''F'' is a field, a non-constant polynomial is '''irreducible over ''F''''' if its coefficients belong to ''F'' and it cannot be factored into the product of two non-constant polynomials with coefficients in ''F''. \n\nA polynomial with integer coefficients, or, more generally, with coefficients in a [[unique factorization domain]] ''R'', is sometimes said to be ''irreducible'' (or ''irreducible over R'') if it is an [[irreducible element]] of the [[polynomial ring]], that is, it is not [[unit (ring theory)|invertible]], not zero, and cannot be factored into the product of two non-invertible polynomials with coefficients in ''R''. This definition generalizes the definition given for the case of coefficients in a field, because, over a field, the non-constant polynomials are exactly the polynomials that are non-invertible and non-zero.\n\nAnother definition is frequently used, saying that a polynomial is ''irreducible over R'' if it is irreducible over the [[field of fractions]] of ''R'' (the field of [[rational number]]s, if ''R'' is the integers). This second definition is not used in this article.\n\n===Nature of a factor===\n\nThe absence of an explicit [[algebraic expression]] for a factor does not by itself imply that a polynomial is irreducible. When a polynomial is reducible into factors, these factors may be explicit algebraic expressions or [[implicit function|implicit expressions]]. For example, <math>x^2+2</math> can be factored explicitly over the complex numbers as <math>(x-\\sqrt{2}i)(x+\\sqrt{2}i);</math> however, the [[Abel–Ruffini theorem]] states that there are polynomials of any degree greater than 4 for which complex factors exist that have no explicit algebraic expression. Such a factor can be written simply as, say, <math>(x-x_1),</math> where <math>x_1</math> is defined implicitly as a particular solution of the equation that sets the polynomial equal to 0. Further, factors of either type can also be expressed as numerical approximations obtainable by [[root-finding algorithm]]s, for example as <math>(x-1.2837...).</math>\n\n== Simple examples ==\n\nThe following six polynomials demonstrate some elementary properties of reducible and irreducible polynomials:\n\n:<math>\\begin{align}\np_1(x)&=x^2+4x+4\\,={(x+2)(x+2)}\\\\\np_2(x)&=x^2-4\\,={(x-2)(x+2)}\\\\\np_3(x)&=9x^2-3\\,=3(3x^2-1)\\,=3(x\\sqrt{3}-1)(x\\sqrt{3}+1)\\\\\np_4(x)&=x^2-\\frac49\\,=\\left(x-\\frac23\\right)\\left(x+\\frac23\\right)\\\\\np_5(x)&=x^2-2\\,=(x-\\sqrt{2})(x+\\sqrt{2})\\\\\np_6(x)&=x^2+1\\,={(x-i)(x+i)}\n\\end{align} </math>\n\nOver the [[integer]]s, the first three polynomials are reducible (the third one is reducible because the factor 3 is not invertible in the integers); the last two are irreducible. (The fourth, of course, is not a polynomial over the integers.)\n\nOver the [[rational number]]s, the first two and the fourth polynomials are reducible, but the other three polynomials are irreducible (as a polynomial over the rationals, 3 is a [[unit (ring theory)|unit]], and, therefore, does not count as a factor).\n\nOver the [[real number]]s, the first five polynomials are reducible, but <math>p_6(x)</math> is  irreducible.\n\nOver the [[complex number]]s, all six polynomials are reducible.\n\n==Over the complex numbers==\n\nOver the [[complex field]], and, more generally, over an [[algebraically closed field]], a [[univariate polynomial]] is irreducible if and only if its [[degree of a polynomial|degree]] is one. This fact is known as the [[fundamental theorem of algebra]] in the case of the complex numbers and, in general, as the condition of being algebraically closed.\n\nIt follows that every nonconstant univariate polynomial can be factored as\n\n:<math> a(x-z_1)\\cdots (x-z_n)</math>\n\nwhere <math>n</math> is the degree, <math>a</math> is the leading coefficient and <math>z_1,\\dots,z_n</math> are the zeros of the polynomial (not necessarily distinct, and not necessarily having explicit [[algebraic expression]]s).\n\nThere are irreducible [[multivariate polynomial]]s of every degree over the complex numbers. For example, the polynomial \n:<math>x^n+y^n-1,</math> \nwhich defines a [[Fermat curve]], is irreducible for every positive ''n''.\n\n== Over the reals ==\n\nOver the [[real number|field of reals]], the [[degree of a polynomial|degree]] of an irreducible univariate polynomial is either one or two. More precisely, the irreducible polynomials are the polynomials of degree one and the [[quadratic polynomial]]s <math>ax^2+bx+c</math> that have a negative [[discriminant]] <math>b^2-4ac.</math> \nIt follows that every non-constant univariate polynomial can be factored as a product of polynomials of degree at most two. For example,\n<math>x^4 + 1</math> factors over the real numbers as <math>(x^2 + \\sqrt{2}x + 1)(x^2 - \\sqrt{2}x + 1),</math> and it cannot be factored further, as both factors have a negative discriminant: <math> (\\pm \\sqrt{2})^2-4=-2<0.</math>\n\n==Unique factorization property==\n{{main|Unique factorization domain}}\n\nEvery polynomial over a field {{math|''F''}} may be factored into a product of a non-zero constant and a finite number of irreducible (over {{math|''F''}}) polynomials. This decomposition is unique [[up to]] the order of the factors and the multiplication of the factors by non-zero constants whose product is 1.\n\nOver a [[unique factorization domain]]  the same theorem is true, but is more accurately formulated by using the notion of primitive polynomial. A [[primitive polynomial (ring theory)|primitive polynomial]] is a polynomial over a unique factorization domain, such that 1 is a [[greatest common divisor]] of its coefficients. \n\nLet {{math|''F''}} be a unique factorization domain. A non-constant irreducible polynomial over {{math|''F''}} is primitive. A primitive polynomial over {{math|''F''}} is irreducible over {{math|''F''}} if and only if it is irreducible over the [[field of fractions]] of {{math|''F''}}. Every polynomial over {{math|''F''}} may be decomposed into the product of a non-zero constant and a finite number of non-constant irreducible primitive polynomials. The non-zero constant may itself be decomposed into the product of a [[unit (ring theory)|unit]] of {{math|''F''}} and a finite number of [[irreducible element]]s of {{math|''F''}}.\nBoth factorizations are unique up to the order of the factors and the multiplication of the factors by a unit of {{math|''F''}}.\n\nThis is this theorem which motivates that the definition of ''irreducible polynomial over a unique factorization domain'' often supposes that the polynomial is non-constant. \n\nAll [[algorithm]]s which are presently [[Implementation#Computer science|implemented]] for factoring polynomials over the [[integer]]s and over the [[rational number]]s use this result (see [[Factorization of polynomials]]).\n\n== Over the integers and finite field==\nThe irreducibility of a polynomial over the integers <math>\\mathbb Z</math> is related to that over the field <math>\\mathbb F_p</math> of <math>p</math> elements (for a prime <math>p</math>). In particular, if a univariate polynomial ''f'' over <math>\\mathbb Z</math> is irreducible over <math>\\mathbb F_p</math> for some prime <math>p</math> that does not divide the leading coefficient of ''f'' (the coefficient of the highest power of the variable), then ''f'' is irreducible over <math>\\mathbb Z</math>. [[Eisenstein's criterion]] is a variant of this property where irreducibility over <math>p^2</math> is also involved.\n\nThe converse, however, is not true: there are polynomials of arbitrarily large degree that are irreducible over the integers and reducible over every finite field.<ref>{{cite book|title=Abstract Algebra|year=2004|publisher=John Wiley & Sons, Inc.|isbn=0-471-43334-9|page=309|author=David Dummit|author2=Richard Foote|chapter=chapter 9, Proposition 12}}</ref> A simple example of such a polynomial is <math>x^4+1.</math>\n\nThe relationship between irreducibility over the integers and irreducibility modulo ''p'' is deeper than the previous result: to date, all implemented algorithms for factorization and irreducibility over the integers and over the rational numbers use the factorization over finite fields as a [[subroutine]].\n\nThe number of irreducible [[monic polynomial]]s over a field <math>\\mathbb{F}_p</math> for prime {{math|''p''}} is given by the [[Necklace (combinatorics)|necklace counting function]]. For {{math|1=''p'' = 2}}, such polynomials are commonly used to generate [[pseudorandom binary sequence]]s. \n\nIn some sense, almost all polynomials with coefficients zero or one are irreducible over the integers. More precisely, if a version of the [[Riemann hypothesis]] for [[Dedekind zeta function|Dedekind zeta functions]] is assumed, the probability of being irreducible over the integers for a polynomial with [[Independent and identically distributed random variables|random]] coefficients in {{math|{0, 1} }} tends to one when the degree increases.<ref>{{Cite arXiv|arxiv=1810.13360|first=Emmanuel|last=Breuillard|first2=Péter P.|last2=Varjú|title=Irreducibility of random polynomials of large degree}}</ref><ref>{{Cite web|url=https://www.quantamagazine.org/in-the-universe-of-equations-virtually-all-are-prime-20181210/|title=In the Universe of Equations, Virtually All Are Prime|last=Hartnett|first=Kevin|website=Quanta Magazine|access-date=2019-01-13}}</ref>\n\n==Algorithms==\n{{main|Factorization of polynomials}}\nThe unique factorization property of polynomials does not mean that the factorization of a given polynomial may always be computed. Even the irreducibility of a polynomial may not always be proved by a computation: there are fields over which no [[algorithm]] can exist for deciding the irreducibility of arbitrary polynomials.<ref>{{citation |author1=Fröhlich, A.|author2=Shepherson, J. C.|title = On the factorisation of polynomials in a finite number of steps|journal = Mathematische Zeitschrift|volume = 62|issue=1|year = 1955|issn = 0025-5874|doi=10.1007/BF01180640}}\n</ref> \n\nAlgorithms for factoring polynomials and deciding irreducibility are known and implemented in [[computer algebra system]]s for polynomials over the integers, the rational numbers, [[finite field]]s and [[finitely generated field extension]] of these fields. All these algorithms use the algorithms for [[factorization of polynomials over finite fields]].\n\n==Field extension==\n{{main|Algebraic extension}}\nThe notions of irreducible polynomial and of [[algebraic field extension]] are strongly related, in the following way.\n\nLet ''x'' be an element of an [[field extension|extension]] ''L'' of a field ''K''. This element is said to be ''algebraic'' if it is a [[Zero of a function|root]] of a polynomial with coefficients in ''K''. Among the polynomials of which ''x'' is a root, there is exactly one which is [[monic polynomial|monic]] and of minimal degree, called the [[minimal polynomial (field theory)|minimal polynomial]] of ''x''. The minimal polynomial of an algebraic element ''x'' of ''L'' is irreducible, and is the unique monic irreducible polynomial of which ''x'' is a root. The minimal polynomial of ''x'' divides every polynomial which has ''x'' as a root (this is [[Abel's irreducibility theorem]]). \n\nConversely, if <math>P(X)\\in K[X]</math> is a univariate polynomial over a field ''K'', let <math>L=K[X]/P(X)</math> be the [[quotient ring]] of the polynomial ring <math>K[X]</math> by the [[Ideal (ring theory)#Ideal generated by a set|ideal generated]] by {{math|''P''}}. Then {{math|''L''}} is a field if and only if {{math|''P''}} is irreducible over {{math|''K''}}. In this case, if {{math|''x''}} is the image of {{math|''X''}} in {{math|''L''}}, the minimal polynomial of {{math|''x''}} is the quotient of {{math|''P''}} by its [[leading coefficient]].\n\nAn example of the above is the standard definition of the [[complex number]]s as <math>\\mathbb{C}=\\mathbb{R}[X]/(X^2+1).</math>\n\nIf a polynomial {{math|''P''}} has an irreducible factor {{math|''Q''}} over {{math|''K''}}, which has a degree greater than one, one may apply to {{math|''Q''}} the preceding construction of an algebraic extension, to get an extension in which {{math|''P''}} has at least one more root than in {{math|''K''}}. Iterating this construction, one gets eventually a field over which {{math|''P''}} factors into linear factors. This field, unique [[up to]] a [[ring isomorphism|field isomorphism]], is called the [[splitting field]] of {{math|''P''}}.\n\n==Over an integral domain ==\nIf ''R'' is an [[integral domain]], an element ''f'' of ''R'' that is neither zero nor a unit is called [[irreducible element|irreducible]] if there are no non-units ''g'' and ''h'' with ''f'' = ''gh''. One can show that every [[prime element]] is irreducible;<ref>Consider ''p'' a prime that is reducible: ''p'' = ''ab''. Then ''p'' | ''ab'' ⇒ ''p'' | ''a'' or ''p'' | ''b''. Say ''p'' | ''a'' ⇒ ''a'' = ''pc'', then we have: ''p'' = ''ab'' = ''pcb'' ⇒ ''p''(1 − ''cb'') = 0. Because ''R'' is a domain, we have ''cb'' = 1. So ''b'' is a unit, and ''p'' is irreducible.</ref> the converse is not true in general but holds in [[unique factorization domain]]s. The [[polynomial ring]] ''F''[''x''] over a field ''F'' (or any unique-factorization domain) is again a unique factorization domain. Inductively, this means that the polynomial ring in ''n'' indeterminants (over a ring ''R'') is a unique factorization domain if the same is true for ''R''.\n\n== See also ==\n* [[Gauss's lemma (polynomial)]]\n* [[Rational root theorem]], a method of finding whether a polynomial has a linear factor with rational coefficients\n* [[Eisenstein's criterion]]\n* [[Perron method]]\n* [[Hilbert's irreducibility theorem]]\n* [[Cohn's irreducibility criterion]]\n* [[Irreducible component]] of a [[topological space]]\n* [[Factorization of polynomials over finite fields]]\n* {{section link|Quartic function|Reducible quartics}}\n* {{section link|Cubic function|Factorization}}\n* [[Casus irreducibilis]], the irreducible cubic with three real roots\n* {{section link|Quadratic equation|Quadratic factorization}}\n\n== Notes ==\n{{reflist}}\n\n== References ==\n* {{Lang Algebra}}. This classical book covers most of the content of this article.\n* {{Citation |last=Gallian |first=Joseph |author-link=Joseph Gallian |year=2012 |title=Contemporary Abstract Algebra |edition=8th |publisher=Cengage Learning |publication-place= |page= |url=https://books.google.com/books?id=Ef4KAAAAQBAJ&lpg=PA311&vq=%22reducible%20polynomial%22&pg=PA311#v=onepage&q=%22reducible%20polynomial%22&f=false |accessdate= }}\n* {{citation | first1 = Rudolf | last1 = Lidl | first2 = Harald | last2 = Niederreiter | author2-link = Harald Niederreiter | title = Finite fields | edition = 2nd | publisher = [[Cambridge University Press]] | year = 1997 | isbn = 978-0-521-39231-0}}, [https://books.google.ca/books?id=xqMqxQTFUkMC&pg=PA91 pp. 91].\n* {{Citation |last=Mac Lane |first=Saunders | author-link=Saunders Mac Lane |last2=Birkhoff |first2=Garrett |author-link2=Garrett Birkhoff |year=1999 |title=Algebra |edition=3rd |publisher=American Mathematical Society |publication-place= |page= |url=https://books.google.com/books?id=L6FENd8GHIUC&lpg=PA268&vq=reducible&pg=PA268#v=snippet&q=reducible&f=false |accessdate= }}\n* {{citation | first1 = Alfred J. | last1 = Menezes | authorlink1 = Alfred Menezes | first2 = Paul C. | last2 = Van Oorschot | authorlink2 = Paul van Oorschot | first3 = Scott A. | last3 = Vanstone | authorlink3 = Scott Vanstone | title = Handbook of applied cryptography | publisher = [[CRC Press]] | year = 1997 | isbn = 978-0-8493-8523-0}}, [https://books.google.com/books?id=nSzoG72E93MC&pg=PA154 pp. 154].\n\n== External links ==\n* {{MathWorld | title = Irreducible Polynomial | urlname = IrreduciblePolynomial}}\n* {{PlanetMath | urlname = IrreduciblePolynomial2 | title = Irreducible Polynomial}}\n* [https://archive.is/20130101095630/http://theory.cs.uvic.ca/inf/neck/PolyInfo.html Information on Primitive and Irreducible Polynomials], The (Combinatorial) Object Server.\n\n{{DEFAULTSORT:Irreducible Polynomial}}\n[[Category:Polynomials]]\n[[Category:Abstract algebra]]\n[[Category:Algebra]]"
    },
    {
      "title": "K-theory (physics)",
      "url": "https://en.wikipedia.org/wiki/K-theory_%28physics%29",
      "text": "{{DISPLAYTITLE:''K''-theory (physics)}}\n{{string theory}}\nIn [[string theory]], '''K-theory classification''' refers to a conjectured application of [[K-theory]] (in [[abstract algebra]] and [[algebraic topology]]) to superstrings, to classify the allowed [[Ramond–Ramond field]] strengths as well as the charges of stable [[D-branes]].\n\nIn [[condensed matter physics]] K-theory has also found important applications, specially in the topological classification of [[topological insulator]]s, superconductors and stable Fermi surfaces ({{harvtxt|Kitaev|2009}}, {{harvtxt|Horava|2005}}).\n\n== History ==\n\nThis conjecture, applied to D-brane charges, was first proposed by {{harvtxt|Minasian|Moore|1997}}.  It was popularized by {{harvtxt|Witten|1998}} who demonstrated that in [[type IIB]] string theory arises naturally from [[Ashoke Sen]]'s realization of arbitrary D-brane configurations as stacks of [[D9-brane|D9]] and anti-D9-branes after [[tachyon condensation]].\n\nSuch stacks of branes are inconsistent in a non-torsion [[Kalb–Ramond field|Neveu–Schwarz (NS) 3-form]] background, which, as was highlighted by {{harvtxt|Kapustin|2000}}, complicates the extension of the K-theory classification to such cases. {{harvtxt|Bouwknegt|Varghese|2000}} suggested a solution to this problem: D-branes are in general classified by a [[twisted K-theory]], that had earlier been defined by {{harvtxt|Rosenberg|1989}}.\n\n== Applications ==\n\nThe K-theory classification of D-branes has had numerous applications.  For example, {{harvtxt|Hanany|Kol|2000}} used it to argue that there are eight species of [[orientifold]] one-plane. {{harvtxt|Uranga|2001}} applied the K-theory classification to derive new consistency conditions for [[Compactification (physics)#Flux compactification|flux compactification]]s.  K-theory has also been used to conjecture a formula for the topologies of [[T-duality|T-dual]] manifolds by {{harvtxt|Bouwknegt|Evslin|Varghese|2004}}.  Recently K-theory has been conjectured to classify the [[spinors]] in [[compactification (physics)|compactification]]s on [[generalized complex manifold]]s.\n\n=== Open problems ===\n\nDespite these successes, [[Ramond–Ramond field|RR fluxes]] are not quite classified by K-theory.  {{harvtxt|Diaconescu|Moore|Witten|2003}} argued that the K-theory classification is incompatible with [[S-duality]] in [[Type II string theory|IIB string theory]].\n\nIn addition, if one attempts to classify fluxes on a compact ten-dimensional spacetime, then a complication arises due to the self-duality of the RR fluxes.  The duality uses the [[Hodge star]], which depends on the metric and so is continuously valued and in particular is generically irrational.  Thus not all of the RR fluxes, which are interpreted as the [[Chern character]]s in K-theory, can be rational.  However Chern characters are always rational, and so the K-theory classification must be replaced.  One needs to choose a half of the fluxes to quantize, or a ''polarization'' in the [[geometric quantization]]-inspired language of Diaconescu, Moore, and Witten and later of {{harvtxt|Varghese|Sati|2004}}. Alternately one may use the K-theory of a 9-dimensional [[time]] slice as has been done by {{harvtxt|Maldacena|Moore|Seiberg|2001}}.\n\n==K-theory classification of RR fluxes==\n\nIn the classical limit of [[type II string theory]], which is type II [[supergravity]], the [[Ramond–Ramond field|Ramond–Ramond field strengths]] are [[differential forms]].  In the quantum theory the well-definedness of the partition functions of D-branes implies that the RR field strengths obey [[magnetic monopole#Dirac's quantization|Dirac quantization conditions]] when [[spacetime]] is [[compact space|compact]], or when a spatial slice is compact and one considers only the (magnetic) components of the field strength which lie along the spatial directions.  This led twentieth century physicists to classify RR field strengths using [[cohomology]] with integral coefficients.\n\nHowever some authors have argued that the cohomology of spacetime with integral coefficients is too big.  For example, in the presence of Neveu–Schwarz H-flux or non-spin cycles some RR fluxes dictate the presence of D-branes.  In the former case this is a consequence of the supergravity equation of motion which states that the product of a RR flux with the NS 3-form is a D-brane charge density.  Thus the set of topologically distinct RR field strengths that can exist in brane-free configurations is only a subset of the cohomology with integral coefficients.\n\nThis subset is still too big, because some of these classes are related by large gauge transformations.  In QED there are large gauge transformations which add integral multiples of two pi to Wilson loops.  The p-form potentials in type II supergravity theories also enjoy these large gauge transformations, but due to the presence of [[Chern-Simons]] terms in the supergravity actions these large gauge transformations transform not only the p-form potentials but also simultaneously the (p+3)-form field strengths.  Thus to obtain the space of inequivalent field strengths from the forementioned subset of integral cohomology we must quotient by these large gauge transformations.\n\nThe [[Twisted K-theory#How to calculate it|Atiyah–Hirzebruch spectral sequence]] constructs twisted K-theory, with a twist given by the NS 3-form field strength, as a quotient of a subset of the [[cohomology]] with integral coefficients.  In the classical limit, which corresponds to working with rational coefficients, this is precisely the quotient of a subset described above in supergravity.  The quantum corrections come from torsion classes and contain mod 2 torsion corrections due to the Freed-Witten anomaly.\n\nThus twisted K-theory classifies the subset of RR field strengths that can exist in the absence of D-branes quotiented by large gauge transformations. Daniel Freed has attempted to extend this classification to include also the RR potentials using differential K-theory.\n\n==K-theory classification of D-branes==\n\nK-theory classifies D-branes in noncompact spacetimes, intuitively in spacetimes in which we are not concerned about the flux sourced by the brane having nowhere to go.  While the K-theory of a 10d spacetime classifies D-branes as subsets of that spacetime, if the spacetime is the product of time and a fixed 9-manifold then K-theory also classifies the conserved D-brane charges on each 9-dimensional spatial slice.  While we were required to forget about RR potentials to obtain the K-theory classification of RR field strengths, we are required to forget about RR field strengths to obtain the K-theory classification of D-branes.\n\n=== K-theory charge versus BPS charge ===\n\nAs has been stressed by [[Petr Hořava (theorist)|Petr Hořava]], the K-theory classification of D-branes is independent of, and in some ways stronger than, the classification of [[Bogomol'nyi Prasad Sommerfield bound|BPS states]].  K-theory appears to classify stable D-branes missed by [[supersymmetry]] based classifications.\n\nFor example, D-branes with torsion charges, that is with charges in the order N cyclic group <math>\\mathbf Z_N</math>, attract each other and so can never be BPS.  In fact, N such branes can decay, whereas no superposition of branes that satisfy a Bogomolny bound may ever decay.  However the charge of such branes is conserved modulo N, and this is captured by the K-theory classification but not by a BPS classification.  Such torsion branes have been applied, for example, to model [[Douglas-Shenker strings]] in supersymmetric U(N) [[gauge theory|gauge theories]].\n\n===K-theory from tachyon condensation===\n\n[[Ashoke Sen]] has conjectured that, in the absence of a topologically nontrivial NS 3-form flux, all IIB brane configurations can be obtained from stacks of spacefilling D9 and anti D9 branes via [[tachyon condensation]].  The topology of the resulting branes is encoded in the topology of the gauge bundle on the stack of the spacefilling branes.  The topology of the gauge bundle of a stack of D9s and anti D9s can be decomposed into a gauge bundle on the D9's and another bundle on the anti D9's.  Tachyon condensation transforms such a pair of bundles to another pair in which the same bundle is direct summed with each component in the pair.  Thus the tachyon condensation invariant quantity, that is, the charge which is conserved by the tachyon condensation process, is not a pair of bundles but rather the equivalence class of a pair of bundles under direct sums of the same bundle on both sides of the pair.  This is precisely the usual construction of [[topological K-theory]].  Thus the gauge bundles on stacks of D9's and anti-D9's are classified by topological K-theory.  If Sen's conjecture is right, all D-brane configurations in type IIB are then classified by K-theory.  [[Petr Hořava (theorist)|Petr Horava]] has extended this conjecture to type IIA using D8-branes.\n\n===Twisted K-theory from MMS instantons===\n\nWhile the tachyon condensation picture of the K-theory classification classifies D-branes as subsets of a 10-dimensional spacetime with no NS 3-form flux, the Maldacena, Moore, Seiberg picture classifies stable D-branes with finite mass as subsets of a 9-dimensional spatial slice of spacetime.\n\nThe central observation is that D-branes are not classified by integral homology because Dp-branes wrapping certain cycles suffer from a Freed-Witten anomaly, which is cancelled by the insertion of D(p-2)-branes and sometimes D(p-4)-branes that end on the afflicted Dp-brane.  These inserted branes may either continue to infinity, in which case the composite object has an infinite mass, or else they may end on an anti-Dp-brane, in which case the total Dp-brane charge is zero.  In either case, one may wish to remove the anomalous Dp-branes from the spectrum, leaving only a subset of the original integral cohomology.\n\nThe inserted branes are unstable.  To see this, imagine that they extend in time away (into the past) from the anomalous brane.  This corresponds to a process in which the inserted branes decay via a Dp-brane that forms, wraps the forementioned cycle and then disappears.  MMS<ref>[[Juan Maldacena]], [[Greg Moore (physicist)|Gregory Moore]] and [[Nathan Seiberg]]. ''D-Brane Instantons and K-Theory Charges''. https://arxiv.org/abs/hep-th/0108100</ref> refer to this process as an instanton, although really it need not be instantonic.\n\nThe conserved charges are thus the nonanomolous subset quotiented by the unstable insertions.  This is precisely the [[Twisted K-theory#How to calculate it|Atiyah-Hirzebruch spectral sequence]] construction of twisted K-theory as a set.\n\n==Reconciling twisted K-theory and S-duality==\n\nDiaconescu, Moore, and Witten have pointed out that the twisted K-theory classification is not compatible with the [[S-duality]] covariance of type IIB string theory.  For example, consider the constraint on the [[Ramond–Ramond field|Ramond–Ramond 3-form field strength]] G<sub>3</sub> in the [[Twisted K-theory#How to calculate it|Atiyah-Hirzebruch spectral sequence]] (AHSS):\n\n:<math>  d_3G_3=Sq^3G_3+H\\cup G_3=G_3\\cup G_3+H\\cup G_3=0\n</math>\n\nwhere d<sub>3</sub>=Sq<sup>3</sup>+H is the first nontrivial differential in the AHSS, Sq<sup>3</sup> is the third [[Steenrod square]] and the last equality follows from the fact that the nth Steenrod square acting on any n-form x is x<math>\\cup</math>x.\n\nThe above equation is not invariant under S-duality, which exchanges G<sub>3</sub> and H.  Instead Diaconescu, Moore, and Witten have proposed the following S-duality covariant extension\n\n:<math>  G_3\\cup G_3+H\\cup G_3+H\\cup H=P\n</math>\n\nwhere P is an unknown characteristic class that depends only on the topology, and in particular not on the fluxes. {{harvtxt|Diaconescu|Freed|Moore|2007}} have found a constraint on P using the [[ME8|E<sub>8</sub> gauge theory approach to M-theory]] pioneered by Diaconescu, Moore, and Witten.\n\nThus D-branes in IIB are not classified by twisted K-theory after all, but some unknown S-duality-covariant object that inevitably also classifies both fundamental strings and [[NS5-brane]]s.\n\nHowever the MMS prescription for calculating twisted K-theory is easily S-covariantized, as the Freed-Witten anomalies respect S-duality.  Thus the S-covariantized form of the MMS construction may be applied to construct the S-covariantized twisted K-theory, as a set, without knowing having any geometric description for just what this strange covariant object is.  This program has been carried out in a number of papers, such as {{harvtxt|Evslin|Varadarajan|2003}} and {{harvtxt|Evslin|2003a}}, and was also applied to the classification of fluxes by {{harvtxt|Evslin|2003b}}.  {{harvtxt|Bouwknegt|Evslin|Jurco|Varghese|2006}} use this approach to prove Diaconescu, Moore, and Witten's conjectured constraint on the 3-fluxes, and they show that there is an additional term equal to the D3-brane charge. {{harvtxt|Evslin|2006}} shows that the [[Klebanov-Strassler cascade]] of [[Seiberg duality|Seiberg dualities]] consists of a series of S-dual MMS instantons, one for each Seiberg duality.  The group, <math>\\mathbf Z_N</math> of universality classes of the <math>SU(M+N)\\times SU(M)</math> supersymmetric [[gauge theory]] is then shown to agree with the S-dual twisted K-theory and not with the original twisted K-theory.\n\nSome authors have proposed radically different solutions to this puzzle.  For example, {{harvtxt|Kriz|Sati|2005}} propose that instead of twisted K-theory, II string theory configurations should be classified by [[elliptic cohomology]].\n\n==Researchers==\nProminent researchers in this area include [[Edward Witten]], Peter Bouwknegt, Angel Uranga, Emanuel Diaconescu, [[Greg Moore (physicist)|Gregory Moore]], [[Anton Kapustin]], [[Jonathan Rosenberg (mathematician)|Jonathan Rosenberg]], Ruben Minasian, Amihay Hanany, Hisham Sati, [[Nathan Seiberg]], [[Juan Maldacena]], [[Daniel Freed]], and Igor Kriz.\n\n==See also==\n*[[Kalb–Ramond field]]\n\n==Notes==\n{{reflist}}\n\n==References==\n*{{citation\n | last1 = Bouwknegt | first1 = Peter\n | last2 = Evslin | first2 = Jarah\n | last3 = Jurco | first3 = Branislav\n | last4 = Varghese | first4 = Mathai | authorlink3 = Mathai Varghese\n | last5 = Sati | first5 = Hisham\n | title = Flux Compactifications on Projective Spaces and The S-Duality Puzzle\n | journal = [[Advances in Theoretical and Mathematical Physics]]\n | volume = 10 | issue = 3\n | year = 2006 | pages = 345–394\n | arxiv = hep-th/0501110|bibcode = 2005hep.th....1110B | doi=10.4310/atmp.2006.v10.n3.a3}}.\n\n*{{citation\n | last1 = Bouwknegt | first1 = Peter\n | last2 = Evslin | first2 = Jarah\n | last3 = Varghese | first3 = Mathai | authorlink3 = Mathai Varghese\n | title = T-Duality: Topology Change from H-flux\n | journal = [[Communications in Mathematical Physics]]\n | volume = 249 | year = 2004 | pages = 383–415\n | doi = 10.1007/s00220-004-1115-6\n | arxiv = hep-th/0306062| issue = 2|bibcode = 2004CMaPh.249..383B }}.\n\n*{{citation\n | last1 = Bouwknegt | first1 = Peter\n | last2 = Varghese | first2 = Mathai | authorlink2 = Mathai Varghese\n | title = D-branes, B-fields and twisted K-theory\n | journal = [[Journal of High Energy Physics]]\n | year = 2000\n | volume = 0003\n | issue = 7\n | doi = 10.1088/1126-6708/2000/03/007\n | pages = 007\n | arxiv = hep-th/0002023|bibcode = 2000JHEP...03..007B }}.\n\n*{{citation\n | last1 = Diaconescu | first1 = Emanuel\n | last2 = Freed | first2 = Daniel S. | authorlink2=Dan Freed\n | last3 = Moore | first3 = Gregory\n | contribution = The M-theory 3-form and E<sub>8</sub> gauge theory\n | title = Elliptic Cohomology: Geometry, Applications, and Higher Chromatic Analogues\n | editor1-last = Miller | editor1-first = Haynes R.\n | editor2-last = Ravenel | editor2-first = Douglas C.\n | publisher = Cambridge University Press\n | year = 2007 | pages = 44–88\n | arxiv = hep-th/0312069|bibcode = 2003hep.th...12069D }}.\n\n*{{citation\n | last1 = Diaconescu | first1 = Emanuel\n | last2 = Moore | first2 = Gregory\n | last3 = Witten | first3 = Edward | authorlink3 = Edward Witten\n | title = E<sub>8</sub> Gauge Theory, and a Derivation of K-Theory from M-Theory\n | journal = [[Advances in Theoretical and Mathematical Physics]]\n | volume = 6 | issue = 6\n | year = 2003 | pages = 1031–1134\n | arxiv = hep-th/0005090|bibcode = 2000hep.th....5090D | doi = 10.4310/ATMP.2002.v6.n6.a2\n }}.\n\n*{{citation\n | last = Evslin | first = Jarah\n | title = IIB Soliton Spectra with All Fluxes Activated\n | journal = [[Nuclear Physics B]]\n | volume = 657\n | year = 2003a\n | pages = 139–168\n | doi = 10.1016/S0550-3213(03)00154-8|arxiv = hep-th/0211172 |bibcode = 2003NuPhB.657..139E }}.\n\n*{{citation\n | last = Evslin | first = Jarah\n | title = Twisted K-Theory from Monodromies\n | journal = [[Journal of High Energy Physics]]\n | volume = 0305 | year = 2003b | issue = 30\n | doi = 10.1088/1126-6708/2003/05/030\n | pages = 030\n | arxiv = hep-th/0302081|bibcode = 2003JHEP...05..030E }}.\n\n*{{citation\n | last = Evslin | first = Jarah\n | contribution = The Cascade is a MMS Instanton\n | title = Advances in Soliton Research\n | publisher = Nova Science Publishers\n | year = 2006\n | pages = 153–187\n | arxiv = hep-th/0405210|bibcode = 2004hep.th....5210E }}.\n\n*{{citation\n | last1 = Evslin | first1 = Jarah\n | last2 = Varadarajan | first2 = Uday\n | title = K-Theory and S-Duality: Starting Over from Square 3\n | journal = Journal of High Energy Physics\n | volume = 0303 | year = 2003 | issue = 26\n | doi = 10.1088/1126-6708/2003/03/026\n | pages = 026\n | arxiv = hep-th/0112084|bibcode = 2003JHEP...03..026E }}.\n\n*{{citation\n | last = Hanany | first1 = Amihay\n | last2 = Kol | first2 = Barak | authorlink2 = Barak Kol (physicist)\n | title = On Orientifolds, Discrete Torsion, Branes and M Theory\n | journal = Journal of High Energy Physics\n | year = 2000\n | volume = 0006\n | issue = 13\n | doi = 10.1088/1126-6708/2000/06/013\n | pages = 013\n | arxiv = hep-th/0003025|bibcode = 2000JHEP...06..013H }}.\n\n*{{citation\n | last = Kapustin\n | first = Anton\n | title = D-branes in a topologically nontrivial B-field\n | journal = [[Advances in Theoretical and Mathematical Physics]]\n | volume = 4\n | year = 2000\n | pages = 127–154\n | arxiv = hep-th/9909089|bibcode = 1999hep.th....9089K | doi = 10.4310/ATMP.2000.v4.n1.a3\n }}.\n\n*{{citation\n | last1 = Kriz | first1 = Igor\n | last2 = Sati | first2 = Hisham\n | title = Type IIB String Theory, S-Duality, and Generalized Cohomology\n | journal = Nuclear Physics B\n | volume = 715 | year = 2005 | pages = 639–664\n | doi = 10.1016/j.nuclphysb.2005.02.016\n | arxiv = hep-th/0410293| issue = 3|bibcode = 2005NuPhB.715..639K }}.\n\n*{{citation\n | last1 = Maldacena | first1 = Juan | authorlink1 = Juan Maldacena\n | last2 = Moore | first2 = Gregory\n | last3 = Seiberg | first3 = Nathan | authorlink3 = Nathan Seiberg\n | title = D-Brane Instantons and K-Theory Charges\n | journal = Journal of High Energy Physics\n | volume = 0111 | year = 2001 | issue = 62\n | doi = 10.1088/1126-6708/2001/11/062\n | pages = 062\n | arxiv = hep-th/0108100|bibcode = 2001JHEP...11..062M }}.\n\n*{{citation\n | last1 = Minasian | first1 = Ruben\n | last2 = Moore | first2 = Gregory\n | title = K-theory and Ramond-Ramond charge\n | journal = Journal of High Energy Physics\n | volume = 9711\n | year = 1997\n | issue = 2\n | doi =10.1088/1126-6708/1997/11/002\n | pages = 002\n | arxiv = hep-th/9710230|bibcode = 1997JHEP...11..002M }}.\n\n*{{citation\n | last1 = Olsen | first1 = Kasper\n | last2 = Szabo | first2 = Richard J. | authorlink2 = Richard J. Szabo\n | title = Constructing D-Branes from K-Theory\n | journal = Advances in Theoretical and Mathematical Physics\n | volume = 3 | issue = 4\n | year = 1999 | pages = 889–1025\n | arxiv = hep-th/9907140|bibcode = 1999hep.th....7140O | doi = 10.4310/ATMP.1999.v3.n4.a5\n }}.\n\n*{{citation\n |last        = Rosenberg\n |first       = Jonathan\n |title       = Continuous-Trace Algebras from the Bundle Theoretic Point of View\n |journal     = Journal of the Australian Mathematical Society, Series A\n |volume      = 47\n |year        = 1989\n |pages       = 368–381\n |url         = http://anziamj.austms.org.au/JAMSA/V47/Part3/Rosenberg.html\n |doi         = 10.1017/S1446788700033097\n |issue       = 3\n |deadurl     = yes\n |archiveurl  = https://web.archive.org/web/20060327202028/http://anziamj.austms.org.au/JAMSA/V47/Part3/Rosenberg.html\n |archivedate = 2006-03-27\n |df          = \n}}.\n\n*{{citation\n | last = Uranga | first = Angel M.\n | title = D-brane probes, RR tadpole cancellation and K-theory charge\n | journal = Nuclear Physics B\n | volume = 598 | issue = 1–2\n | year = 2001 | pages = 225–246\n | doi = 10.1016/S0550-3213(00)00787-2\n | arxiv = hep-th/0011048|bibcode = 2001NuPhB.598..225U }}.\n\n*{{citation\n | last1 = Varghese | first1 = Mathai | authorlink1 = Mathai Varghese\n | last2 = Sati | first2 = Hisham\n | title = Some Relations between Twisted K-theory and E<sub>8</sub> Gauge Theory\n | journal = Journal of High Energy Physics\n | volume = 0403 | year = 2004 | issue = 16\n | doi = 10.1088/1126-6708/2004/03/016\n | pages = 016\n | arxiv = hep-th/0312033|bibcode = 2004JHEP...03..016M }}.\n\n*{{citation\n | last = Witten | first = Edward | authorlink = Edward Witten\n | title = D-Branes and K-Theory\n | journal = Journal of High Energy Physics\n | volume = 9812\n | year = 1998\n | issue = 19\n | doi = 10.1088/1126-6708/1998/12/019\n | pages = 019\n | arxiv = hep-th/9810188|bibcode = 1998JHEP...12..019W }}.\n\n==References (condensed matter physics)==\n*{{citation\n | last = Kitaev | first = Alexei | authorlink = Alexei Kitaev\n | title = Periodic table for topological insulators and superconductors\n | journal = AIP Conference Proceedings\n | volume = 1134 | issue = 1 | pages = 22–30 | year = 2009\n | arxiv = 0901.2686|bibcode = 2009AIPC.1134...22K |doi = 10.1063/1.3149495 }}.\n\n*{{citation\n | last = Horava | first = Petr\n | title = Stability of Fermi Surfaces and K Theory\n | journal = Physical Review Letters\n | volume = 95\n | year = 2005\n | issue = 16405\n | pages = 016405\n | doi = 10.1103/physrevlett.95.016405 |arxiv = hep-th/0503006 |bibcode = 2005PhRvL..95a6405H | pmid=16090638}}.\n*{{citation\n | last = Roy | first = Rahul | title = Periodic Table for Floquet Topological Insulators\n | journal = Physical Review B\n | volume = 96 | issue = 15 | pages = 155118 | year = 2017\n | arxiv = 1603.06944|bibcode =2017PhRvB..96o5118R  |doi =10.1103/PhysRevB.96.155118  |author2=Fenner Harper}}.\n\n==Further reading==\nAn excellent introduction to the [[K-theory]] classification of [[D-branes]] in 10 dimensions via [[Ashoke Sen]]'s conjecture is the original paper \"D-branes and K-theory\" by [[Edward Witten]]; there is also an extensive review by {{harvtxt|Olsen|Szabo|1999}}.\n\nA very comprehensible introduction to the [[twisted K-theory]] classification of conserved D-brane charges on a 9-dimensional timeslice in the presence of Neveu–Schwarz flux is {{harvtxt|Maldacena|Moore|Seiberg|2001}}.\n\n==External links==\n*[http://xstructure.inr.ac.ru/x-bin/theme3.py?level=1&index1=296918 K-theory on arxiv.org]\n{{String theory topics |state=collapsed}}\n[[Category:String theory]]\n[[Category:Algebra]]\n[[Category:K-theory]]"
    }
  ]
}